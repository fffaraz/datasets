Is there a plan to incorporate these into tools like haskell-ide-engine to make them more performant?
The link to the book is broken!
As far as I am aware, this only exists because of HIE. They even mention HIE in the blog.
Yes. The author of the blog post mentions that that is what they will spend the rest of the summer working on.
In this industry they can't afford lose developers and luckily we get the option to choose where to work :)
Wasn't there an extension to compile to closed cartesian categories? [http://conal.net/papers/compiling-to-categories/compiling-to-categories.pdf](http://conal.net/papers/compiling-to-categories/compiling-to-categories.pdf) I think you might have to have a function `fix :: (Packed a -&gt; Packed a) -&gt; Packed a` though
Great to see more woking on haskell‚Äôs tooling
?
Ah! Thanks! I missed that bit. Very exciting!
I‚Äôd definitely be interested in doing that. What is the typical place to put such a write-up?
Not knowing anyone who knows more about Haskell than you do.
Are any donations needed to support this development?
But if you did something like foo(bar, baz) in a normal language where foo and bar are partial you‚Äôd sometimes get null pointer errors. Which also aren‚Äôt good.
@graninas when the video will be published?
Any thoughts on how one might include this in a Vim plugin? It'd be nice to have function types displayed in my editor.
It's probably not generally accepted yet, but I can recommend [co-log](https://github.com/kowainik/co-log). We are already using it in production, and I'm working on making it faster, implementing new features and improving the interface.
working link to the book mentioned: [Haskell Tutorial and Cookbook](https://leanpub.com/haskell-cookbook)
I'm using `hit-on` daily because it helps me to use `git` more efficiently and follow the workflow much easier: * https://github.com/kowainik/hit-on
I actually agree with this, I looked at the dhall webpage before writing this post and couldn't figure out what it could do
People would generally put them on their blogs. If you don't have a blog you could ask someone if they would host your post as a guest post. I'd be happy to have it on http://h2.jaguarpaw.co.uk/, for example.
For those interested, "zonking" refers to a step in type inference in which inferred, temporary type variables ("unification variables") are applied to an elaborated, intermediate form of the program. See slide 9 in this recent presentation (ZuriHac'19) by Simon Peyton Jones : https://drive.google.com/file/d/1NRkP0hz-0Yo49Rto70b2nUwxjPiGD9Ci/view
To be honest, in the real word, then only time you need to be able to chose an instance is for the case you gave with `Sum` and `Product`, which should be solved by defaulting a `Monoid Num` instance to `Sum`. Nobody ever use or need the `Product` instance. Having said that, using the `reducer` package you can get ommit the `Sum` using reduceWith getSum [1,2,3] Ok that doesn't work. you actually need reduceWith getSum [1,2, 3 :: Int] :: Int but in practice you don't need the type annotation. There is also the `reflection` package which helps to override temporary a type instance. I'll give you that both package are an absolute nightmare to use (and I don't undestand any of it ;-))
I do not currently have a blog, although I'll probably make one eventually. That would be great if you would host it! What format would you like the write-up in?
Cool. You can submit a PR to https://github.com/tomjaguarpaw/H2 The format is basically just a Markdown file in the `posts` directory. You can use the following as a guide if you like. https://github.com/tomjaguarpaw/H2/blob/master/posts/scrap-all-your-typeclasses-but-one.markdown
I really like that space invader clone of your, I should really try to run it on one of my boards one of these days. Also, your `clash-utils` library seems very useful! I like the way you organised the VGA timings for example. I had no idea `NumericUnderscores` worked for Nats at the type level! üòÖ
I‚Äôll check that out as well. Thanks!
&gt;[https://youtu.be/hIZxTQP1ifo](https://youtu.be/hIZxTQP1ifo) Paper/post/slides please? Talks are not a good reference. &gt;We can already pass around class dictionaries explicitly with \`-XConstraintKinds\`. I do not see options to create arbitrary dictionary at runtime with this extension. &amp;#x200B; &gt;I'm not sure special syntax for this is desirable; I clearly see that this opens a deep can of worms with legacy code relying on coherence. The question is, is it even possible to introduce the capability for new code without breaking legacy code in some subtle manner ? Because if it isn't, this type of extensions is unlikely to be implemented anyway, and discussing its usability is just a waste of time.
I use pandoc to generate slide-show from markdown.
Will this allow getting the types of application nodes as well as symbols? I'd like to use this for a tool in my Haskell course, where that is kindof essential.
Hey, I've been running through some Haskell tutorials (I'm playing around with LYAH for now) and I'm considering using Haskell to build an API client for something at work. I'm still very unfamiliar with the language / ecosystem / culture, so I'm curious: what's the "Haskell records problem"?
Thanks! I am planning to extend that Intel 8080 into a Z80, then build a home computer around it (TRS-80, or ZX Spectrum, don't know yet), and then write a book about the whole thing -- creating retrocomputers in Haskell. It will be aimed at people who already know Haskell but don't know anything about FPGAs. If you like that VGA driver, check out my more out-there version on the [`vga-ripple-counter` branch](https://github.com/gergoerdi/clash-utils/blob/vga-ripple-counter/src-clash/Cactus/Clash/VGA.hs); even if I won't end up using this construct of multi-dimensional ripple counters, I think I should move to a design where only the pixel clock and the **visible** screen resolution is part of the VGA mode's type, and the rest is encapsulated as implementation detail.
Also, make sure you check out what I call "very high-level simulation" in [this file](https://github.com/gergoerdi/clash-spaceinvaders/blob/master/src-clash/Hardware/Emulator/SpaceInvaders/Main.hs) where the CLaSH CPU is run outside CLaSH, as a simple `State` monad, allowing for interactive IO via SDL. You can play Space Invaders in a window using the same CPU implementation as what is synthesized for the FPGA! This has been invaluable for debugging. I also use the same technique to [run 8080 testsuites](https://github.com/gergoerdi/clash-spaceinvaders/blob/master/src-clash/Hardware/Clash/Intel8080/TestBench.hs), again, without using the CLaSH simulator of `Signal`s etc.
I think I've seen one of these files before! Very cool :D I have actually played around with Clash and SDL before! Here is my attempt: [https://github.com/basile-henry/clash-io](https://github.com/basile-henry/clash-io) I have no idea if it still works, but I could play Snake all on my CPU simulating with a VGA-like interface (it didn't do the timings properly). &amp;#x200B; My ambition with this project was to get a simple API that could get circuits to work on both a real FPGAs and simulated using SDL with a set of predefined inputs and outputs. &amp;#x200B; If I remember correctly, there's a branch on there where I was trying to implement CHIP8 but I never finished it. :( How do you do IO with Clash exactly? Do you have to write circuits that don't run in Signal or do you use \`sample\`/\`simulate\`? What I ended up doing was having SDL on the main thread and running the circuit in another thread, passing inputs and output using channels like this: [https://github.com/basile-henry/clash-io/blob/master/src/Clash/IO.hs#L65](https://github.com/basile-henry/clash-io/blob/master/src/Clash/IO.hs#L65)
It looks nice! The GADT to carry the constraints is something we use more and more at work. :) I'm curious why you decided to put so many fields interdependent fields in your \`VGADriver\`. I would have probably just kept 2 counters kept as an implementation detail and not exported to outside the module along with a bunch of functions to expose the same API as you do. This way you can't represent an invalid state!
I suspect a dedicated plugin will exist some day, but it sounds like the intention here is for this mechanism to work seemlessly with the language server protocol, meaning any existing LSP plugin would suddenly support all its features in a Haskell project. https://www.google.com/search?q=vim+language+server+protocol A great approach, IMO!
What are "application nodes"?
You didn't mention the live demo. You don't have JavaScript disabled, do you?
I'm not sure what you mean. The visible X/Y coordinate has to be exported from the VGA driver, because that is what you use to either index into some frame buffer (for frame buffer-backed graphics) or use that as the input to your pattern generator (for generative graphics).
The live demo was filed under "other noise on the screen". I'm not in the camp which thinks a language _start_ page should contain a live demo. Maybe a link to a live demo, that's fine. But why would I want immediately try a language I don't even even know the syntax of? If you look from that viewpoint, it's nothing more than a small set of (mostly trivial) examples. Maybe it's a good way to learn for some people, but probably not a good fit for _all_ people. Anyway I admit that I didn't spent too much time on the page, but I found the way it was organized very frustrating. YMMV.
The simplest way I've found to do IO with Clash is to do it without Clash. And yeah that's not just some Yoda bullshit, this is actually what I am doing. I am using the [`CPU` monad abstraction](https://github.com/gergoerdi/clash-utils/blob/98f3e1fd03a5b494ee6bbffb55e90a5ee01acde2/src-clash/Cactus/Clash/CPU.hs) that I have [written about before](https://unsafeperform.io/blog/2018-09-15-very_high-level_simulation_of_a_c_ash_cpu/) (except I have changed it to collect an `HKD CPUOut Last` instead of an `Endo CPUOut` because of [reasons](https://github.com/clash-lang/clash-compiler/issues/613)) which enables me to run a CPU definition from normal Haskell, using `IOArray`s for memory etc. It is not fully automated, in that you still have to write some `IO` (in my case, SDL) code specific to your machine, but usually the CPU is where most of the complexity is, so if you can run that without Clash, that's already a huge win.
Sure but the visible X and Y coordinates can be derived from your internal counters. The internal counters start before and finish after their X/Y equivalent and the tick at the pixel clock so you can reliably do your timings with front and back porches.
Ah yes, that must be where I first saw you doing Clash and SDL! :D \&gt; but usually the CPU is where most of the complexity is, so if you can run that without Clash, that's already a huge win. Do you think Clash is inherently too slow or do you think Clash could be improved so that a more lightweight solution like my \`Chan\` solution would be viable for your CPU code?
More concretely what I mean is something along these lines of: ``` data VGADriver dom w h = VGADriver { vert :: Signal dom (Sum (Indices '[h, preH, syncH, postH])) -- Keeping your special Sum counter , horz :: Signal dom (Sum (Indices '[w, preW, syncW, postW])) } ``` And that's it! :D Now you can derive everything else from that with a single source of truth (there is no possible version of `VGADriver` that's not valid: ``` vgaVSync :: VGADriver dom w h -&gt; Signal dom Bit vgaVSync VGADriver{vert} = case vert of There (There (Here _)) -&gt; high -- depending on polarity _ -&gt; low ``` ``` vgaX :: VGADriver dom w h -&gt; Signal dom (Maybe (Index w)) vgaX VGADriver{horz) = case horz of Here x -&gt; Just x _ -&gt; Nothing ``` ``` vgaEndLine :: VGADriver dom w h -&gt; Signal dom Bool vgaEndLine = fmap (== Just maxBound) . vgaX ``` All of this is completely untested, but hopefully you see what I'm suggesting. There might be ways to makes this a bit less verbose and reuse code for both X and Y... What do you think?
i'd guess they're asking about getting the types of expressions like `f x`
Looks interesting! I'm trying to write a minimum sample code, a simple counter, but I'm stuck. It runs into a loop. ```haskell main :: IO () main = do Warp.run 8000 $ app "Counter" defaultConnectionOptions 1 run run :: Int -&gt; IO (Maybe (HTML, Int, Event -&gt; IO ())) run i = do pure $ Just ( [ VText $ "count: " &lt;&gt; show i , VNode "button" (M.fromList [("onClick", AEvent (\ev -&gt; pure ()))]) -- ?? do something here?? [ VText "increment" ] ] , i+1 , const (pure ()) -- ?? do something here?? ) ```
You have to define the handler for the javascript as well, something like this: app :: Connection -&gt; Connection -&gt; Application app conn1 conn2 request respond = respond $ case rawPathInfo request of "/myindex/" -&gt; responseIndex "/myindex/myjavascript.js" -&gt; responseJs _ -&gt; responseNothing responseIndex :: Response responseIndex = responseFile status200 [("Content-Type", "text/html")] "index.html" Nothing responseJs :: Response responseJs = responseFile status200 [("Content-Type", "text/javascript")] "myjavascript.js" Nothing
That's an interesting read, thanks! Some of the ideas described there are very relevant to client side prediction. I was actually thinking along the same lines of storing a history of VDOMs on the server in order to be able to replay events when server and client "desync".
How/why are you using 700 type params? It sounds interesting. Some sort of autogenerated type?
Oh, nice! Very interesting to see how they've solved virtually the same challenges. The only thing I found prior to implementing Replica was Elixir's LabView, which afaics isn't strictly about DOM diffing, but rather about controlling the browser remotely. The idea must be in the air indeed.
I'd recommend checking out https://github.com/pkamenarsky/concur-replica, which is a Concur backend for Replica. It contains some examples that might be helpful.
Exactly - you summed up my sentiment and the motivation for writing Replica quite nicely.
Oh, it was just a test. I later did another test with 4192 parameters.
Nice. reminds of my old idea for a start-up to provide something like Travis, but for benchmarks, maybe building on Gipeda.
Nice!
This is a bit like threepenny-gui. What are the differences?
For example the expression `f x` in `f x y z`. Ie. The `HsApp`nodes of the ghc ast.
Would you like to join a startup in that vein now? We'd love to have you.
For uninteresting reasons, I think some of the types do need to be recomputed (and some other types are skipped outright in the files because computing them the simple way would be expensive). There's a GHC ticket laying around somewhere about this and how to fix it...
Not right now, but hopefully someday. I think application nodes might not currently export their types for performance reasons. There's a GHC ticket about this.
This video should be required viewing for impatient investors. Duncan does a great job communicating the complexities of building Cardano. Makes other cryptocurrencies seem fly-by-night.
I've never heard of an idempotent group. Is that a thing? I've only seen idempotence as a property of an element under a particular operation (or as a property of an operation if \forall x. x * x = x). I can definitely see why such a group would have to be trivial (since the identity of a group is both unique and the only idempotent element), I've just never seen that term before. Great reference, though!
The Essence of the Iterator Pattern: this is one of the key papers in the Haskell lexicon. Unfortunately, it is based on an old version of the Haskell Base Library (eg, Applicative is not a superclass of Monad. Data.Functor.\* and the Data.Coerce class didn't exist). *Is there a rendition of the functions in the paper using contemporary, err, idioms / libraries?* I had a crack at it, but there are so many rabbit holes relating to wrapping and unwrapping (new)types that may or may not be addressed by ScopedTypeVariables or QuantifiesContraints. This jiggery pokery completely subverts the main purpose of the paper, which was to illustrate the nature of Traversable. I completely get that the likes of Conor McBride (@pigworker)'s signature is beautiful notation, but it is a barrier to understanding to have to add a further level of indirection and translate things through banana brackets, or whatever,
Thanks, finally it works. I have spent last couple days on the issue. &amp;#x200B; All my **Wai code**, **javascript** and **html** file are on the **same directory**. In order to make it to work. I have change it a bit as following: &amp;#x200B; app :: Connection -&gt; Connection -&gt; Application app conn1 conn2 request respond = respond $ case rawPathInfo request of "/myindex/" -&gt; responseIndex "/myjavascript.js" -&gt; responseJs _ -&gt; responseNothing Also I have to remove the **slash** from origin code inside **index.html** file change: &lt;script src="./myjavascript.js"&gt;&lt;/script&gt; to: &lt;script src="myjavascript.js"&gt;&lt;/script&gt; &amp;#x200B; &amp;#x200B; **path** is always the painful for web services
https://cs.brown.edu/courses/cs173/2012/OnLine/ is pretty good. And reading the papers and the subject and their references.
Eventually, I got some BLAS-like performance with my fork of `simd` https://github.com/Magalame/simd
An example of an idempotent group: Kleene algebra (i.e. regular expressions) forms an idempotent semiring. So + (regular expression choice) is an idempotent group. A | A is just A.
You have roughly described [PureScript](http://www.purescript.org/).
What is your disruptive project? What is the compensation?
I've wondered about a cloud benchmarking service like that before, but I wasn't sure how you'd make the benchmark results usefully consistent. Just using virtual servers is a problem, because other tenants on the same host affect you. If you get around that, there's still the problem of how to do independent benchmark runs in parallel on the same host without them affecting each other...
A couple thoughts 1. That's not too hard at all! HM + row polymorphism should be quite doable for a motivated beginner 2. That said, I recommend trying to implement some slightly simpler languages first. Namely, try an HM language with no special features (basically, pure ML) first, and perhaps even before that a lambda calculus with type annotation. You don't need a parser or anything, just writing the code to go from untyped AST to typed is really informative 3. If you haven't, looking at Benjamin Pierce's textbook "Types and Programming Languages" is likely to be helpful on your journey 4. Look at "functional pearls" on type checking. For instance [this one](http://gallium.inria.fr/~fpottier/publis/fpottier-elaboration.pdf)
Thank you so much for this. The free PDF "Category Theory as Coherently Constructive Lattice Theory" has this table Your Haskell specified lattice section must necessarily be constructive. Lattice theory is an instance of concept the category theory concept -------------- ------------------- monotonic function functor (pointwise) natural ordering transformation between between functors functions supremum colimit least initial Galois connection adjunction prefix point algebra closure operator monad
It's not so common with groups, as you observed, but people talk about e.g. "idempotent monoids". (They also talk about operators being idempotent, or about idempotent elements.)
Dude, think about the exposure
That's an idempotent _monoid_ ‚Äì | doesn't have inverses. The only idempotent group is the trivial group. Quick proof: suppose (*G*,¬∑,*u*,‚Ä≤) is an idempotent group. We're going to show that any two elements of the group are equal. For all *x*,*y* ‚àä *G*, we have *x* = *xx* and *y* = *yy*, so (*xx*)y = *xy* = *x*(*yy*). We can multiply on the left by *x*‚Ä≤ and on the right by *y*‚Ä≤ to conclude that *x*‚Ä≤(*xxy*)*y‚Ä≤* = *x*‚Ä≤(*xyy*)*y‚Ä≤*. By associativity and cancelling inverses, we get *y* = *x*, which is what we wanted to prove ‚Äì all elements of this group are equal, so *G* = {*u*}.
+1 on TAPL, it will definitely guide you toward H-M. I don't think row polymorphism is covered explicitly in TAPL, but it does survey types of polymorphism. Adv. TAPL might go into more detail about row polymorphism.
Thank you so much for this. The free PDF "Category Theory as Coherently Constructive Lattice Theory" has this table. Your Haskell specified lattice section must necessarily be constructive. |||| |:-|:-|:-| |||
Hmmm I can't find them, are they on another channel?
Thank you so much for this. &amp;#x200B; The free PDF "Category Theory as Coherently Constructive Lattice Theory" has this table Your Haskell specified lattice section must necessarily be constructive. &amp;#x200B; Lattice theory is an instance of concept the category theory concept monotonic function functor (pointwise) natural ordering transformation between between functors functions supremum colimit least initial Galois connection adjunction prefix point algebra closure operator monad
Why learn Hindley-Milner when you can learn [Bidirectional Type Checking](https://www.youtube.com/watch?v=utyBNDj7s2w)? This presentation has some references at the end, and /u/davidchristiansen claims that [Complete and Easy Bidirectional Typechecking for Higher-rank Polymorphism](https://www.cl.cam.ac.uk/~nk480/bidir.pdf) handles Haskell, but is simultaneously way easier than "most other approaches". My worry is that Hindley-Milner needs so many adaptations to become compatible with modern Haskell that it might not be the best starting point.
I love bidirectional, but it's not the best if your goal is inference in the absence of any type annotations.
What does this have to do with Haskell?
I guess I just prefer expressivity over the absence of any type annotations, since I think some annotations make it easier to read the program.
Expressivity is not always a goal in and of itself. Sometimes, decreasing expressivity allows us to get stronger guarantees about a system. For instance, we know things about programs written in a total language that we can't possibly know about programs written in a general recursive language, but we may have very good reasons for using something like Haskell instead of something like Agda. In any particular case, it's a matter of finding a level of expressive power that fits our particular goals, and OP's goal is a Hindley-Milner style system. Bidirectional type checking is wonderful, but it's one of many great techniques, and part of getting good at writing type checkers is learning more techniques. (I also remembered the paper a bit wrong, unfortunately - they don't provide full H-M, they just sketch it in Section 8. Sorry about that! Their system is the usual bidirectional outcome where top-level polymorphic functions have annotations.)
I like the book that we used at ITU Copenhagen, Sestoft's _Programming Language Concepts_. I think it goes into a good level of detail, without overwhelming beginners. It's a good intro.
Oh, that makes sense. Then you can squint and get the absorption laws out of the idempotent monoids on `&amp;&amp;` and `||`. Neat!
[https://www.cs.kent.ac.uk/people/staff/sjt/TTFP/ttfp.pdf](https://www.cs.kent.ac.uk/people/staff/sjt/TTFP/ttfp.pdf) [https://www.amazon.com/Types-Programming-Languages-MIT-Press/dp/0262162091](https://www.amazon.com/Types-Programming-Languages-MIT-Press/dp/0262162091) [https://www.amazon.com/gp/product/0262162288/ref=dbs\_a\_def\_rwt\_hsch\_vapi\_taft\_p1\_i2](https://www.amazon.com/gp/product/0262162288/ref=dbs_a_def_rwt_hsch_vapi_taft_p1_i2)
Because we don't have a decision procedure for which annotations improve readability. So, we leave the choice to the programmer. So, we have to deal with the case when they choose no annotations.
Japanese learning / book reading app [tenjinreader.com](https://tenjinreader.com) &amp;#x200B; Though there is only a hosted version right now.. but its full stack Haskell!
DSP: a simple (command-line ?) audio editor with collection of enhancing filters and mixing capabilities. Informative plotting of key audio spectra. Maybe Elements of sound/speech synthesis. DIP/Machine learning: classification of images using pattern recognition with kernel methods (not neuron netwoks) of machine learning over detected image features. Visualisation of built models, revealing the key image features for the classification decisions.
Well sure, but as long as those don't happen "too often" it's pretty easy to keep walking down the success path in a manner with far less friction than the Haskell one. (To be fair, I think the friction is "necessary": it's absent in other languages due to a lack of safety, but I do think we have yet to find the next big thing that will greatly reduce the amount of necessary hand plumbing while keeping the safety)
To toot my own horn: also see if you can get it working with a [compositional type system](https://gergo.erdi.hu/talks/2016-06-compty/CompTy.pdf) instead of Hindley-Milner.
I don't know if this will fit under your focus: I have not found a simple, well-written example of a source-to-source translator in Haskell. Tutorials on parsing usually don't have very good motivation or they go down a formal compiler route. What I would love to see if is a simple project that: 1. Defines a small programming language (a small subset of C, for ex) 2. Parses the source code into an AST 3. Generates a source code for another language from the AST (ex: Haskell, Java, JS, etc.) I would love to write a DSL in Haskell and every time I try to read some tutorials on parsing, I quickly lose interest either because they are too trivial or too complex. I will pay $10 just for that chapter :)
If you are a time traveler from the past, I regret to inform you Mr. Curry has passed on and this is not his email
[Christoph's talk](https://youtube.com/watch?v=ytPAlhnAKro) is a good place to start.
Purescript?
Sorry, one start-up at a time :-D
When I did this for GHC I eventually counted instructions per valgrind. It's only a proxy for real performance, but good enough to catch most unwanted regressions.
Thanks for your reply! Checked out concur-replica. So I now understand that I should implement `run` function as step-by-step interpreter of free monad. Now the counter sample runs as expected! ```haskell run :: (Int, Free Counter a) -&gt; IO (Maybe (HTML, (Int, Free Counter a), Event -&gt; IO ())) run (i, v) = case v of Pure a -&gt; pure Nothing Free (View html next) -&gt; pure $ Just (html, (i, next), \event -&gt; fireEvent html (evtPath event) (evtType event) (DOMEvent $ evtEvent event)) Free (GetInt next') -&gt; run (i, next' i) Free (IncInt next) -&gt; run (i+1, next) Free (StepIO io next') -&gt; io &gt;&gt;= run . (i,) . next' data Counter a = View HTML a | GetInt (Int -&gt; a) | IncInt a | forall v. StepIO (IO v) (v -&gt; a) instance Functor Counter where fmap f (View html a) = View html (f a) fmap f (GetInt a) = GetInt (f &lt;$&gt; a) fmap f (IncInt a) = IncInt (f a) fmap f (StepIO io a) = StepIO io (f &lt;$&gt; a) getInt :: Free Counter Int getInt = Free $ GetInt $ \i -&gt; Pure i incInt :: Free Counter () incInt = Free $ IncInt (Pure ()) view' :: HTML -&gt; Free Counter () view' html = Free $ View html (Pure ()) view :: ((e -&gt; IO ()) -&gt; HTML) -&gt; Free Counter e view act = do mvar &lt;- Free $ StepIO newEmptyMVar (\v -&gt; Pure v) view' $ act $ putMVar mvar Free $ StepIO (takeMVar mvar) (\v -&gt; Pure v) counter :: Free Counter () counter = do i &lt;- getInt _ &lt;- view $ \handler -&gt; [ VText $ "count: " &lt;&gt; show i , VNode "button" (M.fromList [("onClick", AEvent (\ev -&gt; handler ()))]) [ VText "increment" ] ] incInt counter ```
Implementation of Functional Programming Languages: https://www.microsoft.com/en-us/research/publication/the-implementation-of-functional-programming-languages/ There's a chapter or two about type checking with example source code. The code is a bit convoluted because it is using the Miranda purely functional language. It can be simplified a lot if you use a non-pure language or monads to manage the state.
Sir, this is a Wendy's
Does your test (in package.yaml) executable depend on your main executable / library? This should work just fine
The last chapter of ATAPL is essentially all about one version of row polymorphism.
I disagree -- I think that HM is a better starting point to _learn_, even if you end up doing something different once you learn it.
Yeah, PS is awesome :)
Thanks for the tips, really helped me and kept my motivation going! üòÅ
Thank you!
I'll take a look! Thanks
Ouch! Actually one of my goals with my language is to minimize type annotations (it's an experiment) so it might not work for me
Thaaaanks!
I'll take a look, thanks!
Thanks!
Thank you! I'll take a look!
Oh wow, *another* awesome innovation! I have literally been thinking over the past few weeks of writing a GHC plugin that would store all source information in a SQLite database... and here it is! My main goal is to be able to write an extension of `weeder` that works across Cabal components, and doesn't require `stack`. It sounds like this should be doable with this new flag.
The [Wikipedia article](https://en.m.wikipedia.org/wiki/Haskell_Curry?wprov=sfti1) has a Major Publications section, you could start there.
Desktop link: https://en.wikipedia.org/wiki/Haskell_Curry?wprov=sfti1 *** ^^/r/HelperBot_ ^^Downvote ^^to ^^remove. ^^Counter: ^^264456. [^^Found ^^a ^^bug?](https://reddit.com/message/compose/?to=swim1929&amp;subject=Bug&amp;message=https://reddit.com/r/haskell/comments/c7a6hn/looking_for_haskell_currys_manuscripts_books_or/esec0ny/)
How can I access the module pragmas (ie. language pragmas or ghc-options) using ghc-lib-parser? &amp;#x200B; I need to build a preflight check for web-exercise system and I need to make the whole thing abort when someone tries to pull too nasty extensions to play
I think I've had some problems. I'm using stack from git (`stack upgrade --git`), somehow it disappeared. Maybe because the fix is in master, maybe because I did `stack install intero` inside the project. Not guaranteeing, but maybe one of these might help you (I'd begin by doing `stack install intero` inside your proj).
For the Hindley-Milner fragment I highly recommend [Algorithm-W-Step-By-Step](https://github.com/wh5a/Algorithm-W-Step-By-Step), [A Generalized Let-Polymorphic Type Inference Algorithm](http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=1856F082F33AE95870697067F54564A5?doi=10.1.1.41.6832&amp;rep=rep1&amp;type=pdf) and [Compositional Type Checking](https://gergo.erdi.hu/projects/tandoori/Tandoori-Compositional-Typeclass.pdf). I've found the Algorithm M to be much nicer than Algorithm W, even though it's much less known.
Don't you want to enforce `-XSafe` instead if you're concerned about e.g. TH running IO?
What are those outliers?
Relatedly https://github.com/chrisdone/intero/issues/630
To the best of my understanding, outliers are samples that differ too much from the average (I'm not sure by how much they must be different to be considered outliers). Criterion is complaining that these outliers contribute too much to the total variance. This is usually a symptom of the setup being too noisy, or the sample size being too small. It could also mean that the thing I'm trying to measure just doesn't have a consistent run time. Seeing as the percentage of variance due to outliers goes down as the string length goes up, I would guess that even longer strings would result in lesser outlier-variance-percentage-metric-statistic-thing, and hence, more consistent results. However, Rust's benchmarking library insisted on testing the 1_000_000 long string for 1.5 hours(!) for some reason I couldn't figure out, so in the end I decided to not include benchmarks with strings of length 1_000_000 or higher.
Impressive, but is it not like comparing apples and oranges? After all one language is GCed aiming at high-level development and the other one is not aiming at low-level development.
&gt; I think, first of all, every project web page should start with "what this project is about". And I don't mean big catchy colored sentences, but in no-nonsense language. The first line on the page is: "The non-repetitive alternative to YAML". That is what the project is about. Additionally, the example from live demo is using Dhall to reduce repetition in YAML. I welcome any suggestions for how to more effectively convey the message that Dhall is about reducing repetition in YAML.
I'm not sure whether it suits your need, but you can have a look at `shelltestrunner`: * https://github.com/simonmichael/shelltestrunner
Yes, it's unfair to expect Haskell and Rust to be equally fast, but it's still useful to understand just by how much one is faster than the other. For example, now we know that Haskell can be used for performance-demanding tasks. 2 times slowdown isn't too bad, and it's probably just me not optimising properly.
Thanks for the suggestion. I came across that as well when I was initially researching available solutions. I decided against it but I'll give it another look.
Why are you using custom regex matching implementations instead of using existing libraries?
When initially scoping out test strategies, I read a few accounts of people making their IO code more testable using typeclasses. I decided not to go that route. However, I think I could (and should) refactor my code to expose the parameters that the CLI _would_ pass `executeFile`. That would make testing trivial. Tests would still run IO, but the results would be lists of parameters rather than calls to any execv* functions.
Lmao what a joke
I would suggest to have different level of summaries: * a one sentence summary - you already have this, but all other other noise on the page distracts the eye from this (also what if the reader is not familiar with the abbreviation YAML...?) * then a 5-to-10 sentence summary, still on the start page * then links to more detailed explanations, documentation, examples, etc And forget all the big colored catchphrases, or at least move them away from the start page to a "marketing brochure" page. And I would suggest to also move the live summary away from the start page, and instead just link it from the main page. See also the other comments above. You may agree or disagree, but it seems to me the present thread demonstrates that the current organization of the page is confusing and/or frustrating for at least some people.
Thank you very much :)
I saw a [cool paper](https://sebfisch.github.io/haskell-regexp/regexp-play.pdf) recently, and though to implement the algorithm described there, just to see what happens and how it performs. I'm not saying to use this in production or anything, that indeed would be counter-productive.
Actually, Haskell and Rust aren't that different. Both languages are compiled to machine code (unlike languages like Java or Python). And both are statically typed and allow good optimization, despite having highly advanced type systems.
Unfortunately still in progress, sorry!
Rust is still way faster.
Haskell is highly abstract, rust tries to have zero cost abstractions, but is still full of low level concerns. They're just fundamentally different.
Yes, but the difference isn't _that_ big. Unfortunately, I'm not experienced in Haskell, so I can't tell if the Haskell code could be optimized more.
Hello can anyone help me with my function? I'm completely new to Haskell. &amp;#x200B; `fibIter :: (Int, Int, Int) -&gt; Int` `fibIter a b c` `| b == 0 = b` `| otherwise = fib_iter((a+b), a, (c-1))` &amp;#x200B; `fib :: Int -&gt; Int` `fib n = fibIter(1, 0, n)` &amp;#x200B; I'm getting back this error: &amp;#x200B; *2.hs:6:1: error:* *‚Ä¢ Couldn't match expected type ‚ÄòInt‚Äô* *with actual type ‚Äò(Int, Int, Int) -&gt; Integer -&gt; (Int, Int, Int)‚Äô* *‚Ä¢ The equation(s) for ‚ÄòfibIter‚Äô have three arguments,* *but its type ‚Äò(Int, Int, Int) -&gt; Int‚Äô has only one*
Typically, you store the permutation of the numbers [1..n] (in your case, A..Z, but numbers are more convenient), as the list of images in that order. That is, for example `[3,2,4,1,5]` means the permutation 1-&gt;3, 2-&gt;2, 3-&gt;4, 4-&gt;1, 5-&gt;5. Now an easy algorithm to detect the cycles is start with any element (say 1), and follow the orbit, marking every visited number, until you get back to something already visited. In this case 1-&gt;3-&gt;4-&gt;1, so you have a cycle of length 3. Then if there are any remaining elements (in this case 2 and 5), you can do it again with one of them, say 2. In this case 2 is a fixed point (cycle of length 1), so we already immediately done. Then finally you start with 5, which is also a fixed point. To write this in Haskell, you need state (marking of the visited points). You can either do it by explicitly passing around the state, or using the state monad (which is a more familiar syntax for exactly the same things). Since you are a beginner, I recommend the explicit state passing. If you only want to use it, and not interested in coding, then you can find a ready-made implementation in the [combinat](https://hackage.haskell.org/package/combinat) package, in the module [Math.Combinat.Permutations](https://hackage.haskell.org/package/combinat-0.2.9.0/docs/Math-Combinat-Permutations.html). You want to function `permutationToDisjointCycles`. You can also study its source code, it is relatively simple (though it uses the ST monad, which is a kind of advanced concept, but basically it emulates the traditional imperative programming style)
Stephen Diehl wrote a nice tutorial on implementing Hindley-Milner in Haskell: http://dev.stephendiehl.com/fun/006_hindley_milner.html
Bidirectional checking is the preferred implementation style for H-M and pretty much for everything. Examples: Agda and Purescript, both handling a superset of H-M, are bidirectional.
`Reg` could be a `newtype`.
It looks like I figured out how to do it. But I'm not aware about the quality of the \[code\]([https://pastebin.com/raw/4dMsPdEe](https://pastebin.com/raw/4dMsPdEe)). So I would appreciate any opinion with regard to it.
Sure, I'll certainly use `-XSafe`, but I'm having a bit of hard time trusting it enough. Sure, it blocks overlapping instances etc. but it still allows slapping things like `{-#OPTIONS_GHC -F -pgmF choose_any_program_here #-}` in source files. Also, even disregarding the stuff that happens in compile time, there's dozen or so language extensions added since safe Haskell and having a bug leading to unsafecoerce is not unheard of.
found the issue: I was using package name imports for the main library; removing those made it work.
Why are you running with the multithreaded runtime? It doubles the running time on my machine.
That's a fine goal, but possibly not what OP is looking for if they want Hindley-Milner. Depends on your use case. For example, Elm has total inference so JS devs don't get scared by type signatures, but PureScript attracts a less type-averse audience and gets a more expressive system because of it.
&gt; both handling a superset of H-M Are they supersets in terms of what can be inferred? Hindley-Milner can assign types to any functions in the absence of type annotations, but I'm not sure that the same is true for Agda. Also, Agda uses bidirectional typing, but uses higher-order unification to resolve implicits. It's not purely local inference.
When you write `fibIter a b c` you're asking for three different arguments. If you want to unpack a tuple, you'd write `fibIter (a,b,c)`
I think the hardest part is coming up with reasonable benchmarks that cover your actual use cases, while not being your actual use cases ... &gt; how to do independent benchmark runs in parallel in the same (virtual or dedicated) server without them affecting each other... I guess the question is how often do you really need to run them in parallel? There is a decent amount of interference resistant benchmarking techniques you can run in parallel. Instruction counting using valgrind, simulating cache using cache grind, profiling information, GC stats, memory residency and IO. And that's just what I can think of from the top of my head. All of these should be able to run without issues in parallel. So you run these to some detail on every commit, or maybe only doing a full snapshot every few commits. For more detail than that it get's harder. In the best case run benchmarks on an otherwise unloaded system. But depending on the program running them NUMA aware should be able to reduce interference to reasonable levels in a multi-cpu setup. You have to make sure the APP isn't bottlenecked on shared resources like IO but that seems like a reasonable limitation. You waste a lot of cores that way so the question here is really if it's worth the cost but that still seems *somewhat* reasonably. Especially if you do it eg. on a weekly/on demand basis. There can still be issues like random alignment changes causing regressions for an inner loop. But with that and reasonable benchmarks it would be quite hard to miss meaningful regression.
Shameless self-plug: https://github.com/phadej/OL-1. - That's an implementation of HM-powerful system, i.e. no fancy types. See types: [`Type.hs`](https://github.com/phadej/OL-1/blob/master/OL-I/src/OL1/Type.hs#L19-L30) - Which has bidirectional type-checking. See terms [`Expr.hs`](https://github.com/phadej/OL-1/blob/7e7a626fb11ecb5f15b2d0e74810bde340088555/OL-I/src/OL1/Expr.hs#L25-L49) - Yet, there is type inference: [`Synth.hs`](https://github.com/phadej/OL-1/blob/master/OL-I/src/OL1/Synth.hs) - ... and arbitrary tuples [example](https://github.com/phadej/OL-1/blob/master/OL-I/fixtures/tuples-poly.out) [another](https://github.com/phadej/OL-1/blob/master/OL-I/fixtures/tuples.out) - ... and proof search: [`Search.hs`][https://github.com/phadej/OL-1/blob/7e7a626fb11ecb5f15b2d0e74810bde340088555/OL-I/src/OL1/Search.hs] [example](https://github.com/phadej/OL-1/blob/master/OL-I/fixtures/search.out) - ... and more examples, e.g not the worst possible error messages (see `out` files) in https://github.com/phadej/OL-1/tree/master/OL-I/fixtures That to say, that bidirectionally formulated type-systems are /nice/, and they can be used to formulate "weak" systems too. In this case type-checker in [`Check.hs`](https://github.com/phadej/OL-1/blob/master/OL-I/src/OL1/Check.hs) and type-inferencer in [`Synth.hs`](https://github.com/phadej/OL-1/blob/master/OL-I/src/OL1/Synth.hs) have the very same outline structure: both are structural recursions. (I know, my naming is awful, as I tried to confuse everyone). Yet, writing just a type-checker first is a lot easier task; and a bidirectional system is more human friendly (i.e. to write terms by hand), so one can start playing with it early. In fact, type-checker was there first, and `Synth.hs` started as a copy of `Check.hs`. The `OL-1` might be also interesting, because IMO implementing arbitrary tuples is in some way a prerequisite for understanding how to implement rows (and then their polymorphism). Note how `OL-1` (nor Haskell, built-in) don't have "tuple-polymorphism", i.e. there aren't `fst` which would work with arbitrary N-tuple (N &gt;= 1); in Haskell `fst :: (a, b) -&gt; a` if only for 2-tuple (pair). Disclaimer: `OL-1` is an experiment how far one can push usage of `bound` and [`bound-extras`](https://hackage.haskell.org/package/bound-extras). And my learning exercise. So there's only a lot of code, which probably makes sense only when you already know what's it doing. Sorry for that.
&gt;Why are you running with the multithreaded runtime? I don't think there is a specific reason, it's probably some default somewhere
Using `take n . cycle` instead of `concat . replicate n`, approximately halves the running time for me.
This benchmark is kind of weird since we generate the text while running the benchmark, which means that you never have to store all of the text in memory at one time. That in turn greatly improves memory locality (I think; I'm not an expert on this). Ideally we would generate the text once, before the benchmark starts. But, and I've tested this, then the real (bad) performance of Haskell's linked lists becomes more pronounced. To solve that you could use vectors instead of lists (I have not tested this). But I think that rust also doesn't produce the entirety of the text in memory, so I think it is fair this way (except that it doesn't reflect reality).
Oh, wait this halves the length...
Narrator: It wasn't
I'm so hyped about using any of these. Check their status frequently. Especially webhgc + miso feels tempting.
I have written a compiler from I- to S-Expressions in Haskell and would love some feedback. The source code is on [Hackage](https://hackage.haskell.org/package/haskeme).
I like your style : )
I have tried unboxed vectors and it turns out to be pretty fast. The only disadvantage is that it only accepts 'unboxable' elements of the vector (can anybody think of an interesting use-case for regexes over a type that is not an instance of Unbox?). Benchmark results: benchmarking ab/1_000 time 43.16 Œºs (42.90 Œºs .. 43.47 Œºs) 0.999 R¬≤ (0.998 R¬≤ .. 1.000 R¬≤) mean 44.96 Œºs (44.44 Œºs .. 46.08 Œºs) std dev 3.470 Œºs (2.284 Œºs .. 6.121 Œºs) variance introduced by outliers: 81% (severely inflated) benchmarking ab/10_000 time 443.7 Œºs (438.8 Œºs .. 450.2 Œºs) 0.999 R¬≤ (0.999 R¬≤ .. 1.000 R¬≤) mean 452.0 Œºs (448.7 Œºs .. 455.8 Œºs) std dev 17.97 Œºs (15.02 Œºs .. 21.13 Œºs) variance introduced by outliers: 44% (moderately inflated) benchmarking ab/100_000 time 4.568 ms (4.506 ms .. 4.645 ms) 0.998 R¬≤ (0.996 R¬≤ .. 1.000 R¬≤) mean 4.457 ms (4.435 ms .. 4.503 ms) std dev 147.7 Œºs (91.77 Œºs .. 246.1 Œºs) variance introduced by outliers: 27% (moderately inflated)
I would enjoy the compliment a lot more if it didn't come from a bot :)
This looks similar to /u/chrisdoner 's [Z language](https://chrisdone.com/posts/z/)
As the person who originally posted that comment, I haven‚Äôt found any solution yet. At the moment I‚Äôm disabling `intero-mode` and `global-company-mode` and just using `ghcid` instead, but it‚Äôs not nearly as nice. Note that I did eventually report this issue as https://github.com/commercialhaskell/stack/issues/4901, so if anyone has any idea what‚Äôs causing this problem feel free to post a reply there. (BTW, thanks for drawing attention to this problem! I‚Äôve been waiting for a solution, but no-one from Stack or Intero has responded yet‚Ä¶)
Hiw long does it take to learn haskell enough to get a job without actually using haskell at work? I have started studying haskell a few months ago, half way through "learning haskell for good" and "real world haskell" is on the pipeline, I'm watching conference videos and tutorial, practicing on hackerrank. Will it take me years or months to get proficient enough to have a chance when applying to haskell jobs?
H-M can only assign H-M types to H-M functions. Purescript can also assign H-M types to H-M functions, but can do a lot more. I note that Agda does not support let-generalization, but not because it's impossible but because users don't need it. In terms of practical user experience, Agda inference is much more powerful than GHC.
I think you underestimate the severity of differences caused by GC and HKTs.
Are there any resources to learn about it? I have never seen anything about how to *actually* use it.
Woo! Someone using one of my libraries. I live for days like these.
I think to remember a talk where the gist was basically: your primitive should be `Kleisli IO` (the arrow/category) and not `IO` the monad. That way, you can compose for free and only need to allocate a new IO object if somebody actually wants to inspect it (or store it somewhere). Which should not happen that often as composition.
No lie, LYAH is why I set up Jupyter. Glad to see someone did what I set out to do a few years ago lol
We hired an engineer to work on a 100% Haskell code base who didn't write any Haskell prior to arriving. They've made great contributions. Drive, dedication, and embracement of the technology stack goes a long ways... I wish I could determine those qualities from a resume.
One solution is to get rid of the monad data structure, and use a type-and-effect system. Then, soundness would be given by the compiler respecting effects, instead of the faux-state encoding into the lambda calculus that GHC uses (because it compiles pure lazy code exclusively). This has effects for the overall type system. Of course, this requires an expanded type system. Another strategy is to keep the continuation bit, and instead optimize functions as much as possible. One compiler representation that's associated with this is called CPS, or continuation passing style. As an intermediate representation, CPS does away with the stack, instead explicitly constructing the rest of the continuation as a lambda, and making exclusively tail calls. This means that many obvious optimizations work just as well on custom control flow and natural flow. The downside is that some very powerful optimizations, such as common subexpression elimination become quite difficult compared to direct style or SSA. Starting from this though, making IO as performant as pure code is quite trivial. Running IO looks identical to running pure code. This is one of the upsides to CPS code. The downsides are that getting absolute performance is difficult. Naiively compiling will allocate too frequently and produce linked lists, which are worse than the stack. Compilers that compile into CPS have to put a lot of work into reducing allocations and allocating registers appropriately, and right now there isn't a great backend. If that sounds like a lot, then realistically, you should try to contribute to some great projects that are already out there. [GRIN](https://github.com/grin-compiler/grin) is an optimizing middle-end for Haskell, Agda, Idris, and whoever else wants, that's already targeting pure functional code. There's other performant, functional-friendly languages like Rust and OCaml, and other pure languages in development like Koka, which have already devoted many human-years to these sorts of problems.
Hmm. In my mind, the functionality of a VGA driver is to provide two sets of signals; if you imagine a real physical video adapter card, it has connectors to some kind of main bus on the backplane and a physical VGA connector at the back. So my VGA driver provides the coordinates to the "bus" and the sync signals to the "connector". It is true that internally all it does is derive a bunch of stuff from these two nested counters, but I think it would be only half-finished if it didn't also contain the logic to derive the sync signals connected to the screen.
Hey, so I don't know enough about GHC or compilers to answer this, but I do know that GHC removes World as one of its optimization passes (which would invalidate your hypothesis, at least for "a -&gt; b" functions). Concretely, unless you have measured thoroughly -and read through the GHC code-, I wouldn't be so sure about allocations, much less about IO system, which is likely to be optimized.
You may want to look at [https://en.wikipedia.org/wiki/Clean_(programming_language)](Clean) programming language and its [https://en.wikipedia.org/wiki/Uniqueness\_type](uniqueness type)
Timeline-wise I feel like it's very hard to give an answer with so many confounding variables. Things like your resume and current job, whether your location has haskell jobs, previous FP experience, fluency speed, etc. I would say if your goal is just to get a job in any functional programming language, [Scala seems to have more market share](https://www.benfrederickson.com/ranking-programming-languages-by-github-users/) than Haskell and may be easier to break into industry with. Haskell is also infamous for its extremely tough learning curve even compared to other FP languages. But if you are committed to getting a Haskell job, maybe in addition to what you're doing now, you can try contributing libraries to Hackage and bug fixes to open source Haskell projects which will also give you a sense of how much more you have to learn before becoming productive in Haskell.
I've done so more thinking and I might need also have Control.Arrow.first as a primitive curried first :: (a -&gt; IO b) -&gt; ((a, c) -&gt; IO (b, c)) uncurried first :: (a -&gt; IO b,(a,c)) -&gt; IO (b, c) and of course i don't see any good way to compose the uncurried version so even more into a dependent type hole first&lt;3&gt; :: (a -&gt; IO b,(a,c,d)) -&gt; IO (b,c,d) first&lt;4&gt; :: (a -&gt; IO b,(a,c,d,e)) -&gt; IO (b,c,d,e) now consider the following psuedo code: func(x): let a = pureFunc(x) let b = do inpureFunc(x) (a,b) this should compiled down to: funcStatement1 :: (x) -&gt; IO (x,a) funcStatement1(x) = IO (x, pureFunc(x)) funcStatement2 :: (x,a) -&gt; IO(x,a,b) funcStatement2(x,a) = first&lt;3&gt;(inpureFunc,(x,x,a)) funcStatement3 :: (x,a,b) -&gt; IO (a,b) funcStatement3(x,a,b) = IO (a,b) func(x) = kleisli&lt;3&gt;(funcStatement1,funcStatement2,funcStatement3,x)
https://github.com/ekmett/coda/blob/master/coda.cabal uses it pretty heavily. You might consider cribbing from how I do things in there.
The reason I want to bolt-on the side effects as a part of function types is so that you can still write functions that work an monads other that IO. I'm also not sure whether grin is right for my language, I'm planning on not having garbage collection nor allowing heap based function composition(at least not builtin). I'll still look into it though and cps.
Of course ghc optimizes it, I just want to be able to write code that doesn't allocate even when optimizations are turned off (like c) rather then hoping the optimizer catches my heap allocation.
Unfortunately, neither of those helped me.
Well then those can either be effects, or they can also still be monads. There's nothing stopping you from having non-IO effects/monads.
This adaptation of the book __Learn You a Haskell for Great Good!__ presents the book with all of the code examples as live runnable programs, in a full Haskell execution environment provided by Jupyter and IHaskell.
I wouldn't say I agree, there are a variety of cases in which there is ambiguity in instance choice: `Monoid (Maybe a)`, `Monoid (Map k v)`, `Applicative []` etc. Also the benefits of having the typeclass structure be directly manipulated are not limited to cases where there is ambiguity.
Yeah, I certainly am not the first person to notice that an adaptation of LYAH to Jupyter would make a lot of sense. Recently a bunch of technologies and resources have come together to make this adaptation pretty effortless. Mostly Docker, JupyterLab, IHaskell, mybinder.org. Also [notedown](https://github.com/aaren/notedown) and &lt;https://github.com/pvorb/learn-you-a-haskell&gt;.
I've got the same issue - as it only happens in Emacs I switched to vs.code/haskero on Windows for the moment - not ideal but usable for the moment
Isn't there already a wmonad ( https://github.com/nspin/wmonad )? Anyway, shouldn't W be a comonad?
wmonad doesn't appear to be written for wayland: ["We couldn‚Äôt find any code matching 'wayland' in nspin/wmonad"](https://github.com/nspin/wmonad/search?q=wayland&amp;unscoped_q=wayland).
This work came out of the monthly Haskell CoHack in New York, which was this weekend. I hope people find it useful.
Good point, see [this thread](https://www.reddit.com/r/xmonad/comments/72evgm/idea_wmonad_complete_rewrite_for_wayland_support/) for the source of my confusion.
How great is the IHaskell environment for typical numpy/mpl/Jupyter workflows? Most of my exploratory work is in this area, but because production is obviously a fairly different workflow, it could be fun to try Haskell for exploratory
Very interesting, and a good introduction to FRP! I always thought that Reflex was GHCJS-specific, so this helps clarify that. I do have one question though. The article mentions the following: &gt;\[The functional MVC model\] is radically simple, but it‚Äôs not very compositional. It‚Äôs difficult to abstract over parts of the application, or break apart a complex program into smaller pieces. I have written several medium-sized applications in this model, and Joachim Breitner even programmed his slides for a talk within CodeWorld in this model (and wrote a glorious hack to be able to build them in CodeWorld itself). I think we‚Äôd all agree we‚Äôve stretched the upper scaling limits of this simple model. I'd be interested to know: what exactly does it mean to 'abstract over parts of the application' or 'break apart a complex program into smaller pieces', with regards to GUIs or graphics? And how exactly does the functional MVC model make this difficult? (For context, I'm currently trying to convert one of my own GUI programs from an imperative GTK-callback-style to a custom functional MVC framework, and I'd like to know more about the limitations before I go any further.)
A quick look suggests that it is an absurdist joke by the author. E.g. http://hgbook.red-bean.com/ is his Mercurial book.
This is awesome! Thanks very much, we need more work and discussion about how to deal with complex types in your API. Of course, it would be great if this could be integrated in `base`, so that people don't have to depend on an additional library just to show better error messages.
Is it possible to use ghc-api to parse a source file without invoking the pragmas in the said source file? For example, is it possible to build a ghc-plugin that aborts compilation if the source file contains \`{-#OPTIONS\_GHC -F -pgmF something\_nasty #-}\`?
Basically Haskell records lack what is known as row-type polymorphism. Two language heavily inspired from Haskell (and in fact the compilers are written in Haskell) - Elm and Purescript - have it already. To give a concrete example, you can't write the following in Haskell easily, which is the crux of writing a type-safe RDBMS-backed application: ``` -- made up syntax based on what Elm already has. -- Will NOT work in Haskell. -- -- This basically says that once type `a` is saved -- to the DB, it will have an additional `id` and `createdAt` -- field createRecord :: a -&gt; { a | id :: PrimaryKey, createdAt :: UTCTime } ``` On top of that, you can't have two records that share the same field-name without enabling a few language extensions, which might break your code in other non-obvious ways. ``` -- this is not allowed by default data User = User { name :: Text , age :: Int } data Company = Company { name :: Text -- Duplicate field name , age :: Int } ``` The only way I've managed to make records palatable in Haskell is by the use of some TemplateHaskell and heavily depending upon lenses.
This is great! The documentation is also very clear provided you're familiar with the "domain". By the way, the links in the docs that point to the fcf library are broken (try clicking on `ZipWith` for example).
&gt; Haskell's IO is that it's effectively a function from current global state to new global state. &gt; IO a = World -&gt; (World, a) The IO M.O. if you will.
For extensions, something like this could work: module ExtsPlugin (plugin) where import Control.Monad import Control.Monad.IO.Class import qualified EnumSet as S import GhcPlugins hiding (errorMsg) import ErrUtils import GHC.LanguageExtensions plugin :: Plugin plugin = defaultPlugin { parsedResultAction = \_ _ -&gt; (&lt;$ checkExts) } -- We just need access to 'DynFlags' and 'parsedResultAction' is first place -- where we can get it checkExts :: (HasDynFlags m, MonadIO m) =&gt; m () checkExts = do flags &lt;- getDynFlags let extensions = extensionFlags flags forbidden = [{- your extensions here -}] when (or $ flip S.member extensions &lt;$&gt; forbidden) $ -- Honestly, I would appreciate if someone pointed out better way of -- throwing such errors liftIO $ do -- Put whatever message you want here errorMsg flags $ text "Forbidden extension used" ghcExit flags 1
I've used it for data analysis, it's a breath of fresh air after the cryptic error messages caused by the lack of a decent type system in python, but support for some essential tools is definitely worse than for python. Unfortunately, the fact that something exists is no guarantee it will work for IHaskell. E.g. I've had problems with conflicting dependencies between IHaskell and Tensorflow in the past.
Awesome! Also, I didn't know about this mybinder.org site, it looks like it could be really useful for all sorts of projects. I feel inspired to start writing my own Haskell tutorials using this Jupyter notebook format, and maybe post it there as well.
Unboxed vectors makes so many things in Haskell run faster, and pretty soon with linear typing extensions introduced into GHC we can probably start seeing Haskell programs catch up to Rust benchmarks more often. I have been hoping to update a few of the Haskell submissions to the [Benchmarks Game]( https://benchmarksgame-team.pages.debian.net/benchmarksgame/ ) because they are a bit dated and falling behind some other functional languages that Haskell should be beating in terms of performance.
I'd say that software developers who mention haskell in their list of known programming languages ( even if it is in lasts positions) even though they clearly never had to use them in their jobs, it's a clear sign of dedication and commitment to improve themselves, don't you agree?
Agreed. It would also be cool if it were slotted into the regular module hierarchy, like `Data.Type.Error`.
&gt; ... and use a type-and-effect system What is a "type-and-effect" system?
Why is it worse to depend on an additional library? In the end we still end up depending on the same amount of code. A clear benefit of keeping it in a separate non-core library, is it can be updated without synchronizing with GHC releases. I would rather see something like that addressed at the packaging and community level. - If the problem is the repetitiveness of adding dependencies, one way is to create an alternative standard library which includes everything you use regularly. - If the problem is discoverability, there are some lists of "if you want to do X, use Y." out there, maybe haskell.org could promote one of them or a new list of its own.
Yes, just invoke the parser directly from the Parser module. {-# OPTIONS_GHC #-} blocks will be just comments. However, if you're explicitly interested in that information, use https://hackage.haskell.org/package/ghc-8.6.5/docs/DynFlags.html#v:parseDynamicFlagsFull
In theory, wouldn't replacing the "X" monad in xmonad with a new monad (W?) be possible? I've looked at the xmonad once ages ago so no idea how generalizable that part of the code is.
Got a novice question. I got a map where I have type QuestionMap = Map.Map (Key Question) (Entity Question, [(AnswerChoice, NextQuestionId)]) type NextQuestionId = Key Question Now, I need to construct a multi-way tree (can have any number of child nodes) such as this: type AnswerNext = (AnswerChoice, QuestionTree) data QuestionTree = End | Tree { question :: Entity Question , answers :: [AnswerNext] } deriving (Generic) My construction function looks somewhat like this: buildQuestionTree :: QuestionMap -&gt; Key Question -&gt; QuestionTree buildQuestionTree questionMap nextQuestionId = case Map.lookup nextQuestionId questionMap of Nothing -&gt; End Just (_ , [] ) -&gt; End Just (question, answerPaths) -&gt; Tree { question = question , answers = map (\(answerChoice, key) -&gt; (answerChoice, buildQuestionTree questionMap key) ) answerPaths } **Problem now is traversal**. I would need to traverse this structure but I don't know how. Should I be trying to apply it `Functor` and `Traversable` instances or trying to do that with lenses? Or just attempt to write my own recursive traversal algos?
Oooh! I had completely forgotten Write you a Haskell! Thanks :)
So, for the purpose of learning, I'd say try, at least once, to write your own traversal. I personally would use `Functor` and `Traversable` and stay away from lenses. I'd also consider using [`Data.Tree`](https://hackage.haskell.org/package/containers-0.6.2.1/docs/Data-Tree.html) (it doesn't have an `End`, but an empty list of children is pretty much the same).
How can I use a computation that requires two 'State' variables? See this example: {-# LANGUAGE FlexibleContexts #-} module Example where import Control.Monad.State type Name = String type Age = Int getName :: (MonadState Name m) =&gt; m Name getName = get getAge :: (MonadState Age m) =&gt; m Age getAge = get getNameAge :: (MonadState Name m, MonadState Age m) =&gt; m (Name, Age) getNameAge = (,) &lt;$&gt; getName &lt;*&gt; getAge type MyMonad a = StateT Name (State Age) a -- Error: -- Couldn't match type ‚Äò[Char]‚Äô with ‚ÄòInt‚Äô -- arising from a functional dependency between: -- constraint ‚ÄòMonadState Age (StateT Name (State Age))‚Äô -- arising from a use of ‚ÄògetNameAge‚Äô -- instance ‚ÄòMonadState s (StateT s m)‚Äô at &lt;no location info&gt; getNameAgeMyMonad :: MyMonad (Name, Age) getNameAgeMyMonad = getNameAge (In this example `Name` and `Age` don't have to be in 'State', of course, but in reality I am writing a typechecker which uses both an environment of type variables and a list of 'fresh' type variable names.) I can write `getNameAge` as getNameAge' :: MyMonad (Name, Age) getNameAge' = (,) &lt;$&gt; getName &lt;*&gt; lift getAge but I'd rather make `getNameAge` (or the equivalent function in my real use-case) as general as possible.
I prefer the UNIX philosophy of having small tools that do one task well, and (re)using them to build larger tools. That said, I see value in your approach, at least in the way we think about a project. Start with a monolith of responsibility / authority, and only split those once the projected improvements overwhelm the costs to developing a protocol between the parts.
Can you explain a little more about how it works? Does this library allow programmers to define better types that result in better messages? Or is this some sort of extension to GHC that you can perhaps load as a shared library with some command line options to modify the compiler?
thanks for your help! With applying `Functor` I got the problem that it expects `* -&gt; *`. As you can see my `QuestionTree` is not of type `QuestionTree a`. I don't know how to set up an instance of `Functor` of these types, or I should modify them somehow? With `Data.Tree` I got the problem that the children of my `QuestionTree` are not Trees themselves, but a list of tuples where only the second element is a tree. Ideally, I'd like to be able to apply `Traversable, Functor` on these types but clueless on how to go on with it.
Wonderful! I'm stoked to use this! [Code.World](https://Code.World) is already quiet impressive for beginners, but now I can see applications for more advanced users too!
From a purely code perspective certainly, but there are enough assumptions about the capability of that monad (ie capabilities of X server) that a rewrite would be required. X can do more than Wayland can\* and I'm sure many/most Contrib modules would break. \* from the perspective of permissions, I'm not saying anything about one being more powerful than the other.
I'm a little confused. Does hie-core have anything to do with haskell-ide-engine, which also calls itself HIE? The blog seems to suggest they are two separate things.
Since GHC 8.0, we've had the ability to generate custom type errors via `GHC.TypeLits.TypeError`, which is a magic type family that the compiler interprets as "write this out as a type error." The ergonomics of using that stuff are pretty atrocious (for example, see the [code that produces nice errors in polysemy](https://hackage.haskell.org/package/polysemy-0.5.1.0/docs/src/Polysemy.Internal.CustomErrors.html)). This package is the result of all the little tricks I've learned in the process.
haskell-ide-engine contains an LSP library (which we reuse), and hie-bios was written for haskell-ide-engine (which we can integrate with, but don't have to). For many aspects, haskell-ide-engine wraps over ghc-mod - saying that hie-core is a potential ghc-mod replacement in haskell-ide-engine might be the best description of what we've done. The name hie-core is meant to invoke that kind of relationship. That said, this is the first time we're announcing the project. The relationship with other projects is not set in stone, and the reason we're announcing it is to figure those things out.
Thanks for the clarification!
Thanks!
I think that your formatting is broken in a way that is making it very difficult for me to understand your explanation. Are you saying that records can't have fields with the same names?
A curious mind that is willing to adapt to new tools and technology stacks is what I'd like to know. Some people learn Haskell for that reason others perhaps because of evangelism.
Great question! I think a good example is this: if you're implementing some kind of UI control, it often has internal state ("is the slider being dragged? If so, what's the anchor point?"), and some outside effect (a value like "the slider is currently set to 27" or an effect like "the user just started the simulation"). In that functional MVC model, your control would usually own some part of the application state value for its own internal state, and then it would either stash a result value somewhere else in the app state, or else call code directly to cause effects. Problems: * The implementation of this one control happens in many places: part of the initial state value, part of each event handler, and part of the picture function. These blocks of code don't directly reference each other at all, but just communicate at a distance via shared fields in the global app state. * The control's state belongs to that control only by convention! There's nothing stopping any other component from mucking with it, too. It's quite tempting for someone to fix a bug by cleverly tweaking the state of other controls. * If a control triggers some effect (like a button press or menu selection), that effect is now tightly coupled with the internal event handlers for the control. You can, of course, pass in a higher-order function, but that higher-order function must be able to modify the whole system state -- which means the control can, too! In essence, you've started from a functional language, but snuck in some global mutable state through the back door. That leaves some advantages of functional programming "in the small", but it leaves your program not very composable at larger scale. FRP's answer is to make those dependencies explicit. Instead of the state being the big deal, and components interact via shared state, the dependency graph becomes the big deal, and components interact by being passed their dependencies as arguments, and producing their results. That's made workable by correctly modeling the nature of these dependencies and results, and keeping state local .
We should find a way to consolidate community's effort!
I've lately been doing a lot of command line work involving finding things that match across files, deduplicating log entries by some criterion, etc. etc. and I often have to search around for the necessary obscure invocation of awk required to do some basic set operation. I wrote this very simple but also very flexible tool to make this sort of thing easier and faster.
Yep, we've been reaching out to everyone to try and come to agreement on the best path forward, and talking openly is very definitely step one. But bear in mind there are quite a lot of entirely unrelated IDE's out there already - it just seems no one can agree. We also designed hie-core so it could be at the heart of say Leskah or IntelliJ, if people want, so there's a chance this project might decrease fragmentation...
I was playing around with Control.Lens from `lens`, and with (Just ("3", 'a')) ^. _Just ^. _1 I got an error, because 'a' needed to be a monoid. Why is this? I can understand it if I were trying to access the second field (for instance, `Nothing ^. _Just ^. _2 @(String, Char)`), but why does it need that in the first field?
As Intero's author I have lots of thoughts on the Haskell IDE topic. I think it's a good time to discuss it. There's a question of audience. Who are we making tooling for? Us power users, or newbies too? In the former case, there are things we don't have to care about, and crap that we'll put up with. In the latter case, the work is 10x harder. We should also consider audience choices. Most Haskellers, are using either Emacs or Vim, for their Haskell work. See survey results: [2017](https://taylor.fausak.me/2017/11/15/2017-state-of-haskell-survey-results/#question-24), [2018](https://taylor.fausak.me/2018/11/18/2018-state-of-haskell-survey-results/#question-043). I imagine that shift from Vim to Emacs is mostly due to Emacs's tooling being slightly better and supporting evil-mode, the Vim compatibility layer for Emacs. It's hard to say much about new Haskell users, but I could imagine Visual Studio Code would be a reasonable IDE choice for them. Elsewhere, we have to see LSP for what it is. It's an attempted standard way to talk to IDEs, but designed for Visual Studio. It's difficult to integrate with properly (see ["A LSP client maintainers view of the LSP protocol"](https://www.reddit.com/r/vim/comments/b3yzq4/a_lsp_client_maintainers_view_of_the_lsp_protocol/)). It's not a perfect solution. It's the only one we have, but we have to recognize that for some maintainers it's going to really suck to integrate with. Regarding personpower, it's easy to be ambitious about IDE projects, and also easy to underestimate how much work goes into it. If you want to make something of quality, be prepared to pay someone full time to work on it, or else expect it to go downhill. Every single component you release will be a never-ending source of incoming issues, and most of them won't be interesting or fun. I think Intero did quite well in taking a share of the userspace by being easy and automatic to install, being dumb enough implementation-wise to not break that often, and by simply re-using GHCi (it's a fork of ghci), and also by just assuming stack; not trying to support the myriad of ways to tell GHC "here are your packages and flags". Since releasing it I've been mostly satisfied with the user experience, and it's brought a base level of functionality I come to expect on every repo I open. It does the job. I'm not in a rush anymore to get minimum functionality. It's not embarassingly primitive anymore. I'd like to sunset Intero in favor of The Right Thing. So what's that? Well, the only candidate is haskell-ide-engine. I think, personally, I need to give it another try. But I also need to document the diff. For example, if we want to get Intero's users to move over to haskell-ide-engine, I can do my best to endorse it, but only with a feature list, [like this](https://chrisdone.github.io/intero/), showing that HIE is capable of doing that. I'll put a big sign on Intero's README that says "Go here instead!". That would apply to the Emacs integration... There are also a bunch of integrations of intero with other IDEs; NeoVim, Visual Studio Code, Eclipse and IntelliJ. I think Intero's relative simplicity has enabled that. I've with confidence recommended intero-based plugins to users of VSC and NeoVim and Eclipse on calls and seen success. I'd like a replacement that I know works equally reliably. There are lots of technical issues and considerations. But I feel like the only thing worth writing about at the moment is a willingness to collaborate and endorse the future direction, provided it sincerely caters to the current users of Intero. My only technical comment really is that any architecture should be aggressively simple. If we look at it in terms of budget, the complexity budget has already been spent on (1) LSP, both on the backend and the client IDEs are burdened with it, and (2) Haskell; it's a moving target, compiler changes all the time. This isn't Common Lisp where you write an IDE in 1990 and it still works perfectly in 2019. Therefore anything remaining should be as architecturally direct as possible. Compiling files and getting type errors and type info should **always** work, regardless of whether some other plugin someone's trying to use is failing because it's Wednesday and sunny outside.
I think a lot about what a novel Haskell IDE could look like. I start by precluding it being yet another way to edit 2 dimensional text on a vertically-scrolling page, with the project partitioned into separate text files, which has been our paradigm for... many decades now? We have a ton of *editors* these days and I think we should rethink *editing* itself. But I don't yet have any intuition on what that would actually look like, to be honest, though I rule out the normal 2D sequential text-file editing model right away
The `_Just` traversal may find no element, so you need a way to handle that case at some point. The `(^.)` combinator exposes that as a `Monoid` constraint on the focused type (`(String, Char)`), which requires `Monoid String` (OK) and `Monoid Char` (not OK). Furthermore, `(^.)` uses that `Monoid` constraint to fold all values pointed at by the traversal, which might not be what you expected if you're surprised by that error. It is often preferable to use `(^?)`, which gives a `Maybe`. Just ("3", 'a') ^? _Just . _1 -- note the second operator is a dot To say more about the implementation details leading to this behavior of `(^.)`, `Traversal`s (which include prisms like `_Just`) are polymorphic functions parameterized by an `Applicative` functor. With `(^.)`, this functor is specialized to `Const a`, which requires `Monoid`, which leads to the error you got: instance Monoid a =&gt; Applicative (Const a)
The hie-core feature set isn't that far off what you describe. No completion yet, but that's just a matter of effort. The robustness seems like partly a properly of the code (which I think hie-core has) and partly the environment setup (where Stack only gives a massive advantage). Agreed with almost all your points, although with Ghcid as my personal IDE I've been using/writing.
When you're type-checking most languages (like Haskell), every term in your language has some type in the context of the computation. So you may have a term \`(1 + 2) :: Int\`. We even have things like \`readLine :: IO String\`. But notably, without special support, \`IO String != String\`, so we need to use something like bind. A type an effect system instead annotates every term with both a type and effect. So imagine we had \`(1 + 2) :: Int ! Pure\`. Then we could also have \`readLine :: String ! IO\`. Now you never have to do anything special to access the string portion. You just use it as normal. Now, you'll ultimately get something that's annotated with IO. But how that looks for performance is that the control flow has no intermediate data structures or optimizations needed. You just run it only in contexts where IO is allowed (ultimately the GHC version does compile down to something like this).
These didn't help :(
Great article, it really m√≠ticamente me to experiment and add better type errors to my own code. Do you know what happened to the silica package mentioned in the text as an example of packages in the wild using custom type errors?
How is your "readLine" any different than "readLine :: Monad m =&gt; m String"? The above readLine is precise whereas "! IO" and "! Pure" is hand-wavy nonsense unless "! Pure" = IO and "! IO" = Pure. Also, what does "normal" mean when you treat IO or contextual pure functions as if they were pure? Your description seems rather nonsensical to me.
the description sounds kind of vague, so you could probably do whatever you want
No thanks. My core issue with every IDE I've ever been forced to use has always been an unnecessary and uninvited attempt to wrap filesystem IO in some bad, incomplete, and poorly thought out abstraction. Editors, as opposed to IDEs, are my weapon of choice precisely because they offer a simple '2 dimensional' interface to use to edit text, in files, which is the heart of what I am doing when I'm writing code. I don't want a damn 'package viewer' or 'project navigator', I want an interface that lets me browse the files and folders on the filesystem, make edits to them, and show me the results of those edits. If you want to provide additional features for navigation or display of information, that's awesome and quite welcome, but if those come at the expense of hiding the inherent basic simplicty of editing text in files, you have done something unforgivably stupid and user hostile.
I don't have the time to read through that right now, but you're definitely right when you say "bidirectionally formulated type-systems are nice, and they can be used to formulate weak systems too. Those aren't mutually-exclusive things." There are other approaches, though, and I think it makes sense to be well-read and learn a variety of techniques.
Are there any plans / awareness from IDE developers about .hie files that the head GHC produces?
So then, partially applied, `^? _Just == id`?
I think this needs case examples. I think I know what you're getting at, in that the Haskell ecosystem is not as robust as other similarly old languages in many spheres, and so you're stuck with interop as a the only 'reasonable cost' solution to interacting with some domains. But it does bare pointing out that Haskell as a language doesn't really have limitations that prevent it from succeeding in those domains - It's just that nobody wants to foot the bill for developing that solution, because it doesn't make economic sense to do so. This is still very much a reason not to use Haskell for X project, where X project is supposed to make someone money - But if folks were more proactive at pointing this stuff out, we might be able to get those domains more attention, and resolve this problem by just expanding the ecosystem to fill those gaps.
As a minor point of clarification with `_1` the monoid constraint is only necessary on the first member of the tuple , so as you said, OK, but it would require `Monoid Char` when attempting to use `_2`.
The \`.hie\` files code was added to GHC by contributors to the haskell-ide-engine, so it is a feature that is going to be heavily used there.
The thing Haskell really needs is a proper way of handling records (not via lenses..), I'm mentioning this here because this'd make a lot of room for sensible auto-completion.
Sorry, I'm not the best at explaining this. You are correct that they are similar to monads, in fact this correspondence has long been understood. There are technical differences. The above "! IO" is just syntax, since there is no Haskell syntax for an effect system. To really make it precise would require just as much effort as trying to explain the entire Haskell type system necessary to make "readLine :: Monad m =&gt; m String" precise, so you'll understand if I don't duplicate it here. The effectful version of readLine returns a value of type String, and has the effect IO. This is not the same as a value of type IO String. Syntactically, the translation between the monadic version and the effectful one is indeed quite trivial. We wrap it in do, and use \`&lt;-\`, and this is no accident. Haskell aims to emulate the imperative usage with this notation. So in particular, in 'effectful haskell' we might imagine it looks sort of like the following f :: (Int -&gt;!IO String ) ! Pure f m -&gt; let s :: String ! IO s = readLine n :: Int ! Pure n = length s in n * m Each subterm has both a type signature portion, and an effect portion. In particular, once it occurs in the term, the value that's returned is a pure value. We can see a couple points of interest. \`n\` has type Int, with no effects, much like you would see in do notation. \`f\` seems to have two effects, but this is because one of them is tied to the function itself, although the definition of f is pure. Now, there's only a few places where this matters. When we have effect polymorphism, many functions become easier to write than with monadic or applicative combinators, and in particular we can use the same code for both effectful and non-effectful code, unlike with monads (unless you plan to write all Haskell in the Identity monad). map :: (a -&gt;!e b) -&gt; [a] -&gt;!e b map f [] = [] map f (x:xs) = f x : xs So we get traverse for free here. There's a few other differences, e.g. usually we don't ever have two copies of IO effects, but we can easily have IO (IO a). Similarly \[IO a\] is a type that doesn't make sense for the effect, since values can't have an effect. So they must always be thunked into a function \`() -&gt;!e b\`. For fairly simple reasons, this is not very palatable for a lazy language. But, back to the original post. Operationally, effects may sometimes be easier to implement in a compiler without higher order functions. Whereas with the monadic version, it gets compiled into a host of higher-order functions (a -&gt; m b), the effectful version has the code already flattened out, so it can be very easily compiled into straight-line code, even without any optimizations (like OP asked for). Of course, some features (e.g. algebraic effects ala Koka and Eff) may require the function version again to support the most powerful effects. But that's the gist of it. I'd recommend looking at the Koka project for a powerful implementation of algebraic effects. Technically a few other systems do have things which count as effect systems, such as Java's much maligned checked exceptions.
That's my next blog post :-)
The code is already in hie-core to make use of them.
I have to say using GHCi (or ghcid) goes a very long way reducing the effort to complete/type-at/jump/etc with very little effort. Most of an IDE functionality is already built-in into GHCi. I just moved from Vim to Emacs because of the better tooling and I found it works pretty well this combination. It requires very little effort to setup up: - haskell-mode - company - company-ghci: https://github.com/horellana/company-ghci - flycheck-haskell: https://github.com/flycheck/flycheck-haskell company-ghci works really well and it supports `cabal new-repl`. My config in case it helps anybody: https://github.com/jimenezrick/my-emacs.d/blob/master/packages-haskell.elhttps://github.com/jimenezrick/my-emacs.d/blob/master/packages-haskell.el
Koka is based on a concept known as algebraic effects. Algebraic effects have been gaining popularity in Haskell, polysemy being the latest, as well as other FP langs, or languages that have them built in like Koka and Eff. Most of them are based on free monads and a sum of functors to separate syntax and semantics. It's pure in that it's a grammar of signatures, an algebra that can combined and interpreted and interpreted/evaluated in some semantic domain. The benefit of such a technique is that they compose easily and can be interpreted in different semantic domains, e.g.: IO or some other monad that has nothing to do with IO, say a List. You may find this seminal paper on the topic interesting: http://www.cs.ru.nl/~W.Swierstra/Publications/DataTypesALaCarte.pdf
That was the default config that `stack new` generated, and I guess I just never thought to turn it off. Thanks so much for the tip, it's now 30-ish percent faster! Updated the github repo.
The original expression had `^.` twice, but that is right if the second operator were `.`.
That is right!
Yes, I am aware, that's why I mentioned it...
Yes, but you're explanation doesn't really talk to the core ideas of algebraic effects.
`MonadState` requires that every monad has at most one associated state type with it, so `MonadState Name m, MonadState Age m` is not allowed. Two ways are to define a transformer, or to only access `MonadState` through a lens. ## Transformer of `MonadState` -- A wrapper exposing only one component of the underlying monad's state newtype StateFstT s1 s2 m a = StateFstT (m a) deriving ... instance MonadState (s1, s2) m =&gt; MonadState s1 (StateFstT s1 s2 m) where ... overFst :: MonadState (s1, s2) m =&gt; StateFstT s1 s2 m a -&gt; m a overFst (StateFstT u) = u -- Now if you have (getAge :: MonadState Age m =&gt; m Age) you can lift it using overFst: myCombinedActions :: MonadState (Age, Name) m =&gt; m x myCombinedActions = do -- ... overFst getAge This code is pretty specific to pairs, but the idea could be generalized to other types with some effort... ## `MonadState` with lenses class Has a s where field :: Lens' s a getAge :: (MonadState s m, Has Age s) =&gt; m Age getAge = do s &lt;- get pure (s ^. field @Age) Now you are free to use `getAge` as long as your state contains an `Age`. This is more or less a variant of [the `ReaderT` pattern](https://www.fpcomplete.com/blog/2017/06/readert-design-pattern).
&gt; Is something like FRP better than Shake for describing dependencies? I have the feeling that Shake _is_ actually a kind of (high-latency?) FRP implementation! Just tailored for (seemingly) different purposes. Conceptually, reactive UI, incremental build systems, always up-to-date derived databases, spreadsheets, etc. all feel like instances of the same idea, with possibly different optimizations.
Do you want something like https://www.lamdu.org?
Note that if you are getting rid of `fmap`, you probably shouldn't call it a monad anymore. `return` + `join` + functor is what makes it a monad.
For me the problem with most IDEs is their lack of a good editor. I also think that a file system navigator is more immediately pressing than a package or project navigator. I think any approach that doesn't *start* with a good text editor and then add on features is doomed to never being universal enough. I can't imagine using a IDE that doesn't at least allow me to edit a configuration file that's text but also some custom format half-way between INI files and Java Properties files.
Android keyboard that attempts to auto detect the language?
But people **are** actually doing that with "esoteric" languages such as erlang, clojure, hundreds of thousands of typescript developers are dying to find a way to recursively type their curry or compose functions, elm developers don't even have HKT's, so what's stopping haskell? The lack of one robust domain where it triumphs, just one case to encourage other good software. Haskell just doesn't have it. No gimp, no Firefox like Rust, no Python, no Erlang speed, no Scala flexibility, no Elm's speed on the front end. Haskell just doesn't have one single killer software.
Personally, I like starting with a type-driven design. Think about (and even write down) the types of all the operations / constants, they can inform the implementation.
Thank you very much!
Yep, I think you're probably right. Perhaps you'd describe it as batch FRP - you make changes, let them all propagate, before going again? I think Andrey was hoping to go in this direction following our [Build Systems a la Carte paper](https://ndmitchell.com/#shake_5_may_2019).
Ah, right.
Agreed, hope they can work together better than stack and cabal.
Agreed. Algebraic effects are a nice feature for effect systems, much as things like algebraic datatypes are a nice usage of a type system. But of course many type systems do not include the latter, and effect systems need not include the former. Koka is just a good working example. For OP's use case, algebraic effects pull much of the complexity right back in, as with features like multiple resumptions, they again require capturing the continuation, which is difficult to make performant relative to a stack implementation. Of course, it can be done, as I mentioned with non-stack-based CPS compilers back in the original post, but it's more difficult to do efficiently.
Great blog post! I'm certainly gonna be on the lookout for when and where I can add TypeErrors in my code to make usage (and version migration) smoother!
Not to be pedantic but I think you have mistaken view of Koka. According to this paper: http://goto.ucsd.edu/~nvazou/koka/icfp15.pdf &gt; Using the correspondence between monads and effects [35],we propose a novel system where you define the semantics of an effect in terms of a first-class monadic value, but you use the monad using a first-class effect type. We build on the existing Koka type system [19] to incorpo-rate monadic effects with full polymorphic and higher-order effect inference. Koka's type system allows you to define monads and in turn free monads. So immediately, you have a notion of a functor. Effects are complex, but they can be made ergonomic for the programmer via a compiler extensions or if your type system is strong enough, as a library. I think that if a type system can't express algebraic effects, then it's not really worth its salt.
Your description is kind of vague and it's therefore difficult to give good advice. Could you be more concrete about what you mean with "system", "agents" and maybe give examples? Like, what do you mean with "capabilities", or "intents" etc.
I found this pretty easy to use, and it solved half of a big problem in propellor: Enormous useless tye error messages due to stuckness. The other half of the problem is that sometimes ghc will run out of memory building propellor, apparently because it buffers up a huge list of type error messages. I had hoped that DelayError might help with that, but it didn't.
I think you're missing a bit here. They are not using monads, the datastructure in haskell. Rather, they are using, as the first sentence \`the correspondence between monads and effects\`. So I think you've misunderstood/ I'm the one being pedantic. Technically there is a monad represented by effects, namely the function \`unit -&gt; b &lt;e&gt;\` or however it's represented, but the usage of monadic here is mostly referring to the language, not to the type system, and is relatively informal, much as we might refer to e.g. the ambient monad of Java. I don't really understand what you're intending with those last bits. &gt;I think that if a type system can't express algebraic effects, then it's not really worth its salt. Well, they have their place. So do algebraic datatypes, and anonymous functions, and structurally typed records, and objects, and dependent types, and linear/affine types, and anonymous union and intersection types, and rank n types, and type classes/constraint types, but a language with every feature isn't very usable, and would take extensive effort to work with.
this is a good point, what else do i call it then? dependant IO arrows? idk
&gt; We build on the existing Koka type system [19] to incorpo-rate monadic effects with full polymorphic and higher-order effect inference They state clearly what they're building above using Koka existing type system.
This is so convenient! I just started learning reflex, but I've been running into quite a few bumps trying to get it running with good editor integration (e.g. there's quite a few [suggestions](https://github.com/obsidiansystems/obelisk/issues/184) on how to get obelisk working with emacs/spacemacs/HIE/etc, but no official "how-to" guides yet). This seems like it'll at least make those starting steps of learning reflex a bit easier. Just as a note, I had to change `(keyPress input)` to `(show &lt;$&gt; keyPress input)` in the final code sample for it to work.
&gt; There are lots of technical issues and considerations. But I feel like &gt; the only thing worth writing about at the moment is a willingness to &gt; collaborate and endorse the future direction, provided it sincerely &gt; caters to the current users of Intero. That's great to hear, it really is time for us all to start consolidating efforts on Haskell IDE tooling instead of working in all our own little niches. &gt; My only technical comment really is that any architecture should be &gt; aggressively simple. If we look at it in terms of budget, the complexity &gt; budget has already been spent on (1) LSP, both on the backend and the &gt; client IDEs are burdened with it, and (2) Haskell; it's a moving target, &gt; compiler changes all the time. This isn't Common Lisp where you write an &gt; IDE in 1990 and it still works perfectly in 2019. Therefore anything &gt; remaining should be as architecturally direct as possible. I have to agree here, and it's essentially where my concerns about hie-core start: I had a quick discussion with cocreature (Moritz) at ZuriHac about hie-core and my understanding is that you're not only implementing the IDE parts but essentially replacing all of ghc's `--make` mode (aka `GhcMake.hs` in the source) including constructing the module graph by parsing imports and handling the search path etc. While I'm convinced that the GHC API is not optimal for the IDE use case (or for any more complex use case really) and we could defintely benefit from Shake'ing it up :) I belive it is a mistake to depend on any sort of rewrite of the functionality in GHC just to get IDE functionality. I think if this is worth doing it's worth doing upstream in GHC where we can make sure all the dark corners are handled appropriately. PS: I recently spent a lot of time in the GhcMake and pipeline stuff to improve it for HIE as part of my current GSoC project so I can definetly relate to just wanting to outright replace it though ;)
So if I‚Äôm understanding right, you‚Äôre saying that the problems with functional MVC are: 1. Functional MVC has all the same problems that global mutable state does 2. The implementation of one control is spread across three functions: the initial state, the event handler, and the display function That does make a lot of sense ‚Äî I can easily see why functional MVC has problems with large stuff. &gt;FRP's answer is to make those dependencies explicit. Instead of the state being the big deal, and components interact via shared state, the dependency graph becomes the big deal, and components interact by being passed their dependencies as arguments, and producing their results. That's made workable by correctly modeling the nature of these dependencies and results, and keeping state local . I haven‚Äôt ever seen this conception of FRP before; it makes a lot more sense than my previous readings on the topic (which admittedly weren‚Äôt that extensive). Do you have any resources on how to structure an FRP application? \---------------------------- I do have two more tangential questions, which hopefully you‚Äôll be able to answer. I have a [large(ish) Haskell GUI program](https://github.com/bradrn/cabasa) which is written in a very imperative style ‚Äî global `IORef`s everywhere, `IO` interspersed with pure code, et cetera. I‚Äôve been slowly converting it over to functional MVC, as that seemed a fairly easy refactor to do since it also relies on global state. However, I‚Äôm now thinking of FRP as a methodology which would work very well for this particular program. Only trouble is, an early version of that program *was* written in FRP (using [`threepenny-gui`](http://hackage.haskell.org/package/threepenny-gui), if it matters), and it ended up as an awful, unmaintainable mess ‚Äî even with a very simple GUI! So my questions are: 1. How do I avoid the ‚Äòunmaintainable mess‚Äô I mentioned? (What ended up happening is that every control had its own event stream, the event streams had to be combined in crazy ways to get the correct behaviour, and so everything ended up being incredibly tightly bound to everything else.) 2. Given that I already have a complex imperative GUI with global state, what do you think is the best way of refactoring it to FRP?
Literally nothing? People write quality software in Haskell pretty frequently. I don't recall hearing about any recent, high profile software built in clojure or erlang, so I don't think that's actually a fair assessment of the space. Have you looked at a github diff in the past couple weeks? You may've noticed that all the sudden they have syntactically sensitive diffs - That was written in Haskell. Used facebook? Cool, they've implemented quite a bit of their auto-moderation frameworks in Haskell. Cross compilation with GHC is still a hell of a headache (good strides have been made recently, but there is a long way to go), and there is always the sleeper issue of gmp-integer and large organizations getting cold feet about potential license issues, so there are some practical considerations that are a part of this story as well. But generally - I don't think there is really anything stopping Haskell from succeeding, I think Haskell is succeeding, it just doesn't have an ecosystem on par with Python, Java, C#, or JS, and so it gets about as much use as languages that aren't Python, Java, C#, or JS derivatives.
Thanks for your kind words! Nothing happened to `silica`. I've just blindly added a link to Hackage assuming that such a fantastic package should be there. For some reasons, it's not on Hackage. But you can find it on GitHub. I've fixed the link in my blog post. * https://github.com/mrkgnao/silica
I really feel like most of that conflict was about identity issues and control/power struggle more than anything else. stack uses cabal as an implementation detail. I don't get why it was so controversial beyond the attitudes of all the people involved.
Thanks! Actually, after writing the blog post, I found more places in my libraries where I could use custom type errors. I think they are addictive: the more you use them, the more use cases for them you want to find because the outcome is just amazing.
Glad it helps! I'd love to see the diff!
LSP seems like the way forward here, as half-baked as it is in it's current form. I think what we really need more than a common interface for driving IDEs, is a common interface for driving text editors - sort of an inversion / expansion of LSP's current focus, with the editor presenting a common interface for capturing/delegating user IO for a short list of features like fuzzy search / autocomplete. If Vim, emacs, and VSCode all had the same semantics and core assumptions about how the display / input capture for those features, most of what makes LSP a pain in the ass to work with would kind of evaporate, and you could delegate a lot more logic to the IDE server process where it belongs. But, passing JSON back and forth over localhost probably isn't going to get us there.
&gt; it really is time for us all to start consolidating efforts on Haskell IDE tooling instead of working in all our own little niches. "Consolidation" tends not to work for open source. It's at least plausible in the business world, where you're being paid a good wage to do whatever you're told to do; but even there, "acquihires" (acquiring a company to shut down its projects and get the engineering staff) almost always crash and burn. As a non-salary-payer, you're never going to get much in an open source project from a developer who is there because they were told the community needs to consolidate. If you want to get people on the same people, you have to just build cool stuff, tell people about it, be welcoming and open, and find those who WANT to be part of it.
The stuckness detection method seems to depend on deep ghc magic, would putting it in base be worth it to avoid a change to ghc breaking it?
I was using vscode and somehow I decided to try something more root. Today I'm using vim and ghcid and it is okay for now
The main problem we have with haskell tooling at work is that none of them scale. Intero has memory issues (https://github.com/chrisdone/intero/issues/566) and is so opinionated about tooling that it's not flexible enough. Haskell IDE engine barely works at all and if it does it is also very very memory hungry. The only thing that kinda works is codex and grep. If your project becomes sufficiently large, all haskell tooling falls apart. Even ghci leaks memory (or so it seems). That's why I think that we wont get much improvement on haskell tooling unless performance is taken seriously.
Now that we have fast succinct structures in Haskell, I wonder if we can't make use of them in external (intermediate) files to guide tooling. This necessarily requires some asynchrony in the ide interactions, but it should scale spectacularly!
It just so happens I'm currently working on some tooling for our tooling (hehe) to make fixing the kinds of excessive memory usage problems easier. Here's the PR if you're interested: https://gitlab.haskell.org/ghc/ghc/merge_requests/1227, see also the associated issue https://gitlab.haskell.org/ghc/ghc/issues/16788 Basically the plan is to have a new RTS profiling mode which is concerned with total memory usage of Haskell objects of interest instead of the runtime/implementation focused per-closure views we have now. To that end I had to do a bunch of refactoring first but once that's done implementing what I have in mind is downright trivial.
diff: http://source.propellor.branchable.com/?p=source.git;a=commitdiff;h=de21ef26861db458b0dfb0212cf501f9f8ed459b;hp=14f6ae30809d8bbdb10b91cc59757e865a365df8
&gt; Functional MVC has all the same problems that global mutable state does Yes, sort of. It has many of the same *kinds* of problems, but it has a lot less of them. The success of Elm, for instance, shows exactly how much good that can do. The problem is that it has limits in how it scales to complex tasks. You can raise that ceiling, if you're willing to pay the abstraction cost (and that's FRP). &gt; Do you have any resources on how to structure an FRP application? I don't feel like I'm any more qualified than most of the rest of the Haskell community to make recommendations on structuring your large FRP application. There are many people with more experience than I. I hope that some of them answer.
I have wondered the same thing. I'm not sure it's possible though &gt;&gt;&gt; :{ data Peano z s x where Zero :: Peano z s z Succ :: Peano z s x -&gt; Peano z s (s x) type PeanoRec = Peano 'Zero 'Succ &gt;&gt;&gt; :} &lt;interactive&gt;:30:29: error: ‚Ä¢ Expected kind ‚ÄòPeano z0 s0 z0 -&gt; Peano z0 s0 z0‚Äô, but ‚Äò 'Succ‚Äô has kind ‚ÄòPeano z0 s0 z0 -&gt; Peano z0 s0 (s0 z0)‚Äô ‚Ä¢ In the second argument of ‚ÄòPeano‚Äô, namely ‚Äò 'Succ‚Äô In the type ‚ÄòPeano 'Zero 'Succ‚Äô In the type declaration for ‚ÄòPeanoRec‚Äô
Thanks! Glad it's useful to you. In the final example, I think you might have missed the `{-# LANGUAGE OverloadedStrings #-}` on the first line? `show` is an interesting solution, though!
"monadic" like any adjective, or word in general, has meanings. It's not just a sequence of characters. So you can do what you want.
So you want to know if it's possible to implement a language in which GADTs are indexed by values of that same GADT? You're in luck, [I implemented such a language](https://github.com/gelisam/circular-sig)! It was Jason C. Reed's idea, he told me at a conference that he thought it would be logically consistent to allow it, and so I implemented a proof of concept for fun.
I think there are simpler solutions: a project's continuous integration can track GHC HEAD; I recall some GHC contributors do actually build a fairly large set of packages on a regular basis (Ryan Scott?), and if that process is not already formalized, it could be.
Cool! I'd suggest that if it's working, that's an accident! You probably want `IfStuck e (DelayError err1) (DelayErrorFcf err2)` rather than `IfStuck e (TypeError err1) (TypeError err2)`
Are you applying that statement to the authors of the paper? This is the title of their paper: "Remarrying Effects and Monads" One only needs to read the abstracts, here's a quote: &gt; In particular, we implemented an exten-sion to the effect type system of Koka [19] withuser definedeffects. We use a type-directed translation to automaticallylift such effectful programs into monadic programs, insert-ing bind- and unit operations where appropriate. As such,these effects are not just introducing a new effect type, butenable full monadic abstraction and let us ‚Äútake control ofthe semi-colon‚Äù in a typed and structured manner. To understand that they are implementing monads in Koka.
Okay, that's good to know that they're doing research on that. So anyway, Koka, in the current public version, is a pure effect system. It does not have monads.
Koka seems to be based on free monads. You may not think it exists because of the of its inference system built into the compiler.
In addition to the pithy comments here, you may also be interested in this paper: [Giving Haskell a Promotion](http://dreixel.net/research/pdf/ghp.pdf).
&gt;The problem is that \[functional MVC\] has limits in how it scales to complex tasks. I have to say, I‚Äôm still a bit confused about this. Exactly what limits do you run into if you attempt this?
If you want the skinny on arrows, I'd recommend this paper: http://www.cse.chalmers.se/~rjmh/afp-arrows.pdf
Whoops! You're totally right, sorry about that!
No. I would recommend you not make assumptions on the matter based on what you think it seems like. It is correct to say that algebraic effects are related to free monads. This is similar to how inductive datatypes are freely generated by a set of operations.
The normal presentation of MLTT dependent type theory doesn't allow this. I also fear it might cause inconsistency. That said, the implementation shouldn't be *too* much more difficult than dealing with recursive terms.
You see the limits pretty plainly in large react + redux applications. After a certain size, the main reducer either becomes hundreds, if not thousands, of lines long or you break it up into smaller chunks and combine them all together and end up with 20+ nested function calls barreling through a tight loop. Performance issues abound. And that's just with sequential logic. Asynchronous stuff requires an exponential amount of complexity on top of that and tracing bugs and logic flow through the system from one end to another becomes almost impossible.
MTL style is nice for glue application :D
Switch the new reddit UI, for the formatting to work.
An intent may be derived from a textual request, in natural language. But it's not limited to that. So far I can only think in passing strings around and check around that, but somehow that doesn't feel right.
I had similar experiences. The only editor integration that worked for me for large (200-300 modules) projects is haskell-mode and even then only flycheck errors work in reasonable time. Things like jump-to-definition or type-at-point require manually loading the file which could take up to a minute for some modules, which is why I also use hoogle, ghci and ghcid to enrich the experience. I'm very hopeful of this project (hie-core) and would very much like to see it succeed.
One option is to try to change your data type to have the right parameters: last time I had a similar data structure, I used something like `Tree (Maybe AnswerChoice, Entity Question)`, where the root was a `Nothing` and everything else was a `Just`. Another option would be something like `(Entity Question, Forest (AnswerChoice, Entity Question))`. In either of these cases, you can build the traversal out of standard functions. You can even write more generic forms and then instantiate the type variables: newtype AnnotatedTree a b = AnnotatedTree (a, Forest (a, b)) deriving (Functor, Foldable, Traversable) This won't automatically get you a map (and others) for the first type parameter, but those should be not _too_ hard to write, especially with some type tetris.
You are right that we are currently implementing our own module chasing. I do agree that this is not great but as you mentioned what is in GHC today is not great for the IDE usecase either and GHC evolves too slowly to use upstream for experimentation. Once things have stabilized and we have arrived at a design that we are happy with, we‚Äôll be more than happy to try and get (at least parts of) it upstreamed.
Sam Lindley slides: https://shonan.nii.ac.jp/archives/seminar/103/wp-content/uploads/sites/122/2016/09/handlers.pdf#page=28
The thing is I think it's unecessary to do this experimentation right now. Why not experiment with this once we actually have haskell-ide-engine working reliably? As it is this just feels like fracturing an already fractured ecosystem further. Let's just concentrate on getting HIE to a point where most people can actually use it and once we HIE working properly this sort of experimentation is easy to do upstream because you already have _something_ that works so the 6 months release cadence is not really a problem anymore.
heh, close.. It was an iPhone! I'll edit the comment to remove those typos
Great news! I always recommend this book, though I haven't yet seen it reviewed by any new Haskellers. A marketing suggestion: it would be great to see reviews and testimonials linked on the book's home page; and to see it listed on [haskell](https://www.haskell.org/documentation/) [starting](https://haskell.fpcomplete.com/learn) [pages](https://wiki.haskell.org/Learning_Haskell), so more people could find out about it. Large project ideas: any GUI apps or video games would be popular. Cross platform of course :)
What made you decide against, roboboticus ?
If you replace the second `^.` with just `.` it will work as you expect, as it only has to handle the Monoid combination at the very end instead of twice at both layers.
I agree, but with stack not fully supporting cabal and also not just contributing to the existing project / not being allowed to (I don't know the history of it) it was pretty disruptive.
Awesome write up! I thoroughly enjoyed it :) &amp;#x200B; A heads up: The link to silica is missing and I can't seem to hoogle it or stackage it
Thank you for your positive feedback :) Regarding `silica`: are you reading the latest version of the blog post? The link indeed was broken because the package is not on Hackage (see [my other comment](https://www.reddit.com/r/haskell/comments/c7td6f/blog_post_a_story_told_by_type_errors_a/esj8aaw/)).
Whoops! I was reading an older version. Left it open yesterday to get around to reading today :)
But don't worry, you didn't miss anything :) I've just updated the link to `silica` since publishing.
Thanks
Thanks
What‚Äôs wrong with lenses? `generic-lens` gives me pretty much exactly the functionality I want. The syntax is clunky, but that would just mean I‚Äôd lobby for first-class treatment of lens syntax, not that I‚Äôd say we need to scrap lenses.
You can massage it a bit to make it compile ``` data Peano (z :: k1) (s :: k2 -&gt; k3) (x :: k3) where Zero :: Peano z s z Succ :: Peano z s x -&gt; Peano z s (s x) type PeanoRec = Peano 'Zero 'Succ ``` Don't know if that gets you anything.
I think types indexed by themselves are called or are equivalent to "inductive-inductive" types: https://cs.stackexchange.com/questions/64130/what-is-induction-induction/64139
Oh wow. Do you have any more proofs of soundness you found while implementing it? I am asking because of the following: Suppose you want to implement binary naturals in a dependently typed language. Then you could start by saying that it is a list of binary digits. But the List type looks very much the same as the unary numbers. You can apply a similar construction. A list of length 2n+1 is two lists of length n, a list of length 2n is two lists of length n. Oh, so the list type should be indexed by binary numbers! Which is apparently exactly what you implemented. Would love to hear your thoughts on this :)
They provide what one expects from records and more, nothing wrong with them. But Haskell itself should do something about their records see [this](https://gitlab.haskell.org/ghc/ghc/wikis/records) wiki for some ideas, some of would really be nice to have.
No, I didn't write any proof, and my implantation is based on the [Simply Easy](http://strictlypositive.org/Easy.pdf) paper which intentionally uses an inconsistent type-in-type model for simplicity's sake. I also did not implement a termination checker nor a positivity checker. So this is only a proof of concept, it is definitely not a proof that the idea is sound. You should be able to implement your vectors indexed by binary numbers idea using a normal programming language. You don't need my prototype in order to do so because binary numbers should be indexed by a list of digits, not a vector of digits. I would instead look at [ornaments](http://personal.cis.strath.ac.uk/~conor/pub/OAAO/Ornament.pdf), it demonstrates how to define lists by augmenting unary numbers with data, and I think the same technique can be used to define your fancy lists by augmenting binary numbers with data.
I'd echo that you have to make a choice, pick stability/reliability to make basic things work, or experimentation. You can't do both. It would be useful for Digital Asset to take a clear position on that: is this **experimental** or a **stable foundation**? I wouldn't, for example, recommend or move myself onto a system less reliable than Intero (which isn't a paragon of reliability, but its development is stable), for example. Relatedly, for a number of tools: intero, prana, sift I basically copy/pasted the [`Main.hs`](https://github.com/chrisdone/intero/blob/master/src/Main.hs) file from the ghc project, so it would handle the param parsing (a frontend plugin is not reliable for this purpose because it has to load up your package) and other setup. This commandline interface is used by both cabal and stack for `cabal repl/stack repl` for provisioning which packages and which targets (test suite, lib, etc.) within those packages are loaded along with all the package database and flags info and passed to `ghci`/`intero`. I thought that this should be put in a library that tools can use, to be launched as: `stack repl --with-ghc foo` or `cabal repl --with-ghc foo`. IDE-like tools are distinct from simple compiler plugins. I don't know how HIE, ghc-mod, etc. figure out any of this information. But this is how intero does it. And I think it's pretty reasonable to re-use the same effort put into running GHCi, because GHCi isn't going anywhere.
&gt; Now that we have fast succinct structures in Haskell We do? Where can I read more?
Yes, there are multiple implementation strategies. As said, the interface/type system externally is not monads. I have been very consistent in not talking about implementation details, since I have no experience with implementing Koka. As seen there, Koka uses a combination of Free Monads and CPS (I'd assuming looking like CoDensity) for the implementation. But the type system doesn't suddenly stop being type-and-effect based as soon as someone interprets it into a datatypes? That's like saying a functional language doesn't actually have first-class functions because they eventually get turned into datastructures for implementation.
Interesting, haven't seen OO used in Haskell before. ^((Yes I know about O'Haskell; I said used))
Awesome! Do you have any benchmark numbers you could share? E.g. what cold start times are you seeing, how does function execution fare, and how does warm lambda execution times look like?
Oh I proably only tested that it displayed the stuck error when it was stuck, not when it was not stuck.
It's a solid foundation. That doesn't mean it has to look exactly like what went before, but it means that the cost of each deviation has to be carefully weighed up. For IDE's, there's really the "does it work at all", and "does it work well if it works" - each of which is almost separate. We defer does it work at all to hie-bios, and aim for hie-core to work well. What you are describing around loading up ghci is exactly what hie-bios does. Deliberately, we are keeping this information out of hie-core, and composing the two after-the-fact, since we think the two are best separated.
Those numbers are in the article, with a bit more detail in the linked docs.
This sounds similar to [Elixir's Phoenix LiveView](https://dockyard.com/blog/2018/12/12/phoenix-liveview-interactive-real-time-apps-no-need-to-write-javascript) library. Really cool to see something like this in Haskell.
From what I know about Haskell which is still very limited: functor is a generic type and in this case it's generic over type a and b.
`(a,b)` is a tuple. So it's a functor to a tuple like `(Int, String)`. The type variable `f` is constrained to be Functor but the `a` or `b` could be any type - or the same one. Just for example if the type was `Functor f =&gt; f (a, a) -&gt; f (a, a)` then the items in the tuple would both have to be the same type. Does that help?
Functor has an instance for pairs (two tuples). It only applies the function to the `snd` position and leaves the `fst` position alone.
In that case f(a, b) and f(b, a) should be same? Also isn't a and b type variable?
Yes, in the case of a function a -&gt; b it means that it Takes something in and gives something out and these things don't have to be of the same kind so here you have a type f that's generic over types a and b (or tuples of a and b?) so (neglecting the functor bound because I have no idea what that is) for example [(Int,String)] if it's a tuple or maybe something like a HashMap if it's not
Oh Shit missed your questions; no I doubt that (a,b) and (b,a) is the same. And yes a and b are Type variables to f (or the tuple (a,b) is one type variable to f
This type signature may not be the most rewarding one to study, since it is impossible to implement an interesting function with this type signature. It must be a specialization of `id :: a -&gt; a`. You might have more fun with a type such as `bar :: Functor f =&gt; f a -&gt; f [a]`.
Thanks Still confused with functor to tuple. I was trying to implement foo to understand more tried `foo :: (Functor f) =&gt; f (a, a) -&gt; f (a, a)` `foo x = (fst x, snd x)` but getting this error. `‚Ä¢ Couldn't match type ‚Äòf‚Äô with ‚Äò(,) a0‚Äô` `‚Äòf‚Äô is a rigid type variable bound by` `the type signature for:` `foo :: forall (f :: * -&gt; *) a. Functor f =&gt; f (a, a) -&gt; f (a, a)` `at learHaskell.hs:8:1-42` `Expected type: (a0, (a, a))` `Actual type: f (a, a)` `‚Ä¢ In the first argument of ‚Äòsnd‚Äô, namely ‚Äòx‚Äô` `In the expression: snd x` `In the expression: (fst x, snd x)` `‚Ä¢ Relevant bindings include` `x :: f (a, a) (bound at learHaskell.hs:9:5)` `foo :: f (a, a) -&gt; f (a, a) (bound at learHaskell.hs:9:1)`
u/SV-97 has misunderstood what's going on (or is explaining what he means poorly?) - `(a, b)` is a single type, namely tuples of type `a` and `b` (which are type variables, yes - so is `f`). Some examples to illustrate: `f` has to be a functor, so it could be `[]`, `Maybe`, `Either String`, or a bunch of other things. I'll stick with those three for now. `(a, b)` is a tuple containing things of any two types. It could be `(Int, String)` or `(Char, [Maybe Bool])`, or some other tuple. `f (a, b)` could then be `[(Int, String)]`, or `Maybe (Int, String)`, or `Either String (Int, String)`, or something more complex like `[(Char, [Maybe Bool])]` or `Either String (Char, [Maybe Bool])`. Or, y'know, any other tuple wrapped in some type constructor that is a functor. Does that make sense?
&gt; don't have to be of the same kind You probably meant to say "type" here. Kinds are a separate thing in Haskell. Just for example `Int` has kind `*` because it has no type variables. Functor is kind `* -&gt; *` because it has one type variable. &gt; over types a and b (or tuples of a and b?) `(a, b)` is a tuple with two items that could be of different types. &gt; neglecting the functor bound because I have no idea what that is This might help: https://wiki.haskell.org/Functor In Haskell, it's basically a type that can be mapped over.
Yeah I misunderstood at first and then realized that it may actually be tuple (a, b) :) thanks for the clarification
&gt; foo :: (Functor f) =&gt; f (a, a) -&gt; f (a, a) &gt; foo x = (fst x, snd x) You're trying to treat `f (a,b)` as if it's just `(a,b)` in your example. The tuple needs to be "in" something that's an instance of Functor. An example would be `Maybe`. If you have a `Maybe (Int, Int)` then that would be something you could pass to your function. However, since you've defined your function to take any type of functor I'm not sure you can write anything other than the identity function with that signature. Note: I could be wrong about that, I'm not extremely good with abstract type stuff. If you haven't already, I'd suggest looking at the Functor typeclass: https://wiki.haskell.org/Functor `fmap` and `&lt;$` are the two things you have to work with stuff that's in a Functor, if your only constraint is the Functor typeclass. What are you actually trying to have your function do?
No need to dive that deep into the internals! There's actually a working counter [example]( https://github.com/pkamenarsky/concur-replica/blob/master/examples/Misc/Main.hs#L74) in the concur-replica repo. Clone the repo, then: stack repl concur-replica:exe:concur-replica-misc In the repl you can then call counterApp And then open `http://localhost:8080`. Alternatively, you can build the example (but you'll have to adjust main to call counterApp in that case).
Okay I understood for `foo :: (Functor f) =&gt; f (a, a) -&gt; f (a, a)` it will `id` What will be for `foo :: (Functor f) =&gt; f (a, b) -&gt; f (b, a)` will it be `id` too? &gt;What are you actually trying to have your function do? Basically I saw this type signature some where and trying to understand why functor f takes two type variable. And trying to implement some concrete code to see how it look like and better understandability
Also I was trying to understand how `fmap` work here. foo :: (Functor f) =&gt; f (a, b) -&gt; f (b, a) foo x = fmap (\(a, b) -&gt; (b, a)) x
&gt; What will be for foo :: (Functor f) =&gt; f (a, b) -&gt; f (b, a) will it be id too? That one you can write a more interesting body for - although I don't think you could do anything other than swap the tuple. For example: foo :: Functor f =&gt; f (a,b) -&gt; f (b,a) foo f = fmap (\(t1,t2) -&gt; (t2,t1)) f &gt; Basically I saw this type signature some where and trying to understand why functor f takes two type variable. Functor only takes one type variable, but keep in mind that type variable can have type variables too. It's the tuple that has type variables `a` and `b` in your example, not Functor. If it makes it easier, consider this example instead: data Pair a b = Pair a b foo :: Functor f =&gt; f (Pair a b) -&gt; f (Pair b a) foo f = fmap (\(Pair t1 t2) -&gt; Pair t2 t1) f
Very close, except you forgot the backslash needed to define the lambda. Could also write it with a where clause and separate function if that is clearer: foo :: (Functor f) =&gt; f (a, b) -&gt; f (b, a) foo x = fmap swaptuple x where swaptuple (x,y) = (y,x)
Integrating `reflex` into `code.world` is dreamy. I will now recommend this to anyone looking to learn how to program using reflex.
ndmitchell you‚Äôre on fire!
&gt; We looked at other compiled runtimes, and having one executable per lambda ‚Äî which at first hadn‚Äôt seemed like an option to us ‚Äî now started to be more appealing. &gt; That‚Äôs it! We could have the runtime embedded in the user project, together with the dispatcher. That's what my [`aws-lambda-runtime`](https://hackage.haskell.org/package/aws-lambda-runtime) did from the beginning. (Disclaimer: i don't have a dispatcher, you can make one if you want though - non-opinionated in that respect). Nobody ever listens. :/
Cool, this is pretty great. I am loving how we, at the library level, are fixing some of GHC's issues with atrocious error messages. \u\isovector: Thanks for making this. Only thing left is a QuaziQuoter for a type level printf.
Thanks for the kind words! &gt; is there a way to write unit tests to make sure errors are properly thrown? I was hoping someone was going to ask this. The [test suite](https://github.com/isovector/type-errors/blob/master/test/Main.hs) for `type-errors` is just the haddocks themselves. They're run via [doctest](http://hackage.haskell.org/package/doctest)
True, but not relevant here.
Cool, I've developed something similar [here](https://github.com/advancedtelematic/quickcheck-state-machine/blob/master/src/Test/StateMachine/Z.hs). My inspiration came mainly from [Z](https://en.wikipedia.org/wiki/Z_notation) and [B/B-method/Event-B](https://en.wikipedia.org/wiki/B-Method) and the idea was to use it to define pre-, post-conditions and invariants for state machine specifications. I don't really have a good open-source example of where I use this heavily, but [here's](https://github.com/advancedtelematic/quickcheck-state-machine/blob/c9c424b57ff53a969e769b7c5c3100a0a31fb15e/test/MemoryReference.hs#L113) an example that uses it a little bit to give you an idea of what I'm talking about. I'd be curious to hear how you intend to make use of your library, or are you merely implementing these things to get to know them better? The chapter on "Contract-oriented programming" in Oliveira's book seems particularly interesting as it shows how to actually use all this machinery to write specifications. I can also recommend Jean-Raymond [Abrial](https://en.wikipedia.org/wiki/Jean-Raymond_Abrial)'s [book](http://www.event-b.org/abook.html) "Modeling in Event-B: System and Software Engineering" if you are interested in more examples. By the way, I think what you call `BEnum` (bounded enumerations) is often called `Finite` (because it's a finite set/type).
This makes more sense ... Thanks for more clarification
You probably don't want your tech support chat bot bothering folks when they visit the blog.
I have a PDF of Pierce of questionable origin.
So I'm still a University student but I'm very much so into compilers. Following some of the below suggestions I've read a bunch of papers (I'd read some before) and dug much more into GHC's codebase than I had previously. I also worked through all of Implementing Functional Languages: A Tutorial, except with the addition of some monads. One of my side projects recently has been trying to implement a toy language, very like Diehl's ProtoHaskell, that compiles into Java (Frege has already done this, but I'm doing it to learn). I've also been disappointed that Write You a Haskell stalled, but I think trying to write a tutorial for a modern functional language, from top to bottom, in the same vein is still a great idea. If anyone else wants to work on something like this with me, I think it could be quite a fun project!
Hi, thanks to all those who replied with messages about pdf copies. I‚Äôm grateful for the replies but I would really like hard copies. Thanks.
stack doesn't support Backpack (except of the `mixins` clause). But what happens if one of the dependencies of the current project uses Backpack internally, but doesn't expose any signature or "indefinite" library? Would that work?
Oh! Very cool! Yeah, that is a very similar implementation. I need to dig into that library! I've heard of the Z and B-Method but haven't explored them at all. I'll have to check them out. I don't have anything too specific in mind, and was largely exploring the ideas to learn. I wanted to explore maybe making a point free tensor expression DSL like the linked TACO project. I also was interested in seeing if I could do program synthesis search from relational specifications, in particular with regards to optimization problems. A third thing I have been thinking about is how to approach mathematical programming (linear programming, quadratic programming) from a point free/categorical perspective. I've sort of wandered on that topic to now thinking maybe it makes more sense to build a relational point-free polyhedral computation library. https://github.com/JuliaPolyhedra/Polyhedra.jl I think that makes more sense. Something like Meet = intersection, join = convex hull, compose = eliminate variable, division = optimization? I've been half nonsensically fiddling towards that direction over here https://github.com/philzook58/ConvexCat All of these may be ultimately out of my depth and scope. Baby steps.
I just upgraded some packages and have a change in behavior I need to work around. `jsonString ?^ nth n . key "whatever" . _String` used to return the last instance of "whatever" now it returns the first. How do I get the old behavior?
Printing out the pages and putting them in a binder could work. Also see if you can get them from the library, or from an interlibrary loan
Glad to help!
That sounds like this issue https://github.com/bos/aeson/issues/531 aeson accidentally changed the key it keeps in case of duplicates at some point. The other values are lost at parsing time, so until recently there was no way around that (and doing a breaking change again doesn't seem like such a great idea). If you use the latest version of aeson, there are alternative parsers to get the old behavior back.
thanks, interesting, just a few days ago It appears that I want jsonLast but it is not clear how to hook this into the above expression. Presumably I need to apply something to jsonString before ?\^
`eitherDecodeWith jsonLast pure :: ByteString -&gt; Either _ Value`
Oops, perhaps I didn't state it properly. The first sentence is related to packaging the runtime together with the project, not one executable per function üòÖ
There are quite some people using these patterns, Simon Meier described this as the service pattern, and Jasper VDG calls this the Handle pattern. We've found that handling effects in this way helps non-Haskell experts transition easier to Haskell projects :)
I've been trying to work with monad transformers for the first time and things are not going well. I'm able to define `MaybeT` on my own, although I have to think about it a bit, so hopefully I at least know the basics. I'm trying to make `finishSignin` in the following code use `ExceptT` so it's less nested and horrible: [https://github.com/DevJac/haskell-experiments/blob/ExceptT-experiment/src/Main.hs](https://github.com/DevJac/haskell-experiments/blob/ExceptT-experiment/src/Main.hs) This is part of a Spock web application I'm working on. I've minimized the problem as much as I can; I believe if I minimized it any further it would no longer help me to see it solved. The project is a small stack project with a single file. It will compile as is.
May I ask you what's your background and how did you find this work?
This is an odd signature to consider if this is your first exposure to Functor, since you get the same type (a,b) in and out. Someone correct me if I‚Äôm wrong, but the full signature of fmap for this instance would be: fmap::((a,b) -&gt; (a,b)) -&gt; f (a,b) -&gt; f (a,b) Which, if you‚Äôre new, is more than a little confusing. As someone who was in a similar spot about a year ago, take it slow, and carefully read the [Typeclassopedia](https://wiki.haskell.org/Typeclassopedia). (and this is probably heresy here but I‚Äôd also recommend a read through Essential Scala if you‚Äôre totally new to type classes. The extra syntax made the concepts a little clearer after the initial hurdle)
what does C -&gt; B^A from lecture 5 mean? What is the exponential for types?
I can see three main approaches 1. The real-world threading approach `IO a = World -&gt; (World, a)` 2. The operational approach `IO a where { Pure :: a -&gt; IO a ; Bind :: IO a -&gt; (a -&gt; b) -&gt; IO b ; PutLine :: String -&gt; IO () -- etc... }` 3. The uniqueness type approach Not sure of any others
https://hackage.haskell.org/packages/search?terms=hw -- hw-succinct, and hw-json and hw-xml built on top of it in particular.
I think that your code of the `fetchAccessToken` function is fine. You may think that nestedness looks ugly, but in this case, it's at least explicit, and you can see that you handled all cases. Also, I see that each time on the `Left` constructor you provide new error message each time. This info will be lost if you drop `ExceptT` there. So you need to decorate each function with `ExceptT`, but you can't do this in a uniform and nice way since every function returns a different type of errors fetchAccessToken :: Manager -&gt; OAuth2 -&gt; ExchangeToken -&gt; IO (OAuth2Result Errors OAuth2Token) userInfoCurrent' :: Auth -&gt; IO (Either Error User) So, if you want to change your code to use `ExceptT` you need to do something like this: data MyError = ... fetchToken :: MonadIO m =&gt; Manager -&gt; OAuth2 -&gt; ExchangeToken -&gt; ExceptT MyError m OAuth2Token userInfoCurrent :: MonadIO m =&gt; Auth -&gt; ExceptT MyError m User And only then you can try to compose these functions inside a single nested `do`-block. But I want to say that a combination of `ExceptT + IO` is considered anti-pattern in Haskell programming. If you want to learn more about monad transformers, I can suggest my blog post where I described one use case. It's not a tutorial, but I hope it gives you a better idea. * https://kowainik.github.io/posts/2018-11-18-state-pattern-matching
Ph.D. in physics and an interest (I guess professional now) in functional programming and formal methods. I was looking for information on category theory + optimization problems and found out the second half of Bird &amp; de Moor is kind of all about that. I'd heard of Bird &amp; de Moor for a while, but only gotten around to reading it recently. From there it was google-fu. Clearly, I love that Oliveira book. In other words, it's very roundabout.
Now I have more grasp of the internals of replica, so it wasn't a waste :) I'm now chekcing out concur-replica. I know reflex/react, but first time touching concure. At first glance, it looks like a mix of event-only FRP and TEA-like view update. I definitley need to look into it.
Hi - I'm in a similar boat, but have started with Haskell from First Principles. I picked it based on some reddit comments, but because it's 1250+ pages long, it's quite an investment. Getting a job doing it would certainly constitute appropriate pay-off. Something to consider as your next book maybe?
&gt; I don't know how HIE, ghc-mod, etc. figure out any of this information. But this is how intero does it. And I think it's pretty reasonable to re-use the same effort put into running GHCi, because GHCi isn't going anywhere. But I'm willing to be persuaded otherwise. Both currently use my cabal-helper library underneath. Essentially the underlying assumption there is that the lib:Cabal build-system is _the_ common denominator for all build-tools (cabal-install, Stack etc.) and we directly talk to it to get the info we need. I would say the cabal-helper approach is pretty stable at this point, we're working on adding the necessary support code upstream to let lib:Cabal do the heavy lifting to replace the hack we currently use: https://github.com/haskell/cabal/pull/5954 once we use that it will really be rock solid. However recently some build systems such as Bazel (IIRC) have invalidated the lib:Cabal assumption a tad as they just call GHC directly. Since cabal-helper exposes a very rich interface to Cabal's build info it's not really possible to force that into the same framework. I think that doesn't invalidate the approach though. It just means we'll have a two tiered approach: hie-bios's GHC flags centric stuff as a base level of support that always works and more sophisticated functionality, cabal file refactoring anyone?' :-), with normal Cabal projects. That is all part of my GSoC project so we should have that figured out by the end of the summer at least.
Why wouldn't Haskell apply newtype rules on the IO monad? Other types declared using newtype are optimized away and avoid heap allocations for the wrapping data structure.
&gt; It's a solid foundation. But how can that be true when it literally is new and unproven (at least for real world Haskell instead of DAML)? Please convince me that I'm wrong but when I had a quick look at the code it didn't even seem to handle cyclic modules with hs-boot files at all and that just makes me think how many other dark corners of ghc's module chasing are you not implementing properly? Why introduce this unknown factor into the HIE equation now when we have other things to worry about instead of getting things working and then optimizing the architecture?
Thanks for the advice. I'm jut using `Text` as my error type. Errors end up getting displayed on the webpage. This will work fine for now, since errors are rare. I've never encountered an error case from this code, but it's good to know that it would at least handle the errors, and it would give enough information that I could begin debugging further. I've been trying to implement the function like so: `finishSignin :: Route -&gt; ExchangeToken -&gt; ExceptT Text (ActionT (WebStateM Connection Session st)) a` Yes, there are different error types from the two IO functions, but I just ignore the errors and supply my own `Text` error description.
There's no _extra_ heap allocation (like what would be caused by `data`), but there is a heap allocation associated with the function/closure. `data IO a = IO (World -&gt; (World, a))` would allocate for the `IO` constructor AND for the closure (and potentially an `a`) `newtype IO a = IO (World -&gt; (World, a))` would NOT allocate for the `IO` constructor, BUT it would allocate for the closure (and potentially an `a`) `newtype IO a = IO a` would NOT allocate for the `IO` constructor, NOR would there be a closure at all. It would DEFINITELY allocate an `a`.
I revised my example to be self contained: import Control.Monad.Trans.Class import Control.Monad.Trans.Except import Data.Either data ErrorA = ErrorA data ResultA = ResultA actionA :: IO (Either ErrorA ResultA) actionA = _OMITTED data ErrorB = ErrorB data ResultB = ResultB actionB :: ResultA -&gt; IO (Either ErrorB ResultB) actionB = _OMITTED data FooResult = FooResult errorResult :: String -&gt; FooResult errorResult = _OMITTED successResult :: ResultB -&gt; FooResult successResult = _OMITTED foo :: IO FooResult foo = do a &lt;- actionA case a of Left _ -&gt; pure $ errorResult "actionA error" Right a' -&gt; do b &lt;- actionB a' case b of Left _ -&gt; pure $ errorResult "actionB error" Right b' -&gt; pure $ successResult b' main :: IO () main = _OMITTED Can `ExceptT` help with the nesting in `foo`? I'm having the same struggles with this example as I was with my original code. Note, I'm not sure I will actually use `ExceptT` for such a simple case, I may just stick with the basics, but I do want to solve the nesting somehow as a learning exercise.
Thanks for implementing the package! I wrote a blog post with the tutorial on custom type errors: * [A story told by Type Errors](https://chshersh.github.io/type-errors) Today somebody asked me to solve some problem using custom error messages. And I've already used `type-errors` package for that: * https://chshersh.github.io/type-errors
Here is how I would do this: {-# LANGUAGE LambdaCase #-} import Control.Monad.Trans.Class import Control.Monad.Trans.Except import Data.Bifunctor (first) data ErrorA data ResultA actionA :: IO (Either ErrorA ResultA) actionA = undefined data ErrorB data ResultB actionB :: ResultA -&gt; IO (Either ErrorB ResultB) actionB = undefined data FooResult errorResult :: String -&gt; FooResult errorResult = undefined successResult :: ResultB -&gt; FooResult successResult = undefined data MyError = MyErrorA ErrorA | MyErrorB ErrorB eitherIOToMyError :: (e -&gt; MyError) -&gt; IO (Either e a) -&gt; ExceptT MyError IO a eitherIOToMyError toMyError action = ExceptT $ fmap (first toMyError) action eactionA :: ExceptT MyError IO ResultA eactionA = eitherIOToMyError MyErrorA actionA eactionB :: ResultA -&gt; ExceptT MyError IO ResultB eactionB = eitherIOToMyError MyErrorB . actionB {- Shorter code: eactionA &gt;&gt;= eactionB &gt;&gt;= pure . successResult -} fooExcept :: ExceptT MyError IO FooResult fooExcept = do a &lt;- eactionA b &lt;- eactionB a pure $ successResult b foo :: IO FooResult foo = runExceptT fooExcept &gt;&gt;= \case Right result -&gt; pure result Left e -&gt; pure $ case e of MyErrorA _ -&gt; errorResult "actionA error" MyErrorB _ -&gt; errorResult "actionB error" Basically, you perform several steps: 1. Create your own data type that has constructors for every case of possible errors. 2. Lift all `IO` functions to `ExceptT` to compose them nicely. 3. In the end, you unwrap `ExceptT` and pattern-match on the result to handle all errors or do something with the result.
Fantastic post! Do you mind if I link to this from the official `type-errors` documentation?
Sure! I would appreciate that a lot :)
I use Hakyll everywhere :-)
&gt; I also was interested in seeing if I could do program synthesis search from relational specifications I suppose you're familiar with https://github.com/scmu/aopa ? Together with Agda's proof search (C-c C-a) I guess you get a first approximation of what you'd like to do? I also just remembered I got an old [branch](https://github.com/advancedtelematic/quickcheck-state-machine/compare/feat/more-z#diff-66af4ddf0b8c8fabc0bc4270d1213beaR223) with some more relational stuff, in particular closure properties. I guess it never got merged because I couldn't find a use for them.
Why not, I might need a long holiday period to face 1250 pages though...
I don‚Äôt believe that ‚Äúoptimize the architecture‚Äù is an approach that works. You need to start with a solid foundation that includes a good architecture. Trying to retrofit a new architecture on an existing codebase that has grown organically over years is extremely hard and hard to do incrementally so a big switch to a new architecture is still an unknown factor. You are correct that we do not handle cyclic imports at the moment and I would also agree that there are probably other corners that we do not handle. When u/ndmitchell is talking about a solid foundation, I would say that mostly applies to the architecture which imho is the first thing you need to get right. Making it a solid Haskell IDE will take a bit more work.
I don't have any info on the specifics of the Stack vs. Cabal thing, but having tried to participate (and having participated a little bit) in Cabal development I *can* say that some of the Cabal people definitely don't believe "perfect is the enemy of good/working" and will go to extreme lengths at nitpicking just to kill PRs/proposals which otherwise seem like obvious improvements over the status quo. There also seemed to be aggressive hostility (from certain parties) to trying to learn anything from other ecosystems[1]. (Disclosure: Of course, I'm probably biased -- there's a reason I stopped even trying to contribute to Cabal and it was ultimately based on my perception of the above. I've never contributed to Stack.) [1] Which of course *also* aren't perfect and therefore not worth learning from. /s
I appreciate your enthusiasm for sarcasm, but indicating it defeats its purpose.
You really are the worst bot. As user Pelt0n once said: &gt; God shut up *I'm a human being too, And this action was performed manually. /s*
You a stupid robot that has no feelings. *I am a bot, and this action was performed automatically. If you're human and reading this, you can help by reporting or banning u/The-Worst-Bot. I will be turned off when this stupidity ends, thank you for your patience in dealing with this spam.* *PS: Have a good quip or quote you want repeatedly hurled at this dumb robot? PM it to me and it might get added!*
I think this would justify the separation somewhat, though still, a compatible but better offering would have been awesome (I'm not assuming that possible, just wishing for a pony).
[/r/livecoding](https://www.reddit.com/r/livecoding/) or [/r/algorave](https://www.reddit.com/r/Algorave/) may be a better place to ask this question. That said, without being a Tidal user, this is just five simple patterns laid on the top of each other. So I would try starting with something like this d1 $ sound "bd ~ bd ~ bd ~ bd ~" -- kick d2 $ sound "~ ~ ~ lt ~ ~ ~ lt" -- low tom d3 $ sound "~ ~ cp ~ ~ ~ ~ ~" -- clap etc
And what if it turns out this architecture doesn't work for some of the unimplemented functionality? I just think this is too risky for HIE. Anyways we were having a discussion on IRC (#haskell-ide-engine) about this just now and the devs seem to agree. I think you should open a GH issues if you guys want to discuss this further.
That‚Äôs exactly why I this has to be experimented with downstream first before we try to upstream this into GHC.
Great to see Neo4j embraced. I'm curious how suitable you feel Haskell is at working with Neo4j data (once it is pulled in from Cypher queries) compared to other languages. Or is that you fill the type benefits of Haskell have advantages in scraping and processing data before it's pushed into Neo4j? I noticed for example that your proposed _Deep Learning and Graph Databases_ book would use Python. I hadn't come across your book before, but have just purchased the first edition.
I saw a screenshot of Haskell code where &lt;= was shown as ‚â§ when you weren't on the same line as the operator. Is there a way to get that on spacemacs or vim? I tried to search, but IDK what the search terms would be.
You are probably looking for _font ligatures_. Something like this: * https://github.com/tonsky/FiraCode
Like /u/chshersh already said, it‚Äôs probably a font with ligature support. Some examples include Hasklig, Iosevka, and Fira Code. Alternatively, if the font you want to use does not have ligatures or if you terminal does nit support them, you can use a plugin for vim like in the [Scientifica repo](https://github.com/NerdyPepper/scientifica), in the `ligature_plugins` folder. For vim, the search term would be ‚Äòconceal‚Äô. I recently switched to emacs, but for me ligatures don‚Äôt work with Iosevka without any configuration, but I haven‚Äôt really tried my best yet.
I am aware of that project and have been going over the accompanying papers. It's an interesting suggestion, but I'm initially inclined to think that might not be the most direct road to synthesis search. Could I ask to find programs of lowest cost? I suppose one might be able to hack that in. I think you probably need more control over the search process than Agda has easily available? On the other hand, an excellent project to learn more about how to abuse Agda.
Yes thanks, I got to derive `Functor, Traversable` by generalizing my data type a little and removing the empty type. Basically adding a type constructor not just having the value constructor. &amp;#x200B; However, as you earlier suggested I still opted out to writing the traversal recursions by hand.
It's very popular in production Haskell right now, sometimes combined with mtl, sometimes standalone. Search for "records-of-functions" to find more material
How about including a salary range, instead of just asking people to submit a "salary requirement" with their application? "Competitive pay" is pretty vague, given people can get paid anything from $100k - $250k+... If someone wants to ask for more, you can negotiate, but it may make someone consider relocating who wouldn't otherwise (if it is indeed "competitive"!).
I‚Äôm going through ‚ÄúLearn you a Haskell‚Äù now. I was trying to do the right triangles one, and I‚Äôm not sure what‚Äôs wrong with this solution. let right = [(a, b, c) | a &lt;- [1..], b &lt;- [1..], c &lt;- [1..], a*a+b*b == c*c ] Provided I haven‚Äôt typed anything wrong here, this doesn‚Äôt give any errors. However when I try right !! 5 it seems to be in an infinite loop. The book solution is the same code as I typed, except instead of infinite lists, it has an upper bound at 10.
I've had a few ideas cooking for awhile and have just been waiting for your patch to be merged into serverless
thanks, I have this working now
I'm 100% guessing without a computer to try it, but perhaps it doesn't enumerate the tuples "fairly", and gets stuck trying `(3000, 1, 1)` before `(3, 4, 5)`?
In the example of elimination of Nat with computing the factorial, even though we get another Nat as the answer it's still called elimination?
In type theory, elimination rules are also applied to operators, an example of such is the "&amp;&amp; elimination rule." Say that "A &amp;&amp; B" is true, then we eliminate "&amp;&amp;" and infer A, B are also true. For the factorial case, we have "* elimination," e.g.: f = 1*2*3*4 = 2*3*4 = 6*4 = 24 at each step we eliminate "*", There's a much better and deeper explanation here: https://www.cs.kent.ac.uk/people/staff/sjt/TTFP/ttfp.pdf
Yes. Every non-constant function from `Nat` is given by `Nat`-elimination. Sometimes the results look like proofs of properties, and sometimes they don't.
&gt; let right = [(a, b, c) | &gt; a &lt;- [1..], &gt; b &lt;- [1..], &gt; c &lt;- [1..], &gt; a*a+b*b == c*c &gt; ] If you just drop the last clause like so: let right = [(a, b, c) | a &lt;- [1..], b &lt;- [1..], c &lt;- [1..]] You can see what it's doing: Œª&gt; take 10 right [(1,1,1),(1,1,2),(1,1,3),(1,1,4),(1,1,5),(1,1,6),(1,1,7),(1,1,8),(1,1,9),(1,1,10)] So it's going to try to exhaust the infinite list for `c` before it increments `b` then `a`... which of course will never happen, and the condition will never be met with `c` increasing and `a` and `b` stuck at one. It will work if you set maximums on the range: Œª&gt; let right = [(a, b, c) | a &lt;- [1..10], b &lt;- [1..10], c &lt;- [1..10], a*a+b*b == c*c] Œª&gt; right [(3,4,5),(4,3,5),(6,8,10),(8,6,10)] Œª&gt;
Cool! I'm working on getting it merged. Feel free to ping me if you need any kind of help :)
Thanks for the link to the paper in one of your comments. I thought through the problem and it seems to me that the typeclass around `shift` is unnecessary, and it makes it so that your regexps have to be explicit at the type level (which they aren't in the associated paper). It also seems like it creates extra garbage to reconstruct the whole regex, when much of it is constant. [Here's a version using existential states](https://gist.github.com/ryani/abf8502c3ea5a6bddb474ce46243edaf) that attempts to solve these two problems. I'm abusing Num as Semiring to reduce the dependencies. I haven't benchmarked this but it might be faster. If it isn't, it's probably due to `rFinal` being an additional function call. I thought about ways of moving that data out (`rShift` could return `(st,s)` instead of `st`) but it complicated the design somewhat.
If the appearance changed based on whether the cursor was on that line, I'm almost positive you're describing Vim's conceal characters feature. It allows you to replace or remove certain text depending on whether you are editing it or not.
Great introduction! I just finished reding the first chapter of the homotopy type theory book, and this summarizes it nicely. Helped me engrain some ideas, I feel more comfortable now that I've heard it twice. Recommend watching!
Yes. Usually overloading isn't part of a parser; you just parse anything that is syntactically valid, and let the typechecker determine the semantics of that parse tree.
The run-time behavior of `SymVal (Vec a n)` depends on `n`, but `forall n.` prevents any such dependency. See also this other comment of mine about "`forall` is not 'for all'": https://www.reddit.com/r/haskell/comments/c2uz2m/typelevel_totality_checking/ermqvj7/
Here is a nice way to read __Learn You a Haskell for Great Good!__ in a Jupyter notebook with executable code in a full Haskell runtime environment: &lt;https://mybinder.org/v2/gh/jamesdbrock/learn-you-a-haskell-notebook/master?urlpath=lab/tree/learn_you_a_haskell/00-preface.ipynb&gt;
I'd use a GADT
Why is it grim? It's certainly better than random greek letters.
I'm just not a fan of `unsafeInterleaveIO`-based solutions (which is what I guess yours is doing under the hood; but I haven't looked under the hood of `chanContents`), I am always afraid something somewhere will start pulling on a list that is still waiting on something else, causing a deadlock.
This is the right answer, but for what it's worth you can do it at the grammar level too via something like this: import Control.Monad import Control.Applicative import Data.Attoparsec.Text import Data.Text data Statement = AddInts Int Int | AddStrings String String deriving (Eq, Ord, Read, Show) parseStatements :: Text -&gt; Either String [Statement] parseStatements = parseOnly statements statements :: Parser [Statement] statements = statement `sepBy` (char ';') statement :: Parser Statement statement = lexeme (addInts &lt;|&gt; addStrings) addStrings :: Parser Statement addStrings = AddStrings &lt;$&gt; str &lt;* plus &lt;*&gt; str addInts :: Parser Statement addInts = AddInts &lt;$&gt; int &lt;* plus &lt;*&gt; int str :: Parser String str = char '"' *&gt; manyTill anyChar (char '"') int :: Parser Int int = read &lt;$&gt; many1 digit plus :: Parser () plus = void $ lexeme (char '+') lexeme :: Parser a -&gt; Parser a lexeme p = ws *&gt; p &lt;* ws ws :: Parser String ws = many (char ' ')
As someone who has made the mistake of enforcing typing in the grammar, I think it's worth pointing out a few reasons why it is a mistake. Firstly, since you end up with backtracking in the parser, you are likely to get unhelpful error message. For instance, parsing `1 + ?` might give an error that it was expecting `"` but found `1`, instead of complaining about the `?`. Secondly, it becomes much more difficult to extend and maintain. Finally, when you have a language with enough complexity (e.g. where you have identifiers that might represent a value of string or integer type depending on context) then you will need a type-checking phase anyway. If the type-checker can tell you that `a + b` is invalid because `a` is an integer and `b` is a string, then it can tell you that `1 + "foo"` is invalid for much the same reason. Consequently, it's not worth *also* enforcing this in the parser.
Thanks for all your work to get this merged into serverless, we're so close!
`foo` is a name of the expression `::` is a separation between then name and the type declaration `=&gt;` is a separation between the constraint section and type section - where constraint section states additional predicates that must be tru for some type variable `... f =&gt; f ....` is a syntax for (implicit) type variable, `f` now stands for ANY type as long as they satisfy those constraint section predicats (in your example f stands for any type as long as that type is a functor) `f .... -&gt; f ....` that's the function syntax, we just have more complex types of input and output `f (....)` indicates any type as long as it "holds" a tuple, holds in quotas, as that tuple may just be produced on demand, or in the futre (e.g. Promise from JS) `f (a, b)` indicates any type as long as it "holds" a tuple of two values, which may be of differnt type themselfs (and since those type variabled do not show up in constraint section, they really mean ANY type &amp;#x200B; Put thogether `foo` is a`(::)` function `(-&gt;)` that takes a functor as an argument `((Functor f) =&gt; f...)` and returns a functor `((Functor f =&gt; .... -&gt; f)`. Both functors are holding a tupes of two values of potentially different types `(f (a, b))` &amp;#x200B; &amp;#x200B; PS Since we do not know what `a` and `b` are, we can not change them, nor can we swap one with the other as both `a` are on the first position of the tuple. We do have an access to various functions working on `Functor` but since we can't modify `a` and `b`, all we really can do is return exactly the thing we got as an argument. Thus: &amp;#x200B; `foo = id`
Let's take couple of steps before arriving at your example. So, let's say we a function: yolo :: a -&gt; b It's very simple. You have two unrelated and unrestricted type variables `a` and `b`, the function yolo then can be called with a value of any type to produce value of any type. There's nothing more complicated to that. So stop and think how would try to write any code that has this type. ... After a moment you'll realise that there's no way to provide a value of type `b` in the given unrestricted context. It is impossible to construct such a function without cheating the type system (there are some unsafe functions intended to do it). &amp;#x200B; \-- Let's take a look at another function type signature: boring :: a -&gt; a boring x = _boring This function is somewhat similar but now its argument and produced value must be of the same type. Notice that we don't have any other information about the context in which the function will be called. So when trying to find the implementation of the typed hole `_boring` the only way to provide anything with the same type as the function argument `x` will be to simply use `x`. Try to do it any other way. &amp;#x200B; \-- Can you construct the value to substitute for this typed hole? groundless :: f a -&gt; f a groundless x = _groundless In fact notice that `groundless` is no different than `boring` but `f a` will restrict values to be of types parameterised by at least one other type so it's slightly less general groundless = boring -- this is a valid implementation. &amp;#x200B; \-- fooUnrestricted :: f (a, b) -&gt; f (a, b) fooUnrestricted x = _fooUnrestricted We've got closer to the type you're trying to understand. Notice that when implementing this function we will find ourselves in the exactly same situation as before. There's still only one way to create the value of type `f (a, b)` as we know nothing about `f`, `a` and `b`. We don't even need to understand what `(a, b)` is. Apart from that this is a single type parametrised by two other types `a` and `b` Now let's add a constraint that will restrict f to be an instance of class `Functor` foo :: Functor f =&gt; f (a, b) -&gt; f (a, b) foo x = _foo Can you see that `boring` is still a valid implementation of `foo`? The only thing that changed is that now we are guaranteed that `foo` will only be called in the contexts where `f` is an instance of class `Functor`. What it gives us is another way to construct a value of `f c` from `f (a, b)` by using function `fmap :: (a -&gt; b) -&gt; f a -&gt; f b` given a function `((a, b) -&gt; c).` A functor basically allows mapping a function over the type it is parametrised by. In other words whenever you have a value of type `f _` and `f` is an instance of Functor you can apply a function to it and expect resulting value to also be of `f _`. These are all valid implementations of `foo`: foo x = x foo = fooUnrestricted foo = boring foo = fmap boring foo x = fmap (\(a,b) -&gt; (a,b)) x I would suggest you to introduce more methodical approach to learning Haskell. For example create a class for types of kind `*` and few instances for it, then use it in some functions, next do the same with a class for types of kind `(*-&gt;*)`, then `(*-&gt;*-&gt;*)` or even `((*-&gt;*)-&gt;*)`. So go depth first and make sure you grok the general rule. This way the things will become less complex as you won't be mixing essentially unrelated topics together. Cheers!
I know some of those words!
I think that this answer is bad because it just shuffles the problem around. "Reasonable" is just as vague as that "good" is. With this answer you moved the problem from defining what "good" means to defining what "reasonable" means. So what does this set of reasonable problems that is critical in the definition of a good programmer consist of?
Thanks to \*\*you\*\* folks for the awesome plugin. We'll get this sorted out super quickly üí™üí™üòÅ
I wish I could so casually stand before a crowd of people telling them I'll replace their jobs soon, and letting nobody notice.
intellij-haskell will most certainly use them
Yeah, the general flow is tokenize, build an AST, typecheck the AST for typed languages (here's where you'd resolve function calls and operator overloads!), then generate your output code. Trying to do anything involving types before you have everything parsed to an AST and have a type tree built would require all kinds of hacky solutions to problems you'd be addressing in the next step anyway.
Why does it need to be sound/consistent? Doesn't it suffice to be *useful*? I get that it can only then be useful for *proving things*, like Coq and Agda, but, for example, in *Haskell*, I only need this type to *be there* and *work*.
Great talk! Some questions: Previously, you had mentioned that you couldn't get the constant factors of Reflection without Remorse small enough that it was worth using. Is your use of it in this project due to further improvements in the constants or due to the fact that you're working in a domain where the asymptotics dominate? If the former, could you talk a little about what led to those and broader implications; if the latter, could you describe some features of the domain that lead to this? You mention that the slides will be online. Are they up already? If so, where? If not, could you link them here when they are?
It could be that the barbie package does what your want, even if its purpose is somewhat more general (making higher kinded data)
http://hackage.haskell.org/package/generic-monoid
[generic-data](http://hackage.haskell.org/package/generic-data) and [one-liner](http://hackage.haskell.org/package/one-liner) support this.
I was hesitant to introduce another tool/framework. Since I'm finding my stride with cabal and Hspec, I wanted to stay within those bounds.
Interesting. The reformatted LLVM code does look much more readable in the ContT style. Is there a way of wrapping the operations so you don't need to put `ContT $ ` everywhere?
As the article mentions, if the API itself were using `ContT`, you wouldn't need to do that as a user of the API. However, as it is, if you want to *use* `ContT`, someone has to introduce it. That could certainly be a wrapper API, but it would basically just pre-compose `ContT` on each on the llvm-hs functions.
With [http://hackage.haskell.org/package/rank2classes](rank2classes) you'd say instance Semigroup Config where a &lt;&gt; b = Rank2.liftA2 (&lt;&gt;) a b
I think a lot of tutorials these days skip the lexing / tokenizing. They just go straight from a stream of individual characters to as ADT. OP may have even seen an example where they go straight from the stream to a *Typed* AST. It's certainly possible if you types or expressions are simple enough (STLC, e.g.) I'm a big fan of using a Typed AST, but even I would recommend that if you have any sort of interesting polymorphism at all that you first parse to a normal, untyped AST, that from there do type inference and checking. I'm also a big fan of unnamed ASTs (DeBujin indexes for all variables), so I'd probably parse to a named AST, and then start replacing names with indexes (annotated with the original name) even before I type check.
One person to give a number loses the negotiation. ;)
It's kind of mind-boggling and depressing to me that someone as apparently smart and capable as kmett has wound up working for MIRI.
Part of my concern over Reflection w/out Remorse is that I wanted to have worst-case asymptotics when I was working with `machines`. Here amortized are generally good enough. Slides: [Keynote](https://drive.google.com/file/d/1qF-_HkjMXzGCV1OLb3kXC7zz_oGdG_nO/view?usp=sharing) | [PDF](https://drive.google.com/file/d/1l8g5hYmx3w6C-2MDHYEQfL5KAwznx-t_/view?usp=sharing)
You don't need to believe in MIRI's general overall concerns to be happy with the concrete work they're paying edward to do.
But also, if you don't believe in MIRI's motivation, perhaps reconsider, or give some constructive feedback.
I do love ContT. I do also indeed use it rarely. When I do use it it's for inversion of control (which still blows my mind no matter how many times I've implemented it). Not too big a fan of using it for wrapping CPS code though. First of all, monad transformers are kind of ugly to use and I can never remember their API, and ContT is no exception. It's easier for me to just add `-XNondecreasingIndentation -XBlockArguments` and write main = withFoo \foo -&gt; withBar \bar -&gt; withBaz x y z \baz -&gt; do doStuff foo bar baz Using ContT is about the same anyway since you have to add `lift` and `ContT $` everywhere. Secondly I'm kinda worried about performance. I wrote a [toy compiler](https://github.com/Berengal/hbfc) that uses llvm-hs, and while investigating some performance bugs (turns out llvm-hs and llvm itself both have quadratic complexity traps) I found out that about 80% of my runtime (once the traps were avoided) was spent in `withModuleFromAST`, and about 75%, uninherited, in `AnyContT.&gt;&gt;=` alone (iirc, it might have been 65%). That is, a program that parses a file, transforms the AST multiple times, translates it to a different AST, then to a third AST, then finally to a sequence of bytes, writes those bytes to a file, then waits for a linker to link that file into an executable, spends 3/4 of its time inside the functional equivalent of a semicolon, not doing anything useful, just trying to figure out what to do next. Maybe it's easier to optimize away if you're not wrapping them in an existential like llvm-hs does.
The implementation of [`AnyContT`](https://github.com/llvm-hs/llvm-hs/blob/601443f123cb387ee0dc2279454abc9b8521a2b8/llvm-hs/src/Control/Monad/Trans/AnyCont.hs) also doesn't look like it does any inlining or other optimisations, but I'm not sure if that would make a difference. IME CPS-transforms usually increase performance, so it's strange to hear of it reducing performance in this case.
Would you rather such talent were spent at Facebook? Perhaps a global investment bank? Or maybe a drone company patrolling the US southern border? I say good on MIRI for funding this kind of work.
I remember learning this pattern from someone in the #haskell irc but with `Codensity` instead of `ContT`. The different positions of the `r` mean you can't do callCC weirdness or something like that.
EM: SMT solver Me: Ah, Shin Megami Tensei solver. I didn't play that one.
I didn't investigate closely. My leading hypothesis is that `AnyContT` causes massive headaches for the GHC optimizer. Which is understandable, I'd get a massive headache too if I tried optimizing an existential. It's not so much the CPS-transformation I'm worried about, it's the monad transformer part. They're not a great solution to the monad composition problem. They're okay. But they bring an amount of extra baggage with them, both in runtime performance and in conceptual encumberance. AFAIU CPS can help avoid some of the performance issues with monad transformers, and `ContT` itself is pretty safe from performance issues compared to other transformers, but it's not completely free of them. When you pass it as an argument to other types, don't aggressively inline it and write polymorphic functions in different compilation units things get a little hairy. As for the blog, it doesn't exactly demonstrate that `ContT` is the best. It's the only implementation that uses `allocaBytes` instead of `mallocBytes`. Using `allocaBytes` does require CPS though, because it's the best way to scope in Haskell, and `ContT` has a nicer interface than manual CPS. It also demonstrates that `ContT` doesn't have a penalty in this case, which would be very surprising indeed. While I tend to handwrite the CPS code for resource managers, I would probably use `ContT` for that problem myself because of the recursion. Even then the manual CPS code isn't *that* horrendous. withList :: [Int] -&gt; (Ptr List -&gt; IO a) -&gt; IO a withList [] return = return nullPtr withList (x:xs) return = allocaBytes #{size list} \struct -&gt; do #{poke list, car} struct x withList xs \xs_c -&gt; do #{poke list, cdr} xs_c return struct way2' n = withList [1..n] csum
Nice instructive and well-written article! By the way, `Cont` and `ContT` are special among the usual Haskell functors (which include monads): they aren‚Äôt containers. I used to believe (and tell others) that there are two intuitions behind functors: (1) functors are types of containers, and (2) functors are types of effects. For example, lists can be seen as containers that assemble elements in a linear structure and also as non-deterministic computations. Meanwhile I know that the container intuition is not always possible and `Cont` and `ContT` are the prime counterexamples. There is interesting work on container theory, where the intuitive notion of what a container is is captured mathematically. Once this is done, you can _prove_ that every container gives rise to a functor but the converse is not true. I guess the fact that the continuation-passing functors `Cont` and `ContT` aren‚Äôt containers is part of the reason why they often feel so weird.
One man‚Äôs modus ponens is another man‚Äôs modus tollens.
Do you have a definition for "container"? `(-&gt;) a` and `IO` don't belong to my intuition of "container"s either‚Ä¶
Since he mentioned container theory I'm guessing he's using the definition from that. I'm the opposite, I have no problem thinking of `Cont` as a container. `(-&gt;) r` and `IO` too are no problem. What's the difference between a `r -&gt; a` and a `Map r a` anyway? Or `[a]` and `Int -&gt; a`? You could say one's stored as data while the other's a function, but data constructors are functions too. It's not just a lambda calculus thing either, the STG machine stores data as closures and reads data by calling the constructor function. `IO` is just a different name for `World -&gt; (World, a)`. `Cont` is a container you need to tell what to do with the value before you get it, even if that is do nothing, just give me the value.
And so this can be [derived *via*](https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/glasgow_exts.html#extension-DerivingVia) [`GenericMonoid`](https://hackage.haskell.org/package/generic-monoid-0.1.0.0/docs/Data-Monoid-Generic.html#t:GenericMonoid) and [`..Semigroup`](https://hackage.haskell.org/package/generic-monoid-0.1.0.0/docs/Data-Semigroup-Generic.html#t:GenericSemigroup) {-# Language DerivingVia #-} data Config = Config { cFoo :: Option (Last String) , cBar :: Option (Last String) } deriving stock (Show, Generic) deriving Semigroup via GenericSemigroup Config deriving Monoid via GenericMonoid Config To pull a Hickey (weird) the behaviour of `Option (List String)` is still "*complected*" with its type, it is representationally equal to `Maybe String` meaning they can be coerced at zero-cost &gt;&gt; import Data.Semigroup &gt;&gt; import Data.Coerce &gt;&gt; &gt;&gt; :t coerce :: Option (Last String) -&gt; Maybe String .. :: Option (Last String) -&gt; Maybe String With a [sums-of-products approach to generics](https://hackage.haskell.org/package/generics-sop-0.3.2.0/docs/Generics-SOP.html) we can untangle these ferocious two data Config = Config { cFoo :: Maybe String , cBar :: Maybe String } deriving stock (Show, Generic) deriving (Semigroup, Monoid) via SOP '[ '[Option (Last String) , Option (Last String) ] ]
&gt; What's the difference between a r -&gt; a and a Map r a anyway? Totality and coverage of a non-finite domain.
Sounds like you want an effect system, my dude. Have you considered [polysemy](https://github.com/polysemy-research/polysemy)?
In Haskell especially data can be partial too. And it could be codata.
You might not need a typeclass, perhaps you just need to make `doSomething` a higher-order function: doSomething :: (Text -&gt; IO (Either e Text)) -&gt; IO () Or, if you really do want to keep the typeclass, you could define monad transformers which add retry and caching behaviour to the `GetContent` implementation of the base monad: instance GetContent e m =&gt; GetContent e (RetryingT m) where ... instance GetContent e m =&gt; GetContent e (CachingT m) where ...
Whats so bad about MIRI?
MIRI has given me remarkably free rein to work on what I believe is useful to see in the world. Prior to this a significant fraction of my time was taken up dealing with the needs of the financial sector. I am quite grateful to them for the liberty they offer me. I'd felt pulled in far too many directions before. I want a large body of correct code to build atop to reach for higher goals. MIRI is actively facilitating my work rather than merely tolerating it like most organizations I've worked for in the past. If you don't believe in MIRI's mission, then consider that they are simply funding foundational research that is broadly generally applicable, and freeing me of the need to justify my daytime hours to folks with completely irrelevant goals. In that case you can simply derive more benefits from the byproducts I'll produce here than you can from the smaller number of byproducts I could produce when I could only frantically scrabble away on them in my evening hours between work projects. If you do believe in MIRI's mission, then the work I'm doing becomes a fair bit more relevant. My research agenda is not a carbon copy of theirs, and they seem happy to have a fresh perspective. I do feel that their work is important. In particular, I'm a huge fan of their existing work on [Logical Induction](https://arxiv.org/abs/1609.03543), which has rather drastically impacted my approach to Bayesian reasoning. They've been able to change my mind on things about as often as I've been able to change theirs. A community that is capable of actually responding appropriately to new evidence is something I quite value, and something I'd like to see more of in the world. I'm sorry that you had whatever negative interaction you had with MIRI to form your impression of it.
So I went back and had another look at those profiles. The function that was actually taking so much time was `AnyContT.lift`, not `AnyContT.&gt;&gt;=`, and the most it spent was 53%. This was also with llvm-optimizations at `-O0` (to avoid the mentioned quadratic behavior). It's better, but still pretty bad. `AnyContT.&gt;&gt;=` doesn't get off scot-free, however, as it also took between 5-10% between different input sizes. Add to that that `return`, `fmap` and `&lt;*&gt;` also show up with a few percent and you end up with `AnyContT` taking the majority of the execution time without llvm-optimization (and sharing the top spot when the optimizer is run twice at `-O3`). So the good news is it's not the `Cont` part that's at fault, it's the `T`. Mostly. The bad news for CPS is that the reason `AnyContT` exists in the first place is because `allocaArray` and friends are written in a CPS style. Unfortunately, in the `(Ptr a -&gt; IO b) -&gt; IO b` part of `alloca`'s type, the `IO` shows up in a negative position, which means you can't call it using the standard `Monad` and `MonadIO` function. You either have to unwrap your monad transformer stack to get to the `IO` at the bottom, or you put on your spacesuit and go visit outer type space. Turns out type astronauting doesn't optimize well. I'm honestly a little tempted to see if it's possible to use `unliftIO` (which I don't think is possible, or if it is, improves the situation), or if it's feasible to just delete `AnyContT` and hand-specialize the code instead. Since it's a type internal to the library its uses shouldn't strictly speaking need to be polymorphic.
https://www.youtube.com/watch?v=D7rlJWc3474 and https://www.youtube.com/watch?v=s5OnhepyL7w are the first two hours of a 4 hour workshop I ran at Monadic Party on the same topic. The first video link has considerable overlap with the talk linked above, while the second video link is the start of a deeper dive on propagators as we dig into the implementation of the technology involved in more detail.
We use this pattern in production in a similar to the "Reading from a list of files" case, except quite more complicated, and `ContT` helps a lot. You can take a look at docs [here](https://github.com/input-output-hk/plutus/blob/3bc324e7e138bbe83b96cdf8c8603f2ce6245f3b/plutus-ir/src/Language/PlutusIR/Transform/Rename.hs#L19). ... except it's really supposed to be `Codensity` rather than `ContT`. Compare: ``` newtype Codensity m a = Codensity { runCodensity :: forall b. (a -&gt; m b) -&gt; m b } ``` and ``` newtype ContT r m a = ContT { runContT :: (a -&gt; m r) -&gt; m r } ``` `Codensity m a` is a simpler representation of the `with*` pattern than `forall r. ContT r m a`.
FWIW- AnyContT = Codensity
In container theory, a container type consists of two things: 1. a type of shapes 2. a dependent type that maps each shape to a type of positions in this shape Let‚Äôs take the list type `[]` as an example: The shape type of it is the type of natural numbers, where a natural number *n* denotes the shape of a list of length *n*. The position type for a shape *n* is the type of those natural numbers that are smaller than *n* (often called `Fin n`). The positions are the indexes of the list elements. A type `(-&gt;) a` is also a container type. It‚Äôs the type of total maps whose indexes are of type `a`. There is only one shape here, whose position type is the type `a` (so the values of `a` play the same role as the indexes in the case of `[]`). It‚Äôs not really possible to say whether `IO` is a container type, because there isn‚Äôt really a definition of `IO` in terms of functional programming constructs. If you treat `IO` as `State World`, then it is a container type. `State World a` is isomorphic to `(World -&gt; World, World -&gt; a). Thus the shape type of `State World` is `World -&gt; World` and, independently of the concrete shape, the position type is `World`.
I essentially agree with you except for `Cont`. Even if you wouldn‚Äôt care about container theory, you probably would say that a container should be some data structure that contains elements at certain positions. Thus it should be possible to consider a value of a type `Cont r a` as a data structure that contains values of type `a`. However, what do you do about the following `Cont` value that is essentially a proof of the law of excluded middle: import Control.Monad.Cont (Cont, cont) import Data.Void (Void) lem :: Cont Void (Either a (a -&gt; Void)) lem = cont $ \ k -&gt; k (Right $ \ x -&gt; k (Left x)) A value of type `Either a (a -&gt; Void)` tells us whether `a` is an empty type: * If the value is `Left x`, `a` is non-empty, since it contains `x`. * If the value is `Right f`, `a` is empty, since there is no function from a non-empty type to `Void`. If `lem` was a container, it would correspond to some data structure with elements of type `Either a (a -&gt; Void)` in it. What would this data structure look like? For non-empty types `a`, it couldn‚Äôt contain any elements, since the implementation of `lem` cannot and does not invent values of the unknown type `a` out of thin air. However, the shape of this `lem` data structure would be independent of the type `a`, because we cannot distinguish between different types `a` at runtime. Therefore this data structure wouldn‚Äôt contain any elements also when `a` is empty. How would this absence of elements for any type `a` get along with the fact that `lem` apparently constructs both `Left` and `Right` values? Mysterious! The good thing about container theory is that it captures the intuitive notion of a container mathematically and then makes it possible to _prove_ that `Cont` is not a container.
If it's supposed to be Condensity, why do you use ConT? Is it a historical thing? Performance? (Just curious)
Thanks, I wasn't sure if they were the same. I wonder why they chose to reimplement it, especially when [your implementation](http://hackage.haskell.org/package/kan-extensions-5.2/docs/src/Control.Monad.Codensity.html#Codensity) is almost certainly in their dependency tree anyway and is better optimised.
I am using webviewhs, which provides a win32 window on windows 10. However, there is also the usual console that displays when running applications for basic print / putStrLine, how do I hide this?
An interesting comment, founded on relevant theory. Let me answer with the hackneyed programmer response; the ill-conceived metaphor: A `Cont` is a robotic tin-can. To open it you need a can-opener; the continuation. You give the can-opener to the robot, which then uses it to open up and get the value for you. The value you end up with depends both on the can-opener, and how the robot uses it. Sometimes the robot blows up, but when it does you don't care because you're not around anymore. So looking at `lem`, and throwing container theory out the window, you could say that `lem` does create a value of type `a`, but it doesn't do it out of nothing. It uses the continuation given to do so, which is pretty easy given the type of the continuation is isomorphic to `(a -&gt; Void, (a -&gt; Void) -&gt; Void)` aka `x AND not x`. This ability to use the consumer of the value to produce the value is what makes it weird. Makes it hard to index. It doesn't fit the definition of container according to container theory, but that still doesn't preclude an intuition of `Cont` as a container. It's not often a useful perspective to have, thinking of it as a computation is more relevant. The same is true for `State s` also, imho, even though it is a container according to container theory. `Cont` even as a computation is weird, with it's inside-out inverted structure, time-traveling and parallel universes.
No particular reason, we just inherited that from `llvm-general`. That said, I don‚Äôt think we depend on `kan-extensions` transitively atm.
wow! Monadic Party is so hard core üòÇ
Is there a beginner/intermediate level example of using polysemy? Something along the lines of writing a few effects, use interpret/intercept etc and then compile them down to IO/pure effect will be very handy to understand the idiomatic usage.
(-&gt;) can be seen as a promise, and IO is an inverted Bag of Holding (i. e. one with the rest of the universe inside). ;D
I mean... I love that phrase, but I don't see how it applies to the above comment.
Next question: Do you have any examples of how to _use_ guanxi? I'm imagining using it somewhat like a better interface to an SMT solver in Haskell, specifically for checking whether expressions in a complicated (but first-order) language including floating point arithmetic, booleans, and some custom operators are always `False`. Is it well-suited to that, and if so, where should I look for more information on how to get started?
Someone published one a couple of weeks ago: https://www.reddit.com/r/haskell/comments/c23wxd/example_for_polysemy_a_simple_guessanumber_game/
I use nix dockertool to build my haskell services and works really well. The only thing is you need to build static haskell programÔºåotherwise the final image size will be over 2GB.
I don't think it's fair to call code relying on coherence "legacy". It's a very valuable thing in a variety of circumstances from ordering to serialization.
It is still being built at this point, so it'll probably be a bit hard to use. It is currently made almost entirely out of sharp edges and should refine down to something more readily adopted in practice over time.
Hand-specialize the code is the best option. Following https://gist.github.com/agocorona/2c9149c4d2035f21952fc1d1691b7bde#file-transient-cont-hs-L133 type Dyn= () newtype AnyCont m a = AnyCont{ runAnyCont :: (Dyn -&gt; m a) -&gt; m a } where r has been defined as Dyn, You should use `unsafeCoerce` to match the type of the continuation parameter r, following the gist. That way you avoid the existential wrapping. that is in essence `ContT` with all his performance, but without the headaches of `r`.
`IO String` contains a `String` the same way a clock contains the time. (I.e. it doesn't.)
This doesn't work for me, and I'm not sure how it could -- what is `g` supposed to resolve to here?
Can't wait for part 2: "A Guide to Writing Properties of Impure/Stateful functions"!
Write a blog post about your setup!
There's also a very helpful [https://github.com/jkachmar/alpine-haskell-stack](https://github.com/jkachmar/alpine-haskell-stack) . I build fully static Servant backends with it, with final distributable images under 6Mb.
Hey! Anyone have a post about Haskell build and test through travis ?
Sure! I wrote such a post: * https://chshersh.github.io/posts/2019-02-25-haskell-travis It describes only simple settings (no Docker, no releases, no DB running in parallel for testing), but should be a decent starting point.
Nah I haven‚Äôt had anything to do with it, haven‚Äôt even use it! Though might do soon - mostly interested to keep the Haskell interest at work alive.
Not Travis, but I recommend you to check out CircleCI. This example shows how to run services for testing, GitHub releases and publishing to Hackage: https://github.com/haskell-works/hw-kafka-client/blob/master/.circleci/config.yml Here are the orbs that are used for this config: https://circleci.com/orbs/registry/orb/haskell-works/haskell-build https://circleci.com/orbs/registry/orb/haskell-works/hackage https://circleci.com/orbs/registry/orb/haskell-works/github-release Creating docker containers is also possible: https://circleci.com/orbs/registry/orb/haskell-works/docker-publish We do it a lot, but I can't remember any public repo that has it. It would look something like: ``` - docker/publish: name: Docker requires: [Build] attach-workspace: true source-env-file: ./build/project.env dockerfile: Dockerfile registry: your-favourite-docker-registry image: ${BUILD_EXE_NAME}_${BUILD_EXE_VERSION} tag: $(if [ "$CIRCLE_BRANCH" = "master" ]; then echo ${CIRCLE_BUILD_NUM}; else echo "${CIRCLE_BUILD_NUM}-${CIRCLE_SHA1:0:5}"; fi) ```
As others suggested, why do you need type class for that ?Are you trying to shoehorn OOP in your design or is there a deeper reason ?
I would use Circle CI more often, but it has limited free support for open-source... For example, this is our Circle CI config that we are using: * https://github.com/kowainik/issue-wanted/blob/master/.circleci/config.yml
The `g` would resolve to `Config`, but its kind must be `(k -&gt; Type) -&gt; Type`. You need to parameterize the field wrapper type. One way would be: data Config f = Config { cFoo :: f (Last Text) , cBar :: f (Last Text) } type Config' = Config Option or you can go data Config f = Config { cFoo :: f Text , cBar :: f Text } type Config' = Config (Compose Option Last)
You misread. Legacy code that relies on coherence is not the same a legacy of relying on coherence. &amp;#x200B; Any extension allowing to break coherence should come with ways to control when such breaks are not acceptable. Naturally, new code that needs coherence can use this new way to ensure it doesn't break, so it may use this extension to mark places where coherence is not enforced. Legacy code, however, already doesn't have such marks and coherence should be enforced by default. But how and when to break this coherence?
[removed]
&gt; You need to parameterize the field wrapper type Sure, it all makes sense then.
Hello! It would be interesting to study these examples where not using CPP would be worse. Do you feel like sharing some links?
I'd say anywhere I use CPP. Just search for CPP in any of my repos, eg https://github.com/ndmitchell/shake/search?utf8=%E2%9C%93&amp;q=CPP&amp;type=
This is absolutely awesome! Very useful for \*real world\* Haskell use.
I'm super interested in this stuff, I just need some time to parse it all. It loops back really nicely with my AI study at utrecht university, which was very heavy focused upon logic. I believe if you wish to attract more interested folks that would be a good place to start.
No need. I was just wondering. I just created a typeclass for the first time and wanted to see how far I could go.
I totally agree I can instead use a higher-order function. It's what I would resort to if I couldn't figure something out that I found was worth it. &amp;#x200B; I'll try the monad transformers, that's interesting as it will teach me how to write one. But like you and others said, I'll probably just use a higher order function in the end as it feels more natural already.
I'll definitely check that out. Thanks!
The Monadic Warsaw folks should post the next couple of videos from the workshop relatively soon. Those spend more time diving into propagators and how to use them as a bridge to transfer results from datalog to SAT solving to linear programming and the like, dig into unification under group actions, and start to peek under the hood more at the actual code.
The database variant of relational division that you link to is very different from what you define. The former is a pseudo-inverse of the Cartesian product of the two sets that's a subset of the given relation. Your version is a pseudo-inverse of the composition of two given relations. It has some similarity to a monus operation.
If anyone has a pointer to the chapter and verse on this it would be really useful - I think ghc has a great future in these embedded/edge environments. Happy to test anything on the Jetson Nano as I'm using it as a front end (viz/inference) for some embedded data logging kit and the thing was already developed in Haskell on x86. If ghc could catch this wave then goodness would ensue.
Surely once you reach this level of container nirvana you're capable of understanding the (much simpler) concept of Functor without the "container" crutch.
It uses \`stack\` :(
[https://github.com/haskell-CI/haskell-ci](https://github.com/haskell-CI/haskell-ci) is used for various packages, e.g. \`servant\`
Yes, they are not the same, but I think the cartesian pseudo inverse has a lot of the same flavor and is well described with an example on the wikipedia page. The same flavor in that you're looking for a thing that is as large as possible that when "multiplied" by another thing is a subset of a result. The term monus is not a something I had come across before, thanks! I think the Programming from Galois Connections paper in the references section focuses on something like this as their running example.
Ok. As you can see, Typeclasses are not necessarily the best way to model this kind of problem.
In this case, while I didn't have a lot of time to substantiate the claim. The focus of Kanren on teachability means it uses a fairly simple DPLL-like core, once you strip away the LogicT style walk. This means it flounders redoing much the same search in almost identical subspaces of the search constantly. If it were to drop the LogicT style walk and replace it with a depth first walk then it could engage with an off the shelf SMT solver, which I don't think anyone will claim is anywhere near as comparatively simple as the core of a "little schemer" book. Mastering SMT solving involves mastering something like 80 things. This is great if you are Leo de Moura, but is admittedly not a low bar to entry. My approach in guanxi involves taking a logic programming engine and dragging it in the direction of an SMT solver, using propagators to help smooth the transition and make it _somewhat_ palatable, and then using more structure such as union-find modulo group actions, a bunch of machinery for relocating propagators by a group action in O(1), etc. to make that have an acceptable performance tradeoff. Then I have to fix the problem that depth-first ordering would introduce non-termination in other areas, so we need to adopt rapid restarts and have a mechanism for tracking where you've been in the search space. The downside of all of this is that you basically wind up with a decent cross-section of the SMT literature, including modern "natural domain SMT", all of Okasaki's Purely Functional Data Structures, a little bit of group theory, what limited propagator literature there is out there, and the notion of arithmetic encoding, an overview of abstract interpretation for constraint programming, and succinct data structures to encode the trail of where you've been as necessary components to be able to build the solution. Then there are cases where you _do_ need to brute force a solution. For those I fill in with a couple of variations on Dancing Links which I have a reasonably strong intention of moving to the GPU. The benefit of all of this that it can now "learn from its mistakes" via CDCL or SDCL if we add quantifiers. It can avoid termination in a ton of cases where Kanren will go out to lunch. It can have a _much_ lower memory footprint. We can look at adding universal quantification to cover generation modulo _laws_. Even just the choice of LogicT style search forces a loss of a log factor in performance in the form of the triangular substitutions they use. There exist cases where the performance solution is quite explicable. This is not one of those cases.
Btw why were you saying this is related to OOP?
Btw why were you saying this is related to OOP?
The [`semigroups` package](http://hackage.haskell.org/package/semigroups-0.19/docs/Data-Semigroup-Generic.html) provides tools to define these with GHC.Generics. data Config = Config { cFoo :: Option (Last Text) , cBar :: Option (Last Text) } deriving (Show, Generic) instance Semigroup Config where (&lt;&gt;) = gmappend instance Monoid Config where mempty = gmempty
Personally I abandoned a container model of functor a long time ago. That's because there were many containers that weren't Functors (like `Set`) and many functors that weren't containers (like you mentioned). It just found that thinking of the functor abstraction in terms of containers didn't help me at all in the end.
If you were to refactor to FRP then I'd recommend Reflex. I would recommend that you first start by just modeling what you already have in Reflex. That is, you can create a monad stack that looks like this: `type App t a = EventWriterT t (First StateUpdate) (ReaderT (UniqDynamic t AppState) a` This will give you Elm/Redux architecture almost exactly, but embedded in Reflex. Here `StateUpdate` is a sum type representing all the updates you want to do to `AppState` based on various events. Once you have this working, you can start to break it down into widget-local state incrementally. As with all refactors, the trick is to keep it working with lots of small transitions. This also gives you a fallback if one of your ideas doesn't work out as well as you hoped. But you now have the *option* of using higher-order FPR to build new components.
how old is this? i don't see a date on the document, only on the references. so it must be from at least 2015?
John tweeted it yesterday, so I can only assume it's brand new
The definition of `getContent` suggests that you are planning to define different instances of different `m` and that those `m`s might have a sort of inheritance relation ship and I understand your question as how I can I use the `IO` instance when writing the more specific instance ? This class superclass class relation ship is OOP. However, I'm not asking you are doing that, I was just wondering if that's what you have in mind.
Fwiw, the author (John Hughes) previously published a paper with more stateful examples, as well as some real life examples [here](https://www.cs.tufts.edu/~nr/cs257/archive/john-hughes/quviq-testing.pdf). From digging around a bit, there seems to be a recent library in line with what you're requesting called \`quickcheck-state-machine\`, which has a really good associated article [here](https://iohk.io/blog/an-in-depth-look-at-quickcheck-state-machine/). They reference the quviq paper a few times in the \`quickcheck-state-machine\` article -- I haven't used it but from reading through, the library appears to make the "Model-based properties" type of tests easier to write, especially when the real thing is impure or stateful or doing IO.
Yes! It's important to push forward the "useful &amp; boring" ‚Ñ¢Ô∏è tools, as these will enable more devs into our community :D
If I understand you correctly, you say that the theoretical notion of container is just a bit restrictive and therefore excludes `Cont`, while an intuitive notion of container would treat `Cont` as a container type. I disagree with this. `Cont` also isn‚Äôt a container according to at least my intuition of what a container is. As I said before, I think a container should somehow carry elements in a data structure. I cannot see how `Cont` does that. A good way of finding out whether something can be intuitively considered a container might be to check whether it can be drawn on a sheet of paper with elements directly appearing at some places on the sheet. I can do that with a function of type `r -&gt; a`: I draw a table with two columns whose first column contains all possible values of `r` and whose second column contains the corresponding function results, which are the elements. I can also do that with a value of `State s a`, which is equivalent to a value of type `(s -&gt; s, s -&gt; a)`: I draw a table for the second element of the pair as before and in addition write down the first element as a Œª-expression. I cannot see how to draw a value of `Cont r a` in this way. I think your tin-can analogy would fit `(-&gt;) r` but doesn‚Äôt fit `Cont`. You can consider a function of type `r -&gt; a` a tin can and a value of type `r` a can opener, because the latter gives you access to a value of type `a` by passing it to the former. However, if you have a value of type `Cont r a`, which is equivalent to a function of type `(a -&gt; r) -&gt; r`, then a continuation, that is, a value of type `a -&gt; r`, will not give you access to a value of type `a` but of type `r`. So what you get out of the tin can is not an element, but for being a container the tin can should contain elements. You are right in that the `lem` computation really produces a value of the form `Right f`; it‚Äôs just that it needs the continuation for that. In the course, it also produces a value of the form `Left x`, using the argument of `f`.
You may find my post [here](https://www.reddit.com/r/haskell/comments/c9kmvd/simplifying_typeclasses/) interesting.
Spot on actually! I didn't have it explicitly in mind but that's what I was going for it seems. It kind of felt weird doing that but I still wanted to give it a try.
You might be interested in this https://lukepalmer.wordpress.com/2010/01/24/haskell-antipattern-existential-typeclass/ In your case. A simple function is probably enough.
I think I just didn't want to add a separate dependency and `ContT` worked perfectly well. Perhaps we should change that to `Codensity` indeed.
I believe this was presented at a TFP 2019 last month: [https://www.tfp2019.org/](https://www.tfp2019.org/)
https://www.reddit.com/r/haskell/comments/c9kmvd/simplifying_typeclasses/
Thoughts on [this](https://www.reddit.com/r/haskell/comments/c9kmvd/simplifying_typeclasses/) as an alternative way of approaching explicit typeclass dictionaries?
If it's not sound/consistent then you could be using it and accidentally cause everything to go wrong with no warning. It of course depends on the type of soundness/consistency you are asking about, some types are far more important than others, but no it is not sufficient to be "useful" if there is deep underlying danger.
Could you provide an example? As far as I know, Haskell's `Type :: Type` is inconsistent itself. What problems does this cause?
Two links: * https://stackoverflow.com/questions/7746894/are-there-pronounceable-names-for-common-haskell-operators/7747115#7747115 * https://wiki.haskell.org/Pronunciation
`&gt;&gt;=` bind `&gt;=&gt;` fish `&lt;$&gt;` f map `&lt;*&gt;` spaceship `.` compose `^.` get `.~` set `%~` over `$` apply `&amp;` rev-apply
`&gt;&gt;&gt;` then `$` on/of (ala f of x)
Right. It depends on the type of inconsistency. The inconsistency of pre-roles GeneralizedNewtypeDeriving is an example of very bad inconsistency, see [here](https://gitlab.haskell.org/ghc/ghc/issues/1496).
@chshersh Just out of interest, what are the limits that you are facing? For us it feels pretty decent: OSS gets 4 (if I am not mistaken) parallel builds, and an unlimited number of them. With our CCI config we get build times ~2-3 minutes per build, which gives us pretty decent throughput so that we don't feel limited. So far one of the greatest limitations that we face if that there is no free MacOS builds for OSS. This kind of sucks :( We work it around by piggy-backing on another org, but it's not ideal :( I have plans to look at Azure Pipelines, which looks interesting and offers free workers for Linux, MacOS and Windows for OSS. It unfortunately doesn't have caching abilities. But with `cabal-cache` we don't really need it, so it could be a win situation. I just need to get time and be less lazy perhaps :)
If you don't care about soundness / inconsistency, just use [Ex Falso](http://inutile.club/estatis/falso/). If you do care about soundness / inconsistency, you should care about them in the logic formed by your types. (This is especially true if your types are terms.)
I still think roles was the wrong solution. We deserve something that can handle `Monad` with a `join` member.
Personally I can‚Äôt say I‚Äôm a fan of implicit parameters. I do however appreciate the tradeoff between mtl and explicit dictionary passing. Hopefully [this](https://www.reddit.com/r/haskell/comments/c9kmvd/simplifying_typeclasses/?utm_source=share&amp;utm_medium=ios_app) can make it much easier to switch between them. It seems like rather than having a mess of many implicit parameters, you can bundle them all into a single record and pass just that record around, then with `Reader` added to the mix you can make that passing around implicit. I think the `Has` pattern is a good example of the above. Extensible rows/records/variants etc. could improve the ergonomics of such significantly.
This is essentially a follow up to [this](https://www.reddit.com/r/haskell/comments/c5ii8j/should_the_underlying_structure_of_a_class_be_a/?utm_source=share&amp;utm_medium=ios_app) post I made earlier.
- `&gt;&gt;= ` - right double fish - `=&lt;&lt;` - left double fish - `&lt;$&gt;` - rich banker clutching head in frustration - `&lt;*&gt;` - mother clutching head in frustration - `.` - single eyeball, eyein' ya. - `^.` - single surprised eyeball, eyein' ya - `~.` - single concerned eyeball, eyein' ya - `&gt;&gt;&gt;` - megafish - `%~` - excitebike wheelie - `$` - that which i lack - `&amp;` - that which i cannot write - `&gt;=&gt;` - fishboi - `::` - doubleboi - `-&gt;` - function arrow - `=&gt;` - rocket maaaaaan burning out his fuse up here alonnnne
Yeah I can't say I love roles, but I also can't say I have a better solution myself.
That looks like a very good choice for me! I was planning to use `reactive-banana` and somehow refactor it all in one go, but if Reflex does allow a Functional MVC architecture then it would definitely be way easier to start from there and refactor incrementally. I do have a few questions though: - Is it possible to use Reflex without GHCJS, Reflex Platform or Nix? (I‚Äôm on Windows so can‚Äôt easily use those) - Can I use Reflex with GTK? I already have a large GUI designed with the GTK GUI builder, and I need to find a way of feeding events from that into Reflex. - Is there a way of representing intermediate IO actions? For instance, if I want to ask the user for confirmation before doing an action, is there a way to do that?
What are your thoughts on [this](https://www.reddit.com/r/haskell/comments/c9kmvd/simplifying_typeclasses/?utm_source=share&amp;utm_medium=web2x)? It would avoid the need for you to define the `Generically` newtype or all the custom classes that duplicate the existing classes in `generic-data`, while giving you all the ergonomics of `DerivingVia` without needing the extension.
+1 for alpine, it's the best toolchain I've found with Haskell for producing static binaries. Note that it's [not officially supported](https://github.com/commercialhaskell/stack/issues/2387) though -- [I switched to Fedora](https://vadosware.io/post/least-effort-ghc-8-2-2-upgrade-for-my-servant-project/#step-3-switching-to-fedora) because of this.
If you're willing to change where you host your projects, Gitlab has excellent support for building haskell (it's just containers), and I've written about it a bit. They have IMO the best CI in the game, and 2000 minutes are free (and you can bring your own runners, extremely easily).
I follow this handy pronunciation guide: &lt; &gt; ! * ' ' # -- waka waka bang splat tick tick hash ^ " ` $ $ - -- caret quote back-tick dollar dollar dash ! * = @ $ _ -- bang splat equal at dollar under-score % * &lt; &gt; ~ # 4 -- percent splat waka waka tilde number four &amp; [ ] . . / -- ampersand bracket bracket dot dot slash | { , , SYSTEM HALTED -- vertical-bar curly-bracket comma comma CRASH &lt;https://spot.colorado.edu/~sniderc/poetry/wakawaka.html&gt;
That is the good stuff. You are my hero.
What about *&gt; I've heard people say "shark"?
I'm no where near as proficient as Oleg but I've written about building haskell quickly (with some focus on fast CI builds) as well. These posts are ordered *earliest first* (so outdated info first): - Building with alpine (my earliest post) - https://vadosware.io/post/static-binaries-for-haskell-a-convoluted-approach/#the-completed-dockerfiles - Doing it in CI - https://vadosware.io/post/zero-to-continuous-integrated-testing-a-haskell-project-with-gitlab/#step-2-optimize-the-build - Using the CI setup to do CD - https://vadosware.io/post/continuous-integration-to-continous-delivery-haskell-project-with-gitlab/#tl-dr-code-dump - Build issues on arch - https://vadosware.io/post/haskell-build-issues-on-arch-linux/ - Switching to Fedora from alpine - https://vadosware.io/post/least-effort-ghc-8-2-2-upgrade-for-my-servant-project#step-3-switching-to-fedora TLDR I switched to Fedora (since [alpine is not officially supported](https://github.com/commercialhaskell/stack/issues/2387)) and stopped bothering with static building since I didn't have `musl` any more and static builds don't *really* exist in glibc-powered distros like ubuntu/fedora/etc. You're almost always going to be linking against *some* low level thing, easier to just build with a minimal distro container (most of them are pretty small now, fedora:31 is 90MB right now for example). Thanks to Oleg for all his work on `servant` (along with all the other contributors) and insanely helpful posts over the years.
I love this! Since the previous discussion I am also convinced that this is a more direct and flexible solution to "deriving" than `via`. In particular, there is a limitation to `via` because the dictionary must be coercible, and there are situations where that's not the case, for example when a method quantifies over a functor which gets applied to a type index (try to derive vector's `Unbox`), or the situation of adding `join` to `Monad`.
Exactly what I was falling into
Dates back to 1990 by the way: [https://lists.ding.net/geeks/96/dec/msg00005.html](https://lists.ding.net/geeks/96/dec/msg00005.html)
Firstly, could you please edit your code to use code blocks? &amp;#x200B; Secondly, could you elaborate on exactly which parts you don‚Äôt understand so we have a better chance of helping you?
I don't like most of the english names, like "fish" (`&gt;=&gt;`), for operators in Haskell. The only one that ever really stuck with me was "bind", and that's only because `do` notation makes it actually resemble variable binding. And I guess "compose", because the symbol was given to the word rather than the other way around. But e.g. "spaceship" is bad to me because I feel like it's going to frequently catch people by surprise without reason. I much prefer calling them things like "the applicative operator", or more generally "the &lt;origin&gt; operator". I'll often even use "the monad operator" instead of "bind".
I like u/nooitvangehoord's list but want to add that I read `&lt;$&gt;` very literally: "mapped over." I also just read `&amp;` as "and" because that's why it has the symbol. `5 &amp; (+1) &amp; show` = "Start with 5 and add one and show." I frequently use this operator when writing my `runX` function for tall monad transformer stacks, so that reading the code goes down the stack which I think is nicer.
Just logged in to say you're not alone.
http://www.catb.org/~esr/faqs/smart-questions.html -- I don't see a question in your post *at all*.
&gt;Just out of interest, what are the limits that you are facing? &gt; &gt;For us it feels pretty decent: OSS gets 4 (if I am not mistaken) parallel builds, and an unlimited number of them. With our CCI config we get build times \~2-3 minutes per build, which gives us pretty decent throughput so that we don't feel limited. I see on the official page that I have only 1 container for free with 1000 build minutes limit per month, no concurrency, shared across all repos. Our builds also take ~2-3 minutes, but sometimes you need to rebuild the whole cache and this takes ~30-50 minutes for a project. So 1000 minutes is almost enough for active development on a single project. * https://circleci.com/pricing/ I was looking at Azure Pipelines as well after `stack` switched to it. But the absence of free cache out-of-the-box is very inconvenient. It looks crazy to me that you need to have your own S3 bucket, sync caches manually in addition to figuring out proper configs for your build. I don't have a bandwidth to be a DevOps person as well...
Thank you! Does anyone know why Steven Diehl stopped working on it?
/r/chshersh it should be much more interesting soon.. issue tracker says caching will be released in "weeks".
And here's another reason why operators must be aliases to the alphanumerically named functions.
One of the biggest disadvantages for all the built-in caches is that they cannot be shared between projects. Because of that the "whole cache rebuilt" happens per project, which is very inconvenient. To solve this problem was the motivation behind cabal-cache. But it does indeed require an extra bucket to manage.
Should be really interesting! Looking forward to it :) In the perfect case, I would like to have an easy way to build my Haskell projects with multiple GHC versions and deploy binaries to GitHub automatically on all 3 platforms without much hassle. Would be so nice if this can be easily achieved for Haskell
This has a different info: 4 containers, unlimited builds for OSS: https://circleci.com/open-source/ Unless I misread (from the phone), but it was my impression, and we are using it for a long time...
Whenever an operator has a different equivalent implementation that has a pronounceable name, or describes a mathematical concept with a good name, I use that. `&lt;$&gt;` map `&lt;*&gt;`, `$` apply `&gt;&gt;&gt;` then, `.` after (category theory) `&amp;&amp;&amp;` par, `|||` with, `+++` plus, `***` tensor (linear logic) `-&gt;` to, `&lt;-` from and so on.
I like it, but it doesn't seem practical to have multiple symbols with the exact same pronunciation. I propose something like this: Symbol|Spoken -|- `&lt;`|wakla `&gt;`|wakra `[`|bracklet `]`|brackret Still kind of works for the poem although it's much harder to say smoothly.
Glad you are doing this. Have you considered contacting or coordinating with Deihl?
Ah, thanks! Was on slow data and the images never loaded, so didn‚Äôt see them at first :)
I wonder how I can verify that I'm actually using this plan and if not, how can I switch to it...
Is there any benefit to this other than simplifying the compiler? To me it seems like it makes code way more ugly without much benefit and breaks some current functionality. For example your proposal on how to do "Defining a typeclass instance by defining only a subset of its structure" would only make it so that you can define one of the functions associated with a typeclass, but not the other. That can be a problem with some typeclasses like Foldable, where `null` can technically be derived from the other functions, but it makes `null` into an O(n) function. But many datatypes can implement it as an O(1) function. With your proposal they won't be able to change the implementation of the function and would have to use the O(n) version every time unless they use a custom `null` function that isn't tied to the typeclass. You could technically fix this by adding both/all of those derived functions back to the typeclass and then creating functions that will complete the missing functions for the programmer. But then you'll be faced with a combinatorial explosion of the number of functions you have to write. E.g. with a typeclass that has functions A, B, C and D, where A is the only required function. You would need to make this list of functions that will complete the missing function: `fromA`, `fromAB`, `fromAC`, `fromAD`, `fromABC`, `fromABD`, `fromACD`. And that's not even that bad. Add one more function to the typeclass and you'll have to write 8 more functions. No one will want to deal with this much boilerplate.
It simplifies the language, the compiler, the learning curve, IDEs, syntax highlighters etc. Particularly with how questionable Haskell‚Äôs tooling is and how afraid beginners are of Haskell and how complex the language is becoming over time, I would personally put simplifying the language at quite high priority. Each extension can be dealt with on a case by case basis as to whether it should be removed or kept as syntax sugar, so it won‚Äôt make code more ugly by itself. Plus I personally like the more direct code rather than some magic that I have gotten used to, but to each their own. In response to the rest of your comment you can always have the smart constructor take a bunch of Maybe‚Äôs for optional functions. Long term with extensible records and such defining structures with a lot of Nothing‚Äôs and a few busts could also be made much nicer (`{a = Just x, b = Nothing}` -&gt; `expand {a = x}`). This shows the beauty of it being a direct structure, you can use whatever types and functions you want for defining new instances instead of just some hardcoded options. It also directly enables the very direct passing around and manipulation of the underlying structure of typeclasses, which is currently not possible. Allowing things like easily deriving a class from multiple possible subclasses rather than being forced to specify one and only one default for DeriveAnyClass to use. I covered all this in the post, but yeah to be clear it goes beyond simplicity.
\* \`&gt;&gt;=\` bind \* \`&gt;=&gt;\` Kleisli arrow \* \`&lt;$&gt;\` fmap \* \`&lt;\*&gt;\` ap / tie-fighter \* \`.\` dot \* \`$\` dollar \* \`::&lt;&gt; \` turbofish
http://codewars.com/ https://www.youtube.com/watch?v=NzIZzvbplSM&amp;list=PLly9WMAVMrayYo2c-1E_rIRwBXG_FbLBW
I just call it spaceship because they did it once at a conference and I thought it was funny. Same with fish really. It just sticks in my head like that.
There's also [Urbit's pronunciation scheme](https://urbit.org/docs/reference/glossary/#glyph), which is very convenient once you get the hang of it: ``` ace [1 space] gal &lt; pal ( bar | gap [&gt;1 space, nl] par ) bas \ gar &gt; sel [ buc $ hax # mic ; cab _ hep - ser ] cen % kel { sig ~ col : ker } soq ' com , ket ^ tar * doq " lus + tic ` dot . pam &amp; tis = fas / pat @ wut ? zap ! ```
\&gt; The long term proposal would be for everyone to move away from the old approach and stop using various typeclass extensions and features, until eventually they can be deprecated and then removed. &amp;#x200B; This seems unrealistic. Simply too big a change. &amp;#x200B; \&gt; This cannot be solved by this current proposal alone, but with extensible rows/records/variants etc. all new nominal types will be newtypes over some underyling structure &amp;#x200B; I doubt this will the final form of the extensible records work, as it seems too disruptive. I believe (wrongly?) that records will remain their own thing instead of being reimplemented in terms of extensible ones.
It's a huge project, and IIRC he got hired. I don't know whether it's still the goto reference, but Simon Peyton-Jones's book about implementing a much less complicated language is pretty long
Which book is this? I haven‚Äôt heard of that one.
`&lt;*&gt;` is `ap` Often, something like `foo &lt;$&gt; bar &lt;*&gt; baz` is better pronounced like ‚Äùlifted foo applied to bar and baz‚Äù, i.e. transforming to `liftA2 foo bar baz` on the fly.
Awesome :) I've had recent thoughts along similar lines: an extended tutorial on compiling a functional language (not Haskell though). The more perspectives we have out there, the better.
"The Implementation of Functional Programming languages". Specifically, Lazy ML-like languages [https://www.microsoft.com/en-us/research/wp-content/uploads/1987/01/slpj-book-1987-small.pdf](https://www.microsoft.com/en-us/research/wp-content/uploads/1987/01/slpj-book-1987-small.pdf) That's a horrible scan but I haven't looked at it in years.
 &gt;&gt;= Bind =&lt;&lt; Bind &gt;=&gt; Then . dot &lt;$&gt; map &lt;@&gt; ap &gt;&gt;&gt; Then
Maybe we can summarise this by saying that although classes and instances are pretty much first-class (through reflection, constraint kinds, etc.) deriving strategies (deriving, deriving via, applying via (if it comes to pass -- hopefully not)) are \*not\* first class. You are suggesting an approach to make them so.
There is also "Implementing functional languages: a tutorial" which focuses more on the implementation and less on the theory behind it iirc. And most of all can be found as proper [pdf here](https://www.microsoft.com/en-us/research/publication/implementing-functional-languages-a-tutorial/)! /u/brdrcn
I think this is a great project! Your project sounds like it will be an awesome learning experience for yourself and hopefully others. \&gt; Recently, as a preface to (hopefully) being able to do some significant work on GHC But I want to add that I think the best way to learn how to hack on GHC is to hack on GHC itself.
Galtargar sounds like a villain from Battlestar Galactica.
I don't understand why you're being down voted so much. The direct access/manipulation of the typeclass structure would be wonderful, IMO.
&gt; Is there any benefit to this other than simplifying the compiler? Deriving is no longer limited to the four or five deriving strategies supported by the compiler, and can be reasoned about like any regular, user-level code, because it is regular code. And it's not like it really changes much to the language actually, for example [the previous post presented encodings](https://www.reddit.com/r/haskell/comments/c5ii8j/should_the_underlying_structure_of_a_class_be_a/) that are directly expressible today. data Monoid a = Monoid { identity :: a , op :: a -&gt; a -&gt; a } class TheMonoid a where theMonoid :: Monoid a &gt; You could technically fix this by adding both/all of those derived functions back to the typeclass and then creating functions that will complete the missing functions for the programmer. But then you'll be faced with a combinatorial explosion of the number of functions you have to write. The way the compiler handles default implementations (without the combinatorial explosion) can be translated directly in terms of open recursion and record update syntax: class Foldable f where foldable :: Foldable_ f data Foldable_ f = Foldable_ { null :: forall a. f a -&gt; Int, foldr :: forall a b. (a -&gt; b -&gt; b) -&gt; f a -&gt; b -&gt; b } instance Foldable MyF where foldable = defaultFoldable { -- record update foldr = myFoldrImplementation -- null (and any other missing method) uses the default definition from defaultFoldable, which uses this very instance recursively } -- Default implementation of Foldable defaultFoldable :: Foldable f =&gt; Foldable_ f defaultFoldable = Foldable_ { null = \xs -&gt; foldr foldable (\_ -&gt; (1 +)) xs 0, foldr = undefined }
noone: Haskellers: `::)`
I read this book between stumbling into the post last month and now. It was fun and informative, but lacks the tools needed to build a front end compiler for a modern language - the compilers in the book all are for Core. And not modern Core either, unfortunately. Also the book predates the STG machine, so while the section(s) on the G machine are pretty cool, they dont help too much with the modern process, because the G machine code could be translated to C fairly easily, but STG code translation is more involved. (If im wrong about this, please correct me!) Overall, definitely recommend. I just think the goals of the book were different from mine.
There's a nice website called [exercism.io](https://exercism.io/) with a mentoring system and multiple exercises for you to solve.
I've emailed him before to ask a question that wouldn't have required long term effort from him and he didn't reply. As much as I'd like Diehl to finish the series, I think he had decided to stop working on it before the last commits (which mostly merge PRs).
Ive played with the typechecker errors a bit (see MR 9173) but I struggled to get ghc to build on my Windows 10 laptop and also work at my University helping to write some backend tools for an intro course, so my time to work it out is a bit limited. My schedule right now is much more supportive of small, incremental steps, that I can forget everything between :) Overall, I do agree with you.
I suspect a flock of curmudgeons went past. The comment won't stay in the negative for long.
Reflex is the FPR engine that powers Reflex-DOM which can run in GHCJS, or even on the backend to prerender web pages on the server. But Reflex itself is just a Hackage package that you can use for anything if you wire it up. I don't know of any existing bindings between Reflex and GTK. Wiring up the set of things you need should not be too hard, though. The idea is that you'd connect certain Events to plain IO callbacks that would call GTK APIs. Here's an example of a terminal UI library based on Reflex: [https://gitlab.com/obsidian.systems/reflex-vty](https://gitlab.com/obsidian.systems/reflex-vty) I would be remiss if I didn't at least warn you that venturing into FRP takes some getting used to. Expect your project to take a long break from features during the transition.
Awesome. Thanks!
Thanks :)
That's true. If you were to write a modern compiler from the ground up it's probably worth thinking about incremental compilation and things like IDE support from the start anyway which do require different approaches for quite some things. But GHC is only now slowly adding features aimed at IDEs.
You did not start with a small task there looking at that MR :) I can only reiterate that you should ask on #ghc if you run into build issues. There are few (but some) people running GHC on windows there which might be able to help.
&gt; Particularly with how questionable Haskell‚Äôs tooling is and how afraid beginners are of Haskell and how complex the language is becoming over time, I would personally put simplifying the language at quite high priority. I can't recall any example of a programming language that has become simpler over time. Even in the tremendously unlikely case that the new way of defining instances proved so useful that some kind of consensus were achieved in removing the old way, the actual point in time of such complete removal would be so far in the future that Haskell would actually be *more complex* for years and years.
I did ask there and waited about two hours but no one answered :( &amp;#x200B; I saw a promising post by S. Marlow and another from during Zurihac and hopefully one of them will help, once I get back to GHC :)
With that name I bet someone in the team is from Argentina, I even risk to say she/he is from C√≥rdoba.
Blacket/bracket, blace/brace, palenthesis/ parenthesis?
He started [a company](https://adjoint.io/) that keeps him pretty busy :)
`unsafeRemoveBatteries`
There is another scan of the book here that looks a little better (it doesn't have the heavy jpeg artifacts, but was scanned 2-up): [https://www.microsoft.com/en-us/research/uploads/prod/1987/01/slpj-book-1987-r90.pdf](https://www.microsoft.com/en-us/research/uploads/prod/1987/01/slpj-book-1987-r90.pdf)
I fucking love this.
I'm glad that you've found the project useful! Please keep in mind that if you're building fully statically linked Haskell binaries with the default `integer-gmp` library that GHC uses then your resulting artifact falls under the terms of the LGPL. I am not a lawyer, however: if you're running the statically linked binary on a server then you're probably fine, but if you're distributing the binary to customers/communities (e.g. in the form of an archive or Docker image) then you're bound by the terms of the LGPL.
Not a real answer since I am from mu phone, but a hint to read about. You can mimmick this using proxies.
This looks neat and the examples are nice. Just a quick suggestion, expand your readme. Having to click through to examples and having the best explanation of why this package on reddit isn't great for marketing of this project.
Works for me!
You don't actually need type abstractions or `Proxy`s for this. You can use a helper function with the appropriate type like so: -- Assuming something like -- instance (SymVal a, SymVal (Vec a n)) =&gt; SymVal (Vec a (S n)) where ... foo :: (forall a . SymVal a =&gt; Dict (SymVal (Vec a n))) -&gt; (forall a . SymVal a =&gt; Dict (SymVal (Vec a (S n)))) foo = go where go :: SymVal a =&gt; Dict (SymVal (Vec a n)) -&gt; Dict (SymVal (Vec a (S n))) go Dict = Dict Although I can't see the advantage of using `foo` over just using `go` directly. As for type abstractions, there is ongoing work to add them to GHC, but it's more complicated than it seems. The [original proposal](https://github.com/ghc-proposals/ghc-proposals/blob/master/proposals/0050-type-lambda.rst) was accepted, but problems were later found with it leading to a [revised proposal](https://github.com/ghc-proposals/ghc-proposals/pull/238) that is currently being discussed.
Thank you for your answer. You effectively summarised your entire talk in the above paragraphs. I appreciate the fact that senior researchers like yourself will regularly deal with work which cannot always be summarised in an ELI5 answer. I was simply resenting the celebration of incomprehension among the community. For eg: the UML like diagram demonstrating the relationship between various lens data types in the hackage page of lens ([http://hackage.haskell.org/package/lens](http://hackage.haskell.org/package/lens)) is a classic example of an incomprehensible piece of documentation for even an expert programmer, unfamiliar with lens, who peers at the package for the first time. I actually watched one of your talks ([https://www.youtube.com/watch?v=cefnmjtAolY&amp;t=1h49m](https://www.youtube.com/watch?v=cefnmjtAolY&amp;t=1h49m)) where you explained the whole relationship and it is actually understandable and nothing to be intimidated by. But this indicates a dire need of improving our communication method for explaining complex ideas and we sure can take a leaf out of great science communicators like Dan Friedman. If I speak about this particular talk, I was able to follow your talk until you introduced "Natural Domain SMT". You lost me after you say "If I learn my answer is not in some kind of octagon or interval or polyhedra ...". You talk about turning the "octagons inside out" but at this point I am absolutely lost at what is the technique you are trying to use. And everything after that was hard for me to grasp. Even in the detailed answer that you wrote: \&gt; It can avoid termination in a ton of cases where Kanren will go out to lunch. &lt;I am not sure what are those cases and without examples I simply have to take your word for it.&gt; The arithmetic decoder on random bits stuff lets it achieve much lower K-L divergence against the desired set of probabilities you ask it to use than Kanren can achieve due to Kanren's fixed search scheme. We can look at adding universal quantification to cover generation modulo *laws*. I had a hard time parsing a lot of these statements, primarily because I am myself unaware of a number of jargons in these sentences. I don't believe you owe me or anyone an explanation for each of these words and its perhaps the responsibility of the listener to do his own research to find out what you mean. And like you mentioned, this is more a summary talk where you cited atleast 5 existing papers which are perhaps prerequisites to entirely parsing the contents of your talk. But I just hope people appreciate how difficult a job it is that scientific communicators like Dan Friedman and Gerry Sussman successfully do, when they succeed in explaining to us complex ideas like dependent typing using elephants and toys. Of course, the attention span and the format of communication is entirely different between a video and a book. Nonetheless carefully crafted and explicable communication is an extremely complex task and something we as a community should perhaps aspire to practice more.
I don't think there's a question really, I believe this person has just copy-pasted their homework hoping that someone would just do it for them.
I had misplaced my beat up copy of "Functional Programming" by Field and Harrison so ordered another. I found my original and taped it up and took it to work. So glad I lost it for a bit. This is a short ToC. This is a PDF of the full ToC [http://www3.ub.tu-berlin.de/ihv/000141622.pdf](http://www3.ub.tu-berlin.de/ihv/000141622.pdf) The book does not exist in PDF. I bought a used copy on Alibris. It has the owners name on a label on the inside front cover otherwise untouched. I started the short ToC with Part II because Part I is undergrad introductory and less than 1/6 of the 1988 volume. The Hope language is almost Haskell. Graph reduction is Haskell. Maybe later, Chapter 16 might be handy. Part II IMPLEMENTATION Ch 6 Mathematical foundations: lambda calculus Ch 7 Type inference systems i&amp; type checking Ch 8 Intermediate forms Ch 9 Interpretation techniques Ch 10 Stack-based implementations Ch 11 An introduction to graph reduction Ch 12 Combinator reduction Ch 13 Advanced combinator implementations Ch 14 Dataflow implementations Ch 15 Compiling functional languages Ch 16 Garbage collection Part III OPTIMIZATION Ch 17 Program transformation (operationa) Ch 18 Algebraic Program Transformation Ch 19 Memoization Ch 20 Abstract interpretation Appendix A Hope language summary Appendix B Basic domain theory Appendix C Formal semantics [denotational]
Tie fighter? It's obviously a Tie interceptor.
If you can't Stick around the mailing list is also worth a try. But as with any project I guess there is a chance that a question just falls through the cracks.
[www.kattis.com](https://www.kattis.com) has programming problems that can be solved with Haskell
It looks like there's quite a bit of information there! I'm not super concerned about performance here, and that's part of the reason I'm going to treat the produced Java code as though it were a sort of assembly; I'm not directly translating the Haskell to Java, I'm using Java to host my RTS. The parts I'm most concerned about are - Desugaring pattern matches, although I just found [this](https://www.microsoft.com/en-us/research/uploads/prod/1987/01/slpj-book-1987-r90.pdf) paper (chapter 5 in particular) today, and this seems to be the algorithm that GHC uses - Properly organizing the main compiler pipeline - Actually producing code - Designing everything in such a way that interested readers can extend what's there without having to redesign the whole system To be completely honest, I think there's too many decisions here to expect to make the right ones on my own. GHC made mostly the right decisions, but still had to do some gigantic refactors when certain features were added, and there was a lot more than 1 person working on GHC. I'm putting out a new page as a rewrite (with appropriate changes to details) of Chapter 8, in a few minutes (source to follow later, which is a pattern I think I will continue with). It details the things I want to implement there.
I didn't come up with the name :-P
`ghc-pkg list`
I can appreciate that jargon is problematic. I do firmly believe that if you use it you need to be willing to expand what it means, or you're just either throwing up a smokescreen or creating an artificial divide between "us" and "them". The talk suffered a bit from the fact that I'd thought I had an hour slot and planned content accordingly, then found I had half an hour to fit the content in. A lot of my explanatory text got cut in exchange for a whirlwind tour. To unpack "natural domain SMT", which is admittedly a bit of a rarified term even in SMT circles: Kanren suffers from the fact that it doesn't get to "learn from its mistakes". In a modern SAT solver we use a few techniques, one of which is unit propagation, and another is called conflict directed clause learning (CDCL). A SAT solver is typically set up to work with a term in conjunctive normal form. That is to say, it is a list of clauses that all must be true, (the outer conjunction) made up of disjunctions of literals (positively or negatively asserted variables) e.g. (x \/ ~y \/ z) /\ (~z) /\ (w \/ y \/ ~x) Unit propagation is that when you have a clause that has a single literal in it you know what its assignment should be, as there is no other way to make a clause that must be true be true. Once you run out of things to unit propagate, you guess and hope this triggers more unit propagation. When you hit an empty clause there is no way to make that clause true, so you've made a mistake in your guessing. Now you know something, you know that your series of guesses that led you to this point which were of the form `x /\ ~y /\ z` or whatever is now definitely _not_ true. `~ (x /\ ~y /\ z)`, so you can use De Morgan's law to push the not through the conjunct of assertions you've made, and construct a new disjunction, a new clause, that could be added to the original program. This is "Conflict Directed Clause Learning" and was part of what made SAT solvers fast 30 years ago. (Two watched literal schemes is the other part, and comes up later in the longer workshop I was able to give at Monadic Party when I generalize it to work on other propagator types.) Normally, when you switch to SMT solving, you do something where you have a SAT solver for your workhorse, with its guessing and unit propagation machinery intact. And on top of it you layer some additional theory. Let's consider just inequalities. e.g. you might now wind up with the statement X which stands for n &gt;= 3. or the statement Y which stands for n &gt;= 0. For most SMT (SAT modulo theories) what we do is lead the CDCL machinery from our SAT solver alone. Then we get a bunch of assertions of inclusion of inversion of those statements in our model. e.g. X is true, but Y is false. which is a valid SAT assignment. But it ignores the fact that X and Y aren't independent here. They stand for a pair of statements `(n &gt;= 3) /\ not (n &gt;= 0)`, which are contradictory because of extra information imparted by the theory of inequalities, not because of the SAT machinery we're using to orchestrate it all. This is a rather inefficient state of affairs. What I'm interested in are domains in which I can run CDCL directly, rather than running it just on the SAT parts. Consider, a world in which I can efficiently compute with constraints involving a +/- x +/- y &lt;= c, e.g. `x - y &lt;= c`, or `y - z &lt;= d`, or `x + y &lt;= e`. These inequalities compose. `x - y &lt;= c` can be added to `y - z &lt;= d` to get `x - z &lt;= c + d`, so Bellman-Ford can be used to push the cost of these "paths" through the model. A negative cycle `x - x &lt; 0` is a contradiction and blows up the universe. Now, it is possible to gather a bunch of these 45 degree cuts, and to rule out whether or not there exists any points inside of the delimited regions efficiently in O(n^4) time using a slightly modified Bellman-Ford algorithm. At the moment you realize there are no points inside the space that satisfy your constraints, we want to do the same De Morgan step we did earlier. We know `~ (bunch of constraints)` is true. So I need to turn the delimited region of choices inside out. Now the area outside of a polyhedra isn't a polyhedra itself, but I can carve it up into finitely many such polyhedra. This is the idea of natural domain SMT solving. Now, the octagons I mentioned are one of several abstract domains I'm interested in working in. Actual polyhedra (with more than just 45 degree cuts) is another example, presburger bounds, etc. Each of these admits a notion of CDCL where the conflict is resolved _in_ the theory, rather than in the SAT layer that is puppeting the theory. If I wasn't clear during the talk, I do very much appreciate the hard work that Dan and Gerry put in and that they have a skillset that I've not spent anywhere near the time they have polishing. We all owe them an incredible debt of gratitude.
Would anyone please care to elaborate on how the S combinator is "the same" or "equivalent" to **ap** aka **&lt;\*&gt;**? I've heard it in a few places, but I just can't wrap my head around it. If s is defined as: s f g x = f x (g x) how can that be used to simulate **ap** / **&lt;\*&gt;**? Cheers :)
Fira Code ligatures don't mesh well with Spacemacs. Somebody did make another font for the ligatures and it works great!. [Link to the font](https://github.com/tonsky/FiraCode/files/412440/FiraCode-Regular-Symbol.zip)
Specifically, it's `(&lt;*&gt;)` interpreted in the Reader applicative. So you have `(&lt;*&gt;) :: f (a -&gt; b) -&gt; f a -&gt; f b`, then, if you take `f ~ (r -&gt;)` (which is what Reader means), `(&lt;*&gt;) :: (r -&gt; a -&gt; b) -&gt; (r -&gt; a) -&gt; r -&gt; b`. Perhaps an easier way to read it would be an alpha-renamed (and thus equivalent) version of `s`: `s rtoatob rtoa r = b where b = rtoatob (rtoa r) r`
Ah‚Ä¶ that makes sense. If he‚Äôs reading this, good luck! I am a bit sad though that he can‚Äôt work on his writings any more. *What I Wish I Knew When Learning Haskell* is one of the best resources available on modern Haskell, and his other writings are similarly excellent.
&gt;Reflex is the FPR engine that powers Reflex-DOM which can run in GHCJS, or even on the backend to prerender web pages on the server. But Reflex itself is just a Hackage package that you can use for anything if you wire it up. I don't know of any existing bindings between Reflex and GTK. Wiring up the set of things you need should not be too hard, though. The idea is that you'd connect certain Events to plain IO callbacks that would call GTK APIs. This is what I surmised, but I couldn‚Äôt find the right parts of Reflex to accomplish this. Remember, almost every single Reflex tutorial uses `reflex-dom` and its associated integration with the outside world, so there‚Äôs almost no info on using Reflex by itself. &gt;Here's an example of a terminal UI library based on Reflex: [https://gitlab.com/obsidian.systems/reflex-vty](https://gitlab.com/obsidian.systems/reflex-vty) This gives 404 Not Found for me. &gt;I would be remiss if I didn't at least warn you that venturing into FRP takes some getting used to. Expect your project to take a long break from features during the transition. I‚Äôm aware of this already. But I‚Äôm on Uni holidays at the moment, and I can‚Äôt think of any pressing features I need to add at the moment, so this won‚Äôt impact me particularly badly.
What kind of timeline do you expect this will take?
If you hop onto #reflex-frp freenode IRC channel I think you'll find help to get you started. I'm sorry about the 404. Ping me at eacameron on that channel so I can see about getting you access. I personally haven't done much with Reflex on its own but others have and they will be able to help more than I. Re: holiday: great, I just don't like recommending things without fair warning :)
Try it! I think the encouragement I've received from this sub before is a big part of why I decided to give this a shot instead of keeping this as another personal side project. And like you say, the more perspectives, the better! &amp;#x200B; One thing I know I'd be really interested in is a work that goes through the details of \*designing\* such a language. My previous language implementation project was a Scheme, which is also already a well thought-out and fully designed language. I think it would be pretty cool to see the process of choosing ideas for language features, especially while considering how difficult the ideas would be to implement.
&gt; "Functional Programming" by Field and Harrison &gt; The book does not exist in PDF I read that book a while ago and enjoyed it. Do recommend. Here is a .djvu version of that very book: https://filehorst.de/d/cumDgHdJ If for some reason you need pdf I can convert it to pdf.
The long kind. The Scheme project referred to in the post took the better part of 4 months, and there was a much stronger starting point for that project. This project is a learning experience for me. &amp;#x200B; I'll be fairly happy if this is completed by the end of this school year, but I don't expect that to happen. This coming semester in particular may be difficult to work on this, as I'm taking a Compilers course at University which is supposedly very demanding.
It's a classic. I thought a PDF for the OP as I happily have two hard cover copies but thank you.
It can't! ...because it works the other way around. `&lt;*&gt;` is a *generalization* of the S combinator, and you recover S by specializing `&lt;*&gt;` at the type `t -&gt;` like this: ``` s :: (t -&gt; a -&gt; b) -&gt; (t -&gt; a) -&gt; t -&gt; b s = (&lt;*&gt;) ```
&gt; It's a classic. Absolutely. This is the book I recommend to everyone who is interested in FP.
Unfortunately I can‚Äôt do this since I‚Äôm not on IRC, but thanks for the offer! Luckily though, I‚Äôve managed to find some relevant info in the Reflex documentation. I haven‚Äôt figured it out completely yet but given enough time I think I‚Äôll manage it.
&gt; One thing I know I'd be really interested in is a work that goes through the details of *designing* such a language. That's an interesting point, and goodness knows I have a strong opinion on it. If you're interested in that side of languages, I'd recommend Pierce's "Types and Programming Languages" and then Harper's "Practical Foundations for Programming Languages" to get comfortable with what is required for "good design".
Very nice! &amp;#x200B; Question: how was this made? I‚Äôm already aware of [`reanimate`](https://github.com/Lemmih/reanimate), which was designed for this style ‚Äî did you use that library, or something else?
Yes, I used 'reanimate'. The source code for the animation is here: [https://github.com/Lemmih/reanimate/blob/master/examples/fourier\_draw.hs](https://github.com/Lemmih/reanimate/blob/master/examples/fourier_draw.hs)
These are Lissajous‚Äô, aren‚Äôt they?
No, I don‚Äôt believe so. Lissajous curves are parametric curves where each axis corresponds to simple harmonic motion (refer to [the Wikipedia article](https://en.wikipedia.org/wiki/Lissajous_curve) for details), whereas these are nested epicycles as described in the [relevant 3blue1brown video](https://www.youtube.com/watch?v=r6sGWTCMz2k).
Thanks and a brilliant elucidation too!
The compilers course could be more helpful towards this? I think professors would definitely be interested in projects like these.
Why, thank you! I only meant to provide an outline, so this is high praise!
Since it's from 1987 it differs at least in the code generation phase: AFAIR the book is all about targeting the G-machine whereas GHC targets the STG-machine since the 90ies. But that's only a minor difference and doesn't remove any educational value from trying to implement it.
Does it work on Windows?
So I'm adding a one sentence summary like you suggested here: https://github.com/dhall-lang/dhall-haskell/pull/1079 ... but I'm skipping the 5-to-10 sentence summary since I believe the live coding example already fills that gap well. I know you don't like it, but I'm still convinced that the live demo adds a lot of value by greatly reducing the barrier for new users to try the language. However, for users that prefer textual explanations I also have the one-sentence summary link to this longer-form explanation: https://github.com/dhall-lang/dhall-lang/wiki/Programmable-configuration-files
It probably will help but i dont expect the professor will be too interested. For one the course isnt in Haskell, and as i understand the prof. us a formal methods researcher but not a compiler implementor/maintainer.
[Data.SBV.Control](http://hackage.haskell.org/package/sbv-8.3/docs/Data-SBV-Control.html) provides a means for interfacing with the solver directly, including getting the CheckSatResult - this might be what you're after? The Query monad is very powerful and useful in general.
In addition to Matt this can be tested in ghci with [`@`](https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/glasgow_exts.html#visible-type-application) (*visible type applications*) &gt;&gt; :t (&lt;*&gt;) (&lt;*&gt;) :: Applicative f =&gt; f (a -&gt; b) -&gt; f a -&gt; f b &gt;&gt; &gt;&gt; :set -XTypeApplications &gt;&gt; :t (&lt;*&gt;) @((-&gt;) _) (&lt;*&gt;) @((-&gt;) _) :: (_ -&gt; a -&gt; b) -&gt; (_ -&gt; a) -&gt; (_ -&gt; b) `(-&gt;) _` can be thought of (but not written) as a left-section `(_ -&gt;)`, a function *from* `_`.
Most of our team is from the Canary islands, so it can be applied too üòú
&gt; This seems unrealistic. It's simply too big of a backwards-incompatible change. Honestly one thing I quite like about this proposal is it seems fairly practical to work towards. The main big thing you have to do is make your classes have only a single member. From there it is a gradual process, you can first export a few convenience functions for manipulating this underlying data type, and users can slowly move from using various deriving extensions to using these functions. Changing `base` or similar will of course be hard but we can wait for a while to talk about that, until after the community has hopefully embraced single member typeclasses. &gt; I doubt this will the final form of the extensible records work, as it seems too disruptive. I believe (wrongly?) that traditional records will remain their own thing instead of being reimplemented in terms of extensible ones. I was really hoping that traditional records would end up being syntax sugar for a newtype over an extensible record plus some function declarations and special record syntax hooks. Then long term non-GADT use of `data` could be deprecated and eventually removed.
&gt; I can't recall any example of a programming language that has become simpler over time. Yeah I largely agree and that makes me sad, and doesn't mean we should give up on any attempts to consolidate and unify features and in the process simplify the language. I wish better approaches to backwards compatibility existed for various languages including Haskell, and simplifying a language without having to worry as much about that could be a standard and expected thing for languages to do. It's particularly hard with dynamic languages but not completely impossible, and it's very possible with languages like Haskell with strong static knowledge and guarantees. &gt; Even in the tremendously unlikely case that the new way of defining instances proved so useful that some kind of consensus were achieved in removing the old way, the actual point in time of such complete removal would be so far in the future that Haskell would actually become more complex for years and years. How would it be more complex? The only new feature request in the proposal is some very minor syntax sugar. I understand that actually simplifying the language by pulling out those extensions is pretty far away though.
Just tried this. Looks like the Query monad doesn't play nicely with quantifiers, otherwise it would be perfect for what I'm doing. Thanks!
I believe that I was able to use it with existential quantifiers without any hassle. Can't quite remember how, though. It might have been a case of first constructing and constraining the system, *then* going into the Query monad and using the nitty-gritty stuff.
Hmm, that might work. I've also found the `IsNonModelVar` option, which I've set to `const True`. I'm just compiling to see if it helps...
Wishing you the best of luck!! &amp;#x200B; 1. HLint - has and continues to teach me as much about Haskell as pretty well any other source 2. My recent / late discovery of ghcid has been a massive OMG moment and hugely improved my workflow 3. As a non-vim-nija using VSCode on Windoz I rely on hie and I'm really excited about the the progress being made by the hie contributers 4. I suspect hie files will be huge boost for hie If you can reach agreement on a path forward the stars will really be aligning for big strides in Haskell tooling !!
[haskell.org](https://haskell.org) appears to be dow for me as well with '503 backend is unhealthy' err :/
Ive been trying to get at the Alex docs and am having the same problem. I dont know about Happy, but i was able to figure out Alex by looking at the examples on its repository.
Works for me - it may have been down for maintenance/some other issue. Always remember to check https://status.haskell.org/!
&gt; I was really hoping that traditional records would end up being syntax sugar for a newtype over an extensible record It was mentioned today in the slack channel that replacing the impl of traditional records wasn't an immediate goal, but could be considered in the future.
Silly haskellers
I suppose i should actually follow this up with a real table: - `&gt;&gt;= ` - bind - `=&lt;&lt;` - bind (the one that composes properly) - `&lt;$&gt;` - fmap - `&lt;*&gt;` - ap - `.` - compose - `^.` - get - `.~` - set - `&gt;&gt;&gt;` - and then (arrow) - `%~` - modify - `$` - apply - `&amp;` - and then - `&gt;=&gt;` - bind (kleisli) - `::` - of type (or has type) - `-&gt;` - function arrow - `=&gt;` - I don't really pronounce this. Sometimes, I say "constrains" - `&gt;&gt;` - and then/const - `*&gt;` - and then/const - `$&gt;` - and then/const - `&lt;&gt;` - op or mappend - `#` - review etc
A lot of stuff is still coming back up. Hopefully they'll be finished with the storage recovery by end of day, but its been a long process.
Makes sense. There is a slack for discussing/implememting extensible rows/records/variants?
No, it was in the #haskell channcel of [functionalprogramming.slack.com](https://functionalprogramming.slack.com).
Interesting update: I've determined that the source of all the `tokenize` calls is not, in fact, parsing the model that's returned, but the internal sanity check that SBV does to make sure all it's parens are balanced. I've opened an issue for this, since as far as I can see there's no way to turn it off. I'll try to make my trees more shallow, but I think I might be out of luck in this case.
Is it actually having a measurable impact on the time that your program takes to run? Are you calling Z3 like, thousands of times? O_o
No, but I'm calling Z3 with a single query that ends up being about 10000 lines long. The problem is, SBV is doing a Tseitin transform that is generating a *ton* of intermediate variables, and it's storing the SExpr as a string internally, instead of using Text or something more efficient. So tokenizing that string to count its parens is taking forever.
Ah, right! Well best of luck with finding another way :) As a stop-gap there is also the `z3` library which has a fairly reasonable API. I prefer `sbv` personally but it might be able to do what you need!
Yeah, that's what I'll try next if I don't have any luck. Thanks!
You can find some people who can provide Haskell mentorship on this list: * https://github.com/willbasky/Awesome-list-of-Haskell-mentors
Everything should be back now, fwiw.
I haven't tried it yet but it looks like there's Haskell bindings for graphviz https://hackage.haskell.org/package/graphviz I've used graphviz for graph visualization in docs a few times and it was pretty simple to use with other languages scraping data to generate files in the dot structure it supports.
There's Martin Erwig's Functional Graph Library (fgl), which is pretty mature and comes with implementations of multiple state of the art graph algorithms. Nevertheless, for your use case you would probably want to persist and query your graph in some kind of graph database like Neo4J and just build the business logic in your application.
Is this a proof of concept? Or an actual project for work it would be cool to see the completed system!
I would say both. This is just a fraction of a bigger project, although an important part.
Are you able to share more about the project? It sounds like the goal is to automate an entire office building which would be a much bigger scale than anything I have heard of
Not to tell you how to live your life but my philosophy is - if someone hasn‚Äôt done it yet, don‚Äôt look for libraries that are ‚Äúclose enough‚Äù. I think you should stick with your custom library and just write a thin layer to export JSON to some D3.js or three.js front end if you want static exports. If you want something more dynamic, maybe think about GRPC as a socket level interface?
It's going that way. A kind of smart assistant for the building. One example is you could say: "going home now" and it would tell me that my bus is coming in 5 minutes to the nearby station. But this is just one small example.
About the `=&gt;` token. In the clean programming language (this is how I've learned FP), they notate it like this: `foo :: a -&gt; a -&gt; Bool | Eq a` instead of `foo :: Eq a =&gt; a -&gt; a -&gt; Bool` So I've been thinking of it as: "`foo` is of type `a` to `a` to `Bool`, given `Eq a`." But this pronunciation doesn't work well in the Haskell order of things.
You can write this thing today, you just can't use it with much. It works like a crippled `Traversal`. Way back in the day folks used to use classes like class Functor t =&gt; FunctorM t where mapM :: Monad m =&gt; (a -&gt; m b) -&gt; t a -&gt; m (t b) at least before `Applicative` was discovered, and the "Essence of the Iterator Pattern" was written showing that all that was needed for this abstraction was `Applicative` . and the `Monad` was just historical baggage. The `Traversal` laws (which should be satisfied by anything stronger like this) are sadly enough to rule out any use of the extra power of the `Monad` here. e.g. you can't _use_ the power of `join` to achieve any outwardly observable result about making different decisions as you go based on the values you've seen so far. This is the "fundamental" bit you're missing. There is one caveat to this. You can sometimes use it to get O(1) stack depth in situations where you must lose a log stack depth when working with something that is merely `Applicative`. Consider traversing a list using a `&gt;&gt;=` and accumulating a result in reverse in an accumulating parameter before finally reversing and emitting it in one go at the end. You get worse "online" behavior in that this traversal of the list not lazy, and when traversing with something like `Identity` this would not be productive when fed an infinite list, but it can shift some of the content from the stack to the heap for finite lists. This is really the only benefit I've found for this structure. Unfortunately, to achieve that one dubious benefit, everything else gets worse. You have a `Traversal`, but you can't cleanly use any of the existing tools for walking it. To `get` you have to use `Writer a` rather than `Const a`, because you can't walk with an `Applicative`. This means you're going to spend a ton of time manipulating extra useless structure you don't need whenever you try to read from the structure. The result won't cooperate with almost any of the other combinators for working with optics, because it is incompatible with the tricks we use in there to fuse together multiple passes, which are often based on `Compose`, and monads don't compose in g eneral. At the same time the laws keep you from using any of the extra "power" you think you'd gain from `Monad`. The ultimate problem here is that Monads don't `Compose` in general, and that shows itself in this sort of weird self-crippling behavior.
If you do want to traverse all finite points in finite time, you can do it by reordering your traversal: Œª take 10 [(1+a,1+b,1+n-a-b) | n &lt;- [0..], a &lt;- [0..n], b &lt;- [0..n-a] ] [(1,1,1),(1,1,2),(1,2,1),(2,1,1),(1,1,3),(1,2,2),(1,3,1),(2,1,2),(2,2,1),(3,1,1)]
I've always wondered about the concept of purity, as described in this page. They cite the second example of the greet function as being impure, due to it using a value outside of its own scope. Lots of functions rely on functions outside their own scope, and are still considered pure? If a function is referentially transparent, and can be replaced by its value, then why would it be any less pure to have a value? Is it only pure if it uses global static constants or standard functions? Where's the line?
Well, Homotopy/Cubical/Cartesian Cubical/Computational Cartesian Cubical type theory is definitely an important thing right now. Homotopy type theory about treating equality proofs as paths, which leads to the Univalence axiom stating that equivalent structures are identical, and higher inductive types, which make additional paths arise. The other theories try to give this axiom a computational interpretation, such that it actually evaluates to a thing. All of this allows for easier definitions of quotients, for example.
Do you know any begginer book like Little Typer to learn it?
Well, there is an official and freely available book just called the HoTT book. It gives a quite decent introduction, but take your time. Some concepts aren't that simple to understand, yet important or interesting.
Thank you for your prompt and thorough reply, this is exactly what I was looking for (and then some)!
You can get the book freely at https://homotopytypetheory.org/book/.
It's probably just a server (Apache, evidently) misconfiguration than a deliberate joke. Of course, [Red Bean itself is a joke](https://www.red-bean.com/about.html), but that is a deliberate joke. :) I had emailed John Goerzen about this on Monday. John forwarded my message to Bryan, who maintains the website. Clearly Bryan is busy with other things. :)
\`print\` in rust operates a global \`Mutex\` and preforms IO. Both of these break memoization, hence it's impure.
The `Functor` constraint for `Lens` and `Applicative` for `Traversal` are slightly adjacent to the point of what those optics are doing, and it causes some slight confusion. Each optic (see: [here](https://gist.github.com/emilypi/407838d9c321d5b21ebc1828ad2bedcb#file-optics-hs-L45)) corresponds with a monoidal action, be it the action of a (co)cartesian product, exponentiation and so on class Profunctor p where dimap :: (s -&gt; a) -&gt; (b -&gt; t) -&gt; p a b -&gt; p s t class Profunctor p =&gt; Choice p where left :: p a b -&gt; p (Either a c) (Either b c) right :: p a b -&gt; p (Either c a) (Either c b) class Profunctor p =&gt; Strong p where first :: p a b -&gt; p (a, c) (b, c) second :: p a b -&gt; p (c, a) (c, b) class Profunctor p =&gt; Closed p where closed :: p a b -&gt; p (c -&gt; a) (c -&gt; b) -- imagine [a] was actually a sized list class Profunctor p =&gt; Traversing p where stretchl :: p a b -&gt; p ([a], c) ([b], c) stretchr :: p a b -&gt; p (c, [a]) (d, [b]) class (Strong p, Closed p) =&gt; Glassed p where glassed :: p a b -&gt; p (t, u -&gt; a) (v, w -&gt; b) class (Choice p, Strong p, Closed p) =&gt; Windowed p where windowed :: p a b -&gt; p (Either a (t, u -&gt; a)) (Either b (v, w -&gt; b)) type Optic p s t a b = p a b -&gt; p s t type Iso s t a b = forall p. Profunctor p =&gt; Optic p s t a b type Lens s t a b = forall p. Strong p =&gt; Optic p s t a b type Prism s t a b = forall p. Choice p =&gt; Optic p s t a b type Grate s t a b = forall p. Closed p =&gt; Optic p s t a b type Glass s t a b = forall p. Glassed p =&gt; Optic p s t a b type Window s t a b = forall p. Windowed p =&gt; Optic p s t a b type Traversal s t a b = forall p. Traversing p =&gt; Optic p s t a b Lenses specifically are the action of a cartesian product, Traversals the monoidal action of a polynomial functor. This fact is hidden in the definitions you give. Every functor in Hask is canonically strong (but not costrong!), so it receives the cartesian action naturally. The `Applicative` constraint simulates the polynomial action of a `Traverseable` (i.e. polynomial-like) functor. A monad defines a stronger action associated with composition, but like /u/edwardkmett said, it would just be a slightly-too-strong-and-not-all-that-useful version of `Traversal`.
It's using format! though, so just producing a string?
What you're running into is the concept of closures. I'm Haskell, any reference to a function also includes a reference to its closure and the values that are defined in it. This still counts as "pure" because it's not something you can figure out by calling the function. At long as the function produces the same output given the same input, it doesn't matter how it's defined. In fact, that's the great part about referential transparency. I don't have to care how you've implemented a pure function, and you are free to change it on a whim, as long as you don't break the transparency. What's different about the given example is that it *isn't* Haskell. That variable being used is really an "assignable": an entry point to mutable state. Any part of the program can change the stored value, breaking the transparency of the function that uses it. Now I have to care about how you've implemented your function. Sucks to be me. :)
[Quantitative type theory](https://bentnib.org/quantitative-type-theory.pdf) lets you annotate your usages with zero/one/many, which gives you nice framework large enough to talk about things like linearity and irrelevance.
Thanks, that makes a lot of sense :)
Thanks for asking this; I‚Äôve been wondering the same thing.
Your submission was automatically removed because you linked to the mobile version of a website. Please submit a non-mobile link instead. *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/haskell) if you have any questions or concerns.*
Your submission was automatically removed because you linked to the mobile version of a website. Please submit a non-mobile link instead. *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/haskell) if you have any questions or concerns.*
Thanks for your reply -- seeing the type classes laid out next to the type aliases helped solidify things for me. Time to read some more about Profuctors!
Specifically it also translates very nicely to dependent type theory, as one can easily assert that the parameters are non-linear.
Specifically it's a very nice combination of linear and dependent typing. Usage in types count as 0 uses, so one can still talk about the state of things which have been consumed, to do things like prove correctness of a mutating sort that otherwise consumes its input.
I'm not too familiar with rust but isn't `name ` in that example a compile time constant? Short of flipping bits in the binary how would anyone change it's value?
Yup, you can [decouple irrelevance from type quantification, too](https://twitter.com/edwinbrady/statuses/1088811837376876545).
You are correct. `let name = "hello";` introduces a constant. You must write `let mut name = value;` to introduce a mutable variable.
Has Quantitative HoTT been explored yet?
define beginner
has there been concrete application in programs due to these type theories ? static analysis ? compiler strategies ? complete program design ?
not really so far. There have been some experiments with databases, but that's it mostly. HoTT is mostly about formalizing mathematics like set theory is, so its purpose is a bit different.
yeah but it could lead to different semantic soil to rethink interpretation, structures etc (just like parametric types did)
definitely. I really enjoy writing proofs within it.
I'd like to put in a word for Stephen Dolan's [Algebraic Subtyping](https://www.cl.cam.ac.uk/~sd601/thesis.pdf) from 2016, basically Hindley-Milner elegantly extended with subtyping. This sort of thing had been attempted before, but Dolan's system has decidable inference.
Oh, huh that's an interesting one. I like the twitter conversation there. Idris already contradicts univalence, but a consequence of an appropriate non-parametric function \`forall a, a -&gt; a\` + univalence is classical logic for propositions (i.e. types with at most one element have either 0 or 1 elements).
Wait, but why? Why not just an ADT for the expression? Then it'd be simple enough to prove that your renderer conserves parents and skip the sanity check? That said, I know the author of SBV is quite responsive to feedback, so starting an issue would be a good bet.
Exponentiation is not performed by composition but simple application of one number encoding to another.
Looks like the first chapter doesn't require abstract algebra, but I notice the second chapter launches into groupoids pretty quickly. Might need some basic abstract algebra. I've been working through [An Invitation To Applied Category Theory](https://arxiv.org/pdf/1803.05316.pdf) which has been GREAT for someone like myself who's been away from math for awhile. It might be a good way to ramp up to homotopy theory.
What was your major in if I may ? math ? or another scientific field ?
Cool, til. I don't know Rust, I just assumed the author knew what they were talking about. :)
The issue here is that each executable is seeing *each other* as a library module and complaining i.e. when GHC goes to compile ex-01, it *also* compiles the Ex02 file as a library module, since it's in the source directory of ex-01. At this point GHC errors out, because the name of the file (Ex02) doesn't match the library module name (Main). Vice versa when it tries to compile ex-02. Of course, you probably don't want your executable files to be able to import from each other at all, so what I usually do is to modify the directory structure so that the executables are no longer in each others source directories. If you create an empty directory inside `app`: ``` . &lt;your-project&gt; ‚îú‚îÄ package.yaml ‚îî‚îÄ app/ ‚îú‚îÄ Ex01.hs ‚îú‚îÄ Ex02.hs ‚îî‚îÄ null/ # an empty directory ``` And then modify the executable entries in the `package.yaml` like so: ``` executables: ex-01: main: ../Ex01.hs source-dirs: app/null ... ex-02: main: ../Ex02.hs source-dirs: app/null ... ``` Then the executables should no longer be trying to include each other as library modules and everything should compile fine.
CS major, math minor, but barely touched on any of this stuff at school
This looks absolutely terrible. Why not just have a separate directory for each executable? Much cleaner, and reflects the intention perfectly. . &lt;your-project&gt; |-- package.yaml |-- ex-01 | |-- Main.hs |-- ex-02 |-- Main.hs And then: executables: ex-01: main: Main.hs source-dirs: ex-01 ex-02: main: Main.hs source-dirs: ex-02 No need for those ugly dummy directories, no need for putting the `Main` module outside the declared `source-dirs`, plus you get to put the `Main` module in a file named `Main.hs`, i.e., match filename to module name just like with every other module out there.
interesting, as a softeng/cs trying to deeper in math I'm even more interested by your opinion :)
my regret is taking too much calculus that I've never used instead of stat and higher algebra like we're discussing here, but I guess it depends what you want to do when you graduate.
I agree, it's definitely a hack. But the short answer is that I prefer having all the executables in same directory, and to give the files useful names. It just makes maintenance easier when I don't have to browse into different subdirectories to make lots of similar changes, when I don't have to switch between 4 different buffers named `Main.hs&lt;something&gt;`, it's easier to do things like mass renamings etc. etc. Ymmv.
Your right I was not looking at the right thing.
I like this approach, thanks
did not knew they will try to import each other
Is your middle name Erd√∂s ? and how much speed do we need to provide ? :)
What's the best way to represent a datatype for integers between 0-600 inclusive?
No speed necessary, but morning caffeine would be appreciated!
You don't have to name the main module Main. Just give it the name of the file it's in, eg -- Ex1.hs module Ex1 where main = -- ... It's okay to put them in the same directory, you don't have to do anything special in your `package.yaml`, just executables: ex1: main: Ex1.hs source-dirs: app ex2: main: Ex2.hs source-dirs: app
&gt; class (Strong p, Closed p) =&gt; Glassed p where &gt; glassed :: p a b -&gt; p (t * a^u) (v * b^w) &gt; &gt; class (Choice p, Strong p, Closed p) =&gt; Windowed p where &gt; windowed :: p a b -&gt; p (a + (t * a^u)) (b + (v, b^w)) Are these two right? The other typeclasses turn a `p a b` into a `p something(c, a) something(c, b)`, and it makes sense that we're using the `p a b` to transform the `a` part of `something(c, a)` into a `b`, and that we're leaving the `c` part alone since we don't know how to transform it. But the above two are much stronger, they claim to turn a `p a b` into a `p something(u, t, a) something(w, v, b)`. How do we know how to transform the `u` into a `w` and the `t` into a `v`?
You can‚Äôt plan a world trip without visiting Australia.
A book? I doubt it. The HoTT book was quite heavy for me. The most approachable presentation I've seen is [Cubical Adventures](https://www.youtube.com/watch?v=W5-ulP_JzNc).
I prefer to shape the tools after the things I want to build, not the other way around. Messy scripts to automate working on a solidly laid-out codebase is much nicer than using top-notch tools on a hacky ball of mud.
You can get the best of both worlds by giving your executable modules a lowercase name: . &lt;your-project&gt; ‚îú‚îÄ package.yaml ‚îî‚îÄ app/ ‚îú‚îÄ ex01.hs ‚îî‚îÄ ex02.hs and then executables: ex-01: main: ex01.hs source-dirs: app ex-02: main: ex02.hs source-dirs: app Don't include the `module ... where` line, only the `main = putStrLn "hello world"` part. Since an importable module name must begin with an uppercase letter, neither executable will think the other file is a module.
Do you plan on coming to Los Angeles, CA? I‚Äôd like to invite you to the local Haskell meetup that I go to.
My choice of notation is poor here, sorry - I went for "extra generalization", but in the end they're existential so I should just call them all `c`. `Glass` and `Window` came out of our studies over the past few months deriving a general form for most optics. I still need to check the laws that `Window` holds, but `Glass` is a new one we finished [deriving](https://imgur.com/a/TZ8A32I). The best I've come up with to describe their semantic is that glass acts as a kind of logarithmic relationship (taking its values in representable endofunctors of Set), and `Window` acts as a kind of floating logarithm.
^(Hi, I'm a bot for linking direct images of albums with only 1 image) **https://i.imgur.com/RBNevVF.png** ^^[Source](https://github.com/AUTplayed/imguralbumbot) ^^| ^^[Why?](https://github.com/AUTplayed/imguralbumbot/blob/master/README.md) ^^| ^^[Creator](https://np.reddit.com/user/AUTplayed/) ^^| ^^[ignoreme](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=ignoreme&amp;message=ignoreme)
Sandy lived in Denver for a year and I got to know him pretty well. He's an awesome guy and you should take him up on this!
Do you plan on visiting the UK? I'm a bit tin-foil-hat about giving information online, but if you're ever in (or soon to be in) the north-east UK feel free to message me on here any time. I'd be happy to have an extra house guest for a few days. There's not much (read: any) FP activity in my area and I never have money to travel, so it'd be very cool to be able to pick your brain and work on some things together as I've just recently started on the road of learning how to implement type systems. Either way, enjoy your trip! :)
Put your name on the form, and ask some of the other local Haskellers to do so too!
Sounds good :)
Put down your location and email on the form, and I'll get in touch if it works!
Ooh, very nice! Did not know about that, thanks!
There are a bunch of Cedille tutorials on YouTube. And I linked a redprl tutorial last week.
I would make a newtype wrapper around an Int and not export the constructor. Then write a smart constructor and export that. Optionally add a custom Bounded instance
Is it ok if I‚Äôm terrible at Haskell?
I am surprised you're not talking about how your building is modelled, since that is kinda important? I was working with IFC, which is a file format that can represent pretty much everything about a building. Commercial planning tools like Revit and ArchiCad can export to this format. There is an open source project called IfcOpenShell that lets you iterate through the IFC file, filtered by tags. When I wanted a graph representation, I would generate Cypher queries for Neo4j. Then I would use the Neo4j web interface with manually written Cypher queries to learn about what the different tools would export. I'd bake those facts into the product I was building, which used IfcOpenShell. If you don't wanna use closed source software, you should work with the FreeCAD ecosystem. It has a Python programming interface. But I guess you could make Haskell bindings.
&gt; in the end they're existential so I should just call them all `c`. What you had previously was too general, but now this isn't general enough :) `p (c * a^c) (c * b^c)` would needlessly require both the summand and the exponent to have the same type. How about: class (Strong p, Closed p) =&gt; Glassed p where glassed :: p a b -&gt; p (t * a^u) (t * b^u) Now it's clear that `glassed` applies the `p a b` to all the `a`'s inside the `t * a^u`, while leaving both `t` and `u` (both of which can be arbitrary) alone. Is there supposed to be a difference in power between `(Closed p, Strong p)` and `Glassed p`? With my proposed formulation, it's quite easy to implement `glassed` in terms of those two superclasses. class (Strong p, Closed p) =&gt; Glassed p where glassed :: p a b -&gt; p (t, a^u) (t, b^u) glassed = second . closed
Hey I live in LA. Would you mind sending the Meetup link?
Here‚Äôs the link. We‚Äôre meeting up tomorrow! https://www.meetup.com/santa-monica-haskell/
Not really any beginner books right now. The people researching this stuff are still trying to figure out how to explain it to themselves and grad students! That's not to say it's something you can't have a go at learning, but it's just not going to be as easy. Here are some video series that might help though: - https://vimeo.com/channels/1457250 - https://www.youtube.com/playlist?list=PL0DsGHMPLUWXXA8RHzVZ2B5E5hP8CD15Z
Sure is!
`(:[])` robotic monkey `(.).(.)` Martian stripper
&gt;What you had previously was too general, but now this isn't general enough :) Thanks, that's what i get for absent-mindedly reddit'ing from my phone! There is no difference between `Glassed` and `(Closed p, Strong p)`. It's supposed to be the exact same - we intend it to be one of the simplest "intersections" of optics! Not all intersections are valid optics, but some, like `Window`, still satisfy the optics laws.
I'll be in Eugene, Oregon in fall doing PL stuff at U of O. I haven't secured a place yet but as soon as I do (and make sure I HAVE a couch) I'll fill the form.
I read it: "`foo`'s type, given `Eq a`, is `a` to `a` to `Bool`"
Is there anything like this, but for literate Haskell?
Awesome, I‚Äôll fill in the survey.
My suggestion would be that as you extract data, write it to a local instance of a neo4j graph database. Can use this to let haskell do munging in and out [https://neo4j.com/developer/haskell/](https://neo4j.com/developer/haskell/) It will be convenient to explore and query the graph in realtime without bespoke haskell code implementing some subset of cypher query functionality and compilation times. &amp;#x200B; In the end do bespoke things in haskell (eg serving data to a web service or rendering some animation or visualization), but take advantage of the realtime + query language capabilities of neo4j for persisting and interacting with the data.
M√©xico city here. I'll hide my clojure stuff
Hopefully it involves less meth than the original Erdos
This is a nice package! It reminded me of a similar tool for documentation: * https://theam.github.io/tintin/ My current workflow when writing blog posts is to put all code in a separate `gist` after compiling and running and then copy-pasting the results manually to the blog posts. I see that your `pandoc_filter` is a CLI tool. It would be nice if you could integrate it with [`hakyll`](http://hackage.haskell.org/package/hakyll) for smoother experience during blog post development. I've started to see the power of custom preprocessors for `Pandoc` AST. For example, we've implemented [hakyll-shortcut-links](https://github.com/kowainik/hakyll-shortcut-links) package which allows you to write links in your blog post like this: Package [tomland](@hackage) and article [Google](@w) So the links are automatically expanded on-the-fly during blog post writing. Would be really cool to have something like this for evaluating code blocks :)
What's the best way to evaluate a list of `StateT`, if each `StateT` in the list expects that the states preceding it in the list will have been evaluated. I've tried using `mapM`, but it doesn't seem to have the expected behavior.
You shouldn't need them in Haskell, as they should be implied by their parts + parametricity. In "real" category theory, though you may need them for the same sort of reason that a bifunctor isn't just a functor independently in each argument.
Thanks for the feedback. I was not ware of \`tintin\`. I will check it out. \`hakyll\` integration is a nice idea. I have not used \`hakyll\` personally. Gave up one time when I tried it. I will have to give it a go again. I will see if I can add that kind of integration when time permits.
Most intersections should work, you can go all the way down to p a b -&gt; p (f a) (f b) -- for any Functor f, as a model of Setter after all, and that is stronger than all of the intersections.
Not that I am aware of. There definetly could be some variants of it.
That's exactly the conclusion we came to!
Anytime you might like to visit Westchester NY, let me know. We worked together on a Haskell project. It would be my pleasure to host you anytime. - E
Sounds great, thanks for the offer! The only feasible way for me to keep track of everything is for it to be sent in the form, so please do so if you haven't! If not, I'll see you there!
You have to admit the man got a lot done!
Do you write haskell or clojure at work? I haven't met anyone that's interested in haskell in Monterrey -.-
Instead of defining your own type, you can also use the [finite-typelits](https://hackage.haskell.org/package/finite-typelits) package, which already has all the right instances. `Fin 600` is the type you are looking for; note that you will need the `DataKinds` extension to write numbers in types like this.
The company is transitioning into a new building, which does have a BIM. The current rented office doesn't, so, before I get to work with an actual model, I'd like to quickly iterate over the domain logic.
That reminds me, gotta buy the book
I had a different document building workflow I wanted and wrote knit-haskell (http://hackage.haskell.org/package/knit-haskell) as a starting solution. It also uses Pandoc and is meant to be used by writing a Haskell executable that produces the document. I was targeting a data-science blog-post sort of thing. I‚Äôm going to take some inspiration from your work and see if I can provide something like it in knit-haskell: the ability to give a code block and insert the correctly formatted markdown and the result of executing it. Thanks for the idea and the library!
Cedille isn't really related very much to HoTT / CTT. For starters, its equality type is anti-extensional.
[http-client-tls](https://hackage.haskell.org/package/http-client-tls)?
I want to write relay library, but fully on purescript Sadly I don't have spare home
Fantastic idea
The [most recent version of `http-conduit`](https://hackage.haskell.org/package/http-conduit-2.3.7.1/docs/Network-HTTP-Simple.html) has a `Simple` module that I recommend.
You can also simplify the duplicate fields: ``` _exe-defs: &amp;exe-defaults source-dirs: app dependencies: [animation] ghc-options: [-O2, -threaded, etc...] executables: ex1: &lt;&lt;: *exe-defaults main: Ex1.hs ex2: &lt;&lt;: *exe-defaults main: Ex2.hs ```
If you are among the best students in a master programme of a reasonable level, you should be perfectly able to do a PhD. UK, USA and Canada are fine (but be careful that USA/Canada have integrated master/PhD programmes called "graduate school" that will make you loose two extra years doing another master), but what about other countries? There are many places in Europe that have PhD students, and there are also a few interesting places for functional programming and type theory in South America and Asia. (South America: √âric Tanter in Chile, Beta Ziliani in Argentina, etc.). My advice would be to write a good CV (honest, emphasizing the work you have done related to the project area, including personal projects), and consider contacting directly researchers you are interested in. Try to go to the main conferences of the field (ICFP, POPL; look for their "PLMW" workshops which can fund attendance and travel), or at least look at their papers, find works that you are particularly interested in, and consider sending an email to the authors directly to ask for PhD opportunities.
Thank you for the advice. I will send emails for these professors in America Latina too. In UK, my first try will be with Anton Setzer. Because he is doing the same research of my masters. In Brazil, I can get PhD with Hermann of Puc Rio. I prefer English Countries, because I would like to improve my English and after live in an English country.
This is awesome! Please visit India!
And it's the basis of the very recently announced Idris 2! :-)
The `foldGet` function of the "wreq" library has worked well for me.
London here, HMU!
Some may have Hungarian origins here, I see...
Sorry for off topic. &amp;#x200B; Will we see Thining in Types on safarionline or other such subscription based services?
Thanks for this great answer!
Could you tell more about your development setup for making incremental changes and seeing the result? (E.g. what REPL/ghcid commands or other tricks you used to get code auto-reload)
Suit yourself, but note that living abroad in any country whose language you are not familiar with will help you practice your English, and being open to opportunities irrespectively of the language can only increase your chances of getting funded on a project that you find interesting.
`Monad`s become a lot easier to understand when I think of Kleisli categories. Is there anything similar for `Applicative` functors? As in, a way to view them that makes them seem "obvious"?
Nice! I have long searched for a tutorial for something like this, thanks :)
I had an impression that [req](https://github.com/mrkkrp/req) should be preferred instead of `wreq`.
If you have excellent marks and you would like to do a PhD in Australia then please send me a PM.
&gt; Not all intersections are valid optics Interesting, why not? As I'm sure you know, the `lens` library's API is based on the idea that you can combine optics of different types with function composition, e.g. the lens `_1` with the prism `_Just` can be combined into the traversal `_1 . _Just`. In the lens library, this is implemented in a complicated way, sometimes by combining constraints on the `f` in `Optic p f s t a b`, sometimes by concretizing the `p`. With profunctor lenses, this is implemented in a more uniform way, by combining constraints on the `p`. I assumed I could combine any two optics with function composition and get something sensible back, but you are saying that this is not the case? With the lens API, I can imagine two optics which both try to instantiate the `p` to different concrete types, and that would be rejected at compile time. But with the profunctor optics API, that should always work, it will simply add more and more constraints on the `p`, that should always type check. The worse which could happen is that some of those constraints could be conflicting and so there is no concrete type satisfying those constraints which `p` could be instantiated with. &gt; some [...] still satisfy the optics laws Right, so it's not that using function composition to combine two optics won't compile, it's that even if the two optics satisfy the laws, their combination might not. I understand [the laws for lenses](https://www.stackage.org/haddock/lts-13.27/lens-4.17.1/Control-Lens-Combinators.html#t:Lens) (you get back what you put in, putting back what you got doesn't change anything, setting twice is the same as setting once), but I don't have a good intuition for the more abstract [laws for Optic](https://www.stackage.org/haddock/lts-13.27/lens-4.17.1/Control-Lens-Combinators.html#t:Optic). What do those laws look like for profunctor optics? Do you have a simple example in which composing two lawful optics results in a non-lawful optic?
&gt; Windowed should look like this btw: &gt; &gt; class (Choice p, Strong p, Closed p) =&gt; Windowed p where &gt; windowed :: p a b -&gt; p (a + (t * a^u)) (a + (t, b^u)) &gt; windowed = right . second . closed `right`? So that should work with any summand on the left-hand side, not necessarily just with the `a` from `p a b`. Should it perhaps be a bit more general, like this? class (Choice p, Strong p, Closed p) =&gt; Windowed p where windowed :: p a b -&gt; p (v + (t * a^u)) (v + (t, b^u)) windowed = right . second . closed
I too was thinking of doing this over summer, but without any of the follow through associated with putting together a good looking website. &amp;#x200B; If you're working on a project and you need a hand and you have a sofa/garden for me to sleep in, drop me a direct message and we can talk about it. I've got 4 years of experience programming Haskell in industry working all over the place (finance, compilers, academic referencing) and I'm distinctly house trained. Europe is easier for me, but I'm not averse to hopping on a plane.
Ireland has a PhD funding scheme called an IRC, [http://research.ie/funding/goipg/](http://research.ie/funding/goipg/), which might work for you. First you would need to find a faculty member who wants to take you on as a PhD student, then they help you with your application and you list then as your intended supervisor. It is quite competitive, but has rather generous terms, and the application process is pretty straightforward. Evaluation emphasizes letters, so one from Wadler would be a leg up.
I think scholarship availability depends on the University. If you like Haskell and/or Type Theory, I'd strongly encourage you to apply to our [lab in Nottingham](https://www.nottingham.ac.uk/research/groups/fp-lab/). The School of Computer Science advertises several fully-funded PhD positions every year, and I think they should be open to non-UK/EU applicants.
Codewars is interesting, but the site is very slow ... and it loses the code you typed in the browser (with no warning given) when you navigate elsewhere, which is rather strange.
For some reason my type checker was giving me `a`. `v` works fine
You know I will!
It's pretty good. I'd recommend it!
Unlikely. I don't know what that is! What benefits would a subscription-based site have over just buying the thing for $25 --- most of which goes to me? :)
So, my intuition for morphisms is "vaguely function-like things". A kleisli arrow clearly fits this definition: after all `a -&gt; m b` is just a function with some extra "wrapper" around the result. Similarly, `f (a -&gt; b)` is also a function-with-a-wrapper - but this time the entire function is wrapped, not just the result. You can also verify that it fulfills the requirements of a morphism: newtype Static f a b = Static { runStatic :: f (a -&gt; b) } instance Applicative f =&gt; Category (Static f) where id = Static (pure id) Static fbc . Static fab = Static fac where fac = liftA2 (.) fbc fac Note: the definitions of Applicative in terms of pure and &lt;*&gt; or pure and liftA2 are completely equivalent. Another way to look at these classes is that they are monoid objects in the category of Hask-endofunctors equipped with different tensor products. First, some common definitions: newtype Identity a = Identity a deriving Functor newtype Unit a = Unit deriving Functor type f ~&gt; g = forall a. f a -&gt; g a Applicative arises from Day convolution: data Day f g a = forall x y. Day (x -&gt; y -&gt; a) (f x) (g y) class Functor f =&gt; Applicative f where pure :: Identity ~&gt; f liftA2 :: Day f f ~&gt; f Or equivalently from the usual product: class Functor f =&gt; Applicative f where pure :: Unit ~&gt; f liftA2 :: Product f f ~&gt; f Monad arises from composition: class Functor f =&gt; Monad f where pure :: Id ~&gt; f join :: Compose f f ~&gt; f
Oof, just inquired about FP PhDs where I live (Netherlands), but it's apparently really difficult to get funding for this subject. Your location flexibility should definitely be an advantage though.
Wouldn't this make it possible to overload a class definition for an existing instance in a local binding? That sounds like the sort of thing that should stay impossible.
Easy
i did something similar for my gf's art gallery https://github.com/goolord/skyespace/blob/master/src/Main.hs#L62 https://github.com/goolord/skyespace/blob/master/templates/gallery.html https://github.com/goolord/skyespace/blob/master/templates/art-gallery.html https://github.com/goolord/skyespace/blob/master/css/main.css#L118
The README for `req` says "The machinery for performing requests is the same as with http-conduit and Wreq. The only difference is the API." so I think it comes down to personal preference about the API.
You have one too many levels of nesting in your examples though, Scheme syntax is `(define f (lambda ...))` rather than `(define (f (lambda ...)))`.
Thank you for looking out for it! I fixed it right away :)
[This blog post by Dimitrios Kalemis](https://dkalemis.wordpress.com/2014/03/22/trees-as-monads/) seems to address the question pretty thoroughly. The TL;DR is that that particular type of tree does not admit a valid Monad definition but rose trees do.
Thanks, that *is* pretty thorough. But isn't it just claiming that no "useful" instance of Monad exists?
There is a monad instance for binary trees with data stored at the leaves, but not one for binary trees where the nodes themselves are labelled. data Tree a = Leaf a | Branch (Tree a) (Tree a)
`&lt;$&gt;` Brackety-cash `&lt;*&gt;` Butthole
Yes, I guess technically the implementation that discards the nodes and applies the function to just the root is technically valid but not useful.
Couldn't you distribute into the leaves? {-# Language DeriveFunctor #-} {-# Language DataKinds #-} {-# Language DeriveGeneric #-} -- | An example module. module Example where import Control.Monad import Test.QuickCheck import Generic.Random import GHC.Generics main :: IO () main = test1 &gt;&gt; test2 &gt;&gt; test3 data Tree a = Tree a (Tree a) (Tree a) | Leaf a deriving (Functor, Generic, Show, Eq) distribute :: (Tree a) -&gt; (Tree a) -&gt; (Tree a) -&gt; Tree a distribute l r (Leaf a) = Tree a l r distribute l r (Tree a cl cr) = Tree a (distribute l r cl) (distribute l r cr) instance Applicative Tree where pure = return (&lt;*&gt;) = ap instance Monad Tree where return = Leaf Leaf a &gt;&gt;= f = f a Tree a l r &gt;&gt;= f = distribute (l &gt;&gt;= f) (r &gt;&gt;= f) (f a) instance (Arbitrary a) =&gt; Arbitrary (Tree a) where arbitrary = genericArbitrary ((1:: W "Tree") % (2 :: W "Leaf") % () :: Weights (Tree a)) test1 = quickCheck (\x -&gt; ((x :: Tree Int) &gt;&gt;= return) == x) test2 = quickCheck (\(Fun _ f) a -&gt; (return a &gt;&gt;= f) == (f :: Int -&gt; Tree Int) a) test3 = quickCheck (\m (Fun _ f) (Fun _ g) -&gt; (((m::Tree Int) &gt;&gt;= f) &gt;&gt;= (g::Int-&gt;Tree Int)) == (m &gt;&gt;= (\a -&gt; f a &gt;&gt;= g)))
Not exactly what you are asking, but you should look at etcd (or zookeeper if you prefer) for any kind of distributed coordination: - https://github.com/wereHamster/etcd-hs - https://hackage.haskell.org/package/grpc-etcd-client It will provide you the right set of building blocks.
You can't have a monad for the type you want. You can move the elements to the leaves as others have suggested and get a free monad for binary trees. You can build an `Applicative` that zips trees like you have here together, where `pure` is an infinite recursive tree. If you remove the `Leaf` constructor, you can have a monad that zips the trees together exploiting the isomorphism between such a tree and functions `[Bool] -&gt; a`. That should look something like: {-# language DeriveTraversable #-} module ZipTree where import Control.Monad.Zip data Tree a = Bin a (Tree a) (Tree a) deriving (Foldable, Traversable, Show) instance Functor Tree where fmap f (Bin a l r) = Bin (f a) (fmap f l) (fmap f r) a &lt;$ _ = pure a -- slight optimization instance Applicative Tree where pure a = x where x = Bin a x x Bin f x y &lt;*&gt; Bin a z w = Bin (f a) (x &lt;*&gt; z) (y &lt;*&gt; w) instance Monad Tree where Bin a l r &gt;&gt;= f = case f a of Bin b _ _ -&gt; Bin b (l &gt;&gt;= childl . f) (r &gt;&gt;= childr . f) instance MonadZip Tree where mzipWith f (Bin a x y) (Bin b z w) = Bin (f a b) (mzipWith f x z) (mzipWith f y w) childl :: Tree a -&gt; Tree a childl (Bin _ l _) = l childr :: Tree a -&gt; Tree a childr (Bin _ _ r) = r
Discarding the nodes fails the second law. `m &gt;&gt;= return /= m`
Ah of course... I withdraw my second assertion and stand by my first :)
Sorry, I should have put a disclaimer. What does "anti-extensional" mean? It doesn't mean intensional, does it?
Great to hear that you are enjoying the book!
Me also, what's your favourite type of ice cream?
A studio isn't really enough to host a guest, but drop me a line if you're in the Bay area.
I think I found a lawful monad instance for that type by using the fact that binary trees are isomorphic to forests of rose trees, but I don't think it's useful for anything. {-# LANGUAGE DeriveFunctor #-} {-# LANGUAGE DeriveGeneric #-} module BinaryTree where import qualified Data.Tree as Rose import Generic.Random import GHC.Generics import Test.QuickCheck data Tree a = Leaf | Node a (Tree a) (Tree a) deriving (Eq, Show, Generic, Functor) instance Arbitrary a =&gt; Arbitrary (Tree a) where arbitrary = genericArbitraryRec (1 % 3 % ()) `withBaseCase` pure Leaf shrink = genericShrink joinTree :: Tree (Tree a) -&gt; Tree a joinTree = fromForest . joinForest . toForest . fmap toForest pureTree :: a -&gt; Tree a pureTree x = Node x Leaf Leaf prop_assoc :: Tree (Tree (Tree Int)) -&gt; Property prop_assoc t = joinTree (joinTree &lt;$&gt; t) === joinTree (joinTree t) prop_id :: Tree Int -&gt; Property prop_id t = joinTree (pureTree &lt;$&gt; t) === t .&amp;&amp;. joinTree (pureTree t) === t toForest :: Tree a -&gt; Rose.Forest a toForest Leaf = [] toForest (Node x l r) = Rose.Node x (toForest l) : toForest r fromForest :: Rose.Forest a -&gt; Tree a fromForest [] = Leaf fromForest (Rose.Node x l : r) = Node x (fromForest l) (fromForest r) joinForest :: Rose.Forest (Rose.Forest a) -&gt; Rose.Forest a joinForest tts = do Rose.Node ts tts' &lt;- tts Rose.Node x ts' &lt;- ts pure $ Rose.Node x (ts' &lt;&gt; joinForest tts')
I think that would be a problem for `&lt;&lt;%@=` and family. The `&lt;&lt;` part is "pre-" then `%` is "modify " then `@` is "indexed" and the `=` is "current state". Alternatives include: * `&lt;` instead of `&lt;&lt;` for "post-" or (nothing) for "without-result" or `%` for "with-auxillary" * `+` of `&lt;&gt;` or `**` instead of `%` to perform that operator, * (nothing) instead of `@` for non-indexed, * `~` instead of `=` for "this value".
I think something like [https://imgur.com/a/JX0N7Wy](https://imgur.com/a/JX0N7Wy) happens, which makes complete sense.
This team is very strong. There are Graham Hutton and Thorsten Altenkirch, that makes a lot of videos in Computerphile in Youtube.
yet any of these still seem to be completely invisible to general purpose search engines
That's why we have hoogle.
does hoogle index source code around internets too?
It can. The main one maintains 3 or so indexes; hackage, stackage, and ghc-included, IIRC. But, you can locally install and index whatever you care to.
Almost except that the children trees are added everywhere possible. I think that's needed for associativity but haven't checked. https://i.imgur.com/R0THh6D.jpg Kind of like a search tree for a very naive sat solver. And like a naive sat solver the exponential blowup is probably too much for anything but toy problems?
Take a look at inliterate (https://github.com/diffusionkinetics/open/blob/master/inliterate/README.md) which is used by tintin (mentioned above).
I'm an Australian honours student who's also looking to do a PhD or MPhil next year in a similar area! I'm working in Idris for my honours and can't find too many places where I can do a related PhD! Please also let me know some details :)
I had dinner with Thorsten once! I didn't even really know how famous he was! My scholarship supervisor just introduced him as a 'visting type theorist'. I was so new to the field I had no idea!
For the [beam documentation](http://tathougies.github.io/beam/), I use [mkdocs](https://www.mkdocs.org/) (a python tool) with a highly customized [plugin](https://github.com/tathougies/beam/blob/master/docs/markdown/beam_query.py), that handles the setup to run against multiple database backends. Then, I configure my backends via a [file](https://github.com/tathougies/beam/blob/master/docs/beam.yaml), and the plugin takes care of downloading, setting up, and building.
An proof of monad laws in agda: https://gist.github.com/Rotsor/b402996c2ef86caa09bb6b998d92819d
In my program, I have the following type synonym: type MySttate f a b = State (MyEnv a b) (f b) I would like to have this type wrapped in a `newtype`, using `GeneralizedNewtypeDeriving` to derive the `MonadState` instance. However, this doesn't appear to be possible because the type variable `b` appears in the first argument of the `State` type. Is there a way to make this type into a newtype and keep the `MonadState` instance?
If I squint enough, I maaybe see the Bool list parser monad. This is clearly isomorphic, but much more suggestive: ``` data Tree a = Tree { on_eof :: a, on_symbol :: (Bool -&gt; Tree a) } ```
I haven't worked out the details, but it seems likely to me that this monad is the bool list parser monad that supports failure (whereas the one in the other comment thread is a parser that can't fail).
Nice article. Might take some of what you describe into our next rethinking of our logging system! &amp;#x200B; --- &amp;#x200B; Also, small easy trick, and IMHO more readable:You can always replace `maybe (return ())...` with `forM\_/mapM\_` So instead of:`maybe (pure ()) ({some monadic func}) mUser` You can just write:`forM\_ mUser $ {some monadic func}` *(or use `for\_` if it HAS to be `Applicative`)*
It's a stronger form of intensional equality -- currently, if you postulated that `not` (the boolean operator) itself is equal to the identity function for booleans, you would be able to derive a contradiction.
We've are in the midst of implementing a very similar strategy for fragile tests at Freckle.
This post is getting a bit old now, but after a bit of digging I managed to make some progress on this problem, and have even managed to find a workaround (sort of). Information is available on the Stack issues page, linked in my other reply.
I was about to get start doing more work on my project. Just in time! I'll let you know if it works for me.
I believe you can revert stack versions using `stack upgrade --binary-version &lt;version&gt;`. Not sure if this is correct though as I‚Äôve never needed to use it. Another workaround is to use [`ghcid`](https://github.com/ndmitchell/ghcid), which is what I‚Äôve been using. And I suppose a bit of clarification is in order here: by ‚Äòcan‚Äôt open Haskell files in Emacs‚Äô, I meant that that when I tried Intero would send me into an error message buffer. I could still open them by disabling Intero, it was just a bit of a hassle.
Wow we need [https://gitlab.haskell.org/ghc/ghc/merge\_requests/298](https://gitlab.haskell.org/ghc/ghc/merge_requests/298) badly.
This is a very simple and practical introduction to lambda calculus and PCF. Thank you.
It goes till lambda cube!
I'm a bit confused by the claim that the Applicative instance for the second type of binary tree (labeled at the leaves) is awkward. How can that be if it admits a Monad instance and every Monad is an Applicative? What does the Applicative instance derived from Monad look like for this data type?
Nice! Can we generalize this to "Annotated Free" structures of the form `Pure a | AnnFree a (f (AnnFree f a))`? I feel like we'd need to factor `distribute` into a portion general to the free structure and one that is specific to each `f`...
Sadly, it would not. The upcoming garbage collector does not solve the multi core problem, as it still uses a moving collector for the youngest generation.
Do you have a live demo for it?
Thanks for reading :) You're right ‚Äî I shouldn't use this construct with `maybe`. It's a mistake I make often. I've managed to swap it out with: ``` traverse_ (addHeader "User-ID") mUserId ```
If you want to build a personal website and if you want it to be static, then Hakyll might be a better choice. However, if you indeed want to build a web application with server and frontend, you can have a look at the following repository: * https://github.com/holmusk/three-layer It's a scaffolding template for projects with Haskell on the backend and Elm on the frontend. It uses `servant` for REST API (not `scotty`) and comes with some batteries. Also, it's inspired by the Three Layer Cake architecture for Haskell applications.
Is it [this one]( https://skillsmatter.com/skillscasts/11654-keynote-how-to-deploy-your-haskell-code-hundreds-of-times-a-day)?
well, I wouldn't use windows for haskell at all, but there aren't any notable differences between windows versions in this case
Or you mean to run a Haskell program on Windows 10 home? Also possible.
For programming. I am facing some issues with the gcc compiler and cabal installing packages and wonder if this might be related to the windows version, since everything I read so far didnt help
Why not? Is there a technical problem, or just your personal preference? It works great for me, so I'm just curious if there's some problem I haven't run into that I should pay attention to.
Thanks, I'll check it out
Probably not; Windows is a bit of an oddball in the zoo of OSes that GHC supports, in several ways: it isn't POSIX-compatible, the usual POSIX utilities aren't available, the process and threading models are quite different, signal handling is different, encodings are different (Windows generally uses UTF-16, whereas most Unix-likes have settled on UTF-8), system APIs are completely different, etc. etc. Early GHC was designed with Linux in mind, and many design decisions are less suitable for a non-Unix-like OS. At the same time, the vast majority of Haskell developers in the wild use Linux (either natively or in a VM/container; I believe some people have also had success running GHC for Linux through Linux-on-Windows) or OS X, so Windows receives relatively little love. And to add insult to injury, getting good build and CI infrastructure for Windows is more difficult and more expensive than for Linux, or even OS X, so Windows is underserved in the QA area as well. So, all in all, GHC on Windows is not going to be anywhere near as smooth a ride as you'd experience on Linux. It's definitely usable, but if running Linux is an option for you, I'd definitely recommend that.
I came from ruby, so spaceship is still `&lt;=&gt;` to me.
I don't really use any names myself, but I can understand how having short memorable names is good for accessibility for the visually impaired.
Not sure what is the exact problem, but sometimes working inside a Cygwin terminal or even a Git Bash shell helps.
I often run into problems related to non-ASCII encoding (or non Western locale?) issue. Such as [https://haskell.jp/blog/posts/2018/windows-gotchas-en.html](https://haskell.jp/blog/posts/2018/windows-gotchas-en.html) But I'm satisfied with the overall experience with GHC on Windows.
No, this is the one where he talks on how they do hot code swapping, which is super cool. After this talk, he said that many people had come to him asking about details on how they actually do deploying, so he did another talk where he explains the process. &amp;#x200B; I remember for instance him mentioning that deployment was like a "train" were each version of the code was a wagon moving forward in the amount of traffic routed to it.
In fact Computerphile is made by people here in Nottingham uni.
If you haven't already considered, take a look at GHCJS as an alternative to Elm; you get to write Haskell on the frontend as well. Reflex, via [obelisk](https://github.com/obsidiansystems/obelisk) (if not [reflex-project-skeleton](https://github.com/ElvishJerricco/reflex-project-skeleton)), is a recommended path; here's [an example app](https://github.com/srid/slownews).
https://wiki.haskell.org/Memoization That's a pretty useful read and discusses a few options that could fit your case.
`Data.Memoize` will do what you want https://hackage.haskell.org/package/memoize-0.8.1/docs/Data-Function-Memoize.html
What you want is memoization. A useful resource on how to do that in Haskell is [https://wiki.haskell.org/Memoization](https://wiki.haskell.org/Memoization). You can either use one of the techniques to do the memoization manually or you can use one of the many memoization libraries that build the cache for you.
I feel that Hakyll is more of a *monolithic* choice when it comes to static site generators, and that I'd rather compose existing Haskell tools like `shake`, `clay` and `reflex`. So inspired [Slick](https://github.com/ChrisPenner/slick) I am writing my own as a library called [rib](https://github.com/srid/rib)..
This has nothing to do with the question being asked here and is little more than an extended rant about your distaste for Windows as an OS. It's not helpful, relevant, or good advice.
There's not enough information to apply the `WrapNF` type famiily. `WrapNF (P k) (b -&gt; c)` might match either clause; * the first if `k ~ ()`, * the second if `k ~ P k1` and `c ~ c1 -&gt; c2`. Also, while you can see that the RHS of `WrapNF` always starts with `Fun`, the compiler does not collect and use such information. You might instead drop the `Fun` from the RHS of `WrapNF` and add it back in a way the compiler can use. Finally, while I don't *know* that it will help in your case, closed type families generally have better error messages, since the compiler doesn't have to deal with the open-world assumption when processing them.
Can't help without more information, but I don't think home vs. pro should make a difference.
&gt; https://wiki.haskell.org/Memoization Thanks! This is exactly the kind of info I was looking for.
Thanks for this. I should have made it more clear in my post, I am looking for the functional approach to memoization, not a package that will do it for me.
Thanks - I was not aware Haskell had a wiki page on memoization. This is exactly the kind of info I was looking for.
Did you consider introducing an effect for the sequential parts of the specification? As you sequence them together using the monad you lose any ability to inspect and optimise the sequential sections which don't make use of the argument to bind at all.
For real, if anyone ever schedules a CDMX Haskell/FP conference, let me know. Me encanta la ciudad y siempre busco oportunidades de regresar.
why would you use reflex-dom-core for html generation rather than a dsl like [lucid](https://hackage.haskell.org/package/lucid) or something similar? just curious
yup https://skye.space/gallery.html (excuse the expired cert lol)
In a different iteration I was toying with automatically parallelizing sequential `create` effects. But, I ultimately preferred the clarity given by the fact that if something is parallel it should be in a `par` block. I'm not sure what kind of optimization you would want to do. But, an idea I had in mind was to extract overviews of what an animation will, which needs similar inspection capabilities.
Wow. type OutputFormatterWithDetailsAndHeaders = ZonedDate -- ^ When the log message was generated -&gt; Request -- ^ The WAI request -&gt; Status -- ^ HTTP status code -&gt; Maybe Integer -- ^ Response size -&gt; NominalDiffTime -- ^ Duration of the request -&gt; [S8.ByteString] -- ^ The request body -&gt; B.Builder -- ^ Raw response -&gt; [Header] -- ^ The response headers -&gt; LogStr How often does this type change I wonder? Why does it not take a record of inputs instead?
Thanks for sharing :)
The link to stack overflow made me chuckle!
Yikes...a someone snagged the domain? That's a shame.
It sounds like the workload in the article was pretty large - I wouldn't be surprised if a lot of the inefficiency was in the old generation. So maybe the concurrent old gen GC would help?
bos has a Mercurial book hosted on a `red-bean` domain, so maybe he still owns the RWH domain? [http://hgbook.red-bean.com/](http://hgbook.red-bean.com/)
&gt;I feel that Hakyll is more of a monolithic choice when it comes to static site generators Could you elaborate on why do you think being _monolithic_ is problematic for you? I think Hakyll is actually fine. It does the job, and it's possible to bootstrap a personal website with it pretty quickly. After participating in creating 4 different blog post websites and writing custom libraries for Hakyll, I see that it solves the problem well and what it actually lacks sometimes is some documentation and clearer explanation of steps how to do different things.
Great post, and great work GHC devs! Thanks.
I thought he was on reddit as /u/bos, but I'm not sure that's him. So, I pinged him (?) on twitter: https://twitter.com/DaTwinkDaddy/status/1148980899616346115 It does look like maybe just the vhosting is un- / mis-configured. red-bean.com is still one of his hosts (and the provided cert is from Let's Encrypt under his name).
Home edition is completely fine, and despite what the others say it has been a good experience for me. Switching OS just to experiment with Haskell is not neccesary, if you were 'already planning to set up dual boot sometime' that is a good option though. From what I know the only difference between windows versions is some built-in solutions for remote desktop and the likes.
I can report that http://hackage.haskell.org/package/uglymemo is simple and works well!
Time spent using shake + pandoc is time spent learning general tools, which will be useful on all kinds of projects. Nothing wrong with Hakyll, but sometimes you don't need specialization. PS If you're making a static site with shake check out [Development.Shake.Forward](http://hackage.haskell.org/package/shake-0.18.3/docs/Development-Shake-Forward.html).
[hablog](https://github.com/soupi/hablog) and [gathering](https://github.com/soupi/gathering) use scotty / Spock respectively and are small and simple enough to learn from imo (though note that i wrote them so i might be biased).
Thanks, that's great I would never find projects like that just by using Github search Another question, do you need to define your own functor, applicatives and monads regularly for this kind of project or using the builtin one is enough? I learnt them through books but still not sure about how to use them in real project
Because I already use reflex-dom and reflex FRP in my projects (both work and hobby). It is [not complicated](https://github.com/srid/rib/blob/master/example/Main.hs#L81-L117) to write HTML with it.
In hablog's case I defined a monad by combining a couple of monad transformers in order to get scotty's functionality + reader for configuration and in gathering's case I just plugged in my types into Spock's types. You can find those in the Types module. There are a few approaches to work with effects / capabilities, monad tranformers is one, io + reader is another, effect systems are a third, my suggestion is start with whatever is simplest and refactor and change when you feel some pains. Scotty and spock pretty much provide you we custom monads to work with though. If you want to see some more examples (some of them of web apps) you can check out the lists in my guide: https://github.com/soupi/haskell-study-plan/blob/master/README.org#simple-example-programs Also, I believe haskell-at-work has a few videos on spock. Maybe check those out as well.
/u/dons do you have access to the site admin, or can ping the right people?
Previous discussion: https://old.reddit.com/r/haskell/comments/c7p9pj/real_world_haskell_down/
&gt;There's not enough information to apply the `WrapNF` type famiily. &amp;#x200B; Is it possible to provide the information by manual type signature? How would it look in this particular case? &amp;#x200B; &gt;closed type families generally have better error messages &amp;#x200B; Um, yeah. It seems that my case can use closed and injective type families, I will check later if it does any good.
I'm writing an app using exactly this stack, Elm + scotty, here's a [link](https://github.com/gigobyte/Listeo). I'm still a Haskell beginner, so I'm trying to keep the code relatively simple. It has auth with JWT and everything, I hope it's useful.
I encountered the exact same problem in a calculation in high energy physics and had to use essentially the same solution. Multi-core calculations were not scaling well, so I had to use distributed-process to spawn several single-threaded "slave" programs. Might it be possible someday to achieve multiple independent garbage collectors without separate processes and serialization? I could imagine some kind of "memory sandbox" feature that spawns a separate heap for some set of computations. (On the other hand, the distributed-process solution does allow scaling beyond a single machine, and memory sandboxes would not.)
Example 2 in haddocks for [http://hackage.haskell.org/package/chimera-0.2.0.0/docs/Data-Chimera-Bool.html](http://hackage.haskell.org/package/chimera-0.2.0.0/docs/Data-Chimera-Bool.html) seems to be covering exactly your use case.
&gt; Is it possible to provide the information by manual type signature? Maybe; probably. I'm not experienced enough with resolving type family errors to assist with that though. Sorry.
/u/tdammers' comment is true and doesn't seem pejorative to me.
I use GHC on Windows every day by using WSL. It works great.
You may be interested in [http://h2.jaguarpaw.co.uk/posts/modules-for-lennart/](http://h2.jaguarpaw.co.uk/posts/modules-for-lennart/)
wow, yeah lucid has some bad examples. you can indeed take advantage of do block syntax, the `HtmlT` type is implemented as a monad transformer https://hackage.haskell.org/package/lucid-2.9.11/docs/Lucid.html#t:Html so you could write html_ $ do body_ "hello world" footer_ "foo" etc. i feel like reflex-dom is a ton of bloat considering you can't really use any of the functionality frp for generating a static site. also, having worked on large (30k loc+) projects using reflex or lucid/blaze, i just find the ergonomics more pleasant.
Why Python?
I think a record would be nicer, but I wanted this change to be as unobtrusive as possible for the best chance of having it merged. That isn‚Äôt to say I think it‚Äôs particularly hard to have changes merged in WAI, but I don‚Äôt have many open source contributions under my belt, How would you approach this? Would you deprecate the other custom output formatters and consolidate them into one that encapsulates all described behaviour and provides a record as an API?
I edited the code in one full-screen terminal window, and I ran \`stack build\` in another full-screen window. Nothing special. Since then I've learned about ghcid, and I like it a lot! I would have loved to run the game in GHCi, but I never got it to work. I suspect it's something to do with the SDL linkage.
how would you go from this \[a,b,c\] to \[\[a\],\[a,b\],\[a,b,c\]\] ?
&gt;i feel like reflex-dom is a ton of bloat considering you can't really use any of the functionality frp for generating a static site. That's a fair point. And I do like the monadic syntax of Lucid. I'll consider switching to it.
[`inits`](https://hackage.haskell.org/package/base-4.12.0.0/docs/Data-List.html#v:inits) returns what you want, consed with the empty list `[]` &gt;&gt; import Data.List (inits) &gt;&gt; import Debug.SimpleReflect (a, b, c) &gt;&gt; inits [a,b,c] [[],[a],[a,b],[a,b,c]] (this uses the [*simple-reflect*](https://hackage.haskell.org/package/simple-reflect) package) You can use [`tail`](https://hackage.haskell.org/package/base-4.12.0.0/docs/Data-List.html#v:tail) on the output of `inits` to get what you asked for tail . inits
`tail` is a partial function, we have to trust that `inits` always returns a non-empty list tail :: [a] -&gt; [a] tail (_:as) = as tail [] = error ".." We can instead trust the type checker, and use [`inits`](https://hackage.haskell.org/package/base-4.12.0.0/docs/Data-List-NonEmpty.html#v:inits) and [`tail`](https://hackage.haskell.org/package/base-4.12.0.0/docs/Data-List-NonEmpty.html#v:tail) from *Data.List.NonEmpty* where `tail` is total inits :: Foldable f =&gt; f a -&gt; NonEmpty [a] tail :: NonEmpty a -&gt; [a] &gt;&gt; import qualified Data.List.NonEmpty as NE &gt;&gt; &gt;&gt; :t NE.inits NE.inits :: Foldable f =&gt; f a -&gt; NonEmpty [a] &gt;&gt; :t NE.tail NE.tail :: NonEmpty a -&gt; [a] &gt;&gt; &gt;&gt; :t NE.tail . NE.inits NE.tail . NE.inits :: Foldable f =&gt; f a -&gt; [[a]] &gt;&gt; NE.tail (NE.inits [a,b,c]) [[a],[a,b],[a,b,c]]
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/haskell_jp] [Is the Real World Haskell book's website hacked?](https://www.reddit.com/r/haskell_jp/comments/cbnj0a/is_the_real_world_haskell_books_website_hacked/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
I use Windows 10 Home 64bit as my main machine, and I haven‚Äôt run into any problems with using the Home edition specifically. It is slightly trickier to use Haskell on Windows, but nothing specific to using Home as far as I can tell.
[I suspect so!](https://stackoverflow.com/questions/55148561/are-free-monads-also-zippily-applicative)
OOP is like building a treehouse by driving nails in with your dick while your dad shouts at you to use better technique.
Can the moderators (/u/dons, /u/taylorfausak, /u/edwardkmett) un-link the "Real World Haskell" in the sidebar until this is addressed?
I removed the link and put "(hacked)" next to it, which we can keep there 'til this is resolved.
Thanks!
You didn't even really state a specific problem, this advice is literally just: "Ope, someone is trying to develop on Windows, better tell them how I think Linux is better" Telling folks: "don't try using your OS to develop Haskell" when that OS is considered a tier one platform for GHC isn't helpful, either to the project goals of GHC, or to developers who are using Windows. The fact is, Haskell on Windows works about as well as most other development ecosystems. It has more or less the same problems you'll run into with python, for example. Windows development does have its own unique set of challenges - which nobody is ever going to learn to address if the advice they get is immediately, unquestioningly telling them to jump ship. This is the real reason development on Windows is a pain in the ass in the first place, because any time any issue comes up, some developer comes along and tells the user to go use Linux, it gets 10000 upvotes, and then any time someone tries to research an answer to a problem, they get pages and pages of results with that same story instead of anything that looks like a real solution to the original problem, because nobody who is actually trying to help solve the real problem gets the cult of upvoters to boost their comment.
However bad OOP might be, I find that this article sensationalises how absolutely nothing good had come out of OOP, and how nothing can be made to last with it.
Yes, I believe there's a problem with GHCI using non-main thread to run SDL (at least on OS X): [https://github.com/haskell-game/sdl2/issues/200](https://github.com/haskell-game/sdl2/issues/200)
This is a silly article written by a silly person.
I'm fairly curious about what kind of calculation were you doing exactly? High energy physics and Haskell is a mix I've (too) rarely seen
On conditional compilation: I'm working on a project that requires to know some details regarding the availability of SIMD instructions on the user's machine. Notably it'd need to know what's the maximum size of the SIMD registers available (in order to choose between `DoubleX2#`, `DoubleX4#`, and `DoubleX8#`). How could I go about that?
Agreed. However much I love to rail on OOP, most of it is actually good. The main issue these days is really that the term itself has become so vague as to not convey any real information anymore. A result of running through the buzzword-grinder, which functional programming is now in the process of as well. New languages have more or less stopped calling themselves object-oriented, but still retain about 97% of what people would consider OOP, i.e. dot-notation.
Especially these days
Didn't know about `simple-reflect` - cool!
It'd be interesting to hear more about what GC configurations were tried and what the impacts were. I've yet to encounter an high-residence workload for which reasonable GC behavior can't be recovered with a combination of `-A`, `-H`, and `-qn`. Were compact regions tried?
Thanks Did using Elm help you to get more familiar with Haskell? I heard from many people that while Haskell and Elm have similar syntax, using Elm doesn't help much to learn Haskell If it doesn't, maybe I'll consider to learn and use a more popular frontend framework which will be beneficial for my job
It's a conformal bootstrap calculation.
Then you have to look at the hyperlink to why Golang does not have polymorphic types! [https://crypto.stanford.edu/\~blynn/lambda/hm.html](https://crypto.stanford.edu/~blynn/lambda/hm.html)
While I don't enjoy Windows as an OS for several reasons, this isn't relevant to my comment. As someone who is personally and professionally involved with GHC development, I would really love to see GHC's Windows story to improve, so that I could tell newcomers that Windows is just as good a choice for Haskell development as the next thing. But it's not, and it's at least in part GHC's fault. Hence my advice, in short: - No, you don't need the "pro" edition, "home" should do. - However, Windows in general will give you a rough ride, so if Linux in some form is a viable option, consider that - not because I hate Windows, but because GHC's Linux support is just better.
Archived version : [https://web.archive.org/web/20190509070638/http://book.realworldhaskell.org/read/](https://web.archive.org/web/20190509070638/http://book.realworldhaskell.org/read/)
Unless I'm much mistaken these ideas are older. See "Physics, Topology, Logic and Computation: A Rosetta Stone", for example &amp;#x200B; [https://arxiv.org/abs/0903.0340](https://arxiv.org/abs/0903.0340)
Your data structure is an example of a comonad. It is the free comonad for the ``` data Tuple a = Tuple a a ``` functor. Recently, there was a talk on comonads at https://monadic.party https://youtu.be/HOmOQnQGtPU
&gt; `f (a -&gt; b)` should be thought of as morphisms, but I don't see how You compose them with `liftA2 (.)` -- or was it something else that you didn't understand?
I would say learning Elm is absolutely a helpful step, and I would recommend it. It‚Äôs also a viable technology choice even after you‚Äôre a Haskell expert, especially if you are working with other people who are on their own FP learning curve. Just be aware that of the two steps (zero to comfortable with Elm, then Elm to comfortable with Haskell) the second one is considerably larger (like maybe 10x or more). But this is just another way of saying ‚ÄúHaskell is jam-packed with deep ideas with many consequences, and Elm has done a bang-up job of simplifying things‚Äù.
Insulting the author without any constructive comment or clarification of what you disagree with... r/haskell can do better than this!
So, I finally managed to find a solution to this problem! Details are on the issue page like the previous workaround. And this one is a full solution, meaning all Intero features are working as normal!
I found looking at the source code of Evan's package.elm-lang.org repository to be useful. Although he uses Snap instead of Scotty [Here's the link](https://github.com/elm/package.elm-lang.org)
I'm having some trouble comprehending `ByteString` construction and its relationship with various brands of `unsafePerformIO`. Without delving too deep into specifics, I have a byte array residing in a read only data section of my executable, and I want to construct a `ByteString` referencing a part of it. So the code looks something like this: fn :: &lt;some type&gt; -&gt; ByteString fn &lt;some data&gt; = ??? where ptr :: Ptr Word8 ptr = &lt;some pure function&gt; &lt;some data&gt; len :: Int len = &lt;some other pure function&gt; &lt;some data&gt; What I'm trying to figure out is what should go in place of `???`. Now, [`unsafePackAddressLen`](https://hackage.haskell.org/package/bytestring-0.10.8.2/docs/Data-ByteString-Unsafe.html#v:unsafePackAddressLen) from [Data.ByteString.Unsafe](https://hackage.haskell.org/package/bytestring-0.10.8.2/docs/Data-ByteString-Unsafe.html) seems to be exactly what I need, with a minor wrinkle: it returns an `IO ByteString`, whereas I'd like a normal `ByteString`; after all, the operation is morally pure. So I turn to [`unsafePerformIO`](https://hackage.haskell.org/package/base-4.12.0.0/docs/System-IO-Unsafe.html#v:unsafePerformIO), the docs on which implore me to add `NOINLINE` annotation on `fn`, as well as disable a number of other optimisations. This seems costly, but perhaps necessary. Except I can't help but notice that `bytestring` itself in a [similar situation](https://github.com/haskell/bytestring/blob/7662853cc527e6d46c5b6529e37b4bbd57dadbee/Data/ByteString/Internal.hs#L199) turns to a neat little function affectionately called [`accursedUnutterablePerformIO`](https://github.com/haskell/bytestring/blob/7662853cc527e6d46c5b6529e37b4bbd57dadbee/Data/ByteString/Internal.hs#L591), or simply `inlinePerformIO`, sidestepping all of the precautions listed in `unsafePerformIO` docs. Now, my understanding is that `accursedUnutterablePerformIO` is safe-ish as long as the code in question does not allocate anything, and merely reads from previously allocated `IORef`s and such; everything else is suspect. But this is not what `unsafePackAddressLen` or `unsafePackAddress` do: the principal `IO` operation in both is [`newForeignPtr_`](https://hackage.haskell.org/package/base-4.12.0.0/docs/Foreign-ForeignPtr.html#v:newForeignPtr_), which, in turn, only needs `IO` to allocate a new `IORef` to hold finalizers. I.e. exactly the operation that `unsafePerformIO` docs warn about. On the one hand, I don't have any finalizers in my case, so, as long as nobody tries to *add* a finalizer, I should not have to care whether the `IORef` is shared, floated, duplicated, or whatever. On the other hand, I don't trust myself to think of all possible pitfalls here. And then there is `unsafeDupablePerformIO`, which looks like some sort of cheaper compromise version of `unsafePerformIO`, and should probably be safe in this particular case. Bottom line is, I am thoroughly confused, and would be grateful if someone more knowledgeable could explain what's going on and what is safe and what is not.
I think functional programmers would like inheritance a lot more, if you'd just call it subtyping. I know there's a difference between both concepts, but inheritance as a mechanism makes subtyping possible. Haskell has subtyping (with type classes), even lambda calculus has a theoretical subtyping extension. The rest of the article is reasonably well written. I always thought the rotten parts of OOP are mixing of state and methods, and shared state.
Non-facetious question: redux-style approaches‚Äîusually considered fuctional‚Äîare a big blob of centralized, shared state as well, aren't they? So why they are better?
Very good critique. As a Marxist/Lacanian I can see in a different perspective the forces that will keep reproducing (theoretically flawd) OOP indefenetly. In Marx and Lacan you have these excesses, surplus value, surplus enjoyment and so on. In software industry I think we have ‚Äúsmall object a‚Äù of programming that originates in the symbolic order of enterprise bureaucracy. It‚Äôs no surprise that excessively verbose Java is so intimately interconnected with the enterprise environment. The goal of any bureaucracy is not to solve problems, but to reproduce itself. OOP world so much dislike Haskell, not because of the math terminology, but because they cannot see the excess, the small obstacle that causes the desire to write code.
I knew some Haskell before learning Elm, but I can say that I didn't learn much about Haskell by using Elm, the only thing those 2 languages share is syntax and some basic principles.
This is very nice! As a user of various Haskell libraries, I appreciate the effort you put into documentation. Great stuff. And you can go even further: you can use custom type errors (as [I described recently in my blog post](https://chshersh.github.io/type-errors)) to provide nice compile-time error messages for the function like this one: openUnionMatch :: forall a as. IsMember a as =&gt; OpenUnion as -&gt; Maybe a I'm not sure what is the current error message, but in theory, it could be something like that: You've tried to match a value of type 'UrlParseException'. However, open union contains only the following elements: '[ FileNotFound, DatabaseError, RequestLimitError ] I wish the Haskell community could consolidate effort around single open sum types library so that other libraries could provide a composable interface for exceptions using extensible errors. Performance doesn't really matter in case of errors; extra 10ms won't make your application slow if you add them only to handle exceptions. So in the application, I can just combine different pieces and have your errors declared like this: type ApplicationErrors = Concat '[ SqlErrors , AwsErrors , AuthenticationErrors , ConfigParseErrors ] instead of creating manual data types to wrap each library. I also have one question about your library: is there any reason you've copied implementation of the `Union` data type from the `union` package instead of adding `union` to dependencies?
Your words don't line up with your "advice". You say you like the Windows story to get better but you actively discourage people from using it. Which means no bug reports and no way for issues to get reported back so they're fixed. Frankly, attitude of people such as yourself is the reason a lot of Windows contributors don't want to bother with GHC anymore. Your work is actively dismissed and users are told specifically to ignore it. Linux only patches actively make it hard to implement things cross platform because zero thought is put into making sure it's a solution that would work cross platform. You say you want Windows support to get better, look in the mirror first.
The problem is that you can use inheritance between types even when there is no subtyping relation: [http://okmij.org/ftp/Computation/Subtyping/](http://okmij.org/ftp/Computation/Subtyping/) This is why even most OOP books disencourage the use of implementation inheritance even if the language allows it; interface inheritance (which is more like what you get with type classes) is OK.
&gt; Try to find out what‚Äôs going on with -O1 and -O2 from the IRC There are a few steps where GHC decides what to do based on the optimization level and not the particular flags. This includes **not running most of the simplifier**. So many flags will have no effect when combined with -O0. The code responsible can be found in SimplCore.hs, grep for opt_level. There is also a (less relevant) optimization in the backend keyed on the optimization level.
Even most OOP developers I've seen frown upon implementation inheritance. But I fully agree. However there's some other interesting things to note: * some languages [allow covariant input parameters](https://en.wikipedia.org/wiki/Covariance_and_contravariance_(computer_science)#Summary_of_variance_and_inheritance) and other things which don't adhere to subtyping schemes * most languages have some subtyping relations which are not expressed by inheritance (e.g. int and double, or int32 and int64; every int is a double, instead these are realized by coercions)
[removed]
`gathering` really helped me a lot (along with `plaste`). Thank you /u/gilmi for writing it and making it public. It helped me put a lot of different pieces together and realize it's within my capabilities to write a web app in Haskell. /u/aqua2nd I think I found it by doing a constrained Haskell code search to `hasql` and `Spock` like this: https://github.com/search?l=Haskell&amp;type=Code&amp;q=%22hasql%22+%22spock%22 Or maybe I was looking for examples of `Web.Spock.Digestive` in action, which `gathering` also is.
&gt; Your words don't line up with your "advice". You say you like the Windows story to get better but you actively discourage people from using it. I want the Windows story to improve so that I can confidently tell people to just use GHC on Windows, and that the errors they are getting must be due to something they did wrong. But right now I can't, and I find that somewhat embarrassing, but lying to people about it or withholding information isn't going to help. GHC on Windows *is* buggier and de facto less supported; that's a fact. If you're willing to deal with that, great; but you still deserve to know, so you can make an educated decision. Getting more people to use the Windows is an important goal; but this is not the place to get political. Also, I really did not mean to offend anyone here. I know you put insane amounts of work into the Windows port, and I understand your frustration. I totally respect and appreciate that.
This is a great comment! I've never used custom type errors, but I have seen them used to great effect in libraries like Servant. The error messages for constraints like `IsMember` are not very good! I actually spent a couple minutes trying to figure out how to use custom type errors to make the compile errors better, but I couldn't figure it out. If you or anyone else wants to send a proof of concept PR implementing this, I'd happily merge it in or continue working on it! I created an issue for this: https://github.com/cdepillabout/world-peace/issues/4 &gt; Is there any reason you've copied implementation of the Union data type from the union package instead of adding union to dependencies? When I started working on `servant-checked-exceptions`, I knew I wanted an open sum type, so I started looking for Haskell libraries that provided it. A couple existed at the time, but I had trouble understanding how to use them and how they worked. I picked an easy(?) implementation like `union` and basically re-wrote it from scratch so I could understand how everything works. I then decided to keep my implementation (rather than just throwing it away), because it had grown a lot of helpful documentation. Hindsight being 20/20, I should have just contributed documentation to `union`.
Even though Redux is not purely functional, I still like the approach. The store is immutable, similar to the state monad. Any changes are made by sending immutable messages to the store. Redux gives developers a complete history of changes made to the store, and even allows to go back in time when debugging. Much better compared to OOP scattering mutable state all over the place, if you ask me.
Thanks! Love the bureaucracy analogy.
This background console/terminal window will also appear if you're writing GUI apps in `gi-gtk`and `haskell-gi`. If you are building using cabal or stack, when you first introduce the `-optl-mwindows` flag that /u/Concertizer mentions and you find that the terminal window is still there, GHC may not have rebuilt the upstream package that this affects (unless this behaviour has changed recently). The `-fforce-recomp` flag may help you where. So what you can add to your `.cabal` file for the executable is: if os(windows) ghc-options: -fforce-recomp -optl-mwindows ...or for new Reddit... ``` if os(windows) ghc-options: -fforce-recomp -optl-mwindows ```
I'm not a maintainer of `wai` nor `wai-extra`, so don't read this as a recommendation. Keeping that in mind, I'd first do an experiment with all the function arguments consolidated into a record and measure its performance relative to the current code. If there is no difference, I'd send a PR together with the measurements. If there is a difference, I'd try to add `INLINE` pragmas to eliminate it. The deprecation decisions are better left to the existing maintainers. If there is still a small difference in performance, perhaps they'd prefer to keep the existing interface but move it to an internal module. That way the users would be warned that the interface could change even in a minor release, and that the record is preferred.
I'm definitely not a fan of OOP, but I think the article is a bit unfair in some points. &gt; Modern OOP has never been properly designed. It never came out of a proper research institution (in contrast with Haskell/FP). Haskell may have come out of academia, but "modern FP" hardly has. A lot of what we now recognize as Haskell best practices and "design patterns" came out of the industry from people trying to use FP to do actual work. Academia is a great source of ideas, but as FP users we are still debating over row types vs subtyping, structural vs nominal, dozens different effect libraries, mtl vs free, lens or not lens, earger or lazy. &gt; Precious time and brainpower are being spent thinking about the ‚Äúabstractions‚Äù and ‚Äúdesign patterns‚Äù instead of solving real-world problems. Yeah, in Haskell wasting time thinking about the right abstraction is totally not a thing.