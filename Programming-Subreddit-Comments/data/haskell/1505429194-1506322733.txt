Thanks!
Oh, perfect, I was looking for this type recently. I felt like I just kept reinventing it afresh each time I needed it and was wishing for a package. [I know I'm not alone, either.](https://stackoverflow.com/q/46166512/791604)
&gt; It says that we need access to IO, It says you must handle all sorts of IO exceptions.
I personally would just stick to using `GADTs`, they are a very clean and general extension. And IMO there is not much point in having two ways to do the same thing (without some good reason for it), and since we can't get rid of `GADTs`, our only option is to keep both or get rid of `ExistentialQuantification`. Plus you don't have to type out `ExistentialQuantification`.
Are you using a specific streaming library?
We are looking to implement this idea with MonadMock library https://hackage.haskell.org/package/monad-mock Has anyone tried this library? 
Great post! Thanks for sharing your experience and helping make `new-build` real.
Still this creates a non-trivial amount of boilerplate and will make it harder to change your code later. Thus, do indeed do it, but stabilize your design first.
I made a package for this! [ghost-buster](https://www.stackage.org/haddock/nightly-2017-09-14/ghost-buster-0.1.1.0/Data-SuchThat.html) There's some really cool stuff that you can do with this, like storing polymorphic things in containers. The library was originally built because I needed it for [one of my other projects](https://github.com/Lazersmoke/civskell/blob/3b2d5f35d0665d20c49cce3f53ad5dfd4f2754c9/src/Civskell/Data/Types.hs#L387), so it is at least somewhat battle-hardened.
How it that ironic?
Someone already beat you to posting this link :)
Have a friend way to read Integers from standard input?
Thanks for your feedback @0not and @IronGremlin - I have updated the article to just not mention problems on Windows. Probably my bad experience on Windows is "out of date" and things have changed. I don't want to put people off and installing a new OS especially if unfamiliar might be a bridge too far, if they just want to learn Haskell.
well this is somewhat difficult if your IO relies on another library using IO. for example, your code needs to use http-client which could trigger disk access or network IO. of course you can abstract over http-client functions at a higher level, but that is not always the preferred option.
 someFunc :: Maybe Thing someFunc = Thing &lt;$&gt; Map.lookup "foo" m &lt;*&gt; Map.lookup "bar" m &lt;*&gt; Map.lookup "baz" m This code uses the `Maybe` Applicative functor. Here's the equivalent Python: def some_func(): foo = m.get("foo") if foo is None: return None bar = m.get("bar") if bar is None: return None baz = m.get("baz") if baz is None: return None return Thing(foo, bar, baz) --- allCombinations :: [a] -&gt; [b] -&gt; [(a, b)] allCombinations as bs = (\a b -&gt; (a, b)) &lt;$&gt; as &lt;*&gt; bs This uses the `[]` Applicative functor. Here's the equivalent Python: def all_combinations(as, bs): return [(a, b) for a in as for b in bs] List comprehensions are cool. They can do a lot of the list applicative stuff. For languages without them, then you get to do this: # ruby time def all_combinations(as, bs) result = [] as.each do |a| bs.each do |b| result.push([a, b]) end end return result end --- parseThing :: Parser Thing parseThing = Thing &lt;$&gt; (string "(Thing" *&gt; skipSpaces *&gt; parseFoo) &lt;*&gt; (skipSpaces *&gt; parseBar) &lt;*&gt; (skipSpaces *&gt; parseBaz &lt;* char ')') This uses a `Parser` applicative functor, which typically combines the `State`, `[]`, and `Either` applicative functors (any combination of applicative functors is *also* an applicative functor, which is a neat trick). Here's some Python that does almost the same thing: def parse_thing(input0): _, input1 = string("(Thing", input0) input2 = skip_spaces(input1) foo, input3 = parse_foo(input2) input4 = skip_spaces(input3) bar, input5 = parse_foo(input4) input6 = skip_spaces(input5) baz, input7 = parse_baz(input6) _, input8 = parse_string(")", input7) return (Thing(foo, bar, baz), input8) I say "almost" because -- how does this handle backtracking? error handling? welp. it doesn't. The passing of the input parameter state is handled implicity by the Applicative `&lt;*&gt;` methods, as well as everything to do with backtracking and error handling. Implementing that in Python would be quite a bit more involved.
This is nice. My audience might appreciate it, especially since a large number of them have a mathematical background. 
Because one would assume that he could have been inspired by that.
One wouldn't assume that, and even if one did, that still isn't irony.
I made an example library for a technique for when you want to have multiple constraints instead of a single `a`: https://github.com/glguy/operations/blob/master/src/Example.hs
That's definitely true! For things as common as HTTP I'd wrap up all the HTTP calls into a MonadHTTP anyways because it will make testing considerably easier, without the typeclass you have to make real HTTP calls, with the typeclass you could substitute the IO with Reader or State and stub the calls with predetermined responses. It's a relatively small amount of boilerplate up front for a good value! Maybe even make a Pull Request with the new typeclass into the HTTP library you use so others can benefit next time!
well, I think if you try to make a typeclass that wraps all of http-client you're going to have a bad time; it is not exactly a small api surface to abstract over.
&gt; This uses the [] Applicative functor. Here's the equivalent Python: &gt; &gt; def all_combinations(as, bs): &gt; return [(a, b) for a in as for b in bs] Almost... that's not valid python since `as` is a reserved word :) 
A very real reason why this hasn't taken off in previous incarnations. `MonadIO` co-opts the ecosystem, this would have to supplant it.
It's dramatic irony, not literal irony. Dramatic irony is what most people are referring to when they say "ironically"
The solution would be to build an interface and see if it sticks. That's how mtl happened.
It's not even dramatic irony...
&gt; I only know of one such change: ghci disables the monomorphism restriction. What are the others? ghci also turns on [extended defaulting](https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/ghci.html#type-defaulting-in-ghci). Also ghci will try unifying the type of a bare expression with the types `Show a =&gt; IO a`, then `IO a`, then `Show a =&gt; a`, and this can occasionally make an ambiguous type less ambiguous (e.g. by fixing a type application to `IO` or selecting an instance with the extra `Show` constraint+extended defaulting). Plus there are a bunch of [random gotchas](https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/ghci.html#faq-and-things-to-watch-out-for) not directly related to type checking.
You can make this out of some more general combinators. There's `DSum` from the *dependent-sum* library: data DSum :: (k -&gt; Type) -&gt; (k -&gt; Type) -&gt; Type where (:=&gt;) :: t a -&gt; f a -&gt; DSum t f Or alternatively, using very common `Some` combinator: data Some :: (k -&gt; Type) -&gt; Type where Some :: f a -&gt; Some f data (:*:) :: (a -&gt; Type) -&gt; (a -&gt; Type) -&gt; (a -&gt; Type) where (:*:) :: f a -&gt; g a -&gt; (f :*: g) a type DSum t f = Some (t :&amp;: f) If you use it with the common higher-kinded `Dict` type: data Dict :: Constraint -&gt; Type where Dict :: c =&gt; Dict c data DictC :: (k -&gt; Constraint) -&gt; k -&gt; Type where DictC :: c a =&gt; DictC c a (the *type-combinators* library offers Some and :*:, and also DictC) Then your type is type T c = DSum (DictC c) Identity type T c = Some (DictC c :*: Identity)
Full abstract: &gt; Static type systems are usually not sufficient to express all requirements on function calls. Hence, contracts with pre- and postconditions can be used to express more complex constraints on operations. Contracts can be checked at run time to ensure that operations are only invoked with reasonable arguments and return intended results. Although such dynamic contract checking provides more reliable program execution, it requires execution time and could lead to program crashes that might be detected with more advanced methods at compile time. To improve this situation for declarative languages, we present an approach to combine static and dynamic contract checking for the functional logic language Curry. Based on a formal model of contract checking for functional logic programming, we propose an automatic method to verify contracts at compile time. If a contract is successfully verified, dynamic checking of it can be omitted. This method decreases execution time without degrading reliable program execution. In the best case, when all contracts are statically verified, it provides trust in the software since crashes due to contract violations cannot occur during program execution.
Well, there is `readLn :: Read a =&gt; IO a`, but that's partial. What is your use case? Single `Integer` per line? Multiple? A generic prompt for `Read`ables?
Oh and for those wondering about LiquidHaskell in relation to this, the paper says: &gt; Another approach to express contracts as types is LiquidHaskell. Similarly to our approach, LiquidHaskell uses an external SMT solver to verify contracts. Hence, LiquidHaskell can verify quite complex assertions, as shown by various case studies in [28]. Nevertheless, there might be assertions that cannot be verified in this way so that a combination of static and dynamic checking is preferable in practice.
Bad bot
You're a dick, stop calling innocent bots bad. They don't know what they're doing, man.
`1+1 * 4 = 8` - disagree with this. Semantic whitespace (beyond separation of symbols and indentation) seems like a bad idea to me. The use of `1+1` over `1 + 1` should only ever be because of programmer style.
GADTs is a syntactic sugar that implies the other extensions of equality constraints (not yet an extension), existentials and explicit forall. In an experimental compiler like GHC I like the granularity. GADTs are okay, but it's verbose to write out the type of each constructor with all the arrows inbetween instead of just its field types.
Looking at the constraints library and trying to understand what it does -- does it help to solve something like this: class C1 a class C2 a class (C1 a, C2 a) =&gt; C12 a instance (C1 a, C2 a) =&gt; C12 a -- is this event needed? Not sure.. data T c where T :: (c a) =&gt; a -&gt; T c t :: T C12 t = undefined f :: T C1 -&gt; () f = undefined test = f t -- breaks with type error: Couldn't match type ‘C12’ with ‘C1’ To make this work, I could use some function from the library? Is there any other way to "subtype"/"inherit" constraints (and not need a third party library)? EDIT: And actually, if I'm understanding this correctly, /u/lazersmoke and /u/glguy are doing something along similar lines -- I guess one does need a library?
&gt; Implementing that in Python would be quite a bit more involved. Implementing it in Python _without applicative functors_ right? Because I don't see a reason why you couldn't implement the exact same API in Python. The only difference would be that you can't use the operators and you don't get any type safety.
I agree with you that 80 is a really tight constraints.
First understand Functor. This is Functor: fmap (\x -&gt; x + 1) (Just 123) =&gt; Just 124 fmap (\x -&gt; x + 1) Nothing =&gt; Nothing fmap (\x -&gt; x + 1) [1,2,3] =&gt; [2,3,4] Map a function over a structure, using the same generic method. Now imagine you want to apply a function over two structures at once. You can't do this with the `fmap` function: fmap :: Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b Its type only accounts for one structure. fmap (\x y -&gt; x + y) (Just 123) (Just 456) =&gt; type error fmap (\x y -&gt; x + y) [1,2,3] [4,5,6] =&gt; type error We need some kind of `fmap2` function. You could write specialized functions for each type: fmap2Maybe f x y = case x of Nothing -&gt; Nothing Just i -&gt; case y of Nothing -&gt; Nothing Just j -&gt; Just (f x y) fmap2List f x y = [ f i j | i &lt;- x, j &lt;- y ] So: fmap2Maybe (\x y -&gt; x + y) (Just 5) (Just 7) =&gt; Just 12 fmap2Maybe (\x y -&gt; x + y) Nothing (Just 7) =&gt; Nothing fmap2Maybe (\x y -&gt; x + y) (Just 5) Nothing =&gt; Nothing fmap2List (\x y -&gt; x + y) [1,2,3] [4,5,6] =&gt; [5,6,7,6,7,8,7,8,9] And that works great. But there are two problems: (1) how do we make a type-class to have this general across many types? (2) what if I want to apply across 3, 4, etc. different structures? The fmap2 then becomes too limited. From there, the `Applicative` class solves (1) and its `&lt;*&gt;` method solves (2). Now you have to figure out why. I think you'll have to learn some Haskell in order to do so.
 data T c = forall a. c a =&gt; T c is about the amount of code as: data T c where T :: c a =&gt; a -&gt; T c I'm not suggesting using `GADTs` when they aren't necessary, but I AM suggesting always using `GADTs` instead of `ExistentialQuantification`.
May or may not help: https://www.well-typed.com/blog/2016/09/sharing-conduit/
Your example saves one character (and misses the constructor). Try with more fields: data T c = forall a. c a =&gt; T a Int Char data T c where T :: c a =&gt; a -&gt; Int -&gt; Char -&gt; T c I wouldn't suggest always using GADTs instead of existentials at all.
It's only less understandable if you don't know the rules behind it. But that's true of, like, every innovation in Haskell or any other language.
Why?
I have found another inconsistency in using the *default* clause with out-of-range literals: no warning, wrong value captured out of *fromInteger* method. So I have defined a specific *fromInteger* for the derived newtypes. I have defined a specific Exception type instead of using the generic Arithmetic Overflow. data IntOverflow = IntSumOverflow | IntProdOverflow | IntCastOverflow | IntOutOfRange deriving (Show, Typeable) instance Exception IntOverflow 
Hmm... I'd rather have something more semantically meaningful than just `MonadFileReader`. Something like `getConfig :: MonadConfigWatcher m =&gt; m Config` might be just enough, which captures the notion of asynchronously watching for changes to various config sources. Sure, that might be a bite too big to chew in terms of testability, but `MonadFileReader` mostly doesn't get you anywhere.Instead of wrapping primitive operations which describe how to do stuff, I'd rather see interfaces that describe what to do. Mostly it's describing an interface the *client* would want to use, instead of describing capabilities the concrete *system* provides.
Of course, more or less by definition, knowing the rules behind something makes it more understandable. Still, I am opposed to your proposal. There are plenty of things I know the rules behind (like C++) but that doesn't mean I understand them well, nor that they are well-designed regarding understanding. (For what it's worth, I don't even like `$`, let alone the idea of `$$` and `$$$`!)
I think that further overloading the functional use of whitespace makes code harder to read. I shouldn't have to take notice of the use of whitespace when grokking new code.
I think the word is "grouping" not order.
This technique can reduce the memory footprint by a lot, but iterating over your strings and/or finding the nth string can generate too much overhead for your needs. I'm not sure if there is a haskell package for this kind of thing, but if there isn't, you might want to look at the following paper: [Experiments with Automata Compression](https://www.researchgate.net/profile/Jii_Dvorsky/publication/221568039_Word_Random_Access_Compression/links/0c96052c095630d5b3000000.pdf#page=115) and perhaps this one: [Smaller representation of finite state automata](http://ac.els-cdn.com/S0304397512003787/1-s2.0-S0304397512003787-main.pdf?_tid=34143a84-9a02-11e7-ae0f-00000aab0f26&amp;acdnat=1505472171_077308133cd128a92970ae806212b138) and for reference, you could look at a [java implementation implementing this](https://github.com/morfologik/morfologik-stemming), specifically the fsa folders in the repo. 
*bleep, bloop, I am a bot.* You linked to a GitHub repository, here are some of my favourite commits: - [fix issue #91: Fux &gt; Fuchs](https://github.com/morfologik/morfologik-stemming/commit/145ad6b8fd20c5c0b02f3768932fea5a561986dd) ***** ^[Source](https://github.com/mike-eason/angry-commits-reddit-bot) ^| ^[Issues](https://github.com/mike-eason/angry-commits-reddit-bot/issues)
`&lt;interactive&gt;:1:1: error: Data constructor not in scope: :&amp;:`
The GADT version is missing the constructor name. It also mentions the type `T` twice, which can be seen as redundant in cases such as this one.
Right, I think this is an important thing to remember: splitting a class like this is not necessarily free at runtime and likely will carry a compile time cost, especially if you end up needing many of these small classes. The reason is that ghc must now dutifully pass a dictionary for each constraint, and simplify where possible, potentially specializing in the process. On the bright side, specialization should largely eliminate the runtime cost of this technique. On the other hand it's not free at compilation time and may bloat your generated code size in the case that you have many distinct monads. This may have adverse effects on cache and branch prediction performance. That being said, for the sorts of programs that you are likely to use this technique on these runtime effects likely aren't your biggest concern. 
&gt; `allCombinations as bs = (\a b -&gt; (a, b)) &lt;$&gt; as &lt;*&gt; bs` Is the following considered less readable? `allCombinations as bs = (,) &lt;$&gt; as &lt;*&gt; bs`
The constraints library has an type `(:-)` to represent *constraint entailment* (here, that `C12 a` entails `C1 a` and `C2 a`), but to turn that entailment itself into a constraint can be a pain. In fact this the essence of the recent [quantified constraints proposal](https://www.reddit.com/r/haskell/comments/6me3sv/quantified_class_constraints_pdf/). /u/lazersmoke and /u/glguy represent constraints with sets of type classes, which allows you to approximate entailment with the subset relation. Here is another way. `cast id` type checks with type `T c' -&gt; T c` if the constraint `c' a` entails `c a`. The drawback is it mostly works only with concrete constraints. cast :: (forall a r. (c a =&gt; a -&gt; r) -&gt; (c' a =&gt; a -&gt; r)) -&gt; T c' -&gt; T c cast coerce (T (a :: a)) = coerce T a test = f (cast id t) 
The article says to disable full laziness, but shouldn't there be a way to simply tell GHC that "no `CAF` should be created in this function!". Laziness is fine as long as no CAF is *created/lifted* out of the function.
I really like this idea but the instances are a real problem. If we only write instances for concrete stacks in our app then this has to be redone everytime, if we write general instances then the splitting doesn't scale. Best workaround I found so far is to have a single MonadBase style effect layer so that the lifting logic is factored out: f :: (MonadEff m '[Console]) =&gt; String -&gt; m () f s = do ln &lt;- getLine print (ln ++ s) -- inferred as: -- f :: (ConsoleIn (Base m), MonadBase m, ConsoleOut (Base m)) =&gt; [Char] -&gt; m () type family MonadEff m ls :: Constraint where MonadEff m (x ': xs) = (GetEff x (Base m), MonadEff m xs) MonadEff m '[] = MonadBase m class Monad m =&gt; MonadBase m where type Base m :: Type -&gt; Type liftBase :: (Base m) a -&gt; m a type family GetEff (s :: k) (m :: (* -&gt; *)) :: Constraint type instance GetEff ConsoleIn m = ConsoleIn m type instance GetEff ConsoleOut m = ConsoleOut m -- constraint kind aliases can't be put into a type list data Console type instance GetEff Console m = (ConsoleIn m, ConsoleOut m) 
UChicago cs161?
https://youtu.be/XfpB0kDLEts?t=19
&gt;[**Ed Byrne explains Irony Using "Ironic" by Alanis Morissette [4:26]**](http://youtu.be/XfpB0kDLEts) &gt; [*^Sara ^Hurd*](https://www.youtube.com/channel/UCgc7pXfDuw4oN5ED-GpYs6A) ^in ^People ^&amp; ^Blogs &gt;*^1,804 ^views ^since ^Jan ^2017* [^bot ^info](/r/youtubefactsbot/wiki/index)
That's a nice reference, I googled it. This is [CMI PRGH17](http://www.cmi.ac.in/~spsuresh/teaching/prgh17/)
This is the main problem I have with all things like `MonadHttp`, `MonadFile`, `MonadDatabase`, etc. There's a lot of surface area to cover for each of those.
It is still more involved if you first have to implement such an API ;-). (I guess that such an API does not already exist.)
Sure it does. https://github.com/jneen/parsy
I'm used to the usual rules of arithmetic. So `1+1 * 4` and `1 + 1 * 4` look identical to me. I would be very frustrated if a programming language would distinguish the two. I would definitely write hard-to-find bugs in such a language.
Cool!
As someone who knows category theory for mathers, but not programmers, I am surprised by how early kleisli categories are introduced
Well put!
&gt; `[(Fix Done)]` FYI the parens are redundant.
&gt; fmap (\input -&gt; valueToTypes input) Why not just `fmap valueToTypes`?
I don't see where you're actually using `allInDir` here. Isn't that a critical piece of information?
You don't need to write it all at once, and it's not like it's tricky to write, you could copy paste the source files from hackage and do some sed magic pretty quickly. The implementation is always just a method alias, so I'm not really sure why a large surface area is an issue there. It might take a little while to figure out the proper splitting points, but you can do a MonadHTTP split to start with and do more granular splits later (using the ConstraintKinds trick I show). I think the 10 minutes it would take to copy paste the interface from source will very soon pay greater dividends. I don't really see this as being a problem IMHO
There's no thinking or "trying" involved really. Copy paste the function definitions verbatim, put them in a typeclass instance, boom you're done! You can still rely on the underlying HTTP object types, it's really just IO that you want to replace.
Agreed, I'd take a small compile time slowdown in exchange for testing benefits any day!
No need to hlint my code, that one's just a thrown together example to demonstrate the problem.
One integer per line, however, sometimes I will need to read N integers per line
https://github.com/reactormonk/non-constant-memory/blob/master/app/Main.hs#L30
I disagree that it makes it harder to change your code later, if you copy the underlying interface exactly it's the same difficulty to change as it was before. You may need to update more type signatures, but that's just busywork that the compiler will guide you through.
Sure! You're free to come up with any boundaries you like. So long as you're splitting up IO then I'm happy 
I've tried isolating the `runConduit` (and `runCConduit`) to a separate file with `-fno-full-laziness`, didn't help.
I prefer `allCombinations = liftA2 (,)`
In that case, you might enjoy my [anti-tutorial](http://gelisam.blogspot.ca/2015/01/haxl-anti-tutorial.html) series!
I just wanted to let you know that I had a chance to play with this, and even though it is just a demo, it was actually kind of fun (in a soothing sort of way)! I was able to build `apecs` on Windows 10 with lts-9.4 by forcing `sdl2 &gt;= 2.3.0` (needed due to [this issue](https://github.com/haskell-game/sdl2/issues/139)). *Edit: I also added `sdl2-2.3.0` to my extra-deps. I can't wait to try and implement `apecs` in my own project. Thanks! EDIT: I also needed to install pkg-config and SDL2. The easiest way is with pacman (I'm not sure if pacman comes with stack or with msys2): stack exec -- pacman -Sy stack exec -- pacman -S mingw-w64-x86_64-pkg-config stack exec -- pacman -S mingw-w64-x86_64-SDL2 
You can use some combination of the following: readMaybe :: Read a =&gt; String -&gt; Maybe a -- from Text.Read, total variant of read getLine :: IO String -- get a line of text from standard input words :: String -&gt; [String] -- separate a string into words (delimited by whitespace)
As a counter point, I copied the above into a stack.yaml file and ran stack setup. I get the following error message: No information found for ghc-8.0.1. Supported versions for OS key 'linux64-ncurses6-nopie': GhcVersion 8.0.2, GhcVersion 8.2.1 GhcJs sounds amazing, but I've never managed to reliably run it.
&gt; You just copy paste some text into your stack.yaml and call stack setup don't you? As I mentioned [below](https://www.reddit.com/r/haskell/comments/6z8e3m/benchmarks_ghcjs_reflex_miso_purescript_thermite/dn1ql9g/), stack does not reliably install GhcJs based on the commonly recommended stack.yaml file.
Your Python `all_combinations()` is not quite equivalent to the Haskell one, since the Haskell version is, of course, lazy. To get a similar semantics one needs to use a generator expression instead of a list comprehension: def allcombs(xs, ys): return ((x,y) for x in xs for y in ys) Even with this definition the arguments should be lazy too to be closer to the Haskell world, like `allcombs(range(100), range(100))`, assuming python3. 
This is a neat design but it unfortunately is not really feasible to truly limit side effects like that, e.g.: writeFile "/dev/stdout" "Hello, world!\n" Or the darker: writeFile "/proc/missiles/launch" "1" So while this pattern works great for testing/mocking, I'd argue against giving any hard guarantees about program behaviour.
It definitely is, but that doesn't refute my statement. My statement means that something can be not awesome and unpopular (COBOL) popular but not awesome (JavaScript) awesome but not popular (Haskell) or both popular and awesome (Iron Man)
Thanks for letting me know, did you need to bump the LTS _and_ constrain the SDL version?
I changed it, thanks for letting me know
I agree. If something doesn't have a well established semantic behavior, then sure, change it and make it more clever. However, fighting against several hundred years of mathematic notation practices feels... A bit misguided.
Fair point. Popularity and programming language features seem to be nearly unrelated at times.
&gt; Even though this works perfectly, I lose information about source location in my constructed AST. You probably should add that information to your AST. I doubt that information belongs in the parsing monad - the parsing monad should only keep track of the _current_ source location (while parsing). That said, you do need to manually add the information everywhere to your AST. That _is_ a pain. &gt; Furthermore, if I want to log certain stuff while parsing/lexing using a custom monad transformer I use everywhere else in my program. Then add that monad transformer to your parsing monad stack! As a quick sketch, you could have your parsing monad just be `StateT SourceLocation IO`. That lets you track the `SourceLocation`, all while also being able to log things to stdout using `IO`. In fact, modulo the problems detailed in [this bug report](https://github.com/simonmar/happy/issues/94), you should now even be able to use a type class constrained monad! That means that %monad { MonadLogger m } { StateT SourceLocation m } { &gt;&gt;= } { pure } should work! &gt; Being able to modify the Alex monad would solve this problem, although this feels hacky and is probably not recommended. An AlexT monad transformer would as well, however I haven't found one yet (it probably doesn't exist). You realize that Alex can run in whatever monad you want right? Usually, you thread the same monad through Alex as you do through Happy. This isn't hacky - I think most larger use cases of Alex use a custom monad. ---- I recently completed a project that basically did everything you listed above (except logging from the parsing monad, although that wouldn't have been to difficult to add). I threaded through my [parsing monad](https://github.com/harpocrates/language-rust/blob/master/src/Language/Rust/Parser/ParseMonad.hs#L39-L43) through both [my Alex lexer](https://github.com/harpocrates/language-rust/blob/master/src/Language/Rust/Parser/Lexer.x) and [my Happy parser](https://github.com/harpocrates/language-rust/blob/master/src/Language/Rust/Parser/Internal.y). This monad allowed me to keep track of source location information which I would tack onto [my AST](https://github.com/harpocrates/language-rust/blob/master/src/Language/Rust/Syntax/AST.hs#L305) (so the result of parsing would be things like `Expr Span`, `Stmt Span`) and to occasionally manually backtrack a token. 
&gt;Seems like entirely a type-level code clarity benefit? In practice, this means your code is more likely to be correct, which does have runtime implications :)
&gt; Thus, do indeed do it, but stabilize your design first. I'd actually argue that this makes prototyping easier. I had to use this approach for `reflex` and it ended up being quite pleasant.
So, if I understand correctly: 1. there's an `SqlBackend` which allows both read and write operations 2. there's an `SqlReadBackend` which only allows read operations 3. `SqlReadBackend` is implemented as a newtype wrapper around `SqlBackend` 4. `select` expects an `SqlBackend`, but you need it to work with an `SqlReadBackend` too And your proposed solution is to change `select` so that it only requests a backend which is "compatible" with `SqlBackend`, and `SqlReadBackend` is considered compatible because you can strip off the newtype wrapper to obtain the underlying `SqlBackend`? Relabelling a read-only connection to a read-write connection doesn't seem wise. Since `select` is a read-only operation, wouldn't it make more sense to change `select` so that it requests a backend which is compatible with `SqlReadBackend`, and `SqlBackend` would be considered compatible because you can add a newtype wrapper to obtain an `SqlReadBackend`?
I've also been poking into the internals of Happy for the past month, so I would be happy (pun intended) to answer any questions you may have on what it can or cannot do.
I kept the LTS at 9.4 (even though SDL 2.3.0 is in nightly) and constrained sdl2 &gt;= 2.3.0 in apecs.cabal. I also needed to add sdl2-2.3.0 as an extra-deps in stack.yaml, since that version isn't in lts-9.4. My understanding of stack is limited, but what I did works!
Fixed. I still think using a completely superseded extension to save so few characters is silly. It's one more thing for people to learn for very little benefit. 
That sounds more like a problem with stack and your linux distribution rather than ghcjs. Have you tried upgrading stack to the latest stable version? This issue seems relevant - https://github.com/commercialhaskell/stack/issues/3268
That does not seem worth it to me. Having to use and make people learn a redundant and superseded extension to save so few characters. 
That's pretty neat. Are you familiar with this exact course and can recommend it? I became very suspicious when it comes to internet codding courses (the likes of Udemy and code academy) as they have a very low standard and would often extend something trivial to a few classes.
And unpacked (which O2 should do by default for a strict `Int`).
Just Rust.
No, since you don't count Idris.
It doesn't look like a minimal example though, you have these json and Fix and TestType complications which may or may not be involved... it would probably be much easier to see the source of the problem if the example was minimal. Otherwise, based on the symptoms given, a wild guess: each of your threads is trying to process your entire bytestring, but share a single bounded buffer; due to the shared resource, one of your threads gets starved, causing it to keep a pointer to the beginning of the bytestring until the very end when all the other threads are done with the bounded buffer; as a result, the faster threads cause the later parts of the bytestring to be loaded, and the slower threads prevent the no-longer-used-by-the-fast-thread parts from being GC'd.
Coq, F#, Rust, TypeScript are my (other) poisons of choice, mostly because they have fantastic tooling and small, consistent cores. I'll still do Python once in a while, but it's less and less by choice. I'm falling out of love with it. And I keep telling myself that I'll eventually do some serious Racket, but it hasn't happened yet.
Each thread has its own bytestring read from a file. They don't share any data, except for the channel that provides the filenames. 
Awk. It's just so much better at being Awk than things that aren't Awk.
I like modern Java. &gt; I don't find Haskell offer a ton of advantages over, say, Python when I'm using it to write automation scripts. For scripts that take a long time to complete, I like statically typed languages, Haskell in particular. The experience of having a Python script fail at minute 35 because of a SyntaxError of all things is utterly infuriating. When I have to use Python I lessen the pain with static analyzers like pylint.
I'll crank out some bash, awk, or a vim macro occassionally (not sure if you count a vim macro as programming though). These can be much more succinct than the equivalent haskell code. I used to use python for various automation scripts, but my python has gotten too weak and my haskell too strong, so I end up doing even this stuff with haskell now.
Bash, Haskell isn't concise enough for shell scripting. I'm working on an alternative, though. 
Clojure(Script). It's not typed but it is very simple and nice to use. The tooling is very nice and to date, reagent and re-frame is my best experience using the react paradigm. Hiccup is just wonderful and JSX is just horrible.
Yes I agree with you on the quality of Udemy and Codecademy is rather low, I believe is mainly because of the empirical/repetitive monkey-sees-monkey-does method they use. How ever the Coursera Stanford ones are quite high level in content and quality, haven't tried one on functional programming yet. As for the quality of this one; GHC, Haskell's compiler, stands for Glasgow Haskell Compiler (in case you didn't know ;0 ) and it was(is?) developed in the University of Glasgow. Or course that has nothing to do with the present but I would take it as a good inductive argument.
Not even with e.g. [Turtle](https://hackage.haskell.org/package/turtle)? EDIT: Quick follow-up: I find that Bash (shell in general) is just too easy to get wrong wrt. quoting/escaping and error handling that I don't trust myself to get it right for anything that going to actually end up running over a long period of time (as in: not "constantly running", but rather "we're going to be running this script via cron for a long time."). For anything of that kind, I'd rather use Python or Haskell. (If not, I'm looking forward to what you're going to come up with!)
Anything JVM-based, but I'm not sure this *quite* qualifies as "choice". The reason is usually that they have a *huge* amount of libraries for integration to almost anything under the sun. For example, SOAP/XML, databases, JMS, Excel, PDF, etc. etc. Even if the library quality is usually not great, you can usually find a library to do *anything* and work around its limitations with a bit of effort. The main thing is that you can start demonstrating basic functionality quickly and customers tend to appreciate demonstrations. (Obviously, since they have little to no appreciation for the technical problems with these libraries.)
Bash for, well, shell scripting. JavaScript for quick and dirty web frontend stuff; purescript for proper web frontend stuff. Python for glue code in the awkward zone (too complex for bash, but not quite the kind of problem that would benefit from types a lot, and such that mild amounts of incorrectness are acceptable for the sake of getting shit done). C++ for hard realtime.
Hence orthogonal :p
This is unsurprising. Postgres is amazing and deserves the praise much more than all those hype-driven database startups... 
I think it's somewhat surprising that we were able to compute everything on the fly rather than having to precompute it like we did in Rethink though. Also that Postgres was fast enough to perform some relatively complex multi-index searches that we previously used ElasticSearch for. I knew Postgres was fast, but I was impressed just how fast.
Ah I see, I thought I LTS 9.4 had SDL 2.3, but I must've misread. I'll add the SDL constraint until SDL 2.3 is in LTS, tyvm
First off: As a programmer, the worst thing you can do is "marry" yourself with just one language. It's like being a carpenter and choosing the same hammer, screw driver and saw for everything, instead of changing to the mill saw, the carver or the sander or other hammers, screwdrivers and saws when you need to/should use them. And you said it: you are a novice in Haskell. You don't know the immense (because they are a LOT) advantages that Haskell provides. And not just Haskell but the functional paradigm (which is not the same as functional style), static typing, and lazy evaluation are the ones that give you the beauty in the code. You are familiarized with the imperative paradigm, and just because you don't know others it does not mean that they are less advantageous. You need to read a book about Haskell before writing your first "Hello world", and it is not because Haskell is hard or has less things than Python (which it does NOT) that you need to do it. It is because the sole way of writing code in Haskell requires you to think different and to be certain of what is it that you are going to do and how is the flow of your information in your program. Just because of that it already makes you to learn how to be a better programmer. As for the "Haskell is not python", you can't say "My car is better because space ships are not like it". Python is an imperative interpreted language and it was built with that purpose. Haskell is a declarative, particularly functional, compiled language. Imperative and declarative languages have HUGE differences. Sure they are both Turing-Complete but there is flow of information that CAN'T be written on python because of it's imperative edge-case characteristics that can be written in Haskell because of the pure functional world. Because there is code that you LITERALLY CAN'T do in imperative languages that already is a big advantage over the rest. How ever, you use your tools where you need them. There are things that some times is better to write them in imperative languages, like C for OS's, and some times it is better to use declarative ones like Haskell for others, like Facebook's new spam-mail detector. But in no circumstances you should start cutting your wood with your hammer just because you don't know (or don't want to) how to use a saw.
University of Glasgow is a pretty reputable university. As another poster pointed out it's where GHC was developed. They teach Haskell to undergrad students so I imagine this course is borrowed heavily from that course.
Author here. Quoting Readme: &gt;Sometimes when working with vectors or matrices or tensors of any rank, you know their sizes and types of their elements at compile time, and you don't need to change them at runtime. This library provides a uniform interface for working with tensors of any rank. It uses dependently typed techniques to catch errors at compile time instead of runtime. It also (ab)uses GHC optimizations to unroll loops to achieve greater performance.
Yeah, I still make the occasional simple bash script when I can't be bothered with Shelly. But bash has the lunatic feature of editing the running script file and executing the edited bit all in a single process. Beat that Haskell! [Bash crazy pants.] (https://stackoverflow.com/questions/3398258/edit-shell-script-while-its-running) 
I occasionally willingly program in different languages (e.g., Scala or even Java) to see things from another perspective. In the end it helps me avoid "tunnel vision" and find more elegant solutions in Haskell. Also coming back to Haskell afterwards always feels like falling in love with it again :)
Not really. I even use Haskell for scripts I'd otherwise do in Bash—it's not ideal and calling commands gets a bit verbose, but I've never had Bash scale beyond a handful of lines. The only other language I've written a lot in recent memory is Elisp, simply because Emacs is awesome. I wish there was an alternative to Elisp that was just as well-integrated into Emacs, but that simply doesn't exist at the moment.
I'm specifically interested in writing things on the command prompt. It's great to just write `ls -1 | grep ^a-z` without ceremony. OTOH when I want to do something more complex, I wish I had lambdas and Haskell syntax, and I seem unable or unwilling to learn Bash. [JL](https://github.com/chrisdone/jl) is partly an experiment in doing that, with concise at-the-prompt scripting.
Moving from popular languages to Haskell takes some maturing as a programmer. Growing up can be difficult at times, but I consider it a worthwhile effort.
I guess I did a few more things to get it to work (that I originally did for something else). I installed SDL2 and pkg-config with pacman: stack exec -- pacman -Sy stack exec -- pacman -S mingw-w64-x86_64-pkg-config stack exec -- pacman -S mingw-w64-x86_64-SDL2 
I dove into Haskell and never looked back. I'm curious how you learned Haskell, and what sorts of things are causing you to want to abandon it entirely.
Easy for me to love-hate. Love Haskell's syntax, type system and its *enforced* purely-functional &amp; lazy paradigms. Hovering between mildly-dismayed and enraged by its dependency management &amp; build process, the default Prelude, the myriad alternative Preludes, the reasons that motivated them in the first place, many of the standard libs and their alternatives and other 3rd-party libs in as far as documentation suffers and/or abstractions-for-the-sake-of-it overwhelm the original practical impulse at hand. On the other hand multiple String types, this time focusing indeed on the practical impulse at hand, rather than a single abstraction --- also bugs me.
Could you go into more detail about things you’ve found frustrating that make you want to jump ship? Some are probably legitimate pain points in the language, which may have workarounds, but some might be things that just haven’t clicked for you yet, in which case we can help explain things. It could very well be that Haskell isn’t for you, that’s fine. But I also had an off-and-on relationship with the language for a little while before everything fell into place in my mind and I was able to productively use it as my main language.
[**Racket**](http://www.racket-lang.org). I love Haskell. I like it so much that I’m essentially [porting it to Racket](https://github.com/lexi-lambda/hackett). But if I love Haskell so much, why would I need to port it to another platform? Projects to run Haskell on the JVM or in the browser make sense—those are ways to get Haskell in more places—but running Haskell on Racket isn’t useful because nobody actually *writes* Racket. Racket doesn’t run anywhere that other Haskells don’t. What’s the point? Well, [Racketeers believe there is no “just right” programming language](https://www.youtube.com/watch?v=g6pGGMKql5Y), not for every possible domain. General-purpose programming languages are important, and we want powerful languages that can adapt to as many domains as possible, but sometimes, you need to write a document, not a program. [So why not make your document a program?](http://docs.racket-lang.org/scribble/index.html) Or, as the case may be, [your book](http://docs.racket-lang.org/pollen/)? Some people think that Racket is about macros, and while that’s true on some level, it misses the point. Racket isn’t about macros, it’s about *solving problems using languages*, and it’s about providing tools for constructing *and working with* those languages. Macros have ended up being a big part of that picture, but do not overlook Racket’s [first-class, higher-order, dependent contracts](http://docs.racket-lang.org/reference/contracts.html), its [scope-tracking, phased module system that provides strong compilation guarantees](https://www.cs.utah.edu/plt/publications/macromod.pdf), and its [extensible, language-aware programming environment](http://docs.racket-lang.org/drracket/index.html). When you get started with any other language, you don’t just install the language: you install a compiler, editor integration, a linter, a documentation generator, and a package manager, each of which need to be configured separately, and which often don’t quite work together without a lot of fiddling. When you install a new library, your editor does not magically acquire knowledge of that library unless you install separate a separate editor integration plugin. In Racket, these are all automatically connected, because [Racket internalizes extra-linguistic mechanisms](http://www.ccs.neu.edu/home/matthias/manifesto/sec_intern.html). So yes, I love Haskell. I use it quite a lot, and much of its toolchain and ecosystem is miles ahead of Racket’s. Racket-the-language has flaws, and it doesn’t have everything I want out of the box. But Racket has `#lang`, which means I can absorb many of the best assets of Haskell into Racket, and it will interact with the rest of Racket’s poly-lingual ecosystem with ease. With Racket, I don’t have to pick a language per *project*—I can pick a language per *problem*.
What's an example of something that's easy with awk that's difficult without it? 
Bash! I love shell scripting. JavaScript to make web frontends (I use an almost purely functional style). Nix for making packages and defining systems. Python sometimes for making scripts that use libraries, e.g. interacting with Google Sheets or some Raspberry Pi GPIO thing or stuff like that, especially when someone else might need to understand the code. Ruby sometimes to work on Rails apps. Agda for fun. Emacs Lisp. 
Not really. Sometimes C if I want to do something low-level, bash/perl/awk for small (&lt;100 LOC) scripts, C++ if I have no other choice. (I’m one of those people who knows C++ inside and out, and *hates* it.) But Haskell is now my default, at the very least because it’s good for the way I like to do prototyping and has strong advantages for the kind of software I write, like compilers and distributed/concurrent systems. Sometimes I rewrite the prototype in another language, most times not. It really shines when you’re working mostly within the language and trying to scale up a project beyond a few thousand LOC. A “scripting” language like Python is definitely more geared toward small code that glues external components together, but it becomes difficult to maintain or alter code when your small “script” grows into even moderately sized “real” software. With Haskell, I regularly do refactorings that I would never attempt in Python, because Haskell makes it *super easy* if you take advantage of the type system—just follow the compile errors until it works.
Most of the trickiness comes from a type family defined on Persistent entities. For the SQL case, this is: class PersistEntity record where -- snip type PersistEntityBackend record = SqlBackend Most of the querying functions have a constraint like: get :: PersistEntityBackend record ~ BaseBackend record =&gt; ReaderT backend m (Maybe record) (unnecessary constraints elided) This works fine for `SqlReadBackend`, because `BaseBackend SqlReadBackend ~ Sqlbackend`, so a `ReaderT SqlReadBackend` will type check. Suppose you want to add a new backend (for our cases, that's `newtype SqlFor a = SqlFor SqlBackend`). This is the backend of the records that are associated with that database, and now we get type safety that we don't mix up database models with the wrong connections. If you use that type `SqlFor MyDb` as the backend type, then your entity gets: instance PersitEntity MyRecord where type PersistEntityBackend MyRecord = SqlFor MyDb Now, this means that all of the constraints like :: PersistEntityBackend record ~ BaseBackend backend =&gt; ReaderT backend m a will require that `BaseBackend backend ~ PersistEntityBackend record ~ SqlFor MyDb`. If we provide an instance instance HasPersistBackend (SqlFor db) where type BaseBackend (SqlFor db) = SqlFor db then this works fine. Here's the kicker: There's a constraint synonym defined in the library: type IsSqlBackend backend = ( IsPersistBackend backend , BaseBackend backend ~ SqlBackend ) which gets used in almost every instance where you're doing SQL specific stuff. By *requiring* that `BaseBackend backend ~ SqlBackend`, we've made it impossible to have these specialized database backend types. Either our `PersistEntityBackend record ~ BaseBackend backend` reduces to `SqlBackend`, and we're in plain `SqlPersistT`, or any alternative SQL backend can't reuse any of the code written that hardcodes to `SqlBackend`. 
This looks great. My only question that won't be answered by the hinted next example is entities that interact, or a component that refers to a specific other entity, like if I want Edge and Node entities for example. It looks like the Entity type can perhaps do this.
Yeah, I made a web game in JS by choice. I love Haskell but making a web game in it would've been a combination of research project and creative project, while I wanted it to be solely a creative project because it's hard enough as it is.
As others have said: bash. I've tried to use Turtle for simple bash scripting but it's just not fast enough unless you're going for complicated scripts. That said: it would be awesome to see an `inline-bash` like we have `inline-C` and `inline-java`.
Congratulations to all the hard workers on their progress! I definitely had fun and I'm glad I got to do something really useful at the same time
I pick python over Haskell for small scripting tasks.
&gt; You need to read a book about Haskell before writing your first "Hello world"... It is because the sole way of writing code in Haskell requires you to think different and to be certain of what is it that you are going to do and how is the flow of your information in your program. This is correct, however, $ echo 'main = putStrLn "Hello world"' &gt; hello.hs $ stack runghc hello.hs Hello world Hello World is really not that hard. What's hard is for imperative programmers to learn how to compose side-effecting programs (with `do`), how to compose pure computations, and how understand the type errors that arise when you mix up the two. I feel a whole book is not needed to accomplish this. Perhaps we can come up with a set of exercises that can get people up to speed on this relatively quickly. I don't want to say "it's not hard". But I do want to say "it shouldn't be _that_ hard for people to pick this up." And I wonder if we can solve this learning curve problem somehow.
Obviously. And not by choice, because once you go haskell your only choice is always haskell. In real world enterprise development you have to code at least in javascript (frontend) and either jvm or dotnet (backend). 
Sounds intriguing? What is outline of your alternative?
Nix/NixOS The Nix language and ecosystem are amazing for building, testing, deploying, and distributing code. My main criticism is the lack of a type system
Not sure I really understand your example, you can of course get around it if you like, but if your developers are deliberately being malicious then fire them. This is a tool to help you succeed, not protection or security from "evil programs"
Interestingly, PureScript seems to be considering making a change in the opposite direction: https://twitter.com/paf31/status/908760073303764993 That tweet continues as a thread explaining why they are considering moving off of a granular effect system Also, my own thoughts from having tried this before is that it's never obvious what is the right granularity for abstracting away effects. For example, do you want a `MonadCopyFile` or a `MonadReadFile+MonadWriteFile`? Should you have a `MonadPutStr+MonadPutStrLn` or just `MonadPutStr`?
So, it's not that things are *difficult* to write without awk, just less easy. For (utterly contrived) example: ps auxww | \ awk '$11 ~ /[ungj]hc/ { hccount[$1]++; print $2 } END { for(user in hccount) print user ": " hccount[user] }' Which, on my mac, does something kind of like printing out the PID of every process that sorta looks like a haskell compiler, and prints the number of such processes by user at the end. I'm far from a master of awk, and sure, this is a little silly. But if you've ever had to deal with deleting a mess of docker images, you've probably come up with more-or-less-isomorphic logic a few dozen times.
I certainly do! * Rust. It's just faster, really. Less expressive, but there's not much comparison. Also, the situation with cross-compilation is much nicer, so you can distribute binaries for arm and whatnot. * Idris. It has dependent types and you can do a lot of neat stuff you couldn't do in Haskell. Plus, dependent types will probably go mainstream at some point. * Go. For my job. I haven't used it enough to form a strong opinion. * Python. I only write one-off scripts in Python. It parses command-line arguments better than `bash` can. It's also fairly portable. &gt;I'm asking because, as a novice Haskeller, I don't find Haskell offer a ton of advantages over, say, Python when I'm using it to write automation scripts. Python is good for scripts and Haskell isn't. There are a number of things Haskell is very good at that Python is terrible at, such as writing parsers. 
That isn't even remotely true. Plenty (as in more than half and then some) of enterprise backend development is NOT done in JVM nor dotnet. Likewise plenty (not sure on proportion but not negligible) of enterprise front end development is done in compile-to-js languages. 
Rust seems cool. Although I can't see where I'd use it besides places where GC is a deal breaker or performance really really mattered, as in more than programmer productivity. So maybe big 3D games and some low level systems stuff?
Not really. For the things I do for fun a GC is acceptable and so is not being quite as fast as C, and in that category I personally think Haskell is basically always the way to go.
Look into persistent / esqueleto.
Good point. You are correct though, you can use Entity to keep references to other entities. A bidirectional relationship would be something like `link a b = newEntity (Link a b)`. Of course, you could also just put a `Data.Bimap (Entity a) (Entity a)` in a global to get proper bimap semantics.
Have you tried out my `dhall` library for this purpose? Here is how you would translate the example from your `README` to Dhall: {-# LANGUAGE DeriveAnyClass #-} {-# LANGUAGE DeriveGeneric #-} {-# LANGUAGE OverloadedStrings #-} import Dhall data MySettings = MySettings { aSetting :: Text , anotherSetting :: Vector Double , yetAnother :: Integer } deriving (Generic, Interpret, Show) main :: IO () main = do settings &lt;- input auto "./file1 ∧ ./file2 ∧ ./file3" print (settings :: MySettings) ... and given these files: $ cat file1 { aSetting = "Hello" } $ cat file2 { anotherSetting = [ 1.0, 2.0, 3.0 ] } $ cat file3 { yetAnother = 1234 } ... produces this result: $ ./example MySettings {aSetting = "Hello", anotherSetting = [1.0,2.0,3.0], yetAnother = 1234} Check out the Dhall tutorial, which explains more about the features of the Dhall language and compiler: https://hackage.haskell.org/package/dhall/docs/Dhall-Tutorial.html
Can you search your bash history for most used awk one-liners and share some here?
&gt;First off: &gt;As a programmer, the worst thing you can do is "marry" yourself with just one language. It's like being a carpenter and choosing the same hammer, screw driver and saw for everything, instead of changing to the mill saw, the carver or the sander or other hammers, screwdrivers and saws when you need to/should use them. Your comment and [lexi-lamda's amazing comment] (https://www.reddit.com/r/haskell/comments/70b9j7/haskellers_do_you_still_code_in_other_programming/dn29iyb) make me think your perfect language is racket in the absence of an existing language being an almost optimal fit for a given problem.
Nope, I'm a zsh user :). Actually, the machine with the history containing that sort of thing is no longer in my possession, so there's not much I can conjure up of my own. I hate to say "google it", but there's plenty of results for "awk one liners"---looking around myself, most of my usage in recent months resembles http://www.kuznero.com/posts/tips/updating-local-docker-images-with-awk-xargs.html.
Do you use [cabbage] (https://github.com/acowley/cabbage) or is it no longer necessary for developing Haskell with nix?
JS, bash, for the obvious reasons. Sometimes Python if I need to do something simple requiring interop with some software that haskell just doesn't have solid support for, like .NET stuff or DB2 database (comes up a lot at work on pet projects). All in all, if I switch to another language on a personal project it's either because that language was purpose built for that problem, or because I failed to find a satisfactory way to implement it in Haskell - I don't find many cases where their are logical problems I'd rather solve in another language, but I find a few compatibility problems that I'd rather solve in another language.
&gt;Python is good for scripts and Haskell isn't. Can you tell me why you feel that way? Any examples? I've spent quite a bit of time writing Haskell scripts where I used to write python scripts. 
I document my development workflow here: https://github.com/Gabriel439/haskell-nix
If you're leaving Haskell for C++ because you prefer the runtime characteristics, then can I interest you in Rust? Rust, unlike the C substrate that C++ is built on, is memory (and type) safe. Yet rust is much closer to the machine than Haskell.
Yes. I've used dozens of languages over four decades. I now use Bash, Python, Haskell depending on the scale of the problem and who else might need to look at the code. Bash code looks like what I'd type interactively in a Bash terminal. Nothing else does. I also have Haskell code that manages Bash fragments; that code relies heavily on a "heredoc" preprocessor I wrote for myself. Any language whatsoever that can't get completely out of the way of other embedded code has an ego problem. Template Haskell doesn't do it for me; custom preprocessors are easy.
I think of Rust as a C++ competitor. The general categories of programs you mention are places where I think I would prefer Rust over Haskell too. Something that really muddles my decision procedure though, is rust having algebraic data types. Haskell is more mature and it's the language Im most proficient in. So I'm going to pick it when programmer productivity is more important than runtime characteristics. Fortunately, rust and Haskell can interoperate via FFI so some mixing is possible. My only complaint there is going via C is suboptimal.
Apparently you can write [a http server in gawk](https://www.gnu.org/software/gawk/manual/gawkinet/gawkinet.html#Simple-Server) too!
By choice I use OCaml cause it provides other nice features like modules and some interesting libraries like incremental and js_of_ocaml. I also end up writing a decent amount of shell code to glue things together. 
* `zsh`: convenience of globbing, e.g. I want to recursively list directories which contain at least one file which does not end in `.bak` More practically, looking through my `zsh` history, I found this snippet `print -l *(e:'[[ -f $REPLY/COMMENTS.txt ]]':) | wc -l`, which counts the number of directories containing a `COMMENTS.txt` file, or `noglob zmv -fw /tmp/mozilla_user0/foo/HW4b_*_attempt_* '$1/${2//[[:digit:]-](#c,)_(#c0,1)/}'`, which renamed files from an inane format I had to download them in to something manageable. * `jq`: if I need to search through a json document. I recently wanted to look through my tab manager's serialized json data for the urls of the tabs that shared a tab group with a another, so after a little exploration of the document, I ran: `jq '.windows[0].tabs | map(select(.entries | any (.url | test("toevil")?)))'` to figure out the tab group identifier and `jq '.windows[0].tabs | map(select(.extData."tabview-tab" | test("64")?)) | .[] | .entries[].url'` to list the urls I hadn't touched or looked at `jq` in over a year when I did this. * `python`: for data munging. I have found `pandas` a lot easier to pick up and use than `frames` or anything else in the Haskell ecosystem.
My main qualm is probably that `stack runghc` is slow, which `runhaskell` is less robust than I'd like. And python is just more portable - I can write a one-off script and easily run it on a remote server. It also can be frustrating to deal with the typechecker - I use Python basically as "bash plus command-line argument parser". I'm sure I'd feel differently if I were writing something more significant in Python.
This is probably due different GHC versions, since (I expect it includes the types) newer GHC had several patches to bring deterministic output. Other from this, I don't think GHC pulls anything from outside to generate types. My best guess is that the code that handles this was modified and it changed the naming scheme. But I know little from GHC innards.
&gt; unable or unwilling to learn Bash It's not just you. I was forced to learn bash/sh better by none other than Nix! But I've found that it is chalk full of utterly undiscoverable, inconstruable patterns that, even when you do know them, you avoid with terror. Fortunately, you don't need them 90% of the time.
Not OP but I have had enough trouble with trying to work with monad transformers without copying in magic that someone else wrote. Every single one of them is like learning a new language that has little to do with any of the others, sometimes on a level of basic syntax. Even the usage of some of the "basic" monads are still confusing to me, like Reader and Writer and State. I can implement some of them in other languages but I still can't use them effectively in the language I learned about them from. I have been trying on and off for _years_ to write something substantive that I actually understand. I usually get one of the two. I made a simple site with servant and blaze that I was proud of after several months. That was a fantastic feeling. I still don't get how it works. The Haskell Book helps, but I still haven't been able to understand anything past the applicatives chapter because I've never been able to work through the exercises and that's when the book really starts doubling down on the nasty math book habit of assuming you've understood every problem thus far in the following ones. There is a also serious documentation problem. Most of the docs on haskell are little more than high-level overviews and type signatures. Type signatures do help, but they are not a replacement for soft documentation. Some of the major libraries are great on that front, but most are not. Haskell is beautiful. It's lovely to work with, when it works. Every time I use it I learn something new, and it's changed my code style for the better in other languages. And I'm saying this over text, so I know it's probably reading so much angrier than I mean for it to. But those are the reasons why I can't use it as a main language. If there's a tutorial on using applicatives, or using some of the "core" monads, or monad transformers that made things click for you, I'd be grateful to hear about it. I really, really wish I could be productive with Haskell. But I can't get my head around some of the most important abstractions in it.
That's kind of what I figured. I might check it out someday but pretty much all the projects I do don't fit into that category, and it seems as though Haskell gives much higher programmer productivity.
This is a really cool project, I hope it gains some traction. Something I would love to see is a layer built on top of this using Raft for distributed and replicated storage. I have dreams of building an all Haskell Hadoop replacement, and the storage side of things is really where most of the hard work is - there's plenty of people who hate Hadoop but love HDFS.
Just to add some examples from Raaz. I mantain two files `Reviewing.md` and `Releasing.md` in the main repository which is essentially a check list for reviewing and releasing respectively. If the wiki were a submodule, I could as well put these files in the wiki. More importantly, there can be information that are required to be kept in the repo (mainly for the developers) and also in the wiki (for the outside world). This method can allow sharing of this information. 
That has been my experience too.
If it can count as a different language, I am using SML for a first course on compilers, partly because of it being a simpler language than Haskell. See https://bitbucket.org/piyush-kurur/compilers
Congrats to all! Hadrian (https://github.com/snowleopard/hadrian) is on its way towards being part of GHC and we need new contributors' help now! You can start with easy issues (as tagged) -- Andrey and I will give comments as much as we can.
Not sure that I'd qualify that as easier, but it's definitely cool :)
&gt; So, it's not that things are difficult to write without awk, just less easy. That's close enough. Your example was great :)
Python, for quick and dirty file reading scripts. Nothing fancy, but sometimes it's just easy. Not nice, but easy.
I use `persistent` for migrations, data definitions, and basic queries. `esqueleto` is a very nice layer on top of that that provides type-safe SQL queries that mostly don't fail at runtime (we're working on making them *never* fail at runtime!) These libraries are used and supported by FPComplete, a major player in commercial Haskell development, so they're pretty thoroughly battle tested. Opaleye is an interesting database library that focuses much more on type safety, but is quite a bit harder to use than Esqueleto and Persistent. Then, there are the *very* low level libraries, like `mysql-simple` and `postgresql-simple`. If you just want to write raw SQL queries, these are your bet.
Compiling times is my biggest gripe as of now. Hoping for the 8.21 to help with it when I'll finally be able to switch to it. 
That looks pretty cool! What could be some possible usage of calling Java from Haskell?
I've not used [Haxl](https://github.com/facebook/Haxl), but it seems interesting.
I didn't understand the McBride Applicative paper when I read it, but I figured &lt;$&gt; and &lt;*&gt; could be used to make monadic stuff shorter, and did a lot of that. Much later, I had a parser-like thing and I wanted to extract documentation from the parser and remembered applicatives let you do that, so I tried it, and it worked. Now the paper seems totally obvious. It went the same with monad transformers. So maybe never mind about the documentation, just figure out the syntax and use them. That might be completely useless advice, but I think there's something to it, since it's the same way I learn language or music. Sure, check out the grammar book, but do lots of talking anyway, and eventually the wrong things will start to feel wrong and the right things feel obvious.
Getting access to all of Apache Spark (for distributing computations on many computers) is one of them. See [sparkle](https://github.com/tweag/sparkle). We talk about this more in previous posts: http://www.tweag.io/posts/2016-02-25-hello-sparkle.html http://www.tweag.io/posts/2016-06-20-haskell-compute-paas-with-sparkle.html Writing cross platform GUI's would be another one via JavaFX/Swing. But in general I think the sweet spot for this kind of bridging is supporting existing JVM based enterprise middleware - basically to insert Haskell into existing ecosystems.
If I get an Int at runtime, how can I prove that it can be used as an index in my vector? That's the part where I always get stuck. Is there a way to do it, even with coercions?
You should be able to do this using the reflection package, I think.
Second highest votest post on /r/haskell ever!
Couple days back I wrote an open source app using `postgresql-simple`. This particular file shows setting up DB connection pool and perform migration https://github.com/eckyputrady/haskell-scotty-realworld-example-app/blob/master/src/PG.hs Hope it helps. Let me know if you have any questions. EDIT: as for libraries, persistent + esqueleto seems to be popular choice. I however just happen to like writing SQL directly hence I favor `postgresql-simple` 🙂
Update: applyMetaFun *is* possible! Requires a bit of reworking, but no TypeInType! data Label (a :: k) data MetaFun (f :: k) (g :: k) (l :: [*]) where BaseFun :: (a -&gt; b) -&gt; MetaFun a b '[] LiftFun :: forall k. (forall (a :: k). MetaFun (f a) (g a) l) -&gt; MetaFun f g ((Label (m :: k)) : l) data MetaVal (f :: k) (l :: [*]) where BaseVal :: f -&gt; MetaVal f '[] LiftVal :: MetaVal (f a) l -&gt; MetaVal f ((Label a) : l) applyMetaFun :: MetaFun f g l -&gt; MetaVal f l -&gt; MetaVal g l The type signature works, and I've written and tested (successfully) an implementation. It's actually pretty simple once you understand how MetaFunctions and MetaValues work. ...Sadly, there probably can't be a MetaVal -&gt; RegularVal function, due to my aforementioned reasoning of "we can't know how many variables to apply". But that shouldn't be a major headache in the long term. I still haven't figured out a use for this. But that doesn't mean one doesn't exist!
I have tried many times with no satisfactory solution.
The jni and jvm links from the "invoking java methods section" seem to be broken (they give me 404 Errors). Other than that this seems really good. I was wondering, since it seems like you could call "any jvm function"... How would one go about calling code written in other JVM languages, like Clojure/Scala/Kotlin? Is there a better way than just calling it from Java (which can probably get kinda ugly I'd guess, especially for Scala and clojure) 
I often had a choice: 1. Do the task at hand quickly in another language. 2. Learn about yet another abstraction that I hadn't learned about yet. Haskell has a lot of abstractions one needs to learn, causing a steep learning curve. I've decided to stick with it. I've had the feeling since the beginning that the effort is going to pay off in the long run, and this feeling keeps growing for me as the years go by. Yesterday, I was getting horrible performance (slowness; memory usage through the roof). Thankfully, Snoyman had recently written [this article](https://www.reddit.com/r/haskell/comments/6zl88c/all_about_strictness/) and a few ! completely solved the issue.
Thanks, I just posted [a reply](https://www.reddit.com/r/haskell/comments/70cttz/i_have_given_up_on_haskell_more_times_than_i_can/dn2v8ug/).
A question about recursion schemes. Imagine that you want to label the nodes of a tree with some information that is calculated from the root downwards. It seems that you can do it in two ways: - Use a catamorphism that returns a function that takes the top-most annotation and builds a final result (the [returns-a-function](https://wiki.haskell.org/Foldl_as_foldr_alternative) trick is needed because vanilla catamorphisms consume the tree from the leaves upwards). - Use an anamorphism that takes the original tree as a seed and constructs the annotated tree, stopping when it reaches the leaves. It did that in [this](https://stackoverflow.com/questions/46134949/haskell-labeling-an-ast-with-type-information-using-algorithm-w/46143294#46143294) SO answer. Mi question is, are these two ways related at a "deeper" theoretical level? Is there some formal law that allows you to go from one to the other? Which way is preferable?
&gt; I like modern Java. You mean Kotlin? ;)
I didn’t learn by reading tutorials, so I can’t really make any recommendations there. I mainly followed along reading and modifying example code from blog posts and things like [Write Yourself a Scheme in 48 Hours](https://en.wikibooks.org/wiki/Write_Yourself_a_Scheme_in_48_Hours), tried to write my own projects, and asked questions when I got stuck. Transformers really “clicked” for me when I had to use them at work in a codebase that already used them. Monads in general I found easiest to learn by trying to write the equivalent pure code, then noticing a repetitive pattern and finding out what monad instance would let me avoid the repetition, for example: -- Reader let x = f env y = g env z = h env in x + y + z -- = runReader (do x &lt;- reader f -- Or more commonly f' where f' is a monadic version of f y &lt;- reader g z &lt;- reader h pure (x + y + z)) env -- Maybe case mx of Just x -&gt; case my of Just y -&gt; case mz of Just z -&gt; Just (x + y + z) Nothing -&gt; Nothing Nothing -&gt; Nothing Nothing -&gt; Nothing -- = do x &lt;- mx y &lt;- my z &lt;- mz pure (x + y + z) -- State let (x, state2) = f state1 (y, state3) = g state2 (z, state4) = h state3 in (x + y + z, state4) -- = runState (do x &lt;- state f y &lt;- state g z &lt;- state h pure (x + y + z)) state1 So where monads are good for abstracting away patterns in pure code, transformers are good for abstracting away similar patterns in *impure* code: -- StateT do (x, state2) &lt;- f state1 (y, state3) &lt;- g state2 (z, state4) &lt;- h state3 pure (x + y + z, state4) -- = runStateT (do x &lt;- lift f y &lt;- lift g z &lt;- lift h pure (x + y + z)) state1 As for the functor/applicative/monad combinators, I picked them up in a similar way, by using them to shorten &amp; simplify my existing code in `do` notation—especially parsers, which I use often—as I learned about patterns like these: do intermediate &lt;- action let result = function intermediate ... -- = do result &lt;- function &lt;$&gt; action ... do intermediate1 &lt;- action1 intermediate2 &lt;- action2 let result = function intermediate1 intermediate2 ... -- = do result &lt;- function &lt;$&gt; action1 &lt;*&gt; action2 do intermediate &lt;- action1 action2 intermediate -- = action2 =&lt;&lt; action1 -- = action1 &gt;&gt;= action2 I just used them without understanding them, then got a general idea of *when* to use them: * `pureUnaryFunction &lt;$&gt; impureAction` * `pureBinaryFunction &lt;$&gt; impureAction1 &lt;*&gt; impureAction2` * `impureFunction =&lt;&lt; impureAction` This understanding of *what they’re good for* is what made me understand their types and how to read similar types more effectively and deal with the lack of soft documentation and examples. Obviously this is just a high-level overview, but I hope it’s somewhat helpful guidance for how you might go about understanding and applying these things in your own code. 
both sound like hylomorphisms - tearing down one structure while building up another 
I can relate on documentation. I found that some libraries also have documentation in the form of their unit tests or an examples directory on github. 
I write a fair bit of shader code directly. I've yet to find a DSL for working in that space that is suitably expressive. I also find myself writing C++ here and there. I can get some crazy templates to basically output almost exactly the assembly sequence I want while still retaining the power to build abstractions. Then there is a bunch of bash and a little bit of perl when I have to write a script or munge a bunch of text.
I just use: Rust, Agda, Swift, SML, Haskell, C (although rarely C by choice). I have used Python and Java but only to contribute to other projects, not my own. I occasionally use and write basic bash scripts, but I am equally likely to write small processing tasks in Haskell or Rust. I am not a fan of Object Oriented Programming so I tend to avoid that stuff. Also, if (La)TeX counts, being turing complete, I probably write more of that than anything else. In the past I've used Scala and OCaml but haven't used them recently. 
Thank you for the kind words! You can always contact me if you are interested in contributing!
Well, - `reifyNat` from the reflection package allows you to turn an Integer into a type-level natural. - You'll need some function to compare two type-level naturals `n` and `m` and return either `Nothing` or evidence than `n &lt;= m`. Something in the spirit of `sameNat` from `GHC.TypeNats`. Unfortunately I don't have much time to elaborate, but that's the gist of it. Of course, you'll need to perform some coercions ; but you should be able to write your code in such a way that it is correct iff the comparison function is correct.
Thanks for all the awesome responses. I think I will look into persistent since it seems like easiest to use out of the box :D
In this case, I think, the problem kind of solves itself since you still need to check for negative indices. Good question!
Use more precise types to make programs safer. You can give a type to infinite lists: data Stream a = Stream a (Stream a) Now indexing can be total for non-negative numbers. -- Natural is the type of natural integers, can be found in base. (!!) :: Stream a -&gt; Natural -&gt; Stream a Stream h t !! n = if n == 0 then h else t !! (n-1) -- - `(!!)` also throws an exception if its index is negative. - Repeated use of `(!!)` often suggests that there is a better data structure for the job. It may also be that you can actually avoid random access, with more zips, folds and traversals instead.
I'm sorry, I shouldn't have said 'dependently typed', I've misled you. I should've said 'type-level something'. This library isn't dependently typed. It will only work when you know all indexes you want to access at compile time. Otherwise, inlining will not trigger and all functions will degenerate into functions on lists with the corresponding performance. This might sound like a huge limitation, but I've been using this library for 3d graphics computations for a while, and I've never needed runtime indexing. What is your use case?
`nix-shell`?
The problem is that you very quickly have to start writing manual proofs about everything.
inline-java can't do better than calling those languages from Java. But it would be possible to implement, say, inline-scala in a similar way to inline-java. The techniques to infer and translate types and to generate and load bytecode could be the same, but at the user facing interface the details would depend more on the particular language. For instance, inline-java uses a lexer for the java language to find the antiquotations, this lexer would need to be changed for other languages. Another example: We use the type JType to encode Java types in Haskell, this type would need to be replaced or wrapped so users don't need to be aware of how the specific language types look from Java. Thanks for the heads up on the broken links, they are fixed now.
I am thinking about writing a dependently typed tensor-library. In machine-learning, there are situations in which you don't know the dimensions of your input (or don't want to specify it!), examples are dynamic graphs in neural networks via pytorch. Or sometimes you want to abstract over tensors of arbitrary size, like a simple convolution that just halves all your dimensions. EDIT: but your library is still pretty interesting! I am not quite sure how to tackle it yet and somebody exploring the design space where everything is known at compile-time is interesting and helpful.
Someone should write inline_rust
I'm guessing graphics work doesn't usually deal with dynamically sized tensors, right? Maybe something like machine learning applications? I don't have a concrete use case.
Yeah, I suppose this one won't fit for machine learning tasks. It is more suited for linear algebra. 
This looks just great. The ghc plugin is super smart. Installing with `stack --nix` is really slick.
It usually doesn't. Yeah, I suppose it won't fit machine learning tasks.
Is there a way to configure GHCi to recognize the key-sequence "ESC foo" as "Meta-foo"? In the shell, I find these sequences useful (e.g. "ESC f", "ESC d", etc) since my keyboard's meta (alt) key is in an awkward position.
I think I love you. :)
Pony looks better than Rust to me most of the time. It's a bit more "researchy" though.
I don't think it's a good idea to use anamorphism to build inductive data from inductive data. In a total setting, recursion on inductive data always terminates and corecursion into codata is always productive. In Haskell we can do dirty mix-ups when we unfold into data and recurse on codata, but then we lose totality guarantees: the former only works if the unfolding step function happens to always terminate with leaf nodes, the latter only works if the input codata happens to be finite. In the case of AST-s, I think they are pretty much always inductive and finite, thus we should only recurse on them. Building them from seeds is possible by recursion on inductive seeds (which is necessarily total).
I'd personally hesitate simply because of linear time inefficiency and look for a more appropriate data structure wherever possible. e.g. https://github.com/ekmett/streams/blob/master/src/Data/Stream/Infinite/Skew.hs as opposed to https://github.com/ekmett/streams/blob/master/src/Data/Stream/Infinite.hs
It's not as easy as "disable full laziness and you're done". If you're sharing condutis for _any_ reason you might be in trouble. In particular, if you are sharing conduits because your parallel threads are sharing them you might be in trouble. However, if this indeed is the problem you should see some tell-tale `Pipe` objects in your heap when profiling.
&gt; Not sure I really understand your example Writing to files might change the state of the network, or writing to the network might change the status of memory, etc. Once you access the "real world" you don't have a guarantee that other parts haven't been affected as well. Normally, we think of the different layers of a monad stack as orthogonal. If we `set` or `tell` we don't expect that to affect a `ask` or `get`, respectively. Most of our instances are parametric enough to guarantee this. But, for the different aspects of I/O you don't get that separation / parametricity. --- Of course, with `unsafePerformIO` and the current FFI around, the "guarantees" you get from pure code are rather soft.
I spent several years being conflicted about Haskell, mostly because it's never had anything close to decent tooling. I finally gave up on it after discovering that there was no sane way to implement a type-level composition function. At this point I'd rather fuck around with Coq, from a hobbyist's perspective it's all of the positives with none of the negatives.
I hear that. I'd suggest that you don't let not knowing some abstraction get in the way, and just do stuff the way you know how. Free monads and monad transformers are cool and sometimes useful, but you can get very far with pure functions and `IO`.
`iterate f z !! n` comes up fairly often and I think it's fine. Also with slightly more complicated things that are still obviously infinite, like `unfoldr (Just . f)` or a list comprehension with `[0..]` in it. When it isn't as obvious as this I might write case drop n xs of [] -&gt; error "should have been infinite" (x:_) -&gt; ... (or the same check but using `listToMaybe`).
&gt;&gt;If you're leaving burgers for pizza because you prefer the format, then can I interest you in calzone? &gt; &gt;Chocolate cake looks better than calzone to me most of the time.
Why is the type of `f a b c = a + b + c` resulting in `a -&gt; a -&gt; a -&gt; a` but something like `(a a a) -&gt; a` ?
What is the best way to find out what to put in cabal build-depends section when importing a library? For example when importing system.random you have to put "random" in the build depends but other libraries aren't so obvious. 
I find that `zsh` fixes nearly all of the quoting and escaping issues and adds nice power. I actually find `zsh` more convenient than Python for anything that involves globbing and doesn't involve array manipulations.
Kind of the same thing as saying dump C++ for Rust. I CAN write safe C++. It's all ergonomics or as you say - taste?
And I WILL give Rust another try. Actually thinking next weekend. It has a very compelling set of features and performance. Pony does too and is also worth a look!
It might be worth it to lose the ability of using common formats, and a bit of flexibility in requiring the read of records with keys matching the settings to get Dhall based configs. If nothing else, I do expect to support a Dhall run over the files before reading them. Yet, your Interpreter semantics do not align well with the normal expectation (at least in UNIX). Error messages are hierarchical, what means for example that an invalid key will create an error over the entire record, like as "Expression doesn't match annotation". That's completely unhelpful. Also, file combination is done plainly (all the information is read as if it was a single file) instead of files having different priority. The Dhall `Interpret` seems to just have a different goal.
There's precedent for ditching Haskell for C++. IIRC this is what Edward Kmett did. They're languages with a lot of parallels, some shared use cases, etc. Enter Rust. If I had to place it in language-space, it would be something like "C++ - Haskell + OCaml ≈ Rust". And nobody would bat an eye if the situation were reversed: &gt;If you're leaving C++ for Haskell because ______, then can I interest you in OCaml? Meanwhile, Pony is fundamentally an (incomplete) Erlang successor. Completely different philosophy. And completely different use cases. If you're looking for a hobby language, then you'll get a relatively similar experience from fully-baked-yet-still-evolving languages like C++, Haskell, and Rust. Pony is going to be an outlier. Same for a work language. I get the same strong reaction when people push Nim or Vala as Rust alternatives. Or Haxe as a C# alternative. Come on people.
Yeah, but that's more related to dependently-typed programming than anything else.
Search in the hackage¹ site for the module you are importing. The URL will carry the library name, but if you want, click on the "contents" link at the top-right of the pages that will take you to the library's contents page and its name will be the title. What I don't get is how did you discover the API of a module without going into hackage first. 1 - As in site:hackage.org in google, or !hackage in duckduckgo.
Functions in Haskell are by default [curried](https://en.wikipedia.org/wiki/Currying). In order to get a `(,,)` in the type, you need a `(,,)` somewhere in the definition, e.g. `f (a,b,c) = a+b+c`.
**Currying** In mathematics and computer science, currying is the technique of translating the evaluation of a function that takes multiple arguments (or a tuple of arguments) into evaluating a sequence of functions, each with a single argument. Currying is related to, but not the same as, partial application. Currying is useful in both practical and theoretical settings. In functional programming languages, and many others, it provides a way of automatically managing how arguments are passed to functions and exceptions. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/haskell/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.27
I don't disagree with a single thing you've said. I walk a line between fun, productive hobby languages and practical production day-job stuff. Rust has potential for both! Hence my desire to go back to it. Cheers!
That `f` function is a function that takes an argument of type `a` and returns a function that takes another argument of type `a` returning yet another function that takes an argument of type `a` that finally returns an `a`. It's a bit confusing at the beginning, but `f a` for example has type `a -&gt; a -&gt; a`, and `f a b` has type `a -&gt; a`. All of those are perfectly valid functions, and can be used as parameters of functions like `map` or `fold`. As another example, if you define `g a b = a + b`, you can write `map (g 5) [1, 2, 3]` and it will result in `[6, 7, 8]`. That's because `g 5` is a function of type `Num a =&gt; a -&gt; a` that you can map over that list.
Avoid !! altogether. If you need it, you have probably selected either a wrong algorithm or a wrong data structure.
I have some feedback on JL if you would like it. If not, feel free to ignore the rest of this comment, and thank you for making JL. I tried to use JL instead of `jq` for one of the tasks I describe in my [comment](https://www.reddit.com/r/haskell/comments/70b9j7/haskellers_do_you_still_code_in_other_programming/dn2ll91/) below, but I gave up. I tried it again, with more familiarity with the task, and found myself missing a few features. I had a json file with unknown structure, so this was partly an exploration task. As such, I found the following to be a problem: * absence of a `type` command * absence of an "run this and ignore the type error" command * mapping over objects is verbose (and may be useful to mention in a "recipes guide"): `\o -&gt; map (f o) (keys o)` * I couldn't figure out the equivalent to `jq 'to_entries|map({key, length:(.value|length), type:(.value|type)})'` For my file, it produces the following (colorized): [ { "key": "version", "length": 2, "type": "array" }, { "key": "windows", "length": 16, "type": "array" }, { "key": "selectedWindow", "length": 0, "type": "number" }, { "key": "_closedWindows", "length": 0, "type": "array" }, { "key": "session", "length": 3, "type": "object" }, { "key": "global", "length": 0, "type": "object" } ] 
Of course, as any discerning hacker, I *do* use zsh. Just not for scripting... hadn't actually considered it, but maybe it's actually a reasonable choice given its longevity.
Thanks. I got the idea. Does it mean the Haskell internally interpret multi-parameter functions to curried form, or just the expressions are presented in that form?
You can try to look up modules on hoogle or hayoo.
Well, ok, looks like my answer is in a more beginner level than it should. A function written in the form `f a b c = undefined` is curried. This is what everybody uses because it is more useful than uncurried functions. You can write your function uncurried too, as in `f (a, b, c) = undefined`. It will have type `f :: (a, b, c) -&gt; d`, instead of `f :: a -&gt; b -&gt; c -&gt; d`. Now, that's, of course at the semantics level. Internally, it is a hard question to answer. I don't think there is a well defined line between curried and uncurried functions in the resulting binaries after optimization. Are you concerned about performance?
added explicit messages to the IntOverflow exceptions to report values involved.
I have a question about manually type interference of combined functions. Functions like 'map map' and 'map filter' I can figure out but I am stuck on functions with (.) so for example how would you go about 'foldr . map' can you say that 'foldr . map' == ((. map) foldr) or how should I approach this? 
Ah I see it now thank you so much!
I'm a total beginner but the way I understand it is that "f (a,b,c) -&gt; d" is a function from a single "(,,) a b c" type to "d" and even though these are isomorphic, the thunk shapes should differ. And usually the curried shape is more comfortable to use, since you can still naturally partially apply it without ad hoc lambdas? edit: and this is not guaranteed by the language but maybe "f a b" would cause "a" to be concretely evaluated (like you have with "seq" so that "f a" can be applied to "b") while "f (a,b)" may still keep both "a" and "b" unevaluated (since it only needs the "(,)" constructor evaluated)?
People list out these issues all the time, which isn't to say they aren't legitimate issues for larger enterprise codebases but it shouldn't stop someone from learning. I'm not a professional Haskeller and none of these has ever bitten me. * Building and dependency management are quite nice now with Stack, * I use 'head', 'fromJust' or whatever pretty sparingly * docs for the standard libs eg. Parsec, bytestring, have been fine (although the super abstract ones are pretty doc sparse and I haven't used lens) * String isn't a huge deal, I use it for convenience, profile, if it's too slow pick another implementation. The only real issues I have are * massive build times which the GHC devs are actively addressing * having to fix my Cabal scripts at every freaking release but that's just because I do more than `defaultMain`. Annoying, but I've accepted it. 
On your first comment, yes, they are isomorphic, except that one is applied to a single tuple, and the other is applied sequentially to a series of values. That's one of the ways available in Haskell to express an uncurried function, wether it is exactly an uncurried function or not is way too open to disagreement based on different definitions, yet it preserves the effect of uncurrying, that is, the function receives only one single parameter of a product type. About forcing evaluation, no. Both representations have the same evaluation semantics (except for evaluating the tuple itself). Haskell will evaluate both `a` and `b` only when needed (where "needed" is a complex set of rules that, honestly, I am do not know GHC well enough to explain).
Almost, the infix syntax `foldr . map` is equivalent to the prefix syntax `(.) foldr map`. So given the types (.) :: (b1 -&gt; c1) -&gt; (a1 -&gt; b1) -&gt; (a1 -&gt; c1) foldr :: (a2 -&gt; b2 -&gt; b2) -&gt; b2 -&gt; [a2] -&gt; b2 map :: (a3 -&gt; b3) -&gt; [a3] -&gt; [b3] you can match (b1 -&gt; c1) ~ (a2 -&gt; b2 -&gt; b2) -&gt; (b2 -&gt; [a2] -&gt; b2) (a1 -&gt; b1) ~ (a3 -&gt; b3) -&gt; ([a3] -&gt; [b3]) and conclude that b1 ~ (a2 -&gt; b2 -&gt; b2) c1 ~ (b2 -&gt; [a2] -&gt; b2) a1 ~ (a3 -&gt; b3) b1 ~ ([a3] -&gt; [b3]) and then since `a2 -&gt; (b2 -&gt; b2)` and `[a3] -&gt; [b3]` are both type-equal to `b1`, you can further conclude that a2 ~ [a3] (b2 -&gt; b2) ~ [b3] but a type can't be both a function and a list, so actually, `foldr . map` doesn't type check! But at least now you should be able to try you hand at an example which does type check, like `map . foldr`.
Package inference is a little known but really useful feature of cabal. For example: `Main.hs`: module Main where import System.Random import Data.Aeson main = undefined then if you run `cabal init -n` (the `-n` is noninteractive mode, you can omit it) you get a `.cabal` file like this: -- Initial tmp-I8LzYZVth8.cabal generated by cabal init. For further -- documentation, see http://haskell.org/cabal/users-guide/ name: tmp-I8LzYZVth8 version: 0.1.0.0 -- synopsis: -- description: -- license: license-file: LICENSE author: Francesco Gazzetta maintainer: [snip] -- copyright: -- category: build-type: Simple extra-source-files: ChangeLog.md cabal-version: &gt;=1.10 library exposed-modules: Main -- other-modules: -- other-extensions: build-depends: base &gt;=4.9 &amp;&amp; &lt;4.10, random &gt;=1.1 &amp;&amp; &lt;1.2, aeson &gt;=1.1 &amp;&amp; &lt;1.2 -- hs-source-dirs: default-language: Haskell2010 Cabal inferred automatically that you need the `base`, `random` and `aeson` packages to compile your project! Note that this uses the package index, so be sure to have a recent one (`cabal update`)
As an example of how those things can differ: :t (\ f (a, b) -&gt; f a b) ... :: (t2 -&gt; t1 -&gt; t) -&gt; (t2, t1) -&gt; t :t (\ f p -&gt; f (fst p) (snd p)) ... :: (a -&gt; t1 -&gt; t) -&gt; (a, t1) -&gt; t The names picked by the type inference mechanism might depend on the order in which the AST is traversed, the naming used by functions that you call, or the order in which type variables are unified. For instance, in my second example, the name `a` showed up because `fst :: (a, b) -&gt; a`. As for why it's those names in your example, I'll let someone more GHC-knowledgeable figure it out! :-)
I use persistent, it's good but needs a bit of setup. I think to begin with postgres-simple or mysql-simple might be actually simpler. Thus the name .
Wow that is awesome thank you for the info!
There are vim keybindings that do special things with ESC, so in principle it should be possible, though it might be a bit of work. If you want to try to figure out how to do it yourself, you should take a look at the [haskeline documentation](http://trac.haskell.org/haskeline).
&gt;A while back, I gave up for weeks and returned to the "more efficient and predictable" C++. Depends on your definition of "efficient". Even if you're more productive in C++, you have to define "efficiency" - ease of refactoring, speed of generated code, etc. I'd venture to say C++ is probably less predictable, but of course this is mostly dependent on the programmer, not the language. &gt;It's strange IMO. I don't quite get what's going on yet. &gt; Has anyone else here had similar experiences? That was me when I started learning Haskell. I kind of got hooked on the "Haskell experience" - refactoring a program, compiling it, and finding out it *works* when I run it. What *really* got me hooked on Haskell was a [paper](http://www.cs.nott.ac.uk/~pszgmh/pearl.pdf) on monadic parser combinators. Haskell has a way of making the easy hard and the hard easy. If you need some motivation, I'd always encourage you to start looking at projects that Haskell is particularly suited for. It can be pretty discouraging to work on a project and be thinking "I already know how to do this in _ why is it so hard in Haskell."
Any specific reason for having submodule instead of just creating a docs folder and placing all the information in it ? After the article came out, I migrated the yesod cookbook from wiki to it's own repository: https://github.com/yesodweb/yesod-cookbook. While not exactly a submodule, this has provided a better experience than the previous wiki we had.
&gt;I often had a choice: &gt; Do the task at hand quickly in another language. &gt;Learn about yet another abstraction that I hadn't learned about yet. I'd suggest you make learning new abstractions part of learning Haskell, but that you pick projects that you were scared to take on using C++. I might suggest looking at [Parallel and Concurrent Programming in Haskell](http://chimera.labs.oreilly.com/books/1230000000929/ch06.html#sec_par-accel-shortest-paths), which has a really neat example of how to run nontrivial code on a GPU for a speed boost. &gt; Yesterday, I was getting horrible performance (slowness; memory usage through the roof). Thankfully, Snoyman had recently written this article and a few ! completely solved the issue. Worth noting that (perhaps only for your own edification) there's probably a lazy algorithm to do the same that doesn't have a space leak. 
&gt;what sorts of things are causing you to want to abandon it entirely. Thinking "I could just do this in Python!" or "this error message makes no sense". I was usually mistaken about being able to do it in Python. The type checker saved me from myself even early on.
Minor note: I have had to do your docker example a lot (but I used `-q` and other tricks) and I wrote some ridiculous stuff to do it. They finally added (earlier this year or late last year?) a whole series of `docker prune` commands. You may need a recent docker to use them but if you don't know about those, check them out.
What should it do on `newtype OtherBool = OtherBool Bool`?
Maybe `reallyUnsafePtrEquality` with `True` and `unsafeCoerce`?
 {-# LANGUAGE MagicHash, BangPatterns #-} import GHC.Prim import GHC.Types import Unsafe.Coerce main = do print $ aPerfectlyReasonableThingToDo True print $ aPerfectlyReasonableThingToDo False print $ aPerfectlyReasonableThingToDo 'a' aPerfectlyReasonableThingToDo :: a -&gt; a {-# NOINLINE aPerfectlyReasonableThingToDo #-} aPerfectlyReasonableThingToDo !_x = let !x = unsafeCoerce _x !true = True !false = False in case reallyUnsafePtrEquality# x true of 1# -&gt; unsafeCoerce False 0# -&gt; case reallyUnsafePtrEquality# x false of 1# -&gt; unsafeCoerce True 0# -&gt; x To the extent that this works, it works because [constructors with no fields (like Bool's) are shared](https://stackoverflow.com/questions/3254758/memory-footprint-of-haskell-data-types/3256825#3256825) and [guaranteed not to be moved](https://ghc.haskell.org/trac/ghc/wiki/Commentary/Compiler/DataTypes#Labelsandinfotables) in terms of their representation on the heap. We have to make sure we're not doing the ptr equality test on _thunks_ though which is the reason for the bang patterns. The above is probably some combination of insufficient and overkill; I've only tested it like above, compiling without optimizations. *EDIT*: in case it isn't clear, this is a terrible thing to do: we've broken the language, in particular we can no longer reason in terms of _parametricity_ (which is something we do intuitively, even if we're not familiar with the formal notion). Like this is just as heinous as `foo input = unsafePerformIO randomIO`
Maybe so but it just feels like the docs are better for persistent when it comes to things like migrations and connection pooling. Do you have any good examples that you know of for postgres-simple?
Here's another way to do it (kind of): import Unsafe.Coerce isTrue, isFalse :: a -&gt; Bool isTrue x = unsafeCoerce x == (unsafeCoerce True :: Int) isFalse x = unsafeCoerce x == (unsafeCoerce False :: Int) badid :: a -&gt; a badid x = if isFalse x then unsafeCoerce True else if isTrue x then unsafeCoerce False else x Of course, technically there's no guarantee that `isTrue` and `isFalse` will actually work, in any sense whatsoever. Nevertheless, this seems to work when tested in GHC.
Sorry, I misread your post. I don't think postgres-simple offer any migration or pooling. But you can easily run query.
&gt; I have been trying on and off for years to write something substantive that I actually understand. I usually get one of the two. I made a simple site with servant and blaze that I was proud of after several months. That was a fantastic feeling. I still don't get how it works. That's okay. I wrote a blog using Yesod before I understood either monad transformers or quasiquoters. I wrote several command-line tools using optparse-applicative before I had any idea how they worked. &gt;The Haskell Book helps, but I still haven't been able to understand anything past the applicatives chapter because I've never been able to work through the exercises and that's when the book really starts doubling down on the nasty math book habit of assuming you've understood every problem thus far in the following ones. If you have a study group in the area, you might want to join it. Good exercises may not require you to do *all* the previous exercises, but doing things yourself is what builds fluency. And figuring out which exercises build on one another is somewhere a teacher can help. &gt;If there's a tutorial on using applicatives, or using some of the "core" monads, or monad transformers that made things click for you, I'd be grateful to hear about it. I really, really wish I could be productive with Haskell. But I can't get my head around some of the most important abstractions in it. Some things simply don't fit into tutorials. Saying "make a tutorial about monads" is approximately like saying "make a tutorial for references". I certainly sympathize - it would be nice if there were a choice of introductory texts - but ultimately it does require a lot of effort. If you need motivation, I highly recommend [this paper](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.598.2294&amp;rep=rep1&amp;type=pdf) on monads as well as [this paper](http://www.cs.nott.ac.uk/~pszgmh/pearl.pdf) on monadic parser combinators. As you note, many core libraries are organized around monads and monad transformers. The thing is, there's a *reason* that this is the case. Trying to understand why the library authors made a choice to use monads can be quite instructive. As a final note: I found monads painfully hard when I started writing Haskell. I would've rather not used them at all. Now, they're one of my favorite paradigms and I get annoyed when I can't use them in Rust.
Yeah I'm looking for how to use a database in the context of a potentially long lived production project. If I were to write something like a quick script or similar I would probably go for hdbc or something like that.
This is actually really helpful. The idea of erasing repetition made sense when I ran over maybes, but seeing the idea in context with the other stuff makes it click a bit more. Thank you
Is this even legal?
Is it not the case that the choice of catamorphism determines the order the tree nodes are consumed in? (eg. `foldl` vs `foldr` for lists)
You can even write pattern synonyms pattern AltTrue, AltFalse :: a pattern AltTrue &lt;- (isTrue -&gt; True) where AltTrue = unsafeCoerce True pattern AltFalse &lt;- (isFalse -&gt; True) where AltFalse = unsafeCoerce False badid :: a -&gt; a badid AltFalse = AltTrue badid AltTrue = AltFalse badid x = x 
I see. There is also groundhog which seems a good alternative to persistent. I haven't used it but it look interesting.
I think I looked in to that a while ago but sort of gave up on it due to lack of docs. I think it was kind of new back then so maybe it has gotten better since
Can you this to update an existing cabal file ?
We'll, one of the strength of Yesod ecosystem (which is persistent is part of) is the doc and especially the Yesod cookbook. I personally use persistent but I remember needing to migrate to groundhog for some reasons I forgot (I probably found some workarounds).
For a simple migration tool, checkout `drifter` and `drifter-postgresql`. It would be trivial to write a backend for mysql. I'll be publishing one for Project:M36 shortly.
We were getting close in [numhask-array](https://github.com/tonyday567/numhask-array) but, alas, unwrapping that last pesky Proxy wrapper is a technical difficulty. The slicer technology kind of shows how, via an CPS-style existential `(forall ns. SingI ns =&gt; Array ns a -&gt; Either Text r)` but I find the whole thing difficult to code. 
What would a `foldl` for trees look like?
Look ma, no `unsafeCoerce`! {-# RULES "badIdNegateBool" badId = not #-} {-# NOINLINE badId #-} badId :: a -&gt; a badId x = x It's even worse than bad, it's terribad: you can't test it in ghci, and if you work hard, you can convince the rewrite rule not to fire. But it has the right `id` behavior on `Any` and `All`, unlike the `unsafeCoerce` versions, so it's got that going for it. **EDIT**: Ohoho! After reading the Fine Documentation, I discovered I could eta reduce the rewrite rule and it becomes much less fragile (e.g. now `map badId [False, True] == [badId False, badId True]` unlike my previous version). Still breakable, though. For posterity, here's the old version of the rule: "badIdNegateBool" forall (x :: Bool). badId x = not x
Wouldn't that also flip `Foo` to `Bar` and vice versa given `data FooBar = Foo | Bar | ...`?
In what sense? Can this been done in a remotely safe, reliable and language spec compliant way? No. Will you be arrested for doing it? Depends on what state you live in.
Long response: Yes, many times. A few things stand out for me. Problem 1: “Embarrassment of riches”. I was writing a program that needed to use regular expressions to do text replacement in a relatively short file. In the first place, should I use `Data.Text` or `String`? Which of the many regex packages do I use? Some work with `Data.Text`. Some work with `String`. The one that seems to work best with Unicode appears to put all its results into `IO` (see third problem for more on this). I'm glad There's More Than One Way To Do It, as Perl programmers would say, but I am convinced that whichever way I do choose -- it will be the wrongest possible choice. Problem 2: Getting the right version of what I want. `stack` has helped here; when using only `cabal` it was a pure mystery why anything worked. Problem 3: I don't have an advanced degree in category theory, and I really feel I need one to write even the simplest of programs. (This is going to sound like a rant. Well, OK, it *is* a rant.) For example, I can write this function to extract a value from a `Maybe`, with a default in the `Nothing` case: extractWithDefault :: Maybe Int -&gt; Int -&gt; Int extractWithDefault (Just a) _ = a extractWithDefault Nothing defaultValue = defaultValue But if I try to do something similar with a signature like: extractWithDefault :: IO Int -&gt; Int -&gt; Int I can’t figure out how to make that work. I am thinking it should be possible. `Maybe` is a monad; `IO` is a monad. They’re the same typeclass. They both follow the monad laws. What’s the deal? At this point, I imagine every experienced Haskeller LOLing and thinking, “Yeah, they have the same typeclass and follow the same laws, but why on earth would that lead anyone to infer that `Maybe` and `IO` have any other properties in common?” I anticipate that any answer I would get would be written in terms of advanced category theory constructs. This feeling is reinforced when I see a very complete and well-written book like [Category Theory for Programmers](https://bartoszmilewski.com/2014/10/28/category-theory-for-programmers-the-preface/) and think that, unless I understand the material in its entirety, I may as well give up on ever writing Haskell well. And I also get the impression that the concepts presented in that book are easily and immediately understood by everyone who programs in Haskell (except me). Bottom line: I keep leaving Haskell because I am continually convincing myself that I am just too damn stupid to learn it well.
I'm ignorant about this stuff, which is why I was asking, but I did some reading and it sounded like if I could implement `Foldable`'s `foldMap` I would get `foldl` and `foldr` for free, so I figured I'd give that a shot and see what happened. The result was that I got `foldl` and `foldr` for free but they both produced the same result which suggested that the answer to my question is "no", but I still have no understanding of why. To explore a little further I implemented a version with the `mappend` operation reversed and I get what looks to me like the output I would expect for an "opposite fold", but it seems like I must be missing something if the natural `foldl` and `foldr`'s based on `foldMap` don't exhibit the same "opposite" behavior. FWIW, [the code is here](https://gist.github.com/lgastako/88818df467a5ded086491fd4d8a8dbac).
Nope. Try it in GHCI: &gt; data FooBar = Foo | Bar derving Show &gt; badid Foo Foo &gt; badid Bar Bar
Hmm. Ok I guess something strange must be going on with the `Int` intermediate cast. Because &gt; unsafeCoerce Foo :: Bool False &gt; unsafeCoerce Bar :: Bool True 
Note: This version will also flip newtypes of Bool.
Certainly. That's basically inevitable though, because newtype wrappers of Bool are guaranteed have the exact same runtime representation as Bool. The solution with rewrite rules avoids this, because it works at compile time. But any solution that works at runtime *has* to treat newtypes the same as what they wrap.
Something strange indeed. Try `unsafeCoerce Bar :: Int` and `unsafeCoerce True :: Int`. You'll get different results. But observe also that `unsafeCoerce (unsafeCoerce Bar :: Int) :: Bool` is `True`. In other words, these are two different `Int`s which both `unsafeCoerce` to `True`.
Good job!
In fact I have not yet tried this model at all so whatever reasons I give can be dubious at best. Nonetheless let me attempt at sumarising my reasons: Firstly the code base in general moves much faster than the wiki. This is particularly true for projects that are in the initial stages of development like raaz. Many of the interfaces and best practices change significantly. In such a situation, any documentation that is maintained by the developer is most likely to be accurate and uptodate. Making the docs closer to the source gives it better chance to be accurate. I have found that I am more inclined to update the haddock documentations than updating the wiki. Some comment in the article aludes to this phenomenon when they mention a lack of ownership (for the wiki) on the side of the developer. I am hoping that making the wiki a submodule is a way to bring it closer to code although I agree it mostly has a placebo effect. I am not sure how making an entirely new repo helps as the wiki itself is a repo, except that it does not have an issue tracker or its own wiki ;-)
Thanks! 
Scala !
What about scala ?
I would use a closed type class, just exporting the method: {-# LANGUAGE FlexibleInstances #-} {-# LANGUAGE OverlappingInstances #-} {-# OPTIONS -Wall #-} -- File: Module.hs module Closed (myid) where class MyId a where myid :: a -&gt; a instance MyId a where myid a = a instance MyId Bool where myid True = False myid False = True -- File UseClosed.hs module UseClosed where import Closed demo01 = myid True demo02 = myid "True" 
I like F# a lot. I do wish it was as full a language as Ocaml, but it's Windows compatibility is crucial for the work I do. I work in an industry that is Windows and document centric (not data centric), I usually have to work with *.doc and *.xls files - using cvs files isn't a really an option as the xls files already have "semantic formatting" and aren't strictly tabular. F# makes this doable and the experience is largely very positive. I appreciate the "serious-mindedness" of the F# libraries in this area. Where Haskell has equivalents, e.g. csv parsing for the times when I can use csv, I felt the Haskell libraries were written with half-a-mind to prove a point (e.g. show Data.Vector is better than Data.List) than to make a great user experience.
 That doesn't have the right type signature, does it?
I doubt I will ever use Scala at work, so I guess I just went all the way to Haskell when choosing a "hobby language". Also I'm kind of intrigued by the annotation-driven style of programming that has taken over the enterprise Java world. I'm not sure it is an unconditionally good thing, but I find it interesting. Instead of giving you full flexibility and power from the start, like say with LISP macros, you hang metadata on the ledges and ridges of "conventional", relatively boring code. And it works in a very implicit and "nominal" way, like "well this class requires a Foo here, and the only annotated Foo implementation in the jar is this one, so I guess I'll go with it".
A few complicated, unsafe solutions here. Why not just create a typeclass with overlapping instances? {-# LANGUAGE FlexibleInstances #-} class BadId a where badId :: a -&gt; a instance {-# OVERLAPPABLE #-} BadId a where badId = id instance {-# OVERLAPS #-} BadId Bool where badId = not main :: IO () main = do print $ badId True -- False print $ badId "Hello" -- "Hello" print $ badId (12 :: Integer) -- 12 **Edit:** The reason that no one else suggested this seems to be that the type of `badId` here is `BadId =&gt; a -&gt; a`, rather than just `a -&gt; a`. Even though they are entirely equivalent due to the `forall a. BadId a` instance, even if the compiler could prove that an unconstrained `a` will actually work because it must have a `BadId` instance, it does not know which instance to use.
I'll take a stab at explaining the whole Maybe/IO deal. Okay, so it's reasonable to think "These two things are both X, and therefore I must be able to do the same things to them".. well, it is true, but only to an extent. Let's start by backing up a bit and approaching this from another perspective. I'm going to assume that you know something about design patterns. Not a lot, but I think it helps to approach this from a perspective which many people may be familiar with from other languages. Let's say we have the singleton pattern. We have two classes A and B in some language like, say, C++, and for whatever reason that is irrelevant to this explanation, they should both be singletons. What does that mean? It means that they are objects that should only be instantiated once. This could be because, when instantiated, they initialize some resource which should only be initialized once, and all subsequent initializations should reuse the same instance. This is a common occurrence -- one class could be a logger class, and the other could be a class which talks to some service over the network. Let's pretend for a moment that this "singleton pattern" these classes both implement allows you to retrieve the instance of the object they initialized internally(normally, this would be `private` in OOP terms, but we're pretending). So if I have two objects, `logger` and `networkService`, I know I can call `logger.getInstance()`and `networkService.getInstance()`. However, apart from this one shared property -- they are both singletons -- these classes have nothing else in common. I don't expect to be able to call `logger.sendToService(..)` or `networkService.logMessage(..)`. The point I'm trying to get at is that the same applies to the types `Maybe` and `IO`. They share some properties -- they are both monads -- but the properties that the Monad typeclass enforces upon types that implement it does not say anything about say, retrieving values from them. If you have a function `foo :: (Monad m) =&gt; ..` this `Monad m` constraint tells you exactly what you can expect to do with *all* types that implement this typeclass(namely bind, return and so on), and those things are *the only things* you can do, since you don't know more about the type. 
&gt; it sounded like if I could implement `Foldable`'s `foldMap` I would get `foldl` and `foldr` for free That is correct &gt; The result was that I got `foldl` and `foldr` for free but they both produced the same result which suggested that the answer to my question is "no" I think it's more likely that the `foldl` and `foldr` you created are different, but you used them with an associative operation so that wasn't sufficient to tell them apart. Remember: foldr1 f [x,y,z] = x `f` (y `f` z) foldl1 f [x,y,z] = (x `f` y) `f` z So if you use an operation like `(+)` which is associative (meaning that `x + (y + z) = (x + y) + z`), then you are going to get the same result with both. &gt; FWIW, the code is here. I see you have used `(++)`, which is indeed an associative operation. To see the different ways in which `foldl` and `foldr` parenthesize the result, you need a non-associative operation, like this: -- | -- &gt;&gt;&gt; foldr showParens "." ["a","b","c"] -- "(a (b (c .)))" -- &gt;&gt;&gt; foldl showParens "." ["a","b","c"] -- "(((. a) b) c)" showParens :: String -&gt; String -&gt; String showParens x y = "(" ++ x ++ " " ++ y ++ ")" &gt; To explore a little further I implemented a version with the `mappend` operation reversed and I get what looks to me like the output I would expect for an "opposite fold" I see from your code that you mean an implementation of `foldMap` which traverses the elements in the opposite order. Traversing the elements in the opposite order causes both `foldr` and `foldl` to behave differently: foldr1 f (reverse [x,y,z]) = z `f` (y `f` x) foldl1 f (reverse [x,y,z]) = (z `f` y) `f` x So I guess the confusion comes from the fact that there are four ways to flatten the elements of a list using a binary operation `f`, not two: 1. from left to right, giving `f` the accumulated value then the next element 2. from left to right, giving `f` the next element then the accumulated value 3. from right to left, giving `f` the accumulated value then the next element 4. from right to left, giving `f` the next element then the accumulated value `foldl` and `foldr` use methods 1 and 4, but I guess you expected 1 and 3. Anyway, all of this was a nice detour through Foldable, but the original question was about catamorphisms, not Foldable! Foldable's `foldr` and [Recursive](https://hackage.haskell.org/package/recursion-schemes-5.0.2/docs/Data-Functor-Foldable.html#t:Recursive)'s `cata` are both generalizations of the `foldr` on lists which apply to more data structures than just lists, but they generalize it in different ways: Foldable.foldr fCons fNil [1,2,3,4] = fCons 1 (fCons 2 (fCons 3 (fCons 4 fNil))) Foldable.foldr fCons fNil ((Leaf 1 `Branch` Leaf 2) `Branch` (Leaf 3 `Branch` Leaf 4) = fCons 1 (fCons 2 (fCons 3 (fCons 4 fNil))) data List a = Nil | Cons a (List a) data ListF a r = NilF | ConsF a r Recursive.cata f [1,2,3,4] = f (ConsF 1 (f (ConsF 2 (f (ConsF 3 (f (ConsF 4 (f NilF)))))))) data Tree a = Leaf a | Branch (Tree a) (Tree a) data TreeF a r = LeafF a | BranchF r r Recursive.cata f ((Leaf 1 `Branch` Leaf 2) `Branch` (Leaf 3 `Branch` Leaf 4) = f (BranchF (f (BranchF (f (LeafF 1)) (f (LeafF 2))) (f (BranchF (f (LeafF 3)) (f (LeafF 4)))) The details are a bit complicated, but as you can see, `Foldable.foldr` flattens the tree into a flat sequence of elements and then combines those elements starting from the right, whereas `cata` preserves the tree's structure and then combines each layer starting from the leaves. So when /u/Faucelme mentioned a computation which starts from the root instead and you mentioned `foldl`, I thought you wanted to generalize `foldl` in the same way in which `cata` generalizes `foldr`, except it would start from the root instead of the leaves. I don't think such a generalization is possible, but who knows?
That looks very cool man. maybe a screenshot on README ? starred
&gt; So when /u/Faucelme mentioned a computation which starts from the root instead and you mentioned foldl If you think of a list as a tree where in which nodes have at most one child, `foldl` does start from the root, doesn't it? And you can get `foldl` from `foldr`using the "returning a function" trick.
Well, if you ~~build~~ (or `new-build`) the package you get this (I removed the `aeson` dep): ☃ /tmp/tmp.Q6J8nR3KSe $ cabal new-build Build profile: -w ghc-8.0.2 -O1 In order, the following will be built (use -v for more details): - tmp-Q6J8nR3KSe-0.1.0.0 (lib) (first run) Configuring library for tmp-Q6J8nR3KSe-0.1.0.0.. Warning: The 'license-file' field refers to the file 'LICENSE' which does not exist. Preprocessing library for tmp-Q6J8nR3KSe-0.1.0.0.. Building library for tmp-Q6J8nR3KSe-0.1.0.0.. [1 of 1] Compiling Main ( Main.hs, /tmp/tmp.Q6J8nR3KSe/dist-newstyle/build/x86_64-linux/ghc-8.0.2/tmp-Q6J8nR3KSe-0.1.0.0/build/Main.o ) Main.hs:3:1: error: Failed to load interface for ‘Data.Aeson’ It is a member of the hidden package ‘aeson-1.2.1.0’. Perhaps you need to add ‘aeson’ to the build-depends in your .cabal file. It is a member of the hidden package ‘aeson-1.1.2.0’. Perhaps you need to add ‘aeson’ to the build-depends in your .cabal file. Use -v to see a list of the files searched for. I'm not aware of a way to automatically edit the `.cabal` file, but the error should suffice. EDIT: I just found out that this doesn't work if you don't have that package cached in the store. I don't know if there is a workaround. 
It should return the input unchanged, because this should be isomorphic to any other two constructor data type that isn't boolean.
With `Data.Dynamic`. However there is a `Typable` constraint... import Data.Dynamic import Unsafe.Coerce badId :: Typeable t =&gt; t -&gt; t badId v = case (fromDynamic (toDyn v)) of Just True -&gt; unsafeCoerce False Just False -&gt; unsafeCoerce True Nothing -&gt; v
Yeah, that trick works for lists, but how can you generalize it to other data structures? For completeness, let me begin with the list version: -- | -- &gt;&gt;&gt; list_trick showParens "." ["a","b","c"] -- "(((. a) b) c)" list_trick :: forall a b. (a -&gt; b -&gt; a) -&gt; a -&gt; [b] -&gt; a list_trick f a0 xs = cata g xs a0 where g :: ListF b (a -&gt; a) -&gt; (a -&gt; a) g Nil a = a g (Cons b cc) a = cc (a `f` b) If I understand your situation correctly, you are starting with a tree whose internal nodes are labelled with `b`s. You then pick an initial `a0` value for the accumulator, and you go down the different paths from the root to the leaves, accumulating the `b` values as you encounter them, and re-labelling your internal nodes with the `a` value computed for the path so far. At the end, you have a new tree whose internal nodes are labelled with `a`s, and each `a` is only computed from the `b`s which were above it, so it looks like the information has travelled from the root down, like `foldl` does. data TreeF a r = LeafF | BranchF a r r deriving Functor type Tree a = Fix (TreeF a) -- | -- &gt;&gt;&gt; :{ -- let t = Fix (BranchF "root" -- (Fix (BranchF "left" -- (Fix LeafF) -- (Fix LeafF))) -- (Fix (BranchF "right" -- (Fix LeafF) -- (Fix LeafF)))) -- :} -- -- &gt;&gt;&gt; tree_trick showParens "." t -- Fix (BranchF "(. root)" -- (Fix (BranchF "((. root) left)" -- (Fix LeafF) -- (Fix LeafF))) -- (Fix (BranchF "((. root) right)" -- (Fix LeafF) -- (Fix LeafF)))) tree_trick :: forall a b. (a -&gt; b -&gt; a) -&gt; a -&gt; Tree b -&gt; Tree a tree_trick f a0 xs = cata g xs a0 where g :: TreeF b (a -&gt; Tree a) -&gt; (a -&gt; Tree a) g LeafF _ = Fix LeafF g (BranchF b ccL ccR) a = let a' = a `f` b in Fix $ BranchF a' (ccL a') (ccR a') But while `tree_trick` uses the same return-a-function trick as `list_trick`, the functions are very different! `list_trick` is a _fold_, that is, it collapses the list down to a single value. `tree_trick` is a [_scan_](http://hackage.haskell.org/package/base-4.10.0.0/docs/Prelude.html#v:scanl), that is, it preserves the tree structure instead of collapsing it. When I try to generalize `tree_trick` so it can return an arbitrary `a` instead of a `Tree a`, I end up adding the equivalent of a `TreeF a -&gt; a` to `tree_trick`'s input, making it more like a combined scanl+foldr than a foldl. It only _looked_ like the information travelled downwards from the root to the leaves, in fact the information travelled back from the leaves to the root as well, so that the new tree could be constructed from its new leaves!
Do you mean a [metamorphism](https://github.com/sellout/recursion-scheme-talk/blob/master/cheat%20sheet.pdf)?
Saying that `m` is a `Monad` means that there is a specific API you can use with `m`. Namely everything `Applicative` can use and also `&gt;&gt;=` which has the type signature `Monad m =&gt; m a -&gt; (a -&gt; m b) -&gt; m b`, and you also know that it will behave as you expect. *** behave as expected means that for some expressions using this function you should get a specific result no matter which monad you use. if it's Monad, Either a, IO, or something else. for example, if you write `pure arg &gt;&gt;= func` it should be the same as just writing `func arg` no matter which underlying monad you use. However, this API does not let you extract a value out. so saying something is a monad does not mean that there's a function with the type signature `Monad m =&gt; m a -&gt; a`. Just like saying that something is an Applicative does not mean that you can use `&gt;&gt;=` on it. Both `Maybe` and `IO` are monads, which means you can use `&gt;&gt;=` on both. But it does not mean you can extract from both. extracting is not part of the API for monads. The creators of Haskell did not implement the API for extracting a value from IO for a variety of reasons, but one of them is because it makes lazy evaluation problematic. You can read more about the reasons and the solution in [this article](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/07/mark.pdf). btw, I don't know category theory and i haven't read the book you linked and am not planning to any time soon. You can be very productive in Haskell without knowing anything about category theory, type-level programming, GADTs, type families and other fancy features. I think I'm doing just fine for now. Even so, it is true that the community likes and tends to talk about these features a lot. 
Groundhog cannot express joins. If you want to treat your database as a key-value store, groundhog is fine. If not, I cannot recommend it.
This is beautifully horrible, excellent work!
Fascinating! I was expecting to learn some horrible truths about Haskell, but this is also pretty useful to know!
&gt; But I also had an off-and-on relationship with the language for a little while before everything fell into place in my mind and I was able to productively use it as my main language. Exactly my experience too. 
Great idea - thanks! I just starred all my immediate deps.
And then had doubts. I have devalued my star! It's no longer a considered vote of approval. I'll never get around to reviewing/unstarring. Oh well. :-)
That could be very hard. /u/dmwit's solution *might* do it, but nothing else will.
To avoid `unsafeCoerce` thunks when compiling without optimization, you can either use `unsafeCoerce#` from `GHC.Exts` or use `unsafeCoerce reallyUnsafePtrEquality p q`, coercing the equality test instead of its operands.
That's a good point, but persistent can't either, can it ?
I had the same experience with Applicative. I started with LYAH and could never figure out what Applicative could actually be used for. Then I saw some code where someone just used it to lift a data constructor over a monadic context. That was the moment it first became useful to me.
I was looking at the recent post with the apecs ecs rts example. The package has an sdl2 binding package as a extra-dep because the example binary uses sdl2 - but the library itself appears to not need sdl2 at all (unless I've missed something). So depending on the apecs package, stack pulls and builds the sdl2 bindings package (and a bunch of other stuff) Is there a way to tell stack/hpack that I only want the apecs library itself pulled and built and not to grab anything the executables depend on that the library doesn't? (I'm running around googling and looking at docs too, but I figured I'd ask) 
`stack script` is a bit faster, IIRC.
I've seen Very Bad Things happen with eta-reduced rules in the past (where they'll somehow prevent other important optimizations when they don't fire). I don't know if that still happens.
That is why they are *not* entirely equivalent. They would be equivalent in *classical* logic, but Haskell types are much closer to *constructive* logic. It's impossible to write a legitimate term of type f :: Either (x :~: Bool) ((x :~: Bool) -&gt; Void) which is the form of excluded middle you'd need.
To me this appears as rambling without much insight. I'm not reading such posts for entertainment, but for knowledge. If they're entertaining, too, then that's a plus. But first they have to provide some good and accessible information.
But esqueleto can. If you're using persistent, you can always add esqueleto on top, and then you're able to do joins. If esqueleto didn't exist, then I would regard groundhog and persistent as equal.
Persistent can't but esqueleto can and esqueleto builds on top of persistent.
I used the same idea and came up with a similar solution, but this doesn't work in ghci unfortunately. I suppose it is because of different memory management used by the bytecode interpreter. *edit*: Ok, this works in ghci as well: {-# LANGUAGE MagicHash #-} import GHC.Prim main = do print (badId True) print (badId False) print (badId "test") badId x = let y = unsafeCoerce# x in y `seq` case reallyUnsafePtrEquality# True y of 0# -&gt; case reallyUnsafePtrEquality# False y of 0# -&gt; x 1# -&gt; unsafeCoerce# True 1# -&gt; unsafeCoerce# False To get my version working in ghci I had to introduce the let binding, effectively forcing the application of unsafeCoerce# (edit2: as /u/davidfeuer mentioned) 
I'm such a beginner that I can't call myself a Haskeller yet, but even looking into the future, I might stick with python when it comes to automating the web browser. When checking out the webdriver module for Haskell, I see a lot of dead links for what's supposed to be documentation. There's not a lot of evidence that many people who automate web browsers regularly use Haskell anyways. 
Access to MS Sql, Oracle and DB2 via jdbc. 
That would be pretty nice.
Thanks for the feedback! To be honest, it was mostly just me working through the implementation, so I can see it coming across as stream of thought/rambling. I'll work on this in future posts :) Nonetheless, I'd recommend trying to implement yourself. You get a better intuition for the structure and will probably glean a better understanding for it yourself.
1.5 sounded a bit too good, so I also ran it on my computer. The parallel c++ was 18~20 times faster than parallel haskell (40 threads, 2x10 core xeon + HT).
The final source code for this part can be grabbed from https://github.com/mcapodici/haskellfun/tree/master/googletasks/part2 I'll add part 1 to the repo soon as well.
Not at my computer right now, so I'll just drop a hint: Use `ghc-heap-view`!
[removed]
`perl`. Surprised that I'm the only one. Maybe I'm just old compared to those Pythonites here :-)
[removed]
I really liked this! I love seeing posts using typed holes to work through concepts in Haskell.
[removed]
This does not go far enough {-# RULES "goodIdBadIdea" id = badId #-}
I missed answering why a submodule instead of a docs directory. Having it as a submodule keeps the wiki separate and if required can be decoupled in a later stage of the project. Once the project grows and stabilises, the wiki can indeed see a lot more contribution from non-developers and maybe some vandalism (Every developer secretly wishes that the project becomes successful that it start seeing trolls and vandals).
We've got a lot more posts to come, but I figured I'd get the ball rolling with this one to keep them flowing in reasonably-sized pieces. I'm pretty excited about getting this out the door so that more people can play with `reflex` and see what it has to offer.
Great article! I have one of that exact fashion I was preparing to release. It seems we have a lot of idea collisions! Quite validating ;)
I haven't look into games stuff deeply so have no tutorial recommendation, but ... Haskell seems like an unusual language to build games with. :)
Teaching someone to make a game in Haskell starting from not knowing it at all is a decidedly non-trivial exercise, so you may have trouble finding someone willing to invest the time... but there are plenty of implementations of various games available on github for study, eg. this one which is the top hit on a google search for "pong in haskell": https://github.com/rtperson/Haskell-Pong You might also be interested in the [Helm game engine](http://helm-engine.org/) which does a lot of the heavy lifting for you and will reduce the amount of Haskell concepts you need to learn upfront. And lastly you might find this Pong implementation by /u/edwardkmett enlightening (his code often is): https://github.com/ekmett/lens/blob/master/examples/Pong.hs 
If you want to do graphics for your first project in Haskell you might want to try out the gloss library as it's pretty clean and simple (but not efficient I'm told). There's a lot of tutorials for learning Haskell but relatively few for writing a game in Haskell. There is a guy who is writing a rogue like in Haskell though and that was pretty neat. I think he was using SDL 2 but you may have better luck searching to find other game libraries. Edit: My autocorrect knows about SSL but not SDL (thanks u/theslimde) Edit: It was OpenGL not SDL2
To answer some of your questions: &gt; How often do you use the Hackage website? For documentation. Either trying to remember how to use a function/class, or after searching for a function on Hoogle/Hayoo. Yes, apparently I need to build my own Haddocks locally, but I have yet to get around to it. &gt; Are you usually logged in with an account, or not? I only log in to upload a package distribution. IIRC the site kicks you out quite quickly when you're inactive. You only need to log in to do admin stuff and give votes; to use it as a source of documentation, there's no need to even create an account. &gt; Do you keep it open in browser tab? Too many tabs, to be honest. But that's not necessary. It's pretty quick to type `hackage.haskell.org/package/acme` in the address bar when I wish to look up a package. &gt; Is there some other app or resource that you use to get the Hackage content besides the `hackage.haskell.org` app? Ostensibly, Stackage. But IMHO Stackage cannot serve as a replacement for Hackage, for the very simple reason that it does not display all available versions of a package, only the one in the current snapshot. I very rarely use Stackage for documentation, and half of the times I have tried to look up documentation on Stackage it was because someone linked to it directly (I would then very quickly look up the same package on Hackage and carry on there). &gt; When you go to a package's home page what do you use it for? Very often, to see what the thing does! Of course, far too many packages haven't even the bare minimum of documentation -- a short blurb explaining *what the package even does*. And now, with `stack new`, you have countless packages uploded to Hackage whose blurb reads "See the README file for details" with nary a `README` file in sight... &gt; How do you figure out if a library is well maintained, or is abandonware? Haskell (aka GHC) has been changing quite rapidly in the last half a decade. If the last time your package was uploaded more than two years ago, it will probably fail to compile with the latest compiler/libraries, and I will assume you have abandoned it. &gt; Do you upvote libraries you like? lol no
Yes, it's exactly the things I'd think myself. I think it would be better if you would keep it a bit more dry/with less random rambling. Informal speech is ok, but many of your sentences just don't convey anything useful.
As much as I would love to read this article, a popup saying "Can I help you with DevOps or server software?" right in the middle of reading it is a pretty massive turnoff. Sorry.
Just for the record, Niklas Haas wrote most of that example, but it is still enlightening. =)
Yes the performances are awefull with a high number of threads ;( how does it behaves with on thread one your computer? my experiences ranges between 1.2 times slower to 2 times slower. Edit: thx garbage collector is known to be not really efficient with lot of threads on numa machine (which I suppose you have). Perhaps GHC 8.2 changes in that area may improve the situation.
Agreed, I also find the advertising to be a bit too invasive. Then again, nobody’s forcing you too read it and everybody can decide for themselves how they want to make their content available.
Gloss will be plenty fast for Pong of course.
I made Tic-Tac-Toe in Haskell using the Gloss library. It had a user interface and an unbeatable AI. I was a newbie when I wrote it, and in the end it was 100 lines of code. I distinctly remember that I had one (and only one) bug during development, and never had a runtime error. Yeah, Haskell isn't a popular language for writing games, but it does have some pretty big advantages IMO. Take a look: https://github.com/DevJac/gloss-tic-tac-toe/blob/master/src/Main.hs I can't say it's good coding style, but it's basic Haskell.
[removed]
That's a good overview of the `cryptonite` hashing API. However, `cryptonite` is a big monolithic batteries-included crypto library and from a maintenance &amp; code-audit POV you may prefer (especially if all you need is a single hash function for e.g. hashing file contents) a more focused and stable alternative which is declared ready for production (NB: `cryptonite` is still not considered production-ready by its author); my previous [comments about the `cryptohash` package](https://www.reddit.com/r/haskell/comments/5lxv75/psa_please_use_unique_module_names_when_uploading/dbzegx3/) are still relevant. Besides, in the category of batteries-included crypto libraries, a more promising alternative to `cryptonite` to keep an eye on is [`raaz`](http://hackage.haskell.org/package/raaz) imho.
That's a good post but, besides what the author says, it does not explain where Free comes from. We have seen this presentation many times. Note that it is a good presentation, just not as new as the author claim. To understand where Free comes from it would be nice to see it's alternative definition, the catamorphic defunition: data Free f a = forall (M :: * -&gt; *). Monad m, Functor f =&gt; (f a -&gt; m a) -&gt; (Free f a -&gt; m a) Then talk about monads as F-algebras. Free as the free stucture of this monad F-algebra and finally it's encoding as a algebraic data type.
Sure. Just saying that *if* you want people to read your stuff, then this might not be the best way.
Cryptographic hashing is one area where raaz is feature equivalent with cryptonite. Plus it has some high level routines like `hashFile` function and all the hashes have a show instance that returns the hash in base16. So you would need only the main loop (not tested) import System.Environment import Raaz.Hash main :: IO () main = do args &lt;- getArgs forM_ args $ \fp -&gt; do digest &lt;- hashFile fp putStrLn $ show (digest :: BLAKE2b) ++ " " ++ fp A digest value `d` can also be encoded in base64 (or any of the future encodings that we might support) using `encode d :: Base64`. 
According to [Hackage](https://hackage.haskell.org/package/apecs) apecs does have sdl2 as dependency. &gt; Is there a way to tell stack/hpack that I only want the apecs library itself pulled and built `stack build &lt;package&gt;` should work for that afaik.
That's why I'd say you shouldn't try to model a restriction or a negative, such as having `MonadFileIO` that promises to only touch the file system, or `MonadNetworkIO` that promises to only touch the network. You should instead model the actual purpose of your `IO`, e.g `MonadLogger`, `MonadDB` etc. This allows you to mock such interfaces in a non-IO way for tests and debugging, and also tells you that functions of type `MonadLogger m =&gt; Foo -&gt; m Bar` are only able to call the functions defined in `MonadLogger`. But at the same time it doesn't lie to you about what `IO` can be performed.
I really wish a mod would just go through and ban these non constructive bots. They're fine on subs like r/askreddit but they're just annoying as hell on smaller subreddits
*SDL 2
The compiler replaces them internally with uncurried calls when possible for performance reasons. Partial application incurs a overhead that is usually not an issue when a function is actually partially applied. But treating a fully applied call as a list of partial applications would lead to pretty bad performance. 
Thanks for the feedback, and glad you enjoyed the post! I don't know any about any of that stuff, but hopefully I'll get around to it eventually! I want to go through Bartosz's articles at some point :)
Fair enough. I use persistent without esqueleto. When I need a join, I either do it manually, or use raw sql with `??` which kind of works. I know it's not perfect but I haven't had the time to invest in esqueleto. I think groundhog can do similar thing (but am I be wrong). However, groundhog seems to have better support for custom migration and composite type. But as I said before, I haven't used groundhog, just considering using it a while ok. 
That's for hidden packages, isn't it. Does it work for missing packages ? I guess another option is to just nuke and reinitiale the cabal file each time you need a new package.
convertToBase / convertFromBase work exclusively with bytearray like types. the Show instance of Digest is already in base16. edit: Also I'm not sure your definition of "feature equivalent" but you're missing Whirlpool,Tiger,MD2,MD4,MD5,SHA3,Skein,Keccak,Sha512t,RIPEMD160,SHAKE before having the equivalent set.
Looking forward to more of your blog posts on reflex and nixos! :)
There's never any need to use abstractions you don't know. In fact, I think it's better to first do without the abstraction to later appreciate its power. 
Please don't call MD5 `(slightly outdated)`. In the context of cryptographic hashing that is like calling Brainfuck a sensible programming language. From a crypto point of view MD5 is not *outdated* it is **broken**. 
It doesn't, but with new-build every package ever built is an hidden package.
Hi /u/mboes, what are the advantages of Apache Spark over and above avoiding Java&lt;-&gt;Haskell by instead using Cloud Haskell for distributed computation?
When should I use `Maybe` and `Either` respectively?
What are the options then? I ran into the same problem with my experimental stuff; it scaled pretty badly on my dual CPU machine. With C++ we usually pin threads to cores to avoid them wandering around, but it more affects cases where lots of memory involved (like textures and such). In yours, there isn't much data to process. Btw, using 8.2.1 the results are the following. I enabled some extra optimization options on gcc-5.3.1 but had to disable llvm. 1 -&gt; 2.52 5 -&gt; 5.1 10 -&gt; 8.0 20 -&gt; 17.4 40 -&gt; 16.9 ICC seems to be slightly better than gcc on multiple threads, but the difference is not much.
I'm not sure why you call that definition the 'catamorphic definition'? It is the realization of the definition that the free monad is a free monoid in the monoidal category where the monoids are monads. (or actually just the definition of a free object is sufficient to explain it I think) The fact that we use the inductive definition based on an initial algebra is because the initial algebra for a certain endofunctor (which looks like `I + F ⊗ -`) induces the free monoid, and in the corresponding category we get a free monad.
Cabal uses `-hide-all-packages` even without `new-build`, but unless you have a package installed in some package DB (e.g. in the new-build store), GHC won't be able to give you that nice suggestion.
To set the record straight - Vincent's suite of crypto libraries, including `cryptonite` and `cryptohash`, are used widely in critical production deployments, including for major enterprises. We are among the users. I don't think there's much to argue about them being the *de facto* standard for cryptography in Haskell, as stated by OP. The crypto code is very well written, very well maintained, and covers all of the common use cases quite thoroughly. I feel far safer using these libraries than, say, OpenSSL, and that's great. It's true that versioning, library organization, dependency specifications and other cabal-file-related details, etc., use a very different approach than what I would do. But now that Haskell's build tools are so much more mature, that is only a small side point. We have had zero build issues with these libraries in recent years, neither with cabal nor with stack.
This is a great practical overview of these important and popular libraries. The only thing I would change is adding a mention of Vincent's name on the first line.
I have a program that have a structure like this : data Exp = AddE Exp Exp | NumberE Int ... data Dec = VarD String Exp ... if i want to visit the nodes i have to create a datastructure data Node = ExpN exp | DecN Dec so to visit it i need to create a function like this : prettyPrinter:: Node -&gt; String prettyPrinter (ExpN (AddE x x)) = prettyPrinter (ExpN x) ++ " + " ++ prettyPrinter (ExpN x) ... I find this a little bit ugly, is there a way to create a class (or anything that makes the code better looking) and pattern match like this : prettyPrinter:: (Ast a) =&gt; a -&gt; String prettyPrinter AddE x x = prettyPrinter x ++ " + " ++ prettyPrinter x ...
Thanks yitz for the kind words now (and in the past), but I'ld also like to publicly acknowledge the jolly good work of the other commiters&amp;maintainers of cryptonite too (github: ocheron, tekul, centromere). Also thanks to all the contributors adding bits and pieces to make things better and share the maintenance.
Yeah, just might be worth learning something more reusable. Gloss will be fine for this
Sure: 1. We'll use gloss, make sure you can run [this example](https://github.com/benl23x5/gloss/blob/master/gloss-examples/picture/GameEvent/Main.hs). 2. Refactor the `(\str -&gt; Translate (-340) 0 $ Scale 0.1 0.1 $ Text str)` to a separate function `draw :: String -&gt; Picture`. 3. Experiment with the different [Picture primitives](http://hackage.haskell.org/package/gloss-1.11.1.1/docs/Graphics-Gloss-Data-Picture.html#t:Picture) and use them to draw what a screenshot of pong would look like, including two paddles, two scores, and a ball. 4. Try to think of the information you would need in order to draw the next frame. Where are the paddles? Are they moving? In which direction? What about the ball? Create a data type `PongState` which holds that information. 5. Refactor the `(\_ world -&gt; world)` to a separate function `update :: Float -&gt; String -&gt; String`. You can find the type of all those functions [here](http://hackage.haskell.org/package/gloss-1.11.1.1/docs/Graphics-Gloss.html#v:play). Notice that we're currently using `String` instead of `world`. 6. Use the data type you just created instead of `String` (so `update :: Float -&gt; PongState -&gt; PongState`), and let the compiler's type errors tell you where else you need to change from `String` to `PongState`. 7. The `Float` is the number of seconds which have elapsed since the last call to `update`. Use that to compute the new position of the ball and the paddles, and modify your `draw` function to draw the ball and the paddles at the position specified by the `PongState`. 8. Refactor the `(\event _ -&gt; show event)` to a function `onInput :: Event -&gt; PongState -&gt; PongState` 9. Examine the different [events](http://hackage.haskell.org/package/gloss-1.11.1.1/docs/Graphics-Gloss-Interface-IO-Game.html#t:Event) which come in as you press keys. Pattern-match on the events which interest you (presumably the key down and key up events for two pairs of keys on both sides of the keyboard, maybe `W` and `S` on one side and the up and down arrow keys on the other), and update your `PongState` accordingly 10. Tweak your `PongState` and your `update` to add features like bouncing the ball on the paddles and keeping score. Have fun!
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [benl23x5/gloss/.../**Main.hs** (master → 72df67b)](https://github.com/benl23x5/gloss/blob/72df67b4eb06db44ae1f37a8949a2883739383fc/gloss-examples/picture/GameEvent/Main.hs) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dn5yf8i.)^.
Is it possible to implement `Maybe` monad in dynamic language? How?
&gt; How often do you use the Hackage website? I use it whenever something isn't on Stackage, which isn't very often these days. &gt; Are you usually logged in with an account, or not? I don't think I'm ever logged in. Does anything even change when you log in? I don't even log in to upload packages; that's handled automatically by my CI builds. &gt; Do you keep it open in browser tab? No. If I type `h` in Chrome's URL bar, searching Hackage is the first thing to come up. So If I want to find some package, all I need to do is `h&lt;tab&gt;package-name`. (The same thing is true for Stackage, except that it starts with `s` and it also searches with Hoogle instead of just package names.) &gt; What questions do you go to the site to answer? I go on Hackage to look up package-level metadata and to read module documentation. I think the module documentation on Stackage is better, but Hackage does a better job showing the package-level metadata. But a lot of the time all I want is a link to GitHub, and both sites do that well. &gt; Is there some other app or resource that you use to get the Hackage content besides the hackage.haskell.org app? Google. Searching for "haskell &lt;whatever&gt;" is often a better way to find a package than going to Hackage and searching for "whatever". &gt; When you go to a package's home page what do you use it for? Sort of covered this already, but I use the package homepage to discover who wrote it, how it's licensed, what version it uses, when it was last updated, where the source is hosted, and which dependencies it has. &gt; Do you use the Modules section on the home page? Does it serve as the initial link into the API docs? Yes, absolutely! How else can you get to module documentation? &gt; How do you figure out if a library is well maintained, or is abandonware? I look at the date of the last upload first. If that's old, it doesn't mean something has been abandoned, but it's not a good sign. The other clue I'll use it to go to the source repository (almost always GitHub) and look through the issues. Does the developer respond quickly? Also worth noting here that I generally perceive stuff on Stackage as not being abandoned. &gt; On a particular library page (nomenclature?) what do the Instances sections tell you? I generally don't look at the list of instances. However I will if they have documentation attached to them (not common) or I was hunting for them in the first place. Sometimes the instances are incredibly important even though the documentation doesn't really tell you that. For example, [`UTCTime`](https://hackage.haskell.org/package/time-1.8.0.3/docs/Data-Time-Clock.html#t:UTCTime) is used pretty much entirely through instances. &gt; Do you upvote libraries you like? No. As I mentioned before, I'm basically never logged in. And since Hackage uses HTTP basic auth, account management is pretty rough. So logging in every time I want to vote on a library is a waste of time. I may star something on GitHub if I particularly like it. &gt; What are some use cases that takes you to the hackage web app, and what do you do? I.e., where do you look, and what do you click? What areas are important, and which do you ignore? This is a pretty broad question, so I'll just touch on some highlights: - I pretty much only use search. I never browse, never look at what's new, never do any "maintenance" tasks (like revising or tagging), never look at build logs, and never download source. I sometimes use the API to download the tarball of package descriptions, but otherwise I don't use the API either. - The list of versions on a package home page is super important. It's the only way to switch between versions. That's a problem in my opinion. It would be nice to be able to switch between versions while browsing a particular module within a package. - The list of dependencies for a package is pretty tough to read, but it's important for understanding how "heavy" that package will be. Does it depend on something large, like `amazonka-s3`? Then I probably won't add it to my slim library. Does it depend on a lot of low-level packages like `bytestring`, `text`, and `network`? That's fine. Everyone has them installed anyway. - Pro tip: The top right of every module page has a "Contents" link that will take you back to the package description. I use this link *all the time*. It's a convenient way to jump between modules in a package.
I was toying around with something almost exactly like this a month or so ago. I ended up making a `LoggingT` transformer with a few instances defined for it: https://github.com/jkachmar/servant-persistent-realworld/blob/master/src/Logging.hs ...that way I can use it with Persistent as well as the `App` proper: https://github.com/jkachmar/servant-persistent-realworld/blob/master/src/Foundation.hs#L106 https://github.com/jkachmar/servant-persistent-realworld/blob/master/src/App.hs#L48 ...and I can use the utility functions anywhere since I've defined the necessary instances for my `App`: https://github.com/jkachmar/servant-persistent-realworld/blob/master/src/Foundation.hs#L62 https://github.com/jkachmar/servant-persistent-realworld/blob/master/src/Api/User.hs#L59
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [jkachmar/servant-persistent-realworld/.../**Foundation.hs#L106** (master → 0b01f85)](https://github.com/jkachmar/servant-persistent-realworld/blob/0b01f85492d931d48bae24e674cfc022c420f50c/src/Foundation.hs#L106) * [jkachmar/servant-persistent-realworld/.../**Foundation.hs#L62** (master → 0b01f85)](https://github.com/jkachmar/servant-persistent-realworld/blob/0b01f85492d931d48bae24e674cfc022c420f50c/src/Foundation.hs#L62) * [jkachmar/servant-persistent-realworld/.../**Logging.hs** (master → 0b01f85)](https://github.com/jkachmar/servant-persistent-realworld/blob/0b01f85492d931d48bae24e674cfc022c420f50c/src/Logging.hs) * [jkachmar/servant-persistent-realworld/.../**User.hs#L59** (master → 0b01f85)](https://github.com/jkachmar/servant-persistent-realworld/blob/0b01f85492d931d48bae24e674cfc022c420f50c/src/Api/User.hs#L59) * [jkachmar/servant-persistent-realworld/.../**App.hs#L48** (master → 0b01f85)](https://github.com/jkachmar/servant-persistent-realworld/blob/0b01f85492d931d48bae24e674cfc022c420f50c/src/App.hs#L48) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dn606iz.)^.
See also: [Elgot (Co)Algebras](http://comonad.com/reader/2008/elgot-coalgebras/) which I found via the recursion-schemes' doc.
Do [pattern synonyms](https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/glasgow_exts.html#pattern-synonyms) do what you want? https://ocharles.org.uk/blog/posts/2014-12-03-pattern-synonyms.html https://kseo.github.io/posts/2016-12-22-pattern-synonyms.html
This may interest you: [monad in javascript](https://curiosity-driven.org/monads-in-javascript) edit: code sample var result = new Just(5).bind(value =&gt; new Just(6).bind(value2 =&gt; new Just(value + value2))); print(result);
But how do you enforce that bind takes (a-&gt; Maybe a), what if it gets (x=&gt;x) instead? 
`Either () a` is equivalent to `Maybe a`, but the latter is simpler, so prefer it when it works. `Either` can be used as an anonymous sum type (like tuples are the anonymous product type), but the lack of `Either2` etc. makes that usage too bulky. The most common use of `Either` is to report an enumerated class of errors for a function that can fail to produce a meaningful answer. Say you have a function that inserts a key into a map, then looks up a key, and it is supposed to fail if the first key is present _or_ the second key is absent, you might want an `Either` to let the user know which of the two errors occurred. If it can only fail for one of the reasons, it's common to use `Maybe` instead, documenting the reason for `Nothing` One more use of `Either` is as a pure error reporting mechanism. This is commonly `Either String` and is often found in parser libraries (hidden behind their parse monad abstraction).
&gt; According to Hackage apecs does have sdl2 as dependency. If you click on the "[details](https://hackage.haskell.org/package/apecs-0.2.0.2/dependencies)" link next to those dependencies you will see what /u/anomie-p meant: sdl2, random and linear are dependencies of apecs's rts executable but not the apecs library. So if they only need to build a program which depends on the apecs library, not the rts executable, then they don't need to build sdl2. &gt;&gt; Is there a way to tell stack/hpack that I only want the apecs library itself pulled and built &gt; &gt; `stack build &lt;package&gt;` should work for that afaik. The apecs library doesn't seem to be in [the latest LTS](https://www.stackage.org/lts-9.5), so that won't work. I cloned the github repo and ran `stack build --dry-run`, and stack says it would build sdl2 even though it says that no executables would be installed.
Yes. I've been using Haskell for a few years now and it's my favorite language. I still enjoy using Ruby, Python, JavaScript, etc. Reasons being: the language has some library that looks fun or does something neat, or I know I'm going to throw away the project and I just want something quick, or the tooling is most convenient.
You can't really enforce a whole lot in JavaScript's "type system". But since it's basically a super ugly lisp with first class functions, you can do quite a bit of black magic to make it behave sorta functionally. You'll need something like typescript if you want a stronger type system for JavaScript though
&gt;One more use of `Either` is as a pure error reporting mechanism. This is commonly `Either String` and is often found in parser libraries (hidden behind their parse monad abstraction). Why don't they use `error` instead? Isn't it better if you can't recover from the error anyway? 
Does it mean you cannot use monads to implement pure IO in dynamic languages? 
A parser is an excellent example situation in which you do want to recover from the error: if you are writing a web application and a client makes a malformed request, you want to reply with an HTTP 400 error and a nice error message explaining in which way their request is malformed, you don't want to crash the server and stop handling future requests.
Did you mean that foldr and foldl use methods 1 and 2 instead of 1 and 4?
You probably need to embed/reimplement a type checker for that.
Well you can, monads and pure io can be thought of as a system. You play by the rules and everything works out. The only difference between monads in Haskell vs monads in JavaScript is if you cheat in Haskell, the compiler breaks and if you cheat in JavaScript nothing does and you might not even notice until later when things start breaking later. You can do anything in any turning complete language, it's just a matter of how easy it is and how the language helps you out. That's why people who love Haskell so much tend to like it more for it's typesystem and strict purity than for any other feature it has (type classes, monads, deriving, etc...)
That's cool
Well, even a simple Scotty app uses monad transformers :)
Agree with you on Reflex. But it sounds like he's talking about Nix, not NixOS. 
&gt; one of the advantages of Elgot algebras comes to the fore: we can effectively mix a "supercompiler" with normal recursion I don't see how the use of an Elgot algebra relates to the use of TH to precompute some of the answers. Wouldn't it have been even simpler to write this without the Elgot algebra? collatz :: Int -&gt; [Int] collatz 1 = [1] collatz 2 = $( lift (collatzTH 2) ) collatz 3 = $( lift (collatzTH 3) ) collatz 6 = $( lift (collatzTH 6) ) collatz 7 = $( lift (collatzTH 7) ) collatz 9 = $( lift (collatzTH 9) ) collatz 18 =$( lift (collatzTH 18) ) collatz n | n mod 2 == 0 = n:(collatz (div n 2)) | otherwise = n:(collatz (3 * n + 1))
I cannot help but wonder whether Haskell, if not Reflex, is the future of web development—whether [we'll be able to ride the Haskell wave over the long haul while the other guys will continue swinging from branch to branch looking for the next great thing](https://www.reddit.com/r/haskell/comments/6aqnoq/niklas_h_tells_us_that_well_be_able_to_ride_the/). But that's probably just my arrogance and wishful thinking speaking.
I strongly agree with this. Particularly since as [jaspervdj mentioned](https://www.reddit.com/r/haskell/comments/703a55/monadio_considered_harmful/dn1t93d/) access to one type of IO often gives you access to most of the outside world. So unless you are positive that the primitives you provide don't leak more power than the name implies I would shy away from that approach.
Once Haskell to webassembly and reflex mobile come out I think this is a very real possibility. Cross platform, high performance, app and web dev in Haskell sounds fantastic.
"from right to left, giving `f` the next element then the accumulated value", meaning that given the input `[x,y]` and the initial accumulator `z`, I start from the right with element `y`, giving `f` the `y` and the `z`, now the accumulated value is ``y `f` z``, next I move towards the left, I give `f` the `x` and the accumulated value ``y `f` z``, now the accumulated value is ``x `f` (y `f` z)``, and that is the final result.
Looks cool! I'd like to try it out, but the scripts don't load. 
Might be some relevant stuff for you here : https://lokathor.gitbooks.io/using-haskell/content/roguelike/
Yup, just fixed them, should be working now :) Sorry about that! :)
Ah, I gotcha now. Both of the folds process a list initially from left to right so that tripped me up a bit; I see what you're saying now.
Clearly raaz not feature equivalent to cryptonite in terms of the number of primitivies but if you just want to compute digest, the code is there. Supports (Sha-2 family and blake2 and a depreciated sha1). Raaz is not feature equivalent in terms of stability as well. So for production I would myself choose cryptonite as of now. That said I believe there are still some things where cryptonite should have made use of the strong typing of Haskell for more of type saftey. Raaz is mostly trying to see how far one can push the type system.
I think Cloud Haskell (or something like it) is what you'd want to use to *implement* Spark (or a successor to it). Spark is at a different layer of abstraction than Cloud Haskell. It provides a number of resilient data parallel operations (zips, maps, commutative folds, etc) and then much more on top. Including a full SQL-like query capability, a dataframe like abstraction, adaptors to HDFS, S3 and other data sources accessible from Hadoop.
/u/hvr_ I am happy that you are advertising raaz. I have also gained a lot of insights from the discussions and pull requests. However I wish you had not brought back the old reddit thread in this context. I for one believe that there are some USPs for raaz (despite being not so mature) particularly in the way we (try to) use types. I also believe that having a few selected primitives instead of the more kitchen sink approach is better for security. I also have concerns on the way randomness is handled, memory is locked and equality is checked. However, if the atmosphere is vicious as it has been for some time in the haskell community (and I am not taking sides here), it makes it very difficult to air such views. Issues cannot be examined critically solely on techinical merits without getting personal. 
&gt; or something sim None that I know of.
Who? I tried looking for it, but couldn't find it.
Thanks very much for that awesome and detailed reply. I've got a lot of homework now :)
[removed]
I've always wanted to see something like this. Great job.
&gt; With C++ we usually pin threads to cores to avoid them wandering around. The same can be applied to Haskell as well, especially, &gt; it more affects cases where lots of memory involved (like textures and such). In yours, there isn't much data to process. Actually there is a weird memory behavior that I don't understand, resulting to 60 Mo total memory in use (when it should only be 18 to store the image) AND 21 Giga bytes of allocated memory during the process. So there is definitely something weird with it which can really be the reason it scales so badly on numa. &gt; What are the options then? The changes in GHC 8.2 introduces: - the `--numa` flag: https://downloads.haskell.org/~ghc/master/users-guide/runtime_control.html#rts-flag---numa - the `-qn` flag: https://downloads.haskell.org/~ghc/master/users-guide/runtime_control.html#rts-flag--qn ⟨x⟩ In my case (the 6 core machine without numa), it does not change a lot, for reasons ;) I'll try to understand and fix the weird memory behavior soon.
Probably a reference to /u/Lokathor's [Complete Roguelike Tutorial](https://lokathor.gitbooks.io/using-haskell/content/roguelike/).
My tutorial is: * Sadly not complete at the moment :( * Using opengl + glfw to draw 2d graphics, not sdl2 I need to get back to it some day.
Couldn't you solve this with dynamic programming no template Haskell required? It would subsume the template Haskell and make the algorithm faster.
I'm with you with the strong typing; There's a plan going forward to improve integral and bytearray constraints into something that enforce more at the type level. We already have some minor improvement towards some of the constant (e.g. length of digest) related to cryptographic hashing now represented as type level natural. This is a very delicate balancing act though: * The types available by default in base are not expressive enough, thankfully some of basement types are getting ready to complete the gap (e.g. `Zn` also known as `Finite` in idris) * Most API are set in stone, so most of this will come in form of new additions (new type class &amp; new modules) or some tweaks when we're convinced the breakage is going to be minimal. * the set of GHC supported doesn't allow for a rich type support yet. when 7.8 and 7.10 are dropped, the APIs will be much better type-enforcement wise. Raaz obviously doesn't have the same problem here and have the advantage of not being stuck with the baggage.
That use of Template Haskell could also probably be replaced with some more explicit sharing: collatz1 = collatz' 1 collatz 1 = collatz1 collatz n | blah blah = collatz' n Right? At which point you might as well say collatz = memo collatz' I guess. 
Is https://joashc.github.io/posts/2016-03-23-free-monads.html correct as to how we get to the inductive definition?
That seems a little harsh. You're first sentence reads to me as "you didn't write what I wanted to read". Where could the author have done better? What insight were you hoping for but failed to be given? What did the author hand-wave past? When we identify things like that we *all* get to learn, but I think on a forum like this it should be an active participation. Down vote me as tone policing, but I think you could have at least been a little more constructive. 
`Exp` and `Dec` are not depending on each other. There is really no reason to not separate the functionality: ppNode :: Node -&gt; String ppNode (ExpN e) = ppExp e ppNode (DecN d) = ppDec d ppExp :: Exp -&gt; String ppDec :: Dec -&gt; String You can pack this functionality up into a class (see **ad-hoc polymorphism**) although it is not strictly necessary. It's more a matter of convenience since you will be using the same word (and changing a ADT name will break fewer code, especially when it's only in your code).
I had similar issues when starting out. I would say avoid using an abstraction or extension that you don’t understand until you have to, or suspect that it might be useful for solving your specific problem. Once you *have* to use it, you also don’t have to understand it deeply before *trying* to use it. Playing around in GHCi with what these tools actually *do* will give you a better concrete understanding of them than just reading tutorials and type signatures. As I discussed in [this comment](https://www.reddit.com/r/haskell/comments/70cttz/i_have_given_up_on_haskell_more_times_than_i_can/dn2vki0/), it’s enlightening to understand the concrete problem (especially repetitive code) that a particular abstraction solves. You might benefit from using *typed holes* (on by default since GHC 7.8.1): you can write `_` in place of an expression you don’t know how to write, and the compiler will tell you about relevant values you have in scope to help fill in the hole. Maybe that will make you more comfortable with the day-to-day business of putting Haskell’s general building blocks together to write useful code. I also spent a lot of my early Haskell months searching for functions I needed on [Hoogle](https://www.haskell.org/hoogle/) (you can also try [Stackage](https://www.stackage.org/)’s Hoogle instance), which helped me a lot to learn about what was even *available* for me to use. The community tends to be very accommodating if you have specific questions, which you can ask here, on Stack Overflow, on Freenode #haskell or #haskell-beginners, or the beginners@haskell.org mailing list. 
&gt; Why don't they use `error` instead? You actually can recover from `error` but only in `IO` by catching it. Also, `error` can only throw user errors and therefore only `String`s. &gt; Isn't it better if you can't recover from the error anyway? Absolutely not. For example, you might want use a sensible default value when you can't find a specific key in a map. Errors happen in reality and depending on a situation you don't want your application to crash (see u/gelisam's answer).
It's less the what, but more the how. I tried to clarify it in my response. And yes, probably I should have written in a more encouraging tone.
They are not quite isomorphic. `(,,) a b c` creates another indirection as the triple itself might be a thunk. Defining `f` with the wildcard pattern as in `f _ = ...` will not evaluate the thunk. You can use *unboxed tuples* for that. foo :: (a, b, c) -&gt; Bool foo _ = False foo undefined -- False, as undefined is not evaluated
Ah. I had hoped you'd continued, it was a cool project and I followed along for a bit. I really enjoyed reading you write ups. Thanks 
It might be feasible to distribute GHC Core, although you'd still have to keep around the Haskell types for type checking, and keep a mapping from said types to the GHC Core. It probably would not be worth it, because most of the heavy optimisation and inlining occurs *after* Haskell has been translated to Core. Distributing STG-code or Cmm would not work well, because these do not support the inlining and simplification that GHC depends on for the performance of its generated code. The fact that GHC depends so heavily on cross-module inlining presents problems for a lot of the usual techniques for separate compilation.
I think `error` _is_ a good call for unrecoverable errors, but since whether the error is recoverable or not depends on the context, I think most libraries and helper functions should prefer value-based error representations, which the application can then decide whether to convert into an exception-based error using `error` or `throwIO`.
It could probably be done portably, with some work. You'd need to have a story for dealing with different client side configurations. Think the `cabal configure` step plus whatever `Setup.hs` might be doing on a given package. Okay, so we could do it, but should we do it? I would hazard a guess that the better place (right now at least) to spend time reducing compilation time is in GHC itself. I know the linker has also been a bottleneck at times and I'm just not sure on the status of that. I'd certainly be in favor of faster compilation times. I do things locally to reduce compile times. I do my incremental development using `cabal new-repl` and `:r` as much as possible because it's faster than generating the code and often times I'm just trying to get it to compile. Additionally, I find that `cabal new-build` saves time compared to either sandboxes or stack as more of my build artifacts can be safely reused.
There's a few reason I'm aware of off the top of my head. - Mainly, Core is an in-memory representation. We have a dump format, but there is no proper textual Core language. Different flags vary the appearance of the dump format beyond any sensible grammar. One benefit of this is that Core can change arbitrarily with any GHC release; it has no backward compatibility concerns. IIRC, Core rarely stays the same between major GHC releases, so if anyone published Core on Hackage, their code would break very often, and it would often be impossible to support several GHC versions. - As you mentioned, platform dependency. Now, I believe the Core generated from any Haskell98/2010 file should be pretty much platform-independent. But as soon as you throw `-XCPP` into the mix, all bets are off. A single haskell file can represent infinitely many Core representations, just depending on where it gets compiled. - `-XCPP` causes further problems considering that Core often includes inlined snippets from imported modules. So even if you wrote Haskell98, you could end up with some Core in your package that contains some very platform/GHC dependent code. Same goes for stuff like the compiler flags used to compile to that Core, as many compiler flags will affect the Core representation. `-O2` for example, drastically affects how much code is inlined from other modules. The second and third point are mostly concerns with the idea of publishing precompiled Haskell as Core on Hackage. The current model of having users compile code for their configuration themselves is preferable. If you want precompiled libraries, Nix-style binary caches are the way to go (and this is a *huge* reason to use Nix). But the first point is pretty important to the idea of a proper Core language itself. If we're going to standardize the language for Core, we have to give up the flexibility GHC currently has with it. LLVM has had problems in this area with anyone that's using the IR language themselves rather than the LLVM API. That's not to say it's definitely not worth it; I think having a Core-level IR language for Haskell-like languages sounds immensely valuable. But it comes with a lot of considerations, most of which GHC doesn't currently need to think about.
Those writeups were about 80% of the work unfortunately. If i were to just plow ahead i could finish much faster, but the quality of the teaching would go way down. I will get back to it when I've got the steam for it. Hopefully it's already enough that people can start to see where they would expand their own game towards.
&gt; I would hazard a guess that the better place (right now at least) to spend time reducing compilation time is in GHC itself. I know the linker has also been a bottleneck at times and I'm just not sure on the status of that. Does the "reducing compilation time" includes considerations about SMP? Sometimes compilation takes like forever and I can see my CPU is using just one core, i.e. 12% of it's (theoretical) potential. That would be really big time saver.
That was the impression I got. Ive been wanting to start writing about Haskell and system design but the I just never seem to find the time.
We can write it tersely badid_1 :: a -&gt; a badid_1 = over _AltBool not -- over :: Prism' xs x -&gt; (x -&gt; x) -&gt; (xs -&gt; xs) -- (%~) :: Prism' xs x -&gt; (x -&gt; x) -&gt; (xs -&gt; xs) badid_2 :: a -&gt; a badid_2 = _AltBool%~not with a whimsical-looking [`Prism`](https://hackage.haskell.org/package/lens-4.15.1/docs/Control-Lens-Prism.html) _AltBool :: Prism' a Bool _AltBool = prism' unsafeCoerce (\a -&gt; if | isFalse a -&gt; Just False | isTrue a -&gt; Just True | otherwise -&gt; Nothing ) 
Reminds me of [stepping through a program in SWI-Prolog](https://i.stack.imgur.com/qVqV9.gif).
I was looking for the supercompiler but missed it. Could someone point me to where the supercompiler was invoked/referenced in this post?
The [README linked in the post](https://github.com/quchen/articles/blob/master/useful_techniques.md#poor-mans-supercompiler) explains the idea.
&gt; The top right of every module page has a "Contents" link that will take you back to the package description I lost count of the times I confused "Contents" with "Source" and "Index".
Jacob is in the same town as me, so he knows what other things I'm up to thanks to the local meetup group... :)
That's neat, but the singleton variable references are causing me to twitch.
https://ghc.haskell.org/trac/ghc/ticket/10871 https://phabricator.haskell.org/D1318
Ah, I see. Thanks for pointing that out for me. I had missed the link to the README.
Yes, this (and the “singleton” response) make a lot of sense. Thanks also for the link to the article. It seems, then, that monads, and maybe other parts of category theory, are being oversold. With the singleton pattern, the description is straightforward, as a solution to a particular problem, with no expectation that it should do anything more. Monads have this mythos of being *the* incredibly important, indispensable key to understanding what Haskell is all about, so I imbued them with mythical powers. [This article](https://two-wrongs.com/the-what-are-monads-fallacy) seems to be closer to the truth. That brings me back to Haskell; seeing discussions going to the fine points of theory drives me away again.
&gt; I think `error` _is_ a good call for unrecoverable errors I largely agree, my view on error handling (in general, not just in Haskell) heavily influenced by [this](http://joeduffyblog.com/2016/02/07/the-error-model/) blog post. To the extent to which I disagree, the following apply: * Haskell, being lazy, may have `error`s lurking in pure values, potentially leading to much confusion. * Haskell, not being a CSP model like Erlang (is Erlang actually CSP?) doesn't recover from failure gracefully without additional work. I find the following heuristic to be helpful: "Use `error` if, whenever that bit of code would execute, you personally accept fault and wish to be notified; if you do not believe it is your fault, or you accept that it is your fault but do not wish to be notified, don't use `error`."
ghc-proposal created as requested: https://github.com/ghc-proposals/ghc-proposals/pull/73
Most of the heavy optimization is "Core to Core", so its output is Core as well. Much less happens in STG, cmm, and codegen.
This is really neat. I feel obligated to mention Joachim's [ghc-vis](https://hackage.haskell.org/package/ghc-vis), which is another tool that provides a graph-based representation instead. I see these two tools as complementary.
Very cool. I'm working on something similar called [Duet](http://chrisdone.com/toys/duet-delta) which is an implementation of Haskell 98 plus or minus some features. There's a demo in the list of foldr va foldl. You can define sum or product types. It also includes defining type classes and you can choose a type class example and check "show instance dictionaries" to see explicit dictionary passing, which I think is also valuable for teaching. I haven't implemented superclasses yet. Also I don't have a core AST, there is only one AST, so what you put in is what you get out. I think your evaluator is similar to mine, and the rest of the code; type classes just make everything longer. I also used this to teach some newbies and it really helps to make partial application transparently obvious. As Duet will diverge from Haskell slightly and have a semantic editor, I've been meaning to release its current source under a different name as a "trivial" Haskell implementation that can be run in the browser. Maybe you could incorporate some of it into yours to get the extras like data types and classes. When I get back from vacation I can invite you to my WIP private repo. I'm glad other people in the community are into tools like this. Haskell is fantastically well suited to it, we really only lack interest in working on it!
Thanks for the reply. Maintaining a crypto library is a thankless job and I am glad that there is some one (/u/vincenthz) who is offering a stable option which can be used in production, while I get to do the more interesting (hack the types); see there are vested interests afterall. While fragmentation is a concern, I think time has come to seriously experiment with crypto code. For too long people have been shying away from building crypto due to the overhyped "crypto is hard" slogan. The result has been disasters like the OpenSSL. Raaz being an experimental offerings, can be opinionated, 1. Implement only few choosen primitives. I believe that in crypto one needs a one-trick pony design much like NaCl. 2. Depreciate standards as soon as a serious threats are demonstrated (sha1 is depreciated) 3. Careful desgn of api for things like password hashing, randomness, locked memory etc 
Type classes are part of the type system, and one of the things we like about it! One thing they do is let us make statements about how our types behave. The compiler doesn't check those, but if I trust the instance, I can rely on the properties that come with it.
Fair point! Most of what it enables is more generic functions so, while it's awesome, it's not necessarily the most killer feature that makes the rest of the functional paradigm so pleasant in Haskell vs other languages. (Although it is a very delicious icing on top)
&gt; I dove into Haskell and never looked back. How'd you manage that? I keep trying out new languages and crawling back to Haskell defeated. I imagine you've at least explored other languages a little.
Thanks for your nice article: now I decided to order (and ordered) the frp book mentioned there. Do you have other reading material on this topic you can recommend? E.g. papers, articles that are accessible to not-so-exp people?
The book that I mentioned is the best source that I know of. There is a nice article [here](https://alfredodinapoli.wordpress.com/2011/12/24/functional-reactive-programming-kick-starter-guide/) using `reactive-banana` - it is one of the resources that got me started on playing with FRP. There are a few things at the other end of the experience scale though. The [Real World Reflex](https://github.com/mightybyte/real-world-reflex) talk is great, and there are [other gems](https://www.reddit.com/r/reflexfrp/comments/6l5ddn/how_to_structure_a_reflex_application/) that appear from time to time on /r/reflexfrp, so it's worth keeping an eye on what appears over there.
Yes, `ghc-vis` is awesome, and it was what I would have used before this. What distinguishes the two tools is not so much the visual representation (a graph-based backend for `visualize-cbn` would be possible, and indeed I considered writing one); the big difference is that `ghc-vis` shows you the _actual_ representation in the ghc heap. That is both it's strength and it's weakness. For understanding real code, it can be _very_ helpful; for instance, the graphs in [my blog post about memory leaks with conduit](http://www.well-typed.com/blog/2016/09/sharing-conduit/) were generated with `ghc-vis`. But for understanding lazy evaluation, the real heap is often a little confusing; the focus of `visualize-cbn` is specifically to help understand the behaviour of tricky programs. So yes, I agree completely: the tools are complementary.
A faster, slightly more versatile Gloss would be amazing.
Non-constructive bots? Do they use the Axiom of Choice or the Law of the Excluded Middle?
Haskell is in fact better than Swift, Go, F# in terms of energy consumption and performance according to the paper published. 
That would be awesome. Modelling it after something like the processing JS approach (aiming for simplicity with the option of lower level work) would be huge
&gt; I CAN write safe C++. Yes, but assuming you're not a robot, you'll make at least a few mistakes once in a while... and this is where language choices becomes more than "just" ergonomics. For example, it's impossible to introduce buffer overflows in the safe subset of Rust. I'm using 'impossible' in the colloquial sense -- we're obviously assuming that there's a proof of memory safety for the 'safe' subset of Rust. In practice that's good enough: If some flaw were discovered it would be fixed once and for all, and every single program ever written (that could still be compiled) would once again be 'impossible' to break via buffer overflow.
You don't have to dive in at the deep end, though. Just use "ReaderT env IO" as your base monad and you should be fine. (Maybe add some classy lenses for 'env' to avoid boilerplate for picking apart the 'env'.) Even without understanding monad transformers this'll get you a long way. You'll occassionaly have 'weird' compiler errors and have to insert a 'lift' here or there, but it should be manageable. (I did something similar when first learning Haskell, but it wasn't with a web framework.)
If you're using cabal-install for building, do try "cabal new-build". It's a hugely improved experience (even over sandboxes).
Unless I read their charts incorrectly, Haskell is better on overall energy consumption, but slower and much more memory heavy than Go, roughly equivalent -- but somewhat better -- on all three to Swift, and superior to F# on all three. Personally I just hope more JavaScript people read this, but as always I'm more and more interested in Rust.
That post shows the fold definition resulting from the free object definition (and its corresponding adjunction). I'm not sure if that is what you meant? Since that isn't what I would call the inductive definition. With inductive definition I just meant the standard `data Free f a = Pure a | Free (f (Free f a))` which has a fold `Functor f =&gt; (a -&gt; b) -&gt; (f b -&gt; b) -&gt; Free f a -&gt; b` resulting from the fact that it is an initial algebra. And this is sufficient to induce the free monad. This idea in itself isn't really surprising since it is used implicitly everywhere. 
It's nice to see Rust in such a top position. We all knew in principle the ideas behind Rust would allow it to compete directly with C/C++, but going from "in principle" to "actually competing directly with C/C++" is a satisfying vindication wrought by an enormous amount of hard work.
I would strongly recommend separating you data library from your migrations and certainly don't automatically run them. I've been using [sqitch](http://sqitch.org/) on my latest project and it really does wipe the floor with anything else I've used. The way it manages the actual mechanics of running the migration is particularly well thought out. It also has a proper dependency system which generally isn't a required when there's only one person but as soon as there a multiple people it becomes a real headache not having one.
I'm not going to claim to have any expertise in cryptography or cryptographic API design (since I clearly have none). So take this as a complete layman's question: if the primary goal is to experiment with API as opposed to innovate on the implementation side, would it make sense to implement raaz on top of cryptonite? It seems like it would help in a few ways: * Help raaz by reducing the time spent on implementation * Help both packages by allowing users to stress test the majority of the code base in both packages regardless of which frontend they're using. This can apply to both bug fixes and performance enhancements * Allow end users to focus on a more standardized set of type classes (e.g. `PureByteSource` vs `ByteArrayAccess`), making it easier for third party libraries to decide which type classes to provide instances for
I did the course, as a total newb, last year and I thought it was pretty good.
[removed]
The best tool for visualising lazy evaluation is the GHCI debugger. IMO
+1 my method of learning Haskell is to write my code as best I can with what I know, then reflect and seek to simplify and reduce the code by trying relevant abstractions I am as yet unfamiliar with. I can spend twice as long again, refactoring and redesigning, but I invariably end up with code that is perhaps a quarter the size, obvious in its intent. What I’m doing really is creating practice contexts where there is no friction between the learning opportunity and the sample problem. 
I would prefer you'd suggest to /u/meta_leap following the instructions at https://haskell-lang.org/get-started Please don't recommend `cabal`, that's bad advice and likely the main reason for potential newcomers becoming demoralized before they even have a chance to enjoy Haskell. 
I keep a list of personal favorites here: [frp-guides][1]. [1]: https://github.com/HeinrichApfelmus/frp-guides
I think Spring 2013 version is recommended because it's known to comprehensively cover important FP concepts, compared to 2014 (from [here](http://bitemyapp.com/posts/2014-12-31-functional-education.html)): "Huge gaps in coverage, no longer usable as an introduction to Haskell. Possibly because it’s supposed to be preceded by some other UPenn class? Not sure what happened." I don't know of any reviews of the later courses. There's a post [here](https://www.reddit.com/r/haskell/comments/6pd5fs/join_me_in_upenns_introduction_to_haskell_course/) about an online study group that might be worth checking out.
I would use cabal instead of stack, but one of my deps isn't on hackage, and I haven't looked into building that with just cabal.
I recommend the Spring 2013 version simply because I've worked through it myself. I've been meaning to do a run through all of the versions at some point so that I can see if there's a better version out there, or so that I can point certain people at certain versions that match where they are and what they are interested in, but I haven't had time so far.
Yup. It's a misconception many people try to fix. Monad is just a useful enough general pattern/behaviour/api that apply to many types so it has been given a name. 
If you really want something like this in Haskell you can define your own Monad which you can either interpret to an AST for testing or to `IO` for running. Ultimately there has to be a type of "everything you can do in this system" and if you want it to include things that are not statically known at language-design time, like FFI calls, then it has to be as opaque as `IO` is. There's no choice about that.
What do you think about the way elm handles FFI by using ports?
Interesting. Wonder why TypeScript would be *so* much more inefficient than JavaScript?
Could you please keep version with types as well? I can't find syntax of specifying types in REWRITE rules. I learned it first time from your message. So having both versions is good because it's not clear what your EDIT for.
I meant the fact that it gets to: &gt; We’re effectively asking for the existence of &gt; data Free f a = Pure a | Free (f (Free f a)) &gt; instance Functor f =&gt; Monad (Free f) where &gt; return a = Pure a &gt; Pure a &gt;&gt;= f = f a &gt; Free m &gt;&gt;= f = Free (fmap (&gt;&gt;= f) m) So I wondered if that post was showing how would derive that, otherwise it seems somewhat plucked out of thin and just "happens" to work.
I didn't actually mean `meaningfulName`, literally! My point was the sum `10 * 20 + x` presumably has a meaning. I have no idea what it is, but it should be named as to what it's doing. `plusTwoHundred` is not a better name, because it is just as arbitrary. `adjustForSalesTax`, `incrementByMinimumOrder` and so on are meaningful.
What is probably more realistic is that we share the same low level implementation. I will post a more detailed response some time on some of the challenges for this. 
This metric omits the energy cost of repetitive bug-fix-and-recompile iterations. That cost also varies from language to language.
TypeScript should add almost no overhead over plain JS. Some constructs will result in a little bit of extra code, but nothing major. (This is one of the selling points of TS.)
I find it very cumbersome, and avoid it as much as possible.
Actually, you can create monadic bind in javascript, that enforces the function passed to it has really the signature `a -&gt; m a` (at run time of course). You just use `flatMap = fun =&gt; monad =&gt; (flatten (map fun monad))` (flatten throws run time error, if the function does not return `m a`) !
I'm not familiar with Elm but I can't see how the structure of the ports system is any different to Haskell's IO. In neither case can you define a datatype `Request` or `Response`+ because it's completely unknown how many or which FFI calls will exist in your system. + unless you have polymorphic variants, I guess 
&gt; Haskell seems like an unusual language to build games with Haskell is, in fact, the [best language for producing multiplayer games](https://www.reddit.com/r/haskell/comments/6e875i/lockstep_simulation_is_childs_play/di8fnu2/).
I have an example of pong written in Haskell, OpenGL, GLFW, FTGL and GLU. It is written in a very imperative style. It is not the best example but it should be helpful if you are interested in using those libraries in Haskell. https://github.com/mchaver/phong/blob/master/app/Main.hs
OK, from looking at [the docs for `Cmd`](http://package.elm-lang.org/packages/elm-lang/core/5.1.1/Platform-Cmd), which is a lot like `IO`, it seems that users aren't able to define their own native effects. Is there an FFI for Elm? How would I wrap a JS library in Elm without support in the runtime? Also, the `Monad` instance of `IO` seems to be encapsulated in `Task`, which is wrapped in `Cmd` and then interpreted by the Elm runtime. In Haskell, I'd write the `update` logic as a function of type `Model -&gt; Msg -&gt; IO (Model, Msg)` (I'm sure there are better abstractions in `reflex-dom` or `purescript-halogen`), or some more domain-specific monad than `IO` that is testable. I don't get how it is simpler to have a function `Model -&gt; Msg -&gt; (Model, IO Msg)`. In fact, not having the `model` wrapped in the `IO` requests is artificially limiting expressiveness, which can be witnessed by looking at the [`Random` example](https://guide.elm-lang.org/architecture/effects/random.html): Why is there even a need for two different messages? Why can't we just get a random number when we get `Roll` and update our model with the result? Simply because we can't change the model in response to the `IO` actions we did (resp. `Task`s we performed), which means an unnecessary roundtrip to the elm runtime and back: The gist is that you can *either* update your model in response to some input *or* perform side-effects the results of which are only visible in the next iteration of your update function. Now, I know Elm is all about simplicity. But this whole architecture thing and confusing `Task`/`Cmd` split to avoid talking about monads to instead use an inferior abstraction that is at least equally complicated doesn't resonate with me and is also the reason my Elm packages are more or less in maintenance mode. Also sorry if this came over as some kind of rant. In fact I like how it feels neat to code in Elm, but only until I miss some abstraction power after writing about 20 lines of code. I'm probably just not part of the intended target audience.
Really? I know you can `:step` through an expression, that you can step `:back`wards if you use `:trace` and your computation doesn't exceed the number of recorded steps, and that it's possible to implement [more advanced steppers](http://gelisam.blogspot.ca/2015/05/strongly-typed-ghci-commands.html) out of the primitive stepping commands. But I still get lost very quickly as the execution jumps around, so I find the post's code-rewriting style much more understandable. Seeing the contents of the thunks as they get longer is also much more insightful than `:print`'s underscores. Perhaps you know of some ghci tricks I don't?
Maybe you missed that "if" in my post. (Oh, and please stop trolling -- we all get that you like stack, but if anything you're probably driving people away from stack with your absurd zealotry.)
I would imagine that with any software that sees enough use to care about energy efficiency the development-side energy costs are going to be zero compared to the cost of the executing software. 
Re: time travelling debugger: Everyone has their own workflow, I guess. Mine doesn't involve the repl so much, apart from playing around with using `:kind!` for reducing type-level stuff. So I also never really used the time travelling debugger in a productive fashion. That is not to say that it's not achievable in Haskell: as /u/tomejaguar said, you can abstract the side-effects you want to perform into a custom monad, which you encode by an actual data type you can inspect, etc. It's simply an effort nobody was willing to take until now. I can certainly see how this could be useful in a few specific scenarios.
I want to see Go to be able to reduce fold-unfold compositions to the bests efficient assembly code when compiling. "Slower and much more memory heavy" for the 2nd and 3rd problems. What about the thousands where Haskell beats Go? Or what about the hundreds where Python beats Swift ? See what I'm trying to say ? These "benchmarks" are rather unfair for a comparison, specially if you pick just 3 problems. &gt;Also, for comparability, we have discarded benchmark problems whose language coverage is below the threshold of 80%. By language coverage we mean, for each benchmark problem, the percentage of programming languages (out of 27) in which solutions for it are available. "Problems in which solutions for it are available", "So if there is no code to copy-paste we discarded the problem". I understand that there is no way of designing a good solution for every language by the writers, but I'm skeptic to believe the code taken from the CLBG is "The best out there". This way of testing seems a bit fallacious to me IF you are going to use it make **conclusions about the whole language** instead of making **conclusion about the energy/memory/time efficiency of a language for a specific set/domain of problems** After all, an embedded software with Python would suck compared to one made with C. And parallelism with C++ is surely a headache compare to writing it in Haskell. 
So glad I'm not the only one :)
Yes, in a way it seems plucked out of thin air I guess. But the definition itself seems simple and natural enough to have arisen somewhere and it was later observed that it fulfilled the properties of the left adjoint to the forgetful functor `Monad -&gt; End`. If you are really searching for a constructive mathematical way of how to arrive at this definition, I think you might want to look in the direction of Kelly's ['a unified treatment of transfinite constructions for free algebras, free monoids, colimits, associated sheaves, and so on'](https://www.cambridge.org/core/services/aop-cambridge-core/content/view/S0004972700006353). At least I think it might answer your question, that paper goes beyond my current knowledge.
Probably something simple but I'm not sure how to handle having a function that returns maybe in my main function. It seems to make it hard to work with. What I'm doing is reading a file and then making a web request with that info. The function that returns the information from a file is a Maybe String. When i write my request function do I need to have the parameter be a Maybe String? I think I would prefer it to just take a string so it can be used in other situations. -- I have a function that returns a Maybe with the info needed from the file getConfig :: -&gt; string -&gt; Maybe string makeRequest :: String -&gt; RequestInfo main = do let c = getConfig "somefile" -- here Im not sure how use the makeRequest function? -- It seems like I cant use do again inside the main functions do block. something like, this can all return Maybe a : main = do do c &lt;- getConfig "file" r &lt;- makeRequest c d &lt;- doRequest r Hope this is clear. I'm a little unsure how to use Maybe or something simmilar inside the main function do block. 
Terrific, I'll have a look. Thank you!
It looks like the author might have seen this post. Within the last day he's split out the examples. Since he hasn't replied to your post, the changes might not be ready yet, but keep an eye out!
Was just looking at the GitHub repo right now, actually. Will definitely keep an eye out.
FFI in Elm is done using Ports. It's not too complicated. I agree that the Task / Cmd split is not ideal, but I'm less sure what an ideal interface would be. That being said, I've written thousands of lines of Elm and haven't used Tasks, ever. It being non-ideal doesn't impact me. 
I've explored PureScript, Idris, and Rust since Haskell became my primary language. I've learned PHP for the current job (at least, well enough to read the code and port it to Haskell and write the occasional integration/feature). Smalltalk continues to interest me as an ecosystem. There's just not a lot that other languages have to offer. PureScript's records are awesome, and their standard library situation is much better than Haskell's (hooray hindsight). Idris has dependent types, and that is where you want to learn type level programming and why it's useful. Rust has very interesting memory safety guarantees via types, which is cool for systems programming. F#'s cool features are ".NET interop" (don't care) and "type providers" (seems like a somewhat dubious idea to do a bunch of IO during compile time and generate brittle types from it; much rather have something like [`frames` type inference for rows/columns](https://hackage.haskell.org/package/Frames)). Scala has JVM interop (don't care), OOP features (don't care), and a monstrously complex type system that apparently has a ton of bugs and bad inference (according to my Twitter feed and other posts from folks that have used it in anger). Clojure is dynamically typed, which is a non-starter for me at this point.
You'll need to make some choices about defaults or errors, but I'd use `case` to pattern match on the `Maybe String`: main = do c &lt;- getConfig "file" r &lt;- case c of Just str -&gt; makeRequest str Nothing -&gt; undefined -- default request? d &lt;- doRequest r There are probably many ways to do this, but when I want to operate on the value of a `Maybe` I use pattern matching.
The most straightforward way is to use pattern matching, which in your case would look something like this: main = do configMaybe &lt;- getConfig "somefile" case configMaybe of Nothing -&gt; error "could not load config" Just c -&gt; do r &lt;- makeRequest c d &lt;- doRequest r ... Note this assumes that the signature of your `getConfig` function is actually `getConfig :: String -&gt; IO (Maybe String)` since it would need IO to get something from a file. I would recommend starting out with the straightforward approach, but there are some ways you can simplify/shorten the code. For example, this usage of `fromMaybe` and the `fmap` operator (`&lt;$&gt;`) is equivalent to the above: main = do c &lt;- fromMaybe (error "could not load config") &lt;$&gt; getConfig "somefile" r &lt;- makeRequest c d &lt;- doRequest r ... You never said what you wanted to happen if the config file was not found, so both of these examples assume you just want to crash the program when the config file is not found (which is what `error` will do). If this were actually the case it you could simplify the whole thing by just having the `getConfigFile` function call `error` internally then you could eliminate the `Maybe` from it's type signature to end up with just `getConfig :: String -&gt; IO String` and then your `main` code would could just be straight-lined: main = do c &lt;- getConfig "somefile" r &lt;- makeRequest c d &lt;- doRequest r ... 
Okay, I added it. But the syntax is explained in the documentation...
I know, my point was just that good name are usually hard to find, and sometimes (like this one), is just easier to just use the formula (or code) which is readable enough. 
Table 4 isn't just 3 problems, it's a summary across all the problems. One of the previous tables did summarize just three problems, but then points to an online appendix where all the problem sets are shown. They cop to all of your criticism of their methodology and more, and *yet* the results are pretty much inline with what you would/should expect from each language across a range of problem sets, and while I too doubt that the best possible solution in each language for each problem was chosen, it's interesting to see them compared across the concept of energy efficiency and not merely performance time. At the end of the day I'm unsurprised by any of it, except TypeScript's ranking vs the JavaScript it compiles to, and I'd have expected Go's memory usage to be higher, as well as Python's. Anything in there particularly out if line with what you'd expect? BTW they're not approaching at all qualitative ideas about the languages, or what is harder or easier to do in any of them, just the energy efficiency of the results. For all we know brainfuck is the most energy efficient language on Earth for implementing half of these algorithms, but who'd know?
I am extremely confused, I am trying to play a sound using 'aplay' called through System.Process's callCommand. The following code: callCommand "/path/to/aplay /path/to/soundfile.wav" works perfectly fine when I type it into ghci. However, when I try to *stack exec* my program, or even type the exact same command into a *stack repl* it fails with a pulseaudio connection refused error. Is there some difference in permissions for a simple *ghci* or a *stack repl*? I am thoroughly confounded.
This is similar but, I think, better than my BayHac talk. Two core components to the talk: * an introduction to the probability monad (based on ["Probabilistic Functional Programming in Haskell"](https://web.engr.oregonstate.edu/~erwig/papers/PFP_JFP06.pdf) * an overview of stochastic optimization and how it factors into our Haskell work at Target
If it has a .cabal file you build it with `cabal new-build` or `cabal build`. https://www.haskell.org/cabal/users-guide/
Elm is simply not a general purpose programming language. It works really well because it's restricted to a small domain (web UI programming) and the further you stray from that, the less useful and more painful it becomes. Haskell is much more general-purpose, and so we need a more flexible/powerful IO model. Since Haskell is more flexible/powerful, we can easily write an Elm-like effects system. But since Elm's effect system is pretty limited, it usually gets expanded into an EDSL using a free monad, free applicative, or similar.
To expand on "request -&gt; response seems testable": [Don't unit test your effects!](http://www.parsonsmatt.org/2017/07/27/inverted_mocking.html). Instead, isolate them to a tiny part of your codebase, and test them using integration tests. The rest of your codebase should be agnostic as to where the data comes from.
it's not haskell (but an extension)
I don't know if the splitting out of the examples so that depending on apecs doesn't mean having to depend on sdl2 was due to my question over on this week's Hask Anything thread, but thank you for that. 
It should be pretty straightforward to add runtime indexing. i describe a technique here https://blog.jle.im/entry/fixed-length-vector-types-in-haskell.html and also for runtime-dependent sizes here https://blog.jle.im/entry/practical-dependent-types-in-haskell-2.html, and also the http://hackage.haskell.org/package/vector-sized library uses it in real applications. It's actually a well-established thing in Haskell :)
Vandalism of a wiki hosted in your main repo seems like it should be protected against by the same mechanisms that protect against vandalism of the other (more important!) contents of that repo. Potential difficulty accepting contributions from non-technical users where you lack the relationship necessary to level them up appropriately seems to be the only major drawback... but it doesn't seem like a separate repo helps much there. ... were you imagining systems to automatically generate diffs and merge diffs within the repo?
I don't know why you are pairing your `Char` with `Seq Int` when you always update everything. This seems wasteful. Why not: ``` data Foo = Foo String (Seq Int) ``` What are you trying to achieve? 
Well, the sequences won't all be the same. The integer added to each sequence, on each iteration, will depend on the character.
Coincidence! But I'm glad it helped you out. Feel free to open an issue if you run into anything else.
Yes, I've read your blog :) Indexing functions in my package rely on inlining to achieve best performance possible. See for example: https://github.com/vagarenko/static-tensor/blob/086bb981768ce6786bab900c381b227152510d37/tests/CoreDump/Tensor/GetSlice.hs#L9 That function returns cubic slice of shape 2x2x2 from tensor of shape 2x3x4 starting from element at [0,0,0]. Now, look at its Core: https://github.com/vagarenko/static-tensor/blob/086bb981768ce6786bab900c381b227152510d37/tests/CoreDump/Tensor/GetSlice.dump-simpl.ghc821.golden#L35 That's exactly what you would've written by hand, isn't it? It just picks requested elements from input tensor and makes resulting tensor out of them. This is only possible because of inlining, and inlining doesn't happen at runtime, since Haskell doesn't have JIT-compiler. Without inlining this function will degrade into filter on list, with list performance. So yes, it is possible to add runtime indexing, but it will be slow. And you will still need to know tensors sizes at compile time, because lifting that restriction will require rewritting the whole library. It is called **static**-tensor after all :)
Are you consing on to the front of the list each time, or adding elements to the end? (I’m trying to remember whether finger trees will leak thunks if you append elements to the ends. Might have to test it!)
:set stop :list Is a very good setting, for example. Also I used leksah time ago, that had full integration of the debugger. For newcomers the debugger is a very useful tool to learn about haskell evaluation. It was for me at least
Is there a Slick (Scala) like alternative for Haskell to use as an FRM for RDBMS (Postgres, particularly). Slick: http://slick.lightbend.com
A list sounds like the wrong datastructure for this. I've no idea what you're trying to do but why not a `Seq (StrictPair Char (Seq Int))` or a strict `Dict Char (Seq Int)`.
My problem with ports is that you cannot chain them, Cmd it's not a Monad. 
I'm adding to the end of each sequence. Hmm. If I have to add to the beginning, I might as well use lists...
One of the long-term goals of `cabal-install` is to better parallelize compilation, perhaps with module-granularity. Doug Wilson has also been doing some [great work in GHC](https://phabricator.haskell.org/D3836) improving `ghc -j`.
Is that a full or relative path? 
How about forcing the new `Seq`s to WHNF instead of NF?
Could anyone give a step by step tutorial of how to install the GHC compiler? I downloaded the platform here https://www.haskell.org/platform/ and it says i need to "Modify your cabal config file (you can verify the location by running "cabal user-config init") to contain the following lines:" but I have zero idea what that means.... I'm new to this
There is a middle ground between the two "bad choices" you mention. Performance in Haskell relies a lot on judicious use of `seq` (or `BangPatterns`) to maintain the invariant that values are in normal form without traversing them fully every time. step :: (Char -&gt; Int) -&gt; [(Char, Seq Int)] -&gt; [(Char, Seq Int)] step new [] = [] step new ((c, is) : es) = (c, is :|&gt; i) : es' where !i = new c !es' = step new es 
Although it is not the identity for all other values: Unsafe.Coerce&gt; badid (2882304309355098434 :: Int) 140246523135912
Sure: if you only need to add to the end, just use a SnocList.
Wow, that's cool. I don't see anything wrong with it, but I'll try it out soon! Is it possible to write analogous code if we have `Map Char (Seq Int)` instead of `[(Char, Seq Int)]` (without converting the map to list)?
 With `Map` it's even easier because they already have a strict structure. In contrast, in my previous comment, I manually recurse through the list and build up a new one strictly because they are very lazy by design. The values of the `Map` will be forced to WHNF if you use functions from `Data.Map.Strict`. step :: (Char -&gt; Int) -&gt; Map Char (Seq Int) -&gt; Map Char (Seq Int) step new = Map.mapWithKey (\c is -&gt; let !i = new c in is :|&gt; i) Assuming `is` is in normal form (invariant on the input map), the bang will force `i :: Int`, and with that `is :|&gt; i` should evaluate to normal form.
What do you mean by 'fully computing the sequences every time an element is added?' This hints that there may be a better way to structure this problem. You may want to investigate a streaming library like pipes or conduit, or foldable for composable folds - Or simply question the core assumption that you can't store a meaningful value at the end of the Seq without re-computing the whole content of the Seq. Perhaps there is a way to store something that allows you to compute the final answer at the end?
This is pretty cool to see elsewhere out in the wild. I work in casino games and we use a probability monad of our own - due to the massive size of the probability space we were forced to go with the tree-based approach highlighted later in the talk. We don't currently leverage this fully as you do, visualizing distributions - mostly because we never really have the fully-realized normalized distributions, just virtual trees that we could walk at great expense. I'm interested in seeing how you adapt your current approach to the tree-based.
We haven't started on that yet, actually, but I'm hoping to start on that soon. We're expanding our simulation efforts and will probably find uses for conditional sampling there. I'd love to hear about how you use it and how it plays out in practice.
Could you post the ePub online?
Well put.
Using full paths. In the case of *stack repl* it fails, but simly from *ghci* it's absolutely fine. I am running inside a nix-shell, if that makes any difference. The error is a "permission denied" from pulseaudio, not a 'command not found' or something along those lines.
If you know the number of iterations in advance I would go with a unboxed mutable vectors. Calculate the size required at the start and then run your iterations in ST. * It doesn't cause gc pressure. * You are guaranteed strictness and no thunk buildup. * It's pretty much the least overhead possible for integers. But it does force you into the ST or IO Monad so there is that.
The big problem with ports is that it does not compose. You can not write a library doing FFI using ports that is reusable in any way w/o making very restricting assumptions.
Given that you work in casino games: Do you ever think about the moral implications of what you're doing? How many 'addicts' you're sustaining? (I'm prepared to be downvoted to oblivion for this, but I do think it's important to ask. Obviously, it's not Haskell's fault -- tools are tools.)
When you don't know the concrete choice of 'p' you can't derive `Coercible` for it as you can't talk about if its arguments are representational or not. Given `Kleisli m` when m is just some `Monad`. I don't get to know `m` has a representational argument. So the problem comes up in 'concrete' cases where `p` or parts of `p` aren't known, e.g. when writing combinators that are parametric in the choice of profunctor. In other words, when working with almost every single combinator in `lens`. We could require representational roles by requiring some combinators with type signatures like Coercible a b :- Coercion (p b c) (p a c) Coercible b c :- Coercion (p a b) (p a c) but they are actually harder to use in practice than the #. and .# machinery we can vet (or write in the first place) by removing the # We didn't require such members at first because when we wrote #. and .# Coercible didn't exist at all, and also Functor doesn't give me such a thing so that I can delegate to it for things like the Kleisli case. Could we require something like that in a superclass of Functor? Possibly. But pushing a member into Functor that breaks a lot of the instances that are only 'morally' functors under some quotient would be unlikely to be a popular move and would require a heck of a greater level of consensus than I think is possible to obtain.
`&lt;-` is basically `&gt;&gt;=` backwards (with some sugar). `&gt;&gt;=` has type: `Monad m =&gt; m a -&gt; (a -&gt; m b) -&gt; m b` The upshot of this is that `m` in that signature can be any monad, but it's only one particular monad 'at once.' So `b &lt;- (f :: Maybe b)` only works in a do block where you're dealing with the `Maybe` monad. You don't get to mix and match binds from multiple monads in a single do block (you can -kind of- do that with monad transformers but that's a much more complicated subject and it doesn't really fit your use-case). You need to find a way to convert from `Maybe String` to `String`. To do this , you have essentially two options: * provide a sensible default value to use if the result of `getConfig`is `Nothing` * throw an error and interrupt the program [maybe](https://hackage.haskell.org/package/base-4.10.0.0/docs/Data-Maybe.html#v:maybe) from `Data.Maybe` is a quick, idiomatic way to provide a default value if you want to. Example: main = do let c = maybe "default" getConfig "somefile" doRequest $ makeRequest c If you want to throw an error, or have other, more complex logic on failure, you can do something like this: main = do let c = getConfig "somefile" case c of Just n -&gt; do let r = makeRequest n d &lt;- doRequest r {- do stuff with d -} Nothing -&gt; do {- do something else, like throw an error or log to console-} 
Thank you for the honest explication. I still "hate you" in terms of the generally negative impact of your... games. ... but I take it you aren't bothered by that. (EDIT: It's obviously not fair: information asymmetry, etc. etc.)
&gt; To me the request and response version is highly testable because you can just give different responses to your program and see if it produces the correct requests It is, but monadic IO is more flexible. &gt; as far as I have seen there is no time travelling debugger like Elm. Is this even possible with monadic IO? It's more likely due to laziness than the flexibility of monadic IO. &gt; Do you think IO in Haskell should be changed or do you prefer it as it is? I would like an approach based on free monads, though none of the current solutions seem to have exactly what I want. I don't think Elm's approach enables the same flexibility that some other languages enjoy. Testing IO is hard for reasons other than monads - impurity will always make this a problem.
&gt; This way of testing seems a bit fallacious to me IF you are going to use it make conclusions about the whole language instead of making conclusion about the energy/memory/time efficiency of a language for a specific set/domain of problems I have a problem with a lot of benchmarks for this reason. I'm not convinced microbenchmarks simulate what actually happens in large applications.
Not to mention the programmers themselves. 
My point is pretty minor; if you have a wiki that is languishing without love from developer then make it a submodule of the repository. From the developers perspective it is like maintaining the docs in the repository which is what the post is recommending, with the additional advantage that it can be decoupled later on. 
r/reflexfrp --------------------------------------------- ^(This bot is for those that don't have access to the x-posted sub link) ^| [^(More info)](https://np.reddit.com/r/botwatch/comments/6xrrvh/clickablelinkbot_info/) ^| ^(Downvote to -1 karma to remove) ^| ^(PM for sub to be ignored)
This is the first post with some actual concrete details. I've realized that the SVG elements aren't particularly mobile friendly at the moment - sorry about that. I'll address that later: in a fit of madness I've decided to try to get a series of exercises out along with the posts, so that's going to consume a bit of my time in the near term. Let me know if you have any questions / comments / feedback.
The problem with Haskell's first approach and Elm's current approach is that you cannot have *local* effects, or *local* feedback loops. Every effect must be passed up to the top-level feedback loop. While I have a hunch that you could encode local effects with non-local (global) effects (I think that's basically what the RTS is doing), this encoding is utterly unbearable at large scale. You would spend vast amounts of work keeping track of all the plumbing. That said, it's most certainly the case that local effects are harder to test! If you only have one feedback loop in your entire program, then that is definitely easier to test. That is...unless you have 10,000 inputs and 10,000 outputs. So we tend to make a tradeoff. We try to pull out effects as much as possible, and test each component. But at the end of the day we still use local effects because we need it to scale. This is actually the exact same tradeoff that Reflex makes by choosing FRP. I spent 5 years as a controls engineer using Simulink. We saw the exact same issues.
&gt;* but also to encode variants (` purescript-variant ](https://pursuit.purescript.org/packages/purescript-variant` by [/u/natefaubion](https://www.reddit.com/u/natefaubion)), JS-native effects (` purescript-eff ](https://pursuit.purescript.org/packages/purescript-eff`), algebraic effects (` purescript-run ](https://pursuit.purescript.org/packages/purescript-run` also by [/u/natefaubion](https://www.reddit.com/u/natefaubion)), and a few other things. I would really like to see a blog post on this topic. I tried to read the source code of purescript-eff but it did not make me much wiser. I wasn't even able to locate where exactly is row polymorphism used. 
`purescript-eff` does the simplest thing possible, and just uses a phantom row type and row unification to track which native effects are used in what amounts to an `IO` computation. `purescript-run` does something much more sophisticated, using rows to essentially encode an open coproduct of functors, which are used as the base functor for a free monad.
&gt; since it would need IO to get something from a file. I tried to simplify my question a bit to focus on the maybe. I'll clarify what I was trying to do. I have a file on my computer that contains a json array. So i am reading the file and parsing the content. The parsing step returns Maybe String. My program and main function are actually closer to parseConfig :: Value -&gt; Parser(String) main = do config &lt;- readFile "config.json" let d = decode config &gt;&gt;= head &gt;&gt;= parseMaybe parseConfig I wasnt sure what the best way to continue using d would be. Thanks for the info and help
Thanks for those examples. Those look like they do what I am looking to do. I'll have to spend some time and play with it a bit.
That examaple is helpful. Thanks
I haven't used plain cabal since `stack` was released. `stack` is a program that wraps up cabal and package management in a very predictable way. You can install it following [these](https://docs.haskellstack.org/en/stable/install_and_upgrade/) instructions. After installation, take a look at the [user guide](https://docs.haskellstack.org/en/stable/GUIDE/#hello-world-example) for a quick introduction.
Is the sound resource being used in another process? It's been a long time, but I remember having problems with pulseaudio and playing sounds from two programs.
I don't get it. Storing millions of integers in sequences will take a lot of memory, thunks or not.
https://www.haskell.org/platform is considered obsolete. The currently recommended way to install Haskell is described at https://haskell-lang.org/get-started . There's no cumbersome "modify your cabal config file" instructions anymore.
Blog post would be much appreciated. :) Btw are row types / records implemented as hash maps under the hood? Isn't that a little bit slow?
This looks similar to a package I made, which is [available on Hackage](https://hackage.haskell.org/package/distribution). The internal representation for a `Distribution a` is `Map a Rational`, which forces `a` to have an `Ord` instance to perform pretty much anything. Initially, I duplicated methods found in the Functor/Applicative/Monad typeclasses and specialised them for `Distribution`. Later, I took an approach very similar to the one presented in the talk to be able to [offer a monadic interface](https://hackage.haskell.org/package/distribution-1.1.1.0/docs/src/Data-Distribution-Monadic.html#Experiment). If you're interested, the code is [hosted on GitHub](https://github.com/redelmann/haskell-distribution). I also did a [Javascript version](https://github.com/redelmann/Aleatory.js), and I would love feedback on any of those :)
Maybe this was somewhere in the presentation, but where's the code?
We haven't released any code (yet), but the basic monad I talked about already existed in the [probability](https://hackage.haskell.org/package/probability) library.
&gt; I am running inside a nix-shell, if that makes any difference. Are you running both `ghci` and `stack repl` inside the same nix-shell?
This has the same problem with the functor laws that `Set` does. It relies on `a == b =&gt; f(a) == f(b)` which doesn't need to hold with our `Eq` class.
"Rebalancing" the finger tree inside a Sequence also takes time. Data.Sequence is very unlikely to be the data structure the OP really wants.
Thanks, I didn't know about unboxed types :)
Could you point out where that is implied? I was under the impression that the reason `Set` fails functor laws is that `a &lt; b =&gt; f(a) &lt; f(b)` is not generally true. How is it possible (without unsafe) for `a == b =&gt; f(a) == f(b)` to not hold?
I'm reading the book Haskell Programming from First Principles and to apply what I'm learning, I'm solving the problems on Project Euler. This is my first time doing functional programming, so it's kind of mind-twisting, but I like it! I just feel a bit lost sometimes when trying to solve problems which aren't complex for me in other languages. Anyway, here are my solutions for the first 2 problems on Project Euler. Could you help me improving them? I want to see what could be done. I want to keep the code as reusable as possible, so I'm not interested in one-liners. - 1: http://lpaste.net/2885396228164550656 - 2: http://lpaste.net/8077949429182627840
 data T = A | B instance Eq T where (==) a b = True f A = True f B = False -- A == B, but f A /= f B As for why it breaks the functor law, it's because it's possible for `fmap f . fmap g` to be different from `fmap (f . g)`. `g` could squash multiple values into the "same" thing under the `Eq` instance and the functor instance for `Dist` would combine the "duplicate". g True = A g False = B Now, `fmap g (uniform [True, False]) ~ pure A` (or maybe `pure B`) so `fmap f (fmap g (uniform [True, False])) ~ pure True` while `fmap (f . g) == id`.
You are far from the only person uneasy about the things many of us do for money. I agree with you: we should be conscious of the impact our work has. I recognize that not everything can be sunshine and roses all the time (we can't all work in universities), but some industries are notoriously more toxic than others, and Haskell developers are high enough on the food chain to have a choice in the matter. None of us are Aladdin stealing bread to stay alive.
Nice! There's some rendering problem on desktop for me with the fizzbuzz examples: when there's no event firing then the labels "eBuzz" and "eFizz" end up on the right hand-side.
I like the capabilities of that library but calling the monad `T` puts me off a bit.
Ah, ick - I just replicated that in Chrome, and now that I think about it I only tested that bit in Firefox. I'll fix that up in the morning (and test the future posts out in at least two browsers). The lesson here is that I'm not usually a front-end developer. And that CSS is not to be trusted. Edit: I just did a before-coffee edit as a hacky temporary fix using a table. Your move CSS.
Isn't appending amortized O(1)? [Documentation claiming it's O(1)](http://hackage.haskell.org/package/containers-0.5.10.2/docs/Data-Sequence.html#v:-124--62-) [A video explaining why](https://youtu.be/-HZ4bo_USvE?t=46m24s)
Which part of gloss do you wish was more extensible? The main limitation I have in mind is that Picture only supports a limited number of shapes (e.g. it supports left-aligned text but not centered text), but if you're willing to write your own main loop, you can mix Pictures with arbitrary OpenGL code. [Here](https://gist.github.com/gelisam/27bf515548a9ce551a18) is a gist in which I draw a Gloss `polygon` with `gl_XOR` for example.
To make your code more idiomatic (and shorter/more readable) you could use infinite lists. This works in Haskell because of the lazyness. You just build the list of all multiples or fibonaccis, and then only `take` the ones you need. To show you what i mean: multiplesOf3Or5 = filter (\x -&gt; x `multipleOf` 3 || x `multipleOf` 5) [1..] and then only the ones you want: multiplesBelow1000 = takeWhile (&lt; 1000) multiplesOf3Or5 and then it is only one simple step to the answer. The trick is to not build the list step by step in a manual recursion, but to define them as a whole. There is a widespread example on how to do define the list of all fibonacci numbers. Maybe you can find it yourself.
Thanks for that comment. EDIT: I'd wager very few people go out of their way to be "actively" evil, but these day-to-day "complicit-in-a-very-minor-evil" things add up, and I think we'd be better off as a society if we actually considered this as developers. It's also only going to get worse.
Yep, `ghci` and `stack repl` are called from within the same `nix-shell`. I literally run into a problem in the `stack repl`, close it, start `ghci` and run the same command without problems.
I honestly don't think so, and even if that were the case, why would `ghci` not be bothered by this, while `stack repl` is?
I believe local effects are done using elm tasks and mapping one task onto another? But yes eventually that task needs to be passed back up. 
logEvent birthDay -1 "Nony" logEvent birthDay 1000 "OlderThanMethuselah"
What's the difference between reflex and reactive-banana?
It is incorrect to say the Haskell platform is obsolete. There are two competing "batteries-included" methods of getting up and running with Haskell - stack and the platform. That said, all the devs I know just use OS packaging for ghc/cabal/stack so I'm frequently surprised by the volume of this debate.
I'm not sure what you mean? Now that you have `d` in scope you can refer to it as many times as you want on lines below the `let` statement...
I'm not disagreeing about putting it in the repo. I'm saying that I think the submodule isn't actually buying you anything worth the cost. Yes, it can be decoupled - but I don't think there's reason to decouple. Having the docs directly in the code repo is slightly more convenient when it comes to managing updates to code and docs together. It also encourages developers to default to actually checking out the docs - possibly a problem if the docs are huge, but more likely a win I think. I think maintaining docs in a submodule is probably better than maintaining docs in an external wiki. But I think maintaining docs directly in the main repo is probably better still (and even easier to do).
If you have [Servant with ReaderT](https://github.com/myfreeweb/magicbane/blob/7c417504590fc40ecd37a61e3c3a80640eb4d8dd/library/Magicbane/App.hs), you can compose all the libraries that want their context and IO. [data-has](https://www.stackage.org/package/data-has) is useful for this. See how I integrated [monad-logger](https://github.com/myfreeweb/magicbane/blob/7c417504590fc40ecd37a61e3c3a80640eb4d8dd/library/Magicbane/Logging.hs). You should be able to define an instance of the [`Katip` typeclass](https://www.stackage.org/haddock/lts-9.5/katip-0.5.0.1/Katip.html#t:Katip) like that.
&gt; we were forced to go with the tree-based approach highlighted later in the talk. &gt; we only realize a single value of it per application of the RNG Am I misunderstanding, but the notion that "we only realize a single value of it per application of the RNG" seems to imply what you are doing here is simply sampling, which I think is different from the declarative/free-monad/"tree-based approach highlighted later in the talk"? for the free-monad/"tree-based approach highlighted later in the talk, you would essentially have just some plain structs which reify the _structure_ of the computation, and then you'd have to feed that to a separate interpreter step.
I tested this code. Unfortunately, it looks like it's using a lot more memory than expected. Do you have any ideas? Here is my test code: {-# LANGUAGE BangPatterns #-} import Data.Char (ord) import Data.List (foldl') import Data.Sequence (Seq, (|&gt;), empty, index) step :: (Char -&gt; Int) -&gt; [(Char, Seq Int)] -&gt; [(Char, Seq Int)] step _ [] = [] step new ((c, is) : es) = (c, is |&gt; i) : es' where !i = new c !es' = step new es createData :: [(Char, Seq Int)] createData = foldl' f initial [0..1000000] where initial = [('A',empty),('B',empty),('C',empty)] f list i = step (\c -&gt; ord c + i) list main :: IO () main = do let d = createData putStrLn . show . map ((flip index) 1000000 . snd) $ d Compiled with stack ghc --resolver=lts-9.5 -- -O2 -Wall -prof -fprof-auto -rtsopts test.hs Run with ./test +RTS -hc -p Got a PS file showing memory usage with stack exec hp2ps -- test.hp The resulting test.ps is showing me **140 MB** memory use at the peak. This is bewildering to me because the code creates only 1,000,000 Ints for each sequence. Int is 8 bytes (64 bits) and we have 3 letters ('A', 'B', 'C'), so I would expect max 8 x 3 x 1,000,000 = **24 MB** of memory use. 
The thing is that your personal moral code isn't necessarily universal or shared by others; and I don't think we can all agree on what is moral or not moral. Resolving this is an act of politics and political action. And I think we have to be very careful about what we politicize in our industry; and the more unambiguous and shared those reasons are, the better. Given all the other "negative externalizes" that programmers, or their companies, inflict on the world, i'm not sure we want to go out of our way to chastise casino/gambling verticals. I think that is a marginal, even if personally consistent, viewpoint.
It costs much more than that to maintain a `Seq Int` of one million `Int`. First, `Int` is boxed, so it costs at least one more word for the `Int` constructor wrapping the actual underlying machine integer. I'm not sure how `Seq` are represented, but for a list, for example, you need at least 3 words for each cons cell (one for the constructor tag, one for the head pointer, one for the tail). That's already much more than 24MB as a lower bound. If you need a cost of 1 word/int, you cannot do that with Haskell's persistent functional structures. You can allocate an array and traverse it monadically.
&gt; I would expect max 8 x 3 x 1,000,000 = 24 MB of memory use. Remember that you're not storing all this information in a flat, packed array, but in a tree-like data structure containing a lot of pointers. 6 words per Int doesn't sound that bad, all considering. That being said, when I try your code in ghci, I notice that your `Seq`s still aren't forced to WHNF: &gt; let d = createData &gt; d `seq` () () &gt; :print d d = [('A',(_t1::Seq Int)),('B',(_t2::Seq Int)),('C',(_t3::Seq Int))] If I force `_t1` to WHNF, it normalizes to NF, as expected. Looking at `step`, I see that the `!i` and the `!es'` force the `ord c + i` and the rest of the list to WHNF, but not the new Seq. Using `(c, i') : es' where !i' = is |&gt; i ...` fixes the issue, but I haven't bothered to check if that improves the memory usage; since you're compiling with optimizations on, it's quite possible that ghc's strictness analysis already added the `!i'`.
Blog post is [here](https://github.com/purescript/documentation/blob/master/guides/Eff.md). They're implemented using JS objects, so yes, they can be quite slow.
I wish reflex was better about releasing updates to Hackage. I get the impression that there are many improvements on master, but they haven't put them on Hackage. I'm working on a game in Haskell and would like to use use either reflex or reactive-banana, but I'm discouraged because it seems like the reflex maintainers don't keep Hackage up to date because they have their shell scripts and reflex-platform that bypass the issue. I don't want to use reflex-dom and the reflex-platform, I just want wire up some game logic inside of plain old reflex.
I'll be there, giving a tutorial on my [Threepenny GUI framework][1]. [1]: https://wiki.haskell.org/Threepenny-gui#Gallery
There's an implementation for the "Practical Probabilistic Programming with Monads" paper mentioned at https://github.com/adscib/monad-bayes/tree/master I think.
On top of what Wedamm suggested: For PE001. - While splitting things up into smaller functions is good I don't think your first two functions for PE001 are complicated enough to warrant it. - Write `[x] ++ xs` as `x : xs`. - If you want reusable as possible, signatures like `findMultiples :: Integer -&gt; [Integer]` can be written `findMultiples :: Integral a =&gt; a -&gt; [a]`. As for your PE002 solution, partial functions like `last` aren't idiomatic. [This](https://wiki.haskell.org/The_Fibonacci_sequence) gives some nicer ways of generating the sequence while avoiding partial functions. Additionally, you might find the tool [hlint](https://hackage.haskell.org/package/hlint) useful. It doesn't do any fancy analysis, just some nice, basic hints.
My only thought is that you for some reason have different environment variables when in `stack repl` compared to `ghci`, which might cause some issues. I'm not totally sure, but could you inspect that with `:!env`?
Och, indeed. I should have checked the docs, the amortized O(1) claim is present in the original paper (section 3.2). Finger trees do some work at consing / snocing though - they certainly aren't as simple as list cons.
The other comment shows that it's *technically* possible. It's also *practically* possible. We have different things we talk about when we say equality. We don't need to look further than `Set` itself for an interesting example. When we ask whether two sets are equal, we usually don't care about the underlying tree; we care about membership. However, there are functions that answer questions about the shape of the tree. Prelude Data.Set&gt; let x = insert 3 $ fromList [2] Prelude Data.Set&gt; let y = insert 2 $ fromList [3] Prelude Data.Set&gt; x == y True Prelude Data.Set&gt; splitRoot x == splitRoot y False
&gt; I don't think Elm's approach enables the same flexibility that some other languages enjoy. While that's true, this community in particular should be cognizant that sometimes giving up flexibility makes things easier, if you do it right.
They have quite a bit in common - they're both Event-and-Behavior based FRP and they tick the box for precise semantics. The `sodium` library is also in this space, and they deprecated their Haskell bindings in favour of `reactive-banana`because their APIs had more-or-less converged. I actually had various draft posts for a blog series on `reactive-banana` that was going to lead into something like this series, but life kind of got in the way. There are some things in `reflex` that `reactive-banana` doesn't have that come from the focus on performance. One of these in particular - `Dynamic`s - helps get `reflex-dom` to the virtual-DOM-without-diffs-or-patches state that I mentioned. The other big difference is in the code that you use to run your FRP networks. In `reactive-banana` the API for this is a simple and - in my experiences with it - will give you what you want very easily about 95% of the time. With `reflex` the API for that is more complex, but it gives you a lot of power and control - you can mix and match features you want to provide to the network. There is at least one library out there that helps you get back to how things are with `reactive-banana`, but a few recent additions to the `reflex` host API make me less likely to reach for it now. I have some examples up in a repository somewhere, and with a bit of work I could turn them into a little blog series about the host API. It would be a good way to discuss the various typeclasses in `reflex` in a bit more detail, and it would kind of lead into the thing that I want to do after that... 
Sorry about that! I really should be better about this, and I'm hoping to get on a more frequent release cycle soon.
I started playing with Haskell not that long ago and basically every time I see 'do you want to add &lt;someextensionhere&gt; to the top of the file?' I treat it as 'I didn't do what I think I did'. So far that's been pretty ok, and I figure eventually I'll use that fancy stuff.
The examples all lag quite a bit. Is this is to be expected when using reflex/ghcjs?
Unboxed vectors will do that. Or a custom data type with `-funbox-small-strict-fields`: data ListInt = Cons1 !Int IntBlock | Cons2 !Int !Int IntBlock | Cons3 !Int !Int !Int IntBlock | Cons4 !Int !Int !Int !Int IntBlock | Cons5 !Int !Int !Int !Int !Int IntBlock data IntBlock = End | Block !Int !Int !Int !Int !Int !IntBlock This structure is more cumbersome than vector, but is decent for lots of consing.
Missunderstanding on my part then
My colleague and I were saying the same thing as we examined the source directly last night. Would be much appreciated :)
I don't think it's to be expected with reflex/ghcjs. Does it still lag if you reload the page and don't start the example with the timer? I've been suspicious of that example for a little while. I think in general if there are performance issues it's likely to be something dumb that I'm doing with `reflex-dom` (and the SVG I've hacked in there in particular. My main goal is to show off the `reflex` side of things more than the `reflex-dom` side of things, but if folks are seeing a distracting amount of lag I'll tinker with things to try to remove that distraction.
I still see it even if I don't start the first example. When I wrote the first comment my system was under pretty heavy load and it was really bad. Now that it's not, there's still a noticeable delay, but it's not as pronounced. This is easiest to spot if I mash one of the buttons as fast as I can. It's not so bad as to undermine the point of the tutorial, but I do care how responsive a site I might build with stuff would be.
&gt; `logEvent : (event: Event) -&gt; SchemaType (messageSpec event)` How does a dependently typed language know run time properties at compile time? Or am I just not understanding the `Event` type? (Is it just a special case that can be checked at compile time since the data is already part of the code and not any input?)
Yeah, now that I'm looking for it I can see it. I blindly added -O2 to the cabal files, which made a difference, but I should probably also add some strictness annotations in a few places as well. It's almost certainly me rather than reflex :)
You might be on to something, the `/run/current-system/sw/bin/aplay` directory *is* on the path for `ghci`, but not for `stack repl`. This means that when I `stack exec` the program fails in exactly the same way, but I can just run the binary from the `stack-work` directory directly, and everything works. Still very confused as to why this is happening, but at least I have a solution now.
By pattern matching on `event`, you perform a case split where in each alternative you have learned some information about `event`. A simpler toy example is: f : (b : Bool) -&gt; if b then Int else Char f True = 1 -- in this branch we know b = True, so the result type evaluates to Int f False = 'F' As you can imagine, more complex information becomes more difficult to track, to the point that you need to provide explicit *proofs* of various facts to make programs typecheck.
OK, I dug in a bit and found out what was going on - there was a heinous bug on my part in the depths of the SVG code. Our nginx caching is pretty aggressive so you may need to do a hard reload now you should see closer-to-representative performance. This is also without strictness annotations, or really much thinking about the performance other than one key design principle that I'll be talking about when I discuss `reflex-dom` (which makes this bug even more embarrassing).
I really like the [errors](https://hackage.haskell.org/package/errors) library. It has so many useful little functions to gently guide me away from exceptions and into using error types where appropriate. A lot of the useful functionality is actually from other libraries it brings in but it does a good job at being a one-stop-shop.
`text`, `bytestring`, `vector`, `containers`, `unordered-containers`, `attoparsec`, and `aeson` They give predictably excellent performance and cover a lot of common use cases
Hi, I work on katip. Looking at your code I think the best way would probably be to just add some fields to `Config` as it already is available via a `ReaderT` to your app. If you want the full power of `KatipContext`, I advocate adding 3 fields: one for `LogEnv`, one for `Namespace` and one for `LogContexts`. In fact, this is exactly what `KatipContextT` does! data KatipContextTState = KatipContextTState { ltsLogEnv :: !LogEnv , ltsContext :: !LogContexts , ltsNamespace :: !Namespace } Once you do that, you can implement `Katip` and `KatipT` instances for your monad. The [examples](https://github.com/Soostone/katip/blob/master/katip/examples/example.hs#L114) has an example of that that you shold be able to copy almost verbatim but for your `App` monad. If you have any trouble with this, please open up an issue on the [katip issue tracker](https://github.com/Soostone/katip/issues). Unclear docs are definitely a bug! In fact, I think this shows that the docs need some work: we should probably have an in-haddock example suggesting the fields you should add for your ReaderT-based monad and how to implement the necessary instances. It isn't quite satisfactory to suggest the user look at the source or go mine the examples directory for help. I'll create an issue for this.
What's the thinking behind using the ADT form of the free monad vs the Church-encoded version? 
ClassyPrelude because it helps my not do some noob mistakes ... and I am a noob
Yeah, I don't like that style either. It's really common to call type `t` in OCaml, but that only makes sense given OCaml's module system—and Haskell, all its strengths notwithstanding, does *not* have a module system anywhere near as powerful as OCaml. And even in OCaml it occasionally causes some terrible type error messages, so I'm not entirely sold on the style even there.
Lens is probably my biggest one, followed by recursion-schemes (which is really cool but only sometimes useful). lens is basically constructors/destructors done "correctly". It can reduce boilerplate hugely in some projects. recursion-schemes is good for three reasons: 1) the template Haskell does some of the work for you, 2) it makes sure you don't accidentally cause space leaks by handling folding itself and 3) it can be faster to use a hylomorphism sometimes. I have also used Chart-diagrams in more than one project. aeson and binary have seen similar usage.
I definitely could not live without `base` and `ghc-prim`.
If you build with stack/Nix you can pin your dependency to a git commit :)
&gt; I know the linker has also been a bottleneck at times and I'm just not sure on the status of that. As of GHC 8.2.1, it automatically uses 'gold'. &gt; Additionally, I find that cabal new-build saves time compared to either sandboxes or stack as more of my build artifacts can be safely reused. Seems to be the case, but I've found that cabal can be inconsistent at detecting when flags changed in the cabal file matter. 
ADTs are very nice, but don't discount purity, garbage collection and higher kinded types. I've been enjoying playing with Rust, but it still feels low level without HKTs and having to satisfy the borrow checker, or even having to wrap mutexes and atoms in `Arc`.
If you're okay downloading it, you can add a 'cabal.project' file that will handle a lot of things nicely. 
What makes them better than similar libraries?
Name a library that's similar to `ghc-prim` that doesn't just include it.
`safe-exceptions` (and friends) because I do not want Heisenbugs making me worry about all the ways I'm not doing exception handling correctly.
I'd add `mtl` to the existing answers. It's how I interact with most monad stacks.
I don't know that it's really a library per se, but the `deriving` system makes working in other languages feel like the stone age. What do you mean it's not obvious that my `Tree&lt;T&gt;` is a functor and traversable?!
Ho yes!
I love [megaparsec](https://hackage.haskell.org/package/megaparsec). I had a programming moto, "if you ask me to write a time library, an encoding library or a parser, I'll seek for another job". Now with `megaparsec`, it is a pleasure to write parsers. It is fast enough, gives great error message, comes with some combinators for parsing expression with operator precedence.
How about writing a parser to parse all possible human-readable time formats in all character encodings ever invented?
It's not really a utility library, but `brick` for making TTY interfaces is almost a killer app for Haskell, and I love working with it. Then there's QuickCheck and SmallCheck! Oh, and `async` is so useful and elegant it feels like it should be in the standard library. `optparse-generic` is really convenient too, though I have a few unfulfilled desires with it...
Without repeating others, `stm`.
I really dislike Template Haskell so [generic-lens](https://hackage.haskell.org/package/generic-lens) is a godsend.
`lens` is probably the biggest one for me. What makes it special is that it provides *two* powerful things: the core lens/prism/traversal capabilities *and* a bunch of generically useful typeclasses somehow missing from Haskell's standard library. It took me a while to figure out just how useful that second part is. Lens provides a bunch of classes and tools that reify things normal Haskell libraries don't: * `Empty` for types that can be empty * `Each` for iterating over all sorts of things (especially monomorphic containers) * a generic `is` function (`is _Left`, `is _Just`... etc) * indexed containers and traversals * generic tuple functions (`_1`, `_2`... etc) * newtype utilities * generic indexing and key lookup functions 
It depends on what you see the wiki as. We have layers of documentation 1. Comments in the source - Target Developers 2. Haddock - Target Downstream users of the library 3. Wiki - Taget much wider set of users. The hope is that the wiki will hopefully see (as time progresses) effort from the community. You can also see that 1 and 2 are tightly controlled by the developers where as the contents of 3 is generally not so tightly controlled (and you do not want to either). It is for this reason I was suggesting that wiki be a submodule. Of course all other forms of docs are also good. 
Thank you very much! I ended up doing this for the multiples: http://lpaste.net/350587670587506688 It's much better this way :).
Thank you very much! I like hlint, I'll use it.
generic-lens depends transitively on TH
No challenge unless you also have to detect and recover from incorrect double-encoding...
I'm aware
Phadej/github, slightly modified, a very elegant solution for me.
Man! this is a very great question! These libs are considered "default" for my case: - classy-prelude - mtl - data-has
I'd add `streaming`, `pipes`, `conduit`, or even `free` - choose whichever you want (that's in my personal preference order). Streaming computations arise surprisingly frequently. No mention of `transformers` here, but that's almost used in almost everything I write. I could live without it because I can just write my own version of it in a few minutes :) I'd pair that with `mtl`, `exceptions` (or `safe-exceptions`).
I've actually used liftX :: (forall m. MonadFree F m =&gt; m a) -&gt; n a too, which lets me choose a Church or initial encoding. But honestly I haven't given it much though. Generally you're only ever going to lift a single constructor at a time. 
`deriving` is amazing
I agree, I also usually recommend new people to set up their environment with stack.
`generics-sop`, after you grok it, there's no coming back to `GHC.Generics`.
Oh, OK. I was worried about the quadratic effects you get without the Church-encoded version but if lifting constructors one at a time I guess it's not really a problem?
Right, I don't think it matters because they quickly get folded in. I also don't entirely have a handle on when things become quadratic.
[http-client](https://hackage.haskell.org/package/http-client): A reliable foundation for writing your own http clients. [cryptonite](https://hackage.haskell.org/package/cryptonite): Essentially the go-to lib for crypto-related stuff. [criterion](https://hackage.haskell.org/package/criterion): I don't use it daily, but still listing it here since it eases writing benchmarks.
how does this affect hadrian?
I don't know if it is allowed as its thursday already, but I am learning Haskell at the moment and I love it! I see that most documentation only shows you the input and output of a function. This is some geting used to and now I'm wondering something about an operator in the ReadP package. If anyone could help me understanding it a little bit better, it would be great! https://stackoverflow.com/questions/46345002/what-does-the-operator-do-in-text-parsercombinators-readp-haskell
Sure it's allowed. ☺️
Was that a joke?
I don't know if I should be thankful that I don't yet grok it, then.
A five line diff for the oracle thing, and gives them the skip feature they were looking for to implement freezing phase 2 (a blocker to switching). 
As well as [either](https://hackage.haskell.org/package/either).
wow, three of these library maintained by bos!
At least for a monad, `T` is a name that rings familiar to category theorists :-)
It doesn't. It's just A) an elegant way to separate precomputed values from the rest. B) A neat example of elgot algebras (in particular, I can't think of a way to do this with anamorphisms). 
I don't spend much time thinking about this, as I'm part of the dopamine business like most others, whether you're working for social media, gambling, doing trading systems or other parts of theis industry. But I'm glad it was brought up here. If you analyze the situation, it's not so much about your morals vs mine, but to put it bluntly, more about not wanting to look at the facts (sorry, but I think that's true!). Fact: Gambling, smoking, alcohol, social media, day-trading etc are addictive given our dopamine response system. Fact: Dopamine is extremely addictive. Fact: Our dopamine system does not have a satiety system. There is no "enough" signal in the dopamine system. A lot of us developers are paid by industries that rely on the dopamine feedback system in the brain. I also think it's fairly undisputed that there's a reason for the human species having developed the dopamine reward system. It favors certain behavior that has been successful for the survival of our species. I also think it's fairly undisputed that we're hacking this dopamine system and that the way we're using it is not too related to it's original "intent". None of the above is politics. It's facts and science. Now to the morals: We can discuss the above without being political, but I think it's a moral obligation, the more we're working on dopamine-inducing systems, to really understand how these systems work. Nobody can really defend their moral stand if they don't know the facts. Now a little dopamine is not a bad thing, but we're collectively designing systems for triggering dopamine shots in the brain. That's worrying. It's likely that us hacking away on the dopamine system is making people unhappy (personally I believe that social media might bring more unhappiness, in aggregate, than gambling). I've been in discussions where how to structure the "beeps" and interruptions per unit time is a core issue. And then we reach for reinforcement learning to give us the answer, not realizing that we're using these tools to optimize for maximum addiction. Now my morals says that certain types of exploitation/hacking of this system is indefensible. I don't understand how, say a social media system that covers most of the global population cannot have an active relation to the health effects of letting machine learning optimize dopamine release in the brain when we know it is guaranteed to increase suicide rates, general unhappiness, and reduce human interaction (the latter, in non-moral terms - reduce the intended use of the dopamine system in the brain). I'd welcome yearly dopamine reports from the whole industry - I think it would help us do a lot more good in the world, because right now we're not optimizing for the right goal. No consumer can currently trust the industry to look out for addiction. That's sad. 
You may be able to. I assume it would make things faster only when computing multiple values. 
&gt; In this release Shake stops trying to pretend to be make. Hooray! Investigating why the `make`-like flags didn't work the way I expected has sunk a bunch of my time in the past; hopefully now others won't have to do that.
It's not really a supercompiler, it's more of a "poor man's supercompiler", with the added benefit that you are mixing recursion with precomputed values. 
How does it behaves when the "format string" is only known at runtime ?
- `conduit` for streaming data efficiently with good guarantees on resource cleanup. - `persistent` for easy, convenient, type safe database access - `esqueleto` for composing SQL queries - `yesod` for websites - `servant` for JSON APIs - `swagger2` for the best Swagger documentation system ever edit: I forgot to add my comparisons to other solutions! Here goes: - `conduit` is already used by the majority of the Yesod/Persistent/etc. ecosystem. I could use `pipes` or `streaming`, but then I'd just need to write a conversion for every `conduit` that the ecosystem provides. Ultimately, `conduit`'s ability to handle a closing pipe gives me more flexibility. - `persistent` manages my data types, migrations, etc. for me with a convenient quasiquoter. It generates a ton of useful types for type safe SQL queries. The limited API it presents for querying and updating is perfect for most of the database tasks I do. - `esqueleto` builds on top of `persistent`, so I can reuse all of the type safety with `persistent` when creating more complex queries. It does have some warts (the monadic EDSL allows for some invalid queries; things like `on` clause matter wrt join order; the design of the library makes it very difficult to modify). It's main competitor is going to be `opaleye`, which I've not used significantly. Opaleye is harder to use, contains much more boilerplate, and forces you to write totally polymorphic types (which typically give much worse error messages than the concrete types that Persistent generates). Opaleye has worse query generation wrt performance/optimization. Opaleye's upside is that the queries appear to be more composable, and they've eliminated the possibility of runtime errors using an arrow/profunctor EDSL instead of monadic. - `yesod` has all the batteries you want for a web app. Sessions, persistence, cookies, content type handling, templating, etc. and a fantastic community and documentation surrounding it. Spin up the Yesod template and just start writing your app. I have never used Happstack or Snap; they seem fine, but I couldn't find as much documentation initially, so I started with Yesod. `scotty` and `spock` seem more like microframeworks, and I'm frankly not - `servant` is a killer app for a specific purpose: JSON APIs that you need to provide a client for. We use `servant` at work for our internal APIs, and we get Haskell clients for free (and JS/PHP clients via Swagger code generation). This makes exposing data extremely fast and easy. Ugh, how could I forget: - `ekg` is a fantastic resource for recording application metrics. I wrote a `monad-metrics` wrapper for an easy way to add metrics to your library, and `ekg-cloudwatch` to push EKG metrics to CloudWatch reporting/metrics. - `amazonka` is an awesome library for communicating with all AWS services.
(yes, i'm a web developer, how could you tell?)
* Async: Absolutely indispensable for multi-threading, especially for clean termination. Makes life so much easier. I can't state enough the importance of this library. * STM: makes multi-threaded life also a lot easier * Attoparsec: quickly parsing proprietary space protocols * Conduit: streaming the stuff * Binary: the reverse for attoparsec in building structures. Used cereal before, but then switched because then it had the required functionalities (don't actually remember which one though).
You can do it with stack too. But that's not the answer for the platform. Git pinning is a good mechanism to manage your own inhouse libraries.
I see you have rx and jquery libs loaded. Also your reflex-basic file is suspiciously small (only 250 kb). What's going on there? 
Like a bos.
Those exercises are awesome and I got surprised when I compared my "solution" to the one you give in there. Really looking forward to see more of this blog!
Even the maddeningly verbose way of creating tuples in languages like C++ or C\# is really painful by comparison. 
This seem almost the description of a boxed vector from `Data.Vector`, whose elements are a sum type of your choice.
Yes. As was the parent, I think.
Some additional detail as to your problem might help a bit - Your problem sounds like it could be an architectural challenge as much as a 'choosing the right data structure' challenge. 
Can you comment on `megaparsec` vs `attoparsec`? Megaparsec claims: &gt; Since version 6, Megaparsec features the same fast primitives that Attoparsec has, so in many cases the difference in speed is not that big. Megaparsec now aims to be “one size fits all” ultimate solution to parsing, so it can be used even to parse low-level binary formats. https://github.com/mrkkrp/megaparsec#megaparsec-vs-attoparsec I personally don't have much experience with either lib but I'm curious to learn how close the megaparsec dream is to reality.
I just asked Tekmo for his thoughts on `megaparsec` vs `attoparsec`, and invite you to respond as well: https://www.reddit.com/r/haskell/comments/71fuwa/what_libraries_could_you_not_live_without/dnbg6ue/
&gt; If you analyze the situation, it's not so much about your morals vs mine, but to put it bluntly, more about not wanting to look at the facts (sorry, but I think that's true!). There is nothing in my post that contradicts or dismisses the facts you described. &gt; it's not so much about your morals vs mine We construct policy in order to serve certain values, so it very much is about morals/values, or desired outcomes at the level of political action. &gt; We can discuss the above without being political, but I think it's a moral obligation, the more we're working on dopamine-inducing systems, to really understand how these systems work. Nobody can really defend their moral stand if they don't know the facts. I have nothing against (and indeed support) understanding how these systems work. It seems like you've assumed that I *don't* know the facts you described (and I'm not sure how you came to that conclusion based on the content of my post), in an attempt to discredit my position. --- Basically, if we as an industry want to ban certain types of work and practices, I think that's fine as along as we can come to an agreement/majority. What I don't approve of is holding individual software developers to a double-standard (call-out culture) when the rest of the software industry can engage freely in these activities.
How would I use such an `f`? In the case of `logEvent`: How can I apply a statically fixed amount of function arguments if I don't even know the function type at compile time?
I want to avoid sum types, because they take as much as space as their largest member. I basically need a something like a pointer that can be casted to objects of the appropriate type.
`ghc-prim`? 
That's not really possible for one person to do. I don't even know where you would go to find the appropriate reference materials, to be honest. (e.g. something to explain to non-Tibetan speakers how to parse ༢༡།༠༩།༢༠༡༧).
Does it have the same speed as the TH version?
As long as it cross compiles that's fine. 
I don't know if you know this, but if you use hackage for looking up documentation, you can also see implementation of that function (on the right side of gray line with function name) [Link to hackage documentation](http://hackage.haskell.org/package/Cabal-2.0.0.2/docs/Distribution-Compat-ReadP.html) [Link to function source](http://hackage.haskell.org/package/Cabal-2.0.0.2/docs/src/Distribution.Compat.ReadP.html#%2B%2B%2B)
You could pattern match on `b` and use `f` in one or two of the branches, knowing the type of the result, or compose `f` with another function `g : (b : Bool) -&gt; if b then Int else Char -&gt; Foo`. This toy example is not very convincing, so let's take another one. How about vectors? -- A Vector API type Vector (n : Int) read : IO (n : Int, Vector n) -- Dependent pair type, an integer and a vector of that length. add : Vector n -&gt; Vector n -&gt; Vector n write : IO (Vector n) main = do (n, v) &lt;- read (m, w) &lt;- read if n == m then -- Actually need a dependent comparison operator that propagates the (in)equality constraints. write (add v w) -- it should be safe to add two vectors in this branch. else error "not the same length"
&gt; they [sum types] take as much as space as their largest member Where did you read this? I don't think it's true. It's certainly not mentioned by the [GHC Commentary](https://ghc.haskell.org/trac/ghc/wiki/Commentary/Rts/Storage/HeapObjects#DataConstructors).
An unboxed sum type probably would.
I'm bringing in rx for a comparison with rx in the events post and jquery as a dependency of bootstrap. The reflex-basic file is the code used for the blog series after it is run through ghcjs with the dedupe flag, then minified and compressed. I tried splitting it out into one payload per post, but the size only changed by a few kb between "everything" and "just the event examples". So the fixed cost of the RTS and the dependencies is the bulk of the size that you are seeing. I might explore that in more detail for the last post in this series, along with some related matters.
That's a good question, I don't know. (I would guess not but... I'm not really basing that on anything besides a hunch.)
Actually I think we probably agree. My post was mostly around your introduction, namely: &gt; The thing is that your personal moral code isn't necessarily universal or shared by others; and I don't think we can all agree on what is moral or not moral. I *think* there is a moral standpoint one will arrive to by looking at the facts, and that contrary standpoints might be based on false beliefs. This is similar to global warming where by analyzing the facts it's hard not to come to the conclusion that something has to be done, although one can disagree about how or what. In this case, I also think that when the situation is analyzed, it's likely that people will agree that something should be done, but how or what might be difficult to agree on. That doesn't mean that we can't agree on what's right and wrong (the moral part of this). So I agree with the rest of what you say, namely that gambling isn't necessary something that should be singled out. I also forgot to mention porn in my list, and highly immersive virtual reality, and I focused on social media, not gambling. I think it's reasonable to focus on what kind of dopamine kick the person gets out of the particular type of interactions multiplied by the number of people affected. Thus gambling certainly does not get a free pass, as it's highly destructive for a lot of people. I absolutely think the individual software developers should take responsibility though, if they can. The effect of what one is doing should certainly weigh in on what job one decides to take, and I will certainly admire someone who does "good" over someone who does "evil". 
Thats parsing sorted. Are you still against time libraries and encoding?
I've started this, not a FP newb, and the topics seems light as of now of course, but I'll see. It's always good to exercise a bit.
I did not have enough experience with `attoparsec`. For my needs, the feature list of `megaparsec` are more interesting. I don't care about performance in that case, but I like the recovery function or the quality of the error message of `megaparsec`.
Well, I still don't want to write encoding or time library (seriously, you know that there may be 62 seconds per minutes, that some month have 28, or 29, or 30 or 31 days and that years may have 365 or 366 days... This still blows my mind...). However I'm satisfied by the way encoding are handled in most libraries. On the other hand, handling time is still painful (especially time difference, timezone and leap seconds / days).
Agreed. But the OP doesn't seem to be using unboxed sums. In fact, it looks like they have correctly guessed the behavior of unboxed sums and assumed that this was how normal data types (which are lifted and boxed) work.
Could you give a brief overview for what you're doing with Haskell? Is it used throughout the company, or on a single team?
&gt; And I think we have to be very careful about what we politicize in our industry; and the more unambiguous and shared those reasons are, the better. "Politics is pervasive. Everything is political and the choice to be "apolitical" is usually just an endorsement of the status quo." - Rebecca Solnit 
For day-to-day programming, you don't need to think about such low level details. Sizes and pointers and such are implementation details. Write the program in the most meaningful way possible, ignoring performance, then optimise it after. Regarding this specific question- almost everything's boxed by default in Haskell, so the size of some `[a]` is already the size of a linked list of pointers. Algebraic datatypes are one of the most important constructs in Haskell. Use them liberally. 
ok, instead of "we have to be very careful about what we politicize", if you don't like that characterization, because it's too _apolitical_, how about "we have to be very careful about what (or who) we demonize". I'm not sure that this hair-splitting distinction is addressing the main points.
Worse than that, there's no practical algorithm to decide it, because minor orbital pertubations that we can't measure can change when you need to add leap whatevers. In preparation for the interplanetary stage of human civilisation, I suggest we abandon leap everything and just count seconds since the beginning of the unix epoch (which is NOT actual unix time). [The book A Deepness In the Sky had this for a post-earth civilisation, with Ksec (16 minutes and 40 seconds) replacing hour-day like scales, Msec (11 days 13 hours 46 minutes and 40 seconds) replacing week-year like scales and Gsec (about 35 years) replacing decade-millenium like scales. Phrases like "I'll be there in five minutes" were tranlated to "I'll be there in half a ksec" and you actually get used to it within a few chapters. Hsec would work for minutes as well - "I'll be there in 3 hsec" even has the same number of sylables, but I don't recall it being used. Prefixing with h also allows day-like (HKsec) and year like (HMsec)] ... who's with me?
Would you assist with relocation?
Why do we have both `EitherT` and `ExceptT`? They seem identical.
Actually, the overhead gets optimised away by GHC, [here's](https://github.com/kcsongor/generic-lens/blob/master/test/Spec.hs) the relevant test which uses the `ghc-proofs` library to prove this. 
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [kcsongor/generic-lens/.../**Spec.hs** (master → d5a67a0)](https://github.com/kcsongor/generic-lens/blob/d5a67a0001a49d5038393fa3a97519fe6c432017/test/Spec.hs) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dnbusl6.)^.
iirc. megaparsec fits parsec's featureset better: have good errors for humans. attoparsec is more low level, for machine-to-machine protocol purposes: faster, but less help when error occur.
My name is bos, /u/bos
Not a library, but `c2hs` is a total godsend. Also surprised no one's brought up `base`. There's a ton of great modules in there.
That's awesome! Does the same thing hold for prisms? I remember reading about `Generic`'s nested sum representation causing performance issues for something (I think it was `aeson`?), but that was several years ago. (Or do you skip all that altogether and only use the type-level information?)
Thanks to everyone for the feedback on the last post :) If you've been reading before, you might want to do a hard refresh so you can see the latest goodness in the pages that you've visited before. I've added a few more exercises this time, in case people wanted something to play with over the weekend, and I'm busily working on the exercises for the next few posts.
I don't understand. Why is it so important to evaluate the sequences to WHNF? I would not think that a thunk containing an int and a sequence to insert that int into would be much (if any) larger than the resulting sequence. /u/Syrak, do you have any insight on this?
That's a good point I hadn't considered. I'm not sure about it either. It does seem that a thunked collections in which you only insert elements would be almost as good as a list.
whoa what? I had no idea GHC was any good at optimizing Generics away.
Is there any reason you don't post your own blog posts on Reddit yourself?
https://news.ycombinator.com/item?id=10903778
I'm working on a real-time simulation, where a list stores all the entites. Now, the list can contain as many as 100,000 elements, and each type is between 100 to 500 bytes in size. If I use a sum type, all the elements in the list would take 500 bytes. In C, you could just store a list of pointers that point to the address where each entity is stored. This way each element in the list would only be 4-8 bytes, instead of 500 bytes. This waste huge waste of space is the reason I want to avoid using sum-types. 
That link does not contain anything indicating indicating that sum types take up as much space as their largest member. You can convince yourself of this by running the following code: -- This consumes at least 10x as much memory as a single a data Ten a = Ten !a !a !a !a !a !a !a !a !a !a deriving Show -- This is a thousand (10^3) a's (duh) type Thousand a = Ten (Ten (Ten a)) -- This is a billion (10^9) a's type Billion a = Thousand (Thousand (Thousand a)) -- This is a billion billion (10^18) a's. type Exa a = Billion (Billion a) -- This "should" consume several exabytes of memory. data OneOrExa = One Int | Lots (Exa Int) deriving Show -- Allocating a value of this "enormous" type, just to be sure example :: OneOrExa example = One 42 -- print the value to make sure it's actually used main = print example and observing that it does not, in fact, consume several exabytes of memory. On my machine, loading it into GHCi takes less than 10 seconds, running `main` is instant, and at no point do I get an out-of-memory error.
Well, I always thought that sum-types were defined as tagged-unions. Looks like I was wrong. Thanks for the help.
Sum types *are* tagged unions in Haskell. It's *untagged* unions that take up as much space as the largest possibility, C-style. Tagged unions use a tag to discern how much space the rest of the data occupies. If sum types did not discriminate size in this way, then recursive data types like `data List a = Nil | Cons a (List a)` would take up infinite space. The fact that this only takes as much space as is needed is proof that runtime information is determining the size.
`these`, `diagrams`, `mysql-simple`.
Is that the expected etiquette? I am happy to do whatever is expected. 
"Expected" isn't the right word, but we're certainly more likely to see them if you do =)
This is something I have also wondered about. In terms of the etiquette of it.
I think you should.
I try to avoid posting my own content as well because on reddit self-promotion is generally frowned upon and can get you banned.
Is there anything like `awaitWithDeadline` in Conduit, that will wait at most some specified amount of time? If not, can you give me some clues how it can be implemented and if it can be implemented at all.
Interesting. Honestly, any article that doesn't get posted here primarily because of that convention is evidence that the convention is harmful. If we're going be ok with companies posting their job posts here (which is a much more extreme form of self promotion), we should have absolutely no problem with authors posting their blog posts.
This could hardly be counted as self-promotion. As a mod of two other communities I take the view that if you (a) spam the page with your content relentlessly and (b) don't engage in discussion in comment threads other than your own then you'll get a firm talking-to. This is how it seems to be with most other niche/topic subreddits. I wouldn't expect /r/haskell to be very different and if it is then the first port of call would surely be the mods telling you where you went wrong rather than kicking your arse to the stratosphere.
I think it _should_ hold for prisms, but I'll have to inspect the generated core to make sure, as it's very easy to accidentally trip up the optimiser. As you said, the reason it can do any of this optimisation is that all of the transformations are done using the statically known (type-level) structure, and everything gets specialised and inlined away.
Indeed [Bartosz 's articles](https://bartoszmilewski.com/2014/10/28/category-theory-for-programmers-the-preface/) are very nice. Very **informaly**, one of the explaination of why the free monad is defined the way it is: take a functor ```f :: * -&gt; *``` which only have to be a functor, it may not be neither a monad nor even an applicative. We want to wrap ```f :: * -&gt; *``` into a type/data structure ```m :: * -&gt; *``` such that: * any value of type ```f a``` can be injected into ```m a```. Said differently we need a function: ```inj :: f a -&gt; m a```. * ```m``` is a monad. There are many many such monads ```m```. We can even make it a class class Wrap_f m where pure :: a -&gt; m a map :: m a -&gt; (a -&gt; b) -&gt; m b join :: m (m a) -&gt; m a inj :: f a -&gt; m a Remember that we can equivalently define a monad either by ```map/join``` or ```bind```. The *free* monad over ```f``` is the "smallest" of such monads where a monad ```m1 :: * -&gt; *``` is smaller than another monad ```m2 :: * -&gt; *``` if there is a monad morphism between ```m1``` and ```m2```. Such a morphism is a function ```h :: m1 a -&gt; m2 a``` such that all the ```Wrap_f``` operations commute with ```h``` : h (pure a) = pure a h (map f u) = map f (h u) h (join u) = join (h (map h u)) h (inj w) = inj w For such a "smallest" ```Wrap_f``` called ```Free f``` to exists it is required that there is a unique morphism between it and any ```Wrap_f``` ```m```. This can be translated into h :: Wrap_f m =&gt; Free f a -&gt; m a ```h``` respecting all the laws above. You can build a data type having all the ```Wrap_f``` operations very easily by making each operation a constructor: data AlmostFree_f a where Pure :: a -&gt; AlmostFree_f a Map :: forall b. AlmostFree_f b -&gt; (b -&gt; a) -&gt; AlmostFree_f a Join :: AlmostFree_f (AlmostFree_f a) -&gt; AlmostFree_f a Inj :: f a -&gt; AlmostFree_f a Such a datatype have all the operations but does not respect the laws. For example ```Map (Pure 5) ((+) 1)``` is not structurally equal to ```Pure 6```. To enfore the laws we need to force what should be equal to be structurally equal by only allowing one representation. For example ```Map (Pure 5) ((+) 1)``` must not be a valid representation, only ```Pure 6``` should be. Basically we need to take every law and select only one representation for each equality. For example you can completely get rid of the ```Map``` as it does not add behavior. Its behavior is completely determined by ```f``` being a functor and the monad laws. ```AlmostFree_f``` becomes data AlmostFree_f a where Pure :: a -&gt; AlmostFree_f a Join :: AlmostFree_f (AlmostFree_f a) -&gt; AlmostFree_f a Inj :: f a -&gt; AlmostFree_f a likewise ```join (pure m) = m``` so the argument of ```Join``` must not be a ```Pure```, only a ```Inj``` or another ```Join```. ```join (inj (map pure (u : f a))) = inj u``` so ```Join``` and ```Inj``` can be merged into a single constructor. What you obtain at the end is data AlmostFree_f a where Pure :: a -&gt; AlmostFree_f a JoinInj :: f (AlmostFree_f a) -&gt; AlmostFree_f a which is the definition usually used.
Were optimizations enabled? The code and other information (especially in bold below) to make the benchmark reproducible are also missing. My own [benchmark with **code and commands run**](https://gist.github.com/Lysxia/30f50556cb1681bbaaca630c338b5f78). - **Version** of GHC: 8.0.2 - **Options**: `-O0` then `-O2` - Package versions: Stackage LTS 9.4 - Double check that the program running is the right one: `-fforce-recomp` With `-O2` (see relevant excerpt below) the bytestring's "original" fast version is 3 times faster than the one with a slower `renderRow`. The link includes `-O0` for comparison, as well as variants with the slower `renderString`. benchmarking original time 489.2 μs (478.7 μs .. 504.8 μs) 0.994 R² (0.990 R² .. 0.997 R²) mean 500.5 μs (488.6 μs .. 521.8 μs) std dev 48.93 μs (28.17 μs .. 72.97 μs) variance introduced by outliers: 75% (severely inflated) benchmarking 10 time 1.645 ms (1.637 ms .. 1.654 ms) 1.000 R² (1.000 R² .. 1.000 R²) mean 1.650 ms (1.645 ms .. 1.656 ms) std dev 17.05 μs (13.04 μs .. 24.59 μs) There is still a discrepancy with what the docs report, but in the other direction: slow code is even slower.
I have no relevant experience in the topic, but I found [this video](https://youtu.be/T7XwTolu9YI) very interesting. The presenter live codes the game logic of a simple flappy bird clone using the Yampa library. Yampa is an arrowized FRP library so the upfront learning cost of this approach is probably very high compared to the other suggestions, since you need to understand `Arrow` and related type classes. Also he does not explain the technical details of opening a window, getting keyboard inputs, rendering geometric primitives, etc. So if you want to try this approach you're probably best off editing [his source code](https://github.com/helsinki-frp/yampy-cube) into a pong game so you can focus on game logic.
bytestring is specifically designed to be compiled with -O2
The extra benchmark there mostly to suggest that OP did not enable `-O2`.
Really interresting. I think I'll use `syncIO` from now on. https://hackage.haskell.org/package/errors-2.2.2/docs/Control-Error-Util.html#v:syncIO 
pipes!!!
There's also the safe-exceptions library which expands on this. Easy to drop into existing projects too.
That's a common misconception. They changed the reddiquette at some point. What they really meant was "no spamming". Promoting your blog is perfectly acceptable.
On top of that, ADTs store *pointers* to their fields' values. So even `OneOrExa undefined` wouldn't be a problem.
&gt; If I use a sum type, all the elements in the list would take 500 bytes. In C, you could just store a list of pointers that point to the address where each entity is stored. This way each element in the list would only be 4-8 bytes, instead of 500 bytes This is not at all how sum types work in the GHC implementation of Haskell. In Haskell, every boxed type is stored as a pointer to an object on the heap. Each sum type constructor creates an object on the heap of the minimum size necessary to store only the fields in that constructor. For example, If you had a sum type: data MySum = MySum1 Int Int Int | MySum2 Int And an array `[MySum1 1 2 3, MySum2 5, MySum1 4 5 6]`. Then you can think of having a heap like such: 1. Cons 2. 4 3. 8 4. MySum1 5. 1 6. 2 7. 3 8. Cons 9. 11 10. 13 11. MySum2 12. 5 13. Cons 14. 16 15. 20 16. MySum1 17. 4 18. 5 19. 6 20. Nil Above, each list item is a conceptual word cell that can store one word. Boxed types are stored as pointers, and primitive types are stored unboxed. Thus cells 1-3, represent a `(:)` constructor, where the head of the list is the value at cell 4 (start of the first `MySum1` object), and the tail is the value at cell 8 (another cons cell). Thus cell 1 would be the value pointed to by a variable containing the haskell list specified above. You can think of the constructor names as placeholders for whatever tag GHC eventually assigns the constructors. As you can see, the storage for `MySum2 5` takes up cells 11 and 12, whereas the storage for `MySum1 1 2 3` takes up cells four cells 4-7. Thus, sum types do not allocate anymore than the fields the individual constructor contains.
Thank you for that writeup. I have a tangential question: how does GHC's garbage collection play nicely with the JVM's garbage collection?
It's perfectly acceptable to promote your blog on reddit.
They are identical. The main reason `EitherT` exists is because `transformers` used to not have `ExceptT`. Now that it does, I consider `EitherT` obsolete.
I believe there was a change in professor, so a change in content, change in projects and change in teaching style. Take a look through the same projects and you can possibly see some of the differences. I'm no expert, but I went through 2013 as well recommend it.
In the human history of vice, regulating the production or consumption of vice has had debatable results - It is still unclear, empirically, if attempts for a third party to moderate based on consumption frequency (in isolation) have had any net positive social effects at all. Hence, this is hardly cut and dry for any subject, and if you believe you have objective data convincing you otherwise, I suspect very strongly that you're suffering from confirmation bias due to social norms. I agree that predatory practices can be discouraging, but I would tend to focus less on the delivery of the vice and more on the victimization or ostracization of the consumers (or, in some cases, the proprietors). That, at least, can be objectively observed as definitively harmful to the social fabric, and we have some established methods ameliorating that impact, such as therapy and education.
It's a challenge. What happens is that whenever the Java Native interface (JNI) hands us a reference to an object, it implicitly adds a new GC root for it, so the JVM GC knows not to reclaim the object. But then we need to be careful to *eventually* hand the reference back to the JVM, so that the object can be reclaimed again. We sometimes do that by wrapping a reference in a foreign pointer and registering a finalizer. Most of the time we use lightweight memory regions, where a reference survives the current dynamic scope and then is implicitly handed back to the JVM when exiting the scope. The Java side does similar things for Haskell values. What happens if there are cycles across both sides? In that one case we throw our hands up in the air... It's a problem that shows up in any shared address space interop between GC'ed languages. We had to deal with it in HaskellR. And whoever tackles Python or similar will have to deal with it too. Time to write another post I guess? ;)
&gt; Time to write another post I guess? Yes please! In general, I think these kind of technical details are really interesting. I would also appreciate a bit more technical details on how the typechecker plugin actually works (i.e. something that includes actual code snippets of the plugin). The blogpost here stays quite vague on the technical details :)
&gt; Time to write another post I guess? A blog post would be much appreciated. May I suggest that you write a paper on this topic. It's fascinating stuff.
The predecessor of this library was quite useful, while I was developing new parser for Cabal. Comparing `Show` outputs by hand is just awful. I feel this is quite common problem, hopefully `tree-diff` will suit your needs as well. AMA.
preamble: /u/lightandlight I believe is right on--write your code with correctness in mind and after it's correct use a profiler to guide your optimizations if it doesn't meet your performance specs. however: Curious. You're working on a real-time simulation but you seem to be optimizing on memory usage. Given that Haskell may not be in general a good choice for a real-time simulation but it may work for your specific requirements wouldn't it still be best to optimize (if you're going to optimize early) on performance and not be concerned with memory? 100,000*500 B = 50 MB seems like a drop in a bucket to me in terms of memory usage. Even you were to use an order more memory, it's still not anything to be concerned with especially for a real-time application. 
Nice, I’ll probably use this in the test suite of `llvm-hs`. Manually diffing large LLVM ASTs is not fun.
Feedback welcome, in particular review of the proof's correctness.
More information about Simula: **Mission:** Facilitate a Linux future for VR &amp; AR Desktop. In the short-run, this means allowing people to run 2D Linux apps with current generation headsets. In the long-run, this means allowing people to run Linux in standalone AR &amp; VR HMDs. Currently, Simula is aiming to be compatible with the HTC Vive. **Contributors:** We're looking for open-source contributors. If you're interested in using Haskell to (cleanly) bring VR and Linux together, but don't have an HTC Vive, PM or email me at georgewsinger@gmail.com. **TODOs:** | Goal | Status | Short-Run Horizon | Long-Run Horizon | |:------------------------------|:-----------------|:-----------------:|:----------------:| | Basic, Launchable Compositor | DONE | X | | | Wayland App Compatibility | DONE | X | | | X Applications Compatibility | | X | | | HTC Vive Compatibility | | X | | | Usable VR Desktop | | X | | | Test Suite | | X | | | Clear Text Resolution in VR | | | X | | Special-Purpose 3D Linux Apps | | | X | | A "VR Linux Distro" | | | X | | Standalone HMD Compatibility | | | X | **Technologies in Use:** Haskell, C/C++ (c2hs, inline-c), OpenGL, [wayland](https://wayland.freedesktop.org/architecture.html) &amp; [weston](https://github.com/wayland-project/weston), [OSVR](https://github.com/OSVR/OSVR-Core), [OpenVR](https://github.com/ValveSoftware/openvr/tree/master/samples), [nix](https://nixos.org/nix/) (for build dependencies).
Sure! We have a single team responsible for developing and managing an internal platform that most of the company depend upon to deploy, tune, etc. our main product installations in multiple DC's all around world. The system is a critical part of our cloud tooling, so reliability is a major concern. We also have bi-weekly Haskell workshops aimed at other teams and there has been a lot of interest - many key people think that at least some parts of the main product could hugely benefit from a rewrite in Haskell. :)
Depends on what kind of help you would need. Could you submit your application describing your situation and we'll get back to you next week?
Why Haskell? Aside from, of course, the usual reasons that Haskell is an awesome language, were there any particular reason(s) that you felt it would be suitable for this project?
Look up homomorphic encryption. GameDevs are not doing it right now, because it's still very research-y and the algorithms we do have are terribly slow.
For games soft real time is enough. But that's still hard in Haskell.
I don't think drawing the connection between f-(co-)algebras and lenses is helpful, because with lenses the thing being 'unfolded' isn't actually the updated data structure (`t`), but rather the `Functor` representing the effect, e.g. `Const` or `Identity`. `traverse :: Applicative f =&gt; (a -&gt; f b) -&gt; t a -&gt; f (t b)` looks similarly deceiving, but we aren't actually unfolding the traversable here. If we specialize to `Applicative f =&gt; (a -&gt; f a) -&gt; t a -&gt; f (t a)` we could argue that it unfolds every element of the traversable one level and combines all unfoldings with `&lt;*&gt;` over the structure of the traversable. That feels a little like nailing with a screw driver.
&gt; I don't think drawing the connection between f-(co-)algebras and lenses is helpful, because with lenses the thing being 'unfolded' There doesn't have to be an unfold anywhere. F-algebras appear elsewhere, i.e. groups can be constructed as F-algebras. Also, if you read the linked paper by Erwig, he uses F-algebras and F-coalgebras in novel recursion schemes (to do some pretty neat things).
The original codebase was in C++, and it was so convoluted and hard to understand; Haskell was chosen as the rewrite language to add clarity (and boy did it add clarity). It's also the most beautiful language to program in (IMO), and that was honestly a big part of the decision. The challenges with Haskell are (potentially) as follows: garbage collection causing frame jitters, and a lack of contributor enthusiasm from the Haskell community, which isn't traditionally graphics/window manager focused (with the notable exception of XMonad). However, Haskellers are a curious (and extremely smart) bunch. And if Haskell hasn't been used so much for VR graphics in the past, someone has to start the ball rolling. I'm willing to bet the whole project on Haskell, mostly because it's just not fun programming in most other languages. It also adds some thrill knowing that working on this project means you're taking Haskell to a new domain. The dust hasn't settled with VR as a new platform. Imagine how amazing it would be if in 5 years everyone was programming in Haskell on this new platform. It sounds crazy but I don't see how it's impossible: the web browser made Javascript the most popular language in the world, while Apple and Android products made Objective-C/Swift and Java survive into the 2000s. What will happen in the next 10 years with VR is an open question.
/u/krakrjak is this your secret project?
I'll let him speak for himself :-]
RIR ;)
Yes it is! I'm happy we are finally putting some sunshine on it.
I'm familiar with homomorphic encryption, I'm assuming they want something less restrictive, under-baked, and slow because the topic is game development.
Just out of curiosity, how long is the reflex-platform and the exercises supposed to take to compile and finish setting up? I installed nix, and then ran ./try-reflex inside the root folder of the cloned reflex-platform repo; that alone took several hours (I think). Then I got back out and cloned your exercise repo and ran nix-shell at the root of it; the setup for that took a few hours. Then I realized I was actually supposed to do it inside the exercise folder, so I cd'd into /code/exercises and ran nix-shell in there; it's been a few hours and it's still compiling and setting up but I think it's getting closer. I'm hoping that the caching actually works and that all of this is just the first time painful install... (For what it's worth, I'm using arch linux and a single install version of nix on arch since that's the only one that works nicely; I do have my /nix directory correct though, I think) --- I hope to get to the Events tutorial soon :)
"Haskell hasn't been used so much for VR graphics in the past" Actually, considering the size of the community, there's been some exciting contributions specifically /u/lukexi 's rumpus project https://www.reddit.com/r/haskell/comments/4relu2/a_haskell_livecoding_environment_for_vr/
It seems strange and backwards to me to claim that connecting lenses and F co-algebras argues for lenses being the right way to describe record updates. Quite the opposite! That lenses are the right abstraction for record updates is immediately apparent. (That van Laarhoven lenses are the right implementation is less obvious, but not too hard a proposition to support in retrospect.) That F co-algebras are a useful way to think about this is far, far less obvious, and is the proposition that actually needs arguing for.
The OS specific notes for the reflex-platform mention that things are busted for Arch at the moment, although I don't know if that has changed recently. 
That's only for the multi-user nix install (which is the default). If you just use the normal curl into sh method of installing nix, that works fine. Then you can run ./try-reflex just fine (although it'll take a long-ass time to setup). I'm not sure if that breaks anything else, however. I was more concerned with the fact that running `nix-shell` inside `/code/exercises/` seems to be forcing me to rebuild ghc (again), 2 versions of chromium (again), python (again)... etc.
I've spent only 5 mins looking at slick, and probably Opaleye is closest to it. Does slick solve for object/value lifecycles as well? Or is it just a typesafe DSL over SQL? 
For reference, I think you are referring to [this paper](https://web.engr.oregonstate.edu/~erwig/papers/RandomAccessADT_REPORT.pdf). Sorry, I haven't really read it all and the connection to lenses is still pretty much unclear to me (where is the `Bialgebra`?). So, when you say &gt; We assume further that the lens points to a value of the same type, so that the function `id` will always have the appropriate type You mean to specialise the given lens even further, to the point where you only accept `Functor f =&gt; (a -&gt; f a) -&gt; (a -&gt; f a)`? It reads to me as 'Hey look, for this really special case of a lens we can show how the lens laws can expressed as co-algebra homomorphisms of `(Identity, a)` and `(Const, a)`'.
Jeremy Gibbons wrote up a similar article showing the connection to "costate comonad coalgebras" and that the lens laws are just the comonad coalgebra laws for that functor. 
Maybe the argument should be rephrased as rather than being "evident it's the right way", but more that the presence of extra tangential work confirms that this is a good abstraction?
Good news! I finally found the culprit. It was, as you described, the login shell being set to zsh, but what I hadn't realized before is that [this was set in their admin panel's profile settings](https://www.screencast.com/t/SgDbPhV54). I was looking for some custom ssh setting on my local machine all that time. -.- Thank you for giving me that clue since I wouldn't have thought to try changing it otherwise.
I found that benchmarks in many packages aren't even working. We have CI (eg. travis) to ensure packages can be compiled. But no such comparable service exists to ensure benchmarks run and don't regress. I tried text, aeson, bytestring and a few others and the benchmark code was in really bad shape. Sometimes not even compiling, or used to take hours to complete all benchmarks (that's impractical).
I've been wondering a little about benchmarking on CI recently. Unfortunately, it's a bit tricky on a free cloud CI platform like Travis or Circle CI because your build is run in a VM on a shared host, which introduces a lot of performance jitter. I imagine it could be done, but probably not as an open-for-all service like we have for cloud CI testing.
Interestingly, your improvement helped, so it looks like Haskell wasn't optimizing it in automatically. Thanks!
Makes sense. Thank you!
It's gonna be a pretty large application, so I thought I should make the right choices from the begining. Anyways, my profiling has shown that Haskell is well suited for this situation(with a little help from C).
Seq only needs 3 extra words of memory per element, and it's easy to make a variant which takes only 2 or even less ([video explanation](https://youtu.be/-HZ4bo_USvE?t=49m1s)). How many extra words does the thunk representation use?
Something's wrong with the javascript on this page, it keeps making network request after network request...
I think the extra exercises are great! Thanks!
Ah. I assumed that if it wasn't set to bash then you must have changed it and would know where the setting is. Re 2nd paragraph: no problem.
I have the following `Maybe`like type indexed by a type-level boolean data Optional (a :: *) (t :: Bool) where Just' :: a -&gt; Optional a True Nothing' :: Optional a False And this `AnyList` that keeps track at the type level of whether there's any Just' value in the list: data AnyList (b :: Bool) where Nil :: AnyList False (:+) :: Optional String a -&gt; AnyList b -&gt; AnyList (Or a b) where `Or` is a type family that does the obvious thing. With these types, the only way to construct a `AnyList True` value is by giving `(:+)` a `Just' s` so we should be able to write a function with the following type: extractString :: AnyList True -&gt; String but I can just get to extractString :: AnyList True -&gt; String extractString ((Just' a) :+ _) = a extractString (Nothing' :+ rest) = extractString rest Even though `rest` is guaranteed to have type `AnyList True` (because `Nothing' :: Optional String False`) GHC does not infer that. I know I could use `unsafeCoerce` here but I would like to know if there's a more recommended approach I could take to make this work. Thank you very much.
Any way to get inline-java working on Windows?
This package allows one to send a JavaScript code snippet to Node.js for execution, and retrieve the result as a plain JSON value. The rpc process is totally encapsulated. This is not yet on Hackage, as I'd like to improve documentation &amp; hear some opinions before making the first release. Feedback is appreciated! EDIT: I've changed the project name from `nodejs-eval` to `nodejs-interop`, since I plan to support calling Haskell from Node.js too. The repo is now [here](https://github.com/TerrorJack/nodejs-interop)
Huh, small world. I went to school with Forrest, author of motorcar
&gt; Quite the opposite! That lenses are the right abstraction for record updates is immediately apparent. (That van Laarhoven lenses are the right implementation is less obvious, but not too hard a proposition to support in retrospect.) That F co-algebras are a useful way to think about this is far, far less obvious, and is the proposition that actually needs arguing for. I think I agree with you that the ease of working with the lens library makes it obvious it's the "right" way (that is the relevant criterion), I still think it can be insightful in a "this is the cosmically correct way" - sort of like the confirmation you get when an idea is invented by logicians and computer science both.
Interesting! I will have to track down the paper, thanks :)
Heh, add dependency left pad.
Wow. Up next is a quasiquoter to inline JS into Haskell, right? ;)
Indeed! I'm looking for a way to share a session across all TH splices (at least for a single module). If each splice starts a server, evals and quits, compilation speed will be horrible.
String.padEnd/padStart is a built-in function now ;)
You still need a polyfill for older runtimes (Edge &lt; 15 for example, see bottom of https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/padStart)
Why are you using a linked list? If you're concerned about space, a list cons constructor has quite a bit more overhead than storing elements in a boxed vector. The constructor tag uses a word, the pointer to the element uses a word, and the pointer to the next element uses a word for 3 words of overhead per element in the list. With 100,000 elements, that's an overhead of 300,000 words, or, on my computer, about 18MB. Boxed vectors will be much more memory efficient, with a small amount of overhead to keep track of space/size, and then a contiguous block of memory containing a single word pointer to the element. 
Isn't Simula the name of a programming language? https://en.wikipedia.org/wiki/Simula
That's true!
Ghcjs uses Node for TH, right? Either they've solved it or you could help make it faster!
This project sounds really exciting and it just so happens that I own an Oculus rift. Are there any plans to support that or could you perhaps give some insight into how much work it would be to implement it?
That's why it's funny that it is in the example on the usage page.
Thank you for taking a stab at this problem. I absolutely hate digestive-functors for form processing and am always on the lookout for the something more sensible. Unfortunately, I am beginning to realise that a sane form handling (or validation) library is not possible unless Haskell gets proper records with the ability to treat fields and collection of fields as first-class values at the type-level.
Turns out stateful TH has been there since 2013 (see this [thread](https://mail.haskell.org/pipermail/ghc-commits/2013-June/002106.html)). This is not related to the external interpreter introduced by luite and his ghcjs. I've already implemented inline JS functionality, check the updated README :)
"Absolutely hate" seems rather strong - what bit is quite that bad? The stringly typed matching between field names and their `View` isn't great, but it's not the end of the world and certainly hasn't caused me show stopping problems.
&gt; Are there other free monoids? Yes! This one makes me raise my eyebrows a bit, because free structures are unique up to isomorphism. But using lists as free monoids works under the forgetful functor from **Monoid** -&gt; **Set**. `Maybe` could maybe be viewed as free monoid for the forgetful functor **Monoid** -&gt; **Semigroup**, but I'm not sure. I don't know how this relates to the general term "the free monoid" - is the free monoid only for **Monoid** -&gt; **Set**? https://math.stackexchange.com/questions/705943/are-these-adjoint-functors-to-from-the-category-of-monoids-with-semigroup-homomo#709330 Maybe is relevant, but I don't have time to read it right now.
That's a good point. I don't know enough category to speak from that perspective. 
The problem is that the Oculus SDK and their driver runtime is only for windows. The [OpenHMD project](http://www.openhmd.net/index.php/blog/) is working on open source drivers for the Oculus Rift, Vive and several more devices, but the actual camera tracking code of the Oculus Rift is not ready yet. Once OpenHMD has that ready, the [OSVR-OpenHMD](https://github.com/simlrh/OSVR-OpenHMD) plugin can be used to bring Oculus tracking to the OSVR SDK, and then Simula will already just work with it. (OSVR-OpenHMD will probably need some updates too to actually deliver the tracking data). It should also be possible to use another tracking system like Nolo and make it work together with the current OSVR-OpenHMD plugin. The nice thing about the OSVR SDK is that applications like Simula only query for semantic paths like /me/head or /me/hands/left or /me/hands/right and users can configure their osvr plugins to set up which tracking data from which device ends up at these paths. Some basic info: /r/virtualreality_linux/wiki/intro_osvr. the not so nice thing about OSVR is that Linux support is an afterthought for them.
Haskell's form situation is much more sane/safe than the other languages I've used. It could certainly be better but I don't think we need parametric records for that. Whatever improvement Haskell gets to records certainly won't include parameterizing over a functor Ala vinyl. That's a useful feature, but no other system has anything like that.
Try the monad instance for Formlets. It is the key for dynamic widgets that change its UI depending on the user input.
Ah.. Thanks.. I thought it only was the documentation source code in a sphinx manner.
You left out the most important part - how are you defining Or? {-# LANGUAGE KindSignatures #-} {-# LANGUAGE DataKinds #-} {-# LANGUAGE GADTs #-} {-# LANGUAGE TypeFamilies #-} -- Open world problem: -- type family Or (a::Bool) (b::Bool) = (r::Bool) | a,b -&gt; r -- type instance Or True False = True -- type instance Or False True = True -- type instance Or True True = True -- type instance Or False False = False -- How can we be sure there isn't a -- type instance Or False False = True -- Injective type families? -- Remember injectivity just means the domain uniquely identifies the codomain. So this won't help either. -- Closed type family? Yes, this should help. -- see: https://wiki.haskell.org/GHC/Type_families#Closed_family_simplification type family Or (a::Bool) (b::Bool) = r where Or True a = True Or False b = b data Optional (a :: *) (t :: Bool) where Just' :: a -&gt; Optional a True Nothing' :: Optional a False data AnyList (b :: Bool) where Nil :: AnyList False (:+) :: Optional String a -&gt; AnyList b -&gt; AnyList (Or a b) infixr 7 :+ extractString :: AnyList True -&gt; String extractString ((Just' a) :+ _) = a extractString (Nothing' :+ rest) = extractString rest And the use: *Main&gt; extractString (Nothing' :+ Just' "String" :+ Nothing' :+ Nil) "String"
&gt; The category theory intuition for “free” roughly expands to: &gt; &gt; This structure gives you a free X when given a Y The intuition is actually that a free object is "free" of constraints/relations to the maximal extent possible. Free functors then are things that lift your structure into some other structure in the most unconstrained way possible. e.g. the free vector space over a set is a vector space that has that set as a basis, and linear maps from that vector space can be written as functions from the set/basis which you lift into the vector space structure (i.e. you only need to define a linear map on the basis, and "extend by linearity"). There are no constraints like `b_1 = b_2 + 5 b_3` for your basis elements. The free monoid over an alphabet is the set of strings over that alphabet with concatenation; there is no way to simplify/reorder/reduce expressions beyond the rules for all monoids (associativity, identity). If you denote your "multiplication"/operation in the monoid by juxtaposition, and use repeated elements instead of writing powers (e.g. "xx" instead of "x^(2)"), you get strings.
This is a great post about it: http://comonad.com/reader/2015/free-monoids-in-haskell/
This looks interesting. What would be a use case for this, just out of curiosity? 
Lets check. To see if two functors are adjoint, you look at the "oblique arrows". Let S be a semigroup and M be a monoid, then that instance for `Maybe S` is left adjoint to the forgetful functor `U` if a semigroup homomorphism S -&gt; UM is the same thing as a monoid homomorphism Maybe S -&gt; M Is it true? Yes, because a homomorphism `Maybe S -&gt; M` preserves multiplication so it gives a semigroup homomorphism `S -&gt; UM`, and we can recover it from the `S -&gt; U M` because the identity element has to be sent to the identity element of `M`.
https://patternsinfp.wordpress.com/2011/01/31/lenses-are-the-coalgebras-for-the-costate-comonad/
Not at all necessary, the act of presenting a form and acting on the result forms a monad, then you just need a few combinators to glue pieces together nicely for presentation.
From the introduction: &gt; A puzzlingly named, exceedingly technical device introduced to structure the denotational semantics has by now achieved cult status. It has been married to effects -- more than once. It is compulsively looked for in all manner of things, including burritos. At least two ICFP papers brought it up without a rhyme or reason (or understanding), as the authors later admitted. I am talking about monads. &gt; In truth, effects are not married to monads and approachable directly. The profound insight behind monads is the structuring, the separation of `pure' (context-independent) and effectful computations. The structuring can be done without explicating mathematical monads, and especially without resorting to vernacular monads such as State, etc. EDIT: Gah, just noticed my typo in the title; it should have been 'Kiselyov', of course.
Thanks!!
Any implementation would likely use https://hackage.haskell.org/package/base-4.10.0.0/docs/System-Timeout.html
Just curious, how many forms would you be validating in your project that used dig-fun? How many fields and at what level of nesting? I can't foresee form processing with dig-fun survive one round of refactoring from anyone who is not the original author of the code (thus nullifying the biggest strength of Haskell). What I hate is positional matching of forms and record fields, thus nullifying the very reason why one uses records in the first place. Secondly it seems that you're back to writing parsers by hand when using dig-fun, thus introducing a new bug-vector that didn't exist earlier.
I need O(1) random insertion and deletion.
We have [nodejs-exec](https://github.com/lamdu/nodejs-exec) for Lamdu's execution of JS code. We just execute a subprocess directly. Could be nice to switch to nodejs-eval! However: we do need some way to guarantee that nodejs will support tail-recursions (at least node version 6.2.1). Does nodejs-eval have any sort of guarantee on the version? Can I depend on it with a minimum version requirement to get that node version? 
And so is SHA-1. As far as I know, both are only vulnerable to collision attacks (the ability to create two new messages which hash to the same value).
[True](https://security.googleblog.com/2017/02/announcing-first-sha1-collision.html). Although with SHA-1 at least an attacker requires decent amount of computation power. (Which should not be seen as an encouragement to use it!)
I'm writing a blog engine, mainly wrapping shake &amp; pandoc. pandoc supports inline TeX, and can insert appropriate script in output html to render it, either via MathJax or KaTeX. Then I noticed that KaTeX supports static rendering, so I want to run KaTeX on node and render all the math when generating pages. The simplest way is to pipe scripts to node and parse output from stdout, but I thought since someone else may have similar demand, might as well write a real rpc for this..
I haven't implemented that yet. Should be a piece of cake, simply check node version before `npm install`, and start node with `--use_strict --harmony_tailcalls`. I need to design some proper config types for `withEvalServer`/`makeEval` though. Please open an issue and list missing features you need. 
This is a great explanation of the intuition behind free.
I'm going to assume that its just reddit and that is supposed to be two lines. I think the problem is there is no else clause on your if/else. Everything in Haskell is an expression which must evaluate to a value (or throw an exception) therefore you must give one for the False branch. Also "n elem ['a'..'z']" is already a Bool so there is no need to wrap it in an if...else. You can just write this: smallLetter n = n elem ['a'..'z']
Thanks multivector. Yes it is two line. My sloppy pasting skills is the culprit:) I will try your advice right now. 
You must always have an `else` in an if statement. Haskell if statements are not like others: they do not perform actions, they return values. To see why this is a problem, try to work out what `smallLetter '@'` would be.
It is worth noting, however, that the costate comonad coalgebra view is sort of an evolutionary dead-end in my opinion. Why? It arises because of the coincidence that `s -&gt; a`, and `s -&gt; a -&gt; s` share an `s` prefix, yielding `s -&gt;(a, a -&gt; s)` when you go to fuse the two together. This gives you `s -&gt; Store a s`, and then the coalgebra laws give you the lens laws. However, when you go to look for the notion of a prism you get `(a -&gt; s, s -&gt; Either a s)` with identical laws for embedding and matching and that doesn't have a common prefix or suffix at all! There is no 'state monad algebra' equivalent. The only reason the former worked was because of a quirk of encoding and the presence of currying. It needed all of the Cartesian closed structure of the category we live in to even talk about. On the other hand, approaching a lens as saying `exists c. s_i &lt;-&gt; c * a_i` where * is the tensor for a monoidal category and you can replace exists with a colimit to make it more categorical generalizes to far more settings. You can now talk about lenses in any monoidal category. This gives us the notion of lenses and prisms we have today. If your category isn't symmetric monoidal, you can distinguish left and right lenses usefully. There are plenty of such categories and the hard information preservation requirements of lenses really show that they are a tool for working in linear logic, the internal language of a monoidal category rather than anything about the Cartesian mess that we usually present them as. (This also shows that lenses and prisms aren't properly "dual" as they are just lenses with respect to different choices of monoidal structure on Hask that happen to be dual.)
Tried to understand this in terms of haskell but I am not sure if I got everything: class Monad m =&gt; MonadState s m | m -&gt; s where get :: m s put :: s -&gt; m () Can be seen as a tagless final dsl which offers the primitives get, put, return and bind. That is my (and probably many other haskellers) first instinct when it comes to dsls. However the monad superclass might not be necessary: class Monoid m =&gt; NonDet m where type Val m decons :: m -&gt; r -&gt; (Val m -&gt; m -&gt; r) -&gt; r which might allow for more and simpler implementations. Now that I think about it, we could even stay forwards compatible in case that we need the additional power later on. class NonDet m where nempty :: m a ncombine :: m a -&gt; m a -&gt; m a decons :: m a -&gt; r -&gt; (a -&gt; m a -&gt; r) -&gt; r -- overlaps with monadplus but whatever class (Monad m, NonDet m) =&gt; MonadNonDet m Is there some sort of type hackery that would allow the equivalent of a `forall a. Monoid (m a) =&gt;...` super class? Or could monoid be poly kinded?
That said, if you do want a bunch of material that takes the store-centric view of lenses, http://comp.mq.edu.au/~mike/pub2000.html has a bunch of material on the topic. In particular the slice category formulation and its associated adjunction mentioned in http://comp.mq.edu.au/~mike/papers/72.pdf is really quite pleasant.
I'm also interested in this topic. In the main time the [reducers](https://hackage.haskell.org/package/reducers) might be of interest to you. I also found that one of the main problem when aggregating data what the need for intermediate data structures which are usually slight variation of the original types, to basically keep track of the aggregated keys. Parametric types is an overkill, there is the solution of extensible records, but it's not mature enough. There is mi package Metamorphosis but it's not on hackage yet (and I haven't used it yet to generate report)
Dat intro, dough. 
There is a YouTube series called "code deconstructed". They dive into the code base of yampa (an FRP framework) and xmonad (a titling window manager). 
This is how you would write the code in your post: smallLetter :: Char -&gt; Bool smallLetter n = if n `elem` ['a'..'z'] then True multivector's corrected version: smallLetter :: Char -&gt; Bool smallLetter n = n `elem` ['a'..'z'] Pointless version: smallLetter :: Char -&gt; Bool smallLetter = (`elem` ['a'..'z']) You can use the "source" button below any Reddit post or comment to see the plain text source.
It gets my goat that people bog down what's a relatively simple concept ('imagine if the semicolon in C were an operator, just like the arithmetic, &amp;c., operators, and you could determine how it behaved based on the type of the expression, just like how '+' can mean addition or concatenation depending on the types') with stupid bloody burrito and spacesuit metaphors.
It's basically the tenary operator written out
This is `ForallF Monoid m` with [`Data.Constraint.Forall.ForallF`](https://hackage.haskell.org/package/constraints-0.9.1/docs/Data-Constraint-Forall.html). [Quantified class constraints](https://www.reddit.com/r/haskell/comments/6me3sv/quantified_class_constraints_pdf/) was published at ICFP this year to make such a constraint work more naturally, though people have been talking about it for a while. ([\#2893 Implement quantified context proposal](https://ghc.haskell.org/trac/ghc/ticket/2893))
Sure you can. To get the same effect, you could e.g. class MyEq a where eq :: a -&gt; a -&gt; Bool instance MyEq Char where eq a b = a == b instance MyEq a =&gt; MyEq [a] where eq [] [] = True eq (x:xs) [] = False eq [] (y:ys) = False eq (x:xs) (y:ys) = (x `eq` y) &amp;&amp; (xs `eq` ys) main = do print $ "Hello" `eq` "World" print $ "Hello" `eq` "Hello" You could look up haskell's instance declarations to make yourself familar with this concept.
Thanks for your explanation and patience;)
Awesome! My implementation of `Or` was type familiy Or (a :: Bool) (b :: Bool) :: Bool where Or False False = False Or _ _ = True And that didn't work. Your code does indeed work. I'll look into the documentation you linked to try and see whether I can figure it out
Maybe u will interested in [Ermine](https://github.com/ermine-language) and the presentation by [Edward Kmett](https://www.youtube.com/watch?v=o3m2NkusI9ku)
Thanks a lot for the post ! I have never used Free monads for now, just mtl style, but I was wondering why just a List of Monad was not enough/not the same as a Free monad. Your blog post explain it very well 
[arena](http://hackage.haskell.org/package/arena)
Thank you! That's a great start. :-)
Why not link to the question?
&gt; What else is an action? If the type constructor Foo has a Monad or an Applicative instance, a value of type `Foo Int` can be viewed as a Foo action producing an Int. &gt; `replicateM` will extract the values out of those containers and give me back the values sans container. What do you mean, "sans container"? The type of `replicateM` specialized to IO is `Int -&gt; IO a -&gt; IO [a]`, so the IO "container" is still wrapping the output. By the way, it would make more sense to think of a value of type `IO Int` as an IO action producing an Int than as a container holding an Int. &gt; because it is only a container for a function of type `s -&gt; (a, s)`, but I don't get back a list of functions when I use `replicateM` with a `State s a` value. The type of `replicateM` specialized to `State s` is `Int -&gt; State s a -&gt; State s [a]`. So what you get is not a list of function, but a (wrapped) function of type `s -&gt; ([a], s)`. &gt; I still don't understand how replicateM was useful in converting a value of type `State StdGen Int` to `State StdGen [Int]`. A value of type `State StdGen Int` can be seen as an action which produces an Int. `replicateM n` runs this action `n` times and produces the list of `n` results. How? With the `f &lt;$&gt; action1 &lt;*&gt; action2` idiom and an Applicative instance, we can run two actions one after the other and combine their results using `f`. `replicateM n` uses this idiom `n` times to run `n` copies of its input action, and combines the results into a list.
Your complaint reminds me of this tutorial for a new OCaml monad library: http://binaryanalysisplatform.github.io/bap/api/v1.3.0/Monads.Std.html#intro It is, I think, very clear precisely because it approaches the concept in the way you describe. On the other hand, if you don't come at monads via a category theoretic approach, then mustn't you sacrifice much universality and integrity of understanding? I.e,, you'll know how the work practically, but won't know how they relate to and build on other structures.
When you use `(==)` on values of type `[Foo]`, the compiler knows it needs to find an instance for `Eq [Foo]`. It finds the following instance: instance Eq a =&gt; Eq [a] where [] == [] = True (x:xs) == (y:ys) = (x == y) &amp;&amp; (xs == ys) Which can be specialized to `Eq Foo =&gt; Eq [Foo]`. As you can see, the implementation of `(==)` for `[a]` uses `x == y` to compare values of type `a`, so there needs to be an `Eq a` constraint on that implementation. This is specified by the `Eq a =&gt;` constraint on the instance definition. So after finding this instance, ghc must now find an instance for `Eq Foo`. Whether it succeeds at finding one or not determines whether your original `(==)` call on values of type `[Foo]` succeeds as well. The above mechanism is called "instance resolution". 
What "source" button?
It's an RES feature, I think.
Great, many thanks, that seems to make sense. I needed to know the term "instance resolution". I was googling things to do with type derivation and not really coming up with the right things!
Thanks for the example, makes sense once I see it.
I think "point-free" is probably a less confusing term for newbies
I'm wondering about adding algebraic datatypes to a language, maybe something that already has a vanilla HM type-inference algorithm. Specifically I'm wondering about how to check case expressions. I haven't been able to find anything written except in "The Implementation of Functional Programming Languages" where AFAICS pattern-matching expressions are reduced to the "enriched lambda calculus" where the enriched part adds the `[]` operator (which is used for falling through each case if it doesn't match) and `SEL-t-i` functions (used for selecting the i^th argument in the constructor `t`, and which I think are supposed to be built in to the language and type-checked before being desugared to normal lambda calculus). I think I could use something like a Scott, Church or Parigot encoding and type-check the encoded version, but I'm wondering if that's how ADTs are usually implemented.
I think it's just waiting for somebody to propose and implement it. There might be a psychological effect to it caused by the easy confusion of this question with "Why are functions not `Show`-able?" The difference here is that in a REPL we can query variable names and we can just look up their definitions. How much more convenient would it really be, compared to looking up the source manually or via an editor?
@gelisam - thank you very much for taking the time to respond to my question. Understanding that a type constructor that has an instance of `Monad` or `Applicative` is an action is very helpful, and will help me generalize what I know from `IO`. I have a question (or rather, a statement that I don't know if it is fully correct or not) that is related to this: If I have a value of type `State StdGen Int`, what is the "haskell" way of finding out if that type is valid for `replicateM`'s second argument - i.e., `m a`. With `Maybe`, I can use `:i Maybe` and see clearly in the repl that there is an `instance Monad Maybe`. With `IO`, I can do the same and see that there is an `instance Monad IO`. With the `State` type constructor, I tried to do `:i (State StdGen)` (thinking that I had to feed it the type constructor with kind `* -&gt; *`, as in the other examles), but that didn't work. However, If I do `:i State` instead, I can see some instance [safe] Monad (State s) instance [safe] Functor (State s) instance [safe] Applicative (State s) Since `s` is a type variable without any constraints, I can instantiate `s` to any type constant, including `State StdGen`. Then, going back to the type signature of `replicateM`, `m ~ State StdGen` and `a ~ Int`. Is this correct? I don't think I had internalized before (and am actually in the process of) that the `m` in `m a` is any type constructor with kind `* -&gt; *`, including a type constructor that is "created from the partial application of a type constructor with a higher kind than * -&gt; *`. 
For a fair comparison you should probably use Int instead of Integer. Int fits in a single machine word while Integer will dynamically grow in size to avoid overflow.
Excellent monad tutorial
Have you seen Parallel and Concurrent programming in Haskell (the book) yet? [Here's the code samples from the book](https://github.com/simonmar/parconc-examples) and [a tutorial document](https://github.com/simonmar/par-tutorial) written by the book author. They might help you quite a bit with the parallel and Concurrent bits. Just in general, though, you might have luck speeding the program up quite a bit by using unboxed vectors (or just normal vectors). Strictness annotations on the prime test may also help I'm addition to using Int instead of Integer. (Integer tries to use Int when it can, falling back to the bigint library when it would overflow, so sometimes it's way slower than it "should be")
I would *strongly* recommend reading “Parallel and Concurrent Haskell” by Simon Marlow. It’s a really awesome resource about concurrency, and even just general Haskell performance. But for this particular problem, yes I think you’re right: `parList` or `parMap` is probably the way to go. The [parallel library](https://hackage.haskell.org/package/parallel-3.2.1.1/docs/Control-Parallel-Strategies.html) is almost definitely the right thing to use.
I am on ubuntu and can't get this to work correctly either. With `work-on ghcjs path-to-exercises` it says error: anonymous function at /home/user/Projects/reflex-tutorial/code/exercises/default.nix :1:1 called with unexpected argument ‘mkDerivation’, at /nix/store/wgg4rzg3hyywfd7b0917qmj46 17rza7k-nixpkgs-32833c010ecf868826aaa3b60d322bf697f37134-src/pkgs/development/haskell-module s/make-package-set.nix:69:27 When I just use nix-shell in the exercises directory nix starts to build all the things from source: these derivations will be built: /nix/store/5pkbvjwwqfxbfg11rnp7g1b4dyi8y8mn-sqlite-3.17.0.drv /nix/store/s8jfbj9v38pkvx8gpa3jzgwsip36zwi9-python3-3.6.1.drv /nix/store/0icz1y52xdx3mizqajvpldzc8fbir14d-python3.6-bootstrapped-pip-9.0.1.drv /nix/store/lfhs6d3lvjxbcvmbq5dm28x811rax6bj-which-2.21.drv /nix/store/0ilh8zqnklqf7yx94q017vsn118cmvbf-pciutils-3.5.4.drv /nix/store/xzhhrdff49sdp58sbs67mxff1yjdw8iv-speexdsp-1.2rc3.drv /nix/store/0ir592g0bd68frfx4gbydpxqv4w1bpdk-speex-1.2rc2.drv /nix/store/zhqpqzjifbr0plz4mq5bhjadwm87c8dv-scrnsaverproto-1.2.2.drv /nix/store/16wrv5hwd1ir30l9zgl4i812b0m6hqb1-libXScrnSaver-1.2.2.drv /nix/store/1di47rcklq500f4spsifvaqc926qk48m-util-linux-2.29.2.drv /nix/store/qj914l3frkfwv3gg6lkwxd12j7fykkcr-stdenv-linux-boot.drv /nix/store/m5snv6mxr4fyikd684hic3yarx17lif2-zlib-1.2.11.drv /nix/store/d7x48k2v2m7qv0pgxjr6ncvb9aga8j7p-gnum4-1.4.18.drv /nix/store/fbgqa26fpbkhqi1h2mvlv289a9zyq7az-perl-5.24.1.drv /nix/store/pp904r6p198fafw64zq4cnghgjz1h1kw-bison-3.0.4.drv /nix/store/d3j4qmdp3zr0s2ag510z6j5xlwrfc187-binutils-2.28.drv /nix/store/dkx8zxb38nxsmkc3bl7x77jh5jgkd2i2-expand-response-params.drv /nix/store/gcwq7zb8x57f41xiv0ryskbyxnv554n9-bootstrap-gcc-wrapper.drv /nix/store/p8hxq2jihw7vyr8nxh38dxkynryhzy74-stdenv-linux-boot.drv /nix/store/in4a1vrqc9bsh3b4jb8kpwflqcyvv28d-expand-response-params.drv /nix/store/1hlgnfws63d1dgg4nrfhwppn2xg8387w-bootstrap-gcc-wrapper.drv /nix/store/1mmham578psml77rnp7rrjdydrpfhyx5-util-macros-1.19.1.drv /nix/store/a7spl1la4wr57gah84v0gb8yg54zc20z-paxctl-0.9.drv /nix/store/ifpmfm0j7p53ywlyzxj2p4f88mjsjwp6-patchelf-0.9.drv /nix/store/72b5q61s2kvsbyab5afax4mgcq0d23i5-stdenv-linux-boot.drv /nix/store/5crm90fdj9xl3gy53iyxbjn57bamwphx-xz-5.2.3.drv /nix/store/gjj0k5g85fi08r4ikk1figvh6p5azz4q-gcc-wrapper-5.4.0.drv /nix/store/gm10kw5afy22jp9g3w7yl9acrjmkhbak-stdenv-linux-boot.drv /nix/store/h58x5ha432pkn5fv36wyxwkp6iwz79zf-pcre-8.40.drv /nix/store/24s9bdzm6vgn14fz89ksixx739qbazqp-pcre-light-0.4.0.4.drv /nix/store/xpsnpyx3d6cxh1xgpx47gr5wxrzrlrli-guile-2.0.13.drv /nix/store/4a5xfjxd4zxx6z2h47m184abn9waf5hf-autogen-5.18.12.drv /nix/store/chaijnv6axak34sx1l3g5rdj2cc80xbv-texinfo-6.3.drv /nix/store/gdnfz7y3lh6ziziq2z7rb39lgfzjpdd6-libtasn1-4.10.drv /nix/store/wcsg3ppgxr73dfw15v8i3g2jmy5ffx4z-p11-kit-0.23.2.drv /nix/store/zdrma30cz63qv7arj037m6j9jxjdy40x-lzip-1.19.drv /nix/store/wcwdryhvgbm05bh6kdrkwc31ygdxmsxg-gnutls-3.5.13.drv /nix/store/2pnzwyj9macj6sa0snf50khkbiyl42am-libmicrohttpd-0.9.53.drv /nix/store/dncbhbr44g3jqjlbx3f39dlhi57md366-gettext-0.19.8.drv /nix/store/2y0fab5aqwi66s4nzd3s4ryr87a8lnjk-attr-2.4.47.drv /nix/store/3a9azg6yvnmzkdh77805lsg0qj1vpi3j-nss-3.31.drv /nix/store/qfg8bxd504195912qhd7b5hm8xvqxvvv-ruby-2.3.4.drv /nix/store/ga5jsgns0gxrpm4lkrbb5a2cjlh3pq0j-ruby-2.3.4.drv /nix/store/dmnfm36is9lsl21xqj28d790dbqw02nw-docbook-xsl-1.79.1.drv /nix/store/dy04bc5gmqk3hb3k2qkq4kfwqqim9axr-libcap-2.25.drv /nix/store/w663ksk1awcavaszd1gl921gl1f8ljv1-acl-2.2.52.drv /nix/store/zb7y20pjr023z1n6s41vwk0s6bzmisg4-gnu-efi-3.0.5.drv /nix/store/bbvs3fj0mgncpfz5zk700829cirxjklx-systemd-233.drv /nix/store/3nlkzlv15f7gvfw73ixcpddm6zifyvl1-libusb-1.0.20.drv /nix/store/41g2a00k9l4rsk5c0fl14y863p5h1gps-xcb-util-renderutil-0.3.9.drv /nix/store/xidh2pfwxzq2c3yfg9qz9bx2aldjgcrg-w3m-0.5.3+git20161120.drv /nix/store/4fwrk1kxxinag0ah8iz83g0i7b9mbsgc-xmlto-0.0.28.drv /nix/store/4jh9wnv33k3grh3mzhq9pdhsp2i19d30-yasm-1.3.0.drv /nix/store/mmhd1rjcrazc178y6fwc21dg0bj0dwmv-hook.drv /nix/store/kd8l5xds9hr064rrlyzic0d5n2r78hva-python3.6-setuptools-36.0.1.drv /nix/store/5ayiz4gnbk16v48hq6l06phfgrndm3s8-python3.6-pyxdg-0.25.drv /nix/store/8bzhj3v2kkhnfbpjpwl3iy57rawy7bk0-xtrans-1.3.5.drv /nix/store/94hj59dc6hmkwz3862mxsabv1pg4hpkm-xf86driproto-2.1.1.drv /nix/store/96yc50zx2x9d8iipslzp0swpxs8algcn-xcb-util-image-0.4.0.drv /nix/store/bqz1zlmcn7ayn3a1008fjnnrvl64z5yj-xcb-util-wm-0.4.1.drv /nix/store/d700czlvma1a1h7lx1i6q1zd9m685gll-xcmiscproto-1.2.2.drv /nix/store/f9ikxgdqmxvcb8ghaai5zzc9awm4nkyy-resourceproto-1.2.0.drv /nix/store/dwkj1w8scmvab32a83xwjfa95m4k867m-libXres-1.0.7.drv /nix/store/givp8b5bwqy8m7zkc8m9g11dsfwibl0s-videoproto-2.3.3.drv /nix/store/hcvf65m32fzxalbll5jlrwmddan9cijv-epoxy-1.3.1.drv /nix/store/karr55sanjq53gnlnsqa5qjas0qshm3w-xf86bigfontproto-1.2.0.drv /nix/store/lhrka31i9lvdxiaffdnh89j91zc0sqkq-libXfont-1.5.2.drv /nix/store/mjw1pmrj1rbnxmvscf88ngyxf3d2hry9-xkbcomp-1.4.0.drv /nix/store/qdwygf19dfhn0jklr2wiryihb5wdwvkc-xcb-util-keysyms-0.4.0.drv /nix/store/srn76lv3cvrpv45n05l4f243hdaw62d9-xf86dgaproto-2.1.drv /nix/store/xadlb3jwqfsi8giy4fkx6ny0i567qbb6-libXfont2-2.0.1.drv /nix/store/5rhsm5a59j2xnvqn7qvgjmlfnfg4k4fd-xorg-server-1.19.3.drv /nix/store/kc5dpmix4l54yc8cpij6qixx5gpk8lk9-tasty-0.11.2.1.drv /nix/store/vrn4x8yx3xzsfdkn3f9i0xassh7fg5vb-tasty-hunit-0.9.2.drv /nix/store/75wcq8zisjdc5xm6m732wa6g7206q0c8-temporary-1.2.1.drv /nix/store/7vl0f25ls8inqgx6dgq8c1w496zhjdmc-xauth-1.0.10.drv /nix/store/9a90720h4iv2fzff8y2g61d5qqmg3ami-snappy-1.1.4.drv /nix/store/anlaqybjikxqwaiwfprwzhcsyh43irbv-util-linux-2.29.2.drv /nix/store/aq5fcdqw8qyv43kicz5mbc8hw9x1c50m-libpulseaudio-10.0.drv /nix/store/jj8wvdvs36akrqcqljg6irn9mpv4zy93-svox-2016-10-20.drv /nix/store/q2kq3wypqwrgba9xjw360bj16bbh139x-libao-1.2.0.drv /nix/store/bm0l2c987jyl7z6x1yhnbg7r8dhzcm2k-speech-dispatcher-0.8.5.drv /nix/store/kvplwpsyp521xqv4qjg2wwpq52jb1clh-xdg-utils-1.1.1.drv /nix/store/icf3gj87lr939h8qz922bcxpa1bwr1n6-chromium-59.0.3071.86.drv /nix/store/dqv51i6aaf1cr37qmi870rvdf7nscirg-chromium-59.0.3071.86.drv /nix/store/lwnbhl4814jx84y2s7lm4d0vp4bj001h-temporary-1.2.1.drv /nix/store/ndy9bcazjyfsxafj2ml110dx42hj5b99-xvfb-run.drv /nix/store/8vryjk95jb3ww4fnsy8gi0ih9pgv1vaq-reflex-dom-core-0.4.drv /nix/store/yzgjq4iygnlar5b7a9617xc011f1gdmf-tasty-quickcheck-0.8.4.drv /nix/store/p5sqirr8lca20zs06pmasqw3vbxczvz8-hackage-security-0.5.2.2.drv /nix/store/cj3fywx8pggckbsyj7hzgqjmdw2hwqa5-cabal-install-1.24.0.2.drv /nix/store/klp106s4qzcjavj4771lap32cz2151xr-ghc-8.0.2-with-packages.drv this happens with nix 1.11.2 in both single and multi user install with ubuntu 17.04. Using try-reflex and ghcjs directly works fine. Any ideas what might cause this? 
Yes, that's correct!
Yeah, my bad: I thought sum-types were always implemented as C-unions. Turns out, Haskell's default storage model is extactly what I was looking for all along. :)
You'd have to find it in a GHC extension. Haskell 2010 is not that different from Haskell 98 from a design perspective. The main differences I can think of are that the FFI got rolled into the spec instead of being separate, and NplusK patterns feel out of style again. Because we live in a causal universe (mostly?), none of the of advanced in TT and categorical logic that happened since 2007 were included in the Haskell (19)98 design.
From the source: &gt; Two types are apart when one cannot simplify to the other, even after arbitrary type-family simplifications. Sadly, `Or False False` and `Or _ _` can match the same pattern so you can not draw the desired simplification from these rules. On the other hand my version's `Or False` and `Or True` are always "apart" as the linked page calls it.
The burrito paper was a joke paper by a category theorist for other category theorists...
That's what I thought at first but it still won't work even if I write the whole type family _explictly_ as in Or False False = False Or True False = True Or True True = True Or False True = True Which if I'm right should work due to all of them being apart right?
Couple of things: - You're using big integers, while I am pretty sure that Fortran does not. - You're using `mod`, but for positive numbers you should use `rem` instead. Also, use `quot` instead of `div`. - You print out a lot of stuff using slow `String`. You should either switch to printing things using packed strings (e. g. `Text`) or skip string massaging in order to only examine numeric performance. The following code runs in 0,7 seconds on my machine: isprime :: Int -&gt; Bool isprime n = all (\x -&gt; rem n x /= 0) (takeWhile (\x -&gt; x*x &lt;= n) [2..quot n 2]) main :: IO () main = do print $ length $ filter isprime [2..10^6]
Thanks. Fixing that and fixing the first program to just check values [2..truncate(sqrt(fromIntegral n))] makes them both run in less than 1.5 seconds, i.e about half the speed of Fortran. Cool. This also fixes my idea that there is inherent speed disadvantage for lists. If someone is wondering: I am not a Fortran expert. Trying to move away from Gauss, a Matlab-like program. Have been learning a little Fortran, Julia and Haskell.
Thanks, I'll check that. And you are right, Integer vs Int was a big part of the problem.
Thanks, I'll check that.
&gt; if you don't come at monads via a category theoretic approach, then mustn't you sacrifice much universality and integrity of understanding? There's always time for universality and integrity of understanding once one's actually used monads a few times and a clean and simple tutorial goes a long way to getting to the latter.
I'm on mobile right now, so hard to look things up, but I'm pretty sure Wadler has a paper about efficient pattern matching. Edit: I think this is the paper I was thinking of: http://homepages.inf.ed.ac.uk/wadler/papers/pattern/pattern.pdf Edit 2: I just realized you mean that you want to type check a case expression. Sorry, ignore me.
How do I indent "correctly"? I'm currently learning haskell and I often find inconsistent (or unreadable) formatting in my code. Is there some sort of coding standart? If possible I'd like to do my indenting manually (w/o hilint).
I indent 2 spaces. I prefer short-ish lines. I think about 60-80 characters per-line? Here is a typical record declaration that I might use: data Foo = Foo { fFirst :: Blah1 , fSecond :: Blah2 } deriving (Read, Show, Eq, Ord) For a larger example of how I like to indent here are two examples modules that I've contributed to: * https://github.com/matterhorn-chat/mattermost-api/blob/master/src/Network/Mattermost.hs * https://github.com/matterhorn-chat/mattermost-api/blob/master/src/Network/Mattermost/Types.hs I hope that helps.
Thanks. I'll look at them :D
&gt; You print out a lot of stuff using slow String. As long as you’re using `show`, switching to `Text` will only add unnecessary overhead. So you have to use something that goes straight from `Int` to `Text`. And anyway, wouldn’t the cost of printing to a console at all dwarf the difference in cost between `Text` and `String` in this case? Certainly it is dwarfed by the actual `isprime` calculations. Seems like a pointless micro-optimization to me.
I haven't gotten this, but I wonder if it's related to the removal of static libs? I ended up having to install ghc-static and stack-static before I was able to install criterion yesterday.
I can't shed any light on that. If no one chimes in here then I encourage you to ask on haskell-cafe.
If it's free from points, then why do I see so many `.`'s?
If I write `main` as follows: main :: IO () main = do putStr . unlines $ map show (filter isprime [2..10^6]) I get 0,85 second runtime instead. That's clearly a significant difference. I mentioned fast printing only to possibly get parity with a Fortran implementation; I would prefer not benchmarking printing at all here.
&gt; I'm wondering if that's how ADTs are usually implemented. Not really. Case expressions for plain ADTs are not hard to deal with in plain HM. One possible implementation: first infer a type for the case scrutinee, then get a fresh meta for the type of the whole case expression, then for each case check that LHS is a valid constructor pattern, unify the type of the LHS pattern with the scrutinee type, add the pattern variables to the typing context and unify the RHS with the type of the whole case expression.
You can use [Criterion](https://hackage.haskell.org/package/criterion) package for micro benchmarking.
Oh I see. It’s the `unlines` that’s slow there. I’d wager `Text.unlines` would exhibit the same problem, albeit a little less extremely.
You are absolutely right: my recursive code runs in .97 seconds on my machine when I suppress the extra output and print only the last prime. Yours run in .76 seconds. My Fortran code, printing only the last one runs in .457 seconds. So my main conclusion holds: in this very limited benchmarking Fortran is between 30% to 50% faster. For me that makes even my badly written Haskell definitely a contender, Haskell is really fast. There just is no comparison in readability between the Haskell code and my clumsy Fortran. I am not making any claims that my Fortran code is optimized, I am not a professional programmer and certainly not a professional Fortran programmer.
My employer: [RELEX Solutions](https://www.relexsolutions.com). Sector: SaaS/Supply Chain Solutions. Location: Helsinki, Finland. We have smaller offices all around the world but technical development is concentrated here mostly, remote is not strictly ruled out. Always accepting open applications. See also https://www.reddit.com/r/haskell/comments/7166v5/haskell_job_opportunity_at_relex_solutions_in/
I've rewritten the notes about getting started and set up with things - including adding some notes about explicitly setting up binary caches - because people have been trying a surprisingly large variety of things so far. I think I also misunderstood what ./try-reflex was doing with respect to setting up the caches when I first wrote the install instructions. Hopefully my edits make things more clear rather than less clear :) You might need to do a hard refresh in order to see the updates. I'll try to sort the caching out once I have a spare moment. You're not going to have any luck at all with `work-on ghcjs ./exercises`, so I'd stick to running `nix-shell` from the `exercises` directory - if that doesn't work, let me know and I'll try to fix it. Most other things you can do are just going to heat your machine up a heap.
You're meant to use `./try-reflex` to install Nix - I think that was the first sentence of the exercise :) People have tried all kinds of things, and I think I had some misunderstandings about how much `./try-reflex` was doing with respect to caching, so I've rewritten the getting started notes to be more explicit about the caching and to talk about some other paths to installing Nix as well. Hopefully it's a step forward rather than a step back - I did do the rewrite after a weekend away :)
And it [originally started as someone complaining about monad tutorials](https://byorgey.wordpress.com/2009/01/12/abstraction-intuition-and-the-monad-tutorial-fallacy/) by using "monads are like burritos" as an intentionally absurd internal metaphor, which was then [extended by a guy who said that burritos are potentially a type of monad](https://blog.plover.com/prog/burritos.html). So yeah, "monads are burritos" has been a joke from the start.
&gt; Is there anything obvious that I could do in the second version without sacrificing readability to make it faster (still more 5 times slower than Fortran). I can actually live with five times slower, so this is a secondary concern. The two libraries usually recommended are [repa](https://hackage.haskell.org/package/repa) and [accelerate](https://hackage.haskell.org/package/accelerate-1.1.0.0/docs/Data-Array-Accelerate.html). They would both make parallelism in the example you cite fairly easy. If you decide to do this, I would also suggest that you read the (outdated but very good) [book](http://chimera.labs.oreilly.com/books/1230000000929) by Simon Marlow on the topic. &gt;How do I parallelize that the evaluation (in this case the "let aout" line)? Regardless of the language, I will be running my actual project on a supercomputer cluster with multiple CPUs, and so parallel processing is a must. I'm not sure what the situation for Haskell with regard to multiple CPUs is. I would guess that this would be totally fine, but that depends on how the operating system handles it I think. &gt; my hunch is that "parlist" might be what I need, but I really can't figure out it based on documentation. The repa and accelerate libraries have map, fold, and filter that work in parallel :) Both of them work on arrays rather than lists, but this is completely worth it when you're doing performant computing.
If you're doing numerical computations, arrays are probably better and hence repa or accelerate would be a better fit.
Applicative functors? Anyways theoretical advances often take more than 10 years to trickle down. Monads certainly did, and they're one of the really useful paradigms that FP introduced. The /r/math poster is probably not very well-informed.
Accelerate is definitely overkill here, and linked lists are not problematic in this case. In fact, the linked list could potentially be rewrited-rule'd away in this case, making it cheaper than arrays/vectors.
Hi folks. I was trying to get involved in some beginner-friendly pull requests, but I frankly got stumped. Can anyone help me understand at a high level what this pull request achieved: https://github.com/parsonsmatt/servant-persistent/pull/21/files What background knowledge to I need to have to understand what is going on here? I've been blogging about learning Haskell though the Haskell Book (latest post [here](https://medium.com/@StevenLeiva1/haskell-book-chapter-23-state-757f8423ff1) in case you want to see where my knowledge leve is right now), so its a bit demoralizing to have no idea what that PR (which is, again, tagged beginner level) is doing at this point. 
Whenever I dig into some example I downloaded to play with, what is the best way to find out what library is certain import coming from? Example: #!/usr/bin/env stack -- stack --install-ghc runghc --package turtle -- cp.hs {-# LANGUAGE OverloadedStrings #-} import Turtle import Prelude hiding (FilePath) parser :: Parser (FilePath, FilePath) parser = (,) &lt;$&gt; argPath "src" "The source file" &lt;*&gt; argPath "dest" "The destination file" main = do (src, dest) &lt;- options "A simple `cp` script" parser cp src dest How do I know which library from project dependencies in the `.cabal` file provides the `Parser` type? Most of the time I need that to search for more documentation on this type with google/hoogle Maybe there's some simple tip for doing that.
Not sure if you're joking, but the word "point" here refers to [function arguments](https://en.m.wikipedia.org/wiki/Tacit_programming). Other "points" like the function composition operator or interval notation are not relevant.
Applicative is awkward to define in terms of category theory, and is almost completely irrelevant to mathematicians. Applicative was invented *by* haskellers *for* haskellers.
Indeed, this is what kind of bums me out about the prospect of bring records to haskell. They just don't really do what I need. In spite of this, I understand that they are useful to many other people for various things. However, I am excited that Dependent Haskell will make it possible to write something like `vinyl` but with a field ordering that prohibits duplicates. I want this so badly.
I think the PR is tagged beginner because it doesn't really do much at all (but as you might have noticed it does require some more advanced haskell knowledge). It is about monad transformers, which at a high level allow for multiple monads to be composed together. I believe the haskell book also has a chapter on them, you can take a sneak peak if you're interested. The reason that this is done at all is that this opens the way for interesting combinations of the AppT monad.
They are replacing their `App` monad with the more generic and flexible`AppT` monad transformer. It could be a bit confusing at first, but conceptually monad transformers are types that build monads out of other monads. If `mt` is a monad transformer and `m` is a monad, then `mt m` is a monad too. So where there was just one monad `App`, we now can use any number of monads like `AppT IO` or `AppT Maybe` or `AppT []` or ... It can actually be more complicated. Not all monad transformers can be paired with all monads. But leave that for another day. There's lots and lots of information about monad transformers out there, just google it if you want to know more. (You will want at some point). The old `App` type is equivalent to the new `AppT IO` type, so they provide a type synonym `type App = AppT IO`. This should give some degree of backwards compatibility.
It's not surprising. Parsec consumes about that much. I don't know anything about trifecta. I can see that you're using String which is not great; ideally your parser library such as attoparsec would let you consume a ByteString which wouldn't involve allocation other than the pointer and length, e.g. `takeWhile`. Also, you can !bang your data slots to make them strict, and if you switched to ByteString you could put an unpack pragma there to make it unpack the pointer and offset in-place. I don't know what Asg and Var are but I'd apply similar rules there. That should at least reduce some allocations for you. The rest is dependent on the parsing library which I don't know. I see from your stats output that it's using a rope data structure and decoding the UTF8. You could avoid that overhead using attoparsec, if your language uses ASCII keywords and token separators.
For what it's worth some degree of live reloading is doable: https://github.com/chrisdone/ghci-reload-demo 
&gt; If LISP can do this why can't we? Not really an answer, but in Lisps, functions and data have the exact same structure, which makes it trivial to show the definition of a function (at least its definition after macro expansion). 
Is there any recommended libraries for dealing with xml? I started looking at HXT, but I'm not sure if there's others worth considering. I basically just need to parse some xml and convert it to a data type that I've defined.
I've tried on and off over the past several weeks, and this is about as close as I can get, still struggling to prove that my singletons are the right type. Any guidance? move :: (Played x y b ~ 'False , Turn b ~ p ) =&gt; PieceT -&gt; CoordT -&gt; CoordT -&gt; Board b PieceT -&gt; Maybe (Board ('(x, y, p) ': b) PieceT) move piece row col board = withSomeSing piece $ \spiece -&gt; withSomeSing row $ \srow -&gt; withSomeSing col $ \scol -&gt; case sPlayed srow scol sing of STrue -&gt; Nothing SFalse -&gt; case sTurn sing of SX -&gt; if piece == X then Just $ play spiece (srow, scol) board else Nothing SO -&gt; if piece == O then Just $ play spiece (srow, scol) board else Nothing 
Note that total alloc is way higher than maximum residency, which is "only" 77MB on your machine.
Thank you. Yes, I believe the big issue is that I have not read about monad transformers yet. Also, I didn't understand the `Reader` chapter, and it seems like that chapter is crucial in understanding how values are made available to different parts of the app. 
Hi. I thought I had this down, but I can't seem to unsugar the do notation of `tuppled'` in [this gist](https://gist.github.com/StevenXL/015bc24e874c702ecce0516142df8cac). I understand that each `&lt;-` should translate to a bind (`&gt;&gt;=`). I think I got "stuck" in the list monad (if that makes any sense) because I started my implementation as `tuppled'' s = cap s &gt;&gt;= ...`, before noticing that `(,) a` has an instance of Monad as well, but that left me in a different, though equal, state of confusion. I looked at the implementation of the monad instance for `( , ) a` and given what I saw there I did this: `tuppled'' s = (cap s, "") &gt;&gt;= \_ -&gt; ("" , rev s)`. Is that correct? It doesn't seem to be the right way to desugar this, but what heck do I know. 
&gt; It's not surprising. Parsec consumes about that much. Could you please elaborate a little bit more on this? How come that it's expected? &gt; I don't know what Asg and Var There is a link for the full source in the bottom of the post. Btw, thanks for other points, I'll try to rewrite a thing in `attoparsec`.
r/reflexfrp --------------------------------------------- ^(For mobile users) ^| [^(More info)](https://np.reddit.com/r/botwatch/comments/6xrrvh/clickablelinkbot_info/) ^| ^(Downvote to -1 karma to remove) ^| ^(PM for sub to be ignored)
Thanks to some feedback and IRC discussions, I've tweaked the instructions for getting set up at the start of the tutorial - including being more specific about setting up the binary caches - hopefully that helps folks who want to play with this but we're struggling to get going. 
`trifecta` really isn't designed to parse anything that big. It is billed as supporting "human writable" grammars. It doesn't try to manage residency and builds up a huge rope of input as it goes. That said, your grammar is a bit poorly factored in terms of repeatedly testing the same things. It doesn't seem to matter in the grand scheme of things, though. `lookAhead` is innocent. I went and rewrote it without lookahead by cheating and using some trifecta internals: https://gist.github.com/ekmett/29022e999954f3191cbef083e68c942e The total amount of heap thrashed just went up, which makes sense because its building the same chars and then throwing them away to take slices off the original input. A lazy-bytestring-based slicing combinator might help some, but meh.
Because of how ridiculously simple the grammar you have is, you can probably get away with using Zepto from attoparsec for large chunks of it.
To be fair, I'm not a huge fan of the state of the trifecta API myself. I wrote it to get a job done, and then sort of threw it over the fence. I did factor out all the parser combinators in the API into a nice separate package and then documented the hell of out those, but `trifecta` itself not so much.
Thanks for the gist and thorough explanation! This is exactly my case. Actually, I didn't even compile the code in the first place. I was simply using `runghc` to interpret the code and didn't expect this. Maybe it is worth adding to the documentation :)
&gt; `trifecta` really isn't designed to parse anything that big. It is billed as supporting "human writable" grammars. Oh, I see. Thus probably I'm using a wrong tool for the task. Btw, there is a small typo in the gist. On line 50 it should be `Asg &lt;$&gt;` instead of `Asg &lt;$` :)
Yeah I tried to fix it in place before sending it off. I previously had a redundant call to `spaces` there.
This looks very promising, thank you. My problem involves a fixed grid, so arrays would be as useful as lists. And my understanding is that our cluster from the application perspective is just like a multicore CPU with a very large number of cores. 
I think the main culprit might be that /u/AndrasKovacs doesn't actually print anything besides the length in the original code they gave. The 0.15 seconds extra is probably just to print to the console and is unavoidable even with `Text`. But yes I'm assuming `traverse_ print $ filter isprime [2 .. 10 ^ 6]` would be faster.
Maybe strictness annotations and using ByteString instead of the default string?
 other :: [Char] -&gt; ([Char], [Char]) other = cap &gt;&gt;= \u -&gt; rev &gt;&gt;= \r -&gt; return (u,r) In your comment you tried to desugar `s &lt;- cap` as `cap s` but that's wrong. It is `cap &gt;&gt;= \s -&gt; ...`.
Hac Phi! Hac Phi! Hac Phi! Don't let it die!
I don't see what you are getting at but I would instead use type families anyway: class MonadState m where type State m :: * get :: m s put :: s -&gt; m ()
Hi! I'm largely responsible (/to blame) for Accelerate, so am interested in seeing if this works for you (: If your program involves a lot of looping-over-arrays style processing, then it should fit this niche. Here is a small fluid dynamics application I wrote a while back which might give you some idea what it is like: [lulesh-accelerate](https://github.com/tmcdonell/lulesh-accelerate). I think it is an interesting example because you can compare it to both the specification as well as the actual reference implementations, including one in [Fortran](https://codesign.llnl.gov/lulesh/LULESH_serial.F90) (though I never benchmarked the Fortran version because it is sequential only).
Ah thank you. I've made this mistake before. `&gt;&gt;= :: m a -&gt; (a -&gt; mb) -&gt; mb` `cap :: [Char] -&gt; [Char]`, which can be re-written as `cap :: (-&gt;) [Char] [Char]`. Then `m ~ (-&gt;) [Char]` and `a ~ [Char]`. In short, I forgot that `(-&gt;) a` has an instance of monad. `tuppled'' = cap &gt;&gt;= \capped -&gt; rev &gt;&gt;= \revved -&gt; return (capped, revved)`
For finding the package of a given module if you have it installed? `ghc-pkg find-module &lt;module&gt;` For example: % ghc-pkg find-module Crypto.Saltine /Users/tommd/lib/ghc-8.2.1/package.conf.d (no packages) /Users/tommd/.ghc/x86_64-darwin-8.2.1/package.conf.d saltine-0.0.0.5 But for tying values to modules I use {n}vim plugins a la ghc-mod.
Rage, rage against the dying of the light.
Yes, I know. And it has the advantage of at least being funnier than the average misguided monad analogy.
Sure, but that kind of understanding can come later if/when necessary. You can get a lot done coming at stuff from a more practical angle before you need to get bogged down in [abstract nonsense](https://en.wikipedia.org/wiki/Abstract_nonsense). There are many paths to understanding.
**Abstract nonsense** In mathematics, abstract nonsense, general abstract nonsense, and general nonsense are terms used by mathematicians to describe abstract methods related to category theory and homological algebra. More generally, “abstract nonsense” may refer to a proof that relies on category-theoretic methods, or even to the study of category theory itself. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/haskell/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.27
You can really only do this if you *have* the source code. GHC can use a package that doesn't include the source, if I'm not very much mistaken.
Here are some: [https://haskelliseasy.readthedocs.io/en/latest/#xml](https://haskelliseasy.readthedocs.io/en/latest/#xml)
My understanding from chatting at ICFP is that it will likely still happen but perhaps a bit later in the year than has been typical in the past.
My thinking was that it would be better to collect answers here, rather than deep in a discussion with hundreds of other, unrelated, comments; sorry if that was not an appropriate approach. The question is [here](https://www.reddit.com/r/math/comments/71qd8k/whats_your_favourite_example_of_an_area_of_maths/dndjlvy/).
The most obvious problem here is your use of `[Char]`. The Haskell String type is very space inefficient. Johan Tibbell's talk "High-Performance Haskell" has some really helpful information for reasoning about space usage starting on slide 42: https://www.slideshare.net/tibbe/highperformance-haskell Slide 43 shows that Haskell lists use 5 words per element. On a 64-bit machine, a word is 8 bytes. That means the `String` type uses 40 bytes of memory per character! In short, if you're storing significant amounts of text, use either `Text` or `ByteString` instead of `String`.
But now you don't just have to change `analyseExpr` to `newName`, you also are going to want to change `analyzseExpr_flag` to `newName_flag` but the compiler won't notify you if you don't, and your tooling is also unlikely to do it for you as part of the rename.
When you say that parametric types are overkill, do yo mean that they obscure the relationship between the original and output types? 
Are entity-component systems related to what's called [Data Oriented Design](https://github.com/dbartolini/data-oriented-design) in C++?
Another interesting angle is BuckleScript or Reason ML. Even futher from Haskell, but also somewhat thriving, is ClojureScript. I'd love to see a serious comparison of them all. Or a The Computer Language Benchmarks Game for JS compilers...