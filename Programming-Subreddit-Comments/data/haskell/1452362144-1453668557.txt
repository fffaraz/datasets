IHaskell is a Jupyter kernel, not a plugin, so I think that might be going down the wrong path. This has been a filed feature request for IHaskell in the past, and there's a few links to how to do this [here](https://github.com/gibiansky/IHaskell/issues/462) in the issue. There's currently no progress on it, but I am happy to help anyone who may be interested in tackling this issue.
Thanks, I think I overlooked that function. I'm coming from the Scala world and the `Task` monad which uses Exceptions as the "Left" value (returned, not thrown). But I would rather avoid exceptions and use other types for 400-level responses. 
Quite widely used though
And that is relevant only if you are ok with supporting surveillance state.
thanks. i am on mobile and didn't see a read more button until now. it looked like that was all of the readme.
I'd be interested in a language that was text based but the flow could be rendered in a graphical manner. I assume some kind of metadata would be necessary to not make a mess of it though. It would be especially interesting if it had some sort of effects system and the visual rendering could break out exactly where effects are taking place.
Where other advanced Haskell techniques might be compared to a lightsaber, Template Haskell is a blaster. Kind of ugly but really great to have on hand when you need it. Languages without any capacity for metaprogramming are awful, jmo, and Template Haskell is by far the nicest metaprogramming I've done.
Thanks for writing this!
I guess it doesn't quench your thirst for built-in row polymorphism?
I can't say I ever use it, but there's a special place in my heart for `InstanceSigs`.
Makes me wonder if Vinyl has been used in the context of extensible effects. 
nulls, exceptions, and -1 for primitive numerical types. 
&gt; Would you have said “You are wasting your time on bad product” if it was a package with bindings to Skype or Whatsapp and not Telegram? Definitely yes. I think that a person who is ok with everyone reading their comms is alike a dog who was beaten into submission, perfectly fine with being a second class citizen. As for "the nicest" - have you tried Signal? It has both mobile and desktop clients, multi-device synchronization, encryption on by default, and it's encryption is solid. 
There are more pictures in the presentation https://github.com/wandernauta/viskell/blob/master/viskell-nlfpday.pdf
See comment below (https://github.com/wandernauta/viskell/blob/master/viskell-nlfpday.pdf)
&gt; Have you ever watched "don't ever talk to cops" I haven't, but I read [this link](http://www.kirkpiccione.com/10-reasons-not-talk-police/) instead and I agree with it. &gt; It's an amusing scenario: poor block sitting in Telegram HQ, reading people's chats. Laughable, silly even. I'm sorry if I made an impression that I was trying to mock concerns about security by inventing that scenario (I genuinely wasn't). &gt; This data is being stored now (potentially forever) and will be decrypted when need will arise. This is what I was talking about when I said “there are things in my Telegram log that I'd rather not have there”. I'm not satisfied with the amount of -things that can be used against me- that are currently available on the internet (either publicly or under the “government gets access to Telegram servers” scenario). I'd like to clearly state my points: * I'm not saying that I've got nothing to hide. I do have things to hide – from my family, from you, from my government, from other governments, etc. * For me, switching to Signal is one of the least useful things I can do when it comes to protecting myself from dangerous and potentially malicious agents (governments, etc). Everything in my Telegram log has a huge information trail elsewhere, and *that* is what should be changed first, not what messenger I use. * I don't know the probability that being as careless about privacy as I am would harm me, and exactly how much I'm going to be careful *depends* on that probability (and on the possible harm, of course). You haven't mentioned any probabilities; you appealed to my emotions a couple of times (by saying “dog, beaten into submission”, etc) (sorry if I misinterpreted you), and you presented a single anecdote about a person who was mistreated by police. My current estimate of how careful I should be is “somewhat more than I am right now”, which isn't enough to make me stop using Telegram. If you want to change my opinion (and possibly opinions of people watching this debate), you'd have to show more evidence.
They promised to open-source the language in a [talk given at Mozilla last year](https://air.mozilla.org/flowbox-io-luna/), but there is no public code on [their github](https://github.com/luna-lang).
That's only because of the awkwardness of our syntax at the type level. While type application is a great feature in theory, I'm afraid that from the syntax point of view it is only making things worse. I hope your type sections will be implemented promptly. They can almost always be used in practice. Type application can remain available, protected by a pragma, for the rare cases that require it. That way we can switch to better syntax when it becomes available without much breakage.
Thanks
Yeah. Telegram is pretty worthless
If you ever get stuck with a SomeException, you can downcast using http://hackage.haskell.org/package/base-4.8.1.0/docs/Control-Exception.html#v:fromException
Viskell shares a lot of goals with [lamdu](https://github.com/lamdu/lamdu).
I once saw a talk about something similar by Chide Groenouwe at IFL, the paper was titled "Instant playful access to serious programming for nonprogrammers with a visual functional programming language": http://www.cs.ru.nl/P.Achten/IFL2013/symposium_proceedings_IFL2013/ifl2013_submission_8.pdf
I think that I understand your general idea about state of your own privacy. I think that you are a bit too pessimistic (or maybe I'm too optimistic), but lets leave it at that. So, to my last argument. You may want to consider the fact that other people are influenced by you and by the fact that you are using insecure communication channels. By using secure stuff, you can help them adopt it, thus improving their situation. I.e. they will have at least someone to talk to using secure software, and it will increase chances of secure software being adopted down the line. So, making switch not for yourself, but for your friends, relatives and associates. Anyway, thank you for this discussion. It was interesting. 
I'm sure the authors are aware of John Reekie's PhD work from 1995, on visual Haskell. But just in case, here's the abstract of his PhD thesis: &gt; "The dataflow process network model, although widely-used, lacks a formal description, and I provide a semantics for it. The formal work leads into a new form of actor. Having established the semantics of dataflow processes, the functional language Haskell is layered above this model, providing powerful features --- notably polymorphism, higher-order functions, and algebraic program transformation --- absent in block-diagram systems. A visual equivalent notation for Haskell, Visual Haskell, ensures that this power does not exclude the ``intuitive'' appeal of visual interfaces; with some intelligent layout and suggestive icons, a Visual Haskell program can be made to look very like a block diagram program. Finally, the functional language is used to further extend dataflow process networks, by simulating timed and dynamically-varying networks." His thesis: "Realtime Signal Processing: Dataflow, Visual, and Functional Programming". http://ptolemy.eecs.berkeley.edu/~johnr/papers/thesis.html
Reminds me a lot of the Rapidminer interface, which works fantastically for machine learning. I've had several discussions with Haskell folks on why the Rapidminer style should work even better with Haskell as the underlying language, so it's cool to see something like this project.
Here's an example of visual Haskell for structured expressions from his thesis: [http://imgur.com/O6QX88R](http://imgur.com/O6QX88R) .
In my experience the problem non-programmers face with programming is not so much syntax but the lack of a consistent mental model of how the program is going to behave. The formal aspect is the problem, not the language aspect in formal language.
one advantage of "encryption everywhere" is increasing plausible deniability. e.g. there won't be a flurry of encryption exclusively before some protest. it's like padding ciphertext, which destroys some information, the plaintext length. 
He did say outside FP... Scala technically falls under that umbrella. 
I found this video helpful - [Production Haskell](https://www.youtube.com/watch?v=T2wi0ZUOHfM)
I am concerned about privacy not because I need a whole lot of it, but because I can imagine there are people that *do* need it. Just off the top of my head: * A parent with children who has just left a violent and abusive relationship and does not want their ex-partner to find them (eg don't want their children's friends tagging their photos on Facebook). * A teenager questioning their sexual identity wanting to talk to other in the same situation. * A journalist investigating police, governemnt or corporate corruption or wrong doing. All of these are potentially life threatening situations for the person seeking privacy. If everyone used apps that provided a good meaure of privacy and security then the people that *need* it can probably get easy access and they do not stand out from the crowd for using it. 
No, but the theory behing algebraic effects and handlers is *very* nice, and the type system worked out by Matija Pretnar is based on that. I can't help it if Haskellites take stuff and Haskellify it. In any case, I believe that the effect information *should* be available to the programmer, but it is far from obvious to me that it should be *prescriptive*, as it is in Haskell. With *descriptive* effect information (the programmer can use all effects everywhere and then the compiler tells him which ones got used) life might be nicer. As always, we'll face design questions such as "do I use `Maybe` or do I throw exceptions"? There's no way around design decisions.
[Joke alert] Yes, you can write industry quality software in Haskell. Do all your computations in the IO monad, keep intermediate results in MVars. Use only Int and String types. Use exceptions to handle errors. Write yourself custom constructs to emulate `for` and `while` loops, preferably using Template Haskell. Keep documentation and code separate, and slightly out of sync. For better result, put documentation on a corporate server with "need to know" access policy, requiring several levels of approval. Write only manual tests, do not use QuickCheck. Keep the tests separate from the code, and slightly out of sync. That will make the goal of writing industry quality software quite achievable.
I sense you have had bad times with writing Haskell professionally. I will take your advice as things *not* to do as I believe that is what you intended.
This won't be the biggest problem you have. Two of the best skills to develop is the ability to figure out what the biggest problem is, and the discipline to work on that problem first.
Yes. That is the difference between the academia and the reality. In academia the stock data is a pure list. In the real problem (i.e the evil empire of reality) it comes from a network connection. That is why composability in the presence of impure effects is so badly needed, but rarely considered. And yet here is where Haskell can give critical advantages for real applications. Much more than effect encapsulation and type safety.
I'm not sure that Telegram security is relevant topic here. I would rather see feedback about the code of Telegram Bot API bindings and suggestions how to make it better.
You can even start to [contributing to haskell ecosystem](http://www.haskellforall.com/2015/12/how-to-contribute-to-haskell-ecosystem.html)
&gt; I sense you have had bad times with writing Haskell professionally. I did not. But I do have opinion on the quality of the "industry quality" software :)
`runWriterT` wraps its results in the inner monad for your `WriterT` transformer. This would be the semantics you wanted if you wanted many traces, one for each resulting element of the list, and indeed see that the type returned is `[([[a]], [String])]`. What you want is something akin to `ListT`, with `Writer` inside. `ListT` cannot be implemented safely (it does not guarantee that the generated monad follows the monad laws for all inner monads) but `LogicT`, which is basically the same idea, might be do what you want, here it is: http://hackage.haskell.org/package/logict You could also try the function `sequence :: [m a] -&gt; m [a]` from `Control.Monad` or `unzip` from `Data.List` combined with `mconcat` from `Data.Monoid` to make something like this: sequenceWriters :: [([m], [n])] -&gt; ([m], [n]) sequenceWriters xs = let (returns,tells) = unzip xs in (mconcat returns, mconcat tells)
we've got pretty interesting discussion here about security of Telegram itself and messengers in general, but I think it shifted focus from original topic. One of the ideas to post it on reddit in haskell community was to show that using [servant](https://haskell-servant.github.io/) library is very easy to write bindings to REST interface for your preferred messaging or any other app. And second to inform developers that they can write Telegram Bots using such nice language as Haskell.
I hadn't noticed it. You're doing a good job.
I generally agree that text is better for professional programmers than VPL (visual programming language). However, when it comes to people who are experts in some other domain and just want to design dataflow graphs, it seems that VPL is considered the way to go. For example, biological software often uses VPLs (like neurofeedback practitioners use it to design neurofeedback protocols). Even rocket scientists use VPLs (at SpaceX they use LabView). I'm not sure what to think about this. I don't know whether this is about people learning bad habits due to an easier barrier of entry (VPLs are easier to start with) or whether VPLs are actually more productive in certain domains. Intuitively I would say that interactive text is more productive than interactive graphs, just like how people can communicate with each other better by using a natural language rather than pointing fingers and miming. But if they don't know a language then it's not surprising that people want to start pointing fingers and mime. It's hardly imaginable that end users will want to learn Haskell to do something really basic like their water heater to not turn off at night to safe power if their phone is not within the radius of their home by night (e.g., if they are parting they want to come home and have shower working). But if it's as easy to use as Excel or VPL, then they can connect two values or components together and voilà. It's provides same DRYness as the command line does while not looking as scary to the end user. Now, some water heater software does not need to implement every possible feature users want. It just needs to do one thing and do it well. 
You may want to autoreply to deleted submissions from new users with a comment that says something like &gt; Hey, your post has been automatically caught by our spam filter. [Please send us a message](https://www.reddit.com/message/compose?to=%2Fr%2Fhaskell) if this was incorrectly done. I think that is much more friendly than silently eating their post. I can guarantee that the users that registers in a week and wants to ask a question will not read this post. :) Of course, put this "new user" filter as far down as you can in the automod config, so you accidentally autoreply to legit spam attempts as rarely as possible. Most automated spam that signs up and then sends a message won't bother reading the comments to thoroughly.
What is "industry quality software" supposed to mean? In my experience "enterprise software" is usually of very poor quality. 
While it's great to write an API in servant and ~~eat it too~~ get a client side handed to you, I don't think it is a great way to publish those binding as a hackage library. The resulting modules look gross to me and haddocks aren't friendly either. Maybe servant extras (like the ability to generate mocks, JS and whatnot) do offset that, but I'm not sold on it yet.
I wrote a guide for starting Haskell projects. I called it [Haskeleton](http://taylor.fausak.me/2014/03/04/haskeleton-a-haskell-project-skeleton/). I stand by the explanations, but in terms of tooling you should use Stack (like [sgraf812 says](https://www.reddit.com/r/haskell/comments/40aa4n/how_to_make_industry_quality_software_with_haskell/cysr1se)). 
Just about everything except dataflow. Here is the "Goals and focus points" section from Viskell: * Creating readable and compact visualisations for functional language constructs. This is a goal of Lamdu. They experimented with graphical approaches like Viskell, and came to the conclusion that a new rich symbolic approach is better. * Immediate feedback on every program modification, avoiding the slow edit-compile-debug cycle. Major feature of Lamdu. * Experimenting with a multi-touch focused user interface, supporting multiple independently acting hands. Lamdu considered this as well. In the end they chose an interactive keyboard approach. * Type-guided development: program fragments show their types, and type error are locally visualised. Major feature of Lamdu. * Raising the level of abstraction (good support for higher order functions and other common Haskell abstractions). Lamdu provides this. * Addressing the scalability issues common to creating large visual programs. Also a goal of Lamdu.
[removed]
Know very little about category theory here: doesn't the 'endo-' refer to the functor category, and not the category within? Haskell's Functor is really an endofunctor, and Applicative is really an endoapplicative. An "exofunctor" would define exofmap :: (Functor f, Functor f') =&gt; (a -&gt; b) -&gt; f a -&gt; f' b If that's even possible.
You're right on the first part but you are misplacing the categories. an exofunctor would more likely be something like exofmap :: (Category c, Category d, Exofunctor c d f) =&gt; c a b -&gt; d (f a) (f b) and then something like Exofunctor c c f =&gt; Endofunctor c f EndoFunctor Hask f =&gt; Functor f In either case, you are right and the term "MonoApplicative" might be more appropriate.
I would start with EndoFunctors (like, endofunctor means something else (which all Haskell functors already are), but by your definition it is something different (to avoid this naming conflict, I would try to find a different name)). if you have class EndoFunctor f where fmap :: (a -&gt; a) -&gt; (f a -&gt; f a) It appears to be defining some sort of monoid morphism.
Thanks for the clarification!
Yes, you are right, MonoApplicative would be more appropriate. Thanks for the clarification.
Yes, indeed, you are right it is a monoid morphism. EndoFunctors were the inspiration for this class.
My comment was about privacy in general, not Facebook in particular.
Missed opportunity - enterprise grade software. Pretty sure that involves faking the kinds of OOP patterns that give even Java programmers that WTF look. With the range of typeclass extensions we have available, I think we might just achieve new heights in WTF with a bit of effort, though that's admittedly a very challenging goal.
I would ask a simpler question :) How to match a single `/`.
Seconded! Don's talk contains many nuggets of wisdom every Haskeller (beginner or not) should always keep in mind when writing software ;)
Are sure this satisfies any useful laws? In particular `pureM = const M.empty` looks quite suspicious.
But the theory behind monads is also very nice. It's in two-cells respecting various additional equational laws that the trickiness comes in, and it seems to me that trickiness is sort of innate and appears in the monad story and the effect story just about equally.
There is a very nice guide from /u/dons on the Haskell wiki. [How to write a Haskell program](https://wiki.haskell.org/How_to_write_a_Haskell_program) I think it's perfect for the transition stage you're at: (one .hs file using ghc) -&gt; (proper module hierarchy, build tooling and some tests). I read this guide a while ago, and just skimmed it again - it's still perfectly up to date. There is no mention of stack, which is fine, since you will need to understand .cabal files any. You can learn stack later if you like, it seems like a nice addition, after you get the fundamentals.
Good catch. It doesn't right now. It's a WIP. I just put that in as a placeholder for the types to line up. I wasn't really planning to release this lib yet.
Probably double the `\` ... or remove them ...
Thanks for your feedback.
That's wonderful to hear. Are most of them working professionals in FP using what is talked about at the conference or hobbyists/professionals that can't use FP?
In my mind the difference between "industrial" and "academic" is largely in the finishing touches. So you may want to approach the problem the way you always do, and only make it "industrial strength" when (and if) you need to. Some things that you'll probably need to look into are various build related tools (Haskell specific: cabal, stack; and also more traditional: make/shake, autotools), learn about profiling Haskell code (hp2ps and hp2html to visualize profiling results). Depending on the project you are working on, you may have to learn how to use the FFI and tools like c2hs hsc2hs. One pieces of advice for general development in the Haskell eco-system: you are going to run into Haskell libraries which are not quite finished and then it is quite tempting to "start over and do it right". In practice, it might be easier to just fix/extend the existing library, and go back to your actual product. Good luck!
I wouldn't yet. The first release candidate hasn't been released and there are quite a few serious bugs in the typechecker which cause common packages to fail to compile. 
Problem seems to be caused by empty string. Looks like a [bug](https://github.com/myfreeweb/pcre-heavy/issues/4).
Exactly, I'm running up against the fact that Map does not have an applicative instance. Although the nested part is important, nested map operates in a similar matter to a rose tree, essentially (just key based access, instead of index based) I'm looking to apply a nested map of functions to a nested map of values. The reason why it's a good idea to make it `(a -&gt; a)` instead of `(a -&gt; b)`, like you mentioned, having it `(a -&gt; b)` would require some sort of conversion function for the elements not touched. This is why the `MonoApplicative Map` instance uses `funcApFull` instead of `funcAp`, since it unions the `(a -&gt; a)` nested map with the `M.map (const id)` of the `a` nested map, to give `funcApFull` that projects all the items not touched by the `(a -&gt; a)` nested map alongside the items touched. ZipLists were something I was going to take a look at, thanks!
My understanding is that mono-traversable is for "containers" where you can't change the type. Since you're stuck with for example f a, where will you get the f (a -&gt; a) from?
Two separate containers. One of them is a container of these functions, which is applied to a container of values.
nope no match (I tried with `[0..7]` backslashes) I can only match negative `[^/]`
`(""::String)` is just fine. 
mono-traversable makes sense for containers with specific canonical types for items, like Text or ByteString. in this context, mono-traversable *does* have something like this for these: it's called `MonoZip`: http://hackage.haskell.org/package/mono-traversable-0.10.0.1/docs/Data-Containers.html#t:MonoZip and `oZipWith` makes more sense with mono-traversable. notice that the things contained in each container are all the same type. 
Some people seem to think extensible effects are more complex to use than transformers stacks. As someone that have used extensible effects in both Idris and Purescript, it is a hell of a lot easier and more intuitive. The types are simpler, it's a lot easier to add an effect than add a monad layer and it is more performant. Extensible effects are just that, extensible, with little overhead unlike monad transformers, which either introduce performance overhead, or developing overhead (manual unrolling of your stack).
Hm, no mention of [CCC](https://github.com/conal/lambda-ccc) in the bibliography, even though the phrase "From Haskell to Hardware" is used in both projects. :) [edit] Oh, this paper is from 2009. :) Maybe I need to look in the *other* bibliography....
Sure, but do you have any example instances of your MonoApplicative class?
You're only matching for one character after the first `*`. `\/\*[^\*]*\*\/` should work better.
By the way, [`union`](http://hackage.haskell.org/package/containers-0.5.7.0/docs/Data-Map-Lazy.html#v:union) is left-biased, so your `(M.union (M.map (const id) a) f)` will replace all the functions in `f` which could apply to a corresponding value in `a` with `id`, defeating the point of applying the functions to the values. You probably want `(M.union f (M.map (const id) a))` instead.
Every `Applicative` instances is also an instance of `MonoApplicative`.
I think that LTS was supposed to be stable with only minor upgrades of existing packages allowed. New packages were always added to nightly. However, now LTS will be allowed to gradually grow as well, which is nice :-) These are still early days of LTS, figuring out what's best. But it's fantastic that there will be always a new LTS for each compiler version (even minor like 7.10.2 and 7.10.3) and even the old LTSs will be getting new releases as well. 
yes, which is why I build against master.... In stack, you can add aeson to packages with a particular commit like this: packages: - '.' - location: git: https://github.com/bos/aeson.git commit: 4de5a203eeeea593457bc92bc40062f3ea830426 
Do you have any evidence that e.g. State or Reader operations like those in transformers are less 'performant'? Somebody else above was saying this. State and Reader are just newtypes for really basic Haskell types. I was benchmarking a trivial state update program the other day with using `freer` (which is distinctly superior to the competition within Haskell.) It was basically `replicateM_ zillion $ modify succ` I got 2.999 μs freer 96.35 ns tranformers/mtl which would of course be far greater proportionally if you as it were subtract the math. I think it is a common experience that ghc crushes StateT calculations in particular down to almost nothing. Wrapping every state step in the framing of some free monad implementation will never be able to compete. If, however, your 'effect' is one that you would intuitively implement with something like the structure of a free monad, as with, e.g. the `yield` statement, then sure. There is in any case no competition at all between transformers and a free monad on an extensible sum of functors. There's just no competition at all. Here's yet-another-within-Haskell-extensible-effects-implementation that is precisely as a monad transformer https://github.com/michaelt/extensible-streaming Because of functions like [`extrude`](https://github.com/michaelt/extensible-streaming/blob/master/Streaming/Extensible.hs#L214) the monad-transformer structure makes completely different calculations possible. If for example you have an independent library pertaining to something with the structure of the free monad on f, then you can apply its combinators, keeping the rest of the mountain of diverse effects in the underlying monad it transforms, for handling otherwise, using functions that are completely general and collapse any transformed thing into its underlying monad. For example, if the effect is a yield you can cut and slice the whole stream of effects as if it were a list -- and so on. 
&gt; Of course, in practice, you don't really want a "VPL"; you want visual editing to be just one of many "views" on a general-purpose language such as Haskell. In practice, a 'visual editing' session could just generate a "diff" on the text-based project, and present it to the user for final acceptance or revision. Yeah, I completely agree. I also envision those hybrid modes playing nicely with FRP. You can expose raw signals to end users to do whatever they want to them, because often you don't really care whether a signal comes from some GUI element or from some other place. E.g., a signal which states when the water heater is going to be turned off can come either from some GUI element or it can be merged from a completely different place and this will not really effect the architecture that much. Just like some websites expose a few of their "guts" for users to consume (like REST APIs), FRP systems can expose and consume raw signals from end users, which matches quite nicely into visual dataflow programming.
Been there, done that, went back to using cabal - YMMV ;-) The Stack docs are quite good though...
Hey, `WriterT [String] []` isn't a monoid, but it is an instance of `Alternative`. Just replace `mappend` with `&lt;|&gt;` from `Control.Applicative`. I just tried that change and it does type check: combinations :: Show a =&gt; [a] -&gt; WriterT [String] [] [a] combinations [] = return [] combinations (a:as) = do subcomb &lt;- combinations as tell [show subcomb] ((return subcomb) &lt;|&gt; (return (a:subcomb))) This still isn't what you want, I think, here is how you can write it to get a trace of a sort: λ&gt; unzip $ runWriterT (combinations [1,2,3]) ([[],[1],[2],[1,2],[3],[1,3],[2,3],[1,2,3]],[["[]","[]","[]"],["[]","[]","[]"],["[]","[]","[2]"],["[]","[]","[2]"],["[]","[3]","[3]"],["[]","[3]","[3]"],["[]","[3]","[2,3]"],["[]","[3]","[2,3]"]]) 
More info to be found on: http://www.clash-lang.org/ - The limitations of clash: http://hackage.haskell.org/package/clash-prelude-0.10.4/docs/CLaSH-Tutorial.html#g:19 - A very short comparison between Lava and CLaSH: http://hackage.haskell.org/package/clash-prelude-0.10.4/docs/CLaSH-Tutorial.html#g:20 
Tnx!
My favorite extensions tend to be those that make obvious things work the way people would have expected all along. For example: * `EmptyDataDecls` * `FlexibleContexts` * `FlexibleInstances` * `KindSignatures` * `LiberalTypeSynonyms` * `RankNTypes` * `ScopedTypeVariables` * `TupleSections` That said, the most convenient in practice are undeniably `OverloadedStrings` and `BangPatterns`. Least favorite: `LambdaCase`, which tackled a small aesthetic problem, and added a very big and much uglier wart to the language syntax to do it.
Yes, I think you need it to get a `KnownNat`out of a `SomeNat`, [for example](http://stackoverflow.com/a/30762622/10311).
I think the prelude would come in handy.
Great blog post! I'm looking forward to reading your future articles.
&gt; list/sequence As many as can fit in your heap size / 2 &gt; vector The biggest contiguous block of memory that can fit in the GC heap, which is about your heap size / 2. Not sure how much memory each list cons cell takes or each sequence cons takes. Vectors should only have a couple of words overhead. 
Hackage lists a github project. https://hackage.haskell.org/package/multiset
List has either 64 or 128 bits of overhead per item depending on whether you are running 32 or 64 bits. Sequence should have approximately 150% more overhead if my math is right (it may not be).
Sequence is undefined at lengths above maxbound :: Int, if you go above those numbers sequence behavior becomes undefined. 
What's does IHaskell do? I can't seem to figure it out from the documentation. 
Also, thank you! I think I'll delete this now.
My best suggestion would be to surround the MVar accesses with trace messages.
Short version: * `String` is the built-in string type. It has very bad performance for many things, and it is based around per-character manipulation which is not always valid in all languages. * `Text` is a good type for storing and manipulating text. It is fast, efficient, and in most cases correct. * Normally when you type `"Hello"` in Haskell that gets converted to a `String`. The `OverloadedStrings` extension lets it get converted to any other string type – which specific one is decided based on how you use/store it. This is similar to how the number `12` can get converted to `Integer` or `Float` depending on how it's used. * `ByteString` is not a string at all; it is an ill-named array of bits. * A lot of people like to do parsing with parser combinators, such as Parsec and its variants (Megaparsec is a newer version of Parsec, Attoparsec is a variant on the same concept but more focused on performance instead of user-friendliness) * There are several options for formatting, but the important rule is that you do *not* use `show` for formatting. The thing you get out of `show` is sorta kinda supposed to be valid Haskell code.
It provides Haskell integration for the Jupyter (formerly known as IPython) interpreter/shell. It is capable of showing results as graphics, it lets you save your interpreter sessions as HTML files with graphics embedded and so on. Great for writing tutorials and exploratory programming.
Great work! Thanks a ton for posting this! Side note – if you enjoyed this, you may also like the [IHaskell demo notebook](https://github.com/gibiansky/IHaskell/blob/master/notebooks/IHaskell.ipynb), that covers some similar topics but in a different way :)
In addition, if you'd like to try out IHaskell, head to [try.jupyter.org](https://try.jupyter.org/), select 'New', and click 'Haskell', or click 'Welcome to Haskell.ipynb' to open a demo notebook. try.jupyter.org does not have all the libraries installed, so you will not be able to reproduce the work of the OP, but the Jupyter experience is still available. In addition, you can see IHaskell widgets by going to featured/ihaskell-widgets there and then clicking on one of the demo notebooks. Thanks to /u/sumitsahrawat for creating these and working on this feature for GSoC '15!
ByteString is an array of octets, not bits. Or, if you want to use the same terminology as in the bytestring package documentation: "A space-efficient representation of a 'Word8' vector, supporting many efficient operations."
I **do** see the benefit of being able to pin down dependencies to Git commit ids! I just consider it bad engineering to do this at the wrong layer, especially if the right layer already provides that facility. I'm highly dubious of software which aspires to be a so-called [**Eierlegende Wollmilchsau**](https://en.wiktionary.org/wiki/eierlegende_Wollmilchsau) rather doing one thing, and doing it well... luckily there's still alternatives. Sadly, I don't always have the choice to avoid using bloated software... but that's a different story.
I didn't mean to imply it was impossible, rather I meant to imply that "industry quality" software can do a pretty awful job of doing so, at least in my anecdotal experience.
Could you use a "proxy" thread handling all disk interactions?
I meant that it was really loud compared to the other videos. I have no qualms against the speaker :)
Indeed, but if the student's input cannot be reduced to such a model solution, it just runs a bunch of QuickCheck tests on the student's input and see if it can find a counterexample.
Either offload all disk I/O to a separate thread, and have the other threads communicate with that (e.g. using `Chan`s), or use an `MVar ()` to implement a locking mechanism. The downside of the latter is that you need to be careful not to produce deadlocks, at least when you have multiple files to protect this way.
It works fine; but I can not match `/` {-# LANGUAGE QuasiQuotes #-} module Main where import Text.Regex.PCRE.Heavy (gsub, re, Regex) ignore_comments :: [Regex] -&gt; [String] ignore_comments rs = map (\r -&gt; gsub r ("":: String) ("/*test commentary*/ abc test")) rs main :: IO () main = do mapM_ putStrLn $ ignore_comments [ [re|/|], [re|\/|], [re|\\/|], [re|\\\/|], [re|\\\\/|], [re|\\\\\/|], [re|\\\\\\/|], [re|\\\\\\\/|] ] https://gist.github.com/tolysz/5607133409b37d89c9c5 
Have you tried [Interactive Haskell Mode](https://github.com/haskell/haskell-mode/wiki/Haskell-Interactive-Mode-Setup) (not to be confused with regular, non-interactive haskell-mode)? It's an efficient way to write code, type check it, and try it in very small cycles.
You can see the current tickets [here](https://ghc.haskell.org/trac/ghc/query?status=!closed&amp;priority=high&amp;priority=highest&amp;milestone=8.0.1&amp;order=priority)
Nope. You could easily make a sequence that is much larger, without even using much memory, if the behavior was guaranteed to be reasonable. GHCi&gt; (mapM_ (print . Seq.length) . take 64 . (iterate . join) (Seq.&gt;&lt;) . Seq.singleton) () 1 2 4 8 ... 1152921504606846976 2305843009213693952 4611686018427387904 -9223372036854775808 GHCi&gt;
To this point, I wonder if there could be a way to gift the e-copy of the book to someone else?
100% agree - and I've bought the book Having said this - IMO it could be added but should include some hint 
I stand corrected. That's a nice use of sharing!
People that are in school, a developing country, unemployed, or have adverse VAT or some other extenuating circumstance should contact us.
I was thinking more gifting a "used" copy. Some people may like to hang on to it as a reference, but I personally would like it if I could let someone else use it.
There's certainly place for a general link "Books and other Learning materials" pointing to a Wiki page enumerating, categorizing, and surveying all known Haskell literature...
I wish there were more options in this space. But it seems like the best that's available now is to find a comfortable GPU/openGL wrapper and start from scratch. Gpipe seems like the nicest library at the moment A flocking demo written in gpipe: https://www.youtube.com/watch?v=jn4hNzcmsZU luminance by phaazon sounds promising but that's still in development stages: https://github.com/phaazon/luminance finally, people like ekmett have done some cool stuff with just opengl bindings: https://github.com/ekmett/quine Like I said, wish there was more to build on, but I guess one has to start somewhere. I wonder if it's possible to wrap unreal engine with a C FFI, or at least a useful chunk of it? Seems like a pretty big task though. One other issue is that although haskell is fairly performant, I'm not sure if the current state of the garbage collector and other things are enough for the uber strict low latency requirements that VR requires so as not to make people motion sick.
We'd rather people not do that. This book has been a lot of work. If it's because they can't afford anything or can't afford much, they should contact us. That said, we're trying to get a print version happening so the usual regifting rights would apply there.
I would love to have a "dead tree copy" (still enjoy having real books - it's just the better experience for me)
Fair enough. It'll be a bit of an ordeal given the length of the book, but we're hoping we can get in touch with a good publisher.
you worked your ass off writing this. don't feel bad charging money for your efforts. it'll be pirated soon enough anyway.
I'd definitely like for it to include some of many efficient operations. Like counting end-of-line characters, or any character, in almost the same efficiency as wc.
The most important problems I've had with checked exceptions are: * The standard library (and some third-party libraries) declare such exceptions where it's not appropriate, e.g. closing a stream. In other cases, derived classes inherit their parent's checked exceptions even when it is impossible for them to throw. * There is no good way to abstract over an arbitrary number of checked exceptions. For instance, with a higher order function (say, `map`) there is no way to say "map throws precisely the exceptions that the callback function throws." At best you can declare a fixed number of type parameters, but this breaks Java's weak type inference and obscures the code in the common case that not all the parameters are used. * Due to the aforementioned weak type inference, annotating each function in the call stack with checked exceptions is tedious, even with IDE support. I think checked exceptions are a good feature, but one that Java is not powerful enough to properly support.
http://stackoverflow.com/questions/25280852/space-leak-in-pipes-with-rwst
This depends on what your use case is... Do you want to help test it or take some new feature for a spin and you don't mind compiling GHC yourself? Then now is a good time. Do you want to make packages you maintain compatible with it? I'd wait for a release candidate. This might be in 1-2 months. Do you want to use it in production? We usually wait for at at least one patch release after the initial release. This might be 6 months from now.
I respectfully disagree. A book's price should reflect the value of its contents, not the media used or its publisher pedigree. True, there are publishers out there that do a great job at filtering, only publishing books that are good enough. However, the authors of HPfFP are being very transparent about the whole process, why the books is being written and what they're planning to achieve. This is more important than publisher pedigree, IMO. IIRC (can't recall if I read this in a blog post or slack channel - please correct me if I'm wrong) the authors tried to work a deal with a publisher, only to be told that it should be split on three volumes at a $40-ish price tag each. It simply does not align with the book's objective. TL;DR if you're serious about learning haskell this book is a great deal. 
I don't like reading e-books, is there a physical copy planned?
&gt; you don't mind compiling GHC yourself Not necessary if you're on Ubuntu. There's a great PPA from Herbert Valerio Riedel that contains various GHC versions including GHC HEAD.
There are very good reasons to integrate some trading algorithms into the network stack or even to just build a custom network driver that implements the trading strategy. That reasons is of course latency. A custom network driver will just understand how to read/send the specific packets an exchange implements. As all this will be running inside the kernel this greatly reduces the variance of handling an update from the exchange. For some strategies decoupling from the network stack is not even possible as the added latency will destroy the strategies profitability.
Unless someone can go back in time, I don't think that there can be anything on the horizon for 2015 publication.
heh. and all before the first cup of coffee.
&gt;Overall, the chapters on the extreme basics could use more work if this is truly to be a book from first principles. Julie's had her 10 year old son try the book out, only the first two chapters so far, but the only trouble he had was due to being young and not knowing what things like exponentiation are. She'll be incorporating more of the early material into his homeschooling soon, so we'll have a more complete picture of what needs love soon enough :) Thank you very much for your kind comments. It makes the effort worth it to see people enjoying the book and, more importantly, enjoying _learning_!
Perhaps, OP meant 2016 and the above is a typo. 
Authors, could buy an advertisement about their book one which would display on every page. Otherwise we could add all paid Haskell training which IMO will teach you more than any book.
I can't be the only one in this boat: The book looks amazing, the praise sounds like I should buy this, I'm exactly in the target demographic (tried for years to learn haskell and failed several times to grok it), but there's no way in hell I can put forth $59 for a book, no matter how good. I just can't afford it, and that's all there is to it. That's literally as much as my food budget for 2 weeks.
*2016
GHC 8 is not released yet, not even a release candidate. The GHC 8 branch should be considered just as unstable as anything that's in non-release status. Eventually, the ghc-8 branch will end and become "the release" at the tip, but that's still a couple of weeks ahead of us. That said, you can of course compile it and test the new features already. You can use it on your CI to check whether your packages build against it so that you're compatible on release day. You can write an article about the new features for others to enjoy on release.
And what? Ask for a free book/huge discount? Nah. Hard work ought to be paid. You gave it the price you think is fair. Thanks for offering, though. Much appreciated :)
[removed]
Ha, I can _so_ relate. Had to wait until I started my job to have the money (finance programming, but unfortunately no Haskell yet. Have yet to convince the folks to start using it).
All true but nevertheless it's unclear to me that there's supposed to be a gatekeeper deciding whether a book should be recommended just because it's not free.
[Email us please](http://haskellbook.com/support.html).
uh, no. Authors and readers alike are punished heavily by the oppressive power structures at play and neither should apologize to the other.
[Email us](http://haskellbook.com/support.html).
&gt;Haskell Programming from first principles [Haskell Book](http://haskellbook.com)'s technically going to be published this year in 2016 rather than 2015, if you mark it from completion date rather than early access &gt;:P
Is there any reason not to use STM? It's safer and simpler, and the difference in performance is usually minimal. I think nowadays most people consider STM the default concurrency approach unless there is some special reason that you need to implement low-level concurrency manually.
There is a huge number of non free books :) However they are usually printed. https://wiki.haskell.org/Books Maybe there should be PAID sub-reddit with some special haskell? I simply do not see why HBFFP should benefit from free advertisement; even posting updates feels like a spam. It is exactly like posting links to paid websites.
`s/Chan/TChan/`, `s/MVar/TVar/`, sure, why not.
&gt; the only trouble he had was due to being young and not knowing what things like exponentiation are. I noticed something on similar lines when I tried showing tryhaskell to a friend who has no technical inclinations whatsoever. She enjoyed the "game" but found the math examples boring and not really applicable to anything she'd relate to. It's challenging to think of examples that aren't "mathy", just because arithmetic comes readily as an example to us existing programmers.
Regular expression for `/` is either `[re|/|]` or `[re|\/|]` (unnecessary `\` escape in second case). So regular expression is correct, but `gsub` contains a bug which has to be corrected. As a workaround you can replace `""` in second argument of `gsub` with `"\NUL"` (and then remove all null characters from result). -- ugly, but works putStrLn $ "&gt;" ++ (filter ('\NUL' /=) . gsub [re|/|] "\NUL" $ "//////") ++ "&lt;"
btw. It will still fail on input like this `/*..*//*..*/` (albeit your expression is correct)
Yeah, okay, thought so. Are you gonna suggest the version of Writer that is based on state?
I think we tell them that if they want Writer, they can just use State.
I'm really excited to see this grow. I think haskell is an ideal language for self-learners with limited experience in programming, but sadly it doesn't get nearly as much exposure to that group as it ought. Your book seems like it will really bridge that gap. 
I thought I'd check if other PL subreddits recommend non-free books at their sidebar, here are those that were at the top of my head: [1](https://www.reddit.com/r/clojure), [2](https://www.reddit.com/r/scala), [3](https://www.reddit.com/r/erlang), [4](https://www.reddit.com/r/elixir), [5](https://www.reddit.com/r/idris). All link to non free books in their sidebar. Why? probably because they want their users to be able to learn from the best resources, free or not. If your goal is for people to learn in the path of least resistance, you should link the best resources. The ones who will benefit the most out of this is the community. If we are not linking the best resources just because someone who worked hard will earn money from their work, and without considering the quality of the product, then I feel we are doing a disservice to newcomers and the community as a whole.
Me being a complete beginner affects the book in ways that are probably not obvious to someone who doesn't have access to the first drafts of each chapter. I am going to write a blog post about the process soon, but the tl;dr is most of the book gets written in a Socratic-ish process of me asking him questions. There are entire sections of the book that probably wouldn't exist if I hadn't asked an obnoxious number of questions. The idea is that a self-learner would have many of those same questions and maybe not have an expert there in person to answer them, so we try to cover them in the book. Of course, not everyone has the exact same questions or understands things in exactly the same way, but the book is so long because we try to cover all the questions that arise, from tiny details that I got hung up on to me asking one day about the relationship of recursion and function composition. Chris just went back and added (for this release) a discussion of the usage "bind over" and "bind out" to the Monad chapter because it came up in questions I had about the monad transformers chapter. Your point about Typeclasses coming too early is one that we're still considering. You definitely will touch on that topic again, (fairly soon if you're in Folds now) and it's important to have a solid understanding of typeclasses before you get to the second half of the book. Typeclasses has so far stayed where it is because re-ordering involves a significant amount of rewriting because when one chapter refers to something we've already talked about, whole sections may need rewriting. For example, since we added more lambda calculus stuff, we have redundancies in the Functions (anonymous lambda syntax) chapter that I'm hoping to fix before the next release. So each thing we do sets off a cascade of other things we need to do. This isn't meant as a complaint at all -- we absolutely want the book to be the best it can be. The point is just that every question, every comment we get, every decision ends up changing the book in ways that most readers won't notice because we try to make it not noticeable. 
Right now the big thing I would want from this would be a way to define my own data types. Its basically the first thing I do when I do any programming in Haskell.
[clckwrks](http://www.clckwrks.com/) aims to provide this functionality. The low-level support is provided via [web-plugins](https://github.com/clckwrks/web-plugins). At present only the 'static' version is currently supported. But the `web-routes-dynamic` module has enough code to provide proof-of-concept for dynamic loading in a running server. Basically, just enough code to show that once you have solved the problem of building the modules -- that they can be loaded into the running server. At the very low-level loading the object files can be done by the [plugins](http://hackage.haskell.org/package/plugins) library. Though that library is pretty old and not really supported. A better approach IMO is to rewrite plugins to use the ghc-api (which came after plugins was written). That is what [plugins-ng](https://github.com/Happstack/plugins-ng) intends to do, but it is not production ready yet. It is true that you need some way to build the Haskell code before it can be loaded. That could be done by having GHC installed on the server -- or the modules could be prebuilt elsewhere and downloaded. I think the best way to manage that would be by using Nix to manage the builds. It ensures stability, non-interference with the normal package management system (RPM, deb, etc), the ability to download binaries, and more. At the moment, I am more focused on the client-side aspects. I'd like to switch clckwrks over to use a more modern approach using [servant](https://haskell-servant.github.io/) and client-side UI via GHCJS. But I do plan to get back to the dynamic loading and nix integration at some point. Long term goal is to have a plugin store with both free and paid plugins and themes. 
So if I understand correctly this would work without access to the source code, right? (and thus could be used when both then host system and the plugin are proprietary)
I also use Windows 10. I just use Notepad++, which has most of the convenience features you list (I'm not sure what you mean by selecting code) and stack. It's not quite as straightforward as a single hotkey or button to run programs, but I keep a ghci primed CMD prompt on `Win-1` and Notepad++ on `Win-2`, so to test code is just `Win-1` then `:r` to reload. For finding the location of errors, you'll have to run with profiling and `-xc`, I don't know if Leskah does this automatically or not.
Your question is confused (angular is a js framework, while yesod is a web application framework; neither have "support for image manipulation").
Sorry. Meant rendering. Corrected. 
I'm late to this! A few thoughts: - Strong types help us move faster. Eliminating bugs early is great, and more expressive code is great, but the biggest win is refactor-ability. GHC holds your hand through the refactoring process, making edge cases hard to miss. This works better with more expressive types! - The available "industrial strength" libraries are impressive. Haskell lends itself to lightweight but powerful abstractions—we get a lot done with a few great libraries. - There are still some gaps in the library ecosystem. I'd love to see something as good as `pandas` for numerical computing and something like ActiveRecord for DB&lt;-&gt;type mapping. - Haskell’s initial learning curve is steep (syntax, basic types, tooling), but its secondary learning curve is very productive (transformers, parsers, performance, FFI, etc). Realizing this and giving people space to learn goes a long way. - `stack` (and Stackage/LTS Haskell). This is a huge improvement over `cabal-install` for us. It just works. - Community. The Haskell community (both online and in the [Bay Area](http://www.meetup.com/Bay-Area-Haskell-Users-Group/)) is outspoken and super helpful. I also spoke about this at BayHac ‘15. Check out the video on our blog: [wagonhq.com/blog/bayhac](https://www.wagonhq.com/blog/bayhac)
In that case I completely agree. I think the term apology is likely to have the wrong connotation and may make your audience defensive and less receptive to what you have to say 
`reflex` rather than `reflect`?
yes, edited, thanks :)
Wow that is impressive. Just poking around it seems that the project could use some more love. It is something that I think is desperately needed in order to compete with any framework in an interpreted language. Guess I'll have to dive in and try and understand it so that I can help out :) (still a haskell newb)
I think what my meant by it finding errors is that it would compile each line of code as it was required, and a such it could point you to a specific line and command/function which was causing the program to stop/fail
&gt; Considering OP's question, I don't think his understanding of haskell is enough that telling him about unsafePerformIO is going to give him perspective. On the contrary, at this point I think it will confuse him. Obviously I disagree. &gt; Especially, &gt; &gt;&gt; this is almost certainly not what you want &gt; &gt; If I was a total beginner I would be left wondering if there's a slight chance that it is indeed what I want. If that was all I had said, I agree. I don't think that's likely given the context of the rest of my comment.
I agree with ephiron. Just because there is a valid definition of "apologize" that means what you want it to mean doesn't mean it actually works the way you want it to work. You can talk about "apologetics" in the context of philosophy or religious studies, but anywhere else, the connotation is bad and won't get the response you want. [edit] Here's a stronger argument. Basically, the etymological relation between "apology" and "apologize" is not relevant. To apologize is to admit wrongdoing in modern English. There *is* a [wiktionary definition](https://en.wiktionary.org/wiki/apologize) that connects "apologize" to "apologetics", but it is listed as *dated*.
Can you let me know specifically the multithread IO system built in function which is the alternative for this optimization?
I'm in the position where I don't want to have to ask for a free copy but I don't want to pirate it either... :/
The trouble is (in terms of the tact and clarity of the sentiment), while I have every desire to stay *completely* respectful and understanding, I *do* intend the sort of connotation "apology" has in this case (although it can certainly be overblown beyond the minor way I intend). Proprietary terms *are* an *ill*. Putting proprietary terms on things *is* a bad thing in itself, but it can be justified by the positive effect it has on funding and thus supporting the work (thought not all will agree with me on that). So, when I say "apologize" as in "justify" I *mean* it to have a connotation of "because we should always be admitting that proprietary terms are themselves *bad*". I just do *not* mean "you're a bad person who wronged me and should feel guilty about it". I mean "you're someone doing an unfortunate thing with some justified reasons and should acknowledge it rather than act like the unfortunate thing is just fine".
Yes, but that's the thing: I'm asking for admission of wrongdoing with justification, accepting that this is an unfortunate case bigger than the author where the dysfunctional system leads them to wrongdoing for which they should not be strongly blamed, but it still stinks. I don't mean to have zero connotation of that. Proprietary terms *are* wrongdoing, but they are wrongdoing that can be somewhat excused. My use of "apology" includes the implication that something wrong was done, but it doesn't go all the way to saying that it was unjustified entirely or that the person needs to feel bad. But they should accept the wrongness *just enough* that the feel it requires apology/justification. If there was no wrongness, then no justification would be needed. Asking for this minimal amount of acknowledgement of the unfortunateness is pretty mild thing to ask for.
Why do you need the KnownNat constraint?
A good book which introduces difficult/complicated things to you systematically is important and valuable. I myself would pay for such books.
Think we got everybody that spoke up in this thread. Pretty tired so think I'm taking a break from the book jubilee for now, but there's also [this awesome dude](https://twitter.com/justicefries/status/686698543340363776) now too :)
Nitpick: "Ok, I'll bite" does not mean "I will fight or argue". It means "Okay, I will answer this" or "I will play your game". See: http://idioms.thefreedictionary.com/I%27ll+bite
Bought you're book a little bit ago. Great work you two! Easily worth the money in time saved. Wolftune --- I get what you are saying and thanks for your contributions to the open source wiki. That's a great resource as well. Please bear in mind that this book will only help the community and may in fact allow future haskellers to contribute to the wiki as well. In regards to cost, the authors have seemed more than gracious to offer discounts.
Not having enough good literature to learn haskell is possibly the number one gripe people have hone trying to learn haskell. The author of this book is an active participant in the community and is putting in the humungous effort required to write a good quality text book, which when released will benefit the whole community if it is good enough to direct people to. I find your attitude that no one should be posting anything on the internet/reddit unless it's completely free very distasteful. It is nothing like posting links to paid websites, because most paid websites give you very little benefit for the money, whereas a high quality book (which is bloody massive btw) gives you many, not least of which is the chance to further your career.
Understanding ghc compiler errors takes time and practice.
to get `natVal`, and also to use almost every useful function (like `!`) on vectors, which requires a `KnownNat` constraint :O
Haven't tried it, but this should be really nice for deriving generic for some things. I've run into this problem a lot, trying to do a syb traversal on an AST that stores its source as PrettyPrint.Doc
The second edition of "Programming in Haskell" will be published in 2016. The new version of the book is an extensively revised and expanded version of the first edition. It has been extended with new chapters that cover more advanced aspects of Haskell, new examples and exercises, and solutions to exercises. The remaining material has been completely reworked and reorganised in response to changes in the language and feedback from readers. The new edition is fully compliant with the latest version of Haskell, including recent changes to the prelude concerning applicative, monadic, foldable and traversable types. I'll do a formal announcment with more details later on.
Yay, now we can hide our `.Internal` modules! /s :D 
Ooh, as someone who picked Emacs up in the past 12 months (and always used Enterprise (R) Integrated (TM) Development Environments before), it's a gigantic pain in the ass at first; but after you become fluent in the basic commands, it is absolutely worth it. I use it for everything now and groan whenever I have to open XCode.
Have you typechecked this? I'm pretty sure instance Applicative f =&gt; Applicative (Nullipotent f a) where pure x = Nullipotent $ pure x Nullipotent mf &lt;*&gt; Nullipotent mx = Nullipotent $ mf &lt;*&gt; mx won't work. It should be `(Nullipotent f)` in the instance declaration and also `Nullipotent mf &lt;*&gt; Nullipotent mx = Nullipotent $ mf &lt;*&gt; mx` won't typecheck: `mf` and `mx` are both of type `f`. That can't be, since `f` doesn't have kind `*`. What I think you wanted is newtype Nullipotent f a = Nullipotent { runNullipotent :: f a } e.g. note the `f a`. But then it's just a newtype wrapper around an arbitrary `Monad`. 
indeed, and I should know as well as anyone that facetiousness hardly ever translates onto print. I was trying to sorta joke. But the questions were a bit presumptive seeming. Mea cupla. Text communication is fraught with peril ;)
No, my personal appearance is not copyrightable. I don't even have the copyright in order to license it under CC, and CC can only apply to things that fall under copyright law. At any rate, *privacy* is 100% distinct from free/libre/open issues for *published* works. Privacy is a very important thing. It's when someone *publishes* something that the question of the terms (proprietary or free/libre/open) come into question in terms of ethics and values and practical freedoms etc.
This is deep, dangerous magic... just like in the Inheritance cycle! http://inheritance.wikia.com/wiki/True_name
Try passing -ddump-deriv to GHC for the derived code for instances. 
Oh, let me clarify what seems to be a miscommunication: I'm not asking to apologize for getting paid! There's absolutely no wrong in getting paid. That's not anything to apologize for. I'm only saying to apologize for using proprietary restrictive terms on otherwise shareable works. Getting paid is fine. Proprietary terms are not fine. This is a means vs ends questions. The end of getting paid is fine. The *means* of using proprietary terms is something that calls *at least* for apology (and some would go a lot farther than I would about this). As for Kickstarter/Patreon etc., I've been refraining from mentioning my project ([Snowdrift.coop](https://snowdrift.coop)) because despite it being applicable (and written in Haskell!), I'm not trying to promote myself or our project, I was trying to only mention the main idea. It's relevant though, and the writings and stuff there have more info. In short: there are failings about the nature of Patreon and Kickstarter that make them not as effective as I wish they could be, and we hope to fill a niche that's missing. That said, supporting projects through Patreon *is* good, and yet the only projects that *deserve* such support are those under free/libre/open terms. This book is proprietary, and that's *unfortunate* but at least the excuse is a *good* one: the authors want to be funded. If someone gets funded adequately on Patreon, then they do *not* have that excuse and are just being jerks (or just ignorant) if they don't freely-license the results. Basically: the asking for funding for this book is GOOD and I don't want to discourage that. It's also honorable to have offered ways to get it to those who can't pay so it's not exclusionary. It's just that the proprietary terms also limit the creative freedoms of people to use the material, all the things that make open source software succeed, the unrestricted collaboration and sharing etc. And I'm only saying that publicly *acknowledging* that downside is a fair and honorable thing to do.
I had typechecked (and used, and copied/pasted) the newtype code - but apparently the `a` got deleted somewhere in my editing. You are correct about what I wanted. I did not check all of my hand-expanded code - fixed that as well. Thanks! &gt; But then it's just a newtype wrapper around an arbitrary Monad. Possibly just applicative, but yes exactly. The idea would be that I can elsewhere ask for `Nullipotent m a` or `Nullipotent IO a` or what have you. I do have to be careful when manually constructing a Nullipotent. But I believe the operations exposed are otherwise safe.
I had nothing in particular but the Q&amp;A sessions after talks are always informative.
I wasn't talking about price. The complaint isn't about the money. It's about the legal obstacles that are in place which block me from doing constructive creative things like combining bits of the wikibook with bits of this book to create new value.
CC-licenses don't cover property, they only cover things that fall under copyright law. You can't CC license your chair, only a picture of your chair, and even then not a physical print itself, but only the *soft* image that is the intangible form. But the rest of your comment is correct: personal images are not copyrightable.
So there are many santas :)
Exactly! I should get an undefined exception, not a weird message about not defining the `Show` instance properly...
Don't get me wrong, you should definitely be compensated for your work. The authors of RWH/LYAH/PACPH obviously were able to have their work compensated via a publisher as well as contribute to the pool of open education resources everybody can share URLs pointing directly to a chapter or paragraph. If you don't believe in such creative commons concepts and open education that's perfectly fine. It's your life-time you invested into this book, it's your decision how to publish your creative work, and control how people are allowed to use your work. However, at the same time I believe we should promote open works that contribute to open education way more than closed works, and therefore I don't think this deserves a direct free-advertising link into the sidebar. The book can still be recommended, but it clearly shouldn't be the top-recommended resource, however good it is. After all, the existing open books are not as terrible in comparison as some comments here make it sound...
Thanks for that! I get [1 of 1] Compiling Main ( src/Main.hs, src/Main.o ) ==================== Derived instances ==================== Derived instances: instance GHC.Show.Show n_ayy =&gt; GHC.Show.Show (Main.S n_ayy) where GHC.Show.showsPrec = GHC.Err.error "Void showsPrec" GHC.Show.showList = GHC.Show.showList__ (GHC.Show.showsPrec 0) instance GHC.Show.Show Main.Z where GHC.Show.showsPrec = GHC.Err.error "Void showsPrec" GHC.Show.showList = GHC.Show.showList__ (GHC.Show.showsPrec 0) Generic representation: Generated datatypes for meta-information: Representation types: Linking src/Main ...
Does this kind of information hiding actually deliver boons w.r.t. things like optimization? Why not take Guido's "consenting adults" approach to begin with and allow something like "unsafe import" to depend on unexported functions? With advice that you can expect no upstream support if you do choose to do this.
Well, the trick used with `mtl` is that functions should be polymorphic in the monad that they are consuming, and only rely on classes like `MonadCatch` or `MonadIO`. If this rule is obeyed, library code should keep working regardless of what kind of a monad you built out of the transformers, and you can compose transformers from other libraries into yours.
&gt; I'm just wondering about how the run-time error (?) occurs. Here is a simpler program with the same runtime error: {-# LANGUAGE StandaloneDeriving #-} data Uninhabited deriving instance Show Uninhabited main :: IO () main = print (undefined :: Uninhabited) So the error occurs because you're trying to print the value of a datatype with zero constructors. The error message is not very clear, but basically `print` calls `show`, which calls `showsPrec`, whose derived implementation throws this error. The name of the canonical datatype with zero constructors is [`Void`](http://hackage.haskell.org/package/void-0.7.1/docs/Data-Void.html#t:Void). Here is more complicated example with a custom error message: {-# LANGUAGE DataKinds, GADTs #-} data Nat = Z | S Nat data Fin n where FZ :: Fin ('S n) FS :: Fin n -&gt; Fin ('S n) data Vect n a where Nil :: Vect 'Z a Cons :: a -&gt; Vect n a -&gt; Vect ('S n) a index :: Vect n a -&gt; Fin n -&gt; a index (Cons x _ ) FZ = x index (Cons _ xs) (FS n) = index xs n index Nil _ = error "never happens, Fin 'Z is uninhabited" main :: IO () main = print $ index (Nil :: Vect 'Z Int) (undefined :: Fin 'Z) Here I'm constructing the type `Fin n` of natural numbers which are less than `n`: there are two inhabitants of `Fin ('S ('S 'Z))`, namely `FZ` and `FS FZ`, there is only one inhabitant of `Fin ('S 'Z)`, namely `FZ`, and there are no inhabitants of `Fin 'Z`. I then use this type to implement a safe vector-indexing function, which is guaranteed not to fail with some "index out of bounds" error because the index is a `Fin n` where `n` is the length of the vector. Such an index is guaranteed to be at least zero and smaller than the length of the vector, and so is guaranteed not to point outside the bounds of the vector. In the `Nil` case I'd have to receive a `Fin 'Z`, but there are no constructors which could possibly construct a `Fin 'Z`, so I confidently assert that this case will never happen. And in a total language, I'd be right, because the compiler would prevent me from writing an expression of type `Fin 'Z` which doesn't actually produce a concrete value of type `Fin 'Z`. In Haskell however, `undefined` is a valid expression for any type including `Fin 'Z`, so I have fooled myself into thinking that my error would never be thrown while in fact it can. I guess the `deriving instance` mechanism made the same mistake, thinking that `showsPrec` would never be called with a value of type `S n` because your `S n` is uninhabited. To avoid that problem, I usually force the uninhabited value, thereby causing the error "Prelude: undefined" to occur instead of my custom "never happens" message: index Nil n = n `seq` error "never happens, Fin 'Z is uninhabited" And when I feel really pedantic, I use [`pseq`](http://hackage.haskell.org/package/parallel-3.2.1.0/docs/Control-Parallel.html#v:pseq) instead, which guarantees that the uninhabited value will be forced before my `error` call: import GHC.Conc index Nil n = n `pseq` error "never happens, Fin 'Z is uninhabited" I think the generated code for `Show (S n)` should do that! This way you would have got the error "Prelude: undefined", which would probably be less confusing.
This is the ticket where that error message was decided: https://ghc.haskell.org/trac/ghc/ticket/4302 (5 years ago).
I haven't bought the book thus far, because I already have way too much to e-read and I get distracted. I would 100% buy a physical copy though!
You're absolutely right. The fact that type level `Nat`s are not defined inductively in `GHC.TypeLits` does make them useless. This is however a clue as to what their real purpose is: being used with SMT type checker plugins. If you aren't using a type checker plugin (and at this point, that's still a pretty experimental thing to do), then you should define your own version inductively.
&gt; Visual studio also could tell me exactly which line was erroring Emacs has support for this with Flymake. https://www.youtube.com/watch?v=Zy1dF5suN5E
By debugging tools I mean variable watches, breaks, etc. You can see compile-tile failures just fine, but if your program breaks at run time then it's not so straight-forward (just like with any other language).
They can use the context, they should not update the context.
Just doing stack clean and restarting emacs seemed to fix the problem! Thanks :D
It turns out that the problem was solved by running stack clean and restarting emacs. Thanks though!
yup; and for the record, all the CC licenses even protect publicity issues by requiring any endorsements to be removed from derivatives and for the original authors name and association to be removed from particular derivatives upon request.
That's a good point; the CC licenses are specifically *not* open in this aspect.
The ND and NC licenses are not open, but the requirements to remove endorsements or to remove an authors name do not violate a single bit of any definition of Open Source or Open. There's nothing about Open that conflicts with an author saying "while I can't stop you from making your derivative work under CC, I don't like this work, so I want my name removed from it." That doesn't make the licenses non-open.
Are you going to ask https://www.reddit.com/r/haskell/comments/40hcf4/haskell_books_to_be_published_in_2015/cyv3c8r if their book will be CC licensed?
will do, thanks
Any chance of CC-BY-SA or other free/libre/open licensing? We need more resources to join the commons and be inter-compatible etc. (for example, Yet Another Haskell Tutorial was released to allow its use under those terms, and the result is that it got incorporated into the Haskell Wikibook and greatly improved and integrated to create great value that isn't possible if each resource is just locked down and segregated). I understand that there may be some complex political issues and challenges, but I hope you'll at least consider it. Thanks P.S. CC licensing certainly doesn't mean you can't *also* sell copies of the book, I'm talking about wanting the freedoms to build on educational resources and improve them, this isn't about the money per se.
When it's solely a matter of a library that you are maintaining and someone somewhere else unaffiliated with you is breaking the invariants to their own ends, that's fine, what they are doing is irrelevant and if something goes wrong it's only their headache. But if you both work for the same organization, and you build something and take the time to ensure there are invariants that hold, they're probably important and your code may in fact need them to hold to make sense. Then someone else comes along and rips apart the internals and changes with things to make their code work in a very hacky and un-haskell-like fasion, and returns data to you with the invariants you so carefully preserved all violated and your code is now apparently broken. Now you have a headache. Remember, 90% of everything is crud, including programmers and even co-workers. Much of Haskell's power comes from the kinds of invariants you can guarantee, not from pretty please asking people not to break them unless it's really convenient.
Very cool project! But as far as j can tell it uses string reduction rather than graph reduction, which makes it less practical. 
Thank you :)
But you're not enforcing that. Is the type just meant as a reminder to not do so?
We need to run a `MTL of no Writer` Proposal.
`Nullipotent f a` a little different than `a`, in that the former may produce different values depending on what *other* `f` actions have been run.
It's a reminder at the sites where I can't enforce it (actually wrapping a value that I'm asserting to be nullipotent). It's also exposing functions for composition/manipulation that should preserve it.
My time is worth more to me than the cost of a book. If I think paying for a book will save my time, it is a rational choice to buy the book rather than using an inferior book that has no cost. Note: Free books (as in beer and libre) may be very good. I don't mean to imply otherwise. For example, I bought physical copies of all of LYAH, RWH and HRMLP.
Oops, sorry, read `*&gt;` as `$&gt;`.
The type and `Functor` instance look like [`Data.Functor.Day`](https://hackage.haskell.org/package/contravariant-0.6.1.1/docs/Data-Functor-Day.html). I'm not sure about the applicative instance. I've also seen this type in the context of [recursion schemes](http://blog.functorial.com/posts/2012-02-12-Doubly-Recursive-Functions-Generically.html).
Looks like [Day](http://hackage.haskell.org/package/kan-extensions-4.2.3/docs/Data-Functor-Day.html). Right under your nose! I didn't know about it, just randomly poked around in kan-extensions. Your runWat seems to be a combination of trans1, trans2, and dap.
So out of my head something like this : askForInteger :: IO Integer -&gt; maybe IO Integer askForInteger = do input &lt;- getline case readMaybe input | nothing -&gt; do putStrLn "the input was not a number" return ?? | Maybe number -&gt; do return number 
Thanks. "All concepts are Kan extensions" indeed. I really should gain an intuition for Day convolutions and Kan extensions; right now they are a bit above my comprehension level. At least I have a use case now!
Looking at the [implementation](http://hackage.haskell.org/package/kan-extensions-4.2.3/docs/src/Data.Functor.Day.html#line-80), &lt;*&gt; does seem to do the same thing.
Oh, okay, I get it now. Your `runWat` just needs an applicative functor, so you could as well use e.g. `Concurrently` from async in place of `IO`
Personally, I hope Chris and Julie make a lot of money from this book, firstly to repay them for the time and mental effort they've put into writing it (as well as supporting Haskell beginners in general) but also to encourage them and others to write more Haskell learning materials.
Assuming I understand your intent, I would compare this being polymorphic over Functors/Applicatives/Monads. Consider these values: foo :: Monad m =&gt; m A bar :: Monad m =&gt; m A -&gt; m B baz :: (forall m. Monad m =&gt; m A -&gt; m B) -&gt; C Of these, `foo` is equivalent to a value of type `A`, because we can just pick `Identity` for `m`. (I'm ignoring `fail`.) `bar` is pure, in the sense that it can't perform any effects itself, but its caller can choose a monad and pass an argument causing effects in that monad. `baz` takes a pure function, but may pass effect-causing arguments to it. In your case, we might have: foo' :: Nullipotent IO A bar' :: Nullipotent IO A -&gt; Nullipotent IO B baz' :: (Nullipotent IO A -&gt; Nullipotent IO B) -&gt; C What these can do depends on whether they had were defined with access to the constructors for `Nullipotent`. Without access to the constructors, then `foo'` and `bar'` are equally powerful to `foo` and `bar`, but `baz'` is less powerful than `baz` because it can only pass pure values to its argument. If they are written with access to the constructors, then `foo'` and `bar'` are just regular `IO` expressions, but `baz'` gains the power of `baz`.
Well, good for you. Spend your time however you want and thanks for the Wikibook updates. You may find some people are open-minded - but in the larger context, you are essentially complaining about a few drops of occasional rain when you built your house at the bottom of a waterfall. Authors writing texts for money is well understood and goes back centuries. Telling somebody they need to *apologize* for doing it, need to *recognize* your discomfort with the situation, will make everybody just not give a damn since you're written off as uncompromising unrealistic loon. The sense of injustice here isn't even observable compared to "unfortunate restrictions" compromising "freedoms and collaboration" - copyright law in general. 
&gt; This is for representing subsets of other applicatives that are Nullipotent. That's not going to work. Basically, if you have `f a` where some values are nullipotent actions and some are not, then the same will be true of `Nullipotent f a`, because it's isomorphic to `f a`. You need to have some type `f` where all of the actions are *already* nullipotent, and embed that inside a type `g` where not all actions are. I gave an example in another comment with `Reader` and `State`, which I like enough to repeat: -- | Execute an action that depends on the current state but -- does not modify it. readOnly :: Reader s a -&gt; State s a readOnly ma = runReader ma &lt;$&gt; get The idea here is that `Reader` is a type of nullipotent actions, while `State` is a type that accomodates but does not guarantee nullipotent actions. By interpreting `Reader` inside `State` you can guarantee that the actions that occur inside a `readOnly` block are nullipotent.
The code you posted is still incorrect: askForInteger :: IO Integer askForInteger = do input &lt;- getLine case readMaybe input of Nothing -&gt; do putStrLn "the input was not a number" askForInteger Just number -&gt; return number edit: fixed the type to `IO Integer` :o
Whatever you have to do, buy it. Based on where you're at, it'll be really valuable for you. I never even finished the Yorgey course, it wasn't right for me somehow, but Chris's book has been fantastic. Last night I made a bunch of improvements in my toy project based on the Monads chapter alone.
It's funny, I remember being a bit irritated by the excessive ordering imposed by [this function](http://hackage.haskell.org/package/streaming-0.1.4.0/docs/Streaming.html#v:zips) for 'zipping' two 'free' things. It seems clear that `Day` is really desired type for this, not `Compose`.
If you are learning Haskell, buy this f&gt;&gt;=ing book. This is quite simply the best Haskell resource out there because it's thorough, patient, and in-depth without being dry or talking down to you. Plus it has plenty of exercises including answers (you probably won't need the answers because you'll understand the material). Source: read it every day at lunch since I bought it, currently in chapter 18.4. Now understand a bunch of stuff that 11 months of other books/blogs/redditing didn't help me really grasp.
Your question is still better-suited for the support contact than Reddit, I suspect.
As /u/cdsmith says, email us at the [support line](http://haskellbook.com/support.html), we'll try to get you sorted and setup with a copy.
Ah, curses! Muphry's law strikes again!
One difference here from something like Python is that this would be obvious. You'd need to enable `unsafe import` and it'll show up in the code.
Shouldn't the pattern-matching in the definition of `index` force the second argument already, before we reach the right-hand-side of the equation? Under what circumstances could an `undefined` input possibly cause the impossible error to be thrown, rather an an exception about `undefined`?
the most instant-gratification-y FRP demos I've seen in this space are flare: http://sharkdp.github.io/purescript-flare/ What's sorely missing is client-to-server-and-back FRP story. If a language like R is able to pull off shiny http://shiny.rstudio.com/gallery/ this should be doable in Haskell. Perhaps reflex + ghcjs + yesod can do this in theory, but a real proof of concept and some walkthroughs are sorely needed. Maybe ghcjs is not the best option here?
Maybe you can get some ideas from the Purescript crowd? Thermite solves the composition problem using lenses and prisms, while Halogen solves it by using coproducts. 
Basically it's a two-column layout, where the first column is your code and the second column is a repl which displays stuff about your code. Type-checking (*without* compiling) is a first-class user interface command, so basically I just write an expression, typecheck, write an expression, typecheck, etc., and I always have immediate feedback in the second column. It's just a single keyboard command which executes instantly (even on real-world-size projects) and doesn't even move your text cursor out of the place you're typing. After I have finished constructing the body of a function, I can just tab over to the live-repl and try it. It supports almost everything, including IO, so you can even quickly check queries to a database and immediately tab back over to column one to continue writing. Also, Agda and Idris both operate in this same emacs-mode paradigm, and in their cases, the above is moved to the extreme, because the compiler doesn't just typecheck your code, it actually assists you in writing your code in the first place, even to the point of actually constructing expressions for you from scratch. The hotkeys between all three languages are even the same for all the major commands that I use.
Whoa, that list *is* quite impressive. Thanks for the link.
I'm unsure why you have quotation marks around "implementations". Most of them are difficult to share, my first implementation SKI was in 1980. I think it was in C, but I might have written some of it in 9900 assembly language. It was very much a toy, since there's not very much you can do in 64KB memory. My second implementation was in C and is documented in https://books.google.co.uk/books/about/SMALL.html?id=q-lxPwAACAAJ&amp;redir_esc=y (there's also a BIT publication of this). The third implementation is part of the interactive system for LML and Haskell in the hbc compiler. The combinators are written in LML, and compiled by the regular compiler. Documented in http://journals.cambridge.org/action/displayAbstract?fromPage=online&amp;aid=1322252&amp;fileId=S0956796800000617 I've also recently written a C implementation again, which I actually have the source code for. I'll put this one on github.
Don't forget [Hoed](https://wiki.haskell.org/Hoed) for debugging ;)
As of this point it is basically impossible to use the GHC type level natural number type for things like induction, arithmetic, etc. out of the box. e.g. (+) has no magic power for propagating KnownNat constraints. e.g. even if you have `(KnownNat n, KnownNat m)` you don't get `KnownNat (n + m)` unless n and m are statically known at compile time to be particular constants. You can hack around this with `reflection`-like tricks. Induction can be faked with some type family / GADT tricks, so long as you start from known constants, but given just a KnownNat you run into problems again.
Pattern-matching proceeds from top to bottom, from left to right. So in the following definition, index' :: Fin n -&gt; Vect n a -&gt; a index' FZ (Cons x _ ) = x index' (FS n) (Cons _ xs) = index' n xs index' _ Nil = error "never happens, for real" the first thing which happens is that our undefined index is compared to `FZ`, which causes a "Prelude: undefined" exception to be thrown. However, in the original implementation, index :: Vect n a -&gt; Fin n -&gt; a index (Cons x _ ) FZ = x index (Cons _ xs) (FS n) = index xs n index Nil _ = error "can actually happen" we instead begin by comparing the vector with `Cons x _`. Since the vector is `Nil`, the comparison fails, and `FZ` is not compared with anything. The same thing happens on the second line, and then the third line matches, and the error occurs. You might think you can force an exception-throwing pattern-match by splitting the last line in two, like this: index :: Vect n a -&gt; Fin n -&gt; a index (Cons x _ ) FZ = x index (Cons _ xs) (FS n) = index xs n index Nil FZ = error "can it happen?" index Nil (FS n) = error "can it happen?" But that doesn't compile because `Nil` forces `n` to be `Z`, and the types of `FZ` and `FS n`, namely `Fin (S ...)`, are incompatible with that. You can do this though: index :: Vect n a -&gt; Fin n -&gt; a index (Cons x _ ) FZ = x index (Cons _ xs) (FS n) = index xs n index _ FZ = error "never happens" index _ (FS n) = error "never happens" 
Strange... this didn't show on https://www.reddit.com/r/haskell/new/ when I submitted https://www.reddit.com/r/haskell/comments/40rsn1/ghcdevs_warnings_wall_and_versioning_policy/ Also, your post shows up as "younger" (or rather "newer") even though it's been submitted about 10 hours earlier than my submission.
Massive! Big thanks to all involved: it is humbling to see the pace at which this project moves forward.
This system relies on each module having an apply function from (S, Results) -&gt; Results. So the modules still know about the "Results" type. Each extension requires their specific S. How to transform the "global" source data into the specific S is still work for the users of the extension. It can either be hidden inside the extension and combined monoidally like we see here, or just written by the user in a chain of code that calls apply for each extension, with their wanted data. The the monoidal composition simply moves the compution from code to a list. f1a = f1.comap(a) f2b = f2.comap(b) f3c = f3.comap(c) composeAll s [f1a, f2b, f3c] VS f1 (a s) . f2 (b s) . f3 (c s) Where "a" is the function `S -&gt; Specific_S` and f1a is the extension with the comap applied with a. As long as the extension writer needs to know about `Results`, we don't gain much from the comap part. Moreover, the function being `Results -&gt; Results` screams `BigScaryMutableResultsState` where extensions have free reign over what happens there.
Aha—that's quite enlightening. I wasn't desugaring the two-argument pattern match into nested `case` statements in my head—if you write it out that way, it becomes obvious what's going on. Thank you!
Does this work on windows? I tried it and can't seem to figure out how to get apm on the command line working. It seems to be geared towards Mac. This also seems to be the case for ghc-mod, hlint and stylish-haskell
Ooh, neat! I will likely be working on my Haskell/GHCJS SPA scaffold, and the thing I want the most is a client-side router for `reflex-dom`. No wiki account yet, but I requested one to put it in there.
Thanks for this. I agree with your assessment that the end of mathematics is being able to work through exercises and prove things on your own. I didn't mean to imply that I would be using haskell to...circumvent the learning of calculus as it's traditionally learned. Rather, I saw using it to enhance what I was being taught in class. For example, it's not going to be made explicit in class, that differentiation is higher-order. It takes as inputs functions, and outputs other functions. I think it would be a fruitful enterprise to think through *how* to represent the type of this sort of function in Haskell. Also, I work full-time, so there is not other time. This is what happened last semester. I had to put the breaks on Haskell because I kept having to resort to using other means of calculating things/graphings things.
one really really neat trick is that you can write a datatype to represent expressions: data Expr = Lit Double | Var String | Add Expr Expr | -- etc... which you can then make an instance of the `Num` class: instance Num Expr where (+) = Add -- etc... so you can do stuff like `Lit 10.0 + Var "x"`. Then you can do [differentation on symbolic expressions](http://5outh.blogspot.com/2013/05/symbolic-calculus-in-haskell.html)! And finally you can solve expressions using a function eval :: MonadReader (Map String Expr) m =&gt; Expr -&gt; m Double or, for fun and profit, a function like: simplify :: MonadReader (Map String Expr) m =&gt; Expr -&gt; m Expr which would do one 'step' of simplification.
Ah, you seem to have had a good grasp on what I was saying already. I just wanted to throw my 2 cents in about learning math. Good luck with your studies!
If they're not already on your radar, consider checking out: * [ad](http://hackage.haskell.org/package/ad) * [integration](http://hackage.haskell.org/package/integration) Try to express some of the problems you're solving by pen &amp; paper with the ad package. I think having tools to help with both numerical and symbolic calculus techniques are invaluable when trying to learn how to express and tackle new problems. [Conal's video](https://vimeo.com/6622658) introducing AD gives a better explanation than I can possibly provide here. But for learning and exploring math, I find these corners of Haskell occasionally incomplete (for my particular interests). When I want to brush up on, say, linear algebra, I'm really thankful for [linear](http://hackage.haskell.org/package/linear) and [hmatrix](http://hackage.haskell.org/package/hmatrix). But as of 2016, the "kitchen sink" is not yet built in to Haskell. In order to play with ideas mentioned in lecture or a textbook, you may run out of things to call in Haskell that are available in more "popular" language ecosystems. For instance, practically out-of-the-box, Python supports [toeplitz matrices](http://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.linalg.toeplitz.html) in the wonderful SciPy library, and so does Matlab, but [I didn't find anything for haskell](https://www.stackage.org/lts-4.1/hoogle?q=toeplitz). I'd love to hear how others tackle these problems - when you run out of libraries to express math ideas, and you're like me and too lazy to DIY, what do you reach for? To anticipate a promising answer to my own question, one could always try out [HaskellR](http://tweag.github.io/HaskellR/) since R's libraries and ecosystem have more to offer than Haskell currently does. [For instance...](https://stat.ethz.ch/R-manual/R-devel/library/stats/html/toeplitz.html)
&gt; deprecating -Wall Sounds like a horrible idea. Especially to support a use case out of the lazy wishful thinking corner of people who think they can avoid doing any work to keep their code -Wall clean for years if they just make everyone else (e.g. the GHC devs) jump through enough hoops.
Are you saying that you ran into problems when trying to implement square roots, imaginary numbers, and trigonometric functions "from scratch"? Is that because you can't see how to get from basic addition and such to them? (I'm guessing this is it because simply using a sin function is not hard?) Assuming that the answer is yes, just to avoid a round trip... imaginary numbers are really "just work" or "just programming" on their own, but square roots and trig are legitimately difficult! The problem is that in fact calculus will teach you what you need, but they won't front-load the relevant math as you might like. If you proceed through a normal calculus curriculum, you should at some point discuss [Newton's method](https://en.wikipedia.org/wiki/Newton's_method), which is for finding 0s in a polynomial. The square root of _y_ can be found by solving for the (positive) 0 of the equation _x^2 - y = 0_. This gets you at least integer roots (and via simple composition, rational powers) via simple arithmetic. You will also, somewhat later, cover [Taylor polynomials](https://en.wikipedia.org/wiki/Taylor's_theorem), which allow you to convert a wide variety of transcendental functions into approximate polynomials, again, allowing you to compute them via simple arithmetic. In both cases, I suggest just using the existing functions for now, and then swapping in your implementations when you get to the relevant parts of your course, rather than trying to go too far ahead. Just be confident you can do it when you get there. (And, yes, there are better algorithms for both the approximation algorithms I mention, of course; I'm sticking to what you'll get in elementary calculus.)
What is the use case for this anyway? Why should the whole community invest effort and in fact suffer the consequences of warnings that can not be improved just so someone with an internal policy of always compiling -Wall clean can do so without ever adjusting their code to new and improved warnings? I can see how it would make sense to have a requirement that a changed needed to silence a warning in a new version should never break compilation completely in an old one as there is certainly a use case for allowing compilation with several versions at all (possibly with warnings in some versions) but this is taking things way too far.
The use case is to be able to write warning free code without using CPP, not without doing any work.
We should team up! To be completely and brutally honest, * full-time (low-paying) job + * housing rat race every 9 - 14 months (Austin) + * student loans + * only take 1-2 courses per semester and feeling like time is slipping away + * being 26 years old and feeling like I'm an old fart + * pretty much all masters CS programs presuming that either a) you're going because you just want a job, or b) because you don't have a CS/Math undergraduate degree you might as well not apply + * suspicion that collapse of uni system is getting closer and closer ...I am basically just taking it day by day. Not sure whether I should continue taking more undergrad math/cs courses at UT after I've tapped out the local community college, or should just apply to graduate programs. Not sure whether I should just get another bachelors in math or cs. Not sure whether I should apply to a mathy-logic masters program, or a traditional cs masters (probably won't do this...because of job focus at expense of academic focus), or a philoy-logic program, or... Right now, my plan is to keep on taking math/cs courses at community college up to Calc III/Linear Algebra, then decide whether I am going to re-apply to UT, or apply to a graduate program...while at the same time try to get an actual programming job that would let me do these things. What's been your experience thus far?
Hype!
One giant leap for Man kind!
Oh, I agree with that bit. That would be useful and does not seem like a huge effort. I just don't agree with all the bits where essentially introducing a better warning that warns in previously warning free code would be considered a regression.
i imagined it as a performance optimization, or even for readability. x^3 might arise naturally "at the low level" from dynamically composing "high level" values. like, in some codegen, you might emit: x = 1 y = x use(y) use(x) even if you'd never write it by hand. which is necessary because in general your template looks like: x = &lt;...&gt; y = x x += &lt;...&gt; use(y) use(x) but in particular, {x+=0} was optimized away, and we should thus optimize {y} away too: x = 1 use(x) use(x) I feel like this comes up a lot. does STM optimize away adjacent reads? would a "nullipotent" refinement help? maybe. 
I'm trying to clean up my bit-rotten [process-streaming](http://hackage.haskell.org/package/process-streaming) library, one of the many existing wrappers around [process](http://hackage.haskell.org/package/process). The idea is to completely specify what to do with each piped standard stream when you launch the external process, instead of getting a tuple of resources that you must remember to free (and in the case of output/error streams, drain) afterwards. I have [type](http://hackage.haskell.org/package/process-streaming-0.7.2.2/docs/System-Process-Streaming.html#t:Piping) that does that, but it is a bit ugly because it needs a constructor for each combination of stdin/stdout/stderr in which one may be interested. If that type were an Applicative, I could do something like (assuming ApplicativeDo) execute (do stdinResult &lt;- feedBytes "some input" stdoutResult &lt;- consumeStdout (withFold Control.Foldl.list) stderrResult &lt;- consumeStderr (withFold Control.Foldl.list) pure (stdinResult,stdoutResult,stderrResults)) (shell "cat") "pure" for that applicative would write nothing to stdin, and drain stdout and stderr concurrently, discarding the data. Day can help me construct such an applicative out of simpler applicatives that write to stdin and read stdout/stderr. 
Very nice!
We prefer to call it "PHP mode".^(tongue in cheek)
Fascinating, thank you!
Woah, this looks awesome! Exactly the thing I will need soon in one project :) Thanks a lot
Are there plans to publish release candidates of GHC 8.0–specific packages to Hackage? e.g., `base-4.9.0.0`, `ghc-boot`, `template-haskell-2.11.0.0`, etc. Viewing the Haddocks would be super-helpful when I'm adjusting my code to work with GHC 8.0 (paging /u/hvr_)
&gt; this doesn't sound too conservative, but still unnecessary. It does sound as if extra warnings can only be introduced to -Wall in major version changes which sounds more conservative than any other compiler for any other language.
&gt; and write my class notes in haskell If you are looking for a nice way to type your notes up, LaTeX will help you out the most in the long run for CS/Math, and a calculus class provides plenty of opportunities to practice it; you cover some interesting notation, and the examples are amenable to learning graphing packages like pgfplots (if you're up for it). On a different note, you're really going to miss out on calculus if you try using the computer to solve it all for you, and when you reach the point where the computer really can't help you with problems (Real Analysis, w/r/t calculus) you will find it much harder.
Indeed. I guess this needed one more read-through. 
While there are a few known type checker bugs, the bigger issue is the performance of the pattern checker which tends to blow up on some guard-heavy programs with very high memory usage. There is a sampling of the major known issues present in this release in the announcement. 
This is not safe. The compiler is now free to inline as it likes and we may end up with multiple copies of the IORef. Maybe ghc doesn't normally do this, but I would not trust this construct. 
I didn't put much thought into wether -Wall should be deprecated -- I don't care if it's left as-is (or an alias to the latest all-warnings flag). I think the addition of -WallX.X is the important part of what I suggested.
Can you clarify what you mean by "this" when you say "What is the use case for this"? The linked article is just a policy proposal, not a proposal for a code change, so it's not clear what you're asking for. You seem to be rather upset about something, but I'm not sure what it is. Are you against the no-new-warnings-in-minor-versions part? Because that's inconsistent with what you're saying ("without ever adjusting their code to new and improved warnings" would only be the case if the proposal was to *never* change -Wall, which is not the case).
Good point! At least, it would not help with the simplistic implementation. I could imagine having -fwarn-unused-importsX.X as well, and the -WallX.X flag would alias to those specific flags (when appropriate). I'm only saying it's possible, not suggesting the work should be done :)
This line right here is your problem: mergesort2' (as:bs:css) = mergesort2' $ (merge as bs) : (mergesort2' css) The inner call to mergesort2' ends up sorting all of the elements in css. So (merge as bs) : (mergesort2' css) is actually a two element list (unless css is empty). Therefore the outer call to mergesort2' will just merge "merge as bs" with the (sorted) remainder of the list. In other words, you've created an insertion sort that inserts two elements at a time (i.e., as and bs) instead of one. This will have quadratic performance. I encourage you to step through it by hand on [1..8]. You'll pretty quickly see that you're not pairing up elements the way you expected. 
&gt; Do I follow through the program as if I was a computer? You can do this using `ghci`'s support for breakpoints and step-by-step debugging, which you can find here: * [GHCI debugging](https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/ghci-debugger.html) However, I think you will progress more quickly if you adopt a different approach to debugging your program. I instead recommend breaking your program into smaller functions and testing them interactively within the REPL.
Oh, I see now.
And we're still stuck on 7.8.3 :(
To try this out with stack, put the following in your stack.yaml (you won't be able to use a snapshot, since there aren't any snapshots with ghc-8 in them. Nightly will probably update to ghc-8 soonish after it gets released) resolver: ghc-8.0.0.20160111 setup-info: ghc: linux64: 8.0.0.20160111: url: "http://downloads.haskell.org/~ghc/8.0.1-rc1/ghc-8.0.0.20160111-x86_64-deb7-linux.tar.xz" (assuming 64 bit linux - otherwise select another url from [here](http://downloads.haskell.org/~ghc/8.0.1-rc1/))
Thanks, I was wondering if that was the case. Any advice on how to make it safe?
yes, as opposed to a normal variable in a language does not have any thread-safe API.
Yes you are right. I can see the problem now. I fixed the problem and here is the new time masurement |------------+-----------+------------+--------------| | item count | 1000 | 10.000 | 100.000 | |------------+-----------+------------+--------------| | mergesort | 0.03 secs | 0.29 secs | 3.85 secs | | mergesort2 | 0.02 secs | 0.19 secs | 2.26 secs | |------------+-----------+------------+--------------| Here is the source that I mesured with: https://github.com/huseyinyilmaz/datastructures/blob/424c54fc4ab2c32c82d248b43fcd3c1ad678dd1e/haskell/src/Sorting.hs#L46-L63 Thank you for help me finding out the problem.
Looks super interesting, make sure you keep us all posted when you're ready to go full-remote!
Funny until the bit on monads, where it turned tragic ;)
I didn't even start programming until the age of 25. I bought a couple of books (python and linux) and hit them until I started to understand. I didn't get my first professional programming job until age 30, but I used programming as a "value add" at most of my jobs. I still (at the age of 38) have no formal qualifications in programming but have lucrative career and good prospects. Things can look bleak in your twenties, but you sound well ahead of me at that point in my life. Time is not slipping away, you're not an old fart. :-)
Just for fun, can you compare with the library sort, which is also a mergesort? sort = sortBy compare sortBy cmp = mergeAll . sequences where sequences (a:b:xs) | a `cmp` b == GT = descending b [a] xs | otherwise = ascending b (a:) xs sequences xs = [xs] descending a as (b:bs) | a `cmp` b == GT = descending b (a:as) bs descending a as bs = (a:as): sequences bs ascending a as (b:bs) | a `cmp` b /= GT = ascending b (\ys -&gt; as (a:ys)) bs ascending a as bs = as [a]: sequences bs mergeAll [x] = x mergeAll xs = mergeAll (mergePairs xs) mergePairs (a:b:xs) = merge a b: mergePairs xs mergePairs xs = xs merge as@(a:as') bs@(b:bs') | a `cmp` b == GT = b:merge as bs' | otherwise = a:merge as' bs merge [] bs = bs merge as [] = as 
All of these things are rather essential aspects of category theory, so why does "category theory" not mean that? I quite often say I used linear algebra to do graphics programming, would you prefer I said "I used 4x4 matrices to do graphics programming"?
This is very neat!
This implementation of FRP is prone to space leaks, for basically the same reason that the original work on Fran was: you can write programs which hang on to data too long, because the Next type constructor is an applicative. Concretely, in terms of API, the fact that there is a function of type `a -&gt; Next a` leads to space leaks because arbitrary values can be pushed into the future. To fix the space leaks, you need to do two things. First, Next should be a lax monoidal functor, which (unlike an applicative) should not have a strength. This creates some difficulties in terms of API, which can be resolved by noticing that there are *two* ways to constructivize the Global type operator. One, which the blog post points out, is to view Globally X as a stream of X's. The *other* way is to view it as the subset of X which consists of X-values which are usable at any point into the future without buffering -- call this Stable X. Then you can give operators like map the type `Stable(a -&gt; b) -&gt; Next a -&gt; Next b`. In terms of type theory, this all works out really neatly -- see my paper [*Higher-Order Reactive Programming Without Spacetime Leaks*](http://www.cs.bham.ac.uk/~krishnan/simple-frp.pdf). The one issue is that it doesn't embed nicely into Haskell, because the Stable type is really a comonad that needs syntactic support. However, if it were possible to overload the typing machinery for Cloud Haskell for user-defined types, you could embed it. 
In terms of end result, isn't this a lot like what recursion schemes can already do? Something like: import Data.Bifunctor data InB f a = InB { out :: f a (InB f a) } update f (InB t) = InB $ bimap f (update f) $ t ... so now we can do... data ListF a b = ConsF a b | NilF deriving (Show) data TreeF a b = BranchF a b b | TipF deriving (Show) instance Bifunctor ListF where bimap _ _ NilF = NilF bimap f g (ConsF x xs) = ConsF (f x) (g xs) instance Bifunctor TreeF where bimap _ _ TipF = TipF bimap f g (BranchF v l r) = BrancF (f v) (g l) (g r) instance (Show (f (a, InB f a)), Show a) =&gt; Show (InB f a) where show (InB t) = show t -- Yes, this is a bad show instance, but it's just for show. cons x xs = InB (ConsF x xs) nil = NilF branch x l r = InB (BranchF x l r) tip = TipF list = cons 0 $ cons 1 $ cons 2 $ nil tree = branch 0 (branch 1 tip tip) (branch 2 tip tip) *&gt; list ConsF 0(ConsF 1 (ConsF 2 NilF)) *&gt; update (+1) list ConsF 1 (ConsF 2 (ConsF 3 NilF)) *&gt; tree BranchF 0 (BranchF 1 TipF TipF) (BranchF 2 TipF TipF) *&gt; update (+1) tree BranchF 1 (BranchF 2 TipF TipF) (BranchF 3 TipF TipF) ... Or does the paper go well beyond this? EDIT: Rewrote with Bifunctor to make it tidier.
Depends on the application. I'd be pissed if it logged me out every time the developers deployed a new version (which can happen multiple times a day, if the company has CI set up properly).
Interesting.. 
lol i wish -- I'm excited to learn more about them and play with shiny new language features, but I have no idea what to do with any of them. The phrase made me giggle and apparently a few others.
&gt; comonad that needs syntactic support. Would [`codo`](https://hackage.haskell.org/package/codo-notation) do the job?
That doesn't sound leak a space *leak* - you are purposefully accumulating data. I would think that a space leak is always referring to something accidental (like folding with `+` and being surprised that it's actually building up thunk after thunk).
I-is the named derived from [Karius and Bactus](https://en.wikipedia.org/wiki/Karius_and_Bactus)
It is :)
Not directly, no. But we create interfaces via REST APIs using Servant, which then code from any language can talk to.
Sure, but presumably if accumulating arbitrary amounts of data is possible in Neel's set up then *accidentally* accumulating it is possible too. I'm trying to get at exactly what Neel's innovation is. Is it that it makes it *harder* to do things accidentally?
The problem is you need a functor that lacks strength, but every functor in Haskell is strong, because you can write `strength (a,fb) = (,) a &lt;$&gt; f b`. The fact that we captured `a` in the environment is the problem, so you really need a language in which it is possible to restrict what can be shoved into the environment and then used under a functor.
My current plan is to show up and hack on whatever sounds interesting at the time.
This only happens because we have `always :: a -&gt; Behavior a`, which is also weird from an LTL perspective. `always` is implemented in terms of `pure :: a -&gt; Next a`, so that is the source of the problem.
Right you are. Your work is much more related to LTL than Conal's and my work.
&gt; Are you saying this API makes it too easy to create space leaks by accident? Yes. There are plenty of semantically well-defined functions in Fran which leak a ton of memory by accident: if you ever hold onto a stream (a behavior) for any reason you've got a leak. This is super painful to debug because everything is well-defined mathematically and only causes issues at the operational level. If you can rule out those kinds of leaks statically, then you don't leak unless you explicitly write code to hold onto the data. In this case, all your regular FP intuitions about space usage apply without change. (That's a theorem which didn't make it into my paper. Surprisingly, it turns out by-need evaluation for the next type constructor is essential for making the argument work, which is very unlike the usual case in lazy languages, where by-need wrecks compositional reasoning about space usage.)
file a bug? https://github.com/fpco/schoolofhaskell/issues/
I use hvr-ppa repository, and `ghc-8.0.1-htmldocs` has all of those. I recommend!
This is actually one of the major criticism that I have for Neel's paper. His solution prevents purposeful accumulation (i.e., leaky by Fran's semantics), but didn't talk about things that are *accidental* (semantically shouldn't be leaky). The real reason for *unexpected* space behavior in Haskell has to do with the loss of sharing (of recursive redexes) during call-by-need evaluation. This was explored in my paper: [Plugging Spaceleak with Arrows](http://www.thev.net/PaulLiu/download/leak.pdf).
With a title like that it's hard to imagine the Reg being able to resist.
The article on tensorial strength on nlab [1] led me to believe that we have strength for all functors because all `Hask` functors are `Hask`-enriched. What's the relation of enrichment to "capturing `a` in the environment"? [1] https://ncatlab.org/nlab/show/tensorial+strength
[removed]
Has there been any work looking at other temporal logics and how they might correspond to functional programming? E.g. CTL or Hennessy Milner logic?
Both the Haskell and the Scala pros and cons had me laughing out loud.
If you are in a closed monoidal category (so you have an internal hom) you can curry out 'a' `Hom (a*b, c) ~ Hom(a,[b,c])`, now you can work with [b,c] as usual then shove 'a' back in by going in the other direction. If you go to duplicate these steps in Haskell that corresponds to `a` being in scope in a function from `b -&gt; c`.
Your `halve` function makes this an unstable mergesort. But you can split a list in halves in a stable way, and still have it work for infinite lists! (The second entry in the result will be ⊥ in that case, of course). -- | @halfsies@ picks out every 2nd element of a list, starting with the first -- one. The resulting list is of course half as long as the original one. -- Example: halfsies [1..10] = [1,3,5,7,9] -- halfsies [2..10] = [2,4,6,8] halfsies :: [a] -&gt; [a] halfsies (x:_:xs) = x : halfsies xs halfsies _ = [] -- | @end xs ys@ drops one element from xs for every element of ys. The result -- is equivalent to @drop (length ys) xs@ for finite lists, but `end` also -- works on infinite lists. end :: [a] -&gt; [b] -&gt; [a] end xs [] = xs end (_:xs) (_:ys) = end xs ys -- | Splits a lift in halves of equal (+-1) length. split2 :: [a] -&gt; ([a], [a]) split2 xs = (firstHalf, secondHalf) where h = halfsies xs firstHalf = zipWith const xs h secondHalf = end xs h
Don't do it. You should be very good at calculus before using computers to assist you. Pen and paper, man. Pen and paper.
I don't think there's anything specific to Haskell in that task. Have you tried implementing some form of [numerical integration](https://en.wikipedia.org/wiki/Numerical_integration)?
Yeah, I have a general idea of what I need to do, and I even kind of know how to do it, but... I just wish I could do it in a way where I don't feel like I've written 100 lines of epically unsafe there's-gotta-be-a-mistake-in-there-somewhere code. It's that last part that's eluding me.
Using Criterion: import Criterion.Main import qualified Data.List sortBenchs :: ([Int] -&gt; [Int]) -&gt; [Benchmark] sortBenchs f = [ bgroup "sorted" $ for $ \n -&gt; bench (show n) $ nf f $ [1..n] , bgroup "reversed" $ for $ \n -&gt; bench (show n) $ nf f $ [n,n-1..1] , bgroup "distributed" $ for $ \n -&gt; bench (show n) $ nf f $ take n $ iterate (\x -&gt; x + 17 `mod` n) 0 ] where for f = map f [1000, 10000, 100000] main = defaultMain [ bgroup "Data.List.sort" $ sortBenchs Data.List.sort , bgroup "mergesort" $ sortBenchs mergesort , bgroup "mergesort2" $ sortBenchs mergesort2 ] mergesort = -- see user link mergesort2 = -- see user link Sorry for the `for` mess, just threw the benchmarks together. Compiled with stack ghc --resolver=lts-4.1 --package criterion -- MergeBench.hs -O2 [Here's a graph taken from the generated report](https://imgur.com/VVPkEPj), raw values from CSV follow: Name Mean Data.List.sort/sorted/1000, 1.715683915049486e-5 Data.List.sort/sorted/10000, 2.8476402704303834e-4 Data.List.sort/sorted/100000, 1.0073484700288944e-2 Data.List.sort/reversed/1000, 1.4305127614509405e-5 Data.List.sort/reversed/10000, 1.7146582528524445e-4 Data.List.sort/reversed/100000, 4.89279198975855e-3 Data.List.sort/distributed/1000, 1.7100236526182502e-5 Data.List.sort/distributed/10000, 2.822673632194824e-4 Data.List.sort/distributed/100000,1.0030969744087227e-2 --------------------------------------------------------- mergesort/sorted/1000, 3.7215569435001687e-4 mergesort/sorted/10000, 9.486112126161645e-3 mergesort/sorted/100000, 0.19284197131889105 mergesort/reversed/1000, 3.720323222201021e-4 mergesort/reversed/10000, 9.407102409790072e-3 mergesort/reversed/100000, 0.1970382607138395 mergesort/distributed/1000, 3.737786995513053e-4 mergesort/distributed/10000, 9.547897878220432e-3 mergesort/distributed/100000, 0.19532647365434447 --------------------------------------------------------- mergesort2/sorted/1000, 1.2980977323983687e-4 mergesort2/sorted/10000, 5.512892844980416e-3 mergesort2/sorted/100000, 6.977763839230947e-2 mergesort2/reversed/1000, 1.2629531975778032e-4 mergesort2/reversed/10000, 5.1867552955825345e-3 mergesort2/reversed/100000, 6.832264903826299e-2 mergesort2/distributed/1000, 1.2899487226678512e-4 mergesort2/distributed/10000, 5.469016382278436e-3 mergesort2/distributed/100000, 6.916529992690638e-2 **Edit:** Now that I have a second look at your post, I think you weren't actually interested in a benchmark. Sorry. 
Are you able to give an approximate publication date at all? I'm studying Comp Sci at De Montfort University and just started Functional Programming with Haskell, your book is our set text and from what I've seen of a friends copy, I really like it. I haven't brought it yet so didn't know whether it would be worth me hanging on to purchase the second edition? Thanks 
Can I do that in several weeks? At the moment I have no time because of studies and tests.
`#composeconference` on IRC might be a nice alternative for those who can't be physically present :)
It's fine, just email us.
Promote any workshops you'd like to give too! :) http://www.composeconference.org/2016/workshops/
&gt; MalborgT You misspelled "Perl". $ cat &gt; tmp.pl BEGIN { if ($ARGV[0]) { *{"bah"} = sub (&amp;) { } } else { *{"bah"} = sub ($) { print $_[0]; } } } bah "humbug\n"; BEGIN { print "Parsing phase done.\n"; } ^D $ perl tmp.pl Parsing phase done. humbug $ perl tmp.pl 1 Type of arg 1 to main::bah must be block or sub {} (not constant item) at tmp.pl line 12, near ""humbug\n";" BEGIN not safe after errors--compilation aborted at tmp.pl line 16. The purpose of the second BEGIN block there is to further underscore what the error message already says, if you read it... and believe it... this error is occuring or not occuring during the _compile_ phase, depending on what argument you pass it. In the first case, the "Parsing phase done." message comes out before the humbug is printed out because that is emitted in the compile phase. (I figure that's close enough to a "syntax error" to make the point.)
Actually, I was just checking the time from ghci with ":set +s" setting. Criterion seems really interesting.
I'm amused that the majority of the [/r/programming thread](https://www.reddit.com/r/programming/comments/40u040/el_regs_parody_on_functional_programming/cyxa7sz) is a discussion on how to explain monads.
If you use stack, simple - use my patch ;) and vote for it being merged (https://github.com/bos/aeson/pull/326 ) Till then add this to your stack: packages: - location: git: https://github.com/tolysz/aeson.git commit: c1a7cad8ba8b354e43bc7fcd76b01f9ef64fc190 You could use the other one if you want to be able to distinguish `missing key` from `key with null` (079d26a5c77ed6689c726541c0962978deda1048) edit: rebased against latest commits
;) If you build against https://github.com/bos/aeson/pull/326 you will have a proper `Maybe` in `.:?` behaviour. 
A benchmark was exactly what I wanted. Thanks!
In what sense can sort work on an infinite list?
This works without a hitch in FreeBSD, which I found pleasantly surprising.
If I understand it right, sort does not work on infinite lists. But split2 function does.
I copied this and did a performance check with the rest of the other versions. This version (mergesort3) is very similar to mergesort1 https://www.dropbox.com/s/vrqa0nmnm2azcr0/Screenshot%202016-01-14%2016.40.15.png?dl=0 UPDATE: It turns out I made a mistake. mergesort3 was actually using the mergesort internally. I fixed it and it seems like this version does worst than mergesort1. Here is the new performance report: https://www.dropbox.com/s/odm5hrmv9193upo/Screenshot%202016-01-14%2016.58.16.png?dl=0 Here is the code for mergesort3 https://github.com/huseyinyilmaz/datastructures/blob/69489ef29ab70303d7e14f784d430926b25fe0ff/haskell/src/Sorting.hs#L69-L105
Awesome! You're the best.
Sweet! I would definitely donate if there were a fund for this, but I sadly can't make it out to Mountain View to help with this in person.
&gt; Storing session data in a database is a common antipattern. Not sure if that's a fair characterisation. I wish I'd been taught to do it that way first, instead of deploying my first Rails app to Heroku, scaling it to a second worker, then wondering why I was sometimes randomly logged out. Storing sessions in memory seems like an antipattern, albeit a useful one for someone who isn't going to run more than one instance of their app. Maybe instead of just saying 'usually a database' there should be a little bit more discussion about it, especially since this is a package all about sessions.
Yes! Please let us know if there's some way we can support this without actually being in Mountain View.
Is Template Haskell a hard requirement? Persistent is extremely nice to use, and [connecting to an existing database](https://www.schoolofhaskell.com/school/advanced-haskell/persistent-in-detail/existing-database) isn't that bad.
Hmm... I guess the best way would be to donate to Empoder, which is the group organizing this. There are links on their web site (www.empoder.org), but you could also email Marissa (address in the blog post), and she'd probably be quite happy to help you, too. I don't honestly know if they would be able to take a donation earmarked specifically for the program at Graham Middle School, because I don't know what their budget or funding look like so far. But if not, it could support similar programs elsewhere. Empoder is also planning to support some curriculum development using CodeWorld in the future.
Yikes, not getting into that discussion.
DTU as in the danish technical university? If so, I was unaware of any Haskell courses there. Which one is it?
I have a proposal. I think that if an infix operator's precedence is not defined, mixing it with other infix operators without parentheses (as in this case) should raise an error. Also operators should form a partial order rather than total and their precedence should be defined relative to other operators . precedence * precedes + precedence * precedes - -- ok a + b * c = a + (b * c) a - b * c = a - (b * c) -- error: - and + are incomparable a - b + c
As I mentioned to /u/radix, I imagine that Empoder would be happy to accept donations to help with activities like this. But I don't want to speak for them on the details of this club; I honestly don't know whether there are even any expenses remaining that aren't already covered. I *can* speak for the CodeWorld project, which is the tool used in the class, since it's my project. I'd definitely appreciate any help there. It's [open source](https://github.com/google/codeworld), and contributions are always great. There are a bunch of ideas for improvements on the [issue tracker](https://github.com/google/codeworld/issues), and I'm happy to help anyone get started. If you want something that would make a big difference, I've been trying to find time for nearly a year now to build an Apache Cordova-based wrapper to export students projects to Android or iOS apps. If that's something you are interested in, please get in touch with me about getting started. That would easily double students' interest in learning the system, since the majority of their interaction with technology is through mobile phones.
This quite an unfortunate situation. At this point, I'd expect a `aeson-0.11`release to satisfy the PVP contract if the semantic issues get resolved. Until then, I'll have to keep `aeson &lt; 0.10` around in my `.cabal` files :-| `aeson-0.10.0.0` has been out there far too long, so there may very well be packages already relying on those semantics by now. So we can't blacklist that release in order to reuse the `0.10.*` version range without risking confusion and breaking install-plans.
I have Aeson pegged at 0.9.0.1 for this reason, but yeah, our project has had similar issues with some other packages besides just Aeson. There are a fair number of packages on Hackage which are simply not maintained at all. My general policy has been just to fork and keep our own private versions which suit our purposes, but really Hackage needs to have an official policy for usurping ownership from dead projects. As for putting Aeson 0.10 in LTS, well... now we know why Debian is so patient!
It's our engeneering practise and we have the opportunity to choose a programming focused project. BTW i'm studying Geo Physics and space technology 
DTU people, holla. I did my MSc at Fotonik, bldg. 343
[removed]
This is not an issue of maturity of the ecosystem, if anything maintainers in more mature languages where libraries stay unchanged for years at a time (e.g. C++) are less responsive.
This package brings its own interpreter, which alleviates the problem of packages like `hsruby` (where ruby 1.9 just can't be embedded in GHC, so if that's what's installed on your computer you are out of luck).
The hslua package has been uploaded recently and regularly updated, it looks maintained to me. Frankly, Lua is trivial to bind to from C, it's been designed that way, and Haskell's FFI makes it trivial to use C, it's been designed that way. So using Lua from Haskell is like some kind of Hello World example -- it should work fine.
Maybe a good reason to move backpack forward?; or at least be able to say: `my-fancy-aeson as aeson-10.0.0.0` in `.cabal` ;)
I'm not encouraged by this: {-# LANGUAGE QuasiQuotes, TypeFamilies, GeneralizedNewtypeDeriving, TemplateHaskell, OverloadedStrings, GADTs, FlexibleContexts, ScopedTypeVariables #-} import Database.Persist import Database.Persist.Postgresql import Database.Persist.TH import Control.Monad.IO.Class (liftIO) import Data.Time (UTCTime) import Data.Text (Text) import Control.Monad.Logger share [mkPersist sqlSettings, mkMigrate "migrateAll"] [persistLowerCase| Link sql=hotlist count Int default=0 sqltype=int added UTCTime default=now() followed UTCTime Maybe checked UTCTime Maybe description Text url Text URL url deriving Show |] The entity syntax seems clean, but that feels like a lot of extensions for what seems like it should be trivial. Perhaps I simply can't have my cake and eat it too?
Well, it might not be all that hard, but the assignment is to write an interpreter for a PL that's rather simpler than Lua. In any case, as /u/bartavelle noted, HsLua is not merely a way of linking Haskell &amp; Lua, but does actually include a Lua interpreter.
Is there a good implementation on hackage?
Groundhog is the best library I've found so far. Here's a tutorial: https://www.schoolofhaskell.com/user/lykahb/groundhog Its TemplateHaskell requirements are minimal. I believe it is possible to completely avoid TemplateHaskell, but doing so is more verbose. Here's an example of using it without QuasiQuotes https://github.com/lykahb/groundhog/blob/master/examples/withoutQuasiQuotes.hs The fundamental issue as I see it as that there are two competing concerns for a library like this. First, you want to have data structures as close as possible to the ones that you would have written yourself if you weren't using a database. Second, you invariably need to be able to describe how those data structures relate to the DB schema. Groundhog's quasiquote system is a reasonably concise way of describing this relationship. And if you absolutely cannot tolerate quasiquotes it does provide a way to still do it. At the end of the day what is the TemplateHaskell doing? It's generating boilerplate code for you. If you REALLY REALLY are not willing to use TemplateHaskell AT ALL, you can still use groundhog. You just have to write by hand all the code that TemplateHaskell was writing for you. In practice most people that I've met don't want to do this.
Thanks.
FYI, if you want to interpret your Lua subset etc. we also have [language-lua](http://hackage.haskell.org/package/language-lua).
If your non-functional requirements allow a single point of failure and data loss, go right ahead and store sessions in memory. Me, I've never been in that lucky position. I have been lucky enough to use Redis though. It is astonishingly fast. In my thousands-of-requests per second application, its latency was never more than a couple of milliseconds. It is trivial to set up in AWS, heroku, kubernetes, cf or any other reasonable platform
That's a lot of nothing (pun intended). As much as I'd rather not use TemplateHaskell, given it seems to be the state of the art as far as MySQL is concerned, I'll give both libraries another shot. I think groundhog even has something that will generate data from a sql schema, so I'll have to poke around with that as well.
Has anyone actually asked to take over maintainership or get commit bit on the github project yet? I've taken over a project before where the maintainer wasn't responding on github and I did so by emailing them directly with my offer to take over maintenance. As long as you're not inflammatory or demanding, I find most OSS maintainers are happy to have more people onboard helping them out.
Alternatively you could duplicate postgresql-simple's ToRow/FromRow stuff on top of mysql-simple. postgresql-simple actually was written after mysql-simple. It was inspired directly by mysql-simple, but the author didn't stop at feature parity. He went on and added quite a bit to it. So I think it's totally feasible to make your own fork of mysql-simple and then "backport" posgresql-simple's new features.
I was happy until I saw `unsafeInterleaveST`. Or even `ST`, for that matter.
I don't think so. But now people are fed up enough that somebody might actually do it. Although, the maintainers don't respond to normal issues, what makes you think they'd respond to one asking to take over the project?
As far as I can tell, Bryan O'Sullivan (maintainer of aeson, co-author of Real World Haskell) is currently a visiting lecturer of some kind at Stanford - https://www.linkedin.com/in/bryanosullivan - in addition to his regular Facebook work. 
Agreed. IMO width limiting is easier on the eyes and just looks better in general. 
Here: http://imgur.com/l1oN4dy
Now I could be wrong, but this is how it would (currently) works in my head: For your ByteString example, you would have a MonoApplicative of ByteString and a MonoApplicative of (ByteString -&gt; ByteString). Then you simply use &lt;*&gt;: (&lt;*&gt;) :: MonoApplicative (ByteString -&gt; ByteString) -&gt; MonoApplicative ByteString -&gt; MonoApplicative ByteString 
If you don't want an ORM-like but are happy just getting tuples or extensible records being the result of complex join query, ou can have a look at [sql-fragment](https://github.com/maxigit/sql-fragment) and its companion [sql-fragment-mysql-simple](https://github.com/maxigit/sql-fragment-mysql-simple). It's only a beta and to get the doc you need to download the package and generate the haddock, but it generates automatically field fragments from the database (no TH, just code generation), auto-join (via join-graphs) , HList record, lens (still experimental), use of units etc ... After set up your code will look like roleQuery = roleId !&amp;! roleCompanyId !&amp;! roleName main = do conn &lt;- connection tuples &lt;- selectTuples q let roles = map (uncurry Role) tuples where q = roles_query 
doesn't non-associative infix already work? &gt;&gt;&gt; infix (+) 4 &gt;&gt;&gt; 1 + 2 + 3 -- some error, I'm on mobile 
I like this, and I wish the docs on hackage looked more like this.
&gt; Many programs limit the source code width to 80 despite the fact that modern monitors can display more characters per line. That's a good point. I never thought of it that way. I'm a strong advocate for the 80 columns rule. I'm convinced. +1
The vast majority of websites do not carry the majority of web traffic. Shared hosting isn't necessarily single-point-of-failure. But let's focus on the bit where we agree: most sites don't have or need server-side session. For those that do, I think this package is a great solution.
This looks handy, but I don’t think I can use it because I need separate tokenisation and parsing passes in my current compiler project. There, I handle indentation-sensitive parsing quite naïvely: * Tokenise the input, giving each token a source span and an indent level equal to the indentation of the first token in the line. * Desugar terms of the form `: x ys` into `{ x ys }` by parsing `ys` as a series of “items” whose indentation is greater than or equal to the start of `x`. An item is either a token, or a series of tokens between bracket tokens (`()[]{}`). The start of `x` must also be strictly greater than the indentation of `:`. This has the advantage of being easy to understand—`:` is fructose for `{}` and there is no concept of indent levels—while supporting the two most common indentation styles that I see in Haskell code: if (x &lt; y): foo bar else: baz quux if (x &lt; y): foo bar else: baz quux 
Your comment appears to be in support of the view that publishing some open-source library also constitutes an implicit agreement to respond to issues and fix bugs quickly. I suppose you're welcome to hold that opinion if you want to, but I (and, I'm sure, many other free software maintainers) strongly dislike it. I'd suggest reconsidering it, particularly if you want free software maintainers to keep working on the things they work on.
Excellent.
FYI, bos responded here in a [nested response](https://www.reddit.com/r/haskell/comments/4101ad/what_to_do_with_aeson010/cyzhlbc). Perhaps Github is not the proper channel for alerting aeson maintainers to problems. [edit]: To be clear, I was suggesting this as a hypothetical, not as a mamsy "this is what you should have done" statement. :P
Sorry for taking so long to get back to you :) I wanted to answer the question "properly" by conveying some of the motivation and thought-process instead of just a laundry-list of features, but that was hard, and eventually it got buried under seventy-eight layers of ~~sedimentation~~ tabs. I did eventually manage to reorganize my notes and collect something of a [summary](https://github.com/glaebhoerl/ducks/blob/master/notes/summary.txt). Ironically considering that this itself was initially inspired as a smaller project before I try anything with actual dependent or substructural types, I eventually decided this was too much to chew off at once, with lots of open theoretical and research questions, and I should instead try to work my way up from simpler and more well-established systems first... Edit: Hmm and it seems I forgot that I had separated out all the motivational bits into a [separate file](https://github.com/glaebhoerl/ducks/blob/master/notes/ideals.txt) :)
Ship it!
That looks much better. I think the confusing part is that the table sits above the horizontal border in the first shot. Maybe it should sit a bit lower?
Absolutely stellar write-up. That is the clearest demonstration of the interplay between laziness and amortization that I have ever seen. Great job, and thank you.
&gt; a note outside of github
Then why list github as the bug reporting mechanism ?
&gt; entitled wankers like you from the internet While it is expected from an open source maintainer to have a life, I don't think you can expect people not to be annoyed by bugs! Also it is not alright to insult somebody like that just because he expressed his frustration.
Are there any nifty browser extensions that would allow someone to use this theme? Or is this going to require a change to Hackage itself?
Just a dry "no"? I mean, what if the two sum types had the same cardinality ..?
I was just citing his response but if I were to guess: it wasn't his intent to ignore GitHub but more important things came along so that he forgot to check for a while. The email would be to alert him that GitHub is languishing, not as the endorsed big reporting mechanism. I don't think what I'm saying is implausible or particularly hard to guess, either.
There is [Stylish](https://userstyles.org). It works with most browsers but one would have to submit the CSS there.
To convert the types as they're written in the OP? Without template Haskell surrounding it to build some form of coercible sum representation? Pretty sure it's just no. You'd need something like a custom representation of what it means to be a sum type that you can use to internally validate a coercion and then swap a phantom type. The types in the OP are not phantom. They are genuinely distinct types. The second *is* representationally a superset of the first though, so you can force the matter with `unsafeCoerce`.
Well, here's the nightmare scenario: http://imgur.com/yn4e8HG I have no idea how to fix this with pure CSS.
Perhaps you could place it outside the main column of text, on the blank space. Or as a column width box, above everything.
Criterion is also sharing a similar fate, and probably unlike other people who complain here, I actually sent an email to you on January 9th and asked you for taking over the maintainership of the project, but I haven't heard back yet. I guess you have a life outside of checking your inbox?
here is an example: [PlusAssoc/PlusComm from AndrasKovacs](https://www.reddit.com/r/haskell/comments/3wfzqk/kind_equalities_are_now_in_ghc_head/cxweqsw)
`unsafeCoerce` works for my example? Is there any guarantee that the variant tags are encoded in the order they're defined? I'd be a bit afraid to use it here... If that's the case, is there any reason not to add a (directed) `coercible` instance for sub sums?
The mono-traversable documentation says "All of the laws for the polymorphic typeclasses apply to their monomorphic cousins". I don't think your example would satisfy fmap f x = pure f &lt;*&gt; x, as f should be Word8 -&gt; Word8 instead of ByteString -&gt; ByteString.
Awesome. Love. Please do! Small point: please get rid of the bold cabal property names. When there's no powerful reason for bold, it should be avoided from what I know of typesetting principles. Itallics are better, or slightly small font also works well some times. I mean the bold property names in the top-right of this screenie: http://imgur.com/l1oN4dy
nice, I was working through TAPL and was wondering the same thing! 
I have no idea if this is at all possible possible, but have you checked if you can use Shake to build the `stack.yaml` for people automatically? I don't even know if that's a feature anything like it's supposed to have, but it would be amazing if it did, and I've learned not to be surprised when Haskell tools can do amazing things I would have never expected.
This is almost too good to be true. I love Haskell, I love teaching, I care about diversity and empowering minorities, and I live in Mountain View. Thank you! I contacted the organizer. Looks like a great opportunity to put my efforts where my mouth is.
Oh, I didn't know about TOML, it seems very nice. Thanks a lot for pointing it out and for the library.
Thanks for chiming in. Good reasons indeed; I'll reconsider :) Last points in my defence: * Shouldn't the build service show a user against which snapshots the library should work out-of-the-box? * Somehow shipping the `stack.yaml` give the impression that there is "only one" snapshot that is blessed by the project. * Chances are very slim that the user has the same snapshot laying around as me -- would not that mean a lot of recompiling for him? Whereas with not shipping `stack.yaml` the best match snapshot will be pick considering what is locally available -- right?
The idea was that there would be no additional manual steps involved for omitting the `stack.yaml` file. That you could untether it from a particular snapshot with no addition work for your users. If this isn't what you're looking for, then I'm sorry, just ignore me.
&gt; That you could untether it from a particular snapshot with no addition work for your users. Except for also having Shake around, you mean?
Agreed. `Progress` is very nifty!
Possible newbie questions: - does this approach compose ok? If shipping stack.yaml files became common (say, 50% of libraries did it), what fraction of those have some of their own dependencies pinned to something other than the latest of what's on stackage? Would I be likely to have to tweak multiple stack.yamls to resolve the conflicts? - It seems like widely adopted libraries try to follow a three-release build policy, manually checking their packages against old versions of dependencies. This is hard work for library authors but it seems like a necessity, because different people migrate to the newest versions at different times. With stack.yaml files in the distributions, do you have a feeling about the incentives for authors to keep doing that historical version checking?
Well that's succinct. I think I passed over sql-fragment because it wasn't on Hackage and doesn't seem to have been touched in 6 months. 
&gt; does this approach compose ok? If shipping stack.yaml files became common (say, 50% of libraries did it), what fraction of those have some of their own dependencies pinned to something other than the latest of what's on stackage? Would I be likely to have to tweak multiple stack.yamls to resolve the conflicts? You only have one stack.yaml at a time. In other words, if you are using this library as a dependency of your project, then its stack.yaml file doesn't matter. Now, this does create a little issue when you have a git submodule for this dependency, such as a `htoml/` submodule. When your current directory is a subdirectory of the submodule, stack commands will use its local stack.yaml rather than your project's stack.yaml (similarly to how git commands will work with the submodule, rather than the outer repo). I've opened an issue about this, [here](https://github.com/commercialhaskell/stack/issues/1662). &gt; It seems like widely adopted libraries try to follow a three-release build policy, manually checking their packages against old versions of dependencies. This is hard work for library authors but it seems like a necessity, because different people migrate to the newest versions at different times. With stack.yaml files in the distributions, do you have a feeling about the incentives for authors to keep doing that historical version checking? I agree that this is hard work, and current tooling doesn't support it very well. If package authors only test against their environment, then its very easy for old environments to break. The good news is that we [have plans to directly support this](https://github.com/commercialhaskell/stack/issues/1568). Not only will this allow you to automatically determine version constraints, but test them too!
Hm, that's reason enough to expect someone to notice, I would say!
Both the examples of Rust and Qt use the space on the side to display a table of contents. I'd really like to see something like that, so that the space, when available, isn't just wasted. [edit] Same for Swift docs.
 type T1 = T Void makes more sense to me than type T1 = forall a. T a do they end up being equivalent? 
I want it to be narrower, and I wont make my browser window narrower. Leave it please!
With a stack.yaml, anyone can **build your project directly** No guess, no assumption that solver will do this or that, or anything : it just build. that's not just a time saver in that it works, that's also and perhaps more importantly a guarantee before even trying to use your project, that it **will** work ! As mentioned by mgsloan, if you have special needs, you can customize, for instance point to another stack file, on the command line so, AFAICT, there is 0 upside for not having a stack.yaml 
I think /u/existsforall assumed that you _are_ using Stack yourself. &gt; Also I guess an incorrect stack.yaml is even worse than no stack.yaml file at all? I guess we can all safely agree on that :) 
Yes, "The Elements of Typographic Style" discourages the usage of bold type, but this is mainly in the context of typesetting books. For magazines/web, ads and more generally in other areas of graphic design bold is perfectly fine, even indispensable.
No, it's always needed or else the phone will assume it's a pre-mobile-era site and display it as if it had a wide screen (usually zoomed out to the point where nothing can be read). There are also many other things that'd require patching Haddock to implement properly, like the module list (I want to push em dashes between the module names and short descriptions instead of putting module descriptions on separate lines, but CSS k3wl, CSS c3n7 m4tch un-t4gged t3xt), and I also need some layout changes to make it possible to create a side bar.
&gt; I like it but the Modules section as shown only makes sense for projects with a very small number of modules. Fixed: http://lamefun.github.io/ (I wanted to do this to begin with, but CSS k3wl, so I had to patch Haddock). 
I will do that, that would be fun :)
It's more that bold communicates "important", while a list of properties does not have this importance. The fact that they, and their values, are lined out already communicates their function. Thus I'm of the opinion that bold makes them stand out (or shout) too much. Nothing big, probably just my opinion. :) Feel free to ignore.
I found an excellent answer to this question [on stackoverflow](http://stackoverflow.com/questions/24484348/what-does-this-list-permutations-implementation-in-haskell-exactly-do). Apparently the implementation's complexity is to preserve maximal laziness. I think it will be a while before I can get my head around that way of thinking :)
Well, I have to admit that it's still experimental and I haven't had much time to work on it recently. It was original more a proof of concept about how to make type-safe SQL combinator and doing auto-join by defining one (or more) global join graph. However type inference seems trickier that I imagined (I might need injective type families) and designing join-graphs is far less easy than it thought. Having said that, it works and I'm happy to answer any question ? Also pull request are welcome.
[removed]
&gt; do they end up being equivalent? Yes, since one definition of `Void` is: newtype Void = Void { magic :: forall a. a }
Chris Okasaki didn't have them, which makes me believe it's possible. 
"I know some of those words." :(
&gt; The TypeInType extension removed any distinction between types of kind * and types of other kinds. No, Type-in-Type makes it so * has the kind \*.
Also, if the editor still shows the package as missing after adding to the cabal file, try running stack clean and restarting ghc-mod
AFAIK, `Type` becomes a synonym of `*`, so instead of rather cryptic `*-&gt;*` we can write a self explanatory `Type -&gt; Type`. Also, the kind of `Type` is also `Type`, hence `-XTypeInType`.
ivy league, it seems they predominantly hire ivy leagues students. Searching linkedin I see that most are from MIT, Harvard, UPenn, CMU, Cambridge, and Cornell. Being in the financial world titles mean a lot. Also, people like to hire from the same school they come from.
Can you explain how they differ? It's not immediately clear to me. 
Is there any difference if you run `stack setup` in a terminal rather than through spacemacs? That detail seems like a red herring. You shouldn't need the cabal executable in order for `stack setup` to work. This might be worth filing a bug report with stack.
Thank you for pointing this out to me. Hatlab looks like it will be very useful.
One says that forall a you can use the T for that a, at which time all 'a's in the T will take on the same type. The other says that T holds value each of which can be used as any a you want. This is perhaps better illustrated by changing the example, let's replace T with data Pair a = Pair a a and the unbounded quantification with something more narrow like `Either Int Bool` There is a difference between `Either (Pair Int) (Pair Bool)` and `Pair (Either Int Bool)`. The latter admits more cases: `Pair (Left 1) (Right True)` The difference is more subtle with quantification involved. [] :: forall a. [a] says [] is a list where everything in it has the same type [forall a. a] says that you have a list where everything in it can each pick their own type. The latter requires ImpredicativeTypes in Haskell so we usually replace it with [Void] using the newtype to avoid the rather broken ImpredicativeTypes extension.
Yes, you're right. My initial sentence was too strongly worded. Thanks for the correction!
what do we do about the `Type :: Type` problem?
&gt; Though this causes inconsistency in other dependently-typed languages, it does not in Haskell, essentially because equality proofs are written in a different sub-language than ordinary terms. See ​[our paper](http://www.seas.upenn.edu/~sweirich/papers/fckinds.pdf) for more details. From: https://ghc.haskell.org/trac/ghc/wiki/DependentHaskell/Phase1#Kindsandtypesarethesame
One of the reasons why awk was made is to speed up string based stuff. Sed is also very fast. This will be insanely slow. Try counting something that matches a pattern. Slow, slow, slow. Even the Data.ByteString library is slower in counting lines in a file, wc -l does it much much faster, and seems like a simple thing?
That sounds totally sane (perhaps someone else will educate us both on the contrary), but aside from performance, this is pretty neat! I already have ghci open half the time for little things in my terminal. It gives me nice haskell learning tangents during work. Hwk sounds like a nice little support to my silly hacking habits. : P
Oh so if I make a document that's specifically 720 pixels wide (the width of my phone) without that tag, my phone will render it as a tiny rectangle in the upper-left corner of my screen?
Of course. But it would be really nice to see something as performant on the Haskell side. wc, awk and similar do use tricks like these: https://graphics.stanford.edu/~seander/bithacks.html to improve their performance, and something like that could easily be added in performant ByteString (I believe search for chars and similar is done in cbits), so it wouldn't be hard. But doing splitOn on list of chars isn't going to convince, even me the Haskell lover to use that :D
I think you missed the point of this tool, as stated by the author: &gt; hwk tries to demonstrate how a modern Haskell based stream manipulation tool could look like.
Yes, the demonstration is nice, but it's not exactly unknown that Haskell is extremely good at piping due to its lovely laziness.
Nice! There's a lot I agree with, although I am partial to dependent types :) I think it's almost inconceivable that we won't be programming in dependent types some day, since it's such a simple idea that subsumes many of the points on your list.
you can dump explicit dependencies into cabal.config with cabal freeze 
gosh if only there were some sort of [policy](https://wiki.haskell.org/Package_versioning_policy) that had thought through these issues and provided effective answers. you're right that multiple solutions may exist to a version set. but the point of the pvp is that if you do things right _all those solutions will work_. the why question is easy -- many people despite your protestations to the contrary -- have never needed it, because things -- despite your incredulity -- actually work pretty well without it in many circumstances.
So, what's your secret? Do you know the OCaML compiler inside out? ;)
Yes that's true, there's lots of work still to be done about dependent types. People are just beginning to get a handle on equality in a dependent type system, and there are a lot of areas where the work has barely started. But here's what I think will happen. Lots of people work on modules, records, GADTs, and more. I fear that much of that work will be moot once dependent types win.
&gt; Hawk is a more mature tool. Well, it's certainly older :) It still doesn't have all the features we had originally planned though, because I'm dividing my time between it and so many other Haskell projects. Would you like to join the project? We'd make more progress joining our efforts than working on competing tools!
How does one get involved in that sort of thing?
Especially on the tech side, there were people from a bunch of random schools. I got in from Berkeley (a public school!) and wasn't the only one, and there were a bunch of other schools represented including UCSD, Harvey Mudd, Cooper Union, some school in Spain I had never heard of... I'm forgetting the rest, but there was certainly some diversity among schools represented. Still *somewhat* weighed towards the most selective East Coast schools, but to a more limited extent than people think. And much of it is that they only *recruit* at a handful of schools, and get less applicants from other institutions. It's no surprise that most of their interns come from the schools where they actively advertise, sponsor clubs and conduct on-campus interviews as opposed to schools that they never visit and are far away. I know a bunch of people at Berkeley who would have been very strong candidates, and JSC wasn't even on their radar—many hadn't even heard of it.
&gt; The good news is that we have plans to directly support this. Not only will this allow you to automatically determine version constraints, but test them too! That sounds really, really cool. Thanks for the clear explanation!
Hm, same here. I had to select "other" or something. Maybe they're only looking for target schools.
&gt; want to do is retro engineer for 1 day what were the particular combination of a user's cabal's state and published hackage state at some unknown point in time I'm not sure if you understand how the PVP works: I make the effort to specify accurate version bounds so you (and everyone else!) don't have to guess which versions my package is compatible with! &gt; because some author did not feel like using stack... It's more like "because some author did not feel to set proper version bounds" As it was pointed out [here](https://www.reddit.com/r/haskell/comments/415vne/to_ship_stackyaml_or_not_to/cz1ayw9), a `stack.yaml` is far less useful for library packages. I really don't see the point of having a dozen libraries each with their own individual version pinned down `stack.yaml`, when I actually want to combine those libraries with each other. Is there a tool that let's you recursively merge all those `stack.yaml` files into a consistent(!) project-wide `stack.yaml` file? Or would I rather have to trial and error "for 1 day" trying to resolve all conflicts manually?
The "template store" is written to once and never modified so it's actually not used in an unsafe manner. It is however going to be updated when the next version of servant comes out, as it lets you "register" arbitrary things you need in some kind of `Config` store -- and this little hack is going to go away. Also, `ede` lets you write actual HTML syntax and then adds just a couple of "special commands" on top -- is the latter the one that's annoying to you? Anyway, if `servant-ede` doesn't work for you, you can definitely write something similar for your favorite templating library. Feel free to open an issue on servant's github about it if you need some help =)
&gt; you're right that multiple solutions may exist to a version set. but the point of the pvp is that if you do things right all those solutions will work. &gt; That's how I understood your point too. which I disagree with (not by belief but from time wasted at it) My point is that the user of a library should not be concerned if it is indeed the case or not. The author of a library should provide a way to make it work with *no assumptions whatsoever*, especiallly none that it can't possibly comply with, for the reason mentioned (path dependence, looking in the future etc..) I am not advocating to not use PVP, it is useful to navigate through the version maze and provide flexibility for avoiding to install unnecessary package. They are complimentary things which deal with two aspects of a same thing : navigating the versions, finding a solution (author job). using a library with no assumption (user requirement, who probably has 10 other things to worry about as he himself is building something)
There: http://lamefun.github.io/Pipes.html I hope this addresses your concerns.
Hmm... Does parsing involve semantic information? How would the parser be able to tell that the `+` in the lambda is locally bound?
&gt; PVP is definitely useful. Agreed. &gt; locking things down is also useful for end users Agreed. `cabal freeze` has been able to do this for quite some time. I would say that this statement actually carries an implicit argument against shipping stack.yaml because it really is unique to the end user and not something that should be applied across the board to all users. Maintainers of packages on hackage should be more concerned about the intersection of all the end user situations...aka, the range of versions that work. &gt; if we don't have a global beat, we don't see the problems This is where I don't agree. There's nothing that inherently dictates that problems will not be seen without a global curated collection. We can easily build systems that notify maintainers when new versions of their dependencies are released. The fact that stackage is doing this right now for some people is simply the way history happened to have evolved. As the community becomes larger and larger it will become more and more difficult to synchronize everyone to a "collective clock". &gt; thinking of car/plane, I guess they have the exact same dependencies problems The difference with this analogy is that cars and planes are much more holistically designed to serve a single purpose. Hackage as a whole is clearly not.
A month ago I asked a similar question on if we can create [a subset of a sum type](https://www.reddit.com/r/haskell/comments/3u03ce/define_a_subset_of_constructors_of_an_adt_as_a/), namely only allowing a subset of the constructors to be used. This looks pretty handy to me: when you are writing a compiler and doing desugaring, you don’t want to see useless exhaustivity warning. /u/ranjitjhala ’s [LiquidHaskell](https://ucsd-progsys.github.io/liquidhaskell-tutorial/) can surely do that—seeing the example in my question—but since it relies on using one type, I don’t know if this fits your situation. Anyway, after that question I started to wonder if we can modify the type system to directly support this. It seems that one just need to modify the typing rule a little: data S1 = A | B | C data S2 = S1 except C -- some fancy way to declare the relationship -- in real world this could be a little complicated convert :: S1 -&gt; S2 convert A = A convert B = B convert C = B apply :: (S1 -&gt; a) -&gt; S2 -&gt; a apply f x = f x -- if a :: S2, a :: S1 All we need to add is the rule that (t1 || t2) is more polymorphic than either t1 or t2. However, I am not quite familiar with GHC’s type system, so I am not sure if the change needed is as trivial as it looks like. For example, what’s the type of that constructor if we expose it to another module that doesn’t enable this extension. Besides, I am not sure if this is a feature that matters enough.
Have you looked at hstringtemplate?
&gt; it is precisely entitled wankers like you It's probably part of my entitled mindset that expected more professionalism.
You can't mix infix operators of the same level of precedence but different associativity, so yes it involves some. As far as locally bound, it can tell because it is parsing a lambda at the time and it's included a (+) token from the arguments in the lambda. It has to know this anyway because of the fixity stuff. Try typing `a !! b . c` in GHCi, you get a parsing error.
Is the dependently typed approach somehow related to the "monoid with holes" approach implemented in the already existing [formatting](http://hackage.haskell.org/package/formatting) package? They both seem to construct formatting functions in a type-safe manner.
&gt; Why does their interleave function take a function as an argument? The function here is being used as a [difference list](http://h2.jaguarpaw.co.uk/posts/demystifying-dlist/) where `id` is representing the empty list and `(.)` represents appending and the functions are converted to a real list by apply the function to `[]`. More generally, apply a function to `[a,b,c]` returns the list represented by the function appended by `[a,b,c]`. 
That's part of the answer, but there's a lot more to it. See this fascinating [email thread](https://mail.haskell.org/pipermail/libraries/2007-December/008788.html) where Twan van Laarhoven actually developed the algorithm. Just as a taste, here is an excerpt from my summary email at the end of the thread: &gt; ...permutations3 is essentially &gt; Knuth's Algorithm P. As far as Knuth knows, that &gt; algorithm was first published by English church bell &gt; ringers in the 1600's... I agree with Twan that permutations8 &gt; [the one actually used in the end] must be &gt; close to optimal. EDIT: Ah Twan actually wrote it all up, and more, in the SO thread. :) Great!
`formatting` takes a GADT in lieu of a format string, and uses the GADT to specify input types. Idris takes a regular string as input, and computes the types directly from it.
[removed]
It doesn't use GADTs. In fact I just submitted this: https://github.com/chrisdone/formatting/pull/20 The one use of the GADT extension is to allow access to the `~` type equality operator, not GADTs themselves. [EDIT: I think it's important for people to realise that the formatting package doesn't use any type trickery. It's all just basically the Cont monad]
&gt; Idris takes a regular string as input, and computes the types directly from it. So in Idris a program could read a "format string" from a file and, once it has been read, ask the user for each of the values to be printed and then print them in a type-safe manner. In current Haskell we can't do that, because the "format string" must be known at compile time. Is that correct?
Yeah you need a monad, but you don't have to use IO. You could use Rand (or RandT). "if all you need is a random number, you don't need to hit it with a sledgehammer" - Jiri Lebl
Relevant [xkcd](https://xkcd.com/221/).
That's interesting! How do your web devs know what variables are in scope, and what types they are?
I don't quite follow, I think `printf` should have that property too. Similarly, I can't think of cases where the sides would both type check and be different. 
Did you by any chance start looking into the performance problems? Deech and I have separately been struggling a bit with performance of type level computation, and any clues into improving this would help.
Same, here are mine: https://github.com/Prillan/adventofcode-solutions
I would implement `printf` so that `printf "%"` is well-typed and equals `"%"`, in order to satisfy your mentioned property. But anyway, I don't think this is the crux of the matter. With dependent types, we usually use an intermediate `Format` type that's analogous (or can be made so) to `formatting`'s `Format`, so one can choose to work with either representations, while in Haskell there's no such choice. The most important thing here IMO is that any sort of non-trivial dynamic computation on formatters gets extremely hard or impossible without dependent types, so in Haskell-land we're effectively restricted to using formatters in a C-printf-like static manner. 
I don't think there's inherent limitation with respect to extendibility in the dependent solution. Format strings are just shorthands that compile into corresponding `Format` values that work similarly as `formatting`'s `Format`, and we can also use type classes the exact same way. I agree though that inspectability could be worse, in the sense that formatting-relevant parts inside strings are not easily searchable and not obvious from source alone. But searching for particular formatters shouln't be too hard. If one uses type classes, then it would make sense to parametrize classes by format characters or strings, and then one can hit `:i` to inspect formatter instances along with the input types, or get the type of a format string with `:t` and then search by type.
I have some basic experience with type families, but I did not know that associated data types are injective while associated type synonyms are not. I can see in the `monad-control` code that they changed between the two, but I'm not quite able to follow the types through all the code. Maybe you're right, that missing 'FunDeps for type synonym families' feature in GHC 8 might be why the type inference is less successful here. These GHC features are still fairly esoteric to me. The Wiki page you linked is very readable, though. Thanks!
what's an infinite sum type? like an user defined Int? 
I would want my property to include that they have the *same* type when they're both well typed.
There's always the `unsafePerformIO` "escape hatch", mostly intended for writing FFI functions (since everything from C is considered to be in `IO`, so you need `unsafePerformIO` for pure wrappers). So you could just do `unsafePerformIO randomIO`, and that's a function returning a random number. The compiler might screw you though, ff you just put it in a top-level declaration, like this: foo :: Int foo = unsafePerformIO randomIO it might turn out that the function always returns the same number, as it gets evaluated once, and then just reuses the same value.
I don't understand, why not? Having a producer of randomness that potentially changes every time you call it is one possible definition of effect ..
This would be amazing!
You can write a function that returns the same random number every time.
Integer is actually infinite, but that wasn't what I meant. Existential types act as wrappers to a potentially infinite number of types: data SomeType = forall a. SomeType a Because there are infinitely many types, `SomeType` can contain any one of an infinite amount of types. This is useful if you add class constraints, since type classes follow the open-world assumption (i.e. in principle, any class might have an infinite number of instances): data SomeException = forall a. Exception a =&gt; SomeException a Exceptions are the #1 use case for me, coincidentally. Instead of having some data MyException = HTTPException | Log4JException | BufferOverflowException in my programs, I just declare each exception as its own data type and wrap them into `SomeException`. It thereby becomes trivial to declare new types of exceptions, while retaining the ability to throw and catch them in the same way as any other exception.
that's not a function, that's a value. and it also doesn't behave meaningfully in any way in Haskell... it's not usable at all for any sort of work, heh. the semantics are not defined and your code will behave unexpectedly, and also give different results depending on compiler optimization, etc., it's basically unusable in any code, and it won't behave like the random number generator you'd want in almost every situation. :o also, unsafePerformIO is definitely not an "escape hatch" :O
SomeException as an infinite sum type! very cool. how does it differ from finite sums? since it's infinite, you can't exhaustively pattern match (without a wildcard), even if you had syntactic support like for Integer literals. Strings can work as an adhoc infinite sum type. (just thinking out loud) 
You are welcome to thread the output from [next](https://hackage.haskell.org/package/random-1.1/docs/System-Random.html#v:next) through your code in a completely "conventional" manner. The monadic interface is just syntactically helpful, not necessary. Well, it's also helpful for correctness since if you manually thread it, it would be easy to accidentally re-use a generator without noticing, trashing your "random" behavior. It's _really_ helpful. But it can be done in a pure way. You only need to obtain a random number from IO once, and the rest can be pure from there.
As a side note, if the latest and greatest version of your package didn't make it into lts-4, or if you're not on stackage yet but want to see your stuff in the next lts, now's your 1 week window to squeeze it in for lts-5.
compile time checked printf is trivial with Template Haskell and was infact given as one of the examples of what can be done in TH here: http://research.microsoft.com/en-us/um/people/simonpj/papers/meta-haskell/meta-haskell.pdf
He means explicit generator-passing, like this: randomInt :: Gen -&gt; (Int, Gen)
Why must it be on top of servant and postgresql? Anyways, I use mustache: https://hackage.haskell.org/package/mustache
There is actually another option - drawing from an indefinite random steam. I think this should be manageable with just Applicative.
Try here: http://downloads.haskell.org/~ghc/8.0.1-rc1/
Jane Street uses Haskell and OCaml IIRC
This is great! I don't care much about which colors or fonts we end up with, or whether or not the borders are rounded, but I love that the width of the text limits each line to a few words. That makes it much easier to read for me.
I think you (Stackage maintainers) have found a very sensible solution to this difficult problem; and [issue #1155](https://github.com/fpco/stackage/issues/1155) provides a super clear instruction on how to resolve the matter for those on the critical path. Well done!
In theory: We publish Hamlet API documentation for each version of our app, and a guide for the web developers for porting from one version to the next. In reality: The backend comes with a simple base skin, which provides example code for the available variables and how to use them. The base skin is not documented as well as it should be, but the backend devs are available for questions. In practice there are actually very few questions; Hamlet code is surprisingly self-documenting and intuitive to web developers. And many of the Hamlet API changes are driven by feature requests from the web dev team. In the future: Here is a plan that can get us close to the ideal world of "in theory": We do a small refactoring of our handlers so that every template is instantiated in its own top-level function which does only that, and which takes a single ADT as its parameter. The `RecordWildCards` extension brings the fields of the ADT into scope in the template. The declaration of the ADT with its haddock comments for each field, together with the Hamlet code examples in the base skin, serves as excellent API documentation and porting guide. And the type system guarantees the correctness of the API. If you are starting a new multi-team Yesod project, or you hope that your new project will grow to become multi-team, I recommend starting out this way to begin with.
But this approach only works for PRNGs, which are inevitably periodic. I guess I was thinking about something that continuously draws from some external sources of randomness such as thermal noise ..
Yes, they will be. I'm about to run a nightly build and I'll try to re-enable as many of these as I can.
It is also worth noting that the materialfor the course should start appearing any day now. I reccomend you study it.
It's not automatic, but I'll do this right now, and they'll build with nightly-2016-01-18. If there are any packages still missing from that nightly, then do send a PR. [edit] 18th not 19th
For sure. I was going to consult the other curators on when/where/how to "officially" publicize this decision; this thread is just something I whipped up as a first step to getting the news out there.
&gt; Also, downgrading a package is very unexpected. I guess there is little chance for a coordinated and less bumpy way by including a 0.11 aeson that reverts the unwanted changes from 0.10? It is indeed unexpected. This is, however, an exceptional situation. I'd love to see aeson-0.11 released with bugfixes for everything, but then upgrading the whole ecosystem to use it will take time. We don't want to wait that long; lts-4 ships with a "broken" aeson so we are remedying the situation as quickly as possible.
But mustache looks good.
You can also try the v2.16 branch which should build with 7.10 and not have diverged too much from master.
The Book of Hasochism adds a new chapter.
Looks awesome. Small layout issue here (http://lamefun.github.io/Pipes-Prelude.html#g:4): http://puu.sh/mA84a/62815d6cda.png The "Source" link is pushed downwards. On Chrome 46, Windows 7. EDIT: Use [this tool](https://dev.windows.com/en-us/microsoft-edge/tools/screenshots/) to see how it looks on a multitude of browsers.
&gt; doesn't use any type trickery &gt; just basically the Cont monad ...I clearly have some reading to do.
&gt; The "Source" link is pushed downwards. On Chrome 46, Windows 7. It always did (try it on official Hackage with a narrow browser window), it's just that the layout was wide enough for it not to happen. It's because CSS pre flexbox had no proper horizontal layout. I'll fix it in my Haddock patch. CSS is stupid, W3C should never have existed!
One thing high schoolers have going for them is a ton of work experience, if they landed on their feet. It is hard to ignore an applicant with six years of production coding, especially if they have a high aptitude.
You don't have to use the glibc if you want to build a static binary. Look at alpine-linux, it is a distribution that use a libc (musl) that is statically linkable. There is also some docker image that already package ghc in this distibution https://github.com/mitchty/alpine-linux-ghc-bootstrap and https://github.com/mitchty/alpine-ghc You will endup with a fully static and distributable binary that doesn't use the glibc 
Oh yeah it would be nice to add it.
Yes, I was just discussing the monad case. System.Random also has `randoms` which returns an infinite list. I'm not sure if Applicative particularly buys you anything over monad here, because from a software engineering perspective you still have the same outcome; if you unpack out of the applicative you'll have to store the context and you risk making a human error and reusing it incorrectly if you do, if you don't unpack out of the applicative you're nearly using it as a monadic interface anyhow. (But if there's an argument that it does make a difference I'm listening... I really do mean I'm not sure.)
&gt; but I don't like the new spacing No, it's perfect, for PEOPLE. &gt; for documentation compactness is actually a good thing (since you have more information in less space) And you get lost in the said information. The problem with Haddock is that its framed layout implementation is horrible, so you don't have any quick navigation that works properly. I'll address this in my Haddock patch. 
Ah well, no risk, no reward. You have a good team around you so its not too stressful. It's busy though and varied.
I think this is more an issue of tone. Beating up on volunteers is seldom appropriate (maybe it is if you have a malicious volunteer, which isn't the case here.) Instead of the tone being "they are unresponsive and won't fix bugs, drives me very angry, how dare they" I think it's more productive to be fact centered and just say "the bugs are not fixed, for the time being we should use the old version and if this situation continues we can fork it." Even a little "and thanks for all your hard work in bringing us what became an essential library, folks rely on it so let's figure out a way to keep it going" wouldn't hurt. If they don't respond, go ahead and fork! It's free software. There's no need for the anger. 
It would only work for linux, not sure that effort would be that beneficial. Musl is faster largely due to it not doing everything glibc does. Which is both good and bad depending on your needs. Aka, things like language support for locales is worse. But it is meant for static linking and it shows. Works for me at least.
Here is my talk from DevOpsDSM where I get Haskell working on AWS Lambda: https://github.com/chadbrewbaker/introToAWSLambda Commands I used to compile were: ghc FastFib.hs -O2 -o FastFib -threaded -static -optl-static strip FastFib The trick is to run the "ldd" command repeatedly on the binary until you have removed all your dynamic libs and recompiled them to static versions. (.a extension)
You need IO to return real random numbers. But if you can't use IO, you should be looking at pseudo-random number generators. https://hackage.haskell.org/package/random For example, use getStdRandom to get a generator from IO, you can pass this generator to pure code. Or create a new generator using a random seed. If you'd like, you can get deterministic randomness by using the same seed every time you make the generator. 
They use haskell now too? I wonder if that means Yaron Minsky has decided it's now performant enough, or if someone just loves it enough to use it for performance non-critical scripts
You may find this bit of code I wrote on similar lines somewhat helpful. &lt;/promotion&gt; https://github.com/mrkgnao/pebble But `ad` is indeed wickedly cool.
Yes, that's the one. I see it is not being used much. I wondered why and whether there's a more widely accepted alternative. 
I've been meaning to give Idiris a try for a while now, but real life keeps getting in the way. It sounds like it solves a lot of Haskell's problems.
and adds new problems.
Light grey is not middle grey. Take a look at #ECECEC like suggested. It reduces the glare enourmously with very little lost of contrast. The contrast of a white light bulb and black text is much higher than the contrast of paper, and much less comfortable.
OK. "Hamlet" is still the name of the HTML-specific template language in shakespeare. The four languages in shakespeare were separate libraries, but now they are all in the shakespeare library. For JSON in shakespeare, you would probably use Julius, not Hamlet. Julius is meant for Javascript/JSON. But it is much simpler than Hamlet - you get type-safe string and route interpolation, and that's it. The rest is just regular syntax. What you gain is compile-time type-safety of string and route interpolations, via TH.
&gt; If types could reveal everything, we'd be battling skynet
Put nginx in front of your app, as a caching reverse proxy, and let it deal with the https stuff.
I do too! That's my only gripe with this new layout so far (I haven't poked around all that much). I really want to be able to access the synopsis from any place on the page, but the way it fails with long type signatures on the current haddocks is frustrating.
I wrote this with the intent that it would be relatively comprehensible to non-experts in both (or either) biology and functional programming (I certainly still consider myself a beginner in the world of Haskell). I am exploring the use of Haskell for computational biology and hope to continue writing a little as I go along. I think the declarative style is extraordinarily accessible and powerful, so perhaps this post is most focused on demonstrating such. I would appreciate any feedback or thoughts from the community here; let me know how I might improve in any regard.
The first example brings up something I always really disliked about rewrite rules. They break parametricity: {-# NOINLINE f #-} f :: a -&gt; a f x = x {-# RULES "f" f True = False #-} main = do print (f True) print (f 5) Prints: False 5 But I thought I could deduce from the signature of `f` that it *had* to be `id` (or bottom)! *EDIT*: Formatting
I think this approach is a rather interesting way of doing it. As you said, it is less subject to human error in the writing while requiring more domain knowledge to interpret or space to explain. I'll definitely be taking this into consideration.
Could make greater use of ADTs rather than type synonyms for strings. There should be performance + safety gains, although I get you might want to catch odd cases of ambiguous nucleotides depending on your data source. I want to see more on this - some of the bio packages on hackage are out of date/abandoned (biohaskell) or sparsely documented (eg fastx-pipe). There needs to be more of an effort to get the Haskell scientific computing ecosystem fleshed out and provide learning paths for newbies coming from other fields. What say you /u/ocramz /u/idontgetoutmuch /u/cartazio ... (what was acowley's username)? Within bioinformatics, there's a few individuals are kind of in the woodwork, I know of David Powell (Degust) and Michael Barton. May be some others as well. Nobody I know have has committed to go all in expanding the limits of applied computational biology work in Haskell for others to follow. 
TIL Central Dogma isn't an Evangelion reference!
At which point you start wondering why they're format *strings* at all.
You could always [come and work for Standard Chartered](https://donsbot.wordpress.com/2016/01/18/haskell-developer-roles-at-standard-chartered-london-singapore/) and get all the Haskell for Finance resources you'll ever need, or at least write them if we haven't got them already :)
This is the common approach for SSL and application servers in general. Source: worked at several network based companies.
You should take a look at [MonadRandom](https://www.stackage.org/lts-4.2/package/MonadRandom-0.4.2.1). You can use it to abstract away all the RNG passing, and just evaluate using our RNG once at the end. Example: import Control.Monad.Random main :: IO () main = do gen &lt;- getStdGen -- We could easily use a different RNG here if we wanted let values = evalRand diceSums gen -- Evaluate using our RNG print . take 10 $ values -- Generate sums from rolling two dice diceSums :: RandomGen g =&gt; Rand g [Int] diceSums = do xs &lt;- dieRolls ys &lt;- dieRolls return $ zipWith (+) xs ys -- Single die roll function. dieRolls :: RandomGen g =&gt; Rand g [Int] dieRolls = getRandomRs (1, 6) (This printed `[9,5,8,7,6,9,7,10,6,6]` when I ran it)
sure i'll add some to the github readme
It's been a long time since I've seen it, is it possible it's a reference to the biological term?
Fair point. The safety of equational reasoning goes down the drain too...
Let's please all try to have a slightly more nuanced view than "x said a bad word, so x is in the wrong". Honestly, the original comment was far more objectionable than this response.
No, I don't think so. There was never any kind of agreement or promise of continuing maintenance from the maintainers of aeson, so why would there be any responsibility on their part? If people have decided to put software in production that relies on aeson, that's unfortunate for them, I suppose, but they still have two good options: * Stick to 0.9.x * Fix any issues themselves. I'm sure that many of the people whining here (and elsewhere) about this situation have the ability to! In the vast majority of cases, users will have derived a lot of value from aeson already anyway, and will be in a much better position than if it had never existed.
It's not like FRP at all. The basic idea is to have some kind of "variables" where you can attach a handler that gets called when the variable changes. Some of the variables are connected to UI elements. It's all rather imperative, but with Haskell you can build nice layers of abstraction. /u/ndmitchell can tell you more; he designed it. 
If you encode them as bit pairs A(0,0), T(1,1), C(0,1), G (1,0), then by taking the complement you get their complement base. You can also pack 32 bases in a 64 bit register. Then use machine instructions to reverse/complement them. For storage and manipulation this is usually the encoding I use. 
that seems a bit too clever to me. I can imagine code getting hairy with the conversions by numeric indexing. Maybe there's a clean way to wrap the implementation.
Well, the RULES are *supposed* to be used in a way that doesn't change the value of the expression, it just optimizes how it's calculated.
If the compiler was smart enough to figure out non-breaking identities itself we wouldn't need rewrite rules in the first place.
I'm not happy with the answers. Here is a very simple program that generates 4 pseudo random numbers: rand :: Int -&gt; Int rand seed = (1103515245 * seed + 12345) `mod` (2^32) main = do let a = rand 123456789 -- change for different sequences let b = rand a let c = rand b let d = rand c print (a, b, c, d) Of course, Haskell's random number generators are more featured, have better properties and are more convenient than that (that's what monads are for - they're not a magic entity that bring impurity to the language, they just bring convenience to that kind of style). But you want to know how it is possible in principle, and this example is more than enough to illustrate that. You don't need impurity for pseudorandomness, at all.
Thx, looks great
on the other hand rewrite rules allow for some cool performance boosts if you are not afraid to use them (and manually check that what you wrote is identical to the original (heck not even quickcheck would work except if you run it without optimizations on)) - since you can have a nice polymorphic function and then for certain corner cases provide vastly better implementations. (the example the manual gives is toDouble having a rule that turns Int -&gt; Double from a complex calculation into a single machine instruction.) ... what I'm doing here is really just intentionally breaking all the conventions for fun (and perhaps knowledge profit ^^).
I don't suppose Standard Chartered would like to open a Vancouver branch ...
&gt; ... what I'm doing here is really just intentionally breaking all the conventions for fun (and perhaps knowledge profit ). Oh, don't get me wrong! I enjoyed your blog post, and think exploring the "oh but you really shouldn't do that" avenues is something one should do :) And I also much appreciate rewrite rules generally. I think `toDouble` is great example of a good use of it; but note the `Real` context in its signature! That means it's not open to the sort of objection I mentioned. The rule itself could be wrong, of course, but then so could the original implementation of the class methods, so it's not like rewrite rules are making things worse (modulo having to check one's code in two places, and with two different optimization levels).
sounds like you didn't contact me for interning with me... did you read the applicable thread the parent linked to...
then why are you commenting on the subthread about working with me :''(
What's the work/life balance like? How many hours are people typically working?
I hadn't heard of actors before today. Thanks for explaining that although they're the hot thing right now, they're not actually all that great. I'm not sure where you're going with Gell-Mann Amnesia. The people in this sub who talk about stuff I know about are very knowledgeable, and because of that I trust them on the things I don't know. I'm brand new to Pony, but the few things I recognize in it so far seem like good ideas (though I haven't gotten into how well the language holds together in practice yet). 
i'm just trying to hook you up maaaaaan
Discussion about the book: https://www.reddit.com/r/haskell/comments/296l80/today_i_published_an_introductory_book_on_haskell/
I would still switch over to `formatting`, because `formatting` lets me build my own custom format specifiers
Sure. A type which references a value could use that value multiple times. Doing so will often cause types to unify and lead to a less informed type. If you're trying to figure out the "only" inhabitant of a type it's sometimes a good idea to outlaw reuse of values for a bit and see if that's workable at all. Take special note of duplication and think of it as an action you ask for the right to use. Essentially this is just saying that linear types are more refined since you'd have to explicitly ask for the right to ignore or duplicate an argument.
Oh sorry, to clarify I was talking about my experience applying to Jane Street.
What relevance does this have to Haskell? This looks like just another hipster object-oriented language using words like "type safe" to signal sophistication. You can throw it in the bin with yer [Nimrods](http://nim-lang.org/) and yer [Cobras](http://cobra-language.com/).
Interesting! I still think it's important to give 'x' a better name. I.e., what does it mean, or represent in the domain of the internals of the function? Because otherwise when re-reading the code, I must pause to figure that out every time. So to me `x` is good for an x-axis coordinate, or as a single, obvious parameter to a one-liner.
Parameters in haskell can potentially have many parts. A seven argument function can be made into a one argument function that takes a seven tuple can be made into a one argument function that returns a six argument function. Haskell is already very clean in a lot of ways. Things don't interact unless they explicitly interact. Also, we deal with multiple levels of abstraction regularly. Code doesn't document itself, the compiler documents it for you (types). The compiler is your pair in pair programming. Whether a function is short is subjective, because what is in a function is subjective. Anything part of the function can be put outside the function without changing anything. In a way, it's not necessarily contradicting anything you already know, it's just that what you know may no longer even have meaning any more. This is Haskell. Embrace the Lambda. (Note, I may be embellishing on some points for effect.)
Usually they are fairly obvious. `map f (x:xs) = f x : map f xs` for instance has: * `f` which is a generic function (can't name something you don't know the purpose of) * `x` which is the first item of the list (note this is common) * `xs` which is the rest of the list (something `s` is used in many cases) That isn't to say that some people aren't too short with their variable names, that certainly happens.
I found [a good example]( https://wiki.haskell.org/Fold): -- if the list is empty, the result is the initial value z; else -- apply f to the first element and the result of folding the rest foldr f z [] = z foldr f z (x:xs) = f x (foldr f z xs) The code continues... And I needed to look back to the comments to see e.g., "what is z?" But clean-coded, foldr fun initial_val [] = initial_val -- etc... It seems that it's self-documenting — the comments are redundant and can be removed.
The key idea behind pony is to use substructural types to manage concurrency, in a fashion reminiscent of Rust. The novelty relative to Rust is to move some ideas that are well known in the program verification community (using deny permissions to specify rely/guarantee conditions in a local, modular way) to a type system context, which ought to make the types a bit more flexible. I doubt it has the maturity of ghc, but if you have free time, it's likely worth playing with for learning purposes. 
Thanks! What do you think of this example: (from the haskel wiki) -- if the list is empty, the result is the initial value z; foldr f z [] = z Re-written in clean code style which removes the need for the comment: foldr fun initial_val [] = initial_val Compare also to [Elixir's Spec for `reduce`](http://elixir-lang.org/docs/v1.0/elixir/Enum.html#reduce/3).
The argument usually goes thus: In a function like `id`, the argument really doesn't stand for anything besides 'the sole parameter of this function'. id :: a -&gt; a id x = x The same applies to a couple of very abstract functions (`(.)`, `fmap` etc.), where for example parameters denoting any function are usually named `f`, `g` etc. (following mathematical tradition). Unfortunately, there's a certain tendency to overuse this style and go for one-letter names where more descriptive designations could well be found. I don't think there's a particularly good reason for this.
Not really idiomatic haskell. The wiki was just giving an example. Best would be foldr::(a -&gt; b -&gt; b) -&gt; b -&gt; [a] -&gt; b foldr f z [] = z ... Although `fun` and `initial_value` convey some meaning, `(a-&gt;b-&gt;b)` and `b` have precise meanings that the compiler can verify. `(a-&gt;b-&gt;b)` implies that `f` is a function, and specifies exactly what function it is. The fact that z is the initial value is implied clearly by the line ```foldr f z [] = z``` I probably lied when I said code doesn't document itself. Rather, code documents by default in haskell. Maybe more descriptive names wouldn't have been a bad idea, but types are *so much more powerful*. In fact, naming your *types* well is probably the most important thing for naming (not type variables, but actual types (actual variables in general aren't named very precisely)).
I guess the main thing to remember is the types. Types are documentation that the compiler can verify, create, and create and verify at the same time.
Well yes, we could have both. It's just that Haskellers, for whatever reason, have deemed Types to be sufficient. Especially when you use typed holes. Like, there a lot of ways to document code. You could give each variable its own document if you wanted too. Haskellers like to have a high-density code though. With types, it usually isn't too hard to understand code. That said, I doubt anyone would complain if you are more explicit. They would find it weird, but wouldn't be too distracted. (Take everything I said with a grain of salt. I am very tired at the moment. Do look up typed holes though; it's awesome.)
I think I get it. And `a` looks like the common convention in Haskell for _any_ type. But compare it to Elixir's convention, `any`; I like that better because it says what it is.
But that tells you nothing new at all. Specifically, why is "initial_value" enough documentation, but the more accurate "final_rightmost_default_value"? Your name does not actually document anything useful, and isn't even accurate. Just switching to initial_value is well on its way to doubling the character count of the definition. And indeed, it is neither strictly the initial not the final value, so even still we haven't fully documented it's purpose! So we look at the type signature to figure it out and remember "ooh, this tells us everything we actually needed to know in the first place." And no, it really is not the initial value, as you can use foldr on infinite lists and return both finite and infinite results without examining this supposedly initial value. And it truly is not the final value either, as we can just add easily set up a right fold where it *is* the very first value evaluated.
I would suggest discarding the "Clean Code" book entirely, since it is an inconsistent mess of "let's do OOP for the sake of OOP" with an emphasis on having mutable state and other stupid idea. Although those things you mentioned are probably not a bad idea in specific. And 1 letter identifiers are usually used when more than 1 letter doesn't gain us any real descriptiveness: f vs func, x vs "firstElementOfList" and so on.
&gt; why is "initial_value" enough documentation That term is from the comments. And so I'm only showing how descriptive names remove the need for the docs.
In haskell calling it "Any" would get it confused with the Any type (which is already used twice - once as a newtype for Bool for a specific implementation of monoid on bools. And the other by unsafeCoerce where it becomes really Any type ... without the typechecker giving you any help at all). Also considering you often have functions with types like :: (a -&gt; b -&gt; c) -&gt; [a] -&gt; [b] -&gt; [c] it'd be less readable to call it "any1, any2, any3" (or perhaps any_a, any_b, any_c?)
Using `f` and `z` there is very closely analogous to the widespread use of variable names like `i` and `j` for loop indexes in imperative languages. `foldr`, after all, is one of the functional programming counterparts to such loops. You're supposed to know it anyway! 
&gt;`foldr fun initial_val [] = initial_val` &gt;And so I'm only showing how descriptive names remove the need for the docs. `initial_val` isn't correct here, though. The `[]` is a terminating condition, so your `initial_val` is likely to be the terminal value at the end of a potentially very long recursion. A better name would be `acc` for 'accumulator.' This is why many of us don't trust names nearly as much as types. You can't get the types wrong the way you just got the names wrong.
Haskellers jump to point out short variable names in functions with high parametricity and short scopes, but I've noticed this is starting to feel like a "default answer" that is used to avoid discussing any nuance on the topic whatsoever, because without an example one will simply insert the example that is most convenient to argue their position. Here is an example: https://github.com/bitonic/binary/commit/e46b7b61111579befcc99954be8a0f48738f8ef7 examples of variable names include inp, ks, mbBs, bss0. Actually, I don't think this example is all that bad (I can figure out their meaning with some thought), but I'm not sure that this point one can invoke parametricity with a straight face as to why these variable names are so short. If the only code we have to write is involving an implement ion of `map`, `foldr`, and `id`, then I agree about the ultra-short variable names. However, most of the code we will actually write (especially if not in a library) is far more concrete and less general than those methods; good variable names should be encouraged more in haskell culture, and the the fact that parametricity exists and prevents good names for a small subset of library functions shouldn't distract us from that. I think the real reason folks use short variable names in haskell is because they prefer to see the whole context of a computation on the screen at the same time. Perhaps laziness has something to do with this because when the order of operations isn't meaningful, you can't just understand the first page of text in isolation if the are multiple pages; you probably need to see the whole thing at once.
I find it much harder to read your "clean" style. I prefer the short variable names because it's immediately obvious that the function returns its second argument when the list is empty. The comment is useless too, I would remove that.
I do agree, that Haskell uses much more one-letter names than other languages I worked in so far. I think in this case we should think about if we should care what `z` is at all. `foldr` is such a generic function, that `z` can be almost anything. My real frustration with one-letter variable names (or with undescriptive variable names) comes from work, where we use Perl. In perl, variables like `$x`, `$tmp` are very frustrating, because you have no information about those values at all. In Haskell at least you have the types. I guess I'll have to see how is this in practice in Haskell, as I learn it. 
Why not have both, you ask? Both comments and variable names are only clues for what a function really does. Nothing binds them to the behavior, which means they can (and *do*) drift. So now you have to guess.. which is right? The comment? The variable names? Or neither? Even if you do a perfect job of keeping comments, names, and behavior in sync, that sure sounds like a lot of work. Types, on the other hand, can't lie. Becoming a good Haskeller means learning to lean heavily on types. Read them first. Write them first.
&gt; can you make such important news at a more official place than a random discussion forum on the internet? I think /r/haskell is not a random place for Haskell announcements at all. It takes quite a central place in the Haskell community.
&gt; Pass no more than four parameters into a method. I try to live by this rule. In fact I aim for three parameters maximum. Parameter order is also more important in Haskell than in other languages and merits its own guidelines: https://wiki.haskell.org/Parameter_order 
That sounds great until you're thrown into some function in the middle of a 200,000 LoC project you've never seen before and you have to make a small change to business logic. If you're lucky to know where to start in the first place that is. Clarity in convention and naming is important in any large project. Not only for your own sake but for the next guy who absolutely won't have time to read the entire project. 
Here is some silly mathematics. Let φ : S → N be a function from a set S to a monoid N. Then there exists a unique homomorphism of monoids φ' : List(S) → N such that for every element s in S, φ'([s]) = φ(s). Did we do a good job naming things? Perhaps you would have liked this instead: Let fun : Set → AnotherMonoid be a function from a set Set to a monoid AnotherMonoid. Then there exists a unique homomorphism of monoids freelyGeneratedFun : List(Set) → AnotherMonoid such that for every element s in S, freelyGenerated([s]) = fun(s). I'm wondering if that seems more clear, even if you're not familiar with the problem domain. At least to me, I find the first to be much clearer because it conforms to the norms I'm familiar with. It's shorter, too, requiring less reading. Are the names less informative? I wouldn't say so. M and N are good names for monoids, S is a good name for a set, φ is a great name for a homomorphism (φ is close to "f", which stands for function, and is a traditional choice for the name of a homomorphism), and φ' is what I wrote instead of φ with a tilde, the traditional choice for an extension of a function. But on the flip side, does having all the names spelled out make it clear what such a function does? (If it wasn't clear, the above actually defines a higher-order function of type `Monoid n =&gt; (s -&gt; n) -&gt; [s] -&gt; n`).
Using short names for variables and long name for functions helps to distinguish functions from variables. It's easier to recognize patterns and long variable names add noise to the syntax.
&gt; (e.g., *x* is a function parameter, but **x** is a vector). Whoever does this should be slapped, along with physicists who prefer to put hats on vector-valued variables. But it's true that mathematics has access to a much richer typography. Access to Greek letters, tildes and other decorations, and the ability to distinguish (and slur) between function application, operator notation, and indexing is very useful and important to mathematical writing. That said, I have read a few books where notation is needlessly overused. I have a differential geometry book that lists three distinct ways to talk about the set of local sections on a sheaf, and uses all three, each instance chosen seemingly at random. Even something as simple as "A ⋂ B ≠ ∅" instead of the more direct "A and B are disjoint" bothers me.
&gt; Haskell's notation is similar to mathematics. I sometimes wish mathematics would have better variable names, though. Using `f(x)` is like using `foo(bar)`, and sometimes they get used when a more long-winded but more descriptive name would've been better. Ultimately the single-letter restriction results in adding numerous diacritics, sub/superscripts, even using different fonts—the culmination of which must lie beyond APL somewhere. I.e. I don't see anything wrong with single-letter variables/functions for small, generic stuff. I did pick up one thing from CTM that I liked though: Rather than going `(x:xs)` they go `(x:xr)`, or `xs@(x:xr)` (paraphrasing from Oz). I.e. `xs` is some list consisting of the head `x`, and the remaining elements `xr`.
So here's a different perspective on this issue from a game developer. Writing C++, I'd write template &lt;typename A, typename B&gt; B FoldRight(Func&lt;A,B,B&gt; combine, B initialVal, List&lt;A&gt; list) { ... code ... } or something like that. Some things to note about this prototype: 1. template&lt;&gt; is just line noise, but it gives us the type names (which are generally short, by convention!) 2. Type names and top-level function names are UpperCamelCase. 3. Variable names are lowerCamelCase. These are all style choices, not required by the language, but they are chosen with purpose. Now, in Haskell foldr :: (a -&gt; b -&gt; b) -&gt; b -&gt; [a] -&gt; b {- code -} Things to note: 1. Type variable names are still short. They begin with a lowercase letter as required by the language (this is important!) 2. We can't name the parameters in the prototype. I think this is a big weakness of the language. Dependently typed languages are nicer because they require that you can name the parameters in the type. 3. Top-level function names and local variable names both start with a lowercase letter. This means we can't distinguish them just by case! It is point (3) that makes me lean towards code with short variable names. My function names are long and descriptive, variable names are short. That way I can tell my variables from my identifiers quickly when browsing code. This is made more difficult because often you have 'local' top-level functions due to how you want to encapsulate helpers (in where clauses, or let clauses in a do-block). In an OOP language these would be mutating some state on an object, and the class would grow as more of these 'helpers' were needed. In functional languages, you need all your state explicit and local. This is a good thing, in my opinion! But it does mean your coding style has to change. Some functions in business logic end up longer because that's clearer than making a helper function that takes a huge number of parameters, e.g. code that looks something like runApplicationGUI = do win &lt;- makeWindow button &lt;- makeButton win "Quit" $ do putStrLn "quitting!" closeWindow win etc. In lots of languages you'd be required to make the "quit" action some form of callback which takes the current object as state. In Haskell all your state is explicit, so in order to get access to `win` we either need to pass it as an argument to said callback (which gets ugly!) or include it in a local closure which has access (as I've done here).
I'd love to give you full code and technical specs, but alas, one of the disadvantages of working for a bank is the code isn't yours to share. However, some of the ideas were originally developed during my PhD, and can be seen at https://github.com/ndmitchell/proplang (there's no chance the code will still compile, but the ideas are there). There you have properties, which is just an IORef with callbacks on it. You then have ways to update the variables, get notified when they change and get their value. Finally, the clever bit is that things like textBoxes are given properties, and then you can watch for users changing a textBox in the same way. As /u/augustss says, it's just the imperative paradigm, wrapped with abstractions/types, and then you can build up the rest of the world in Haskell.
&gt; I did pick up one thing from CTM that I liked though: Rather than going (x:xs) they go (x:xr), or xs@(x:xr) (paraphrasing from Oz). I.e. xs is some list consisting of the head x, and the remaining elements xr. My convention in this situation is `xxs@(x:xs)`, so xxs is `x:xs`. This way you can also have `(x:xs):xss` and `xyxs@(x:y:xs)`.
I'm definitely not a bioinformatics person but I understand they use wildly diverse tools; drawn from combinatorics (aligning sequences, filling gaps ), to inference .. moreover these tools need to be fast and validated so practitioners tend to flock to ready-made solutions. The few bioinformatics researchers I know are Perl/Bash/R ninjas. Don't really care for fancy language features .. Regarding the broader SciComp question; "we're working on it". In the sense that's is a very complex issue, tackling efficiency, expressiveness, ease of configuration, portability etc. But I firmly believe composability and types will ultimately win people over also from the HPC/numerics camp.
&gt; Haskell functions often have more parameters simply because stuff can't be implicitly passed in by mutable state (something Clean Code stupidly advocates). Can you elaborate on that? I'm new to Haskell and a fan of Clean Code, and not able to figure out what you're referring to exactly in either case. **edit:** Ok, I just recently search through Clean Code briefly and could not find anything in it advocating what you say it's advocating. It has a chapter on functions where it talks about parameters. It doesn't suggest moving them into fields but combining the related ones into objects and for variable number of arguments, use argument lists. Example of moving x and y into a Point object: Circle makeCircle(double x, double y, double radius); Circle makeCircle(Point center, double radius); The page right after than has a section called, "Have No Side Effects." In that section he starts it off by saying: "Side effects are lies. Your function promises to do one thing, but it also does other hidden things." Perhaps you are miss-remembering. I think I have seen him something like what you're describing in a Clean Coder video, but I that doesn't mean he is advocating it.
More than 5 lines seems inevitable in some IO applications
Oooo it's so pretty ! Thanks for sharing, will try asap
I think he is talking about the book where "Uncle Bob" writes all the examples in a quite old fashioned OOP style (look there is an argument to that method ... we better put this into a field quickly)
You have to remember that "Clean Code" and the rules you provided are opinions of the author. They are not some universally applicable truths, just some guys' opinions, which are roughly as good as anyone else's. Don't blindly follow such rules. Having hard limits (5 lines per function, 4 parameters per function) is just an artificial constraint which does not necessarily make your code any better. It's easy to follow such rules in e.g. Ruby, you just add a class to hold some of the parameters but then you introduce more complexity to do what is essentially a partial function application. E.g. my guidelines for length of function and number of parameters are very different and depending on the programming language. When writing C, I would consider it fine for a function to be a screenful of code, or roughly one page if printer (I never print code, though). When writing Haskell it would be shorter. When trying to write lots of small functions, you easily end up writing more code than necessary and adding complexity that is not required. Don't be afraid to ignore silly rules like the ones you show. Over time you'll gain an intuition that will work better than blindly following hard rules.
Yet handwriting in this case is a very advanced technology that allows us to write stuff like `x̂` easily—here on my computer I couldn't combine a dead circumflex with an x and had to resort to a unicode combining char. Often these things get used as a neat type hint, i.e. we can write `v :: Vector` as v with a little arrow on top. Wouldn't it be great if computers were powerful enough to enable that? Then you could have variables like the direction of a ball named just `ball` with an arrow on top. It's instantly visible what it is, because of the arrow-name-convention. But our puny computers still can't handle that.
hlint, hlint, hlint. There is always a succinct combinator you can use.
I think that book is actually pretty decent and has some good advice. It influenced my Haskell style for the better, I think.
i have my right alt key set to be a compose key which makes exactly what you are talking about possible and easy
&gt; I think your version is too narrow for desktops. IMO it's fine. The code blocks can fit 80 characters and a few more, so it's OK. Edit: made it just a bit wider though. &gt; I've also changed colors to match current Haddock theme. I belive it has perfect color balance. Implemented all your color revert suggestions and some more. Doesn't look as consistent with haskell.org as it used to, but it looks lot more friendly and less evil now. http://lamefun.github.io/Pipes.html
Not sure why this is relevant since hlint gives no suggestion for all four pieces of code in my comment and the parent to that.
Quite possibly! Evangelion was pretty scattergun with its references, haha.
Yeah, well. I find that hlint often provides some combinator for me to use — perhaps it is my love of point-free code.
I know the auto-pointfree very well. And I know restraint, don't worry. Sometimes a variable binding is better.
&gt; Monoid n =&gt; (s -&gt; n) -&gt; [s] -&gt; n) This was the only part of this post that made sense to me :p. And to avoid anyone else having to scratch the same itch: Prelude Data.Monoid&gt; :t \f -&gt; mconcat . map f \f -&gt; mconcat . map f :: Monoid c =&gt; (a -&gt; c) -&gt; [a] -&gt; c
I would bet he's changed his mind on that given he's a fan of the discipline imposed on state by functional languages. 
I felt inspired for a second, but was quickly disappointed. :) λ&gt; let v⃗ = [1, 2, 3] &lt;interactive&gt;:6:6: lexical error at character '\8407' λ&gt; "v⃗" "v\8407"
&gt; As the community becomes larger and larger it will become more &gt; and more difficult to synchronize everyone to a "collective clock". Probably, but hopefully by then, we'll have nice automated tools with matrix reports directed by PVP and crafting a new global version will be a single click :) 
that sounds like the best option, given that you that target nightlies
Well I'm reasonable confident that the projects I've planned for the right summer interns will be cooler 
I would be interested in how to get *real* (non-pseudo?) random numbers using IO ... do you have some kind of geiger counter connected to your rig or are you using https://www.random.org/? PS: :D
Disciple uses append (xx yy : List a) : List a = case xx of Nil -&gt; yy Cons x xs -&gt; Cons x (append xs yy)
it's not that far away from the [implementation in random](https://hackage.haskell.org/package/random-1.1/docs/src/System-Random.html#stdNext)
What's wrong with evalState (replicateM 10 $ sample stdNormal) (pureMT 42) :: [Double] [-2.2016035548104447, -0.13436088466523924, 1.8488760426492017, -1.667523256909233, 1.2102195192444156, -0.4295155648631194, -0.16480155484220715, -0.12159756795295017, 1.2591726544833504, 0.23883909276097806]
I do understand the compulsion to rewrite ugly code whenever it appears, but I don't see how these rewrites are better examples of how &gt; When pattern matching, casewise function definitions, and guards come into play, lines get even longer I'm also not sure what was less consistent about the original indentation/formatting.
why don't you use [`hFileSize` from `System.IO`](https://hackage.haskell.org/package/base-4.8.1.0/docs/System-IO.html#v:hFileSize) using this you can just do import System.IO fsize :: FilePath -&gt; IO Integer fsize path = withFile path ReadMode hFileSize --- **note** that you will very likely end in IO or another monad here anyway I would try to fix yours but I cannot try it for real right now - I think a simple `return $ fromIntegral size` at the end together with changing the signature to `entrySize :: FilePath -&gt; IO Int` should do: entrySize :: FilePath -&gt; IO Int entrySize entry = do stat &lt;- getFileStatus entry let size = fileSize stat return $ fromIntegral size but again: I did not check this and only had a quick look at the documentation
This is pretty much all I know about these things: [wiki entry](https://wiki.haskell.org/Obfuscation). I'm not in any way involved.
I'm saying if you follow a different style guide, a lot of those problems aren't as big problems as they are made out to be. What's inconsistent about the original style is that the function body starts at a different column for every line. After having worked with Python for a while I'm really opposed to aligning things and continuing things on the same line. I much prefer to make a line break and indent by four spaces whenever something new starts. In my mind, the when-in-doubt-make-a-new-line-indented-by-four-space style makes the code much easier to read and work with in terms of cutting and pasting during refactoring. As a bonus, it also means people who aren't familiar with Haskell go "Ah, I can see how that works" rather than "What the heck kind of Perl magic is this!?" 
It is also easier to test if it is split up.
Hi - I wrote [quantfin](https://hackage.haskell.org/package/quantfin) (the third link above), and I partially did it to show what is uniquely possible in finance in a functional language. Also I noticed that there really wasn't much available in the open source world. This is [good though](http://www.timphilipwilliams.com/slides/HaskellAtBarclays.pdf).
Think `IO` as the outer world. Can you always input a file path (in the case of `hFileSize`, a `Handle`) and guarantee that the output (the file size) is always the same? No. Why? Because I can have another process in this "outer world" appending information in this file. Although the `Handle` is always pointing to the same file, its file size is changing (and is out of control of _our world_, your Haskell code). Hence, everything from "outer world" has the `IO` label. And that's the reason you simply cannot return `Int`: because I cannot guarantee the next time you will call `hFileSize`, the output is the same. That's the different between *pure* (those that return `Int`, `String`, etc) and functions with side-effect (e.g., `IO Int`).
Of course you *can* always split it up, but too much indirection hurts readability so there has to be a greater gain somewhere.
The IO signals that it the Int is "in" IO, so can only be used in other functions operating "in" IO. The `main` functions is "in" IO, so you could use it there. In that case you may "bind" the value to a local variable: main :: IO () main = do size &lt;- entrySize "./somefile.txt" printStr $ show size I avoided the word *Monad* in my explanation. I'd like to suggest you to learn Haskell by a bit more structured means then just diving in, it is not a very suitable language for "just diving in with a background in on or more OO or imperative languages and I'll figure it out along the way". And while just diving in might not work, I still believe learning Haskell will be a very good investment. Here a good overview of free online resources: https://github.com/bitemyapp/learnhaskell And this book (currently in beta) is very promising: http://haskellbook.com/ 
What do you guys think about functions that are long only because they are broken up into several helper functions? If it is say 4 helper functions that are about 5 lines long and 1 line for the main that they are tied to, would you consider that as 5 short functions, or one long one?
Unrelated to the debate here, large Haskell projects exist. Here's statistics from compiling 4 of our projects (for Mu, read Haskell). This is total number of LOC, including libraries. 328281 lines (importing 1122 Mu) compiled in 274.31 CPU seconds, 1197 lines/s 342271 lines (importing 1175 Mu) compiled in 278.85 CPU seconds, 1227 lines/s 391803 lines (importing 1488 Mu) compiled in 401.91 CPU seconds, 975 lines/s 288321 lines (importing 969 Mu) compiled in 471.65 CPU seconds, 611 lines/s 
Then we disagree here. Characterising this behaviour as "complaining about it" doesn't really capture it adequately. &gt; What drives me furious is the fact that [people did not do work for my benefit, on a timescale suitable for me, for no compensation]" It's entitlement, and it's disgusting. If "wanker" offends you more, then I would consider re-evaluating your approach to these things.
Pretty much. I don't actually want to program with variable names like א. It was more a comment on how OP seems to think of handwriting as "outdated", even though it's still a more powerful way of writing symbols than current computers are capable of, and, I suspect, some sort of stockholm syndrome with keyboards and the ascii charset.
Here is a simple convention I follow: If something deserves a name, it should be a where/let or top-level definition.
&gt; "[people did not do work for my benefit, on a timescale suitable for me, for no compensation]" That was not what the original commenter asked for. He asked for a comment on the issue, which by the way had been fixed in HEAD for 4 months. He also asked how to take over the package, to fix the problem. Not sure how this qualifies for disgusting entitlement. And yes, I will take random people hurt feelings over insults, especially from respected contributors, every day.
Disagree strongly. Variables are just plumbing. The concrete functions you use should be well named, but the variables are just connections between them.
Thanks a lot, I'm going to take a look!
There are backup maintainers on Github and the issues (at least those that were bothering me) seemed to be fixed. It is a backup maintainer on hackage that would have helped!
And still, the variables most of the time carry some meaning, which, when you know it, makes understanding, maintaining and extending the implementation a lot easier. Can't hurt to understand function parameters by their names instead of having to refer to the comment explaining them, either.
I disagree with the tone of your comment (I even downvoted it), but you're totally right about the name "pony" being hipster. (Makes me think of bronies).
I think that's even worse than the starting code tbh. Sorry! However, my suggestion would be your final point: I would introduce a `TetrisColors` record type with `gridColor`, `red`, `green`, etc as fields. Then you can have a top-level function `initializeTetrisColors :: IO TetrisColors` that is basically all those binds up there, followed by `pure TetrisColors{..}`. Then you're big main function gets a bit smaller, as it just needs to call `initializeTetrisColors` (and maybe bind it using `RecordWildCards`).
No, there's no parallelism in the compiler.
Agreed, I would do the same. The list solution is problematic.
I was thinking recently that it would be nice if Haddock would let you comment type variables in type definitions. So type Lens s {- ^ Global -} a {- ^ Focused -} = Lens s s a a Then have tooling report the documentation, without loosing the short-hand of `s` and `a` which are useful once you're familiar with the structure. 
That sounds interesting. I found [the paper](http://www.ponylang.org/papers/fast-cheap.pdf). Edit: Having finished skimming-reading it, I'm still left wondering what useful patterns, constructions, or programs are expressible in Pony which one would have difficulty expressing (with similar performance, safety, etc. properties) in Rust.
You should refer to them by the types. The types will be checked. If you can't understand them from the types, you have some clean up to do.
 defaultPair :: a -&gt; b -&gt; Maybe a -&gt; Maybe b -&gt; (a, b) defaultPair defaultA defaultB maybeA maybeB = (fromMaybe defaultA maybeA, fromMaybe defaultB maybeB) 
It's a sort of type theoretic analog of Russell's Paradox, called [Girard's Paradox (PDF)](https://www.cs.cmu.edu/~kw/scans/hurkens95tlca.pdf)...at least, that's my understanding. There's a variety of [notes (PS)](http://www.cse.chalmers.se/~coquand/paradox.ps) on the problem, specifically about the [logical paradox](http://mathoverflow.net/questions/18089/what-is-the-manner-of-inconsistency-of-girards-paradox-in-martin-lof-type-theor) one encounters when trying to work with `Type` as if it were just another datatype. It turns out that `False` is not normalizing, if one tries to just pretend `Type` is a type. That means any program involving `False` (in this system) would not terminate, if it could run at all.
I've had no trouble diving into large Haskell projects written by other people. The short variable name issue is simply not a problem in that situation, because: 1. Function names are typically descriptive, so the short name issue is restricted to variable names. 2. In good Haskell code, variable names have a very limited scope - typically a few lines. 3. Haskell types, used properly, give you an enormous amount of information about the contents of variables. In this context, long variable names simply don't have much value, and are more likely to get in the way from a readability perspective. 
I was curious, so here are the current stats for GHC: cloc --include-lang=Haskell --exclude-dir=.stack-work,.idea,dist,old,bin,doc,site {compiler,testsuite,nofib,utils,libraries} ------------------------------------------------------------------------------- Language files blank comment code ------------------------------------------------------------------------------- Haskell (compiler) 422 45996 83160 160457 Haskell (testsuite) 5066 27965 14866 102720 Haskell (nofib) 1270 42990 43233 162166 Haskell (utils) 200 4554 4177 21672 Haskell (libraries) 1693 45414 65496 186694 ------------------------------------------------------------------------------- Haskell (all but libraries) 6946 121407 145337 446635 Haskell (all) 8623 166606 210646 632481 ------------------------------------------------------------------------------- 
a good monad tutorial! it's example driven and involves actual coding to motivate the abstraction and the notation.
is `comparing age` to be defined in a where clause or something? Based on your comment, the above is far more readable for me.
This is really nice, mightybyte. I have one critique though. I think most beginners fail to understand the monad construction because they have no familiarity with simpler concepts, like functor, applicative or monoid. I think most tutorials fail because they try to jump directly to the monad, instead of building up.
I wouldn't call the toplevel scope wrong. it's testable and the most empty. 
Sounds lonely. Come find some repos on [darcs hub](http://hub.darcs.net/explore) to contribute to. :)
No good reason -- the latter is probably better :-)
Looks great. 
I'd say subjective things like "a page" aren't good enough bounds: I get to use a huge monitor at work and can easily fit 200 line functions on a single screen.
Ok, I've made an official announcement on haskell-cafe and the Stackage mailing list.
I'd say it's actually a lot like reactive-banana would be if it gave up being functional and just decided to embrace imperativism.
Would be nice to have instructions using sandboxes instead of installing a system package.
I did this $ git clone https://github.com/mightybyte/monad-challenges.git $ cd monad-challenges $ stack init $ stack install $ stack ghci Configuring GHCi with the following packages: monad-challenges GHCi, version 7.10.3: http://www.haskell.org/ghc/ :? for help [1 of 1] Compiling MCPrelude Ok, modules loaded: MCPrelude. *MCPrelude MCPrelude&gt;
excellent post I've read through it but i really want to take some time over the next few days to delve deeper. thanks for taking the time to write it
Great! That's what I wished for several times already. I read a lot on monads/functors/applicatives and I do feel like I have *understood* them, I am even doing (successfully solving) some excercises from some online books, but getting into this from a practical perspective all the way is quite another story, thanks for putting this together!
This came up in a code review at work recently. There was some repeated code for extracting a value from a weird data source and sticking it into a map to convert to JSON. The weird data source had field names that needed to be mapped to the field names we'd use in the JSON, so I mentioned that a helper method could be introduced: extractToMap(responseMap, responseFieldName, source, sourceFieldName); But that annoyingly modifies responseMap and has too many arguments. Having recently read Clean Code, I know that Uncle Bob would recommend extracting a class: new ResponseMapper(source) .mapField(responseFieldName, sourceFieldName) .mapField(responseFieldName2, sourceFieldName2) .getAsJSON(); But that's a heavy abstraction to reach for to eliminate a few duplicate lines in one class, so it was left as is. Additionally, you'll notice that internally, ResponseMapper will be modifying a privately owned map. That's the state that CKoenig was talking about. With lambdas (or haskell) it would have been much easier, but we're still on Java 7.
A little library I've been meaning to work on for a while. All existing logging solutions in Haskell seem to be stuck in `String` land which is a real shame, not to mention makes them fairly incompatible with things such as logging to the `systemd` journal (or really anything that has structure). You'll probably notice that this is pretty similar to `monad-logger`, and you'd be right. There are of course a few differences: * `logging-effect` is polymorphic over log types. This is the main point * `logging-effect` uses pretty printing for log messages, which can lead to some really nice multi-line log messages where everything lines up as you'd expect. * `logging-effect` has a different handler which lets you accumulate a log under some `Monoid`. This is/should be `WriterT` done correctly (it uses `StateT` under the hood). * Lots more documentation! Logging is something that almost everyone should be doing, so I wanted to go for maximum new-to-Haskell friendliness. I hope I achieved this. In terms of performance, it seems to come out a little bit faster than `monad-logger` at runtime - but nothing to write home about. We're both in the same ballpark (according to [these](https://github.com/ocharles/logging-effect/blob/master/Benchmark.hs) hastily thrown together benchmarks). If you're thinking "why not just add this to `monad-logger`" - I contacted /u/snoyberg and we had a conversation about integrating these changes maybe a year or so ago. I think he was mostly in favour of them, but we didn't really reach any conclusion (my fault, I let the conversation die!). This library might vanish at some point and be absorbed by `monad-logger`. But in the meantime, I wanted to have a play around and see what this would look like "in the real world". It's a fairly big change to `monad-logger` which already has its share of users, so this felt like the fastest way to start playing with things.
He's definitely changed his mind. Heard him talk last year, and he very strongly advocates using only a subset of JS w/ a functional paradigm. For example, don't use `this` or `new`, return frozen objects that represent API's, etc.
[removed]
There are only four failure points to test in ex. 9: lookup, head, tail, maximum.
is the offer over? Must be in a different time zone or something. It's directing me to Clojure for Machine Learning. Who wants that =P
ex3-2 might need to be reworked a bit: the type of `cardSuits` is `[String]`, not `[Char]`.
That's a very good point -- I don't think books (and papers!) should skimp on code quality just because they are describing some higher-level concept. The code illustrations should still be high-enough quality that you would want to use them in real code.
OK, thank you for your suggestion.
I think there should be a generalized version that is language neutral especially if you're copying the Matasano crypto challenges model. I think people would have a much better chance of learning what monads are if they were able to implement them in the language that they know best. Having to know Haskell is a barrier to many if your sole purpose is to teach monads.
Glad to see this, since the world really needs more structured logging. I'd love to see an example (or another library) for using Aeson to json-format log messages with this library.
I'm so sad I missed this :'(
An `Integer` is just an integer, like the number 4. An `IO Integer` is a subroutine that does stuff (perhaps reads/writes values to/from the outside world) and then returns an `Integer` as its final result. An `Integer` (no-`IO`) is always the same value every time you use it, no matter how many times you run your program. An `IO Integer` may have a different final result each time you run it.
Indeed, that would make it better still.
Well I don't have a copy of the book around so I can provide no page/chapter as proof - but while reading it I saw hints of this a lot (I never said that this is a direct quote or something). To my memory this was a common thing to do in Java land for quite some time, where you always tried to keep the arguments to methods to a minimum. And yes I am aware that he is shifting towards FP (or seemed to be some time ago) but to be honest: I don't follow him (or others like him) to closely.
You can define your own `main` in a separate module with the full `Prelude` and run tests in that. Having tests is useful later in the series.
For http requests: https://hackage.haskell.org/package/wai-extra-3.0.14/docs/Network-Wai-Middleware-RequestLogger-JSON.html
[removed]
Nice! &gt; This library might vanish at some point and be absorbed by monad-logger Please let me know before you abandon this library, as by then people (I can see myself relying on this one) may have started to depend on your library... and would like to continue to do so!
If I remember it correctly, ldd cannot discover dependency if some one calls dlopen/dlsym
With the "* Remove CWD requirement from command-line tools" change it should work again AFAIU
How about this? let ath = addHeader . toStrict . toLazyByteString $ builder (newToken, newExp) in lift $ route (Proxy :: Proxy sublayout) (subserver sid uid) request (respond . mapRR ath) And yes, text-string-bytes-builders conversion should go elsewhere.
Without resorting to Template Haskell?
Oh don't worry, if it were to get subsumed by another library I will continue to maintain this one as a shim to whatever it becomes. But I don't think that will happen any time soon. Either way, never want to just leave users hanging (they are so hard to get, anyway!). Let me know if you run in to any problems using the library, or if you have API improvements.
Thanks! I thought about that. I was thinking about adding some more smarts to the hakyll code so it knows about the set/exercise structure and can automatically generate the link markup on the set pages. It seems like this kind of a change would go really well with an automatically generated next button. I probably won't be able to get to it any time soon, but pull requests welcome though! :)
This doesn't look right data WithTimestamp a = WithTimestamp {discardTimestamp :: a -- ^ Retireve the time a message was logged. ,msgTimestamp :: UTCTime -- ^ View the underlying message. }
tooling can remove trivial issues. not real issues. with or without global version, your ecosystem is fragmented. Having a process that craft a (not the) point of reference is orthogonal to the issue you mention. I am not sure what the problem will be when the community (you mean the package set ?) gets bigger and bigger..
I was having this problem: $ cabal install &lt;snip&gt; src/MCPrelude.hs:99:5: Not in scope: `undefined' cabal: Error: some packages failed to install: monad-challenges-0.1.0.0 failed during the building phase. The exception was: ExitFailure 1 I commented out the "undefined" export in that file, and then `cabal install` worked.
I would have to agree. Thanks, fixed and re-uploaded documentation.
While it is structured, I don't think there's enough structure to be entirely meaningful to Haskell programs - it's not particularly Haskell like to start inspecting a JSON AST when you could just work with the underlying data. Other than that, looks like a great library!
Oh! Hur dur, that makes total sense. :) Thanks! Might be worth a note in the instructions, /u/mightybyte ?
Actually he has added a note on now to test your code - at the bottom in the "Getting Started" section http://mightybyte.github.io/monad-challenges/
Cool!
I'm just evaluating expressions: *Set1 λ randLetter (mkSeed 1) ('l',Seed {unSeed = 16807}) *Set1 λ randEven (mkSeed 1) (33614,Seed {unSeed = 16807}) 
Well, the metaphor of box is really good, I can understand it and I really appreciate it, but to tell the truth, I've read articles about monad before. So I can't tell whether it's easy to understand for your students.
&gt; logMessage (WithSeverity Informational "Don't mind me") That's pretty verbose. I'm not going to want to write that. I'd rather some convenience functions to give you: &gt; info "Don't mind me"
Yep. I don't think the `UnicodeSyntax` extension actually affects what's considered valid identifiers.
Yes, that is how we have things set up, as a feature. It means we get compile-time type safety for interpolated values and logic in our HTML/CSS/JS. In particular, a large class of XSS attacks are statically guaranteed not to exist. You can also render Shakespearean templates at runtime. And we do that in certain places in our apps, because we are forced to. But you lose a lot of the killer features of compile-time templates. We definitely prefer compile-time.
I think he means 5 lines per equation.
thanks for looking over it, im sure there's lots of optimizations that can be done as this is my first haskell project. feel free to do a pull request with improvements and ill gladly merge them into my code.
Both Teχ and troff/eqn are pretty good, once you get used to them. Not as easy as handwriting, but you get better looking output.
Also, is there a reason it's called "logMessage" rather than just "log"? Does "Message" add any useful information?
It's likely that you can relax that constraint and still have it work. It's probably only set to `&gt;= 4.8` because that's what `cabal init` generated.
_ugh_ that makes me angry.
In general, I like following DRY (don't repeat yourself). If there seems to be code that is called many times in same way, there's likely a way dissolve that repetition. More pointers: * No need for the "do" in main, it's already in the monad. * Put a space between the classes and the values. i.e `IO ()` rather than `IO()`. The first looks like a type and the second looks like a weird function call. Consider that `IO a` is reasonable and `IOa` is a bug. * I would parameterize Grid with a type, so you could have different grid types rather than using [[x]]. * As for randomShape. Consider [this](http://stackoverflow.com/questions/11811498/generate-a-random-value-from-a-user-defined-data-type-in-haskell) answer using Bounded and such. BTW, official Tetris rules state that shape choice is "shuffle the 7 shapes" as the 7 next shapes and so on. So you might want a different approach for choosing shapes :) Could be a nice exercise too. * fullLine, I would use `fullLine = all isJust` instead of filtering and comparing. * Several magic numbers, the number 10 specifically, is used in the code, even though the constant exists. * `(grid !! x) !! y` is a bit scary, can raise an exception and break your code. I'm not sure if there's anything better to do in a non-dependent type though. * The score function has a lot of parentheses. You want the amount of fullLines. `length $ filter fullLine state` would be good enough for the counting part. The `product $ replicate 2` part seems to be just squaring the result. So `score state = x * x where x = length $ filter fullLine state` should be the same. * Instead of `tail (tail (tail (tail rows)))` you can use `drop 4 rows`. Hoogle is your friend for these functions :)
Some feedback: Having done 1.1, a little link to 1.2 would be nice, instead of having to go back, and then down again. Also, under 'Generalizing Pairs Even More', I've no idea what I'm being asked for. A type signature would be helpful, but might give the game away. I can't think of an easy way to hex-decode something off the top of my head. Would base64 be more accessible? Rebindable syntax has eaten ifThenElse, which I wanted to use for lookupMay Deriving Eq on Maybe in Set2 would make those tests copy-pastable. (Not that you can't anyway, but people may not realise)
An interesting experiment is to enter the type `Maybe a-&gt; Maybe b-&gt; Maybe b` in Djinn and see what you get. 
Really cool! I'm working through them, but got stuck at 1.4 when writing generalB. It's not clear to me what exactly it should do, is there any way you could add it's type to the exercise?
You're right! I totally wasn't trying to come off dogmatic - my bad. I don't have time to write those (nor would they be any good if I did :p) Thanks for putting these out there. I like what you've done! 
You're not, generally speaking. `mapLogMessage` needs to choose *something* to interpret your original `logMessage` calls, and using `LoggingT` is sufficient (and looking at benchmarks about as performent as we can hope for). This is the pattern of handling effects in the `mtl`. Note that after calling this you'll be polymorphic once again. In practice this means that the `LoggingT` layer you're seeing in the type doesn't actually end up reaching your code at all. For example: logA :: MonadLog String m =&gt; m () logA = logMessage "Hello!" logB :: MonadLog Int m =&gt; m () logB = logMessage 42 logAandB :: MonadLog (Either String Int) m =&gt; m () logAandB = do mapLogMessage Left logA mapLogMessage Right logB Notice how that even though we used `mapLogMessage` (twice!) at no point did we have to really think about that or notice it.
Welcome, comrade!
If I had to give the first two arguments to `foldr`a slightly longer name, I would go with 'nil' and 'cons'. Suppose for a moment that the built-in list type had constructors `Nil` and `Cons`, then the definition of `foldr` would be: foldr nil cons Nil = nil foldr nil cons (Cons x xs) = cons x (foldr nil cons xs) or maybe even foldr nil cons = go where go Nil = nil go (Cons x xs) = cons x (go xs) which makes the whole 'replacing the constructors by the supplied functions' thing pretty obvious. But this is still an idiom, I suppose...
It does build with stack, I can't believe they downvoted you for this :|
The above problem is exactly why I started using stack instead of cabal. I never knew how to resolve the "rejected base" error. It's just not something I want to have to deal with regularly when sitting down to a new codebase. And it was coming up a lot with almost every haskell repo I cloned onto my local machine.
One reason to consider functors and applicatives is that they are widely used to implement the types of functions you are asking for in the tutorial. I feel like omitting to teach these forces you to reimplement common patterns over and over again. Instead, they should implement those patterns and learn to use them, along with learning how all of them relate to each other. I got the general feeling of working a level too low and missing these great abstractions. For example, the generalized `rand` functions become very easy to write using `fmap`, and the `randPair` function can be easily written using the combination of `&lt;$&gt;` and `&lt;*&gt;`.
probably just the last few cabal die-hards... we all know Stack is the better tool, so just ignore them ¯\\\_(ツ)\_/¯
No summary here or on the video? Please help. I want to know if it's worth investing 50 minutes.
I think that I will try stack and see if with that compile :) 
When I was first learning haskell, I went through the LYAH book online. I could understand what `Functor` did pretty easily. When it got to `Applicative`, I did not understand why anyone would want that. For me, `Monad` was much more understandable than `Applicative`, larger because I could see more motivating cases for it.
You probably want to remove gui.glade~ from the repo.
I think either way is fine. I learned how to use Monads before Applicatives, and I don't think I had a worse time than if I went through Applicatives first. Learning the latter afterwards was rather trivial, too.
I've added those combinators here: https://github.com/ocharles/logging-effect/blob/master/src/Control/Monad/Log.hs#L209 Hopefully you don't object to the `log` prefix too much (it's consistent, as we can't have names like `error`)
You should definitely go with `servant-foreign`, just as Julian said. It won't change immediately and it'll most likely answer your needs.
One thing that struck me was the use of the infix composition function `.` without separating spaces (i.e., `test = head.tail` vs `test2 = head . tail`). Outside of this book, I haven't come across this before. While the code compiles just fine, I feel that using the `.` infix function without spaces looks like using an OOP method or accessing object properties in Javascript etc. Having said that, I am very happy that I could pick up this book for free! I think it should be very useful for me.
Yea, I keep forgetting to escape those. Fixed and will be in the next release.
I enjoyed reading your post. I have to agree though about the use of sum types to increase safety. Type synonyms are quite nice for self documenting code (i.e. pretty type signatures). Other than that, they don't really really provide us with additional safety. For example, take two type synonyms for the units metre and feet, `type Metre = Double`, `type Foot = Double`. The type system does not stop us from doing arithmetic with different units - GHCi&gt; let distance1 = 30 :: Metre GHCi&gt; let distance2 = 20 :: Foot GHCi&gt; let distance3 = distance1 + distance2 GHCi&gt; distance3 50.0 This is obviously not ideal since adding feet to metres makes little sense in most cases. Also, having type synonyms for `Char` means that many of your functions will be partial functions (i.e., a function expecting an `'A'`, `'T'`, `'C'` or `'G'` will have a run-time error if given any other `Char`. 
`servant-foreign` sounds very interesting; could someone elaborate a bit on its characteristics?
My book says the same. You make a good point. I think it doesn't reduce the complexity of understanding what the function is doing by moving a parameter into a field just so it can have one parameter instead of two. Now we have some sort of temporal coupling with regard to what modifies the state of the StringBuffer and when as opposed to having a pure function with two parameters.
This problem should be fixed now.
Great! I'm glad you like it. I put it out there in this rough state precisely because I'm hoping other people will be interested in adding more to it. I have a shortage of time right now, so I'm very willing to bring more people in to work on the project.
Unf I missed it :/
There's some posts on my blog that deal with vanilla and (slightly) exotic derivatives pricing via PDEs; also a post on estimating stochastic volatility. https://idontgetoutmuch.wordpress.com/2015/03/11/stochastic-volatility/ https://idontgetoutmuch.wordpress.com/2013/01/05/option-pricing-using-haskell-parallel-arrays/ https://idontgetoutmuch.wordpress.com/2013/02/10/parallelising-path-dependent-options-in-haskell-2/ But finance is a large field. Do you have a specific interest?
Unfortunately this is one of lowers quality programming books I have approch . In sample find online there are so many errors it makes you wonder. http://cdn.oreillystatic.com/oreilly/booksamplers/packt/9781783988723_Sample.pdf Just to name few I found. -- First example in book sum = foldr (+) 0 -- Funny prototype class TemplateAlgorithm where setup :: IO a → a teardown :: IO a → a doWork :: a → a fulfillPurpose = do setup doWork teardown And monads are explained in way without any type definitions, monad laws, but with example evaluator, for handling erorrrs, using custom Either monad. 
You should be able to reuse the `FromField` instance for `Int`. instance FromField Role where fromField field mdata = do x &lt;- fromField field mdata case x :: Int of 1 -&gt; return Staff 2 -&gt; return Student _ -&gt; mzero 
ok .. that is sad :( Maybe someone should put a warning on HaskellWiki or remove the reference - after all there are lot's of good books out that are not mentioned there... 
This looks like pretty printing. So, yes?
Yeah, I just went through the sample as well... It takes some common OOP patterns, like the Iterator pattern, and then says "Haskell uses `map`for that: (code example)". That's it. Like, what's the point?
I was more interested in the later parts which seemed to capture some *advanced* topics but yes (reminds me of http://de.slideshare.net/MarcoYuen/clipboards/fp-patterns)
If you have any questions, I'm happy to answer them!
I see no problems with porting this. Why do you think there may be a problem with haskell?
Good idea. Azure can do Linux too, of course. I wonder if Haskell.org is eligible.
We should qualify as a charity. It isn't clear that there are any other restrictions. The real question is if we can make sufficient use of the resources to be worth the headaches.
Because I try to do the same witht the boxes library. I have not looked at the actual code. I think I need lots of datatypes. Correct ? 
Do you have a example how do add these to the code. IM just a beginner with a wild idea 
Thanks so much for writing this up. This is an extremely helpful piece of information in a largely undocumented area.
I would recommend jumping over to the streaming-commons library instead to get slightly easier handling than you get in the process package. conduit-extra provides a nice conduit interface on top of that. Here's an example which uses the `curl` executable and prints out the byte size of the output. It closes stdin before opening the child process, and lets stderr go to the console. #!/usr/bin/env stack -- stack --resolver lts-4.1 runghc --package conduit-extra import qualified Data.ByteString as S import Data.Conduit (($$)) import qualified Data.Conduit.List as CL import Data.Conduit.Process (ClosedStream (..), Inherited (..), proc, withCheckedProcess) main :: IO () main = withCheckedProcess (proc "curl" ["http://www.yesodweb.com"]) $ \ClosedStream src Inherited -&gt; (src $$ CL.fold (\x bs -&gt; x + S.length bs) 0) &gt;&gt;= print A full tutorial is available at: https://www.schoolofhaskell.com/user/snoyberg/library-documentation/data-conduit-process __EDIT__ Just to clarify, I think the best approach is using pure Haskell code like /u/alexbiehl mentioned. But if you'll be shelling out, this is how I'd do it.
Thank you very much :)
Well yes, there's usually a lot of functions with the same signature, unless you have very very restricted domains. That's why you need laws for type classes, not just type signatures. Another, IMHO somewhat more striking example comes from monoids - what should `mappend 2 3` be? 5? 6? 2? 3? All of these would be valid results for some monoid implementation, which is why there isn't one for numbers by default, instead there is one for specialized newtypes `Sum`,`Product`,`First` and `Last`.
Adding sliders to code is such a useful idea - the domain that I really want sliders for is 3D CSG modeling, i.e., IHaskell support for the [`implicit`](https://hackage.haskell.org/package/implicit) package. I haven't found support (from googling) in Jupyter for OpenSCAD or STL files, but `implicit` does have a `writeTHREEJS` option, so maybe adding support to IHaskell is feasible.
If it is not a coincidence that all the inner lists you are using have the same length, you could define something like in [linear](https://hackage.haskell.org/package/linear): data V5 a = V5 { _1 :: !a, _2 :: !a, _3 :: !a, _4 :: !a, _5 :: !a } and a `Vector (V5 a)` would give constant access to every element. If the fact that the second list has 5 elements too is not a coincidence, you could even have a matrix : type M55 a = V5 (V5 a) and have even nicer properties.
 type Var a = Path ((:) * a ([] *)) What percentage of Haskellers can decipher that?
Here's an answer to your first point at least. You want to start with System.Process. The most general way to start processes is `createProcess`, but I think there are some other more specialised versions of that function the module. It has a bit of an odd API in that the return contains file handles wrapped in Maybes. Basically, the Maybe will be a Just if you asked for that stream and Nothing otherwise. Here's an example that runs curl but adds a few headers to the argument list. runCurl :: PandaAccessToken -&gt; [String] -&gt; IO ExitCode runCurl accessToken curlArgs = do requestId &lt;- Data.UUID.toText &lt;$&gt; Data.UUID.V4.nextRandom let authHeader = "Authorization: Bearer " ++ (T.unpack $ access_token accessToken) requestIdHeader = "RequestId:" ++ (T.unpack requestId) curlArgs' = "--header" : authHeader : "--header" : requestIdHeader : curlArgs cmd = (proc "curl" curlArgs') { std_in = Inherit , std_out = Inherit , std_err = Inherit } (Nothing, Nothing, Nothing, handle) &lt;- createProcess cmd waitForProcess handle I asked that all the streams were just piped to my processes' standard out so I'm expecting Nothings back. You could pass `CreatePipe`instead to get a new handle. 
Excellent! Thanks, this is a very clear explanation.
Thanks! Among other things, it was [your question](https://github.com/clash-lang/ghc-typelits-natnormalise/issues/1) about implementing GCD that provided an incentive to write about type-checker plugins in the first place :-)
Why not take a stab at it and if you have specific questions, you have this reddit. 
94% of that document is proof... that's amazing :)
&gt; Then there are the usual stream libraries (pipe and conduit) that might be a lot more handy if you are used to that kind of stuff. I wrote [pipes-cliff](https://www.stackage.org/package/pipes-cliff) for just this sort of situation.
Because `foldr` is not tail recursive. Later on (page 6) author also explains why `foldl` is better to use that `foldr`, but he still forgets to mention `foldl'`. Technically it is not wrong, but it isn't kind of practice author tries to promote. [https://wiki.haskell.org/Foldr_Foldl_Foldl'](https://wiki.haskell.org/Foldr_Foldl_Foldl')
I hope and intend that aeson 0.11 will fix the regressions introduced in 0.10, thanks in large part to some carefully put-together pull requests by other people (thank you all!). It would definitely be helpful to have the Stackage maintainers give it a whirl once it's close to ready, as honestly they're better placed to have an overview of all the downstreams that may be affected by changes in 0.11 than I am.
While Haskell does have regex libraries, it's almost universally agreed that the parser combinator libraries are far better. Could you elaborate a bit more on what you need?
The class you need is called `Foldable` (or `MonoFoldable`, or `ListLike`). You can call `toList` on your data structure, and then almost any library can deal with a list. I understand that this is not what you had in mind, but really, it's one function call away, so surely this shouldn't be the criterion by which you choose a regex library. People asked me several times about generalizing functions in regex-applicative in this way (and I once thought it was a good idea myself), but there's not much gain. There might be performance benefits to specialize to `Text`/`ByteString`/`Vector`, but this doesn't apply to generic "custom containers".
Thanks for the quick response! As you guessed already I'd like to not convert the custom container (which btw is an implementation of the so called piece table data structure) to a list for every regex call, for premature optimization reasons. And I agree, it shouldn't be my first criterion for choosing a regex library, but then again I don't have any other criterion so far ;)
&gt; modify that global state I do not think you are allowed to say such words here…
This paper looks great, I look forward to reading it in detail. Also, I love so much the amount of effort and detail put into the proofs.
What's the release date on .5 and can we find a changelog anywhere? 
Your post is showing up as 404 for me. 
Alright, I'll ask there tomorrow. Azure does provide Linux VMs, not just Windows.
Sorry to hijack, but, about regex-applicative. How do you write [\^abc]?
Why? 
In my mind, you should be able to do something like that at the IDE level. The code obviously doesn't need those tags to work, so an IDE-level implementation would let you do that sort of tagging, and toggle it on or off depending on coder preference.
The repl could display it either way, but there's no reason the code shouldn't use it. Semantically it could bind the proper variable to that name, taking a role similar to the @ operator in pattern matching. 
O(4) == O(1)
Can someone explain the role of these simplified web frameworks like scotty and spock? It's like 40 lines of fairly understandable code or so in yesod to setup a minimal hello world web page. Why is the "small web app" task not subsumed by a small yesod project? What am I missing out on?
When you are just putting up an endpoint, yesod is massive overkill.
you don't have to use all of it, and as far as I can tell yesod can start almost as small w/ ~ 40 LOC or so. As I mention below, working in the repl, I barely notice compilation time as I iterate. Not trying to be difficult, just trying to understand what the cost of "overkill" is from this perspective.
I'm not saying they shouldn't exist. I'm saying, I don't get it, I want to understand what I'm missing out on.
I can't speak for anyone else, but when I first started learning Haskell, I wanted to see what web development looked like, and yesod seemed like an intimidating arena to step into. Perhaps others want something really quick and with a short learning curve to set up?
Not particularly, except: 1. It's not particularly useful, when we have other features that overlap with the functionality it provides (note: OCaml has an OO system that no one uses, and I suspect an OO Haskell would be similar.) 2. It's a huge pain in the ass to work with formally and best avoided if you want to keep your formalisations simple. 3. It makes type inference much harder and type errors more confusing. 4. It's unclear how to make it interact cleanly with algebraic types (see Scala's "Some" constructor problem).
Haskell *does* have subtype polymorphism along class constraints. Both the sub classing system and that (C, D) satisfies C.
Haskell has some subtypes. For example, `Int -&gt; Int` is a subtype of `forall a. Num a =&gt; a -&gt; a` They are generally only available via existing polymorphism and to some extent via typeclasses as seen here. Subtypes of arbitrary data types definitely complicate type inference significantly, though, and also require variance annotations on polymorphic ADTs which make them more verbose and potentially less useful. For example, if `A &lt; B &lt; C`, and I have an object of type `Maybe B`, might it contain an `A` or a `C`? Which, and how can we tell from the definition of `Maybe`? Might it depend on the consumer of this object? For example, is a function of type `Maybe B -&gt; Maybe B` covariant on the left and contravariant on the right? What about `Reader r a`?
I'm curious. Could you (or someone else) elaborate on your fourth point, please? What is Scala's `Some` constructor problem?
Does that syntactic sugar for a type-level singleton list actually exist? Or is that what you're asking?
It does exist.
Not necessarily. For example, if `A &lt; B &lt; C`, then `(B -&gt; Int) &lt; (A -&gt; Int)`, that is, if you need a function from `A -&gt; Int`, a function `B -&gt; Int` will do (since it's getting passed in `A`s, which are obviously also `B`s.) You need notation on `Maybe` to tell which of these it is. It gets even more complicated when you add mutation to the mix; is `IORef B &lt; IORef C` or vice versa? Both cause problems (this is the `List&lt;Cat&gt; &lt; List&lt;Animal&gt;` problem, if it is and the list is mutable, then you can upcast to animal and add a Dog)
Perhaps it has to do with the necessity of making `Option` covariant in its type variable, `Option[+A]`, so that `None[Nothing]` (where `Nothing` is Scala's bottom type) will have the same type as a corresponding `Some[A]` instance.
Ocaml's OO system is very rarely used but you see [Polymorphic variants](https://realworldocaml.org/v1/en/html/variants.html#polymorphic-variants), from time to time, which are built on the same underlying type-system feature (row polymorphism)
Yup!
If you're willing to use scott encodings you can implement some fun subtyping examples: http://cs.unm.edu/~stelleg/subtypes/ There are serious limitations though, e.g. broken impredicativity, so you should really not use it for anything.
Um, sorry, but there were two questions. Which were you saying yes to?
personally I don't want to spent my time trying to understand all the Yesod/TH parts for my smallish projects. And I could pick up Scotty in a couple of minutes without reading blogs/books/... plus it was very easy to build up on this. Of course it's harder to do more specialized things but that is fine with me. For the same reason I still use knockout over something like angular - for the stuff I have to do it's fine and you can learn it in a few hours max. 
&gt;Powered by Safe Haskell I wouldn't rely on Safe Haskell alone for security. I was poking around at it last year and found multiple vulnerabilities fairly quickly. In discussing them with others, I got the impression that maintenance on this feature isn't keeping up as GHC continues to evolve. "No one really uses it", so it's not seen as a serious concern&amp;mdash;there isn't even a procedure in place for reporting security-sensitive bugs in GHC.
I'm also stuck at that. I'm not sure to understand &gt; pass in a function that does the constructing What does that mean? e.g. for a `Gen BlogPost`... a `x -&gt; Gen BlogPost` or a `Gen x -&gt; Gen BlogPost`? 
That's a shame.
This is a fantastically clear example. 
I used to be an academic and have written such papers, though none with proofs quite this long (I think they maxed out at 50 pages or so). So when I see a paper like this I see the amount of blood, sweat and tears that went into it :) 
This is also not working : http://lpaste.net/150311
If you use "typeclasses" (implicits) in Scala, the type inferencer will get in your way. `Some(42)` is of type `Some[Int]` not `Option[Int]` so you won't get any of your instances.
Oh man, we could *definitely* use some build farms for stuff like fully automatic bounds pushing, so that a package maintainer can provide meaningful starting bounds, but the system goes through all possible permutations (this probably gets pruned quickly by bounds that do not compile) to expand these.
One advantage is that you can use typeclasses to combine different parts of the DSL very easily, and don't have to write the sum logic by hand. Example: class Lambda repr where lam :: (repr a -&gt; repr b) -&gt; repr (a-&gt;b) app :: repr (a-&gt;b) -&gt; repr a -&gt; repr b class Expr repr where int :: Int -&gt; repr Int add :: repr Int -&gt; repr Int -&gt; repr Int simpleExp :: Expr repr =&gt; repr Int simpleExp = (int 10) `add` (int 20) add10 :: (Expr repr, Lambda repr) =&gt; repr (Int -&gt; Int) add10 = lam $ add (int 10) This compiles without any extensions
Isn't that technique the same as [functional unparsing (PDF)](http://www.brics.dk/RS/98/12/BRICS-RS-98-12.pdf)?
hmm, I wonder if I need then accountRow if I can send the data direct to the lefrRight function. 
I have the impression you can do that.
I think the question was about what the abbreviation "MOOC" itself stands for. It's "massively open online course" or somesuch.
&gt; in non-pure languages, subtyping also causes issues with variance Real languages usually have no variance, hence, no issue (Java arrays is one brain-dead exception). &gt; you just have a function Candy -&gt; Thing Let's go for a classic semi-realistic example: a geometry editor. You have a list of shapes. A shape can be a triangle, a circle, or whatever. How do you write a `Triangle -&gt; Shape` function? What would you do with the resulting `Shape`?
One really big advantage is that you can use the tagless final terms as a generic term type, and then convert that to both a value for evaluation, and a string for pretty printing, with no effort. Suppose we're using /u/jfmueller's example, then it's simple enough to do: instance Expr Id where int n = Id n add (Id x) (Id y) = Id (x + y) instance Expr (Const String) where int n = Const (show n) add (Const x) (Const y) = "(" ++ x ++ " + " ++ y ++ ")" Now if you have some term, let's say foo :: Expr repr =&gt; repr Int foo = ((int 1) `add` (int 2)) `add` int 3 You can both evaluate it and print it by just specifying what `repr` is: foo :: Id Int ~&gt; Id 6 foo :: Const String Int ~&gt; Const "(1 + 2) + 3" I believe I've also seen work that extends this also to ***type checking***, but I'm not sure if it's exactly a tagless final approach. I forget. https://www.youtube.com/watch?v=R5NMX8FBlWU
FRP might be a nice approach, but you probably still have to do a lot of low level work as well. I think the ideal combination there would be a low level framework that knows how to parse into a high-level structure (for example, if you have TCP streams, maybe applying `attoparsec` to them, and then pushing the results into an FRP network). It might be possible to do the low-level stuff in the FRP network, but it feels like the wrong place and I imagine could well get pretty hairy.
If you're going to be calling wget via the shell, you should take a look at [Turtle](http://hackage.haskell.org/package/turtle). _Edit:_ Formatting and grammar
It's not really subtype polymorphism. You cannot have a `[Show a =&gt; a]` for example. (Unless you use -XImpredicativeTypes, but even then it won't work like you would expect). You can have `Show a =&gt; [a]` but that's not the same. 
So I just switched from vim to emacs. Haskell mode seems awesome but I don't use cabal anymore and the Haskell mode setup tutorial has huge dependencies on cabal for its syntax checking and other features. Is there a tutorial for how to replace the cabal functions with stack functions?
Here, I made an example of use of this library for you: import Text.PrettyPrint.Boxes vDiv :: Int -&gt; Box vDiv n = vcat left (replicate n (char '|')) hDiv :: Int -&gt; Box hDiv n = hcat left (replicate n (char '-')) surround :: Box -&gt; Box surround box = let r = rows box c = cols box in (char '+' &lt;&gt; hDiv c &lt;&gt; char '+') // (vDiv r &lt;&gt; box &lt;&gt; vDiv r ) // (char '+' &lt;&gt; hDiv c &lt;&gt; char '+') Using it in ghci: λ printBox $ surround (text "Hello!") +------+ |Hello!| +------+ λ printBox $ surround (text "Hello!" // text "Bye!") +------+ |Hello!| |Bye! | +------+ 
oke, What if I want to print Helloi and Bye in seperate boxes. As far I understand I have to use a list [ "hello", "byee" ] I see that you use rows and cols box. How does these know if you want 1 or 2 boxes 
&gt; write the sum logic by hand. And it is plain Haskell '98! 
If you are interested in this sort of thing, I highly recommend getting active on the #haskell-infrastructure channel on freenode.
Maintaining `Safe` haskell in a warning-free way constituted an embarassingly large percentage of my development time. I mostly gave up even trying to maintain it, as if I mark a module `Trustworthy` and it infers as `Safe` I give my users a warning, but then upstream packages flip between `Unsafe` to `Safe` on a fairly regular basis, even on patch level releases that I can't detect, so I need to consider the full set of possible upstream versions, even ones that haven't been released yet or which I can't detect -- and getting that information comes in the form of running the haddocks at the end and looking at one configuration in that explosively large state, not a very useful development process. And even if I get the `Unsafe` failure mode I don't usually get told why in an actionable way. Finally, we all make mistakes. I've claimed `Trustworthy` on code that isn't before. Now what? I can't do a maintenance release on hackage for that code -- that isn't something I can edit in the cabal file! I can ship a revision that turns off the affected versions of the package entirely of course, but what if they are in LTS? Consequently, I've taken only to putting explicit `Unsafe` tags in, or when I use an explicitly known `Unsafe` API in a `Trustworthy` way, I'll notify about that. Then the fact that `coerce` isn't considered Safe forces a choice between speed and safety.
&gt; I still use knockout over something like angular Hehe, same.
&gt; You are a beautiful person making a beautiful web site.
Every time you combine two boxes is becomes just one. For example, you could have something similar to two separate boxes with: λ printBox $ surround (text "Hello!") &lt;&gt; surround (text "Bye!") But you would have two divisors between each pair of boxes. Try it! If you want to have something that put just one divisor between boxes, you could make a function with type `surroundList :: [Box] -&gt; Box` which would concatenate them vertically introducing divisors. Try to make it, using my function as a model!
Here's a key for manual translation: /a/ =&gt; char 'a' /abcd/ =&gt; string "abcd" sequence [ char 'a', char 'b', char 'c', char 'd' ] (:) &lt;$&gt; char 'a' &lt;*&gt; string "bcd" (++) &lt;$&gt; string "ab" &lt;*&gt; string "cd" /[abcd]/ =&gt; oneOf "abcd" /[^abcd]/ =&gt; noneOf "abcd" /[a-z]/ =&gt; oneOf ['a'..'z'] /[^a-z]/ =&gt; noneOf ['a'..'z'] /a*/ =&gt; many (char 'a') /a+/ =&gt; many1 (char 'a') /a?/ =&gt; optionMaybe (char 'a') /(abcd)*/ =&gt; many (try $ string "abcd") /(abcd)+/ =&gt; many1 (try $ string "abcd") /(abcd)?/ =&gt; optionMaybe (try $ string "abcd") /a|b/ =&gt; char 'a' &lt;|&gt; char 'b' /$/ =&gt; eof /(?=abcd)/ =&gt; lookAhead (try $ string "abcd") /(?!abcd)/ =&gt; notFollowedBy (string "abcd") 
And it ensures exhaustive case handling.
yeah FP101x was a let-down - had so high hopes `14 and even volunteered some labs conversations but the material and the handling of the community was a huge disappointment in the end. The OCAML course was way better ... but I guess you already know that ;) Looking forward to see you in yet another fp-mooc-forum this autumn :D
What exactly do you want to do?
I've been told they have had PLENTY of response from volunteers. Thanks, everyone!
Thank you so much, this is great tool. The most frequently used feature for me and my colleagues (who do the first steps into haskell) is to get the type of an expression. It is usually bound to a hotkey and really easy to use and helps to understand haskell concepts faster. To work with GHC 7.10.3 I changed stack.yaml to - cabal-helper-0.6.3.1 resolver: lts-4.2 GHC-MOD compiles happily and works.
Do you have an opinion on something like [conduit](https://hackage.haskell.org/package/conduit-extra-1.1.9.2/docs/Data-Conduit-Network.html)?
Great writeup, and lots of really good (and honestly tedious) work involved. Thank you!
Well, to make the lib for the first time, you mean, right? But after it is done it could be abstracted away for good, I hope so.
And if you're in Scotland on Tuesday 9th February then one of the MOOC designers, Jeremy Singer, is presenting a preview of it in Edinburgh to garner feedback: **Title** Developing a Haskell MOOC https://opentechcalendar.co.uk/event/3613-developing-a-haskell-mooc
The biggest help would be a volunteer to help clean up our builder infrastructure by improving the codebase and making it more easy to monitor and more resilient -- we have plans in that regards, but hands-on-deck are in short supply.
Spock does everything I need from a web framework, except for persistence and templating where I'm not too fond of Yesod's library choices anyways. I'd either have to spend time replacing the parts I don't like, or wire up a lot of features myself on top of the minimal Yesod template. Spock is also easier to understand and work with, IMO. Less TH and generated code is one advantage. I'm also not too fond of Yesod's documentation, and frequently got stuck on basics that weren't covered either in the book or the API docs. My go-to used to be Snap, but Spock gives me type safe routing out of the box and isn't stuck in limbo with a major update pending for 2+ years.
Is there a development package for the Haskell-ide-engine emacs mode. I would love try that out and maybe help out. 
You can have `[exists a. Show a =&gt; a]`, with `ExistentialQuantification`, but you don’t spell it that way. For those unfamiliar: data SomeShow = forall a. Show a =&gt; SomeShow a instance Show SomeShow where show (SomeShow x) = show x map show [ SomeShow (1 :: Int) , SomeShow "two" , SomeShow (3.0 :: Double) ] (This is usually considered overkill.) 
One thing that has been hinted at here but not explicitly mentioned is that it allows types to be written that would typically require GADTs, but without enabling that extension. This makes it applicable in more languages as well as in implementations of Haskell without GADTs.
Makes sense. I don't think Microsoft are giving that for free though.
&gt; The OCAML course was way better ... but I guess you already know that Heh. Yeah, I liked 56002 a lot, and it wasn't just good, it was also quite different from the other FP MOOCs out there. I really hope that team does decide to go ahead and put together a follow-up class, or just some more unrelated CS goodness. &gt; Looking forward to see you in yet another fp-mooc-forum this autumn :D Same. :-)
Yes, with scoped type variables. {-# LANGUAGE ScopedTypeVariables #-} f :: forall a . a -&gt; [a] f a = b where b :: [a] b = [a] GHC can't figure out that you mean the same `a` unless you explicitly say so.
Yes, this is one method of having it.
How do you draw it? Can you show some code?
the demo was really interesting! thanks for sharing!
Why use an Eot representation over a Sop one?
&gt; what you might mean by this In C++ or D or other OO languages I know of, a `Bag&lt;Candy&gt;` is not a `Bag&lt;Thing&gt;`, so there's no problem. Some languages knowingly make their type systems unsound by making `Bag&lt;Candy&gt;` a kind of `Bag&lt;Thing&gt;`but I can't be held responsible for those. &gt; Here's perhaps a less obscure example. In your example, a file writer just contains a handle, like any other writer. So you can just extract a handle and pass it around. All the magic happens inside this Handle. Not very exciting. With your permission, let's concentrate on the shapes example. I used to program such things for a living so you can't say they are unrealistic. Can you extract a shape from a triangle? How would you implement that? If you insist on discussing a writer, show me how you use a writer that has no `Handle`. Perhaps it's a memory writer and handles are not relevant. Or perhaps it's a device that doesn't have the same kind of OS support like other devices, for whatever reason. Or maybe it's a transforming writer that mangles bytes before they hit the handle. How would you work with that?
Thanks. To celebrate I've released haskell-mode 13.18 today. I'll write about it in January Report.
I'd love if somebody gathered all the dispersed information and put it in our official manual: http://haskell.github.io/haskell-mode/manual/latest/ There is no way to update all the different blogs or scraps of elisp here and there. Please contribute directly to the project, thanks.
If a shape really is a super type, it must have less information than any subtype. Just take whatever attributes all subtypes have in common and that's the definition of shape. 
 data Shape = Shape { listOfPoints :: [Vec2] } data Triangle = Triangle { p1 :: Vec2, p2 :: Vec2, p3 :: Vec32} triangleToShape :: Triangle -&gt; Shape triangleToShape (Triangle p1 p2 p3) = Shape [p1,p2,p3] drawTriangle :: Triangle -&gt; IO () drawTriangle triangle = drawShape (triangleToShape triangle) drawShape :: Shape -&gt; IO () drawShape (Shape pts) = glBegin ... You can even write a shapeToTriangle function! shapeToTriangle :: Shape -&gt; Maybe Triangle shapeToTriangle (Shape pts) = case nub pts of [p1,p2,p3] -&gt; Just (Triangle p1 p2 p3) _ -&gt; Nothing This limits shapes to be polygons. But this limitation is easily lifted by making Shape into a sum type to support more exotic shapes.
&gt; This limits shapes to be polygons Exactly. Not too exciting. If I wanted to work with polygons, I would have a Polygon type, not a Shape. &gt; easily lifted by making Shape into a sum type That's the closed-world assumption. No new shapes can be easily added to a program. You will have to go over the code and review *all* the patterns and add the new stuff where appropriate. Then when you add more stuff to the sum type, you do it again. And again and again. Haskell has type classes, you will seriously want to use something like that very very quickly. And you can for the most part. You can create a `Shape` type class and put all the `draw` and `area` and `perimeter` and what not in it.
The situation gets even worse if you add in a universal `Any` super type like Scala does. That has been the source of so many "false negatives" (i.e. programs that shouldn't compile but still compile).
Indeed, the Shape type could look like data Shape = Shape { draw :: Graphics () ; area :: Double ; perimeter :: Double ; intersects :: Shape -&gt; Bool -- just a predicate ; intersection :: Shape -&gt; Shape -- that's a tricky one -- more stuff } Wait, that looks rather similar to a method dictionary of a type class. Why can't we use that instead of reinventing the wheel for the Nth time, poorly?
The main goal of `generics-eot` is that it's easy to understand. So if you're already comfortable with `generics-sop` there's little reason to switch.
 cabal install generics-eot Resolving dependencies... Downloading generics-eot-0.2... Configuring generics-eot-0.2... Building generics-eot-0.2... Preprocessing library generics-eot-0.2... ghc: could not execute: markdown-unlit Failed to install generics-eot-0.2 cabal: Error: some packages failed to install: generics-eot-0.2 failed during the building phase. The exception was: ExitFailure 1 :-(
data Shape = Shape {draw :: Diagram} using the diagrams library :-P
Dang! Just released version `0.2.1` to hackage. Can you try again?
I'm not sure I'm following your point. Of course typeclasses can be used to do this. The supertype is then just the existential quantification over a typeclass.
For modal dialogs there's /u/mightybyte's [modal](https://hackage.haskell.org/package/reflex-dom-contrib-0.3/docs/Reflex-Dom-Contrib-Widgets-Modal.html#v:modal) in reflex-dom-contrib. For validating I attach some styles to a field. For example in cochleagram I [parse an arithmetic expression](https://github.com/CBMM/cochleagram/blob/00eead23ad384a5a0aad6c7e54c1c7382d56be04/exec/Main.hs#L71-L82) from a field, and if it parses to a good value, put a green fringe around the field. I don't know how validation works in angular, but if there's something nice, maybe the idea could be ported over to reflex-dom?
Wait, you're working on that? That's my old topic. Email me papers and notes!
The point is, one can have subtypes in Haskell (with existential quantification), and I don't see any of the problems you've mentioned arising from it.
That makes me wonder if I could get a neat language design out of writing "subtype" relations in my type definitions that actually just auto-derive the relevant injectors according to a set of rules, which could then become instances of something like an "Upcast" typeclass with a transitivity law.
Checkout hindent some guy told me that's cool.
What are they waiting for rewriting the tutorial to use Stack rather than the obsolete cabal?!? ( ͠° ͟ʖ ͡°)
Just to compare this with other languages: Java,C#,Scala have F-Bounded Polymorphism (FBP). That is "tagless" in the sense that it lets you express demands for functions without mentioning the concrete type. Now, FBP is a broken logic with many holes, that I'm not sure even composes well, as Haskell's typeclasses do compose quite well. My only observatuon here is that FBP lets you "vary the backend" (or concrete type) subject to constraints, which the primary/main thing typeclasses lets you do. Of course, there is a reason quickcheck doesn't exist in Java with the same fidelity, because FBP is only a crippled form of parametric polymorphism. But it's interesting to note Java/C# encoding of FBP gives *some* of the same benefits, without having to read white papers.
You have to read a BOOK :)) You do not need to read a book to build a web app with spock, scotty etc. 
Awesome presentation! I loved the way you could clearly see the demarcation between syllables in the cochleagram.
While I think we all have high hopes for that project, if you notice the update history has been quite slow. Further, IIRC I personally did not find the networking layers sufficiently abstracted for my purposes. Specifically, I really did want the network to be completely orthogonal, hidden behind a sufficiently high abstraction such that all callers of the networking code needed was a basic send and basic receive.
[removed]
[Haste App](https://github.com/valderman/haste-compiler/blob/master/examples/haste-app/haste-app.hs) allows you to write server side and client side code at the same time. It's not quite automatic, (the client still has to query), but there is definitely no mundane networking stuff going on. In particular, server side operations are represented as functions, and the client can execute these functions. The framework automagically serializes the arguments, sends them to the server, has the server execute them, serialize the result, and send it back, all while keeping try of the different clients, and in such a way that the client side code can be compiled to javascript.
Isn't "either of tuples" a "un-jargoned" way of saying "sum of products"? What's the actual difference between the two?
Looking up "military shadowbox", I see that it's an expensive box in which to store military medals. I bet the domain has expired and has been bought by somebody who sells such boxes. Clearly part of the cottage industry called "niche websites" which works like this: 1. pick a product which ideally costs a lot but isn't bought by too many people (so competition is low) 1. make a website selling said product via an affiliate link (meaning you get a share of each sale made via that link) 1. funnel as many people as possible to your website by making it rank high on google. one approach to do so involves buying recently-expired domains that have a high "website authority" (high profile pages like wikipedia link to them so google ranks them higher), and having them link to your product website to make it rank higher. (my girlfriend has a [blog](http://livingoffcloud.com/) about building and buying niche websites)
Have you looked at process algebra? They're commonly used for abstracting this stuff on pen and paper.
Can I suggest a format more like [NICTA](https://github.com/NICTA/course), where you provide the instructions, type signatures, and tests in source files, and users just have to "fill in the blanks"? I find it easier to work through, with less context switching.
A recent commit has added the "two inputs" requirement... https://github.com/mightybyte/monad-challenges/commit/0b4481f3413730a6b258fbb3ad8ce4831c1a65b9 However, I think the examples are still a bit misleading. 
"Sum of products" as in `generics-sop` is really just a *single* n-ary sum of n-ary products, without nesting. "Either of tuples" may nest tuples and sums arbitrarily. `generics-sop` is kind of a normal form with all nesting information removed, and as a result it's nicer to work with (but uses GADTs and `[*]` which aren't as friendly to beginners).
I think this is really cool. It gives me shivers and I internally scream "NOOO THAT'S NOT WHAT a -&gt; b MEANS!" but I sorta-kinda like the idea very much anyway, since it's completely optional and makes the language slightly more powerful. The problem with type checkers is that they reject valid programs because they are inconclusive proofs of the types. If the user promises a program is valid, I don't see why we couldn't let it through (see also the similar situation with `unsafePerformIO` and friends.) I can even see a flag of some sort to tell the compiler "Don't warn me about this part. I know it looks odd but I assure you it works."
First of all, thank you very much, I'd love to hear more like these. Secondly, and this is an off-topic, iMovie has a great background-noise removal function, I just tried it on your video and it works fairly well. So may I suggest you doing that. Thanks again.
In general, because of ugly-looking typography and low-quality content.
I think his definition of gradual typing is slightly off. As I've always understood it, gradual typing is about the integration of typed and untyped modules of code (as in the canonical case of Racket), with the gradual typing "magic" generally happening at their interface. I would say that this idea of Richard's is more of a generalization of gradual typing, to a very fine-grained definition of interface. I'm not totally convinced that it would be useful, but I do think that it's an interesting idea that may warrant further research.
I don't have much against ST, but I don't like unsafe primitives. 
You’re going to have trouble composing such functions. `notSilly (notSilly True) :: String` doesn’t work, for example. 
&gt; I know it looks odd but I assure you it works. I know it looks odd, **but I take full responsibility**.
I don't think the requirement changed; they just made it clearer. In asking for `generalPair` to be made more general, it indicated the output should be more general, not the inputs `Gen a` and `Gen b`, and I don't think it implied that there should now be only 1 input, so it was still a function of 2 inputs (which each provide their own output). This further implies that they meant for us to change this type: Gen a -&gt; Gen b -&gt; Gen (a, b) ...to this one: (a -&gt; b -&gt; c) -&gt; Gen a -&gt; Gen b -&gt; Gen c And the way to do that was to remove the hard-coded tupling of the `Gen` outputs and replace it with a function call on the two outputs to do the merging thereof into the final output type.
&gt; It seems to me that your version is limited to type constructors that build a type from two others `(a -&gt; b -&gt; c)`. That's what it says to do (in the last paragraph [here](https://github.com/mightybyte/monad-challenges/blob/0b4481f3413730a6b258fbb3ad8ce4831c1a65b9/hakyll/pages/ex1-4.md)): &gt;All you need to do is pass in a function that does the constructing with two inputs. Remember that we were generalizing this type: generalPair :: Gen a -&gt; Gen b -&gt; Gen (a,b) However, we weren't getting rid of `Gen a` or `Gen b`; we were generalizing the output so it didn't have to be `Gen (a,b)`, but could be, e.g. `Gen String`. &gt;I do not see how this could work for a String, for example. The caller passes in the function, and so decides what the `c` type is. For example, I could pass in a function `g` of type `Int -&gt; Bool -&gt; String`, and then `generalB` would want `Gen`s that generated an Int and a Bool, and would give them to `g`, and get back a string. An example of such a function `g`: g i b = "The number " ++ show i ++ " is " ++ show b Example inputs (outputs from `Gen a` and `Gen b`, ultimately): 42, True. Example output: "The number 42 is True". If you gave `Gen`s that produced those outputs to `generalPair` instead, you'd get `(42,True)` out instead.
I'm assuming /u/tel was asking about the difference between `generics-eot` and `generics-sop`.
And with more recent extensions you can generic-ify this too. {-# LANGUAGE ConstraintKinds, ExistentialQuantification #-} data Has c = forall a. c a =&gt; Is a test :: [Has Show] test = [ Is (1 :: Int) , Is "two" , Is (3.0 :: Double) ] {-# LANGUAGE RankNTypes #-} with :: (forall a. c a =&gt; a -&gt; r) -&gt; Has c -&gt; r with f (Is a) = f a test2 = map (with show) test But you have to be pretty verbose with type annotations, the compiler is not good at guessing which `c` you mean for some object of type `Has c`.
Beware the links shouldn't have a '.' in them. Correct GitHub URL: https://github.com/snowleopard/shaking-up-ghc
It’s not the first time the author of TFA has accidentally reinvented a monad: https://www.reddit.com/r/programming/comments/66qbl/raganwald_reinvents_monads/?
Thank you for reading and commenting, your remark is true about the monad instance for lists and is welcomed
I don't understand what the exact interpretation of focalization should be. One natural idea is to view it as a syntax for Paul Levy's call-by-push-value, with values corresponding to positive types, computations corresponding to negative types, and the adjunction between them modelling the shift connectives. However, that's not the only game in town: other people, such as Guillaume Munch-Maccagnoni, have other ideas (in his case, that it arises from the notion of evaluation order), with correspondingly different models (though I don't understand the exact relation). 
If you're interested in a comparative study on efficiency, I'm more than happy to offer you a guest post on my blog so we can continue the conversation. What do you think?
&gt; The ideal number of arguments for a function is zero. That's almost certainly solid circumstantial evidence that the function participates in side effects (ex., Time.now()) unless it always returns the same value
But what about infinite lists? 
I think I read and re-read this chapter in LYAH for like 4 nights straight until I was too sleepy to continue (didn't take long) before it started to sink in. I'm not confident I can predict what you can understand, or where your confusion lies. One thing that strikes me though, is that you need to understand the do notation is only syntax sugar. So suppose we define a function that runs in a Reader Int monad - a Reader environment where an Int is available. The function will just get that value in the reader, and add it to a parameter. So a function defined: addReader :: Int -&gt; Reader Int Int addReader i = do r &lt;- ask return (i + r) Could also be defined: addReader i = ask &gt;&gt;= \r -&gt; return (r + i) You would use it in a program like this: main = do let n = runReader (addReader 5) 10 print n [prints 15] 10 is the value you are passing to the Reader environment which will be available by calling the ask function. edit: more explanation and context
Yeah, using `MultiParamTypeClasses` to do this is fairly common. Off the top of my head, the [`aws`](http://hackage.haskell.org/package/aws-0.13.0/docs/Aws-Core.html#t:Transaction) library uses it. You'll most likely also want to use `FunctionalDependencies` to change `RequestPair` to: class RequestPair a b | a -&gt; b where This tells the type system that every `a` has exactly one specific `b`, and if you have the `a`, you can determine the `b` based on that. So in your `f` example, if you changed it to f = request (GetUserIdByNameReq undefined undefined) Without the functional dependency, the type system wouldn't be sure what the type of `f` is, but with it, it'll infer the correct type because the `a` part is known. Another pattern for this is possible with `TypeFamilies`, providing semantics similar to `MultiParamTypeClasses`+`FunctionalDependencies`. class Request a where type Response a :: * instance Request GetUserIdByNameReq where type Response GetUserIdByNameReq = GetUserIdByNameRes request :: Request req =&gt; req -&gt; IO (Response req) In fact, this is what [`amazonka`](http://hackage.haskell.org/package/amazonka-core-1.3.7/docs/Network-AWS-Types.html#t:AWSRequest) uses.
I don't like the name `Flip` for this, if only because there is already a well-known existing [`Flip`](http://hackage.haskell.org/package/bifunctors-5.1/docs/Data-Bifunctor-Flip.html) that looks like this (unfortunately with the wrong kind for your application, but perhaps you can convince Ed to turn on kind polymorphism in the appropriate module): newtype Flip f x y = Flip { runFlip :: f y x } Together with a newtyped type-level application like newtype Apply f x = Apply { runApply :: f x } your thing might conceivably be implemented as `Flip Apply`. Or you could just keep your existing implementation and name it something else, like `FlipApply`. In any case, to answer your direct question, I don't know of a library that provides the exact newtype you're asking about.
Thanks for pointing out the already-existing `Flip` type. I definitely don't want to steal a name Ed's using. I think `FlipApply` sounds like an alright name, and think that would be nicer than two levels of newtype wrappers.
Or you can use a type function: {-# LANGUAGE KindSignatures, TypeFamilies, PolyKinds #-} type family Id (x :: k) :: k where Id x = x type Reversed = Flip Id Then `Reversed a f` resolves to `Flip Id a f`, which is isomorphic to `Id f a`, which resolves to `f a`. Edit: Except that doesn't work, because you can't partially apply type families...
When thinking about Reader, I find it helpful to remember that we're transforming the result of a function. This can be seen in the `Functor` instance, which essentially runs the transforming function (`f`) after the original function (`m`): instance Functor ((-&gt;) r) where map f m = f . m -- alternately: map f m = \r -&gt; f (m r) To define the `Monad` instance, we first recognize that `return` can lift a single value into the constant function that always returns that value. `(&gt;&gt;=)` is trickier, but if you follow the types you can start to make sense of it: h &gt;&gt;= f = _ (h :: m a) &gt;&gt;= (f :: a -&gt; m b) = (_ :: m b) (h :: r -&gt; a) &gt;&gt;= (f :: a -&gt; r -&gt; b) = (_ :: r -&gt; b) (h :: r -&gt; a) &gt;&gt;= (f :: a -&gt; r -&gt; b) = \r -&gt; (_ :: b) (h :: r -&gt; a) &gt;&gt;= (f :: a -&gt; r -&gt; b) = \r -&gt; f (_ :: a) (_ :: r) (h :: r -&gt; a) &gt;&gt;= (f :: a -&gt; r -&gt; b) = \r -&gt; f (h (_ :: r)) (_ :: r) (h :: r -&gt; a) &gt;&gt;= (f :: a -&gt; r -&gt; b) = \r -&gt; f (h r) r h &gt;&gt;= f = \r -&gt; f (h r) r So that's how we arrive at the definition (ignoring, for the moment, whether we follow the laws). So what can you use Reader for? We usually use it for reading values from the environment, as if it was a configuration file or a set of flags. For a simple/silly example, consider this data type: data Flags = Flags { enableFeatureX :: Bool, enableFeatureY :: Bool, backendServerAddress :: String} (Recall that the type of `enableFeatureX` is `Flags -&gt; Bool`, so these three functions can be used with `Monad ((-&gt;) Flags)`) With Reader we can write logic that reads many values from `Flags`, using either `do` notation: shouldOpenConnectionToBackend :: Flags -&gt; Bool shouldOpenConnectionToBackend = do enableX &lt;- enableFeatureX enableY &lt;- enableFeatureY return $ enableX || enableY Or by manually threading through calls to `(&gt;&gt;=)`, which is quite similar: shouldOpenConnectionToBackend' :: Flags -&gt; Bool shouldOpenConnectionToBackend' = enableFeatureX &gt;&gt;= (\enableX -&gt; enableFeatureY &gt;&gt;= (\enableY -&gt; (\_ -&gt; enableX || enableY))))
As stated in my blogpost, Iavor already hooked up an SMT solver to solve numeric constraints. I'm sure you can set it up to solve other constraints also. The problem lies in the annotations, as in, how do we assign refinement types to expressions?
Doesn't `unsafeCoerce` already achieve the goal of allowing users to promise the type checker they're doing something sensible?
Yes, but getting it wrong leads to a hard crash or insidious security bug rather than an exception.
&gt; Of course it's possible to fork projects, to remove or replace maintainers, etc., but these are awkward and embarrassing things to do to the original author of the software -- whom most people generally accept have a presumed (but not absolute) right to be in control over their own creation. It's like a little coup. It implies accusing the deposed government of illegitimacy. Ideally it wouldn't happen. But if people think that their control implies no social obligations to others it will have to happen. And forcibly taking away the commit bit from the author is better than forking? How about doing either one of those things without ever sending a single courtesy email to the author giving him the chance to respond?
Interesting how this is just observing that `($) = id` at the type level.
Check this video/channel https://youtu.be/Pt8osMv4Jao
To me it was a pretty big hint that the maintainer was busy! It never occurred to me that he just didn't look at the Github issues, and I was waiting for the release. I obviously agree with the second part of your comment.
So, `(-&gt;)` is of kind `* -&gt; * -&gt; *` and `Monad` of kind `(* -&gt; *) -&gt; Constraint`. Does `Constraint` live in `*`?
The decision has been made to roll LTS back to aeson 0.9. But as an additional data point, several more PRs have been merged into aeson to fix issues mentioned in this post. And /u/bos has implied that an aeson 0.11 release is imminent.
I know. I tested this a minute after posting, and edited my comment to point out that it doesn't work and why.
oh, nice! You can add this to the documentation: at the application level I am perfectly happen with an orphan instance. As a side note, I was suspicious of the claim of faster performance because logging-effect does not depend on fast-logger. A look at the benchmarks seems like they might be missing testing logging multiple messages in one run of the monad and also proper setup code as per: https://github.com/yesodweb/yesod-scaffold/blob/postgres/Application.hs#L53 http://haddock.stackage.org/lts-4.2/yesod-1.4.2/Yesod-Default-Config2.html#v:makeYesodLogger Perhaps Kazu or Snoyman can help with benchmarking. 
I've used something similar using GADTs for quite a while. Can't immediately find (public) Haskell code using this (though I'm pretty sure I have a Gist somewhere with some example...), but here's an OCaml sample: https://gist.github.com/NicolasT/3168d5b831605b4e3389#file-rpc-ml-L32 This defines a type somewhat like data Command req res where Get :: Command (Consistency, Key) (Result Value) Set :: Command (Key, Value) (Result ()) In Haskell, using some typeclasses and associated types, it's fairly trivial to define a generic handler for any such 'Command' taking the right arguments etc. so you can use runCommand Get Consistent (Key "key") :: Result Value (where the type hint at the right is not really required, just put here for demonstrational purposes).
&gt; I think FlipApply sounds like an alright name Flap
I can't answer your stack questions, but I am in favor of breaking large projects into multiple libraries. From my experience, it helps with decoupling and creating clear concerns.
Servant app I work with has 44 endpoints, 9.8k lines w/ tests. send-to-repl (`C-c C-l`) in emacs (haskell-mode) takes ~6-7 seconds to reload 114 modules. `stack build` is ~1:30 seconds. It's a non-issue. The type is large, but once you understand the grammar it's hard to make mistakes. If you do make mistakes, the type error can be long. But the type errors are pretty obvious to spot with a careful re-reading. An example could be forgetting that `Capture` takes a `Symbol`, this could be hard for beginners to track down. Don't forget to factor in all the time you'll save through code reuse when testing your API (`servant-client`), and generating docs (`servant-swagger`). 
[removed]
I'm partial (pun not intended) to always give the option of using sum types to signify errors, even in IO contexts. What I often do is to add a new type variable for "error values" that, if it's never used, remains polymorphic and may then unify with Void, thus simplifying the run functions in that case. One example is my [conceit](http://hackage.haskell.org/package/conceit) package, an almost verbatim copy of the ever-useful [Concurrently](http://hackage.haskell.org/package/async-2.0.2/docs/Control-Concurrent-Async.html#t:Concurrently) Applicative from async, with the difference that it lets you abort the computation by returning a Left value, instead of having to throw an exception. It also has a Bifunctor instance to let you massage the errors, compose different error types, etc. 
I don't think `(-&gt;)` is a `Monad` - rather `((-&gt;) r)` is. `((-&gt;) r)` is of kind `* -&gt; *`.
Test and compare? I've experienced the same rather painful slowness that stack can lead to with one lib and many executables. I'd like to see the best way to resolve this one, as I otherwise love stack.
Sidenote: I wish gloss was on stackable, it's such an annoying experience to install it. 
You used to be able to build only one executable in a one cabal file, multiple executables workflow. You cannot right now but they intend to bring it back. https://github.com/commercialhaskell/stack/issues/1406
It's not faster *because* it doesn't depend on `fast-logger` - it just happens to be faster. But it's really only constant factors, we're both in the same order of magnitude.
I'm sceptical that the proposal indeed corresponds to gradual typing (I think whether or not this is the case depends a lot of the details and the elaboration semantics for type classes), but that does not mean it could not be useful in practice. The "deferred type errors" trick does not correspond to dynamic typing, yet it is fairly useful in some usage scenarios. A paper I like on "what is gradual typing" is [Refined Criteria for Gradual Typing](http://drops.dagstuhl.de/opus/frontdoor.php?source_opus=5031), by Jeremy G. Siek, Michael M. Vitousek, Matteo Cimini, John Tang Boyland, 2015. That said it presents the theoretical view of what research on gradual typing considers, what gradual typing should be; practitioners will present as gradually typed systems that have some ways to mix typed and untyped code, even if they may not be as well-behaved.
There's also &lt;*&gt; and &lt;$&gt; of Functor and Applicative Functor, such that (,) &lt;$&gt; [1,2,3] &lt;*&gt; [4,5,6] or if you need another list (\(a,b) c -&gt; (a,b,c)) &lt;$&gt; ((,) &lt;$&gt; [1,2,3] &lt;*&gt; [4,5,6]) &lt;*&gt; [7,8,9] behave the same. I'm not sure how to generalize it to a higher number of lists though. Just in case you need it for a non-monad applicative type. Also, I recently needed to pair up the elements in a Tree (which is a Applicative, among other things) with the elements in another tree, like so: zipTree :: (a -&gt; b -&gt; c) -&gt; Tree a -&gt; Tree b -&gt; Tree c I stumbled upon functions from Functor and Applicative that I could use to fit that signature. However, the result was not what I wanted. Now, of course that's rightfully so, and shame on me for assuming that that would work. However: Is there some way I can use or abuse Applicative to essentially hand me zipWith for other data structures? I couldn't figure out how, but there's *gotta* be some way...
This is actually pretty nice, because one can actually pattern match on `Request` in `commandHandler`, which would be much harder with distinct datatypes for every request/response pair!
I just commented on that issue to give some clarity. In addition: you can in fact build one executable at a time with Stack, you just can't get a successful copy step from Cabal without all of the executables built. Your options are to either build all the executables once, and then thereafter build just the executable you want, or accept that you'll get a "build failure" from the copy step. I filed this as [cabal issue #2780](https://github.com/haskell/cabal/issues/2780).
Oh, this is nice too! The only drawback I see is that one can't generically derive Aeson/etc instances from `Command`.
You can still use [wai-routes](https://hackage.haskell.org/package/wai-routes) for routing in wai apps. it provides handlers and subsites just like yesod, but also provides no-overhead access to bare wai. **Edit**: I just added a simple example of using "bare" wai. https://github.com/ajnsit/wai-routes/blob/master/examples/bare-wai/src/Main.hs. It requires some internal functions that were previously not exposed from wai-routes, but I just pushed a commit exporting them. I think a reorganisation of the wai-routes imports is needed to enable bare wai access to be easier.
must be getting old - I can remember a time when a medium size project took long enough to compile to go pee or grab a coffee ... I'm sure there are people around who would drink the coffee too ;)
I just want to take this opportunity to point out [how nice WAI's Application type is](http://haddock.stackage.org/lts-4.2/wai-3.0.5.0/Network-Wai.html#t:Application) and encourage people to try using raw WAI before jumping straight into a framework.
I agree the wai response type is great, however the routing is not, which is what wai-routes aims to solve. wai-routes handlers are pretty much the same as raw wai's `RequestData master -&gt; (Response -&gt; IO ResponseReceived) -&gt; IO ResponseReceived` but with the option to use a much nicer interface as well. 
Thanks for this /r/haskman!
Absolutely, I'm more than willing to help. If you email me what you have and some of the tries you've made I'll take a look. Also, if you talk to some people in the #haskell IRC channel on Freenode I'm sure you'll find people there who would be willing to help and respect your wishes of not simply being shown the solution.
You writing selenium scripts in Haskell?
Here's a tip that may get you started. Keep strongly in mind that `Gen a` is a function that takes a seed and returns a random value and a new seed. So the type signature says that genTwo's first argument is a function that takes a seed. Where are you going to get that seed from? genTwo's return value is also a function that takes a seed. Then you're going to have to apply the second argument somewhere and that gives you back something else that takes a seed. Which seed are you going to use there? Also keep in mind that the above type signature for genTwo is equivalent to this type signature: genTwo :: Gen a -&gt; (a -&gt; Gen b) -&gt; Seed -&gt; (b, Seed)
I remember when compiling things took hours. In the grand scheme of things 6-7 seconds is nothing. It takes about 2 minutes to compile all our c stuff at work, incremental compilation occasionally screws up there so even though it can compile in about a second its not all that useful. Still have to wait for rpms to get built and then test those. Add to that having to find time to get access to a system with the right hardware and yeah, it can take an hour to compile for all I care. I have plenty to do in the meantime, like review other peoples changes.
I use selenium to browse web page. I need to scroll the page to the bottom :) 
Yep, I'm not surprised they've been defined multiple times. They're pretty basic tools of type-level hacking.
Thanks a million! I'll take another run at genTwo and email you or jump on IRC if I simply run out of steam. Cheers!
How did you arrive at that being my conclusion? I'm not sure if you got my gist, which is simply 6 seconds is NOT a long time. If you demand "realtime", which is ill defined but lets go with &lt; 100ms, then yes this will be disappointing. But when you work on things that can cause kernel oops, then compilation time is the least of your concerns. Even before I hit save, i'm looking over what I typed to try to catch errors before I touch the compiler. Anyway, obviously we disagree based on our preconditions, unless you can quantify a bit more as to why you need immediate feedback we're done here.
Is the repo for the NLP side proper available by any chance? 