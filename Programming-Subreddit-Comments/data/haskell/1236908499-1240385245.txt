 &gt; cabal install --user yi -f -vty Resolving dependencies... Downloading yi-0.6.0... Configuring yi-0.6.0... Preprocessing library yi-0.6.0... Preprocessing executables for yi-0.6.0... Building yi-0.6.0... Yi\Keymap\Vim.hs:36:7: Could not find module `System.Posix.Files': it is hidden (in package darcs-2.2.1) cabal.exe: Error: some packages failed to install: yi-0.6.0 failed during the building phase. The exception was: exit: ExitFailure 1
in a manner of speaking, neither does windows.
Sorry about lack of numbers. I was using my own code for the graphs, and didn't get around to working out how to do text. s/vertical/horizontal. yep. 
You drank backwards?
jpb's only uploaded it, as a kind of preview. He's going to do actual ANNs later this week or so.
4 years on, so happy to see the yi project continuing. Here's an [arch package](http://aur.archlinux.org/packages.php?ID=18640)
Yeah, I always do because I prefer being hung over *before* I get drunk.
http://yi-editor.blogspot.com/2009/03/yi-060-release-notes.html
Ah, thanks. Though I really think that Cabal (or just Hackage) should mandate a CHANGES file.
If you'd like to help then see ticket: http://hackage.haskell.org/trac/hackage/ticket/299 We need a detailed design beyond "I'd be nice if..." before someone can get hacking, so you can help even if you don't have the time or inclination to write the code. Indeed the harder part is working out what to do.
Pretty excited about this. Come say hello in the Filmhouse bar everyone! (Also quite excited, in a nerdy way, about ICFP'09 being held in Edinburgh.)
Just an idea: For programs that use STM, it may be nice to show when transactions are started, commited, and aborted. It would help to show when computation is wasted due to optimistic concurrency, among other things.
And if you look at [section 5.14.7](http://www.haskell.org/ghc/docs/latest/html/users_guide/runtime-control.html) you can build a binary that atomatically uses N cores without any run-time options - great for distributing! Edit: Made a link, as intended.
Is there some way to do this without a .c file, perhaps with FFI foreign export?
Awesome, this addresses one of the issues I raised in the RWH book comments, that it was disappointing to learn that you had to nail this down at compile-time. Hopefully next edition can include this updated info.
&gt; at compile-time Hmm? it's always been a runtime flag (available programmatically via `numCapabilities :: Int`)
But I guess the RTS isn't really running yet at that point, so probably not.
No, you make a good point that I have heard before. One desire is to beable to set the number of OS threads used by the RTS during run time (so a main, or code before main, could bump the OS thread count up to the number of cores). Unfortunately, this is not as trivial of a change as one would like due to the complexity of our current threaded RTS.
Isn't numCapabilities GHC only? Not to say that isn't appreciated, but if so then perhaps there should be a Haskell' proposal covering it.
Haskell' doesn't have anything to say about multicore at this stage.
I was kind of assuming the release notes would include a list of what's changed since the last release. :)
Wow, this editor is really nice, especially with all the arrows and lambdas!
Similarly, it would be good to know how much time it takes to sync MVars across threads (if possible).
Can someone explain ( for a ignorant like me ) what's the difference between this and dependent types ?
Sorry to say, but whatever GUI Yi currently uses *sucks*. It crashes, text doesn't always appear when it should, etc. How do I get the old command-line version back?
As we put it in our application to become a Google Summer of Code mentoring organisation: We love darcs. We think it is unique in the revision control world because it uses the full patch history to get operations like merging and partial undos right. But we also know that it has a lot of warts: the "patch theory" is still a work in progress, it has not yet been optimised to deal with large repositories, and it's still behind in GUIs and web interfaces. Help us make darcs better!
Hi! All the best in improving darcs. Its simplicity to use and powerful concepts are still without comparison. I contributed with a modest donation...hopefully you'll make it! Cheers 
For those who don't understand the title of this submission: http://projects.csail.mit.edu/gsb/old-archive/gsb-archive/gsb2000-02-11.html
The GTK and Pango GUI are currently experimental. Actually, GTK is likely to be discontinued in favour of Pango. You can just recompile like this: `cabal install --user yi -fvty` to get the vty frontend. You can also specify your frontend preferences in your configuration file. Have a look at the config archive, which is in the source distribution.
Thanks for making Arch Linux and Haskell such an enjoyable combination. Yi is still going strong. The core gets more hackable everyday, and the frontend and UI work is continuing. It'll take a while to get mainstream-ready, but it's getting there :-)
Thanks!
I have started learning Haskell and since this was the newest book published, I figured it was a good place to start. While so far I have enjoyed it, reading and understanding Haskell is a lot easier as I have recently gone through 2 F# books. As such, the ideas that Haskell exposes thus far does not seem so alien to me anymore. The one peeve I have with haskell or it could just be the Eclipse Plugin and Editor is indentation. Sometimes it makes no sense what at all and takes some trial and error to get it right. However, the same code written in Notepad++ works fine. Just one of those things I guess. Also, I wished that Real World Haskell introduced modules a bit earlier and discussed file/module names just as an intro before handling it later on. So far, I like it. I have enjoyed F# and I am definitely enjoying learning Haskell.
Sounds like you're mixing tabs and spaces in Eclipse. Haskell treats tabs as 8 spaces, so if your editor displays them differently things which appear lined up in the editor won't appear so to GHC. Simplest solution is to have the editor always write spaces to disk.
Macros are used for many more things than delaying or suppressing evaluation. There's a reason they made Template Haskell.
Thanks for the tip, but I don't really see an option to do that in the Eclipse Editor. I know I can do it in Visual Studio for F# but the only options I am given here are: [1] Displayed Tab Width [2] Insert Spaces for tab Here I am not certain if displayed tab width is the *actual* tab width, which I have set to 4 and I also turned on [2]. I will set the displayed with to 8 even though it looks horrible :-) 
There's a reason Template Haskell isn't used nearly as much as lisp macros, too. A lot of the things you used macros for in lisp you can use regular Haskell for.
There's a simpler explanation to this. TH is much harder to use than lisp macros :)) 
And we don't need macros nearly as much thanks to types and laziness.
There seems to be a bug in the documentation of sorts insofar as the `-N&lt;n&gt;` case still has the (default: 1) clause. Or am I misunderstanding, and it's defaulted to 1, if you don't use the option at all? No option: 1, `-N`: auto detect, `-N&lt;n&gt;`: _n_ then? 
&gt; TH is much harder to use than lisp macros :) I thought "X is hard" would make Haskell people more likely to play with it...
Don, not really a macros question. What is the closest equivalent to lisp optional, keyword and &amp;rest function parameters in haskell ? I understand that one can pass a Map to a function. But that obfuscates the function usage. Lisp environment (emacs + slime) shows you what key and optional parameters function expects. With Map as a function parameter, you loose such useful hints. 
Passing records?
But record has to be constructed fully. It does not allow partial constructors. So if you have say like 5 key parameters, but want to pass only 1, you have to construct a record with all 5 of them initialized. Or am i misunderstanding haskell records ? 
No, you don't have to initialise (or access) all of them. They can be undefined. Still, it's only for cases where Maybe a doesn't work.
You could provide a record filled with the default values, then just modify the ones you want when you call the function: data Foo = Foo { foo :: Int, bar :: String, baz :: [Int] } fooDefaults = Foo { foo = 1, bar = "hello", baz = [1..5] } function :: Foo -&gt; Result Then: usingFoo = function (fooDefaults {bar = "goodbye"}) I agree that there's quite a lot of boilerplate in using fooDefaults, but I'm not sure what else you can do, except that if you only have one or two optional args you could use `Maybe` for them.
The example would be great. I recently had to use TimeDiff record from System.Time, and I had to construct it fully, although i needed only one field from it. Maybe i'm doing it wrong. Here's my code: http://hpaste.org/fastcgi/hpaste.fcgi/view?id=2068#a2068 
The optional things are just 'undefined' here: data T = T { a :: Int , b :: Bool , c :: Char } deriving Show f :: T -&gt; Int f (T { a = v }) = v main = print (f (T { a = 42 })) Might be better to use explicit defaults.
Yes, that's how i'm doing it too. And indeed, lots of boilerplate. 
I see, thanks! 
Haskell is the sponge of CS.
Another option is to use only tabs for indentation. Your code blocks won't be perfectly aligned, but I never found much use in that anyway.
Which would be ironic because Gates doesn't have one.
wow Typeclassopedia is an awesome reference! I don't usually print a lot of stuff, but this is too handy.
Just following up on this: we did it! We've raised our first [$1000](http://lists.osuosl.org/pipermail/darcs-users/2009-March/018447.html),thanks to generous contributions from the darcs community.
&gt; 1.5 Used Packages and programs &gt; &gt; * HXT &gt; &gt; * Alex So much for my hope of a 3D library that is cabal-installable without external dependencies on Windows :( (HXT requires the curl libraries and Alex requires perl. And of course the previous alternative, GLUT, requires glut). If only cabal had the capability to automatically install 3rd-party software...
Yesterday while talking to a friend who recently discovered closures in groovy and loves it, i was trying to get him interested in Haskell. And here is the list i used to highlight the virtues. 1. pure .. ensures referential transparency 2. Functions are First Class objects .. so you can write folds etc 3. Currying .. makes partially specified functions 4. Lazy .. makes declarative style of thinking easy[ eg: can work with infinite lists] 5. Monads .. Make managing State etc.. easy to use Contrary to my expectations of having to spend a lot of time with Monads, most of the time was spent in explaining the fold operator [ i did refer him to the universality and expressiveness paper] and currying. Of course I missed a few other things like pattern guards etc.. but i felt those are just sugar [ Note: I myself have not worked on any significant project using Haskell ] Did I miss something? What would you have said to a friend who is a very good Java and C++ programmer to interest him in Haskell?
I'd add: a type system that catches most errors (including many design errors) statically.
If they are already familiar with the concepts, your list hits most of the important ones (though I'd add type inference). If they're not, it might be better to explain them the advantages of using Haskell over more traditional languages with more specific examples, such as: 1. Ever had NullPointerExceptions in Java? You'll never have to worry about them in Haskell. 2. Did you ever try using Command- or Strategy patterns and didn't like all the boilerplate? Haskell has a much shorter alternative (first-class functions) 3. Find it difficult to unit-test your code because there's a lot of state managing? In idiomatic Haskell you won't have to do setups or teardowns or mock objects. Just pass in some data and see if the result is the desired one. 4. Do you hate the verbosity of C-like languages where even the simplest function takes three lines due to the curly braces (same thing for begin/end in ruby)? In Haskell it takes only one (or two if you follow the style guides and include a function signature). 5. Do you get tired writing boilerplate for simple data container classes (e.g. a 3D vector), such as equality and ToString overrides? Thanks to the deriving keyword that's a one-liner in Haskell. 6. Do you hate having to explicitly define your types in Java? Haskell can infer them automatically. There are certainly more, but these are the ones that immediately came to mind.
Well, I don't know that any language specific package manager provides good functionality for that. Were this a Python or Ruby or Perl package, you'd see one of two things: * The package maintainer wrote lots of extra code to download `curl` and all that stuff for you. * You have to install it yourself. 
&gt; If only cabal had the capability to automatically install 3rd-party software If only Windows had a package manager!
Some other gems during the conversation.. with C you can make a Gun and shoot yourslef easily. C++ : Bomb and blow your foot. Haskell: difficult to make weapons, but if you manage to make one, .. i dont know, im not that good with Haskell. Java, there is just so much code all around you, you make bugs due to frustration.. Regarding type inference, Actually I found it reassuring to be able to specify the types and think in terms of type signatures. I personally dont think it is a plus for beginners because it also one kind of magic.. Any time some one says, "Don't worry the compiler is smart enough to figure that one out for you" i get the feeling there is a bug hiding somewhere.
It looks awesome but being licensed under the GPL is a turnoff. I'd like to help out with it but I need to concentrate on reinventing the wheel for commercial purposes.
When you reinvent it, can you please MIT or BSD license it?
I fully agree with you there. That certainly is one of the more useful features of Linux. Unfortunately I still have too much Windows-only software that doesn't run in Wine, otherwise I'd probably switch. But since we all know a package manager for Windows isn't happening any time soon, making cabal smarter is a more likely way of improving the Haskell experience on what is still by far the most used OS in the world.
Agreed. I wish Haskellers were more windows aware. So many things use unix-only packages... Too bad. I'm a game developer by trade (graphics programmer, even) and I could've possibly been convinced to contribute to this, but no windows = no deal.
I don't think it's that we're not aware. We could really do with more help from the Windows hackers. For example here are the Cabal Windows bugs: http://hackage.haskell.org/trac/hackage/query?status=new&amp;status=assigned&amp;status=reopened&amp;group=milestone&amp;platform=Windows&amp;order=priority Most of them are waiting for advice or testing from Windows users. None are fundamentally difficult.
We can easily fix Alex. There's no need for it to use perl. It's probably a couple hours to switch it to use pure Haskell code and test that it still produces the same results. I wonder if HXT needs curl or if the HTTP package would be enough. If it needs SSL then perhaps it really does need curl.
Do we really have to hear about when anyone with a blog starts learning Haskell? It seems like there's a post every week of someone starting to read Real World Haskell: "I'm only on chapter 4 but WOW!" It's great that someone has decided to learn Haskell but many of these posts are from people who are just barely scratching the surface and they're rarely enlightening or informative. Can we just put a big list somewhere for everyone to sign when they start learning Haskell?
Being GPL doesn't mean that it is useless for commercial purposes. Tons of companies rely on GPL'ed code for their applications and day to day work. You can even sell GPL applications for money. You just have to distribute the source. And just because you write an application that relies on GPL code does not mean that your application must therefore be GPL also. Unless your intention is to modify the source of the program, and then resell it *without* providing your modified source, you are in the clear.
&gt; And just because you write an application that relies on GPL code does not mean that your application must therefore be GPL also. I thought the author of CLisp had a problem with this. RMS wouldn't let him use libreadline unless CLisp was GPL, even if the user linked in libreadline themselves. http://www.reddit.com/r/programming/comments/7ez5b/why_clisp_is_under_gpl_an_email_thread_between/ 
If windows users don't contribute, how will it ever get ported to windows?
The 1-liner implementation of fibonnaci in this post is just ... wrong. It should be: fib = 0 : 1 : zipWith (+) fib (tail fib)
&gt; And just because you write an application that relies on GPL code does not mean that your application must therefore be GPL also. This is incorrect. Code that uses a GPL library must be released under GPL. You are probably thinking of LGPL. &gt; Being GPL doesn't mean that it is useless for commercial purposes. Tons of companies rely on GPL'ed code for their applications and day to day work. You can even sell GPL applications for money. Time is money and I would not want to invest tens of thousands of dollars building an application that my competition could also sell. GPL does not suit my needs and the opportunity loss of using a GPLed library is greater than the cost of reinventing the wheel. BSD code is more flexible because I can choose whether to release code changes or not. Bug fixes and small improvements are something that I'd want to release. Large investments (e.g., a significant rewrite) is something that I would want to keep proprietary until I could recouperate my investment.
Is there a page that describes this gzipped file?
Your browser doesn't expand .gz pages?
&gt; If only cabal had the capability to automatically install 3rd-party software... I don't want Cabal messing with my non-Haskell configuration. Dependency issues and test configurations are difficult enough to deal with without having to worry about multiple package managers independently installing software. If Cabal installs libcurl, will apt or rpm know about it? Fink? Cygwin? External dependencies should be clearly documented and checked during compilation/installation.
The MIME type isn't text/*, it's whatever a darcs patch is, so it's downloaded instead of displayed.
Sure, you won't use your technical advisor position on EA/Nintendo/Squarenix to recommend Lamdacube engine 'cause the GPL. But if he change to LGPL, it'll used in next FIFA/Mario/FF. 
Really? Running wget -S reports: Content-Type: text/plain; charset=UTF-8 Content-Encoding: x-gzip Which is what it should be. A plain text file, but transfered using gzip encoding.
Where can I see the candidates? Are they top secret? ;)
printStrLn?
The original list : http://haskell.org/haskellwiki/Haskell_logos/New_logo_ideas The official one : http://www.haskell.org/logos/poll.html
We may not have NullPointerExceptions, but we can have runtime exceptions from partial functions (head []). These always seemed like related problems to me.
well half-life is written in haskell soooo
Granted, though in Haskell you can avoid this problem entirely by simply not using functions that cause runtime errors. There's not that many of them, so it's easy to define some safe alternatives like safeHead :: [a] -&gt; Maybe a Hackage has a Safe package that defines most of the ones you'll need. The downside of this is of course that it makes your code more verbose, so personally I just configured my syntax highlighter to show all the potentially unsafe functions in the prelude in red, forcing me to think, for example, "Is this list really never going to be empty?". Now ideally we'd have some king of static analyzer that can tell you if it's technically possible for your program to throw a runtime error, but I suspect we won't be seeing that any time soon.
I really like the idea of highlighting unsafe functions. Now if a smart editor like Yi could run something like Neil Mitchell's Catch totality checker in a background thread and thus *automatically* highlight partial functions...
Haskell.org had the lambda back in 1997, a full year before half-life came out. Placing it inside a circle is hardly very original.
They may take our lives, but they'll never take our lambdas! I think they can safely be considered somewhat disjoint markets -- like Apple Computers and Apple Records.
I've just made a patch that fixes this issue; after `validate` is done it'll hopefully hit GHC HQ. :)
If the very first release is already using platform specific libraries (or rather, libraries which are platform-specific for *no good reason*), then it's not like it's very encouraging for windows users to get involved. I'd say 99% of contributions start with someone downloading the code to mess around with it without any intentions of contributing, as it stands someone has to go into it with the intention of spending several hours porting two libraries to windows...
I would say that a fairly large number of packages are written with no regard for portability. E.g. a lot of them are *nix only because they run some shell scripts as part of the configure stage. Maybe hackage should have an automatic rating or something taking test coverage, portability, and user ratings into account. That way people would have an incentive to at least write portable code when it's low hanging fruit to do so (like not using a trivial shell script when you could just write it in Haskell).
Great, now that I've looked at those "Haskell" doesn't even look like a real word anymore....
&gt; The MIME type isn't text/* Firefox disagrees strongly.
I play Half Life 2 almost weekly, and I love Haskell. I also don't confuse lambda in programming with the lambda in half-life for pharmacokinetics. 
Vote it down, and/or submit your own articles!
Safari doesn't have any idea what to do with them, apparently.
79 functions is a good start. I don't think they should track the fractional part though. It just feels desperate.
(different countries have different digit separators and decimal marks)
And that's why my comment was supposed to be taken as humor.
I had the opportunity to play with Agda thanks to a short course on Programming with Dependent Types given by Conor McBride, and it was a lot of fun indeed!
Hilarious! He gives up on languages because they don't have IDEs!
it's not; it's a proper noun :-P
Unfortunately, thats not the case. Hence the existence of the LGPL. See libreadline.
&gt; Maybe hackage should have an automatic rating or something taking test coverage, portability, and user ratings into account. That way people would have an incentive to at least write portable code when it's low hanging fruit to do so (like not using a trivial shell script when you could just write it in Haskell). Yep. That's the plan. Would you like to help us get there?
Learning Haskell by installing an IDE? MWWWWWUUUUUHAHAHAAAAAA!
He does acknowledge that "there is emacs if your twisted".
Also a [shiny new release](http://article.gmane.org/gmane.comp.lang.agda/766) with many new features, debs and other installers :-) 
Good work to the leksah team.
You might also enjoy the proof assistant Coq, then (no sniggering at the back there - in French the name is perfectly innocent). Coq has a library of theorems and proofs, and provides a range of tactics to ease proving (and programming). You can also define your own tactics. It supports dependently-typed programming with the Program command. The latest version, Coq 8.2, has support for Haskell-style typeclasses (with support for dependent types with Program Instance) and plugins. I recommend the ssreflect plugin, which I think provides a nicer style of proof writing - but the version of ssreflect for 8.2 has not yet been released. Coq also has a (very small) [reddit](http://reddit.com/r/Coq).
Yeah. It'd be better to boast about how those 79 functions implement one entire package! (There are [1.135 packages on Hackage](http://hackage.haskell.org/cgi-bin/hackage-scripts/stats).) Now there's concision &amp; power for ya.
I'm not sure why this is supposed to be hilarious... Take a language like C#, there are legitimate reasons for liking it, and 90% of them are spelled "visual studio".
Notepad is actually fine to learn any language. You don't need IDEs. In fact, you probably will waste more time with them if you are not familiar with all their quirks. If you know a good editor already, use that one. No need to try some really experimental IDEs for the language you are learning. Take the book RWH, most of the code examples don't take more than 1 or 2 pages. You don't really need sophisticated features to edit a few lines of code at the time.
This is only a problem in Smalltalk.
Visual Studio makes me *at least* twice as productive. IDEs matter. A lot.
I meant in the context of learning a language. Learn the language, then play with IDEs. Of course some languages benefit more because there is so much boilerplate needed. Not so with Haskell.
Nice! I'm looking forward to seeing lots of good work come out of this :)
Looks like it installs the library, but not the executable, which is kind of useless from my POV :( edit: Just found out that there is also an [Agda-executable](http://hackage.haskell.org/cgi-bin/hackage-scripts/package/Agda-executable-2.2.0) package.
Would the solver be able to simplify something like (I'm just guessing the syntax here) puzzle x = valid x &amp;&amp; [| a == 0 | a == b || [a,b] &lt;- transpose [a,b] |] == ~zero where _ = 0 b = [[ _ 9 _ 7 _ _ 8 6 _] [ _ 3 1 _ _ 5 _ 2 _] [ 8 _ 6 _ _ _ _ _ _] [ _ _ 7 _ 5 _ _ _ 6] [ _ _ _ 3 _ 7 _ _ _] [ 5 _ _ _ 1 _ 7 _ _] [ _ _ _ _ _ _ 1 _ 9] [ _ 2 _ 6 _ _ 3 5 _] [ _ 5 4 _ _ 8 _ 7 _]]; It seems inelegant to have two copies of the board...
It would have been more newsworthy if they hadn't been accepted...
Agreed, I independently discovered the same kind of queue after reading Richard Bird's paper, which is also the first citation mentioned in Allison's paper. I tried generalizing this to, e.g. monotonic associative maps to little satisfaction. Maybe that would be possible with some radical changes to the language, but I don't know.
Pearls usually mean code and I think you could glean most of that information from the homepage. LURK MOAR.
That might be true, but it doesn't mean that every language must have an IDE. There are many reasons to like Python and none of them are an IDE afaik. I mean you could use an IDE but there's plenty enough to like otherwise. As such, it's hilarious that someone would assume that you need a 1gb piece of software to code and then go on to call people who get along with emacs weirdos.
I recently added Duane to my contact list since he kept ending up in my spam folder. Something about having the same name as a famous pro-wrestler-turned-actor put his messages there.
Please santa, give me : * parsing of python function in each module * transforming the pure python function into haskell equivalent * wrap the haskell functions into a python module * replace the function in each module by a call the new python-haskell module.
Is it correct that memcached's gets and cas are the building blocks for a distributed STM ? It's great how often there are new things on hackage.
Nice, but for the people unfamiliar with Haskell, he's not explicitly telling the biggest benefit: you cannot mix Fahrenheits and Celsiuses, the compiler won't let you.
Right, no more Mars Orbiter crashes due to a miles / kilometers mistakes if the type system is leveraged properly
But you *can* give it a numeric literal wherever it expects either one.
I've started with [RWH](http://book.realworldhaskell.org/) the other day, now I can read 50% more reddit!
Real World Sather?
Are we doing some haskell meta-blog kind of thing, a place for nuabs to stumble across things that are linked on the wiki (gosh, did you know that you can look at api docs at haskell.org? ZAMG!), a place to collect CS information too advanced for progit, or what? Quality seems to get drowned.
somewhat, I was expecting something more... olegly.
Could you be more concrete? I'm currently posting: 1. new library or app releases of note 1. new research papers 1. important new patches to GHC 1. blog posts by experts 1. blog posts by new haskellers that might benefit from some help 1. requests from the community Basically, today's haskell reddit should reflect everything important going on in Haskell today. Could you say more about what is the problem?
xD typo :)
it's a bit sad that many posts are uncommented, but it's not your fault.
&gt; (no sniggering at the back there - in French the name is perfectly innocent) means *rooster*
Mmmm, a Num instance for Fahrenheit. So now I know that 32F * 212F is 6784F!
I don't think "we" are doing anything specific. Anyone is free to post interesting developments in the Haskell world. dons, having a keen eye for what's going on in the haskell world, posts a lot of interesting stuff, both for rank newbs, rank-1 newbs (me) and rank-n pros (thanks, dons). I think the quality in this subreddit is good. If anyone has additional interesting Haskell material, as yet unmentioned on reddit, then submit it, and the upvoting/downvoting can take its course.
I've just used the `[[_,a,b,c]] &lt;- input =~~ "(a+) (b+) (c+)"` form. (usually in Maybe) It seems like the easiest way to get all the captures where you want them. It's not error-proof, but then I wouldn't be using regexps if that's what I wanted.
people upvoting "hey look! you can do IO with monads!"-posts? dunno. Sometimes, the whole community just looks like a pack of vultures circling over newbies. I don't think there's any need of brining the mountain over to the people, after all, it's easy enough to find. 
In some way, this is missing from RWH. OTOH, one can argue that the world is better off without regexen, but then, quick and dirty solutions are important to have.
I vote for 69 on the official list. It looks professional, simple and includes the lambda sign in a subtle way.
Even if I like looking at newbie blog posts now and then, I don't really think they belong in the Haskell subreddit.
What I'd like to know is where the named groups are to make life easier for those of us using haskell in the real world.
I can confirm this.
[Arch Linux](http://aur.archlinux.org/packages.php?ID=23335) package (`yaourt leksah`). We need to do more to help this project thrive.
Yeah, it's high on my list, too. I actually like 62 most, because it *doesn't* include a reference to lambda (or maybe I'm just missing it) and because it works well in small sizes.
It unfortunately depends on everything under the sun on my mac, whereas Yi is happy to work in a terminal. Getting gtk2hs working (still doesn't) is quite a chore.
Ah, you need a better distro :) pacman -S gtk2hs Done.
He founded the channel, afaik.
A better mac distro? ;) Leksah was super easy to compile/install back when I was an Arch user, but since I switched to OS X I'm doing my occasional haskell coding in Vim. Hopefully when a stable version is released it'll come packaged for mac too.
Yep! If anyone else wants moderator rights, just let me know! (dons already has it, FYI)
I didn't have an issue getting it to work on OS X although it took awhile on my macbook. Go get macports and then "port install gtk2hs", install cabal install then use that to install leksah. Just make sure you have macports in your path.
If you're on OSX using the GTK package from http://www.gtk-osx.org, there are instructions for building gtk2hs against it here: http://www.haskell.org/haskellwiki/Gtk2Hs#Using_the_GTK.2B_OS_X_Framework I followed this and afterwords I was able to use yi (with gtk,) hieroglyph, etc..
Nope. No way in hell Sony/Microsoft/Nintendo would let a game get through approval that saw _any_ of its code released to the public's eyes.
Not entirely true. the CLisp sources would still have used libreadline code in order to be ready to be linked by the user. The libreadline headers aren't LGPL.
Yup Kind of the whole point of the GPL is to open the user's ability to modify the software they use. If you don't want to compete with your users you have to avoid the GPL. What I don't get is why so many in the Haskell community are upset/turned off by the GPL. There's really not much commercial work being done in Haskell, you'd think they'd be indifferent. My take is that it's based in hubris.
The work is being done for free to appeal to the hacker's curiousity or scratch a personal itch. They have no incentive to support other end users aside from fame and good will. It's up to you to scratch your itch and fix things for windows.
Hubris is thinking that your code is so awesome that a closed-source company would open-source a product to be able to use it.
Because John Resig is not a one trick pony. You may know him for JavaScript, but like most of us, he has a keen interest in several areas of programming and computer science.
Interesting. I suppose I can give it a shot, in between my other projects... *EDIT* So, after about an hour looking at the code, I've come to the conclusion that this is going to take some serious updating, this code is _very_ old, and as such has succombed to serious bitrot. I've moved the code to a darcs repo (just a darcs init in the svn checkout repo for now, I'm looking into conversion tools for svn to darcs to see if I can recover the patch history) here[1]. Is the author of this package still around? I'd love to get an overview of what-does-what... That would help a great deal in cabalizing and (eventually) improving this app. *EDIT part deux* This is pretty bad, methinks it'd be better to rewrite this from scratch- using this code as possible inspiration. Many of the files are importing via the old, nonheirarchical syntax, the make process is unintelligible. The whole thing needs to be gutted, tbh. I can't commit that kind of time- but I'm happy to work on it in my spare time till someone comes along and wants to take over... [1] http://patch-tag.com/repo/dhs/browse
macports was trying to install 0.9 instead of 0.10. I'm building 0.10 right now.
Yep, looks pretty awesome!
I created a port file for 0.10 and attached it to this... http://trac.macports.org/ticket/17308 but nothing seems to have happened yet. You can download it manually and put it in... /opt/local/var/macports/sources/rsync.macports.org/release/ports/devel/gtk2hs/ 
The application uses check boxes however each problem only has one possible answer. Seems like radio buttons would be more usable. Perhaps they intend to add problems which have more than one answer.
Not saying he is, I was just curious. I assumed that dons created this sub-reddit, but apparently I was wrong.
Anybody? Anybody at all? Pick me! data Mod = JResig | DStewart | JFredette :) 
 &gt; let (_,_,_,[group1,group2,group3]) = "foo 123 baz" =~ "([a-z]+) *([0-9]+) *([a-z]+)" :: (String,String,String,[String]) &gt; group1 "foo" &gt; group2 "123" &gt; group3 "baz" Unfortunate that the pre string, after string and matching string also need to be matched (it typically seems to mean a type annotation is needed) but it does the trick.
Maybe using pure functions on streams of data from the filesystem just doesn't make any sense. 
Well, it does make sense - I assume what you mean is using pure functions *to read* streams of data from the filesystem. (If the data has already been read fully into memory, and the handle has been closed, there's no problem.) If the former is what you meant, there has been quite an involved debate on that on the haskell-cafe mailing list recently. I think the traditional way of doing it does make sense for very simple applications where you know what you're doing. But, as this announcement points out, it does have risks, like not allowing you to handle read errors. This new safe-lazy-io library looks like a good compromise which allows you to combine pure lazy functions, resource management and error handling.
Yes, I've used that trick, but it's really just a poor substitute. When I converted a project prototyped in Python into Haskell, the last thing I wanted to do was have to rework my carefully designed regular expressions so that I could use them in some massive let statements. It was bad enough that I switched to Parsec, until I had to switch back because Parsec wasn't nearly fast enough. What we really need is named group handling that returns a Map.
If I try to emerge gtk2hs with the firefox use flag this requires it tries to pull in firefox 2.x, is there no firefox 3 support in gtk2hs?
I'm not sure what the "former" is in your comment. (And I guess there is a "latter".) 
The sucky thing about regex in haskell is no =~ s/../../ like in perl, nicely packaged up. There is subRegex in Text.Regex but that only works on posix regexes. I bitched about this at http://groups.google.com/group/haskell-cafe/browse_thread/thread/95bc546417446274/96a1f552114d456f?lnk=gst&amp;q=pcre#96a1f552114d456f and also tweaked subRegex so it would work for pcre. Even with these tweaks, I am completely unsure as to where subRegex and =~ s might diverge in their behaviors. Mulling this problem, I came to the idealistic notion that maybe a good way to get substitutions would be to tweak the pugs code for perl 6 to make perl 6 regexen easily accessible in haskell. http://perlmonks.org/?node_id=750768 But then I got stuck trying to load pugs in ghci so I could poke around. Maybe someone else can pick this up. 
Hint: Add --user to your config flags, or be insanely puzzled by the fact that configuration works on the shell, but not inside leksah.
What's new in GHC 6.10.2 ? 
Done.
Sorry. Bad phraseing. "The former" is using pure functions to read streams of data from the filesystem. "The latter" is reading data into memory and then closing the handle before calling the pure function.
Are there any performance comparisons online comparing programs compiled wth jhc, ghc and other haskell compilers?
Lol, awesome... I feel all superusery now. :)
Rather confusing title, but worth a read. I think with increasing use of formal verification (when it is done in the *right* way ;-), we will see a gradual firming up of claims like "We needed to implement this part in C", providing more than just justification by assertion - and a gradual reduction in reliance on C, because I simply don't believe claims like "we needed to implement the *whole thing* in C for speed". When you're able to reliably reason about non-functional desiderata such as resource usage (on which point see Edwin Brady's recent work) as well as functional correctness, you'll be able to precisely say "These three particular functions absolutely had to be optimised to meet our real-time requirements, but we didn't actually need to go any further in optimising things - because we know that at that point, due to such-and-such properties of the input data, the performance of the system will always be within our required bounds." And - which is my main point here - you'll be able to prove it!
Dear Proggit, I wrote my first ever Haskell program beyond Hello World! Yay! But I am discouraged by the performance. It is ~20x slower and 10x more memory hungry than the same program in C. (2.23 seconds compared to .12 seconds.) Boo! [Haskell code](http://ridiculousfish.com/haskell/main.hs.txt). [C code](http://ridiculousfish.com/haskell/main.c.txt). I'd really appreciate it if some of the Haskell folks here could take a look at my program and suggest ways to improve it. Not just performance, but stylistic criticisms or ways to reduce the code size. If you want to reproduce these results, you can get everything you need from this [tar.gz file](http://ridiculousfish.com/haskell/help_my_haskell.tar.gz) or this [zip file](http://ridiculousfish.com/haskell/help_my_haskell.zip) The program is a "Scrabble cheater." There's a large file containing a list of words. The program takes a string as a command line parameter and outputs every word in the file that contains all the input letters, accounting for multiplicity. The Readme file in the above archives gives more information. I should probably point out that this is not homework. I'm just trying to determine if Haskell is a language I should spend more time learning. Thanks for any help! 
Had a similar experience. My first program looked for words matching a new phone number my cell provider proposed. It turned out discouragingly slow, too. Can't help except point to [Real World Haskell](http://book.realworldhaskell.org/read/profiling-and-optimization.html)
It helps to avoid destructive array updates. This is a bit faster: import Data.Array import System import Control.Applicative counts word = accumArray (+) 0 ('A','z') [(x,1) | x &lt;- word] -- like "zipWith" in the prelude, but for arrays zipArrayWith f a b = [f (a!i) (b!i) | i &lt;- indices a] main = do target &lt;- counts &lt;$&gt; head &lt;$&gt; getArgs words &lt;- lines &lt;$&gt; readFile "extended_words" mapM putStrLn $ filter (and . zipArrayWith (&lt;=) target . counts) words I *think* your code has to copy the `sieve` array a bunch of times. Thanks for Hex Fiend, and good luck learning Haskell :-)
This is my version of scrabble cheater, written some time ago. Caveat: not intended for performance competition! You can expect reasonably ok code though. import qualified Data.Map as M import Control.Applicative import Control.Monad import Data.Function import Data.List type Bag = M.Map Char Int toBag l = M.fromListWith (+) $ zip l (repeat 1) subBag :: Bag -&gt; Bag -&gt; Bool subBag = M.isSubmapOfBy (&lt;=) main = do ws0 &lt;- lines &lt;$&gt; readFile "/usr/share/dict/words" let ws = filter ((&gt;= 3) . length) ws0 bigList = [(toBag w, w) | w &lt;- ws] loop = do i &lt;- toBag &lt;$&gt; getLine when (M.size i &gt; 0) $ do print i mapM_ putStrLn $ sortBy (compare `on` length) $ [w | (ls, w) &lt;- bigList, ls `subBag` i] loop loop 
Here is some output from the profiler ;-) COST CENTRE MODULE %time %alloc line_matches Main 89.7 89.7 main Main 9.5 10.1 definitely start with line_matches. EDIT: and a [link](http://www.haskell.org/haskellwiki/How_to_profile_a_Haskell_program) for you.
I haven't looked too closely, but you use the (//) operator quite a bit. Take a look at Data.Array.Diff, it can make a huge improvement when you do many array updates.
Thanks, that made a big difference! [Version 2](http://ridiculousfish.com/haskell/main_v2.hs.txt) It's more than twice as fast as my first version, running in 1.03 seconds.
Try using UArray instead of regular Array. This lets you store unboxed values in your arrays, instead of pointers to thunks.
And STUArray is the sensible equivalent in Haskell to a mutable C array. Same representation, same kind of operations, [similar performance](http://shootout.alioth.debian.org/gp4/benchmark.php?test=nsievebits&amp;lang=all).
It was a legitimate question/curiosity.
The conversion to and from unicode characters seems to be harming performance. Using Data.ByteString.Lazy to get a lazyish list of Word8s really improved my code's speed.
The front page has lots of text, buries the links to the useful package index and Hayoo, doesn't really explain what Hayoo covers, and has outdated info about the cabal tool. How about something simple like: Hackage is a Haskell packaging infrastructure. * HackageDB is an archive of Haskell projects * Hayoo is an API search engine, which covers all packages in HackageDB * Cabal is the packaging format used by Hackage packages. You can install any package from Hackage by: cabal update cabal install &lt;packagename&gt;
Send the patch to Ross Paterson. Note also, hackage has been reimplemented and redesigned by [tupil.com](http://tupil.com/) so expect something new after the hackathon.
Thanks. Data that's _been read_ from a file can surely be handled with a pure function. Lazy IO tries to treat reading the file as on demand streaming. When there are no file errors and the file data is not changed it gives the same data as would reading the whole file. It's operational qualities are hard to control, though. Streaming deserves to be made explicit. What is a semantics for streaming? It is a sequence of `read`s from a resource. It is very natural to suppose that a file is a container; the "file monad" specifically sequences the "effect" of trying to read an element. A `read` should offer us an item or no item (if there is none left). So maybe we have: data Read t = One t | None read :: (Monad m, Stream s t) =&gt; s t -&gt; m (Read t) So now we have a pure stream -- one that has no errors or hiccups but has items and an end. We need something else to handle files: data Stat message = Continue message | Fail message stat :: (Monad m, StatStream s t msg) =&gt; s t -&gt; m (Stat msg) This allows for a possibility of "hiccup" (read nothing but still clear to continue) or "corrupt" (read something but have an error in doing so) as well as the usual one and none. A "stream program" written in terms of `read` can be applied "purely" as well as impurely, with out making us pay for the extra book-keeping required by `stat`. This is all kind of a loose bag, I admit.
&gt;it doesnâ€™t track **binary** installations via the Linux distributions (particularly Ubuntu, Debian, Fedora, **Gentoo** and Arch). Er, what?
&gt; A "stream program" written in terms of read can be applied "purely" as well as impurely, with out making us pay for the extra book-keeping required by stat. But that would be a program which ignores read errors, which *in general* you don't want, so you wouldn't necessarily write it.
Actually, these pure programs should be easy to transform to the impure kind. That's how we can write pure code and easily use it in a impure situation. So you want to write them and then apply a simple wrapper. As a concrete example, we have a `String` parser. It does not have `IO` errors of course. Because it only uses `read`, though, it's straightforward to transform it to a file parser that captures some errors on the outside. The reason it makes sense to even have "stream programs" is because in either a pure or an impure setting, they have similar, desirable operational characteristics -- bounded memory usage and destruction/release of the resource. However, the particulars of the interface have frustrated me somewhat. The typeclasses I use in my example are actually hard to get right.
That definitely sounds useful. It could probably help solve the Functor/Applicative/Monad/MonadPlus ugliness as well. My knowledge of the inner magic of the type-system is very limited though, so I have no idea if this is even possible to implement.
We should coordinate any rewrite of the Hackage front page with the Cabal home page. Both need some attention.
I would guess what they really mean is "It doesn't track distros using their own set of mirrors"
Well, when I emerged the ebuild, I downloaded xmonad from Hackage :) . &gt; `SRC_URI="http://hackage.haskell.org/packages/archive/${PN}/${PV}/${P}.tar.gz"`
can't you have installed both versions of haxml at the same time?
Hi! Here's a first pass on the program. This one is focused entirely on idioms, and likely won't change the speed very much at all. It's just to give you a quick pointer at some parts of Haskell you might not have known about. -- IO (System.IO) isn't needed if we use readFile instead of -- openFile/hGetContents (see below). -- import IO -- Hierarchical modules are the way to go these days. See -- http://www.haskell.org/ghc/docs/latest/html/libraries/ -- import System import System.Environment import Data.Char -- again, hierarchical -- import Array import Data.Array import Data.List -- We'll use some convenient functions from these later. I've imported them -- explicitly so you know which ones they are. import Control.Monad (mapM) import Data.Monoid (mappend) import Data.Ord (comparing) -- The beauty of Array is that we can use any Ix instance as the array indices. -- Since Char is an Ix instance, let's do away with this conversion. -- pop_count x = (ord (toLower x) - ord 'a', 1) line_matches sieve [] = all (&lt;=0) (elems sieve) line_matches sieve (x:s) = -- let ind = ord (toLower x) - ord 'a' -- population = sieve!ind -- in line_matches (sieve//[(ind, population - 1)]) s let ind = toLower x in line_matches (sieve // [(ind, sieve!ind - 1)]) s -- Looks like a map, right? But in a monad, so mapM. --put_lines [] = do return [] --put_lines (x:s) = do putStrLn x -- put_lines s put_lines = mapM_ putStrLn lowercase = map toLower -- Monoids are a pretty nifty way of doing this. -- compare_lines x y = -- case compare (length x) (length y) of -- EQ -&gt; compare (lowercase x) (lowercase y) -- other -&gt; other compare_lines = comparing length `mappend` comparing lowercase -- let's drop the extraneous parameter, just for fun sort_lines = sortBy compare_lines main = -- let's use pattern matching here, it's nice! -- do args &lt;- getArgs do (arg:_) &lt;- getArgs -- this bit is now obsolete, since we are just using Char for our index -- array_updates &lt;- return (map pop_count (head args)) -- "x &lt;- return y" is just the same as "let x = y", and the latter is used more -- sieve &lt;- return (accumArray (+) 0 (0, 25) array_updates) let sieve = accumArray (+) 0 ('a', 'z') (zip arg [1,1..]) -- we have a convenience function already for this -- f &lt;- openFile "extended_words" ReadMode -- text &lt;- hGetContents f text &lt;- readFile "extended_words" put_lines (sort_lines (filter (line_matches sieve) (lines text))) Now, let's do a second pass for speed. I didn't actually profile, so this is just a guess at where the speed is going to. But here: import System.Environment import Data.Char import Data.Array import Data.List import Control.Monad import Data.Monoid import Data.Ord -- In Haskell, the Array that lives in the pure world is immutable. This means -- that all the update operators copy the entire array! So let's try to avoid -- that as a first change. -- line_matches sieve [] = -- all (&lt;=0) (elems sieve) -- -- line_matches sieve (x:s) = -- let ind = toLower x -- in line_matches (sieve // [(ind, sieve!ind - 1)]) s -- note that this now has a different type! line_matches xs ys = null (xs \\ ys) put_lines = mapM_ putStrLn lowercase = map toLower compare_lines = comparing length `mappend` comparing lowercase sort_lines = sortBy compare_lines main = do (arg:_) &lt;- getArgs -- This is obsolete, since we're not using Array any more. -- let sieve = accumArray (+) 0 ('a', 'z') (zip arg [1,1..]) text &lt;- readFile "extended_words" -- Now just pass the actual arg, rather than a "sieve" array -- put_lines (sort_lines (filter (line_matches sieve) (lines text))) put_lines (sort_lines (filter (line_matches arg) (lines text))) Testing this with argument `foo` and `grep -v '[^a-zA-Z] /usr/share/dict/words` as the wordlist gives 0.37s for the original, 0.37s for the idiomatic version, and 0.07s for the faster version. I'm sure it could be improved quite a bit from there using ByteString, an even better line_matches function, etc. But I should point out that we went 5 times faster with a pretty small change, *and* the final result is only 9 lines of real code! Not bad, I think.
Let me clarify this comment: -- In Haskell, the Array that lives in the pure world is immutable. This means -- that all the update operators copy the entire array! So let's try to avoid -- that as a first change. The meaning of "copy the entire array" is slightly different in Haskell than in other languages. What I really meant here is that updating an Array involves copying the entire *spine* of the array. That is, for any un-changed elements, the "copy" is just a pointer assignment; we share the old and new values. This still kind of sucks -- it's definitely O(n) for even a small change -- but it's at least better than copying the entire contained value. =)
Alternatively: newtype Fahrenheit = Fahrenheit { unFahrenheit :: Float } deriving (Eq, Ord, Show, Num, Fractional, Arbitrary) newtype Celsius = Celsius { unCelsius :: Float } deriving (Eq, Ord, Show, Num, Fractional, Arbitrary) far2cel :: Fahrenheit -&gt; Celsius far2cel = Celsius . (*(5/9)) . subtract 32 . unFahrenheit cel2far :: Celsius -&gt; Fahrenheit cel2far = Fahrenheit . (+32) . (*(9/5)) . unCelsius Or it could be nice if we had the libraries and ability to auto-generate Reversible functions data constructors: -- In a library import qualified Control.Category as Category import Control.Category(Category) import qualified Control.Arrow as Arrow data Reversible a b = Reversible { rAToB :: a -&gt; b , rBToA :: b -&gt; a } instance Category Reversible where id = Reversible id id Reversible bToC cToB . Reversible aToB bToA = Reversible (bToC . aToB) (bToA . cToB) instance Arrow.Arrow Reversible where arr = error "Arr shouldn't exist in Arrow class :-(" first (Reversible aToB bToA) = Reversible (Arrow.first aToB) (Arrow.first bToA) runRev :: Reversible a b -&gt; a -&gt; b runRev = rAToB rmul :: Fractional a =&gt; a -&gt; Reversible a a rmul x = Reversible (*x) (/x) radd :: Num a =&gt; a -&gt; Reversible a a radd x = Reversible (+x) (subtract x) rev :: Reversible a b -&gt; Reversible b a rev (Reversible x y) = Reversible y x cdot :: Category cc =&gt; cc b c -&gt; cc a b -&gt; cc a c cdot = (Category..) -- Derive automatically -- rfar :: Reversible Float Fahrenheit rfar = Reversible Fahrenheit unFahrenheit rcel :: Reversible Float Celsius rcel = Reversible Celsius unCelsius -- This would be the code with reversible arrows: newtype Fahrenheit = Fahrenheit { unFahrenheit :: Float } deriving (Eq, Ord, Show, Num, Fractional, Arbitrary) newtype Celsius = Celsius { unCelsius :: Float } deriving (Eq, Ord, Show, Num, Fractional, Arbitrary) farCel :: Reversible Fahrenheit Celsius farCel = rcel `cdot` rmul (5/9) `cdot` radd (-32) `cdot` rev rfar -- The above can be used for both far2cel and cel2far 
Yes you can, but when installing a new set of packages, that set can only depend on one version. Strictly speaking, it'd be ok for that set to use more than one version of a package so long as the transitive dependencies of each individual package contains at most one version of each package. That would be local consistency rather than global consistency.
A couple out-of-hackage packages there, I wonder if they will get uploaded.
Can anyone comment on replacing regexps with Parsec ? Would that be feasible for a person who does not know and use regexps in other languages ? If i need to parse some text and do not know regexps at all, why would i chose regexp library versus Parsec ? 
Haskell performance still seems to me to be somewhat of a black art, although there's a time honored technique for Haskell program optimization -- just write a blog post with a title like "Haskell Performance Sucks (Worse Than Python!)." Moving to Data.ByteString and STUArray and making everything strict can make this faster, but even with those the best my poor Haskell skills could get was about 5x slower than C. You should learn Haskell for the mind-expanding experience and because programs are so much slower (dmwit's solution is only 9 lines) and because when multicore is everywhere that you'll be able to run circles about the guys trying to multithread in their Blub languages. You can get raw speed out of it, but a) it seems easier to get raw speed out of other languages (i.e., Ocaml) and b) you tend to lose a lot of elegance when you do this. EDIT: The [Haskell wiki](http://www.haskell.org/haskellwiki/Wc) has some good articles on performance optimization.
Good to know. I didn't catch that on my read through the book, thanks.
Are you *trying* to raise my blood pressure? I need to relax...
Wish i could up mod you responses more.
Failed to install encoding library. I installed it via cabal install separately. Then salvia still failed cabal install with this: src/Network/Salvia/Core/IO.hs:39:22: Module `Data.Encoding' does not export `decodeLazy' 
It's okay, Haskell just isn't for everyone.
He's reading [RWH](http://twitter.com/gvanrossum/status/1269954818) - the revolution will be tweeted :)
Hmm $ cabal update $ cabal install salvia ... some time later ... src/Network/Salvia/Core/IO.hs:39:22: Module `Data.Encoding' does not export `decodeLazy' Time to talk to the author.
Better than the powdered stuff.
Two weeks from now: "... after reading ... and after much heart wrenching consideration ... many of you will take this as quite a shock, I'm sure ... your BDFL no longer ... this awakening ... you see, Haskell ... Simon Peyton Jones appeared to me in a dream, claiming ... It was all so true ..." 
In my experience, Data.Array.Diff tends to make things slower rather than faster.
are you comparing haskell to pepsi? Pepsi sucks, so obviously Guido is a pepsi guy.
Python is Coca-Cola, Java is Pepsi, and Haskell is Double Cola. 
Maybe it's like grapefruit juice. 
Haskell is beer. Way better than soda, and gives you a hangover if you have to much of it.
I think it would be more like: PEP 6.10.02 - Adding Type Classes to Python PEP 6.10.01 - Adding GADTs to Python 
I was just sticking to the soda metaphors. :-)
interesting, but -- iirc -- record syntax is currently just sugar for changing: data Foo = Foo {bar :: Int, baz :: String} to -- or is this a newtype? data Foo = Foo Int String bar (Foo i _) = i baz (Foo _ s) = s Since this is just a few extra pure functions, wouldn't this modification introduce some _serious_ overhead due to having to pass a class dictionary around? Is there a way around that, whats more, while this is a pain in the ass, isn't it generally not necessary -- if you're writing a datatype, isn't it normal to separate these into modules anyway? 
It is indeed ever-growing, but not all of us would say this is a good thing. Any chance of things getting settled down a bit sometime soon with Haskell'? 
Oh great, a web server powered by bong hits ;)
If you wanna find out, you've got to try her out. Haskell. If you wanna get down, down on the purely func. Haskell. She don't lie, she don't lie, she don't lie. Haskell.
Looks like the reinvention of an old proposal. 
For existing code it would be equally efficient, since the types are always known and the dictionaries can be eliminated.
Haskell '98 is pretty settled AFAIK.
LOL! We'll just have to wait till April 1.
I think its a little bit odd that a language designer does not know one of the important/prominent languages of the time. Guido really ought to learn Haskell and other languages already -- as a language designer he can't be living in a bubble :-)
Delicious?
Well, it depends on the context. If you don't do lots of (//) operations or similar then there is a performance overhead. But I've had some success in speeding up programs where I did many updates. 
I think Record names should not be getters for that field, but accessors or lens (pairs of getter/setter functions). For example: data Blah = Blah { a, b, c :: Int } now instead of (a, b, c :: Blah -&gt; Int) we should have: (a, b, c :: Accessor Blah Int) where Accessor is something like: data Accessor whole part = (whole -&gt; part, part -&gt; whole -&gt; whole) Then, you can have functions like: (^.) :: whole -&gt; Accessor whole part -&gt; part (^&gt;) :: Accessor a b -&gt; Accessor b c -&gt; Accessor a c which are nice to use: blah ^. first ^. bleh or: accessor = first ^&gt; bleh blah ^. accessor 
He is learning it, I think.
Can someone explain to me what the ice, sugar etc. are? Water = side effects? Ice = monads ("frozen" side effects)? Sugar = syntactic sugar for monads?
Insecurity much Mr Rossum?
Balanced with a little bitterness.
I've spent a lot of time thinking about this myself: is purity really worth the hoops you have to jump through to maintain it? I used to think it wasn't, that it was enough to write and design your code so that impure code and pure code were separated. This is the approach adopted by Scala. Scala doesn't force purity but it does encourage it and give you the tools to make it happen. After thinking about it some more and spending more time with Haskell I now believe that its purity is worth the effort. I have more confidence in the code I write in Haskell than in any other language and part of this is due to its purity (the other big part is its type system). It can be very difficult to maintain purity in a language that doesn't force it and the temptation is always there to rely on some sort of mutable state. Haskell frees us one from this temptation and in doing so takes away the added complexity of checking, updating, fetching some global or local state. On top of this, the effort required to get around the purity is really not a big deal; the IO Monad really isn't that complicated.
Dependencies are still hard to figure out correctly without being to conservative. New version is on its way to Hackage. (Hackage upload is timing out currently)
&gt; Haskell's purity reminds me of lemon juice: you need to add lots of water, sugar and ice to make refreshing lemonade. Is he saying it needs lots of extensions to make it useful, or is he saying Haskell's superiority over Python makes him feel bitter? 
uhhh... Data.Map? lookup? While Functors are nice, we still couldn't use the same name for vanilla functions and accessors, and changing existing code to use the one or other requires refactoring. There was a discussion on the cafe a while ago, which settled on inline modules: import qualified module Foo where data Foo = Foo { baz :: Quux } import qualified module Bar where data Bar = Bar { baz :: Quux } baz f b = quux2 Foo.baz f Bar.baz b I dunno if there's a H' proposal to enable the type system to disambiguate imports using unification, it _could_ get rid of the qalificators here, after all.
Whoah, whoah, overthinking.
Consider that a lot of applications these days (and more so in the future I suspect) could be linked for the very first time on the user's machine (think plugins) and the importance of APIs that contain information about side effects should become clear.
Yep, he's definitely doing coke.
You're not Simon Marlow, are you? Will the real Simon Marlow please stand up?
I think you misunderstand me (or vice versa). I was going on a tangent that accessors are a better choice than getters because they allow a superset of the functionality, while remaining composable and easy to use. I wasn't speaking of the namespacing issues.
It's especially nice when you don't normally use an older version of the array, since that means it doesn't have to be reconstructed.
&gt; Hackage upload is timing out currently That should never happen. Can you provide more details ?
What language is RC Cola?
"Fast packed strings" is the old name for ByteString, right?
This is the kind of stuff I love hearing about. Thanks, this is is useful information. 
Does it have completion? That always drives me crazy on Windows.
I was surprised to find that it's written in C.
useful for what? it is a very detailed study but seems more like snob spam to me. stay classy haskell! you're getting more popular already, no need for this.
Thanks for this! The long tail analysis type stuff was particularly interesting.
One more cherry cola, to lift up our dead hearts.
This is a really nice beginner's reference -- much more organized and accessible than anything I've written on the subject myself :-)
Yes, so is ALGOL 60. Unfortunately, many of the nice features you want (and really *need*) to use aren't available in '98.
Haskell is a language. It has formal semantics, and it can be optimized. Things can be proven about its local and total behavior, and it provides a solid collection of tools for parsing and extending itself. None of those statements are true of Python, because Python is not, nor has it ever been, a language. What Python is, and the reason that it is useful, is the best foreign function interface yet devised by anyone. It provides a means for library writers to project aspects of their semantics in reasonably repeatable ways into a scriptable FFI composition environment. And it completely rocks at doing that. Now, some crazy (and rather awesome) people have written things that look like python (Language-level Duck Typing yall!) and act like python, sorta, if you squint. And some even more crazy people have worked out formal semantics for something that looks very similar to python, and that's all cool. But python wasn't designed like that. Hell, it wasn't really designed, no matter what Guido says. He added bits, and pieces, and bells, and whistles, and ignored 30 years of prior art, and got it to work with lots of libraries, and that's all cool. In fact, the CPython implementation can _never_ add any form of code optimization, because you can not safely reorder or elide _any_ calls to the wrapped libraries, because you don't know what they do; and all actions in python call through to the wrapped libraries (which is why its so extensible). But baking one pie doesn't make you a baker, building one house doesn't make you a builder, and getting one toy language out the door, with the help of hundreds of other programmers, doesn't make you a language "designer". The folks behind Haskell, for all their foibles, designed _and_ implemented many, many languages before Haskell was worked out. You can talk about "Pragmatism over Purity" all day, but if you don't even seem to know what the rules _are_, how can you possibly talk about what's practical? This is why so much effort has had to go into Python over the years to 'fix' (for rather hacky values of 'fix') rudimentary stuff, like iteration and inheritance. Haskell has lots of problems, lots of things that need to be solved, and by all accounts of the cabal statistics, that's happening very very quickly. But then again, it was designed to be correct by people who'd done their homework, and not as a Christmas hacking project deriving a prettied up derivative of BASIC and AWK: http://en.wikipedia.org/wiki/ABC_programming_language Edit: toned down the rhetoric a bit.
Unfortunately, this is way outdated.
Do I need to write my congressman? What do I need to do to help this happen?
&gt; snob spam Package authors until now didn't know how many downloads there were. This is the first time we've ever had data on this stuff. I think the numbers are higher than we anticipated - which is good, of course.
&gt; Yes, so is ALGOL 60. Well yeah, if you want to use ALGOL you can use 60. 
don't get me wrong I think those are good numbers too but given the context "snob spam" is the only thing that comes to mind.
I think my point was that I don't want to use ALGOL 60 (or Haskell 98 for that matter). I'd like a Haskell standard that incorporates many of GHC's extensions in a manner I know I'll be able to depend on for the next decade.
What context?
I don't know what you are saying either. When a lot of companies (or people) look at a technology, open source technology especially; they like answers to these types of questions. What is the community like? What is the maturity of the application? How many downloads does it get over a year. How active is the mailing lists or user forums? How works on the application, etc, etc. If I say, "the community is great" without any quantifiable metrics than an organization is likely to ignore the technology. 
You must be referring to this: http://www.piumarta.com/papers/colas-whitepaper.pdf
Please tone down your idiotic rhetoric a _lot_.
I know this is 3 week old news, but I only just heard about it.
If I understand it correctly, it's basically based on winhugs... So like most things in C, there's no real reason for it other than legacy :-)
++ for gitit. Been using it daily (inside my xmonad) for about 3 months now. Flawless.
Um, which bit was idiotic? I mean, its a bit of a pent up rant, but it seems pretty factual, and I could talk to you a good deal about how I reached this point.
reddit
I don't think this is the place to put that, besides being the haskell subreddit this info is just a "look mom I have a lot of friends" it is not programming, not even related to haskell itself just some stats about the packages.
&gt; This is the kind of stuff I love hearing about. &gt; Thanks, this is is useful information If berlinbrown's happy, I'm happy.
So...the haskell subreddit shouldn't have anything related to haskell's increasing pervasiveness but instead what Guido Rossum tweets about (see "Guido van Rossum: Haskell's purity reminds me of lemon juice ... (twitter.com)")? This is where I see a disconnect between the 'paid' developer community and others (students maybe?). The large company I work at, if you want to use X open source technology, you have to give a rundown of how it is used, how much it is used and where it is used, by whom. These numbers are exactly what could be used to show others. In relation to 'programming', it may show which packages are more mature than others. Guido's tweet about Haskell or "Haskell is great" blog posts aren't normally helpful. "Task Library Downloads Client-side HTTP HTTP 26203 Database HDBC 3098 XML HaXml 6307 Control mtl 12517 Parsing parsec 8468 Binary Parsing binary 15752"
hehe, it is the only thing that matters. I am thinking I want to use haskell for another project but I haven't gotten around to it yet.
This is awesome work. Then we can get the top 100 packages into Debian. Step 3 will be profit.
iirc, there was a 'packed string' before ByteString. But in general, yes, not only is FPS the same as ByteString, but I believe 'ByteString' still uses the term FPS internally as the name of the constructor for strict bytestrings.
&gt; These numbers are exactly what could be used to show others. Woot!
Also, function composition is cool! main = do (arg:_) &lt;- getArgs text &lt;- readFile "extended_words" putStr . unlines . sort_lines . filter (line_matches arg) . lines $ text
They're already lenses: data R = R {x :: Int, y :: Int} r = R 0 1 -- Getters x r == 0 y r == 1 -- Setters r { x = 1 } == R 1 1 r { y = 2 } == R 0 2 The syntax may not be the nicest thing, but it's there. Just use any value of a record type as if it were a function taking the funny {field=...} thing as an argument. For the syntactic precedent, consider record-style pattern matching.
Well, 1) Python _is_ a language. 2) Python programs can be _extensively_ (automatically) optimized. 3) Guido is really good _designer_. Isn't it obvious? If not, here are some hints: 1) This is so obvious that I really don't know what else should I say. Even ABC _is_ a language (take a look at link you have posted :-) 2) Should I point at PyPy? Psyco? Maybe even V8 or HotSpot? 3) Design is about making things easy. And Python scores pretty good in it â€” you won't find Python tutorial that explains monomorphism restriction right after basic arithmetic. What I really don't like in your post is it's "Haskell is _so_ superior to Python" tone. Because you can only say things like that after majority of people will start using Haskell instead of Python for getting things done â€” and we're _very_ far from that mysterious point in time now.
of course the twitter shit should be downvoted to hell, in fact twitter itself should be gone from the face of the web but that is unrelated; if I were to start worrying about gossip I'd rather hide under a rock or kill everyone on this planet. now, you've said this is useful to prove the language's popularity, I admit I haven't considered it from that angle and yes, if you need to "prove it" then it might be useful. /me removes downvote EDIT: [:'(](http://www.reddit.com/r/twiddit/ "just saw it, happiness halved")
As a package maintainer, it is very interesting to know that this stats are collected. I'd love to have them published on a more frequent basis (realtime?). Also, per-version statistics would be great.
I'm working on polishing the script. We should at least have monthly or weekly stats soon... Let me know what kind of information you think would be useful.
Awesome :) Mostly I'd like to compare the popularity of various versions of a package. As somebody mentioned, I'd be nice to overlay this information on the dependency graph, though not a top-priority for me.
Bookmarked! Thanks so much for writing up this tremendous response. I learned a lot from it and I'll definitely refer to it in the future.
zlib now lint-free on debian :-) Tue Mar 24 12:05:44 GMT 2009 Duncan Coutts &lt;duncan@haskell.org&gt; * Fix "api" to "API" in description in .cabal file Apparently it's a debian package lint warning! :-) I'm glad they take these things seriously. 
Gentoo does provide some binaries, although I don't know if xmonad is included.
Proof that twitter is utterly fucking useless. Not even a link to something usefull relating the the subject. Die twitter die.
You have to admit, it's the language you stole _layout_ and _list comprehensions_ from! ;-)
I wouldn't call that a "lens" because: A. The setter is not a function, and not composable. B. The getter and setter are not coupled, so cannot be composed and used together. 
Yay! I like it. But I dislike the purple/blue version in the reddit header :/
Congratulations! I personally think this colour is not too bad.
Post a better color scheme! Note also the original had 4 different segments.
by how much is it winning?
That makes sense. Otherwise I was wondering how one could have enough Haskell enthusiasm to write an interactive GUI for it, but not enough to actually write it in Haskell.
That looks like Lisa Simpson giving a blowjob!
Haskell already has lots of syntactic sugar and its pretty cool, so I feel refreshed already.
Someone did it already :D
Excellent -- I voted for this one.
RC Cola is Common Lisp---mostly ignored, but its aficionados go breathless proclaiming its superiority.
[â™¡](http://www.haskell.org/pipermail/haskell-cafe/2007-November/035263.html) One of the cool things about this (and either syntax should work) is that you can define lenses for some ordinary functions, like sort. Imagine `update (head . sort) (const 'i') "whale"` = `"while"`.
I liked the logo until I saw this. I don't think it's wise to associate haskell with the failtrain.
Uh... They're really not that similar...
Urgh... are we going to see the new Haskell logo photoshopped onto increasingly ridiculous objects now? And then websites that allow you to upload images to have this process automated (created, of course, with HAppS)?
They seem pretty similar to me -- taking off the lambda's right leg almost gets you there. But this is of course a fuzzy area, and would be boring to have an argument about. On the bright side, amtrak.com seems to suggest that they no longer use that logo.
"He'd see everything!... I mean... he'd see the big board!"
For the subreddit icon, it might look better shifted down a few pixels so the baseline lines up with `reddit` and `HASKELL`. Beautiful logo, though. Love it. `EDIT:` Thank you! reddit looks a little lonely dangling off on the right there, but the idea of lining haskell and reddit up with the baseline and midline respectively is a clever one. One thing you might try: you could put `haskell` beneath and `reddit` above.
I would definitely fly on that airline.
Where does it say this is in Haskell?
Indeed if you take my: data Accessor whole part = (whole -&gt; part, part -&gt; whole -&gt; whole) And reorganize (whole -&gt; part, part -&gt; whole -&gt; whole) into: (whole -&gt; part, whole -&gt; part -&gt; whole) you see that there's a common (whole-&gt;) in both tuple elements, so you can take it out and get: whole -&gt; (part, part -&gt; whole) which is the focus function. So Accessor is isomorphic and indeed has all the Category/arrow niceness
so..."The Big Board" is powered by haskell? Shouldn't it be more like this: http://yfrog.com/08bigboardpowereddbyhaskep
It seems that perhaps you've not really read my post, or I failed to be sufficiently clear for you. First) Python, or rather CPython, really isn't a language. It isn't just that it is difficult to describe its semantics, but that it is actually not possible. Python translates its syntax into a recipe for delegation to external semantic providers, even for its core data types. These providers can do absolutely anything, even launch the rockets. Now, that is why python is such an effective FFI, and why its so useful. No one said it wasn't useful, in fact I said quite the opposite in my post, multiple times. But being useful and easy to use doesn't make a thing a language. To be a bit more formal, it is possible to define infinitely many languages, all which run in the CPython environment, with wildly different behavior processing the same code. I know, I've done it, a lot. Second) Python programs can _not_ be optimized by computer. Since there are no uniform semantics, you cannot know the result of any particular code change. You can't remove any lookup, reorder any code, and be certain that it was safe. Now, you can fake it. You can write heuristics which work on some code, usually. Which can get you pretty far; but they'll always be fragile. Third) PyPy and Psyco are languages based upon python, which have implemented their own, much restricted, set of semantics. They are very interesting projects, and I suspect that long term, PyPy will ultimately subsume Python, because there's nothing to slow down their compiler research. V8 is a virtual machine for ECMAScript (JavaScript) which in fact has much stronger semantics than Python, and I'd say that it was actually a language. HotSpot is a virtual machine for JVM code, which again, has well defined semantic properties. In this regard, both are much stronger than Python, and not good support for your criticism. Fourth) Being popular doesn't make you right. Guido built something people like, and that they use a lot. But it has core problems that have been extremely expensive for the Python community to attempt to address; problems with threads, problems with optimization and lazyness, problems with mathematical accuracy and type enforcement. Python is successful, but it wasn't well designed, and Guido et all have spent the past decade trying to work around that. Python is useful, it is popular, but it has warts. Being useful and popular doesn't make you _correct_, and you need _correct_ to write an optimizer.
Jefferson Heard, the author, says so (he posted asking for deployment help last week on haskell-cafe).
[Yes](http://galois.com/~dons/images/lambda_death_star.jpg)!!!
Don't you mean Yeeeeaaaaaaah!?
http://imgur.com/3KTJ.jpg
In your opinion, to be considered a language, thing has to have formal semantics. In my opinion, to be considered a language, there should exist people who are willing to speak it. In your opinion, if language has no formal semantics, it can't be optimized. In my opinion, if a multiple real working optimizers exist, language definitely can be optimized. And, finally, popularity means that many people believe that you are right. And this is the most important thing â€” because programming is not about machines, it is about people.
"And, finally, popularity means that many people believe that you are right. And this is the most important thing â€” because programming is not about machines, it is about people." Well, sorta. See, it has to actually _work_. Computers don't care what you believe, they only care what the code says. Most of the work done on CPython in the past ten years has been attempts to work around the core design mistakes that were made when it was first written. On a meta point, I'm not really sure why you seem so upset by this. I've certainly made the claim that python is useful, and interesting, and popular. But ultimately, you are correct in that I am in fact arguing that languages posses something like meaning, and python doesn't. You refer to the fact that there are (many) people who 'speak' python. I'll grant you this. But I'll also point out that their understanding of what python 'means' is wildly inconsistent; not because of their faults, but because of the language. And worse, the executable generally disagrees with them as well.
It's okay. I like pretty much [every single other one](http://www.haskell.org/logos/results.html) better, especially the five below it. I guess using Haskell inclines one to simple expressions with compound interpretations over graphical *aesthetics*. EDIT: Spelling
yes! the one i wanted and neglected to vote for. =D
In no way I am upset by what you think I am upset by. I was upset by phrases like "But then again, it was designed to be correct by people who'd done their homework, and not as a Christmas hacking project deriving a prettied up derivative of BASIC and AWK" I don't think this haskell-is-so-superior tone is ok. Because of this tone I thought you are just some crazy haskell fanboy. Now it looks like you are not (but I can be mistaken here :-) I think I can see your point (which I disagree with), hope you can see mine. And I'm too lazy to turn this into yet another flamewar â€” let's stop here.
It reminds me of the Commodore logo for some reason. EDIT: I'm not saying that's a bad thing :)
Well, it's not ridiculous yet. The train makes sense, since the new logo looks a lot like the old AMTRAK logo. You can take it as a complement, though I wouldn't. The logo is really bad though. It makes me want to disassociate myself from an old and dying system, rather than embrace the new hotness. It's the kind of logo that you usually have a logo contest to replace. That said, it's better than the old python snake logo.
Link?
Beg your pardon? Link to the /r/haskell logo at the time of my post? I didn't think to take a screenshot.. Actually I see the logo has been improved even more now..
I didn't vote, but it would have been my choice. Agree with those that are saying that the color scheme isn't right for Reddit though.
&gt; I guess using Haskell inclines one to simple expressions with compound interpretations over graphical ascetics [sic]. I'm assuming you meant "aesthetics", in which case you are basically saying that everyone else's aesthetic judgment must be somehow impaired because they don't agree with your's. Does it make you dizzy, what with the world revolving around you like it does?
I know... I was asking if it might be ready sometime soon. It's like I'm talking to a brick wall here!
I think the vote-runner said it was up by a 100 or 150 in however the Condorcet scores things. So a good margin was my understanding.
so, you squeezed the right side for perspective, but didn't warp it or try to match it up with the equator? \*sigh\*
__BREAKING NEWS__: Logo design space well explored! All simple concepts already taken! Seriously, people, come up with the logo that doesn't look like something else, and it'll probably not be in serious use for a good reason. It's all been done, if you squint enough.
&gt; Now I'm confused why you can't use what is in Haskell Prime as implemented in Glasgow Haskell. The idea of having a standard you can count of being implemented across compilers seems to confuse a lot of people nowadays.
Go nuts... this isn't my job.
Great choice. It was clearly the best one there.
&gt; Well, it's not ridiculous yet. [It will be](http://www.reddit.com/r/haskell/comments/877cu/official_haskell_logo_placement_thread/). Just a matter of time. ;)
Oh, I thought the dull, grey one was the old one, not the improved one. I hope to logo color scheme gets modified to something a little more vibrant.
In my â™¥, **C=** â‰« **ã€‰Î»**=
Reddit should have stuck with the Narwhals one.
Well I disagree. It's not the one I would have voted for, I was a fan of the mountain, but I think it's clean, simple and clever.
hmm. there's a lot that's unsatisfactory about this, so I wrote to the author.
I wonder if the author knows about the ghci debugger. It's possible he does, but doesn't consider it a realistic option because it is, admittedly, a bit hard to use. Maybe some enterprising Haskell bloggers can produce some more intro materials or walkthroughs for it. http://www.haskell.org/ghc/dist/current/docs/users_guide/ghci-debugger.html
http://donsbot.wordpress.com/2007/11/14/no-more-exceptions-debugging-haskell-code-with-ghci/
So did I. He may be in for quite a lot of haskell spam today, the poor guy.
Seems like he just didn't find all the right tools. My guess is he was using hugs or ghci as well...
Yeah, it doesn't resolve the namespacing issues, its only a minor peeve I have with Haskell's record field names being defined as getters. Also, there's a minor refinement, replacing the pair: (whole-&gt;part) (whole-&gt;part-&gt;whole) with: (whole-&gt; (part, part-&gt;whole)) 
135 people preferred it to the one that came second, and 100 people preferred the one that came second.
A debugger is the wrong answer to this one anyway. Learn to see the thunks.
I am getting better at seeing the thunks myself, but it has taken a lot of practice. I also did a lot of experiments with Debug.Trace in ghci to find out when things are getting evaluated.
Be aware that there is some fine print here: &gt; The Edison Design Group (EDG) front-end is used to parse C and C++ applications. Although the EDG source code and interfaces are protected, they may be distributed freely in binary form. (from: http://www.rosecompiler.org/ ) While the EDG parser is a good one, it is not open source and so this may not be an option for some who need an open source front end as well. YMMV. Isn't there a C/C++ parser being developed in Haskell? I wonder how easy/hard it would be to plug that one in instead.
that is an incredibly short blogpost... interesting...
&gt; In practice, this means that you have to pay excruciatingly close attention to every single expression you write, or as soon as you run your program on non-trivial input, it will either run very slowly, eat all your memory, die with a stack overflow, or all of the above. Could you respond to this statement? While it is admittedly hyperbolic, I have also experienced similar troubles, and would welcome hints on combating such difficulties.
Hint: it surely isn't helpful for productive discourse to use a different definition for "programming language" to everyone else. There are better ways to make your point than to redefine terminology.
You can't see the thunks. That's impossible. Instead, realize that there *is* no thunk; it is *you* who evaluates.
Use ghc -O2 and a few strict types (like Data.ByteString). You will have to learn to understand evaluation strategies different to the (default?) strict strategy, that's inescapable. It just doesn't need to be a hurdle.
I've been bit a few times by the laziness of MVar's &amp; friends. I have had code do numerous updates to (non-strict) fields in a struct without the contents being used very often. I ended up piling up structure-modification-thunk after thunk until I ran out of resources. The solution in my case was to mark my structure fields as strict, but I also probably could have used seq or $! when updating the MVar.
&gt; Isn't there a C/C++ parser being developed in Haskell? It baffles me that there are C++ parsers *at all*. Then again, there are plenty of masochists on the planet...
Use the strict-concurrency package for strict-on-write MVars
Click the link at the bottom... :)
I know I've proposed this elsehwere, but have you seen this in a more formal setting? Perhaps you have a link to a paper?
There is a [step-through debugger][00] in `ghci`. I'm not sure whether to upmod or downmod this post. It calls attention to a common problem for early Haskellers but it sums the matter up in a way that's ridiculous (no more laziness!) and false (no runtime debuggers or traces!). [00]: http://www.haskell.org/ghc/docs/latest/html/users_guide/ghci-debugger.html
&gt; My guess is he was using hugs or ghci as well... If we was using `ghci`, wouldn't the step-through debugger have been enough?
I really don't think that I'm redefining terminology. I am attempting to make a distinction between things like Fortran, C, Java, SmallTalk, XSLT, Haskell, Scheme, Pascal, Ada, JavaScript, Prolog and even PHP to an extent, which are all programming languages; and TCL, Python, and just-maybe Sh, which are more wiring or glue languages. The former category (programming languages) describes processes, algorithms, and values. It describes what things "mean". The later category (glue languages) describes how components get wired together. They aren't the same, they never were, and I would think that most programmers would be able to tell the difference.
I don't have any references, but Mark Jones suggested something similar in his thesis, where records was one application of qualified type. And ever since improved records in Haskell have been discussed I've seen the one-class-per-field proposal.
Yes.
&gt; Isn't there a C/C++ parser being developed in Haskell? Yes, we wrote a C parser (see `Language.C`) but a C++ one is a good deal harder. I don't know of any in development.
Yes, C++ is difficult to parse. It's not surprising that gcc's c++ frontend is probably the only freely available C++ parser. I wonder if gcc's C++ frontend could emit something that is useful for this sort of tool?
The task now is to take that design as inspiration to prepare * icons, * logos, and * banner graphics with color, shapes, and suggested text. 
In the `fib` example, `memo` is freed after every call, I'm pretty sure. I gather this is actually what you want for the matrix multiplication example.
I don't know what Peaker has in mind, but something more like focus can be somewhat more efficient than a getter-setter pair. Suppose you have a lens to the thousandth element in a list, and do: modify thousandth (+1) or something. With the getter-setter, that's: modify lens f l = let x = get lens l in put lens (f x) l Whereas with focus it's: modify lens f l = let (x, put) = focus lens l in put (f x) But, in the second case, `put` is essentially already a list with a hole waiting to be filled; when you provide it with an element it prepends it to the tail, and then prepends the already pulled off prefix. An implementation could look something like: nth :: Int -&gt; [a] -&gt; (a, a -&gt; [a]) nth 0 (x:xs) = (x, (:xs)) nth n (x:xs) = let (y, f) = nth (n-1) xs in (y, (x:) . f) With a getter-setter, the getter traverses all the way to the thousandth element, and then throws the context away, returning only the element. Then, the setter traverses all the way to the thousandth element again, and throws away the element in favor of its replacement. So, a lens like `whole -&gt; (part, part -&gt; whole)` is duplicating less work in general.
yes to both. for fib it might make sense to retain memo, but fib was meant just as an explanatory example anyway. for most dp problems the values in memo depend on the specific instance of the problem and there's no point keeping it around
Oh, I did, but it's still a little jarring... but interesting!
A big problem, at least in Haskell, is that Strings aren't arrays. Many algorithms (e.g. Knuth Morris Pratt, Levenshtein Distance..) assume O(1) access to any character. I haven't yet heard of a satisfying solution to that problem.
Use Char arrays?
Bytestrings? Also, specifically, http://hackage.haskell.org/cgi-bin/hackage-scripts/package/stringsearch . I've found no issues with those BM and KMP implementations that'd make them unsatisfying.
Can we have recordings? Quality doesn't really matter, an audio-only or webcam-quality record is better than none at all... actually, audio cut onto the slides might be the best format for talks there is.
IIRC, GCC is specifically designed to make it hard to do this, to prevent "non-free" tools from making use of its front-end.
The first definition of `fib` given seems to be very wrong. fib n = foldl (+) 1 [1..n] That's just `1 + sum n` isn't it?
!!! you're right.. i fixed it.. that was supposed to have been a placeholder so i could write the rest of the post without thinking too much. forgot to change it in the end! fib n = fst $ foldl (\a b -&gt; (fst a + snd a, fst a)) (1, 0) [1..n] 
 $ ghci GHCi, version 6.10.1: http://www.haskell.org/ghc/ :? for help Prelude&gt; :m + Test.QuickCheck Prelude Test.QuickCheck&gt; let fib n = foldl (+) 1 [1..n] Prelude Test.QuickCheck&gt; let prop_sum n = 1 + sum [1..n] == fib n Prelude Test.QuickCheck&gt; quickCheck prop_sum OK, passed 100 tests.
the idea and implementation look very like Warren Burton's "improving values" from the '80s: represent a value by a list of improving approximations (lower information bounds). or &amp; and correspond to min &amp; max. lazy evaluation itself is also built on a representation that moves from less information to more information, but uses side-effects (thunk replacement) for efficiency. warren pointed out that the list representation doesn't have the efficiency that the in-place update has. for instance, once a boolean representation (`Answer`) is known to be equivalent to `Yes`, the list traversals still have to happen each time. 
When can we get the T-shirts?
I really like it. It was the one I would have voted for if I had voted... I'm glad it won.
Would the developers of Haskell please slow down! I wouldn't normally ask that, but I'm seriously starting to suspect that there's a limit to how many times my head can explode. 
You would have to lift yourself to asploding. 
It's fairly straightfoward to prove the correctness of a function. However, it's more difficult to determine if a function maintains laziness. Are there any algorithms or tools that can verify the laziness of a function? Ideally, an algorithm should be simple and straightforware and tools could be incorporated into automated testing (e.g., HUnit, QuickCheck).
Your brain eventually gets used to it, or at least quits complaining so loudly ;-)
"strictcheck" and "chasing bottoms" are your friends.
You can test non-strictness by testing inputs with undefined. &gt; take 3 $ concat ([1,2,3]:undefined)
Even for something that simple, doing a modify with get-set would fully inline into something like: modify f v = case v of Blah _ _ c -&gt; case v of Blah a b _ -&gt; Blah a b (f c) It's conceivable that the compiler would optimize this into one case expression, but then once we start composing lenses with one another, or using them in situations that are less amenable to inlining and such, that sort of automatic optimization becomes harder to achieve. Edit: I should note that this of course is all in tension with constructing and destructing tuples in this representation, so it's indeed possible that there's no real gain. One other advantage this type has is that its composition is nicer to look at, I think: Lens focus2 . Lens focus1 = Lens $ \whole1 -&gt; let (part1, replace1) = focus1 whole1 (part2, replace2) = focus2 part1 in (part2, replace1 . replace2) as opposed to something like: Lens get2 set2 . Lens get1 set1 = Lens (get2 . get1) set' where set' part2 whole1 = let whole2 = get1 whole1 in set1 (set2 part2 whole2) whole1
Is it to soon too change the [wiki page](http://en.wikipedia.org/wiki/Haskell_(programming_language)? 
Yes, to agree with roconner, it's not terribly difficult to determine whether a given function is lazy. I recommend reading "Introduction to Functional Programming using Haskell, 2nd Ed" by Richard Bird. It has a nice discussion of such details. More recent books probably have good discussions too.
For examples, check http://moonpatio.com/vacuum/dlist.html or http://moonpatio.com/vacuum/sequence2.png
Ridiculously crazy awesome.
Let's practice scientific precision: it's very useful... * to learn how sharing works * to fix problems memory-usage problems (how does it scale?) Thank you Matt Morrow!
But this is actually a monadic parser, it just doesn't use the Monad typeclass! (&gt;&gt;=) = (&gt;.) return x = Parser $ \_ -&gt; x 
Looks great, but how do I use it? The vacuum function is pretty useful alone, but how do I make the pretty pictures?
Yes, [as I already said](http://www.reddit.com/r/haskell/comments/87v5v/use_vacuum_to_graph_your_heap/c08hpsw) :-)
Indeed.
LEWL
Those definitions won't type check, since (&gt;.) :: Parser -&gt; Parser -&gt; Parser doesn't match the type of `(&gt;&gt;=)`, and the type of function wrapped by `Parser` is: State -&gt; State For his `State` defined in the article. Unwrapping a little, you can see this as close to: Maybe (ByteString, Int) -&gt; Maybe (ByteString, Int) which is quite similar to a parsing monad: Parser a = String -&gt; Maybe (String, a) And you can, of course invent combinators corresponding to his for this type. Note that these use only `Applicative` combinators, not monadic ones: -- Everything works with Parser Integer nothing = pure 0 i = char 'I' *&gt; pure 1 v = char 'V' *&gt; pure 5 -- ... adding p = p subtracting p = negate &lt;$&gt; p -- &lt;|&gt; is from Alternative p |. q = p &lt;|&gt; q p &gt;. q = (+) &lt;$&gt; p &lt;*&gt; q I think that covers the bases of what's in the article. But note that since all we're doing is parsing pieces into integers and then adding them up, we could instead add a hidden `Integer` state and add or subtract things as we go along. Then we'd have nothing to return in the parameterized place of our parser, so they'd all have type `Parser ()`. And this is exactly what the parser in the article does, dispensing with the parameterization. When you have such an applicative, and you restrict yourself to only things with type `Parser ()`, what you have is the monoid of 'side effects'. `pure ()` is the identity element, an `(*&gt;)` (called `(&gt;.)` in the article) is the multiplication. Parsers, of course, have a second monoid structure, where `(&lt;|&gt;)`/`(|.)` is the multiplication, and the trivially failing parser is the identity. So, it's probably most appropriate to say the parser in the article is a type with two interacting monoid structures (not sure what you call that; dimonoid?), but is, strictly speaking, not a monad. P.S.: The above parser is not the usual monadic one. Usually you'd use: String -&gt; [(String, a)] Which keeps all alternatives around at choice points. With the maybe instead, you can write parsers such that (a &lt;|&gt; b) *&gt; c /= (a *&gt; c) &lt;|&gt; (b *&gt; c) For instance, if you look at the parsers corresponding to the regex-like notation: (abc|ab)c abcc|abc trying to match on the string "abc", then the first will choose abc in the parentheses, and then will be unable to backtrack when it finds out it needs yet another c to parse, while the second will backtrack out of the first case and into the second case. The parser in the article has the same behavior, I believe.
What a clever plan those archers have. Cater to millions of haskell programmers, and their distribution will become the most popular. 
I propose to rename Arch Linux to Harch Linux. 
Yeah, I was sad to see that there are no haddock links on that hackage page, because this otherwise seems wonderful. EDIT: found this, though, which has some example code: http://moonpatio.com/vacuum/haddocks/GHC-Vacuum.html
Does this mean using DPH has been difficult or unimpressive?
Does this (or will it) show unevaluated thunks, or does it force evaluation?
Get a few haskellers as package maintainers and you will have upgrades without side-effects ?
I get it. The upgrades will be lazy. You are running pacman -Syu, and it reports that loads of packages are upgraded (not really). Then you start Firefox, and upgrade kicks in AS NEEDED. So you sit and wait. 
I think it's more that the physics engine is difficult in the first place, without programming it on top of a moving arrays library.
Yeah, I should have worded the question a bit differently, I think.
All very well and good, but this showing off with the state monad that results in a function that has a bug, as you see further in the thread. Claus Reinke presents another derivation, for the corrected function, at http://groups.google.com/group/fa.haskell/browse_thread/thread/4240bc7c7abd4d30/24d3fc252ce0b8d5 The corrected stateful version is takeListSt' = evalState . foldr k (return []) . map (State . splitAt) where k m m' = cutNull $ do x&lt;-m; xs&lt;-m'; return (x:xs) cutNull m = do s&lt;-get; if null s then return [] else m not nearly as beautiful as the original (and incorrect), takeList = evalState . mapM (State . splitAt) but oh well. Me, I still like partitions [] xs = [] partitions (n:parts) xs = let (beg,end) = splitAt n xs in beg : ( case end of [] -&gt; [] xs -&gt; partitions parts xs) until we get a version of mapM that does the right thing when fed a list of stateful computations, I stil think the version with explicit pattern matching and recursion is the most beautiful of the bunch.
Meh, we're too lazy to do that.
I do all of my version numbers in Roman Numerals...
Well, yes, the record syntax is entirely borked and non-firstclass. The approach you proposed isn't much better though, IMO. The (.^) function is just a more restricted version of flip($). The (.&gt;) function is just a more restricted version of composition of arrows. Nothing new we can't already do, just an OOP syntax for it. First-class issues aside, the biggest thing missing from the current system are automatic generation of functions Part-&gt;Whole-&gt;Whole which gives composable updaters so we can treat records as monadic state. *edit:* oops, I meant to say (Part-&gt;Part)-&gt;Whole-&gt;Whole
Fortunately the time to download and install Firefox is only a fraction of the total startup time.
I think he's currently trying to figure out how to determine if there's an unevaluated thunk without evaluating it, but it's difficult.
Wow, quantity is such a great way to measure quality.
Nice. Very nice.
Did you know you can pattern match in lambdas? fib n = fst $ foldl' (\(a, b) _ -&gt; (a + b, a)) (1, 0) [1..n] Also, since you're not using the second argument, you might consider using `iterate` instead: fib n = fst $ iterate (\(a, b) -&gt; (a + b, a)) (1, 0) !! n
I wonder if the OverloadedStrings extensions could be used here.
I love how cabal-install failed to install the game, but the game was already obviously installed already, and the failure was ignored. ;)
Yeah, apparently the docs weren't in the dist bundle. The author's corrected that in latest release.
(IntMap.fromList (zip [1..20] (repeat (0xdeadbeef::Int) ==&gt; http://galois.com/~dons/images/intmap.svg
I thought that the narwhal logo got picked? What happened? That was the reddit haskell logo for a while...
Instead of __ to do the gettext call, yes, but then pot file generator would know how to find the strings that you want to translate.
The problem I have with this whole line of i18n is that it doesn't scale. For "sentences" with more than one hole in them, string-for-string replacement can't accommodate all languages because of reordering of phrases. The proper solution would be to define each "sentence" rather than each string segment as the level of i18n.
i find myself in the unenviable position of making a website. i was dreading it until this article . thanks.
Also translation for some sentences depends on context. Example I encountered when I tried to translate Abiword (a few years back) to Czech. There was a page in print dialog to select which pages should be printed. One of the options was "All". This is translated as "VÅ¡echny" - female gender as it relates to word "strÃ¡nka" (a page). But the same "All" was used in other contexts where different mode was required, leading to variant "vÅ¡echno" or "vÅ¡ichni". This requires to use unique keys for each occurrence (common in Java, but not in gettext).
For some reason all the videos you post cause the buffering icon to stay permanently playing in the middle of the video. Anybody else get this?
We could change hgettext to use the ghc api to extract the strings based on type.
Hey dons, love the videos, but I think it'd be beneficial if the fonts were bigger (or the window was smaller) so that we could easily read what's written. Nevertheless, keep this up, it's a nice and quick way to learn about cool Haskell libraries.
Cool, thanks. I'm slowly approaching a good screencast, in the limit :-)
I'd suggest linking to `&amp;fmt=22`.
Me too, when viewing the HD version.
Using the ZipList applicative functor: f &lt;$&gt; list1 &lt;*&gt; list2 &lt;*&gt; .. &lt;*&gt; listn I believe it is also possible to model his function more faithfully using type class numbers; however I think the above use of applicative functors is better, even if it isn't perfectly analogous to his function.
Presumably toLower is slow because the function works on any Unicode character? 
Yup. It's just a call to wtolower, in a C library.
i've made a little page for vacuum @ [http://moonpatio.com/vacuum](http://moonpatio.com/vacuum) Glad to hear it's useful! :) It's soo addicting..
It's kind of hard to define what exactly this means, since the top-level of what "vacuum" gets handed is usually a thunk itself, so under what conditions should it force and/or not? If we think of a good heuristic (e.g. only force the top-level, and nothing else (this sounds reasonable)), it could be done for sure.
You're welcome! :)
ImageMagick's montage is super useful for making pretty sequences of images. I use this page as a montage-options cheatsheet [http://www.imagemagick.org/Usage/montage/](http://www.imagemagick.org/Usage/montage/)
Yeah, for some reason Cabal seems to think that some type in there isn't Cabal's when it really is. I'm not sure what's happening. The current haddocks will remain at that link though.
err, s/Cabal seems to think/GHC seems to think/, which is even more odd.
it'd be godly if this were put into haskell-mode for quick visualizations when writting code
Here's v0.2: http://www.youtube.com/watch?v=nQkhELdAYB8 And v0.3: http://www.youtube.com/watch?v=oujaqo9GAmA
To me, this sounds a bit like complaining that in Lisp, `'(1 2.0)` doesn't automatically convert the 1 into floating point. 
Just plain old `vim` and the interpreter are starting to look a lil' shabby...
Sorry, I forgot to mention I did indeed mean the HD version.
http://hpaste.org/fastcgi/hpaste.fcgi/view?id=3039 yes it is too hard to use. but I've never used zipWith4, and I can't remember using zipWith3. replicate/map/zipWith are so diefferent that it is nice to use different names for them. Even though there are difficult things to typecheck in haskell, it is still much better option than no types at all. Without types you loose that warm feeling of writing complicated (complicated means that there are many types involved, diddling with (NumOrString a ) =&gt; a/[a] isn't complicated) program that works on the first try.
Eric want map to combine *corresponding* elements. This applicative code is all ways, like the List monad: (+) &lt;$&gt; [1..3] &lt;*&gt; [10,20,30] [11,21,31,12,22,32,13,23,33] 
Force nothing, is what I would like to see. I'd like to be able to step through an algorithm and observe evaluation as I go. I don't see anything wrong with also offering WHNF, but force-nothing just seems more useful to me (and possibly easier?). [Edit: A harder one, but huge bonus points for showing what a thunk references, too!]
That's why roconnor specified the `ZipList` applicative functor, not the `List` applicative functor. To accept plain lists, it would look like: getZipList $ f &lt;$&gt; ZipList list1 &lt;*&gt; ZipList list2 &lt;*&gt; ... &lt;*&gt; ZipList listn
See roconnor's version for a more general way to express it.
what's the fun when you can/must insert symbols everywhere? the point is, it should be easy to call (as easy as other functions). edit: besides, I use the same idea but in "nicer" wrapper
The Haskell Reddit logo changed between the candidates up to the final vote.
Doesn't require undecideable instances, for one. ;)
I'll nerver understand why you don't like undecidable instances, but runtime bottoms are fine.
I *don't* like that just any value in Haskell might be bottom.
Unless I am mistaken, part of the problem could be solved by allowing existential typing. For instance, showables :: [exists a. Show a =&gt; a] showables = [1, 2.0, 'a', "Hello"] main = print $ map show showables == ["1", "2.0", "'a'", "\"Hello\""] Though it does not entirely solve summing different numeric types, it would make expressing certain things a lot more elegant. The summing might be doable with something like add :: (Num a, Num b, Num c) =&gt; a -&gt; b -&gt; c with lots of guard clauses handling the different types. It wouldn't be elegant, but it should work.
I don't find the sum complaint very compelling. Just convert all the elements for the list to the same type before summing. If you desperate need to use more than one number type for some strange reason, you could use a simple union type data Number = Integer Integer | Int Int | Float Float | Double Double | Complex (Complex Double) and make it an instance of Num. You probably could restrict it to the few number types you will be using.
&gt; the point is, it should be easy to call (as easy as other functions). Personally I find using `&lt;*&gt;`s to be acceptable, but would using [idiom brackets](http://www.haskell.org/haskellwiki/Idiom_brackets) satisfy you: iI f zipList1 zipList2 .. zipListN Ii 
Yeah, me too. 
The first complaint seem slightly off-base: GHCi, version 6.10.1: http://www.haskell.org/ghc/ :? for help Loading package ghc-prim ... linking ... done. Loading package integer ... linking ... done. Loading package base ... linking ... done. Prelude&gt; sum [1.5, 2, 3, 5.9] 12.4 Let's add complex numbers too: Prelude&gt; :m +Data.Complex Prelude Data.Complex&gt; sum [1.5, 2, 3, 5.9, 3 :+ 5] 15.4 :+ 5.0 This only works, of course, because of the magic of fromInteger. Using terms of different definite types will cause it to fail. I think this is a reasonable trade-off for type-safety in other areas, and is even the right (DWIM) thing much of the time in the numeric case
And besides: http://hackage.haskell.org/cgi-bin/hackage-scripts/package/data-accessor http://hackage.haskell.org/cgi-bin/hackage-scripts/package/data-accessor-template 
You get similar issues in Japanese where in certain contexts (e.g. a menu) a noun or other abbreviation is most appropriate, whereas in other contexts (e.g. a dialogue) you need a verb form of "the same word" in order to construct a grammatical sentence. This is part of the reason I was being loose about saying "sentence" when I meant, essentially, any use site. Translation between languages with any degree of morphology is far more intricate than concatenating strings. In English and Chinese you can almost get away with concatenation, but even there you run into the non-linear issue. It's a hard problem to begin with, made only harder by the fact that most programmers know too few languages to anticipate the design flaws. (And most programming languages have too weak a type system to handle the irregularities and specificities of natural language.)
This would break the following code. f :: Float -&gt; Float f x = x + 1 Why? Because the type of 1 would be ambiguous.
If I try to run main = print 1 with -Wall I get the following warning: Warning: Defaulting the following constraint(s) to type `Integer' `Num t' arising from the literal `1' at E:\test2.hs:1:13 In the first argument of `print', namely `1' In the expression: print 1 In the definition of `main': main = print 1 GHC is already smart enough to default to a useful type. The same could be done in your scenario.
So far, the issue seems easy to solve using Template Haskell.
Discuss.
Like this?: http://en.wikibooks.org/wiki/Haskell/Existentially_quantified_types
Varargs (polymorphic) in Haskell: http://okmij.org/ftp/Haskell/types.html#polyvar-fn With FunDeps, you can get a bit of dependent typing, giving you (arbitrarily-) fixed-length lists (monomorphic) http://www.haskell.org/haskellwiki/Functional_dependencies ...and with -XExistentialQuantification you can get any implicit run-time typing you will ever need. Granted, all these things aren't things you'd want to deal with as a newbie, and rightfully so, because even experienced Haskellers think thrice before using them: Wanting to use them is usually a sign of an unclear formulation of your understanding of the problem you're trying to solve, not a streak of genius. Last, but not least, dynamic typing is shunned in Haskell because of two reasons: First, t requires run-time support: Not having any types left in the compiled code means faster code. Then, it's just too annoying to have to run a program to figure out that it won't work.
Explain. 
Duh, if I told you, you'd stop thinking.
This post dovetailed nicely within some programs that I was writing. You can make this within spitting distance of C, if you [make your own lowercase function](http://www.brool.com/index.php/haskell-performance-lowercase) and [avoid array creation](http://www.brool.com/index.php/haskell-performance-lowercase). The following runs about 2x slower than C by using STUArray and ByteStrings. import IO import System.Environment import Data.Char import Data.Word import Data.List import Data.Monoid import Data.Ord import Data.Array.ST import Data.Array.Unboxed import qualified Data.ByteString as B import qualified Data.ByteString.Internal as BI import qualified Data.ByteString.Char8 as C ctype_lower = listArray (0,255) (map (BI.c2w . toLower) ['\0'..'\255']) :: UArray Word8 Word8 lowercase = B.map (\x -&gt; ctype_lower!x) letter_ind c = (ctype_lower!c) - 97 initial_array = listArray (0,26) (repeat 0) :: UArray Word8 Int countchars word = runSTUArray $ countchars' word countchars' word = do arr &lt;- thaw initial_array mapM_ (\ix -&gt; bump arr (letter_ind $ B.index word ix)) [0 .. B.length word - 1] return arr where bump arr ix = readArray arr ix &gt;&gt;= \v -&gt; writeArray arr ix (v+1) compare_lines = comparing B.length `mappend` comparing lowercase sort_lines = sortBy compare_lines zipArrayWith f a b = [f (a!i) (b!i) | i &lt;- indices a] line_matches sieve line = let test = countchars line in and (zipArrayWith (&lt;=) sieve test) main = do (arg:_) &lt;- getArgs let sieve = countchars $ C.pack arg f &lt;- openFile "extended_words" ReadMode text &lt;- B.hGetContents f mapM_ print $ sort_lines $ filter (line_matches sieve) (C.lines text) 
Indeed, but, as that article mentions, the exists syntax currently isn't part of Haskell, requiring you to define an existential datatype, which in my mind is a fairly ugly workaround. I'm still hoping someone will make a GHC extension to allow this, as I would really like to have it.
Use the tuple package. :)
Why? (Serious question; not trying to be a jerk.) 
The romans?
I know I'm never going to work as a financial analyst so if someone explains a complicated financial "product" to me, I'm likely to take their word for it for the most part. (Hence the global financial crisis, I suppose.) If you have a similar approach to Haskell and intend to stop at listening to people talking about it then the same might apply, even though it's not meaningful to compare the two fields of knowledge IMO. There is no substitute for hands-on experience.
Well, for fun, but also with some serious applications in mind. Some algorithms have really been fine tuned to be efficient in an imperative setting. You can program imperatively in Haskell, but it's rather inconvenient. This is an attempt to make it more convenient. 
Happens to me too... a solution: if you advance it just a little past the beginning it then plays fine.
It might also be good for finding performance issues with ghc. Compare a c and haskell/cmonad program written in the same way (which should be very simple), and checking if the ghc performance is near that of the c program. It will never reach 100% of c's performance, but I can't see any fundamental reason why a program written with cmonad can't perform at 90% of the speed of a similar c program.
Much easier to read the later stuff with this version: http://www.youtube.com/watch?v=oujaqo9GAmA&amp;fmt=22 
How come you don't use the quasiquoting extension if you want the syntax of other languages (Basic and C)? Wouldn't it be able to solve the problem with less hackery, better error messages and more precise syntax? I guess it's not as fun; but if one wants to do a "serious" EDSL wouldn't the qq solution be more convenient for the users? Or is there some problem with qq?
I think quasi-quoting is a cop-out, and I don't like it. But that's just my personal opinion. 
syntax highlighting:)
wow, I guess I really asked the right question:) thanks for all the work. but why that weird Ord class? it makes harder to type conditionals in for/while. how about this: liftE2' :: (Monad m) =&gt; (a -&gt; b -&gt; c) -&gt; E m a -&gt; E m b -&gt; E m c liftE2' = liftE2 (&lt;=.) = liftE2' (Prelude.&lt;=) then that infinity example works without explicit type in conditional (only change is &lt;= to &lt;=. , but that could be solved with another import hiding)
great, after half of an hour of having fun with this, the impossible happened. I guess C really is evil, even inside haskell.
Well, I would not have posted the link were it not for Haskell being an extreme case: Ruby's "5.times" might tend to make people curious, while I fear "ap" will make the majority of people despair and shut off their brains. Still, I doubt that the principle is anything less but general: When you're hunting mammoths, it's vitally important for your survival to just stop thinking and do what you're told. The questions that are indeed left are the conditions necessary for someone to be regarded as an "expert", and whether and how people, regarded as experts, can actively prevent people from blanking out.
But I want to use &lt;= for my special booleans, and I also want &lt;= to still work as usual. Unfortunately I've not persuaded the GHC type checker to accept what I want yet. 
If the impossible happens, report a bug!
But surely you could do that without so much hackery. (Which is yet very cool, btw.) Eg, the subscript operator. From what I can see in that snippet, an array has the type `[Int] -&gt; LValue a` or something like that. But the thing that strikes me is that you're using Haskell's list syntax sugar to emulate C's syntax, but a list has no business being there. C's semantics are a great model of low-level computing, but why keep the anachronistic syntax? You can't copy it completely, anyway. Throwing lists at the compiler is just making its job harder. What if the subscript is `[]` or `[1,2,3]`? Please correct me if I'm wrong, and those are not in fact lists. Nonetheless, this is rad, and I do hope the final version has both the 'fun' C-style syntax as well as a 'serious' side, with a more sensible embedding of C's semantics into Haskell (eg, a proper subscript operator.)
This indexing syntax is just a fun hack, still I like the C indexing syntax, but don't take the Haskell version of it too seriously.
BTW, most of the hackery is to get variables that can be used both as l-values and r-values, but having expressions that can only be used as r-values. 
it turned out to be smth related to ghci using mixed compiled and interpreted modules, and when one of them changed it failed badly. I can't reproduce it though:-(
This isn't subtyping! Subtyping allows you to send an instance of your subtype to somebody else's function that expects the supertype. The key here is that it is _somebody else's_ function. With this approach, you can only send your "subtype" to somebody else's function if that somebody else was forward-looking enough to make it typeclass polymorphic in just the right ways. Moreover, this specific example can (should) be done with much less boilerplate -- and no type classes! Simply represent an _n_-tuple (a1, a2, a3, ..., an) as (a1, (a2, (a3, ...(an, ())))). Then you can write first = fst second = fst . snd third = fst . snd . snd fourth = fst . snd . snd . snd Then the term `distance p = sqrt ((first p)**2 + (second p)**2)` can be specialized to `(Float, (Float, ()))` and `(Float, (Float, (Color, ())))`, respectively, giving exactly the same power as in the article. But even better is just to have a Distance type-class and use real types (rather than this anonymous product honkey), since that's the thing you're actually being polymorphic about. ;-)
I do this sometimes, but there is a downside. For me, the downside typically takes the form of wtf = do xs &lt;- "a list" ys &lt;- "another list" res &lt;- lookup 'a' [('b',1),('c',2)] return $ "hello" ++ (show res) which returns just "" which to me feels like probably incorrect behavior. The thing is, you probably wanted to catch the fact that there was no lookup match and return an error message or something, but because fail in the list monad is just the empty list you get this for me unintuitive behavior. If you're dealing with a situation where monads are layered in transformers and maybe it's hard to keep track of what monad you're in, this can lead to frustration when you get the empty string and don't know why, forgetting that this could be fail from the list monad. what it amounts to is that arguably, not all monads should be allowed to fail. In an ideal world, I think the list monad should not have fail in this way. Monad should just implement &gt;&gt;= and return, and that's it.
&gt; The thing is, you probably wanted to catch the fact that there was no lookup match and return an error message or something, but because fail in the list monad is just the empty list you get this for me unintuitive behavior Only because you're running it in the list monad. And you may think it's unintuitive, but it makes perfect sense if you think about the list monad in a different way (unfortunately, being monads, it's pretty hard to actually explain). In any case, the empty list stops evaluation so it does what it's supposed to. If you want to actually detect and handle the error, then evaluate it inside the Maybe or the Either String monad.
If there is only one pattern you want to match against, you can also do it like this: f x = do (Foo bar) &lt;- return x return $ blah bar
I think the idea of returning data types like Maybe or List is that they're universal. If you want to turn a Maybe into something else, with F instead of Just and G instead of Nothing, then you just apply (fromMaybe G) . (fmap F) Or if you want to use some generic CONS instead of (:), then you just apply foldr CONS I don't really want to have to type ugly things like if (lookup k m)::(Maybe String) == (lookup k' m) then ...
Bad idea.
Any reasoning to add to what's already been said here?
The name of the list monad is a bit misleading, because it's really for modeling things like non-determinism. In that context, an empty list *is* failure.
Wait, Jim Cramer uses Haskell?
My brain shuts down before I am given expert advice. Thus maximizing non learning.
Nope. It uses fail, with shouldn't be in Monad. And Maybe is in some sense canonical and easily converted to anything you like. 
So, why shouldn't `fail` be in Monad?
If you want this functionality, wouldn't it be better to use MonadPlus? Eg: lookup _ [] = mzero lookup k ((k',v):xs) | k == k' = return v | otherwise = lookup k xs ? That would cover the list/maybe stuff, since Maybe and List are MonadPlus-es. Am I missing something here?
Check out the definition of what a monad is. There's no fail in there. The fail in Haskell's monad is just an ugly hack. It used to be done right in Haskell, but we ruined it (I didn't protest enough). 
Functorial personality disorder: the tendency to upvote any upcoming articles that mention Haskell. They should add that to the DSM-V axis II.
You do realize this was posted to the *Haskell* subreddit, right?
Haskloff's Syndrome: results in lack of insight into why one is subjected to so many Haskell articles while subscribed to the Haskell subreddit.
archive.org??
[Just Maybe](http://thread.gmane.org/gmane.comp.lang.haskell.libraries/9082/focus=9610) won.
You only had to look at the title bar to discern that this is the *Haskell* subreddit..
I think using quasiquoting means that you're no longer really an "Embedded" DSL.
It depends what you mean by "doomed to fail". If you measure success as becoming a mainstream language which steals the lunch of Java and C++, then you're probably right. It's none of my business but I'm quite content with the idea that the number of programmers that see the benefits is growing but has a hard limit. "Haskell for Dummies" might see the light of day at some point given current trends, but I don't see it selling well. A lot of HOFs take some thinking about the first few times you see them, but you will know some Haskell by that point and have a framework for reasoning about what functions do based on their type. Have an A-ha moment and move on.
One does have to wonder if some of these contortions needed to maintain purity end up making programs harder to reason about rather than easier. (Obviously they're needed in Haskell due to laziness.) Does anyone know of a serious treatment of this topic?
I don't view them as contortions at all. The complications introduced by mutable state (and the external World is a huge example of mutable state) can be quite serious.
If they're so awkward that people prefer to use unsafePerformIO in certain situations, they clearly became contortions at some point. That's not really open to debate. The question is if they can become so awkward that dropping them and using unrestricted IO can actually make reasoning easier. Keep in mind that an effect system could still track the effects in question even if they were unrestricted.
I think the reason people use unsafePerformIO is they have yet to learn the techniques to make not using unsafePerformIO feasible. I found that when I started haskell, I used unsafePerformIO a lot, but now in only rare occations (such as in testing, or throwaway code). The program with unsafePerformIO is you can no longer trust any function that uses it (or calls a function that uses it) to give the same output when given the same input every time you call it. That property is incredibly nice when looking for bugs.
Why does haskell hate (P)RNG?
&gt;Does anyone know of a serious treatment of this topic? As a general concept, probably not. It's a pretty subjective matter, at least at the moment. But there is a lot of evidence that it makes at least some hard problems easier. STM is a good example of this.
awesome page, especially the IO (String -&gt; String), just so elegant and neat, MAN I LOVE HASKELL
It probably makes reasoning in the small easier. For example, it might make a few lines of code be more readable, but in the large arbitrary state changes usually make it harder to reason about you application. This is especially true when you look at concurrency. You also have to keep in mind that the type system is there to help you reason about your code. 
I agree that `fail` could be a little nicer, but what would pattern-matching look like in do blocks if it wasn't there at all?
Pattern matching would be handled like in Haskell 1.3: if there is a refutable pattern in a do block it will have to be of type MonadZero (or maybe MonadFail) instead. That way the fail method can be put in its own class where it belongs. 
I see OpenGL support, but no GTK support. Is there a widget toolkit that has no dependencies outside these packages?
I don't like solutions that have potential pattern match errors. I flinch every time I see head or tail. I use Safe.
This *is* safe. A pattern match failure in the code above causes fail to be called (which equates to Nothing if you're in the Maybe monad) - it doesn't (directly) call error.
We need more stuff like that and less space suits, nuclear waste processing plants and burritos.
Yes, both the GTK+ and Wx bindings depend only on platform packages.
What about GLUT? The trac page makes it look like its not going in. What good is OpenGL without any toolkit to host it?
Does it? It ships with several RNG functions in the base package (import System.Random), and I count several modules on hackage for even fancier random stuff, such as monte carlo monads, the mersenne twister, and a random.org interface.
Spam. Original is at http://cdsmith.wordpress.com/2008/06/06/ray-tracing-in-haskell/
Thanks, didn't spot it.
Ah I see what you mean. Sorry that is a bit confusing. Each package listed links to a wiki page for any details about that package. The ones marked with "?" just means the corresponding wiki page hasn't been created yet. I've added a comment to the page to make that a bit clearer. To be specific, GLUT is listed as going in. On the other hand ALUT is out because it doesn't build "out of the box" on OSX (because OSX lacks the C lib).
One of the examples isn't working for me on ghci 6.8.2: &gt; fmap (+1) (1,2) &lt;interactive&gt;:1:0: No instance for (Functor ((,) t)) arising from a use of `fmap' at &lt;interactive&gt;:1:0-14 Possible fix: add an instance declaration for (Functor ((,) t)) In the expression: fmap ((+ 1)) (1, 2) In the definition of `it': it = fmap ((+ 1)) (1, 2) 
It works if you import Control.Applicative
What about [burrito tunnels?](http://www.idlewords.com/2007/04/the_alameda-weehawken_burrito_tunnel.htm)
My blog. Just liked this algorithm and wanted to see if it could be simplified further, or if there are other approaches. Also any comments on the blog itself, readability issues, etc. would be appreciated.
 &gt; :m +Control.Applicative
Reads like it was translated with Babelfish :(
Thanks, I've fixed that in the article to show the extra import needed.
It is striking to me that all these functional approaches to interaction start with GUIs and then promise to do something about files, sockets, &amp;c. Seems ass-backwards to me.
basically why at the first part of my post, I say that I had a problem to solve. I have files and webservices i want to deal with on the same framework as the GUI.
Sounds great but when are they going to put together some convenient packaged builds (especially for the mac)? IDEs are supposed to make it easier to program, having to build from source isn't really in keeping with that idea.
Keep your feet on the ground. Part of what turns me off about some of these grand-scope functional libraries is that they refine their abstractions so much, in order to accommodate so many possible uses, that they end up with a vocabulary that is impenetrable to the uninitiated. What you have now seems very pragmatic and rooted in everyday metaphors, I encourage you to go with that. This pragmatic/keep-it-simple view has gotten some push-back from Haskellers lately, who see it as whining from day-job programmers who can't be bothered to google a few basic category theory terms. This is probably true, but there's a difference between appropriating abstractions from an established field of mathematics, and making shit up out of thin air. A lot of FRP seems a little bit like the latter to me. If it works, great, but it's hard to play around with until you learn all those metaphors and basically get inside the library author's head. What you have here seems much more solidly grounded in established computer metaphors (+1 to `Bus`) which is no more a waste of Haskell's capabilities. As such I feel like I could casually experiment with this more easily. Good luck, and again I urge you to keep it simple (ie, the minimal amount of abstraction needed to solve your problem in an elegant way.)
I was halfway through doing this when I saw that someone had beat me to it on the mailing list. I guess it was just an obvious idea.
So when does it go on Hackage? :)
 import Graphics.Rendering.OpenGL trackball (x,y) (x',y') = let normalize (x,y,z) = (x/n,y/n,z/n) where n=sqrt(x*x+y*y+z*z) cross (a0,a1,a2) (b0,b1,b2) = (a1*b2-a2*b1,a2*b0-a0*b2,a0*b1-a1*b0) dot (a0,a1,a2) (b0,b1,b2) = a0*b0+a1*b1+a2*b2 getZ x y = let d = 1 - (x*x + y*y) in if d &gt; 0 then sqrt d else 0 z = getZ x y z' = getZ x' y' v = normalize (x ,y ,z ) v' = normalize (x',y',z') (rx,ry,rz) = v `cross` v' angle = acos . max (-1) . min 1 $ v `dot` v' in rotate (angle*180/pi) (Vector3 rx ry rz) 
Great! but : &gt; &lt;flynux:~ $&gt; cabal upgrade leksah &gt; Resolving dependencies... &gt; cabal: dependencies conflict: ghc-6.10.1 requires process ==1.0.1.1 however process-1.0.1.1 was excluded because ghc-6.10.1 requires process ==1.0.1.0 (Leksah 4.3 is installed without problem)
Both the blog and the algorithm look beautiful to me. =)
Thanks! :)
Hm. The changelog mentions that "Setting stdin to NoBuffering now works on Windows", but the bug hasn't been closed in the [bug tracker](http://hackage.haskell.org/trac/ghc/ticket/2189) yet and my test program doesn't work correctly yet. Since the bug was re-opened I'm guessing someone forgot to take it off the changelog.
&gt; This pragmatic/keep-it-simple view has gotten some push-back from Haskellers lately, who see it as whining from day-job programmers who can't be bothered to google a few basic category theory terms. I think that lazy folks who don't want to learn terms fundamental to the language will always get push back from the community (just as I suppose people who didn't want to learn HTTP or OO well would get push back in the Rails community). That is natural and healthy; it is also pragmatic: if you don't know what a `Functor` is you're going to have a real hard time in a language where containers are explicitly modelled as functors. In addition, what you learn about functors is transferable knowledge, like knowledge of HTTP. Theory "embiggens the smallest man". However, there are those of us who are perfectly willing to read our category theory but remain off-put by FRP. As you say: &gt; ...there's a difference between appropriating abstractions from an established field of mathematics, and making shit up out of thin air. A lot of FRP seems a little bit like the latter to me. I fear it is becoming Haskell's Beans/IoC/Materialization (all Java magic-talk). There is a fair amount of research and thought that's bundled up in FRP; but to appreciate the work requires extensive knowledge of Haskell (specifically lazy evaluation), GUI libs (like most web developers, I do not write much GUI beyond JavaScript) and other work in FRP. Were FRP simply a GUI technique, I would not have made my earlier comment; however, most any FRP lib is accompanied by an unfulfilled promise to provide an insightful approach to files and network services.
Mac is one of the best supported and documented platforms to install on now (I use a Mac). For details RTFM. Leksah is unfortunately quite fussy about which versions of GHC (6.10.1) and Gtk2Hs (0.10.0) you use and most of the problems stem from getting those installed correctly.
http://haskell.org/pipermail/haskell-cafe/2009-January/054523.html
Yay! We can finally upgrade to 6.10 at work.
I'm jealous. 
And that's really why I went about writing something new. I start with GUI mainly because that's where everyone else starts and because I'm a visualization researcher and we need such things, but i wanted something that would let me use the same abstraction with the things that supply the GUI with the data it needs to exist, and I wanted something that would also support the AVL system backend that I'm in charge of. I needed something general, so this was as general as I could imagine getting while still having a nice abstraction to work with. It's a bit like COM, a bit like FRP.
Interesting, most of our projects are on 6.10.1. Some will move to 6.10.2 pretty quickly.
Me too. The compilers I have to use at my work are Visual Studio 2005 and gcc 3.x. Blah.
There is talk on the mailing list that the Time library is missing. Does anyone know if this is true?
Mr. President, we cannot allow, a MINE SHAFT GAP!! Plan R. R for "Robert" 
hmm... looks like you're right: $ cabal list --installed | grep time * old-time $ cabal install time [...] $ cabal list --installed | grep time * old-time * time Synopsis: A time library 
When do you plan to upgrade the arch package ? 
ghc 6.10.1 could not generate Windows DLLs, so it was impossible for us to use.
Yeah, dons, when do you? :)
http://www.haskell.org/pipermail/glasgow-haskell-users/2009-April/017010.html being the talk
At least you *get* a compiler. I had to write my own in a Forth I wrote myself in machine language using Notepad and Windows' Alt-Numeric Key Pad input system. Maybe I'll eventually be able to compile gcc with it so I can end the nightmare. Nothing like counting out the offsets in a PE header...
http://www.haskell.org/pipermail/glasgow-haskell-users/2009-April/017011.html being the answer. In the mean time you can just: $ cabal install time
&gt; Mac is one of the best supported and documented platforms to install on now (I use a Mac) Right, but compare the complexity of this installation to, for example, installing TextMate or even Carbon Emacs. Is there some fundamental reason why you can't create a DMG file that can be dragged into the Applications folder?
No fundamental reason. MacPorts and Cabal are just (IMHO) a better way to install this stuff. I never install anything using the DMG if it is on MacPorts. Remember most of the install instructions involve setting up Gtk2Hs, GHC and Cabal (and leaving the source in place). Would we include those in our DMG? What about GTK? Quartz, X11 or both variants? If you don't care about using lots of disk space and you want the X11 version. You can install the lot with &gt; sudo port -k install ghc gtk2hs hs-cabal gtk-chtheme gtk2-clearlooks &gt; cabal install leksah The slightly more complicated instructions are just to avoid using -k on packages you do not want to keep source for. If you want you could try out this... http://porticus.alittledrop.com/ I have not used it myself
We have had some confusion over something that is not made clear enough in the current version of the documentation. If you are installing the Quartz variant of GTK (by adding to the variants.conf file as per the instructions in the manual). Then you should leave gtkglext out of the list of packages to install. Making it... &gt; sudo port install gtk2 cairo librsvg libglade2 gtksourceview2 gtk-chtheme gtk2-clearlooks &gt; sudo port -k install ghc gtk2hs hs-cabal &gt; cabal install leksah 
am busily working on a new version. feedback on the current system is very much appreciated.
windows needs cygwin/mingw to install time this way, of course.
&gt; Numbers were down a bit this month, probably because we only had one speaker. should post a reminder about fp-syd on cafe about these :)
Bah, you had a keyboard. When I was a lad we had to enter the code with the switches on the front panel (I'm actually not kidding). 
why link to an https page with an invalid certificate when the normal http page works just as good ?
hmm, I thought those were the easy parts.
Nothing sweeter than `newtype`.
Is consultant_barbie subscribed to the Haskell subreddit?
Sorry, I didn't realize it was https. I found it via planet.haskell.org, which had the https link. And I never got a certificate error on it, which is itself worrisome...
I often wish for newtype in C++.
yes, but s/he doesn't say anything unless asked to
 learning_a_new_language :: Curiosity -&gt; Excitement -&gt; Reality Sets In -&gt; Frustration -&gt; Rage
Prelude&gt; :l confusing.hs [1 of 1] Compiling Main ( confusing.hs, interpreted ) confusing.hs:30:0: The type signature for `learning_a_new_language' lacks an accompanying binding confusing.hs:30:27: Not in scope: type constructor or class `Curiosity' confusing.hs:30:40: Not in scope: type constructor or class `Excitement' confusing.hs:30:54: Not in scope: type constructor or class `Reality' confusing.hs:30:62: Not in scope: type constructor or class `Sets' confusing.hs:30:67: Not in scope: type constructor or class `In' confusing.hs:30:73: Not in scope: type constructor or class `Frustration' confusing.hs:30:88: Not in scope: type constructor or class `Rage' Failed, modules loaded: none. Prelude&gt;
import SevenStagesOfMan 
you'd think a mormon would like the strong constraints of a type system.
I actually don't really get why newtype is useful. I can do monads/applicative functors/arrows all day long, but newtype is still mysterious to me.
Think of it as a hiding mechanism. * data = create a type * type = make a synonym of a type (same as typedef in C) * newtype = hide the underlying type 
They are useful for keeping your `Int`s separate. The sanest way to do mutable cyclic data structures in Haskell is using arrays, which, when given the integer id of some thing, yield the integer id of the referenced thing. In, say, C++, these things would be objects and they would have pointers to other objects and the type system provides (a modicum of) safety when using those pointers. With plain ints, you're back to no safety. You might accidentally access the array of `Foo`s using the integer id of a `Bar`. To get back the safety, just make `BarId` and `FooId` `newtypes` of `Int`, deriving `Ix`,`Enum`,`Num`,etc.. Note this is wholly different from using `data` to do the same thing because `newtype` lets you derive any instance automatically. Of course, all of the cool new array libraries (vector, uvector, the DPH stuff) use monomorphic `Int` for for indexing, rather than `Enum i =&gt; i`, and don't give you a way to tie the index type to the array anyway, so you either have to write your own safe wrapper or you're back H98 arrays, which have their drawbacks. In general, `newtype` lets you use the type checker to do stuff you might otherwise do with naming conventions like Hungarian notation. You've got two things which are of the same physical type so you want to re-use code for both of them, but they are of separate logical types with respect to the application and so you want to keep the separate.
Lazy...
Programming the type system.
`s/Man/Madness/`
He's also into scouting, so I'm slightly surprised he favours Ruby over, say, Ada. Scouts was all about B&amp;D in my day.
Somebody REALLY needs to change the syntax words "data", "type" and "newtype". How about "data", "synonym" and "wrapper"? Edit: while we're renaming, change "class" into ["trait"](http://www.iam.unibe.ch/~scg/Research/Traits/).
I wish GTK2HS was the other way around. Rather than having the *more* general system being exposed using an unsafe interface, the *less* general one should be. I.e. the default should be that initGUI should be the threaded one, and every GTK action should use postGUISync (so that you can never forget to post it to the right thread). This would be entirely safe. If you want the extra performance for single-threaded apps (or if you want to call postGUIAsync for something) you could import the unsafe versions of the methods and then you have to guarantee that you don't compile with -threaded (and that returning immediately won't cause an error for posting a GUI action asynchronously). Seems backwards that the default is the one that's likely to break in obscure ways for non-obvious reasons. The only rationalization seems to be performance-based, which seems antithetical to the spirit of Haskell to me. By all means offer an unsafe but fast version, but don't make it the default.
4 paragraphs! 3 of which failed to actually mention the contents of the book.
My pants are a little warmer now.
Nicely done. :-)
"milestone changed from 6.10 branch to `_|_`."
&gt; dons posted a good rebuttal to the original version of Harrop's argument on haskell-cafe. If his rebuttal was good, why did he and Simon Marlow censor my response? 
Well, newtype is basically just a data declaration, though newtype tends to be more efficient, sometimes drastically so. For most intents and purposes, they are interchangeable as long as they both apply: every newtype can be a data, but not vice-versa. For example, defining Bool as data Bool = True | False cannot be a newtype, as it contains more than one alternative The type contains three different possible "values": âŠ¥, True, False âŠ¥, aslo known as "undefined" or "bottom" can be thought of in a few different ways, depending on which is useful to a given context: it can represent either a completely undefined value, such as an infinite nonproductive loop or an error "message", or you can view it as a thunk that might possibly get evaluated and filled in with a concrete value when it gets pattern matched against. Bool is an example of a "flat type", as every value is either fully formed or completely undefined. Lists, for example, are not flat, because there are values that are neither fully formed nor completely missing. If you define a linked-list representation of the natural numbers (or "Peano representation"), data Nat = Zero | Succ Nat then the possible values are: âŠ¥, Zero, Succ âŠ¥, Succ Zero, Succ (Succ âŠ¥), Succ (Succ Zero), ... let x = Succ x in x The last one is basically infinity, as Haskell types are coinductively defined. You could remove "Zero" as a base case, and the set of possible values (CPO) would look like this: âŠ¥, Succ âŠ¥, Succ (Succ âŠ¥), ... let x = Succ x in x This modified Succ cannot be a newtype either. Oversimplifying things a bit, it's because it's recursive. (Although recursive newtypes are allowed on function types, e.g.) newtype Nat = Succ (() -&gt; Nat) is allowed. In high-brow terms, these sets are known as complete partial orders, and every type defines a CPO. None of these examples can be newtypes, they must all be datatypes. The key semantic difference lies with regard to partial values, e.g. the CPO for data Foo = Foo Bool has four possible distinct "values", namely âŠ¥, Foo âŠ¥, Foo True, Foo False Data introduces a new, distinct, âŠ¥ value that's below the CPO of Bool. However, if you change it to a newtype, newtype Bar = Bar Bool Then there are only three values in it's CPO: Bar âŠ¥, Bar True, Bar False. Pattern matching on Bar alone cannot fail, because it's just a type coercion, and Bar âŠ¥ is the same as âŠ¥, so from the point of view of newtype, two entries would be redundant. Concisely summarized, data is lifted, while newtype is unlifted. One key difference between Miranda and Haskell is that pairs are unlifted in Miranda but not in Haskell. In Miranda, (âŠ¥,âŠ¥) is the same as âŠ¥.
Why did you censor my comments on your blog a few months ago?
Bot failure. /r/science.
Technically, newtype Succ = Succ Succ is a valid type. It has exactly one element, which is `âŠ¥`, of course, but you can also look at it as `Succ âŠ¥`, or even `let inf = Succ inf in inf`. From the typical Haskell code perspective, it looks like the one element is the last of those, because you can always match on Succ and have it succeed. So all values look like 'infinity'. However, if you use the evil `seq`, it will tell you that all values are undefined. This is also a way of defining the 'uninhabited' type (which actually is inhabited in Haskell) in Haskell98, I think. The report disallows: data Void because you're not allowed to have 0 constructors (you need the EmptyDataDecls extension to make GHC accept this). However: data Void = Void Void is isomorphic to the above type, and should be valid H98. Addendum: I should also note that the following type crops up when you're studying (co)algebraic semantics of datatypes: newtype Mu f = In (f (Mu f)) which is another case where you have a recursive newtype that doesn't (necessarily) involve functions. In general, whenever you have an equirecursive type that isn't allowed by Haskell's type system, you can use a recursive newtype wrapper to turn it into an isorecursive type that is allowed, and has the same representation as the equirecursive type would presumably have.
cool, but not Haskell.
Very cool, but very not Haskell. And dons is the one complaining about links with no code... :) 
If you can think of other high-priority things, throw them into the mix here.
interest +1 
&gt; ...I'm sure it'll only be of interest to me. No, I think many others would be interested.
http://www.reddit.com/r/science/comments/8a1k4/how_to_outrun_a_photon/
Anything else you have to say about the Unruh effect interests me. It's one of those bizarre things in physics that "worry" about now and then. 
The comments here seem more intelligent than the comments in the science sub-reddit. 
&gt; I'm sure it'll only be of interest to me. Oh, no - it won't be.
Yeah, the thread is packed with retardation there.
The hash table? :) Or, more somberly, card-marking for mutable boxed arrays. That one is definitely a frowny :(
You're more likely to find out which questions are easier. I'm sure some questions are influenced by language, but I suspect that easy questions will skew this a lot, lot more.
very neat stuff, and timely ! I might need this soon.
no worries :)
If any of you are working on Project Euler problems in Haskell, which Hackage libraries (if any) do you find useful?
I tend to desire mutation because of constant-space concerns, not because of constant-time concerns. This article doesn't address that concern at all.
Depending on exactly what you mean by constant-space, it seems either impossible whitout mutation (perhaps hidden behind linear typing) or not a problem at all. As far as I can see the zippers have constant amount of none garbage memory.
I am not entirely sure, but I think if you add strictness annotations to your functions then in most cases they should perform in constant space. Or I could be attributing magical powers of optimization to GHC. I've been guilty of that before.
Ok, here's an example of an algorithm I came up with recently that solves a problem in constant space in C but (I believe) not in Haskell. The problem is as follows: You need to write a single function that takes as input an array of integers. As output, you produce another array of integers, equal in size to the input. Each number output_n should be the product of all numbers input_i where i != n. In other words, each number in the output is the product of all inputs except for the one corresponding to the same location in the input array. For example, if my input is [a,b,c], the output is [b*c,a*c,a*b]. The solution I came up with runs in constant space (after accounting for the size of the output array, which is dependent on the length of the input) by re-using the output array as scratch space. In simple pseudocode: IntArray foo(IntArray input) { int n = input.length; IntArray output = new IntArray[n]; // first pass for (int i = 0, int acc = 1; i &lt; n; i++) { output[i] = acc; acc *= input[i]; } // second pass for (int i = n-1, int acc = 1; i &gt;= 0; i--) { output[i] *= acc; acc *= input[i]; } return output; } I also came up with a simple Haskell function to do the same thing: foo xs = snd $ mapAccumR (\acc (lprod, x) -&gt; (acc*x, acc*lprod)) 1 lProds where lProds = snd $ mapAccumL (\acc x -&gt; (acc*x, (acc, x))) 1 xs Now, I may be wrong and the GC may in fact be more magical than I thought, but I do not believe this runs in constant space.
&gt; Ok, here's an example of an algorithm I came up with recently that solves a problem in constant space in C but (I believe) not in Haskell. I believe you mean "not with Haskell lists," because we do have some mutable arrays that would be able to solve this the same way as with C arrays, with in-place update and everything. I think that array fusion can even allow you to use functional combinators to describe the algorithm while actually reusing existing arrays for intermediate values in the compiled version. Edit: Here is a relevant paper. I'm not sure if any existing libraries use these ideas yet, but for some reason I'm thinking there is one that does. http://www.cse.unsw.edu.au/~rl/publications/recycling.html
Yes, I'm using lists, but I expect the same problem with non-mutable arrays. I realize that Haskell has mutable arrays, but I'm specifically talking about implementing this without mutability. &gt; I think that array fusion can even allow you to use functional combinators to describe the algorithm while actually reusing existing arrays for intermediate values in the compiled version. I don't know anything about array fusion. Is there somewhere I should go to read more? I just read the paper on stream fusion a couple days ago. I should caveat this with the fact that I am a Haskell neophyte, and am really only playing around with the language in my spare time. Were I to use this algorithm in a real program and were I to use Haskell, I would probably have ended up using a mutable Haskell array to accomplish this task. However, I am very curious if this can be accomplished in constant space without the use of mutability.
&gt; I don't know anything about array fusion. Is there somewhere I should go to read more? See the paper I linked to in the parent comment as an edit.
Also, the problem-list is getting quite long, so just seeing how many haskellers solved the problems isn't that enlightening. OTOH, this comparison against similar lists for other languages would be very interesting. 
What do you mean by 'constant space'? Your C-like thing (what is that anyway? C#?) allocates a new array, which is not constant. Do you mean no additional allocation besides the result? You probably won't be able to do that without mutation. However here's something that allocates only 3 arrays, the left-products, the right-products, and the result (omitted.) import Data.Array prod :: Num a =&gt; Array Int a -&gt; Array Int a prod a = a' where b = bounds a (zero:inds) = range b a' = array b $ [(zero,a!zero)] ++ [ (i, a!i * a'!(i-1)) | i &lt;- inds ] revProd a = a' where b = bounds a n = snd b - fst b + 1 (zero:inds) = range b a' = array (bounds a) $ [(zero,a!(zero+(n-1)))] ++ [ (i, a!(zero+n-i-1) * a'!(i-1)) | i &lt;- inds ] This is using lazy arrays, though, so you also get a thunk for each element, effectively doubling the memory used, assuming the compiler does its job right and gets rid of the list comprehensions. Even so, your mapAccum solution is probably cheaper. Really though I don't see whats wrong with doing this in ST and then freezing the result. von Neumann is always lurking down there somewhere. Best to make friends with him. ------ Edit: ugh there is a bug in this when your array does not start at zero, but you seem like a smart guy so I'll be you don't suffer from that problem.
You pay the price for a zipper simply by moving it around. Seeking it to the n-th element allocates n contexts. You can say "oh the garbage collector will pick those right up" but its still work being done.
&gt; What do you mean by 'constant space'? Your C-like thing (what is that anyway? C#?) allocates a new array, which is not constant. Yes, and I very explicitly pointed out that I'm ignoring the size of the output array when I say "constant space". &gt; after accounting for the size of the output array, which is dependent on the length of the input The output array size is fixed by the problem, so the "constant space" refers to any space the algorithm uses outside of that original output array. If it helps, I could reformulate the algorithm to accept an already-allocated space for the output, which would make it clearer that the C-like implementation does not allocate any new space (however, this would interfere with attempts to make an immutable version). &gt; However here's something that allocates only 3 arrays, the left-products, the right-products, and the result (omitted.) &gt; &gt; [snip] The version I gave that operated on Lists instead of Arrays used only one intermediate List instead of the two that you have. And yes, were I to actually want to use this in practice, I probably would go ahead and do it in ST. My original point was that taking a simple algorithm expressed in C-like pseudocode and mapping it directly to naive Haskell ends up no longer working in constant space.
Obviously "Seeking it to the n-th element" involves some work. Doing that on a mutable linked list would also involve some work. And in both cases the work would be linear vs n. so no diffrence there.
&gt; My original point was that taking a simple algorithm expressed in C-like pseudocode and mapping it directly to naive Haskell ends up no longer working in constant space. There's your problem. :) I can also write a simple algorithm expressed in Haskell-like pseudocode and mapping it directly to naive C ends up using more space (and time). I'm thinking of the time when I was [computing confidence intervals for some distributions](http://r6.ca/blog/20081016T174811Z.html). &gt; What is interesting is that, because of laziness, my naÃ¯ve Haskell implementation can compute the 95% confidence intervals above without completing the computation of the distribution. I have no idea how I would do that in a traditional programming language.
It could have been constant space if you used dequees instead of lists.
An additional advantage to hiding the underlying type is that it allows the compiler to make a bunch of assumptions: namely that you won't be mucking with the internals of the type. What does that mean? {-#LANGUAGE GeneralizedNewtypeDeriving #-} That nifty little compiler flag makes it possible for the compiler to automatically deriving wrapper functions for your underlying type. It's one of Haskell's many ways of doing this so-called "inheritance" thing. You should look into it in the RWH book. I &lt;3 GeneralizedNewtypeDeriving.
We're all different. I spent some time on that chapter actually, but now that I know what it does, I can't live without newtype.
I guess if you used the article's classes: foo :: Num a =&gt; [a] -&gt; [a] foo = map contextProduct . takeUntil eos . iterate forward . open where contextProduct (px, x, sx) = product px * product sx takeUntil f (x:xs) | f x = [x] | otherwise = x : takeUntil f xs takeUntil _ [] = [] and assuming `contextProduct` is determined to be strict, you'd still need O(N) space to build the reverse list (ie, `px`). But that's just a guess. And if nothing else holds a reference to the input list, memory is turned into garbage at exactly the same rate. 
nicely done :-)
Well done Tupil. Well done Mathew Elder and the Happstack team!
congratulations!
sweet!!
Nice, but in the future when you quoute twitter cant you just post the hole thing? It is short enough.
Won't that recompute the entire product for every single term? The entire point of the algorithm I came up with was to perform no unnecessary multiplications while still operating in constant space.
Hm... Yes, you're right. I've seen this before and completely forgot about that aspect.
Lets see if I can reformulate this a little bit more elegantly : foo xs = zipWith (*) (init $ scanl (*) 1 xs) (tail $ scanr (*) 1 xs) On lists that is more or less the best we may do... But on array it is possible to do better, even expressing it pretty functionally : fooArr :: UArray Int Int -&gt; UArray Int Int fooArr a = accumArray (*) 1 bs $ leftProducts ++ rightProducts where bs@(low,high) = bounds a leftProducts = zip (range bs) $ init $ scanl (*) 1 $ elems a rightProducts = zip [high, high - 1.. low] $ init $ scanl (*) 1 $ [ a ! i | i &lt;- [high, high - 1.. low] ] This is "in constant memory" if I'm not wrong. accumArray use mutation under the table of course but the semantics of the function itself are perfectly functional.
Also of course you have a "constant space" solution for lists if you're really using Int : foo xs = zipWith div (repeat prod) xs where prod = product xs And for arrays : fooArr a = listArray (bounds a) . foo . elems $ a 
Real industrialists don't user Twitter! _Sorry, I came over all Harrop there..._
Can emacs' haskell-mode do those things?
Direct links: http://www.youtube.com/watch?v=iG2eYJKxHlw http://www.youtube.com/watch?v=gMeiA_IuSPo http://www.youtube.com/watch?v=znIubQoNwU4
I like that list solution, it is definitely more elegant, though of course still not constant space. And the array one is also pretty nice, though certainly harder to read.
`div` is actually not acceptable here, especially when using a bounded type like Int, as it introduces edge cases. Specifically, if any of the list elements are zero, then the `div` solution causes errors. And even when nothing is zero, if the numeric type is bounded, then you could overflow the type in cases where the non-`div` algorithm works.
is it available somewhere for ArchLinux ?
Long story short: yes. Most of the time, Emacs can even do it everywhere, not only in haskell-mode (I'm thinking about tags, completion, folding or alignment for example). GHCi interactions are of course handled only in haskell-mode, as well as Haskell syntax coloring and special indentation.
It wouldn't be hard to make a PKGBUILD and pop that on the AUR
The things that impressed me the most were automatic type signature insertion, organization of imports, and code completion that shows the types of the completions. I also have a wishlist item that I don't know if either has: When pattern matching on a variant, I'd like the editor to show me the list of constructors I can match against so that I don't have to go and look at the definition of the variant (for the nth time).
`learning_a_new_language :: Curiosity -&gt; Excitement -&gt; Reality Sets In -&gt; Frustration -&gt; Rage -&gt; Either (Acceptance -&gt; Fumbling -&gt; Productivity) (Undying Hatred)`
Vim can also do tags, completion, folding, and alignment everywhere. Things in those videos that had to be explicitly coded: * a mapping from module name to file name, for the `gf` and `^W^F` commands to work on imports * hover-type-signatures * `:info` for current identifier * compiler line for `:make` * information on parsing GHC errors (it's true that emacs has better heuristics for this) * opening haddocks (for the current identifier, for the libs, etc) * import munging (adding imports for the current identifier, making imports explicitly list imported things) * adding qualifications for current identifier * adding compilation flags * language-aware completion (distinct from the file-aware completion that comes built-in, ask more about this if you're confused) These are just from the videos; I'm sure there's a more comprehensive list of features. Anyway, I'd be very surprised if emacs could do the above things without explicit additions, except for perhaps the error-parsing bit.
That's obvious that Haskell-specific things can't be in Emacs' core. They are in haskell-mode, as I said (apart from :make, is it just running make in the current directory with some arguments? If it is, Emacs handles it directly).
Try this http://www.vim.org/scripts/script.php?script_id=2603
I think it's actually calling `ghc --make`. And yes, of course I wouldn't expect language-specific things in the core, sorry.
Thanks, it wouldn't be possible without all the stuff on hackage. Off to the next app! (Note: we were already running a couple of commercial and non-commercial Haskell-apps for our own projects).
I was thinking Hadron Collider. This is nowhere near as cool.
this is the 4th time I have made this mistake on reddit! :-(
&gt; I was thinking Hadron Collider. Check the subreddit yo.
Nice stuff. There seems to be a QuickCheck for loads of languages except the ones that really need it, like C. ;-) It is possible to integrate C and Haskell to do this testing but it's not *quick* to do. I fear I will be unable to convince my colleagues to go down this path without extensive evidence of usefulness, which will require a fair investment of effort. Thoughts and experiences from people who've done C property tests using Haskell?
Why do people keep doing this? I mean why do people keep starting new software projects, companies,... using anything but words that return zero google results for their name?
looks good but I don't know what I am looking at... (note I have no sound at work)
It is a demonstration of a high-polygon (+/-10K) render of a procedurally defined surface. Entirely written using Flux, a simple UV modeling engine and a bunch of abstractions on top of the Haskell OpenGL binding.
Reading comprehension fail. This research is not about people shutting off their brains when presented with a new programming language that they're not familiar with. It's about people shutting off their brains when they're presented with "expert advice".
Is this your desktop in the screenshot? What was that thingy that popped up when switching terminals?
&gt; Thoughts and experiences from people who've done C property tests using Haskell? It's not quick to do, and works best when your C code is sensibly behaved (e.g. purely functional :) With modern binding tools like c2hs, you could imagine automating large parts of this task.
Really neat, but is the choppiness caused by the video recording or by Flux?
It is caused by the video recording tool. The geometry is uploaded entirely to the video card, so it runs very smoothly without using (nearly) any CPU.
Thanks bsdemon. I think this is [what I've been looking for](http://www.reddit.com/r/haskell/comments/7l384/any_good_editor_or_preferably_a_vim_plugin_that/).
Which layer did the rendering? Flux or OpenGL?
&gt;Youâ€™ll also notice how I avoided polymorphism. Since DPH only supports Ints, Doubles and Word8 (unsigned 8-bit int), it isnâ€™t of any use. When you transform your datatypes into nested parallel types, you will loose generality. I have some silly questions about this: Is this just because DPH is still in its early days? Is it planned to make it more flexible in the future or is this some sort of fundamental limitation? Also just wondering - it looks like DPH depends on this separate prelude - so is DPH really a fairly fundamental reworking of haskell from ground up then? I mean, it doesn't sound like you would be able to take old code and easily change it to take advantage of DPH, if you can't use any complicated datatypes or prelude!
Alas, not Cabal, which was my first thought. The second thought ran something along the lines of Charleton Heston's famous line at the end of Planet of the Apes when he finds the head of the Statue of Liberty.
They do it that way to keep out people who are too lazy to include "Haskell" or "compiler" in their search.
I believe it is [Witch](http://www.manytricks.com/witch/).
Integral Calculus in Lambda Calculus (Lisp) http://jng.imagine27.com/articles/2009-04-09-161839_integral_calculus_in_lambda_calculus_lisp.html
It's a reworking (compatible) of the basic types to be parallel-friendly (via vectorization), and a bunch of list-like ops on data parallel arrays. The main thing is that it *does* integrate with all your existing code, and it gives you implicit, high performance, parallelism.
thank you. good work indeed. what's next ? ( Do you have a rss I could follow ? ) 
Thanks, nice trick. Add this to the file to also get the symbol syntax highlighting: &gt; syn match hsVarSym "\(Î»\|â†\|â†’\|â‰²\|â‰³\|â‰¡\|â‰ \)"
People who include that obviously already know what it is...
Excellent, thanks!
I agree, we should use (&gt;&gt;&gt;) for composition of Accessors, as they should be arrows. Also, the Whole-&gt;(Part, Part-&gt;Whole) is nicer than the pair I originally suggested.
You have to add some strictness annotations. http://www.haskell.org/haskellwiki/Performance/Strictness
Now, that was a nice and interesting read, thanks for submitting it; BUT, what I still don't get is, exactly how does this make the IO Monad a hack at all. If anything, it's the `do` notation that *gives* *the* *impression* that something fishy is going on. But if you break the `do` construct down to the monadic `&gt;&gt;=` notation, you'll already notice that the first `getChar` isn't the same as the second (because the first `&gt;&gt;=` depends on the second, which in turn depends on the third. And breaking it down into the bound world pairs makes it perfectly clear what is going on. Haskell is all about hiding complexity in nice, abstract ways, so you can juggle your *algorithms* and *data* *structures* instead of having to care about technical details. The IO Monad does the exactly that. Granted, it hides a shitload of complexity, but would you rather code that yourself? And does it limit the expressive power of the language? I'd say it doesn't.
&gt; ...if you break the do construct down to the monadic &gt;&gt;= notation, you'll already notice that the first getChar isn't the same as the second (because the first &gt;&gt;= depends on the second, which in turn depends on the third. At that level, the `getChar` really do look the same: they are just arguments to `&gt;&gt;=`. You can argue that the `&gt;&gt;=` are both different (hence sequencing) but why evaluate the `getChar` twice? You have to visit the definition of the `IO` monad to see why. &gt; ...exactly how does this make the IO Monad a hack at all. I don't think it does. `IO` comes under criticism from folks on the FRP side, for example, because they posit something better; however, that doesn't make it dirty. If anything, I hoped to make plain with my email that monads allow you to express sequencing in a pure language with no hacks whatsoever.
Also my conclusion. It would be nice with a Char type for convenience :) And I'm sure there's more of these cases. Converting primitive types is ugly. In the long run, I guess that the two alternatives are: 1) Core primitive types in GHC will all be available in the DPH Prelude, or 2) the vectorizor will be made compatible with the rest of GHC and the DPH Prelude will disappear. Anyone who knows about the prospects?
I still think it's a dirty hack. * `forkIO` "duplicates" the World state and then proceeds to pretend as though nothing happened. * There are no guarantees that the World which one action receives as input is even the same World returned by the action before it.
What do you propose? A different abstraction or that we don't try to isolate the "real world"?
No proposal in particular. I'm just pointing out that the IO monad is not really as elegant or referentially transparent as some of its promoters like to claim. At the very least, I think IO shouldn't be explained in terms of RealWorld, due to the inaccuracies I pointed out. There is perhaps a better way to explain its semantics than as a state monad. At the most, some future incarnation of FRP may be most appropriate for IO.
`World` itself is completely fake. After all the typing has been done and data dependencies are established, GHC suddenly realizes that `World` (or `RealWorld`) is actually the same as `()` and can be thrown away entirely before it generates code. The second point you make is really only meaningful when talking about the semantics of the `World` as if IO were the State monad. However, it's not, and that's why I would say is why IO is a hack.
As long as you don't go pretending that `RealWorld` is actually state, then you're OK. If you only use it as in this article, to establish data dependencies and preserve RT, then that's OK because that's exactly what its function is.
What is this World you are talking about? The IO monad is abstract and you don't know what it does on the inside.
GHC does too, via [hs-boot files](http://www.haskell.org/ghc/docs/latest/html/users_guide/separate-compilation.html#mutual-recursion).
True. I think what I'm getting at is exactly that IO has no semantics. Even our best approximation is deeply flawed. Do we really want to claim that a construct with *no* semantics is somehow *not* a hack?
Yes, this is just because DPH is in it's early days. The vectoriser can't handle all the GHC extensions used in the real Prelude yet. 
So I think LHC is doing this now: http://galois.com/~dons/images/lhc.svg
Personally I find the most intuitive way to think about IO is not as threading the world through the computation, but as composing a little imperative program which is then executed by the environment. So when you see a function like `sequence :: Monad m =&gt; [m a] -&gt; m [a]`, don't think of it as taking a list of "IO values" and returning an "IO list of values", but rather taking a list of little imperative programs and returning a new imperative program which produces a list. Of course it's the same in the end, just another perspective.
I was just curious, but is there any way to rewrite &gt;&gt;= in terms of applicative functors?
Well, ((-&gt;) r) is the same as the Reader monad. I can't think of any reason to prefer it over Reader, as it's a bit less clear to the viewer what's happening. Sometimes it's used in golfing a function down to a one-liner.
I haven't seen LLVM mentioned in any of the LHC blog posts yet - well, except for that one a ways back that ways dismissive of the idea. Am I missing a link?
Lemmih has stated in IRC that it's on his todo list, at some point in the future.
no. (but you can write &lt;*&gt; in terms of Monad -- to follow your terminology)
I think you gotta explain this one, dons :) Why is this important?
These ones? instance Functor ((-&gt;) r) where fmap = (.) instance Monad ((-&gt;) r) where return = const f &gt;&gt;= k = \ r -&gt; k (f r) r and: instance Monad [] where m &gt;&gt;= k = foldr ((++) . k) [] m m &gt;&gt; k = foldr ((++) . (\ _ -&gt; k)) [] m return x = [x] 
Personally, I don't consider (liftA2 (+)) for addition of functions to be golfing. To me, the fact that Haskell can express things like this directly is *the* reason to use Haskell.
 g' :: Int -&gt; Int -&gt; Int g' x y | False = z where z = x `div` y g' x y = x With this, `print (g' 4 0)` prints `4`, because defining a name for an expression is (more or less) lazy; you could inline the definition and get the same result, modulo some performance due to sharing. However, the function in the report: g :: Int# -&gt; Int# -&gt; Int# g x y | False = z where z = x `divInt#` y g x y = x results in a divide-by-zero exception, because defining names for (strict) unlifted values using let/where occurs similarly to how things happen in, say, ML, in order (I assume) and before evaluating the resulting expression. This is particularly weird with the `where` in the example, since it scopes outward of even the always-failing guard (although that is not surprising since things defined in a `where` can be used in multiple guards), and occurs syntactically _after_ the code _before_ which it is necessarily executed. However, there is another feature in GHC that can produce this behavior: g'' :: Int -&gt; Int -&gt; Int g'' x y | False = z where !z = x `div` y g'' x y = x with BangPatterns enabled. This will also give a divide-by-zero error when called with `y = 0`, because BangPatterns are crazy like that. So, I believe the proposal is to make it an error to give names to (strict) unlifted values without a similar bang, to call attention to the difference in evaluation order. I don't know if that explains why it's important, but it's what's going on.
There'll be [darcs hackers](http://lists.osuosl.org/pipermail/darcs-users/2009-April/019059.html) there too. See you all there!
The IO semantics that builds a term representation is a correct and exact one from Haskell's point of view, but it tells you nothing about what the IO operations do to the real world. It is unsatisfactory, but somewhat inherent when dealing with a world where things like file operations have no formal semantics. That doesn't mean we should give up, more work is needed for Haskell's IO semantics. When I use IO in my Haskell program's I just treat it like any other imperative language; it's about as well specified.
I recommend reading byorgey's Typeclassopedia [(The Monad.Reader 13)](http://www.haskell.org/sitewiki/images/8/85/TMR-Issue13.pdf), as it explains the relations between type classes and e.g. how Monad is more powerful than Applicative.
The latter is actually the List monad and dainaki asked for the instance for Array [(which is similar)](http://hackage.haskell.org/packages/archive/base/latest/doc/html/src/GHC-PArr.html): instance Monad [::] where m &gt;&gt;= k = foldrP ((+:+) . k ) [::] m m &gt;&gt; k = foldrP ((+:+) . const k) [::] m return x = [:x:] fail _ = [::] @dainaki: If these definitions are too overwhelming, try figuring out the type of `(&gt;&gt;=)` for the specific instances first.
I'd be interested to know where this stands today (the posted article is from 1997). Is it still being used?
JHC and LHC use a typed variant of GRIN, because Boquist's work basically reached the limits of his untyped intermediate language (at least that's what people told me at Chalmers.)
I wish I could be there, but the timing just didn't fit :(
Thanks!
I agree. Its what we have, it's not horrible, and it's practical. I'm just an idealist.
I think it is no less clear than Reader. I use Reader or ReaderT when I want to make a new abstraction, of course, but for one liners it's a bit heavyweight to wrap and unwrap an expression just for documentation that describes something fairly obvious to a somewhat advanced programmer anyway.
A few more translations that are useful, and some improvements on when the source translations get applied: imap &lt;buffer&gt; =&gt; â‡’ imap &lt;buffer&gt; &gt;&gt; Â» imap &lt;buffer&gt; .&lt;space&gt; âˆ™&lt;space&gt; imap &lt;buffer&gt; forall&lt;space&gt; âˆ€ in s:UTF8ToHaskellSrc() silent %s/â‡’/=&gt;/eg silent %s/Â»/&gt;&gt;/eg silent %s/âˆ™ /. /eg silent %s/âˆ€/forall /eg in s:HaskellSrcToUTF8() replace the silent %s's with silent %s/[^Î»â†â†’â‰²â‰³â‰¡â‰ â‡’Â»âˆ™âˆ€\\\-!#$%&amp;*+/&lt;=&gt;?@\^|~.]\@&lt;=\\\([^Î»â†â†’â‰²â‰³â‰¡â‰ â‡’Â»âˆ™âˆ€\\\-!#$%&amp;*+/&lt;=&gt;\?@\^|~.]\)/Î»\1/eg silent %s/[^Î»â†â†’â‰²â‰³â‰¡â‰ â‡’Â»âˆ™âˆ€\\\-!#$%&amp;*+/&lt;=&gt;?@\^|~.]\@&lt;=-&gt;\([^Î»â†â†’â‰²â‰³â‰¡â‰ â‡’Â»âˆ™âˆ€\\\-!#$%&amp;*+/&lt;=&gt;\?@\^|~.]\)/â†’\1/eg silent %s/[^Î»â†â†’â‰²â‰³â‰¡â‰ â‡’Â»âˆ™âˆ€\\\-!#$%&amp;*+/&lt;=&gt;?@\^|~.]\@&lt;=&lt;-\([^Î»â†â†’â‰²â‰³â‰¡â‰ â‡’Â»âˆ™âˆ€\\\-!#$%&amp;*+/&lt;=&gt;\?@\^|~.]\)/â†\1/eg silent %s/[^Î»â†â†’â‰²â‰³â‰¡â‰ â‡’Â»âˆ™âˆ€\\\-!#$%&amp;*+/&lt;=&gt;?@\^|~.]\@&lt;=&lt;=\([^Î»â†â†’â‰²â‰³â‰¡â‰ â‡’Â»âˆ™âˆ€\\\-!#$%&amp;*+/&lt;=&gt;\?@\^|~.]\)/â‰²\1/eg silent %s/[^Î»â†â†’â‰²â‰³â‰¡â‰ â‡’Â»âˆ™âˆ€\\\-!#$%&amp;*+/&lt;=&gt;?@\^|~.]\@&lt;=&gt;=\([^Î»â†â†’â‰²â‰³â‰¡â‰ â‡’Â»âˆ™âˆ€\\\-!#$%&amp;*+/&lt;=&gt;\?@\^|~.]\)/â‰³\1/eg silent %s/[^Î»â†â†’â‰²â‰³â‰¡â‰ â‡’Â»âˆ™âˆ€\\\-!#$%&amp;*+/&lt;=&gt;?@\^|~.]\@&lt;===\([^Î»â†â†’â‰²â‰³â‰¡â‰ â‡’Â»âˆ™âˆ€\\\-!#$%&amp;*+/&lt;=&gt;\?@\^|~.]\)/â‰¡\1/eg silent %s/[^Î»â†â†’â‰²â‰³â‰¡â‰ â‡’Â»âˆ™âˆ€\\\-!#$%&amp;*+/&lt;=&gt;?@\^|~.]\@&lt;=\/=\([^Î»â†â†’â‰²â‰³â‰¡â‰ â‡’Â»âˆ™âˆ€\\\-!#$%&amp;*+/&lt;=&gt;\?@\^|~.]\)/â‰ \1/eg silent %s/[^Î»â†â†’â‰²â‰³â‰¡â‰ â‡’Â»âˆ™âˆ€\\\-!#$%&amp;*+/&lt;=&gt;?@\^|~.]\@&lt;==&gt;\([^Î»â†â†’â‰²â‰³â‰¡â‰ â‡’Â»âˆ™âˆ€\\\-!#$%&amp;*+/&lt;=&gt;\?@\^|~.]\)/â‡’\1/eg silent %s/[^Î»â†â†’â‰²â‰³â‰¡â‰ â‡’Â»âˆ™âˆ€\\\-!#$%&amp;*+/&lt;=&gt;?@\^|~.]\@&lt;=&gt;&gt;\([^Î»â†â†’â‰²â‰³â‰¡â‰ â‡’Â»âˆ™âˆ€\\\-!#$%&amp;*+/&lt;=&gt;\?@\^|~.]\)/Â»\1/eg silent %s/forall /âˆ€/eg silent %s/ \@&lt;=\. /âˆ™ /eg Hrmm. this just grew bigger than I should probably supply as a patch via reddit. ;)
I think you'll need to copy the contents of /usr/share/vim/vim71/syntax/haskell.vim into your local ~/.vim/haskell/syntax/haskell.vim and add the lines there, or they won't take, no?
Damn, every time I think about the [Large Hadron Collider](http://en.wikipedia.org/wiki/Large_Hadron_Collider). Why did they choose the same name? Can someone reply to my question instead of downvoting me? :/
Parallel arrays. Similar, yes.
&gt; Sometimes it's used in golfing a function down to a one-liner. I've never come across this term before, although that might be because I'm new to FP. What does "golfing a function" mean?
[code golf](http://codegolf.com/)
Well, that's not how I would put it. Urban Boquist got some very impressive results, and then got his PhD and left to work in industry. So nobody picked up his worked and packaged it for consumption. He was also using a dying Haskell front end (my second one, hbcc, also used by the pH compiler at MIT). 
I have added this line to script but symbols, which are highlighted, are only â† â†’ â‰² â‰³ â‰¡. So I've tried &gt; syn match hsVarSym "(\|Î»\|â†\|â†’\|â‰²\|â‰³\|â‰¡\|â‰ \| )" and it works well. 
I do not know VIM well and so I have question: why are your translations better?
The more complicated translations avoid the problem where the operator translations get applied in the middle of larger operators. in particular \\\\ from Data.Map showing up as Î»Î», ==&gt; as â‰¡&gt;, etc. so what they do instead is check to make sure that the preceding character isn't an operator character without matching it: [^Î»â†â†’â‰²â‰³â‰¡â‰ â‡’Â»âˆ™âˆ€\\\-!#$%&amp;*+/&lt;=&gt;?@\^|~.]\@&lt;= and that the following character is also not an operator: \([^Î»â†â†’â‰²â‰³â‰¡â‰ â‡’Â»âˆ™âˆ€\\\-!#$%&amp;*+/&lt;=&gt;\?@\^|~.]\) but with matching, so we have to emit it explicit into the replacement. You will still get these transiently during data entry in the input buffer if you don't pause sufficiently long while typing in input mode in the middle of an auto-replaced glyph, but they'll go away when you save.
Thanks, I couldn't figure out how join (*) was the same as (^2), but now it makes sense.
This is cool. We finally got some hard evidence that you don't need to be Oleg, or one of his clones, to play with types.
"playing" starts with undecidable and overlapping instances:) to play with types is easy, you just read all Oleg's work 10-20 times and you should learn a trick or two. but how many people can come up with TypeCast definition on their own?
There's some post analysis of GRIN by John Huges here: http://www.cse.unsw.edu.au/~dons/haskell-1990-2006/msg07195.html and Urban's response: http://www.cse.unsw.edu.au/~dons/haskell-1990-2006/msg07199.html In 2006, Christof Douma worked on extending GRIN to add IO, asynchronous exceptions, and threads, targeting C--. I believe he did a thesis defense (https://mail.cs.uu.nl/pipermail/st-students/2006q2/000327.html), but don't know what transpired. 
Another package with a shallow documentation. Out of 11 functions, 6 functions are without a line of documentation, 5 with a single, short line. No examples, no use cases. 
It has examples: http://hackage.haskell.org/packages/archive/monad-tx/0.0.1/doc/html/Control-Monad-Tx.html#v%3Atest0
Well there's a couple functions named test0 and runtest0, and since there's not a single line explaining what's going on I thought it was some test left behind. So I have to figure out what o, s, e and a are supposed to be in the type Tx, since there's no explanation for it. I "guess" 's' will stand for the type of the state, and 'e' for the type of error. Still puzzled about 'o'. It took me about 5 minutes to (think I ) understand what the test was doing, i.e. show what happens for the 5 ways you can leave the monad. It still doesn't teach me what is it usefull for, doesn't give me a real world, usable example of how to use it.
I 100% agree. It isn't well documented. mmorrow!! Here's how I'm [trying to document packages](http://hackage.haskell.org/cgi-bin/hackage-scripts/package/adaptive-containers-0.3). Any thoughts on how we can raise the expected documentation standard?
The documentation for your package is really nice. It would be cool if haddock could embed the png's you linked in the description. 
A high quality documentation needs to properly describe all parameters of a function or a constructor, give an example, with context, of the functions, or alternatively some lines you could type in an interpreter together with the expected result. A way for users to annotate or comment the documentation is welcome too, for example to give extra info on some behavior, or give more examples. All of this could require lots of text, some diagrams or images, and for me it would be a pain in the ... to have all that inside the source code. So my thought at the moment is the probably inpopular idea that Haddock isn't the right tool for the job. 
Some packages are released with no documentation, some have a books of documentation. There's wide variance. How can we drive up the overall usefulness of hackage documentation? I want to raise the general expected standard. Thoughts? Here are some of mine that I think illustrate about as far as we want to go documentation-wise: * [download-curl](http://hackage.haskell.org/cgi-bin/hackage-scripts/package/download-curl) * [adaptive-containers](http://hackage.haskell.org/cgi-bin/hackage-scripts/package/adaptive-containers) Are there packages whose documentation you think is really outstanding? Maybe we should have a contest to raise the profile/importance of good documentation, to help set the standard? Or produce a tutorial/guideline on documentation that could help serve as a standard reference for what is expected?
The package description itself should provide enough information to let one know what one can use it for, and why. If the package is based on a paper, a link to the paper should not be enough. Each and every constructor or function should have at least : * A few lines explaining its purpose, its relation with other parts of the package. * Each parameter should be detailed, as well as return values and which exceptions might be raised. * If knowledge about another function is assumed, its documentation should be linked * Some examples, if possible a code snipped. For a documentation published on the web, a possibility for users to comment, add examples, etc would be great. The best part of it could be retroactively added to the official documentation. 
By the way you have a typo on download-curl : &gt; Download web content as strict or lazy *bytestringrs*, strings, HTML tags, XML, RSS or Atom feeds or JSON, using the curl network library. edit : nice job on the documentation for download-curl too !
An idea would be to develop system so that the haddock-made documentation on hackage is served as a wiki, and the modifications typed in by users can be approved by moderators and a patch is automatically made and sent to the author. That way the autors wouldn't have all the burden of making a complete documentation, and it would be easy for casual programmers to contribute.
A few ideas -- 1) Some kind of cabal warning that gets generated if there are modules without alot of docs -- so that you would have to manually edit your .cabal file to ignore looking for documentation. 2) Some kind of karmic system. Vote up for good docs, vote down for bad ones. Could be extended to multi-dimensional voting, eg - vote a package up for usefulness/code quality/documentation quality/cool factor, etc. 3) We give Phillipa a Taser and have her train all of us to write better docs. 4) ... 5) Profit? EDIT: Just a note- we probably shouldn't put too much pressure on early-release software, certainly any package in V1.0 (assuming it started at V0.0) ought to have some damn-fine docs, and anyone past that should be even better, but early releases are likely to be in flux so much that extensive docs would be counterproductive, they'd be changing all the time.
I like the taser option.
The biggest things I look for are succinct examples. Being still a neophyte at Haskell, it's still sometimes hard for me to translate just the API docs into working code. This is especially true for something larger like a database library or something similar.
Could we have package uploaders have the option to sign up for a wikification of their docs? We could allow members with a wiki account to modify the documentation to correct errors or add information, and have some prominent community members have admin privileges to lock pages or make final decisions on what does and does not go into the primary documentation. Finally, whatever doesn't make it into the primary documentation could be moved into a separate corresponding 'experimental' page that has documentation in progress or less essential info.
Improve Hackage by: * Allowing author deletion of packages * Hackage ran Quickcheck instances * Hackage generated HPC stats based on QC tests. * Adding dynamic filters to the list of package properties: * Library or executable * build success/failure * haddocks * latest upload date * HPC coverage of hackage-ran quickcheck tests * Dependant packages * Author (positive and negative filtering on name) * Platform
I think even seasoned Haskell programmers run into the same problem fairly often. Haskell libraries are different from libraries in other languages because their primitives are not necessarily structured in noun-verb-adjective order, which is usually intuitive for a lot of people. Instead, our documentation can skip around a lot, introducing some nouns here, some verbs there, not really giving a cohesive picture of how everything is meant to be composed. Examples are the simplest way to resolve this problem, in my opinion. Good documentation structure can also do it, but that is much more difficult for most programmers, who are not well-trained technical writers. Even with good document structure, I think numerous examples is almost a necessity. In summary: **examples examples examples**!
This is an awesome idea. I would *love* to see a project start around this.
make them reflect the level of documentation sun put into the java class library documentation. that is, include a detailed explanation and code examples in the docs
How about documentation rating feature on hackage ? At least it will give some insentive to developers to provide some documentation, just like reddit karma whoring.
Those are all good ideas, but a bit off topic as this thread is about the documentation.
Not to toot my own horn, but I think [emgm](http://hackage.haskell.org/cgi-bin/hackage-scripts/package/emgm) does pretty well on this front.
This is the best thing about the new logo. It's easy to make ASCII art from it, as well.
As an example, here's a real-life experience with a beginner (me) : 5 minutes ago I wanted to try doing something with unboxed arrays. So I went there : http://hackage.haskell.org/packages/archive/array/0.2.0.0/doc/html/Data-Array-ST.html We have the STUArray datatype explained. I don't get what &gt; s: the state variable argument for the ST type means, so I go over to Control.Monad.ST, where I see : &gt; The strict state-transformer monad. A computation of type ST s a transforms an internal state indexed by s, and returns a value of type a. The s parameter is either &gt; &gt; * an uninstantiated type variable (inside invocations of runST), or &gt; * RealWorld (inside invocations of Control.Monad.ST.stToIO). &gt; &gt; It serves to keep the internal states of different invocations of runST separate from each other and from invocations of Control.Monad.ST.stToIO. That doesn't tell much more to me, I'm still puzzled. I decide to drop it for now, but I'm not happy. I take the opportunity to browse quickly the rest of Control.Monad.ST, but I see nothing that'll help me use STUArrays, so I'm back to Data.Array.ST. I don't see any function to make a STUArray. My search takes me to Ghc.Arr ( yepee, there's an array funtion that makes an array, but not a STUArray one, obviously. Still I feel like I'm getting somewhere), then Data.Array.Unboxed ( so short it's totally useless ). I eventually click on the MArray from the instances list and there I get the feeling I'm on to something. After 5 minutes of strugging with newListArray, I give up and try to find a blog post, or a tutorial. Documentation for Arrays : totally unusable for me. What would have I liked ? Just an answer to those simple questions : * How do I declare an array of 10x10 Ints. * How do I set,retrieve or update an element. 
no quotes?
This data Operator a b compose :: Operator a b -&gt; Image a -&gt; Image b looks an awful lot like a `Functor`, for which `Array` already has an instance.
`&gt;\=` maybe? I dunno.
Brent gets it in the neck every time he forgets to include quotes :-)
AND RIGHTLY SO. Seriously, the quotes are often awesome (or used to be, I guess that as the HWN becomes actually weekly there are less quotes to work with)
if `byorgey` can't do it, I can! Aaron_Denney says: "Don't anthropomorphize computers. They hate it when you do that." BMeph says [to psygnisfive] In #haskell, you can't hardly be taken seriously w/o writing a monad tutorial... heatsink says: @pl (\y -&gt; you y off) taruti says: damn GHC. I had a nice example for a pretty but inefficient way to compute things and now the new GHC optimizes it to be fast ._. Japsu says: segfault cat is watching you unsafeCoerce :)
I really liked this piece, but I would find the code easier to follow if the author included some type signatures.
Is there an existing haskellwiki page of collected cuteness like that @pl command? I'm sure there's a lot of other things like that, but I can't seem to specifically recall them right now...
If there isn't, create one! -- unless you don't have an account. In which case, you should email whoever you're supposed to email to get one. :)
This doesn't address the problem with Hackage docs, but it may (hopefully) help your situation: http://book.realworldhaskell.org/read/advanced-library-design-building-a-bloom-filter.html#id680590
Update. The STUArray code from page 586 of real world haskell isn't much *immediately* helpfull, after reading it I tried defining a new Array but was still struggling with an type error. OTOH, http://en.wikibooks.org/wiki/Haskell/Hierarchical_libraries/Arrays was more helpful with the following code snippet : import Control.Monad.ST import Data.Array.ST buildPair = do arr &lt;- newArray (1,10) 37 :: ST s (STArray s Int Int) a &lt;- readArray arr 1 writeArray arr 1 64 b &lt;- readArray arr 1 return (a,b) main = print $ runST buildPair The realisation here comes from the type signature I have to provide when creating the array, with a bit of sense I could have come up with it, but I dumb, so I didn't. Too bad the information is a bit of it here, another bit there.
The link doesn't work for me, but easyVision is probably related: http://covector.blogspot.com/ Also related: a couple years ago I implemented Burns' line detection algorithm as part of [a graphics project](http://www.cs.utexas.edu/~quark/cs384g_p4/writeup.html). The algorithm itself is in C but it has Haskell FFI bindings.
Nice ones, I love it !
`mauke: data What a = No; instance Monad What where { return _ = No; No &gt;&gt;= _ = No }` `mmorrow: a functor is like an analogy between two analogies`
Good idea. Just went and started a skeleton. No doubt many haskellers are more steeped in #haskell lore than I and could fill it up with goodness. http://haskell.org/haskellwiki/Cuteness
Although once I did that I noticed the Quotes entry, which might be a better place to put this stuff. http://www.haskell.org/haskellwiki/Quotes Either way, this one is definitely in need of some love.
Simply put: make it easier to contribute. I'm currently the maintainer of HUnit and I'm sitting on some documentation that I plan to get out soon. My experiences with documentating HUnit were: * Document the library. * Find out how to have the documentation added to the library (maintainer was libraries@haskell.org or somesuch). * Create a code.haskell.org account and upload to there. * Find out that someone documented the library already but it the documentation was rejected because the documentation lacked a tutorial (i.e., it was not complete enough). * Integrated the documentation from steps 1 and 2. * Decided to wire the included unit tests into the Cabal build so &lt;tt&gt;./Setup.hs test&lt;/tt&gt; would call them. * Tried to find out which OSes and compilers it needed to work with. Was told that the current version of GHC, previous version of GHC, current version of Hugs, and current version of NHC(?) needed to be supported. * Fought with getting the library to work with Hugs. Ended up coming up with a hackish solution where the user has to manually rename files to get it to work with Hugs. * Tried to find NHC(?) for all platforms. I couldn't find a version for one of Mac OS X or Linux (I can't remember which). * Find out how to upload the documentation to Hackage. * Create a Hackage account. I'm trying to find some time to fix one remaining bug and test before I upload to Hackage. I realize that a lot of the problems that I faced are due to integrating tests into Cabal. However, there are some general problems I ran into: * A lack of information on how to do multi-platform testing. How do I set up the major systems to allow for multiple versions of multiple compilers? (I'm looking into this one as time allows.) * No simple way to test and report across multiple environments. I need to test 3+ compilers on each of 4 OSes (5 soon) and I don't want to have to do it manually. (I'm looking into this one as time allows.) * Documentation rejected for not being "all that and a bag of chips". If it's a significant improvement over past documentation, it should be included, even if it's not perfect. 95% is better than 0%. Had the original documentation been accepted, I could have worked on TH documentation, instead. * An agreed upon standard for support. There are 9 or more compilers listed on the [implementations](http://www.haskell.org/haskellwiki/Implementations) page. Some of these are incomplete and some are out of date. * Hugs. It's too popular to discard but not popular enough to support. Either get it up to date or put it out of its misery. I hold high hopes for the Haskell Platform project, as I think it will solve a lot of the bigger questions, such as target platforms. The rest will require some more contributions from community members (e.g., tutorials). A step-by-step manual for contributors would be very helpful.
From what I've seen, people that write libraries rarely document them. It's those that "come after" who document them. In many cases, this is a good thing; it is more valuable to have major contributors make more contributions. The people that use the library may document it better because they approach it from a non-expert perspective. Some ideas: * Encourage package creators to list references (e.g., if someone creates a MIDI library, include references to source materials in the documentation or comments) so that others can * The Hackage uploader states the status of the documentation (e.g., None, Minimal, Some, Much, Almost Complete, Complete). * If the documentation is incomplete, put a message on the download page asking people to contribute. * Have a standard file (e.g., TODO.documentation) stating what the author wants to see improved. (This could also be useful for other parts of the package, such as TODO.features, TODO.bugs, TODO.tests, etc.). * Allow users to vote on which libraries to improve the documention of. * Allow people to register to work on library documentation to avoid duplication of effort. * Add a karma system to encourage people to contribute. * Make it easy for users to submit comments and for maintainers to integrate the comments into the documentation.
I often write some example code for my packages. It would be nice if cabal installed that somewhere, and maybe if one could make a link to it from hackage.
Safari warns me that visiting this site may harm my computer, with a link to a [Google Safe Browsing](http://google.com/safebrowsing/diagnostic?tpl=safari&amp;site=divinets.cn&amp;hl=en-us) page on divinets.cn. Is this a redirect or something?
 &gt;Î»=
Well, but if you read the code, the operators seem to rely on context and not just the point itself, so that's not a functor. It is, however, an arrow, I think. And also can be represented by a comonad and cobind, fwiw.
typecast is a damn dirty trick.
Well, all the HWN quotes (and many besides) are stored in Lambdabot. Specifically, you can surf to the darcs repo, look through state/ and gunzip the quotes file and you'll have literally hours of reading and lulz.
Wouldn't the example be better in the Haddocks? The XMonadContrib authors seem to try to do that, and from what I hear from users that helps a lot.
I'd like to see embedded XHTML allowed in Haddock to allow for that. Also, some guidelines on how to install external documents (e.g., HTML, graphics, Flash applets, etc.) as part of the documentation would be nice.
Because it was a fork of 'John's Haskell Compiler' by someone named 'Lemmih' so he called it 'Lemmih Haskell Compiler' or LHC. Now that the project has changed it should be 'Lemmih's Glasgow Haskell Compiler and Low Level Virtual Machine Backend' or LGHCLLVMB for _short_.
Damnit! Now I have to get NXT stuff and all my old legos. I'm supposed to be _working!_ not screwing around with toys... Why the _hell_ does haskell have to be so awesome?
That looks like a dancer. &gt;\= &gt;|= &gt;/= &gt;\= &gt;S= O|= O|&lt; O|= _bow_
Erm, I was up really late that night. ;)
OK, thanks.
that'd be a start
Yes, perhaps so. If I can figure out a good way to get the structure of the haddock documentation that way. 
Hmmm, I'm about to buy mindstorms for my 15 year old's next birthday --- wasn't thinking of introducing her to Haskell though....wonder if I should rethink that!
I find the eta-expansion of `step 1 (...)` to `\a -&gt; step 1 (...) a` a little unhelpful. Equational reasoning can make the last few steps of this a little less painful. To recap, we've defined --a custom foldl using foldr myFoldl f z xs = foldr step id xs z where step x g a = g (f a x) and we've evaluated far enough to find that foldr step id [1,2,3] = step 1 (step 2 (step 3 (id))) So now, let's start using equational reasoning: myFoldl f z [1,2,3] = foldr step id [1,2,3] z = (foldr step id [1,2,3]) z = (step 1 (step 2 (step 3 (id)))) z = step 1 (...) z Now, check above the definition of `step`! We have just the right number of arguments to expand it, so: myFoldl f z [1,2,3] = step 1 (...) z = (...) (f z 1) = (step 2 (step 3 id)) (f z 1) = step 2 (step 3 id) (f z 1) Expanding `step` two more times, we get myFoldl f z [1,2,3] = step 2 (step 3 id) (f z 1) = (step 3 id) (f (f z 1) 2) = step 3 id (f (f z 1) 2) = id (f (f (f z 1) 2) 3) = f (f (f z 1) 2) 3 Still, his basic insight -- functions of two variables are just functions which, when applied to one variable, yield another function of one variable -- is definitely right on target, and it's the exact same insight that got me excited about Haskell and function programming in general. =D
The title alone deserves +1.
I'm wondering why I'm not hearing as much news about Haskell on ARM. While x86 is big in the desktop and low-entry server market, SPARC is big in servers, ARM is big in embedded and micro-devices, while having more than enough oomph to scale to the desktop and clusters... and has darn sexy assembly. So, is there any specific reason why there isn't as much effort for ARM, or are people just waiting for their pandora to arrive?
Sun donated hardware and the GHC people hired someone to work on it. Plus, the person they hired is forthcoming with what he is doing, much to my delight. Fascinating stuff this, just fascinating.
I thought it was going to be something about the new Haskell logo.
Is anyone active on any Haskell on ARM project? GHC on ARM? Having someone working the problem helps create news and, as altmattr noted, having funding helps get people working.
See http://www.mail-archive.com/haskell-cafe@haskell.org/msg32199.html . The main gotcha is that ghc broke bootstrapping some time ago (you need a port of ghc &lt;= version XYZ to compile the current, don't ask me for details), hugs runs anywhere but isn't a compiler, and the rest, while promising, just isn't ghc.
I'm sooooo tempted to downmod this... "Engines are the new cars" "Ketchup is the new Hotdog" "Money is the new Economy"
Well, a simple start would be to have haddock generate links to http://haskell.org/haskellwiki/hackage/&lt;package name&gt; , with the title "contributed documentation", and hope that people contribute. ...and fix wiki registration, while I'm at it.
Is the implementation wrong? It's tough to tell from the graph, but it looks like the trie diverges pretty quickly from Data.Set when the data sets get large. Another problem is that what the graph is showing is not completely clear. AFAIK trie insertions and lookups should be O(m) where m is the length of the string. In comparison, Data.Map insertions and lookups would be O(m log n). It looks like the author is actually using Data.Map to implement the trie, which is not something that makes a heck of a lot of sense to me. I'm only a beginning haskeller though.
&gt; It looks like the author is actually using Data.Map to implement the trie, which is not something that makes a heck of a lot of sense to me. I'm only a beginning haskeller though. You could very well be right. I got a few alternate implementations from comments and am looking at those. I decided to try Data.Map to address the problem of how to quickly search the various branches of leading off from a node. It may be that simply using a list would be faster. I'm a new haskeller myself :)
He's using Data.Map for the k-keyed maps that are needed at each level of a [k]-keyed trie. That'd be fine, except for Ints, and anything that could be simply converted to them (Chars as well, probably), IntMap is significantly faster, so that's a potential source of inefficiency. Similarly, you wouldn't want to use Data.Map for k = [k'], because a trie should be faster (of course, for whatever reason, the one in the article isn't), although I doubt that's the sort of key his benchmark is using.
We should ask ARM for hardware + $10k to fund someone to do the port + tweaking.
Awesome, I had just read those papers a few weeks ago. This'll be handy for Project Euler. 
This is cheating. If you're not going to implement it yourself, just go use maple/mathematica.
It's always interesting to crack the mainstream press.
I wonder how many sequences should be pre-packaged.
Yay RWH!
Hackage: http://hackage.haskell.org/cgi-bin/hackage-scripts/package/hommage-0.0.5
Why not all of them (as they are implemented of course)? Perhaps the more important question is how should they be catalogued and packaged so that they can be eaily found, and how can the non-existence of one be determined?
Allow users to comment on them?
the de facto standard is the [OEIS](http://www.research.att.com/~njas/sequences/)
The URL is great!
I once again discovered why Haskell is a joy to learn a few minutes ago. Even though I'm sort of used to it by now, Haskell still manages to amaze me with the brevity of its solutions. The given [problem](http://programmingpraxis.wordpress.com/2009/04/14/google-treasure-hunt-2008-puzzle-4) was finding the first prime that is a sum of 7, 17, 41 and 541 consecutive primes. The first posted solution was 36 lines of Lisp code. I figured I could do better, so I had a go at it: import Data.List import Data.Numbers.Primes main = print $ test [541,41,17,7,1] consecutive n = map (sum . take n) $ tails primes test = head . foldl1 (\b -&gt; filter (\x -&gt; elem x $ takeWhile (&lt;= x) b)) . map consecutive I love Haskell.
Article enlightened me a bit: the `Maybe` monad is a container. I had never thought of it in that way, but now it makes sense. 
... which is accessible via the [oeis](http://hackage.haskell.org/cgi-bin/hackage-scripts/package/oeis) package. &gt; I wonder how many sequences should be pre-packaged. Done. :)
I wonder if the author chose a discrete representation deliberately. *Laziness* improves modularity by allowing intermediate lists (etc) to be infinitely *long*, which allows choice of cut-off to be separated from generation. (See *[Why functional programming matters](http://www.cs.chalmers.se/~rjmh/Papers/whyfp.html)*.) *Continuity* improves modularity in an analogous way, allowing intermediate signals to be infinitely *dense*, which allows choice of sampling rate to be separated from generation.
It would be nice if the automatically-adjusting wheel was included.
There are plenty of well-known and efficient algorithms for generating prime numbers; I've rolled my own before, but I don't see a reason to do so now. I'd rather have a nice library I can import and focus on the actual problem. Also, there're a lot of people that use maple/mathematica/matlab to solve these. All of those are listed as language options under your user profile. So basically, you consider it cheating, I don't. And that's fine because PE isn't about competition, it's about learning.
Your correction is appropriate. You can verify it by setting a = 4j + {1,3} and n = 4k + {1,3} and seeing that of the resulting four possibilities the exponent is odd only for (2j+1)(2k+1), that is only if a = n = 3 (mod 4).
Can anyone clarify something in the language? The author talks of monads as computations, for instance: &gt; In the Maybe monad, `Just x` is a computation, which results in x. I'm unclear on the meaning of computation here: it seems that `Just x` is a computation that results in `x` wrapped inside a Maybe container, no?
It's like math with math!
In a similar project, I ended up with generators producing a `Time -&gt; a`, which was then sampled at the output rate and pushed through the rate-agnostic filter network. I'm not sure how to reconcile Fruit-style signal transformers with digital filters, which I think is what you might be getting at. Lists and streams provide [a very natural mapping](http://www.reddit.com/r/programming/comments/8d1hx/hommage_a_haskell_edsl_for_music_generation_and/c08wkxn) to DSP techniques, seems like straying too far away from that would create more problems than it solves. 
Sweet thanks. I find this a very empowering as it means a) I have accomplished a basic understanding of Haskell. b) My first contribution to existing open source code was valid (and very needed!) c) I understand something about number theory.
I think it makes more sense looking at the types instead of actual values. For example, Maybe Int represents computations that return an Int that may fail. Eg, Just 4 -- successful computation returning 4 Nothing -- failed computation There are other kinds of computations, such as [a], which are computation that may return many values (or fail with []), and IO a (computations that have an effect on the real world. All the Monad class does is gives a common interface to sequencing these different types of computations together. Eg addMaybes :: Maybe Int -&gt; Maybe Int -&gt; Maybe Int addMaybes m1 m2 = m1 &gt;&gt;= \x -&gt; m2 &gt;&gt;= \y -&gt; return (x+y) -- eg addMaybes (Just 2) (Just 3) = Just 5 -- addMaybes (Just 5) Nothing = Nothing addsToValue :: [Int] -&gt; [Int] -&gt; Int -&gt; [(Int,Int)] addsToValue lst1 lst2 val = lst1 &gt;&gt;= \x -&gt; lst2 &gt;&gt;= \y -&gt; if (x + y /= val) then [] else return (x,y) -- eg addsToValue [1..5] [1..5] 4 == [(1,3),(2,2),(3,1)] prompt :: String -&gt; IO String prompt text = putStr text &gt;&gt; getLine All three functions do very different things, however, they all use the same functions to link their computations together. 
I still think its best to explain Monads as a natural extension to Applicatives, and explain Applicatives as a natural extension to Functors. In other words, explain Functor, then Applicative, then Monad.
See [Monads as containers](http://www.haskell.org/haskellwiki/Monads_as_Containers).
Instead of fromMaybe G . fmap F You can also use the maybe-fold (or catamorphism, if you'd like): maybe G F p.s: No need to parenthesize prefix expressions, prefix is always higher precedent than infix. 
In an FRP world, you probably wouldn't have files with write mutators. Instead of files, you'd have a Behavior you can use directly.
How does "newtype" translate to C++? C++ has no type-classes and instance, nor does it have laziness, so I'm not sure what you mean.
&gt; Lists and streams provide a very natural mapping to DSP techniques, seems like straying too far away from that would create more problems than it solves. I'd again apply the analogy with strict vs lazy semantics. The improved composability of continuous (as with infinite/lazy) introduces some implementation challenges. It has taken quite a while for pure/lazy functional programming to get to be as efficient as it is now. I predict the same will hold with *continuous* functional programming. As I think you're suggesting, the challenges include more than just efficiency. There are also questions of how we adapt or replace current theory &amp; techniques, such as digital filters. We'll have to do some re-thinking. I'd start by asking what continuous concept is being approximated by those discrete algorithms. I expect we'll get some elegant and useful answers by teasing apart (decomposing) some discrete algorithms into continuous and discrete portions, just as "Why functional programming matters" teases apart some finite algorithms into infinite (and more composition-friendly) and finite parts. I predict that the continuous portions will be much more composable than today's discrete-centric algorithms (just as with lazy/infinite vs eager/finite). Of course these predictions are speculation on my part. We'll only learn what's possible by trying something new. 
Sometimes I want a type that behaves exactly like, say, an int, but it won't type-check as one or automatically coerce to one. Then I can use function overloading to dispatch on it differently. You can kind of do this with classes but it's more of a pain than a "make an alias of this type that doesn't typecheck as this type" keyword. And there are other cases where I've wanted it, but I can't remember them right now. ;-)
Ooh ooh! okay... I wish for a space-ship!
In case people don't want to read the whole article to see why I would say that, the article was about a common claim that Erlang doesn't have state. The arguers tend to equate state with representation. I tried in another article to explain why state was an abstraction but didn't get far. So in this article I show the assembly GHC generates for a tail recursive function to show that a register gets mutated at runtime but that it's invisible to the programmer. I then transfer the idea into Erlang where I show that message sends/receives allow visibility into the mutation. Thus the abstraction offered by a pure Haskell function is stateless whereas the one offered by an Erlang actor loop is (or at least can be) stateful. For even more on the topic see the discussion brewing here http://www.reddit.com/r/programming/comments/8d9b8/erlang_style_actors_are_all_about_locking/
&gt; As I think you're suggesting, the challenges include more than just efficiency. There are also questions of how we adapt or replace current theory &amp; techniques, such as digital filters. The problem is that in going straight to analog filters, all the well-behaved difference equation stuff gets replaced by differential equations, which would then have to be solved numerically, and now we're back at having to fix a sampling rate. &gt; I'd start by asking what continuous concept is being approximated by those discrete algorithms. I'm no expert, but my understanding of it is as follows. If `x(t)` is the continuous input of a filter, and `y(t)` is its continuous output, then a large very class of filters can be described as `Y(s) = H(s) X(s)`, where `F(s)` is the Laplace transform of `f(t)`. `H(s)` is the transfer function, it characterizes the filter by relating inputs to outputs. The Laplace transform has a time shift property that Fourier-like transforms tend to exhibit; specifically, `e^{as} F(s)` corresponds to translation by `a` in the time domain. Now, say we sample the output signal `y(t)` at some ideal sampling rate, `r`, and write `z = e^{s/r}`. The difference between the inverse transform of `Y(s)` and `Y(z)` is the time shift of `1/r`, i.e. one sample. This gives rise to the discrete analog of the Laplace transform, the Z transform. The substitution allows for a very nice property: `z^{-k} Y(z)` corresponds to a delay of `k` samples. If `X(z)` and `Y(z)` are polynomials in `z`, you get a mechanical translation to difference equations of the form `a_0 y[n] + ... + a_k y[n-k] = b_0 x[n] + ... + b_k x[n-k]` for a `k`th order filter. So, you get two sets of tools: designing the filter in terms of the transfer function lets you think in terms of zeros and poles of ratios of polynomials in the frequency domain; at the same time, the Z transform gives you a straightforward path to a working model in the time domain. &gt; I expect we'll get some elegant and useful answers by teasing apart (decomposing) some discrete algorithms into continuous and discrete portions, just as "Why functional programming matters" teases apart some finite algorithms into infinite (and more composition-friendly) and finite parts. I think I just managed to talk myself into a potential angle of attack here. It might be possible to specify filters *symbolically* in terms of the Z transform, and then reify it at the output. In other words, filters would be `(Z -&gt; a) -&gt; (Z -&gt; a)`. Edit: removed a rather nonsensical postscriptum. If `Z` represents rational functions by wrapping `Ratio (Poly a)` (with instances of `Num (Poly a)` and `Integral (Poly a)` provided), you can write filters directly in terms of the transfer function. I'll have to play with this during the weekend, it could turn into something very cool. 
Yes, that's about as far as anyone has gotten with FRP and files.
&gt; The problem is that in going straight to analog filters, all the well-behaved difference equation stuff gets replaced by differential equations, which would then have to be solved numerically, and now we're back at having to fix a sampling rate. Yes, this is a wonderful problem to have! This shift from difference to differential equations is part of what I'm talking about in refactoring with improved modularity. Distill out the continuous/differential essence from the numeric solution. Compose at the simplified (sampling-independent) continuous level. Then use a high-quality stock library of numeric solution/approximation techniques (probably using adaptive sampling rather than having to "fix a sampling rate"). Since the numeric/discrete techniques get reused considerably, economy of scale makes it more worthwhile to use more sophisticated (accurate &amp; efficient) techniques than it would be if mixed in (as is typically done) with the sound specification. And of course these considerations, challenges &amp; benefits apply to higher-dimensional spaces such as imagery, as well as to sound. As I mentioned before, I foresee the same sort of evolution as has happened in making the shift from strict to lazy functional programming. For efficient implementation, lazy is a tougher place to start. The huge win in modularity (the subject of *[Why functional programming matters](http://www.cs.chalmers.se/~rjmh/Papers/whyfp.html)*, perhaps more accurately titled "Why *laziness* matters"), gives rise to reuse and hence economy of scale, which then more than makes up for the initially more difficult implementation problem. That's my vision, anyway. &gt; [...] I'll have to play with this during the weekend, it could turn into something very cool. Please let us know how it goes! 
Wow. Now there's really no excuse for me _not_ to buy the book.
&gt;(File x _ _) == (File y _ _) = x == y I don't know Haskell so I was wondering what does this does?
This is defining equality for File types, It is using pattern matching and it's pattern on function arguments. Basically It is "deconstructing" (don't think destroy here) the data constructor of File to pick out the integer member and ignore the others, this is what the _ means here, it means to "match anything" because we don't care about it here. If you look back at the definition of File: data File = File Int String String deriving Show This defines a type File with a "data construtor" that takes integer and two strings. These are the data members of File. Does it make sense now?
&gt; Morale of the story: Perl's dead. You cut me deep, Haskell
&gt; (File x _ _) == (File y _ _) Comparing the equality of two Files &gt; = is equal to &gt; x == y comparing their first fields.
Nothing but providing an Eq instance for File, which isn't used in the program, but necessary for the Ord instance: Not to implement it, but to satisfy the typeclass hierarchy. Sometimes, I wish for something like data File = File Int String String derivation Ord (File n _ _ _) = Ord n , filling in the Eq instance automagically.
You know about generalized derived extensions for GHC haskell? http://www.haskell.org/ghc/docs/latest/html/users_guide/deriving.html
Let the compiler shoot-out begin! :)
Is uhc considering slower performance than any other haskell compiler as a bug, like ghc? Pleeeeeeeaaaaaaseeeeee!
Fortunately, Haskell doesn't say such inanities, but some morons coding in Haskell do.
 mapMap2 t b1 b2 c t1 t2 = mapMap tip1 bin1 t1 where tip1 = mapMap t b2 t2 bin1 s1 k1 i1 l1 r1 = mapMap tip2 bin2 t2 where tip2 = b1 s1 k1 i1 l1 r1 bin2 s2 k2 i2 l2 r2 = c s1 k1 i1 l1 r1 s2 k2 i2 l2 r2 Hard to read
All hail Haskell, destroyer of Perl.
I think he probably wanted to restrict equality to only work on the first argument. Derived equality (I think) compares all arguments.
Perl's not quite dead, it's still very fun... Haskell and Perl are a bit like hot girls who are into the good kind of threesomes with nerds like us... 
... I'm watching you, Brent... you remembered this week, but I'm Wait for it. Watching you.
Perl has been declared dead every week since its creation (1989, for recall). Haskell won't destroy it.
Haskell and Perl are imaginary?
Patience, it's really really hard to create a good implementation of Haskell, and the creation of new compilers is a good sign! :-) 
I don't think they'd consider it a feature, let's put it that way.
"Where is your GHC now?"
I posted a follow-up here where I did a bit of a brain-dump of what I learned. apologies. http://coder.bsimmons.name/blog/2009/04/initial-tests-of-tries-follow-up/ I'm interested to see if people agree with m conclusion regarding Radix Trees. 
It's right over here http://haskell.org/ghc/ silly!
Interesting indeed. Is the last core parallel slowdown seen on any other operating systems (FreeBSD, Windows)?
I'd especially like to see if this also happens under FreeBSD. *Edit:* From [this thread](http://www.reddit.com/r/programming/comments/8dma0/interesting_no_last_core_parallel_slowdown_on_os_x/), an [interesting link](http://www.haskell.org/pipermail/glasgow-haskell-users/2009-April/017054.html).
Would love to hear from a Linux Kernel hacker (however unlikely that is on the haskell reddit)
no, they (haskell and perl) are the stuff of dreams. :)
So I've seen a number of posts and uploads about adaptive containers, but is there a single post explaining what it's all about and not a little piece of the picture?
&gt; Also, the Whole-&gt;(Part, Part-&gt;Whole) is nicer than the pair I originally suggested. It's isomorphic to the (Whole-&gt;Part, Whole-&gt;Part-&gt;Whole) function pair. Efficiency-wise either one could be better depending on the task, so I'd think a typeclass should provide all three. Ideally with rewrite rules to interchange them as needed. Something I'd really like to see, though, is a project for supporting braiding of accessors. Both of these implementations are like the State monad, which is nice and all but how often have you wanted to compose multiple states together? Both the State (a,b) and StateT a . StateT b approaches have their issues; tupling is too general and can allow for bugs, but composing is too restricted and prohibits certain interactions between fields. The normal State monad is essentially a graphical model for HMMs, it'd be nice to generalize that to a little language for describing more intricate graphical models.
In GHC, you can write a datatype like: data IntPair = IP {-# UNPACK #-} !Int {-# UNPACK #-} !Int The `UNPACK` pragmas cause the data (`Int#`) in the `Int` to be stored directly in the `IntPair`, rather than the `IntPair` storing pointers to `Int`s that store the value. Thus, it is more efficient. But what if you don't want to be restricted to just `Int`s? You could try: data Pair a b = P {-# UNPACK #-} !a {-# UNPACK #-} !b but this doesn't work, because such polymorphic fields can't be unpacked. Having something like the above work is a tricky problem to solve in general; storing pointers like GHC does for things that aren't unpacked gives a uniformity to the representation of data, so something like: swap :: Pair a b -&gt; Pair b a swap (P a b) = P b a can actually be compiled to a single function that works regardless of what `a` and `b` are. It only has to swap the pointers' positions in the constructor. If you start specializing your data representation based on what it's parameterized by, you also have to start specializing all the functions that work on that specialized data representation. That could probably be done automatically (although it's probably not simple), but it isn't currently. However, there's a way to do this manually with associated data. You declare: class Unboxable a b where data Pair a b :: * fst :: Pair a b -&gt; a snd :: Pair a b -&gt; b ... And then you make an instance for every combination of unboxable things: instance Unboxable Int Int where data Pair Int Int = IIP {-# UNPACK #-} !Int {-# UNPACK #-} !Int ... Then, whenever you use `Pair Int Int`, you get the specialized, high performance code for `Int` pairs, and so on for other types. You can, of course, do this without classes/associated data, but you end up with n^2 data types and m*n^2 functions for using them, instead of one parameterized data type, m functions for using them, and n^2 instances. It isn't elegant, but it works now, instead of having to wait for someone to implement it in GHC.
Well, I just installed it, so I might be able to tell you not too long from now. However, I'm currently prying my eyes out trying to get x.org to work right, so it could be later rather than sooner.
This is great. Now we have both hugs, lhc, jhc and uhc as competing compilers to the all mighty ghc. Lets hope this leads to some healthy competition and innovation from all parties. :)
&gt;In Haskell, every type has at least one value â€“ âŠ¥. Unlifted types don't contain âŠ¥, do they?
What about a looping function that returns an unlifted value? 
This logo makes me has a sad. :( It looks grainier and less sleekly modern than when I voted for't.
I don't know, I'm asking :).
If you're the author of the linked code, I noticed that justRights can be simplified to a very readable one-liner: justRights xs = [ x | Right x &lt;- xs] 
Yeah, the colours are wrong too. I didn't vote for those colours.
&gt; Yes, this is a wonderful problem to have! This shift from difference to differential equations is part of what I'm talking about in refactoring with improved modularity. Distill out the continuous/differential essence from the numeric solution. Compose at the simplified (sampling-independent) continuous level. Sure, I just meant that it's not entirely clear that divorcing signal processing from sampling while continuing to work in the time domain would actually simplify anything :). &gt; Please let us know how it goes! So far so good, switching to the frequency domain means a little algebra goes a long way. Finishing up the translation to difference equations so I can actually run some data through it. In the meantime, I can write `comb a k = transfer (\z -&gt; 1 / (1 - a/z^k))`, and say things like *Main&gt; transform (comb 0.3 4) pretty z 10 % 3z^4 H(z) = -------------------- 10 % 3z^4 + (-1) % 1 This provides much more information than the difference equation definition, so that's rather nice. Polynomials have to be of finite degree, unfortunately, so no power series tricks a la Henning. Assuming any of this works at all, it's a pretty useful tool in itself (want a 65th order Butterworth filter? here's a 65th order Butterworth filter). The interesting part though is going to be coming up with a useful algebraic framework to fit this into, sort of a frequency dual to FRP. 
What do you mean? Files are basically mutable string variables. They don't fit inside an FRP world, except perhaps as simple (Behavior String), not as readable and writable constructs, at least not sanely and with simple semantics.
In what cases is (Whole-&gt;Part, Whole-&gt;Part-&gt;Whole) more efficient than Whole-&gt;(Part, Part-&gt;Whole) ?
There's also the pimply bottom: (âˆ´âŠ¥âˆµ)
Agreed. The colors are what really turn me off.
WTF did they do to the colors! God damn committees :D
unlifted types contain âŠ¥, it just means it's indistinguishable from the next approximation in the CPO. For example, in miranda, pairs are unlifted, so âŠ¥ == (âŠ¥,âŠ¥) Or for any newtype declaration, newtype Foo = Foo (...) âŠ¥ == Foo âŠ¥ Whereas in lifted types, these values can be discriminated.
wait... []'s fail is []? that's cool. I thought about using a comprehension to make it shorter, but assumed that I'd still have to pattern match on Either.
I don't like those colors too.
Not exactly: I only use the Ord instance, restricted to the Int member. I figured it's evil not to have the Eq instance work on the same member as Ord does, so I didn't derive it. So much for "as hackish as possible"
Success. comb a k = transfer (\z -&gt; 1 / (1 - a/z^k)) *DSP&gt; take 16 $ runZFilter (comb 0.3 4) (1 : repeat 0) [1.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,9.0e-2,0.0,0.0,0.0,2.7e-2,0.0,0.0,0.0] which is the correct impulse response. The "4" refers to samples (which is why I'm not having to specify a sampling rate), but switching to the s-domain is trivial and doesn't affect the definition of `comb`. Things that are easy to automatically extract from the continuous definition (in contrast to the difference equation definition): Bode plot, pole/zero plot, radius of convergence, frequency response, etc etc. This is getting interesting :). 
This is the neatest simple introduction to the sum-of-products view that I've seen. Awesome!
Its like that bad guy from those horror films.
This is the best hackage package I've ever cabal-installed!
Yep. `[]`'s fail is `[]` so you can use it to implement nondeterministic programming: a lazy `[a]` considered as a set of possible `a`s.
Another approach is to consider computations which may yield anywhere from zero to an infinite number of `Int`s. Those are of type `[Int]`. Now consider the subset which can only return zero or one `Int`s. Those are of type `Maybe Int`. (Yeah, this is a "consider the n-dimensional case, now let n go to 1" kind of answer.)
The violet colours salvage it! What the new logo demonstrates is that programmers have no taste. If the male programmers had let their wives and girlfriends vote in their stead, then we would have a beautiful modern logo instead of the back-end-of-a-bus that the majority gave us.
Perhaps he is eluding Haskell by using a scripting language instead of learning more Haskell. :)
Where do I buy my official t-shirt?
When you have a long string of calls to the update functions, frex. The combined functions must do more work to return the old value at each step. For concrete records it's a small but non-trivial cost; if the framework is extended to allow accessors on abstract records then some types may require a good deal of work to generate the extra information that'll be thrown away.
Wow, that was very informative!
You are welcome! ;-)
What color should we paint the bikeshed?
Well thank you!
Is it just me, or does a dutch hug sound scary? I mean, are they gonna hug me so hard that I explode?
I think the lines need to be thicker.
By "old value", do you mean the "Part" in (Part, Part-&gt;Whole) ? If so -- its not actually generated, only a thunk is generated and thrown away. 
How did you get it to work? The module Test.Complexity.Misc is missing here.
&gt; By "old value", do you mean the "Part" in (Part, Part-&gt;Whole) ? Yes. &gt; If so -- its not actually generated, only a thunk is generated and thrown away. Not so. Let's say I apply the original W-&gt;(P,P-&gt;W) function to some w :: W. Now we get a thunk (if lacking a Sufficiently Smart Compiler). Step two, we pull on that thunk because we want to pull out the P-&gt;W function to use elsewhere. The question now is how much work must be done to render (_,f) ? The answer is: it depends. It's true that since we don't pull on the _::P we can leave it as a thunk (if it was a thunk to begin with). However, since we do pull on f::P-&gt;W, in order to render the f we may need to do some additional work in preparing the _::P thunk and (_, ) packaging, which we wouldn't've had to do with a W-&gt;P-&gt;W function. For accessors on record/tuple datatypes, this extra work is rather trivial and a SSC should be able to eliminate it. (Though generating a thunk and throwing it away does have non-trivial cost, mind.) If we generalize the accessors so they can also work on abstract types (as I suggested) then it's possible that this extra work could be great, since the data dependencies may force us to evaluate _::P on our way to getting (_,f). Just because we don't directly want to evaluate the _::P doesn't mean it doesn't get evaluated. Also, the need to look into w::W in order to extract the _::P at all can introduce complications on how to go about extracting f::P-&gt;W, whereas using a W-&gt;P-&gt;W function could have a more direct implementation. If you don't believe this, consider why we'd want to have a W-&gt;(P,P-&gt;W) function in the first place, instead of two functions (W-&gt;P, W-&gt;P-&gt;W) ---to share work in traversing the input object! Now, what if we didn't need to traverse the object in order to insert/update a value in it, but only needed to traverse it to extract values? I say all this having messed around with generalized accessors for various abstract types. It's very pretty to create the one Ur function that can do everything, but even if that function is optimal as an Ur function there are many cases where GHC is not a SSC enough to be able to simplify for the common basic patterns. Besides, folks'll define their own helper functions so they don't have to write fst and snd everywhere...
&gt; -- or is this a newtype? It's data. In order to use newtype it'd have to be a newtype over the tuple (Int,String), which amounts to the same thing as data (including many optimizations like unpacking, thanks to it being a single-constructor data type).
*facepalms* Totally should have noticed the single Cons, Single Field thing... 
Awesome. Sometimes I wish Vim had a Proofgeneral interface-- I don't want to have to learn Emacs. Even enough to set it up is so confusing...
Sigh... I spoke a bit prematurely. I was trying to channel [Strongbad](http://homestarrunner.com/trogdor.html). I hope the author gets this fixed soon, as this is definitely of great interest to me.
Yes. I got into programming because of my love for theoretical math, but I haven't learned Haskell yet. It's #1 on my to do list this summer--namely because of its syntax and how close it is to math.
I started programming in Haskell in high school, and I do not exaggerate when I say that it made my math scores max out.
Does it deal with bottom? Or are these proofs about idealized Haskell that always terminates and has no domains with infinite chains? 
$CABAL_HOME or some other environment variable if declared, or globally if not. I say globally for consistency; pretty much all other software installs globally.
It is nice to be able to install in my home directory, so that ~/.cabal/ can be tarballed and follow me around, a lot like ~/.emacs*. Excluding that you have to alter $PATH, ~/.cabal/ is quite an elegant way of doing package management without interfering with the host distro (which normally has older libraries).
alias cabal='cabal --global' and you're done. I definitely don't want my still bug-ridden self patched-up libraries be installed globally by default by the very system I use to develop them.
Nice catch, and an interesting site that I'd never seen before.
I'm a vim-user, it took me about 3 days to learn Emacs enough to use the Haskell major mode, the Haskell and Lisp repls etc.
i'd rather read a whole page of comments than try to grok haskell written that compactly
why is this even a question? act like every other peice of unix software and go to a globally callable directory. fuck.
no.
I refuse to participate in this poll as it does not specify whether we're voting about Cabal the library or cabal the executable. I don't believe the results are valid with this ambiguity.
&gt; ~/.cabal/ can be tarballed and follow me around, a lot like ~/.emacs*. I don't think it can actually. You'd at least have to copy GHC's package database as well.
You could also emulate vi-bindings inside Emacs using viper-mode. While not a perfect solution, many might find it a more compelling than learning new bindings.
I tried viper mode, and it bugged me a lot for some reason.
This is the second article that I've had a really hard time reading the code. http://www.reddit.com/r/haskell/comments/8di21/flattening_datamap/ It seems to me it could be re-factored into smaller functions with more understandable results from each. 
Idealized. Haskabelle can spit out code like "ones = (1 # ones)", but Isabelle will complain. If your Haskell defines f = reverse.reverse, g = id, then in the generated Isabelle/HOL you can prove f=g: theory RevRev imports Fun Prelude begin definition f where "f = (rev o rev)" definition g where "g = id" lemma f_g: "f = g" apply (simp add: expand_fun_eq) apply (unfold f_def) apply (unfold g_def) apply auto done end I was pleasantly surprised to find that Isabelle will accept a definition of the Ackermann function without any supporting proofs. Try it on this Haskell: data Nat = Zero | Succ Nat ackermann Zero n = Succ n ackermann (Succ m) Zero = ackermann m (Succ Zero) ackermann (Succ m) (Succ n) = ackermann m (ackermann (Succ m) n) 
I certainly wouldn't do so much nesting as this author. I particularly avoid nested where-clauses. But at the same time, I view some elements of his style as overly verbose. E.g., instead of: ` case (...) of Just x -&gt; let (shortestKnownPath, _) = x in ...` I would probably write: ` Just (shortestKnownPath, _) -&gt; ...` He also throws in newlines after `=` where I would not. And I'm a big fan of pattern guards rather than `if..then..else`. But we all have our own personal styles, I suppose.
I have to agree about that flattening article.
I'm all about pattern matching. Every time I'm tempted to throw in an if or case I look to factor it out into its own function with multiple clauses. It's cleaner to me even if the function is not strictly re-usable elsewhere. I guess this is what the where is for in Haskell, the context specific function declaration. In erlang you end up with a lot of functions with one use, but I don't know where its written that functions are only for DRYing up you're code. 
Cool projects, but none that I find really *exciting*
this works the other way too.
Gotta put something exciting into the proposals reddit, and turn it out next year.
shit cock balls We are cool.
I am of the belief they should both be the same behavior (they aren't right now), as such there would be no ambiguity as the vote would be for both. The new behavior would mandate a bump in the major version number of Cabal library (as I feel that is the one behaving undersireably), but thats the reason to have versions. Whoa unto the code that doesn't propery specify the dependencies.
Ah, I'll look into it immediately.
It's fixed now. Version 0.1.2 available in a hackage near you. Now I now what the `other-modules` field is for :-) In case of any more bugs or questions, don't hesitate to send me an e-mail!
Agreed that it wasn't the optimal solution (the author here) and I'm still working on my Haskell style as I go along. I have cleaned it up a little but would always appreciate how to make it better: http://gist.github.com/98840
Works great now, thanks!
Leksah is really cool, but it's needs a little bit more polishing. It took me forever to get it to compile, and now I'm afraid to use it because it crashes and takes all of X down with it. There are also somewhat minor issues with the creating a project/package, but those are probably best attributed to user error.
types reddit?! The balkanization is complete.
yea i think some people spent too much time writting perl and forgot how to write code thats actually readable
Please report your crash problem here: http://code.google.com/p/leksah/issues/list. 
I plan on it. I've been just trying to track down exactly when it's been happening and seeing if I can get any sort of error messages before I do.
&gt;Resolving dependencies... &gt;cabal: cannot configure leksah-0.4.4.1. It requires glib &gt;=0.10, gtk &gt;=0.10 and gtksourceview2 &gt;=0.10.0 &gt;There is no available version of glib that satisfies &gt;=0.10 &gt;There is no available version of gtk that satisfies &gt;=0.10 &gt;There is no available version of gtksourceview2 that satisfies &gt;=0.10.0 I can't get it to install on Ubuntu 8.10 :(