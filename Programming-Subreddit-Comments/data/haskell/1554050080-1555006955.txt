Not only the best imperative language, it's now also the best dynamic language! Success can't be far away...
Now, if only they added strict evaluation by default and wrapped everything in unsafePerformIO, then we‚Äôd be talking!
It needs `default (Dynamic)`. Pity you can‚Äôt get the default by an import. 
It is a meaningful distinction within Haskell. Haskell makes a clear distinction between functions and non-functions. See http://conal.net/blog/posts/everything-is-a-function-in-haskell for a breakdown of why it doesn't make any real sense to call main a function, and why it could be misleading.
You could generalize this to any well-behaved foldable Monoid. Size is a Monoid with 0 and +, the size of a foldable structure is given by `foldMap (const sizeOne)`. All other instances operate on the contained structure. Could be useful to have sized Finger Trees, sized Set, sized etc..
* Best functional language ‚úîÔ∏è * Best imperative language ‚úîÔ∏è * Best [object-oriented](https://www.well-typed.com/blog/2018/03/oop-in-haskell/) language ‚úîÔ∏è * Best statically typed language ‚úîÔ∏è * Best dynamically typed language ‚úîÔ∏è
Thanks for posting that article, it was an interesting read. Though it didn't actually answer the question of whether the distinction is *meaningful*. The conclusion from the comments seemed to be that the Haskell Report encourages (accidentally or otherwise) the interpretation of expressions as functions with zero arguments. And no argument against doing so was actually presented, beyond " `-&gt;` defines a function".
Thanks for making these points and providing examples! I wasn't aware of either of these behaviors. TIL
This is great, this is exactly what I needed for some data science stuff I've been doing in Haskell
Love the enterprise-software tag
But I enjoy static typing
A disadvantage of this representation/implementation is that, in practice, it will force a strict spine of the list. So it is not convenient for every case where a normal list would be used and is not as composable (composability being one of the main advantages of lazyness). I guess `slist` would be useful in the case where, *for some reason*, you really need to repeatedly "compute" the length of the list (being `O(1)` in `slist`).
Good point :) The article is more about why the non-distinguishing is not meaningful. There is no benefit to considering something like True as a function. As for meaningfulness of the distinction, I refer to my edits in the previous comment: Haskell is a *strongly typed* language, so it makes it meaningful to distinguish between types. The reason why Int is different from Bool, or why String is different from IO (), is because we have functions that are reigned to take only strings, only bools, etc. Essentially, the types determine the behavior of what our values can do. Since functions are values, their types, too, determine what we can do with them. If something is a function, we can: * Apply it to values using application syntax, f x * Compose it with functions like (.) * Provide it to higher-order functions like map, filter, foldr, etc. The distinction is meaningful in Haskell because, unlike other langaues, *types* are meaningful in Haskell. To say that the distinction between function and non-function in Haskell is meaningless is to disregard one of the most important aspects of Haskell.
It's a little different. As a Nix and Haskell fan, Nix fans are like Haskell fans - "This thing is so great, it's clearly how we should be doing things! Now that I've used it, having to do stuff the old way actually really sucks.", occasionally to the point of some peoples' annoyance. Guix fans are GNU fans - "It's not 'Linux', it's 'GNU/Linux'. Calling it free and open source is a lie unless you can read the driver sourcecode and run it on open hardware.". Every time there's a thread about Nix on HN or the like, someone from the Guix community pops in to hate on it for not being _truly_ reproducible; I'm sure they're right, but they do a better job turning people off to the whole concept than advocating for their own cause.
Millions of Python programmers can‚Äôt be wrong.
I actually feel like this is a good learning module for people newer to haskell, i.e. it's a decent sized example of sum types + typeclasses + aeson + core libraries / data types. Not sure how joking this was really meant to be but I can see it being pretty useful, especially for one-off tests. 
Yeah, there's definitely a case to be made that having a word for "thing which takes arguments and gives values" [informally]. And that in Haskell, (-&gt; r) is an important part of the language. But I disagree that treating "zero arguments" as different from "one or more arguments" is helpful. It's the base case in an inductive class. It almost feels like treating `Zero` as different from `Succ Zero`, `Succ Succ Zero`, ... . Another example of why this is a little bit of an unhelpful idea is to consider a definition like `doubles = map (*2)`. Is this a *function definition*, then, or just a definition, or something else? My reckoning is that it is a function definition, not because of how many arguments there are (or aren't). [Moreover I just searched the reddit for "main function" - if we treat language as evolving, then I think it might be worth considering that ship as sailed]
I extremely disagree with that. I think compile errors are much better than runtime errors.
&gt; One problem with this representation is that it will often leave the size undefined in situations where it should really be Infinity. I would say that it is a problem with lists generally, not particularly with this approach. You can never say what would `filter` convert the infinite list to. The package covers the cases where you can actually tell whether the list infinite or not. &gt; Also, saying that it "doesn't actually add any overhead on the existing functions" seems clearly wrong because it clearly does just that by adding an extra record field to maintain and an extra indirection to access the actual list. The idea is that you as the package user would never deal with the size directly. Slist implements almost every function from `Data.List` so you should be able to replace ordinary lists without the overhead of dealing with sizes manually. &gt; Also, the semantics of safeReverse on infinite lists is way unexpected. I'm sure this function has its uses, but I think the name is misleading. The "safe" here means that it won't hang unsafely as the `reverse` function would.
Just because many people use python doesn't mean it's got good design. APL used to be one of the most popular languages. 
I was thinking about this approach but it using Size directly has some benefits: 1. Ability to tell if the list is infinite or not 2. More efficient size recalculation in some cases (like in `intersperse` or Applicative instance) 3. Ability to control behaviour depending on the list finiteness/infiniteness 
&gt; is not as composable (composability being one of the main advantages of lazyness). What do you mean here? All the functions from `Data.List` are reimplemented for Slist, so you can implement identical scenarios with Slists as well. Or it's something deeper (like instances in other libraries)?
They were probably not being serious...
Thanks. I hate it.
The library for when you really hate your code being correct all the damn time.
I see that you're using an !Int for finite sizes, with a comment that size should not ever be negative. Have you considered using a strict natural (from Numeric.Natural) instead? That would give you stronger types and arbitrary precision. 
I hope not
/r/woosh
The thing is that something like `doubles = map (*2)` already *has* a good name: it's a *value* definition. There is already a good word for a "thing that can have 0, 1, 2, etc. eventual arguments". It's a *value*. It seems like you are suggesting that there is no good word for "variable-argument function" in Haskell, but this isn't the case. The beauty of Haskell is that all term-level concepts are *values*. Saying that main is a function takes away the "big picture" of Haskell, that *everything is a first-class value*. Realizing that everything is a value is a huuuge insight that is yields great reward when writing Haskell, and it's arguably one of the biggest benefits of the language. The fact that IO actions are *not* functions, but rather just normal first-class values? It's a huge deal. Insisting on viewing main as a "function" instead of a non-function value really holds back from understanding and appreciating the benefits of Haskell.
Yeah. I got wooshed good
&gt; Also, init works on infinite lists out of the box, so you should update the table. If you check [the implementation of the `init` function](https://hackage.haskell.org/package/base-4.12.0.0/docs/src/GHC.List.html#init) you can see that it truly works infinite time without actually doing anything on the infinite lists while the [Slist implementation](https://github.com/vrom911/slist/blob/cec65339c709cfc86dbf0825c9ec68cbd7e34ae3/src/Slist.hs#L637) works instantly in that case.
I was also thinking about this idea. But decided to go with `Int` as it's more convenient and fast for working with functions from base. Using `Natural` will introduce additional numeric conversions so I stopped at `Int`. 
&gt;Now, if only they added strict evaluation by default One could use -XStrict.
Really great article with great step-by-step thought process explanations. &amp;#x200B; Will there updates or addendums made to the article in light of some of the feedback here? It would be great to see a before &amp; after!
Are these impossible properties to add to finger trees etc? It would be awesome to have equal functionality there too.
If I do something like f a b c v = a++ if v then b else c At least in theory accesses into the head items of the result list (the elements from a) need not compute b, c or even v. If we always update the length of the list we need to know which of b and c were used and so need to compute v.
I'm trying to figure this stuff out rather than autogenerate a response from my brain (as reddit discussions tend to devolve into!) so sorry if this is hard to read. Regarding the last bit, single-element lists isn't really a good comparison, it would be more like saying that `[[1]], [1] and 1` are all examples of nested lists with the latter being nested "zero deep". Is that a useful idea, probably not? But it does, for example, exist as the limit of repeatedly calling `fold` or similar on an arbitrarily nested list. I've just noticed that this is literally only a choice of terminology thing. I substituted the word "value" for "function" and "function" for "imperative-style function" everywhere in your post and agreed with almost all of it. I feel like function is a better word than value because I am a mathematician and I see functions as these very pure mathematical constructs with zero or more parameters. It's very possible that you are seeing function as a fundamentally inappropriate word because of it's connotations for people coming from imperative languages where function is a very specific type of thing. Is that right?
One thing I wish they had been a bit more careful about is the introduction of `IO`. An `IO String` is *not* a string inside an `IO` container that indicates it was built using side-effects; it‚Äôs a representation of an *action* that produces a string when executed by the runtime. One of the better ways I‚Äôve heard of explaining this is ‚ÄúAn `IO String` contains a string in the same way that `ls` contains a list of files‚Äù (i.e., it doesn‚Äôt). `IO` is a way of *encapsulating effects*, not ‚Äútagging values‚Äù. This matters for pedagogy, because if you think of it as a ‚Äúwrapper‚Äù or ‚Äúcontainer‚Äù, you‚Äôll end up asking the classic beginner question ‚ÄúHow do I get a `String` out of an `IO String`?‚Äù‚Äîand the answer is, of course, you don‚Äôt! You can use this action inside other actions, and they can get the `String` out and use it within the context of that action‚Äîbut your overall program is entirely pure, since it‚Äôs only *building* these actions (statically or dynamically) and the *runtime* is what executes the actions that you hook up to `main`. 
It productively yields elements, though, e.g. `take 10 (init [1..])` does not hang.
What I mean is that, because the list spine will be forced, I cannot use `Slist` the same why I would use normal lists. Here is a simple (useless) example of what I can do with lists because they are lazy: &gt;&gt;&gt; take 5 $ [1..10] ++ undefined [1,2,3,4,5] &gt;&gt;&gt; :set +s &gt;&gt;&gt; take 5 [1..100000000] [1,2,3,4,5] (0.01 secs, 92,584 bytes) Now with `Slist`: &gt;&gt;&gt; import Slist as S &gt;&gt;&gt; S.take 5 $ S.slist $ [1..10] ++ undefined *** Exception: Prelude.undefined ... &gt;&gt;&gt; :set +s &gt;&gt;&gt; S.take 5 $ S.slist [1..100000000] Slist {sList = [1,2,3,4,5], sSize = Size 5} (6.40 secs, 8,000,486,176 bytes) See that `Slist` forces the spine of the list, causing the `undefined` to be evaluated in the first example and taking too much time and space in the second.
At what point can I consider myself "good" at Haskell? 
It‚Äôs April fool haha 
It's March 31st where I live
This is a very nice exercise, thanks! I wonder if you considered `-fdefer-type-errors` to get even more flexible. It doesn't play nice with GHCi though.
I know that `take` does not hang. But we are talking about `init`, don't we? If you would look at the `take` row in my table you will see `O(i)` and nothing about hanging, so again I don't need to change the table as you are telling the same things that are written in there. So I don't understand your concerns. `init` function from `base` itself works the infinite amount of time while `init` from `slist` works for `O(1)` (it doesn't reconstruct the list again just returns the same list that was given, so no additional memory allocation either).
I'd categorize being "good" at Haskell as being proficient in three fields: doing things, understanding things, and using things. &amp;#x200B; **Doing** For some examples, I hope you can: * write a library to read data from a file, sort it, and send the results to a web service as a JSON message? * make a command line tool that reads some arguments, starts a repl, parses, and evaluate some simple language. * build a structure and accompanying functions such as a binary/b/prefix tree. **Knowing** Do you understand: * How to use the common monad transformers such as State, Reader, ExceptT, and ST. * laziness (test: tie the knot to populate a tree with the minimum value) **Using** Can you use one or two of the common build systems? Can you experiment in GHCi? ... got to go, hope this is a start.
Well, okay, if you need to work with `undefined`s all the time then you don't work with `slist`. I believe it's your common use case, but as you can notice I didn't mention this use case suitable for the library, you can find other use cases in which `slist` can be helpful. And about the example you gave. If you won't construct the slist from the ordinary list at each step then it works faster. If you just change your example to `fromListN 100000000 [1..100000000]` it would work significantly faster.
If you have a masters in mathematics after 7 years of hard studying otherwise after 14 years of hard work. But perhaps you can start to apply for jobs before you are good!?
if only there was more than one time zone
Not possible
It is not that in practice anyone would be working with `undefined`. I used these (silly) examples just to make clear that `slist` forces the list spine to be fully evaluated, which is inconvenient.
It's fully evaluated when you use `slist` function to create the slist. All other functions like `take` are as much lazy as their list analogue. The library tries to be smart in that way and get the most from knowing the list length.
&gt; in practice, it will force a strict spine of the list Depends on how you're going to use the library. From the code it looks like the library is indeed smart enough to calculate length efficiently without need to evaluate `length` of the list each time. So something like the following is as fast and as lazy as ordinary list but in addition you have efficient access to the list length: take 42 $ map g $ drop 10 $ filter p $ replicate 5 x &lt;&gt; iterate f seed `slist` is not the only way to construct `Slist`, the library heavily uses algebraic approach for constructing values, so you are able to construct `slists` efficiently, enjoy usual lazy properties of ordinary lists and also have fast access to length.
Some points to clarify, I think that both `doubles xs = map (*2) xs` and `doubles = map (*2)` are value definitions, so I don't make that distinction :) They also happen to be both function definitions, since they both declare things of type `Num a =&gt; [a] -&gt; [a]`. Just like how `theTruth = True` and `theFalse = False` are both value definitions, and they also define `Bool`s. I think, yes, this whole discussion is about choice of terminology :) In Haskell, the word function already *has* a meaning. And so does the word *value*. And there is a reason to prefer *value* to be "a thing that exists at the term level". It has its origin in type theory, and being able to see "everything is a value" is a very significant thing in Haskell: it means that all things can be treated as values, without any distinction. Being able to unite functions, numbers, booleans, strings, etc. all under "value" is a big deal. As for values vs. functions, I think there is a good reason to make a distinction. Just like you should make a distinction between `:: Bool` and `:: Bool -&gt; String`. Haskell is a *strongly typed language*, and so if you call all values functions, then these statements become false: 1. Higher-order functions are functions that take other functions. This becomes false, because now something like `not` becomes a higher-order function. After all, `not` takes a `Bool`, and a `Bool` is a function, right? 2. You can apply a function to an argument. This becomes false, because you cannot apply `True` to an argument. 3. `(.)` can be given any function. This becomes false, because you cannot give it `True`. 4. Any function `f` can be "eta-expanded" to `\x -&gt; f x`. These two must be mathematically equivalent. However, this becomes false if "all values are functions", because this isn't true of `True`. Do you see how the idea of "function" fits so naturally within the context of Haskell? So many very *useful* things would become very complicated if we can call `True` a function, *in Haskell*. ---- The point you make about being able to think about `1`, `[1]`, and `[[1]]`, and `[[[1]]]` all as "nested lists" is interesting here. You're right, it *does* make sense in the context of thinking about nested lists. If you're talking about levels of list-nesting, then you might be able to talk about `1` as a zero-nested list. *But*, this only makes sense in the context of a list-nesting discussion. What if, in the article, this line was written instead? &gt; How do we tie everything together? If we think back to the high level data flow at the beginning, we describe that exactly in Haskell for **our `main` nested list**. If we aren't currently engaging in a discussion about different nested list levels, then it's really silly to just drop in "this is a nested list". I see the same thing here with functions. If we aren't currently engaging in a discussion about a different levels of "inductive function arities", then it would be equivalently silly to just drop "`True` is a function".
I had the same dilemma. Guule was a selling point as it seems a hundredfold more sane than nix expressions. However, the very strict GPL-compatible licenced software is a very high burden for an everyday usecase and a true workhorse machine. Also, the community size is considerably bigger with NixOS, and trust me, even with sysadmin experience you will need it a lot. Either NixOS or GuiX: it'll be a rough road. Obviously I went for NixOS. I still don't have everything set up the way I'd like to uave :-)
Thanks for the link. In assuming that you've read the reference to your link, I have no idea what this means: &gt;The fact that we don‚Äôt talk much about strong monads in Haskell is due to the fact that all functors in the category Set, which underlies the Haskell‚Äôs type system, have canonical strength. Is it true that all functors in the category of Set underlie the Haskell type system? What is canonical strength? 
Unfortunately not. The library uses the `QuantifiedConstraints` extension, which is only available since 8.6.
I am interested to know why community members are learning Haskell ? For me personally, it is because I want to experience typed language as I have spent majority of my time writing JavaScript in the past. Secondly, I want to strengthen functional programming concepts to see how it can shape my thinking and reasoning about code, and lastly, learn about interesting ideas from lambda calculus. So what's your motivation behind picking up Haskell ? It could be something like: - You are looking for a FP/Haskell job - You are looking to switch to Haskell inside your company - Perhaps, this is more like a hobbie to build interesting side-projects etc - May be you are building a start-up and Haskell is the best choice for that domain
Ugh, I'm pretty sure people reading this can figure out exactly what I mean when I say that non-substitutive `Eq` will cause problems with a VDOM library that checks `Eq` before rerendering. Lets say you have an `Int` type with a weird `Eq` instance that only cares about sign (obeys all the other `Eq` laws besides substitutivity), lets call it `SignInt`. Now suppose we have state: `data State = State { foo :: Int, bar :: SignInt }` Now lets say we have a Miso view with both the `foo` and the `bar` rendered, and buttons for incrementing / decrementing each. Clicking on the button to increment `bar` won't actually cause a visual update, as the `Eq` check on the new state will return `True`, saying nothing has changed. Now when you later change `foo`, `bar` will suddenly snap to the true underlying value, at least right now, in future various optimizations might cause Miso to never actually update `bar`, due to multiple "layers" of caching instead of just top level checks.
APL is a fantastically designed and extremely interesting language. Why would that be your example?
I hope this is an April fools joke 
Certainly not, APL has a far better design than something like PHP or JavaScript. 
Nice joke. It's pretty funny
With `cat` the file can even be a device. Simple disk cloning: `cat /dev/sdb2 &gt;/dev/sdc3`
How horrendously immature. Grow up.
APL is probably one of the worst languages I've ever seen
How many lines of code have you written in it, and which resources did you use to learn it?
APL is terrible because it's hard to read. Its nickname is the write only language. Unless you plan on only working by yourself, that's a huge problem. 
This is why I love Haskell, especially applicatives :P As abstract and mathy as this is, I still consider it practically useful for real world jobs.
That‚Äôs very much irrelevant to the question I asked. Right now you sound about as credible as those who cry that you need a PhD in category theory to understand Hello World in Haskell.
I have not ever written apl, but I have read apl code and I have read about it. My opinion is mostly shaped by communities that I've talked to. Outside of code golfing I can't understand why someone would use it. Why do you like it so much? 
Because it contains extremely interesting ideas on how to process both scalar and vector values in a consistent style. I don‚Äôt think APL is the best language for many tasks, but its design advanced the state of the art and produced new ideas to explore. Plenty of languages fail to do this.
I guess that's kind of true. It's one of the reasons I learn esoteric languages. But my problem is that apl doesn't seen very practical compared to normal programming languages because of readability. APL seems like it would be extremely difficult to maintain
But `init` from base absolutely does not "hang" in any way shape or form.
Do we have a rogue's gallery of these things? instance IdempotentMonad Identity instance IdempotentMonad m =&gt; IdempotentMonad (IdentityT m) instance IdempotentMonad Maybe instance IdempotentMonad m =&gt; IdempotentMonad (MaybeT e m) instance IdempotentMonad (Either e) instance IdempotentMonad m =&gt; IdempotentMonad (ExceptT e m) instance IdempotentMonad ((-&gt;) e) instance IdempotentMonad m =&gt; IdempotentMonad (ReaderT e m) The product of two idempotent monads should be idempotent. Lindsey Kuper's `Par` monad should pass the test, at least when her L-Vars are actually _lattice_-variables and not being repurposed for more general purposes. I suppose if you split something like the Adapton paper's inner and outer computations apart the inner computation which can read from references but not write to them would pass the test. Similarly you should get something similar for the read transaction code in `rcu`. I realize I've focused on idempotent monads, but the ideas should port. Once you expand to Applicative you get a few new examples, like `Const l` for any semilattice `l`.
So how do you think the `init` works in terms of `O` notation? 
Nice job - i enjoyed reading it. Keep it up!
I don't write APL for a living, but a derivative (k/q), and readability isn't an issue. Firstly, most code isn't in the hyper-terse style that's shown off when talking about array languages. Almost all the code that's actually written uses multiple lines, has variables, and tries not to use long chains of operators. The code that people like to show off is flashy: the 1-liner game of life in APL is of similar ilk to the haskell fibonacci 1-liner. It's cool, but you don't really want to push it to production. Secondly, even with the above, the style is still a bit denser. But this is something that you just learn and adjust to, like any other language. There's no ability to scan-read an APL program, and that's absolutely fine.
What is the advantage of array languages?
For k/q, it's used as the query language for a fast time-series database, so that's why I get paid to write it. Otherwise, it's main advantages to me are aesthetics and expressiveness. It turns out that a surprising number of problems have clear and satisfying solutions when phrased as index arrays, and are naturally quite performant as well. In a technical sense, there's nothing that stands out about them - you will have at least as good performance with other languages.
Well thank you for enlightening me. This has been interesting. And sorry I was such a jackass earlier. I was just being a salty bitch. 
I think it was just a cheeky sarcasm about dynamically type language 
(I'm not the same person as the original defender of APL here, I just ran across the thread). I suggest that you give APL (or J, if you can't get your fingers around the keysdet) a try, it's really a great family of languages.
Ok. I guess I can try it. I have a friend who learned who didn't like it, but I might as well learn it for myself. Thanks. 
It's fully evaluated when you use `slist` function to create the slist. All other functions like `take` are as much lazy as their list analogue. The library tries to be smart in that way and get the most from knowing the list length. So the times you calculated above don't tell anything at all about the real performance, as it's known that `slist` works for `O(n)`. But when you already work with slist you don't need to use `slist` each time! The same as you work with vectors instead of lists, you don't do `fromList` a lot, because it defeats the purpose of using vector in first place. If you check out the documentation of `slist` you could see that I added the performance characteristics to every function and you can judge upon that. Apparently, in most of the functions the size value doesn't give you any overhead since the size comparison operation is cheap. And `take` is a nice example of such function. It would work lazily at the list and establish the size depending on the `i` argument. Slist is a data structure so it is composable within itself. It's strange to hate Containers library because it doesn't implement the same interface that list do. It is just another data structure with other goals and tools. And, btw, you can even make Slist work with undefined lazily: &gt;&gt;&gt; take 5 $ (slist [1..10]) &lt;&gt; infiniteSlist undefined Slist {sList = [1,2,3,4,5], sSize = Size 5} 
The readme certainly emphasises the wonders of dynamic typing
* Best linearly typed language [Coming soon]
thank you so much!
Thanks for your well-worded response. I think Haskell is a really interesting case because it's as close as we've ever come to the exact midpoint between theoretical computer science and theoretical mathematics. Which is why we have these longwinded discussions about terminologies and distinctions. I think you've convinced me that the CS definition is closer to the mark for Haskell, despite its claim towards using "mathematical functions" in most aspects. I will be interested to see what happens once we reach full dependent typing - at which point types can be value-dependent and we lose that rigid line between the two. Regarding the last part, the "main nested lists" thing is an interesting thought. I think it's a bit of a mis-step though; for example I could see such a thing as making sense in a language where lists are universal. Just how you could concievably talk about the "main() object" in an OOP language where functions are first class [though, admittedly, people would look at you funny]. If we take functions as being the intrinsic foundation of the Haskell language, then saying "the main function" makes sense. And to me " `True` is a function " reads just fine because again, that's part of the model that has allowed me to reason about function arity for the longest time.
Philosophically Guix doesn't use systemd, which I suppose doesn't matter much in Nix since you don't have to interact with it yourself but still. For context what I was trying to do was generate a livecd for a stateless webserver (not an install CD, something that would run from ram). Both Nix and Guix have a way of generating an iso from a config, but it's actually not that easy to figure out how, there's very little documentation about this (or there was, at least, when I looked). Then I needed to define plenty of my own packages, for example nix doesn't seem to have any ways of running multiple PHP versions at the same time, and there the DSL got annoying for me, that was easier to do with Guix since I already knew the language. But I can understand that the DSL might be a positive for people, I just wish I could use a language I know instead of having to learn yet another DSL. Anyway that's kind of on pause for now, I ran out of time and the project is running with a debian iso I generated using deboostrap and a bunch of bash, it works great but I'm still hoping the replace that with a cleaner Nix or Guix iso at some point, I just need the time to figure all of that out.
We will most likely record the talks and put them on our [YouTube channel](https://www.youtube.com/channel/UCCeiYYR2fCXarkfSqqFBwuA). We are still hashing out the details though.
Oh for sure, but why stop at the thought ;-)
 -- fzip and unit are equivalent in power to (&lt;*&gt;) and pure. I think you also need fmap. Not a big deal, but worth noting. (If I'm right. It's early and I haven't verified my feeling there.) 
Ah, finally someone gave acme-php the modern update it deserved. 
Cool! Note that there's also BPF (Berkeley Packet Filter). It was originally designed to inspect and filter network packets, until they realized it could be used to inspect syscalls as well. See [http://www.brendangregg.com/blog/2019-01-01/learn-ebpf-tracing.html](http://www.brendangregg.com/blog/2019-01-01/learn-ebpf-tracing.html) .
You should put "Python 5" in the title. I almost downvoted. :D
At last!
I was getting into Emacs, and I thought "this Lisp stuff seems interesting". I had never experienced a REPL like SLIME (coming from mainly Perl, C, and PHP). I worked through Practical Common Lisp and then read Land of Lisp, which mentioned Haskell offhandedly. In short, I dropped Land of Lisp for LYAH, and then I just kind of never left. I think it's the *right* language, right now, though not perfect by any means. I write code at work in Haskell and give talks about Haskell, but adoption is basically nonexistent in my company. There are a handful of people who are also way into Haskell, but I largely just have a lot of autonomy so I write the code *I* need for the job I do, in very prosaic Haskell, rather than trying to reason in a language I don't use fluently like Go or Python. I'm a site reliability engineer, so a lot of my tools are generic "pull data from these services, run some commands, etc.", rather than serious long-running applications. I'm currently trying to get comfortable with amazonka so I can stop writing wrappers around AWS CLI calls. Being able to write a parser, pretty printer, and other interchange tooling for weird hardware and services in a couple of hours in the obvious way rather than hoping to find an existing library or using something OTS has been really nice. I recently started experimenting with `swagger-codegen` to do the annoying part of writing API clients in Servant, which has been pretty neat.
You're right haha Btw what plugin do you mean? Do you mean like writing a language extension..?
Have implemented something like this in a CI server that used miso + wai-websockets. Users are subscribed to build notifications / output. You essentially want these things to exist in memory: \- A map of a user and his/her connection (can just use an IntMap for this) \- A map of rooms and a list of users present in them \- A monotonically increasing integer used as the index into the connection map (incremented when a user connects). You can implement this with a TVar that holds the map of users, the map of rooms and the monotonically increasing user ID integer. On the client a user will send a message to the server that contains both the room ID and the message they'd like to send a message to. When the server receives this message it will broadcast a response to all users in the given room ( does a lookup in the room map for all users present ). It should be that straightforward. You'll also need to make sure that on disconnect you remove the connection from the connection map by user id, and filter him/her out of every room as well.
* So good at success we need to avoid it ‚úîÔ∏è This isn't even our final form
Advice on using stack with source plugins? Specifically, I'm trying to create a tool based on [graphmod-plugin](http://mpickering.github.io//posts/2018-08-09-source-plugin-graphmod.html), and to begin with I'm trying to put that in stack. I can do stack init stack build graphmod-plugin stack ghc -- -fplugin=GraphMod -fplugin-opt=GraphMod:out SomeFile.hs and that works. (Though I haven't tried to run the finalizer yet. Also I [can't run it on GraphMod.hs](https://gitlab.haskell.org//ghc/ghc/issues/10077) itself.) But then if I want to run the plugin from outside the directory with .stack-work, how would I do that? Or how about running it on all the .hs files of another stack project? I know if I have the package available I could add `-fplugin` to `ghc-options` in the cabal file, but is there something more convenient? Ideal would be to have a single executable I can run from anywhere with e.g. `graphmod-plugin *.hs &gt; modules.dot` (and no visible output from ghc), but if that turns out to be a lot of effort I can do without.
Wohaaa, that is a huge set of improvements for Python 5 üòÇü§£
I don't think this post proves that `Twisted` doesn't brake any `Applicative` law? Or did I miss something?
I create this configuration loader inspired by spring-boot's configuration management. Wants to know if there is anyone needs it, or how can i improve it, thanks.
This is great! I often need to get the length of a list and end up using a different data structure for that reason
I was thinking of [essentially this](https://jship.github.io/posts/2018-10-13-subvert-your-type-checker-today.html)
This pattern sounds a little bit like you could use a message oriented middleware (mom)? Maybe take a look at rabbit mq or zeromq? I think you can configure the latter to use websockets, while the former uses the amqp protocol which is not http based. 
It's better than a runtime *woosh*
I'm glad they put the for loop in it's own package, back in the day, python 3 confused new learners. 
I keep a integer counter for new client IDs, a `Map ClientID TMQueue` for passing messages to the client, and a `Map ChannelID [ClientID]`: https://github.com/prikhi/hIRC/blob/master/server/Main.hs#L617-L632 I have a separate thread running a socket server, when a new client connects, I make the in/out TMQueues and simply encode/decode the messages as they go between the queues &amp; the socket connection: https://github.com/prikhi/hIRC/blob/master/server/Main.hs#L196-L199 Then when I need to send out a message to the clients in a channel, I lookup the ClientIDs subscribed to the channel &amp; insert the message into each clients queue: https://github.com/prikhi/hIRC/blob/master/server/Main.hs#L423-L430
I‚Äôm rather nervous posting here and asking this question. I‚Äôve read the posts here and everyone seems so knowledgeable. I want to learn to program in Haskell but my laptop is slow as a snail so my only option is using my IPad Pro 3rd gen (it was a gift). Has anyone had problems coding Haskell in IOS? Is that even possible.
Website: https://github.com/nh2/hatrace There will most likely also be a `hatrace` hacking session on ZuriHac.
Yes, I discuss eBPF at `1:32:52`: https://youtu.be/CZJghAptsEI?t=5572
That doesn't sound like a breakage to me.
That already exists. http://hackage.haskell.org/package/monoid-subclasses-0.4.6.1/docs/Data-Monoid-Instances-Measured.html 
I like this Python 5, when is it going to be released? I cannot find it in the repo
You are April fool
It's the only language I've found where I can build something that doesn't feel like a collection of disgusting hacks built on a layer of other disgusting hacks that I don't understand. Would be pretty cool if there were options for employment that didn't involve relocation or shitcoin startups, but while I wait and watch for that, I can at least build tools and side projects I can take some measure of pride in while I pay the bills with enterprise schlock.
&gt; coding Haskell in IOS https://www.reddit.com/r/haskell/comments/o9h39/why_programming_in_haskell_on_an_ipad_is_a_good/ https://itunes.apple.com/us/app/raskell/id783015132?mt=8 GL
That was a nice read! At some point you mention `liftA` but it doesn't seem explained, or is it assumed that the reader is aware `fmap` and `liftA` are the same? AFAICT the only purpose for `liftA` is to implement `fmap` from a standalone `Applicative` instance. From a theoretical perspective, the name `liftA`, next to `liftA2`, suggests the sequence `liftA0 = pure`, `liftA1 = liftA`, `liftA2`, `liftA3`, etc., which is pretty neat. In `base`, the `Applicative` instance for `Compose` is written using `liftA2 (liftA2 f)`, but I prefer `(liftA2 . liftA2) f`, because the pattern extends easily to more functors (and the `(.)` also relates to the idea that we are `Compose`-ing functors): liftA2 . liftA2 . liftA2 :: (a -&gt; b -&gt; c) -&gt; f (g (h a)) -&gt; f (g (h b)) -&gt; f (g (h c))
The more power you have as a programmer, the easier it is to write things at the local scale. It's why so many languages focus on maximum power to the programmer. Mandatory immutability makes it less convenient, and locally more annoying to write code. Plus I can tell you than in a typical Erlang app, you're doing a *lot* of state updates to the local view of the "gen\_whatever", broken up in an event-based manner that rather resembles Node code, only with more forced structure on you. Plus the syntax has the Haskell record syntax problem, but on steroids, and with no practical way do to lens or anything. Typically, the reason why you want to limit the programmer locally is so you can build better global structures. So, in Haskell, you've got mandatory immutability, and mandatory constrained effects, but in return you get the advantages of a nice separation of pure vs. effectful code and all the fun things we get to do with that. But Erlang doesn't really get those advantages. The only aspect of immutability it claims is with the strict read-only messages between Erlang processes, which it doesn't even need "immutability" for; Rust-style controls and the inability to send references would be fine. You don't get effect control. You don't get very nice syntax (Haskell is *much* cleaner than Erlang), you get a type system that from an /r/haskell perspective is actually *worse than Go's* (/r/haskell may still prefer Erlang because it has pattern matching, but the type system itself is still worse), you get a language that has some bizarre choices of what is and is not in a supervisor tree, you can't get laziness \[1\], and so on for quite a while. The limitations put into the local language don't contribute to the global features it offers, none of which truly involve immutability. It just has a klunky, limited local syntax for no reason. Brilliant, ahead-of-it-time runtime. Worth study. Not a great language when you're down in the trenches, though. When it was the only choice in its field, I paid that price willingly, but in 2019, I've got too many other choices that are better on other dimensions. \[1\]: Also weird for a "functional" language, it is impossible at the language level to have a "thunk" like Haskell has. You can have a concrete value, and you can have a function that returns a concrete value, but because everything's immutable and strict, you can't have a function that computes a value once and stores the result, returning it directly after that. You have to have a very expensive function before it's worth putting the necessary pieces together to make this work.
no way! I already found it and started programming my bubble sort. It works!
Great idea! :)
I encountered the same problem, which I solved using the Haskell-caf√© as an oracle: https://mail.haskell.org/pipermail/haskell-cafe/2018-June/129231.html With `u = newIORef 0`, `liftA2 (,) u u` is observationally distinct from `join (,) &lt;$&gt; u` (one gives you two reference, the other gives you the same twice, so you can distinguish them by mutating one reference and looking at the other). But `u *&gt; u` and `u` are undistinguishable. It's somewhat counterintuitive if you're used to thinking of a reference as a concrete memory location that needs to be allocated. But it comes down to the fact that there is no way to obtain much data about the reference itself (at most you can get booleans by comparing it with others), so if you discard it immediately, it might as well not have existed in the first place.
That is excellent feedback. I'll rework that part of the post so that it uses `fmap` instead and only mention `lift` at the end when I talk about base and hackage
Maybe tuning the RTS and buffing out the performance regression testing framework would make a good project: https://gitlab.haskell.org/ghc/ghc/issues/16499#note_190773 https://phabricator.haskell.org/D4679
I get where you are going with this. The amount of extra work `init` causes you to do when you traverse the result is `O(n)`. And thus the extra work to call `init` on an infinite list and print it is sort of ‚ÄúO(infinity)‚Äù which doesn‚Äôt even make sense as a concept, but it definitely does not hang, and it is very very misleading to say it does. The error in the analysis is that you are using a complete traversal of the result, which is often reasonable for finite structures, but very unreasonable for infinite structures. Unfortunately there is no simple universal asymptotic analysis I can think of for lazy/infinite structures, but one decent approach is to analyze the runtime in terms of how much of the resulting list you traverse, and how much extra work is done vs just the cost of traversal: ``` tail O(1) init xs(length m) = ys(traverse n) O(n) (n &lt; m) take n xs(length m) = ys(traverse p) O(p) (p &lt; min n m) ``` So then you would say `O(n)` for init on an infinite list instead. And `O(1)` for init on `Slist` so you would still get to demonstrate the lack of wasted computation without misleading anyone. 
The readme redirect doesn't work very well, it is not completely evident how to get there.
How does it not sound like breakage?
Honestly it's more of a Erlang rant than an answer to the question ‚Äúwhat price for immutability‚Äù. &gt; you can't have a function that computes a value once and stores the result, returning it directly after that Of course you can, `ets` ;-) And cannot have that in Haskell either, strictly speaking. 
Sounds me be like relevant changes to `bar` are still being propagated.
What is that clacking noise?
&gt;Honestly it's more of a Erlang rant than an answer to the question ‚Äúwhat price for immutability‚Äù. Well, what did you expect from a list of ways that Erlang fails to capitalize on the things it makes you pay the price for? &gt; Of course you can, ets &gt;&gt; You have to have a very expensive function before it's worth putting the necessary pieces together to make this work. That's a very expensive thunk. It may be worth it if you're saving a HTTP request, it isn't worth it in general. Haskell is actually made of thunks; almost everything is a function that computes its value once and returns it immediately after that. That's what the laziness is, under the hood. I'm not complaining that Erlang isn't lazy by default, I'm complaining that there's no good way to get that behavior at all. I can do it in Haskell, I can do it in any imperative language that supports closures... it's almost uniquely Erlang specifically that can't do this with any reasonable efficiency or user-friendliness.
The sound of static typing.
It‚Äôs the keyboard. Seems a step out of time though. 
Yes, you do.
Alright, I hope you will succeed in recording them all then :)
Thanks for the contribution! Always nice to see new, useful, data structures. :)
You added typing sounds just to make that joke, didn't you?
What do you mean? The changes to `bar` may or may not be propagated at some basically nondeterministic time in future. 
The relevant changes are when the sign changes. Those are propagated immediately.
But the ‚Äúirrelevant‚Äù changes are still propagated, just at some fairly random time subject to the optimizations implemented by the library author. That‚Äôs the most obviously buggy part.
Great job. Why would I use this over Configurator though?
Based on that representation, I wouldn't expect anything else, so no I don't consider it a bug.
Now that Guido is out of the picture, Python can finally make some real improvements!
\&gt; It's strange to hate I don't think "I find your type to be less composable than I'd like" means "I hate your work". The idea that criticizing something = hate is common these days but definitely not true in general and assumes a lot!
CAF?
&gt; I would say that it is a problem with lists generally, not particularly with this approach. Fair enough, generally we can't tell if a lazily generated list will ever end. However, I do feel this `Infinity` constructor makes it worse in some ways by introducing two different infinities and having the user worry about which one they're dealing with. Another way of doing this would be making the type strict in size (which is what I initially thought you were doing), which would make the set of representable values easier to understand, but it would also eliminate the possibility of streaming these lists (which is already a questionable activity, to be honest). &gt; the package user would never deal with the size directly I see. I have to say that wasn't clear to me. &gt; The "safe" here means that it won't hang unsafely Yeah, I understand. I still think that if a function called `reverse` doesn't always reverse, it's not a well-named (or well-thought-out) function.
The /u/Tysonzero's reply below gets to the crux of the issue. What he describes sounds like a much better way of dealing with infinite data structures than just declaring them "infinite-time". (otherwise we couldn't tell apart prime sieves of different time complexity)
That is already covered thanks to `fmap f u = pure f &lt;*&gt; u`. (Even if we were talking about monads, though, I wouldn't really mind saying "`join` is as good as `(&gt;&gt;=)`" -- I tend to see the `Functor` instance and `fmap` as part of the package; as background assumptions, so to say.) 
I had considered that, and I'm quite certain it is lawful, though I didn't write down the full proof yet. It certainly won't hurt to add it to the appendix of the post; thanks for the suggestion. 
What I found surprising about this example is that `filter` "knows" that it produces an infinite list. That could lead to some surprising results: ``` &gt; length $ take 42 $ filter false $ [1..10] 0 &gt; length $ take 42 $ filter false $ iterate (+1) 0 42 ```
I was looking for a new language to learn. I decided I wanted something functional; very different from the languages I was getting bored with (C variants, mostly, native, JVM, and CLR based). I was looking through wikipedia and read about *pure* functional, most notably at the time Clean and Haskell. I also wanted something with a standard, not just implementation-defined; not necessarily something with ISO-approval, just something that defined the language separate from on group of tools.[1] Clean either didn't have one or didn't have one I could find. Haskell had the 98 report. So, I started playing, and using it in all the online programming games/training/competition I could find time for. At the same time, H-M inference got me interested in type systems in a way all my past experience of types didn't. I started watch ICFP (and related conf.) videos, and I even attend ICFP has a "vacation" from work now. I actually don't do that much Haskell anymore. I do some playing around with Idris and Agda, but I'm hoping for a dependently typed systems language with a real specification to come out -- though sometimes I spend a little time toying around with what the design for such a language would look like myself (and there I might use some Haskell, because it has good LLVM bindings.) [1] I think my brain works different than most people. I really love a good EBNF paired with something like the JVM spec for learning a language. It's how I learned Java and C#, though not how I learned C. I want *exhaustive* detail on all the small parts, including how I'm allowed to snap them together -- examples aren't bad, but I find they are rarely exhaustive -- and from there I can some up with experiments and examples that will eventually develop in to a practice of programming. Even better if the exhaustive details are formatted in a way that's good for referencing later.
Well, my point was that you need `fmap` with `unit` and `fzip`, but not with `pure` and `(&lt;*&gt;)`. 
That's a nice gallery! A couple more entries: `ZipList`, and any representable applicative.
Oh, of course! Thanks; I'll soften the language of that comment a little bit to account for that. (Just a little bit, as in this context I feel it is fine to take the existence of a lawful `fmap` as a background assumption.)
Can you write FizzBuzz, quickly? Then you are better than a lot of programmers at their language of choice. Do you work in another language? If so, imagine a project you've worked on in in that language. Now, imagine you've been tasked with providing the same feature set, but you are *required* to use Haskell. Do you panic? Is there anything you'd need to learn how to do in Haskell? If no and no, you are ready (or at least confident enough). If no and yes, go learn. If yes and no, go practice. If yes and yes, go learn and practice. There's a number of sites like HackerRank and CodinGame and Cyber Dojo. Pick one, do some exercises, see if you can make middle of the pack. It's true the "programming in the large" is different than what you'd produce from one of these sites, I'm not sure it's a significantly different technical skill set. If doing these problems are beyond you, you probably need to skill up before applying for most Haskell jobs. "Soft" skills and being able to work with on a team are part of pretty much any professionals career these days, and programmers shouldn't ignore them, but I don't know a good way to measure them. Vastly superior technical skill *might* allow you to have poor soft skills, but I wouldn't count on it.
That's weird... I'm not getting any error when I try your code. The error is likely to be caused from something else you've done. If you're entering your code into GHCi, try creating a new GHCi session and re-entering your code; if this is part of a larger program, could you give us some more details?
Thats the whole program, I have to determine the persons desirability with the gender, poor(true or false) and age, and I have tried it on multiple sessions and I still get "Data constructor not in scope:"
Very interesting! I'd say this example further strengthens the case for spinning off this notion of a `(*&gt;)`/`(&lt;*&gt;)` asymmetry into a concept fully distinct from that of idempotency.
Well, it makes sense you're getting an error if you're doing `des F False 30`. `F` by itself is interpreted as a data constructor (like any identifier beginning with an uppercase letter), and since it's undefined, you get your error message. Try `des "F" False 30` (since `"F"` is a `[Char]`).
Try `des "F" False 30`; you need the quotes around F for it to be parsed as a string
Wow, lost an hour and a half for "", thank you so much!! Did not think that that would make a difference cuz it was going to read it as a char
You're welcome. For future reference: - `lowercaseIdentifier` is an identifier referring to a value (e.g. `let`-ed values, parameters etc.) - `UppercaseIdentifier` is a type name or data constructor - `'x'` is a single character (type `Char`) - `"xxxx"` is a list of characters (type `[Char]` or `String` - they're the same). Don't confuse `'x' :: Char` with `"x" :: Char`!
Cont? :-)
Of course he didn't
I LOVED the new logo, especially its colors
To get working on an existing codebase, you'd probably need to only go as far as Monad Transformers. Once you have those, the trunk seems to branch out and you can learn most of what you need piecemeal.
Constant Applicative Form‚Äîessentially a top-level value or where-clause binding that will be retained (as long as a module is loaded).
The readme is a soft link, GitHub does has the problem. Real file is in Salak subfolder. Thank you for your advice. By now I just provide a reloadAction, for manually call reload configurations. I can provide one detect SIGNUP.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/haskell_jobs] [Job - Bitnomial - Chicago, IL](https://www.reddit.com/r/haskell_jobs/comments/b8brov/job_bitnomial_chicago_il/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
`Reader` covers representables. `ZipList` is sort of like a representable tensored with a min-semilattice.
Nice shot, but not really. A counterexample: -- (*&amp;*) is curried fzip GHCi&gt; foo = cont (\k -&gt; foldMap k ["7","20","4"]) GHCi&gt; bar = cont (\k -&gt; foldMap k ["7","20","4"]) GHCi&gt; runCont (foo *&amp;* foo) (:[]) [("7","7"),("7","20"),("7","4"),("20","7"),("20","20"),("20","4"),("4","7"),("4","20"),("4","4")] GHCi&gt; runCont (dup &lt;$&gt; foo) (:[]) [("7","7"),("20","20"),("4","4")] FWIW: -- newtype wrapping omitted f &lt;$&gt; u = \k -&gt; u (\a -&gt; k (f a)) u *&amp;* v = \k -&gt; u (\a -&gt; v (\b -&gt; k (a, b)) u *&amp;* u = \k -&gt; u (\x -&gt; u (\y -&gt; k (x, y)) dup &lt;$&gt; u = \k -&gt; u (\x -&gt; k (dup x))
I read the configurator document, found some different things between salak and configurator. 1. configurator defined a special configuration format, while salak don‚Äôt have which is designed for supporting common configuration files like yaml, toml etc. Even can support Configurator‚Äôs format. 2. Configurator provide auto reload files with simple strategy. Salak now don‚Äôt have automatic reload functions. Just a manually reload action. I want to improve this by adding automatic reloading strategies, git pull configuration, or loading from configuration server. 3. Configurator provide a Configured type class for parsing config to destination type, it seems not provide tools like Aeson‚Äô FromJSON, to simplify instance implementations. And Value defined in Configurator cannot present arrays of complex type except bool, string and number. Configurator is a powerful package, but lacking supports for common configuration files, simple creating destination type without use many calls of lookup. Salak try to do it.
Do you have a picture of this menu? I have the same problem, everything builds fine with stack however I can't find the menu. I'm using Ubuntu 16.04 if that helps. Here's a screenshot of my editor: [https://i.imgur.com/FPvFjyv.png](https://i.imgur.com/FPvFjyv.png) 
I think you have it in your screenshot! Click on "default", it should pop up
Have you seen the example in the [docs](http://hackage.haskell.org/package/time-1.9.2/docs/Data-Time-Format.html) for `parseTimeM`? Prelude Data.Time&gt; parseTimeM True defaultTimeLocale "%Y-%-m-%-d" "2010-3-04" :: Maybe Day Just 2010-03-04 If so (or even if not), is there something in particular you're looking for beyond this?
nice!
This is insanely powerful. This captures so many use cases and is a wonderful abstraction over current manual techniques. Modern Haskell's toolset gets more incredible every day.
I have seen but I'm new to haskell, i would love some examples where this is implemented in. 
I have seen but I'm new to haskell, i would love some examples where this is implemented in. 
&gt; I'd like to write blog posts on topics I've struggled with to improve my understanding and to pass some hints and clues on to others. That's a very good strategy! Nice observation on the readability of those `(&lt;*&gt;)` implementations. In spite of my personal bias in favour of the `(&lt;$&gt;)`/`(&lt;*&gt;)` combo, I must admit the `liftA2` spelling is, in this specific case, much easier on the eye.
Top 10 pranks that went too far.
Until I realized the date today this post rendered my entire world foreign to me. On the brink of an episode I checked my calendar. I‚Äôve been had.
Yep, that worked! Thanks so much :)
 This PASHpost community corresponds to the Haskell-Beginners Mailing List on PASHpost. 
I'm curious to know where would find yourself using slist.
Hint, represent the gender as an ADT and use the power of having a type system.
Error 15, Access denied. From both my home network and workplace one.
Hard lesson I've learned over the years of asking questions and giving answers: Always test *precisely* the code you're about to post. As in copy paste from the reddit comment box into a file and try to use it :P Eliminates many "works on my machine" scenarios and can even illuminate the original problem.
Try linear typing for less distracting noises.
Funnily enough, data Gender = M | F would have solved his problem of writing F instead of "F"!
Frankly, it would be nice to see a bit more effort - being a beginner also means you need to try things for yourself! Play around with the functions in GHCi, show us what you've tried and where exactly you're having trouble, and people will happily help.
When the actual author gets downvoted to -3 for answering a question directly asked of them it's clear we've gone beyond peer review. What possible reason those downvotes?
I am generally a fan of such initiatives but adding another social thing to my existing list of social things for programming of - Gitter - IRC - Slack - Reddit (actually several subreddits) is a bit of a turnoff. I'm not sure how much fragmentation a community the size of Haskell's can realistically take.
There is also the relatively new Discourse community, which received the same criticism when it was announced here about a month ago...
Nice! Thanks for this. I've got a few places in my code where something like this would come in handy. Will give it a whirl. :o)
Not to mention several Haskell mailing lists, two(!) Discord Haskell communities, https://discourse.haskell.org/, https://stackoverflow.com/questions/tagged/haskell, ... 
Interesting, that one flew over my head.
Is there a reason things couldn't be moved to the already existing beginners@haskell.org mailing list?
&gt; Stop Member :: (* -&gt; *) -&gt; [* -&gt; *] -&gt; Constraint interface. This makes the API much less useful than mtl. You should really make the set of effects map-like. Can this be done without painful compile times and without sprinkling effect inclusion functions all over the place?
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/haskell_jp] [Statements on extensible effects](https://www.reddit.com/r/haskell_jp/comments/b8hwyo/statements_on_extensible_effects/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
Name checks out
I think your \`add\` function is a bad example of what you're trying to say since it would typecheck even without any functional dependencies.
The type of `runStateT` is a bug in the API as far as I'm concerned. `StateT m s a` is a functor in `a`, but `(a, s)` (the return type of `runStateT`) is a functor in `s`. This is clearly stupid.
&gt;for example nix doesn't seem to have any ways of running multiple PHP versions at the same time Wait, what? This has to me one of the least likely possible confluences of technologies
As the implementer of a [to-be-announced extensible effects package](https://github.com/isovector/polysemy), forgive me if I bristle on this one. --- &gt; The true utility of extensible effects would be to avoid implementing enormous instances of MonadIO, MonadReader, MonadState, etc when creating your monad, and providing instances for existing monad transformers when making a monadic interface. I strongly disagree. The "true utility" is having a low-boilerplate strategy for changing the interpretations of your effects. And that's OK, because we're all trying our best to find the optimal points in the design space. But IMO posts like yours come down like "I know better than you, so let's stop talking about it." &gt; Stop reimplementing effects: We have Refl(reader), Proxy(termination), Identity (coroutine), and various monads out of the standard libraries. What if those things have the wrong kind? What's wrong with reimplementing types? Especially if doing so gives the concept _a significantly better name?_ --- Your "advice to implementers" really rubs me the wrong way. I'm sure you meant to be helpful, but without providing context on why, or on links about how it should be done, your conclusion just reads aggressively. I am an implementer of an extensible effects package. It's as fast as MTL, supports higher-order effects, and has amortized O(0) boilerplate. Along all of these lines I think it is a serious competitor in the extensible effects space, but _I don't consider MTL to be a competitor._ I'm not concerned with giving MTL instances because those things significantly limit the utility I see in my package. All of this is to say that I am interested in what you're trying to say. I see that you're also the implementer of an effects package, and so I'm happy to learn from your experience. If you can provide insight into your claims, I'd love to hear it! I really want my package to be the definitive point in the design space, and I'll do as much work as possible to make that happen.
I happen to be a perfectionist (with the freedom to compromise should the need appear). And Hasell was the obvious "next step" in reaching towards that goal. I worked a lot on dynamic typing (Python, Clojure, Elixir), and also "run of the mill" statically typed languages (Go) - none of seemed "right" (they still had silly nil errors).
I got my Haskell job without even having used Monad Transformers (I remember even specifically mentioning this in the interview :-P). I think interest, willingness to learn and being able to demonstrate them (I had github projects) are more important.
I agree here. The post says GHC used to generate bad code for transformer stacks but is much better now. Couldn't the same thing happen to effects? It seems to me everyone else (e.g. Idris, Elm, etc.) have gone with effects so maybe there is something to explore there and we shouldn't just give up and accept MTL as the final answer?
Yeah you'd expect it to be easy, but the answer I got back then was to spawn a container per PHP version as a workaround. I don't know if that has changed since, admittedly it was a while ago
[Funny you should mention it.](https://gitlab.haskell.org/ghc/ghc/merge_requests/668)
thanks, do you have any examples of this as it's close to what I had in mind but wasn't able to convert my thinking to actual code :(
Sure! Once I get on my computer I'll post my code and what I've tried. 
How do you pronounce various operators? Some suggestions (I don't actually use all of these, but I think I might do if they came up): For some you can just describe the ascii - "dollar", "plus-plus", "colon-dot". For some there's a fairly obvious name based on semantics - `&lt;$&gt;` "fmap", `&lt;*&gt;` "apply", `&lt;&gt;` "append". (`&gt;&gt;=` "bind" is canonical; `=&lt;&lt;` could be "reverse bind" or "left bind".) Occasionally I suspect you can't do much better than "vaguely descriptive". In Servant, my colleague's suggested `:&lt;|&gt;` "gooseneck", and my brain is leaning towards `:&gt;` "peck".
\&gt; I strongly disagree. The "true utility" is having a low-boilerplate strategy for changing the interpretations of your effects. And that's OK, because we're all trying our best to find the optimal points in the design space. Well, I acknowledge that that's another important advantage, but I don't think you can negate the utility it provides by unnecessitating quadratic number of instances. &amp;#x200B; \&gt; What if those things have the wrong kind? What's wrong with reimplementing types? Especially if doing so gives the concept *a significantly better name?* If they have the wrong kind, it's totally fine to reimplement (I used to define Const' which is poly-kinded in the last parameter). If you want better names for stock effects, you should be able to use type synonyms. I didn't like extensible-effects, effin and freer's opaque effect primitives (extensible-effects improved in later version though). &amp;#x200B; \&gt; Along all of these lines I think it is a serious competitor in the extensible effects space, but *I don't consider MTL to be a competitor.* My criticism was about extensible effects advertised as an alternative to MTL. In fact most of the packages seem to be trying to be MTL-alternative. &amp;#x200B; \&gt; I'm not concerned with giving MTL instances because those things significantly limit the utility I see in my package. I'm curious to see how it limits the utility. My extensible effects library provides \[MTL-compatible instances\]([http://hackage.haskell.org/package/extensible-0.5/docs/Data-Extensible-Effect-Default.html](http://hackage.haskell.org/package/extensible-0.5/docs/Data-Extensible-Effect-Default.html) ) so that people can reuse actions in terms of mtl (e.g. lens's (%=) operator) and I see no downside to it (maybe except that arbitrary chosen effect names ("State", "Writer", etc) are reserved). &amp;#x200B; My main point is that people really should stop regarding extensible effects as a better MTL as the original paper advertises, unless it offers legitimately good performance and fundep/TypeFamilies equivalent of type inference. At the time I dust off extensible's Effect module, the performance was 2x better than the second (cf. [https://www.schoolofhaskell.com/user/fumieval/extensible/the-world-s-fastest-extensible-effects-framework](https://www.schoolofhaskell.com/user/fumieval/extensible/the-world-s-fastest-extensible-effects-framework) ) and offers type resolution better than mtl or any of the competitors (cf. [https://www.schoolofhaskell.com/user/fumieval/extensible/named-extensible-effects](https://www.schoolofhaskell.com/user/fumieval/extensible/named-extensible-effects)). I've used extensible in production but it turns out to be not so useful. It has eventually been replaced by ReaderT pattern. &amp;#x200B; I'm still hoping that extensible effects can be useful when it comes to designing a DSL that can't be expressed by a stack of transformers. IMO we need to explore more to make a better extensible effects library.
I've used \[extensible's effect module\]([http://hackage.haskell.org/package/extensible-0.5/docs/Data-Extensible-Effect.html](http://hackage.haskell.org/package/extensible-0.5/docs/Data-Extensible-Effect.html)) which offers map-like mechanism in production and compilation time has never been a problem. I think it's actually better than set because it only has to compare with type level strings. 
I guess it means that \`Member :: k -&gt; \[k\] -&gt; Constraint\` is worse than mtl without fundeps.
&gt; If they have the wrong kind, it's totally fine to reimplement That is much more nuanced than &gt; Stop reimplementing effects The original post reads like there is One True Way‚Ñ¢ of doing things, which is patently untrue, especially in a community such as Haskell. Potential implementors of extensible effects are not going to take easily three pieces of unsubstantiated advice. Such people are those who would want to know most about the various trade-offs are in detail, so that they can address their own needs (which may not be the same as yours).
`(&gt;&gt;&gt;) :: Category i =&gt; i a b -&gt; i b c -&gt; i a c` "cat", short for "con(cat)enation", but my real motivation is that more cats are good because cats are cute.
it's obviously a joke, but it perhaps actually would increase ~~lisp's~~ haskell's popularity
&gt; I don't think you can negate the utility it provides by unnecessitating quadratic number of instances. Absolutely, but that's only a point of concern because `mtl` is the status-quo. Imagine a world in which we already all used extensible effects, and someone introduced `mtl` saying "hey you guys look, I made this thing that requires O( n^2 ) instances." We'd all be up in arms! Relatedly: &gt; I'm curious to see how it limits the utility. Giving `mtl` instances means you need to adhere to their fundeps. Which means you can only ever have a single `State` effect. You can only ever have a single `Writer` effect. You can only ever have a single `Reader` effect. This is pretty commonly a stumbling block for programmers new to Haskell, who are told "oh you actually need to consolidate all of your state/environment/whatever into a single type to appease the `mtl` gods." It sort of works, but it leads to this [huge mess of problems](https://www.parsonsmatt.org/2018/11/03/trouble_with_typed_errors.html). There are solutions, but it's important to remember that these are treating the symptoms, not the causes. &gt; My main point is that people really should stop regarding extensible effects as a better MTL This sounds like a strawman. I've been one of the most vocal proponents of free(r) monads lately, and most people do indeed [rise up](https://www.reddit.com/r/haskell/comments/aq8kwd/freer_monads_more_better_programs_reasonably/ege8for/) to say "performance and type inference are really what counts." They say free monads are [overhyped](https://www.reddit.com/r/haskell/comments/aq8kwd/freer_monads_more_better_programs_reasonably/egf5df6/). They say the approach is [too complex](https://www.reddit.com/r/haskell/comments/aq8kwd/freer_monads_more_better_programs_reasonably/egg26tw/). None of them are necessarily wrong; they just have different design goals or past-bad-experiences than I do. And even as an apologist of extensible effects, [I've been quick to point out where `mtl` is better](https://reasonablypolymorphic.com/blog/freer-monads/) (search for "mtl" and/or "shit"). &gt; I've used extensible in production but it turns out to be not so useful. Why not? I've used `freer-simple` in production and it was fine. I'm curious what bit you --- maybe we can find a solution for the next time someone tries an extensible effect in prod.
I'd say this would be better on /r/haskellquestions, but I don't actually see a question, there. I could be wrong, but as far as I can see 3 (out of 4) of your issues actually don't have much, if anything, do to with Haskell.
But then how do you pronounce the `=^..^=` operator?
Previous discussion from last year is available [here](https://www.reddit.com/r/haskell/comments/877p53/applied_category_theory_online_course/).
&gt; As a side note I do not love how getting witherable into base would require a compiler upgrade even though it feels very much like a library-level change. That's actually a good reason to keep stuff *out* of base, but in something like the platform. `base` contains this that almost have to be implementation (compiler or whatever) specific, so *everything* in it is going to be have to be released/upgraded lock-step with your implementation. --- I'm clearly more biased toward efficiency than you, as I'd mostly prefer to do away with Foldable/Traversable/Witherable/Align and use the [EdisonAPI](http://hackage.haskell.org/package/EdisonAPI) and [EdisonCore](http://hackage.haskell.org/package/EdisonCore), with a few additions (lenses, indexed traversals, and recursion-schemes, oh my!)
brb finding a cat(egorical) concept that fits the notation.
Unless you are also accusing someone of using multiple accounts to amplify their vote value (which I believe can result in a site-wide ban), holding one person accountable for that actions of at least 3 (and probably 5 or more) people doesn't seem reasonable.
&gt; That's actually a good reason to keep stuff out of base, but in something like the platform. base contains this that almost have to be implementation (compiler or whatever) specific, so everything in it is going to be have to be released/upgraded lock-step with your implementation. Yeah I understand why it is the way it is. IMO `ghc` should only bake in something like `ghc-prim` and `base` should be strictly library level. One of the issues is all of the syntax sugar Haskell offers such as `do` and `guards` that implicitly use `Monad` / `Eq` etc. Something like `RebindableSyntax` could perhaps alleviate this, although I would prefer it to be done more Agda style (`{-# BUILTIN BOOL Bool #-}`) rather than just looking through the current scope for something with a matching name. &gt; I'm clearly more biased toward efficiency than you, as I'd mostly prefer to do away with Foldable/Traversable/Witherable/Align and use the EdisonAPI and EdisonCore, with a few additions (lenses, indexed traversals, and recursion-schemes, oh my!) Looking at `EdisonAPI` it doesn't seem to be all that different efficiency-wise then what I am suggesting. It implements indexing and rcons for lists for example, which is pretty much the main thing I was referring to with my mentions of functions with controversial performance. It's unclear to me what the value-add (performance-wise or otherwise) EdisonAPI would have over continuing to iterate on and improve the existing hierarchy. Ignoring things like it having classes that I have not listed, because I already mentioned in the OP that the above is incomplete but much better than the status quo.
For Old Reddit folks: `Foldable`: (!!) elemIndex elemIndices findIndex findIndices head intercalate (inner `[a]` becomes `Monoid m =&gt; m`) isInfixOf (questionable as it would ignore keys) isPrefixOf (questionable as it would ignore keys) isSubsequenceOf (questionable as it would ignore keys) isSuffixOf (questionable as it would ignore keys) last unlines (would break symmetry with `lines`) unwords (would break symmetry with `words`) `Functor`: unzip* (would break symmetry with `zip*`) `Traversable`: permutations (still ends up with one `[]`) reverse scanl1 scanr1 sort sortBy sortOn `Filterable`: filter partition `Witherable`: (\\) break delete deleteBy deleteFirstsBy dropWhile dropWhileEnd group (still ends up with one `[]`) groupBy (still ends up with one `[]`) init inits nub nubBy span splitAt stripPrefix (questionable as it would ignore keys) subsequences (still ends up with one `[]`) tail tails take takeWhile uncons deleteAt :: Witherable t =&gt; Int -&gt; t a -&gt; t a over :: Traversable t =&gt; Int -&gt; (a -&gt; a) -&gt; t a -&gt; t a set :: Traversable t =&gt; Int -&gt; a -&gt; t a -&gt; t a update :: Witherable t =&gt; Int -&gt; (a -&gt; Maybe a) -&gt; t a -&gt; t a
~~fixed~~ generalized ;)
http://hackage.haskell.org/package/sqlite-simple-0.4.16.0/docs/Database-SQLite-Simple.html The section on named parameters seems to cover your select problem reasonably well. r &lt;- queryNamed c "SELECT id,text FROM posts WHERE id = :id AND date &gt;= :date" [":id" := postId, ":date" := afterDate] It's just a normal prepared statement. For foreign keys, I thought it was relatively standard practice to call your keys `fk_resource` or `fk_thistable_thattable`, which should help you avoid naming conflicts in your records. `Query` is just a `Text` newtype, so you could construct one using any of the usual `Text` machinery and some un/wrapping. It looks like they made this intentionally hard so injections are harder to introduce. You can use prepared statements (as in the example from the docs) or just write a normal query to select particular columns. Write the join the way you normally would in SQLite. SELECT a1, a2, b1, b2 FROM A INNER JOIN B on B.f = A.f; Supposing you want to print out all the rows of that query, you'd have something like conn &lt;- open "ab.db" r &lt;- query conn "SELECT a1,a1,b1,b2 FROM A INNER JOIN B on B.f = A.f" mapM_ print r Note, however, that if the result set is large, you may want to use [fold](http://hackage.haskell.org/package/sqlite-simple-0.4.16.0/docs/Database-SQLite-Simple.html#v:fold) (which is kind of underdocumented unless you read types a lot, so I found [this example on SO](https://stackoverflow.com/questions/17891288/haskell-sqlite-simple-fold-io)).
Your second problem is solved by DuplicateRecordFields extension. Just put {-# LANGUAGE DupliilateRecordFields #--} on top of your file and you should be good. Third one is the hard one. Haskell doesn't have ad-hoc record types, so basically you have to define a different type for each of your queries. Maybe more generic solution can be built with something like superrecord library, but that's not for faint at heart. I don't have any experience with sqlite-simple, so I can't help you with problems 1 and 4. For joins I've succesfully used beam library, but it is using some advanced language features and I wouldn't recommend it for beginner. Generaly RDBMS integration in Haskell is not as good as in mainstream languages. Just the number of competing librsries indicates that people are still searching for "correct" way to do this.
I don't see how this contributes anything to the discussion. In Python, I could be operational in less than 20 minutes, I've been trying to figure this out in Haskell for a week. So this is very related to Haskell...
Thank you, that convention is helpful for foreign keys! How is the data returned on an inner join? If you have two record types that contain your columns, how does query return those?
That's a nice extension, I'll take a look at that!
I found a blog post with an example of a join: http://www.mchaver.com/posts/2017-06-28-sqlite-simple.html It looks like you have to make a type to represent the joined data and write To/FromRow instances. As the post mentions, this is quite a bit of boilerplate, which is probably to be expected for a library billing itself as ‚Äúmid-level‚Äù. The blog post mentions some other, higher-level libraries that likely have a nicer story for joins. Persistent + Esqueleto seems like a popular combination, but I haven't used either.
Throw in [these](http://hackage.haskell.org/package/these) as well, it contains useful typeclasses for zipping and aligning. Shame about the heavy dependency footprint. [monoid-subclasses](http://hackage.haskell.org/package/monoid-subclasses) as well. 
You're the man, I really appreciate the help
You appear to be answering somebody else's post. Mine asked for a reason why anyone would do that.
I would suggest using a database library that is designed to be convenient, like [`persistent`](https://www.yesodweb.com/book/persistent), which is rather well documented and has many tutorials. I'm a maintainer on this project and would be happy to help with getting you up and running :)
The way you worded your comment, it sounds like you were asking eacameron to explain a the "-3" points on a single comment. And, eacameron would only be accountable for, at most, -1/+1 of that total.
Ah I see what this is about. I was mistakenly thinking that meant to stop using type classes for membership constraints altogether and instead use more concrete data structures.
I don't think speed has ever been understood as a motivator for these effects libraries. It's one of the most well-known challenges to implementation.
[https://jobs.swisscom.ch/professionals/offene-stellen/attribute-10/software-engineer/aa62179f-8f2f-4768-a2d7-2f89e877782a](https://jobs.swisscom.ch/professionals/offene-stellen/attribute-10/software-engineer/aa62179f-8f2f-4768-a2d7-2f89e877782a)
`these` is very cool and I have enjoyed using it in the past, I omitted it largely because it doesn't seem to directly replace any of `Data.List`, but I do support it becoming defacto-standard for interacting with containers. The heavy footprint is a shame but it is understandable, as it defines the `These` type and the various instances for it do need to go somewhere. We really need to figure out a long term solution to the orphans problem. `monoid-subclasses` seems like a very cool library. There is a lot of overlap between a lot of the above functions and the functions in that library, it would be interesting to investigate the relations between the classes that have overlap, whether one is perhaps a subclass of the other (via `QuantifiedConstraints`). There are some small things I don't love like how it seems like perf requirements are a part of the laws of some of the classes, especially since they seem to mention a concept of "length" which `Monoid` doesn't actually have. I also don't love that there are laws that only appear if a type is an instance of another class, adding a new instance of a typeclass should never cause previously valid instances to become invalid.
Looks like you have a typo: DupliilateRecordFields
&gt; I would suggest using a database library that is designed to be convenient, like persistent, which is rather well documented and has many tutorials. I would second this recommendation.
Someone may correct me, but I believe Compactable just straight up generalizes Witherable ?
I personally dislike `Compactable`. I don't like the way it's laws are set up, with a bunch of `if instance blah then X` statements but zero real laws.
Sorry, I don't follow. The docs for functor in prelude read "...If f is also a monad, then the following laws should also apply" &lt;- isn't this the same? (I'm assuming that "should" was written because it would be otherwise possible to define lawful Functor, Monad instances without the laws holding)
 (&gt;=&gt;) - fish (&gt;&gt;=) - bind (&gt;&gt;) - then (:) - cons (&lt;$&gt;) - fmap (&lt;*&gt;) - ap, apply, or spaceship (&lt;&gt;) or (++) - append (&lt;|&gt;) - or (or maybe alt if I also use (||) somewhere (.) - dot (though I never say this one out loud, since composition is so fundamental) ... and all the lens things that have names I'm really stumped by what to call `(&amp;)`, though. I don't call `($)` anything, either, though maybe `id` to be cheeky, so `(&amp;)` can be `di`. Similarly, `(=&lt;&lt;)` is clearly dnib.
So I'm not a huge fan of that wording because on the surface it does seem to imply the same problematic situation. But the key difference is the subclass relation avoiding any actual need for an "if" or for allowing new instances to invalidate existing ones. If that doc was simply moved into the Monad section you could remove the need for the problematic "if" statement. In fact those laws actually already exist in the `Monad` section, so the docs you say there are actually redundant and don't imply anything new. Outside of Prelude what I see is laws in `Applicative` / `Monad` that specify the laws that must hold that relate to `Functor` / `Applicative` respectively. But that is completely different, because this isn't `if instance blah then X`, this is `X -- this law type-checks because instance blah is a superclass`. There is no "if" statement and there is no possibility of having a new instance invalidate an existing instance.
The related operator `.^^.` is pronounced ‚ÄúOhio‚Äù because it's round on the ends and high in the middle.
Oh, so `=^..^=` is "equivalent modulo boring state". `.^^.` = Ohio; Ohio is a boring state; `^..^` is the opposite of `^..^`; `^..^` means lacking a boring state. So, `=^..^=` which is `^..^` stuck in the middle of `==` (equals); therefore `=^..^=` is equivalent without considering boring state. /s ;) Keep rockin', Ohio.
See my `fin` library for a bit different approach, I don't have commutativity proof, but I do have `n + 0 = 0` one: [http://hackage.haskell.org/package/fin-0.0.1/docs/src/Data-Type-Nat.html#proofPlusNZero](http://hackage.haskell.org/package/fin-0.0.1/docs/src/Data-Type-Nat.html#proofPlusNZero) Using [`induction`](http://hackage.haskell.org/package/fin-0.0.1/docs/Data-Type-Nat.html#g:6) the induction hypothesis newtype ProofPlusNZero n = ProofPlusNZero { getProofPlusNZero :: Plus n Nat0 :~: n } the proof of base (`Refl`) and step step :: forall m. ProofPlusNZero m -&gt; ProofPlusNZero ('S m) step (ProofPlusNZero Refl) = ProofPlusNZero Refl are all clearly there. My high school teacher would been proud :) Note, that this is not only a theoretical exercise. In `vec` package, many functions are implemented using (a variant of) `induction`. Click *Source* in http://hackage.haskell.org/package/vec-0.1/docs/Data-Vec-Lazy-Inline.html, e.g. source of [`map`](http://hackage.haskell.org/package/vec-0.1/docs/src/Data-Vec-Lazy-Inline.html#map)
I would like to have this *somewhere* as an importable module. But it would be quite annoying to have it as the regular definitions, since you'd too often end up with things that compile which shouldn't have, or error messages about missing instances that make little sense.
I'm not sure how I feel about the way it has functions that add constraints to the type the instance is over. On the one hand, that's a clever way to allow overriding the implementation of generalized functions. On the other hand, it means that upstream can break your instance with changes that would ordinarily be considered non-breaking. I think I'd consider the latter to be more important than the former.
&gt;Giving instances means you need to adhere to their fundeps MTL without fundeps is really, really awkward. It's there for a reason. Most effect implementations do not offer anything better in this regard; they even disallow polymorphic type parameter in effects. Well, you could put two states for example, but only when their concrete types are different, unless they introduce map-like mechanism. You can't reasonably expect the typechecker to resolve whether `tell 42` is Writer Int or Writer Double. You should check out [my article about named extensible effects](https://www.schoolofhaskell.com/user/fumieval/extensible/named-extensible-effects); I think this is how it should be done. &gt;This sounds like a strawman. I've been one of the most vocal proponents of free(r) monads lately, and most people do indeed [rise up](https://www.reddit.com/r/haskell/comments/aq8kwd/freer_monads_more_better_programs_reasonably/ege8for/) to say "performance and type inference are really what counts." They say free monads are [overhyped](https://www.reddit.com/r/haskell/comments/aq8kwd/freer_monads_more_better_programs_reasonably/egf5df6/). They say the approach is [too complex](https://www.reddit.com/r/haskell/comments/aq8kwd/freer_monads_more_better_programs_reasonably/egg26tw/). Maybe people here are more realistic. In Japanese community around me, a lot of people have been convinced that extensible effect is a good alternative to MTL a few years ago. &gt;Why not? I've used freer-simple in production and it was fine. Mostly because it's slow and has poor exception handling. Maybe capability works better.
Finally I can recommend Haskell to all my JavaScript friends!
This issue with it being an importable module is that, as I mentioned in the OP, many of these functions need to be in the class themselves for optimization. Also it seems like half of Data.List is already generalized, so stopping half way to preserve certain aspects of the remaining half seems very weird. I would personally prefer something like the following (ignoring backwards compatibility for a sec): `Data.Foldable`/Traversable` etc: all the above generalized and maybe in the class `Data.List`: basically just the type and functions that have not yet been generalized `Data.List.Utils`: plenty of monomorphic functions, used by `Data.List` / third parties to define instances. `Prelude` (assuming we insist of having one at all): I would prefer to have either just the generalized version or neither. 
https://github.com/azimuth-project/applied-category-theory-course
The classes themselves can be in a separate module was my point.
Wait what now? Can you elaborate? The classes already exist and are already in `Data.Foldable`/`Data.Traversable` etc. and are re-exported by the prelude. I am proposing adding more functions to these classes and to the modules as well.
Oh right. I was only thinking about Filterable and Witherable. Still, you can re-export a class without all of its methods. module A where class Foo a where foo :: a bar :: a -&gt; a -&gt; a module B (Foo (foo)) where import Foo module C where import B works :: Foo a =&gt; a works = foo breaks :: Foo a =&gt; a -&gt; a -&gt; a breaks = bar `breaks` will fail to compile because `bar` isn't in scope, but `Foo` and `foo` are, so `works` will successfully compile. So my suggestion is to add the new methods to the classes, which are in other modules, but not export them from prelude, instead requiring the user to import something else. The `Foldable` and `Traversable` classes could be moved to `Data.Foldable.Class` etc. and `Data.Foldable` could export only the old methods in order to not break existing code.
Nice work! I also noticed that you are using `tomland` for `salak-toml`. As one of the maintainers, I'm happy to see it and hope it was pleasant to work with the library :)
I wouldn't call it a bug or stupid. Some arbitrary choice I'd say. It's fine as long as it's not meant as transformer-replacement.
Welcome to the Haskell community :)
Why would it break existing code? People shouldn't be open importing modules like `Data.Foldable` unqualified, and if they really want to they should be following PVP and depending on base-X.Y.Z, thus incrementing Z will avoid any overly problematic breakage. I'm hoping no one is expecting `Data.Foldable` and the like to be "locked" from adding new functions that may or may not collide with existing functions. I would hate to have these powerful generalized methods relegated as far down as `Data.Foldable.Class`. I can understand putting them in `Data.Foldable` and leaving `Prelude` alone as much as possible. I really would like to see more containers treated as first class citizens instead of just `[]`, and I do think adjusting `Prelude` could help with that. I think a great way to make that happen is pushing good abstractions and classes into easily accessible places like `Data.Foldable`, and sliding overly monomorphic functions a little bit further away into `Data.List.Utils` and the like.
For the most part I agree that adding new symbols shouldn't be considered breaking. But when those symbols are already in use by other things, it gets much harrier. For instance, adding `&lt;&gt;` to `Prelude` ended up breaking *a lot* of builds because the name was so commonly stolen by other packages. But this is an order of magnitude worse than taking names that are already in `Prelude` and likely to be in widespread use. I guarantee that adding a different `unlines` to `Data.Foldable` would break a lot of builds because the regular function is very commonly used.
IMO we shouldn't be holding back progress because of people who refuse to follow the expectations of Hackage / PVP. Also adding to `Prelude` is a fairly different situation, modules that are explicitly expected to be open imported (very few, but `Prelude` is one of them) should be much more reluctant to add new names, and such additions should be considered a breaking change, incrementing `A.B` rather than just `A.B.C`.
Thanks Robert! I'm planning to update the article this week and mention the users that drove the changes üëç
A generally agree with the whole Hackage / PVP thing, and in a perfect world people would qualify their imports. But that *drastically* more common than any other PVP violation, both because a lot of people don't really know about it, and because the language and tutorials all give you the idea that open imports are fine. This is a case where there's an obvious and simple solution that doesn't really compromise on much which avoids a practical problem.
What's the obvious and simple solution? Because the `Data.Foldable.Class` thing is gross, then when people get used to it and we want to do something like this again do we have to move to `Data.Foldable.Class.Extra`, and so on.
You only have to do it once. After that, additional functions become just like any normal new symbol; i.e. they won't conflict with prelude because this module will already be treated as conflicting with prelude, just like e.g. Data.Map.
So long term we end up with list functions easily usable and `F.blah` for interacting with literally every other type in existence, great. I really don't think keeping everything in `Prelude` specialized to `[]` forever is the move. I mean seriously `!!` for positional indexing which `[]` isn't even good at forever specialized to `[]`? It's also worth noting that a lot of these don't conflict with `Prelude`, and those ones should absolutely just be put in `Data.Foldable` even if they conflict with `Data.List`.
I think you're making this out to be a greater problem than it is. Don't let perfect be the enemy of good. It's not really a big deal if we have list functions in Prelude and generic functions elsewhere, and it's an easy way to minimize the shock of the change. If it comes to it, we can migrate later and replace the list functions with the generic functions if it turns out people like them well enough. But all at once switching to a completely new set of definitions for a great many popular functions is a dangerous choice for more reasons than just namespacing. Gradual and cautious is the right move for Prelude at this time.
I mean I'm not advocating touching the `Prelude` or `Data.List` or "switching". I just want to play with `Data.Foldable` and add new functions to it. What percentage of libraries are actually importing `Data.Foldable` unqualified and also importing and using a `Data.List` function or a `Prelude` function that conflicts with one of the above I am suggesting generalizing? What percentage of those libraries are actually using an overly liberal `base` bound such that the above would be cause problems, also I'm open to making it a `A.B` change if `A.B.C` would be too problematic.
I think you've got a bit too much faith in humanity :P My perspective is that there are a *lot* of packages that would break if these duplicate names are introduced. The choices are to either upgrade them generally to the new versions, or gate the new versions behind a new import. Anything else breaks stuff for people who haven't been diligent. The former is much more attractive than the middle ground of upgrading Data.Foldable without changing the functions in Prelude, and the latter is more attractive than either of those because it lets us proceed gradually.
Isn't there a way to test this kind of breakage? Also is it possible to add in a weird sort of "deprecation" of open importing `Data.Foldable`. I mean ideally we would have some sort of `INCOMING` pragma, which is basically like `DEPRECATED` but it gives out a warning if the `INCOMING` name conflicts with something else you have defined. That would solve all these issues.
&gt; Isn't there a way to test this kind of breakage? It should be possible to write such a tool. Could take a couple days, so I'm not interested in pursuing the work :P &gt; Also is it possible to add in a weird sort of "deprecation" of open importing Data.Foldable. Not to my knowledge. &gt; I mean ideally we would have some sort of INCOMING pragma, which is basically like DEPRECATED but it gives out a warning if the INCOMING name conflicts with something else you have defined. That would solve all these issues. That's a pretty cool idea. I wouldn't be opposed to seeing something like this added to GHC. I'd actually really like to see much more highly programmable warnings from packages. Something like TH but for warning analysis. That'd make it trivial to create a library for doing this kind of INCOMING thing.
&gt; It should be possible to write such a tool. Could take a couple days, so I'm not interested in pursuing the work :P Hmm fair, don't people do analysis of hackage in various ways all the time? I feel like I hear about this kind of thing a lot. &gt; I'd actually really like to see much more highly programmable warnings from packages. Yeah that would definitely be quite cool. As much as I love how fantastic programming Haskell is with just a simple text editor like vim, I think that fundamentally a lot of things are much better done through language-aware tools. For example uploading a dependency with a tool that can more or less guarantee lack of breakage, or at least flag situations where breakage appears unavoidable. Simple things like naming conflicts and renames of functions and so on would be pretty trivial to deal with though.
All I can say is it must have changed lately.
Yea I'm pretty sure that there's some system that could be invented that would guarantee no breaking changes as long as any breaking change was accompanied by a change in types or names. It'd involve tracking the versions of packages that packages are good with etc and automatically adapting APIs of packages on the fly in the compiler to adapt to the history, but I think it could be done. Of course this is way outside the realm of reasonable changes to GHC at this point.
Ideally even implementation-only changes could be tracked in some way, such as changing of internals being assumed to be breaking unless the tool can verify otherwise (chasing renames around to see that its a strictly rename change, or a developer assertion). Yeah I realize GHC itself wouldn't implement it, but external tools could be developed for such tasks.
Unless I'm missing something, "If they have the wrong kind, it's totally fine to reimplement" is like saying nothing at this point. Now that most datatypes in base are poly-kinded whenever possible, it doesn't matter.
Thanks! Fixed
For third problem again: you can always use tuples as ad-hoc records, but then you don't have field names, only positions.
Great!
This is just being considered for implementation in GHCHS: https://github.com/ghcjs/ghcjs/issues/743 
($) : Application operator (&amp;) : flipped Application Operator ?
"Perfectionnism" is a subjective and relative notion..., sometimes it's just a judgement to say you want to do more than the others around you :-) 
You don't need to create as many custom types as it might look like. E.g. if you have a type `Foo` that you populate with three columns, and a type `Bar` that you populate with four, and you select seven columns to try to create a `Foo` and a `Bar`. You can create a `FooBar` type and do something like ```haskell fooBars :: [FooBar] &lt;- query ... ``` and use some deconstructing `FooBar -&gt; (Foo, Bar)` function. But you can also just use the supplied `:.` data constructor, like ```haskell fooBars :: [Foo :. Bar] &lt;- query ... ``` And then deconstruct them with the function `\(f :. b) -&gt; (f, b)`. (At any rate, this is how it works in postgresql-simple. From my brief glance at sqlite-simple, I think that should be the same.)
Yes, and let's not mention the Python 4 debacle with the failed attempts at implementing proper Unicode support. Fortunately they came to their senses and put that in a library as well.
How do you guarantee that things get inlined? 
Newtype constructors are optimized away at compile time. You can still target them with `coerce` from `Data.Coerce`, which was made in part for this use case (see the great paper "Safe zero-cost coercion for Haskell" from Breitner et al. , Section 6.5 ).
[removed]
Is anyone actually able to sign up for this? Whenever I try to register I just get the error message "Please re-read Terms of Service", which I have done...
Is this running again? It looks like this post is from March 2018
Check out this \[categorical database thing\]([http://catinf.com/](http://catinf.com/)).
How do you go about managing directory structure for an API to maintain scalability? I'm unsure which of the following (or one another way entirely) is best. Having specific directory for each domain like a directory named `Api/User` containing `Models.hs` `Mtl.hs` `Email.hs` etc Or having specific directory for each set of functionality like multiple directories `Models/User.hs` `Mtl/User.hs` `Email/Email.hs` etc
Monadic stacks are a mess. neither MTL neither extensible effects solve the problems. The workflow of creating stacks as onion layers one on top of the other by using runners and lifters is the best way to destroy composability of effects and the best recipe for ruining the usefulness of funcional programming for real world problems as well as the assurance that nobody would try Haskell for their programming problems. So congratulations, you sucessfully avoided success at a high cost for 20+ years. Is time to try something different.
oh, I was under the impression it was an on-going thing.
I believe another session is commencing. 
I believe another session is commencing. 
As I understand your question is that you want to perform action with database, which imply talking to IO device whether it is RDMS or simple file or document DB - any kind of data storage- knowing we will know that we are having side effect by talking to the world outside. Also having effectual computation would change the signature of our functions so instead of having a function \`item:: Int -&gt; Item\` our computation will be a function that do effectual computation and return an data of type item \`item:: Int -&gt; IO Item\`. &amp;#x200B; However, IO is a monad and it is a concrete monad, so for testability issue I would like to make things more abstract so instead of dealing with monad of type \`IO Item\` we can deal with \`m Item\` on a condition that our \`m\` is monad instance. so type classes would help us with this concept: &amp;#x200B; class (Monad m) =&gt; Database m where item :: Int -&gt; m Item &amp;#x200B; then we have a type class that have a \`item\` that perform some monadic computation and return an \`Item\`. &amp;#x200B; then what we have to do is we can use this function in our Haskell code base without having to implement it. for implementation we can create a function such &amp;#x200B; getItem ::(MonadIO m,MonadReader r m,IConnection r) =&gt; Int -&gt; m Item getItem = do conn &lt;- ask articles &lt;- liftIO $ getItemQuery conn ..... return Item &amp;#x200B; however, the function \`getItemQuery\` is a plain SQL query written using \`Database.YeshQL\` &amp;#x200B; for more information how to use it in practice you may have a look at real world scenario I have already used in a tiny project [sql functions](https://github.com/kwaleko/blog-post/blob/master/src/Adapter/Sqlite.hs) and [queries](https://github.com/kwaleko/blog-post/blob/master/src/Adapter/SQL.hs) then after having done the above we can be able to link both the implementation and the abstract declaration together in order to achieve the mission. &amp;#x200B; &amp;#x200B; &amp;#x200B; &amp;#x200B; &amp;#x200B;
See [http://hackage.haskell.org/package/fin-0.0.1/docs/Data-Type-Nat.html#t:InlineInduction](http://hackage.haskell.org/package/fin-0.0.1/docs/Data-Type-Nat.html#t:InlineInduction)
This one can be fixed by using `-XDuplicateI`
Actually this is the function I'm asking about. I got the impression that using this function to implement something (like the \`unfoldedFix\` below) somehow guarantees that the implementation is inlined.
Best part is Section 7: Unacknowledgements
The code Output is: `send 1` `send 2` `send 3` `Example.hs: thread blocked indefinitely in an MVar operation` &amp;#x200B;
I think what is going on here is different? The problem is that the introduction of the \`cast\` function seems to happen inbetween my rewrite rules, which prevents one of them from firing. Did I misunderstand what you mean?
This is my first time ever writing up a tutorial like this. Any and all feedback is greatly appreciated!
Just a guess, but your code only runs `takeMVar` once, and then the forked thread dies, so the main thread blocks waiting for the `MVar` to be cleared a second time. Maybe stick the child body inside `forever`? ```haskell sendMessageFromMVar mVar = do forkIO $ runTCPClient (clientSettings 4001 "*") (\app -&gt; forever $ do strMessage &lt;- takeMVar mVar runConduit (yield (BS.pack strMessage) .| appSink app) ) return () ```
I've written a small engine in Brick as well the problem though that put it on hold was that Brick doesn't have a Windows back end. &amp;#x200B; I've been tempted to take up the torch and build one but with my current situation I don't have the means to acquire a computer that can A: Compile a significant Haskell program that could B: Run on Windows. &amp;#x200B; Otherwise Haskell is a fantastic language for roguelike development. There are good A\* libraries out there, state machine libraries to build/test AI, etc.
I've built a small engine with Brick and a few other Haskell libraries cobbled together for pathfinding, AI, etc. &amp;#x200B; Haskell is a fantastic language for building roguelikes in! &amp;#x200B; There was one problem that stopped me from taking my game further and that was a lack of Windows support in Brick. I've been tempted to take up the torch on this one and contribute a back end but I'm severely limited in my access to computers that can A: compile a significant Haskell program and B: Could run a modern version of Windows.
Perhaps you'd like something more like a Haskell DSL that will handle most of this for you. I'll shamelessly promote my [own package, beam](https://github.com/tathougies/beam/) &gt; The packages are not well documented, [Here you go](http://tathougies.github.io/beam/)
Between those two, I'd generally go for the former to avoid short name collisions. But, I think either can work as long as it's easy to avoid introducing dependency cycles.
Oh sorry, I read your code and replied too quickly. `cast` seems to be only a type operator form GHC's core, I don't know if it prevents any rule to fire.
Thanks for writing this! This will be a very valuable resource for me.
Nice post! However I'd suggest not adding "with Stack" to each of your blogposts as there was nothing Stack specific in your tutorial. And it's just as easy to cover both Stack and Cabal if you use Haskell's native .cabal format which is supported by all build tools: library hs-source-dirs: src c-sources: src/fun.c 
I'd love to watch this video, but unfortunately the content is locked behind an account creation wall. Anyone have a link to the content hosted on a platform where individual's can access the information freely, like YouTube.
How do I find a girlfriend?
Unfortunately, this is the case with most (all?) Skills Matter videos. If it is any consolation, I think you can sign up using your GitHub login.
I'm not sure I follow; what do you mean by "it"? If you're asking why Python sets SIGPIPE to SIG_IGN, then this link https://docs.python.org/3/library/signal.html says "SIGPIPE is ignored (so write errors on pipes and sockets can be reported as ordinary Python exceptions)". I don't think it's related to the GIL. HTH
I guess that might be acceptable for some, but it's a hard pass from me.
I was able to
John Baez is a very engaging mathematician from a technical perspective and quite friendly. I would recommend joining anything he does - there's bound to be loads of insight gained.
https://www.wikihow.com/Get-a-Girlfriend seems to be an okay guide, though I'm not sure I really like the term "friendzone". Might also be some good answers [elsewhere on reddit](https://www.reddit.com/r/NoStupidQuestions/comments/7q05cg/how_do_i_get_a_girlfriend/).
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/haskell_jp] [hackage downtime.](https://www.reddit.com/r/haskell_jp/comments/b99gwr/hackage_downtime/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
&gt; we quickly found that our use of the ‚Äúfast-forward only‚Äù merge strategy (necessary to preserve bisectability) This was new to me. Isn't git-bisect able to inspect merged branches if it finds a merge commit? (Or did I misunderstand what this means?)
I didn't even notice Hackage was down when using `cabal update` as it completed quickly as usual: &gt; cabal update &gt; &gt; Warning: The update command is a part of the legacy v1 style of cabal usage. &gt; &gt; Please switch to using either the new project style and the new-update command &gt; or the legacy v1-update alias as new-style projects will become the default in &gt; the next version of cabal-install. Please file a bug if you cannot replicate a &gt; working v1- use case with the new-style commands. &gt; &gt; For more information, see: https://wiki.haskell.org/Cabal/NewBuild &gt; &gt; Downloading the latest package list from hackage.haskell.org &gt; To revert to previous state run: &gt; &gt; cabal update --index-state='2019-04-04T03:41:19Z' &gt; Only when I run `cabal v1-update -v` I notice a fallback to the mirrors is happening via &gt; Downloading the latest package list from hackage.haskell.org &gt; Selected mirror http://hackage.haskell.org/ &gt; Downloading timestamp &gt; &gt; /usr/bin/curl 'http://hackage.haskell.org/timestamp.json' --output /tmp/transportAdapterGet10252-1 --location --write-out '%{http_code}' --user-agent 'cabal-install/2.4.1.0 (linux; x86_64)' --silent --show-error --dump-header /tmp/curl-headers10252-2.txt --header 'Cache-Control: no-transform' &gt; &gt; Exception Unexpected response 502 for http://hackage.haskell.org/timestamp.json &gt; when using mirror http://hackage.haskell.org/ &gt; Selected mirror http://hackage.fpcomplete.com/ &gt; Downloading timestamp &gt; &gt; /usr/bin/curl 'http://hackage.fpcomplete.com/timestamp.json' --output /tmp/transportAdapterGet10252-4 --location --write-out '%{http_code}' --user-agent 'cabal-install/2.4.1.0 (linux; x86_64)' --silent --show-error --dump-header /tmp/curl-headers10252-5.txt --header 'Cache-Control: no-transform' &gt; To revert to previous state run: &gt; &gt; cabal update --index-state='2019-04-04T03:41:19Z' Would it make sense to have `cabal update` emit a notice when it falls back to a Hackage mirror automatically? Or is this intentionally hidden from users?
Stil, nothing related to the javascript problem
Thanks for taking the time to read this! Is the stack.yaml config file exclusive to using stack? I could never get the `extra-include-dirs` field to work in either project.yaml or the .cabal file, it only worked in stack.yaml. Admittedly I have basically no experience with using Cabal as a build tool.
That's great to hear- glad I can help.
The posts in this community were migrated from the corresponding community on Google+, which I founded and which went out of service when Google+ itself went out of service on April 2. Migrating all the posts to the [beginners@haskell.org](mailto:beginners@haskell.org) mailing list would have flooded the mailing list; conversely, leaving them to perish would have lost them, potentially forever. Hence, I migrated them to a new home here.
The what problem?
try to seek for High Cohesion and Low Coupling...
If you want to bisect between A and B, and there's a merge conflict in between, some of the commits git will show you will be from the merged branch. i.e. A---M---B X--/ if you bisect from A to B, you'll see commit X, which will often be unhelpful. I've seen on SO a way to mark all off-spine parents of merge commits as good, but I don't remember it.
&gt; I could never get the extra-include-dirs field to work in either `project.yaml` or the .cabal file, it only worked in stack.yaml. One thing that's helpful to know is that Stack is powered by Cabal underneath. But unfortunately Stack makes things unnecessarily to confusing to newcomers by trying to hide this by suggesting users to use a slightly different dialect (`package.yaml`) which is then translated into the actual `package.cabal` file in Cabal's native format before building and now you have to check both the documentation of the `package.yaml` dialect for the syntactical translation into the Cabal format as well as the Cabal documentation for the meaning of each field to fully understand what's going on. But you don't *need* to use the `package.yaml` dialect! Stack understands the native .cabal format just fine and by using that you avoid the extra complexity and your package works with Cabal out of the box too. It seems like all you need to use the [`include-dirs`](https://www.haskell.org/cabal/users-guide/developing-packages.html#pkg-field-include-dirs) property in your .cabal file. Generally if your package *requires* a stack.yaml file to build it's often a hint there's something wrong or missing in the .cabal file. 
rabble rabble rabble
When do you foresee that hackage will be online again?
(By ‚Äúmerge conflict‚Äù did you mean ‚Äúmerge commit‚Äù?) I would be great if git-bisect could treat the merge commit as one, atomic commit up to the point where it is discovered that the merge commit was the source of the bug, after which it could continue down the merged-in branch to pinpoint the commit that introduced the bug.
(Yep, fixed, thanks.) I agree, I was honestly a bit surprised it didn't have native support for that.
I totally did! My attention to detail is so crap! This is why I'm single!
Your effects would need to be idempotent and commutative.
Funny thing, there was a discussion about idempotence recently. https://www.reddit.com/r/haskell/comments/b7xsp1/idempotent_applicatives_parametricity_and_a_puzzle/
Now that you mention it, I wonder if full `Commutative` is necessary or just an artefact of my poor choice of implementation. I think I could get away with something slightly weaker if I folded to a list representation and then `nub`'d the elements instead, which would preserve the order of distinct effects without the need to demand the freedom to reorder arbitrary effects - like a game where you can revisit areas you've already completed, but you still must progress along a predetermined path.
I had this thought too
I think it permits a very clean of eg. `mapWithSharing` or `mapMemoized` where the side effect is simply performing the computation required to get the return value. `mapMemoized f xs = traverseWithSharing (pure . f) xs` ? 
I think a "containers" hierarchy is actually a much better use-case for backpack, i.e. havving a module signature for `Map`, etc
There is probably something weaker you can ask for, but it starts to be pretty obscure and non-algebraic in specification.
We're in a similar situation of trying to reinvent our build infrastructure at my workplace, and it's really interesting to hear how the team overcame/are addressing the unexpected blockers (like the merge train problem). Thanks for sharing this!
That's weird. For me, when Intero crashes, it switches to a buffer containing the error so I can see it. (Although I suppose this isn't too useful in your case...)
Well there you can get rid of the `Applicative` entirely from the interface! mapMemoized :: (Traversable t , Ord a) =&gt; (a -&gt; b) -&gt; t a -&gt; t b mapMemoized f = runIdentity . traverseWithSharing (pure . f) 
Can you ask just for (idempotent and) one-sided commutativity wrt. the `Ord` instance? Ie. `a &lt; b =&gt; sequenceA [ f b , f a ] == sequenceA [ f a, f b ]` because the traversal of the Map just means we're applying the effects according the order of the Order instance ?
I have problems with cabal 1.22.6.0 in ARM. it appears not to fall back to other servers http://hackage.haskell.org/packages/archive/00-index.tar.gz : ErrorMisc "Error HTTP code: 503"
Well this is what I was saying was wrong with my original implementation - it's a bit silly to perform the effects in the order defined by the `Ord` instance on `a` rather than in the order induced by the provided value of type `t a`. My revised implementation should perform distinct effects in the correct order.
Too old I think
For ones who would like to check basic package info, you can do it with `cabal` cabal info lens or cabal info profunctors-5.2 works locally. Also cabal list servant acts a basic search.
I manage to launch intero manually and intero doesn't crash, so I suspect is more an Emacs problem. Still it would be nice to have access to the buffer.
Complete WIP, please tear it apart. Looking for feedback, if you have * a better name * examples (please more compositional examples): foldl f z t = foldMap @‚Äã_ @(a -&gt; a via Dual (Endo a)) (flip f) t z * or if you don't like it
I'm going to assume GHCJS, but I may very well be wrong. /u/raducu427 what javascript "problem" are you talking about?
Yes, I understood that. Just stating a weaker and algebraic condition for the original question.
This is cute, and I love deriving via a lot. However in this case I'd rather just use something like the prism functions that already exist. Even `coerce (foldMap @_ @(Dual (Endo a)))` doesn't seem much worse to me
Thanks, DAML looks very interesting and I like that it has multi-platform support. I look forward to experimenting with it! I have spent quite a while experimenting with the Pact smart contract language also https://github.com/kadena-io/pact 
Indeed. It's fun to start thinking of computation as a side-effect in the same way as eg. `Applicative` though. Makes me wonder about ways to declare sharing. 
This is so damn cool!
I am seeing this on a build host. I guess the cabal there is too old too.
It's not that simple, we need to hold `Coercible`'s hand all the way. The inferred type of your expression is (Coercible b ((c -&gt; Dual (Endo a)) -&gt; f c -&gt; Dual (Endo a)), Foldable f) =&gt; b so one way or another *both* sides of `coerce` must be specified coerce @((a -&gt; Const m ()) -&gt; (b -&gt; Const m ()) -&gt; t a b -&gt; Const m (t () ())) @((a -&gt; m) -&gt; (b -&gt; m) -&gt; t a b -&gt; m) bitraverse And all of these types must be in scope, so to specify on ghci you must introduce type variables that you don't care about at all &gt;&gt; \(_ :: _ a m t b) -&gt; coerce @.. @.. bitraverse This limits exploration, compared `bitraverse @_ @(m via Const m)` which is localized and the intent is clearer
I agree that it would be nice if this post covered both Stack and Cabal. That being said, I think it's important to encourage people to share what they're excited about even if it's not perfect. This author may not use Cabal, and updating their post to address Cabal may not be interesting to them. If that additional hurdle means they don't publish their post, I think everyone is worse off. Furthermore, their post *does* include information that's specific to Stack. It talks about [`extra-include-dirs`](https://docs.haskellstack.org/en/stable/yaml_configuration/#extra-include-dirsextra-lib-dirs), which will almost certainly be useful for some future Stack-using person trying to use Haskell's C FFI. Reading your other comment, it seems to me that you're railing against `hpack` rather than Stack per se. `package.yaml` files work just as well with Cabal as they do with Stack, except that Cabal doesn't automatically convert them into `*.cabal` files. Also the `include-dirs` property works the same between `*.cabal` and `package.yaml` files. 
I'd also like to plug improving mapped coercions in ghc. Currently deriving via can't handle stuff like Traversable because it can't know the type role of `f`. One way around this would be to include a `MapCoerce` class with `mapCoerce :: Coercible a b =&gt; (a -&gt; b) -&gt; f a -&gt; f b`, which is logically the union of `coerce` and `map coerce` depending on role (we can check this now via QuantifiedConstraints), then using `mapCoerce` automatically in DerivingVia. Ultimately I'd like a good story for typeclass unions (`c || d`) but this special case is the only real usecase I've had so far and would be enough to bake into DerivingVia somehow
You're right, I didn't think that example through enough. What are the improvements over `ala`? 
Have you read Ryan Scott's [QuantifiedConstraints and the trouble with Traversable](https://ryanglscott.github.io/2018/06/22/quantifiedconstraints-and-the-trouble-with-traversable/) and Edward Kmett's comment about [coproducts of constraints](https://www.reddit.com/r/haskell/comments/6k86je/constraint_unions_bringing_or_to_the_language_of/djlghz8/)?
It seems like the best place to dedup effects is in the `f` itself, if you already need the effect to be idempotent for this to work
Why was the comment removed by the mod?
It is bad, but in less bad than other options. 
Could anyone compare Bartosz Milewski's [**Category Theory for Programmers**](https://github.com/hmemcpy/milewski-ctfp-pdf/) and Brendan Fong and David I Spivak's [**Seven Sketches in Compositionality: An Invitation to Applied Category Theory**](https://arxiv.org/abs/1803.05316)? Why would a (intermediate) Haskell programmer choose one over the other in order to study category theory?
I'd considered that, but in my motivating context I usually had existing application-level guarantees that duplicates aren't possible, and in such contexts, it's just a waste of work to dedupe all the time when I already know there's no duplicates. However, one context came up recently where duplicates were not only possible, but expected to be frequent, and that's why this came to me.
Could you please elaborate? Bad as in..
Thanks! That is super help! PS: How did you get the code listing working? What's the correct way with markdown?
Now I can finally extort people and buy drugs with a type-safe language
We've had some reported failures in our \`nix\` builds. Looks like \`nixpkgs\` doesn't include mirrors: [https://github.com/NixOS/nixpkgs/blob/master/pkgs/development/haskell-modules/make-package-set.nix#L186](https://github.com/NixOS/nixpkgs/blob/master/pkgs/development/haskell-modules/make-package-set.nix#L186) :(
You can explicitly use the FP Complete mirror. We wrote up a blog post on this a few years ago: https://www.fpcomplete.com/blog/2015/03/hackage-mirror
Glad you like Pact! :)
 ``` works on new reddit but not old reddit ``` --- 4spc works on new reddit and old reddit 4spc --- With the former version, I think you might be able to specify a language for syntax highlighting, but I'm not sure.
I'm not sure that'll compile
thanks
Sorry for dubious post, i wanted for suggestions on how to do that ?
I'm gonna go ahead and assume the question is implicitly referring to the induction principle for lists. The thing is, though, that \`take\` and \`drop\` are defined by induction on the natural numbers - not the list. At least in the case of \`take\` you wouldn't need to case-split on the list.
Sorry for being facetious :) so my tip would be to think about how you can keep track of decrementing the n value. It's easier to guide you towards a solution if you can show attempt at the problem and then we can pinpoint specifically where you need help üëå‚úå
I've added an edit to post, kindly request you revise it &amp; also please take my very limited haskell knowledge into consideration :) 
But what's *your* attempt? :D You'll learn best by trying! Do you understand how folds work?
Reported this as an issue / feature request. https://github.com/NixOS/nixpkgs/issues/58971
Thanks for posting an update!
i have a basic idea about what fold functions do and how they work but not much into the mechanicals, explanations on the above code or even some directions will be appreciated.
So the type of `foldl` for lists is `(b -&gt; a -&gt; b) -&gt; b -&gt; [a] -&gt; b`, so we're going to have to think of some `b` that will be our accumulator. Our `a` will be the items coming in from the list. So try `take` first. We want to accumulate the `a`s _up until some predicate on n_. So we want to be able to check how many values have we taken. So I would use an accumulator of type `([a], Int)` which will be the items we've _taken_ and the _number_ of items we've taken.
Would you be willing to link to the Brick Hackage or Github page from your post?
ok i'll try, thank you very much
No problem, good luck, and let me know if you need further help!
And you can go deeper... shareElements :: (Traversable t, Ord a) =&gt; t a -&gt; t a shareElements = mapMemoised id 
I've now edited the article so that it should hopefully work for both stack and cabal.
What Blockchain does it run on? Ethereum?
You're a hero, thank you
i experimented with this one but its giving me errors, what it does is basically it takes list and a limit to which the foldl recursively iterates the list with the specified function (func) while specifying n(limit) and prepending the single items until the condition is met. CODE: myFunc :: Int -&gt; \[a\] -&gt; \[a\] myFunc n list = foldl func \[\] list where func x y | (length y) &gt; n = x : y | otherwise = y ERROR PRODUCED : \*\*\* Expression : foldl func \[\] list \*\*\* Term : func \*\*\* Type : a -&gt; \[a\] -&gt; \[a\] \*\*\* Does not match : \[a\] -&gt; \[a\] -&gt; \[a\] \*\*\* Because : unification would give infinite type &amp;#x200B;
It's impossible to implement either of these functions in terms of foldl. To see why not, consider `take 3 [1..]`. With the real `take` function, this returns `[1,2,3]`. However, `foldl` always bottoms when it receives an infinite list.
what if with the premise that the list will not be infinite ??
I totally disagree. Most functionality is not unique to any specific data type, and most data types have at least some non trivial difference in functionality. `Map` for example could not be satisfied by `HashMap` due to functions relating to ordering. Backpack also seems way too heavy for my needs, I just want functions that I can quickly import / throw into a custom prelude, that will work on any reasonable container type I throw at them. 
Wow, this is really cool! And I think it would be super useful with stuff that uses a more extensive numerical hirarchy, where ambiguous things occur a lot (for example, a lot of mathematical operations define a group).
A challenge: do it in one pass (and preserve the order of effects). If you require \`Monad f\`, it's trivial with \`StateT\`; but without should be possible too!
Intertrac links from other sites are broken. It would be easy to fix them. E.g. https://prime.haskell.org/ticket/156 links to https://ghc.haskell.org/intertrac/ticket%3A9079 but the correct URL is https://gitlab.haskell.org/ghc/ghc/issues/9079 /u/bgamari 
 foldlTake :: Int -&gt; [a] -&gt; [a] foldlTake = flip . foldl step $ const [] where step :: (Int -&gt; [a]) -&gt; a -&gt; (Int -&gt; [a]) step _ _ 0 = [] step next elem n = elem : next (n - 1) foldlDrop :: Int -&gt; [a] -&gt; [a] foldlDrop = flip . foldl step $ const [] where step :: (Int -&gt; [a]) -&gt; a -&gt; (Int -&gt; [a]) step next elem n@0 = elem : next n step next _ n = next (n - 1) ... is wrong, but using a higher-order function for your `step` might help.
I would suggest to start with 7 sketches, it's very well written. But I don't think that paper alone would suffice, so Category Theory for Programmers might supplement it.
What was the failure in the end? Which block storage product is in use here?
Thanks for the effort, i'll take that into consideration
Sorry for the late response. I don't think this is true for Rust yet, despite what some people might feel. Rust is not difficult to learn because there are complex constructs in Rust. It's difficult because there are some difficult things in the languages basics. This is different from Haskell, Haskell has some difficulty when learning initially when you're not used to purism, but after learning the basics Haskell is actually really simple. It only gets complicated when including complex libraries. Rust is the other way around, it's paradigm is more complex, but it doesn't have complicated libraries or extensions.
At the moment, DAML is only supported on the Digital Asset platform. Opening the language was a necessary first step in expanding that base. We've been working with a number of platform vendors and open blockchain platforms (as well as databases - the persistence layer does not have to be a blockchain) and you should begin seeing announcements very soon.
Congrats and thanks!
 foldlTake :: Int -&gt; [a] -&gt; [a] foldlTake n l = fst (foldl step (id, n) l) [] where step (mk, 0) _ = (mk, 0) step (mk, n) e = (\l -&gt; mk (e : l), n - 1) foldlDrop :: Int -&gt; [a] -&gt; [a] foldlDrop n l = either (const []) ($ []) (foldl step (Left n) l) where step (Left 0) e = Right (e:) step (Left n) _ = Left (n - 1) step (Right mk) e = Right (\l -&gt; mk (e : l)) ... seem to work in my limited testing. My previous message was mostly me putting together something and then noticing it failed, but thinking it might be a good example. :)
You don't really need w.r.t an Ord constraint, just to check for equality. I think what you're looking for is more of an absorption or left distributive law something like m *&gt; n *&gt; m = m *&gt; n Why is this left distributive? A left distributive magma gives you x(yz) = (xy)(xz). Then since we have a left distributive monoid: xy = -- identity xye = -- associativity x(ye) = unit intro (xy)(xe) = left distribution xyxe = associativity xyx -- unit elimination This provides the ability to absorb "later" copies of the same effect without requiring commutativity to put it in place and provides the idempotence-like effect.
&gt;foldlTake :: Int -&gt; \[a\] -&gt; \[a\] foldlTake n l = fst (foldl step (id, n) l) \[\] where step (mk, 0) \_ = (mk, 0) step (mk, n) e = (\\l -&gt; mk (e : l), n - 1) Thank you very much chief! this one works fine.
Fixed. Thanks!
Somehow I never thought about an operation distributing over itself, but... yeah, why not? Honestly that looks pretty much spot on. Very nice!
It seems to work well when the colon hasn't been URL-encoded, but in the example I gave, it sadly is. Since the links are automatically generated, presumably all those links are still broken.
I'm inclined to agree with Dan Burton and /u/goldfirere in that thread. As convenient as this looks, I'd rather have a mechanism for referring to specific instances directly. Which is not to say that I'm strongly against this or anything. I'd just prefer named instances to using newtypes as instance name proxies. 
But what about typeclasses is better suited to that than a module system? All of the usual indicators for "is this a good typeclass" (does it have any laws, am I expecting to use it with more than one type at once, might I conceivably want it around at runtime) seem to point in the other direction for this case. Also, with these container classes, typeclasses involve a performance cost (whereas backpack doesn't). Anyway, I might be thinking about a slightly different API than you: I'm mainly thinking of the [EdisonAPI](https://hackage.haskell.org/package/EdisonAPI) classes and methods that /u/bss03 mentioned. I think that *those* are better suited to backpack than as typeclasses.
I personally would recommend Haskell book ([http://haskellbook.com/](http://haskellbook.com/)). Mainly because it does a very good job of providing samples with an explanation and doesn't go to far into the "academic rabbit hole". &amp;#x200B; Each section has exercises so you can practice problem solving with the new concept the section of the book is teaching you. More importantly, it approaches explaining the concepts of the language from a very practical standpoint instead of getting the reader lost in the semantics behind the abstraction instead of how to use the abstraction.
Yes, you are write, I was referring to GHCJS [https://wiki.haskell.org/The\_JavaScript\_Problem](https://wiki.haskell.org/The_JavaScript_Problem)
&gt; https://ghc.haskell.org/intertrac/ticket%3A9079 How about now?
Perfect, thanks. It works now.
Sorry, I wasn't clear, I intended the condition wrt. the original statement, which sequenced effects according to the \`Ord\` instance. Then, the proof of equivalence is constructed as a bubblesort on the effects - all we need is the ability to swap effects in one direction without affecting the result, when the order doesn't match the underlying \`Ord\` instance. 
Convenience and easy of use for one. I want to be able to call `init`, `!!` etc. in a single file on a variety of data structures with no hassle and no noise. That's really all I want and it would be a nice boost to my productivity and it would make things easier for me. &gt; does it have any laws All except `Foldable` do have some solid laws, and the free laws of `Foldable` plus some intuition means its going to be pretty unambiguous what the `Foldable` instance of any given type is going to be. &gt; am I expecting to use it with more than one type at once Absolutely, various convenience functions and utilities for data structures, such as a simple `slice` function that utilizes `take` and `drop`. &gt; might I conceivably want it around at runtime Can you give some concrete examples of typeclasses you definitely do and definitely don't want to have around at runtime? I don't see why any of the above would be all that different from your usual type classes in that regard. &gt; Also, with these container classes, typeclasses involve a performance cost (whereas backpack doesn't). They also require 1000x less effort to use, and they only involve a performance cost when things don't optimize away, which usually means you are using typeclasses in a polymorphic way that backpack isn't even capable of doing. There is zero reason for typeclasses used with a know type to be slower than backpack, and if there are examples where there are there should either be other advantages (smaller code size), or it means GHC has a bug (or at least an "issue") that needs attention. &gt; Anyway, I might be thinking about a slightly different API than you: I'm mainly thinking of the EdisonAPI classes and methods that /u/bss03 mentioned. I haven't looked enough into EdisonAPI to agree or disagree, but regardless of that I don't see the downside of adding the convenience functions I mentioned into the above typeclasses and moving away from monomorphic list functions. You would still be able to use EdisonAPI or EdisonAPI2BackpackBoogaloo with no difference from now. One particular thing I like about the typeclass aspect is that it would be nice for people getting into Haskell, who may be used to things like `x.get(i)`, `x[i]` or `x.reverse()` from other languages, and may find it frustrating to not have something equivalent in Haskell. Backpack is interesting but it's significantly heavier and less convenient than typeclasses are.
&gt;shareElements = mapMemoised id Does this just ensure that if two elements are the same, they're two pointers to the same memory location rather than potentially residing distinctly?
I should confess I've only used backpack a handful of times, so my experience is mainly coming from Agda's module system (which is, as far as I know, similar to ML's). Anyway, what about backpack is more heavyweight than typeclasses? In my experience, modules (which would be backpack) work better for cases like Data.Map, whereas typeclasses work best for Functor. (As in, you'd have a "Mapping" module/signature with methods like `lookup`, `insert` and so on). `Foldable` is right on the edge, but if there was a `RandomAccessCollection` kind of thing, I'd expect that to be a signature, rather than a typeclass. In terms of "definitely do and don't" want to be around at runtime, you *need* them to be around if you're doing any polymorphic recursion, so that (for me) includes Functor, Foldable, Traversable, Applicative, etc. right off the bat. Also `Monoid` and so on for: newtype Free c a = Free { runFree :: forall b. c b =&gt; (a -&gt; b) -&gt; b } In terms of definitely *don't* I'd say anything high performance, really (`lookup` would be an example). If I don't *need* the overloading, I'd prefer to be really sure that it's going to go the monomorphic version than use the nice overloaded interface. GHC does a fantastic job at optimising in the right places, but nonetheless I've seen several cases where typeclasses haven't specialised, causing serious slowdown! Also, when I say "use more than one at once" I mean something like: toList2 :: (Foldable f, Foldable g) =&gt; f (g a) -&gt; [a] 
&gt; adding the convenience functions I mentioned into the above typeclasses and moving away from monomorphic list functions Note that this has already introduced some novice confusion; `length (1, "foo")` reduces to `1` since FTP came in; you'd have the same thing happen to these other list functions. Monomorphic is actually *better* for new users, since they get simple type errors up front. Whether `Prelude` should be targeted as new users is an open question, with a tendency toward having it be more generally useful and away from novice-friendly. (But, then again, novices often find themselves tripping over the division functions in the `Num` hierarchy and have for decades, so maybe a `Container` hierarchy of type classes wouldn't be much of a change.)
It's basically `ordNub` generalized to any `Traversable`.
Having had some experience in the domain, maybe you could aid the OP with a non-trivial example?
&gt; Anyway, what about backpack is more heavyweight than typeclasses? I mean I just want to be able to do: ``` foo :: [Int] foo = [1, 2, 3] bar :: Maybe Int bar = foo ?! 0 baz :: Seq Int baz = [2, 3, 4] qux :: Seq Int qux = reverse baz ``` With no extra ceremony besides `OverloadedLists` and maybe a custom Prelude/import that puts all these things in scope. I feel like this isn't much to ask, and you can already do it (besides the OverloadedLists) in most OOP languages via methods. From what I can tell backpack is not particularly lightweight or simple and requires a bunch of cabal file noise. Maybe if it was implemented in a cleaner way (Agda's module system seems cool but I'm still fairly new to Agda) I would have less apprehension. &gt; In terms of "definitely do and don't" want to be around at runtime, you need them to be around if you're doing any polymorphic recursion, so that (for me) includes Functor, Foldable, Traversable, Applicative, etc. right off the bat. Also Monoid and so on for: So you are including all the typeclasses I mentioned? I suppose you didn't mention `Filterable` and `Witherable` but they are just natural extensions of the above classes so I am assuming you're not trying to explicitly exclude them. If you are including the typeclasses I mentioned I am not sure why you seem to be in opposition to my suggestion, as all the functions I mentioned can already be implemented purely in terms of those typeclasses, they just would be more efficient if at least some were included in the class (look at `Foldable` for clear precedent of doing such a thing). &gt; I'd prefer to be really sure that it's going to go the monomorphic version than use the nice overloaded interface I get being performance aware, but really this seems premature for most tasks. I want to be able to dev efficiently and quickly, and I will benchmark and optimize later if it turns out I need to. Particularly given GHC's impressive optimization ability it seems like we should embrace developer convenience and abstraction and just make sure it's always possible to benchmark and optimize later.
\`ordNub\` removes duplicates, \`shareElements\` does not ?
I recommend Learn You a Haskell for Great Job ([http://learnyouahaskell.com/](http://learnyouahaskell.com/)), it's a free book (pdf) with an online version. Also, [https://github.com/soupi/haskell-study-plan#beginning](https://github.com/soupi/haskell-study-plan#beginning) is a Haskell study plan without a lot of concepts, the goal of the repository is practice programming and solving tests.
I don't love the tuple/either situation. I am hoping that proper extensible rows will fix a lot of that, as then you would use heterogeneous extensible arrays instead of tuples. You would have: ``` Array :: Type -&gt; Type Row :: Type -&gt; Type Sum :: Array Type -&gt; Type Product :: Array Type -&gt; Type Record :: Row Type -&gt; Type Variant :: Row Type -&gt; Type ``` And then you would use `Product [Int, String, Char]` rather than `(Int, String, Char)`, and due to the different kinds `length` would not typecheck on `Product` anyway. You also wouldn't have [this](https://github.com/ghc/ghc/blob/master/libraries/ghc-prim/GHC/Tuple.hs) weirdness and various max lengths for various situations. Long term I would prefer if there was no such thing as a single blessed `Prelude` that is imported by default, in any non-trivial project I always end up defining or using some sort of custom Prelude anyway. Then for beginners we can simply have them import `Prelude.Simple` or `Intro` or whatever, and have more experienced users import `Prelude`, and big projects will probably continue to import or define custom preludes, but now they won't have to explicitly hide any conflicting `Prelude` functions. &gt; (But, then again, novices often find themselves tripping over the division functions in the Num hierarchy and have for decades, so maybe a Container hierarchy of type classes wouldn't be much of a change.) Fair point, I do think typeclass polymorphism is a core aspect of Haskell, so I don't think it should be shunned too much, even for beginners. Perhaps better error messages are needed / specific beginner friendly tooling for investigating and fixing type errors.
I would not recommend Haskell Programming from first principles (haskell book). I used to think it was a good book for beginners to Haskell till I recommended it to my friend, a developer. He found the book too slow. If you do not have issues with that then you should definitely try that book. He wanted to build something already! &amp;#x200B; I recommend that you find a blog or something to learn basic haskell syntax and do beginner coding exercises. Haskell syntax can make things seem more unfamiliar than they are. As you keep writing more code you will start learning more. You will have to learn to move past things without completely understanding them or you may get down deep frustrating rabbit holes. Do not sink your time into cabal vs stack. Pick one, stick with it. (My recommendation is cabal. Only use the new-\* commands from it). &amp;#x200B; One of the biggest issues troubling him has been the environment/ide setup issues. Get comfortable with ghcid and the repl(ghci). They take you a lot of the way. &amp;#x200B; After you are comfortable with basic haskell, I would read the books to cement understanding. &amp;#x200B; Join the irc/discord communities. Ask for help, ask frequently, haskell has lots of helpful people around. &amp;#x200B; You can also find haskell streams on twitch which can help. &amp;#x200B; [https://github.com/ndmitchell/ghcid](https://github.com/ndmitchell/ghcid) &amp;#x200B;
Thumbs up for not claiming everything you do is magically secure because it is *blockchain*. It is more honest since most cryptocurrencies are mined only by a few people and are therefore not as decentralized as they claim. The alternatives to PoW are not well-understood and therefore deemed to be complicated and not suitable.
&gt;I would not recommend Haskell Programming from first principles (haskell book). I used to think it was a good book for beginners to Haskell till I recommended it to my friend, a developer. He found the book too slow. If you do not have issues with that then you should definitely try that book. He wanted to build something already! My experience as well. While *Haskell Programming From First Principles* is the most commonly recommended beginners book I found it unnecessarily verbose. If you are a seasoned programmer who is yet unfamiliar with Haskell and appreciate concise writing I'd recommend Graham Hutton's [**Programming in Haskell**](http://www.cs.nott.ac.uk/~pszgmh/pih.html).
Get programming with haskell -&gt; think with types -&gt; haskell in depth
Yes, it's forcing sharing after evaluating for equality with `(==)`
I have all the Haskell books. And have had a lot of false starts picking up the paradigms of the language. [get programming with haskell](https://www.manning.com/books/get-programming-with-haskell) Was the one that finally clicked for me. It doesn‚Äôt cover IO until almost 1/2 through the book which requires a lot of implicit knowledge I understand. Can‚Äôt recommend it enough. I cover a ton of the books contents in a follow along method on the show [javascript to elm ](https://jstoelm.com/2)
Not sure if this belongs in here or in the github thread, but is there a place where I can get a draft or other version of this paper? https://dl.acm.org/citation.cfm?id=3242752 It's hard to follow the conversation without it being available for me to read.
I found it searching for "Safely Exposing Haskell's Hidden Powers" (https://lirias.kuleuven.be/retrieve/522311)
Ngl I spent a while attempting this and felt like I was close but couldn't finish it. Did you write a version yourself or just reason that one must exist? I was playing around with Data.Functor.Utils.StateL and Data.Functor.Compose and managed to (a little inconsistently) increase sharing, but it definitely wasn't fully correct. &amp;#x200B;
Generate a sparse matrix. data SparseMatrix = SparseMatrix { row: :: Int, column :: Int, value :: Int } iDm :: (Num a, Enum a) =&gt; Int -&gt; SparseMatrix iDm n = [ SparseMatrix r r 1 | r&lt;-[1..n]] &amp;#x200B;
`[[x == y | x &lt;- [1..n]] | y &lt;- [1..n]]` gets you an identity matrix of booleans of size n. Does that point you in the right direction?
I learnt Haskell from [Learn You a Haskell for Great Good](http://learnyouahaskell.com/). There's quite a few people who don't particularly like it, but I think it's a great resource, especially when followed up with Stephen Diehl's amazing essay [What I Wish I Knew When Learning Haskell](http://dev.stephendiehl.com/hask/).
Assuming this isn't homework here's a classic solution iDm :: Num a =&gt; Int -&gt; [[a]] iDm n = [ (replicate (r-1) 0)++[1]++(replicate (n-r) 0) | r &lt;- [ 1..n ] ] You only need either the `Num` or the `Enum` class constraint on `a`. If you want the version using the `Enum` class, replace `0` and `1` with `(toEnum 0)` and `(toEnum 1)` respectively.
about &lt;\*&gt; there is an interesting discussion here : [https://stackoverflow.com/questions/55513329/does-in-have-a-special-meaning](https://stackoverflow.com/questions/55513329/does-in-have-a-special-meaning)
I like Get Programming with Haskell, there's a good number of practical projects you implement along the way.
&gt; Any sufficiently advanced technology is indistinguishable from magic That also applies to category theory ;). 
He says he wants nested lists (and I'm guessing it's for an assignment where he can't change the type). Even if it is for the sparse matrix assignment that a few people have asked for help with, they use a very different sparse matrix type than this. 
It's probably homework. 
yes its small part the of homework :) part where i got stuck for several hours. thanks for your understanding.
thank you very much Boss, indeed a neat and easy to understand solution!! 
awesome solution, hands down best solution so far thanks!!
You need to look at the core to understand what is going on or at least post it (using [`dump-core`](http://hackage.haskell.org/package/dump-core) preferably) so someone else can look at it. The recursion schemes example is not going to be as fast unless the abstraction is optimised away.
&gt; I would not recommend Haskell Programming from first principles (haskell book). I used to think it was a good book for beginners to Haskell till I recommended it to my friend, a developer. He found the book too slow. I haven't read Haskell Programming from first principles but I can easily justify its ~~slow~~ meticulous approach. Haskell requires a mind-shift. It's naive to expect to grasp the language quickly because you've got tons of imperative or object-oriented programming experience. Much of the beginners prior prior experience is of much use and often gets in the way. There's a lot to be 'unlearned' I would manage your friend's expectations. &gt; I recommend that you find a blog or something to learn basic haskell syntax ... After you are comfortable with basic haskell, I would read the books to cement understanding. You stopped short of recommending [LYAH](http://learnyouahaskell.com/) ;-) I'm certain many of us program other languages and have studied more than one text on the same language -- I have/do. Each text or resource takes a slightly different/refreshing perspective on the subject matter and introduces concepts omitted by other texts. Why should Haskell be different? As a community we should move on from this categorizing a book as *bad* unless it contains multiple factual inaccuracies (not to be confused with typos or imperfections). My advise to your friend is to pick one text that and study but use other resources (texts, articles, user groups) when needing greater clarity. And when he finished, pick another books, perhaps a more advanced one and go one from there.
They aren't the same thing, for one. Recursion schemes are leaf-first while explicit recursion usually goes down the spine. 
Thanks, I'm learning Haskell myself so this was a fun problem to think through.
Yes, this might save you few memory bytes. It depends if the traversal is worth that.
Coercible doesn't have a fundep by design so the desugaring probably would be somthing like expr :: t expr @m1 @m2 @(x via y) @(a via b) -- using made up syntax for instantiation expr :: t[m1, m2, x via y, a via b] coerce (expr :: t[m1, m2, y, b]) :: t[m1, m2, x, a] fold @[] @(Int -&gt; Int via Dual (Endo Int)) [(* 10), (+ 5)] 10 fold :: forall t m. (Foldable t, Monoid m) =&gt; t m -&gt; m (coerce (fold :: ([Dual (Endo Int)] -&gt; Dual (Endo Int))) :: ([Int -&gt; Int] -&gt; Int -&gt; Int)) [(* 10), (+ 5)] 10 ?
Well, it's trivial, but ordinary addition and multiplication both from a Group, so pretty early in the hierarchy there's a pretty obvious problem. If we turn our attention towards matrices, there a few options for invertible matrices over some field a, here: &amp;#x200B; \- matrix multiplication forms a group \- matrix addition forms a group \- the hadamard (or element-wise) product forms a group For example, in machine learning I often encounter the need for the element-wise product.
I thought the same thing about First Principles. It felt that it over-explained everything. Get Programming with Haskell is a decent intro book to get your feet wet and see if you want to explore the language further. 
Somehow I thought that this more than a 1000 pages long book pretending to be *the* modern book for haskell beginners just *must* have good understandable explanations of *type families, functional dependencies and GADTs*. Even thought it's slightly advanced topics these things seem to be needed for real world, at least understanding and working knowledge of them and the book is damn *1000* pages long. I just checked and no, it has nothing about it.
As an OO/imperative programmer who learnt Haskell largely from the First Principles book I completely disagree with you, having tried the other approaches you list and finding them way too frustrating - unlearning OO is hard if you're only doing it as a side project - taking the time to do the exercises is invaluable to adjust your mindset. The First Principles book is a slog but I think it's a very good path to take to actually learn the language.
For that we have [https://intermediatehaskell.com/](https://intermediatehaskell.com/) \- but the book seems to be delayed indefinitely. :-(
While I write a response please tell me what it is about named instances that you like
Great good* Ironically, I think LYAH is probably the worst resource to learn haskell from. I read the entire book and still had no idea how to write a Haskell program that did anything interesting. I recommend Haskell: Programming from First Principles (http://haskellbook.com/)
It doesn't look like Hutton's book covers mtl, exceptions, IO?. Two things anyone writing real world Haskell code is going to run in to pretty quick. 
Leksah is under active development (see GitHub here): https://github.com/leksah/leksah The http://leksah.org/ webpage is dated (as are the downloads there). There are build instructions in the Readme.md on the GitHub page (via Nix on Linux works for me). Hope that helps. (sorry for the slow reply...)
I came here to say the exact same thing. I found reading *The Haskell Book* unbearably slow and the examples in the book contrived. Hutton's books is much more succinct and cover most of the basic Haskell syntax in much faster pace with better examples.
It is a beginners book. You are looking for *intermediate* Haskell books. Manning's upcoming [**Haskell in Depth**](https://www.manning.com/books/haskell-in-depth) seems to be promising in that regard. And there is [**Intermediate Haskell**](https://intermediatehaskell.com/) however the release date for that one is uncertain.
I have read the book and hence recommended it to my friend. I read it already knowing haskell to see if I could learn anything new since I did not learn haskell from any books. You stopped the quote short of "If you do not have issues with that then you should definitely try that book", implying that I disagree with the book or its approach. I am simply sharing issues my friend had with it. &amp;#x200B; My friend is using multiple articles, videos, books as he encounters issues with progressing further in his studies. More importantly he sees and realizes the need for something and then learns it. He will sometimes take leaps far beyond his current grasp or need but it keeps things interesting as all of it relates to his project for him. &amp;#x200B; \&gt; As a community we should move on from this categorizing a book as *bad* I don't see where this accusation of categorization this as a bad book stems from. People are simply sharing their experiences with the book providing insights into what did not work for them. &amp;#x200B;
This feature will be disabled by default in Cabal 3.0. [https://github.com/haskell/cabal/pull/5985#pullrequestreview-223232990](https://github.com/haskell/cabal/pull/5985#pullrequestreview-223232990) &amp;#x200B;
No idea in particular about your particular example with the insertion/bubble sort code, haven't really done (cata . apo) before, but I have used an apomorphism before and it was better performing than a regular anamorphism, so not sure what might be going on. By the way, in case you're curious it looks like you can write some recursion-schemes code that performs closer to listViaStrictMap reference implementation using a metamorphism (fancy way of saying unfold after fold): import qualified Data.Map.Strict as MS import qualified Data.Functor.Foldable as RS import Data.Bool (bool) populateMap :: Ord k =&gt; RS.ListF (k, v) (MS.Map k [v]) -&gt; MS.Map k [v] populateMap RS.Nil = MS.empty populateMap (RS.Cons !(k,v) m) = MS.insertWith ((:) . head) k [v] m mapToList :: Ord k =&gt; MS.Map k [v] -&gt; RS.ListF (k, [v]) (MS.Map k [v]) mapToList m = bool (RS.Cons (MS.elemAt 0 m) (MS.drop 1 m)) (RS.Nil) (MS.null m) meta :: (RS.Corecursive c, RS.Recursive r) =&gt; (a -&gt; RS.Base c a) -&gt; (RS.Base r a -&gt; a) -&gt; r -&gt; c meta f g = RS.ana f . RS.cata g listViaMetamorphism :: Ord k =&gt; [(k, v)] -&gt; [(k, [v])] listViaMetamorphism = meta mapToList populateMap I'd be interested in knowing what turns out to be the problem when you find out!
go away and take your propaganda with you
Seriously?
This is a redundant duplicate post of https://old.reddit.com/r/haskell/comments/9a6fg4/package_environment_files_run_counter_to/ that was already posted and debated already. The default setting will be changed for the upcoming 3.0 release as a short-term measure to resolve the remaining issues with this feature affecting some people; but we'll need the help of those complaining so we can address those, otherwise we'll be back to square one when we enable it again. 
I understand the problem with respect to implementing a more granular numeric hierarchy ‚Äî which we need if we‚Äôre going to get a good base for building the needed numeric api to drive a unified data-science ecosystem in Haskell. However, given that this is a proposition for a compiler is pragma, an example of the api for the binary operation of a group on array like things (in terms of what we can do now, what we could do with ApplyingVia, and what we would like in the best case) would contribute to the discussion between /u/icelandjack, /u/goldfrier, et al. I say this because I know via datahaskell that you‚Äôve spent some time thinking about this precise problem. 
&gt;I say this because I know via datahaskell that you‚Äôve spent some time thinking about this precise problem. unsuccessfully (until know üòâ) yeah, i know my answer was lacking. It was just a quick answer i typed on my phone when I was waiting for my train. I should find some time on the weekend.
I don't have an alternate video link, but if you just want to get a sense of what it's all about, the \[author's paper\]([https://github.com/snowleopard/alga-paper](https://github.com/snowleopard/alga-paper)) (linked to in the video page above too) is available, and they have \[a library up on hackage\]([https://hackage.haskell.org/package/algebraic-graphs](https://hackage.haskell.org/package/algebraic-graphs)) implementing these ideas as well, along with a bunch of pretty good blog posts, starting \[here\]([https://blogs.ncl.ac.uk/andreymokhov/an-algebra-of-graphs/](https://blogs.ncl.ac.uk/andreymokhov/an-algebra-of-graphs/)). The paper is pretty readable too I think, although predictably somewhat denser than the blog posts. I hope this is useful information!
Thanks for pointing me to dump-core! That's an excellent tool. [Here's the result.](https://github.com/adamConnerSax/Frames-utils/tree/master/map-reduce-folds/bench/core-html) I've looked at it some, before I had the dump-core version, and I can see that maybe something is going on with loop-breakers but there's nothing obvious to me which is why I posted. If someone can look and help me learn how to understand where to look for important differences, that would be most helpful!
Thanks! I'm not expecting them--I assume you mean the to/from Data.Map.Strict version and the recursion-schemes version--to be the same. I just have the map version to check correctness and as a vague speed reference. What I do expect to be similar are two recursion-schemes versions, one using an unfold of a fold and one using an unfold of a paramorphism. Because in that case, the paramorphism isn't making any use of the extra information. And I expected some speedup when moving from a fold of an unfold to a fold of an apomorphism, because the apo does use the additional information to save work. In both of those cases, the speed differences were surprising (to me!). 
My only interpretation from your posting is that Cardano is full of bullshit. 
Thanks! So a metamorphism is sort of a co-hylo? Maybe that's an abuse of "co". But somehow like a hylo but in the opposite order. Cool. I'll add your variant to the bestiary of variations I'm collecting! I was headed for Tree implementations, though I was trying for one that would be a hylo, so that rather than folding to a Map, I was unfolding into a Tree structure and then folding that tree back to a list. That's where the paper I referred to ends up, a version of mergesort. The nice thing about that is that the tree gets fused away and that seems cool and possibly performant. 
Yeah a metamorphism is pretty much that... (paper by Gibbons)[http://www.cs.ox.ac.uk/jeremy.gibbons/publications/metamorphisms-scp.pdf] I might take a look this weekend out of curiosity to see if it could be done with a hylo performing well. 
&gt; which btw is considered in violation of r/haskell's guidelines As a moderator, I feel okay with duplicate posts if enough time has passed and/or something has changed. It's clear to me that in this case, something has changed. Namely: PR 5985. &gt; we'll need the constructive help of those complaining This seems like a reasonable venue to do that. I'll start: I recently decided to start a project using Cabal instead of Stack because I hadn't done that in a while. After a short while I decided to also build it with Stack. I immediately ran into a problem because of the `.ghc.environment` file. I only managed to rescue myself because I happened to hear about this issue before. I was not happy about the whole situation. I feel very comfortable using `cabal new-repl` or `stack ghci` rather than plain `ghci`. In fact, I often want to keep those things separate! Here's my rationale, which applies equally well to both Cabal and Stack: - `ghci`: A bare GHC REPL using my global GHC and installed packages. Not related to the current project at all. - `stack exec ghci`: GHC REPL using the project's GHC and installed packages. Sort of related to the project, but only in that the project is available like any other dependency. - `stack ghci`: GHC REPL using the project's GHC and installed packages. Intimately tied to the project. 
What I think is tricky about the hylo version--but my intuition is very crude at this point--is that you are building subtrees often during the unfold. That's fine, maybe, for a sort, which can then do more of the sorting work as the tree is folded back to a list. But here, we want as much combining as possible as early as possible. So there's some tradeoff, I think, between the binary-search advantages of the trees and the early combining. And the optimal thing might depend on the probability of any two elements being combinable. Or something. But there are probably a lot of ways to build the tree, etc. and maybe some capture all/most of the early combining of the bubble-sort-like version. I'm interested in all of that, but it's tricky to sort out when even the simple things don't make sense, benchmark-wise.
I've had ideas for `git bisect --first-parent` for a long time. Maybe I should make a proposal to the git list‚Ä¶
Why should the feature be re-enabled by default if it‚Äôs resulted in this much of a negative user experience for people using `stack` and `nix`? Throughout these discussions, both on Reddit, on GitHub, and on the mailing list, this feature has been treated as something where it being on by default has some intrinsic value in and of itself. As far as I can tell, no significant _deep_ intrinsic value has been demonstrated, only a minor added convenience for a small subset of users. So, to repeat myself: I‚Äôm curious, after the negative feedback that has resulted in this change for the upcoming 3.0 release, why it should automatically be assumed that this contentious feature should be turned back on?
Showerthought: The social adoption of smart contracts have to have the certification from a court that it faithfully implements the legal languages of a contract of current usage and fall back to court for final dispute resolution. Therefore the establishment of authority of the runtime is separate from securing it with strong type checks and blockchain. Such a broad definition probably includes stuff like automatic traffic ticket resolution and electronic stock trading. There is also news about AI assisted judgement, and small claim court experimentally run by AI. On the other hand there are opinions that large scale escrow payment services like Alipay is the true innovation of recent. What do you think?
&gt; except that Cabal doesn't automatically convert them into `*.cabal` files. That's a very strange definition of "work just as well".
&gt; when it's enabled again Will there be as much discussion around re-enabling it as there has been to change the default now? Part of the reason I (and possibly others) feel so strongly about this is that the original change was snuck in without any discussion/consultation (as of this writing, the change still isn't in the `CHANGELOG` for `cabal-install` 2.2). The only (semi-)official mention that this change was made at all was in a Haskell-Cafe mailing list post. I've been inconvenienced enough by this change that I refuse to use any `new-*` commands at all, and I'm very happy to hear that you're open to changing this behaviour.
I hope we can have a productive discussion about this rather than just dunking on Go. This post reminds me of these classic posts that introduce monads in very approachable ways: - http://blog.sigfpe.com/2006/08/you-could-have-invented-monads-and.html - https://fsharpforfunandprofit.com/posts/recipe-part2/
Skimming really fast, I think that's a typo in the tutorial code. term5 = term term5 is wrong. It also doesn't behave like the example uses of it listed under it. And it's different than `term6`, which looks correct. It should be: term5 = term simpleExpr5 Good luck!
Figured it out! Sort of... &amp;#x200B; In the very cool blog post [Recursion-Schemes (part 4.5)](https://blog.sumtypeofway.com/recursion-schemes-part-41-2-better-living-through-base-functors/), Patrick Thomson points out the interesting way `cata` is defined in the `Recursive` class in recursion-schemes: `class Functor (Base t) =&gt; Recursive t where` ... `cata f = c where c = f . fmap c . project` &amp;#x200B; Patrick says "...the name `c` appears unnecessary, given that you can just pass `cata f` to `fmap`. It took several years before I inferred the reason behind this‚ÄîGHC generates more efficient code if you avoid partial applications. Partially-applied functions must carry their arguments along with them, forcing their evaluation process to dredge up the applied arguments and call them when invoking the function. whereas bare functions are much simpler to invoke." &amp;#x200B; Some version of that is happening here. I cloned the recursion-schemes repo and commented out the `[]` specific implementations of `para` and `ana` and my code gets faster. In particular, the two should-be-identical bubble sorts perform nearly identically. I'm not sure why the list-specific versions are in there, or if there is a way to call them which obviates this problem. But in the short term, that confusion is resolved. And I will post the observation as an issue on the recursion-schemes repo.
I'm currently going through HPFFP and there are a few things that are tripping me up. First thing tripping me up is how (-&gt;) is the type constructor for functions, but the values on the term level are the functions itself. Can I think of something like fst :: (a,b) -&gt; a as being: fst :: (a,b) fst a with fst being infix in the type signature and applying itself to the pair argument to the left and then returning the value on the right, a? ------------ (-&gt;) is right associative - so something like ex1 :: String -&gt; Bool -&gt; Integer would be parenthesized as: ex1 :: String -&gt; (Bool -&gt; Integer) I keep thinking of this as: 1. A function applied to the Bool argument. 2. Returning a function with Bool applied. This returned function would have a type signature of "String -&gt; Integer". 3. Waiting for a String argument. 4. Retuning an Integer. Which I'm pretty damn positive is the wrong way to think about it! I assume it would be more appropriate to look at it as: 1. Taking an argument String 2. Retuning "(Bool -&gt; Integer)" which would be another function waiting for a Bool argument. 3. Return Integer. But this feels like I'm missing something. With right associativity, how come the parentheses are not applied first? ___________________________________ Last thing I'm wondering about is multiple typeclass constraints on more than one variable. My mind keeps thinking of the class constraint as tuples. How would I be able to tell the difference? Ex: (Num a, Num b) =&gt; a -&gt; b -&gt; b Thanks!
&gt; Can I think of something like &gt; &gt; fst :: (a,b) -&gt; a &gt; as being: &gt; &gt; fst :: (a,b) fst a &gt; with fst being infix in the type signature and applying itself to the pair argument to the left and then returning the value on the right, a? I certainly wouldn't. That's like saying can I think of `5 :: Int` as `5 :: 5` or `[7,8,9] :: [Int]` as `[7,8,9] :: 7 : 8 : 9 : []`. At best you'll have to get away from that thinking in the future, most likely it will cause you quite a bit of confusion before then. --- If it helps, you might want to think of: f pat _ = res1 f (C pat) pat2 = res2 as f = \x y -&gt; case (x, y) of (pat, _) -&gt; res1 ((C pat), pat2) -&gt; res2 Then the lambda+arrow `\`+`-&gt;` is a infix-ish constructor for the `-&gt;` type.
I gave an answer to that here https://github.com/ghc-proposals/ghc-proposals/pull/218#issuecomment-480392621
&gt; I assume it would be more appropriate to look at it as: &gt; 1. Taking an argument String &gt; 1. Retuning "(Bool -&gt; Integer)" which would be another function waiting for a Bool argument. &gt; 1. Return Integer. &gt;But this feels like I'm missing something. With right associativity, how come the parentheses are not applied first? They are, and you did here. Note how your "Returning" in step 2 (already) referred to the type `Bool -&gt; Integer`? It couldn't refer to `Bool` or `Integer` alone, but rather the already combined (via `-&gt;`) result.
&gt; My mind keeps thinking of the class constraint as tuples. How would I be able to tell the difference? They aren't `Type`s, they are `Constraint`s -- for less formally recognizing that something like `Num c` can't be put in the same place where you'd put `c`? Failing that, the fact they occur before a `=&gt;` instead of a `-&gt;`?
I personally think that smart contracts will always require a supporting legal system to manage disputes. Contracts almost always require some level of flexibility to deal with things that are out of the parties' control, and how that flexibility plays out is always subject to interpretation. Even after thousands of years of practice, paper contracts are still challenged in courts. I'm not sure that we can expect - or even desire - anything different from smart contracts. If you buy into this line of thought, then the key is to ensure the contract produces a sufficient evidentiary trail to make these legal challenges quicker and simpler to resolve. [This blog post](https://medium.com/daml-driven/smart-contract-language-the-real-arbiter-of-truth-efe833031ca1) describes the DAML design in this respect.
Yes exactly
I'm also reminded of the \[IO monad realized in 1965\]( [http://okmij.org/ftp/Computation/IO-monad-history.html](http://okmij.org/ftp/Computation/IO-monad-history.html) ) post by Oleg Kiselyov.
I appreciated this post for showing the monad pattern present in Go. Then showing how an abstraction over this pattern leads to simpler code. It demonstrates why the common abstraction is useful, and not just a way to categorize things -- although that's useful in its own right.
in this post, they describe the Go example: ``` ew.write(p0) ew.write(p1) ew.write(p2) ``` but the analogous Haskell thing ``` write p0 &gt;&gt; write p1 &gt;&gt; write p2 ``` doesn't run the later code if the earlier code fails, which is not the behavior of the Go.
Came in here to note the same thing. The go version of the code is going to do a lot of repetitive failure checks rather than just stop.
As /u/edwardkmett states the Haskell version is more efficient; but note that if we DID want the go behaviour it would also be quite simple to write. That's the power of being able to pick your monad or implement it yourself.
Ah. Will have a look in the morning. It's rather late here, and I'm too tired to process what I'm reading at the moment. 
I don't see how it is different than any of the other 100 monad tutorials that have exactly this example, besides showing us that Rob Pike, despite his big name, doesn't know what monads are.
&gt; I hope we can have a productive discussion about this rather than just dunking on Go. I don't think there can be any productive discussion about the reinvented wheel that is hilariously square in that it changes the meaning of the original program and is completely ad hoc and needs to be implemented over and over again for every interface that has some errors in it.
In my mind (so possibly erroneously) this is connected to the worker/wrapper transformation. The worker can take fewer arguments because it always runs in the environment created by the wrapper, and that makes it easier to inline (though `c`, being recursive won't normally get inlined, `cata` can be which might fuse `f` or `project` (and maybe even the `fmap`) into the surroundings.)
You've come from Java; how comfortable are you with the JLS and the JVM spec? If they make sense, you might just jump into the Haskell 2010 Report; it is a different computational model, but I basically learned Haskell from the 98 Report. I added RWH in there when I was having trouble navigating through the `mtl` package, and accepting that extensions (like MPTCs) were going to be the norm for many of my programs.
Yes, it works like a charm. Thanks a lot. Good find, it is indeed a 2-year old issue.
I think the best solution is to educate users to use `cabal repl` (or `cabal ghci`; don't remember) if they want a REPL with project-specific packages loaded. This feels a lot cleaner and more explicit to me. I don't agree with the frequent comparison with Git, where a hidden file (well, directory) also controls behaviour. The difference is that Git is completely non-functional without the presence of the `.git` directory, while here we had the situation that `ghci` and other tools changed their behaviour based on the presence of a hidden file.
1. It was part of a uni course 2. I wanted to learn *some* FP language because I notices that OOP languages were adopting FP features (lambdas, list constructors, returning functions) and I thought it would be a good idea to at least know 1 FP language to understand the source of all those features. I don't think I'll use Haskell in a practical way (too abstract for me, and so... many... operators...), but I'm definitely happy I've learned how FP works. 
&gt; so... many... operators... See, and I want more; I want the [mixfix operators / notation](https://agda.readthedocs.io/en/v2.5.2/language/mixfix-operators.html) of Agda. :) Being unable to create my own operators was one of the things I disliked about operator overloading in C++; if I reused an existing operator is came with semantic baggage.
&gt; Why should the feature be re-enabled by default if it‚Äôs resulted in this much of a negative user experience for people using stack and nix? Because its not the existence of this feature that's the problem -- its getting all the tooling to catch up to it, and all the tooling _is_ catching up to it! So at some point, one would expect, use of this handy feature wouldn't have bad side-effects.
At the time it was added it was as part of the experimental development of an experimental feature. When new-* commands are made standard in 3.0, which is the first time new-* will be _not_ experimental, it will default off. In the meantime, you've been able to globally turn off generation for a long time now, so its unfortunate that you haven't taken advantage of new-* commands just because you didn't want to add a line to your cabal config :-/
Thanks! My main problem with Leksah is that I'm on Windows, and have never managed to get `haskell-gi` to compile successfully, preventing me from using it. I know there's Windows build instructions, but I haven't yet managed to follow them successfully...
And of course there‚Äôs also the problem of other effects in later steps that should not occur.
what's go?
A newer, garbage-collected, C-like language. I think it's supported by Google a bit. ESR likes it for anything where the memory-management in C is unreasonable to do accurately manually. Most notable (to me) for [only providing generics to Canadian first peoples](https://www.reddit.com/r/rust/comments/5penft/parallelizing_enjarify_in_go_and_rust/dcsgk7n/).
I remember the previous discussion, but it's archived now. If the OP wants to discuss the issue (which is on-topic for the sub), they have to create a new thread.
&gt; which will often be unhelpful. Odd, I've always found those helpful when bisecting. While I suppose the relevant merge-to-master might also be helpful, I prefer the small, branch commit instead of the potentially large merge-to-master because smaller commits are generally easier to analyze. That said, ff-only is fine strategy for small-ish teams. (If you've got 10k people that can merge (ff-only) to master, they'll spend more time rebasing on current master and re-running tests than writing code.)
Funny you should ask: https://www.usgo.org/what-go. It a fun strategy game.
Though I haven't looked closely enough at your concrete problem to know exactly how the following would affect it, there is one important thing worth noting about `hylo` and performance. If we were to write `hylo` as the straightforward composition of an `ana` and a `cata`, we would end up with: hylo f g = h where h = c . a a = embed . fmap a . g c = f . fmap c . project If we expand `c . a`, something interesting reveals itself: h c . a f . fmap c . project . embed . fmap a . g f . fmap c . fmap a . g f . fmap (c . a) . g f . fmap h . g The "leaves" can be consumed on the fly, as they are generated; that being so, we don't have to actually build the intermediate data structure. The definition of `hylo` in *recursion-schemes* exploits that: hylo :: Functor f =&gt; (f b -&gt; b) -&gt; (a -&gt; f a) -&gt; a -&gt; b hylo f g = h where h = f . fmap h . g Note how the intermediate data structure doesn't show up explictly. This trick is not possible with a metamorphism.
He didn't claim it was monads. This other blogger did, and they are wrong.
&gt;As far as I can tell, no significant deep intrinsic value has been demonstrated, only a minor added convenience for a small subset of users. This original question is still (imo) unanswered, which is why I'm having a hard time understanding *why* this is considered a "handy feature" that makes it worth having implemented by default and with no apparent notice in the `CHANGELOG` for `cabal-install-2.2` (as /u/vaibhavsagar notes below). It feels as if a few people are saying "This is a useful feature!" and a larger component of the community is responding with "Actually, no this feature doesn't seem to be that useful, I don't really care for the added complexity that it entails.", and the latter group is being ignored.
Hm, that quoted explanation is dubious. You see that sort of thing as a way to trick ghc to inline a recursive function (the `cata` above is not recursive by this definition; it's really kind of a hack...), often so that it will be specialized and possibly fire other rules as well. Another thing to keep in mind: ghc will only inline functions that are syntactically "fully applied". That's why you see the other hacky approach of doing `funcIWantInlined a = \b c -&gt; ...`
As far as I can tell the entire purpose of this "feature" is to allow a small subset of people to avoid typing the word cabal sometimes.
I fell in love with the "Get Programming with ..." Manning book series. Easy to read, beautiful structure and a lot of examples to play with it.
The situation I'm thinking of is when a feature wasn't even introduced yet on the merged-in branch. I think you can typically just mark those commits as good, but it's not obvious. (At least to me. Maybe someone who understands bisect more deeply would find it obvious.)
Awesome. Thanks so much for the effort here
Since it was an experimental feature, couldn't the default have been changed when this post was originally written last year? It's strange to argue that the default is both important and not important at the same time. It's not just about adding a line to one file: I can't in good conscience provide instructions for using the `new-*` commands without first checking that the recipient of these instructions has the correct options set, in which case it's easier and more consistent to also not use them myself. I also use &gt;1 laptop, set new ones up relatively often, and would need to sync my `~/.cabal/config` between all of them or get bitten by this when I least expect it. This default changes using `cabal-install` from a pleasurable experience to an obstacle course that I (and others) have lost hours to. Defaults matter!
&gt;Because its not the existence of this feature that's the problem -- its getting all the tooling to catch up to it You could argue this about any feature, e.g. a hypothetical `cabal nuke` command that deletes your home directory. In that case, the correct tooling response is to *avoid invoking it at all costs*. The bar for including a feature has to be higher than this.
Can you explain how they are wrong?
So I've just written a hylo version which seems to do ok: import qualified Data.Map.Strict as MS import qualified Data.Functor.Foldable as RS import Data.Bool (bool) -- Algebra to transform a list of Maybe as into list of as, by dropping Nothings and unwrapping Just values. stripNothings :: RS.ListF (Maybe a) [a] -&gt; [a] stripNothings RS.Nil = [] stripNothings (RS.Cons Nothing acc) = acc stripNothings (RS.Cons (Just a) acc) = a:acc -- Coalgebra where the seed is a list/map pair. buildList :: Ord k =&gt; ([(k,v)], MS.Map k [v]) -&gt; RS.ListF (Maybe (k, [v])) ([(k,v)], MS.Map k [v]) buildList !([], m) = bool (RS.Cons (Just (MS.elemAt 0 m)) ([], MS.drop 1 m)) (RS.Nil) (MS.null m) buildList !(!(k,v):xs, m) = RS.Cons Nothing (xs, MS.insertWith ((:) . head) k [v] m) -- hylo after pairing our input list with an empty map to provide the initial seed to the coalgebra. listViaHylomorphism :: Ord k =&gt; [(k, v)] -&gt; [(k, [v])] listViaHylomorphism = RS.hylo stripNothings buildList . flip (,) MS.empty The main difficulty when I first thought about implementing this with a hylomorphism is that an unfold is going to be building a level of our structure in each step of the coalgebra, e.g., if we have b -&gt; ListF a b ... you have to provide Nil or Cons a. Nil only makes sense for the bottom case because it ends the corecursion by not providing a new seed, so I thought it might make sense to use Maybe a as the Cons value: we use Nothing whilst we're going through list elements (which can then be stripped out during our fold), and only add the (k, [v]) values once the list is empty by popping them off the map and wrapping them in Just constructor. Can you please run benchmarks with this function and the metamorphism one and let me know how they performed against your reference implementation? Genuinely curious to find out which solution is the clear "winner", if any. Thanks!
The worst language to gain mainstream adoption since PHP.
Currently I write Java for a living. Oh, I don't enjoy it, and think that many aspects and the ubiquity of Java is a malice. However, package imports are fully automatically handled in my IDE. The only thing I want to say: it **can** be done.
Maybe I missed something but that method used side effects. &gt; Landin relied on call-by-value But this bit confuses me. &gt; [...] and hence does not depend on the choice of call-by-name or call-by-value strategy.
A language similar to haskell in some ways: * records and traits instead of inheritance * green threads * garbage collected * compiled * binaries include runtime * high level but performant (go probably more performant) However, wildly different goals: go was created to maximise productivity in Google, which makes it very boring, while haskell was created as a research language, and is packed with all kinds of bells and whistles to learn about. Haskell‚Äôs type system is also very powerful, while Go‚Äôs is comparatively quite poor. 
I'm hoping for a [MMark and Reflex](https://github.com/mmark-md/mmark/pull/61) post.
I know. I've used TypeScript and it has great tooling.
How does this package compare to [bv](http://hackage.haskell.org/package/bv) or [bv-little](http://hackage.haskell.org/package/bv-little)?
I am not well acquainted with these packages, but at first glance neither `bv` nor `bv-little` provide `Vector`-instances. Having `Vector` instances in `bitvec` allows you to use all `vector` API and utilities for free.
I don't think this isn't an accurate to say Go was designed for productivity and Haskell wasn't. All the bells and whistles Haskell has are there for productivity. Even in this case the code becomes simpler is you use an actual monad. Go was design not just productivity but also for use in huge teams. Additional goals were simplicity and minimizing the learning curve so developers could be on-boarded quickly. That's why the language is so simple. I think it's a shame that Go is being used by a lot of startups and small teams. These teams would benefit from using a language that can offer more features so they could outpace teams using Go, Java, or C#.
&gt; The idea was to have something like Conduit but that could run a DAG. [`machines`](http://hackage.haskell.org/package/machines) also supports that use case, but is much more complicated! Part of the complexity lies in allowing the user to carefully specify the order in which the events are consumed. In which order does your solution run the handlers? There are many mays to topologically-sort a DAG, is it the responsibility of the user to make sure that as long as their `m` effects are executed in some topologically-sorted order, the end result should be the same?
Thanks for your efforts! Is this going to end up on Hackage?
It is a language from 10 years ago that pretends nothing happened in type checking [since 1968](http://cowlark.com/2009-11-15-go/) other than garbage collection and structural typing.
&gt; I tried to put full effect list into each action on the level of action itself and on the level of sum type (which I use internally) and couldn't do it, due to types/kinds becoming recursive. Hmm, I tried that too recently and it worked fine, can you give more details about the problem? Some differences which may or may not be relevant: in my prototype, I didn't bother with a sum type, and I used data Freer g a where Pure :: a -&gt; Freer g a Bind :: g (Freer g) a -&gt; (a -&gt; Freer g b) -&gt; Freer g b Instead of the `forall m. Monad m =&gt; ...` encoding. 
If you make `data Throws effs a`, then try put those in a typelist, then GHC will yell that `unable to construct infinite type f0 ~ [Throws f0, Env e, ...]`, or something like that. This encoding looks a lot like `Coyoneda`. Hmm, its maybe worth to try, thanks! How do you combine several types of actions into one?
Already there. http://hackage.haskell.org/package/bitvec
I usually control the systems I deploy to, so I just `nix copy` to them. Otherwise I'd probably read your notes and do similar to what you've done :)
After staring at your code for a minute, I was able to solve the problem: now effects are `(Type -&gt; Type) -&gt; Type -&gt; Type`, where first argument is `Effect effs`. Therefore the type cycle is broken and I write actions as: ```haskell data Throws m (a :: Type) where Raise :: Exception e =&gt; e -&gt; Throws m a Rescue :: Exception e =&gt; m a -&gt; (e -&gt; m a) -&gt; Throws m a ``` and implementations are _required_ to take an "intepreter of everything" an argument. If you're interested, I've updated the [example](https://bitbucket.org/heimdell/yo/src/master/src/Control/Effect/Example.hs).
Looks like you and I are thinking about [similar things](https://github.com/isovector/polysemy)! I've got the higher-order effects and performance figured out, but still working on making it freer. Interested in teaming up?
I think your point was contained (in small part) if we read it "created to maximize (productivity in Google)" rather than "created (to maximize productivity) in Google"
Good point!
Im a beginner Haskller and currently trying to scrape some wiki page, but unfortunately I'm a bit stuck. I want to extract everything I can from some info-box. for example: `alias 1 &lt;br&gt; &lt;sup&gt;...&lt;sup/&gt; &lt;br&gt; alias 2 &lt;sup&gt; .. &lt;sup/&gt; &lt;br&gt;...` Furthermore I am using scalpel-core and Wreq, and working with lazy bytestrings. Can you forward me to some place where I can learn how to extract \[alias 1, alias 2 ..\]? 
Ah yes, I see where that thinking will be bad. That definitely does help a bit. Thank you! I'm a bit slow, I need to do some further Haskell reading, lol. 
Okay great, I'm glad that I have this one down at least!
It's still a monad, just not exactly the `Either` monad.
It's starting to click a little more for me. This is a comment that I'm definitely going to come back to after some further reading. Thank you for all your help! I really appreciate it :)!
See also https://hackage.haskell.org/package/array-0.5.3.0/docs/src/Data.Array.Base.html#line-500
Evidence that natural language is not associative
The handlers are called in the same order as they are added, if many handlers are listening for the same type. Regarding ordering, i suspect that if you have that issue, that you can use additional types to trigger some handlers before others, and if you still have that issue, then the DAG is probably the wrong tool for the job. The advantage - and the disadvantage - of a dag is that it provides loose coupling. In my case this is appropriate because my application needs a small data pipeline and I don't want to keep rewiring all the inputs and outputs manually, the event model is much more appropriate. But it's a tradeoff; in this case, events are dispatched top down, and the type system cannot provide you with any guarantee that you will get `n` outputs of a given type. You will get `&gt;=0` outputs of any output type, that's all you can know at compile time.
Ya so you could implement it for finite lists :) 
Sure, bisect is cool, But, often it's not given all the good/bad information that might be available to the developer using it. A linear history maximizes the amount of information that marking a single commit as good/bad gives.
\&gt; The idea was to have something like Conduit but that could run a DAG I just now notice that your example, &amp;#x200B; addHandler $ makeTestHandler A B 10 addHandler $ makeTestHandler B C 10 addHandler $ makeTestHandler C A 10 defines a cycle, not a DAG. How does that work, does that mean that this example runs forever?
has it replaced any C-language projects at google? i heard some small very part of ChromeOS might be getting ported to Rust (from C, obv), but haven't heard about anything performant being ported to Go.
&gt; The idea was to have something like Conduit but that could run a DAG I just now notice that your example, addHandler $ makeTestHandler A B 10 addHandler $ makeTestHandler B C 10 addHandler $ makeTestHandler C A 10 defines a cycle, not a DAG. How does that work, does that mean that this example runs forever?
I just use \`nixops\`. 
I don't follow it much, I'm just aware of it.
No, that example is testing that the code that builds the dispatcher detects the cycle (\[here\]([https://github.com/libscott/feather/blob/master/src/Feather.hs#L138](https://github.com/libscott/feather/blob/master/src/Feather.hs#L138))). If it didn't, then the call to \`addHandler\` would run forever, you would never get to call a dispatcher at all. A dispatcher closes over a list of it's downstream handlers and simply calls each of them whenever a value is yielded. When a handler is added, re-build is triggered recursively upstream. The readme has an example.
Ah, I hadn't noticed the readme. It says: &gt; dispatch &lt;- getHandler &gt; put $ error "will not be reached, because dispatch\ &gt; \encapsulates the whole downstream DAG" &gt; dispatch (1::Int) But I don't understand what "encapsulates the whole downstream DAG" means. It looks like it says that the `put` line is never executed, but that makes no sense, otherwise the `dispatch (1::Int)` line wouldn't be reached either and there would be no input. So is that instead saying that `dispatch` never returns, like `forever`, and so `runState` never returns either?
Yep, good old `array` is also memory-efficient for `Bool`. But I usually choose either `vector` or `primitive`: there is a relatively narrow spectrum of tasks which need something in between, like `array`.
Correct me if I am wrong, but `bv` and `bv-little` are for immutable bit-vectors only, while `bitvec` provides an interface to mutable as well. 
&gt; The handlers are called in the same order as they are added Good, that sounds like a very well-defined ordering! &gt; if many handlers are listening for the same type. Oh. But what about the handlers for different types? I am guessing that the order is as follows: the events are handled depth-first, in the sense that if one particular handler triggers an event, that event will be handled immediately, and the events generated by its handlers will be processed, etc., and only after all the consequences are dealt with will that particular handler have the opportunity to trigger another event. I am not a fan of that particular ordering (It's the same easy-to-implement but hard-to-think-about event ordering which observers use in OOP languages. By contrast, FRP provides a hard-to-implement but easy-to-think-about event ordering), but at least it's well-defined! &gt; But it's a tradeoff; in this case, events are dispatched top down, and the type system cannot provide you with any guarantee that you will get `n` outputs of a given type. You will get `&gt;=0` outputs of any output type, that's all you can know at compile time. That's fine, `conduit` doesn't guarantee anything about the number of outputs either. To clarify, I am asking for predictability, not type-level guarantees. For example, `putStrLn "foo" &gt;&gt; putStrLn "bar"` and `putStrLn "bar" &gt;&gt; putStrLn "foo"` have the same type, but they execute their effects in a different order, and it's very easy to predict what that order will be.
No, the `put` is executed, the error never happens. The dispatch function returned by `getHandler` passes the arguments to all listeners of that type, which are also provided dispatchers for their output type, and so on. When `addHandler (handle :: EventHandler i o m)` is called, the following happens: * All listeners for type `o` are fetched from the state. * A new listener that closes over `handle` and it's downstream listeners is added to the state. * The build function for all handlers that output type `i` are called; this process recurses upstream, and updates each of the associated listeners to include the new downstream handler in their closure. After this process, if you fetch a dispatcher for a given type, it never needs to reference the event state, or do any lookups for other listeners etc. You can think of it as a single pure function. At that point there is no intermediary representation for the event graph, it's just a single recursing closure starting for a dispatcher of a given type. However, if there were an IR, it would look something like: ``` data Dispatcher i o m = Dispatcher { handler :: EventHandler i o m , downstream :: [DownstreamDispatcher o m] } data DownstreamDispatcher i m where forall o. Typeable o =&gt; Dispatcher i o m -&gt; ClosedDispatcher i m ``` I'm not sure how interesting this really is, but I hadn't seen anything that uses this technique before, hense posting about it.
I use "cp". It works flawlessly 
How do you compile the binary?
\&gt; By contrast, FRP provides a hard-to-implement but easy-to-think-about event ordering), but at least it's well-defined! Would that be that all event dispatch is asynchronous, and there is an event loop that is repeatedly running queued events in the order that they were added? So I suppose that might be something more like breadth first. Or something else? But yes, it's depth first, I did have a queue at one point but I didn't need it, and basically all other needs can be layered on top anyway; adding events to a queue for processing (there is no event loop), per-handler state, using conduits / coroutines... I think it would also be quite easy to parallelize using MVars.
mmm, lately, in a docker image running out in a cloud IDE. I download the binary from the web interface in every computer and voila!. 
tnkx
Ok thx
&gt; Would that be that all event dispatch is asynchronous No, asynchronous event handlings would make the ordering even harder to think about, since it would be non-deterministic. FRP has a notion of time, and has well-defined semantics for what it means for two events to occur at the same time and in which order the events will be processed if they do. One big difference though is that in FRP, the nodes are not typically allowed to perform effects at all, only values. That makes things a lot simpler!
Haskell was designed to accomodate reaearch into functional programming. I think that if it‚Äôs productive to work in then that serves to demonstrate the value of the experiment, to the limited number of people who choose it. But it wasn‚Äôt a direct goal afaik. With Go, it very much was.
Oh i see. Im in favour of the nodes being pure. Where could i read about FRP event ordering?
You can pass the flag explicitly to the new-* commands if you want to put it in your instructions. and in general, having a properly configured cabal/config is important for many reasons.
It is a useful feature because it means you can use _all_ the features of ghc (not just interactive mode) seamlessly in a project directory, just as you had with old-style commands. It actually helps _decouple_ people from cabal, because it lets cabal setup and configure a build, and then _get out of the way_. This matters especially not just for end-users, but for some external tooling that works _better_ with this workflow, because it need not worry about doing special invocations of cabal to get the "right" slice of the package-store into scope. Instead it can just make use of the env-file functionality directly. Having these env-files is very important. Having them in a location where they're automatically picked up by ghc and ghci obviously has pros and cons -- but having them around at all records important data that would otherwise be lost, and enables integrations that are otherwise difficult-to-impossible.
[removed]
I think "frp glitch" might be a good keyword to find some resources on that
I've been using ```zsh rsync -av $(nix-store -qR result) root@dest:/nix/store ``` There's also some funny business that needs to happen in /etc, plus a symlink to the active closure so it knows what code to run. So I just rsync them, too. It means I get a bunch of rubbish in /nix/store from older versions, with no obvious way to rollback (which hasn't ever been necessary) since rsyncing the symlinks squelches any indication of the previously active version.
Yes, I tried debBuild using cabal but couldn't find a way out on the internet for the cabal update / cabal install (I tried to add a network card to the qemu VM but couldn't). But I can create a deb automatically with the static binary I generated. (Which is the same thing)
Having a low-level tool like `ghc` operate in this manner honestly does not make any sense to me, and I don't think I'm in in the minority here. If `gcc`, `clang`, or `rustc` were to have added behavior like this people would be justifiably quite confused and upset when it started breaking their workflows. This comment thread and as a fair number of responses to this issue on the mailing list seem to indicate that there's just not a large number of people who think this is a good *default* to have in place. Quoting another commenter from this thread (/u/Hrothen): &gt;As far as I can tell the entire purpose of this "feature" is to allow a small subset of people to avoid typing the word cabal sometimes.
Consider the following statement, deliberately phrased similarly to yours: "In general, having defaults that conform to what the 'average user' might expect is important for many reasons." I think this is the situation we're finding ourselves in here. There is an expectation of behavior that most users have for `cabal-install` and `ghc` based on their own past expectations as well as the way these tools exist with respect to their counterparts in other language ecosystems. Violating these expectations is very dissonant, especially when the it is on both fronts (e.g. this affects people with a lot of experience in the Haskell ecosystem as well as others). IMO, any change that results in such a violation of these "accepted norms" should be done carefully and with a lot of community feedback/interaction to limit the negative impact that they can have. It appears that this feature was implemented without collecting significant feedback and/or advertisement, and so you are seeing a viscerally negative response from people who that they were not sufficiently involved or informed.
Just had a chance to put both those in the benchmarks. They are both extremely close to Data.Map.Strict.toList . Data,Map.Strict.fromListWith (&lt;&gt;). Reference: 13.36 ms listViaMetamorphism: 14.09 ms listViaHylomorphism: 13.89 ms Which is cool! I'm still not clear on whether these variants actually build the map. If they do, I wonder if there's a way not to? Anyway, I'll look at the core more later. I just had a few minutes now to throw them into the benchmark suite. Thanks for providing them! 
I don't see any functions for thread-safe updates. Am I missing something? If not, those should surely be offered as well. It might even make sense to offer two types: one for single-thread access and one for multiple-thread access, perhaps using a `newtype instance` for the latter.
I just explained what the purpose of the feature was. And it has very little to do with typing the word "cabal" and everything to do with letting any tooling besides cabal use the package store in a meaningful way, for which some listing of the appropriate slice of the packet store, and the ability for ghc to index into it is _absolutely essential_. I don't really care under exactly what situations the defaults do or don't do whatever. All I'm trying to explain is why environment files, in some form, are absolutely essential.
The counterargument is that the expectation of behavior is that once you've built something, then ghc should let you interact with it. This is also something users came to expect. The process of thought that led to these defaults was precisely that it was good to preserve this behavior and that it would violate expectations less than the alternative. Obviously, some people disagree. Hence, after precisely the discussion that we're having, which _is_ the community feedback you keep complaining we didn't have (and which _is_ why it was turned on in the _experimental_ phase of new-build -- precisely to garner such feedback), now it is being turned off. I'm happy to have a nice discussion over this. What I don't like is the complaint that a process of development that deliberately solicited feedback on an experimental workflow was a problem. If the feature wasn't turned on, then people wouldn't have given it a workout. What we're doing is called learning from experience and discussion, and the negativity here is really unwarranted, hurtful, gratuitous, and downright mean. People need to learn to have discussions without being such jerks about it.
I think Go has generics now, or at least the proposal was accepted. It's developed primarily by Google
It hasn't replaced anything because Go is basically not optimized at all to give faster compilation times
I've been trying to go out of my way to be unambiguously polite and careful to avoid phrasing things in such a way that I am *not* calling individuals out, but rather trying to explain how I believe this feature could have been implemented in a way that had negative consequences without being ill-intentioned. What I mean to point out is that threads like this one, like the [recent mailing list thread](https://mail.haskell.org/pipermail/ghc-devs/2019-March/017351.html) discussing [Matthew Pickering's PR](https://github.com/haskell/cabal/pull/5985) to revert this behavior, and like the [GitHub issue thread](https://github.com/haskell/cabal/issues/4542) that discussed adding a flag to opt-out of this default behavior are a strong signal that this is an extremely contentious feature with quite a bit of negative impact to users, and that its development could have been handled in a way that worked to gather and incorporate feedback _before_ it was implemented. --- &gt; What we're doing is called learning from experience and discussion, and the negativity here is really unwarranted, hurtful, gratuitous, and downright mean. I really don't know how to respond to this except by saying that I've earnestly tried to avoid phrasing that would call out individuals so that no one would feel as if my words were targeted at them, but rather at the process that I believe has led to this situation.
Go is popularly used for "servers" rather than "applications" so it's usually not very visible.
https://golang.org/doc/faq#generics and https://github.com/golang/go/issues/15292 (still open)
No; because lazy;`Left "foo" &gt;&gt; (Right "x" &gt;&gt; Right "y")` doesn't actually check to see if `Right "x"` is a left or a right.
Haskellers already knew that. We "avoid (success at all costs)" not "(avoid success) at all costs".
&gt; this is an extremely contentious feature with quite a bit of negative impact to users, and that its development could have been handled in a way that worked to gather and incorporate feedback before it was implemented. This is asking for 20/20 foresight. It was not expected it would be contentious. It was discussed and implemented in, again, an _experimental_ feature as a whole (the entire new-* thing, that is), with the explicit purpose of _getting_ feedback. The response of a few people has been to get extremely angry, almost immediately, that something which was put out for the purpose of soliciting feedback was done without _first_ consulting them. There have been like three rounds of improvements to this stuff already, resulting in better and more granular control each time. But rather than recognizing that devs are making a genuine effort to understand arguments, the response to a request that feedback be _constructive and helpful_ is essentially along the lines of "here's some constructive feedback: you suck." Even you, elsewhere in this thread have been playing that game, insisting that no motivation was ever provided for why environment files are useful, when such motivation has been given repeatedly. The problem is that to have a good discussion, we always need to recognize that a variety of needs and workflows exist, and we need to serve all of them. The response of some people has been to insist that anything which does not suit their current workflow is just useless junk. This doesn't lend itself to a productive exchange of ideas, because it doesn't help lead us to a situation where everyone's needs are serviced. Even now when we're in a situation where there's agreement, currently, that the default be changed (which was the case when this thread was started!) people still decided to dogpile this thread full of vitriol about how much they hate env features and how terrible they thin devs were for implementing them. Why? I mean -- you got what you wanted! The default is changed! Like... cheer up and chill out! The process works. (And would work better and more efficiently if everyone was more cheerful and chill to begin with, instead of upping the volume to 11, which just makes it harder to hear. Being a jerk might be satisfying, but it does not result convincing people, just browbeating them and making them feel miserable and resentful.)
But what was the goal of that experimentation? Isn't the goal programming research ultimately productivity, safety, and efficiency?
I'm going to be as direct as possible here, since we've spent quite a bit of time going back and forth on this: * None of my feedback has been "you suck" * I've gone out of my way in multiple comments to avoid saying things that would be construed as direct attacks on individuals * You are now (indirectly) calling me a jerk, after (indirectly) saying that my comments have been "unwarranted, hurtful, gratuitous, and downright mean" * You are misconstruing peoples' takes on the situation when they have attempted to clearly their reasoning beyond subjective preference * "The response of some people has been to insist that anything which does not suit their current workflow is just useless junk" * cf. /u/vaibhavsagar and /u/taylorfausak in this thread, and /u/ElvishJerricco in a previous thread for examples of people who have emphatically *not* responded this way * You claim that this thread has been a "dogpile" that is "full of vitriol", but I mostly see people taking this as an opportunity (as they did in other threads previously) to once again *express why they dislike this feature* because *all of the developer comments* have made it clear that it will be turned on again in the future * If the developers of these features are going to interpret honest feedback given in good faith this way, it creates a chilling effect that makes people feel uncomfortable with the prospect of providing any feedback at all
Sound fun. Just don't expect me to work N hours per day - I usually do things when I have mana for them. Do you have any docs/wiki/description of your architecture?
`&gt;&gt;` is left associative, so this isn't the case in original example
What exactly are you trying to do? It is not clear to me. If you want to add additional packages to be available in 'cabal new-repl' you do: cabal new-repl --build-depends &lt;pkg&gt; If you want to overwrite a dependency with a version from github, write in cabal.project (or cabal.project.local): source-repository-package type: git location: https://github.com/abc/def tag: 38923893298329823 If you want to overwrite a dependency with a local version, you just add the directory to the 'packages' stanza in cabal.project: packages: ./ ./3rdparty/some/other
I wasn't just talking about you. I was talking about the feedback as a whole.
I think you meant "yes"
The issue you linked to is an _open_ ticket. It is an idea that nobody has implemented. The way maerwald describes should work for you. In general, adding packages to your cabal.project or cabal.project.local should be straightforward.
I always miss rank/select queries in every bit vector implementation. Will this library support this kind of operations?
You could use extensible records to store interpreters. [extensible](http://hackage.haskell.org/package/extensible) provides one based on GHC's SmallArray, which should be quite efficient. You could define `Dispatch` as ``` newtype NT g f = NT { unNT :: f ~&gt; g } newtype Dispatch effs m = Dispatch { unDispatch :: NT m :* effs } ``` extensible also has its own extensible effects implementation, though...
This story is very daunting. The optimizer should not be blackbox, but in reality it is always the case. What would the best way for the optimizer to provide feedback to the programmer?
Does `vector` offer thread-safe updates?
I use ghcid and it's really awesome, you should check it out https://github.com/ndmitchell/ghcid https://www.parsonsmatt.org/2018/05/19/ghcid_for_the_win.html
vector writes one byte when it needs to update a single boolean. with packed representation you need to write (at least) a byte with new bit updated and old bits preserved.
I too am a Spacemacs user. Is the Spacemacs' Haskell layer features not good enough? I use [Haskell layer with flycheck enabled](http://spacemacs.org/layers/+lang/haskell/README.html#flycheck) and that works well enough for me most of the time. Maybe you haven't turned on `syntax-checking` in your spacemacs dot-file? Once flycheck is on, I just hit `Space e l` (or as I remember it, Space, **E**rror, **L**ist) to see the list of errors. You can click on errors to go to them, or you can hit "Space Error Next" (`Space e n`) to jump to the next error, and ofc `Space e p` to go back.
I'm kind of stuck in an intermediate rut (both Haskell, and in general). I've been a solid, intermediate-to-senior, backend web developer for a few years, and I'm having trouble growing past that. Some of the problem is developing new skills, and some of it is convincing people to hire me for something challenging instead of something I can already do easily. I'm halfway to burnt out and not really sure what I should be working on anymore. Does anyone want some help on an interesting project in exchange for some mentoring? Or have any suggestions for projects/courses/etc to both "level up" and *prove* it? 
I was thinking more along the lines of type checking (you know, making sure that the entire program compiles - e.g. if I change a type in Foo.hs which Bar.hs relies on, then upon saving Foo.hs I'd like to jump to Bar.hs's error). From reading the documentation I get the sense that flycheck/hlint/... the spacemacs layer built-in features focus on the local file instead of the global build. Is that fair to say or am I underestimating how far flycheck gets you?
I'd just prefer we come to an agreement on how these things should look, rather than hitting hackage with two more free monad packages! No hours necessary, other than discussion and (hopefully!) consensus!
One have to explicit. Is \`update\` bare \`write\` or \`read-write\`, i.e. \`modify\`. e.g. \`unsafeModify\` isn't thread-safe in \`vector\`: [http://hackage.haskell.org/package/vector-0.12.0.2/docs/src/Data.Vector.Generic.Mutable.html#unsafeModify](http://hackage.haskell.org/package/vector-0.12.0.2/docs/src/Data.Vector.Generic.Mutable.html#unsafeModify) And as \`bitvec\` relies on \`vector\` machinery, it cannot be better. &amp;#x200B;
Ok so I think the best way to do this is to use ghcid as /u/splurke said. I've just got a few more things to add on that matter: ## Installing ghcid properly Assuming you're using stack: install ghcid *relative to your project's compiler* by runnning `stack build ghcid --copy-compiler-tool` in your project. `--copy-compiler-tool` will allow you to access ghcid with `stack exec ghcid` but only in any project using the same GHC version, letting you have multiple ghcids installed to avoid having to overwrite a global install every time you switch between projects with different versions of GHC. ## Viewing ghcid in spacemacs You can pop open a new spacemacs window below your current one and then open a shell buffer in it, then run ghcid in the shell. Shells can be accessed with `space a s &lt;something&gt;` (Space Application Shell &lt;Something&gt;). Now if like me you enjoy pain and suffering and that's why you develop in Haskell on **Windows**, you can get a Powershell buffer by adding the `windows-scripts` layer to your dot-file and then using `space a s p`.
 &gt; Most notable (to me) for only providing generics to Canadian first peoples. Generics are in go 1.13. https://stackoverflow.com/questions/55451423/how-to-use-the-new-generics-feature-in-golang-1-13 (Although they no longer work as of 2nd of April.) 
The built in Haskell layer does this if you pick Intero as the completion backend (see the layer documentation). Yes it also works across modules.
Edited for clarification.
Ghcid or stack build --file-watch
What have you tried? I've never used scalpel-core, but it seems to have all the primitives I would need to accomplish that task. Are you familiar with Applicative and Monad? Those appear to be the primary way to combine scrapers.
The idea was to make an effect system with the least amount of dependencies, providing minimal API. The storage is not a problem, I use `Any`/`unsafeCoerce` under the hood to store interpreters in the array. Since I only read from the array, `SmallArray` will add no benefits for me here.
Could you please elaborate what kind of queries we are talking about?
Could we just not create the env files by default? I agree it's a cool feature; I use pyenv and virtual environments for python all the time, and it's nice that when I'm in the directory of a particular project then all my tools are pulled from that project's environment. But, creating a virtual environment, and setting it as default for this shell / directory are *both* manual actions with pyenv. I don't know that is optimal, but it is, at the very least, less surprising. I honestly think that if creation of the env files was more explicit you'd have much less confusion and complaints.
Rank and select are basic operations used to implement succinct data structures, the primary applications of bit vectors. [https://en.wikipedia.org/wiki/Succinct\_data\_structure#Succinct\_dictionaries](https://en.wikipedia.org/wiki/Succinct_data_structure#Succinct_dictionaries) &amp;#x200B; *rank\_1(i)* counts the number of 1s in the first *i* bits, and *select\_1(n)* finds the index of an element which is *n*th occurrence of 1 (in other words, it finds *i* that satisfies `rank_1(i) = n`
&gt; Having a low-level tool like ghc operate in this manner honestly does not make any sense to me, and I don't think I'm in in the minority here. I'm actually fine with building this into ghc and other tools. In fact I think it makes good sense. With pyenv, I know that the tooling doesn't have support for the virtual environment as much as the virtual environment have support for some tools. I.e. pyenv manipulates your shells $PATH to point toward small "shims" that invoke the underlying tools differently to "keep them in" the virtual environment. It think it's also "aggressive" at creating shim for any binary that's installed via pip. I'm not sure that's optimal. I certainly know that I've run into edge cases where I was using a tool that pyenv hadn't (yet) shim'ed so it was operating outside the virtual environment and giving confusing results. I think it's worth it to have ghc, ghci, etc. be context sensitive in this way -- using environment files -- at least by default. Compiler-as-a-pure-function hasn't been true in a long time, if ever, and I think cleaving too much to that ideal is not the best UX. I wouldn't consider ghc a low-level tool ever since `--make` mode came in, and certainly not since it became the default.
I'm not opposed to this way of working, though my experience with `pyenv` makes me feel there might be advantages in have `ghc` / `ghci` be context-sensitive by default.
I'm not opposed to it in principle either. The difference is that `pyenv` is opt-in. You have to manually set up your system to work that way. 
I‚Äôm not sure one could do it with single pass with Applicative. It feels that Monad is too strong of requirement though.Is Selective https://www.staff.ncl.ac.uk/andrey.mokhov/selective-functors.pdf enough?
Before this discussion even started, it was already agreed to change the default to not put them in a location where they're picked up. Which is why I've been so confused by the nature of this discussion! Everyone seems very angry about something. But people already agreed to not do that something. So I don't know why people are so vituperative in their comments!
I can't speak for anyone else, but I'm a little agitated because of comments like [this](https://github.com/haskell/cabal/pull/5985#pullrequestreview-223232990): &gt; While I still consider most of the arguments brought forward for changing the default to be weak and in some cases even irrational, and I therefore remain unconvinced by those, I'm willing to reconsider the default setting for the upcoming 3.0 release That makes me feel like the default has been changed begrudgingly and will be changed back at the first available opportunity. I don't want that to happen, so I'm being vocal about it. 
Just so future readers are aware, this comment was edited substantially after it was initially written and replied to. If the replies don't make sense in context, that may be why. Unfortunately I did not save the original version of the comment, even though I know HVR routinely edits comments like this. 
That image is very difficult to read, but something to get started chewing on would be `sum $ concat $ map (\x-&gt; [1..x]) [1..10]`. My stock suggestion when you're just getting started in haskell is always to write a solution recursively and then try to improve it by using standard higher-order functions.
All it says is that someone is willing to make changes out of respect for the workflow preferences of others even if they don't fully make sense to them. You seem to be complaining that you not only want agreement in practice, but you want to browbeat people into sufficiently _enthusiastic_ agreement. I don't think that's a good way to proceed.
http://chrisdone.github.io/intero/ It's not as heavy as a `stack build`, but it gives you all the info a stack build would do. 
The equivalent of \`\\Sigma\_{i=0}\^n i\*i\` (sum the squares of the numbers from 0 to n) is \`sum \[i\*i | i &lt;- \[0..n\]\]\`. The keyword for this notation is "list comprehension".
I appreciate that you have answered me , thanks ! I've managed to get to the page by scraping a page with a lot of links: `charLinksScraper = chroots ("div" @: [hasClass "mw-parser-output"] // "ul" // "li") $ attr "href" "a"` I've planned to run for each page some scraping in order to create a list of characters. In order to get the name I haven't face difficulties either: `getName = chroot ("div" @: [hasClass "mw-body"]) $ innerHTML "span"` to extract from the above's output I've gotten the `&lt;tr&gt;` tag inside of a specific `&lt;table&gt;` Now to my attempt parsing out the aliases: I've tried to extract from this `&lt;tr&gt;` object the html and see if I can drill further but I didn't have any tag to use. I thought I might be stuck and the library doesn't provide a way to get further information, at this stage I tried to get the text inside, which gave me all aliases inside a string where some were separated by spaces and some were not separated at all. "alias1Alias2" I thought about separating the words by capital letters, but some aliases are composed from several words with a capital letter each. at this point I thought about python where I know how to parse the strings and grab the wanted words. (but I wanted this small project to be purely Haskell) I know that Haskell should be good at parsing\\ creating parsing but I'm unsure how to approach this.Another problem is that I've received from the Wreq library lazy byte strings, which I am not familiar with and am not sure how to process them. (I intend to make a read about them) I am aware of monad and applicative, not familiar with working with new monads which aren't defined in the prelude, and don't know the mathematical meaning behind them. 
That's what I do too, with a tiny addition, I keep \`\`\` stack build --test --file-watch \`\`\` running in a terminal on the side.
Aaand... note that we're hiring, including hiring one or more Haskell devs: [https://www.cloudseal.io/hiring](https://www.cloudseal.io/hiring)
Oh woops
Write the function that represents a partial sum, map that function over your domain, then sum the new list. Example: Sum of squares: square = (^2) sumOfSquares = sum . map square Sum of some weird function: myFunction n = (n + 1) * (n^2) - sqrt n mySummation = sum . map myFunction
&gt; `&gt;&gt;` is left associative, Sure, but do-notation naturally groups to the right: `do { x &lt;- expr; stmt }` = `expr &gt;&gt;= (\x -&gt; stmt)`.
The lazy bytestring API is darn near identical to the bytestring api, and with the exception of things that assume bytes=characters the bytestring api is fairly similar to the `[Char]` api. The `.Char8` packages even provide the functions that assume bytes=characters. If you don't want to learn a parser combinators library, split(At/With)/break(End)/span(End) can be stitched together into an ad-hoc solution, though anything complicated will devolve into your namesake. Some of the parser libraries might prefer lazy or strict bytestrings or vice-versa, but they are intra-convertable. There's plenty of parsec / attoparsec / megaparsec tutorials out there, and those are what I would use for parsing stuff -- I tend to default to attoparsec, but any of them should be able to do what you want. 
In which way is `array` "in between" `vector` and `primitive`? `primitive` looks like low-level stuff I'd never use, while `vector` and `array` are both high-level APIs which offer different features: `vector` offers a list-like API which gets optimized via fusion, while `array` offers `Ix`-based indexing, which is useful for e.g. 2D arrays.
I was trying to encode recursive types as described in [Recursive types for Free!](https://homepages.inf.ed.ac.uk/wadler/papers/free-rectypes/free-rectypes.txt). So far, I managed to encode the least fixpoint as `type Fix f = forall x. (f x -&gt; x) -&gt; x` and somehow convinced myself it works by writing down a few terms for an integer list: `data IntList a = Cons Int a | Nil` `type IntList' = Fix IntList` `(\f -&gt; f (Cons 2 (f (Cons 1 (f Nil))))) :: IntList'` However, I got stuck when trying to do the same with the largest fixpoint. &amp;#x200B; I defined the combinator as `type GFix f = forall x. (x, x -&gt; f x)` after doing some google search about existential quantifiers in Haskell. However, I wasn't able to construct any terms for a stream in a sensible way. Is my definition of GFix wrong or did I simply fail to figure out the right way to define a term for Stream? &amp;#x200B; Thank you
&gt; am I underestimating how far flycheck gets you? You're not. As far as I can tell, flycheck only checks the active buffer and will not help you with catching errors that occur in other files. Sometimes I use `ghcid` in a separate terminal, just to give me visual cues about which files still contain issues. Open the file in spacemacs, and go off of flycheck from there. I'm not 100% satisfied with this workflow, but it's decent.
I use [`hasky-stack`](https://github.com/hasky-mode/hasky-stack) for global error checking. Once I'm done getting the current buffer to check, I run `stack build` using `hasky-stack`, which gives me a buffer with the output of `stack`, along with jumpable error messages.
* Least Fixed Point: [Mu](https://hackage.haskell.org/package/recursion-schemes-5.1.2/docs/Data-Functor-Foldable.html#t:Mu) * Direct Fixed Point: [Fix](https://hackage.haskell.org/package/recursion-schemes-5.1.2/docs/Data-Functor-Foldable.html#t:Fix) * Greatest Fixed Point: [Nu](https://hackage.haskell.org/package/recursion-schemes-5.1.2/docs/Data-Functor-Foldable.html#t:Nu) --- Using Nu I can unfold a small list: downFromNu :: Int -&gt; Nu (ListF Int) downFromNu = Nu coalg where coalg i | i &lt; 0 = Nil coalg i = Cons i (i-1) --- &gt; downFromNu 5 fromFix (Fix (Cons 5 (Fix (Cons 4 (Fix (Cons 3 (Fix (Cons 2 (Fix (Cons 1 (Fix (Cons 0 (Fix Nil))))))))))))) However, using your GFix, I get some errors: &gt; :{ | downFromGFix :: Int -&gt; GFix (ListF Int) | downFromGFix n = (n, coalg) | where | coalg i | i &lt; 0 = Nil | coalg i = Cons i (i-1) | :} --- &lt;interactive&gt;:23:19: error: ‚Ä¢ Couldn't match expected type ‚Äòx‚Äô with actual type ‚ÄòInt‚Äô ‚Äòx‚Äô is a rigid type variable bound by the type signature for: downFromGFix :: Int -&gt; GFix (ListF Int) at &lt;interactive&gt;:(23,1)-(26,34) ‚Ä¢ In the expression: n In the expression: (n, coalg) In an equation for ‚ÄòdownFromGFix‚Äô: downFromGFix n = (n, coalg) where coalg i | i &lt; 0 = Nil coalg i = Cons i (i - 1) I think this is because all Haskell existentials have to be CPS'd, and the `type` isn't doing that, so your `forall` is being a universal, rather than existential, qualifier. But, I still have my own troubles with existentials, so I could be wrong. I recommend trying to switch to `data` (`newtype` doesn't allow `forall`, IIRC), maybe even using the GADTs+Record format, which I find a little clearer than the others. Once you get the existential encoding correct, I think you are there.
It was originally just the part before the "PS:", I think.
You can see how to use `smuggler` source plugin with `cabal`: * https://github.com/kowainik/smuggler#how-to-use Basically, you can pass plugin options as `ghc-options`. I guess similar can be done with `stack`. But that's true that in order to do this you need to tell your project somehow about the plugin. I think with `stack` you could build the whole project like this: stack build --ghc-options="-fplugin=GraphMod -fplugin-opt=GraphMod:out" --package graphmod-plugin However, `--package` option doesn't work to bring the plugin locally... Though, probably if you do `stack install graphmod-plugin` there is a chance this could work. 
That's probably it! My definition of GFix using type wasn't really existentially quantified and was only inhabited by (bottom, ....). With GFix defined using data I was able to implement the morphisms I needed. Also, thanks for posting the links. I've seen the concept "recursion scheme" a while back but didn't realize it was related to the notes I was reading. &amp;#x200B; &gt;because all Haskell existentials have to be CPS'd Does this CPS stand for continuation-passing style? I'm not sure what it means in the context of types. Would you mind explaining that a little bit? Again, thanks for your detailed and well-written answer. I really appreciate it!
I've done both Go and Haskell professionally for a short amount of time and IME the times error handling is wrong or no one really knows what's going on under the monad stack, whether something short-circuits or not, whether the web handler crashes and whether exceptions are caught or not... is higher in haskell. However, this could be totally project specific. But my point is that not just explicit error handling causes bugs and has pitfalls. Implicit error handling also does. Monads don't magically solves this, especially when there is almost no consistency whatsoever in the ecosystem. Verbosity is annoying, but it's not always your enemy. I prefer explicit error handling most of the time. Rust also has the problem that people stop caring about where to catch what and let the Result type and the `?` operator "handle" it. The result is not really better.
[removed]
&gt; Does this CPS stand for continuation-passing style? Yep! This is the transformation from a type `T` into a function taking a continuation `forall r. (T -&gt; r) -&gt; r`. (If you squint, it looks a bit like double-negation in logic.) You can always translate between a rank-2 existential in negative position and a rank-1 universal in positive position, or between a rank-1 existential in positive position and a rank-2 universal in negative position: (‚àÉa. F a) ‚Üí b ‚âÖ ‚àÄa. f a ‚Üí b a ‚Üí ‚àÉb. f b ‚âÖ a ‚Üí (‚àÄr. F b ‚Üí r) ‚Üí r So this comes up in Haskell when you‚Äôre working with existentials‚Äîyou often want a function like this that takes a rank-2 continuation to unpack an existential within a given scope: data Something where Something :: forall x. Fields x -&gt; Something withSomething :: Something -&gt; (forall x. Fields x -&gt; r) -&gt; r withSomething (Something x) k = k x Aside: the `ExistentialQuantification` extension (ab)uses the `forall` keyword to mean `exists`; it‚Äôs clearer imo to use `GADTs`, so when you would have written this: data GFix f = forall x. GFix x (x -&gt; f x) Write this instead: data GFix f where GFix :: forall x. x -&gt; (x -&gt; f x) -&gt; GFix f Which makes it clearer that the `forall x.` (which can be omitted) refers to the quantification of `x` within the type of the *constructor*, not externally. 
&gt; Does this CPS stand for continuation-passing style? Yes. So, instead of just exposing an `a` you expose a `(a -&gt; r) -&gt; r` -- they are isomorphic. Instead of a `forall x. f x` you expose a `(forall x. f x -&gt; MyType) -&gt; MyType` By putting the `forall` in a negative position, it becomes a existential instead of a universal, if I'm understanding that right.
 I think I see what you‚Äôre getting at with your first question, but that‚Äôs not typically quite how people think of it. The function *does* correspond to the arrow in the function signature, in that the function is a *value* whose type happens to be a function type. For example, a definition like this: const :: a -&gt; b -&gt; a const x y = x Desugars to something this: const :: a -&gt; (b -&gt; a) const = \x -&gt; (\y -&gt; x) -- Or: const :: (-&gt;) a ((-&gt;) b a) -- Or: type Function a b = a -&gt; b const :: Function a (Function b a) Then the outer lambda (`\x -&gt; ‚Ä¶`) is a value whose type is the outer `a -&gt; (b -&gt; a)` (where `x :: a` and `‚Ä¶ :: b -&gt; a`), and its result is the inner lambda (`\y -&gt; x`) whose type is the inner `b -&gt; a` (where `y :: b` and `x :: a`). ---- As for your second question, the right-associativity of function arrows might be clearer with a function of more arguments: addThisOrThat :: Bool -&gt; Int -&gt; Int -&gt; Int -&gt; Int addThisOrThat condition this that x = if condition then this + x else that + x If we add parentheses to the function signature, and desugar the definition to lambdas, we get: addThisOrThat :: Bool -&gt; (Int -&gt; (Int -&gt; (Int -&gt; Int))) addThisOrThat = \condition -&gt; \this -&gt; \that -&gt; \x -&gt; if condition then this + x else that + x This illustrates what happens as we apply more arguments to the function‚Äîand note that function application is *left*-associative, so `f x y z` is equivalent to `((f x) y) z`: addThisOrThat :: Bool -&gt; (Int -&gt; (Int -&gt; (Int -&gt; Int))) -- == -- = \condition -&gt; ‚Ä¶ -- Applied a ‚ÄòBool‚Äô to get an ‚ÄòInt -&gt; Int -&gt; Int -&gt; Int‚Äô addThisOrThat True :: Int -&gt; (Int -&gt; (Int -&gt; Int)) -- == -- let condition = True in \this -&gt; ‚Ä¶ -- Applied an ‚ÄòInt‚Äô to get an ‚ÄòInt -&gt; Int -&gt; Int‚Äô (addThisOrThat True) 1 :: Int -&gt; (Int -&gt; Int) -- == -- let condition = True; this = 1 in \that -&gt; ‚Ä¶ -- And so on‚Ä¶ ((addThisOrThat True) 1) 2 :: Int -&gt; Int -- == -- let condition = True; this = 1; that = 2 in \x -&gt; ‚Ä¶ (((addThisOrThat True 1) 2) 5 :: Int -- == -- let condition = True; this = 1; that = 2; x = 5 in -- if condition then this + x else that + x -- == -- if True then 1 + 5 else 2 + 5 -- == -- 1 + 5 -- == -- 6 The parentheses, or implicit parentheses due to associativity, don‚Äôt determine what‚Äôs *evaluated* first, just the structure of the type‚Äîwhich is reflected by the structure of an expression of that type. The lambdas are nested to the right, and so too are their corresponding function arrows.
I think the easiest approach is to nest all your endpoints that require an `AppContext` under a common URL prefix: ``` type AppAPI = Some :&gt; End :&gt; Point :&lt;|&gt; Other :&gt; End :&gt; Point type API = Header' '[Required] "X-A" :&gt; Header' '[Required] "X-B" :&gt; AppAPI ``` Then your handler could look like: ``` -- apiHandler :: Text -&gt; Text -&gt; Server AppAPI apiHadnler :: Server API apiHandler _a _b = appApiHandler $ AppContext _a _b appApiHandler :: AppContext -&gt; Server AppAPI appApiHandler ctx = handler1 ctx :&lt;|&gt; handler2 ctx ``` If you have many endpoints under `AppAPI`, you could also inject the `AppContext` into a `ReaderT` layer in `apiHandler`, so that it becomes invisible in the plumbing. If you don't like the common prefix solution, then you can consider: ``` type AppContextBuilder xa xb api = Header' '[Required] xa :&gt; Header' '[Required] xb :&gt; api type API = AppContextBuilder "X-A" "X-B" :&gt; ReqBody '[JSON] B :&gt; Get '[JSON] C ``` then you can also define a utility function for APIs using `AppContextBuilder`: ``` packAppContext :: (AppContext -&gt; Server api) -&gt; Server (AppContextBuilder xa xb api) packAppContext apiServer _a _b = apiServer $ AppContext _a _b ```
&gt; Verbosity is annoying, but it's not always your enemy. Amen. When you come from J2EE to Haskell, your internal verbosity pendulum way swing too far, past concise. One letter variables, no type signatures, and lots of (implicitly passed) type classes can feel amazing; but it can actually be harder to maintain later.
This is really nice! I keep meaning to expand a guide I wrote that uses Stack so that it enumerates other possibility like Cabal (new-*) and nix, so this is very helpful.
Often hlint is quite helpful as well. In your example it'd give `concat $ map =&gt; concatMap` for instance which is arguably more readable. It can also give built-in functions for simple hand written loops but it can't deal with more optimized handwritten ones like g :: Int g = outer 10 0 where outer i acc = inner i (i-1) acc inner i j acc | i &gt; 0 = inner (i-1) j (acc+i) | j &gt; 0 = outer j acc | otherwise = acc 
False - Go performance is quite decent and it is widely adopted out there
It's not that simple. Haskell developers are not easy to hire and startups can't afford months for OOP developers to learn using Haskell properly. Also Haskell ecosystem can't be compared to popular languages like Go, Java, C#. 
Employers that enlightened are not easy to find, I don't think, but it's great that it worked out for youj.
I didn‚Äôt say that it was a poorly performing language, it‚Äôs just that the compiler doesn‚Äôt perform many aggressive optimizations (at least compared to say your average C++ compiler) which yields really fast compilation times
It looks like you already can use implemented in Haskell rank-select data structure: * https://hackage.haskell.org/package/hw-rankselect-base-0.3.2.1
`Vector` implements sliced arrays: -- | Boxed vectors, supporting efficient slicing. data Vector a = Vector {-# UNPACK #-} !Int {-# UNPACK #-} !Int {-# UNPACK #-} !(Array a) Because of that it supports fast (`O(1)` time) slicing operations like `drop`, `take`, `splitAt`. But also because of that all general functions like _get by index_ contain some overhead to deal with offsets. Arrays from the `primitive` package doesn't contain such overhead. And, for example, because of that they are used in [the `typerep-map` package](https://kowainik.github.io/posts/2018-07-11-typerep-map-step-by-step). This gives significant performance boost in this case, however the interface is indeed quite low-level.
I am not specifically suggesting Haskell. There is always Clojure, Elixir, or even Ruby and Python. Those offer big productivity gains over the verbose and clunky languages like Go, Java, C#.
The parallel job post for a Rust dev now has some Q&amp;A about the technology too: [https://www.reddit.com/r/rust/comments/baohwd/job\_rust\_software\_engineer\_remote\_startup/](https://www.reddit.com/r/rust/comments/baohwd/job_rust_software_engineer_remote_startup/)
Another sleepless night &gt;&gt;.&lt;&lt; I have not achieved it. It's entirely possible my instance-fu is weak though. I think most of my attempts boiled down to these three definitions, `newtype A1 s f a = A1 { runA1 :: s -&gt; (s, f a) }` A1 doesn't let you put the \`a\` results of running \`f a\`s into the state \`s\`. `newtype A2 s f a = A2 { runA2 :: f (s -&gt; (s, f a) }` A2 doesn't let you be (lazily) selective in \`f\`. It seems that you can deduce at best \`Applicative f, Selective g =&gt; Selective (Compose f g)\` ie. you are selective only in the inner functor. `newtype A3 s f a = A3 { runA3 :: s -&gt; f (s, a) }` A3 is sort of where you "want" to be at, but I can't find a productive and lawful definition. I could obtain a summary state by restricting to \`Monoid s\`, but the intermediate computations didn't have access to it accumulating. &amp;#x200B; Do you want to have a go?
Here's a list comprehension that does what you want \`\[c : show i | i &lt;- \[1..\], c &lt;- \['a'..'z'\]\]\` and something like this to get the ones without a suffix at the beginning \`\[c : if i &gt; 0 then show i else "" | i &lt;- \[0..\], c &lt;- \['a'..'z'\]\]\`
&gt;I was thinking of going about it by having a set of strings \[a-z\], and concatenating it with \[1..\] to give me the whole set \[a,b,...,z,a1,b1,...,z1,a2,b2,...z2...\], but i dont really know how to start.. `zipWith (\n c -&gt; c : show n) [1..] (cycle ['a'..'z'])` &gt;as an aside question, is there anyway i can shorthand write the alphabet as a set of strings (as opposed to chars)? i know that \["a".."z"\] doesnt work as \['a'..'z'\] does `(:[]) &lt;$&gt; ['a'..'z']`
What have you done so far? What's the major source of anxiety in what you understand to be necessary?
How large is your codebase? Can you (estimate a) benchmark against the performance of \`ghcid\`?
Haskell has a pretty steep learning curve. I hate to say this but if I had to learn one to get to a word processor I'd go with smalltalk for which one I could get up to a word processor faster. That being said I know Haskell far better. Books to get you started: Haskell book is the best all around first resource; http://haskellbook.com/ Manning set: https://www.amazon.com/Get-Programming-Haskell-Will-Kurt/dp/1617293768/ https://www.manning.com/books/haskell-in-depth I really like Bird's book (which is in your college library). The issues with out of date won't be too much of a problem once you start learning the language. The reason you are failing is because you aren't doing easier exercises.
(I don't have any great suggestions, but I would just say if you're feeling burnt out (quite common in our industry, unfortunately) to be patient with yourself, and don't feel like you have to force yourself to learn a new skill right now if you aren't motivated to do so)
It's honestly just making a start with either language in a direction that will help me with my assignment. I wanted to use smalltalk at first since it is apparently much easier to get GUI working, but when I attempt to use it nothing every works how the tutorials (wether video or book) work how it does for the creator. &amp;#x200B; I consider myself skilled in other languages like C# and PHP, just the lack of resources that do as they say they do on my version of Pharo is so frustrating and what scares me the most. I haven't tried Haskell nearly as much as Smalltalk purely because I can't visualise how a word processor would even work on a console application
Thanks for the help. Yeah I assumed as much but I can't find any beginner tutorials that deal with GUI that work with the latest version of Pharo meaning I just don't understand what changes I need to make for the latest version. &amp;#x200B; I have been going to class and even shared my frustrations with my teacher and fellow classmates. The teacher hasn't been much help and classmates are all leaving it till last minute in classic CS fashion so I just don't seem to be able to get help from any direction. &amp;#x200B; I consider myself skilled with other languages like C# and PHP, these two are such a different ball game though and every time I try to make progress I just end up nowhere
&gt; I can't visualise how a word processor would even work on a console application For what it's worth there's nothing that restricts a Haskell solution to being a console app. There are a number of viable approaches for building GUI applications in Haskell. For example [FLTKHS which was just mentioned here](https://old.reddit.com/r/haskell/comments/ba4dw0/ann_new_release_of_fltkhs_with_much_better/), or [Reactive Banana+WX](http://hackage.haskell.org/package/reactive-banana-wx) which I've used successfully in the path. That being said, if you're new to Haskell working with some of that stuff may be pretty challenging and a console based Word Processor is also possible. You might want to investigate old DOS based Word Processors like Word Perfect for inspiration. If you do decide to go this route [Brick](http://hackage.haskell.org/package/brick) is a great library for building console apps in Haskell and while it has a few interesting wrinkles would probably be much more approachable than a full blown GUI toolkit.
I'd definitely be interested to discuss any wrinkles in my library. :)
A little known fact about Free Software: if you think that something is so terrible that you are forced to exclaim to the entire community (including the authors) how much it sucks, you are ENTITLED to your money back! I think you deserve it, you've worked hard for this, and those authors are really not trying hard enough for your custom.
[Lear you a Haskell](learnyouahaskell.com)
I've heard many good things about fltkhs ([https://github.com/deech/fltkhs](https://github.com/deech/fltkhs)). I'm not sure how beginner-friendly it is...but it lets you use GUI-designer (Flow?) built for fltk and just reuse those designs in your haskell app. The actually word-processing part could just a be pure function from `Text -&gt; Text` that updates on every change or something.
I'm glad the default is being changed! I think that will make a lot of folks happy that have been negatively impacted by this change, and gives people the ability that enjoyed the change a chance to evangelize it properly - with blogs and guides and documentation saying how to opt-in to this new work flow. The tension that this situation has generated is real. I think it is a good idea to study the situation and try to see what technical and social factors contribute to greater tension than we usually see in software tooling. Technically speaking, the story seems to be: - GHC introduced a feature that would read environment configuration files to extra information. These configuration files were introduced in [GHC 8.0, released January 11th 2017](https://www.haskell.org/ghc/download_ghc_8_0_2.html). - Cabal started automatically and silently generating these configuration files when using `cabal new-*` features at some point. /u/vaibhavsagar [says that this started](https://www.reddit.com/r/haskell/comments/b9scx2/package_environment_files_run_counter_to/ek6ys3g/) in [cabal-2.2.0.0](https://hackage.haskell.org/package/Cabal-2.2.0.0/changelog) (though this is not present in the release notes). This was released in March 2018. What's odd is that the [cabal issue #4542](https://github.com/haskell/cabal/issues/4542) that initially discusses the feature is first posted in May 2017. The `new-build` commands were introduced in `cabal-1.24.0`, released in March 2016. [`cabal-2.0.0.0` was tagged on May 5th](https://github.com/haskell/cabal/releases/tag/Cabal-v2.0.0.0), which is right before the relevant issue was created. - People report that this change is breaking their existing workflow in ways that are hard to detect and fix - [this GitHub issue](https://github.com/haskell/cabal/issues/4542) was posted on May 17th by /u/hvr who was reporting the complaints on behalf of others. Socially, the discussion was initially posted [this GitHub issue (`cabal/#4542`)](https://github.com/haskell/cabal/issues/4542) on May 27th 2017. The first round of comments was relatively brief, but we have two experienced GHC developers (Edward Yang and Alan Zimmerman) expressing that this is confusing, a request to work-around this in `stack`, and a note that this breaks `nix`. All told, we have one in favor and four not-in-favor. Discussion reboots in the GitHub issue after [this Reddit thread](https://www.reddit.com/r/haskell/comments/8iyvoo/psa_for_cabal_22_new_users_regarding/) was posted on May 12th 2018. Examining the reddit thread, the top comment is a request to remove the feature (22 upvotes) with two supporting comments. The top comment expresses that this new feature *broke existing workflow* and described it as "a major pain for me." The second-top comment is from a GHC developer that likes the feature, but "has been surprised by it a handful of times." /u/gbaz1 posts a link to the GitHub issue, which presumably exposed it to more people, who chime in. The GitHub discussion goes for quite a while. I counted the people either making comments or posting approval/disapproval emojis, and I found 27 people wanting the feature to be opt-in (or removed) and 4 people that liked the feature. /u/ElvishJerrico [remarks that](https://github.com/haskell/cabal/issues/4542#issuecomment-417695776) "the magnitude of any negative reaction has consistently seemed much larger than the magnitude of any positive reaction." Benefits of the change seem to be limited to "Using `ghci` or `ghc` directly instead of `cabal repl` or `cabal ghc`," and "`cabal repl` would require passing extra CLI flags," while negative experiences report losing ["a significant chunk of time"](https://github.com/haskell/cabal/issues/4542#issuecomment-309407946) or ["wasted about half a day on mysterious breakage"](https://github.com/haskell/cabal/issues/4542#issuecomment-417665123). How can we learn from this situation to resolve similar conflicts in the future with less stress and strain?
So why not write the basic, library code that takes the current state of the document and and an edit and produces the new document. Then you can plug that into whichever GUI library looks to have the least overhead (or looks the most interesting; [obelisk](https://github.com/obsidiansystems/obelisk) is also interesting, but there's more infrastructure to get going).
It's too smooth.
Oh, I didn't mean to imply any weaknesses with Brick at all -- I just meant things that might not be obvious to someone new to Haskell -- but again, compared to the full blown GUI toolkits it's going to be a piece of cake :)
Cool post! I'd love to see more about the translation of a *recursive* function into smt, since it gets a little tricky here IIRC. Define-func works like a c macro (the body is simply substituted wherever the name appears after it is declared) so it can't encode recursion. I believe the solution is to declare a function, and then give it recursive/base cases via assert statements, but at that point I'm not sure if your solver will give you back the solution you expect (the "smallest" solution) or some other definition that also satisfies the constraints.
Some advice that‚Äôs not language dependent: break it down. Start building _any_ piece that you find interesting. Don‚Äôt be afraid to build something that you‚Äôre going to throw away. Seriously, find the absolute smallest unit that you have the faintest idea on how to handle and _go_! This will build some traction/confidence/direction. This will also enable you to find specific problems that you can bring to others for help. Take a deep breath and break off a single interesting piece. You can do it :)
A dumb question perhaps, but isn't this exactly what the fixpoint combinator is supposed to solve?
It is what also I'm reading now, seems a good book for now but I'm only at the beginning (tuple)... List comprehension of lists of lists are bloating my mind üòÇüòÇ
I don‚Äôt have such kind of issues at all. How large is your project?
it's just a project generated with \`stack new my-new-project\`
it's just a project generated with \`stack new my-new-project\`
I am very greatfull for free software and i don't blame anyone for that. i understand that free and opensource software is written in most cases in free unpaid time. you could have noticed that in my question I put myself on the first place for blaming here. So your comment doesn't make any sense. But hope you are doing well
I don‚Äôt have any issues with projects less than 15k lines unless I have a lot of generics or type-level stuff going on. And then it‚Äôs not bad but noticeable.
Absolutely. By "smallest" solution, I was really referring to the least fixed point of the constraints. But I don't believe there is any fixed point operator in smt2 (I thought I heard something about a fixedpoint extension to z3 a while ago, but it specifically applied to relations). Now that I think about it, I'm sure that z3 and other solvers will probably give you the "smallest" definition for your recursive function when queried with "get-model". I think the real problem creeps up when making additional assert statements on that function, not trying to contribute to the definition, but just checking if a statement is valid/sat with respect to the minimal solution of the previous constraints. To my knowledge, there is no way to get the minimal solution and make queries on that, and that is the basic problem I was getting at.
Oh, I see. Well, as its author I definitely think it has some weaknesses so I just wanted to be sure it was clear I would like to discuss those with others if people run into issues!
Thanks for the writeup. How would you express monadic functions to eventually some monad-stack function that uses mtl?
Exactly, in my experience muldtidimensional arrays are the only niche for `array`. Otherwise, as described by /u/chshersh, if I am fine with a constant overhead for offsets, I go for `vector`, offering much richer API than `array`, and if I am not - for `primitive` (because `Ix`-based indexing also introduces overhead). Historically `array` was important being a part of Haskell Report, but nowadays there is only one compiler alive.
Is there a relation between this and refinement types? To me it feels very similar.
As much as I love haskell if you have a limited timeframe I would go for smalltalk.
I must confess that I am illiterate with regards to multithreading. Are we talking about `basicUnsafeWrite` here? basicUnsafeWrite (BitMVec s _ v) !i' !x = do let i = s + i' let j = divWordSize i; k = modWordSize i; kk = 1 `unsafeShiftL` k w &lt;- MV.basicUnsafeRead v j when (fromBool (w .&amp;. kk /= 0) /= x) $ MV.basicUnsafeWrite v j (w `xor` kk) How can it be rewritten to become thread-safe?
More of them! I think GHC 8.6 has had more patch releases than any other GHC version since I started using Haskell ten years ago. And this is with the now much shorter period between major releases! Does anyone know the reason? More resources for patch releases?
I just went back and looked through the API to see if I could recall anything in particular that I stumbled over, but I was fairly new to Haskell then and looking at it now it all makes perfect sense. I suspect it might've been something to do with either the `EventM` monad or Chans but it's hard to see it through fresh eyes now. Either way I wouldn't worry about it too much, as tom-md hinted at, using it is a fantastic experience. I would go so far as to say that it's one of the real gems of the Haskell ecosystem.
[removed]
[removed]
are you open to applicants from outside of the us and do you offer a relocation package?
I'm a spacemacs user. I use intero but also ghcid and instead of launching ghcid from a term buffer, I have a make file with a target \`run-ghcid\`, which I can call with \`SPC c c\` (compile command) or \`SPC c r\` (to recompile). By doing that, ghcid is launched in \`compilation-mode\` which parses error and allow to jump to them.
First take a deep breath and figure out which language you're most confortable in. Judging from your responses, you've used Pharo. Try to break down your problem into small steps and build up to the features of a word processor. But before you start, get a little acquanted with Pharo: https://medium.com/@richardeng/pharo-quick-start-5bab70944ce2 The above has a hello-world program. Get that working first to ensure that your installation of Pharo works. Once you have that worked out, try to build your application in small steps, i.e., the above print "Hello World" to the console. One potential project plan could be this: * print "Hello World" to console using the current version of Pharo * launch an empty window * modify your empty window to display "Hello World" * modify your empty window to accept input (read from the keyboard) and display it etc.
Wow, that's very kind. Thank you! I'm glad you've enjoyed using it. :)
Sorry to digress from the original post, but what is the difference between refinement types, liquid types, and dependent types? My understanding is that a dependent type system is any system in which values appear in types. Sometimes this means you need to prove the type of a thing, because the types become too complex to be inferred automatically. Refined types and liquid types sound like the same thing to me: a subset of dependent types where typical types are enriched with only specific predicates that can still be inferred/checked automatically. Is all that correct? I guess what is confusing me is that refined and liquid types sound the same to me.
8.6.1 had a showstopper so an 8.6.2 needed to happen promptly. The rest seem to mostly be a function of improving Windows support and a willingness/ability to release more often and for less-than-critical bugs - possibly due to improved tooling and processes?
&gt; We will plan on starting the alpha cycle for 8.10 in mid-June, as previously planned. This is the most fascinating bit. The 8.8 branch was cut months ago and the patch flow from master has been somewhat limited, right? So, despite the likelihood that GHC 8.8 and 8.10 will only be a handful of months apart, they'll still be quite significantly different.
GUIs are tough in Haskell. If you are allowed to use Haskell like syntax I'd say https://elm-lang.org/ . Ask the professor if that counts as Haskell. As far as smalltalk I'd suggest Squeak that has a built in GUI with versions designed to let 6 years olds program in it. There are tons of getting started guides and books. * https://wiki.squeak.org/squeak/2983 * http://wiki.squeak.org/squeak/689 * https://pdxscholar.library.pdx.edu/cgi/viewcontent.cgi?article=1112&amp;context=compsci_fac That might literally be over 1000 beginner oriented resources online.
In the work motivating this post, we were analyzing a non-turing-complete language, so we never had to deal directly with this issue. We do, however, have to deal with properties on lists, which can be arbitrarily long. Currently we solve this by bounding the length of lists that we check (say the bound is 10, if a property falsification doesn't happen until length 20 then we won't find id). I think we can do better than this but i'll take a bit more work. &amp;#x200B; As far as other work, I'd look at liquid haskell, in particular *refinement reflection*, which seems to handle recursion well. For a different approach, check out Dafny's loop invariants. By the way, both LH and Dafny have systems for termination checking -- LH calls theirs *measures* and Dafny calls theirs *decreases annotations*.
You prob want data Album = Album Title Artist Year Sales
&gt; I wanted to use smalltalk at first since it is apparently much easier to get GUI working This is true to some extent. Smalltalk is certainly _designed_ around GUIs, but all this means is that it comes with a builtin GUI library; it isn't necessarily easy to use! On the other hand, Haskell has a reputation for being bad with GUIs, but I personally haven't had that experience myself. At the moment, if I were to write a GUI application I would definitely do it in Haskell. If it helps, I wrote up a fairly comprehensive summary of Haskell GUI libraries [here](https://www.reddit.com/r/haskell/comments/a6bvr2/graphics_in_haskell/ebxti0v/), complete with installation instructions where appropriate. &gt; when I attempt to use it nothing every works how the tutorials (wether video or book) work how it does for the creator. Yes, this is often the case for less popular languages, such as Smalltalk. To some extent, this is also a problem with some of the old Haskell tutorials. For Pharo Smalltalk specifically, I've found [Pharo by Example 50](http://books.pharo.org/updated-pharo-by-example/) to be nice (although to be honest I've never really done much with Smalltalk). &gt; I consider myself skilled in other languages like C# and PHP Unfortunately, this may not help much. Pharo and Haskell are both incredibly different to more popular languages such as C# and PHP; normal programming advice like [this comment from below](https://www.reddit.com/r/haskell/comments/bavk9z/i_have_a_assignment_using_haskell_and_im_freaking/ekenej3/) is still good advice, but beware of thinking imperatively or trying to use OOP patterns. &gt; just the lack of resources that do as they say they do on my version of Pharo is so frustrating and what scares me the most. I've often found that for languages like Pharo and Haskell, the best thing to do is to seek out lots of individual resources; often none of them make much sense on their own, but together they can help me fully understand the concept involved. &gt; I haven't tried Haskell nearly as much as Smalltalk purely because I can't visualise how a word processor would even work on a console application Honestly, I couldn't imagine how this would work either. However, as mentioned above, there are plenty of GUI libraries for Haskell. Again, I would recommend having a look at my [Haskell GUI libraries summary](https://www.reddit.com/r/haskell/comments/a6bvr2/graphics_in_haskell/ebxti0v/) (also linked above) for a nice overview.
Thanks
Thanks! I'll take a look at the previous posts you mentioned. I've read up a bit on liquid haskell, but not nearly as much as I'd like. Perhaps now is a good time to dive back in!
Sorry forgot to include, send us an email at jobs ‚àÄ costarastrology ‚àò com to apply. &amp;#x200B; We can't sponsor visas at the moment but if you're eligible to work in the US we can potentially help some with relocation.
oh wow thank you, this is perfect
Correct; to avoid throwing off the release schedule the 8.8 cycle will be quite condensed.
Does GHC 8.8 include Linear Types?
See this for a brief explanation: [https://cs.stackexchange.com/questions/21728/dependent-types-vs-refinement-types](https://cs.stackexchange.com/questions/21728/dependent-types-vs-refinement-types)
spam
I'm not sure what language you were taught in your first year but I'm betting it was not a functional programming language. If so, i found this article for building a text editor with haskell [https://wewantarock.wordpress.com/2010/01/31/building-a-text-editor-part-1/](https://wewantarock.wordpress.com/2010/01/31/building-a-text-editor-part-1/) I also found this small nano clone in python [https://github.com/OzTamir/NanoPy](https://github.com/OzTamir/NanoPy) I would try to learn enough small talk to see if you could replicate that.
This is awesome
This is so cool. Structural semiotics of code; where's Baudrillard at when you need him?
I was referring to bare `write`, but `modify` would be useful to have too. `Data.Vector.Primitive` seems sufficient for the underlying *mutable* vector, and that offers full access to GHC's atomic operations.
You'd have to use an atomic version of `w = w .|. b`. See the [relevant area](http://hackage.haskell.org/package/ghc-prim-0.5.3/docs/GHC-Prim.html#v:fetchOrIntArray-35-) of `GHC.Prim`.
What you're missing in describing github issue is the multiple changes to both ghc and cabal that were put in place in the course of that discussion. On the basis of feedback, a _ton_ of fixes were made (and a few remain) that handle most of the rough edges that were raised. Once people reported issues, cabal devs were _very_ responsive. The thing is just that there was not agreement to change the default (even thought that idea was raised early on, including by myself) but instead people wanted to just make sure that the issues people ran into were resolved, _even with files being generated_. I think this was a reasonable approach, and one frustration I've had in this discussion is the myth that nothing was done, even though a whole bunch of things were done, and there was a lot of attentiveness to the issues raised. It doesn't make sense to record the "upvote" and "downvote" sentiment but to ignore the concrete patches made to both ghc and cabal as a result of the discussion. I don't care much about the default either way, but in my opinion most issues people had raised (outside of a general concern of "user expectations" which can really vary between users) had been concretely resolved either by changes already made, or changes that are not yet made but considered blockers for a cabal 3.0 release. I think the main issue involved was expectations management around the new-* features, which were always marked experimental and for early-adopters, despite how nice they were working already. The frustration seemed to arise because there were rough edges in these features, particularly regarding management of these env files, and because the new-* features had worked so well, people treated them as somehow "finished" when they were still in flux. But if opt-in users to an experimental and unfinished feature are not a good testing ground for fixing workflow issues, then who is?
&gt; What you're missing in describing github issue is the multiple changes to both ghc and cabal that were put in place in the course of that discussion. While I commend the excellent work of the cabal team, I don't really see how that is relevant to this.
Great post, Joel!
You gave an account of the discussion on the ticket. But the most important part of the discussion on the ticket was the concrete changes it resulted in. It wasn't an "up/down" poll. It was a discussion on how to improve the workflow, and changes were made to the workflow as a result of it which changed the parameters of the discussion over the course of it, as they resolved many concerns which were initially raised.
Ruby and Python performance is far worse than Go I don't know enough about Clojure and Elixir to compare but one disadvantage they have against Go is required to install heavy runtime to run.
Very cool! I enjoy seeing the benefits in this case of using the "least powerful" abstraction. Interesting to see what it gets you over just using Free Monads for everything üòÑ
For me, hie+vscode sucks and rocks simultaneously. If you just expect it to work flawlessly, it'll suck for you, because IME there are some predictable circumstances that break it. For instance, if I have a project with 100 modules, and I try to work on two modules simultaneously and if one of those modules is at the top of the dependency tree and the other at the bottom, hie very reliably breaks. Another circumstance is when you're working on two modules from two local packages and if one depends on the other. On the other hand, hie+vscode is so great when it works that I still love it, because I can easily predict when it's going to break and either ignore the breakage temporarily or take precautions. It's like the old kettle in the kitchen, it has its quirks but it serves me well. (dies from a kitchen fire the next day :P )
&gt; See description for instructions how to use. I can't find any documentation.
I'm pretty sure kind-generics supports that. https://hackage.haskell.org/package/kind-generics
What happened to [Template Your Boilerplate](https://hackage.haskell.org/package/TYB)? They seem to have a nice paper, but the code didn't age well and there's no link to source repo. On a related note, what is the next best thing that could do generic bottom-up traversals like SYB, but faster?
Overall I'm happy with the idea of a regular release cadence, but I was surprised to see it as short as 6 months. Do things like these make you wonder if 9 or 12 months would have been a better choice?
Nice plugin! Thanks for sharing it. I still like `ApplicativeDo` for `optparse-applicative` though: ``` application :: Parser (IO ()) application = do foo &lt;- parseFoo bar &lt;- parseBar pure $ do stuff &lt;- readFile foo writeFile bar ``` Removes the need to define a record for the parameters and saves you from typing the argument names 3 times (`data` definition, parser, main io). Good for small CLI utilities IMO.
There's an issue in GitLab: https://gitlab.haskell.org/ghc/ghc/issues/15981 - looks like no. 8.10 the earliest.
documentation left as an exercise for the reader
Very interesting abstract. Looking forward to read the paper coming weekend
Anybody looking for an example should head to the tests https://github.com/strake/comprehensions-ghc/blob/master/test/Main.hs ``` test1 :: Functor f =&gt; (a -&gt; f b) -&gt; a -&gt; f b test1 f a = [b | b &lt;- f a] test2 :: Applicative p =&gt; (a -&gt; p x) -&gt; (a -&gt; p y) -&gt; a -&gt; p (x, y) test2 f g a = [(x, y) | x &lt;- f a, y &lt;- g a] ```
It's set to milestone 8.9, but that was 4 months ago so maybe the situation changed.
It's a GHC plugin ‚Äî just include the preamble (as given in the package description) in your source file, and it will magically generalize all the comprehensions therein!
&gt; restricted to `Functor` and `Applicative` I think i know what you mean, but just wish to note for the information of readers: the plugin only ever makes the type of a comprehension more general. &gt; Don't forget about `ParallelListComp`. This plugin actually ignores parallel comprehensions (i.e. leaves them unmodified) ‚Äî the notion makes no sense unless the type has another possible `Applicative` instance, as List does.
Gotta add https:// for your link to work :)
This looks pretty good. Where did it come from?
It can also be written as a comprehension, with no records or argument names in triplicate: `[do stuff &lt;- readFile foo; writeFile bar | foo &lt;- parseFoo, bar &lt;- parseBar]` But hey, use whichever you find convenient.
Odd numbers are development versions (like GHC-8.1, 8.3, 8.5...).
Ah, I didn't know that. Thanks
liftA2 (flip (:)) (map show \[1..\]) \['a'..'z'\]
Oh, I think you're the only one that has interpreted someone's willingness to compromise as a negative thing. Exactly what proof do you have aside from conjecture and unfounded rethoritic that it would be changed back without any public consultation? PS. Since when are you a cabal-install user? Welcome to the club!
From **Cosmia -** [https://github.com/Cosmius](https://github.com/Cosmius) . It has a video record at [https://www.bilibili.com/video/av35854780](https://www.bilibili.com/video/av35854780) , but in chinese.
I think you can fix this by replacing lines 2 through 4 with this: WORKDIR /opt/build COPY . . When you `RUN` a `cd` command in a `Dockerfile`, the rest of the script doesn't stay in that directory. You either need to set the `WORKDIR` or `RUN` all the commands together like this: `RUN cd /opt/build &amp;&amp; stack setup &amp;&amp; stack build`.
I just read the chapter on Monad Transformers and really like it; this looks very concise which is the exact opposite of Haskell Book From First Principles.
Awesome to see CI with comprehensive testing emerging like this. Keep up the good work!
Let me restate what I was writing about: &gt; I think it is a good idea to study the situation and try to see what technical and social factors contribute to greater tension than we usually see in software tooling. This is what the post was trying to summarize: "Why are people upset about this? What are people's feelings?" I think it might be interesting to ask *why* the concrete changes and work done didn't seem to assuage folk's feelings on this (until the PR that disabled generating the files by default). But that's getting more into the realm of speculation. Folks that have been personally impacted by this would be providing valuable insight if they felt like chiming in.
Happy to see alternative styles of exposition, however, the ratio of narrativity to non-narrativity is a bit high and this coupled with the saccharine treatment of the heroine (and genre) causes me to experience too much tedium to read the text carefully (if at all).
Thanks! `stack install graphmod-plugin` just installs a binary into my PATH, so no luck there. I couldn't find a way to make the package available globally (I'm not even sure that makes sense; in any case, presumably it wouldn't have any impact on other stack-based projects). But if I add it to stack.yaml (`/path/to/graphmod-plugin/graphmod-plugin` under `extra-deps` and .cabal (`graphmod-plugin` under `build-depends`), then `stack build --ghc-options="-fplugin=GraphMod -fplugin-opt=GraphMod:out"` does work.
I was more focusing on developer productivity and not on the language performance. &amp;#x200B; I agree that Go is probably one of the best choices out there right now if you need something high performance, but I would still choose Rust for performance.
That's the first time in a long while that I didn't skim the abstract, and I'm not even interested in Coq or theorem provers.
In my experience shorter release cycles work better, for two reasons: * Longer release cycles incentivize contributors to prematurely merge large last-minute changes in order to not wait for the next release boundary * Smaller incremental releases provide a smoother upgrade path for users
I like the idea of HIE but I agree that it's a pretty bad user experience now. Since you're using stack for your project, I would check out [http://rikvdkleij.github.io/intellij-haskell/](http://rikvdkleij.github.io/intellij-haskell/), if only for the great library navigation (using ctrl+b, the first on that page). &amp;#x200B; If you want to use vscode and you really just want some quick error highlighting, check out [vscode-ghc-simple](https://marketplace.visualstudio.com/itemdetails?itemName=dramforever.vscode-ghc-simple). It's pretty good about quickly working out of the box for all basic projects, though it's restricted to whatever features GHC itself provides.
&gt; bloating my mind I think you mean "blowing my mind".
Anyone have a mirror? OneDrive refuses to download.
the "sucks" in the question is pretty prominent tho.
Thanks! I‚Äôm trying to be patient and give myself freedom to not work all the time. I‚Äôm also cognizant of the fact that if I don‚Äôt change anything, nothing will change. That‚Äôs why I‚Äôm looking for something fun/interesting that I‚Äôll actually enjoy working on.
FWIW the HPFFP's length is almost entirely a product of reviewers not understanding something and needing more examples, explanations or exercises. This gets brought up often enough that I might make an accelerated version of the book just so people stop complaining. I did like the Accelerated C++ book many years ago, but when I was really desperate it was Stroustrup's book that got me unstuck.
\&gt; If I had more time I'd have written a shorter letter. (Blaise Pascal) But I agree, there is a need and place for both, even for the \*same\* reader!
&gt;If I had more time I'd have written a shorter letter. (Blaise Pascal) Having written a book and more than a few letters, it changes with scale dramatically.
I'd imagine it's exponential...
intellij plugin is pretty good though I don't use jetbrains product for political reasons. nice feature of that plugin is that you can navigate to source code of libraries used in the project. wonder if it is possible with hie
I think it's just one of the many ways english is ambiguous. Or it's at least underspecified. Functor and Applicative are more general than Monad, so there are always "more" of them and the types are more general, they "follow less rules". But in context can read it as "restricted to `Functor` and `Applicative` [as an alternative to `Monad`]", that is "restricted" can be read as "alternatively constrained to", not implying "more rules" The easy way out of this would be to say "weakened to `Functor` and `Applicative`" but I admit, I read the post the way you did and it made sense. :P
Rust definitely have performance advantage against Go but I'm not sure about productivity though For Go, I'm sure that most of people will be able to pick it up and be productive with it quickly Rust somewhat has the same productivity myth as Haskell "once you really get it you can be more productive in it than simple language like Go ". I feel that it doesn't apply for most developer out there.
As far as I know, with HIE you can jump to definition within your own code, but to go to library source you have to search with Hoogle. The way the intellij plugin does it is very "custom"...I think they have a lot of custom scala code around downloading libraries locally and searching through them.
[removed]
Interesting. You can ultimately elide the Alt and just write your primitives in terms of `StateT String Maybe`, which recovers the classical monadic parser combinators. But the useful thing about Alt here is that it *forces* you to write regexes, and outlaws context(ual|-free) grammars.
One thing that occurred to me in terms of process is that env files were added to ghc a _long_ time ago actually (near the end of the 7.8 series). If they were getting added these days, I'd imagine that stuff would go through the ghc proposals process, which would have recorded some of the decisions etc more durably. That said, the tickets in the proposals process that attract interest are nearly all language extensions, and virtually no tickets (and especially no tickets that anyone comments on) regard compiler features that don't affect the language directly. The problem with this stuff is really everyone takes it for granted and doesn't pay attention until they get bitten by something, which means discussions have a weird character :-/
Yeah, you're conflating the result by \`++\` operator. What you need is to return \`\[\[a\]\]\` instead of \`\[a\]\`, so for each number in \`xs\` you have a whole list.
You're right but then is not compiling
Obviously, you also need to update the code, using `:` in place of `++`, for one.
Aren‚Äôt you simply forgetting newlines, like \`\`\` | length (x:xs) &gt; 1 = replicate x n ++ "\\n" ++ histogram n xs \`\`\` ?
"hey I'm a rando from the internet, your software sucks and is slow and stuff, kthxbai"
If you always want a string consisting of '*'s and newlines, you could do it like this: histogram :: [Int] -&gt; String histogram [] = error "Empty" histogram xs = unlines (mkStrings xs) where mkStrings [] = [] mkStrings (y:ys) = replicate y '*' : mkStrings ys The `unlines` function takes a list of strings, and concatenates them together with newlines in between.
noop ;/
Cool solution as well. Does not work like i did ?
I was hoping other people would ask more specific questions since mine is more ephemeral; I'd like to build UIs in Haskell with simple single-file scripts and I'm using Stack to help simplify this process (but I'm not a Stack zealot and really don't care about the silly Cabal vs. Stack thing) - however last time I tried spending a few minutes to install some UI toolkits, yours included, I found that there weren't versions in Stack. Given that context - will you be supporting versions through Stackage?
Small typo: 3 + 100 is 103 not 113 :D
This looks great. I've written quite a few simulations of this kind that were pretty hacked together, especially since I don't have strong math chops. I've found the behavior of even pretty simple systems involving queues can be surprising. It would be really neat to see a library built on this that allows a simulation-interpretation of concurrent haskell code (or even a cloud haskell system?)
As far as I know, Intellij Haskell relies on Intero for source navigation. Nothing fancy really.
It does use Intero for some parts of it, but I think it has custom code on top of Intero too. See [https://github.com/chrisdone/intero/issues/231](https://github.com/chrisdone/intero/issues/231) for their discussion on this.
Yes that is definitely on the roadmap, I *think* it's stable enough now. The problem with running it as a `stack` script is there's a bunch of setup that needs to be done in `Setup.hs` I'm not sure how to do that with a single file script. If someone can help here I would love to make this possible. However until then I do [provide](https://github.com/deech/fltkhs-hello-world) [some](https://github.com/deech/fltkhs-fluid-hello-world) [templates](https://github.com/deech/fltkhs-light-theme-skeleton) to help you get started. It's more ceremony but not by much.
Yes, but `x + y + 10` *is* 113.
Your types are wrong, you have a -&gt; [Int] -&gt; [a] Which says you will any type *a* and a list of Ints and return a list of *a*‚Äôs, but you specifically want a String, a.k.a *[Char]*. Try this type signature: Char -&gt; [Int] -&gt; [Char] That should compile and five you something like &gt;&gt;&gt; histogram ‚Äò*‚Äô [1,2,3] ‚Äú*\n**\n***‚Äù Which when printed using *putStrLn* will produce * ** ***
Why is this not properly upvoted? It's Haskell. Compensation is specified and is pretty good, perks are great. And I do not think astrology is less fun than some random banking stuff (and we've seen that they often either underpay or do not specify a salary fork, i.e. wish to underpay). It's one of the best vacations I've seen in this reddit.
The last time Co-Star posted a job, a bunch of people got snooty about how astrology is scum. Very unfortunate! I think this looks like one of the cooler jobs to come through here. If I weren't already happily employed writing Haskell + they offered remote I'd be all over it. Astrology is fun! Get over it! Being 100% committed to an evidence-based lifestyle is an existential decision, not a base fact! Get over it!
Maybe the fact that the company is about astrology is a bonus - it weeds out the toxically rational folks that seem to permeate programming communities.
Thanks, looks like it.
You can pattern match on (x:[]) instead of doing a length check for 1. It's more efficient and idiomatic. You are taking a Char as your first argument and returning a [Char], or String. If you want to instead return a list of strings, [[Char]] or [String], you need to use the the list cons operator, ':', instead of '++' and when passed an empty list, instead of erroring, supply the empty list, []. This constructs a list of lists of Char like: ('*':[]):('*':'*':[]):('*':'*':'*':'*':'*':[]):[] With each parens representing the return result of your call to replicate. This is why you're just getting a string of asterisks - when you use '++' it just builds one long list of Char, like: "*"++"**"++"*****" Or: ('*':[])++('*':'*':[])++('*':'*':'*':'*':'*':[]) Which becomes: '*':'*':'*':'*':'*':'*':'*':'*':[] Or: "********"
Is it possible (or maybe already implemented) to run a network of deterministic virtual machines? Or at least multiple services on a single machine? As you've mentioned in the post, the flaky tests are usually integration tests, and that can involve a very complex system.
http://tmp.link/f/5cad7896d17a9
&gt; we can't deduce `m &lt; n` from `S m &lt; S n` This is something we can fix with `{-# LANGUAGE UndecidableSuperClasses #-}` in a nice, general way. First, let's define the type family of super classes: ``` type family Super (c :: Constraint) :: Constraint ``` We'll use it as a super class for our proof search class: ``` - class (x :: a) &amp;&lt; (y :: a) where + class Super (x &amp;&lt; y) =&gt; (x :: a) &amp;&lt; (y :: a) where ``` Now, for each `x &amp;&lt; y` instance, we add a corresponding `Super (x &amp;&lt; y)` instance: ``` type instance Super (Z &amp;&lt; S n) = () instance Z &amp;&lt; S n where ... type instance Super (S m &amp;&lt; S n) = (m &amp;&lt; n) instance m &amp;&lt; n =&gt; S m &amp;&lt; S n where ... ``` And we're good to go. Now GHC will infer `m &amp;&lt; n` from `S m &amp;&lt; S n`, via the super class of `&amp;&lt;`. Here's the revised version of your example: https://gist.github.com/int-index/42aa92b974bd3ca624bffd9441da7b3e (Consider this answer a gift from https://monadfix.io/ ;)
How about having an explicit argument, but classes like `&lt;?` are opt-in strategies to supply it automatically? inj :: forall n m. n !&lt; m -&gt; SNat m -&gt; SNat n -&gt; Fin n At use sites you can write `inj lt_proof` and `lt_proof` fires the constraint solver, that seems like a reasonable compromise to me. This also has the advantage that if a proof search strategy is not suitable, you can just switch it with something else.
I don't know if this will help you, but I have written [a little bit about getting an app started with fltkhs](https://typeclasses.com/timepieces) (lesson 1 and lesson 4 are about it, with another installment coming soon). Also, the fltkhs [author gave a talk about it](https://haskanything.com/content/presentation/presentation--fltkhs-easy-native-guis-in-haskell-today.html) and about how to use the GUI builder called FLUID.
Strict bytestrings, no. For lazy bytestrings, it depends on who you ask. If you keep a reference to a lazy bytestring in memory, then no; it will cache all that data and keep it in memory. If you make sure not to keep such a reference though, then it will nicely behave as a stream. Different people weigh this distinction differently.
It has its ups and downs. I'm looking forward to it and hope i have the time to contribute in the future. You should contribute as well! That's how software improves - it takes contributions from you (the user) putting in your spare time to help make it the thing you want it to be.
I wish I had enough skills for that. I am only on the learning path right now :( When you don‚Äôt even understand all the syntax enough you can‚Äôt do much
If you need help on that path, I'd be happy to lend some time, as will many others :)
It should be possible to subsume SYB-style traversal with GHC Generics or kind-generics, but I don't know of an existing, comprehensive solution. There may be a nice combination of [`Lens.Plated.transform` (in lens)](https://hackage.haskell.org/package/lens-4.17/docs/Control-Lens-Combinators.html#v:transform) and the typed traversals in `generic-lens`. The `generic-deriving` package also has a version of [`Uniplate`](https://hackage.haskell.org/package/generic-deriving-1.12.3/docs/Generics-Deriving-Uniplate.html).
(One of the others here) Since it was quite painful to get it through the reviewing process (there was always at least one reviewer who just couldn't "live" with the presentation style), we'll probably not write a paper in a similar style again ; ) Nevertheless, I absolutely see your point/concern, why the style might be distracting.
In terms of the fact that they both deal with binary data? Yeah, basically. However, usually you use both lazy and strict ByteStrings for passing around data within your application, rather than for I/O with the outside world like you would with Java's Stream. As /u/ElvishJerricco points out, you *can* use lazy ByteStrings for this latter usecase as well, although it has... pitfalls. If you need to stream data from a network connection, file etc., you should probably reach for [`pipes`](http://hackage.haskell.org/package/pipes) or [`conduit`](http://hackage.haskell.org/package/conduit) instead.
PWND! My bad haha
And also (in a star free world) you can also directly inspect and print it (or generate samples), giving you some bidirectional it :)
Are you still using some variant of `Eff`?
An implicit rule on hackage is "The less documentation your package has, the smarter you are." Who cares about the package user ?
For the record, here is the content of [the Gist](https://gist.github.com/SimonAlling/00e728961c3f3f8cbb9daa32cc1d8b20) at the time of writing: ``` {-# LANGUAGE RebindableSyntax #-} import Prelude hiding ((&gt;&gt;)) data Config = Config { depth :: Int, width :: Int } printInfo :: Config -&gt; IO () printInfo config = mapM_ putStrLn $ do "************** INFORMATION **************" "Welcome to the Hydraulic Press Channel." "Here is your configuration:" "" " depth: " ++ show (depth config) " width: " ++ show (width config) "" "*****************************************" [] where (&gt;&gt;) = (:) main :: IO () main = printInfo defaultConfig defaultConfig :: Config defaultConfig = Config { depth = 5, width = 10 } ```
This is as evil as C++
Why? (I'm not an expert Haskeller, and I only have basic knowledge of C++.)
Because the semantics would become very different to what other Haskellers expect (like `&gt;&gt;` not being a right shift in C++), plus this seems like a C-style multi-line string.
Note: Triple backticks don't work on mobile reddit apps. Please use 4 space indents instead!
Please take all my money
Yeah, I was wondering what was going on there. Thanks for the heads-up!
They don't work on old reddit either.
In a module `Messages`, which only contains messages like the one in the example and a comment about the modified semantics of the `do` notation, is it still evil?
Wow, this is the book I wish I had when I first encountered haskell!
Isn't that possible with OverloadedStrings already?
How?
Why not something like [qc](http://hackage.haskell.org/package/interpolatedstring-perl6-1.0.1/docs/Text-InterpolatedString-Perl6.html)? So the example becomes: printInfo config = putStrLn [qc| ************** INFORMATION ************** Welcome to the Hydraulic Press Channel. Here is your configuration: depth: {depth config} width: {width config} ***************************************** |]
Read Oleg's notes, it is indeed there.
Don't forget that if you submit any of these solutions you've seen here you will be committing plagiarism, which is something very serious at any university. I've caught students who've been seeking answers (not help with coming to the answer themselves) on IRC several times before and it doesn't end well for them. Just keep this in mind - universities are about students demonstrating they have attained the knowledge of their field, not that they can find the answers to tests.
Wow, that's definitely neater in the case of strings. But how about lists in general? {-# LANGUAGE RebindableSyntax #-} numbers :: [Int] numbers = do 5 9 12 16 [] where (&gt;&gt;) = (:)
care to tl;dr for muggles like me who‚Äôre on mobile?
You haven't even read the book :v, how do you know, from few lines of intro...?
There are more than 40 chapters available for reading on the website already :)
Oh thanks, I didn't read well the bottom part.
I've only had time to read the first few paragraphs, but I'm already very excited about this book. It sounds amazing so far! I can't wait to read more :)
I purchased and read through the 40+ chapters. As an FYI, the content is very introductory.
I just reworded it a bit to make it more obvious :)
Ah, [found it](http://okmij.org/ftp/tagless-final/course/TTFdBHO.hs). The type `Intensional` in Dino corresponds `HORepr` in that file. Thanks!
What‚Äôs the scope of the text? Is it complete?
I'm not sure what you aversion to commas is: numbers :: [Int] numbers = [ 5 , 9 , 12 , 16 ] Same number of lines, no extensions needed.
But, printInfo isn't a message; it's instructions for interacting with the RealWorld# that give back no meaningful value. info :: Config -&gt; String info config = unlines [ "************** INFORMATION **************" , "Welcome to the Hydraulic Press Channel." , "Here is your configuration:" , "" , " depth: " ++ show (depth config) , " width: " ++ show (width config) , "" , "*****************************************" ]
Will you use horoscopes to find proper employee?
&gt; For more information, see the README. The hackage page links to a different [repo (trackit)](https://github.com/emilaxelsson/trackit/blob/master/README.md)
A reply like this sorely needs the error from the compiler.
A reply like this strongly needs the error(s) from the compiler.
Oops, copy-paste error. I've fixed it now, thanks!
The book is not complete yet, I'm still writing it. As of today, 40+ chapters have been edited and published. Early access subscribers have access to all of them. You can expect more chapters to be published on a regular basis for many months to come. The book will cover enough material so that the reader can go from knowing English to being a knowledgeable programmer particularly comfortable with Haskell and types. It will be a very long and fun book :)
To be pedantic, there are more valid "programs" than the identity function for a "program" of type `program :: input -&gt; output`. For example, choose any value `v :: output`: program :: input -&gt; output program = const v The Socratic reasoning falls apart a bit because of not properly constraining the initial question... In general though, a great read.
This is certainly clever, but I can't say that I like it. As others have points out, you can accomplish the same thing with list literals or quasi quotes. You could also do this with multi-line strings, although it's pretty ugly: printInfo config = putStrLn $ "************** INFORMATION **************\n\ \Welcome to the Hydraulic Press Channel.\n\ \Here is your configuration:\n\ \\n\ \ depth: " ++ show (depth config) ++ "\n\ \ width: " ++ show (width config) ++ "\n\ \\n\ \*****************************************"
Programs linked with ASAN report memory leaks when building with GHC 8.6, but not with 8.4. What is the easiest way to suppress them without disabling leak detection globally?
Cool. I‚Äôm gauging its applicability to a pro-bono reading group. Can you gloss the scope (in Hask, if you wish) of the current 40 chapters?
You can: module MyAllPackages ( module Data.List , module Control.Monad ) where import Data.List import Control.Monad This is pretty common when building a custom prelude. Stephen Diehl's post goes into (much) more detail: &lt;http://www.stephendiehl.com/posts/protolude.html&gt;
Exactly. I meant a `Messages` module with a couple of pure functions like `info :: Config -&gt; String`. Is it then evil to construct multi-line messages the way I did? More importantly, is it evil to use `RebindableSyntax` and `do` with `(&gt;&gt;) = (:)` to define a list? For example in a small module that only contains one or two configuration lists. I'm not talking about dropping `where (&gt;&gt;) = (:)` at seemingly random places in a code base.
As far as I can tell, the book introduces `program :: input -&gt; output` as a way to talk the concept of programs taking input and producing output. It goes on to talk about programs that simply return their input. That is, `program :: input -&gt; input`, or `program :: output -&gt; output`, or ultimately `program :: x -&gt; x`. That last `program` is the one it claims is the identity function. Is it worthwhile to say that `f :: x -&gt; x` has more than one implementation as long as you have some value `v :: x`? I don't think so. There's no way to come up with such a value, other than things that are the same as `undefined`. That's certainly something that's worth knowing at some point, but I feel like it doesn't belong in an introductory text.
Do you have screenshots?
* No trailing commas. Depending on your choice of formatting, changes at either the beginning or the end will produce an ugly and not so informative diff. * The commas are basically noise to me in this context. I only want to express a list of numbers (or something else). I wouldn't put commas like that if I listed something on paper. * More to type when adding items to the list. I have actually found a use case where just pressing Enter feels _very_ intuitive, but that might be a topic for a different post.
Would love to hear more on this; for example what do you mean "very introductory"? What is the range of concepts covered? How much of it applies to intermediate+ Haskell concepts?
I didn't know about `QuasiQuotes`; it definitely seems like an even better solution. Maybe my example isn't so good since it uses strings. Take instead as an example lists in general: numbers :: [Int] numbers = do 5 9 12 16 [] where (&gt;&gt;) = (:)
I don't know of a flag that you can pass to `new-build`, but you should be able to run `cabal new-clean` first.
I want to learn haskell on a Windows 10 machine. What is or are the best choices for a ide/text -editor to use.
There's nothing technically wrong with doing that, but: - `RebindableSyntax` is a very big hammer to wield for such a small problem. - I have never seen Haskell code like this. Coming across it in the wild would make me do a double take. - There are a lot of ways to accomplish the same thing using less powerful constructs. For example: `numbers = map read $ unwords "5 9 12 16"`. You could even write your own quasi quoter to do that at compile time. This is a neat idea, and it's good to play around with stuff like this, but I think you'll be hard pressed to convince people that `RebindableSyntax` is a good idea for avoiding list literals.
Nice! That's a great idea! So far, more or less, we've touched compilers, runtime, types, names, expressions, function definition and use, custom datatypes, pattern matching, exhaustiveness, strings, parsing, either, coproducts, isomorphisms, pairs, products, syntax, lists, induction, general recursion, runtime representations, termination, lambda calculus, partial application, mapping, typeclasses, instances, functor, parametricity, typeclass laws, composition, fixity. &amp;#x200B; As you probably realized from the first few paragraphs already, and from the weird order in which seemingly unrelated topics are introduced, the book takes a less ‚Äúhands on‚Äù approach, and focuses instead on a more philosophical way of looking at things, if you will. At least in these first few chapters, where the text is still trying to bootstrap the student, getting them into the proper mindset from where they can start to figure out themselves how to tackle the harder problems. Moreover, by design, there will never be an exercise that the student must do on their own, nor a need for having a computer nearby. As such, I think it's a great content to discuss out loud with peers for hours.
Added a screenshot to the post.
Looks nice! I'll try it and see if it can replace Synapse for me.
I must admit that it looks very nice! :-)
I think you should use whatever text editor you are comfortable with, along with `ghci` in your terminal. You don't need anything fancier to learn (or to program professionally for that matter).
Thanks! If you see any problems, feel free to file an issue - I'm not afraid to make some radical changes if they are required to improve UX.
Great! Thanks for the overview. I‚Äôve been looking for a text suitable as an introduction to (functional) programming that doesn‚Äôt assume prior CS or math.
Wow, I appreciate this so much! This coupled with some additional reading that I did helped so much. I love how you broke it down like that. Thank you :)!!
It has been deprecated and I'm not sure it still works. See: [https://downloads.haskell.org/\~ghc/latest/docs/html/users\_guide/codegens.html?highlight=backends#c-code-generator-fvia-c](https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/codegens.html?highlight=backends#c-code-generator-fvia-c)
For those in NY, but not NYC, the website says "Full-time, On-site, Brooklyn". I've got nothing against Brooklyn, except the 4.5 hour commute, one way, across two additional states.
Hm you should keep getting errors, otherwise that's a bug.
&gt; The commas are basically noise to me in this context. I only want to express a list *commas* are what indicate it is a **list**. They aren't noise, they are signal. &gt; More to type when adding items to the list. I have actually found a use case where just pressing Enter feels very intuitive Get / configure your editor to insert the ", " automatically, if that's more ergonomic for you. It's certainly possible in both vim and emacs.
&gt; No trailing commas. Yeah, would be nice if Haskell could support this. I've been told it makes building the AST slightly more difficult, but I really think optional-trailing-separator has shown itself to be the superior way to format code combining good aesthetics with small diffs.
What actually IS haskshell? What makes it different/worth learning (can be personal choise) for you? First time on this sub reddit and I don't know anything about the language...
"evil" is a loaded term, and I didn't introduce it into the conversation. I will say that `do` already as a semantics attached to it, and if you attach a significantly different semantics to it via `RebindableSyntax`, it can cause confusion and negatively impact maintenance speed. (This case is particularly troublesome since `[]` is already a `Monad` that can be used to `do` without rebinding syntax, and `String ~ [Char]`.) *I* don't think that cost is worth any advantages claimed so far in the discussion; I certainly don't think that it's worth it to avoid leading commas. But, it's your code, so you make the trade-off decisions. I expect to change my opinion if more clear advantages are presented, or if there the disadvantages are easily mitigated.
*After* you've learned a bit of Haskell, and decide it's worth it to spend time "fighting" with tooling, Haskell-IDE-Engine+VSCode might be a good solution. (Disclaimer: I've never used Windows 10.)
Nobody will be able to help you without more information. Have you tried &lt;http://help.code.world&gt;?
I find the idea of using parametricity as a basic guiding principle for an introductory book fascinating. Looking forward to the rest.
I think the idea is that `input` and `output` are uninterpreted, so with more traditionally naming we would say `program :: forall a b. a -&gt; b`. Although in this case there are no possible function definitions, since we have no information about `b`. Of course it *is* true that the only function of type `forall a. a -&gt; a` is the identity function.
oke, is there a sort tutorial that I can follow the install Haskell-IDE-Engine and VSCode.
Check this comment [https://www.reddit.com/r/haskell/comments/bbjq1o/a\_type\_of\_programming/ekjph20/](https://www.reddit.com/r/haskell/comments/bbjq1o/a_type_of_programming/ekjph20/)
That's an an excellent point! Thanks. I'll try and make it clearer.
Thanks for the help, What about the Language extensions? can the language extensions be shared like the 'import modules'?
If you are a programmer and you already know Haskell very well, this might be an entertaining read. But for anyone else, my opinion is that this is not going to work...It might keep them hooked for a while, and that will be all.
It seems to me it is NOT possible to import module locally. e.g. fun::String -&gt; String fun _ = L.map(...) where L = Data.List
I was inaccurate there. It shows me the errors but not warnings again
You can, but not in a module like the imports. You'll want to use the `default-extensions` field in your `package.cabal` file: &lt;https://www.haskell.org/cabal/users-guide/developing-packages.html#pkg-field-default-extensions&gt;.
I got conflicting when I use above code to import modules: and I can not use 'qualified' and 'as' inside module(...) module MyImport ( module Data.List.Split ,module System.Random ) where import Data.List.Split import System.Random
Ofcourse, thats why i was seeking for the simplest solutions which are easy to understand &amp; digest in order to get into the right mindset while replicating the solution to my own. But i appreciate your concern thanks.
&gt; At the other end of the programming spectrum, far away from computers, we have our imagination. Programming is the conversation that happens while these two ends struggle to understand each other. Why are both ends struggling? What are computers trying to make us (or our imagination) understand? And how is the struggle in other direction "programming". Programming is a well understood concept. Why drag unnecessary analogies (that does not work, by the way) into the mix? The whole article feels like something that is meant to sound "deep" but breaks down under close inspection. I think the author should go through the whole thing and remove such parts.
No, it's not possible to do that.
This is the error you're running into, right? Conflicting exports for ‚Äòsplit‚Äô: ‚Äòmodule Data.List.Split‚Äô exports ‚ÄòData.List.Split.split‚Äô imported from ‚ÄòData.List.Split‚Äô at Example.hs:5:1-22 (and originally defined in ‚ÄòData.List.Split.Internals‚Äô) ‚Äòmodule System.Random‚Äô exports ‚ÄòSystem.Random.split‚Äô imported from ‚ÄòSystem.Random‚Äô at Example.hs:6:1-20 There are a few ways you can work around it: - Hide the identifiers you don't want: `import System.Random hiding (split)` - Only import the things you do want: `import System.Random (randomIO)` - Qualify imports and explicitly list everything you want to export: `module X ( R.randomIO ) where import qualified System.Random as R`. You cannot export two things with the same name from one module.
Haskell is a non-strict, functional programming language originally designed by committee to be a unifying language for multiple avenues of research into non-strict semantics. There's more information in the links in the sidebar.
For the first point, you could try something like: \`\`\` (+&gt;) = flip (:) infixl 2 +&gt; &amp;#x200B; fromSnoc = reverse &amp;#x200B; myList = fromSnoc $ \[\] \+&gt; 1 \+&gt; 2+3 &amp;#x200B; myJSON = Data.Aeson.object $ \[\] \+&gt; "key1" .= (1) \+&gt; "key1" .= (2+3) \+&gt; "key3" .= ("4"&lt;&gt;"5"&lt;&gt;"6") \`\`\`
Interesting. Are notions like monads, monad transformers, arrows, lens, etc. outside the scope?
They are definitely in scope, but they are not yet part of the published material :)
I'm not sure what /u/elvecent meant, but you could do something like this: {-# LANGUAGE OverloadedStrings #-} {-# LANGUAGE GADTs #-} instance (s ~ String, IsString r) =&gt; IsString (s -&gt; r) where fromString str1 str2 = fromString $ str1 ++ "\n" ++ str2 test :: String test = "This is a test" "of a multiline string literal." "It supports multiple lines." The problem with this is that it uses an orphan instance which will spread to other modules. But `OverloadedStrings` doesn't actually get you much here, you could use the same technique without it to avoid the orphan instance: class MultilineString s where multilineString :: String -&gt; s instance c ~ Char =&gt; MultilineString [c] where multilineString = id instance (s ~ String, MultilineString r) =&gt; MultilineString (s -&gt; r) where multilineString str1 str2 = multilineString $ str1 ++ "\n" ++ str2 test2 :: String test2 = multilineString "This is another test" "of a multiline string literal." "Look ma, no orphans!" It's more difficult to get arbitrary lists though. I fiddled around with it a while back and couldn't get it to work.
Sure; I don't want to come across as too critical. HPFFP has great material, but if it was concise enough it would easily have become my favourite (introductory) Haskell book. At this point I'd love for someone to come up with an *intermediate*\-level book. How is your [https://lorepub.com/product/cookbook](https://lorepub.com/product/cookbook) coming up? It is sad to think that the other books (Joy of Haskell, [Intermediate Haskell](https://intermediatehaskell.com/)) don't seem to be going anywhere.
[removed]
Rust has a 3 month staged release cycle with both a stable release and a beta and I think it's working out pretty well there. New features are available on the nightly compiler. When ready they are stabilized, which means they get into the next beta and see testing and potential fixes for three months and then automatically go into the next stable version, unless big issues are found. That still means a change merged could take 6 months to reach stable in the worst case, but it's short enough to have a good pace but long enough to ensure maturity and not too much effort for maintainers.
&gt; _commas_ are what indicate it is a *list*. They aren't noise, they are signal. While I agree on this in general, I'm not convinced in the case I'm thinking of: Some sort of config list in a module containing nothing else. For the `numbers` example, I personally find the type signature, `numbers :: [Int]`, enough to understand what's going on. For me, commas are more of a visual and typing distraction than an information-conveying medium in a *multi-line* list; I don't expect everyone to have the same opinion though.
This, or you could probably do `--ghc-option=-fforce-recomp`
Great, I'll consider buying it then. :-)
There are a lot of subtle choices to be made here. I'm on my phone/lunch break, so I'm keeping it terse. I'm not sure this will work, but I think it'd be informative for you to play with: data instance (m :: Nat) !&lt; (n :: Nat) where LTZ :: Z !&lt; S n LTS :: m &amp;&lt; n =&gt; S m !&lt; S n step :: S m !&lt; S n -&gt; (m &amp;&lt; n =&gt; r) -&gt; r step LTS k = k HTH.
Oops, must be some old stuff we need to update. We've recently moved to Manhattan!
Yes we are!
Congratulations! Still too far a commute from the fingerlakes :-).
I‚Äôm super noob at Haskell, but shouldn‚Äôt be there an `=` sign somewhere around isEqual?
Guard expressions expect booleans in every branch. Put `otherwise` (which happens to be `True` in disguise) and `=` before `error`.
On line 45 there is no guard (you probably want `otherwise`/`true`).. Also a few general tips (not all of them restricted to Haskell, I guess): - If a compiler/interpreter tells you the error is on line N and you can't find anything there, start looking at the lines immediately above it (as you did) - when posting code online don't use images - learn precedences and avoid unnecessary parentheses (line 44 can be written as `(fst x, max (snd x) (snd y))` or even `(fst x, snd x \`max\` snd y)` - `greater` is usually defined already and often called `max` - don't use `error` it will come back and slap you in the face
When using guards, each guard has the following format: | &lt;condition&gt; = &lt;expression&gt; Your second condition (the one with the error) is missing the `&lt;condition&gt; =` part. If you want it to always return the error when reaching there, you can use `otherwise =`.
Thank you so much! That fixed the errors I had. Ofc new errors have popped up, but that's life.
This is exactly what I meant, thanks.
Thanks for the tips :D I'll bear that in mind in future.
This would benefit from direct comparison to MTL in the examples, as it is from the README I can't see how this is supposed to be easier to read or write.
/u/isovector, can you provide some more examples beside that copypasted over every free monad library Console one? I had some hard time figuring out how to make an effect that's built over regular State, Writer, etc.
I think it should be common for every freer library out there. I don't have a link at hand, but googling advantages of freer over mtl should provide some articles
Setup a hlint. It will tell you a lot of new things about code style
Huh, on an unrelated note, it occurs to me that this type-checks even without RebindableSyntax: Prelude&gt; :t (do "foo" ; "bar" ; "baz") (do "foo" ; "bar" ; "baz") :: [Char] It's Haskell, so if it type-checks, it must be correct! ;) In all seriousness, though, I also love RebindableSyntax, but I agree with others that it's best used in cases where Haskell is actually the syntax you want. For instance, in CodeWorld, I use it to reduce polymorphism. But if you want your own different syntax, it's easier to embed it in a quasiquote than a Haskell module.
Is this another extension heavy, system resource usage obscuring, confusing abstraction laden, effects package which supposedly helps productivity because standard Monads don't compose (in a functional language)? Gotta love those crazy Haskell programmers.
Can anyone explain this? isPalindrome = (==) &lt;*&gt; reverse I've gone over the types and everything but can't wrap my head around it (the &lt;*&gt; part, more specifically)
First off, the performance of this does seem really really good, especially compared to other free monads. I recognize that the criticism that follows is nitpicking at this point. But I'm skeptical that this is actually zero-cost. The linked GHC merge request includes a test that shows RankNTypes-style contraints can be specialized, which is half the problem (and will actually help Reflex perf considerably, as a side note). But the other half is that the interpreter has to be called, and can't be specialized because it's a higher order function and not a class method. So, what would ordinarily be a static function call with regular monads should result in at least a constructor allocation and dynamic function call from the user, and a `case` evaluation from the interpreter. Luckily constructor allocation in GHC is stupidly fast, and branch prediction should make the dynamic function call nearly as fast as static after all the code paths have been warmed up. But I'd be very surprised if all of this actually inlined down to zero in a non-trivially sized codebase. I think GHC would have to inline your whole entire program into a single function, and have perfect optimization, for this to be zero-cost. So if the user forgets an INLINE pragma or if the optimizer decides against inlining the interpreter in any place in this uber-function, it won't be zero. Plus, it's hard for me to judge what the perf characteristics of your union type will be. With mtl-style, you do still need to be diligent about `INLINABLE` (not necessarily `INLINE`) to make sure functions get specialized, but if you are then it's all just ordinary static function calls, not an uber-function, and you don't rely on the optimizer for much else. Anyway I know at this point the argument is close to negligible even for non-IO-bound tasks. The trick used by this library is really cool. It's essentially the transformer style, but with type directed lifting. Each effect is interpreted using some analogous transformer, and the type system tells GHC what `send` should do. In fact it makes me wonder if any of this is even necessary. Can't we have the same type directed lifting for chains of regular transformers? No need for intermediate ADTs and interpreters; whatever part of this library is figuring out how `send` should work could just be figuring out how many times to call `lift` instead. send :: (Member t r) =&gt; (forall m. Monad m =&gt; t m a) -&gt; TransformerStack r a Preferably such that `TransformerStack` is just some kind of type family, such that no wrapping or unwrapping of newtypes is necessary and you can just do this: runWriterT $ flip runStateT 0 $ runExceptT $ do send (tell []) send (modify (+1)) send (throwError "foo")
This is using the `Applicative ((-&gt;) a)` instance of functions for which you can find the implementation [here](http://hackage.haskell.org/package/base-4.12.0.0/docs/src/GHC.Base.html#line-822), in that case `(&lt;*&gt;) :: (a -&gt; b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c` is basically the well-known [S-combinator](https://en.wikipedia.org/wiki/SKI_combinator_calculus). Unfolding the definition (`(f &lt;*&gt; g) x = f x (g x)` gives you `isPalindrome ‚â° \x-&gt; (==) x (reverse x) ‚â° \x-&gt; x == reverse x`.
Exercise: Turns out `isPalindrome = (==) =&lt;&lt; reverse` works too, can you come up with a property that the left-hand side function (`(==)` in our case) must satisfy, such that this equivalence holds?
I've been waiting for this to drop! It looks too good to be true. Can't wait to read about the implementation &amp; dig through the source. And use it of course!
Are you as hype for [`polysemy`](https://github.com/isovector/polysemy#readme) as I am?
Does Agda too allow [insert name here] operators, eg. defining `‚ü¶_‚üß` (a one argument function) or even `‚ü¶_‚üß_` (a two argument function) etc.? When I learned Isabelle/HOL I loved the mixfix operators so much and this other notation which I don't know the name for, they can really improve the readability of proofs/code.
Looks like something went wrong with the haddock generation for https://hackage.haskell.org/package/polysemy-0.1.0.0. Links to `Monad` for example point at https://hackage.haskell.org/package/polysemy-0.1.0.0/base-4.12.0.0/Control-Monad.html#t:Monad which doesn't exist.
Not gonna lie, your commentary on this was what I was waiting for. The implementation details are rather over my head, but your comparisons between `mtl` and the various free/r constructions have been very informative as this design space has evolved. Reading this comparatively glowing praise is also pretty encouraging.
Can someone explain like I more or less know what monads are but not sure what a higher order free monad library accomplishes? Is it just a collection of monads that implement generic programming patterns?
Very cool. Especially your explanations regarding type safety, such as: ‚ÄúThe normalizing property of Alt means that we are forced to treat both of those the exact same way. It forces us to obey the laws about the structures of regular languages.‚Äù It reminds me of a few years ago when i tried to explain why haskell was so cool and how type safety helps avoid errors. I noticed I didn‚Äôt really know what the hell i was even talking about. This might be hard to get across in a conversation, but at least I have a deeper example to draw on if my usual ‚ÄòMaybe‚Äô based example fails to impress.
If you know Scala at all (or maybe even if you don't), I recommend [R√∫nar Bjarnason's "Reasonably Priced Monads" talk from a few years back.](https://www.youtube.com/watch?v=M258zVn4m2M) `polysemy` solves a bunch of less-than-perfect aspects of what is described in that talk (need for boilerplate, performance penalties, inability to express things like `bracket`), but the value proposition is the same.
The compensation is ridiculously low, specially for haskell.
There was an ASPLOS paper back in 2013 that explored this concept: [https://www.gribble.org/papers/asplos021-hunt.pdf](https://www.gribble.org/papers/asplos021-hunt.pdf) &amp;#x200B; We would like to have good support for this eventually with deterministic containers, but we don't yet. If we think of the boundary between the deterministic system as the outside -- everything that crosses that membrane from the outside world basically must be recorded in order to reproduce the run (i.e. record and replay). But as the paper above explores, you can either encapsulate each node individually, or an entire distributed system, which creates a tradeoff between amount of network communication recorded, vs. overheads of synchronization. &amp;#x200B; The initial version of our containers will initially let you, say, determinize every container in a Kubernetes deployment individually, but it won't directly support making the entire distributed system run deterministically. Then again, for debugging, being able to reproduce failures by running just the container that crashed is probably most convenient anyway.
&gt; Does Agda too allow [insert name here] operators, eg. defining ‚ü¶\_‚üß (a one argument function) or even ‚ü¶\_‚üß\_ Yes. Completely "around" operators ([\_]) don't have fixity / precedence. "Dangling" operators ([\_]\_) do have fixity / precedence that apply to the dangling side. You also don't have to use punctuation only; so if_then_else_ the defined / parsed the same way.
&gt; Does Agda too allow [insert name here] operators, eg. defining ‚ü¶\_‚üß (a one argument function) or even ‚ü¶\_‚üß\_ Yes. Completely "around" operators ([\_]) don't have fixity / precedence. "Dangling" operators ([\_]\_) do have fixity / precedence that apply to the dangling side. You also don't have to use punctuation only; so if_then_else_ the defined / parsed the same way.
Thank you. &amp;#x200B; I didn't really stay interested in maintaining the large set of template Haskell right at a point in time when the churn of TH AST changes introduced by GHC was proving to be incredible. That's what happened (sorry Michael). &amp;#x200B; Your options vary by your needs. Instant generics (now just "GHC generics"), which I disliked at time of working on that paper, has now came into being with compiler support that reduces manual labor (some). Combine this with solutions like plated and you have what, in many cases, will optimize well I expect (see Syrak's comment and link). This solution doesn't fully cover the same feature set as TYB, hence the "needs" caveat above.
&gt; Speaking of palindromes, can you figure out why init &lt;&gt; reverse palindromizes (eg. turning "abc" into "abcba") words? That's the `Monoid m =&gt; Monoid (a -&gt; m)` instance interacting with the `Monoid [a]` instance. The former is implement like `mempty = \x -&gt; mempty` (argument ignored) and `(&lt;&gt;) f g = \x -&gt; f x &lt;&gt; g x` (pass argument to both sides). For the types: `(&lt;&gt;) :: Monoid m =&gt; m -&gt; m -&gt; m`, `init :: [a] -&gt; [a]`, so `(&lt;&gt;) init :: ([a] -&gt; [a]) -&gt; [a] -&gt; [a]`. And, `reverse :: [a] -&gt; [a]`, so `init &lt;&gt; reverse :: [a] -&gt; [a]`. For the implementation `init &lt;&gt; reverse = \x -&gt; init x &lt;&gt; reverse x = \x -&gt; init x ++ reverse x` and in particular `(init &lt;&gt; reverse) "abc" = init "abc" ++ reverse "abc" = "ab" ++ "cba" = "abcba"`. `id &lt;&gt; reverse` will also make palindromes, of even length.
Is it? It doesn't say the level of experience they're looking for, but it is in line with my expectations given SF remote salaries. And I don't know how NYC-local salaries differ.
`const undefined :: a -&gt; b` and ``\x -&gt; x `seq` undefined :: a -&gt; b`` are there, but they have bottoms. `undefined :: c` can be correctly typed as `undefined :: a -&gt; b`, and it is a bottom. I know we like to ignore bottoms, but it might be useful to make sure an mention that.
Whoops, I was trying to use haskell syntax to speak generally about functions. While undefined certainly enhabits every type in Haskell, there is no univeraal inhabitant for mathematical sets.
The main idea is to figure out a nice way to "combine" effects from different monads in a clean and composable way. And the additional hope is that, if it's simple and clean enough, you can even break-down monolithic monads like IO into smaller pieces that can only do certain types of effects.
sorry i am busy
Beautiful
The author of this lib has a great blog post about it, Google "too fast, too free" and "reasonablypolymorphic" (sorry, writing from the phone with a poor internet connection)
From the [`layers` documentation](http://hackage.haskell.org/package/layers-0.1/docs/Documentation-Layers-Overview.html): &gt; The other reason why this is not done is because these instances require the OverlappingInstances extension. layers doesn't solve this problem, but we just say "fuck it" and use OverlappingInstances anyway. I agree. If we are willing to use overlapping instances, then we can avoid the O(n¬≤) instances problem in `mtl`.
&gt; GHC would have to identify that a recursive function is only ever called with the same interpreter argument to inline the interpeter into it. This is actually what is also holding back stream fusion. The responsible optimisation would probably be constructor specialisation (`-fspec-constr`), but it's a little unclear how to apply this to function parameters without duplicating the original function definition (i.e. `interpretH`) arbitrary many times. Let alone the compiler performance implications of doing so. See the thread [here](https://gitlab.haskell.org/ghc/ghc/issues/16473#note_189984).
That looks nice, how does it compare to \`operational\`?
You don't think a life style based on reason is a better choice that one based on a rejection of reason and an acceptance of superstition?
How about the toxically irrational folks?
this is just as readable and I won't look at the code asking wtf is going on.
When I run HLint, it makes the following suggestion: ``` src/Handler/Risks.hs:183:17: Warning: Avoid reverse Found: reverse . sortBy (compare `on` (riskCreatedAt . snd)) Perhaps: sortBy (flip (compare `on` (riskCreatedAt . snd))) ``` Should I avoid using `reverse`? If so, why?
Why does runState require a Typeable? https://github.com/isovector/polysemy/blob/master/src/Polysemy/State.hs#L51
Let's say I make a type ``` data MyType = MyType { a :: Int , b :: Int } ``` Then I know by using the data constructor `MyType` to construct a new value with this type. However, what I want to do is to *restrict* this type a little bit, by not accepting arbitrary values `a` and `b` of type `Int` as arguments of `MyType` constructor. Let's say I want the two integers satisfy some conditions, e.g. I want `a^72 + 33357 * a * b - 96 * b^3` to be a non-zero value. What are my options then? I can create a new function which is basically a constructor ``` f :: Int -&gt; Int -&gt; Maybe MyType f a b = if (&lt;a and b satisfy the condition&gt;) then Just (MyType a b) else Nothing ``` But it is annoying to deal with `Maybe` wrapper hanging around. Otherwise I can make using `error` if the condition on `a` and `b` does not meet. But I feel it is generally redundant to create a new constructor. I wonder if there is any neat way to deal with this situation?
Post an actual description of your issue.
This link has a lot of detail on this topic: https://ro-che.info/articles/2016-04-02-descending-sort-haskell I personally think the alternatives to reverse have better syntax, but it appears that there's no clear superior choice.
Possibly related: https://github.com/commercialhaskell/stack/issues/4706#issuecomment-480671812 There is a long-running feud between @snoyberg and @hvr. I can't find a documented timeline but it was [well-established](https://github.com/commercialhaskell/stack/issues/3345) a year ago. I thought things had de-escalated recently.
Hi! Thanks for the response! You might be right about large-scale programs, but really-and-truly all of the machinery optimizes away in my benchmarks. For example, loop :: Member (State Int) r =&gt; Semantic r Int loop = do n &lt;- get if n &lt;= 0 then pure n else do put $ n - 1 loop main :: IO () main = print $ countDown 100 countDown :: Int -&gt; Int countDown s = fst . run . runState s $ loop after my GHC patch is merged + [a userspace core plugin](https://gist.github.com/isovector/e4832512ec9c73bff94432a7a58470f9#gistcomment-2872671) to make the opimizer work a little harder, results in the following core: Rec { -- RHS size: {terms: 18, types: 6, coercions: 8, joins: 0/0} main2 :: Int -&gt; Identity (Int, Int) main2 = \ (s1_a6pN :: Int) -&gt; case s1_a6pN of wild_a5Hp { I# x_a5Hr -&gt; case &lt;=# x_a5Hr 0# of { __DEFAULT -&gt; main2 (I# (-# x_a5Hr 1#)); 1# -&gt; (wild_a5Hp, wild_a5Hp) `cast` &lt;Co:8&gt; } } end Rec } -- RHS size: {terms: 17, types: 18, coercions: 4, joins: 0/0} main1 :: String main1 = case (main2 (I# 100#)) `cast` &lt;Co:4&gt; of { (a_a2BS, b_a2BT) -&gt; case b_a2BT of { I# ww3_a5Lf -&gt; case $wshowSignedInt 0# ww3_a5Lf ([] @ Char) of { (# ww5_a5Lj, ww6_a5Lk #) -&gt; : @ Char ww5_a5Lj ww6_a5Lk } } } -- RHS size: {terms: 4, types: 0, coercions: 0, joins: 0/0} main :: IO () main = hPutStr' stdout main1 True which as you'll notice is pretty dang good! (I'm not sure why `main2` isn't getting a join point, but hey, I'll take what I can get). &gt; So if the user forgets an INLINE pragma or if the optimizer decides against inlining the interpreter in any place in this uber-function, it won't be zero. The library encourages using TH to generate all of the necessary pieces, and the TH won't forget the inlinable pragmas :) &gt; Recursive functions make it even harder. GHC would have to identify that a recursive function is only ever called with the same interpreter argument to inline the interpeter into it. This was indeed a problem, but I figured out a workaround: factorial :: Int -&gt; Int factorial 0 = 0 factorial n = n * factorial (n - 1) {-# INLINE factorial #-} you can instead write it with an explicit loop breaker: factorial :: Int -&gt; Int factorial 0 = 0 factorial n = n * factorial_b (n - 1) {-# INLINE factorial #-} factorial_b :: Int -&gt; Int factorial_b = factorial {-# NOINLINE factorial_b #-} and now GHC will happily do all of the usual optimizations on `factorial`. [I've added some TH](https://hackage.haskell.org/package/polysemy-0.1.0.0/docs/Polysemy-Internal-TH-Performance.html#v:inlineRecursiveCalls) that will build these for you. &gt; what the perf characteristics of your union type will be The core `Union` stuff is actually crazy friendly to the inliner; it uses constant space and no `unsafeCoerce`s. By itself, I was often seeing GHC 8.6.3 optimize everything away --- even in lieu of my patch! Where it does seem to break down is the introduction of `Yo` which is what makes the whole thing freer. Honestly it was a hard bullet to bite, but after enough of my test users complained about having to write instances for the higher-order effect threading, it seemed like the right move. &gt; In fact it makes me wonder if any of this is even necessary. Can't we have the same type directed lifting for chains of regular transformers? What a neat idea! I'd love to see the outcome of that. Anyway, thanks for the response, the kind words, and the fact checking!
It's an annoying little side-effect of getting [`runErrorInIO`](https://hackage.haskell.org/package/polysemy-0.1.0.0/docs/Polysemy-Error.html#v:runErrorInIO) to be possible. The good news is that GHC will solve typeable constraints on the fly, so it shouldn't really be any more of an issue than an annoying API.
&gt; The library encourages using TH to generate all of the necessary pieces, and the TH won't forget the inlinable pragmas :) The "necessary pieces" aren't the parts I'm worried about. It's userspace functions written in terms of the generated primitives. Those functions need to be given the interpreter at runtime to give the interpreter to the primitives. So the primitives may surely get inlined, but if not all the user's functions do as well then you're going to break the optimizer's ability to substitute the interpreter. Hence the uber-function I mentioned. I think literally the entire program *must* be inlined into one giant function for the optimizer to even have the opportunity to make this zero cost, which it's still not guaranteed to do.
I assumed those big whitespace chunks were images that wouldn‚Äôt load on my machine. Good to know that‚Äôs not the case, but you should know it‚Äôs not obvious (to me) that they‚Äôre chapter dividers.
There's a ghc option to make errors out of warnings.
Honestly, I feel the `Maybe` smart-constructor approach is the "neat"est way that *any* language has of dealing with this. It's hella better than having to check `errno` after a "constructor" call to determine if the object you got back is even valid. In languages that support contracts, has that inequality be a precondition of the constructor. Haskell doesn't support contracts in that way, though. When the compiler/interpreter can automatically determine if my contract is satisfied, this works well. When it can't I find things rapidly devolve: I might have to write in a separate, inner language of contracts to proofs or tests or something like that. I might have to simply assert the inequality is true. The language might (silently) turn it into a runtime test. (Or some combination of the three). Since Haskell doesn't have contracts, you either have to go the assertion route, or the runtime test route, but you never have to deal with a secondary langauge of contracts. You can, in dependently typed languages, have the constructor take an additional proof term that represents the inequality. With enough GHC extensions, you might be able to do this in the Haskell-like language it implements. It's honestly got basically all the same trade-offs as the contracts approach, though in a proper dependently-typed language you are using the same language for proofs/expressions and propositions/types; even with all the GHC extensions in the world, proposition/proof programming doesn't feel like normal programming. Proofs can be inferred sometimes (equivalent to the compiler automatically seeing the contract is satisfied). Proofs can be erased from the run time operations sometimes (equivalent not NOT doing runtime testing of the contract).
&gt; Should I avoid using reverse? If so, why? It's O(n). Don't worry about it for short lists.
I think if you‚Äôve had no experience programming and learning fp on your own you‚Äôre likely to be hard pressed to have a better outcome with any of the other material unsupplemented. This text interests me in that it could be used, after a point, as the ‚Äúspine‚Äù on which to hang other materials for such a person.
(congrats on the release!) It would be really nice if there was an effects zoo, that in particular contained code that proved challenging in terms of performance for various libraries. Obviously the suite would have to be ported and adapted to each library, but it would at least make comparisons much easier and it would codify a lot of the gotchas that people have discovered. Personally I've been burned by an `mtl` alternative (at a certain point trivial additions were causing bad performance regressions we couldn't understand, but the prospect of rewriting the code was extremely daunting and risky). So I'm looking for big examples, spread over multiple modules, code with many a dozen `Reader` and `State` effects, zooming, etc, etc.
Looks interesting, I've added to https://github.com/somlor/functional-cryptocurrencies#smart-contract-languages.
warnings should remain too
this behavior of \[warnings disappearing\] confused and bothers me too
Is it really surprising FPComplete would resort to such petty actions?
You might enjoy http://hackage.haskell.org/package/dejafu, if you're not already familiar.
Add a `cabal.project` with the following contents: ``` packages: . package name_of_your_package ghc-options: -Wall -Werror ```
Software development doesn't seem to be permeated by those types :) probably because it peddles in logic.
It did looked interesting at first. But soon I encountered pretentious stuff. I wrote another comment in this thread about it, but it soon disappeared from the view... If you have no experience in programming, then this stuff can bore you to death, and you might even come out with the idea that programming some magical stuff that require such elaborate setups to comprehend...Which is quite a sad thing to happen to anyone..Imagine if it can do this to plain old simple imperative programming, what it can do to stuff in Haskell..