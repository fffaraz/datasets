Yep, great IDE! I hope it will continue to evolve.
Try the installation procedure described on the wiki: http://haskell.org/haskellwiki/Leksah#Installation_for_Ubuntu and consult the installation section of the manual: http://leksah.org/leksah_manual.pdf
I don't really get why everyone wants consistency between the two. It's not as if you ever have to use both. As a user you can always use the cabal command line tool. The only remaining use case for using runghc Setup is distro packages (and they always specify a prefix explicitly).
Yay, fail by default.
Race to register /r/notypespleasewerebritish...
Don't forget nhc98/yhc!
Right you are - my mistake. Copying ~/.cabal would only copy over the tarballs of things you've downloaded.
I'm being serious here, but why is this exciting? I don't mean that negatively, I was just curious what it has to do with Haskell.
Mechanized theorem provers are essentially the "cloud of languages" beyond Haskell. They're where Haskell will steal its next ideas on types, IDEs etc. This is a serious book by an industrial user of theorem proving (Harrison is at intel doing chip verification), and, along with things like Haskabelle/Isabelle, Coq, Agda can help inspire us Haskellers to push the boundaries.
I've read chapters 2 and 3 from a pre-print version of this book, and I know I need to spend much more time with it. Highly recommended!
Hmm... looks like I'll be skipping class on Thursday.
"You could say haskell is kind of a spreadsheet on steroids, although it lacks the graphics ;)."
Same here. Are you in PSU CS?
I vote global for now. If you want to compile a file that uses a library that was cabal-installed, you have to cabalize the file too. It's a hassle for rapidly changing portions of apps, especially while everything is in the prototyping stage of things.
Haha, sucks to be you. Just remember your NFA-DFA conversion and the pumping lemma, and you'll do fine :) Edit: I'd be surprised if Tolmach isn't going...
Just remember, anything you do there will have no global side effects . . .
If anyone needs heredoc syntax in haskell now, you can use this code (I can't remember where I got it from). In Heredoc.hs: module HereDoc (heredoc) where import Language.Haskell.TH.Quote import Language.Haskell.TH.Syntax import Language.Haskell.TH.Lib heredoc :: QuasiQuoter heredoc = QuasiQuoter (litE . stringL) (litP . stringL) To use it: import Heredoc someString = [$heredoc| This is a string it is in a heredoc (unfortunately you can't embed haskell expressions in it though) spaces before and after lines are kept |] main = putStrLn someString Note that the heredoc can also be embedded in expressions, it doesn't have to be top level. Eg printHelp = putStrLn [$heredoc| -v Prints every action -R works recursively --dry-run only prints the actions, doesn't run them |] Note that the function keeps all whitespace, eg the strings string1 = const [$heredoc| Some String |] 42 string2 = "\nSome String\n " are equal. Therefor you might want to trim the whitespace off the front and end of the string before use. I use the function: -- | Removes all whitespace from the start and end of the given String trimSpaces :: String -&gt; String trimSpaces = reverse . dropWhile isSpace . reverse . dropWhile isSpace to do this. Also, any space at the front and end of each line is also kept, eg string1 = const [$heredoc| Some String |] 42 string2 = "\n Some String \n " are equal (you can't see the extra spaces in string1). To remove all whitespace from the front and end of lines, use removeLineSpace :: String -&gt; String removeLineSpace = trimSpaces . unlines . map trimSpaces . lines 
Leksah is sadly crashing X for me too: Ubuntu 8.10 amd64, ghc 6.10.2. You can raise the bug and I'll comment on it. The URL below has a trailing . so here it is fixed up: http://code.google.com/p/leksah/issues/list Leksah is excellent so I encourage everyone to try it.
In the shell and Ruby, initial whitespace is stripped from `HERE` documents; however, Python's multiline strings keep all of it so you have to do the same transformations as given here. The present system in Haskell isn't bad but could be so much nicer :)
I don't see the point of explicitly dropping single character escapes. Since his heredoc format explicitly elides the final carriage return, you'd need \n to get a terminal newline! Otherwise, I could actually see myself using these.
The trimSpaces and removeLineSpace transformations could be integrated into this heredoc syntax by rewriting the Quasiquoter. For example this one applies the removeLineSpace transformation automatically: heredocS :: QuasiQuoter heredocS = QuasiQuoter (litE . stringL . removeLineSpace) (litP . stringL . removeLineSpace) With this, the following is true: condition = [$heredocS| Some String |] == "Some String" Writing a quasiquoter function that would allow embedded haskell code would be much more difficult, but still possible. The main issue I have with this syntax is it is impossible to nest heredocs. While this isn't often necessary, a good syntax should allow it when it is. 
Where's the generated proof itself?
I like it more than TH solution.
You'd use `\NL` instead, because when embedding a newline to be interpreted by, for example, `sed`, you want to input `\n`. The idea is that you can encode most languages that aren't Haskell straightforwardly in the `HERE` document; unfortunately, that means that most single character escapes must go (what would the regex example look like with them?).
Whatever it does, it should print a message to the effect that it's not doing the other thing. Cabal will install these packages for your user only. Or maybe: You have not set an install location -- Cabal will install for your user by default. Would you like to set an install location now? The Mac has spoiled me :)
In a round-about way. Right now I'm taking some Middle English courses and working on a software startup. I am, however, a CS major at PSU.
To be honest, the whole \ system does not make a lot of sense to me. What is the deal with the \&amp; ?
About two days ago the beta version of the Haskell Platform was released. Since it comes with an OpenGL library, it is now trivially easy to start making OpenGL programs with Haskell. To test this, I decided to make a simple Pong clone for two reasons: * To experiment with making an OpenGL game * I chose to use the GLFW instead of the GLUT library because GLUT doesn’t respond to closing a window with the close button very well. However, I could only find one piece of sample code for GLFW. Because of that, I decided to make a small game that others can use as a starting point for their own games. The controls are very simple: The up and down arrow keys move your paddle and Esc quits the game. This is my first upload to Hackage, so any comments or suggestions are welcome.
I usually don't post +1s, but .. Very nice code :)
So I've been trying to recreate the bug (which seemed to happened at least 50% of the time) for the last couple of days with no luck. I can't remember exactly what triggered it, but I feel like it was related to copy/paste. Any bug post I make now will be way too under-detailed to do anyone any good. If you have any more "luck" getting it to occur, you may want to post it &amp; I'll add information as it turns up.
`\&amp;` is already in the string language for disambiguating certain character sequences. For instance, there are two non-printing characters identified by `'\SO'` and `'\SOH'`. So, what if I write `"\SOH"`? Does that mean the string `['\SO','H']` or the string `['\SOH']`? The answer is that it means the latter, and if I want to write the former, I have to write `"\SO\&amp;H"`. Similarly, `"\1234"` would mean (I think) `['\1234']`, whereas `"\12\&amp;34"` means `['\12','3','4']`. And so on. You can of course just insert `\&amp;`s all over the place if you want: "1\&amp;2\&amp;3\&amp;4" = "1234" they just get removed, as they represent the empty string. But they're necessary sometimes for the reason above.
Well, the solution in perl has always been to allow you to have a separate notion of single and double quoted heredocs, but the proposal as stated doesn't allow for for named heredoc terminators in that fashion. Using \NL is pretty arcane and violates expectations. Few people even remember those silly multichar names exist. ;) I wonder if a more extensible syntax would be beneficial: foo ``END a more heredoc like heredoc which could outdent all the way END I love the definition of foo `` a concise trimmed layout based heredoc But perhaps with the above 'traditional heredoc' added to handle the outdent case, perhaps ```` reads better as double quoting? foo ```` a "double quoted" $layout based heredoc with variable expansion and \n and all sorts of perlish goodness Then you can use foo ````END Dear $recipient, ... END This seems to give the best of all worlds.
Excellent, thank you so much for testing the platform, sharing the code, and writing up your experiences!
Excellent tool. Needs more exposure.
OK, so in review, it seems to only happened when using the menu item I created in the GNOME menu (or using Gnome-do... which is basically the same thing). If I launch it from a terminal instance it seems to work just fine. I've filed the bug report, but I'd be curious to know if this fixes it for you too.
This is on the right track, I think. That crazy escaping example took up probably 80% of the time I spent on the proposal `:)` We'd like a notation that interprets the `HERE` document in a double-quotish style; however, the variable references in your example are concerning. This amounts to a kind of implicit parameters and broadens the scope of the proposal to include templates. I'd rather allow quasi-quoters to generate templates (Haskell is not the functional extraction and report language, after all). As for the more traditional `HERE` document style: ``END I guess I actually prefer long strings of `` ` ``. Were we to adopt your more traditional style, then long regexen would start with this: ``r`END which I think is beastly. The alternative I have in mind at present is not so great, though: `` -- indented raw ``r` -- indented quasi-quote `" -- indented double-quotish `"r` -- indented double-quotish quasi-quote ``` -- block raw ```r` -- block quasi-quote ``" -- block double-quotish ``"r` -- block double-quotish quasi-quote This could easily become a bikeshed issue. I'd like to see a nice way to use `"` to indicate double-quotishness but your proposal is pretty good.
I have a quicky-hacked heredoc QQ that supports splicing in haskell code: http://moonpatio.com/fastcgi/hpaste.fcgi/view?id=2208#a2208 ghci&gt; [$here|The value of [0..4] is $([0..4])|] "The value of [0..4] is [0,1,2,3,4]" 
The above (quartz gtk2) also requires xcode 3.1, which you can find at http://developer.apple.com/mac .
I'll agree that the $variable expansion was a bit of a stretch and that perhaps quasiquoting is a better solution than adding magic that strings don't already offer. That said, we have the ability to do multiline quasiquoted literals with variable and code escapes with the [$heredoc| ... |] hacks mentioned above and those even subsume parsing without stripping initial space. So perhaps a dedicated heredoc syntax should just focus on the two cases of overly-literal quoting for easy regex-like encoding like you advocated for, and an 'everything works just like a normal string' encoding like I advocated for above: foo `` ^[-+]?[0-9]*\.?[0-9]+([eE][-+]?[0-9]+)?$ And an escapeful string: foo ```` Tell me more, I would like to subscribe to your newsletter\n and punt the rest of them to quasiquoter hacks. This has the benefit that compilers that don't implement the very recent quasiquoter stuff (read, all but ghc) might even consider adopting it. I have to admit the thing I liked most about your proposal was the stripping of the layout spaces.
I like this, but I think there is a slight flaw in the implementation of removeLineSpaces. Shouldn't it only remove the spaces that would be eliminated by layout? i.e. the spaces up to the indentation of the first non-space following the start of the heredoc? [$heredoc| hello world |] should probably decode to "hello\n world"
A further consideration about 'how to make it more haskelly': layout in Haskell has traditionally allowed the next token to start on the same line or on the one after it, that would, in the context of the above, encourage the following two things to also be legal, even if they are less 'heredoc'ish. foo `` hello world foo ```` hello world 
Well, I can't get to IRC easily, so I used Reddit. Could someone please notify the fine folk at Haskell.org that the front page link to GHC still links to GHC-6.10.1, and not the newest .2 !
dunno about you, but the ghc link links to the ghc homepage, at that one lists 6.10.2 as newest.
*Wiki* -&gt; *Edit* -&gt; *Done*.
&gt; and punt the rest of them to quasiquoter hacks. Rather than punt to quasiquoter hacks, why not use this syntax for quasiquoting in general. We start by making ``f ... (note no trailing backquote) the new syntax for [$f|...|] It's then not too hard to define a bunch of quasiquoters to use in place of f, such as *quote* (interprets escapes, but no antiquoting), *quasiquote* (interprets escapes and has antiquotes/interpolation), *verbatim* (no escapes nor antiquotes) or even *quasiverb* (antiquotes but no escapes). We also want lighter notation, we we can have a default quoter. Let `` ... stand for ``quasiquote ... If I want to use a different default quoter, I can't simply rebind *quasiquote* in the current file, because there's a phase problem, but I could (as far as Template Haskell is concerned) import a module that defines a different *quasiquote* to change the default. We can also allow the quoter to take arguments: ``(quasiquoteWith '#') #a + #b = #(show (a + b)) Note that quoter evaluated at expansion time so we can't do let q = quasiquoteWith '#' in ``q ... Again, we need to import *q*. Whether to strip leading/trailing/layout space can also be up to the particular quoter. Finally, it wouldn't be too hard to support arbitrary (non-alphanumeric?) delimiters rather than just sequences of backquotes: ``[[[I want `````` and ]] to be okay in this one.]]] ``r/a.*b/ ``r!need to match / here! 
I like it, its light weight and it subsumes the other uses mentioned here.
This is more in line with the original proposal; in particular it retains quasi-quoting as a use case. The terminal `` ` `` for quasi-quoters is there to cause an error if you accidentally leave out the space between the `HERE` doc start and the text to be quoted. It is a matter of preference, I suppose; it'd be interesting to hear arguments pro and con. The removal of some initial whitespace (`/\s*\n?/`) and some final whitespace (`/\n?\s*/`) is there to support what I think is a most usual thing to quote: usage = ```` USAGE: ... Use with potatoes... ```` Here we would keep `"\nUSAGE: ...\n\nUse with potatoes...\n"` which is all that we want. Also, when we think about the desired analogy with `do`, `if`, &amp;al. it seems reasonable that: xml = `` &lt;a&gt; &lt;b/&gt; &lt;/b&gt; should have no leading spaces. I do not want to seem not to be listening; however, I can't see a compelling reason to leave the spaces in and I personally have always hated having to take them out in, for example, Python. I never, ever find I want to leave them in.
The quad `` ` `` for double-quotish is growing on me.
At least on Swedish and Finnish keyboards, backtick is pretty much the most difficult character to produce. One needs to press shift+backtick-key and then space (e.g shift+backtick and then 'a' will produce à). So I hope that syntax requiring four consecutive backtick-characters never passes into any language. How about Python's """hello"""-syntax? 
What can you use this data type for?
Brain explosions, mostly. :-)
Cool, Reminded me of a [blog entry](http://byorgey.wordpress.com/2007/10/01/higher-dimensional-enumeration/) of Brent's.
I agree that I've never wanted to keep the initial spacing on a heredoc.
The "new account creation has been disabled as an anti-spam measure." really needs to be fixed, so that regular users can fix these problems. There have been a couple of occasions I have wanted to edit something in the wiki and then haven't due to this.
So I think we have relatively high level of agreement on stripping space from the front a `HERE` doc. What about stripping the final newline and any final spaces from the end? I'd like to encourage people to indent the `END` marker to line up with the first one. 
There is now a [part 2](http://twan.home.fmf.nl/blog/haskell/non-regular2.details), for some more brain explosions.
I'm not sure how you write much Haskell without backticks -- do you never use infix notation? I don't want to propose something that's hard for Finns (they did give us Linus, after all) but I would imagine a Haskell programmer from Finland would have encountered and overcome this problem long ago. However, triple `"` is not such a bad idea. I don't know that there is anyway to construct a legal identifier with it in Haskell.
Well, if there is no END marker at all, then that isn't a problem Layout ends the doc, and you might as well strip the final newline. Then can always doublequote and add it back if they really want it 
So I guess the only thing left for me to do is to write something to go through some Haskell and pull out the `HERE` docs, with space correctly removed and any quasi-quotation indicated.
Well, Niklaus Broberg was going to see if he could make haskell-src-exts round trip in such a fashion that prettyPrint . parse = id, it might be worthwhile just to see if it could be added as an extension to haskell-src-exts, and then the desugarer would just have to go through and replace this one feature and pretty print it back out.
It took me a moment to find the PDF link, but it was worthwhile. The article is only 10 pages and is a pleasure to read.
looks good, I'm getting a laptop with Windows to start doing some game development with Haskell, so this will be very useful as a baseline for my dev environment.
Is it widely known that simply switching from `[]` to the fold embedding alleviates the backtracking efficiency problems, without the need for difference lists? (Edit: the paper uses 'functional list' to mean 'difference list,' changed the wording to use the less overloaded term) To wit: data Backtr a = B { collect :: forall t. (a -&gt; t -&gt; t) -&gt; t -&gt; t } instance Functor Backtr where fmap f s = B (\c -&gt; collect s (c . f)) instance Monad Backtr where return x = B ($ x) s &gt;&gt;= f = B (\c -&gt; collect s (\x -&gt; collect (f x) c)) instance MonadPlus Backtr where mzero = B (flip const) mplus a b = B (\c -&gt; collect a c . collect b c) dfs s = collect s (:) [] upto 1 = return 1 upto n = upto (n-1) `mplus` return n Testing: *Main&gt; length (upto 10000) 10000 (1.66 secs, 1404689668 bytes) *Main&gt; length (dfs (upto 10000)) 10000 (0.06 secs, 4369904 bytes) Fundamentally, I'm just poking at the same type with a different stick (and BFS quickly becomes painful), just thought the correspondence was interesting. 
This isn't a particularly surprising result. upto for lists is repeatedly adding elements to the end, which is well known to be a bad operation for lists: upto 1 = [1] upto n = upto (n-1) ++ [n] This is O(n^2) if the entire list is evaluated: *Main&gt; length (upto 5000) 5000 (2.00 secs, 703565824 bytes) *Main&gt; length (upto 10000) 10000 (12.27 secs, 2809468944 bytes) That's why someone wrote the dlist package on hackage. We can write: upto' 1 = fromList [1] upto' n = upto (n-1) `append` fromList [n] which `DList` arranges to be `O(n)` in a similar way as `mplus` for your backtracker (although `DList` uses `[a] -&gt; [a]` internally): *Main&gt; length (toList $ upto' 10000) 10000 (0.08 secs, 6764152 bytes) *Main&gt; length (toList $ upto' 20000) 20000 (0.15 secs, 12411888 bytes) the more snocing your backtracking code contains, the better the continuation passing version will be, simply for algorithmic reasons (the continuation version may well optimize better, even if there are no asymptotic differences, of course).
&gt; This isn't a particularly surprising result. upto for lists is repeatedly adding elements to the end, which is well known to be a bad operation for lists: Of course, I'm just reusing the motivating example in the paper. &gt; That's why someone wrote the dlist package on hackage. Also known as FunList in the paper :). My point was that `Backtr a` is just the Church embedding of `[a]`, while `[a]-&gt;[a]` is, well, not. 
This has to be one of my favorite Haskell quotes ever: &gt;Berengal: I was squashing a bug, got frustrated, and typed "fix error" in ghci... 
The epoch of the "haskell weekly news, but the weekly part really is only a name really" had true gems e.g. &gt; "If a graph is reduced in a forest, and no one is around to pattern match the resulting WHNF, does it cause a space leak?" -- bd or &gt; "Why does the haskell webpage link to 'research papers' under the 'getting started' section?" -- wkh or &gt; "Haskell already has enterprise monads; there is a fail method." -- augustss
Thinking of it, I use this one: when' c a p = if p then c else a ...which is basically if', but with predicate last so you can curry consequence and alternative, then &gt;&gt;= in the bool.
How do I learn to understand non-strictness? I would like to be able to reason about my code and tell by myself which arguments of the functions I write are strict and which are non-strict. I haven't found a good explanation for this yet; most examples on the web talk about how to implement laziness instead (with thunks, yay). What I'd like is a good grasp of the theoretical basis. Exercises to go along with the definitions would be great. I usually learn effectively from them.
The theoretical (and practical) basis you're looking for is called *graph reduction*. The [Haskell Wikibook](http://en.wikibooks.org/wiki/Haskell/) features a [chapter about it](http://en.wikibooks.org/wiki/Haskell/Graph_reduction), but it's still incomplete. In the meantime, Richard Bird's [Introduction to Functional Programming using Haskell](http://www.prenhall.com/allbooks/ptr_0134843460.html) has an excellent introduction to graph reduction.
You can learn more about it when you need it.
Yes, the Wikibook talks about things I wanted to know about. I'll consider the paper book as well. Thanks!
Try also SPJ's [The Implementation of Functional Programming Languages](http://research.microsoft.com/en-us/um/people/simonpj/papers/slpj-book-1987/).
I am preparing a short paper describing the library for a local FP workshop in Spain. A draft is [available](http://safe-tools.dsic.upv.es/mediawiki/index.php/Jose_Iborra/Papers/Exceptions)
of course, going directly to the church encoding works as well. the nice thing is: you can make this into a two step process and reuse one step to implement different strategies. btw, the 'upto' example was not in the paper -- you must have read my preceding blog post :)
I thought the term "difference list" only describes a similar technique in logic programming but it seems that I was wrong. I have changed "functional list" to "difference list". Thanks for pointing that out!
&gt; the nice thing is: you can make this into a two step process and reuse one step to implement different strategies. Absolutely, I didn't mean to imply that splitting the type isn't more expressive. Excellent paper, btw. &gt; btw, the 'upto' example was not in the paper -- you must have read my preceding blog post :) Doh. I made the connection between `CPS FunList` and `Backtr` while reading your blog post, ran it against the `upto` example, and was going to post that general observation. This plan was foiled when I got sidetracked into trying to encode search strategies as a phantom type argument (splitting out `mplus` into a separate class and parametrizing on the strategy), which turned out to be less appealing than it sounds. So then I saw the paper, and figured I'd post the comment after all, not counting on the cunningly renamed central example :). 
&gt; the continuation version may well optimize better, even if there are no asymptotic differences, of course I'm not sure that the asymptotics are the same here, but I could be wrong. This is based on my own experience with DLists. I may be fallaciously generalizing from other situations that use DLists in ways that don't apply here, but I know of other applications where the continuation-based implementation is much *much* faster than DList based implementations. These examples use the same types, more or less, but the corresponding monad is completely different.
I use it as my window manager. Holy crap is it awesome, seamless, powerful. 
I can certainly imagine wanting to keep some leading or trailing space, especially if this is a general facility for arbitrary quoters, which is why I'd propose leaving it up to the quoter. The default quoter should certainly drop space. Actually, it hardly matters, since either way subsumes the other. It's not hard to write a quoter that keeps space within some delimiters: withDelim q = q . (unlines . tail . lines) . init Assuming that leading and trailing space is dropped, I can now get a string with space anyway: ``withDelim quote` . keep some space . ==&gt; " keep some\n space " Hm . . . if these things could expand into patterns with guards, then that could be an awful lot like views. For example, suppose we have amortized O(1) queues: data Queue a = Queue [a] [a] dequeue (Queue [] []) = Nothing dequeue (Queue (a:as) bs) = Just (a, Queue as bs) dequeue (Queue [] bs) = dequeue (Queue (reverse bs) []) Then we can destructure queues using quasiquote patterns, where: case e1 of ``queue`( x:xs ) -&gt; e2 ``queue`( [] ) -&gt; e3 expands into case e1 of q | Just (x, xs) &lt;- dequeue q -&gt; e2 Queue ([], []) -&gt; e3 
Ugh, Data.Typable.
Hooray for cabalisation!
I use xmonad and have been for about six months. Its absolutely perfect for my day to day work... One day when someone decides to resurrect the LISPM (but this time with haskell) this should be the GUI.
Hooray for EDSLs!
I've heard people argue that calling, say, DList a "difference list" is a distortion of the original idea of difference lists, and that the term only applies to the logic programming technique. I don't know how widespread the `[a] -&gt; [a]` usage is, but it's certainly possible that it's incorrect.
&gt; Also known as FunList in the paper :). My bad. :) I hadn't heard the term "functional lists" before.
Well, there are certainly some operations that are poor on `DLists` but would be better for continuation passing. For instance, I think the only valid way to implement fmap for `DList` is: fmap f = fromList . fmap f . toList which (not thinking about lazy evaluation for the moment) builds an `[a]`, builds a `[b]`, and then consumes it into a `[b] -&gt; [b]`. The continuation version, on the other hand, just precomposes the function onto the continuation. :) My remark was meant to say that it's conceivable that, say GHC, could do a better job optimizing continuation passing code than equivalent code operating on pattern matching with lists, even if no asymptotically worse operations on the lists are used. However, I don't have any specific examples (I have heard reports that implementing State with continuation passing generates faster code than using tuples (even unboxed tuples) like is currently done).
With regards to your last paragraph, yes, that's been my experience too. GHC does a wonderful job of optimizing CPS. Another example where DLists break down is if you want to take the tail of a DList: not a problem if you convert it to a list only once, but then if you want to append more things to the end of the list... Anytime you have to convert back and forth between DLists and lists, you are in for a world of hurt.
(Feel free to leave feedback on the talk page of the wikibook. :-))
I quickly searched via Google and found that Wikipedia mentions the term "difference list" in the context of functional programming and the Haskell Wiki also has an article on "difference lists". Neither mentions functional lists (at least I did not find such mentioning).
While I normally love Haskell's laziness, I lost a couple of hours yesterday because I did not fully understand it yet. I typed this up in the hopes of preventing others from making the same mistake.
I think that's required for extensible exceptions in general, and this framework doesn't make any extra use of it.
Couldn't you also use a structure like: data Image = Image {... foo :: ![[Pixel]]} Doesn't the `![[Pixel]]` mean `strict [[Pixel]]`? Or am I misunderstanding this?
Let's test, shall we? data Image = Image { width :: !Int, height :: !Int, pixels :: ![[Pixel]] } data Pixel = Pixel { red :: !Int, green :: !Int, blue :: !Int, alpha :: !Int } deriving Show makeImage :: Int -&gt; Int -&gt; Image makeImage w h = Image w h . replicate h . replicate w $ Pixel 255 0 0 255 Open ghci: *Main&gt; :set +s *Main&gt; last . last . pixels $ makeImage 800 600 Pixel {red = 255, green = 0, blue = 0, alpha = 255} (0.00 secs, 1092876 bytes) Nope, doesn't do the trick.
how about polymorphic variants?
What do they have to do with exceptions?
As FalconNL points out, this doesn't work, but he doesn't say why. *You* on the other hand, did say why: &gt; Doesn't the `![[Pixel]]` mean strict `[[Pixel]]`? Yes, exactly. It means strict list of list of Pixel (in fact ![a] is not even a strict list, but a list strict in its *outermost* constructor - i.e., the first cons cell is always evaluated), whereas what's needed is strict list of strict list of strict Pixel.
Loading raster data into a linked list of linked lists seems kinda strange to me. I would think you could load it into an unboxed array and avoid both strictness problems and a crap-ton of cons cells.
Shh, don't tell anyone.
This is the example from within the tarball: -- | An example atom design. module Language.Atom.Example ( compileExample , example ) where import Language.Atom -- | Invoke the atom compiler. compileExample :: IO () compileExample = compile "example" example -- | Example design introduces a unsigned 16-bit variable, -- and declares two rules: one to increment the variable, -- one to reset the variable back to zero when it hits 100. example :: Atom () example = period 2 $ do -- Set execution period as a factor of 2 of the base rate. -- A local state variable. count &lt;- word64 "count" 0 -- An external variable. reset &lt;- bool' "reset" -- A rule to increment the count. atom "increment" $ do cond $ value count &lt;. 100 count &lt;== value count + 1 -- A rule to reset the count. atom "reset" $ do cond $ value count ==. 100 cond $ value reset count &lt;== 0 
http://dutherenverseauborddelatable.wordpress.com/downloads/exception-monads-for-ocaml/ porting it to haskell, with this clever typelevel trick (I've yet to wrap my head around how things disappear from contexts in that control-monad-exception) and it should work without typeable
But Haskell doesn't have polymorphic variants, does it?
well, you have to cast a spell or two from the spellbook of Oleg the Great http://okmij.org/ftp/Haskell/VariantP.hs
More like -2 glasses of confusion ;-)
Oh, it's an old trick. I think I saw it first in Stefan O'rear [RIO](http://article.gmane.org/gmane.comp.lang.haskell.general/14526) library. 
Linked list of ByteStrings. Best of both worlds.
My friend is bringing me his [Arduino](http://www.arduino.cc/) board tonight. I shall share my adventures and hopefully provide a full example to go along with what Tom Hawkins provided.
thanks for the link, haven't seen it before. I've read that README.LONG and I think it is a bit different (simpler) from your library. in that RIO, everything only adds more constraints to a context (which is easy), but there is no removing from the context (catching needs it), or checking if context is empty (pure run function requires it), although maybe that explicit forall works as checking for empty context, I'm not sure. I'll have to think about it some more. anyway, thanks for the library, I love checked exceptions and I tried many times to write it myself (though I wanted pure version with polymorphic variants, and I wanted it to form parametrized monad/monadish with magic bind) and I had no idea how to get things out of the context without using explicit type signatures.
Any advice for how to find a job with a company like this for somebody soon to graduate with an M.Math degree and a combination of applied math and comp. sci courses?
Interesting stuff. Is there a video recording of this talk?
It's so complex, it has to be _i_ glasses.
lol
I can't think of a situation in which I'd prefer my raster data to be in a list of ByteStrings (presumably one per scanline) rather than an unboxed array. Do you have an example to help my feeble imagination?
/me gives the official optimistic thumb up of awesomeness!
&gt; Improving hsc2hs/c2hs + Cabal to make it easier to write C wrappers to C functions Presumably they mean Haskell wrappers to C functions here. Would be awesome if they could somehow do something similar for C++ too, even if it could only handle simple cases (e.g. nothing involving templates or preprocessor-magic).
No, we mean C wrappers. The point is that some C functions cannot be bound because they pass structs by value, or take a variable number of parameters, or perhaps they're not actually functions at all but are CPP macros. In all these cases you cannot use the FFI to import them. The solution is to write a small wrapper in C and to use the FFI to import the wrapper. Having to put that C wrapper in a separate .c file with it's own .h file is a pain. It'd be nice to be able to put the C wrapper right next to the FFI import in the .hsc/.chs file. The point is to lower the overhead of using such C wrappers and make them easier to inspect and maintain.
Ah, okay, I see what you mean now. My original point still stands though. A lot of the kinds of libraries that take years to write (GUI, 3D engines,...) are only available in C++ so anything that makes wrapping C++ easier would be useful, anything helping C helps C++ too so that is of course more important.
No OS X love? It would be nice to support dynamic linking for OS X as well.
Has anyone sent out a press release about the IHG yet? Or tried to get the media interested? If it's covered by the media we can say a bit more about it on Wikipedia.
I don't know. I guess we prefer coding to writing wikipedia entries about each other? Oh and don't forget. Avoid Success At All Costs.
And if you're a commercial user interested in having some things done for GHC et al, please consider joining the IHG!
New xmonad user, 3 years from now: "Ohh, it's a Haskell program! I wonder if it-" xmonad: "*** Hello World! ***" user: "Welllll, I see that it can. I wonder how it knew?!?" 
Wish I could go. :(
**Utrecht is beautiful**
One happy Epic user here. I would recommend it to haskellers looking for a compiler backend.
Don't worry about the glasses, they are imaginary anyways.
Ah, glad to see that you got around to packaging it up. Did you ever get a chance to do the same thing with a piecemeal effect monad?
Interesting...
Apologies for the noobish question, but I'm interested in attending some of the CUFP events, just as an interested Haskell hobbyist. I guess I would have to register somehow but haven't seen any details how a person could do this --- just advertisements (like this) and calls for papers. Any thoughts from the redditors?
Oh, it is so disappointing that I'm just a poor student from Russia and I don't have anything like £400
Registration for ICFP, CUFP etc typically opens much closer to the event, maybe a couple of months in advance. This summer school isn't directly associated with those events, just timed and located to fit in well, so will presumably have its own independent registration arrangements.
Apply?
Nope, sorry.
"full-text electronic access to all papers is freely available, without any need for registration or subscription"
You don't have to use seq to force evaluation, however. I find this function quite helpful: demandList [] = () demandList (x:xs) = demandList xs This doesn't force the evaluation of the elements of a list, but it does force the evaluation of all the cons cells. More to the point, however, is that [[Pixel]] is a terrible representation for this kind of computation. Look at unboxed arrays instead.
Close. But you still succumb to part of the same fallacy in the end. What you both are trying to do is express this definition: data StrictList a = Cons a !(StrictList a) | Nil Now, you could optionally decorate the elements with their own strictness annotation, but this is only of marginal utility if the elements themselves aren't a "flat" type in the sense that they don't have meaningful partial values, i.e. all values are either fully formed or ⊥, and no in-between such as (3:⊥) or (⊥:⊥). 
This strikes me as interesting, as a Scheme lover and Haskell newbie. Can anyone more experienced offer some commentary on its possible value?
Maybe that's what I said. If so, I didn't express myself well, because what I meant was: data Pixel = Pixel { red, green, blue, alpha :: !Int } data StrictList a = Cons !a !(StrictList a) | Nil or is that still wrong?
A pretty nifty-looking library, I must confess. I've gotten long since tired of filtering `.` and `..` out of directory listings by hand.
Might bring some Schemers in to Haskell, but as for Liskell, we're unlikedly (?) to start seeing Hackage libraries written with this system...
Ok, I reread your comment, and I think you are right. What threw me is that you agreed with the statement; and you didn't clearly delineate what a "strict list" really was. You correctly suggested that ![a] is not a strict list, but probably should have made that point a bit more clearly. :-) I originally modded you up, BTW.
&gt; I originally modded you up, BTW. Far more important is that we had a conversation that clarified things for each other and for the reddit public. Thank you.
Yes, I was wondering about the connection to Liskell. It seems like an awful lot of duplicated effort here.
Where is the code for this GPU monad?
i guess haskell is too main stream for cool people now :&lt;
Oh, damnit. I _never_ get to be cool. :(
Psst. If you want to be really edgy, try [Coq](http://coq.inria.fr/) ([Coq subreddit](http://reddit.com/r/coq)). Ian Lynagh is using it to do theorem proving for camp, which may become the next version of darcs. OK, he's not really programming in Coq AFAIK, but you can program in Coq as well.
There's a really good buzz about Agda at the moment. I switched from using Haskell to Agda for part of my PhD even though it's not known at my uni. I only chose it over Coq because of the syntax but since then it seems to be everywhere I look -- everyone I meet seems to be using it, and I've seen a few talks on type theory or NBE that turn out to have practical demos using it. 
You can program in Coq but it doesn't really *feel* like programming in an elegant foundational FP language, to me at least. A nice thing about Agda is the "pay as you go" formal methods -- you can just use it like a total version of haskell then gradually add more expressive types as needed. 
I like the 'Program' extension in Coq, which has at least made it at least tolerable to program in Coq (thank you Matthieu Sozeau!) but I'll agree, Agda is a lot more natural to program in.
We are still working at getting it in shape for a first release.
Great presentations, and it was wonderful to get to meet people in real life. Thanks for the heads up on this!
So what's different?
liskell uses the ghc api to process lisp syntax. hasp transforms source code using scheme.
Do they have data structures that are sharded or replicated? For example, distributed hash tables or distributed timers? It seems that these are basically utilities to share channels/semaphores -- so they've gotten as far as Erlang, at least.
Oh, aha: http://holumbus.fh-wedel.de/trac/wiki/Storage
glad you like it. any other functionality you would be interested in?
Wow, that's an impressive editorial board, and considering the current state of many journals today, I can't vote this one up enough. I hope to see more efforts in this direction; unfortunately I myself am not so terribly interested in pure type theory, so this effort isn't directly applicable to my own interests.
Needs more video, and I heard it was recorded. Looking forward to seeing the presentation.
What was the feedback of the audience?
Twitter knows all: http://search.twitter.com/search?q=erlangfactory+haskell
No, I like it quite a lot.
After a couple of weeks, the new logo already seems a little dull. Take a look at some other language logos that have held up much better: * [Ruby](http://www.ruby-lang.org/images/logo.gif) * [Python](http://python.org/images/python-logo.gif) * [ML](http://www.smlnj.org/Lindig2.jpeg) * [CaML](http://upload.wikimedia.org/wikipedia/en/b/b1/Caml.128x58.gif) * [Java](http://blogs.sun.com/theplanetarium/resource/t_java_logo.jpg) * [OZ](http://www.mozart-oz.org/logos/mozart-259x112.gif) * [Cat](http://www.cat-language.com/cat-logo-160-b.jpg) * [Erlang](http://erlang.org/images/erlang.gif) * [Visual Basic](http://upload.wikimedia.org/wikipedia/en/9/92/VB_cover.png) **Edit:** I don't mean the design so much as the colour scheme. Its like something you'd expect a group of IBM sock-suspender wearing managers to come up with. 
I think it would be much better with a different colour scheme. * [for example](http://imgur.com/Gr5F.png) 
it's actually growing on me and i like it. welp.
It's just like "the worlds funniest joke". It wasn't actually funny, but a joke that everyone could understand. The logo isn't brilliant, but it's one that the people involved in Haskell could vote for.
I think there's scope to take the shape and put it into a banner like this. Get to work! Currently all we have is an icon, you want a logo and banner.
i hope you like it, if you have any comments or corrections plz post them here or email me! enjoy!
It looks like it has bit-rot to me. Hasn't been updated since 2002.
I recently started learning haskell and I find most of the concepts to be nothing short of amazing. My only concern is that a lot of example code (including that in RWH) is sometimes very hard to read. Is this a function of the fact that I'm new to the language, the example code is too long/complicated and needs to be re-factored, or I'm just not smart enough and need to move on? Note: By hard to read I mean it's difficult to know what a function call with a given set of parameters will mean at runtime.
Where's that damn infinite upvote button I built for reddit...
Probably your lack of experience.
&gt; By hard to read I mean it's difficult to know what a function call with a given set of parameters will mean at runtime. Could you elaborate?
It gets a little easier with experience, but Haskell has some very annoying syntactic decisions that can make it quite hard to read: 1. Having (&gt;&gt;=) associate left-to-right, but (.) and ($) associate right-to-left. This means that when you mix monadic actions and function composition, your eyes have to jump all over the line. 2. An overuse of punctuation in general. Haskell is like Perl; a lot of the common operations are operators. It has the same readability problems as Perl (and the same conciseness benefits). It doesn't help that it's super-easy to define new operators, and Haskell culture often encourages this. 3. Partial application. This is one of those mind-bending features that everyone should learn, but when used frequently, it makes you keep much of the type information of the program in your head. There's really no distinction between functions and values, which is good for flexibility, but means that any token might potentially be a function call. Having to spell out the arguments provides some nice self-documentation that at least gives you a reference point while trying to figure out an API.
It should be a lot *easier* to know what a function call will mean at runtime since there's no state. I'm guessing experience is the issue here. Imperative programmers are used to picking up new languages in a few days, but Haskell is totally different and will take much longer to get used to (but then you'll be able to pick up other FP languages in a few days). Stick with it.
it's because you were exposed to C-based syntax for your whole life. anyway, haskell's syntax is pretty powerful (only lisp and prolog have something better), so you can write in C-style: swap(a :: ArrayInt32, i :: Int32, j :: Int32) = do { tmp &lt;- auto (a[i]); a[i] =: a[j]; a[j] =: tmp; } quicksort :: (ArrayInt32, Int32, Int32) -&gt; Void quicksort(a, left, right) = do { i &lt;- auto 0; last &lt;- auto left; if1 (left &lt; right) $ do { for( i =: left + 1, i &lt;= right, i += 1) $ if1 (a[i] &lt; a[left]) $ do { last += 1; swap(a, last, i); }; swap(a, left, last); quicksort(a, left, last-1); quicksort(a, last+1, right); }; } 
Same here, some wish : * Explicit notation of partial application and call to function returning a function. * High-level data structures with shorthand notation. * Simple and clean associativity rules. Breaking source compatibility would be necessary : * Find a new name (Liskell ;) ) Remarque, Clojure made such change to lisp syntax. But as grahagre said : with more experience ...
&gt; By hard to read I mean it's difficult to know what a function call with a given set of parameters will mean at runtime. Sounds like you just need more experience with currying, referential transparency, and the idea that a function can (and very often does) return another function. I'm a pathetic failure at learning Haskell after several attempts, but I can't complain that the syntax is hard to read or learn. It was a little weird at first, but when you get used to it the syntax is very nice and clear. 
Any context? Why it should be faster?
For one, continuation passing just seems to optimize better than building and taking apart tuples, like the usual State implementation does. But I suppose that doesn't figure into the headline, since it's comparing to other CPS state monads. For two, a default continuation passing State with an Int state looks like: State Int a ~ forall r. (a -&gt; Int -&gt; r) -&gt; Int -&gt; r The adaptive state uses some fancy new type stuff to turn this into: State Int a ~ forall r. (a -&gt; Int# -&gt; r) -&gt; Int# -&gt; r where `Int#` is an unboxed integer. A normal `Int` is implemented like a pointer to some code that calculates an `Int#`, which is necessary for it to be able to be undefined. If that doesn't make sense, don't worry about it. Suffice it to say that this removes some indirection, and gets things optimized about as much as is possible (it's unlikely that GHC's optimizer could do this manually, because in order for unboxing to be semantics preserving, it has to be sure that the `Int` you put in the state will eventually be evaluated; it's unlikely to be able to be sure of that in general).
The best applicative functors guide I've read for haskell. Why couldn't you have written it 3 weeks ago, where I was trying to figure them out based on those dense academic papers linked from the Control.Applicative doc page??? :P
Yes, it was not possible to write this before.
Could you upload the benchmark program as well?
&gt;I'm a pathetic failure at learning Haskell after several attempts, but I can't complain that the syntax is hard Then why the failure ? What stopped you ? 
I find Erlang pretty easy to read, but Haskell is still tough for me. I guess as mentioned a few comments down the associativity and precedence just needs to be second nature and then it gets easier. 
#3 this sums up my issues. Without having memorized the type signature you are unable to reason about the results of a function. 
I made a lot of progress on my last attempt but ended up getting my ass kicked somewhere near state monads and existential types. The syntax is easy, that's not the problem at all. I think I had it mastered in two weeks. The problem is that I've been studying Haskell off and on for at least two years and I still really have no idea how to write a useful program. I've never failed so hard at something I put so much effort into learning before, but for me at least, that's half the appeal of Haskell. 
Thank you for explanation.
Same here. I have no problem with haskell syntax or even monads and IO and all those fancy operators, and laziness and purity and partial application and functional composition. All this is great stuff everyone raves about and what's interesting, everyone quickly gets, in a matter of days. But programming in haskell is really a programming with types. So to master haskell one has to master the family of type classes from category theory: monoids, functors, applicative, arrows, monads, monad transformers etc. That's where it is very different than any other programming language. That's why simply picking "Practical programming" book on haskell will not do. 
All of those can be dealt with by a sufficiently smart editor, and they should, too.
Most of the issues with Java can be dealt with by a sufficiently smart editor too, and have been. Heck, for that matter, a sufficiently smart editor could take your Haskell program and display it to you as Java, then compile your Java edits back to Haskell to be written into the source file. "Sufficiently smart" arguments don't usually work unless you can point to a sufficiently smart editor that already exists, point out step-by-step how it would solve the problem, and have the resulting instructions be less hassle than just going with a different language to begin with.
I got it to compile and run on i686 Ubuntu 9.04 fairly easily.
See [Liskell](http://liskell.org/) and [Hasp](http://www-student.cs.york.ac.uk/~anc505/code/hasp/hasp.html) for legible Haskell.
&gt; Explicit notation of partial application and call to function returning a function. Yuck, that'd destroy legibility of so many programs. One of the nicest things about Haskell is the *lack* of needless syntax you find in other languages (which is, itself, something that confuses newcomers admittedly). In SML and Ocaml they don't do partial application by default and so it requires extra syntax. They're different from Haskell on a wide range of other details, but are worth looking into if you're into that sort of thing ;)
Well, the first two points don't address Haskell as a language, but library and naming issues, and you can easily deal with them inside the current Haskell syntax: Redefining (&gt;&gt;=), (.) and ($) is trivial, and an editor with simple refactoring support will be able to re-arrange your code automatically. It's hardly rocket science, but, yes, it hasn't been done, yet. The third point can be addressed by providing type signatures for program fragments... I've never looked into it, but I believe such a thing already exists. And, no, you can't solve Java's problems with an editor, not even with eclipse. Eclipse doesn't get you over "implements SwissArmyKnife", does fix neither collections nor generics, and doesn't automatically abbreviate identifiers. Last, but certainly not least, it doesn't fix the VM's instruction set.
I know about: (--&gt;) = flip (.) infixl 9 --&gt; (==&gt;) = flip ($) infixl 0 ==&gt; That doesn't change the problem of every other Haskell programmer not being able to understand your code if you write it that way. The "simple refactoring support" will change the source file itself, so again, you have problems communicating with other programmers. The Emacs mode for Haskell had some experimental support for type annotations, down on the modeline. I got all excited about it, then tried it and found it wasn't all that useful, because it never showed me the expression I wanted to typecheck (I think you needed to select the full expression or something). If it's not instantaneous, it's not really an improvement, though I would really like to see a type-aware IDE for a type-inferencing language. I switched to vim shortly after anyways. And IntelliJ is pretty fricking good. I've been avoiding Java jobs for the past year and a half, but in every other language I've worked with since (that includes Haskell, C++, JavaScript, ActionScript, Python, and PHP), I've *really* missed IntelliJ's context-aware global refactoring support. For that matter, most of those languages' IDEs struggle just supporting context-aware autocompletion.
&gt; The "simple refactoring support" will change the source file itself, so again, you have problems communicating with other programmers. But the same applies for eclipse/IntelliJ's refactorings, and, frankly, it. just. doesn't. matter. Other Haskell programmers can refactor it to (.)/($), you can refactor it to (--&gt;)/(==&gt;), everyone's happy. Hell, if you want, you can even hack darcs to canonicalise things to a specific style to prevent bogus patches. Last, but not least, Yi and Leksah are both coming along, nicely. I wouldn't even have dreamt of any of them as I started with Haskell. I doubt they would refuse your patches that add refactoring.
You're right. But, if in the context of a definition, a sub-expression is known to return a function. Would it harm to denote it. A prefix operator would work for this.
The problem is with _reading_ Haskell, not writing it. So redefining (&gt;&gt;=), (.) and ($) in _your_ code doesn't help.
The first one is my main gripe. We can have everything right to left ((=&lt;&lt;) , (.), ($) and (&lt;$&gt;)), but there are no standard left to right versions of (.) and ($). I use .%, $% and &lt;$&gt;%, but it isn't ideal since everyone isn't using them. Left to right is very useful for long statements, as something like func = monad1 &gt;&gt;= fMonad &lt;$&gt;% someFunction is much easier to read than func = someFunction &lt;$&gt; fMonad =&lt;&lt; monad1 since in the second case you are reading from bottom to top (very unnatural). The second only concerns me outside the standard libraries. I don't have any problem with Control.* modules (eg Monad, Applicative), and to lesser extent the Data.* modules (eg Data.Set). These are very general operators, like + and -, and learning them is like learning the control structures like loops of other languages. It does annoy me when libraries such as Test.HUnit and Parsec use them, as they make the code harder to read for people not used to the libraries. 3 takes a long time to master, especially when dealing with "multiparameter" functions, such as ones used with foldr functions.
I think the best way is to bite the bullet, and to start a project with what you know of haskell. I've been learning it with a moderate sized personal project that analysis statistics from a file with an emacs org organisation and can add to and remove from it using a command line program. When I started it, I didn't understand any monads except for IO and Maybe. Therefor a lot of the code had a lot of problems in it. For example as I didn't know about Reader. Every function accepted an env argument, which wasn't optimal. However, as I wrote more and more of the program, I got better at using some of the more advanced concepts. Another example, one of my datatypes I wrote a few list like functions like joinOrgs. Now, I would have made it instances of Monoid, Foldable and (possibly) Traversable. So, I think your best bet would be to choose a program you need written, and just write it in haskell, not caring how crap your code will be or if you will replicate code that exists in the common libraries. It will improve in time, trust me!
This is incredibly useful. Thanks a lot.
I giggled a few times and was enlightened, so thanks. Two things: * I don't know how to pronounce &lt;*&gt; or &lt;$&gt; * You say things like "getLine is an I/O action with the type getLine :: IO String" often. This sounds weird when I say it in my head because I pronounce "::" as "has type".
i call &lt;$&gt; fmap and &lt;\*&gt; apply i always wondered why they did not choose to use &lt;$&gt; instead of &lt;*&gt; for apply though.
i dont know how to pronounce them either! haha! thats a good observation though, sometimes i say "with the type", sometimes "is a" and sometimes "has type", i'll probably go over LYAH one more time and look for these terms and unify them into one, good find
How's that? How does refactoring _your_ copy keep you from reading source in _your_ favourite style? Don't get me wrong, I'd agree with you if you'd talk about e.g. applicative vs. monadic usage of parsec, or MonadCont or type wizardry. (&gt;&gt;=)/(.)/($), OTOH, are _purely_ syntactical. Hell, there's even (=&lt;&lt;), just to prove my point.
 instance Ord Isect where i1 &lt; i2 = isect_t i1 &lt; isect_t i2 Can't he derive Ord automatically ? 
No. The derived `(&lt;)` would (potentially) compare all the fields, not just the `isect_t` field, and there isn't an `Ord` instance for `Vec` at all (for obvious reasons).
Thx, duh, i completely missed that only one field was compared. 
Nitpick: Ocaml/SML do partial application the same way as Haskell, if I'm understanding you correctly. # let add x y = x+y;; val add : int -&gt; int -&gt; int = &lt;fun&gt; # let addone = add 1;; val addone : int -&gt; int = &lt;fun&gt; # addone 10;; - : int = 11 
The vector type (non-unpacked Doubles) looks suspect.
Just wanted to say thank you to all the responders, I do _really_ like Haskell and I was feeling concerned that wider acceptance might be mitigated by these issues.
I don't read the second from bottom to top though. Bottom to top is "first do this, then do that". The typical way is "someFunction as applied to fMonad, all applied to the result of monad1." Which feels how declarative should, to me.
It looks like a lot of boilerplate, though. I guess once I have my state type nailed down I can transition from a polymorphic state monad to the faster, fixed version here. Is there a library put together that has the faster CPS state monad?
 v0 `vadd` v1 = Vec (x v0 + x v1) (y v0 + y v1) (z v0 + z v1) v0 `vsub` v1 = Vec (x v0 - x v1) (y v0 - y v1) (z v0 - z v1) v0 `vscale` s = Vec (x v0 * s) (y v0 * s) (z v0 * s) v0 `vdot` v1 = (x v0 * x v1) + (y v0 * y v1) + (z v0 * z v1) The maths hurt my brain...
The "Typeclassopedia" in [Monad Reader 13](http://www.haskell.org/sitewiki/images/8/85/TMR-Issue13.pdf) is a wonderful resource for learning about the core typeclasses in Haskell. I've been using Haskell on and off for several years now and I learned quite a bit from it.
thanks, i found this really useful
The main reason this form of CPS transformed state is fast is that if you don't use the state it isn't looked at during the partial application of the continuation. In essence the state sits 'lower down the stack' unmolested during fmap return and bind. When I unboxed it I noticed I could actually keep the state unboxed in that same position by using the tricks we've been exploring for adaptive-containers. I have a suite of monad-transformers that use this same layout (which happens to be the form of a right kan extension) to effectively replicate the MTL that I've been working on. The step after that would be to provide nice unboxed variants like this. 
http://moonpatio.com/repos/MISC/state-bench/ is a sort of minimalist benchmark, and was the reason why I built the AdaptState (Int,Int) instance.
I'm packaging it up with other 'right kan extension' transformers, but its slow going, there are a lot of newtypes to swim through to get this class of optimizations in general.
This is fun, and I like the feel of the controls, but it's short. After getting it onto hackage, it needs a level editor, and some kind of goal as well.
is Data.Time back ?
Yay! It only took me ~3 years :) What do you think of the result ? Re effect monads, encoding the exceptions as a type level list runs into trouble with typing alternatives (e.g. different branches of a case construction). 
Nice work, BONUS_. You might like to mention the applicative instance for functions, which lets one do things like `tan = (/) &lt;$&gt; sin &lt;*&gt; cos`
I submitted this originally in the main programming section but got downvoted out of sight so this is the comment I left before: Note the name has changed to Super Monao Bros, Monao meaning Monadic Man in japanese :D, the source has also moved to a git repos: http://github.com/mokehehe/monao/tree/master Also note direct3d bindings for haskell :D
So....? No description, no meaningful documentation, no examples, virtually useless "homepage"... someone want to explain this a little better? I'm not smart enough to absorb 30 type signatures and just go _Aha!_
I've been writing a lot of Haskell lately, and agree that it can sometimes look like line noise; especially to beginners. Over time, however, you start to recognize (and use) the common idioms. You have to absorb a lot to get good at Haskell, lazy evaluation, partial application, immutable state.. these represent major changes in thinking for anyone who learned imperative procedural programming first. (I.e. almost everyone.) Once you start to develop some fluency, however, I'm a firm believer that you can get a LOT done using Haskell, very quickly, and (generally) it's much easier to feel confident that your program will have the correct *semantics*. That said, even experienced Haskell users can find it extremely frustrating sometimes, especially when you run into things like concurrency bugs in the runtime (augh!)
I don't follow? How would you annotate this: cata :: (F a -&gt; a) -&gt; Fix F -&gt; a cata f = f . fmap (cata f) . unFix newtype Fix f = Fix { unFix :: f (Fix f) }
I seem to recall that SML/NJ, at least, makes a distinction between these two definitions: add1 x y = x+y add2 x = \y -&gt; x+y Perhaps it's just a performance thing rather than syntactic. I never did much ML before switching to Haskell, so I may be fuzzy on the details.
&gt; MList is parameterized on a monadic type, such that folding the list executes actions of that monad. So... I guess it's a list of IO actions... that... get evaluated? Honestly, how is this different than a regular old (Monad m) =&gt; [m a]? I mean, look at the constructor: data Monad m =&gt; MListItem m a = MNil | MCons a (MList m a) I don't get it. dons, care to explain what's so interesting here? Am I just n00bing out? Edit: found [some examples](http://github.com/Peaker/mlist/blob/c42ac0150238ec00b5616445ec75d30a556ea531/src/Example.hs) on the GitHub page.
The key sentence is &gt; MList is parameterized on a monadic type, such that folding the list executes actions of that monad. That is, it's like an iteratee without continuations, and similar and different enough to utterly confuse me this late at night. Just drop hGetContents from your code and replace it with fromList and a couple of other functions...
It seems obvious to me that both the tail and init of an empty list should be the empty list again. Why did the designers of the Prelude decide to force a null check before using these functions?
That just doesn't make any sense. Are you a Lisp user? Well, anyway, list cells and the empty list partition the list type, and the 'tail' and 'init' functions operate only on list cells, which is the way it should be. If it helps, think of tail as "part after the first element" and init as "part before the last element." Recommendation: use pattern matching instead.
Use `drop 1` instead of tail. I don't have a solution for `init` off the top of my head. (BTW, you can use `listToMaybe` as a replacement for head.)
 data Monad m =&gt; MListItem m a = MNil | MCons a (MList m a) newtype Monad m =&gt; MList m a = MList { unMList :: m (MListItem m a) } The types are mutually recursive, so you to see them both. The key is that the monad is interspersed with the cons constructors. Nesting a monad inside itself is a standard technique to delay the monadic effects.
to make this concrete, let's look at a function we might write to compute the length of a list. first, in scheme: (define (count ls) (if (null-list? ls) 0 (add1 (count (cdr ls))))) here i'm using `null-list?` from [SRFI 1](http://srfi.schemers.org/srfi-1/srfi-1.html) instead of the more traditional `null?`, because i want to make sure `ls` is what it is supposed to be: either `null` or a pair (cons-cell). a direct translation of the above to haskell would look like this: count ls = if null ls then 0 else 1 + (count $ tail ls) note that if i were high and forgot to check for the terminal case ... count' ls = 1 + (count' $ tail ls) ... then i should get either a runtime error (because `tail` is not defined for the empty list) or a computation that goes nowhere fast. in fact, i'm pretty sure haskell's lazy semantics require the latter behavior; in any case, when i run it in ghc it doesn't do anything apart from getting the fan going on my laptop. but consider this more idiomatic way of writing `count` (as suggested by klodolph): count'' [] = 0 count'' (x:rest) = 1 + count'' rest here, if i leave out the first clause, i can get a compile-time warning because it is clear i have not covered my bases with respect to the input type of `count''` (i.e., [α]). (this requires compiling with `ghc -W`.) and even if it is compiled and run, i will immediately get an error from the "non-exhaustive" pattern-match. i vaguely understand that this comes from the strict-evaluation semantics of haskell's pattern-matching. i guess i'm not really answering the question here ... just thought this example might make the choice a little clearer. this is a very common pattern, and suggests to me that you don't really *want* to be asking for the 'rest' of the empty list; it is a very different thing from a full list and is a case you'll want to check for anyway. requiring this (as `tail` does) helps prevent programming errors from propagating. 
You can also use the [safe package](http://hackage.haskell.org/cgi-bin/hackage-scripts/package/safe) from hackage, which provides safe (total) versions of functions like init and tail.
not haskell, but very cool.
Hmm, how is this different for any other language?
I am the author of MList. Its a very initial release. I apologize I hadn't had the time to document it properly. I just barely got it to minimally work, the last time I worked on it. I hope to create some documentation soon.
To replace hGetContents, you'd have to use Data.MList.IO.hGetContents (which doesn't exist yet :-) which would be very similar to hGetLines, except it'd use hGetChar in each list item. Then hGetLines could be implemented in terms of hGetContents, but I probably need some more mlist combinators to do this elegantly.
It would be pretty confusing if these functions returned [], since that's also the return value of both functions for a one element list. Presumably it would also mean that tails and inits would each return an extra [] as well, which would be annoying. I'm not positive that this is the case here, but I think some of the awkwardly designed functions in the Prelude, Data.List, etc. were designed before the language was as rich as it is today. For instance, I'd imagine that head and tail existed in the first version of the prelude, and perhaps Maybe wasn't a standard data type back then. Of course it could also just be because there's extra complexity dealing with things wrapped by Maybe.
To clarify: I don't blame you. I can see the small version number. My question is "What is reddit-worthy about this post?", not "Why is that dev such a jerk?" :) And note I'm willing to assume it is worthy in advance. I know enough to know why this is at least potentially interesting, just not how the potential is actualized.
A lot of this mirrors folklore: hdbc is the tool to use, fastcgi is a good idea, et al. Where is the "Haskell for the web" wikibook? Is the Haskell web community big enough to sustain an organized effort to document and improve things?
Basically, the idea is to replace: List a = Nil | Cons a (List a) with something like: -- Monad m =&gt; MList m a = m (Nil | Cons a (MList m a)) Note that it's pretty similar, except the continuation of the list is wrapped in a monad. Then, you have: fromList :: Monad m =&gt; [a] -&gt; MList m a Maybe a better name for fromList is "pure", as the resulting MList will not have any effects. You can extract the elements: toList :: Monad m =&gt; MList m a -&gt; m [a] execute :: Monad m =&gt; MList m a -&gt; m () -- Maybe a better name for execute is toList_ And of course, you can do various things on the MList like normal lists. It has list-like instances for Monoid, Functor, Applicative, Monad. Similar functions to lists: zipWith, take, repeat, replicate, cycle, ... You would use an MList to do something like read all the lines of a file: import Data.MList.IO(hGetLines) h &lt;- openFile ... let lns = hGetLines h -- lns :: MList IO String Lets say you want to print each line. Instead of the usual mapM print lns, you use: -- mmap :: Monad m =&gt; (a -&gt; m b) -&gt; MList m a -&gt; MList m b mmap print lns The idea is that as you iterate to read the MList it actually reads the lines from the file. The actions you specify in mmap are interlaced such that the resulting action is: readLine &gt;&gt; print &gt;&gt; readLine &gt;&gt; print &gt;&gt; ... Important note, though, is that the MList does not memoize its results. Every time you "iterate" the mlist it will re-execute the actions. If you do want it to memoize, like the lazy I/O list that results from hGetContents, you can use: memo :: MList IO a -&gt; IO (MList IO a) which uses MVars to memoize the MList items. It could be nice to generalize this to other monads too. mlns &lt;- memo lines mlns will now be memoized, and will lazily read lines from the file, and not re-read them when the same item in the mlist is reiterated. MList is very initial work, so I'm not sure if the exposed combinators are ideal or complete. There are some obvious missing combinators (e.g drop, splitAt, splitBy, takeWhile, and various other Data.List functions). MList started out as I felt unsafeInterleaveIO is the wrong thing to do, and didn't like Iteratee's code (though after this mlist experience, I do intend to re-look at it :-)
Many web hosts seem to only support PHP+MySQL. If Haskell can spit out CSS + HTML + PHP+MySQL, handle WYSIWYG design somehow and make sure the databases work great if the website is to scale in the future, I think Haskell would be a winner.
Hm. Okay. That's something that surely slipped by on first read... I read MList and inserted MListItem. I'll have to think about this some more. I'm still not sure exactly how it works.
so cool
i tried reading the docs for happs once... i had to stop because it just wasn't clear what was going on
i just did my first prolog assignment last week, pretty kewl langauge
Let's get web hosts to spit out Haskell support! I think that would be much easier and much more fun for everybody.
see also: [Pausable IO actions for better GUI responsiveness](http://www.reddit.com/r/haskell/comments/7uv8a/pausable_io_actions_for_better_gui_responsiveness/) for something similar.
I misread this as "Futurama" at least the first 20 times my eyes passed over the string "Futamura".
Excellent, thanks. I'm at this weird point with my Haskell where I know almost all of the syntax, but I'm basically a theory and idioms n00b. Stuff like this is exactly what I feel like I need to be reading.
Why do we care so much about fastcgi? The FastCGI stream is so similar to HTTP that you may as well just implement the latter. You can then bypass the webserver entirely, or put it behind an HTTP proxy or nginx for static content/load balancing.
A lot of hosting is done through virtual hosting also. Basically, you have a 5-10+ gig image that runs on its own, preconfigured OS instance.
For a dedicated app there aren't any notable benefits. For low-traffic or shared environments FastCGI is desirable. If you're after neophytes, you definitely want it. They can get reasonable performance out of a shared host with little effort.
somewhat related: [http://code.haskell.org/~bkomuves/projects/DirectSound/](http://code.haskell.org/~bkomuves/projects/DirectSound/)
Was this before or after the rebranding as happstack? By my lights, things improved a lot then.
I say "lang ast rang" and "lang doll rang". (short for left angle, right angle) My favorite operators are "rang rang eek" and "eek lang lang" :)
I have no idea why the monad stack seems to have gotten even more complicated in happstack -- what's wrong with a simple error over state over IO?
i'm not sure, but i didn't come away convinced that haskell would be good at web stuff
This is really cool. A few comments: (1) I guess edwardkmett attempted to explain this already, but it's not immediately obvious to me why CPS style should be better than non-CPS. (2) I notice a lot of similar work happening between this, DPH, generalized memo-tries, uvector, etc. I wonder if there is a way to unify some of this work? (3) Do you need IntIntState? Is there a way to write an instance UState (a,b) with the appropriate constraints on "a" and "b"?
It's worth noting that there is a caveat here: the Haskell definitions are being translated into HOL, which has only total functions, and no bottoms. The theorem that is proven for the HOL function is not true in Haskell, because 'mirror' is strict, and so there are counter-examples such as: (mirror (mirror (Node bot 1 bot))) = bot =/= (Node bot 1 bot).
I'm looking to write some audio software soon and I'd love to use Haskell to do it. The problem is that GC pause times of longer than 3-5ms will be unacceptable. Is there currently any Haskell implementation that is working towards (or has already met) this goal? Are there any other functional languages that might meet this requirement?
I can understand your confusion. After reading the Happstack tutorial I felt it did a decent job of explaining *how* to do a, b and c - but it failed to explain exactly *what* was happening under the hood so I couldn't easily take the tutorial and perform x, y, or z.
That's interesting: where's Takusen? :)
Because error over state is not enough to get everything Happs/Happstack provides. You need MaybeT for noHandle, ErrorT for escape (and finishWith), WriterT for setResponseFilter and ReaderT for retrieving the request. Granted ReaderT and WriterT could have been replaced with StateT, but then you couldn't separate the functionality of WebT and ServerPartT. Happstack just reused existing library code to make the monad easier to implement and verify as correct (not to mention add numerous features and fix a few bugs). 
Tell me about it. Just look at these gems in tutorial: &gt; You might be saying "Hold on, there, what's all that about?". &gt; I'm going to say "Oh look, a Unicorn!" and hope you remain distracted until the chapter on versions &amp; migrations. &gt; This is a bit of lovely Template Haskell hackery that you really shouldn't think too hard about. &gt;Suffice to say, you need to call this. 
I think "Writing a program to blink an LED" is a better title :)
Ah, my bad. In fact, it does blink an LED. I also have one that does Pulse Width Modulation in software! That one is a few posts out yet...
If you didn't use writer, but state for filters, then you wouldn't need escape I think (or you at least could have more control over ignoring filters)? finishWith seems to be a sorta funky mechanism to bake in as well, since there's no *need* for it to be part of a core web monad, and users might well prefer a uniform model with exceptions. Meanwhile, usable exceptions are not provided so easily, and need to be put in a custom layer, but there's all this weird mapServerPart stuff floating around to do it? And yes you need MaybeT for monadplus. In fact, that was the Error I mentioned above, but depending on how you do it you only need the Maybe bit. The thing about making it Error instead is that you can then have some sort of union type adt for your errors that handles both failures of the dispatcher to match and other forms of exceptions with some sort of uniform model. Finally, I should note that passing around Request in a Reader bugs me anyway, since it makes the dispatch functions nonuniform -- 90% of them can be written as type m (), but the path ones have to be m a -&gt; m a because they run the modified request in a local environment. Much better to use state with backtracking and actually consume the path you match on -- that way everything is uniform, and the dispatching mechanism more closely matches a parser on the request, which is what it really is doing, after all.
Can anyone explain how he can match t to a type constructor in the first Haskell listing?
`t` is just an enum. Those type data constructors take no args. edit: Here's the [definition](http://hackage.haskell.org/packages/archive/atom/0.0.2/doc/html/Language-Atom-Expressions.html#t%3AType). And I guess they're technically *data* constructors rather than type constructors.
Very good questions. 1.) The short answer is that in this form a lot less code motion occurs on the stack and more can be done with partial application. 2.) dons and I and some others have been coming together to build a common adaptive-containers library. This seems to fall under that framework in terms of the unboxing. I've also been working on a 'right kan extension transformer' library (See monad-ran in hackage for a VERY early preview), which doesn't really fit under the concept of the 'adaptive-containers' moniker'. This covers the CPS tranformation used here. This code falls somewhere in between and I'm as of yet unsure where it will reside. 3.) Unfortunately a 'direct' implementation of the idea for UState (a,b) fails because the unpacker can't unpack polymorphic values. That said, I've been working on a much more complicated Packable class that deals with automatically packing into a small bounded number of slots of type Int, Double, Box and does some type level arithmetic to keep it all straight and to let the container store its slots in a canonical ordering, with the packer swizzling things into the right order. The net result is you'd be able to pack anything you can represent in up to say 5 slots using a small number of instances (and potentially anything larger can box up the remainder). Unfortunately, I've yet to get that to benchmark well, so its still pie-in-the-sky. The Packable version should it pan out will you the nice property that you can define an instance for (Packable a, Packable b) =&gt; Packable (a,b).
Oh, so he's got data constructors that are named like the type constructors. That makes more sense then. Thanks!
This is ListTDoneRight. Yes, this has always been a good approach to lazy IO. To make it nice, you need to re-implement a lot of Data.List so that you can use them without first manually forcing some of the IO before you know how much you want (e.g., using toList . take). John Goerzen's ListLike class could be helpful, with some minor modifications. Unfortunately, there are a few essential features of the IO system which only work for IO itself and not for MonadIO instances (which this obviously is). The main showstopper is that the type of block is IO a -&gt; IO a, and this is a GHC primitive. That makes the whole exception system unusable, because much of it uses block internally. I discussed this once with Simon M.; it could be fixed.
(`urlEncode' can be replaced with escaping functions from [Network.URI](http://hackage.haskell.org/packages/archive/network/2.2.1.1/doc/html/Network-URI.html).) * If one needs statically typed HTTP requests, why not importing [Network.HTTP](http://hackage.haskell.org/packages/archive/HTTP/4000.0.6/doc/html/Network-HTTP.html)? * If one wants to wrap `wget', a simple shell script would suffice. I don't see the point of mixing these two approaches. Well, there is one: someone's learning purposes... Still there is no reason, IMO, to upload wow_it_compiles-0.0.0 to hackage. github is the place for such kind of personal stuff. I apologize for being grumpy, Don, but I just dislike messy-cpan-alike characteristic of hackageDB. Best of luck to Haskell Platform project!
The text that's there is very enlightening and clear. I think the author has done a wonderful job of giving intuition about Applicative. But I feel there's quite a lot missing. All the examples are already monads so why do we need an extra typeclass for Applicative? We can define pure and &lt;*&gt; for all monads, so why is Applicative an interesting generalization? There is unfortunately nothing in the text that help us answer this question. With monads we can let future computations depend on the result of a previous computation, whereas this is not possible with applicative functors. With applicative functors all the computations happen in a fixed order. A discussion about this would be nice. A consequence of the fact that the order of computations is fixed is that we can do things like statically analyzing the computations, like the self optimizing parser combinators by Swierstra et al. I realize that these kind of parser combinators might be a bit overkill for this tutorial but it would be nice with an example of what one can do with applicative functors that cannot be done with monads. Also, the examples are not quite real world code. Of course it doesn't have to be that. For pedagogical reasons it's nice to talk about small snippets of code but it would also be nice with some hints about when applicative functors are used in the wild, and when they are appropriate. I hope you don't read this as a lot of complaints. I mean for this to be constructive criticism to help make a good text become even better.
Absurdly ugly but slightly faster: http://hpaste.org/fastcgi/hpaste.fcgi/view?id=4660#a4660 I deny any role in the creation of that code.
I happen to be the author of the library in question. (I'm a little surprised to see it on reddit...) As far as your first point: urlEncode from Network.URI is probably a good idea, I hadn't realized some of the standard libraries provide the functionality. With regard to the second: Network.HTTP does not support HTTPS. With regard to the third: what if you have a Haskell program that needs to download something via HTTPS in the middle? I don't see how a shell script will solve this problem any more than wget itself will. I'm not claiming that this library is brilliant, but it simplifies a task that I'm sure other people will need to accomplish. PS: Network.HTTP is very difficult to use. This library (if you can even call it that) exports a single function.
Will there be a "haskell-platform" package on Hackage so that "cabal install haskell-platform" will pull all the packages into an existing Haskell install?
Yes, http://trac.haskell.org/haskell-platform/ticket/15
I poked around the site a bit and couldn't find an answer. The current version of The Haskell Platform only targets the GHC 6.10.2 compiler. Are there near-future plans to target other compilers (e.g., Hugs)? Are there near-future plans to target past versions of GHC (e.g., 6.8.3)?
See also the great "embedding prolog in haskell" : http://lambda-the-ultimate.org/node/112
One thing you need to be careful with with this kind of thing is that examining the lists involves side effects, so you need to use them linearly. For instance, if you write: do ... let lines = hGetLines h someConsumer lines anotherConsumer lines Then `someConsumer` and `anotherConsumer` will not see the same list. `someConsumer` will read in however many lines it needs, and then `anotherConsumer` will read in new lines, even though you're passing it the same 'list'. To get them to see the same thing, you either need to make the list memoize itself somehow, or have the computations pass back a modified list that has the stuff that's been read pushed back on to the front. This sort of thing comes up in, say, parsers. Lookahead will potentially eat characters if you're not taking the above into consideration. Not that this makes it unusable, but it's a trade-off to consider.
HUGS isn't a compiler, but more to the point I'd argue there aren't any other production worthy compilers for Haskell (not a good thing, but a fact from my point of view). I'm pretty sure much of HP can't be used by hugs - such as STM, hpc, perhaps GLUT. If other compilers become stable, compile "fast enough", generate "fast enough" code, and support a sufficient set of extentions then I would think the best way forward would be many flavors: HP-{GHC,JHC,*HC} Or to just use cabal --install --with-hc=X to install the platform with/for your preferred compiler (requiring you to already have the compiler, of course).
Why MD5 over SHA1? I'm not saying `ZOMG IT ARE INSECURE'! I'm just curious why MD5 given a choice between the two hashes ([Crypto](http://hackage.haskell.org/cgi-bin/hackage-scripts/package/Crypto-4.2.0) supports both). Also, instead of packaging the hash inside the encrypted blob, why not HMAC the plaintext and append that the the ciphertext. IMHO that's a little more standard.
Any example how to use it on the web server ? 
Not only that - "anotherConsumer" will be run multiple times, depending on how many elements are returned by "someConsumer". Well, the whole idea is that ListT is a kind of list monad. So you would use list-monad-like techniques: do ... line &lt;- lines $ hGetContents h processOneLine line For your case, where you have one consumer for some lines and then another consumer for the rest, you would use functional techniques, just like for regular lists. For example, you might arrange for "someConsumer" to return a ListT of the remaining lines, and then just write: anotherConsumer . someConsumer . lines $ hGetContents h Or, if you have a pure predicate that decides which lines need to be processed by the first consumer, you might define a variation on span: spanListT :: Monad m =&gt; (a -&gt; Bool) -&gt; ListT m a -&gt; ListT m [a] In this variation, we return the two pieces in a ListT instead of a tuple, because the order in which the two pieces are subsequently processed is significant. Now we can write: zipWith ($) (fromList [someConsumer, anotherConsumer]) . spanListT pred . lines $ hGetContentsH h Our goal is to be able to use functional style even for lists with side-effects. I think this is a better way to do that than to use unsafeInterleaveIO. 
Cabal and hackage support multiple compilers, so I am optimistic that HP will also.
Well, the simplest behavior when a particular package in HP is not supported would be just not to install it. It is an interesting idea to support variations on HP for different compilers, but it sounds complex. Besides trying to keep track of many different sets of packages that are supposed to provide more or less the same set of services, it also means another layer of dependencies on top of what Cabal already has.
Okay. Sorry, Michael, I didn't want to offend you. Let it live on Hackage, let the version be 0.0.0; I'll shut up. &gt; it simplifies a task that I'm sure other people will need to accomplish. Could you please provide a sample task? (And I will try to solve it with wget from shell.) &gt; Network.HTTP is very difficult to use. What do you think about [Network.Curl](http://hackage.haskell.org/cgi-bin/hackage-scripts/package/curl)? Thank you!
Well, my example was doing an rpxnow login from a web application. I use it for a website I have of my son's photos. I'd have to rewrite the whole site in shell script to accomplish what you're saying. Network.Curl is equally frustrating from an API perspective (trust me, I know, I've used the C API), but the real reason I've shied away from it is the issues I had using Network.Curl on Windows due to some strange DLL issues. Probably was my own fault, and I'm not using Windows on this project, but I decided to go for the simplest approach for this problem.
The web application you are talking about is in Haskell, isn't it? Well, then... Good luck! :)
I have a little website for pictures of my son. I've been taking pieces of the code separately and uploading them to Hackage. Once I finish with that, I'll try to put together a little sample webapp that uses them all.
Hmm... because I know nothing about cryptology? I know what I have works, and I'm fairly confident that you would need to determine the encryption key in order to hack this system, so I'm in no rush to rewrite it just to be more "standard." If you want to fork it on github and make it better, I'll take a look. The repo is at: http://github.com/snoyberg/clientsession/tree/master
Would be interesting to see how far you get with `--compiler=hugs`
Man, the GHC team is on **fire**!
&gt; We also advertised our intent to switch to Git as our version control system (VCS). We always planned to change the build system first, and only then tackle the VCS. Since then, there has been lots of activity on the Darcs front, so it's not clear how high priority making this change is. We'd welcome your opinion (email cvs-ghc@haskell.org). Good news for the Darcs folks.
I always thought of functions providing arrows from types (sets of values) to other types (other sets of values). Things that look [a bit like this](http://upload.wikimedia.org/wikiversity/en/thumb/a/a6/DomainRange.png/400px-DomainRange.png). Programmatically generating such images from ASTs is an interesting idea -- I bet such images would reveal when there wasn't enough type information.
Good lord, put them out! Surely they'll not be able to type in the burn ward!
&gt; Don Stewart | 2009 04 20 | London HUG Oh dons, I see you're actually human. To think I always suspected you were some sort of web spider that went awry and developed a strange fondness for Haskell.
LSD and Haskell, I should try that!
I have to admit I've never thought of functions like this (not counting the "black box" thing they teach you when you're first learning). Perhaps a mild case of synesthesia? ;) It seems like it wouldn't be that hard to generate similar images directly from type signatures via a program. Hoogle Image Search, anyone? :)
Yes, yes it would. What about if you don't know if you're returning a function? You would have to split the kind system just to add an arbitrary distinction that isn't needed by the compiler and potentially force the user to deal with an exponential explosion of such markings in the number of arguments to the function.
I didn't suggest splitting Function from the Value space. I'm suggesting that you can add type annotation to a sub expression. map ( f::(Integer -&gt; Integer) ) [1 .. 5] (But with less notation) By the way, if you move function from the value space and add two special operator for boxing and un-boxing function as value : you can have the same effect. I didn't write some Haskell code for 2 years and a Sudoku solver is my biggest achievement. I was just answering : why some Haskell expressions can be hard to read. Just a question : Do you know a language who split value/function/type and let you define them in the same syntax ?
Data.Accessor needs to become more popular so that it can be included in the Haskell Platform. Data.Accessor is awesome! Use it people.
From Web.Authenticate.OpenId: contains needle haystack = begins needle haystack || (contains needle $ tail haystack) I knew Haskell could do it ;-)
While "I dunno" is not a good answer to the question, MD5 seems to me a very reasonable choice. It's faster than SHA1, and given that the data are encrypted, SHA1's better protection against attacks isn't necessary. As for packaging the hash inside the encrypted blob, that proves that you've decrypted it with the correct key. If the hash were appended to the cyphertext, an attacker could give you random data with a correct hash, you'd decrypt it to different random data, and then you'd have to do some sort of other check to make sure it was actually valid. Perhaps by including a hash with the data. :-)
I made a trivial [patch](http://hpaste.org/fastcgi/hpaste.fcgi/view?id=4747) to improve the output to drop *1's.
This interview seems like a missed opportunity. The interviewer is allowing the interviewee to stumble around by asking vague, open ended questions. Interesting guy, but I don't think this shows it.
If I have to annotate every time I return or use a function, then a function is effectively a different thing than a value. Hence a separate kind. In Haskell the stuff that you box and unbox, i.e. primitive ints and doubles, are values of another kind, #. =) 
As a Mac OS X developer (i.e., I use Haskell to develop), I'd rather not hold up the release because a Mac installer is unavailable. An installer would be nice but the source tarball is so quick to build that it's not an issue.
Add that to the ticket :-) We don't hear -- yet -- from as many end users of the platform as I'd like. (I guess we're only 4 days in though).
Done. I was somewhat concerned about cluttering up the ticket with an opinion.
I can't even begin to describe how cool this is.
Writing an interesting title, one little snag
Do they mean that ghc 6.10.2 is now supported? AFAIK, the finalizer changes caused breakage with gtk2hs, so I think this is just a slight typo maybe?
I suspect it is a typo, but best confirm that on the users mailing list.
&gt; Fully curried definitions is the right default! This is not news, but over time, I've become more and more convinced of this. Prospective language designers: please heed this advice. The design space around this issue is well-explored, so if you insist on using products on the left instead of exponentials on the right, you're being sadistic. &gt; Scala's inability to infer types with kinds other than \* is a pretty big problem At least it can *define* higher-order kinded types! The limitations of plain HM get old pretty fast. &gt; All told, it is possible to express these ideas in Scala It is also possible to express some of these ideas in Java, too. I had this argument with Tony Morris on these pages a long while ago. It doesn't mean it's practical, much less pretty (his point, which I missed at the time). The use case for such an advanced typing wizardry on the JVM is yet to be seen, I'm afraid. 
It seems silly not to link straight to the pdf... http://www.cl.cam.ac.uk/~mb566/papers/tacc-hs09.pdf
Ex 1.09-1.14 [here](http://sdasrath.blogspot.com/2009/05/20090503-haskell-road-to-logic-math-and.html)
At my work, I'm occasionally tasked to write oddball, limited-use programs. Sometimes these stay completely in-house, other times they're sent to customers with a small problem. I'd like to write some of these in Haskell in the future, but I'm concerned about GHC's use of GMP, which is licensed under LGPL. I believe GHC statically links with GMP, which isn't a problem *per se* with the LGPL; you just have to provide a way for someone to re-link your object files with a new version of the LGPL'd library, which means providing all object files to anyone who demands it. I know what files to provide for C/C++ programs, but not with Haskell. Is it possibly to just provide the .o files, and somehow use GHC to re-link those with a different version of GMP?
&gt; I believe GHC statically links with GMP It depends. On Unix systems, it is dynamically linked (so you are free to redistribute). On Windows, you should follow the guide for [dynamically linking GMP on Windows](http://haskell.forkio.com/gmpwindows). Finally, the main IHG task for this round is to remove GMP as a required dependency.
So will GHC switch to another multi-precision library? If GMP really is the fastest, wouldn't that cause a slowdown? I think it'd be easier just to dynamically link to GMP on Windows by default.
The aim is to provide easy pluggable Integer libraries (so GMP, OpenSSL, Integer-simple et al), rather than being soley tied to GMP. 
I find it interesting that the first solution given: zipWith (,,) ( [1..] ~~ "hi" ~~ "world" ~~ id) is very similar to the solution using Control.Applicative with an alternate implemetation of the pure and &lt;*&gt; operators: fmap (,,) ([1..] &lt;*&gt; "hi" &lt;*&gt; "world") Even nicer: (,,) &lt;$&gt; ([1..] &lt;*&gt; "hi" &lt;*&gt; "world") Or, code that will actually work: getZipList (,,) &lt;$&gt; ZipList [1..] &lt;*&gt; ZipList "hi" &lt;*&gt; ZipList "world" ZipList is just a newtype for a list, but has the alternative implementation of Applicative.
In principle it's also possible to dynamically link to GMP on Windows. It's just a management problem. For redistributable programs you'd just bundle the gmp.dll along with your .exe. The management problem is just for the development case where you make a .exe in some random dir and then expect that .exe to be able to find the gmp.dll. Windows doesn't make that easy.
what resources did you use to research them?
I guess they are trying to show a scheme transliteration of the Haskell code in appendix C, but of course for lists, `zipWith&lt;n&gt;` is spelled `map` in Scheme.
I think it's provided for those who are not so familiar with Haskell, but yeah, the interesting part here is all in the types, which Scheme doesn't have.
Well, this was written in 1999 it appears, before Applicative was even around.
I completely agree with the author. I would add: what helped was that OOP [ actually Object Based ] is based on abstractions that are easy to understand and relate to. By not being a major paradigm shift for most people, it has a lower barrier to entry.
"People were not forced into this style, you can still access your friend’s private members, but programmers were encouraged.", interesting choice of words. ;)
I find it odd that he points to dynamic dispatch as a major risk factor. It's true that, when you make a method call, you don't know what function is going to run. But why is this worse when you call it a method than when you call it a first-order function?
Get tweeting [#haskell](http://search.twitter.com/search?q=%23haskell). BTW, [FP people on twitter](http://www.serpentine.com/blog/2008/12/05/functional-programmers-on-twitter/).
amazing. btw, this is worth of proggit you happy elitist! ;)
I felt kinda dirty when I wrote that.
I suspect perl is on top merely because everybody who doesn't like it has already moved on and doesn't even consider it worth talking about.
Wow, all the C* lumped together..
For a second there I thought they were talking about [C*](http://www.google.com/search?q=cstar+simd)
"I should tread lightly because Haskell’s typeclass system provides dynamic dispatch." Um, no. Type classes provide polymorphism which is resolved at compile-time, not run-time, and my understanding of the term "dynamic dispatch" is that it refers to dispatch at run time.
This Twitter survey does not compute! Here's what I think happened, in order of result: 1. **Perl:** The bulk of casual and real world users have moved on to **Python** and only the hardcore remain, spending their time compulsively twitting about how Perl is still relevant in between downvoting this comment on Reddit 2. **Lisp:** Anyone who speaks ill of Lisp gets a cockpunch by a bearded man 3. **Java:** Number 3? Seriously? I'm beginning to think this list has been accidentally randomized, possibly by a team of outsourced Java developers running 6 months behind schedule on the happiness ranking project and confused about the requirements 4. **Haskell:** Would have been higher, but most Haskell programmers suffer from extreme emotional swings ranging from the enlightened high of finally 'getting it' to the low produced by feelings of intellectual inadequacy after failing to comprehend Oleg Kiselyov's latest paper, or any of his previous papers for that matter 5. **Ruby:** Overall, Ruby developers are a happy bunch, but are busy seeking programming enlightenment and don't have time to descend to the crude, messy world of twitting 6. **Python:** Would have been number one but users are too busy having fun writing programs [and getting high](http://xkcd.com/353/) 7. **Fortran:** The remaining Fortran programmers are too stressed about grant applications and can't get over their bitterness with Stephen Wolfram 8. **Visual Basic:** Users are sad because they have discovered that, just because they have an IP addresses, it does not mean hot women will use VB to create GUIs to track them down 9. **C/C++/C#:** Too busy with being employed to bother chatting positive things on Twitter 10. **Cobol:** Old people just don't know about this newfangled internet thing... can you even twit in EBCDIC at 96 baud? Or maybe its just too much trouble to create a JCL card to kick off a twit job? 
Dynamic dispatch is only as good as the programmer discipline surrounding its use. Shallow hierarchies and an understanding of the [**Open/closed Principle**](http://en.wikipedia.org/wiki/Open/closed_principle), the [**Liskov Substitution Principle**](http://en.wikipedia.org/wiki/Liskov_substitution_principle), and the [**Dependency Inversion Principle**](http://en.wikipedia.org/wiki/Dependency_inversion_principle) are crucial. One of the biggest boosts to productivity and code safety comes from judicious use of the [**RAII idiom**](http://en.wikipedia.org/wiki/Resource_Acquisition_Is_Initialization), ensuring safe, deterministic resource control without the need for such things as naked memory management. 
i thought this would be something about dependent type.
I believe OO is not the ideal approach, but to say that it is bad because of dynamic dispatch because that dynamic dispatch calls "might do anything" is silly, IMO. Dynamic dispatch tables can have well-specified semantics and laws that make it very possible to reason about them. 
I've not attended an academic conference before; is ICFP free? Can I just turn up?
If I develop a module where a write a polymorphic function with an `(Ord a)` constraint, at software development time I don't know what `compare` function I am using. It is the software development level that I care about "dynamic" behavior, as this is what affects maintainability. When GHC compiles this module, it will resolve the function at run-time, thus truly making it dynamic dispatch. Some other compiler doing whole program analysis (JHC/LHC?) probably can figure out all instances at compile time. I should have used a less operational-semantical term than "dynamic-dispatch", but I wanted to keep the term familiar for the reader (and for myself).
&gt; Dynamic dispatch is only as good as the programmer discipline surrounding its use. I agree with the above statement; however, given the general state of programmer discipline, I cannot believe that dynamic dispatch could have been responsible for an *industry-wide* increase in productivity for large systems. &gt; One of the biggest boosts to productivity and code safety comes from judicious use of the RAII idiom, I think that wide-spread use RAII postdates the particular supposed-burst of productivity in the 1990's that I am discussing. (Is there wide-spread use of RAII today?)
It's not free, you have to register: http://www.cs.nott.ac.uk/~gmh/icfp09.html
There is nothing magical about OO anymore. A lot of the principles can be enforced in other ways in other languages. I think encapsulation and information hiding are one of the key ideas of CS that will not go away. Encapsulation can be achieved via modules. Only in languages like java the class is both the mechanism for encapsulation and the criteria for dynamic dispatch. When in fact the 2 concepts are orthogonal. For example modula-3 has both modules and objects as separate concepts. What is visible in an object or not is controlled by the module not the object/class itself. Using immutable data structures and statelessness intelligently is probably the next logical step in CS this could happen with or without OO.
Watch it [in action](http://www.youtube.com/watch?v=gVLFGQGRsDw#t=0m53s).
&gt; Is there wide-spread use of RAII today? Certainly in C++ it is used everywhere. As for other languages, this idiom would only apply to those that do not have intrinsic GC I imagine. 
In addition to roconnor's reply, existential types also move the dispatch to runtime completely.
The code has several lists that would have looked better as dictionaries. With Python-syntax, {"a":1, "b":2} etc instead of long lists of ["a", "b"] and [1, 2]. Also, Haskell is great and everything, but I think Haskell code is very hard to read and understand compared to for instance Python. It may just be a matter of getting more aquainted with Haskell, though.
I think you mean higher-order function. And I can see how it could be slightly worse, since some methods are resolved to the local type, some to the super type, and some to the inherited type. The number of permutations is much larger.
I know I was using RAII in 1992.
I am absolutely thrilled that your most eloquent and crushing complaint is that `{"a":1, "b":2}` is better syntax than `[("a", 1), ("b", 2)]`, because that means *Haskell is winning*. Why, I remember the days when people were complaining about purity and the need for monads...
I was under the impression that RAII wasn't named as such until 1994.
Heh. Syntax. I'll take pattern matching on ADT structures for a thousand dictionary literals any day :)
Surely someone can write a template haskell extension that lets you say something like [$map|"a":1, "b":2, "c":3] to produce a Data.Map (and variants for assoc lists/intmaps).
now that would be confusing to Haskell programmers who instantly recognise stuff of the form [("a",1)] : is cons.
Good point. How about `[$map|"a"=1, "b"=2, "c"=3]`? **Edit**: I'm not seriously suggesting we should actually use constructs of this form, I just wonder if it would be at all useful.
Anyone already using this and having some more extensive examples? I (currently) can not imagine simple use cases. 
Define an operator `(:=)` such that `a := b = (a,b)`. Then `Data.Map.fromList ["a":=1, "b":=2, "c":=3]`. Use `(=&gt;)` for PHP-flavor. :P
No, first-order. The function that calls it is higher-order.
Difficulty of reading code is not a function of just language. Its a function where language is a factor, the paradigm in use is a factor, and most importantly, the knowledge base of the reader is the largest factor. Haskell does require the reader to have a larger knowledge base in order to read than Python. For professional programmers, I believe that its a no-brainer that learning a language, even if it costs months is worth a productivity boost for years to come. I believe this is the case in Haskell. 
Could be, but I was definitely using it in 1992. I was working in C++ on Windows 3.1, and I had a GraphicContext leak. (This was a severe problem, because GraphicContexts were allocated from a small system-wide pool.) So I created a class that allocated and freed a GC. I'm pretty sure I didn't invent the technique; I probably read it in Stroustrup.
I read that page before, but I can't see any place to register. Perhaps I'm being blind?
The function could return a function, which makes it higher-order. You did not specify inputs or outputs.
Registration probably hasn't started yet.
Do the exploits work?
If I understand this correctly, this seems to be a bit like [TiddlyWiki](http://www.tiddlywiki.com/), which has some interesting use cases (personal notebooks, a place to organize tasks, notes, todo items...). However, TiddlyWiki uses JavaScript, and therefore works in every modern browser, which means you can copy it onto a USB-stick, carry it around and use it on every computer. Bookshelf requires Haskell, which means you'll only ever use it on your own computer, and I don't see why you couldn't use simple text-files in that case...
Well, yes, it could. Or it could place a VoIP call to order a cheesecake. But that's got nothing to do with my point. My point is that, in a language with first-order functions, calling a function which is not known at compile time entails dynamic dispatch, just like an calling an object method. The original article does not explain why one is bad and the other is good.
Apparently Ted Neward also said not to use paragraphs.
&gt; F# doesn't have monads, and look how well it is doing. How well is F# doing ?
Joyce does too make sense, after studying his biographies, reading his published letters, becoming at least passingly familiar with the same corpus of materials he had on hand and being aware of contemporary Irish/English politics. Not an author for a leisurely weekend read (The Dubliners being an exception to this statement, lovely book that) but certainly sensible.
I never claimed to be eloquent nor crushing. Haskell is a programming language to me, not a battle. Why are people involved in Haskell so incredibly touchy? Besides, my main complaint was about readability.
Thanks you for a considerate, insightful, well written and non-touchy reply. I agree with everything you said.
I explained why in my original reply.
http://www.flapjax-lang.org/ Not exactly a framework, but it is implemented in haskell and is reactive :) 
On the whole we're not that touchy. In the Reddit world we're touchier because of years of dealing with trolls like Jon Harrop, and the constant slighting that functional programming gets from people who haven't honestly tried it. I hear tale that [C++ programmers get touchy](http://railsconf.blip.tv/file/2089545/) when people start bashing them too. Unfortunately, it's human nature for people to over-generalize their defensiveness when in an abusive setting, and the shrapnel tends to make that setting abusive for others too.
Actually, infix binding is trivial: &gt; let (=:) = (,) &gt; [ 1 =: "a", 3 =: "x"] 
That is very cool. Funny smiley too. Thanks.
Not to be confused with the [ECLiPSe Constraint Programming System](http://87.230.22.228/)
Awesome! I use EclipseFP for work a fair bit and I'd love to see some of the suggested improvements. The program is a good start and I look forward to seeing what improvements are made.
How many people would want to maintain the Haskell-version of Super Mario, compared to the Python version, though? I know I would take the well-written Python version over the well-written Haskell version any day. This could be attributed to my knowledge, or lack there of, but I attribute it to readability. Haskell is more expressive, though, which is nice when you're writing something from scratch. Syntax is incredibly important, since readability is so important.
[Yay!](http://www.reddit.com/r/haskell_proposals/comments/8c57r/dynamically_linked_builds_static_links_are_soooo/)
For whatever it's worth, neither of your suggestions works. Both `-&gt;` and `=&gt;` are reserved syntax, and `:=` would have to be a new data constructor (or type name) because it begins with a colon. Of course, you can use `:=` anyway if you want to see that in your pattern matches.
Why the hell aren't there things like that in the U.S.?
This is not meant as an insult, but I will never understand why somebody would want to make Haskell look like C. The author even got the indentation right, as far as I can tell at a glance... why the semicolons and curly braces everywhere? Oh, and to get back on topic, this looks an awful lot like Erlang. I know that is no mere coincidence, but it's still interesting.
My main use for the semicolons and curly braces is when I have to use some benighted forum/blog software that will destroy my formatting. Or sometimes ghci one-liners. Otherwise it's just [line noise](http://twitter.com/sigfpe/statuses/1466660765). 
But the title is all wrong. Shared libraries don't work in GHC. The page is about how they should work.
Research.microsoft.com server seems to be melting.
I love seeing peoples' light bulbs turn on.
The create/kill actor code should be using `bracket`. Ideally the library would provide some sort of `withActor` function to do this for you.
Been there, done that. :)
Some of my students use(d) MS editors which often screws up Haskell formatting rules. Explicit semicolons and braces make it also easier for blind programmers to 'read' code.
Or some subset of flags enabled by -Wall
Tom should find a better and smaller picture.
A demo can be found here: http://sp2o.org/~sebas/frp-js/www/main.html It is pre-compiled due to my current lack of Haskell hosting. It is still very unoptimized, but is works.
firefox only
-Wall -Werror make my life almost too easy.
Or compile via a .cabal and stick -Wall in it.
HAWT
I like -Wall -Werror for my own code, but I've been bitten by it in 3rd party packages available through hackage in the past. For instance, when -fffi became deprecated and was replaced with the LANGUAGE pragma there were a number of packages that still had the -fffi option, but were building with -Wall and -Werror, which should have still compiled, but which bombed because of the new warning.
There are some issues that prevent me from using these combinators as-is: 1.) There is an ambiguous instance head for Functor, which erroneously claims that the only Functors are ones that instantiate their particular notion of Applicative, which breaks any other code you might import at the same time. 2.) And the local redefinition of Applicative is a needless duplication of the code from Control.Applicative, if the modified version of the (&lt;$) (&lt;*) and (*&gt;) combinators are simply renamed then the ExtApplicative can live alongside the code from Control.Applicative just fine. Even if you don't rename them and just allow those 3 to conflict with the definitions from Control.Applicative you only force them to import Control.Applicative hiding ((*&gt;),(&lt;*),(&lt;$)) which is a lot less hassle than dealing with 2 contradictory definitions for Applicative.
It seems like a sensible default. Certainly it encourages good style and will aid in the prevention of at least some bugs. It seems hard to argue against to me. Setting -Werror to also be the default seems like it might be overdoing it. A case can be made that it will cause code to fail to build which might actually be okay (I feel like this is from RWH or one of the Simons, correct me if I'm wrong).
Maybe it's my machine, but as cool as this is it's very laggy on my machine. It basically stops responding as long as the mouse is being moved.
Same here. firefox 3 on linux
I think I ought to plug some alternatives (which I maintain the Hackage packages for): scgi, BerkeleyDBXML, hexpat and hexpat-pickle. This is the 21st Century. You do not need to use SQL!
I agree. Some of the warnings like "no type signature for f" are pretty obvious to the programmer and most likely won't affect the code. Other warnings, OTOH, are very helpful. Also, some functions that substitute pattern matching (like fromRight) could give warnings (fromRight won't give a warning even with -Wall).
Same here, but he says it's unoptimized. I'm impressed, and I expect it will get a lot better.
As some people pointed out on the mailing list, it can encourage people to write code like: case foo of ... _ -&gt; error "default" simply to silence the errors. But the above is actually worse than a pattern match failure, because the latter at least gives you line information. -Werror by default would make the above style of cop-out even more attractive. Some people also pointed out that the coverage checker isn't that great. For instance, it seems to be unaware of GADTs, so if you have: data Foo a where IFoo :: Foo Int BFoo :: Foo Bool foo :: Foo Int -&gt; Int foo IFoo = 0 you will get warnings about non-exhaustive patterns, even though `BFoo` can't possibly be passed to `foo`. So you need to add cases like: foo BFoo = error "Can't possibly happen." to dismiss the warnings at present. View patterns are, I believe, another case where the compiler warns erroneously. So, the "don't enable it by default" position isn't without arguments, although I'm not sure if it's the more compelling.
Those cheeky devils! That server doesn't work from New Zealand but works perfectly if the request comes from inside the USA. Maybe it's one of those "good country / bad country" things. Here's a copy for the benefit of us outsiders... http://www.blacksapphire.com/~blackh/typefun.pdf 
The GADTs issue sounds like it should be reported to GHC central as a bug (if it hasn't been already). It doesn't seem like it should be that difficult to fix, though I suppose it depends on what the guts look like.
First of all it might be important to say that this FRP EDSL is not specifically for animation. Just for everything you want to do FRP style in your browser. This demo demo is the result of a single weekend of hacking. There are two reasons why this demo is quite (very) slow: - Firstly, the FRP constraints are -- due to the setup of the compiler -- inlined everywhere they are used. This means _no_ sharing resulting in lots and lots of redundant recomputation. This is very easily fixed by common sub-expression elimination. I have almost implemented this, resulting in code that does full sharing. - Secondly, (time based) animation in JavaScript is quite hard to achieve efficiently. The current JS code is synchronous meaning every tick stalls the entire browser for a while. Time based animation should actually happen asynchronously and there are very clever tricks to speedup things. But this has nothing todo with FRP, so this was not my focus. Hmm. Maybe I need a Blog for these kinds of comments. This is a very fun project to work on, so if I find some time I'll try to improve things a bit and create a `real' demo.
Thanks for the explanations. It is a very cool project and I've been looking forward to watching it evolve. Even using the popular JavaScript frameworks, it's hard to create smooth animations. I'd be curious how much this improves with the compiler changes you talked about. Thanks for sharing this and good luck on it.
This is why hackage now rejects packages that specify -Werror, it's just too fragile. Yes, use it during development but it's not suitable for distribution.
Did any language emerge that fulfills the criteria described? Is epigram, or agda, such a language?
With *-Wall* on, I find myself using *error "xxx not implemented"* to stub out those functions and cases that haven't been implemented yet. It can be somewhat troublesome to root them out later. A simple way to handle it is to add a function *todo = error*. It would be very handy to have this made into a macro that provides more information (e.g., line number), similar to how *assert* works. And to add it to -Wall (i.e., a warning is generated when code with a *todo* is compiled).
I have never signed any manifestos, as there is always a hidden agenda behind them.
I think Epigram enforces termination. Agda's termination checker is optional. Coq also requires it. I am even less familiar with the other dependently typed languages / theorem provers, so I can't speak about them at all.
That's quite an admirable intent.
&gt; Hmm. Maybe I need a Blog for these kinds of comments. I would love to read an explanation of what your code does and how it works. Maybe you have some docs somewhere that I couldn't find. Looks very cool!
Well, SPJ knows about the two I mentioned, at least, but there's no official bug. Apparently it's listed as a [summer of code project suggestion](http://hackage.haskell.org/trac/ghc/wiki/ProjectSuggestions) though. Neil Mitchell also points out: &gt; Do you really want exhaustiveness, or is what you actually want safety? &gt; With -fwarn-incomplete-patterns: &gt; test1 = head [] &gt; test2 = x where (x:xs) = [] &gt; test3 = (\(x:xs) -&gt; 1) [] &gt; test4 = f [] where f [] = 1 &gt; GHC reports that test4 has incomplete patterns, but the others don't. However, test4 is safe, but the others aren't. Exhaustiveness is a poor approximation of safety. &gt; ... &gt; Using Catch, it reports that test1..3 were faulty, but test4 is safe.
JHC has a 'magic underscore' extension where you can write code like: foo rest = _ and the `_` will be expanded to `error "..."` which includes line number information and such. Hasn't made its way into GHC, though.
Does anyone know, is it supposed to be (or can it be made) suitable for writing real-time applications?
I'm not convinced that XML databases are the obvious 21st century replacement to SQL databases, unless we're just talking about which fad is current. That said, it's good to know about the BerkeleyDBXML bindings, thanks. 
.. Timber [is] particularly suited to both the specification and the implementation of real-time embedded systems. ...
Maybe not, because some of the warnings provided by -Wall are unavoidable. I'm thinking specifically about the warning over instance declarations not being in the same file as the data declaration. You don't have any control over this if you are creating your own typeclass and instancing a gadt from another package.
Ah. Good to know!
That sounds very close. The downside is that it's very difficult to find with a text search; something like *todo* would be easier to find.
Wouldn't that be nice?
Charity?
I think part of the point of Epigram is that it is impossible to write a non-terminating program (at least, and to persuade the type checker to accept it). There is a whole universe (pun obligatory) of total languages, which are necessarily not Turing complete, and yet computationally practical. If my memory serves, Martin-Loef type theory provides the framework for building such languages...
Mathematically impossible.
Don't forget the other side of the coin. Turner seems mostly interested in outlawing programs whose termination properties are undecidable. There are a whole host of programs that are provably non-terminating that are perfectly acceptable.
That seems excessively paranoid and prejudiced.
Why?
I think you can use Prelude.undefined for that.
It seems to work fine in Safari.
&gt;paranoid yes &gt;prejudiced no
Is total functional programming practical without dependent types?
To the non-Haskell, monads are something you *don't want to use*.
Excellent page! It would be nice with a link to this page from the documentation of the different regexp packages. If you just go to hackage and look for a regexp package it's not very easy to navigate between the handful of packages that are there. A link to this page is exactly what's needed in that situation.
Rocking the free world. Good work, Max!
Repeating a remark I made on that blog post: &gt; About Monad, I recommend starting with Monoid, then Functor and Applicative, and only then play with Monad. Monad is the most complicated of those four interfaces (type classes), and the most often confused with imperative programming. Elaborating on my previous comment: Monad and IO (imperative computation) are independent concepts. There are many monads that have nothing to do with IO; and the IO type can be used without the Monad interface, as it was in the old days, before Haskell had type constructor classes. I wince at the common phrase "the IO monad", because I think it encourages the confusion of these two independent notions. Sure IO is a monad, but it's also a Functor and an Applicative, and 'IO a' is a monoid, whenever 'a' is a monoid. To improve our branding, I suggest we demystify both the `IO` type and the `Monad` class a bit by emphasizing their independence, e.g., by discussing them separately from each other whenever possible. As a start, I recommend weaning ourselves of the term "the IO monad", replacing it with "IO" or "the IO type" (cf "String" and "the String type"). Or, for shock therapy, calling it "the IO Functor", "the IO Applicative" or (my favorite, though a little imprecise, due to kinding) "the IO Monoid". How does separating `IO` from `Monad` help demystify them? Because each one is a clever idea and alien to most programmers. Each one can be assimilated more easily without the other. Moreover, the Composability Coolness of Haskell shines when these two clever-but-graspable independent ideas are used in combination. 
I want people to think: *"Awesome! this thing I'm struggling with is a monad. now my life just got easier"*. After all, monads are one of the big reason that [their language is our library](http://augustss.blogspot.com/2009/02/more-basic-not-that-anybody-should-care.html).
Can't upvote you more about the need to teach monads separately from IO. Even some very smart people tend to have an extremely hard time comprehending that the concept of monads has absolutely nothing to do with sequencing, side-effects and state. I'd also suggest to not introduce the "do" notation until the person in question can write his own monad transformer or at least understand how parsers, probabilistic monads and Cont work.
You, sir, are, in my opinion, right on track. Such separation of concerns in necessary in "modern" Haskell, as is the increased importance of a more rich understanding and application of functors and friends, if I may be so glib.
Actually, I think "hello world" with do is a quite reasonable first Haskell program. They don't expect that it needs to be explained till they've learned a little Haskell -- only after learning about lazy evaluation and referential transparency do new Haskell programmers even realize there is anything to be puzzled by. You can put them on two separate threads, basically: * Learning how to do simple things with the language. * Learning how the language really is different. 
&gt; As a start, I recommend weaning ourselves of the term "the IO monad", replacing it with "IO" or "the IO type" (cf "String" and "the String type"). Or, for shock therapy, calling it "the IO Functor", "the IO Applicative" or (my favorite, though a little imprecise, due to kinding) "the IO Monoid". Re 'replacing it with "IO"', from the perspective of natural language, for clarity and readability's sake, it's often convenient to identify a value with a word in addition to the plain type name. Part of the issue is how well the type name works as a noun. "IO" seems a bit borderline in that respect, and that may be part of why it's so tempting to use an extra word like "monad" to identify such values. Perhaps "IO value" would be more suitable? 
I could not disagree more. The more I read this comment, the more I suspect you are just trolling! Let's take it point by point: &gt; IO type can be used without the Monad interface But it'd still be a monad (lowercase) interface &gt; IO is a monad, but it's also a Functor and an Applicative So it is of all monads!!! (Haven't you written a paper about this???) &gt; the IO Functor Even more confusing! Finally, about "improving branding"... I certainly hate the term "branding", for it is loaded with dishonest connotation. Sure, you do not have to understand the subtleties of Monad to understand IO, and vice-versa, but hiding links between concepts is assuming people are idiots. And dumbing down Haskell is the opposite of what I want. 
For values of type `IO a`, say "IO value". For a type `IO a`, say "a/the IO type". Just like we say "a list" or "a list value", and "a/the list type". Just as we don't go around saying "the list monad". I hope no one would refer to an IO value as "an IO monad", since type constructors can be monads but values cannot.
When you talk about "the list type" instead of "the list monad", are you *hiding* the link between `[]` and `Monad`? Similarly for other monads, including pairings, functions, trees, and Maybe. 
It's very common to use lists without using the fact that they are a monad. It's much less common to use IO without using its monad operations (or, if you like, the functor/applicative operations, which are implied by the monad ones).
&gt; Just as we don't go around saying "the list monad". Here's a [quote from wikipedia](http://en.wikipedia.org/wiki/Monad_(functional_programming): "In a language with lazy evaluation, like Haskell, if only the first element of a list monad is requested..." Quoting from wikipedia is sort of cheating, but I'm just demonstrating the issue as people have encountered it in real life. &gt; I hope no one would refer to an IO value as "an IO monad", since type constructors can be monads but values cannot. See whether you agree with the usage in the first handful of results [here](http://www.google.com/search?hl=en&amp;q=%22an+io+monad%22&amp;btnG=Search). I don't think it's unusual to loosely refer to monadic values using the word "monad". People are good at disambiguating such things, to a point. I'm not defending this, just saying that natural language description tends to introduce requirements that can be at odds with formal precision, so if you're looking to change the way things are done, it can be worth taking that into account. 
&gt; I don't think it's unusual to loosely refer to monadic values using the word "monad". People are good at disambiguating such things, to a point. Well, or rather they're not, that's the whole problem. Most uses of "monad" for "monadic values" I've seen are not intentional shorthands but genuine confusion about the difference. Also, it seems that one root cause for this is that people don't know of the term/concept of "type constructor". In general, it's a bad idea to use mathematical terms loosely.
You're fighting an "eat your broccoli" battle, though. That'll work as long as your audience is willing to be rigorously formal. The links I gave suggest that's not always the case. Also, there's some justification for these barbarisms: for example, "monadic value" is rather long to be used everywhere it's strictly needed, practically speaking. If there's no good alternative, it's going to get shortened anyway. "Monad" is the obvious shorthand. Perhaps it's time to coin the "moval"! :-P 
I agree with you: it sounds reasonable to *separately* teach people how the 'do' notation (without a word about monads) allows you to do imperative things, *and* how monads (without a word about do notation, imperativeness and even the State monad) allow you certain cool kinds of things. And then, when they completely understand what a monad is, introduce the State monad and gradually transition to IO, and *then* say that turns out, IO was a monad, just you didn't notice it, and you can also use 'do' notation for other monads.
That section of the wikipedia article is severely fucked up, thanks for pointing. I'm fixing it now.....Done.
Just because IO's (&gt;&gt;=) and (return) don't have their own names -- causes us to use the IO operations through the Monad type-class. But IO and its composition functions are a separate concept from monads in general, and interwining the two just confuses people and makes them think that to do trivial IO in Haskell you must grasp the abstract concept of Monads. Its not true, understanding IO's return and IO's (&gt;&gt;=) requires *less* understanding than understanding Monad's return and (&gt;&gt;=) and join/etc in general. 
Agreed, but the composition functions of IO are also the monad operations, so it makes perfect sense for those that know about monads to talk about using the IO monad. There's certainly a case for the beginner presentation of IO to leave out the full generality of monads, but that doesn't mean we should deprecate the term 'IO monad' for general use.
Its just bad marketing. People do get the impression that do simple imperative programming in Haskell, they need to grasp what "Monads" are.
&gt; That'll work as long as your audience is willing to be rigorously formal. I think "formal" is not quite the right word, I mean it in the sense of "being precise". The problem is not that "monadic value" or "monadic action" are being abbreviated, but that the abbreviation "monad" has already a different meaning and the difference between these too happens to be crucial to understanding monads in the first place. I'm quite sure that this audience would kill me if I were to say that "I read an article on wiki and I finally understand that the internets I got from my staff was delayed this morning because the internet is not a big truck, but a series of tubes." Ridiculous as this may sound, it's exactly the same issue; it's just that in the case of monads, the geek audience is as wise as the hapless senator. More importantly, I'm often hearing "wiki" instead of "wikipedia" from laymen now. Should I educate them? Or should I let it slide and swim along with the mainstream? It's not that they'll stop saying "wiki" and meaning "wikipedia" after being told about it. :-) &gt; The links I gave suggest that's not always the case. Yeah, sadly. :-( You rightly point out that the forces of human nature are at work trying to turn "monadic value" into "monad". The question is whether and where it's worth resisting them, for instance by cleaning up the mess that is the [wikipedia article](http://en.wikipedia.org/wiki/Monad_%28functional_programming%29). 
The article makes me want to rewrite most of it from scratch. I've fixed the section on lists, but the very first lines, and the "motivational example", the two last paragraphs of "Definition", the "monadic zero", they are absolutely freakingly wrong or misleading, but fixing them is beyond my today's availability of time. Anyone, fix them please! It will take just some 5 contributors or so to make the article fairly OK. By the way, the correct URL is: http://en.wikipedia.org/wiki/Monad_%28functional_programming%29
I don't disagree with you, really. But to your last paragraph, where I started with this is that if the terminology is to be repositioned as Conal suggested, some thought to its usability might help improve matters.
Perhaps someone can file a cabal feature request. I'd like us to be able to do all of these: cabal install ~/some/dir/foo.cabal cabal install http://foo.com/foo-1.0.tar.gz cabal install [--darcs?] http://code.haskell.org/foo/foo.cabal 
Indeed. It's also easy to create safe but incomplete patterns when you define local functions with a where clause; happens to me all the time.
&gt; I agree. Some of the warnings like "no type signature for f" are pretty obvious to the programmer and most likely won't affect the code. Other warnings, OTOH, are very helpful. The problem is, essentially none of the warnings is foolproof. Detecting unused variable/definition? Nope, it can make mistakes. (My bug is still outstanding, last I checked.) Omitted type sigs? Sometimes you can write functions whose type you cannot write (because it uses a type which wasn't exported or something crazy like that. I have in fact run into this!) And so on. You can't say 'let's just use the ones with no false positives' because there aren't many. You have to bite the bullet and accept that there's going to be noise that will bother some people - but enough Haskellers might object to this to kill the proposal.
I think we should stop using the expression "list type" as it gives the impression that you have to understand type theory to use lists! Each concept can be assimilated more easily without the other. Seriousness aside, remember that list is not a type in haskell, but a type constructor.
Add to that the ability to link to a darcs repository in the .cabal file. Then one could do something like this with a package that is on Hackage: cabal install --darcs foo [Edit: Oh, you already implied the .cabal thing. In that case, just add the ability to `--darcs` via packages on Hackage.]
You can already specify a darcs repo in the .cabal file. See the user guide: http://haskell.org/cabal/release/cabal-latest/doc/users-guide/authors.html#source-repos We're just waiting for people to write tools to make good use of the info.
Ah. This must be a recent addition.
A warning that it's a PDF would be appreciated.
See also the [proggit discussion](http://www.reddit.com/r/programming/comments/8ltq1/the_c_language_is_purely_functional/).
Yep, since Cabal-1.6, released with ghc-6.10 last autumn.
Thanks for pointing that out. The documents say that's the purpose of Prelude.undefined. Unfortunately, it doesn't do that in GHC 6.10.3. When running a program called "tests", the output is "tests: Prelude.undefined".
&gt; You rightly point out that the forces of human nature are at work trying to turn "monadic value" into "monad". The question is whether and where it's worth resisting them [...] Yes it is worth it! People's misunderstandings of new information are shaped by their experience. Most people coming to Haskell will be used to OO languages, in which classes contain *things* (values/objects). When they learn Haskell, they'll gravitate toward the same thinking, which is dead wrong, since Haskell classes contain *types* (possibly higher-kinded). If we sit by quietly while sloppy language reinforces predictably and damagingly incorrect thinking, we're missing a chance to help people get type classes, and so Monad in particular.
&gt; Most people coming to Haskell will be used to OO languages, in which classes contain things (values/objects). I think this highlights a crucial misunderstanding by OOPers. The use of "monad" for "monadic value" is an error of conflating the type level with the term level. This conflation is highly prized by OOPers, which may be why it is so hard to unset. Even within the OO paradigm itself it is often difficult to make people separate the concepts of a class itself from instances of that class. The terminology is there, but the concepts don't seem widely known/distinguished; OOPers will freely switch between using a class's name to refer to the class itself and the instances thereof, and when pressed on it they seem to miss the point of the distinction. This isn't bashing of OOPers in general, nor the specific ones I have in mind, but seems to be in the nature of the paradigm as it's taught. I say this after having many type theory discussions with talented and intelligent OOPers who have no formal training in programming languages or type theory (beyond what's necessary to get the CS degree). Languages like Smalltalk have classes be objects too, which only serves to further confuse the issue (and to increase the similarity to our "expressions as computations"). There's still a strong type/term split here, but because the same mechanisms are used to discuss both sides, the split goes unnoticed. The fundamental insight of monads for computation (ignoring for now all the other interesting monads) is much in the same nature as staged programming. And like with staged programming, there's a fundamental separation of layers which "normal" programming lacks. It's a bit like explaining "true" vs "provable" to someone without the prior insight of Goedel. Perhaps this may offer some insights for a path forward.
He has only been learning the language for a few days... I think he's just saying that he isn't completely familiar with monads yet, not that they're somehow bad.
The name of this summarizes exactly what is wrong with the Haskell community, and explains why Haskell will never hit the mainstream.
I always thought the 2006 Portland GHC Hackathon was also the first Haskell hackathon... anywhere. I guess not everyone agrees.
You're thinking Hac++ has a better chance?
Well, "Hac φ" was worlds better than my suggestion. After all, "φladelphia" is a rather clever pun, don't you think? ;-)
I know, I know. This is the first grassroots hackathon. The one at PDX was a side workshop of ICFP, for GHC developers.
good stuff. someone should send it to GvR, so finally python people would get tco. and iirc, GvR likes SPJ, so who knows?
ewww... that looks so... mutable.
Any chance we could reframe the mutability issue like the Light Side/Dark Side of the Force? Luke: Is the Dark Side better? Yoda: No, no, no. Quicker, easier, more seductive. Luke: But how am I to know the good side from the bad? Yoda: You will know, when program multi-threaded you need to write.
In other words, functions in imperative languages are insane.
No, they're just procedures.
&gt; Yes it is worth it! &gt; If we sit by quietly while sloppy language reinforces predictably and damagingly incorrect thinking, we're missing a chance to help people get type classes, and so Monad in particular. I agree. The question is where to act. I mean, we can't possibly clean up every such misconception on the internet, nor is it possible to force people to spend the effort that is required for understanding. But fixing things at some high visibility place like the [wikipedia article](http://en.wikipedia.org/wiki/Monad_%28functional_programming%29) seems worthwhile. We'd just have to do it. ;-)
Just curious: Is there any relationship with timber, except the link to galois' home page?
YAY!
It also seems to be [here](http://crab.rutgers.edu/~pjohann/popl08.pdf) if that link isn't working, as it wasn't for me.
i live 20 minutes from upenn and i'd want to go, but account creation on the wiki is disabled so....
Hooray! I'm going to port ghc to interix now
Looking forward to the next generation of netbooks, and things like the Sheeva plug, an ARM port would be a nice thing to have. Something to consider helping out with if/when I get some hardware.
http://crab.rutgers.edu/~pjohann/popl08.pdf seems to have the same name and should work First post in reddit ^^ Hi to all :)
&gt;Cpo, Cppo, Cppo Whay are there 3 cpos?
Because the mainstream is afraid of Greek letters? That seems rather irrational to me.
Here's your chance to set a new trend and write a Monoid, Functor, Applicative tutorial.
What is that "banner above paper title" doing there?
There's instructions for making an account [here](http://www.haskell.org/haskellwiki/HaskellWiki:New_accounts). Anyway, I'll note it down for you; I take it both June and July work for you?
They're three different (kinds of?) categories. I'm not read up enough on all this stuff to explain exactly what each one is, but you can see some of the differences in his chart. 1) The objects in Cpo don't necessarily contain a least element, while they do in Cppo and Cppo⊥ 2) The morphisms in Cpo and Cppo are continuous functions, whereas the morphisms in Cppo⊥ are strict functions. He eventually comes to the conclusion that the appropriate category for giving Haskell's semantics is Cppo⊥ (despite that sounding weird, because Haskell has non-strict functions; but he explains how to represent those in that category).
sure
"Hac φ" Um, how do you pronounce this? 
Here is the GHC def of "unregisterised": http://hackage.haskell.org/trac/ghc/wiki/Building/Unregisterised This is great progress! I look forward to a registerised build.
That this is a draft paper (probably for Haskell Symposium'09)--the text is added by the Latex stylesheet. Once the paper has been accepted this is where the conference title will appear.
I'm working on it right now. Unfortunately, Ian's unregistered build apparently had a problem when trying to compile a registered build (a panic in `pprDynamicLinkerAsmLabel`,) which I have fixed (I believe) in a patch which isn't in GHC HEAD yet. Current status: with my patch, I was able to compile an unregistered GHC like Ian's above, and using it, a registered build goes all the way to building a stage2 compiler. Unfortunately, the stage2 compiler segfaults when run, because the stage1 compiler produces segfaulting executables. This is likely a biproduct of the fact that the RTS needs to be modified in order to sanely deal with the x86_64 and OS X combination. I'm trying to track down the first problem right now. More news as it develops.
But realistically, to do simple imperative programming in Haskell, they **do** need to grasp what "Monads" are. The reason is that they need to understand the difference between monadic binding vs. binding with "let", and how IO values cannot be used directly, so that refactorings that are common outside of a monad don't work in the monadic context - for example, you can't simplify "do c &lt;- getChar; print c" to "print getChar". To understand how all of this works well enough to understand your mistakes when using IO, you need to understand monads. 
Yes - Timber started out at the Oregon Graduate Institute (OGI) which is now defunct. Many of the OGI folks moved to Portland State and form what is now the HASP group.
Note: lazy unicode strings are now provided. Well done bos!
&gt; But realistically, to do simple imperative programming in Haskell, they do need to grasp what "Monads" are. As someone already pointed out, Haskell had the `IO` type constructor *before* Haskell had the `Monad` type constructor class (or, indeed, *any* type constructor class). Which demonstrates that understanding `Monad` is *not* necessary for understanding and using `IO` well. Instead of `return` and `(&gt;&gt;=)`, you used `returnIO` and `bindIO`. (See [Imperative functional programming](http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.53.2504).) There was no `do` sugar, so there was less confusion about what was going on. Moreover, understanding `IO` is *easier* without `Monad`, because one can focus on the concrete case (`IO`), rather than the concrete case *plus* the general abstraction (`Monad`). Similarly, `Integer` is more accessible without bringing in the various algebraic abstractions that `Integer` happens participate in. I'm talking about learning by newbies here, as was the original post. When someone has learned the concrete types (`Integer`, `[a]` and `IO a`), and *if* one is interested in mathematical abstractions, then by all means bring in `Monoid`, `Group`, `Ring`, `Functor`, `Applicative` functor, and `Monad`. Those quite abstract notions (categorizations of categorizations) give one a lot of leverage. Branches of abstract mathematics become applicable, and typeclass-based libraries can be written and used. But *please*, spare the newbies from these mathematical abstractions until they've grasped the concrete instances like `Integer`, `[a]`, and `IO a`. &gt; The reason is that they need to understand the difference between monadic binding vs. binding with "let", and how how IO values cannot be used directly, so that refactorings that are common outside of a monad don't work in the monadic context [...] If newbies share your perspective, no wonder they find `IO` a difficult concept and are full of confusion. From my perspective, all of this complexity that "they need to understand" is unnecessary. A much simpler explanation suffices, but is *obscured* (not revealed) by bringing in `Monad` and "do" notation. Once you remove "do" sugar, the whole notion of "monadic binding" vanishes. It never had substance. The crucial difference has nothing to do with "monadic binding", but simply the difference between lambda and let. Just drop the sugar, look at the signature for `bindIO` or of `(&gt;&gt;=)`, and the confusion disappears. 
&gt; As someone already pointed out, Haskell had the IO type constructor before Haskell had the Monad type constructor class (or, indeed, any type constructor class). Which demonstrates that understanding Monad is not necessary for understanding and using IO well. Instead of return and (&gt;&gt;=), you used returnIO and bindIO. Perhaps I'm not understanding what approach to actually using IO you think should be taught to newbies. I didn't think you were suggesting going back to the above approaches. Let's say you don't teach do notation, but you teach that e.g. a character can be printed with some other variation on "getChar &gt;&gt;= print". Avoiding do notation doesn't complete solve the problem I raised: it's still necessary to understand the need to wrap and unwrap values in IO values, and thus the way that bind and return work. This is a change for anyone familiar with imperative languages. IOW, it's still necessary to explain that you can't use "let c = getChar in print c", and why, and what the alternatives are. Further, if the alternative you're suggesting involves binding via lambdas, as in "getChar &gt;&gt;= \x -&gt; ...", then you risk confusing people just with the syntax, which takes some getting used to. I suspect do notation provides a benefit for newbies in particular. &gt; But please, spare the newbies from these mathematical abstractions until they've grasped the concrete instances like Integer, [a], and IO a. I'm not involved in any curriculum efforts so the newbies are safe from me. What I was getting at is that to use IO successfully, you have to understand how to use its bind and return, and possibly do notation unless you have some better alternative in mind. While I agree that it's not strictly necessary to mention that all of this has anything to do with monads, or explain what monads are, you're still using monad operations to do IO, and need to understand the basics of using monads even if you don't know that that's what you're being taught. I'd agree that it wouldn't usually make sense to launch into a tutorial of monads in their full generality before explaining how to do IO, though. --- P.S. Responding to the following edits of the parent comment: &gt; If newbies share your perspective, no wonder they find IO a difficult concept and are full of confusion. I appreciate the gentle and constructive criticism. &gt; From my perspective, all of this complexity that "they need to understand" is unnecessary. A much simpler explanation suffices, but is obscured (not revealed) by bringing in Monad and "do" notation. As I've mentioned, part of the problem I'm having is not knowing what simpler explanation you have in mind. I've raised some of the issues I see above. &gt; Just drop the sugar, look at the signature for bindIO or of (&gt;&gt;=), and the confusion disappears. I'd say that's speculation, that would need to be tested in practice. 
And the best place to learn haskell is http://www.haskell.edu/
Somebody needs to change that "Smallman" sign to "Stallman".
[There can be only one!](http://maps.google.com/maps?f=q&amp;source=s_q&amp;hl=en&amp;geocode=&amp;q=One+Microsoft+Way+Redmond,+WA&amp;sll=-37.833158,144.964342&amp;sspn=0.011897,0.021887&amp;ie=UTF8&amp;ll=47.641205,-122.129602&amp;spn=0.005075,0.010943&amp;z=17&amp;iwloc=A) 
&gt; First post in reddit ^^ Welcome!
No, to "Smalltalk"
I'll bet there are lots of wrecks at the intersection of Haskell and Smalltalk.
&gt; Let's say you don't teach do notation, but you teach that e.g. a character &gt; can be printed with some other variation on `getChar &gt;&gt;= print`. Avoiding do &gt; notation doesn't complete solve the problem I raised: it's still necessary &gt; to understand the need to wrap and unwrap values in IO values, and thus the &gt; way that bind and return work. This is a change for anyone familiar with &gt; imperative languages. &gt; IOW, it's still necessary to explain that you can't use `let c = getChar in &gt; print c`, and why, and what the alternatives are. I think `do` notation is actually good for this. One of the things you learn from languages like Sed, AWK and Bourne shell is that clear syntactic differences between use cases help you see different things as different. &gt; Further, if the alternative you're suggesting involves binding via lambdas, &gt; as in `getChar &gt;&gt;= \x -&gt; ...`, then you risk confusing people just with the &gt; syntax, which takes some getting used to. I suspect do notation provides a &gt; benefit for newbies in particular. The traditional "hello world" program (and simple arg processing variations) would be pretty rough if approached this way. 
&gt; The traditional "hello world" program (and simple arg processing variations) would be pretty rough if approached this way. Yes, this is what I was thinking. In the abstract, it's all very well to say "down with sugar!", but actually writing out typical beginner examples and explaining how to do I/O without the sugar would, I suspect, introduce its own set of problems. Here's a version of getLine from the old [Gentle Intro](http://www.haskell.org/tutorial/io.html) tutorial: getLine = do c &lt;- getChar if c == '\n' then return "" else do l &lt;- getLine return (c:l) Here's a version without sugar: getLine = getChar &gt;&gt;= \c -&gt; if c == '\n' then return "" else getLine &gt;&gt;= \l -&gt; return (c:l) I suspect that teaching the latter to beginners would soon illustrate the benefits of do notation. I thought the gentle intro's handling of the monadic aspect of IO was fine: &gt; Haskell's I/O system is built around a somewhat daunting mathematical foundation: the monad. However, understanding of the underlying monad theory is not necessary to program using the I/O system. Rather, monads are a conceptual structure into which I/O happens to fit. It is no more necessary to understand monad theory to perform Haskell I/O than it is to understand group theory to do simple arithmetic. A detailed explanation of monads is found in Section 9. But, my earlier point was that this is one of those pedagogical white lies, because you're about to teach them about a particular instance of bind and return, and a syntax for simplifying its use, so they're learning a fair chunk of monad theory right there, and they do need to understand the details reasonably well to get it right. 
Here is a little cow town in north Texas. http://bikeacrossamerica.org/trip-report/day24/haskell-texas4.jpg Apparently, Haskell in their water supply isn't improving things for them a whole lot, but maybe they're just not using it properly.
AweSome!! links to the code please?
I think that the version without 'do' notation is only slightly harder to visualy scan than one with it, but it is *much* harder to misinterpret. So I'd suggest to teach the do notation as late as possible; probably after a full understanding of all standard monads.
I think that you're looking at this from the perspective of someone already familiar with a lot of detail, and you forget how much you need to know to understand that second example. It's like riding a bicycle, you have no problem balancing and you wonder why the beginners need training wheels. The problem here is not just with visually scanning the code, but with understanding the semantics. It's only harder to misinterpret the second example once you're already familiar with all the details of how bind works, how that sort of monadic continuation-passing style works, how the scope of the lambdas works syntactically, and so on. One point that hasn't been discussed is that this does depend a lot on the target audience. Some people might indeed do well with just learning to compose lambdas directly - but those are the people least likely to need the sort of structured "how to teach beginners" approach that's implied in this discussion. 
I agree that the do-less approach has bad readability by beginners as a drawback, but after all, if they can't understand this, they surely won't be able to *correctly* understand the version with do notation, because they are the same thing, just one of them does have some syntactic sugar whereas the other doesn't! You can't simply ignore the CPS nature of IO, it's just whether you show it explicitly (and I don't think it's *that* hard to explain) or hope that people will somehow understand it implicitly (because it's anyway present and necessary for a correct understanding).
If so, then prove it.
I'd love to see this cabalized and put on hackage. I imagine there are many people who (if only for Project Euler) would love to have access to all of these functions. Also, to Polyomino, great work!
yay!
I think I understood (maybe) every fourth thought, but what I did understand blew my mind. I want to understand more, where would be a good place to begin to understand type theory? I am a RWH follower and an acolyte of mathematics rather than CS, who has no other experience with type theory.
You should at least read Wadler's original paper, "Theorems for free". It is not an easy read at all if you want to understand it fully, however. Also, google for "free theorems calculational introduction" and read the found presentations. One of them finally clarified the calculational side for me, after a long time of struggling with Wadler's paper.
Looks cool from the point of view of cool examples; however, does it present anything scientifically new? [that is a question, not an accusation: I have yet only briefly skipped over the article] I mean, type constructor classes are just dictionary passing, t.i. can't I derive the theorems for Monad-involving functions by deriving the theorem for a function f :: (forall a. a -&gt; m a) -&gt; (forall a b. m a -&gt; (a -&gt; m b) -&gt; m b) -&gt; blahblahblah ? Curiously, that is the first time that I am seeing the need for a forall quantifier *not* at the top level of the function type.
Agreed, jkff. The do-sugared code looks deceptively similar to conventional imperative languages, and so may be less scary to an imperative programmer getting a first impression of imperative Haskell. However, to actually understand what's going on and/or actually write working code, do notation adds a whole extra layer. At that point, the deception that lured imperative programmers in then becomes a liability, because their cleverly cultivated expectations of semantic familiarity turn out to be false. Overloading (of `return` and `(&gt;&gt;=)`) adds a layer as well.
I only realized that pi is not exactly equal to 22/7 in high school. This point wasn't mentioned anywhere and I assumed it should be equal to the never ending number. Then on, I used 355/113 whenever there was 5 in the denominator or 22/7 when some even number was there. I know, it ain't that useful.
what does a hackathon entail exactly?
I think the nested forall is called a Rank2 type. There are also higher rank types. One example of a forall quantifier not at the toplevel is: runST :: (forall s. ST s a) -&gt; a 
Yes, I forgot about that one. However, I never really understood what is going on here in ST; need to read the paper..
I am not sure I understand it properly myself, but I believe its a mechanism meant to ensure that ST constructions such as STRef cannot be preserved between multiple ST computations: newSTRef :: forall a s. a -&gt; ST s (STRef s a) What you get here is a polymorphic value for all s's. However, the STRef's s must match the ST's s, so you cannot use this STRef with any other ST computation, just ones with a matching "s".
Thanks, that clarifies things somewhat. However, it will anyways not harm to read the paper and to re-read the chapter on enforcing modularity in DCiPL.
Kudos for using Haskell ASCII syntax and not fancy unicode!
Do notation doesn't add a whole extra layer from the point of view of the beginner - it only does that once they start to learn the full generality of the notation, which shouldn't normally happen until long after they've been using it to deal with simple I/O. It's not just a matter of do notation being "less scary" - it addresses a bootstrapping problem during the learning process. There's a lot of un-abstracted detail involved in doing simple I/O in Haskell - essentially, programmers have to be compilers that emit a monadic lambda intermediate form. Some of that detail can be glossed over, for a while, using do notation. That may have a cost in terms of expectations being violated later, but it's a tradeoff against greater up-front costs before being able to simply string a few I/O actions together. As I said, the best choice probably depends to some extent on the audience - whether they have imperative experience, whether they have the patience to learn more basics before they learn how to do simple I/O, etc. Of course, if the goal is to return to the "avoid success at all costs" approach, then by all means, abolish do notation in introductory material! 
It takes a big man to do things the Haskell Way?
Lots of hacking on whatever Haskell projects you want to hack on, with the camaraderie of lots of other Haskell hackers to help you on your projects, answer questions, or be helped with their projects. Maybe a few talks. Eating good food. Generally having a good time. Etc.
Good formulations of parametricity with type constructors are few. (I don't know of any) The author admit that there is not really anything new beyond applications (hence the "pearl" classification).
My mother (who recently became a part-time maths literacy teacher, which is basically primary-school maths for high-school students) only learnt this a few months ago -- and she didn't learn it from the syllabus.
Ah ha. 6.10.2 is on 32 bit. Still not on the 64 bit machine. Great work! Also : very impressive to beat the hand written GMP calls -- I didn't think we'd be able to do that.
The best thing is that the code is still reasonably looking (no magic hashes nor plethora of strictness annotations, etc.) Kudos!
Takes a lot of RAM though. But the fact that the next 9 entries all use GMP is most impressive.
only the 64-bit one, because of a ghc bug
wat?
only the 64-bit shootout entry uses a lot of RAM, because of a GHC bug in how Integers are treated (which was fixed in 6.10.2)
Um no, the entry here is the 32b one, and I was talking specifically about it: in the top 10, only the Scheme/PLT entry uses more RAM (10m), the next bad case is at half GHC's memory (2.7m versus 5.2), then GNAT at 2m, g++ at 1.6m and everything else is barely above 1m (20% of GHC)
That's a slightly large footprint, but by no means excessive for a serious runtime (look at Java, Scheme and C#). Nothing to see here.
Oh, fair enough. I assumed you'd gone and looked at the ridiculous ram consumption on the 64-bit entry, sorry :) 
Isn't Integer implemented with gmp in GHC?
Wouldn't splitting the program into a calculation and printing thread be even faster? That's a quadcore, there...
Aren't benchmarks like these only going to reinforce the belief that Haskell is only good for this kind of stuff instead of "real world" applications? How about a benchmark that involves serving large amounts of webpages for example?
Something like: http://turbinado.org/Home/Performance
Sounds reasonable. Try it and see if it works. :)
Looks like a good start :)
Yes. The point is that everybody is using GMP, but *our* compiler uses it better. ;-)
It's true, most peoples opposition to Haskell is because of the significantly different programming style compared to mainstream languages, but I don't think showing a bit of speed will hurt.
Haskell is perfectly fine for real world applications. Best Regards Dr. K. Frankenbuettel Fibonacci Inc. - Your primary source for fibonacci libraries. 
It's not like performance benchmarks are the only thing the community is doing, and this is a great way to demolish meme remnants about performance (and simultaneously show up competitors like Ruby, Python et al). We need to attack on all fronts.
That's a good idea. Strict chans.
The obvious thing, sticking 2 forkIOs into the 'pr' function and running with +RTS -N2 -RTS, doesn't seem to give any speedup here: [07:46 PM] 2Mb$ time ./pidigits 10000 &gt; /dev/null &amp;&amp; time ./pidigits-threaded +RTS -N2 -RTS 10000 &gt; /dev/null real 0m4.830s user 0m4.768s sys 0m0.012s real 0m6.211s user 0m6.116s sys 0m0.164s
"Reasonably looking"? It's practically identical to the code given in the paper! I'm really impressed!
The thing that blew me away was looking at the implementation in Ruby and realizing it would take me less time to figure out what the Haskell implementation was doing. That's something I haven't compared before and amazed me.
Heh, I got an email from them, funny.
He was not kidding when he said a 4 level depth game was really slow. But then again, that is already better than my average play :)
What's also interesting in this is that without -optc-O3 it consistently provided 0.5s-1.0s better results (at least on my machine) than with it. Anyone care to confirm this?
Fairly common - GCC isn't expecting the kind of C code GHC generates. Often -fasm will win out.
***NO EXCEPTIONS***
Having this system as an Haskell library would be really neat. 
His problem with the winner avoiding checkmate seems easy enough to correct in the current code by just capping the evalBoard function at the threshold value. That way (checkmate + all pieces) == (checkmate), and the minimax should just go for the quicker one. A more complicated board evaluation metric is probably the next step anyway, though... Another small comment: In genGameTree it might be simpler to leave out the maxdepth and finalState checks. Haskell's laziness means you can cleanly define the entire tree and then prune as you walk it. genGameTree z = GameTree z (map genGameTree (nextStates z))
my virus scanner goes crazy when I go to that page and reports some malware is trying to get installed.
Nice read: [Bidirectionalization for Free! (.pdf)](http://wwwtcs.inf.tu-dresden.de/~voigt/popl09-2.pdf)
Man those examples are about as opaque as code can be.
The source code for the haskell entry is also the smallest.
That is definitely one of the coolest papers I've read. However, I feel obligated to point out that the class of functions for which you get this kind of free bidirectionalization is very small indeed; it is only those list functions that you can write using *only* equality or ordering comparisons. In particular, pattern-matching is right out. Boomerang's lenses are much more flexible in this regard.
very cool, I've always wanted to write my own text-mode, scriptable IM client, but I've never really wanted to muck around implementing protocols. Any plans to turn this into a library? Maybe some kind of HAIM monad? Or- perhaps bind to other protocols too, HMSN, HJabber, etc? A general HIM monad (Really just Record (login info(s)) + State (connection state(s)) + IO (networking stuff)) would be very cool.
Of what concept is it proof?
that a AIM protocol implementation is feasable and pretty easy -- by the looks of it.
But that's true with almost any modern language that has the support libraries. I really "want" to like Haskell and I'm struggling to try and "get" it....but I'm not really seeing anything where I can't respond with "that could be easily done in (pick your favorite language)" Maybe the concurrency stuff....
New C entry is on top
People interested in doing complex things with embedded domain specific languages in Haskell might be interested in our paper [Unembedding Domain-Specific Languages](http://homepages.inf.ed.ac.uk/ratkey/unembedding.pdf). We take the "finally tagless" interface (aka Higher-Order Abstract Syntax (HOAS)) that Oleg promotes in this Haskell-cafe post, and show how to convert it to a concrete well-typed de Bruijn representation that can be used for more complex analyses, like common subexpression elimination. We also show how to add nice things to the HOAS interface, like pattern matching in the EDSL.
I don't know --- I can't read your version....but consise doesn't mean better....otherwise we'd all still be using C, very obfuscated. I'm all for the abstraction part (and in theory I'm very strongly in favor of strong typing), but pragmatically, I am sure that the same application (AIM Client) could be implemented with Ruby (say), just as consisely.
Are you kidding?
I would, If I didn't have a good, ole-fashioned single core.
He didn't use libraries there, I think. He implemented the protocols in there. Also, the stuff that cannot "easily be done in (pick your favorite language)" is not usually in terms of getting functionality working, but in other terms: A) Reliability * Lack of null references, and use of Maybe instead gets rid of NULL pointer problems * Strong type system: Type errors catch a lot more than other languages * Purity: Effects are quarantined, you get a **lot** of reliability guarantees from library API's that have pure interfaces, that you just can't get anywhere else. B) Performance: * Extra information about the code can help the optimizer even [exponentially speed up code](http://www.reddit.com/r/programming/comments/8mmcu/i_tried_to_translate_the_ironpython_code_to/) C) Conciseness * Code is simply far shorter. The types that are being automatically inferred allow getting rid of a lot of the code. D) Power * Others' languages are Haskell's libraries. In Python, one needs a new interpreter release to get extra functionality like continuations, or support for better exceptions. In Haskell, anyone can just implement it as a library. Augustusson also demonstrates how you can implement C-like and BASIC-like languages in Haskell as simple libraries. * Just yesterday, I created a little proof-of-concept example showing how Haskell's ContT library can be used to emulate Python generators very closely (I believe it can be near identical, except with more power, as you have full continuations). E) Documentation * Something like Hoogle is not as possible/practical in any other language * Purity again: This time, it helps the types of functions tell the *whole* story, rather than hiding potential effects everywhere. 
&gt; but consise doesn't mean better....otherwise we'd all still be using C, In what way is C concise?
Its a shame that some of these don't have links. In particular I find HCluster interesting. Is it closed source? Is it not complete and this is just a forward-looking description?
Excellent! I'm glad to see the tagless approach is being researched further. I'm actually translating Oleg's tagless code to C#, so it's not quite "tagless" due to runtime types. Just stuck on some of the partial eval implementation. It's tricky translating the code into a language without higher kinds.
I don't see the newsworthyness of these "trivial application X implemented in Haskell", the same thing implemented in any other language certainly wouldn't be newsworthy. I mean, its good to learn a new language by starting with some simple tasks, but its really not necessary to submit every little scrap of code you write to Reddit.
Replacing the naive minimax with MTD(f) with iterative deepening should work nicely to cut the branching factor down and replace it with logarithmic search, but then you need to drop the 'infinite' king cost down to something you can have a finite logarithm for like (maxBound :: Int). This will usually be a win until your scoring function becomes really really fine grained, then you can revert to negascout. Iterative deepening has the benefit that you can always stop the computer and force it to make its best move so far, which lets it make better use of its time slot and MTD(f) has the benefit that it cuts your branching factor in exchange for a logarithmic search. Most of the other common optimizations will require you to drastically restructure the board representation. For a great insight into how that can seriously cut down on your constants look at: http://www.cis.uab.edu/info/faculty/hyatt/bitmaps.html Transposition tables will take you farther, but are side-effect heavy: A really nice very light weight transposition table for chess programs is also available there, even if it doesn't transcode nicely into Haskell, or onto modern architectures that lack write ordering guarantees (i.e. most everything but x86/x64): http://www.cis.uab.edu/info/faculty/hyatt/hashing.html
Here's another Haskell version that is 20% faster than Arnaud's, and within 6% of the fastest C entry. *Update*: actually, it's [as fast as the fastest C entry](http://shootout.alioth.debian.org/u32q/benchmark.php?test=pidigits&amp;lang=all). import System pidgits n = 0%(0#(1,0,1)) where i%ds | i &gt;= n = return () | True = putStrLn (concat h ++ "\t:" ++ show j) &gt;&gt; j%t where k = i+10; j = min n k (h,t) | k &gt; n = (take (n`mod`10) ds ++ replicate (k-n) " ",[]) | True = splitAt 10 ds j#s | n&gt;a || r+n&gt;=d = k#t | True = show q : k#(n*10,(a-(q*d))*10,d) where k = j+1; t@(n,a,d)=k&amp;s; (q,r)=(n*3+a)`divMod`d j&amp;(n,a,d) = (n*j,(a+n*2)*y,d*y) where y=(j*2+1) main = pidgits.read.head =&lt;&lt; getArgs If the Haskell `Integer` implementation exposed `mpz_mul_2exp`, my code would be as fast as the C version. It's the same speed as the second-fastest C version, which differs from the fastest only in its use of that call.
Wow, sounds like one change in GHC would make Haskell as fast as C while having 35% the amount of code.
Is it faster to multiply by three using a `mpz_mul_2exp` and an add than two adds? By how much? Would `a+a+a` not be faster than `a*3`?
It seems like if that change was exporting an interface for a few GMP functions and adding some strength reduction, Haskell could get faster than C.
Ooh, nice! igouy added the new code to the pidgits listing, and [it's in first place!](http://shootout.alioth.debian.org/u64q/benchmark.php?test=pidigits&amp;lang=all&amp;box=1)
Since the launch, there has been 10560 downloads of the Windows installer.
As an aside, that is just about the most insubstantial blog post I've ever seen in my life.
Can we optimize the other benchmarks as well?
Yes, it is faster. Three adds is not, however.
maybe this is a dumb question, but couldn't someone just submit the C code output from GHC for the C benchmark?
How come languages differ at all in this benchmark, if it mainly consists of calling gmp?
It would probably suffer a lot on code size.
GHC can compile via C or directly to assembly. A few years ago, compiling via C and then compiling the C with gcc -O3 usually generated faster code. These days, direct compilation usually wins out, and I believe in this case compiling via C was about 10% slower.
By the way, now the Haskell implementation is the fastest!
What's he talkin' about?
There are three factors at play. 1. Some of the implementations are not so hot. Look at the Ruby code, for instance, which even though I'm not a Ruby hacker sure looks to me like it's doing a lot of unnecessary work. 1. Even when they use more or less the same approach, implementations in different languages have done varying jobs in seeing how to implement the algorithm in as few GMP operations as possible. 1. Some languages have slow FFIs, or slow bindings to GMP.
It wouldn't hurt if the post had a link to the Haskell Platform in it. http://hackage.haskell.org/platform/ 
[We largely have](http://shootout.alioth.debian.org/u64q/benchmark.php?test=all&amp;lang=ghc&amp;lang2=ocaml&amp;box=1)
So?
I think the Evil Mangler still has to do some work after GCC has done its stuff.
I see that this is posted by the famous dons, but I can't figure out what this has to do with haskell.
Is HDBC still broken on GHC 6.10.2 and .3 ? 
it's kind of a saga. please join the private google group for details if you're interested or know someone who might be. ( http://groups.google.com/group/haskell-startup ) 
Would someone be so kind as to explain what this changes, maybe with some motivating examples?
Probably some false positive in Dons' google search RSS feed...
I'm with goofy, what does it mean to not generalise nested bindings?
What's the rationale for this?
I hope I'm getting this alright. I can only half understand this stuff. Generally, an untyped definition in Haskell takes the most general type possible. So if you write: readAll xs = map read xs then the type will be (Read a) =&gt; [String] -&gt; [a] There is an argument that these sorts of polymorphic bindings can be confusing in certain contexts. This argument led to the introduction of the monomorphism restriction in Haskell 98. Certain untyped bindings, instead of being given the most general polymorphic type, are given a monomorphic type (i.e., one without type variables like a). The example to motivate this from the Haskell report is foo xs = let { len = genericLength xs } in (len, len) --len might be computed twice without the monomorphism restriction This patch expands the scope of the monomorphism restriction to include local bindings which otherwise wouldn't fall under the rule. The bottom line: if you turn this on, you might have to write a few more type annotations. If you leave it off, you might occasionally get some confusing behavior from polymorphic bindings.
Ahhh I hate the monomorphism restriction! Though I suppose it could be useful if it is an opt-in feature to catch performance problems (which is what the mono restriction should have been).
SPJ has something up his sleeve. (5% performance improvement via more specialization?)
Simonpj told me that this makes type inference with type families *much* easier. Personally I think it's a high price to pay.
Learn to love the monomorphism restriction: when you bind a label to a value, there's a sort of tacit understanding it'll be computed once, and the monomorphism restriction is there to guarantee that expectation. If you really want it to be a polymorphic binding that can be evaluated to multiple values of different types then by all means give it a polymorphic type signature. The monomorphism restriction is useful enough that if it wasn't enabled by default, it would still probably be included in `-Wall`, so you'd end up living with it anyways.
To me, this restriction doesn't seem that hard to live with. It would be nice to see the mentioned library modifications to get an idea of what sort of changes this souped-up monomorphism restriction really entails.
How does this interact with -XNoMonomorphismRestriction? Can it be used to make *only* the local bindings monomorphic? (It would be easier to just use type signatures, I suppose.)
Feel free to sign up! There's no proficiency requirements... only interest requirements. =) I look forward to seeing you there.
go gitit team... this looks great!
Seconded, please show some examples.
Things like this will not compile if you turn on the flag, unless you provide an explicit type signature for *lt*. let lt x y = x &lt; y in (lt 'a' 'z', lt 4 3) Admittedly this example is minimal and kind of lame, but hopefully it illustrates what's going on.
Nice, but, please: Don't call the front page "FrontPage" (for the same reason you don't label the frontmatter of a book accordingly). It's minor, unimportant things like that which annoy me most about websites.
Just remember to compile with -XMonomorphicAccounting
So how would one fix that? Simply special-case the front page to not display the title?
Urged by Ross' suggestions too I have split the intrface now into Functor, Applicative and Alternative. I hope this makes you happy. I will soon upload this new version, which I hope will make you happy. One of the reasons for not doing so before is that I foresee that for specialised parsers many of the default definitions will not work. For many one want to check that the parser does not recognise the empty string etc. Doaitse 
It doesn't appear to be length-limited Huffman, like deflate needs. Last October I was dabbling in a similar area and got as far as implementing length-limited Huffman, if anybody is interested.
Yes, I guess so. Or maybe special-case it to print "Darcs", "The Darcs Wiki", something like that.
Great compression example he gives. He saved a whole three bits!
Thank you very much! Sorry for sniping about this here rather than sending you a direct email. A couple of other random observations: 1.) A lot of the instance declarations for P_m have redundant constraints on P_h and P_f, which are already satisfied. 2.) The names P_h, P_f, and P_m may format into a nice LaTeX document and I understand their selection, but they aren't idiomatic in that they don't fit the style guidelines folks use these days. Perhaps History, Future, and Parser? or ParserH, ParserF, ParserM? 3.) Could recognizers be folded into the P_m monadic parser in the same manner as the P_f future Applicative? This might let more combinators be monomorphic which could increase sharing of parsers. It allow any parser be used as a recognizer without requiring it to have a polymorphic type.
(Steve) Huffman Coding: http://farm1.static.flickr.com/37/79433616_5b1ca4d34c.jpg
In Haskell? Link please :-)
I don't quite understand why his Ord/Eq instances are only comparing the weight -- ignoring all sub-trees completely. Sounds like that's kind of wrong.
I'd have to partially blame Twitter for encouraging the practice of broadcasting the minutiae of one's life into the ether so egregiously. 
I don't have a link because I never put it online, but here it is. ----------------------------------------------------------------------------- -- | -- Module : LengthLimitedHuffman -- Copyright : (C) Alex Stangl 2008 -- License : BSD3 -- -- Generate optimal code lengths for length-limited Huffman codes. ----------------------------------------------------------------------------- -- package-merge algorithm for determining optimal length-limited Huffman coding module LengthLimitedHuffman (codeLengths) where import Data.List (sortBy, foldl', group, sort) -- | take list of symbol frequencies and maximum code length and return -- list of code lengths for length-limited Huffman code codeLengths :: [Int] -&gt; Int -&gt; [Int] codeLengths freqs maxlen = let n = length freqs sortPkgs pkgs = sortBy (\x y -&gt; compare (sumFreqs x) (sumFreqs y)) pkgs sumFreqs = foldl' (\a b -&gt; a + snd b) 0 pkg xs = map (\x -&gt; [x]) xs getPkgs 0 = [[]] getPkgs val = chunkPairs . sortPkgs $ (pkg [(i, freqs !! i) | i &lt;- [0..(n - 1)]]) ++ getPkgs (val - 1) in map length $ group $ sort $ map fst $ concat $ take (n - 1) $ getPkgs maxlen chunkPairs :: [[a]] -&gt; [[a]] chunkPairs (x:y:ys) = ((x ++ y) : chunkPairs ys) chunkPairs _ = [] 
Its too late to read it thoroughly, but just a few style suggestions: \x y -&gt; compare (sumFreqs x) (sumFreqs y) -&gt; compare `on` sumFreqs (\x -&gt; [x]) -&gt; return \a b -&gt; a + snd b -&gt; \a (_,b) -&gt; a + b map length $ group $ sort $ map fst $ concat $ take (n - 1) $ getPkgs maxlen --&gt; map length . group . sort . map fst . concat . take (n - 1) . getPkgs $ maxlen Building chunkPairs in terms of splitting into sized groups, and then (map concat) on those groups... Seems very concise, will try it out :-)
That might make more sense. when I `mappend` two trees I add their respective weights, making that the top level weight for the new tree. I suppose because of referential transparency I could have given only the Leaf constructors weights and defined my Ord instance as the sum of the weights of all leaves in the tree, and the compiler would know to calculate a sub-tree's weight only once. true? is that what you mean?
Oh, sorry then, I didn't know you added all the weights into the parent nodes. If you do that, then it isn't wrong.
There's also Clean, Mercury, unlambda, and, of course, Scheme. Agda anyone?
Could you please post the details here? I don't think it's very nice to have to sign up for a group that I may or may not actually be interested in.
The first thing I thought to look for was an Agda implementation! Alas.
This is a great blow-by-blow example of Haskell in the real world. Recommended reading!
Thanks for the style suggestions. I'm still learning idiomatic Haskell and appreciate suggestions. Let me know how the code works out for you.
Here's a version that avoids redundancy as much as possible, using pretty printers: import Text.PrettyPrint.HughesPJ import Data.Char (toUpper) verse 0 = verse' 0 99 "Go to the store and buy some more" verse n = verse' n (n-1) "Take some down and pass it around" verse' n m msg = beer True n &lt;+&gt; wall &lt;&gt; comma &lt;+&gt; beer False n &lt;&gt; period $$ text msg &lt;&gt; comma &lt;+&gt; beer False m &lt;+&gt; wall &lt;&gt; period where period = text "." wall = text "on the wall" beer b n = bottles b n &lt;+&gt; text "of beer" bottles True 0 = text "No more bottles" bottles False 0 = text "no more bottles" bottles _ 1 = text "1 bottle" bottles _ n = integer n &lt;+&gt; text "bottles" song n = vcat . map verse $ [n, n-1 .. 0] main = putStrLn . render $ song 99 
More great advertising for Perl! Please show this to your manager as to why Perl should be used in your company.
Thought that /r/haskell might be interested in this, too. Here's my comment from the submission to /r/scala. I implemented the first and second column in Haskell: http://hpaste.org/fastcgi/hpaste.fcgi/view?id=5490 and http://hpaste.org/fastcgi/hpaste.fcgi/view?id=5491 . Compile with -O2 -fvia-c -optc-O3 -optc-mfpmath=sse -optc-march=pentium4 -optc-ffast-math -fexcess-precision -funbox-strict-fields . First one runs in 3.6s, second in 4.0s. Their C++ version with same compiler options runs in 2.7s on my machine. So, the price of abstraction in Haskell is 11.1%. 
You can write unreadable code in any language. Some languages just *reward* you for doing so instead of discouraging it.
You could implement "high level" by making Complex an instance of Num and then using the Prelude + and * operators which are "duck typed" in terms of Num.
Well, I considered it somewhat cheaty and was thinking of using a GADT to force dynamic dictionary passing :) However, I've done instance Num at http://hpaste.org/fastcgi/hpaste.fcgi/view?id=5495 . I re-ran all 3 implementations; they have equal time: 3.7s. 4.0 must have been a measurement error. So, the price of abstraction in Haskell is 0.0%.
I bet if you disassembled them, you'd find they were the same machine code. GHC is Sufficiently Smart ;-)
I should be able to make it.
I've also done truly dynamic binding with GADTs and performance is abysmal: 58sec. Obviously GHC is not smart enough to optimize *that*. http://hpaste.org/fastcgi/hpaste.fcgi/view?id=5503
John doesn't seem too enthusiastic: http://groups.google.com/group/gitit-discuss/browse_thread/thread/5ebcfcc464e12a9
broken link: http://www.iis.sinica.edu.tw/~scm/2009/on-a-basic-property-for-the-longest-prefix-problem/
I'm on the fence as to whether the article has merit or is a total troll. On the one hand it could potentially be used to make interesting points about the cost of different sorts of dictionary passing versus templates, etc. On the other hand, the benchmark and choices involved feel quite arbitrary and rigged.
Nice submission. That is kind of my experience too. But for me one of the reasons to learn Haskell was to find out what all the talk about monads was about. I don't think that is the usual path one takes. But I guess not knowing something will attract the proud and obsessive like me. I learned many languages for those reasons. And haskell is definitelly the language that has taught me the most about programming. The funny thing is I come to FP and Haskell in particular from OO. And I found out that it does what OO set out to do, but better. Better abstraction, better composability, better encapsulation, better reusability and testability. There is no way this won't result in better quality in the long term. 
Haskell was the first functional language I looked into, and as such it has become the sort of "standard" by which I judge other FP languages. Recently I've also been looking into Scala and F# (their interop with Java and .NET, respectively, being interesting). For lack of a better description, I'm finding myself confused in those languages as to when to use classes and objects or when to stick to a functional style. I'm curious as to opinions on these "impure" functional languages. Do you use them? What are some pros and cons?
I see those languages as transition languages from OO to FP. I forgot who said that FP strives to eliminate state while OO merely tries to manage it. So I suppose all those languages allow you to maintain some statefulness via the OO features with some FP options to try to eliminate some. But I agree that it might add to the confusion instead of simplify things. 
F# is a very conservative design, so you won't learn much new from it. Scala is pretty much the interesting choice. Learning a new language won't teach you very much about how side effects increase the expressive power. Those powers are real, but are often quite exotic, relying on the interplay of multiple advanced features (such as higher-order store and type abstraction). Unless you have a pre-existing interest in parametricity theorems or constructive topology, you can safely give this a pass. That said, Scala is still worth learning. Its imperative features are irrelevant, but its object-oriented style does have genuine modularity advantages over the functional style. (I figured out a proof of this only a few weeks ago, though probably I've just rediscovered of a well-known result.) You will have to really make an effort to drink the kool-aid and use everything Scala gives you, though -- it's very easy to just use the "type-theoretic subset" of Scala's type system.
I've looked at Scala a bit, but the Franken-syntax always drives me back to working either entirely in Java or entirely in a language with more appealing syntax (i.e., Haskell). You should give some of the languages a try and see if the bits of FP syntax tickle your fancy. (If you're looking at the JVM, you should also look at JRuby and Groovy, both of which have appealing bits of syntactic sugar along with a few warts.)
I came to Haskell because it sounded like all the functional programmers talked of it with some sort of reverence. Like it was a more pure form of functional programming where their languages were designed to be more practical. I have been amazed. Coming from a background in C, PHP, Perl, and Ruby it just blew me away. * I never realized how easy pure functions are to understand. * It makes perfect sense for a function to be a first-class value and I get annoyed when I can't curry them now. * Mapping/folding over lists is amazingly elegant for many problems. * Monads just blow my mind. * Strict types eliminate about 90% of would-be bugs with helpful compile errors. There is only one problem: after you've been to the bottom of the rabbit hole you will never see the world the same way. You may start to wonder if it was all a dream, and which was the dream. 
Neelk, can you give me some more information about your modularity claims? I'm not very clever but even a decent example would be nice as I fail to follow you here. You could always blog the proof and post the link instead. :)
&gt; The bit that stirs me up is that this “stuff” isn’t, repeat is not, Haskell-specific. Its rooted in the fabric of our reality, in our mathematics and our problem domains, and bits poke up like the tips of icebergs into mainstream OO languages, their true structure part-revealed.
So, suppose you have some abstract class List, with two subclasses Nil and Cons. This is just the usual encoding of datatypes in terms of classes. Now, a client program that uses a value of type List can be viewed as a function taking a client and returning an answer -- ie, `client : List -&gt; result`. So far, functional and OO languages work in exactly the same way. Now, suppose that you add a subclass to the List class, e.g. Concatenate, representing the concatenation of two lists. So the modified List class (which I'll call List') now has *three* alternatives. Now, List is a subtype of List', since every value of List is a value of List', but not vice versa. Now, look at `client`, which has the type `List -&gt; result`. In a functional language, we *cannot* pass a List' to `client`, and expect the program to work. This is because the List argument occurs on the left-hand-side of an arrow, and so by contravariance `List' -&gt; result` is a subtype of `List -&gt; result` -- which is the wrong direction -- we already have a `client : List -&gt; result`, and we want to pass it a List'. However, in an OO language, we *can* pass a List' to the client, and the program will still work. So we get extra modularity, in the sense that we get a direction of extensibility that goes in the opposite direction of the subtype ordering. Basically, we just can't write OO programs which make a closed-world assumption about the cases of a sum, which means that we get an added degree of extensibility. Put that way, I'm now sure someone already knew it. :)
My interest in functional programming has increased ever since I found immutable data structures to be a good match for a concurrency related problem I ran into on the job a few months ago. I've learned hardly a fraction of the things mentioned in this article (currently studying Purely Functional Data Structures) but I think in ten years this kind of knowledge will be necessary to get a decent job writing software. I'm using some of the links to help catch up, thanks to the author!
Python was always good. Easy syntax and optional oop. But haskell is just more consise especially for matmatical things
I think that is known as the expression problem: * [Code reuse through polymorphic variants](http://www.math.nagoya-u.ac.jp/~garrigue/papers/fose2000.html) * [Open Data Types and Open Functions](http://people.cs.uu.nl/andres/OpenDatatypes.pdf) * [Polymorphic variants: solving the expression problem](http://okmij.org/ftp/Haskell/generics.html)
The OO features in OCaml seemed puzzling to me; unnecessary and seldom used.
I understand completely where he is coming from. I had been toying with my own little pet compilers for imperative languages for a decade, constantly trying to figure out how to write a language that I wanted to think in before I found Haskell. When I found Haskell, I quite frankly, had a "conversion experience." In it I found almost everything I had been looking for expressed far more elegantly and succinctly than in any of my previous designs. I can still code in other languages, but I don't choose to think in them any more.
Call me back when there's a solid IDE
The question for me is WHY it is appropriate to transition from OO to FP? I'm not seeing examples where it is EASIER to develop real applications (not toy ones) in Haskell (say) than in one of the well known OO languages?
Don't hold your breath waiting for comparative studies - no one is going to spend money doing such a thing.
I'm curious what specific features you'd like the IDE to have. Usually a decent text editor alongside ghci is more than enough for me. (You can just type :r in ghci to reload the file when you change it.) The only feature I consider absolutely crucial is the ability to convert tabs to spaces automatically, and secondarily, it's nice to have syntax highlighting. I can imagine a few Haskell-specific things that it would be nice to do in a text editor. Highlighting the locations of type and syntax errors would be nice for instance, but it's something I can live without, as my text editor makes it easy to jump to a given line number. Also, I've yet to run into an editor which completely understands Haskell's indentation rule, which is a bit silly, because it shouldn't be too hard to get it right. On the other hand, it also doesn't bother me enough to do something about it myself. For the most part though, I view over-reliance on an IDE as a sign that there's a problem with the language itself. If the syntax is so verbose that you need a tool to generate something from a template which you then fill in each time, then I think something is seriously wrong. You should have a higher order function or value of some sort which captures that pattern. If things get really tough, then you perhaps should have some sort of macro. (Though it's quite often possible to avoid going that far.)
I would absolutely love to see a standalone installer for OS X on the Haskell Platform. The current common way to get GHC is to install via MacPorts, but that can cause some issues with trying to install packages later via cabal (some packages which depend on MacPorts libraries then need extra switches just to install), and in fact the MacPorts-installed GHC doesn't even have the editline package (for no reason I can see), so I can't even use it to install the Haskell Platform.
[Work is almost complete](http://projects.haskell.org/pipermail/haskell-platform/2009-June/000406.html)
Clojure, Scala.
Thoughts?
I am thinking I need to eat more fiber.
This is great! Please submit it. Note that your import of toUpper is lint. I agree that a pretty printer is the right way to do this. But this case is simple enough that ShowS serves just as well, so you don't even need that import: verse 0 = verse' 0 99 "Go to the store and buy some more" verse n = verse' n (n-1) "Take some down and pass it around" verse' n m msg = beer True n . wall . comma . beer False n . period . (msg ++) . comma . beer False m . wall . period where period = (".\n" ++) comma = (", " ++) wall = (" on the wall" ++) beer b n = bottles b n . (" of beer" ++) bottles True 0 = ("No more bottles" ++) bottles False 0 = ("no more bottles" ++) bottles _ 1 = ("1 bottle" ++) bottles _ n = shows n . (" bottles" ++) song n = foldr (\k -&gt; (verse k .) . (("\n" ++) .)) (verse 0) [n, n-1 .. 1] "" main = putStr $ song 99 
http://homepages.cwi.nl/~ralf/OOHaskell/paper.pdf Which, tbh, doesn't offer some OOP, but all of what's must-have in state of the art OO languages and much, much more.
Or if you prefer: song n = (foldr1 (.) . intersperse ("\n" ++) . map verse) [n, n-1 .. 0] "" But then you need to import Data.List (intersperse).
I started out in OCaml, and it took me a while to realize how dandy and useful the OOP features were. But then I realized that I'd never be doing that sort of work in the backend where I'd be using it. The web pretty much forces separation of concerns down your throat. Everything must be coded as an RPC (usually of AJAX form) so what's the use of having an OO language for that anyway? I'm interested in how the phone platforms shape out though. Seeing that they're a miniature PC platform, OCaml's OO may finally find some use.
Thanks, I'll give the alpha pkg a try!
You didn't ask me, but what I find most useful in an IDE is navigation, cross referencing a definition with all its uses and being able to quickly leap between them. The best thing I've got going now for Haskell is dumb text search, which is nice but not *as* nice. Contextual tooltip documentation based on Haddock would be cool, too. Also would be nifty to query inferred types when there are unrelated errors in the file (so it wouldn't load in GHCi).
Have you considered also distributing it as a Haskell Platform port, superseding the `ghc` one &amp; stuff? Instead of only a `.pkg`?
No, the point is that this is art, not engineering. If your company is an art gallery, Perl wins decisively. Art is not readable - most of the time - and that's OK. There's no reason why you couldn't arrange the unlambda entry to be in the shape of bottles. On the other hand, there's no standard library that does it for you, so Perl still wins, for now.
Oh my - Coq is also missing. I'm devastated.
That sounds like a story to tell your grandkids.. Oh wait.
So that's what your username is about :)
&gt;If your company is an art gallery, Perl wins decisively. ??? I personally see coding as more art than science but perl not only doesn't win, it's not even in the running. If you mean beauty or expensiveness I wouldn't reach for any script language. I would reach for something that is actually expressive: e.g. Lisp, Smalltalk, Haskell, etc. &gt;On the other hand, there's no standard library that does it for you, so Perl still wins, for now. You have a really strange definition for "win". And this is what is so different about Perl programmers. Being able to write code that cannot possibly be read is not considered a "win" by a sane person.
It is my name
sometimes you just got to try things and see how they feel.
I've used scala to some degree and F#. Unfortunately both left a bad taste in my mouth. Horrible syntax, muddled semantics and in F#'s case the crippling lack of a decent module system sent me back to Haskell. I've been playing around with how to derive Haskell typeclass/ML module like functionality using multiple inheritance, but it seems the modules wind up being the objects, rather than the data you are manipulating with them. At least if you want the post-hoc extensibility that Haskell offers.
OOHaskell is an interesting exercise, but I feel it would almost have been better for Haskell's evolution (or at least its mainstream adoption) for it not to have been able to be constructed. Sure, it proves that Haskell's type system is sufficient to provide a more traditional OOP like framework. Unfortunately, the encoding is so heavy that no one can bring themselves to use it. Whereas a negative result would likely have spawned an effort that could have evolved into something more recognizable to the outside world. As is common in mathematics, having reduced it to a previously solved problem, the community moved on.
10k? zomg.
It's similar to the reason that it was appropriate to transition from procedural languages like C and Pascal to OO languages: the advantages provided by OO were possible to achieve in the procedural languages, but it was tedious and error-prone. Similarly, it is possible to manage mutable state in OO languages, but they don't provide explicit support for it and their libraries often fight against it. Good FP languages provide explicit support for managing mutable state, and this can make a big difference on complex problems. I wrote "complex problems" because the average business CRUD application, implemented as a layer above a database, doesn't present many serious problems. This is partly because of all the tools designed to support such apps, and the architectural styles which have arisen to manage state, such as transaction-oriented systems where little other than database state is shared across transactions. These tools and architectural styles end up constraining the languages being used in various ways. By contrast, FP languages have such constraints built-in. It's when you get to more complex problems that the advantages of a language with good state management really become apparent. 
http://leksah.org/ ?
Yeah, it'd be nice to have that built-in, but I can still work with Haskell without it. All I need is Hoogle, GHCi, and gVim, and I can pretty much find and play with anything I want, and then code it.
&gt; Yeah, it'd be nice to have that built-in, but I can still work with Haskell without it. Oh yes, absolutely. I'm just saying there's a lot more to an IDE than code generation.
On that last point, I think it would be really cool for GHCi to be able to load a file partially when there are errors in some of the definitions (and say which definitions it managed to load).
Failed for me during the opengl install.
also failed for me at that point.
Likewise.
You'll need the OpenGL headers, I guess, guys. Add details to http://trac.haskell.org/haskell-platform/ticket/55 And suggest solutions
Ditto.
Also, apparently Xmonad weighs 6.1 oz.
The alpha2 package installed successfully on my machine.
Light weight!
Same.
Are you guys using the GHC binary install package, or MacPorts? I'm not sure it'll work with the latter. The intent is to eventually bundle them together but the alpha releases are for early testing.
I like that Curry is 12em high.
2lbs. 11in. high Pugs feed on Curry and poop Perl5.
Installing GHC 6.10.3 before installing the haskell platform packages fixes this problem. I'm pretty sure GHC 6.10.3 was meant to be installed *along with* the haskell platform package anyway, and I think people didn't realize that I guess..Though the problem described on the ticket seems to be just a slight variation. Like someone has GHC installed via fink or something.. 
Symlinking the dylibs and headers from the OpenGL.Framework into /usr/lib and /usr/include/GL doesn't help. OSX relies on OpenGL pretty heavily, is it OK to update it? 
Do you have [GHC 6.10.3](http://www.haskell.org/ghc/download_ghc_6_10_3.html#macosxintel) installed? It should work after that if you don't.
I have GHC 6.10.1 currently. I'll update that and see what happens. __Edit:__ That fixed it.
Does anyone know how I can get ghci in 6.10.3 to use readline or editline again, this new haskline thing has no vi mode. Edit: Spoke too soon, Haskline has Vi and Emacs mode also, from their [trac page](http://trac.haskell.org/haskeline/wiki/KeyBindings) $ cat ~/.haskeline editMode: Vi bind: k up bind: j down 
Anyone know how to use this?
I wouldn't consider Clojure as language with OO features.
Neither, I compiled GHC 6.10.1 myself. I'm installing the 6.10.3 binary package right now. Update in a few minutes.. Edit: Yes, the alpha2 install package for the Platform works fine now.
Could you upload this library to hackage ?
I'll be releasing a .dmg with the two bundled together shortly.
I think sleepingsquirrel has it right. You can probably construct a dual scenario that functional languages can do, but OO languages can't.
It's for the same reasons functional code is easier to parallelize: immutability makes local reasoning easier, and easier to compose programs. [On the Importance of Purity](http://higherlogics.blogspot.com/2007/10/on-importance-of-purity.html).
I used a different Haskell XMPP library (hsxmpp) to accidentally DoS my company Jabber server, once.
How heavy is xmonad-contrib?
More more more!!!
On #ghc it was reported that this installer is for leopard only (Mac OS X 10.5 and above) - it will not work on tiger. I think that ought to be made clear on the download site. It is also not explicitly stated there whether the installer will work for ppc, but the name of the file seems to imply that it is for intel only.
That's a pretty sucky bug. Is there an entry in Trac about that yet?
I don't have a Tiger machine, sorry :(
I love it when there's a Haskell tutorial I can understand :)
What bug? Only working on Leopard? I've amended the page to state that.
Sorry. There seems to be this impression that OSX can be updated just like Linux. Doesn't work like that (and I'm not giving Apple any more money anymore, thank you very much). Well, I'm glad you've updated the page -- just cancelled my download. Are you going to build for 10.3/10.4?
It is an experiment. Someone had an opinion, and tried to create a language to see if his opinion was right. Now we know he was wrong. 
&gt;I forgot who said that FP strives to eliminate state while OO merely tries to manage it. Whoever said it, do not repeat his bullshit. FP strives to ISOLATE state, not to eliminate it. You can't eliminate state without making language useless :)) 
from wikipedia on Functional Programming: &gt;In computer science, functional programming is a programming paradigm that treats computation as the evaluation of mathematical functions and avoids state and mutable data. FP with state is not pure FP. You make your language impure to avoid it being useless. But the fundamental priciples of FP is to avoid state. &gt;FP strives to ISOLATE state, not to eliminate it I diasgree with this because that's what OO set out to do with encapsulation. 
I believe that it's not just a matter of rebuilding the binaries. The package tools and format had some significant changes in OS X 10.5.
Do you want me to show you a pure functional language that perfectly manages state ? It is called haskell. &gt;I diasgree with this because that's what OO set out to do with encapsulation. That's what EVERY language is set to do. There are different ways of doing it. Encapsulation in OO is one way, monads is the other. But both are simply an attempt to manage the state. (Monads of course are good for many other things too) &gt;FP with state is not pure FP. Wrong. FP with unmanaged, uncontrolled state is impure FP. haskell State, Writer, IO monads are still pure FP. 
We would very much welcome the people who do mac ports making one for the Haskell Platform(*), just as we encourage all the other distros to do the same. (*) of course it would not be one port/package but a whole collection of packages with a meta-package to tie them all together.
My point was that the FP part in all FP languages strives for purity even in the presence of destructive updates and side effects. I agree that haskell is the most pure out there. But even in scheme or ocaml, you are not going to use side effects if you can avod it. On the other side, OO always taken the stance that state was unavoidable, even good, it just has to be managed properly which I don't agree with. You will always have explicit state. Just look at iterators, you have actually externalized the state of you collection iteration inside another object. Compare that with a map or fold where there is no explicit state. &gt;That's what EVERY language is set to do Not as explicitally as OO. A lot of the features of non pure FP languages still allow you to greatly reduce the amount of explicit state that is shared by components. Even in haskell, I am sure it would be considered bad style if you used the state monads when you could have used instead parameter passing and higher order function for example.
Wow. class Complex a where make :: Double -&gt; Double -&gt; a getx :: a -&gt; Double gety :: a -&gt; Double I'm sure you know this, but for the benefit of others, this class doesn't actually abstract anything.
[GHC bug report](http://hackage.haskell.org/trac/ghc/ticket/3275) submitted. Excited to see this coming together, though! It's going to be way easier to get people to try out Haskell software with this in place.
It's going to take me about month or two to fix my buggy code and automate/document the process. But by then it should be possible to use my tools to generate Tiger packages; last month I actually had a version generating packages in that format. The biggest issue is with GHC; the GHC binary installer is Leopard-only (and Intel-only to boot), and you can't include Leopard-format packages within Tiger-format distributions (and vice versa). Even on Leopard I can't figure out how to bundle the GHC binary installer within the haskell platform installer; the OSX installation system is barely documented (thanks a lot, Apple) and my attempts to extract a flat .pkg out of the GHC distribution via reverse engineering have been miserable failures so far. Plus, I don't have a machine that runs Tiger, and I don't see myself buying one soon. So if someone with Tiger volunteers to fix the GHC build to generate Tiger-format installers, maybe it'll happen. In spare time, it's a month's work or more. So be gentle please :)
Note that this is the same requirements as for the OSX package you get on the ghc download page. I've not noticed everyone complaining that that is 10.5 and Intel only.
+1 for Ceiling Cat.
Unfortunately the pkg download link is 404ing right now.
I don't understand what the author is saying. If he is saying that using unsafePerformIO is always bad then I disagree with him. If he's saying that it's bad to use it to wrap a function with side effects, then I agree. I think for externally defined functions, there is a grey area about what constitutes a side effect.
There are a lot of uses of unsafePerformIO to try to accomplish various optimisations or achieve semantics for pure functions which are otherwise impossible. For example, it's possible to construct an implementation of (&amp;&amp;) which forks two threads -- one for each parameter -- and if *either* one evaluates to False, it results in the other thread being terminated. That is, it has a symmetric kind of shortcutting. There is an [unamb](http://hackage.haskell.org/packages/archive/unamb/0.2/doc/html/Data-Unamb.html) library which uses unsafePerformIO behind the scenes to handle this kind of situation more generally, where you might have two (or more) ways to evaluate what ought to be the same value if they're defined at all, and you're unsure which of them terminate or which of them are expensive and which are cheap. The implementation however is nontrivial, because you immediately run into problems with what happens when an unsafePerformIO'd expression gets thrown an exception while evaluating/executing and later its evaluation is resumed. It turns out that GHC's current behaviour is to freeze the state of the computation exactly when the exception (from a killThread) is caught, and resume from right where it left off when evaluation starts again (an undocumented interaction between unsafePerformIO and exceptions). However, since there's IO in there, things might have changed, and it requires trickery to get things to roll back if they need to be retried. The reason that this is important is that if you have something like: x = unamb a y y = unamb b c and at some point you evaluate x, and it creates two threads and one of them starts evaluating y, which creates its threads, but then the evaluation of a finishes, and y's thread gets thrown an exception, and gets killed. The first problem is ensuring that y's threads are cleaned up. The second problem is ensuring that later on in the program, it's possible to evaluate y and get a reasonable result. This is where things are complicated by the fact that without any additional work, the unsafePerformIO will resume the IO action from the step at which it left off when it previously caught the exception. Anyway, the result is that it's all very very dependent on the specific way that GHC does things. It does appear that we need something more abstract and reliable for this sort of thing.
The author's point of view is valid for someone that is interested in doing research, but IMHO not for someone trying to have something that just works now.
Well, it abstracts the same things that are abstracted in C++ and OCaml implementations, doesn't it?
Well, the 10.4 and or PPC users don't complain because they can get GHC from MacPorts. It's not a binary distribution, however, everything is compiled anew. 
Quite to the contrary, unsafePerformIO is for research work, while you probably don't want to use it much if you just want to get something done "right now". The main point is that you cannot know what unsafePerformIO ever does without referring to a specific implementation, and that using it necessarily ties you to a subset of the possible Haskell implementations.
Seconded! Although it makes me a sad puppy every time I try to do Haskell in other languages and get bitten by performance problems and bloated syntax.
Excellent! Now if only someone could implement the wave extensions...
It seems like so many important Computer Scientists have died in the past few years.
Have a look at this (Oleg alert): [Lightweight Monadic Regions](http://www.cs.rutgers.edu/~ccshan/capability/region-io.pdf)
Install seemed to go OK on my Macbook. I absolutely love the idea of a Haskell Platform; keep up the good work.
Looks awesome, hope to see more in the future!
Great, lets ask the MacPorts maintainers to make a port for the haskell platform.
That would be [Gregory Wright](mailto:gwright &lt;AT&gt; macports.org) then.
&gt; For example, it's possible to construct an implementation of (&amp;&amp;) which forks two threads -- one for each parameter -- and if either one evaluates to False, it results in the other thread being terminated. That is, it has a symmetric kind of shortcutting. Functions like this have really strange effects on the semantic theory of the language, actually. Even if you don't expose the implementation, but only specify that or must return true if either of its arguments do, then you can prove that there is no sequential implementation of the language. This can then mean that *other* "safe" uses of `unsafePerformIO` become invalid! For example, suppose you have a function `f` that takes a stream (`nat -&gt; A`) as an argument. Is there any way to figure out how much of any given stream `f` looks at? One way to do this is to wrap `f` so that it updates a reference cell with the max index, and then look at the ref after `f` returns. In Ocaml, you might write this as: val peek : ((nat -&gt; a) -&gt; b) -&gt; (nat -&gt; a) -&gt; (b * nat) let rec peek f stream = let r = ref 0 in let spy n = begin r := max !r n; stream n end in (f spy, !r) You could do something similar in Haskell using `unsafePerformIO`; basically it's okay because you're using state in a way that doesn't change observable behavior. But this is only true as long as the semantics of the pure language is observationally equivalent to that of some sequential semantics. So any uses of `unsafePerformIO` that add visible parallelism to the language (such as a parallel or) will break this function, because you can send `peek` a stream that evaluates the same thunk in parallel, multiple times. `unsafePerformIO` is very strong magic. Even if you have two uses that are safe in isolation (such as parallel or you suggested, and the spy function I sketched), you have no general assurance that their combination is safe! What's worse, the interaction that causes safety breaks can sometimes arise only very complex higher-order functions, which are not intuitive to think about at all. If all this sounds really cool instead of really terrifying :), then you should look at [John Longley's research page](http://homepages.inf.ed.ac.uk/jrl/Research/index.html). 
Ah, you are right. I see that this is a toy example of abstraction to test the cost.
Another project that hasn't been updated for 3 years. The internal bytecode looks a lot like what Hugs uses - interesting.
I was wondering if someone was going to use TH for this since I read that "Fun with Type Functions" paper. They demonstrated a little DSL for type-safe printf (and scanf), but it still seemed unwieldy compared to the old familiar printf strings of my youth.
My initial parsing of this was "hScamWire", perhaps a haskell library for committing wire fraud.
Who needs printf when you have [pretty](http://hackage.haskell.org/packages/archive/ansi-wl-pprint/0.5.0/doc/html/Text-PrettyPrint-ANSI-Leijen.html) p[rinters](http://hackage.haskell.org/packages/archive/marked-pretty/0.1/doc/html/Text-PrettyPrint-MarkedHughesPJ.html)? =)
Well I'll say two things based on developments over the last several days. Funding is farther away than I thought. And, I'm looking into building some kind of web-panel based tool around puppet, for managing clusters of linux servers. To some extent, making contacts is more important to me than what project, if any, I will ultimately pursue with whomever I partner with.
As does using GHC extensions. Many won't mind.
btw, why is GHC 32-bit on Macs? &gt; (maxBound :: Int) == 2^31-1 True
I'm using Apache with mod_fastcgi on Arch Linux.
I'll never use unsafePerformIO again now that I know Ceiling Cat is watching. Besides, I heard it can make you go blind.
What if the format string is not known at compile-time?
Neat! A couple of comments: The link to the introductory article doesn't work for me (I think it is [this one](http://lukepalmer.wordpress.com/2009/04/12/some-constructions-in-ixi/)). I like the unified taste the formalism has. I suppose it is due to equating types with their characteristic functions, but it's not clear how far it lets you go. The focus on implicative relations (containment and monotonicity) seems to me should reveal interesting connections with Reynolds's work on relational logic. &gt; I’m using set equality here [...] which is probably a bit weaker than Leibniz equality I don't see how both notions can't coincide since it all seems to be about small sets. You can already quantify over all sets, so that a ≅ b (Leibniz equality) can be defined as ΞL(λP.Ξ(Pa)(Pb)∧Ξ(Pb)(Pa)). &gt; I’m trying really hard not to become a logician There are worse destinies in life, Luke. Anyway, it doesn't seem you're resisting too hard. Keep up the good work.
Did Luke ever prove [Girad's paradox](http://coq.inria.fr/coq/distrib/current/stdlib/Coq.Logic.Hurkens.html) in IΞ?
I hereby renew my loud protests that I have been sounding since this problem first surfaced. The reality is that GHC is difficult to port, so keeping it a truly multi-platform compiler takes a lot of work. For my part, I volunteer my Intel MacBook with Tiger for testing purposes.
MacPorts is nice if that's what you need. But it's not a solution. Apple provides the technology for creating installers for all Mac OS X platforms that are currently supported by Apple. That is what we need for GHC. 
That's somewhat similar to another question asked on haskell-cafe a while back. Someone asked why: unsafeSTToIO :: ST s a -&gt; IO a is unsafe, unlike: stToIO :: ST RealWorld a -&gt; IO a And as far as I can tell, the former is essentially safe on its own, but it can break other 'safe' uses of unsafe functions. For instance: runSTArray :: Ix i =&gt; (forall s. ST s (STArray s i e)) -&gt; Array i e runSTArray st = runST (st &gt;&gt;= unsafeFreeze) (I'm not certain that's the implementation, but it's close.) That `unsafeFreeze` is 'safe' under the assumption that the `runST` ensures that no actions that access the array can escape from the scope. However, `unsafeSTToIO` lets us do just that: construct `IO` actions that access the internals of the `ST` computation (while the `ST` computation remains eligible for `runST`). This means that one can construct examples where you can observe mutation in response to evaluation of pure code. So there again, two things that might be safe on their own interact to become unsafe.
I'm not a Perl programmer. I used to be, but I haven't used Perl for years, because I'm not working as an artist. The Perl code *is* readable - can't you see that it's in the shape of bottles? And can't you check that it indeed does the right thing when run in a Perl interpreter? That's all, there's nothing else to it. That's the artistic medium here. It's not an engineering creation. It's art. When you look at a typical painting hanging on the wall at an art museum, you can experience fully its intended visual effect without inspecting individual brush strokes under a magnifying glass or understanding all of the subtleties of the artist's technique. The value of the painting is not judged by how easily it can be reproduced or refactored. All of those things are interesting to certain experts, but they do not define the painting. Only its visual effect defines it. That is very different than what we mean when we say that we "see coding as more art than science." You're right that viewing a programming language as a plastic medium is peculiar. And I'm not the one to decide whether such practice is sane. But under those assumptions, Perl wins.
Aha, now I see what you meant.
The 64bit OSX port is under development. It might be usable by the time of the ghc 6.12.
hurray! :)
Maybe this will discourage people from writing monstrously complicated Haskell in an effort to achieve performance. Currently Haskell is spread out between "concise" and "verbose" (tending towards verbose) and achieves low times.
You mean "achieves high speed". It is hard to be both concise and fast, I think is the take away lesson. In any language. Currently Haskell is always fast, at least. Haskell sometimes achieves both.
I kind of wish the shootout would separate programs written with different objectives (performance, length, etc.), and that these graphs showed all of them. That way we could see a nice spread of short but slow to long but fast programs. The more refined the line, the easier it may appear to be to optimize or shorten the program.
come on man, how objective can you be ? ;)
I don't think the conciseness part is really relevant. These are all relativelly small programs. So I don't thnk the delta between the largest and smallest program is any indication of anything. At best it's more of a subjective quality as which is more readable. 
Don't do that. Haskell will pop a cap in yo ass.
I disagree. If you consider (for example) the ability to sum vectors, then the shortest programs that can do that *likely have that functionality built-in*, either as a primitive (as in SQL SUM()) or as a composition (as in APL +/). This can translate into huge productivity gains for the programmer, as in our example, why write this: a = 0; s = sql("SELECT data FROM table"); while (r = fetch(s)) { a = a + get(r,0); } when you can write this: s = sql("SELECT SUM(data) FROM table;"); a = get(fetch(s), 0); If your language doesn't have this (or some other functionality) built-in, then *even if it can do this*, you'd still have to implement it first.
So, they're going back to the JHC architecture?
In a very limited sense, maybe. This C backend is just a temporary bridge that allows us to move on to more interesting topics. Since C cannot give us the performance and flexibility we want, eventually we'll write a proper backend. We still do not (and can not) share code with the JHC project.
There are lots of simple implementations of graph libraries. I don't see why one would add another one. Those people who didn't write their own *efficient* graph library, will only find that they need the efficiency when they try to port some existing graph algorithm to Haskell. The other algorithms listed on http://www.polyomino.f2s.com/haskellformathsv2/HaskellForMathsv2.html seem quite interesting, but are probably not efficient in the same way, which makes calling some external program which already solves the problem and then parsing it back into Haskell faster than just calling this library. 
Technically the Mandelbrot set is not known to be computable (for the usual technical definition of computable).
Nice article, but I'm pretty sure that C doesn't have ¬ as a bit-complement operator.
Good news, everyone! Good luck, Erik.
Great to hear!
Was considering switching to Debian. Sounds like another point in its favour.
I kind of wish that people who wished the benchmarks game did their neat idea would just go implement their neat idea ;-)
&gt; the delta between the largest and smallest program How much difference in *program size* do you think comes from the language, rather than from the libraries? It seems like a program can be a few times shorter because of the language, but it seems like what makes it *really short* is not having to write code because it's already there in the codebase.
Can't say I hadn't thought about it.
So what are the real-world implications of that?
I think the consequences are that there might be/are little filaments that we are not seeing. But I am not certain. IIRC, there is an algorithm that is conjectured to work (not the usual one). If so, then we aren't missing anything.
I think I was wrong about the description of the behaviour of the conjectured correct algorithm. I think what happens is that for some pixels it might never decide if it should be white or black if it is incorrect. Although I still could be wrong.
Recent H1B data: 3/20/2007 I-07079-3163279 Software Engineer 96000 107000 3/20/2007 I-07079-3163295 Formal Methods Engineer 96000 126000 7/10/2007 I-07191-3553947 Software Engineer 95992 105000 9/19/2006 I-06262-2809273 Sen. Comp. Software Eng. 103000 115000 12/6/2004 I-04341-1473371 Software Engineer 95000 105000 1/22/2004 I-04022-0907175 Systems Engineer 94100 105000 ... so, interesting work, but not exceptionally well paid.
Is the last column the actual salary? What is the next-to-the-last column number? For Oregon those salaries are actually very good... though, considering that most of those guys have PhDs it may not be quite as competitive. However, there aren't a lot of jobs for PhDs in the Portland area.
The company can specify a range when applying for the visa. Some companies apparently use the official "prevailing wage" as the minimum and the actual wage as the maximum. Some only give one number. I'm not sure. [(source)](http://www.flcdatacenter.com/).
should also post to: [/r/jobs](http://www.reddit.com/r/jobs)
This job seems to be more about HR than with development. Of course I could be wrong.
Yes, you are wrong. Also, there are multiple positions available.
interesting. too bad I don't have a PhD
Thanks for clearing that up.
Your reading skills might also be a strike against you.
I'm the author of that message, so if you have any comments, I'd love to hear them.
Nice to see it back online! :)
Crypto biz apparently going well. Big order from the NSA?
well, there is that too
If only you were in the bay area. :(
I thought the encoding was quite nice. The basic idea of dependent types is easy, but the practice of using dependent types in Coq or Twelf or Agda often results in extremely baroque code (with generally poor documentation :) So seeing a familiar non-trivial(!) example with all the bells and whistles of type equality constraints and dependent induction functions really helps make other dependently typed code legible.
How does the company deal with engineers from other countries? H1B is too long to get (and AFAIR is a lottery).
still hoping that galois will start offering internship opportunities. I would love to learn in person from some experienced haskellers!
This is why Haskell burns my brain. I just know this stuff is out there and i'd be better knowing it, in fact it probably appears everywhere in ad-hoc form, but damn is it twisty and abstract.
In defense of Haskell, knowing these toys isn't necessary to use Haskell, it just happens to be that Haskell is one of the few languages in which they can be cleanly expressed in their most general form.
No, no, I wasn't putting Haskell down. I wish I knew this stuff. I wish there was a ramp-up to it that didn't involve a decade of university math. I just have the nagging feeling that this kind of high abstraction, properly understood and applied, could turn complicated programs into short ones.
No offense taken. =) In practice, I think a lot of this is a blind alley. It does help out occasionally though. Weirich and Washburn wrote up a form of higher order abstract syntax in a fashion that you could only perform catamorphisms on it explicitly so you could be sure that no one tried to encode an illegal program in it. Knowing that a bunch of traversals are all catamorphisms (or something slightly stronger) can permit fusion of them, eliminating multiple passes over the source data or even the asymptotics of the solution. Mostly I tend to use the ad-hoc solution with an eye towards what kind of abstract traversal I'm implementing rather than use the explicit combinators for these things.
Awesome! I can't count how many times I've had to explain that while Haskell strings support Unicode, the default IO mechanism doesn't. As an aside, hrmm, didn't old Macs (pre-X) use just a CR as a line terminator? That would slot in fairly easily to the Newline ADT.
Yes it'd be possible to support the CR line terminator. Doing so however seems almost completely pointless! :-) How many MacOS9 text files do you have? Of course if someone knows specifically that they need to read CR-style text files then they can easily do it explicitly. This new API is for convenience to cover the normal cases. Anything abnormal can be done by layering over the binary/raw case. eg: -- | Fix different systems silly line ending conventions fixLineEndings :: String -&gt; String fixLineEndings [] = [] fixLineEndings ('\r':'\n':s) = '\n' : fixLineEndings s -- windows fixLineEndings ('\r':s) = '\n' : fixLineEndings s -- old osx fixLineEndings ( c :s) = c : fixLineEndings s 
Heh, sad as it is, I actually I have a fair number of them from some old projects sitting in stuff it archives. ;) Not that I'm likely to look at many of them again this decade, let alone read them from Haskell.
Great work! Perhaps this will be the end of line ending errors when cabal is trying to read the package index.
Awesome. Finally.
If you're seeing a problem reading the package index then it must be something else. Please report it in the Cabal/hackage trac: http://hackage.haskell.org/trac/hackage/ Cabal uses the `fixLineEndings` function I mentioned and has done since version 1.2 (which is before cabal-install and the package index).
I just love to see signs of people making money out of Haskell! Let it increase and go on increasing.
Thanks. I'd never really thought about this but intuitively it makes some sense. Here's what [wikipedia says](http://en.wikipedia.org/wiki/Mandelbrot_set) about it: &gt; In the Blum-Shub-Smale model of real computation, the Mandelbrot set is not computable, but its complement is computably enumerable. However, many simple objects (e.g., the graph of exponentiation) are also not computable in the BSS model. At present it is unknown whether the Mandelbrot set is computable in models of real computation based on computable analysis, which correspond more closely to the intuitive notion of "plotting the set by a computer." Hertling has shown that the Mandelbrot set is computable in this model if the hyperbolicity conjecture is true. The Hertling paper about it is [here](http://www.fernuni-hagen.de/imperia/md/content/fakultaetfuermathematikundinformatik/forschung/berichte/bericht_298.pdf). Penrose also discusses it in Emperor's New Mind, text [here](http://books.google.com/books?id=oI0grArWHUMC&amp;pg=PA161). 
BTW, the Blum-Shub-Smale model of real computation is a moronic model of computation that has almost nothing to do with actual computation as we understand it. Hertling more or less says this, but in a kinder way. It is kinda sad that the BSS model gets the attention that it does.
Where I live, that's about double the pay recommended by the union. Which most people don't get.
Fixed. Thank goodness it's a wiki that anyone can edit. =)
Title is not appropriate for the Haskell reddit. By all means post a link to the "Future of Happstack" discussion, but there's no need to flame the developers.
But i'm not posting a link to mere plans of happstack development. You are covering haskell progress on reddit quite fine without my help. I'm posting to discussion that clearly shows realization on the part of happstack developers that they've made a series of mistakes with scope of their project and priorities. 
You're editorialising in the title though. That's the problem.
&gt; didn't old Macs (pre-X) use just a CR as a line terminator? Yes indeed. I was just about to mention that. Mac Classic is dead by this point, but it is a worthy historical point. For a long time OSX made sure to write files with Classic newlines in order not to muck things up for people using both. OSX still supports reading in Classic files (last I checked), though I wouldn't be surprised if the Classic write-out has been removed now that Classic has been killed. *Edit:* On the one hand, having wrestled with Classic programming for many years, I'd love to see it "just work" for anyone pulling out legacy files for munging with. On the other hand, backwards compatibility with "really, it should be dead by now"-platforms is one of the issues which has caused innumerable complications with Perl's development over the years. I'd hate to see GHC get caught in that mire.
is Data.HashTable really the best choice for this? it is notoriously slow...
Cool, there's lots of good stuff on this blog! Bookmarked.
Sounds great! I'll be there!
The title is really misleading IMO. They are talking about how to make happstack scale, not how well it already scales.
But, good times, this title rhymes! ;-)
QOTD: "If extreme idealism isn’t working out for you, maybe it is because you are not wholeheartedly following your own ideals."
I think this post is misleading. HAppS, last I was aware, is trying to create a transactional, sharded store. Unfortunately, transactionality has a complex relationship to scalability...
Now even Haskell is into FML...
I can't say the code I wrote is "the best" (In fact I'm sure it's far from it), but I'm pretty happy with it overall. Haskell, or I guess GHC, does an awesome job on parallelization, easy and efficient.
It was posted on the happs list, where most people would already know the current situation, as well as the context of recent discussion about the future of happstack. dons just can't resist a snappy title though. :)
The only problem I see with this representation is that an instance of Monoid that violates the associativity or unit laws could potentially distinguish between list constructions, so it is slightly larger than [a], much in the same way that different lists are.
From the little I know about ray tracers, it would seem that it is a problem that is very well suited to running in parallel. If that is the case, why are we observing a &lt; 2X speedup when there are 8X as many cores?
Likely just because not every possible opportunity was taken for parallelism in awj's implementation.
From my (admittedly poor) understanding of how things work, you might be seeing the disk write and string conversion time for the PPM files it creates. The parallelization I implemented split work along each image row. This isn't exactly ideal as some rows have more work involved than others, but in general it shouldn't be terrible. Unfortunately I don't have access to profile these things on the systems those benchmarks were run on, so I'm not really sure what's going on.
Page 18, issue #1: Isn't this the same question as asking if functions should be curried or not? Enjoyable read. Not so different from what I wrote into my thesis last week.
anyof's backwardness is interesting. 2.1 "We insist on aspiring a more elegant solution." This sentence is awkward. Perhaps "We insist on a more elegant solution", or "We aspire to find a more elegant solution"
thanks, I have rephrased the sentence.
woohoo! Enterprise ready! http://github.com/tenderlove/enterprise/tree/master 
The #haskell-iphone irc channel has just been set up on freenode. Looking for ideas for channel logging.
so i guess this means haskell on arm works now?
I would really like see the project achieved
It would be interesting to know how he did with this since it was written in the beginning of '08. 
[Seems to be][1] `ryant5000` ([just joined Twitter][2]). [1]: http://twitter.com/fac9/status/1938253968 [2]: http://twitter.com/ryant5000
hugs has been running on iphone for a year now...
Pretty happy with how smooth this appears to be, post-platform.
Hm. Correct me if I'm wrong, but aren't most/all of the Okasaki papers already implemented and on Hackage in the form of the Edison library?
&gt; Telling dons that something has been added to the shootout is the new telling Oleg that it can't be done in the type system *Edit:* Apparently in reply to [this](http://farm4.static.flickr.com/3595/3632587721_530c89a8d0_o.png)
Yeah, in pre-RWH days. And that blog has become totally inactive since soon after that post.
&gt; Dependent types are a “niche” feature with a couple of convenient uses: Propagating data invariants attached to data structures. Propagating input-output invariants through monadic computations. (Note that proof automation more powerful than Coq’s could, in principle, achieve the same propagation without dependent types.) In all other cases, I believe it’s just more effective to write plain ML/Haskell-style data structures and functions, and separately state and prove properties about them. seems to be saying there's too much mental overhead for dependent types to be widely useful.
Well, yes, and no. He proceeds to avocate for alternative solutions such as the Program extension for Coq, which can nicely separate the dependent part of your types from the code that is actually doing work.
This is a port of GHC, though. I suppose I should have labeled it as such.
do it over and don't use a do construct do's are unreadable (in my opinion) if their more than 3 or 4 lines long
Konqueror crashed showing me a weird error message which mentioned some *.ru domain after I clicked that link.
Real World Haskell, the book he cited as his main learning guide, actually recommends that newer Haskell users use `&gt;&gt;=` syntax over `do`. It has been a good idea for me. Using `do` can trick you into thinking procedurally, e.g. run this function and store the value here, then run this function and store its value, then call a function with those two values and store the value again. When you start using `&gt;&gt;=` a lot of the elegance of functional programming is more evident and it makes it easier to see generalizations. Of course, I'm still a Haskell newbie, so take that with a grain of salt.
The whole thing was a good idea but in the end I think the haskell community would benefit far more from work on development tools and infrastructure. I'm working a full time job and finishing my MSc dissertation so I cant see myself finishing the library any time soon. There is a lot of useful code in the repo already and I would love to eventually see it cleaned up and merged with the edison library. The test code I wrote is also pretty interesting - it allows a single suite of quickcheck properties to be specialised to any instance of the Map class. 
Can you write the next turn's state as a function of the current turn's state plus the user's input? Now, it may be that this particular program doesn't lend itself to being shorter in Haskell. It looks like nearly half the lines of the original program are doing interactive IO, and that there's almost no space spent on or to be saved by program structure abstraction. If your goal is to rewrite in a modern language in the minimum number of elegant lines of code, something like Perl or Python might be more appropriate in this particular case.
Another solution to Gunther Schmidt's sequence (well, basically Reid Barton's solution) is sitting at the bottom of http://haskell.org/haskellwiki/New_monads/MonadSupply
Man, I'm tempted to just rewrite the whole thing, but I'm not sure if I feel like taking the time...
I think the problem is a failure to separate the responsibilities of the program into composable abstractions. The state, IO, random number generation, etc. are all interleaved with one another. That may not even shorten the code (although it might), but it certainly would make it clearer!
First, I'd like to say that the code doesn't look that bad. Here are some suggestions: showResults could probably use unlines [ ... ] instead of lots of printfs.. Pattern-matches on maybes are usually shorter when using "maybe" instead. IO (Maybe a) is often shortened by using MaybeT IO a instead (Typically the MaybeT binding is exactly what you want). The pattern: do x &lt;- action return (f x) can be reduced to: f `fmap` action And: do x &lt;- action case x of Nothing -&gt; return oneThing Just y -&gt; return (anotherThing y) Can be reduced to: maybe oneThing anotherThing `fmap` action Instead of manipulating state directly, you could use StateT IO and use get/put on the state. Then, "doYears" could be used via "forever" instead of manually recursing. btw: You could probably use: type GameMonad a = StateT GameState IO a gameState = id io = lift -- Use (io $ print ...) to perform io actions in GameMonad, and (gameState $ get) or (gameState $ put newState) to access the state. Then, every function that currently takes a GameState arg and is in IO, would instead be in GameMonad. This has the advantage that it allows you to later extend this monad with more features. There are some unnecessary (), e.g: if (year sOut) &gt;= 10 The various validate functions that are hand-written could probably be described more concisely as: validate = validateInRange or such common code. Once your stuff is in the GameMonad, you wouldn't need the intermediate Orders data structure, and could directly manipulate the game state instead. Also, you can throw in a MaybeT or EitherT into the GameMonad, which allows "throwing" all the way out for negative inputs, instead of "complicating control flow", and avoiding the need for the "Abort" thing. Then, validators can use a simple Maybe result instead of the Accept/Retry type.
When using `fmap` infix, I find it nicer to use the `&lt;$&gt;` alias from `Control.Applicative`.
At first I said that you're right. I take it back. I recommend that you use `=&lt;&lt;` instead of `&gt;&gt;=`. :)
Oh geeze, now you're just confusing me. Next thing you know I'll be advised to write everything as a functor and just use `&lt;$&gt;` all over the place.
+1 on that. I hate having to read expressions involving both (.) and (&gt;&gt;=), as you switch directions repeatedly. Either use (&gt;&gt;&gt;) along with (&gt;&gt;=) if you really like left-to-right-ness (or even just (&gt;&gt;&gt;) with Kleisli), or stick to pure right-to-left-ness, I'd say :)
When you can, definitely. :)
How does this compare or relate to Text.StringTemplate? Looks like a lot of overlap, at the very least.
Yea, I am sure haskell apps will pass Apple's rigid review process.
he links to this video, but theres no sound http://www.youtube.com/watch?v=4I7VZV7elnY
I, for one, would be interested in comparing your version with his--and I imagine other newbies like me would be also. Of course, your time is your time :)
I'm thinking I'm gonna give in and do it tonight. [Edit (next day): I did some last night, but lost interest and went to something else. I'll tackle it again tonight, maybe.]
I changed a few functions to make use of MaybeT and StateT doYears :: GameState -&gt; MaybeT IO () doYears sIn = do ((), sOut) &lt;- (flip runStateT) sIn $ do modify chooseNewLandPrice s &lt;- get orders &lt;- readOrders resultsOut &lt;- applyOrders orders sOut &lt;- get lift . lift $ showResults sOut resultsOut lift $ checkStarve resultsOut s if year sOut &gt;= 10 then lift . putStr $ finalReport sOut else doYears sOut checkStarve :: Results -&gt; GameState -&gt; MaybeT IO () checkStarve results s = if peopleStarved results % people s &lt;= 0.45 then return () else do lift $ printf "You starved %d people in one year!\n%s" (peopleStarved results) finkMessage fail "" killPeople :: Int -&gt; GameState -&gt; GameState killPeople n s = s { people = people s - n, totalDeaths = totalDeaths s + n } useRandom :: Monad m =&gt; (StdGen -&gt; (a, StdGen)) -&gt; StateT GameState m a useRandom func = do (res, rngOut) &lt;- gets $ func . rng modify $ \s -&gt; s { rng = rngOut } return res applyOrders :: Monad m =&gt; Orders -&gt; StateT GameState m Results applyOrders orders = do modify $ \s -&gt; s { year = year s + 1 } peopleInit &lt;- gets people let starved = max 0 $ peopleInit - (bushelsForFood orders `div` 20) modify $ killPeople starved modify $ \s -&gt; s { cumDeathRate = cumDeathRate s + fromIntegral starved / fromIntegral peopleInit } modify $ \s -&gt; s { food = food s - (acresToPlant orders) `div` 2 } bushelsBeforeRats &lt;- gets food harvestYield &lt;- useRandom $ randomR (1, 6) ratD6 &lt;- useRandom $ randomR (1, 6) let eatenByRats | ((ratD6 `mod` 2) == 1) = 0 | otherwise = bushelsBeforeRats `div` ratD6 bushelsHarvested = harvestYield * acresToPlant orders modify $ \s -&gt; s { food = food s + eatenByRats + bushelsHarvested } let calcDiedOfPlague :: Double -&gt; Int -&gt; Int calcDiedOfPlague r p = if r &gt;= 0.15 then 0 else p `div` 2 calcBorn r l b = 1 + ((r * (20 * l + b)) `div` (peopleInit * 100)) born &lt;- liftM3 calcBorn (useRandom (randomR (1, 6))) (gets land) (gets food) modify $ \s -&gt; s { people = people s + born } diedOfPlague &lt;- liftM2 calcDiedOfPlague (useRandom random) (gets people) modify $ killPeople diedOfPlague return Results { peopleStarved = starved, peopleDiedOfPlague = diedOfPlague, peopleBorn = born, bushelsEatenByRats = eatenByRats, bushelsPerAcre = harvestYield } readNum :: Int -&gt; Int -&gt; String -&gt; String -&gt; (GameState -&gt; Int -&gt; String) -&gt; StateT GameState (MaybeT IO) Int readNum maxN defaultN units purpose retryMsg = if maxN &lt;= 0 then return 0 else do val &lt;- gets $ validate . retryMsg lift . MaybeT $ readValidatedNum prompt val defaultN where prompt = "How many " ++ units ++ " do you wish to " ++ purpose ++ " (0-" ++ show maxN ++ ")? [" ++ show defaultN ++ "] " validate rMsg n | n &lt; 0 = Abort abortMessage | n &gt; maxN = Retry $ rMsg n ++ ". Now then," | otherwise = Accept n readOrders :: StateT GameState (MaybeT IO) Orders readOrders = do let thinkAgain = "Hammurabi: Think again. You have only " buyLandRetryMsg s = const $ thinkAgain ++ show (food s) ++ " bushels of grain" sellLandRetryMsg s = const $ thinkAgain ++ show (land s) ++ " acres" feedRetryMsg s = const $ thinkAgain ++ show (food s) ++ " bushels of grain" plantRetryMsg s n | n &gt; land s = thinkAgain ++ show (land s) ++ " acres" | n &gt; 2 * food s = thinkAgain ++ show (food s) ++ " bushels of grain" | n &gt; 10 * people s = "But you have only " ++ show (people s) ++ " people to tend the fields" maxBuyLand &lt;- (liftM2 div) (gets food) (gets landPrice) ((lift . lift . putStrLn) =&lt;&lt;) . gets $ ("Land is trading at " ++ ) . (++ " bushels per acre") . show . landPrice buyLand &lt;- readNum maxBuyLand 0 "acres" "buy" buyLandRetryMsg maxSellLand &lt;- if buyLand &gt; 0 then return 0 else gets land sellLand &lt;- readNum maxSellLand 0 "acres" "sell" sellLandRetryMsg let landDiff = buyLand - sellLand modify $ \state -&gt; state { land = land state + landDiff, food = food state - landPrice state * landDiff } maxFeed &lt;- gets food defaultFeed &lt;- gets $ min maxFeed . (* 20) . people feed &lt;- readNum maxFeed defaultFeed "bushels" "feed your people" feedRetryMsg modify $ \state -&gt; state { food = food state - feed } maxPlant &lt;- fmap minimum . sequence . map gets $ [land, (* 2) . food, (* 10) . people] plant &lt;- readNum maxPlant maxPlant "acres" "plant with seed" plantRetryMsg return $ Orders landDiff plant feed One interesting note: * Having record syntax produce changers and setters instead of just getters would be a big win. I'm also seeking advice on how to make this shorter :)
Thanks, geezusfreak. I'll be looking forward to that.
&gt; Having record syntax produce changers and setters instead of just getters would be a big win. http://hackage.haskell.org/package/data-accessor
awesome! I'll try to use it to further improve the solution later.
hmm, I'm glad I read that, I appear to be chairing a session
I don't see why not. Wouldn't be interpreted.
I'm pretty much none the wiser after that. Needs the audio, I think...
Arg.. you set my hopes high.. You currently need to manually define each accessor :(
Ah, sorry. :( It's still useful!
The page doesn't claim success yet, so I'm guessing that no - GHC on ARM is not yet working.
[xformat for Arch Linux](http://aur.archlinux.org/packages.php?ID=27527)
This is the number one reason I get frustrated reading other people's Haskell code.
It does way less. No logic at all in fact. And no multiple types of inputs and no multiple backends. But hey, if that's all you need, it might be slightly simpler to get started with.
Thanks, that's the impression I had, but I thought maybe I missed something.
Do you consider the template-haskell method manual? $(deriveAccessors ''MyStruct) 
I tried commenting on Seán's post on his blog, but blogspot ate my comment. Feh. I think his approach is cute, but in this day and age, a text formatting library should be sensitive to the needs of localisation, by at least allowing the location of an interpolated piece of text to be changed. I believe that his current approach will not allow this.
Why is it that the Haskell reddit so often provides exactly what I'm looking for, when I'm looking for it?!
I don't consider it haskell per se
Granted it's not Haskell98, but it's still Haskell. All you have to do is import Data.Accessor.Template and do something like the above $(deriveAccessors ''YourStructHere) call, and you get all your bidirectional accessors written for you. http://hackage.haskell.org/package/data-accessor-template It might not be built into [this revision of] the language, but I wouldn't characterize it as "manually defining each accessor". You just invoke the macro once per struct.
Agree. And there is no mention of QuickCheck in the slides...
I don't like the `transpose`: extremes = (maximum &amp;&amp;&amp; minimum) . foldr1 (zipWith (+))
no slides, no paper, no code and the talk was yesterday, are you trying to make us jeaoulus? edit: nevermind, I'm stupid and I parsed the wrong date.
I think a `:: Slides` tag is more useful than just `:: PDF`: both slides and papers take the form of a PDF, but one is useful and the other is just frustrating.
It's an announcement: &gt; Date: Tuesday, June 30th, 2009 &gt; &gt; Time: 10:30am - 11:30am
The talk is next week...
yeah, sorry about that.
I've parsed it like that too - the date on the blog is _too_ prominent. ;-)
Schwartzian transform?
&gt; we create an array from a list, which we build, in part, by looking up elements from the array we are in the process of building. lazyness is great
GADTs give me envy...
As a Haskell newbie it's nice to see other Haskell newbies post ways in which their naive approaches were changed to be more concise and powerful in Haskell. It helps in learning how to think in Haskell.
It should be something like: dsu :: Ord a =&gt; (b -&gt; a) -&gt; [b] -&gt; [b] dsu decorator = map second . sortBy (compare . first) . map ((,) . decorator) (feel free to correct me, I'm no Haskeller.)
Yup
I've always considered this approach rather hacky. What we really want is something like this: http://hackage.haskell.org/trac/hackage/ticket/215 Basically we make a special test section. It's much like an executable. e.g. test test-is: Test build-depends: QuickCheck hs-source-dirs: tests src 
I'm looking forward to trying out Happstack for my next small web app. I can't wait to have strong type-checking and pure functions in web development.
When you're just starting, Haskell has a way of looking really complicated for things you already know how to do in other languages. You have to think a lot to figure out how to make Haskell do the things you want to do. As you get better, you'll start to have some algorithms just slip right out of your brain and into the code. You'll start to think in Haskell and then the Haskell solution becomes natural, concise, and very powerful. 
As requested: dsu :: Ord a =&gt; (b -&gt; a) -&gt; [b] -&gt; [b] dsu decorator = map snd . sortBy (comparing fst) . map (decorator &amp;&amp;&amp; id) "compare . fst" doesn't quite work, because you need to apply fst to both arguments of compare: comparing :: Ord a =&gt; (b -&gt; a) -&gt; a -&gt; a -&gt; Ordering comparing f x y = compare (f x) (f y) (&amp;&amp;&amp;) is a nice combinator for applying two functions to a single value and returning a pair; it's defined in Control.Arrow but applies to regular functions as well: (&amp;&amp;&amp;) :: (a -&gt; b) -&gt; (a -&gt; c) -&gt; a -&gt; (b,c) (f &amp;&amp;&amp; g) x = (f x, g x) Also, you can use regular sort if you don't mind requiring Ord b as well; it will then compare the original element as a tiebreaker if two elements compare equal after decoration.
I thought we declared you an honorary Haskeller a few months ago, notfancy? If not, we should make it so =)
The nervous system of the communal brain...
Just remember that this sort of trick should be saved for cases when 1.) there's a measured performance problem and 2.) this is the cleanest and most effective optimization available.
You made me blush to the root of my hair!
&gt; "compare . fst" doesn't quite work, because you need to apply fst to both arguments of compare Of course you do! My bad.
Why decorator-sort-undecorator is better than simplest function: dsu' :: Ord a =&gt; ( b -&gt; a ) -&gt; [b] -&gt; [b] dsu' f = sortBy (comparing f) 
Actually it's not just an ordinary minesweeper game, it uses probabilities to figure out places for the mines, so there is no pre-generated map, it is generated dynamically on every player move. Really fun to play :)
Do you really think a Perl programming invented this technique? You can't be serious.
Did I say that?
That is covered in the original post. dsu can be more efficient because it only computes f once for each element of the list.
Is it worth having `sort . comparing == map snd . sortBy (comparing fst) . map . (&amp;&amp;&amp; id)` as a rewrite rule? (Although this does use more space than an ordinary sort) 
Oh.. I had no idea template-haskell is part of GHC. I thought it's something like hsc2hs where you need to run an external pre-processing script. Cool,
The proof is also at http://afp.sourceforge.net/entries/Stream-Fusion.shtml
Stigler's law is well-known. No such claim was made.
QuickCheck comes in from the Arbitrary and CoArbitrary instances mentioned.
dons should be interested in this.
Ah, maybe that's why he posted it on reddit :)
he manually posts all this stuff?
One wonders how he finds the time.
No, because in some case the cost of the computation of f is low enough that the Schwartzian transform is actually slower than the direct "sortBy . comparing" due to the space and pair building cost. At most, the schwartzian transform could be made into another sort function, like "sortOn" for instance.
you could use "compare `on` fst" though, this on combinator is actually quite useful in some cases. Of course comparing == (compare `on`).
I posted this because I haven't seen this paper referenced anywhere, but it makes effective use of parametricity in the spirit of Wadler's "Theorems for Free" to improve garbage collection by collecting parametric values. This has (minor) issues in Haskell, because you'd need to be careful about seq, but the approach is pretty nifty!
Truly, I would like to see the actual talk.
Scripts...
Hm, a quick peek at the results shows quite some substantial savings. The paper is quite old, though, and GHC uses fusion and inlining to remove a lot of garbage. I wonder how the number would look in that context.
Nice walkthrough that demonstrates a progression: 1. functions 2. monoids 3. functions 4. monads Yeah, it's wmv, but on Linux, we can $ totem mms://mschnlnine.wmod.llnwd.net/a1809/d1/ch9/0/Beckman_OnMonoids_NoFear_s_ch9.wmv
This would be great if jhc could compile any non-trivial programs. Perhaps there's been big improvements recently but last time I tried to build the Cabal lib I seem to remember getting stuck building basic libs like filepath, directory, process etc. It's rather frustrating, all the other cool jhc stuff is for naught without the ability to use it for basic programs (meaning H98 + FFI + standard libs).
Not sure. Some of these techniques (like the accessor application for fst (_,x) = x) are done on an ad hoc basis in GHC already. I tripped over this while I was exploring the tagless GC design space for other purposes. I would say that the amount of space required for type variable instantiation in its two-pass model could be burdensome. One option might be to simplify the model to use a less accurate unification model to reduce the impact of the # of type parameters on the space consumed during gc for unification of argument types. One more concern for using something like this in GHC is that this scheme doesn't address polymorphic recursion, which was the biggest bugaboo I was facing for my own tagless gc scheme anyways. There I had modeled this as storing a gc tag in constructors and stack frames that use polymorphic recursion.
This is a really decent description of what they are.... I remember watching this about one year ago.
Surely anything that uses FFI is out of the question for the JVM anyway? (Well, one might be able to do an FFI-JNI bridge of some sort, but the point of JVM is portability).