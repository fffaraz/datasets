Is there any difference between 'Pipes.Core.X' and 'Data.Void.Void'?
do you plan to offer a `Pipes.Prelude.Text` or `Pipes.Prelude.ByteString.Char8` as well? (in a separate package of course.) because you want pipes to be stable, you might think about renaming it to `Pipes.Prelude.String` (or similar) so that whenever text get's into base you can just use all the nice `Text`-interfaces in a `Pipes.Prelude`.
No difference. I just wanted to avoid the `void` dependency until Edward gets it into the Haskell platform because I also want to get `pipes` into the Haskell platform eventually. When that happens I will just replace it with: type X = Void
Any reason Bryan doesn't want to add this?
I just haven't gotten around to asking him yet. I have no idea if he plans to add it or not.
IMHO 'Void' more clearly explains the purpose than 'X', so if you don't want to add a dependency on 'void', use 'data Void' and later on re-export 'Data.Void.Void'?
Alright, I'll do that. Edit: Fixed and pushed to Github.
Fair enough. I confess on my first reading it came across as "Markdown is hard, and we can already do everything it can do anyways", which struck me as an odd position.
The linked version includes them: http://arxiv.org/pdf/1103.2841v1.pdf
Thanks, simon, for sharing! Is there also work on the thrift package yet to be released?
I used both Scala and F# quite extensively. I would pick F# over Scala if I was greenfielding and had to choose between them. Having done both pure functional and "mixed paradigm" development I don't believe mixed paradigm really exists. At best its OO with high level functions and maybe some type level features. We had much of this on C# in 2008 with Linq. It took me a long while to around to haskell and I don't believe in lazy by default but it is an excellent language for productive development. The reason to use Scala is to use libraries that run on the JVM.
PART 1: Greetings. I'd like to address some points pointed out here. Unfortunately I don't know how to reply to multiple replies. Also, if you want to reach me about this, the best way is to do through haskell-café as I don't use reddit (and would have totally missed it if not directly linked to). First of all, I'd like to note something: the OP post was written in respect to how Haddock is right now in the working state, on [my branch](https://github.com/Fuuzetsu/haddock/tree/pullbase). I'm mentioning this because some of the points might be coming from the ‘but Markdown has bold and Haddock doesn't and yet you say we gain nothing from Markdown!’ point of view. Bold is implemented on the branch I'm working on, as are quite a few other things. I hint that this is the case when I say that the post stemmed from me just writing a TODO when I actually sat down to implement the thing. I do ask that you don't build and use Haddock from this branch: the branch sees a lot of rebasing and squashing and interface file version changes frequently. You don't want docs generated by this out on your system. While I could just speak with Edward again on IRC about any more of his problems, it's a community project so it's better that it stays out in the open, somewhere more static. A lot of these will be ‘please open a Trac ticket’. I don't mean to come off as harsh or uncaring and I'm well aware that there are many age-old tickets but that's really the best way to get your desired feature considered. You can find the Haddock Trac [here](http://trac.haskell.org/haddock) and I encourage you to use it. Unfortunately the two maintainers, Simon and David are both rather busy people and it seems to be a recurring theme that some of the most used libraries in the Haskell community are those getting least developer love. Fortunately, I can help them out now, at least a little bit so the tickets should be seeing a bit more love. Replies: edwardkmett: &gt; I simply want some way to express the formatting. That could be &gt; embedded html fragments in callouts, embedded markdown under some &gt; markdown block incantation, pretty much anything! A lot of things fall under ‘formatting’. An example of what you'd like to do would be very, very helpful. The only two tickets on Trac with the word ‘formatting’ are closed. Please file a ticket. I know that you write a lot of documentation and you clearly have to jump through hoops to do what you want to do but if I can't see the ticket or a post on the mailing list, I can't fix it. Even today, I only caught the Haddock chatter on #haskell by pure chance, first thing that happened to be going on when I woke up. I would have totally missed it otherwise and you probably still wouldn't know about `&lt;url title&gt;` syntax. &gt; I'm willing to bend over backwards if I can get the functionality of &gt; decent documentation content on the hackage website. A Trac ticket will be plenty enough, thanks! acow: &gt; Indeed, so much of the reasoning here seems to be based on the &gt; impossibility of fully leveraging someone's familiarity with &gt; markdown. That was certainly the intention. As I mentioned [today on haskell-café](http://www.mail-archive.com/haskell-cafe@haskell.org/msg107738.html) in a reply the alternatives are either taking away features from the Markdown we would end up implementing, or spawning a bastard child of Markdown and Haddock which doesn't look that much different but with 5 times the quirks and unfamiliarity, be it to the Haddock or Markdown people. &gt; That is a fine goal, but it is not the only goal. That would be the &gt; icing on the actually-usable-markup-support cake. The icing didn't &gt; come out right, so now there is no cake? Who said there would be no cake? Haddock is seeing multiple improvements. The parser has been rewritten. As a consequence, now things like nested markup are possible. Long missing bold was added. Image alt text is now possible. Headers in function documentation are implemented (and Hoogle upstream contacted appropriately). For all back-ends. Multiple bugs squashed. Tens and tens of new unit tests. LaTeX back-end test framework set-up. Escaping markup is no longer arcane. You no longer have to have line breaks between same kind of lists. Extension to multi line markup is now trivial (one line change for anything we want to allow multi line for). URL auto linking is now implemented. The parser is now total. You should not get a parsing error from Haddock (report as a bug if you do) as it happened in the past. Heck, I was actually putting per-module [extension list support](http://fuuzetsu.co.uk/images/exts.png) until I got pinged on IRC, informing me of this reddit thread. I hope this is the cake you're looking for. If not, file tickets on Trac and maybe I can help you then. co_dan: &gt; And online version of haddock documentation is just so out of date Yes it is, there's no dispute over that. There's a very slightly more up-to-date documentation under the ‘doc’ subdirectory in Haddock sources that you can build. At the very least, it mentions the &lt;url title&gt; syntax. It still doesn't mention the image syntax nor does it point out any quirks. I hope you can hold out for a while. New documentation will be written, hopefully covering everything I listed above and more. Technically the coding period for this project ends on 16th (I think?) and GHC 7.8 comes out some time after ICFP so it shouldn't be long now. nicolast: &gt; IMHO several of the issues mentioned are easily solved by using ReST &gt; instead of Markdown. […] The reason why Markdown was chosen is simple: popularity. There were a few voices of reason, pushing for reST and Creole syntax (as I mention in the post) and perhaps they would be more suited. The main idea behind this whole alternate syntax shenanigans was to provide an already well-known method of documentation to large amount of people, without them having to learn Haddock markup. You might have the greatest syntax ever suited for what we do in Haddock but it doesn't mean much as an alternate syntax meant for a large amount of people, if large amount of people doesn't use it. It was pretty much a popularity contest in this respect. If you have to learn a new syntax anyway, just learn Haddock markup. Hopefully this will be much easier with many of the quirks gone. 
Author here... Yes, it's a Hungarian word unfortunately, because the project has much more humble beginnings. I thought that we will only ever use this to synchronize our emacs version between 3-4 machines and 2-3 people max. So we don't have to put conditionals into our dotemacs. I didn't thought it 2 months ago, that it will compile GHC itself. You can choose 32-bit or 64-bit without using VMs or chroots... So, back to pronunciation, it's the Hungarian word for Guild, and it's pronunced like the C programming language, but you can try to pronunce the h at the and a bit (it's not silent in Hungarian). So like the C language + a bit of an H. Sorry about that :)
Making `stdin` and `stdout` add and remove newlines seems arbitrary to me, especially when it's noted that the Text and ByteString versions will behave differently. Would it be better to rename them to something like `stdinLines`? Anything that shows they work on lines, not fixed-size chunks.
PART2: munificent: &gt; From my experience (I chose and implemented support for Markdown as &gt; the doc comment format for Dart) it's actually the case that 10 people &gt; want GitHub markdown. For reasons already mentioned, even if everyone actually wanted GitHub syntax, it's just not suited feature-wise for Haddock and in the end it would not look or feel like the GitHub Markdown at all. I would also absolutely hate to have to skimp out on new features/fixes in the future simply because I/other dev can't think of a good Markdown representation of it. Maintaining 2 distinct markup formats that are initially meant for different tasks would probably be a great burden. chrisdoner: &gt; I hate writing in Haddock syntax, but I don't do it often enough for &gt; this to be a big issue for me. It'd be nice to hear why. If it's the problem on Haddock end, please make your way to Trac, maybe your experience can be made better. sclv: Yes, indeed it is not a retreat from the proposal at all. The proposal is rather large and large chunk of time was spent on just getting a feel around, re-writing the parser, slowly working on other parts of the proposal. I'm not afraid to admit that some of the things on there might not make it in. I certainly hope to implement them and will try my best to do so (and it's not like I plan to just never touch Haddock again the second GSoC timeline ends) but I also have to acknowledge that there are limits to what can be done. As an example, Type Family support. It's a big deal, people want it, I want it, I hope to put it in. It's not easy to do however. Haddock is very tightly bound with GHC. Frankly, I'll probably have to amend the GHC lexer and parser to put this in. Changing a 5KLOC lexer + parser is not the easiest thing in the world, as you might imagine. Further, development is restricted to libraries available to GHC at compile time. That nice library you want to use for something? If it doesn't come with GHC boot libs, you're out of luck. The only exception is the test suite here as that's not ran when GHC compiles. Worse yet, we're even experiencing a bug from [the cabal side](https://github.com/haskell/cabal/issues/1266). Better yet, to even get the 1.18 running on GHC HEAD, you have to patch some libraries by hand. Of course you need GHC HEAD due to tight binding. If you need a GHC API change for whatever reason, be ready to file a GHC Trac ticket, wait a day or two and then recompile HEAD and all the libraries and tools you need to work with. I guess the point I'm making is that some features are much harder to implement than they look. In the meantime, I'm looking at things that aren't even mentioned on the proposal at all. If I see a bug, I have to fix it whether I like it or not. For this reason I can't say ‘Yep, XYZ feature will be in 100%’. I hope this is understandable. I'll most certainly try to get it in. edwardkmett (again): &gt; I confess on my first reading it came across as "Markdown is hard, &gt; and we can already do everything it can do anyways", which struck me &gt; as an odd position. I was afraid that it might sound as such which is why I actually took the time to target and reason about every feature Markdown offers. I confess that initially I was just going to give a brief explanation and do the rest of the discussion on the mailing lists but I decided against it in case it came off as a ‘it's too hard so lets make excuses’. I guess I failed. That's the end of the replies. Again, please, please, please use Haddock Trac. I will _not_ be able to help you if you briefly mention something you don't like on IRC, when I'm not on. It will be lost on me (and probably Simon and David too) forever, you'll be unhappy and we'll be oblivious. I would also be most greatful if you could express any questions or anything you disagree with about the post on the thread on café. For Haddock problems, please visit the Trac. To contact me personally, you can find my details [here](http://fuuzetsu.co.uk/contact.html). PS: Funnily enough, reddit seems to use yet another custom flavour of Markdown. PPS: Apparently I suck at formatting these posts so apologise any incoherent post structure. 
Yes, so actually I think it makes sense to set it up for your travis project even if GHC 7.6 is coming for Travis. It's not on the slides, but if you go for the travis URL: https://travis-ci.org/errge/thyme/builds/10734231, then you can see that the 32-bit is broken. And that is a real bug, thyme is really buggy on i686 currently (pull request already sent). Since the author is using amd64 for development and travis is 64-bit, it's not easy to find it. Of course it would be even better to test it on other architectures too, but 32-bit and 64-bit is already a big advantage compared to only one of them. Also, we will have 7.8 coming in October and I'm pretty sure that we will start seeing packages coming out for 7.8 and not for 7.6 in a year or so. This is where Nix (and therefore Ceh) excels, since it's separate from the system, it's a bit easier to keep it fresh or to even have multiple versions of the same library/compiler/program in it.
Alright, but that name is too long. If you want to rename it then it has to be something shorter.
`stdlin` and `stdlout`?
Thanks for the reply! I'll look into packing up the example when I get some spare time (unfortunately currently I have basically none :( ).
Just let me be the token adult here for a moment. You're "starting a rather large undertaking" and plan to use an experimental compiler? Come on guys, is there not one responsible programmer here that thinks this is a bad idea? Token adult says: before you start, take a look at TypeScript. People (not only the compiler authors) have built large projects with it. 100,000 LOC 3d game engine: http://hardcodeded.blogspot.jp/2013/02/mostly-painlessly-migrating-3d-game.html more real-world projects: http://typescript.codeplex.com/discussions/430577 
I like your confidence, and hope you'll deliver ;-)
The problem that Simon described in his talk has nothing to do with Applicative not being a super class of Monad. The problem is that the subset of monadically written expressions that can actually be expressed as Applicative notation can never be recognized as such. The function in bind disallows this observation. For Simon's use case this means that users may write code that could potentially be parallelized will still be sequential. Unfortunately there is no simple pure Haskell way to fix this. Simon's solution is to discourage people to write there own monadic abstractions by conveniently providing Applicative versions of sequence/mapM etc. My solution would probably be to not give a Monad instance at all and provide a specific bind called something like blockUntil.
I think the "open datatype" and "open function" ideas are what I was trying to wrap my head around. It is great to have it explained so clearly instead of spending many hours struggling to come up with my own half baked version. For now I'll probably try with the data constructors instead. If I start to feel it is not the right solution I can switch over to the open datatypes etc. The Channel 9 site seems like a great resource. Thanks for bringing it to my attention.
You are confusing the syntax and the model. When I speak of "elements" of an inductive type, that means elements of some structure that we call "inductive type". This structure may be a set, or a space, or a sheaf. In any case, the statement then is about the fact that the structure has only those elements that are obtained by using the constructors. In your example, the element denoted by 2+2 is equal to (not "definitionally equal" because we are talking about a model, not the sytnax) the element denoted by S(S(S(S 0)))).
You are of course forgetting the most important constraint which we always make when we say "inductive", namely that the structure satisfies an induction principle, or an initiality condition. Your suggestion that Zero be () and Succ be the identity function is invalid because it violates the relevant induction principle. And yes, you are missing the fact that you cannot add axiom which prevent you from having junk. Apart from some very limited cases (such as finite types), whatever your axioms are, there will be exotic models. There are very general theorems in logic that say so, and you will not be able to evade them. (NB: "there are no exotic elements" is not an axiom until you figure out how to state it precisely either as an axiom, axiom schema, or an inference rule -- and it turns out that once you do this, the general theorems kick in and defeat you.)
Have you considered checking out Helm[0]? It's really needs some more man power. :-) 0. https://github.com/z0w0/helm
Does it? Surely not. Since every `x : Nat` denotes `()`, then it satisfies the induction principle trivially: if `interp P ()` is true (which is contingent on `interp P`) and `forall x. interp P x -&gt; interp P x` is true (which is a tautology) then `forall x. interp P x` is true Obviously this is true, because the intermediate tautology is irrelevant, and the conclusion is just the abstracted version of the first premise, but since the variable `x` ranges over only `()` in the model, if the first premise is true, the conclusion is true.
Sorry. My bad.
I hope to someday help with this. Not that I can personally make a dent in the problem, but I'll try to do my little part. Right now, I don't feel experienced enough with any particular library to write authoritatively on it. That will eventually change. How easy is it to get documentation improvements accepted upstream, in general? I know this depends on the personality of the maintainers, but how's the culture, in general? Is there a culture of eagerly accepting improvements, or is it more like a turf battle?
http://hackage.haskell.org/package/plugins
could you explain that?
Note to down voter, I'd like to hear your rationale for using an experimental compiler for a large (what sounds like commercial) project, or are you also opposed to a balanced view?
I like FRP, but I'm trying to avoid experimental things like FRP and stick with technologies known to work that people are more used to. This is, after all, in the spirit of pygame.
Looks nice! I'm going to use this opportunity to gripe a little: This looks better than the Prelude's FilePath, but it's still stringly typed. The weak typing of FilePath has bitten me many times in the past. I would really appreciate a `FilePath` typeclass implemented by separate `AbsolutePath` and `RelativePath` types. [system-filepath](http://hackage.haskell.org/package/system-filepath) is a good start when it comes to strongly typed FilePaths, but I haven't found anything that lets me differentiate absolute and relative paths. Maybe I'll write one myself. /end rant. Anyway, if I can't have strongly typed FilePaths I appreciate fast ones. Nice work!
Like `LiveBackwards`, I recommend that you use `system-filepath` for `FilePath`s. I also recommend that for directory traversals you copy what my upcoming `dirstream` library does (or just use `dirstream` when it comes out). The benefits of `dirstream` is that you only traverse as much of the hierarchy as you actually need. Here is some example code to illustrate: {-# LANGUAGE OverloadedStrings #-} import Data.DirStream import Pipes import Pipes.Safe import qualified Pipes.Prelude as P main = runSafeT $ runEffect $ every (descendentOf "/") &gt;-&gt; P.take 3 &gt;-&gt; P.show &gt;-&gt; P.stdout That code prints out the first 3 directories of a recursive traversal: $ ./dir FilePath "/lost+found" FilePath "/root" FilePath "/mnt" This doesn't open any directories other than root, but if I remove the `take` then it will descend the entire directory hierarchy (eventually getting endlessly lost in the `/proc` directory). Also, like `posix-path`, the traversals are really fast. It also makes it much easier to define your own recursive traversals because it uses `ListT` done right. For example, here's how you define a traversal that only goes `n` directories deep: descend :: Int -&gt; FilePath -&gt; ListT (SafeT IO) FilePath descend 0 path = return path descend n path = do path' &lt;- childOf path isDir &lt;- liftIO (isDirectory path') if isDir then return path' &lt;|&gt; descend (n - 1) path' else return path' You can find the `dirstream` code here: https://github.com/Gabriel439/Haskell-DirStream-Library
There is a thing that has been bugging me about Pipes.Concurrent. I think it is good that it handles Input or Output being garbage collected but it does seem right that forcing a garbage collection is the only way to end the communication in a timely manner. This is mixing two quite different concerns that should be handled independently. I think it would be natural to have 2 extra functions to end the communication in a timely manner. An example could be: Input - endInput Output - endOutput They should have exactly the same function as the current finalizers. I hope I'm making sence.
Excellent! Thank you. This leads me to the next problem: this still fails: baz :: Category cat =&gt; cat a a qux :: Category cat =&gt; cat a a (baz, qux) = (id, id) With this error: Could not deduce (Category cat0) arising from the ambiguity check for `baz' from the context (Category cat) bound by the inferred type for `baz': Category cat =&gt; cat a a at Skolem.hs:17:1-21 The type variable `cat0' is ambiguous Possible fix: add a type signature that fixes these type variable(s) Note: there is a potential instance available: instance Category (-&gt;) -- Defined in `Control.Category' When checking that `baz' has the specified type `forall (cat :: * -&gt; * -&gt; *) a. Category cat =&gt; cat a a' Any idea what's going on there?
&gt; That's going to take some convincing Yeah, I'll agree that one is a little more out there. But I can kind of see something of an argument that with the same language it might get tricky to figure out what code is client-side and what is server-side. I'm sure there are other ways to solve that problem, but I thought the issue was worth at least a little thought.
Yeah, I can do that. Let me explain one thing first, though: the garbage collection behavior is not intrinsic to the `Input` or `Output` themselves and is only specific to `Input`s and `Output`s created with `spawn`. You can very easily define your own custom `Input`s and `Output`s which have nothing to do with garbage collection. So for that to work that means that you have to return the finalization actions as separate values from the `spawn` command (or a variation on it) like this: spawnExtra :: Buffer -&gt; IO (Input a, Output a, STM (), STM ()) ... where those two extra `STM` actions would be the `endInput` and `endOutput` actions that you are asking about. So yeah, I will add that to the API.
Prof. Ralf Lämmel* ;-)
Where's a good place to discuss issues and questions on using this? I'm running into some problems, which are most likely due to my newb status, and would like to discuss.
I don't care about backwards compatibility in this case. The main reason they are formulated that way is that I have a much more general application for them in mind than the one advertised in `pipes-concurrency`. I have to think if building in the end of input/output signal plays well with that more general application domain that I have in mind. If it does, then I will build that into the type. If not, then I will fall back on just adding a variation on `spawn` that returns the closing actions.
I copied and pasted his name direct from the Channel 9 page I linked because my keyboard is English, and doesn't have umlauts. Probably both versions are correct.
&gt; Like LiveBackwards, I recommend that you use `system-filepath` for `FilePaths`. There's just one problem with the `FilePath` type as it is currently implemented: lots of heap objects due to the use of `[Char]`, this is a significant overhead in terms of time and space... type Chunk = String type Directory = Chunk type Basename = Chunk type Extension = Chunk data Root = RootPosix | RootWindowsVolume Char | RootWindowsCurrentVolume deriving (Eq, Ord, Data, Typeable) data FilePath = FilePath { pathRoot :: Maybe Root , pathDirectories :: [Directory] , pathBasename :: Maybe Basename , pathExtensions :: [Extension] } deriving (Data, Typeable)
Just a few days ago i had to traverse and dump into database about 600,000 nested folders in several network shares. It was very slow, took 3 days. But it was a one time task, and i'm done for now. I wish i had this library then. 
You can reason about them, mostly, since it's read only. It's probably not transactional, though, and you'll have to `runHaxl :: Haxl a -&gt; IO a`. I agree it's a great pattern for server/client interfaces, though.
Then maybe we need to request that John Milikin changes the underlying type to `Text` or `ByteString`.
Since nobody else has asked: what's the likelihood of the core Haxl code being open sourced? The concept seems pretty applicable to a lot of situations, and it would be pretty neat to have such a killer library available from / supported by Facebook.
Alright, I just renamed them.
As far as I remember (been a while since I tried yi), the recompilation thingie does not work when you start yi from hsenv, because of a path issue.
You need type-level functions (google for TypeFamilies).
I know how to use type families, I just don't know how to get at a binary representation of the Nat at compile time.
Great!! I think these new names better convey the intent of such functions; they will be less confusing now. I updated [the documentation](http://monoid.k0001.org/haskell/Pipes/) to include this and the other recent changes.
Another potential related project: rewrite GHC's overlapping/non-exhaustive pattern checker. Right now, spurious warnings make working with view patterns very frustrating and there's also a host of related bugs. See http://ghc.haskell.org/trac/ghc/ticket/595 for details.
Is there any reason, beside educational purpose, to avoid [JuicyPixels](http://hackage.haskell.org/package/JuicyPixels) for PNG serialization?
The main reason was that JuicyPixels isn't currently on stackage as near as I can tell, so it isn't supported on the School of Haskell site and I had to roll my own. The second reason, which you managed to guess, was educational. I was thinking about reformulating the list based stream of automata into a Moore machine anyways, so this provided a nice way to do that exposition and spin it towards a constructive end. Then I found the `Comonad` while working on the PNG writer and the rest of the article wrote itself, switching me off my original intended topic to Moore machines.
If this could be done, the fact that one can draw from any data source, would allow something that uses this framework/tool to be added as a real-world Haskell benchmark. Any thoughts on that?
We are using overloaded strings. Some of the data sources have text-based APIs and we’re not going to use `String`!
We have talked about it. I expect it will happen in a few months as the project settles down a bit.
One could wonder if some ever get their own work done, given the sheer amount of time spent explaining things to newbies.
I do not believe that you can type these in Haskell. bazqux :: (Category c, Category d) =&gt; (c a a, d a a) bazqux = (id, id) baz = fst bazqux qux = snd bazqux `bazqux` has a dependency on two categories; but the type of `baz` and `qux` would hide one: there is no way for Haskell to understand that the hidden dependency can be safely ignored [*], or to choose a "random" one. It will also refuse `baz :: (Category c, Category d) =&gt; c a a` as we can't provide an explicit instance for `d` with this type. [*] Imagine that an hypothetic Category typeclass could contain: class Category c where ... liftCat :: Category d =&gt; d a b -&gt; c a b -- now `baz` "really" needs the other category (baz, _) = ((liftCat f) :: c a a, f) where f = (id :: d a a) --- What you can do however, is explicitly type `bazqux` so that the non-dependency is explicit (`-XImpredicativeTypes`): bazqux :: (forall a. Category c =&gt; c a a, forall a. Category d =&gt; d a a) 
Have you seen Max Bolingbroke's proposal at https://gist.github.com/anonymous/1194308? More discussion at http://www.haskell.org/pipermail/haskell-cafe/2011-September/093808.html
Sometimes my programs take a filepath as user input. Is it absolute or relative? Do I have to prepend the working directory? If I pass it to another function, does *it* need to attach it to the working directory? Standardizing things doesn't really work, because then my functions are brittle. (Are you supposed to call it with relpaths or abspaths? Can it handle both? Does every function need to handle both?) Every time that I run into these problems, I wish I had some sort of way to track the type of the filepath. If only Haskell had some way to track the types of values... Other cases where this comes up: - Whenever you get filepaths from a directory watcher. - Whenever you load files from a filepath. (Are the resulting files absolute or relative?) - Basically whenever you deal with the filesystem. This stuff is possible to track, but I shouldn't have to. If I do, I'll make mistakes. This sort of work is what type systems are for.
This looks fantastic. Great work.
The type theory alone is worth it. For example, say I'm running a bunch of scripts which will all be bundled together but which may not be installed globally. It's very nice to have a static check that I don't accidentally depend on something outside the "local root". Or, say I'm building up a bunch of different paths in my program. It's often nice to distinguish between incomplete paths which are still being built, vs those which have actually been anchored to the filesystem. Absolute and relative paths are different beasts and really should be distinguished; complete and incomplete paths are *really* different beasts and really must be kept distinct. We've had this discussion before over on the libraries list; just search the archive for more examples of why this three-way distinction (absolute complete, relative complete, incomplete) is a good idea.
posix-paths has no intention to add any type safety. It's purpose is to demonstrate a faster implementation that will hopefully end up in base. You could use posix-paths to implement the operations of a type safe file path library, but they are orthogonal.
Thanks! :)
7.8 will include a warning if you make a Monad without an Applicative instance. 7.10 will include Applicative as a superclass of Monad. That would put it around september of next year.
&gt; Also, like posix-path, the traversals are really fast. Did you benchmark this? I don't see anything in your dirstream code that would make it any faster than a directory traversal using `System.Directory.getDirectoryContents`. The extra time spent packing and unpacking Strings alone is significant. Changing `system-filepath` to use ByteStrings would make it faster, but still not as fast as `posix-paths` for directory traversals. When I [benchmarked your code](http://johnlato.github.io/posix-paths/pipes.html), it was almost 3x slower than the `getDirectoryContents` approach given in RWH, which is already painfully slow compared to other languages. It's about 30x slower than posix-paths. This was on a directory structure with c. 80k entries (a ghc-7.6.3 installation). I fail to see how you could consider the performance at all close.
Am I misintepreting (heh) what you said, or can I break your assumptions by building a `forall` that does not strictly preserve information?
The two notions collapse in the relevant categories, so yes, they're both inductive *and* co-inductive.
Your second statement (that `forall x. interp P x -&gt; interp P x` is true is a tautology) is fine with me, but I'm having trouble seeing why `interp P ()` implies `forall x. interp P x` in any system *including* those systems in which `v : forall x : singleton k. x` does not imply `v : k`.
I like this line: &gt;I want to write code that people would rather read and use than rewrite.
Can you port it to `ByteString` paths and see how the speed compares? Also, are you just traversing or are you also rendering the file paths?
I'm not sure what you're asking here -- your last bit of logic doesn't make any sense to me -- but, `interp P () -&gt; forall x. interp P x` because the only value for `x` is `()` itself, so it's trivially true because we already know that `interp P` holds of all the values of of the type. If we want to prove this with Agda we can: lemma : (P : ⊤ → Set) → P tt → ∀ x → P x lemma P p tt = p But it should be quite simple to see the intuition regardless. `interp P` *must* hold of every `x :: ()` because there's only one thing in `()`, namely, `() :: ()`, and we know that `interp P` holds of it.
But just because we know *externally to the theory* that `tt` is the only inhabitant of `⊤`, and despite the fact that, in Agda in particular, we also know that *internally*, there are some systems in which that knowledge is not available to us to actually use. In other words, this could very well be invalid (look at Haskell!): lemma : ∀ (P : ⊤ -&gt; Type) . P tt -&gt; (∀ (x : ⊤) . P x) lemma p = p You've basically just asserted what Andrej is attempting to disabuse everyone of. :)
But we're talking about the model that I chose -- where the denotation of the type `Nat` is the set unit set (which, for lack of a better symbol, I wrote as `()` but you could write as `|1` or whatever your preference) -- not the syntax. We know *about the model* that it satisfies an induction principle. Which is what Andrej was saying was necessary. So it's not sufficient to simply say "the model has to satisfy an induction principle" because that doesn't rule out boring trivial models like I gave. Also the point about Agda is that if we take Agda to be the model, then we'd have something like a type of internal types `Type`, where `Nat : Type` and `Nat` interprets down to Agda's unit type, etc.
It wasn't a request so much as just an idea, but thanks :). I didn't even know about the mailing list! Which means you were already getting a lot more feedback than I thought. (I was just stalking you on GitHub.)
I asked something similar recently, and the answer that concerns you is [this one](http://www.reddit.com/r/haskell/comments/1l7xdl/ghctypelits_modular_ints_and_fixed_size_vectors/cbwnbyl): it's a bit clumpy, but you can't do better with GHC's `Nat`s atm. But if you are using GHC.TypeLits, you should be able to use [Bool] (at the type level) instead of your old representation. To use `(:)` and `[]` at the type level, you must prefix them with single quotes.
...is there attention to be paid to when the hot-swapped/replaced code contains (modified) `data` type definitions and/or typeclass instances?
So, I've never used Catch, but probably the biggest blocker here IMO is: how do you display the error messages? Bad error reporting make features significantly more confusing and frustrating to use. I see no mention of it in the paper, mostly just core algorithms. That's not what we want! If you use GHC Core, you have 0 mapping back to the original source. We have no APIs or anything else to relate it back to the input module. So your errors are going to be really, really bad. Or you refactor the entire frontend to persist this information. GHC actually typechecks the parse tree during compilation, instead of any renamed/desugared version - precisely to give better error messages. After typechecking, you lose lots of info. But this stage isn't suitable for the work either: Catch is designed to work on *first-order* programs, and 100% of Haskell programs are higher-order, realistically. ~~Finally, Catch is actually quite a large codebase from what I can see - a couple thousand lines at least for the 'meat' of it (the actual `src` dir is about 12kLOC minus parser, but half of it could be stripped probably from a glance.)~~ Honestly? This is perhaps *too large* for a GSoC. At least using GHC. IMO, you're possibly better off using the `haskell-suite` when it's complete for this, complete with a typechecker. Then you can translate its output to a first-order form and feed it to Catch, without all of GHC weighing you down.
&gt; Can you port it to ByteString paths and see how the speed compares? I'm not very familiar with system-filepath, so I'm probably not the right person to do so. However, a straight port of system-filepath to ByteString would be likely be incorrect due to encoding issues (this doesn't really affect posix-paths because the posix API operates on char* already). Text is probably the correct internal representation. I'm rendering the filepaths to /dev/null, since it's a fairly accurate load for what I was interested in benchmarking. However, testing just the traversal is a good point, so I tried that too. For `posix-paths.traverseDirectory` printing accounts for ~20% of the runtime, for RWH's algorithm ~15%, and for `dirstream` it's ~30% of runtime. This means the performance differential for just traversing a directory structure is ~27x between `posix-paths` and `dirstream`.
Yay! (Also, because of you I spent all of today reading papers about comonads and even subjected someone to the pain of having me trying to explain them :p) 
Something that annoys me about School of Haskell is that code samples get truncated at the right margin, without any visual indication that anything is missing. (I am able to see that a type signature doesn't make sense, of course, or that a trailing `w` is supposed to start the `where` keyword and is not a type variable, but a beginner — who may be an accomplished imperative programmer but new to Haskell's syntax and all this relatively advanced type engineering — does not have that luxury.)
BTW, I suspect the interesting/clever bits of Catch are the firstifier (~1000 lines) and the solver (~300 lines). There is a lot of junk in there.
I would like to be able to quite large numbers (old system could handle numbers in the hundreds of thousands). &gt;If not it's possible but messy to implement a set of type families that will do the conversion, or at runtime using Rank-N types How do you do this?
To allow for more complex constraints you need to carry around a heterogeneous map of some sort in the environment. This can be done, and I've done it in solvers of my own, but you'll wind up needing more `unsafeCoerce` than you may be comfortable with at first!
&gt; perhaps because Haskell discourages this by putting catch and handle in IO, even though there's nothing impure or unsafe about them. Uhh, there's nothing unsafe about catch or handle, nobody's said otherwise, but it's definitely impure. What's the result of this expression? (throw ExA + throw ExB) `catch` (\ExA -&gt; 0) `catch` (\ExB -&gt; 1)
I'll get in contact with Skills Matter and let you know asap.
Okay, I've read through the article and the wikipedia page on effect systems slowly. let's see if I'm getting this right. When you evaluate a Haskell function, which must be ultimately triggered by IO, one of three things can happen. 1) you get the value, 2) an exception happens (e.g. sqrt (-1)) 3) nontermination. We're screwed in the general case with nontermination because of the halting problem, but it's sometimes possible to prove a function terminates. So the article is wishing Haskell had some way to say something like: aFunc :: (Total a, Total b) =&gt; a -&gt; a -&gt; b If the invented syntax is at all clear. The other case, exceptions, is more tractable. We know what sqrt will do when fed a negative number. We can also write: foo = undefined bar = error "I haven't implemented this yet, sorry." So they're also throw from Control.Exception that has type Exception e =&gt; e -&gt; a. I'm going to read that as "takes an exception and we might as well say it returns a value of any type suitable for whatever context because we'll never get there if that value is required." Basically, if we need the value of the a, we're screwed. So we could put something in the type signature to say these kinds of things could happen. So it could look like... foo :: Int -&gt; Int foo = --code that does not use undefined, errors, or throw. But if throw, undefined, or error is used, then we have to write (more invented syntax, "might" can be a keyword): foo :: Int -&gt; Int might undefined throw foo 0 = undefined foo 1 = throw "I never trusted the number 1" foo v = v Okay, lets see where this leads us. For a start, we can already do that kind of thing with Monads like Either or Maybe. foo :: Int -&gt; Either String Int foo 1 = Left "I never trusted the number 1" foo v = Right v And it works quite well thanks to do notation. We are forced to eventually handle errors, or at least make it very plain that we're being lazy or confident by using functions like fromJust. So we can do this, but Haskell doesn't force us to. It could make us write everything in something that resembled the Either Monad (an effect system, I assume). That's a design decision. It might get painful to clutter up all our type signitrues because we suddenly realised we needed to use a sqrt somewhere deep in the program. But does that effect the semantics by making some programs that would terminate fail to terminate? Maybe I need to think about this more? --- (The following edit was made before I say anvsdt's reply). Yes it certainly would because using a Monad introduces data dependences between formally intendant code paths. I get lpsmith's comment now. Haskell expressions are evaluated from the outside in. Hypothetically, let's invent a "catch" function that works in pure code. It's signiture is catch :: a -&gt; (e -&gt; a) -&gt; a. It instructs the runtime that, if a throw needs to be evaluated while computing the first argument, then the value of catch is the second argument, otherwise it is the first argument. e is what is passed to throw to create the exception. So what is the following: catch (show $ throw "Error 1" + throw "Error 2") (\e -&gt; "You're screwed, the following error occurred " ++ e) What is the result of this supposedly pure function? We can't really say. Either branch of the "+" could be evaluated first. They could even be sent to different processors. We can rewrite with Either: v = do v1 = Left "Error 1" v2 = Left "Error 2" return show (v1 + v2) case v of Left e = "You're screwed, the following error occurred " ++ e Right a = a And now we know what will happen, but we lost something doing this. The patten matching forces the expression evaluated more than it otherwise would be. Oh, here's another one: v = "The quick brown fox jumps over the lazy dog " ++ throw "End of the line, there's nothing more here." checked_v = catch v (\_ -&gt; "An error occurred") main = putStrLn $ take 2 checked_v Now that one is really weird. Is take 2 checked_v an Return Value ("Th") or an Throw Error ("An") in the language of the article? Clearly there's no sensible way to define what it should output. 
His problem isn't that Haskell does what it does, it's more that (some) Haskellers (in his opinion are) thinking that Haskell's design decisions wrt bottoms, exceptions and nontermination are necessary evils. &gt;It could make use write everything in something that resembled the Either Monad (an effect system, I assume). More like an internal support for certain Kleisli arrows, `a -(effect)-&gt; b` would be `a -&gt; effect b`, with `a -&gt; b` being a pure, total function from a to b. Then, yeah, throwing exceptions is like `a -&gt; Either theException b`.
Will the websockets library support Hybi13 once you finish porting it over to io-streams?
Creating a Selenium-like framework was indeed the first thing I thought too as soon as I saw the words "Controlling" and "Chromium". 
Appreciated, but it's not something you should have to worry about.
Sorry, I'm still very much a beginner with Haskell. Thank you for your responses. I feel like I'm learning things today :) Okay, so your notation here is a -(effect)-&gt; b is a function mapping an a to a b, where effect could happen. E.g. sqrt maps a Float to a Float but a DivByZero situation could occur. Okay, Kleisli Arrows. According to the haskell wiki &gt; A Kleisli arrow (Kleisli m a b) is the arrow (a -&gt; m b) for all monads. So if I write a function, sqrt :: Float -&gt; Either String Float then that is a "Kleisli arrow" because Either is a monad. I can use it with the Arrow library combinators if I wanted to because it is an arrow. It's also a Kleisli Either Float Float so I can use the additional runKleisli which would apparently give me a Float -&gt; Either String Float Oh, right, okay, that's just the thing that extracts the function from the wrapper. So: sqrt = runKleisli $ Kleisli sqrt So what's the point? Okay, right, I think what we're doing by wrapping them is saying "okay, we want to combine some functions together using the arrow library combinators". runKleisli isn't magical, it just says it's time to remove the wrapper and leave is with a nice a -&gt; m b function ready for use. So Haskell doesn't give us any syntactic sugar to help with handling errors this way. It could, but it doesn't. It's a design decision, not a law of nature. &gt;For example, some Haskellers consider definedness monotonicity a virtue rather than a weakness. (Inability to handle errors makes it easy to prove that your program doesn't recover from them, but hard to make the program do so!) In other words, if I pepper my code with throws then try to claim what I've written is sound because it type checks, I'm doing it wrong? The fact that Haskell lets me do this is a weakness not a strength? I think I'm getting this now. Thanks again.
Thanks for the input, Neil. I went through the users guide for Catch, and it makes a bit more sense now. I think the biggest part is still a bit of frontend work if we want to reasonably persist information across the first few stages of the compiler for error messages if we want anything more sophisticated like what Catch does today - it has the benefit of just using a parser directly as it stands. It's good to see the current existing implementation does have fairly reasonable errors however (although the fully qualified names make things difficult to read, but this is obviously very minor.)
Then I'm going to have to bug John to switch to `ByteString`/`Text` internally. Thanks for benchmarking that.
Unsafe seems a bit overloaded to me, as it seems it can be unsafe with respect to type safety, e.g. unsafeCoerce, or purity, e.g. unsafeInterleaveIO.
It's worth noting that the Text library has a rewrite rule that eliminates `pack` for string literals into a raw c-array at compile time, so there's no need to worry about it packing a bunch of linked lists on first run.
In what model of Haskell are they both inductive and co-inductive?
I see. Then I should clarify the first metatheorem in my post, namely that "is of the form S(S(...S 0))" is to be understood in terms of defintional equality. I will make the change, will that help? I am also curious, why do you find it productive to misinterpret theorems so that they are trivially false? Is it really that hard to guess that I meant definitional equality?
If you were referring to Rank-N types you just do the conversion at runtime... and the result of the conversion is passed to a continuation. Unlike using a type family, conversion functions like this need to carry around a constraint during conversion that allows something to be done with the result of the conversion. In this example I'm using `Typeable m` but the main thing to note is that all values (intermediate and terminal) need to be instances of the typeclass for this to compile. {-# LANGUAGE DataKinds #-} {-# LANGUAGE DeriveDataTypeable #-} {-# LANGUAGE KindSignatures #-} {-# LANGUAGE RankNTypes #-} {-# LANGUAGE ScopedTypeVariables #-} module Main where import Data.Typeable import GHC.TypeLits import System.Environment data D0 n deriving Typeable data D1 n deriving Typeable data D deriving Typeable data Proxy a = Proxy deriving Typeable re :: forall (n :: Nat) r . Sing n -&gt; (forall m . Typeable m =&gt; Proxy m -&gt; r) -&gt; r re n c = let next :: forall m . Typeable m =&gt; Bool -&gt; Proxy m -&gt; Integer -&gt; r next True m 0 = c m next _ _ j = case j `divMod` 2 of (q, 0) -&gt; next True (Proxy :: Proxy (D0 m)) q (q, 1) -&gt; next True (Proxy :: Proxy (D1 m)) q in next False (Proxy :: Proxy D) (fromSing n) main :: IO () main = do [arg] &lt;- getArgs print $ re (unsafeSingNat (read arg)) typeOf Basic example: *Main&gt; :main 0 Proxy (D0 D) *Main&gt; :main 1 Proxy (D1 D) *Main&gt; :main 0xFF Proxy (D1 (D1 (D1 (D1 (D1 (D1 (D1 (D1 D)))))))) *Main&gt; :main 0xFEED Proxy (D1 (D1 (D1 (D1 (D1 (D1 (D1 (D0 (D1 (D1 (D1 (D0 (D1 (D1 (D0 (D1 D)))))))))))))))) 
They wouldn't literally be sugar for in-language `a -&gt; m b` functions, it's like how Haskell functions `a -&gt; b` are `a -&gt; Partial b` functions in Agda, or procedures in imperative languages are `a -&gt; IO b` functions in Haskell. Effectful arrows `a -(eff)-&gt; b` would be built in, and maybe `eff` could be constrained some way to make effect more combinable (i.e., to avoid the problem monad transformers have, they don't commute in general, by the way this should be what the `Eff` type does in Idris). I don't know, it's an imaginary language I'm using as an example. The point is, Haskell still has some effects that are not part of the signature of a function, like nontermination and exceptions, and because of thatthe empty type is not empty. But when *all* the effects are expressed in types, in a way or another, then the empty type `forall a . () -&gt; a` *is* empty, because the equivalent of Haskell's "empty" type would then be `forall a . () -(Partial, Exception)-&gt; a`, which is inhabited by `const (fix id)` like in Haskell. The important part is that this is *inside the language*, it's not syntactic sugar like the `Kleisli` type is in Haskell. &gt;In other words, if I pepper my code with throws then try to claim what I've written is sound because it type checks, I'm doing it wrong? The fact that Haskell lets me do this is a weakness not a strength? Yep. The same argument Haskellers make against languages with lesser type systems can be applied to Haskell itself. It's not as bad, of course, but it still applies.
I think that's been available for ages, the problem is either you have to compile your own GHC, or GHC have to ship the whole-program information. There is a reasonable amount of engineering here which needs to be completed. If GHC had a -fwhole-program flag it would be great. Edit: I offer 5 beers to anyone who gets a usable whole program flag available in GHC as installed from the Windows installer.
 (throw ExA + fix id) `catchAll` 0
The only worthwhile thing in that exceedingly confused article is the link to "A semantics for imprecise exceptions" which in fact gets everything right that the article worries about.
That would still let you distinguish if an argument were used or not, which would break monotonicity.
The other thing this article misses is that we _can_ and _do_ reflect exceptional conditions in types, using the `Either` monad. Imprecise exceptions are a different beast, for when we want different behavior. And asynchronous exceptions, which are arguably the "point" of imprecise exceptions, are more complicated and tricky still.
While RebindableSyntax isn't that nice in itself (you may need to define/import other names as well), Fay uses this pragma combo to support Text literals without type classes. The compiler just spits out js strings instead of lists or doing a conversion. 
GHC segfaults should be reported on [the GHC bug tracker](http://ghc.haskell.org/trac/ghc/wiki/ReportABug).
The Glorious Glasgow Haskell Compilation System, version 7.4.1
Thanks, that makes sense.
Basically I have a data type which is parameterised by a Nat. data Modded (n :: Nat) a = Modded a It is easy to make `Modded` an instance of Num. The thing is, `Modded n a` is only an instance of `Fractional` when n is prime. I want to know if it is possible to do something like this: instance (Prime n, Integral a) =&gt; Fractional (Modded n a) I already have a way of doing it when I use single types (in a way similar to how it is done in the `dimensional` [library](http://hackage.haskell.org/packages/archive/numtype/1.0.1/doc/html/src/Numeric-NumType.html#NumType), but that makes much less clear type signatures. One option is to just make a `Fractional` instance for all n and make it a runtime error if you try to use a composite base.
Seems to work for me. Please create a ticket if you still experience the issue with the latest version.
GHC would be a great start, but plumbing some flags through Cabal might also be required - just something to bear in mind.
Woah, I didn't know so much has changed already. Thanks for your work :)
I notice await and yield are implemented in terms of request and respond, but those are only exported by Pipes.Core. Is it kosher to import that module and write bidirectional requests and responses, or do you intend to keep that out of the api? Also, with proxy transformers going away, what do you recommend as a replacement? Thank you for putting so much work into this library.
If you use the shelly library then every function provided should work with relative or absolute paths. The output of ls/find is relative to the given directory. This is how filesystem APIs should work by default. 
the shelly library handles most of the absolute/relative issues (see my other comment), but there is still the issue of the compiler not catching appending an absolute path to a relative one. The concept of an incomplete path is interesting, isn't it always a relative path? An absolute path would always correspond to a filesystem path unless you are waiting for your program to create it. For your bundled scripts, is it possible to use some named paths (much like how Cabal generates some named paths), or Template Haskell that verifies the existence of a path?
I just meant prof. instead of dr. but I was being pedantic. :-)
In the category of complete partial orders.
yeah, I was thinking the notation of the initial slash could define an ADT type using a fromString instance. But an ADT doesn't seem satisfactory for our use cases. Why can't we solve the issues with an incomplete path by modeling it as a function that creates a FilePath? 
As several others have pointed out, the gold standard right now is `system-filepath`, which provides a platform-independent high-level abstraction for file paths that are rendered to the correct native representation of paths on any specific platform. It's great that you have a faster implementation for Posix-style platforms. It would be really nice to get this integrated with system-filepath for those platforms. Why do you think this library should go into base? Is it because you know that path operations on Posix are a big enough bottleneck in GHC compilations that incorporating this library into base would yield a noticeable speed-up in compilations?
 Is this what you are thinking of, or something different? newtype RelPath = RelPath { unRelPath :: FilePath } newtype AbsPath = AbsPath { unAbsPath :: FilePath } data RelAbsPath = Relative RelPath | Absolute AbsPath instance fromString RelAbsPath where -- a begninning / is absolute class Path path where toAbs :: FilePath -&gt; path -&gt; FilePath toRel :: path -&gt; FilePath toFilePath :: path -&gt; FilePath So the shelly API generally looks like: shellFn :: RelAbs path =&gt; path -&gt; path And append is: (&lt;/&gt;) :: Path path =&gt; path -&gt; RelPath -&gt; path 
&gt; as long as you're willing to do some client side programming in JavaScript :3 
The rule of thumb is that for any given pipe you define you should either use only the unidirectional API or the bidirectional API and not mix both within the same function (but mixing both within the same module is okay). The `Pipes.Core` API is supported and blessed for bidirectional purposes. I'm planning on writing up a separate tutorial on School of Haskell for how to use bidirectional pipes and that will serve as a replacement for the old bidirectional tutorial.
I just updated it to run in parallel after a discussion with `haasn`.
Initiality isn't required for a model of Nat under any model theory I know of. Initiality is merely a requirement for *initial* models. But that's precisely what No Confusion gets you, which is why No Confusion is oft-mentioned in the literature as an option you can add so you can get nice, but unnecessary, properties. I'm going to be cheeky and refer you to Awodey and Bauer's Categorical Logic Notes, which you must certainly know intimately, where you say &gt; Actually, when computer scientists define a datatype like this, they have in mind a particular model of the theory, namely the free one. Which is precisely the point of what I said before -- there are plenty of models of it, but the ones we really want to think about are the free ones, the ones with No Confusion. Goguen and Burstall discuss this a lot in their work on institutions, and Sannella and Tarlecki built up an entire variant of ML around institutions in order to let programmers specify these different properties (No Confusion, No Junk) independently, and to take advantage of these, or the lack thereof, when desired. &gt; In sets is just so happens that induction together with the assertion that Succ is injective and that Zero is not a successor is But this is No Confusion, as I stated it before, only specified for naturals. Namely, forall x. interp Zero =/= interp Suc x &gt; The answer is: because simple induction does not allow you to prove that Nat is determined up to a canonical isomorphism, i.e., there are many non-isomorphic structures which all satisfy the simple induction principle. You discovered the singleton set. But it is easy to cook up more, for instance bool where Zero is false and Succ is fun _ =&gt; true. Yes, I believe I said that a few comments ago when I said that the unit type satisfied it, at least at the level of providing a witness, maybe not something satisfying those specific equations. Which was my whole point: you said the singleton set doesn't satisfy the induction principle, now you say it does. But what we *really* want is determination up to canonical isomorphism. What we *really* want is No Confusion. That cuts out all of the silly interpretations like the singleton, but leaves all of the "exotic" but useful interpretations like 1+|N. Which brings me back to my original question: didn't we already know this back in the 70s, at least?
&gt; Worse yet, we're even experiencing a [bug](https://github.com/haskell/cabal/issues/1266) from the cabal side. I'm not so sure that the issue linked is actually a Cabal bug. The problem can be reproduced even without using Cabal by trying to build documentation for a library that uses TH when Haddock is linked against a dynamic GHC. See my comments in that thread.
I personally would like to see this merged to the `unix` package, not base. I think the choice of `type FilePath = String` was poor and will continue to cause problems for Haskell programs. My biggest complaint with the `system-filepath` approach is that too much of the internal detail is abstracted out. If you need to interact with posix APIs or system libs, you can't do so with `system-filepath` without round-tripping through its internal representation. Even if it had a good internal representation, the round-trip would still be wasteful. For directory traversals, using `system-filepath` you first read an entry, converting from ByteString (system call) -&gt; String (ghc's API) -&gt; FilePath (internal rep). Then you stat that `FilePath`, going back to a ByteString rep. Then you perform some traversal logic, and eventually return the value (FilePath). Then to do anything with it, you need to eventually convert it back to at least a `String`. If you're serializing that value to JSON, you convert it back to a `ByteString` again. That's a **lot** of pointless churn, and it adds up to real cycles. Even if `system-filepath` had a more compact internal representation, it's still stuck going through the base API's `String`-typed functions. IMHO the real solution is for `base` to expose both a low-level, system-dependent filepath type and an abstract `FilePath` that's essentially a wrapper over the system-dependent type. Then that `FilePath` API would be consistent on all platforms, programmers could go into system-specific reps when necessary, and it would all work without any data conversions.
Thanks for bringing this up! I agree that memory usage is a very important consideration. `posix-paths` provides a few different traversal schemes for which the evaluation properties (e.g. laziness/strictness) are all documented. Perhaps you could point me to the parts that weren't clear for you? My `/usr/local` is a bit larger than yours (ghc itself is larger!), which I mentioned above. And on the github repo where I linked to benchmarks. Anyway, I would like to look at the memory performance. I like to use ghc's `-s` option to see the peak memory usage, because it ensures I won't miss anything between system monitor refreshes. Anyway, for folds `posix-paths` provides the `traverseDirectory` function. I tested a dircount written as: main = getArgs &gt;&gt;= traverseDirectory (\ (!x) _ -&gt; return $ x+1) 0 . BS.pack . head &gt;&gt;= print and got this: $ find /usr | wc -l 253598 time ./posix-paths-traversal /usr +RTS -s 253598 95,780,144 bytes allocated in the heap 163,392 bytes copied during GC 44,416 bytes maximum residency (2 sample(s)) 25,216 bytes maximum slop 1 MB total memory in use (0 MB lost due to fragmentation) ... real 0m0.219s user 0m0.068s sys 0m0.148s The "1 MB total memory in use" is consistent across multiple runs, in many different locations. So with `posix-paths` we can have both really fast filesystem operations and constant, low memory usage. I am sorry that you can't use `posix-paths` on OSX, but we're working on it and I hope that you'll be able to try it out soon.
Jhc compiler auther is John Meacham. http://repetae.net/computer/jhc/ Thinking his work is a magic, truly. I would like to understand his compiler pipeline.
Thank you John Meacham!! I wonder what are Ajhc's goals regarding real time programs: Could it be possible in the future to write *hard real-time software* using Ajhc? 
A segfault is **always** a bug.
Umm...no. (A)jhc has GC, and can't support HARD real-time. But John had thought region inference on jhc. https://github.com/ajhc/ajhc/blob/arafura/docs/announce/announce-0.7.3.txt#L45 Region inference on jhc is good idea or not? I don't know it. But John may know something... 
For those interested, there is also a section about Mandelbrot in Parallel and Concurrent Programming in Haskell, a mandelbrot set generator using Accelerate, http://chimera.labs.oreilly.com/books/1230000000929/ch06.html#sec_par-accel-mandel
Well, I am not really going to discuss things ad nauseam on reddit, we should just meet at a conference. In any case, we seem to agree more than disagree. But yes, of course this is old stuff, who ever said blog posts were original research? They are not even research, which is why I do not have a "referrences" section. There are all these generation Y's who seem to get their wisdom from blogs and reddit, so perhaps there is some benefit in writing little stories on blogs.
It is `genRooms 5000` that is causing the stack overflow, and I will show you how you can see this for yourself. Notice that when generating the list of rooms, `genRoom` forces every room in the list of rooms that is its argument. That means that when a later-generated `Room` is forced, it forces all earlier-generated `Room`s. You are putting the earlier-generated rooms on the front of the list that is the return value of `genRooms`, so as soon the first element is forced, it forces everything else. I speculate that the reason this consumes too much stack space is that the resulting evaluation of `genRoom` for the first element triggers a nested sequence of `genRoom`s for all the subsequent elements. This code may give you some hints about how to probe further import Control.DeepSeq (deepseq, NFData, rnf) instance NFData Room where main :: IO () main = do gen &lt;- newXorshift let g = evalRand (genRooms 50000) gen head g `deepseq` return () The quickest fix would be to increase your stack space: ghc -rtsopts test.hs ./test +RTS -K20M -RTS Otherwise you'll have to think harder about your control flow for this problem.
I wasn't really disagreeing, more, I was surprised that it needed to be said at all. Perhaps I should've been more direct about this: &gt; Apparently the following belief is widely spread What has given you this impression? Everything I've read on denotational semantics, including the categorical variety, eschews this entirely, even stuff that *you've* written. Or at least if the authors hold this belief, they never state it in the work itself. &gt; we should just meet at a conference If only a lowly linguistics grad student like me could afford to hang out with the real movers and shakers. :\ The best I've got is Reddit/IRC/Twitter.
The choice is entirely yours, I don't want to feel like I'm piling on - but seeing the prevailing pattern in the rest of the module of giving the names of `Prelude` functions to analogous `Pipe`s, I don't see why the resistance to doing the same for these two. They're practically the only ones left. The names `stdin` and `stdout` have a certain cachet and I empathize with that completely, but once you've already sullied them with the `Ln` suffix... might as well go all the way, and leave `stdin` and `stdout` for the `ByteString` and `Text` versions where they're more appropriate. Just IMHO. My other ideas are also no better than bikeshedding: - I liked `Pipeline` much better than `Effect`. - I think, in keeping with the renewed emphasis on the `Pipe`s aspect of `pipes`, that I might also like `BiPipe` better than `Proxy`. It would certainly look better inside of the `Pipes` module: when seeing it in a type signature, thinking "this is a more general form of `Pipe`" rather than "what's a `Proxy`?". (`Client` and `Server` can stay, no other name would be remotely as descriptive.) - I think there might be too many operators. The original `pipes` had two (not counting flipped versions), but they were minor variations of each other, reducing the cognitive burden, and I think that was about right. Now `Pipes` has three different ones, and `Pipes.Core` has even more. Symbols are a lot harder to understand than words, and each additional one should carry its weight. Where an operator is important for concision/prettiness I might complement it with a named equivalent (so you can at least know how to pronounce it), and in other cases I might suggest using a named function \`as\` an operator. These don't affect BC: - It might help comprehension to define more-specialized type synonyms in terms of immediately-less-specialized ones, rather than in terms of the most general one (`Proxy`/`BiPipe`). This could force choices between equivalent formulations (e.g. `Pipeline` in terms of `Producer` versus `Consumer`), but c'est la vie. - It might be helpful to somehow organize or group the equivalent type signatures offered up under some functions (even just separating them by newlines might have a positive effect), or possibly prune them. Currently the effect can be to get visually overwhelmed by the complexity of the `Proxy`-based signature, and then looking below, to get visually overwhelmed again by the mass of alternate signatures, which is probably not what was intended. Again, these are only ideas offered up for consideration! You're in a better position to judge their worth than I am. And these are just quibbles: I think the program of simplification for `4.0.0` and its execution are simply fantastic. Keep it up!
This is shaping up to be one helluva eXchange!
I guess that is what is at the heart of what I was trying to achieve. But I really want to wrap my head around the Haskell type system as throughly as possible. So I have been still trying to get it to work in way that doesn't side step the type system. I feel I have almost got it working by making more use of your Lens library. But I hit a bit of a problem. If I try to zoom on the same lens twice in one monad, each time returning a different type, the code doesn't compile. If I 'generate' the lens each time I need it the code does compile. I can't understand why this is the case. This code doesn't compile: http://lpaste.net/92505 But this does: http://lpaste.net/92504 Can you give me any insight? Edit: This works: http://lpaste.net/92506 I think it has to do with laziness, but I still don't understand why the first version doesn't work.
Hi Crandom. I've now spoken to Skills Matter and they can easily transfer the ticket to your name. Can you drop me an email at __MY_USERNAME__ @gmail.com and we can arrange payment and transferring the ticket.
`BiPipe` can be also rationalized as "a thing that's a `Pipe` and a `CoPipe`", just a thought.
Using the [] data type instead of Vector removed the problem with MUT_ARR_PTRS_FROZENs filling up the memory.
You can't, in general, represent unix file paths using Unicode code points. In the unix world a file path is a string of bytes. We're forced to use conventions to guess the encoding. For the same reason we shouldn't be using String either. Therefore, I think bytestring is the right choice. I do wish it could be text though.
I used hmatrix for a while, but I really needed sparse matrix algorithms. Unfortunately, the only library for those types was just starting out and lacking a lot of algorithms I needed (sparse SVD).
`Pipes.Prelude` doesn't have `stdin` and `stdout` any longer, if that's what you mean. I already renamed them and didn't keep the old names, preferring to leave `stdin` and `stdout` for `ByteString` and `Text` like you suggested. The problem with the `Pipeline` synonym is that the synonym only works if you arrived at it from using the `(&gt;-&gt;)` operator. There are several other ways to build an `Effect` where the `Pipeline` synonym does not make sense in that same context, like: lift :: m r -&gt; Pipeline m r for P.stdinLn (lift . print) :: Pipeline IO () The main reasons I chose `Proxy` is to use the very apt analogy to a networking proxy. I think more people will know what a networking proxy is than a bipipe. Also, it's consistent with the `Client` and `Server` synonyms. My choice for what to make operators in the unidirectional subset was that anything that was a proper composition operation in some category got to be an operator, and everything else was a named function. So three operators for three categories seems fine to me. For `Pipes.Core`, that leaves four operators which are not composition operators (i.e. `(+&gt;&gt;)`/`(&gt;&gt;~)`/`(//&gt;)`/`(&gt;\\)`). I kept them as operators mainly because I ran out of creative names. The other constraint was that the implementation of `Pipes.Core` had to be highly symmetric, even in terms of nomenclature, and it is very hard to do that with named functions. I'm a really big stickler for symmetry, down to the number of characters for function/operator names, especially in the `Pipes.Core` implementation. The reason the type synonyms are defined in the fully expanded form is for convenience in debugging type errors. For example, consider the type error example given at the bottom of the appendix of the tutorial: Couldn't match expected type `Void' with actual type `String' Expected type: Effect m0 r0 Actual type: Proxy Void () () String IO () The type error is inscrutable to most newcomers because it's because it is not obvious what the exact mismatch is until you fully expand the `Effect` type synonym. If I followed your suggestion the user would have to click through three type synonyms: (i.e. `Effect` -&gt; `Producer` -&gt; `Server`) to fully expand the type and take notes to remember which type variables each successive layer defined. It's already asking people a lot to even debug that type error at all, and I don't want to compound that by making it difficult for them to figure out what the fully expanded type of `Effect` actually is. I agree about grouping type signatures by lines. I did this in `Pipes.Core` and then somehow forgot to do it in the `Pipes` module. I will fix that right now. Edit: Oh wait, now I remember. The reason I left the ones in the `Pipes` module on a single line was to make it easier for users to see the connection between the simpler type signatures in the haddocks and the general type signature. That's why I left it on a single line. I have mixed feeling both ways, so I will think about this some more. Edit #2: I went ahead and put the type signatures on multiple lines anyway. It looks nicer.
Thanks for the explanations!
Slightly off topic but none of the samples in the site work on my Safari in iPad. The keyboard is not popping up when i tried to edit the code.
Thanks for the report, I'll try to it that sorted out. edit: It appears to be a bad interaction between CodeMirror and my code. It is slightly improved in Chrome for iOS, but stilll a bit weird. I don't think I'll succeed in debugging it today, but I'll keep trying :)
You're welcome!
Yes, I saw later that `traverseDirectory` would probably give the desirable result for this test, while `allDirectoryContents` was more like the RWH definition, except in having a much better way of interacting with the file system. But anyway I couldn't test it. It would be really nice to see this material integrated into the unix package; something like the pipes `dirstream` would be massively improved if it could take advantage of it, or if not, we would find out where some pipes bottlenecks are. (It would be similar for all the new-model io schemes of course) It is really nonsense when an attempt at close 'high performance' IO suddenly needs to use `System.Directory.getDirectoryContents :: String -&gt; IO [String]` and the like.
Try puffin browser
This is a confused blog post if I've ever seen one. &gt; But for negative proofs, it isn't really obvious how to do it. Since refutable propositions (allegedly) have no inhabitants, how do we write a pattern-matching function between them? There's no difficulty here. Under the assumption of some (false) statement P, you are tasked with constructing an element of _|_. You might whine "there is no such element", but that's because you didn't read carefully. It's not that there are no elements of _|_.... It's that there are no elements of _|_ *in a closed context*. (Of course, assuming consistency). That means that if you have an element of type x : _|_ just chilling in your context (that is, you have a variable x of type _|_ in scope), then you can just use that. Similarly, if you have a proof p : P and a proof q : ¬P together, you can generate the element q(p) : _|_. The key then is to realize that your assumption, the (false) statement P, must lead you to a situation like I just described. Here's a simple example: Code : Nat -&gt; Nat -&gt; Type Code 0 0 = Unit Code 0 (S n) = _|_ Code (S n) 0 = _|_ Code (S n) (S m) = Code n m lemma : Πxy. x = y -&gt; Code x y lemma x .x refl = unit ZeroNeOne : 0 = 1 -&gt; _|_ ZeroNeOne p = lemma 0 1 p That last line is tricky. Watch the types: lemma : Πxy. x = y -&gt; Code x y lemma 0 1 : 0 = 1 -&gt; Code 0 1 And then ask "what does `Code 0 1` evaluate to?
In terms of the in/complete path distinction, I'm thinking something more like: -- Aliases for exposition purposes only. type FileName = String type User = String -- N.B., incomplete paths must not be empty. data Incomplete = File FileName | Path Incomplete FileName data Anchor = Root | CWD | Home (Maybe User) -- N.B., complete paths are non-empty, because they're anchored. data Complete = Complete Anchor (Maybe Incomplete) -- N.B., it doesn't make sense to combine two @Complete@ paths. class Path p where (&lt;/&gt;) :: p -&gt; Incomplete -&gt; p instance Path Incomplete where p &lt;/&gt; File f = Path p f p &lt;/&gt; Path q f = Path (p &lt;/&gt; q) f instance Path Complete where Complete a Nothing &lt;/&gt; q = Complete a (Just q) Complete a (Just p) &lt;/&gt; q = Complete a (Just (p &lt;/&gt; q)) -- N.B., @Incomplete@ cannot be converted into a @FilePath@. toFilePath :: Complete -&gt; FilePath toFilePath (Complete a p) = anchor a ++ maybe "" path p where anchor Root = "/" anchor CWD = "./" anchor (Home u) = "~" ++ maybe "" id u ++ "/" path (File f) = f path (Path p f) = path p ++ "/" ++ f Of course, the actual implementation should be far more efficient than that (e.g., not using `String`; not having `path` be quadratic; etc). And the names of the types and data-constructors could be improved. And `toFilePath` should be cross-platform. Etc. But that's the basic idea. In order to handle the absolute/relative distinction for complete paths, we could convert `Anchor` into a data family, or parameterize `Complete` by the anchor type.
Not really on-topic, but does elm not have support for playing sound? It seems like games is a particularly well suited role for elm, so I figured sound support would show up early on.
This is a hilarious trick.
In Firefox on Linux I'm finding it jumps to the wrong place in the page (always the same wrong place, further down) whenever I interact with the text box. Great article and very cool demos, though!
As one of those "efficiency afficionados" I must say I never use `rnf` outside Criterion benchmarks. My philosophy is that if you should construct your data with the appropriate amount of evaluation, not sledgehammer it with `rnf` after you screwed up.
I wholeheartedly agree, but I've seen more than one codebase littered with them, so I wanted to at least give folks a jeweler's hammer to tap with rather than have them keep using a sledgehammer. =) In practice I try to force just the right things in the first place.
My experience in programming in strict languages with `lazy val` and the like is it is never enough to get the kind of algorithm reuse I want and any code that you want to make lazy is too ugly to maintain once you've converted it. Also, attempting to use monads in that sort of setting is a recipe for pain -- without proper support for tail call optimization non-trivial traversals blow the stack and/or require manual trampolining, reducing the ability to understand the code to a handful of experts. This bites users of F# and Scala on a fairly regular basis, and leads to the "FP isn't ready for prime time" mentality I see so commonly talked about in those cultures.
Nice, but it does replace one kind of overhead with another - more items to allocate and garbage-collect. I imagine it's still possible to abuse it. Also, it means other operations must tolerate those `Once` values, or else you must `runOnce` and remove them before calling those operations. In the latter case, if those operations return a structure containing parts of that previous structure, you may again end up needing to force a structure that is already mostly forced. I have no real experience to base this on, but I wonder if the real issue is that you shouldn't "spam `rnf` in your code" - that strictness should be targeted to a few key points, allowing the compiler the freedom to determine evaluation order in-between. That would also seem to fit with other optimisations such as deforestation - every time you force an expression, I suspect you're forcing a particular structure for the intermediate result and limiting the opportunities for the compiler to eliminate those intermediate structures. Is that sense or nonsense? 
You can fuse the `Once` notion into the surrounding data types more often than not, either implicitly via `{-# UNPACK #-}` or by explicitly duplicating the logic, so the overhead for the `Once` constructor goes away and becomes simply an extra member in the containing type, that reduces the overhead and pointer chasing quite a bit. The general usage pattern is that if you use this approach all the way down the syntax tree, you never have to 'force a structure that is already mostly forced', one level at most of unforced content is forced. If you skip levels then you get more flexibility about how you want to deal with forcing. That said, I strongly agree that you shouldn't spam `rnf` in your code!
Nothing easy jumps to mind, but it might be easier to encode the boundary rather than the cells.
It seems like this ties back into the fact that graphs (of the possibly cyclic variety) aren't clean to describe inductively, and our clean type solutions tend to be on nice inductive types.
Hm, I'm not sure `ThunkT` is what you want though. For example, `ThunkT Maybe a` is a strict `Just`/`Nothing`, but a lazy `a` which means in practice you'll have executed almost all the computation strictly just to find out whether it ends in `Just` or `Nothing`. In most cases that will have eaten almost all the laziness on `a` already.
I concur, algorithm reuse in strict languages sucks. Explicit thunking just doesn't help with this (unless you do it everywhere). 
This belongs as an appendix to DAS's 'Wat' talk.
I pointed out in the comments that you could write something like setMap with foldMap but to make it more container agnostic you needed to use the [pointed typeclass](http://hackage.haskell.org/package/pointed) foldedMap fn = foldMapOf folded (point . fn) There is probably a better name then foldedMap. According to Typeclassopedia however Pointed is not currently [considered idiomatic](http://www.haskell.org/haskellwiki/Typeclassopedia). [The explanation for why it fell out of favor is not very satisfying](http://www.haskell.org/haskellwiki/Why_not_Pointed%3F). It seems like a likely reason was that it was just one more instance to write without much benefit, but are there any other reasons it feel out of favor? 
I don't think this is nearly as "WTF" as [the reverse State monad version of Fibonacci](http://lukepalmer.wordpress.com/2008/08/10/mindfuck-the-reverse-state-monad/).
Is the () field essential? Is it superior to the following? newtype Once a = Once a once a = Once (rnf a `seq` a) instance NFData (Once a) where rnf (Once a) = a `seq` () edit: ah, the difference is laziness in runOnce, isn't it? With yours, it's possible to unwrap the a value without ever rnf'ing it.
# **Link Syntax Error** It looks like you got your link syntax backward. I tried to fix it for you! - [The explanation for why it fell out of favor is not very satisfying](http://www.haskell.org/haskellwiki/Why_not_Pointed%3F) ^Bot ^Comment ^- ^[ [^Brobot ^Stats](http://jordanthebrobot.com) ^] ^- ^[ [^Moderators ^FAQ](http://jordanthebrobot.com/moderators) ^] ^- ^[ [^haskell ^Control ^Panel](http://jordanthebrobot.com/r/haskell) ^]
Hey Tekmo, this looks like a much simpler API. Thanks for all the hard work! I do think that it might be a good idea to add a section in the documentation for pipes-safe that replaces the old "Upgrade Proxy Transformers" section. For instance, I'm using pipes-safe along with pipes-concurrency for the callback support, and it took me some digging to figure out that I could do `hoist liftBase $ fromInput input` in order to lift the `Producer' a IO ()` to `Producer' a (SafeT IO) ()` (frankly, I'm not even sure if this is the appropriate way to do this, or whether a version of `fromInput :: MonadIO m =&gt; Input a -&gt; Producer` a m ()` should be written). Then again, this might just be due to my lack of experience with mmorph and monad transformers...
Hi, I'm the guy in the video. A few "coming attractions" are mentioned in the video that I wanted to call to people's attention, as they are based on beta user feedback and are planned for the quite near future: - A personal-use (strictly non-commercial) edition that costs less - Support for other, non browser based text editors. We do already have key bindings selectable under your Account Settings page for vim and limited emacs, but The People Have Spoken. - Ability to deploy apps automatically onto your own machine(s), not just the Amazon cloud. In addition we're listening to requests for extensibility -- so if you are thinking you'd like to use extensibility hooks to customize or add to FPHC, let us know what you'd like to be able to do. Click the Feedback link on the IDE or the website, or email the 'support' alias, or PM me. Your feedback is how we know what to work on. Thanks! 
Actually, I was planning on generalizing it to `MonadIO` but I forgot about the functions in `pipes-concurrency`. Thanks for catching that. The reason I switched over the rest of the functions to use `MonadIO` was precisely because it gives better type inference in conjunction with `pipes-safe`. However, until I fix that the correct solution is `hoist liftIO (fromInput input)` or `liftBase` would work, too. Edit: I fixed it. You can use the new `MonadIO` versions if you pull in the latest changes.
It's because the `Pointed` type class has no laws that you can use to verify that you wrote a correct instance. With `Semigroups` you at least have an associativity law.
what does having an anchor of CWD mean if the CWD changes? It seems better to say it has no anchor and call it relative. I am also wondering how the Home anchor will play out, particularly since I could Root anchor a path that goes through a home directory.
If you find this stuff amusing, checkout http://augustss.blogspot.com/2009/02/more-basic-not-that-anybody-should-care.html It is pretty cool!
Just because `lens` does something doesn't automatically make it principled. I love `lens`, but I think that type classes like `Each` go too far.
You're welcome!
I personally tend not to use the rather absurd `each` lens, it is too DWIMmy even for me, but some folks really like it.
To be fair, that assessment is a bit of a simplification of my position. ;) A slightly less simplified version of my position is that Pointed has no useful laws and _almost_ all applications people point to for it are actually abuses of ad hoc relationships it happens to have for the instances it does offer. The one law `Pointed` offers is how it interoperates with fmap: fmap f . point = point . f but this is a free theorem of the type, so Pointed does not need Functor as a superclass, and now, unlike at the time of the original Typeclassopaedia when I first pushed Pointed on the community, it no longer has the superclass. Most usecases folks claim for it have to do with things like making sets of valus with constructions like 'foldMap point' but there we're relying on an ad hoc relationship because we happen to know what this does operationally for (Set a). At first blush one might think it generalizes. After all, if we substitute [a] then we get a list of all of the elements, right? But when you go to drop in Maybe all of a sudden we're getting Just the result of smashing together the results as a Monoid. or Nothing. Not anything at all sensible. Without knowing the concrete instances you're getting for Monoid and Pointed you know nothing about the behavior. The notion of a semigroupoid on the other hand gives you an associativity condition and can be used to drive many useful operations. You can 'foldMap1' a non-empty container with a semigroup. You can 'traverse1' a non-empty container with a mere Apply (semi-applicative) instance. You can use it to do interesting zip-like things to maps. Including Pointed in the hierarchy comes at a cost. Including the semiapplicative (Apply)/semimonad (Bind) tiers would come at a cost. If you fully fleshed out the lattice of them you'd indeed get some finer grained control over what you could do with the standard classes. For instance lens would be able to give real types to affine traversals given Pointed -- one of their few legitimate uses! However, this comes at the price that you no longer really get to define good mutual definitions for these things. The full lattice. 1.) Functor 2.) Pointed 3.) Functor + Pointed -- this is free theoremed, no class needed 4.) Functor =&gt; Apply -- associativity law 5.) Apply + Pointed =&gt; Applicative -- class needed, unit laws 6.) Apply =&gt; Bind -- inhabited by Map k, IntMap, etc. 7.) Bind + Pointed =&gt; Monad takes the user up to having to define 6 classes before breakfast just to get to Monad and back up to the functionality he had in 3 _lines_ before we started tinkering with his code. Worse, some of these tiers are uninhabited by methods, they merely offer laws. Laws that newer users may not understand are critical to the correctness of their code, and which won't be pushed on them when they get a bag of constraints out of the typechecker. So the user can silently introduce code that relies on constraints it hasn't put properly on the type. There is also an understandable undercurrent in the community that having to deal with so many classes would be a bad idea. So this leads us to consider either a.) default superclass systems that can try to take some pain out or b.) removing layers from our über-system of classes. No extant default superclass proposal deals well with complex lattices, due to multiple candidate default definitions conflicting. So we try to focus on a few good abstractions, rather than capturing them all. Pointed has a bad power to weight ratio and induces people to write code they can't reason about. Or you can just say "people were whinging” =)
&gt; We're screwed in the general case with nontermination because of the halting problem, but it's sometimes possible to prove a function terminates. So the article is wishing Haskell had some way to say something like: &gt; aFunc :: (Total a, Total b) =&gt; a -&gt; a -&gt; b &gt; If the invented syntax is at all clear. Well, as I understand it (and please somebody correct me if I'm wrong), it's certainly possible to treat nontermination as a monadic effect: 1. Do not allow recursive function or type definitions, or any other pure construct that can express the `fix :: (a -&gt; a) -&gt; a` operation. Such a pure fragment would be guaranteed to always terminate; see, e.g., [System F](https://en.wikipedia.org/wiki/System_F). 2. Provide a `Fix` monad, with the operation `mfix :: (a -&gt; m a) -&gt; m a`. (See [`Control.Monad.Fix`](http://www.haskell.org/ghc/docs/7.6.2/html/libraries/base/Control-Monad-Fix.html).) Now the evaluation of a term with a type like `Int` would always terminate, but a term with type `Fix Int` might not.
I thought I had check for that thanks for pointing it out.
Thanks for the expanded explanation, somehow I suspected there was more reason/evidence behind the move to semigroupoids. I have copied this post to to the wiki, with minimal formatting, so other will benefit as well hopefully.
They have an occasional contest where the goal is to write the strangest code possible for a given challenge.
If you want to delay the constructor then it's `ThunkT (MaybeT Thunk) a`. (Sure it looks messy! :) )
&gt; programming in strict languages with lazy val and the like Do you mean just Scala and F# here, or are there other languages you'd include as well? &gt; attempting to use monads in that sort of setting is a recipe for pain -- without proper support for tail call optimization non-trivial traversals blow the stack and/or require manual trampolining Interesting. Can you give an example?
In your example if you `rnf` twice the structure `a` is walked twice. In edwardkmett's example it is only walked once.
Thanks for taking the time for such a complex answer. It makes a lot more sense now. I found a better solution was to hide the lens inside the VarStore module and give the propagators a simpler interface to update variable state. If I finish the solver (hopefully in the next day or two) I will put it on git hub and post again.
Heh, you're right, good catch. :)
Do you have any references to the type/frequency of times this bites F# or Scala users? Also Scala seems to be in a slightly different category, not having tail call optimization (or at least not provided by the JVM as far as I recall?).
ASCII is totally an encoding. Perhaps you should argue for only including UTF8 encoding/decoding support.
Is this true in Mu? If so, how do you deal with it?
These videos have little value, unfortunately, as you can't read the screen. 
Mu has the same reuse problem as (e.g.) ML, and we deal with it in the same way. I.e., we don't. You can still get a fair amout of reuse in a strict language, but anything relying on some kind of short-circuit evaluation is not going to behave well.
Scala has only "self-tail calls", but the way they `flatMap` is necessarily two functions mutually recursing at best, so their lack of proper tail call optimization means that if you have a `Monad`, and go to traverse a list, it'll just stack overflow if the list has more than a few thousand elements unless you take apart the Monad and rebuild it in trampolined form. I worked through how to do the trampolining with Runar Oli Bjarnason a couple of years back and we put it in `scalaz`, but compared to the "identity" monad it can slow your code down by a factor of 50x because the JVM is terrible about optimizing it. In F# the situation is a bit better on this front, but worse on others. The lack of higher kinded polymorphism just means I can't write almost any of my Haskell libraries in F#. You can `inline` away some of the problems... right up until you need recursion.
Set up scalaz, grab the basic State monad, traverse a list of 5000 elements, enjoy your stack trace.
Thoughts: 1.) `iso id id` can be replaced with `id`. `id` is an `Equality`, which is stronger and cheaper than an `Iso`. 2.) The main problem there is that it forces you to pay for all of the list constructors during the traversal of say a ByteString or Text, whereas with `each` we can go through and use the fact that we're monomorphically traversing `Word8` or `Char` to be vastly more efficient. 3.) There is already a universal translation from any `Traversal` to a `Traversable`. We call it `magma`. It even supports type changing assignment. The output data type happens to be `Traversable`, and you can make multiple passes over it before turning it back into the modified data type. The implementation of `magma` is terrifying, but we only had to write it once. 4.) For reading or just manipulating the elements of a traversal you can aready convert all of the items to a list by using `partsOf each`. 5.) We do have a lot of ad hoc classes like the ones supplying Data.ByteString.Lens's packedChars and packedBytes. We have heretofore avoided unifying them explicitly because in the case of, say, ByteString we wanted both packedChars and packedBytes, while in Data.Text.Lens we wanted just the packed Chars. **tl;dr** Basically, `magma` is a universal version of `isoTraversable`. *protip:* It is also useful for debugging the shape of a Traversal via its show instance. *P.S.* `imagma` generalizes this to work with any indexed `Traversal` 
Yeah, `Once` just acts as a shield preventing rnf'ing its contents twice from causing another `rnf`, it doesn't mean that you always want it to be in normal form.
Just to check I understand what you're saying: 1. The same applies to strict lists in Haskell, doesn't it? For example I got a stack overflow when trying to sequence a strict list of 5 million elements, where the data type is defined like this: data List a = Nil | Cons a !(List a) deriving Show 2. Presumably a Scala lazy list would not cause a stack overflow when sequenced, would it? 
 import Control.Applicative import Data.Foldable import Data.Traversable data List a = Nil | Cons a !(List a) deriving (Eq,Ord,Show,Read) range :: Int -&gt; Int -&gt; List Int range i j | i &lt;= j = i `Cons` range (i + 1) j | otherwise = Nil instance Functor List where fmap = fmapDefault instance Foldable List where foldMap = foldMapDefault instance Traversable List where traverse f Nil = pure Nil traverse f (Cons a as) = Cons &lt;$&gt; f a &lt;*&gt; traverse f as I can `traverse Just (range 1 100000)` in Haskell just fine. If you go to do the same thing using Scala with the obvious `Maybe` monad `(Option[_])` you stack overflow. I'm not talking about the list as a monad being crippled by strictness, I'm talking about trying to traverse any sort of traversable container with any other monad being crippled by strictness.
You can't `traverse Just (range 1 (10 * 1000 * 1000)))` in Haskell though. But is this a different issue to the one you're talking about?
With a GADT it is not usually possible to write a `Functor` instance because of the `fmap id = id` law; but it is frequently possible and desirable to write a pmap where `pmap f . pmap g = pmap (f. g)` and so on. In such a context, `pmap f . point = point . f` is a perfectly good law associated with a frequently highly desirable concept, this would be clearer if it were named, e.g. `lit` instead of `point`
a would not be "walked" more than once with my implementation, but it would be seq'd more than once — just like Kmett's unit field. So I think the only operational drawback here (beyond Kmett's comment below) is that you get pointer tagging with (), but you wouldn't get it if a has too many constructors. How that balances with the decrease in allocation is probably case-by-case.
I don't understand. How can it be seq'd more than once but only walked once? A large lazy datastructure is walked every time it's seq'd, in general.
Nope! The `seq` only forces whnf. The fact that you're `seq`ing the explicit `rnf a` is what forces the full walk, and that only happens once. The problem with the above is you _always_ get the `rnf`, instead of being able to choose to avoid it.
Different issue. The scala one happens even with a lazy list.
Sure. I'd likely just bundle them into the surrounding data type though.
I find that very counterintuitive. Shouldn't Scala's equivalent of runState return after yielding the first element?
 traverse f (Cons a as) = Cons &lt;$&gt; f a &lt;*&gt; traverse f as is building up a huge pile of flatMaps (&lt;*&gt;'s in this case) recursively on the right. In scala this means that you wind up mutually recursing between traverse and the flatMap for your Monad, which is precisely what they can't optimize. To work around this you can trampoline, but in practice I write monadic code in scala by actually not using monads at all! -- by instead plumbing implicits that carry mutable variables because they run 10-100x faster, have no issues and result in succinct code. Plus I can use the built-in `foreach` sugar. It just makes any use of a `lazy val` that captures them treacherous, so I have to weld myself completely to the strict framework to use that approach.
What do you do with data created by a library?
Wow! You nailed it!
But can't you `traverse` an infinite lazy list in Scala? Are you just saying this would be slow, not that it would blow the stack?
No, I'm saying you can't do it at all. It doesn't even have to be infinite or lazy, just big. It'll blow the stack because `traverse` and your `flatMap` will mutually recurse to death. The only way to traverse a `Stream` in Scala is to trampoline your monad. This means ripping apart your monad and rebuilding it with a different base functor. The 'fundamental' version of the `State` monad `(s -&gt; (a, s))` is broken in Scala for this usecase! You need to instead switch to a trampoline, which is the [free monad of Function0](https://github.com/scalaz/scalaz/blob/scalaz-seven/core/src/main/scala/scalaz/Free.scala#L23), this makes it so you can pattern match on what to do next in such a way that interpreting it can move the stack off to the heap. This means that you are instead working in State[S,A] = Function1[S,Free[Function0,(S,A)]] otherwise your `State` monad will just die with enough right associated binds, which any version of `traverse` that is generic in the monad will necessarily induce!
Ah right. Is this the same as saying that Scala's version of the `State` monad is too strict, somehow? I shall have to go away and think harder about this so I understand it properly. Thanks Edward.
Oh hang on. I just had a brainwave. When you `runState` in a strict language you get the final state out straight away. It's not a thunk. That means all the state computation had to happen at once, and unless you took care not to push onto the stack at each bind you're going to stack overflow. I hope I'm beginning to understand something :)
Wait, it's worse than that. When you `runState` all your binds must be done at once, and if they are naive function calls then they're going to stack overflow. It's got nothing to do with the type of the traversible, just its size. It's to do with the naive definition of `State` being the wrong one in a strict language. OK, I am getting it :)
If you wait a bit they do zoom in.
Acme-c?
&gt; The only way to traverse a Stream in Scala is to trampoline your monad. This means ripping apart your monad and rebuilding it with a different base functor. Is it not enough to use StateT with Cont as the base monad? I was bitten by the lack of tail call elimination writing a monads lib in Clojure but that seems to take care of it (though one shouldn't have to decide in advance whether or not to do that): user&gt; (s/run-state (m/lift-m last (u/map-m (comp m/return inc) (range 1000000))) :my-state) StackOverflowError monads.types.Return (types.clj:65) user&gt; (c/run-cont (s/run-state-t (s/t c/m) (m/lift-m last (u/map-m (comp m/return inc) (range 1000000))) :my-state)) #&lt;Pair [1000000 :my-state]&gt; 
&gt; No extant default superclass proposal deals well with complex lattices, due to multiple candidate default definitions conflicting. It's not obvious to me why this has to be the case. Is there a collection of proposals somewhere I can browse?
Thanks. The team has really come together and I'm so happy with everyone's work. The UI is built primarily in Fay. Gregg Lebovitz is planning to give a talk at ICFP/CUFP later this month talking about how we built the whole thing.
There's an [Eclipse plugin](http://eclipsefp.github.io/). I haven't used it but I've seen it recommended so I assume it's good. Also see [the HaskellWiki page on IDEs](http://www.haskell.org/haskellwiki/IDEs).
Coming from the other direction, what would a strict language have to do to make these less painful? Full TCO? Would sibling call optimization be helpful?
Many people use their favorite source code editor (vimacs, TextMate, Notepad++ ...) and manually load files into GHCi. It works great for me.
I've never used Parsec before and I've never heard of `between`, but its definition [1] seems unnecessarily specialised to `ParsecT` when it seems like it ought to be a perfectly simple `Applicative` combinator. [1] http://hackage.haskell.org/packages/archive/parsec/latest/doc/html/src/Text-Parsec-Combinator.html#between
 between :: Applicative f =&gt; f a -&gt; f b -&gt; f c -&gt; f c between a b c = a *&gt; c &lt;* b I'm not sure, but Parsec ([introductory paper from 2001](http://legacy.cs.uu.nl/daan/download/parsec/parsec.pdf)) may be older than Applicative ([introductory paper from 2008](http://www.soi.city.ac.uk/~ross/papers/Applicative.pdf)), which would explain the unnecessary specialization. That'd also explain why Parsec defines its own `&lt;|&gt;`, rather than just using the definition from Alternative.
If sibling call is that you can deforest pairs of calls it'll help but not eliminate the problem. Full TCO helps more, but strictly more programs terminate under non-strict evaluation than strict, so there is a limit to how much it can help.
That looks like a regexp done in parsec. Why not go further and parse IP and date to make a record with meaningful fields?
If you are able to grok haskell, you are more than able to grok emacs or vim. Furthermore, learning how to efficiently use a proper text editor is one of the biggest and best investments a programmer can make.
That's all good and dandy, but you are asking too much from a novice. Especially considering that haskell already have a very steep learning curve. Adding to it emacs or vim is just cruel :) I am using emacs to write haskell code on linux. 
Consider class Functor f =&gt; Comonad f where fmap = liftW class Functor f =&gt; Monad f where fmap = liftM which one wins when f is both a Monad and a Comonad? 
Also, IIRC Scala Cont still blows the stack.
I could not readily find the academic license option. Any idea when this would become available? Great work btw. Keep it up.
We have been using the release candidate for a week now, and it is great. I don't have to remember to use cabal-dev instead of cabal, I just has to type `cabal sandbox init` once. This is going to be truly revolutionary for Haskell: new users are actually going to be able to install stuff! Please start using this version and its sandbox feature and spread the word. This is the biggest improvement for new users of Haskell that I know of since starting using Haskell. 
Thank you. We are going to be rolling out the free academic license in the next week or so.
For hosted IDE + cloud deployment features, that's the commercial license price, yes. We'll also be coming out with much cheaper personal (strictly non-commercial use) licenses shortly, and $0 academic licenses. 
This will probably make me look stupid, but can someone explain how and why this works? 
&gt; what does having an anchor of CWD mean if the CWD changes? The `CWD` anchor always means the cwd as defined by the operating system. Naturally, this means the extrinsic interpretation of `CWD` will vary depending on context; but that's not our fault, those semantics are inherited from the OS. &gt; It seems better to say it has no anchor and call it relative. Paths which are anchored to cwd are, by definition, relative paths— but, again, these relative paths should not be confused with incomplete paths. Relative paths are anchored to the cwd. The fact that the cwd can vary based on `IO` is neither here nor there; relative paths are still anchored. In contrast, incomplete paths are not anchored— not even to someplace that varies depending on context. To put it another way, consider the distinction between vectors and points in space. **If and only if** our space has a unique point designated as the origin, then it is possible to construct an isomorphism between points and vectors; consequently, many people fail to distinguish them. However, it becomes obvious that they're different concepts once we remove the notion of there being an origin. A point in space is just that: a point. Points are just locations in space, they're not going anywhere, and if we decided to designate a new origin then the points would stay wherever they are. In contrast, vectors are fundamentally represented by *two* points, the difference between which gives rise to both a direction and a magnitude. Thus, vectors are always going somewhere, they're not stationary, they're paths not locations, and if we're representing a vector by its non-origin point then choosing to designate a new origin will change all those vectors[1]. [1] I.e., assume `(0,0)` is the originally designated origin. We can represent the vector `((0,0),(1,1))` by the point `(1,1)` since we can implicitly assume the vector is anchored at the origin. However, if we designate a new origin like `(2,3)` then the vector represented by `(1,1)` is now `((2,3),(1,1)) == ((0,0),(-1,-2)) /= ((0,0),(1,1))`.
Thanks for the feedback. I agree that "catches all errors" should be changed -- I'll follow up on that right now. Your second point appears to be a joke, as I assume you know what we mean here. I'm going to think about your third point -- the challenge here is basically one of how to communicate concisely yet accurately. We'll try to do better. 
Let's explicitly define heap objects by `x := e` where `x` is a heap location and `e` is some data. And let's explicitly annotate thunks by using `~`. Thus, if we have the heap `{x := ~(1+1)}` and we force `x`, we will end up with the new heap `{x := 2}`. And let's make the pattern matching of `rnf` explicit: rnf x = case x of Once y _ -&gt; case y of () -&gt; () * Start with the heap `{a := ~(...); x := ~(once a)}`. * Now suppose we force the expression `(rnf x)`. * Now we must force the expression `(case x of Once y _ -&gt; ...)` * Now we must force `x`, resulting in the new heap `{a := ~(...); x := Once ~(rnf a) a}`. * Pattern matching gives us the new heap `{a := ~(...); x := Once y a; y := ~(rnf a)}`. * Now we must force the expression `(case y of () -&gt; ())` * Now we must force `y`, resulting in the new heap `{a := (...); x := Once y a; y := ()}` where we've traversed all of `a` in order to force it. * Now `y` drops out of scope and we're left with `{a := (...); x := Once () a}`. * Now, suppose we force the expression `(rnf x)` a second time. * We must force the outer case expression, so we must force `x`, but `x` is already in WHNF, so we immediately get the heap `{a := (...); x := Once y a; y := ()}`. * Now we must force the inner case expression, so we must force `y`, but `y` is already in WHNF, so we don't do anything. Hopefully that makes sense...
I'm so glad to see ghci support come so quickly!
Finally! sandboxes are now widespread.
There is always: http://www.haskell.org/haskellwiki/GHC/AdvancedOverlap A modern version would use equality constraints instead of TypeCast ... I think. 
As chris suggested, translating the posted code into an Applicative style and adding a few combinators condenses the code quite a bit, without sacrificing readability. valueBetween:: Char -&gt; Char -&gt; Parser String valueBetween o c = between (char o) (char c) (many $ noneOf [c]) plainV, bracketedV, quotedV, finalQuote :: Parser String plainV = many1 (noneOf " \n") &lt;* space bracketedV = valueBetween '[' ']' &lt;* space quotedV = valueBetween '"' '"' &lt;* space finalQuote = valueBetween '"' '"' logLine :: Parser LogLine logLine = do ip &lt;- plainV ident &lt;- plainV user &lt;- plainV date &lt;- bracketedV req &lt;- quotedV status &lt;- plainV bytes &lt;- plainV ref &lt;- quotedV ua &lt;- finalQuote return $ LogLine ip ident user date req status bytes ref ua 
Haskell is easier to reason about than either Emacs or VIm.
Only if they are implemented legally. That doesn't help you once you start building up things like monoids out of semigroups and selected values, groups, loops, etc and you wind up with O( 2^n ) points below you on a lattice of features with many different possible default definitions, and parametricity isn't enough to save you there. You'd want them all to be the same but many times they'll have very different operational flavor, some may be the right ones to pick given the other explicit definitions you've given. Consider Monad. If join was part of Monad then join+fmap+return is a full definition, but return+(&gt;&gt;=) are sufficient to define join+fmap+liftW. If you use liftW for fmap though, then you'd better choose to define the Monad through return+(&gt;&gt;=) or you'll just silently get a bottom! Similarly on the Comonad side. Bringing in more definitions by default introduces many many more similar opportunities, especially when there are several candidate definitions being supplied by subclasses and no clear selection criterion by which one can choose between them. Superclass instances are a nice idea, but there are real issues with implementing them in a way where they provide a net benefit and actually enable complex class hierarchies like they are intended to.
I've never seen that before and I'm on the site quite regularly. Interesting.
Beautiful exposition
Lennart made a blog post years ago about the difficulty in achieving this kind of abstraction in Haskell. http://augustss.blogspot.com/2008/12/somewhat-failed-adventure-in-haskell.html
I don't understand how you're defining a function literal, I haven't heard the term before. It seems to me that your `x`s and `n`s are not function literals. `length $ return length` might suit your needs. No brackets, and the 'length' at the end could really be almost anything else. 
&gt; new users are actually going to be able to install stuff! As a new user I can tell you that new users have no idea that they shouldn't just `cabal install` anything they need.
You can condense `logLine` further: logLine :: Parser LogLine logLine = Logline &lt;$&gt; plainV &lt;*&gt; plainV &lt;*&gt; plainV &lt;*&gt; bracketedV &lt;*&gt; quotedV &lt;*&gt; plainV &lt;*&gt; plainV &lt;*&gt; quotedV &lt;*&gt; finalQuote
Fixed.
Well someone had to say it: try FP Haskell Center at www.fpcomplete.com -- it's a full Haskell IDE in your browser!
Up to this point there weren't much of an alternative (unless you use some third-party solution, like cabal-dev). Now we have a much better story for new users (run `cabal sandbox init` and then hack away).
Great explanation, Thank you! :)
Here's an implementation like the one jfischoff pointed to. {-# LANGUAGE TypeFamilies, DataKinds, … #-} type family IsIndexable f :: 'Bool class Searchable f where search :: Ord a =&gt; f a -&gt; a -&gt; Bool instance SearchableHelper f (IsIndexable f) =&gt; Searchable f where search = searchHelper (Proxy :: Proxy (IsIndexable f)) class SearchableHelper f p where searchHelper :: Ord a =&gt; Proxy p -&gt; f a -&gt; a -&gt; Bool instance Indexable f =&gt; SearchableHelper f 'True where searchHelper _ = -- uses binary search instance SearchableHelper f 'False where searchHelper _ = -- uses linear search The key issue becomes defining instances of IsIndexable. For example: type instance IsIndexable UnOrderedArray = False type instance IsIndexable OrderedArray = True instance Indexable OrderedArray where … Feel free to ask for further explanation. There may be other encodings more suitable to your use case. I haven't yet looked at the current details of Richard Eisenberg's implementation of overlapping type family instances, but it possibly could help here.
It uses its own &lt;|&gt; for precedence reasons.
Exactly. Less line noise and perfectly follows the structure of your data type.
Thanks. As far as I can see, the fix is in the development repository only. Will there be a new release of cabal-install soon? Otherwise, downloading the latest tarball from hackage and running bootstrap.sh will still fail.
It happened to me lately with Java. My only suggestion is as naive as effective: deal with the fact you are coding in C++. The only way to be effective with a language is to completely embrace the language idioms and best practices. So forget about FP, and do the converse: exactly as experienced functional programmers told us to perform a mind shift and to embrace the new paradigm, you need to do the same in the following direction. Everything will buried under silly 100-layers of indirection, everything is a "Proxy" or a "Translator" or a "Wrapper" or just another name for put-here-your-design-pattern-of-choice. Put up with it. Then pick a good book like Meyer/Alexandrescu's ones, even better "Accelerated C++" or "C++ for impatient" and try to enforce the style contained in it. At the end of the day, clients do care about software and a problem being solved, they are much less enthusiast about the technology. As long as it works, they are happy. Even more, if the project is shipped on time. So take this bitter mouthful and carry on :)
That is true. I think I am talking about trampolining. Which doesn't bridge the non-strict versus strict evaluation gap (does it?), but works around limited stack space. Is there a straight correspondence between "how much" TCO you have and how much trampolining you can avoid, i.e. full TCO means you don't need to trampoline at all and more restricted forms of it remove the need in the restricted cases and not others, or is it more involved than that? (ISTR sibling calling optimization can be done when the callee function is known, i.e. you're not going through function pointers, but the [LLVM docs][1] don't explicitly say that.) [1]: http://llvm.org/docs/CodeGenerator.html#sibling-call-optimization
I was hoping so badly that you'd end that with a "just kidding, this is a library that will help you out". Come on, FP is **so simple**. Just give me high order functions and lists and I'm done. How a language can suck so bad that you can't have that!?
Are you able to use c++11?
The following should work: $ cd /path/to/Cabal $ runghc Setup.hs configure &amp;&amp; runghc Setup.hs build &amp;&amp; runghc Setup.hs install $ cd /path/to/cabal-install $ sh bootstrap.sh
Ok that makes sense thanks
Hmm, this is pretty much what `bootstrap.sh` normally does anyway. Restoring that to where it was is probably a good thing over all. They may be waiting for a few days to see if there are any other small bugs in 1.18.0 before releasing a bugfix, 1.18.0.1 or something like that.
I'm not a C++ programmer by any means, but what about boost::lambda? Lists are supported by the STL anyway as far as I know. Haskell lists are not much different from ordinary linked lists.
You know people like [The Sealed Knot](http://www.thesealedknot.org.uk/)? Or folks who spend their weekend grinding wheat in lovingly recreated windmills so they can bake their own bread from beginning to end? You have to get into that mindset. It's not the most advanced way to do it but maybe that extra time devoted to the task can be form of meditation.
This is why I never touch C++ any more if I can possibly help it -- it's just completely the wrong level of abstraction. I have a hierarchy of languages, unfortunately haven't yet managed to work Haskell into the tower, currently it seems to be (in decreasing order of abstraction): 1. bash (yes, seriously, first choice for the right jobs) 2. Python 3. C 4. System Verilog (my little joke, is true at the moment though). Of course, Haskell belongs in there, probably between Python and C, but haven't found the opportunity for it yet.
I'm not sure if this will help or hinder http://bartoszmilewski.com/2009/10/21/what-does-haskell-have-to-do-with-c/ http://bartoszmilewski.com/2011/07/11/monads-in-c/ Higher order function of course are already prevalent in C++ (std::algorithm) of course the syntax is horrible and you don't get currying or partial evaluation for free 
https://gist.github.com/j4/6448010 - Is it a good simple example ?
C++ code can be beautiful in its own way. I felt like you when I realised my problem was that I was trying to enforce Haskell idioms in a language that isn't Haskell. What helped me was reading lots of idiomatic and beautiful C (in my case) code and learning to appreciate the C kind of beauty. It helped having a C programmer by my side to ask him, "How would you solve this?" Most of the time, his solutions were much clearer and simpler than my hackery. TL;DR: Are you sure C++ is at fault and not you? (By trying to use the wrong idioms.)
Have you tried template metaprogramming? I hear it's supposed to be almost identical to Haskell.
Been there. Countless times. [This abomination](https://bitbucket.org/tdammers/f) is the result of the most recent episode.
C++ (even pre-11) has higher-order functions in the form of what OOP folks call 'functors' (although they have nothing to do with FP functors). Even C can do higher-order function stuff with function pointers. And lists? Part of STL, or if you really have to, implement your own cons list primitives. So, in short, you *can* do it; whether it's a good idea is a different question.
Might not be exactly what you're looking for, nor is it quite release ready, but it might at least be interesting for you to have a look at [FTL](https://github.com/beark/ftl). It is more or less a re-implementation of a number of Haskell libraries and features in C++, such as you mentioned yourself.
Gave me the fuzzies, as well as a distinctly acidic taste in my mouth. Wonderful!
I would replace Python with Haskell, actually. 
I think your problem isn't so much your functional programming knowledge as a tendency towards being an [architecture astronaut](http://www.joelonsoftware.com/articles/fog0000000018.html), or a tendency towards the [inner platform effect](http://thedailywtf.com/Articles/The_Inner-Platform_Effect.aspx). I have those tendencies too. The reason - it's more fun that doing what you should be doing. But as good as it is when your job is fun, the real point is getting the job done. 
`#include &lt;algorithm&gt;`
&lt;rant&gt;Why is this function returning -1 on error instead of using `Maybe`? Why is this argument accepting only three possible values is an unsigned integer and not using at least a strongly-typed enum? Why `fopen` takes a `const char*` for its mode? Why am I wasting my life to write `if (system_call() == -1) { /* do something with errno */ }` for every function when `(&gt;&gt;=)` does the plumbing nicely? Why I cannot write this function in pointless style? Why are references in closure mutable and make me cringe every time I see it? Why this so useful map built into language can only have `string`s as keys? Why am I trying to implement sum types using `union`, a tag integer and `switch`? Why there is no pattern matching and I have to write a visitor instead? Why there is no `STM`? Why the author of this library doesn't seem to understand RAII? Why this function's behavior depends on a global variable which is also modified by hundreds of other functions? Why didn't the compiler slap me in the face when I accidentally passed a `String` as an `Int` and instead think that when I say "foo" it actually means 0? Why am I recursing over this data structure and there is no general `traverse` for that? Why is everything so stringly-typed? Why am I trying to become a human type checker by writing unit tests? Why this programs doesn't have an option to output structured data and instead I have to parse human-readable text with `awk` and someone thinks it is funny to alter the output after a month so that my carefully constructed regex breaks? Why is the compiler perfectly fine with `strlen` forking a process to call `launchMissiles` and building a skynet AND ARRRRRRRRRGGGGGHHH emoragequit!&lt;/rant&gt; Sometimes I'm afraid I'm no longer able to work as a normal programmer anymore. :(
Wouldn't interoperate very well with my colleagues, but yes, the right level of abstraction ... and there is a Python binding I did that's quite widely used that maybe I should also write in Haskell. A nice project for a rainy day (well, month, really) perhaps.
Also don't forget `#include &lt;numeric&gt;` for `fold` (`std::accumulate`), `scan` (`std::partial_sum`) and `zipWith` (`std::inner_product`). :)
I suggest that you go and live in a yurt far away from technology for a little while until FP takes over the world. At which point you emerge triumphant, shed your robes and rejoin the workforce.
Write Haskell to generate the C++!
It looks really great if you have not yet been spoiled with emacs or vi!
So I guess you could say that GHC knows how to delay evaluation really, really efficiently :)
&gt;bash (yes, seriously, first choice for the right jobs) No, sh is the right choice for those jobs. Adding unnecessary reliance on GNUisms is bad.
Good thought. I'm addicted to a handful of bashisms though. Actually, sometimes find myself targeting the busybox sh, in which case I have to wean myself off.
That reminds me of a library I wrote before I knew haskell. I used things like ForIterator and used &lt;algorithm&gt; and &lt;numeric&gt; to simulate lists and the list functions of haskell. I also had Strong, which is like newtype. [Link](https://bitbucket.org/bennofs/geomlib/src/c6fc5b7fd0c5b4481d920d514429a9aea94c01aa/Util.hpp?at=master)
Gentlemen we have arrived.
I think not being able to write two Haskell programs on the same computer without risking breakages sounds like a good idea to discourage users (specially new ones) from global installs.
We will make another release before GHC 7.8, which will ship after ICFP. This gives the new release a little more baking time so we can fix any other bugs that pop up.
I don't mean to imply there is no use for sandboxing, just that the long standing meme that "cabal is broken and you can't use it and everything always explodes so you have to use cabal-dev but really just don't use haskell" isn't accurate.
The signature is the same as `fmap`. I made up a name `pmap`, but one writes `pmaps` for GADTs all the time. Take the most trivial case: data Pointy x where Point :: x -&gt; Pointy x Number :: Int -&gt; Pointy Int a Functor instance is impossible; in this simple case, anything with the type of `fmap` will clearly have to return something with the `Point` constructor. pmap f (Number n) = Point (f n) pmap f (Point x) = Point (f x) Almost every GADT of kind `* -&gt; *` is like this. `pmap id` is idempotent, -- `pmap id = pmap id . pmap id` and in general `pmap f . pmap id = pmap f`, `pmap id . pmap f = pmap f` and so on, and, crucially, `pmap f . pmap g = pmap (f.g)`. But `pmap id (Number 3) = Point 3` thus `pmap id /= id` . I have named the constructors to bring out the substantive character of `pmap f . Point = Point . f` which is secured by the second line of the definition. This phenomenon is omnipresent among GADTs of kind `* -&gt; *`. If you add a constructor that is aware of the identity of a type to any existing type realizing the Functor class, you will immediately write a `pmap` and are likely to have or write a `point` -- both functions subject to powerful laws. The `fmap id = id` rule is thus much more constraining than it seems; the mathematical importance of the nominally equivalent rule arises from the fact that the functors one contemplates are typically from one category to another; in the bread and butter case one is precisely attempting to escape one complicated category in order to measure it by another, simpler one. Haskell's `Functor` of course does not express this concept but something several degrees more specialized, and can be viewed as specializing more than one thing. The `id` on the two sides of `fmap id = id` is avowedly the same `id`, which introduces a number of curiosities. The tiresome no laws/free theorem argument against a `Pointed` class thus is just a reflection of a prior arbitrary decision not to make some sort of Semigroupish class of (`*-&gt;*`) things with `fmap/pmap` as a superclass of `Functor`. This may or may not be a reasonable decision, but it is a decision pure and simple, like all these tower-of-superclass decisions; if the decision had gone the other way, as it might have if GADTs were more widely used, then the 'free theorem-no laws' argument would be more visibly captious. 
C does have a kind of beautiful purity to it though. If Haskell is the penultimate abstract programming language, then C is the ultimate explicit programming language. Haskell let's you state exactly the problem you want solved, and how to solve it, declaratively. C lets you tell the machine exactly what you want it to do with no magic or hidden behaviors; it's just you and the machine, pure.
I wouldn't say C is the machine, as it is rather far removed nowadays. It is also by no means explicit. There is quite a bit of undefined and awkward behavior in the language that varies from compiler to compiler. It is also often impossible to express your intent in the language and so it must be annotated heavily with documentation.
He should use this time to become some sort of FP Gandalf. He leaves as Gandalf the imperative and returns as Gandalf the functional and leads his army to defeat Saur-Oracle (Sunron...?).
I just have a list of languages I want to learn/use...: Haskell, C, Python, Lisp (either SBCL or Chicken Scheme), Perl Edit: I think I'll add Prolog as well.
I assume this is a joke, but if it was for realz, I'd say you never really understood C++, moreover you failed to learn the FP lesson. What you should have said is: I've done Haskell for a while and when I went back to C++ it felt like I used a different (better) language! (FTFY)
Cabal sandboxing is great, but how can we integrate it with tools like ghc-mod or hdevtools? Apparently ghc-mod has no (as expected) idea of the packages installed inside the sandbox :(
I think assembly language fits that description better than C.
have you tried turning it off and on again?
[This](https://github.com/bennofs/hdevtools) hdevtools fork has cabal &amp; sandbox support, although it may be a little buggy sometimes. You can also pass "-package-db .cabal-sandbox/x86_64-linux-ghc-7.6.3-packages.conf.d/" (replace x86_64... with the right directory)
Any up to date docs? In particular I have always been confused about integrating test suites into Cabal. The manual says something about PureTestable but I can't find that anywhere in current Haddocks (though it is in older Haddocks.) The method that seems simple and usable (exitcode-stdio-1.0) is apparently deprecated. So far my reaction to all this has been to throw my hands up and just make my tests a regular executable.
Thanks, I'll take a look! 
Iavor and I were working on a library for sized vectors, etc, using Type Nat. See git@github.com:ku-fpg/sized-types.git, type-nat branch for the current status. It is complete but not well tested. Kansas Lava uses it. 
I've been using [this fork](https://github.com/supki/ghc-mod/commit/726c2400fb47c7caf08d123c5d868c5d92a0cada) of ghc-mod for a while. I had to do a little symlinking in my sandbox directory, but it's working out.
Many of those are still flaws of C++: * No sum types to properly model errors * No STM * Weak typing in certain cases * No compiler-enforced purity
C is the most portable language that approximates that ideal
I'm having the same problem in university, did a several months F# gig and now I have to code in Java... Kill me pls
I also always miss the "types as documentation" in C++. I think Haskell libraries have a much better documentation. 
I'm waiting for @dcoutts to upload the new user guide (I don't have access to the machine). `exitcode-stdio-1.0` is not deprecated! We expect that the `detailed` test interface will give us better integration in the future (because cabal will know exactly which tests failed etc), but for now the `exitcode-stdio` interface is the way to go (together with test-framework).
The lack of sum types in particular makes me super sad because lots of other languages from the same time as C and C++ already had support for variant records or similar concepts. Too bad those got forgotten when OO became more popular.
As stated, your problem has no solutions.
a.k.a. Oleg the Continual
"They let you write output from *any* ol' function??? How obscene!"
Although I appreciate the urge to write good code, using applicative is not always the best fit for a simple tutorial. The internet needs a lot more non-applicative parsec tutorials. The simple fact is that this article can be read by more people than the applicative one could. Applicative use of parsec is well documented and common. Monadic non-trivial use is very uncommon.
This post deserves more upvotes. It's not about replacing your working mindset (not that I wouldn't mind working in Haskell more), but learning how to see different solutions to different problems so you can apply more techniques in a given language. You do lose some of the nice features of Haskell in C++, but you don't lose the ability to think about problems in a functional way. If you've "lost" the ability to think imperatively, that speaks more about your ability as a programmer than your desire to follow the "better way."
Thanks. The IDE includes vim keybindings (and even limited emacs keybindings). Support for actual emacs and vim is planned too.
I see your point. We'll think about better ways to say that.
I believe Edward may be referring/alluding to the GHC feature *default signatures*. Cf [the GHC docs](http://www.haskell.org/ghc/docs/7.2.1/html/users_guide/type-class-extensions.html#class-default-signatures)
Clicking through, it looks like it (ie the Matrix type) uses Data.Array.Base.Array
Oh, I didn't know that! TIL :)
I've used boost::variant, and while it does indeed work (you can even essentially patten match on it) you play a heavy price in terms of compile time and massive compiler errors. Optional, however, seemed to work just fine. 
I'll expand on my original comment too; if we squint a bit (lot?) `algorithm` includes (potentially destructive) `fmap` (`transform`), `filter` (`copy_if`, or destructively `remove_if`), `replicate` (`fill(_n)`, also non-pure `generate(_n)`), `take` (`copy_n`), (`&lt;iterator&gt;` has `drop` (`advance`)), `takeWhile` (`find_if_not` as end iterator), `dropWhile` (`find_if_not` as start iterator), `all` (`all_of`), `any` (`any_of`), `elem` (`find`). There are also some unusual ones like `zipWith f xs (tail xs)` (`adjacent_difference`). 
&gt; &lt;rant&gt;Why is this function returning -1 on error instead of using Maybe? c++14 will have [std::optional](http://en.cppreference.com/w/cpp/utility/optional), but more monad-like chaining utility would be nice.
Quite amazing. How much is compile time affected?
Obligatory: [http://thedailywtf.com/Articles/OMGWTF2-The-Honorable-Mentions.aspx]
Nimrod has a gc that lets you specify a max pause time. It compiles to C.
MIThrandir?
Och, it's a terrible one if it isn't tongue-in-cheek though. Generation only really fits where you have variations that can't be "library-fied" - parsers (via parser generators) was one such domain; otherwise the effort to make a generator is significantly greater than the effort to make a solution in the native language.
C++11 has lambdas :)
Undefined behaviour and when it occurs is specified in the standard though. That's why people should closely stick to the standard when writing C code. Relying on compiler specific behaviour is pretty much the worst thing a programmer can do in this language. That said I love C for what it is and especially for what it isn't and doesn't try to be. It somehow appeals to my love for the actual computer beneath all the abstraction.
They definitely help reduce the number of cases for which you need to write explicit instance bodies, but the question asked here doesn't seem to require them.
I highly recommend [Brent Yorgey's lectures](http://www.seas.upenn.edu/~cis194/lectures.html) if you're starting out - the homework exercises are fantastic - and recommend [this](https://github.com/NICTA/course) for afterwards.
More or less as you'd expect from something with this level of template meta programming. Which is to say, quite a bit. In my own anecdotal experience, I find it to be slightly better than boost, but basically that level. Depending of course on how many and which templates you instantiate.
I haven't been on SO nearly as much as I used to be, but today I had a Ruby on Rails question that I asked there. I noticed that I got another +10 rep for my Leksah answer to that question (I don't even use Leksah these days, usually emacs or sublime text) and realized that FP Haskell Center should probably be represented there as well, so I wrote up a quick description. So go upboat that new answer ~~because 23k rep just isn't enough~~ because people are continually googling and landing on this resource and they should know about the latest hotness.
Difference lists work because `++` is O(n) on the left-hand side, but only O(1) on the right-hand side. So by composing a series of right-associative append operations, the total cost is O(n) for the total number of elements. Difference vectors don't work the same way, because appending is O(n) on both sides. But you could create a different data structure which keeps a `Sequence` for remembering each appended component vector. At lowering time it would determine the aggregate size, allocate a destination vector large enough, and then use a fold to copy all the component vectors into place. This would also be O(n), while still allowing operations like `head`, `tail`, `map`, etc., on the intermediate representation.
Also updated the info on haskell wiki, just quickly copy/pasted the same text: http://www.haskell.org/haskellwiki/IDEs#Cloud
&gt; there parts of the book that are going to be more problematic than if I was using OCaml. I'm mostly thinking here about having things like mutable variables or data structures. Free your mind from mutable variables, they're pretty much unnecessary. If you do need them, `MVar`s are pretty easy to use, they just require that you work in the IO monad. As for data structures, Haskell's biggest strength is its rich type system, so I wouldn't imagine data structures being an issue. Functional programming in general has been a great choice for compilers because you have immutable variables and rich data types. It is relatively easy to define and manipulate ASTs, and with the Parsec (or similar) text parsing libraries, it's relatively easy to parse source files. I would recommend using Haskell.
Good idea. I have a used yurt left over from my doctorate program.
http://www.pythonchallenge.com/ I know it says python but they have solutions for each problem in many languages.
It's really up to you, but I would actually recommend you stick with what you know, which in this case is OCaml. If you choose Haskell, just realize that laziness and purity are *awesome*, but the fact that every language except Haskell lacks these things means that it will take some extra time to get used to them. This is time which you may or may not have; only you can decide. I can guarantee that learning Haskell will make you a better programmer. I can't guarantee that you can learn the nuances of Haskell quickly enough to succeed in this course.
It's worth noting that the data structure you describe feels a lot like a (1-dimensional) REPA array.
I think if you wanted to do it yourself and you're familiar with Haskell (in your case, OCaml), then sure. But I would not teach a class with it for the simple reason that students would have to fight Haskell instead of fighting their compiler implementation. I took my undergrad compilers class with MatLab, and it turned out to be a brilliant move on the part of my professor: he had reimplemented every level of the compiler toolchain in MatLab so that we could clearly and easily inspect WTF was going on, and it allowed us to simply write our code without worry about C++ templates and other dumb shit that, while not actually dumb shit, would be beside the point of a compilers class.
I'm not a complete newbie to Haskell; I've worked through Graham Hutton's "Programming in Haskell" as well as "LYAH", however I have never reached for Haskell when I've had a large-ish project. OCaml is pretty well suited to writing compilers, and it was pretty fun to use it, but I think I'd like to give Haskell a whirl. I imagine that if I get stuck, I can ask on the Haskell mailing lists/StackOverflow forums to get unstuck without having someone else do my homeworks.
I would go with OCaml in your case. I don't know how advanced you are with OCaml, but do you use ocalmbuild for you projects? Have you tried utop and opam? Jane Street's Core std lib is nicely organized. Parsing with menhir (an improved ocamlyacc) and ocamllexx is pretty convenient. I recently came back to OCaml because of the Real World OCaml book and it teaches you all the tools/libraries that I mentioned above. So unless this sounds boring to you, I would play safe, since you can still learn a lot of useful things. I like exploring and learning languages like any FP enthusiast, but it's good to pick one language and learn it well (including the ecosystem around it). It does save the amount of googling for one. Moreover, Haskell and OCaml are both excellent for writing compilers. Should you decide to try Haskell anyways, I would suggest to pick up some Applicatives and Monads as you write a parser in Parsec and, say, a type checker. For instance, the reader monad (transformer) makes it easy to add environments to an existing code. But really, try it when you have some free time and you have aced the course.
When I started learning Haskell I did a lot of the problems on http://projecteuler.net/ After that I think it will usually be more effective to find real problems that you are personally interested in.
It's the pointiest functional programming language out there.
The C++ folks do an amazing job adding lightweight high level abstractions, considering one of their major constraints is to (mostly) maintain backwards compatibility at all costs.
And some type deduction (C++14 goes even further). C++14 also has std::optional, which is basically Maybe.
I did this exact thing for my Compilers course last semester. It was a team of three, and none of us have ever used Haskell before. It went fantastic! I would absolutely recommend it. It's the whole reason why I subscribed to this subreddit, and am now using Haskell as much as possible.
David Sankel does a lot of functional programming in C++. He gave a talk at boostcon, [The Intellectual Ascent to Agda](http://youtu.be/vy5C-mlUQ1w). There's also a pdf he wrote, [Modern Functional Programming in C++](http://zao.se/~zao/boostcon/10/2010_presentations/thu/funccpp.pdf). Take a look at [boost::variant](http://www.boost.org/doc/libs/1_54_0/doc/html/variant.html), and also [boost::lambda](http://www.boost.org/doc/libs/1_54_0/doc/html/lambda.html) 
It looked like a past Cabal bug and it behaved like one (and I couldn't replicate without going through Cabal). In any case, I communicated with the Cabal folk and while it could be fixed for their end, they bounced it back to Haddock. It has since been fixed on the Haddock side, waiting to go upstream.
I agree, Haskell only made my imperative work tighter. I've heard of people that have the OPs issue, but never felt withdrawal, only synergy. Once I learned Haskell my C(++) got very basic and predictable. 1. enumerate and typedef everything 2. create a strongly typed function with the scope of a switch/case that handles every parameter value + default for each function 3. profit Mileage may vary for others but I **must** have tested, safe, efficient, correct code as a part of my work for certification.
Read section 5 ;)
As an extention to 1, I don't like bare primitive types. Any time I'm passing around an int that means something, I try to wrap it in a single-element struct that has an appropriate name, so I can't swap the order of (say) price and quantity in a function call.
I used Haskell when I did my compilers course and it was pretty great. Parsec made parsing really nice, semantic analysis was natural with ErrorT State and so was optimization, register allocation was a bit tricky because I didn't know about the ST monad but it turned out fine in the end.
nitpick: "A" here being Algebraic, not Abstract. (I read this, then thought "wow, view patterns have been implemented?!" then went "oh")
Thanks for the tips; Parsec was one of the reason I was thinking of using Haskell. OCaml's ocamllex and menhir are okay tools (more pleasant than doing your own recursive descent), but they are a lot clunkier IMO than a nice parser combinator library. The compiler will need be for a small web DSL, so the target language is not going to be LLVM. It might be PHP!
Yeah, lex/yacc based parsers are incredibly clunky compared to parsec, I can't really use them anymore. If you have to compile to a scripting language, I'd recommend compiling to something other than php, maybe javascript or just anything with well defined semantics :p
We haven't had the spec yet, but I understand that we want a sort of mini-OPA like language; a web framework in a language. I could even generate Haskell code using Scotty+Warp!
True; I could always do the class project in OCaml, and in my free time, try to redo it (without time or good mark constraints) in Haskell.
I got an industry secret right here called stackoverflow.com
You can't do point free programming with templates?
View patterns are available with -XViewPatterns.
The problem in Haskell comes when types are *not* enough documentation, and the only other solution is an academic paper.
As someone who does a lot of C++ for work and rarely codes in anything but Haskell otherwise, I would suggest that you 1. Accept that C++ is not Haskell. I know this is difficult and I feel your pain, but it just isn't. I've been where you are; yesterday I spent twenty minutes seriously considering writing a taint monad using template metaprogramming in order to encapsulate a piece of code that needed to be async-signal-safe, and then I realized that I was on crack. Sweet, sweet Haskell crack but crack nonetheless. 2. Spec prototype in Haskell. I produced some exceedingly complex and surprisingly bug-free pieces of C++ code handling priority queuing and parallel task dependency resolution in like, two days, which scared my boss to death. What I didn't tell him is that I wrote and tested the whole thing in Haskell first, *with an eye to eventually porting it to C++*, and so by the time I wrote the code I knew exactly how it would work. Amazingly, writing the same piece of (complex) code twice was actually *more* productive than trying to write it just once in a non-expressive curly-brackets language like C++. Those are my suggestions. They've worked for me. But the "argh I could do this in one line in Haskell, why must I write thirty lines of boilerplate in this stupid language" feeling never goes away. Unfortunately.
Several similar sites such as spoj.com and (I believe) codeforces.com accept Haskell. By the way, if you're interested in competition programming, you should not use USACOgate. The style of problems there is not reflective of the modern-day IOI, and the US IOI team has stopped using it. The USACO coaches instead recommend other online judges, especially the Saratov State University Online Contester, acm.sgu.ru .
It doesn't install on OS X 10.8. :-( I got this error: Distribution/Version.hs:237:4: error: invalid preprocessing directive #-}
Holy lambda, that is indeed amazing. Good suggestions, thanks.
Haskell is a great language for compiler design. If you're targetting LLVM IR then use the new [llvm-general](http://hackage.haskell.org/package/llvm-general) library.
`MVar`s are for shared-state concurrency. If you just need something mutable `IORef` is the way to go.
The second is indeed not suffering from the same problem, hence my question.
to defeat the army of uruk-hai-order-functions?
But it *works* when the IO action is actually done (`print "Hi"`). It fails when all that's happening is `return ()`. Isn't that odd?
I'm not sure, but here is my guess: In `main`, because `return ()` is so simple, the allocation caused by replicateM isn't that much, so the program gets far enough in the recursion to cause a stack overflow. On the other hand, in `main'`, `putStrLn "Hi"` is causing some allocation, to the result list causes an OOM before it can reach the level of recursion that would stack overflow. I would bet that if you significantly increase the allowed heap size, both of them will stack overflow.
Interesting hypothesis, but I don't think it's right. If I set the stack size to 4 bytes (that's write 4 *bytes*) then `return ()` stack overflows with only `1000` iterations, but `print "Hi"` completes successfully. Having said that, `return ()` completes successfully with `100` iterations, seemingly not using any stack, so I admit I am even more puzzled now.
I've never used O'Caml. What can you do with modules that you can't do in Haskell?
Didn't other replies show it fails with print as well, just more slowly?
My dummy guess would be the first case doesn't allocate and so doesn't yield to the scheduler thus failing with stack overflow.
Why doesn't the first case allocate?
Boookmarked! Thanks buddy!
There are some arguments that could be made for modules. I'll leave some literature for you at the end of this post, but here's two points to consider [1][2]: 1) Modules give you more than one typeclass instance. Consider the following signature for ORD typeclass: signature ORD = sig type t lt : t * t -&gt; bool geq : t * t -&gt; bool end which in haskell would be class ORD a where lt :: a -&gt; a -&gt; bool geq :: a -&gt; a -&gt; bool A major contention here is that Haskell only gets to have one instance of ORD per type without resorting to newtypes. ML allows you to have as many implementations of ORD as you wish for a given type, allowing you to do unnatural orderings (e.g. the integers in reverse). Of course you could use newtypes in haskell to overcome this limitation, but that's *inconvenient*. 2) Sealed views. Haskell would manifest this idea via existential quantification, but that's a messy low level construct. SML allows you to hide the implementation of any signature (called a structure) with a sealing annotation. e.g. structure TreeMap :&gt; MAP Now no matter how the internals are implemented (in this case a tree), the user of the structure cannot get the underlying data structure directly. Note that this can also be used to hide global state being recorded by the structure which is useful for things like splay trees and fresh variable generation. Once again, Haskell *can* do these things, but the types of constructs you need are not immediately intuitive (existential quantification, for example). At this point, you should be saying, "But as you said, haskell can do all these things!" This leads into my *main* point: haskell can live without modules, but modules make things so much *easier*. Many times an advantage of a programming language is not about what it can and cannot do compared to another language, but rather what it makes easier. In this case, the module system makes code structuring intuitive (too intuitive, refer to my previous comment's warning about overengineering). One suspects that our current cabal woes might've been solved with a module system, but apparently there are some big problems that need to be solved in order for that to happen [3]. Further Readings: - [1] http://www.cse.unsw.edu.au/~chak/papers/modules-classes.pdf - [2] http://www.mpi-sws.org/~dreyer/papers/mtc/main-long.pdf - [3] http://www.mpi-sws.org/~skilpat/backpack/backpack-paper.pdf edit: added how the readings are relevant.
What optimization level are you building with? 
We also have a course on compilers in the master programme. it's a bit more in depth. : http://www.cs.uu.nl/wiki/bin/view/Cco/CourseResources#Lecture_Notes I love it that my university is so active with haskell. Have and had some real quality people lecturing here. Erik Meijer, Swierstra, Dijkstra etc...
Do you get the same behaviour with return $! () or similar? Stack overflow seems like a strange thing to get on this code in general...
Do you mind filing a ticket with the full output (including your GHC version, old Cabal version, etc) at https://github.com/haskell/cabal/issues ?
Yeah, I've pretty much made up my mind to do this project in OCaml, and find a side project later (perhaps the COOL language taught by Alex Aiken at Stanford) and try to do that one in Haskell without the concerns of time and good grades.
Yes, tail recursive version works ok, it just OOM very fast, which is expected anyway: sequence' :: Monad m =&gt; [m a] -&gt; m [a] sequence' l = go l [] where go [] rs = return rs go (x:xs) rs = do r &lt;- x go xs (r:rs) replicateM' :: Monad m =&gt; Int -&gt; m a -&gt; m [a] replicateM' n = sequence' . replicate n -- with 100 instead of 10 uses over 2 GB of memory bignum = 10 * 1000 * 1000 main = replicateM' bignum (return ())
I've tried with both `-O0` and `-O2`. I get the same behaviour.
Yes it's the same. The stack overflow is not surprising (see the thread in the linked email). The *lack* of stack overflow for the `putStrLn "hi"` case is surprising.
Like jwiegley said, `(++)` is O(n) in the length of the left argument. It might help to note that `(++)` is right associative. In an expression like: as ++ bs ++ cs It already does what you want. You pay for the length of `bs`, then you pay for the length of `as`. If you write `(as ++ bs) ++ cs`, you have to pay for `as` twice. Whenever you use a left fold, the elements will be combined in this inefficient order, so you use a difference list to re-associate them to the right. This commonly comes up with the writer monad. So to answer your question, they defer work until the rightmost element is available because it is more efficient to work from right to left.
I love `Maybe`! Error handling without necessarily interrupting flow control.
Done
When I say pointiest, I'm making fun of all of the angle brackets.
You can do this w/o `ConstraintKinds` if you're willing to throw in an extra constructor: {-# LANGUAGE GADTs #-} {-# LANGUAGE ConstraintKinds #-} {-# LANGUAGE TypeFamilies #-} module Combine (Combine(), combine, split, apply) where import Control.Category import Control.Arrow ((***)) import Prelude hiding (id, (.)) data Combine p q where Combine :: (a -&gt; c) -&gt; (b -&gt; d) -&gt; Combine (a,b) (c,d) Id :: Combine p p instance Category Combine where id = Id Id . u = u u . Id = u Combine f g . Combine f' g' = Combine (f.f') (g.g') -- dealing with the extra constructor may be a pain outside of this library, -- so use a smart constructor combine :: (a -&gt; c) -&gt; (b -&gt; d) -&gt; Combine (a,b) (c,d) combine = Combine -- and a smart destructor split :: Combine (a,b) (c,d) -&gt; (a -&gt; c, b -&gt; d) split Id = (id,id) split (Combine f g) = (f,g) apply :: Combine p q -&gt; p -&gt; q apply Id = id apply (Combine f g) = f *** g I changed your name b/c it seemed more like [the split/combine operator `***` from Control.Arrow](http://hackage.haskell.org/packages/archive/base/latest/doc/html/Control-Arrow.html#v:-42--42--42-) than currying. 
First, `cid` is ambiguous and could never be called, since it mentions type variables in its constraints that are not used in its type. You may have wanted `C cat a a a =&gt;` instead, but I'm not sure that works either. Second, you can introduce the existential variables via the constraint more indirectly: data IsPairPf a where IsPairPf :: (a ~ (x,y)) =&gt; IsPairPf class IsPair a where isPair :: IsPairPf a (`Pf` being short for "Proof"). Then you can use isPair/case analysis to bring the existentials into scope in the implementation. But I'm not sure that's the best way to do this type of restricted category. Also, I'm not sure GHC knows how to discharge the existentials if it requires casting--someone more familiar with GHC's implementation will have to weigh in here.
Will do.
I did some poking around and here's what I figured out. Actually, both `main` and `main'` use lots of stack space. The difference is that `main'` gets away with it! The RTS doesn't raise a stack overflow exception when exceptions are blocked. Instead it just allocates another chunk of stack as though there were no stack limit. See https://github.com/ghc/ghc/blob/master/rts/Threads.c#L494. Now exceptions are not blocked in the loop in `main`, nor in the loop in `main'`. But they are blocked for most of the execution of `putStrLn`. `putStrLn` allocates quite a lot of stack space compared to a single iteration of the loop in `replicateM`, so the point of maximum stack usage is always within `putStrLn`, with exceptions blocked. So even though `replicateM` does use increasingly large amounts of stack space, in excess of the stack limit, any time that the task overflows its currently allocated stack chunk, it will have exceptions blocked and the RTS will give it a new chunk without testing whether it has exceeded the limit. The stack use of a single iteration of `replicateM` always fits within the current chunk, because there's a bunch of space free after the previous `putStrLn` has completed.
But both of the `IO` actions are completing with `()`. That doesn't explain the difference.
https://github.com/simedw/master The tasty bits is in Generator.Compiler
By completing you mean having a return value? Well but IO actions also have effects and putStrLn possibly have allocations somewhere inside while `()` doesn't allocate (I hope so, at least).
I used Haskell to implement my compiler for my last year compiler class. I did a compiler for a subset of the C programming language (two types : bool and int, while, if-else and arrays) which compiles to LLVM bytecode as text (I found it easier to generate LLVM by hand than using the API). The Haskell code, using Parsec and monad transformers is notably concise : around 680 lines of code for the whole compiler. I was already pretty fluent in Haskell, so monad transformers (for the parser and the code generator) were an obvious solution from the beginning. Given my experience I advise you to do your homework in Ocaml as you are more at ease with it and you will spend a lot of time learning monads. Moreover, characteristics of Haskell (purity, lazy evaluation) will not be killer features in the making of a compiler, so the Ocaml solution will not be so different. Statically typed functional languages are really good to build compilers anyway. As a piece of advice, I recommend you to do not try to use GADTs, whatever it's in Haskell or in Ocaml. Those are pretty but it's damn hard to write a parser which deals with them. Here are my compiler's sources (comments are in French) : https://github.com/RaphaelJ/Cours-passerelle/tree/master/Compilateur
FYI, I've changed the behavior of unordered-containers to only be strict in values actually inserted into the map now.
The default initial stack size (`-ki&lt;size&gt;`) is 1k, so your numbers for `return ()` would be consistent with the RTS not checking the initial stack size against the maximum stack size.
Fascinating. This seems like a bug, though, shouldn't GHC just defer the 'stack overflow' exception until exceptions become unblocked?
I learned more from Simon Peyton-Jones' free book [*Implementing Functional Languages: a Tutorial*](http://research.microsoft.com/en-us/um/people/simonpj/papers/pj-lester-book/) than I did from my compiler course in college. It could be that I was just more advanced in my understanding at the time, but I think that book is totally reasonable for an undergraduate compiler course. In addition, Haskell's LLVM bindings are amazing; check out Lennart Augusston's [BASIC compiler in Haskell](http://hackage.haskell.org/package/BASIC); the [actual compiler](http://hackage.haskell.org/packages/archive/BASIC/0.1.5.0/doc/html/src/Language-BASIC-Translate.html) is around 200 lines of code.
Cool, merci beaucoup! As I said in another reply, I've pretty much made up my mind to go ahead and do the class assignments in OCaml, but I'll probably take some time during Christmas break to play with a Haskell compiler.
simple putStrLn works fine for me :)) my haskell apps are all services configured by systemctl. So all their output goes to journald. Which is what i want/need. 
I've used hslogger. It works well, though indeed it is in the IO monad. [StackOverflow: logging - What are the best Haskell libraries to operationalize a program?](http://stackoverflow.com/questions/5808825/what-are-the-best-haskell-libraries-to-operationalize-a-program)
I use hslogger. Runs in the IO monad. Just replace all your putStrLn's. Supports multiple handlers so I have everything from local logfiles, to Growl messages, to syslog messages. As an aside, there are several web services out there now trying to help you build dashboards with your forwarded syslogs. Pretty easy to set up. 
Yup, view patterns work quite nicely with regexes! That was the inspiration for my rex package, which does safe / pre-compiled regexes: http://hackage.haskell.org/packages/archive/rex/0.4.2/doc/html/Text-Regex-PCRE-Rex.html It's safer because it keeps track of the number of groups in the regex, and checks that it's a valid regex.
I presume you'll come across Attribute Grammars soon if you haven't already. If you do end up using Haskell, consider using UUAGC for semantic analysis or codegen. It's an attribute grammar preprocessor for Haskell. There is a nice [introductory tutorial](http://www.haskell.org/haskellwiki/The_Monad.Reader/Issue4/Why_Attribute_Grammars_Matter) available, as well as a [manual](http://www.cs.uu.nl/wiki/bin/view/HUT/AttributeGrammarManual). There was a Tiger compiler frontend written in it, which hopefully you can learn from (without plagarising ;).
Okay, I get it! So my approach is an optimization because it takes the temporary matrix heavy `a × b × c × d × e • v`, and turns it into the equivalent `a • (b • (c • (d • (e • v))))` which generates only much smaller temporary vectors. Amazing! I made an optimization, and I had no idea how it worked! Of course this is only an optimization when a, b, c, d, and e are variables. When they are constants it makes much more sense to flatten them out into a single matrix.
Here is the concrete code for what Faucelme is talking about: log :: (Monad m) =&gt; String -&gt; Producer' String m () log = yield impurely :: Producer String IO r -&gt; IO r impurely p = runEffect $ for p (lift . putStrLn) purely :: Producer String Identity () -&gt; [String] purely = Pipes.Prelude.toList This is using `pipes-4.0.0`, which comes out on Sunday.
What does `~` mean in the type language? I'm guessing that `a ~ b` means `b` unifies to `a` or something like that? You can't really google it, being a single character and all...
 {-# LANGUAGE ViewPatterns, ScopedTypeVariables #-} {-# OPTIONS_GHC -F -pgmF she #-} import Text.Regex.PCRE urlRegex = "^(https?)://(\\w+(?:\\.\\w+)*)/?$" pattern URL proto host = (=~ urlRegex) -&gt; [[_,proto,host]] :: [[String]] foo (URL proto host) = Just (proto,host) foo _ = Nothing ----- h&gt; foo "http://lelf.lu/" Just ("http","lelf.lu") 
The [History of Haskell](http://www.haskell.org/haskellwiki/History_of_Haskell) paper states that "To this day, the Haskell community periodically agonises over the absence of a single standard Haskell GUI [library]". That paper was written in 2007, and I don't feel like things have changed much. Still, I really wouldn't advise "going at this alone" if this means creating your own widget and/or painting library, because you will probably end up spending more time on those libraries than on your program. Haskell has [many GUI libraries](http://www.haskell.org/haskellwiki/Applications_and_libraries/GUI_libraries), divided into categories whose advantages and disadvantages are described in the aforementioned paper; the community simply hasn't settled on one particular choice. For the non-GUI graphics part, I've heard very good words about [LambdaCube](http://lambdacube3d.wordpress.com/).
If you don't mind cheating with purity and dedicating stderr to your logging, Debug.Trace has worked fine for me. Although I did feel a bit dirty afterwards :)
Right. Like I said, "Maybe." A couple narrow points: &gt; the alternative would presumably be to convince them to use the eDSL and if that was possible, why not convince them to use Haskell itself? If the problem is solely political, it may be enough to be able to say "yes, I am using C++" and "not be lying". More legitimately, perhaps, in an environment with fledgeling Haskell developers and experienced C++ devs, you may be able to manage some aspects of performance better working in something manipulating C++. Otherwise, I mostly agree. 
Your `Set` type seems to be an explicit virtual table/activation record. ~~It seems as if you're writing the low-level code to save the compiler the job of translating away the typeclasses. The lack of type constraints on `t` also seems to suggest that all types must be able to act as `Set` containers.~~ ~~I assume I'm misunderstanding.~~ **EDIT** - Oops - I was misunderstanding, and of course you say "Haskell packs the type for you implicitly, which is nice" etc. The rest of the reply left anyway, if anyone's curious. On the "Clever use ... pretty close representation of OOP-style" - my example ADT was based on that, though it gets more obvious if I change the name... data ThingRef = forall a . ThingClass a =&gt; ThingRef a and provide an instance (maybe there's a `deriving` for this?)... instance Thing ThingRef where dothing ThingRef a = dothing a ... Basically, `ThingRef` does the job of a reference type in OOP. It implements the `Thing` interface by doing the dispatch and calling through to the underlying concrete implementations for the specific types. That doesn't seem to need much cleverness. Inheritance is supported too - that's a feature of typeclasses as well as OOP classes - though the casting of references isn't, at least not without writing casting functions manually. I actually like the fact that you have to specify the reference types to make available and implement your own casts. It discourages overuse. Absurd as it seems, even in OOP, OOP is often overused. Very few apps/libraries need large class hierarchies. One potential issue where existentials in Haskell may be more awkward than OOP actually exists in OOP too - it's just that the most common case doesn't occur in that context because in-place mutation is done rather than replacement. Basically, with a function... `ThingRef -&gt; ThingRef` You don't know that you'll get the same kind of `Thing` back that you started with. That's often exactly how it should be, but it can also be a problem. Of course the solution is to not create that problem - don't forget things (from the static type) that you still need to remember. And therefore don't *overuse* existentials. On your side-note - there's a similar issue going the other way, though it needs more cleverness and a bit more than pure OOP. Going to C++, for example, template structs have similar polymorphism (implemented differently) to ADTs without constraints. Template variant records would be closer still, but for some reason C-family languages rarely support variant records. Anyway, with some fiddliness, you can extend that so template classes and objects do the job of typeclasses and instances. The objects have no member data - they're just there so you can pass the virtual tables around as parameters and share type parameters in the template-class types with the real arguments. Please don't make me explain the template-trickery you'd need to make this work - it involves templates that take templates as parameters, and it gives me a serious headache. However, lose some of the template trickery and complexity and this is very similar to something I've actually done, long before I ever heard of typeclasses. Naive OOP theory tends to teach that "the shape draws itself". I've observed in the real world that OOP is meant to model that there are "tools" which are objects in themselves, but their purpose is to manipulate other objects which they don't own or contain. Nails don't hammer themselves in, for example - hammers are used for that. And sometimes having "tool classes" that don't own or contain the data they work with is useful. It happens in some of the well-known OOP design patterns too - `Visitor` is a tool class that doesn't own or contain the `Element` objects that it visits, `Observer` is a tool class that doesn't own or contain the `Observables` and so on. So I might have an abstract class for set-manipulating tools... class SetTool { const Set* empty () const = 0; const Set* insert (const Set* s, const Val* v) const = 0; bool element (const Set* s, const Val* v) const = 0; }; I wouldn't consider this a real-world example. Actually, the tool classes I've used tended to be very low level, and to have interfaces that dealt with `void*` untyped pointers. A result of old-school C++ where templates were often thin typesafe layers over shared type-unsafe internals to avoid bloat. Part of the job of the tool class was to know the run-time layout of the data structure nodes those untyped pointers referenced - a pattern derived out of envy of languages with generics based on closures. But strangely enough, that's remarkably close to your Haskell `datatype Set a` example. 
In (modern) functional programming you already have various dictionary structures * finite maps (the standard one is a red-black tree) * tries - implemented with prefix keys/paths that shorten the search * arrays - indexed with integers and sort of fixed size (but fast) If you think concretely about the problem you have in hand, what are you missing? 
You aren't thinking functionally. The thing about pure functional data structures is that they are immutable and being immutable forces them to also be persistent (that's as opposed to ephemeral rather than volatile). By introducing mutable pointers, you break immutability and you therefore lose persistence. Persistence is a useful property for a datastructure to have; it makes things simpler by decoupling value from identity.
I am not even aware of any algorithms for doing incremental topological sorting. Care to educate me?
Hmm there are some papers, easy to find on google. Generally you just make a graph with some integer tags and when you insert an edge, you increase the tags of every parent recursively. Then there are some voodoos for optimizations. http://www.siam.org/proceedings/soda/2009/SODA09_120_benderm.pdf
Let me second the web browser. If you want buttons and forms and so on I find HTML to be just lovely, and a web page can access a local server just as easily as a non local server. Personally I'd just write the JavaScript but if you want to work with Haskell to JavaScript compilers you really do have a lot of choice. If you were also to write Haskell bindings to angularjs I'd be very interested in testing that.
this is pretty interesting. knowing about elm, i had wondered if the best way to go would be to do what you've done (at least what i think you've done) in that haskell could directly draw to a browser window rather than needing elm. also, in the texture 2.0 post i referred to in my original post, i had missed the quil library, which is basically a clojure wrapper of the processing api, which seems to be another option and a related idea since processing is platform independent as well. thanks again for the link, and i'll attempt to try it out.
Yes! This works like a charm. Interestingly, this is very similar to my first approach, but that didn't work out and made me think I needed `ConstraintKinds`. I can't remember what the difference was exactly. Thanks a lot! 
thank you for the response and the link to that paper. i had visited the gui libraries page before, but that page is in severe need of updating and cleaning up. some of the libraries haven't been updated in well over a year (some MUCH longer), some links don't even work, some of the packages seem to not even exist anymore, the others are terrible looking or have no documentation, etc. this is what i have found incredibly frustrating about haskell is that there seems to be no infrastructure to write a full featured application with a ui. the only real options seem to be gtk2hs and wxhaskell, but i've heard bad things about g2k and gtk2hs hasn't had an update in almost a year. thanks again for that paper link and also for the LambdaCube link. i will have to look into it more.
I've also used hslogger, and wrapped it in a typeclass. Most of my code uses the typeclass instead of hslogger directly. The instance for IO uses hslogger, the instance for Writer doesn't and thus can be used with QuickCheck.
gtk2hs is a decent GUI library. I made 'hoodle' using the library and overall I am quite happy about it. Although it is yet gtk2, it will be upgraded to gtk3 soon, I believe. BTW, Hoodle homepage is here :) http://ianwookim.org/hoodle
Awesome!!!!
The main issue I've had with this approach when I've used it in the past is that the new category isn't a proper product category as it is enlarged with identity objects for things that aren't products. The real product category would use product kinds, but that doesn't work, because Any is an extra distinguishable member of each kind, so `(x,y)` is effectively `x*y + 1`, rather than `x * y`, and consequently the extra eta-expansion rules to say the only inhabitants of kind `(x,y)` are of the form `'(tx,ty)` that you'd need to define `id` aren't valid. This annoyance is actually what first drove me to write the `semigroupoids` package, because we can define a perfectly good product semigroupoid in Haskell, even if a real product category is currently unsoundly beyond us.
I should clarify that `threepenny-gui` is a GUI framework in Haskell. While it does connect to a web browser, there is no need to write or know JavaScript and we don't compile Haskell to JavaScript either. It's like Gtk2Hs or WxHaskell, just with a seemingly weird choice of display. Also, who needs Angular.js when you have FRP?
html5
The closest similar thing to what you describe is to store values in some type of map, indexed by unique identifiers, and store the identifiers in the other structures. Then you can update the values in the identifier map once, without needing to change all the structures. However, this type of question strikes me as not being about a 'problem' at all. There is nothing particular you are trying to compute here. This is a question about an implementation technique, or practice in imperative languages. It is rather like the, 'how do I make a heterogeneous list,' questions that people new to Haskell often ask. One can give many answers to that, but the real answer is that heterogeneous lists are not an end in themselves, and they are pretty much never (in my experience) necessary (or even especially desirable) for whatever your actual goal is. So it doesn't matter how you make them. This is a bit less in that direction, but it is general in such a way that even if the answer were, 'you cannot do this technique except with ST,' that wouldn't mean anything with respect to any particular problem you want to solve.
A trivial way to do fast updates on data held in multiple data structures.
And this is for the lazy ones :) http://comonad.com/reader/2012/hackage-mirror/
&gt; Monads seems like a very hackish way to set the order of things explicitly Monads are a very principled way to set the order of things explicity, and allow subsequent "things" to depend on the result of previous "things". &gt; something just hacked together to trick the compiler into doing things in the order we'd like They aren't. &gt; Are there any alternate ways to do this? Perhaps you could suggest some approaches and we'll discuss whether or not they'd work. &gt; Do monads have other uses that I'm not aware of? Probably a lot. Were you aware of the use of monads for ambiguous choice, exceptions, nullability, parsers, mutable state, software transactional memory? They're a very general design pattern. &gt; I apologize if these are very naive questions but I find the best way to understand something is to question why it works like it does. Fair enough. Feel free to ask away. 
&gt; Why isn't explicit order for things like IO a language feature instead of something just hacked together to trick the compiler into doing things in the order we'd like I would argue that reusing a general pattern (Monads) is much less of a hack than a language feature. Why hack IO into your compiler if you can do it in a generic way? Besides that, though, the Monadic design allows for things like maps containing IO actions that you can look up, IO actions that can be passed between threads, and all kinds of other useful things. If you haven't yet, go learn about transformers and try out some of the awesome things Monads can do that have nothing to do with IO. Thinks like the coroutine transformer, or the list monad.
While I agree with tomejaguar, you might want to look at Functional Reactive Programming. 
Since Haskell is pure, the compiler is free to carry out computations in any order that produces the correct result (equational reasoning). So, in pure code, you cannot order (or sequence) computations. This doesn't matter for side-effect-free functions. But, if you want to print two lines of output to the screen, the order obviously does matter. This is one use of Monads: to isolate side-effecty code (such as I/O) from the rest of the program. This is why main is of type IO () (pronounced 'IO Unit'). Main can of course call pure functions, but pure functions cannot call IO functions (with the exception of UnsafePerformIO, which is rarely needed). So, the type of putStrLn is not a function from String to nothing, but rather a function from String to IO (), and that means that it can only be called from within the IO monad. Put differently, *lack of* explicit order is a language feature; it frees the compiler to do all sorts of optimizations, stream fusion, and so on. It makes refactoring code much easier. There are other uses for monads as well; the IO monad is special because main is in the IO monad. A much simpler monad to understand is the Maybe monad, values of which are either 'None' or 'Just value'. So, a Maybe Int could be None, or it could be Just Int. The cool thing about this is that a function that takes a Maybe Int can do the correct thing whether it gets an actual value or not. This is very much like manually checking in python or ruby that the argument to a function is not null or nil. I hope this is a bit helpful; Learn You A Haskell has some much more detailed explanations of monads.
Ok thanks, I guess its just reusing a general pattern as much as folds are. Thanks for the insight
&gt; Also, who needs Angular.js when you have FRP? Performance? Did you do testing of large number of objects synchronized on a web page and compare it to AngularJS? It could be that frp is just as performant, but we need to be sure. 
Well I have heard of a few alternatives like streams, pipes and conduits but they don't seem to be in heavy use. What advantages/disadvantages do they offer?
First, you are mixing do notation and monads. Do notation is just that, a notation, that could as well be left out and monads would be exactly the same: it doesn't have anything to do with the type of `putStrLn`. Haskell needs the IO monad not because it's lazy and functional, butbecause it's *pure*. That means a function is not the same thing as in other languages. In, say, Python, or even List, a function is something that takes some arguments, executes some code(which may look on mutable variables, set them, generate random values, ask for input, whatever) and *also* may return a result. That means that two things are conflated in one: interacting with the outside world(side effects) and transforms argument values into result values. It is sead that he language is **imperative**: you write a sequence of orders that the computer will run sequentially. In Haskell, those two roles are separated: functions do program logic *only*. A function `Int -&gt; Int` just is a value that, when applied to an integer, will result in an integer. It won't do anything else, ever. ^(1) That means that, in Haskell, we don't say(shouldn't say) that `putStrLn` is "a function that prints a string": functions can't possibly do that. How are side effects executed then? Enter IO. A *value* of type `IO a` represents a *computation*, or a program, that does a bunch of side effects and has a result of type `a`. You can't *extract* that result(see 1), but you can make a new program that depends on the result of another, with `(&gt;&gt;=)`, and you can also make the "free" program (the one that has a result without doing anything) with the misnamed `return`. And they are just normal values, so you can use them as arguments to functions, and return them. Indeed, Haskell is said to be **declarative**: you describe what your program should do, by combining smaller programs and manipulating them with functions. So `putStrLn :: String -&gt; IO ()` is a function that, when applied to a String, *has as a result a program that prints a string and has a () as its result*(because there is no meaningful result: in Python you would use `None`). ^(1) Okay, I lied: GHC provides a function `unsafePerformIO :: IO a -&gt; a`, which can shoehorn values with side effects into normal functions. It's called "unsafe" for a reason.
So it sounds like my limited and simplified introduction to monads only for IO is clouding my view. Is that right?
&gt; values of which are either 'None' or 'Just value' `Nothing` instead of `None`, as it is implemented in GHC and specified in the [Haskell 98 report](http://www.haskell.org/onlinereport/maybe.html)
Thank you this helps make more sense. Because lack of explicit order is a language feature, monads are needed to define sequence. It's not that the haskell developers were too lazy to define explicit order, they specifically chose not to as a trade off for optimizations and other things.
Streams, pipes and conduits are also based on monads.
Thank you, this helps a lot. It looks like I am going to have to read a lot about different applications of monads until the idea clicks in my head as a whole.
&gt; It's not that the haskell developers were too lazy to define explicit order Indeed it's quite the opposite of "lazy". It takes a lot of hard work to define a pure language where the evaluation order doesn't matter (much). 
I'm not sure I'd say "clouding". It's just that the concept of monad is very general and if you've only seen it in the context of IO it's probably very easy not to grasp how powerful that concept is. 
A really simple trick is to only have one data structure: central :: A ... then have your other data structures be functions of your central data structure: other :: A -&gt; B Then if you update your `A` you just re-apply the `other` function to get your new `B`. This is not expensive because laziness will only compute what you actually needed.
They are not alternatives to IO: they also use IO. They are an alternative to *lazy* IO: the idea is to be able to consume input as it comes, instead of having to load everything in memory first. Naive lazy IO(a subset of the IO actions are only run if they are needed) is not so good(it breaks a few things that shouldn't be broken, and is very unpredictable), so you want to use these instead. An alternative to IO would be, as another used said, FRP. Elm does that, for example.
It sounds like you may be drifting into a problem area I recently wrestled with. The problem I've been wrestling with is combining special purpose data structures, like a scene-graph and a quadtree, in a functional way. The techniques applied to these structures are typically pointer-based, mutable, and do not translate to canonical functional alternatives. There's nothing in the playbook that precludes emulating pointer-based structures. Emulating the implied topology of pointers allows you to create pointer-based structures without sacrificing referential transparency. I use persistent directed graphs, wrapped behind an interface that emulates the operations of a particular structure. "Shared data" are nodes with no outbound arcs (leaves of a Directed Acyclic Graph DAG). "Pointers" are represented by arcs. Using a graph-backed datastructure, you can emulate the pointer-based semantics of your imperative cousins without sacrificing referential transparency. The cost is that you have to make the relations - which were implicit in the pointers - explicit in the structure of the Graph. You end up with a bit of extra book-keeping. Still, it works.
&gt; to trick the compiler into doing things in the order we'd like? You can already force "order" in lazy and functional languages. `[1] ++ [2]` will always evaluate to `[1,2]` and never to `[2,1]`. This seems silly, but actually a similar thing goes on with `IO`. You cannot control the order in which subexpressions are evaluated. So instead of coupling side effects to evaluation of expressions (as common programming languages do) you make the side effect a first class type. You can think of `IO a` as a programm or description or action to produce a value of type `a`. By itself it does nothing, unless it is executed. A value of type `IO a` is thus pure. For instance, you can happily evaluate `length [putStrLn "Hello", putStrLn "World"]` to `2` without printing anything. The monadic interface allows you to compose such programs. For instance `a &gt;&gt; b` is a program, which will first execute the program `a` and then the program `b`. The `&gt;&gt;` operator forces the order of the actions exactly like the `++` operator forces the order of the list elements. The true power of Monads comes from the `&gt;&gt;=` operator, though. For this, I recommend a good Monad tutorial. By the way, there is no way in Haskell to actually execute an IO action (ignoring hacks like `unsafePerformIO`). The only way to execute an IO action is to bind it to `main` and let the runtime system execute it. To summarize, even in lazy, pure, functional programming languages we can define the order of side effects without need of hacks by making a data type for a "side effect" and provide operators for composition.
This actually PRECISELY what I'm doing. I have a graph of modules that are connected by "wires" and a zippered KD tree that tracks the location of the modules on screen. I tried to generalize it as well as possible so perhaps I can figure out what precedent has been set as far as how to do this properly. This to me is the place at which nice pure functional approaches have always fell apart.
I like to think of the type signature of "putStrLn :: String -&gt; IO ()" as saying that putStrLn does two things; it produces an output of type () for an input of type String, and it performs some IO. There's only one possibility for it's first task; it must output () for any String input, so in reality the only purpose of putStrLn is to perform the IO action of putting the string on the screen followed by a newline. This isn't a hack; it's an explicit way of telling both the programmer and the compiler what putStrLn can and cannot do.
I really appreciate all of the graphics, but you've mostly restated the approach that I wasn't a huge fan of. Again, Say your set is A, and your list is B. "The way around this is to store copies of a, b, c, d... in A, B, C, D... and if we've found d through C for instance, one also stores the path to d for lookup in A, B, and D in the data for d itself, so one can update A, B, C, and D all together when d needs mutation." Though the path TO 2,1,3 in your example is trivial since you're mapping to ints. Assume some complex object with a nontrivial key. Again, to do the update, one must store the key for each data structure WITHIN the the object itself so it can be reached, and then the time to update as well as the additional bookkeeping storage scales with the number of data structures you store the object in. Not a fan of this! Either you replicate a pointer based approach by coming up with unique identifiers, maintain a ton of copies, or perhaps there's another way to think about the problem at hand.
I missed your first point, which I unintentionally repeated. That's actually a general solution to a general problem: there are many techniques that deeply rely on pointer and mutable structures; they don't often have a clear functional alternative. As you pointed out, there is a functional alternative. I've been grappling with pure functional game development, and translating pointer-based solutions to problems (like updating entity data across different structures for collision detection, rendering, etc.) was a big hangup. I've kept from "bending the knee" to state as much as possible, to see how far one could take a pure approach. With pointer-based structures no longer a problem, a lot of existing game programming techniques become valid (if not desired). In some cases, there are cleaner functional approaches, and pointer emulation is not necessary. You actually highlighted a solution to a general problem. 
Even in Python such a function would return `None`.
&gt; This isn't a hack; it's an explicit way of telling both the programmer and the compiler what putStrLn can and cannot do. Ah this makes a lot more sense than any other IO monad tutorial I have seen. Thank you 
No no no! Understanding how to do this properly has been a real struggle for me. Every time I ask in IRC or something people just don't understand what the hell I'm asking! Thanks for getting the ball rolling
&gt; "a procedure that does some I/O and then should yield an a" That makes perfect sense. Thank you
I would say the `Maybe` monad is the best to start with because it's nice and simple (and very useful!). 
You might find this useful http://www.haskellforall.com/2012/08/the-category-design-pattern.html
I'll take a look
Also in ML I believe. 
I think this is a really nice explanation. 
What is the application of this? 
There's two projects you can use: objective-Haskell and language-inline-c, both can be found on github. I'll add links to this comment when I'm at my computer
Also in like all the literature except for Haskell. &gt;,&lt; too late to go back now... 
Then you don't make the list your base data structure. It will help if you describe a concrete problem that you want to solve using mutable data structures.
... which is analogous to `IO ()`.
This is very useful to find out which order elements must be drawn in a 2d ortographic game. http://shaunew.github.io/IsometricBlocks/ And it needs to be incremental because resorting 1000 elements 30 times per second is not very kind with the CPU :/
The base structure in this case should be a `Vector` (i.e. an array), provided by the `vector` library. This will store the objects of your scene. Then the nodes of both your quad tree and scene graph just reference indices within this `Vector` instead of storing objects directly. This has the effect of simulating references, where the index into the `Vector` behaves like the reference.
I'm under the impression that interfacing with OO code without high impedence is tricky.
So indeed the proper way to do this is by emulating pointers?
It may well be the case...
It seems as if we've converged on a graph based/identifier based/pointer based approach being the best.
Yes. Can you give a pointer to the introduction to monads you were reading? (You might read 10 or 20 other introductions - of the perhaps 100s - they might each illuminate a different facet, and they get progressively easier to read)
For only the last 10 years ...http://www.cs.yale.edu/homes/nilsson/HIM/Slides/Pang-DemoMocha.pdf. :)
[It seems still to be active.](http://code.google.com/p/hoc/)
Note the placement of the IO matters. For example, the type: putStrLn :: IO (String -&gt; ()) Would not work, despite also producing () for an input of type String and performing some IO. The effect must depend on the input string, so it must be: String -&gt; IO ...
How about this? (I'm using the names as in the gist) class IsProduct p where withProduct :: proxy p -&gt; (forall p1 p2. p ~ (p1,p2) =&gt; r) -&gt; r instance IsProduct (a,b) where withProduct _ k = k instance Category Uncurried where type C Uncurried a b c = ( IsProduct a , IsProduct b , IsProduct c ) cid = withProduct (undefined :: proxy a) $ Uncurried (Curried id id) :: forall a. IsProduct a =&gt; Uncurried a a (!) (g :: Uncurried b c) (f :: Uncurried a b) = withProduct (undefined :: proxy a) $ withProduct (undefined :: proxy b) $ withProduct (undefined :: proxy c) $ compose g f Edit: I just saw that ryani already proposed essentially the same thing. Maybe this is still useful, as you mentioned that you couldn't get it to typecheck; this does typecheck for me with GHC 7.6.2.
I think I read the intro to IO monad on the Haskell wiki. Since then I have started to read a bunch of new monad tutorials
&gt; Conclusion: vacuum is awesome! Except that it's not installable with base 4.6: Control/Concurrent/MVar/Strict.hs:46:8: Could not find module `Control.OldException' Perhaps you meant Control.Exception (from base) Use -v to see a list of the files searched for. Failed to install strict-concurrency-0.2.4.1 Already sent an e-mail to Don Stewart, who maintains both strict-concurrency and vacuum-cairo.
So when I solve problems like this I try to reduce the problem to the smallest pathological case possible. I will take this sentence of yours as the simplest statement of the problem: &gt; The tree-based, top-down, uni-directional approach that we get so much mileage from in FP, kind of gums up in the face of propagating bilateral changes between structures efficiently. The simplest example of the problem you describe is a cycle of size 2. In other words, something like this: x -+ ^ | | v +- y In other words `x` depends on the value of `y` and `y` depends on the value of `x`. I will take "depends" to mean that there is a function between them (in both directions): x :: A y :: B fw :: A -&gt; B bw :: B -&gt; A If we want to compute `y` from `x`, we apply the function `fw`. If we want to compute `x` from `y` we apply the function `bw`. If we want to update `x` and propagate that change to `y`, we just reapply the function `fw` to the new value of `x`: x0 :: A y0 :: B y0 = fw x0 update :: A -&gt; A x1 :: A x1 = update x0 y1 :: B y1 = fw x1 Now, the inherent problem in a bidirectional update scenario is that there is a risk of a never-ending loop of updates. After all, if `x` changes then `y` must change, but then that change to `y` must in turn trigger a change to `x`, and so on. That means we need to impose a restriction that if we start some `x`, then compute a new `y` from that `x`, then compute a new `x` from that new `y`, we should arrive back at the original `x`: fw (bw x) = x Similarly, we expect that if we start from some `y`, then compute a new `x` from that `y`, then compute a new `y` from that new `x`, we should arrive back at the original `y`: bw (fw y) = y We can simplify these two equations into the following more point-free versions: fw . bw = id bw . fw = id This means that `fw` and `bw` must be [isomorphisms](http://stackoverflow.com/questions/11245183/importance-of-isomorphic-functions), and the above two equations are the isomorphism laws. Note that I used functions between these two data structures, but it doesn't have to be functions and `fw` and `bw` can be morphisms in any category. The reason I emphasize the point-free versions of the two equations is that they work in any category (since `id` and `(.)` are defined for all categories, whereas function application is only defined for functions). So while I used functions as an initial example, don't limit yourself to thinking only in terms of functions and I strongly suspect the solution will not use functions to form the cycle between `x` and `y`. To illustrate this, let me propose a potential API but gloss over implementation details. Imagine that we have an `Update` type which represents a series of deltas to a data structure data Update a = ??? I would expect this type to be a monoid of some sort: instance Monoid (Update a) where mempty = ??? -- The empty update which doesn't change anything mappend = ??? -- Combine two updates into one Presumably, this would be an efficient representation of changes to that structure. Then we need some sort of `update` function which applies those changes: update :: Update a -&gt; a -&gt; a I want to stress that the internal representation of `Update` may not be a function at all. This is why we need the `update` function to convert this internal representation to a function when we are ready. The reason we don't want `Update` to be a function internally is that functions give us no detailed information about the individual sub-components that are changing, information we could use to optimize bilateral changes between data structures. I'd expect `update` to be obey the following functor laws: update mempty = id update (f &lt;&gt; g) = update f . update g We want to wait as long as possible before actually applying `update` because once we convert an `Update` to a function we lose important information we could use for optimizing these bilateral updates. Then we need a `Translation` data type which would be responsible for efficiently translating updates on one structure to updates on another structure: data Translation a b = ??? This would provide an efficient way to convert any `Update` on `a`s to an `Update` on `b`s. We need some sort of `translate` function that applies this conversion: translate :: Translation a b -&gt; Update a -&gt; Update b Note that `Translation` itself might not be a function between `Update`s. Again, this is because we might have additional information we want to preserve about this conversion process that a function does not preserve. I'd expect `Translation` to form some sort of `Category`: instance Category Translation where ... ... and `translate` to obey the following functor laws: translate id = id translate (f . g) = translate f . translate g Then you can imagine that our `fw` and `bw` could be morphisms in this translation category instead of functions: fw :: Translation A B bw :: Translation B A fw . bw = id bw . fw = id So I still don't have a precise answer to your question, but maybe this will give you some ideas to work with.
I'd be interested in Angular.hs because there'd be less re-inventing the wheel. FRP is a radical re-invention of the wheel, so I'm definitely interested in it in the long term, but in the mid to short term I'd say using the excellent work done by the Angular team is a good compromise. Not to mention I like the way Angularjs uses html templates. &lt;ul&gt; &lt;li ng-repeat="person in people"&gt; &lt;p&gt;Name: {{ person.name }}.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; Has a nice ring to it. My ideal long term solution currently looks like the above templates, except with type-safety (somehow), and instead of Angularjs there would be some Haskell FRP "controllers".
 -- Returns an IO action which prints the string and returns nothing. putStrLn :: String -&gt; IO ()
Yeah, that was my point, in case I wasn't clear enough.
&gt; What is the return value of something that prints to the screen? There is no useful result from such a computation. Well, conceivably success/failure.
A good way to begin is to think about how you would do this without FRP. If you present your non-FRP solution as part of the question, it will also make it easier for others to understand what your desired behavior is.
This is an excellent idea, I've edited the question to reflect this.
It's 99% that I want to specifically do it in Elm, and 1% that I want to actually learn how FRP works, since it seems pretty cool.
Assuming that you have a constant `Request`, you can do: yourRequest :: Request send (lift (\_ -&gt; yourRequest) (fps 2)) :: Signal Response That will send out that request twice a second, I think, and return the response.
Absolutely perfect! Thanks so much!
&gt; You can already force "order" in lazy and functional languages. [1] ++ [2] will always evaluate to [1,2] and never to [2,1]. Changing evaluation order never changes the value of results, except that it can cause a computation to go into an infinite loop that would otherwise have succeeded. What you're talking about is the semantics of `++`, which is unrelated to evaluation order. For example, whether you evaluate the result in a strict language or a lazy language, the result is still always `[1,2]` and never `[2,1]`. The list doesn't suck values in in the order they're computed - the order in which the values are evaluated doesn't determine the order they appear in the result list. Basically, `++` is associative but not commutative. `([1] ++ [2]) ++ [3] == [1] ++ ([2] ++ [3]) == [1] ++ [2] ++ [3] == [1,2,3]`. Evaluation order of the `++` operators doesn't change the result, let alone whether you evaluate the arguments left-to-right or right-to-left, randomly or even concurrently. One way to force different evaluation order rules in Haskell is using the [`seq`](http://hackage.haskell.org/packages/archive/base/latest/doc/html/Prelude.html#v:seq) and [`par`](http://hackage.haskell.org/packages/archive/parallel/latest/doc/html/Control-Parallel.html#v:par) functions. These don't affect the results, providing the expressions terminate at least, but things like that can have huge performance implications. The concurrency issue is significant, for example, in our increasingly multi-core world. But because evaluation order is changed, if the expressions had effects, the order of those effects *could* be changed - your prompt for input might not appear until after the user provided that input etc. That is obviously bad, and that's why it's important to have a way to order effects and to use the type system to ensure that it's handled correctly. In a way, the IO monad isn't really about ordering effects - other languages manage that just fine without it. It's about allowing effect-free computations the freedom to be not care about evaluation order, or to change that order for performance reasons, without *breaking* the ordering of effects. 
&gt; so this means that if i wanted to eventually distribute my application to multiple platforms, could i just bundle a custom web-browser with my application (say chrome) that gives me windows management, tabs, etc. for my application? Yes, exactly. The small JavaScript FFI allows you to call arbitrary JS code from Haskell, you probably need that to manage windows and tabs. &gt; in other words, it would be transparent to the user that the application is really a web browser bundled with haskell application code. At the moment, yes, but at some point, I would like to have a "native shell", i.e. a custom web browser whose sole purpose is to run Threepenny applications. See [issue #52 "Native shells and app deployment"](https://github.com/HeinrichApfelmus/threepenny-gui/issues/52).
&gt; "So you take a string and it turns into an IO object of type nothing........ Why is it returning something? I just want to print a line of text. Whats up with this silly do notation?" Returning `()` in Haskell is roughly the equivalent of returning `void` in C, C++, Java, C# etc. An action that does something and yields a result isn't really different to an action that does something without yielding a result. Instead of having two different kinds of actions, we have a standard dummy value/type. Returning `()` is the Haskell way to not return anything. It mostly turns up in monadic code (not necessarily IO) because there's not much point in a function that doesn't have either an effect or a result. 
Pipes are really cool, and the new version seems a lot simpler. 
[A typeclass with no laws](http://hackage.haskell.org/packages/archive/pipes/4.0.0/doc/html/Pipes.html#t:Enumerable) in a library by Tekmo?
[Dead for 3 years?](https://code.google.com/p/hoc/source/list)
I really like the new API. I always found `runIdentityP` and these `()`-arguments a bit messy. I would like to see more documentation (especially example code) on how to use the bidirectional API, though. Also, some combinators in `Pipes.Prelude` (e.g. `take`) should be generalized maybe to work with bidirectional pipes.
&gt; Time flies like a monad Just when you think you have monads figured out...
Don't start on your own - as Tekmo said Andrew Cowie wants to see a `pipes-http` that reuses parts of `http-streams`, and myself and Renzo are also interested in helping. We'll certainly welcome more help though!
Any of the `Pipes.Prelude` pipes can be generalized to work with bidirectional pipes by using the `generalize` combinator.
&gt; by referencing that composed expression twice, I have evaluated (and executed) it twice. What does "executing the multiplication operator" mean? I see "execution" as a term, which only makes sense with actions. And it means to cause the side effects of that action, i.e. to modify some external state. And by the way, evaluating `f a` does not mean, that `f` is evaluated again. &gt; Similarly, you have composed an expression using putStrLn as a building block. That composed expression is evaluated twice, each time (conceptually) with a different world argument. You can see `IO` as a function of type `World -&gt; (a, World)` and that also helps reasoning. But it does not explain, why a side effect occurs. After all, why should the world change only because we give it to a function, which coincidentally computes another world. Somewhere (in the runtime system) we need some code like this: world = getWorld(); (a, newWorld) = act(world); putWorld(newWorld); return a; Where `putWorld` would replace the world and so causes side effects. And that code would "execute" an IO action. By the way, this is only one possible implementation of `IO`. Others are based on CPS, an implementation based on the operational monad or free monad would also be possible.
Very very nice! &gt; STG is a lot like Core, but with some differences... Ahem. Last I heard, the syntax of Core is *still* not documented anywhere, except by reading the GHC source code. So I would say it the other way around: Here is the syntax of STG. Core is a lot like STG, but with some differences...
Fruit flies like a GUI framework.
There is a lot of discussion of `threepenny-gui` in [this concurrent reddit thread](http://www.reddit.com/r/haskell/comments/1lw9j3/what_is_the_state_of_the_union_regarding_graphics/).
Well these seem sensible: toListT (return x) = return x toListT (lift m) = lift m toListT (fmap f m) = fmap f (toListT m) I suspect that it should be a functor from one kleisli category to another, but not sure: toListT . return = return toListT . (f &gt;=&gt; g) = toListT . f &gt;=&gt; toListT . g 
You're welcome!
Many experienced Haskellers feel that regexes are inferior and should never be used. Personally, as a former Perl and Python programmer, I love regexes - I still use them all the time in one-off pipelines at the Unix shell prompt, in Emacs and Vim, etc. I wouldn't hesitate to use them in my Haskell code if I ever found a use case where they were the best solution. But in my years as a full-time Haskell programmer, I have never come across such a case. I guess one such case would be literal non-idiomatic porting of regex-based code from another language to Haskell, but I haven't needed to do that. Parser combinator expressions are just so much more semantically expressive, readable, and maintainable, and I find them much easier to write than complex regexes. Haskell has a number of excellent parser combinator libraries - why not use them?
Pretty much! :) There are the parametricity laws, but I don't think those count. I think Dan is on the right track with the monad morphism laws, but I'm not going to claim that I thought that out. The main reason I added it was just to parallel `Foldable`. This class has already come in handy for me on several occasions.
The reason why is that the idiomatic way to do this is to use `for` instead: f :: a -&gt; m () p :: Producer a m () yourCodeShouldBe = for p (lift . f) :: Effect m () However, if you still don't like that then I can add a `mapM_` in the next minor update. Also, `pipes` re-exports `liftIO`, so you can use that to replace `lift . lift` when using `pipes-safe`.
For IO, you can use the `MonadIO` instance and just use a single `liftIO`. Or you can define `lift2 = lift . lift`. But the "double lift" is unavoidable, since for many of the nontrivial Pipes idioms, you use an extra monad transformer underneath the Proxy transformer. (In the case of pipes-safe, it's SafeT).
Well there's the dummy implementation that always typechecks: toListT _ = Select (return ()) So I wouldn't be so quick to trust parametricity in this case (even if we are ignoring bottom).
That still satisfies parametricity. The relevant law I'm thinking of is: fmap f . toListT = toListT . fmap f Even that dummy implementation satisfies that law.
Oh right, I'm getting two different things mixed up in my head.
I've been very confused by this change. Wasn't the bidirectionality the big discovery that made this ecosystem so interesting in the first place? It certainly was for me...
As I understand, bidirectionality isn't *gone*, it's just kept out of the way so that you can write simpler code in those cases where you *don't* want bidirectionality.
I meant `old` as in the previous tutorial. It's definitely not deprecated. See `pipes-network`, for example, which uses `Server`s to request variable-sized chunks from `Socket`s.
It's still there and still officially blessed. I just decided to move the bidirectional tutorial outside of the package into a separate upcoming School of Haskell post. The official style guide is that you don't use unidirectional and bidirectional code within the same function, but within the same module is perfectly acceptable. If you can use only unidirectional you should, the reason being that you can always trivially upgrade unidirectional code to bidirectional code later on if you need to. See `pipes-network` for an example of this style guide in action, where it supports both unidirectional and bidirectional pipes within the same module. The unidirectional `Producer`s use `yield` and the bidirectional `Server`s use `respond`, for example.
I've been thinking about this recently, and I hate that there's a different HTTP library for pipes, conduits, enumerables, etc, when they all already have attoparsec libraries. If some time was spent polishing off [Bos's HTTP parser example](https://github.com/bos/attoparsec/blob/master/examples/RFC2616.hs) and extending it to handle chunked post and other goodies, then wouldn't all the streaming libraries benefit? Hm, looks like most of this is probably discussed in the mailing list link that Tekmo posted. I'll read through that.
Richard Eisenberg maintans a document formalizing the type system for System FC: [pdf](https://github.com/ghc/ghc/blob/master/docs/core-spec/core-spec.pdf?raw=true)
Am I missing something, or is this difficult to use? For a large and complex set of data types - which is a prime candidate to need `NFData` - wouldn't this require wrapping every non-leaf component of every data type in `Once` and then refactoring the entire code base to sprinkle `once` and `runOnce` all over the place? As tibbe and others said, I try very hard not to use the sledgehammer of `NFData` at all. But recently I had a case where I did need it, and it seems that those kinds of cases are exactly when `Once` would be impractical.
Thanks, that is very helpful.
I'd just like to add to what's already been said that the fact that IO happens to be a monad is secondary to the fact that IO actions are values. We're not "using monads" to describe what input and output is to take place, we're using something which *just happens to be* a monad, and that just says something about what kinds of ways we can combine IO actions, but the monad part is a tiny fraction of the stuff which is available in IO, and doesn't really tell you very much about how it operates or what can be done with it.
Good point. Thank you
If I was solving this problem I'd cut the Gordian Knot with a z-buffer, so that it doesn't matter what order I draw in. Almost all modern hardware handles this extremely quickly.
I thought this was going to be about the `RegularPatterns` extension (a.k.a. [HaRP](http://hackage.haskell.org/package/harp)): partitionEithers [(Left ls | Right rs)*] = (ls, rs) Unfortunately I don’t know how to actually use that implementation—or whether it’s even possible anymore—but it seems incredibly useful as far as syntactic improvements go. 
I'm new to this library, but the API looks very intuitive to me and liked it. It also has a nice tutorial. As long as you have experience with monad transformers, it does not look too difficult. What's the difference between pipes and conduit? Are there any features you are still to implement in pipes?
Sounds promising. And if one wanted to write straight HTML instead of with combinators that would just require a simple template library on top. Since cabal sandboxes lower the difficulty of getting libraries to compile I think I'll have a play with threepenny. I'm fed up with inferior cross platform GUIs with non native looks so I think I might be just the target audience. Edit: regarding incremental updates, Angularjs currently has to do dirty checking to make sure that things have actually changed. A place where a Haskell solution could out-shine it is using [computed properties](http://emberjs.com/guides/object-model/computed-properties/) like Emberjs without the horrid syntax.
All the core features are done. Everything else is just a library on top of the core `pipes` implementation. There are two kinds of differences between `pipes` and `conduit`s. First, there are differences in features: * `pipes` permits bidirectional communication * `pipes` interconverts with `ListT` * `pipes` permits two additional ways to connect pipes (i.e. `for` / `(&gt;~)`). Then there are differences in idioms: * `conduit` uses `Maybe` to signal end of input. `pipes` instead uses functions of `Producer`s to detect end of input * `conduit` has separate mechanisms for leftovers vs connect-and-resume. `pipes` uses the same mechanism (`StateT`) to handle both. * `conduit` groups substreams by concatenating them. `pipes` groups substreams using `FreeT`. Then there are theoretical differences, like the fact that `pipes` has a very high emphasis on structuring the API along category theory and satisfying the relevant theoretical laws. These laws keeps the library "honest" and what gives the library its intuitive feel.
I would love to see a modern overview of STG as a whole with the tagging modification and the removal of vectored returns, and whatever else has gone into GHC since those.
gtk2hs is indeed a decent GUI library. I've had good success using it under linux. However others seem to have problems with installation on OSX and windows. I don't thinks there any fundamental problem there - it's just that a fair bit or manually fiddling is required.
This is no coincidence. Alex Stepanov who wrote the C++ STL studied and understood functional programming (which can't be said about most other C++ gurus).
Thanks for the plug :-). But I'm as frustrated with C++ as the next guy.
Works for me in GHC 7.6.3. http://pastebin.com/jt8jCw9k
Just use Lua everywhere.
Nobody here has explained yet what the IO monad actually *is*. First it's helpful to review the State monad: newtype State s a = State { runState :: s -&gt; (a, s) } instance Monad (State s) where return x = State (\s -&gt; (x, s)) (State m) &gt;&gt;= f = State $ \s -&gt; let (x, s') = m s in runState (f x) s' Semantically, you can think of this as performing a computation (the "monadic" computation, i.e the thing that returns "x") while keeping some "mutable" state around. (In reality the state is not actually mutable, this is just a wrapper around function application). You can see an example of this by bringing up ghci: Prelude&gt; import Control.Monad.State Prelude Control.Monad.State&gt; let m = (modify (+1)) :: State Int () Prelude Control.Monad.State&gt; runState (m &gt;&gt; m &gt;&gt; m &gt;&gt; m) 0 ((),4) So what is IO? In some sense you're correct that it **is** a "trick", but once you understand the State monad the trick becomes clear. newtype IO a = IO (RealWorld -&gt; (RealWorld, a)) (btw the actual type is slightly different due to unboxed types/tuples but this will do for now). This is isomorphic to the State monad! So what does it "mean"? An IO action is a *function* that, provided with a copy of the "real world", produces a new modified "real world" plus a "monadic result" (the "a" in "IO a"). Who can produce values of type "RealWorld"? Well, nobody. It's a token used for book-keeping, and in fact the compiler has a pass that removes RealWorld values from computations before the final compiled machine code is emitted. Semantically you can think of side-effects happening because you're producing a new "real world", but the formulation is only there to ensure that computations on the right-hand side of the monadic bind depend on the results of the left, so that side-effects (like printing a line to stdout) happen in the order that you specified them. tl;dr: think of a value of type "IO a" as a **function**, that when "executed" by the runtime system, produces a value of type "a" plus a modified world.
By ship code you mean an so/lib you could use [Gambit Scheme](http://en.wikipedia.org/wiki/Gambit_(scheme_implementation\)) and generate C code.
Don't. If you need a GUI, make a front-end in python and communicate with a Haskell back-end via socket, d-bus, or whatever. State of Haskell GUI bindings is too sad for practical use; you'll waste too much time and achieve nothing.
&gt; monads, if you do functional programming long enough, you will invent them on your own I guess this must mean pure functional programming. Lisp and ML programmers didn't invent them, after all.
&gt; And if one wanted to write straight HTML instead of with combinators that would just require a simple template library on top. Yup, pretty much, though you have to use `getElementById` or similar to get access to the elements after they have been instantiated. &gt; Since cabal sandboxes lower the difficulty of getting libraries to compile I think I'll have a play with threepenny. Let us know what you think. :-)
That'll work. Thanks.
&gt; The operator is code. Code is executed, or translated to another form which is executed. Executing code is how expressions are evaluated and results are computed. I think you use "execute" and "evaluate" differently from the standard explanation of `IO`. Here's the explanation I heard: 1) Any expression can be evaluated and you get a literal as a result. Evaluation is always pure (disregarding unsafe*). Lambdas are evaluated by leaving them alone; they are already literals. The expression `if 2 + 2 &gt; 3 then \x -&gt; 4 + 1 else \x -&gt; 5 + 1` is evaluated to `\x -&gt; 4 + 1`. The condition `2 + 2 &gt; 3` is evaluated, but `4 + 1` is not. A value of type `IO a` is evaluated to one of three IO literals: (a) `return x`, where `x` is a literal (b) `x &gt;&gt;= f`, where `x` is an IO literal and `f` is a lambda (c) a name of a primitive IO action such as `getLine` 2) Any expression of type `IO t` can be executed. Execution is similar to calling a function in an imperative language: it can perform IO and returns a value of type `t`. To execute an expression, first evaluate it and then depending on the literal (a) For `return x`, do no IO and return `x` (b) For `x &gt;&gt;= f`, execute `x`, getting a value `x'`. Next, execute `f x'` and return its result. (c) For primitive IO actions, the behavior is built-in. 3) To run a Haskell program, (evaluate and) execute the expression called `main`. There are some rough edges here; for example, I assumed the language is strict, but for purposes of explanation they do not matter. With those terms evaluation is pure and decoupled from execution. From evaluation you cannot go to execution, while from execution you can go to evaluation.
Thank you. 
ML programmers don't have the benefit of higher-kinded types, so popular monads like State and Reader don't come as naturally as they do in haskell. Not that you *can't* implement these monads, but it's far easier to go impure, as you mentioned. 
and webkit ;)
You're welcome!
The second question, in the Edit, suggests you want a pipe that will print but then and reforward whatever your producer is yielding? (Else blah yields an indefinitely long series of `()`'s). In that case I wondered if `Tekmo`s yourCodeShouldBe = for p (lift . f) :: Effect m () answers everything, since it's an Effect. You can also use `for` to tag something onto a producer, while keeping it a producer. So for example the following represents a `String`-forwarding variant of your `blah` but then the same thing expressed with the `for` locution, I *think* competently import Pipes import qualified Pipes.Prelude as P import Control.Monad import Pipes.Safe import Pipes.Safe.Prelude as Safe -- without 'for' blahpipe :: Pipe String String (SafeT IO) () blahpipe = forever $ do str &lt;- await liftIO $ putStrLn str yield str a :: Producer String (SafeT IO) () a = P.stdinLn &gt;-&gt; blahpipe aa :: FilePath -&gt; Effect (SafeT IO) () aa file = P.stdinLn &gt;-&gt; blahpipe &gt;-&gt; Safe.writeFile file aaa :: IO () aaa = runSafeT $ runEffect $ P.stdinLn &gt;-&gt; blahpipe &gt;-&gt; Safe.writeFile "blah.txt" -- with 'for' blahsimple str = do liftIO $ putStrLn str yield str b :: Producer String (SafeT IO) () b = for P.stdinLn blahsimple bb :: FilePath -&gt; Effect (SafeT IO) () bb file = for P.stdinLn blahsimple &gt;-&gt; Safe.writeFile file bbb :: IO () bbb = runSafeT $ runEffect $ for P.stdinLn blahsimple &gt;-&gt; Safe.writeFile file
Yeah that was a typo. I had a custom function in place of putStrLn and changed it before I posted. I constantly make mistakes like that which is probably why I'm attracted to strong types systems. For function is something I messed with but I'm still a little weak on what can be plugged into it, but after screwing around with it a bit I'm getting the hang of it.
This explanation of `IO` falls short on close investigation. It is okay from an implementation perspective, where the 'RealWorld' passing creates data dependencies that make primitive, side-effecting functions happen in the right order. But it cannot be used to actually make sense of even some basic `IO` operations (like, `forever (putStrLn "hello")`).
Oh, I misread your question the first time. To discard a pipe's output, use `for` + `discard`: for p discard
Many of the links on that page are file:// URIs.
Cabal is a software coming with haskell-platform.
Agda compiles to Javascript.
Two reasons: * dependencies on build tools don't work very well yet * we're not so sure that it's a good idea for packages to over-constrain their dependencies to a specific haskell-platform version The first should be solved eventually. For the second we may decide to warn or ban dependencies on specific versions of meta-packages, and/or see if we can find better alternative solutions.
rather than keep bugging you with questions in the other [thread (what is the state of the union regarding graphics...)](http://www.reddit.com/r/haskell/comments/1lw9j3/what_is_the_state_of_the_union_regarding_graphics/), i figured i'd move them here. :) what would be the possibility of integrating javascript libraries into threepenny-gui, or should that be the job of some separate library that wraps the library in a more haskell-like manner, or both? as i've mentioned, i'm new to haskell, so i apologize if this has a rather obvious answer. since you mentioned your project, i've been thinking a lot about what do to regarding nice graphical libraries in haskell, and beyond diagrams and gloss, there aren't any. however, in the javascript world, i've discovered the absolutely amazing [Raphael](http://raphaeljs.com/) and [Paper.js](http://paperjs.org/). these tookits are exactly what i envision needing, and given that your framework is centered about the browser, it seems libraries like these are a perfect fit for the use case of graphical UIs. i know you mentioned possibly integrating the diagrams package sometime in the future, but these two libraries seem way beyond what the diagrams package offers. in fact, i disagree with the other poster in this [issue thread](https://github.com/HeinrichApfelmus/threepenny-gui/issues/22) since drawing on a canvas is exactly what i want from a gui framework. i basically would want to able to build something like [meemoo](http://meemoo.org/) or [noflo](http://noflojs.org/), but with haskell.
Great explanation, thanks for going into detail about monads and how they relate to the IO monads.
And let's not forget that now Snap.Snaplet.Test's functions (e.g. evalHandler) takes as input the environment as well, which is quite a boon if you need to test a handler with a different configuration based on the environment (e.g use a different db)
I wonder how many people there are in the world that would get this joke. 
Nice. I'm glad that compiled Heist has been reorganized for clarity. I really like Heist's clear separation of presentation and logic, combined with the efficiency of compiled templates. But I took me a while to wrap my head around the old compiled splices API.
No, it doesn't: &gt; Note: Most people already have Cabal because it is included in the Haskell Platform. From [cabal itself](http://www.haskell.org/cabal/download.html) Edit: This is a reply to "No, it doesn't, cabal comes with ghc binaries"
I definitely think any such package would be a convenience package. Depending on it would be very foolish.
I'd like to add that sequencing in imperative languages is also not as trivial as it looks. A compiler is free to reorder statements as long as it can *prove* they have no side effects. Incidentally, this is a huge problem in concurrent programming, where (for instance, in C++) the compiler has no idea about inter-thread side effects and can use optimizations that break concurrency (you have to use atomics or locks). Usually there isn't that much reordering in imperative languages because every function call is considered effectful, so code cannot be moved around it. In Haskell, the compiler *knows* whether a function has side effects or not. It knows it from its signature. Functions returning `IO` may have side effects. And there is no way of calling an IO function from a non IO function. Knowledge of side effect is essential in the implementation of Software Transactional Memory (STM), where the execution of concurrent code may be aborted and then retried. If that code had any side effects, every retry would repeat them, launching nuclear missiles over and over again. Since the compiler knows about side effects, it will not allow IO inside STM. 
Threepenny has a small [JavaScript FFI](http://hackage.haskell.org/packages/archive/threepenny-gui/0.3.0.0/doc/html/Graphics-UI-Threepenny-Core.html#v:ffi), so you can call arbitrary JS code. Have a look at the source code for the `JQuery` and `Canvas` modules and the `driver.js` support file. Keep in mind that all this is still quite experimental, but it works if you really need to bind to that JS library right now. When it comes to binding external JS libraries: I have put all my eggs into the Haskell basket, so personally I would try to write a Haskell equivalent rather than binding to a JS library (also because the binding will likely feel alien in Haskell land). Concerning graphics libraries in particular, I would be surprised if diagrams can't already do most of what you want (though the current examples may not be as flashy).
Yeah, I mentioned it.
Some of the comparison here is still valid: http://www.yesodweb.com/blog/2013/02/upcoming-conduit-1-0 In terms of broad use cases (rather than specific code) that only one library fully supports: pipes * bi-directional communication conduit * connect-and-resume * early resource finalization I am assuming pipes has a better story on exception safety now, maybe some other points have changed.
In two words, what are main differences and advantages of H2 over H1?
I think it only needs one word actually "maintainability". Meaning that the thing is now structured internally such that we can maintain and extend it with new features in a sane manner. The old server is a bunch of cgi scripts and it stores all the data in the file-system in rather ad-hoc ways. This makes it very hard to extend or to do things like atomic data updates. This then leads on to a whole bunch of other advantages and differences like more features, better security, easy deployment, REST API, etc.
`haskell-src-exts` supports it, I think.
`pipes` supports connect and resume using `pipes-parse`. See the `input` combinator and the example in the haddocks to learn how to use this. `pipes` also supports early resource finalization using `pipes-safe`. See the `runSafeP` function which lets you finalize the enclosing `SafeT` block without exiting from the pipeline.
FYI: user self signup is currently not working while we sort out local email on the new VM. Details: we're using ssmtp to relay outbound mail to the main haskell.org smtp server, but that's currently configured to reject all relaying. The haskell.org infrastructure team will sort it out for us. **Update**: fixed! Thanks to johnw from the infrastructure team.
What db are you guys using? Postgres? 
The haddocking seems slightly off, yes. See the omnibus haddocks for all or much of the just released material at http://monoid.k0001.org/haskell/Pipes/ where the links to hackage stuff seems to be working.
I saw it! I've just had a little play doing this - just enough to open a window and make it red. How far did you get? Could we collaborate on this?
Since the words 'formally verified kernel' don't make any more sense than 'formally verified kitty litter', one hunts for what they did verify; five propositions are mentioned, some interesting e.g. "no tab can ever affect how the kernel interacts with another tab". Given the hideous character of the .v files, I wish all good luck convincing themselves that this is what anything proven actually means. 
We gained 3 readers in 3 hours!
With cabal-install 1.18 you can have an optional `cabal.config` file in the same directory with your `.cabal` file for customising per-package and per-sandbox settings. For example, the following `cabal.config` is an equivalent of a lock file: constraints: dependency-a == 1.0, dependency-b == 2.0 I need to write a blog post advertising this feature a bit more.
That would be great, please blog about it! I will try it out when I get a chance. That means instead of writing to a lock file we could write to the cabal.config and then we would not bother to read the lock file back in and pipe it to cabal since cabal would use the constraints automatically. I never add a per-project cabal config file, so for me just adding a single constraints item would work, but it would take some more effort to make it work with any existing cabal config file. For example I see absolute paths in my user config and sandbox config which means I can't check them in. But probably this is the way forward to get this functionality into cabal.
Great work, the API is super slick. Thanks for the help generalizing pipes-safe, it works rather nicely! I've been using the pipes-parse approach to do some buffering, I'm guessing it would work in general for parallel processing with pipes. Oliver
Best gift ever.
&gt; For example I see absolute paths in my user config and sandbox config (that cannot be checked in). The idea is that `cabal.config` holds things like `constraints` and `flags` and gets checked in the source control, while `cabal.sandbox.config` holds sandbox-specific configuration (absolute paths etc.) and is ignored by source control.
this book is the shit. Hideo Kojima signed my copy. http://i.imgur.com/rqkBSm0.jpg
For anyone interesterd, [here is a link directly to the FNIStash landing page](http://fluffynukeit.com/?page_id=535), which has a youtube video tutorial showing the program in action. Edit: As I mention in the blog post, I hope to write a post-mortem analysis of my experiences as a Haskell newb. If anyone has any specific questions or concerns they'd like me to address in my (eventual) write up, post them here and I'll do my best to accommodate.
that's so cool! I've heard a lot of things about it, so i cant wait to get started!
Is there some relationship between Hideo Kojima and Haskell? Or was it kind of a 'why the heck not' sort of idea? Which would be totally cool by the way ;).
I'd like to know as well, but I also know what I'll ask him to sign if he does another uniqlo tour.
Oh, I was also wearing a Haskell t-shirt at the time.
awesome, Cabal just needs an API where I can overwrite an existing constraints field in a cabal.config hen. Hopefully you will tell me that exists also :)
indeed. Marketing copy for those who know nothing. 
Fwiw, I simply install the binary releases (e.g. http://www.haskell.org/ghc/download_ghc_7_6_3#binaries) as that allows to have multiple GHC versions installed in parallel for testing. But it would be convenient for me to have a simple way of just `cabal install haskell-platform` in a cabal sandbox for testing purposes (as I don't want the platform installed globally).
This book is **the best** programming book I've ever read. It's insanely well-done and polished. Plus Haskell is nice too :)
Thats actually pretty cool, makes me wonder if you could set it up as some kind of service to people could trade and advertise items they have to others.
Very excited for you. This was the book that got me into functional programming in general and it's opened all sorts of doors for me professionally. Let us know if you have any questions!
Probably because it's not (yet) being pounded by people installing and updating packages.
A few months ago I was reading that book on the subway in New York, and a guy across from me says, "Haskell, all right! You're a programmer, I take it?" I was impressed that he even knew what Haskell was, but it happened just as the subway was pulling into my stop so I didn't get a chance to talk to him more. Excellent book, by the way. I was just reading through it the other day!
Looks like acid-state...
I think it's probably because it's on a rather faster box, and it's on the other side of the Atlantic.
Right, the `cabal.config` is an important new mechanism that will allow several different features. I expect that over time we'll add new UI features that use this, and a good candidate is indeed the "freeze my deps" use case (it's been requested many times).
For someone used to python generators, this vocabulary makes things much more simple. I am eager to see the ArrowChoice-like instance back, though. Also, some more very basic tutorials would be greatly appreciated, especially related to StateT, like keeping a state in one pipe or sharing it for a few pipes in a longer chain, etc. Apart from this, the tutorial is great as usual, even for far-from-expert haskellers like me.
As you mentioned 'the most obscure', was part of the reasoning for getting it that it kind of looks like a hipster elephant on the cover? Welcome to the cult :P
Example code is [here](https://gist.github.com/nh2/6505995)
Welcome! I'm also interested in that graph theory book - how do you find that? I don't know any graph theory, so I'm in the market for a good introduction to the subject.
I want to thank you again for jumping in at the right time and helping with threepenny-gui, I don't think I would have had the courage to take over Ji all by myself.
You mean overriding `build-depends`? No, that's not possible ATM.
...how would you generate the constraints list? (Is there a simple way without using a custom `Setup.hs`?)
The idea is that you write `cabal.config` by hand and place it under source control. There is no support for generating the constraints list automatically yet (although this would be easy to add - just parse `dist/setup-config` and pretty-print `configConstraints`).
What is the period of time covered by the "top downloads" data?
This looks pretty cool! Couldn't you just generate the appropriate structure (perhaps to a free monad) using attoparsec and provide an interpreter to run it - how do the internals work currently?
Looks interesting! Can you generate this from existing code? It might be a great teaching tool.
Hey... that's hardly obscure enough. This is obscure: [Murach's OS/390 and z/OS JCL - amazon link] (http://www.amazon.com/Murachs-OS-390-JCL/dp/1890774146/ref=sr_1_1?ie=UTF8&amp;qid=1378805568&amp;sr=8-1&amp;keywords=jcl)
I don't want to be rude, but is this some new kind of April 1 joke? I mean, you seriously think that this is easier to read or write, for *anyone*, including beginners, than the native syntax?
It has to be. Although, I wasn't sure until I read "concise".
It's a Dover book. They publish a huge number of inexpensive paperback versions of classic books from several fields. They're pretty well known particularly for their [science and math titles](http://store.doverpublications.com/by-subject-science-and-mathematics.html).
Of course. As I said, it's a trick; the side effects are not modeled inside "RealWorld", it's just an empty token. Providing a denotational semantics for IO (which is what you're getting at) is not possible without providing a denotational semantics for all of the primops. I do, however, find this explanation helpful for understanding the *operational* semantics.
Yes, I have some Dover books - I was wondering more what /this/ book is like :)
Extra points if you pushed up you glasses, took your pipe out of your mouth and said "it's not very mainstream, most people haven't heard of it" :-)
This is clearly a joke.
Have you read Okasaki's Purely Functional Data Structures, yet? It's not an introduction, but it's a joy to read.
It's only the most obscure one the friend could find.
I wish I was given that book when I was 17... 
No, thank you for taking the reins! Ji was the only GUI package that I could get to work easily on Windows. Super excited to see it growing.
Which one is the other side?
Super excited too! Good job guys!
You won't regret this, Haskell is awesome. Do you want to use it as your main language?
For me, it's SICP.
Well, should it turn out that you actually don't like Haskell all that much, you can still look at the funny pictures!
I wouldn't use the word "joy". It's incredibly informative but his coding sample style is awful (no meaningful names) and the book is really dense. By contrast, Learn you a Haskell is much more playfully written and actually readable. 
A few years ago I tried explaining to a Chinese friend who was in an advanced English slang class that saying something is shit means it's terrible, but if you say something is *the* shit, then that means it's great. It was almost as if I could see her brain seizing up in a "This does not compute" fashion.
Completely unrelated to the article... On your product page reconsider having the tour guided by a narrator, instead of that annoying background (actually foreground) music.
no, I don't need to override build-depends. I need to automatically generate the constraints in the cabal.config every time the user installs. So the first time the user install it will write out constraints. When they add a new dependency the constraints must be written out again, but must overwrite the existing constraints.
The new haskell.org VMs are hosted on a machine in Germany. The old hackage box is hosted by Galois on the US West coast.
Yes, it's down. Admins are aware and sent in a reboot request to our host.
Thanks for your reply. Do you know if there are any mirror sites for the binary distributions of GHC? I found the haskell platform source at lambda.haskell.org/platform
World revolution, one question-exclamation mark at a time.
Well one is a phd paper and another is an "intro" programming book. Two extremely different audiences. Still I agree with you :)
Incredibly funny, mind bending and insightful book! It's a great way to learn haskell. I also love the pop culture references contained in its pictures.
Oops...misread your post as "How **did** you find that?" :)
Why keep the quadtree updated? Could just rebuild it after finished updating the scenegraph.
Do compiled and interpreted splices work together? Digestive-functors-heist for example seems like it is only interpreted? Does that mean I can't use compiled heist if I want to use df-heist?
The community is free to provide you support - or not.
I'd rather have us not go down regularly :-P
I was wondering how one would go about finding a job that uses functional programming?
Prefixes are ridiculous too. Like pro- is the opposite of anti-, re-, etc. but then words start with pro that have nothing to do with the prefix (eg. program). English also has an unnecessary number of synonyms.
Just wanted to point out that this book is available online, free. [http://learnyouahaskell.com/chapters](http://learnyouahaskell.com/chapters)
I will try this again: I don't think the constraints is going to work as it currently stands because it was designed to be manually edited by users. We need a field that can be re-written by an automatic tool.
A close second.
It is. I purchased the book as well.
Does this mean that the Riemann hypothesis has been proven?
pssh, i've got two 390/JCL books on my office desk as we speak :)
Investment banks.
The term is 'interrobang'. :-)
I used functional programming to write the backend of a real time game (erlang in my case). I am working on something now that would let people make games in Haskell. They jobs are coming and they don't have to be investment banks. I know of several gaming companies, several internet companies, and a few database companies that use functional programming on the backend. Or, you could also blaze the trail. In my case, there was no functional programming at the company I used to work until after I got there and demonstrated the utility for what we were doing.
&gt; games in Haskell Is it actually fast enough?
Do we? I've only ever met 2, and I'm a Computer Science student in Cambridge, I was expecting there to be lots.
[Nope](http://www.reddit.com/r/haskell/comments/1lob2e/fp_complete_official_launch_announcement_for_fp/cc1rz52)
I just wish I could have said "Haskell? HAHAHA. Don't be silly, that's so 2000s. This is Idris"
You don't necessarily *need* to use monads to guarantee the single-threaded sequencing of computations. For example, the type system for the [Clean language](https://en.wikipedia.org/wiki/Clean_%28programming_language%29) supports [Linear Types](https://en.wikipedia.org/wiki/Linear_type_system), a technique that lets you guarantee that values are only used once, in a sequential fashion. Its pretty neat, and you can use syntactic sugar to hide the "World" parameter that you are threading around. The reason Haskell ended up using monads is because they didn't require big changes to the type system, are very general (lots of things can be monads), and play well with Type Classes (you can write generic monadic combinators like "sequence" or "&gt;=&gt;")
Agreed! The chapter on implementing datastructures by analogy to number systems was a blast, in particular.
Single player or multiplayer, so yes, rampant multiplayer cheating is possible. There are some in-game checks to detect cheating and visibly flag the player for it. I don't think FNIStash in its current scope is likely to trigger any of them, though.
Ah, OK. We need to agree on UI, but this also should be doable.
Hey another 17 year old haskeller! Might I suggest joining Haskell-Cafe, a very nice mailing list and stack overflow has lots of people willing to help new haskell programmers.
Please see the other discussions for existing commentary: http://www.reddit.com/r/haskell/duplicates/1m3xa0/extensible_effects_an_alternative_to_monad/ Including a previous post to /r/haskell: http://www.reddit.com/r/haskell/duplicates/1m3xa0/extensible_effects_an_alternative_to_monad/ The previous discussions seemed to give the idea a lukewarm reception.
I've just written a program, [cabal-constraints](https://github.com/benarmston/cabal-constraints) which uses `dist/setup-config` to spit out a list of all dependencies for a build. It's only a couple of hours old so expect some rough edges, but it does more or less what you want. https://github.com/benarmston/cabal-constraints
Well, that depends on what you mean by "work together". You can have both compiled and interpreted templates in the same application. (Just call the compiled or interpreted rendering functions.) However, if you call the interpreted render, none of your compiled splices will be available. On the other hand, in compiled mode, you do have access to some manner of interpreted splices. The restriction is that these "interpreted" splices don't run at runtime (because that's what was slow about interpreted mode). They run at load time, which is why we call them "load time splices". The newest version of digestive-functors-heist supports moth compiled and interpreted modes. Just import the appropriate module.
&gt; A lambda isn't evaluated to a single concrete value, it remains the expression. I wouldn't call that evaluation myself Are you saying that it's odd that something evaluates to itself? I insist it's definitely not odd. If we want to define what does it mean to evaluate "x+y" we say it means: evaluate x to a literal, evaluate y to a literal, and add the results. With this definition, evaluating 2+3 means we need to evaluate 2 to 2 and 3 to 3. Likewise, in "f x" we will evaluate "f", probably to a lambda, and it is possible "f" was a lambda already. &gt; If 99.9%+ of your program has been lumped together and bypassed by the evaluation because its root lambda was "evaluated by leaving it alone", I don't really think it means anything useful to say your program has been evaluated. Correct, whether "main" is evaluated is usually a dull question. The interesting thing is whether "main" is executed, what are expressions that have to be evaluated during execution of main and what do they evaluate to. &gt; With my definitions, parts of the program are pure and have well-defined meaning. [...] Other parts, which are clearly identifiable by their static type, are impure. Since we don't agree on what "evaluation" means I'm not sure if we will agree on "purity". But let me try. I assume you identify that a part is impure from the fact that its type contains IO. This is a good heuristic, but in full generality, I think it's not correct. Consider f :: IO String f = getLine Is `f` pure or impure? If your program is main = seq f $ return () then `IO` in the type of `f` is bogus: `f` could as well be a number. If your program is: main' = f &gt;&gt; return () then `f` might be called impure (although I dislike this, because I'm saying purity technically depends on whether you evaluate or execute, _not_ on the expression). Also think about `main = return f` and `main = join (return f)`. If evaluation and execution are the same notions, it's not clear to me how you distinguish such situations, that you can always use equational reasoning, when do side effects occur etc.
This book is not obscure at all :/ 
It's cropping up in surprising places. My company uses it to generate C for embedded systems. 
Internal Server Error for me. EDIT: All better.
I'd be interested to hear how you find working with `threepenny` specifically - I've not yet had chance to play with it myself.
I've definitely used some "antigrams" in my time. Too bad nobody would know what I meant if I used that word :(
They are having some issues. Refreshing gets through eventually.
that is awesome, where were was that a couple of days ago! It still doesn't work in the general case at the moment though. Even if it could automatically overwrite constraints, constraints was not designed for automated version freezing (someone might manually put in some constraints and then this would override it). Help get this implemented in Cabal: https://github.com/haskell/cabal/issues/1499
Right now I do mostly java and python, but got into functional programming with a little clojure. I want to use the crap out of Haskell, so I hope it can be my main language!
I haven't gotten into it yet, but it came recommended on #math! (Or ##programming, I forget :p) It was around $6 so I got it as a gift to myself!
A subset of the readership of /r/haskell would now.
See also "bollocks" vs "the dog's bollocks".
When I try :k Cofree Declaration String in ghci it says: &lt;interactive&gt;:1:8: Expecting one more argument to `Declaration' In a type in a GHCi command: Cofree Declaration String ? Also, what does the `:&lt;` symbol mean?
Very nice, and very fast! Two questions: 1. The accounts page mentions getting a new account added to the package uploaders group. How would one go about doing this? 2. Is the rule about real names still in place?
We need more (haskeller) meetup in Cambridge, we're more than 3
&gt; Are you saying that it's odd that something evaluates to itself? In the case of a lambda, definitely yes. A lambda is a function. Ever since my math lectures at age about 12 or 13, I've been told that defining a function is different to evaluating it - that evaluating a function gives the result, not the definition. Of course there's a sense in lambda calculus where I can evaluate an expression to get a lambda. Making my point, I probably come across as some kind of insane pedant. However, in that spirit of insane pedantry, I prefer to think of that as a potentially misleading metaphor. Unless you're writing a compiler, you can't evaluate a lambda to a concrete value - and if you *are* writing a compiler, even `+` is strictly a data constructor or code generating operator, not an arithmetic operator. Mathematicians are famous for claiming to be formally rigorous, yet systematically abusing notation. Or rather *almost* systematically abusing notation. As long as you know what you're doing it's fine, but in my experience, when you tell people that evaluation and execution of expressions are separate, they *don't* know the limits of what you mean by "evaluation". In fact you yourself previously asked me "what does it even mean to execute `+`?", or words to that effect. Well, if that `+` is buried in a lambda, it won't be evaluated in that earlier decoupled evaluation of yours anyway because the lambda will be evaluated to itself (with everything inside unchanged). So the idea of execution of that `+` must have meaning, and must include what most people would consider evaluation of that `+`. &gt; Correct, whether "main" is evaluated is usually a dull question. So what's the point of defining "evaluate" in that way? If it was the way most people, or most programmers, or even most mathematicians use the word "evaluate" - fine, we can't expect all word definitions to be useful in a niche. But Haskell seems to have created it's own definition of "evaluate" for the specific purpose of explaining the IO monad - purely in order to make the claim that evaluation is pure. What's the point of that? What's the point of claiming "evaluation is pure" if the definition of "evaluation" you use takes all the substance out of that claim? &gt; Is f pure or impure? Yes, it's impure. Not conditionally, it's *always* impure. The question is whether that impurity is ever expressed and, considering that expression in isolation, that must be a referentially opaque issue - it depends on the how the expression is used. &gt; although I dislike this, because I'm saying purity technically depends on whether you evaluate or execute, not on the expression I don't say that. I say the impurity is expressed when you evaluate/execute the subexpression, or more precisely the primitive IO actions contained in that subexpression. An expression that has the possibility of expressing impurity (as indicated by its type) is (formally) impure, though it may still be pure in practice. If you wrap that expression in a larger expression that has a non-`IO` type, that larger expression is (formally and actually) pure. Even if you use `unsafePerformIO`, provided it was used correctly, the larger expression may still be referentially transparent in the sense we care about, with any internal "impurity" considered in much the same was as the mutation of system RAM and caches, or the use of virtual memory (which also involves doing I/O without the type system knowing about it). Obviously, if you use `unsafePerformIO` badly, the expression may be formally pure but actually impure. Side effects potentially occur when you evaluate an expression that has an `IO` (or similar special) type. Whether those side effects actually occur depends on the details of the expression, arguments and closure - there's a potential halting problem issue if you want to know for certain. A pure expression can have an impure subexpression. Provided you don't abuse `unsafePerformIO`, the type system tells you whether you've prevented that impurity from ever being expressed or not. To be honest, I think "pure" is a bad word - it brings intuitions along the lines of contamination which don't always work. Then again, "referentially transparent" brings similar intuitions - how can an expression be transparent when a subexpression is opaque? Possibly a term based on safety would be better. We all know that a safe machine can have dangerous parts. The internals of my PC power supply could kill me even when the power has been disconnected for some time, because of those huge capacitors. But those internals are internal - contained. Of course analogies are often misleading past a certain point anyway. 
How about &gt;When using pure functions it's much more likely you will get stack overflows than segfaults ;D
Please, explain more?
I addressed some of this guy's concerns (regarding exceptions, records, and haddock) in the comments there. He's been able to understand the essence of monadic IO pretty well (his explanations make much more sense than of a typical beginner), and still he finds IO in Haskell hard.
Though, this post is 3 months old. The author chose OCaml eventually.
It seems somewhat bizarre that you have chosen YAML as your format, yet neither your production or consumption of this actually use a proper YAML parser. In other news, I'm personally solving this problem by using Nix - all my projects now have a default.nix which specifies all the dependencies, so whenever I `nix-shell` to begin work on a project, I know what environment I'm in. It does the job, but this might scale better. Good work either way! 
To be fair, lazy IO *is* hard to reason about.
$6!? I wish I could get maths book that cheaply. Are those IRC channels? I could do with hanging out in more "general" channels, so maybe I'll see you there :)
This is great! Really awesome to see Haskell being used in the "hobbyist" space. And I use that term in the most positive sense. Things like this are exactly what Haskell needs imo to move out of the academic/industrial realm and into the general purpose realm where it belongs.
Did `lookupEnv` get added after the post? Because it appears to do what he wants: &gt; I want to do a getEnv operation and return Nothing if the variable isn’t set. 
http://www.haskell.org/ghc/docs/latest/html/libraries/base/src/System-Environment.html#lookupEnv
To be fairer, the author didn't have any lazy IO problems. He had trouble with the basic distinction between IO and pure values (“oh I have to use `mapM` instead of `map`”).
[You posted the wrong link to the previous discussion in /r/Haskell](http://www.reddit.com/r/haskell/comments/1j9n5y/extensible_effects_an_alternative_to_monad/).
1. We still need to sort out a set of admins, though we've had some volunteers. For the beta for now you can ask edsko or myself. 2. Still to be decided. There was some discussion of this on the cabal-devel list between the people who volunteered to be admins.
&gt; Haskell &gt; &gt; Wow. I have no idea how this works. We've all been there! :-)
Not sure what you mean. Could you elaborate?
A lot of people program Haskell with their text editor of choice because large scale IDE features are not needed that much. Recently, FP Complete has release a [cloud IDE](https://www.fpcomplete.com/) if you prefer a zero-setup solution. ~~I don't like their terms of use, though, it sounds like they can do whatever they want with code I put in there.~~ EDIT: The terms of use have been updated and I think it's recognizable now that FP Complete only gets a license for code that you publish publicly.
It was just the name for an infix constructor
What are `:k Cofree` and `:k Declaration` ?
Wait, so load time splices don't work with interpreted heist? I thought they were totally orthogonal to the whole compiled vs interpreted business, and now I am confused.
Emacs has all what you are asking for and more. It has haskell support and does everything a decent IDE can. It can require more than 3 days of setup though.
leksah is (by far) the best choice ever I seen I use my text editor but for large projects maybe a good choice
Vim with [vim2hs](https://github.com/dag/vim2hs) and [ghc-mod](http://hackage.haskell.org/package/ghc-mod) works quite well for me. I get automatic syntax checking when I save the file, HLint when I save the file, and the ability to check types of subexpressions usually whenever I want.
There are nice Haskell modes for Emacs and Vim. Both provide neat autocompletion features, in-editor type checking, ability to compile and run code from the editor and pretty much everything on your list. I know more than 10 programming languages and I regularly use more than 5 of them. I definitely do *not* want an IDE for each language, I know one editor very well and I want to use that. No language I know of is so special that it would warrant creating a special editor.
Some parts of it are hard. Exception handling for instance. It is anything but intuitive. His example with the need to use tryIOError illustrates this well. P.S.: why doesn't hoogle find "tryIOError" ?
&gt; Emacs has all what you are asking for and more. So does Vim + haskell-mode. It was rather easy to set up, although I did add some Haskell specific keybindings to eval code. Use what you like best!
as it was not proposed (yet): I really like sublime text 2 (with the sublime-haskell plugin) - you almost get a full IDE this way :D
[EclipseFP](http://eclipsefp.github.io/) is a plug-in for the Eclipse IDE, which supports almost all the features requested in here, as [you can see](http://eclipsefp.github.io/features.html). In particular, it features autocompletion, automatic addition of imports, integrates the GHCi debugger and shows feedback on the fly thanks to [BuildWrapper](https://github.com/JPMoresmau/BuildWrapper). Furthermore, it doesn't need too much setup: download Eclipse, point it to the EclipseFP repository, and the plug-in itself will take care of downloading and installing all the dependencies. Out of topic, I don't fully understand why people is so reluctant to use and recommend EclipseFP. Everybody I know coming from C or Java into Haskell feels that good integrated environments are missing, but the truth is that EclipseFP is quite complete: it even has support for Cabal sandboxes in projects! (Disclaimer: I've been a developer of EclipseFP).
I think Rubear is talking about `[(String, String)]` vs `Map String String`.
So, if I publish my code on the site, it doesn't belong to me; but if I just use the IDE nothing changes?
I just don't like the idea of having to learn an editor, then learning the programming language...
How so? I had a very poor experience with this. None of the type inspection worked, nor any of the other features short of syntax highlighting. Did you do anything special to get it set up?
Could you go into a bit more detail related to your point, apart from your 4th I don't really see the others that important, for my workflow; so that is mostly why I ask you. Just for reference so that people don't have to count bullets &gt; A good way to display subexpression types Starting with automatic management. How would you want that to "flow"? I just do a straight `import Module`, rarely aliasing them (only when they conflict in many points). Also for that point I can mostly "blame" the Prelude, I'd personally want it to export mostly everything in base, except for data structures. Also related with exports? How would that work? What is safe to export, and what should remain internal? How would that be decidable by an IDE? I'm honest that I don't understand what scope means here "Good type and scope-based completions", module scope, package scope, function scope? I won't raise any remarks about integrated/visualized debugger, because I generally don't use that category of tools in other languages. "Compilations/feedback on-the-fly", why on the fly and not on request. I think that was some article about how much of the time on-the-fly compilation is just useless resource usage because you only have certain points in the process of editing code when it is syntactically valid. I don't see a benefit here, where instead of the x seconds it waits for idle to compile you run a shortcut. Please do reply, because I'm honestly curios of the ways you work and how these stand in your way.
I also gave eclipsefp a major go, but I couldn't figure out how to debug anything. Hoogle didn't integrate, and I had all sorts of other issues. :(
I'm not sure about the phrasing of “it doesn't belong to me”, I'd _imagine_ it's more like “if you publish, you give us license to use it, modify it, use it for promotions, etc.” rather than “we own it now, and your little dog, too.” But certainly, for **private** content, yes, if you just use the IDE and don't publish that code (there's a button in the IDE to publish your project for other people to clone as a template), then nothing changes. This privacy and retained ownership is obviously a very important aspect of the service. I'd check with the official support guys for definitive statements. The full terms of use regarding content is: &gt; By posting content viewable by others, you grant us a non-exclusive, worldwide, transferable, sub-licensable, royalty-free license to use it. In the future we may offer you finer-grained control over this licensing policy. &gt; Do not post content unless you have the legal right to do so. (For example, do not post content copyrighted by someone else without their permission.) &gt; Access to this site authorizes you to read and make personal use of the published content herein. However, no license is granted to make commercial use of the content, nor to reproduce it, except to make fair use of the content in personal study which may or may not be in a commercial setting. 
Vim will serve you well for basically any editing task you have, unless you're in a situation where you really need an IDE. I now curse most other editors I have to work with for not being Vim... and end up typing :w everywhere :P. (EDIT: I imagine the same goes for Emacs, but I haven't had personal experience with it.)
&gt; “we own it now, and your little dog, too” heh Thanks, it's much clearer now. 
I just downloaded the latest version from http://leksah.org/download.html. So, I guess, 0.12.0.3? Edit: latest windows version: leksah-0.12.0.3-ghc-7.4.1.exe
Hoogle doesn't work for me either. No idea. It doesn't even update.
It doesn't matter so much. Notepad++ is straightforward and has syntax highlighting. Do you need more than that? 
The most basic concept of managing imports is that when you use an identifier, the required module to import for that identifier is added automatically to your file's import list. When you stop using that identifier, the import is removed.
&gt; Starting with automatic management. How would you want that to "flow"? I just do a straight import Module, rarely aliasing them (only when they conflict in many points). This has 2 consequences that I really really dislike: * When reading code, I have no easy way to figure out where the names I'm seeing come from. Which means I also have no idea about what the semantics of those names are. Hard to read! * Results in (true) stories like this: My package breaks because some indirect dependency no longer builds with a newer GHC, because it imported both `Foreign` and `System.IO.Unsafe` unqualified, and `unsafePerformIO` is exported differently from both. The package maintainer refuses to upload a trivial fix. I have to duplicate the dependency chain from my package to his :-( I think it's important that exporting new names from a module, or new definitions with equal semantics should not break code, but importing unqualified willy nilly breaks this. By "automatic import management", I want to be able to type a name, and press a key to pop up all available modules that export this name. Then choosing one of them ought to add the import to the top if missing (closed or qualified), and also complete the name. Bonus points if this is type-aware. &gt; Also related with exports? How would that work? What is safe to export, and what should remain internal? How would that be decidable by an IDE? The user should decide, of course, but it would be nice if deciding to export a name involved pressing a key on that definition, for example. Also, it would be nice to visualize exported vs. non-exported names differently. &gt; I'm honest that I don't understand what scope means here "Good type and scope-based completions", module scope, package scope, function scope? When typing names, I want it to auto-complete based on names in current scope, and based on what's already imported. I also want it to prioritize/first-show names that would match the needed types in that position better. We have a prototype of this in our IDE project Lamdu (still a toy), and it already shows great results: it is both easier to write code, and takes far fewer key strokes when type information is used. &gt; I won't raise any remarks about integrated/visualized debugger, because I generally don't use that category of tools in other languages. I find them a very important benefit. They take away much of the cognitive load and make runtime debugging much less mentally exhausting. This results in faster debugging, too. &gt; why on the fly and not on request. So that you get immediate feedback, and not have to request compilations every other second. &gt; because you only have certain points in the process of editing code when it is syntactically valid A good IDE can reduce these points (in Lamdu we reduce this to 0). &gt; I don't see a benefit here The benefit is immediate feedback, which means you get to handle errors immediately after making them, rather than "swapping in" your mental state later when you encounter the error as you decide to try to compile. 
Well, is worth it.
Integrated REPLs/command lines are nice. :P
When I used this setup, I had to open WinGHCi separately. It's a bit noobish, but it's much easier to setup. Haskell mode in emacs is better, but harder to set up/get used to. 
Where is Ji currently hosted? I can't seem to turn up anything Googling except Chris's original library announcement which links to missing github page.
I know, I still use notepad++ and WinGHCi until I find a suitable IDE. I think I could settle for Leksah.
Thanks chrisdoner. I would also like to point out that we will be shortly presenting our roadmap for FP Haskell Center for the fall and through the end of December. Watch out for announcements of lower price editions for personal use and the addition of large project features along with deployments options for private servers behind the firewall. 
There are useful features that you don't have in your editor by merely running GHCi, of course. Just off the top of my head: * Identifier completion * Import completion * Import managment (sorting, adding/removing automagically) * Jump to line/col of type errors, warnings and hlint suggestions, move to next, etc. * Type of expression at point * Get type of symbol at point * Get information of symbol at point * Drill down type/information from the output of the above * Structured editing operations that need to grok Haskell * Live type-checking success/failure display * Refactoring (i.e. rename a symbol and change all the references to it, taking scope into account) * A debugger jumping to the line in the source for each step * Automatic insertion of extensions suggested by GHC, [like this](http://chrisdone.com/images/hs-lang.png) * Automatic insertion of type signatures * Jump to definition (local or global) * Jump to usages * A list of all top-level declarations for viewing and quick jumping * Dead code removal And if you're in something extensible like Emacs, more integrated REPL support than a dumb terminal, [like this](http://chrisdone.com/images/hs-repl-error-demo.png) and [this](http://chrisdone.com/images/hs-repl-completion.png). 
Ji no longer exists. It has been renamed to [threepenny-gui](http://www.haskell.org/haskellwiki/Threepenny-gui).
I started out using [Leksah](https://github.com/leksah/leksah), but as I learned more Haskell, I've scaled back to emacs with [Haskell-mode](https://github.com/haskell/haskell-mode) and a few other mainly aesthetic goodies.
The IDE is editing a structure, not text.
At Windows, I had problems with Hoogle too. What did I do? Download the [gnuwin](http://gnuwin32.sourceforge.net/), putted in my path and tried again. The problem was that Hoogle needed *wget* to download the database and, of course, it is not default in Windows. For me, everything works fine.
I use vanilla vi(m), tmux and the wonderful utilities provided in Unix-like systems and it works great!
Ah, the license agreement is new to me, I only knew about the Terms of Use so far. It's not entirely clear which applies to which, as they always talk about "the service" or "the website". I can guess what it's supposed to mean, but with legal matters, I do *not* want to guess. Compare with the [github terms of use](https://help.github.com/articles/github-terms-of-service#f-copyright-and-content-ownership), which I think are really clear and even enjoyable. In particular, the content section is way shorter. &gt; F.1 We claim no intellectual property rights over the material you provide to the Service. Your profile and materials uploaded remain yours. However, by setting your pages to be viewed publicly, you agree to allow others to view your Content. By setting your repositories to be viewed publicly, you agree to allow others to view and fork your repositories. Apparently, there is no need to grant github a non-exclusive sub-licensable etc. license to anything, just the sensible fact that if I make my content viewable, then I agree that others may view it.
I am busy now, but I can look into it this weekend if you let me know the details (Leksah, OS, GHC versions you are using).
I do have auto-completion in haskell-mode. It is based on automatically generated (on save) TAGS file. Yes it is not intelligent, it just gives you tags. But surprisingly it works fine for like 99% of the cases. One of the things i'm missing is code navigation. Jumping to a function definition. If you did not open, compile and save the module, you won't get code navigation into it.
I don't know, I generally try to move away from IDEs when I can. I (and many other programmers) believe they create and reinforce bad programming practices, the main one of these being the fact that they do everything for you.
As an avid vim user I'm afraid I have to... agree.
Yes, you're correct. I described it that way because that is what originally motivated load time splices. When I realized that we needed load time splices in compiled mode it just made sense to make it orthogonal and apply to both modes and eliminate the old onLoadHook functionality which always felt a little out of place to me.
`getEnvironment` returns `[(String,String)]`, when `Map String String` might be preferable. I don't use `getEnvironment` that often and there's `lookupEnv`, so it doesn't really matter to me.
&gt; This is rather complicated. Haskell functions can’t have side effects (like, say, creating a launcher or execing a process). Instead, the function returns an `IO` request to `main`, which returns it to whatever is driving Haskell. I like this explanation.
What version of the Haskell platform do you have?
GHCi, version 7.4.2 Edit: I just updated to 2013.2.0.0
If you want Vim/Emacs-ish feel and Haskell programmability - check out [Yi](http://www.haskell.org/haskellwiki/Yi).
I still don't know how to set up completion and type checking using haskell-mode, after having used it for some 7+ years! I think one thing that e.g. Eclipse provides is smooth always-works integration. Perhaps a tutorial how to set up a working Emacs setup could help here.
But how do I turn it on! My emacs-fu is very weak. I just want to install haskell-mode and have it work.
Emacs but not Vim? You editor bigots!
Hehe. Really, we're providing an external API for any editor. It's just that me and John Wiegley are Emacsers with Elisp-fu so we're capable of providing and maintaining Emacs integration. Seeing as we'd be writing Elisp anyway for our personal use, it's something we can officially provide.
It's in the works—design phase—won't be released for a month or so, or thereabouts. The way we're intending is that the FP server does everything for you. It's essentially a GHCi, ghc-mod, hoogle, hdevtools, etags, cabal-dev, etc. all in one in “the cloud”, so the setup cost should simply be “get an FP Complete account” and load `fpde.el`, which will just make API calls to the server for all its work.
https://github.com/haskell/haskell-mode/issues/197
Ok glad to know that you're thinking ahead by providing an API. A similar situation happened in the OCaml land. OCamlPro wrote an emacs based idea for OCaml (typerex) but then opted to rewrite most of it in OCaml for version 2 and provide hooks for any editor to integrate with.
Well, the thing is that EclipseFP tries to integrate a lot of separate tools, and each has its own idiosyncrasies, especially on Windows. 
Scotty seems like a good choice to me, I have used it for a very small project and it worked just fine. *Correctness* is one of the eight virtues in the Haskell community.
Just make sure every issue is logged onto my github repo so it doesn't get ignored. I'm releasing version of EclipseFP regularly enough and each comes with bug fixes. I'm willing to help users get set up if they run into issues.
Well, personally, I have a Terminal window for building, another app for version control, I tend to keep type information in my head, haddock is Ctrl+H and most of my refactoring cannot be automated.
Because I often use a monoid that requires information from the surrounding context. I could and may switch to always implementing that via reflection, but it definitely complicates the implementation of the Applicative and Monad requiring dozens of newtype wrappers for simple one use monoids.
Interesting. It seems like the author did write the OCaml however.
You definitely want to use haskell-process. It works great, even with multiple projects (cabal) at the same time. Can also switch between regular ghci and cabal-repl easily.
You know what, Emacs does look interesting...
cool
Thatnks for the link to paste bin config. Will try it out. Maybe ghc-mod will indeed add the missing features.
TAGS-based auto-completion: It's better than nothing, in that sense I agree it "works fine". But it could and should be so much better.
I am looking right now at ghc-mod. Apparently it has a more intelligent completion mode and even code navigation. http://lpaste.net/92858 
Directed by JJ Abrams.
All of these extensions seem to work only for top-level stuff, not code in lambdas or with `let` or `where` clauses. This makes them far less useful.
Thanks, I'll take another look at Scotty and try building something in it.
Consider: instance Choice M where left' (M k h m z) = M (_Left %~ k) (_Left %~ h) step (Left z) where step (Left x) (Left y) = Left (m x y) step (Right c) _ = Right c step _ (Right c) = Right c {-# INLINE left' #-} right' (M k h m z) = M (_Right %~ k) (_Right %~ h) step (Right z) where step (Right x) (Right y) = Right (m x y) step (Left c) _ = Left c step _ (Left c) = Left c {-# INLINE right' #-} That would need a custom monoid each or to 'twist' one of the cases.
I may actually wind up dong this anyways. There aren't many places made more complicated.
Exactly. Maps are implemented using binary trees, specifically for use with key-value, dictionary type items. It might make the program a little faster if you implement those.
:k (short for :kind) is like :type in GHCi but shows you the kind of the type expression. It's useful for seeing if things are valid types. 
lol, intentionally missing the point of the comment
I didn't, but I am totally willing to give it another go. Ill try again this weekend. Thanks!
Ya, this is a common technique to assist in writing portable code. only code to UINT32, INT64 etc. Then utilize a types layer for each target architecture. 
That's your assumption. Don't knock it till you try it :) 
OK, i figured out at least one thing that ghc-mod adds: Autocompletion from all available modules. Haskell mode only does autocomplete based on generated TAGS file. I admit, that's cool. 
I know that. =) I meant "what does it show you for these values?". You should see: Cofree :: (* -&gt; *) -&gt; * -&gt; * Declaration :: * -&gt; * If you don't, then somewhere along the way something was dropped. =)
Sweet. If only TL2 worked on my mac :)
haskell-mode for vim is very good. if you aren't already sold on an editor; it probably makes sense (if you are going to continue to do a lot of programming) to learn vim or emacs
I spent years in vim in college. It's nice but for real work I want something more robust. 
Sorry, I should have provided an example. I edited the post, and added it. The columnC indicates how many table will be generated, and which tables will be combining which other tables. 
Data.Monoid's relatively new &lt;&gt; operator is pretty convenient. But another method I like is mconcat: mconcat ["Retrieved ", show n, " items"]
Type of sub-expressions.
I build REST APIs on a regular basis using Snap. In fact, we even created a little package to help call [restful-snap](http://hackage.haskell.org/package/restful-snap). We also wrote a [blog post](http://devblog.soostone.com/posts/2013-06-04-restful-snap.html) about it. I should mention that this is not an official Snap Framework project. It's just something that we put together to keep our APIs uniform.
- Code completion (with ac-ghc-mod) - Cabal-dev &amp; Cabal Sandbox ready.
Eh, I can't afford to pay $75 a month to mess around with Haskell... I don't know any Java editors with a subscription.
How? I'm trying C-c, C-t (first disabling haskell-mode command for type info) and it gives me error. When i try to compile file using ghc-mod compile instead of haskell-mode compile i see it loads ghci but fails to compile the file because it cannot find modules. So it did not recognize cabal-sandbox. So i have to revert back to haskell-mode functions for type info. 
Second point: haskell-mode easily works with either system as well.
While that all sounds nice and the beta looked good, you guys are high if you think that this will sell for $750 a year with no support.
I'm currently using this book. I'm very confused with how he goes over recursion. Only the Fibonacci example makes any sense. Rest of the book is fairly decent, although he doesn't tie in the lessons into anything.
How about something like this: import Data.List (foldl', null, intercalate) type ColumnItem = (String, String, Int) type ColumnList = [ColumnItem] testData :: ColumnList testData = [("one", "two", 2), ("three", "four", 3), ("five", "six", 1), ("meep","zort", 0), ("whaargarbl","flibble",0),("blah1","blah2",10), ("blah2","blah3",20),("blah3","blah4",30)] thrd :: (a,b,c) -&gt; c thrd (_,_,x) = x groupList :: ColumnList -&gt; [ColumnList] groupList l = reverse (if null temp' then accum' else reverse temp':accum') where (accum',temp') = foldl' helper ([],[]) l helper (accum,temp) i | null temp || thrd i &gt; thrd (head temp) = (accum,i:temp) | otherwise = (reverse temp:accum,[i]) ~~`groupList :: ColumnList -&gt; [ColumnList]`~~ ~~`groupList l = groupBy (\(_,_,col) (_,_,col') -&gt; col &lt; col') l`~~ makeTable :: String -&gt; ColumnList -&gt; String makeTable tbl l = "CREATE TABLE " ++ tbl ++ " AS " ++ subtables where subtables = intercalate " UNION " selects selects = map (\(col,subtbl,_) -&gt; concat ["SELECT ", col, " FROM ", subtbl]) l result :: [String] result = map (makeTable "testTable") (groupList testData) It could be made a lot more terse/idiomatic/performant, but when learning Haskell I'd suggest not trying to be too tricky. `result` will be set to `["CREATE TABLE testTable AS SELECT one FROM two UNION SELECT three FROM four","CREATE TABLE testTable AS SELECT five FROM six","CREATE TABLE testTable AS SELECT meep FROM zort","CREATE TABLE testTable AS SELECT whaargarbl FROM flibble UNION SELECT blah1 FROM blah2 UNION SELECT blah2 FROM blah3 UNION SELECT blah3 FROM blah4"]` based on the contents of testData. *edit*: Fixed flaw in initial version.
Which are the other seven?
In idiomatic Haskell, it's easier to break down the problem. First, we want to group the input rows into "tables": type Row = (String, String, Int) -- | Group rows such that, whenever ColumnC is &lt;= the value it had in the last -- row, it starts a new group. groupByAscendingC :: [Row] -&gt; [[Row]] But I didn't even implement this without generalizing—not because I feel like being fancy, but because it turned out to be much easier: -- | Pile items into groups. The predicate will be tested on each consecutive -- pair of items (items are passed in order the items appeared). If it returns -- 'True', the second item will be separated from the first and start a -- new group. -- -- &gt;&gt;&gt; breakWhen (&gt;=) [2,3,1,2,2] -- [[2,3],[1,2],[2]] -- &gt;&gt;&gt; breakWhen (&gt;=) [] -- [] breakWhen :: (a -&gt; a -&gt; Bool) -&gt; [a] -&gt; [[a]] breakWhen _ [] = [] breakWhen f (x0:xs0) = go x0 xs0 [] [] where go a (b:xs) g gs | f a b = go b xs [] (reverse (a:g) : gs) | otherwise = go b xs (a:g) gs go a [] g gs = reverse (reverse (a:g) : gs) groupByAscendingC = breakWhen (\(_,_,a) (_,_,b) -&gt; a &gt;= b) Here, the annoying grouping logic isn't strewn across a big loop. It's all in one function that's easy to test in ghci (GHC's interactive console). The rest is pretty easy, with the help of [intercalate][1] (which joins lists with a delimiter list) and [zipWith][2] (which I use to call chainToSql with unique names zipped with corresponding chains): chainToSql :: String -&gt; [Row] -&gt; String chainToSql _ [] = error "chainToSql: empty chain" chainToSql tableName xs = "CREATE TABLE " ++ tableName ++ " AS\n" ++ intercalate "\n UNION \n" (map rowToSql xs) ++ ";" where rowToSql (a, b, _) = " SELECT " ++ a ++ " FROM " ++ b rowsToSql :: [Row] -&gt; String rowsToSql xs = intercalate "\n\n" $ zipWith chainToSql (map name [1..]) (groupByAscendingC xs) where name n = "table" ++ show (n :: Integer) [1]: http://hackage.haskell.org/packages/archive/base/latest/doc/html/Data-List.html#v:intercalate [2]: http://hackage.haskell.org/packages/archive/base/latest/doc/html/Data-List.html#v:zipWith
Doh! I don't use groupBy too often, and I just assumed. It's true what they say — when you assume, you make an ASS of U and ME. Good catch. I suppose I will rewrite it with a fold.
Why not implement Catch as a compiler plugin that only gives extra warnings? http://www.haskell.org/ghc/docs/7.4.1/html/users_guide/compiler-plugins.html
Yes, this is kind of what I was hoping for .. an interesting solution. Thank you! Is there a reason why you're adding things to the front of the list and then reversing, instead of appending? Or is it just due to Haskell's/GHC's performance characteristics of lists?
Are you seriously comparing something put together by an individual with a long standing commercial product with many man years of effort behind it?
Perhaps try with hsenv? That munges your path to put all the stuff in the sandbox at the front. You might also have to install ghc-mod in the sandbox though.
The order of lines defining a single function (insert, flatten, treesort) matter. I recommend the book "Learn You a Haskell for Great Good". It is available for free online. Chapter four deals with pattern matching in functions.
Hi, the order of lines can matter (but not in this case) - as case-expressions and pattern matching is done from top-to-bottom what you can do is shuffle the functions (every block that begins with the same name - for example "insert") around. As for how to read it ... well, honestly I do not know how to answer this - can you give some details of where your problems are? Her is a short example where the line-order matters (but you will get a warning for this :D): data Tree a = Leaf | Node (Tree a) a (Tree a) sample :: Tree Int sample = Node (Node Leaf 1 Leaf) 2 Leaf showTreeOk :: Show a =&gt; Tree a -&gt; String showTreeOk (Node l x r) = showTreeOk l ++ "&lt;-" ++ show x ++ "-&gt;" ++ showTreeOk r showTreeOk _ = "{}" showTreeFail :: Show a =&gt; Tree a -&gt; String showTreeFail _ = "{}" showTreeFail (Node l x r) = showTreeFail l ++ "&lt;-" ++ show x ++ "-&gt;" ++ showTreeFail r &gt; showTreeOk sample "{}&lt;-1-&gt;{}&lt;-2-&gt;{}" &gt; showTreeFail sample "{}" 
It is all explained here: [sublime-haskell readme](https://github.com/SublimeHaskell/SublimeHaskell/blob/master/README.md) This works like a charm for me (with or without cabal-dev) - of course you have to work inside a cabal project (you need a correct .cabal file for you project in the base folder). REMARK: right now there seems to be some problems with using this in ST3 - but ST2 works on both my windows and ubuntu systems 
It is a tree sort algorithm taken from [http://en.wikipedia.org/wiki/Tree_sort](http://en.wikipedia.org/wiki/Tree_sort) I know the end goal it is trying to achieve, but I can't even begin to read it line by line. 
I think you can give hints to the paths for most tools it needs in its SublimeHaskell Settings file: // Extra directories to be added to the front of the PATH environment variable. // Specify this for using custom ghc, cabal, and ghc-mod // Example: /home/user/.cabal/bin "add_to_PATH": [], 
Do you know any Haskell? If not, it might be fairly hard. data Tree a = Leaf | Node (Tree a) a (Tree a) That defines a datatype called `Tree` which uses one type variable named `a`. The name `a` is arbitrary — it's just convention to name the first general type variable `a`. The datatype `Tree` has two constructors: `Leaf` and `Node`. The `Node` constructor will hold three pieces of data. For example, if you had a `Tree Int` then `Node` would be `Node (Tree Int) Int (Tree Int)`. You can use those constructors to create an instance of the type `Tree Int`, for example: `Node tree1 123 tree2` The lines that look like `blah :: x -&gt; y -&gt; z` are type definitions. If you're familiar with C-type languages, you can think of them as similar to function prototypes. sample :: Tree Int That means the `sample` function will have type `Tree Int`. If you don't explicitly set the type, the Haskell compiler will attempt to infer it. Sometimes type inference is ambiguous and it tends to make code clearer if you're explicit about what type you want something to be. It also helps catch bugs, because you'll get an error when your expectation diverges from the type the compiler expects. sample = Node (Node Leaf 1 Leaf) 2 Leaf That uses the `Node` constructor that I previously mentioned to create a sample tree. You can think of constructors as functions that when called will give you an item of the type they belong to. They can also be partially applied like other functions and will return a function that expects any remaining arguments. For example, a `Node` constructor for `Tree Int` has the type signature `Tree Int -&gt; Int -&gt; Tree Int -&gt; Tree Int`. showTreeOk :: Show a =&gt; Tree a -&gt; String `Show a =&gt;` means that the type variable `a` must be an instance of the `Show` typeclass. Types that are instances of `Show` can be applied to the `show` function which converts the type to a string. Basically, if you want to print out a value of some type, that type must be an instance of `show`. Note that this is not the same `a` type variable from the `Tree` type. showTreeOk (Node l x r) = showTreeOk l ++ "&lt;-" ++ show x ++ "-&gt;" ++ showTreeOk r It's a recursive function that displays the tree. In Haskell it's possible to define the same function multiple times and Haskell will pattern match based on the arguments. Very simple example: test :: Int -&gt; String -- Function that takes an Int and returns a String. test 1 = "You passed me one." test 2 = "You passed me two." test x = "You passed me a number: " ++ show x `++` is string concatenation, and remember that the `show` function converts something to a string. Anyway, if you consider the `Node` constructor for `Tree Int` you'll remember it basically has an Int sandwiched between two trees. So doing `showTree ++ show the_int ++ showTree` recursively descends into the tree, generating string representations of the `Node`s it encounters. showTreeOk _ = "{}" `_` (underscore) in a pattern matches anything and does not bind a "variable" (using the term loosely here). There are only two things that could be in the first argument when passed something of type `Tree a` — a Node or a Leaf. Since the first function definition covered `Node`, the second definition must apply to `Leaf`. That `_` could be changed to `Leaf` and the program would work the same. Anyway, whenever it gets a `Leaf` it simply returns the string `"{}"`. So now you might wonder why one function fails and the other doesn't: the reason is that since `_` is a wildcard and pattern matches are applied in order the `_` will match either a `Node` or `Leaf`. So basically, the first constructor of `Tree a` it gets to, it simply returns `"{}"` and does not recurse further. Wildcards don't necessarily have to use `_` though. Anything that doesn't force a match to something specific will do. A possible simpler example of the same concept: test :: Int -&gt; String -- Function that takes an Int and returns a String. test x = "You passed me a number: " ++ show x test 1 = "You passed me one." test 2 = "You passed me two." That function will always return `"You passed me a number: [...]"`, because the first pattern will always match and it will never get to the more specific ones. Hope this helps. If you want to start more, I'd recommend starting with [Learn You A Haskell](http://learnyouahaskell.com/) a book for beginners that has a free online version.
Well, asking nosy question is definitely not one of them. ;-) I just made up the number in reference to Ultima IV.
They have free academic licenses coming, not sure if that applies to you. Maybe we should argue for a setup a la PyCharm, where you can get cheap licenses is you work on open source projects?
Correctness, abstraction, avoidance of success, tiny libraries, [taking a joke too far](http://stackoverflow.com/questions/5057136/real-world-applications-of-zygohistomorphic-prepromorphisms), lamenting the definition of existing typeclasses, rewriting the Prelude and bottom.
Ajhc ability to streamline the RTS to only ship used parts is interesting, are there any projects to do something similar in GHC?
&gt; Yes, the order matters. The "data Tree... " line has to come first because insert and flatten refer to Tree, and treesort has to come last because it refers to insert. Not true. You can list those definitions in any order. 
Insufficient. In a similar situation, we have a formally verified C compiler (CompCert) and a formally verified operating system (seL4) but that doesn't mean that if you compile seL4 with CompCert you get a result that is necessarily correct. You need to verify that CompCert's model of C matches seL4's model of C. Likewise, you'd have to match Quarks' model of JS with whatever Agda model of JS you're compiling to..
fyi, some work in progress code: https://github.com/haskell/haskell-mode/issues/178?source=c#issuecomment-21621418
You can shuffle each _definition_, but not necessarily each line. In general, pattern matching is done from top to bottom, so it's important to keep those lines in order, since the behavior of the program can be altered if you change the precedence of a case or guard. In this case, you could swap the lines of `insert` and it wouldn't matter, since each pattern is completely distinct. Haskell does not care what order each function, data type, type class, etc is defined in, just that they're defined, but order does affect each definition. Another example to consider would be if I had the type data MyNums = Zero | One | Two | Three deriving (Eq, Ord, Enum, Show) Which is equivalent to data MyNums = Zero | One | Two | Three deriving (Eq, Ord, Enum, Show) just written in a different style. Since we deriving `Ord` and `Enum`, these are resolved in the order in which the constructors are declared. If you shuffled lines around in this to be data MyNums = Zero | Two | One | Three deriving (Eq, Ord, Enum, Show) It would obviously have different behavior (i.e. `One &gt; Two` and `succ Two == One`)
We can just write this all in JS, obviously!
Obvious question, but won't that have latency issues?
Great to see you, I'd love to ask you some questions! This is kind offtopic here but what are your experiences with OCaml? Was it a good decision? Would you change your decision with the knowledge you now have?
It's not that, it just doesn't make sense. There needs to be a free license or community edition version. Look at intellij - it's a very polished, very good IDE and it has a free community edition that devs can use for side projects. Even the commercial license is cheaper. It's more polished, supports multiple languages, and is way more feature-complete. So not only is the FP Complete IDE not priced competitively (but granted, it is the only decent haskell one), I don't think it makes business sense to charge an arm and a leg. FP Complete should want to increase haskell adoption. One of the downsides of haskell is the lack of tooling, and by offering a cheap or free ide, they will make haskell much more enticing.
I'm very happy with it so far (having converted more than 10,000 lines now). OCaml is simple and readable and doesn't try to be clever, so I think it will be very maintainable, though more verbose than Haskell. I wrote the code for OCaml 4, but then found Debian only has OCaml 3. But it seems there were no backwards-incompatible changes and after removing a couple of utility functions that weren't in 3, it works there too. So API stability seems excellent. The only problem has been the portable bytecode[*], which is a regression relative to Python. For the next release, I'm planning to ship native binaries for common platforms instead. Others will have to compile from source. [*] http://roscidus.com/blog/blog/2013/07/07/ocaml-binary-compatibility/
In a British accent.
Well, I don't know… I think being curious must be one of them! Heh.
Modulo Template Haskell.
For large things, my understanding is that it's best to turn to builders. Using monoids does keep things nice and generic, though. For sql in particular, I quite like esqueleto... don't build strings if you don't have to.
Thank you. I like your plain English explanation. 
Using cons on the list head is more efficient than rebuilding the list with each append. You can get around that with a difference list which is a partially applied function of type [a] -&gt; [a]. You only build the list once at the end. 
$750 is nothing for many commercial users. Profitable given 4 hours of productivity gain. For hobbyists and startups it's different. I can understand that it's hard to set a price.
Agreed for the commercial users part, but why not make $750 the commercial license and have it otherwise free? Let's face it, haskell does not have a huge industry following. I'm willing to bet the majority of users are hobbyists, and the ones who use it at work probably sneak it in for some smaller scripts and couldn't really get the company to buy a license. (Of course I realize there are companies that would buy a commercial license, and there are companies that use haskell as a major language).
Yes, that'll be part of GHC 7.8.1, but you can benefit from that with 7.6.3 as well if you install [ghci-ng](http://hackage.haskell.org/package/ghci-ng) via `cabal install ghci-ng` and configure `haskell-mode` to use `ghci-ng` as ghci executable (or alternatively, symlink `ghci` to point to `ghci-ng`)
Do either of these provide code completion based upon the current type? e.g. I'd like to find all functions that act on Text in their first argument. I'm a by day .net developer and it saves loads of time not having to look up every little function in the documentation.
+1 for Yesod. You can actually get a really compact, single-module Yesod app for a simple REST API pretty easily. I'm a big fan of the typesafe routing for well-defined REST endpoints and could not care less if I need to use Quasi Quotes to do it. I've yet to have as nice a time with the other frameworks for this use case. I typically build apps that embed a simple REST API into a single module in the project. I base my embedded API off of something like this (but without the view code) https://github.com/pbrisbin/yesod-minimal/blob/master/minimal.hs For a real-world example: https://github.com/MichaelXavier/vigilance/blob/master/src/Utils/Vigilance/Web/Yesod.hs (still a work in progress)
Yeah, I don't think an academic license is the answer. The issue is that they're charging almost as much as Visual Studio (or Intellij, or PyCharm) for a brand new web based IDE for a pretty uncommonly used language. That seems crazy to me.
No, just name match. 
`[a]` is the same as `a:[]`, i.e. a list of length 1. in the pattern match you bind `a` to the only element, so you only get a non-exhausting pattern. Note: you should check for empty lists, but with your signature, i don't know what you could possibly do to prevent a partial function. what you mean is func :: [a] -&gt; Int -&gt; a func a 0 = head a func a n = func (tail a) (n-1) edit: and (i know you are only practicing) you might like to have a look at `drop` and `head`.
Your first definition pattern matches on list constructor, `:`. In your second definition, you pattern match on a list with a single element (`[a]` is sugar for `a:[]`). That’s why the patterns are said to be non-exhaustive, you do not match the empty list, or a list with more than one element. That said, the first definition is also missing the empty list case, and should give the same warning.
Your method for replaying a frozen build using `xargs` iteration sounds wrong. Whenever you do builds one package at a time, you are likely to get different results from building all at once, unless perhaps you provide a full set of constraints on each iteration. In fact, the key to reproducing a build accurately is a full set of constraints, where you can bind every single direct and indirect dependency to an exact version as well as specify the cabal flag settings. Our equivalent to your shell invocation is one which produces a single build command with many `--constraint` specifications. But that is awkward. When there are more than 100 constraints, we need to pare them down without affecting the build. The idea is to remove constraints either that can be proven not to affect the resulting build plan, or that only affect (even indirectly) packages which are only being build to satisfy dependencies but aren't actually being used by our application.
Another approach to reproducible builds is freezing hackage instead of freezing the build plan. If `cabal` is presented with the same `cabal` file and the same exact state of hackage, then it will produce the same build plan. (Well, that is assuming that your versions of `cabal` are using the same solver.) So instead of trying to take a snapshot of the `cabal` build plan (or perhaps in addition), you can start with a fresh sandbox and a clean package cache, do the build, then archive the package cache and `00index.tar`. If [Stackage](https://github.com/fpco/stackage) (now supported by [FPComlete](https://www.fpcomplete.com/)) starts providing periodic stable versions that will be supported over a long period of time (i.e. years) without changing the package version inventory, then that would also solve the problem.
This is a critically important feature. Thanks for telling us about it. We'd love to see a blog post! Exact reproduction of a `cabal` build plan over time, after Hackage has significantly changed, is only possible by providing a full set of fixed constraints. That is very awkward to do when there are many constraints, say over 100, and the only way to specify the constraints is either on the command line or in the global config file. So this feature will really help!
Interesting. Does that also give flag constraints? Besides eegreg's custom `Setup.hs`, other methods are parsing the output of `cabal install --dry-run --verbose` in a fresh sandbox, and parsing a listing of the sandbox `lib` directory after a build in a fresh sandbox. So far, parsing the `--dry-run --verbose` output is the only method I have found that also includes flag constraints.
In the type definition for func, func :: [a] -&gt; Int -&gt; a [] is being used as a *type* constructor. That is [a] refers to the *type* "a list of as". However, in the definition of func, func [a] 0 = head [a] [] is being used as a *value* constructor. [a] means a singleton list whoes only element is labeled as a. These two as are distict as well (they fall in different namespaces). The first a is a polymorphic type variable and the second is the label for a value. To answer your second question. The reason parentheses are require in the pattern func (x:xs) 0 = x (where (:) is being used as a value constructor) is because without the parentheses func would be treated as a function of 4 arguments (x :: a, (:) :: (a -&gt; [a] -&gt; [a]), xs :: [a], 0 :: Int). This is actually the same reason why you need parentheses around tuples. func 2,3 = ... would be a function accepting the 3 arguments (2, (,), 3), whereas func (2,3) = ... has just one argument, the pair (2,3).
&gt; That said, the first definition is also missing the empty list case, and should give the same warning. The difference being that in the first definition he would have to explicitly test for "func [] 0". Which is probably why he didn't notice. 
Once you've solved this one, here is the next challenge: automated metrics to measure how a new build differs from a previous frozen one, and how the differences affect the resulting compiled application. Use case: you want a build that is effectively equivalent, or almost equivalent, to a previous build, for the purpose of supporting a released application, but you are unable to use the exact same set of dependency packages. The reason might be, for example, that a certain package, or a certain version of GHC, is not available on some platform. So you want to replace a small number of dependent packages and the subdependencies that spin off them in the way that least affects the behavior of the application.
&gt; In fact you yourself previously asked me "what does it even mean to execute +?", or words to that effect. Well, if that + is buried in a lambda, it won't be evaluated in that earlier decoupled evaluation of yours anyway because the lambda will be evaluated to itself (with everything inside unchanged). So the idea of execution of that + must have meaning, and must include what most people would consider evaluation of that +. It was not me who asked. By my terms, execution of + does not have sense (evaluation does). It will be evaluated if its containing expression (of type IO) is executed. &gt; So what's the point of defining "evaluate" in that way? If it was the way most people, or most programmers, or even most mathematicians use the word "evaluate" - fine, we can't expect all word definitions to be useful in a niche. But Haskell seems to have created it's own definition of "evaluate" for the specific purpose of explaining the IO monad - purely in order to make the claim that evaluation is pure. What's the point of that? My understanding is that the word "evaluate" I defined above coincides with mathematical usage; it's very similar to reduction in lambda calculus. Mathematicians say (I hope...) that 2+3 evaluates to 5. Evaluation in mathematics is pure. Then, imperative programming came and twisted the meaning, telling how to evaluate "impure" expressions: random() * 2 can evaluate to different things, readln() + " world" evaluates depending on what you enter in the console etc. This destroyed algebraic laws expected by expressions (e.g. 2*x is x+x, but random() * 2 is not random() + random()) and referential transparency (if you know readln() evaluated once to "hello", you cannot substitute that in the program). Haskell does not go this path and makes evaluation pure. This means we have a wide range of transformations that can be applied. For example, you can substitute `m &gt;&gt;= return` in your program to `m`. It doesn't matter that `m` has an IO type. IO and non-IO code have equal rights in such transformations, while in C you have to think twice when you do a seemingly-justified algebraic manipulation. Formally, evaluation is not dependent on the IO monad: it would exist if Haskell did not have it. I do not bring `unsafePerformIO` here. If it is used incorrectly, it's programmer's fault, evaluation might have side effects, transformations will be not valid etc. It is an equivalent of opening a PC and being shocked by the internals. &gt; Side effects potentially occur when you evaluate an expression that has an IO (or similar special) type. Whether those side effects actually occur depends on the details of the expression, arguments and closure - there's a potential halting problem issue if you want to know for certain. You are saying they potentially occur. I want to know exactly when they occur. The halting problem is an issue of _mechanically computing_ behavior, but not of _defining_ it. For example, you can define the semantics of "`any f [1..]`" as "`True` if there is a natural `n` such that `f n` evaluates to `True`, `_|_` otherwise" (disregarding the situation when `f m = _|_` for some m &lt; n which is trivial to fix). This is a valid definition, even though telling the result is undecidable by the halting problem. Let me ask: with your single notion of evaluation/execution how do you define `seq` and `&gt;&gt;` such that the difference between `main1` and `main2` f = getLine main1 = seq f $ return () main2 = f &gt;&gt; return () is visible? (Of course, `f` could be something very complicated)
You are also welcome to ask questions on the haskell-beginners mailing list.
To be concrete about it, note both of these are valid: Prelude&gt; let x = head :: [a] -&gt; a Prelude&gt; let y = head :: [] a -&gt; a I've often thought that if I were going to write a Haskell tutorial (which I'm not, we've got enough), that I would actually start off with the second syntax, then explain the first as a special case for lists. I also think `[] a` helps beginners more easily understand why lists are functors: Prelude&gt; :t fmap fmap :: Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b Matching `[] a` to `f a` is easy enough; matching `[a]` to `f a` can be much more confusing if you haven't internalized the desugaring.
Just wanted to say that I got eclipsefp up and running today with your help and I like it a whole lot more than sublime text. great debugger integration, auto completion, type checking, ghci repl integration, hoogle, all the bells and whistles. The only thing I'd really like is a dark theme and the ability to replace \ with the lambda symbol (like leksah).
TIL about [ajhc](http://ajhc.metasepi.org) seems analogous to [gambit scheme](http://en.wikipedia.org/wiki/Gambit_(scheme_implementation\))
I'd be willing to look at your code, just send me a gist or pastebin link. I don't know if I'm an incredibly experienced haskeller, but I consider myself pretty decent at least.
You could ask right here too. 
Now you have two problems.
Ah, I was thinking of the compile-time warning. Forgot that it’s not enabled by default.
If the semantics of your code do not change when thunks get forced "early", don't you want strict evaluation anyway?
This isn't really related to the answer edwardkmett gave, though. When you write `[a]` and `[] a`, you are talking about types. In the answer up to that point, there were no types. As values, `[a]` and `[] a` are certainly *not* the same -- the second attempts to treat the empty list as a function, and will never type-check.
Also, if your thunks have a defined evaluation order, what can you do with them? [EDIT] It is unclear to me whether ALL thunks are evaluated FIFO, or only those thunks which are evaluated when you "overflow" the queue get evaluated this way. Either way seems you’d have to pretend they all evaluate FIFO. [EDIT] &gt; when a thunk gets forced, remove it from the queue (one of two reasons the queue is doubly linked) Looks like it's the latter.
I'm talking about the "pun" he referred to in the last sentence. I think it's a lot clearer all around to not pun, and it's worth observing the pun is not mandatory at the type level. Take away the punning and while it won't make this mistake impossible, it would make it a great deal less enticing. `[a]` is convenient, but it also allows beginners to think it's something more magical than it is.
That's an entirely different (and orthogonal) practice.
I would _love_ to have some kind of code review exchange group -- I've been coding in Haskell for a few years but would still love to know when what I wrote makes no sense to anybody other than me.
Because more thunks could be added to the end of the queue rather than the beginning, it is possible that some computations can still be made to halt which would otherwise not halt: (\x . print "hi") delay( (\x . x x ) (\x . x x) ) would still complete with a max queue size of greater than 2. Mainly, this way we treat a computer more like it is in reality: as having a finite heap. Rather than giving up when we reach capacity of the heap, there is something else we can try: evaluate some thunks.
 {-# LANGUAGE StandaloneDeriving, OverloadedStrings #-} module Config ( CommandDictionary(..), constructDict ) where import qualified Data.Map.Strict as M import Control.Applicative((&lt;$&gt;),(&lt;*&gt;)) import qualified Data.ByteString.Lazy as L import Data.List(unlines) import Data.Maybe import Data.Either(partitionEithers) import Data.Tuple import Data.Word(Word8(..)) import Numeric(readHex) import Control.Monad(mzero,liftM,mapM) import Data.Aeson import Codec.Picture.Types import Text.Regex.Posix((=~)) -- the CommandDictionary describes a mapping from pixels to strings -- it is accessed via the translate function data CommandDictionary = CommandDictionary { des :: M.Map PixelRGBA8 String , bld :: M.Map PixelRGBA8 String , plc :: M.Map PixelRGBA8 String , qry :: M.Map PixelRGBA8 String } deriving(Eq,Show) data ConfigLists = ConfigLists { designate :: M.Map String [String] , build :: M.Map String [String] , place :: M.Map String [String] , query :: M.Map String [String] } configTup :: ConfigLists -&gt; (M.Map String [String],M.Map String [String], M.Map String [String],M.Map String [String]) configTup cl = (designate cl, build cl, place cl, query cl) instance FromJSON ConfigLists where parseJSON (Object v) = ConfigLists &lt;$&gt; v .: "designate" &lt;*&gt; v .: "build" &lt;*&gt; v .: "place" &lt;*&gt; v .: "query" parseJSON _ = mzero deriving instance Ord PixelRGBA8 constructDict :: L.ByteString -&gt; L.ByteString -&gt; Either String CommandDictionary constructDict alias config = do aliasLists &lt;- eitherDecode alias :: Either String ConfigLists commands &lt;- eitherDecode config :: Either String ConfigLists buildCommandDict aliasLists commands where buildCommandDict :: ConfigLists -&gt; ConfigLists -&gt; Either String CommandDictionary buildCommandDict al cs = buildCommandDict' (tmap4 (expandList . M.toList) altup) (tmap4 (expandPixelList . M.toList) cstup) where altup = configTup al cstup = configTup cs buildCommandDict' (a,b,c,d) (w,x,y,z) = do designate' &lt;- genMap a w build' &lt;- genMap b x place' &lt;- genMap c y query' &lt;- genMap d z Right (CommandDictionary designate' build' place' query') -- map a function over a 4 tuple tmap4 :: (a -&gt; b) -&gt; (a,a,a,a) -&gt; (b,b,b,b) tmap4 f (t1,t2,t3,t4) = (f t1,f t2,f t3,f t4) genMap :: [(String,String)] -&gt; [(Either String PixelRGBA8,String)] -&gt; Either String (M.Map PixelRGBA8 String) genMap _ [] = Right M.empty genMap [] _ = Right M.empty genMap al cs | not (null errorList) = Left (unlines errorList) | length (filter pred genList) == 0 = Right (M.fromList $ map noMaybe genList) | otherwise = Left "Error generating pixel-string map: an alias is referenced\ \ in pngconfig.json that is not present in alias.json" where (errorList,genList) = partitionEithers $ map (checkEither . doLookup) cs doLookup (pix,str) = (pix,M.lookup str dict) -- checkEither extracts the Either state from a tuple checkEither (Right p,s) = Right (p,s) checkEither (Left e,s) = Left e dict = M.fromList al pred (_,a) = isNothing a noMaybe (a,b) = (a,fromJust b) expandList :: [(String,[String])] -&gt; [(String,String)] expandList = concatMap (expand . swap) expandPixelList :: [(String,[String])] -&gt; [(Either String PixelRGBA8,String)] expandPixelList = map (toPixel) . expandList -- expand a tuple holding a list of keys and a value into a list of key value pairs expand :: ([String],String) -&gt; [(String,String)] expand ([],_) = [] expand ((k:ks),val) = (k,val) : expand (ks,val) -- TODO: need to make these check for malformed strings toPixel :: (String,String) -&gt;(Either String PixelRGBA8,String) toPixel (key,val) = (keyToPixel key,val) -- color representations: -- base ten: &lt;val&gt;:&lt;val&gt;:&lt;val&gt;:&lt;val&gt; -- hex: #&lt;val&gt;&lt;val&gt;&lt;val&gt;&lt;val&gt; or 0x&lt;val&gt;&lt;val&gt;&lt;val&gt;&lt;val&gt; keyToPixel :: String -&gt; Either String PixelRGBA8 keyToPixel = (liftM listToPixel) . keyToPixel' where keyToPixel' key | key == "" = Left (fErr "attempted to pass null key string") | fst hexResults /= "" = Right $ parseHex (snd hexResults) | fst base10Results /= "" = parse10 (snd base10Results) | otherwise = Left (fErr $ "malformed key: " ++ key) where matchHex = key =~ hexPattern :: (String,String,String,[String]) matchBaseTen = key =~ baseTenPattern :: (String,String,String,[String]) hexResults = results matchHex base10Results = results matchBaseTen results (_,match,_,substrs) = (match,substrs) fErr s = "Error in keyToPixel: " ++ s -- parse a list of hex strings to Word8 values -- we're guaranteed that the list will look like [&lt;hex prefix&gt;,&lt;val&gt;,&lt;val&gt;,&lt;val&gt;] -- from the pattern match that calls parseHex parseHex :: [String] -&gt; [Word8] parseHex = (map toHex) . tail where toHex = fst . head . readHex parse10 :: [String] -&gt; Either String [Word8] parse10 = mapM (readWithBounds) -- readWithBounds will either return the String as a Word8 or -- throw an error if the value is larger than 255 where readWithBounds :: String -&gt; Either String Word8 readWithBounds s | val &gt; 255 = Left ("key value too large: " ++ s) | otherwise = Right (fromInteger val) where val = read s :: Integer -- listToPixel can't fail on an input of Right, the pattern matching in keyToPixel' -- guarentees that parseHex and parse10 will return a list of the correct size listToPixel :: [Word8] -&gt; PixelRGBA8 listToPixel (r:g:b:a:[]) = PixelRGBA8 r g b a hexPattern :: String hexPattern = "^(0x|#)([[:xdigit:]]{2,2})([[:xdigit:]]{2,2})([[:xdigit:]]{2,2})([[:xdigit:]]{2,2})" baseTenPattern :: String baseTenPattern = "^([0-9]{1,3}):([0-9]{1,3}):([0-9]{1,3}):([0-9]{1,3})" Like I said this code works and I'm mostly just looking to make it cleaner/faster. I do have a couple questions as well though. First, the regexes at the end: according to wikipedia the posix style should let me write `baseTenPattern = "^([0-9]{1,3}):\1:\1:\1"` but this does not match when I try it. Second, when I'm passing Either String Results around in code like this, how does the monadic code actually operate? Will `sequence [Left "foo",Right 3,Left "bar"]` return `"foo"` or `"foobar"`?
Early forcing does change the semantics of your program.
oh? how are they different and how are they the same?
I think using gist would be a better way to share snippets of code
We also like lambdapaste : http://lpaste.net
What you describe involves typedef-ing names to give you types you can work with of a consistent size across architectures/compilers/etc, because the standard doesn't guarantee the sizes (though does guarantee &gt;= relationships between them). You can still work with UINT8 with the usual operators (which is mostly a good thing), and passing a UINT8 where a UINT32 is expected will compile with no warnings. If what you're dealing with is "just numbers" this is fine - no risk of overflow or loss of precision. However, if I am calling a function "buyDonuts(uint32 quantity, uint32 price)" and I call it with "buyDonuts(price, quantity)" then my program will compile, may pass tests (depending on how thorough the tests and how unlucky I am), and will likely get me the wrong number of donuts. So what I do instead is: typedef struct price { uint32_t value; } price_t; typedef struct quantity { uint32_t value; } quantity_t; int buyDonuts(price_t, quantity_t); because then if I call it with "buyDonuts(quantity, price)" the compiler will complain that I am passing in the wrong type. This does mean that when I need to add or subtract or whatnot, I need to add a .value, which isn't ideal but hasn't been terribly cumbersome. I was also able to wrangle some C11 features to write a macro that asserts type equality (strictly, type compatability, but when dealing with named structs that's equality) statically. 
I am one of core Leksah devs and I would love to fix your issue with debugging not working in 7.6.3. Could you please provide a few more details? Leksah version, GHC version and OS would be cool. Also does it output anything to the log pane when you start GHCi. Details of the current dev versions are here... https://groups.google.com/forum/#!topic/leksah/MfKW6I-tTlY As far as I know ghci mode should work with GHC 7.6.3
If you have trouble with your metadata not updating (now that your GHC is newer than the one used to build Leksah), then please try upgrading to one of the dev versions... https://groups.google.com/forum/#!topic/leksah/MfKW6I-tTlY 
[Kay](http://lpaste.net/92931) Oh, here's another question. I had to write a variant on `words` that cuts on `','` instead. Why isn't there a version in Data.List that just takes a predicate or list element to match on?
So I wonder. Is it possible to make the compiler accept the code without warnings by changing the type of "func" to a function that takes 1 element lists and an int ? I'm guessing there's no way at the type level to have a 1 element list type ?
I highly recommend reading Real World Haskell and Learn You A Haskell, both free textbooks on introductory Haskell. They clarify a lot of this stuff, and help ya develop good habits.
Neat! Doesn't explain why the basic functionality isn't in Data.List though.
You will need to fake dependent types, so you cannot use directly lists, but have to resort to vectors. An example is given in McBride’s ‘Faking it’ (2001).
No you don't. data SafeList a = Single a | Cons a (SafeList a) 
May I suggest a slightly more readable grouping function? import Data.List (groupBy) groupByAscending :: (a -&gt; Int) -&gt; [a] -&gt; [[a]] groupByAscending cond list = map (map fst) grouped where shouldGroup gs = zipWith (&lt;=) (0:gs) gs groupList = shouldGroup $ map cond list grouped = groupBy (const snd) $ zipWith (,) list groupList groupTablesForCreation :: ColumnList -&gt; [ColumnList] groupTablesForCreation = groupByAscending (\(_,_,n) -&gt; n) main = print $ groupTablesForCreation [ ("one", "two", 2), ("three", "four", 3), ("five", "six", 1), ("meep","zort", 0), ("whaargarbl","flibble",0),("blah1","blah2",10), ("blah2","blah3",20),("blah3","blah4",30) ] -- returns [[("one","two",2),("three","four",3)], [("five","six",1)], [("meep","zort",0),("whaargarbl","flibble",0), ... ]] Your formulation is likely very fast, however this formulation is able to generate an infinite list of groups from an infinite list input.
You can't use the built in [a] sugar then though.
You wouldn't be able to do so by faking indexed vectors either. Anyway, could use viewPatterns? foo (asList -&gt; [x]) = _
[Posted here](http://www.reddit.com/r/haskell/comments/1ma081/pretty_new_to_haskell_wheres_a_good_place_to_go/cc7dd2l)
You can see from the URL that it's in another package (split-0.2.2) which is separate from the base package that Data.List is a part of. You're right that it should probably be in base, but remember that Haskell was, up until relatively recently, a very academic language with relatively few "practical" users. In the last five to ten years usage has really exploded and people have added packages to fill the gaps. Lots of us have problems with the structure of the Prelude and the base libraries, but they unfortunately reflect the somewhat haphazard evolution of the language ecosystem. In some cases fixing problems would mean breaking with the standard (which in some cases was not well thought-out), and in the other cases it would mean breaking what now amounts to a lot of existing code. This is the price you pay for success I guess, which is why we've always tried to avoid it at all costs.
Oh yea, we're on the same page. I just wish there was a way I could define a hard range like 0 .. 99 without going to mods or libraries. Well, I guess if you work with full scale values then it doesn't feel so wasteful assuming precision is useful.
So, charging, say, $20 per year for open source projects could be reasonable? Or $10 or $100, whatever. I guess as a community we could make a case for something like that. I think the main problem might be that the number of developers is not that high, so charging very little might not work out for them if they need to deploy sufficient machinery on their backend. And of that smallish number, there are probably a lot who will stick to emacs, vim, or whatever they have set up now. At least until everybody starts bragging about how awesome the tool is (if it is). 
you might like to port it to use bytestring. that will improve your baseline performance considerably. when you build (byte)strings you might like to check blaze out. (i don't know whether it is still faster than bytestring's builder though.) using a builder instead of appending already constructed bytestrings should lead to a speedup as well.
 -- This header goes at the top of each Blueprint and tells -- quickfort where to start and in what mode to run header :: Position -&gt; Int -&gt; Phase -&gt; String header pos w p = '#':mode p ++ start ++ replicate w ',' where start = maybe "" (λx -&gt; " start" ++ show x) pos mode Dig = "dig" mode Build = "build" mode Place = "place" mode _ = "query"
I had not known gambit. Thank's.
Every time I read something from Edward, I come to a very startling conclusion by the end: *that I don't really know how to computer*.
&gt; Conor McBride wrote the wonderful titled "Clowns to the left of me, jokers to the right" on how one can compute the derivatives of a polynomial functor and use it as a one hole context. Isn't this a mischaracterisation of the McBride paper? What Ed describes here are regular zippers, whereas the Clowns &amp; Jokers paper is about representing a data structure 'in the intermediate state' of a map of some `f :: a -&gt; b`, when some of its leafs are already processed and so are `f x :: b`, and some are still to be done, so are `x :: a`.
I've just now realized that the author probably mixed up the Clowns &amp; Jokers paper with this one also by McBride, which really is about a mechanical derivation of the type of a zipper for a polynomial functor: [The Derivative of a Regular Type is its Type of One-Hole Contexts](http://strictlypositive.org/diff.pdf).
There's also the [Code Review Stack Exchange](http://codereview.stackexchange.com/questions/tagged/haskell) although Haskell activity there is kind of low.
Yes, Clowns and Jokers is a next-step after the One-Hole Contexts paper, I think.
Glad to be of help! I had pinged the color themes developers to know how I could integrate but they never came back to me, I'll try again.
I guess it depends on what you want out of Haskell. Do you want a programming language that will pay your bills? Or do you want a challenge that will undo and then expand many notions you have about mathematics, computation, and what it *means* to write a program? Neither of these answers is wrong. And luckily, they are also not mutually exclusive. The thing is, as a working programmer I've realized something: *many things you would write in Haskell are probably boring*. They're boring, and would still be boring if you wrote it in Java, or Ruby, or any number of things. That UI in labVIEW? Sounds boring, who cares what you write it in - really? In the long run, while Haskell may make you a happier engineer, and give you some real technical benefits, it's not going to make the programs you write 10x more exciting, in all honesty. Most of the time it's the same, Haskell or not: we do our job, and move on It's true, nobody writes-with-glee an article "How to write a network server with `forkIO`", but Edward may write this article instead. Yes, maybe that network server *is* more 'practical' every day of your life, as opposed to conquering folds with Comonads - but it's also boring as hell! And I've done it in about every language ever, modulo each-to-their-own technical concerns. Yes, Haskell has *technical features* that set it aside from the rest of the crowd. But really? Technicalities are learned every day. It's my job. I can use a `Monad` just as much as an `AbstractSingletonProxyFactoryBean` in real code, learn how to use an `MVar`, etc. That's *cool*, and it gets the job done. But I can get that same feeling from any other number of things - including a powerdrill.* So what you're seeing is, IMO, a biproduct of people discovering results on their own. These results are not the kind you will not see in another language. When you give someone a new method of communication, they will often use it to its strengths. It's no wonder a foreign programming language with roots in the CS community gives rise to abstract thought! So the fact we're good at it is not surprising either. When you have a choice between the boring and mundane, or the constant enlightenment Haskell seems to give most people - which do you think they will be more willing to speak of? I'd much rather enlighten other people, than write the 90 **trillionth** article about a HTTP PING/PONG load test - even if we kick ass at PING/PONG benchmarks. Perhaps this isn't an indictment of Haskell - but of other languages, that they do not allow us a means of communicating such thoughts clearly. The Sapir-Whorf of programming languages. Haskell is a language that has challenged me constantly, with a community that has done the same. I'm not even a mathematician, I'm a college dropout, and professional programmer by trade. I was lured by the uniqueness, and stayed for the language. And it has forever tied me to the realm of programming language theory, discrete mathematics, and our abstract notions of *what it means to compute 'stuff'* - a practice performed by Humans since the dawn of written history. Incidentally, Haskell also happens to be the language now paying my bills. I'm not writing the most exciting software ever, all the time, with comonads of parallellized CRC'd morton-ordered folds in every other module. But I would be extremely sad to see this sort of work leave the community, as it's the reason many of us stay. ------------------ * There are, of course, many interesting things to be said about using Haskell's technical features to tackle a problem in an interesting, unique way. And we have lots of those! Real World Haskell, Simon's new book, and there is tons and *tons* of content in places like StackOverflow about how to use Haskell-abstractions to build robust programs, in ways unlike other languages. And we have an extremely helpful community with many professional programmers who will help you. You can find many of the same resources for Haskell as you can for other languages. We may not have as many, for sure. And we can always have more. But even then, programs come and go - but ideas, they may live forever.
Thunks don't just sit around and take up space. The computations they guard might produce values that take even *more* space.
I think that was a list of separate items: &gt; Real World Haskell, Simon's new book, and there is tons and tons of content in places like StackOverflow about how to use Haskell-abstractions to build robust programs, in ways unlike other languages. is &gt; (i) Real World Haskell, (ii) Simon's new book, and there is (iii) tons and tons of content in places like StackOverflow about how to use Haskell-abstractions to build robust programs, in ways unlike other languages.
But what about: let x = undefined c = {- computation that uses too many thunks, but doesn't use x -} in c Now, if the 'x' thunk gets forced because the thunk queue overflows while evaluating c, the semantics of the program have changed: x is now evaluated. 
A derivative of a functor takes that functor and punches some kind of hole in it. The is one of the interesting results in combinatorial species. If you look at the Morihata et al. paper I mentioned in the writeup you'll find they are doing exactly that. The zippers I'm writing here are hand-expanded versions of what you'd get automatically from Conor's approach from section 2.1 of the dissection paper. Conor wasn't the first person to do this though. The notion goes back to Joyal's less accessible theory of [combinatorial species](http://en.wikipedia.org/wiki/Combinatorial_species). In fact, when I first did this I derived them automatically through generic programming by just reading off the formulae. He starts there then dives deeper, by switching to a different derivative. But, [all of these derivatives are related.](http://blog.sigfpe.com/2007/01/foxs-ubiquitous-free-derivative-pt-2.html)
That probably would have better a better paper to cite, but I never read it. ;) I've edited the post to mention it.
See my answer to this question -- we want a smaller base, not larger!
What a funny coincidence — I've been [implementing][gh] record wildcards in [haskell-names][] recently, and even started to write a blog post about them (although I'm not sure I'm going to finish it). Yes, they are tricky to implement. What annoys me the most about them is a possibility of this happening inside a single module: data A = A { a :: () } A {..} = undefined It's not valid because of the name clash between the selector function and the top-level binding, but depending on the order of these two declarations you'll get either the not-in-scope or the ambiguity error. So you have to be careful to process data declarations before pattern bindings just to produce the correct error message, even though you know that that can't be valid code. [gh]: https://github.com/haskell-suite/haskell-names/issues/36 [haskell-names]: http://documentup.com/haskell-suite/haskell-names 
Thank you for the response, but I think readability is in the eyes of the beholder. I would expect that using multiple levels of map/zipWith/tuple sections and groupBy all together would be more difficult for a beginner to understand than my version which I'd expect to be pretty straightfoward as soon as someone understands foldl (with the possible exception of why the reversing is necessary). Being able to deal with infinite lists certainly can be useful, but since this is taking input from an SQL query and generating SQL queries, I don't think that is necessary here. Still, it is certainly useful to be aware of those differences. Having more versions to look at surely helps the OP, so even if I don't prefer it I'm sure your work is not wasted!
Actually, in this case 'x' wouldn't get evaluated (in python). My use of weakrefs ensures that when 'x' is collected (immediately), it is removed from the thunk queue.
Or they might not. The case where they do not is a laziness derived space leak. Examine for example one of the quintessential laziness space leak ([I use leak loosely to mean unexpected space inefficiency](http://www.ittc.ku.edu/~neil/papers_and_talks/strictness.pdf) ) : sum [] cumm = cumm sum (a:r) cumm = sum r $ a + cumm Obviously, the leak could be solved by inclusion of a well placed bang, but suppose you didn't know to do that. What would happen is that as you recurse, a thunk "list" gets created: sum (a:b:c:d...) cumm ===&gt; ... + ( d + (b + (a +cumm))) ... Our corresponding python code might look like (supposing we have tail recursion - ha, and we've implemented it with thunks for no good reason): thunks = lethargy.lethargy(20) def sum(lst, cumm): if not lst: return cumm return sum(lst.next, thunks.delay(lambda arg: lst.value + cumm())); Suppose you pass a larger list, say of size 3000, into sum. Instead of the result being a thunk stack of 3000 layers deep, it is now constrained to be a thunk stack 20 layers deep. The drawback here is that you can no longer pass an infinite list into sum. What would previously be both a space leak and a time leak is now just a time leak (many would argue that this is easier to debug). This doesn't stop you from defining infinite lists though. class Node(object): __init__(self,item,next): self.item = item self.next = next thunks = lethargy.lethargy(20) def iterate(foo, curr): return Node(curr, thunks.delay(iterate, foo, thunks.delay(foo, curr)) ) This way though, if you try to access force the 1000th element of the list, a thunk stack of size 1000 isn't actually generated. 
Yeah, I have this tendency to code in a stream of thought way that abuses guards, that's a lot cleaner.
Oh cool, I don't know how I missed that when I was looking through the bytestring library before.
Hmm, I don't see how that's related.
There's a fair bit of imperative code (grep for "\&lt;ref\&gt;" and "&lt;-"). Partly because I'm converting Python and partly because that's how I think. A few times I used fold_left to do something first and then simplified it by using mutation instead. Maybe I should write a utility function to do the Haskell list monad thing (flatten (map ...)) efficiently. I think writing the SAT solver in a functional style would be a nightmare (maybe it would be possible using the state monad, but that's not really a functional style). Here's the current code if anyone fancies a challenge: https://github.com/0install/0install/blob/master/ocaml/support/sat.ml Mainly I use mutation locally, and then return an immutable result. Having everything immutable by default (e.g. lists) is a big win over Python (e.g. you can return a list without worrying the receiver will modify it). My impression is that the community is a bit smaller than for Haskell, but so far I've found all the libraries I need. But I haven't used many. I'll find out more in the next stage (porting the networking and GUI code). I'm using Vim for editing. The default OCaml support is good (syntax highlighting, error parsing, querying type annotations, smart indentation), but now I've moved to using the LWT version of the plugin to support the light-weight-threading syntax extensions: https://github.com/talex5/ocaml_lwt.vim
I get that they're a pain to implement; that's really not the same as them being evil.
Right now, I'm more interested in getting practical stuff done than admiring the beauty of the abstractions. And I also feel intimidated by the title and the intro paragraphs in Edward's posts (in my own field, it's customary to start a paper with at least three platitudes about how animals without ability X wouldn't be able to survive, so it can be jarring to dive right into these triple-hylomorphism co-backflip kinds of things). But I come away with the opposite feeling from yours, I think. First, while learning Haskell I'm coming across lots of promises about how the language features will end up improving your code in practical ways. For example, benefits of purity, lists being about control flow rather than just data structures, and monads being "programmable semicolons" - at first I didn't understand these ideas at all (and I was skeptical that they would ever be useful). But invariably, as soon as I understood one, it would instantly pop up in my haskell code, and I'd sorely miss it when I went back to matlab. When I read edward's posts, I'm reminded that that well of abstractions - things I don't yet understand but someday will, and someday will make my code better - will never dry up. The second feeling I have when I first browse an ekmett post and think about the ridiculous amount of productivity is incompetence-dread: How can this guy (and the Simons and Snoyman and Tekmo and the REPA guys and bos and etc etc etc) produce so much awesome stuff? Am I just too dumb for this? But the resolution is actually hinted at in Edward's own words in the recent haskell-cast. When you learn some math things, the next math things become easier to learn. I think Edward picked up a few masters degrees than synergized, he (and his ilk) hit a learning-positive-feedback loop, and is now riding up some kind of vertical asymptote toward infinite productivity. I love it when I read some practicality-oriented haskell post that leaves me feeling like I know how to accomplish task x TODAY (every chapter of RWH). But I also love the feeling I get from ekmett posts - that something is completely baffling to me today but I'm getting subconscious scaffolding that could help me hit the positive-feedback-loop down the road. Not saying your view is invalid! Just sharing my developing feelings about the whole theory vs. practicality thing.
Agreed. And there are cases where they fit nicely (e.g. DSLs). But in general I tend to avoid them as a user for the same reasons they're hard to implement. E.g. you can't find where the variable is bound by simple text search.
"There are more things in Heaven and Earth"?
Keep in mind that all of the enormously productive people you encounter all have one thing in common: their day job is to program in Haskell (or has been at one point in time). Once you program in Haskell professionally you become enormously productive because you have the time to practice and fully flesh out all the little details that you would miss out on simply from reading posts and paper. Also, the fact that these programmers are so productive is a reflection on how well-designed the language is. It really does make you that productive, both because of the intrinsic benefits of the language and also because it teaches you to become a more productive programmer in a language-agnostic way.
type classes are erased before getting to core, so not an issue in practice. Polymorphism though is a problem. More generally, just converting to a point free categorical language doesn't really get you efficient circuits, since the categorical language is still higher order.
Might want to look into [cassava](http://hackage.haskell.org/package/cassava). It offers some nice typeclass-based abstractions so you can define CSV representations at the type level similar to what you do in Aeson for JSON. Must be more performant than using arrays of strings as well.
It's an example of why re-exports are different from import-and-then-export when implementing mutually recursive modules.
Interestingly, most of my posts came from before I got to where I get to program Haskell professionally. The other option is to just give up sleep. ;)
I sadly mostly avoid them just because of the shadowing warnings. ;)
I don't think it's clear how such a length function would be defined. I can think of two possibilities: length1 :: BashVar -&gt; Int length1 (BashString _) = 1 length1 (BashArray xs) = length xs and: length2 :: BashVar -&gt; Int length2 (BashString xs) = length xs length2 (BashArray ys) = length ys Which one do you want? 
Great reference! I can't believe I never saw that paper before.
You may be interested in using ClassyPrelude, which abuses ad-hoc polymorphism to overload commonly used function names such as `length`. http://hackage.haskell.org/packages/archive/classy-prelude/0.5.10/doc/html/ClassyPrelude.html#v:length
thank you for the considerate response. i'm having a hard time summarizing it to myself, but i'll respond to a few comments. &gt; Or do you want a challenge that will undo and then expand many notions you have about mathematics, computation, and what it means to write a program? i'm on board with haskell itself, but the ecosystem is simply not good. so if that ecosytem exists elsewhere, someone needs to convince me that it's worth my time investing in helping to build a similar ecosystem in haskell. when i feel that the general community is not interested in that, it lessens my want to do so and increases my leaning towards other solutions. honestly, haskell hasn't pushed any boundaries for me mathematically, as coming from a mathematics background, i find most of haskell intuitive since it directly draws upon that pool of knowledge. trust me, as any other beginner, i have been incredibly excited about haskell and its potential. but moving beyond that stage has proved frustrating, more so than other languages i've experienced, and everything i seem to see in terms of it pushing computation and programming is experimental and ultimately not immediately useful. &gt; Sounds boring, who cares what you write it in - really? exactly. if you were to put up labview vs. haskell in terms of what "software engineers" or "programmers" would consider to be the better language or which one is more preferrable, i bet haskell would win hands down. but yet, labview helps run one of the most complex experiments and machines ever in the LHC at CERN and runs SpaceX's software down in mission control. does haskell have ANYTHING that comes close to being that useful? i'm disappointed to say that i'm afraid not. labview itself has many useful abstractions and has similarities with functional programming given that it's a dataflow language, but i would wager haskell's abstractions destroy labview's. but when it comes down to being immediate and useful, haskell cannot hold a candle to labview and its many applications. so some of my frustration has come about through hearing about how all these abstractions make haskell so amazing. then show me beyond showing me a tool just made for other programmers or some undocumented library made for programmers! i'm optimistic about haskell and what it stands for, but i'm getting a confused message from the community. is it a research language or a language made to build useful applications for people or is it both? i'm gathering it's the first choice right now, but i'm excited to see it move to the right.
Proofs from the Book is excellent.
this is true, and i am attempting to get to that point. however, as i mention in another thread, i have to balance my time and queued projects wisely. and one of my most major concerns is i have serious doubts in haskell being useful in writing an end-to-end application with full GUI functionality for general users.
thanks! are there disadvantages? there must be a reason why this isn’t the standard prelude.
that’s a nice narrative, but i seem to have missed its climax ;) the last part was very informative, but with `derive`, there is a way to, well, derive operations which support all used data types, so i’d like to use that for length, since both data types are lists, which i can call length on. are you trying to say that i shouldn’t do it that way? how else? i need some way to store both lists of strings and strings while being able to discriminate them, and calling length on them. currently i implement “are you a list of strings or a string? i don’t care, i’m calling the same function on you whatever you are” and feel silly.
Here's a Calkin-Wilf tree compatible with this tutorial, extracted from that paper calkinWilf :: Tree Rational calkinWilf = unfoldTree step (Pair 0 1, Pair 1 0) where step (l, r) = let m@(Pair n d) = adj l r in Just $ ((l, m), n % d, (m, r)) adj (Pair m n) (Pair m' n') = Pair (m + m') (n + n')
This isn't a research article. Granted, I work with Ed. But we use stuff similar to this in actual programs. It is not just for blog posts. This might be a little fancier than normal, but it's not purely academic.
The main reason Haskell suffers on the GUI front is purely due to very few up-to-date bindings. `gtk` is the only mature and maintained library for GUI functionality.
Wrong. Lists are *free* monoids: arbitrary monoids are not necessarily like lists. I'd say that the ones that capture the essence of a list best are `Foldable` and `Traversable`. Indeed, it does allow to define `length` and folds generally, among other things.
&gt; that’s the reason why i asked in the first place, as i simply want to use the list function length on the list that invariably is in each BashVar: both String and [String] are lists, so length could be applied without knowing which one we have. How about this? asList :: (forall a. [a] -&gt; b) -&gt; BashList -&gt; b asList f (BashString s) = f s asList f (BashArray arr) = f arr asList' :: (forall a. [a] -&gt; [a]) -&gt; BashList -&gt; BashList asList' f (BashString s) = BashString $ f s asList' f (BashArray arr) = BashString $ f arr' These functions, if written, would allow you to "access the underlying lists", as you want. Specially, `asList length` is what you want. However, the types are telling you the problem with what you want: yes, you know that they are lists, but you don't know *what* they contain until you actually pattern match, so they must support everything: that's what you can't take "functions on lists" just like that and put them into your ADT. There is not a safe, general pattern to do that, let alone make the compiler derive them, as you asked for. Another confusion: no, `[String]` and `String` are not "both `[a]`s). Basically, a polymorphic type is one that can have many concrete types, instead of type one. That means that an `[a]` can be either a `String` or a `[String]`, but the other way round doesn't make sense: a `String` can't be anything but a `String`, and `String` and `[String]` don't have the same type at all. What happens when you do `length [1,2,3]` and `length "abc"` is that `length :: [a] -&gt; Int`, so when it's applied to a `String`, the compiler infers that the type we want is `[Char] -&gt; Int`. 
The disadvantages are: 1. Sometimes type errors are difficult to understand/misleading. 2. Some of the classes don't have or break some laws in the name of pragmatism.
This is the best answer.
But it's not what OP wants, since the kind of Foldable doesn't match with his ADT. [I came up with this](http://www.reddit.com/r/haskell/comments/1mbn17/why_no_list_type_class/cc7qna1), which is ugly, but because OP's question doesn't make a lot of sense.
We have a student hacking this summer of code on GUI bindings. I'm not that student. This post may not be of interest to you today. However, it was intended to showcase that there is a way to compute many algorithms we commonly compute inefficiently over trees with a great deal more parallelism. This has led to some [practical speedups](http://dl.acm.org/citation.cfm?id=1146860) when applied elsewhere, even in C++, in a setting where it can be given to the user as a library and the craziness can be largely concealed. In Haskell we have REPA and Accelerate. They do some crazy stuff under the hood, and in the end naively written straightline code becomes efficient and parallel. The internals of these tools are rarely understood by their users, but their public APIs are quite easy to use for the everyman. The "third homomorphism theorem on trees" shows that this isn't a speedup limited to working on 'data parallel arrays', but instead can be applied to just about every data type! In the end it has the potential to offer you a suite of tools that feel like mapping, reducing, scanning, folding just like you know how to do, but which just happens to use all the cores you have for free. The approach I'm exploring in the post is how to start turning it into a library rather than a research problem. It isn't yet in the form that it can be picked up by 'someone in the trenches' but eventually it may turn into something easy enough for them to use. I found it interesting and so I took a few hours to write up a post about it, so that other people who may be able to contribute to the effort can see what it is all about. Some of the posts I write are targeted at a very general audience. Others aim a bit higher. Along the way I generally try to point people at interesting bits of theory, because that is what interests me about Haskell. Your statement makes it sound like there is a zero sum game; that either we can do web apps, or we can have beautiful theory. In practice I'm writing the post on something that has a beautiful theory or I'm probably not writing anything at all. If nobody pushes the envelope of these things then the world strikes me as a relatively depressing place to live in. The idea that I'll be thinking the same thoughts in 8 years working on the same problems would be enough to drive me to contemplate a different career. In fact, it did once, but fortunately I found Haskell before my transformation into the guy in a suit was complete. If you are looking for immediate applicability, this post isn't for you. It is a stab at one approach I think could be useful for how to think about a bigger problem. We burn through a lot of those and some of them pay out. Or I could go write a GUI binding and turn to drinking on the weekends. I maintain dozens of packages for things that I try to make "just work" in Hasekell. I write Haskell precisely because it lets me think thoughts I can't think in other languages. I try to encourage people to learn new things from a theory perspective because it gives me more people to talk to and makes the conversations we can have more interesting. I too am interesting in productive, scalable software. My time horizon is just a little bit longer than yours, and my sights are set on something a bit more ambitious than on replicating the status quo that exists elsewhere. 
i’m new to haskell, so are “laws” what others call “conventions”? because the compiler seems to be more than able to keep people from breaking laws…
What about TH?
Well, which functions should it contain, and what laws should they follow?
Well, it's the first phase after unlit, `CPP`, `ImplicitPrelude`, module resolution, `TemplateHaskell`, `QuasiQuotes`, deriving mechanism (in that order). Note that these phases are mostly metaprogramming-related. Also, I'm not going to implement TH and QQ, because nofib doesn't use it ;) (\*knock on wood\*)
&gt; someone needs to convince me that it's worth my time investing in helping to build a similar ecosystem in haskell. when i feel that the general community is not interested in that, it lessens my want to do so and increases my leaning towards other solutions. There is nobody in the world who can convince you of what your time is worth, other than yourself. Certainly not any Haskell programmer. It sounds as if your mind might already be made up, in fact. I will say the two things you've highlighted in this thread (windows and GUIs) are certainly lackluster in comparison to many other libraries we tout. Unfortunately I hear people complain about Windows and GUIs like, every week, and every week goes by that I see nothing done about it by anyone, including these complainers. Thus, the patience I (and many people) have for these complaints is wearing thin to the point there's literally nothing I can do but say "fix it then." I'm a Linux user, my clients (right now) use Linux, my software runs on Linux. I'm not writing GUI software. What are we as a community to do? Stop everything and write Windows and GUI bindings? Like you, I have limited time. Working on Windows and GUI bindings is the last thing on my mind (and I help maintain GHC on Windows.) &gt; but yet, labview helps run one of the most complex experiments and machines ever in the LHC at CERN and runs SpaceX's software down in mission control. does haskell have ANYTHING that comes close to being that useful? I don't know. If LHC and CERN are your only metrics for "useful" - a nebulous term itself - I'm not sure many programming languages qualify or can even come close. Haskell has been used in many industries from HDLs for automotive hardware design, to writing theorem provers for cryptographic software like Cryptol, which can be used to prove correctness of software implementations (or hardware implementations.) And static analysis tools. And financial tools. And used at banks. And used for quantitative analysis. And signal processing. And microkernel verification (and the NICTA se.L4 project has been commercialized, FYI.) Are these as 'useful' as SpaceX? I don't know. Perhaps garbage truck hydraulic control and cryptographic software, finance and all that other stuff are not as *hip* as SpaceX, for sure - but these are systems people literally risk their lives on every day, systems which the world needs to work correctly. I don't think it's fair to downplay this work as "less useful" than something like SpaceX. Frankly I'm far more likely to see "useful" results personally from the COBOL running my bank account, than the labVIEW software at SpaceX.
`Foldable` is basically the `toList` type class, so you can always have an (inefficient) `length` function by just defining: length :: (Foldable f) =&gt; f a -&gt; Int length = Prelude.length . toList I suspect a better solution would be to add `length` as a member to the `Foldable` type class since many data structures that implement `Foldable` already keep track of the length and can provide a O(1) implementation of it.
"Laws" are things that the compiler can't enforce (otherwise there's no need to specify them) that are likely to be relied upon by code using the type(class).
The experimental tag on hackage is useless. Its sort of like how most packages (even very stable ones) are afraid to go from 0.xxx to 1.xxx. Its a community "feature" that people are extremely loathe to declare something as "solid". But in my experience, some things labeled "experimental" and in the 0.xx series in hackage are some of the most reliable libraries I've used (others of course really _are_ unmaintained proofs-of-concept, as is the case with any large listing of community generated libraries). You actually had a few good responses to your UI question, so I don't understand the frustration. We have a _great_ ecosystem generally, including lots of great algos and datastructures packaged up, plenty of foreign bindings to standard C libraries, as well as lots of api integration stuff, etc. What we lack is largely _great_ UI libraries. But we have adequate ones. I also note from your post below that you're frustrated about the windows ecosystem. You're right that everything there is generally worse. This is because most core Haskell developers have traditionally worked on *nix derivatives. Many things are different between windows and *nix systems, and there are many people paid by first sun and now oracle a large chunk of change to maintain a platform-independent substrate. We don't have those people and that funding. Instead we find Windows is often a second-class citizen, despite our best efforts, and the only solution is to find more people on windows machines willing to put in more effort to make sure libraries work there too. This is precisely why so many people turn to web-style interfaces -- because they're immediately portable across platforms, and don't require bindings to C libraries that are often hard to get working on windows (or even sometimes on mac). There are many examples of useful real-world haskell deployments for all sorts of things. But yes, most of them don't involve GUIs (other than sometimes web GUIs). I wish it were otherwise, but it requires a critical mass of people tackling the problem, and willing to work to make things better. 
Haskell is not a language that has ever errored on the side of being easy for the compiler writer to implement. So this argument doesn't really hold much weight IMO.
[those](http://www.haskell.org/ghc/docs/latest/html/libraries/base/Data-List.html). e.g. Bytestring already does al (or almost all) of them.
Doh, thanks!
 data BashVar = BashString String | BashArray [String] deriving (Eq,Show) This is not like a list. If it was a list, what would the type of its elements be? You might say that the elements are `Char` or `String`, and we will know at run-time which specific type. But we need to know at compile-time: otherwise how can the compiler know whether `myBashVar ++ "penny"` typechecks or not? You might say, ok, the elements are `Either Char String`. But then you have to allow values like `[Left 'a', Right "carrot"]` which you specifically want to exclude. So one answer is: `BashVar` wouldn't be able to implement a list class even if Haskell had a standard list class, because although it has a sensible `length`, it doesn't have a sensible `++`, `cons`, `uncons`, etc.
From the snippet on StackOverflow, I don't know what you should do. It depends on what you're using the length for, and why it seems to you that the natural length for a BashArray is the number of items, and not, say, the length of the string formed by concatenating together the items with spaces (like bash does when you try to nest arrays). If you structured it like this, you could use list functions: data BashElem = BChar Char | BString [Char] type BashVar = [BashElem] But that gives you heterogeneous BashVars in a way you probably don't want. 
&gt; as said multiple times in the stackoverflow answer: the second one. It's not so much that people are confused by what you mean. It's that the compiler can't know that everyone would always mean what you mean. Honestly, that's true of the existing, legal deriving clauses too. Deriving type classes is a bit of a hack. It's an incredibly convenient hack, which is why it exists for a few of the most-used classes, but you don't want it everywhere.
Usually in Haskell lingo, "laws" refers to guarantees which are not already enforced by the type system. For example, stating that "the `even` function will always give you `True` or `False`" is enforced by the type signature `even :: Integral a =&gt; a -&gt; Bool`, so even though a statement like this could be called a "law", it's usually not. When chrisdoner says that some of the ClassyPrelude classes "break some laws," what he means is that the classes do not enforce certain behaviors which you might expect to be enforced. It is common for Haskellers to create a class, and then say "if you want to make an instance of this class for your data type, you should first make sure that your instance obeys certain laws X, Y, and Z..." ClassyPrelude does not do this. For example, one intuitive law is that: length (map f xs) == length xs ClassyPrelude documentation mentions nothing and promises nothing about this law, or any law for that matter. This is why some Haskellers find it distasteful. ClassyPrelude is just a hack to make writing Haskell code easier and more intuitive, it relieves the annoyance of having to, for example, `import qualified Data.Text as T` and then `T.map`.
Or you could just make a related class (with convenient but slow default implementation): class (Foldable f) =&gt; Lengthy f where length :: f a -&gt; Int length = Prelude.length . Foldable.toList 
&gt; But we need to know at compile-time: otherwise how can the compiler know whether myBashVar ++ "penny" typechecks or not? `length` doesn’t use the type information of the elements, it’s just length :: [a] -&gt; Int length [] = 0 length (_:l) = 1 + length l
Some laws could possibly be checked at runtime, but often they can't (or you wouldn't want to for reasons such as efficiency). Laws are often expressed as equations, and the notion of equality you're using might not be exactly the same as the language's notion of it. As an example of a law, consider associativity. A function `f` is associative if `f (f a b) c === f a (f b c)`. (There are [lots](http://hackage.haskell.org/packages/archive/base/latest/doc/html/Data-Monoid.html) [of](http://hackage.haskell.org/packages/archive/base/latest/doc/html/Control-Monad.html) [typeclasses](http://hackage.haskell.org/packages/archive/base/latest/doc/html/Control-Category.html) that rely on some function or other being associative.) It's conceivable for the language runtime to always run the code both ways whenever your program contains either and then throw an exception (or something) if it fails, but it would be very slow. But it being slow isn't the only problem: what does the `===` mean above? It's not always the same in every case: For example, you can write "lists" that are trees internally (`data TreeList a = Leaf a | Branch (TreeList a) (TreeList a)`) so that `append` can be efficient (`append a b = Branch a b`). As long as you don't expose the internals of your library, `append (append a b) c` looks just like `append a (append b c)` (they're both `a`, then `b`, then `c`), but there's no way for the compiler *or the runtime* to know that you intend `Branch (Leaf 1) (Branch (Leaf 2) (Leaf 3))` to be the "same" as `Branch (Branch (Leaf 1) (Leaf 2)) (Leaf 3)`. A "law checker" might complain about `append` even though there's no way for the library's users to tell the difference.
&gt; why it seems to you that the natural length for a BashArray is the number of items because it is: foo=('ab' 'cd') bar='abcd' echo "${#foo}" # →2 echo "${#bar}" # →4 and thanks for the idea, but i already considered it and it’s indeed just trading one uglyness for another. nice thinking, though (if i may say so)
Sure, but any list typeclass will have to include functions that *do* use the type information of the elements. And if that typeclass can be automatically derived at all, the compiler would only do so when *all* those functions can be defined; otherwise it might be covering up a bug in your program: it doesn't know that you won't try to use one of those other functions, after all. Maybe you're not asking about a list typeclass, maybe you're asking about a has-a-length typeclass?
You can get some functions such as `insert` for free if you implement `Eq` and `Ord`.
I don't think I understand what justification you believe GHC would have for removing one of your recursive calls to delete. 
Once place you could look for ideas is [Lava](http://raintown.org/lava/). I'm excited to hear more about your project!
I would use pattern matching instead of those "x &lt; y" guards because then you can have the compiler warn you if you forget to handle one of the cases. In fact, I think your insert function is missing the "equals" case. case cmp x y of LT -&gt; (rebalance ...) EQ -&gt; ... GT -&gt; (rebalance ... ) Another minor point is that I think that delete' might be needing to run bothe leftRotate and rightRotate because of the pattern matching you do. To be safe, and to minimize scope, I would move those definitions to inside the corresponding cases: | balance t &lt;= 0 = let (Node rrl rrr rrv _) = rightRotate t in rebalance $ (Node rrl (delete' rrr) rrv (inlineHeight rrl (delete' rrr))) | otherwise = let (Node lrl lrr lrv _) = leftRotate t in rebalance $ (Node (delete' lrl) lrr lrv (inlineHeight (delete' lrl) lrr)) 
I think he means this predicate: rebalance $ (Node rrl (delete' rrr) rrv (inlineHeight rrl (delete' rrr))) once `delete' rrr` is evaluated the first time, could'nt a compiler know that a second call would have the same output?
I think he wonders if GHC remembers the value of "delete l x" and "delete r x", when he uses them twice in an expression, of if the expressions are reduced twice when they are used twice. That is, if GHC caches the result of "delete l x".
I see. GHC does occasionally do common subexpression elimination, but only in very specific circumstances. Might as well just let bind it if you only want it to happen once.
I suppose with a language with a sufficiently clever run-time system, you could measure how much allocation/freeing happens as a result of forcing a thunk. If it takes more memory than if you hadn't forced it and you don't need the value right then, you could just turn it back into a thunk, throw away the result you just computed, and stick that thunk on a separate list of thunks that you shouldn't try to evaluate early.
My understanding is that for GHC to do common subexpression elimination you pretty much have to let bind both expressions, in which case you might as well just let bind it once and be guaranteed that it works, with less code. I could have something wrong though, because that restriction makes it seem nearly useless. I don't think your quote means what you think it means. I think it just means that it won't reduce the same expression *as in identity* more than once, not that it won't reduce the same expression *as in syntax* more than once.
There's an interesting thread developing on the ocaml list [1, but I'll completely summarize the part relevant for this post, so you don't have to search through the whole thing] - someone had complaints about lack of good GUI options. Jon Harrop (whether seriously or not, I'm not sure) suggested that the OP start working on a brand new native ocaml GUI library on top of opengl. There's a nice chapter in the Developing Applications in Ocaml book [2] that goes through the exercise of writing a from-scratch gui library on top of ocaml's primitive graphics/windowing api. Bet this would be easier with type classes! I'm not qualified to have a strong opinion about this, but to me it sounds like a nice idea, given that we are several years into having a great Haskell Platform (now with opengl). Personally, I'm not dying for feature parity with gtk. We'd probably love to have something simple to start with, on top of opengl, totally cross-platform. The only bindings and installation headaches we'd have would be those associated with opengl itself (minimal, thanks to haskell platform), and the window manager we'd go with (I'm guessing that something like glfw-b, which doesn't monopolize the main loop, would make experimentation easier?) I'd love to help work on such a thing, too. "Just go use hui" (or whatever you'd call it) could be a nice debate-ender :) There MUST be some reason why this hasn't been done already - but my first 5 minutes of googling only turn up discussions about GUI /bindings/. Yes, we'd be duplicating effort - maybe duplicate effort is less bad than wrestling with gtk though? Could anyone point me to my obvious oversight? Has it already been tried? Can we build on or steal ideas from Fudgets? Diagrams (for layout)? Should we try to put something together according to the simple prescription in the ocaml book? Also curious - would a gui library without an imperative soul's baggage make FRP or other abstraction experiments easier? [1] https://groups.google.com/forum/#!topic/fa.caml/ih0_k8RwHac [2] http://caml.inria.fr/pub/docs/oreilly-book/html/book-ora124.html edit: the second 5 minutes of googling is unearthing a lot more history :) And some current things like TV that seem relevant). Still interested in: the state of the union regarding work on a haskell native gui library. edit2: gloss? is gloss's handling of main (animate/simulate/play IO) ok for a gui library? edit3: last one, sorry for the noise: I just found haskell/r/haskell_proposals 
Think of it this way: all of the awesome stuff we already have — including GHC, Cabal, haddock, the libraries — are examples of things that failed to be monetized. (Except for contributions from MSR and IHG, but that's not enough.) To monetize open source projects (esp. developer tools) is a *really hard* problem which no-one in the community knows how to do, so it's not surprising that FP Complete doesn't want to tackle it.