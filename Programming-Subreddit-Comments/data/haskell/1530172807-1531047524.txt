They are Haskell and remote. Even if USA and Canada only show some excitement that the market is going this direction! I'm also from Europe but I'm glad companies like that take a try on remote and Haskell. Others will follow! 
I don't think they are. `flip ($) &lt;$&gt; Nothing &lt;*&gt; f` short circuits to `Nothing`
I think this is a good post, although it might be easy to interpret it like it was written in anger or something. I don't judge. Except for the performance issue, I have encountered every other problem you mentioned. Regarding how to interpret `Either`, this could be very similar in spirit to whether or not we should call `IO` "the `IO` monad", even though we do not make use of `(&gt;&gt;=)` in a given context and could just as well refer to "the `IO` semigroup" or just the data type. This terminology thing is probably a consequence of us using "dumb data types" and pushing semantics out to use sites. About composability: Using `withExceptT` and friends is not exactly composable, but I think it is tolerable. It doesn't *hurt* just yet, if used within reason. It is of advantage if the wrapper constructor accepts the "wrappee" as last argument. I do not think that `ExceptT` is the best choice in the first place, for errors that you can't handle "somewhat locally" or *at all*. If you *do* choose to propagate an error like this up a deep call stack, then probably because you want to annotate the error in some way. I don't know how you would do this with purescript, but using nested data types seems like a very principled choice then. And if you have made this choice because you actually want to pattern match on errors and somehow handle them, then the problem with the all-encompassing super-app-error should be mitigated *somewhat*. Of course you can handle errors "thrown by prisms". You just choose a concrete instance. This *might* of course result in you having to define a dedicated data type. Okay, that's boilerplate. You might be able to live with having to define a throw-away data type, or not. Maybe the type isn't throw-away to begin with. In any case, there are low-tech solutions, and while they may be *so 2012*, the situation isn't exactly bleak.
Drop the functional dependency on the `MonadError` class and suddenly you can throw specific errors and catch specific errors any way you want. As for the performance remark, I'd also like to see a benchmark. Since almost every statement in your transformer will be a `lift something` under the hood (with regards to the `ExceptT` transformer) except the ones throwing exceptions, each of those cases becomes a case-of-known-constructor which can be optimized away.
That caveat in the end it really worrying. I'm not really convinced that there are no other possibilities for an exception to go unchecked. Besides, what's the point of checked exceptions if you can't be absolutely sure that they work as expected? The whole thing seems pretty gimmicky, like it only happens to work accidentally. The exceptions should really be somehow attached to the actual computation, not just some scope in source.
Do you also like using `Bool` instead of a domain-specific ADT?
It's true that from `ExceptT e IO a` you can't really tell much about how a function behaves. I usually make a choice about what kinds of "exceptional situations" I want to handle locally, and which ones I can only print and bail out on. Since I don't want my whole application to be one giant `ExceptT` block, I will use exceptions for the latter, and catch them somewhere near `main`. While you *can* go all the way and define things like `MonadHttp` and `MonadReadFileSystem` or whatever, it comes with a lot of boilerplate. If you have some routine already, or if your application is large and complicated, you may choose to go with it. But for smaller stuff, or things you are unlikely to reuse anyway, `IO` as base monad isn't horrible. I don't think that using `MonadIO m =&gt; m a` instead of `IO a` buys you much in terms of type expressiveness. While you make `lift`ing implicit, you can still `liftIO . throwIO $ {..}`, so anything still goes.
The different with Bool is that it's easy to mix things up due to the fact that there is zero payload besides the constructor. With Either the very explicitly typed payload is what keeps things safe and unlikely to break, not the little constructor names (which can be accidentally avoided via things like "pure" and "toList" and so on anyway). 
&gt; Non-composable. `ExceptT SomeError IO a` and `ExceptT OtherError IO a` don't play nicely together, because the types don't match. The natural solution is to have some larger sum type that can handle both and projecting into it, like `data BiggerError = Some SomeError | Other OtherError` and using `withExceptT as withExceptT Some someErrorThrowing &gt;&gt; withExceptT Other someOtherThrowing`. I disagree, `withExceptT Some someErrorThrowing &gt;&gt; withExceptT Other someOtherThrowing` is *exactly* demonstrating composability. You might find it *inconvenient*, but we need to stop saying it doesn't compose. I also disagree that having a larger sum type is the natural solution. It's a trivial solution, but that doesn't make it the right one. The right solution is entirely context dependent, and there may be other ways to handle the error or change your code execution path. Thinking entirely in terms of "I must preserve" this error limits your viewpoint. &gt; Monomorphic. If you choose to have many error types, as above, then you can't use `mtl`-style type classes. `ExceptT` must be on the outermost transformer, so you can project errors at will. This might not be how you want to deal with exceptions, as exceptions don't commute with other monads (StateT s (Either e) and EitherT e (State s) have differing behavior wrt how the state and exceptions interact). This means that you can't reuse functions like ExceptT e m a in a Conduit or some other transformer, you have to runExceptT to convert it to an m (Either e a) before it can be used. Using `ExceptT e m` to me isn't the interesting part, using `MonadError e m` is. And this plays just fine with anything else. Furthermore, it is mappable - and `ExceptT` provides that mapping! (Though it's not the only way). `mapError :: (MonadError e2 m) =&gt; (e1 -&gt; e2) -&gt; ExceptT e1 m a -&gt; m a` where `mapError f m = runExceptT m &gt;&gt;= either (throwError . f) return`. This fits in just fine with other transformers. &gt; Types are too big. Why does everything have to be in `AppError`? Does this comment only apply if you don't use my `MonadError`-mapping trick? &gt; Performance. Every `&gt;&gt;=` with `ExceptT` requires a case expression, which introduces a branch in the code, as well as a pointer dereference to get to the next thing. If you have a tight loop that's computationally expensive, this will dramatically slow things down. For pure code, there's monad-ste which uses a similar trick to the ST monad to provide fast, pure Either-like behavior. If you want typed exceptions without this particular cost, you can use this trick: newtype Thrown a = Thrown { unThrown :: a } instance Show ( Thrown a ) where show _ = "&lt;Thrown&gt;" instance ( Typeable a ) =&gt; Exception ( Thrown a ) newtype MapErrorT e m a = MapErrorT { unMapErrorT :: m a } deriving ( Functor, Applicative, Monad, MonadIO, MonadThrow, MonadCatch, MonadMask, MonadLogger ) instance ( Typeable e, MonadCatch m ) =&gt; MonadError e (MapErrorT e m) where throwError = MapErrorT . throwM . Thrown catchError m f = MapErrorT ( try ( unMapErrorT m ) ) &gt;&gt;= either ( f . unThrown ) return mapError :: ( MonadCatch m, MonadError e' m, Typeable e ) =&gt; (e -&gt; e') -&gt; MapErrorT e m a -&gt; m a mapError f = try . unMapErrorT &gt;=&gt; either ( throwError . f . unThrown ) return This gives you a `MonadError` implementation that uses the underlying monads `MonadThrow` and `MonadCatch` instances. In `IO`, this means you get `MonadError` without branching. What's even cooler about this is you can still use this in pure code - just stack `CatchT` in and you get a pure implementation of `MonadCatch` and `MonadThrow`! I haven't benchmarked this yet, but this is actually my preferred way of implementing `MonadError` these days, primarily because it also works with `MonadUnliftIO`.
For the reasons outlined in the other replies: `Traversable` won't give you that. You can get close, if you play around with it for a bit, but even if you do there are "other issues" as I somewhat cryptically stated in the edit. Specifically, my use of `sequenceA` above relies on the `Applicative` instance for `Either`, which is (and must be) short-circuiting. Which is why you only get one result if there is a "skippable" value in the input in your example. But a proper implementation of `handle` isn't supposed to short-circuit the entire computation! That the defeats the whole purpose of it. I suspect you could construct a perfectly sensible family of maps of the form `f (Either a b) -&gt; Either (f a) (f b)` but not with the standard typeclass machinery. You'd probably have to define a new `DistributesOverEither` typeclass or something to that effect. As for the bit about pushing things in, what I meant was: doing something I sometimes do with structures wrapped in monads: `fmap` what I want done *into* the structure under the `m`, consume the structure under the `m`, and use `join` to get back out of the resulting doubly wrapped monad. This basically: handleUnwrappable :: Applicative f =&gt; (f (f b) -&gt; f x) -&gt; f (Either a b) -&gt; f (a -&gt; b) -&gt; f x handleUnwrappable un x f = un (either id id . bimap appfun pure &lt;$&gt; x) where appfun z = ($z) &lt;$&gt; f Which will give us a definition of `handle` whenever we can provide a (well behaved) map `f (f b) -&gt; f b`. The obvious choices that comes to mind are `join :: Monad m =&gt; m (m a) -&gt; m a` and `extract :: Comonad w =&gt; w a -&gt; a`, and indeed you can define: handleMonad :: Monad m =&gt; m (Either a b) -&gt; m (a -&gt; b) -&gt; m b handleMonad = handleUnwrappable join handleComonad :: Applicative w =&gt; Comonad w =&gt; w (Either a b) =&gt; w (a -&gt; b) -&gt; w b handleComonad = handleUnwrappable extract This `handleMonad` has the right semantics, I believe: &gt; handleMonad [Left 1, Right 2, Left 3] [(*10)] [10,2,30] I've not experimented with the `Comonad` one though. But, assuming lawful `Functor` and `Applicative` instances, it should work correctly if `extract . pure = id` holds. Which is not asking much. I suspect the existence of a map `unwrap :: f (f b) -&gt; f b`, possibly with a handful of laws (not sure which ones, although `unwrap . pure = id` seems like an obvious inclusion) might constitute a sufficient (but not necessarily necessary) condition for the existence of a valid `Selective` instance. I've no idea if any of this is of any use to you, but I enjoyed puzzling it out.
That makes sense. So can you give me a concrete example where it's useful to use `Either` firstly as a sort of anonymous sum or for one of its instances unrelated to `Monad` and also secondly for its `Monad` instance? I'm doubtful that there are convincing examples where it wouldn't make sense to transform the `Either` to a "`Result`" explicitly.
Oops, you are right! So, these two laws actually imply short-circuiting? That's interesting. `Maybe` and `Either` are fine. `Const` and `Validation` are not. Interestingly, "non-empty" (what's the right term?) instances such as `ZipList` are fine too. So, it looks like there are non-monad instances of `StrictSelective`. (I haven't checked that other selective laws hold for `ZipList` but I expect that they do.)
*Open recursion* is something that you unconsciously use more often once you know about it. If you tie the knot, you reimplement fix every time. Another usage may be something like being able to define recursive functions inline. So might define something like `sum` like mySum = \f xs = case xs f { [] -&gt; 0; (x:xs) -&gt; x + f xs } I find this convenient in ghci. It also saved me from some refactoring once with TemplateHaskell.
&gt; "non-empty" (what's the right term?) instances Oh, perhaps the term I was looking for is `Comonad`? See the (awesome) comment by /u/yakrar below.
Agree with all these points. In addition: Perhaps the biggest advantage of the exceptions approach is separation of concerns. Some functions aren't involved in some particular exceptions - or all exceptions. They can't throw them, they don't (and shouldn't) catch them. With the exceptions approach, there is no mention or hint of the irrelevant exceptions in those functions and their type signature. It's completely transparent. So you can totally refactor your whole approach to exceptions, and you will only need to change the functions that are actually relevant to them. There are complex type tricks, involving polymorphism, where you can kinda sorta hide the exceptions you're not interested in with the `EitherT` style. But exceptions style is much simpler and more robust in this aspect. Overall - I agree with OP that it's important to know and understand both approaches, and use the one that works best for your use case.
Gilmi - just busy with another project, but I will get back to you :) Many thanks for offering that, very kind! 
Slides: https://github.com/Gabriel439/slides/tree/master/zurihac 
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [Gabriel439/slides/.../**zurihac%EF%BB%BF** (master → ef68b65)](https://github.com/Gabriel439/slides/tree/ef68b658e6cf1212db10bd3d0bd4c56c697a7e07/zurihac%EF%BB%BF) ---- 
If my function calls some other function that can throw an exception, then my function can also throw an exception. This sounds right to me. What's your objection?
I don't think your thinking of [Comonad](http://hackage.haskell.org/package/comonad-5.0.3/docs/Control-Comonad.html) exactly, unless you intend for non-emptiness to mean that there exists a map `unwrap :: forall x. f x -&gt; x` for `f`. I don't think that's true of `Ziplist`s. That said, if I'm right in my second edit of the comment I posted below, such an `unwrap` map does give you something `handle` like, since it lets you inspect the `Either` value. I'm quite sleep deprived however, so my reasoning skills are currently somewhat suspect.
Does the company offer work VISA for outside US / Canada worker?
That's pretty interesting. On one hand it seems that `Selective` is already too strong since it requires a concrete value to be produced by the left computation (like `Monad` does), and on the other it doesn't seem to grant any additional expressiveness in terms of what programs you can write and type check (since a function with the same type can be implemented for applicatives). Seems a counter-intuitive.
Yes, that is evil.
It does seem counter-intuitive. But I think the explanation is that types, in general, provide little guarantees for effects. For example, if you see a function `f :: Applicative f =&gt; f a -&gt; f a`, you don't know how many times the effects have been performed, e.g. `f x *&gt; f x` typechecks just fine. Similarly, a function `f :: StrictSelective f =&gt; f Bool -&gt; f a -&gt; f a -&gt; f a` does not give you any guarantees, even though it says that `f` is `StrictSelective`. You can say pretty much nothing by looking at this type signature. So, we can dictate strict selective laws and then have a guarantee on what the function `handle` does, but that's it -- any other function will have to be checked for compliance with the requirement (2) (that unnecessary effects are indeed skipped). The **must** version of laws is difficult to enforce. On the other hand, **may skip** (`Selective`) and **may not skip** (`Applicative`) are enforced by the compiler.
Make a type that holds both the deck and the hands, and anything else you need to keep track of. Something like: data GameState = { deck :: [Card] , player1Hand :: Hand , player2Hand :: Hand } drawFromDeck :: State GameState Card drawFromDeck = do st &lt;- get case deck st of [] -&gt; -- handle empty deck somehow (x:xs) -&gt; put (st { deck = xs }) &gt;&gt; return x addToHand :: Player -&gt; Card -&gt; State GameState () addToHand Player1 card = modify (\st -&gt; st { player1Hand = card : player1Hand st }) addToHand Player2 card = modify (\st -&gt; st { player2Hand = card : player2Hand st }) drawCard :: Player -&gt; State GameState () drawCard p = drawFromDeck &gt;&gt;= addToHand p
Yes, and as a fun extra, you also sometimes see `xss` for lists of lists, which, I am not even going to try to translate that into english.
But does `Applicative` actually enforce must-not-skip? The `Maybe` instance certainly ignores the second argument if the first is `Nothing`. Whether this means the effect is skipped or not is a bit pedantic (since the whole effect of `Maybe` is the short circuiting), but it becomes a much more practical question with something like `MaybeT IO`. 
No, sorry.
I think `Applicative` does enforce must-not-skip-unnecessary-effects, but we should fix what we mean by "unnecessary effects". These are effects, that are unnecessary *at the value level*, e.g. we have no need for the value `a -&gt; b` if we hold a value `Right b`. When you talk about `Maybe` shortcircuiting in the case of `Nothing`, this relates to skipping unnecessary effects *at the effect level*, i.e. effects depending on previous effects, but not on previous values.
The problem I have with this is that maintaining two isomorphic data Result a b = Error a | OK b data Exit a b = ShortCircuit a | Continue b loses the fact that these two constructions are exactly the same thing, risks one or the other having half of the instances you'd go to reach for, incurs an operational performance tax by forcing you to flail around swapping constructors when you move between them across different APIs, means you can no longer just talk about "the" sum type for `(-&gt;)`, because now you have two of them, etc. This "clarity" you seek doesn't come for free.
Denotationally - no it can't. It can return bottom, which inhabits every type in Haskell. All bottoms are denotationally equivalent. Operationally - If I don't care whether the run time happened to have a call to this function pushed on its stack when the exception happened, then I don't want to be forced to represent that low-level detail in my program. That is the beauty of a pure language. If I do care, then by definition this function is in `IO`, and I can catch the exception.
If anyone's wondering what OP is talking about saying PureScript users are crazy about row types and you don't follow /r/purescript (where I spam a lot of my blog posts), you might visit some of these pages: * Records in PureScript as parameterized by a row of Type: https://github.com/purescript/documentation/blob/master/language/Records.md * PureScript-Variant and its README: https://github.com/natefaubion/purescript-variant * Post about RowLacks: https://liamgoodacre.github.io/purescript/2017/05/27/row-lacks.html * Post about RowToList: https://liamgoodacre.github.io/purescript/rows/records/2017/07/10/purescript-row-to-list.html * Uploaded generated docs (pulp docs -- --format html) of Prim.Row, Prim.RowList: https://justinwoo.github.io/generated-docs-12/generated-docs/Prim.Row.html, https://justinwoo.github.io/generated-docs-12/generated-docs/Prim.RowList.html * Example of a JSON record decoding implementation using row type information: https://github.com/justinwoo/purescript-simple-json/blob/a2f8123d83f8e0e43b49727487a37b44ae08b15f/src/Simple/JSON.purs#L161-L201 A plug: I wrote a post about parsing Symbols in PureScript to construct a record type using row type constraints: https://github.com/justinwoo/my-blog-posts#well-typed-parameterized-sqlite-parameters-with-purescript. I'll be talking about this in Milan on Sunday so please come!~ http://www.haskell-ita.it/2018/06/haskell-day-mini-incontro/
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [purescript/documentation/.../**Records.md** (master → 2ae4723)](https://github.com/purescript/documentation/blob/2ae4723320c3591ac33f138cd2327c9edfe2d4bf/language/Records.md) ---- 
Thank you, your `handleUnwrappable` is pretty cool! The link with `join` is now more apparent. `handleComonad` and `handleExtractable` seem to be strange though: I think the `fmap fromLeft` will actually blow up if we extract the `Left` but the functor contains some `Right`s. I need some time to think a bit more about comonads and how they fit here. 
 extract . pure === id always holds (unless it produces a bottom) as the type of `extract . pure` is `forall a. a -&gt; a` which is only inhabited by `id` (and bottom). 
Honestly, at this point I wish we could just put a bounty on this feature and pay somebody a couple of thousand bucks to get this into the language.
The word on the street is that someone's working on this.
Thank-you. The explanation really helps me greatly.
That link is broken because there are invisible bytes after "zurihac". Here is a working link: https://github.com/Gabriel439/slides/tree/master/zurihac
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [Gabriel439/slides/.../**zurihac** (master → ef68b65)](https://github.com/Gabriel439/slides/tree/ef68b658e6cf1212db10bd3d0bd4c56c697a7e07/zurihac) ---- 
Based on the size of this feature and the size of the change required to make it work, that feels to me like paying an adult a nickel to mow your mansion's lawn.
There's a street? But more seriously, where do you hear such things, and where can I learn the answers to questions like "Who?" and "When is it expected to be done?" and "What are the high-level design decisions being made?"
&gt; Nope, many people use cabal-install and don't use stack. Many others do use stack. There's no "probably" either way here. So you dismiss all survey data we have which supports the quite reasonable observation made by u/chris_conlan's that Stack is the most common way of doing Haskell development. Do you also dismiss the evidence you can find on Slack or even this subreddit where people frequently recommend to newcomers to use Stack? What evidence do *you* have to back up your claim of cabal-install being nearly as popular as Stack? Does haskellorg have any secret statistics they don't share? If you consider the survey data to be pro-Stack biased I'd say you're a hell more anti-Stack biased given your well documented opposition to advertise Stack on haskell.org 
Yeah, I think the functions past me was groping around for (but failing to find) was this one actually: handleComonad x f = extract . either appfun pure &lt;$&gt; x where appfun z = ($z) &lt;$&gt; f which has a fun syntactic similarity to handleMonad x f = join $ either appfun pure &lt;$&gt; x where appfun z = ($z) &lt;$&gt; f Those seem to work as expected: &gt; let nonArg = Left 1 :| [Right 2, Left 3] :: NonEmpty (Either Int Int) &gt; let nonFun = (*10) :| [] :: NonEmpty (Int -&gt; Int) &gt; handleMonad nonArg nonFun 10 :| [2,30] &gt; handleComonad nonArg nonFun 10 :| [2,30] 
One unsolved problem (I don't know satisfying solution), is how to respresent recors, so you can write *efficient* row-polymorphic code. For example PureScript C++ implementation, https://github.com/andyarvanitis/purescript-native/blob/11f5f9704333407bd4a074f52b1aaf4de806c2ee/pcc/runtime/purescript.hh#L133-L136 using record = std::map&lt;const char *, any, cstr_cmp WITH_ALLOCATOR_PAIR(char * const, any)&gt;; Using `Map` for records is non-acceptable, it will ruin all the performance. JavaScript backend uses JavaScript's Objects. I guess the performance is acceptable, because JavaScript virtual machines are smart, and e.g. use tracing to optimise hot paths. I wonder how /u/edwardkmett and the team implemented row polymorphism for Ermine for JVM. I suspect that - monomorphic case are specialised: fast. - polymorphic worked using JVM built-in reflection: slow.
Try something closer to "tens of thousands of dollars" and you'll have a much better estimate.
The `handleUnwrappable` should probably also take a function with a universal quantifier in it, in the interest of forcing the function to only consider the structure of `f`/`m` and not the values contained within. The `Comonad` variant is broken though. That's what I get for trying to reason about code without running it in my current state. But I see how to fix it now: handleUnwrappable :: Applicative f =&gt; (forall x. f (f x) -&gt; f x) -&gt; f (Either a b) -&gt; f (a -&gt; b) -&gt; f b handleUnwrappable un x f = un $ either appfun pure &lt;$&gt; x where appfun z = ($z) &lt;$&gt; f handleExtractable :: Applicative f =&gt; (forall x. f x -&gt; x) -&gt; f (Either a b) -&gt; f (a -&gt; b) -&gt; f b handleExtractable un x f = un . either appfun pure &lt;$&gt; x where appfun z = ($z) &lt;$&gt; f handleMonad :: Monad m =&gt; m (Either a b) -&gt; m (a -&gt; b) -&gt; m b handleMonad = handleUnwrappable join handleComonad :: Applicative w =&gt; Comonad w =&gt; w (Either a b) -&gt; w (a -&gt; b) -&gt; w b handleComonad = handleExtractable extract This doesn't blow up, and produces the same result regardless of which way we got there (`NonEmpty` and `Tree` support both): &gt; let nonArg = Left 1 :| [Right 2, Left 3] :: NonEmpty (Either Int Int) &gt; let nonFun = (*10) :| [] :: NonEmpty (Int -&gt; Int) &gt; handleMonad nonArg nonFun 10 :| [2,30] &gt; handleComonad nonArg nonFun 10 :| [2,30] I don't think there's anything special going on with `Comonad` here, other than it being able to tear down extra layers of `w`. Disclaimer: I've only tried these definitions on relatively simple things like `[]`, `NonEmpty` and `Tree`. They might have undesirable behaviour in other cases. And defining a custom `handle` directly is probably going to give better performance in many cases, since you can use specific knowledge about the thing your defining it on, rather than relying on `fmap` to "do the right thing" as I have above. 
You can't use an `IO` function inside of a pure one anyways so I don't see what your point is. You're still propagating the fact that somewhere down the line some function deep in your callstack can throw an exception. This still infects your whole call chain. The only difference here is that you don't know anything about the exception.
For us rows were arrays or maps or whatever we needed at the moment. We were building up typed terms in an EDSL describing how to transform data more than actually pumping records through. That way we could define interpreters for the semantics of the reports that produced pdfs, spreadsheets, a swing gui, a fancy website, etc. The row typing stuff we offered was for safety on the ermine side, for the most part the java side didn't get to know or care about the row types we gave things.
I heard it second hand from someone who heard it at a meetup. Since the person(s) allegedly working on it hasn't publicly announced it I don't want to name anyone.
&gt; I disagree, withExceptT Some someErrorThrowing &gt;&gt; withExceptT Other someOtherThrowing is exactly demonstrating composability. You might find it inconvenient, but we need to stop saying it doesn't compose. It doesn't compose without explicit "lifts" or conversions. This is exactly the kind of annoying boilerplate that `mtl` and type classes solve. &gt; I also disagree that having a larger sum type is the natural solution. It's a trivial solution, but that doesn't make it the right one. The right solution is entirely context dependent, and there may be other ways to handle the error or change your code execution path. Thinking entirely in terms of "I must preserve" this error limits your viewpoint. You're right, but in every app that I've seen try and use `ExceptT`, a giant single error is what everyone ends up doing. I'd love to see counterexamples in the wild. Alternatives that I can think of: - Use `Either`, resulting in an error type like `ExceptT (Either A B) m a`, which you then nest for "anonymous" sums. Maybe with `type (+) = Either` this isn't terribly: `ExceptT (A + B + C) m a`, except that it doesn't commute or associate, so you get to play "project into the sum" bingo (or write a class that handles this for you). - Write a data type for every function that has a combination of errors it carries around. This still gives you the "error type too big" problem, at a smaller scale, because any aggregation of errors is going to lose the ability to talk about those errors specifically and remove them (excepting Either and open sum types). &gt; Using ExceptT e m to me isn't the interesting part, using MonadError e m is. And this plays just fine with anything else. Furthermore, it is mappable - and ExceptT provides that mapping! Doesn't that have exactly the same problem of using `ExceptT` everywhere, because `ExceptT` is forced to be the outermost transformer? The `MapErrorT` trick is very cool, indeed :)
No you are confusing the two approaches. The term "throws an exception" is imprecise and means two totally different things in the two approaches. In the `EitherT` approach, the exception is a value that the nested function returns its result. In the exception approach, that is not so. The exception is an effect, an event that happens in the world while the run time is running generated code. Since we want Haskell to be a pure language, we must make certain that effects are not observable in any way inside your pure code. But that doesn't mean that you "don't know anything". You get all the information you need - call stack, line of source code, everything. That happens in the IO monad, exactly in the place where you need it, where you define how your application interacts with the user. It's a different approach to program organization. As OP points out, you should be aware of both approaches, their advantages and disadvantages.
Many thanks for sharing these experiments :-) Indeed, it looks like `extract` can't help us. Quite counter-intuitive, since the type signature of `extract` does seem to match that of `join`. It's interesting to find the law that actually makes `join` work.
It's not great. I actually packaged up [safe-exceptions-checked](https://hackage.haskell.org/package/safe-exceptions-checked-0.1.0/docs/Control-Exception-Safe-Checked.html) once upon a time but have never actually used it. This flavor of checked exception doesn't work at all with `forkIO`.
Bad bot 
I'm working on this in my _limited_ free time, as a type checker plugin. Here's a link to my first attempt: https://github.com/nfrisby/coxswain It's definitely buggy and overly complicated; I was using it to learn about the GHC equality constraint representation and solver, plugin architecture, etc. But the `Data.Sculls` library API for records and variants is still (roughly) my end goal. I'm currently rewriting the set equality solver as a parametric function. Then I'll instantiate it for use in the GHC plugin. If someone else is actively working on this kind of solver for use in GHC, I'd be happy to discuss ideas and plans!
There is. Some of it’s circumventable (e.g. use stack). Some of it’s that there’s a near endless learning curve (the best people are constantly working on better ways to do even quite fundamental things). And Rust’s community and approach is excellent. However... Haskell is kind of awesome so I highly recommend sticking with it. I guarantee you’ll learn something that makes you go “oh wow”.
It's probably due to the fact that, as you've noted, `handle` can be implemented for any `Monad`, and `pure` + `join` is just a different presentation of that class (that is, you can define `(&gt;&gt;=)` in terms of `join` and vice versa). I doubt that there are many types that are `Applicative` and have a `join`-like operation that yields a valid `handle` using my definition, but which do not have any lawful `Monad` instance. This was fun, but sadly didn't really clarify much of anything about `Selective`. Oh well. A negative result is still a result, I suppose.
Sad but true. I'm working on it (see other comment), and money would be cool. But I also have a well paying job that I like. Even matching one year of salary wouldn't compete with that: I need stability. Treating it as a second job isn't about money as much as time. I have my spouse. And I like to cook dinner. And friends. And parties. And family vacations. And volunteering. And dogs, and blah blah blah. I'm not complaining. I'm just trying to paint the picture of what it is competing for my time that I really truly would love to spend in the flow on this type checker plugin. That said, I'd be happy to see someone else allocate their free time on this because of a generous bounty. Surely someone would be enabled by that. Or make an offer I can't refuse and my spouse and I will make time work out for our third job for a few months haha
Clarification: I think a few months would suffice to get a poorly optimized, well documented, significantly expressive type checker plugin up and running. That's my general goal: a shunt so we can start experimenting with set/map equality constraints in code. Then those examples would give the kind of experience necessary to allocate the time and attention of GHC HQ et al on integrating/maintaining this kind of capability in the "stable" GHC infrastructure (either folding into type checker or prioritizing/further committing to plugin API).
Isn't it typical to encode offset information in the evidence for Has and Lacks constraints if you want efficient row-polymorphic records? If your record types are all known at compile time, I expect GHC would be able to inline all of that away to pointer addition, right?
I have no such opposition. Stack is well represented on haskell.org, and it has been for a long time. I supported the proposal to put stack in the haskell platform, and I even performed the actual technical work to accomplish this. I'm really tired of these false rumors flying around.
It could take a year or two quite frankly.
In the earliest work I know of for this, offsets were basically how it was done. GHC has a harder story for this simply because it doesn't have a nice flat polymorphic record story 
Sure, for the *monad* instance, but not for the applicative instance, or the functor instance, or using it as a regular semi-anonymous sum (eg `Either Double Integer` as the type of numeric literals in PureScript's compiler). I'd be happy to see pattern synonyms for `Left` and `Right` or named-functions that make the *intent* of the code more clear, but the datatype shouldn't give intuition that harms understanding of it's potential use cases.
It doesn't mean two different things. Not in the context of this discussion. Whether I decide to throw exceptions with `throwM` or `throwIO` makes no difference. It will behave like an exception in both systems, meaning it will propagate through the call stack until caught. This being implemented via a "value that the nested function returns as its result" or via the runtime isn't important. Of course, the runtime characteristics and the value level information is different but again, I don't think that's what's being discussed here. The meaningful difference here is how much is statically known about a function. With the `ExceptT` approach, I know what kinds of exceptions a function can throw and I know if I've handled them at the type level. With the IO approach, a function can throw anything and handling the exception doesn't reflect on the type level. I appreciate the point that handling exceptions is mostly done in the outermost IO layer of the application, but this simply ignores the whole pipeline that provides the exceptions to that outer layer. The fact that somewhere in the guts of my program I divided by zero isn't something I want to expose to the user, yet at the throw site that's the only thing you know. Checked exceptions provide a systematic approach to transforming exceptions as they travel through layers of the application where each layer can further contextualize what actually went wrong. A call stack is a poor substitute for that. Your other point was (I think) that intermediate functions (the ones not doing the throwing or catching) have to be tagged at the type level which makes refactoring difficult. I think this is very overstated. It's exactly as difficult as you want it to be. If you want to document that some function is part of an "exceptional pipeline", you write that in its type. And if something changes later, you really want to update that documentation. On the other hand, if you feel this function isn't worth documenting as precisely or that perhaps it will require constant updating, put a `_` wildcard in there and forget about it. The actual type still gets propagated and you literally lose nothing that you didn't explicitly want to lose. In my setup I can even hover over the function and still see its type.
What we do is have multiple `ExceptT` layers. This ultimately lets you avoid the whole sum-type-of-errors thing. In the actual code, the `ExceptT` transformer isn't mentioned anywhere. Instead, an mtl style class is used to signal that a function can throw an exception (basically `MonadThrow` without the fundep). You can handle the exceptions in any order because you get commutativity via the commutativity of constraints. You can also handle them pretty much anywhere (recursive functions are more problematic) without fixing your transformer stack at all because the function you use to catch the exception changes the type of the computation. It "materializes" exactly one layer of your transformer stack, peels it off and the result is still completely polymorphic meaning that the type of the function that does the catching isn't affected at all.
Great talk. If people are interested, it looks like it builds on stuff Gabriel did with regular expressions: he goes through it in [this](https://begriffs.com/posts/2016-06-27-fast-haskell-regexes.html) talk, and the slides are [here](https://github.com/Gabriel439/slides/blob/master/regex/regex.md). 
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [Gabriel439/slides/.../**regex.md** (master → ef68b65)](https://github.com/Gabriel439/slides/blob/ef68b658e6cf1212db10bd3d0bd4c56c697a7e07/regex/regex.md) ---- [^delete](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply e1g94qh.)
You could take a look at https://github.com/ConferHealth/composite It’s a layer on top of vinyl records/corecords that adds named fields and some TH to make lenses for them all and in general improve the ergonomics. It isn’t first class to the language but we have used it to almost entirely replace `data` and we use it in production (though a very small production).
Is there a reliable way to make GHC show the roles it inferred? Experimenting in GHCi, I see that `:info &lt;type&gt;` sometimes shows the inferred roles, but not consistently. Example definitions: ``` data T1 a = T1 data T2 a = T2 a newtype T3 a = T3 a data T4 a where T4 :: Int -&gt; T4 Int type family F a b type instance F Int b = Int class C a where c :: a -&gt; a ``` What `:info` in GHCi reports for them: ``` &gt; :info T1 type role T1 phantom data T1 a = T1 -- Defined at &lt;interactive&gt;:1:1 &gt; :info T2 data T2 a = T2 a -- Defined at &lt;interactive&gt;:2:1 &gt; :info T3 newtype T3 a = T3 a -- Defined at &lt;interactive&gt;:3:1 &gt; :info T4 type role T4 nominal data T4 a where T4 :: Int -&gt; T4 Int -- Defined at &lt;interactive&gt;:8:1 &gt; :info F type family F a b :: * -- Defined at &lt;interactive&gt;:15:1 type instance F Int b = Int -- Defined at &lt;interactive&gt;:17:15 &gt; :info C class C a where c :: a -&gt; a {-# MINIMAL c #-} -- Defined at &lt;interactive&gt;:20:1 &gt; :info! C class C a where c :: a -&gt; a {-# MINIMAL c #-} -- Defined at &lt;interactive&gt;:20:1 &gt; :info! F type family F a b :: * -- Defined at &lt;interactive&gt;:15:1 type instance F Int b = Int -- Defined at &lt;interactive&gt;:17:15 ```
I really don't get the composable exception stuff ... To be honest, I pretty much never use exceptions in 20 years and almost never a exception of a given type. What I mean is, at the opposite of the spectrum, you have exceptions which are caught pretty much straight away (in term of callstack) or far away (near the mainloop or equivalent). the "low" level usually corresponds to problem which can be recovered (network failure, deadlock etc ) and the "high" level corresponds to just avoid crashing gracefully and warn the user about it. In those two extreme case, you don't really need composability. The lower or closed you are from the throw, and the less possibility of exceptions occurs and the higher the less you can do something about it and the less you care. The real problem occurs at mid level, when you have lots of different exceptions and don't know what to do about it. That's where you probably indeed have a composability. However, in my opinion it is a code smell and and flow control in disguise which shouldn't be dealt with exception. The `VapourError` is good example of this, insufficient found or item unavailable are part of the normal workflow of a vending machine and shouldn't be dealt using exception. 
I agree with this 100%. The fact that so many libraries use exceptions to indicate control flow is really bad.
&gt; And friends. And parties. And family vacations. And volunteering. HEY if your friends aren't helping you pro-bono with your sub-minimum-wage programming work, are they really your friends? And if your parties don't involve pro-bono coding, are they really any fun? As for volunteering, why not make it a two-fer? Teach underprivileged children how to...extend the compiler of a notoriously sophisticated functional programming language. &gt; And dogs, Don't even get me STARTED on those freeloaders!
The most reprehensible part about this is the mixed case in the language pragmas. Have you no shame!?!
I was worried it might not be obviously evil enough without them 
Sigh. We could go on and on with the religious arguments. But as an engineer, I can only say that the comments at the beginning of OP are spot on. In real life, these are two different legitimate approaches. The best is to understand the trade-offs with an open mind, and to do what's best for your particular use case.
Fair enough. In my personal experience, the checked exception approach has always turned out to be the better approach but it's very true that different problem domains call for drastically different solutions. Perhaps I just haven't worked on stuff where the IO approach is better.
Are you sure he isn't joking? Excel is among all the other languages that screw up type safety badly.
Super cool idea and well presented talk! My intuition for the optimal haskell implementation is something like: - inline all the things, eliminate state machine wrapper - inline stream fusion loop and state machine step function - spec constr the loop into a single loop per state - inline bytestring get-a-char code into each loop Almost prefectly predicted branches might be faster than relative addressing of L1 memory? Definitely still slower than both SIMD and process paralism, though. I don't think the inline assembly version in haskell would work. You would have register mangling and a function call for each primop invocation. Found an example that does this and it looks like it ran into this issue https://github.com/jberryman/almost-inline-asm-haskell-example Looks like opencl has the same shuffle operations. Could this be done on the gpu? 
Is there any intention to offer the materials for this course for a larger audience for cheaper than 400 USD? It seems a bit absurd to take such an active topic that so many people are interested in and would benefit from and limit it in this way. I’m not against getting compnsated for your work, but 6 people at this price ...
That's a pretty skewed view of how difficult this work would be. 
&gt; in a pure, non-strict language to get any decent performance the compiler has to be able to and is able to completely re-order the function logic and constantly move code that is inside function definitions selectively inside of other functions meaning that functions unlike in most languages aren't "called" in the same way Consider [`map`](http://hackage.haskell.org/package/containers-0.6.0.1/docs/Data-Set.html#v:map) from the `containers` library. It has type signature map :: Ord b =&gt; (a -&gt; b) -&gt; Set a -&gt; Set b How would you write an ABI for that? I'm not sure it's impossible, but Haskell is quite different from C and you can't just recycle approaches to linking from other languages/ecosystems. 
It seems that your comment contains 1 or more links that are hard to tap for mobile users. I will extend those so they're easier for our sausage fingers to click! [Here is link number 1](http://hackage.haskell.org/package/containers-0.6.0.1/docs/Data-Set.html#v:map) - Previous text "map" ---- ^Please ^PM ^/u/eganwall ^with ^issues ^or ^feedback! ^| ^[Delete](https://reddit.com/message/compose/?to=FatFingerHelperBot&amp;subject=delete&amp;message=delete%20ID_HERE) 
&gt; I'm not sure if they've fixed the nondeterminism in the ABI or not, but if not then you can't even expect the same code to produce the same ABI twice. You can export functions, which I think uses the C ABI.
You mean foreign export? Yes, that's stable AFAIK, but the ABI between Haskell functions isn't.
To be fair, you could write an ABI for that using dictionary passing. That's how non-specialized calls to polymorphic external-package functions works. I think the ABI is just not stable because GHC reasons.
&gt; `ExceptT SomeError IO a` and `ExceptT OtherError IO a` don't play nicely together Classy prisms solve this well. 
TOWER I SAY AGAIN, please don't make me install a spam filter on /r/haskell.
&gt; Classy prisms solve this well, much better than polymorphic variants. They do! But then you run into the problems that classy prisms have; namely, there's no way to take some type `(AsFoo e, AsBar e, AsBaz e) =&gt; e` and handle it into a `(AsBar e, AsBaz e) =&gt; Either Foo e` without writing a *lot* of boilerplate instances for your classy prism for `Either`. `generic-lens` might hold the key to this, but I haven't used it in anger enough to say. &gt; You can. Can you elaborate? 
Hi, I'm the author [data-diverse](https://hackage.haskell.org/package/data-diverse) which has both [records](https://github.com/louispan/data-diverse/blob/master/test/Data/Diverse/ManySpec.hs) and [variants](https://github.com/louispan/data-diverse/blob/master/test/Data/Diverse/WhichSpec.hs). Please take a look at the test cases for example usages. Do they suit your needs? 
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [louispan/data-diverse/.../**ManySpec.hs** (master → 96be655)](https://github.com/louispan/data-diverse/blob/96be655fe74a270d85de632ed45a7d37aa8a8853/test/Data/Diverse/ManySpec.hs) * [louispan/data-diverse/.../**WhichSpec.hs** (master → 96be655)](https://github.com/louispan/data-diverse/blob/96be655fe74a270d85de632ed45a7d37aa8a8853/test/Data/Diverse/WhichSpec.hs) ---- 
Makes sense. I look forward to the public announcement.
I wonder if [this](http://pl.cs.jhu.edu/projects/big-bang/dissertations/safe-fast-and-easy--towards-scalable-scripting-languages.pdf) thesis is relevant. It's solves a more general and more difficult problem, but the solution might require too much information.
I'm still waiting for this library with regular expressions to be released on Hackage...
The Sirea stuff looks like it hasn't been touched in 5 years and the Quora answer seems to be unrelated to that in any way, but it looks like you might just be interested in Functional Reactive Programming as realized by, eg. [Reflex](https://github.com/reflex-frp/reflex), [Reactive Banana](https://hackage.haskell.org/package/reactive-banana), [Netwire](https://hackage.haskell.org/package/netwire), etc.
I clarified in the edit. There was a hyperlink in the quora answer that linked to the third link I provided. I have reason to believe that the person answering the question is the same person who owns the blog by the detailed reference to the keyword "local state."
I did this recently [too](https://github.com/aboichis/sudoku/blob/master/src/Main.hs), inspired by a post on r/programming. It's always interesting to see the different approaches used by other people. 
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [aboichis/sudoku/.../**Main.hs** (master → 1366b15)](https://github.com/aboichis/sudoku/blob/1366b1520524a68728accec382f2df2be31bcd39/src/Main.hs) ---- 
Ah... ok... well, does the FRP stuff I linked help or are you looking for something different/more specific? 
I think fundamentally without the flat polymorphic record / row support in GHC it's going to be impossible to find an ideal solution, and it will probably require some unsafe stuff under the covers. ADTs are fantastic but they do treat contiguous (both in the sum and in the product sense) structural types as second class citizens. It would be interesting to see if GADTs can be built off of these anonymous structural base types as well in a nice clean way. 
This focus function is what I expected. Thank you for answering. I will study about lens library.
Thank you for answering. This approach seems to be almost same as mine. But I did not know this boilerplate style value construction. Thank you.
Thanks! Happy cake day!
That was my first idea but then it would not work with `Double`s. Right?
How much knowledge does it require? I have a basic understanding of most Haskell concepts found in books (typeclasses, functors, applicatives, monads, etc), but I don't really grok how to use them properly yet. Will this book be too difficult for me?
I believe that it is an exact fit for you. There is a short refresher on the concepts you've mentioned in Chapter 2 and then I start using it for doing real stuff. 
Good to know! I'll have to check it out, thanks for writing this :)
I mean you can probably argue that its "better" to do a whole lot more stuff like that in most codebases for documentation and stuff, but people like to work fast and get things done, so I know I would personally not convert around too much in most projects I work on. Another issue is you then have to define all kinds of instances for all those types and various convenience functions, which many third party libraries won't bother doing. Particularly if you extend the discussion to things like an Either monad transformer.
Save half on Haskell in Depth and these other selected books. Just enter mlbragilevskylt in the Promotional Code box when you check out. Expires Friday, July 6. Only at [manning.com](https://manning.com) " not working...
Where this ad comes from? I'll try to inform Manning team about it. And please, use **mlbragilevsky**, it does work!
I'm not sure, and have been wondering this myself! It doesn't seem to make any rhyme or reason.
yes it does - just bought it :D
\&gt; I couldn't find much on it on the internet ... Search for "cross module optimization" and you will find plenty of references. In short, ghc performs very aggressive inter module inlining and that makes very difficult to keep the ABI-s stable. The variability of ABI-s produced by ghc is less of a shortcoming "to be fixed", but can rather be considered as a trade off between highly optimized executable or more stable ABI-s. Nonetheless, I believe, making ABI-s more stable in the face of cross module optimization is an active research area. Dynamic linking has two purposes: minimizing the total memory consumption of programs (of potentially multiple copies) simultaneously running in the system and the ability to swap changed modules without complete recompiling. I would say the first one is more important. If you completely disable optimization (-O0 flag), for example during development, that can dramatically speed up (re)compilation of large projects since ghc can recognize which modules ABI-s have not changed.
I'm eagerly looking forward to this book. I wish it were structured backwards, though. If I'm reading it, it's because I want to learn about software architecture in Haskell. Give me the "Large Applications in Haskell" chapter up front. Tell me what I'm going to learn, tell me where I'm going to find it, then teach it to me. Maybe I'm a little bit jaded by Haskell resources which promise I'll know Haskell, teach some basics, then tell me about monad burritos. (Holy shit y'all are overcomplicating the fuck out of monads. "It's a workflow. You can use functions within a workflow easily because of do-notation. If you want to make your own workflow you should define: how to change a value within the workflow to another value within your workflow using some function; how to do that using a function that came from your workflow; how to apply your workflow to a value that's not in your workflow. That's it. If you're doing something super fucking weird we might yell at you for "breaking the law" but unless you're doing weird shit you won't hear from us again."
в slack Hexlet, в чате random чувак запостил, наверно их много (отслеживают источники трафика) и кто-то ошибся, но по первому коду у меня цена точно не снизилась
&gt; data Roots = Roots Float Float | SingleRoot Float deriving Show should be data Roots a = Roots a a | SingleRoot a deriving Show if you want a more general formulation. There is no real reason to monomorphize to `Float` there -- unless you are concerned about the size of it and unboxing, but then you'd want !Float anyways.
I am fully aware that "a couple of thousand" is what many consultants bill in a single day. And I 100% agree with your choices of having other life priorities. However, I have actually been thinking a bit lately about how the community could better incentivize progress in some areas. Do we need to do committee-style work first? Can we solve a social problem by helping bring people together that are working in isolation? Should we do more of [these kind of bounties](https://twitter.com/mattoflambda/status/997589748427341824) for small, incremental improvements? How much is the "offer you can't refuse" amount? I am not sure at all about the optimal role of money in funding open source. But as somebody who doesn't have the technical skills yet, I'd love to find out how I could help accelerate these developments in the language that I love and want to see grow.
[@mattoflambda's latest tweet](https://i.imgur.com/KLxNMp1.jpg) [@mattoflambda on Twitter](https://twitter.com/mattoflambda) - ^I ^am ^a ^bot ^| ^[feedback](https://www.reddit.com/message/compose/?to=twinkiac)
Which book would you recommend as my *first* book on Haskell?
Are amazonka and gogol affected by this?
[http://haskellbook.com/](http://haskellbook.com/) The best programming book I've ever read
Yeah. I'm afraid this *is* off-topic. 🙂 
Why not doing it the simple way and return a list of roots? It easily extends to any polynomial equation.
You can read my answer here: https://www.reddit.com/r/haskell/comments/82p0de/haskell_books_comparison/dvbt110
You might be interested in the [fgl](https://hackage.haskell.org/package/fgl) package which uses a representation similar to yours and implements quite a few graph algorithms.
First programming book I've actually purchased. Looks great, can't wait to start it when I get home?
That was my question! I followed your advice and went with Kurt's Haskell book. Throughly enjoying it. Will definitely be going through yours as soon as I finish it.
It just opens google.com/webhp for me.
Can you give an outline on what you plan to cover in chapters 9 and 10?
It's on Hackage now: https://hackage.haskell.org/package/coercible-utils.
Don't know anything about the company but I can confirm they submitted a great PR to Opaleye! https://github.com/tomjaguarpaw/haskell-opaleye/pull/392
Is any library that provides middleware for wai to compute etag and cache-control for the response? Scotty doesn't come with a middleware that computes etag and cache-control in the header, which is useful for the client to cache the response and know when to invalidate the cache. Is there any library does that?
This probably would’ve saved me some time if I had known about it several months ago... oh well, at least I learned something along the way. They came up with some interesting solutions here it looks like. 
Much appreciated, Tom :)
will delete, sorry about that
&gt; I think the authors took criticism of previous learning material of Haskell too much at a face value and overcorrected. Not quite. Each chapter in the book started out quite a book shorter. The chapters were lengthed in response to review and _testing_ of the material with learners. I also wasn't making any decisions based on other peoples' criticisms of the other materials but on what was causing the people I was helping online problems as they learned Haskell.
Is there an established way to write a Haskell program in such a way that it allows users to make plugins for it? Ideally plugins would be written in Haskell itself; I don't want to have to define a plugin language and interpret that. I found this: https://www.reddit.com/r/haskell/comments/6pu7ch/differences_between_hotreloading_plugin_libraries/ and came away thinking that I should probably use another language. Cheers
No worries, hey. Note that your post was automatically hidden by the AutoModerator since you're not a regular participant of the subreddit, but don't let that dissuade you from making relevant posts in future. We tend to be very liberal in approving posts related to Haskell (or even Elm, Purescript, Idris, Agda, and others), and are especially fond of *relevant* job postings. 😉
Vsyo normalno, brat.
Makes me happy and hopeful to see Stockholm on here, next time i I'm ready to apply! :)
If you prefer, you can email us directly at jobs@hihenry.com.
I assume you are not satisfied with something like fFoo' = go &lt;$&gt; f1 &lt;*&gt; f2 &lt;*&gt; f3 where go (x1, y1) (x2, y2) = (x3, y3) but I would say that this *is* the general way, since the type of `go` is uniquely determined by the return type of `fFoo'` and the number and types of applications of `(&lt;*&gt;)`. This kind of "shape" always applies. You can make use of typeclass instances as well to maybe simplify things, like the fact that pairs (tuples) of monoids form themselves monoids.
Could you be more specific in why you think that? While this is probably easier in a dynamic language, the `hint` library seems well-maintained and in the issue tracker the maintainers appear responsive. The plugin language is Haskell. At least I wouldn't say the development is *dead*, like someone else did in the thread you mentioned, and things don't look quite so bleak to me like at the time `xmonad` came out.
There are a quite a number of materials on type-level programming in GHC available for free, among others my lectures notes for the SSGEP summer school from a few years ago (https://github.com/kosmikus/SSGEP/blob/master/LectureNotes.pdf). The materials for this particular course are currently not online, but yes, it is possible that this will happen at a later point in time.
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [kosmikus/SSGEP/.../**LectureNotes.pdf** (master → 3e0247a)](https://github.com/kosmikus/SSGEP/blob/3e0247add3f7f19fff5ab86c8ddde45816514a56/LectureNotes.pdf) ---- 
Happens the same for me, I understand the concepts but in practice I don't get how to use them properly I think is a common problem with Haskell courses and books too theoretical and no practical, I'm staring at you LYSHFYOG
Learn You Some Haskell For Your Own Good?
If you truly believe that you need to read more books
Looks great so far, bought the MEAP - thanks for the discount code! One question, how would you prefer specific feedback? I came across some typos and the like, and just used the note feature on the livebook. Does that get back to you for an update, or is that just for my own use?
To clarify, this is largely due to `yaml`'s use of `buildable`, which could be argued to be misuse if impl(ghc &lt; 8) buildable: False I believe this makes cabal think that the version bounds don't matter because the component was *intentionally* made un-buildable, not un-solvable. The difference is subtle but I don't think it should have been taken for granted that stack's way was the right way. Certainly it should have been test with cabal before ever being released this way. Side note: I don't think we need every minor failing of the Hackage ecosystem to be reported here. The fix is done or in progress, and workarounds are known and discoverable.
I think you just wrote the best monad tutorial so far.
Indeed, there's a fix for cabal already merged: https://github.com/haskell/cabal/pull/5337 It isn't yet in a released cabal-install, but it _is_ in the one from the debian ppas for use in travis scripts, etc.
If you want to selectively narrow the sites with official information of Haskell/GHC, you may be able to use it ;-)
I can't give a good answer to all questions but [https://ghc.haskell.org/trac/ghc/wiki/Commentary/PrimOps](https://ghc.haskell.org/trac/ghc/wiki/Commentary/PrimOps) might be a good starting point for more information. &gt; Are they hooks for functionality in rts, and if so is it possible to access these features directly from rts, circumventing ghc-prim entirely? More or less. They get compiled into the rts as regular (haskell) functions so that Haskell code can call them. &gt; circumventing ghc-prim entirely? ghc-prim is part of the GHC distribution. So I don't think you gain anything by doing so.
The paper is available on [Todd Mytkowicz](https://www.microsoft.com/en-us/research/publication/data-parallel-finite-state-machines/) page. 
It read to me like a run down of why nothing out there during that post was very good. Reading it again (now I'm not grumpy on the train), you're right. I shall give \`hint\` a go. Thanks!
Reading Chapter 1, there's just too much strange grammar, I understand that English is not the author's first language, but it needs some editing.
What's meant by Haskell in the book ? Haskell by 2010 report or GHC with all its extensions and deviations ? Just asking ...
Your title is worded like it's cabal-install that caused the breakage here when clearly it's yaml that did something broken. It worked in one version of yaml and then it didn't. That's a regression. Once they added that constraint they should have tested it with cabal-install.
Please, put put a salary range. It's not that hard. By putting nothing down, you're essentially forcing someone to go through your whole application process before finding out what they would get paid (as generally asking about salary right away is seen as a negative for an applicant, as if "you only care about the money"). Many (if not _most_) people have some constraint on how much money they need to make at a job, so it's just disrespectful to not give that info up front. Salary ranges don't have to be super specific. For example, just a couple days ago there was [a posting](https://www.reddit.com/r/haskell/comments/8u35gj/job_simspace_is_hiring_remote_and_local_haskellers/) with: $90K – $150K / 0.05% – 0.2% equity. Those are pretty wide ranges! But that's okay, because they still give a good sense to prospective applicants, and you could apply knowing you aren't going to be jerked around later on with "well, we think working for $30k/year _is_ competitive given how great it is to work on Haskell".
This is a nice small library, so there’s not much to review—that’s a good thing because not much can go wrong. :) So just a couple of small suggestions: `NodeSet` could be the more compact `IntSet` instead of `Set Node`, and instead of a lazy tuple, `Edge` could be a distinct data type with strict fields (which would be unboxed by the compiler): data Edge = !Int :=&gt; !Int Whenever I write `empty` for a type, I usually try to consider whether `Monoid` &amp; `Semigroup` instances makes sense (or `Alternative` for parameterised types). Here I’m honestly not sure—there are a few possible choices of “combining” operations; I like the properties of “connect” and “overlay” from [An Algebra of Graphs](https://blogs.ncl.ac.uk/andreymokhov/an-algebra-of-graphs/), which you might be interested in taking a look at even if you don’t end up using it. Of course, if no single operation makes sense to privilege above the others as the “default” instance, then the desired operation could just be selected by different functions or operators, or by `newtype` wrappers—a good opportunity to learn about the handy wrappers in `Data.Monoid`/`Data.Ord` btw. 
Well, lucky for you there's the new post about a job in Sweden 😃!
In chapter 9 I plan to start with a bit of theory about polymorphism in general talking about forall quantifier hidden inside Haskell type signatures and bounded polymorphism by type classes. Then I'll continue with existential quantification and higher-ranked polymorphism—mostly examples from existing libraries with practical usage. I'll finish chapter 9 with the discussion of multiparameter type classes, functional dependencies and other GHC extensions dealing with type classes and their instances. In chapter 10 I'd like to cover generalized algebraic data types, type families, kinds and kind polymorphism. In fact, my progress in this chapter depends on the progress of the TypeInType GHC extension. I'll try to go as fas as what we have in GHC Haskell.
Thank you for buying! I am not sure about livebook notes unfortunately. The main source of feedback for me is Book Forum https://forums.manning.com/forums/haskell-in-depth. As for typos they are supposed to be fixed on a later production stages. The book content will be copyedited and proofread after finishing draft. 
Thank you, it will definitely be fixed by copyediting. In fact the text was copyedited before starting MEAP but then I had to revise it and introduced plenty of new grammar errors, my bad.
Thanks for taking the time to reply! I didn’t know about intset before- I’ll make sure to check that out. I’m not to concerned about the edges being lazy- they’re not used for the internal representation and are just for interfacing with a graph. Since I’m using IntMap.Strict, I don’t think that’ll matter. I’d actually read a paper similar to that article. If i create a Monoid instance for the graph (which I probably should), I’d probably go for overlay, in which case my empty would be mempty. 
As this book tends to describe Haskell in practice by Haskell I mean GHC Haskell with all implemented extensions. 
Have you read [David Barbour’s posts](https://awelonblue.wordpress.com/) about his work on RDP and his Awelon project? I haven’t spoken with him lately but he seems to be focused on [wikilon](https://github.com/dmbarbour/wikilon) at the moment.
Re: not being able to derive an instance for `Show`, is there a reason you can't add `Show a` to the set of constraints for the type constructor? Then you'd be guaranteed that `a` implements `Show`, so you could derive `Show` for your type. (I'm not very familiar with GADTs, so I'm genuinely asking.)
Great! I'm very excited for this. I grok the theory behind GADTs, type families, etc., but I've always wanted to see more in depth coverage of how people employ these features in practice.
Thanks for writing! I'll check out the forum for sure.
**Hackage:** [**https://hackage.haskell.org/package/StrictCheck**](https://hackage.haskell.org/package/StrictCheck) **GitHub:** [**https://github.com/kwf/StrictCheck**](https://github.com/kwf/StrictCheck)
As a student of Math and (recently) someone who has been reading about Haskell a lot, something that people often ignore when learning a technical topic (especially one where there might be some "deep theory" involved) is the amount of time you spend thinking about the topic in the background. A well-known technique to make progress on hard problems is to "sleep on them." I personally have applied this "trick" more times than I can count, and I think it extends to learning. This is also why some people find resource X easier or clear than resource Y, while others may prefer resource Y to X - resource X was what they used to get some initial (but frustratingly incomplete) intuition for the concept, spent some time thinking about it and working with the concept to build more intuition and then "bring it home" when they read resource Y and everything clicks. Anyways, welcome to the Haskell community and I hope you have a good time here, learning more about Haskell and "expanding your mind" (Haskell certainly helps expand your mind - there are some deep theoretical underpinnings that are fun to think about from a Math perspective.)
" The underscores indicate that neither the first element of the list nor the tail of the list were not evaluated by the context " What? Double negatives are hard to parse. I don't follow.
Rage bought it. :D Keep it up!
Beautifully written.
... Ugh. The first sentence of the linked guide for C programmers uses the word "obtuse" (stupid), when the writer probably meant "obscure" or "abstruse". Puts me off a technical piece, too. 
From the perspective of Category Theory, which part of Haskell corresponds to Category Theory objects? Are they the types or is the programming language itself an object? If the types are objects, is it right to say that when writing a program, the program itself is an instance of Category Theory model?
You'd make it much faster if you'd just code in Haskell a lot. Took me ~3 months of full time work on a project to become very confident with Haskell.
Unfortunately, Haskell pedagogy is very bad. It emphasizes what is different instead of what is similar. that´s because the Haskellers with pedagogical leaning don't want to teach Haskell the language for getting things done, but functional ideology which is a religion and a way of life. There are no how-to manuals. How to print in the console is teached in chapter 1000 after you learn monadoic ectocontravariant profunctors and the first 1000 chapters is spent doing useless ghci snippets. I experienced that nonsense the first time I tried to learn C++. The book available at that time( I'm old cof cof) was the one of Barne stroumptrump it was an exercise of presumptuous pedantry. I really learned C++ *programming* when I bought the Borland C++ compiler with a 10 page resume of C++ beautifully written. Since Borland wanted people to use C++ rather than buy books or get invited to conferences, they did the right thing with the right pedagogical orientation. Whith Haskell this same thing happens raised to the seventh power. Remember: old people often say the truth.
Nice, I was wondering how to do the kind of variadic currying described in appendix A.
I will give it a try. Thanks.
I like the minimalism of your library! You might want to try this benchmark suite for graphs to see how your library compares to others on common operations: https://github.com/haskell-perf/graphs.
What tools are you after? cabal-install, stack, and other tools should work okay. Stackage Nightly has been on 8.4 for quite a while now.
&gt; Queries and manipulations with common subparts can be factored for reusability. Can you provide an a few examples of this?
See, someone told me that when I was starting, so I tried it – and it was just insanely frustrating because I couldn’t do *anything. * Like, I couldn’t even ask meaningful questions because the whole thing was an incomprehensible mash. So I went away and learnt some theory and some background and that helped enormously. Just offering a counter example; I’m glad going in at the deep end worked well for you. Were you doing it as part of a full-time job?
Haskell from First Principles is a funny one. It’s what I used to get started and it worked okay, but it has a lot of problems like structural inconsistencies and exercises not matching their chapters, and it looks like it’s never going to leave early access. Also it’s arrogant af for them to be calling it “the Haskell book”. That’s the kind of monicker the community should bestow once a work is well known. Also the different personalities of the authors is very apparent. One of them is patient, nurturing, and has a sense of humor. The other one has a “yeah it’s hard, get used to it, dweeb” attitude. The latter one I ended up unfollowing on twitter for their constant tech-bashing and negativity about things they happen to dislike.
I would guess that it's a typo rather than an intentional double negative and they meant &gt; The underscores indicate that neither the first element of the list nor the tail of the list were evaluated by the context 
It wasn't a job, I was a kid then and dropped out of high school, had a lot of free time for hobby projects. I do work in software now, though. Yes, theory is essential, more for Haskell than for other languages - there's really no way to arrive at a modern Haskell style from scratch without reading. But applying the techniques is essential too, even just blindly if you don't understand them, otherwise it won't stick.
I think that the books you have mentioned are very good ones and relevant today. [Get Programming with Haskell](https://www.manning.com/books/get-programming-with-haskell) is a simple intro to Haskell, with a lot of practical knowledge. Give it a try!
I am really sorry I was not specific enough. For example ghc-mod is way back. 
Leksah has been updated. To try it out run: git clone --recursive https://github.com/leksah/leksah.git cd leksah nix-env -f . -iA leksah-ghc843 leksah-ghc843
Here's pretty much the go-to: https://github.com/bitemyapp/learnhaskell I think it'd be a good idea to add the repo to the sidebar. LYAH is a good reference, but pedagogically flawed in terms of learning the language (no exercises, etc). 
With reference to https://www.reddit.com/r/haskell/comments/8uzmqt/how_i_finally_cracked_the_nut/e1jgdyc/, it's plausible that your incomprehensible mash was necessary for the theory to click, and someone who learned theory first would need to code in Haskell a lot for it to click.
I found RWH to be quite helpful for wrapping my head around monad transformers.
The hakell-ide-engine I’m quite happy with it since I started using it.
Luckily it's a wiki so you can improve it!
Fixed.
So Taylor Fausak ([accidentally](https://github.com/theindigamer/theindigamer.github.io/issues/1)?) reminded me that I had a neglected blog and I should write. Well, so I wrote something! Thanks Taylor 😉. Initially when I was writing it, I was planning to have it be kinda' like an introduction "if you want to write a compiler in Haskell, this is the fun stuff and this is the not-so-fun stuff". Now that I've written it, it has turned out to be quite different ... and I'm not sure how much sense any of the points make to people not familiar with the concepts. Also, it seems that I put in way too many in-jokes 😅. So here's some stuff that I wanted to say but couldn't fit cleanly into the post: 1. If you want to write a compiler, writing in Haskell is an awesome idea. There are very good reasons why Compilers is on the [top of the list](https://github.com/Gabriel439/post-rfc/blob/master/sotu.md#application-domains) in "State of the Haskell Ecosystem". (Shout-out to Gabriel Gonzalez, your Lens tutorial has been super helpful! 😄) 2. If you want to get started with Haskell and are open to working on different stuff, an interpreter/compiler is a great first project. But be careful though, trying to learn and use the latest and greatest techniques might be counter-productive on your first attempt -- instead try something more traditional the first time and something fancier later if you so desire. 3. IMO, a good rule of thumb for a beginner project is -- try to find a well documented library so you don't have to worry about figuring WTF is going on there and you can focus on your application. Some of my favourites are Megaparsec and Uniplate. 4. Don't read monad tutorials! Just use Hoogle [1] to look up type signatures and think that you're playing tetris. How do I glue things together? The concept and laws might mentally click later than you might want, but that shouldn't prevent you from writing some useful code. Also you could write some dumb code -- it'll blow up in your face and you'll learn from it. The "understand it fully before starting to use something" mentality can be really harmful, throw it in the trash can (unless you're writing some serious software, then please don't! 🙃). [1] I highly recommend setting up Stackage's Hoogle as a keyword search in Firefox (or equivalent), as that searches through a lot of packages by default.
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [Gabriel439/post-rfc/.../**sotu.md#application-domains** (master → 1be40de)](https://github.com/Gabriel439/post-rfc/blob/1be40de1212f90fa221079f88c528bea5f831965/sotu.md#application-domains) ---- [^delete](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply e1jsbvg.)
Surely you were being purposefully abstruse when you said "The first but one sentence…" instead of "The second sentence…". Wait, or maybe you were being purposefully obtuse. Hmm…
The thing is, everytime paradigm change, and the old way is gone, this will almost certainly happens. People need to jump through a lot of hoops to do the old thing in a new way (if possible at all). Maybe you can look at specific hoop, and say 'this is hard to jump', but people have to jump through them. For the C++ part, I have no idea what book, but it is different - C++ have tight integration with C(and inherit the C way to do stuff, even if there is a C++ way) to let you do stuff old way, so this is possible. Let me copy/paste your format, line by line, to demonstrate this. Unfortunately, FORTRAN/ALGOL pedagogy is very bad. It emphasizes what is different instead of what is similar. that´s because the ALGOLER with pedagogical leaning don't want to teach ALGOL the language for getting things done, but a kind of structural ideology which is a religion and a way of life. There are no how-to manuals. How to write to a register is taught in chapter 1000 after you understand BNF, learn denotational semantic through category theory and can roll your own separation logic, and the first 1000 chapters of ALGOL book is spent doing useless stepwise refinement via axiomatic semantic from hypothetical algorithmic need. Even then you cant really write to a register!
I never used nix. Is it heavy weight or is just a light tool? I'm not happy with the free space I have on my computer. 
People usually talk about **Hask**, the category where objects are Haskell types, and where morphisms are Haskell functions. They don't call it **Set** (objects = sets, morphisms = functions), since *bottom* (non-termination, undefined) is implicitly an inhabitant of every Haskell type. The other perspective is surely interesting as well. Programming languages as objects, compilers as morphisms. I guess `cat` would be the identity morphism. Or you regard compilers as functors between, say, **Hask**, and other categories like it. I can't recall having read something like this anywhere though.
Were you really all beginners? Using mutually recursive cofree comonads as an AST representation doesn't sound so beginner-y to me.
I'm glad to finally see a new non beginner book coming out. Good luck with writing the book, and I hope you can stick to the claim of releasing updates every month, especially when manning has quite a few meaps dragging on with no updates for months on end.
One comment asked "why we used the cofree comonads in our AST representation initially" but it got deleted. Well I already wrote an answer: Good question! Mostly it was just that one team member suggested that "hey, we can do this thing and it would be really cool if we could pull it off and XYZ would become much easier if we used this representation" and we all agreed that "sure, let's do it, it would indeed be cool if we can do XYZ easily" after we understood some basic stuff. Turns out using advanced concepts when you only understand the basics can be a bad idea sometimes 😅.
Yeah that was me, sorry. The first version of my comment was something like "Were you really all beginners? Then why cofree comonads". Then I thought "there's no way these people were beginners at that time", and completely edited it. Then I thought "maybe cofree comonads are what people usually reach for when writing compilers, I probably should write one myself before asking stupid questions". 
That link appears to be broken. 
I think there are a ton of people stuck at this level. Yes, yes I understand monads in this laboratory setting, but not outside of it. 
I wouldn't say I was a total beginner, I'd written a full language parser (in Haskell) before I started working on this compiler. I also wrote a small compiler in OCaml before that.
Nix has a garbage collector that you can run manually when it starts using too much space (`nix-collect-garbage`), but it definitely needs it. Unless you are using NixOS it is going install everything again rather than use your OS installed versions of things. I use Nix on macOS for all sorts of stuff and my /nix directory often gets to 80GB before I run the GC to get space back. I think Nix is well worth it if you can free up some space though. Here are some of the some highlights for me: * Reproducible builds. A [nixpkgs](https://github.com/NixOS/nixpkgs) commit hash can pin down everything. * [Nix builds docker images better than docker](https://github.com/NixOS/nixpkgs/blob/master/pkgs/build-support/docker/examples.nix) * I no longer need MacPorts or Homebrew on macOS. * [NixOps](https://nixos.org/nixops/manual/) works great ([getting it working on macOS is fiddly though](https://medium.com/@zw3rk/provisioning-a-nixos-server-from-macos-d36055afc4ad)).
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [NixOS/nixpkgs/.../**examples.nix** (master → dd608f8)](https://github.com/NixOS/nixpkgs/blob/dd608f80dbbfd39e072b11174fad0e3751e2d388/pkgs/build-support/docker/examples.nix) ---- 
Often you have a couple queries that have the same from clause, usually a big old joined table, but different select lists like joinTable :: FromClause Schema '[] JoinTable joinTable = table (#orders `As` #o) &amp; innerJoin (table (#customers `As` #c)) (#o ! #customer_id .== #c ! #id) &amp; innerJoin (table (#shippers `As` #s)) (#o ! #shipper_id .== #s ! #id)) query1 = select #c ! #name `As` #name (from joinTable) query2 = select #o ! #price `As` #price (from joinTable) query3 = select #s ! #name `As` #name (from joinTable)
Thanks! That makes things much clearer! When you talked about `undefined`, that's due to Haskell's lazy-evaluation isn't it - since there is no Time in math. Is this a concern if we're talking about program runtime..? &gt; morphisms are Haskell functions Does one function map to one morphism or do we collapse all functions into one morphism between category objects?
Strange, it works fine for me. Could be the dot at the end? Here it is without the dot: https://github.com/haskell-perf/graphs 
It's working fine now - I was on mobile before, that could've had something to do with it.
I started out by doing Project Euler problems. The problems are simple enough that you don't need to learn a lot of new concepts at once, and they give you lots of opportunities to practice what you just learned. Sometimes I would go back and re-solve an old problem with a different technique so I could compare and contrast the two solutions.
&gt; exercises not matching their chapters This has annoyed me so much. I thought it was the authors throwing some "gotchas" in there for ""learning"" purposes.
I wouldn't say it is about run-time. Sure, there are things like the traveling salesman problem, but you could in principle say "we just need bigger computers". *Bottom* on the other hand would correspond to either an *infinite* loop (in contrast to a really, really large one) or something that just can't be implemented, like `f :: a -&gt; b` without "cheating" via `error` or `undefined`. There is no need to collapse morphisms, since more than one morphism can go between two objects. Sometimes you can count them, like in the case of `Bool ~ 2`, for which there are `2^2 = 4` functions of type `Bool -&gt; Bool`. Or more generally, `B^A` functions of type `A -&gt; B`.
Thanks! Are there any dimensions of composition of queries that you don't support currently? That is, can I build any reusable parts with beam or opaleye, that I can build with squeal today?
You actually can, I did not think of that {-# Language GADTs, GADTSyntax, StandaloneDeriving #-} data Quadratic a where Quadratic :: (Show a, Floating a) =&gt; a -&gt; a -&gt; a -&gt; Quadratic a deriving instance Show a =&gt; Show (Quadratic a) data Roots a where Roots :: (Show a, Floating a) =&gt; a -&gt; a -&gt; Roots a SingleRoot :: (Show a, Floating a) =&gt; a -&gt; Roots a deriving instance Show a =&gt; Show (Roots a) But you have to add a `(Floating a, Show a)` constraint to all the functions that create a Roots or Quadratic. I don't know which option is better.
Yeah, I think that would be a better idea. I tend to over do it when experimenting with something new.
Squeal is highly compositional. In particular, [\`subquery\`](https://hackage.haskell.org/package/squeal-postgresql-0.3.0.0/docs/Squeal-PostgreSQL-Query.html#v:subquery) allows you to embed queries in other queries and [\`with\`](https://hackage.haskell.org/package/squeal-postgresql-0.3.0.0/docs/Squeal-PostgreSQL-Manipulation.html#v:with) allows you to embed manipulations in other manipulations. Views which were added in 0.3 also provide a form of compositionality. If there's a feature from another library that you want support for then I can look into it, just open an issue on the [GitHub](https://github.com/morphismtech/squeal/issues).
No.. obtuse as in stupid is what works in context. More precisely "doing things in weird, over complicated ways that don't make sense". Which is how Haskell feels. 
I’m happy to hear that I promoted you to write a blog post! I’ll be sure to feature it in the upcoming issue of Haskell Weekly 😄
Well, tbf, I was considering writing it for a while but never got around to doing it. Maybe that was the nudge I needed :).
That is why I think I needed that article to which I linked. It seemed to me the author was saying, "I know you want to know what a monad is. Trust me. Just forget about it right know. It's some thing that does some other thing and ... oh, hell, I don't know. Get thru this bit first," along with "By the way, turn your mind 90 degrees this way and look at these problems again. ... There, you see it? ... Now put your head back right and try to unsee it." Whatever the "it" was, I couldn't unsee it. In this case, I think it was the idea of viewing functions as *mathematical* functions and not procedures/methods. There could still be some action involved but if I were to think of `f a b` as `f(a, b)` from an algebraic textbook, it would help make things easier. I think *that* helped to start a sort of "reset" in my mind, allowing me to make a new path for myself.
First, I'm seconding the llamas-are-bare comment, you may be attributing to an external source what is the fruit of your own work. That said, now that you got Haskell, you may want to revisit Rust too. If you professionally program in C, you may get a lot of value out of it, but one does need to comprehend high level languages before it's useful.
:) I use a cheap MacBook Air and my free space varies between 5 and 9 GB. Should I give it a try? I don't use haskell professionally, just for learning. And docker I don't use at all.
The word "obtuse" appears in three other places, that judging by the context, seem to be incorrectly used.
That is absolutely something that one of the two authors does – there’s even one where they effectively say “I can’t be bothered writing this chapter, just google it”. Other instances though, I think it’s just a mistake that would be corrected if they came back to finish the book. 
Absolutely, both are needed.
&gt; First, I'm seconding the llamas-are-bare comment, you may be attributing to an external source what is the fruit of your own work. I don't understand what you mean by "llamas are bare". The link I posted is certainly not my work. Since the page was first created on the old Haskell site 13 years ago and the last major edit to the page by the author was almost seven years ago, it would be weird for me to wait seven years to hype my own stuff. I don't know about you but I don't have the patience nor the attention span for that.
Cool! I'm curious about the structure of the book, one of my favorite haskell books was Haskell: First Principles because it had chapter questions that you had to solve and no solutions. I'm looking through the livebook on MEAP's site here and I can't tell if the book follows a similar structure. Do you go through and describe different kinds of programs, are there any exercises?
LYAH is relevant, and good if you have a strong math background.
RWH definitely is. I would say LYAH is as well but it's too informal for my tastes and there are other options now. 
Thanks for raising this; in my experience as a candidate with UK, US and Swedish companies, the latter prove consistently to be _very_ reluctant to talk about money, until the very end of the process.
I agree with /u/llamas-are-bare comment that was the top rated one on this thread (and probably still is).
[We've had these in the Agda codebase](https://github.com/agda/agda/blob/master/src/full/Agda/Utils/TypeLevel.hs#L66) for a while to provide generic serialization combinators and it's been a nice experiment so far.
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [agda/agda/.../**TypeLevel.hs#L66** (master → fe63378)](https://github.com/agda/agda/blob/fe6337817cd295f1b7a928b4865f187243744cf0/src/full/Agda/Utils/TypeLevel.hs#L66) ---- 
&gt; Don't read monad tutorials! [Shameless plug](https://wiki.haskell.org/What_a_Monad_is_not)
Bottom exists in every turing complete programming language. Think about it in terms of functions. Even a strict language can have a partial function `foo a = foo a`. Hask as a category doesn't really have a concept of laziness or strictness; just what inputs map to what outputs. A language being strict just means it uses an image of Hask where all morphisms map bottom to bottom. &gt; Does one function map to one morphism or do we collapse all functions into one morphism between category objects? One function maps to one morphism, generally. The only collapsing is that functions that are different at the machine level can be the same function at a theoretical level. Specifically, if two functions have the same exact output for all inputs, they are the same function and thus the same morphism (this includes bottom as an input or output). This makes it impossible to prove generally whether any two functions are the same morphism or not; the halting problem proves that we can't tell whether or not they both return bottom for the same inputs.
I will try further. Thanks!
Once again, the objective facts about what is happening are obscured by noise. * What is the issue with `buildable` in cabal files? What are the symptoms, and what library/tool versions does it affect? * What is the issue with yaml? What versions are affected? What is the work-around?
Great post! &gt; It would be nice if stack of­fered a clean way to unin­stall things – since it doesn’t, the op­tions left are (a) te­dious: use ghc-unregister to unin­stall stuff and cor­re­spond­ing de­pen­den­cies or (b) slow: nuke ~/.stack, re­run stack build and wait for it to re­com­pile the uni­verse (3). You don't need to nuke `~/.stack` just wipe old LTS snapshots. You can find the big ones conveniently with `ncdu -x ~/.stack`: ncdu 1.11 ~ Use the arrow keys to navigate, press ? for help --- /home/niklas/stack ------------------------------------- 13.4 GiB [##########] /programs 12.0 GiB [######### ] /snapshots 1.2 GiB [ ] /indices 245.3 MiB [ ] /build-plan --- /home/niklas/stack/snapshots/x86_64-linux -------------- /.. 1.6 GiB [##########] /custom-cachix-tCF4IxKUIdTa 1.5 GiB [######### ] /lts-10.0 1.1 GiB [####### ] /lts-9.1 754.1 MiB [#### ] /lts-11.9 738.6 MiB [#### ] /lts-8.13 594.1 MiB [### ] /lts-10.5 Press `d` to delete. This works so well for me and is so easy that I'm not sure what better method for deleting old stuff I could wish for to be provided by stack. &gt; ... stack ... stor­age space/pro­ces­sor speed are not avail­able eas­i­ly – I’m guess­ing this is most­ly a stu­dent bud­get/old lap­top is­sue that pro­fes­sion­al Haskellers don’t en­counter (for ref­er­ence, I’ve been us­ing a Thinkpad X230 with a 256GB SSD and at some point had ~/.stack at size 25 GB+). I didn't get the "processor speed" bit. Stack and cabal add virtually no overhead over GHC beyond perhaps final linking. (Full disclosure: Professional Haskeller using a Thinkpad X220 since 2011 who will use this machine hopefully until at least 2023. By the way, you can buy 500 GB SSDs that fit into the mini-PCIe slot and you will still have the normal HD slot free.)
So ppl often say that committee make bad/boring language while individual designer design good language. (I also remember reading somewhere that ALGOL is effectively dictated by peter naur). Is this false or is haskell an exception (or haskell not being anything special, a bit 'boring' because it is an aggregation of miranda/gofer/etc)?
&gt; Professional developer using X220 What do you do about compile times, with lenses/TH/type families? In our code with about 60-70 modules, changing the core modules would lead to build times of 1-2 minutes and Intero would start choking on the bigger modules... in some cases, it would show that the same module was being compiled multiple times, I have no idea why... The stack overhead is mostly storage related (not speed related, apart from the initial ghc setup for a snapshot) because the LTSes keep piling up whenever I download other projects from Github. I have to go and check which other packages I'm still reading the source for and avoid deleting those snapshots or I can just nuke everything and rebuild it later.
That's some quite impressive type magic. I wanted to try this out by testing whether toStream :: Applicative m =&gt; LogicT m a -&gt; m (Stream m a) toStream l = unLogicT l (\a b -&gt; pure (Yield a b)) (pure Done) fromStream :: Monad m =&gt; Stream m a -&gt; LogicT m a fromStream c0 = LogicT $ \cons zero -&gt; let loop c = case c of Done -&gt; zero Yield a m -&gt; cons a (m &gt;&gt;= loop) in loop c0 msplit_ :: Monad m =&gt; LogicT m a -&gt; m (Maybe (a, LogicT m a)) msplit_ l = do stream &lt;- toStream l case stream of Done -&gt; return Nothing Yield a m -&gt; do stream' &lt;- m return $ Just (a, fromStream stream') has the same strictness as `msplit` from `Control.Monad.Logic`. Couldn't even get the spec for the normal msplit, though, because on windows it crashes with *** Failed! Falsifiable (after 4 tests): ┌────────┐ ┌──────────────────┐ │ Inputs ├───┤ Demand on result │ ├────────┤ ├──────────────────┤ │ StrictCheckTest.EXE: &lt;stdout&gt;: commitBuffer: invalid argument (invalid character) 
I hadn't realised that type families let you pattern match on a function type constructor!
So do you have a preferred reference/tutorial you'd recommend to a Haskell beginner?
I think it's probably not quite true that committees make boring languages, and it's probably true that haskell is a bit boring. Let me elaborate: On the first bit, looking at languages with committees, I think that there is a bit of correlation != causation. By and large, I think that as languages mature, one of two things can tend to happen: - The amount of legacy code, libraries, and the broader community make it more and more expensive to add features to the language, leaving you with a boring language - Features are added to appease specific groups of users, and must be added in a backwards compatible way, leaving you with a language with too many features that often don't work well together and can feel bolted on Not to overly pick on the language, but I think C++ has been a great example of both of those problems. Neither problem is strictly related to a committee though, it's just the natural challenges that a language faces as it grows in adoption and matures. The maturity also tends to push toward more desire for standardization- so the same forces that can make a language bad or boring also tend to push for committees to standardize the language. New languages tend to have one main developer, although in reality no language of note is going to be the sole effort of a single person even if one person is the face of the language. On the second bit, looking at haskell specifically, I'd say that in some ways it is a bit boring. It may not feel like it if you're comparing it to Java or Go, but there are plenty of recent languages that have features that are either not available in Haskell, or else not fully mature or easy to use (for example: OCaml and Elm have row polymorphism, SML's module system, or Idris's dependent types). That said, Haskell (and GHC specifically) has benefited enormously from both the general power and flexibility of the language, and the language extension architecture, since it's allowed features to be added, experimented with, and refined over time without causing the language to suffer from too much baggage.
I did the same thing while writing my compiler! I've definitely regretted it at times and I'm still not _100%_ sold on it being a good representation since it prevents using a lot of other interesting libraries (ie: `unbound`). I've definitely had to learn a lot more about Comonads and higher ranked / kinded types though!
I’m afraid not! I just finished finished From First Principles so I’m in a position to critique it but I’m really only a beginner myself. 
Users of nix can test their package using the instructions in this gist. It should be straightforward as the 8.6.1 alpha will be downloaded from the binary cache. https://gist.github.com/mpickering/fd26e9f03d6cb88cbb91b90b6019f3dd The compiler will use patches form head.hackage in order to build dependencies. 
Leksah is 5.3GB including its dependencies like Gtk+ and ghc etc. ([here](https://gist.github.com/hamishmack/54c8c3d0f842ffdb3a7e00dbd4f98e69) is a breakdown). On top of that Leksah builds metadata and downloads the source for packages into `~/.leksah-0.17` and it is not unusual for that directory to go over 1GB (mine is 1.9 right now). Even if Leksah is too big, I still think you might want to try Nix. Many open source projects seem to be better supported on Nix than anywhere else (not just Leksah). For instance running `nix-env -i inkscape` works and often seems to install a newer version than is available in `dmg` form. Nix has binary caches of everything including all the Haskell packages. This is great if the machine your using it slow (no waiting for builds). Unfortunately this is not true of Leksah on macOS right now (The atk C library in the nix cache does not work with haskell-gi on macOS, so if you do install Leksah it will take hours to build on a MacBook Air). I use don't recommend using stack with nix. Stack's raison d'être is to address issues nix solves better. Instead I recommend using Nix with `cabal new-build` (and `cabal new-repl` etc.) as they work nicely with Nix installed haskell packages. If you have a large `~/.stack` directory or lots of bid `.stack-work` directories lying around you might be able to reclaim some space there. Similarly if you have installed GHC by itself you might get a lot of space back once you are happy with Nix by uninstalling ghc and clearing out `~/.ghc`, `~/.cabal` and `~/Library/Haskell` (check in `~/.cabal/bin` and `~/Library/Haskell/bin` in case you have something you `cabal installed` that you need to `nix-env -i`). To uninstall a nix packages run `nix-env -e leksah-ghc843` then run `nix-collect-garbage -d` to GC stuff you are not using. If you try Nix and it all goes horribly wrong the best uninstall process is to run the Nix installer again. It will complain that Nix is already installed and give detailed instructions on how to uninstall it. 
&gt; What do you do about compile times, with lenses/TH/type families? In our code with about 60-70 modules (~8k sloc), changing the core modules would lead to build times of 1-2 minutes (or more) and Intero would start choking on the bigger modules I use `ghci`'s `:reload` or `ghcid` for most changes (and also ghci for testing whether the code works, e.g. via `:main`) and only compile when I'm done. The slow bit is always codegen (unless you do some ultra fancy type level lists stuff, which when done wrong can blow up typechecking and coercions exponentially). So by using `ghci`, no codegen is done, so it's ~10x faster than building. If I remember correctly from my last chat with /u/chrisdoner, right now Intero uses `-fobject-code` which does codegen. It may be a good idea to add a mode where it does `-fbyte-code` like ghci instead, allowing the user to trade the ability to resume across interpreter restarts (`-fobject-code` is incremental in that case, `-fbyte-code` isn't) for faster reloads. &gt; it could use the ghc-pkg unregister solution and ask you whether it is okay to transitively delete all the dependents That sounds feasible, but I'm not sure how useful it is vs deleting the entire snapshot (e.g `lts-...`). Since package DBs are always per snapshot, the UI would have to look something like `stack uninstall lts-123 mypackage`. So you would have to already know very precisely which package from which snapshot you want to delete. That makes sense technically but at least for my own use cases I've always only longed for "delete the entire snapshot, I haven't built anything with that one for months".
I personally really like CIS 194 (Spring 2013).
I personally thought the book was unclear and not very well-written; at least the chapter on applicative functors which only left me more confused after.
Yeah, I recall reading a blog post by Matt Parsons on using `ghcid` but I like Intero way too much to stop using it :P. The UI can be thought of and iterated on if this feature were actually approved. For example, if you say `uninstall mypackage`, then it could give different prompts based off what LTSes have that package (in the trivial case, it does the obvious). I don't think that itself is a big deal. The problem is that this was closed as a "wont-fix" (or at least that is how I remember it, too lazy to look it up right now).
Section 3.5 of the paper "[A History of Haskell: Being Lazy With Class](http://haskell.cs.yale.edu/wp-content/uploads/2011/02/history.pdf)" seems relevant: &gt; **3.5 Haskell is a committee language** &gt; &gt; Haskell is a language designed by committee, and conventional wisdom would say that a committee language will be full of &gt; warts and awkward compromises. In a memorable letter to the &gt; Haskell Committee, Tony Hoare wistfully remarked that Haskell &gt; was “probably doomed to succeed.” &gt; &gt; Yet, as it turns out, for all its shortcomings Haskell is often &gt; described as “beautiful” or “elegant”—even “cool”—which are &gt; hardly words one would usually associate with committee designs. &gt; How did this come about? In reflecting on this question we identified &gt; several factors that contributed: &gt; &gt; * The initial situation, described above in Section 2, was very &gt; favourable. Our individual goals were well aligned, and we &gt; began with a strong shared, if somewhat fuzzy, vision of what &gt; we were trying to achieve. We all needed Haskell. &gt; * Mathematical elegance was extremely important to us, formal &gt; semantics or no formal semantics. Many debates were punctuated &gt; by cries of “does it have a compositional semantics?” or &gt; “what does the domain look like?” This semi-formal approach &gt; certainly made it more difficult for ad hoc language features to &gt; creep in. &gt; * We held several multi-day face-to-face meetings. Many matters &gt; that were discussed extensively by email were only resolved at &gt; one of these meetings. &gt; * At each moment in the design process, one or two members of &gt; the committee served as The Editor. The Editor could not make &gt; binding decisions, but was responsible for driving debates to a &gt; conclusion. He also was the custodian of the Report, and was &gt; responsible for embodying the group’s conclusion in it. &gt; * At each moment in the design process, one member of the &gt; committee (not necessarily the Editor) served as the Syntax &gt; Czar. The Czar was empowered to make binding decisions &gt; about syntactic matters (only). Everyone always says that far &gt; too much time is devoted to discussing syntax—but many of the &gt; same people will fight to the death for their preferred symbol for &gt; lambda. The Syntax Czar was our mechanism for bringing such &gt; debates to an end.
These are related information. &amp;nbsp; GHC plans for 8.6.1 https://ghc.haskell.org/trac/ghc/wiki/Status/GHC-8.6.1 &amp;nbsp; GHC 8.6.x Migration Guide https://ghc.haskell.org/trac/ghc/wiki/Migration/8.6 &amp;nbsp; LANGUAGE Pragma History https://ghc.haskell.org/trac/ghc/wiki/LanguagePragmaHistory &amp;nbsp; Current document source for language options https://github.com/ghc/ghc/blob/ghc-8.6/docs/users_guide/glasgow_exts.rst 
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [ghc/ghc/.../**glasgow_exts.rst** (ghc-8.6 → 149d791)](https://github.com/ghc/ghc/blob/149d7912eb84a24861b021c13d2ee61b44de5856/docs/users_guide/glasgow_exts.rst) ---- [^delete](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply e1kzdhd.)
Is [ghc.haskell.org](https://ghc.haskell.org) down? I'm getting no responses.
Haskell from first principles is pretty great. Massive, but I had tried LYAH before and the language didn't click. With first principles it really beats you over with exercises, and now it all makes more sense.
This time if I'm orange, it'll be because I'm actually orange. I managed to get a pretty bright sunburn yesterday.
The ghc.haskell.org seems to be redirected to www.haskell.org/ghc or https://ghc.haskell.org/trac/ghc . 
I went through that book and yeah, it's very long-winded. It did eventually pay off though as nothing else managed to teach me haskell. It could be fun for you to build something that interacts with an API. I've been using wreq (http://www.serpentine.com/wreq/tutorial.html) to put together a simple application that uses the reddit API. Here's all that code: https://github.com/bontaq/reddit/blob/2c4cc8eccfb9fd186b3da9d1becb31cd803f38fe/src/Main.hs There's also brick https://samtay.github.io/articles/brick.html which is a neat way to build command line apps, if you want to do something like that. I'd say use hoogle a lot as well. That book is such a slog but it does cover a lot of important things in excruciating but valuable detail. 
It seems like it's resolved now. Maybe just a server restart or something.
All of this is pretty well detailed in the link.
`BlockArguments` is almost as exciting as `QuantifiedConstraints`! This will be a great release.
Oaw! This is a real answer. My take is I can reclaim some space on this machine, but it will have pay having a new one. Story of my life. :)
Is the source available anywhere? Maybe I missed it in the article? I like looking at implementations like this for new ideas and things I might not know yet.
Hm. I might not particularly like the style, but I'm not sure I should go altering someone else's guide just because of that. 
Best way to learn Haskell is by practicing. I really like exercises from this course: * http://www.seas.upenn.edu/~cis194/spring13/lectures.html The speed of learning is really great there. And tasks are also practical and meaningful. It's completely okay to spend time to learn Haskell. Just take your time to understand basic ideas and concepts. And homeworks in this course allow you to grasp those concepts slowly but you will understand things. It's also always good to have somebody who can answer your questions and review your code to help you learn better and improve your skills. Our organization can give you mentorship (review solutions for homeworks, asnwer questions): * https://github.com/kowainik I think /u/vrom911 can help you with this!
I wrote [reading simple Haskell](https://soupi.github.io/rfc/reading_simple_haskell/) and [writing simple haskell](https://soupi.github.io/rfc/writing_simple_haskell/) to try and make Haskell a bit easier to get into. It's not a replacement for a more thorough learning resource, but it might help you get to the stage of writing simple Haskell a bit faster.
What is a good resource to learn about lenses and prisms, and what are the prerequisites to learn about them?
I suggest you have a look at [uu-parsinglib](https://hackage.haskell.org/package/uu-parsinglib), a parsing library designed exactly for that, and representing years of research on the topic at Utrecht. Besides the many practical examples mentioned in the library description, you might also be interested in the libraries whose names begin with `uu-cco`, beginning with [uu-cco](https://hackage.haskell.org/package/uu-cco), which provide utilities and examples for compiler construction using this library.
&gt; Certainly it should have been tested with cabal before ever being released this way, considering it's a fairly important package. That's up for debate, between package maintainers who use stack and ones who use cabal-install. * When Herbert released a bytestring version with a flag that stack's parser rejected and essentially broke stack because bytestring is also a "fairly important package", it's clear that he also didn't test it against stack (and said on the relevant issue that stack should fix its bugs and refused to change the flag). * Here, Michael has released yaml with a use of buildable which is resolved differently on cabal causing users problems, and he also doesn't test his package against cabal-install. As it turns out, I implemented both of the stack parts that differed to cabal a few years ago. There are probably others I don't know about. &gt; The difference is subtle but I don't think it should have been taken for granted that stack's way was the right way. Should we take for granted that either tool's is the right way when a new package release uses a configuration that no other package on hackage has ever made use of? So far we've seen flags and buildable constraints, there'll probably be others in the future. Ideally, package authors would test everything they make on all build tools. In practice people aren't doing that. Saying that people "should" probably won't change anything. I expect mitigation infra and one-off fixes will continue to be the MO going forward.
This looks interesting. In my humble opinion, though, a more detailed agenda needs to be available for a course that costs 360 GBP. I’m familiar with most, if not all, of the subjects presented, but only superficially. Depending on how much we’re going in depth with each subject, I might end up paying a sizeable sum of money for just a recap of what I know already. So, for what it’s worth, in order for me to consider joining, I’d need a paragraph or two elaborating on the level of detail of each of the topics presented (e.g. what, exactly, wrt. “Kinds and promotion” are you going to cover in the course).
If Haskell, or any language, is an exception then the statement is false. Haskell did have more ugly warts but as spj said, our pointy hatted users are tolerant of changes. Changes including removing n+k, constraints in data declarations, generalizing operations from lists to functors, redefining monad a couple times, etc.
Not sure why you think that. For me, the link only made the issue more murky for me, and more worrying. There is [#3978](https://github.com/haskell/cabal/issues/3978), related to backpack, which apparently is actually this bug. And then there is [#5325](https://github.com/haskell/cabal/issues/5325), which is about `http-client`. And then there are a bunch of different PRs where the link of this thread is only one of them, and where `yaml` comes into the picture somehow. Can someone who understands what is going on please briefly summarize what this is and where we are at?
A huge difference between Michael and Herbert is that Michael is more reasonable and has already prepared a workaround to help the very few users that are still using Cabal.
Where can I find changelog for `base` package?
Yes, I can help you with reviewing your solutions and answering your questions. I can't say I'm very experienced in Haskell, it's only a year I'm learning it, but I know how hard to walk this way without mentorship, so don't hesitate to ask :)
&gt; What is the issue with buildable in cabal files? Michael inadvertently used this cabal feature in good faith to denote that a package is not buildable with old GHC versions and this turned out to be broken to the point of being unusable &gt; What are the symptoms, and what library/tool versions does it affect? It affects only Cabal users &gt; What is the issue with yaml? What versions are affected? Latest release of yaml has a Cabal file that triggers a bug in Cabal with GHC 7.10 and below &gt; What is the work-around? Use Stack if you don't want to wait for Michael to release the workaround
I'm not 100% sure, but the current version is probably below. https://github.com/ghc/ghc/blob/ghc-8.6/docs/users_guide/8.6.1-notes.rst#base-library https://github.com/ghc/ghc/blob/ghc-8.6/libraries/base/changelog.md 
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [ghc/ghc/.../**changelog.md** (ghc-8.6 → 149d791)](https://github.com/ghc/ghc/blob/149d7912eb84a24861b021c13d2ee61b44de5856/libraries/base/changelog.md) * [ghc/ghc/.../**8.6.1-notes.rst#base-library** (ghc-8.6 → 149d791)](https://github.com/ghc/ghc/blob/149d7912eb84a24861b021c13d2ee61b44de5856/docs/users_guide/8.6.1-notes.rst#base-library) ---- [^delete](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply e1leysg.)
&gt; When Herbert released a bytestring version with a flag that stack's parser rejected and essentially broke stack because bytestring is also a "fairly important package" My opinion is that it should have been tested with stack and he shouldn't have pushed that breaking change. With that said, I think my position that this change also shouldn't have been made is fair. We should absolutely expect central packages to build with both stack and cabal-install. Just because a maintainer is partial to one or the other isn't an excuse to neglect the other. It should not be taken for granted that people use one tool if it is trivially avoided. &gt; Ideally, package authors would test everything they make on all build tools. In practice people aren't doing that. Saying that people "should" probably won't change anything. For people maintaining packages so important to Haskell, I absolutely expect this. You're right; It's a high standard that I don't hold for everyone. But if you maintain some the most important packages on Hackage, the bar is higher.
&gt; A huge difference between Michael and Herbert is that Michael is more reasonable Please don't use ad hominem. &gt; has already prepared a workaround So has Herbert. The issue is resolved in cabal-install upstream.
&gt; Just because a maintainer is partial to one or the other isn't an excuse to neglect the other. Why? If I invent a new build tool right at this moment, should I expect you to start caring?
&gt; If I invent a new build tool right at this moment, should I expect you to start caring? If not, then what is the criteria for mandatory caring? If a significant majority of the Haskell community (see [this user survey](https://www.fpcomplete.com/hubfs/Haskell-User-Survey-Results.pdf) and also this [other independent user survey](http://taylor.fausak.me/2017/11/15/2017-state-of-haskell-survey-results/#question-23)) uses your tool then hell yes. 
So because a thing is popular, I have a moral obligation to support it? PS: I assume and hope, in this case, that we are going to once again, ignore the flaws that are repeatedly pointed out in this survey.
I never used the word mandatory. Expectations are quite different than requirements. I think it's fair to expect that central packages work with central tools. Your personal new build tool obviously does not fall into this category. But yaml obviously is not strictly required to work with cabal-install, or else it would not have been possible to fix the broken version. Any ethical concerns seem irrelevant in this particular case; AFAIK, snoyman has no ethical concerns with users of cabal-install
For the love of god stop posting those surveys. They're not convincing and obviously flawed. It's starting to feel like gaslighting.
&gt; For people maintaining packages so important to Haskell, I absolutely expect this. If not mandatory, then what does this mean exactly, in terms of an expectation? &gt; central packages work with central tools What does this mean, in that my new build tool does not meet this criteria? I honestly don't know what "central packages work with central tools" means. ---- Ethical concerns definitely come into these expectations. It is possible, for example, to believe that supporting certain software is unethical. What if I hold the belief that proactively supporting some software is unethical? I'm not going to impose that belief on others, but I'm also going to expend zero effort on supporting it. Is that OK with your absolute expectation?
Part of it is that these structural types are such a fundamental building block that it's unlikely that any library will be satisfying, as unless everyone agrees on said library and builds on top of it, usability is more limited. Usually when I want this feature while coding, it's because I value the general improvement in productivity and readability and expressiveness from them for the situations at hand, and wish that the libraries I used were based more heavily around them, not because they will be an instant solution to some concrete problem. Hence why I usually don't reach for a library, and just wished they were well supported and used by the language itself.
Are you disputing that Stack isn't the most popular used for Haskell development or do you merely oppose to those survey as being methodologically unsound?
What about just using composition instead of inheritance? data Entity = Entity { someEntityField1 :: Int, someEntityField2 :: Bool } data Document = Document { someDocField :: (), entity :: Entity } data Article = Article { someArticleField :: Text, document :: Document } 
Thanks! I like this particular change a lot: * Move the module `Data.Functor.Contravariant` from the `contravariant` package to base. Now waiting for `Profunctor` to be in `base` so we can finally can have `microprism` package. 
YES! BlockArguments is happening &lt;3 &lt;3 &lt;3
Thanks for the replies so far. I will take a look at these other resources as well and see if any of these help quicken the process a little bit. I am patient I know it is going to take a little while to learn but I will persist and keep pushing not going to give up I am determined.
Can someone tell me what BlockArguments are? out of the loop for a while.
This is the proposal for blockArguments extension. It was implemented by Akio Takano. https://github.com/ghc-proposals/ghc-proposals/blob/master/proposals/0010-block-arguments.rst 
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [ghc-proposals/ghc-proposals/.../**0010-block-arguments.rst** (master → 0572178)](https://github.com/ghc-proposals/ghc-proposals/blob/05721788de9ab6538def68c3c2c9dec50c9f24a8/proposals/0010-block-arguments.rst) ---- 
`do` became a dollar cheaper. 
I the hierarchy open or closed? In OOP there is often big emphasis in creating classes that are open for extension (you can create more subtypes of the hierarchy) but in general, Haskell takes the other side of the expression problem: We tend to create data types that are closed for extension. If the hierarchy is closed, then I would say Haskell is the natural language to model your problem. I would also suggest that you take a look at the [generic-lens library](http://hackage.haskell.org/package/generic-lens) which will help you emulate the up-casting property of class hierarchies. For example, it will allow you to create a LegalRecord into just a Document if needed, or even apply "super" functions to any entity down the hierarchy.
DerivingVia is also amazing! https://github.com/ghc-proposals/ghc-proposals/blob/master/proposals/0023-deriving-via.rst 
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [ghc-proposals/ghc-proposals/.../**0023-deriving-via.rst** (master → 0572178)](https://github.com/ghc-proposals/ghc-proposals/blob/05721788de9ab6538def68c3c2c9dec50c9f24a8/proposals/0023-deriving-via.rst) ---- 
As mentioned before, `haskell-ide-engine` works with GHC-8.4: https://github.com/haskell/haskell-ide-engine It uses `ghc-mod` internally, so if you just want `ghc-mod` then look at this fork: https://github.com/alanz/ghc-mod/ and its branches. The one that is currently used by `HIE` is this one: https://github.com/alanz/ghc-mod/tree/ghc-8.4-hie so I think that you should be able to build it and use it. 
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [alanz/ghc-mod/.../**66fc0980d2c731caf36215969a31bff8ef40f3e2** (ghc-8.4-hie → 66fc098)](https://github.com/alanz/ghc-mod/tree/66fc0980d2c731caf36215969a31bff8ef40f3e2) ---- [^delete](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply e1lifcw.)
Have a look at megaparsec recovery feature: https://markkarpov.com/megaparsec/fun-with-the-recovery-feature.html, this may be what you are looking for.
Excited that NumericUnderscores landed, a feature I've used in OCaml in the past. It's a, relatively speaking, simple feature but can be used to improve code readability.
I built HIE and so far is working fine. Given my low space machine I’m still pondering if I should bring hoogle on the scene.
&gt; I expect mitigation infra and one-off fixes will continue to be the MO going forward. I think the CI infrastructure in the ecosystem is constantly improving. It will continue to become more and more robust against various classes of regressions.
Well, there's two ways to learn lenses and prisms: 1. Learn how to use lenses in applications for simple tasks. 2. Understand how lenses works. Also, there's `lens` as an idea (which is pretty simple and implemented in multiple packages) and `lens` as the Haskell library (which is pretty complicated). First is pretty fast to achieve. And I can recommend this tutorial: * http://hackage.haskell.org/package/lens-tutorial-1.0.3/docs/Control-Lens-Tutorial.html Regarding 2: I don't think it's possible to completely understand everything behind lenses. But I can recommend this tutorial from /u/peargreen: * https://artyom.me/lens-over-tea-1
Haha, I see what you did there :)
I would probably recommend https://en.wikibooks.org/wiki/Haskell/Lenses_and_functional_references instead of lens-over-tea, as the latter is very meandering. Some people like it, but it's not everyone's cup of tea (haha).
As the author of one of those surveys, I’m interested in addressing flaws, especially since I plan on running another survey this year. Can you point me toward some critiques or resources for making a better survey? Thanks! 
Too short notice! :-(
&gt; Certainly it should have been tested with cabal before ever being released this way, considering it's a fairly important package. I don't like to get into these threads, but this misinformation is pretty bad. I _did_ test this with cabal. Anyone can review the Travis configuration script and history. I would challenge anyone here stating that "this should have been tested for" to describe to me a set of reasonable and normal tests that should have been included in the yaml package that would have discovered that this bug can occur. I will happily include such changes. To my knowledge, no standard CI script that exists would have revealed this bug, because _GHC 7.10.3 was supposed to fail_ based on the new version bounds.
Some of the critique was recently pointed out by u/ElvishJerrico in https://www.reddit.com/r/haskell/comments/8tc8pr/fp_complete_launches_new_blockchain_auditing &gt; We've pointed this out to you before. Both of those surveys show severe selection bias. A poll by the Stackage devs, and by an independent Stackage contributor who has alienated contact with non Stackage supporters on the platform he used to advertise the poll is about as biased as it gets. &gt; Any survey by a party that is partial to a particular view is going to have selection bias. In this case, it's pretty extreme. It should not be surprising to think that fp complete has much better outreach to Stackage users than to non Stackage users.
I added an explanation at [the end of my recent blog post](https://www.snoyman.com/blog/2018/07/stop-supporting-older-ghcs): &gt; It turns out that with all released versions of cabal-install, there's a bug that works something like this: if a component is `buildable: False`, then all of its dependencies are ignored. However, the dependency solver will still select such a package as a library dependency, even though the library component is marked as non-buildable. Then, when trying to build this dependency, cabal-install will (rightfully) complain that it cannot build a package with no library or executables.
The "three major GHC versions" meme originated when GHC was on a much slower release schedule - by a factor of 3 or 4. This is not a new question for the Haskell ecosystem. These kinds of trade-offs have been balanced in every language and OS ecosystem. There is plenty of design space in between "full support" and "only major security issues". Most mature ecosystems eventually settle on some graduated scale. Something along the lines of: * Shiny new APIs and features only on very recent platform versions * All bug fixes, even minor ones. back-ported far enough to cover at least a couple of standard deviations of the user base * Major bug fixes back-ported to all but the outliers * Security fixes back-ported with best effort to cover all conceivable current users * Airlines still running the SABRE reservation system from the 1950's via scores of nested historical hardware emulators will have to manage on their own
Is the following going to fold as the primes are taken, or is it going to find 2,000,000 primes *first*, and then fold *that* list of primes? foldl (+) 0 $ takeWhile (&lt;2000000) primes 
Some people do learn better from a tutorial-style approach. For those of us who do better banging our heads against a reference-style approach, there used to be the Haskell Report+Gentle Intro, but those have not been kept up. There are things you can supplement with somewhat, like the Language Extensions chapter of the GHC User Guide, but we really need something much better.
Any ideas on making it easier to support old GHC versions? For example, would ignoring unused import warnings on older GHCs help?
Oh neat, this was one thing I missed in Haskell that I learned to like in Purescript.
What is the best vim plugin for Haskell development?
Well, I don't think that exercises are something that we really need in an in-depth books. Readers at this level usually have their own problems so the best approach would be to apply an acquired knowledge to them. Alternatively, they can work on examples provided in the book to extend them as much as they like. I give some suggestions on that in the text.
As the author of a number of libraries I've often wondered about how many GHC versions I should prove I support. For anyone looking for more data, I've never personally received requests to *lower* my bounds to support older GHCs. I consider us to have good build tooling. It seems trivially easy to me to bump up to the latest compiler. **Question for commercial Haskellers:** is this also true in large applications? If it is, who are these hypothetical legacy users that we're extending support for? One legitimate concern is for [Eta](https://eta-lang.org/), which I believe is essentially GHC 7.10 with a few 8.x backports. If you do still want to support older versions, here are some things off the top of my head that make 7.10 Haskell sad: - `8.0` adds `TypeApplications` syntax (`@Foo`) and `ApplicativeDo` syntax - `8.2` adds `DerivingStrategies` syntax (`newtype Foo a = ... deriving newtype Functor`) - `8.4` advances the Semigroup-Monoid proposal, which confuses imports in old code For Semigroup-Monoid, I've found it not enough to realias `mappend` as Semigroup's `(&lt;&gt;)` (yet). You can avoid CPP mess by reimplementing `mappend` with the same code as `(&lt;&gt;)`. 
In fact I believe that understanding monads in the laboratory setting is sometimes harmful. They are simpler in practice than in all those rather artificial examples made up to complicate things.
Consider using OSF for pre-prints
&gt; who are these hypothetical legacy users that we're extending support for Probably platforms for which modern compilers are not easily available, e.g. SmartOS or Raspberry Pi. Unfortunately that can often make builds *less* robust, due to inconsistencies in the C preprocessor or whatnot.
Our customers are large enterprises, each with a highly customized version of our app. Upgrading each takes work. We only do it when a customer pays for that. Otherwise, they pay only for maintenance and bug fixes. That can be for years at a time. Furthermore, some customers have our product installed in their corporate network, where they might have provided us (years ago) with servers running a platform where recent GHC isn't supported. When a third party library breaks, we need it fixed, certainly if it's a security concern, and we need that to happen on a GHC that is years old.
&gt; It seems trivially easy to me to bump up to the latest compiler. Question for commercial Haskellers: is this also true in large applications? At work we write everything for the backend and ops in Haskell, and we have on the order of magnitude of 100,000 lines of Haskell code. Bumping our compiler version is usually a couple hours work at most for one engineer a couple times per year. That is to say, it is super easy. In fact, the bulk of the work is usually because some dependency in our Stackage snapshot made some backwards-incompatible changes we have to address. I don't remember the last time we had to change something because of GHC itself, or any changes in `base`. For my open source work, I tend to try and support the latest 2 or 3 GHC versions. Certainly if someone asked me to support a slightly older version, or if they want to make a PR to support a slightly older version, I would oblige. That's never happened though, so I don't really see the ROI in expending effort to supporting very old GHC versions in recent versions of my library.
This is not a case that CI would have caught individually for building a package. It's about mismatched expectations about how the solver interacts with the full state of constraint interpretation and how it interprets certain flags.
Yep thanks!!
I disagree with the approach to handling `ghc` dependencies. Cabal files can have an `other-extensions` field where you can put all the extensions your project uses. You can then depend on any version of `base` that fits and `cabal` will solve the constraints for you. This has the added advantage that it works with GHCJS as well.
I would actively encourage *not* trying to support old GHC versions. The hypothetical legacy users are either largely a) hypothetical, or b) industrial users. In the latter case they've *chosen* to stay on old versions and that's on them. Generally speaking and IME, upgrading is not painful enough to bend over backwards to try to remain backwards compatible to GHC &lt; 8.0. (Debian stable seems to be used as a kind of marker for what even very legacy-minded people care to support, but Debian stable is absurdly out of date on most things. Even hardcore supporters are either running testing/unstable or only running stable on servers that don't actually need any remotely recent software. So, I suggest ignoring Debian for the purposes of determining what should be supported.)
[removed]
I neither support Stack, to be honest. Don’t like this craziness of downloading an older GHC just because one of the modules didn’t bump its dependencies for long. And it is a gargantuan storage eater.
&gt; the version of the base library that ships with GHC. You can use this handy lookup table I put together, which I made because I can never remember this information. The standard handy lookup table for that has always been [this page](https://www.haskell.org/platform/contents.html).
In reality, that doesn't actually work. GHC has bugs. Things move between versions. In theory working with well published and formally verified extensions and libraries gives you everything you need. In practice, it doesn't.
My approach is to stop supporting old versions when the hassle gets above manageable levels. At the moment some of my projects support back to GHC 7.4 (e.g. HLint, Shake), while others stop at 8.0 (Hoogle). It's getting gently annoying going as far back as 7.4, so I'm tempted to jump to 7.8 when 8.6 is out (I find 7.6 and 7.4 always break together).
Translation: Michael cares more about himself than the collective effort his users have to take to use his libraries. This is precisely why I've heard people say that they avoid depending on Michael's libraries--because they impose a large maintenance burden on people who depend on them. This is especially true in organizations with large Haskell codebases that can't afford the sometimes large amount of effort it takes to upgrade GHC versions every year and a half. 
Liar. It is telling that your account was created just a few days ago and you have only 2 posts trashing something about haskell community. 
or https://ghc.haskell.org/trac/ghc/wiki/Commentary/Libraries/VersionHistory which is more neutral...
That's not a translation.
Another related ugly use of `$` is when applying functions to lambdas or using lambda case: foo $ \bar -&gt; baz foo $ \case Wot -&gt; qux Somehow PureScript has managed to elide the need for `$` in both cases, I wonder if that could be implemented for Haskell as well?
Debian stable is actually not too far behind when it is released. Right now we are probably more than half way to the next release which is why it is getting a bit dated. Not nearly as dated as RHEL though.
Agda does this too (lambda binds to the right)
Option 2 isn't *completely* crazy - I've implemented a small OOP language in Haskell before, although iirc it didn't have inheritance (it was an exam assignment for uni, took 2-3 days from scratch). Haskell is *really* good at making those small interpreted languages, and OOP evaluation is pretty easy to model with a State monad.
True, RHEL should also be disregarded :). (Just FTR, I don't bear any ill will towards Debian/RHEL, I just don't think it's a thing that a cutting-edge language/ecosystem should even try to support outside of e.g. Docker containers and the like.)
For me, supporting older GHC is a very small cost. Travis CI builds with older GHCs just fine, so I don't need to care (i.e. test locally). It's quite rare occasion when a library "maintainment" development suddenly requires a feature available only in the newer GHC. So I don't see a point of dropping support for older compilers "just because" (Also https://github.com/haskell-foundation/foundation/issues/450 issue is just silly, the compat stuff is still there cluttering code base, sounds like lose-lose to me). Libraries like http://hackage.haskell.org/package/base-compat help with AMP (to support pre-7.10), and its bigger brother http://hackage.haskell.org/package/base-compat-batteries helps with Semigroup-Monoid proposal. There are also other functions in `.Compat` module, like `Data.Either.Compat.fromRight`, which is only in base since `4.10`. http://hackage.haskell.org/package/base-orphans has orphans. You can get very far using these. I suspect that the pressure comes from the fact, that `stack` is badly suited for getting new libraries to work with older GHCs. You have to **manually** find good install-plan, to get working `stack.yaml`, because there aren't Nighties for other than current GHC (or any snapshots with recent package versions, for older GHCs). (`http-client` does also use `cabal` in CI, but if it breaks getting equivalent `stack.yaml` for local debugging is PITA). So my knee-jerk reaction is rather: **stop supporting older Stackage LTS**. It's very easy to put lower bounds close if not to the latest version of dependencies (sans GHC bundled libraries). For example dropping support for `QuickCheck-2.10` will barely affect anyone (except LTS-11 users), but you get new helpers from `QuickCheck`!
There's quite some audio clipping. Sounds like normal microphones weren't built for Ed's voice.
What do you consider the mainstream if not the stable releases of the most popular distros? In my experience it is hard to even get customers to upgrade their systems once per stable release cycle (once every 3-4 years).
&gt; the fact, that `stack` is badly suited for getting new libraries to work with older GHCs No shit Sherlock... because that's not a relevant use-case. If you're trying to make stack look bad you have to try harder than complaining that a train is badly suited for traversing the dead sea. 
Latest non-LTS Ubuntu (or LTS when they happen to coincide, obviously) seems like a good baseline. It also roughly corresponds to snapshots of Debian unstable at regular intervals. What customers are willing to do is another issue and tradeoffs will vary wildly here -- are we talking desktop systems or servers? What distro *are* they running? Are they getting security updates, how on top of security is their vendor? It's also my experience generally that *if* you upgrade regularly the less of a big deal it becomes to upgrade. That is, you get good at it and evolve enough support infrastructure to make it Not a Big Deal.
Michael is clearly stating that this is resulting in more maintainance cost than he's willing to endure when he writes &gt; The basic claim here is simple: Supporting older GHCs together with new ones adds a real maintenance cost to a library. This is even higher if your goal is to make the code compile without warnings across all supported versions ... He's perfectly entitled to set his preferences this way but that doesn't change the reality and the effects that has on other people depending on his packages.
&gt; The "three major GHC versions" meme originated when GHC was on a much slower release schedule - by a factor of 3 or 4. I've seen people using formulations like 'all major versions of GHC released in the past two years, plus the most recent major version released more than two years ago' to account for that. Unless GHC moves to a browser-like release cadence and we get a major version every six weeks, that should be workable for most people, and has obvious generalisations for more/less stable software: just change 'two' to 'N'.
What exactly am I lying about?
How does Tesla violate workers' rights?
I was talking servers. Latest non-LTS Ubuntu would mean a major upgrade every 6 months. Not to mention they are pretty good at breaking stuff. You definitely want something that gets security upgrades, especially for servers that are directly connected to the open internet. I agree that you should run upgrades pretty much as soon as possible but not distro upgrades, especially since you tend to get worse security support on bleeding edge distros compared to stable ones.
\&gt; for\_ \[True, False\] \\x -&gt; print x True False \&gt; :{ | for\_ \[True, False\] \\case | True -&gt; print "t" | False -&gt; print "f" | :} "t" "f"
`&gt; for_ [True, False] \x -&gt; print x` `True` `False` `&gt; :{` `| for_ [True, False] \case` `| True -&gt; print "t"` `| False -&gt; print "f"` `| :}` `"t"` `"f"`
``` &gt; for_ [True, False] \x -&gt; print x True False &gt; :{ | for_ [True, False] \case | True -&gt; print "t" | False -&gt; print "f" | :} "t" "f" ```
Sorry to hear about the audio clipping. I'll see what I can do to fix it for the next stream.
I gave 4 days notice on twitter. Follow me there. ;)
With `foldl`, it'll traverse the first 2,000,000 primes first (though it won't necessarily calculate them, depending on the definition of `primes`; it only needs to traverse the list, not evaluate its contents), and then it'll start to evaluate the additions. But with `foldl'`, addition will be performed as the primes are taken.
Cool, I didn’t know megaparsec had this. It looks promising and like less of a change than uu-parsinglib—although I’ll still have to manually ensure it’s total.
What is the best way for someone who is not super familiar with the GHC but, knows a bit about LLVM to get involved and contribute? 
Twietter? What's that?
I don't know the details not generic-lens but just using `mkClassy` (from `lens`) might be a lighter solution.
generic-less is like mklens, but instead of using template haskell, it uses derive Generic
generic-lensis like mkClassy, but using derive Generic instead of template haskell
I recommend following this guide: https://github.com/bitemyapp/learnhaskell Yorgey's CIS 194 course gets you up to speed with Functors, Applicatives and Monads which are used very frequently. The "Functional Programming" course will help you build intuition for Applicatives and Monads; I was awkwardly type-mashing the functions at the beginning, but developed strong intuition and Actually Knew what my code did by the time I was done with the Parser exercise(s).
[Quantified constraints](https://github.com/Gertjan423/ghc-proposals/blob/quantified-constraints/proposals/0000-quantified-constraints.rst) is a big deal. This opens up the possibility of quite a lot of refactoring. For example: class (Category a, forall b. Applicative (a b)) =&gt; Arrow a where ...
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [Gertjan423/ghc-proposals/.../**0000-quantified-constraints.rst** (quantified-constraints → 14b5898)](https://github.com/Gertjan423/ghc-proposals/blob/14b589876a19d523c6700cbdb2681544ebacfd99/proposals/0000-quantified-constraints.rst) ---- 
&gt; A generally accepted rule of thumb is three major GHC releases. I would like to challenge this "rule of thumb". At least two GHCJS releases (i.e. branches) should be supported as well IMO. Supporting GHCJS has much higher value than older GHC releases.
Recording: https://www.twitch.tv/videos/279832717 Code: http://github.com/ekmett/auth
This is pretty much the approach I take as well. I support old versions for old packages until it really blocks forward progress on the API. New code? I generally don't bother to backport, but will almost always take patches that backport functionality to older compiler releases as long as they don't clutter things up unduly.
This works for a handful of extensions that haven't changed in 10 years, but `other-extensions` has no idea how broken, say, `PolyKinds` are on GHC 7.4, where using them will produce broken .hi files, and many other extensions have little one or two version ranges of horrible brokenness or radically changed semantics.
The fact that `Eta` is locked at 7.10 is really the biggest barrier to me adopting it today. =/ I have a bunch of code that uses backpack that would be amazingly well suited to running on the JVM, but crippling the code to run in 7.10 is such a big loss of functionality I just can't bring myself to do it.
Thank you for the pointer, we were not aware of OSF. The preprint is posted to arXiv, and will be announced shortly. The final paper will be open-access licensed CC-BY.
&gt;That's quite some impressive type magic. Thank you! &gt;on windows the error reporting breaks None of us (the authors) run Windows—thank you for the bug report! We're investigating the cause of this issue. I suspect it has to do with Unicode text handling, as the StrictCheck diagnostic printout uses Unicode arrows and such to make itself pretty.
You are [issue #1](https://github.com/kwf/StrictCheck/issues/1) on the StrictCheck GitHub repository! We'll take a look as soon as we can.
This is indeed a typo. Thanks!
Try changing your console codepage before running it: \`chcp 65001\` will set it to UTF-8.
It depends on *your* style of learning. If you are a fast leaner, or what to quickly quickly understand what makes Haskell so different from other languages, LYAH is a good bet. 
[Trac #13615](https://ghc.haskell.org/trac/ghc/ticket/13615) means that any program using parallelism and `ST` with GHC versions before 8.2 can silently produce wrong answers. As far as I know, no one has backported the fix and released fixed versions. Therefore, versions 8.0 and earlier should probably all be considered unusably broken for anything important. Of course, lots of programs end up working lots of the time, but I wouldn't want to put my faith in that.
&gt; So I don't see a point of dropping support for older compilers "just because" I agree. Most of the time the reason I want a newer compiler is related to new extensions to the type system - not various functions in `base`. As such, I rarely need to drop support for older compilers on a project I'm maintaining. 
Wut. 
GHCJS is currently on 8.4 I think. 
Not a single plugin but I use: * https://github.com/vmchale/cabal-project-vim * https://github.com/vmchale/ghci-syntax * https://github.com/vmchale/hs-conceal and the semi-related 
&gt; So ppl often say that committee make bad/boring language while individual designer design good language &gt; Is this false or is haskell an exception Haskell is "boring" in that it is an standardized lazy functional language. However, that happens to be quite different from pretty much anything else in existence. 
Is there anyway I can run Haskell programs on my pc(win10) without messing around with command line? I have used eclipse and visual studio before but when looking at how to even install and run something I am at a complete loss. I pretty much only need this to run a single program and have 0 experience with this from what I have been reading it does not seem very beginner friendly. I have tried to use online compilers but from what I can tell if my program isn't done running in 40 seconds I get timed out.
I hope one of the Eta people sees this.
This is good evidence of needing to support legacy. How far back do your clients' GHCs go? Are you at liberty to say?
Same here - about 2 hours for a single engineer on our codebase
I really wish this comment was upvoted higher, because it's the most important point this thread needs to see. Arguing about supporting older versions of GHC, which GHCHQ itself is not supporting those versions of GHC, is simply flawed logic. If people want bugfixes, unfortunately the only way to get them is to upgrade GHC versions. I'd personally prefer slower release cycles for GHC with more bugfixes applied to "older" versions. But the decision on the new faster release cycles had been made before I even knew the discussion was happening.
I'm going to refer to [David's comment below](https://www.reddit.com/r/haskell/comments/8va8mc/stop_supporting_older_ghcs/e1mw6tv/), which was suspiciously downvoted despite being factual and relevant. In sum: I don't see any way to make the argument that we need to support older versions of GHC when those versions of GHC themselves are no longer supported. If you care about bug fixes, you _must_ upgrade your GHC version. Personally, I'm very disappointed in that answer, but it's the answer from GHCHQ right now, and arguments to the contrary have not made a difference. Backporting bugfixes at the library level when the compiler itself is shipping bugs is only papering over the problem.
Our position on adoption GHC 8 features has been a lot more lenient than before. We've actually been slowly backporting many GHC 8 features for upcoming v1.0 release. On master now, we've backported ApplicativeDo, Strict, and StrictData and we've adopted the new pattern match checker so you get accurate warnings for GADT pattern matches. TypeApplications and others (except for TypeInType) are still on the to-do and I'm not sure they'll make it in time for v1.0. Backpack is something we're open to but I heard there were performance issues and were waiting until those were fixed. If you think it has tolerable performance, we can actually backport this right away.
There is no particularly good reason to require slower release cycles to get bugfixes applied to older versions. We just need someone to step up and backport fixes. I think hvr *may* actually be doing some such work with his PPA, but there's no current system for making "official" releases of such versions. On the flip side: the particular bug I mentioned has a fairly well-contained fix that could be backported, but many bugs *don't*. Lots of times, someone will rewrite great gobs of some GHC component from scratch (or nearly so), and at some point someone will realize that doing so fixed some bugs. In many cases, trying to figure out exactly why the bugs went away is non-trivial. Backporting massive changes is pretty risky, as they can easily introduce new bugs as well.
One of the problems with supporting older GHCs is the way how this support is implemented: basically, bunch of `if` statements via CPP preprocessors + `if`s inside `.cabal` file. In Haskell language itself everything is so composable, we have cool features like function composition, ADTs, pattern-matching and much-much more cool stuff! But when it goes to higher level it becomes imperative mess which is really not pleasant to write and maintain :( For example, with GHC8 you can write custom type error messages. This is a really great feature but when you want to support GHC7 your code becomes really hard to read and maintain (especially if you want to put `ghci` examples of such error messages in documentation and test automatically with `doctest`: now you also need to manually check documentation). Also, if you care about optimizing dependencies of your packages and you want to make them pluggable, you're doomed currently. For example: I have custom prelude which reexports some lenses functions to make application development more convenient. I would like to use `microlens` package by default if I need some lenses. But if I already have `lens` package as a dependency (even implicit one) it doesn't make sense to bring `microlens` as a dependency so I would like to switch to `lens` in that case. Or I just don't want any lenses if I don't use them. What I would like to have is some ADT with the following functions but on type-level (with passing proper arguments automatically for me, but that's another story): ``` data LensVersion = None | Micro | Lens extraReexports :: LensVersion -&gt; [ImportDeclaration] extraReexports None = [] extraReexports Micro = [ Lens.Micro [(^.), (.~), ...] ] extraReexports Lens = [ Control.Lens [(^.), (.~), ...] ] ``` And then in your package configuration you can write just ``` build-depends: my-package{LensVersion=None, ... other options ...} -- or guessed automatically ``` But that's like a very big dream. The point is that bringing cool ideas and features from language on the level of package-management for this language can really simplify things. Like packages as functions, pattern-matching on compiler and library version instead of writing `if`, auto-pluggable dependencies and so on. I think `Backpack` moves really well in that direction and I'm looking forward to more research in this area!
Not really the must useful, but Haskell can totally do OOP [https://arxiv.org/abs/cs/0509027](https://arxiv.org/abs/cs/0509027])
In [superrecord](https://hackage.haskell.org/package/superrecord) we make sure the labels are always sorted and thus you can use a simple array to store the contents of your record, you'll know statically at compile time which position to read/write which results in a single pointer indirection. In our case the machine code generated for record access is very similar to the record access that GHC generates (used to generate?) for normal field access.
It's all about audio compressors.
Not looking for a dev position, but I’ll be traveling to Stockholm for a couple weeks soon. Will be great to see what the Haskell presence is!
^The linked tweet was tweeted by [@snoyberg](https://twitter.com/snoyberg) on Jul 02, 2018 04:30:46 UTC (0 Retweets | 2 Favorites) ------------------------------------------------- Apologies to anyone having trouble using the most recent http-client, a Hackage Trustee added a revision breaking it to work around a cabal-install dep solver bug. Users of Stackage should be insulated for now. I'm making a new upload for cabal users. ------------------------------------------------- ^^• Beep boop I'm a bot • Find out more about me at /r/tweettranscriberbot/ •
Combined with https://twitter.com/jkachmar/status/1013442504006520833 this paints a very bad picture.
TLDR - Thinking in rank 2 polymorphic space is great; trying to write those thoughts into working code is kinda annoying.
I think lambdas as arguments are part of BlockArguments as well.
You don't see the irony here? This post and especially this comment are just as unacceptable for the same reasons, if not more considering you're adding zero technical value.
How exactly was the package broken by a trustee? I can't reproduce the breakage on the revised version (0.5.13) with either stack or cabal
One interesting thing about these `User Maybe` types is that they are automatically a `Monoid`: User w h &lt;&gt; User w' h' = User (w &lt;|&gt; w') (h &lt;|&gt; h') Which makes it possible to make an interface such as: is :: Lens User a -&gt; a -&gt; User Maybe is l x = set l x mempty myUser :: User Maybe myUser = height `is` 2.5 &lt;&gt; width `is` 5.5
[https://github.com/haskell-infra/hackage-trustees/issues/165#issuecomment-401698244](https://github.com/haskell-infra/hackage-trustees/issues/165#issuecomment-401698244) Lol. The package was \*never\* broken and he didn't even bother to test it. This whole post is based on an actual lie.
I think that it's safe to assume that a major motivation of Michael's libraries are their usefulness to theirs users. However, with limited resources sometimes one needs to prioritise. The result is prioritisation is that not all use-cases will be served equally if at all. Ironically, you are misinterpreting the ill-served cases as disregard to users when it's nothing but care for the users.
The package was not broken at all: https://github.com/haskell-infra/hackage-trustees/issues/165#issuecomment-401698244
Always happy to see people write about functor functors. ICYMI, I built out some categorical structure to deal with this variety of parameterisation in [a blog post from a few months ago](https://www.benjamin.pizza/posts/2017-12-15-functor-functors.html)
I met with the SumAll folks for an informational interview before I took my current position and they were thoroughly nice. At the time they were knee-deep in the language transition, and doing fun stuff with CRDTs within a microservice system. They’ve also made some interesting management decisions like salary openness. Nice to hear that they seem to be doing well!
I see this was quickly resolved by /u/snoyberg simply admitting he was mistaken and leave it at that without going into politician-mode... NOT
&gt; One interesting thing about these User Maybe types is that they are automatically a Monoid: Yup, and more generally, I think ideally you should just be able to write `instance (forall a . Monoid (m a)) =&gt; Monoid (User m)`, but I think this is the sort of thing we need quantified constraints for.
Fake news!
Learning Haskell from First Principles: http://haskellbook.com/
Your post is actually where I discovered that `rank2classes` package! If it weren't for that package and its convenient TH tools, I would never use this approach, but that package automates away enough of the pain that I think in many use cases, the benefits are indeed worth the remaining pain.
IDK that your `Monoid` approach is much of an improvement over the native `lens` way of doing it: myUser = emptyUser &amp; height .~ 2.5 &amp; width .~ 5.5 Also I think the `Endo` version will do just as much rebuilding as the usual `Monoid` version (compiler optimisations notwithstanding).
Backporting large changes in general is of questionable usefulness. Essentially what you end up doing is basically just making a new fork of an old version. This is just as much a new version as far as potential for breakage is concerned as the regular new versions. Or in other words, it requires just as much testing as new version to be considered safe to upgrade without breaking anything. Old versions with backports are used by fewer people so they tend to get less testing. This is in direct conflict with the idea of using old versions for stability.
Is there an advantage for `forall a. Monoid (m a)` instead of `Alternative m` or `MonadPlus m`?
The `lens` version would be: myUser = emptyUser &amp; height .~ Just 2.5 &amp; width .~ Just 5.5 which is a little more cumbersome. The `Endo` version will at least not build an `User` for each update, as well one for each function application. But you are right, it would be nice to be able to guarantee just one application without partial results (without relying too much on compiler magic).
Dunno, intuitively it feels like there's less required, but maybe that's me not thinking hard enough about it. But ya, you can get `instance (Alternative m, MonadPlus m) =&gt; Monoid (User m)` by using `mzero` for all the fields and using `&lt;|&gt;` pointwise for `mappend`.
Ok.
Thread locked. 
So it's the offsets-approach mentioned in other comments. Nice to see it working.
You could probably whip something up with nix to do this for you. Then you would also get the licenses of non-haskell dependencies as well.
Well, you can look at: [https://programming.tobiasdammers.nl/blog/2017-10-17-object-oriented-haskell/](https://programming.tobiasdammers.nl/blog/2017-10-17-object-oriented-haskell/) on how to do something like that in Haskell.
Triple backticks don't work on Reddit, you'll have to indent by 4 spaces :).
We have a hacky tool in-house that does this by grabbing the license file from hackage (the filename is guessed), based on package name and version. You could try going that route?
I would try to help you :)
Even running GHC itself on Windows is a bit wonky. Every other release is plagued by segfaults.
If you have some recommendations, I'd be happy to have them :)
You can always override the ghc version in stack, or even tell it to always use the system ghc :) (you *have* to do the latter on FreeBSD 12-CURRENT right now [haha](https://github.com/commercialhaskell/stack/issues/3515))
It's usually ignoring the warning on new GHCs that's necessary. That might be a fair trade-off, but I don't like avoiding -Wall cleanliness. Another option is using either an alternative prelude or import module which absorbs all of the CPP ugliness for us. The problem is a lot of people dislike adding extra dependencies to libraries, and repeating import modules across packages is a pain.
What? I've been using Windows exclusively and while I can't say I've _never_ seen a segfault, they are extremely rare. And I don't think I've ever had the compiler itself segfault.
Same. Currently discussing with my colleagues whether we can open-source ours.
&gt; If you care about bug fixes, you *must* upgrade your GHC version. Sometimes it is simply impossible to upgrade GHC, for various reasons. Even in those cases, you still need your product to keep working. Ongoing library support is critical for that.
Try 8.4.1, 8.4.2 or 8.4.3 with the 32-bit arch.
I've only seen one segfault and that was last year, the issue only occurred in a really specific situation and has since been fixed.
To throw another example out there that currently affects less people but will become more important in upcoming years, [trac #15038](https://ghc.haskell.org/trac/ghc/ticket/15038) means that anyone using `UnboxedSums` to make a type like `(# Int# | Foo #)`, where `Foo` is lifted, may experience a crash on GHC versions before 8.4.3. And [trac #15300](https://ghc.haskell.org/trac/ghc/ticket/15300) means that `UnboxedSums` on GHC versions less than 8.6 might cause bad code generation in currently unknown circumstances. Although use of `UnboxedSums` is currently uncommon, I suspect that it may pick up stream in the next two years, at which point picking up a transitive dep on anything that uses `UnboxedSums` may mean that using GHC below 8.6 is unsound.
AFAIK, that "rule of thumb" doesn't pertain to the general ecosystem; it's just an internal rule the GHC project uses, saying that the GHC codebase must be bootstrappable with a compiler up to 3 major releases older. It says nothing about libraries (except those required to build the stage1 compiler).
This is the sanest approach I can think of. It's a cost/benefit ratio - as long as the cost is minimal (auditing a few trivial commits, checking build status, and clicking "merge" every now and then), and the benefit is that it keeps working for a few more users, why not. Breaking support for political reasons ("everyone should be using the newest GHC version, this is my attempt at forcing them to") is just a shit move.
Pulling the library support rug out from under the entire ecosystem just because of a single specific GHC bug is throwing the baby out with the bath water. (How's that for a mixed metaphor?) /u/davidfeuer said "any program using parallelism and `ST`", not every application. If every application were irrevocably and catastrophically broken in some GHC release, it's safe to assume that there would have been an immediate bug fix release and no one would be using the broken one. Conversely, if a particular GHC release was widely used for a while, and it's still in use now by a non-trivial user base, it is by definition a usable GHC release. So libraries should still endeavor to support it, if they can. Obviously, library maintenance takes work, and we can't always have the ideal. But by comparing to other mature ecosystems that are used in production scenarios, we should know what to strive for.
There is one flaw with that logic, namely, that even if both GHC and the libraries are buggy, tightly coupling the two together still makes things worse. Between GHC bugs and library bugs, it's very much possible that one affects you and the other doesn't. "If you want GHC bugfixes, you must upgrade GHC" is a reasonable demand, and I doubt anyone will argue with that. And that's essentially the deal that the GHCHQ team is giving you: "we're not going to support multiple GHC releases in parallel". (And while that is not an ideal situation, it is kind of a necessity given the available manpower). However, "if you want *library* bugfixes, you must upgrade GHC, and also probably all the other libraries" is much less reasonable. The one fix you're after might just be that some library now officially exposes some useful internals (off the top of my head, WAI is an example where this has happened), but then the library version that has the fix might require a compiler upgrade, which then breaks some other completely unrelated libraries, and triggers a cascade of required libray upgrades, or you may even have to find replacements for some packages entirely because even though the ones you're using were perfectly fine, they break because of SMP, and suddenly you're juggling a hundred moving parts and even rewriting some modules in a legacy codebase just so you can access some request field that you need without relying on an unstable `Internal` API. Upgrading the compiler is not a trivial change, and the more library authors put in at least a minimal effort to support a reasonable backlog of GHC versions (the keyword here being "reasonable"), the less likely the above horror scenario becomes.
If this sub is only meant for _conference_ videos, please say so in the sidebar. Otherwise, I might be tempted to post [my own Haskell videos](http://haskellcat.com/) and the Haskell talks of [Lambda Montreal](https://www.youtube.com/channel/UCbLK7HM5Ox2tvFZbQ2ytT0Q)...
It’s for conference and meet ups. I will update the side bar.
This is more complex than you're asking, but [Fossology](https://www.fossology.org/) is a language-agnostic tool for tracking open-source licenses and copyright notices in source code. Fossology scans directory trees and compares against a database of license texts, displaying both exact coincidences and deviations (diffs) from the canonical text for every license (which is important because a single sentence, or even a word, can completely change the distribution terms). It cannot automatically look for Haskell dependencies, but maybe it's possible to implement this functionality as a plugin, and that would be a helpful contribution for the Haskell community. Given a project, it automatically finds license files, but *classifying* (assign copyright and distribution terms to every source file) might require some manual work. The good think is that it preserves manual classification actions upon project upgrades.
What is the fuss (and point) about LLVM ?
I'm not sure I understand the question, in part because it's not clear whether "common data", "extra data", and "payload" all refer to the same thing or to different things. Are you saying that you want a datatype which holds both an Int and some existentially-quantified `e`? Something like this? {-# LANGUAGE GADTs #-} import Data.Typeable data SomeShowTypeable where SomeShowTypeable :: (Show a, Typeable a) =&gt; a -&gt; SomeShowTypeable data IntAndSomeShowTypeable = IntAndSomeShowTypeable { theInt :: Int , theSomeShowTypeable :: SomeShowTypeable } toIntAndSomeShowTypeable :: (Show a, Typeable a) =&gt; Int -&gt; a -&gt; IntAndSomeShowTypeable toIntAndSomeShowTypeable i a = IntAndSomeShowTypeable i (SomeShowTypeable a) fromIntAndSomeShowTypeable :: Typeable a =&gt; IntAndSomeShowTypeable -&gt; Maybe a fromIntAndSomeShowTypeable (IntAndSomeShowTypeable _ (SomeShowTypeable a)) = cast a showIntAndSomeShowTypeable :: IntAndSomeShowTypeable -&gt; String showIntAndSomeShowTypeable (IntAndSomeShowTypeable _ (SomeShowTypeable a)) = show a -- | -- &gt;&gt;&gt; fromIntAndSomeShowTypeable example :: Maybe String -- Just "foo" -- &gt;&gt;&gt; putStrLn $ showIntAndSomeShowTypeable example -- "foo" -- &gt;&gt;&gt; theInt example -- 42 example :: IntAndSomeShowTypeable example = toIntAndSomeShowTypeable 42 "foo" 
The major factor in "how much can we backport" is always one of time, of course. One-year schedules offer a much more flexible window to take time to port things, so you can get by with fewer hands doing the work. I'd argue that with a much shorter release window, you're going to be time-strained, so you either need a much bigger pot of contributors doing piecewise work -- or you need people who spend dedicated time doing backports. But that tends to require pretty detailed knowledge and isn't always glamorous. There are also plenty of times a big rewrite happens, but a bug *doesn't* get fixed, which means you better be ready to write a bespoke fix for it...
I made [this horribly hacky script](https://gist.github.com/adamgundry/0b99d80cfc8b74cbb249c97822bf247f) to do exactly this. There must be a better one out there somewhere, though...
I have a servant app being served by Wai/Warp, using `withStdoutLogger`. Normally I get apache style logs like 127.0.0.1 - - [29/Jun/2018:09:44:58 +0100] "GET /path/to/endpoint HTTP/1.1" 200 - "http://localhost:8080/" "Mozilla/5.0 (X11; Linux x86_64; rv:52.0) Gecko/20100101 Firefox/52.0" but when there's an uncaught error, I get something like 127.0.0.1 - - [29/Jun/2018:09:45:00 +0100] "GET HTTP/1.0" 500 - "" "" i.e. the endpoint that caused the error isn't shown. (This happens with e.g. `error` calls, not when using `Servant.throwError`. With `Servant.throwError` I get the expected endpoint and error code.) This isn't a big deal, and it hasn't been worth my time yet to investigate thoroughly. But does anyone happen to have seen this before and knows an easy fix?
Maybe it's the 32-bit. I've never used 32-bit GHC releases.
Yes it's good for starting but no for doing practical things
Yes good tutorials and docs for practical haskell would be better to overcome this
Therebis always `?~` to get rid of some of that boilerplate. 
would be awesome :)
nice, I'll take a look
I've got the same problem on Archlinux.
I wrote a quick little bash script for this using jq and Nix 2.0: nix show-derivation -r $1 \ | jq '.[] | .outputs | .[] | .path' -r \ | (while read path; do [ -e "$path" ] &amp;&amp; find $path -name "LICENSE"; done)
You can do this with Bash: find -iname '*LICENSE' -exec cat {} \; &gt; file.txt Not at my computer, so not sure if this 100% accurate. However, looking at the 'find' man page should resolve issues if any.
You should open an issue on trac for this or bring it up on the mailing list. The main reason it was so easy to get `Data.Functor.Contravariant` into `base` was because it had been [discussed twice on the mailing list](https://ghc.haskell.org/trac/ghc/ticket/14767) and was fairly popular. The only trick with `Profunctor` is that `QuantifiedConstraints` opens the door for a possible `Functor` superclass. If this minor API churn is going to happen, then the class may have to live outside of `base` for a while longer. But, I haven't seen any comments for Edward on what the superclass plan is for `Profunctor`, `Bifunctor`, `Bifoldable`, etc. now that `QuantifiedConstraints` is available.
The upcoming release of [`cabal-plan`](http://hackage.haskell.org/package/cabal-plan) has a new `license-report` sub-command which generates license reports such as [this one for `hackage-server`](https://matrix.hackage.haskell.org/~hvr/hackage-server.html) And its also got the ability to copy the license textfiles into a local folder (and have the generated report use local filesystem hyperlinks to those; the one linked above doesn't) simply by issueing $ cabal-plan license-report --licensedir=licenses exe:hackage-server &gt; hackage-server.md $ pandoc --self-contained -c license-report.css -s hackage-server.md &gt; hackage-server.html and which populates a folder hierarchy under `licenses` such as licenses/aeson-1.1.2.0/LICENSE licenses/async-2.2.1/LICENSE licenses/attoparsec-0.13.2.2/LICENSE licenses/base16-bytestring-0.1.1.6/LICENSE licenses/base64-bytestring-1.0.0.1/LICENSE licenses/base-compat-0.9.3/LICENSE licenses/base-orphans-0.7/LICENSE licenses/blaze-builder-0.4.1.0/LICENSE licenses/blaze-html-0.9.1.1/LICENSE licenses/blaze-markup-0.8.2.1/LICENSE ... Any feedback or help with improving the report generation is welcome!
The problem with windows and haskell is that even though GHC itself is supported on windows, the libraries are written by hundreds of different developers who do not belong to GHC team. And I would say easily 90% of them do not work on windows and do not even have ability, time or desire to test their libraries on windows. 
Wrote a little bash script for this: #!/usr/bin/env bash set -eou pipefail findLicenses() { while read path; do if [ -e "$path" ]; then find "$path" -name "LICENSE" [ -d $path/share/info ] &amp;&amp; find "$path/share/info" -name "*.info" fi done } fetcher() { if [ x != "${FETCH_DEPS:-x}" ]; then nix-store -r "$@" else printf "%s\n" "$@" fi } fetcher $(nix show-derivation -r "$@" | jq '.[] | .outputs | .[] | .path' -r) | findLicenses Build your project with Nix, then do `./licenses.sh /nix/store/...-my-path`. It'll find all LICENSE files and `share/info/*.info` files. The arguments to the script are actually just the `nix show-derivation` arguments, so you could even do something like `./licenses.sh nixpkgs.hello` to try it on the `hello` package. By default, it'll only check the licenses of paths already on your system. You can set `FETCH_DEPS=1` in your environment to tell it to `nix-store -r` everything else, causing it to download or potentially build everything that's *not* on your system. This would include the *entire* build time closure, meaning it's going to include everything back to the bootstrap C compiler used to build GCC.
Practically every application uses `ST` whether it knows it or not. So "parallelism and `ST`" is practically equivalent to just parallelism. That means pretty much any time you or a dependency uses `forkIO`, `par`, `rpar`, etc., there could be trouble. I think that probably covers most interactive or networking programs, and some batch programs too.
Thanks for the instructions. I just had to add `cabal-plan-0.3.0.0` in stack.yaml
I wrote a little script for doing this at the store level. You were probably thinking about this at the expression level, but that can't discern the difference between build time and runtime dependencies, which is likely important to most people. That said, I'd love to see an expression-level license finder, which should be easy since most derivations have a `meta.license` field. #!/usr/bin/env bash # licenses.sh set -eou pipefail findLicenses() { while read path; do if [ -e "$path" ]; then find "$path" -name "LICENSE" [ -d $path/share/info ] &amp;&amp; find "$path/share/info" -name "*.info" fi done } fetcher() { if [ x != "${FETCH_DEPS:-x}" ]; then nix-store -r "$@" else printf "%s\n" "$@" fi } getPaths() { if [ x != "${USE_DERIVATION:-x}" ]; then nix show-derivation -r "$@" | jq '.[] | .outputs | .[] | .path' -r else nix path-info -r "$@" fi } fetcher $(getPaths "$@") | findLicenses This takes a store path as an argument and searches for licenses in its closure. E.g. `./licenses.sh /nix/store/...-my-path`. By default, it operates only on the runtime closure of the path; i.e. it checks the licenses of all paths in the store that might be used at runtime by your path, such as `glibc`. If you set the `USE_DERIVATION=1` environment variable, the script will instead check all the paths from the build time closure that are on your system; so it will also check any build tools used to build your path. If you set `FETCH_DEPS=1`, it will even go as far as to attempt to download or build any paths that *aren't* on your system, meaning it'll go back as far as the bootstrap compiler that built GCC. The rules for finding license files are in `findLicenses`, so it's pretty easy to add more rules. This one just checks for `LICENSE` files and `share/info/*.info` files. Finally, the arguments to the script can actually be whatever you would pass to the new `nix path-info` or `nix show-derivation` shorthand commands. So you can even just do something like `./licenses.sh -f foo.nix bar.baz`.
Maybe, it's not much you can do if you have to link with 32-bit stuff.
That's a fair comment. It's just frustrating having to have a separate OS purely (excuse the pun) for using Haskell.
I use backpack almost entirely because of performance issues -- just in the other direction. ;)
Sadly OpenGL is deprecated in macOS 10.14 
It's not very strong and certainly makes no problem in understanding the content. I just thought it might be a small settings/setup change yielding great payoff in fidelity and being able to lean back and listen.
Not blaming anyone, an honest question: Why such critical bug is reported to wider audience only 14 months after the fact and on /r/haskell? I don't see mentions in release notes or GHC users mailing list. For the future, summary of discovered &amp; fixed critical bugs would be good to have. If I were an user of older GHC, and couldn't upgrade immediately, I could have built my own GHC version with the patch? 
Good to know, thanks! Then plan B as outlined - logic in Haskell-land, rendering (using whatever is present in Mac, though for this example it barely matters) in ObjC.
Was there a problem before the first break about an hour in?
I've literally just put a patch up for this https://phabricator.haskell.org/D4917 The reason it took so long to fix is that a report saying "it segfaults" is incredibly not helpful...
from a quick look at that package, I'm sorry to say it just doesn't look to be portable at all. There's no way to really work around that error without modifying the source. The issue is that on unix systems `mysql_config` is a shell script, on Windows it's a perl script with a .pl extension. modifying the source to run "perl mysql_config.pl" would get further but not by much as the next issues will come from the use of posix APIs and types. In short.. probably not worth the hassle. Also lots of the advice in that thread are outdated. GHC supports import libraries these days. Can you instead of that package not use an ODBC package? 
Don't misunderstand: I'm not complaining about this, or the speed at which these get fixed and I'm glad for all this work. It's just one example to illustrate the fact that GHC doesn't have the same level of support for every platform. Platforms which get used by more people are more stable and reliable. Not much any single person can do about that :)
They do in the redesigned Reddit interface, which seems to be slowly gaining in use.
/u/edwardkmett mentioned MoltenVK on his last stream, which looks like it's more or less just in need of Haskell bindings to bridge that gap.
The issue comes down to mostly one of resources. At this point, the most widely tested ports are the 64 bit versions of the compiler. This is true for Linux as well and for upstream projects we rely on (GCC, binutils etc). Our CI's currently only run 64 bit ports, and on the latest kernel versions. While it is true that Windows isn't as well supported as other platforms, it is still a Tier 1 platform. If you look at the GHC 8.6 changelog, a you'll see a lot of Windows specific improvements. 8.8 will have even more and bigger ones. However no matter how well the compiler gets it just can't account for packages that are non-portable. I've noticed also a lot of misunderstandings and bad advice when it comes to linking shared code on Windows. When you do stuff like pass a DLL to the linker, we can't really do much but to do as you ask and pray for the best... In any case, if you have issues on Windows report them on Trac with as small a repro as possible which will decrease the time it takes to fix them. I'm not saying they'll be fixed immediately, but without the reports we can't improve the port.
You're missing one part of the audience: university lecturers who don't have control over the machines they're teaching with and can only do so much if IT is not willing to upgrade the system-wide installed ghc to a more recent version.
There are some Haskell Vulkan bindings, but IIRC, they are just for 1.0 not 1.1.
I noticed that this repo was missing a CI script, so I [sent a pull request](https://github.com/tonymorris/do-not-use-stack/pull/2) to add a script that ensures it builds with cabal-install and fails with Stack. Bonus points: I tightened up the `base` version bounds to properly respect PVP rules.
hilarious :D
[Oh my!](http://i3.kym-cdn.com/photos/images/newsfeed/000/312/563/05d.jpg)
depends, which parts of LLVM are you familiar with and what would you like to work on?
This trolling is getting tiring. Downvoted.
Why does the [original repo](https://github.com/tonymorris/do-not-use-stack) readme say `fuck stack` - Seriously? Why? How does this benefit the community in _any_ way? This kind of behavior has no place in any professional community. If the original author reads this - please offer constructive comments on the issues you have with stack instead of spewing such vitriol.
When Tony made the original repo I rolled my eyes and thought "well of course". What's actually wrong with stack? It works well, the autocomplete and packaging works. I haven't managed to get myself into cabal/dependency hell with it. The template system is meh, the config files are a pain, but until I can get the same ease of use I'm not using cabal. Sure you can call nix a solution but I'm not up for writing nix Configs until the config language is neater, more intuitive, the parser gives errors that I can use to fix the problem without contacting a human and the usage grows. Haskell is already a pretty small community, the nix community is even smaller.
Mainly familiar with the basics of llvm-ir and the irbuilder. I have been playing around with making a toy language to learn the basics but, I would love to learn more. I would prefer to work on generating IR code (I think GHC uses C as IR before compiling that to llvm-ir) but, I would be happy to start whatever is needed. 
Oh, good thinking! [Output is still slightly borked](https://i.imgur.com/f65QOCf.png) but it doesn't crash with this.
I feel like in any open source community it's in Vogue to hate something that makes life easier but moves you further away from the dogma of open source. So I'd say nothing is wrong with stack except people are using it.
Here is a script which is used to create the PureScript license file: https://github.com/purescript/purescript/blob/f8ca834ebe3d8e5d484e5b55b5d1b8b6f0a783a2/license-generator/generate.hs
What was the last Cabal you used? I'm on 2.2 and it's \*dreamy\*. \`new-build\` is a game changer, along with \`cabal.project\`s.
Oh, yeah, and it looks like MoltenVK is 1.0, as well, so that might be just right!
We're building [FOSSA](https://fossa.io) to do just this. Haskell support isn't ready yet, but our main [CLI](https://github.com/fossas/fossa-cli) is open source. License and dependency analysis is actually a surprisingly non-trivial problem. I'm happy to elaborate if anybody is curious.
Do I still have to do all the sandbox management crap?
["Perhaps we should add in some environment variable fuzzing to make sure Stack doesn't pull any funny business to detect this script."](https://github.com/tonymorris/do-not-use-stack/pull/2#issuecomment-401943101)
No. There are no sandboxes with \`new-build\`. You just pull a repo you want or unpack a package and call \`new-build\`. Packages depended on don't go into a global db, but instead are installed into a "nix-like" \`store\` where they are identified by the hash of themselves, their dependencies, and everything's configuration flags. Each time you run \`new-build\` the solver figures out the dependencies fresh, and you can get reproducibility by pinning to a particular index-state. You also get multi-package project support via the optional \`cabal.project\` file, so you can build a suite of things together, vender deps when you desire, etc. It really "just works"\* \*with the exception that \`new-install\` isn't fully there, and \`new-sdist\` isn't there at all, when \`new-haddock\` fails it is more exceptional than it should be, etc. All these things are coming "real soon now" including via ongoing GSoC work.
GitHub's [`licensed`](https://github.com/github/licensed) can do this for you (and also supports many other languages).
I tried this out with nix on OSX. It failed with an error about not being able to find `ld`. I commented on the gist with details: https://gist.github.com/mpickering/fd26e9f03d6cb88cbb91b90b6019f3dd#gistcomment-2636273
You don't need MonadPlus; Alternative has `empty`. As far as I can tell the two classes are completely identical apart from naming and superclass.
Oh, you're right!
Yeah you can do really wild stuff. It's a lot of fun to play with!
I'm a little late to the thread, but here's a stack.yaml that can get stack users started playing with the new ghc alpha: https://gist.github.com/DanBurton/43b5f5155fdd1affd02f6e86f37da9ae
There is also was (is?) some weird "political" games from the company and some of the individuals which maintain stack, which has set off some alarm bells.
Pinning the universe of packages makes for a pretty nice workflow for application development: if you write proper bounds in your `.cabal` file, then when you bump your snapshot version it tells you what packages you should look at checking if they advance outside of your package's version bounds. That's only the tips of the dependency graph, and it doesn't look so good workflow for libraries. Instead, a library should know which versions of packages it can work with and maintain proper bounds. I moved off stack to cabal.project files and nix because: 1. I needed to use ghcjs 2. I got sick of rebuilding intero in every project
Give [haskell-mysql](http://hackage.haskell.org/package/mysql-haskell) a try, and [persistent-mysql-haskell](http://hackage.haskell.org/package/persistent-mysql-haskell) made by Naushadh too! Though on windows we still have no event driven I/O, which may affect the performance under high concurrenct connections, but please do give it a try, i'll try my best to fix your issues. Another thing is, my [libuv based I/O subsystem](https://github.com/haskell-stdio/stdio) is still under polishing, as soon as it's released i'll start to migrate my haskell-mysqsl package to use the new I/O subsystem, hopefully that will solve various issues on windows, such as non-interruptible FFI, etc. 
Why can't stack give you the same bounds/universe of packages approach (I though it called cabal under the hood)? 1. Makes sense, ghcjs is very nix based. 2. Why not have a global intero?
Sounds good then. Where do I go to learn the new workflow?
Any source on that?
Could you give more specifics about how the output is broken? If you get a chance, feel free to drop us a line in the issue tracker: [https://github.com/kwf/StrictCheck/issues/new](https://github.com/kwf/StrictCheck/issues/new). Thank you in advance!
We can't make it open source because the course material may be reused later. I can send you PM you some architectural details/answer questions if you're interested though.
It does, but each stackage snapshot specifies a GHC version and exact versions of a lot of packages. Re: 2\.: I don't know if the elisp side of intero allows that, but since I've moved my emacs over to using dante I've been happy with that.
Same as the normal `cabal` workflow, but with `new-`. For non-Nixified projects, I just `cabal new-build` and it goes to work. I used [`crew`](https://github.com/maxigit/crew/blob/master/README.org) for a while to rewrite the `new-` commands, too, but I think they’ll be the defaults soonish.
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [maxigit/crew/.../**README.org** (master → 3d959ba)](https://github.com/maxigit/crew/blob/3d959ba4e319b4f12457967ac221d8f9a4c0674d/README.org) ---- [^delete](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply e1p87ir.)
https://www.haskell.org/cabal/users-guide/nix-local-build-overview.html
The users guide elvish linked is good, and the old intro blogpost from '16 has a good quick-start http://blog.ezyang.com/2016/05/announcing-cabal-new-build-nix-style-local-builds/
`Alternative` and `MonadPlus` also have different laws. One derives from `Applicative` and another from `Monad`, in a very specific way. A good reference is the "From monoids to near-semirings: the essence of MonadPlus and Alternative", by Exequiel Rivas, Mauro Jaskelioff and Tom Schrijvers.
Ah, I didn’t even notice `empty`! Makes sense.
The problems with yaml are well documented at this point. Basically, there are lots of ambiguous (or surprising) parses that can lead to all manner of issues that don't show up right away or just do the wrong thing. The big thing that has bitten me every I've tried to use stack is the rebuild bugs. In a multi package setup, I routinely ran into an issue where I'd rebuild a package, trying to fix or implement whatever. Then I'd go back to trying to build something that depends on that package and my changes wouldn't exist. Like I could go into the first package and introduce an obvious syntax error. Rebuild the second package and it would not see the syntax error. The solution? Do a clean or `--force-dirty` and start over. I ended up wasting days due to fixing a bug and not having the fix show up or just waiting on the rebuild. It's one thing to get errors from your build system, but having it build something other than the current version of your source code is just evil. I have no idea what causes that bug in stack but it's as if it copies your source somewhere else and then builds that copy. And then maybe the logic for doing the copy doesn't always detect when changes have been made? At any rate, I just can't trust stack anymore.
Can anybody give an explanation of what this is and why it is funny (I am assuming it is), for someone who is not very well-informed (especially on the political front)? I know what cabal and stack are, but feel like I am missing something in this post.
I can give you my favourite two reasons: * It creates competition in a community that is too small for that. If the same effort was poured into Cabal instead! My idea is that it is not a fault of the Stack team per se, but a fault of communication between the Cabal team and some number of commercial Haskell users that made impossible for these two groups to cooperate. But overall, it is strategically unfortunate for Haskell that this division is not being bridged, and *that* is a fault of both sides. * Behind the nice interface, there is quite some complexity in Stack, a significant part of which is there to adapt to the particulars of Cabal. I do not believe a tool with such simple purpose should be so inwardly complex. The code of Stack is so convoluted, I have forgone the wish to contribute to it and now consider it an example of poor code architecture.
&gt;Why does the [original repo](https://github.com/tonymorris/do-not-use-stack) readme say `fuck stack` - Seriously? Why? How does this benefit the community in _any_ way? Humour. Your mileage may vary, but having some of it is a good thing, even if it sometimes isn't your cup of tea. Apart from that, not everything has to be measured by its benefit to the community. This could simply be some catharsis from a frustrated developer. Nothing wrong with that. &gt;This kind of behavior has no place in any professional-_ish_ community. If the original author reads this - please offer constructive comments on the issues you have with stack instead of spewing such vitriol. I think your standards for what counts as vitriol need some adjusting, if a simple 'fuck xxx' is enough to count.
The easy fix is to not use `error` :)
GHC uses Cmm (C--) to generate code for targets, I don't use this backend so I can't really comment on that. I suggest you just look at Trac and see if there's anything you want to work on and just jump in :) 
The first time I read I thought this was a typo, then I noticed that this is [an operator from lens](https://hackage.haskell.org/package/lens-4.16.1/docs/Control-Lens-Operators.html#v:-63--126-)! That is nice to know, thanks!
Not really, since this is mostly errors from postgresql-simple. It's certainly possible, but right now it's even less worth my time than investigating this.
You're not missing much, it's really just build tools we're talking about here.
[https://www.youtube.com/watch?v=CJQU22Ttpwc](https://www.youtube.com/watch?v=CJQU22Ttpwc)
Before you know they speak about killing hamsters.
In addition to the sibling comments another noteworthy resource is the 2nd part of the [Introduction to Cabal" Haskell-At-Work screencast episode](https://haskell-at-work.com/episodes/2018-05-13-introduction-to-cabal.html) introduces `cabal new-build`.
I usually write e.g. `round 1e7` to improve readability of large integers. Would be nice if one could use scientific notation for integers as well, such that `**a**e**b**` can be interpreted as an integer as long as `a` is an integer and `b` is positive.
Since last month or so intero only builds once per GHC version, it uses `stack build --copy-compiler-tool`, so you only compile a new intero per GHC version now.
Is this a common issue? I haven't seen stack not detect changes in a project, that's kind of its whole reason for existing. It doesn't copy your source anywhere. Any actual building is done by running `runghc Setup.hs configure &amp;&amp; runghc Setup.hs build &amp;&amp; ...` Was the file you edited listed in your .cabal file? That's how stack detects changes. If you had to clean/`--force-dirty` and then it rebuilt that module, it would have been as a dependency of a module that is listed in the cabal file.
There isn't a cache for OSX so it would build everything from source. It seems that failure is caused by https://github.com/NixOS/nixpkgs/pull/42247 which requires some further investigation.
Stack is just a different CLI for cabal as far as I can tell. The biggest advantage is it automated pinning your package set with the help of Stackage. For individual projects I think it’s a wash at the moment, but professionally I don’t see why you shouldn’t use Nix from a technology standpoint. And now that I do do that, I just use Nix for all my personal projects as well.
Does it support dependencies from github? I have to fork stuff now and then to fix some bugs in dependencies, and until they've made a release on Hackage I need to use a fork. Is that possible?
Here's the three most prominent (i.e. easiest to find by google) --- SLURP https://github.com/haskell/ecosystem-proposals/pull/4 --- The Haskell Platform saga https://github.com/haskell-infra/hl/pull/130 https://mail.haskell.org/pipermail/haskell-community/2015-September/000014.html --- The Haskell.org debacle https://www.reddit.com/r/haskell/comments/4zzmoa/haskellorg_and_the_evil_cabal/ https://github.com/snoyberg/snoyman.com-content/blob/a796432a685907c8017eb84c9062c20cf139367b/posts/haskell-org-evil-cabal.md
My concern is that Vulkan would not be available on older systems (unless there is an emulation layer?), so striving for uniformity on the Haskell side is pointless. Rather leave rendering details for the native part.
I do tutoring for fun sometimes. I like tutoring rather than teaching because it's interactive. I don't know what the best way to present an idea is until I have observed how you think. I will ask questions along the way and try to assess which parts of a metaphor you are using are helpful or not. As someone with the perspective of experience, I have the ability to *see how you think;* you can't see that, because you are stuck thinking that way. I also *love* helping people learn. It improves *my* life. If someone is nosing around for days (or years) in a book when they could have just asked me a question, they have missed an opportunity to make me happy. I love helping people learn enough that when I feel it is time for them to stop asking questions and go work through some concepts, I will tell them so, with no resentment or burden felt. It is of course completely valid to want to learn on your own. I'm a musician and have seldom had a teacher, even though I would probably improve faster if I did have one––I enjoy finding my own way. Nonetheless, it seems like you maybe had some hang-ups and misperceptions about asking for help, so I wanted to clear those up if I could. Welcome to the community!
&gt; Does it also support local dependencies? Yes, just point your cabal.project file at the individual cabal files and it Just Works (TM) &gt; Does it support dependencies from github? Not yet, but since local dependencies are absolutely trivial it's just a matter of keeping a local copy of the fork to use it.
Nice, glad it's getting better. Previous sandboxes were far from ideal to use.
Those are prime examples of how FP Complete's tireless efforts of contributing to the Haskell ecosystem are being misrepresented and actively obstructed by the haskell.org institution. And it's *still* going on as this more recent example of [ongoing misconduct](https://github.com/haskell-infra/hackage-trustees/issues/165#issuecomment-401698244) shows.
Uh, so actually, I just found out there is currently a PR for git (and presumably mercurial and subversion) dependencies scheduled for 2.4: https://github.com/haskell/cabal/pull/5351
And may I and only way to try out the awesome backpack as of now.
Why is this story still here? Mods, please kill it.
Sorry for the flippant response... Unfortunately I don't know of a real solution, but as a workaround could you create a `withServantException` combinator that catches all exceptions/errors and then converts them into a valid `throwError` call (so that your handlers would all take the form of something like `fooHandler = withServantException $ do ...`)?
Sure, "what if the same effort had been poured". But, for whatever reasons, we have stack and cabal now. Both work, in their own ways. People prefer one or the other. Personally, I'm very productive and happy with stack but I'm absolutely fed up with this recurrent debate; I find it sterile and childish.
I'm not sure that kind of tutorial exists, the switch from Haskell to C++ happen far more often than the switch from C++ to Haskell. From my point of view and in no more than 5 minutes: A few words of vocabulary: - in C++ generic programming is what we call parametric polymorphism in Haskell - There is no "generic programming" as in Haskell in C++. - A Functor in C++ is a class with an `operator()`, not at all related to the haskell Functor. A *few* points I thought about: - use `std::optional` (the C++17 `Maybe`) everywhere. It sucks because there is no builtin chaining, and usually people are using exceptions, but that's better than nothing. A lot of people are still using the `bool foo(T &amp;return_value)` pattern, that's fine too. (Well, no, it sucks, but `std::optional` is not really better in that matter, I think) - Try to use the new functions of the STL, such as `std::begin`, `std::end`, `std::size` instead of the member functions. - Use lambda everywhere. Just be aware of the liveness of what your lambda captures. In Haskell, you don't care, there is a garbage collector, in C++, everything captured by a lambda by copy is copied (so usually expensive), and everything captured by reference must live until the end of the life of the lambda. - Use `std::function` to wrap lambda and get something close to a true closure. Be careful about the previous point. - Have a look at the range library (https://github.com/ericniebler/range-v3). - Read all the documentation of `std::algorithm`, there are some really nice functions in it. You'll need to understand the "iterator" pattern. It is convoluted, but that's the C++ way of doing stream / "lazy" evaluation. - Have a look at C++20 concepts (https://en.cppreference.com/w/cpp/language/constraints), it kinda like typeclass. Be aware that C++ templates are checked when used, when Haskell `instances` - Use `std::variant` to create poor's man ADT. - C++ has a really strong support for type level programming in template, that's just totally unreadable, contrived and weird. Type phantom in C++ are usable, use them! - use (abuse!) `std::unique_ptr` and `std::shared_ptr`, it will give you a feel of memory safety. - abuse `auto`, that's the C++ limited way of doing type inference. It was greatly improved in C++14 and now even lambda case use it. Just be aware about how it behaves about references. For example, a foreach loop like `for(auto a : something)` will *copy* all items from your collection, you usually want `for(auto &amp;a : something)`. - Read about `std::move` and "r-value references". - C++ support default function argument and function argument overloading. Use your judgment, but I highly encourage you to use different function name as how it is done in Haskell. Be aware that default argument are part of the API and not the ABI. - `const` everywhere. But that's difficult. At least, but try to have `const` method on most of your object. - `constexpr` (compile time function evaluation) are great and can be used in type level programming for great things. I really miss `constexpr` when doing Haskell (this can be replaced by template haskell). - learn about the `template template` pattern, it is mandatory if you come from haskell and want some parametric polymorphism using highly kinded types. Last thing, do not try to write Haskell in C++. C++ is not Haskell. There are reasons you are writing C++ instead of Haskell (for me it was performance and environment), so try to be pragmatic. 
That's an excellent overview. 
Yea, nixpkgs is in a bad state right now. Some cross compilation changes were merged rather aggressively which has caused strain on many use cases.
That's really great news. This is currently the only stack feature that I miss when using cabal.
Thanks, I'll take a look!
I don't know of anything for Haskell devs specifically, or even functional programmers, but Stroustrup's "A Tour Of C++" is a good place to start as someone who already programmed in another language. It will give you a quick overview of the language. It's C++11 so you will have to learn C++14 and C++17 features later, but neither is as big of a change as C++11 was so that's not a problem. You can read it online for free: [https://isocpp.org/tour/](https://isocpp.org/tour/)
&gt; If the same effort was poured into Cabal instead! Likewise you could suggest that we should invest all effort into the tool that's most feature-complete and is integrated with tooling and infrastructure (stackage, intero, ...) instead of wasting effort trying to have half-finished newbuild cabal play catch-up with Stack. Just imagine how much better off we would be!
An honest question as I'm genuinely curious: Assuming that Cabal manages to catch up to Stack feature-wise, why would you want to use Cabal at all rather than standardize and simplify your workflow on Stack as the one stop tool? 
&gt; On macOS, Metal supports Intel HD and Iris Graphics from the HD 4000 series or newer, AMD GCN-based GPUs, and Nvidia Kepler-based GPUs or newer. It’s been supported at the OS level since El Capitan, IIRC, so as long as your computer is &lt;6 years old and your OS is up to date, it should be AOK.
I'm not sure I follow (I'm admittedly weak on rank-2 types); in what way does this break without the quantification ?
Wow - that is an amazing answer. Thank you so much for taking the time to write this up!
Done. 
**Thread locked.**
No worries. Something like that would work, or with less boilerplate it must be possible to do with `hoistServer`. Part of me is reluctant to fix it like that when I haven't tried to figure out what's causing it. But now that I say so explicitly, I think that part of me is probably wrong in this instance, and I should just go ahead.
&gt; recommendations for tooling like HLint/hdevtools, if such exist Not sure if it fits the bill, but try clang-tidy. Use valgrind and sanitizers to catch bugs.
[removed]
&gt; use std::optional (the C++17 Maybe) everywhere. I disagree. Monadic error handling is amazing, but it really leans on do notation (or at least a nice bind operator) for readability. In C++ you'll end up having to mix normal code with error handling if you don't use exceptions.
I agree with you. Actually I don't know what you disagree about ;). IMHU `std::optional` is better than the previous `bool` flag + reference return value approach, but not by a lot because it misses chaining (by default) and that chaining in C++ will sucks because there is no `do` notation.
&gt; Actually I don't know what you disagree about I disagreed that they should use `std::optional` everywhere. They should just use exceptions where needed and try and write total functions where possible (which bypasses the problem entirely).
Use -XNumDecimals 
Thank you! A lot of the clang tooling looks really good for the learning process. Yay competition :)
You may also want to check `clang-format` if you're a `stylish-haskell` user.
[This doesn't work by design](https://ghc.haskell.org/trac/ghc/ticket/14860). Quantified constraints are intended to be "local instances", and since there's no way to define a top-level `Num (F rep a)` instance, there's no hope for it working as a quantified constraint either. The way I've hacked around this problem in the past is to use a newtype around `F`, since they actually work within quantified constraints. Something like class (forall a. Num a =&gt; Num (Wrapped rep a)) =&gt; Test rep where It's unsightly, but I don't know how to do better. 
hmm, I can't really follow this discussion, but I think this will work. Thanks!
Thank you! One area I'm lacking is knowledge of the available libraries, and this looks like it will help a lot with that.
Yeah you should get familiar with most important parts of the standard library there, but there's more to it. I saw books dedicated to STL alone. And there are tons of third party libraries for C++ (and C which is mostly compatible) for anything you can think of. A go-to reference for the language and the standard library is [https://en.cppreference.com/](https://en.cppreference.com/w/) Probably the most used third party library (well, more like a collection of libraries) is Boost: [https://www.boost.org/](https://www.boost.org/) Which has tons of stuff from generic algorithms and containers, unit tests, template metaprogramming utilities to networking, math functions, concurrency, memory management etc. Big part of modern C++ is based on boost, it's useful to at least know what you can find in it, it may solve a lot of problems you have without reinventing the wheel. Then there's stuff like Qt often used for GUI programming but it also has a lot of it's own containers, smart pointers, stuff for handling audio/video, networking, databases... some even say it's like a separate version of C++. Of course whether you need to learn it depends on what you want to do with C++. Here's a list of other popular libraries: [https://en.cppreference.com/w/cpp/links/libs](https://en.cppreference.com/w/cpp/links/libs)
I use git + stow. How does this compare?
Check out [yadm (Yet Another Dotfiles Manager)](https://thelocehiliosan.github.io/yadm/).
I was looking at Conan as a Hackage-like collection of libraries - it is useful to have a somewhat-curated set of libs available in a searchable format. I used Qt in the past and really liked it, even though it was a world unto itself. The Qt Creator IDE was lush.
This. While I'm generally happy with the faster pace of GHC releases, there must still be releases that can be relied upon for long term stable releases of production software.
How about something like what /u/phadej is suggesting? Certain releases - say, one per year - are designated as LTS, and we make best efforts to backport fixes to those releases?
If you use stack, it's better to use VSCode with [Haskero](https://marketplace.visualstudio.com/items?itemName=Vans.haskero) plugin and install Intero for backend Most of Haskell IDE plugins use backend service. Only installing plugin is useless without it 
In addition to the great answers so far, it's worth reviewing the C++ Core Guidelines https://github.com/isocpp/CppCoreGuidelines
+10 for `const auto` everywhere possible. 
NumericUnderscores is for writing `123_456_789` and have it interpreted as if you didn't include the three `_`'s. If you want to go crazy, you could [use ICU](http://userguide.icu-project.org/formatparse/numbers) and support all kinds of notations, but that's a slippery slope I'd advise against *very strongly*.
Just out of curiosity, did you try Rust?, probably for something out of your control you need to use C++, but I think for a Haskell dev Rust should be easier to pick up and you have a few things very similar to Haskell.
100&amp;#37; agree on this. There are other ways but to start out with I think this is easiest. My go-to flow with this: 1. Install stack: `curl -sSL https://get.haskellstack.org/ | sh` 2. `stack new my-project` 3. `cd my-project` 4. `stack build` 5. `stack build intero` 6. open VSCode with Haskero installed, point it to my-project folder. 7. Test it out by removing some parentheses in Main.hs and saving -- it should show compile error in there. And while there's probably fancier ways to surf documentation, easiest is to just look at the hackage docs for whatever you want to use. 
I always install everything Haskell related through binaries and then update through Cabal.
Not sure. I looked at a few maintenance-only customers and saw at least as far back as 8.0.2 - putting it in range of versions /u/davidfeuer says must not be used. This is very bad. Fortunately, these sites do still seem to be working empirically. But there should be basic bugfix backporting. That is far from an unreasonably old compiler version.
Arch used to be the best platform for Haskell dev using native distro packages when /u/dons was actively supporting that, some years ago. Nowadays that's not true anymore, but it's no worse than any vanilla Linux distro. From the GHC web site, install the closest matching Linux binary tarball based on libc version, and you should be fine from there on.
It probably depends on what you are doing. For small projects you can use the repo packages for things that are available, cabal for everything else and then just link dynamically. Which means you have to occasionally recompile it. For something bigger or more fragile just use stack. The only downside I see with stack is having to compile almost everything.
a more excotic solution is to use the Nix package manager for your Haskell builds. See something like this ([http://www.kuznero.com/posts/nixos/haskell-project-structure-in-nixos.html](http://www.kuznero.com/posts/nixos/haskell-project-structure-in-nixos.html)) for instance :-)
Some people have good suggestions. But for a quick initial project like this, it might be easiest to do it the old-fashioned way: Write and edit your program in Atom. Also have open a terminal window in your project directory. Save in Atom, click over to the terminal window and type `stack build &amp;&amp; (command to run your program)`. Click back to the Atom window. Repeat until it works. Whichever way you go - come back to us if you need any help.
I can't seem to install SDL2 on windows with Stack. I've tried going through [this procedure](https://www.reddit.com/r/haskellgamedev/comments/4jpthu/windows_sdl2_is_now_almost_painless_via_stack/), but it fails on step 4. [The output looks like this.](https://hastebin.com/gisolucuro) I'd really like to be able to use SDL2. Does anybody know how to sort this?
Rust is absolutely fantastic, yes.
Why do you mean by "the code is not working"? How have you tried to run it?
Thanks kindly for this work. Both the pure MySQL client and libuv libraries are very compelling pieces.
That's right. It's less intimidating than it seems too. 
The answer by /u/guibou is terrific. One addition I’d make to answer part of your question is that `cquery` is a powerful bit of tooling. I use it with emacs, but it works in other editors, too.
If you're willing to pay, [haskell for mac](http://haskellformac.com) is excellent. It's a little constrained in terms of capabilities, but if you can work within those constraints it's very robust and easy to use.
If you have a modern enough installation of cabal, you don't need stack. You can simply use `cabal new-install hlint` for installing tooling or `cabal new-build` for projects. 
Ironically, Nix has been the most reliable way to install GHC on different distros for me. Things are way more likely to work the same across OSes with Nix
You can shorten the instance declaration to instance Monoid (User Maybe) where mempty = Rank2.pure empty mappend = Rank2.liftA2 (&lt;|&gt;) An additional benefit is that this instance continues to work as you add more fields. 
 (time world) is a value. I think what you want to say is tick :: State World () tick world = do world &lt;- get put (world { time = ((time world) + 1) } That is “give me the current state of the world, then put back a new state with time incremented by 1” or something like that.
Thanks! Yes, this works perfectly. Still need to understand exactly what's happening here, but at least I'm able to continue experimenting :) &gt; it's not clear whether "common data", "extra data", and "payload" all refer to &gt; the same thing or to different things "Extra data" and "Payload" was referring to the same thing. &gt; Are you saying that you want a datatype which holds both an Int and some &gt; existentially-quantified e Yes. Many different `e`s which shares some common data, the Int in this example.
1. How do I pass options to ghci (-fobject-code) launched from intero/haskell-mode? 1. How do get stack to link external libraries using --start-group --end-group?
I had no idea this existed. Thanks!
That is really nice! Thanks! Side questions, is there any reason for `rank2classes` to be attached to `grammatical-parsers`.
That is really nice! Thanks! For the reader, these instances should come from the `rank2classes` package. Side questions, is there any reason for `rank2classes` to be attached to `grammatical-parsers`?
&gt; https://obsproject.com/wiki/Understanding-The-Mixer When I reset the audio source at the beginning of the stream it looks like I accidentally cranked my mic volume up past the optimal range, and didn't notice because I had too many other spinning plates. That should be fixed for next time.
Thanks, I'm giving this process a try, and this is what I have Here's what I've done so far: 1. Installed VSCode for Mac from ([https://code.visualstudio.com/docs/?dv=osx](https://code.visualstudio.com/docs/?dv=osx)) 2. Installed Haskero for VSCode from ([https://marketplace.visualstudio.com/items?itemName=Vans.haskero](https://marketplace.visualstudio.com/items?itemName=Vans.haskero)) 1. Clicking the install link brought me into VSCode 2. Clicked Install on Haskero within VSCode 3. Ran this: $curl -sSL https://get.haskellstack.org/ | sh, but it was already installed. 4. Ran this: $stack new my-project (seemed to succeed) with this: &gt;`Selected resolver: lts-11.16` &gt; &gt;`Initialising configuration using resolver: lts-11.16` &gt; &gt;`Total number of user packages considered: 1` &gt; &gt;`Writing configuration to file: my-project/stack.yaml` &gt; &gt;`All done.` 5. after $cd my-project, I ran this: $stack build and got this (same as before): &gt;`Preparing to install GHC to an isolated location.` &gt; &gt;`This will not interfere with any system-level installation.` &gt; &gt;`Already downloaded.` &gt; &gt;`Configuring GHC ...` &gt; &gt;`Received ExitFailure 77 when running` &gt; &gt;`Raw command: /Users/&lt;username&gt;/.stack/programs/x86_64-osx/ghc-8.2.2.temp/ghc-8.2.2/configure --prefix=/Users/username/.stack/programs/x86_64-osx/ghc-8.2.2/` &gt; &gt;`Run from: /Users/&lt;username&gt;/.stack/programs/x86_64-osx/ghc-8.2.2.temp/ghc-8.2.2/` Where have I failed?
[removed]
Cool. Glad it was easy to diagnose. I will say from experience, that you should be using a compressor for voices. Pretty much always. The natural human voice range can be challenging for speakers and headsets. The compressor just makes sure to make quiet things louder and loud things quieter, thus forcing your voice in to a range that tends to sound better for the listener. It's also easy to setup. You right click the audio source in OBS and add a filter. Here are the details on what the different knobs and dials for the compressor do: https://github.com/obsproject/obs-studio/wiki/Filters-Guide#compressor 
&gt; True, RHEL should also be disregarded :). Our customers are almost exclusively on RHEL. In the days when Haskell was only a research language, disregarding RHEL would have been fine. Not anymore.
We happen to be using stack. Why is it not neutral to use a versions table that happens to be maintained by the HP team? And that was the most commonly used table since long before stack existed?
`tick` should not take `world` as a parameter (I'm guessing you copied OP's code to modify, and missed it). Alternatively, here's a solution without record syntax: tick :: State World () tick = do (World t w) &lt;- get put (World (t + 1) w) And one that uses record syntax and the `modify` function: incrementTime :: World -&gt; World incrementTime world = world { time = time world + 1 } tick :: State World () tick = modify incrementTime
Is there a Yesod scaffolding site using mysql-haskell?
I use the [stack-static](https://aur.archlinux.org/packages/stack-static/) package from the AUR, and then Stack manages GHC, it just works. There is also a `stack` package in the normal repositories, but some time ago Arch started shipping every single Hackage dependency as a separate package, so installing Stack that way (or GHC + Cabal for that matter) takes about half a gigabite of disk space, and it causes a lot of update churn (there are multiple releases per day of these packages, even if the upstream packages did not change for months). The `stack-static` package is only 60 megabytes and updates only when there is a new upstream release.
That is exactly what I meant. That's what I get for writing code on mobile.
 tick :: State World () tick = modify' bump where bump w = w { time = time w + 1 }
Is there any advantage to that over the standard way to [install stack](https://docs.haskellstack.org/en/stable/install_and_upgrade/) on any Linux distro?
Is there any way to takeWhile on a list of tuples? I have a list of tuples `[(x, y), (a, b), ..]`, where the second item of each tuple is actually a list itself, and I'm trying to takeWhile until the length of the second element of the tuples is greater than some number 'n'... Example: [(1,[1]),(3,[1,3]),(6,[1,2,3,6]),(10,[1,2,5,10]),(15,[1,3,5,15]),(21,[1,3,7,21]),(28,[1,2,4,7,14,28]),(36,[1,2,3,4,6,9,12,18,36]),(45,[1,3,5,9,15,45])]
I once read something somewhere about how a jazz musician could be driving whilst listening to music and all the while improvising along subconsciously. Later on in a practice session he comes out with some new lick or motif, seemingly out of nowhere but actually hes been practicing all the time hes been driving and its suddenly come to a head. This is definitely a thing in maths, and likely other technically demanding pursuits (like jazz); even though you're not aware of it your brain is still making sense of things behind the scenes. I do also think you have to have a great deal of "momentum" for this to work. You cant just study for an hour, leave it 7 years and expect to be brilliant!! 
I'm struggling to see the use of this tool honestly. You really just need a small shell script to "bootstrap" your dotfiles onto a fresh machine, which you invoke remotely with `curl`. I use Make to handle all the Stow commands and installation of Homebrew packages. This has the added disadvantage of needing to install Stack first. Haskell is pretty much the wrong tool for this job.
 Parenthesis are needed around `&lt;n` takeWhile ((&lt;n) . length . snd) 
Is there any reason we don't have an `{-# UNDECIDABLE #-}` pragma in the style of `INCOHERENT` and `OVERLAPPING`? There's been a few cases where I use types to help validate correctness in a very proof-like way, and I dislike having to mark whole modules instead of those specific instances. I already make sure to have comments for those instances which show why those reductions terminate, and loosing those extra errors for every instance in the module just bugs me. 
Thanks :)
Just the advantages of a package manager in general: you can update all of the software on your system with a single command. Also, there is a uniform way of installing and uninstalling packages, you can list all software installed on your system, automatically remove dependencies once they are no longer needed, etc.
To expand a bit on Seventh_Railgun's answer, this is because it's a partial application of an infix operator (aka "section") which you can [read more about here](https://wiki.haskell.org/Section_of_an_infix_operator).
If you will be using clang, lldb is freaking amazing: https://lldb.llvm.org/
Thanks! Makes sense.
Got it! Thank you for the link.
So I should be fine just installing from the binaries for both ghc and cabal-install
Oh yeah -- I wasn't aware of `hoistServer` but that definitely looks like the way to go. I'm not an expert so maybe someone more knowledgable can chime in but I think that's basically the "right" way to handle this. I also just came across [the servant-exceptions package](https://hackage.haskell.org/package/servant-exceptions) which appears to be attempting to solve the problem you're describing, though it looks like it requires you to enumerate the specific errors you want to handle rather than providing a "catch all" case. I'm not sure what the logic behind this is.
[removed]
[removed]
I’m a huge fan of this!
I find that for modern language where you are encouraged to install many 3rd part packages, using the system package manager for your dev environment is a bad time. Instead I use some language specific package manager and install my build dependencies to somewhere where they don't mess with systemwide things. For haskell there is stack as you mention, but good old cabal also supports this through sandboxes ([this](http://coldwa.st/e/blog/2013-08-20-Cabal-sandbox.html) was the first tutorial I found on Google, there might be better ones out there). Then ofcourse there is the issue of distributing a finished program if it is not only supposed to be run in some environment you control. I don't really have much experience with this. It seems like the problem of distributing software is a bit of a pain in the ass in general. I guess for haskell you would want to distribute a statically linked binary, rather than asking your users to somehow obtain the right version of 150 haskell packages or install a haskell development environment on their computer and learn to use it. 
I had the compressor set up, its just that one slider got cranked way up in OBS, when I was flailing around trying to figure out what wasn't working.
Well done! Have you though of adding a homebrew formula for mac?
I agree that Haskell support for Windows should be better, but you should really try using Linux as a development environment because it is a huge improvement over Windows
&gt; Haskero I tried `stack build` but got the following error: Error parsing targets: The specified targets matched no packages. Perhaps you need to run 'stack init'? Any advice? 
I recommend just using docker for your local development. Chances are you'll be deploying with it anyway and that way you won't be relying on the state of your machine.
For small Haskell programs, I sometimes use the Raskell app on my iPad Pro. Surprising nice if you are working through problems in a book (while reading said book), etc.
 g
For fun, I've been working on mirroring useful Haskell functions from Prelude and other libraries into C++17. It may help you to take a look at the library and see how I wrote some things. [https://gitlab.com/zerovectorspace/fct](https://gitlab.com/zerovectorspace/fct)
/u/ollir the comment you replied to seems to have been deleted. Do you remember what the best monad tutorial was?
The idea of `life-sync` is to achieve the following goals: 1. Make it hard to mess up. 2. Provide convenient and interactive interface. 3. Introduce as less overhead as possible. It was quite a challenge to achieve all those goals at the same time and I still see opportunities to improve. Another thing I noticed: I'm using mac on work and ubuntu as my home machine and configs are slightly different there. At first I wanted to have just a single command like `life sync` which automatically does everything for you, but then I realized that things are not that simple. So now I'm thinking about branch-based workflow for storing settings for different machines. You can have simple write-once only bash script to do dirty work for you. But if you want to make it user-friendly (in case you forgot how it works or something changed) you need to patch this script and I don't see bash-scripts easy maintainable in that sense. Also, it was an interesting experience of using libraries for type-safe file paths like [`path`](http://hackage.haskell.org/package/path) and [`path-io`](http://hackage.haskell.org/package/path-io). And ADTs really helped to handle all errors and different invalid states in a nice way. Also, this CLI tool is written in relatively easy Haskell and gives opportunities for beginners to contribute and learn new stuff if they want to. I didn't tell that `life-sync` is better than the other tools. But I personally like it and I'm using it and it already paid of for me :)
I think that happens when you try to run stack in a plain old directory. Did you make the directory with \`stack new project-name\`? I'd recommend doing this so it sets it up with some sane defaults. 
Shameless plug for my preferred setup https://gist.github.com/androidfred/a2bef54310c847f263343c529d32acd8 
Agreed! `cabal new-build` is the best thing ever. Cabal hell is gone.
The main issue in Arch is that the maintainers configured GHC to use dynamic libraries and that messes up everything, it a quite bizarre setup, very uncommon. The solution to this issueis simple, if you still want to use the GHC present in the repos, just build your own `cabal-install` with a stack. That's all. Once you have your own cabal-install, this one won't use dynamic linking and everything will work as expected. Also, remember that now cabal has `new-build` and such commands which are amazing. You can still use stack if you like it, but cabal now has improved radically :) I described the process here: https://wiki.archlinux.org/index.php/Haskell#Building_statically_linked_packages_with_Cabal_.28without_using_shared_libraries.29
I've been using a tool called [rcm](https://github.com/thoughtbot/rcm) that handles the alternative case quite well, if that's something you need. All it does is symlink it into a separate `host-&lt;name&gt;` directory and pull from there if needed.
There're a lot of differences between `life-sync` and `stow`: 1. `stow` uses symlinks approach while `life-sync` literally copies files. This is just a different approach. Can't say which one is strictly better. But copying files have opportunity to support Windows in some future. 2. `stow` manages only your file system. `life-sync` also performs `git` commands for you and it shows you diff before commit (and allows you to cancel commit) so you can verify your changes before committing but you don't need to do `git` commands. But, of course, `life-sync` shows you every `git` command it performs in terminal. 3. Before you start using `stow` you need to have the `dotfiles` repository. `life-sync` can create `dotfiles` repository directly on GitHub for you (using `hub` tool). Can be convenient for beginners. 4. Nice and pretty colourful messages! The task of managing `dotfiles` repository doesn't look too difficult. But documentation for `stow` is quite a read. I understand that `stow` does a lot but probably too much for my taste and for this task. `stow`'s specilization is not only managing the `dotfiles` repository. But if your goal is to manage `dotfiles` repository only, you can use a tool which goal is to make this exact process cleaner. Also, I see the following ways to improve `life-sync`: 1. Introduce branch-based workflow for managing different sets of settings. 2. Try to read global `.gitconfig` file to not ask github name. 3. Implement some interesting logic with `.gitignore` (without regexes) to help with filtering. Also, `stow` is written in Perl while `life-sync` is written in Haskell. I don't say that Haskell is better but `life-sync` uses type-safe path libraries and ADTs to make it less error-prone. Such tools are really hard to test and very easy to mess up with. Using Haskell features increase robustness of the tool.
Cool! It's really useful to know! I've created this issue with link to your comment: * https://github.com/kowainik/life-sync/issues/39
Nice project! I will take a look at it.
Jeez, there's so many tools for managing `dotfiles` repository... Though, this makes sense to me. They all are hard to discover and find. When I tried to google existing tools, I can only see other `dotfiles` repositories, not tools for managing those repositories. But it's good to be aware of other tools!
Avoid using pacman haskell packages. Download the hackage packages and haskell binaries (e.g. ghc) you need instead of using pacman. It works if you just use stack, which will help you download binaries and hackage packages.
Then you're looking for `rsync` honestly. I respect OP's vision and all the hard work that must have gone into making this tool, but I sincerely think this tool provides *more* overhead; either for managing configurations across multiple machines or installing dotfiles on a fresh machine. You're making Bash &amp; standard Unix tools out to be way more complicated than they really are. Managing multiple OS configs is as simple as ```bash if [[ "$(uname -s)" == "Darwin" ]]; then macOS configs here elif [[ "$(uname -s)" == "Linux" ]]; then Ubuntu configs here fi ``` It's just silly to shoehorn Haskell into an environment where the shell's native language is more than capable of handling installation and synchronization of environment configurations. Even the bare-bones POSIX sh can handle these tasks, while being 100% portable. Life-sync can't be installed without either Cabal or Stack. *That's* overhead. Especially for a user with a fresh OS.
Just to offer another angle on this, the reason this is invalid: time world &lt;- get Is that the left side of a binding statement (`&lt;-`) needs to be a *pattern*, but you’ve written what looks like a *function call* instead. It can actually be expressed in any of these ways: t &lt;- gets time t &lt;- fmap time get t &lt;- time &lt;$&gt; get world &lt;- get let t = time world World { time = t } &lt;- get That is, `gets` returns the state like `get`, but first applies a function to it (here, `time`) before returning it. `gets time` is equivalent to `fmap time get`, which takes a function (`time`) and an action (`get`) and applies the function to the result of the action. `(&lt;$&gt;)` is a commonly used infix operator version of `fmap`. In the last example, `World { time = t }` is a *pattern* that matches a `World` and extracts the `time` field, naming it `t`. Similarly, when you write: put (time world + 1) Supposing you created a variable `world` by writing `world &lt;- get`, `time world + 1` would still just be an `Int`. This won’t work because `put` expects a whole `World`, as you’re in `State World`. What you want is either this: world &lt;- get put (world { time = time world + 1 }) Or, because the combination of `get` and `put` is so common in `State`, use `modify :: (s -&gt; s) -&gt; State s ()`, here used at the type `(World -&gt; World) -&gt; State World ()`: modify (\ w -&gt; w { time = time w + 1 }) This may seem rather long-winded, and there are some more advanced tools (like lenses) that can help shorten this type of code, but you should stick to simple records while you’re learning the language. 
The only important advice is: Don't install _anything_ haskell-related via `pacman`. Some people suggest cabal, some suggest stack. I personally suggest the core haskell-platform "generic linux" installer which puts ghc, cabal and stack, all statically linked, on your system. But the main thing is just _steer clear_ entirely of the arch packages (because that way lies sadness), and then proceed with whatever your preferred setup would be otherwise.
Use containers.
I'm not familiar with Yesod scaffolding, but I'm pretty sure the persistent document provides a good start, just replace the sql driver with persistent-my-sql.
I used a tool named [mackup](https://github.com/lra/mackup) for dotfiles management, but actually I wish to forget about dotfiles. Because I am using Emacs, I will have to manage ~/.emacs.d anyway, but I don't want to maintain other dotfiles. Perhaps I will switch to NixOS and use [home-manager](https://github.com/rycee/home-manager). 
The packages are separate, they share only the Git repository. The historical reason is that rank2classes grew out of the work I did on grammatical-parsers. Also, the grammatical-parsers test suite throughly exercises rank2classes, so I tend to run the test suites together.
That shows just how much I know about GHC :) Anyway, thanks for the suggestion - I will start there.
It's not allowed at all without the extension. Specifically, you cannot have a universally quantified constraint without the extension (thus the name of the extension)
Hello haskellers! So I want to scrape som stuff using (scalpel)[https://hackage.haskell.org/package/scalpel] but also parse the scraped markup into a datastructure, accumulating all errors in the way of (validation)[https://hackage.haskell.org/package/validation-1]. I'm not sure how to get these to play nicely together, mainly because `Validation` isn't a monad and can't be stacked upon `Scraper`. Do you have any experience with using `Validation` in a similair way? Maybe a `WriterT Error` could be stacked upon and manually used to write errors? Cheers!
I wrote this tutorial about Haskell build tools: * https://kowainik.github.io/posts/2018-06-21-haskell-build-tools.html It doesn't touch IDE topic. But at least you will have an idea of what it looks like to work with packages.
&gt; Haskell takes the other side of the expression problem: We tend to create data types that are closed for extension. I wouldn't go that far, Haskell handles both sides of the expression problem quite well. Closed ADTs for extending functionality, and either typeclasses or records of functions for extending data.
Thanks for the in-depth explanation. This really helped alot! 
You are right, I exaggerated there.
How about this: instance (Alternative m , Rank2.Applicative r) =&gt; Monoid (r m) where mempty = Rank2.pure empty mappend = Rank2.liftA2 (&lt;|&gt;) Maybe that's what /u/guaraqe has been smelling nearby this whole time!
Definitely on the brief side, what is llvm-ng?
Sure, that's be great. I'm mostly interested in how you converted to the target (x86 or other).
GHC comes with an `llvm` backend, that produces textual IR, which is in turn fed into llvm's llc to produce assembly, which is then mangled and turned into object files. `llvm-ng` is an alternative llvm backend for GHC, that produces binary IR instead. Both backends take of from the Cmm phase, and are similar, but not identical. One of the features of the `llvm-ng` backend is, that it allows to properly `-dead_strip` for iOS. The current `llvm` backend in GHC essentially streams the textual IR into a file. Whereas the `llvm-ng` backend builds up a representation of an LLVM module and then serializes that into a file.
What about `haskell-ide-engine`, sometime ago I heard that the aim is to make this the defacto LSP server?
Congrats angerman!
Thanks for your reply. I've tried using composition, but I've hit a wall when trying to create "relationships" between objects, because relationships are heterogeneous (eg authors may be NaturalPerson, LegalPerson, or *both*). I'm playing with the solution of having a massive Something sum type like `data Something = SomeEntity Entity | SomeDocument Document | SomeArticle Article | ...`, so a relationship could be, from Haskell PoV, to `Something`, leaving the code do the work of enforcing relationships between valid types at runtime.
By closed, you mean not designed to be extended by a consumer of the library, right? In an ideal world, the hierarchy would be user-configurable, but this automatically means I can't use Haskell ADTs at all, so let's say for now it's closed. Thanks for the pointer to generic-lens, I'll look into it!
Thanks, do you happen to have a link to your work?
Yeah. HIE is great. However it is still in development stage (unstable). It also takes more efforts to setup. I just suggest much simpler way to do. IMO, most of Haskell IDEs are useless if you use advanced structures, e.g multiple targets project, Nix... or upgrade new GHC version. Low level GHCi front-end such as Dante still be the better choice
Well, if you have a `Person`, you can't do stuff that's specific to a `NaturalPerson` or a `LegalPerson`. I'm not sure how an author can be both of those, or how you'd express that in an OO language.
&gt; I'm not sure how an author can be both of those They can be *any* of those. &gt; how you'd express that in an OO language. pure virtual class, I guess. Again, thanks for your help. I'm implementing a minimal version of (1) and (2) right now to see which feels the most natural. 
Probably not allowed inside the secure corporate network. We would need to check. And even if so, Haskell will soon cease to be viewed as a viable option for real applications if the *only* way you can use it is by deploying in a container with certain characteristics.
Not an answer to your question. But this might be interesting to you: * https://github.com/ghc-proposals/ghc-proposals/pull/114 `{-# UNDECIDABLE #-}` pragma is also discussed there in comments.
That's great for feature software. For a fundamental developer tool like stack or cabal, it's often better to have full manual control.
Yes. For cabal-install there are less choices of libc version for the binaries. If you can't find one that matches, you can install it using the `bootstrap.sh` script described in the [README](https://hackage.haskell.org/package/cabal-install#readme). If you want to use stack, there is an install script on the [stack website](https://docs.haskellstack.org).
Yes, that is what I meant. Consumers of the library would not be able to add more cases to an ADT, but they could add as many operations to the existing types as they need.
Is there any "reasonable" reason as to why \`Functor\` is in \`Data\` (i.e. \`Data.Functor\`) while \`Applicative\` and \`Monad\` is in \`Control\`? 
The reason I'm using C++ is because it is one of the approved languages at my company. Rust does look gorgeous, though: I'd love to give it a proper test-drive sometime.
/u/formulab, this might be a question best asked under the pinned Hask Anything thread. But I will unhide it. 
Okay, so we were targeting x86_64. So the code structure was - we had an abstract assembly and a x86_64 assembly. The only difference is that abstract assembly had infinite registers. So we had a `data family` for registers parameterized by an abstract type. This family with instances for abstract asm, concrete x86_64 asm, and one for quasiquoted asm. Everything else builds on top of these registers, with ordinary data types/GADTs. Each instruction had its own data type with some variants for separate op codes. All these get glued together into one "Instr" data type. After doing instruction selection on the IR (the quasiquoter is very helpful here to write readable stuff, as well as for testing), we do register allocation (have a look at GHC's code!) on the abstract assembly and have a very small conversion pass which converts abstract assembly to concrete, which we just print out. Pro-tip: Writing the pretty-printing by hand for all instructions would've been tedious, so we gave the constructors good names and used `generics-eot` to derive all of it for us with a relatively small amount of boilerplate.
I use \[this simple\]([https://news.ycombinator.com/item?id=11071754](https://news.ycombinator.com/item?id=11071754)) \`alias\` to \`git\`, which just works.
- `stack build`: compile the project and place any executables in a project-local `.stack-work/` directory. That executable can be run with `stack exec -- &lt;exe-name&gt;` - `stack install` compile the project and place any executables in `~/.local/bin/`, which in theory is in your PATH so you can run it anywhere.
All you need to do is curl -sSL https://get.haskellstack.org/ | sh 
&gt; skip the GHC install. Stack installs its own local copies of GHC. That ought to be the default setting of the Haskell Platform installer given Stack is what's best for most newcomers.
&gt; Cabal hell is gone. Have you tried Stack? With Stack I never experienced this "Cabal hell" thing cabal users seem to suffer from.
That's the thing, I started using stack because I was tired of dealing with dependency hell. But now with `cabal new-build` it's completely solved. I personally prefer cabal, but I value that stack brings good value and stackage is very useful, but I feel like cabal is a tool closer to the tooling that Haskell provides.
A little correction: stack install places executables to `local-bin-path` which is configurable in global/user stack config and by default is `~/.local/bin` on *nix-likes and i don't remember what in Windows. You can check current setting by running `stack path --local-bin`.
I should have mentioned I did steps 1-3, but it failed on step 4. I spent a while troubleshooting, and I realized I had an old version of stack. I updated, and it worked fine! 
I think the main problem isn't that it's not a monad, the problem is that neither is a transformer, so you can't stack them together. Can you give some code that illustrates the problem you have and I might be able to help you more.
my life totally changed since i stopped using \`stack install\` command in (almost) all cases. instead i use \`stack build\` with \`--copy-compiler-tool\` option which builds given thing and copies executable under corresponding directory for given ghc version. \`ghc-mod\`, \`hasktags\`, \`ghcid\`, \`haskell-ide-engine\` etc. for all these build with copy compiler tool option. only and only case i need to use \`stack install\` is, if i need only the built binary on PATH. other than that, for any development tool, right choice is always build with copy compiler tool. reference article: [https://lexi-lambda.github.io/blog/2018/02/10/an-opinionated-guide-to-haskell-in-2018/](https://lexi-lambda.github.io/blog/2018/02/10/an-opinionated-guide-to-haskell-in-2018/)
Depends what you mean with resonable. The most common interpretation of functor usage is modifying data, while applicative functors are usually interpreted as preforming some kind of action in a control structure/dsl. Because of laziness, most structures can be interpreted both as data and as control structures, e.g. lists are either containers of data or for example a backtracking monad. This means that the choice of such classification is mostly up to arbitrary choice. 
In the early days of Rust, developers are encouraged to use `.and_then()` which is the same as `&gt;&gt;=` in Haskell. To me bind as a method is completely readable.
Do you mean that it’s not idiomatic rust any more? 
Is there an idiomatic way for "storing" previous calculations? I'm calculating the factors of a list of numbers, but, as 'n' gets large, the algorithm slows down heavily. I essentially want to 'store' the previous results of the factors, so that when factoring a large number, if I run into a number I've already calculated the factors for, it will just concatenate those factors into the list of factors.
I didn't say you had to use just a container. You can also use Nix or a non-obsolete platform. (Look, I get that some places require RHEL, but you can always just use an old GHC.)
Laziness actually turns out to be a great way to accomplish this. You should read up on "dynamic programming" in Haskell. [Here's one pretty good article on it](http://jelv.is/blog/Lazy-Dynamic-Programming/).
Rust has created a syntax sugar for it.
There's some sort of sound symbolism thing going on for me where by brain 'wants' the A summands to be red and the B summands to be blue, flipped from what they are in the paper. It made for quite a few double takes while reading. I'm curious if any one else experienced the same thing.
I don’t get the int example- it doesn’t even compile unless you have Num [a]. 
Haskero should show compile errors from VSCode (let us know if it's not doing that). I don't think you should expect to "run" it from there. You probably still want to run your program with `stack exec` or `stack build` and running the executable directly. But that's not the best way to test minute to minute changes -- what I normally do is set up an "integrated terminal" in VSCode, run `stack ghci` there, and use that repl as a test bed for my changes. I.e. catch compile errors with Haskero, and sanity test the actual functions I just wrote with actual inputs in the repl. FYI if you're using stack you won't have to build cabal files at all, since stack will generate them for you. Re: needing more than a single-file - you can arrange your code in many files (modules) and import as you please. Re: where source files are kept - for small projects, I usually just use a web browser / liberal googling for hackage pages to search through "imported libraries". This is obviously not the BEST way...something like the method described in the `Accessing Local Documentation` section of https://lexi-lambda.github.io/blog/2018/02/10/an-opinionated-guide-to-haskell-in-2018/ would probably be better. That whole article is really good, especially to get a high-level beginner footing, and describes some of what I've mentioned in more detail...if you're still struggling you might want to give the first part of it a read. 
These are common sorts of requirements in enterprise companies. It's not *on them*. It's *on us*. We must demonstrate that we are using stable, reliable tooling to build their software - i.e. tooling that is *supported with bugfixes*. It's that if we don't even try to do that, Haskell is an unsuitable language for use at any reasonably large company. I don't think we want that; at least I hope not. In short - we need to support RHEL, and we need to endeavor to provide bugfixes for some reasonably acceptable amount of time, like any other serious platform.
I've used Ubuntu a reasonable amount. The problem is it's still a somewhat unfamiliar environment. It also requires keeping a Windows installation for gaming purposes.
I think the `Data` vs `Control` distinction is an anachronism from the early days of Haskell and newer libraries should just drop those prefixes
This is perfect! Thank you.
It is all explained in the linked page. But I agree that what is actually going on doesn't make much sense without more context. I guess the point just is to show that you can define things in ways which seem circular.
Everyone else stopped having this stupid argument two years ago, please get with the program.
I'm trying to find a series of blog posts that solved a programming challenge using monoids, polynomials, and automatic differentiation in Haskell. I read it a while ago, but I can't seem to find it now. 
If you want then you should be able to try Home Manager out even If you are using macOS or GNU/Linux distros other than NixOS. There are some limitations, though, especially with macOS. For example, the HM user services won't work. But program configuration in general should work fine.
Don't use `State` for memoization, or at least don't make it a habit. It's much better to directly tie the knot on the memoization result. In this particular case the input is a list of characters, the output would be a list of ASTs, and this refactoring gives you the Packrat algorithm. 
I think https://github.com/RichiH/vcsh is the state of the art for simple git based dotfiles sync
you might have done an un-Eli5 here
So if I want to use hlint for development I should just use the stack build with '--copy-compiler-tool' option instead of using 'stack install' ?
Thank you
Stack Question What's the best way to uninstall a specific package and the numerous other packages that came with it created by "stack install" ?? 
I was going to suggest green
&gt; I understand that stow does a lot but probably too much for my taste and for this task. Fortunately the most basic use of `stow` does what you want from a dotfiles manager. This how I set up my dotfiles on a new machine: cd ~ https://github.com/barrucadu/dotfiles.git cd dotfiles stow emacs git zsh
I once used (or tried to use) vcsh. I abandoned it in favour of mackup (I am lazy, so I wanted to minimise manual configuration). A recommended way to use vcsh is with myrepos. It was a good solution when I was using vim, but I stopped using it since I switched to Emacs. 
I am a long time user of Arch Linux. I tried to install NixOS, but it wasn't as easy as it seemed. The live media was awesome, but installation required a lot of manual steps, so I gave up. It seems that I need to take Nix Pills first. Then I will try HM, and install NixOS. Thanks for your advice. 
nuke `$HOME/.stack` or your project-specific `.stack-work`
The ghc distributed with the platform links against `libtinfo.so.5` and apparently your system doesn't have it. Depending on the details of your distro, you might be able to install the compat package for this, or use the advice in https://forums.opensuse.org/showthread.php/446927-missing-library-libtinfo-so-5 or https://github.com/Valloric/YouCompleteMe/issues/778 
yeah, same https://en.m.wikipedia.org/wiki/Grapheme-color_synesthesia red A, blue B, yellow C, green D is common. 
Here's something that will *just work* and get you up and running with Haskell in no time: curl -sSL https://get.haskellstack.org/ | sh
iiuc, /u/rycee is saying that home-manager works on Archlinux, via nix (the package manager), it doesn't need NixOS (the operating system).
You keep snipping short bits of my messages and responding only to those bits. For example, why exactly would a "enterprise company" object to deploying AppImage-bundled executables?
weirdly enough when i look in my lib folder i have libtinfo.so.5 present in there
The bouncing back and forth until you get into the desired image is reminiscent of geometry of interaction, which also utilizes the algebra of partial injections which in the abstract is the theory of inverse semigroups. When I heard of such a gadget I thought it must be exceptionally marginal being two adjectives removed from a first class mathematical concept, but they're extraordinarily important! 
I know. Before I use home-manager, I have to get used to Nix expressions. 
idk how antergos works but i understand it is arch based? if it shares the same aur, maybe https://aur.archlinux.org/packages/ncurses5-compat-libs/ could help?
I don't think so. There's lots of evidence for [newcomers struggling with the Haskell Platform and whey ditch it and install Stack things start working magically](https://www.reddit.com/r/haskell/comments/5quf5y/learn_purescript_or_haskell_first/dd5fvba/).
There is a paper by Doyle and (reluctantly) Conway on the related problem of dividing by three: given a bijection between three copies of A and three copies of B, can you produce a bijection between A and B? Although the constructions are concrete, the computational content of the Doyle and Conway paper is really murky, even though they explicitly avoid the axiom of choice. It is nice that the computational content of subtraction is so pleasant by comparison! https://arxiv.org/abs/math/0605779
`stack install` simply performs `stack build` and copies the resulting executable(s) to a specific directory; I don't recall what the default is. If you just don't want that executable to be on your PATH anymore, simply delete it, or remove the directory from your PATH entirely. `stack build` doesn't leave build artifacts anywhere that some unsuspecting tool will stumble upon them and get confused; leaving them has no downsides apart from taking up space on your filesystem. Thus, you don't need to delete them, unless you need to free up space. In that case your best recourse is to delete `~/.stack` or `/path/to/your/project/.stack-work`. Obviously this will delete more than just the offending build artifacts; those directories are where stack stores build artifacts, but also package DBs and sources. Stack will download those when needed, but that's slower than having them on disk already. Amusingly enough (at least with my configuration, which I believe is the default on Windows) deleting those directories won't remove the finished binaries. A final note: stack doesn't keep track of installed packages, which is why there's no uninstall command and also why there's no "collect garbage" command.
Thanks /u/spirosboosalis, that's indeed what I meant.
You can run `stack path` to see all the paths it cares about, and the value for `local-bin` is where it will install executables.
Your hastebin link seems to be broken; all I'm seeing is a blank paste. Since I can only guess at the error you're having, I'm not sure if this'll be helpful, but: - In order to build my project, I installed SDL2 via the `stack exec -- pacman ...` method you linked. - However, to *run* my game, I simply downloaded the relevant binaries from libsdl.org, placed them in a folder alongside my excutable, and ran from there. - I wrote a small wrapper script which runs `stack build` and then `cp $(stack exec which my-game-here) dist/` to make that process less painful.
My suggestion would be to familiarize yourself with the Nix expression language and Nix package manager in the safety of a distro you already know well. I used Nix purely as a package manager under Debian for probably a year before I actually put NixOS on a day to day computer and in retrospective I'm happy I did.
Correct.
Thanks :) 
Yesod calls a function called `initLibrary` when using the regular mysql library. The function is documented [here](http://hackage.haskell.org/package/mysql-0.1.5/docs/Database-MySQL-Base.html#v:initLibrary). The `initThread` and `endThread` functions found just below in the documentation are also used. I couldn't see any obvious equivalents in mysql-haskell so I presume no such functions are needed and as such these lines can be removed?
 data Tree f a = Leaf a | Tree (f (Tree f a)) type RoseTree = Tree [] data Pair a = Pair a a type BinaryTree = Tree Pair
IIRC, they also wanted to deal with countably infinite sets.
I've got things working now, thanks! For anyone who finds this thread in the future, I'm going to link to [this](https://github.com/naushadh/persistent/issues/2) issue on Git which was helpful in getting things to work.
Bought a book. Thanks for the post!
Shill for stack if you'd like, but *please* dont advocate running scripts blindly off the internet :)
With arch being a rolling release and the AUR having very recent packages, it's much less of an issue than it would be for other distros. I'd totally trust stack static to "do the right thing" (Fwiw I tend to just do the manual binary because the static package wasn't out when I had to wipe my Haskell install last)
Yes, thanks. That's what I meant. Nix Pills is a tutorial on Nix, and I had considered reading it. I will adopt Nix in the following order: 1. Learn Nix 2. Try out HM on Arch 3. Switch to NixOS
You're right, that's an important difference. Doyle and Conway prove that you can "divide by three" no matter what the cardinality of A and B are. I think this paper can be generalized a bit, too. I might be missing something, but it seems like you get a bijection A &lt;-&gt; A' from (A + B) &lt;-&gt; (A + B') and B &lt;-&gt; B' whenever B is finite, no matter the cardinality of A.
For initial baby steps, you don't need to know much about cabal. You will not be modifying the cabal file at all. After a few days you might want to use a package. In that case, its just a matter of adding one line containing the name of the package to the appropriate section of the cabal file. My advice would be to not get sidetracked by tooling/IDE etc initially. While a good editor setup definitely helps your productivity, it is less important in the initial learning curve. Haskell is very different from other programming languages; it would be a good idea to focus on the language itself.
&gt; We say that two partial functions `f, g: A →Maybe B` are *compatible*, written `f || g`, if they agree at all points where both are defined, that is, for all `a: A` and `b: B`, `f a = Just b` if and only if `g a = Just b` Am I missing something or do the informal gloss and the more formal statement disagree? f 0 = Just 1 f 1 = Just 2 f _ = Nothing g 1 = Just 2 g 2 = Just 3 g _ = Nothing agree at all points where *both* are defined, i.e., at 1; they don't agree at each point where each is defined, e.g., at 2.
1. Every new language you learn teaches you something 2. The things you learn will make you a better programmer in _every_ language 3. The further the language is from your comfort zone, the more likely the things you learn will be things you wouldn't have learned otherwise There are two possible outcomes from learning Haskell. Either you'll really like it and want to stick around, or you'll decide it's not for you, and go back to C (or wherever it is your programming journey takes you next) with nothing to show for it beyond a better understanding of the techniques and mathematical underpinnings of functional programming, the applications of a comprehensive type system, and the circumstances where laziness, immutability and isolating side-effects can improve your code.
&gt;Convince me to learn Haskell No. 
&gt; when asking about how to improve my code, the conversation inevitably directs to functional programming. I've had several different people tell me to learn Haskell for various reasons. GHC is the best tool available for functional programming. But if they’re suggesting it as a means of improving your C code I doubt they know what they’re talking about. Functional (immutable) programming is quite sophisticated and it can’t be trivially carried over to imperative/object-oriented languages. 
Haskell taught me to mathematically reason about my code and how it works. Soon after learning Haskell I ended up writing a python algorithm from scratch and I understood how it worked at a mathematical level. I was able to write that function a *lot* better than before I had learned Haskell.
From a C background, Haskell apparoaches programming problems in a very different way. Aside from the broadening your experience reason, some specific valuable things to learn from haskell are: * how to be strict about function input/output types * How to work with pure functions (functions that have no effect except for giving a return value). This is useful for any language. * Related, how to analyse program flow based on the type system. * how recursion works. This is a powerful, general of looping a program and can sometimes be more general than normal looping. Ultimately, Haskell is not some super programming language above any others. It it is different from most common languages and I got a lot of value out of the different style. You can probably pick up languages like python and java pretty quickly because they have the same basic style as C. Haskell (and lisp) require a different approach.
For me the main reason to adopt Haskell was that it's so \*different\* from every mainstream language. It's fundamental weirdness (in particular, laziness and restricted effects) makes it a valuable tool to have in your toolbox because some problems that are hard to solve the C/C++/Java/Python way are easy to solve the Haskell way. 
I think this is what the author calls abstraction. You define a new type that's higher in the abstraction hierarchy. Instead they want 'analogies' where you can take a concrete binary tree type and construct a rose tree type by describing the differences.
Functional programming is a fundamentally different way of solving problems than imperative programming or object oriented programming. You have to learn to think about the problems differently. When you're comfortable in the functional paradigm as well as the OOP paradigm or imperative paradigm, you now have options for how you want to implement a given algorithm. Those options all come with pros and cons, so it's good to be able to weigh them. (Maybe one particular version is most performant/maintainable/easiest to get right/etc.) But those are options *you don't know you have* unless you take the time to learn the other paradigms. Aside from being a functional language, Haskell also has some other interesting features that can be useful to learn: * Laziness (mimicked by Java' streams, Rust's iterators) * Very strict and expressive type system It's useful to learn how to use each of these to their full potential, even if you mostly work in other languages, because you'll learn techniques for optimizing performance (be lazy - don't do more than you need to do) and for ensuring your program will do the right thing (are the types specific enough to exclude bad behavior? Do they line up?)
He wanted to replace pair with a list as a way to say I have this thing and I want something similar. My point here was abstraction can do that just factor out the similarity and it becomes a precise reusable building block that describes all the similar kinds of recursive tree things. It can be thought of having a Tree f a and then “replacing” f.
He wanted to replace pair with a list as a way to say I have this thing and I want something similar. My point here was abstraction can do that just factor out the similarity and it becomes a precise reusable building block that describes all the similar kinds of recursive tree things. It can be thought of having a Tree f a and then “replacing” f.
&gt; I have some Haskell code to rewrite into C++ and would like to bring as many of the idioms with me as possible. That is usually a mistake. I once saw someone from a Java back ground trying to do OO heavy Ocaml and ending up with really bad Ocaml code. 
Why not? The alternative is to download and run the `stack` binary blindly of the internet, which seems no safer.
The compiler will do more of your work for you than in any other language.
The general wisdom I've heard about this issue is that people trust their package managers to have safe software. Plus you can be given a malicious link without realizing it; i.e. https://get.haskellstack.io. I'm not sure whether I agree with the logic, but it's not insane to trust your package manager to have a lower chance of malware.
I understand what you mean (and I probably agree with you), but I think the article was more philosophical in nature. The reason why abstraction works for us is because we managed to formalize it and explain it to the compiler. It doesn't require much effort to imagine a future language/compiler that's smart enough to understand what we mean by a certain analogy and to do stuff properly. It doesn't matter if it's imprecise, that's a different issue that has different solutions.
Something slightly similar to this is deriving via no?
I also recommend deleting `~/.stack` directory periodically. After working on projects with different snapshots, the size of this directory becomes bigger and bigger and this directory accumulates older versions of libraries you might never use.
`stack install` is literally an alias for `stack build --copy-bins`. Similar to how `stack test` is an alias for `stack build --test`, bench, etc.
Intero for Emacs installs with `--copy-compiler-tool` too now. 
I'm not too familiar with arch, but it appears that stack is somewhat broken on arch, because I keep [getting reports](https://github.com/lamdu/lamdu/issues/51) that its provided GHCs are crashing on my sources there, whereas nix's GHCs work fine there.
Perhaps. Not really. It's still a much lower level concept than what I think we're talking about here but it's a move in that direction.
Like [ornaments](https://pages.lip6.fr/Pierre-Evariste.Dagand/stuffs/journal-2013-catorn-jfp/paper.pdf)?
If you have a few minutes to spare: https://youtu.be/wn-xW3g8jXY "Code generation with llvm-hs by Stephen Diehl" -- ZuriHac 2018 keynote. 
I wonder if stack could / should have a GC roots system like Nix does.
i wrote [a book for this exact goal](https://libeako.github.io/c/ID_1371518733.html) in short : haskell is the most efficient learning space for good software engineering, which will make you many times more efficient in your coding work and also make coding fun again 
You can define your functions in an internal module, then reexport the public ones from an interface module: module Foo.Internal(privateFunction, publicFunction) where privateFunction = ... publicFunction = ... module Foo(publicFunction) where import Foo.Internal You can then test the internal module. This shouldn't effect optimisation.
You could use histomorphisms I think
Thanks, great idea.
I support this idea with `.Internal` module naming. In addition I want to say that there should be no `other-modules` in `cabal` file in `library` stanza. There's always a possibility that package users might need your internal modules. So there's no reason to forbid importing those modules. Though, it's harder with private function. Recently I needed private function from public module. Maybe it's actually a good idea to reexport every function and data type from your package but under different namespace (for example, `Internal`)? :thinking:
I have used arch with `pacman` and though I had issues until I understood that it was using dynamic linking I would say it does have it's place. My computer is OLD and if I try to compile most of the libraries it just fails. Using system packages I was able to do stuff without a problem. Then I could just clean up the cabal config and compile on more powerful computers without a problem. But yes, if you have the machine for it I would just go with ghc+cabal.
I agree that this is the best way to do this. However, it does affect optimization. GHC is very keen on inlining unexported functions. In particular, if the function is only called in one place, GHC will inline it (always?). If you export the function, you don't know how many other places you'll need it, so you have to have generated code for the internal function.
I haven't seen this before but, with a quick glance, I can't see how it relates.
Spotting that the result is a palindrome and so you can always extend on the right is quite clever. All this talk of partial bijections, etc. makes me want to turn some of my current ramblings on inverse semigroups and inverse categories into a package though.
So you can engage in these conversations from an informed standpoint.
I usually use the shortcut of exporting, but placing the exported function under a haddock section called "for testing". Its a little crude, but seems less noisy than the internal module pattern, especially if you are implementing an application instead of a library 
Good point - I should have said "benefits" rather than "idioms". I understand that some (but not all) idioms should translate because of the recent developments in the C++ world, and was looking for clarity on where the sweet spot lay.
I was somewhat amused by the section on computer-aided synethesia. Many IRC clients do this, by hashing names and associating them stably to colors.
I have seen some people use a CPP macro to export them only when built as part of the test suite. You would then include all modules in the test suite in Cabal (rather than depending on the library), and would compile stuff twice, but OTOH it would not affect the final library.
Thanks, I thought there was some Haskell-theoretic reason behind that as well. :)
Lol self post
[This](https://stackoverflow.com/a/3209189/52310) SO answer and the [MemoTrie](http://hackage.haskell.org/package/MemoTrie) package spring to mind.
It's a Wiki. It only works *because* it's so easy to edit someone else's work. 😉
Funnily enough, the arch maintainers' odd haskell packaging decisions are what finally pushed me over to Nixos/Nix. 
Because programming in Haskell is really fun.
That's a good point. Another reason for the `.cabal` file to be a more accessible data format that can be easily processed by tooling. For example, being able to strip `*.Internal.*` from exported functions when not testing.
I strongly suspect that Haskell can be learned more easily if you learn it from a person in real life and that most of us don't have someone in real life we can learn it from. I have been trying to learn Haskell in my spare time for several years. I finished LYAH after a few attempts, then did FP101x (Eric Meijer) and learned things from that, including reading most of the first edition of Graham Hutton's book. I bought the Allen &amp; Moronuki book. It is well worth the money. I agree that it is not a perfect book but I have definitely learned a considerable amount. I forced myself to try the exercises until I got about 3/4 of the way through. I often found I could not do them from what the book had taught me (or from what I had retained from reading chapters several times). I would like to get a good handle on monad transformers just because a lot of libraries do seem to use these. That is the part I'm on currently. At that point I will probably stop reading the book. My current frustration with Haskell is that I understand type signatures perfectly well but cannot hold these in my mind as well as I would like when composing types or working out how types compose together. I was always happy manipulating symbols through algebra in maths. I find this a lot tougher. The inarguable power of type signatures in Haskell is no good to me if I cannot mentally manipulate them. I also see expressions buried in the middle of code and struggle to see the types of these expressions. It must eventually come with practice but it does seem to take a lot of practice. At a certain point perhaps some of us will never be able to do this mental juggling so the full power of the language will not be available. For an example of type signatures which are hard to mentally work with, I recently puzzled myself about how join can be written in terms of bind. This answer is a model of clarity but at this point after several years of Haskell I would still not 'see' how these types can be combined without a lot of effort. https://stackoverflow.com/questions/34398239/with-monads-can-join-be-defined-in-terms-of-bind/34398340#34398340
How can I undo the effects of `stack install`, since I've been using it for a long time now.
As someone who has been primarily a C/Python programmer I'm actually writing Haskell in my day job as my primary language. It hasn't been easy. Haskell asked me to basically throw away my 15 years of experience and told me that I don't know as much about programming as I thought I had. Sticking with it regardless has been worth the effort. One of the interesting distinctions I didn't notice right away until I became comfortable with Haskell is that Haskell doesn't require you to be a great programmer. The philosophy of C, if I may be so bold, is _trust the programmer_. I used to get good feelings about that: the language does exactly what I want it to do with the machine. Haskell ruined that for me. It turns out writing C programs for any definition of correctness is _really_ hard. Instead of helping the programmer to write correct programs the philosophy of C only lends you a metaphorical branch and tells you get _get gud_. Working with Haskell is a much different experience. To work on large Haskell projects I don't have to be a Haskell expert. I don't have to memorize all the different ways that Haskell programs introduce undefined behavior into my programs. I also don't have to completely understand how my program _should_ be structured. I can write the first awful thing that comes to mind and Haskell's tooling will guide me to the right program. I find developing Haskell programs to be more interactive like a conversation. I make some declarations, express some propositions, the type checker verifies my assumptions and I get an informal proof. That's super-useful on large projects. However I haven't had to write performance-critical code in Haskell yet. As I understand it the practice is cognitively more difficult to reason about than in C... but not required very often for many, many applications. I don't imagine writing a AAA game engine is going to be easier or better than it is now in C; but could it be done in Haskell? _Maybe_. So if your goal is to write _working_ software _faster_, I'd say go with Haskell. Working here means: - Maintainable: code I write today will be readily understood a year, two years from now. - Documented: The documentation will not be out of date with the code over time - Verifiable: is amenable to verification without expensive tooling and highly specialized teams
Maybe a silly question, but why would you want to test your internal functions? Assuming you are talking about some form of unit testing.. It is my experience (granted, not with Haskell, but with Java and C#), that writing tests for the internal plumbing of your module only hinders future development. You want to test the outward facing functionality, so you can modify the underlying code, safe in the knowledge that - as long as no tests fail - you did not break the functionality of your module. 
I'm going to have to disagree with that assessment. While it's true that the final result of the fold cannot be returned until after those elements are traversed. The folding itself is absolutely happening right as the primes are generated and you do not need to generate all 2000000 primes before the first addition is performed. So in other words it is not unreasonable to assume that it will run in constant memory given that the prime generation is done in a sufficiently streamable fashion (e.g reading them all in from a file via lazy IO or checking each prime with all possible factors one by one with no caching) For proof: primes = go 0 where go x = x : trace (show x ++ " traversed") (go $ x + 1) foldl' (\a x -&gt; trace (show x + " folded") (a + x)) $ takeWhile (&lt; 1000) primes Gives: 0 traversed 0 folded 1 traversed 1 folded ...
Isn't that because you used `foldl'`, which is exactly what I said would happen?
It seems like dependently typed language such as Agda, Coq and Idris all have proof assisting abilities. 1. Is having a proof assistant a requirement for dependent type, if so, why? 2. Dependent types will eventually comes to Haskell. Is there any plan on adding a proof assistant to Haskell too? 3. If so, will it be able to achieve as much as Coq?
If you could structure your scrapping in an "applicative" way (so no value is chosen or rejected to be scraped depending on the resulting value of a previous scrape) perhaps you could compose `Scraper` and `Validation` using [`Data.Functor.Compose`](http://hackage.haskell.org/package/base-4.11.1.0/docs/Data-Functor-Compose.html). The composition of two monads isn't always a monad, but the composition of two Functors/Applicatives is always a Functor/Applicative. Furthermore, when the outer functor (that would be `Scraper` in our case) is an `Alternative`, the composition is `Alternative` as well. At least, that's what the instance says: (Alternative f, Applicative g) =&gt; Alternative (Compose f g) 
The less granular your tests are the more hunting you need to do when one breaks.
Ah dammit my phone messed up your comments formatting of ' and ` and the like.
Hadn't seen the 'Probability 5 Ways' article before and enjoyed it. The comonad version is equivalent to `newtype Prob a = Prob (NonEmpty (Rational, a)`, right?
I agree that when problems get huge, Haskell programs still have a lot of problems. And I'm sure you could find ways to improve on that. But I don't think there's a magic "other way" that removes the deep emergent complexity. The requirements for any huge piece of software are complex. Nothing can make the expression of the solution simpler than the solution itself. Whatever the sociological cause, real-world software is expected to have hundreds or thousands of special cases. It's just the way the requirements always end up. And there's no way to make the code simpler than the business logic it implements.
Come, join us, don't be afraid. You had yuor C programming fun and you are pardoned for it. Time to get serious
Testing internal functions is a great way to identify problems, however. 
As of recently, cabal has support for internal libraries. This is used in (for instance) the [htoml-megaparsec](http://hackage.haskell.org/package/htoml-megaparsec) library. You can create an internal library that exports things for use in the test suite, and a public library which depends on the internal library. 
As others point out, I used to have "dll-hell" or cabal hell (breaking reinstalls whenever I was installing a package) all the time back when I was using pacman to install things. Then I built ghc from source, including cabal, and never had issues again. Then the nix-style builds became a thing, and things are even smoother now. I use stack sparingly, as I'm not terribly familiar with it, but it is quite useful when using fpcomplete-related stuff, e.g. yesod. Using a stack-managed ghc quickly leads to big disk space usage, btw. 
*I'm spamming a little here, sorry -- I like your answer (and rather dislike OOP)...* OOP is not tied to neither any particular strategy of expressing (or not expressing?) the control flow (ie "imperative" aka "procedural" vs "functional" aka "denotational" vs "purely declaratively" aka "figure it out, HAL"), nor to decisions of allowing (or disallowing) mutations. For example OCaml is mostly regarded as functional (rich type system, immutable data, higher order functions, and General Coolness), but is (also) an Object Oriented language. My point is: when you say "imperative" you already include languages like C++ or Java, where "the OO part" is mostly about arrangement of state and organization of procedures -- descriptions of "step-by-step" ways of mutating some data from inputs to outputs (and the remaining part is about reusing them via inheritance and polymorphism). And last thing, did you notice that stuff like haskell's `do` notation, or (more generally) any functional code written in CPS *is* procedural, disregarding the standard interpretation/philosophy of the host language? And even worse, any dirty trick like `call/cc` is procedural as well, and it does express mutation (!) of the call stack. I hope the world is less polarized now ;)
&gt;Nothing can make the expression of a solution simpler than the solution itself This is true of the entirety of a given solution, but misses the point of the article and the reality of the experience of the modrn software developer. Where, exactly, one draws the lines to make a given solution parametric over some conditions is currently more art than science. Different ecosystems provide different tools and paradigms to facilitate what the community, committee, and/or developer believes is the clever set of mores to follow, but I don't think anyone so far has been arrogant enough to claim this as a solved problem. I think it's ambitious to say that we could have a scientifically backed method of choosing how to compartmentalize code, but nothing in my experience or my understanding of human history would lead me to claim it was impossible, and I don't think it's a stretch to claim that such an effort would do well to borrow from advances made in studying human language and behaviors. CompSci borrows a ton from those fields already to great success, I see no reason whatsoever to believe that trend won't continue.
Depends on what type of application you're looking for: 1. Simple CLI tool. 2. Server web-client. 3. Application with GUI and all that fun with stateful widgets. 4. Sophisticated cryptocurrency. 5. Compiler of some language. 6. Tooling for Haskell programming language. I assume all these types of applications have different architectures and implementation approaches. Regarding simple game: this is 2048 in terminal implemented in Haskell using library called `brick` * https://github.com/8Gitbrix/2048Haskell
Dependent types pretty much imply theorem proving capability. For example, any function `myProp :: Int -&gt; Bool` can be converted to a type which is inhabited if and only if it `myProp` is `True` everywhere: -- A dependent function type as a theorem. myProp_valid :: pi (x :: Int). if myProp x then () else Void It would not be possible to define `myProp_valid` if there were some `x` where `myProp` is `False`, since the corresponding output type would have to be `Void`. The catch is that in Haskell every type is inhabited, because we can write infinite loops and throw exceptions in any type. The planned design of dependent types is not going to change that. So we can actually define `myProp_valid` even if `myProp` can be `False`. myProp_valid = myProp_valid Thus a Haskell "theorem" gives much weaker guarantees than a theorem in a total language like Coq, but it will still significantly increase the confidence we can have in the correctness of many programs.
I think [xmonad](https://github.com/xmonad/xmonad) is a common answer to questions like this.
I wrote [firefly](https://github.com/ChrisPenner/Firefly/blob/master/README.md) precisely for this purpose; it's a small (but real) web server wrapper which should demonstrate some simple monads (Reader, Either) and simple typeclasses too! For this reason it's also quite well documented as far as haskell libs go. Let me know what you think!
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [ChrisPenner/Firefly/.../**README.md** (master → b1776e1)](https://github.com/ChrisPenner/Firefly/blob/b1776e1cca8e614ee276a0e45e8224a7b411e114/README.md) ---- 
Since you mentioned simple games written in Haskell I thought I would recommend Graham Hutton's book: Programming in Haskell, the second edition was released a couple of years ago. The code for the examples used in the book is freely available on his [website](http://www.cs.nott.ac.uk/~pszgmh/pih.html) although I recommend purchasing the book to get the full explanations. If you're willing to spend a bit of money on learning Haskell then it's well worth it.
Thanks! The type itself is very close to what you describe (there’s one fewer `Rational` in the version in the post). In terms of the instances and so on, I haven’t figured out how to properly decompose it—although I *think* NonEmptyT (in the vein of ListT done right) would get you close.
Sure, I know "imperative" and "object oriented" aren't mutually exclusive, and I guess the same can be said about functional and object oriented (though I don't know OCaml). I was mostly just listing off adjectives/ways of characterizing languages, especially as contrasts to Haskell. And yes, I am aware that do notation is syntactic sugar that lets purely functional code be written as if the host language is procedural. :)
&gt; I've had several different people tell me to learn Haskell for various reasons Did those people not do a good enough job convincing you? If not, why not? Have a similar number of people, or more, told you to learn some other programming language? Why are you asking our community this question, instead of some other community regarding their language of choice? Aren't you curious to see for yourself why people talk so much about Haskell? C is a remarkable language. It strikes a unique balance between low level instructions and high level coding. Learning Haskell is less about the low level and more about empowering your abstraction capabilities. (Although if you want to deep dive into Haskell compiler details regarding laziness and optimizations, there's plenty of fascinating low level stuff there.) I would strongly recommend that curious individuals learnin both C and Haskell; it seems you've already dabbled in the former.
\[Aura\]([https://github.com/aurapm/aura](https://github.com/aurapm/aura)) is a mid-sized CLI tool for Arch Linux.
[https://github.com/dmjio/miso](https://github.com/dmjio/miso) for building single-page web applications. * **Tetris**: [https://flatris.haskell-miso.org/](https://flatris.haskell-miso.org/) / [https://github.com/ptigwe/hs-flatris/](https://github.com/ptigwe/hs-flatris/) * **2048**: [http://2048.haskell-miso.org/](http://2048.haskell-miso.org/) / [https://github.com/ptigwe/hs2048/](https://github.com/ptigwe/hs2048/) * **TodoMVC**: [https://todo-mvc.haskell-miso.org/](https://todo-mvc.haskell-miso.org/) / [https://github.com/dmjio/miso/blob/master/examples/todo-mvc/Main.hs](https://github.com/dmjio/miso/blob/master/examples/todo-mvc/Main.hs)
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [dmjio/miso/.../**Main.hs** (master → 9378329)](https://github.com/dmjio/miso/blob/93783297bd79685b7a471bc565bcdc801c270b02/examples/todo-mvc/Main.hs) ---- 
Do you have some specific suggestions? I am curious. By the way, I think there are functions in the Cabal library that can give you access to `.cabal` format.
Log a bug?
I am not sure why. Did you read it? I looked at the code once and I could not say it, per se, had stricken me as something special. I heard somewhere that some key parts of the code were proven in Coq or something, but it would not be apparent from the code itself. I would appreciate if you can give that reason.
I would say it's the combination of: - Tackling a clearly defined problem that is large enough to be more than a toy example while being small enough for a casual reader to understand - The code being well written and idiomatic 
Pandoc (take any of their parsers) demonstrates monadic parsing with parsec quite nicely. 
One of my favorite trees is data BalancedBinaryTree a = BBLeaf a | BBBranch (BalancedBinaryTree (a,a)) and if we monkey a bit with the definition of `Tree`, we can use it to define `BalancedBinaryTree` too: data Tree f a = Leaf a | Branch (f (Tree f) a) type RoseTree = Tree (Compose []) type BinaryTree = Tree (Compose Pair) -- type BalancedBinaryTree = Tree (`Compose` Pair) newtype Flip (f :: a -&gt; b -&gt; c -&gt; *) (bb :: b) (aa :: a) (cc :: c) = Flip { runFlip :: f aa bb cc } type BalancedBinaryTree = Tree (Flip Compose Pair)
I have a few projects like that, they are not well documented by they are simple and short: - [JSON EDSL](https://gist.github.com/soupi/c7c94a45d006bc70f3b896f327ea47a3) - [hen](https://github.com/soupi/hen) - a very simple static blog generator - [imgs](https://github.com/soupi/imgs) - a minimalistic web image browser - [status](https://gitlab.com/gilmi/status) - the client runs a linux program and sends the result to the server. the server displays the latest result from each client in a web page and colors it: green for success, red for failure, orange when too much time passes since the last message.
It seems that your comment contains 1 or more links that are hard to tap for mobile users. I will extend those so they're easier for our sausage fingers to click! [Here is link number 1](https://github.com/soupi/hen) - Previous text "hen" ---- ^Please ^PM ^/u/eganwall ^with ^issues ^or ^feedback! ^| ^[Delete](https://reddit.com/message/compose/?to=FatFingerHelperBot&amp;subject=delete&amp;message=delete%20e1vmx6i) 
Getting Stack via your package manager is bad advice as you likely get ancient versions of Stack which can't cope yet with that intentionally broken-for-Stack `cassava` package.
I'm a c# developer so far. I developed my first haskell program and I found a better way to do something in my code. I would like to make a promise that when I refacator my code it will working well. It's unit testing in c# and I think in the every programming languges this is the right way. In c# you can define a function with private, public, and internal rights and the internal is enough good for testing. That's all, the refactor is the cause :) 
&gt; I use stack sparingly, as I'm not terribly familiar with it, but it is quite useful when using fpcomplete-related stuff, e.g. yesod. In other words, Stack supports installing *more* packages as it works perfectly with fpcomplete *and* non-fpcomplete packages whereas cabal doesn't work well with fpcomplete related packages. Wouldn't it make sense for you to become more familiar with Stack so you don't have to switch between Stack and cabal and just stick with the tool that works better for everything?
Please wait before you upload packages using internal libraries to Hackage until there's a release of Stack until there's a Stack release that incorporates [full support for internal libraries](https://github.com/commercialhaskell/stack/pull/4111). One would hope Hackage wouldn't accept such bleeding edge features until the ecosystem fully supports them.
Since a lot of people seem to agree with this simple reaction, there must be a common collective reason/princile/sentiment behind it. Anyone want to elaborate?
Getting stack via your package manager then using stack to upgrade itself is still probably a better idea than copying random scripts off random reddit comments.
Fugacious by Jasper v.d.J. is exactly for this purpose: a "boring" web app that demonstrates a number of useful patterns and libraries. https://github.com/jaspervdj/fugacious
That's not a better idea because thanks to Hackage's faulty design choices Stack was forced to protect itself against package mutation on Hackage but had to sacrifice `stack upgrade`... # stack upgrade Fetched package index. Populated index cache. stack-1.7.1: download Could not parse '/tmp/stack-upgrade9179/stack-1.7.1/stack.yaml': AesonException "failed to parse field 'extra-deps': (Invalid package identifier: \"rio-0.1.1.0@rev:0\",\"rio-0.1.1.0@rev:0\")" See https://github.com/commercialhaskell/stack/blob/release/doc/yaml_configuration.md. 
I just published `v0.0.7` and it reuses a single GHCi session for all code files for 'package workspaces' (those with `stack.yaml` and/or `my-blah-package.cabal`). Apparently I did not realize how time consuming pre-`stack repl` building was :)
It's really not my responsibility to support stack. At all. 
Wow, if you do the wrong thing it's easier! Amazing revelation. 
Yes, also see [Edward Kmett - Encapsulation vs. Code Reuse]([http://youtu.be/yFXzuCFeRGM?t=1h34m55s](https://www.youtube.com/watch?v=yFXzuCFeRGM)
The proof of Doyle and Conway is not constructive though (it is more natural than using the axiom of choice, though). Recently it has been shown that even "dividing by two" cannot be done constructively (On dividing by two in constructive mathematics, Andrew W Swan, 2018).
Sure, JavaScript is something of a mess but that doesn't mean we can't learn from it's tooling. Npm's Package.json is much easier to use than Haskell stack's stack.yaml and cabal files, cabal files on their own and nix files. We could even just use Haskell for our config and we'd be in a better place.
The lens library makes this more conveniently with curTime &lt;- getting time modifying time (+1) But that's something that should be learned separately. 
It's a bit meta and probably too large but ghc's code has consistently high code quality with great comments. It has a chapter in 'The Architecture of Open Source Applications' for a reason.
If you want to use some more realistic graphs, you can look at [SNAP, the Stanford Network Analysis Project](http://snap.stanford.edu/data/index.html). But this is unlikely to change the outcome. Surprisingly, none of these libraries use a representation `Map v [(v,e)]` or `Map (Map v e)`, which is something that I often use for ad-hoc graphs. Fgl is similar, but much more complicated.
May I offer a different perspective to what seems to be the consensus here. In my experience, using archlinux for development, even for production, is fine in general. Of course, you need to know what you are doing and what are the trade offs between being on the bleeding edge and stability, sysadmin work. While it is unfortunate that arch does not include static libraries into its haskell packages any more, one can works this around while enjoying the abundance of haskell related packages available, currently well over 600. It is nice to have access quickly to the most recent ghc and packages through the packaging system without bothering with compiling them and keeping them compatible with each other. Admittedly, there have been haskell related stability problems on arch in the past but I think they have been ironed out for now. On my desktop system I have about 300 haskell packages including xmonad, pandoc etc. They work fine (most of the time :-). Here is the outline of my current method, all packages are arch ones, mainly from community. * install ghc, cabal-install * install ghc-static (static core libraries) * install ghc-pristine from AUR, "Symlinks to GHC with only boot libs, useful for building static binaries". It is worth to read the source and learn how it is done. * install whatever haskell programs you want to use, like xmonad etc. * install/remove whatever haskell packages you want to play in ghci or experiment with. * I use cabal new-\* operations, they work great. Cabal has recently made really significant progress. * During development if I can I try to link dynamically when the packages I need available from arch. * For deployment build static, for example: &gt;cabal new-configure -w /usr/share/ghc-pristine/bin/ghc --allow-newer &gt; &gt;cabal new-build ... etc. Cabal's new-\* operations work like a small haskelized nix system, so one can fix a current package resolution and rebuild reliably without recompiling everything etc. * The big secret is frequent updates! I do it daily, it takes just a few seconds. I tried but eventually don't use stack for various reasons. I am now happy with cabal new-\*. Also in general, I don't really like to download random binaries from the net. I know, I am using them in arch packages, but that is about my limit and they are signed. For more, some time confusing, details see the arch wiki haskell related pages. If you like to see some missing haskell packages included let the arch maintainers know.
Asked a million times before.
I heard this story about a jazz musician too. I share your vision.
I agree and disagree at the same time :D Haskell from First Principles, although it has some problems is a book that is very well written FMPOV. The book is verbose, using a simple vocabulary and is very easy to read. I'm happy to read it, along some other references of course.
Ahhhh, gotcha – you're a moron. To clarify: I refrain from editing not because it is hard, but because I think there's little value in me imposing my personal tastes on someone else's writing. 
For me it's the fact that there shouldn't be some imperative to convince OP to use Haskell, or anyone for that matter. There's plenty of material on features and benefits of Haskell. If one is curious then they should just give it a go, learn the language, and possibly fall in love with its benefits like the rest of us. If they have more specific questions then about Haskell then I'm sure people will have useful answers. 
Your own library also have internal structure. For a 'inner' module, it's outwards-facing side could very well still be internal to the library
I shy away from, and here would like to discourage, the implications that other languages such as C is a some sort of sin and inferior to another. Frankly, there are extremely few options for low level language that give the fine grained control that is necessary in many contexts. Several Haskell programmers I work with rather like C and the fusion of C (sometimes even rust or LLVM) into Haskell packages has brought some significant benefits. Let's avoid creating an "us vs them" confrontational atmosphere.
I don't have specific quesions, but something like: - Decompose it more, so if some part of it was fully extensible by writing code, then it doesn't mean other parts couldn't be analyzed statically. - A lot of fields contain sets - maybe support ways of modifying sets that still makes it possible to statically know, say the maximum and minimum sets can can possibly come out of a transformation. The conditional parts of a `.cabal` file could possibly be exposed like this to make it easier to run static analysis. - Use a language-agnostic format since part of the benefit of static analysis would be to be able to do that analysis from within a different language/framework. 
I'm based in Melbourne and a regular haskell user. Our haskell uptake at $dayjob is small (primary languages are c#, python and js), but we have a haskell application that certainly forms a critical part of our operations. This application is deployed in remote locations, taking sensor data and turning that into important operational information for decision making purposes. (Could that be any less specific? - I could be more specific in a proper talk) Is an experience based on this report a useful presentation for this conference? Key parts of the experience report would be that developer uptake has been limited (though speaking at events like this may change that)..., windows is a second class citizen (although getting much better quickly - particularly with WSL (especially when coupled with nix)) and that tooling can be below (and above once they get the hang of it) developers expectations. Positive parts would likely include awesome refactoring ability, general overall reliability (once deployed, can go months without new/bugfix releases) and the existence of this component of our product at all (previous attempts at similar products in other languages (primarily python) have died a horrible death - mainly due to testing overload even with small changes). So is it worth me submitting an RFP? Obvious answer is yes, but is this the sort of presentation this conference is looking for?
I would urge you to try [Concur](https://github.com/ajnsit/concur) (which I wrote). It's designed to be extremely easy to use, and I would be happy to help out people getting started with it!
I’m currently writing a JSON library (for my own personal amusement/experience, not planning on releasing it) and one piece of functionality I want is serialization/ deserialization (transform json into a Haskell data type and vice versa). My deserializer looks like this: newtype DeserializerT m a = DT {runD :: JSON -&gt; m a} Which is just a specialized version of the parser monad we all know and love. What I’m not so sure on is the serializer, which I imagine would look something like this: newtype SerializerT m a = ST { runS :: a -&gt; m JSON } This is obviously not actually a monad, since it’s not even a Functor (though it is contravariant). What other instances might this have? Is there a paper or article on this type of structure? I don’t think it’s a comonad, but I could be wrong on that. 
There is no best solution. If you ask different people what to use, almost everyone will give you opinions varying in some degree. I wrote a blog post comparing the big three Haskell web frameworks. http://softwaresimply.blogspot.com/2012/04/hopefully-fair-and-useful-comparison-of.html It's quite old now, but still a pretty accurate characterization of those three frameworks. There have been a few new developments since then. Here are the ones that I think are most worth mentioning: [Scotty](http://hackage.haskell.org/package/scotty) is a web framework focused on simplicity that is built on top of the [warp](http://hackage.haskell.org/package/warp) web server. I (being one of the authors of Snap) would say that it's a similar level of complexity to using the Snap's lower-level interface defined in [snap-core](http://hackage.haskell.org/package/snap-core). [Servant](http://hackage.haskell.org/package/servant) is a library for representing REST APIs at the type level. It allows you to specify your API once and then generate a variety of useful things from that with a little extra code. If you supply the backend handlers, it will give you a web backend (running on warp). It can also generate API docs, Javascript client functions, Reflex FRP client functions, etc. If you want to build rich interactive web frontends, there are a few projects that have been created for doing that over the last 2-4 years. GHCJS is a compiler from Haskell to Javascript which lets you use Haskell for frontend development. There are two main projects that I'm aware of that sit on top of GHCJS and make it easier to build rich frontend apps: Reflex and Miso. I personally use Reflex. It was released a little over three years ago and is being used in production at several good size Haskell companies, is quite actively developed, and can also generate Android and iPhone apps. I don't know much about Miso other than that it came out a year ago and tries to mimic the architecture used by Elm. People in this subreddit also tend to have a fair amount of interest in Purescript. Purescript is a Haskell-like language designed specifically to be compiled to Javascript. Since it's a brand new language and not constrained by backwards compatibility concerns, it was able to fix a number of Haskell's warts. I might reach for Purescript if I was building something where the size of the generated Javascript was very important such as a mobile app. However, I tend to default to using Haskell on the frontend because having the same language, libraries, and tools in both places is going to be lower cost (hence the existence of Node.js). I'm sure there are plenty of other libraries and frameworks out there now that I'm not aware of. These are just a few of the most established projects that I'm aware of.
thanks :)
I've just bumped into this behaviour today. I moved the module from the internal library to the library and the performance changed. I also checked the generated core and it was different from the one that this module has while it was it the internal library, it has more complex structure. So I don't know what is the right way to keep the same performance but to have this module exported, probably you can give me some advice?
Cool results! It would be also nice to describe what other users should do to test their graph libraries against this bench-suite if they want to experiment with their implementations of graph libraries.
It uses a lot of immutable functional data structures well. 
http://github.com/lorepub/moot/ is in progress but will be developing quickly over the next ~6 months. https://github.com/bitemyapp/bloodhound is a reasonable example of writing a client for an external API, IMO. Similarly: http://github.com/alexeyzab/ballast I have more stuff kicking around on my GitHub.
That's true. It *is* constructive for finite sets at least (though they point out that you can just write down a constructive proof that finite sets obey the rules of arithmetic and use it to transport the proof of 3x = 3y =&gt; x = y)
http://hackage.haskell.org/package/contravariant-1.5/docs/Data-Functor-Contravariant-Divisible.html
usually I just create a typeclass for serializing class MySerialization a where a -&gt; MySerializationType I'm not sure about this, but maybe you can use some sort of "building pattern" to serialize your data, then you could have a comonad like described in this blog post http://www.haskellforall.com/2013/02/you-could-have-invented-comonads.html 
This may be relevant to your interests (supposedly there is a Haskell implementation somewhere): http://www.informatik.uni-marburg.de/~rendel/unparse/
Interesting. SerializerT m appears to be Divisible if m is Alternative. 
You probably don't even need that. `Op (Ap m JSON)` is isomorphic to `SerializerT`. You're basically just lifting a monoid into an applicative pointwise, and you don't need anything more than that to be Divisible/Decidable.
The error message here is actually pretty good. Let's walk through it. 1) Couldn't match type ‘a0 -&gt; String’ with ‘[Char]’ Expected type: String Actual type: a0 -&gt; String Alright, so where it's expecting a String (or [Char], same thing), it's finding a function that takes something (a0) and returns a String. 2) Probable cause: ‘(.)’ is applied to too few arguments In the expression: unwords . map show . compareAtZero xs ys So reading that function we see that we are actually composing a function when we want to be applying it. Instead of solve s = unwords . map show . compareAtZero xs ys We want solve s = unwords . map show $ compareAtZero xs ys
&gt; Specifically, I can't figure out why I can't store the partially applied function into `solve s` which partially-applied function? `compareAtZero xs ys` looks fully-applied to me.
Thank you for walking through that, clear as day now. Thanks!
Thanks for the source of realistic graphs, it looks great ! I might add one or two to compare results with more sparse/dense graphs than the one I actually use. &gt; Surprisingly, none of these libraries use a representation Map v [(v,e)] or Map (Map v e) One of the implementation of algebraic graphs is based on `Map a (Set a)`: https://github.com/snowleopard/alga/blob/master/src/Algebra/Graph/AdjacencyMap/Internal.hs#L88 But yes, maybe a simpler representation is the key to efficiency :)
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [snowleopard/alga/.../**Internal.hs#L88** (master → 7c58514)](https://github.com/snowleopard/alga/blob/7c585142afc3811dc44093f5e6e7165f6f609539/src/Algebra/Graph/AdjacencyMap/Internal.hs#L88) ---- 
Thanks ! You are right, I will expand a bit the corresponding README section: https://github.com/haskell-perf/graphs/#and-if-i-dont-care-and-only-want-to-add-a-benchmark
Awesome work! Great to see source plugins gaining some momentum!
If you use haskell-ide-engine (`hie`), then it will come with HaRe built-in for use with `lsp-rename`. However it times out whenever I try to rename a symbol. At least it build with 8.4, I guess.
Thank you for your response! The base monad does not need to be a transformer though? I'll try to write something down as I don't have the code in front of me. This is the gist of it scrapePage :: Url -&gt; Scraper (Validation Error Page) scrapePage url = do maybeValidationCompositThing &lt;- scrapeUrl url $ someSelector $ do validationThing1 &lt;- parse $ text $ "div" @: \[hasClass "thing1"\] validationThing2 &lt;- parse $ text $ "div" @: \[hasClass "thing2"\] CompositThing &lt;$&gt; validationThing1 &lt;\*&gt; validationThing2 case maybeValidationCompositThing of Nothing -&gt; thrownSomeError Just validationCompositThing -&gt; case validationCompositThing of \-- ... It feels like I have to layer a lot of stuff upon one another which leads to a lot of unwrapping.
That's interesting, I've never used \`Compose\` before. Nor \`Alternative\`. I probably need to go on a blog-post-reading-adventure to see how they can be useful.
Looking good! How about some benchmarks about dynamically modifying the graph, e.g. inserting or removing edges? Without that, it's not surprising that `containers` wins most of the time, as AFAIK it's backed by an array.
Why publish to hackage? Usually people only put libraries or individual-use tools to Hackage; is the intent that the website have individual instances run by users?
There's no good text for this right now. I've written about my experiences on architecture in Haskell ([cake](http://www.parsonsmatt.org/2018/03/22/three_layer_haskell_cake.html), [type safety](http://www.parsonsmatt.org/2017/10/11/type_safety_back_and_forth.html), [managing effects](http://www.parsonsmatt.org/2016/07/14/rank_n_classy_limited_effects.html), [invert your mocks](http://www.parsonsmatt.org/2017/07/27/inverted_mocking.html)), but it's a small fraction of what I'd cover if I had time to write a book.
The demanding tone is definitely offputting, as barischrooneyj mentions. But along with that, I don't think "convince me to learn Haskell" is a great way to start engaging with the Haskell community or the language itself. I daresay most of us found our way to Haskell without expecting in-depth, persuasive arguments to convince us to try it out; a bit of curiosity about functional programming, an experience with another language that was less than satisfactory, interest in math, frustration with the ad-hoc nature of industry development practices, etc...is all it took most folks I know. I mean, [here](https://www.reddit.com/r/haskell/comments/8jmf5l/why_did_you_decide_to_learn_haskell/), read for yourself--most of those responses are about self-motivated curiosity, in some way, shape, or form, even those answers which are a bit off-the-wall. While I appreciate the positive responses this post got--it's nice that a lot of Haskell users feel strongly enough about the language that they would respond even to this post with great reasons about why they think Haskell is worth learning--I think that it's a lot to expect those of us who've found our way here through our own curiosity and who *stick around because of our own determination* should then spend more time trying to convince others to start learning about it. I'm skeptical anyone coming in with that expectation will be willing to engage past a very basic level, and I have better things to do...like learn more Haskell.
The latter and the former are equivalently simple. It's a question of where you put the expectation of variance. With the `HasLog env` approach, you can concretize it to `ReaderT (String -&gt; IO ()) IO a`, or `ReaderT Env IO a`, or `ReaderT (String -&gt; IO (), Int) IO a`, etc. With the `MonadLog` instance, you can concretize it to `IO`, a transformer over `IO`, a newtype wrapper around the monad, etc. With the former, you generalize the environment. With the latter, you generalize the action. These are very similar. I would suggest that, for [imperative programming concerns](http://www.parsonsmatt.org/2018/03/22/three_layer_haskell_cake.html), it is better to parameterize the environment, and for business logic concerns, it is better to paremeterize the action type.
Most (all?) parsers are `Alternative`, that's what lets them try another option (`&lt;|&gt;`) after a previous one fails. I described the `Compose` trick in [this SO answer](https://stackoverflow.com/a/48835376/1364288).
I totally agree, I never had "us vs them" in mind. My argument was a progressive call, an imitation of the famous philosopher Slavoi Zizek quot "Do not be afraid, join us, come back! You've had your anti-communist fun, and you are pardoned for it—time to get serious once again!"
One web framework not mentioned yet from the simpler end of the spectrum is [Spock](https://www.spock.li/). It provides a bit more than Scotty but it is still small and simple. Some of its features: fast typesafe routing, middleware, sessions, cookies, database connection. Here is a nice short screen cast to give you some idea how web development using Spock may look like: [Your first web application with Spock](https://haskell-at-work.com/episodes/2018-04-09-your-first-web-application-with-spock.html)
This was done :) I might not have very commented them in my blog post, but you can find for example `removeEdge` results at https://github.com/haskell-perf/graphs/blob/master/results/TIME.md#removeedge
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [haskell-perf/graphs/.../**TIME.md#removeedge** (master → fedfb94)](https://github.com/haskell-perf/graphs/blob/fedfb941aa75ae8fc5b9713aa8924b8eec396d77/results/TIME.md#removeedge) ---- [^delete](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply e1wy4sc.)
Ah, right. Must have skipped it because it didn't mention \`containers\` at all. Even if there's no builtin functionality, could you maybe include the timings of rebuilding the whole graph?
If we encourage posts like this, how long will things stay nice
What do you mean by "rebuilding the whole graph" ? Exporting it to a list of edges and convertin it back to the library representation ?
Why did you skip some benchmarks for certain libraries? I guess there is a deeper reason but when just skimming this seems weird.
This is a creative theft of syntax hm could [or patterns](https://github.com/ghc-proposals/ghc-proposals/pull/43) be implemented as a source plugin?
That affects optimization, however. 
Sounds great. Looks forward to it!
Neat! I've wanted idiom brackets for yonks.
or patterns are a great idea!
Personally, I tend to avoid Internal modules. I just dump everything into the public module and only export the honest-to-goodness public interface. I don’t typically end up in situations where I need to test internal functions. However, if you are in that situation, here’s what I recommend. Create a flag in your cabal file. Maybe it’s named “debug”. Using CPP, you can check to see if this flag is set and export internal functions when it is. Whenever you build your test suite, you have to make sure this flag is set. Otherwise, the internal functions will not be included in the export list.
I've had many people suggest doing a project to really get a handle on any language. I opted for excercises from project euler and 99 Haskell problems. So far it's been a great learning tool. I use many of the books mentioned here and stack overflow as references. This for me seems the most productive of routes to learned material. However, hurdles remain. Memoization, Monads, Applicatives and Functors oh my. 
/u/winterland1989 Thanks for the shoutout to persistent-mysql-haskell :)
I have been debating this.. something like hledger wants people to install it locally. In our case, I think people could take the application, build it locally and run it, and use that as inspiration for how they might want to repurpose it... The application is something like gitlab/hackage, but for researchers, and we host a central instance of it, but research groups could choose to host local instances later on. Another unrelated advantage I see in more applications publishing on hackage is to provide more test suites and dependencies for core libraries, for things like pack deps and stackage builds. Sometimes, I use packdeps reverse dependency lookup to find examples of how a library is being used. Our applications test suite might help exercise more corner cases for a library we use - although such tests should be moved upstream after such a failure is encountered.
A similar question - should hackage-server be published on hackage? Pros and cons?
[An alias for `--copy-compiler-tool` would be nice.](https://github.com/commercialhaskell/stack/issues/3908)
thanks mate,will contact you. As now i working on some other project , after that i will work on Haskell IDE.
Something like that, yes. Preferably without roundtripping through a list (I'm not familiar with the API).
Hey, I didn't know this user name was you! :).
It would be nice to make a new proper release sometime. It certainly is intended to be a standalone-installable app that users can host locally
Is this analogous to reader-macros in common-lisp? Can we use something like this to making type-safe SQL in Haskell easier?
Hey! I think that this could potentially be a good talk, although we would definitely need more concrete details in order to make a judgement. The remote deployment aspect seems pretty unique. Does that contribute to interesting deployment requirements, does Haskell's correctness help prevent classes of bugs that would be especially painful in that context? Looking forward to seeing a submission!
You can't introduce new syntactic elements in source plugins, as you don't get to change the parser. It looks like the proposal wants to use `;`, which I don't think is currently valid syntax. That said, you could approximate the proposal by just using something that would parse as an infix operator, and then rewrite that in a source plugin. So, you might have module OrPatterns where data OR x y = x :|: y And then in your source plugin you would look specifically for the `(:|:)` name and do your magic on the given `x` and `y`. If you give `(:|:)` fixity, you should end up with a parse tree that is correct. The plugin would fire before type checking in this case, but after the renamer. This is just thinking out loud, but it seems doable.
Which bench did I skip ? If a library is not listed in a particular benchmark, this is due to a lack of a functionality from the library (for example, Fgl doesn't implement `transpose`) or the impossibility to implement the function (for example you cannot write `addVertex` for containers).
I see, this is possible only for containers :) Alga is not concerned (since it offer function to interact directly with the inner representation), and Fgl and Hash-graph are _hiding_ the representation (they too both offer functions to change the inner representation, but "safely" )
No, this is more analogous to regular macros. You can only make transformations on the AST. QuasiQuotes in template haskell is more like a reader macro.
Exactly what I had in mind, I want to know if source plugins are a viable way of implementing certain language extensions but I haven't gotten my hands on them yet
Yes, I had planned to do the same! AFAIK, there's no real performance difference to writing the code yourself (except longer compilation) as it all runs before core rewriting
That's what I meant! I was thinking this is the reason, but it just wasn't mentioned in the doc iirc.
Thank you for the links!
Mhh yeah it definitely worth a mention ! Thanks for your comment :)
I am looking forward to buying the hardcopy when it's available (not bothering with the ebook) but I did not buy it one bit when I one of the authors rubbished LYAH. LYAH is far from perfect but it's done the language a great service by providing an accessible resources no matter how imperfect. I've been reading it at a gentle pace for about 2 or so years now (got several irons in the fire) and I'm nearing the final chapter. Gonna do a shout out when I'm done.
Reminds me of my journey into C++, which is how I pay the bills as we speak. I searched for a readable text that didn't throw in templates in chapter 3 (BTW I'm now a template fan boy). Eventually I stumbled across Late Night Guide to C++. It started from the beginning and justified every feature of C++ that it thew in. I'll never stop saying good things about that book.
I found this [video](https://skillsmatter.com/skillscasts/4251-lenses-compositional-data-access-and-manipulation) by SPJ very useful to understand the basic idea.
(This is probably going to be great for EDSLs!)
&gt; What we'd really like to be able to do is count every occurrence of query in this monad before it branches based on the result of an earlier query Another possible way of doing this would be to structure the function that is mapped as an `Arrow`, possibly an `ArrowChoice`. &gt; since our guard h line really-and-truly is necessarily monadic. Perhaps you could bake-in the "failure effect" into the `Applicative` itself, perhaps composing it with [Validation](http://hackage.haskell.org/package/validation).
Right. Enable `-XApplicativeDo`, then let the compiler rearrange stuff and offer an optimized `Applicative` instance.
I am not sure. You could do something like guardA :: (Alternative f) =&gt; Bool -&gt; f a -&gt; f a guardA b a = if b then a else empty But the bool can't depend on an effectful computation if we stay purely applicative. We could do filterA :: (a -&gt; Bool) -&gt; f a -&gt; f a filterA (const False) f == empty filterA (const True) f == f But that implies mixing the pure and effectful parts of the computation so it's a monad - or at least more than applicative.
Unless I'm misunderstanding the use case, I think you could return the unaltered position when the flag is not set. This does slightly change a bit how it works, but is applicative with `ApplicativeDo`: do p &lt;- query position v &lt;- query velocity h &lt;- query hasPhysics pure $ if h then _1 else _2 where `_1` is with an altered position and `_2` is with an unaltered position.
Not conditionally. You could do something like (\a b -&gt; if a then b else magicEmptyValue) &lt;$&gt; pure True &lt;*&gt; pure someValue but then what do you put in for `magicEmptyValue`? It can't be `empty` since you're running in a pure function context by that point. You can try to cheat by saying the return type is `Maybe a`, but now you're just running monadic code again and you still can't inspect it.
But that restricts you to writing applicative code, which is too much of a constraint for the things I want to do. Also it doesn't work with `guard`. I tried it :)
You can do this, but now you have a performance problem if setting---or equivalently computing equality---is expensive (which both are). But the example isn't really the point. It's an approach for inspecting things we previously thought weren't inspectable!
Am I correct in understanding that in the following case: do p &lt;- query position if something p then do v &lt;- query velocity ... else ... The potential `query` on velocity will not be discovered by `prospect`?
Correct
It's not the same but I will advertise the paper [*Combining Deep and Shallow Embedding of Domain-Specific Languages*](http://www.cse.chalmers.se/~josefs/publications/svenningsson2015combining.pdf), it's one that's always fun to come back to (disclaim, I never read papers all the way through) * (page 17) figures 2 and 3, subsection *4.10. Rendering the AST* * (page 20) section **6. Monads**, especially data FunC :: Type -&gt; Type where (:$) :: FunC (a -&gt; b) -&gt; FunC a -&gt; FunC b .. newtype Mon m a = M (forall xx. (a -&gt; FunC (m xx)) -&gt; FunC (m xx)) newtype Codensity m a = Codensity (forall xx. (a -&gt; m xx) -&gt; m xx) where `Mon m` is just [`Codensity (Compose FunC m)`](https://hackage.haskell.org/package/kan-extensions-5.2/docs/Control-Monad-Codensity.html) in disguise, indeed we can use the upcoming [`-XDerivingVia`](https://www.reddit.com/r/haskell/comments/8aa81q/deriving_via_or_how_to_turn_handwritten_instances/) extension (GHC 8.6) to derive its functionality *via* `Codensity` newtype Mon m a = ... deriving (Functor, Applicative, Monad) via (Codensity (Compose FunC m))
Looks really sweet!
In general there is a culture in Haskell that tends to favor using short names where they have limited scope, but more descriptive types. newtype Cup = Cup { ounces :: Int } coffeeCup :: Cup coffeeCup = Cup 12 -- if you want to be more descriptive -- coffeeCup = Cup { ounces = 12 } -- amount to drink in ounces drink :: Cup -&gt; Int -&gt; Cup drink (Cup n) k = Cup (n - k) The types you started with are "too big" in one sense. Cups don't change their behavior radically at different sizes. They are completely characterized by their contents in your presentation above.
The example i wrote was doing (i think) a simple simulation of OOP in haskell, it's not my code. However thanks for the explanation, i will try to keep in mind that i should strive to be more descriptive by types, not function/variable naming.
Glad to hear that! Let me know if you need any help getting started.
Oh, true! I think this is equivalent to splitting (the monadic) error handling out of the applicative. That is, have monadic functions like Position -&gt; Velocity -&gt; HasPhysics -&gt; Maybe Result And wrap them in the applicative f (Maybe Result) So the program is a mix of a set applicative pipeline and monadic bits. This sounds a lot like arrows but historically arrows lead to awful api's no matter how perfect the use case.
What are source plugins? release notes don't mention it, and I didn't find anything by Googling. https://downloads.haskell.org/~ghc/master/users-guide/8.6.1-notes.html 
Top-level functions should have reasonably descriptive names. But those names are generally seen *with their types*. `drinkFromCup` seems redundant, because its type shows that it takes a `Cup`. /u/edwardkmett's `drink` seems to be missing information: the fact that the quantity is given in ounces. One option would be `drinkOunces`. Another would be to add a new type representing drink quantities: newtype DrinkAmt = DrinkAmt {mlAmt :: Double} ounces :: Double -&gt; DrinkAmt ounces oz = DrinkAmt (29.5735 * oz) getOunces :: DrinkAmt -&gt; Double getOunces drink = 0.033814 * mlAmt drink
Hey everyone, what are the trade-offs between the current, actively-maintained extensible effects libraries? \`freer\` and \`freer-effects\` seem less maintained. Are they just "done", or rotting? \`extensible\` and \`extensible-effects\` seem more maintained. The latter looks a lot like the \`freer\` ones, the former seems organized differently altogether. What about \`more-extensible-effects\`?
As to your second bullet, have a look at [dhall-to-cabal](https://github.com/dhall-lang/dhall-to-cabal). Probably not what you wanted but it does make things more flexible and it's definitely cool.
I’m currently reading this one https://www.manning.com/books/get-programming-with-haskell and I find it very good, Much less verbose than Haskell from first principles and more technical and up to date than LYAH. Strongly recommended if you already know how to program.
This is pretty neat! Have you thought much about whether your technique is referentially transparent? We had to think hard to justify why ours was, in StrictCheck (see the end of section 3.2, on page 14). When you're observing evaluation, you have to be careful to force all the evaluation you're observing, before you return your observation. We got this wrong at first—our original version of \`observe\` also returned the \_result\_ of the function being observed, which destroyed referential transparency. (There is a way to have your cake and eat it too, but it didn't make it into the paper.) I'd be worried in particular about how all your functions are marked \`{-# INLINE #-}\`. We used \`{-# NOINLINE #-}\` a lot in StrictCheck to make sure a single call to \`entangle\` didn't get inlined as two separate calls. If that happens, reference cells which are supposed to be identical point to different areas in memory, and so you can potentially get erroneous results. Cool idea, I think there's room for more work on this kind of analysis.
I am glad that my complaints were being heard 😉 I am wondering whether the upcoming SourcePlugins would allow us to define our own rebindandable syntax allowing for heterogenous lists.
What do people mean by static analysis in haskell world? I haven't seen any additional tools that does further analysis than the typechecker.
Does this video have sound issues, like the one [on youtube](https://youtu.be/wguYuQwjTtI)? (I prefer to know before signing up for skillsmatter.com)
Very neat trick. Thanks for making the feature announcment into a sort of tutorial.
\&gt; I am glad that my complaints were being heard Yes, over and over in my head, in the voice of Fran Drescher. It helped.
Nice. I actually need this in a project for multiplications in T\_16 (full transformation semigroup on 16 elements) Quasi-related hack I had back in the day to do Roman numeral evaluation: [https://gist.github.com/chadbrewbaker/4542999](https://gist.github.com/chadbrewbaker/4542999) 
If you're looking to write heterogeneous lists my package [heterogeneous list literals](https://hackage.haskell.org/package/heterogeneous-list-literals) is a fairly readable way of doing things
My rule of thumb: the more polymorphic the type, the shorter the name. You hardly even need a name for `const :: a -&gt; b -&gt; a`, but just `k` does fine for a lot of mathematicians, but [`improveComponentRatings :: GameDB -&gt; RatingDB -&gt; Component -&gt; [RatingDB]`](https://github.com/dmwit/mcmario/blob/master/src/MCMario/RatingDB.hs#L51) might even be too short and nondescript.
I do not remember any sounds issues. I have gone back to that video a couple of times for review as well.
You can check out the original proposal [here](https://github.com/nboldi/ghc-proposals/blob/patch-4/proposal-source-plugins.rst).
Using the type annotation as Nil is cool but iirc mistyping leads to really ugly type signatures.
I don't think `fluidOunces` is an ounce more descriptive than `flOz`.
Agreed. A lot of Haskell's cultural aversion to descriptive names \*starts\* with not wanting to be overly specific in naming, when the idea itself is a lot more general. When you're generalizing over an arbitrary value, \*any\* descriptive name you give to the variable is too descriptive, and prevents you from seeing the full abstraction. In practice, though, Haskell code tends to have a lot of short names, so it's easy to sneak in one or two more, even when this time there is a lot of meaning to convey. So we're not perfect, either. Short names end up being an unfortunate habit even when there's no risk of overspecifying.
I apologize for asking a question that's slightly off topic, but what happens when you choose a universe for these structures that isn't an Identity? That's what "I" is here, right?
To add on to the other good advice in this thread, I think [this post](https://mail.haskell.org/pipermail/haskell-cafe/2008-June/043986.html) makes some good points.
Good question. The "universe" or "interpretation" type `f` in `NP f xs` is what makes heterogeneous lists so useful in my opinion. When you choose `I` you get a product type. What other interesting choices are there for `f`? You could have `Maybe` or `Either String` to get records whose fields may not be there (with a message in the latter case). But more interesting is that the kind `f :: k -&gt; *` means that the list `xs :: [k]` doesn't have to be a list of datatypes. For example, if we take `f=Alias` as in the linked piece, then `k=Symbol`. This facility is extremely important in Squeal because Squeal's types are not necessarily Haskell datatypes, they're often Postgres types!
It is very more descriptive. The unit of ounce is not widely used outside the US. At first I thought of `flOz` as a l33t 57yl3 j0k3 of some sort.
Types are part of the variable name, in a way. On the other hand, I think its a habit the community could improve. I understand very terse lambda expressions but imo there's no reason your params can't have descriptive names. Be the change.
Nice work! Seriously considering switching from Elm to Concur now. Will definitely keep an eye on this. :o)
Excellent! I'm really interested in Elm folks' impression of Concur. I had posted a link on Elm Slack's #random channel (because I didn't want to spam #general), but didn't get a lot of response. So yeah, I would really appreciate your feedback, especially if you found something harder to use as compared to Elm!
Well, for one, the compiler does static analysis after desugaring to its Core intermediate representation to identify places where certain code transformations are sound and beneficial (e.g. is an optimization). Also, there are tools like `hlint`, which basically are static analysers. One could argue that the post shows a static analysis over the AST of the domain-specific language (querying an entity component system, in this case). Try to identify as many data-independent queries as possible and compute their intersection directly instead of back-tracking. That happens at run-time, so it's more like a JIT, I suppose.
If you don't like his book you don't have to buy it. As simple as that. But can you and u/renfieldist please stop bashing u/bitemyapp aka Chris Allen for having personal opinions?
Oh don’t get me wrong, I have no idea how big an ounce is, but I still know that it’s a unit of measure. (I am English.)
I'm a fan of your writing, this interests me, for sure!
A not uncommon use case is choosing a parser type as the "universe". If you choose a constant functor you get an homogeneous list indexed by types. If you use a function, you get a list of functions each taking the same type but returning the type corresponding to each position in the list. (This means by the way you can apply a list-of-functions to an homogeneous indexed list.)
[The Internet tells me](https://en.wikipedia.org/wiki/Imperial_units#United_Kingdom) that Imperial system is still in wide use in the UK too. I should have included it in my previous post alongside the US.
Please read my post again I am not bashing Chris or his work, which though I am yet to read (cos it's not available in print) I'm prepared to go out on a limb and describe as a masterpiece based on the glowing feedback it's received. I'll order the print edition the instant it becomes available. Seriously. However I disagree with his assessment of LYAH. It's far from prefect but it's made a contribution to the Haskell community. Just like Chris' work has. Frankly I'm surprised the OP or a few people I've people I've heard of can't grok Chris' work. Maybe I shouldn't be surprised. No resource will work for everyone. The community is better for having a plurality of resources; each giving a different perspective to the language.
- I have enjoyed most of your blog posts - I am very into type-level programming lately Today was a good day
I for one would love to have a type level programming book! Could you _please_ make it cheaper for students? That would be a great help :) 