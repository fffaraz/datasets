Yes! That's an interesting option to avoid Stack (if that's a useful objective). The main aim of my wrapper was to ease project-requirements so people can just get going. I only picked Stack at all as it seemed easy and repeatable with the LTS concept.
Any idea why smart contracts and Plutus in particular need to be Turing Complete? At least in finance, the one very nice feature of contracts is that they mostly have a deterministic end point : ) On the other hand some don't (e.g. an equity) so perhaps that's why..
I would wager that’s why. Contracts in the large don’t seem to be finite. What if there’s a breach? Or a renegotiation?
Without anything else, `Narrow` and `Common` are likely to exhibit terrible type inference, making this painful to use in practice.
Nothing a generous amount of incoherent instances can't fix.
The design of Dependent Haskell does not emphasize soundness. It unifies `Type` and `Kind`, which leads to something called "Girard's paradox" (which is like Russel's paradox "one level up"), and it does not attempt to disallow nonterminating proof terms (because doing so would require a termination checker). For more information, you should probably check out Richard Eisenberg's [thesis](https://arxiv.org/pdf/1610.07978) (the GitHub [repo](https://github.com/goldfirere/thesis) may have more info), which is pretty readable as far as theses go, and the GHC Trac [page](https://ghc.haskell.org/trac/ghc/wiki/DependentHaskell).
I thought about inference, in combination with overloaded literals using (.+.) is going to be a pain. But in the (maybe common?) case where both argument types are known, it should be okay. after all the type of fromIntegral is quite similar.
Please tell me more :-). The problem of the massive amount of instances still remains... Is there a way around it?
That wasn't really a serious suggestion (although I'm pretty sure it can be done and might be an interesting challenge). I think the current situation is actually pretty decent. The problems you state about information truncation are kind of actually solved by the functions you mention. Among other reasons, that's why there's not explicit numeric type promotion. If you need to use `fromIntegral` it's because your types don't match so a bit of extra work is required from the programmer to make sure that the conversion you have in mind actually makes sense.
Any feedback on my solutions so far of the AdventOfCode 2015 : [https://gitlab.com/roelofwobben/aoc2015](https://gitlab.com/roelofwobben/aoc2015)
`ghcup` is a very thin and useful wrapper around `./configure &amp;&amp; make install`. It also makes it quite easy to get the latest `cabal-install` binaries and has the added benefit of easy uninstall.
Unless the Turing complete contract language is used to create simpler, non-Turing complete contract-DSLs (which are then used to formulate the actual contracts), it seems like a mistake to me. I can't see a scenario where it'd be useful to have the definition of a term in a contract depend on itself. But I'm interested in knowing whether I'm mistaken here.
I see your point, but I still prefer to be more explicit about the conversion I have in mind :-). The concern is about performance of fromIntegral and realToFrac, e.g. here is a case were converting from Word16 to Double generates horrible code: [https://godbolt.org/z/CGpo\_V](https://godbolt.org/z/CGpo_V). Using an intermediate conversion you can work around it, but its not so great, and you have to be aware what it does.
Have you considered running each test in a separate transaction? That way you don't need to setup the database each time and can just do a rollback after each test.
It's a big change, but I would question whether testing against a real database is truly what you want at this level of testing. A good question is to step back and work out what you trust and what you don't trust, in the context of testing. Once you can answer this, you can build an API that might be able to exploit that trust relationship in order to obtain easier testing. As an example, suppose I'm building some kind of website with projects. I might want to test that my `/projects` handler does actually return projects. This is all I'm interested in *at this level of testing*. So now I have `projectsHandler :: MonadProjects m =&gt; m [Project]`. At this point I'm free to implement `MonadProjects` however I please - avoiding the database entirely! Note that I'm *not* suggesting you implement a full in memory relational database - you could implement `MonadProjects` just using `ReaderT` (depending on what `MonadProjects` is). In your `main` you would choose an implementation of `MonadProjects` that targets a relational database, but that's nothing to do with testing things that use `MonadProjects`. Of course, at *some* point you need to know that the database code works, but that might not need QuickCheck. Even if you did want to use QuickCheck, you again need to ask what it is you trust and don't trust. If it's just schema stuff, if your schema was reflected out of the database into a file, you could instead parse the generated queries and type check them against your schema - there's again no need to have an actual database running.
I think that would work for a lot of the tests, but we'd need a lot of infrastructure changes to get the others to work. (Some of the code being tested creates its own transactions, and we need to test that those transactions work as expected, so there's a can of worms there. And some of the test code uses multiple different connections, so that's another can of worms. Some of the code being tested might do that, too, I'm not sure.) I wouldn't be surprised if that infrastructure work had other benefits, but I don't think it's worth doing right now.
If you're using PostgreSQL, there's a concept of savepoints which are nested transactions. Maybe that could work for you.
`Fin (n*m)` is not the product of finite sets. You need an auxiliary function `(n, m):(Nat*Nat) → Fin (n*m) → (Fin n, Fin m)` that computes the quotient and remainder
In the specific case of Plutus, we are implementing the non-turning complete contract-DSL Marlowe on top of Plutus, and yes, that requires recursion.
Look at it like this: Plutus is the general-purpose substrate on which we can build more specific little languages and apps for specific application scenarios. Hence, we want the full generality of Haskell at our disposal.
I like this idea in theory, and we've made small stabs in this direction in the past (using monad-mock, which unfortunately seems defunct). I suspect that if we were to try it, enough tests would want to use an actual database that we still couldn't avoid this problem. (In particular, we have a bunch of tests that are basically "does this SQL query include a join on the relevant permission tables?", and I guess that not using a real database for those tests would make them useless.) Maybe avoiding quickcheck, but at that point it's a big enough change that I can't even sensibly reason about it without putting in a lot of time and effort.
That would be part of the solution, but it's still a can of worms.
Woah. Thank you for the links! Really helpful. 
Nice to see Nike using Haskell in prod.
Try it. Write a few instances by hand and then use it in real code. 
What, like this is easier to deal with in Java, C, C++, C#, or anything but the 'best in class' ecosystems? Please take a step back and do a more honest comparison for brand new users to those ecosystems. You think Stack documentation is bad, and it's CLI interface leaves a little to be desired? Have you heard of Maven? Do you honestly think cabal hell is even remotely as bad as dll hell? Building and packaging are surprisingly difficult problems to solve and I honestly don't think the Haskell user experience is significantly more poor than most of it's leading contenders. We can improve substantially, yes. I think minor surface changes to do things like improve documentation and provide CLI front ends to stack/cabal for managing project config files would probably be enough to significantly ease the pain of adoption. But really the foundation here is pretty strong when compared to most other ecosystems, and I don't think it's really fair for us to call out our build tools as being somehow sub-par or deficient when they most definitely are not.
Unitial. Though, technically, that means that the type has a unit w.r.t. to some operation and we haven't exactly been talking about some operation, yet. If you type has some sort of append/concatenate then, it's probably monoidal, with the empty element being `mempty`. Definitely use this if that's the case. But, if not, we don't have to bring in all the monoid intuitions that might not apply in your case. If you have any sort of fold/reduction across your data structure, then, certain types of folds across your data structure values have algebraic structure, and the folds across the empty value are the unit in those structure, so unitial applies if you have any type of fold. If you have any sort of unfold/production of your structure from a seed value, then the empty value is what you get from a "sufficiently small" seed type. Again, I would argue there's a structure here where the empty value serves as a unit. So, unitial applies if you have any type of unfold. --- Honestly, I think "potentially empty" is actually fine. It seems odd that you'd need to use this more often than "nonempty", and being just a little longer is fine is it is used less often.
If you don't care about soundness, [Ex Falso](http://inutile.club/estatis/falso/) is the proof system to go with. It's much simpler than Agda, Idris, or even Haskell.
If you need versions from fromIntegral and realToFrac with more restrictive types, just create them: intToWord8 :: Int -&gt; Word8 intToWord8 = fromIntegral No need to introduce type class machinery.
This is the user-hostile part. No other language locks capability intentionally in this way. It makes it seem like elm doesn't trust and/or respect their users and it's a very bad look IMO.
I've been wndering this: 
Yeah, but the implementation might not be optimal. Isn't fromIntegral = fromInteger . toInteger? AFAICT, there are special rewrite rules to pick a better implementation for certain cases. The Problem is, there is no way of knowing by just looking at the source code. (See my link to the generated assembly for realToFrac above)
Like functions in math, haskell doesn't have "variables that can change". It may be difficult to understand the answers to your questions without actually starting to dive into the language, but SO has a lot of relevant answers: https://stackoverflow.com/questions/19594655/random-number-in-haskell https://stackoverflow.com/questions/11467066/how-to-get-normal-value-from-io-action-in-haskell https://stackoverflow.com/questions/7267760/how-can-a-time-function-exist-in-functional-programming https://stackoverflow.com/questions/3117583/is-haskell-truly-pure-is-any-language-that-deals-with-input-and-output-outside/3118369#3118369 https://stackoverflow.com/questions/4063778/in-what-sense-is-the-io-monad-pure https://stackoverflow.com/questions/7840126/why-monads-how-does-it-resolve-side-effects https://stackoverflow.com/questions/2751313/how-do-functional-programming-languages-work/2751469#2751469 
Are there simple functions in the GHC codebase to do simple reductions such as substitute a type for a type variable throughout an expression. What is the best way to find and learn to use these functions?
I think maven is easier that cabal or stack to just list my dependencies and so a normal build. Customization or even figuring out what the CLI can do, is bad (or at least worse) in maven, but it doesn't serve as quite the early stumbling block that cabal/stack do. Also, I think binary distribution of packages needs to be solved (or at least worked on) in the Haskell ecosystem. Even [languages that *don't compile*](https://www.python.org/) are using [binary distributions](https://www.python.org/dev/peps/pep-0491/) since it just makes it easier on everyone that depends on your package. Yes, there are APIs/ABIs to be managed, but that also should have already happened in the Haskell ecosystem.
You can have all of that with corresponding monads. Description on site is poorly written and misleading. What it actually means is that by default all your code is pure - no state, no random, no side-effects, a math function basically. You can have random, state and side effects and whatever else but you would have to make it explicitly.
Thanks! It's been running in production for now... I guess ~3.5 years? Without really causing any problems. It could do with being updated to work with the latest Redis though, as the syntax of the few small fragments of Lua that is used (for atomicity) has changed (see https://github.com/positiondev/hworker/issues/2), and that hasn't been a priority because moving to a newer version of Redis hasn't been a priority!
This quite a complex topic. First of all, to answer your questions, Haskell can generate random numbers, and use them too. Also, there is something you might consider changing variables in some specific scope, but actually, whole of non-IO Haskell consists only of function calls and function definitions (or type definitions, but let's just ignore that right now) A Haskell function always returns the same result if it gets the same input parameters, which is called *pure*. For example, you can guarantee the function `id` just returns its argument. Since this can work regardless of the data type of the input, it has the type signature `a -&gt; a`. `a` stands for an arbitrary type, so no matter which type your input is, the output will be of the same type. The arrow between the two variables just means it is an function from a to a. A function like this (also non-polymorphic functions like negation, which only works with booleans and therefore has the type `Bool -&gt; Bool`) can *never* depend on additional information, like files, the internet, or global mutable variables. Basically, any variable (or function call) could just be replaced by its definition, which is called *referential transparency*. You might compare this *parametric* polymorphism with templates/generics (both were actually inspired by Haskell). If you wanted to actually do IO in Haskell, you need the `IO` types. It is a type function, so a type that takes types, but do not overcomplexificate this, I'll just show you an example. `getLine` is of type `IO String`. This means it is not a regular string, but a string depending on its environment (user input in this case). But with a value of this type, no function that is made for strings can be directly applied on it. You could not just do `lines getLine`, which would normally split the string into a list of all lines. To use functions on IO values, you need IO's definition of a monad. Explaining what a monad actually is is a bit too complex for the moment, but the important part is that you can modify functions to be able to use IO values for actual computation. However, it is definitely impossible to write a function with type `IO String -&gt; String`, because then, the whole referential transparency thing would break and your pure functions could depend on the environment. 
But whatever implementation you want there. I just used `fromIntegral` because that's what I would use to covert from `Int` to `Word8`.
The notable existing total languages can deal with infinite contracts just fine, with coinduction. 
**Guidance on using** **Control.Monad.Free.Church** I'm making a small DSL with only one type and pure functions that are uncurried and non-recursive. I had the following type , `TermX a` . data Term a r = Value a -- a pure value | WillBeArg (String -&gt; Maybe r) --used in function definitions to type expressions that contain what will be passed as an argument in a future call. | Area (String -&gt; Maybe r) a -- namespace and a value (makes sense in the domain) | Func [String] (String -&gt; Maybe r) -- arg list and a namespace deriving (Functor, Typeable) type TermX a = Fix (Term a) This was going fine; but I realized my type (minus the Value constructor) was probably isomorphic to something like `Free Term` and hey, I'm writing and interpreter. So `Free` feels right but I've never used it before and in all the examples I see the underlying functor is `* -&gt; *` , not `* -&gt; *-&gt;*` &amp;#x200B; What would using `Free` here look like and would there be any advantages to doing so?
That auxiliary function is exactly `\x -&gt; fst x, snd x`. I'm sorry, but I don't know how to call category where objects are natural numbers and arrows are functions between finite sets of that size (finite sets of same size are isomorphic). It's not https://en.wikipedia.org/wiki/FinSet, but how to call it if `Fin n` is a finite set of size n?
Fin (n*m) is *not* a pair. It's a number less than the natural number n*m Are you talking about the discretization of FinSet? (forgetting all the non-trivial arrows).
Quick summary ;Currently our categories are Category :: Cat ob -&gt; Constraint for arrows (`type Cat ob = ob -&gt; ob -&gt; Type`) (-&gt;) :: Cat Type Kleisli m :: Cat Type (&lt;=) :: Cat Nat .. This exploratory version of `Category` is not indexed by arrows, but objects Category :: Type -&gt; Constraint where the arrow is an associate type family (so knowing the object `Type :: Type` we should figure out the arrow) class Category (ob :: Type) where type (--&gt;) :: Cat ob The problem, 1. `(-&gt;)` and `Kleisli m` both have types as objects 2. The kind of `Kleisli m` must carry `m` Solution; create a new kind which wraps `Type` newtype KleisliKind :: (Type -&gt; Type) -&gt; Obj where Kl :: Type -&gt; KleisliKind m that is indexed by `m :: Type -&gt; Type`. Now we wrap the kind of the objects of `Kleisli m` with `Kl` and we can write a `Category` instance of the wrapped kind `KleisliKind m` data Kleisli m :: Cat (KleisliKind m) where MkKleisli :: (a -&gt; m b) -&gt; Kleisli m (Kl a) (Kl b) instance Monad m =&gt; Category (KleisliKind m :: Obj) where type (--&gt;) @(KleisliKind m) = Kleisli m -- (visible kind applications -- https://phabricator.haskell.org/D5229 
Ahh so the program needs to exit cleanly to write the file? From the documentation, I had assumed that it would write out periodically. My program runs indefinitely so I don't actually have a way to exit it cleanly (though I'll be able to add one without too much effort) &gt; Then try ./my-executable +RTS --info, you should see a line like ("RTS way", "rts_p") (the "rts_p" says "profiling runtime"). I got something similar, but not exactly the same: [("GHC RTS", "YES") ,("GHC version", "8.6.2") ,("RTS way", "rts_thr_p") ,("Build platform", "x86_64-unknown-linux") ,("Build architecture", "x86_64") ,("Build OS", "linux") ,("Build vendor", "unknown") ,("Host platform", "x86_64-unknown-linux") ,("Host architecture", "x86_64") ,("Host OS", "linux") ,("Host vendor", "unknown") ,("Target platform", "x86_64-unknown-linux") ,("Target architecture", "x86_64") ,("Target OS", "linux") ,("Target vendor", "unknown") ,("Word size", "64") ,("Compiler unregisterised", "NO") ,("Tables next to code", "YES") ]
Short version: You can generate random numbers, but you have to initialize a random number generator at program start, and pass it through to any function that needs randomness.
I'm assuming the thr is because my application is threaded. I meant to ask if this might be an issue with profiling.
Looks like the issue was just exiting cleanly. That fixed the issue for me! Thanks for your help!
What "website for Haskell" are you talking about? This is broadly accurate but, at the same time, oversimplified. * Haskell is expression-based. *But:* the syntax includes `do` notation, which is statement-based and kind of resembles code in imperative languages. * Haskell values are immutable. *But:* there are many ways to obtain either the appearance and functionality of mutability, or the actual thing. The `State` monad, for instance, is the classic way of tracking a pseudorandom number sequence, or any other variable that needs to be updated. This does incur the cost of copying the value behind the scenes so that each instance remains immutable; however, you can have real mutable variables via the IO or ST monads (they are called `IORef` or `STRef`, among many other variants). * Haskell values are deterministic. *But:* You can get actual random numbers in the `IO` monad, which is the environment that is directly executed when the program is run (and so can do anything the computer allows). Most statements about Haskell have "except in the IO monad" as an implicit exception. The one statement that I can't really contravene is that Haskell does not have instructions. It doesn't. You are fundamentally limited in how specific you can be about the exact hardware operations that are performed in your program, and this limitation is a lot broader than in less high-level languages. For instance, a Haskell executable will *always* incorporate a dynamic allocator and garbage collector and it is quite difficult to prevent them from running in, say, an algorithm that you know can be done without allocation, because those immutable values have to be copied and cleaned up whenever they are reused or abandoned. Related to this, however, is Haskell's most awesome runtime property: laziness. Expressions are only evaluated when the result is used (by another evaluation, going all the way up to the `main` function), leading to somewhat self-organizing execution paths, including the possibilty of writing but not using expressions that might, say, cause an infinite loop under the circumstances where you ignore them. It's hard to overstate, and also hard to exactly characterize, how useful this is.
Curious, but what system are you on?
How is recursion handled in GHC Generics? I thought I understood how it worked, then I started seeing wild bugs in my code, and now I'm... very confused at what GHC is doing, because it's not doing what I thought it did or what I understood the documentation to say: The [documentation](https://hackage.haskell.org/package/base-4.12.0.0/docs/GHC-Generics.html#t:Rec0) says `Rec0 = K1 R` is a "Type synonym for encoding recursion", which makes sense, except that that's not what I'm seeing GHC actually do. For example, when I do this: data Ex = Ex Bool deriving (Generic) term :: Rep Ex a term = _ There is no recursion in this `Ex` data type at all, yet when I look at the type of this hole, it clearly has a `Rec0 Bool` nested in there! So how is GHC encoding recursion information in the generic representation? To me it looks like `Rec0` is always there, regardless of whether there's any recursion happening at all, but my understanding was `Rec0` should only be there at recursion points, and other holes should have some other `i` in `K1 i`.
&gt;Is there a way to start using this without having to go through the couple-of-hours long installation phaze? I scanned through the documentation on Github but it doesn't seem to mention an update process.
"Smart contracts" don't have much in common with, well, actual contracts. They're [finance bots](https://youtu.be/xCHab0dNnj4?t=1727).
This is not true. See, for example, any of the governance contracts on the EVM. 
Not really an interview. This is just another pitch for a crypto platform (cheesy music and all)
This is a really good answer! However, I feel it would be enhanced by an example program demonstrating the principles you talked about. Using the [Haskell Stack program](https://docs.haskellstack.org/en/stable/README/), the following program can be saved as `test.hs` and then run using `stack test.hs`: -- stack --resolver lts-12.26 script --package random module Main where import Data.IORef import System.Random -- Haskell is an expression-based language. This means that functions -- always consist of one long expression. For instance, this -- function to calculate the LCM of two numbers is one long -- expression: myLcm :: Int -&gt; Int -&gt; Int myLcm a b = let multA x = (x `mod` a) == 0 multB x = (x `mod` b) == 0 filterFun x = multA x &amp;&amp; multB x in head (filter filterFun [1..]) -- Note that even though this includes a 'let' statement, it's still -- considered an expression, since it is possible to remove the 'let' -- by substituting the 'letted' (is there a better word?) values into -- the 'in' bit to get: myLcm' :: Int -&gt; Int -&gt; Int myLcm' a b = head (filter (\x -&gt; ((x `mod` a) == 0) &amp;&amp; ((x `mod` b) == 0)) [1..]) -- The example above also demonstrates laziness. [1..] is an infinite -- list; however, its values are only calculated as they are required -- by 'filter', and after the 'head' function returns, it is not -- calculated any more. -- Although Haskell is expression-based, it can also use (or at least -- simulate) imperative statements using 'do' notation: main :: IO () main = do print (myLcm 4 6) print (myLcm 4 5) -- Run the examples defined below r1 &lt;- mutator print r1 r2 &lt;- getARandomNumber print r2 -- One subtelty which /u/ryanreich didn't mention: internally, 'do' -- blocks are also expressions! The compiler converts them -- to nested application of the (&gt;&gt;=) and (&gt;&gt;) operators: main' :: IO () main' = (print (myLcm 4 6)) &gt;&gt; (print (myLcm 4 5) &gt;&gt; (mutator &gt;&gt;= (\r1 -&gt; (print r1 &gt;&gt; (getARandomNumber &gt;&gt;= (\r2 -&gt; print r2) ) ) ) ) ) -- The nested application might be a little clearer if we rename (&gt;&gt;=) -- to 'bind' and (&gt;&gt;) to 'seq': main'' :: IO () main'' = let bind = (&gt;&gt;=) seq = (&gt;&gt;) in seq (print (myLcm 4 6)) (seq (print (myLcm 4 5)) (bind mutator (\r1 -&gt; seq (print r1) (bind getARandomNumber (\r2 -&gt; print r2))))) -- The preceding examples also illustrate how the 'IO' type is used -- to support things (mainly IO and mutation) which Haskell doesn't -- normally allow. For instance, you can get mutation in Haskell via -- 'IORef's: mutator :: IO String mutator = do x &lt;- newIORef "some stuff" writeIORef x "new stuff!" readIORef x -- this is the value which is returned -- However, in Haskell, use of 'IORef' is considered unidiomatic. -- Most code which would require mutation in other languages can be -- more easily written in Haskell using either recursion, higher-order -- functions such as 'foldr', or explicit state-passing (where a -- function is passed a 'state' as parameter, and simulates mutation -- by applying some functions to the state and returning the updated -- value.) -- Finally, random numbers. As with most other similar things, random -- numbers can be generated - as long as you stay in the IO type: getARandomNumber :: IO Int getARandomNumber = getStdRandom random
https://www.reddit.com/r/haskell/comments/ab8ypl/comment/ed3cvti
&gt; I don't think that's intuition. I think that is learned behavior … I don't think that's a distinction with a difference.
I'm honestly not sure how you could compare [this](https://www.haskell.org/cabal/) and [this](https://maven.apache.org/) and come out thinking that Maven is easier to learn. Ultimately it's a pretty subjective question, but it kind of beggars belief for me to really believe that you learned Maven basics based off official Maven documentation and found that experience to be smooth and user friendly. I suspect pretty strongly that you, and most anyone else who claims learning introductory Maven was a smooth experience, probably read some third party tutorials. My apologies to you if that is an inaccurate assessment of your experience. I will agree hands down that, if we're going by third party introductory material, Maven wins the "documentation" competition quite handily. No matter who you are or how you learn, someone has probably written a maven tutorial you'll understand. Neither Cabal nor Stack comes anywhere close to this, and it probably never will, because Haskell hasn't been among the top 15 most widely used languages in the world for more than a decade. But I don't think that's a fair bar to set, or, more accurately, it doesn't seem reasonable to expect that gap will get filled. What seems achievable is focusing on some standard, modern, maintained sources of introductory documentation and trying collectively, as a community, to direct new users to those sources - And I think that we do have some room for improvement in that arena, most certainly, but I don't think we've done so poorly compared to many of the big players in the scene. I'm not sure how binary distributions relate to new user experience. I'll agree with this as a general point of potential improvement for our ecosystem, but I don't think it's affecting introductory use of Stack or Cabal. As an aside though, it's hardly fair to compare Python and GHC that way. The implementation of wheels relies on an interpreted bytecode format - It's not really a 'binary distribution' any more than a JAR is a binary distribution. And technically, we could distribute DLLs - GHC/Cabal can do that. We just don't. I'm personally glad we don't, because dynamically linking code based off of filename and fiat is a ****ing terrifying rats nest of horrible issues, and I presume the reason that this isn't standard is that most of the folks in the ecosystem agree with this philosophically. But, FYI, if you really want to do it, it can be done.
A JAR is a binary distribution. And, if introducing some bytecode layer would let us install reasonably on a raspberry pi or a 256Mio VM slice, then it should be done. Because I have no problems getting Python or Java programs up on those, but somewhere between containers and lens non-trivial Haskell installs either fail entirely or simply take on the order of days. --- I do actually prefer the Apache documentation over third-party tutorials since they generally provide a more specification-like presentation, which is what I prefer. The first "book" I read when learning Haskell was the 1998 report.
That's kinda like saying "If you don't care about correctness, `rm -rf /` is a good programming language to go with." It conflates "willing to put up with the possibility of unsoundness/incorrectness" with "cares absolutely not at all".
The short answer here is code in Haskell is 'pure' by default, but that this 'pure' code can be executed in contexts that allow things like persistent state or random number generation. To do something like perform IO, store a global variable, or generate a random number, you need to clearly indicate with Haskell's type system that you're "applying" code in a context in which one or more of these things is possible. So, no, it doesn't mean that you can't have a random number generator in Haskell, or track state in some way. It just means you have to be really up-front about it when you're doing it.
Please provide something that can be proven in Ex Falso that can't be proven in Dependent Haskell or vice-versa.
Some properties really are absolute.
This is very cool! Can you do joins?
&gt; I got something similar, but not exactly the same: "thr" means "threaded", "p" means "profiling", so "rts_thr_p" says threaded profiling runtime.
What do you use to bootstrap a project from a template you've made?
I still have yet to understand shake. I'm going to make a solid attempt to learn it for my next project though. I'm not entirely sold on the shake file being 100% raw Haskell, though; exploring what a dhall integration with shake would even look like is somewhere on my list of things to explore in the future :)
That being said, I do wish there was a `$buildtool add &lt;library&gt;` command. Editing the files by hand is quite annoying compared to JavaScript where things are just a `yarn add`/`npm -i` away. Even cargo (rust) has an add-on someone has made to give you `cargo add`
Not at the moment, unfortunately.
If you look at the docs for `stack new --help` it says - Usage: stack new PACKAGE_NAME [--bare] [TEMPLATE_NAME] [-p|--param KEY:VALUE] [DIR] [--solver] [--omit-packages] [--force] [--ignore-subdirs] [--help] Create a new project from a template. Run `stack templates' to see available templates. Note: you can also specify a local file or a remote URL as a template. Available options: PACKAGE_NAME A valid package name. --bare Do not create a subdirectory for the project TEMPLATE_NAME Name of a template - can take the form [[service:]username/]template with optional service name (github, gitlab, or bitbucket) and username for the service; or, a local filename such as foo.hsfiles or ~/foo; or, a full URL such as https://example.com/foo.hsfiles. Is that what you were looking for?
Yeah, but If I'm not mistaken I need to add all the "template files" in a single file, which makes it a big hurdle to create the templates. I'm trying out cookiecutter (a python script) now, which seems to do the trick
I'd take a look into the [hint package](http://hackage.haskell.org/package/hint).
Look at the relation between `Free` and `Fix`. newtype Fix f = Fix (f (Fix f)) data Free f a = Pure a | Free (f (Free f a)) data FreeF f a r = PureStep a | FreeStep (f r) -- Free f a = Fix (FreeF f a) So if your `Fix (Term a)` is isomorphic to `Free SomeFunctor a`, `Term a r` must be isomorphic to `FreeF SomeFunctor a r`. In other words, you have to be able to rewrite in the following form: data Term a r = PureStep a | FreeStep (SomeFunctor r) In your `Term`, The parameter `a` is used in two different constructors. So that rewriting is not possible. Is this modification OK? data Term b a r = Value a | WillBeArg (String -&gt; Maybe r) | Area (String -&gt; Maybe r) b ^^^ Here | Func [String] (String -&gt; Maybe r) deriving (Functor, Typeable) type TermX a = Fix (Term a a) If so, now you can use `Free`. data TermF b r = WillBeArg (String -&gt; Maybe r) | Area (String -&gt; Maybe r) b | Func [String] (String -&gt; Maybe r) type TermX a = Free (TermF a) a I don't know whether using `Free` has a benefit or not since I don't know how you interpret this type into something more concrete. Generally speaking, representing it in `Free` is beneficial when You want what `Monad`s have -- `(&gt;&gt;=)` operation and `do` notation. 
Ubuntu Linux
So I realize this is a dead topic at this point, but for my Haskell learning project I decided to write a new ADT generator and accompanying optics for C#: [https://github.com/sourcerist/adt-gen](https://github.com/sourcerist/adt-gen). &amp;#x200B; &amp;#x200B;
http://hackage.haskell.org/package/husk-scheme looks like a cool extension language.
Have you got any explanatory links? In my imagination coinduction is like corecursion or the y-combinator, which would give you totality..
Thanks! No, it doesn't support joins. But it seems it should be possible. Something like this: ```haskell table @(Join '[Person, Car]) &amp; where_ (jfld @Person @"drives" .= jfld @Car @"brand") ``` I'll think about it.
No, that's not a problem for profiling. You can profile with both threaded and non-threaded runtimes.
Not sure what you are asking - could you elaborate, please?
In my wish to better understand recursion schemes I decided to tackle the Advent of Code problems using them. It's gonna be a slow and probably long (and more than likely incomplete :P) process, but I hope to do all 25 days. I'm trying to describe how I solved the problems and some of the stuff I use so that it's helpful to others and my future self :)
This is really nice syntax! I never saw it before, but it applicative clearer. &amp;#x200B; I am going down the a more dependent type / liquid Haskell / Idris route now. I suspect being able to explicitly stating what's required in types might be easier to understand for the average spreadsheet user than other beefier options, usually used in FP..
Let's say a haskell program has access to modules A, B, and C. Would a haskell script executed by hint have access to A, B, and C? Can hint control access to modules?
I think it's meant to refer to the fact that *if* you have a recursive type, then the recursive occurrences are going to be `Rec0` fields, so that's how generics handle recursion. But indeed `Rec0` uniformly marks all the fields of a data type, and I also don't think of those actual "recursive occurrences" differently from other fields. This is pure speculation, but maybe the authors encountered issues with recursion while they were working on this system, and this is a remnant of those problems. Nowadays, the `i` in `K1 i` is redundant. [Looking at the original paper](http://dreixel.net/research/pdf/gdmh.pdf) there used to be another `Par0` that, like `Rec0`, was also defined using `K1`. It was part of the representation of parameterized types like `Maybe` and `[]`, so `Rep` used to be somewhere inbetween the current `Rep` and `Rep1`. In fact, the GHC Generics documentation still has a dangling mention of `Par0`.
FWIW, pandoc uses Lua as an extension language (via \[hslua\]([https://github.com/hslua/hslua](https://github.com/hslua/hslua)).
I think the simplest solution that covers most use cases is defining new records normally, using DuplicateRecordFields so they can have fields with the same name. Then using RecordWildCards/NamedFieldPuns whenever you can to make it easy to use those fields and convert between similar records. For trickier situations use generic-lens so you don't have to deal with field name ambiguity. I think the HKD pattern integrates seamlessly with this approach so you can use that for validations without defining multiple records with the same fields.
Ya I think the original paper distinguishes between when we're using an abstracted parameter and when it's just another unrelated type, and off the top of my head it seems like that's an unnecessary distinction. But I still don't see how that justifies simply ignoring the recursion information and simply marking everything as recursive, because the recursion points definitely do matter in many cases, and it seems like we're just completely losing that information. I do agree it looks like there were issues encountered in the implementation -- my best guess is there are difficulties making this work with mutually-recursive data types and positive/negative occurrences, but honestly those seem like a really obtuse cases and I'd prefer the Generic deriver just bail on hard cases and say "I can't derive generic for this type." As long as it works for free stuff (any data type that can be encoded as a free monad), I'd be happy, and to my intuition that should be doable. But ya, the way the current implementation is just marking `data Ex = Ex Bool` as recursive really throws a wrench in what I'm trying to do. 
I always get confused by this &amp;#x200B; newtype KleisliKind :: (Type -&gt; Type) -&gt; Obj where Kl :: Type -&gt; KleisliKind m &amp;#x200B; the type of `KleisliKind` is `(Type -&gt; Type) -&gt; Obj` ...what's `Obj`? But this means that `KleisliKind` takes a `(Type -&gt; Type)` (the `m`) and returns `Obj`. But `Kl :: Type -&gt; KleisliKind m` does not define `m` and just takes a type, so `m` is a phantom type and that's why you need kind applications? &amp;#x200B;
Yeah, curious about the size of the team and use of the language if /[u/IamfromSpace](https://www.reddit.com/user/IamfromSpace) is able to respond . . . 
That's crazy! This lead me to the ‘about’ page of the official Lua website and found the following trivia: Lua was created at the “Pontifical Catholic University of Rio de Janeiro in Brazi”
The y-combinator is not possible in any total language, and is not related to coinduction. Coinduction and corecursion are synonyms, and they allow one to define possibly infinitely running processes with the property that they never go into an unresponsive loop. See e.g. [this](http://lambda.jstolarek.com/2015/03/the-basics-of-coinduction/) and the links from there.
If this is a "pitch", then it is as much a "pitch" for Haskell and formal methods as it is for Cardano.
Oh yes, it's rather difficult to do something special for actually recursive occurrences of a data type. I did something like that once for [a generic implementation of recursion schemes](https://github.com/Lysxia/generic-recursion-schemes). I think [kind-generics](https://hackage.haskell.org/package/kind-generics) solves that. The issue with GHC Generics is that type parameters are kept as type variables in the generic representation, and we can't match on variables at the type-level without breaking coherence. In kind-generics, type parameters are represented explicitly with constructors, so pattern-matching works again.
&gt; The issue with GHC Generics is that type parameters are kept as type variables in the generic representation Well the generic representation seems to indicate it does take recursive information into account, it's just that apparently GHC does not actually do this when constructing that representation - and GHC of course should have access to this information, given that it's, well, the compiler, and so it can match and compare types and figure that sort of thing out, even though yes, that sort of "pattern matching on types" is not available to us in "user space." Anyway ya, I'll check out some of the other generics approaches - I know there's several others, and I guess the fact that they exist means I'm not the first to hit my head on GHC generics. I also might just bail on trying to do the builtin recursive case and just do it for `Free` and define everything using that. Anyway, thanks for the help and the links, I'll check them out!
I believe you can preload: http://hackage.haskell.org/package/hint-0.9.0/docs/Language-Haskell-Interpreter.html#v:setTopLevelModules Not sure if sandboxing is possible. The usual cheap way of handling that issue is by giving your user a warning that running scripts is dangerous. 
You could rewrite it in the applicative style: addM a b = (+) &lt;$&gt; pure a &lt;*&gt; pure b This Stack Overflow answer explains it a little: https://stackoverflow.com/a/11702411/1274282
And just to make clear, this is equivalent to `pure (a + b)`.
Just my two cents, but you might want to consider nix not as a hurdle you have to go through, but a chance to taste FP ideas applied to the whole OS. Don't regret any moment you spend trying to understand nix.
I think `Language.Haskell.Interpreter.setImports` is how I do sandboxing with hint. 
Assuming `pure a` and `pure b` are stand-ins for something more complicated, and so have to be there: addM a b = (pure a :: IO Integer) &gt;&gt;= (((pure b :: IO Integer) &gt;&gt;=) . ((pure .) . (+)))
I'd be very reluctant to use a package that wasn't even on Hackage. Are there plans to cut a proper release?
I believe there is. Greg said he's never had any luck with hackage so it's been put off :/
yes lua is Portuguese for moon iirc
1. `m` is phantom but I thought we needed [visible kind applications](https://phabricator.haskell.org/D5229) because otherwise `m` is not in scope: `type (--&gt;) = Kleisli m`. Turns out this works (thanks to Sjoerd Visscher) type (--&gt;) = (Kleisli m :: KleisliKind m) 2. Yes we need it, just seeing `kl` isn't enough to convince GHC that it has the shape `Kl _`. See [`#7259` Eta expansion of products in System FC](https://ghc.haskell.org/trac/ghc/ticket/7259) 3. When the category is kind (object)-directed it means we don't need to lug the categories around as arguments. class Category (ob :: Type) where type (--&gt;) :: Cat ob data (-×) :: Cat (ob1, ob2) where ProdCat :: (a --&gt; a') -&gt; (b --&gt; b') -&gt; ('(a, b) -× '(a', b')) compared to the standard approach class Category (cat :: Cat ob) class (×) :: Cat ob1 -&gt; Cat ob2 -&gt; Cat (ob1, ob2) where ProdCat :: cat1 a a' -&gt; cat b b' -&gt; (cat1 × cat2) '(a, b) '(a', b') it gets more unwieldy when things get complicated. This is the same approach /u/edwardkmett uses in [*hask*, under `/old/..`](https://github.com/ekmett/hask/blob/cd4d30e7911dd7cc2da78383fd833272b1ff9303/old/src/Hask/Core.hs) &gt; Third, we use kind-indexing to pick the category. This means it &gt; is harder to talk about `Kleisli` categories, etc. but in exchange &gt; most of the category selection *just works*. A central working &gt; hypothesis of this code is that this is sufficient to talk about &gt; interesting categories, and it certainly results in less verbose &gt; code than more explicit encodings which clutter up every type class &gt; talking about the choice of category.
&gt;addM a b = (pure a :: IO Integer) &gt;&gt;= ((pure b :: IO Integer) &gt;&gt;=) . (pure .) . (+) This is rather ironic, because I used a similar page (from this sub-reddit) to "de-sugar" exactly that in to my original code. Not sure why I thought I'd get a better answer on how to "re-sugar" it! Of course my real issue is that this "applicative style" does not "read naturally" to me, so I wanted to find an alternative.
If only that was the case. The original function has type `Integer -&gt; Integer -&gt; IO Integer`, but your answer has type `(Applicative f, Num a) =&gt; a -&gt; a -&gt; f a`. So it does not work for how I am calling it. (Probably shouldn't have given a stripped down version of my code.)
Thank you, this is the answer I was looking for. But not the answer I wanted. :-) In that I can't "read it" naturally. Where is this syntax actually explained? I've seen a lot of places that give examples, but none that actually explain how it "works".
For what its worth, I am messing around with different versions of the Haskell version of the "Man or Boy test" from here: [https://rosettacode.org/wiki/Man\_or\_boy\_test#Haskell](https://rosettacode.org/wiki/Man_or_boy_test#Haskell). Not that there is anything wrong with that version. I'm just using it as a learning tool. Here's what I have right now: &amp;#x200B; `import` [`Control.Monad.ST`](https://Control.Monad.ST) `(runST)` `import Data.STRef (modifySTRef, newSTRef, readSTRef)` &amp;#x200B; `main = print manOrBoy` &amp;#x200B; `manOrBoy = a 10 1 (-1) (-1) 1 0` &amp;#x200B; `a k x1 x2 x3 x4 x5 = runST $ aST (pure x1) (pure x2) (pure x3) (pure x4) (pure x5) k` `where aST x1 x2 x3 x4 x5 k =` `newSTRef k &gt;&gt;= \ kRef -&gt;` `let b = modifySTRef kRef pred *&gt; readSTRef kRef &gt;&gt;= aST b x1 x2 x3 x4` `in if k &lt;= 0 then (+) &lt;$&gt; x4 &lt;*&gt; x5 else b` I was hoping to replace `(+) &lt;$&gt; x4 &lt;*&gt; x5` with something I found "more readable". But probably this version is best and I just need to get used to it. Probably the closest I'll get is to just use liftA2 as from the original version, i.e.: `if k &lt;= 0 then liftA2 (+) x4 x5 else b`. I was rather hoping for `if k &lt;= 0 then something (x4 + x5) else b` where something represents an already existing standard function (`pure (x4 + x5)` does not work). Regardless, it's been fun/interesting/frustrating getting this far.
This is not really a problem. `Integer` is an instance of `Num` and `IO` an instance of `Applicative`. The more general type can be specialized to yours.
thanks for the answers! Regarding 2: You attach `kl ~ Kl (UnKl kl)` to the class `UnKl_` in order to set `type Object = UnKl_`, so that the `kl ~ Kl (UnKl kl)` statement is in scope? We need this because we can only partially apply type-classes and something like `type WrapUnwrap kl = kl ~ Kl (UnKl kl)` is not really useful?
I read the post, plus the comment at the end. I need to spend some more time thinking about it, but statement that: &amp;#x200B; 'Totality can also be Turing Complete' &amp;#x200B; is sort of breathtaking. &amp;#x200B; Thanks!
I can go over it step by step. :) First, if you don't know the `(.)` operator, it's defined like this: (.) :: (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c f . g = \x -&gt; f (g x) So writing `\x -&gt; f (g x)` is the same as writing `\x -&gt; (f . g) x`, which is again the same as just writing `f . g`. This is known as function composition, or just composition. Now, look at the function `\z -&gt; pure $ (+) y z`. If we add some parentheses, making it `\z -&gt; pure ((+) y z)`, then it's exactly the same as `\z -&gt; f (g z)` where f is pure, and g is `(+) y` (remember that function application is left-associative, so `(+) y z` is `((+) y) z`). So we can rewrite it to use the `(.)` operator, which means we have `pure . (+) y`. Now we can turn your original function: addM a b = (pure a :: IO Integer) &gt;&gt;= \ y -&gt; (pure b :: IO Integer) &gt;&gt;= \ z -&gt; pure $ (+) y z Into this slightly neater version: addM a b = (pure a :: IO Integer) &gt;&gt;= \y -&gt; (pure b :: IO Integer) &gt;&gt;= pure . (+) y The next step is to add some parentheses: addM a b = (pure a :: IO Integer) &gt;&gt;= \y -&gt; ((pure b :: IO Integer) &gt;&gt;=) (pure . (+) y) Now, looking at the remaining anonymous function, `\y -&gt; ((pure b :: IO Integer) &gt;&gt;=) (pure . (+) y)`, we'll have to do a little more work to get it onto the right form. The problem is that `pure . (+) y` is not just a function applied to y - it's `(+)` applied to y and then composed with something else. We can, however, rewrite it to `(pure .) ((+) y)` - all I've done is add some parentheses. Figuring out where exactly to add those can be a bit tricky, and something that you get good at with practice/experience. Anyway, now we have `\y -&gt; ((pure b :: IO Integer) &gt;&gt;=) ((pure .) ((+) y))`, which has the right form. It's `\y -&gt; f (g (h y))` where f is `((pure b :: IO Integer) &gt;&gt;=)`, g is `(pure .)` and h is `(+)`. `\y -&gt; f (g (h y))` can be rewritten as `f . g . h`, so our function can be rewritten as `((pure b :: IO Integer) &gt;&gt;=) . (pure .) . (+)`. And now all we have to do is plug it into the surrounding function: addM a b = (pure a :: IO Integer) &gt;&gt;= ((pure b :: IO Integer) &gt;&gt;=) . (pure .) . (+) I hope all of that made sense! A neat trick to remember is that whenever you have a 1-argument function (like `pure`), and a two-argument function (like `(+)`), you can compose them with two `(.)`s, like this: `(pure .) . (+)`.
&gt; I was rather hoping for if k &lt;= 0 then something (x4 + x5) else b You can make that work by creating the overlappable `instance (Num n, Applicative a) =&gt; Num (a n)`. Then `something` can be `id` (or dropped entirely). It might make it "easier to read", but it definitely also makes it harder to understand what is really going on. It's not like you are adding two plain values; you are running two actions that may modify memory (in a particular order), and then adding their results.
wow that's a really interesting exercise gonna steal that :D
Haha! Great we can trade notes ;)
Does putting a package on hackage involve luck? It seems very easy. 
No luck meaning has had trouble with it. I'm sure it can be figured out.
&gt; it seems like it's basically the cartesian product or permutation of 10 different GHC extensions. Could you give a few points within that large space as examples of what you're looking for? Are the following examples of points within that space, or are you thinking of some wilder variants such as extensible records? data Person1 = Person1 Age Int data Person2 = Person2 { name :: String, age :: Int } data Person3 = Person3 { personName :: String, personAge :: Int } data Person4 = Person4 { _personName :: String, _personAge :: Int } makeLenses 'Person4 
So, was your real question "How do I create a new stack template?"?
Indeed. Note that hint currently requires a ghc installation at runtime, even though it doesn't use the ghc executable, because the ghci which hint embeds inside your program needs to load some libraries and it currently looks for them wherever your ghc was installed at compile-time.
Given that gloss only supports 2D rendering, I am impressed that you managed to coerce it into rendering a 3D cube!
I think a better strategy would be to learn to love applicative style. It's a bit awkward that no nice applicative syntax exists for infix operators, but other than that, the similarity between "pure" code and applicative style is entirely desirable: f x y f &lt;$&gt; x &lt;*&gt; y
I think some examples of what you've been doing would be really helpful
&gt; From a psychological point of view, people's ability to generate and parse longish sentences suggests that the underlying algorithms must be computationally tractable. I don't think that "polynomial time" is the right stand-in for "computationally tractable". H-M type inference has exponential behavior is some well-known cases, but it's still a very good approach to type inference, and computationally tractable for almost all real programs. Understanding sentences like "Buffalo Buffalo Buffalo Buffalo Buffalo" (and longer versions) hints to me that we might have some non-polynomial-time approach to understanding sentences, but we have something -- probably in the lizard brain -- that interrupts the process (leaving us mildly bemused) if it takes too long, so it doesn't interfere with FFFF processing or other things evolution prioritized over language.
Joins are one of the core features of DBMS. Otherwise, what would you need a DBMS for? You can simply serialize and deserialize everything on a shared filesystem. (I guess you could use an index to filter a table and avoid some disk IO.) --- [This topic comes up fairly regularly here.](https://www.reddit.com/r/haskell/comments/80xmpi/monthly_hask_anything_march_2018/dwaqfx6/?context=3)
(for reference: HKD means "higher-kinded data", since when you say something like data Foo f = Foo { unFoo :: f Int } you can see `f` takes a type parameter. In this case the parameter is a concrete type so `f` is `* -&gt; *` )
Thanks! I actually didn't know this before I started. I knew that Gloss was based on OpenGL, so I figured it would provide 3D-rendering, even though it is advertised as primarily 2D. Moreover, at one of the Austin Haskell Meetups, one of the attendees showed some 3D wire-frame rendering he had done with Gloss that I though was pretty cool, so I figured Gloss also provided 3D support. However, when I actually started playing around with it, I found that I would need to handle the 3D rendering myself, which was a learning experience in itself. &amp;#x200B;
Well, at my current work we're using Haskell to query an existing database managed by Rails. So far we simply haven't had the need for joins in the Haskell part of the code. (This is also my only experience with databases...) But at least there doesn't seem to be anything fundamentally preventing joins in my approach. If there are other, more full-fledged libraries that provide similar ease of expression, I'd be happy to use those. I'll check out the link you provided.
Indeed, you can write a coinductive Turing interpreter in a total language. The difference is that in a total language there *must* be a way inside the program to timeout or interrupt an interpreter, but not so in a partial language. You can argue that in practice you get the same observable capability in both cases, since you can never obverse an actual infinity of steps in a partial language, so you might as well call the total coinductive languge "Turing complete" as well. But I think at this point we're just nitpicking definitions.
Well, since base-4.11, we have: import Data.Functor((&lt;&amp;&gt;)) x + y x &lt;&amp;&gt; (+) &lt;*&gt; y 
I posted it on both places as I am new to Reddit. I was a little confused. But, yes, I did see what those people have said because I use notifications.
Ok, this will be helpful. Thank you!
What type of template is it that you've made?
Thank you for the translation!
Ok, great thanks!
Thanks for the info!
Thank you!
The pointfree style of this would be addM = liftA2 (+) It takes a binary operation and lifts it into a binary operation that works on applicatives.
While Nike doesn't have dedicated Haskell teams, we have a number of engineers across the org make up a growing Haskell community. We've got a mix of advocates/learners/etc and we're always on the look out for places where Haskell would be a good fit for a project. I should also point out that while I work for Nike I don't speak for Nike. My entirely personal hope is that things like FaaS allow companies to start using Haskell with a lower barrier of entry. Smaller components mean we can freely try new things without making sweeping changes to large systems.
[removed]
&gt; It's a bit awkward that no nice applicative syntax exists for infix operators It's a bit unfortunate that `&lt;*&gt;` was "stolen", but for everything except `*`, you can follow the `&lt;$&gt;` style and do stuff like: &lt;+&gt; :: (Applicative f, Num a) =&gt; f a -&gt; f a -&gt; f a &lt;+&gt; = liftA2 (+) &lt;-&gt; :: (Applicative f, Num a) =&gt; f a -&gt; f a -&gt; f a &lt;-&gt; = liftA2 (-) &lt;:&gt; :: Applicative f =&gt; f a -&gt; f [a] -&gt; f [a] &lt;:&gt; = liftA2 (:) etc.
Can you form a category over a type class? I.e. all objects have an instance for a specific type class.
I understand what it means. :) I just thought out putting a package on hackage has been very easy. 
No, I was just wondering what tool people are using for this kind of thing
So I've been struggling with this for the past couple of days, and it seems like everyone has a different answer.. I'm not sure if it's the right answer, but my favorite so far is to use \`makeLenses\` and access it with \`myWrappedValue\^.coerced\`
Thank you for writing this! This is the best part about AoC, it's great for learning new ways to think about solving problems with code, especially reading other people's ideas
Also, try playing around with http://pointfree.io/ 
I did experiment with using Haskell as an extension language for pandoc (via hint and the bare ghc API). But I abandoned this approach for several reasons: - this added quite a lot to the size of the executable - scripts were somewhat slow to load - pandoc users aren't likely to know Haskell Using lua (via hslua) has worked really well. We make Haskell functions for manipulating the pandoc AST available as lua functions, so most lua filters are comparable in concision and elegance to Haskell filters that do the same thing. And performance is great.
Thanks! That means a lot 😍
You can, but it's not "automatic" like the `f &lt;$&gt; x &lt;*&gt; y` syntax, which works with any `f`, without any additional definitions.
Love it! Looked into recursion schemes once long ago and put them on back burner due to perceived complexity vs usefulness. The part about Algebra being a synonym for `f a -&gt; a` reminds me of `extract :: w a -&gt; a` in Comonads. Is the relation that they’re functors or is there more to it? (Or maybe I’m completely wrong!)
 Is there any way to get around this restriction? I'm trying to distribute a `hint`-enabled application as a standalone program, and so far I haven't succeeded. (See also [this SO question](https://stackoverflow.com/questions/51064855/use-dependencies-in-hint-when-installing), where I first asked this.)
I'm writing a library which uses generics-eot. Parts os this library are to be used server-side, compiled with GHC, and some client-side with GHCJS. I have split some of this library into smaller packages to minimize the size and dependencies in the GHCJS part. ..But I am having an error when building. I am using `reflex-platoform` Preprocessing library for extra-1.6.9.. Building library for extra-1.6.9.. [ 1 of 19] Compiling Data.IORef.Extra ( src/Data/IORef/Extra.hs, dist/build/Data/IORef/Extra.js_o ) [ 2 of 19] Compiling Data.Tuple.Extra ( src/Data/Tuple/Extra.hs, dist/build/Data/Tuple/Extra.js_o ) [ 3 of 19] Compiling Data.Typeable.Extra ( src/Data/Typeable/Extra.hs, dist/build/Data/Typeable/Extra.js_o ) [ 4 of 19] Compiling Numeric.Extra ( src/Numeric/Extra.hs, dist/build/Numeric/Extra.js_o ) [ 5 of 19] Compiling Partial ( src/Partial.hs, dist/build/Partial.js_o ) [ 6 of 19] Compiling Data.List.Extra ( src/Data/List/Extra.hs, dist/build/Data/List/Extra.js_o ) [ 7 of 19] Compiling Data.Version.Extra ( src/Data/Version/Extra.hs, dist/build/Data/Version/Extra.js_o ) [ 8 of 19] Compiling Data.Either.Extra ( src/Data/Either/Extra.hs, dist/build/Data/Either/Extra.js_o ) [ 9 of 19] Compiling Control.Exception.Extra ( src/Control/Exception/Extra.hs, dist/build/Control/Exception/Extra.js_o ) [10 of 19] Compiling Control.Monad.Extra ( src/Control/Monad/Extra.hs, dist/build/Control/Monad/Extra.js_o ) [11 of 19] Compiling Control.Concurrent.Extra ( src/Control/Concurrent/Extra.hs, dist/build/Control/Concurrent/Extra.js_o ) [12 of 19] Compiling System.Directory.Extra ( src/System/Directory/Extra.hs, dist/build/System/Directory/Extra.js_o ) [13 of 19] Compiling System.Environment.Extra ( src/System/Environment/Extra.hs, dist/build/System/Environment/Extra.js_o ) [14 of 19] Compiling System.IO.Extra ( src/System/IO/Extra.hs, dist/build/System/IO/Extra.js_o ) [15 of 19] Compiling System.Info.Extra ( src/System/Info/Extra.hs, dist/build/System/Info/Extra.js_o ) [16 of 19] Compiling System.Process.Extra ( src/System/Process/Extra.hs, dist/build/System/Process/Extra.js_o ) [17 of 19] Compiling System.Time.Extra ( src/System/Time/Extra.hs, dist/build/System/Time/Extra.js_o ) [18 of 19] Compiling Text.Read.Extra ( src/Text/Read/Extra.hs, dist/build/Text/Read/Extra.js_o ) [19 of 19] Compiling Extra ( src/Extra.hs, dist/build/Extra.js_o ) Preprocessing test suite 'extra-test' for extra-1.6.9.. Building test suite 'extra-test' for extra-1.6.9.. [1 of 4] Compiling TestUtil ( test/TestUtil.hs, dist/build/extra-test/extra-test-tmp/TestUtil.js_o ) test/TestUtil.hs:10:6: error: Conflicting exports for ‘isWindows’: ‘module X’ exports ‘X.isWindows’ imported from ‘System.FilePath’ at test/TestUtil.hs:33:1-27 (and originally defined in ‘System.FilePath.Posix’) ‘module X’ exports ‘X.isWindows’ imported from ‘System.Info.Extra’ at test/TestUtil.hs:34:1-29 | 10 | ,module X | ^^^^^^^^ builder for '/nix/store/33ki7l442cjmvlf012r60nf9ap6jnhmf-extra-1.6.9.drv' failed with exit code 1 building '/nix/store/lqcy1fbjpigbp6rlcqikhr568lzsw2pq-logging-facade-0.3.0.drv'... cannot build derivation '/nix/store/xqv37f3m18j7l4g1xp7c6c405k8bdyg0-shake-0.16.4.drv': 1 dependencies couldn't be built cannot build derivation '/nix/store/j8n41pjavh2zrr79g2f9lc6gbl9a2wzk-generics-eot-0.4.drv': 1 dependencies couldn't be built building '/nix/store/0djxzar7agcbgkndm0fidngnhq1nvxxp-vault-0.3.1.2.drv'... cannot build derivation '/nix/store/rzdzysalrr6f3qs6hn5m760aipb4471f-telescope-0.1.0.0.drv': 1 dependencies couldn't be built error: build of '/nix/store/rzdzysalrr6f3qs6hn5m760aipb4471f-telescope-0.1.0.0.drv' failed 
An algebra normally pairs with a monad, and a coalgebra with a comonad. With a monad, you have `return :: a -&gt; m a` 'for free', so the interesting question is: when do you have an interpretation going the other way `m a -&gt; a`? If the monad is syntax, the algebra represents a semantics. Dualize all that for comonads/coalgebra.
I can't find the module they come from, but with (&lt;^) = flip (&lt;$&gt;) (^&gt;) = &lt;*&gt; we can write x &lt;^(*)^&gt; y for any operator. Maybe fixity needs tweaking but you get the idea.
Using `TypeApplication`, we can specialize `addM`'s type explicitly. addM a b :: (Applicative f, Num a) =&gt; a -&gt; a -&gt; f a addM a b = (+) &lt;$&gt; pure a &lt;*&gt; pure b Calling `addM` with explicit type `Integer -&gt; Integer -&gt; IO Integer` addM @IO @Integer 1 2
This is repulsive and fascinating at the same time. I don't know if I want to cry tears of joy, or throw up.
One type spec should be enough there. `(pure .) . (+) :: IO Integer` should be enough too.
I agree with much of what you say here regarding the current state of Haskell, but I feel compelled to respond to a couple of points: 1. There is a lot of effort in the Haskell community to improve tooling. Like, a ton. There aren't many highly polished solutions, and they don't have super fancy corporate backing, but that's not the same thing as saying the community is putting 'little effort' into solving the situation. There are a lot of very nice people working very hard on improving the tooling situation, and it's a little rude to dismiss their efforts. 2. Your characterization of Haskell extensions as a whole is wildly inaccurate. The only extension that actually sees widespread use that I would consider to be characterized in this manner would be CPP, which I agree is a bit of a hack-job and a workaround for what could be a more well developed feature set. The rest are doing exactly what they're supposed to do - Allowing a proving ground for controversial features without breaking run-time guarantees or breaking existing codebases. I get that this feels weird and hacky coming from other languages, but it's really a much cleaner and saner process than it appears at first glance. Most of the extensions that aren't purely syntactic sugar are more like file-specific compiler flags than anything else. Aside from those two points, I think you're spot on regarding libraries and documentation, most especially for interop with things external to the ecosystem. There are notable exceptions for sure, but the norm is poorly documented, low level wrappers that assume an intimate knowledge of the technology being wrapped, and may not even expose a great deal of the surface area.
Honestly I find that going through these kinds of iterations 'manually' while writing code in an unfamiliar domain can be a useful tool for helping me fully model a problem. Sometimes these early lessons are not things we somehow evolve beyond, but just steps in a process that we learn to internalize so completely that we don't remember we're still doing it. I see no harm in continuing to push the partiality doctrine, as long as we also strive to surface techniques for structural avoidance - Crashing your program instead of doing the right thing is usually better than doing the wrong thing, but it's still something you'll need to learn how to fix.
Within the context of measure theory.
Hello, I'm new to Haskell. I'm having a hard time identifying which type of array to use. I want to implement the following scenario: \- Main thread initializes a mutable array (each value will have a version, I looked into Tickets maybe I'll use them). \- Multiple threads will be forked: \* Threads should access values concurrently with no wait. \* they should also write values to the array with no wait (using compare&amp;swap which returns false if the value can not be updated). &amp;#x200B; Can you help to identify which array type to use in this case?
Please describe to me a scenario in a program you feel is of intermediate complexity that is not an edge-case in which the use of `Control.Monad.ST` is necessary and advisable.
HaskellR embeds R. The project included an interaction prompt
Just like we have the arrow [`(:-) :: Cat Constraint`](https://hackage.haskell.org/package/constraints-0.8/docs/Data-Constraint.html#t::-45-) instance Category Constraint where type (--&gt;) = (:-) we can define newtype (:~) :: Cat (ob -&gt; Constraint) where Sub1 :: (forall x. cls xx =&gt; Dict (cls' xx)) -&gt; (cls :~ cls') instance Category (:~) where type (--&gt;) = (:~) .. does that answer the question?
You want to look at the `atomic-primops` package, and the array types in `primitive` the latter is just a very thin wrapper around GHC's build-in array types. These are Array/MutableArray which are boxed (i.e. operationally they are arrays of pointers to things on the heap), and ByteArray/MutableByteArray, which are just arrays of bytes. Other array-type packages are built on these primitives, as well.
I'll probably have to read this about 100 times before I understand it, but thanks!
I used this a couple of times, but I can't get it to work for this.
Thank you, I'll read about them.
Described this way it does indeed become fairly readable. Thanks!
Checkout the signature of `foldM`: `foldM :: (Foldable t, Monad m) =&gt; (b -&gt; a -&gt; m b) -&gt; b -&gt; t a -&gt; m b ` and the translation to `do` syntax: do a2 &lt;- f a1 x1 a3 &lt;- f a2 x2 ... f am xm `foldM` binds over the result of each application of `binSmalls` using the `Maybe Monad`. In other words, each application of `binSmalls` creates a `Maybe b` which is then 'unwrapped' and used in the next application of `binSmalls` (unless it hits a `Nothing` then it short circuits to the end of the fold). 
Note that this example uses [`foldM`](http://hackage.haskell.org/package/base-4.12.0.0/docs/Control-Monad.html#v:foldM), not (`foldl`)(http://hackage.haskell.org/package/base-4.12.0.0/docs/Data-List.html#v:foldl)! Compare their types, specialized to your example: foldl :: (Int -&gt; Int -&gt; Int) -&gt; Int -&gt; [Int] -&gt; Int foldM :: (Int -&gt; Int -&gt; Maybe Int) -&gt; Int -&gt; [Int] -&gt; Maybe Int `foldl` does take the value returned by the binary function and gives it back to the binary function's as its first parameter, in this case `acc`. So if you were using `foldl`, you'd be right to be concerned, and the code wouldn't type check. But you're using `foldM`, which uses bind (`&gt;&gt;=`) in order to obtain the `Int` if the `Maybe Int` is a `Just`, and pass that `Int` to the binary function as its first parameter, in this case `acc`. If it's a `Nothing` instead, then we can't continue to traverse the list, and the whole `foldM` call returns `Nothing`.
[turtle](https://hackage.haskell.org/package/turtle) is sort of a shell scripting edsl there are some other packages on hackage but I can't speak for their quality [https://hackage.haskell.org/package/HsPerl5](https://hackage.haskell.org/package/HsPerl5) \- PERL [https://hackage.haskell.org/package/BASIC-0.1.5.0](https://hackage.haskell.org/package/BASIC-0.1.5.0) \- simplified basic as far as scripting edsls go hslua is probably as good as it's going to get
Lua is a fine language. A tiny one. But a fine one. It really is what you make it. That is presumably why so many hate it. 
Javascript with hs-duktape.
Probably not exactly what you're looking for, but Jetbrain's IntelliJ + IntelliJ-Haskell plugin (bèta branch, as stable doesn't play well with GHC 8.*) 
[removed]
Why does `GHC.Generics`'s `Rep a` has kind `* -&gt; *`?
How about [dhall](https://hackage.haskell.org/package/dhall)? Dhall can be directly interpreted into a Haskell data type representing your script (which can be interpreted by Haskell), is non-turing-complete (so scripts can't be structurally infinite), and highly extensible. The only thing is that I don't think it supports any sugar for do-notation-like syntax.
dhall is a configuration langauge. It's not a general-purpose scripting language.
Indeed, it is not. But it can be used to write scripts.
So jealous :) That's really cool! Sure, why not. Why not also do some stuff like katas on CodeWars or Project Euler (some katas on CodeWars are written to be solvable in both Python and Haskell). Yeah, LYAH is pretty fun, and two of my friends from two different schools used it in their class this past semester (that was the recommended "text" by the professors). If you're curious about Haskell, I'd definitely get started asap. You'll get more out of the class (or frustrate the professor accordingly with too many questions) that way. Have fun!
Use GHC API, and embed Haskell in your Haskell program :D
I tend to use a cabal test-suite for unit tests, and treat integration tests as their own executable independent of the main cabal package. I like to be able to to choose between a shell script, a haskell script, a haskell executable, or whatever feels right, for the integration tests. I usually don't plan for hackage-matrix-builder or stackage to run my integration tests.
Not exactly true. Unless you need Turing completeness. But for an embedded scripting language, Turing incompleteness is arguably a feature. Vanilla Dhall is pretty limited &amp; oriented towards configuration, true. But the Dhall AST type is very extensible, so you can really make it be whatever you want. And you get a really nice type system on top of it. [I did some work here](https://github.com/ramirez7/dalek) a while back to make the Dhall AST highly extensible. It isn't documented well (outside of Haddocks) and Dhall itself has probably drifted away from my requirements. But at my last job I was using extended Dhall (`dalek`) to script map-reduce jobs. It was all very experimental, but I was able to create some really cool APIs that felt like working with Haskell GADTs, Data Kinds, type lits, etc. Dhall was still pretty verbose though due to no inference. I'd say that was the biggest drawback.
If you want a Lisp-looking language, you can always parse s-expressions with `s-cargot` and interpret them yourself.
It's not used by `Rep`, but by `Generic1`'s `Rep1`. It's a result of having `Generic` and `Generic1` share the same constructors.
Almost what `hint` does.
can I ask why you want to embed a scripting language in there? it might be easier to use zeromq /gRPC for message passing between applications 
Something very strange is going on, because`isWindows` is not exported from `System.FilePath.Posix`. 1. Maybe your distribution did something to the `filepath` package. 2. Or maybe GHCJS is ignoring the export list. I also had a hard time finding which package needed those dependencies. It turns out it's the test suite of `generics-eot`. Does nix or something else in your toolchain necessarily build test suites? You might want to disable that. It happens often that they have a much bigger dependency footprint than the user-facing part of the package. 
Is there a place where people have shared Haskell solutions to AoC? I started AoC a bit late, but I was hoping to compete AoC in Haskell to completion. Keep us updated OP on your progress!
Scripting *is* configuration! You haven't explained what you want to do, but I would also encourage looking at Dhall.
Indeed, I used embedding a scripting language as a fun distraction from my real life. I used zeromq in the past to create remote plugins. It required too much effort for a quick project because I had to formally document the protocol. I concluded that I should just create a haskell library and let haskell users create a program with it. Xmonad, propellor, yi, and various other haskell applications can be configured in this way.
do I understand correctly that want to use something like python script as input/config for the library? Riemann http://riemann.io/ uses clojure as it’s configuration language. maybe you can get ideas from there. how about creating a haskell based dsl for configurations?
I am not going to answer your question here. But if the goal is readability, have you considered do-notation? ``` addM a b = do y &lt;- pure a z &lt;- pure b pure (y + z) ``` 
But it's not functional at all (yeah ok you can work with functions but it doesn't work well). Lua with types and a bit more functionality shouldn't be that hard to implement tho...
Thank you very much for the investigation! I am not really familiar with nix, but I opened an issue on the reflex-platform repo about how to skip the test suites https://github.com/reflex-frp/reflex-platform/issues/434.
Yeah, point-free style makes you feel sweet spot (of such), whole point-free can be esoteric though. 
I actually started with that. One of my goals for this was not using do notation.
The category I was looking for is FinOrd. It's a **skeleton** of `FinSet`; which the Wikipedia article I linked points out. &gt; In FinOrd, the categorical product of two objects n and m is given by the ordinal product n · m, So my use `fst` and `snd` for product projections should be ok. --- &gt; Fin (n*m) is not the product of finite sets. No it isn't, but it's a product of finite ordinals. Which is (category-wise) equivalent, so very very close. 
Yes indeed, the conclusions that can be drawn from the fact that people are usually able to successfully parse sentences are quite weak. (Chomsky used to make roughly this point when people would complain about various versions of transformational grammar being too powerful.) I'm not sure how much garden path sentences like the "buffalo" example tell us with regard to computational complexity. People often seem to give up on alternative parses long before there's any risk of exponential blow up. For example, something as simple as "The horse raced past the barn fell" (where there's only one alternative parse of the first six words) often gives rise to a garden path effect.
Lua is actually quite nice for functional programming. Sure, the syntax for anonymous functions is a bit clunky, but that's to be expected for a small language with almost no syntax sugar. Example: `map({1, 2, 3}, function (x) return x + 1 end)` This isn't too bad, is it? I *do* miss stronger types when programming in Lua, but that's a completely different topic. At least it doesn't do crazy type conversions like JavaScript or PHP. And let's not forget that it's a scripting language, after all.
Actually OpenGL does not really support 3D too. It works in a 2D screen space and you have to do all the matrix work by yourself to transform 3d information to the 2D space. OpenGL just adds an hardware accelerated Z-buffer which is highly convenient for handling occlusion (i.e. "which primitive is the first in front of the camera). From what I quickly saw in the source code, OP is handling occlusion using "painter algorithm", he displays the square in the right order based on a depth per square. This works well for this setup, but will start to generate artifacts if he animates the cube. I really love this project because I did something similar in 2004, except that it was in free pascal ;) Good work OP!
I guess it's ok, but if you're going to embed it in haskell, creating syntactic sugar shouldn't be that hard anyway
You may find my blog post with introduction to both build tools (including installation steps) useful: * https://kowainik.github.io/posts/2018-06-21-haskell-build-tools You can compare workflows with both `cabal` and `stack` and see how you can manage to get your stuff done :)
And a weird one (arrays are indexed from 1)
Lua is kind of a scheme with records instead of tuples and strange syntax. Yes it does have proper tail calls.
No. You misunderstood. I was dreaming about writing things like hexchat plugins in haskell. But, I realized that I am not going to create programs that need plugins. I realized that I might want to configure something in haskell in the future.
I just don't like it having state, else I quite like lua
r/surrealmemes approves your desire to _BECOME_ stateless.
No weirder than Fortran, Mathemactica, Julia, and R. ;)
For v2 cabal-install, I think that you should be able to use `cabal v2-run -v0 pandoc` to invoke the program under test (though that'll could be too slow if you're doing it many many times). Note that this won't necessarily use the executable you've just built, but might build a fresh one if the build options have changed somehow; I'm not sure if that will matter. So you might be able to do something like: case buildSystem of Stack -&gt; execve "XXX/pandoc/pandoc" argv CabalV1 -&gt; execve "XXX/pandoc/pandoc" argv CabalV2 -&gt; execve "cabal" $ ["new-run", "-v0", "pandoc", "--"] ++ argv I'm not sure this satisfies your desire for something less hackish, but it's likely to be less brittle than hard-coding paths.
Yes, there is a way to get around this restriction, see [my proof of concept](https://github.com/gelisam/deploy-hint/) and the discussion on [issue 3](https://github.com/haskell-hint/hint/issues/3) and [issue 80](https://github.com/haskell-hint/hint/issues/80).
I don't know if it was not well articulated really. Michael et. al. set out to solve a specific problem. It turned out that a number of us had solutions of varying quality yo the same problem. We had built two Haskell build systems, one on WAF and the the other on shake that allowed us to build the roughly two hundred packages that were in our codebase in one go. You can see a writeup on what we did with WAF here: [https://breaks.for.alienz.org/blog/2011/10/28/building-large-haskell-projects-with-waf/](https://breaks.for.alienz.org/blog/2011/10/28/building-large-haskell-projects-with-waf/) I think there was simply a difference in workflows. It was annoying but fine that the cabal "team" (I don't know if they think of themselves as a team) had very different ideas about what the right workflow was. I was thinking about trying to marshal support to build yet another tool when Michael reached out to solicit our input on what eventually became stack. I has just happy I could spend my day doing things other then worrying about building and maintaining a build system. Given the number of other people that participated in the discussion, a number of companies had built and were maintaining custom build systems. Maybe cabal would have added whatever features they have added even if stack had not been built. I have not really used cabal on its own since 2011 so I can't really comment on how applicable whatever solutions have been built there are. I tend to think something would have happened but stack was a great forcing function.
That makes sense. Thank you!
Expanded link: https://functional.works-hub.com/jobs/senior-haskell-engineers-in-bengaluru-india-4a700
hint *doesn't* require ghc installation. It's a bit fiddly to distribute hint binaries without ghc, but apparently it is possible. See this issue: [https://github.com/haskell-hint/hint/issues/3](https://github.com/haskell-hint/hint/issues/3) I'm struggling with it though, so definitely on the look out for easier options..
Aside from syntax (semicolon rule, anyone), type conversions, and sanity when embedding pretty much the only difference between lua and JS is that lua does have proper tail calls. They're very similar languages. PHP... I'm not sure it even has something that could be, in good conscience, be called "semantics".
https://vaibhavsagar.com/blog/2017/05/29/imperative-haskell/
Well, I approve r/surrealmemes' desire to not longer exist exist exist exist
Do that if you don't mind to slowing down your compilation times upto desperation
Your own. 
Ps: if you need guidance, write me a PM
Some great explanations already, but I'd like to add that you should also try implement foldM! :) I think that will help understand how it works
Yup, that's pretty firmly in the realm of shit most people wouldn't reach for as a first or second option when writing Haskell.
What's `Just 2 + Nothing` ?
big fan of Hasura! Sadly this is not for me atm
That just raises the question: how do we get `buildSystem` from within the test suite? 
oke, a big one. Can I also work with ghcid 
What's your point? You asked for &gt;a program you feel is of intermediate complexity that is not an edge-case and I provided not one, but *two* examples.
[https://s3.amazonaws.com/hackage.fpcomplete.com/](https://s3.amazonaws.com/hackage.fpcomplete.com/) this site is down.
Yeah, though it's not great to do in the IDE directly, as you can't use multiple terminals at the same time (AFAIK).
Are you sure this isn't an [X-Y problem](http://xyproblem.info/)? This doesn't sound like an end goal, and it may not be the most "idomatically Haskell" way to reach your real goal.
Bummer
Can you elaborate? I'm new to Haskell and so far my projects have been too trivial to notice the compile times.
makeLenses uses Template Haskell (slang: TH) which slow down haskell compilation a loooot
Might be worth mentioning how this differs to threepenny-gui: https://github.com/HeinrichApfelmus/threepenny-gui
haha is this a brazilian slang or not? 
Behold the advent of 7 character operators! 
"suavemente" means "softly". Not really a slang.
Ah. well I don't imagine I'll be giving up lenses any time soon.. I've been using them in other languages for years and quite enjoy them. I can see how it would increase compile times, but I feel like that would be offset by the fact that the VSCode extension tells me what the "zoomed in" type is with each lens combinator. I'm really impressed with how far the development environment has come since my previous (failed) attempt to learn Haskell 6 years ago.
It's certainly at least a song: [https://www.youtube.com/watch?v=WPiEbYSF9kE](https://www.youtube.com/watch?v=WPiEbYSF9kE)
Do we have an actual spec for dhall? I wanted to implement a parser for it, but I keep getting pointed at the tutorial, which seems swamped with inane examples instead of providing actual specifications, though maybe those come later, but I couldn't find a link to a eBNF or similar grammar.
Well, it's either `Just 2` or `Nothing`, depends on context.
I want to implement something similar to the data structure in [this](https://www.cs.cmu.edu/%7Erwh/papers/farray/popl17.pdf) paper (Parallel Functional Arrays). I'm looking for the most efficient way to handle mutable arrays in Haskell. I think I'll be using unboxed arrays. The main array will contain elements of this type (Int,Int, reference to another array), I might also put this in a Ticket so that it can be used with casIORef. 
Ah did you mean that an arrow `a --&gt; b` is `(Monoid a, Monoid b) =&gt; (a --&gt; b)` modulo kind-wrapping? In that case you would define a kind 'tag' newtype AlgKind :: (ob -&gt; Constraint) -&gt; Type where AlgK :: forall (ob :: Obj) (cls :: ob -&gt; Constraint). ob -&gt; AlgKind cls indexing data Alg (cls :: ob -&gt; Constraint) :: Cat (AlgKind cls) where MkAlg :: (cls a, cls b) =&gt; (a --&gt; b) -&gt; (Alg cls) (AlgK a) (AlgK b) Defining the `Category` instance is difficult because of the `id :: Ob a =&gt; a --&gt; a` constraint. Does anyone know of better ways of writing this -- Same as before type family UnAlgK (alg :: AlgKind (cls :: ob -&gt; Constraint)) :: ob where UnAlgK (AlgK alg) = alg -- Everything with an UnAlg_ constraint has shape (AlgK _) class AlgK (UnAlgK algK) ~ algK_a =&gt; UnAlg_ algK_a instance AlgK (UnAlgK algK) ~ algK_a =&gt; UnAlg_ algK_a -- LiftCls (AlgK @_ @Eq a) -- entails -- Eq a class cls (UnAlgK algK) =&gt; LiftCls (algK :: AlgKind cls) instance cls (UnAlgK algK) =&gt; LiftCls (algK :: AlgKind cls) -- LiftOb (AlgK @_ @Eq a) -- entails -- Ob a class Ob (UnAlgK algK) =&gt; LiftOb algK instance Ob (UnAlgK algK) =&gt; LiftOb algK Maybe it is inherent in wrapping the kinds, I have tried tagging them separately with [`TypeFamilyDependencies`](https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/glasgow_exts.html#extension-TypeFamilyDependencies) which might be more powerful but I want to see the limitations of this. Anyway, here is the final `Category (AlgKind cls)` instance: instance Category ob =&gt; Category (AlgKind @ob cls) where type (--&gt;) @(AlgKind cls) = Alg cls type Ob @(AlgKind cls) = UnAlg_ @ob @cls &amp; LiftCls @ob @cls &amp; LiftOb @ob @cls id :: cls a =&gt; Ob a =&gt; Alg cls (AlgK a) (AlgK a) id = MkAlg id (&gt;) :: Alg cls algK_a algK_b -&gt; Alg cls algK_b algK_c -&gt; Alg cls algK_a algK_c MkAlg f &gt; MkAlg g = MkAlg (f &gt; g)
Is this close to what you are looking for? https://github.com/dhall-lang/dhall-lang/blob/master/standard/dhall.abnf
This looks very interesting, but such long blog posts are a bit daunting and I personally find them hard to follow. Perhaps splitting it up into 2-3 posts would do it more justice?
I'm surprised the low level [`casArray`](http://hackage.haskell.org/package/base-4.11.1.0/docs/GHC-Exts.html#v:casArray-35-) operation isn't used/exposed by `vector`. Does anyone care to bubble this up to Vector's [primitive array](http://hackage.haskell.org/package/primitive-0.6.4.0/docs/Data-Primitive-Array.html#t:MutableArray) and finally the [mutable one](http://hackage.haskell.org/package/vector-0.12.0.2/docs/Data-Vector-Mutable.html) we use most?
Close enough.
Generally, I just go with an unboxed vector, but I don't know if it supports a CAS instruction, and I generally only mutate from one thread. Good luck.
I've been using an "open type witness" type [IOWitness](http://hackage.haskell.org/package/open-witness) as an alternative to TypeRep. IOWitness doesn't do everything that TypeRep does: in particular, it can't easily do cross-program stuff like Cloud Haskell, but it's conceptually much simpler. IOWitness :: k -&gt; Type instance TestEquality IOWitness newIOWitness :: IO (IOWitness a) iowitness :: TypeQ -&gt; Q Exp IOWitness internally wraps an Integer. You can create them dynamically with newIOWitness, or statically with a bit of Template Haskell: mywitness :: IOWitness MyType mywitness = $(iowitness [t|MyType|]) All created IOWitnesses are different. Thus, testEquality can see if two witness values are the same, and if so, guarantee that they witness the same type. But unlike TypeRep, the converse is not true: if two IOWitnesses witness the same type, they are not necessarily the same value.
Thank you very much. I understand how (&gt;&gt;=) works, but I did not see this in the foldM before. Now I get it throughout your explanation. 
That undoubtedly, any examples you provided would not be examples broadly relevant to intermediate Haskell experience. And they definitely, firmly, and absolutely were not, because `Control.Monad.ST` is definitely not of broad relevance and utility to most code written by intermediate Haskellers. ST is sometimes a great tool for solving a problem, it's almost never the only tool you could/should use to solve a given problem, and it's pretty rarely the best possible tool to solve an intermediate problem. Expecting all intermediate Haskellers to be familiar with ST is completely ludicrous. Not because using ST is really hard or because those examples are really complicated - Because they aren't common to general intermediate code. Containers, sure. You should probably have baseline familiarity with all structures present in the containers library. That would be an example of a rational expectation. ST? No, there is no way that's rational. That's absurd.
Striking my question from the record, I misread op as being confused about the result instead of being confused about the type signature.
What are some key concepts I should learn pertaining to Haskell in order to land a programming job?
\[What I Wish I Knew When I Was Learning Haskell\]([http://dev.stephendiehl.com/hask/#data-structures](http://dev.stephendiehl.com/hask/#data-structures)) , by Stephen Diehl, section on data structures. There is a TON of great stuff in there, and it's hand's down the best one-stop shop for someone who is new to the language and wants to answer things like 'what build tool and why' or 'why are there 3 idiomatic types for strings, what is wrong with these people' It also has a lot of good material on more complex topics for later on - Don't treat it like a syllabus, treat it like an encyclopedia. Really good material, but probably you don't need to know ALL of it.
I wouldn't try to sell yourself on programming concepts so much as results. Do you know free monads, applicative laws, and how fixity works in the happy parser? Who cares. How about you build up skills, and present that you have the skills, to do something interesting. For example (just making up tasks at this point), make a basic administration system for kubernetes and ec2 nodes, or parse and interpret a DSL for checkers moves, or deduplicate files based on hashes, etc etc.
That's right. When the internal model of the cube is rendered, each colored cell-face is converted to a `Square` type that contains its points in three-dimensional space, its colors and where it came from in the internal model, which is managed independently from the visual representation and rendering. Because these `Squares` represent finite 2D-planes that *do not intersect*, you can get their depth cues by simply ordering them according to their nearest (i.e., most negative) *z*-coordinate (the *z*-axis being orthogonal to the screen). On top of that, I also tried to ensure that the cube is always located fully "in front" of the screen and the user is always located fully behind the screen so that I did not need to worry about clipping issues. Doing things this way also made it a little easier to determine when the user is clicking on a `Square`, because the points projected on the screen always form a convex boundary, as well as determining whether it is facing towards or away from the user, since the 3D-surface normal will be the same over the entire `Square`. Depending on what you mean by animating the cube, this can be done without artifacts. The internal model of the cube has a fixed orientation in space and is only changed by rotating the individual layers thereby changing its *configuration*. The visual *orientation* of the cube is represented as a single rotation matrix that applies to the entire cube. This works, because rotating the whole cube has no effect on its configuration. So, when you drag the mouse to rotate the whole cube, all you are doing is changing this single rotation matrix. Consequently, you can animate rotations of the cube by mapping a time series to rotation matrices. In fact, when I was trying to debug everything, I used animated rotations to check for problems. However, you are absolutely correct in that this approach will start to introduce artifacts if any of the above assumptions are not satisfied. For example, if the `Square`s are immediately adjacent to one another such that their edges intersect/overlap, the depth cues will start to break down and you will indeed see artifacts. This is one of the reasons why they are spaced the way they are---the other reason being that they just look nicer that way :) Of course, this all has relatively little to do with Haskell. Nevertheless, I thought it would make for an interesting post, since it provides a visual example of just what you can do with Haskell in the form of a complete program/game, which is something that people just starting out frequently ask. 
 class (cls, cls') =&gt; cls &amp; cls' instance (cls, cls') =&gt; cls &amp; cls'
&gt; In real world, there are programming situations we need to deal with data whose type cannot be determined at compile time, for example, fetch data from API, parse JSON string, query from database... Can you give a more concrete example? I hear this argument a lot and I am not convinced it is true. There must be some common denominator (same type, same record selector, same map key, same type class) to actually work with your data otherwise what knowledge is there to gain from it?
OK, then we have a functor Fin from the category of finite ordinals to the category of types. Then you need to make use of the action of the functor on the product projection. I guess the reason I want you to be precise here is that your definition of product on lists requires closure over the variables m and n independently, which your notation is obscuring. `fst` itself depends on the factorization of the object its acting on as n*m, so really those need to be arguments to fst (we can give fst type `m -&gt; n -&gt; Fin (m*n) -&gt; Fin m`)
Java! *runs away
Lua is horrible - it's like a worse version of python. It doesn't check your function arguments (they just turn into `nil` ), it doesn't check that the variable names you use exist (again they just turn into `nil`). I have used Lua at length when torch used it as their scripting language (torch is a deep learning framework). Python is just better in almost every respect.
I come bearing good news: http://hackage.haskell.org/package/yaya-0.1.0.0
Hmm. That's a problem, yes. Is it important that the command to run the tests is always a simple `stack test` / `cabal v2-test all` / `cabal v1-test`? If it isn't, you could pass the build type as an environment variable and switch off that. Alternatively, another plan of attack: ask the build system to put the binaries somewhere where you know where they are. Before running the test suite, you could do something like `cabal v2-install --prefix /tmp/pandoc`, and then the test suite can just invoke `/tmp/pandoc/pandoc` and be happy.
Are there any natural language requirements?
Awyiss!
`Applicative Suave` can be [derived via `Compose (StateT Int STM) Input`](https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/glasgow_exts.html#extension-DerivingVia) {-# Language DerivingVia #-} .. newtype Suave :: Type -&gt; Type where Suave :: StateT Int STM (Input a) -&gt; Suave a deriving newtype Functor deriving Applicative via (StateT Int STM `Compose` Input)
This is how you do it: https://blog.rcook.org/blog/2018/ghci-custom-key-bindings/
Stick these magical incantations into your `~/.haskeline` file (which you'll probably have to make) bind: f5 : r e l o a d return keyseq: "\ESC[15~" f5 (It'll probably work; you might need to change the keyseq depending on what your terminal records as the escape sequence for f5) [More information](https://blog.rcook.org/blog/2018/ghci-custom-key-bindings/)
Yes, all of these are possible solutions. But they're all pretty awkward and raise other issues, since they rely on manual steps by the user prior to running the tests. We have a standard test infrastructure, as documented in the [Cabal user's guide](https://www.haskell.org/cabal/release/cabal-2.4.0.1/doc/users-guide/developing-packages.html?highlight=stdio#test-suites). Can we all agree that it would be desirable to add to this infrastructure some way to retrieve the location of built executables from inside the test program? As suggested above, it would be simple enough to set some environment variables. The necessary code could be added to Distribution.Simple.test. 
Hm I wonder if we can avoid duplicating `StateT Int STM` and `Input`? (or indeed if that is desirable) It's not a solid idea but we can compare the underlying representation of via (_ `Compose` _) and `Suave`. Of course this means we inherit from `Suave`'s underlying type, if that changes the `via` type changes as well!
That's defintely the first half solved. Does adding the return at the end make it somehow re-run the previous command? If so I am now perfectly happy. Although from a utilitarian perspective we should still add something like this to GHCi since thats a constant small cost that will see high use as opposed to a hard to find (and I looked! Apparently I was using the wrong keywords) per-developer modification.
Thats defintely covering everything I said in the post title, but I'm not sure how it could be extended to what's I the post content... unless we start stimulating key presses to go up to the previous line and re-execute which seems like a very un-haskell solution
Updated my writeup from last month on use cases for the different list folds according to feedback, hopefully it is correct now. https://gist.github.com/cjay/c15813c911609d355f8e280ee64b3e8f
You can embed anything you want becase Haskell is *miles* beyond any other language for parsing and execution of other syntaxes. If you want to write your own language, thats easy too. Your embedding story is: Run parser combinators to understand input into and ADT, transform from one ADT language to another for optimization, translate final ADT language into Haskell operations or some other language you can easily compile and deploy.
I'm not the author and I don't know if this would be a good use of Dynamic or Typeable, but I think a simple example of this would be a program that offers a structured editing GUI for arbitrary trees of JSON. Similarly you may have used a GUI for querying and displaying data in a user-provided relational database. In either case the structure of the data is completely unknown until runtime, but the program is still able to do meaningful things with it.
Cool! I thought about writing it in terms of `Compose` to get the applicative instance, but `deriving via` slipped my mind. Cheers!
That proof of concept looks amazing! Unfortunately, I don't know Docker all that well, so I can't really understand how this works. Could you explain?
I missed the second half about wanting to return the last command; the return is a literal enter on the keyboard. If you look in the help for ghci there's a command that already runs the previous command I believe, but in this case it would now be the refresh command.... But you could just do it yourself with `: &lt;up&gt; &lt;up&gt; return` added to the end of the first line. Idk what `&lt;up&gt;` should actually be since I'm on my phone at the moment
It’s Spanish and it means “Smoothly”
Yes that is what I meant. Thanks for clearing that up
How can I use Stack to manage an environment without having an actual package? To elaborate, I want an environment that can be initialized with `stack build`, and where I can do `stack exec ghci`, `stack exec runhaskell` etc. with certain packages loaded. The following `stack.yaml` file contains the exact specification of the packages I want to be in scope: resolver: lts-12.14 extra-deps: - ghc-typelits-natnormalise-0.6.2 - ghc-typelits-knownnat-0.6 - ghc-typelits-extra-0.3 - git: git@github.com:clash-lang/clash-compiler commit: f2060a077 subdirs: - clash-prelude - clash-lib - clash-ghc What it does not contain, is a `packages` field. That is because I don't have a local package; it's just a playground of loosely organised `.hs` files. Running `stack build` fails because there is no `packages` field. Interestingly, if I work around this by putting something dummy in `packages` (like a directory with some unrelated package), and then run `stack build` and then remove the dummy `packages`, then `stack exec ghci` etc. will have the required packages in scope. How do I tell `stack` to not look for a `packages` field for `stack build`? 
&gt; Can you give a more concrete example? Not the author. But I think the author is talking about cases where it is required to convert something that is a value in say, JSON to something in type level. Say if you have two different types for the different types of user in your system 'Admin' and 'Client'. And you want to parse a json string that contains an object that represent a user. And say, depending on a key 'userType' in that object, the end result needs to be a value either an 'Admin' or a 'Client' type. In cases like this you wouldn't know what you should be expecting when you are about to parse the json string at compile time, right?
The `Ord` typeclass kinda only works for total orders, while it sounds like you have a partial order. You can define your own custom typeclass for this if you want (with `compare' :: a -&gt; a -&gt; Maybe Ordering`, where `Nothing` means "not applicable").
There is a F# Web Framework named Suave.
What is cyclone??
Something similar could be said in the case where the via-`newtype` is obtained by applying a type constructor to the type you're defining. newtype Foo a = ... deriving Generic deriving Kitchen, Sink via Generically (Foo a) -- why not just "Generically" for short In fact, to derive "via `Compose`" could be done via this other newtype: newtype Composely f a = Composely (f a) -- (???) = some constraint that says that f is itself a newtype that wraps a composition (m (n a)) and that m and n are Applicative instance (???) =&gt; Applicative (Composely f) where ... So you could write newtype Suave a = Suave (S (I a)) deriving Functor deriving Applicative via Composely (Suave a) -- why not just "Composely" for short
https://github.com/justinethier/cyclone
What about something like this: data Play (mode :: Mode) = Pass | Play [Card] deriving Ord data Mode = Single | Double | Triple | FourOf | Straight | ... class KnownMode mode where modeOf :: proxy mode -&gt; Mode instance KnownMode 'Single where modeOf _ = Single -- ... data SomePlay where SomePlay :: KnownMode mode =&gt; Play mode -&gt; SomePlay data SomePlays where SomePlays :: KnownMode mode =&gt; [Play mode] -&gt; SomePlays validate :: [SomePlay] -&gt; Maybe SomePlays validate [] = Just (SomePlays []) validate (SomePlay p:ps) = (SomePlays . (p:)) &lt;$&gt; check (modeOf p) ps where check :: Mode -&gt; [SomePlay] -&gt; Maybe [Play mode] check _ [] = Just [] check mode (SomePlay p:ps) | mode == modeOf p = (p:) &lt;$&gt; check mode ps | otherwise = Nothing You add a validation pass to make sure all your plays are mutually legal, then do your logic afterwards (including comparison) after making sure they're all using the same mode of play. You can get rid of the `KnownMode` boilerplate by using `singletons` or `Type.Reflection`
This sounds like a new and easy way to prove anything I want! W O W !
If it's really "Admin or Client", a sum type is a more precise solution. But I may be missing something because I don't see why parsing the JSON string at compile time makes dynamic typing relevant. In the quote above, I still understand parsing to happen at run time, and the claimed issue is that sometimes one cannot give a type to the parser's output. 
If the schema of the data is provided at runtime there is always an ADT to over-approximate all possible schema statically, such as a plain `Value` from aeson, or a custom one if the schemas for the application are more structured. Would this not give guarantees at least as strong as any solution based on dynamic typing? Furthermore, dynamic typing with `Typeable` doesn't create entirely new types at runtime. The `Typeable` things that persist at runtime are all representations of types made of constructors present in the source program.
I am the author. Thanks for the feedback. The article were split.
Lol @ that overview. What’s the performance like? 
`Typeable` is really interesting and useful piece of Haskell! You can also see how to build dependent-map on top of `Typeable` in the following blog post: * https://kowainik.github.io/posts/2018-07-11-typerep-map-step-by-step
in portuguese means too, but in Rio de Janeiro is a slang. 
I wrote a quick gist on paper for `/r/haskell` not a submission to an academic journal. However, I want to thank you. I learned about "category skeleton" and the FinOrd category.
Slang for what?
Slightly different from what you're asking but what about using `ghcid` with the `-T` option to run whatever expression you want, for example: ghcid -c "ghci -isrc src/Test.hs" -T "print myTestVar"
Really? Great minds
I have no idea! It's good enough over localhost! There's not really anywhere to lose performance IMO---other than my stupid strategy for just dumping json blobs back to the client. PRs welcome!
The language itself is not much harder than anything else, though learning how to use it can be somewhat unsystematic as much knowledge is scattered around in blog posts, otherwise undocumented. But that is no terrible complication, of course. IMO, there is enough accessible learning material.
I first learned Java then C then R and then Haskell. Wasn't easy but absolutely fascinating since it was so new and different and I was genuinely interested. Go on, learn Haskell, it'll be great and you'll be amazed about the thing's functional programming does really well 😁
Read the book Functional Thinking - Paradigm over Syntax by Neal Ford. This was the book I wish I'd read when we did Haskell in university. I'm also really enjoying Category Theory for Programmers by Bartosz Milewski. These two together really help you "get" what Haskell is trying to do and why.
I was in a similar situation, coming from C, then Perl, then Python. I learned first ELM by curiosity. I understood quickly the advantages of FP, and having a type system over the other languages (like Python that Im doing professionally for years now). So I switch to Haskell because I thought it would be the best FP language to learn. And I don't regret so far. The community is welcoming and extremely clever (don't be afraid of that and just enjoy it), the materials are good (the wikis, the documentation, the books...). After 6 months of learning Haskell, I'm more efficient in Haskell than python... And by far on my criteria (maintainability of code and performance primarily). Not only Im still learning and fascinating by Haskell, but I'm also a much better programmer in Python and all the other language thanks to my knowledge from Haskell. So don't hesitate and give it a try for couple of months I would say. Also, try to code a medium size project at the same time as learning Haskell to grasp the concepts. It helped me a lot. And of course have fun :)
&gt; can I somehow compile the file with a `-ddump` flag to show me some intermediate representation where `&gt;&gt;=` etc. is expanded No. The `-ddump` flags show you intermediate states as your code gets compiled to a binary. Since function calls are (usually) run at runtime, not compile-time, the `-ddump` flags aren't the right tools here. I don't know of any tool which allows you to inline the definition of a function call inside your code. In this case, the definition of State's `(&gt;&gt;=)` operator is more complicated than what you need here because it is based on StateT, the monad transformer version of State. So even if you did manage to expand `(&gt;&gt;=)`, it would not be that insightful. Here is a simpler but equivalent definition: (&gt;&gt;=) :: State s a -&gt; (a -&gt; State s b) -&gt; State s b stateA &gt;&gt;= f = State (\s0 -&gt; let (a, s1) = runState stateA s0 stateB = f a (b, s2) = runState stateB s1 in (b, s2)) Along the same lines, here's a version of `dumped` which uses `let`s instead of `(&gt;&gt;=)`, `(&gt;&gt;)`, `replicateM`, and `head`: expanded :: State [Int] Int expanded = State (\nums0 -&gt; let nextNum = head nums0 + 1 nums1 = nextNum : nums0 in if nextNum &lt; 10 then let (nextNum1, nums2) = runState expanded nums1 (nextNum2, nums3) = runState expanded nums2 in (nextNum1, nums3) else (nextNum, nums1)) &gt; This gist shows a simple `State [Int] Int` with `replicateM`. It doesn't look simple to me! I couldn't figure out what the code was doing until I saw your `| - recurse 3` expansion, which I think is correct. I think what made it difficult for me to understand your code is the fact you are calling `head` on the result of `replicateM`, this just looks really weird to me. Whenever I use `replicateM`, I either need the full list of results, or I don't need any of them, in which case I use `replicateM_` instead. Keeping just one result seems weird.
if you want to know how `replicateM` works you can look in the source-code: https://www.stackage.org/haddock/lts-13.1/base-4.12.0.0/src/Control-Monad.html#replicateM here it's replicateM cnt0 f = loop cnt0 where loop cnt | cnt &lt;= 0 = pure [] | otherwise = liftA2 (:) f (loop (cnt - 1)) which might not help you - a simpler version is replicateM n comp | n &lt;= 0 = return [] | otherwise = do res &lt;- comp rest &lt;- replicateM (n-1) comp return (res:rest) so if you call it with `replicateM 2 comp` you are sequencing the same computation twice and return a list with the two results. it's probably best to write down the state and the results you are doing: step 1: state = [2] - you pick nextNum = 3 and set the state to [3,2] - you now call the function twice with this state! the first call will see: state [3,2] - nextNum = 4 - newState = [4,3,2] - again call twice .... till you'll see [9,8,7,...,1] - your nextNum will be 10 - next state will be [11,10,...,1] - you don't recurse but return 10 the call before had an replicate so it will to it again with state [11,10,...,1] - nextState [12,11,...,1] - will return 11 &lt;- this return will be scraped because you do head all this will contine till your first replicate yielding the result from 10 with the state [17,16,...,1] --- don't think you can dump the simplifications (there might be some projects doing this though) - but an easy fix is to use [`traceShowId`](https://www.stackage.org/haddock/lts-13.1/base-4.12.0.0/Debug-Trace.html#v:traceShowId) and let it run listDoReplicate = do nums &lt;- S.get let nextNum = head (traceShowId nums) + 1 ... 
This isn't bad, but still requires you to kill the script and re-run it whenever you want to test a new expression, which is pretty often for me (I tend to build and test in the smallest possible chunks). I think this is the closes to what I want though, I didn't know GHCid had this functionality now.
Sure. Most of the code is the bash script in [`with-ghc.docker`](https://github.com/gelisam/deploy-hint/blob/master/with-ghc.docker), you can ignore the docker-specific stuff. I use two machines, with-ghc and without-ghc. First, I build my program on with-ghc. I then copy a whole bunch of files from with-ghc to without-ghc. The files include: * The compiled binary for my program. * The C libraries which my program automatically loads on startup, in my case just `libgmp`. * The Haskell libraries which my program automatically loads on startup, plus those I will load using `hint`, in my case `rts`, `base`, `ghc-prim`, `integer-gmp`, and `acme-dont`. * The `conf` files for those libraries, from the package database into which they were installed. Those files point to an absolute path on with-ghc, `/opt/ghc/7.10.3/lib/ghc-7.10.3`, so I use `sed` to rewrite those paths to the absolute path I want to use on without-ghc, `/root/my-program/haskell-libs`. * `platformConstants`, which contains information like how many bytes does a `Double` take. In my proof of concept, with-ghc and without-ghc use the same OS and the same hardware, so these values are the same for both machines, but I imagine this could cause trouble if you wanted to distribute your program to both x86 and x64 machines. * `settings`, which contains paths to various compilation tools such as `ld` and `gcc`. We will only interpret code, not compile it, so almost none of this will be used. Surprisingly, `gcc` does get used, but not for compiling C code, for some filename transformation. So I implemented [`fake_gcc.sh`](https://github.com/gelisam/deploy-hint/blob/master/fake_gcc.sh), which only implements this transformation, I put it on without-ghc, and I changed `settings` to point to `fake_gcc.sh` instead of `gcc`. That's it, now that everything is in place on without-ghc, I can run my binary and it will successfully load all the above files.
not only some people exist in similar situation but i think many of the present haskellers were OO programmers in the past; i was; for me the absence of OO when learning haskell felt freshingly natural and simple
They have equal inference to `fromIntegral`.
Really? I've read that Ocaml tools are kind of bad. Maybe that was outdated information. Do you have an article or other information on how to get started with Ocaml and tools as someone completely new?
You can't.
I'll see if I can get a physical copy of that book, thank you! I'll admit, I'm still unsure as to why I would use Haskell over some other OOP languages (especially in Game Development, where I want to specialize in) so ill take a look into those books.
I would avoid category theory. You don't need to know it to use Haskell effectively.
Not even there yet lol, still trying to wrap my head around lazy evaluation :P
Just `:r` works to. The last evaluated line is bound to `it`, so yout can try to just evaluate `it` after return.
Maybe but that book genuinely helped me get my head around things I otherwise would have found more difficult. 
Well, I think it's still worth keeping a clear idea of how to describe the relevant computation :)
I personally like to think of dynamic typing and Generic in Haskell as attempting to include more tools for working with types in a structural manner instead of a purely nominal fashion. I'm still unsure if this is the best intuition but I like it so far.
No need to kill the script. Have `-T` point to `main` and change `main` 😄
This is probably the solution I'd go for, but it's on the advanced side, using the DataKinds extension
I quite like it too!
Opaleye * ✓ Works with normal Haskell records * ✓ Type-safety obtained through typed record labels * ✓ Supports inner queries * ❌ Integrates with Persistent (providing multiple backends) * ❌ No TemplateHaskell and minimal use of generics 
Can you make that a main/real question? Because I have the same question and legit one.
I agree with the above -- I think a lot of people here come from OO, since that's what most schools teach and what the majority of industry is right now. Coming from a Java background as well, OO gave me a reference point for a lot of functional concepts, and a lot of the time made me appreciate the simplicity and "uniformity" of a lot of functional concepts. This isn't to say that getting to a competent point in Haskell is quick and easy, but I think it's more a function of effort put into learning concepts &amp; ecosystem than raw difficulty.
Some people don't think in categories like OOP and functional programming. You might find Alan Kays comments useful: [https://news.ycombinator.com/item?id=11808551](https://news.ycombinator.com/item?id=11808551)
Also, TH isn't mandatory for making lenses. You can always write them manually. Or, you can use TH to generate them, but then --dump-splices and replace the splice with it's expansion. Either avoids most, if not all, or the compile-time overhead of `makeLenses`.
If you don't want to go /u/rampion's route, one option is to straightforwardly write the `isValidNextPlay :: Play -&gt; Play -&gt; Bool` function data Card = Card {rank :: Rank, suit :: Suit} -- Assumes all plays are well formed by themselves; e.g. Two cards in a double actually have the same rank isValidNextPlay :: Play -&gt; Play -&gt; Bool isValidNextPlay (Single c1) (Single c2) = rank c1 &gt; rank c2 isValidNextPlay (Double c1 _) (Double c2 _) = rank c1 &gt; rank c2 ... isValidNextPlay _ _ = False You may also want to remove redundant information from `Play`, like keeping only `Rank` (or `Rank` of the lowest card for `Straight`); that will make it easier to work with `Play`s.
My programming background is vastly slanted towards C++ with a sprinkling of other languages. Specifically game development, even more specifically rendering/graphics. I tried to learn Haskell several times for my side projects, bouncing off it pretty hard each time but always with an appreciation for the language and a measure of frustration that it just wouldn't fit in my skull. The sequence of things that finally moulded my brain into sufficiently Haskelly shapes was learning Scala, then Clojure, and finally reading _Real World Haskell_ and doing some of the exercises. It was a case of finding the approach that allowed me to get just enough traction with the language to start making non-trivial programs. This was also a goodly number of years back, when RWH was much closer to contemporary Haskell.
I like this solution a lot, thank you. Nice easy 1 to 1 replacement for what I already have. 
Can't get a simple quasiquoter to work. Fails with a message about interface-file declaration for `Data.Text.Internal.pack` Some code and a ghci output: [https://gist.github.com/wiz/009c9d94e68d4f8e35bce3e94b9ad525](https://gist.github.com/wiz/009c9d94e68d4f8e35bce3e94b9ad525)
That's a useful summary, thanks! I'm looking at this example from [Opaleye's tutorial](https://github.com/tomjaguarpaw/haskell-opaleye/blob/master/Doc/Tutorial/TutorialBasic.lhs): data Birthday' a b = Birthday { bdName :: a, bdDay :: b } type Birthday = Birthday' String Day type BirthdayField = Birthday' (Field SqlText) (Field SqlDate) In Quirinius you'd just have: data Birthday = Birthday { bdName :: String, bdDay :: Day } That's what I meant by "normal records". Or can Opaleye do that as well? I'm not saying there's anything wrong with Opaleye (it seems a very nice library!), but I think it's an interesting point in the design space to be able to work with plain Haskell records.
Thanks, the version with `let` makes it a bit simpler. The code is a bit contrived, but I was just playing around with `StateM` and `replicateM`. So bottom line is that my comment regarding the order of the function calls was actually kind of correct? 
Thanks. I'll be very honest... it still hasn't clicked. Maybe I'm just not made for that kind of thinking and so it takes me way longer. I understand what `replicateM` does conceptually and found the source (although your simpler version helps!). Sprinkling some trace over the function gives me this: ``` [2] [3,2] [4,3,2] [5,4,3,2] [6,5,4,3,2] [7,6,5,4,3,2] [8,7,6,5,4,3,2] [9,8,7,6,5,4,3,2] return 10 [10,9,8,7,6,5,4,3,2] [11,10,9,8,7,6,5,4,3,2] [12,11,10,9,8,7,6,5,4,3,2] [13,12,11,10,9,8,7,6,5,4,3,2] [14,13,12,11,10,9,8,7,6,5,4,3,2] [15,14,13,12,11,10,9,8,7,6,5,4,3,2] [16,15,14,13,12,11,10,9,8,7,6,5,4,3,2] (10,[17,16,15,14,13,12,11,10,9,8,7,6,5,4,3,2]) ``` I understand that each function application sets of another, recursive call, until `nextNum` greater than, or equal to, 10. From the source, and from the description on hackage, it says that `replicateM` gathers the results. In the case of `State [Int] Int`, where `State [Int]` is the `m` in `replicateM :: Applicative m =&gt; Int -&gt; m a -&gt; m [a]`, `a` is therefore the `Int` of `State [Int] Int` - the num that is returned from the `else` branch. So now, where do the ints in the list come from, before and after the `return 10` line I posted? And WOW was I wrong. I just added some more tracing and now I have this: ``` [2] [3,2] [4,3,2] [5,4,3,2] [6,5,4,3,2] [7,6,5,4,3,2] [8,7,6,5,4,3,2] [9,8,7,6,5,4,3,2] return 10 [10,9,8,7,6,5,4,3,2] return 11 head [10,11] [11,10,9,8,7,6,5,4,3,2] return 12 head [10,12] [12,11,10,9,8,7,6,5,4,3,2] return 13 head [10,13] [13,12,11,10,9,8,7,6,5,4,3,2] return 14 head [10,14] [14,13,12,11,10,9,8,7,6,5,4,3,2] return 15 head [10,15] [15,14,13,12,11,10,9,8,7,6,5,4,3,2] return 16 head [10,16] [16,15,14,13,12,11,10,9,8,7,6,5,4,3,2] return 17 head [10,17] (10,[17,16,15,14,13,12,11,10,9,8,7,6,5,4,3,2]) ``` This explains a lot... I really should have been more creative with my tracing. I totally didn't really understand how the call to `head` kind of "negates" the gathering of the results that `replicateM` does, since it always just returns the same result. I guess ultimately it was both positive and negative that this just happened to be the first function I came up with to play around with `StateM` and `replicateM`. Thanks for the feedback, also to u/gelisam 
So I'm looking for a good native-esque GUI framework for a personal project. Ideally whatever combination of libraries I end up with would support the following: - Decent collection of widgets. - It would be very nice is there is a code box widget w/ line numbers and syntax highlighting. - Native app or one where a web interface is wrapped to look native. - FRP based interaction mode. - Integration with Diagrams such that I can receive click/mouse events on elements of the diagram. If I need to use diagrams-svg as a backend and interact with the svg, that's fine, though an example would be nice. - In particular I want to be able create a diagram and allow people to change it by clicking and dragging elements. - Can work with stack. - Must have Linux support, supporting other platforms is nice but not strictly necessary. - Ideally I'd be able to build a self-contained executable (single file) for each platform, that I can distribute relatively easily. Basically I want to build a basic editor for a specific type of diagram which has an associated DSL. 
Yeah, it's been very difficult for me. My first language was Pawn (an imperative language with syntax that resembles C), and along the way I learned a bit of C++, Java and C#, mostly because I had to use them for college, and I found it quite easy to solve assignments with those. I think I've wrapped my head around the basics of Haskell, but I keep breaking problems into small concerns which I'm not usually able to translate to Haskell code.
&gt;If it's really "Admin or Client", a sum type is a more precise solution. B Then the difference between an Admin and a Client becomes something at value level and not at the type level, right? &gt;I still understand parsing to happen at run time, and the claimed issue is that sometimes one cannot give a type to the parser's output. Consider parsing a json string that contains a list of aforementioned users where each user can either be a value of type `Admin` or of a type `Client`. Maybe `Admin` and `Client` is a bad example. Think of something like `Currency` where values in a big sum type have been lifted to the type level. In such cases you are really dealing with a lot of types. And if you choose to carry that type information through out your processing pipeline, you ll have to deal with every single one of them all places where a type is checked. So in such cases, as I understand it, Dynamic typing allows you to `smuggle` the type information through places of type check, and some point later, bring the types back, where it really matters... 
No, Opaleye cannot do that for very good reason! You have data Car = Car { brand :: Text , speed :: Double } and you use it like where_ (fld @"speed" .&gt; 120) ... project (fld @"brand") whereas Opaleye has restrict (speed car .&gt; 21) ... brand car I'll leave it up to each individual to judge which they think is "normal" use of Haskell records! 
It's not obvious at all! I think it's a bug in template-haskell's `liftData` function. `pack` is defined in `Data.Text` but not in `Data.Text.Internal`. My guess is `liftData` tries to infer how to qualify the constructor `pack` from where the `Text` type is defined, instead of reading it in the `Data` instance (which does say it).
I've finally read. My biggest question is, how can you generate meaningful and working examples automatically? I suspect just combining the symbols (the functions and some values) in type-checked manner doesn't make desirable examples... 
You can use `Either Int String` as the type.
Sorry I should specify a little more, I'd like the leaf to be any type not just int and string, my tree definition: data Tree a = Empty | Leaf a | Node a (Tree a) (Tree a) 
Well, you _can_ use [`Dynamic`](http://hackage.haskell.org/package/base-4.12.0.0/docs/Data-Dynamic.html#t:Dynamic). But maybe you could tell us a bit more about _why_ you want to do this? Since Haskell is a statically-typed language, there aren't many circumstances in which throwing away the type information is the right solution.
It's more so for homework, I need to do other functions such as height, which I've done but it only works for when the type of the leaf are all the same 
This might help you: https://www.reddit.com/r/haskell/comments/owjvu/haskell_equivalent_of_rackets_any_type/ In short check out existential types, in addition to `Dynamic`
Will do, thanks all 
No problem! I continued looking around and I remembered that tuples do somewhat that: they can accept any different type as input, maybe it could help: https://stackoverflow.com/questions/7086668/haskell-tuple-constructor-ghc-and-the-separation-between-a-language-and-its-im
I'm quite new to haskell so on first glance I don't think I will be able to utilise tuples for what I'm trying to do (mostly because it seems like a unusual strategy compared to what I've found online) however it does make sense since it accepts any different type, I'll definitely look more into this thanks 
First you tell me how to get any type then I'll tell you how to get a binary tree with leaf as any type!
Well, in a statically-typed language, you usually _do_ want all your leaves to have the same type. Do you have an example homework question in which this was not the case?
Notice that [`Validation`](http://hackage.haskell.org/package/validation-1/docs/Data-Validation.html#t:Validation) intentionally doesn't have a Monad instance! For this reason, it doesn't make much sense to make it into a Monad transformer. An Applicative transformer would make more sense, but since Applicatives compose using [`Compose`](https://hackage.haskell.org/package/base-4.12.0.0/docs/Data-Functor-Compose.html#t:Compose), there is no need to define both a regular and a transformer version of `Validation`.
Easy, you start with a `Tree Void` and them `fmap absurd`. voila, a `Tree a`. /s
Im in a similar situation: Having.average.IQs Also I dont even have a CS background. I have had quite a lot of difficulties learning about Monad Transformers. Theres been so many times I had wanted to give up, after struggling with compile time type errors,especially trivial ones such as string vs text vs bytestring vs lazy or strict. But today Im quite comfortable with Haskell. I can use most libraries on Hackage quickly without feeling lost or irritated if there's barely any documentation. In other words, Haskell is serving me instead of hindering me. My two cents is that you will definitely run into frustrating moments. dont give up, "just keep doing it for 30 years", to quote the Monad creator:)
If it's so easy to spin up, why is there no live demo?
The question asks me to define a polymorphic data type tree in haskell, which has either a leaf (element of tree), empty or 2 binary trees (left branch/right branch) and then to create some functions like height. One of the test cases for height has a tree leaf1 = 1, leaf2 = "true", leaf3 = 2 and leaf4 empty, result = 3 The layout is not really specific, like it just has the function call and layout in parentheses so (height ( 1 ( true ( 2 empty)))) When I run the function in haskell I would include the "Node" and "Leaf" parts so that it's a tree. Does this make sense? 
I would suggest you remove that single word fuck from your landing page.
[removed]
Instead of `fld @"speed"` you can probably also implement an IsLabel type class instance to allow writing `#speed`.
Makes perfect sense :) It's unfortunate that this is a homework problem because this isn't something you really encounter in Haskell and all of the solutions you'll find aren't particular idiomatic and definitely not super beginner friendly. In short, a dynamic tree is a terrible way to learn Haskell. The only thing it's going to do is make you wish Haskell was as easy to use as (insert dynamically typed language here) Does your professor have a good reason for this?
The main reason would probably be so we don't try and find a solution online and just copy it so he's made a lot of the questions quite specific to something we can't really Google. Also there was some lambda lisp questions which require us to create trees and the other functions like height exactly like the haskell question I've described. So he probably wanted us to apply what we know from those questions into this one in. 
No.
What's "lambda lisp"?
I did my PhD in related topics. I guess there is nothing close to what you want that is good availiable in Haskell. (If you need guidance feel free to write me.)
Is there any recent advances in FRP? There is a lot of papers and lots of libraries (some of them are deprecated), so I'm unsure what should I use.
I think that [Fmt](http://hackage.haskell.org/package/fmt) is a better choice to show Text than text-format or formatting: it makes code easier to read.
A lambda lisp interpreter, its not really important to the initial question, it's all functional programming based 
Is it possible that the lambda lisp interpreter only supports a certain number of values, say integers, strings and lists, and that the leaves of your tree only need to be able to hold values of one of those types?
Thank you! A lot of insight in your comment, I think I got it all now :)
Fair point, I should clarify better what I mean.
That's a good idea! I didn't think about that.
 Prelude&gt; :set -XExistentialQuantification Prelude&gt; data Tree = forall a. Leaf a | Node Tree Tree | Empty Prelude&gt; :t Node (Leaf 42) (Leaf "foo") Node (Leaf 42) (Leaf "foo") :: Tree 
The lambda lisp interpreter does indeed only support some values, however in the lambda lisp interpreter the trees support a mix of any of these types (integer, string, bool) . My haskell one needs to do the same but for any data type available in haskell according to my professors words. Maybe it would be best for me to ask my professor since he's created this, it's not the end of the world if I don't figure it since I've done enough of the other tasks, I appreciate your help though :) 
Dynamic/Typeable *is* the ADT approach, just generalized slightly. Observe that there is an isomorphsim between the (dependent) types Either a b \iso Sigma (x : Bool). if x then a else b we can, indeed, encode any sum type as sigma over a witness where that witness is an enumeration. Indeed, this is actually how many compilers implement sum types. And so, this is the idea of `Typeable`. `Dynamic` is equivalent to having a type data Dynamic = DynInt :: Int -&gt; Dynamic DynChar :: Char -&gt; Dynamic DynFloat :: Float -&gt; Dynamic ... with an *infinite* number of constructors (one for every possible type) except that we use the sigma encoding instead. Of course, haskell does not have full dependent types, so it gets a little wonky, but that is what is going on. My only real complaint about `Typeable`/`Dynamic` (in our modern world where the compiler makes all the instances) is that the structure of the type witnesses leave something to be desired. That is, things like the nice subsumbtion structure of haskell types (e.g. every `forall a.a -&gt; a` is an `Int -&gt; Int`) are not well captured in the `TypeRep` witnesses. That makes using them to do "gradual typing" sort of things rather clunky.
Hey, just as an FYI, your site has verrrrry small margins on mobile. [I thought the text was actually getting cut off on the sides.](https://i.imgur.com/lpwQL6M.png) I'm using Chrome Beta 72 on Android 9. I don't know if you care, but I figured I'd give you a heads up.
&gt; and you must process them correctly, `text-icu` will be indispensable. Instead of `text-icu` I can recommend `unicode-transforms` package: * https://github.com/composewell/unicode-transforms /u/hk_hooda gave a talk at Functional Conf about performance optimizations he made to make this library blazingly fast. So I would give it a try!
Thanks, fixed (chose a different theme)!
I wrote a small Coq script: https://github.com/phadej/lens-laws/blob/6edf23f694f853c3722f0547944e53201392849e/theories/Zip.v which shows how this way of thinking can be turned into "what laws we need". The `min x y &lt;= x` like law would give a proper *zippy* feel to `zip` (and `x &lt;= max x y` to `align`!) If someone want to play with Coq, please try! I don't have time :/
Have you heard of [ChronicleT](http://hackage.haskell.org/package/these-0.7.5/docs/Control-Monad-Chronicle.html)?
Never heard about it, thank you! I've been thinking about whether or not I should use a Writer to be able to gather errors, but decided against it. It does seem like a legit alternative. &amp;#x200B;
I suspect the test infrastructure was built with testing libraries in mind. I see the potential for portability across operating systems and build systems that comes with testing your executable directly in the same cabal package using haskell only. Maybe you can start smaller and build a proposal in a cabal issue that starts to adjust test-suite to consider various factors that one would want in testing an executable instead of a library. The first step might be adding a new attribute that like exe-depends that notes which executable(s) that a test-suite depends on.
I'm not actually sure if it's a good alternative and was hoping someone would weigh in. Anyways, I looking into it myself. [WriterT generates space leaks](https://blog.infinitenegativeutility.com/2016/7/writer-monads-and-space-leaks) because of a call to `mappend` required by `&gt;&gt;=`. So as it turns out, [ChronicleT uses mappend](http://hackage.haskell.org/package/these-0.7.5/docs/src/Control.Monad.Trans.Chronicle.html#line-74) in it's Monad bind instance, so I suspect ChronicleT suffers from the same space leak issue as WriterT. Which is unfortunate, because I really like using MonadChronicle for exception handling. WriterT can accumulating errors, but it doesn't provide a way to abort writing, so you can't broadcast a fatal error. WriterT is fixed by defining the writer in continuation-passing style, and is available in [writer-cps-full](https://hackage.haskell.org/package/writer-cps-full). I suspect the same could be done for ChronicleT, but no one has done it yet.
In my use-case for short-lived code paths memory leaks wouldn't be a concern at all, but I think that leaving something like a simple applicative constructor for first level of validation and then just resorting to a regular handler code which short-circuits as usual looks a bit more appealing to me. Would like to restrict the use of custom transformers as much as possible to not over-complicate.
Feel free to edit! The wiki is completely user-editable, no registration needed.
I've made [valor](https://hackage.haskell.org/package/valor) a while ago for one of my projects where I needed "structured" errors to which I can apply smart error correction strategies, but it's also perfect for all kind of other validations. Maybe this can be of use to you.
Oh nice! The only problem will be that you can't interact with elements in the tree at all, so this won't allow operations like `member` or `delete`, but considering the absurdity of OP's assignment, this is a good tradeoff. And it even seems that they don't need to implement such operations anyways.
Thanks, will check it out!
I like [PyF](http://github.com/guibou/PyF) too, but I'm the author ;)
Was Pawn formerly called Small? Did you write AMX/AMXX mods, or was it deployed elsewhere?
I kinda wish ByteString had been named like ByteList or something. Then maybe it wouldn't get compared to strings so often. It's not really an array, so ByteArray or something wouldn't work (plus I think that's taken), but it still shares more with `Vector Word8` than it does with `String` or `Text`
I'd like to clarify. `Tree a` is polymorphic. Are you sure that your professor is requiring your tree to be able to hold multiple types at the same time? If I were in your shoes, I'd be emailing your professor asking for a clarification of the requirements. Maybe post the test case you mention?
That's true. Btw, there's also [http://hackage.haskell.org/package/vector-bytestring](http://hackage.haskell.org/package/vector-bytestring) – and I think that at some point I've seen a long comment somewhere explaining why replacing ByteString with Vector is tricky, but I can't find it now.
IIRC the main difference is that ByteStrings use pinned memory. Other than that they're fairly similar.
Honestly, although there's some promising inroads with SDL2 and shaders, Haskell does not have the ecosystem + community for game development yet. There are a few honorable mention pioneers like rumpus (vr) and lambda lantern - but haskell is definitely a path of iconoclasts and not careerists for now: https://github.com/lettier/lambda-lantern https://www.youtube.com/watch?v=pnEdY2Qttvw
I'm pretty close to 100% sure that's a bug.
note that CPS-writer is `StateT`
That’s definitely a bug.
Thanks for reporting this. I've minimized your program slightly and reported this as a bug [here](https://ghc.haskell.org/trac/ghc/ticket/16141). (In the future, do feel free to report bugs like this directly to GHC's issue tracker.)
If you're going to suggest advanced Haskell techniques to beginners, at least provide the required GHC extensions to make it compile.
Welcome to add it to Guide!
Isn't the `ap` = `&lt;*&gt;` law the only reason for not having a Monad? It's a rather silly law, since `ap` is a broken version of `&lt;$&gt;` (it introduces a depency that isn't necessary). 
Monads were most difficult. That theoretical mathematical nonsense just did not make sense to me. this illustrated explanation was the most helpful. [http://adit.io/posts/2013-04-17-functors,\_applicatives,\_and\_monads\_in\_pictures.html](http://adit.io/posts/2013-04-17-functors,_applicatives,_and_monads_in_pictures.html)
[Types and Programming Languages](http://port70.net/~nsz/articles/book/pierce_types_and_programming_languages_2002.pdf) offers some answers to these questions. That book does a great job of breaking down common type system features into minimal calculi that can be formalized with a page or two of syntax, semantics, and typing rules. Many of the features of object-oriented languages can be modeled by the calculi studied in that book. For example, encapsulation (e.g., private member variables) can be implemented by existential types, described in Chapter 24. Existential types, in turn, can be implemented in terms of universal types (specifically, using rank-2 polymorphism). Chapters 18, 19, and 27 are dedicated to the theoretical ideas underlying object-oriented programming. The general theme is: objects are records, and methods are functions in those records. But accurately modeling the vagaries of mainstream object-oriented languages is quite cumbersome. Classes in OOP can have fields which contain references to objects of the class being defined. This is modeled by equi-recursive types (described in Chapter 21), which have a rich and complicated metatheory. The form of recursive types used in languages like Haskell is called iso-recursive types, which is quite a bit simpler to formalize, but requires the programmer to explicitly roll/unroll terms (think of constructors and pattern matching). Iso-recursive types play nicer with type inference. Subtyping is a well-studied language feature. Chapters 15, 16, 26, and 31 cover it in depth. Subtyping greatly complicates type inference, and that's probably why languages like Haskell do not have it. Many OOP idioms that use subtyping have analogous solutions in Haskell (e.g., with type classes). A common theme when studying type systems is that System F (described in Chapter 23) is quite powerful and subsumes, at least in a theoretical sense, many features we are used to having hardcoded into a language. For example, you can implement booleans, pairs, sum types, natural numbers, lists, and even sorting functions all in pure System F. And as a bonus the fact that System F is strongly normalizing implies that the sorting function always terminates! You get all that with only 5 constructors for terms and 3 constructors for types. I quite enjoyed the way you asked "are they something weirdly defined that takes a bunch of ugly piecewise functions to be described". Indeed many "features" of mainstream languages are actually anti-features because they destroy important metatheoretical properties. For example, common forms of runtime reflection completely breaks parametricity, which is a great source of [free theorems](https://people.mpi-sws.org/~dreyer/tor/papers/wadler.pdf). The encoding of existential types in terms of universal types crucially relies on parametricity to work correctly.
&gt; Further, I find the equation of the "radical left" (so called) with the "radical right" outlandish. On the latter side you have people increasingly organizing in explicit ways to promote bigotry and misery. On the former side you have... people who stridently oppose racism? Your bias is showing if you think the radical left is just “people who stridently oppose racism”.
Thank you for answering in such a thorough manner.
Just English will be fine!
Thank you! Just ordered :-) Happy New Year!
Not that I'm understanding its contents, but it sounds that's related to http://conal.net/papers/compiling-to-categories/
Just wondering, have you seen [Compiling to Categories](http://conal.net/papers/compiling-to-categories/compiling-to-categories.pdf)? It seems similar to what you're doing, although Conal Elliott achieved it with a GHC plugin, which I understand is not what you're going for.
Yes, it's meant to be a lightweight version of Compiling to Categories.
It's somewhat related, but I manage to avoid using a compiler plugin by sacrificing a lot of versatility.
IMO, type systems are useful when working w pure functions. They describe things much more precisely, and can be depended upon. As @stepstep says, when you have features which break that, the reliability and precision and usefulness of the types decrease..
I've found a workaround that is going to be good enough for now: I made a dummy package that depends on CLaSH, and I use that as the `package` as far as Stack is concerned: resolver: lts-12.14 packages: - location: git: https://github.com/gergoerdi/empty-clash commit: f5ce90ce1 extra-dep: false extra-deps: - ghc-typelits-natnormalise-0.6.2 - ghc-typelits-knownnat-0.6 - ghc-typelits-extra-0.3 - git: git@github.com:clash-lang/clash-compiler commit: b4e3d5e79ee5 subdirs: - clash-prelude - clash-lib - clash-ghc 
Please see my sibling comment: I think that should work for our use case.
Not too much. Searching for "algebra" gives this package (presumably by the same Ishii): [computational-algebra](http://hackage.haskell.org/package/computational-algebra) There was also [DoCon](https://homepages.inf.ed.ac.uk/wadler/realworld/docon2.html), but I don't know much about it. I have some code for multivariate polynomials and the ring of symmetric functions, but it's not released yet. I also have a combinatorics library: [combinat](http://hackage.haskell.org/package/combinat). In my experience, Haskell's type system is not rich enough for computer algebra (you would want full dependent types), and probably also not convenient enough (you want to leave lots of things implicit most of the time).
I agree that it is a silly law. I think a better reason not to have a Monad instance is because it lets you write code which silently breaks the promise of accumulating the errors.
If you're interested in a denotational semantics for inheritance, you can look for William R. Cook phd thesis "A Denotational Semantics of Inheritance"
My background was entirely in object oriented programming (well, and some C and assembly). I don't really know why, but functional programming appealed strongly to me once I started reading about it. The first thing I read was LYAH, which isn't really the best tutorial, and I remember that I would read through several chapters and then reread them the next day and then again the next day. Eventually, I started to develop a mental model of how programs in Haskell worked, and then I had to figure out how to actually do anything useful with the language (easier said than done!), and now I've been worked the last four years exclusively in Haskell. I would recommend trying to learn it. It's worthwhile to study different models for building software even if you don't use them all. And you may not even like functional programming (and by FP, I really mean immutability + referential transparency + higher-order types). Not everyone does. But even if you absolutely hate, it's at least worth looking into since it would give you a better idea of why you like object-oriented programming or procedural programming. It's better to pick the tools you use intentionally than to use whatever you happened to hear about first.
How does this compare with already existing packages? * https://github.com/theam/aws-lambda-haskell-runtime * https://github.com/phadej/aws-lambda-haskell-runtime
see also Haskell’s overlooked object system https://pdfs.semanticscholar.org/369b/2b0b33c17c8be9c3922ec06b00b2f02cb94b.pdf for ideas as to how OOP can be implemented in Haskell
I don't think there is any way to do this, mostly because Haddock markup doesn't support it. I'm also not sure this is something we should add - Markdown doesn't support this sort of thing either. Why not manually make a resized copy of your image for the sake of the docs?
/u/stepstep has provided an extensive explanation, I just wanted to also mention Hoare logic, which is a very small formal logic to verify your typical procedural language: it can reason about conditionals, while loops and variable assigment.
Rather than requiring that executables tested in the test suite be built, it seems better simply to provide information to the test suite about the executables (including whether they have been built). Then the test suite could simply disable executable tests for executables that aren't being built. This would allow users of a library+executable package to turn off building of executables they don't need, while still ensuring that any executables that do get built are tested.
I found [this stackoverflow post](https://stackoverflow.com/questions/51225261/can-i-actually-build-and-run-an-executable-from-the-same-package-as-part-of-a-te/51226090#51226090), which shows that `build-tool-depends` can specify `pkg:executable-name` to ensure that the executable is in path for the test suite. If this is stable and intended Cabal behavior (and [this commit](https://github.com/haskell/cabal/pull/5561) suggests that it is), then I think it addresses my initial concern. (In my comment above, I noted that we might want to make executable tests optional when a flag is provided to disable building of the executable, but I believe that could be done in present Cabal by including two separate test programs, one of which depends on the executable.) On the issue of setting up the environment when using `cabal run` to run the tests, see [this issue](https://github.com/haskell/cabal/issues/5411). It seems to me that it would be better to change `cabal test` so it can accept test arguments; using `cabal run` to run the tests is a hack. 
Update: I found [this stackoverflow post](https://stackoverflow.com/questions/51225261/can-i-actually-build-and-run-an-executable-from-the-same-package-as-part-of-a-te/51226090#51226090), which shows that `build-tool-depends` can specify `pkg:executable-name` to ensure that the executable is in path for the test suite. If this is stable and intended Cabal behavior (and [this commit](https://github.com/haskell/cabal/pull/5561) suggests that it is), then I think it addresses my initial concern. (In one of my comments to this thread, I noted that we might want to make executable tests optional when a flag is provided to disable building of the executable, but I believe that could be done in present Cabal by including two separate test programs, one of which depends on the executable.) On the issue of setting up the environment when using `cabal run` to run the tests, see [this issue](https://github.com/haskell/cabal/issues/5411). It seems to me that it would be better to change `cabal test` so it can accept test arguments; using `cabal run` to run the tests is a hack. 
Not really; you have to not fight it. If you are using Haskell think about things the Haskell way, not to Java or Python way. Eventually, they'll ways of thinking will met in the middle; don't try and rush it.
I just want to add that programming languages *originally* arose out of necessity, not formal theory. In von neumann machines, we had a set of step-by-step instructions that performed ALU operations and control flow to dynamically solve problems depending on inputs, creating a state machine with huge amounts of state. It wasn't until later we slowly realizing that constraining languages could produce more clear intent. I'm reminded of Worse is Better in this regard. The first languages high level languages prioritized solving tangible real world applications first, instead of clean, unambiguous solution descriptions. I don't think the original creators of the B programming language considered substructural type systems.
If I were in your shoes, I would just use main as a library function for now. Then, when the cabal parts are mature, switch to using fancier executable tests.
further [self contain everything](https://github.com/nrolland/helloNixShebang)
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/programminglanguages] [Overview of how different practical type systems related to theory](https://www.reddit.com/r/ProgrammingLanguages/comments/adks4d/overview_of_how_different_practical_type_systems/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
That reminds me of *Applicative bidirectional programming* ([PDF](http://www2.sf.ecei.tohoku.ac.jp/~kztk/papers/kztk_jfp_am_2018.pdf)), by Kazutaka Matsuda and Meng Wang, where they turn the type of lens `Lens' a b` into `Lens' s a -&gt; Lens' s b`, similarly allowing a pointful style.
This article accompanies my new library, [cantor-pairing](https://hackage.haskell.org/package/cantor-pairing). Similar work has been done in this area before (see [omega monad](https://hackage.haskell.org/package/control-monad-omega)), but this is my take on it, which has a bit of a different flavor, focusing more on the isomorphism with the naturals than the enumeration aspect (you can skip around, rather than being forced to re-traverse all prior points to get somewhere) and focusing more on types than values. It uses GHC generics to make usage very simple. The article mostly explains the ideas behind the library from a Haskell perspective, and once you understand the basic idea, the library is easy to understand.
It's good you're bringing attention to it Syrak, it's a fun application of the Yoneda lemma I have been working on building an intuition for Yoneda, here specialized to post-composition: ---- You are going on a hike. The Yoneda lemma states that the following statemtents are equivalent: &gt; I can get from point `A` to point `B`. &gt; I can *transform* any trip ending in `A` to a trip ending in `B`. Similarly equivalent, for functions: &gt; I have a function `show` from `Int -&gt; String`. &gt; I can transform any function ending in `Int` to a function ending in `String` (by post-composition) &gt; (.) &gt; :: (Int -&gt; String) &gt; -&gt; (forall x. (x -&gt; Int) -&gt; (x -&gt; String)) &gt; &gt; (.) show &gt; :: forall x. (x -&gt; Int) -&gt; (x -&gt; String) The same happens in this paper, lenses `Lens' A B` are 'lifted' into a *transformation* between lenses ending in `A` (`Lens' x A`) and lenses ending in `B` (`Lens' x B`). And funnily enough, we can go back and forth between `5 &lt;= 10` and a way of transforming `x &lt;= 5` into `x &lt;= 10`.
The Graham Hutton, of Computerphile fame? Cool!
&gt; Async functions are just functions in an async monad. In particular, the async/await syntax that is creeping into languages like Rust, JavaScript, etc. is really just Haskell's do notation hardcoded to a particular monad. It is not that easy in Rust: https://twitter.com/withoutboats/status/1027702531361857536
Worse is Better; C vs. LISP
That looks like a similar trick, thanks! Though they only use the half with the Yoneda embedding, not the other half for pattern matching.
Interesting! Are you willing to have any public discussion about the sorts of research you're looking to support? 
What is hask-scheme???
I have come to use a weird trick involving typeclasses. In order to treat a set of typeclasses as one—to partially apply them together for example—I declare a typeclass without methods that has them as superclasses, and immediately afterwards an instance that has them as preconditions. For example: -- I will use PresentIn as a partially applied constraint elsewhere in the code class (Key k t, Value k t ~ v) =&gt; PresentIn (t :: RBT Symbol Type) (k :: Symbol) (v :: Type) instance (Key k t, Value k t ~ v) =&gt; PresentIn (t :: RBT Symbol Type) (k :: Symbol) (v :: Type) or -- This basically ignores the second argument, useful when some other context assumes two of them class KnownSymbol k =&gt; KnownKey (k :: Symbol) (v :: z) instance KnownSymbol k =&gt; KnownKey k v My question is: does this trick have a name? Maybe I'm overcomplicating things and there's a simpler way to do this stuff? I tried to do it with type synonyms but it seems that they can't be partially applied.
How do I create records with validations ... but without all the boilerplate: https://github.com/public-law/nevada-revised-statutes-parser/blob/master/src/Models/Section.hs ``` module Models.Section ( Section(Section, body, name, number) , SectionName , SectionNumber , SectionBody , toSectionName , toSectionNumber , toSectionBody , parseName ) where import BasicPrelude import Data.Aeson ( ToJSON ) import GHC.Generics ( Generic ) import qualified Data.Text as T import Text.InterpolatedString.Perl6 ( qq ) import HtmlUtil ( Html , toText ) import TextUtil data Section = Section { name :: SectionName, number :: SectionNumber, body :: SectionBody } deriving (Generic, Show) maxNameLen :: Int maxNameLen = 1126 maxNumberLen :: Int maxNumberLen = 11 newtype SectionName = MakeSectionName Text deriving ( Generic, Eq ) instance Show SectionName where show (MakeSectionName n) = T.unpack n toSectionName :: Text -&gt; Text -&gt; Either String SectionName toSectionName n context | actualLen &gt; maxNameLen || actualLen == 0 = Left [qq| Section name must be 1...$maxNameLen chars ($actualLen): $parsedName. context: $context |] | otherwise = Right $ MakeSectionName parsedName where parsedName = parseName n actualLen = T.length parsedName newtype SectionNumber = MakeSectionNumber Text deriving ( Generic, Eq, IsString ) instance ToJSON SectionNumber instance Show SectionNumber where show (MakeSectionNumber n) = T.unpack n toSectionNumber :: Text -&gt; Text -&gt; Either String SectionNumber toSectionNumber n context | actualLen &gt; maxNumberLen || actualLen == 0 || not (T.isInfixOf "." n) = Left [qq| Section number must be 1..$maxNumberLen characters and have a dot: "$n" context: $context |] | otherwise = Right $ MakeSectionNumber n where actualLen = T.length n newtype SectionBody = MakeSectionBody Html deriving ( Generic, Eq ) instance Show SectionBody where show (MakeSectionBody n) = T.unpack (toText n) toSectionBody :: Html -&gt; Text -&gt; Either String SectionBody toSectionBody n context | actualLen == 0 = Left [qq| Section body is blank. context: $context |] | otherwise = Right $ MakeSectionBody n where actualLen = T.length $ toText n parseName :: Text -&gt; Text parseName = normalizeWhiteSpace . removeAnnotation where removeAnnotation = T.takeWhile isLegalNameChar isLegalNameChar :: Char -&gt; Bool isLegalNameChar c = c /= '[' instance ToJSON Section instance ToJSON SectionBody instance ToJSON SectionName ```
I read somewhere that it was influenced by Small-C, although I don't know if it used to have another name. I used to write scripts for San Andreas Multiplayer, an online mod for GTA San Andreas; and those scripts compiled to an intermediate language which was interpetred by an abstract machine called AMX. However, I think you're referring to something else... &amp;#x200B;
The Pawn I was thinking of used to be called Small: https://www.compuphase.com/pawn/pawn.htm Back in the day, someone made a plugin system for extending Half-Life 1 mods called MetaMod. This loaded the actual mod DLL and a bunch of plugins written in C++. Someone wrote a metamod plugin called AMX Mod which let you write server modifications using Small. At some point this forked into AMX Mod X (AMXX), and both of them allowed for a weird alternate world of modded servers which did some wild and gleefully unbalanced things to games like Counter-Strike.
[removed]
Not a bad description. This line is kind of off: "You are smart and can find a way to show us." 
Check out my [countable](https://hackage.haskell.org/package/countable) package. (Note that "Countable (a -&gt; b)" instance is an orphan in Data.Searchable.)
This sounds so awesome. Shame I haven't finished my masters degree yet. Well, well, next year!
Is there a good reason for making that instance an orphan? I can't really think of any good reason for a package to expose an orphan for one of its own classes. If the instance is the only sensible one, you can (always?) fiddle with the module system to make it non-orphan, and if it's not, you should be using a `newtype` anyway.
&gt; You have exceptional emotional intelligence and people skills This and "excellent verbal skills" are in more and more engineering posts I've been seeing. I think a lot of great engineers are screening themselves out right away since this complete package of hard/soft skills is pretty rare, I would think. I hope there are just as many places still looking for all-round solid developers, who happen to be a bit quieter and mostly keep to themselves (but crank out great code every day)
There is nothing wrong with being quiet. Softer individuals can easily have great empathy and communication. It is all about quality not quantity.
Indent four spaces for code blocks.
Thanks for the feedback. 1. I'd love to hear more about what you feel is off about that line. I think understand, but I don't want to miss the nuance of your perspective. 2. We don't ask engineers to design products, but we do need them to work collaboratively with our product team using their critical thinking, problem solving and analysis skills to help manage complexity, find elegant solutions and help contextualize work. This demands a desire to understand the business and the purpose and desired impact of the work we do. I've met many talented Haskellers who have the desire to build great products with exceptional engineering and tools and I want to meet more!
Is this how one would use `hpython`, by writing an `.hs` file using the DSL? [ line_ $ def_ "a" [p_ "b", p_ "c"] [ line_ $ return_ ("b" .+ "c") ] ] Your [readme](https://github.com/qfpl/hpython/) talks about `print . parse`, and your [docs](https://hackage.haskell.org/package/hpython) obviously have a lot of related modules, so I assume the intended use case is reading in `.py` files? I love this. I reach for python especially for their scientific computing libs, and frequently feel that a type-safe `numpy` et al. would be amazing, I look forward to seeing a bit more documentation/motivating examples!
Well, it is just do notation hardcoded to a particular monad. They even explained in the thread how a "monad interface" is possible, just only with very limited constraints. If you work with those constraints in the metalanguage instead of the language level, you can achieve the required ergonomics (breaks, statements, early return, no runtime or boxing, etc) because the computer is given the auxiliary information to solve the borrow tracing in a specific case even though it's unable to do so for the general case.
&gt;1. I'd love to hear more about what you feel is off about that line. I think understand, but I don't want to miss the nuance of your perspective. It has that feeling of "we are the elite squad." There are great programmers with low self-esteem and vice versa...I also personally like working with people who are hard working and expanding their knowledge just as much as people born with a great IQ. It's interesting watching people grow.
&gt;Deadline 18 January 2019. &gt; &gt;Initial contact with supervisors should be made at least two weeks prior to the closing date for applications. Hmm... &amp;#x200B;
Yes, and a monad interface is not only possible, it is in fact *the* current way to use futures in Rust. I just wanted to put that in perspective - otherwise you might think that the designers of Rust (or other languages) would add hype features without thinking about more general abstractions (but I don't think stepstep meant that).
Thanks! That was certainly not the intention. We are 100% in to growth. Continuous reflection and growth are core tenants of how we get things done.
&gt; Is this how one would use hpython, by writing an .hs file using the DSL? Yep, then you can print the value to a file. &gt; I assume the intended use case is reading in .py files? The library can read and write `.py`s, but also had good support for transforming the code. &gt; type-safe numpy et al One thing on our list is to play around with a statically typed variant of the embedded Haskell DSL. If it works well, then definitely expect a type-safe `numpy` wrapper in the future :) 
Gotcha, that makes sense :) Yeah async/await vs do was nicely thought out for rust and I appreciate their tradeoffs; more than I can say for a lot of languages!
The end of the article is interesting, and sort of ambiguously correct. It's certainly true that there are uncountably many (set-theoretic) functions from the the natural numbers to `Bool`. However, that is *not* true of values of the type `Natural -&gt; Bool` discussed here. In fact, this type contains only computable functions, and computable functions are countable! After all, there is an enumeration of computer programs simply by listing all programs with one character first, then all programs with two characters, and so on. So why doesn't the diagonal argument work? Well, even though there is such an enumeration, it's not *itself* computable. Hence, while the counter-example from the diagonal argument exists as a distinct function, it is not itself a computable function. So I guess you can still characterize the set of values of the type `Natural -&gt; Bool` as uncountable, but not in the standard cardinality of sets. You must define some kind of "computable cardinality", which is about having a *computable* one-to-one correspondence. Not sure where that leads. Perhaps someone with a deeper understanding of theory of computation than I could follow it somewhere of interest.
Somehow I missed yours, otherwise I’d have included it in my comment! I guess I was searching for stuff like “enumeration” and “cantor”.
Exercise: create a bijection between `Natural` and `Natural -&gt; Bool`.
Ya there is definitely some distinction between what constitutes a function in set theory and what constitutes a function here. &gt; Well, even though there is such an enumeration, it's not itself computable. But see I would say in our world, if your enumeration isn’t computable, then no it doesn’t exist after all. I don’t think that “there’s a smallest real number but it’s a secret and I can’t tell you what it is” kind of proof is valid in our world. The character enumeration thing (just generate all possible strings and you’ve made all possible programs) is an interesting theoretical argument—I’ve always confronted it with the barrier being at “but how do you know a particular string is actually of the correct type?” and claimed obtaining that information in the first place is where things fall apart, but admittedly that’s a terrible argument and more one I tell myself than one I expect others find compelling.
Interesting on its own, the [Eudoxus reals](https://ncatlab.org/nlab/show/Eudoxus+real+number) is a construction of the real numbers as functions from Integer to Integer with a few boundedness restrictions.
Well, there is such an enumeration. There's no doubt about that. Some subsequence of the enumeration of all strings does, indeed, give an enumeration of computable functions. The contradiction here doesn't occur until you assume it is *recursively* enumerable. Otherwise, it has an easy resolution: the diagonal construction does indeed give a function from the naturals to `Bool` that's not in the set of computable functions, and there is nothing wrong with that. The answer to "how do you know...?" is that you don't, in general. I'm here excluding the possibility that God acts directly to inspire your knowledge of the answer in some non-computable way... If you could know by any deterministic computation, though, then you could also compute the diagonal counter-example, and *that* is where the problem lies.
I had similar thoughts and tried to do without Compiling to Categories. My approach was to replace `Prelude` with a minimal functions that work on categories, representing a `newtype Object b = Obj { unObj :: forall a. ProductOp a b }` and let all methods work on this object type. for example fst :: Object (a, b) -&gt; Object a fst = Obj . Compose Fst . unObj this should work cleanly until you need exponential types and/or fix points.
Wow, this is way more than I was hoping for. Thanks for summarizing the book you linked in such a clear way, and for addressing everything mentioned in the question and more. Thanks also for encouraging me :) I'll try to put some efforts into this, this time!
Stating "you are smart" implies that there are dumb people out there, which is what seems to be off about it. That was my take at least.
Nope, it works! You can even do this: ```haskell data Tree a = Node | Branch (Tree a) a (Tree a) deriving (Generic) instance Cantor a =&gt; Cantor (Tree a) where cardinality = Countable ``` Give it a shot! You *do* have to manually specify that the cardinality is countable for recursive types, though. It's an unfortunate artefact of the way GHC generics works that I haven't been clever enough to work around. One of the emergent use cases of this (at least in principle, god knows how well this works in practice) is encoding: you can say `toCantor @([ Bool ]) 8192734817239481723948127934819723498273948127394812379482` and get a big list of bools, or you can take your big list of bools and say `fromCantor` and get an integer encoding.
Is it the case that "If there exists a constructive injection and a constructive surjection, there exists a constructive bijection"?
I meant the following two examples that do not work (both crash with stackoverflow) toCantor @([Tree Bool]) 0 fromCantor infinite where infinite = 1:infinite 
Yeah - if anything, I hope including a standard verbal/communication skills requirement in engineering roles continues to increase. The ability to communicate effectively, both verbally and in written form, will not only increase the positivity in your own work life but that of the others who work with you. &amp;#x200B; It is extremely frustrating working with people who just will not communicate with you when you need it or seem to take it badly when you need to speak with them, no matter how good they are at their job. I have worked with very quiet people who were great communicators (took feedback well, open to discussion and could communicate their work and ideas well when appropriate) and loudmouths who sucked at communication (wouldn't shut up but couldn't communicate any important info). It's all about understanding when to speak and how to communicate what you need to say effectively and appropriately. 
It doesn't break that promise. It's accumulating the last error! It makes sense, because monad introduces a dependency on the value of the last computation. So the reason people would expect this is historical, or not truly understanding how monad works.
Ya, that infinite list won't work, but I think that's intentional. We often conflate infinite lists with real inductive lists in Haskell (for example, `[]` has a `Binary` instance as well, but you can't actually serialize your infinite list example, either), and while that's unfortunate and sloppy, it's just how things are. But yes, the instance here is only for actual, inductively-defined lists, in the Agda sense of the term. &gt; Can't you automatically derive that from the recursive type definition? If you know a way to do this, please tell me and I will update the library immediately, because this has been annoying the fire out of me for the last week. I [asked about this a few days ago](https://www.reddit.com/r/haskell/comments/ab8ypl/monthly_hask_anything_january_2019/ed3vrjb/) in the monthly questions thread, but it doesn't seem like this is possible, because GHC generics falsely tells you all fields are recursive even when they're not. But yes, it's an ugly wart on what otherwise is a really nice API 😡
I don't know about using a surjection, but if you have an injection going one way and an injection going the other way [Cantor–Schröder–Bernstein](https://en.wikipedia.org/wiki/Schr%C3%B6der%E2%80%93Bernstein_theorem), which is the result that classicly gives a bijection, doesn't work constructively.
**Schröder–Bernstein theorem** In set theory, the Schröder–Bernstein theorem states that, if there exist injective functions f : A → B and g : B → A between the sets A and B, then there exists a bijective function h : A → B. In terms of the cardinality of the two sets, this means that if |A| ≤ |B| and |B| ≤ |A|, then |A| = |B|; that is, A and B are equipotent. This is a useful feature in the ordering of cardinal numbers. This theorem does not rely on the axiom of choice. However, its various proofs are non-constructive, as they depend on the law of excluded middle, and are therefore rejected by intuitionists.The theorem is named after Felix Bernstein and Ernst Schröder. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/haskell/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
This isn't a hard constraint. The reason the advert says this is because candidates need to obtain the support of a prospective supervisor prior to applying, so there is a bit of a 'match making' process prior to the actual application. 
I work on the 'mathematics of program construction', which aims develop simple but powerful techniques for writing and reasoning about programs by exploiting their mathematical structure. My recent papers (available from [http://www.cs.nott.ac.uk/\~pszgmh](http://www.cs.nott.ac.uk/~pszgmh/#bibliography)) illustrate a number of different aspects of this. However, most prospective PhD students don't have experience in this area, so what I'm looking for in practice is an excellent academic record, mathematical ability and experience in FP. Hope this helps!
I actually mailed venanzio.capretta, but didn't get a response from him. Could you please request him to check my mail? My email address agnishom at cmi dot ac dot in
It did help; thank you! Your work seems pretty similar to the stack of papers currently stuffed all over my nightstand/backpack/laptop/etc., so if nothing else you've pointed me to some more good reading. 😄 
You could write the instances for `Data.Typeable` which should be enough to compute polynomial equations for the cardinality of types and solve for one variable.
Hmm. Well that sounds... fun. I'll investigate and see what I come up with.
You might have been interested in browsing the Functional Works platform: [https://functional.works-hub.com/](https://functional.works-hub.com/) and uploading this vacancy there too! Likely a little late now, but you should check it out nonetheless :) Good luck!
I've known for a while that lists and trees of countable sets are countable. But I've never been able to work out the explicit bijection. Are you able to explain how that works?
Ya, that's basically how I think about it. The way it's actually computed though is just sums and products -- you have a goal of type `Tree a`, which is a sum, so we go to the left or the right: if we go to the left, we have `Leaf` and no further goals; if we go to the right, we have a `Branch` and three holes of types `Tree a`, `a`, and `Tree a`, which is just a product of countable things, and we know how to handle that!
Wouldn't you need to keep `z` the same in both cases?
This doesn't mention anything about remote work--is that a possibility?
Is the role open to international applications? Any possibility of visa sponsorship, etc?
&gt; hask-scheme It was a typo. It is husk-scheme. Search hackage.
r/prolog
I have no idea. But I'll write a prolog interpreter today and report back on the results 
This is serious dedication to the cause
Maybe because Prolog has side effects? That's the only thing that might make using Haskell more challenging than doing it in some other high-level language, but this is not a Prolog-specific reason.
Thanks, u/[Rozenkrantz](https://www.reddit.com/user/Rozenkrantz), I am eternally grateful.
I don't see how side effects can be an issue. Haskell supports side effects: they are controlled, but they are there.
I don't see any reason why it might be hard. Maybe this is one of those questions where you learn something while trying to answer it?
I agree, but it is arguably more complicated that unconstrained side effects (although for good reasons). And I really can't find any other reason why it would be "hard" to implement a Prolog interpreter in Haskell, as compared to other languages.
You don’t need to have finished yet. The starting date for the student ships is 1st October 2019. 
I didn't even know prolog had side effects. Though I've only ever used it to when trying out some graphs and queries on graphs. But I did hear people can make web servers on it, so I'm guessing it does have some IO support.
I think I've heard it referred to as a "class synonym".
I don't think it's hard at all, one of the first Haskell programs I wrote was a Prolog implementation, see it here https://github.com/osa1/MANTI I'm on mobile right now so I cant check but IIRC it's small too! Should be a few hundred lines
Haskell is one of the strongest languages for implementing compilers and interpreters. One reason some might think implementing Prolog interpreter is difficult is because it is generally difficult to represent graph and graph based algorithms in Haskell, and in Prolog programs are represented as knowledge bases usually visualized as graphs or trees.
I call it the "class synonym" trick. It is indeed quite useful. The duplication looks ugly but it's one of those points that's still bearable enough that nobody cares to propose a dedicated syntax for it. Once we get [`DecidableInstances`](https://github.com/ghc-proposals/ghc-proposals/pull/114) there may be a greater incentive for that because that trick would probably be the next main consumer of `UndecidableInstances`, which, while safe, can still be considered a wart in various respects. Sometimes this trick is needed very locally, e.g., only to call a single function. In that case a top-level declaration can feel quite heavyweight. The only point of using a `class` declaration is to get a constraint constructor that can be partially applied. If we had type-level lambdas, we could write that `KnownKey` example as `\k v -&gt; KnownSymbol k`. Of course, we don't have type-level lambdas, but we can get quite close using defunctionalization. There seems to be a potentially useful library to be written here...
This is why I was confused, most websites told me that Haskell was one of the best languages for interpreters.
A grammar-of-graphics lib (on top of diagrams, maybe) like ggplot2?
Wasn't there a Prolog interpreter written by Mark Jones that was included in the Hugs distribution? I'm not sure that implementing Prolog in Haskell is that hard but I suspect there aren't many tutorials written with Haskell as an implementation language and general tutorials will use mutation.
&gt;has anyone successfully snuck Haskell into the workplace That's not a great approach. You need the support of management. Technology choices have many factors, not all of which are based on the merits of the technology itself. For example, you might want to consider the following: * How easy is it to find people already trained in this technology? * How long does the training take? * How big is the community and how easy is it to get support? * What are the salaries? * Does it have a solid future or is it a temporary fad? There are more. But the above list should give you an idea that management is sometimes making a wiser decision than you would because they are looking at a bigger picture than you. A better approach would be to have an honest conversation with your boss about what factors they consider when adopting new technology and then to try to make the case that Haskell is a good choice for your company. It might not be. And if it isn't, you should accept it and find other ways to scratch your Haskell itch, or move to a company where it is a good fit. &amp;#x200B;
Fair enough
Not entirely sure if this is what you're talking about, but embedding lambdas into your EDSL so you can write in pointful style is something we did [here](https://github.com/sebastiaanvisser/AwesomePrelude/blob/master/src/Lang/Value.hs) as well and assume is pretty common. We just had: data Val l a where Con :: String -&gt; Val l a Prim :: ([String] -&gt; String) -&gt; [String] -&gt; Val l a App :: Val l (a -&gt; b) -&gt; Val l a -&gt; Val l b Lam :: (Val l a -&gt; Val l b) -&gt; Val l (a -&gt; b) Var :: String -&gt; Val l a Name :: String -&gt; Val l a -&gt; Val l a and we made sure to instantiate the `Val l a` in the `Lam` case with a fresh `Var` during "compilation". (this was a terrible but fun experiment to see if we could write some prelude types and functions in an EDSL that runs both in Haskell and compiles to JavaScript) Again, not sure if this is actually what your asking for ;)
When working for a company,you always have to consider the "getting hit by a bus" factor. If you write a program in Haskell and you leave the company for some reason or another, getting someone to maintain the code that you have written is going to be pretty hard. If you are in a small job market, there might not be any candidate that's available to work on the code you have written. Something you can do that might successfully work is writing functional code that's closer to what your company already uses. If your company works in .Net, you might have a better chance introducing F#, if they do Java, you might be able to introduce Scala. You can also continue working in a functional style using languages that you already use (ex: functional-style JavaScript). You still have to watch out that whatever you are doing, make sure to get managerial approval. When you write quality code, your #1 objective should always be to make the code as readable as possible. If you write code in a style that's foreign to any other developers you might work with, it really harms readability, even if the code is very readable to anyone that's used to working functionally. The last thing you want when working at a company is to get a bad relationship with your managers, it will make your work life more difficult and will ruin any chances you might have at introducing functional programming in traditionally imperative or object-oriented workplaces.
You've heard about this before, Avoid success "at all cost". Very often management that is considering the bigger picture doesn't factor in the cost to maintaining the product in the long run, troubleshooting and fixing bugs. These can end up costing the company a lot more than training time, salaries, ... Unfortunately, you won't be able to convince your boss that Haskell is a better choice than Python, by simply stating how much you hate the later. Now that you've got your prototype running on Haskell, you may suggest that someone else implements the final product, using Python, if they want. I understand that you weren't supposed to write that software anyway; so maybe your boss doesn't need at all.
Might go down this route. And don't worry, I've kept quiet about my dislike of python. My argument was about how this is analysis and I want to be able to prove my analysis is correct easily. This is easy in Haskell but not python. He understandably cared more about maintenance after I'm gone.
This isn't quite the same because my `ProductOp` category can be strictly first-order while still supporting this trick.
In your situation, you should look at Typescript. Much easier to get management approval for, since in the worst case, you can just compile it and have perfectly clean js. But ts is sooo much better to work with. 
Google tweag.io I think they managed to do that in some companies in France.
It's the puppy operator! Daww
Effects, yes; side effects, no.
I vaguely remember an old Infoq presentation called "Molog: typed functional logic programming" that mentioned some challenges. 
&gt;"Molog: typed functional logic programming" Thanks, u/[Faucelme](https://www.reddit.com/user/Faucelme), that presentation helped a lot. Heres the link for anyone interested: [https://www.infoq.com/presentations/molog](https://www.infoq.com/presentations/molog)
&gt; core tenants Are you open to feedback on typos? :)
Not a library, but I'd love a solution to the dichotomy between "force people to provide orphan instances" vs "make your library have a huge number of dependencies so you can provide a lot of instances." The solution in my brain is to add a pragma that marks an instance as being conditionally avilable: instance {-# CONDITIONAL "aeson" #-} ToJSON MyType When determining module dependencies, you then track conditional instances separately, and on a package level, if a dependency is used only by conditional instances, it becomes a conditional dependency. Which is to say, any downstream libraries which *do not* already import `aeson` will not pull it in through this instance above. But if you're including it anyway, you might as well get your instances! This strikes me as having our cake and eating it too---we can avoid orphans and giant dependencies and as a result the ecosystem requires less building and becomes more composable and everybody wins.
Often, when people say "Prolog", they really mean only the pure backtracking core part of Prolog. That's the most interesting part, too, and is quite nice and easy to implement in Haskell. However, real Prolog also has extralogical features (cuts and negation), as well as arbitrary IO. It's a much more pragmatic (and ugly) language than most people give it credit for.
There is an "injective function" (in some sense) from `Natural -&gt; Natural` to `Natural`. http://math.andrej.com/wp-content/uploads/2011/06/injection.pdf
While I didn’t “sneak it” in I suggested it and then started using it after a successful use of Elm. Previously our JS experience hadn’t been great so I suggested Elm and everyone loved it. Then I used that to say there is an Elm like language that works as a server too, and we tried Haskell. Got mostly a mostly good response with some “wtf there are so many more symbols!?!” Comments. Still doing it at work, but I wouldn’t literally sneak it in as others have said it needs to be a company decision.
The fact that you said “sneak” means it’s probably a personal thing that you want to do, vs. something that would really benefit your company. It’s important to try and identify your biases, especially with software. If it’s just a personal interest of yours, I’d stick to doing personal projects with it. That’s more fun fun anyways Getting your company to adopt Haskell is a totally different story. If you want it to be used, try and find some concrete problems you’re facing and show how Haskell could solve them. As in, show lots of code examples and the suggested fixes. If Haskell will bring real value to your company, it should be obvious from the examples you show. I’m not advocating for Haskell at work, but I am using Haskell as an example of how we should be structuring our code. I’ve identified over-mocking and over-stubbing as problems in our test suite that lead to difficulties in refactoring. That translates to physical dollars of programmer time. My argument is that these test doubles are mainly from interacting with external systems all throughout the codebase, rather than at the edges of the system. So I’m then showing how it’s easier to write tests without doubles if you separate pure logic from side effects, for example by limiting database access to the top of the call stack. This is directly inspired by monadic side effects and IO from Haskell, but I think it will give us a tangible benefit. Hopefully my coworkers agree and my arguments are compelling, otherwise I’ll be just doing that on my personal projects.
I feel this pain. I've got a library named `ip` that provides data types for working with IPv4 and IPv6 addresses. I use it in most of the projects I work on. Having `FromJSON` and `ToJSON` instances is essential for a lot of the projects I work on, but it's unfortunate that my library that has absolutely nothing to do with JSON has to incur a dependency on `aeson`. In my mind, there's a small problem with the solution you suggest. What if I'm working on a project with around 100 dependencies and then I add one more. The last one might cause a dependency near the bottom of the tree to be rebuilt (since it must now provide an additional instance). Not only is this inconvenient, it makes it impossible to ship prebuilt libraries, so it breaks things for `nix` users (not that I'm big user of `nix`, but some people are). I think the approach that doesn't ruin separate compilation is to do something like what Purescript does or something like what Edward is trying to do in coda. You have to put the instances in their own packages, but you need a non-burdensome way to do this.
This CONDITIONAL flag doesn't look like complete solution for the problem to me. 1. Instances like `ToJSON` require imports, so those instances need to be wrapped into `CPP` pragmas still. 2. This will probably require new syntax for `.cabal` files. Current syntax uses flags, but if I understood your proposal correctly, you would like to avoid using flags and make this instance available automatically depending on other dependencies. I agree that the problem with orphan instances needs to be addressed somehow. But this particular solution has too wide design space and can be discussed very long time :)
i think a number of people might wish there were Master's projects to work on Haskell library *documentation* .... If nothing else, it might be useful to note [the most-upvoted comment](https://www.reddit.com/r/haskell/comments/9xz3ir/2018_state_of_haskell_survey_what_is_your_least/e9wouzc/) on [this post](https://www.reddit.com/r/haskell/comments/9xz3ir/2018_state_of_haskell_survey_what_is_your_least/).
State of haskell ecosystem: https://github.com/Gabriel439/post-rfc/blob/master/sotu.md#education
A few things happened here that are worth unpacking. 1. You showed that using code instead of manual hand-turning of data is a win. So much so that your boss is giving you time to work on the tool. This is a win. Take it. 2. That response sounds like one from someone who's been repeatedly disappointed (by you?). You fight this, especially by subterfuge, and you'll lose ... badly! In his eyes you've just been caught trying to do just what you're suggesting. I think you've got some work to do to improve your relationship with your boss before trying to influence him. Then, maybe you can have a discussion about the trade-offs of various technologies. 3. Introducing technologies to a company is always a long term proposition. It can only be done by stressing the positives, and they have to outweigh **all** the negatives. Maybe having two implementations (as long as they're done fairly) is a good starting point for that discussion, as you'll be able to compare the benefits. 3. I'm interested in why you "hate" Python. JS I get. The weak typing is unforgivable IMHO, but Python's fundamentals are sound. It supports pretty much any coding paradigm you like, including functional, and has used Haskell for inspiration multiple times. Sure, it's not got the type system of Haskell, it's not declarative and it's not compiled, but it's a perfectly practical language. Now a lot of it's freedom can mean ill-disciplined people write some horrible code, but they'd write bad code in any language. There's no reason your code has to be bad. Above all, tread carefully. You don't want to have someone saying "That James! He's really smart, but you have to keep him on track else he's off in the weeds". I've had a few of those engineers and they're really hard work. 
Hello, I have three questions. Could you explain the difference between equi-recursive and iso-recursive types? What's the formal definition of subtyping and why does it complicate type inference? And third, could I get to know you? I am currently too mentally ill to think about it much, but I have a programming language that I would really love to create one day, and I would truly appreciate your expertise, if the topic does not sound too boring to you. 
Note: I'm fairly new to the haskell ecosystem, so I'm not sure how hard this would be to implement. Also, I don't know purescript so maybe this is what you're talking about already. What if there were such a thing as a conditional library ("patch module?") that could come with any given library (probably optionally, but enabled by default) that's only enabled if the libraries it's a "patch" for are installed? So then your ip library could come with a patch module that includes ToJSON and FromJSON instances, that only gets built and installed if the aeson library is also installed (which would naturally happen if the project used json, i.e. needed ToJSON and FromJSON instances). Then if there were a way for people to write third-party patch modules, and at least some support for downloading them more easily than having to explicitly search (a suggestPatchModules command?), it might be much easier to get integration between libraries. Of course, this would require adding new logic to both build systems and package repositories, so it's not exactly cheap to implement. Really, this isn't a problem unique to haskell in the slightest. It pops up in almost every language with independently written libraries (That's every language worth using) so I'd definitely like to see some solution for it. Programming as a whole seems to have settled on the structure of a package repository and an install tool and it works pretty well almost everywhere... Why not settle on some means of inter-library compatibility too? 
Always :)
&gt; or you can work remotely from anywhere in the US, if that’s how you roll. Yes!
We are not right now. We have in the past and have international/visa employees, but cannot currently.
I've added a web page that gives some guidance for anyone who may be interested in applying: [http://www.cs.nott.ac.uk/\~pszgmh/phd-notes.html](http://www.cs.nott.ac.uk/~pszgmh/phd-notes.html)
Well said!
It’s not about sneaking or buy in. It’s about delivering and doing so more effectively / better or faster or other wise. What are the bottlenecks for product delivery / success in your organization and how does using Haskell to deliver make things measurably better? As long as you can quickly ramp up contributors or whatever that’s just bonus points on top. Point is: deliver deliver deliver. If Haskell makes it that much easier, the proof is in the delivered pudding. Caveat: at some point you will need colleague / management buy in. But the best way to get that is to demonstrate some improvement in delivery of the actual business / org goal. Or a radical improvement in the processes thereof 
If you actually want to make a real pitch, it has to be honest and you have to deliver something impossible. In a former life, I did this by writing a bit-compatible replacement for something that generated a lot of server load but was not mission critical. Rollback was as simple as tweaking a single nginx config. Everyone knew what I was doing as I did it and everyone agreed that I had taken proper precautions. Secondly, you really need to offer something that's impossible with other languages. This is easier than it sounds. :) I pitched Haskell to a team that was frustrated with PHP. I offered super fast, safe concurrency and more reliability than can be expected from Java. Another impossible thing you can offer is 100% reliable unit tests. If you set up your main application monads to be runnable with our without access to IO, you can guarantee that every test is fast and reliable. Lastly, you really need to honestly be willing to work with your team. Your leadership has real, logical concerns and they might actually have a point. You need to understand and address those concerns in a rational way.
I disagree. I believe the value of an API is not just in what it allows, but also in what it disallows. Validation's API is about accumulating all the errors, and as a result I think it is a feature that its API disallows monadic composition, so that I don't accidentally write code which stops after the first error instead of writing code which accumulates all the errors. It is true that if I took the time to think about it, I would no doubt conclude that it is impossible to implement monadic composition in a way which continues after the first error, but I'd rather have the API's limitations tell me this than to have to write it wrong, think about it, realize my mistake, and then forever be careful when using this API that I don't accidentally use `(&gt;&gt;=)` or use any function which internally uses `(&gt;&gt;=)`.
```works on new reddit but not old reddit``` --- works on both new reddit and old reddit
1) You can solve the imports at the same time---if an import is only used by conditional things then it too is conditionally imported. We have the entire dependency graph available to us in order to solve the problem and I don't see an immediate reason it's not as easy as asking about reachability on said graph. 2) Absolutely---I don't think that's a reason not to do it though! Yes, it can be bikeshedded for a long time, but an easy way around that is to just not, and instead present a good-enough, working solution. 
Do you any preference? There are many different kinds of libraries: - low-level bindings to an existing C/C++ library - data structures and algorithms - interface to a Web service - database interface - language AST/parser/pretty printer/etc. - binary format loader/serializer, - ... I left out the EDSL/combinator libraries, because that's not the kind you'd want to tackle as your first big project. 
Burdensome things are best done with tools---how about a tool that takes instances as we write them today, computes their transitive dependencies, and spits out invisible packages? Tools like hackage can support them no problem, and the dependency trackers can do something similar to my CONDITIONAL suggestion to compute extra instance packages to pull in.
&gt; That James! He's really smart, but you have to keep him on track else he's off in the weeds *sheepish cough*
I used to work for a company where most of our code base was either in Python, and there was one particular program written in C++ for the sake of performance. I offered to try rewriting the program in Haskell to see if it would run more efficiently, and my boss said “sure, give it a try.” (Unfortunately, the Haskell version *didn’t* run more efficiently, but I can’t blame my boss for that.) Approaching your code with a functional-programming mind-set is a useful thing even if you aren’t writing in a functional language. (If you look at the ReactJS Web framework you can see that the architects are very conscious of the need to manage mutable state.) So prototyping a program in Haskell and then rewriting it in Python might be a better experience for you than writing the program all in Python in the first place. Also, if Haskell has made you fall in love with the combination of strong typing and type inference, check out TypeScript.
The craziest thing like that I have done was a command line deployment tool written in Haskell that would automate away some of the web UI annoyances. I did this in the last 2 days of my employment with the company, when nobody would expect anything out of me anyway, other than wrapping everything up. Like others said, I don't think it's a very company-friendly thing to do if you expect to stay. Others may need to pick up the code from you, can't expect them to speak any Haskell.
I don't know if Prolog is harder to implement than Datalog, but this was just posted two weeks ago https://dodisturb.me/posts/2018-12-25-The-Essence-of-Datalog.html 
I write Haskell because it allows me to do more, faster, and better, in certain circumstances. How long did it take you to do the data analysis program in Haskell, including verifying correctness? *Can* you do the same in Python in the same time? If you can, then Python is a fine choice. If you can't, then this points to a tangible business advantage with Haskell. The decision ultimately lies with your boss, but you can report the advantages to him. &gt; You: I chose Haskell to do the data analysis because it would be faster to write and more correct. It took me about X hours to write and verify the code. The Python variant took me N * X hours to write and verify. Using Haskell is going to allow me to produce analyses faster and more reliably, and I anticipate that will be an advantage to our business. &gt; &gt; Boss: I understand that it is better *for you*, but we have other people we need to consider. Haskell is a rare skill that is hard to hire for, and the productivity gains you have right now are negated by the loss of productivity in potential new hires and other folks that are currently working on the project. How do you account for that? You need to have a good answer for this question. Are the scripts for data analysis throwaway? If so, then there's no maintenance burden -- future scripts can be written in whatever language by whoever is proficient. Do you have existing coworkers that work on these projects? If not, then you're the only person that matters *right now*, and the potential trouble only comes through in later hiring. Tons of people want to write Haskell but are using other languages in their day jobs, and the opportunity to use Haskell can be a compelling point in a job ad. However, most people with Haskell experience tend to be fairly expensive senior engineers that prefer remote work, and that may be out of consideration. If they hire a non-Haskeller, how will you train them on the Haskell code? If you do have existing coworkers, then how are you going to train them up on it? What do they think about it? Do they want to use Haskell? Can they make changes to your scripts? How are you managing the complexity and accessibility of your code? 
That is extremely cool!
The scripts were meant to be throwaway but maybe not anymore. They certainly were when I wrote them. And it took almost no time in Haskell. Python will be probably take longer because I'm going to have to nest for loops until the cows come home. But you are right. No one else seems to see the point in Haskell.
You have to sell them on it. They may not buy it.
You are right. Boss doesn't like me much, but that's for other reasons, namely, I approach all my work (when I can) from quite an academic angle and he thinks I'm a pretentious know it all for that reason even though I only do it to minimize bugs. But it's only things like working out loop invariants, proofs etc. This was the first time I tried using Haskell at work. You are right about that relationship though 😬 I hate python because, when combined with all the libraries we use, it's really inconsistent. Sometimes it's OOP, sometimes it isn't, some libraries use different variable naming conventions etc. And it's too free, allowing the sloppiest of code. I know I can overcome all this easily enough, but I don't want to have to. I'll take your advice and tread carefully
This is just someone's opinion. Implementing Prolog is not a straightforward as you might expect. The most common approach, Warren's Abstract Machine, makes use of two stacks instead of one, the second to track choice points for redos. Another complication is user-defined operators in Prolog. But these complexities have nothing to do with Haskell. If I had to, I'd rather take it on with Haskell than a lot of other languages.
What's cool about the "conditional library" approach you suggest is that, in his work on backpack, Edward Yang added cabal support for including multiple libraries in a single package (Currently, only one of the libraries can be public though). But I wonder if there's a way to piggyback on this feature. What if you could have: name: foo version: 1.0 license: BSD-3-Clause cabal-version: &gt;= 2.4 build-type: Simple library foo-aeson exposed-modules: ... build-depends: foo, aeson library foo-distributive exposed-modules: ... build-depends: foo, distributive library exposed-modules: Data.Foo build-depends: base And cabal knew to also build `foo-aeson` if `aeson` was a dependency of the whatever pulled in `foo`. I have no idea what the in modules should be named, and you would have to somehow get those modules to magically get imported when `Data.Foo` was imported.
http://hackage.haskell.org/package/exhaustive
&gt;Very often management that is considering the bigger picture doesn't factor in the cost to maintaining the product in the long run, troubleshooting and fixing bugs Do you have the data to show all of the above will be cheaper with Haskell? &gt;These can end up costing the company a lot more than training time, salaries, ... How much more? Can you quantify it and show data to support your claim? Data supporting these claims would help OP make his case. If on the other hand you don't have data then the case you are making to management is very weak and they have every right to ignore it and move on.
&gt; but that's for other reasons, namely, I approach all my work (when I can) from quite an academic angle and he thinks I'm a pretentious know it all for that reason even though I only do it to minimize bugs. You're dealing with someone who only cares about the deliverable. That's true of a lot of managers. It's understandable. It's how their boss measures their performance. Their focus is the ship date. Anything which distracts from that is a problem. So if you're spending extra time (in his eyes) on diversions (in his eyes) you're always going to get his back up. Writing something in Haskell when it's a language the company doesn't use, and so it needs to be rewritten is yet another example (in his eyes). If you can show that something saves you time, you'll gain a fan. That's probably why you automating the task got him excited in the first place. 
&gt; What's the formal definition of subtyping and why does it complicate type inference? I found [this piece of rust documentation](https://doc.rust-lang.org/nomicon/subtyping.html) very useful to understand that. &gt; And third, could I get to know you? I am currently too mentally ill to think about it much, but I have a programming language that I would really love to create one day, and I would truly appreciate your expertise, if the topic does not sound too boring to you. I don't think that's how the world works. For any topic, for each person who knows a lot, there are tons of people who know way less and who are still interested. Besides, people who know a lot usually have way better ideas than people who know less. Unless you're willing to pay (a lot) for experts' time, I'm afraid you need to study and become an expert yourself if you want to do something that requires expert knowledge. Thankfully it's a lot easier to learn than to research and discover, thanks to the resources published by the masters of a topic.
I did not know there were programming language experts you could pay for their expertise. I wasn't really intending to just exploit you for your knowledge, I actually think my language has some interesting ideas, I am just not fully capable of thinking about them myself, heh..... Ah well anyway, I'll take it as a no, sorry for asking weird favors.
Thanks for the great advice!
There does actually exist a way to reason about the structure of GHC generics, if you're willing to do a bit of type-level programming yourself. {-# LANGUAGE DataKinds #-} {-# LANGUAGE TypeFamilies #-} {-# LANGUAGE TypeOperators #-} Type families can be used to do arbitrary compile-time programming, including introspection of generics. Consequently, it's possible to use type families to manually find recursive cases in data types. There are multiple approaches to accomplish this: here, I will return some custom type-level data that reflects the structure of the generics, except it also tracks recursion data: data Struct = Void | Unit | Const Type -- Reflects K1 cases that are *maybe not recursive* | Recur Type -- Reflects K1 cases that are *definitively recursive* | Struct :+ Struct | Struct :* Struct To produce this reflected data, we essentially want to scan the entire generic stack for a "recursive case". What that means can be a little difficult to define: Here, we define a "recursive case" as any data which is *exactly the same* as the definition of the data type. Note that this may break down in the presence of polymorphic recursion or when the "recursive case" is an argument to another type. In other words, the type function should scan for occurrences of the definition of the type itself. An easy way to accomplish that is to thread the type definition through as a parameter, and pattern match on equality: type family ToStruct b i where ToStruct b V1 = 'Void ToStruct b U1 = 'Unit ToStruct b (K1 i b) = 'Recur b -- If the constant node equals the -- recursive case, mark as recursive ToStruct b (K1 i a) = 'Const a ToStruct b (M1 i c f) = ToStruct b f ToStruct b (f :+: g) = ToStruct b f ':+ ToStruct b g ToStruct b (f :*: g) = ToStruct b f ':* ToStruct b g This type family can now be used to calculate our desired reflected data. GHCi can be used to show this: &gt; kind! ToStruct [Int] (Rep [Int]) = 'Unit ':+ ('Const Int ':* 'Recur [Int]) Which correctly marks the recursive case as "Recur" and the constant case as "Const"! Making use of this in the definition of generic code is quite straight-forward; one simply needs to thread the "Struct" as an additional argument into the type class. A partial example can be shown in a function "dump" which simply yields the recursive structure of a generic type: class GDumpStructure (s :: Struct) f where -- f is the traditional generic gdump :: proxy s -&gt; proxy' f -&gt; Tree (Maybe String) Most of its instances are trivial, fitting into the form instance ( GDumpStructure s f , GDumpStructure t g ) =&gt; GDumpStructure (s ':+ t) (f :+: g) where ... What is different are the *two* constant cases: instance GDumpStructure ('Recur b) (K1 i b) where ... instance GDumpStructure ('Const a) (K1 i b) where ... Just like that, it's possible to give two different definitions for recursive and non-recursive data! Using it is relatively straight-forward: dump :: ( Generic a , GDumpStructure (ToStruct a (Rep a)) (Rep a) ) =&gt; proxy a -&gt; Tree (Maybe String) And I believe this approach should be sufficient for your use case. That said, if you want a more robust system (e.g. one that deals correctly with polymorphically recursive data), I would recommend experimenting a bit with this. I am not sure if I explained every part of this particularly well, so if you have any questions or suggestions for improvements, feel free to either ask them here, send a private message, or something similar.
Hey, I'm no expert in this topic at all, I probably know less than you :) And sorry if I sounded like a dick, that wasn't my intention. The person you replied to previously sounds like the most expert in this thread - but I'm sure that in order to acquire his experience he's been studying the world of types for years, developing tons of ideas related to it. I'm also sure that his expertise (and this and other topics) can land him very well paid jobs pretty easily.
&gt; Indeed many "features" of mainstream languages are actually anti-features because they destroy important metatheoretical properties. Could you give a more in depth example. I'm particularly interested in the end-consequence of destroying one of these mathematical properties is. The references you gave were a bit too academic for me to get my head around.
Thanks, this looks like it's exactly what I wanted! Is this packed up in a library somewhere? I don't want to duplicate all the reflective dumping machinery in my repository if you've already got it packaged up somewhere. &gt; Note that this may break down in the presence of polymorphic recursion or when the "recursive case" is an argument to another type. Ya, that doesn't bother me - as long as I can hit the simple cases I'm content.
Did I ever say it would be cheaper with Haskell ? You said it, so I'll let you go get the numbers. My point is, management usually don't factor in maintenance costs after the product has been released. Get us some data to prove the opposite, if you have them. For management to ignore and move on is typical too, without ever evaluating the benefits of a tool they don't want to learn/understand. Just because it's not mainstream (BS)! But that's fine, some folks are fine using a spoon to shovel the snow in their backyard. As long as they can move some snow around, in their own backyard, I don't care 😉.
I care
Good on you for taking my comments in a positive way.
As far as I know, there is no library for doing this kind of stuff. I just brought it up because there is a general class of problems that can be solved by factoring things out into DataKinds + TypeFamilies, and this just happened to fit very neatly into that problem class. If I'm not mistaken, I believe nearly all problems of conditional instances can be solved using this approach (as long as the condition doesn't depend on the existence or non-existence of a type class instance, since GHC lacks the ability to query for whether an instance is defined.)
Ohhh, good to know. Thanks.
I’ve been workong on something similar. A lightweight compiling to categories that takes in regular polymorphic haskell functions. http://www.philipzucker.com/compiling-to-categories-3-a-bit-cuter/ my FreeCat type is very similar to yours. Irecently added a limitted form that works for closed categories too in the github repo, and some of the rewrite rules. https://github.com/philzook58/not-bad-ccc
&gt; as long as the condition doesn't depend on the existence or non-existence of a type class instance Ya, that was actually another thing I was asking about last week, lol. I originally wanted more size information at the class level with classes for `Empty a` and `Countable a`, but I couldn't express the interactions I needed at the typeclass level, so I just moved cardinality to the value level. Anyway thanks for the help with the type-level reflection stuff - I'll probably implement it in the next couple days or so, or maybe a bit longer, since actually this gives me the ability to do a lot of things I wanted to before but didn't have the vocabulary to say, like balancing the sum and product trees instead of just having it be `Constructor1 U (Constructor2 U ( ... ))`, which should if nothing else give a nice performance boost, and I think should also help the enumeration itself be much less biased.
"Tenant" is a common typo (thinko?) for "tenet" https://grammarist.com/spelling/tenant-tenet/ 
Speaking as a manager of software developers my first instinct would be to trust you. When I delegate a task to someone and I don't specifically give them parameters I expect they will make the best, good-faith decisions in support of our teams' objectives and overall goals of the company. In your case the code would be your responsibility: and that includes figuring out how we're going to support this new code and maintain it. It'd be your responsibility to train developers on Haskell, provide tooling and support, documentation, etc. This means choosing a small, inconsequential tool to write in Haskell is probably the easiest place to start introducing Haskell at your workplace. You might be the sole developer for a while but for a small project it's manageable. A small program is easier to introduce to programmers who are unfamiliar with Haskell than a large program. And you can use that project as part of the training and on-boarding. I don't know the specifics of your company's situation and your team's situation. There may be cases where it's not an appropriate time to introduce Haskell even for an inconsequential and self-contained program. In that case I would ask your manager for feedback. If you're willing to take ownership of this code, ensure it's documented, teach Haskell to your peers, etc... is there some other factor preventing your team from adopting your work as it is?
Thanks, that seems like exactly the same thing, except you achieve a nicer interface at the cost of being slightly more heavyweight.
About the balancing of sum and product trees: Do you mean that you would like to balance the trees generated by the Rep associated type? In case you didn't know, the trees generated by GHC generics are in practice given a reasonably good balance, as specified in the [library for GHC generics](https://hackage.haskell.org/package/base-4.12.0.0/docs/GHC-Generics.html#g:9). Well, technically, it can be any nesting, but in practice it is balanced. Aside from that, I'm very glad to be of assistance! That said, do note that my statement that the previous technique can solve a class of problems is a hypothesis (after all, type families are turing-complete and can pattern match on data, so presumably it could do arbitrary calculations on that data.) However, that's just an intuition I have; it could be wrong because of some complex unforeseen factors. Consequently, I'd recommend solving the problem of cardinality first, since I'm nearly completely sure that can be solved with DataKinds + TypeFamilies.
JavaScript... PureScript compiles to JavaScript [http://www.purescript.org/](http://www.purescript.org/)! In all seriousness, awesome that you used Haskell. I do understand your boss but I wish he would be more interested in your Haskell approach. If someone without Haskell knowledge needs to edit your program, it will be a daunting task... Maybe you can propose to organise an introduction to functional programming in Haskell? See if you can get other colleagues on the Haskell train.
&gt; In case you didn't know, the trees generated by GHC generics are in practice given a reasonably good balance, as specified in the library for GHC generics. Hmm, somehow I missed that. Well that's good news, that should work correctly out of the box then. I still need to do some sort of reordering though, because currently I'm having problems with if you specify a recursive type with the base case not listed as the first constructor like `data N = S N | Z` instead of `dat a N = Z | S N`, you get an infinite loop when trying to do `toCantor @N 0`, which is clearly a bug, so I do need to at least put the zero in the "right place" for my enumeration to hit it.
Why is it generally difficult in Haskell?
Obvious, its not
Tell him, I'll get right to it. It will take me approximately ten times what I spent writing it in haskell. But as long as you are paying. 
At IMVU the conversation lead to a series of tests giving by management to validate that Haskell was a worth the investment. * They made a small prototype to show performance * To prove that hiring was not an issue they hired a senior dev in week after looking * There were other conditions as well but I can't remember them. Then after using Haskell for a while they interviewed all the engineers that had been trained internally to use Haskell to see if it was going well. Long story short, it's not about sneaking in. It's about working with the company to address the concerns.
What about remote international? Same time zone as the US. No need for visa.
Build systems and deployment scripts is my suggestion. Start with things that are always old, crufty and unloved. Make them great, without making Haskell essential (you can always go back to the old scripts if you must). Prove it to everyone there and build on that. See slide 10 from https://ndmitchell.com/#shake_09_oct_2015 for details. 
The Hugs interpreter used to come with a prolog interpreter implemented in Haskell as an example application. Download hugs (2006): https://www.haskell.org/hugs/pages/downloading-May2006.htm 
Derive `beam` table types from plain-old records. 
I don’t want to discourage you but this to me sounds like an unfair place to work. Either they should’ve made clear what tools you should be using, but if not, they shouldn’t dictate the terms if the end goal is what’s important. It also seems particularly ignorant to me that your boss just dismissed the code after just looking at it. He didn’t even try to understand the merits of the language used and demanded it be written in some other language? 
Through the front door in a completely above board manner. Doing it behind management's back is a great way to lose their trust and the ability to do anything radical to improve things in the future.
I did some test setup in Haskell at a previous job. Gave myself a simple DSL from which I could generate both config files and wiring diagram. IIRC, I asked permission.
Not really advice, but what happened for me was that I'd built something on my own time because I wanted to play with it, without expectation that it'd be used for anything - and then we found ourselves needing something that was a few days of coding away from what I had.
We have been teaching this for years to our students. It shows unification, parsing and searching. See the http://hackage.haskell.org/package/NanoProlog Package. 
It can be non-straightforward to create a cyclic graph in a functional manner (without mutating the graph as you construct it). For instance, if you have a type for a node that contains its edges, and you want to make a cyclic graph like `a -&gt; b -&gt; c -&gt; a`, you need `c` to exist before you make `a`, but you also need `a` to exist before you make `c`. In a conventional imperative language you would probably make the nodes and then mutate them later when you add the edges. IIRC, if you look at the [fgl](http://web.engr.oregonstate.edu/~erwig/fgl/haskell/) they wind up creating a monad just for defining graphs, and they cheap out a bit and force you to use numbers as your nodes, so if you want your nodes to be something else you'll have to carry around a map from integer to your type and doing lookups yourself. This may all just be shortcomings of the fgl; I haven't looked for a more modern graph library in Haskell, but maybe there are some that improve on these limitations. It's been years since I needed something like this.
why hate python? - because you spend 90% of the type catching typos, really slow feedback loop of running program and waiting to see where it crashes. - have no idea what type a variable is - I find the language pretty ugly to be honest 
yeah :P, take a month to do it instead. Your boss sounds like a jerk anyway.
You could also go with Reason if you want JS compatability
Why sneak in Haskell when you can sneak in hookers and coke?
I did this with ocaml probably 15 years ago. It was the only way I knew how to build this thing I needed. I felt bad having left the company with this one (fairly small) piece of infrastructure written in a language nobody on the team knew until they eventually outgrew it. The program wrote files in a format that had a hard size limit the they eventually outgrew. I contracted with them to help fix it and started with a design doc to shard the file format. I proposed a fix for the writer tool and suggested the little parts they needed to update the reader (which was Java). They said they didn't know how to iterate iterators to visit the records in the sharded files from Java and wanted to know if I'd do that part, too. I did not, but I worried less about the fud of language barriers after that.
Once again with the `LANGUAGE` pragmas "problem"... {-# LANGUAGE CPP #-} #include "LANGUAGE.hs" Where `LANGUAGE.hs` is 29 lines of `LANGUAGE` pragmas. Does this seem like a reasonable solution?
I have had success 'sneaking' with following technique: * Solve *non-critical* business problems. * These problems should have an existing fallback if your app dies. * Do the work during hackathons / free time if you get these. * Actively communicate about it to your team so everyone is aware. * Be prepared to do out of hours work if needed to keep it going.
A Haskell numeric library on par with numpy
How are you "proving your analysis is correct" in Haskell?
My strategy so far has been to accept that I'll never get to do anything interesting at work, or that anything interesting that I get to do will have to be done in the most frustrating language/environment possible.. &amp;#x200B; I'm really hoping that more software shops start recognizing the value of robust type systems and referential transparency soon.. I don't know how much longer I can deal with wasting my time on boiler plate code and runtime errors.
It would depend on your location and our existing compliance with your country.
The very thought of Haskell, to the soul-crushing machine that is best-practice software development, invokes fear and loathing. You must sneak and mis-direct and obfuscate about your toolset if you are to survive this beast with your sanity intact. So, my successful sneak: Step 1: Incorporate Jupyter into your workflow Step 2: Describe Haskell as an "alternative engine for jupyter python notebooks" Step 3: Find a critical and slow part of the computational pipeline, and introduce the "fast python engine" that is called "haskell" as a solution to a bottleneck (of speed and bugs). Step 4: In describing haskell code, never ever use FP jargon. It isn't a type signature, it's an inline unit test of an immutable type. It's not polymorphism, it's encapsulation of object inheritance. Practice until it sounds natural. &amp;#x200B; It's a jungle out there, good luck! &amp;#x200B; &amp;#x200B; &amp;#x200B; &amp;#x200B; 
Hmm, I guess if you want a linked-list style graph, it'll be difficult, but if you keep nodes and edges separate, a cyclic graph is really no problem. Nodes: [A, B] Edges: [A--&gt;B, B--&gt;A] 
Fgl is I think considered one of the most straightforward approach for most graph requirements in Haskell. The whole numbers thing happens due to the fact that Fgl uses Adjacency List representation for graphs.
Like I said, it's been years, but I did not come away with the impression that using fgl was straightforward.
Proofs by induction, reasoning about recursion schemes and composition laws. As well as all the rest of the intermediate maths laws like commutiveness and associativity.
`brick` for windows console.
It has been a while, I think the report is supposed to be out by now. What is the state of it? If there is something holding back, is there anything we can do to help?
Just want to say job well done on how quickly you took this random possible type-system issue from bug into a diagnosed issue with a prototype fix on a codebase as big as GHC. I get that's not the end of the story, it's an outlier, etc., but still, that's impressive work.
If you aren't tied to Haskell specifically: ReasonML. It's just re-skinned OCaml, but it has the backing of Facebook, has excellent JS interop and it looks less "weird" to people who have only used C-descended languages.
&gt; You are right. Boss doesn't like me much, Once you're in that situation, it can be quite hard to recover. You need to consider that everything you do will be read in the worst possible light and act accordingly.
Wow, looks like I missed this! Four from four years ago. I’m late to the party. Well, it’s great to see someone else feels there’s a need for this too! My colleague Syd commented that it’s also be useful in writing Arbitrary instances. Brainstorming regarding a solution to this problem, I have some comments: * I do think you need to be able to write the constructor names, like a case statement does. * I think that the constructors need to be listed together to read clearly in code, like a case statement. I.e. each case line starts with the name of the constructor and the variables in the fields, you don’t have to go hunting for the final result down a tree. * Template Haskell splicing works (and you repurpose existing syntax) but it’s rather heavy and I’m not sure that a final solution in it can get much better. * Using QuasiQuotes gets you arbitrary syntax, but limits your ability to have arbitrary Haskell code inside it without using HSE or something. And tools like hindent/brittany won’t work on it. * My personal preference for this is a syntactic solution, I personally wouldn’t feel that Generics can provide an ergonomic experience. * I think a source plugin (as you demonstrated with your what-it-do plugin), would give a lightweight syntax (by repurposing as in the TH example). * I do think that list comprehensions, where the result comes first, and the bindings second, makes the most sense as inspiration for syntax. Maybe e.g. onto [ Num i | x &lt;- foo , App f x | f &lt;- expr, x &lt;- expr ] To re-use list comprehensions in one go. I tried to do this with TH, but you can’t define the same variable x twice in the same list comp. Whereas in a source plugin you can do a transformation in the parser stage before hitting the renamer. 
I notice that all the question you raised are short term ones. Actually training is not a problem because almost all people writing Python in data related jobs are not trained to. Salary is not a problem either because Python demand is very strong so qualified people are very expensive but people interesred in Haskell usually accept a lower salary for the opportunity to work with Haskell. Management is usualy skilled to run the business at the upper level: strategies, communication, etc. But have little understanding of the technical reasons that makes operatives efficient. For example evaluating a technical solution by its popularity is not wise. It is much wiser to evaluate what it can bring to the company and what it may cost. My company chosed Scala, which is not very popular, we invest time and efforts in training newcomers. It may seem a poor choice considering the question you raised. But it makes us very efficient. Our clients do appreciate this efficiency. So this is a viable decision. 
Do you just mean that the program is doing what you think it's doing. None of what you said sounds like a product of analysis.
Yes it will be cheaper in Haskell, simply because Haskell has a type system. This would also be true with Java, C#, OCalm, Scala and every language with a type system. If you want data, just look at the Python 2 vs 3 debate. Evolutions and refactoring are harder in untyped language because you're on your own. Python is often used because it very very easy to write something in it. I didn't say something good, just something. Which is actually nice for prototyping. But when you want a reliable software, you're doomed: hard refactoring, mono threaded, very slow outside of Cython, dependency hell, backward compatibility issues, etc. For small scripts Pyhton is perfect, but not for business critical applications. The problem is that when you realise the problem, it is too late: you already have hundreds of lines of Python and no more budget to rewrite them. 
I am have absolutely no experience with that GSoC usually focuses on, so forgive my lack of knowledge. I was thinking that there was a discussion not too long ago about what might be lacking for data science in Haskell (https://www.reddit.com/r/haskell/comments/aa9lmp/when_is_haskell_more_useful_than_r_or_python_in/?utm_source=reddit-android), while we pretty much all agree that Haskell has a lot of potential in that domain. Maybe there could be a project about improving some aspect of Haskell for that purpose? It seems like google doing a lot of data related stuff might like the idea. But again I have a very very naive approach to the whole thing
A haskell numerics library on par with .Net numerics.
Just write a ruby/python/whatever program that calls the haskell executable. /s good luck
My gut (not some deep theoretical understanding) is that this problem should be solved somehow by making it easier to convert between sums and products. If every constructor is necessary, that just feels like a product. If you could easily convert back and forth it would make this simpler I imagine.
How do I find a proper Haskell Developer position? I'm still a Junior and it seems like my country has no opportunity for it and the job postings online most of the time require that a person should have 5+ years of Haskell dev experience etc. I'm still learning the language and I'm also afraid I've already hit a roadblock.
Most of the time, when they say they want 3-5 years dev experience, just apply anyways. Just make sure you're clear about your Haskell dev experience, and if they really do need it, there's little cost for them saying no, and often times, it's not a hard requirement. 
I think you can put the list of extensions you need for *every* file in to .cabal file -- not sure if you can do that for hpack format, but I think so.
I'm using Aeson for deserialization from files, and some of the types use IO, as they need to load image files from a file path when they are parsed. As such, some of them use the following instances: instance FromJSON (IO MyImage) where ... But now I'm having issues with writing the parseJSON for types that hold other ones that require IO. Normally I'd use parseJSON (Object v) = MyType &lt;$&gt; v .: "val1" &lt;*&gt; v .: "val2" so that it is (a -&gt; b -&gt; MyType) &lt;$&gt; Parser a &lt;*&gt; Parser b, returning Parser MyType but for the IO ones, it ends up with (a -&gt; b -&gt; MyType) &lt;$&gt; Parser (IO a) &lt;*&gt; Parser (IO b) -- returning Parser (IO MyType) which of course doesn't compile. I'm rather inexperienced with this, and have no idea how the nested Applicatives would work, since I'm still trying to wrap my head around it. Is there any general solution for this that keeps it relatively simple or reusable?
It’s still substantially worse than Haskell and not even particularly Haskell-like. I’d keep trying for Haskell personally. 
 - Linters, static analysis, type hints. (I think there's also runtime analysis tools if you really care enough about this.) - Errr... nearly all practical languages are typed. - It's not formally beautiful like Haskell, but it's the most elegant dynamically typed imperative language I've seen; from the outside, as well as under the hood.
FWIW, Python is a very popular language in data science (though most of the heavy number crunching is done through bindings via libraries like numpy, scipy, pandas, tensorflow, pytorch, ...). Why do you need to nest for loops?
I've opened an issue here to discuss a project for improving compile times - https://github.com/haskell-org/summer-of-haskell/issues/79
I would write the JSON parser in the normal style without IO and then do a second pass over the parsed JSON to load the images. 
I understand that there are some people gradually working towards dependent types. Types and Kinds being integrated was a dependency of this, if I recall correctly. Are there other reasonably modular features which are required to implement dependent types, that are small enough for GSoC? 
Maybe Elm or PureScript
I'm worried that as from everything I've seen I'd need to use "partial" types, which would extend down the tree. Doing that for sprites would do that for animations, which do that for render components, which do that for entities, and so on.
You can avoid that either by having two types that differ only in the types of the pre/post-hydration fields, eg: data FooRecord = FooRecord { imageUrl :: Text ... } and data Foo = Foo { image :: LoadedImage ... } or by having one parameterized type, possibly with some type aliases for convenience: data Foo a = Foo { image :: a } type DehydratedFoo = Foo Text type HydratedFoo = Foo LoadedImage 
/u/ocharles There's also /u/gelisam's [surjective](https://hackage.haskell.org/package/surjective) (Previous [discussion](https://www.reddit.com/r/haskell/comments/7z7r7q/ann_surjective_an_output_coverage_checker/)).
Sorry, I got swamped with work (career change just before the call for contributions) and real life issues. &amp;#x200B; I'll resend the call for contributions again in March, for the same edition. &amp;#x200B; Sorry again for missing it
You can also browse the source code online: [https://github.com/haskell-implementations/hugs/tree/master/demos/prolog](https://github.com/haskell-implementations/hugs/tree/master/demos/prolog)
seriously, this kind of stuff was massively off putting when I was very first trying to learn haskell and even now just keeping up with this all is a lot of cognitive overhead I can hardly deal with when trying to get my head around a language like haskell perhaps I'm spoiled by "simpler" (to me) language's package managers/ways of dealing with this but something like rust's cargo.toml, one single file that manages everything, is very clear and well laid out would improve my learning and using of haskell by an enormous amount
Have a look at [symengine.hs](https://github.com/symengine/symengine.hs#readme). It needs further development though.
"Formally beautiful" made me chuckle a bit. I like Haskell but I've never seen a specification for this property in any language.
The [algebraic-graphs] (https://hackage.haskell.org/package/algebraic-graphs) library is pretty nice, IMHO. 
Please for your own sake, don't. I was there and I hated C++ and I hated Python and I wondered why Haskell is still not broadly adopted. I regret that I didn't have a good mentor back then and wasn't able to embrace all great opportunities I had at hand. There is a whole world to learn outside of Haskell. How companies organize people to achieve big goals not possible by individuals. How people write and read code. How unit tests make it possible to write complex systems in Python. How machine code works, how memory management works. What popular libraries are out there for Python, C++, Javascript. Computer cryptography, computer geometry, statistics, simulation, system software, IT infrastructure and continuous delivery. I encountered some Haskell and FP opportunities eventually, but they all required experience in software development, C++, Java, mathematics. And all opportunities in the world without exception require social skills and team work.
That's largely because of python's learning curve for non-programmers rather than the merits of the language itself. Obviously it has a good ecosystem for data science now as a consequence, but its popularity says little about its suitability for the task at hand. Anecdotally, I've done a decent amount of ML myself in Tensorflow and I absolutely despised the lack of a type system, particularly when I would train for hours only to have my program crash by a type error or something else that's easily caught by a compiler.
There will be, once you donate a server ;)
FWIW, I LOL'ed.
&gt; Running a suavemente program automatically spins up a webserver and hooks up its pages with websockets. What does this hooking up of websockets comprise? What's sent back and forth? Does the example from the GitHub README send anything over websockets and, if so, what?
&gt; [...] subtyping is a deep topic that has big ramifications for a programming language (i.e., it's not just something on the surface that can be easily desugared away). Question: given the definition of e.g. `Real`: class (Num a, Ord a) =&gt; Real a could we consider `Real` to be an "open sum type" which is a subtype of both `Num` and `Ord`? Firstly, as far as I can see, there's a one-to-one correspondence between type classes and sum types. At compile-time (at which point all instances of a particular type class can be enumerated), we could construct a sum type called `Real` which contains a constructor for each implementation of the `Real` class: data Real = Double Double | Float Float | Int Int | ... and we should be able to pass this type to functions which accept a ` Real a =&gt; a` argument. And -- given that `Real` requires its instance to also be an instance of `Num` and `Ord` -- we can also give `Real` as an argument wherever a `Num a =&gt; a` argument or `Ord a =&gt; a` argument is required. Is this a form of subtyping, or am I missing something?
So you want GHC to compile faster, but you want the task to be detailed by someone else, the work to be done by a student, mentored by someone else? :confused:
It's a bit of a strange question. A better one would be "is it hard to implement a prolog interpreter in Haskell?". If you research that question, either you'll find that the answer is "no", or you'll find that it's "yes", in which case you will also have found some reasons for why that is. I don't like questions that ask you to accept a totally unjustified premise like that. It feels dishonest, or at best clumsy. 
I'm certainly willing to help out but I lack the experience to mentor someone (because I am not that familiar with GHC itself) and I won't be a student in the summer otherwise I would've jumped at the opportunity.
I don't think that issue hurts anyone. Worst case scenario, it gets ignored. Best case scenario, someone with the time and expertise takes it up (and wouldn't have if someone didn't give them the idea otherwise).
&gt; the expectation that a random guy selected from the street should be able to understand a company's product worth of years of work with minimalist effort is a fallacy. Training will always be part of the hiring process, no matter what language a company uses. I agree with this very much; for a large enough project, learning a new language from scratch and then understanding the code base might take less time than understanding it written in you favorite language, if the new language is naturally a much better fit for the project.
Oh yes, please. This would be so cool!
Personally I prefer to see the pragmas in the files so that I know *what language* I'm reading. Complaining about language pragmas is no different than complaining about import statements to me.
[removed]
What would be needed for that? Would it be enough to derive some generics-based representation and then "wrap" all the fields in some type contructor? There are libraries like generics-sop than can provide that.
Oi, tell us the one about how ya found bugs in the CPython parsers using this.
The `collapse_NP` function from package generics-sop (using a product with Parser entries) in combination with `asum` from `Data.Foldable` could help with this.
Maybe, the only work I’ve heard of being undertaken in this direction didn’t make it so far. The record needs to become paramterized by a functor `f` and each field needs to be wrapped in a `C f`. Then you needs some instances to make keys and figure out how foreign keys and primary keys should work. Plus any nested data structures and enumerations. 
The next Mathematics of Program Construction (MPC) conference will be held in the historic city of Porto, Portugal in October 2019, co-located with the Symposium on Formal Methods. Paper submission is 3rd May 2019. Please share, and submit your best papers!
Oh nice, another! Some comments: That approach seems to duplicate the case with construction of the case: &gt; With surjective, I can no longer forget, but there is still the risk that when I do update my function, I update it wrong, and the even smaller risk that I update it wrong in a way which still passes surjective's check. That's good enough of an improvement for me! I think this is a difference, where in my approach you just write `App f x` without duplicating what you're constructing: &gt; I considered automatically transforming the expression given to covers into a pattern, but I decided that this was too error prone because e.g. let x = True in covers (Just x) would generate the pattern Just x instead of Just True. That's another difference. Surjective checks pattern exhaustiveness `Just True, Just False, Nothing` whereas my demo just tests for `Just` and `Nothing` i.e. enumeration of the constructors. I'm not sure whether I want that kind of checking in a parser or generator. If I wrote above `[Num 0]` should I expect a warning that `[Num n]` hasn't been specified? What do you think? That could be nice. Another idea that occurred to me is that my demo assumes `Alternative` to enumerate the cases. `Gen` doesn't implement `Alternative`. In the case of implementing `Gen` for `Arbitrary` instances, you'd want some kind of `oneof :: [Gen a] -&gt; Gen a` list, so that you could write e.g. instance Arbitrary Exp where arbitrary = oneof (ontoList [Num i | i &lt;- arbitrary] [App f x | f &lt;- arbitrary, x &lt;- arbitrary]) I think that would be pretty neat. And with full pattern checking, you could have instance Arbitrary Exp where arbitrary = oneof (ontoList [Num 1] [App f x | f &lt;- arbitrary, x &lt;- arbitrary]) produce the warning `inexhaustive construction: missing: Num [0,2,..]` or whatnot. I guess I can see how that would be valuable; you'd know that if you're using only one constructor of a type then probably the type isn't useful, or your parser is wrong. In the case that some values are just constants, you could stick them on the right hand side with a `let i = 1`. instance Arbitrary Exp where arbitrary = oneof (ontoList [Num i | let i = 1] [App f x | f &lt;- arbitrary, x &lt;- arbitrary])
It could be off-putting for imposters.
&gt; It supports pretty much any coding paradigm you like, including functional I disagree with you here. I think JS is more lenient to FP than Python is. In Python, lambdas are terrible, too many things are statements and there's no tail call optimization. My personal experience trying to write Python in a functional style has been a big disappointment. If you write Python, you need to make peace with OOP and exceptions.
[removed]
If you're not going to put language extensions in each file, please use the Cabal feature intended for that.
So, there are two places you can put an instance without creating an orphan: * Where you define the type * Where you define the class Then, maybe what we need is a third canonical place that you can put the instance in. Maybe something like: ``` expect instance Data.Aeson.ToJSON MyType in &lt;package-qualified?&gt;.MyLib.AesonInstances ``` In the module that you define MyType or ToJSON. 
Yup, like this default-extensions: BangPatterns , GeneralizedNewtypeDeriving , OverloadedStrings , ScopedTypeVariables 
All it takes is just one bad apple before you start writing that in all job posts. "Excellent verbal skills" basically means people shouldn't have trouble finding common ground with you and they shouldn't loathe the time of the day that they have to speak to you.
ML is fairly awkward in Haskell due to the quality of numerics libraries (mainly having nice, efficient ways of dealing with matrices). While some neural net libraries exist, grenade, I really would not recommend using Haskell for ML any time soon. If you want type safe ML, Julia looks fine. It’s still a pretty young language, but it is definitely developing a lot of valuable ML features. I find quite interesting that they put autodiff into the compiler instead of as a separate library. Lastly, I think you got the end backwards. Idris already has dependent types and has had them from near the beginning as that was one of the key things about idris. Haskell will be gaining them eventually, but I’d be surprised if they end up as ergonomic as idris. My main comment for idris is 1. Dependent types have a fairly decent learning curve so I would not learn them if you don’t already have a good sense of more basic functional programming, 2. Idris package/library support is in a much sadder state than Haskell and do to how niche it is I don’t think that will improve any time soon.
The story here shows why time-to-write isn't always a great metric. Sure, you can whack something together quickly in Python, but then someone sees it and says "awesome - let's use that in production!". Now you have to estimate and sell the costs of productionising your Python code: which are often non-trivial and (to people focused on "delivery" only) a waste of time. The difference between prototype code and the final production product gets elided over and over again in my experience.
For me (and I know others have different concerns), it's not *compile* times that matter, but the amount of time it takes to typecheck that matters most. I use a lot of holes when developing, and sometimes I even use `-fno-code` (which sacrifices my ability to even use the repl!) to make this process as fast as possible. The speed at which I can obtain and process feedback on a hole is, for me, the most critical aspect of development.
It streams results as HTML and inputs as JSON. The example in the readme does.
Some reasonably down-to-earth ideas could be reused from the GHC proposals: * Backpackify integer-\*, work on integer-openssl (or I would prefer integer-tommath since it could be vendored easily), see also [https://github.com/ghc-proposals/ghc-proposals/pull/183](https://github.com/ghc-proposals/ghc-proposals/pull/183) * /u/bgamari is working on enhancing the GC to reduce latency by adding a concurrent and parallel mark and sweep collector. I think this is interesting runtime work. How far is that project? * Row polymorphism compiler support, see [https://github.com/ghc-proposals/ghc-proposals/pull/180](https://github.com/ghc-proposals/ghc-proposals/pull/180) * Finishing text-utf8 and merging it with text or backpackify, see [https://github.com/text-utf8/META/issues](https://github.com/text-utf8/META/issues) I don't think something along the lines of "improving compile times" is a good GSOC project. While it is certainly very important it is too unspecific and requires knowledge of many parts of GHC.
&gt; too unspecific and requires knowledge of too many parts That's true. Other comments on Github have also pointed this out. I'm thinking of refocusing that proposal to add better tooling around profiling GHC, or something even smaller than that. Will write that up soon.
Vega (-lite) is such a grammar, so I would try out [`hvega`](http://hackage.haskell.org/package/hvega) I'm sure the library itself could use some love, but it stands on a solid foundation.
Sounds good! I think it is important that GSOC projects have a concrete outcome. For example if a small tool is built or in the end the new GC gets integrated, that sounds substantial and attractive for a student project.
better a relational, transactional in-memory record cache that may leverage STM, with configurable persistence in any database.
Just by curiosity, what is hmatrix missing?
The `ghc-proposals` repo has a number of unimplemented proposals that have been vetted by the steering committee. A few useful ones that stand out to me are: - [Small Primitives](https://github.com/ghc-proposals/ghc-proposals/blob/master/proposals/0014-small-primitives.rst) - [Forall Arrows](https://github.com/ghc-proposals/ghc-proposals/blob/master/proposals/0035-forall-arrow.rst) - [Resizing Boxed Arrays](https://github.com/ghc-proposals/ghc-proposals/blob/master/proposals/0025-resize-boxed.rst) 
Thank You very much. After reading your comment I decided not to deal with Idris at all. I would focus either on Haskell or Julia. I want to implement machine learning algorithms and neural networks just for learning how they work and study bias vs variance as a part of internship. The reason I am looking for immutability and safety is that when code gets huge I might have to deal with more programming headaches instead of logic&amp;maths if I use Julia or python while with Haskell I can code closer to mathematics without much problem(at least that's what I heard about Haskell). Also when I entered 10^9^9 in Julia it gave me 0 as answer while in GHCi it took a long time and froze my system and then crashed stating cannot allocate memory. Such kind of quirks bother me but at least I know GHCi tried to calculate instead of giving wrong answer. It made me lean towards Haskell for now. Am I thinking right? 
&gt;Yes it will be cheaper in Haskell, simply because Haskell has a type system. That's great. Can you point us to some data showing that? How do those costs compare with salaries for Haskell programmers, training costs, etc? If my business is based in rural USA, will I have trouble finding programmers in Haskell? Can I pay a company for 24x7 support in case we run into problems? How many companies provide such support and how long have they been in business and how stable are they? Will they disappear next year like so many other startups? These are exactly the questions any responsible business owner or manager will ask. And we are scientists, no? Don't we want to lean towards making claims that can be proven using evidence rather than just trying to make a persuasive argument? I'm not trying to be difficult here - I've been programming for decades and I'm mostly on the side of us programmers. But I've also owned businesses and have learnt the hard way that what looks like the right tech from a programmer's perspective can turn out to be a poor long term decision. If we want to convince management and business owners to **invest** their money in a technology change, we need more than "trust me, it will be cheaper". I hope you can use this info to build a stronger argument backed up by data or other evidence before trying to make the case to mgmt. Happy coding! 
&gt;I notice that all the question you raised are short term ones They aren't actually. If we are a growing company, we will be constantly hiring and training. Companies can grow for decades. &gt;Management is usualy skilled to run the business at the upper level: strategies, communication, etc. But have little understanding of the technical reasons that makes operatives efficient. That's just not true. We don't hire logistics people to run IT departments. Most IT managers have years of programming experience, and for good reason. I have had some great mentors over the years in IT management who have helped me make wiser decisions about tech. &gt;For example evaluating a technical solution by its popularity is not wise. It depends on the values of the company, doesn't it? If a company is very risk averse and only wants to adopt proven technology then evaluating a technical solution by its popularity is very wise. One size doesn't fit all. &gt;It may seem a poor choice considering the question you raised Well not really. My list was simply meant to help folks understand that every company has its own set of values and those values may include priorities that are not the same as an idealistic programmer who wants to always use the "best" technology. It sounds to me like Scala was a good fit for your company, based on the values and priorities of your company.
[Algebraic graphs](http://hackage.haskell.org/package/algebraic-graphs-0.3/docs/Algebra-Graph.html) has a nice interface which I usually steal even while using other libraries. Basically: - fromInteger makes singleton graphs - `a*b` is the crossproduct so `1*2*..` is the strongly connected graph containing `1, 2...` - `a + b` is the union of `a` and `b` so (1 + 4) * (2 + 3) contains the nodes `1,2,3,4` and the edges `[(1,2), (1, 3), (4, 2), (4, 3)]` aka a diamond. Directed graphs don't fit perfectly into this but an `a ~&gt; b` smart constructor can fix this. 
&gt; I'm not sure whether I want that kind of checking in a parser or generator. If I wrote above `[Num 0]` should I expect a warning that `[Num n]` hasn't been specified? What do you think? That could be nice. I think both have their uses, but constructor checking (rather than pattern checking) seems more common and easier to implement nicely. I'm also reminded of "structured co-recursion" as described [here](https://patternsinfp.wordpress.com/2018/11/21/how-to-design-co-programs/)
Or just use Ocaml.
nice nickname
Sounds like some good ideas. Don't hesitate to write proposals.
If Haskell is a big NO, how would Ocaml be any easier to get past management?
The big selling point of Typescript in this situation is that it is just js, but with some type annotation. Any js dev will be able to read it and modify it, and minimal training is required to get up to speed with writing new code. And as I pointed out; if all else fails, you can just compile the ts code base and be left with perfectly idiomatic and readable js. You can hardly say that about most languages that compile to js. 
i have. my pm just told me to write a part of the project without any mentions of languages, just requirements. so i wrote it in haskell and put it into prod. everyone is happy, i guess.
Don't "sneak" *anything* into the workplace. But on the other hand if something's just a utility script not intended for production you shouldn't be told how to write it. If they specifically don't care about the method, they shouldn't care about the method. You could write it in Fortran if it does the job, so long as no one else ever needs to maintain it because it's a one-off. If they're saying "we want this as a project now" then they need to allocate effort for building it to whatever spec they want, but they can't complain that you built the prototype in a different spec if they didn't ask for anything specific in the first place.
Blog describing a package we created for parsing and generating arbitrary ABIF files
Ok. Since those are not my ideas, I will ping the relevant developers @github and we'll see if these are viable projects.
 % ghci GHCi, version 8.0.1: http://www.haskell.org/ghc/ :? for help Prelude&gt; :set +s +t Prelude&gt; (10 ^ 9) ^ 9 1000000000000000000000000000000000000000000000000000000000000000000000000000000000 it :: Num a =&gt; a (0.02 secs, 137,096 bytes) Odd that it crashed on you.
&gt; At compile-time (at which point all instances of a particular type class can be enumerated), Not necessarily finitely, though. For example, there's `Show String`, `Show [String]`, `Show [[String]]`, etc., etc. This is particularly relevant for polymorphic recursion involving a type class constraint where the type class dictionary may actually have to be constructed and passed at run time. But, yeah, there's definitely some connection between subtyping and the type class hierarchy.
Is this not already possible with Cabal flags and CPP?
Nice small project with clear code!
I would recommend reaching out to Richard Eisenberg -- he mentored a GSoC last year [1] around this topic which was successful. https://summer.haskell.org/news/2018-09-01-final-results.html#dependently-typed-core-replacement-in-ghc
The post is about submitting ideas, not getting them done.
He might be thinking through ReasonML.
This does not work (at least for me) at the top level. So if your .cabal file has more than one target, this clause must be repeated for each.
Here's a use case to consider: something like Project Euler, where you wish to have each problem in a separate file. You've already decided on the base language you wish to use (some extensions, like `TemplateHaskell`, you would leave to individual files). Would you still advocate adding the same 29 pragmas to each file?
I'm thinking about Bucklescript mainly.
I think Ryan Scott mentioned a patch he was working on for the visible dependent quantification. I'm not sure how far along it is.
The small primitives proposal is at least partially implemented https://phabricator.haskell.org/D5258
Maybe add this to the biohaskell github org
Sorry, that's what I meant by "partial" types. Thank you.
&gt; how the nested Applicatives would work Applicatives have the nice property that nesting them *always* produces another applicative. There is a newtype that wraps the nesting and gives you the composed instance: [Data.Functor.Compose](http://hackage.haskell.org/package/base-4.12.0.0/docs/Data-Functor-Compose.html). The relevant instance is: &gt; (Applicative f, Applicative g) =&gt; Applicative (Compose f g) Furthermore: if the outer applicative is an `Alternative` (like parsers tend to be) the composition is also `Alternative`: &gt; (Alternative f, Applicative g) =&gt; Alternative (Compose f g) [This SO answer](https://stackoverflow.com/questions/48833162/programming-pattern-or-library-i-e-idiomatic-way-to-handle-cli-arguments-sema/48835376#48835376) features an example of applicative nesting.
Nothing to be sorry for, life happens to all of us! Thank you very much for all your efforts, and hope you'll get everything on track.
I'm getting really tired of this mentality too. Carefully carving out a GSOC-sized problem (esp. in GHC performance) and then mentoring someone is a lot of work. Unless you end up with a really motivated student, it'll probably be more work than actually just solving the problem yourself. A lot of GHC's shortcomings are not "fun" well-defined challenges. There's way too much moaning compared to contributing. Not everyone is going to be able to make drastic improvements, but most people would probably be able to fix at least some papercuts (thereby indirectly helping by freeing up other people's time).
The type system on Julia should be strong enough to take care of you for the most part. I don’t think Haskell’s type system adds much that will be ML useful unless you want to actually do quite a bit of work with types. The most obvious candidate for a place where near future Haskell would be useful in ML is using dependent types to ensure dimensions of tensors for all operations are consistent (as in you only multiply matrixes that can be multiplied). As for the number example it isn’t really meaningful. If you ever have something like that actually appear, I’d hope it never enters your gradient unless you want to deal with issues of too large a gradient (which would screw over something like gradient descent). Julia I’d guess (based on the 0) also does not by default use big ints which while big ints may have the benefit of precise results, are also slower than using native ints and for ML you rarely want to go outside native. In fact for ML doubles are rarely used as they have too much precision and are just slow. Some people use half-floats which are lower than normal precision floats just because even floats are more precise than needed for a lot of ML applications. Other aside good luck working with matrixes in Haskell in a convenient and efficient manner. That’s the languages biggest ML weakness. The tendency for immutable also can be annoying for parts of ML. There are ways of using mutable things in Haskell but it’ll complicate your code.
To be clear. I think 1 &amp; 4 are perfect ideas but 2 &amp; 3 are not as good. You should know though that Jasper himself worked on text-utf8 for a GSoC in 2011 so it might not be an easy project. 
*Finally* a reply that isn't so serious. I was beginning to think /r/haskell had lost its sense of humor. Here's an additional, fairly sneaky, technique that might bear fruit: * Write some Haskell on a whiteboard, without anyone noticing, and hide somewhere with the whiteboard in sight. When a group of colleagues starts forming in front of the blackboard -- scratching their heads and looking in wonder at each other -- come walking by with a cup of coffee, stop in front of the whiteboard, take a sip, and loudly proclaim "that looks a lot like Haskell!", and take it from there. 
You can have the same type inference with plain record fields too. I used VSCode with haskero and it is very pleasing.
I see. What's the actual issue you have with them? Is it that you have a lot of different fields that need to be populated via IO so you'd end up with tons of type parameters (and/or lots of duplicate classes) or what? I can't say that I've ever dealt with a situation with an exceptionally large tree of types but I've used the parameterized approach on reasonably large and complex trees of types and found it pretty satisfying, especially with the type aliases to avoid having to manually fill the parametrs everywhere.
Well, that's a matter of opinion. The problems focus on different aspects and require different skill levels and interests. What I would agree on, is that 1 &amp; 4 might have a more defined outcome. 1. Is a bit undefined, since it is not clear what people want in the end. I don't think integer-openssl is a good idea, in contrast to integer-tommath. Also there was some discussion about a pure haskell solution, which is faster than integer-simple. This project is mixed lowlevel code/Haskell code. 2. Working on the GC (Immix) has happened before in a GSOC. This project would be interesting for someone who likes to work on the lowlevel runtime internals. However in the end it might turn out that the GC won't be added (as has happened to Immix). 3. There was a long discussion on github, which I stopped following at some point. Maybe they concluded that the proposal should be done differently. But then some research could be done as part of the GSOC. 4. I know that text-utf8 work was done during another GSOC. I asked /u/hvr_ at [https://github.com/text-utf8/META/issues/4](https://github.com/text-utf8/META/issues/4) and he seems positive about it.
Semi-relevant plug here. In the last month or so I've been playing with making a library for declarativly representing optimization problems. Right now it's fairly limited (only LP with two phase simplex; restrictions on how problems are defined) but the aim is to extend to other methods and support things like FFI wrappers and nonlinear problems. Link: https://github.com/alex-mckenna/optimum
Very interesting! Did you already see https://hackage.haskell.org/package/optimization ? It's a native implementation (with minimal dependencies) of a number of recent methods for convex optimization. Maybe it's convenient to use within your project, later on.
I hadn't seen that. Very cool (and by Ben G, so probably far better than my library). I could see it being good for comparisons later down the road if I get into nonlinear things. I think the main thing I'd like to see is a hmatrix / numpy / Math.NET type thing with a decent dependently (or semi-dependently) typed API. I'm currently using the Static module in hmatrix but find it pretty lacking. I actually do most of the work with vector-sized and convert to hmatrix types where I have to...
This isn't what you've said you're looking for, but I like to use nix shells for playgrounds: `nix-shell -p 'haskellPackages.ghcWithPackages(p: with p; [aeson lens whatever])'`. You can then set up a `shell.nix` file so you don't have to retype the incantation.
Your general point is valid, but this is one of the reasons I don't like Aeson's approach. A typeclass instance says there's one canonical way to do this thing for this type, and for JSON encode/decode that just isn't true. I find myself either: * defining serialisation in the bowels of my program alongside core data types (in the web service context, this messes up layering) * defining newtypes at the API layer, JSON instances on the newtypes, and hoping that people remember to use them when defining services. I'd much prefer encoders/decoders to be normal values, and I'm looking forward to learning [waargonaut](https://hackage.haskell.org/package/waargonaut).
 python -c `perl -e 'print "[" x 100'`
That makes everything way clearer, thank you! And I'll make sure to make a newtype for it instead of just using IO.
Yeah, that's the issue I'm afraid of with it, but doing the other way definitely has the issue with manually filling the parameters. I'll make sure to keep that in mind.
I think the differences are even more fundamental. Near as we've been able to figure, the computational model of the human mind involves an incredible amount of, for lack of a better term, heuristic hacks. At simple levels, such as sensory input, we do things like re-arrange or re-scale our perception of time retroactively so that cause and effect appear to fit together more appropriately, or so that we process realizations about input when it's more appropriate or convenient. There hasn't been much discovered, as far as I'm aware, that may indicate that higher order functions like communication function any differently. One of the fundamental assumptions behind modeling computation is that there are discrete steps involved, and that they happen at specific points in time in relation to each other - Our brain craps all over that foundational concept constantly in even the most basic of it's operations. Trying to measure `O(anything)` related to cognition is likely totally impossible.
Echoing this, I've had similar experiences. It hasn't really lead to much adoption by the organization, but I've had such a solid track record with being able to quickly spin off various tools from my side projects that I now spend a fair bit of time at work getting paid to write Haskell, solving issues others would find too arduous or too risky to bother attempting to automate. It's still a far call from my full time job, but being able to consistently provide quality, safe, adhoc work-arounds to fight specific fires has more or less given me carte blanch to write whatever tools or scripts I want to in Haskell. Sadly I am no closer to actually getting a day job writing Haskell, so it's hardly a basis for a career, but it's improved my job satisfaction immensely.
I might borrow your method of embedding examples sometime. I'm not sure if I will keep the examples in the library or add another examples executable.
As an Ethiopian-American, Haskell user, and as someone who is working with Cardano for my final grad project, I feel like he went further ahead and done what I would have attempted to do later on. Such a wonderful project!
Indeed, I have an almost-finished implementation [here](https://gitlab.haskell.org/RyanGlScott/ghc/tree/visible-dependent-quantification). The biggest remaining hurdle is resolving some ambiguities around parsing `forall a -&gt; ...`, which could possibly require a GHC proposal (or two) to establish more clearly how much special treatment we should give the word `forall` in GHC. Barring that, however, I think it's nearly there. 
I would be careful about jumping into other cultures. It might be more natural to teach a local women computer scientist the overall framework and allow her to shape the curriculum to match communicating within each rich, complex culture.
That was great. Something I am definitely going to steal.
Thank you. I will try to code in Julia and Haskell and see which fits me better. 
That's what common stanzas are for.
I used 10^(9^9) and may be because I am already running a few ml models it ran out of memory. But I love the fact that Haskell didn't give me wrong answer and tried to do the right thing.
Yeah I was not sure about the best way to do that. Embedded as a library seems to make the most sense for now. And it is not my idea, I stole it from someone else :P 
:D
Yea! I'm sick of how overrepresented Etheopian men are in functional programming! /s
I'm so glad someone found it useful :)))
Because men are born with knowledge, money and position, they don't have to work for it /s &amp;#x200B; Can't we just teach PEOPLE? No matter what sex, religion and color they are / have?
How do I subscribe to a comment thread on Reddit?
Haha right? This is going to be good. How dare I not think maximizing certain demographics participation in arbitrary fields of study is a good idea?! Nobody has replied yet, though. And I was actually pretty excited to see people try and justify why it's more important that Ethiopian women are programmers than Ethiopian men!
Serious question though - why? As in why Haskell? 
Lost me at blockshit
Found this: https://twitter.com/LarsBrunjes/status/1081104252171415552 So the courses were all men in the past (due to explicit exclusion of women?; it’s unclear). So he’s explicitly excluding men now because… two reasons I can think of that make sense with that tweet: either because he was explicitly excluding women before and he’s playing the segregation game — which I doubt is the case — or because he’s a subscriber to the equality of outcome doctrine. Either way, not good. The equality of outcome doctrine is poison and I will constantly be calling it out.
Looks great. The use of tikz is the main reason why I still compile LaTeX with pdflatex/xetex while I could have written markdown with pandoc template.
Bingo! And ew. "at least as talented," huh? Guy seems sexist to me. 
Welcome to Reddit, /u/fast2slow!
[The Economist ](https://perspectives.eiu.com/technology-innovation/blockchain-secure) 
servant. It takes some time to get used to, but is really elegant. Plus, they have really good documentation: https://haskell-servant.readthedocs.io/en/stable/tutorial/index.html
For small applications: Spock (https://www.spock.li/) Medium-sized: snap (http://snapframework.com/) Large APIs: servant (http://snapframework.com/) They are all very good, have good documentation and are well maintained, so look into all of them and judge their relative merits by yourself.
If indentation's the problem, this is my best try: {-# LANGUAGE GADTs #-} main = case Bar 0 of { Bar a -&gt; case Bar (a, ()) of { Bar b -&gt; print b }} -- Haskell won't let me drop these braces :( data Foo where Bar :: Show a =&gt; a -&gt; Foo Otherwise, overloading `let` like that seems feasible with a source plugin.
I think calling this "sequential" is a bit misleading. Let expressions are not evaluated in any particular sequence, whether or not they are recursive. By the way, a simpler desugaring would be: let pat1 = exp1 in let pat2 = exp2 in ... in &lt;expr&gt; That's actually lightweight and comprehensible enough that I think you could reasonably just use it as a non-recursive let today, rather than going through the proposal process for new syntactic sugar.
Oops, of course I'm wrong. I was thinking of the mutually-recursive case, but not thinking about direct recursion. So, never mind about the last bit.
Not sure how problematic this is to implement, but something that would be nice is not dropping the known type information when moving a hole to a `where` clause: -- correctly shows hole type as `Int` e :: Int e = _ -- annoyingly shows hole type as `t`, even though the only valid solutions are of type `Int` e :: Int e = m where m = _
While I agree that some statically-sized data could help users in these applications, I personally find dependent type techniques to have a very small power/weight ratio, at least for a library author. Lots of arcane machinery for relatively little added safety. The real catch in numerical applications is performance; speed and memory, at meaningful problem sizes. This is still a wide-open research area in Haskell. Then again, there are various performance tradeoffs if you look closer, e.g. bridge mechanics simulations have different requirements than high-frequency trading, but you get my point.
This is not the same. Consider: data T = forall a. MkT (Maybe a) f1 t = case t of MkT a -&gt; isJust a f2 t = let MkT a = t in isJust a GHC accepts `f1`, but rejects `f2`.
Haskell was challenging for me to learn but, now that I look back, I can see it's because it's so different from most other languages. And these differences are what makes it so good. I started out learning Visual Basic, then C, Python (and a bit of Java). Haskell was difficult for me to learn because all these languages are very similar to each other, and I had to unlearn a lot of stuff I had unconsciously learned through these languages. In my opinion, Haskell is simpler than all mainstream languages. It's a bit like writing logic compared to programming a machine. It should be easier (if you know logic), unless you still think you're programming a machine.
And if you really don't like all the \`in\`s you could use \`do\` notation: test :: Int test = do let x = 3 let y = z z = 2 x + y main = print test &amp;#x200B; &amp;#x200B;
Surprisingly, `do` notation works, even though `Int` is not in a Monad.
why, aren't you obsessed about d e c e n t r a l i z e d d i s r u p t o v a t i o n
This doesn't work, `let` of any kind is problematic for skolem type variables.
Yes, you're correct, this doesn't introduce the same case statements a monadic do notation would introduce but it is equivalent to the `let .. in` pattern the comment I'm replying to suggests, no?
I was surprise too the first time I saw this. My understanding is that since I am not using a single `&lt;-` it desugars to just a few `let ... in` expressions. :-)
Yeah, I think that must be it. Still doesn't solve the type variable problem though.
I'd also like this. Maybe the syntax could be `&lt;-` to show that it's one directional: letseq x &lt;- abc y &lt;- foo For completeness in the discussion the monadic way is: f3 t = runIdentity (do x &lt;- pure t pure (isJust x))
When you need the pattern matches to actually bring type information in scope you could use an actual monad like `Identity`: test = runIdentity $ do let x = &lt;expr&gt; &lt;gadt-pattern-match&gt; &lt;- pure &lt;expr&gt; ... 
Yeah you're right, in that case you can use an actual monad (say `Identity`), or if you don't need too many GADT pattern matches, I quite like using PatternGuards! :D
I think PatternGuards can help here! {-# LANGUAGE GADTs #-} main | Bar a &lt;- Bar 0 , Bar b &lt;- Bar (a, ()) = print b data Foo where Bar :: Show a =&gt; a -&gt; Foo &amp;#x200B;
In the second case (if that is the case), maybe the women felt like they didn't belong in such a course but because of the explicit exclusion of men they do (for obvious reasons). If the previous two classes were all men (but both men and women were allowed) yet he is able to fill a class of all women now it seems as if something was keeping women out the previous classes (cultural, fear, less interest, I don't know). So women might be interested but aren't showing up. How do you solve it? First approach would probably be to be explicit about women being allowed to attend (maybe this was tried) yet no women attended. So maybe you are wrong, women aren't interested, however the current incarnation now "proves" (who knows, maybe they were forced to attend) otherwise. For next year how do you solve the problem?
Yep, this seems to work. f4 t | MkT a &lt;- t = isJust a 
By the way you can also throw in \`let\` bindings in there if you need: &amp;#x200B; foo | MkT a &lt;- t , Just b &lt;- a , let c = b &lt;&gt; ... , MkT d &lt;- c = ... 
I believe this can also become a pandoc preprocessor ! Very nice work
Thanks for articulating this much better than I did.
Easier said than done. generics-sop is a big beast of a library, with gnarly types (though it's decently documented, it uses some idioms I've never seen used in other Haskell libraries). I too think it's the way to go as a "Rosetta stone" between storable tabular formats, but a practical demonstration still needs to be written.
In that case you could even stick with the `let` keyword. let &lt;pat1&gt; = &lt;expr1&gt; &lt;pat2&gt; = &lt;expr2&gt; &lt;pat3&gt; &lt;- &lt;expr3&gt; &lt;pat4&gt; = &lt;expr4&gt; in &lt;expr&gt; =&gt; let &lt;pat1&gt; = &lt;expr1&gt; &lt;pat2&gt; = &lt;expr2&gt; in case &lt;expr3&gt; of &lt;pat3&gt; -&gt; let &lt;pat4&gt; = &lt;expr4&gt; in &lt;expr&gt; 
[removed]
I agree that for the most part, when I hear Haskell programmers say their library is dependently typed I groan internally. I'm trying (and failing in some ways) to make the types in optimum as unobtrusive as possible. Anything dependent machinery should be hidden if possible. What I'd like in the future is for the indexes on Problem to allow to you choose specialised solvers / reject problems from a solver (e.g. you can't solve a non linear problem with a linear solver). Right now I'm mostly using them to prevent silly errors like mixing up rows and columns. I'm not that good at linear algebra and the typing has already stopped me committing several embarrassing and hard to find bugs! It is a compromise though, and if the types get too strong / weak that it becomes less pragmatic I'll hopefully adjust. As for performance, if the types aren't subverted, I would hope that a linear algebra library with static sizes wouldn't need to perform things like bounds checking at runtime. Although that's probably a very small win in practice.
I am alone in feeling disappointed that this was just marketing hype? Maybe this kind of approach seems to be enough for blockchain investors, but I am reluctant to show this to other developers/teacher because it might consolidate the belief that Haskell is not be taken seriously... &amp;#x200B;
Thanks for the kind, thoughtful and well-researched words.
I recall a discussion on haskell-cafe some time ago: https://mail.haskell.org/pipermail/haskell-cafe/2013-July/109116.html
Servant fits nicely with small, medium and large APIs.
If you want other people to take Haskell seriously, tell them about spam fighting at Facebook, or show them dons's presentation on Haskell usage in Standard Chartered. As for the link in the OP, you might want to block it on their computers.
Thanks for the suggestions, but I already knew about those (and shown them to other people).
When did this sub became like this?
Yes, I'm in Haskell since before 2006. This "troll" know a little bit about Haskell and the community 
Yes, I'm in Haskell since before 2006. This "troll" know a little bit about Haskell and the community
There are some cases in cognitive science where complexity analysis (of a simple kind) appears to be useful. For example, there was a famous 1971 experiment by Roger Shepard and Jacqueline Metzler which tested people's ability to compare rotated three-dimensional objects. Wikipedia summary: \&gt;\[The\] experiment specifically tested mental rotation on three-dimensional objects. Each subject was presented with multiple pairs of three-dimensional, asymmetrical lined or cubed objects. The experiment was designed to measure how long it would take each subject to determine whether the pair of objects were indeed the same object or two different objects...\[T\]he reaction time for participants to decide if the pair of items matched or not was linearly proportional to the angle of rotation from the original position. That is, the more an object has been rotated from the original, the longer it takes an individual to determine if the two images are of the same object or enantiomorphs. &amp;#x200B; That seems to tell us something about the algorithm that people were using to rotate and compare the shapes. 
Just thinking out loud: One thing that makes Python so great is the ease of doing I/O in different file formats. Certainly we could make some DSL on top of Haskell, but if we want to remain in Haskell, then newcomers will have to deal with its strict approach to IO. Is this something we would want to keep (in the end, Haskell being strict about things is one of its main benefits) or can we work around it (including a pragma that does some simplification so that newcomers can do I/O more easily?)
I love your videos
You can already handle that specific example with `do` notation: foo = do let (x,s) = foo 1 [] let (y,s) = bar x s let (z,s) = baz x y s ... (x, y, z, s) The issue here is that the let statements don't bring type information like they would when pattern matching whereas the `Identity` monad workaround does bring that.
can talk a little bit about how guitaa uses haskell?
ImportURL extension for haskell
I recently read about recursion schemes, and to be honest I don't fully get it. It looks very general and interesting for theory, but do you know some example of problems that are better solved with recursion schemes ? In particular, how does it compare to a Foldable/traversable approach ?
Needs more slap bass in the title slide tbh : https://www.youtube.com/watch?v=_V2sBURgUBI 
More cowbell!
Is this related to [Chordify](https://chordify.net/)?
Jobs page makes no mention of Haskell or even FP https://www.guitaa.com/join-us
when i grow up i want to be like oskar... truly a knack for making things easily consumable, and also does great work
Thank you! I'm very glad you enjoy the content.
Thanks! Haskell meditation perhaps? 😜
&gt;If the previous two classes were all men (but both men and women were allowed) yet he is able to fill a class of all women now it seems as if something was keeping women out Do we know yet if this is actually the case? Has he filled those classes?
I'm a bit confused on how this looks when you get to your boundaries and have a concrete monad or monad stack. Do you just provide a function from \`f r e a\` to \`EitherT e (Reader r) a\`, \`ReaderT r (Either e) a\`, \`Either e a\`, etc.? And where do the effects functions come from such as \`ask\`, \`get\`, \`put\`? 
What's poison is waste-of-time discussion threads like this on /r/haskell. 
&gt; It looks very general and interesting for theory, but do you know some example of problems that are better solved with recursion schemes ? All of them. ;) "Recusion is the GOTO of functional programming" -- http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.41.125 The vast majority of languages (including Haskell) do not check the totality / productivity of recursive calls, accepting programs that will "go wrong" on some inputs. Each recursion scheme reflects a certain (fairly) safe way to do recursion, which can eliminate certain types of errors. In addition, recursion-schemes is simply DRY applied to the "structure" of the recursion. Each scheme corresponds to a way to place recursive calls in direct recursion. This is similar to the way "structured control flow" keywords gave names to certain ways to use GOTO, thus carrying more meaning and making code easier to read and maintain. Recursion-schemes can replace direct recursion entirely, just like structured control flow has replaced GOTO in many languages. Also, *unlike* structured control flow recursion-schemes are perfectly general. There are certain GOTO structures that don't have a structured control flow replacement, but *every* direct recursion (dealing with uniformly recursive data) that you can write is actually a form of either `gcata` or `gana` --- In practice it's good to know about recursion-schemes, but there *might* be a cost to using them. Polymorphism, lack of REWRITE rules, and needing to encode some strictness properties via CPS means that using recursion-schemes in your Haskell code *might* cause it to be slower than direct recursion. At one time, recursion-schemes was generally faster, since all of them have been worker/wrapper transformed; if your recursion is subject to that optimization and neither you nor GHC apply it, recursion-schemes might still be faster.
Semi-related question: I see that my post gets little response, which means I haven't communicated well enough. If anyone has tips for me on communication, you are most welcome!
+1 for wanting syntax for this. We really are just asking for a reoriented syntax for a case with one alternative, right? And one that doesn't necessitate braces or extra indentation. caselet &lt;bpat&gt; = &lt;bexpr&gt; in
True. Does this conflict with any syntax?
I'd hesitate on using `&lt;-` for this, since I read that as "bind" and there's no monad in this context. … I suppose you could argue that this context is the `Identity` monad. (The `PatternGuard` context is effectively `Maybe`.) Could be nice as Ashley mentions to have something you could interleave in a multilet, though.
Why won't this cause an incomplete pattern match warning?
In that case, you ought to use the `default-extensions` field in your Cabal file.
Like what? Conscious that men are people who deserve to be treated equally? 
Because `Foo` only has one constructor: `Bar`. Otherwise you would need to handle the other cases in other guards. :-)
Oh that's a good point. I could easily make a version with the \`IO\` monad instead of \`Compiler\` so people could use it outside of the context of Hakyll.
 s_push: parser stack overflow MemoryError
Looking at his twitter it seems that way.
Piss off.
Piss off.
[removed]
This is the response that has finally shown me the way. I did not know about common stanzas. Thanks for mentioning the important key phrase.
Thanks. The missing piece was "common stanzas", which I did not know about, but /u/Solonarv showed me the way.
While I can get behind separating WARNING and DEPRECATED, I dislike special-casing any warning for -Werror. It's inconsistent and violates the principle of least surprise.
My first language was Python, I then learned quite a bit more JS, and then learned Haskell. My learning experience went through two basic phases: Syntax, and the type system. Syntax was a brick wall for about a week. Then it got easier, and shortly after I got hooked and started to hate every other language. The type system was and still is an open topic of research. It's huge, it's confusing, but it's awesome. You get to a point where you realize how much you need to know to write code, and focus on honing that core knowledge instead of trying to swallow the whole thing. That process takes a lot longer but it's generally less frustrating/painful and more just mystifying and confusing. Key points: - GHC error messages are not there to punish you, they're there to help you write good code. Learn to recognize them and get some idea of what they're trying to tell you. You don't have to fully understand them all at once for them to be helpful. - Due to several quirks of the language syntax you'll get type errors for what feels like it should be a syntax error when you're learning. Look for bad indentation, spacing, or what not before looking for type mistakes until you get more comfortable with the syntax. - When you're learning how to use recursion instead of loops, it's helpful to think of it as 'goto' with state you have to manually carry around. That gets you through the initial hurdle, you can build a stronger understanding later. - Don't read a bunch of tutorials about Monad. Just try to write some do notation and read GHC error messages carefully. Go learn about how do syntax desugars into calls to `&gt;&gt;=` and `&gt;&gt;`, and try manually re-writing a few functions without using it fairly early on. Once you're comfortable with doing that, that exercise can be a good tool for understanding confusing error messages later. - If any article or documentation starts blabbing on about category theory, just skip that paragraph and keep reading. It's not important and it probably won't help you unless you come from a strong high-level math background, which it sounds like you don't. - It'll be really confusing for awhile until it isn't. That's totally normal. - Use stack as a build tool until you understand why you might not want to, then use whatever seems appropriate. It's not worth thinking deeply about as a beginner, and stack has a better new user experience. - Don't mess around with installing fancy editor extensions and crap to give you better tooling until after you figure out how your build tool works. GHCi in another window works fine for a long time. If you try to learn all about buildsystems and integrations at the same time you're learning the language, you'll get overwhelmed and have a bad time. Save it for later. - Get help on reddit and irc (check out the sidebar on this sub for appropriate links). Stack overflow is drastically less useful than it is for other languages, but the community there is still responsive, well meaning and very helpful. 
I'm trying to speed up a raytracer using parallelism, but just can't get it to work. Whatever implementation I'm using (for testing I used amongst others [this code including the fix](https://stackoverflow.com/questions/51366501/performance-issue-with-parallel-computation-in-haskell), so the code itself should be fine) but using multiple cores doesn't give any speed-up and -s says I'm not making any sparks. As far as I'm aware I'm giving cabal all the flags: ghc-options: -O3 -threaded And I run the program using cabal new-run +RTS -N4 -s Given that the code is correct I suppose my build configuration is at fault, but I don't see where I could have messed this up. Help would be much appreciated.
Is this not giving the rts options to `cabal` rather than your executable? What about `cabal new-run -- +RTS -N4 -s`? Otherwise try `ghc-options: -O3 -threaded -rtsopts -with-rtsopts="-N4 -s"`.
I disagree with the premise. Downstream users have `-Werror` explicitly because they want to be informed of stuff just like this. If they don't care to adapt just yet, they can add an exception to their build process.
In `PatternGuard`, the two sides of the `&lt;-` have the same type. Indeed, it turns out this works (note there's no kind of monadic or Maybe-ish context): f4 :: T -&gt; Bool f4 t | MkT a &lt;- t = isJust a 
Hey, thanks for the input! I agree that users of \`-Werror\` *should* be fine with being broken by any change to a dependency that causes a warning, but the fact that folks that use this option has been used as an argument to **not** to deprecate a function (even a simple rename+alias) because it *could break a build*. So, this could also be restated as an expectation and policy problem. We as a community would need to decide that if you're using \`-Werror\` then you can have zero expectation that you aren't broken by minor releases that add deprecation notices. I would also be fine with this, and I would actually prefer it tbh. As I mentioned in the trac ticket [pvp#18](https://github.com/haskell/pvp/pull/18) allows for \`DEPRECATED\` pragmas to only require a minor version release, and has received support from the CLC. What are your thoughts on such a policy change?
It does seem to work this way (-s does print the information on the performance, including that the program is invoked with -N4). I tried your suggestion still but as expected it doesn't change anything.
I actually don't agree with that still. A warning is a warning, not a broken build. Users of `-Werror` should know what they're getting into and be prepared to add some exceptions to their build in the future. Any breakage from `-Werror` is entirely self inflicted, and most importantly, trivially resolved.
\&gt; While I can get behind separating WARNING and DEPRECATED I think we should do this regardless, and the MR that I have can very easily be adapted to do that without the change to \`-Werror\`, I included them both together since the former carries less weight/usefulness without the latter. \&gt; I dislike special-casing any warning for -Werror I can definitely see this argument, as I mentioned in a reply to /u/ElvishJerricco below, the problem I'm trying to solve could be fixed by adjusting expectation and policy (and I would be 100% on board with that). I'd like to elaborate a bit on my rationale for treating them differently. There's different "types" of deprecations: the most extremes are "It was discovered that this API/function/etc. is broken and you should not use it!", and there's "Hey, by the way, this function foo has been renamed to bar (available now), and foo will be removed in some later version. If you want, you can migrate to the new version now, if not you'll just have to update your code when you upgrade to the next major version when its removed completely." The former is use of an API that could be considered as "dangerous" and should rightfully be treated as an error (and is what I assume folks who use \`-Werror\` care about, not trying to speak for every single user of this flag of course), the latter is harmless and is more of an FYI than anything else. Your code will continue to work just fine using the old function name. This is as far as I know why we have two separate "deprecation pragmas": \`WARNING\` for the former, and \`DEPRECATED\` for the latter. Adding a new function to an API does not require a major release, so why would adding a new function to the API and letting users know about it via \`DEPRECATED\` now require a major release? The API surface itself does not change at all. &amp;#x200B;
It does have one mildly interesting sequential property. `letseq` assures that an earlier binding *can* be evaluated without evaluating a later one, because there's no way for the earlier one to depend on the later one. That said, this isn't a particularly useful property because, as you said, it doesn't actually effect real evaluation. It just imposes a somewhat interesting sequential dependency requirement.
I completely agree with you, but I don't know how to make that official :/ When I proposed renaming `HashMap.lookupDefault` to `HashMap.findwithDefault` in unordered-containers (see the [libraries thread](http://haskell.1045720.n5.nabble.com/Proposal-Rename-HashMap-lookupDefault-to-HashMap-findWithDefault-td5870348.html)) there was a lot of push back and concern because "adding `DEPRECATED` to the old function would break builds compiled with `-Werror`". That entire proposal seemed to languish because it couldn't be agreed upon how to deprecate the old function. That was over a year ago at this point, we could have successfully deprecated and moved users over to the new function in that period of time. In the absence of being able to find a policy solution, I decided to put forward a code solution haha. So, in summary, I would be happy to abandon this proposal if the CLC would adopt a policy on the correct way to change the API of a core library being to add the new function, mark the old as `DEPRECATED` in a minor release, and move on. I really appreciate the feedback, I'll likely take the outcome of the discussion here and on other channels and put together a policy proposal to the CLC and see what they say :)
GHC extensions are usually decided through the GHC proposal process. You or a student could definitely submit such a proposal to the process, and propose it be implemented as part of a GHC Summer of Code project. It would be awkward to accept a student without an accepted proposal, though, because it's unclear what that student would do if the proposal is rejected outright. They would at least need a backup plan to avoid failing the whole project in that case. That's all aside from the details of this specific language proposal.
[removed]
[removed]
I'm fairly sure I understood your reasoning before. I don't think it addresses / outweighs the issues I have.
Ok, I've gone ahead and implemented this. I ran into a bump where it seemed like that `ToStruct` wasn't reducing unless the types were completely monomorphic, e.g., `instance (Cantor a , Cantor b) =&gt; Cantor (a , b)` wasn't being found, but `instance Cantor (Bool , Bool)` was. The former would throw some sort of error like "can't find `ToStruct (a , b) (K1 i a)`, and given that `K1 i a` is clearly not a product `:*:` but the left hand side of the product, it looked like it was only traversing on the second pattern, but... that makes no sense, since it would only have gotten to `K1 i a` if it had already gone through the product thing, which does itself have a first pattern of `':*`, so... I'm not sure quite what was going on there -- my best guess is that it was evaluating the `ToStruct` up until it had to decide whether `a` is recursive or not, then bailed trying to unify an infinite type or something, but then somehow that didn't make it into the error message. Hard to say. Anyway, assuming that was indeed the problem, I changed your instance GDumpStructure ('Const a) (K1 i b) where to instance GDumpStructure w (K1 i b) where and turned on `IncoherentInstances` and put an `OVERLAPPING` pragma on the recursive pattern, which was a complete hail mary, but... actually it... completely works. I ran a bunch of test cases to check since I didn't really believe it, but it passes them all. So yeah, cardinality is now properly detected automatically. Amazing! Thanks again pointing me in this direction!
I totally agree that trying to keep `-Werror` builds from breaking is not a reasonable goal as far as API stability, and that the CLC should be less concerned about `-Werror` builds. --- I don't want to complicate things, but maybe there should be a new type of compiler diagnostic that is even less severe than a warning, and that doesn't get manipulated with a -W* flag and doesn't get promoted to an error with `-Werror`. Certain types of deprecation could use this new low-severity diagnostic level. (I can think of at least two other warnings that are so low-severity I would support downgrading them: `-Wtabs` and `-Wunused-import`, although I'm not sure about the later.)
It seems like for sufficiently small sets, you could use some of Brent Yorgey's (not sure if he's on reddit) work to stitch together a bijection, constructively, from the two injections. I keep thinking about his ICFP 2018 presentation when imagining the geometry of what that bijection would look like. That said, I was spacing out during his presentation a little bit, because I thought that his technique could be though of at the least fixed-point of some process and I was trying to figure out exactly what the step would be.
It sounds like a more general solution would be the ability to turn on `-Werror` but also pass flags to stop certain warnings from becoming errors.
The first course was open to anybody but only men registered. So now they felt would be nice have a first class in Ethiopia with only women not a big deal guys at the end of the day there will be more devOps skilled in Haskell and that’s the main goal
The classes weren’t in Ethiopia so I guess demographics made a difference and now their searched only for women
Because Cardano blockchain is mainly written I. Haskell and they are trying to get more programmers trained to use it and Africa is a big market for Cardano 
How training ppl in Haskell is just marketing hype?? They will have real use cases to work on and these women might have their life changed after this. 
wai/warp
Thank you for taking the time to provide text to accompany your videos.
Which you can already do today.
Looks cool -- lots of the chords look very wrong, but it's impressive nonetheless.
Thanks everyone for the feedback so far! After reading through the comments and thinking about this a bit more there are a few different things at play here, so I'll attempt to separate them out. First, the main problem I'm trying to solve is the lack of policy/clarity around deprecating APIs (the unordered-containers [proposal](http://haskell.1045720.n5.nabble.com/Proposal-Rename-HashMap-lookupDefault-to-HashMap-findWithDefault-td5870348.html) was the motivating factor). The current policy seems to be that if your change would involve breakage for builds using `-Werror` then you need a major version bump, which is unreasonable because those using `-Werror` are explicitly opting in to causing these failures. There are two ways of addressing this: 1. Change the policy ([in the PVP](https://github.com/haskell/pvp/pull/18) and CLC) such that deprecating an API only requires a minor version bump. 2. Change the behaviour of `-Werror` such that deprecating an API doesn't cause a build failure (this proposal). I put this proposal together to have something to compare/contrast the policy change to. Having both in hand we can have a frank discussion about the pros and cons of each. I completely agree with all the criticisms raised here and on trac, and personally I would prefer a policy change and to abandon this proposal. Second, this proposal actually should have been split into two. Proposal A. Differentiate between `DEPRECATED` and `WARNING` at the flag level (no change to `-Werror` at all). And Proposal B. (dependent on A), changes the behaviour of `-Werror`. Proposal A I assume is less (non?) controversial since it actually more closely matches what you would expect the behaviour to be. Proposal B is definitely controversial as seen from the feedback here and on trac. I should have done a better job to differentiate between the two. I'm not personally attached to either way of addressing it, as long as we can come to a decision and implement it going forward.
I'm really glad to hear that it worked out for you! I would've felt so bad if I was actually completely wrong and accidentally wasted your time. About the problems with type families: as far as I can tell, it's probably because type families seem to not unify in exactly the way I expected. While I don't fully understand the rules myself, I took a look at [closed family simplification](https://wiki.haskell.org/GHC/Type_families#Closed_family_simplification), and my intuition is telling me that (a, b) and a aren't rejected necessarily because of infinite looping, but rather because of how GHC picks equations. As for whether this hypothesis is correct, I simply haven't had enough time to *truly understand* the rules enough to be sure. Consequently, this problem seems to be a lot more difficult than I had originally thought, so it's really impressive you found a way to make it work! That said, I think we can both agree that relying on IncoherentInstances is a bit ugly, even if it should--in this case--be perfectly safe, so I've been thinking about how to avoid that: If you've already committed to using OverlappingInstances, then there is no reason to use type families at all in this example. I hadn't considered that simpler approach earlier because of tunnel vision caused by wanting to avoid that extension. However, if the type family approach inevitably requires OverlappingInstances anyway, then we might as well take the simpler approach. Consequently, instead of preprocessing the generic type using type families, and then defining GCantor as: class GCantor' (s :: Struct) f where -- Such that s ~ ToStruct b f hasExit :: Bool gCardinality' :: Cardinality gToCantor' :: Integer -&gt; f a gFromCantor' :: f a -&gt; Integer We can instead pass the original type directly: class GCantor' (b :: Type) f where -- Passing b directly hasExit :: Bool gCardinality' :: Cardinality gToCantor' :: Integer -&gt; f a gFromCantor' :: f a -&gt; Integer And then use OverlappingInstances to recreate the pattern matching in the type family: instance {-# OVERLAPPING #-} Cantor a =&gt; GCantor' b (K1 i b) where hasExit = False gCardinality' = Countable gToCantor' = K1 . toCantor gFromCantor' (K1 x) = fromCantor x instance {-# OVERLAPPABLE #-} Cantor b =&gt; GCantor' b (K1 i a) where hasExit = True gCardinality' = cardinality @b gToCantor' = K1 . toCantor gFromCantor' (K1 x) = fromCantor x Hence we can avoid the use of type families entirely! I suspect that the type family approach has strictly more power (even if it requires IncoherentInstances). However, it seems OverlappingInstances is perfectly capable of dealing with this on its own. As for whether or not you want to apply this simplification to your library, that's obviously up to you.
Yes. See https://www.haskell.org/cabal/users-guide/developing-packages.html?highlight=flag#id2 for an example. Basically, define the flags and use conditional blocks to both add the dependency and define a CPP variable that will guard the relevant code.
You can also do this in pandoc with a small lua filter. &lt;https://pandoc.org/lua-filters.html#building-images-with-tikz&gt; 
Africa is a big market for starvation and AIDS and low iq mongs. Hope you’re ready to be culturally enriched. “What inspires me is teaching african refugees to program in javascript”
I absolutely positively **want** my build to be broken by anything that even smells like a warning. That is the entire point of `-Werror`.
It seems like currently, if you want to deprecate something in your mypackage-1.5.2, you need to bump it to mypackage-1.6 rather than mypackage-1.5.3. Is that correct? This seem OK to me, tbh.
I seem to remember Chordify was also Haskell software (is it still?).
Timing seems to be quite a hard thing for these kind of programs, Chordify last I looked lets you manually adjust the timing a bit so you can get closer to the truth.
That is an awesome bit of Sherlock Holmes given that /u/jamhob seems to agree with all that you said. We all will be expecting a, "You were wearing green shirts which needs a bit of ironing" kind of prediction next.
Why is an IntMap faster than a Map? Even when the Map is specialized to Int? Even though log(n) &lt; W &lt; n?
It's not the timing, lots of the chords are just straight wrong
I haven't noticed any of them do particularly well on the chords unless there's a very strong baseline when it is more reasonable.
I love what they are doing in terms of storing the code as an AST indexed by a hash of it. This is pushing the nix store concept to its logical conclusion. When can we have this in Haskell?
Thanks for the clarification! If there is any mentor or student interested? you could create the GHC and the GSOC proposal? If it is not the case, In a few days I will create the proposals anyway. 
Praise the Monad and keep your mind pure.
Yeah I was thinking the same thing - when I'd originally tried overlapping instances (before posting anything on hackage/Reddit), it didn't work because I only had one parameter and I was trying to match on that `Rec0` vs `K1 i`, and GHC just marks everything as `Rec0`. But yeah, as long as that second parameter marks the recursion point, I think you're right, the type family stuff isn't necessary. I'll give it a shot later today.
The article says that blockchain code should be correct that Haskell is good; that's just wishful thinking IMHO. 
You are the second clearly hostile foreign actor to show up in this thread (unless the first one I sniped was you too). No posts for 3 years, not a member of the Haskell community, coming here to post in the most inflammatory thread and make things worse. I am willing to put up with *a lot* in the name of free speech, especially from people who have karma to burn. You do not. Get out of here.
Most of the project suggestions in this thread are to do with GHC. It would be useful to also think about projects which are related to libraries or applications written in Haskell as they tend to be easier and more potential impact. 
Another alternative is Yesod: [https://www.yesodweb.com/book/restful-content](https://www.yesodweb.com/book/restful-content)
I’m not a computer engineer however I see a lot of business that code is crucial and need to be correct using Haskell so I assume it was a wise choice
I guess in Haskell this has something to do with the fact, that keys in `Map` are stored as a polymorphic variable in data constructors, thus they are stored in heap. In order to get better performance comparison, I can recommend compare `IntMap` with `Map` from `unpacked-containers` package. * https://hackage.haskell.org/package/unpacked-containers My other guess would be that this has something to do with the fact that bitwise operations are faster than comparison. Thus, you may see, that in real-life it's not about asymptotic but often about memory model, CPU cache and CPU instructions.
Your response is meta-poisonous
This!
I'm looking for something like this too, please do share any progress you make on this. &gt; However, it does have the limitation that it doesn't deal perfectly with nested lams (as the parameters to the outer lam cannot be used within the inner one). I'd like to share a relevant link: [Higher-order Abstract Syntax for Cartesian Closed Categories](https://blog.functorial.com/posts/2017-10-08-HOAS-CCCs.html)
&gt; said "God sake James... This was the phrase that sounded so familiar. It's an expression of exasperation. It's happened before. Also somebody doing Haskell in their own time (as I do) is someone driven by curiosity. Whilst that's great and can be a great strength, it's very easy for such people to get very narrow in their focus, and then lose sight of the company goal. The choice of Haskell also suggests they value purity of design over other concerns. Again, a double edged sword. Having both been this person, and managed others with these traits, it wasn't such a leap. Fortunately such people want to learn and grow, so they normally show a desire to understand the bigger picture when exposed to it. Broaden their focus and they step up.
These are quite sad news ;( I was really hoping to see this proposal accepted and implemented soon! It works so nice with common idioms and programming patterns in Haskell. I wished for such feature long before I knew about its existence, it is needed very often.
Would it be possible to implement this in a language-independent way? That is, rather than implementing a Unison Codebase Editor, just implement a Codebase Editor (where maybe each language might need to implement a few details of how that language fits in with the codebase editor, but that's nowhere near as difficult as having to implement all the codebase-editor functionality from scratch)? (Analogous to [Language Server Protocol](https://langserver.org/)?) Like, what aspects of this idea are dependent on the particular details of the Unison language? 
`-Wno-error-&lt;whatever the name for the deprecation warning is&gt;` Will turn those errors back into warnings.
`-Wno-error` exists for this.
I know that there are a lot of technology startups in central africa working in mobile technology, specially electronic payment since they are heavy users of this tecnology, due to the lack of conventional banking and ATMs. Moreover, they can use strong currencies instead of the weak official money. That has been probably the number one de facto cause in the reduction of monetary inflaction in these countries.
Was there a separate post on fused-effects that I missed? It looks interesting.
Which libraries do you have in mind?
That is a great question, I would love to see the same. But I think the Unison devs are working out a system at the moment, there is no point trying to prematurely generalize it. Something that did catch my eye as a possible starting building block is https://github.com/chrisdone/prana
I'm a bit iffy about using overlapping typeclasses in this way, but it would solve the problem of nested `lam`s...
I mainly work on GHC so I have lots of ideas for GHC. Perhaps a library like \`brick\` could host a good project? There must be work to be done on \`stack\` as well? It doesn't really matter as long as the project is of a decent size and used by a decent number of people. 
(FWIW you mean "tenet" rather than "tenant".)
From October: [fused-effects 0.1.0.0: a fast, flexible, fused extensible-effects system](https://www.reddit.com/r/haskell/comments/9s8ce2/ann_fusedeffects_0100_a_fast_flexible_fused/)
Just downvote this person and move along This is /r/Haskell not /r/DebateMisogyny
From the article: "**TL;DR**: [Alex Lang](https://twitter.com/Alang9g) and I recently “finished” a library for dealing with [dynamic graphs](https://github.com/alang9/dynamic-graphs). The library focuses on the dynamic connectivity problem in particular, although it can do some other things as well."
"Like union-find, there is unfortunately no known persistent version of this algorithm. ". I don't think that is true. If I recall correctly Demaine et al. [1] techniques can be used to obtain a functionally persistent graph-connectivity data structure. (I cannot check that since I'm at home and do not have access to the paper here). [1] https://link.springer.com/article/10.1007/s00453-008-9274-z
You're a little late to the party dude xD Also, downvotes don't threaten me. This is a throwaway! ;)
&gt;`putStrLn` is an `IO` Action gottcha!! Not really. It is a function that takes a string and gives you an `IO` action.
I believe `()` is called unit
That doesn't seem right to me at all. Major version bumps are for definitely breaking changes (renaming, removing, retyping). Possibly breaking changes get minor bumps (new name or type that *could* clash depending on how you import things).
Cool, I have never looked at chordify or any of the others.
As I understand it, it's not about ensuring that *you* don't trigger errors from depreciating something, but that rather there are people who *aren't willing to depreciate things* because it can cause breaking on `-Werror`.
The only answer I can think of is "because it's tricky to interpret Prolog in *any* language". I can't think of another language I'd even consider trying it in.
I think you're correct -- I'll update this to say "Like union-find, there is unfortunately no known persistent version of this algorithm." and I'll have a look at the paper you linked.
Why is my comment a waste of time? It’s at least tangentially on-topic.
Those people are crazy and should not be catered to.
Is there any recent Haskell activity in the embedded World? I'd just love to do ESP32 programming in Haskell somehow... I saw some projects, but they weren't recently updated, so I wonder, has anyone done some embedded programming in Haskell using one of the DSL approaches, recently?
Also, there is no debate. This guy us clearly sexist
Hi, sorry I didn't get back to you. Christmas/holidays kind of intervened! Yes, I did mean "continue but do not redraw", which is more eloquent than my description. However, I don't currently have a use case of Brick/Vty, so I'd probably be wasting your time to raise a ticket when I'm not going to be doing a Game TUI for a while (possibly never) ... I wrote Pacman to learn lenses/Haskell in general, and it's still very much not-a-day-job activity! However, for other types of TUIs that I would be interested, the current application model fits very well, so I wouldn't need a "continue, don't redraw" statement. Thanks again for a great library!
It also inherits nix's biggest flaw, which is the difficulty in seeing which packages are installed in a given context. Being able to list and fuzzy search them is a start, but it really isn't going to scale to projects with more than a couple dozen definitions. If definitions could be tagged, and the IDE could create some representation of a filtered list of definitions, that would be way better than a static file tree. That way you could, say, tag a bunch of definitions that you want to refactor, run a filter for #refactor, and then your code explorer would show only those. And if there are more than a dozen matches, group them based on what other tags they have. And of course, the meta-data would also be available, so you could also run a filter for all definitions that have been created in the last week by Alice or Bob. There's also opportunities for the source code to be analyzed to automatically generate tags or tag recommendations, and for scripts to be hooked into them. Integrating with project management software could be as simple as generating tasks from any definitions that use `undefined`. Treating definitions as points rather than elements of a collection (aka a file or module) is definitely a good direction, and the logical conclusion is to have some mechanism for dynamically structuring them. If all you end up with is a flat list, then source navigation hasn't really improved. But if the full potential of this is realized, the results could be pretty awesome.
I think a possibly-breaking change is a breaking change.
Oh ?!? It’s not a function we call an ‘IO’ action, it’s a function that **returns** a value of type ‘IO’ action. Am I saying that right ?
A unit. That sounds way better. Is that specific to an empty tuple, or return type `IO` Action that just happens to be an empty tuple ? 
Good catch. That’s way I prefer the podcast format to written. Truth be told, I struggle with pronunciation too, but am working on it. 
Acording to this wikipedia page: [https://en.wikipedia.org/wiki/Unit\_type#In\_programming\_languages](https://en.wikipedia.org/wiki/Unit_type#In_programming_languages) &amp;#x200B; It can be interpreted as a \`zero-tuple\`, but in the context of haskell I see people calling it unit. &amp;#x200B; Maybe this "post" (it's actually gold :D) can give you a better insight into the unit type: [https://bartoszmilewski.com/2014/11/24/types-and-functions/](https://bartoszmilewski.com/2014/11/24/types-and-functions/) Search for the "Examples of Types"
Okay, thanks - I'm glad you enjoyed it!
Technically it returns a value of type `IO ()`.
runState has type `State s a -&gt; s -&gt; (a, s)` [1]. The value of type `a` is the result of some stateful computation that carries around a state value of type `s`. This for cases where the value of the stateful computation is not necessarily just the state itself. For example, in chess, determining whether or not an inputted move is legal (the result of the computation) given the current position on the chessboard (the state). There is a decent section on the chapter on monads in [Learn You a Haskell](http://learnyouahaskell.com/for-a-few-monads-more). While dated, Real World Haskell also has a [good chapter](http://book.realworldhaskell.org/read/monads.html) that tries to implement its own State monad from scratch.
The Monad represents traditional state machines which transition in state and may have outputs. The traditional example is a vending machine, where “give change” is an emitted effect that accompanies that state changing to “paid”, but isn’t really part of the new state, it’s an output. The other important part is that then it’s “State s a”, so the “a” is the value you interact with monadicly. This can be great for being the “view” of the state machine, but its full internal state is encapsulated.
I've also seen it referred to as "bivariance".
The state isn't always the result you care about. The state is often just being carried along so you can calculate some other value. That's what the `a` is for.
In addition to `Data.Proxy` there’s also `Data.Functor.Const`
[removed]
"Action" designates the value, `IO ()` is the type. - `putStrLn foo` is a value of type `IO ()`. (Sometimes the type argument is irrelevant, so it's also fine to omit it.) - `putStrLn foo` is a value of the type of `IO` actions. - `putStrLn foo` is an `IO` action.
``` flags: "$everything": "-Wwarn=deprecations" ``` 
Is TVar the equivalent of Clojure's atoms in Haskell?
Is is that good?
The PVP already accepts them as not. Introducing new functions and types CAN be a breaking change depending on how someone imports your module, but the PVP specifies that new functions and types justify a minor version bump. This is for default behaviour, where no extensions are
I agree, but that doesn't stop them from existing, or worse, being in charge of things.
I have taught Haskell to 1st year university students and while it great choice because of its mathematical foundations, but it is not a panacea. It is still hard to think correctly and to translate such thinking into code. As I said in my OP, my disapointment is because I was expecting a more technical interview. In particular I would like to know how is Haskell going to be taught, what background the student's have. My experience teaching in Portugal is that students that have a weaker mathematical background tend to struggle a bit with Haskell and FP in general.
Having experienced servant-swagger I can't imagine using any other library, really.
You certainly can use `s -&gt; s` to represent a computation which transforms a state of type `s`. This is even a very mathematically sound representation: you can compose two such functions `f` and `g` into another state transformation function `f . g`, that binary composition function `(.)` is associative, and it has an identity, namely `id`. This is great! You have invented the State Monoid. But note that I said Monoid, not Monad! A monadic computation performs some side-effects (in this case modifying a state of type `s`) and then returns a value of type `a`. The State Monoid is useful when you only need to transform a state of type `s`, whereas thee State Monad is useful when you're doing other stuff too; for example, if you're both using your state to keep track of which nodes in a graph you still have to search, and your return value to indicate whether you've found what you were looking for.
Related links: /u/S11001001's blog post on the same topic, [The missing diamond of Scala variance] (https://failex.blogspot.com/2016/09/the-missing-diamond-of-scala-variance.html), and my [`VFunctor`](https://github.com/gelisam/n-ary-functor/blob/master/src/NAryFunctor/Variance.hs) implementation which generalizes `Functor`, `Contravariant`, `Invariant`, `PhantomVariant`... and much more. For example, `StateT s m a` is invariant in `s` and covariant in `a`... and covariant1 in `m`! -- | -- &gt;&gt;&gt; execState (divideState 2.0) 6.0 -- 3.0 divideState :: Double -&gt; StateT Double Identity () divideState x = do modify (/ x) -- | -- &gt;&gt;&gt; execStateT (divideState' 2) 6 -- Just 3 divideState' :: Int -&gt; StateT Int Maybe () divideState' x = do guard (x /= 0) vmap &lt;#&gt;/&gt;#&lt; (round, fromIntegral) &lt;##&gt; NF (Just . runIdentity) &lt;#&gt; id $ divideState (fromIntegral x) 
Awesome. Thank you for the resources. 
That makes sense. And the value is an empty tuple referee to as a unit! This is great. 
I like the use of ‘designates’ to describe the purpose of “Action”. It helps to clarify its purpose and what it is meant to communicate about what is happening in the program. 
I don't know clojure, but a quick search suggests that they're vaguely equivalent. Other similar Haskell types are `MVar` and `IORef`.
While others already got you some great explanations, I will drop another example. &amp;#x200B; Imagine you have a Stack and want to pop an element. with `s -&gt; s` you would only get the resulting stack but not the element, thus we it is nice to have s `-&gt; (a, s)` because now we can get the value and the resulting stack.
have you considered running n-databases so you can run n-tests in parallel?
Agreed with you in terms of the contents of the article. IOHK will make the material used in this course available online in the coming months so we can see the methodology 
Usage example: runningAverage :: [Double] -&gt; State Double [Double] runningAverage = traverse step where step a = do curTotal &lt;- get put (curTotal + a) return (a / curTotal) If runState was `s -&gt; (a, s)` we couldn't get the running averages. 
if you model State as\` s -&gt; s\`, then it wouldn't be very useful because all it can do is to take a current state and return a updated state. However, if you model it as \`s -&gt; (a, s)\`, then, you can process the effect (the update of the state) and the value at the same time, think of \`(a -&gt; m b)\`. Then you can make \`State\` a member of Functor, Applicative etc, to have those generic operations defined for those classes available to \`State\`.
good job!
MVar and IORef are not thread-safe aren't they..?
`Atom` works fine, but is a little barebones - all setup and hardware specific stuff would be in C or C++ (Atom compiles into C99, so there might be some issues). `copilot` needs quite some manual dependency management and IIRC some fixes to work on a recent GHC + Stack, but is doable. Compiles to C99 through Atom, so shares the same issues. `ivory` should also be OK, though that's essentially C with metaprogramming in Haskell.
In the biplate parts, he uses type signatures. Is it possible to use type applications now?
An MVar can be empty or full; this allows it to act as a lock, and several concurrent data structures cab be implemented using MVar. IORef is thread-safe if you use the `atomic*` operations.
Fantastic idea! That's a niche that is completely unaddressed as far as I am aware.
I go to these all the time, and they are great.
TVar is special in that it's atomic across large transactions. You can read and write several TVars in a row, and STM will roll your entire sequence back and try again if any thread would ever make itself apparent to you by modifying the same TVars in parallel. This is in contrast to MVar, which is only atomic in individual writes. It is thread safe, and in fact it makes both a useful concurrent mutable ref and lock. But only for one write at a time. IORef is not thread safe by default, but it does have `atomic*` variants of its functions to make it thread safe
 Neat! Those are some truly horrifying operator names though. Not sure if I'm more appalled by `(&lt;##&gt;/&gt;##&lt;)` or `(👻#👻)`.. 😁
How often *do* people end up using the state [`execState`](https://hackage.haskell.org/package/mtl-2.2.2/docs/Control-Monad-State-Lazy.html#v:execState) versus the return value [`evalState`](https://hackage.haskell.org/package/mtl-2.2.2/docs/Control-Monad-State-Lazy.html#v:evalState) execState :: State s a -&gt; (s -&gt; s) evalState :: State s a -&gt; (s -&gt; a)
It was useful to me when I needed to calculate best fit lines and such.
How would you name them? I like the names: `(&lt;#&gt;)` is covariant, like `(&lt;$&gt;)`, `(&gt;#&lt;)` is contravariant, like [`(&gt;$&lt;)`](http://hackage.haskell.org/package/contravariant-1.5/docs/Data-Functor-Contravariant.html#v:-62--36--60-), and `(&lt;#&gt;/&gt;#&lt;)` is a combination of `(&lt;#&gt;)` and `(&gt;#&lt;)`, because invariant requires both argument you'd give to `(&lt;#&gt;)` and the argument you'd give to `(&gt;#&lt;)`. Then for covariant1, contravariant1, etc., I use `(&lt;##&gt;)`, `(&gt;##&lt;)`, etc. I wish I could add a `1` to the end but that's not allowed in infix names. Finally, for phantom variance, [I used to have `(!#!)`](https://github.com/gelisam/n-ary-functor/commit/2bfd64ed4a7403e3cf33d1aa99c31c66fa519d59) but I renamed it to `(👻#👻)` in honour of /u/S11001001's post.
In package sop-core there is the [following signature](http://hackage.haskell.org/package/sop-core-0.4.0.0/docs/Data-SOP.html#v:cpara_SList): &gt; cpara_SList :: All c xs =&gt; proxy c -&gt; r '[] -&gt; (forall y ys. (c y, All c ys) =&gt; r ys -&gt; r (y ': ys)) -&gt; r xs The question I have is with the function argument. How can I refer to the type variable `y` from inside the body of a lambda? For example to use the type with `-XTypeApplications`. Right now I have to define a separate helper function with the same signature and pass it as an argument, which is verbose. Is there a way of doing it "inline"?
In the context of a webapp, why would TVar be preferred over IORef or MVar to implement a global state? Here's a global state example from scotty repository https://github.com/scotty-web/scotty/blob/master/examples/globalstate.hs 
a good html parser.
So... HoTT instead? That just results in ¬¬(P ∨ ¬P)
Perhaps worth mentioning that `pmap` has a [sensible default implementation](http://hackage.haskell.org/package/contravariant-1.5/docs/src/Data.Functor.Contravariant.html#phantom).
The author works on Cedille, which is based on extensional type theory.
Who *is* the author? The "about" page, etc. weren't very informative?
It links to his (Aaron Stump's) webpage, which has a CV with a list of publications. What kind of information are you looking for? 
Oh! Missed the link somehow. My apologies. (EDIT: Not that it should matter who wrote something, but one has to decide what to pay attention to *somehow*.)
so i'm trying to solve this little task of replacing all instances of substring "WUB" with a space in a string, and obviously there's libraries and functions for stuff like that but I wanted to do it on my own here's how I approached it ``` dewub ('W' : 'U' : 'B' : rem) = ' ' : dewub rem dewub "" = "" dewub (a : other) = a : dewub other ``` and it _kinda_ works, except it replaces the WUBs with three spaces rather than one and I don't have a clue why. could anybody explain this to me? I asked on the haskell irc but nobody seemed to look at the snippet and just wrote to do what I already did.
This could just be me, but the only thing this seems to bring into question is the ability to judge whether something is justifiable or falsifiable. With the caveat that I approach this as a complete amateur, the computational interpretation of what is classically considered true or false sort of transforms itself into the consideration of "multiple worlds".
Just depends on what you want from it. If you need locking behavior, MVar is good. If you need large logical transactions, TVar is good. If you don't care about any of that and want performance and don't like MVar's nullability, IORef is good.
Huh, I've only ever seen folks talking about Curry-Howard in the context of constructive or intuitionistic logic. Possibly for this reason?
&gt; Edit2: Incidentlly, use of classical logic in computation resolves what has always been a pet peeve of mine in standard type theory where disjunction is always exclusive rather than possibly inclusive. Is that true? In (what I would consider) standard type theory, you can have a proof of both sides of a disjunction and only give one of them to provide a witness of the disjunction. Even though the disjunction is "exclusive," it can be possible for both sides to be provable. I feel like that could be reasonably described as "possibly inclusive." Maybe I am misunderstanding what you're saying?
It does work as you expected. $ ghci GHCi, version 8.6.3: http://www.haskell.org/ghc/ :? for help Prelude&gt; :{ Prelude| dewub ('W' : 'U' : 'B' : rem) = ' ' : dewub rem Prelude| dewub "" = "" Prelude| dewub (a : other) = a : dewub other Prelude| :} Prelude&gt; :t dewub dewub :: [Char] -&gt; [Char] Prelude&gt; length $ dewub "WUBWUB" 2 It is possible that you are running a code other than you wrote here. Did you try `cabal clean`, `stack clean`, or deleting build artifacts manually?
Case analysis without continuations always discriminates on whether to compute on the left or right side of a disjunction, with no way to make use of the case where both cases are true. In the presence of a continuation acccepting the side which was not pattern matched (using a language like Wadler's dual calculus) allows you to consider either case in your proof.
You have turned on `ScopedTypeVariables` (GHC Extension), right?
That's interesting. I did this stuff on codewars kata so I don't really have control over the environment. It ran ghc 7.10 or something though.
Intuitionistic disjunction is not exclusive. In an exclusive disjunction, to prove a disjunct you must also prove the other disjunct false. 
The issue with classical logic is not about the existence of a computational interpretation, but about the lack of good properties for various interpretations (lack of confluence, lack of normal forms, etc)
I think the usual focus on the "disjunction property" failing in classical logic is misguided. And the invocation of " Curry-Howard doesn't provide any sort of argument why we should believe the disjunction property should be satisfied by a good theory. 
Yeah, I made too strong a statement. I intended to say that there is no way to make use of an disjunction wherein there is evidence for both cases in intuitionisitic type theory without introducing an additional case specifically handling that.
The interpretation of Not A in intuitionistic logic leaves a lot to be desired too. Something is missing. Absurdity should have nontrivial computational content.
Why? Isn't the whole point of absurdity that it's unreachable by computation?
What class does this function belong to? `Applicative m =&gt; f a -&gt; (a -&gt; m (f b)) -&gt; m (f b)` You can implement monad bind with it where `m` is `Identity`. I put this in my own typeclass to write effectful Bound substitutions.
The general pattern here would be to introduce a way to downgrade something back to a warning when `-werror` was enabled. Something like `-wno-error-___`, i.e. `-wno-error-deprecated`
Indeed. The whole point of intuitionistic logic is that ¬P isn't the "opposite" of P. Perhaps to give u/madelinja some more credit, it *would* be nice to have a satisfying, *intuitive* (perhaps geometric?) explanation for the relationship between P and ¬P in the case of a "generic" type P.
I mean, I see *why* you named them the way you did. I'm just not a fan of long operator names in general. Personally I'd probably have reached for *more* unicode. Which, admittedly, would probably get on even more people's nerves. I don't know. I just find 4+ ascii character operators hard on the eyes. This is one area where I feel like we should just copy what's happened in Agda land. Both the input method stuff, and the allowing the programmer to specify where the arguments are supposed to go. That would let us put subscript numbers on operators too, if I'm not mistaken. 
 {-# LANGUAGE ScopedTypeVariables, PartialTypeSignatures #-} cpara_SList u v (w @y @ys :: forall y ys. _) It assumes that the type of the body under the `forall` can be inferred so the compiler knows what `y` and `ys` correspond to. Otherwise you'll have to at least expand to w :: forall y ys. _ -&gt; _ (y ': ys) and of course the relative benefits over a whole declaration are getting much smaller.
How would you write a conditional type family? This page https://haskell-lang.org/library/vector says &gt; If you don't need to pass values to a C FFI, and you have a Prim instance, use unboxed vectors. &gt; If you have a Storable instance, use a storable vector. &gt; Otherwise, use a boxed vector. So I want to write something like - type family VecType a :: Type -&gt; Type type family VecType a = if Prim a then Unboxed.Vector else if Storable a then Storable.Vector else Boxed.Vector
Yes. A simplified example: {-# LANGUAGE RankNTypes, ScopedTypeVariables #-} import Data.Proxy foo :: forall c. (forall a b. b -&gt; b) -&gt; c -&gt; c foo f = f -- with an explicit signature I can refer to the "a" bar :: forall a b. b -&gt; b bar = let a = Proxy :: Proxy a in id 
Cool, thanks!
Is that operation different from this? trabind :: (Traversable f, Monad f, Applicative m) =&gt; f a -&gt; (a -&gt; m (f b)) -&gt; m (f b) trabind fa k = join &lt;$&gt; traverse k fa -- Note that (traverse k fa :: m (f (f b))) 
Am I missing something? Why can't use case-split? Here's an example on cubicaltt: module curryhoward where -- https://queuea9.wordpress.com/2018/10/17/why-i-no-longer-believe-in-computational-classical-type-theory/ -- couldn't find how to define a datatype without constructors in -- cubicaltt, imagine it doesn't exist please :) data Absurd = Absurd data Either (A : U) (B : U) = Left (a : A) | Right (b : B) lem (A : U) : U = Either A (A -&gt; Absurd) data bool = true | false usefulFunc (A : U) : (l : lem A) -&gt; bool = split Left a -&gt; true Right aToAbsurd -&gt; false
Can you give an example of the kind of situation where you’d want to make use of “evidence for both cases”?
I was confused about the same thing when I first learnt State monad as well, but to put it simply State monad isn't actually for a long-lived shared state but rather a temporary one used for stateful computation. Think about it as `index` in for loops rather than a global state that you pass around to different processes
&gt; David Hilbert’s position that non-constructive reasoning is an essential tool for mathematics Where can I read more about this?
This might be relevant: https://golem.ph.utexas.edu/category/2018/05/linear_logic_for_constructive.html
In computations following classical logic, you can't use evidence for *either* case of a disjunction, with no way out to gain the intuitionistic information back, much less considering the case where evidence for both is present. That's the whole point of article in the OP...
There's a quote of Hilbert's, "No one shall expel us from the [Paradise](https://en.wikiquote.org/wiki/Paradise) that Cantor has created." Given he'd spent a significant amount of his time working on things that are meaningless/nonsense without non-constructive reasoning, it's not surprising he felt that way. 
I think you're right! :) Let me try it out.
The point is not that you can't case split at all, but it's more about what does case-splitting actually give you, on a whole-program/logical scale? The computational interpretation of `lem A : Either A (Not A)` using control operators *always* returns a convenient lie, it gives you a `Not A` which, when you construct an `A` and try to show absurdity with it, goes back in time (actually, calls the continuation it captured just before giving back control to you, no time travel needed) and gives you back your own constructed `A`. You can lie back at it, too, and simply show `Not (Not A)`, then you use the faux `Not A` to show absurdity and force it to give you back an `A` it doesn't actually have, and neither do you. At that point, you can *never* be sure if the `x : A` you have is real or a fiction, at *any* point in the program, it can be a chain of convenient, internally consistent lies that will repeat the whole program when its weakest, front-showing link is proven wrong. That's why the programming language community moved on from unrestricted call/cc, which requires whole-program unrestricted backtracking making reasoning about programs hard, onto delimited continuations that correspond about to Markov's principle. Therefore, when you case-split a classical disjunct `A + B`, you learn nothing about `A` or `B`, you could be living in a fictional world created by `lem` when called out on the impossibility of `Not A`. You can't "take action" as the OP says, because if any of your assumptions is ever proven wrong, all your work will have gone to nothing, as if it never happened, so it had to be revisable/revertable in the first place. No irrevertible effects like IO.
((((((((
It was more of a controversy on the somewhat radical idea of removing the Law(axiom?) of Excluded Middle in classical logic. IMHO, the debate has been plagued by the ego of hilbert&amp;brouwer though. [https://en.wikipedia.org/wiki/Brouwer%E2%80%93Hilbert\_controversy](https://en.wikipedia.org/wiki/Brouwer%E2%80%93Hilbert_controversy) Stephen Kleene's *Introduction to Metamathematics* mentioned in the article seems like a good "summary".
**Brouwer–Hilbert controversy** In a foundational controversy in twentieth-century mathematics, L. E. J. Brouwer, a supporter of intuitionism, opposed David Hilbert, the founder of formalism. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/haskell/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
Someone has to say it: Haskell already is the perfect mix of Haskell and Clojure &amp;#x200B; Also note that Lux uses a [weird license](https://github.com/LuxLang/lux#whats-the-license).
Look into linear logic, which has an involutive negation (not not A = A) but is completely constructive. The odd state of "not" in intuitionistic logic results from a kind of polarization, of favoring proofs over refutations. 