+1. Make sure you charge for it, that way we know it will happen :)
Sure there's such a thing as too short but java's not the right language to inherit naming conventions from imo. It's like java devs get bonuses for coming up with the longest names possible.
Absolutely! Do you have a list of things you'll cover?
I did some brief handwaving to myself that the things I've done here are not egregious, but I've certainly been wrong in my `unsafePerformIO` reasoning before. My understanding is that we usually want to `NOINLINE` `unsafePerformIO`s because if they were inlined their side effects would be duplicated at every call site. In my case I'm using it in order to catch (unconditionally thrown) exceptions. As far as I can tell, this approach is referentially transparent---at least in the absence of async exceptions---but I am more than willing to claim ignorance in this domain.
The rough TOC currently looks like this: \chapter{Maintaining Invariants} \section{Phantom types + roles} \section{Add a type variable} \section{Data Kinds} \section{Indexed Monads} \section{Rank-N Types} \section{Reifying Dicts} \chapter{Boilerplate Reduction} \section{Trees that Grow} % ecstasy \section{HKD} \section{GHC.Generics} \section{DTALC} \chapter{Code Generation} % servant \section{Proxy Objects} \section{Variadic functions / parsing + generating} \chapter{Modeling domains} % opaleye-sot \section{Free Objects} \section{Static Analysis} \section{Type Families} \chapter{Modeling domains 2} % grpc \section{GADTs + type indexing} \section{Symbols and labels} \section{Constraints} \section{Type Errors} \part{Tactics} \chapter{Tricks} \section{ST Trick} \section{Constraint Trick} \section{Injectivity} \section{Functional Dependencies} \section{Freer} \section{Polykinds / Datakinds} \section{Type Applications} The part/chapter organization isn't likely to survive, but I do plan to hit all of these topics --- ideally each in the context of a motivated project. 
There is a universal law of naming things: Name length should be roughly proportional to the scope of the name. (Note: I'm intentionally being a little inexact here. If you're going to get mathematical, than I'd say that by scope I mean some log of the size of the universe of values.) This law is not just limited to computer programming, but is applicable everywhere. Take phone numbers, for example. They're really a name for a particular phone. As the scope gets larger, the length increases. If you want to make a local call (in the US), you dial a 7-digit number. If you want to make a long distance call, you add a 3-digit area code. And if you want to make an international call, you add another prefix which is the country code. This law applies to Java as well as Haskell. Now with respect to naming, there's one big thing about Haskell that is very different than Java. In Java, the names of class member variables are scoped to the class. You say `person.name`. Haskell data types are different: ``` data Person = Person { personName :: String } ``` When you define this data structure, Haskell creates the following functions: ``` Person :: String -&gt; Person personName :: Person -&gt; String ``` And here's the big difference...**these functions have global scope**. It therefore follows that those names need to be more complex. This is why I generally prefix field accessors with the name of the data type. Now, you wrote this function: ``` drinkFromCup typeOfCup amountToDrinkInOunces = (fluidOunces - amountToDrinkInOunces) where fluidOunces = getFluidOuncesFrom typeOfCup ``` In this function, the following names have local scope: typeOfCup, amountToDrinkInOunces, fluidOunces. They only exist here in the two lines of the body of this function. So I would argue long names are not needed for these things. If I had written that code, I might have used these names: ``` drinkFromCup ty amt = getFluidOuncesFrom ty - amt ``` I think this is much easier to read. Furthermore, Haskell's type system gives us another way to know lots about our names. You are putting the units in the name. That's not necessarily a bad thing. But you could also put the units in the type! There are a few packages ([units](http://hackage.haskell.org/package/units) and [dimensional](http://hackage.haskell.org/package/dimensional) are two come to mind) that define tools for making this easier. If you used an approach like this, then you could leave units out of your names completely. If you don't use something like this, then I think it can make sense to use units in your names.
stylish-haskell only really formats data type declarations and imports. Brittany is my favorite tool by far. Only thing it's missing for me is formatting type class instances, for some reason. Other than that, its layout rules are excellent. It's designed to try and respect your intention w.r.t. blank lines, comments, parens, etc.. It generally just does what I would almost always do myself, whereas I feel like hindent almost always finds a way to disagree with me. Part of this is that brittany is far more configurable than hindent, but I only tweak a couple of settings from the default. I know some people prefer less configurability to enforce One True Way on people, but I always felt one of the purposes of a formatter was that there didn't have to be one true way, because the tool will just make everything consistent within the project anyway.
Good idea. I wonder if it'd be better to wait until DependentHaskell has arrived?
[Any `Applicative` can be reversed](https://hackage.haskell.org/package/transformers-0.5.5.0/docs/Control-Applicative-Backwards.html): applicative composition with `(&lt;*&gt;)` is juxtaposition of computations, and `Backwards` juxtaposes them the other way around. The `Monad` instance makes reverse state interesting because `Backwards` doesn't have one (it can't) but a traversal does not really exercise that extra power. Using `Backwards`, it is also possible to define a ["traversable transformer"](https://hackage.haskell.org/package/transformers-0.5.5.0/docs/Data-Functor-Reverse.html) whose `Traversable` instance traverses the underlying structure "right-to-left".
I'm used to hindent, but could you explain why brittany could be a better choice?
Yes, definitely! 
Already learned something new from your book - how to use GHC.Generics! &gt; get feedback on its style I'd suggest to try to condense the sentences - my impression is that roughly 50% of page text is flowery language without useful content. Also, the pompousness could use a reduction too, especially in the chapter on JSON schema - you may, in theory, get skeptical readers who aren't themselves experienced Haskellers - they may get triggered by excess pompousness.
I‚Äôve been using hindent for a long time, but I‚Äôve been growing more and more disappointed about it. Yesterday I gave brittany a serious try and was impressed at how much faster it is and found it refreshing that it preserved my new lines and the comments in their right place. I even found settings that made it look the same to the hindent output I was already used to work with. My only gripe so far is that it makes a bad job at pretty printing imports.
&gt; GADTs and other ‚Äútricky‚Äù data constructors fail to promote My understanding was that in recent GHCs, GADTs do promote. &gt; Boilerplate polymorphism doesn‚Äôt have any formal definition I have sometimes seen generics referred to as "structural polymorphism".
&gt; Use Docker to fit multiple services on the same VPS. (If you do not need this, try NixOS.) I don't understand this. You can definitely have as many services as you want in one NixOS system. In fact, I generally strongly prefer deploying NixOS configs rather than docker images when not using something requires docker.
I guess I just don't have enough experience with NixOS. Transitioning from multiple dockerised services to building one of those docker containers with Nix is a lot easier than transitioning everything to NixOS at once. I also don't know if you can protect the other services on NixOS in case one of them has a vulnerability. 
Definitely interested! Any rough timeline in mind?
&gt; Transitioning from multiple dockerised services to building one of those docker containers with Nix is a lot easier than transitioning everything to NixOS at once. That's true. Certainly if you already have a bunch of docker stuff, it's a lot more effort to try and migrate it. &gt; I also don't know if you can protect the other services on NixOS in case one of them has a vulnerability. NixOS supports containerized services pretty easily without losing any of the benefits of NixOS.
that's at two-three years out, why wait?
Well any book such as this is likely to take at least a year to develop. And it's always unfortunate to see good learning material made dramatically out of date after only a year or two, which DependentHaskell is sure to do to any book about type level Haskell. I'm not saying for sure that waiting is the right call, but it's at least worth considering.
Super helpful, cheers. This is exactly the kind of stuff I need to hear sooner than later :)
This is really cool! It certainly fills a need in the pedagogical Haskell landscape. I would definitely be interested in reading the complete book. One thing I would ask: can you please remember to include full code examples with the language pragmas? For instance, on lines 330-340, I was trying out your `printf` type family stuff and I had to enable a lot of extensions: *Main Hakyll Œª&gt; :set -XDataKinds *Main Hakyll Œª&gt; :set -XTypeFamilies *Main Hakyll Œª&gt; :set -XTypeOperators *Main Hakyll Œª&gt; data (a :: k1) :&lt;&lt; (b :: k2) &lt;interactive&gt;:4:1: error: Unexpected kind variable ‚Äòk1‚Äô Perhaps you intended to use PolyKinds In the data type declaration for ‚Äò:&lt;&lt;‚Äô &lt;interactive&gt;:4:1: error: Unexpected kind variable ‚Äòk2‚Äô Perhaps you intended to use PolyKinds In the data type declaration for ‚Äò:&lt;&lt;‚Äô *Main Hakyll Œª&gt; :set -XPolyKinds *Main Hakyll Œª&gt; data (a :: k1) :&lt;&lt; (b :: k2) *Main Hakyll Œª&gt; :kind! (:&lt;&lt;) (:&lt;&lt;) :: k1 -&gt; k2 -&gt; * = (:&lt;&lt;) *Main Hakyll I find that blog posts and sample code often elide the extensions they're using. Unfortunately, this may make your work more firmly entrenched in a particular version of GHC: I have no idea how to remedy that.
I wasn't commenting on whether it would work via the AUR package - and I'm very glad to hear that the situation is so good. I was saying that perhaps - for some people - dev tool chains are a different use case than usual software installations. So even for a perfectly working package in a package system that does the job it's designed for perfectly, it could still be that the optimal workflow is the tool chain's native installation and not package manager installation.
At the very least, the explanation of the kind system will still be useful once DependentHaskell arrives. And I presume Generics will still be around, along with some uses of type families.
Good advice. One concern I have is that it's hard to work through things incrementally if they always must be complete code samples. Maybe a link to a fully-realized version of the completed code at the beginning of each chapter would be a reasonable compromise?
Also, later on, I got a complaint from GHC that I needed `FlexibleInstances` (and I used `*` instead of `Type`): *Main Hakyll GHC.TypeLits Œª&gt; :{ *Main Hakyll GHC.TypeLits| instance HasPrintf (sym :: Symbol) where *Main Hakyll GHC.TypeLits| type Printf sym = String *Main Hakyll GHC.TypeLits| :} &lt;interactive&gt;:30:10: error: ‚Ä¢ Illegal instance declaration for ‚ÄòHasPrintf sym‚Äô (All instance types must be of the form (T a1 ... an) where a1 ... an are *distinct type variables*, and each type variable appears at most once in the instance head. Use FlexibleInstances if you want to disable this.) ‚Ä¢ In the instance declaration for ‚ÄòHasPrintf (sym :: Symbol)‚Äô
Also, for lines 435 to 451, I had to do the following: Œª&gt; :set -XTypeApplications -- this one you mentioned Œª&gt; import Data.Proxy *Main Hakyll GHC.TypeLits Data.Proxy Œª&gt; :set -XScopedTypeVariables Œª&gt; import Data.Monoid ((&lt;&gt;)) After that, I got the following example to compile in GHC: Œª&gt; :{ *Main Hakyll GHC.TypeLits Data.Proxy Data.Monoid| instance KnownSymbol text =&gt; HasPrintf (text :: Symbol) where *Main Hakyll GHC.TypeLits Data.Proxy Data.Monoid| type Printf text = String *Main Hakyll GHC.TypeLits Data.Proxy Data.Monoid| format s _ = s &lt;&gt; symbolVal (Proxy @text) *Main Hakyll GHC.TypeLits Data.Proxy Data.Monoid| :} *Main Hakyll GHC.TypeLits Data.Proxy Data.Monoid 
Yes, I think so. I don't think *each* example must be complete. All pragmas and imports, though, should probably stated at least once at the beginning of a running section of code? I don't think they need to be restated each time.
What about this one? Do you really need `UndecidableInstances`? Œª&gt; :{ *Main GHC.TypeLits Data.Proxy Data.Monoid| instance (HasPrintf a, Show p) =&gt; HasPrintf ((param :: *) :&lt;&lt; a) where *Main GHC.TypeLits Data.Proxy Data.Monoid| type Printf (param :&lt;&lt; a) = param -&gt; Printf a *Main GHC.TypeLits Data.Proxy Data.Monoid| format s _ p = format (s &lt;&gt; show p) (Proxy @a) *Main GHC.TypeLits Data.Proxy Data.Monoid| :} &lt;interactive&gt;:92:10: error: ‚Ä¢ Variable ‚Äòp‚Äô occurs more often in the constraint ‚ÄòShow p‚Äô than in the instance head (Use UndecidableInstances to permit this) ‚Ä¢ In the instance declaration for ‚ÄòHasPrintf ((param :: ghc-prim-0.5.1.1:GHC.Types.*) :&lt;&lt; a)‚Äô
This looks great. As far as style goes, a lot of the inline code snippets are broken up by line breaks. This can make them hard to read (e.g. `Maybe \\ Maybe` at line 125-126 or `Type -&gt; Type -&gt; \\ Type` at 135-136). It would be nice if this could be prevented in the full book.
They have different philosophies. Hindent formats code in a more regular manner, while Brittany tries to maximise the use of horizontal space. For example, hindent always puts a \`where/then/else/etc\` on a new line while Brittany generally doesn't if the whole expression fits within one line.
&gt; My understanding was that in recent GHCs, GADTs do promote. Except when they don't contain typeclass dictionaries. Or I think (someone tell me if I am incorrect) more precisely it is all GADTS get promoted but there are no typeclass dictionaries at the type level so GADT constructors that contain dictionaries cannot be constructed.
Try instance (HasPrintf a, Show param) =&gt; HasPrintf ((param :: *) :&lt;&lt; a) where You mistyped param as p. This is why AllowAmbiguousTypes is not on by default!
Footnote 4 that is referred to from line 160 gives the wrong type to `MonadTrans`. Should it not be `((Type -&gt; Type) -&gt; Type -&gt; Type) -&gt; Constraint`?
I occasionally try to get into type level haskell, hack on some problem until it works awkwardly and am never sure whether the weirdness is my fault or a limitation of current haskell. Like, today I tried to [implement SYB via GHC.Generics](https://gist.github.com/Tarmean/b5a743da6f398130da5390f89686a8d7). The generic implementation dispatches on the result of a type family so all the deriving instances have an awkward `type BiplateSuper b a = DispatchOracle b a (GetOracle '[] b a) ` superclass which breaks DeriveAnyClass. However DispatchOracle is total so it feels like it shouldn't need a constraint. DependentHaskell probably could do it as a normal function? But I have no idea if there is some workaround for now and am unsure how to find out. TL;DR: Very interested in the book. Worried how much relevance it could lose after dependent haskell lands, though.
 data Australian = Nah | Yeah deriving (Eq, Show, Ord, Read, Enum, Bounded) instance Semigroup Australian where _ &lt;&gt; m = m instance RegularSemigroup Australian where isPseudoInverseOf _ _ = True isInverseOf Yeah Nah = True isInverseOf Nah Yeah = True isINverseOf _ _ = False 
Yes you are absolutely right that this basically only exercises the power of Applicative. But I want to describe it as a monad because I think in the future we *are* going to need this extra power. But thanks for your link to `Backwards`; I didn't know this existed in transformers!
Sometimes, like in this case, people are referring to static analysis of an EDSL. So it's at runtime for Haskell, but it's before the DSL runs. Sometimes, they're talking about things like LiquidHaskell, though.
brittany is more powerful and configurable because there's no agreed upon Haskell style. I mean, unlike Lisp, Haskell is very hard to parse and it's also leading whitespace "sensitive". Meaning, it's very hard to write a Haskell formatter. Lennart has been highly responsive and is, from what I can tell, always looking for bug reporters, testers, and contributors. Since brittany has been integrated into haskell-ide-engine, I'd say let's make it the best formatter and check off that missing tool from the list of gaps compared to more popular language ecosystems. I mean, you can write very pleasant looking Haskell code, but it comes at the price of a complex parser and therefore a lot of work for a formatter.
&gt; stylish-haskell only really formats data type declarations and imports That's interesting, I could swear that current stylish-haskell does more than that based on my last try, but I have to test again.
I'm enjoying this greatly. One style question - why do you say "TYPE" for the kind we all know as "*"? Is it really likely that people will come to this without a Haskell background, or without being on their way to writing Haskell code?
Thank you, I'll give it a try in my Emacs setup for Haskell and see which one suits me better.
Thanks! As far as I understand, `*` is on its way out. There's a new language extension called `StarIsType` that is planned to be set to `NoStarIsType` by default in a few releases.
Guess I'd better write really fast then :)
Good catch, thanks.
Is there a guide or gallery or anything at all for brittany configuration? I don't like the defaults but I'd be curious to see if I can twiddle its knobs into giving me something I can live with.
&gt; I generally strongly prefer deploying NixOS configs rather than docker images when not using something requires docker. What are some of the things you came across that require Docker?
It should auto generate a config file in your home directory somewhere with all the options
I be written a small library that uses a similar implementation to what you described: https://hackage.haskell.org/package/IntGraph The graph is represented by mapping Ints to sets of Ints. 
Why there's no \`cataM\` and other monadic versions of functions in recursion-schemes? (I know about recusion-schemes-extra)
Here's two funny bits from the stream: - Clip shown at [00:32:27](https://www.twitch.tv/videos/282254911?t=00h32m27s) is also available at https://www.facebook.com/ComedyCentralANZ/videos/1772016499676959/ - Clip shown at [2:30:57](https://www.twitch.tv/videos/282254911?t=02h30m57s) is also available [here](https://i.redd.it/exmobtj3hb811.gif)
Here's the archival video from my stream today: Regular and Inverse Semigroups: https://www.twitch.tv/videos/282326274 Q&amp;A at the end: https://www.twitch.tv/videos/282330151
Haskell noob question: How do you get away with what appear to be partial definitions of the instance methods?
What are you referring to? The `deriving` portion, the `_` thing or something else?
I did some quick research on this last week and came to the conclusion that Brittany is the state-of-the-art: * It [uses](https://www.reddit.com/r/haskell/comments/514h8s/ann_alphaexperimental_release_of_brittany_haskell/d797410/) [ghc-exactprint](https://github.com/alanz/ghc-exactprint) which (in my limited understanding) will parse your code according to the version of GHC you're compiling with, so it won't break when you start using a new feature. * It has been selected as the formatter for [haskell-ide-engine](https://github.com/haskell/haskell-ide-engine), which is a pretty big vote of confidence. * It does better than hindent on some [corner cases](https://github.com/lspitzner/brittany/blob/master/doc/showcases/BrittanyComparison.md).
``` isInverseOf Yeah Nah = True isInverseOf Nah Yeah = True ``` This definition covers only two of the four possible input combinations, but I see now that "isINverseOf" is just a misspelling of "isInverseOf". When I was watching the stream earlier (and first had the question but didn't ask it), the everything-else definitions hadn't yet been written, and I thought that was repeated here.
I'd recommend looking into https://github.com/well-typed/pretty-sop
Sandy, thank you very much, keep up the good work!
 1. What does this mean? More specifically, what function is being returned in the sequence of arguments (the one that takes integers y and z)? I understand that each argument of the function \*mult\* is being worked with independently, or one at a time. 1. But what function is being returned that is working with the remaining arguments 'y' and 'z' ("takes an integer x and returns a function")? 2. Are arguments 'y' and 'z' stored while the function works with x? 3. Please explain, show, etc the process which takes place as well.
[https://imgur.com/a/mYazo41](https://imgur.com/a/mYazo41) TEXT EXPLAINING IMAGE: "This definition states that mult takes an integer x and returns a function, which in turn takes an integer y and returns another function, which finally takes an integer z and returns the result x \* y \* z." 1. What does this mean? More specifically, what function is being returned in the sequence of arguments (the one that takes integers y and z)? I understand that each argument of the function \*mult\* is being worked with independently, or one at a time. 1. But what function is being returned that is working with the remaining arguments 'y' and 'z' ("takes an integer x and returns a function")? 2. Are arguments 'y' and 'z' stored while the function works with x? 3. Please explain, show, etc the process which takes place as well.
^(Hi, I'm a bot for linking direct images of albums with only 1 image) **https://i.imgur.com/xFfBj2h.png** ^^[Source](https://github.com/AUTplayed/imguralbumbot) ^^| ^^[Why?](https://github.com/AUTplayed/imguralbumbot/blob/master/README.md) ^^| ^^[Creator](https://np.reddit.com/user/AUTplayed/) ^^| ^^[ignoreme](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=ignoreme&amp;message=ignoreme) ^^| ^^[deletthis](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=delet%20this&amp;message=delet%20this%20e20wss3) 
Need some advice regarding unit testing an HTTP wrapper library for some complicated (many methods, fancy authorisation logic) REST API. Here is one of the functions: createX :: (MonadThrow m, MonadTime m, MonadHttp m) =&gt; Connection -&gt; DbName -&gt; CollName -&gt; Value -&gt; m Value createDocument ... = send c $ Options { _resource = Docs dbName collName , _headers = M.fromList [("Content-Type", ["application/json"])] , _requestType = POST (BSL.toStrict $ encode value) } And there are different ones looks almost exactly like this one, and all of them are using this helper: send :: (MonadThrow m, MonadTime m, MonadHttp m) =&gt; Connection -&gt; Options -&gt; m Value send ... = do -- get current time -- fill Auth header -- fill some other headers -- serialize body -- prepare the URI r &lt;- case requestType of POST body -&gt; post opts (_session c) uri body PUT body -&gt; put opts (_session c) uri body GET -&gt; get opts (_session c) uri case decode (r ^. W.responseBody) of Nothing -&gt; throw DeserializationException Just vs -&gt; pure vs There are number of assertions that need to be made for `createX`, like: - http request's uri is valid - http request's method is GET - Auth header built appropriately - Some other headers built appropriately - Body is serialized properly The only place where these assertions could be put in is custom implementation of `MonadHttp`. And there should be correspondent check for every function, should they be placed altogether in this implementation? Also it should have implementations for both Monad and Functor. All of that looks kinda awkward. Is it some kind of a bad types decoupling, or what am I doing wrong?
Could you explain that first example (`fst ("no problems", True &lt;&gt; 17)`) in more detail please? I looked up `(&lt;&gt;)` on Hoogle and the only result is some `Doc` type I've never heard of - seems like this example could be made more accessible?
This book might be too difficult for you if you don't know `(&lt;&gt;)`. Actually `(&lt;&gt;)` is pretty common. It's even in Prelude: https://hackage.haskell.org/package/base-4.11.1.0/docs/Prelude.html#v:-60--62-
Looking good! There's a typo on line 561. Should be F2 b1 c1 == F2 b2 c2 = b1 == b2 &amp;&amp; c1 == c2 not F2 b1 c1 == F1 b2 c2 = b1 == b2 &amp;&amp; c1 == c2 
http://hackage.haskell.org/package/generic-lens
Presented (video): https://www.youtube.com/watch?v=Shl3MtWGu18
#MultiMachine Response - u/ysangkok ###Half Life 3 Delayed &gt;---- &gt;Congratulations by mentioning HL3 you single handledly delayed it for one more month the new release date is: November 2685 &gt;---- Don't be a worm rate the bot! Contact the creator at /u/Rogocraft
Also pretty sure the definition of the Functor instance for Yoneda doesn't work ;) Line 924. Should be more like instance Functor (Yoneda f) where fmap f (Yoneda y) = Yoneda (\k -&gt; y (k . f)) 
The desugared syntax is `\x -&gt; \y -&gt; \z -&gt; x * y * z`, which is a function that takes an `x` and returns a function `\y -&gt; \z -&gt; x * y * z`, which in turn takes a `y` and returns yet another function `\z -&gt; x * y * z`, which in turn takes `z` and returns `x * y * z`.
It seems that the last step (the one involving `coerce`) can be made a bit prettier using `DerivingVia`.
I think that /u/ephrion has a project (maybe one his company uses?), for connecting Persistent to multiple schemas [https://github.com/parsonsmatt/persistent-typed-db](https://github.com/parsonsmatt/persistent-typed-db)
The how comes Hoogle doesn't list it, and import Prelude :type (&lt;&gt;) yields no results in GHCi?
Check your version. It wasn't in Prelude before 8.4. It was in Data.Monoud before that. 
Change `fst` to `snd` and examine what happens.
I think you're on the right track here - just try writing test transformers for all your classes. [Here's an example to get you going.](https://github.com/lexi-lambda/mtl-style-example/blob/master/test-suite/MTLStyleExample/Test/Stubs.hs) I'd recommend taking a look through that repository, as it's a nice simple example of running an mtl-style approach.
Yup! I wrote this for my previous company. The apps talked to between 2 and 5 different database schemas. Contrary to OP, `persistent` supports multiple schemas just fine. When you define the entities, it doesn't have *any* notion of *which* database they're associated with. What it lacks is type-safety about which models belong to which database. Before I wrote the library, we'd essentially do: runAccountDatabase account accountQuery accountQuery :: SqlPersistT m () runMasterDatabase masterQuery masterQuery :: SqlPersistT m () As these types might suggest, there's nothing stopping you from writing runMasterDatabase accountQuery which will blow up at runtime with a SQL error saying "these tables don't exist." The library I wrote allows you to associate models with different backends, which gives you: accountQuery :: SqlPersistTFor AccountDb m () masterQuery :: SqlPersistTFor MasterDb m () runAccountDatabase :: Account -&gt; SqlPersistTFor AccountDb m a -&gt; m a runMasterDatabase :: SqlPersistTFor MasterDb m a -&gt; m a This provides type safety and caught a few bugs. The library hasn't been officially released yet, as I'm waiting on `esqueleto`'s new version to drop before I finalize the library.
Right OK, got myself updated. But now that evaluation complains about there being no instance of `Semigroup Bool` from using `(&lt;&gt;)`. 
This is true. I do prefer `Type` over `TYPE` but I'm not sure if this is a syntactical requirement or just my preference :)
Yea, there are two valid and intuitive ways of combining \`Bool\`s, \`&amp;&amp;\` and \`||\`. So there is no built in instance for \`Bool\`. Anyway, the idea behind that particular example is that \`fst ("no problems", True &lt;&gt; 17)\` will fail to compile in Haskell because of the \`True &lt;&gt; 17\` part, but the logic of that code does not actually depend on that part (since the code as a whole only gets the first element of the tuple. In a dynamic language like Python, this would not be a problem. For instance, in Python, I can run the following code: \`\`\` if True: print("no problems") else: print(True + 17) \`\`\` and it will run just fine. Since the types are not checked until run time, we never hit the \`else\` block that will throw a \`TypeError\`. So this is kind of an example where static type checking might get in the way (though I'd argue being able to catch those errors at compile time prevents bugs further down the line).
That's not a particularly helpful example since `True + 17` is [valid](https://ideone.com/o1bnDX) in Python. Correct me if I'm wrong, but isn't the point to say that we needn't check that `True + 17` is semantically valid in whatever language we're using if we don't need its value? 
d'oh, I should have actually checked that... But yea, that's the point 
There's a typo, the last line would be: ``` isInverseOf _ _ = False ```
Thanks for the advice on everything. I appreciate it.
This post is much improved by cloud-to-butt browser extension.
Any idea when esqueleto‚Äôs new version can be expected? 
Yup! `Bool` is not an instance of `Semigroup`. Try `Any` or `All`
Maybe at the end so people don‚Äôt bail on the good stuff :)
With `Backwards`, things become pretty nice :) Just swap out `traverse f` for `forwards . traverse (Backwards . f)`, and you get time-traveling for free, without having to define any extra types :D
Maybe that's my bad type-face. I was going for small caps, but maybe it reads just as caps. I was looking for a nice way to clearly demark kinds from types; any suggestions?
Your notes on `DataKinds` say "this is a shit example". My go-to `DataKinds` example is something like this. Suppose you have a record that you need to check before you let other parts of your program use it (maybe it comes with a MAC, and you want to guarantee that the MAC is checked before you do anything else with it): ``` {-# LANGUAGE DataKinds, KindSignatures #-} data Verification = Unverified | Verified data MyRecord (v :: Verification) = -- ... load :: FilePath -&gt; IO (MyRecord 'Unverified) verify :: MyRecord v -&gt; Maybe (MyRecord 'Verified) doSomething :: MyRecord 'Verified -&gt; IO () ```
Thanks! That's what I get for renaming variables in my latex document without recompiling them first. Mental note to myself to stop doing that.
Good feedback. FWIW `(&lt;&gt;)` is the semigroup/monoid [append operator](https://www.stackage.org/haddock/lts-11.17/base-4.10.1.0/Data-Semigroup.html#v:-60--62-), which has type `Semigroup m =&gt; m -&gt; m -&gt; m`. Since `True &lt;&gt; 17` clearly are not the same type, this example can't possibly typecheck, but then again it doesn't matter if we're only asking for the first element of the tuple.
I'm using Atom + HIE as my dev environment. For "regular" Haskell this works really well. Do you know how it fares with GHCJS?
I haven't used Atom+HIE myself, but Concur-React supports compilation with GHC, so you should be able to use the usual dev tools (type-checking, IDE features etc.) and only compile to GHCJS when testing / deploying. I personally use Purescript a lot more than Haskell these days, so the Purescript flavor of Concur gets a bit more love, but please open issues for any problems you might encounter with Concur Haskell, and I'll get to them soon!
You might have to rethink what you are looking for here. Lists are homogeneous in Haskell, so you can‚Äôt return a list that contains both the \`Int\` and the \`Double\`. Now for this particular case, you could convert the \`Int\` to a \`Double\` and return a list of \`Double\`s but that doesn‚Äôt work for all values that are an instance of \`Num\`.
Hoogle doesn't list it because it searches a fairly old version of a fairly small subset of hackage. Hayoo, for example, *does* list it: http://hayoo.fh-wedel.de/?query=(%3C%3E). So does the "new" Hoogle: https://hoogle.haskell.org/?hoogle=%28%3C%3E%29&amp;scope=set%3Aincluded-with-ghc. If GHCi doesn't report it, then you probably have a pre-SMP GHC installed, i.e. 8.2 or older; in that case, import `Data.Monoid` to get `(&lt;&gt;)`.
Maybe it would be less confusing if you used a construct that is the same in all GHC versions, and doesn't require any typeclasses? Lists spring to mind, so maybe `fst ("no problems", [True, 17])`?
&gt;You figure out that you need to make sure that the base image of the docker build keeps up with your development machine. Could you elaborate on it? I still don't get on how that nix config is different from a dockerfile based on alpine. 
Why don't functors have something like `pure` or `return` ? I'm reading Awodey's book on Category Theory where he mentions that Functors are maps `F` between categories `A` and `B` respecting the category structure. In particular for _objects `a` in `A`, `F(a)` is an object in `B`_. But Haskell's definition of `Functor` includes only `fmap :: (a -&gt; b) -&gt; (f a -&gt; f b)` which is just the mapping between the arrows. Can we call this a proper functor then? 
I've been using http://haskellbook.com/ to teach Haskell to a couple of people and one thing we found was suitable was exercises. I've only read the first 2 chapters so far but the second example could easily have had exercises like asking the reader to work out the kind of various expressions. The first 2 chapters were very engaging though and I would definitely buy this book. As an intermediate Haskell developer the content of this book is exactly what I'm trying to solidify in my head (along with recursion schemes). I didn't used to like books but since reading http://haskellbook.com I've found it really good to have something more rigorous than a collection of various blog posts.
Looks very interesting. I hope to that by the time you finish it, I will have sufficient knowledge and experience to start studying it :)
Is the link correct? I get a 404 from Github.
bad bot
Thank you, ocramz, for voting on MultiMachine. This bot wants to find the best and worst bots on Reddit. [You can view results here](https://goodbot-badbot.herokuapp.com/). *** ^^Even ^^if ^^I ^^don't ^^reply ^^to ^^your ^^comment, ^^I'm ^^still ^^listening ^^for ^^votes. ^^Check ^^the ^^webpage ^^to ^^see ^^if ^^your ^^vote ^^registered!
The paper says the new algorithm is efficient, but doesn't seem to have any measurements.
Works on Android...
ah right. my mistake. I was so focused on communicating the issue of filtering by constraint and/or type that I accidentally oversimplified all the way to a `[]` return type. I'll edit the question. so lets say, again for simplicity but correctness this time :), an hlist of values whose types are all instances of `Num`. a further simplification would of course be to simply return `[Double]`. this could be done with say `Typeable` but as you said this wouldn't would work for all `Num` instances
This book is the Deal of the Day today at [https://www.manning.com/dotd](https://www.manning.com/dotd), you can buy it half-priced together with 'Get Programming with Haskell' which I highly recommend to start learning Haskell. 
Oi mate, looks like you got the truth wrong eh: https://www.reddit.com/r/straya/comments/78bfbx/yeah_nah/
The link kinda works for me, but it links to http://www.github.com instead of https://github.com, and the redirection from one to the other loses the fragment and just dumps the reader at the top of the thread.
I think this is getting a bit ridiculous üòï Linear Types have one of the most discussed proposals, a clear roadmap, support, and theory. It's still behind a language-pragma after all. I feel like there's a point where the author could just surrender and let the idea die. I don't think the discussion for the proposal has been that productive after all. I think linear types could be very useful for some applications. Of course, the design isn't perfect, but I seriously doubt more discussing will fix this! Let's just communicate that they are an experimental feature and wait &amp; see how the community (ab-)uses them.
Ya, this is what happens for me on desktop Safari. But on my iPhone (same wifi network) it doesn't even get that far -- it's a full 404.
\[OT\] I would like to try britanny but it's not on LTS 11.13. How can I get \`stack install britanny\` to work? I aready tried adding it to extra-deps and packages.
1. I'm very interested in type-level programming, and it's hard to find good sources. A book like this is clearly missing. Judging from your blog posts you are an excellent candidate for writing it. 2. I'm definitely willing to spend about 60 USD on this book. 3. You could consider crowd funding if that would somehow help or motivate you. 4. I don't know about your experience with publishing (I don't have any), but if you're going ahead with this you should probably figure out the publishing process very early. 5. I agree with the comment about the flowery language. I personally like it when textbooks just talk about the matter at hand in simple and precise language. No cheery chit-chat or forced friendliness, no cultural references that may not mean anything to non-US readers. I'm not saying you did or intend to do any of that. I'm just casting my vote for a particular style. The author of Learn You a Haskell for Great Good deserves praise for doing the community a great service, but I found the style to be tiring. 6. If you decide to buy "On Writing Well" by William Zinsser from [bookdepository.com](https://bookdepository.com) (other sellers on request, though I would prefer to avoid Amazon), you can send me the receipt and I will reimburse you via PayPal within 7 days.
Normal, *Italic*, **Bold**, `Mono` in this order is what I personally use to separate different things visually in text. Monospace ahould probably be avoided in a book about code.
We can call this a proper Functor, yes. Haskell's Functor is an endofunctor in Hask (so a mapping from Hask to Hask), Hask is the category of Haskell types and functions. Given the objects in Hask are types (so things of kind `*`), the mapping between the objects is `* -&gt; *`, so it's the `f` in `Functor f`, for example `Maybe` changes the type `a` into the type `Maybe a`. The mapping between the arrows is `fmap`, since it changes the arrow `a -&gt; b` into the arrow `(f a -&gt; f b)`. 
bad bot
&gt; Future work includes detailed performance analysis (compared with backpropagation and other conventional AD algorithms); efficient higher-order differentiation; and applying generalized AD to derivative-like notions, including subdifferentiation [Rockafellar, 1966] and automatic incrementalization (continuing previous work [Elliott, 2017]).
The level of support here is almost overwhelming, cheers. I'll check out "On Writing Well". Do you have a textbook whose prose you think is a particularly good example of being precise?
I mentioned that one on twitter as an alternative truth table / regional or inflectional variation. ;)
Ohh, I get it. The mapping F here is the mapping from Hask to Hask. Thanks!
&gt; I am usually a fan or Richard Eisenbergs work, but I hoped that he would communicate clearer whether committee intends to accept the proposal or not and only list minor stuff that should be corrected. If you read further down through his response this is precisely what he recommends. &gt; In a followup email to the committee, I will recommend that we encourage you to resolve these open questions, with an eye toward acceptance.
I read it, but it still didn‚Äòt strike as as overly positive and encouraging. Maybe the proposal is really more flawed than I understand it to be. But if there‚Äòs the chance of it getting accepted, there must be something solid there. Maybe I am a bit overreacting and the response is not what I think it is...
I personally share many if not all of Eisenberg's concerns and his general conclusion. I _do_ think warts and all, it is still a good move for the community to continue on towards inclusion, but to shave off whatever warts we can along the way. That said, I personally find the interaction with exceptions to rob it of much of its overall merit for the original stated goals of the project, as you get this sort of uncomfortable middle ground where things act like linear types except when you take an exceptional control flow path and then they degrade to something more than affine types. Given the kinds of performance sensitive code this seems most suited for is the kind of code that is most littered with exception handling, I'm somewhat dubious how much this will pay out in practice for the "obvious" applications, but I'm also cautiously optimistic that there will be some benefits in unusual areas as well.
&gt;limick "Principles of Quantum Mechanics" by Shankar was one of my absolute favourites. "Linear Algebra Done Right" by Axler also comes to mind. Of course precision is a prerequisite for a textbook about maths or physics. No great surprise there. But I do find it impressive how the authors of these books manage to explain difficult concepts using simple language that plainly reveals the facts and doesn't lead astray.
The idea seems fine, but I think you should explicitly mention that is the convention. Small caps for kinds, monospace for types.
My main concern there (sorry if it wasn't highlighted explicitly) is the whole bunch of assertions are need to be placed inside a test transformer implementation, which looks kinda weird. Thanks for pointing to the mtl-style-example, that a great project. At the same time I don't see how this problem is solved there - all these implementations are just `ReaderT`\ `WriterT` and doesn't have any assertions inside.
You can't, because of the open-world assumption. That is, you cannot ask _if_ a type has a Num instance, you can only require that a type _must_ have a Num instance, and then get a type error if that type doesn't have a Num instance. If you could ask the question (which, okay, [I guess you can](https://github.com/mikeizbicki/ifcxt) if you really want to), you'd sometimes get the wrong answer, because orphan instances can change the answer later on. I'd suggest using a type family instead: {-# LANGUAGE DataKinds, TypeFamilies #-} type family Keep a :: Bool where Keep Int = 'True Keep Double = 'True Keep _ = 'False Next, we need to convert the record to an `HList`. This has been covered by a [recent post](https://www.reddit.com/r/haskell/comments/8v1lkq/deriving_vinyl_representation_from_plain_haskell/), so for simplicity, I'll assume we already have an `HList` containing _all_ the fields of the record, and we want to filter it so only the values whose type are accepted by `Keep` remain. Now, what would be the type of such a transformation? It's a function from an `HList as` to some `HList as'`, in which `as'` is `as` filtered by `Keep`. So we need to implement the type-level filtering function first: {-# LANGUAGE TypeOperators, UndecidableInstances #-} import Data.Type.Bool (If) type family HFilter as where HFilter '[] = '[] HFilter (a ': as) = If (Keep a) (a ': HFilter as) (HFilter as) We can now write down the type of the transformation we want: `hfilter :: HList as -&gt; HList (HFilter as)`. That's not _quite_ the right type though: this type says that the transformation works for _any_ list of types `as`, even if we don't know anything about that list. We do need to know something about that list, namely, whether `Keep` returns `'True` or `'False` for each element of that list. Let's focus on a simpler case. Which constraint do we need to add to a function `keep :: a -&gt; Bool` so it can return `True` if `Keep` returns `'True` and `False` if `Keep` returns `'False`? We need a variant of pattern-matching which pattern-matches on the type-level value instead of the value-level value: {-# LANGUAGE FlexibleContexts, RankNTypes, ScopedTypeVariables, TypeApplications #-} import Data.Proxy class KnownBool (b :: Bool) where caseBool :: Proxy b -&gt; (b ~ 'True =&gt; r) -&gt; (b ~ 'False =&gt; r) -&gt; r instance KnownBool 'True where caseBool _ t _ = t instance KnownBool 'False where caseBool _ _ f = f -- | -- &gt;&gt;&gt; keep (2::Int) -- True -- &gt;&gt;&gt; keep (2.5::Double) -- True -- &gt;&gt;&gt; keep ("hello") -- False keep :: forall a. KnownBool (Keep a) =&gt; a -&gt; Bool keep _ = caseBool (Proxy @(Keep a)) True False We will need this information about every type in `as`, so let's construct a constraint which says exactly that: import GHC.Exts (Constraint) type family AllKnownKeep as :: Constraint where AllKnownKeep '[] = () AllKnownKeep (a ': as) = (KnownBool (Keep a), AllKnownKeep as) We could use it to map `keep` over all the elements of an `HList`, for example: {-# LANGUAGE GADTs #-} data HList as where HNil :: HList '[] HCons :: a -&gt; HList as -&gt; HList (a ': as) hlist :: HList '[Int, Double, String] hlist = HCons 2 (HCons 2.5 (HCons "hello" HNil)) -- | -- &gt;&gt;&gt; mapKeep hlist -- [True,True,False] mapKeep :: AllKnownKeep as =&gt; HList as -&gt; [Bool] mapKeep HNil = [] mapKeep (HCons x xs) = keep x : mapKeep xs We are now ready to implement `hfilter`: -- | -- &gt;&gt;&gt; let r = hfilter hlist -- &gt;&gt;&gt; :force r -- r = HCons 2 (HCons 2.5 HNil) hfilter :: AllKnownKeep as =&gt; HList as -&gt; HList (HFilter as) hfilter HNil = HNil hfilter (HCons (x :: a) xs) = caseBool (Proxy @(Keep a)) (HCons x (hfilter xs)) (hfilter xs) Note that we can't simply call `keep`, because the `Bool` returned by `keep` doesn't give any information to the type checker about what `HFilter (a ': as)` will reduce to. By using `caseBool`, the true branch runs in the context `Keep a ~ 'True`, and so `HFilter (a ': as)` reduces to `a ': HFilter as`, whereas the false branch runs in the context `Keep a ~ 'False`, and so `HFilter (a ': as)` reduces to `HFilter as`.
This seems like a great list of questions to answer. I hope/think the proposal authors have received enough encouragement from the community to not let the discouraging parts dominate.
Is it trimmed by default now? The sizes are compatible with my experience with trimmed and non-trimmed ones. It used to be that you had to compile all of your libraries for trimming if you wanted GHC to do that, and by default it didn't.
By trimmed you mean stripped of symbols? Debug symbols were stripped before too (I verified) . Maybe local symbols where not stripped.
and inversely proportion to the generality of the thing being named
I think they mean compiling libraries with "--enable-split-objs"
I would definitely buy a book on TLP that's written by you. Your blog posts are great.
Semi-related: https://jtobin.io/ad-via-recursion-schemes
Yes, this is what I meant. Somehow it has a different name, with different rules on every language :)
This is awesome. It is not everyday that one gets to see a reasonably clear explanation of such material. I am looking forward for more.
This is an interesting and, to me, very relateable take on C programming. As a mostly-embedded programmer, I mostly work in C. I've been using C and C++ on and off for something over 30 years now and I feel that I'm pretty good at it, although there is always more to learn about some particular technique or optimization or way to write more portable, safer code. Because I haven't figured out a way to use Haskell much in actually writing firmware for shipping products---at least not yet---I have so far only gotten so far with Haskell. But it has definitely changed the way I think about coding, especially with respect to state and how I organize it. This in turn has helped me write code that is easier to maintain and easier to use in separate parallel tasks.
Is there an easier way to import dependency modules/packages into the REPL when using `stack ghci`, instead of importing one-by-one? I'd personally find this a little more streamlined for development, rather than just modifying the source code and using `:r`.
yea after reading this paper: [https://www.google.com/search?q=generic+traversal+lens&amp;rlz=1C5CHFA\_enUS797US797&amp;oq=generic+traversal+lens+&amp;aqs=chrome..69i57j69i60l3.7016j1j4&amp;sourceid=chrome&amp;ie=UTF-8](https://www.google.com/search?q=generic+traversal+lens&amp;rlz=1C5CHFA_enUS797US797&amp;oq=generic+traversal+lens+&amp;aqs=chrome..69i57j69i60l3.7016j1j4&amp;sourceid=chrome&amp;ie=UTF-8) i was going to attempt to implement this via \`GHC.Generics\` directly facilitated by a type family to designate out types of "interest" as oppose to a typeclass constraint. you've beaten me to that to haha. this is a fantastic answer! thanks a bunch
brittany author here. config file documentation is indeed missing currently. There are tiny amounts of comments [in the source code](https://github.com/lspitzner/brittany/blob/master/src/Language/Haskell/Brittany/Internal/Config/Types.hs#L52). This is one of the first items on my version 1.0 goal list.
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [lspitzner/brittany/.../**Types.hs#L52** (master ‚Üí 4497fa9)](https://github.com/lspitzner/brittany/blob/4497fa927fc77a41f49ee385af4c35f391cc5a7f/src/Language/Haskell/Brittany/Internal/Config/Types.hs#L52) ---- 
&gt; parse your code according to the version of GHC you're compiling with only if by "compiling" you mean the process of compiling "brittany". if you compile brittany with ghc-8.0 and try to use it in a project that uses ghc-8.4 features, you may still run into problems. But while the GHC API changes (which does require some adaption from brittany with each GHC release), the fact that brittany uses the GHC parser itself makes the transition relatively easy and less error-prone. A separate parser implementation like HSE is at higher risk of accidentally diverging in some manner.
(brittany author here) &gt; Yesterday I gave brittany a serious try and was impressed at how much faster it is and found it refreshing that it preserved my new lines and the comments in their right place. I even found settings that made it look the same to the hindent output I was already used to work with. Nice to hear! &gt; My only gripe so far is that it makes a bad job at pretty printing imports. I hear that you don't like it, but without some more specific "in this case i'd prefer layout x" it is really hard to do anything with such feedback :p
It is actually "Split Sections", not "Split Objects", which is now enabled by default since 8.2.1: https://ghc.haskell.org/trac/ghc/ticket/11445 In particular, split sections leverages the linker's ability to garbage collect unused sections in object files. This means you have 1 object file per module still, rather than one-per-function. This means certain horrors in GHC can be avoided (including the Satanic Splitter, `ghc-split`) and it interacts better with certain utilities like `strip`.
It does! There will be an official post on [the stackage blog](https://stackage.org/blog) soon.
If we define a type constructor for discrete probability distributions like `[(a, Double)]`, we can't write a fast implementation of `Monad` for it, because without the `Ord` constraint the lists will grow and never shrink. Recently I found [this approach](https://jeltsch.wordpress.com/2015/09/03/constrained-monads/) which seems like it should solve the problem. But it still comes out slow and I can't figure out why. Here's my code: {-# LANGUAGE ExistentialQuantification, GADTSyntax #-} import Control.Monad (liftM, ap) import Data.Map.Strict (Map, fromList, fromListWith, toList, singleton) data Dist a where ReturnDist :: a -&gt; Dist a BindDist :: Map a Double -&gt; (a -&gt; Dist b) -&gt; Dist b instance Functor Dist where fmap = liftM instance Applicative Dist where pure = return; (&lt;*&gt;) = ap instance Monad Dist where return = ReturnDist ReturnDist a &gt;&gt;= f = f a BindDist d h &gt;&gt;= f = BindDist d (\a -&gt; h a &gt;&gt;= f) toDist :: Map a Double -&gt; Dist a toDist d = BindDist d ReturnDist fromDist :: Ord a =&gt; Dist a -&gt; Map a Double fromDist (ReturnDist a) = singleton a 1 fromDist (BindDist d h) = fromListWith (+) [ (a,b*v) | (k,v) &lt;- toList d, (a,b) &lt;- toList (fromDist (h k)) ] sumCoins 0 = return 0 sumCoins n = do a &lt;- toDist (fromList [(0,0.5),(1,0.5)]) b &lt;- sumCoins (n-1) return (a+b) main = print (fromDist (sumCoins 15)) When I increase the number of coins to 20 or 30, everything becomes intolerably slow. What am I missing?
I don't think that it is an accurate characterisation of linearity in presence of exceptions. What a linear function gives you is that if you consume the returned value with multiplicity `p`, then the argument will be consumed with multiplicity `p` as well. Evaluating a (base type) value which can raise an exception, can be seen as consuming it with affine multiplicity, in which case, the argument is also consumed with affine multiplicity. However the function stays linear, and the affine consumption is a consequence of its linearity. Saying otherwise is akin to saying that I cannot write a total function, in Haskell, because I can apply it to `error`. In fact, exceptions can be modelled in linear logic, as the `_‚äï‚ä§` monad (which bears some relation to affinity, as it is dual to the affine comonad `_&amp;‚ä•`). Nevertheless, you wouldn't argue that linear logic is somewhat affine because you can write a function `Œº : (X‚äï‚ä§)‚äï‚ä§`. What is true, however, is that `catch` cannot be given (safely) any flavour of linear types. And it may make some application harder to the point of not being worth it. Nevertheless we have examples of code bases without many `catch` which we expect to benefit greatly from linear types (as described, for instance, in [this blog post](https://www.tweag.io/posts/2017-11-29-linear-jvm.html)). The [`RIO` library](https://github.com/tweag/linear-base/blob/a89215459b47b7e780dfcbcf14fa6446017dd2fc/src/System/IO/Resource.hs) used as an example of the proposal is an example of a ressource-safe (even in the presence of exception, asynchronous or otherwise) linear abstraction. It doesn't have a `catch`: exceptions are propagated to, and rethrown by, `RIO.run`; but everything gets safely deallocated. Because it is linear, types force you to reason about resources' release. Which is exactly what we need for the example in the blog post. 
My concern is more that I can write perfectly safe seeming code, wherein I never use exceptions, but the moment someone throws an exception _at_ me, I lose all my carefully managed resource consumption guarantees. If all linear code is going to live in a `mask`ed world, then everything is fine, but this is pretty far from the way Haskell gets written. I wind up having to make some kind of affine-like cleanup code path for when I do get killed. I'm not saying it is unusable. I'm just saying that it has non-obvious challenges, so finding use-cases that fit the semantics it necessarily has is more complicated than I might like.
I don't believe Mac OS supports it either, since, well Apple does their own thing. it does work on Mac OS using GNU tools, but I don't believe that's how we spin the binaries. On Windows hopefully we'll be able to turn it on in 8.8.
Yes. It's a case of as a first step managing expectations. As a second, trying to find ways to get "any real sort of resource management" that is useful. The aforementioned RIO pattern, which is implemented and typechecks today, is an existential proof that this is possible.
Not OP, but perhaps if you're running some premade images on youre single docker host it might feel simpler to hook them up with "docker means". Nix is hard for a beginner, having recently gone through much of what the OP is describing.
This seems like a very important breakthrough. The sentence &gt; Let‚Äôs now look at some AD examples, to which we will later in the paper as well: missing a word. 
Also note that `mapAccumL` and `mapAccumR` in https://hackage.haskell.org/package/base-4.11.1.0/docs/Data-Traversable.html are optimized with an internal `StateL` and `StateR`, e.g. https://hackage.haskell.org/package/base-4.11.1.0/docs/src/Data.Functor.Utils.html#StateR e.g. one could write cumulativeR :: (Monoid w, Traversable t) =&gt; t w -&gt; t w cumulativeR = snd . mapAccumR stepper mempty where stepper w acc = (acc', acc') where acc' = w &lt;&gt; acc 
Looks like `-XStandaloneDeriving` became easier to use. From the [release notes](https://downloads.haskell.org/~ghc/master/users-guide/8.6.1-notes.html): &gt; GHC now permits the use of a wildcard type as the context of a standalone deriving declaration with the use of the `PartialTypeSignatures` language extension. For instance, this declaration: &gt; &gt; deriving instance _ =&gt; Eq (Foo a) &gt; &gt; Denotes a derived `Eq (Foo a)` instance, where the context is inferred in much the same way as ordinary deriving clauses do. See Partial Type Signatures. 
But with RIO the question becomes if the extra complexity is worthwhile when compared with ResourceT. The compiler can enforce early releasing and warn against double freeing at compile time instead of run time. On the other hand there is some syntax overhead from -XRebindableTypes, less type inference and passing resources between nested recovery scopes becomes somewhat more complex. At least to me personally nicer api's when encoding state transitions and a non-monadic ST alternative are an easier sales pitch.
I get a 406 on that. Bad link?
That's very true. Sorry for not getting that the first time reading :) At work I tend to install quite a few things manually and lock them to versions that I know work across our team, for example, and I'm sure I'm not the only one.
I'd echo everything that /u/ElvishJerricco said. I have no problem with running scripts, however, and `curl https://some-script | vim -` is something I do every now and then. A simple `:! sh` in vim will execute the script once you've verified it. I had to do this to install a rust toolchain on my work computer because it's not in the package manager and rustup annoyingly insists on trying to install to its own directories for things instead of `/usr/local/bin/` and the `$XDG_DIR`s
Yup! This is the code we are using. I did mention in the last paragraph that it was a surprising discovery to me that base already contained StateL and StateR. 
You don't put them inside the transformer, you pass the data into your program and run it with the test transformers in each test. You use the `WriterT`s etc to record what your program did, and base your assertions off that. [There's a small example here](https://github.com/lexi-lambda/mtl-style-example/blob/master/test-suite/MTLStyleExample/MainSpec.hs), but if that doesn't make sense, let me know and I'll whip up a gist with some example of what we're doing at work.
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [lexi-lambda/mtl-style-example/.../**MainSpec.hs** (master ‚Üí 06d0606)](https://github.com/lexi-lambda/mtl-style-example/blob/06d06065a8186f2af2ab92e716de906ffa42f22a/test-suite/MTLStyleExample/MainSpec.hs) ---- 
Not strictly Haskell related, but what did you use to master writing CSS with ease?
Isn't it much easier to use stack for this?
When it comes to managing GHC versions I think stack covers the use-cases of a lot of users yes, but not my uses. So I thought this post would be worth writing up in case it can be of use to anyone else.
The post may not be relevant to Stack users, but there are plenty of cabal-install / Nix users out there, so it's still useful. I can think of plenty of reasons you'd want to try a variety of GHC versions specifically with cabal-install or Nix. Personally I find it easiest to just use Nix on the command line rather than NixOS configs, Ubuntu PPAs, or Stack, since I already have Nix on every system I use. `nix-shell -p haskell.compiler.ghcXYZ`, bam. Don't even have to worry about symlinks or install locations. Then I can just use `-w` for cabal-install or `--system-ghc` for Stack. I just wish both tools used the hash of `ghc --info` rather than the GHC version number when determining whether rebuilds are required. [Cabal issue](https://github.com/haskell/cabal/issues/5116); not sure if there's an open one for stack. But if anything in `ghc --info` is different, it should NOT be considered the same compiler by either tool, and I *believe* both of them consider only the version number.
It would be nice to see the section for MacOS as well. I've spent some time to figure out the good way to install different \`ghc\` versions on MacOS (I'm very new to Mac). Here is the python script I find useful for these purposes: [https://haskell.futurice.com/](https://haskell.futurice.com/) . Though I had troubles with \`ghc-8.6.1\` as it's not supported by that installer yet..
\`brittany\` has my vote for many of the reason already mentioned. * Built on \`ghc-exact-print\`. This is a much better foundation than \`ghc-src-exts\` as others have mentioned. It utilizes the GHC parser and keeps pace with GHC development. * \`ghc-exact-print\` has idempotent round tripping of src. This means that \`brittany\` does not need to format all new forms in order to function properly, instead it can ignore new constructs and keep pace with GHC without having to make hasty formatting decisions. * Lennart is a fantastic steward. I've opened/merged a few issues and pull requests. Every time he has been communicative, helpful and all around lovely to work with. 
Is there an advantage to using cabal-install over using nix entirely?
Yea. cabal-install gives you a solver. When you want to add a new version of something to your Nix project, it's a major pain to have to go through and change dependency versions one at a time until everything is happy. Plus Nix can be a big hammer sometimes; it necessarily comes with a little overhead whereas cabal-install is zero overhead until you hit problems. I've begun to default to `cabal new-build` when starting something new, moving to Nix at the first sign of trouble or once I want a reproducible, easily distributed build (cabal can do mostly reproducible builds but Nix can do it better w.r.t. system dependencies, revisions, environment variables, etc.). Of course I use Nix to pin the system dependencies like GHC in all cases.
*Stack to the rescue* https://chrisconlan.com/the-haskell-package-ecosystem-in-30-seconds-or-less/
Recently `ghc-8.6.1-alpha` came out. It was very difficult with `stack` to install that GHC version. And it's even difficult to discover solution. With Ubuntu PPA it's the same as installing any other GHC version.
&gt; it's a major pain to have to go through and change dependency versions one at a time until everything is happy I haven't had to maintain larger nix projects, so I'm not sure how applicable my strategy is, but I like to omit version information from my cabal files, and just have versioning implicit in my pinned nixpkgs. I guess that's unorthodox, but since it gives reproducible builds, I think it should be forgivable.
If you can't reach that page, here's an archive page. http://archive.is/1LUnI
No what you do is typical. The issue I'm describing is when the version of one of your dependencies that is pinned in nixpkgs is not new enough. Trying to update that dependency can be a frustrating rabbit hole of having to manually recurse back and solve newer versions of many of *its* dependencies.
Without the fixed `network-2.7.x` none of these will build on AppVeyor, right? Would it make sense to wait for that to be included?
Patience, practice and css-tricks.com. Unless we are talking about a different kind of CSS?
Please don't wait, /u/isovector. No one knows when dependent Haskell will arrive, and if it takes three years from now, plus one year of writing the book, we'll have to wait four years, as opposed to just a single year if you write it now. Linear Haskell was also targeted for release in early 2018[1], but that didn't exactly happen. [1] https://www.tweag.io/posts/2017-03-13-linear-types.html
The compiler version could be just an argument of `release.nix`, and could be set in `shell.nix` for `nix-shell`, or set on-demand via `--argstr compiler XXX` for `nix-build`. [https://github.com/Gabriel439/haskell-nix/tree/master/project1#changing-the-compiler](https://github.com/Gabriel439/haskell-nix/tree/master/project1#changing-the-compiler)
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [Gabriel439/haskell-nix/.../**project1#changing-the-compiler** (master ‚Üí 035d75f)](https://github.com/Gabriel439/haskell-nix/tree/035d75f07f4ba9f0aa44fa61d8eccaffc066fa49/project1#changing-the-compiler) ---- [^delete](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply e2448r4.)
consider using \`nix\`
Recently I've had the joy of experiencing something I thought I understood but clearly did not. My program in `Writer String` was running slow, and I thought "well I know what the problem is -- `Writer` is associating the appends in the wrong order, making it all quadratic and slow, so I'll just rephrase my program in `Writer (Endo String)` and everything will be fine." Well... to my surprise after changing everything, nothing changed. Not a single second of performance difference. So I decided to make some synthetic tests to convince myself I wasn't crazy, and I've now convinced myself whatever I was thinking was totally wrong: xs :: Int -&gt; [ Int ] xs i = [ 1 .. i ] notActuallySlow :: Int -&gt; Writer String () notActuallySlow = traverse_ (tell . show) . xs actuallySlow :: Int -&gt; String actuallySlow = foldl (\a -&gt; (&lt;&gt;) a . show) [] . xs go :: Bool go = -- takes ~10 seconds, returns True actuallySlow i == execWriter (notActuallySlow i) -- takes &lt;1 second, returns True -- execWriter (notActuallySlow i) == execWriter (notActuallySlow i) where i = 15000 I expected `actuallySlow` and `notActuallySlow` to have the same asymptotics, but running this program, clearly they do not. As far as I can see, the `Writer` implementation is not doing the "wrong" thing and traversing everything repeatedly as I thought it was - and this is kinda bad, actually, because what if I *wanted* the left associative stuff evaluated first (e.g., I was using `Writer Int` and wanted constant space)? So my question here is what am I missing? I could have sworn everything was being evaluated left associatively, since that's like... half the point of having stuff like `DList`/`Endo` and `Codensity`, right?
&gt; It would be nice to see the section for MacOS as well. I think the NixOS instructions would probably work with [nix-darwin](https://github.com/LnL7/nix-darwin).
I use Gentoo Linux. I got problem too. However, I install ncurses version 5, And solve this problem. [No setup information found for ghc-8.4.3 when not installed ncurses version 5 ¬∑ Issue #4144 ¬∑ commercialhaskell/stack](https://github.com/commercialhaskell/stack/issues/4144)
I'd certainly buy it.
I'm on MacOS, so from what I gather \`ld -dead\_strip\` was turned on?
Hi! Thanks for your active involvement, that really makes me confident that brittany is the way forward. I think something that would bring brittany on part with indent is by providing support for: * Sorting imports: [https://github.com/lspitzner/brittany/issues/155](https://github.com/lspitzner/brittany/issues/155) * Sorting of symbols imported per module \`import Data.Text (a, b, c)\` * Utilize more of the horizontal space, right now it looks like all functions imported get a new line by default I'm really not a fan of vertically aligned stuff, as somehow that makes things more difficult to read for me, but I guess I will eventually adapt.
I'm not sure which fix is on the 2.7 branch, I know the MVar bug was backported to 2.6.3.6. If you're referring to the tempdir one I blogged about, adding `TMP: "c:\\tmp"` fixes the problem for me with all versions of network I've tested.
Hurrah! It builds on my Mac fine, but when I do `docker pull` I get an error saying "manifest for fpco/stack-build:lts-12.0 not found". Has the docker repo been updated yet?
Yeah, I was talking about [https://github.com/commercialhaskell/stack/issues/3944](https://github.com/commercialhaskell/stack/issues/3944) Okay, I'll try to set that variable then. Are there plans to fix this in the long run or will this be a requirement for all \`appveyor.yml\` for Haskell projects moving forward? Thanks for all your work on figuring the issue out, that was quite the rabbithole :D
:) There's a patch added to Cabal, which should work around this. https://github.com/haskell/cabal/pull/5388 It looks like it won't be backported to existing Cabal releases, so the workaround will be necessary as long as you want to use GHC 8.4, but fortunately as far as workarounds go it's not too bad.
It usually takes a few days at least for that image to get updated, I'm not quite sure what the process is for it kicking in. If you want, you can [jump on Gitter](https://gitter.im/commercialhaskell/stack) to ask about it.
Honestly, I just download GHC bindists from the website, run `./configure --prefix=$HOME/ghcXX/ &amp;&amp; make install` to install various GHC versions in `$HOME`. I switch between them by just changing my path (i.e., `PATH="$HOME/ghc82/bin:$PATH"` when I wanna use 8.2) and it Just Works (TM). cabal-install just uses whichever GHC is first on your path and since GHC smartly uses a version specific package database, multiple parallel versions don't affect each other at all.
If anyone is interested, here's the full working code for the printf example: `{-# LANGUAGE FlexibleInstances #-}` `{-# LANGUAGE TypeOperators #-}` `{-# LANGUAGE DataKinds #-}` `{-# LANGUAGE PolyKinds #-}` `{-# LANGUAGE TypeFamilies #-}` `{-# LANGUAGE TypeApplications #-}` `{-# LANGUAGe ScopedTypeVariables #-}` `module Study.TypeProxies where` `import GHC.TypeLits` `import Data.Proxy` `import Data.Monoid ((&lt;&gt;))` `import Prelude` `data (a :: k1) :&lt;&lt; (b :: k2)` `infixr 5 :&lt;&lt;` `class HasPrintf a where` `type Printf a :: *` `format :: String -&gt; Proxy a -&gt; Printf a` `instance KnownSymbol text =&gt; HasPrintf (text :: Symbol) where` `type Printf text = String` `format s _ = s &lt;&gt; symbolVal (Proxy @text)` `instance (HasPrintf a, KnownSymbol text) =&gt; HasPrintf ((text :: Symbol) :&lt;&lt; a) where` `type Printf (text :&lt;&lt; a) = Printf a` `format s _ = format (s &lt;&gt; symbolVal (Proxy @text)) (Proxy @a)` `instance (HasPrintf a, Show param) =&gt; HasPrintf ((param :: *) :&lt;&lt; a) where` `type Printf (param :&lt;&lt; a) = param -&gt; Printf a` `format s _ param = format (s &lt;&gt; show param) (Proxy @a)` `instance {-# OVERLAPPING #-} HasPrintf a =&gt; HasPrintf (String :&lt;&lt; a) where` `type Printf (String :&lt;&lt; a) = String -&gt; Printf a` `format s _ param = format (s &lt;&gt; param) (Proxy @a)` `printf :: HasPrintf a =&gt; Proxy a -&gt; Printf a` `printf = format ""`
You can manually thread monadic code through `cata` and friends easily, including specifying the evaluation order based on the shape of your recursive data. data TreeF r = Leaf Int | Bin r r deriving Functor type Tree = Fix TreeF go :: Tree -&gt; IO Int go = cata alg where alg (Leaf x) = putStrLn ("Leaf " ++ show x) *&gt; pure x alg (Bin left right) = do l &lt;- left r &lt;- right let total = l + r putStrLn ("Bin " ++ show total) pure total
Right, these are all sensible suggestions. The alignment in imports has one advantage: it keeps diffs small when imports change. But I can completely see that the horizontal space usage is far from ideal and I would be fine with having a config flag to switch to a block-fill approach (similar to what stylish-haskell does, iirc). It mostly comes down to who finds the time to put in the work of implementing those features :-)
Hmm. Why have `cataM` at all, then? üòï
I'm trying to write a fast [constrained monad](https://jeltsch.wordpress.com/2013/02/14/the-constraint-kind/) for probability distributions, but it's still slow. Works fine for 15 coins, chokes for 20. Does anyone know why? {-# LANGUAGE ConstraintKinds, RebindableSyntax, TypeFamilies #-} import Prelude hiding (Monad (..)) import GHC.Exts (Constraint) import Data.Map.Strict (toList, fromListWith) fail = undefined class Monad m where type Object m a :: Constraint type Object m a = () return :: Object m a =&gt; a -&gt; m a (&gt;&gt;=) :: (Object m a, Object m b) =&gt; m a -&gt; (a -&gt; m b) -&gt; m b data Dist a = Dist {unDist :: [(a, Double)]} instance Monad Dist where type Object Dist a = Ord a return x = Dist [(x,1)] d &gt;&gt;= f = Dist (toList (fromListWith (+) s)) where s = [(b,p*q) | (a,p) &lt;- unDist d, (b,q) &lt;- unDist (f a)] main = print (unDist (sumCoins 15)) where sumCoins 0 = return 0 sumCoins n = do a &lt;- Dist [(0,0.5),(1,0.5)] b &lt;- sumCoins (n-1) return (a+b)
Every bind `d &gt;&gt;= f` calls `f` as many times as there are elements in the distribution `d`. So `sumCoins n` calls `sumCoins (n-1)` twice because that's the length of the list above it. Thus `sumCoin` has exponential complexity. In this case you can recover polynomial complexity by memoizing `sumCoins`.
That makes sense, thanks! Looks like I can achieve the same thing by swapping the lines for `a` and `b`, then it can go up to 1000 without problems. Is there any way to make it do the right thing regardless of the order?
I am also (still) doing this.
Really? That sounds like Cabal hell from 10 years ago... I would have hoped and expected that nix provides something smoother here.
[`traverse_`](https://hackage.haskell.org/package/base-4.11.1.0/docs/src/Data.Foldable.html#traverse_) is defined using `foldr`, applied to `(*&gt;)`, which is basically `(&lt;&gt;)` if we focus only on the monoidal component of `Writer`. The performance issues of `WriterT` cannot be worked around using just a fancier monoid. This is a consequence of `(*&gt;)` being just a wrapper for `(&lt;&gt;)`, which it should be semantically but is too naive to be optimizable. For constant-space performance, [a different `WriterT` transformer](https://hackage.haskell.org/package/writer-cps-transformers) is really necessary.
That's disturbing. Would uniqueness typing suffer from a similar problem? The current \[Clean Language Report\]([https://clean.cs.ru.nl/download/html\_report/CleanRep.2.2\_1.htm](https://clean.cs.ru.nl/download/html_report/CleanRep.2.2_1.htm)) doesn't mention exceptions at all.
The compiler would need to recognize that `sumCoins (n-1)` doesn't depend on `a`, and that it is worth floating out of that lambda (`(\a -&gt; sumCoins (n-1) &gt;&gt;= ...) = (let sc = sumCoins (n-1) in \a -&gt; sc &gt;&gt;= ...)`) but that is generally not such a good idea outside of this particular definition of `(&gt;&gt;=)`. Another remark is that these two lines in `sumCoins` are really meant to be independent computations, so `Applicative` would be a more suitable abstraction, and `ApplicativeDo` might have the right behavior here.
&gt; The performance issues of WriterT cannot be worked around using just a fancier monoid. I mean to say I *expected* performance issues with `Writer` and yet I can't actually produce any. (Though yes, I suppose I could if I tried to have a strict, constant-space state - I can see how that requires something slightly different). So how does that square with the free/codensity story? Because here it looks like everything is already associated to the right, but I thought the whole claim to fame of codensity is it... reassociates everything to the right? At first I thought maybe bind would associate differently than `traverse`, so I rewrote `notActuallySlow` with a bind/recursive call, but it's... still fast, so it's still associating to the right: stillNotActuallySlow :: Int -&gt; Writer String () stillNActuallySlow = f . xs where f :: [ Int ] -&gt; Writer String () f [] = pure () f (x : xs) = do tell (show x) f xs 
Yeah, I noticed that `liftA2` has exactly the behavior that I want. But `Dist` can't be `Applicative`, because functions can't be `Ord`. So I guess I'm out of luck...
&gt; Apparently, there is some feature in Agda called positivity checking which can apparently keep the system sound [even if type-in-type is enabled](https://gist.github.com/gelisam/5152919). You link to my gist, but my gist does not demonstrate that the positivity checker keeps the system sound even if type-in-type is disabled. In fact, the opposite is true: the type system becomes unsound if _either_ `--type-in-type` or `--no-positivity-check` is added. My gist only demonstrates how to prove ‚ä• when _both_ flags are added, so it's not a very good demonstration of why either is needed.
I just use nix on darwin.
Please submit Agda-related posts to /r/agda, not /r/haskell.
I don't really understand the convention for existential quantification. For example: ``` data F x = forall a. Foo (a -&gt; x) ``` Reading this definition, my intuition says that `Foo` should be `Foo :: (forall a. a -&gt; x) -&gt; F x` That is, `Foo` can contain only functions that do not depend on their input type, i.e., `const x` functions only. But this is not true. `Foo length :: F Int` works fine. Rather if a function _accepts_ something of type `F x`, it cannot assume anything about `a`. That is `f (Foo g) = g 2` doesn't work (demands `Num a =&gt; ..` on the `forall`) Is there a reason behind this convention, or is my intuition just twisted.
Well, r/haskell certainly seems to be a more vibrant community
You're welcome! &gt; So how does that square with the free/codensity story? Because here it looks like everything is already associated to the right, but I thought the whole claim to fame of codensity is it... reassociates everything to the right? Indeed `traverse_` already associates `&lt;*&gt;` to the right, but then something breaks when composing it with another action: traverse_ f [x,y, ...] *&gt; doSomething because this now looks like: (f x &lt;&gt; (f y &lt;&gt; ...)) &lt;&gt; doSomething but `Codensity` would allow us to put `doSomething` back inside, without rewriting the original line above. (f x &lt;&gt; (f y &lt;&gt; ... (... &lt;&gt; doSomething) ...)) In particular we don't need to define a specialized version of `traverse_` to carry `doSomething` to the end of the list, `Codensity` does that for free (although there may be an implicit cost to understand how to use it).
Uniqueness types don't have this problem. You can drop a "unique" value on the floor, they haven't been contracted yet, but may be weakened at any time. They are like a slightly stronger claim than affine, but not the same claim as linearity. Linear is a promise to never contract or weaken in the future. Affine is a promise to never contract in the future. Uniqueness is a promise you haven't contracted in the past (and since the value is still around you haven't weakened it in the past either.) It says nothing about the future.
What you are describing is data G x = Goo (forall a. a -&gt; x) -- universal quantification It helps me to write it in [`GADT` syntax](https://downloads.haskell.org/~ghc/8.4.3/docs/html/users_guide/glasgow_exts.html#generalised-algebraic-data-types-gadts) -- Existential data F :: Type -&gt; Type where Foo :: (a -&gt; x) -&gt; F x -- Universal data G :: Type -&gt; Type where Goo :: (forall a. a -&gt; x) -&gt; G x `a` doesn't appear in the return type! You can pass any function to `Foo` but `Goo` will only accept functions that discard their arguments like, `const x` as you said. Let's use [`TypeApplications`](https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/glasgow_exts.html#visible-type-application) to highlight this: &gt;&gt; :set -XTypeApplications &gt;&gt; :t Foo .. :: (a -&gt; x) -&gt; F x &gt;&gt; :t Foo @Int .. :: (a -&gt; Int) -&gt; F Int &gt;&gt; :t Foo @Int @() .. :: (() -&gt; Int) -&gt; F Int We (the callers of `Foo` can choose the type of `a`. Compare this to `Goo` &gt;&gt; :t Goo .. :: forall (forall a. a -&gt; x) -&gt; G x &gt;&gt; :t Goo @Int .. :: (forall a. a -&gt; Int) -&gt; G Int where we cannot choose the type of `a`.
It's possible to return the underlying function of `G x` fromG :: G x -&gt; (forall a. a -&gt; x) fromG (Goo goo) = goo but Haskell doesn't support first class existential quantification so we cannot write fromF :: F x -&gt; (exists a. a -&gt; x) fromF (Foo foo) = foo we must instead encode (fake) it with universal quantification fromF :: F x -&gt; (forall a. (a -&gt; x) -&gt; res) -&gt; res fromF (Foo foo) cont = cont foo
Well, "cabal hell" specifically refers to the breaking of builds due to changing the installed version of a package without updating its dependencies, so that doesn't seem relevant here; Nix never has that problem. Anyway, yea it's a little frustrating, but it's not often necessary. Usually bumping a package is just bumping that one package; it's just really frustrating when it isn't. I'm sure someone could create a solution to this pretty easily, but I don't know of any attempt at the moment.
Yes, it is.
https://ghc.haskell.org/trac/ghc/ticket/14845
That ticket was how I learned this. I found it going through the ghc-tickets mailing list like I often do in my spare time. 
&gt; but there are plenty of cabal-install / Nix users out there Please stop claiming there were "plenty" of cabal users without providing any evidence when at the same time you attack me when I quantify Stack's market share in the 90% ballpark.
"Plenty" doesn't necessarily mean 80-90%, or even 10%. I'm not making any claims about statistics or relative popularity; but there are definitely a non-negligible *absolute* number of cabal users, even if the relative number is like 5%.
I think I understood what you said, but correct me if I'm wrong: ``` data F = forall a. Foo (a -&gt; x)` ``` is equivalent to ``` data F :: * -&gt; * where Foo :: (a -&gt; x) -&gt; F x ``` In this case, given a `F` constructed with `Foo`, we have no idea what `a` is, so can't rely on that in our functions. Also, `Foo` is interpreted as `forall x a. (a -&gt; x) -&gt; F x` , which takes two type arguments as you showed using `TypeApplications`, but `Goo` doesn't. Thanks for the detailed answer. I also got to know about `TypeApplications` as a bonus!
It's not the worst, but it also can lead to using buggy libraries (and then debugging an issue that was fixed upstream) or libraries with security vulnerabilities. 
This is not a solution. 
AIUI, nix doesn't do incremental rebuilds. cabal-install does. So, for development, even if your dependencies and environment are being managed by nix, you still want to drive builds with cabal-install (or stack if you prefer).
Are you talking about bleeding edge packages, or situations when you want to upgrade one package but don't want to change the pinned nixpkgs?
Mostly talking about the latter. For instance, bumping `free` from `4.12.x` to `5.0.x` was pretty painless. But bumping any major version of `servant` requires solving *a lot* of packages.
Of course. Though that's a different question. It may only be worth it in rather specific scenarios. &gt; warn against double freeing Well, prevent it altogether, really. Also prevent resource handler from escaping their definition scope (which is not the case in `ResourceT`). With `RIO` you typically have just one scope, compared to `ResourceT` where you have many nested scopes. `ResourceT` advocates a stack-like structure for resources (which is quite often sufficient, to be honest), while `RIO` doesn't. Another cost of `RIO` is that you don't use the same types as `System.IO` for file handles and all that (they need to be wrapped somehow). &gt; At least to me nicer api's when encoding state transitions and a non-monadic ST alternative are an easier sales pitch. To everybody their own. The beauty of linear types is that they have plenty of potential applications. Not everybody cares about the same. And some may not stick, it's quite hard to predict this sort of things.
&gt; In this case, given a `F` constructed with `Foo`, we have no idea what `a` is, so can't rely on that in our functions. Yes, `a` is "some" type ([rigid](https://mail.haskell.org/pipermail/haskell-cafe/2008-June/044622.html)), it's already been specified. When a user constructs `Foo` they can choose `a` to be any type that is *not* reflected in the type Foo (show @Int) :: F String Foo (show @Bool) :: F String That's why we can't write -- Couldn't match type ‚Äòa‚Äô with ‚ÄòInt‚Äô -- ‚Äòa‚Äô is a rigid type variable bound .. -- -- Expected type: Int -&gt; x -- Actual type: a -&gt; x -- asInt :: F x -&gt; (Int -&gt; x) asInt (Foo foo) = foo what if the user passed in `Foo (show @Bool)`?? This is perfectly sensible to define for `G` however (we are explicit with *visible type application* again) asInt :: G x -&gt; (Int -&gt; x) asInt (Goo goo) = goo @Int To drive the point home I use type synonyms a lot to understand higher-rank types type Element x = forall a. a -&gt; x data G :: Type -&gt; Type where Goo :: Element x -&gt; G x
aka data F x = forall a. Foo (a -&gt; x) data G x = Goo (Element x)
Maybe we could move to nightly LTS releases? I struggled to see the point of LTS 3 years ago. Every Haskell company I advise or work for I always start with telling them to give up on LTS and the result is always positive. http://neilmitchell.blogspot.com/2015/12/whats-point-of-stackage-lts.html
Last year I made the statistics below. If you shorten the lifespans even more you should really stop calling them "long term support" to avoid misleading everyone. GHC Version | First LTS | GHC Lag | Last LTS | LTS Lifespan | Last Update ------------|-----------|----------------:|----------|-------------:|-------------: GHC 7.8.3 ^(*[2014-07-11]*) | LTS 0.0 ^(*[2014-12-12]*) | **154d** | LTS 0.7 ^(*[2014-12-28]*) | **16 days** | 1063d ago GHC 7.8.4 ^(*[2014-12-23]*) | LTS 1.0 ^(*[2015-01-11]*) | **19d** | LTS 1.15 ^(*[2015-03-29]*) | **77 days** | 972d ago GHC 7.8.4 ^(*[2014-12-23]*) | LTS 2.0 ^(*[2015-04-02]*) | **100d** | LTS 2.22 ^(*[2015-08-09]*) | **129 days** | 839d ago GHC 7.10.1 ^(*[2015-03-27]*) | | **‚â• 974d** | | | GHC 7.10.2 ^(*[2015-07-29]*) | LTS 3.0 ^(*[2015-08-12]*) | **14d** | LTS 3.22 ^(*[2016-01-10]*) | **151 days** | 685d ago GHC 7.10.3 ^(*[2015-12-08]*) | LTS 4.0 ^(*[2016-01-06]*) | **29d** | LTS 4.2 ^(*[2016-01-18]*) | **12 days** | 677d ago GHC 7.10.3 ^(*[2015-12-08]*) | LTS 5.0 ^(*[2016-01-26]*) | **49d** | LTS 5.18 ^(*[2016-05-23]*) | **118 days** | 551d ago GHC 7.10.3 ^(*[2015-12-08]*) | LTS 6.0 ^(*[2016-05-25]*) | **169d** | LTS 6.35 ^(*[2017-06-05]*) | **376 days** | 173d ago GHC 8.0.1 ^(*[2016-05-21]*) | LTS 7.0 ^(*[2016-09-14]*) | **116d** | LTS 7.24 ^(*[2017-05-28]*) | **256 days** | 181d ago GHC 8.0.2 ^(*[2017-01-11]*) | LTS 8.0 ^(*[2017-02-12]*) | **32d** | LTS 8.24 ^(*[2017-07-27]*) | **165 days** | 121d ago GHC 8.0.2 ^(*[2017-01-11]*) | LTS 9.0 ^(*[2017-07-26]*) | **196d** | LTS 9.14 ^(*[2017-11-18]*) | **115 days** | 7d ago GHC 8.2.1 ^(*[2017-07-22]*) | | **‚â• 126d** | | | GHC 8.2.2 ^(*[2017-11-20]*) | | **‚â• 5d** | | | 
Ah, ok. Wasn't sure quite how it worked. I can wait! Thanks.
My impression (which is based solely on intuition and zero actual knowledge in the area) was that an LTS series may not be the most recent LTS series for the long term, but it may receive bug fixes and security updates for the long term. i.e. we may move on to LTS 12.0, but LTS 11.0 can still receive fixes. That's sort of how the Linux kernel treats LTS, anyway.
Hm. Using nightlies by default seems strictly worse than using a solver and checking in freeze files (potentially with --allow-newer). The point of LTS to me is that it provides a concept of non-major updates to the entire package set. Without LTS, any attempt to update the package set used by your project must be considered a major update, unless you cherry pick the packages to update.
Yes. But it's never happened in practice. The one security fix that did happen to aeson coincided with a major version bump and didn't get merged back. 
I'm looking at the respective Trac tickets for 32bit Windows for ages! Good luck guys! Go #12913! \\o/
Any update to your packages must be considered a major update. Real companies don't skip testing because an open source dev added only 0.0.1 to their changes. That benefit has zero value to me. Imagine we had someone run the solver, test the result, and figure which bounds to restrict to balance compatibility and latest versions. And then ping everyone who needs to update the packages and a central place to track it. Before stackage that process cost months. With nightly we can do it on whatever schedule suits us with little work. It's incredibly powerful!
Hm. I suppose kernel sized solutions don't really apply unless you have kernel sized problems :P Has it actually \*never\* happened, or is it just exceedingly rare?
I believe literally never, but could be wrong. I certainly can't find an advisories page, so if they did, it wasn't to much benefit. 
`class Applicative m =&gt; Monad m where ...` and `class Functor f =&gt; Applicative f where ...` we need `instance Functor Tc where` `fmap = liftM` and `instance Applicative Tc where` `pure = return` `(&lt;*&gt;) = ap`
&gt;Imagine we had someone run the solver, test the result, and figure which bounds to restrict to balance compatibility and latest versions. And then ping everyone who needs to update the packages and a central place to track it. Before stackage that process cost months. With nightly we can do it on whatever schedule suits us with little work. It's incredibly powerful! Ok. I suppose the advantage that nightlies have over the solver is that nightlies are "tested" to some degree, and don't advance until certain tests pass, whereas a random person re-running the solver may run into failures due to PVP related bugs / misuse. So updating to a new nightly is potentially more likely to be successful than re-running the solver.
&gt;Any update to your packages must be considered a major update This isn't true in my experience. Minor LTS updates almost never cause breakage for me. Nightlies do.
If you decide to upgrade to nighties every 2 weeks, you get a small amount of breaking at compile time, and a small amount of breakage at runtime. If you upgrade to LTS every 2 weeks, you get a small amount of breakage at runtime (so you'd better have those tests in place) and a huge amount of breakage every time you do a major upgrade (which is vastly harder to fix than the cumulative nightly cost - since you have 5 things in a module to fix simultaneously). In my experience, LTS has a higher total cost. You also end up with bugs that have been fixed upstream, but not made it into the nightly, which sucks big time.
I tried the solver approach. It doesn't work even slightly - we spent days battling with constraints, relaxing and tightening bounds etc. Great in theory, sucks in practice. Nightlies are tested, and curated to figure out which bounds to add to get a consistent whole.
Ah that makes a lot of sense. So the LTS minor updates are actually fairly minor, but the major updates are just *too* major. I could see that.
I thought nightlies simply didn't use bounds, and just used the latest version of every package in the nightly rather than being curated? And according to [their readme](https://github.com/commercialhaskell/lts-haskell/blob/master/README.md), they are released nightly. If both of these things are true, I can't imagine how a nightly is different in any way to the solver with `--allow-newer`
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [commercialhaskell/lts-haskell/.../**README.md** (master ‚Üí b69b998)](https://github.com/commercialhaskell/lts-haskell/blob/b69b9987e989c925c2bc467f409b259fe248106f/README.md) ---- 
As one data-point, `text-1.2.3.0` fixed a [very disturbing `RULE` bug](https://github.com/haskell/text/issues/197) which can result in wrong computations, so could I'd consider it a security fix or at the very least a high priority fix. A quick `staversion` query tells me that only LTS-11+ feature `text-1.2.3.0`; all prior LTSes (i.e. LTS-0 through LTS-10 !) are still pinning compromised `text` versions. The irony is that not only Stackage doesn't provide any meaningful security-fix support contract, but it was also demanded that we [relax the lower bound for the Cabal-2.2.0.0 release](http://hackage.haskell.org/package/Cabal-2.2.0.0/revisions/) to allow Stackage snapshots *not* be forced to upgrade away from the compromised `text &lt; 1.2.3` releases... ;-) 
I've been using this bash script that I cannot seriously recommend anyone rely on, but it's been working for me: https://github.com/mitchellwrosen/ghc-switch I'm running Arch linux at the moment, so my options seem to be: - Use `stack` to install GHC for me - Manually download and build GHC from downloads.haskell.org
&gt; thought nightlies simply didn't use bounds They use plenty of human curated bounds. Just like LTS. If I release a package that breaks other packages in nightly typically they will bound my package down, ping all dependencies that broke, and manage everyone towards allowing the new package and then upgrading my package. If someone goes AWOL, they chose when to drop other packages to allow mine through. There's a fantastic amount of work that goes in. LTS snapshots are just grabbing a nightly and freezing it, all the hard work happens on nightlies. If you rely on a solver to figure out what to bound, it doesn't have context of what changed most recently to figure what should get downgraded first. You could argue the solver should use that information (I certainly do!) but it doesn't.
Ah ok. Somewhere I heard nightlies were much dumber than that. I see the value in that.
This is just a matter of finding the correct stanza for your `stack.yaml`, is that correct?
LTS has been great for us, and the logic seems clear. As a yesod shop with a lot of complex add-on functionality, we have quite a large number of recursive dependencies. With nightlies, we could be subject to a a form of slow-moving cabal hell. In any given nightly, the chance is high that at least a few of our deps will have been kicked out due to some incompatibility. So we could be stuck without any upgrade at all for a significant amount of time. When a new nightly finally appears that we can use, it requires significant integration work at unpredictable times, so in practice it will wait even longer, and we get stuck in a negative feedback loop that keeps us deep in the hole. It also causes extra work and uncertainty - constant testing of nightlies, and fiddling with version pinnings. LTS is a chance for everyone to come together at a predictable pace and produce package sets that work. The curators have done a great job of producing really high quality LTS releases. The pace is fine - it's worth it for us to be consistently a tiny bit behind in order to get a fully working package set regularly. LTS saves us a huge amount of work.
"Much" when the difficulty for either tool is low doesn't mean much. Nix vs. Stack comes down to how much you care about managing your non-haskell dependencies in the same way.
They are tested by CI builds. If a package misbehaves, it is kicked out of that nightly. Whereas with an LTS, there is time to work on getting misbehaving packages back in before it is released.
Sure it happens all the time - via minor LTS version bumps. We can go with those without issue. Whereas for major LTS version bumps, we have time to work on it. We internally switch to the lead-up nightlies on branches and work on ironing out issues. When the LTS bump comes, we are ready for switching to it for production by merging in the work we did on the branches.
Hm. Neil's comments suggest they are doing bounds curation on nightlies. Which is it?
Would this reduce the quality of the LTS releases? Seems like it would be hard to maintain the faster pace without reducing quality. And if that is the case, I am opposed to this change.
I've now built and pushed fpco/stack-build:lts-12.0
Nix should work on Arch, I believe, as long as you use the installer script from nixos.org instead of Arch's package manager to install it.
There's some value in having the latest (ish) versions of your dependencies be the path of least resistance. With a solver + freeze files it's a bit easy to dodge new dependency releases; this is solvable with tooling, but it's not trivial to get yourself set up and to have the discipline to use it. This pressure to upgrade is what I get out of Stackage nightlies over freeze files.
 Yeah TypeApplications really makes this clear. Thanks! :)
Why did you link to the revision rather than the issue that prompted the revision? https://github.com/haskell/cabal/issues/5198 That issue points to open issues in both `lts-haskell` and `stackage` about `text-1.2.3.0` being excluded from LTS snapshots. As far as I can tell, `text-1.2.3.0` has not been included because some other packages in the snapshot have bounds that prevent it. https://github.com/commercialhaskell/lts-haskell/issues/103 https://github.com/commercialhaskell/stackage/issues/3347
Why does it matter?
nix makes it very easy to create any number of environments, with like one line, including compiler options like `-fPIC`.
So what? What are you getting at? The point still stands that we were forced to perform a metadata revision in order to relax the lower bound of `lib:Cabal-2.2.0.0` to allow it to depend, against better judgement, on compromised versions of `text` which may silently compute wrong results because, for reasons I don't consider relevant in that context, the Stackage snapshots couldn't be upgraded *and* that **all** LTS releases prior to LTS-11 are still stuck with a compromised version of `text`. Moreover, even though I released `text-1.2.3.0` already in 2017 it took till mid-March of 2018 before it ended up in LTS-11.0, which was the very first LTS to feature `text-1.2.3.0`. Long story short, everyone using LTS-0 through LTS-10 in mission critical settings would be well advised to set a version of at least `text-1.2.3.0` to avoid this known silent miscalculation bug.
How can this example be extended in case of additional constrain to the monad stack, such as `MonadThrow m`? So, instead of `Identity` in test cas, probably, there should be something like `Either SomeException`. It's not playing well as is, e.g. ‚Ä¢ No instance for (MonadTime (HttpT (TimeT (Either SomeException)))) 
I like the looks of this toc. Good luck with the writing I‚Äôm sure I‚Äôll buy at least one copy when it‚Äôs out. Consider having a beta / early access scheme for it. 
Perhaps my text at the bottom of that long post is indeed too discouraging... but that's a sign of the fact that I honestly felt discouraged after thinking about it all for some time. I *want* linear types to be awesome. I would be very happy to write a full-throated endorsement. As it stands now, though, the proposal is, well, discouraging to me. It has several pain points and folks whom I respect seem uncertain of its utility. (Others I also respect are more convinced of its utility, to be fair.) All that said, I do believe the proposal will be revised and accepted. My official recommendation to the committee as the shepherd for this proposal: "Encouragement to continue the proposal and implementation, with an eye toward acceptance." As I said here, I want linear types to be awesome, and I think accepting this proposal (after it gets refined and fleshed out -- especially with regard to type inference), is the best way to get awesome linear types.
Do you have MonadTrans instances for those transformers? That looks like HttpT doesn‚Äôt have an instance for MonadTrans (and thus the instance for TimeT isn‚Äôt being selected), or there isn‚Äôt an instance of MonadTime for TimeT.
Are uniqueness and linearity interconvertible with continuations? I seem to recall that you can go at least one way.
So is there any reason someone would still use "Split Objects" on an linux/ELF? Or is "Split Sections" always better?
I'm keen on this idea; any suggestion for how to do such a thing?
Not sure it's about the absence the MonadTrans instance. Here is a minimal reproducible example of the same issue on the original repo: https://github.com/dmalikov/mtl-style-example/commit/8bf22f80e61e61ddcd6c0cf23b6ab8429279dea7
One element with nightlies is that the amount of contained packages has a sort of sawtooth as it drops drastically with a bump to a new compiler typically, then gradually builds up again, then cuts. So defaulting to nightlies will drastically compress the average quantity for available packages in a way that's nonuniform among different users unless some care is taken more broadly. Not saying it is unworkable, but it is a tradeoff that would be worth considering and mitigating.
I'd be a little surprised (but not terribly) if you could do both ways.
Nice work! I've been working on a [implemention in Yesod](https://github.com/tzemanovic/haskell-yesod-realworld-example-app) and I'm getting close to finish too. Have you tried connecting your backend to any frontend? I ran mine with the Elm frontend and found that there were a few small details missing from the API spec.
Unfortunately, I haven't tried any. Perhaps I will try purescript sometime in the future. What kind of missing details? 
Not only. 1. I need to find this `stack.yaml` and integrate it into my project. 2. Since there's no snapshot for GHC alpha, I need to write all my 50 dependencies in `extra-deps` field in `stack.yaml` which is an extra work and duplication with `package.yaml/.cabal` file.
Never mind, I just a look again and it looks like it's only a slight difference in the Elm implementation, where the user is expected to have \`createdAt\` and \`modifiedAt\` fields.
Not really any experience with it as a writer only as a consumer. Manning does it via MEAP and some of the self publishing places like leanpub. 
what special bindings does it need? I never used Fedora, so this might be totally wrong, but I think you should be able to use [ghc](https://www.haskell.org/downloads/linux) or [stack](https://docs.haskellstack.org/en/stable/install_and_upgrade/#fedora) just as it is
Messed around in a vagrant box to test different install methods. Stack doesn't seem to have it yet: $ curl -sSL https://get.haskellstack.org/ | sh $ stack --compiler ghc-8.4.3 ghci Writing implicit global project config file to: /home/vagrant/.stack/global-project/stack.yaml Note: You can change the snapshot via the resolver field there. Using latest snapshot resolver: lts-12.0 Downloaded lts-12.0 build plan. No setup information found for ghc-8.4.3 on your platform. This probably means a GHC bindist has not yet been added for OS key 'linux64-ncurses6', 'linux64-tinfo6'. Supported versions: ghc-7.8.4, ghc-7.10.2, ghc-7.10.3, ghc-8.0.1, ghc-8.0.2, ghc-8.2.1, ghc-8.2.2, ghc-8.4.1, ghc-8.4.2 But Nix worked out of the box: $ curl https://nixos.org/nix/install | sh $ nix run nixpkgs.haskell.compiler.ghc843 -c ghc --version The Glorious Glasgow Haskell Compilation System, version 8.4.3 The instructions in your ghc link installed an old version of GHC, but OP wanted 8.4.3. AFAICT, there's only one GHC version in the package repo. $ sudo dnf install ghc cabal-install $ ghc --version The Glorious Glasgow Haskell Compilation System, version 8.2.2 The Haskell Platform also came with outdated packages: $ sudo dnf install haskell-platform $ ghc --version The Glorious Glasgow Haskell Compilation System, version 8.2.2 You can add an unofficial repo though, which is mentioned in that ghc link: $ sudo dnf copr enable petersen/ghc-8.4.3 $ sudo dnf install ghc cabal-install $ ghc --version The Glorious Glasgow Haskell Compilation System, version 8.4.3 This does not change the GHC version with the Haskell Platform, however: $ sudo dnf copr enable petersen/ghc-8.4.3 $ sudo dnf install haskell-platform $ ghc --version The Glorious Glasgow Haskell Compilation System, version 8.2.2
I think `Data` meaning "general purpose data structure" arguably has some value. So `Data.Vector` or `Data.Tree` or whatever. `Control` is definitely a weird one though, maybe even `Class` for general purpose classes like `Functor` or `Witherable`? It would be good to come up with a nice consistent scheme that everyone would follow.
It's worth noting that GHC does actually have an LLVM backend too, which it converts Cmm into.
yes sorry about the link - I should have probably pointed to the "manual" section - I assumed this would work as for stack: I'm sure that'll be fixed in the next few days - I opened an issue here: https://github.com/commercialhaskell/stack/issues/4147
Yes, very true - that's a place where having two overlapping series simultaneously might be valuable.
&gt; One element with nightlies is that the amount of contained packages has a sort of sawtooth as it drops drastically with a bump to a new compiler typically Ever wonder why this is? As u/snoyberg has expressed countless times, the main most wasteful culprit that holds up the curation process are useless version constraints in cabal files. Version constraints are an antiquated mechanism that may have made sense before Stackage. But now that we have Stackage as the standard distribution mechanism every package that is part of Stackage needs to drop their their version bounds for Stackage curators.not have to keep spinning their wheels and waiting for maintainers to act.
Insert benchmarks would be a nice reference as well. 
&gt;`nix-shell -p haskell.compiler.ghcXYZ`, bam. How do you start your developer tools (like an editor) then? From this new shell? From the outside? How do you make sure that they find the same version of GHC that your project uses? I guess my high-level question is, how do you compose your developer tool environment with your project specific environment?
I did focus on \`lookup\` performance as it was the priority for the library. Indeed insert operation is important and adding benchmarks for that too sounds like a good idea, thanks!
For now I just use [dante](https://github.com/jyp/dante) in Emacs without needing to spawn Emacs in this shell. It can detect nix based solutions automatically in many cases, and let's you specify your own repl launcher if you want. In the future I plan to switch more permanently to haskell-ide-engine, which let's you use a wrapper if you want, which can just invoke HIE under a Nix shell.
I thought about it some more, and it seems like `ApplicativeDo` is just doing the wrong thing for constrained applicatives. It shouldn't be putting functions in containers, most uses of that can be covered by tuples and `fmap` just fine. Something like this (`sumCoins` and `sumCoins'` are the original and my preferred desugaring): {-# LANGUAGE ConstraintKinds, RebindableSyntax, TypeFamilies, ConstrainedClassMethods #-} import Prelude hiding (Functor(..),Applicative(..),Monad(..)) import GHC.Exts (Constraint) import Data.Map.Strict (toList, fromListWith) class Functor f where type Domain f a :: Constraint type Domain f a = () fmap :: Domain f b =&gt; (a -&gt; b) -&gt; f a -&gt; f b class Functor f =&gt; Monoidal f where unit :: Domain f () =&gt; f () mult :: Domain f (a, b) =&gt; f a -&gt; f b -&gt; f (a,b) class Monoidal f =&gt; Monad f where return :: Domain f a =&gt; a -&gt; f a (&gt;&gt;=) :: Domain f b =&gt; f a -&gt; (a -&gt; f b) -&gt; f b fail = undefined data Dist a = Dist {unDist :: [(a, Double)]} mkDist x = Dist (toList (fromListWith (+) x)) instance Functor Dist where type Domain Dist a = Ord a fmap f d = mkDist [ (f a, p) | (a, p) &lt;- unDist d ] instance Monoidal Dist where unit = mkDist [ ((), 1) ] mult d e = mkDist [ ((a, b), p * q) | (a, p) &lt;- unDist d, (b, q) &lt;- unDist e ] instance Monad Dist where return x = mkDist [ (x, 1) ] d &gt;&gt;= f = mkDist [ (b, p * q) | (a, p) &lt;- unDist d, (b, q) &lt;- unDist (f a) ] main = print (unDist (sumCoins' 20)) where sumCoins 0 = return 0 sumCoins n = do a &lt;- mkDist [(0, 0.5), (1, 0.5)] b &lt;- sumCoins (n - 1) return (a + b) sumCoins' 0 = return 0 sumCoins' n = let a = mkDist [(0, 0.5), (1, 0.5)] b = sumCoins' (n - 1) in fmap (\(x, y) -&gt; x + y) (mult a b)
I thought that unboxed vectors already did the struct-of-arrays thing for tuples. That's what the docs say.
The reason we keep \`Fingerprint\`s as two vectors of \`Word64\` is that we can apply the faster binary search algorithm for lookup. Also if you check \`Vector\` instance for \`Word64\` you can see that it implemented with the usage of primitive vector, which contains two \`Int\`s and \`ByteArray\`. And we actually ended up using \`PrimArray\` which literally has only \`ByteArray#\` field.
What GHC flags are you using to compile and do you have the code for the benchmarks?
For benchmarks we compile with \`-O2\` and here is the code: [https://github.com/kowainik/typerep-map/tree/master/benchmark](https://github.com/kowainik/typerep-map/tree/master/benchmark) I also tried with LLVM backend but performant boost was not too significant to keep \`-fllvm\` flag.
While writing `typerep-map` a lot of different topics were raised, but I decided not to include all information directly in the blog post, though there is a lot more to tell. If you are interested in any of the following topics I can describe it in a much more informative way (or at least will try to tell how the development process for this was going): * Inlining and other optimization that were used in binary search and lookup algorithms (including `&lt;#` etc. functions), how each step affected the performance, how it changes generated core. * Writing `Unboxed.Vector` instances for data types like `Fingerprint` * Benchmarking with polymorphic recursion in more details * Property-based testing for structures like `TypeRepMap` * or probably you're interested in any specific step of implementation Thanks for reading, any feedback is really appreciated!
Hi, /u/AaronNGray. Your question would be better-suited to the "Hask Anything" thread pinned to the top of the subreddit. But I will approve it. Please use the Hask Anything thread for simple/beginner-level questions such as this one. üòä
Can someone explain what ‚ÄúLamping‚Äôs abstract algorithm‚Äù actually is? I don‚Äôt really feel like paying $15 to read something I will probably not understand üòû
Here's one very easy way to do it, though it is a bit of a hack: 1. Use the GHC binary tarball to install GHC with \`./configure --prefix=\~/.stack/programs/&lt;your-architecture&gt;/ghc-8.6.1\` 2. Create the file \`\~/.stack/programs/&lt;your-architecture&gt;/ghc-8.6.1.installed\` containing exactly the text \`installed\` with no newline (so exactly 9 bytes). If you already have the GHC installed somewhere else and you want to use it, you can replace step 1 with this: 1. Create a symlink called \`\~/.stack/programs/&lt;your-architecture&gt;/ghc-8.6.1\` that points to the existing GHC directory.
Why not use the GHC binary tarball? That's what stack does behind the scenes.
(Beta-)Reduction of anonymous functions means evaluation by passing in arguments. This algorithm is an optimization over the naive version that minimizes recomputation of sub-expressions by using a clever encoding. HTH?
Hah, that's pretty funny. Me and and u/andrewthad had made something extremely similar: https://github.com/andrewthad/type-containers
slicing is overrated
That's interesting! The interface looks similar. I see that you're using map-based implementation, so I believe that performance will differ. `typerep-map` has benchmarks for lookups which shows that map-based implementation is less efficient than array-based, but it will be vice versa in case of inserts.
Sweet. Someone else is making an array-backed dependent map. I've written one in [primitive-containers](https://github.com/andrewthad/primitive-containers/blob/master/src/Data/Dependent/Map/Unboxed/Lifted.hs) as well. Now we just have to do a benchmark shootout.
I think this explanation of kinds is flawed. There's no real distinction between types and kinds. Consider the following definition: https://hackage.haskell.org/package/singletons-2.4.1/docs/Data-Singletons.html#t:SingKind class SingKind k where type Demote k = (r :: *) | r -&gt; k fromSing :: Sing (a :: k) -&gt; Demote k toSing :: Demote k -&gt; SomeSing k Is `k` here a kind or a type? Note that if we didn't care about singletonization for `-&gt;`, `Nat`, `Symbol`, and `Type` (or if we made these things promotable), we could go even further and declare: class SingKind k where fromSing :: Sing (a :: k) -&gt; k toSing :: k -&gt; SomeSing k and at this point it is pretty clear that in `fromSing` the `k` occurs both in a kind position and a type position. The proper way to talk about kinds is to explain that we have two relations, `term :: type` and `type :: type`. The right-hand side of `type :: type` is occasionally called a kind. That's it! I especially disagree with your "kind declarations", because that would imply that `Bool` the type and `Bool` the kind are different entities, which they aren't.
I'm the author of `type-map`. The mention seems to have missed [its `Dynamic` module](https://hackage.haskell.org/package/type-map-0.1.2.0/docs/Data-TypeMap-Dynamic.html) which offers a similar interface, but defunctionalizes the `f` parameter in `typerep-map` to avoid syntactic wrappers ([HKD-style](http://reasonablypolymorphic.com/blog/higher-kinded-data/)). My implementation is `Map`-based, so `typerep-map` is definitely more efficient!
What are the cons of this approach?
No, it should largely (from my understanding) be superior in every way, including stability, output size, and performance. (In fact `--split-objs` wasn't ever even recommended for use outside GHC itself, due to outstanding problems in the implementation. Inside GHC, it is used to build final versions of the "bootstrap libraries" it ships, like `base`, to help trim every executable since they _all_ use `base`). I imagine `--split-objs` will be removed entirely (or simply made a deprecated alias for `--split-sections`) in time, once the macOS and Windows work goes through and is considered stable.
At a high-level, it helps a bit. Just wondering if there is a published description that describes how it works, on a theoretical and practical level.
How do you disable SSL verification when using [the req library](https://github.com/mrkkrp/req)?
Which data structures could also provide a performance improvement? A quick search online reveals solutions using finite maps (between coordinates and values -- known or a set of unknown) and one with a board of this type which I certainly do not understand: newtype Sudoku a = Sudoku (StateT (DiffUArray (Int,Int) Int) Nondet a) deriving (Functor, Monad, MonadPlus)
Can you clarify? The script I use does download the binary tarball. (Though based on /u/ElvishJerricco's comment I'm thinking it's time I use start using nix + gnu stow or something)
Oh, I see! But I didn't notice this module on hackage, so it might be more difficult to do benchmarking at the moment..
That's a good point! I will update this part of the post. Thank you!
More space leaks. 
Presumably this can be "fixed" by providing a do-not-share primitive, right?
For example I am stuck with lst-8.24, which less than 3 year old but has actually been dropped (for LTS-9). When I say stuck, I mean stuck. I spend the weekend to try to upgrage to LTS-nightly. Yes, even though I work for a company, I have to do the upgrade on my own time ... Anyway the few problem I have are : - I use Fay and Yesod. Fay has been broken until recently following some GHC improvements. Now Fay has been upgraded, but unfortunately you get with the new compatible version some backward compatibility breakage (which are IMO totally unnecessary) and can't use anymore `yesod-fay`, which anyway has been dropped with lts-9 (which is why I'm stuck with lts-8) - I need to updrage to `Yesod-1.6` which breaks a few things. I manage to fix some, but I also need to upgrade `conduit` which apparently has dropped `finalizer` which unfortunately I need. So, after having wasted a weekend, I'm back to lts-8.24 and GHC 8.0.2 :-(
Keep your eye out for [Intermediate Haskell](https://intermediatehaskell.com/).
It's a Cthulhu type
I'm not even sure DiffUArray exists anymore. Once upon a time, it was an array type with a pure/persistent interface that his mutation behind the scenes. The goal of the design was to make incremental updates very fast at the cost of making access to the non-latest version of the array much slower. It turns out this pattern utterly destroys performance in any situation where the persistent properties are used. It also adds a ton of overhead in all cases. Eventually it was given up because it just wasn't better than the alternatives for any particular use case. 
The bit about "Handler can't be a reader" was weird to me. Handler can be whatever you want it to be pretty trivially. The docs are incredibly annoying about this fact because they're split across 2 versions with 2 drastically different ways of accomplishing that, but once you work out what your specific version wants you just close over your configuration values and then you can work with mostly any context you want.
yeah, the ecosystem is definitely lacking when it comes to static data structures optimised for reads (they only get built once). structures built on top of primitive are really great for implementing these static structures, where lookups are super fast, but modification is much slower. for something like typrerep-map, it might be good to have both. i find it's useful to build up large structures using something like data.map and turn it into something like map.lifted from primitive-containers
I understand that `return` cannot simply be moved to `Applicative` as that would break existing class definitions. Hence the [Monad of No Return](https://ghc.haskell.org/trac/ghc/wiki/Proposal/MonadOfNoReturn) proposal. But what about, e.g., `sequence` and `mapM`? Why do they still have the `Monad` constraint?
Having read the book as it's written so far. I'm very intrigued, but as a beginner in TLP a lot of your reasoning isn't written and is lost on me. For instance, why does format take 3 arguments in case 3: format s \_ p = format (s &lt;&gt; show p) (Proxy @a). But only 2 in the others? I also didn't really grasp what a Proxy is, or how you decided upon the recursive cases, why you chose an associated type for the HasPrintf typeclass, etc.
What am I doing wrong here? Everything I try returns `Nothing` at best. I can run `r ^. responseBody` in GHCi and return the raw JSON, but I cannot figure out how to get Aeson to decode this. ``` {-# LANGUAGE DeriveAnyClass #-} {-# LANGUAGE DeriveGeneric #-} {-# LANGUAGE OverloadedStrings #-} import Control.Lens import Data.Aeson import Data.Text import GHC.Generics import Network.Wreq data Listings = Listings { id :: Int , name :: Text , symbol :: Text , website_slug :: Text } deriving (FromJSON, Generic, Show) getListings :: IO (Maybe Listings) getListings = do r &lt;- get "https://api.coinmarketcap.com/v2/listings/" return $ decode $ r ^. responseBody ``` ``` Œª getListings Nothing it :: Maybe Listings (0.51 secs, 48,151,408 bytes) ```
&gt; static data-structures optimised for reads Not exactly static, but [my prototypical array-mapped trie implementation](https://github.com/sgraf812/amt) had better lookup performance than any other map implementation I benchmarked against (Map, IntMap, HashMap). It's probably not on par with vanilla arrays wrt. reads, but still has acceptable update performance. Check out `stack bench` if you are interested. Inserts are within a factor of 2-3 compared to IntMap, whereas lookups are about 30% faster (as in 70% of IntMap lookup time) and there seemingly is no slow down for bigger maps.
I looked to see if the Aeson documentation had an alternative to `decode` that returns an error message, and found [`eitherDecode`](https://hackage.haskell.org/package/aeson-1.4.0.0/docs/Data-Aeson.html#v:eitherDecode). This code yielded a useful error message for me (I'll let you see it for yourself), hope it helps for you: ``` {-# LANGUAGE DeriveAnyClass #-} {-# LANGUAGE DeriveGeneric #-} {-# LANGUAGE OverloadedStrings #-} module Main where import Control.Lens import Data.Aeson import Data.Text import GHC.Generics import Network.Wreq data Listings = Listings { id :: Int , name :: Text , symbol :: Text , website_slug :: Text } deriving (FromJSON, Generic, Show) getListings :: IO (Either String Listings) getListings = do r &lt;- get "https://api.coinmarketcap.com/v2/listings/" return $ eitherDecode $ r ^. responseBody main = do result &lt;- getListings case result of Left error -&gt; putStrLn error Right listings -&gt; putStrLn (show listings) ```
Thanks for the reply. I'm still a little lost, though. I'm guessing Haskell needs me to tell it to look in the "data" array of the JSON. Except it won't let me actually use the word "data" in a new data type declaration. I'm just confused how to circumvent this. I guess I can't use a Generic `FromJSON` instance here, but even when I had my own hand-written instance, it still returned `Nothing`. Here's the JSON (sample) if you haven't looked at it already: ``` { "data": [ { "id": 1, "name": "Bitcoin", "symbol": "BTC", "website_slug": "bitcoin" }, { "id": 2, "name": "Litecoin", "symbol": "LTC", "website_slug": "litecoin" }, { About 3,000 more objects... } ], "metadata": { "timestamp": 1530998150, "num_cryptocurrencies": 1620, "error": null } }
Thanks for posting the sample, I hadn't seen it. The problem is the Haskell type doesn't exactly match the JSON data structure. Sorry I don't have time to have a go at this myself right now, but your best bet is to write the \`FromJSON\` instance for the listings type yourself. There should be information on doing that in the Aeson documentation. Personally, I've found this is more robust than relying on \`deriving\` to do it for you anyway.
You can use `sequenceA` and `traverse` instead.
Figured it out, there were no MonadTime instance for HttpT and vice versa.
I appreciate any help you can offer. Thanks.
I think \`takeWhile (&lt; 2000000)\` will keep taking elements until one that is greater or equal than 2,000,000 is found (this will be bounded by the definition of \`primes\`). Also, they will be calculate since the value is needed to evaluate \`(&lt; 2000000)\`. Perhaps OP meant \`take 2000000 prime\`?
Since there's only 9 possibilities and we don't actually care about their order, a bitset (e.g. a 2-byte value with 0/1 in the 9 least-significant bits) would probably have better performance.
A flat matrix probably would help here but also the `zip [1..9]` part will destroy fusion anyway. I kind of wish there was a specialized function for this, like enumerateFrom :: (Num n) =&gt; n -&gt; [a] -&gt; [(n, a)] enumerateFrom n ls = L.build $ \c z -&gt; let step a acc = oneShot (\i -&gt; c (i, a) (acc (i+1))) in foldr step (pure z) ls n For instance test :: Int test = sum . map (uncurry (*)) $ zip [1..] [1..100] produces some amazingly awful core: $wgo $wgo = \ i# ls acc# -&gt; case ls of { [] -&gt; acc#; : y ys -&gt; case i# of wild1_Xr { __DEFAULT -&gt; case y of { I# y# -&gt; $wgo (+# i 1#) ys (+# acc# (*# i# y#)) }; 9223372036854775807# -&gt; case y of { I# y# -&gt; +# acc# (*# 9223372036854775807# y#) } } } test test = case $wgo 1# (eftInt 1# 100#) 0# of ww_s3d0 { __DEFAULT -&gt; I# ww_s3d0 } whereas test :: Int test = sum . map (uncurry (*)) $ enumerateFrom 1 [1..100] produces a nice loop $wgo $wgo = \ i# j# acc# -&gt; case i# of wild_Xq { __DEFAULT -&gt; $wgo (+# i# 1#) (+# j# 1#) (+# acc# (*# i j)); 100# -&gt; +# acc# (*# j# 100#) } test = case $wgo 1# 1# 0# of ww_s3bw { __DEFAULT -&gt; I# ww_s3bw } 
Modern GHC made Monad a subclass of Applicative, so you need to declare an `instance Applicative Tc` as well. This shouldn't be too awful - follow the types.
Okay so I finally managed to learn enough Haskell to do this. Here's a link to the repo if anyone is interested: https://github.com/sam46/Paskell I'm loosely using this grammar Any tips or tricks are welcome. Thanks http://courses.washington.edu/css448/zander/Project/grammar.pdf
I was hoping there would be some cool `vector` hacks in there.
I can't speak to the theoretical side of your comment, but FWIW I thought your comment had the right spirit behind it, especially the tailing comment. Maybe put that text at the top of your post in future similar instances?
pm'd
Wait for the next post :-)
warp lets you override the default exception handler in some settings field if I remember correctly (can't look it up right now), and the loggers are also customisable, so with these two things you should definitely be able to fix this. If you don't find a way I will give it a shot once I'm back on my computer, tomorrow.
I want to add that `typerep-map` not only uses array-based approach, but also implements cache-optimized binary search. And this is important part. After implementing binary search over Eytzinger array layout we noticed significant performance boost.
That sounds cool! We have an idea of another very efficient static data structure in mind. So if you upload your package on Hackage, we can implement benchmarks against your package as well! And uploading to Hackage will allow other users to use your package. If you really have fast lookups faster than `IntMap` then for me in all my cases it makes sense to use your data structure instead of `IntMap`.
Yes, please! I'd pay money for this. 
Yea I was thinking a 9-tuple of bools although yours would certainly be more space efficient albeit potentially clunky.
Is this code fast enough to let you generate new puzzles?
This code is not to generate puzzles. That'll require a different algorithm.
What would happen if you ran your algorithm on an empty grid?
&gt; The present paper embodies the latter choice, augmenting the popular Haskell compiler GHC with a plugin that converts standard Haskell code into categorical form to be instantiated in any of a variety of categories Is this basically the same as compiling into combinators (SKI etc), and then further evaluate them to different types that have instances implementing the combinators for them?
It'll throw an error.
It'll give you a solution. In fact, it'll give you the exact same solution every time because the code is deterministic.
This was one of the proposed uses of transient and co. I‚Äôd be curious about similar benchmarks on it as well. 
I'm pretty sure your library is a win, you just need to find places where the working set is small. Some random ideas in this area for things you might or might not want to explore: 1. A `wai` middleware that proxies incoming requests through a set of shared shared memory segments (one for each subprocess), and a single-threaded `wai` web server sitting in the (single-threaded) subprocesses. 2. The inverse - a `wai` middleware that proxies incoming requests to a single parent process (would be used for a subset of requests). 3. A `servant` plugin that can receive direct foreign pointers to the data structure (no deserialization). This would sit in the subprocess or parent process depending on how the server is setup. 4. Create a usable wrapper around `warp` for properly using [`SO_REUSEPORT`](https://github.com/jfischoff/reuse-port-example#readme) so the requests go directly to the subprocesses, so point 2 (and 3) would work - routing requests back to the parent process. 5. Write a wrapper to `warp`/`wai` to safely redeploy a web service with zero downtime, using `interprocess` for synchronization. 6. Generic "pre-GC" warning hook system and GC lifecycle system where subprocesses write into shared memory the probability that they will have a major GC soon. Could be lease-based (i.e. a process must write regularly or will be considered to be in GC). After hooks have run, do manual GC in subprocess. 7. Do master election between a group of processes based on major GC probability. 8. Write a library for manipulating queuing and routing in the linux kernel to stop routing of requests to a subprocess with high likelihood of getting into GC. 
Reminds me of the "Trash Day: Coordinating Garbage collection" paper. That one focused in jvm nodes.
\&gt; Now, I am curious if the cost of interprocess communication can be smaller than the overhead of the stop-the-world GC. I'm not sure how IPC would solve original case though, since they want to store a large dataset on GHC heap rather than offload them to in memory KV e.g. levelDB, etc. I guess they don't want to bring in serialization/deserialization overhead? If you split data into different processes, let's say based on consistent hashing, then the IPC serialization/deserialization become a new bottleneck just like in memory KV case. I'm quite skeptical why they don't use a in memory KV though, put some efforts on HA you can even get disk backup failover, etc.
I read the title as `instance Monad Problem` and it made think a lot :thinking:
Call yourself Monadroom
There's `setOnException` and `setOnExceptionResponse`. I think I need to construct a `Response`, which would mean `setOnExceptionResponse`; but the function passed to that is `SomeException -&gt; Response`, it doesn't get to know about the request. By constrast, `setOnException` takes a function `Maybe Request -&gt; SomeException -&gt; IO ()`, so it can do something with the path, but I don't think it can change the value sent to the logger. But I haven't looked into these in depth, so maybe I'm missing something. (It would also be an okay compromise to have the `setOnException` handler print the request path along with the error, if I can't get the path to the response logger.)
I've never been sure why people like list comprehensions when `do` notation exists.
Yes, thanks. My question is, why do the others not take the Applicative constraint instead of Monad since AMP? Is there any reason other than historical artifact? These functions are not class methods, so weakening the constraint to Applicative should not cause any code breakage? If there is somewhere it breaks, I‚Äôd like an example.
&gt; Na√Øve recursive descent parsers‚Äîwhich are basically LL(1)‚Äîcan't handle this, but they can resort to a classic trick: backtracking! Isn't backtracking just LL(k) for some k? I.e. basically LL with arbitrary lookahead. Doesn't really seem like a trick.
You could eventually tweak the logger to behave exactly the way you want it to, in the worst of cases.
This code calls `f` four times: {-# LANGUAGE ApplicativeDo #-} import Debug.Trace (trace) f x = trace "f" [0] main = print $ do x &lt;- [1, 2] y &lt;- [3, 4] z &lt;- f x return 5 I understand why this happens. But to someone who just wants to work with containers, it seems pretty wild. Is it possible to make do-notation work better for containers, calling each function once per input to that function, not once per whole state so far? Is there existing work on this?
How does `do` notation provide the same functionality as a list comprehension?
Same argument applies to `do` notation: pattern &lt;- expression -- vs. expression You don't know until you `try`.
[x*x | x &lt;- [1..], x &gt; 10] is the same as do x &lt;- [1...] return (x * x) Anything you can do with list comprehension can be done in terms of the monadic operations. There is even an extension called monad comprehensions which allows you to use list comprehension syntax for any monad. 
Because you have to understand monads to understand why do notation does the same thing as a list comprehension, and monads are notoriously hard to understand, despite their simplicity. All you need to understand list comprehensions is exposure to set builder notation in high school maths class.
I'm frustrated with using do-notation on containers: import Debug.Trace (trace) f () = trace "f" [1, 2] g () = trace "g" [3, 4] h x = trace "h" [5, 6] main = print $ do x &lt;- f () y &lt;- g () z &lt;- h x return 0 This calls `f` once, `g` twice, and `h` four times. With `ApplicativeDo` enabled, it calls `f` and `g` once, and`h` four times. (Another possibility is that it could call `f` once, and `g` and `h` twice.) I understand why this happens. But to anybody working with containers, it seems obvious that `f` should be called once, `g` should be called once, and `h` should be called as many times as there are elements in `f ()`. All information to make that happen is available at compile time. Has there been any work on this?
I doubt you could find a bound on the `k`.
The GHC parser has lots of hacks üòõ. For example, have you ever wondered how it parses fixities even though you can specify them in arbitrary places (e.g. inside a where clause)? It actually parses everything with the same fixity and precedence and then rebalances the trees in the Renamer (!).
I particularly like list comprehensions to partially match on a single constructor. I think it makes the code more readable than many other equivalent versions: ``` [a | Just a &lt;- listOfMaybes, a &gt;= 100] ``` Here I'm both filtering out Nothing and wrapped elements `&lt;100`
I don't like them. Introductory courses love to introduce them for some reason, where they do an excellent job of confusing students.
Pedantic correction: LL(k) for some k and LL(*) (arbitrary lookahead) are not the same thing.
I currently think not the logger; https://github.com/yesodweb/wai/blob/master/warp/Network/Wai/Handler/Warp/Run.hs looks like the logger doesn't get passed the original request if there was an error, but a dummy request. (See `sendErrorResponse`. `sendResponse` is responsible for calling the logger, see https://github.com/yesodweb/wai/blob/master/warp/Network/Wai/Handler/Warp/Response.hs.) So it looks like I'll probably need to work around this, but the workarounds exist.
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [yesodweb/wai/.../**Response.hs.** (master ‚Üí eb298a8)](https://github.com/yesodweb/wai/blob/eb298a8bafbe1934333188334160623f463f13d0/warp/Network/Wai/Handler/Warp/Response.hs.) * [yesodweb/wai/.../**Run.hs** (master ‚Üí eb298a8)](https://github.com/yesodweb/wai/blob/eb298a8bafbe1934333188334160623f463f13d0/warp/Network/Wai/Handler/Warp/Run.hs) ---- 
Sure, the "some k" would be determined by the specific stirng being parsed.
Oh cool, thanks for the explanation!
That is nice! I think you can do the same thing with `do` notation too: do { Just a &lt;- listOfMaybes; guard (a &gt;= 100); pure a }
This is really, really neat. In an application at my workplace, this would cut out some boilerplate and would be safer than what I currently do.
Oh, cool. I did not know you you also partially match with `do` as well. I'll put it to test today when I get some time
Yeah, and ideally this could perhaps be improved upstream by passing the original request to those functions. Probably a good task for a first time warp contributor, if anyone is interested. :-)
What does `pure a` do?
I don't get it.
Yeah, it's `MonadFail` and a bit of a Haskell wart waiting to be made into a gem.
It's the same as `return a`. In fact, [`return`](https://www.stackage.org/haddock/lts-12.0/base-4.11.1.0/Prelude.html#v:return) is more or less an alias for [`pure`](https://www.stackage.org/haddock/lts-12.0/base-4.11.1.0/Prelude.html#v:pure) these days. 
If you look at this example you'll see that `do` notation is almost the same as set builder notation. https://www.reddit.com/r/haskell/comments/8y8x1j/parsing_list_comprehensions_is_hard/e2901ol/
Sure, list comprehension is cool. But have you heard about SQL-like list comprehension in Haskell? ```haskell ghci&gt; :set -XTransformListComp ghci&gt; import Data.List ghci&gt; import GHC.Exts ghci&gt; :{ ghci| employees = [ ("Simon", "MS", 80) ghci| , ("Erik", "MS", 100) ghci| , ("Phil", "Ed", 40) ghci| , ("Gordon", "Ed", 45) ghci| , ("Paul", "Yale", 60) ] ghci| ghci| output = [ (the dept, sum salary) ghci| | (name, dept, salary) &lt;- employees ghci| , then group by dept using groupWith ghci| , then sortWith by (sum salary) ghci| , then take 5 ] ghci| :} ghci&gt; output [("Yale",60),("Ed",85),("MS",180)] ```
``` blocks are not supported on reddit. You have to prefix each line of your code block with 4 spaces IIRC.
[removed]
You could bound it by the information limit of the universe :^)
It works for me on new Reddit design.
It doesn't work on mobile, ironically. But the new design works fine with it ü§∑‚Äç‚ôÄÔ∏è I use the old design on the desktop because it plays better with vim browser extensions
I am still new to haskell, but I would love for there to be a book like this for when I get to this point!
Oh I see. The new design is super slow for me and feels pretty bloated so I use old.reddit.com instead.
Ironically, this comment works on old reddit, but not on new.
Thanks for suggesting `typeRep`. I ended up using [a phantom type wrapper](https://github.com/jprider63/LMonad-Yesod/blob/dev.jp/src/PhantomType.hs#L10) around `Type` and writing a function that parses one from a string. I'll try switching to `typeRep` in the future. 
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [jprider63/LMonad-Yesod/.../**PhantomType.hs#L10** (dev.jp ‚Üí 80fec2f)](https://github.com/jprider63/LMonad-Yesod/blob/80fec2fa90af506e6666921e2631e7b6f31db6dc/src/PhantomType.hs#L10) ---- [^delete](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply e2997gs.)
https://stackoverflow.com/questions/24281304/vim-input-is-not-from-a-terminal
That's not computer science, that's engineering
I was able to get by with the following import System.Process main = spawnProcess "vim" \["test"\] &gt;&gt;= waitForProcess
Can `singletons` or something help with the boilerplate of demoting `Data.Aeson.Options`?
Thanks for this update. Some of this is a little higher-level than my current understanding as I haven't managed to write anything that targets assembly, but I'll keep it as a reference for when I do.
`ApplicativeDo` has a weird corner that a hypothetical `ApplicativeComprehensions` would not: the treatment of `pure` and `return`.
Basically yes, but there is at least one pitfalls: even with `singletons` package, there is no obvious way to promote *arbitrary* functions of type `String -&gt; String`. I think there is not so much functions used for field-label/constructor-tag modifier, so one ad-hoc solution is to provide *type function universe* for a prescribed family of specific string manipulation functions. Perhaps, `reflect` package or so could help here to add user-defined custom string functions, but I'm not sure.
Thank you! This worked
Lamping's algorithm is an optimal lambda calculus evaluator, where "optimal" in this context means that it will always use the fewest number of beta-reductions possible. However, that does not necessarily mean that it is always the fastest lambda calculus algorithm because it does other work (often called "bookkeeping") that in certain cases can cause it to run slower. There are certain subsets of lambda calculus where the bookkeeping work is not necessary. Specifically, any lambda expression that can be type-checked using a type system based on elementary affine logic doesn't require these bookkeeping steps and if that is the case then this algorithm really is optimal in every sense. However, restricting yourself to lambda expressions that are typeable in elementary affine logic gives you less flexibility in how you write your programs. Also, to compound the problem, I'm not aware of an actual implementation of a type checker for elementary affine logic. The algorithm is described in a paper but I do not believe it has been implemented. The version of "Lamping's algorithm" minus the bookkeeping steps is know as "Lamping's abstract algorithm", which is what the post describes.
"The optimal implementation of functional programming languages" is the standard book on this subject
Alternatively this could be formulated as a fold over `b-&gt;b`. Or `foldr :: (a -&gt; Endo b -&gt; Endo b) -&gt; Endo b -&gt; [a] -&gt; Endo b`. Interestingly CallArity analysis (or an explicit oneShot) can allow eta expansion so we don't actually build up the function on the heap! That's basically how foldl-via-foldr works. I also was surprised by the mapAccum's in base when trying to implement a fusing enumerate. Annoyingly enough the mapAccum definitions in base destroy fusion, though. They aren't specialized for list so they can't be wrapped with build. I ended up with L.build $ \c z -&gt; let step a acc = oneShot (\i -&gt; c (i, a) (acc (i+1))) in foldr step (const z) ls n
&gt; expressions can't nest inside patterns They can with `-XViewPatterns`!
Aha! That's why I'm in favour of `do ... in ...` syntax. I have yet to convince SPJ of the beneft of this ...
What's `do...in...`?
See vimhl.hs from https://github.com/lyokha/vim-publish-helper/blob/master/pandoc/haskell/vimhl.hs that calls vim from command line. On line 53 there is a comment about launching vim from not-a-terminal. On lines 53-61 vim gets launched. The trick itself is on line 53.
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [lyokha/vim-publish-helper/.../**vimhl.hs** (master ‚Üí 0d92f14)](https://github.com/lyokha/vim-publish-helper/blob/0d92f14845f347e933205dd30e329290bfee47f1/pandoc/haskell/vimhl.hs) ---- [^delete](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply e29l53o.)
It's a version of `do` notation where you could use an explicit `in` at the end of your block. What we currently write as do ... return foo would be written as do ... in foo
Let me answer the deeper question. One way of defining a monad is defining 3 operations fmap :: (a-&gt;b) -&gt; F a -&gt; F b pure :: a -&gt; F a join :: F (F a) -&gt; F a fmap only = functor, fmap + pure = applicative functor, fmap + pure + join = monad. 
&gt; fmap + pure = applicative functor You also need `ap : F (a -&gt; b) -&gt; F a -&gt; F b` for a functor to be applicative.
&gt; I just set up the Gold linker on my systems and my Haskell builds are much faster. /u/snoyberg you should try LLD. I've heard it's even like 2-3x faster.
I remember when I learned how the GHC parser handled operator precedence and fixity. I didn't think it was a hack, I thought it was elegant! :D
Kudos for finding that gem from the distant past!
As someone that's just starting to get into type level Haskell (as a result of those first chapters of the Types book)... this is incredibly cool, learned a lot reading this comment. 
I haven't been to the NYC location yet, but considering I am a member of both the haskell community and invisible college, I figured it might be helpful to mention that the invisible college has a lot of great creative and intelligent people :)
I don't see `DerivingVia` in the release notes: https://downloads.haskell.org/~ghc/master/users-guide/8.6.1-notes.html Is the linked paper the best source for the implemented version? (c.f. stuff like the labels extension which changed from the paper, iirc).
In Scala with shapeless, I know you can have singletons or arbitrary functions (for static functions). You just do val f = (x : Int) =&gt; x + 1 // f.type is now the Singleton type of this function needsSingleton[f.type] I think in Haskell you could do something like this: class Witness w ty | w -&gt; ty where witness :: Proxy w -&gt; ty Then you would have to associate arbitrary types with functions which isn‚Äôt as nice, but I wonder if you could write some TH within which you define a function normally and get a phantom + `Witness` instance defined for free?
Thanks for the correction. Yeah that was dumb of me you need bind for pure =&gt; ap. 
My initial reaction was "wow, that's neat/amazing/hacky/eww" so I partly empathize with you. I feel that it is good in a bad way, if that makes any sense.
I'd love to see this syntax added to GHC. It's concise and elegant and makes more sense with ApplicativeDo
Honorary featured happening: Simon Peyton Jones asks, [What is your favourite Haskell "aha" moment?](https://mail.haskell.org/pipermail/haskell-cafe/2018-July/129443.html), with tons of great discussion following.
you're missing zip :: F a -&gt; F b -&gt; F (a, b) fmap + pure + zip = applicative functor fmap + pure + zip + join = monad
Woohoo! Glad the idea is getting some support.
I got the information about `DerivingVia` from [GHC's trac](https://ghc.haskell.org/trac/ghc/wiki/Status/GHC-8.6.1). I'm neither of a maintainer or author of the paper, so I can't really say anything correct about this, but it seems (at least in GHC 8.6.1 Alpha 1) that syntax and functionality is not so different than in the original paper.
In that case, I think list comprehension has three advantages, it makes it clear that you are constructing a list, it fits on one line, and it has the same syntax as set definitions usually have in math.
I believe I was the first [to suggest this syntax](https://github.com/purescript/purescript/issues/2435#issuecomment-268023442), AFAIK, so I don't really represent growing support :P Not sure I agree with you on the indentation though. I *think* I would prefer \`in\` to be indented with the statements in the block, not with the \`do\` itself. Not sure though...
but sequenceA and traverse are exactly that. they are well known and used frequently. What is to be gained from changing the type of mapM to use applicative instead of just using traverse?
Ah, thanks for suggesting it!
Oh, I didn't know much about Scala, but it seems the cool feature! It would be nice if `singletons` also supports such functionalities, but I think it is not so easy, because the current GHC provides only limited operations (such as comparison and concatenation) on `Symbol`s and we need to write some compiler plugin to adjoin new symbol operations. And, as far as I know, `singletons` adopts `Text`, rather than `String (= [Char])`, for the demoted representation of `Symbol` and it also makes it hard to promote Text-related operations up to the type-level. On the other hand, the latest edition of my code on gist uses `Reifies` class from `reflection` package, which is much similar to your `Witness` class. And, yes, I agree with you that TH hack can reduce boilerplate somehow.
Hehe, heya, fancy seeing you here :) Shows like this are a regular occurrence. So if/when you do come by, check in with myself or cryptogoth to see what's going on! 
Heh, bit of a name clash with [https://github.com/FormationAI/hazel](https://github.com/FormationAI/hazel) :D
Some statements seem very bold: &gt; ... For this reason, such implementations tend to use considerable memory. In contrast, the implementations in this paper (Sections 12 and 13) are free of mutation and can easily free (reuse) memory as they run, keeping memory use low. If the above is general enough, it could, for example, have enormous consequence on recurrent neural networks. Is the method available for testing somewhere? 
Happy to answer any questions about how this came about, and how it has worked out for us.
You know, I saw that and probably should've linked to it, but I hate reading mailing list threads. Is there a better interface anywhere? 
Jens Petersen is offering a build of 8.4.3: https://mail.haskell.org/pipermail/haskell-cafe/2018-May/129210.html
What specifically made you choose Elm over GHCJS ([reflex](http://docs.reflex-frp.org/en/latest/), [obelisk](https://github.com/obsidiansystems/obelisk), [miso](https://haskell-miso.org/), etc.), when the later allows you to share code between client and server (arguably an important benefit)?
Thanks for this writeup. I was recently hired by a startup as a contractor to build a MVP. Shortly after I was offered to stay full time to lead the project and build it out into a full blown platform. The MVP was done in PHP, but I would love to use Haskell for building the platform. The complexity of the project overwhelmingly comes from the business domain and thus modelling this domain is the primary challenge for which Haskell would be a great fit. Here's my problem: I'm just a hobby Haskeller. I've been toying around with it for a couple of years and I use ghci daily to think through and sanity check ideas that i then implement in some other language as well as occasionally writing small throwaway exploratory code. However I lack actual commercial experience. Now I would love to build this product using Haskell and build a team around it, but I'm fearful of diving into the unknown using a technology that i have full faith in but no battle scars from using it commercially. How do companies get started with Haskell? Is having someone with deep expertise a prerequisite?
Elm is *much* simpler for onboarding developers with no pure FP experience, plus there's one standard way of doing things. Yes, it's strictly less powerful, but I feel like it has been a successful choice for us. If I were to build a new app alone or with Haskell-experienced people, I'd seriously consider ghcjs or purescript, but I suspect I'd still end up with Elm.
Oh I see how that leads to an applicative! Nice. Is there a name for fmap + pure? 
Elm is in some ways an ML-like DSL more than a true language.
But aren't you already using Haskell for backend ?
Yes, but we have some team members who focus more on the front-end. In reality, we've had a bunch of cross-over, and the people who can Elm can also Haskell. The big benefit IMO is really the just-one-straightforward-way-to-do-things that Elm offers. Only rarely have we been frustrated by the language compared to Haskell. It's so superior to Javascript for our purposes that it's all a question of degree.
If you have a sufficiently recent version of `nixpkgs` you can do: $ cabal2nix --shell https://github.com/commercialhaskell/stack.git &gt; stack.nix $ nix-build stack.nix If you have a local checkout of `stack` then instead do: $ cd /path/to/stack $ cabal2nix . --shell &gt; shell.nix $ nix-shell --run 'cabal configure' ... and then use `cabal build` and `cabal test` like normal. See also: https://nixos.org/nixpkgs/manual/#users-guide-to-the-haskell-infrastructure
I hope you manage to find work with Haskell. I'm confident the space will grow rapidly, and will continue to agitate for that personally. In the case of this specific project, I was a long-time Haskell enthusiast who also has 20 years experience in the industry building systems and teams, so I was given quite free rein to make choices. Indeed, it was my primary remit. But I came to this group with a fellow senior Haskell/Elm enthusiast, and some pre-existing group members were already interested in pure FP, even if they had no prior experience. What happened was that a couple of us very quickly wrote some proofs of concept and then just rolled with it to see if the team would take to it. It did, slowly at first, and then enthusiastically. Now many of those colleagues have been ruined for non-FP languages (sorry folks!). This is a start-up environment, providing a SaaS service, so our trade-offs reflect that. These are not necessarily the technologies I would choose if I were contracting for a company with only Java, C# or Javascript experience, because you have to consider the whole team in context.
I built a large user-facing GHCJS app for my company previously. At the time, it was being more actively developed, so I thought it might be worth the risk. But the fact is, that it's just not sufficiently maintained and improved to trust your business to it. I contributed a fix or two that were fairly important for my company's needs, and it took a while to get the patches merged. Add to that the difficulty surrounding debugging the code in production, large JS bundle output, slow Template Haskell... it's not worth it unless you've got significant enough resources as a company to invest heavily in fixing these things yourself. As a small startup, you just don't have that sort of time or money.
Could you please elaborate on the back-end a bit? Did you use a particular framework (e.g. yesod)? Also, did lazy evaluation cause your team any headaches?
Re. the back-end, we use a PostgreSQL database (with PostGIS), and sit a Servant app on top of that, which acts as a pure JSON REST API server. We have additional components which run separately and interact with AWS services. Lazy evaluation didn't exactly cause headaches. The only case where we had to reason about it was in parsing enormous JSON files without blowing out memory. The naive solution didn't magically work - and it wouldn't have worked in any other language. We actively used Haskell's laziness in this case to process those huge files in low, constant memory. Thinking about all of that was hard, but the underlying problem was also hard, so that seems fair.
Hey, purcell's team mate here - we used [servant](http://hackage.haskell.org/package/servant) for our API framework along with [postgresql-transactional](http://hackage.haskell.org/package/postgresql-transactional) for our database access. Our only real bit of lazy pain was in our JSON parsing code. Since we had to ingest massive JSON files (often in the order of several gigabytes) we had to do some extra work to parse it in a streaming fashion, occasionally we'd hold onto a reference for a bit too long and had to figure out how to deal with that. Overall I'd say we probably spent an order of magnitude less time dealing with the odd laziness edge case than we would have spend dealing with standard pain points in a more mainstream language. I'd say working around compilation times are much more of an issue than laziness for anyone with at least a little experience with it.
Glad you didn‚Äôt hit any major snags. Your write-up is encouraging and inspiring. Has performance been in line with what you were anticipating?
I think you're right about the indentation. Lots of people (like myself) tend to write foo = blah blah blah $ do x &lt;- ... ...
This is such a good post!
Thanks for the write up. I was with wondering how your servant web app is performing production. What level of traffic does it handle and what are pause times during GC? What sort of performance problems did you have to solve along the way to your first release?
Yes, absolutely - it has been excellent. The binaries we get are small, fast, economical with memory, and run very reliably.
I can't really go into traffic and performance details, but our baseline for comparisons these days is Ruby on Rails, which this crushes. No web performance problems to solve - see my other replies for some other optimisation we needed to do.
For great good?
Do you overlap with the industries Remix serves?
I could never dare using GHCJS exclusively to build all of the front-end, but I think I leave some room to the prospect of using GHCJS to share some business logic between the back and the front ends. Do you think the issues you faced would hurt even with this mild use?
fmap + pure is known as pointed.
What would it take to get it to generate a list of all possible solutions for a given board, rather than just a single solution?
If simplicity is a goal, then I would urge you to look at my Concur UI framework. ["Simpler than Elm, and yet more powerful"](https://github.com/ajnsit/concur-documentation/blob/master/README.md) :) . It has [Haskell](https://github.com/ajnsit/concur) and [Purescript](https://github.com/ajnsit/purescript-concur) implementations, and allows you to use React components seamlessly (https://ajnsit.github.io/concur/examples/sortable-tree-example.jsexe/index.html).
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [ajnsit/concur-documentation/.../**README.md** (master ‚Üí 382a1c8)](https://github.com/ajnsit/concur-documentation/blob/382a1c82729d7dcd627bebb8856742a013efbf29/README.md) ---- 
love :: FP c =&gt; Haskell x -&gt; Elixir y -&gt; IO (AwesomeCode) From Padawan to Acolyte I see. Welcome to the dark-side. Mwahahahahahahah!
Welcome! If we can be of assistance then don't hesitate to ask. 
Your journey into the rabbit hole begins!
Thank you very much for this blog post. My question will be more on the "hiring" part. Do you find enough developer interested in Haskell to join the project? What is the organization around the skill improvement around Haskell?
[Phrasing!](http://cdn1.thecomeback.com/wp-content/uploads/sites/94/2017/06/Archer-Phrasing.jpg)
If it‚Äôs an internal thing then maybe not, but I don‚Äôt see the tradeoffs really working in your favor regardless. If you want to do it for the novelty, that‚Äôs fine. It‚Äôs a fun piece of technology to play around with after all.
Rabbit hole? What do you mean? 
Not in scope: type constructor or class `Elixir'. 
Not to mention the ambiguous type.
Type Constructor
Which meetup did you attend and what did you learn, pray tell.
That's cool. Thanks. I guess it's quite easy to go from this code to code that will generate randomish problems that have unique solutions.
Sure, you can type `allSubsets = (filterM :: _) (pure [True, False])` into GHCi. &lt;interactive&gt;:12:26: error: ‚Ä¢ Found type wildcard ‚Äò_‚Äô standing for ‚Äò(a1 -&gt; [Bool]) -&gt; [a1] -&gt; [[a1]]‚Äô Where: ‚Äòa1‚Äô is a rigid type variable bound by the inferred type of &lt;expression&gt; :: (a1 -&gt; [Bool]) -&gt; [a1] -&gt; [[a1]] at &lt;interactive&gt;:12:26 To use the inferred type, enable PartialTypeSignatures ‚Ä¢ In an expression type signature: _ In the expression: filterM :: _ In the expression: (filterM :: _) (pure [True, False]) ‚Ä¢ Relevant bindings include allSubsets :: [a] -&gt; [[a]] (bound at &lt;interactive&gt;:12:1)
So a distributed runtime is easier to achieve than a parallel garbage collector? :thoink:
Do a breadth-first search instead of a depth-first search as done here. Accumulate all the solutions instead of stopping at the first one.
Just that Haskell (like the rabbit hole) is hard to escape from - because it is so much better than mainstream languages. Which is a blessing and a curse: using Haskell is a pleasure, but it has totally dissatisfied me with the current state of the industry/languages used.
It's a cultural reference. Cf the book 'Alice in Wonderland' or the film 'The Matrix'. A rabbit hole is hardly noticeable in the landscape outside the hole, but inside it might open to whole new world.
Whoops, meant to write "I wrote a thing"... whomp! Anyway I wrote about a step-by-step way of implementing Functor and Applicative instances for Compose, and hopefully gave some intuition around it :)
I don't know what you mean, I'm pretty turned on by haskell.
Somewhat, maybe. Looks like there's a little overlap, but we're not trying to do what Remix are doing.
I know a bunch of smart people (even just here in little Wellington, New Zealand) who would leap at the chance to work with these technologies, so I'm not super worried. We haven't been hiring for a while. As a small team, skill development has mostly been a matter of teaching each other as we learn new things.
Very often when I'm trying to do type-level programming involving integers I end up facing a compiler error where GHC cannot deduce some constraint related to sum commutativity or associativity. I feel like proving those properties to the compiler might not be very difficult, but I never know how to do it. What should I look into if I want to solve that kind of problems?
Well the work is put on the developer who chooses when to keep data local to one GC and when to copy/share/manually manage data. So it's more about moving responsibility onto the developer than making a distributed runtime.
Thanks for your answer. I feel that if I choose to go down the Haskell road on this project, which I'd love to do, then I'll need to find someone to kickstart me and my team on the journey. I have ~12 years of industry experience and has worked on and architected large applications, but only used Haskell for fun. I have confidence in my general expertise but not in my Haskell. Re team, code ownership and responsibility - I would only do this, ie. choose Haskell, if I decide to stick around at my current place leading the project.
What is the bundle size story with GHCJS ?
Usually companies start with Haskell when they have some Haskell expert in company. Or they have enough money to pay different consulting companies (but usually this is not the case, because for company it's much easier to take existing popular technology and start working on product ASAP instead of investing time and money into developers' education). Luckily for you, I'm a member of Kowainik organization. And we can offer you free Haskell consulting! Organization is very small, but don't worry, we have members with 3 years of experience in teaching Haskell and using Haskell in commercial development. You can check some of our open-source projects: * https://github.com/kowainik Don't worry, we also have big real-world projects with Servant, SQL, protocol buffers and other fun stuff, but they are private. I'm thinking about something like: answering your small questions in Telegram/Slack/whatever, 1 hour or 1 hour and half call weekly/bi-weekly about architecture design, suggesting good tutorials and blog posts or even write guidelines and code review of course. ### What's good for you in this offer It's free. And we are not noobs. ### What's good for us in this offer If your project succeeds, we will have a case of successful consulting and we will become more popular.
`Functor` and `Applicative` instances for `Compose` are great! But personally I really like `Foldable` instance for `Compose`. Because it also explains why `Foldable` instance for tuple is useful: ``` ghci&gt; sum $ Compose [("Foo", 3), ("Bar", 5)] 8 ```
If you're interested in learning the language, I definitely recommend [Learn You a Haskell for Great Good!](http://learnyouahaskell.com/)
Big thanks for this - helps the rest of us know we're not alone : ) and there is hope for our industry yet!
Welcome to the ~~cult~~ club.
The compiler already does what you want if you enable optimizations! With O0 you get f g h h g h h [0,0,0,0,0,0,0,0] with O1 however f g h [0,0,0,0,0,0,0,0] 
Thanks for the write-up, Steve. Encouraging to see Haskell in particular fitting so good in your work flow.
Here is also information on ghc8.6.1-alpha1: https://github.com/ghc/ghc/blob/ghc-8.6/docs/users_guide/glasgow_exts.rst#L5194 https://github.com/ghc-proposals/ghc-proposals/blob/master/proposals/0023-deriving-via.rst 
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [ghc-proposals/ghc-proposals/.../**0023-deriving-via.rst** (master ‚Üí b3c3dba)](https://github.com/ghc-proposals/ghc-proposals/blob/b3c3dbab7f67fdccc90a5c466ffaf298b58458ec/proposals/0023-deriving-via.rst) * [ghc/ghc/.../**glasgow_exts.rst#L5194** (ghc-8.6 ‚Üí c0323d9)](https://github.com/ghc/ghc/blob/c0323d979d3676f919d6d02aecad7a8bfdcb8b8d/docs/users_guide/glasgow_exts.rst#L5194) ---- [^delete](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply e2bcizy.)
Great article! The community needs more experience reports like this.
Weird to cite The Matrix when they were making a reference to Alice's Adventures in Wonderland anyway.
&gt; I still don't get on how that nix config is different from a dockerfile based on alpine. You probably have to detail the question. A dockerfile based on Alpine doing what? * Just copying the files from the local system into the image? This would not achieve what the nix docker build does (copying all transitive dependencies into the image, all the way down to glibc). * Running `stack` inside the Alpine image? That would likely have you end up with a different build result (e.g. things being linked against `musl` instead of `glibc`). Also Alpine support for latest GHC has been a bit [problematic](https://github.com/commercialhaskell/stack/issues/2387) in the last half year.
AWESOME
Great question. I feel your pain, and I don't know of any good existing solution.
There's a plugin for that: https://hackage.haskell.org/package/ghc-typelits-natnormalise It can also be axiomatized like in [constraints](https://hackage.haskell.org/package/constraints-0.10.1/docs/Data-Constraint-Nat.html). Another potentially useful package is https://hackage.haskell.org/package/singleton-typelits which defines induction for typenats. There is no way to do implement this safely within the confines of everyday GHC Haskell (the interfaces should be safe though). 
I successfully generated a \`stack.nix\` via your first command; however, I'd like to be able to stick a link to this \`stack.nix\` into my \`configuration.nix\` as opposed to using \`nix-build\`. Do you know how to do this? I tried putting \`(callPackage /path/to/stack.nix { })\` in my \`environment.systemPackages\`, but that didn't work.
`Q` is "the metaprogramming monad", so `Q (Q a)` is certainly a thing (metaprogram that produces a metaprogram that produces an `a`). `join` on `Q` is merely the act of flattening two phases of metaprogramming into one where do the outer phase, then the generated inner phase, in sequence.
Random questions: * hspec or tasty? * stack or nix? do you use any tools like buck? * CI - self-hosted or cloud? which system/vendor? * testing - how many test suites (unit, integration, etc) do you have and what level of mocking/stubbing occurs in each test suite? * route tests - homegrown, cloud service, or other? * did you pick postgresql-transactional because you didn't want any higher level abstractions to get in your way?
With Parsec or any other monadic parsing combinator library CLAUSE ::= EXPR | PAT "&lt;-" EXPR can be parsed with no backtracking: clause = expr &gt;&gt;= (\e-&gt; do operator "&lt;-" p &lt;- expressionToPattern e PatternAssignment p &lt;$&gt; expr &lt;|&gt; pure e) If you abhor such tricks, I'm going to shamelessly suggest [grammatical-parsers](http://hackage.haskell.org/package/grammatical-parsers). Either a memoizing parser or the left-recursive one will avoid full backtracking. 
Is this not precisely what is described in the blog post? &gt; GHC's parser uses a hack: it parses patterns as expressions, and only later checks that the expression it parsed was a valid pattern
Las Vegas Meeup, the host talked about the Errors Library [https://www.meetup.com/las-vegas-functional-programming/events/252178490/](https://www.meetup.com/las-vegas-functional-programming/events/252178490/)
Thanks!
nice , but I hope some people would not read it because I think you gave some solutions to some challenges of the haskell book 
To clarify, /u/want_to_want, this is probably because of let-floating. i.e. if you have something of the form \`\\x -&gt; ... $ \\y -&gt; ... $ h x\`, GHC knows it can float the \`h x\` out above the \`y\` lambda: \`\\x -&gt; let hx = h x in ... $ \\y -&gt; ... hx\`
I wonder if it had something to do with the Applicative Monad Proposal? Maybe they feared the old instances of Monad that didn't have Applicative instances because there previously was no superclass constraint on Monad. Calls to mapM with such Monad instances would indeed break then. But I *thought* that the Applicative Monad Proposal landed at the same time as Traversable...
It is a hack, granted, but the lack of the code snippet in the blog post could make it seem worse than it actually is. Even hacks can be terse in Haskell! 
Now there is: [https://github.com/MaiaVictor/formality](https://github.com/MaiaVictor/formality)
I'm constantly frustrated now when writing in anything other than Haskell. I had to write API endpoints in Python yesterday. Took ages, very verbose. I get no type safety for all the time that it takes. What's the point really I kept asking myself
Thanks for answering. It wasn't a technical criticism! It was more about how I felt that in a community-driven environment it's very important to encourage and motivate individuals to contribute. It also wasn't meant to be a personal attack! I am a big fan of your work üôÇ I see a lot of communities struggle with this, even bigger ones (scala comes to my mind)
Cabal
There are SWE's in Vegas? I thought it was just where we go for "conferences".
Wow! Thank you! I only ran this on repl.it and thought that's just the way things are. Haskell continues to pleasantly surprise :-)
 I believe there is an efficiency consideration (i.e., the possibility of inserting inadvertant performance bugs). From [ApplicativeDo](https://ghc.haskell.org/trac/ghc/wiki/ApplicativeDo): "Some Monads have the property that Applicative bind is more efficient than Monad bind. Sometimes this is *really important*, such as when the Applicative bind is concurrent whereas the Monad bind is sequential." So an engineer might inadvertently introduce a performance bug by (unnecessarily) forcing a monadic bind. As far as I can tell, you should never be use `mapM` or `sequence` in new code post-AMP (would love to see a counter-example).
I did find this thread on the mailing lists: [mapM /= traverse?](https://mail.haskell.org/pipermail/libraries/2015-May/025708.html).
Or "Haskell From First Principals"
&gt;We were pretty paranoid about introducing space or time regressions and didn't have a proof that we wouldn't introduce them by changing something there, so we left it alone. --- &gt;We managed to show that the old counter-example of a mapM that works where traverse that would blow the stack isn't an issue since [https://ghc.haskell.org/trac/ghc/ticket/8189](https://ghc.haskell.org/trac/ghc/ticket/8189) was resolved. &gt; &gt;Consequently, we're looking at removing mapM entirely from the class and just making it a top level definition. &gt; &gt;To do that we'd need to deprecate redefinition of the method in instances for a version or two. This would need a new form of deprecation, where you deprecate redefinition but not use of a member of a class. (I think Herbert filed an issue to create it, but I can't find it off hand.) &gt; &gt;Once we can make that transition, then the constraints on mapM would relax to the same as those for traverse. That would fix both the constraints and the implementation going forward for everything, but we should probably handle this particular case first or you won't see any benefit for a couple of years. \- Edward Kmett So it looks like changing the constraint is desirable, but we can't because `mapM` came originally as a class method of `Traversable` with a `Monad` constraint. Since it started with that constraint, relaxing it would be a breaking change, since instance may be relying on `&gt;&gt;=` specifically.
 Œª&gt; (+1) &lt;$&gt; Compose [Just 1, Just 2, Nothing] [Just 2, Just 3, Nothing] Should the result be Compose [Just 2, Just 3, Nothing]
Ya, thanks! I'll edit :)
Are the meet up groups too advanced for Haskell beginners? I'm pretty competent in other languages and have a strong background in math but there are a few things about Haskell that confuse me. I'm currently learning it on my own through a book. 
Subtly
Forgive me, but you mentioned that persistent supports multiple schemas just fine, but then start taking about databases. A database and a schema are separate concepts. In MSSQL and Postgres, a schema is a module of tables within the database. I'm trying to keep the language precise, but does Persistent officially support schema identifiers within the database? I tried to go through various source code. The relevant method that escapes the table name when querying, for example, is connEscapeName conn $ entityDB t where t is the entity definition. And I'm trying to dig down, but I'm guessing that the schema name is never set in the SqlBackend definition (the variable conn :: SqlBackend). So Postgres' default schema 'public' is assumed and SQL Server's default schema 'dbo' is assumed. Would you be able to write an example where SQL Server's default schema is replaced by 'sys' or Postgres' default schema is replaced by 'information\_schemata' in Persistent? 
WAAAH
I run a Haskell meetup group and we welcome people of all skill levels! I think most other groups are similar. I would encourage you to go if there's one nearby! 
Hi, do you have a project in mind, that uses this technique? I get the idea but would like to see an example put into practice. Thanks.
My apologies! I wasn't aware of that use of the term -- I've only used the term schema for the tables that an application talks to, and I wasn't aware of the non-default schemas in other databases.
Thanks, I'll take your advice as I believe I've heard of one in my area (Philadelphia). I was nervous that I'd walk into a room full of people with Phd's and that I'd have no clue what they were talking about. Thanks again!
Great article. I have never managed to understand Applicative before. I always end up "looking into it later", and then I forget :P
Fascinating walkthrough of your thought process for the creation of such a magnificent library. Thank you!
If you have that much experience, and confidence in your general expertise, then I'm pretty certain Haskell would work out fine for you. But yes, of course, there's a responsibility to make sure it works out for the team and business in the long term, which often means sticking around.
* `hspec` _and_ `tasty` * `stack`, then deployment via Docker, not because it's necessary for the Haskell parts, but because other parts of our stack benefit from its encapsulation (_cough_ Rails) * CI: we use Travis because it's convenient and off-premises, but it's been frustrating: it sucks for Haskell because the caching is slow. Nonetheless, it builds our deployment Docker images nicely, and it's easy to configure. We haven't had time (or, perhaps, sufficient annoyance) to set up a better alternative, like Circle or Concourse. * Bunch of unit and integration tests at different levels. Not mocking or stubbing, for the most part. * Route tests: unsure what you mean. * `postgresql-transactional` (and `-simple`) because we lean very heavily on PostgreSQL, and it's better then IMO to be close to the queries. Offloading work to PostgreSQL means as much of our processing as possible is co-located with the data, and therefore amazingly fast.
In that case you might want to refer to my guide on using Haskell with Nix, which covers the more general solution: https://github.com/Gabriel439/haskell-nix
Yes indeed, it's an exciting time! I fully expect to build more and more software in future with these tools.
Thanks. I hope to find more time in which to write up some of the details.
Thank you so much for this article. I recently started reading about functor, applicative, and monad. Your writing really helps reinforce my understanding. I agree that most material on these concepts appears too abstract and it was really refreshing to see you gradually transform a simple example into the official definitions. This line was especially enlightening for me: &gt; But wait a second, can a Maybe type contain a function? As I read it, I realized that I have seen this signature many times from previous readings. But the emphasis was usually on curried functions or partial application and I never formulated what I was seeing as clear as how you explained. A small typo that I noticed: one instance of `mapMaybe` became `mayMaybe`.
One interesting twist would be to upgrade the compact region support we added to GHC to allow sharing those regions between multiple GHC processes. For example, each CNF could keep a coarse reference count for the number of GHC processes using it / mapping those pages. 
Interesting. Hspec and tasty!! You have to at least pick one as your top level organizer (:. I think you can only use use hspec inside of tasty and not vice versa. I don't miss having to investigate why bundle was so slow, or having to order my dockerfile correctly to minimize cache misses. Your use popular tools for low value portions approach reminds me of how Sefaira mixed Rails and Scala. I debated converting from Jenkins to Travis in the past, but went towards reading about Hydra for a while, and I currently don't have a go to system I would use. Route tests - curl scripts/runscope/etc for api
You will sometimes (: , but they will be happy to have someone new to talk about their favorite language with
Yep, we use `tasty-discover`, and then write (mostly) `hspec` tests.
Very interesting. What do you feel is worse in concur vs elm?
Is it really principals, or rather principles? I mean learning from principals sounds great, I'm just not sure they are available.
Thanks for reading.
Haha that would be much better!
Interesring indeed! At first, I wanted to implement shared MVar using compact regions (and just copy a serialized region to shared memory), but ASLR issues scared me off.
Loving this so far. /u/isovector what's the best way to support / help you?
It's true that implementing `(a -&gt; b -&gt; c) -&gt; f a -&gt; f b -&gt; f c` and higher arities is the motivation for `Applicative`. But my brain revolts at the idea that this requires putting functions in containers. After all, something like `Set` allows this functionality as well - you can write code to combine two sets of integers into a set of their sums - but it can't use a set of functions as an intermediate step, because functions aren't `Ord`. To define constrained versions of `liftA2`, `liftA3` etc that would work with `Set`, we could use intermediate containers of tuples instead of containers of functions. Something like [this](https://en.wikibooks.org/wiki/Haskell/Applicative_functors#The_monoidal_presentation).
just change `www` to `old`, as in: https://www.reddit.com/r/haskell/comments/8y8x1j/parsing_list_comprehensions_is_hard/ to https://old.reddit.com/r/haskell/comments/8y8x1j/parsing_list_comprehensions_is_hard/
Another nice aspect of `Compose` is that it is enough for the outer functor to be alternative for the composition to be alternative: (Alternative f, Applicative g) =&gt; Alternative (Compose f g)Source This can be useful for sprucing up parsers with extra layers of effects.
Thanks for the kind words! I've set up [a patreon](https://www.patreon.com/isovector) if you want to help that way. Anything helps :)
I've setup a [patreon](https://www.patreon.com/isovector) for the project, as well as early-access/preorders of the book at [leanpub](https://leanpub.com/book-of-types/). It's definitely happening :)
* 3. I've setup a [patreon](https://www.patreon.com/isovector) for the project, as well as early-access/preorders of the book at [leanpub](https://leanpub.com/book-of-types/). * 5/6. Thanks for the recommendation for "On Writing Well." The subsequent chapters I've written are significantly terser and less buddy-buddy. I think it's a good change.
Dont worry about the Ph.Ds. Just go &lt;https://www.youtube.com/watch?v=M5hI6VY_rmE&gt;
Haha great clip, Randi is the man. 
Compose has improved some of my nested-Applicative code a lot. That said, I was kind of hoping from the title for a tetris-like game where the peices are somehow typed..
Just remember to wear a glove
Finally started after all this: [https://www.reddit.com/r/haskell/comments/860pdt/prerequisites_for_writing_a_primitive_pascal](https://www.reddit.com/r/haskell/comments/860pdt/prerequisites_for_writing_a_primitive_pascal/)
Outside of personal projects that wouldn't make much sense to share, I'm afraid not.
Cool compiler! You might be also interested in this project as well: * https://github.com/int-index/kalium
See also: [https://github.com/tilarids/pascal2js](https://github.com/tilarids/pascal2js)
Cult was right. Haskell is Mother. Haskell is Father. ;)
A big aspect of Functor and Applicative (and Monad as well) is that there can be no class constraints of the contained types. It's a fun exercise to implement a probability monad, and it seems like a good idea to base it on `Map` with a key of the contained type. But `Map` requires `Ord` and thus an implementation of a Monad can't depend on Map. I dealt with the problem by basing the operation of the Monad on assoc lists instead, and created a `normalize:: Ord a =&gt; Prob a -&gt; Prob a` function to efficiently consolidate the disparate outputs.
Have you read the last link? Constrained monads exist. Do-notation works fine for them (with RebindableSyntax). Applicative do is the thing that fails.
Haha that's fair. I like to spruce up my titles to make them fun. Maybe I should do the same with my code :D
Well I tell the reader to try implement them first. It's on them after that. This is a post for people who need more help with understanding the concepts a bit better, and getting a my take on it.
I also find it really useful to copy all library functions into the module and then incrementally reimplement them by playing type tetris. -fdefer-typed-holes helps a ton with that. Though using pure instead of const almost feels like intentional obfuscation. 
The title gives me an idea for some kind of tetris game based on haskell type signatures + type holes.
Instead of `ap` (which is aka `&lt;*&gt;`), you can also use: liftA2 :: (a -&gt; b -&gt; c) -&gt; f a -&gt; f b -&gt; f c or zipA :: f a -&gt; f b -&gt; f (a, b) -- not sure what this one is called . Any of those combinators will do.
oke, and it's a very very good read. much kudos for you 
Thanks dude! Hope you got something out of it 
Is it possible to create a heterogenous list type that can only contain composable functions? Ie. `[a -&gt; b]`, `[b -&gt; c, a -&gt; b]` and `[c -&gt; d, b -&gt; c, a -&gt; b]` are all valid because applying `foldr (.) id` doesn't cause a type error. Is it possible to create a heterogenous list type that enforces this invariant via the types system, and if so, how?
I've now made this PR. Thanks for the nudge :) https://github.com/yesodweb/wai/pull/698
Great, cheers!
How's this data ComposeList (xs :: [*]) t where CNil :: ComposeList '[t] t CCons :: (a -&gt; b) -&gt; ComposeList (a ': ts) t -&gt; ComposeList (b ': a ': ts) foldC :: ComposeList (u ': ts) t -&gt; t -&gt; u foldC CNil = id foldC (CCons f fs) = f . foldC fs It's kind of hard to work with this structure though. You might as well represent the list by the result of its composition if folding is the only thing to be done with it.
You‚Äôve done some of this already, but various bits of your parsing code could be simplified with the use of Applicative combinators instead of Monad‚Äîdoing so tends to make parsers easier to read because it makes them follow the structure of (simple parts of) the grammar more closely. Examples: tok p = p &gt;&gt;= \x -&gt; whitespace &gt;&gt;= \_ -&gt; return x -- = tok p = p &lt;* whitespace -- = [point-free] tok = (&lt;* whitespace) parseTypeDecl &gt;&gt;= \xs -&gt; return $ DeclType xs -- = DeclType &lt;$&gt; parseTypeDecl parseDesignator = parseIdent &gt;&gt;= \x -&gt; try (many parseDesigProp) &gt;&gt;= \y -&gt; return $ Designator x y -- = parseDesignator = Designator &lt;$&gt; parseIdent &lt;*&gt; try (many parseDesigProp) parseOPrelation &gt;&gt;= \x -&gt; parseSimpleExpr &gt;&gt;= \y -&gt; return (x, y) -- = (,) &lt;$&gt; parseOPrelation &lt;*&gt; parseSimpleExpr -- = liftA2 (,) parseOPrelation parseSimpleExpr stringIgnoreCase "boolean" &gt;&gt;= return TYboolean -- = TYboolean &lt;$ stringIgnoreCase "boolean" a &lt;|&gt; b &lt;|&gt; c &lt;|&gt; d -- = choice [a, b, c, d] -- = asum [a, b, c, d] 
Backpack is now available in Eta, and will be available in the next release (whatever comes after v0.8.0b2). You can play with it right now if you build from source though.
O_O Wow.
I'm not u/frud but had a similar experience. The approach with `normalize` is **not** using `normalize` only at the end, it is to use "cleverly" in the middle of the computation. And, more importantly, you need to be clever even if you are using constrained monads. For example, the following code is an example of "clever" usage. coin :: Prob Int coin = Prob [(0, 1/2), (1, 1/2)] -- O(2^n) slowCountHeads :: Int -&gt; Prob Int slowCountHeads n | n &lt;= 0 = return 0 | otherwise = normalize $ do x &lt;- coin sumXs &lt;- slowCountHeads (n - 1) return $ x + sumXs -- O(n^2) fastCountHeads :: Int -&gt; Prob Int fastCountHeads n | n &lt;= 0 = return 0 | otherwise = normalize $ (+) &lt;$&gt; coin &lt;*&gt; fastCountHeads (n-1) Using constrained monads only helps you by inserting `normalize` automatically. `slowCountHeads` is still slow if you used constrained monads.
Great article - I've never quite realized the motivation for applicative until now. One nit: JavaScript isn't untyped, it's just that every value is the same type (I.e. JS is unityped). That type, call it `Any`, is the union of `null` , `true`, `false`, `undefined`, all doubles, all strings, all classes. You could think of it as a giant sum type. In other words, philosophically there's still a type system, it's just the most permissive one possible (where every expression is deemed valid). Having said that, though, pragmatically I don't know if there's a meaningful distortion between untyped and unityped, or if I just prefer to think of it that way.
We have a pending issue for this: https://github.com/typelead/eta/issues/517. We'll probably implement some solution before v1.0. Basic idea is that we have a "thunk evaluation counter" and every 100-1000 or so evaluations, we traverse the list of selector thunks that have been created so far and check whether the product type they reference is evaluated or not. If it is, we overwrite it with an indirection to the value. We also have a solution to the problem of overwriting thunks with their indirections, which involves doing something similar to the above and not implemented yet. For both problems, we'd like to have a collection of test programs so that we can tune both solutions accordingly as they do incur some performance cost. A crazy solution to both is to use the JVMTI and write a native agent to traverse the heap periodically and search for live closures (which are subclasses of `eta.runtime.stg.Closure`) and replace their fields which may be thunks with their indirections if they exist and do similar processing for selector thunks. https://docs.oracle.com/javase/8/docs/platform/jvmti/jvmti.html#FollowReferences Anyways my point is that we can do something about it and not all hope is lost :) GraalVM is built on top of JVMCI (Java Virtual Machine Compiler Interface) that allows you to plug in your own JIT compiler written in Java (or even Eta if you want). Unfortunately the docs are almost non-existent and you have to read the GraalVM source code, which is the only non-trivial example of how to use the JVMCI. Someone can very well make a JIT compiler specialized to lazy functional languages via JVMCI, but it'll take a lot of work.
How can I read, *and then write* to a socket? import Network (withSocketsDo, listenOn, PortID(..)) import Network.Socket (Socket, accept, close, setSocketOption, SocketOption(..)) import Network.Socket.ByteString (send, sendAll, recv) import Control.Concurrent.Async (async) import Control.Monad (forever) import Data.ByteString.Char8 (unpack) import Request main = withSocketsDo $ do sock &lt;- listenOn $ PortNumber 3000 putStrLn "Listening on port 3000..." forever $ do (conn, _) &lt;- accept sock async $ handleAccept conn handleAccept :: Socket -&gt; IO () handleAccept sock = do putStrLn $ "Connected!" rawReq &lt;- recv sock 4096 let req = parseRawRequest $ unpack rawReq putStrLn $ show req handleRequest sock req handleRequest :: Socket -&gt; Maybe Request -&gt; IO () handleRequest sock Nothing = do putStrLn "Closing..." handleRequest sock req = do sendAll sock "In handleRequest!" I can make a connection, "Connected!" is printed on the server, but nothing is printed on the client. When I close the server (`CTRL+C`), "In handleRequest" appears in my client. Why isn't it being sent instantly? Why does it wait till the end? I thought it might be something with the laziness of `recv`, but I'm parsing the result immediately after, so it should be evaluated. Any thoughts?
Eta picking up support for backpack means I have a whole host of Eta-centric Haskell stuff that I can start working on now. I'm quite excited.
The JVM tool interface solution isn't _so_ crazy. In fact, it's quite clever. The sort of leaks from this thing tend to be pretty slow leaks, so even fairly infrequent traversal would be enough. I've been exploring using GraalVM myself, for a current research project, which is actually why Eta recently re-entered my view. I don't know so much about the JVM Compiler Interface bits that were exposed to support GraalVM, though.
oh nice thanks a lot, I'll refactor soon. I have a couple questions if you don't mind: - For the next steps (scope/type checking), should I use a symbol table, or is there a different approach taken when using a functional language like Haskell? - Should there be a pass to further reduce the parse tree or Should I modify the parser to directly produce an "abstract" syntax tree from the get go? - Also, how do I know if the parse tree I got out of my parser is abstract enough? 
I'm disappointed that [Michael's concerns regarding multiple public libraries](https://www.reddit.com/r/haskell/comments/3cu5nu/feedback_requested_for_supporting_multiple/csz0b6z/) were completely disregarded &gt; Please, please don't do this. Our tooling is barely holding together as is. Throwing yet another curve ball is yet another failure case we all get to worry about and experience. This is hurting Stack as well as the majority of Haskell users that relies on Stack. We should impose a moratorium on Cabal and stop adding new features until Stack has been able to catch up and properly support them.
I disagree. On the superficial facts, I probably seem predisposed to feel as you do and dislike Backpack: * I use Stack exclusively and have for years. * I find the C++-esque growth of Haskell (with grafing on things like dependent and linear types) to be disconcerting. However, Backpack is fine. While the ergonomics of it seem rather terrible compared to the module systems you'd find in Standard ML or OCaml, it's complexity that can be very effectively hidden away inside packages. At the end of the day, I will just have access to regex-string/regex-bytestring/regex-text packages that have identical APIs except for their string type representation. Whether they are internally defined using Backpack is not really my concern. My basic assumption is this: Tools can always be written. It is complexity that interfaces with the user directly that we must be careful about.
\&gt; My basic assumption is this: Tools can always be written. It is complexity that interfaces with the user directly that we must be careful about. But the tools are the interface to the user! The problem is that Cabal's been dashing forward without paying attention to what this is doing to Stack and Stackage. And if Stack suffers everyone suffers.
Backpack, as /u/Athas already said, is not as clean as SML modules. But still it gives Haskell some modularity that is otherwise impossible. I have been exploring this for my cryptographic library [raaz](https://github.com/raaz-crypto/raaz) mainly to make cryptographic implementations (some of which require hardware support) pluggable by advanced users. It is doable using type classes but is significantly worse. So I hope stack will catchup with backpack and we can all be happy again.
But to handle all this, doesn't Stack have to do pretty much the same thing as Cabal does? The main difference between the two is how they do sandboxing (although they both use the same GHC APIs as I understand it), as well as dependency resolution. Backpack does not seem like it interferes much with either of these. Can't Stack take the code or algorithms for Backpack handling from Cabal? Is there a writeup for why this is more complicated to put in Stack than it was for Cabal?
It's also also very interesting we just had another GSOC in which none of the Stack proposals were accepted by haskell.org while Cabal had even more than one project funded! Seems like FPComplete will have to fund work on supporting backpack from their own pocket, again.
Given the discussion around the ticket for stack support of backpack, I was assuming that it was just a matter of time before stack starts supporting backpack. Also it seems that the discussion you link is something that is 3 years old. I am not sure of the internals of this but if eta-lang can support backpack --- from what I gather typelead is an enterprise with an even smaller pocket --- I do not see why stack will not be funded to support backpack. 
So fpco decided to reinvent `cabal-install` instead of contributing to its development and now they're realizing the costs of NIH? Too bad!
Right. Like I said in both comments above, fixing do-notation for constrained applicatives would solve that problem and make `slowCountHeads` compile to fast code. The whole point of `ApplicativeDo` is figuring out that the computations `x` and `sumXs` are independent, so the second doesn't need to be called twice. (Or you could try compiling with -O1, there's a chance that it will make `slowCountHeads` fast even with constrained monads.)
[removed]
I want signatures more than I want stack. (And to be clear, stack is great tool). 
always
If we're talking about Backpack: I see that mostly as a GHC feature that needs build tool support, and it was developed in the open over a large span of time. If the way I'm viewing it right, then it's not so much Cabal adding new features: it's that Cabal supports all of the features of current GHC and Stack has fallen behind.
One potential use-case for Backpack is to instantiate a signature internally in order to show the user multiple, slightly different, versions of an API without too much code redundancy. An experimental example [here](https://github.com/bitemyapp/bloodhound/issues/234). This can be done with typeclasses / paremeterized types, but I think they impose a greater cognitive burden on the user. He is likely interested in only *one* version of the API after all, so why should he have to spend time understanting the mechanism that enables sharing code between the versions? Alas, the Backpack solution also relies on `reexported-modules`, which don't seem to play well with Haddock :(
Ahh, sorry. You're right. ApplicativeDo + constrained monads will optimize this automatically, and that's great if it would work! In hindsight, it was a bad example to express what I wanted to say. I'll show another example. I came across the following code running very slow: do x1 &lt;- sampleSomething (score1, cost1) &lt;- f x1 cost0 x2 &lt;- sampleSomething (score2, cost2) &lt;- g x2 cost2 x3 &lt;- sampleSomething (score3, _) &lt;- h x3 cost2 return (score1 + score2 + score3) Rewriting it to following form greatly reduced the computation time. do (score1, cost1) &lt;- normalize $ do x &lt;- sampleSomething f x cost0 (score2, cost2) &lt;- normalize $ do x &lt;- sampleSomething g x cost1 (score3, _) &lt;- normalize $ do x &lt;- sampleSomething h x cost2 return (score1 + score2 + score3) In this case, I knew both `score`_n_ and `cost`_n_ take very few possible values and have lots of duplication in results. If `cost` had very few duplications in results, this rewriting would slightly worsen the performance. So constrained monad is not a panacea, that's what I wanted to say. But I stand corrected there will be many cases constrained monad (+ ApplicativeDo) will give us optimization without much work.
Thanks! I will try to wrap my head around it later. I‚Äôm still not fluent in this type level stuff. The reason I want it in a list, is to make it easy to show the intermediate steps of the computation (ie. convert the list of functions to a `String`), e.g. as `a -&gt; b -&gt; c` rather than the result of the composition (`a -&gt; c`).
Hmm, maybe I'm missing something. Even without optimization, with `ApplicativeDo` this code calls `f`, `g` and `h` twice each, which seems like the best possible result to me: {-# LANGUAGE ApplicativeDo #-} import Debug.Trace (trace) s = [1,2] f x = trace "f" [x+3,x+4] g x = trace "g" [x+5,x+6] h x = trace "h" [x+7,x+8] main = print $ do x1 &lt;- s s1 &lt;- f x1 x2 &lt;- s s2 &lt;- g x2 x3 &lt;- s s3 &lt;- h x3 return (s1 + s2 + s3) And with a constrained applicative, I don't see why the normalization wouldn't happen on each line as well. Though of course I can't test it directly.
In my example, `g` depends on `cost1` which is the output of `f`, and `h` depends on `cost2` which is the output of `g`. Your example has no dependency between `f`, `g`, `h`.
Aside from type-level nats, I was interested in the general case of proving things to the compiler. Your recommendation of the constraints package and some more digging set me on the right direction to get started in this matter. Thank you!
While I very much disagree with /u/haskelll that we should stifle development of one tool to ‚Äúwait‚Äù for another, I would also like if we could stop this toxicity on our subreddit. We‚Äôve already seen enough exodus as it is, it would be nice if we could not push away more members of the community.
Oh! Sorry, I missed that. You're right. It looks like after the computation branches with `sampleSomething`, it can't unbranch itself back, even if the next result is smaller. I keep wishing for do-notation to work differently, as though each `x &lt;- ...` behaved like a single `fmap` over the relevant state so far. But maybe it's just not possible.
Before Stack came along every professional developer I know refused to touch Haskell. After Stack, it's finally viable as a productive language. I don't think the community realizes how valuable this tool is, and how ruining your tooling will ruin your language.
&gt; Well, I guess if my opinions are going to be dismissed because I work for a company, there's no point continuing this discussion. Does he really think that has anything to do with it? Stack's inability to keep up is no excuse to halt highly desired development on GHC and Cabal. It'd be different if there were any ambiguity on whether or not Backpack is a good thing, but there isn't. Stack and cabal-install are bad excuses to halt progress in GHC.
&gt; how do I know if the parse tree I got out of my parser is abstract enough? Compilers for production languages often keep quite a lot of concrete syntax information around - line numbers, whitespace, token ordering, etc - for the purposes of error reporting, refactoring tools, etc.
Whether or not Stack was successful has little to do with whether or not Backpack is a good idea. If Stack is going to *continue* to be successful, it needs to support the features that the Haskell community as a whole have overwhelmingly decided to accept. If it fails to do so, well, that's on Stack.
 Aren't the gsoc projects chosen by the students, not haskell.org?
&gt; Why don't you write up a GHC proposal? Hm I don't think I have the familiarity with GHC required to make a proper proposal. I'd want such a proposal to talk about the pros and cons with respect to the parser and desugarrer, and I can't speak much about those.
&gt; However, Backpack is fine. While the ergonomics of it seem rather terrible compared to the module systems you'd find in Standard ML or OCaml The key point here is that Backpack does not prevent any future growth, as far as I can tell. With something like linear types, it may have a C++-like effect where it stifles better solutions that may arise in the future.
&gt; After Stack, it's finally viable as a productive language. Completely false. &gt; I don't think the community realizes how valuable this tool is I use exclusively `cabal` at work. 
Indeed it‚Äôs student driven. If the low risk / high quality students aren‚Äôt proposing to work on a thing, it won‚Äôt be done. It‚Äôs the responsibility of prospective mentors to find and derisk good students for their prjects. 
&gt; So I hope stack will catchup with backpack and we can all be happy again. After insisting that they were the more pragmatic/industry-friendly tool? Would be possible but kinda galling that their "agile"/"pragmatic" team hasn't managed to catch up with open-source contributors.
[removed]
Indeed. The stack-involved gsoc mentors were given the chance to review the stack-involved proposals (and all other proposals!) and the judgment on whether or not to pick them was based on _their_ feedback as to the quality of the proposals.
If some data type has both \`bind : (a -&gt; Data b) -&gt; (Data a) -&gt; (Data b)\` and \`pure : a -&gt; Data a\` functions, but does not have \`map\`, what is it called?
You could define `map f = bind (pure . f)`, so really you always do have map.
Why *are* the ergonomics of backpack so terrible? I‚Äôve wondered about this for years and not really seen a good answer. Why couldn‚Äôt we just have added module syntax as an ordinary syntactic construct of the language like in ML, rather than some strange second-class feature that lives in package manager land?
This is a tool I have been working on casually. It still misses some (or many..) vital features, but it seems to be a right moment to get some feedback from the community, to see what others may think of the idea and the implementation itself. Let me know what you think!
Looks like this is classification of data items, AKA an ontology. Have you tried modelling it in the Web Ontology Language (OWL)? And maybe storing the data in Amazon Neptune? 
Yes, we have used this approach in the past to achieve high performance: https://www.fpcomplete.com/blog/2017/01/speeding-up-distributed-computation In that benchmark the communication between processes happened over the network, but having more IPC functionality would be very nice. Theoretically it's a bit of a shame: Theoretically threads should always be better or equal to processes as long as the threads do the right thing. But in this case that would be independent, concurrent GC, which we don't have, so that's why multiple processes can often help a lot. You may also be interested in Linux's new `memfd` functionality to pass memory cleanly from one process to the other (more easily than with shared memory).
How are you sending data from your client? Using `netcat localhost 3000` and sending a single newline does what you'd expect. Also you might want to add a call to `forever` in `handleAccept` to receive more than just one request
Best representation of a grid world in haskell? As a learning exercise I'm looking to implement breadth-first navigation over a grid world in haskell. You can move up, down, left or right on the grid. The grid has walls and that prevent moving into specific spaces. There are also portals that transport you to the same space on another level. This can be represented as a general directed graph fairly easily (portals are one direction only). However since the edges don't arbitrarily go between nodes, but are instead implicit in the structure of the world, a more efficient representation is possible. In a language like c++ or python, allocating an Array of grid squares and using a FIFO queue of indices into the grid would provide a fairly intuitive representation of the grid search. You could also write information into the grid as you're searching it, like marking nodes as visited or storing a previous pointer so you can backtrack along the grid and extract the actual path. I'm not sure how to implement this efficiently in Haskell. I found both the array and vector libraries, which seem like a good start for representing the grid world itself. However I'm not sure how to handle the other information I need while I'm doing the search. (Current location, path back to the starting location, marking squares as visited, Queue of other squares.) So what's the Haskell way of representing this problem? What would the best way of actually searching the grid and keeping all the information I collect along the way? Other constraints: The start and end points aren't know ahead of time, they are read in as special tiles in the grid world input. That means I need to search either the input or the fully constructed grid for those tiles. I need the actual path, not just the length.
we do. I've used stack for years, and recommend it to anyone I'm teaching Haskell. Production environments might be on an earlier GHC (/Cabal) version. Programmers learning Haskell shouldn't be learning about signatures (unless they're coming from an ML, but even then, typeclasses are currently the most widespread and idiomatic solution to modularity). Stack users don't need packages with signatures, nor do many such "useful" package exist yet (`raaz` for cryptographic algorithms, and ekmett's monomorpnic sets for `Ord`-like signatures). There is *zero* benefit to cabal artificially delaying this new feature (and these features already takes years to implement, let alone mature). Just like I'm okay (and was okay) with stack providing better project support (than cabal sandbox), including non-hackage repositories, years before `cabal new-build` and `cabal.project` (as well as snapshots i.e. `resolver`s). And we learn about Backpack by using it, you can't use it without a single implantation.
Well, that was the point of backpack, w.r.t. research. It's a language-agnostic (iirc) module system that requires minimal language support, which any package manager for any language can implement. Haskell (GHC Haskell) just gets to be the first language that benefits from a lot of programming language research. 
Any logic in the `Cabal` library could/should be useable by `stack`.
Mainstream spreadsheets are so dumb... Being able to define and evaluate any Haskell function is a great idea I think. I didn‚Äôt try it yet but I sure will!
This is a fantastic idea! I'd be interested in contributing in the future when I have some free time.
I should have probably go right to the point: Spark allows using `map`, `flatMap` and `pure`, but it disallows nested dataframes, so `Dataframe (Dataframe a)` would throw an error. Which means `map` is actually partial function. Now I think hat I cannot call dataframe a functor or monad because of this. Maybe it is a different category?
Thanks, and yes definitely feel free to contribute! Both code as well as ideas are very welcome!
Paging /u/lexi-lambda and /u/tekmo... I would love to see one of you in this position, if you have the bandwidth for it!
This is interesting! Are you considering adding a GUI, or would you rather stay with a TUI? Both could coexist as well. There are a few things I might want to try with reflex-dom, and it could be a nice intersection of our interests for me to work a bit on this. Are you open to such a contribution? Or do you have a differing preference? ----- Nevermind, I've just noticed that this is written most entirely in C. For some reason I was guessing and hoping it would be Haskell with brick. But, a GUI for this project could be nice nonetheless. And I might still just go ahead with my reflex-dom experiments as writing a spreadsheet core with `hint` might not be that hard.
Yeah I have no idea why but for some reason I started writing this in C 3 years ago. I guess it served as a minimalistic puzzle of sorts. I am entirely open to GUIs, the only reason this is now a TUI is that I am not familiar with nor interested in designing frontends. I am however interested in creating hooks (in the form of a C ABI library), which any frontend (no matter its language) could then call? In this setup this library would serve as a backend. That said, yes the core functionality of a spreadsheet is quite easy to define. So if that is all that you need then defining it yourself seems appropriate. You could also have a look at an older repository of mine: [https://github.com/RKlompUU/FPSpreadsheet](https://github.com/RKlompUU/FPSpreadsheet). Before I started writing this C variant I wrote a similar tool in Haskell for an experimentation project, but it is much less fleshed out. If I remember correctly it uses javascript and a local server as a frontend provider.
&gt; Completely false. Your statement about it being completely false, is completely false.
There was an old library called 'thrist' that implemwnted this data structure iirc
I actually asked Edward on IRC about this once, and (speaking purely from memory after using backpack a little myself): there's nothing that really fundamentally prevents us from having module application syntax inside the Haskell grammar, I think. Right now, we just have the mixins existing inside the `.cabal` file, which act as applications, but we could have both. This was a minor sticking point for me since there's an issue of provenance, needing to go back between the code and the `.cabal` file to keep things in mind. One problem of course is you're going to go up against Wadler's law, on this one, but ordinary module-application syntax doesn't seem far fetched, at least.
Have you seen [obelisk](https://github.com/obsidiansystems/obelisk)? It's a bit lacking in documentation, but it seems similar to what you're talking about.
This is really cool! I've long wanted something like this to exist, and not be dead (like [SIAG](http://siag.nu/)), though I didn't quite feel confident enough to try to create it myself. I also love the fact that you have modal editing! :)
I have seen it - and wasn't it a surprise to see Obsidian Systems release something that's functionally equivalent to something I'd build at the start of the year. But ultimately, obelisk focuses on making Reflex apps easy from the infrastructure side - deployment, "isomorphic rendering", the Nix derivations required for completing what's missing in reflex-platform (all things I've had to do in my projects, just baked into them and not separate). Maybe there are other plans for it, but I haven't seen any roadmaps. I might even base my work upon obelisk (just with a different skeleton app) to have it take care of the stuff it's made to do - I want to focus more on the application side of the problem, closer to Yesod - and on things that are needed to meet the new web app design trends like PWAs.
You might be interested in the [routing PR](https://github.com/obsidiansystems/obelisk/pull/112). It's only one piece of what you're talking about, but it might make a nice starting point.
Well, Obsidian Systems sure is busy... I'm not sure what the best way forward is here, especially if Obelisk's intended purpose is being a general-purpose platform for full-stack Haskell web apps. My school has interesting requirements on our bachelor's theses (or rather bachelor's projects, even if they aren'≈ß called that) - they're supposed to be solo projects, not too theoretical work, but ideally something that has real-world use (the more the better). At least that's the way my advisor summarized it for me and given these requirements, this seemed like the ideal project for that.
There's still plenty of work to be done for obelisk. Maybe your project could be more about making contributions to obelisk? There's no reason you couldn't build your own stuff from scratch, but that seems less likely to be used in the real world than something maintained by a company like obsidian. Alternatively, if you're looking for suggestions, WebGHC [just got the ability to run a hello world program](https://github.com/WebGHC/wasm-cross/wiki#try-it-out) written in Haskell on WebAssembly. We've still got tons of work to do on runtime syscalls and JS interop, so there's plenty of opportunity for a student project there.
Well yes, I'd like that - but I need a well-defined problem that I can solve solo, I very much doubt I could write a thesis based on continuous contributions to a project, obelisk or another. (I've been following WebGHC a bit, but this is some interesting news - though I see the same problem here... :( ) I could return the original problem that I was solving - offline-first applications and eventual data synchronization - investigate the problem space, write a library. That's something I was going to focus on anyway, this way I could make it the main focus of my work...
It's sad that it has to be solo. Collaborative efforts like obelisk or WebGHC will provide far more educational value to you IMO.
Well, I wouldn't know, I'm used to working solo both at work and outside of it :) But yes, if that was an option, then both obelisk and webghc would be great projects to work on. Though in that case, my first choice would be working on compile times of GHC, which was the first thing I considered - that would have a lot of "real-world use" - namely, the development experience of every Haskell developer :)
To be honest, I don't feel like this really addresses my question. Does ezyang have a reddit account we can ping?
You asked both about economics in general and a language level module syntax in particular. I was addressing the second (and I don't know that much about backpack bruins its usage). But yes, their Reddit username is ezyang, and they're responsive!
Can you give an example of an untyped language?
I unfortunately don't have the bandwidth for it otherwise I would volunteer
I don't think such a language can exist. Either the values in the language are distinguished in some meaningful ways at compile-time (in which case there are multiple types in the type system), or they're not (in which case there's only one type).
Yeah, I figured that it was a buffering issue on my client's end - `netcat` fixed it perfectly, cheers :) Doesn't the `forever` inside `main` do this? I thought it looped infinitely, spawning a new thread for each connection via `async $ handleAccept conn`. Is this not the case?
Seems like something that could be manifested as an extension to one of the existing frameworks. E.g. Yesod for typical application stuff + Servant routing/RESTful content/client generation. There's a project called [magicbane](https://github.com/myfreeweb/magicbane) that seems to attempt to do this.
/u/ezyang, are there any plans for ML-like module syntax directly in the language? Inquiring minds want to know.
Thanks! Pinged him elsewhere in the thread.
You‚Äôll still use a symbol table, it‚Äôll probably just be an immutable map that you pass around, either explicitly as a function parameter or implicitly with Reader or State. Generally speaking it‚Äôs best to retain enough information that you could pretty-print the source, not necessarily verbatim, but retaining all the syntactic sugar‚Äîfor example, if your language has an `if`‚Ä¶`then`‚Ä¶`else`‚Ä¶ expression that desugars to `case`‚Ä¶`of { True -&gt; `‚Ä¶`; False -&gt; `‚Ä¶`}`, you‚Äôd keep separate AST nodes for `IfExpression` and `CaseExpression`. You can do whatever analysis passes you want (like typechecking), *then* desugar to a smaller representation, because it‚Äôs easier to produce useful error messages when the internal representation is relatively close to the source code‚Äîbut you can discard that information later, or bake it down into a different form like debug info (e.g. DWARF). 
The reality might be a bit more forgiving about which binaries can successfully exchange static pointers, but nonetheless it would be a very bad idea to rely on any stability beyond what the documentation *guarantees*. If you have a use case that requires stronger guarantees, that would be great to discuss (as part of a GHC Trac ticket). Tag Facundo and Edsko. Maybe future versions of GHC will provide the stronger guarantee. And it might well be a simple documentation patch to achieve that.
Great! The `forever` in `main` only accepts connections forever, but only runs `handleAccept` once per connection in this case :)
Providing a web based interface could be a nice alternative to building an entire UI on top of this. From systems like Google Docs/Spreadsheet we already know that spreadsheet software can work quite well in the browser.
I would strongly advise against using the LLVM codegen (`-fllvm`) with the 8.6.1-alpha2 due to [D4969](https://phabricator.haskell.org/D4969).
&gt;Your journey into the **typed** rabbit hole begins! Fixed it for you. ;)
Well, my intent wasn't to reinvent the wheel. Ideally, I'd like to have a pluggable backend (e.g. either Servant or Snap). Magic bane looks quite nice now, I've seen it I think about a year ago when there wasn'≈ß much to see yet. It's somewhat similar to what I'd imagined, but only on the server-side. Do you know if there is anyone using this in production, apart from the author I mean?
Thanks a lot. I've opened a [Trac ticket](https://ghc.haskell.org/trac/ghc/ticket/15395#ticket) to discuss this.
I'd imagine it would be useful to interact with a frontend compiled with GHCJS
Lol that‚Äôs massive. 
I've never been a fan of complex webapps though. They never seem to work as well as their desktop variants do (e.g. I rather use something like Thunderbird than gmail via the webbrowser).
What is the most convenient lens library, which avoids excesive use of infix functions. (I favor simplicity, since I have not used lenses before) 
I would not fear working with immutable data structures, unless you find it a bottleneck of your algorithm. Therefore I would have one 2d vector containing the unchanging state of gridword and second one containing the changing state (like the path you came from). For queue you can simply use Data.Queue...
Posted this here because the server is written in Haskell. I love seeing projects like this and PostgREST.
Also, I am open to rewriting this in Haskell. Especially since functionality wise it is very basic still. Probably the most time went into communicating properly with the ghci session, but that is the same regardless of the programming language.
Smaller ecosystem, worse error messages, maybe worse performance, but none of these are inherent to the approach Concur takes, and will improve with time. If you have any program or UI spec that is harder to develop in Concur vs Elm, I'll be happy to try and rectify the situation.
As the next development step, I'd actually recommend a pretty-printer before the type-checker and whatnot. The reasons are that it's easy, useful, and makes your test suite much more comprehensive (yes, you should add a test suite). Instead of merely testing whether a valid program parses without errors, you can parse it, pretty-print it, parse the output again, and compare the parsed trees. Or alternatively, pretty-print yet again and verify that the two pretty-printed programs are identical. It's not Pascal, but you can see the same testing method in my [language-oberon](http://hackage.haskell.org/package/language-oberon) package. 
In that case you could try an encoding like this: data S f a b where Z :: S f a a S :: f a b -&gt; S f b c -&gt; S f a c This immediately gives you your list-like operations: identity :: S f a a identity = Z comp :: S f a b -&gt; S f b c -&gt; S f a c comp Z x = x comp (S f g) x = S f (comp g x) If you plug in something like `-&gt;` for `f`, this is just function composition with the identity, but you can add whatever extra info you want to the `f` and you'll still have piece-wise access to it as you break apart the `S` structure.
Do you know, besides preferring Haskell, why you would use this over [postgraphile](https://github.com/graphile/postgraphile) (formerly postgraphql). Postgraphile seems more mature. 
I have a [test suite](https://github.com/sam46/Paskell/blob/master/src/tests.hs) although admittedly a bit lame and not rigorous. But yeah pretty-print is definitely the next step for me. Speaking of, what is the next step? Some folks suggested I write an interpreter, and I've seen example of making type checks within the interpreter, so I'm super confused. Should I just do scope and type checking next? 
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [sam46/Paskell/.../**tests.hs** (master ‚Üí 0c6df95)](https://github.com/sam46/Paskell/blob/0c6df956efddf92faaa1e44b6c70cfd8cec13f69/src/tests.hs) ---- 
Isn't the problem with a newly introduced primitive (adding words with Carry)? If so, then it does not affect the existing codebase I guess.
&gt; I have a test suite although admittedly a bit lame and not rigorous. I missed it because I looked for a test section in the .cabal file. You should definitely declare your test-suite there. The next step you should take entirely depends on what interests you the most. If you're into proof theory, do the scope and type-checking, and you can follow that up with a more sophisticated static analysis. If you're more of a hands-on type and want to see something concrete, do the interpreter first. With Pascal's simple type system you can easily implement the type checker as an abstract interpreter, without getting overly involved in theory. Note I said *abstract* interpreter; a proper Pascal should not check types at run-time. 
Personally, I'm not that keen in having ML-like module syntax in the language itself. I feel that having both typeclasses and modules in the language could get confusing. Integrating backpack in the package manager has some secondary benefits like being able to rename modules from a dependency. I believe it fits remarkably well with existing package system.
Bad title. Just to be clear, this is not type-level lambdas (which "type lambdas" sounds like). Rather, this is adding types to lambda expressions so that you can write `foo @t x = ...` and use the type `t` in `...`, like you can with `ScopedTypeVariables`. 
&gt; But‚Ä¶ the entire structure of the application is just hidden in the `do` block and we just cannot programmatically access it. If it were possible to compute the information from `do` blocks, would you consider that an improvement of the current servant library?
That sounds cool thanks for the great tips!
Titles can‚Äôt be edited, right? It is a lambda that binds a type; seems okaish. ‚ÄúBig lambda‚Äú would be another good short name, but only to those who read type theory papers.
The parser is a big enough mess that there's very little you could do to make it worse. You'd definitely simplify the renamer somewhat if you removed the special support for `pure` in `ApplicativeDo`, but of course that would break existing code. I wonder if there should be a transitional period with a warning, and if so how that would be implemented.
Perhaps the title should be "Richard Eisenberg wants to add type bindings to Haskell"
I think between this and the proposal for type variables in patterns we can ditch Proxy and its runtime overhead. As a seperate proposal I would like to see visible dependent quantification so typeclass mathods could take a visible type argument instead of the current Proxyies or invisble arguments.
Hey, Potato44, just a quick heads-up: **seperate** is actually spelled **separate**. You can remember it by **-par- in the middle**. Have a nice day! ^^^^The ^^^^parent ^^^^commenter ^^^^can ^^^^reply ^^^^with ^^^^'delete' ^^^^to ^^^^delete ^^^^this ^^^^comment.
delete
Next time someone says a particular unit test is too trivial to bother with, we will have something to point to! Is this triggered by uses other than directly calling `addWordC#`?
But Richard Eisenberg certainly *does* want to add type-level lambdas. Sadly, it's not in this proposal. Just you wait. :)
Note that GHC 8.6 remove the last vestiges of Data Parallel Haskell. In particular, this means the `-Odph` command line option has been removed. Unfortunately, some packages (like `vector-algorithms`) specify this option for some reason, and `vector-algorithms` is a dependency of certain high-profile packages like `criterion`.
Glad to read both of these comments of yours! Together with /u/dfordivam we've spent a bit of time contemplating about and experimenting with what could make sense to write with reflex-dom. We [contacted here](https://gitter.im/haskell-pair-programming/Lobby?at=5b4bbf0dc02eb83d7c793c8b). And here is a small outcome of our exploration: https://github.com/Wizek/h-sheets
There are no plans right now! ;)
Well... in a sense, it is rather nice conceptually that there's an implementation-agnostic description of the web application. Indeed, one could get things wrong in the server code (say wrong type of response) and not know about it if the server-side code was the single source of truth (which would be the case if we were to deduce information from it). We also would not be able to derive clients for a web application that we have not written.
Good old grammar nazi bot. 
This is great! GHC core, the intermediate language GHC Haskell compiles into, already translates polymorphic functions, typeclasses, etc. into type lambdas with a similar syntax: bar :: forall a. Foo a =&gt; a -&gt; Bool bar = \ (@ a) (v :: Foo a) -&gt; v `cast` &lt;Co:2&gt; 
Grammar nazi bot that lies about being deletable. 
If you use miso + acid-state it would be very close to meteor. Just be sure to share the client and server state, keep the state pure (i.e. not a monadic expression) and kept it in sync via a websocket connection. This would be the closest thing to meteor, and the most performant option. Miso does have a router, it doesn't make assumptions about authentication (for good reason), but the servant ecosystem has a lot in the way of options here. 
All aboard the type level programming train *choo choo*
delete your account
bad bot
`Proxy#` has no runtime overhead and still has all the power of type-lambdas. Now, both `Proxy` and `Proxy#` are horrendously ugly, so this proposal is still desirable. But the runtime overhead is always avoidable (I think).
`Proxy#` is not something I knew existed. I wonder why `Proxy` gets used instead most of the time.
Hey I know it's been some time, but I'd appreciate it if you'd help me out. I used a grammar and ADT to parse, but then I realized that the AST I want isn't exactly represented by the ADT. Here're some details: data Factor = FactorReal Double | FactorInt Int | FactorStr String | FactorTrue | FactorFalse | FactorNil | FactorDesig Designator | FactorNot Factor | FactorExpr Expr | FactorFuncCall FuncCall -- the grammar: works nicely (correct precedence, avoids infinite recursion) data Expr = Expr SimpleExpr (Maybe (OPrelation,SimpleExpr)) data SimpleExpr = SimpleExpr (Maybe OPunary) Term [(OPadd,Term)] data Term = Term Factor [(OPmult,Factor)] -- the ideal AST data Expr = Relation Expr OP Expr | Unary OP Expr | Mult Expr OP Expr | Add Expr OP Expr | ExprFactor Factor Is it possible to parse immediately into the desired AST or I'll have to go over the grammar's tree once parsed and make it into an AST? 
A few thoughts here: 1. Even before I started working on Backpack, SPJ was quite insistent that we not add piles of more goop to Haskell's typechecker to support "first-class" modules. Having gotten to the other end of my PhD, I absolutely believe that this was the right decision: Backpack in GHC today is amazingly orthogonal from all of the advanced type system shenanigans that GHC development is constantly up to, and I guarantee you that this would not have been the case as an actual syntactic construct. 2. Having interned at Jane Street for a summer (and written some amount of OCaml in the process), I don't think you can say with a straight face that ML module ergonomics are that great. You had usually have a good reason to resort to them. I think this even more true for Backpack: if you just want to do small things, try your best not to use Backpack. Backpack is there for the cases when you really, really have no other choice; e.g., you have twenty full size packages and you need all of them to be parametrized over some backend library. 3. One thing we get for free from having Backpack be integrated so closely with the package manager is that if you instantiate a package the same way in different libraries, you only have to build it once, and then each library can use that same instance. This is completely opposite to how C++ templates work (which, in terms of runtime perf, are much more closely related to Backpack than OCaml modules), where every template is recompiled every time its used, and the linker deduplicates them at the end. You could write a compiler that knows how to handle this, but it would require considerable surgery.
I‚Äôd always looked at unfoldr and thought ‚Äúyeah, that makes sense‚Äù, but that isomorphism blew my mind. 
Mainly because it lives in kind `*`, so you can hang instances off of it for things like `Monad`, `Eq`, etc., which can be convenient for getting some common patterns of type argument plumbing done, and, well, I wrote it first, a few years before I wrote `Proxy#` with Austin, so it had time to get established. We added `Proxy#` anticipating using it in one of the `Typeable` rewrites, but then `TypeApplication` and `AllowAmbiguousTypes` came along, making a muddle of that plan.
TIL Proxy has runtime overhead. So far, I was thinking that it's just a trick to pass around type variables.
That `foldr`, `unfoldr` example is really cool, not sure I ever would've figured out that there's a formal relationship between those two types. It's also interesting that in that example, the dualizing seems to turn a least fixpoint into a greatest fixpoint: If we care about totality, then the list argument in `foldr` must be finite. However, in `unfoldr` our function argument might never return `Nothing`, so our output list must be potentially infinite.
&gt; I'm happy to advise and support a volunteer who wishes to implement. I might do it myself or work with a student on this someday, as well. That sounds like an awesome opportunity! /u/goldfirere, what is the expected level of `ghc` knowledge to start working on this? I would love to participate when the proposal is approved, but I'm not very familiar with `ghc` internals..
I have seen type-level lambdas in Scala, how would they look here?
Proxy is basically an empty tuple with a phantom parameter (2 if you count the kind parameter). So it has the runtime overhead of an empty tuple.
It seems like you can get the same effect with `foo (undefined:Type) ...` by the caller, and `foo (_:t) ...` at the callee.
Cleaning brains from my walls at this moment. I love Haskell 
I like the idea of using acid-state quite a bit. I've disregarded it some time ago after reading about the problems Hackage2 has (had?) with it, but I'll have to look into it more now. As for miso, while I like the simplicity of TEA, I've grown to prefer the more expressive FRP provided by Reflex. Of course the ideal end state would be that a developer can simply choose between Miso/Concur and Reflex, but right now I'll likely start with Reflex only.
I‚Äôm in already. Started this morning and couldn‚Äôt stop. Beautiful language.
Is it possible to use this map for uninhabited key types? For example, I'd like to map a `dst :: Symbol` to a `[Money.ExchangeRate src dst](https://hackage.haskell.org/package/safe-money-0.6/docs/Money.html#t:ExchangeRate)`.
Thanks! Looks like this does exactly what I need.
I think that your solution has performance overhead of passing extra argument to function. Even if it's `undefined`, you still need to pass reference to object.
Consider the following definition which is exactly the same as `Identity`: ``` newtype A a = A { x :: a } deriving (Eq, Num, Ord) ``` with `GeneralizedNewtypeDeriving` on. Now, we have ``` Œª: A 2 == 2 True Œª: :t A 2 A 2 :: Num a =&gt; A a Œª: :t 2 2 :: Num p =&gt; p Œª: :t (==) (==) :: Eq a =&gt; a -&gt; a -&gt; Bool ``` But as seen, `2 == A 2` shouldn't even typecheck, unless both are made of the same type `a`. Still `A 2 == 2` is `True`. What exactly is happening here?
Is it possible to create a type-safe map, that works sort of like (pseudo-Haskell): data Map (key :: k) (val :: k -&gt; *) (keys :: '[k]) empty :: Map key val '[] insert :: val key -&gt; Map key val keys -&gt; Map key val (key ': keys) class (keys `Contains` key) =&gt; Lookup key val keys where lookup :: Map key val keys -&gt; val key where the `Contains` constraint makes sure the `key` is present in the type-level list of `keys`; `insert` adds a type of kind `k` to the type-level `keys`-list; and `lookup` causes a compile-time error if the requested `key` is not present in the map. So, for example, a `map :: Map (dst :: Symbol) (Money.ExchangeRate src)` would be used as: empty :: Map Symbol (Money.ExchangeRate src) '[] er :: Money.ExchangeRate "EUR" "USD" newMap = insert er map :: Map Symbol (Money.ExchangeRate "EUR") '["USD"] value = lookup newMap :: Money.ExchangeRate "EUR" "USD" I'm sure I'm missing something in my syntax (otherwise I would write the code and test it out), but could this work in principle?
This is right, the buggy `MO_AddWordC` instruction is new. The main problem is D4592 was merged without any tests.
I rarely use Excel anymore for my own work. I open a GHCi prompt and do exactly what this program does but without the GUI. Excel is for when I need to communicate with \~muggles\~ normal people.
Yikes, that one is on me! [https://phabricator.haskell.org/D4969](https://phabricator.haskell.org/D4969)
&gt; Is this triggered by uses other than directly calling addWordC#? Currently (unless I'm missing some commits that were done in the meantime) you have to use the new `addWordC#` primop to reproduce.
Exactly, no existing code will be broken by this.
Indeed, this is worth mentioning in the GHC 8.6 migration guide. I've done so [here](https://ghc.haskell.org/trac/ghc/wiki/Migration/8.6?version=11#DPHisgone).
Thanks! I also submitted a patch for `vector-algorithms` (unfortunately it's not on Github, so I just hope the email hole is active).
Well, in my defense, there was [`D4605`](https://phabricator.haskell.org/D4605) which was merged immediately after with a test that should have caught this. But it didn't, because I wasn't aware that testing with `-fllvm` is not tested by default.
Very nice! I am studying Bartosz's Category Theory and these are some very nice examples of the tings I am learning there. Thanks for writing / sharing this!
Assembly language and B are untyped, there are only bytes without any particular meaning.
Here's a stupid question. I'm new to haskell and wondered how to call a no parameter function. (not that useful unless doing IO but just trying to understand syntax etc...). In GHCi I created a function \`noParam = 5\` and then tried to call it with \`noParam \`. with a space. But GHCi didn't print any output. However I think a no parameter function in this case in just a variable (or a constant). Is that correct are 'variables' just zero parameter functions in Haskell?
Count me in!
When you write an integer literal, like `2`, it is desugared to `fromInteger 2` where `2` in the desugared program is a concrete value of type `Integer`. So, `A 2 == 2` is desugared to: A (fromInteger 2) == fromInteger 2 These two occurrences of `fromInteger :: (Num a) =&gt; Integer -&gt; a`, do not have to be the same type. The first `fromInteger` gets a type `(Num a) =&gt; Integer -&gt; a`, and the second `fromInteger` gets a type `(Num (A a)) =&gt; Integer -&gt; A a`.
Oh, that is new to me. I always thought 2 is treated as `2 :: (Num a) =&gt; a`. Seems like it was `fromIntegral`'s doing under the hood. Thanks! 
&gt; If we care about totality, then the list argument in foldr must be finite. Because of laziness, this is surprisingly not true! For instance you can write filter using foldr and it will work for infinite lists. As a simpler example: `foldr (\x y -&gt; Just x) Nothing` implements safe head using foldr. Finally, in Haskell, least and greatest fixed points coincide due to the laziness/divergence combo. In denotational semantics this is called algebraic compactness, though I'm not sure why. 
This packaged was earlier discussed at https://www.reddit.com/r/haskell/comments/8e3vf3/package_worth_highlighting_named_adds_support_for/ There were three common criticisms: * no optional parameters * no infix notation in types * too easy to mix up order of patterns I addressed all three in this new release. Let me know if anything else can be improved!
You added to the compiler and fixed the bug, you‚Äôre the hero here! The villain is testing.
I'll have to make sure this test runs in fllvm when I finally finished rebasing my performance test patch soon :)
I wondered if there was a way to remove the Maybe from unfoldr, but I couldn't come up with anything.
I'm not saying that there aren't specific instances where `foldr` terminates on an infinite list, just that if you want it to terminate in *every* instance then you need the list to be finite. Another way of putting this is that if you were to write these two functions in a total language, `foldr` would need to be written for inductive lists, and `unfoldr` would need to be written for coinductive lists.
Still not the best, `forall` can bind types already. I prefer "type abstraction".
This project is really cool! Looking forward to use it! I highly recommend everyone read tutorial and usage examples at the beginning of `Named` module: * https://hackage.haskell.org/package/named-0.2.0.0/docs/Named.html And here I will copy-paste the part I'm excited about the most. Now with the cost of little extra more code you can have named arguments with default parameters: log :: "message" :! Text -&gt; "severity" :? Severity -&gt; "handle" :? Handle -&gt; IO () log (arg #message -&gt; msg) (argDef #severity Error -&gt; sev) (argDef #handle stderr -&gt; hndl) = ... And you can pass arguments in any order and fill all defaults: log ! #message "Could not match type Int with type Bool" ! defaults
Reflex-DOM is fundamentally different from Miso and I don't think it would be possible to swap them out. The expressive power of Reflex-DOM comes at the cost of separation of concerns. Your view logic will be intermingled with the application logic. It also forces you to think about how the DOM is being modified and to perform tedious, error-prone manual DOM manipulation, whereas virtual-DOM abstracts that away entirely. You won't be able to properly pre-render with Reflex-DOM since a monadic expression graph doesn't have a one-to-one correspondence with the DOM (unlike a virtual-DOM). On a more general note, FRP is better suited on the server, not the client. It's moreso for programs that have a notion of continuous time, not the browser DOM, where the event model is discrete actions.
This looks awesome! 
The type inference is good, so you don't even have to write the type signature. Fun fact: it also works well with partial type signatures, so you can choose to write out the types of arguments, but not their names: log :: _ :! Text -&gt; _ :? Severity -&gt; _ :? Handle -&gt; IO ()
You can create constants like this: myName :: String myName = "YuntiMcGunti" and then just refer it as `myName`, so: main = putStrLn myName
Looks awesome! Has the compile-time overhead been benchmarked?
This is new and improved version of the benchmarks and graphs that I shared earlier on reddit. I received some good feedback earlier and incorporated it in the new version, the package is available on hackage as wel,l and it is very easy to use once it is built. You can easily compare any number of libraries side by side, and even show the delta of a library from other library to easily see the difference. The changelog can be found here [https://hackage.haskell.org/package/streaming-benchmarks-0.2.0/changelog](https://hackage.haskell.org/package/streaming-benchmarks-0.2.0/changelog) . Feedback and suggestions are always welcome!
No, I didn't check the effect on compile times.
One of the hasktorch authors here. A quick note on Ed's call for help: personally, I've been holding back on pushing public announcements of hasktorch until [Backpack for Stack #2540](https://github.com/commercialhaskell/stack/issues/2540) is resolved (I haven't really mentioned this to anyone in our slack group, though). While the wait has been working in our favor and we will be wrapping up some basic end-to-end examples of deep learning architectures soon, I think stack users will still be blocked from using hasktorch until someone can add backpack support (I've been sticking to `cabal new-build` in the mean-time). Help here would be greatly appreciated.
I thought I was bordering on intermediate Haskell until I saw this. How does this even work? What is the `#`? What is the `:!`?
&gt; What is the `#`? These are overloaded labels: https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/glasgow_exts.html#extension-OverloadedLabels &gt; What is the `:!`? This is a type operator defined in the library. https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/glasgow_exts.html#extension-TypeOperators
Did you take a look at `microlens`? Most of the operators defined there seem to have a non-operator alternative.
It is not a function, just a value. You can not "call" it, but you can use it such as `print (noParam :: Int)`.
Was there a particular reason you went with argF for Maybe wrapped optional parameters instead of e.g. argMay or argMaybe?
1. `argMay` and `argMaybe` are too long, it would've been `argM`, which at this point looks like it's monadic 2. `argF` isn't actually specific to `Maybe` - when you use it to match on a regular named parameter, it will be wrapped in `Identity`. I'm planning to support variadic functions in the future, their parameters will be wrapped in a `[]`. `F` stands for "functor" here, but I guess I could've used `W` for "wrapper" instead.
So I've written a small web framework, and I want to see how well it performs under load. I've compiled it with `-O3 -threaded`. It seems to perform incredibly well -- even with millions of connections, I never get more than a few ms of latency. I tested it with `wrk`, and also through a small Go program that spins up a few million `http.NewRequest` calls on separate goroutines. I suspect this (amazingly good) performance is since I'm testing it locally. How can I test it properly? It's built using `Network` and `Network.Socket`, so it's pretty low-level. Maybe that's why?
Okay, Functor was the first I thought of with F. If it actually works for more than just Maybe that is a perfectly fine naming choice.
`#a` is not a valid pattern, but in `named-0.2` I made it possible to write it like this: f (arg #a -&gt; x) (arg #b -&gt; y) = ... Type signature not required.
Thanks for posting those benchmarks--very interesting. Regarding streamly and pipes. I really like pipes because it's well grounded in theory with proofs: https://github.com/jwiegley/coq-pipes. Do you know whether Streamly has a similar theoretical background?
Interesting stuff! Hadn't looked at streamly before and that is some impressive performance. Does someone know why the singleton case in the continuation definition of streamly is there? I learned the hard way that vector code shouldn't mess with heuristics. Now I usually throw an inline pragma on everything stream related and use -Odph -rtsopts -fno-liberate-case -funfolding-use-threshold1000 -funfolding-keeness-factor1000 -fllvm -optlo-O3 Also, I noticed that concat/concatMap was part of the benchmark but not in the results. Would be interested how frameworks compare there since it somewhat famously breaks stream fusion via ghc rules.
Note that -Odph is going away in GHC 8.6 as mentioned here: https://www.reddit.com/r/haskell/comments/8z6oqz/announce_ghc_861alpha2_available/e2hn8q1
The dph flag doesn‚Äôt do anything ... and as of 8.6 is deadcode. Just use 01/O2 and compare across ncg and llvm backends via measuring. Anything else that‚Äôs not empirically driven is a bad day waiting to happen. Likewise careful what you choose to inline. I only inline stuff I know will either simplify away or exposed more rewrite/optimization opportunities. Full disclosure: I help co maintain some stuff like vector and such. (Optimization is a complex rabbit hole, but it should be approached with care) These micro benchmarks should be read in the context that many of these libs are meant for different workloads:)
The program I tested it on used a ton of popCount, if ghc translates that to an llvm intrinsic that might be why it won for me. The manual says `-0dph` enables `-fmax-simplifier-iterations=20 and -fsimplifier-phases=3`. Specifying those manually doesn't appear to have a significant effect, though. My kinda naive intuition is to inline everything that has a stream in the type signature. I usually try to manually push stream/unstream/new'ing vectors as far out as possible which probably is a terrible attitude but makes rules not firing less of a hassle. Also manually adding specializing pragmas and adding strictness to all possibly unboxed vectors since they might be tuples because I find those easy to forget. After than I look at the profiling data first.
I found the solution. persistent-odbc seems to be the culprit. The SQL Server module has a function escapeDBName which auto encloses every field in SQL Server's square brackets. I rewrote escapeDBName to stop enclosing every field in square brackets. autoDownloading the github package and not auto-escaping the code and then dealing with package configuration let's me call schema qualified database objects. 
Just chiming in that I‚Äôve been using streamly in production and on a couple hobby projects and in all cases it has been a joy to use. 
This has been the clearest explanation of Kinds I've read so far. If there was a way I could buy a copy while you write it I'd be happy to! 
Perhaps the singleton case can be removed as of now. The reason for this case was performance when converting a foldable container of actions into a stream. The way it was done was by lifting each action into a singleton stream and then appending those streams together. Singleton continuation creates a singleton stream in one shot compared to calling two continuations (yield and stop) and therefore performs better for that special case especially if you are doing it at scale. But as of now we have introduced a `consM` API to create streams efficiently (without lifting and appending) from a series of actions so the singleton case may not be necessary. I will try removing it and see, thanks for reminding! The concat operation has not yet been implemented in streamly, so I have just omitted that for now in the comparisons. It is available in the benchmarking code, and can be plotted for libraries that support it.
Conceptually, the serial streamly is very much the same as lists or vector, if they are well grounded then it is likely that streamly too is, but we have not attempted any formal proof yet. Are there any formal proofs about lists or vector? I guess the concurrency part may be even harder to prove formally, though it is quite simple in concept, we can try to see what can be done on that front once we are done with the practical/engineering part.
That's good to hear! In case you face any problems you can ask on the gitter channel.
Spoilers: https://www.snoyman.com/blog/2017/12/what-makes-haskell-unique
Very cool, output looks great! Graphics for Haskell have always scared me away from working with them ha.
You can try using Zippers, which are interesting in that they are a comonad, which may serve your use case. Look it up!
Why is there no Lens like library written in direct style instead of CPS? How would the type definition look like? 
Hello, I'm having trouble importing a module. At the top of my haskell file I have `import Math.NumberTheory.Primes.Testing`. But when I compile GHC is telling me `Failed to load interface for ‚ÄòMath.NumberTheory.Primes.Testing`` 
I was actually thinking about what kind of side/weekend-projects would you recommend for someone who is semi-experienced in functional programming languages like F# and SML, but is new to Haskell. The environment can feel a little confusing and overwhelming?
Happy to hear that you liked it. :)
Good release, congratulations /u/int_index. As a joke instance (name ~ name', a ~ a') =&gt; IsLabel name (name':!a -&gt; a') where fromLabel :: name:!a -&gt; a fromLabel = arg (Name @name) instance (name ~ name', a ~ a', a ~ a'') =&gt; IsLabel name (a -&gt; name':?a' -&gt; a'') where fromLabel :: a -&gt; name:?a -&gt; a fromLabel = argDef (Name @name) this lets you replace `arg #name`, `argDef `name` by `#name`, `#name` (don't do this) log :: "message":!Text -&gt; "severity":?Severity -&gt; "handle":?Handle -&gt; IO () log (#message -&gt; msg) (#severity Error -&gt; sev) (#handle stderr -&gt; hndl) = ... 
I actually attempted this before I introduced `arg` and `argDef`. It wreaks havoc on inference :(
Related: [Here](https://stackoverflow.com/questions/50159349/type-abstraction-in-ghc-haskell) is an example where you can't use `ScopedTypeVariables` to the same effect as lambdas binding types.
your code seems very polished, I am gonna try it. thank you!
&gt; Did anybody think about it? Sure, we did. We didn't leap for the most complicated encoding right out of the gate, just to complicate things. `data-lens` started out with that sort of encoding. And there was a whole cottage industry of lens libraries before `lens` came along. (Now there, is still a whole cottage industry, but using the encoding of `lens` they are mostly compatible with each other.) Upgrading from `data-lens` to a type-changing form data Lens s t a b = Lens { get :: s -&gt; a, set :: s -&gt; b -&gt; t } is usable out of the box. You just have to write a bunch of combinators for working with it. You can come up with a similar encoding of a prism as the two arguments to the `prism` function, and treat an `Iso` family as a pair of a function `s -&gt; a`, and one `b -&gt; t`. `Traversal`s aren't quite as amenable to this treatment, as they handle some infinite cases that are awkward to work with in this direct style. The main disadvantage of this approach is that you don't get combinators that magically upgrade themselves when used with lenses or traversals or prisms, etc. to require a little bit more from the user for nice reasons. This means you wind up exploding the number of combinators you use with the number of types of optics you allow for, or things become deeply magical for non-fundamental reasons as you try to fumble your way back towards the generality of the existing `lens` encoding but now on a more ad hoc basis.
I'm aware of the differences, I meant more 'libraries for both' than 'swap them as you wish'. As for the rest - I could try to debate you and refute these points, but I think that at this stage, it comes down to personal preference. Well, we could try and measure the productivity of these two approaches, that might help e.g. companies choose :) (Ok, I'll try to answer some: * Separation of concerns is enforced by TEA, whereas in Reflex it comes down to the programmer's discipline the same way it does in e.g. PHP or JS, and if necessary, you can make an exception. * DOM manipulation - you can choose to think about it this way, but in practice you almost never edit DOM directly, usually you use one of the many combinators. * Pre-rendering - reflex-dom has added \`StaticWidget\` some time ago. I haven't yet tested what all it can do, but it works well at least for the so called 'app shell'. * Server/client - it's true that DOM itself doesn't have a notion of time, but the values it works with do. I sometimes think about it as TEA, where each component has its own model/update function. Implementing Miso in Reflex is trivial (this is the closest public example I can think of: [https://www.reddit.com/r/reflexfrp/comments/85ov8a/how\_to\_share\_auth\_tokens\_throughout\_all\_the\_app/dvzjv0d](https://www.reddit.com/r/reflexfrp/comments/85ov8a/how_to_share_auth_tokens_throughout_all_the_app/dvzjv0d)), implementing Reflex in Miso not so much (AFAIK, though I haven't tried that). Oops, I wasn't setting out to write this...) The main point was that my end goal is to have libraries like x-reflex and x-miso/concur, which can both work with x-server on the backend, that's all :)
Great to hear. :) Please share if you manage to get some nice fractals out of it!
The reason I am not using this yet, even though it's really cool and I would love to have it, is none of those. It's that the cost of resolving the parameters is quadratic in the number of parameters. This was also mentioned in the previous thread. Has this now been addressed?
Yes that is the showstopper for this feature. It's quadratic in the number of parameters. So without some good benchmarks, I wouldn't recommend using it.
I'm so happy to hear that it's helpful :) [And there is a way you can buy a copy!](https://www.patreon.com/isovector)
I don't think this can be addressed. It'll likely to take a toll on compile times, but that is generally true for anything that does anything useful at type level.
Hasktorch sounds great - how feature complete is it? I presume in order to implement it you needed to replicate pytorch's auto grad mechanisms (using the backprop library), which could be potentially quite a bit of work?
&gt; Unless we perform some real IO operation, the operation being benchmarked can get completely optimized out in some cases. We use a random number generation in the IO monad and feed it to the operation being benchmarked to avoid that issue. This might be the same situation for which I created a [pull request](https://github.com/bos/criterion/pull/199) for criterion, which adds `nfAppIO` to avoid this.
stack doesn't initialize the msys2 environment to a state where it's generally usable. In this case you're missing an update to `ca-certificates`. If your `pacman` isn't too far away from the required version `pacman -Sy ca-certificates` should fix it for you. If it's too far out of sync, you'll have to upgrade the msys2 runtime, then pacman and ca-certificates.
I don't really know yesod, but one way you can do it is deploy your app once and then use something like nginx to link different domains to different static folders. Then for example if you have `foo.com/static/css/style.css` and `bar.com/static/css/style.css`, and your yesod templates (is that a thing?) require `/css/style.css`, that means that depending on the actual domain in the address bar you'll load a different stylesheet. All of the above would of course work properly only if the "interface" to the static files is the same. Also only works for static files, I wouldn't know a yesod-specific answer if you want to load different templates/html files.
I wrote one soon after that post: https://www.reddit.com/r/haskell/comments/2413fc/idiomaticlenshs
I assume that `Math.NumberTheory.Primes.Testing` module comes from `arithmoi` package: * https://hackage.haskell.org/package/arithmoi-0.7.0.0/docs/Math-NumberTheory-Primes-Testing.html In that case you need to tell `ghc` that you depend on `arithmoi` package. There're different ways to it depending on which build tool you're using (`cabal` or `stack`). And I'm sure there should exist one-liner how to do this without creating package. But probably one of the simplest and straightforward solutions is to create new package (with `cabal init`) for example and add `arithmoi` package to `build-depends` field in your `.cabal` file. I've wrote tutorial about Haskell build tools so you can read about more details here: * https://kowainik.github.io/posts/2018-06-21-haskell-build-tools.html If you use `stack` you write `stack repl --package arithmoi` and then load your module inside REPL (if you want to avoid creating package). Probably something similar is possible with `cabal` as well. And you can have a look at `cabal-env`: * https://github.com/hvr/cabal-env
As u/primitiveinds suggested, you are probably better using a reverse proxy and setup 'virtual hosts' (that's how it called and it's designed for that). You can either use Apache or nginx. I personnaly use apache with docker (and docker compose) and it is really simple to setup and really powerfull (https://httpd.apache.org/docs/2.4/vhosts/examples.html). Internally, you just need to have a different root for the 'bar.com'.
Well, usually dependent types allow to prove such things to compiler. For example, if you take Idris or Agda programming language then `n + m = m + n` is a theorem from language point of view and needs to be proven. Once proven (this theorem is very simple and usually is already proven in standard library) then you can apply this theorem inside your function definition. Most of the time languages with dependent types provide relatively convenient ways to apply theorems.
All of Torch (and cutorch) are feature-complete with dynamic and static interfaces! The nn library is a little lacking, however: we will probably release with a few basic nets and have a "call for architectures" to finish backprop-ing up these functions. It takes time reading source code and adding the correct dependently-typed constraints.
I tried it. Outputs were beautiful, thank you for sharing! Nitpick on instructions for compilation: GHC doesn't have optimization level `-O3`, and 3 or greater means `-O2`. Also, I tried compiling with `-O` and `-O0`. I don't think `-O2` is necessary. `-O` was not different compared to `-O2` in my environment. `-O0` was slow though.
I should add that all of the THNN c-calls are accessible - so we are technically "feature complete"... but the nn function signatures are opaque, occasionally with performance hacks in the arguments, so I am reading through them and making them all user friendly. 
Thanks for the answer, but this is not what I'm asking :)
I already have nginx as a reverse proxy. What I was asking was what's the better way to handle two websites that share most of the code in Yesod. I guess I didn't explain myself very well as all the answers are off the mark so far :D What do you mean with "have a different root"?
Have a look at the [diagrams](https://hackage.haskell.org/package/diagrams) library. It's perfect for this sort of thing - you could probably do something like this in a few simple lines of code.
Typo on the 2nd line: "hasell"
FY(and OP's)I: For GHC, `-O` is the 'release level optimization', and `-O2` is 'try really hard'.
Thanks for pointing out! Didn't know that. And yeah, no optimization was slow here as well.
The reason they're mentioning that as a solution is that your original post specified "it'll need to have a different look" So they're saying you could handle that by having literally the same code not know which it's talking to, but use nginx to handle serving one set of css styles to one domain and a different to the other. 
Knew about `diagrams`, but didn't know it could be used for pixel-by-pixel coloring as well. Thanks for the tip!
Wow. How _could_ I miss that! Thanks!
&gt; What do you mean with "have a different root"? I meant starts all "internal" routers with `/internal/` (of foo) and all customers with /customers/ (or bar). You can do this with a subroutes in the yesod route TH. To go back to your question (now I understand it ;-)), I'm facing a similar problem : wanted to expose to the outside world some bit of our internal website. Regardless of the implementation , the question is, do you need two servers or can you do with one. The advantage of two servers is to isolate your internal server from the outside world. That way, you don't have to worry about people attacking your internal site, pinging it etc ... Bandwidth and resource problems etc ... Depending on what you want to expose, you could just have the same app, but hide everything internal behing a reverse proxy AND replicate the database (in realtime or not) with a readonly copy. In that case, you don't have to worry about security. However, you are strongly limiting what's the user can do. Once you have decided to use one app, subsite or not doesn't change anything (as everything should be covered by the reverse proxy). Regardless of that, if the app share the same db (schema and data) it's much easier to have on app, which you can duplicate or not. One trick I use (between staging version and production) to change the look and feel of the same app on different server, is to use docker (compose) to actually export different directory or files with the same. You could do the same for your css, also that could also be resolved via reverse proxy. 
Yeah, my two apps would share the same db and basically 80% of the logic. The "different look" bit is not as important and it probably made you all focus on the wrong aspect :D I don't have many resources/security concerns. I was thinking about a solution like this one: https://github.com/yesodweb/yesod/wiki/Domain-based-routing 
&gt; Implementing Miso in Reflex is trivial Miso is a lot more than just TEA. Implementing TEA in reflex-DOM is trivial, sure. But implementing miso in reflex-DOM is impossible. The way reflex handles events is fundamentally different (event delegation vs. manually binding events). Reflex doesn't have a notion of a virtual DOM, if it did, you'd have a duplicate representation of the DOM (one being the expression graph, the second being the virtual DOM data structure), which would be unnecessary at best, inefficient at worst. &gt; it's true that DOM itself doesn't have a notion of time, but the values it works with do. I sometimes think about it as TEA, where each component has its own model/update function. TEA can also have a notion of time (just discrete) related to values, but it only makes sense in the context of events. Where events allow the user to travel through the application state at each point they were fired (see Elm's time traveling debugger). &gt; reflex-dom has added `StaticWidget` some time ago. I haven't yet tested what all it can do, but it works well at least for the so called 'app shell'. Without a rose tree representation, or something isomorphic to a rose tree, you'd have to blow away the existing DOM and repaint. &gt; DOM manipulation - you can choose to think about it this way, but in practice you almost never edit DOM directly, usually you use one of the many combinators. For inefficient DOM manipulation the combinators might work well, but in practice I've seen people resort to DOM Fragments or just naively blowing away the entire DOM and repainting. Wish you the best on the project!
Oh, yes, I have seen this sort of problem many times and I guess that is the right solution for it. I think I opened a ticket to fix that in gauge but never got around to fix it. Maybe we can pull your fix in gauge as well. It will be great if you can send a PR for gauge too.
&gt; I don't think this can be addressed. You mean it would be too complex to be practical? Because it's possible to implement any lambda at the type level, so in particular it's possible to implement lookup that is better than O(n^2). We really need more work on making type level programming easier. In the meantime, it still might be best to implement features like this using quasiquoters.
The lookup is `O(n)`, but we have `n` lookups (one per `(!)` call). So it's not about inconvenience of type-level programming. &gt; In the meantime, it still might be best to implement features like this using quasiquoters. If your concern is compile-time performance, this is bad advice. TH is slow in my experience. It also forces a stage restriction, its syntax is more heavyweight, and for this particular feature I would have to reimplement an entire Haskell parser (the way Nikita did it in https://hackage.haskell.org/package/record-syntax). IOW no way I'm using TH for this :)
If you're experienced in F# and SML how about rewriting some of your code in those languages in Haskell?
From your comments and the post above, if I get your question right, you're just trying to avoid duplicate code in two very similar web applications. There are two ways that I can think of to work with two applications that share a majority of their code, and this doesn't go only for Yesod but applications in general: 1. Write the shared code as a library and make it more generic so it can be shared by two host applications. 2. Develop your services in an SOA or micro-service based design so that you can isolate the shared functionality in one place and the application accessed by the end user can interface with the shared service for the required functionality. In general it's a good idea to avoid duplicate code by merging them together.
The `Cartesian` stuff looks a lot like SKI.
You can do it by fixing the scale of the output coordinates. But more likely you would define color as a function of x and y coordinates viewed as real numbers. This would result in a simpler description of the fractal. It would also allow the picture to scale arbitrarily as a vector graphic, as well as rendering as a pixel graphic like you do now.
Cool. I should look into it. 
There's tons! Here's an arbitrary pick - Structure and Interpretation of Computer Programs - Clean Code - C programming language, 2ed - Types and programming Languages - Introduction to Algorithms - Computer Architecture: A Quantitative Approach - Parallel and Concurrent Programming in Haskell - Code: The Hidden Language of Computer Hardware and Software
If they share the same db instance (ie same data), it's usually easier to have only one application that two. That makes migration and deployment easier.
&gt; Math.NumberTheory.Primes.Testing You should install the arithmoi package. For example, `cabal update &amp;&amp; cabal install arithmoi`
Since the data for each listing is below a key called "data", and "data" is a keyword, you can't just use generic to derive a datastructure that will accept this. But you can decode into a `Value`, which is the AST of a JSON data type, and then decode a derived `Listing` from that part of the JSON AST. data Listing = Listing { id :: Int , name :: Text , symbol :: Text , website_slug :: Text } deriving (FromJSON, Generic, Show) getListings :: IO (Maybe [Listing]) getListings = do r &lt;- get "https://api.coinmarketcap.com/v2/listings/" return $ case decode (r ^. responseBody) of Nothing -&gt; Nothing Just v -&gt; flip parseMaybe v $ withObject "" $ \o -&gt; o .: "data" 
You can do this with \`forwardOptions\` from \`optparse-applicative\`. It can be applied to whole parser or a subcommand. testCmdP, testP :: Parser \[Text\] testCmdP = hsubparser $ command "cmd" (info testP mempty) &lt;&gt; command "cmd-args" (info testP forwardOptions) testP = many (strArgument mempty) main0, main1 :: IO () main0 = execParser (info (helper &lt;\*&gt; testP) forwardOptions) &gt;&gt;= print main1 = execParser (info (helper &lt;\*&gt; testCmdP) mempty) &gt;&gt;= print
This is great stuff!
Hello, I have problem with installing snap: `cabal install snap-templates` `Resolving dependencies...` `cabal.exe: Could not resolve dependencies:` `[__0] trying: snap-templates-1.0.0.1 (user goal)` `[__1] next goal: template-haskell (dependency of snap-templates)` `[__1] rejecting: template-haskell-2.13.0.0/installed-2.1... (conflict:` `snap-templates =&gt; template-haskell&gt;=2.2 &amp;&amp; &lt;2.13)` `[__1] rejecting: template-haskell-2.13.0.0, template-haskell-2.12.0.0,` `template-haskell-2.11.1.0, template-haskell-2.11.0.0,` `template-haskell-2.10.0.0, template-haskell-2.9.0.0, template-haskell-2.8.0.0,` `template-haskell-2.7.0.0, template-haskell-2.6.0.0, template-haskell-2.5.0.0,` `template-haskell-2.4.0.1, template-haskell-2.4.0.0, template-haskell-2.3.0.1,` `template-haskell-2.3.0.0, template-haskell-2.2.0.0 (constraint from` `non-upgradeable package requires installed instance)` `After searching the rest of the dependency tree exhaustively, these were the` `goals I've had most trouble fulfilling: template-haskell, snap-templates` It seems to be problem with impossible dependicy required ( [template-haskell](http://hackage.haskell.org/package/template-haskell) (&gt;=2.2 &amp;&amp; &lt;2.13) ) so I tried to update template-haskell and compile snap-templates manually then exactly the same error occured. Any ideas?
The version of template-haskell is tied to GHC. You could use an older GHC, but the right long-term solution is for the maintainer of snap-templates to update the package by making it compatible with the newer dependencies. I suggest you file an issue on the project's github issue tracker.
Thanks.
Hmm - that is very impressive. In order to support a more pytorch API I guess it is necessary to typeclass all the operations so that they can operate over backprop 'lifted' types? Does that go against the grain of how backpack is used in this project? 
That used to be how we did it and it's definitely backpack-compatible! It was something along the lines of "write a bunch of typeclasses, fill out one instance with backpack, and have backpack fill out 14 tensor instances." I was afraid it wasn't very backpack-y, so I got the approval of ezyang via the PyTorch slack : ) It turns out that the indirection was a lot of code bloat and typeclasses are incredibly specific to Torch, so we nuked them and things are much more simple. This means that every concrete torch type (in the form of FloatTensor, LongTensor, ByteTensor, etc) carries it's own suite of functions at the term level (instead of also having GHC carry a type dictionary). This is fine because you usually only care about doing fancy tensor-ops on one types. There are a couple more implementation nuances, that I wont get into. A super dumb, annotated code block to explain this looks something like: ``` -- choose your default precision: import Torch.Cuda.Float -- now you have all the functions! -- If you want to do something fancy to your indexes: import qualified Torch.Cuda.Long as Ix -- and all the Long specific functions are now at your disposal. ``` Like I said, super dumb. Haha, I am fighting the urge to explain more, but I think that's fine for now : ). When we release there will be an end-to-end example which might help make things a little more clear.
This should be fixed now.
That makes sense, yeah - almost never you'd want more than one type of real / one type of index. What I was trying to refer to is that pytorch also overloads the 'backprop' operations, so if you have a function using some Tensors - you can also use that function as part of your neural net, all the usual tensor operations are also 'backprop' functions. In earlier versions of pytorch this was done using a wrapper which they called 'Variable', (in the latest version the same Tensor type is used for both, you can chose on initialisation if you want gradient or not) Could you also? &gt; -- choose your default precision: import Torch.Backprop.Cuda.Float The types would be a little different I'm thinking, with the Tensors wrapped in BVar? I'm very excited to have a closer look when I can... currently i have a Haskell application which communicates with a pytorch application using json.
Yup, Tensors have an instance of `Backprop` from Justin Le's library. Perhaps this recent test suite can help shed a little light: https://github.com/hasktorch/hasktorch/blob/master/core/tests/Torch/Static/NN/LinearSpec.hs 
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [hasktorch/hasktorch/.../**LinearSpec.hs** (master ‚Üí 0090135)](https://github.com/hasktorch/hasktorch/blob/0090135457543925c33c7374c93f15b612595893/core/tests/Torch/Static/NN/LinearSpec.hs) ---- 
Well, generally the thing to do is define `quoteDec`, which describes what to do when the quotation appears as top-level code. It should return e.g. a `data` declaration (`DataD`). But it‚Äôs not really a requirement afaik‚Äîif you don‚Äôt mind forgoing the quasiquote syntax, you can just use the same function for everything, and call it with a splice, e.g., `$(quoteExp yourQuasiquoter "input string")` instead of `[yourQuasiquoter|input string|]`, or set `quoteDec` to be the same function as `quoteExp` and just ensure that you return a declaration when needed. The separate functions just let you know in what context the quoter was called; if you don‚Äôt need that information, you can ignore it. 
&gt; I always thought 2 is treated as 2 :: (Num a) =&gt; a That's another way to think of it. Since you derived the instance for `Num`, it's perfectly fine to typecheck `2` as `Num a =&gt; A a`.
I wonder if anyone would find the `(Maybe (a, b) -&gt; b) -&gt; [a] -&gt; b` type easier or more intuitive to work with. foldr :: (Maybe (a, b) -&gt; b) -&gt; [a] -&gt; b foldr f = go where go [] = f Nothing go (x : xs) = f (Just (x, go xs)) sum = foldr $ \ case Nothing -&gt; 0 Just (x, acc) -&gt; x + acc sum = foldr add where add = maybe 0 $ uncurry (+) It‚Äôs not as elegant or concise at the use site as `sum = foldr (+) 0`, but it does have the property that the *function* passed to `foldr` decides what to do in the case of empty input, rather than the call site passing a value. It just feels more ‚Äúoperational‚Äù while the standard definition feels more, well, ‚Äúdefinitional‚Äù‚Äî`foldr f z xs` replaces all the `:` in `xs` with `f` and the final `[]` with `z`.
Yes, I thought about that but it looks too much effort for what I need.
You don't know where I can look at some code, do you? It's a pity I cannot find more examples easier online..
In that case you can still setup two different routes on the same application and have the reverse proxy route to the right now. Then you can have your views reused. For example, your application can implement endpoints like this: ``` /customer/...&lt;action&gt; /internal/...&lt;action ``` Then your reverse proxy (Nginx in your case) can route things accordingly. ``` customer.website.com/...&lt;action&gt; ----&gt; &lt;internal_host&gt;/customer/...&lt;action&gt; internal.website.com/...&lt;action&gt; ----&gt; &lt;internal_host&gt;/internal/...&lt;action&gt; ```
ok thanks for confirming. 
What makes \`streamly\` performance so much better compared to \`streaming\`?
Hey! I am building a rest API and I have a function that runs a test and then clears the database. However I realised that if a database error was thrown the database did not get cleared and would muddle future tests. I created the following workaround, and I am wondering is there a more idiomatic way to do this/does this function exist? ```haskell runAnyway :: IO a -&gt; IO b -&gt; IO b runAnyway a b = a `E.catch` (\\(e :: E.SomeException) -&gt; b &gt;&gt; E.throwIO e) &gt;&gt; b ````
Of course, if you're testing locally, you won't see network latency - that will vary depending on where the server and client are located. You could always try putting it online on an AWS instance or something like that, if you want to see some realistic network latency.
Does anyone have good resources on "reversing the arrows" in haskell? I know some basic category theory, and my instinct for reversing `(a ‚Üí b) ‚Üí (c ‚Üí d)` would be to just flip the middle arrow, giving `(c ‚Üí d) ‚Üí (a ‚Üí b)` (just reverse the morphism's direction). But the post seems to flip the parenthesized arrows like this: `(b ‚Üí a) ‚Üí (d ‚Üí c)`. Why is that?
Why do you consider testing to be a villain here? Maybe a non-all-powerful sidekick? But surely you wouldn't advocate apprehending all tests because one bug wasn't caught by them, would you? Is the police villainous if they don't catch all criminals?
I meant ‚Äútesting‚Äù to encompass all facets of that activity: writing tests (is this labor worth it?), running tests (are we wasting time running a test over and over?), and figuring out if we‚Äôre testing everything we think we‚Äôre testing (this is just hard).
So, continuing with the analogy, would you say policing is villainous if we don't catch all criminals? Or do you see some difference?
I am not an expert on "streaming" interals, but I guess mostly because of stream fusion. The continuation version of streamly which does not fuse shows performance almost identical to streaming. The direct style stream implementation of streamly is very much like vector, it optimizes and fuses well and shows similar performance as vector. Streamly uses both direct and continuation styles where they are strong, getting the best of both worlds.
It‚Äôs a terrible analogy that has no bearing here so I will not continue it. No human had malicious intent or even self-interest in their heart when undertaking any action. That testing can not be a corporeal villain of our arithmetic tragedy is the entire point. The code had a bug; the takeaway is not that the author should feel bad, but that our testing setup could do with improving. That is a shared burden that all of us can help with.
I will explore this solution for sure, thanks!
Thanks!
I feel like this is just `Control.Exception.finally`.
I think it's troubling that this submission is being downvoted within minutes of its submission, as if it's irrelevant or inappropriate for this community. There's lots of people on here who always like to stress community and civility, will they show up for this one? I hope to god Julie isn't targeted with harassment for saying this. I hate that I have to say that. When I started with Haskell it would have been unthinkable to me that that would happen, but communities grow, and change, and revert to the mean. I have seen too many people burned out by the often abusive dynamics of our tiny corner of the industry. I hope Julie sticks around with us for much longer and this community can get through these growing pains right before it becomes intractable and endemic (too late?).
&gt; I think it's troubling that this submission is being downvoted within minutes of its submission It's very likely this is just Reddit fuzzing the numbers. The score you see is intentionally fuzzed quite a bit (especially in the first half hour or so) to prevent vote manipulation.
Worth noting Julie did not use the #MeToo hashtag. It's my understanding that this hashtag is specifically related to physical sexual abuse, not the psychological abuse she speaks of here. Is this understanding correct?
I downvoted this post because the title is completely unsubstantiated. The linked tweets don't mention Chris Allen (or anyone else) by name, and the #MeToo reference implies some sort of sexual harassment, which isn't mentioned in the linked tweet threads at all. This is a smear job by some anonymous account. It is meant to troll and stir up hostilities. This is **the exact opposite** of community and civility.
The submitter editorialized and since it's a new account i'd say it's a coin flip whether they're trying to stir shit and attract negative attention to Julie or pose a discussion in good faith.
Betcha a nickel it was Chris Allen.
I live too far to apply, but I am curious to hear about how you are using the state-machine library? I have been trying to make the case for using state machines on a formal method project at work.
I agree that the title is bad, but I hope it doesn't delegitimize her tweets. I wouldn't be upset to see the mods take this post down and replace it with a better titled post
Agreed, and something with title like this should be deleted ASAP.
You have to have your head pretty deep in the sand to think there's any chance she's not talking about Chris Allen. For the most part I agree with you that the title is harmful to both the community and to Julie's message and I'd hate for there to be a witch hunt. But this guy has caused quite a lot of pain and it's not good to ignore it.
If there is some problem between Julie and Chris that needs to be mediated, that is private business, and it absolutely shouldn't be conducted in the public sphere. Neither Julie nor Chris have made any sort of specific, public claims about their situation. This post is unsubstantiated shit stirring. If I were in either of these person's shoes, I would *hate* to have this posted and publicized by someone I didn't know.
It's not really "editorializing" so much as it's "literally making stuff up." The title makes unsubstantiated claims about a person that is not named in the linked tweets and implies sexual abuse, which is (again) not in the linked thread. This is 100% shit stirring. There's no way someone wants to have a good faith conversation and opens with this.
I disagree with the premise that content posted publicly to twitter doesn't have a right to be reposted elsewhere. Again, I agree that the title is bad. If she doesn't call anyone out by name, neither should any repostings. But a link to these tweets on this subreddit is fair game. If she didn't want this getting public attention she wouldn't have put it on Twitter of all places. She was very careful to leave the private parts out, and I think the message about the toxicity in this community is one worth discussing.
&gt; There's no way someone wants to have a good faith conversation and opens with this. Sure there is. Step 1: Ignore the title Step 2: Consider the tweets Step 3: Be very oblivious if you don't think it's Chris Allen, I guess.
You're right about the #MeToo thing, but the context clues are pretty damn clear about Chris Allen
Nothing I'm saying relies on the premise you mention. Julie tweets about a toxic subset of the Haskell community -- that's fine. Linking to it and having a discussion on Reddit -- that's fine. An anonymous account making inferences and allegations on a social media platform without the knowledge or consent on either of the alleged parties is harassment and abuse, to *both* sides. Dealing with an abusive situation in public is immensely difficult and painful for the abused and can easily trigger panic attacks and other PTSD symptoms. We should treat Julie's claims seriously. Part of that is *not escalating the situation*. This post serves solely to escalate the situation.
Well then I don't really understand why you responded to my first comment with such vigor if it was exactly the thing you seem to be agreeing with here.
Please everyone read Simon Peyton Jones on the value of having respect in the Haskell community. &gt;There's no denying that our shared dialogue as a community has taken a nose-dive in the last few months. If this change of tone becomes established as a norm, I believe it will corrode our common life, perhaps permanently, and harm our shared purpose. I would be heartbroken if that happened. [https://mail.haskell.org/pipermail/haskell/2016-September/024995.html](https://mail.haskell.org/pipermail/haskell/2016-September/024995.html)
Typical politics. Here we are encountered with an important issue described delicately and sincerely, and the only thing we can talk about is the part that matters least: The fucking title. Mods please just remove this and repost with a better title.
I'm Julie and I downvoted it because the title is really inflammatory. Nothing I said there has anything to do with #MeToo and that's a pretty serious implication to make. As others have pointed out, my tweets were public so they are otherwise fair game for posting here, but not with this title which is a lie to the extent a hashtag can be. I don't know who posted it here or why. I do not generally participate in this subreddit, but I thought I should at least come clear that up.
Thank you for clearing that up. I completely disregarded the title because it's that sort of dismissal *on procedural grounds* that I've seen used to similar effect in other communities. The title most definitely poisoned the well and I would have seen that if I had my morning coffee and understood the nuance of the hashtag more but what is there to do once the well's been poisoned? You're not the only one affected by this and I've seen people I cherish grow distant or outright leave because of the same dynamics with the same group of people. That makes me rash and impatient to just *have this conversation already*. I'm sorry about how the topic got on this subreddit. Thank you for speaking out.
As a victim of abuse, I tend to act emotionally when discussing this sort of thing. I misread your original reply, and I apologize for speaking harshly.
There's a lot going on in this post, but I think the gist is roughly: * Stack has a cache for quickly referencing data in the Hackage index. This cache is very slow to build and takes a lot of memory. * Allowing multiple indexes makes any given package identifier potentially ambiguous. * If we only allow one index, we can build a smarter cache that is much faster to build. Is this about right? Couldn't you allow multiple Hackage indexes by having cabal files be indexed by the Hackage index they came from too? I've never needed an extra index, but I can see how it would be useful. Also, can anyone explain how Hackage overlays fit into this picture? I don't really know the first thing about them other than that they're pretty useful for testing with GHC HEAD among other things.
That would probably require a big change to nixpkgs to do. You can always access the path by just referencing the `doc` field of the derivation; shouldn't be too hard. Alternatively, you can use `ghcWithHoogle` to use hoogle for docs without having to browse the files manually.
[removed]
Check out the `type-level-sets` and `dependent-map` packages for variations on this theme.
You could use symlinkJoin in order to stitch the outputs back together but I don‚Äôt see what the advantage of this is.
I recommend reading the paper "Out of the Tar Pit". It covers what I'd deem good practices.
Polymorphism: are you being more specific than necessary? For example, did you write a function `[Int] -&gt; [Int]` which could be generalised to `Num a =&gt; [a] -&gt; [a]`, `Ord a =&gt; [a] -&gt; [a]`, or even just `[a] -&gt; [a]`? This will make your code easier to understand, and allows code re-use. Algebra: does your API compose in common algebraic ways? For example, are there commutative or associative operations, or left or right identities? If there are edge cases that prevent some interesting algebraic property, then is the edge case really necessary? Mathematical properties are a good sanity check for program design, and help you write good tests.
I found this talk pretty cool. While the examples use Liquid Haskell, the talk itself is more about the core ideas such as how the type-checker works (in very broad strokes), what the obstacles are making refinement types mainstream and so on. I found it more useful to understand stuff compared to jumping into the papers related to Liquid Haskell which are heavy with jargon. If folks are interested in Liquid Haskell but found the paper(s) hard to read, I recommend watching this for a more approachable introduction :).
I'll use this library as soon as the named decoders are in place.
I like `t:Foo` best, though `'type Foo'` is nice and explicit, though, seems clearer. Having it match the haddock anchors is nice, though. I have thought about this some in the context of using markdown as an alternate syntax. I think that markdown for haddock is still a very good idea, and I hope that someone implements it. I think we could get away with only having the backtick marks be used for references and inline code. In other words, backticks would be used for everything that `@`, `'`, and `"` are currently used for. The inline code blocks would have every identifier be a hyperlink, and so they can be used for referencing one or more identifiers. However, we have the same ambiguity problem there. I propose that it would work by suffixing the context in parenthesis, for cases where it is ambiguous: ``` data Foo = Foo Int -- |# `func` returns a `Foo`(t) by using the `Foo`(v) constructor. -- Its overall type is `Int -&gt; Foo`. func :: Int -&gt; Foo func = Foo ``` Since `Int -&gt; Foo` only parses as a type, not as an expression, resolving those names is unambiguous. It might give a warning if any of the identifiers are not in scope and no domain is specified. (`|#` is a made up convention to start a markdown haddock)
Yes, there exist more idiomatic way for RAII. There's `bracket` function for such cases. It ensures that your resources will be cleaned up properly: * https://hackage.haskell.org/package/base-4.11.1.0/docs/Control-Exception.html#v:bracket
Why not do like template-haskell does? Where `''Foo'` would describe `data Foo`, and `'Foo'` would be `data Bar = Foo`.
Just wondering, but GHC 8.4 didn't have official ARM releases. Is there any chance of official ARM releases coming back for 8.6.x?
I searched around for a while before responding but couldn‚Äôt find any solid examples of using `quoteDec`. But again, it looks like it only matters what you *return* from your quasiquoter; you can just specify `myQQ = QuasiQuoter { quoteExp = f, quoteDec = f, ‚Ä¶ } where f = ‚Ä¶` if you want, and it‚Äôll generate an error if the user tries to use an expression in a declaration context or vice versa. The advantage of knowing the context is that it can let you produce better error messages by bailing out earlier if you encounter the wrong thing for the context.
Today I have started the branch :)
thanks anyway, this is useful in other ocasions.
I'm in the progress of updating a Yesod web app to Yesod 1.6. One big change is the use of \`MonadUnliftIO\`. Since this is supposed to replace \`MonadThrow\`/\`MonadCatch\` (among others), I'm trying to get rid of all those type classes in my type signatures. However, some code uses \`sinkDoc :: [MonadThrow](https://www.stackage.org/haddock/lts-11.17/conduit-1.3.0.3/Conduit.html#t:MonadThrow) m =&gt; [ParseSettings](https://www.stackage.org/haddock/lts-11.17/xml-conduit-1.8.0/Text-XML.html#t:ParseSettings) \-&gt; [ConduitT](https://www.stackage.org/haddock/lts-11.17/conduit-1.3.0.3/Data-Conduit.html#t:ConduitT) [ByteString](https://www.stackage.org/haddock/lts-11.17/bytestring-0.10.8.2/Data-ByteString.html#t:ByteString) o m [Document](https://www.stackage.org/haddock/lts-11.17/xml-conduit-1.8.0/Text-XML.html#t:Document)\` from xml-conduit-1.8.0. How can I call \`sinkDoc\` without being forced to introduce \`MonadThrow\` in the signatures of all the callers?
Thanks for the reply! I've used bracket before didn't piece together it would fit this scenario though. 
[@name's latest tweet](https://i.imgur.com/PoWr1Aw.jpg) [@name on Twitter](https://twitter.com/name) - ^I ^am ^a ^bot ^| ^[feedback](https://www.reddit.com/message/compose/?to=twinkiac)
Never use a blanket `SomeException` and swallow it like in your example. You'll end up swallowing async exceptions, which have to be re-thrown because that category includes e.g. `ThreadKilled`.
I hope to write a longer post once we got more experience using it, but in short: we do whole system black box testing. The commands that we generate correspond to actions that the users/admins can perform. A rough sketch of what this might look like can be found here: https://github.com/advancedtelematic/quickcheck-state-machine/blob/master/example/src/CrudWebserverDb.hs I think the [ABZ](https://link.springer.com/conference/abz) community (Abstract State Machines, Alloy, B, TLA, VDM, and Z) make quite a good case for using state machines to model systems. I find Lamport's paper [Computation and State Machines](https://www.microsoft.com/en-us/research/publication/computation-state-machines/) and Jean-Raymond Abrial's book [Modeling in Event-B: System and Software Engineering](http://www.event-b.org/abook.html) particularly good. There's also many interesting ideas about statistical testing in the [Cleanroom](https://sci-hub.mu/https://ieeexplore.ieee.org/document/5387350/). literature. They also make use of randomly generated test cases, but go much [further](https://sci-hub.mu/https://ieeexplore.ieee.org/document/207234/), with what statistical inferences one can make from those. 
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [advancedtelematic/quickcheck-state-machine/.../**CrudWebserverDb.hs** (master ‚Üí aa38cb0)](https://github.com/advancedtelematic/quickcheck-state-machine/blob/aa38cb0aa2c6c0f61e5d38e6e5b385c4eb644ee1/example/src/CrudWebserverDb.hs) ---- 
It seems that your comment contains 1 or more links that are hard to tap for mobile users. I will extend those so they're easier for our sausage fingers to click! [Here is link number 1](https://link.springer.com/conference/abz) - Previous text "ABZ" ---- ^Please ^PM ^/u/eganwall ^with ^issues ^or ^feedback! ^| ^[Delete](https://reddit.com/message/compose/?to=FatFingerHelperBot&amp;subject=delete&amp;message=delete%20ID_HERE) 
Can you provide a link to the paper please?
Link and commentary: https://blog.acolyer.org/2015/03/20/out-of-the-tar-pit/
I hope so; unfortunately I've been having a bit of trouble building reliable bindists for ARM recently. It would be great if someone could step up to help pin down some of these issues.
I rather like 'type Foo' in that it is more legible than the alternatives when you are stuck reading raw haddock.
I don‚Äôt write Haskell professionally anymore, and my time and energy is mostly focused elsewhere. Furthermore, even if I was still focused more on Haskell, I‚Äôm not sure I‚Äôd feel comfortable committing to such a role. It sounds extremely interesting, but I just don‚Äôt think I have the necessary spare time to do it. I do appreciate the sentiment, though.
&gt;Polymorphism: are you being more specific than necessary? I have seen this advice before. But in practice, I have found that this just results in more type errors because the type checker having hard time inferring types...
Would it be possible to write a new version of `sinkDoc` that uses `MonadUnliftIO`?
I think it's a balance. For instance, I only occasionally prefer generalizing `Int` to `Num a =&gt; a`. Even though there are other `Num` instances with the semantics I was looking for in `Int`, I don't necessarily know that's what I'm getting. I don't ordinarily generalize to `Num` unless A) I deliberately want to use this function with multiple numeric types in my code or B) It's in a library I'm publishing where other people might have compelling reason to do so.
Here's an example demonstrating all the ways in which you can declare functions using Template Haskell and QuasiQuoters: {-# LANGUAGE TemplateHaskell #-} module Lib where import Language.Haskell.TH import Language.Haskell.TH.Quote import Language.Haskell.TH.Syntax -- There are two ways to add top-level declarations in Q: -- * via addTopDecls -- * by returning a list of declarations -- -- And there are two ways to run Q computations: -- * via QQ -- * via TH defineFooViaAddDeclsInQQ :: QuasiQuoter defineFooViaAddDeclsInQQ = QuasiQuoter { quoteExp = \_ -&gt; do decls &lt;- [d|fooViaAddDeclsInQQ :: String fooViaAddDeclsInQQ = "foo!"|] addTopDecls decls [|()|] , quoteDec = error "defineBarViaQQ must be used as an expression" , quotePat = error "defineBarViaQQ must be used as an expression" , quoteType = error "defineBarViaQQ must be used as an expression" } defineFooViaAddDeclsInTH :: Q Exp defineFooViaAddDeclsInTH = do decls &lt;- [d|fooViaAddDeclsInTH :: String fooViaAddDeclsInTH = "foo!"|] addTopDecls decls [|()|] defineFooByReturningFromQQ :: QuasiQuoter defineFooByReturningFromQQ = QuasiQuoter { quoteDec = \_ -&gt; do decls &lt;- [d|fooByReturningFromQQ :: String fooByReturningFromQQ = "foo!"|] pure decls , quoteExp = error "defineBarViaQQ must be used as a declaration" , quotePat = error "defineBarViaQQ must be used as a declaration" , quoteType = error "defineBarViaQQ must be used as a declaration" } defineFooByReturningFromTH :: Q [Dec] defineFooByReturningFromTH = do decls &lt;- [d|fooByReturningFromTH :: String fooByReturningFromTH = "foo!"|] pure decls {-# LANGUAGE QuasiQuotes, TemplateHaskell #-} module Main where import Lib bar :: () bar = [defineFooViaAddDeclsInQQ||] baz :: () baz = $(defineFooViaAddDeclsInTH) [defineFooByReturningFromQQ||] -- Top-level TH call split the source into separate "declaration -- groups", and so the definitions added by addTopDecls in the above -- TH calls only become visible after this line. defineFooByReturningFromTH -- | -- &gt;&gt;&gt; main -- ("foo!","foo!","foo!","foo!") main :: IO () main = print (fooViaAddDeclsInQQ, fooViaAddDeclsInTH, fooByReturningFromQQ, fooByReturningFromTH) 
Why not borrow from the import syntax and refer with `'Bar(Foo)'` to the constructor `Foo` of type `Bar`? 
I think the problem is when you allow `e` to be polymorphic: foo :: MonadError e m =&gt; m () foo = return () bar :: MonadError e m =&gt; m () bar = foo baz :: MonadError Foo m =&gt; m () baz = foo I get: src/MonadError.hs:29:8: error: ‚Ä¢ Could not deduce (MonadError e0 m) from the context: MonadError e m bound by the type signature for: foo :: forall e (m :: * -&gt; *). MonadError e m =&gt; m () at src/MonadError.hs:29:8-29 The type variable ‚Äòe0‚Äô is ambiguous ‚Ä¢ In the ambiguity check for ‚Äòfoo‚Äô To defer the ambiguity check to use sites, enable AllowAmbiguousTypes In the type signature: foo :: MonadError e m =&gt; m () | 29 | foo :: MonadError e m =&gt; m () | ^^^^^^^^^^^^^^^^^^^^^^ src/MonadError.hs:32:8: error: ‚Ä¢ Could not deduce (MonadError e0 m) from the context: MonadError e m bound by the type signature for: bar :: forall e (m :: * -&gt; *). MonadError e m =&gt; m () at src/MonadError.hs:32:8-29 The type variable ‚Äòe0‚Äô is ambiguous ‚Ä¢ In the ambiguity check for ‚Äòbar‚Äô To defer the ambiguity check to use sites, enable AllowAmbiguousTypes In the type signature: bar :: MonadError e m =&gt; m () | 32 | bar :: MonadError e m =&gt; m () | ^^^^^^^^^^^^^^^^^^^^^^
We've been using pretty much the exact same thing in production for a while now. Can't say there were any drawbacks.
I see. \`TypeApplications\` is not a problem for me though; I've always hated that haskell won't let me provide as explicit types as I want. 
Good to hear. Have any code to share?
Nah, not really. The actual library that we use is [simple-effects](https://hackage.haskell.org/package/simple-effects) of which I'm the author. Check out the tutorials and the `Signal` module.
https://blog.rcook.org/blog/2018/haskell-aws-lambda/ and https://blog.rcook.org/blog/2018/lambda-updates/
I have a project called \`distributed-fork\` and on that I run Haskell binaries on Lambda. Basically, * Statically compile the Haskell binary (\` -static -optl-static -optl-pthread -fPIC\`). * Create a wrapper in a programming language supported by Lambda (I used Python in my case) which executes the Haskell binary, passes the input (via stdin) and gets the output(via stdout). \[Here\]([https://github.com/utdemir/distributed-fork/blob/master/distributed-fork-aws-lambda/src/Control/Distributed/Fork/Lambda/Internal/Archive.hs#L40](https://github.com/utdemir/distributed-fork/blob/master/distributed-fork-aws-lambda/src/Control/Distributed/Fork/Lambda/Internal/Archive.hs#L40)) is what I have, it's a bit complex because I also push the return values to a queue. * Archive them together and upload to Lambda as a deployment archive This approach works pretty well in my case, there's just the overhead of spawning an each process on each invocation. If you don't want to have that, you can spawn the Haskell binary once and communicate with the existing process on your wrapper script. Hope it helps.
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [utdemir/distributed-fork/.../**Archive.hs#L40** (master ‚Üí ebfddc5)](https://github.com/utdemir/distributed-fork/blob/ebfddc5bf50f898b8fdc59c500fce501311dcb0e/distributed-fork-aws-lambda/src/Control/Distributed/Fork/Lambda/Internal/Archive.hs#L40) ---- [^delete](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply e2r7rwm.)
I don't know what you mean. Do you have an example?
For those wondering; this is the spiritual successor to my previous project \[SitePipe\]([https://github.com/ChrisPenner/SitePipe](https://github.com/ChrisPenner/SitePipe)). SitePipe had zero caching and adding it would have been prohibitively difficult. Using Slick requires slightly more effort to get started, but allows you to rely on the Shake ecosystem for helpers, provides great caching and command line tools, and allows even greater adaptability in page renderers, etc. This release runs with Pandoc 2.0, which is an upgrade from SitePipe.
Instead of NPM's `serve`, you should advocate `hserv` for testing the site ;)
As others have said it's absolutely possible to run Haskell in AWS Lambda. Create a statically compiled binary and a shim script to invoke it. I haven't done it in a while (2016) but this should get you going https://www.agileand.me/haskell-on-aws-lambda.html.
As others have said it's absolutely possible to run Haskell on AWS Lambda. Create a statically compiled binary and a shim script to invoke it. I haven't done it in a while (2016) but this should get you going https://www.agileand.me/haskell-on-aws-lambda.html. May be easier now to that AWS have released their AWS Linux distro images.
How performant is the result? Are cold starts impacted? Paying for serialization twice seems unfortunate, but probably trivial. I‚Äôve always been curious to do AWS Lambdas with Haskell.
Hey. So; in my case I'm using Lambda's when batch processing, and my invocations take tens of seconds; so overhead on the invocation time is not my bottleneck. My payloads are Haskell objects encoded as ByteStrings and the wrapper just passes them to the executable, so I'd think that serialization cost wouldn't differ much. I think that spawning the new process will take the most time. One can mitigate this by spawning a single Haskell executable on the first invocation and communicate them with something like a FIFO. I also tried to use GHCJS and NodeJS backend, it also works. However it's much more tricky to get it right and I don't think performance would be better.
Excellent introduction video, thank you for the share! 
Might be a little contrived, but the following wont type check... ``` class IntegerConvertable a where toInt :: a -&gt; Int instance IntegerConvertable Double where toInt = undefined toInt1 :: (IntegerConvertable a) =&gt; a -&gt; Int toInt1 a = undefined add5 :: (IntegerConvertable a) =&gt; a -&gt; Int add5 a = 5 + toInt1 a add5ToString :: String -&gt; Int add5ToString s = add5 $ read s ``` A possibly better example and explanation can be found in the starting paragraphs of [1] and [2]. Now change the constraints in the toInt1 and add5 functions to Num and see it magically works due to type defaulting in GHC. So it is extra confusing because it works for some typeclasses (Mostly some of the built in ones) and not for the rest. In practice, you hit this all the while if you use lenses heavily in your code.. [1] https://kseo.github.io/posts/2017-01-04-type-defaulting-in-haskell.html [2] http://www.alexeyshmalko.com/2014/haskell-defaulting-rules/
I agree.
Ranjit Jhala has a certain clarity of thought and amazing way of talking about, well, just about anything, that keeps me spell-bound and listening.
Is this actually a problem? `foo` can't use any of the MonadError methods, so the constraint is redundant.
Typo: &gt; extravogent Extravagant?
This is neat, but &gt; Does not support HTTPS. It is expected that you run it behind a reverse-proxy server with HTTPS support, like nginx. It's literally like there extra lines including imports to make a tls server. It seems like you might as well just serve up content with Nginx directly and skip this tool altogether, why use both?
It wasn't my usecase so I decided to not do the extra bit. Please feel free to open a PR for it and I'll be happy to accept.
Probably off topic, but do you think using Apache arrow instead of `streamly` is a good idea? 
It'll be most problematic when you're just type constructing `e` with constraints. Like if `foo` has a `Monoid e` constraint and `foo` returned a`throwError mempty`. The polymorphism isn't redundant but it's still ambiguous.
Things can become problematic when you start mixing in `MonadIO` and friends. For example, foo `catch` (\Multiple -&gt; blah) Doesn't catch multiple at all. Though in this case, it will be a type error, because Multiple isn't an instance of Exception. If you are mixing in IO, you need to either: 1. Re-interpret MonadError into MonadThrow (or `liftIO . throwIO`) and then use `catch` as normal. 2. Eliminate `MonadError` with something like `runExceptT` and then check the result. Ultimately I found the double error-checking path in this case ultimately more confusing, and accepted reality and just use `throw` with `MonadUnliftIO`. If you're in pure code with no `MonadIO` at all, then I think `MonadError` can work well.
This is a pretty vague question and the answer is vague as well :-) I am not an expert on the Apache projects, just have a vague idea. AFAIK Arrow is an in-memory/deserialized data specification, e.g. the way arrays represent in-memory data with random access. Streamly is a computation engine so it can rather be compared with Apache Spark/Streaming rather than Arrow. But it may be premature as streamly is more focused declarative stream processing and does not yet have a distributed processing capability. However, you can visualize a more advanced form of streamly that can be compared with Spark or other computation engines like that. The advantage of streamly would be completely declarative pure functional expression as Haskell is a pure functional language by default, compared to the imperative engines which are approaching declarative streaming expression from a pure mutable expression by default. You can ask whether it would make sense for streamly to utilize a format like Apache Arrow, perhaps it does, I am not sure and have not given it any thought yet. But streamly would need a lot of work before we can say that you can use it instead of Spark in all or most use cases.
Shameless plug: We've built this thing to run Haskell on AWS Lambda: https://github.com/seek-oss/serverless-haskell You don't need a static build, but you have to compile in an environment that's similar enough to what AWS runs.
This is cool! Does it fit the same niche as e.g. [`wai-app-static`](http://hackage.haskell.org/package/wai-app-static)?
Thank you! I've fixed this now.
Though with the 'binding type variables in lambda applications' it could be a quite pleasant throwEmpty :: (MonadError e m) =&gt; m () throwEmpty @e = throwError (mempty @e)
That seems to be the case, except hastatic is much more minimal and comes with docker integration.
I'm not sure what you mean by 'Docker integration' (unless you mean that you've written a `Dockerfile`), `wai-app-static` looks like it should be just as easy to link statically and deploy. I tried building it and it's only 4.9MB so still reasonably small for something that's more fully-featured.
 &gt;unless you mean that you've written a `Dockerfile` That's what I mean. It's also available on docker hub and you don't need to build any code to use it. 
Perhaps this is the 10000th time someone asked a trivial question about Haskell performance, but I can't seem to make any sense of this: ``` type I = Int maxn :: I maxn = 1000000 factors :: Array I [I] factors = flip execState (array (2, maxn) [(x, []) | x &lt;- [2..maxn]]) $ forM_ [2..maxn] (\i -&gt; forM_ [i , i + i .. maxn] (\j -&gt; do s &lt;- get put (s // [(j, i : (s ! j))]))) main = print $ factors ! 1000 ``` This is a (very simple) code for calculating all factors of numbers &lt;= `maxn`, in an Eraosthenesy style. The problem is ofcourse the performance. The speed totally sucks, and also, it stack overflows. The equivalent C++ code is blazing fast, with no memory issues. I also tried `Control.Monad.State.Strict` but observed no benefit whatsoever. 
serverless-haskell is great. That's what I use in the examples on my blog at https://blog.rcook.org/blog/2018/hlambda/ etc.
Glad to see more projects in the web space written in Haskell! Just wanted to point out for people that might be passing through that [the code](https://github.com/abhin4v/hastatic/blob/master/src/Main.hs) all fits in one file and sits on top of [Warp](https://hackage.haskell.org/package/warp) the workhorse of Haskell web devs everywhere.
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [abhin4v/hastatic/.../**Main.hs** (master ‚Üí 72009b5)](https://github.com/abhin4v/hastatic/blob/72009b5db22e86eb490dbf8816e927f109ebe88b/src/Main.hs) ---- 
In case you‚Äôre interested in details, the basis of what‚Äôs happening here is called *unification*. Indeed you have `(==) :: Eq b =&gt; b -&gt; b -&gt; Bool`, `2 :: Num p =&gt; p`, and `A 2 :: Num a =&gt; A a`. I renamed the `a`s in the `(==)` signature so we don‚Äôt have the same variable in different type signatures. Now to typecheck the expression `A 2 == 2`, we need to collect all the constraints and make the actual types of the arguments ‚Äúmatch‚Äù the the types expected in the function type signature. This ‚Äúmatching‚Äù goes, in the general setting, by the name of *unification*. So we need to unify `b` with `A a` and `b` with `p` for the two arguments. In this simple situation you can go with your intuition and say, well everything works if (and only if) we just ‚Äúmake‚Äù `A a` equal `b` equal `p`. You can gather these in Haskell syntax as type equality constraints `(A a ~ b, b ~ p)`. The `Num` constraints are just gathered with this, and everything gets attached to the result type of the function signature into: `(A a ~ b, b ~ p, Num a, Eq b, Num p) =&gt; Bool)`. This way of archiving new type information is actually how the whole process of type inference works in Haskell. Inferring types yourself in certain examples is really helpful to be not surprised about type error messages from the compiler so much anymore. Back to our example, we‚Äôre not done yet, for example we don‚Äôt know what `a` is and we also still have a huge context anyways. Before we know `a` here, we cannot run the program, since we need to know how the methods of `Num` are supposed to be implemented. The other issue (with the context anyways), that actually needs addressing first, is that we need to ‚Äúresolve‚Äù the typeclass constraints that actually have concrete (or somewhat concrete) types in them, for example those constraints containing `A a`, since `A` is a concrete type constructor, and we also *actually* need to resolve the equality constraints. Resolving constraints can also give more new type information, so help with the inference and hence with the first problem of ‚Äúknowing what `a` is‚Äù, well lets stop talking and continue. First the equalities take us from `(A a ~ b, b ~ p, Num (A a), Eq b, Num p) =&gt; Bool)` to `(Num a, Eq (A a), Num (A a)) =&gt; Bool)`. Then your `deriving Eq` yields an instance `Eq a =&gt; Eq (A a)`, that is meaning \*if you need an `Eq (A a)` instance, you actually only need an` Eq `a instance. Hence we can replace the` Eq (A a`) by` Eq `a, which is the* constrain*t left. Just like in real life, constraints are there to be leveraged. So it‚Äôs` (Num a, Eq a, Num (A a)) =&gt; Bool`) now. The` deriving Nu`m instance is analogous to the` E`q one, we get to` (Num a, Eq a, Num a) =&gt; Bool`) drop the duplication and it‚Äôs` (Num a, Eq a) =&gt; Bool`). Now we‚Äôre done with the basic Haskell approach to type inference. You‚Äôd get an error message now, if this whole thing was part of a Haskell program, because there‚Äôs still the unknown variable `a` left, that appears in a type class context, but we know nothing more about it; heck, it doesn‚Äôt even appear in the type anymore. But since this problem is common with `Num` constraints, there is a *convenience rule* in Haskell‚Äôs type inference that goes something like: *If there‚Äôs a type variable not appearing in the type (left hand side of the* `=&gt;`*) anymore but in the constraint, and it appears, more specifically in a* `Num` *constraint, and other than that, it* ***only*** *appears in constraints with* ***standard*** *Haskell type classes, then try ‚Äúmaking‚Äù that type Variable be* `Integer`*, and if that doesn‚Äôt work try* `Double`*, and if that doesn‚Äôt work either, finally give up.* *Standard* includes pretty few classes, but `Eq`, `Ord` and `Show` are among them for example. With this rule, we finally come from `(Num a, Eq a) =&gt; Bool)` to the type `Bool` with `a` being `Integer`, since `Integer` *is* indeed an instance of `Num` and of `Eq`, and at the side (if you took notes, like the compiler does) found out, that `a` is `Integer`, and `b` and `p` are `A Integer`. By the way, you can modify this *convenience rule* with a line like `default (Integer, Double)` in your program (this would change nothing), for example `default (A Integer, Integer, Double)` would try `A Integer` first, then `Integer`, etc.. when resolving a `Num` constraint. This is only about `Num`, so a pretty specific thing (or even *hack* if you like). If you also derive `Show` on your `A` datatype and write a function similar to `(==)` like `makeSameType :: b -&gt; b -&gt; (b,b)`; `makeSameType x y = (x,y)`, then by default `makeSameType (A 2, 2)` gives the result `(A 2, A 2)` in GHCi, but if you type `default (A Integer)` in GHCi first, then `makeSameType (A 2, 2)` gives the result `(A (A 2), A (A 2))` *\[probably, didn‚Äôt test this\]*.
Or `sws`... Too many of those around.
Time to shamelessly plug my package [SimpleServer](https://github.com/ajnsit/SimpleServer), which also provides a single server binary, but also supports runtime configuration through Haskell config files (just like XMonad). (Of course it is not minimal since it bundles ghc.)
Wow, that is some pretty deep stuff! Didn't know that `Num` had such quirky behavior. I recently began looking at compilation for typed languages, and I met unification there. In your last example, if I understand correctly, Haskell tries to unify `(Num a, Num b, A a ~ b)`. For this Haskell tries to make `b` an `A a`. Since haskell knows `Num a =&gt; Num (A a)`, it tries, making `2` some `A a` with `Num a`. But at this stage, a remains unsolved, which needs to be replaced with some concrete `Num`. As you said, it tries in some default order, which is normally `Integer` which works in our case. Had we specified `A Integer`, then we see the extra `A 2`'s as you mentioned. Did I get the stuff correctly, or did I miss anything?
Added HTTPS support. It doubled the code size though :)
Personally, I like `t'Foo'` and `v'Foo'` but maybe that's just my experience with python's `u'Unicode'` syntax.
Yep. Sounds like you got the idea.
Warning: I don't actually know anything about the array library you're using. I'm guessing `//` copies the entire array. So every time you're setting one value in the array, you're copying the whole thing. So that ups the time by at least a factor of `maxn`. Try using a mutable array type instead
I played around learning Haskell many years ago, but have been gone almost 10 years. Back then, it was very easy to get into trouble with things like library version conflicts, hackage being an unsorted mix of best-in-class libs with bitrotted experiments, libraries not being thoroughly documented for the non-expert, difficult to analyze CPU and memory usage of a program, and hit-and-miss IDE support for things like managing dependencies and incremental rebuilding of a program. And so much of a programs' meaning being expressed in punctuation/layout (in type signatures) or unqualified imported symbols, so it's hard to research what a piece of code means. What are the major improvements in the ecosystt since then, for the casual/hobbyist programmer writing applications? IDEs, debuggers, profilers, libraries, "frameworks", documentation, package management, etc?
I am using `Data.Array`. It should be persistent right? 
How does this implement of `memoize` force reuse of computed values across function calls in different parts of the program, with no apparent CAF to hold and provide the `(memoize f) x` valued? https://www.reddit.com/r/programming/comments/crgxs/comment/c0uqe5x For comparison, Edward Kmett's answer here: https://stackoverflow.com/a/3209189 uses an obvious CAF (fmap f domainTree)
Yea. Which means every time you do an operation like setting a value in it, you're not actually mutating it. You're creating a copy that has that change. Otherwise you wouldn't be able to continue referencing the old copy (which you don't actually do in your code, so this feature is not valuable to you)
Inlining is not conversion to jumps. Inlining is replacing the function call with the body. Or in more simple terms, hygienic copy-paste. fac n = go 1 n where go acc x = case x of 0 -&gt; acc _ -&gt; go (acc * x) (x - 1) Now if you have a call `fac x` where x is a runtime value, if the compiler would keep inlining `go` into its definition, it would look like this (suppose you inlined `fac` first). go 1 x -- inline case x of 0 -&gt; 1 n -&gt; go (1 * x) (x - 1) -- inline again case x of 0 -&gt; 1 n -&gt; case (x - 1) of 0 -&gt; (1 * x) n -&gt; go ((1 * x) * (x - 1)) ((x - 1) - 1) -- inline ad infinitum Recursive functions can be converted into jumps (and GHC does this when it can) but that isn't called inlining AFAIK.
I meant inline the function and replace the recursive function call with a jump, instead of (again) the function body.
Isn't it tail call optimisation ?
Yeah, but I thought TCO is Independent from inlining (shouldn‚Äôt it run in a later Stage?)
Yeah, that is what is going to happen in this case in practice ([godbolt](https://godbolt.org/g/Ja2Uvz)). `fac` will be inlined and `go`'s inner calls to `go` will be replaced with jumps. http://johantibell.com/files/haskell-performance-patterns.html#(7)
Here are package takeover procedures: https://wiki.haskell.org/Taking_over_a_package I tend to think that npm-sized packages should be discouraged. Though there are no hard and fast rules, my opinion is that packages should be both _useful_ and _nontrivial_ in that they wrap up some unit of functionality that is substantially harder to reproduce than just writing it yourself. (I.e. such that discovering the package and incurring the dependency cost is still a positive tradeoff). This is not the same as lines of code. For example, there are some rather subtle and complicated algorithms (for example, graph-theoretic or geometric) which nonetheless fit in ~20 lines. Putting those up as individual packages is potentially reasonable, though equally reasonable would be big packages collecting a bunch of them. 
Is it typical for smaller packages to just link them in with your github? Or do you just rewrite the code?
that's not what I mean. Go isn't inlined. Couldn't go be inlined with a jump to the start of go (in the corresponding new line)
Stack, nix-style cabal builds, and nix itself offer solutions to the library version conflict issue. Cabal hell is a thing of the past. Hackage containing bit-rotted packages isn't actually solvable without a major curating effort. Type signatures are *part* of the program; obviously, ignoring part of the program makes it harder to understand the program. I don't have answers to the rest of your problems; they've never bothered me much. Still, I hope this helps.
On the other hand, working with backpack currently forces one to make many micropackages to get the full modularity benefit. Fortunately it looks like this will be improved by the work being done to expose multiple libraries in a single package. There still seem to be cases where you'd want tiny packages, like signature-only packages, where the benefit is being able to refer to the same signature from multiple downstream packages even though they could easily have defined their own. The best-practices in a post-backpack world are still being discovered (possibly it is unworkable), but otherwise I'd agree about useful and nontrivialness
It sounds like you are asking about tail-recursion optimization, not about inlining. The reason that the recursive call in the traditional factorial definition cannot be optimized into a jump is that there is still work to be done *after* the recursive call. You need to take the result of the recursive call and multiply it by `n`. If you just jump into the recursive call you never get a chance to go back and do this. fac n = if n &lt;= 0 then 1 else n * (fac (n-1)) 
Ah! I forgot that. That's right. Seems like this would also work with TCOable recursirve functions. 
You can look at the simplifier iterations with -ddump-simpl-iterations -dsuppress-all -fforce-recomp This dumps a bunch of core which is ghc's internal language. It's a bit verbose and a lot of language constructs are simpler - both `where` and `let` are translated into `letrec` for instance. I have simplified the names a bit. ident# is a convention to show that ident# is unboxed and passed in registers. Direct desugaring: fac fac = \ n -&gt; letrec { go go = \ acc x -&gt; case eqInt x (I# 0#) of { False -&gt; go ($fNumInt_$c* acc x) (case x of { I# x# -&gt; I# (-# x# 1#) }); True -&gt; acc }; } in go (I# 1#) n ---------- full laziness pulls up go. join is like let but with a guarantee that we can compile into jumps. Inline $fNumInt_c* which is Int multiplication. Inline and constant fold eqInt. Try -fno-full-laziness if you want to see the join point survive. We lift go to the top level because if it's small enough to inline we don't lose anything and if it's too large we can at least inline fac and maybe skip boxing the argument lvl_s2eX lvl_s2eX = I# 1# fac fac = \ n-&gt; go lvl_s2eX n go go = \ acc x -&gt; case x of { I# x# -&gt; join { $j_s2f6 $j_s2f6 = go (case acc of { I# acc# -&gt; I# (*# acc# x#) }) (I# (-# x# 1#)) } in case x# of { __DEFAULT -&gt; jump $j_s2f6; 0# -&gt; acc } } ---------- I am gonna drop fac for now because it doesn't change. Inline the join point, it was a precaution against duplicating code while constant folding the case binder. Note that go still compiles into a loop: go go = \ acc x -&gt; case x of { I# x# -&gt; case x# of { __DEFAULT -&gt; go (case acc of { I# acc# -&gt; I# (*# acc# x#) }) (I# (-# x# 1#)); 0# -&gt; acc } } ---------- wild_Xp is like an as-pattern on the case binder. In this case the binder is atomic anyway, though go go = \ acc x -&gt; case x of { I# x# -&gt; case x# of wild_Xp { __DEFAULT -&gt; go (case acc of { I# acc# -&gt; I# (*# acc# wild_Xp) }) (I# (-# wild_Xp 1#)); 0# -&gt; acc } } ---------- Strictness analysis showed we use our argument strict so we can do the worker-wrapper transform. This leaves us with an inner worker that uses unboxed values in registers and an outer wrapper that does the unboxing/boxing: go go = \ acc x -&gt; case acc of { I# acc# -&gt; case x of { I# x# -&gt; case $wgo acc# x# of result { __DEFAULT -&gt; I# result } } } -- RHS size: {terms: 14, types: 3, coercions: 0, joins: 0/0} $wgo $wgo = \ acc# x# -&gt; case x# of wild_Xp { __DEFAULT -&gt; $wgo (*# acc# wild_Xp) (-# wild_Xp 1#); 0# -&gt; acc# } ---------- Wrappers are always inlined so inline go into fac: $wgo $wgo = \ acc# x# -&gt; case x# of wild_Xp { __DEFAULT -&gt; $wgo (*# acc# wild_Xp) (-# wild_Xp 1#); 0# -&gt; acc# } fac fac = \ n -&gt; case n of { I# n# -&gt; case $wgo 1# n# of result { __DEFAULT -&gt; I# result } } For comparison the end result with -fno-full-laziness: fac fac = \ n -&gt; case n of { I# n# -&gt; joinrec { $wgo $wgo acc# x# = case x# of wild_Xn { __DEFAULT -&gt; jump $wgo (*# acc# wild_Xn) (-# wild_Xn 1#); 0# -&gt; I# acc# }; } in jump $wgo 1# n# } You can dig further with the likes of -ddump-stg and -ddump-cmm . Also note that the resulting code is different when you use a function instead of just exporting it because inlining. If we have `main = print (fac 100)` we just get this cmm somewhere in main: _s3id::I64 = 100; _s3ic::I64 = 1; goto c3jd; c3jd: if (_s3id::I64 != 0) goto c3jj; else goto c3jp; c3jj: _s3if::I64 = _s3ic::I64 * _s3id::I64; _s3id::I64 = _s3id::I64 - 1; _s3ic::I64 = _s3if::I64; goto c3jd; Sorry for the huge wall of text 
I usually only use ExceptT as a convenience when I deliberately want to be dealing with Either but still want a convenient Monad. I almost never have deep call graphs of ExceptT. I absolutely avoid using IO exceptions as a form of control flow though; I either catch them as instantly as possible or I let them bubble up and just try to fail gracefully with a top level catch.
How does a finger tree store and update its measures?
Each node contains a cached measure generated by `mappend`ing the measures of its children; or by using `measure` directly for leaf nodes. You may only insert leaf nodes at the beginning or end, so typically insertion in the middle requires splitting the tree, inserting at the end of one half, then rejoining. At the 'rejoin' step only the affected parent nodes re-compute their caches by `mappending` in the new measure which bubbles up the tree. There are much better blog posts and papers than this one if you want to dig deep, this is meant as a quick'n'dirty guide to get you building things with Finger Trees without needing to know HOW they work. ** I probably oversimplified or mis-spoke; if you know better feel free to correct me, but I think that's a nice simple summar of how they work **
A "practical" introduction to anything starts with concrete examples. This article starts by introducing two abstractions.
Seems like a strange requirement, may I ask how you became the arbiter of practicality?
I was democratically elected. But... I now understand that the /r/haskell community can't handle concrete examples. Any specific case is too pedestrian to waste time on. I'll go back to /r/coq and /r/wittgenstein where things are a bit less rarefied.
I think abstractions are very practical üòÅ
Not OP but thank you for the huge wall of text, it's very helpful to me :).