Regarding your `elookup` question: I don't know what you've written in your code vs. what was provided, which makes things difficult if you have to stay within the confines of what you've been given. If you cannot lookup a value, to me that represents an invalid expression. So, I would change `elookup`'s type to elookup :: Var -&gt; [(Var, Val)] -&gt; Maybe Val and, similarly, I would change `eval` to eval :: [(Var, Val)] -&gt; Exp -&gt; Maybe Val If you get a `Nothing` from `elookup`, you should return `Nothing` from `eval` since the expression is invalid in that case. 
Unfortunately, I can't use Monads, this problem is from [monad challenges](http://mightybyte.github.io/monad-challenges/) and the goal is to implement monads from scratch, so we start with a very limited library. Your second option is what I think I will be going with. Thank you!
I install GHC from the Haskell Platform core installer. It's not in the distro package manager, but for me it's the easiest way to get the most up to date version (which I tend to always want).
Ubuntu is capable of taking patches that aren't in an upstream point release. (In fact, they're probably _less_ inclined to take an upstream point release because it will include other changes; saying "Apply this one small patch to the version that got released" is preferable to "Here are a bunch of changes from 8.4.2 to 8.4.3.") Read through Ubuntu's docs on [StableReleaseUpdates](https://wiki.ubuntu.com/StableReleaseUpdates), at least up to the "Publishing" line. That process is pretty straightforward _if_ you know how to create a Debian package, but I'm not totally sure who to contact if you don't. I would still start by filing a bug on Launchpad against the Ubuntu ghc package (https://bugs.launchpad.net/ubuntu/+source/ghc/+filebug - you'll need to sign up for an Ubuntu One account) and writing some text that could be turned into that template eventually, and stating that a) an upstream patch exists b) you would like to get an SRU c) you don't know how to build a package but you're happy to test one. Be sure to specify in what manner the package is broken (i.e., presumably hello-world works, right?) and how the patch fixes it. If you get stuck, ask the IRC channels #ubuntu-devel or #ubuntu-motu ("Masters Of The Universe": Ubuntu packages without official support from Canonical, i.e., usually unmodified Debian packages, are in the "universe" component) on Freenode. Stick around a bit, and maybe ask a few different times of day if you don't get an answer. The long-term answer is that someone needs to volunteer to test packages on Ubuntu a little bit before release (preferably a month or two out) and report bugs to Ubuntu and work on figuring out what the communications channels are. Unfortunately because the package is in universe, there's no official support&amp;mdash;but that also means that the barrier for changes is pretty low before release.
Actually - are you getting this with the ghc version in Ubuntu, or with the ghc from some PPA or something? Ubuntu Bionic has version 8.0.2 according to https://launchpad.net/ubuntu/+source/ghc , no 8.4.x version is going to get into Bionic at all.
Backticks \` around a bit of text render it in a `fixed font`. `λvar. exp` is pseudo-lambda calculus terminology. You are effectively implementing an untyped [lambda calculus](https://en.wikipedia.org/wiki/Lambda_calculus) with builtin integer expressions. `λx. M` is just how those expressions are written in that calculus - lambda to introduce abstraction, dot to separate variable from term. In your context, variables are `Var`s, and terms are `Exp`s.
**Lambda calculus** Lambda calculus (also written as λ-calculus) is a formal system in mathematical logic for expressing computation based on function abstraction and application using variable binding and substitution. It is a universal model of computation that can be used to simulate any Turing machine. It was first introduced by mathematician Alonzo Church in the 1930s as part of his research of the foundations of mathematics. Lambda calculus consists of constructing lambda terms and performing reduction operations on them. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/haskell/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
I'm quite surprised there won't be another release of 8.4 to fix this. What's the justification for that?
AIUI It's the most up to date version of GHC that's broken.
&gt; Ubuntu is capable of taking patches that aren't in an upstream point release. (In fact, they're probably less inclined to take an upstream point release because it will include other changes; saying "Apply this one small patch to the version that got released" is preferable to "Here are a bunch of changes from 8.4.2 to 8.4.3.") It seems that it's not the version in Ubuntu that's broken but something in the latest Ubuntu causes the latest binary release to break.
My point is that you can use the Haskell Platform (whatever version and when it's ready) instead of waiting on the distro.
Patches to Ubuntu don't solve the issue for people that use stack (like we do) and they doesn't solve the issue on any other distributions that are up to date (Arch, Gentoo, etc.). The only solution is to roll a new version or declare that GHC 8.4.* (and 8.2.*) will just be broken and users should learn to live with that. Either give up on their packages or downgrade them to 8.0.
Yup, you can get the version from haskell platform or you can use stack directly. Problem is all the latest versions, both 8.4 and 8.2, are affected. So we're hosed without a release because we can't downgrade to 8.0.
I bailed on the language entirely due to this kind of attitude. Went to Rust. Never looked back.
Looks like the most recent comment 50ish minutes ago indicate there will be a 8.4.3 release to fix this :)
Does it? That comment seems to be &gt; Can those who are affected by this issue confirm that they are building with debug information enabled (ghc -g)? so I don't understand.
Oh okay. I thought from the post title that this issue was specific to the way Ubuntu did something and not a GHC issue.
the label changed too: milestone: 8.6.1 → 8.4.3 status: closed → merge which gives me hope as well
The last comment on the bug report suggests they will fix it in 8.4
It was one offhand statement. Doesn't seem like they're married to the idea of no more 8.4 releases. Title of this post is way too aggressive... The linked ticket is exactly the place to raise concerns.
I think it's insane to talk in this way. Nowhere before closing was stated that GHC was completely broken on 18.04. Even the title is downplaying the issue. This may be clear when looking at the test fail itself, but this could had been completely overlooked when sorting multiple tickets. 
I can sympathise with OP getting scared when he/she saw "I doubt we'll have another 8.4 release so closing." 
This "attitude" is exemplified by one recent noncommittal comment by one maintainer. You haven't really given fair time to reconsider the position after the recent complaints to be making these serious accusations. &gt; Who do we ask for help The linked ticket is clearly the right place to leave concerns.
I'm building a CLI for checking cryptocurrency prices, but I can't figure out how to parse this JSON object \([example](http://coincap.io/page/ETC)\). I'm using Aeson and getting errors like "Expected \[a\], encountered object." From what I can gather, I think I'm having issues because it's technically an invalid JSON instance. But I'm not entirely sure
Aha. That's good.
Yeah, but I also can understand bgamari. No one stated that the issue was a deal breaker.
Can you expand on that a bit? I've used both tools before but I'm not quite sure what you mean
It's not a full command line client yet - I'd like to get it to that point, but getting syncing to work properly might be quite tricky.
That's not true. Someone did state that 18.04 is broken before the bug was closed. &gt; This also happens when booting GHC with GHC 8.4.2 on Ubuntu 18.04. And two people before me said that their packages are broken, asked for help, and nothing happened.
Miscommunication is the root of bad nashor equilibria!
&gt; I doubt we'll have another 8.4 release so closing. To me, this doesn't say "refuse." This says they hope another 8.4 release isn't necessary, but one could be made if people think it's necessary. They were clearly open to further discussion on the matter. &gt; two other people asked for help and were ignored. I would hardly call 2 or 3 days "ignored."
I doubt I'll have ice cream today. That doesn't mean I am refusing to have ice cream today.
It's clear that we interpret the bug being closed, messages not being answered for 3 days, and the bug being assigned to another milestone many months from now, very differently. That's ok. For me, a bug that breaks a popular LTS distro and gets treated this way is a major issue with Haskell itself. If making sure that end users don't have broken builds isn't the priority then how can I confidently do anything in Haskell?
What do your types &amp; decoder look like? Something like this should work: data CurrencyData = CurrencyData { priceBTC :: Scientific , priceUSD :: Scientific } instance FromJSON CurrencyData where parseJSON = withObject "CurrencyData" $ \v -&gt; CurrencyData &lt;$&gt; v .: "price_btc" &lt;*&gt; v .: "price_usd" Also, if you like cryptos, I've been messing around w/ writing a portfolio app in haskell: https://github.com/prikhi/crypto-portfolio 
Previous post: https://www.reddit.com/r/haskell/comments/7ym94z/linear_types_by_aspiwack_ghcproposalsghcproposals/
s/insane/unreasonable/
I think you may be overestimating how much is supposed to happen in 3 days. I have *never* seen a software project as large as GHC that chooses to cut new, unplanned releases with just 3 days thought.
Of course I don't expect a new version to be released in 3 days. If that bug had been taken seriously and there was a version coming, I would wait patiently. Bugs happen and releases are annoying to make. The problem here is how the bug was treated, closed and ignored, instead of being a priority given how extensive the issue is. It should give you pause that this is how things can go in the Haskell world when your code stops building one day.
Well I've been working through the problem with baby steps. Keep in mind I am new to Haskell and saw this as a basic project to learn Haskell with. So far I have two versions; One only parses the argument from the command\-line, converts to uppercase to build the request URL and returns the raw JSON. The other one I've been toying with and have been able to return an AST version of the JSON, but I don't know where to go from here. 1: import Data.Char import Network.HTTP.Conduit import System.Environment import qualified Data.ByteString.Lazy as BL fetchData x = do simpleHttp ("http://coincap.io/page/" ++ (map toUpper x)) &gt;&gt;= BL.putStr main :: IO () main = do args &lt;- getArgs case args of [] -&gt; do putStrLn "Error: No arguments given" (x:[]) -&gt; do fetchData x 2: {-# LANGUAGE OverloadedStrings, DeriveAnyClass, DeriveGeneric #-} import Control.Applicative import Control.Monad import Data.Aeson import Data.Char import GHC.Generics import Network.HTTP.Conduit (simpleHttp) import System.Environment import qualified Data.ByteString.Lazy as BL data CoinInfo = CoinInfo { cap24hrChange :: Double , display_name :: String , id :: String , price_btc :: Double , price_eth :: Double , price_eur :: Double , price_usd :: Double } deriving (Show, Generic, FromJSON) fetchBTC = simpleHttp "http://coincap.io/page/BTC" &gt;&gt;= BL.putStr coincheckFunc :: String -&gt; IO BL.ByteString coincheckFunc x = simpleHttp ("http://coincap.io/page/" ++ (map toUpper x)) prettyPrint :: CoinInfo -&gt; String prettyPrint x = (display_name x) -- fetchData :: String -&gt; (CoinInfo -&gt; String) -&gt; IO () fetchData x = do rsp &lt;- coincheckFunc x print (decode $ rsp :: Maybe CoinInfo) main :: IO () main = do args &lt;- getArgs case args of [] -&gt; do fetchBTC (x:[]) -&gt; do fetchData x Here's a third one where I was playing with the curl\-aeson library with no luck: {-# LANGUAGE OverloadedStrings #-} import Control.Applicative import Control.Monad import Data.Aeson import Network.Curl.Aeson Data CoinInfo = CoinInfo { cap24hrChange :: Double , display_name :: String , id :: String , price_btc :: Double , price_eth :: Double , price_eur :: Double , price_usd :: Double } deriving (Show) instance FromJSON CoinInfo where parseJSON (Object o) = CoinInfo &lt;$&gt; fetchBTC = simpleHttp "http://coincap.io/page/BTC" &gt;&gt;= BL.putStr coincheckFunc x = simpleHttp ("http://coincap.io/page/" ++ (map toUpper x)) fetchData x = do coincheckFunc x &gt;&gt;= BL.putStr main :: IO () main = do args &lt;- getArgs case args of [] -&gt; do fetchBTC (x:[]) -&gt; do fetchData x
I would focus on immutability, functions as first class values and functions having no side effects. 
&gt; That's what made your post very alarming, it would signal that GHC was changing for the worse That's exactly the conclusion I came to after seeing failing builds and finding that bug.
&gt; How can I convince others to adopt Haskell and rely on it for their research / companies when that's how the developers respond to build failures? For research I don't know but do companies typically use bleeding edge versions of the compiler? For something else than CI to future-proof their codebase? Seems risky.
&gt; use bleeding edge versions of the compiler This happens on 8.2 as well, which is far from bleeding edge.
Yet that bug only implies failing tests and one loose comment implies that booting ghc with ghc 8.4.2 doesn't work on 18.04, not that ghc itself is unusable. You only noticed the seriousness of the bug because you yourself was directly affected, someone who has to deal with a whole lot more would easily (and apparently did) mis assess the urgency. By the way, that comment about no 8.4 release was probably fired for multiple tickets, as usually done. While of course that is not on you to know that, I don't think you have applied a single drop of good faith/understanding and went directly to shoot accusations and inflammatory remarks. 
Tell them about self balancing trees. data AVLTree a = Empty | Node a Int (AVLTree a) (AVLTree a) The Int is the height of the tree. 
OP was scared that his/her setup would be broken for several months. Let's please be sympathetic and considerate, by reassuring him/her and making sure this regression gets fixed. We're a big, grown up community with a big, grown up compiler dev team. We can handle perceived accusations and inflammatory remarks without flinching, especially if we are sympathetic and considerate amongst ourselves too. 
ELI5, what are the benefits of linear types?
&gt; "elookup _ [] = Vnum(0)" I agree w/ the other poster, failure to lookup in the environment should be an `error`.
Copyright laws in the type system allowing for strong guarantees no one will mishandle your resources maybe that’s not like u’re 5 but that’s the simplest i can come up with.
In short (correct me If I'm wrong) but it has mainly to do with (ala RUST) memory optimisation. By given extra information to the compiler about how data are shared, it allows the compiler to either construct an object on the head (instead of the stack) and/or reuse it (modify it) instead of destroying it and creating a new one. It also add some static safety by making sure than you are using (or not) input parameters.
Seems you must have, this is Haskell reddit you know. Not much Rust discussion.
This is a really informative review. Good work We will watch your summer thesis with great interest.
Could someone explain how filter (\line -&gt; length line &lt; 10) and filter ((&lt;10) . length) are the same? like what happens in the second line of code that it gives the same result as the first line of code?
I'm trying to install the hmatrix package on Mac \(OS High Sierra, 10.13.4\). The LinearAlgebra part of the package works great, but when I run `import Numeric.GSL` in GHCI I get the "could not find module error" and I've got no idea what the problem is. I have GSL installed via Homebrew` ($ brew install g`sl\), and I installed hmatrix via Cabal` ($ cabal install hmatr`ix\). My GSL is also installed via Homebrew. I'm reasonably new to Haskell so not sure if any other information is relevant. Is there some other dependency that I need for the GSL part? I've tried googling but can't find anything, which seems strange given that hmatrix is reasonably popular. I would have thought someone else would have previously run into this problem. Thanks!
Is the "why functional programming is the correct way to program" title really necessary?
Happy to announce the reworked version of my library. Some rudimentary examples can be found in its [test folder](https://github.com/achirkin/easytensor/blob/master/easytensor/test/Numeric/DataFrame/Arbitraries.hs), or in [vulkan examples](https://github.com/achirkin/vulkan/blob/master/vulkan-triangles/src/Lib/Vulkan/Vertex.hs). Also, [uploaded it on hackage](https://hackage.haskell.org/package/easytensor). The DataFrame is a data family of frames, all of which are wrappers on primitive arrays. data family DataFrame (t :: l) (xs :: [k]) Known dimensionality, simple array: newtype instance DataFrame (t :: Type) (xs :: [Nat]) Partially known dimensionality, simple array: data instance DataFrame (t :: Type) (xs :: [XNat]) Multiple arrays under the same dimensionality: newtype instance DataFrame (t :: [Type]) (xs :: [k]) 
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [achirkin/easytensor/.../**Arbitraries.hs** (master → fcad811)](https://github.com/achirkin/easytensor/blob/fcad811e834da10c338b789c07f779258483e56d/easytensor/test/Numeric/DataFrame/Arbitraries.hs) * [achirkin/vulkan/.../**Vertex.hs** (master → 4b02bda)](https://github.com/achirkin/vulkan/blob/4b02bdaea62e45dc3805610cbfe181d242fd78a8/vulkan-triangles/src/Lib/Vulkan/Vertex.hs) ---- 
Thanks, this is the kind of article I was looking for actually.
Where does `Ann` in `annotateLocation :: Parser a -&gt; Parser (Ann SrcSpan a)` come from?
What you're doing with the Ord instance is going to cause problems. All the operations in an Ord instance need to respect a single ordering, because polymorphic code will expect that and there's no expectation that changing the subset of Ord methods you use in Ord-polymorphic code can be a breaking change or that mixing them freely could cause bugs. If you want more than one ordering you should do it with newtype wrappers.
Thanks! I admit this is a dangerous decision. The main problem here is that Ordering type returned by compare does not support partial ordering. But it turns out to be so much more convenient for some algorithms to use these definitions of other comparison ops. Maybe I could add some deprecation pragma for `compare` or find other ways to restrict people from using DataFrames as keys for Map or so. 
As of this date, that is correct. Work is being done for Stack to support this, and [here](https://github.com/commercialhaskell/stack/issues/2540#issuecomment-319570811) is the issue to keep track of.
`withResource` and `testProgram` don't seem to work well together... Instead, you could grab the temporary file before running `defaultMain`. main = do tmp &lt;- getTmpFilename defaultMain (myTestWith tmp)
I really hope `-XLinearTypes` as proposed doesn't make it into GHC...
Some functionality of hmatrix has been outsourced. Could it be you need the [hmatrix-gsl](http://hackage.haskell.org/package/hmatrix-gsl) package additionally?
I don't think HTTPS has ever been supported for hackage.fpcomplete.com. You can access the same content by HTTPS at https://s3.amazonaws.com/hackage.fpcomplete.com/
Perhaps the `partial-order` package could help with this? I admit the situation is not ideal.
Can someone ELI5 why this is useful? Perhaps through an example of something that is currently impossible to achieve without this language extension?
Haskell's `Exception` type class relies on `Data.Typeable`, implying that information about what kind of exception you're currently dealing with has to be resolved at run-time. This makes it impossible to embellish type signatures at compile-time, albeit I don't know if you could theoretically do it with `TemplateHaskell`. There are some packages that provide their own `throw` functions, like [safe-exceptions-checked](https://hackage.haskell.org/package/safe-exceptions-checked) for instance. But you would basically have to reimplement `base` in terms of this if you wanted functions like `readFile` to have checked exceptions. If you take propagation of unhandled exceptions into account however, non-trivial functions would quickly yield complicated and unintuitive type signatures. That might be ok at the function call site you're interested in, but then maybe you wouldn't be able to handle something like an unexpected `ArithException` sensibly anyway, and you would have to rethrow it. Probably using the "opaque" `throwIO/throwM` functions, since you don't *intend* to handle it sensibly in the first place. You just catch `SomeException` somewhere in main, print and bail. It's just one scenario that I could imagine, and you might not agree with it. The point remains, that sadly the current exception implementation doesn't allow what you would like to do. Although alternatives are possible, there is probably a reason these are not in widespread use.
I don't know what a better formulation for haskell would be, and I don't think anyone does at the moment, which is why I'm afraid of settling on this so soon.One foundation with a lot of nice properties is Call-By-Push-Value semantics like in the Levy toy language. Fitting this into Haskell is very hard though because it requires a different semantics than Haskell’s Call-By-Need. The real issue is that linearity doesn't really make sense in a construct language that can't distinguish between data and codata. As it exists right now, `LinearTypes` is a syntactic restriction on where variables can appear in functions, but this is a very confused notion. In CBPV linearity is a property of values, not functions, and a “linear function” is initially a _value_ with holes popped out of it, which can be interpreted secondarily as a function via phase-shift, while true functions (continuations) naturally annihilate data in a linear fashion, not as an ad-hoc syntactic constraint.So in order to have sound linearity we’d need: first class data/computation types, and the shifts between them (“computation which returns value”, and “name of computation”). At which point linearity will naturally fall out. Getting computation types right in general is very hard and requires tackling type-level concurrency (ex: session types) - but fortunately haskell data is already a subset of computations (they are Not Not Data). So in practice I’d at least like to see a better story for `UnliftedDataTypes` (ie real data, not codata) before we seriously consider adding linear types. Carter makes a good argument for this in the GitHub discussion.Also, this proposal explicitly won’t work with any dependent type extensions (linear dependent types are an open problem theoretically) so trying to preserve both extensions will slow down / fragment development
Thank you - it looks like I was barking up the wrong tree, because our internal builds had broken and I thought it was to do with index fetching. Still don't know what the problem was, but the builds are working again now.
Thanks, this is a much better response! Lots of stuff I can track down and check out. Might have some more questions later though.
I find the title of this thread very misleading. It sounds as if the ghc team closed the OP's ticket as "won't fix" or something, when in fact [a workaround has been merged](https://ghc.haskell.org/trac/ghc/ticket/15068#comment:16) two weeks after the issue was reported, despite the fact that the investigation found that [the bug is in gcc](https://ghc.haskell.org/trac/ghc/ticket/15068#comment:7), not ghc. The OP can now fix their problem in two different ways, either by switching to a version of gcc which doesn't have the bug, or by compiling ghc-HEAD, which does include the workaround. I also take issue with the "Who do we ask for help here?" part of title. In the context of the rest of the title, it sounds as if they want to complain the supervisor of the person who handled their ticket, or something like that. As a user of an open source OS, the OP should know that this is not how things work in the open source world. If they can't find a volunteer who is willing to fix their open source software for free, they can either contribute a fix themselves, or equivalently pay some consultants to contribute one for them.
Thank you! :)
This is not correct. It has nothing to do with memory optimization. In section 6.3 of the [the Linear Types paper](https://arxiv.org/abs/1710.09756), there is a discussion of the differences between rust's type system and Linear Haskell: &gt; Linear types and uniqueness types are, at their core, dual: whereas a linear type is a contract that a function uses its argument exactly once even if the call’s context can share a linear argument as many times as it pleases, a uniqueness type ensures that the argument of a function is not used anywhere else in the expression’s context even if the callee can work with the argument as it pleases. Seen as a system of constraints, uniqueness typing is a non-aliasing analysis while linear typing provides a cardinality analysis. **The former aims at in-place updates and related optimisations, the latter at inlining and fusion.** Rust and Clean largely explore the consequences of uniqueness on in-place update; an in-depth exploration of linear types in relation with fusion can be found in Bernardy et al. Emphasis added. Everything discussed in the paper and in the proposals is about making it possible to safely write programs that have need to consume values in a linear fashion, not about doing in-place updates. The paper and the proposals have detailed examples. It's worth noting though one big use case for linear haskell is writing code that performs in-place updates, but it isn't the compiler that makes the updates in-place. It's going to be the work of library authors who carefully wrap the `Array#` primops to build safe linear interfaces on top of them.
If you don't need to build your packages from source, you could use the same method as ours. I just made debian and rpm packages using [`fpm`](http://fpm.readthedocs.io/) by basically specifying the dependencies and copying the binaries: fpm -s dir \ -t deb \ -n yourpkg \ -v $YOUR_PKG_VERSION \ -C $TMP \ -d "libgmp-dev" \ -d "libexpat1" \ -d "netbase" \ -d "libgomp1" \ -p yourpkg_VERSION_ARCH.deb \ usr/bin This assumes that you copied the binaries that `stack` produced to `$TMP/usr/bin`. Figuring out the dependencies was a matter of trial and error, but I guess there must be tools out there that can report the shared libraries upon which an executable depends. You can find the scripts I've used to make the packages and test them in docker containers [here](https://github.com/TorXakis/TorXakis/tree/develop/ci/mk-package). And the instructions for using these scripts \(in case the names are not self explanatory\) can be found [here](https://github.com/TorXakis/TorXakis/blob/develop/docs/wiki/developers/index.rst).
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [TorXakis/TorXakis/.../**index.rst** (develop → dbab9fa)](https://github.com/TorXakis/TorXakis/blob/dbab9fabec4b52e4dfc11c67cfbe988437e23c2c/docs/wiki/dbab9fabec4b52e4dfc11c67cfbe988437e23c2cers/index.rst) * [TorXakis/TorXakis/.../**mk-package** (develop → dbab9fa)](https://github.com/TorXakis/TorXakis/tree/dbab9fabec4b52e4dfc11c67cfbe988437e23c2c/ci/mk-package) ---- 
&gt; Also, this proposal explicitly won’t work with any dependent type extensions This in incorrect. Indeed the whole design of the language extension very much has the forward-compatibility-with-dependent-types constraint at its core. Quoting from the paper: &gt; Note that, in the above, we parameterize over multiplicities instead of parameterizing over kinds directly, as is customary in the literature. [...] Linearity on the arrow meshes better with dependent types s (see Sec. 7.2). Indeed, consider a typical predicate over files (P : File → ∗). It may need to mention its argument several times to relate several possible sequences of operations on the file. While this is not a problem in our system, the function P is not expressible if File is intrinsically linear. Leaving the door open to dependent types is crucial to us, as this is currently explored as a possible extension to ghc [Weirich et al. 2017].
Thanks for the correction, I must have been reading an old commentary, my mistake!
Name shadowing: bug or feature?
your hint works. Thank's.
&gt; One foundation with a lot of nice properties is Call-By-Push-Value semantics like in the Levy toy language. Fitting this into Haskell is very hard though because it requires a different semantics than Haskell’s Call-By-Need. The real issue is that linearity doesn't really make sense in a construct language that can't distinguish between data and codata. What matters is the polarity. Read some textbooks (maybe Bob Harper's). You'll see that (of course) there are polarity shifts in Haskell. In particular at the arrow type, which is precisely why we focus on it in our paper. &gt; As it exists right now, LinearTypes is a syntactic restriction on where variables can appear in functions, but this is a very confused notion. You may find it confused, but there is extensive literature on the topic, including Girard's paper on linear logic. &gt; Getting computation types right in general is very hard and requires tackling type-level concurrency (ex: session types) It is in fact very well understood how to encode the dual types "computation/data" by using double negation. In the case of linear logic, the thesis of Olivier Laurent deals with the topic extensively. 
100% agree, it's an obnoxious sentence in the abstract, and doubly so as the very first item on the list. In addition to being, in the end, just a statement of opinion. 
What is technically incorrect or weak with the proposal as it stands? Can you highlight parts of the proposal that you're concerned about?
Tell them about self balancing trees: data AVLTree a = Empty | Node a Int (AVLTree a) (AVLTree a)
That comment also seems to indicate that this is _only_ a problem when you build with debug information, so... maybe not that big a problem after all?
_Out on the road today I saw a Monad sticker on a Cadillac / A little voice inside my head said "Don't look back, you can never look back."_
I'm confused. Do the the packages build with the `-g` debug option? Or do you build them that way specifically? My understanding is this issue arises with DWARF symbol generation, unless I'm misreading...
A lot of stuff you could use indexed monads for (tracking in the type system to give safer api's) can be done easier and with better error messages using linear types. Think state machines or streaming api's that guarantee constant space usage. The proposal doesn't cover resource management ala RAII like rust/c++ give. This is because linear types as proposed ignore exceptions so you'd end up with something like ResourceT anyway.
&gt; (g.f) :: Int -&gt; Int -&gt; Int and it works as I expected Are you sure? Prelude&gt; let f = (+) :: Int -&gt; Int -&gt; Int Prelude&gt; let g = id :: Int -&gt; Int Prelude&gt; :t g . f &lt;interactive&gt;:1:5: error: • Couldn't match type ‘Int -&gt; Int’ with ‘Int’ Expected type: Int -&gt; Int Actual type: Int -&gt; Int -&gt; Int • Probable cause: ‘f’ is applied to too few arguments In the second argument of ‘(.)’, namely ‘f’ In the expression: g . f
That’s correct but apparently stack enables \`\-g\` enables by default \(\[source\]\([https://github.com/commercialhaskell/stack/blob/master/src/Stack/Build/Source.hs#L148](https://github.com/commercialhaskell/stack/blob/master/src/Stack/Build/Source.hs#L148)\)\) which has resulted in this being a problem for far more people than one would expect.
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [commercialhaskell/stack/.../**Source.hs#L148** (master → c435a3c)](https://github.com/commercialhaskell/stack/blob/c435a3cf38ea2bd33a53819893415c1f1a4c4183/src/Stack/Build/Source.hs#L148) ---- 
I feel like it's unfortunate that [multiplicity polymorphism](https://github.com/tweag/ghc/issues/59) isn't implemented yet. I always end up being blocked on this when trying to do something nontrivial with linear types. Also, I completely understand why exceptions interact with the proposal as they do but it's still really unfortunate. A lot of the immediately compelling use cases - gc-less code, safe resource management - is impossible. Or at least a reimplementation of ResourceT with worse type errors and no important new compile time guarantees.
I see exactly what you mean, I've been accumulating the wrong thing all along! I will try what you said so thank you. As for foldr I used it because I want something like a:b:c:[] not []:c:b:a, not sure how that could happen with foldl since (:) adds stuff at the head. You know what I mean?
I see now that my accumulator was where I went wrong, I will change it. Thank you! 
One observation. Prelude&gt; f = (+) Prelude&gt; g = id Prelude&gt; :t g . f g . f :: Num a =&gt; a -&gt; a -&gt; a I don't know what's happening.
Perfect \- thank you! I didn't realise they were separated.
Fwiw, if you really can't avoid Stack, you can use Stack w/ the GHC 8.4.2 (`ghc-8.4.2 8.4.2-8~18.04`) or GHC 8.2.2 (`ghc-8.2.2 8.2.2-4~18.04`) packages for Ubuntu 18.04 LTS from my Ubuntu PPA which don't suffer from this issue. 
Interesting. Why don't your versions suffer this issue? /u/0xab, this may be a useful workaround for you.
And you can't turn it off!? drat.
Yes, it is. 
This is one of the worst things about GHC. Compilers frequently break on a new OS, and GHC + libraries often lack full backwards compatibility. So even if you use a stack snapshot with fixed libraries + compiler a year or two of time will break most code as it can't be compiled anymore on a current OS and migrating to a new compiler &amp; libraries requires work. Code should not bitrot and require constant maintenance just to keep compiling. This is just not acceptable for a language used in production and even just for small personal projects it creates constant busywork and makes me question my choice of using Haskell.
I have to agree with the remark about Data and CoData / coindnductive records. You really need those two fleshed out to really be able even start to touch interesting linear logic. Plus the right support for first class choice types allows first class cases / join pointexpressions in userland 
Apparently the problem is that stack turns on debug information by default, which most people don't realize, and also you can only turn it off by enable symbol stripping, which is a pain.
&gt; We're a big, grown up community with a big, grown up compiler dev team. We can handle perceived accusations and inflammatory remarks without flinching, especially if we are sympathetic and considerate amongst ourselves too. This is an uneven standard.
I don't get it -- `stack build --resolver nightly` works fine in my projects using GHC 8.4.2 and Ubuntu LTS 18.04 LTS.
Eh. I think this specific case (GCC breaking one feature of GHC that Stack turns on by default when it probably shouldn't) is sufficiently obscure that I wouldn't worry about it. You can't reasonably expect GCC to never break GHC, but it is exceedingly rare. Granted, issues like this come up far more often on macOS since Apple breaks basic tools all the time, but this affects other just as much as Haskell.
That only works for first order function. But when mixing co- and contravariant arguments: ($) :: (a -&gt; b) -&gt; a -&gt; b there are two incomparable versions for this, i.e. neither is more general than the other: (a -&gt;. b) -&gt;. a -&gt;. b (a -&gt; b) -&gt;. a -&gt; b So either we have two implementations for $ or we add multiplicity polymorphism: (a :p-&gt; b) -&gt;. a :p-&gt;b For is especially relevant for `&gt;&gt;=` and similar composition stuff.
More importantly. Name shadowing warnings not enabled without -Wall, bug or feature?
&gt; textbooks (maybe Bob Harper's) What would that textbook be called?
This is a great idea, thanks!
Thanks for the suggestions; both the `repmin` problem and the simple `take` example are good ideas!
&gt; Commercial Haskell [...] they have an extremely strong voice in the community This is a surprising statement. What makes you think so? Can you give us any examples of the "commercial haskell usergroup" making their extremely strong voice heard in the community? 
Have you considered asking the *stack* developers to provide a workaround instead of aggressively demanding the GHC folks fix a bug that already has a workaround that amounts to *not passing a rarely used flag to the compiler*?
Actually, feature.
I'm not sure the intention why it's not enabled by default. It may be time to submit to https://github.com/ghc-proposals/ghc-proposals
Yea I think that was a pretty pretentious wording of that sentence.
Essentially, when you write `or . map`, `map` takes a function of type `(a -&gt; b)` and returns a function of type `[a] -&gt; [b]`, and you’re trying to give that function as the argument to `or`, which expects `[Bool]`, and these don’t match. If you want to compose a one-argument function with a two-argument function point-free, there’s a standard idiom for it: f p xs = or (map p xs) f p = \ xs -&gt; or (map p xs) f p = or . map p -- by definition of ‘(.)’ f p = (.) or (map p) f = \ p -&gt; (.) or (map p) f = \ p -&gt; (.) or (map p) f = (.) or . map -- by definition of ‘(.)’ f = (or .) . map -- standard idiom f = fmap or . map -- alternative using ‘(-&gt;) r’ instance of Functor For each extra compose operator, you ignore an extra argument: or :: Foldable t =&gt; t Bool -&gt; Bool (or .) :: Foldable t =&gt; (a -&gt; t Bool) -&gt; a -&gt; Bool ((or .) .) :: Foldable t =&gt; (a -&gt; b -&gt; t Bool) -&gt; a -&gt; b -&gt; Bool … (These can also be written `fmap or`, `fmap (fmap or)`, …) 
You were correct, foldl was the better choice, thanks again.
This so called 'AppNum' will be in base 4.12, in 'Data.Monoid'. Its name will be 'Ap'. It is defined as newtype Ap f a = Ap { getAp :: f a }
[Practical Foundations for Programming Languages](https://www.cs.cmu.edu/~rwh/pfpl/2nded.pdf).
No, really, I'm not. Considering the average personality traits of career developers and prior disputes in other communities, the worst of the stuff that gets thrown around here is extremely measured. I would welcome improvement in this arena, but I don't think it's an active pain point for constructive discourse as a whole, and it certainly isn't a toxic environment by any stretch.
On a unrelated note. Never migrate your production systems to newly released OS. Ubuntu 18.04 is just a few days old. I usually wait at least 3-4- months before committing.
You could riff on the problem specified in the [Haskell vs ...](http://haskell.cs.yale.edu/wp-content/uploads/2011/03/HaskellVsAda-NSWC.pdf) paper (PDF).
Their json export formats can be considered a description of their dsl's. You could compare those dsl's with the one you are defining.
Thanks :)
Not pretentious, they just left out some info
Much more reasonable position. No argument. 
I would agree it isn't toxic. But the arguments between FP Complete and other members of the community about build / configuration scripts have been deeply personal insults with people needlessly flaming and hating one another on a personal level. It was absolutely personal and needlessly so on what was a reasonable disagreement on both sides on how to handle a complex social and engineering problem. 
That means it's a candidate to merge ... *if* there's an 8.4.3. I wouldn't take it as a strong indicator that there will be one, especially since there are good work-arounds, including the option of using Herbert's ppa.
Yup. `Val -&gt; Val` is a function that takes a `Val` and returns a `Val`. So in full, that declaration defines the type `Val`. A given value of type `Val` is either a `Vnum` that holds an integer, or a `Vprim` that holds a function. Here's an aimless little example that constructs a value of this type: myVal :: Val myVal = Vprim (\otherVal -&gt; case otherVal of Vnum x -&gt; Vnum (x + 1) Vprim f -&gt; f (Vnum 5))
I totally miss it. The /language/ of Haskell was amazing. But, I liked having a compiler that actually worked way, way more. 
Sorry I about that; I was in a bit of a hurry writing that comment.
So it is like in LISP or imperative languages, where `foo` is a value and `foo(..) ` is a computation? 
Don't worry about it. I make wording errors all the time!
&gt; `pretty :: a -&gt; Doc` The question is: _whose_ `Doc` ? http://hayoo.fh-wedel.de/?query=Doc
The only problem here is that hackage doesn't help in choosing. If hackage would point away from some of these libraries towards others, based on comments, "related other packages", "popular packages similar to this", reverse deps by date histogram etc, then you could easily ignore most of these.
You've put _text-render_ and _rio's Display class_ so you should also put: * [`Buildable` from `text-format`](https://hackage.haskell.org/package/text-format-0.3.1.1/docs/Data-Text-Buildable.html) * [`Buildable` from `formatting &gt;= 6.3.0`](https://hackage.haskell.org/package/formatting-6.3.4/docs/Formatting-Buildable.html#t:Buildable) * [`See` from future of `fmt` package](https://github.com/aelve/fmt/pull/21) * [Another `Display` from its own `display` package](http://hackage.haskell.org/package/display) I also was overwhelmed by something like this recently... * https://www.reddit.com/r/haskell/comments/7q8kkd/uniform_buildable_type_class_for_formatting/ 
But this website helps. It's aim is to help to choose between different Haskell libraries for different domains. * https://guide.aelve.com/haskell/pretty-printing-uhierj0c
Well, as they say, beauty is in the eye of the beholder. ;) Jokes apart, not all these packages are purely for pretty printing. For example, `pretty-show` is primarily for deriving better `Show` instances by default if you have a `Generic` instance. OTOH, the `*wl-pprint*` family is for doing pretty printing using combinators.
You missed [mainland-pretty](https://hackage.haskell.org/package/mainland-pretty), which is necessary for interaction with [language-c-quote](https://hackage.haskell.org/package/language-c-quote).
I'd argue the same goes for a newly released compiler (yes, including GHC) when it comes to mission critical systems. I wouldn't dare using GHC 8.4.2 in anything critical yet until it has been out there for a couple months. And I sure hope that there'll be a GHC 8.4.3 released in a couple months fixing the issues which will be found till then, as the current GHC 8.4.2 release was more of an emergency to fixup the broken GHC 8.4.1 release.
&gt; Should we try to standardise https://xkcd.com/927/
FWIW, from the [description](https://hackage.haskell.org/package/prettyprinter-1.2.0.1#readme) of the `prettyprinter` package: &gt; Why another prettyprinter? &gt; &gt; Haskell, more specifically Hackage, has a zoo of Wadler/Leijen based prettyprinters already. Each of them addresses a different concern with the classic `wl-pprint` package. This package solves all these issues, and then some: This package seems like a good default choice to me.
essentially yes, IO is exactly the marker for the side-effects of the program
Yes, it's actively maintained and looked legit. The only thing I miss is Pretty a =&gt; Pretty (Identity a)...
How many are String and how many are Text or Bytestring? Don't forget [aeson-pretty](http://onoffswitch.net/adventures-pretty-printing-json-haskell/).
Hey, kuribas, just a quick heads-up: **basicly** is actually spelled **basically**. You can remember it by **ends with -ally**. Have a nice day! ^^^^The ^^^^parent ^^^^commenter ^^^^can ^^^^reply ^^^^with ^^^^'delete' ^^^^to ^^^^delete ^^^^this ^^^^comment.
…I’m on it! :-)
My votes are for `pretty-simple` (use it constantly, perfect for debugging) and `prettyprinter` (never used, but seems nice).
Thank you! 
Can you explain how that binding works?
&gt; I wanted to pick a pretty printing library for displaying extensible records and I just got overwhelmed by a tremendous number of packages This is what opinionated, curated lists like http://haskelliseasy.com/ are for. Unfortunately that list doesn't include a pretty printer.
Why are they called *linear*? According to the *Practical Linearity* paper, *"a function is linear if it consumes its argument exactly once. It is affine if it consumes it at most once"*. Can this somehow be connected to the concept of linear transformations f(x + y) = f(x) + f(y) f(c*x) = c*f(x)? From searching around a little, the term seems to stem from *linear logic*, so maybe the reason is more complicated.
Are the type errors comprehensible?
I don't understand the reason for why Data61 refuses to support Stack which is generally considered the ideal beginner tool.
If you enjoyed this, you also might like [datafix](https://hackage.haskell.org/package/datafix-0.0.0.1/docs/Datafix-Tutorial.html).
Pretty close to what I would create for an example. Only minor differences I would choose: - straight aeson parsers without digestive-functors - tasty-hunit (Assertion type is quicker to explain to beginners) Which prelude wrapper is a hard decision.
This is the correct answer. Hackage doesn't have "too many" pretty-printing libraries, it just has discoverability and ranking issues (which are hard to solve). Another thing I've been wanting latetly - some sort of namespacing on Hackage. I have a lot of code that I would love to throw up for others (and especially _myself_) to easiy grab with `cabal`/`stack` if it was clearly namespaced under my username or something, but it honestly feels rude to take up valuable global namespace with working-ish packages like my [`timer-wheel`](https://github.com/mitchellwrosen/timer-wheel) that I spent 2-3 days on, so I don't do it. Perhaps an okay solution to this probem is to host my own Hackage server and upload my junk to it, so it'd at least be cached nicely by my build tools and not re-downloaded or re-git-cloned every time. 
Yes if you fix an element type and the length of a dimension list (i.e. put type signatures with dimensions in square bracket syntax DataFrame Double [2,5,n] rather than simething like Floating t =&gt; DataFrame t (2:5:ns)). Otherwise, it can become quite really complicated
&gt; Why does stack always result in good quality work being forked Has this happened before? O_o
[nicify-lib](https://github.com/scravy/nicify-lib) is the one I picked for [hspec-expectations-pretty-diff](https://github.com/myfreeweb/hspec-expectations-pretty-diff). It's fast.
Yes. I'll leave it at that. Shouldn't have brought it up
How does one go about this painful process of enabling symbol stripping with `stack`?
Quite a bit less useful than it could be when it's not part of hackage. How can I know that all libraries have been reviewed?
If it were on Hackage it couldn't be opinionated, at least not without offending lots of people.
mind that `String` is just `[Char]`, so the binding is something like let ('w':...) = ('p':...) which *would* fail to match, except the binding is never used, so laziness means that pattern is never evaluated. No dark matter is at work here, there are four lights: Prelude&gt; let "war" = "peace" in "ministry of " ++ "war" "ministry of war"
I'd assume because Tony is involved. https://twitter.com/dibblego/status/925278706779557888
NeXTSTEP and _nothing else_.
According to `stack install --help` these look like the appropriate flags: --[no-]library-stripping Enable/disable library stripping for TARGETs and all its dependencies --[no-]executable-stripping Enable/disable executable stripping for TARGETs and all its dependencies 
Not exactly... Variables can store either values or computations; you can return either values or computations from functions; you can `force` a computation to make it a value or `delay` a value to make it a computation. There's also a distinction between things like value pairs and computation pairs. Honestly, I don't think I can do it justice, since I have never worked deeply with it. The [thesis](http://www.eecs.qmul.ac.uk/tech_reports/RR-01-03.pdf) was pretty skimmable.
I'd be curious to know why he's "certain stack has never helped anyone." I sympathize with the preference to avoid stack, but it still seems like it has its place to me.
I don't see the problem. Hackage shouldn't write that library X is better than library Y, but it certainly *should* publish that "btw, /u/tomejaguar thinks that X is better than Y" when I'm browsing Y.
Is remote considered?
Dream Job!
In all honesty, I don't know. The original repo repeatedly refuses PRs that support stack, and Tony complains *constantly* about how his students have so many problems with `stack` (presumably with his course, which explicitly refuses to support it). So we're forking the course and making it `stack`-friendly, and Tony can feel free to dump his stack woes on us :)
Could we add some of these features maybe then?
I did noticed some anti\-Stack ramblings \("Stack doesn't work at all" "I always advice people not to use Stack" \) around 00:39:35 when I was watching the otherwise great Sonic 2 Haskell live coding video at [https://youtu.be/lm\-8sbFFV24?t=39m35s](https://youtu.be/lm-8sbFFV24?t=39m35s) 
https://goo.gl/images/E8hZSU
I'm not Tony and I can't speak for him, but here are the two main issues I've personally had with stack that make me prefer cabal (esp. cabal's new-build stuff): * Primary issue: Sometimes when building a multipackage setup with stack, it will stop noticing changes until you use `--force-dirty` or similar. This has bitten me on work projects and wasted days of my time. What's weird is that when this happens you can change a file in a way that introduces an obvious syntax error, attempt a build, and stack will build some older version of your code (that is, you don't get an error from ghc). This has given me severe trust issues with stack builds. I find that I have to do a clean build before every test in order to know that I'm actually testing what I think I'm testing. * Yaml: Yaml has a lot of documented shortcomings, but the main thing I've been bitten by with stack is the ambiguous nature of some yaml. I think my config means one thing and stack thinks it means something else and sometimes you don't find out about this until pretty late after you've made the edit. These days, I attempt new-build and if that doesn't work (I honestly can't remember the last time it didn't work at this point), then I fall back to sandboxes. 
&gt; which is generally considered the ideal beginner tool. I disagree. I certainly don't recommend stack to anyone, beginner or expert. I've had too many issues with it. I think "generally considered" probably depends crucially on who you've been talking to.
`\w f -&gt; \y -&gt; w (\x -&gt; f y x)` ~ `\w f -&gt; \y -&gt; w (f y)` ~ `\w f -&gt; w . f` ~ `(.)`
Are uniqueness types the same as Affine types? My understanding was that Linear=used exactly once, Affine=used at most once. 
It's composition on a more specific type.
I notice by the way that the fork does not seem to link back to the original (https://github.com/data61/fp-course/) in any way. It might be nice if it were to do so, for those who arrive at it first, but are interested in the original version. 
I would start with the difficulty of the questions it is trying to answer \- "do these packages fulfill the same task" and "how do they rank in quality against each other."
We need to go deeper! pretty :: Doclike doc =\&gt; a \-\&gt; doc
All kinds of things *should* happen, but what tends to get done is that which can be done unilaterally.
You have to run the tests to validate your answers in the course.
[removed]
&gt; So we're forking the course and making it stack-friendly Fair enough. But what if the shoe is on the other foot? Let's assume somebody decided that `haskellbook.com` is doing beginners who want to learn Haskell using Cabal instead a disservice by covering only Stack (which makes sense given Chris is on FPCO's payroll). Would you support those who *just want to make this wonderful book available for people that want to `cabal`, for whatever reason*?
It's a first class language, with a small number of larger projects underway. &gt;1M loc. Growing reasonably, and few barriers to adoption.
That would be copyright infringement. The `fp-course` is under BSD3 license which permits redistribution with or without modification. I am not affiliated with haskellbook so I can't comment further. I welcome PRs in my own projects and learning materials to improve stack, cabal, or nix support, and as far as I know, all of my projects and libraries build equally well with stack or cabal-new (and, hopefully, with nix using `stack2nix`, though I admit I haven't tried). 
I run the course. We do it several ways, depending on setup. We don't use any build tools either :\)
Cool! :) What's one way you do it?
The minimum requirement is to have GHC installed such that all the modules load with ghci. Some people then go on to run tests or use build tools, but that's on them so that others are not disrupted when things go wrong.
But would support those people's desire to have a version of the book which covers more than one build tool? Or do you consider this the author's prerogative to decide what tools he wants to support? And speaking of the BSD3 licence are you sure you're not violating its terms? Do you have actual permission from Tony and Mark to use their names prominently to promote your derived work?
&gt; (Const is just Writer without the a value) Also worth noting that type Writer w = Const w + Identity
Though I agree with you, I'll stress that this is still a much less extreme claim than "stack has never helped anyone."
&gt; But would you support those people's desire to have a version of the book which covers more than one build tool? Sure. People can want whatever they want. &gt; Or do you consider this the author's prerogative to decide what tools he wants to support? Of course the author can decide what tools they want to support. I wouldn't expect an author, especially one contributing OSS, to do anything they didn't want to do. It is quite evident that `stack` is a burden that `data61` does not want to support (and has closed PRs adding said support), so this fork exists to provide that support. &gt; And speaking of the BSD3 licence are you sure you're not violating its terms? Do you have actual permission from Tony and Mark to use their names prominently to promote your derived work? Thanks for pointing that out! I'll file an issue on the repo. We just forked it yesterday, so I'm sure there's a lot to iron out :)
This smells like a kafka trap. I left their names in there as a gesture of respect to the immense work they put into the course. If I hadn't, I'd get called out for erasing them from their work. Since I left them in, this bizarre objection is raised. You surely know that if they asked me to remove their names I'd respect their wishes.
&gt; (and has closed PRs adding said support) Here's what I can find of PRs adding support: - https://github.com/data61/fp-course/pull/152 This one was only shortly after Stack was first released. I don't blame them for ignoring it. - https://github.com/data61/fp-course/pull/272 The user opened this an quickly closed it themselves without any discussion from maintainers. Also didn't really write any learning materials about Stack, which would be critical (as your fork successfully does). - https://github.com/data61/fp-course/pull/273/files Now, this one was closed immediately, and in seemingly bad faith as there was absolutely no discussion. However, the PR merely adds a stack.yaml and doesn't describe using Stack to readers in any way. I wouldn't say any of these constitute sufficient effort to even *try* to get them to support Stack. Not saying they'd accept any such PR, but I don't think it's fair to claim that any attempt has properly been made.
London is a fairly awesome city, worth exploring for a few years. I've moved around geographically several times and never regretted it :)
Fair enough. But would you be willing to accept contributions to extend the book to cover more tools besides Stack in a beginner friendly way? Or would this constitute a conflict of interest given your current employment with fpco? 
Agreed, it looks the best to me. I've got a TODO item to switch stack over to using it, away from wl-pprint-annotated. I chose that package because I hoped that we would have some fancy output annotations that hook into editor automations, like idris's automations that are powered by the same annotation library. However, we really just needed the functionality of ansi-wl-pprint, so I implemented my own ansi annotations in the stack code base - https://github.com/commercialhaskell/stack/blob/master/src/Text/PrettyPrint/Leijen/Extended.hs. Switching to the `prettyprinter` and `prettyprinter-ansi-terminal` would be a good way to reduce the amount of code.
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [commercialhaskell/stack/.../**Extended.hs** (master → c435a3c)](https://github.com/commercialhaskell/stack/blob/c435a3cf38ea2bd33a53819893415c1f1a4c4183/src/Text/PrettyPrint/Leijen/Extended.hs) ---- 
[removed]
1. Primarily, OSS people need to do what they *want* to do and no more. I don't believe any OSS contributor should do anything they don't want to do. With that said, I would have personally replied at-the-time with any objections or requirements that I wanted from the PR to bring it to completion, or to say that the project didn't plan on supporting `stack`. 2. This PR was made [after this commit](https://github.com/data61/fp-course/commit/2747b55dc232f3270953803859bb749b700f3cff#diff-0a369498a5a8db3ac8fa606b544c9810) which makes the official repository policy pretty clear. If the objections were "You don't teach people how to use `stack`, please include that information in the README," that'd be one thing. That's clearly not the objection. The objection is using `stack` at all. Which is fine! Totally 100% fine. Tony's doing great work with this course and I don't want to disparage that at all. We just want to make the course available to people that want to use stack.
Good bot
Thank you, mgsloan, for voting on GitHubPermalinkBot. This bot wants to find the best and worst bots on Reddit. [You can view results here](https://goodbot-badbot.herokuapp.com/). *** ^^Even ^^if ^^I ^^don't ^^reply ^^to ^^your ^^comment, ^^I'm ^^still ^^listening ^^for ^^votes. ^^Check ^^the ^^webpage ^^to ^^see ^^if ^^your ^^vote ^^registered!
OK, cool, thanks for clarifying :)
Being allowed to work with Haskell outweighs many other criteria based on which I'd choose a job, but not enough to work for Facebook.
I've been gradually moving everything I have over to David Luposchainsky's `prettyprinter`. It provides the cleanest separation between the documents, the annotations, the layout strategy and ultimate display that I've found between the various pretty printing packages. There are two major schools of pretty printing. The Hughes-PJ school and the Wadler-Leijen school, so at most you'd get the list down to two. The difference is mostly whether or not `&lt;+&gt;` tries to collapse to empty when fed mempty on either side. `prettyprinter` falls into the Wadler-Leijen approach. It has compatibility packages for providing the same API as `wl-pprint`, `annotated-wl-pprint`, `ansi-wl-pprint` to ease migration and has packages for converting back and forth to documents produced with those packages as well for when migration isn't possible. I handed over maintenance of `ansi-wl-pprint` to David, but it is pretty clear to me that any interesting work going forward will be done on `prettyprinter`. Pitch aside, a lot of the others can be classified based on functionality: e.g. printing to Text without going through String, ansi terminal color support, etc. * `final-pretty-printer` offers a bunch of additional functionality you can't find elsewhere, like support for proportional fonts. * Pointwise annotations are supported by `marked-pretty` (Hughes-PJ style) or my older `wl-pprint-extras` (Wadler-Leijen style). But I think a pretty compelling case has been made by the work on `wl-pprint-annotated`, `final-pretty-printer` and `prettyprinter` that pointwise annotations are far less useful than ones that cover spans of the document. (`wl-pprint-terminfo`, which builds on `wl-pprint-extras` had to contort itself around the fact that I only had pointwise annotations and the fact that I only supported those kinds of annotations is what initially drove David Christiansen and company to write `wl-pprint-annotated` and later `final-pretty-printer` for Idris. Some of these aren't pretty printing libraries in their own right, or are just additional functionality for an existing library. e.g. `pretty-simple` converts `Show` output into a pretty printed document. `pretty-display` is a little class that sits atop `ansi-wl-pprint` allowing slightly more human-intended output than `pretty-simple`'s abuse of `Show`, etc. Then there are a few packages that don't fit into the Hughes-PJ or Wadler-Leijen bins. Things start to get pretty obscure down here: * `pretty-compact` attempts to address some short-comings of both the Hughes-PJ and Wadler-Leijen school of pretty printing when it comes to documents full of s-expressions as well as provide annotations. * `layout` seems to be the start of a small package for doing text and latex pretty printing, but it only has tables(?) and hasn't been updated in 2 years. * `text-render` seems to be a sort of similar minimal start of a pretty printing library rather than a full library. * `boxes` which provides a different layout model based on simple nested 2d boxes. To your question of whether or not we can have one class? Probably not. Why? Well, 80% of those libraries worked with some sort of parameterized notion, either `Doc :: * -&gt; *` or `Doc :: (* -&gt; *) -&gt; *`, some of them worked with class constraints on `m` for some monadic pretty printer, rather than a concrete type. Half the time you want to work independent of annotations, the other half of the time you _do_ want to include the annotations in what you pretty print, e.g. including semantic markup so that when you finish printing you can color things correctly for terminal display. If you can only work pointwise `Doc X` for some concrete annotation type X then you'll find that you get a mishmash of constraints on the doc type itself, on the annotation and on the pair of both floating into your environment. If you tie it to the doc type and assume it'll take an annotation you rule out the grandfathers of this industry `pretty` and `wl-pprint` that don't have those annotations and rule out the folks who work with classes for their documents rather than concrete doc types. That is a lot of masters and usage patterns for one class to serve! This is even before you consider the fact that each of those document formats have rather different semantics around the behavior of (&lt;+&gt;) and the like across the Wadler-Leijen or Hughes-PJ divide, so you can't pretty print anything non-trivial without being aware of the school of pretty printing you are using. After resolving all of those technical issues, you'd need to tackle the social issue of convincing a dozen library authors into picking up a dependency. So while it feels good to call for unity and ask for a shared pretty printing class, I don't know how to pragmatically address all of those concerns mentioned above.
&gt; 1. Primarily, OSS people need to do what they want to do and no more. I don't believe any OSS contributor should do anything they don't want to do. With that said, I would have personally replied at-the-time with any objections or requirements that I wanted from the PR to bring it to completion, or to say that the project didn't plan on supporting stack. Not quite sure which PR you're referring to, but if you mean the third one I listed, yea I agree the discourse wasn't handled well. For the others, I don't blame them. The second was closed immediately by the author. And the first was way before considering Stack was a high priority. &gt; 2. This PR was made [after this commit](https://github.com/data61/fp-course/commit/2747b55dc232f3270953803859bb749b700f3cff#diff-0a369498a5a8db3ac8fa606b544c9810) which makes the official repository policy pretty clear Yikes. That clears this whole thing up for me :) Certainly that's a strong enough message to ward off any and all PRs.
I was trying to respond to the PRs you linked in order and forgot to use a `3.`. Should have been more clear
What about those "New to haskel n want to get into it."?
He says Stack doesn't work *on NixOS*, which matches my experience as well. And I agree with him; if you are on NixOS, using nix would generally be a smart choice.
I wouldn't personally consider download counts a very good metric. I don't have any idea what a good metric would be. But for example, the `is-even` npm package [has 24k downloads *per week*](https://www.npmjs.com/package/is-even), but only because some actually important package has a distant transient dependency on it. Almost no one would personally choose to depend on that package if they could avoid it.
I've been using Haskell for about half a decade now but it still got me confused. It is completely useless.
Stack works fine on NixOS if you either pass --nix, or add `nix: enable: true` to `~/.stack/config.yaml`
The claim that he has made to me is that stack doesn't work *ever, at all, for anyone* and anyone that thinks otherwise is deluding themselves. Which, uh, doesn't correspond with my experience, but I'm sure Tony's experiences differ such that that's a reasonable thing to think.
Thanks! So it's just repl cannot infer most general type? 
Should I expect repl inferring the most general type?
I’m happy to work in OOP land if that means I never work for Facebook or some other crooked companies :) 
I wonder how well would a backpack-based approach work. The implementation "adapter" packages for each library would likely have to define newtypes over `Doc` to smooth out the differences.
&gt; \ w f -&gt; \y -&gt; w (\x -&gt; f y x) Here you are saying that `f` is a binary function and `w` takes a unary function. Your term as defined demands more structure from its two arguments than `.` does. It just so happens that when `.` is restricted to the same types as your function, they are observationally the same. The more structure you assume about your inputs, the more specified their types are. In general it's undecidable, given a value with some type, whether there is some other value with a more general type that has the same behavior when restricted to the original domain. Even saying "this type is a more specific version of that type" is a tricky question in general.
Are the enhancements produced going to be contributed upstream? Maybe the offer should clarify this.
A stack snapshot only covers your Haskell dependencies. Of course it can't solve breakages if there is a mismatch between your Haskell stuff and every other dependency, of which there are tons between you and the hardware. *Stack doesn't solve that problem*; it doesn't try to. &gt; This is just not acceptable for a language used in production and even just for small personal projects it creates constant busywork and makes me question my choice of using Haskell. I would say try Nix, but Nix is hard to use. However, it *is* designed to solve this problem and can do so to varying degrees. If you use just Nix, then everything but your OS can be locked down. If you use NixOS then even your Kernel can be locked down. A more mainstream option is docker but that comes with its own pains and bureaucracy. Now, if you don't think this problem plagues other languages' development environments, that's because upstream providers try to make sure they don't break, but Haskell doesn't get the same share of resources. That's not the Haskell community's fault, nor is it the fault of the Haskell tech stack. Even so, any sufficiently serious project will have to do something like containers or Nix because these things happen to *everyone* at some point or another. Is that threshold sooner for Haskell? Maybe. I don't know if anyone should be avoiding this tech in production in the year of our lordt 2018 though.
This is some Insanity Wolf meme shit &gt; Be new at Haskell &gt; Take a job at Facebook working on GHC with Simon Marlow
I try to use `cabal new-build` as much as possible but I'm surprised you have had such a good experience. I hit the "shadowed dependencies" but nearly every single day. I have a shell alias for `rm -rf dist-newstyle &amp;&amp; rm -rf ~/.cabal/store &amp;&amp; cabal new-build`. It's cabal new-hell ;)
I hear there's more murders per capita in London than NYC.
Is there a reason that kind of binding is allowed? It seems like a nonstrict let binding with a pattern that binds no names is always dead code.
I suppose most people just copy and paste the doctest stuff into ghci? Being able to run test suites would be a bonus for learning too I guess :\)
Well that doesn't say much, though. Last century, sure, NYC was a gang-infested nightmare, but today, it's a very safe city. Its crime rate is much lower than the US national average.
Hmm, well the change detection issue certainly shouldn't happen, sorry the problem wasted days of your time. I think I recall there being a fix to a symptom like that. Have you experienced that with recent stack versions or is this just a contributing reason to switch a while back? I suspect that this is no longer a problem. Please report such things to the stack issue tracker!
It is because there are some folks that will obstinately refuse to merge even trivial changes that fix their stuff building with stack. Happily this is a small minority of people, most people want their stuff to work as much as possible
Am Londoner; can confirm - am dead.
Why not both?
Why are they doing this? When did this start? What caused these animosities?
The ultimate dealbreaker.
Good documentation. Precise types. Regarding dependencies, I much prefer when they are well-established libraries that I'm likely to find a use for anyways. Or when they're fairly small. It just feels so silly when your project has second-hand dependencies for five different libraries that do the same thing. 
Do people in this sub like facebook as an employer? 
You heard wrong.
That must be the most extensive production environment running Haskell today. Very enticing, thanks!
If you have modules that you want to consider internal, still expose them in your cabal file but put internal in the name somewhere.
- ["I'm certain stack has never helped anyone. It's easy to make the mistake of believing otherwise."](https://twitter.com/dibblego/status/925599580955164672?s=20) - ["But homeopathy works for me! and Judy and Bill. How can you just dismiss our experiences!?"](https://twitter.com/dibblego/status/992920161874137089?s=20) (the response to, like, at least six people in the thread saying "stack has been pretty great for us") - ["It also hasn't been for you. That's my claim, and I can point to why."](https://twitter.com/dibblego/status/992643861070561280) (in response to ["Stack was great for me as a beginner and all of the beginners I've helped learn fp."](https://twitter.com/mattoflambda/status/992643264321871872)
https://www.reuters.com/article/us-britain-crime-murder/london-murder-rate-overtakes-new-york-as-knife-crime-rises-idUSKCN1HA1DH
That's not delusion, right? It's just believing someone is wrong about a thing. Believe it or not, it used to be a thing that could be moved passed in a helpful way.
The Haskell code in GHC is actually rather simple in terms of language features used. So it's not as bad a way to get into Haskell as it might seem.
I have a lot of friends and past colleagues who work there and wasn’t familiar with the extent of this anti-fb sentiment. Is it a r/haskell thing? Is it recent, related to the Cambridge Analytica news?
Consistent naming and parameter order is always a plus.
Chris was hired at FPCO *way* after the book was finished.
Speaking of obstinately refusing to merge trivial changes which would help *stuff to work as much as possible*... what about [restoring the links to cabal config files for the benefit of non-Stack users](https://github.com/fpco/stackage-server/issues/232)?
Sure, and the thing that Tony appears to believe that the people are wrong about is their own experience; eg "A: Stack helped me" "B: No it didn't." If I say, "I saw a blue flower today," and someone else said, "No you didn't," then it would be very difficult to interpret that as anything other than "You're memory of your own experiences is faulty, and I happen to know better about your own experiences than you do," which is a bit of a weird claim.
I have never been able to figure out exactly what uniqueness types are. But my understanding of affine types agrees with yours. Rust has something called ownership types, and I don’t understand exactly what that means. There’s a language called clean that claims to have uniqueness types.
What if someone claims that stack helped them in a way that was otherwise not possible? Then, you were to believe that actually no, the help that was obtained by that process is inefficient, the measurable results in having a poor grasp of the subject matter highlight that inefficiency, and that any benefits that were gained, were despite stack not because of it. There exists a strictly superior and strictly more beneficial method of learning, that has been executed in a way that is much more reliable than the reports of a few beginners who have used stack. That is believing a method of learning is beneficial. What if that is wrong? Is that delusory?
Yeah sure, that's equivalent to picking a day such as May 4th and then claiming "I hear there's more murders per capita in London than NYC.". These are the sorts of posts that makes you wonder if reddit is a waste of your time.
I had replied to this then they posted about a 2 month period where London had slightly more murders in the last 30 years... I deleted my post after reading that. Not much point discussing the topic with someone using that as evidence :)
&gt; pretty-simple's abuse of Show, etc. What do you mean exactly ? Show is supposed to output valid Haskell and usually, pretty printing means displaying code in a pretty way (as for example an editor will do). That's exactly what pretty-simple do. 
Now *this* is a reasonable claim! :) On the topic of teaching beginners: I use `stack` to get people started with Haskell, once they've advanced beyond the "use GHCi and GHC to play with single files." It is a one-stop tool that takes care of their GHC version and does a good job of avoiding many common dependency problems. The experience is the same across OSX, Windows, and Ubuntu, so I spend more time helping with Haskell and project-related stuff than "here's how to do it on Ubuntu, here's the OSX way, here's the Windows way" -- I just say "Here's the `stack` way" and it works for everyone. Ultimately, the question of "How do I manage my GHC version?" comes up when some library works with GHC 8.0 but not 8.2 etc. Many developers are used to tools like `rustup`, `rvm`, `nvm`, `phpvm`, etc to manage their compiler/build toolchain on a per-project basis, and `stack` fills that role nicely. So if you can present a tool or workflow that more quickly and efficiently has these properties: - Project scaffolding and initialization - GHC management on a per-project basis - Ability to clone and manage non-Hackage dependencies - Provides some amount of safety wrt dependency conflicts - Works on OSX, Windows, and Linux then I will drop `stack` today, both for my own projects, and for when I teach others. &gt; There exists a strictly superior and strictly more beneficial method of learning, that has been executed in a way that is much more reliable than the reports of a few beginners who have used stack. Please, share! I use stack because I am ignorant of a better way. This is not a claim that stack is the best evar, or that stack is even the best tool around today -- I am just not aware of another one. I promise, I will listen to reasonable arguments and I'm not dogmatically in any camp -- after all, I used other things before `stack` and only switched when it seemed reasonable to me to do so :) &gt; That is believing a method of learning is beneficial. What if that is wrong? Is that delusory? Ultimately we can only compare experiences. I had some experience of learning and teaching Haskell before `stack` (vastly more learning, the "teaching" was more of an excited noob trying to share). It was hard and difficult and I experienced a lot of problems with dependencies and GHC versions. I then had some experience learning Haskell with `stack`. These experiences were better. Is there some third set of experiences that are *even better* than `stack`? I'm sure there are! I just haven't **seen them** yet. But I am not wrong or deluded when I say that "Stack was an improvement over what I was doing beforehand." The possibility space for doing things wrong and bad is vast, and `stack` is far from the lowest point there :D
I think you read that far more negatively than I intended. I mostly just meant more that pretty-simple was twisting `Show`'s output into another form by reformatting it, and that because of the number of wonky `Show` instances out there, it is a bit of a stretch to assume that you can reformat it without a problem. One admittedly could argue that it is those instances that were truly abusing `Show`, and they are, but it makes the situation a mess. It works reasonably well if you are working mostly with stuff from base or that you wrote, though.
That'd handle a subset of the scenarios above, or work when you lock things down to a particular Doc type applied to a particular set of arguments, but you don't have the parameters to plumb through to handle things more generally. That would also still leave you the issue of dealing with the different conventions between Hughes-PJ and Wadler-Leijen, etc.
They probably weren't supporters of free software. I think most haskellers are.
Of you are a señor in ocaml, possibly.
I agree on its own it doesn't help. But combined with rating and upload date it at least tells you to first approximation _something_ about the package. 
Less competition :P
I probably shouldn't comment so vaguely on this. I didn't really want to rehash it, but against better judgement commented anyway. So yeah, have a good friday, y'all
I said free software, not opensource. Free software endorsement is about ethical principles, not public code. And facebook is one of the greatest examples in the antipodes of this ideas.
I'd imagine it makes the executable bigger. But I'm not at a computer right now, so I can't check. 
I see MIT licenses on the repos I randomly chose to check, that seems like it fits with Free software principles?
Just realized this now but sometimes with `ApplicativeDo` I use `Const` like `Writer` when I don't care about the result. And, usually, when you use `Writer`, you don't care about the result anyway in practice. Useful for things like https://ocharles.org.uk/blog/posts/2013-02-12-quick-dsls-with-endo-writers.html !
Oh, `hspec-expectations-pretty-diff` looks like a useful package. Cheers!
Facebook's business model is to acquire information as intimate as possible about as many people as possible, aggregate that data in their database, and sell your attention to advertising companies. It plays a large role in both the recent rise of populism and the constant extension of surveillance infrastructure. Its convenient and fun and social, but overall I think it damages our society.
&gt; I suspect that people's concerns are really much more about the recency of the CA news My distaste for Facebook long predates CA or the 2016 US election.
`subtract` is the same as `flip (-)`, not `(-)`, so your last line should read like this instead: … = (`subtract` x) y
We also got the patent grant removed from the Haxl license, FWIW. My understanding is that it just takes time and effort to update all these licenses.
Right. Thank you for explanation! So `(\x -&gt; f y x)` implies `f` takes [at least] two arguments - I missed this, and `α-conversion` doesn't preserve *most general type*.
Standard Chartered Bank has several million lines of Haskell, based in London and Singapore.
That question is conditional. And it would be valid only if "my function" was not "composition", which is (as explained) not the case.
It was the reasonable claim the entire time. I have presented a tool or workflow that does not meet your properties, but absolutely poops on anything in terms of efficiency and effectiveness learning Functional Programming. 
The setting of cost centres compromizes compiler optimizations big way. If you set them in critical parts of your program, you may end up with degenerate performance — by orders of magnitude. See [this Stack Overflow answer](https://stackoverflow.com/a/48412705) for example. Also, this is why you should not really trust internal profiling. Always have some numbers written down for the space and time performance of your code compiled with `O2` and without `prof`: if your program performs significantly worse with profiling enabled, you should distrust the results. I have heard that "ticky-ticky" profiling has negligible effect on performance, but my impression is that it is a bit hard to set up and so I did not try it yet.
I'm nowhere near knowledgeable in the field, but in this context, I imagine "linear" to mean something that doesn't branch out. Like games with a linear story line.
We use that combo in `dhall` to do syntax highlighting in the terminal. It was an absolute breeze to implement that.
 1 cat 4 brown 6 submarine 2 two 4 reddit 6 haskell 6 mouse would result in: 4 brown 6 submarine 4 reddit 6 haskell
Yes! Works like a charm! Thank you! 
A solution using the [streaming](http://hackage.haskell.org/package/streaming) library, just for kicks: import Data.Foldable (toList) import Streaming import qualified Streaming.Prelude as S import qualified Data.Text as T import qualified Data.Text.IO as TIO main :: IO () main = withFile "/tmp/source.txt" ReadMode $ \hSource -&gt; withFile "/tmp/target.txt" WriteMode $ \hTarget -&gt; S.mapM_ (TIO.hPutStrLn hTarget) . flip S.for S.each . S.filter (\window -&gt; toList window == [T.pack "4",T.pack "6"]) . S.slidingWindow 2 . S.untilRight $ do atEof &lt;- hIsEOF hSource if atEof then Right &lt;$&gt; pure () else Left &lt;$&gt; TIO.hGetLine hSource
 &gt; import Data.Tuple &gt; let f = \w f -&gt; \y -&gt; w (\x -&gt; f y x) &gt; ($ 3) `f` (+) $ 2 5 &gt; ($ 3) . (+) $ 2 5 &gt; (fst . swap) (1, 2) 2 &gt; (fst `f` swap) (1, 2) &lt;interactive&gt;:10:2: error: • Couldn't match type ‘t10 -&gt; t20’ with ‘(t3, b0)’ Expected type: (t10 -&gt; t20) -&gt; t3 Actual type: (t3, b0) -&gt; t3 • In the first argument of ‘f’, namely ‘fst’ In the expression: fst `f` swap In the expression: (fst `f` swap) (1, 2) • Relevant bindings include it :: t3 (bound at &lt;interactive&gt;:10:1) &lt;interactive&gt;:10:10: error: • Couldn't match type ‘(Integer, Integer)’ with ‘t10 -&gt; t20’ Expected type: (Integer, Integer) -&gt; t10 -&gt; t20 Actual type: (Integer, Integer) -&gt; (Integer, Integer) • In the second argument of ‘f’, namely ‘swap’ In the expression: fst `f` swap In the expression: (fst `f` swap) (1, 2) 
I am so stupid. I even tried it out in the repl beforehand.
How about: main = interact $ unlines . map (show . round5 . read) . tail . words
That's cool. I've done a similar thing [in my game](https://github.com/soupi/yh/blob/master/src/Play/Engine/Sprite.hs). One thing where this could be improved is by adding the ability to have multiple action animations.
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [soupi/yh/.../**Sprite.hs** (master → 69a92c5)](https://github.com/soupi/yh/blob/69a92c5fbdad4a85d1a51619ed772942d7211f4a/src/Play/Engine/Sprite.hs) ---- [^delete](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dyuw57z.)
Really love these videos! :)
I reckon sed or grep could do what you want. The speed difference will be small and probably outweighed by the time to write the Haskell program.
Glad you found a Haskell solution. For reference, it sounds like `grep -A 1 '^4'` would work too.
Thank you for this, hope you continue the series
This is also a working solution, but packing everything into one line rather than logical units isn't an improvement.
Sed will probably be faster, not slower
I agree that testing is somewhere between nice and necessary, but I do not believe it is imperative to prove to someone that my library is good enough for them. I do not even think one *can* prove one's work to be good in any way: the goodness of the work is something the author can hope for, but not be certain in, and if you cannot actually make such judgement, trying to convince others as though you were yourself sure is dishonest. So, I cannot help but find that proving goodness is both a poor motivation for testing and an unethical endeavour by itself.
I'd disagree with the `Internal` to be honest. I'm all for hiding constructors and what not if you're going down the smart constructors route or what not. But I think `Internal` should be used sparingly so that people can access modules if they _need_ it. Otherwise they're just gonna end up forking.
Just fyi, you used backticks to make a function an infix operator but didn't explain that.
is there some articles to point at in order to get started with quick check? thanks. 
\&gt; he Haskell stuff started to surface at about an hour in or so That said, the first 60 minutes or so is not about Haskell.
There is also `readLn = getLine &gt;&gt;= readIO`. It's nicer that `fmap read getLine` because it throws an IO exception immediately if the input doesn't parse correctly rather than waiting to throw a pure exception at the first use of the parsed value.
Is it the act of trying to demonstrate rigour and effort (therefore "quality") that is unethical, in your view? Or have I misunderstood.
fwiw `zip` breaks streaming for lists, so this *may* not have the desired properties
The pound becoming weaker means engineers are cheaper to employ. 
Sounds like Shake might be appropriate instead: https://shakebuild.com/
&gt; 1+ years experience working on and contributing to an active compiler toolchain codebase, such as GHC, LLVM, GCC, MSVC Welp, this cuts out almost everyone. I wonder if it would be easier to just approach the few people who actually do this directly? 
I might have misunderstood. But do you mean to hide the Internal module or expose it? :)
&gt; If /u/quchen changed the description field […] to say pretty-printer instead of prettyprinter, that would make it a bit more discoverable [Thanks for the suggesion!](https://github.com/quchen/prettyprinter/commit/fea133ca1b0eec3445487dc7667fcf72b432fe88) 
I'm personally split on that one. I have libraries where I expose the `Internal` *just in case*, with a "buyer beware" disclaimer, but also ones where I hide in cases where I'm confident that there's nothing a user could need in there.
GHC can stream a list if it is only ever consumed once. Then the intermediate data structure is never materialized, and everything is fine. Consider `sum [1..10]`. We know that `[1..10]` is only used in one location, so we can garbage collect it as we go. For `sum . map f . filter p`, there simply never even is a list that gets allocated, due to fusion (specifically, [short-cut fusion](https://wiki.haskell.org/Correctness_of_short_cut_fusion)). But when you do `zip xs xs`, `xs` must now be maintained in memory, so we have to materialize the list. (I'm pretty confident on this, but I might be wrong)
[removed]
Ok we're on the same page :D
If that's the case, I'm really abusing zip a bit anyway because it's in prelude already. You can replace that part with pairs x:y:rest = scanl ((_, b) c -&gt; (b, c)) (x, y) rest I think (on mobile). Not as elegant, and needs more handling for when the list is smaller, but at least it's a composable piece (assuming scan maintains fusion and streaming?) 
I'd generally agree, but the Haskell stuff at Facebook seems relatively benign. Reducing spam, contributing to GHC, lots of OSS stuff, etc.
There are few if you just look at GHC. Once you expand out the list, you'd be surprised how many there are !
Hmm, while the idea is pretty cool, it looks like an overkill for a compiler, mostly because both domains (compiler vs build system) are a bit different. Also I can't see how to use Shake base code as library. It forces me to create build dirs etc. Basically what I try to achieve is to have an API looking similarly to this: -- Given import clause (with wildcards), list all imported symbols -- use std::io::* -&gt; [print, write, FileReader, Stream, ...] fetchImportClauseImports clauseAst = do mods &lt;- resolveModulesOfImportClause clauseAst exportGroups &lt;- map getAllExports mods return $ concatMap exportGroups
I'm getting an error page :( &gt; **Page Under Construction** &gt; We are making several improvements to our careers site and have lots of exciting opportunities. Our site will be up momentarily. https://imgur.com/a/1VKJriX 
I think you are off in several ways here. First of all, your function `f` doesn't take "nothing" as argument, but the only possible value (called "unit") of a type (called "unit") with *cardinality one*: data () = () That is, this data type doesn't encode "no information", it encodes a single piece of information that is useless, because it's always the same. So basically, all that `()` does when it goes into your `f` is say "*Here I am!*". Contrast this with a value that really doesn't doesn't encode anything, literally: data Void {- No right-hand side -} Not only doesn't it encode *anything*, it can't even take any values, it has cardinality zero. You might have heard that Haskell's algebraic data types correspond to things you know from high school algebra. Technically, they form a *semiring* `(Type, +, *, 0, 1)` where + : Type -&gt; Type -&gt; Type + = Either, i.e. the type constructor on the left hand side of its definition * : Type -&gt; Type -&gt; Type * = (,), i.e. the 2-tuple type constructor 0 : Type 0 = Void 1 : Type 1 = () Then, things like `1 * x = x` make sense, since `((), Int)` does not encode any more information than `Int`, or `0 * x = 0`, since you can't construct a `(Void, Int)` in the first place. Functions behave like exponentials, that is, `f :: () -&gt; a` encodes the same information as `a^1 ~ a`, which you can imagine as a one-element vector of `a`s that will give you an `a` if you index into it using some type that can only take one value. Just like, ideally, you would have an index that can only take three values for getting an `R` out of an `R^3`. Ok, so we have `a^1 ~ a`, but what exactly *is* this `a`? Since you didn't constrain it to something like `f :: Monoid a =&gt; () -&gt; a`, it can be *anything*. Including a function of course, just like `undefined :: a` can stand for anything (like your `g :: a`!). If you tried to implement this function, you would have a hard time to construct such a value. Compare: f () = ? head [] = ? Indeed you can make this function typecheck with `Void`, that is f :: () -&gt; Void should tell you something goofy is happening here. The typechecking approach is generally useful. For instance, you know that scary :: Monad m =&gt; Int -&gt; m Int is actually pure since it typechecks as `scary :: (Int -&gt; Identity Int) ~ (Int -&gt; Int)`.
Can someone explain what makes DFINITY the "internet computer"? Is it supposed to be a distributed system where consensus is reached for a transaction that's executed by a WebAssembly VM and, if so, does it avoid the scalability issues like long transaction processing times plaguing past systems?
Due to the pumping lemma for regular grammars, you're not going to have any particularly nice combinators, since if you have any binary operator with more than one option, the pumping lemma would apply. E.g. if you have combinators to match 0 and 1, and composition/alternation operators, then you can match any computable subset, so it's not remotely regular. You might be able to describe a regular language based on a total computable function from the conatural numbers (so natural numbers with infinity, i.e. what you get in haskell if you have Nat = Z | S Nat, since it has S (S (S ...))))
Are you looking for something besides the operations that build up regular expressions? I.e. you have the empty language, alternatives, the empty string, concatenation and the Kleene star. Without the Kleene star you want the axioms of a semiring, and with the Kleene star it's called a closed semiring. There's a nice functional pearl that shows some applications of such a structure, with Haskell code: [https://www.cl.cam.ac.uk/\~sd601/papers/semirings.pdf](https://www.cl.cam.ac.uk/~sd601/papers/semirings.pdf)
Wow, that's exactly what I was looking for, thank you! 
This seems to contradict the answer above given by /u/maxiepoo_, or am I missing something?
Internet dialogue success &lt;3
Good to know, thanks!
You changed the words. Shifted from actual goodness to the effort to reach it, and from proof to demonstration. My proposition was that the goodness of the work is something the author cannot be a judge of. But of their own effort, they have direct knowledge. *(Notice that the work may still be flawed, despite the effort put thereinto.)* I do not think an honest effort may be demonstrated though. It is an internal state. Can you show off your headache, or your wisdom? I like your new phrasing much more though. It highlights attainable states of mind that would inform the process, rather than external judgement of the result.
It's because haskell is lazy, so we can build infinite structures even if the tools we have seem finite.
I like the following pattern: Prelude&gt; f xs = map snd . filter ((==3) . fst) $ zip xs (tail xs) Prelude&gt; f [1..100] [4]
I'm not sure if this is exactly what you're looking for, but you may be interested in [VerbalExpressions](http://verbalexpressions.github.io/) ([original JS](https://github.com/VerbalExpressions/JSVerbalExpressions), [Haskell port](https://github.com/VerbalExpressions/HaskellVerbalExpressions)).
&gt; If monadic parser combinators correspond to context sensitive grammars, and applicative combinators correspond to context free grammars Is that true? Which kinds of lookahead primitives are you assuming?
This comment from that thread still holds true, afaict. &gt; I'm not opposed to adding in information on using with cabal-install again, but in its current state, I don't believe we can advertise the cabal.config file. In particular, due to Hackage file revisions sometimes breaking old build plans, the current format (which does not include any Hackage file revision information) is unsuitable. I'm not familiar with all the details of cabal.config files to know if they support indicating Hackage file revisions. Such a change would be necessary to reliably provide support for cabal-install. tl;dr It would be reasonable to restore said links if and only if cabal.config can be used to pin packages to exact revisions.
[regex-applicative](http://hackage.haskell.org/package/regex-applicative) is a very nice library.
&gt; To defer the ambiguity check to use sites, enable AllowAmbiguousTypes Do that; the ambiguity check is misleading for APIs which use type applications.
I was trying to avoid that. Is there a way to allow ambiguous types for only one function?
What is this Pied Piper?
In my experience, this feature has been more trouble than it's worth, and I'd rather see it removed. The ability to run `ghci` instead of `cabal repl`, or somesuch, is not at all valuable to me, but these environment files frequently cause extremely confusing behavior. Just yesterday I had someone come to me for help because their project failed to build, but only when it had a specific parent directory. Lo and behold, he had one of these files in there and didn't even know about it. The reward seems superficial and unimportant to me, while the costs are extreme confusion. Not to mention, if you're using a `nix-shell` + `cabal-install` workflow, you're in for even more hurt with these files. Also, it's very common to be building a project with multiple different versions of GHC, which can have unexpected behavior because of these. I'll admit to some bias here, as I haven't truly taken the time to appreciate why one might want this feature. But so far it has been a major pain for me.
Agreed. This feature is confusing and harmful. It's only made me annoyed. 
Paul Hudak’s name is misspelled. 
Looks like it's from a novel mechanism called Threshold Relay that derives consensus from randomness Threshold relay; https://www.youtube.com/watch?v=9HRurPVF3Pg Internet computer (from their docs page): https://dfinity.org/pdf-viewer/pdfs/viewer?file=../library/dfinity-internet-computer-intro.pdf
I think you can rewrite any lookahead parser into a backtracking one, but definitely not positive. If you had: lookahead a *&gt; b &lt;|&gt; c You can change that to. combine a b &lt;|&gt; c Where `combine` is not a real function, but instead a mechanical translation of `a` and `b` into a subset that parses both. 
Imho the default behavior is not great, and really should have been rethought, but the files themselves are potentially useful. In the new-* everything world of cabal, having an ambient package environment a-la-carte is really nice. But the UI around it is not good at the moment, and having them auto-created while there's these warts in the UI is really unfortunate for everyone. I didn't realize until just recently that this was new Cabal 2.2 behavior! In particular, the search logic should be improved. It would be good to only search upto the same level as a cabal.project file, for one. Additionally, these files should not be auto-created, which circumvents expectations. Instead, they should only be created when explicitly requested by some specific `cabal` command, so users know what they're getting into. That said, I think the design is these files are per-ghc-version so I'm surprised there's different behavior when moving between ghc versions?
Thanks for the link. I found the claim `The 1st Open Standard for Universal Software That Runs Anywhere` funny. But other than that, it's interesting they're not being specific what actually can be expressed in the "business logic" that runs on this system and how scheduling and resource allocation are handled. I don't think you're going to port a video encoder to DFINITY. In one of the slides they show that the Dproc is run on DFINITY and the Dapp is run on regular servers. I want to believe this is realizing the vision of a universal, distributed, infinitely scalable computer, but I can't yet see how. `threshold-relay-blockchain-stanford.pdf` is interesting, but I'm lost at their claim it achieves consensus without concensus (quorum), just to follow it with `Only a threshold of group members needs broadcast a signature share`. Their PHI use case sounds promising but they're ignoring that a cashless society is a society at higher risk and less autonomy of the individual. I get they want to build a demo, but page 20 in `phi-dfinity-extended-v2.pdf` is naive, to say the least. Too much to digest at once, have to ponder why a totally unique and unpredictable random numbers obviates the need for the usual consensus process.
&gt; If monadic parser combinators correspond to context sensitive grammars, and applicative combinators correspond to context free grammars Unfortunately, while this "feels" true, it isn't actually true. Applicative parsers can parse context sensitive grammars over finite alphabets. The key is that you can build an _infinite_ "context-free" grammar that has one leaf for every sentence you'd parse. The need for a finite alphabet comes from bounding the fanout of `(&lt;|&gt;)`'s between the different cases.
This doesn't really answer the question of how difficult it would be to implement in GHC but that seems like it would make things more confusing to have a special corner case like that when, as-is, you only have to use a `newtype` and it's clear from any perspective (inside or outside the module) what you mean.
[removed]
Is there something to be said about the complexity of monadic/applicative parser combinators for context sensitive languages?
GPL is what is in line with Free/libre software. MIT is very much "free as in beer", not "free as in liberty and ethics"
Very Pythonesque, and very wise.
[this post on star-semirings](http://r6.ca/blog/20110808T035622Z.html) is really really cool too
I'd be happy to use a workflow that is more efficient and less complex. What do you suggest I use instead of `stack`? I'm unhappy that you feel good faith was busted. I still extend good faith and charity in trying to understand you; if you feel I am not doing so, I'll certainly try to do better.
I'll show you in Boulder. Forking the repository is not going to fix anything. \-\-\-\- On the good faith thing, I don't mean you, personally. The following paragraphs are in good faith. I'm sure it will be pulled apart. On good faith, I also don't mean Chris' recent gaslighting and subsequent idiocy \(he's had a tough time, I can let it slide\), or mgsloan's repeated rancid abuse \(too gross to post, don't ask\). That doesn't directly affect me personally, but it does affect others, and therefore, me. Years ago, when this political nonsense started, a number of my friends, highly skilled programmers, stopped contributing to the overall collective of knowledge and code in our common field. You probably don't know these people exist. In my opinion, their total individual contribution to knowledge and progress is far greater than anything that has been provided by the individuals of this movement combined, and by extension the program, stack. Call that selfish if you like; it is. Importantly, most importantly, this slide backwards really shows when you have contrast, which is why you see either opposition or exasperation, not just from me. Therefore, stack is one concrete manifestation of something that I will call, "massively indebted to the collective of human progress." Anything I say or do pales in comparison to the damage that is being done here. I'd really rather focus on technical matters, but that has proven impossible, again. "Stack does not work" is a far less grandiose claim than that provided by opponents. It's part parody of the excessive confidence on display, and lack of insight into the consequences of the subsequent failure that inevitably results \(as in the most recent case\), but mostly it is accurate, technically and can be examined as such. It may be brief, or require expansion to clarify \(of course it does\), but it is universally met with political idiocy; another slide backwards. It also provides a different start point from which to begin corrections, however inaccurate it may be on its own. This is incredibly important in achieving useful outcomes in discourse. However, unfortunately, criticism of stack is almost immediately responded to with some contrast to cabal, as if, there must be sworn allegiance to one of two political parties. Just to test this silly scenario, mention nix, and now you're in one of three political parties. It's utter utter stupidity and I want no part of it, except to have a laugh. In short, you're not helping. Not you, personally, but you, whose head cannot fit the idea of "assume good faith." It destroys discourse. I am happy to be your scapegoat for it.
Agreed, Phi looks fascinating still wrapping my head around that one The founder responded to some critiques on it here a year ago: https://www.reddit.com/r/ethereum/comments/5fjncm/a_critique_of_phi_the_lending_platform_and_stable/
According to (this article)[https://simonmar.github.io/posts/2016-02-12-Stack-traces-in-GHCi.html] you can also get stack traces using -g without the overhead, if that's what you're trying to use -prof for.
Impressive... Although makes me want to write an ironic profile of myself like "goes grocery shopping most weeks."
Unfortunately not. This is why so many APIs still use `Proxy` passing, even though we've had explicit type applications for a couple of releases now. `AllowAmbiguousTypes` lets too many programs through that are actually bad. =(
I genuinely appreciate your willingness to expand, and I'm looking forward to seeing things in Boulder :) I owe you a beer (/other beverage of your choice) for the course, after all!
Beer is good :\)
The FSF [regards MIT as a free software license](https://www.gnu.org/licenses/license-list.html#X11License), even though it naturally isn't strongly endorsed by them in the way the GPL is.
The only difference between Tayacan's solution and reximkut's solution is that it avoids a second map by doing a quick manual fusion. (For reference: `main = interact $ unlines . map show . solve . map read . tail . words` was the solution in the video, where `solve = map round5`)
Since I'm pretty new to the haskell toolchain I thought I could add some value by talking about things I encountered.
There are 2 related problems: 1. Lazy data structures: your parser can be infinite. 2. Functions: your parser can have an infinite number of nonterminals. For example, a finite regular language cannot parse `a^n b^n`, but it's trivial to do with even less power than 'regular language combinators'; we don't even need kleene-\* -- basic parsers eof, a, b :: Parser -- alternation (&lt;|&gt;) :: Parser -&gt; Parser -&gt; Parser -- sequence (&lt;.&gt;) :: Parser -&gt; Parser -&gt; Parser an_bn :: Parser an_bn = infiniteparser 0 infiniteparser :: Int -&gt; Parser infiniteparser n = eof &lt;|&gt; (a &lt;.&gt; infiniteparser (n+1) &lt;.&gt; b) 
Yeah, I wish they would address these obvious questions in their overview material.
Just for the kicks, here's a way of doing it without lazy IO, using the [streaming](http://hackage.haskell.org/package/streaming) package: import Data.Foldable (toList) import Streaming import qualified Streaming.Prelude as S import qualified Data.Text as T import qualified Data.Text.IO as TIO main :: IO () main = withFile "/tmp/source.txt" ReadMode $ \hSource -&gt; withFile "/tmp/target.txt" WriteMode $ \hTarget -&gt; S.mapM_ (TIO.hPutStrLn hTarget) . flip S.for S.each . S.filter (\window -&gt; toList window == [T.pack "4",T.pack "6"]) . S.slidingWindow 2 . S.untilRight $ do atEof &lt;- hIsEOF hSource if atEof then Right &lt;$&gt; pure () else Left &lt;$&gt; TIO.hGetLine hSource
A compiler usually ends up having a build system in it eventually, to support things like `.hi` files in GHC for example. Currently Shake does require build dirs, but that's not fundamental and could be removed if people wanted. Ultimately Haxl and Shake aren't that dissimilar in their underlying guts, so it may well be that neither works for you. Maybe all your really want is memoisation?
Awesome, thank you - definitely going to take a look at that :)
one can not blame companies though for using patents; being profit-oriented is natural and generally healthy; the problem is the patent system [its existence], not the companies utilizing it
copy-left does not add any freedom
Using the `State` monad sounds a lot like how game developers `pool` resources in the beginning and never allocate/deallocate. If there are bullets in the game, pick a number good high enough and never have more bullets than that. Even if that number's pretty big, gamers care more about dropped frames than high loading times.
I thought lenses would fit this wrapping well main = readLn &gt;&gt; interact solution where solution = lined . _Show %~ round5 but it turns out `lined` and `iso lines unlines . traversed` do different things.
nothing unethical exists in utilizing the copyright or patent system for money; the problem is the existence of such law, not the companies adopting their business practice to them
With `lens` λ Control.Lens&gt; each (Just . (+2)) (1,2,3) Just (3,4,5) There are `Each` instances (providing `each`) up to 9-tuples. My `vec` package has also `VecEach`: λ&gt; traverseWithVec (\x -&gt; Prelude.traverse (Just . (+2)) x) (1, 2, 3) Just (3,4,5) but that's more useful when you need to transform n-elements to n-elements, with interactions (non-independently). For example, given `f, g, h :: a -&gt; a`, return `g . h`, `f . g`, `f . h`. You could use `partsOf . each`, but that's not as safe! 
it does not matter who you work with if the cooperation is for a good goal
The bounds are meant to be specified locally. If your `mylibrary` works with `foo &gt;= 1.0 &amp;&amp; &lt;1.2`, you say that. If it works with `bar &gt;= 1.0 &amp;&amp; &lt;1.2` you can say that too. It's OK if some points in the product space aren't satisfiable. It's enough that there are some. (And optimally every install-plan you can find also compiles - but that's costly to check, shameless self-plug: http://oleg.fi/gists/posts/2018-01-08-haskell-package-qa.html#s:6). Note: there could be (in the future) `bar-1.1.1` with `common &gt;= 2.0 &amp;&amp; &lt;2.2`, i.e. extending its support window. Then you library would allow that automatically.
No sorry, I disagree completely. What people want is to socialize. Facebook doesn't sell because "we track you", people just don't know or don't care. There are social networks not built around aggregating huge amounts of data in a central database. (Unfortunately, we know they're not as popular and successful.) And I do think that Facebook (and social media in general) plays a major role in spreading populist ideas. Before the Internet, you could meet with your like-minded peers in your local pub, there'd be like 10 people who hate foreigners like you do yourself, and hundreds of other people who disagree with you. Today you don't have to go outside, visit your special interest forum / subreddit, where there are thousands of people from all over the world who agree with you, but almost no one who doesn't, because they are in their own echo chambers. I'm pretty sure you know the discussion. And what Facebook does is selling attention and showing you what you like. Want a targeted campaign for people who respond to "kick the immigrants"? Here you go. You seem to spend more time on Facebook if we show you headlines of criminal immigrants? Here you go! Facebook will show people what they "want" to see in the sense of what catches their attention best. And that is simple "facts" that fit our own image of the world best. Of course none of these problems is Facebook's fault alone. But they play a major role and as long as there's no scandal or congress hearing, they give a shit. I don't want to be part of this.
There are various packages, e.g. `universe` providing `Finite` class with `(Finite a, Finite b, Ord a) =&gt; Finite (a -&gt; b)` instance. (If it's `Finite` it can be made `Ord` too). [http://hackage.haskell.org/package/universe\-instances\-base\-1.0/docs/Data\-Universe\-Instances\-Base.html#t:Finite](http://hackage.haskell.org/package/universe-instances-base-1.0/docs/Data-Universe-Instances-Base.html#t:Finite) I wouldn't use that for anything super critical. Function space size is exponential, so it becomes big pretty fast.
I think this is false. Exploiting overly permissive, incomplete, or even outright immoral laws is unethical. Law, being a mere codification of ethics, is subordinate to it and imperfect in its rendition. And no one is absolved of blame just because they are a decision making person in a for-profit organization. Would you disagee with any of these points?
Could this be used in editors? I often find annoying syntax highlighting problems in vim. Is it also tolerant to bad syntax?
A [comment](https://www.reddit.com/r/haskell/comments/8ic3c5/ghc_fatally_broken_on_ubuntu_1804_bionic_and/dyrn79x/) of /u/sclv on the other reddit thread says there is a work-around in stack using the following options, but no details provided: --[no-]library-stripping Enable/disable library stripping for TARGETs and all its dependencies --[no-]executable-stripping Enable/disable executable stripping for TARGETs and all its dependencies 
\&gt; Could this be used in editors? I often find annoying syntax highlighting problems in vim. Perhaps! You would need to create a separate executable and somehow periodically call it from your editor. I think the library is rather slow at the moment, but I haven't benchmarked it. \&gt; Is it also tolerant to bad syntax? Quite so, for example you could write a definition and leave some part as an ellipsis, and it'll work as expected without breaking the other content.
is there some kind of syntax highlighting that differentiates between terms (Data constructors) and types (Type constructors)? everything I've seen so far lumps both of these together. i think it would be great, especially for beginners!
To summarize comments I added to the issue: `stack` works fine on Ubuntu 18.04 by default. It only fails if you explicitly disable library/executable stripping.
according to https://github.com/commercialhaskell/stack/issues/4019 this stack should work by default: &gt; From what I can tell, stripping is enabled by default and so -g is not passed to GHC (confirmed by testing with --verbose on stack-1.7.1 &gt; I've now confirmed that things work by default on Ubuntu 18.04, and fail when stripping is disabled.
Good news - stack team [has found](https://github.com/commercialhaskell/stack/issues/4019) that this is less common than people thought. While stack does enable `-g` by default, it also enables executable stripping by default. So stack users who do not explicitly disable stripping are not affected. Will update OP.
And to relocate.
What if I want to stick with C/C-- parts of GHC?
`Shortcut fusion for accumulating parameters &amp; zip-like functions` is about `unfold/destroy` fusion which supports zip-like functions. It's the direct precursor to stream fusion which is used by the vector/bytestring/text libraries and others. Data.List uses `build/fold` fusion which doesn't support zip fusion. Stream fusion on the other hand has problems with nested loops (concatMap) without `-fstatic-argument-transformation` which is off by default because it usually breaks more than it helps. This isn't impossible to solve, though. Technically Data.List style fusion also could run splitting (opposite of zip) like `sum xs / length xs` in constant space but Data.List does not.
This sounds like a cool feature! Is there a way to make this work with Stack?
Look up cachedComputation \- this is how you define a datasource where the implementation is itself a Haxl computation. It's basically a memoization mechanism.
Is there a reason you can't pattern match for equality? For instance, consider the function sameTuple :: Eq a =&gt; (a,a) -&gt; Book Of course, this could just be implemented as sameTuple = uncurry (==) But why is this not possible: sameTuple (x,x) = True sameTuple _ = False 
&gt; Exploiting overly permissive, incomplete, or even outright immoral laws is unethical. the problem with intellectual property is not just imperfection, but the very basic idea behind it is incorrect fighting against bad law is good; but one needs to be wise in the way he does it; attacking the law itself is good; the way you propose [companies not using the intellectual property] is wrong; because 2 causes : * the companies are subject to the law; by not using IP themselves, others still can use it against them - this is competitive disadvantage, a significant one; that would make them not only weak, but to fall out; by this changing the population of companies towards those who perhaps do not even care; this is bad even from the perspective of the fight against IP * by blaming the companies one kind of moves away the blame from the real culprit, which is the law &gt; Law, being a mere codification of ethics, is subordinate to it and imperfect in its rendition. i agree
It is not illegal to cheat your wife, but it is not ethical either. Legality and moral are different things.
While perhaps mine might not be a common case, I personally have been quite happy with the environment file feature. For one, I've found that `flycheck-ghc` works brilliantly in all of my projects as a result. Secondly, putting my GHC developer hat on, it makes it significantly easier to debug GHC as it captures all of the invocation details that I would generally need to scrape out of Cabal's debug output. I do admit it might be better to produce a message when such a file is picked up though; I've been surprised by it a handful of times.
The picture you are painting is that of prisoner's dilemma. It may exist only insofar as those people that are unethical enough to consciously inflict lasting harm for a minute advantage are numerous enough, which is a question of the values of society. In other words, what kind of people would do that? As the law is a *reflection* of ethics, it cannot be the *real* culprit. It must be the people's values, and the choices they therefore make — consistently promoting harmful and short sighted ways of making a lavish living, be it by introduction of dubious laws, or by exploiting unregulated externalities. In other words, both poor law and poor management spring from the common source that is in the hearts of people. I think what you are implying is that there is a class conflict between the elites that promote laws only beneficial to themselves, and the common folk who get passed over, and that the way for the common folk to even the odds is to force the introduction of better laws. Kinda like that?
You could do that with some limited parsing on the tokens to determine context. 
This sounds very similar to what is done by Haddock's hyperlinker backend (the stuff you see on Hackage when you navigate to source), minus the actual links. The big challenge there was dealing with CPP. Unless I missed something, there is not mention of CPP here - any reason for that? 
I made [some rough sketch in this direction](https://github.com/kindaro/profile) when the problem had stricken me. It knows how to gather data, but I could not at the time think of a nice way of representing it to the human operator. If by *we* you imply you and me, let us maintain a correspondence, and maybe make some further steps along this road jointly.
&gt;Emacs handles the example code fine. No, it doesn't. Reddit doesn't allow inserting images, it seems, but on the line `let msg' = ...` the character `':'` is not recognized as such and the rest of the line is highlighted as a character/string/comment \(all the same color, I don't know what exactly\). Next try this: data Foo (a :: Bar) data Bar = F' | G' foo :: Foo 'F' foo = bar `F` is clearly not a character in that case, but it's highlighted as such. External tools like `highlight.js` will fail on these things too. So highlighting is not a solved problem, imo. \(Well now it is.\) And even if some tool manages to get it exactly right, it's enough to just wait till next GHC release.
There is a difference between *invalid Haskell* and *stream that cannot be tokenized by GHC lexer*. The library in robust again the former, but not the latter. After all, we don't use GHC parser here, only lexer, so we don't try to actually parse Haskell expressions/declarations/etc.
Lexer of GHC does not deal with CPP, so no support for CPP so far. That's a good point, actually.
TL;DR: GHC or Stack users not broken/affected by default. Issues appears by compiling with with `ghc -g` or `stack` with disable stripping explicitly configured.
&gt; Legality and moral are different things. unfortunately they differ, yes &gt; It is not illegal to cheat your wife, but it is not ethical either. this is only one example, it does not make all legal activity unethical
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [haskell-stdio/stdio/.../**tcp** (master → 563a800)](https://github.com/haskell-stdio/stdio/tree/563a80018eb923110b98cf8a015b1eb206db92f3/bench/tcp) * [haskell-stdio/stdio/.../**result.md** (master → 563a800)](https://github.com/haskell-stdio/stdio/blob/563a80018eb923110b98cf8a015b1eb206db92f3/bench/tcp/result.md) ---- 
Propietary software is another one. Forcing users to not cooperate with their neighbors. Selling software with malicious features to control their computer. Making money with their data, etc.
&gt; Maybe all your really want is memoisation? Yeah, memoisation is the most important thing for me, but I'd also like to have ability to evaluate dependencies in parallel (with memoisation). I'm aware this is hard problem and that's I'm looking whether it's possible to achieve this using existing libraries. &gt; A compiler usually ends up having a build system in it eventually Yep I agree, but I'd like to design it in such way that it could support LSP and such. Also Shake looks like an overkill for me, I think, I would use only very small subset of its capabilities. &gt; so it may well be that neither works for you Yeah, I'm starting to think the best solution would be to implement something similar for my custom needs.
It's mb/s, the more the better. And you can find our new io manager are saturating the 10Gb NIC!
I guess that it will break as soon as there is a tokenizer error or a syntax error that completely confuses GHC from there on: But since the source of such errors is usually because the developer is typing, just applying the old result on the buffer should mostly work.
Done.
You misunderstood. "If you don't use stack but you do use \-g, enable stripping" is incorrect, afaik. That doesn't do anything, If you don't use stack, but just use \-g, you \_will\_ get the bug, full stop. Stripping is unrelated to this bug \_except\_ in stack, where stripping and \`\-g\` are tied together.
By the time I finished [Dino Rush](http://jxv.io/blog/2018-02-28-A-Game-in-Haskell.html), I wished I had a tool to visual sprite edits as they happened. And since I'm making another game with many more sprites, it seemed wise to make that tool before editing sprites.
I think Ownership = Affine + Borrowing, the idea being that it's okay to use a value multiple times provided that you don't capture it (or its components) in your return value, and that you can have multiple immutable borrows but only one mutable one. I think, for the most part, ownership types are just an ergonomic way of capturing the pattern of "I consume this value by passing it to a function, but that function passes me back an identical value so I can use it again".
Oh really? So you mean stack turns off `-g` if you turn on stripping, figuring you don't need it? OK thanks, I'll update.
In action on video [https://youtu.be/9DDbeVvkcaE](https://youtu.be/9DDbeVvkcaE)
Do you mean eta-conversion? `f &lt;=&gt; (\x f x)`?
Good question \- there are languages where you can do this sort of thing, like Prolog and Erlang. First, what you're referring to is called **non\-linear** pattern matching. Knowing that, you can pull up old mailing list threads where people are discussing exactly this. [Here's a good one](https://www.mail-archive.com/haskell@haskell.org/msg03721.html). Important to note is that while term\-level definitions can't have non\-linear patterns, type\-level ones can. Consider the type family: type family F a b :: * where F x x = Int F x y = Bool matching :: F Int Int matching = 5 nonMatching :: F Int Char nonMatching = True
You could try using the FFI to call into C library routines (example `usleep`, `nanosleep`, possibly `setitimer` and its related functions) for your delay. If you don't use an OS thread (for example with `forkOS`) you might not get the results you expect and I believe it would block the RTS. Examples are based on a POSIX OS, if you're using Windows you'd have to find the corresponding functions.
It looks like performance is identical to MIO (and similar to go and node). Is that what it's meant to show, or do I need to look more carefully? (I know I read an old thread where you outline motivation, but can't remember and can't seem to find it in the repo here)
How old is your haskell-mode? &gt; No, it doesn't. Reddit doesn't allow inserting images, it seems, but on the line let msg' = ... the character ':' is not recognized as such and the rest of the line is highlighted as a character/string/comment (all the same color, I don't know what exactly). Works for me: https://i.imgur.com/ZtnYqlN.png &gt; Next try this: &gt; data Foo (a :: Bar) &gt; data Bar = F' | G' &gt; &gt; foo :: Foo 'F' &gt; foo = bar &gt; &gt; F is clearly not a character in that case, but it's highlighted as such. External tools like highlight.js will fail on these things too. Works for me: https://i.imgur.com/DRDXNhW.png 
Is this something that could be included in \[HIE\]\([https://github.com/haskell/haskell\-ide\-engine](https://github.com/haskell/haskell-ide-engine)\)?
&gt; As the law is a reflection of ethics, it cannot be the real culprit. it can; as you also said : the quality of that reflection is poor &gt; I think what you are implying is that there is a class conflict between the elites that promote laws only beneficial to themselves, and the common folk i do not see class-war; the only people gaining by the patents are the lawyers who specialized in the patent field, but they do not form a strong enough lobby; the reason behind the patent law is rather simply that people do not know that it is harmful 
Well, yes the throughput characteristic is quite similar with MIO, which is already quite high, and we are almost reaching the hardware's limit (10Gb ~ 1GB), but still my new code show a little bit advantage under high load, 5%~10% is not a small number after all ; ) If you look closer at laterncy and timeout, you will find the new code is more pleasing, under high load MIO is dropping a lot of connections! And I think this benchmark have a pretty good evidence that golang's single poller is limiting scalability under high load, it just too far from reaching hardware limit while under light load the throughput is very high, but in real application this may not be a problem since we have to spend much more time on other CPU intensive thing rather than barely IO like this bench. The motivation is simple, I want to build a better/complete I/O toolkit for my daily engineering tasks, and libuv helps me. After putting lots of designing, experimenting, optimizing. There're just too much things to be shown. I'll be giving a talk on this new io manager next week at a Chinese FP meeting, so I prepared these data for the talk. Hopefully I can share more thoughts and lessons on this journey soon.
Well, Haskell programmers are generally used to `type` being a type synonym everywhere. The `(..)` at the top would have non-local effects since it would change the nature of a `type` definition somewhere in the file which I, personally, would probably find confusing. I could see getting used to it, but it seems like it could noticeably increase the mental overhead of figuring out how a given module works. I think it would probably be best to introduce a new keyword for that. I suspect that would be easier to implement as well (it could probably just go through a preprocessing stage to translate it to a `newtype`). I could also see where something like that could potentially be nice. There's some work that has been done along these lines: You might also be interested in [Backpack](https://ghc.haskell.org/trac/ghc/wiki/Backpack), which is a project to put an SML-style module system in GHC. Also, the [`coerce` method](http://hackage.haskell.org/package/base-4.11.1.0/docs/Data-Coerce.html) can make dealing with `newtype`s (as they are currently) faster and, in some cases, easier.
Didn't know about linear/non-linear pattern matching, thanks for that. From what I gathered by the first two mailing list entries, some of the main points against including it in the Haskell report at the time were increased strictness, and surprising additional constraints, like `Eq`. Additionally &gt; The argument then against non-linear patterns was that, in the interests of equational reasoning, it was desirable to define a function using disjoint cases, and there was no way of defining, using a pattern, all the values that do not match the non-linear pattern. In my opinion (even though I don't use them that often myself), `PatternSynonyms` address these, since they are optional, and because you can add `COMPLETE` pragmas to specify sets of exhaustive patterns. Although GHC has no way of verifying this of course. Out of curiosity, and because I have asked about why exactly *linear types* are called "linear" (and am at this point not quite convinced yet), why are pattern matches called linear or non-linear? From a quick google search, pattern matching algorithms are discussed in terms of their asymptotic complexity. Is this it?
As the maintainer of `hasktags`, I am also very interested in applying this.
I'm aware - that's why I brought up Haddock. It also uses GHC's tokenizer and has some heuristics for trying to deal with CPP too.
To shed some light on what happened here: The `as` version shipped with Bionic likely contains a bug which is triggered by GHC when it is asked to produce debug symbols (using the `-g` flag). Typically I wouldn't consider this to be a sufficiently serious to be worth a release on its own. Afterall, GHC's debug symbol support is still a fairly new feature and has only become truly usable with 8.4.2. Consequently, my first feeling was to simply defer the fix until 8.6. However, it appears that a non-trivial portion of users are affected by this. These seem to be primarily Stack users as Stack enables `-g` whenever library stripping is disabled (although stripping is enabled by default). However, the issue is by no means exclusive to Stack and is one that will clearly need to be addressed on GHC's side. Thankfully, the [fix](https://ghc.haskell.org/trac/ghc/changeset/358b508051333882d4099acca8f269e6fb2b7d65/ghc) is rather straightforward and has been merged to `master`. Before this issue arose the question of whether there will be a GHC 8.4.3 was rather in-the-air. At this point, however, it looks like that one will certainly be needed. It will likely be a small release, so I'll try to push it out next week. Thanks for you patience, everyone!
&gt; Works for me: https://i.imgur.com/DRDXNhW.png But `'F'` is colored like a character in your pic. 
Hence my supposition is that `threadDelay` will have the same behaviour / limitation as the `setitimer` functions, because it is probably build on top of that (?). I think I'll stick to using `threadDelay` for the moment, as the precision is good enough for what I do, but the main reason I posted this question was to learn a bit more about how `threadDelay` works, to know what mechanism is responsible for the 2.5ms upperbound.
Looks cool, I've somehow concentrated only on dataFetch and missed this. I'll play with this :) Thanks! 
&gt; Thanks for the suggestions, concerning usleep and nanosleep I can't use them because they would block the whole os thread which doesn't work for my application. Why not? You can have other threads that wouldn't block, it would just block that one specific OS thread. It doesn't seem that the semantics of doing that are much different from threadDelay which blocks the current lightweight thread. &gt; Hence my supposition is that threadDelay will have the same behaviour / limitation as the setitimer functions, because it is probably build on top of that (?). I'm not sure. I can't say I have much familiarity with the internals of the RTS but the comments on top of the timer file say it's for context switching which I presume occurs at an interval. You could possibly use them for a more immediate wakeup rather than waiting for the context switch to occur. There's a related function that will get you a fd to monitor so you can probably use the functions that check for the readability of a file handle which *might* allow you to wake up immediately when the timer expires. By the way, keep in mind that garbage collection currently stops the whole world (all threads/cores at once) so if latency is really important that may be a factor.
yep, thanks!
FWIW, cabal-install has freeze files, which you check into vcs to make sure everyone uses the same versions. This is the far more common solution in other languages (e.g. cargo lock files). The purpose of Stackage is essentially to maintain curated lock file so that users don't have to do it themselves. It's extremely ambitious to lock so many packages down, which is why no one else really has it.
&gt; You can have other threads that wouldn't block, it would just block that one specific OS thread Yes, I misinterpreted what I read in the doc of `usleep` [here](http://hackage.haskell.org/package/unix-2.7.2.2/docs/System-Posix-Unistd.html), and thought it would block the whole capability (core). I'm well aware of the "GC stops the world in GHC/haskell", that's the reason I use a C++ audio engine with an audio thread that is not managed by the ghc runtime, to avoid clicks when it stops... Latency is not an issue until it becomes audible in the rythm of the music, I guess I can live with a 20ms delay here and there!
&gt; Yes, I misinterpreted what I read in the doc of usleep here, and thought it would block the whole capability (core). No problem. Well, hopefully that approach helps you! &gt; I'm well aware of the "GC stops the world in GHC/haskell", that's the reason I use a C++ audio engine with an audio thread that is not managed by the ghc runtime, to avoid clicks when it stops... You probably already know this, but one way to minimize pauses is to manually call `performGC` frequently. It may result in more time overall performing GC but the average time to complete should be lower and you're less likely to get a forced GC at a bad time.
I'm by no means an expert, but I'd imagine linear patterns and linear types share a meaning of "linear". Just as a linear type implies that a value is only consumed once, a linear pattern is one where each variable pattern only occurs once. I'm pretty sure this is from linear logic, where P∧(P ⊸ Q) doesn't let you derive P∧Q (because P is in a sense "consumed"). But I don't know why linear logic itself is called linear :) 
I read this somewhere, but never had a chance to use it as GC pause never came to be an issue. In fact for the kind of things I'm doing right now it would be complicated to compute (but possible) when we should call `performGC` to minimize the likelyhood that it disturbs the rythm of the music. It would be an interesting problem to solve :)
You wouldn't necessarily have to have a complicated calculation. You could, for example, call it once per frame (or per X frames) or something along those lines. Might not matter, just thought I'd mention it in case the the information would be useful at some point.
Sure, but I was thinking of another use case where for example you have a server that runs loops of music (midi-like note on/off events are broadcast to clients) : in that setting, there is no notion of frame, so to know when we can GC, we would have to inspect the state of all loops and if, say, for the 100 next ms there is no note on / off event to send, then we can GC, something like that. But now that I think about it, even that is not good enough because it doesn't take real-time play into account (i.e when a client improvises a melody that is broadcast by the server to other clients : and this is a feature that my synth application also supports). There is no "silver bullet" here... And anyway, my view is that, on a more artistic side, actually introducing some randomness to the rythm makes the music sound more natural (not that I verified it, but it's an intuition that I have). I used the same kind of reasoning to randomize the phase of the oscillators in the synthethisers I use, and it kind of produces more pleasant sound. Well, at least I'm convinced it does :) it's not easy to prove anything in that field!
It’s nice that you got those performance numbers, well done! But I’m not that excited about libuv being used. Are there any findings you made that could be backported to MIO to reduce the number of connections dropped?
Thanks for adding link for the old wiki, I should be writing a new one ; )
Thank for adding the link to the old post, I should be writing a new one ; )
 &gt; But I’m not that excited about libuv being used. Is there anything particular makes you feel so? I found libuv is powerful and nice to work with. Generally I believe MIO's architecture can be simplified, for example it really should just use an IntTable of MVars instead of callbacks, since we don't support running custom callback on io manager thread anyway. 
Why wouldn't you just ask this on the ticket?
Don’t want to sledge it or anything but libuv was really buggy on Windows about 2 years ago and not many of the knobs were tunable at runtime.
Thank you
I hope there isn't going to be a trend of calling out maintainers on Reddit instead of more productive channels.
Arh, if I guess, that must been on Windows IOCP and overlapped IO are difficult to get right. But you can fire an issue on their github, it is very actively maintained.
I opened https://github.com/haskell-hvr/uuid/issues/34 two months ago. Various people have commented on it, made the corresponding PRs, etc. I myself have pinged related issues various times. hvr does a lot for the Haskell community, so instead of competing for his attention, it seemed wiser to draw community attention and encourage more people to be involved.
Any functionality implemented in python will be easy to implement in Haskell. Any functionality implemented in C or whatever will be a bit more painfully imported via the Foreign Function Interface.
This is excellent. I did manage to hack my way by implementing an instance of `Enum` to `a -&gt; b` dependent on the base types being themselves enumerable (with the snake-thing that you see to prove the cartesian product of countable sets is countable), but this is better.
Indeed this is looking quite promising!
The analogy is with linear functions. If a function from the reals to reals such that `f(x) = ...` is "linear" in `x` then `x` will only appear one time on the right hand side (i.e. it will be of the form `a*x + _` where `a` is nonzero and `x` does not appear in `_`. Hopefully that's enough to make things clear (and also why "affine types" allow `x` to appear _zero or one_ times).
A DSL for assembler is something Haskell has that is not quite sad elegant in Haskell, as an example
I update my Emacs packages almost daily from MELPA. If you look closely at your first screenshot, you’ll see that single quotes around the char literal are of different colors. Although it’s hard to tell for sure from that image, but it looks like this.
I’d be really interested in this - I’m still noobing out in Haskell (like you pointed out in my field python and ruby tend to make you a citizen on the world)... I’d be more than willing to pitch though. 
Good to know I'm not alone. This library is definitely happening by the way, my mind is made up. Stay in touch! (PM?)
Indeed! You may be interested in seeing the QuickCheck-driven integration test suite we have for the new wallet at IOHK. [Here's the main bit of the source code](https://github.com/input-output-hk/cardano-sl/blob/develop/wallet-new/integration/Functions.hs#L62-L105). We generate 50 [random actions](https://github.com/input-output-hk/cardano-sl/blob/develop/wallet-new/integration/Types.hs#L50-L72) according to a probability distribution, and the interpret each one in turn. We maintain some information about the local state, and modify it appropriately based on the action we take. This approach is Cool, but it has some pitfalls. Notably, test failures are liable to uncover problems with your local state management rather than bugs in your implementation. So you end up needing to either simplify the local state you carry (and make correspondingly less strong assertions), or you need to reimplement the entirety of the state management for testing. We chose the former path, but it's likely that a full-blown, [specification-compliant](https://cardanodocs.com/technical/formal-specification-for-a-cardano-wallet/), and well-tested *testing* implementation would be a good idea (it's seems unlikely for two different software teams to make the same bugs twice when implementing a spec).
I like Literate Haskell. Even though the odds seem to be against it in the evolution of the language as it transitions from the academia to the industry, I see it as one feature that gives Haskell its soul, making it as suitable for transferring understanding between humans as it is for driving machinery.
:o, this is really cool. Makes me want to try and write the game I'm working on 100% in Haskell.
I'd be interested in checking it out as well!
In this instance, I am using reddit as supplementary to those other channels, rather than as a replacement. I am not trying to put down anyone; I am trying to find a way to get results.
LHS is a great thing, but I've always found its comment-code convention to be counterintuitive, i.e. code should be uncommented and immediate to copy-paste.
Perhaps this is a off-topic, but what does your workflow with using `mmark` for writing the blog look like? I was looking to try it out for my blog but I'm not entirely sure where to get started ... e.g. what do you use for overall site generation (something Hakyll-like? custom?) and what would be the use case for using the library vs the CLI for converting markdown to HTML using mmark?
Haskell is decent for that kind of thing, but exploit development doesn't really play to Haskell's strengths. An exploit is normally something you fiddle around with for a couple of hours and then never touch again, which Python is great for, and since there's usually no maintenance or refactors the type system is of limited help. Python's biggest weakness for CTF's is that it is interpreted, which means that it takes a bit of effort to run it on an arbitrary box, but even with static linking Haskell binaries can also sometimes run into trouble here. But on the other hand there are no obvious showstoppers for creating a library that would be nice to use. A thing that would be very useful, which pwntools doesn't do and where Haskell would shine, would be a library for machine code analysis. Things like a DSL for writing assemblers/disassemblers, implementation of algorithms like loop detection and taint analysis, or a DSL of rewrite rules for deobfuscation. I've thought about starting such a library for quite some time, but I haven't gotten around to it (yet).
Looks like an appropriate revision to bounds was already made four days ago actually? about a day after the ticket?
Ah, nice! I hadn't seen any update on the related issues about a revision being made, but glad to see it now.
Feels like we could develop a pretty nice set of Folds for the lexer if it stabilises.
I thought about it quite a bit. Contrary to other opinions here, I believe a strong type system would be a huge asset for that kind of tool. I find using tools such as `metasm` or `miasm` to be really hard, as these are really toolboxes, and the tutorial-like documentation that is available doesn't help at all. That would not be a problem with Haskell (it would *merely* require knowledge of Haskell ;). However, these tools are already existing and awesome, and porting them would be a huge amount of work. I already experimented with [a formal DSL for describing instruction semantics](https://hbtvl.banquise.net/posts/2017-05-29-01-parametricmonad.html), and writing analysis on top of it, but it clearly is just a toy for now, even though it took me hours of work.
My answer is probably more about static analysis than exploit development though.
CPP seems to be the bane of Haskell tooling development 
Tip for people putting up versioned documentation on their website. Make every page link to Latest version, and make that a temp redirect to where the real documentation is. (Obviously, this is easier said than done, but you don’t have to just accept that Google sends everyone to the wrong page.)
Of course, because it _is_ a character token! 1. GHC does not accept this example, it's a parse error: https://i.imgur.com/dAsCPpx.png 2. The GHC tokenizer (and thus ghc-syntax-highlighter) lexes this as a character: GHC.SyntaxHighlighter&gt; tokenizeHaskell "foo :: Foo 'F'" Just [ (VariableTok, "foo") , (SpaceTok, " ") , (SymbolTok, "::") , (SpaceTok, " ") , (ConstructorTok, "Foo") , (SpaceTok, " ") , (CharTok, "'F'") ] If you use more characters in your constructor such as `'Foo'` then both haskell-mode and GHC accept and highlight this properly. But otherwise it is entirely ambiguous from a lexer stand-point. The only way you can highlight ambiguous tokens properly is by doing some proper parsing. 
It's nice to get positive response from ghc devs! I'm actually considering adding a extra queue(two extra fields) to Capability_ struct, i.e. `StgTSO *blocked_queue_hd; StgTSO *blocked_queue_tl`, and some primitives to park a haskell thread to the queue, or resume from c side, just like in non-threaded RTS. Do you think it's a plausible idea? If so i may come up with a proposal then.
My original point was simply to disagree with the comment in your blog post: &gt; I could not find any flaws. Even syntax highlighting in my editor (Emacs) works worse. Emacs works just as well and has done for years. It may not in the future (which I have agreed with), but your comment was simply false, as were your follow up examples in reply to me. By the way, your example is not valid for GHC and your own library does not handle it properly either, see [my other comment](https://www.reddit.com/r/haskell/comments/8j304i/announcing_ghc_syntax_highlihter/dyy6ghl/) From the GHC manual: &gt; Just as in the case of Template Haskell (Section 7.16.1, “Syntax”), there is no way to quote a data constructor or type constructor whose second character is a single quote.
Just some initial thoughts glancing through the docs: * A link to the CMU Pronouncing Dictionary would be useful :) * You should generally `newtype` over `type` especially when involving stuff like `Text`, `String`, `Int` * Hard to tell what `initDict :: Maybe FilePath -&gt; Bool -&gt; IO CMUdict` is doing without looking at the source code. I'd probably use a custom sum type instead of `Bool` to give it a better name for what you're checking. That and/or document the arguments * `dictAppend`/`(&lt;||&gt;)` look like `Alternative` are they related?
State machine specifications also gives you race condition testing for free! It's also possible to get mocks for free from a state machine specification, so that for example the frontend can be developed using the mock (before the backend is ready). The mock is based on the specification and once the backend is finished it is tested against the spec, if those tests succeed we know that the frontend will work against the backend as well as it did against the mock. See the following [presentation](https://github.com/aleryo/homomorphic-event-sourcing/raw/master/slides/slides.pdf) and [code](https://github.com/abailly/ioautomata/blob/master/src/IOAutomaton/Model.hs), or this [paper](http://www.cse.chalmers.se/%7Ejosefs/publications/paper_117.pdf) for more details. Here's a full [example](https://github.com/advancedtelematic/quickcheck-state-machine/blob/master/example/src/CrudWebserverDb.hs) of a state machine specification using [`quickcheck-state-machine`](https://github.com/advancedtelematic/quickcheck-state-machine) of a `servant` + `persistent-postgresql` CRUD web application. `quickcheck-state-machine` doesn't do the frontend mocks yet though.
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [advancedtelematic/quickcheck-state-machine/.../**CrudWebserverDb.hs** (master → aa38cb0)](https://github.com/advancedtelematic/quickcheck-state-machine/blob/aa38cb0aa2c6c0f61e5d38e6e5b385c4eb644ee1/example/src/CrudWebserverDb.hs) * [abailly/ioautomata/.../**Model.hs** (master → c68ccf4)](https://github.com/abailly/ioautomata/blob/c68ccf4557b7eba924cb26c4a254c340329bc83c/src/IOAutomaton/Model.hs) ---- 
Ah, right, thank you :)
Hscolour has its own custom lexer.
yesss
What's the hiring process? Do the interviewers know Haskell? I applied to an "80% Haskell coding" and had quite an experience (not even sure if the process will continue as I have never heard back from FB's recruiters).
you can list many [true or false] examples, they even together do not make all legal activity unethical
That's amazing, can I pm you, I'd be happy to work together. This got me really excited, really cool stuff.
Sure, you might be disappointed by the amount of work left though! If you are interested in this, you might like bincat, which has a ton of work poured into and is in ocaml. 
By popular request I recently open\-sourced my site: [https://github.com/mrkkrp/markkarpov.com](https://github.com/mrkkrp/markkarpov.com). Hope it gives you some inspiration!
I agree with you completely, that's why I'm considering doing the library in C if I see that Haskell offers no advantages. I feel like if there was research done on Haskell for offensive security, which I don't think there is much if any at all, we would find some pretty amazing things, so I have a feeling Haskell is going to surprise me in good ways there while building the library. As for the DSL, see /u/bartavelle's comment, seems like he's already started. Maybe we can work together on this. I have a hard time seeing it as part of a CTF library though because at first sight, it seems more like a tool than something someone could use programatically, so I could be wrong but I see it as a separate project and not something that would fit into an exploit development library. Please correct me if I'm wrong. Between, I have a lot of new ideas for the library thanks to your comment!
Question: Does hasktags support automatically updating tags for a file upon save? I've switched to fast-tags just for this feature but perhaps with no need..
The "examples" link is broken, and the "design overview" link points to an empty page.
Your point is clear, but I can't help simplifying (you never use `infiniteparser`'s `Int` argument): an_bn = eof &lt;|&gt; (a &lt;.&gt; an_bn &lt;.&gt; b)
"This file is binary and cannot be displayed inline"
I would like to complain about this post, as I feel I have been robbed of my time by it and as I don't understand why so many upvote. First, the title is catchy but fails to explain what this is all about. You land on a pdf containing only charts with no legends, nor any explanation. You are left wondering "WTF ?" Second, you go to the comments only to found out that the autor of the post put an effort to leave a comment but still does not explains the what nor the why ... Third, after reading someone also complaining about the charts without legends, you start to understand what this all about and go back to the charts to see what stdio brings. Just to discover it does not add much and you are again left wondering "WTF ? Why someone would held those charts as a truth bringer while it does not show much" Fourth, you say "dude what this is all about ?" and go see the root of the project only to found a out a super cool logo but with broken example link, empty design doc design and a haddoc documentation with no comments and function that only look like wrapper around libuv, again you are left wondering "WTF ?" Fith, You go back to the comments and found that the autor wrote a huge paragraph but still fails to explain what is the purpose of this project and what are the problems it tries to solve ... /u/winterland1989 your post is a dick move, as the only information it convey is "Hey ! Look at me ! I am fabulous". Explain yourself and the purpose of the project, what it is trying to resolve. Nobody will use it if you fail to explain its motive clearly. For now, you post just shine badly on you 
https://github.com/winterland1989/stdio/wiki/Why-libuv,-why-multicore%3F
Sorry about the lack of document, they will be available shortly. 
If your phone support pdf, click on that link, otherwise please fallback to a computer. 
The main pain point is dealing with bird tracks. `\begin{code}` is easier to handle. I'm happy to spin it out into a separate module (which I'm planning to do with a lot of components, anyway) which may make it easier to maintain/contain. I just wanted to get a feel for the size of the intersection of "writes LHS files" and "uses `hasktags`" was.
Using parts of GHC in that way gave me an idea: Could it be useful to do alternative code colouring based on types, configured by the user? Use cases like "mark any expression that has type *IO a* in red". Editors could call it "type search" or "type marking". Marking multiple types at once would need to handle nested expressions though. It could use priorities for different types, or let the enclosing/enclosed type always win, or do formatting as nested boxes with html.
Well, i certainly didn't expect languages like that, but i do wish i would take the chance at the coming talk to explain more questions. I'm excited by my work and wants to share it, that's all. If the incompleteness troubled you, well, honestly i don't have a clue on what to make it up but to put more effort on it.
Which is worse I wonder: posting something that isn't understood by 100% of the people who come across it, or posting something that is overtly hostile...
Oh, I didn't realize that! Thanks, I'll take a look. Also, a big thank you for Megaparsec and the great documentation! We've been using it for a compiler project at university and it's been a pretty positive experience.
Out of curiosity, which GHC bugs did Stitch reveal?
May I ask what is the problem with bird tracks?
I know that, but that doesn’t answer my question, which was more about if this is actually an improvement on that in any concrete circumstance,or vice versa.
So I recently got something working, but I am still new to haskell and there is probably a better way. I am using the stack docker integration. To build your dependencies you could use a custom base image: [https://docs.haskellstack.org/en/v1.0.2/docker\_integration/#custom\-images](https://docs.haskellstack.org/en/v1.0.2/docker_integration/#custom-images) I was not satisfied with the `stack image container` command because I could not choose the base image and set the exposed ports, so I used the following build script \(the bash version was shorter, but I wanted to try turtle\): #!/usr/bin/env stack -- stack --resolver lts-11.8 script {-# LANGUAGE OverloadedStrings #-} import Turtle import Turtle.Format artifactsDir = ".linux-artifacts" removeArtifacts = do artifactsExist &lt;- testdir artifactsDir if artifactsExist then rmtree ".linux-artifacts" else return () stackCommand = format ("stack install --local-bin-path " % fp) artifactsDir dockerCommand = "docker build --tag asdf/server ." main = do removeArtifacts shell stackCommand empty shell dockerCommand empty removeArtifacts This is my Dockerfile for the artifacts: FROM ubuntu:18.04 # Copy built binary COPY .linux-artifacts /app-bin # Copy static files COPY ./webapp /app-bin/webapp EXPOSE 80 WORKDIR /app-bin CMD ["/app-bin/server"] 
Impressive work! Is it a summary of experiments in [glambda](https://github.com/goldfirere/glambda)?
For my part I create a folder named .stack-work-docker and I mount it inside the container under .stack-work (while not forgetting to add both .stack-work and .stack-work-docker in a .dockerignore file) Once mounted, I invoke stack install --only-dependencies before doing a stack build. By doing that it allow me to cache the dependencies and avoid recompiling them. P.S: in the stack.yml you have a section extra-package where you can specify a path or a git url/commit for packages that are not in hackage
It gives you a warning and then says 'ok, one module loaded'. No error. Are you sure it's not actually fine?
The short version is that Anorak was developed against older versions of libraries, you’ve installed newer versions. In this case, it looks like they’re even compatible, but someone’s marked an API it uses as deprecated. The good news is: that’s not an error, just a warning. You haven’t done anything wrong and you should be good to go. As an aside, this is why I wish people would use hard-snapshots or stack for applications, because apps not installing because their version boundaries are wrong is no fun at all.
Yes I think there are some reasons to be reluctant to `entropy-0.4` - it breaks GHCJS!!!
I've made fork that can be built with Stack: https://github.com/hsyl20/anorak
Well, it depend on your platform, on windows you can't have non\-unicode file path, and windows API works on UTF\-16 encodings, by saying libuv will do the convention for you, it means if you try to get filepath with libuv's functions such as `scandir`, libuv will [re-encode the result in utf-8](https://github.com/libuv/libuv/blob/v1.x/src/win/fs.c#L1008) with `WideCharToMultiByte`. And if you try to do fs operations such as open, rename, etc. You should provide utf-8 encoded path, libuv will re-encode the path to utf-16 and call the windows API. On unix, things are quite casual, since filepath are just NULL-terminated strings. But still most unix systems keep a utf-8 convention, for example your shell may obey this convention even when LC_TYPE=C. Now when you type `ls` commend and encounter a non-utf8 encoded filename, you terminal will still try to decode it as it was utf-8 encoded, so you may see some escaped codepoints. But this won't affect opening. So on unix libuv will not do any translate for your path, no matter it's reading like `scandir`, or using like `open`, but if you want to do some textual processing with the filepath, the best bet is to take it as utf-8 encoded. Overall libuv's document is quite OK, but i do have to read the source code from time to time(which is pretty fun IMO).
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [libuv/libuv/.../**fs.c#L1008** (v1.x → 60bac5a)](https://github.com/libuv/libuv/blob/60bac5a98fcefa5a35449b1494230a6e4588e541/src/win/fs.c#L1008) ---- 
Well, it's possible in the sense that ResourceT supports safe resource management nowadays. Carry an `IORef (Map Key ResourceHandle)` around, catch exceptions and free all resources left in the map when you do. This allows you to manually free resources early and still free everything promptly on exceptions at the cost of some runtime overhead. Linear types let you wrap this in a fancier api - preventing you from manually double freeing a resource - but they don't add anything fundamentally new. C++ has compiler support to do this much more efficiently but that isn't what the proposal is about.
Somehow you ended up in a REPL on setup.hs instead of actually executing setup.hs. I'm not familiar with Windows, but do you have a `runhaskell` command? If so, try running `runhaskell setup.hs configure --user`, etc.
&gt; GHC’s recent support for using GADT constructors at the type level Suggestions for reading more up on this? I was looking at the GADTs section in the GHC user's guide but couldn't find this bit.
Thanks so much! [code]runghc setup.hs configure --user[/code] got me a bit further! It's now throwing up these errors [code]src\haskell\Anorak\Results.hs:43:30: error: * Couldn't match expected type `time-1.8.0.2:Data.Time.Format.Locale.TimeLocale' with actual type `System.Locale.TimeLocale' NB: `System.Locale.TimeLocale' is defined in `System.Locale' in package `old-locale-1.0.0.7' `time-1.8.0.2:Data.Time.Format.Locale.TimeLocale' is defined in `Data.Time.Format.Locale' in package `time-1.8.0.2' * In the first argument of `formatTime', namely `defaultTimeLocale' In the first argument of `(++)', namely `formatTime defaultTimeLocale "%e %b %Y: " (date result)' In the expression: formatTime defaultTimeLocale "%e %b %Y: " (date result) ++ BS.unpack (homeTeam result) ++ " " ++ show (homeScore result) ++ " - " ++ show (awayScore result) ++ " " ++ BS.unpack (awayTeam result) | 43 | show result = formatTime defaultTimeLocale "%e %b %Y: " (date result) ++ | ^^^^^^^^^^^^^^^^^ [/code] Is it a mismatch between the time format of my system and what the code is looking for?
Is the full code hosted somewhere?
It looks like Haskell's time libraries changed in an incompatible way since Anorak last updated. Try the following (I'm basing these instructions on hsyl20's fork above): 1. Open the file `src\haskell\Anorak\Results.hs` in a text editor 2. Find the line `import Data.Time.Format(formatTime)` and change it to `import Data.Time.Format(formatTime,defaultTimeLocale)` 3. Delete the line `import System.Locale(defaultTimeLocale)` 4. Save the file, and try the build commands again Instead of steps 1-3, you can download a new `Results.hs` from https://raw.githubusercontent.com/hsyl20/anorak/9110a51ca086d3f7e4bbdf13bb399c9f290a0d3d/src/haskell/Anorak/Results.hs if you find that easier.
&gt; Also, all 'real' linear resources need to be in an IO monad since you must catch runtime exceptions with this scheme. Couldn't library authors use unsafePerformIO to do resource bookkeeping behind the scenes? Users would have to wrap their exception handlers in a function provided by the library, but that should be a lot less error prone than manually managing the resources.
Thanks again! Bet you're regretting that first reply now! Your help gets me to step 7 of 14 in its attempts to build an executable file. Then I'm presented with these errors: src\haskell\Anorak\RLTParser.hs:163:15: error: * Ambiguous type variable `t0' arising from a use of `elem' prevents the constraint `(Foldable t0)' from being solved. Probable fix: use a type annotation to specify what `t0' should be. These potential instances exist: instance Foldable (Either a) -- Defined in `Data.Foldable' instance Foldable (Map k) -- Defined in `Data.Map.Internal' instance Foldable Set -- Defined in `Data.Set.Internal' ...plus three others ...plus 34 instances involving out-of-scope types (use -fprint-potential-instances to see them all) * In the expression: c `elem` "\n\r" In an equation for `isNewLine': isNewLine c = c `elem` "\n\r" | 163 | isNewLine c = c `elem` "\n\r" | ^^^^^^^^^^^^^^^ src\haskell\Anorak\RLTParser.hs:163:24: error: * Ambiguous type variable `t0' arising from the literal `"\n\r"' prevents the constraint `(Data.String.IsString (t0 Char))' from being solved. Probable fix: use a type annotation to specify what `t0' should be. These potential instances exist: instance (a ~ Char) =&gt; Data.String.IsString [a] -- Defined in `Data.String' ...plus four instances involving out-of-scope types (use -fprint-potential-instances to see them all) * In the second argument of `elem', namely `"\n\r"' In the expression: c `elem` "\n\r" In an equation for `isNewLine': isNewLine c = c `elem` "\n\r" | 163 | isNewLine c = c `elem` "\n\r" | ^^^^^^ Thank you!
Should I be putting it in like this? `E:\Users\PC name\Documents\Anorak 2\.stack-work\install\27a5ac99\bin&gt;stack exec anorak -- publish path/to/config.xml` Because that gives this error: `anorak.EXE: path/to/config.xml: openFile: does not exist (No such file or directory)`
What's the best way to perform IPC across two Haskell applications running on the same machine? Sockets + Data.Serialize? DBus? Servant?
If you include the dictionary in your package anyway, might as well provide a pure `CMUDict` users can access that is directly compiled into your binary :) You can do this with something like Template Haskell at compiletime.
Open `src\haskell\Anorak\RLTParser.hs` and find the line `isNewLine c = c `elem` "\n\r"`, replace it with `isNewLine c = c `elem` ("\n\r" :: String)`
That's definitely working, but anorak isn't finding the config.xml. Try using an absolute path to the file instead.
Cheers, should I then be running: E:\Users\PCname\Documents\Anorak\dist\build\anorak&gt;anorak.exe anorak.exe: user error (Pattern match failure in do expression at src\haskell\Main.hs:14:11-30
&gt;Try using an absolute path to the file instead Ah... I've just searched the entire directory and there isn't a config.xml to be found anywhere... ho hum.
Oh dear god. This is a whole new can of worms. I'm in over my head!
In what way? I don't see any issues filed on the [entropy issue tracker](https://github.com/TomMD/entropy/issues) about this yet. Is there something the `entropy` package can do to fix this?
Don't quote me, but I think you might find what you want in data kinds. It definately describes using normal constructors at the type level. 
I'm not sure I follow the problem you are trying to solve. Let's discuss this on Trac with a new ticket.
yay
At least it's [documented](https://github.com/TomMD/entropy/commit/2904d2d44aca704b0f7e51121269095e1a280247) now
Strats - full-stack developer interfacing directly with clients on-site and directly reporting to someone offsite. Sounds like a quick-road to burnout.
This is a good team to work in.
This is one of the results of the `TypeInType` work, which added kind-level equalities.
[http://cs.brynmawr.edu/\~rae/papers/2018/stitch/stitch.tar.gz](http://cs.brynmawr.edu/~rae/papers/2018/stitch/stitch.tar.gz)
Can generative adversarial networks be represented in this way?
Yes; GAN's are essentially two functions; the difference is that instead of training the two functions together or separately, you alternate between training `g` and training `f . g`.
How does this backprop library compare to the reverse mode in the ad library? 
It is essentially the same as the wengert mode implementation, except it works heterogeneously. the ad library only works if your input, intermediate and output values all have the same type. 
I like the alpine base. I've been building everything with a CentOS7 base image and all of my images end up being 3.5gb. As an alternative, I've been creating a Dockerfile.build for building the binary and then a regular dockerfile for running that binary. It's a bit more of a hassle when trying to show someone how to use it. 
At this point, I think the best long-term solution is going to be letting Dependent Haskell as presented in Richard Eisenberg’s thesis play its way out. One of the neat design decisions that it makes (which has nothing to do with dependent types) is to untangle the unnecessary connection between types and visibility. Basically, we will get a new quantifier, written as forall followed by a type variable and then an arrow (instead of a dot). For example, we currently have to make do with this: size :: forall a. Storable a =&gt; Int Which is used like this: size @Word32 With dependent Haskell, we could instead write: size :: forall a -&gt; Storable a =&gt; Int Which is used like this: size Word32 This new quantifier allows us to more accurately capture what we want this function to communicate. Namely, that we expect the type `a` to be passed explicitly by the caller, not solved as a part of unification. With the new quantifier (and this part is me talking, not Richard’s thesis, so I may be wrong), AllowAmbiguousTypes should not be necessary since we are no longer writing a function whose default behavior is to ask the solver to solve for a dictionary that it cannot possibly solve for without being passed an invisible argument explicitly.
This is a great learning resource! Suppose we wanted to go beyond STLC, for example adding polymorphic functions to the language. What extra fancy types beyond GADTs would we need in the interpreter in order to suport that?
This is great, and can't wait for upcoming posts. Operational semantics feels very low level after doing some of the more abstract FP. I really think the whole AI industry would benefit if they re-do neural network techniques using ADTs, GADTs, and their laws.
What is your use-case? I suspect strongly that whatever you're doing here, there is likely a smoother way to get where you're headed without using Char. It probably involves `-XOverloadedStrings` and/or `Data.ByteString`
Nice
This is not the best way to roll out a feature...
I was trying a thing to turn certain kinds of lambdas into inspectable data. forall a. a\-\&gt; a is inhabited by id likewise forall a b. \(a,b\)\-\&gt;a is uniquely inhabited by fst. So maximally polymorphic functions of tuples are uniquely inhabited. And if I write a lambda \(\\\(x,y\)\-\&gt;x\) that type is inferred. I was trying to come up with a way to reflect types like that back to the value level. I have no idea how to do this. Something like instance DoesNotWork \(forall a. a \-\&gt; a\) does not work. And the myriad other things I've tried haven't either. The closest I've come is specializing to a type T with unexported constructors. \(\\\(x::T, y::T\)\-\&gt;x\). I think the inferred type can only do duplication and permutations \(The type tells us it can only be snd or fst\) if you can't inspect on T. Then I can use typeclasses to generate labelled examples of arbitrary nested tuples of T for example \(\(T,T\),T\) becomes the value \(\(T 0, T 1\), T 2\) . type T = Tag class GetVal a where val :: Int -&gt; Proxy a -&gt; (a, Int) instance GetVal Tag where val n _ = (Tag n, n+1) instance (GetVal a, GetVal b) =&gt; GetVal (a,b) where val n _ = ((v1, v2), n'') where (v1 , n') = val n (Proxy :: Proxy a) (v2 , n'') = val n' (Proxy :: Proxy b) Which I can then feed into the lambda to see what the result is and determine the content of the lambda. Does anyone have a better way of doing this? I don't even know how to phrase the question I want to ask exactly. Can I do typelevel programming on polymorphic unspecialized types in any way? I guess it's probably impossible?
&gt; I wonder if you could do something cool with monad transformers though. https://www.youtube.com/watch?v=Bxcz23GOJqc directly tackles this, and the follow up https://www.youtube.com/watch?v=YTaNkWjd-ac takes it in a slightly different direction.
The interface looks rather nice, and thanks for persevering with this stuff! It is rather annoying that python presents much better interfaces for something which seems like should be a strong point with Haskell. I'm somewhat flummoxed as to how it works though, I looked under the hood expecting to see something to do with composing Lenses and functions with forward/backward, instead I see this is an internal representation: data BVar s a = BV { _bvRef :: !(BRef s) , _bvVal :: !a } data BRef (s :: Type) = BRInp !Int | BRIx !Int | BRC
This is a bit beyond the scope of this post, but I'll probably write a tutorial on the implementation of `backprop` some day, to help people who want to start on their own versions. There are actually two pieces of magic coming together here. One is `Reifies s W`, and the other is `unsafePerformIO` (used benignly with no external observable side effects or violations of referential transparency). And, `W` is a newtype wrapper over an `IORef` tracking the current ID and references to all allocated nodes. The type of `liftOp1` gives a hint: ``` liftOp1 :: Reifies s W =&gt; Op '[a] b -&gt; BVar s a -&gt; BVar s b ``` The *reflections* library means that a `Reifies s W` constraint is essentially a `W` parameter: ``` liftOp1 :: W -&gt; Op '[a] b -&gt; BVar s a -&gt; BVar s b ``` And since `W` is a newtype wrapper over an IO Ref: ``` liftOp1 :: IORef ??? -&gt; Op '[a] b -&gt; BVar s a -&gt; BVar s b ``` And since `liftOp1` is implemented with unsafePerformIO, the type really is: ``` liftOp1 :: IORef ??? -&gt; Op '[a] b -&gt; BVar s a -&gt; IO (BVar s b) ``` Hopefully that helps you get started tracking things down!
And it is also your implication that a person is absolved of moral responsibility if they happen to be a decision maker in a for-profit organization?
You might be interested in multi stage builds, they combine the build environment and run time environment into one file with an easy way to copy files over:[https://docs.docker.com/develop/develop\-images/multistage\-build/](https://docs.docker.com/develop/develop-images/multistage-build/)
As explained in the documentation of `threadDelay`, you cannot assume more than the delay being at least the specified number of microseconds. It seems you did a good job with benchmarking, but this jitter might react to other things going on in the runtime such as scheduling other threads and the operating system. Also, you might find that you're gonna hate the GC at some point. GHC's GC is [not suitable yet](https://stackoverflow.com/q/36772017/854672) for applications with hard realtime constraints.
I see that you talk about Grenade https://github.com/HuwCampbell/grenade, as far as I know Grenade also has an autograd that can be extended with normal function support, or did I miss something? By the way you might be interested in Thinc, https://github.com/explosion/thinc, it's the autograd library that powers spaCy a very promising NLP framework. It's unique among the Python DL library in that it the forward pass returns closures instead of adding nodes to a graph. 
Yeah, it's very promising! I don't know about dates, but I recall it's going to be default in Cabal 3.x. Please correct my if I'm mistaken, couldn't find any official confirmation on this.
Grenade doesn't really have "automatic" backprop, it's all done explicitly by the user. Trainable layers are *data* in Grenade; they're actual matrices and vectors etc.; first, you define the data type you want to train. *Then*, you write an instance where you *explicitly* define the gradient. It is not automatic. So, for example, a fully connected layer in grenade is: 1. The matrix and bias vector 2. A typeclass instance for that matrix and bias vector that computes the application and the gradient Furthermore, composing layers requires either manually jumping in and manually writing your own gradient function, or else using a closed data type `Network`; your composition API is either to write an explicit gradient, or use a closed data type that is your only other option. However, the the system described in this post, a feed forward layer is just a an actual function, essentially `Matrices -&gt; Input -&gt; Output`. You don't need to define the gradient explicitly. And composition is just normal function composition with `.`. You don't need to use a closed data type, and you don't need to manually compute any gradients. It's just normal function composition. In grenade, the layer is the *data*, with a typeclass instance where you have to provide explicit gradients. In this post, a layer is *just the function itself*, the `Input -&gt; Output` function, written in normal haskell, composable with normal haskell combinators.
I see, it's similar static vs dynamic framework
It's a little odd that they don't generate the lockfile (ie. `cabal.project.freeze` in the Cabal nomenclature) by default though - seems like you need to explicitly [call `cabal new-freeze`](https://www.haskell.org/cabal/users-guide/nix-local-build.html#cabal-new-freeze). That's definitely a very nice to have when working with Cargo, and I imagine it's yet another default that will have to be changed down the line. :/
There are proofs of refinement, which some IOHK people have blogged about as well. It looks like you aren't explicitly using one of the state machine libraries. Did something obstruct that?
OK, I checked with latest haskell\-mode and Emacs without any custom configuration. Here it is: [https://imgur.com/a/g8rHiQj](https://imgur.com/a/g8rHiQj)
^(Hi, I'm a bot for linking direct images of albums with only 1 image) **https://i.imgur.com/hZvRutm.png** ^^[Source](https://github.com/AUTplayed/imguralbumbot) ^^| ^^[Why?](https://github.com/AUTplayed/imguralbumbot/blob/master/README.md) ^^| ^^[Creator](https://np.reddit.com/user/AUTplayed/) ^^| ^^[ignoreme](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=ignoreme&amp;message=ignoreme) 
Thanks for your Dockerfile example! I haven't try it yet, but I like the idea of preinstalling project dependencies. It will be done once assuming dependencies doesn't change over time, am I right?. What will happen if number of dependencies will increase, should I clean cache and rebuild image? Did you mention `extra-` options in stack.yaml because of my question about "external dependencies"? I was asking about C library dependencies. I would like to know how to incorporate full project build including Haskell and C parts in Docker. Sorry for confusion :)
I like this one, but boy does it require some reasoning to work out. :)
[wikipedia](https://en.wikipedia.org/wiki/Product_category) has a nice article on that so: - yes you have for each object c in C and d in D a object (c,d) in C \cross D (but not (d,c) of course) - yes can happen you get an arrow in the product if you can find a fitting pair of arrows in - every arrow (c,d) -&gt; (c',d') corresponds to one c-&gt;c' in C and one d-&gt;d' in D - I think "pair of morphism" is the one morphism in C \cross D you get by "pairing them up" - not two of those to be honest it's just a dry definition - I would start at the wiki article, take a pen&amp;paper and try to see that the definition is sensible (the laws for composition etc. holds)
Thanks for your answer, I know I can't expect to implement real-time stuff with GHC, I just wanted to get a feel of what would be the guarantees in a particular case (assuming no GC is triggered, and other treads are all idle).
Can you elaborate?
Hey, does libuv correctly handle the situation of reading file contents asynchronously? That's an issue I found yesterday: https://mail.haskell.org/pipermail/ghc-devs/2018-May/015749.html
Very cool! &gt; The Reifies z W is just a constraint that allows for backpropagation of BVars. This is a bit mysterious. What does that constraint actually allow you to do?
It would except for the Haskell. That's what keeps you shipping, and keeps you sane.
&gt; \(but not \(d,c\) of course\) Oh yeah, duh :\) Allright, thanks. So After drawing I see it better now. Am I right for instance that 1\) the morphism \(c,d\) \-\&gt; \(c,d'\) = \(id\(c\), g\) ? 2\) there is no morphism from \(c,d'\) \-\&gt; \(c',d\) because only c\-\&gt;c' exists and not d'\-\&gt;d ?
^ (^( it's not serverless, it's only someone else's server) )
There's a google summer of code project that's going to add the missing `new-` variants of all the commands. I suspect that after that, it will soon become the default.
This is definitely the kind of thing we ought to iron out now, before it becomes stable and standard. Do you want to open an issue over at https://github.com/haskell/cabal/issues?
I think you're looking for: mapM_ print matrix
Right! Ok so, got this part now. Thanks!
Yeah you are right, big thanks.
On the behalf of miss Nero: [her message, screenshotted :^)](https://imgur.com/a/zds31Aa) 
No problem!
Excellent article! Has anyone seen `StableName` get any use in the wild? I stumble across it from time to time, and it looks cool. But it seems like any attempt to use it to build a data structure that would help shortcut equality checks would leak space, since there's no way to figure out which ones point to things that have been GCed. Also, is there a fundamental reason that they cannot be given an `Ord` instance?
Yes and no, regular file are difficult to deal with in general, because OS will try to page cache your files for speed, so it's hard to predict fs operation's performance. libuv provide both directly blocking fs operations via NULL callbacks, or thread\-pooled fs operations if you're accessing slow filesystems such as network file system, or slow spinning disk. In stdio we plan to export both interface, for example there're `scandir` for common access, and `scandirT` for thread-pooled operations, and it's the programmer's responsibility to decide which way to go.
It may be widely understood in the bay area VC funded startup industry, but thankfully not all Haskellers are part of that.
I like to use `traverse_` rather than `mapM_` (I think they're the same nowadays actually)
"Serverless" means for me "without a dedicated server"
Was meant as a funny aside, no harm intended
Any chance you could use an `STRef` and get rid of the `unsafePerformIO`? 
These "right default" questions are always tricky in general. Personally I like the solver trying to pick the latest allowable deps unless I request otherwise. In general I prefer to use the latest versions unless there's good reasons not to. I suppose this is in part if you do more library dev (as I tend to when using new-* commands) or app development (as I tend to using a straight nix workflow).
You should check out (markdown-unlit)[http://github.com/sol/markdown-unlit]. It gets you closer to what you’d like.
This seems really useful. One difficulty I've considered in the past for haskell on aws lambda is that running haskell code requires booting the whole rts, which can add latency if aws decides to kill the underlying capacity between invocations. Do you have guideline resources on the ideal size and frequency of IO actions to run on aws lambda so that the capacities stay live and/or do enough useful work each time?
In fact, I failed my masters but I'm happily working in a job writing Haskell :) I chose the wrong topic to do my thesis on and that's my only regret. You can always do your own research! 
One thing I’ve been wondering about the type-level lambda calculus stuff that both you and /u/AndrasKovacs have done recently: what are the implications for getting real type lambdas into GHC? Is that possible/on the horizon? Can any of the work be carried over? It’s something I’ve wanted a couple times now, it would be really cool to have.
Yeah, I wish it had an Ord instance, for Map etc. 
Isn't that an even smaller pool of people? What if I've only ever worked on Haskell for pay (ergo, no publicly available aspects)?
Nah, it's unnecessary. People only care if you can write code and don't seem like you'd be shitty to work with.
The hype train kept passing through my neighborhood and shaking all my china off the wall.
Because it's totally different from anything else and it was looking hard.
Will this new cabal features be able to deprecate stack? In particular, will it be able to handle the GHC version of a project as well, to keep the build reproducible?
Nice one.
You can fix the exact version of base to use with `cabal new-freeze` I suppose. I think that will also fix the GHC version. But generally, the philosophy of Cabal seems to be slightly contrary to fully reproducible builds. Personally, the main reason I (as an application - not library - developer) appreciate Stack is exactly because it helps my users get the proper version of GHC to compile my application, even if whatever OS they are using does not bundle the right one. Once these new Cabal features become sufficiently wide-spread, I will probably start using them more aggressively instead of their equivalents in Stack, but I don't see Stack going away for Haskell application development/deployment.
Stack will still have two major features that cabal-install won't have: Stackage-by-default, and GHC installation. Whether these features are *desirable* or not is a question of much debate, but they've certainly helped a lot of people. GHC installation is really hard though, so it's only a good idea if you're confident that it'll handle your OS correctly. This is what makes `stack --nix` often more reliable than `stack`; it gets GHC from Nix, which is an extremely reliable, cross OS package manager. There's also a number of smaller features that Stack has that cabal-install doesn't, like multi-component ghci and git dependencies. But these aren't serious blockers to me.
It would be interesting if you could say more about that. As far as I can see from the [AD Haddock](https://hackage.haskell.org/package/ad-4.3.5/docs/Numeric-AD.html) it's completely polymorphic over the variable type and any number of output variables (through the `Traversable` class). What extra heterogeneity does backprop provide?
It was kind of a confluence of things. I had been in industry. Everything I'd seen had been a mess of complexity, with no realistic path to taming it. 1. I had been exploring functional programming. The declarative nature of the style worked well with how I thought about things. It was clearer, more communicative and code ended up being concise yet easier to understand. Not to mention all the OOP code I'd seen was a shit show. Inevitably I ran across people mentioning Haskell as a "real" functional programming language. 2. I had been trying to sell JavaScript `promises` to my company and dev community. I saw them as an elegant solution. They convert what is an extremely imperative form into something closer to value semantics. Somewhere along the line someone said "promises are a monad" and I said WTF is that? 3. I'd been doing a ton of research to understand complexity and how to tame it. One bit of research I found was "out of the tarpit", Moseley and Mark's fantastic work. They mention Haskell quite frequently. It's worth noting that I also dabbled in SmallTalk (real OOP), Erlang (actors) and Lisp (unbound expressivity) at this time, since they were also touted as solutions to my perceived problems. In the end Haskell hit a sweet spot and sunk its claws into me.
Because monads. This word kept popping everywhere and I couldn't figure what the fuck it meant. Oh and maybe Curry Howard isomorphism : this seemed pretty profound. 
I just discovered a [really old ticket](https://ghc.haskell.org/trac/ghc/ticket/913) requesting this.
Cool, thanks for the reply! For the records, I've filed the GHC issue at https://ghc.haskell.org/trac/ghc/ticket/15153
I don't have any degree at all, I barely got my high school diploma as I'd spent the last 1/3 of my senior year in secondary in in-school suspension for "hacking."
I had a project that would benefit from pattern matching and async IO. Looked for languages that made those easy, got Haskell. In the end those two features were very small wins compared to the rest of the language.
It could be useful. I'm committed to a PhD program for next year, and whenever people ask me what I want to do with it I always describe Galois to them as something vaguely that I'd be interested in. I think I technically knew that you guys hire undergraduates, but never really considered it strongly as a possibility. This changed (but not too much) after hearing that another student from my class of &lt;10 majors in the department got hired there immediately after undergrad.
Arh, the rabbit hole will not stop at base, here is the same issue with other fs operations: https://github.com/haskell/unix/issues/34 , which affect directory package. I choose libuv to save me from bothering these issues exactly.
It was used in my introductory CS course I took my first semester of college. :)
Thanks! And no, I haven't played much with mtl to be able to write about it just yet. I remember reading though that most of the mtl transformers are same as the ones in the transformer packages. The differences being: 1. MTL adds the transformers to the same module as the monad itself. So, State monad module also contains StateT if you're using MTL. 2. MTL does not export MonadIO in the monadic modules. I think they're moving away from MonadIO for some reason, I don't remember why. Beyond this, I cannot comment :)
Curry Howard is some of the coolest shit of all time. Doing a conputational logic course with Coq at the moment and I'm knees deep in that stuff. :)
I was trying to write a roguelike in C. The only other languages I knew at the time were perl and PHP. Anyways I got frustrated that every time I decided to change something I went through a days long refactoring, with endless testing and dealing with segfaults and memory problems. That triggered a years long learning process.
no
[removed]
I am just trying to make the separation of pure from impure simple, obvious, and accessible to programmers coming from a more traditional language like C/C++/Ruby.
I was researching reactive programming and kept reading those papers with examples in this weird language. It was haskell. So I learned it.
[removed]
I wrote Lisp for a long time, then someone posted a link to LYAH on IRC and I never looked back (except ELisp, I suppose).
As a ML engineer, I can't stress this enough!
I've been hearing about that and keep failing to look into it.
The first language I learned was Java. Used mostly that in college, took a mandatory class where we learned the basics of SML and Prolog. Thought they were really neat but didn’t pursue any further. Graduated, got a job, was put to work learning/using Python. I liked the language more than Java bc it was less verbose and had a great standard library, but after a couple months I began running into issues with refactoring and I started missing static types dearly. Somehow I came into contact with Haskell and the type system blew me away, even the basic/intermediate stuff without the magic. Combine that with becoming sick of mutability through working on an ancient, crappy C++ codebase, I found all the motivation I needed to learn Haskell. Plus, it was a fun/interesting language and I knew it would be a valuable experience. I’m making slow but steady progress and enjoying every bit
I have ADHD and struggle to keep multiple things in my head - which makes my debugging process harder. I don't like debugging, frankly. Haskell is a great language to reduce mental burden while programming. The reusability of its design pattern (functors, monads, ...) are another great appeal!
Wow, what college was this?
When I started programming, I really enjoyed learning new languages, but didn't really *like* any of them (JavaScript, Perl, Java, C++ and a handful more). At one point I realized I needed to find a language I liked and could use for different tasks, so I flipped a coin between learning Haskell and Lisp and chose Haskell. The rest, as they say, is history :). (Actually, I ended up learning Scheme at the same time as Haskell because that's what we used for our intro CS class in college. I did generally prefer Haskell, even after doing a pretty large project in Racket a couple years later.)
Cons: Invasive form wall in front of State of Haskell 2018 Report. Pros: Doesn't actually validate form fields.
Reed College
But, then, you are saying: &gt; companies are subject to the law; by not using IP themselves, others still can use it against them - this is competitive disadvantage, a significant one; that would make them not only weak, but to fall out By which you are justifying all the decisions of an executive, insofar as they are lawful _(even if they also happen to be unethical!)_ to be appropriate and good. How do I read this as something but a grant of absolution?
Hi, interesting work ! How does it compare with [functionless](https://github.com/tweag/functionless) ?
Sure. "28 Days Later" was the name of a 2002 zombie movie. It was used as a passing reference at the start of the music video for "Party Rock Anthem" by LMFAO, with had a very vaguely zombie-like theme. All in all, it was a time period chosen precisely to make a joke about zombies. Zombies are irrelevant to the actual point I was making though, which is that on any of the three most common general-purpose operating systems in use today, there is *no* upper bound to how long it might be between consecutive time slices allocated to a process (or set of processes). User tells the operating system to sleep? Your next time slice comes after the system is woken again. Buggy driver acts up? Your next time slice might come 30 seconds later. Your process gets suspended? Who know when, if ever, your next time slice will come. And those are just some egregious examples. Scheduling issues can sometimes result in milliseconds of extra delay. Paging memory in from a spinning rust drive that has spun down can take seconds. There's no end to potential sources of issues, regardless of what granularity the language runtime tries to provide. Maybe you aren't worried about these things, as it seems like you're doing audio work, and it's not too sensitive to most of the smaller fluctuations and the user will understand transient failures with clearly use-visible causes. Regardless, no discussion of this topic is complete without at least the reminder that unless you're running a hard real-time OS, there is no upper bound to the time between two execution points. 
My uni made this decision for me :D
A fair amount of the jobs that ask for higher degrees are looking for people who are experts in programming-language design and implementation rather than just Haskell coding -- positions that are really "applied research" as much as just straight dev. Even in those situations, a strong body of work or demonstrated experience is often just as good if not better. Let's not forget that SPJ never got a PhD (though he has collected a few honorary ones by now, I think).
Yes, it's polymorphic, but the input variables and output variables must all have the same type. Note here that we have functions that take in doubles, matrices, vectors, tuples, all at the same time, and transform between them throughout our function. With ad, you can only use one type, not all of them.
It wouldn’t happen if we stopped using state violence to protect the claims of such exploitative business models that violate cyborg rights.
Yes it does for end users.
We hired a really smart guy at my early stage startup. He said, “what about haskell instead of scala?” (Actually more words that were pretty persuasive) and it sounded like a pretty good idea so we went with it. 
It is worth noting that 90% of the `lens` library and _all_ of the laws don't make sense when you go off the reservation like this. The 'a' and the 'b' in a lens aren't independent. See the "Why is it a Lens Family" bit of ["Mirrored Lenses"](http://comonad.com/reader/2012/mirrored-lenses/) where I introduced the 4 parameter notion of a `lens`. Logically, `Lens s t a b` is really `Lens (outer i) (outer j) (inner i)(inner j)` for some type level 'families' `outer` and `inner`, the s, t, a b, stuff is just specifying a pair of indices that you come in and exit on, because that is what can be smuggled through Haskell's type system, and in general its always possible to 'fuse' all of the uses of the optic into one pass to make this possible, which this discipline enforces.
Well, I guess it's time to contribute :-P
I have interviewed about a dozen people for Haskell positions. I wouldn't even consider penalizing someone for having no degree at all.
Closest I could find to pure math. 
Depends on the application. Unless the work is related to something highly theoretical like some kind of AI etc. From my experience self taught or those with just a bachelor's program circles around those with masters/phd.
The Cardano blockchain project got me curious.
Sorry about that. Here's a [direct link to this hilarious pdf](https://www.fpcomplete.com/hubfs/Haskell-User-Survey-Results.pdf). Enjoy! 
cardano
Curry-Howard for me. Gave me a deeper connection and intrigue into what I do every day for a living. 
I like this question! Sorry about my long answer, but here it goes \(quoted from my blogpost \[Why I care about Haskell\]\([https://nunoalexandre.com/2017/06/11/why\-i\-care\-about\-haskell](https://nunoalexandre.com/2017/06/11/why-i-care-about-haskell)\)\): &gt;Why learning another language if Java will do it? Why spending time and energy learning a language that is so little used in production? Why another paradigm if ~~procedural~~ object\-oriented programming works so well for me? Why bother about such theoretical concepts when inheritance solves all my problems? &gt; &gt;These are all reasonable questions for someone first hearing about FP/Haskell. And I get them. &gt; &gt;Let me tell you a story to better you explain why I find it worth it: &gt; &gt;I started making websites when I was 16. At the same age, I went on an internship and had my first enterprise projects as a web designer, using the *unexpected* HTML\+CSS\+PHP\+MYSQLstack. As much as I was happy with being able to deliver the projects I had in hands, I was terrified about the parts I didn’t know. &gt; &gt;My reaction to this fear was to lie to myself saying there was not much more to know about programming beyond what I knew already. &gt; &gt;Obviously, what I knew at that time often fell short and I was forced to explore a bit more in order to deliver something new. And at every time I had to go out of my comfort zone, I would do the same: Tell myself that **it was finished**, that there was no more to know. &gt; &gt;This, unfortunately, it quite a common behavior in IT. There are endless things to learn in our area and getting overwhelmed is inevitable. It is hard, but closing your eyes and expecting the best is not the solution. &gt; &gt;During university, I dropped this attitude and came to peace with the fact that I would have to learn for the rest of my days. More than peace, actually: I rejoiced knowing that I was part of a discipline where I could keep on learning forever. That is not just humbling but also exciting! &gt; &gt;And that’s how Haskell plays such a sweet role. Haskell is probably the best language for humbling yourself if you think you know what’s there to know. If you go on learning Haskell, it’s not to get promoted, nor because in a few days you will be programming in such a different language and look smart, neither because you will increase the number of job offers you get on Linkedin. &gt; &gt;Learning Haskell, to me, is a matter of embracing the unknown. It’s about spending spend time on something that probably won’t be palpable, that will take a long time to master \(I’m far, far from it\) and that make us feel lacking brain power. But that, nonetheless, it is still worth it because it will change everything, for better. &gt; &gt;Thus sharing my joy about Haskell is not to intimidate but to bring people to embrace this career where it will never be enough and where *that* is actually is part of the fun! &gt; &gt;As I say in the presentation, if you consider programming languages as mere tools, then Haskell probably won’t make sense to you. I don’t believe that, though. At the very least, they are toolsets. But that’d be like saying that Art is just an expression. It’s falling short. &gt; &gt;Programming languages can transform our brain, can totally transform the way you see and interpret the world and how you solve problems. There is craft side to it, which takes us to see a deeper level of meaning and purpose on what we do. &gt; &gt;That’s why I care about Haskell.
I got interested in Category Theory, and I started seeing how so many articles would show examples in Haskell. Then I stumbled upon Bartosz's CT articles and videos. 
well, of coarse because of its terse syntax.
&gt; What if I've only ever worked on Haskell for pay (ergo, no publicly available aspects)? That's an even smallerer pool of people :) The set of people who have a Master's degree is small, the set of people who are actively contributing to the community is smaller, and the set of people who get to use Haskell at their day job is smaller still. Inversely, if you already have a Haskell job, it's very easy to convince another Haskell shop that you can handle a Haskell job, if you're active in the community, it's a bit less easy, and if you have a Master's degree but no Haskell experience, it's going to be hard. I intentionally didn't suggest "work for another Haskell shop, that's the easiest way to get us to consider you", because the OP is asking how to get into a Haskell shop, so that would be circular.
Hah! My story is weirder than any of the others that have been posted. Back in high school, I used to play world of warcraft, and I'd made a friend from my guild, a british guy named Harry, who was around my age. We were chatting on skype during class (I live in Denmark, so the time zones are close). At some point, the writing style changed drastically. I asked what was up, and it turned out his friend and classmate Shane had taken over his keyboard for fun, and just continued the first open conversation. Shane turned out to be a bit of a programming nerd, just like myself. I got his skype as well, and we ended up spending a lot of time talking about coding and math (still during class). At some point, he recommended Haskell, I checked it out, and never looked back. Later, it turned out that Haskell was also used at the university where I ended up studying, so I probably would've learned it eventually, but I definitely got a head start.
It was covered in a programming languages class along with Lisp and Prolog. Loved the conceptual purity and practical benefits of pure functional programming and the "as close to programming in math as you're going to get" syntax 
if those who think that a certain law is harmful avoided using it against others, then they would suffer a competitive disadvantage compared to those who either do not think that the law is harmful or do not care; thus they would go out of business, in the long term achieving nothing in the topic, apart from getting broke; even worse : all their former relative economic power [and the political power with it] would shift to those who are okay with the law; thus such behavior would even strengthen the law so being ethical in the way of not using a bad law is counteractive; because it ultimately hurts the goal : it can not be the behavior that a morally conscious person should do
I think this very much depends per person. I am part of a team of 6 \(Haskell\) engineers at Channable. 4 of them did a Masters degree in Computer Science in Utrecht, The Netherlands, and I personally do notice that I miss not having done it. But, the colleague left in the counting is completely self\-taught and it's just at the same level as the other guys.
&gt; No thanks! I'd rather spend time with my family instead of spending whatever free time I have writing blogs to get yet another job. I understand the sentiment, but the sad reality is that we can't afford to hire non-Haskellers for our Haskell positions. So if you want a Haskell job, you'll have to learn Haskell first, and that probably means you'll have to learn Haskell in your free time. If you know Javascript though, you could apply to one of our frontend positions and join our weekly haskell-beginners presentations, this way you could learn Haskell during work hours and ask to switch to a backend position once you feel ready.
I was sceptical about the nice things people said about Haskell and I set out to prove them wrong
No, but the \[lecture notes\]\([https://courses.ps.uni\-saarland.de/icl\_18/2/Resources](https://courses.ps.uni-saarland.de/icl_18/2/Resources)\) are freely available. Also, there's always \[Software Foundations\]\([https://softwarefoundations.cis.upenn.edu/](https://softwarefoundations.cis.upenn.edu/)\). \(Although in my course, we spend a lot more time discussing and understanding exactly how Coq works compared to SF\). Also, there's always Adam Chlipala's \[book\]\([http://adam.chlipala.net/cpdt/](http://adam.chlipala.net/cpdt/)\). 
It will depend on the person hiring and the nature of the position. Personally: unless the job requires some very specific domain knowledge that is typically concentrated only in academia (maybe at the level of cryptography research or something) then I will probably ignore education altogether, as IMO it is a very weak signal. For most programming jobs, I reckon that one good public blog post that showcases a candidate's knowledge and skills beats an otherwise unremarkable PhD listed on a CV.
I was a 17 year old that had mostly written C and similar languages, and I somehow kept stumbling on this language being mentioned as something you should really pick up if you want to broaden your horizons. I think I was slowly becoming more interested in programming languages in general at the time, and decided to take the leap. How easy everything was compared to many other languages just blew my mind, and while I struggled a lot in the beginning and definitely didn't grasp all the concepts, it felt like I was using something that could be incredibly powerful if I could just achieve true understanding. And here I am 10 years later. I still haven't achieve true understanding, but learning more has only allowed me to understand that there are more things to learn, so I'll definitely still be here in 10 years. One thing that really drew me in as well, and helped me slog through some of the hardest parts of Haskell, was the community. Everyone is just really willing to help, almost to the point where you can't keep up with all the answers to your questions -- it's pretty hilarious to ask a question that catches the interest of #haskell on freenode and then witnessing the avalanche of answers like you just accidentally [nerd sniped](https://xkcd.com/356/) half the channel. 
I had a mentor that recommended I learn a language for mind expansion. Initially this was Scheme until one day he emailed me about Haskell being the modern replacement for Scheme or Lisp for mind expansion. After sticking with it for 2 or 3 months, I was hooked.
What, is writing a blog post supposed to be more time consuming than getting a master's degree or PhD? The former is a cheap way to signal employability -- the latter is extraordinarily expensive, not to mention of dubious quality. (Obviously there are other ways to signal employability as well -- e.g. reams of successful and noteworthy professional experience listed on a CV.) You could say "well I shouldn't have to signal employability," but this is not a very strong argument, IMO.
&gt; I don't like debugging I had never really considered this before, but haskell appeals to those who don't like debugging for two reasons: (1) the powerful type system means that the compiler can help you ensure that your invariants are maintained (2) a debugger for a lazy functional language is difficult to use, so almost no one uses it.
That's just unhealthy. Sounds like you might benefit from /r/relationship_advice.
Some time around 2007-ish, I was watching [Abelson and Sussman's SICP lectures](https://www.youtube.com/playlist?list=PLE18841CABEA24090) on YouTube. Their point about substitution as an evaluation model was really powerful, even though they ultimately abandoned it. In the process, they mentioned a language called Miranda, and their description immediately appealed to me. So I went to research Miranda, but of course it was 2007, so I found Haskell instead.
Hey, you are right that I could've made the distinction between other similar libraries like `functionless` more to the point; but I am not that good with words :). The main difference is that, `functionless` follows a more traditional approach where you deploy your application to AWS Lambda, set up some events to trigger it, and then as those events arrive, AWS runs your application and sends back to answer. This is more useful for request-response type applications like web servers or processing messages in a queue or something like that. However, you `serverless-execute` to offload some part of the computation to AWS Lambda. Think about it like, you can use `forkIO` to run some tasks in parallel to get your result faster. Replace that `forkIO` with `serverless-execute`, and now you those tasks run on AWS Lambda and you are not bounded by the power of a single machine. You still have a driver running on your machine which invokes your functions on AWS Lambda and aggregates the results. Maybe I should also state that; my ultimate goal is to build something like MapReduce or [Apache Spark](https://spark.apache.org/) where you can process large amounts of data in a short time leveraging the parallelism of AWS Lambda. 
Appreciated. On a serious note: The presentation rubs me wrong because its design is DYNAMIC BUSINESS SYNERGY in the extreme. But on the other hand, I could hand this to one of my executives and probably get a positive response to a Haskell pitch, since they deal with jumbles of fonts and colors and stock photos every day.
I'm a hardware and low level C kind of guy normally, but a lot of High Level HDLs (basically anything not Verilog or VHDL) have started to take serious looks at Functional Programming. Bluespec and Chisel come to mind. Bluespec IIRC is built on ghc, Chisel is a DSL in Scala. In order to think effectively and design reasonably in these I had to learn some FP (I still read that passively as floating point...). Scala is fun and I like playing with it. It has its good uses, but it lets you play fast an loose with the FP paradigm. Haskell does not. Haskell keeps you in line and makes you learn if you want to advance (I still suck at it) Also, after having to deal with ATS in university, I wanted an FP language that was human readable.
I'm looking to hire Haskell programmers. I don't require a Master's degree.
Because Matt Might and Larry Wall suggested it.
I would imagine that applying for a haskell job is the same as applying for any software development job. The degree requirement isn't dependent on the language, but rather the tasks you're expected to do on that language. The language itself is irrelevant. The master's positions you are looking at aren't master's because of Haskell, but because of the things you are going to be creating and doing.
Because Haskell attempts to make logical sense of programming, unlike most other languages.
IIRC traverse_ works on applicative and foldable, while mapM_is just for monad and list
Because of Stack
Same at TU Dresden
Because it made programming 20x more fun, insightful, and easy.
i'm kinda curious, why did you quit? if you don't mind me asking. only thing I can think of is the low prospects of a job in academia if thats your thing. this assumption comes from what I read on /r/math
Ralf Lämmel was my prof at university and I got curious why he was dissing all other languages... 
I can relate to this. I'd been using computers (from the command line) my whole life and I wanted to learn to program. I tried learning Javascript, Python, C, and Java each in turn, but each time I failed to ultimately advance beyond very basic programs of like a few dozen lines or so. It seemed like programming was beyond my reach. Then I read Learn You A Haskell For Great Good and Real World Haskell, and the immutability and explicit I/O made everything a lot easier for me to grok. Specifically, you can compartmentalize functions based on their signatures in Haskell for more than you can in Java or C because there's no non-local state or effects in Haskell. The inputs in the signature are the only context you need, and similarly the outputs are only those that are explicitly stated in the signature. Really helped me break things down and hold a model of what was going on in my head in a way that wouldn't really be considered idiomatic or encouraged in other languages (though in retrospect I can, and do, apply those principles---all inputs and outputs explicitly stated in a function signature---in the Java I write today).
I'd recommend instead Graham Hutton's _Programming in Haskell_, 2nd edition. It's much more pedagogically sound (in my opinion) than LYAH and much more focused and straightforward than the Haskell Book. Both of those other works have their strong points, but right now when someone says to me "I'm an adult with previous programming experience", I point them at the Hutton book as being the right tool for the job. 
You are right, this is a common problem with Lambda, even if we did not have RTS; when its caches are cold it might take a few seconds for Lambda to even start executing your application. However, in `serverless-execute` you usually value throughput more than the latency, e.g you want to process large amounts of data and time to first byte is not your primary concern. My usage pattern when using `serverless-execute` usually looks like: * Do nothing for hours. * Invoke ten thousand functions and wait for all of them to finish. * Do nothing for hours. As you can see, that middle step probably takes a few minutes and I can afford losing a second of cold-start time. Time wise, on my trials, I found that making your tasks take around 10 seconds was good enough for me. Frequency is an awesome question. [AWS docs](https://docs.aws.amazon.com/lambda/latest/dg/scaling.html) says something like: &gt; Lambda can immediately provision 3000 concurrency in US East (Northern Virginia). Afterward, Lambda must scale up at a rate of 500 concurrency per minute. which means, if you invoke more than 3000 functions, AWS will throttle some of them. And this does not mean that they will be run immediately when there's enough capacity, as far as I can understand AWS retries throttled/failed invocations every 30 seconds. So, if you have 10 second tasks, and if you send 4000 of them in parallel; AWS will run 3000 of them immediately and they'll finish at t=10, wait for 20 seconds doing nothing, and run the rest when t=30 and they'll finish when t=40. However, if you throttle your calls on application level, you can get result in 20 seconds instead of forty. So, I think, if you arrange your workload so that: * Every invocation takes 10-30 seconds. * It does not spawn more than 3000 functions at once. will give you the best throughput. Take all of those as a grain of salt; I mostly experimented a lot (I have a 40$ AWS Lambda bill) and these are what I was able to infer from the behavior. Sorry I don't have any numbers about how long AWS keeps your function alive. But if you are keen to try, it should pretty easy to write something like this using this library: ``` -- prints how long the IO action took time :: IO a -&gt; IO a main :: IO () main = do initServerless withLambdaBackend opts $ \b -&gt; do putStrLn "First run took:" time $ execute backend (static Dict) (return 42) threadDelay $ 30*1000*1000 putStrLn "Second run took:" time $ execute backend (static Dict) (return 42) ``` 
Oh neat I didn't realise traverse had a underscore varient. Thanks
Is there a good reason to be restrictive? I think the traverse_ solution is probably better than my original.
I used LYAH and thought it was fine. Haskell Book is more in depth but can feel piddly and filler. LYAH is closer to a better balance but glosses over some stuff. Ultimately I bought both. You can get by with LYAH+Internet.
I see wondering if someone was going to say Cardano
Understood. Thanks Also, that was fast.
I wanted to learn yet another language. Decided upon FP as I was unfamiliar with it. After some research it came down to learning either LISP or Haskell. Some more research suggested that Haskell has a nicer community, so I went with that. It might be confirmation bias, but I believe I made the correct choice. Strong typing and referential transparency make Haskell the most important programming language I have ever taken up. 
Excellent detailed and insightful response, thanks!
I was hanging out in the esoteric programming languages channel on Freenode (`#esoteric`) in 2010–2011, and one of the users there (`ehird`, Elliot Hird) was an avid user of Haskell, and was quite vocal about its benefits for writing languages. I tried reading “Learn You a Haskell” but gave up because it was too slow and didn’t have enough practical examples. The tutorial that ultimately made Haskell click for me, as a programming languages guy, was [Write Yourself a Scheme in 48 Hours](https://en.wikibooks.org/wiki/Write_Yourself_a_Scheme_in_48_Hours). At the time I was starting to get into concatenative programming, so I started writing a compiler in Haskell for a language called [Kitten](https://github.com/evincarofautumn/kitten). Soon after, I got a job writing an ActionScript compiler in Haskell, which levelled up my skills considerably. Then we got “acquihired” and I ended up at Facebook working with Simon Marlow on Haxl. :) Since then, the practical benefits &amp; problems of using Haskell (along with other languages) in production have directly inspired various features of Kitten, which are either borrowed from Haskell (static types, algebraic data types), deliberately opposite what Haskell does (strict evaluation, unboxed data by default, no GC), or an improvement on what Haskell does (algebraic effects instead of monads). 
I think it is really ok if you have some defined goal/project from the start. Really lightweight and a good reference for syntax and simple examples.
Nah, it’s an entirely consensual, healthy, and happy domination/submission arrangement. Sometimes the compiler and I switch roles and I force it to do dirty low-level or type-level work. ;)
Really depends on the role. Some folks want a masters or PhD. Some don't care. My first professional Haskell was an internship with an Atlanta Haskell company. My second was my first full-time software job after getting my undergrad. My third is IOHK, which employees a lot of PhDs, but they don't require it :)
&gt; What if I've only ever worked on Haskell for pay (ergo, no publicly available aspects)? Then it's rather obvious that you're competent from a 15-20 minute conversation, and maybe another 20 minutes to suss out whether your personal style is a good fit for the rest of the team. If there are any remaining doubts, a 2-3 hour take-home problem with a generous and agreed-upon deadline is reasonable.
This is my goto list of resources.
&gt; good well, that's a matter of opinion and your exact criteria, but generally the answer is "no" it's less effective than just reading blogs (which I ended up having to do anyway while self-teaching through bitemyapp's assembled courses, CIS194, NICTA, etc) &gt; up-to-date No, LYAH is very out-of-date at this point. There are many things in the book that don't compile anymore.
To configure xmonad, mainly. Turns out I loved it and kept doing more stuff with it after
Imperial? Oxford?
?
My journey to Haskell was long and winding path that involves prequel episodes in Smalltalk and C#. The thread that connects all three was first-class support for functions-as-data. I developed a functional style on my own, doing hobby and then semipro work in Unity3D. As I got more serious about it, I started reading the Fabulous Adventures in Coding blog by Eric Lippert, one of the lead designers for C# 3, 4 and 5, and particularly the LINQ query system, which was a monad under the hood. He did a couple of blog series about Haskell; I'd heard of it before, but this was the endorsement that made me take a closer look. I have not looked back.
Back when I read “7 languages in 7 weeks” and did all the exercises Haskell turned out the only language that gave me a struggle. I don’t like it when I don’t understand things so I decided to spend more time on Haskell, learn the type system and then learn a bit more about category theory. Haven’t regretted this at all - except that I now miss a lot of things when programming in other languages.
I'm guessing the question is what university you attended that taught classes in Haskell.
University of Copenhagen \- as I said in my original comment, I'm from Denmark. :\)
I learned Haskell because `pugs`, the then-current implementation of Perl 6 was written in Haskell, and at the time I was working on a javascript compiler so that folks could run code server-side, and the then-in-progress ecmascript specification (that was later abandoned) that I was looking to implement had a lot of "dynamic" typesystem features that felt a lot like the craziness going into perl 6 at the time. I figured I'd write the compiler and learn another language at the time, by falling back on doing whatever `pugs` was doing. it's just another programming language, right? I had no idea what I was getting into.
 putStrLn . concat . intersperse "\n" . fmap show $ matrix or you could do it more manually/imperative p [] = return () p (x:xs) = print x &gt;&gt; p xs p matrix Just kidding. You should just use mapM_/traverse_ , but I think it is fun and sometimes valuable to look at other ways to do it 
I guess one thing is that it's going to be more future proof.
I downvoted you. The "problem" with GPL is that you can't do "Commercial software"? (you are not using the terms correctly. You can sell software under GPL, you are actually referring to privative software). Some people consider privative software unethical, and think that all software must be free software (as in freedom), then GPL is not a PITA, but a way to code without helping to our enemys. That is the case if you code free software under a non copyleft license like mit or bsd. For example when some well known operaning system(s) use bsd code in their tcp/ip stack implementation.
&gt; **As the world’s leading provider of Haskell tools and services**, FP Complete is committed to contributing more than its fair share to the community. Oh, you're too modest...
If you already know how to write code you should consider this one https://www.manning.com/books/get-programming-with-haskell it’s clear, concise and straight to the point. Really good book. If you don’t already write code then Haskell book will be a better introduction since it starts with the foundations and has many exercices.
"ok" is also the most generous thing I could say about it :)
&gt; You can sell software under GPL Please elaborate? I was under the impression that if you sold GPL software then you have to give away the source code under the GPL license and therefore your client can just sell it freely and screw you over. &gt; Some people consider privative software unethical IMO that is stupid, people need to make money, and selling software is one very reasonable way to make money (there are plenty of legal ways to make money that contribute far less to society), but if you have to give away the source every time then that can make that very impractical. One of the projects I am personally working on is a full stack Haskell web project, and GPL absolutely would screw me over, as I am compiling Haskell to JS. Therefore any GPL code in the transpiled JS would force me to release a lot of the codebase under GPL, which we are not willing to do.
That’s so weird as I too have ADHD and while I started with Haskell, somehow I got lured to the complete opposite extreme in low level programming. I basically only write C now and at first it was pretty rough but there is something “zen” about being able to see things from the machine perspective. My experience is that most of the limitations of ADHD come from being forced to do things that aren’t intellectually stimulating. If you ever get the urge to explore a few levels down, give it a shot. I think you’ll surprise yourself at your ability to adapt.
I will have to sit down with this an understand it, since I've never used GADTs before. Thank you!
At least a lot of the concepts carry over to other languages, like preferring immutable data structures, minimising shared state, and taking advantage of the type system as much as possible. In a language like C++ with a fairly expressive type system, or even languages with weaker systems, you can encode a lot of things from Haskell—it’s just that people rarely do because it’s often quite verbose. For instance, now I often find myself using the visitor pattern since I’ve realised it’s just an encoding of algebraic data types (Böhm–Berarducci encoding). I can use template template parameters when I want higher-kinded polymorphism, and do template metaprogramming with ease now that I can see it’s a verbose functional language—although this is becoming less needed thanks to `constexpr`. Because of Haskell I now tend to make things generic by default, use simple wrapper types, and enforce safety with phantom types, for example: template&lt;typename CoordinateSpace&gt; struct Point { double x, y; }; typedef Point&lt;struct WorldSpace&gt; WorldPoint; typedef Point&lt;struct ScreenSpace&gt; ScreenPoint; ScreenPoint project(Camera const &amp;, WorldPoint const &amp;); 
Because of this open source project: [https://github.com/facebook/duckling](https://github.com/facebook/duckling)
good job!
IMO Learn You A Haskell is a great first book. It mainly only covers the fundamentals of the language itself so I don't imagine it being outdated any time soon. 
Because i was annoyed by all the perenthecies, brackets and generally the long-windedness of java and co
Seems neat! A couple quick comments: - `execute` doesn't seem very useful (why not just run the io action locally?) - on the other hand the code in the body of that function (after the call to executeAsync) seems like the sort of boiler plate all your users will end up defining, so perhaps would be useful to abstract out - in this thread you effectively explain the concept by relating it to `forkIO`; maybe using `fork` in the naming in your API would be useful
Add your local packages to the `packages:` section of `stack.yaml`. packages: - location: 'path/to/package' extra-dep: true ...
It's fine. Just keep `ghci` handy and futz around to understand stuff as well :)
They seem commited to contributing more than their fair share of bullshit.
as a fellow haskeller, what is twitter?
Thanks for this intro!
Elm was my gateway drug to Haskell. I got hooked to the idea of changing code throughout, making the compiler happy and then have it run without bugs. I use Reflex these days and I'm excited about its future, especially in regards to using Haskell for writing mobile apps.
Thank you for your input! I wrote a compiler from Java to Mips in class before, that was nice. I am not afraid of assembly anymore - but I like the higher levels more I think:)
I also came from Smalltalk and loved Lisp! Smalltalk was great and programming with a live environment is awesome, but fp has enough to offer so that i can turn my back towards OO.
Got tired of refactoring python code base. 
Also around 2007, I watched the video of Simon Peyton-Jones' talk at [OSCON](https://youtu.be/jLj1QV11o9g). The beauty of the language, combined with SPJ's clear explanations, was what got me interested enough to download GHC and try it out.
I did something like that some time ago. Also check out the paper "Testing Polymorphic Properties", by Bernardy et al. that approaches this problem with free theorems. https://github.com/Lysxia/metamorph The basic idea is the same as what you have here, substituting the universally quantified type variable with a tag to inspect the monomorphized type. Indeed, there is no other way of inspecting a quantified type in Haskell. Another approach would be to step out of the language, with Template Haskell, plugins, or go further outside the toolchain. I was also trying to make the tag type as small and structured as possible, depending on the type being considered, so I ended up with a fixpoint construction to take advantage of substitution in the host language (Haskell). But now that I know more about type families, I think that may have been unnecessary. The goal was to come up with a general technique, but while figuring out the theory I ran into various problems, there are some cases where I generate more values than I would like, and then I lost steam but I'll come back to it when I have the time. 
I see your point, thanks.
This finally got me to understand lift and liftIO
I had to learn enough of it that I didn't fail my Language Engineering module at university. I spent about a week at my computer banging my head trying to understand parser combinators and then things started making sense and I appreciated the syntax. Ultimately I think I just really appreciate the maths-y-ness of Haskell. It's incredibly satisfying to use in lots of different ways because of this.
The question can be asked the other way around: what kind of Functor-container corresponds to the optic in hand. E.g. for Lens: http://oleg.fi/gists/posts/2018-05-12-singleton-container.html, Prism would use Pointed (no Functor!) in its Traversable-like class. Pointed+Functor for AffineTraversable... and then I guess you have it all, as Folds are Traversable -&gt; Foldabke line restrictions of these classes.
&gt; Who is paying to you for your development? I, as a client whould actually buy only GPL licensed software, I don't want a product that I don't know what actually does. I thought I made it pretty clear from my post that its a web project, so it is a website you go to, not software you buy and download. My point is that technically the end users are downloading the software (since its JavaScript) so if I did have GPL libraries in my code (luckily I do not) it could be a problem. &gt; That you find our libraries not useful for your propietary software is not a problem. Moreover, that is actually the reason why we do it. Lucky for me the vast majority of libraries are MIT/BSD/similarly licensed and understand my point of view.
Why \*both\* \`locaction\` and \`extra\-dep\`?
We usually call these `[ANN]` here.
I kept hearing "if you really want to challenge yourself, and you really want to think differently about programming, learn a functional language." I blew it off when I heard it. Eventually though, I started going through a JavaScript book, and there was a chapter on higher order functions. The concept of higher order functions blew me away and I was immediately hooked. I felt like it opened up a world of possibilities that I had never even considered before. To sink in the concept, I started learning Haskell so I could really grok JavaScript functions, but before I knew it, I was way more interested in learning Haskell than JavaScript. On a side note of learning Haskell vs another language, I've felt that when I learn something new in JavaScript (or C# for that matter), I constantly feel like I'm learning new things to either memorize or exceptions to the rules that I've come to understand. The languages are unpredictable at times and I feel like what I'm learning is just "Oh, add that to the pile of things to memorize when I'm using the language." But when I learn something in Haskell, it feels like I'm deepening my knowledge of math and programming, rather than just learning useless exceptions and odd syntax that can be googled.
This.
Because I want to improve my programming skills and problem solving abilities.
I think it's extremely common in Germany \(I'm doing my MSc. in Germany\-\-first CS course here teaches ML\). 
Well done and thank you!
Thanks! All excellent points: * You're right that `execute` alone is not useful. It is supposed to be used in concurrent fashion, e.g `results &lt;- Control.Concurrent.Async.mapConcurrently (execute ...) inputs`. But I agree that I need to somehow emphasise this aspect. * Makes sense. I guess I can create `wait :: TVar (ExecutorStatus a) -&gt; IO a` and make `execute = executeAsync &gt;&gt;= wait`. It'll make what's going on a bit clearer. * That's an awesome point. I honestly haven't thought about it before, I only figured using `forkIO` as an example while writing that comment. Probably calling this library `serverless-fork` and renaming the functions as `fork = executeAsync`, `forkAndWait = execute` would be much more clearer. What do you think?
Me too. I was really intrigued when Swift came out, so I desperately tried to show that all the cool Haskell things could be done in Swift. Not only was I wrong, but the research required taught me that Haskell was actually awesome.
Did you write it in Haskel? Can I play it?
And now I'm noticing how much I've completely forgotten all of my kanji. =( Those flashcards are gorgeous, though.
Super clean syntax. No opinionated anything. There's language pragmas, all the error handling I could want to choose from. Kick ass composition, strong typing, reasonable performance. Tons of libraries. Default green threading and GC. I came from Go, which of the above list, only achieves performance, green threading and GC. The rest of that language absolutely sucks. Python is pretty good, but dynamic typing is just too hard on big projects, the performance sucks, and they fucked up their concurrency model with this async bullshit.
Oh nice! Yeah I just saw in the Beam docs that you can [embed mixins](https://tathougies.github.io/beam/user-guide/models/#embedding). I guess the only thing I'm still going for is automating the behavior of default columns common to all tables in a database. I'd almost rather go the reverse way... that is from `BlogPost -&gt; BlogPostTable` Reason being, the behavior around `createdAt` and `updatedAt` fields, as well as the ID field, should always be identical. I'd like my selects and inserts to always have the same contractual behavior around them. In other words, I'd like to start with `BlogPost` and make something like `instance MyAppTable BlogPost`, which is an instance of Beam of that automatically has an ID field and createdAt and updatedAt field. I can then implement generic `insert` functions and such that default `created_at` and updated_at` fields. Either way, thanks for the response. This is actually extremely helpful, and I am going to start implementing this in my current app!
Like Neo would say - Because I choose to 
I've recently found myself in need of a type like newtype LiftMonoid f a = LiftMonoid { unLiftMonoid :: f a } deriving (Functor, Applicative) instance (Applicative f, Monoid a) =&gt; Monoid (LiftMonoid f a) where mempty = pure mempty mappend = liftA2 mappend Of course, this wasn't exactly hard to write; [here](https://github.com/Solonarv/perfect-flow/commits/master/src/Data/Monoid/Extra.hs) is the version I ended up with. This newtype seems like it should exist in a library somewhere, but I haven't been able to successfully search for it as the term "monoid" appears in nearly every piece of applicative-related documentation. Does anyone know of a library containing it?
I grew up teaching myself basics of imperative code via QBasic, C++, and JS. I also ended up getting a degree in math, not because I like numbers or calculation, but because I enjoy the logical epiphanies it delivers. Years later when I was first learning modern JS web dev, a classmate of mine (who apparently understood me well) said I would like Haskell. Sometime at least a year after _that_, I stumbled across some Haskell-based article – probably something about functors and monads, and how JS promises are (trying to be) monadic – and whatever the article was, it blew my mind. Here was something _significantly different_ from what I assumed pretty much all programming languages were like. At that point I had at least played around in QBASIC, C++, Python, Ruby, Java, and JS, so the idea that there was this entire _other way_ to program, which was based on fundamental mathematical/logical principles and completely divorced from the concept of a stateful machine, was tremendously exciting. Since then everything I have learned about Haskell, pure FP, lambda calc, category theory, various type gymnastics etc. has only deepened my appreciation for the ideas underpinning Haskell and the terseness / aesthetic appeal of the language (both semantically and syntactically). I'm still learning it, relatively new to the language and working through various texts / courses etc. I know enough now to also see some of the inevitable warts in the language. All told however, Haskell seems to be a constant wellspring of brilliant ideas which are often exportable to other languages. If the goal is to learn what's possible in FP, I am not sure that I can pick a richer conceptual landscape to explore.
Because [Mark Jason Dominus](https://blog.plover.com/) talked about it.
I didn’t know that about SPJ. Good to see people traveling the road less traveled in their chosen field.
My background is in philosophy \(I did a PhD\), and specifically I have a background in formal logic and semantics. I was familiar with type theory, and category theory, among other things. So when I stumbled across Haskell, it clicked. I primarily do Python and Go in my day to day but I'm waiting for the day I can do some Haskell at work.
Yup, we just merged functionality for parameterized tables, so you can define a container table for cross\-cutting concerns. You've probably figured this out, but just wanted to put it out here for those coming later: data MyAppFields table f = MyAppFields { createdAt :: Columnar f UTCTime , updatedAt :: Columnar f UTCTime , payload :: table f , myAppId :: Columnar f UUID } deriving (Generic, Beamable) instance Beamable table =&gt; Table (MyAppFields table) where data PrimaryKey (MyAppFields table) f = MyAppKey (Columnar f UUID) deriving (Generic, Beamable) primaryKey = MyAppKey &lt;$&gt; myAppId It's not in the docs yet, because this is new :\)
he had you ad comic sans didn't he
Yeah, it was a bit of both, plus some health issues (stress related) and a long term relationship ending unexpectedly that put me in a weird place. Honestly, I miss it a lot, but realistically, I’d probably be doing the same thing I’m doing now even if I stuck with it, just 3-4 years later. 
Has anyone made a projectional editor like you described? I'd be interested in taking a look at one.
Monads
When the first Haskell report came out I wanted to try it. But there was no Haskell compiler. So I learned Haskell in order to write the compiler (hbc). 
what a load of shit
My company does fairly standard industry software development, so advanced type theory or compiler design knowledge or whatever won't really affect your chances of getting a job with us. What I care about is if you are capable of picking up new tools, working on a team, and able to engineer a full software product from requirements and maintain it through its life cycle.
I have worked at Galois for over 8 years and have no advanced degree. My background prior to Galois was primarily product and consulting companies. I regularly interview engineering candidates for Galois and can say that while we do look for researchers, we also look for folks with interests in general software engineering and learning new topics as needed. Galois needs people all over the research/engineering spectrum to succeed.
For Rust library dev you normally just `.gitignore` the `Cargo.lock` file. But that's a special case for library developers who generally know what they are doing. You want to optimize for the case where you forget - both for newcomers who don't know best practices and you when it inevitably slips your mind. Granted, there is some teaching that is still required - eg. "what is this `Cargo.lock` thing?", but at least folks can search for it on Google if they are curious.
I'm in the same boat. In fact, it would be great to have a professional PDF, say 2-3 pages or so, about how awesome Haskell is for saving money, developer time, etc, for companies (plugs by professional consulting would be a bonus since it adds authenticity to Haskell). That way I have a nice thing I could point middle management or a team lead to for advocating it in the company for internal tools
Not sure if I'd be the best one to do so because I don't have much context on the actual constraints of the cabal tool. Tbh I haven't done a lot of actual Haskell dev. Granted, part of the reason is that the package management/tooling story seems so messy and impenetrable for newcomers: - Cabal: non-deterministic by default with a weird form of versioning - Stack: complex and heavyweight with confusing docs - Nix: even more poorly documented with a huge amount of things to learn and not many clear best-practices If you want to link to my comment in an issue, feel free though! My github username is @brendanzab if you want to mention me.
Are you still afloat? The suspense is killing me
I was a Pythonista at the time, and I looked into Haskell because a friend said it would help me better understand Python's functional programming features. People don't seem to favor LYAH as much these days, but this (free!) book was the hook that caught my interest.
We left for other reasons, and brought haskell to another startup. Both are still afloat so far
Good to know! I'll see about reusing this then; the parsers are not very complicated in the end, just basic usage of hexpat, but weren't specifically interesting to write, and their code isn't so nice to look at at the moment.
I was very fortunate to have been able to take a class that Bryan O'Sullivan taught at Facebook back in 2012. I had been interested in the language for a very long time \(especially after spending years writing production Erlang prior to FB\) and couldn't pass up the opportunity to learn it at work :\) I left shortly after and put in a fair amount of self\-study before I started working again, but haven't had a good opportunity to directly put it Haskell to any practical use. However, putting in the effort to learn it has made me a better programmer in every language I use, and it made it so much easier to learn how to use other type systems \(I've worked with FB's Flow a lot recently\).
Oh, please, no! Do not make me pass standard tests here! I am alright with data kinds. But I will never be forcing myself to read the whole of _Real World Haskell_ (not because it lacks merit, but simply because it is not my style of learning). The day Haskell becomes another *academic discipline* with courses and grades, I will leave my beloved language in tears forever.
Haskell is really diverse. There are a lot of concepts and there isn't one single path to take. Some people use mtl without knowing anything about free, some understand ffi really well without ever touching lens, some do a lot of type level programming never using pipes, some can reimplement parsec without ever using generics. My point is, the level approach is problematic because programming in Haskell is not a linear path. Each person has a different subset of skills and knowledge, and that's ok.
Here's an article on mtl: https://blog.jle.im/entry/mtl-is-not-a-monad-transformer-library.html
As someone who enjoyed Why's Poignant Guide to Ruby, LYAH fills a similar niche, though the goofiness and tangential stories of LYAH are dialed down to more generally palatable levels than the poignant guide. More serious/boring material exists, but as far as Haskell is concerned, LYAH is (to my knowledge) still unique in serving up lighthearted illustrations and similarly lighthearted examples while it teaches you Haskell. It's neither perfect nor comprehensive, but I feel it hits a sweet spot that no other Haskell resource does.
Page 11, the description for `-XDerivingVia` is still not 
I think the general buckets of "new", "intermediate", and "expert" are sufficient. There is always this: http://lambdaconf.us/downloads/documents/lambdaconf_slfp.pdf but I hesitate to even link it because it feels very arbitrary to me. And of course the level names are ridiculous.
4chan /g/ made me do it.
Thank you. I think I now have a clear picture of your landscape. And I must say it is quite dystopic. Would the following two points hold? * Political power grows with economic power, and falls with the fall thereof. * Economic power grows with sociopathy, and, therefore, due to zero sum competition, holding to any kind of ethical values inevitably results in complete loss of power.
I thought there going to be a new version of the haskell report, FML...
Hah, this was quite close to my motivation as well!
IMO, I learn a lot more when I ask for help and people give me a solution beyond my understanding :) Maybe it's not such a bad thing?
&gt; there is something “zen” about being able to see things from the machine perspective Where did you get this mythical machine with a processor that executes instructions sequentially in order without any pipelining?! :)
I use `StableName` in CodeWorld, to detect when certain functions won't don't do anything. For example, if the function update a game state when time passes is actually the identity function, you can avoid spinning every frame and just wait for event handlers instead. And if a frequent UI event like a mouse movement doesn't change the game state, you can avoid propagating it over the network in a multi-player game. Key code: isUniversallyConstant :: (a -&gt; s -&gt; s) -&gt; s -&gt; IO Bool isUniversallyConstant f old = falseOr $ do oldName &lt;- makeStableName old genName &lt;- makeStableName $! f undefined old return (genName == oldName) where falseOr x = x `catch` \(e :: SomeException) -&gt; return False It may be an abomination, but it's an abomination I'm quite proud of.
As a Clojure programmer by day, I wanted to learn a pure functional language and understand the differences, the benefits, and the trade\-offs.
_executable_ pure math
I wish to continue my master degree in germany
Still a better love story than Twilight.
I've had a ghci session running at all times since 2015 I think.
The playful style of LYAH can be of service to a Blue Tie Programmer as well though. At any rate, I find that many concepts in Haskell simply don't tie to any feature of other languages, so prior coding experience doesn't really matter.
Is it available online?
You lucky dog!
&gt; Thank you. I think I now have a clear picture of your landscape. And I must say it is quite dystopic. but please note : this dystopicness is a consequence of an already existing problem; i assumed that a bad law exists &gt; Political power grows with economic power, and falls with the fall thereof. true &gt; Economic power grows with sociopathy false; the more social, friendly, ethical, trustworthy someone is, the better his business will go &gt; holding to any kind of ethical values inevitably results in complete loss of power. not any kind, but only in a few areas but note : i am not saying that one should drop morality; rather that in some cases the good [hence moral] behavior is different than one would perhaps think at first thought; you may think at your first thought that you should not patent your "invention", because monopolizing by force [using the law] is unethical; but i say : while getting rid of your competition by force is really unethical in general : it is the good choice in the patent case; if you invest the money (that you gain by using the law) into lobbying against the law then you achieve better result at the end; by "lobby" i mean for example creating and advertising an educational material about the disadvantages of the particular law the sense in being ethical is not that we can show off with it, or that we can feel our souls clean; but to achieve something overall good at the end; hence the successful way is ultimately the ethical way this is not always the right recipe though; for example : a politician can not achieve good result by lying, cheating, by that gaining power and using it for good as planned; this is because in this case additional costs, dangers and lack of real result happens; the costs are for example poisoning the society with internal wars based on lies; the dangers include the risk of tyranny; the lack of real result is that the society did not come to the good end by understanding, which hints that the achieved good situation is not stable so one needs to think case-by-case; in the case of patents : the situation is clear for me; using the patents is not dangerous, and only temporarily harmful, while clearly more successful at the end
Hahaha! I remember wtf-Ing when I saw the video too.
Wandered into my first meetup in town, PWL \(Papers we Love\). They were discussing a Haskell Curry paper. They invited me to come to a Haskell group the next day \(same time, same place\). Dumb luck, really. It's been really enjoyable thus far, it's pretty to look at \(clean, concise\), and the community has some very fun people I consider to be really great friends and mentors.
It’s been retired for years. 
I went through both Common Lisp and Haskell (still a beginner-intermediate in Haskell), and I concur - Lisp is all nice to write, but very difficult to maintain. For me, strong static typing ultimately trumps everything else.
marketing game pretty heavy-handed imo
After being introduced to Haskell, I find myself to be incredibly snobbish regarding dynamic languages. I attribute almost all the difficulties in maintaining large Ruby and JS codebases to the willingness of their compilers to accept almost anything that vaguely resembles canonical code, without even verifying that you aren't trying to find the square root of a string or whatever. 
You're basically just inventing `!` polymorphism, which is going to be the same thing as monad polymorphism, with all the same confusion.
I meant as a way to read the code. Perhaps you could open source it on Github?
Because it's refreshing. At work I do web applications in PHP and C#, which are languages for getting things done, with multitude of libraries, frameworks and SO answers, and yet messing with Haskell is satisfying because it's so logical and pure (no pun intended).
The most workable solution I can think of would be the implementation of sodalities. An esoteric word, certainly, but a good one; meaning: a brotherhood of organisational purposes. One can argue that boy scouts, \[classical\] fraternities to the military have this distinction in common; the other being investiture. Investiture can be summed up as the ceremony or acknowledgement of honor, merit, or title. For scout troops, the scout in question is acknowledged to have a merit badge for learning a skill, which gets into standardisation of skills, or CS certifications. Though the question is who sets and monitors the skills or badges: Who is the scout leader? A so\-called adult: Collegiate, or Officer. Getting past scout troops, there are the fraternities, also called mutual/benefit/honor societies. They are effectively the hereditment of alumni and associates, and are basically a scholastic society. Though a concrete example for this analogy would be a GHC forks' working group. We can eschew standards like GPA, with something like involvement, vetting, and probation. People in this realm don't necessarily need to be employed, much like college students don't need to be employed, they are in it for advisory, mentorship, or research. And often time the alumnus or associates are from the military or industry. The other people to set the standards would be the military, or rather the industry. There's enlistment and training to be a fully functional employee, or a fully integrated employee. And the usual cadre of specialisations within the company: manager, backend, ... The military in general is the best example of investiture because of medals like the Congressional Medal of Honor. Everyone in Congress, the Senate, and the President have to rise for the medalist. To say the least about the in\-groups formed around deployments and regiments, or projects and companies. As far as how this plays out, the scouts would effectively be initiates or reservists for the latter two. Fraternities and the military can be said to be complementary or duals. The point is that standardisation into buckets doesn't really work for something like a programming language, much less things like basic knowledge and skills, curriculum vitae, project resume, or employment. And further to say the absurdity of creating a single or central institution to learn, teach, implement, research, or use a programming language. Unless of course the person in question is still part of the *scout troop*. Going back, scout troops often have the cub scouts, eagle scouts, and scout leaders. Eagle scouts could be underclassmen, or NCO's; scout leaders are upperclassmen, alumnus, or CO's. And the general manner in which scouts are taught, I think would be called, mobbing. This is to say the least of alternative methods like workshops or boot camps, not discounting those that are self\-taught, *all roads lead to Rome*. . Any thoughts on my general frame of mind here? The gist is that scout troops are just participating and learning, while fraternities and the *military* require some amount of initiative or recommendation, people aren't flippantly inducted or employed, that'd be irresponsible and wasteful.
I study PL/type theory and compilers and Haskell is a beautifully pure functional language with a really neat type system! I also think it could be the perfect way to teach programming and computation from a pure mathematics perspective; Turing machines and state are great as a mathematical model (and literally equivalent in expressiveness) but I honestly don't feel they align as well with the way we ought to think about programs. State is a messy necessary evil, but we could at least have people thinking in terms of invariant properties and laws instead of trying to manage knowledge about mutable states while simultaneously trying to get raw functionality happening. 
I worked at a place where they used a lot of OCaml. I was amazed at the stability and richness of their codebase, but got put off the language because of its nasty edge cases and syntactic warts. I then saw this code written on the back of a coffee machine [1] at a shop round the corner from Standard Chartered in London: `f = 1 : 1 : zipWith (+) f (tail f)` By the time I'd worked out what this meant, I was hooked. [1] True story. I still have no idea who put it there.
I joined a company and was looking for a team that matched my interests. Only two did, and the other one was predominantly C++ which I had already worked with.
I wanted to learn to love static types, but the only statically typed languages I'd written were Java and C#. While I can \*respect\* both of those, I just couldn't \*enjoy\* them, and kept turning to Python, Clojure, and \(yes\) JS when I actually wanted to enjoy programming. I figured if I was ever going to love a type system, it would have to be a properly powerful one that would help me express intent, instead of making me create a new file with 20 lines of boilerplate for everything and still not really represent the model very well.
Discussion on it: https://www.reddit.com/r/haskell/comments/5fohat/lambdaconf_standardized_ladder_of_functional/
I was looking for something new to learn back in 2006. At the time I was in something of a rut with respect to CS/SE, as everything looked exactly the same, old and boring to me. More or less randomly I decided to learn... XSLT. My mind was blown. I wasn't really interested in applications of XSLT that much, but I found this very strange way of looking at things to be very appealing. Then I figured out that this was very much the FP way of looking at things. So I decided to learn "FP proper". I researched the topic a bit and was considering to start with OCaml, F# or Scheme... but Haskell looked to be the most hardcore option. No excuses were accepted. And I always believed in jumping off the deep end, not just for shits and giggles, but also as the most effective way to learn something. Thus, Haskell.
I found it somehow in the Internet many years ago. At that time there was no LYAH, Real World Haskell, Haskell from First Principles etc. so I tried the Gentle Introduction out of pure curiosity. That didn't go well so I learned Scheme instead. After some years, when Real World Haskell came out, I tried again (I don't like not understanding things). This time it was better but I was also writing a Scheme compiler at the time so I wrote a couple of small programs and left it. Only a couple years ago I got serious about it again and decided to stop messing around. I still don't use it for anything substantial but I love it anyway.
One word answer "Recursion". After being dissatisfied by the way recursion (as in recursive programs and also as in recursive data types) was treated in main stream program, ML with which I started was a breath of fresh air. Slowly I moved to Haskell with a brief interlude with ocaml.
Because I wanted to understand homotopy type theory.
Probably, if you are extremely careful to not let any lazy thunks escpe. I don't totally remember how unsafePerformIO interacts with the stack traversing machinery to be honest.
Ah, interesting. It seems that they intentionally changed the names of the "levels" from "Novice"/"Advanced Beginner"/etc to gibberish on purpose, probably in response to the critique that the level divisions are fairly arbitrary.
There was this [GHC proposal](https://github.com/ghc-proposals/ghc-proposals/pull/52) for partially applied type families that went dormant recently and is waiting for someone to revive it. This would give type level functions and from there lambdas would just be a syntax thing.
I am very surprised not finding Hedgehog (https://hackage.haskell.org/package/hedgehog) in this report 
What a loada farkin bullshit. Scala flashbacks.
It was never up to the level of playable, and I would be kind of embarrassed at the code I wrote back then. It did work a lot better than C did at the time. It would work even better with the libraries that are available now.
Haskell was the first FP language I learned, and I used it for a year. Been using Clojure for about 8 years since then, and haven't seen a single reason to go back. My team has likely built more large projects using Clojure than most people have with Haskell here, but by all means keep patronizing.
Here :) https://github.com/Icelandjack/ghc-proposals/blob/patch-3/proposals/0000-deriving-via.rst https://github.com/ghc-proposals/ghc-proposals/pull/120 https://phabricator.haskell.org/D4684 
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [Icelandjack/ghc-proposals/.../**0000-deriving-via.rst** (patch-3 → 239cfc8)](https://github.com/Icelandjack/ghc-proposals/blob/239cfc8ef532db95f15ea392e073061f04273d8e/proposals/0000-deriving-via.rst) ---- 
That comment was more tongue in cheek, no offence intended! It's always fun to have new people have the old static-vs-dynamic systems religious war! :D
pure comment
In any way, you have to traverse the list. A possibility is: replace [] _ = [] replace (x:xs) (0,a) = a:xs replace (x:xs) (n,a) = if n &lt; 0 then (x:xs) else x: replace xs (n-1,a)
fair enough :)
If you're going to be doing it a lot you could look into data.sequence, which has an update function. Or arrays. Probably not worth it, though, since splitting and consing will probably be faster if you're doing it only once. You could also probably write it with a fold... Might be faster than split and cat. 
Unfortunately, no one submitted an entry for it. Maybe in October?
I noticed [HaRe](https://github.com/RefactoringTools/HaRe) mentioned in the new report -- how close is it [scalafix](https://scalacenter.github.io/scalafix/) in terms of functionality? (Disclaimer: I haven't used scalafix but I've heard good things about it.) Right now, it seems like it is intended to work inside the editor only. If we had something like this, then it'd be easier for library authors to make small breaking changes for a better API without worrying about downstream users not upgrading.
I wanted to learn a new language and narrowed it down to a choice between Scala and Haskell. Scala was natural at the time because I was doing a lot of Java development. Haskell got on my radar because I saw it mentioned a few times on proggit. I specifically chose Haskell because it seemed like the hardest and would stretch me the most.
Yes, this is an extension of the work I started with glambda.
I am able to confirm this with the following: import GHC.Compact import Data.HashMap.Strict as HM main :: IO () main = do _ &lt;- compact (HM.fromList [(1,2),(2 :: Int,3 :: Int)]) putStrLn "done" Building this with GHC and then running the executable gives the same crash you are getting at GHCi. I suggest opening this on trac. Please provide a link if you do since I am interested in following the issue.
Are you writing that as an exercise, or is it something that needs to be fast that you intend to call over and over?
To configure my window manager. I didn't know any programming (beyond maybe some bash) and was working as a Manufacturing Engineer. I was using Arch and XMonad and wanted to change some things. I would read a little LYAH and see how to apply some concept to achieve something in my config. It was the perfect level of challenging-but-achievable to keep me motivated. I didn't really know what a Monad was, but I had manged to put together some pretty complicated stuff (e.g. parsing and displaying content from RSS feeds through a dzen status bar). At some point, that got a little ridiculous so I had to find a new project. I stood up a blog through Yesod and started the same process of reading a little and applying concepts in that project. Eventually I was extracting things to libraries and getting involved in the budding Yesod community (this was pre-1.0). I still didn't really know what a Monad was. At this point, I've made the jump to Software Engineer and am fortunate to have Haskell as my professional language. My XMonad config is now basically stock and my blog is rightfully back to a simple static site. I'm still not really sure what a Monad is.
My only question is: why
Thank you for the confirmation and for the Trac ticket ! I wonder what other data types besides `HashMap` use `SmallArray#` .
I practiced Project Euler problems to learn programming a while back and kept seeing terse Haskell solutions in the forums after finishing them. I thought that was cool, so I gave it a try!
Just as an exercise
I'll create a more formal post later but we, [Weever Apps](https://weeverapps.com/), basically build line-of-business information systems that collect data from people in really, really large organizations. We replace clipboards and paper with tablets and phones; we replace spreadsheets with live, up-to-date data, notifications, analysis, etc, etc. Some of our products under development are intended for deployment in regulated industries and we chose Haskell to help us get to _working software_ faster. _Working_ meaning: it can be proven to meet its specifications, is documented, and maintainable. So what I look for in a programmer is someone who is a great communicator, interested in the problem domain, and has ideas about how to solve problems we face. We don't have a tonne of Haskell experience on the team yet so I will be looking for candidates who can demonstrate experience with the language, tooling, and ecosystem to help bring us up to the next level but I'm rather open to what that experience is and where it came from (school projects, open source libraries, side projects, etc all good.. I just want to bring in people who are able to teach other developers).
A lot of universities, particularly in the UK, teach Haskell. It's not just Imperial/Oxford.
None so far, but we'll post if they come up. 
8h working day, weekdays only.
I'm always fascinated by languages, when I was young I tinkered with many and I read lisp will make me a better programmer, then mercurial was a thing and I found a link to real world haskell book, which was a complete mindshift for me, I was familiar with many of the apps, but not familiar with the language. Knowing gtk and ffi and did lots in python, even wrote a complete pcre bindings for python motivated by that chapter, yesterday I wrote a parsec library for python too and applied functors and applicatives with either and maybe monads. Haskell did change my mindset and the way I tackle problems. I hope I utilize it more :).thanks for reading this
It was the most difficult, weird looking language that I ever came across. I remember looking at some pointfree Haskell and it looked like programming in Greek. Plus, I had been in js-land too long and I needed to drink the type koolaid.
`Traversable` is a good constraint for this, it means we `replace` preserves the shape of the structure
By default Beam nests fields by separating the parent and child field with a double underscore. This avoids name clashes with any name beam will generate. You can modify this by using `withDbModification` and the `renamingFields` function. Something like myDatabase = defaultDbSettings `withDbModification` renamingFields myRenamer where `myRenamer` is a function from `Text -&gt; Text` that takes the default name and returns a new name. You can drop everything before the last `__` if you want \(but you'll have to make sure your names don't clash.
OG
Ah, yes, I should have clarified that my goal was to be productive. Given the goal of learning *(and infinite time), then I agree that the most appropriate solution would always be welcome, regardless of how many advanced concepts it embodies.
Ah, this is exactly what I had in mind! The concerns and objections noted elsewhere, I will say that I could almost immediately identify myself as somewhere between Lubline and Skrig.
Surface area sounds much easier, since you can simply sum the areas of all the triangles. In that case, you only need to be able to parse your file; either googling will lead you to a library for doing that, or you'll have to write your own, in which case we can give you more advice as to how to do that. *googles* You're in luck, there's a package called [STL](https://hackage.haskell.org/package/STL)! But I assume you've probably already found that on your own. Calculating the volume is much harder, since a bunch of triangles might not even describe a closed volume! Whichever algorithm you come up with to determine that will probably involve a lot of vector operations such as dot products. I recommend [linear](https://hackage.haskell.org/package/linear) for those. Good luck!
Wicked! If you need Kanji split by their 漢検 levels, I [provide those here](http://hackage.haskell.org/package/kanji-3.4.0/docs/Data-Kanji-Levels.html).
If you mean that the descriptions seems incomplete, good catch, I saw it only now. I'm going to look at home if it was a pipeline bug trimming the text or just a mess-up on me while editing.
&gt; Each person has a different subset of skills and knowledge, and that's ok. I absolutely agree, and to the individual it's also certainly true that: &gt; programming in Haskell is not a linear path But I would be willing to bet that with a sufficient sample size it would be likely \(in the [Bayesian sense](https://en.wikipedia.org/wiki/Likelihood_function)\) that someone who claims proficiency in a later skill in e.g. the [LambdaConf Standardized ladder of functional programming](https://www.reddit.com/r/haskell/comments/5fohat/lambdaconf_standardized_ladder_of_functional/) would have skill in an earlier one.
How does this compare to [UPX](https://en.wikipedia.org/wiki/UPX)?
**UPX** UPX (Ultimate Packer for Executables) is a free and open source executable packer supporting a number of file formats from different operating systems. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/haskell/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
I agree! It presents ideas in a clear way and provides many interesting (!) examples. I just want to note that this book is written without the assumption that the reader has programmed before. My personal experience with LYAH is that I found the quirky humour distracting.
I second pretty-simple, my current favorite.
The error appears copied from here: https://ghc.haskell.org/trac/ghc/wiki/Status/Apr18
[removed]
Oh nice, thanks! I'm curious, where do these levels come from? I recognize the kyouiku levels 1-6, but where did you find the definition for the other levels? Also when combined, do all 10 levels from your lib amount to the full jouyou set?
Using government thugs to beat up anyone that copies and pastes your app just so you can make money is wrong. 
Using government thugs to beat up (all laws flow from the barrel of a gun) anyone that copies and pastes your app just so you can make money is wrong. The infrastructure necessary for enabling this system of violence to protect intellectual monopolies requires the development of censorship infrastructure that totalitarian regimes use to censor dissent. I don’t feel comfortable with being in a society with such infrastructure as it could be co-opted for such purposes should the society turn authoritarian. This fact is illustrated by the MPAA literally citing totalitarian regimes as evidence that the policies it wants to implement will be effective.
Trying to get through LYAH seriously turned off my boyfriend from learning Haskell :( It's too slow and gives you just a little lick of Haskell syntax before ending abruptly, without teaching you anything interesting or any techniques you can immediately start using to develop apps. On the contrary, I've heard good experiences of people who were developing their first projects while going through the Haskell Book at the same time, so it must be more suitable for the 'learn-as-you-go' style of learning typically favored by industry programmers.
Is there any particular reason you don't want to do splitting? import Data.List replace :: [a] -&gt; (Int, a) -&gt; [a] replace xs (i, e) = before ++ [e] ++ after where (before, _:after) = splitAt i xs
I hand-constructed them years ago from crappy PDFs I found on the organization's official website. Everything up to 2級 is included (all the Joyo), but not 準1級 and 1級, since those aren't actually defined anywhere. You might appreciate [my article](https://www.fosskers.ca/blog/kanji-en.html) on the subject.
Using government thugs to beat up (all laws flow from the barrel of a gun) anyone that copies and pastes your app just so you can make money is wrong. The infrastructure necessary for enabling this system of violence to protect intellectual monopolies requires the development of censorship infrastructure that totalitarian regimes use to censor dissent. This fact is illustrated by the MPAA literally citing totalitarian regimes as evidence that the policies it wants to implement will be “effective”. I don’t feel comfortable with being in a society with such infrastructure as it could be co-opted for such purposes should the society turn authoritarian.
On a related note but more focused on CI: http://bitemyapp.com/posts/2016-03-28-speeding-up-builds.html
Note that the second thing you mention, `g :: a`, is not a function in Haskell. Functions in Haskell have types constructed with `-&gt;`. `g` is isomorphic to `() -&gt; a`, though, if we disregard bottoms. ``` fToG :: (() -&gt; a) -&gt; a fToG f = () gToF :: a -&gt; (() -&gt; a) gToF = const ``` The two types are isomorphic, but technically not the same.
Note that under standard interpretations, `()` actually encodes no information; its information content is quantifiable using shannon entropy as `- 1 * log_2 (1) = 0` bits.
What? No I'm not suggesting that. I'm not worried about users copy and pasting our outputted JS/HTML and running it on some other site. That's not viable for them at all. My issue is that if we were using GPL we would have to also give them the source code we used to generate said HTML and JS, which would be much more risky. 
There is a simple algorithm detailed in this stack overflow question : https://stackoverflow.com/questions/1406029/how-to-calculate-the-volume-of-a-3d-mesh-object-the-surface-of-which-is-made-up
The only reason for hiding source code from users is to have power over them. For example, to gain a monopoly on support services for said software (such as adding features). The purpose of the GPL is to prevent developers from having power over the users and allowing the users of any software program to become developers and customize it to their needs or switch vendors.
I mean we just don't want users to be allowed and easily able to just copy paste our entire infrastructure and compete directly with us, and the source code that generates the JS depends on most of the infrastructure (to get all the types), so if we had to release it a large amount of our infrastructure could be trivially copied. I think it's perfectly reasonable to not give users your entire infrastructure (and literally license them to reproduce it freely) that you worked for so many hours to create.
Is it difficult to integrate `unexceptionalio` with exiting applications or libraries?
I've tried to make it as easy as possible by providing the three levels of use: the exception instances for differentiating uses of the exception system, the helpers which you can use in an all-IO stack just to catch things etc, or whole-hog where you write your own functions to return Unexceptional. I do different ones of each of these depending on context, though of course the last one is my favourite.
As an update, Ben Gamari has written a patch for the issue, and it will likely be released as a part of GHC 8.4.3.
I thought this would be complex and the 'simplicity' would require a maths degree, but it's actually really elegant.
Twitter is kind of like Google+, except that unlike G+ it's not dead. :P I use Twitter almost exclusively as a Haskell/FP social network.
Thanks! I'm not sure what a Google+ is but I'll stay away from it if it's dead already
In my experience, for application development, you absolutely *do* commit the `.lock` file into your repository, so that devs can reproduce each others' issues, and to guarantee that the thing you build to deploy is the same thing that you tested and developed against. I would strongly, strongly urge that the default be to freeze upon first [new-]build. Upgrading deps should be an explicit choice; automatic upgrades should be opt-in rather than opt-out.
Cabal does have the `with-compiler` option for selecting your desired GHC version -- assuming you've installed it yourself somehow. http://cabal.readthedocs.io/en/latest/nix-local-build.html#cfg-field-with-compiler
Something cabal still lacks (as far as I am aware) is the ability to freeze a dependency to a specific revision. The specific situations where you need this are rare and unusual, but this is necessary to properly use Stackage snapshots. The tl;dr on that is that some revisions have been known to break snapshots in the past, which is why Stackage snapshots pin dependencies down to a specific version *and* specific revision.
&gt; I ran into a truly bizarre stack-cant-reproduce-my-build nightmare scenario 2 days before a launch. If you have the time and interest, I'd love to see a blog post about it, and I'm sure I'm not the only one.
At first I misread authors name as Aaron Contorter :)
[removed]
The compiler is faster, but it is still slow overall given all it can do (ofc the speed is dependent on what you are doing). As for evaluation, lazy evaluation can be hard to get your head around but I kind of got used to it. You could also use -XStrict ;) But beside, evaluation doesn't matter when using Haskell as a learning and thinking tool. Like I said, I use Scala at work, but think in Haskell (and thinking has no evaluation). &gt; nest of maps and flatMaps (fmaps and binds) are not causing stack overflows. Stack overflow? Do you mean space leak? Stack overflows are a strict thing (which can happen in normal Haskell too since not all operation are lazy. ie: pattern matches can lead to strictness).
Fixed now.
it says "configure: error: *** SDL not found! Get SDL from www.libsdl.org." after following the readme
Yeah sorry, the README has not been kept up to date. For now just listen to whatever error messages you get and follow them. We are cleaning up some stuff related to that now, then we will update the readme.
Do you have any screen captures?
Yes we did.
We do have some. In hindsight I probably should have waited a little longer and cleaned some stuff up before posting this. Will add those to README soon.
It isn't really like that. I know a bunch of Haskell developers, all of which are very knowledgeable about Haskell. And I know stuff they don't, and they know stuff I don't. Every Haskeller that I know of has a specific set of things they know really well, and the rest? Well, they get it, but it's not really their primary tool. 
In 4.9.3 Automatic type inference from JSON, the link to further reading is incorrect, it should be [this](http://hackage.haskell.org/package/json-autotype) (packages -&gt; package)
RemindMe! 4 months HCAR notification (let's see if this works)
Fixed now, thanks.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/haskellgamedev] [We made a game in Haskell for our class project, feel free to check it out.](https://www.reddit.com/r/haskellgamedev/comments/8jzx9m/we_made_a_game_in_haskell_for_our_class_project/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
I got a job writing Haskell with neither a college degree of any kind nor even a high school diploma.
What do you mean by "booting the RTS"? That sounds like a lot of startup time, but in fact even a Haskell executable with many dependencies such as `stack --help` starts and terminates within 10 milliseconds.
&gt; In my experience, for application development, you absolutely do commit the .lock file into your repository FWIW, the person you're responding to was talking about library development, not application development. &gt; I would strongly, strongly urge that the default be to freeze upon first [new-]build. Upgrading deps should be an explicit choice; automatic upgrades should be opt-in rather than opt-out. It's been pointed out to me that index-state might be the more appropriate feature to use for the sake of reproducibility, as it won't risk being made inconsistent by revisions, and is a much more lightweight solution.
This is what the index-state feature is for. Make updating things more of a pain, so it's not a perfect solution, but it does prevent inconsistencies due to revisions, and can take the place of lock files as a lightweight way to pin dependencies.
The large fruit company as in the one Forest Gump invested his shrimp money ? 
I like mathematics and programming and someone told me that Haskell was a mathsy PL, so I decided try it out. Needless to say, I fell in love with the language.
But none of those are Haskell? Sure, Agda is written in Haskell and has similar syntax to Haskell, but still. I'm really curious about your story here.
Nice! I did this in C++ a while back, inspired by a different source. https://github.com/benjaminselfridge/mazecut http://www.astrolog.org/labyrnth/algrithm.htm
Have you looked at proof assistants/dependently typed languages like Agda or Idris? They are less practical as programming languages, but more mathematical in many ways.
I think they’ve got it pretty close to optimal, tbqh. For instance, consider what happens when you include the smaller record twice.
Hello Haskellers! I have been thinking a lot of the `Lens` library (or lenses in general) and how to use it properly lately. When I program nowadays I usually put my data types in their own modules (Even tiny ones, just to avoid name collisions), then I create useful methods to manipulate those data types and import them qualified. This provides a nice abstraction of implementation details. Using lenses I feel like the abstraction vanishes. Then the code that consumes the data type writes some ad-hoc lens "query" and focuses in on all the implementation details, and even implementation details of "child data types". I am suspecting this is not the best way to use them. It must be possible to strike a balance somehow, right? If you have some wisdom to share please do! Cheers! 
Same thing at the Chalmers University of Technology in Sweden.
Using index-state as a "pinning" technique is very heavy-handed; it makes it difficult to perform selective upgrades down the line.
The index-state feature is a very poor choice for version pinning. Limiting yourself to observing hackage at given moments in time leaves too little control in the hands of the programmer. It can cover a few simple cases, but is not a powerful enough tool to recommend in general.
I've only run into a real space leak in production once, and it was pretty easy to fix. The vast majority of our performance issues are poorly written SQL queries. I suspect if I were working in an more performance-sensitive space, I'd have stronger opinions about it
That's the one
https://ghc.haskell.org/trac/ghc/ticket/14859. That is the most recent thing I can remember about possible changes to impredicative types.
I like the colors. On arch: `sudo pacman -S glu sdl2 sdl2_mixer freeglut`
What OS are you on? It should be `brew install sdl2`, `brew install sd2_mixer`, on OSX. It should be the `yum` / `apt-get` / `pacman` etc. equivalent for linux distros. Not 100% sure about windows.
That's not total. Better: import Data.List replace :: [a] -&gt; Int -&gt; a -&gt; [a] replace xs i e = case splitAt i xs of (before, _:after) -&gt; before ++ e: after _ -&gt; xs
What we can do is enumerate a set of proficiency levels *without canonical ordering*. That is, while saying "I know Haskell" is too vague for many purposes _(such as outlined in your example)_, we could improve the precision of such a formulation if we outline separate concepts that constitute "knowing Haskell" — for example, "data kinds" (or, perhaps, generally: "modern typing"). In other words, binning and ordering are distinct operations, and we may want to peform one while refraining from the other.
I get wingsuit: user error (unknown GLUT entry glutInit) on Ubuntu 18.04.
Thanks so much for sharing this great project. From the POV of us in the community, the earlier you share the better. Then we also get to share and enjoy the process. But of course it's up to you how much to bother with that, and it also means sometimes you have to put up with our comments like "what about this and what about that" when you're still in the middle.
Glad you like it! And good to know! We didn't release it (or advertise it rather) any earlier because it was a project that was assigned specifically to us for a class, and weren't sure exactly what the policy was on that.
So as mentioned in the wingsuit README, you have to install glut, sdl2 and sdl2 mixer. I only know the exact command for OSX and for Arch, but I just added an "other" section that explains in plain english what is required, as time goes on hopefully more OS specific exact commands will be added.
Gonna delete this and post new one with proper name
Has anyone learned Haskell via the book [Haskell Road to Logic, Maths and Programming?](homepages.cwi.nl/~jve/HR/). I've just decided to get into Haskell as a side part of me trying to study Maths again and wonder if anyone has any experience with this book? And if not, any tips for someone trying to get back into studying Maths as a mid-20s "I was good at Maths at school but did art stuff instead" kind of guy?
I wanted to be able to understand my XMonad config. 3 years later, I still don't understand my XMonad config, but at least I know Haskell now.
I hated the paranoia I got when I shipped C++ code that could crash, or the god damn "cannot read property [x] of undefined" in js...at runtime. Learning Haskell was for self preservation and better sleep.
Copying the result of `stack build` isn't sufficient?
I wanted to learn functional programming and decided to go directly to the source, i.e., Haskell. While the language is different, and challenging, from other languages I've traversed in the past, I do like the aesthetics of it. The language can be used for data analysis, data mining. So what's not to like?
For Hackage you will want to try out the release candidate feature before you make an actual release. If you get a forbidden access error during uploading, you will need to send an email to the Hackage team for upload access (instructions can be found there but I glossed over this in my first try). For inlining related pragmas, I found this useful: https://www.stackbuilders.com/tutorials/haskell/ghc-optimization-and-fusion/ You'll want to check the unfoldings manually by dumping hi files and inspecting the output (read the article). If you really want to be thorough, you should write benchmarks that check that your pragmas are actually improving the performance. Haphazardly slapping pragmas left and right is probably a good way to increase compile times with little to no gain.
Question from someone not completely following your definitions: is the transformation somehow connected to the adjoint relation of the underlying (co)monad? That is, do the resulting comonad from monad (and viceversa) arise from the same adjunctions?
Nice, I'll try it. 
Yes I think you're right - it's much shorter than I thought. I was worried that even a small amount (~100 ms in my imagination) would be bad when multiplied by thousands of calls - but it sounds like it's not really an issue compared with the total provisioning time of an aws-lambda node, which is good to hear.
Runs like a charm on mac. Thanks for sharing. Btw:Could you make a high level comment on the "design pattern"? I saw some lens usage in the code. So is the structure of the code involves updating some global state by using lens libary?
OOC why are all of the instances orphans?
I'll never forget the type of a ReadP parser since Ken taught me that A parser for things is a function from strings to a list of pairs of things and strings \(he didn't write the poem, but he \*did\* put it on his lecture slides\)
What is this nonsense? I thought FPComplete guys were the engineering guys not the suits!
I got interested in Cardano because of Haskell, weird that it was opposite.
Why a GADT instead of a normal ADT? You don't seem to use any of the extra features.
are you aware of diagrams? https://wiki.haskell.org/Diagrams
Oh someone I met on Twitter wanted to know how hard it was to teach Haskell to someone who had never programmed before (relative to teaching it to experienced programmers), and it seemed like an interesting challenge for me, too. A talk I saw about type systems that reminded me of the generative syntax work I'd been doing in college clinched the decision. The Haskell books that existed at the time relied on me understanding things about programming that I didn't know yet, so the best solution seemed to be to write a new book. So I learned Haskell in order to write [that book](http://haskellbook.com/). 
Yes, I agree. However, they're also followed by the word "Syntax" everywhere they appear. When I first read it, I too mentally skipped over the "syntax" bit and was confused when I saw the core type, so I empathize with your point.
As far as I know, the syntax of _using_ the GADTs is exactly the same as the syntax for ADTs. The only difference is in the definition, and that's not what the readme is talking about.
Try solving the problem in front of you with the most straightforward tools you can find. If that becomes too complicated, too verbose, or too unstructured, us a tool or technique to try to re-architect your solution to solve that structural problem. More to your specific case: Don't reach for lenses until you hit the point where implementing or maintaining adhoc functions to do the same thing becomes difficult to do. Haskell makes refactoring really easy, so don't commit to tools or techniques before the need for them arises naturally.
stack generates a standalone executable, what else do you need?
I agree. What my reply to your original comment was trying to say was that this bit &gt; you don't seem to use any of the extra features seems to imply that you're thinking that they're actually using a proper GADT, which isn't the case, as they're just using a plain ADT. (Sorry for the poor wording in the long sentence!) I too am confused why they mention "GADT syntax" repeatedly in the Readme, as it does not affect the library's users.
The common case (only two arguments in the supplied function) is most similar to `foldl`. However, important point of fact: The function passed to any of the JS array methods has full knowledge of the entire array at any execution of that function by the method. Because JS functions can always access their arguments object and receive/process arguments they didn't declare, this basically means that there is no programmatic way to enforce that a caller of reduce or map or whatever array method hasn't decided to do use the 'extra' argument, or some weird `this` context, etc.
You can't go back into the cave. Especially when you start using it for your day job.
Ask and ye shall receive, @jerf http://joeyh.name/blog/pics/bananafridge.jpg
You could limit your use of lenses to within your implementation modules and not export them. I would say that lenses do provide some degree of internals hiding. They let you rename the actual fields in the record, move them into sub-components without bothering clients, and avoid exposing record accessors (when a record accessor is exposed, it lets you use record update syntax, [and that can be trouble for backwards compatibility](http://blog.ezyang.com/2016/12/a-tale-of-backwards-compatibility-in-asts/).) They also let you have internal representations of fields that are isomorphic but not exactly equal to the external one.
Awesome, don't bother with the GUI, stick to the command line one. Feel free to jack any of the algorithms.
As /u/IronGremlin points out, it's actually foldl. If the order of evaluation doesn't matter (which is a common case) then foldr and foldl are the same. (I learned the difference when implementing an interpreter for AoC and discovering all my answers were wrong.)
Since the book is from 2004, it is quite likely that parts of it are a little dated. This might complicate things somewhat, in addition to learning a new language and other unfamiliar topics at the same time. On the other hand, you should probably just dive in and see if you feel like you're making progress. You have more choices, however. There's also [the DSLs of Math course](https://github.com/DSLsofMath/DSLsofMath), which from what I have seen is also targeted at Haskell beginners. I've been itching to take a shot at it for a while now.
Read the "Eloquent JavaScript" book. Liked the functional programming chapter a lot, made a mental note to go find the most functional language I could get my hands on and learn it as a brain bender after I was done.
https://www.reddit.com/r/haskellquestions/
As a wingsuit pilot myself, I *had* to play your game. That's fun, thank you. For your information, it builds smoothly on nix/nixos/nixpkgs using the following derivation: ```nix with import &lt;nixpkgs&gt; {}; with haskellPackages; (developPackage { root = ./.; }).overrideAttrs (oldAttrs: { buildInputs = oldAttrs.buildInputs ++ [SDL2_mixer SDL2 freeglut]; }) ``` And a recent checkout of nixpkgs. 
Chris Doran's book is nice.
Yeah you're right, I overlooked that. My bad.
The short answer is that you're using the monad instance for `((-&gt;) a)`, which can result in some weird-looking code. Looking at the instance itself: instance Functor ((-&gt;) a) where fmap f g = \x -&gt; f (g x) instance Monad ((-&gt;) a) where g &gt;&gt;= f = \y -&gt; f (g y) y You can inline the definitions to find out what's going on in your example: (fmap &gt;&gt;= id) -- Inline (&gt;&gt;=) (\y -&gt; fmap (id y) y) -- Inline fmap (\y -&gt; (\x -&gt; (id y) (y x))) -- Inline id (\y -&gt; (\x -&gt; y (y x))) So basically, `(fmap &gt;&gt;= id)` takes a function, and applies it twice to some input. The following function `twice` is equivalent: twice f x = f (f x) Applying that to `(+5)` and `5` we get: (\y -&gt; (\x -&gt; y (y x))) (+5) 5 (\x -&gt; (+5) ((+5) x)) 5 (+5) ((+5) 5) 5 + (5 + 5) 15
Have you seen the [grid](https://hackage.haskell.org/package/grid) package? It's a library for working with grids for things like games—including hexagonal grids. Now that you have the experience of implementing hexagonal grid logic yourself—projects like yours are the best way to learn about something—it's the perfect time to read through Haskell code by somebody else doing the same thing to see other design decisions you could have taken.
No worries. Dust yourself off and try again. 😎
Because I feel in love with fp after learning F#.
You don't use index-state and nothing else. The point is you use it for getting a lock _in combination with proper bounds_.
This looks really interesting! Thanks for the link. I hadn't considered how old the book was, which thinking about it now seems very obvious. Well I will persevere with it as long as I can until the examples break down I guess. Can't hurt. And in the mean time supplement it with some other stuff.
Do you recommend the course?
Excellent!
Hi, I did find another package for hexagonal tiles, that like mine was based on [this excellent guide](https://www.redblobgames.com/grids/hexagons), but had something missing that I needed and to be honest Iiked the idea of re-implement it. :) I don't remember the name right now, but I am sure it wasn't this one. Anyway, thanks for the suggestion, I will have a look at it. Also you are right, I should start reading more haskell source code, I haven't done it a lot. 
Incidentally, at this level of Haskell understanding, I very strongly recommend working out how to expand things as in toBrowsing's blockquotes, and working out by had either in a text editor or on paper the reductions to the final answer. Trust me. I think this is one of the faster ways to develop the intuition for what is happening here.
Just to put some things into context -- this confusion isn't actually about "monads" per se, but about a *specific* single Monad, the `(-&gt;) r` instance :)
Thanks for the tips. Your right, about the performance claims, the results are in the benchmark's comments, I will move the results up to the readme.
I don't know, is that bad? I tried to match some of the support that Linear was providing. I was kind of thinking that Cabal would have Use Flags like Gentoo Linux, where it could bring in support for optional dependencies.
The main books I have experience with are :Electrodynamics: A Modern Geometric Approach" by William E. Baylis. And "Clifford (Geometric) Algebras: With Applications in Physics, Mathematics and Engineering" William E Baylis Editor. I have heard good things about Chris Doran's "Geometric Algebra for Physicists" book too.
Ok, I agree, I didn't realize that this would be a source of confusion. It's definitely just an ADT. How it is defined in the code and the pragma is not really important.
For setting up CI, you may want to have a look at [packcheck](https://github.com/harendra-kumar/packcheck/) to get started if you're unfamiliar with it, once you get the test suite running time down (e.g. Travis times out after 50 min).
It is not. Due to the fact that most end users computers don't have SDL, SDL_mixer or Glut.
Most people's computers don't have glut, SDL or sdl_mixer, so we need those bundled in somehow. 
And docker doesn't help here, since getting all that setup is more effort than just installing SDL and Glut.
Actually Chris Doran gave a talk about implementation of geometric algebra in Haskell last year: http://geometry.mrao.cam.ac.uk/2017/10/geometric-algebra-in-haskell/ And here is his implementation: https://github.com/ga/Haskell May be you can combine efforts?
I was exposed to Haskell at my introductory computer science class which used it as the teaching language. I did pretty well in the course and even got to TA it (which turned out to require only marginally more knowledge than my students) but I dismissed the language itself as impractical and of limited utility compared to my beloved Python. After a short time in industry, though, I kept running into problems that were beyond my nonexistent debugging abilities and that I began to suspect wouldn't happen if I used a language like Haskell. Around this time some people started a Functional Programming Users Group in my city and seemed so happy and excited about Haskell that I wanted to join them. I offered to give a talk and one of the organisers suggested implementing Git in Haskell by following [this part of the Git Book](https://git-scm.com/book/en/v2/Git-Internals-Git-Objects). I learned enough Haskell to give the talk, kept going, and have never regretted this decision!
Wielding your theory, you are prepared to *get rid of your competition by force*. Suppose, in the race for power, you destroy an entreprise lead by a person that was unwilling to step over their ethical principles, justifying it by the end you are about to achieve. But what if your theory is wrong? And you will not achieve anything? You destroyed the work that was better than yours. What for?
Yeah sure. I quite liked our design pattern, and would use it again for a lot of types of game, although if you have a ton of different game objects interacting with each other (items, enemies, allies, obstacles etc. that all interact with each other), then I'd probably end up deciding to put an ECS (entity component system) in the middle of it all. Our general design pattern was basically a tree of state, where each element of the tree is responsible for updating its own state based on events that happen, and each element is also responsible for rendering itself and outputting sound. Each element then also must call the appropriate render / step etc. functions on any of its active children. Lenses were used as a nice clean and composeable way to view and update all the necessary state. I wouldn't say they were deeply embedded into the project in the sense that you could have used vanilla records instead, but they were definitely much more enjoyable to use and I would use them again. [I made a graph of the module dependencies](https://i.imgur.com/R4vMRtE.png) which should give you a somewhat better idea of what's going on. I don't have an automatic graphing tool for the state dependency, so here is a quick hand written nested tree of the key parts (smaller things like `State.sessionId` and images were omitted for brevity, dots represent products and numbers represent sums: * State * Audio * Mode 1. Menu * Current location in the menu tree 2. Game * parallax information * status, e.g start / paused / playing * World * Player * [Acorn] * level information, e.g start / end / obstacles * Hud * PauseMenu Most of these objects also contain things like the images they need to render / locations of things / meta information.
Oh, HCAR didn't make it this week. I computed the release date wrong, next edition will be released a day earlier :)
It did make it in! I forgot to include the edition number, but it’s there in the “in brief” section. 
One thing you should realize is that if I don't get any money from this work I will basically just end up having to ditch the project entirely and work for some big company. So will everyone else on the team. I need money to eat and to live and to get around and to support my hobbies. If I open up the project then it is going to be very hard to get funding as who would fund a company that can be copied. Which again takes us back to the whole "having to quit and join a big company" thing. It's also not good for the world if the project gets copied. Because the project is based around the idea of getting things all in one place. So competitors would just fragment it and make it so that no single group can get the market share to really make the project amazing. In the long run this project fundamentally requires a ton of manpower, and for that it needs a lot of money, and for that it needs to not be easy to compete with. I think you have an incredibly naive and idealistic view of the world, and need to realize that in reality releasing your source code under GPL isn't universally a good idea. 
Thanks! Added to readme. 
Unfortunately, no, as long as some library are dynamically linked, you won't be able to get a standalone executable. Actually, that's not totally true, there is some interesting solutions such as [nix-bundle](https://github.com/matthewbauer/nix-bundle) which can make a standalone executable from any nix derivation, but it does not work well with OpenGL on non nixOS plateform.
I can only point to what I'm sure you already know, the standard bundling approaches for each platform: Mac: Create an app bundle. To do it manually when you need stuff from brew I have found to be a bit tricky, though. You create a minimal app bundle directory structure, then use `otool` and `install_name_tool` to get your brew dylibs to work after being relocated into your app bundle. Or you can be a Real MacOS Developer™ and somehow get it to work as an XCode project, but I've never done that. Or write a brew formula (I know, Ruby, what can you do), polish up your game a bit, and get homebrew to accept it. :) Windows: If you can get your app to build at all on Windows, this is easier than MacOS. Pick your favorite Windows installer tool, get it to throw your exe and all the dlls you need into `C:\Program Files\Wingsuit` and you're good to go. As for getting it to build at all on Windows - well, good luck. You'll at least be happy to know that msys2 uses pacman. 
Here is a link to [Capturing the Future by Replaying the Past](https://arxiv.org/abs/1710.10385)
Pretty much nonexistent I think, but there’s a job going at Tesla if you’re willing to relocate to Cali.
Australia is incredibly strong for Functional Programming. There is a government\-sponsored programming lab that is committed to functional programming: [http://qfpl.io/](http://qfpl.io/) The city of Brisbane was the first in Australia to demand higher standards of software development, and also long before similar started occurring overseas \(e.g. USA\) resulting in a user group of over 800 people: [http://bfpg.org/](http://bfpg.org/) Sydney \(like USA\) with its higher population, got dragged along, and there are now many companies in Sydney taking advantage of the benefits. 
I can see 5 or so companies listed [here](https://github.com/erkmos/haskell-companies) as using Haskell, and I know of a similar number of companies using Scala. There are a few places using Clojure and Elixir, but I haven't been following those languages closely enough to have a sense of how many companies are using them.
Yay my work is on that list, Ansarada. We use a mix of Haskell, ocaml and fsharp with future things being mostly Haskell oriented. 
[Skedulo](https://skedulo.com/) uses Scala to drive our backend, using the the almost-purely-functional [Typelevel ecosystem](https://typelevel.org/projects/). FP has worked really well for us, and we're progressively experimenting with more advanced FP techniques and patterns. disclaimer: I work for Skedulo
http://jobs.qfpl.io/ Here's 5.
Actually that's not right. Until recently I worked at Ambiata in a team of 15 engineers doing Haskell dev. That team has been disbanded, buy Commonwealth Bank has a Haskell team and there are at least two startups using Haskell. I'm currently doing remote work (in Haskell).
Section 3.1 (GHC) doesn't have a blue header - almost skipped it before thinking "that cannot be right".
Eragon tho
See the progress report's comment section, for an update that's only a month old: https://typesandkinds.wordpress.com/2016/07/24/dependent-types-in-haskell-progress-report/#comment-13327
For reasons of idle curiosity: what are your thoughts on Haskell vs. F# and your company's choice to focus on the former?
&gt;There is a government\-sponsored programming lab that is committed to functional programming Interesting. Is this sponsoring under any supervision? Aren't you worried you may lose the sponsoring if somebody pointed out to them how the programming lab is used as a platform for what seems to be a [political agenda against Stack](https://www.reddit.com/r/haskell/comments/8in4dr/bitemyappfpcourse_fork_of_the_original_data61/dyt0hq9/) ?
Hopefully not very important, given I've been writing Haskell for about 6 years with neither!
The comments about Stack are based on our experiences with it and on what we've seen while working with the local functional programming community. I'm confident that we could defend them. I think before it got to that we'd be able to make a strong case that most of the people likely to try to push that point have a history of playing their own political games in this are and should probably be ignored.
Ahaha, missed that comment, thank you!
Heads up, you have two assets directories. This could hurt on a case-insensitive file system like macOS uses by default. I haven’t tried cloning your repo on a Mac yet, but I suspect it would choke somehow or only end up with one of the directories intact.