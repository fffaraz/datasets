http://hackage.haskell.org/package/disjoint-set
I was going to respond but then I recognized that you're ranting. Anyways, I hope that you find the gig that suits you at the pay scale that you think you deserve without the bullshit of colleagues, middle managers, and executives.
Definitely a very noisy index: for June 2014 Haskell is back at position 36.
I'm not into the whole web dev thing, but based on my limited experience with Yesod and Snap, Yesod just doesn't feel right to me. It is lacking composability: it is very Duplo compared to Snap's Lego. Also, I think the comment about its community being weak is spot on. It seems like it's targeted at people who want to get something done quickly without taking the time &amp; effort to get to its bottom. Do you want Ruby on Rails? Because that's how you get Ruby on Rails.
I also was repelled by Yesod when I tried to use it. I've had better luck with other web frameworks. I agree with a lot of your points. The typical Haskell approach to a project is to boil out core abstractions with well-defined semantics. Bonus points if you can provide an equational axiomatisation. I get the impression that Yesod was designed with a very different view. The "abstractions" it uses are much like the "abstractions" you see in OO languages. It's possible to read and write code that uses the abstraction without understanding the implementation, but it's not possible to reason about it without understanding the implementation. This is partly caused by inadequate API documentation, but also poorly thought out abstractions, in my opinion.
It feels like your critique is mostly in the details and not in the overal philosophy of the platform. Discuss this with the authors and give constructive feedback. Or even better, fork and fix it and try to get it merged back into Yesod. &gt; What's the deal with Yesod? It's ok not to like a piece of software, but asking a question like this just feels like you want to start a fight. &gt; Or is it just a vehicle for Michael Snoyman to write a book? Ah, come on. Michael is obviously a very capable (and productive) programmer that has written tons of useful open source software. That's a lot of work if your goal is just to write a book.
union find is notoriously a hard algo to get purely functional performance for with the same asymptotics as the mutable version. the paper cdsmith cites in his package is available here, and you might enjoy it... https://www.lri.fr/~filliatr/ftp/publis/puf-wml07.pdf
Hehe. Very nearly. :)
&gt; It feels like your critique is mostly in the details and not in the overal philosophy of the platform. i think that dismisses one of their points. having used the `authenticate-oauth` i can tell that it is not as typesafe as it ought to be. /u/tel's `oauthenticated` shows what is missing because it's even easier to use with more type safety. yesod is very concerned about backward compatability in the front api so i guess most is just legacy leftovers that might eventually be cleaned up. having said that, i agree with your (svfisser's) post.
most comments (so far) seem pretty negative towards yesod and even personal to its main author. i also don't like yesod as much. but please keep it nice. most people recognize that in the wider yesod ecosystem there are many nice and important packages.
I normally try to avoid commenting on posts like this... but seriously? This is just too easy to refute. &gt; Or is it just a vehicle for Michael Snoyman to write a book? Oh no! My grand master plan has been figured out! I decided to write an entire web framework, dedicated countless hours of my life to helping people understand how to use it, create a bunch of documentation and give it away for free on a website, and continue to maintain it and improve it for years, *just so I could write a book*. Wat? &gt; still no blog system, after years of discussion about it Umm... what? Who's been talking about making a blog system? I think I've been fairly clear that I *don't* think it makes sense to recreate something like Wordpress in Yesod. I can go into the details of that, but this is a truly bizarre comment. &gt; highly, highly opinionated at the core level No one ever said otherwise. If you want something less opinionated, that's why we've made all of our libraries pluggable. Want Shakespeare and Warp, but a different routing system? By all means, go for it! Now, I happen to think that the things Yesod does at the core level are correct, and I'd be happy to have a real discussion about these design choices. But "it's also wrong very often" is no place to start a discussion. &gt; There are a lot of examples like this Can you name three others? &gt; Highly inconsistent and type un-safe interfaces. This is especially scary in the Auth system. A "Creds master" is a text token and list of text key-values. I'll admit that the auth system is one of the weaker points in Yesod... but again, this critique is bizarre. The auth system is about allowing people to plug in arbitrary components without constraints from the system. We threw out type-safe URLs in this implementation too. So yes, it's less strongly typed, and that's for a good reason. If you have a better approach, feel free to recommend it. &gt; Having a "Foundation" module splits your project in two So then don't structure your project that way. The scaffold is a recommended practice, it's not in any way forced on you. &gt; Actually, the whole Import idea is misguided. I end up having to import parts of Prelude constantly, especially on the framework side of the Foundation boundary. Umm... then add them to the export list from `Import`? Or turn of `NoImplicitPrelude`? Or a number of other things. I don't get it. How is the scaffolded structure so problematic that you can't address it? Anyway, there are [precisely six functions](https://github.com/yesodweb/yesod-scaffold/blob/postgres/Import.hs#L5) not reexported from `Prelude`, and I sincerely hope you're not regularly using those six functions. &gt; There are like 5 different ways to load a widget. The pro's and con's are not explained anywhere, including the source code. Then you didn't read the book. Also, I count two ways: `whamlet` and `widgetFile`. I don't know what you're on about here to be honest. &gt; The documentation is actually really really bad. You've picked one example, have a misunderstanding about what the functions are supposed to do, and have extrapolated that all the documentation is really bad. There's no such thing as perfect documentation, and I regularly improve documentation when there's concrete feedback. This is not concrete feedback, this is just kfetching. &gt; If you Google for Yesod function names, Google ends up pointing you toward old versions. Gah! Now Yesod is guilty because Google indexed an old version? Anyway, I've been telling people regularly for some time now to [use Hoogle](https://www.fpcomplete.com/hoogle)... problem solved. &gt; Multitudes of special cases. Why is whamlet a widget quasiquoter, but not julius? Because julius can be used outside of a widget. It's all described in the Shakespeare chapter of the book.
&gt; having used the authenticate-oauth i can tell that it is not as typesafe as it ought to be authenticate-oauth isn't (yet) a product of the core Yesod team. Felipe and I are going to be taking over maintainership soon, but it's not really indicative of what a "Yesod library" would be.
I see these kinds of vague criticisms a lot. Can you make the comments a bit more concrete? Are there abstractions in Snap/Happstack/Scotty that you think are good, that Yesod doesn't have? I'm truly interested. An example of a web framework with a *very* interesting abstraction is MFlow. I'm actively following the work Alberto is doing, and think he's coming up with some cool stuff. But I don't really see "abstractions" like you seem to be describing coming out of the web frameworks themselves.
MFlow is really cool.
&gt; Never mind things like CRUD screens. Shouldn't these be derivable from the Persistent model You want something not opiniated, yet able to generate CRUD screens for you? For the record, even asp.net mvc only provides a "scaffolding" mecanism (meaning : something useful for demo/ greenfield developments). The more features one framework delivers, the more opinionated it should be. 
But my type was `Int??`, i.e., `Optional&lt;Optional&lt;Int&gt;&gt;`. So `nil` could be the outer `Optional` or, with automatic lifting (like `5` gets), it could be the inner `Optional`.
Hi 2pilx, My advice is that you should play around with Yesod, try different approaches to the problem you are trying to solve and improve on them. Don't expect it to be a one shot solution for all your problems. In a real world project you shouldn't be using a framework that you don't know well (this goes for any framework in any language). CRUD screens hide the true complexity of the problems and can break at many corner cases (the ones you are likely to encounter in real life). Try to understand why things are done in a certain way and what are the compromises being taken (there is always a compromise). And here is my (hopefully constructive) take on your points: 1. "still no blog system, after years of discussion about it. Never mind things like CRUD screens. Shouldn't these be derivable from the Persistent model?" -&gt; CRUD screens, while they can help you a lot with the boilerplate, are not the focus of a framework like Yesod. Yesod is a set of libraries/tools that are being developed in order to help Haskell programmers code web related projects with a given set of options already chosen for them. CRUD screens only arguably can fit into the category of "Haskell programming". Also remember: Persistent is not Yesod. 2. "highly, highly opinionated at the core level. This wouldn't be so bad, but it's also wrong very often." -&gt; Yesod, like any good library, takes away the burden of making certain choices so that the programmer can focus on the domain of the problem at hand. Like the best toolsets, Yesod "forces" you into their way of solving things, with their philosophy on what is "best". Did they make the "right" choices ? Maybe for certain use cases, maybe not for certain others. In most cases, when a friend of mine wants to do a web project with Haskell, I recommend using Happstack instead of Yesod because it is easier to get into and their philosophy fits really well in small to medium size projects for the Haskell begginer. And this is the beauty of it all: you can chose between a bunch of web frameworks in Haskell. The case here is to improve your knowledge of the web and Haskell in order to chose the right tool for the right job. 3. "Highly inconsistent and type un-safe interfaces. This is especially scary in the Auth system." -&gt; The Auth system is entirely optional in Yesod. But Yesod clearly distinguishes authentication from authorization, and is permissive enough so that you can easily write your own intrusive auth* stuff, just take a read on the Yesod typeclass: [http://hackage.haskell.org/package/yesod-core-1.2.16/docs/Yesod-Core.html]. I don't know what you are trying to say with "inconsistent", there are a few typeclasses in Core, and you should know them and use them. These are well thought and battle tested in *many* dif. use cases from the community. I don't feel they are inconsistent or unsafe, actually the other way around (only GHC knows how many hours it has saved me). 4. "type safe URLs are over-hyped. Especially for a "RESTful" framework." -&gt; Have you tried to build an Hypermedia API ? Did you ever tried to write an API like the one github has [https://api.github.com/] ? Type-safe URLs are paramount in properly designed RESTful frameworks, and specially now that the world is becoming more and more aware of the importance of semantic information on the web (things like JSON-LD and schema.org are pushing forward) where the URL/URI/IRI/... is the core identifier of information. Try to write your own API with and without type-safe URLs and then compare ;) tl;dr; "The documentation is actually really really bad" -&gt; You can always read the source code, haddock even helps you with that and if you don't understand something then head to the mailing list where the response time is usually very short. You can also write your own tuts or help out with the current state of the documentation. disclaimer: I am not a Yesod developer, just one of the many anonymous users of the framework. I use it for many things in my daily job and in my hobbies. As an outsider I actually enjoy Michael approach to problems, how he communicates and how he seems to be ok in reverting his decisions (specially after dedicating many hours into them). Yesod has evolved a lot thanks to this mindset.
I understand what you are saying, but the GC lacks information about *when to collect garbage* and *where to collect garbage*. Look at the following simple example: handleRequest :: Request -&gt; Response handleRequest req = do res &lt;- handleRequest' req let res' = deepseq res -- GC IS CHEAP HERE return res' where handleRequest' req = do user &lt;- lookupUser req tmp &lt;- calculateLargeIntermediateResult user database -- GC IS EXPENSIVE HERE return $ calculateResult tmp Clearly, tracing the live data represented by tmp during GC is not optimal. The data will be moved into a parent generation by the GC and a few clock cycles later it will be garbage. So there are two things we should be able to tell the GC. First, when is it a good time to do GC. We can do that by calling `performGC`. But the other issue is to be able to give a guarantee to the RTS about which root pointers exist for a given memory region. If we have no pointers into the memory region then we can instruct the GC to reclaim the whole memory region when we exit by copying the result out to the parent region. Most of the type-level support seems to already exist in for example [this package](http://hackage.haskell.org/package/regional-pointers) but integration with the GC is missing so we can't get the performance we want out of it.
The most important thing you need to know about Haskell before you write a rant like this is that we are a cooperative, positive community. There is definitely a place for a good comparison of pros and cons of different web frameworks, but a post in this tone is a bad way to start off. Let's note that Yesod has quite a large following of talented and experienced professional web developers and Haskellers who stand by its excellence. It's surrounded by a significant ecosystem of supporting software and applications, and it's becoming recognized by web developers even outside the Haskell community as an important web framework. Not that there isn't anything that can be improved. But if your main point is "this is just so bad, nothing to see here, move on", which is what it seems to be, that shows that you are not really too familiar with what Yesod is and how it is supposed to be used. One thing to keep in mind about Yesod - the target audience is professional web developers. Very little previous knowledge of Haskell is required to get started, although, of course, the more Haskell you know, the more you can do. Yesod does require significant previous knowledge and experience in web programming, which has become quite a broad field. So people who are already advanced Haskell programmers but have never done much more web development than putting up a simple web site or two are often frustrated with Yesod at first. Perhaps that explains why you felt like writing a rant like this. Yesod is not designed to be a web API in Haskell - that is what WAI and its associated software are for. Yesod is a web *framework* built on top of that. Regarding your specific criticisms, I'll just pick a sampling. For me the strongest points about Yesod are: * The community. The yesodweb email group is active and responsive; reported bugs get fixed almost immediately; the community is helpful and accepting; constructive ideas for improvement are always taken seriously; you can often get instant responses on the #yesod channel (although it is nothing close to #haskell). In short - it's one of the best Haskell subcommunities. * The documentation. The online book and blog posts are excellent. They provide easy-to-find answers to just about any question about web development with Yesod. Keep in mind, though, that they are written from the point of view of a web developer, not a Haskell guru. But the full source code and Haddocks are available if you want to see what is going on behind the scenes. And I do find that googling a Yesod function name almost always takes me to the right place - do you need some help with how to use Google? A few more points: &gt; still no blog system wat? Have you ever visited the Yesod home page? Yesod itself is not blog software, it is a web framework that you can use to build blogs. But still, the [yesodweb blog](https://github.com/yesodweb/yesodweb.com) has been very actively maintained since 2011. If you don't like that blog, you could easily roll your own in an hour or two with only basic knowledge of Yesod. &gt; highly, highly opinionated at the core level Are you mixing up WAI with Yesod? If you want a flexible Haskell API for web development, see WAI. Yesod is a framework - its whole purpose is to provide a convenient pre-built structure for your web app. &gt; Having a "Foundation" module splits your project in two This is not true if you structure your Yesod app properly. I think you may have misunderstood what the `Foundation` is for. Please re-read the "Foundation" section in the [Yesod book](http://www.yesodweb.com/book/basics). &gt; There are like 5 different ways to load a widget. The pro's and con's are not explained anywhere, including the source code. There is a whole [chapter in the Yesod book](http://www.yesodweb.com/book/widgets) which explains all of that quite clearly. &gt; Type safe URLs just aren't useful when your hrefs are dynamically generated by JavaScript. You should not be generating URLs in JavaScript using string hacks; that is bad technique in any web framework. Even in JavaScript, you should build hrefs from type safe URLs passed in to a Julius template. But yes, JavaScript is seriously lacking in type safety. That is why many people generate their JavaScript from a higher-level language such as Fay.
Wow, really? I have yet to see "industry" code but I always felt that academic code is extremely ugly compared to most of the open source code that I saw. My impression was that it's generally more important to produce a nice looking paper. The people I had to deal with almost were kind of condescending towards implementations because "it's not the real work" and doesn't count. That's what drove me away from academia and is still my source of disrespect for it.
&gt; Don't bother to try to understand it, While this guide explains what the solution is (SYB), I think [my guide](http://chrisdone.com/posts/data-typeable) explains more on how to understand how SYB works and can be used.
&gt; The problem &gt; &gt; Haskell's statically typed data structures make it hard to write code that works against many data types. I rather disagree with that premise.
&gt; As an outsider I actually enjoy Michael approach to problems, how he communicates and how he seems to be ok in reverting his decisions (specially after dedicating many hours into them). +1
+1 for MFlow and also Workflow. It would be great to see some of that work make it into Yesod! (In a similar vein,Gabriel's Model-View-Controller stuff also looks really interesting) 
A few days ago, I actually got an immediate response on #yesod to an urgent problem I encountered. It wasn't a Yesod core dev. But there are a lot of people using Yesod nowadays :). It's definitely not #haskell, but it's worth a try.
Good to hear, thanks!
MFlow brings back some of the ideas of WASH. That's something I've hoping to see for a long time.
The "modern" way to do this (given you have access to up-to-date compilers) is to use GHC.Generics, which give you back full type safety.
Off-topic, but you might be interested in knowing that these [angle quotes are not part of English typography](http://en.wikipedia.org/wiki/%E2%80%BA#Uses)!
&gt; As is usually the case in the Haskell ecosystem, the answer is that there are about five different packages providing this functionality. The Zen of Haskell: There should be five-- and preferably only five --obvious ways to do it. 1. by creating a custom combinator library (usually a monad transformer) 2. by using an obscure ghc extension 3. by exploiting laziness somehow 4. by abusing unsafe functions 5. by calculating the answer via category theory
Please write a tutorial on it!
Nice project. And a nice description of how the technology side of the project evolved and reached its successful conclusion.
I think there's a lot of variance in both academia and industry code, but generally industry code is of higher quality from a *software engineering* point of view. Industry code solves a problem for money, and therefore there is an emphasis on robustness, modularity, and consistency. This means version control, code reviews, testing, idiomatic style, etc. By comparison, academic code is primarily throwaway code focused on producing results for a paper. In non-CS fields, code is often written by scientists who see computers as another tool and don't care about best practices. This results in situations where internal libraries are a mess of spaghetti code that is distributed via copy / paste.
&gt; Umm... what? Who's been talking about making a blog system? I think I've been fairly clear that I don't think it makes sense to recreate something like Wordpress in Yesod. I can go into the details of that, but this is a truly bizarre comment. I plan to write one in the near future. Why doesn't it make sense?
Possible alternatives?
Maybe "doesn't make sense" is too harsh. Let me copy-and-paste an answer I gave via email a few months back: &gt; To be honest, I'm not sure if there would be a huge amount of interest from the outside world in something like this. From my experience in speaking with Wordpress and Joomla users, they tend to not understand the security and performance implications of using a poorly designed tech stack. For them, the selling point is that there is simply a huge volume of existing templates and add-ons, and plenty of people willing to work very cheaply to get things done. &gt; That's not to tell you that I think the project would be a waste, but I do think it's important to understand the world you'd be competing against. Code quality is something which, to a non-developer, is intangible, and therefore difficult to make as a selling point. To clarify what I mean a bit further: I'd *love* to see a blog or CMS kind of platform built on top of Yesod. It would be really interesting, and would force us to add features to Yesod in a new direction we haven't approached previously. I'm just not sure who'd use it.
Very true, but there are systems that are more robust than others. For example, the 18th century Enlightenment was when people stopped believing in the "meritocracy" (often justified on religious grounds) of their political leadership and began to build more robust systems of government. We now *have* a limited government in the developed world, and that's a really good thing. Unfortunately, the power vacuum it creates allows the elite of the private sector to get away with too much bullshit. That problem has yet to be decisively solved. 
Much of it can also be done with lens (and it's easier to use than GHC.Generics IMO), with better performance than syb.
To expand on this, the solution to this is parametric polymorphism (a.k.a. "generics") and ad-hoc polymorphic (i.e. "type classes") (which I like to think of as a special case of parametric polymorphism using the dictionary translation). A really simple example of this is Haskell's `length` function: length :: [a] -&gt; Int Lowercase type names like `a` in the type signature will type-check as any type, meaning that our `length` function works on lists that hold any element type. However, where things start to get neat is that you can make code polymorphic in the container type, or even polymorphic in things that have nothing to do with containers. This lets you reuse the exact same code across multiple types.
There's mutation under the hood, but they claim observational persistence (though not threadsafety). Also the bounds only match up with imperative union find in the no backtracking case...
&gt;“this is just a monoid and a bunch of crap because I didn't realise this is a monoid” Echoing what was mentioned in the comments, I would like to see an actual example of this (anyone can feel free to provide one). I've been doing OO programming for over 15 years, FP for probably the last 2 or so. I feel like I grasp Monads and so on well enough but no concrete examples spring to mind for this example.
I disagree strongly with this. Most industry code I've seen has been made under extreme time constraints and is resilient purely by brute force (i.e. hard code in what ever is needed to get past the current emergency and never look back).
It's a vehicle for M. Snoyman's valuable time and material and he's giving it away all for free with source (batteries included). There are lots of productive options one can do if one finds free software that's distasteful: * fork and fix * find alternatives * start a better project * start a discussion with M. Snoyman and suggest ways to fix the distasteful bits * etc. Unfortunately, you decided to throw a tantrum on a public forum. Get off of that supermarket floor. You're being a nuisance and only getting in the way. 
Are you going to support linux?
Currently `hmidi`, which I'm using as the MIDI backend for `Bang`, isn't supported on Linux. I'd love to support Linux, but I'm not sure it would be possible without some significant changes to the code. I might make an attempt to get it building and working on Linux eventually, but it's not my top priority. If this is a feature that many people want, I'd be happy to try (and even happier to let someone else try), though!
The problem isn't having opinions. It's having no way to fix them when they go "wrong". Do you really want to fork a huge library with constantly changing internals and string typing at critical junctions every time a "default" doesn't suit your needs? 
Very cool!
&gt; So people who are already advanced Haskell programmers but have never done much more web development than putting up a simple web site or two are often frustrated with Yesod at first. With some effort, it's even possible to learn web-programming via Yesod. At [BayHac2014](http://www.haskell.org/haskellwiki/BayHac2014), I gave a lightening talk on my experience. The help I received from Michael Snoyman and others on the Yesod mailing list was invaluable.
 do izbicki.me mind &lt;- blown return mind 
&gt; Type safe URLs just aren't useful when your hrefs are dynamically generated by JavaScript. Don't do that then. Don't generate basic HTML with JS! WTF (not to be rude, just keeping with the tone of the post, but seriously, that sort of thing breaks the foundation of the web. HTML is not supposed to *rely* on JS, as far as I understand.)
What I've been told is that GHC.Generics is simpler and more typesafe, but often significantly slower.
If you're hearing them a lot, perhaps you should listen. Or even listen to specific criticisms people have helpfully compiled for you. You say I pointed out a "single example" of bad documentation. But there are literally hundreds in there. I am not trying to be hurtful -- you've made a great project. But you have blinders on. It's worse that your interpersonal skills are lacking, and are condescending to people with valid complaints.
Don't bother, I know the pain. I'm gonna buy a Mac to use it.
I plan to use Yesod for a blog sorta kinda (really a more static site with articles with something like a blog). I really don't want to see bloat into a crazy CMS that is over-the-top but some quick pop-in clean blog stuff would be nice. I like ghost.org on first impression in terms of cleanliness, but not in terms of reliance on JavaScript. I want a site that works with NoScript. EDIT: I might just use the blog example from Yesodweb… why not? That's a Yesod Blog already and works pretty well!
Pardon me, but how is my list of complaints a "tantrum"? Forking yet another Yesod package might just be my best choice now. It is truly unfortunate that I have to fork a core package. That none of the yesod-* packages that rely on yesod-auth will work if I do that. That I'll have to fork those too.
Haha, seriously?
Yeah, I tried to set up a midi environment on raspberrypi for my music project.
Ooooh! This makes my heart go ```bd &lt;&gt; sn &lt;&gt; bd &lt;&gt; sn &lt;&gt; bd &lt;&gt; sn```.
http://ocharles.org.uk/blog/posts/2014-04-26-constructing-generically.html is one, and there are a bunch of Magalh~aes/Löh papers on generics (starting 2010).
Well, by definition an opinion cannot be wrong. It may be different from yours. As to making a framework in which you can correct every opinion you disagree with, it is impossible. Using WAI provides you less features and less opinion. Using Network: still less opinions &amp; features. Using assembly: even less opinion, but you still have to deal with the possibly bad CPU architecture choices. Some people have a precise idea of what a web framework should be like. If they are not satisfied with the current ones, they go one making their own (creation is the best form of critique as people say). Other people more focused on producing a client facing product might want to accept the issues with the existing frameworks in order to spend more time on other problems. I can understand why some people don't like the quasiquoters + many DSL used by yesod. I only use it to write web api, so I am not dealing with hamlet &amp; other client DSL. But a lot of parts can be used separatly from a yesod foundation (persistant, hamlet, conduit), so you are free to pick what you like. yesod is just an umbrella project with many different parts designed to be able to work separately, but which work well together. That in itself is really hard to design. Some other haskell frameworks like snap also achieved this level of separation of concern. I attribute this to the language focus on purity, and the general quality of the library designer involved in those projects. 
Hello, just discovered this thread. Thanks for all your nice words! I also hope that you have some patience with the less stable parts of the Suite, I am still learning how to develop and maintain a library of this scale. I am aware of most of the issues mentioned here and am happy to see that you have been able to find workarounds – the Suite is just a little over a year old and (as I wrote in the announcement) there is definitely much to improve. I would like to ask you all to *please* report all problems you might have on https://github.com/music-suite (if you are not sure in which repo, just put them in music-suite), this feedback really helps. If you want to discuss something that is not a bug, or contribute to the Suite yourself, please write to https://groups.google.com/d/forum/music-suite-discuss. Thanks! /Hans
I'm sorry, I was certainly frustrated at my options last night. And it came across in my "tone". But let me say this: the book is not documentation. The book walks you through using the scaffolded site. And that's great. But it is a prolonged tutorial. Not a guide to the API or its design. The other book chapter (in the compilation about Haskell projects) covers topics like WAI and Warp. Also cool, but not helpful to somebody who needs to figure out how to get the framework to do what he needs. And the reason I say the community is not so hot is that I have tried to bring these issues to the community before, and been rebuffed. I have explicitly mentioned other failings in the documentation, and told that I'm "wrong" (the implication being that I can't read, apparently) I have issued bug reports and they have been closed with condescending notes. &gt; This is not true if you structure your Yesod app properly. I think you may have misunderstood what the Foundation is for. Please re-read the "Foundation" section in the Yesod book. I understand that it is the "foundation"/bottom/yesod of your application. Sometimes you want to write "framework code" without splitting it off into another package -- perhaps because it isn't generic enough for **all** Yesod sites, but is generic enough for multiple parts of yours. To do stuff like that, you basically need to put the generic frameworky code on the framework side of the Foundation. Sometimes you only realize this when you end up with cyclical imports. So you spin it off into a module, and find that the module won't compile because the Import file is meant for imports on the application side of Foundation. Yes, this is a minor inconvenience. But it is surprisingly time consuming. &gt; Are you mixing up WAI with Yesod? If you want a flexible Haskell API for web development, see WAI. Yesod is a framework - its whole purpose is to provide a convenient pre-built structure for your web app. No, I'm very much not mixing up WAI and Yesod. I understand that Yesod is a framework. And of course I understand that a framework makes choices. Some of those choices (with respect to default behavior and the like) do not suit my needs. Unfortunately, those choices can't be corrected at my end without forking a large framework with quickly changing internals, and a lack of type safety at critical junctions. This does not sound like an appealing solution. Here is how I design an opinionated library (a scheme, at least): module Yesod.Foo where class YesodFoo master where type YesodFooToken :: * type YesodFooRequest :: * fooWorkflow :: YesodFooRequest master -&gt; HandlerT master IO () fooWorkflow = defaultFooWorkflow -- does a few things; effectively designs an algorithm in terms of other YesodFoo methods (namely, bar) bar :: HandlerT master IO () bar = defaultBar defaultFooWorkflow = undefined defaultBar = undefined Look at what this gives us as an architecture. The framework has made choices. We have a default workflow that works with the default implementations for the class methods. We can override the choice if we need to. I don't think it is controversial to say that this is a very common pattern in the framework. The problem is, there aren't enough changeable defaults. Methods that ought to be in the class, because their behavior could very sensibly vary between sites/apps, are not in the class. And that means you have to fork critical pieces whose assumptions have been subsumed by other libraries. So you end up forking the other libraries too. Or rolling your own. I thought the purpose of a framework was code reuse -- **not** having everybody roll their own. &gt; There is a whole chapter in the Yesod book which explains all of that quite clearly. The scaffolded site's defaultLayout uses like three different methods itself. Some of them are not explained by the book. Why is the scaffolded site using those if they're not different somehow? Do they serve a need? On what basis do I pick between them?
It looks frozen. But I hadn't seen it before, so I thought I'd share it here. Interesting stuff.
In any case, I think the OO-type abstractions kamatsu was describing is how you use type classes. (I do not have a problem with the pattern. I wish you took it farther) See http://www.reddit.com/r/haskell/comments/27rlyh/whats_the_deal_with_yesod/ci3xgub
That's because he moved on to [blip](https://github.com/bjpop/blip)
In that case, we're really just using different terminology. I think using Yesod to write a blog makes perfect sense (I've done that myself multiple times). When I hear about a "blog system," I think of something like Wordpress: a plugin-based system that allows lots of customization through add-ons and configuration files. That *could* be done in Yesod, but that's where my comments above come into play. So please don't let my initial comments scare you away from using Yesod for a blog, I think that's perfectly reasonable.
&gt;I'm just not sure who'd use it. You might be surprised. I would love to be a Joomla/whatever customer because I like the feature set they theoretically offer but I can't because of the issues you mention and many more besides. Since an sensibly implemented equivalent doesn't really exist [1] my options are to do without or write my own. Full time employment doesn't really play well with the latter so I'm stuck with the former. [1] Django actually looks very, very close to the kind of tech stack I would want (including separating admin function from the normal tech stack so I can make a sensible SELinux profile for it) but I'd much rather invest in a type safe language if I can.
I'm certainly not above admitting that I could be wrong on this. If there's enough drive to get something like this written, I hope it gets off the ground. I'll definitely be happy to give pointers on getting it done or add features to Yesod itself. This likely just needs someone to take the ball on it.
Why are mailing lists still so popular with so many open source projects? I hate signing up to them, having to set up my local client to push all that stuff to its own folder, etc., etc., etc. I'd much rather be reading some forum or something (which I would be fine to sign up to for commenting, just don't spam my email).
Thanks for the reply. I intended to start it over the last 1-2 years but things got in my way before doing that. Now I have some more free time (and more experience) so I might start.
Lenses have nothing to do with imperativity. "Setting" just means returning a modified version of the argument: that is, `set _1 3 (1,2)`(I'm making up the syntax) returns `(3,2)`. What have you been reading about lenses?
&gt; &gt; There are a lot of examples like this &gt; Can you name three others? I sure can! Passing around bytestrings all over the place, instead of newtypes. Passing around Text all over the place, instead of newtypes. Passing Json Values around all over the place, instead of newtypes. &gt; &gt; highly, highly opinionated at the core level &gt; No one ever said otherwise. If you want something less opinionated, that's why we've made all of our libraries pluggable. Want Shakespeare and Warp, but a different routing system? By all means, go for it! Now, I happen to think that the things Yesod does at the core level are correct, and I'd be happy to have a real discussion about these design choices. But "it's also wrong very often" is no place to start a discussion. You shouldn't take that personally. Every framework is opinionated. And every framework is wrong very often, merely because it doesn't fit your needs. So how hard is it to fix a "wrong opinion"? With yesod, it entails forking a complex library with stringly-typed boundaries and no clear statement of what assumptions library users can make. That is to say, **HARD**.
Thank you! It appears I've also missed the previous episode. Double the fun!
I agree with Snoyman that exceptions is the way to go. If I understand correctly, monad-control is useful for 'lifting' functions with IO in the negative position, like many in the async package. So we will still need it. However, if most libraries were written more polymorphically using exceptions, this would alleviate this use case AFAICT
There should be six-- and preferably only six --obvious ways to do it. ... Say Generics, I dare you, I double dare you.
I think that's a bit harsh. I've seen plenty of stuff from Michael that seems completely in good faith and often way-over-the-top helpful. In this case, he's walked into a thread where he's being attacked on multiple fronts. It's not surprising if his patience is running a bit thin (though I thought his response in this thread was particularly mild considering it's in response to a post claiming work he's probably invested more hours in than Justin Bieber has even been alive hasn't had much thought put into it).
My guess is that he was referring to /u/tekmo's [Program imperatively using Haskell lenses](http://www.haskellforall.com/2013/05/program-imperatively-using-haskell.html)?
Yea, IRC is an even bigger hassle for me. But a dedicated forum, where I can set up mail alerts if I care to gives me everything I want without the spam involved in a mailing list (keeping in mind that I won't be interested in 90% of the traffic of any medium but for a mailing list I'll still be storing it all). Google group is an acceptable compromise though. 
This cuts out a lot when Chris Done is talking, due to network loss... pretty hard to listen to.
Are you watching the video or listening to the audio?
This is really awesome, I can't wait to dig into their source and read the paper.
The video. ~~Is the audio not like that?~~ The audio-only version is fine.
We're hoping to get the final paper out some time today. That and the 'official' blog post should be up shortly. 
What’s the application? I’m one of the engineers who worked on this, and I’m excited to see how people might use Haxl outside the Facebook context.
Would it be possible to share the total write throughput and the cluster size. If you cannot share that number, would it be possible to share some measure of throughput / osd (or node). I am interested in knowing any measure of write and read performance so that I can understand how it will behave in my production cluster. 
I'm having a bit of trouble determining from the documentation whether Haxl supports write operations occurring as part of data access. I recall from the earlier talk that it wasn't supported at the time. I'm wondering if something along these lines would be feasible: data User = User { userId :: Id User, accountEnabled :: Bool } users &lt;- getSpammyUsers -- invariant: accountEnabled is true for all users returned here mapM_ disableAccount users getUsers $ map userId users Could getUsers return the users without requerying &amp; just have intelligently set accountEnabled to False for all of the users that disableAccount was performed on? 
Support for writes is something we need to flesh out later. As it stands, you can do writes, but they'll be batched along with the reads so it's not a great idea to mix reads and writes that might conflict. We stick to either read-only or write-only workloads within a single runHaxl. 
Thanks for the heads-up!
The discussion around 50:00 about using streaming libraries for shell scripting was interesting. I think this is an area that holds great promise. There already are a number of packages that use streaming libraries for interfacing with external processes, like [process-conduit](http://hackage.haskell.org/package/process-conduit), [io-streams](http://hackage.haskell.org/package/io-streams-1.1.4.6/docs/System-IO-Streams-Process.html) and my own pipes-based attempt, [process-streaming](http://hackage.haskell.org/package/process-streaming).
I work at [Silk](http://silk.co), and our backend is made up of several different kinds of services with REST APIs, as well as a postgres database, memcached, etc. Our client uses our API ('single page app') but to render the initial page (for quick startup, but also for Google indexing) we need to do a lot of different calls. We've parallelized this now, but we left out a few calls because of data dependencies on the first calls, and we included a few that might not be needed in all cases. One of the tricky things is that we have to integrate this in [heist](http://hackage.haskell.org/package/heist) templating, which means execution is driven by template evaluation, and parts are precompiled. So it will require some research on our part, but it seems like it could be a good fit.
I love it! Thanks for sharing!
Nice! I was surprised to hear Chris say during the discussion of JavaScript options that Haste does a Fay/UHC-style FFI, but GHCJS requires wrappers. In fact, isn't it the opposite? In GHCJS I can use `foreign import javascript` to write inline JavaScript with formatting parameters, as in foreign import javascript unsafe "$1.onclick(function() { alert($2); });" js_alertOnClick :: JSRef Element -&gt; JSString -&gt; IO () Haste only offers `foreign import ccall`. Its `ffi` function, from my understanding, actually dynamically builds and evals the string at runtime. Did I get that wrong about Haste? In any case, the statement about the FFI in GHCJS is not correct.
Certainly sounds like a good candidate, do let us know how your research goes. Pull requests are very welcome :)
What is your use case ? why the rant ? what kind of project did you try to do with yesod that went so bad ? why all the unconstructive hate ? can we try to build something together ? or are you really not at it ? can we look at some code and try to help in a more concrete scenario ? I have done a lot of projects with Yesod that do auth* without even working with yesod-auth (and i have also done a lot of projects that use yesod-auth, one of them centered on it). What is it that you are trying to actually do ? Please be concrete about it otherwise people might judge you as a troll and your point might be lost.
:( don't you have an unedited, uncut audio master track you can use as overlay?
&gt; Build something with haskell (the most obscure and hard to learn language today) while being paid pennies. Make sure entire business of company is tied to your product. Spend at least a year quietly building a critical mass. Then BAM, resignation letter on the table. Within a day you will be paid TWICE as much as you were getting just to agree to stay. And no, they won't find any replacement for you. Aha, that's why they don't let us use Haskell in the first place! That awkward moment when you realize that your boss is not just richer and better looking, but also smarter than you =/
Here's the ICFP'14 paper about Haxl: http://community.haskell.org/~simonmar/papers/haxl-icfp14.pdf
Would it be possible to have a monad transformer version of Haxl?
Awesome work to everyone involved, this is going to be a killer library - especially once an ecosystem around it evolves. I'm very impressed with the example of building up a blog post out of modular components, but only paying for queries once - regardless of how many times the same data is asked for.
I wondered about that but `trim` is only used when munging the data, a process which completes almost immediately (although it could only *appear* to complete immediately, due to laziness...?). It certainly might be able to be tightened up. I tried to compile with profiling but attoparsec wasn't compiled with it and it yelled at me... sigh.
I am interested in seeing (or in future researching myself) if Haxl can be extended for streaming data. Imagine big data application, where user writes a SQL-like statement over multiple data sources and the system should plan the execution, deduplicate sources, eliminate common subexpressions, etc. and then execute it while streaming data from sources to a sink (since we can't store all of the data in memory). That would be exciting to see.
 In a previous life I worked on an ADA compiler. Like Swift, ADA was intended to make it easy to write reliable, fast, and readable programs. I don't remember any other language with inout formal parameters. I agree on range types; properly implemented range types would eliminate array bounds checking overhead.
There's an old piece of Haskell advice something like "make a record value instead of a typeclass instance unless there are typeclass laws." The tagless approach seems to disregard that advice.
I would be suprised if you are getting any memoization with classify currently: classify :: [LabelPixel] -&gt; [Int] -&gt; Int classify training !pixels = _label mini where dist !x !y = foldl' (\s (a, b) -&gt; s + (a - b)^(2::Int)) 0 $ zip x y comp !p1 !p2 = dist (_pixels p1) pixels `compare` dist (_pixels p2) pixels mini = minimumBy comp training So if you have `[a,b,c]` where `a &lt; b &lt; c` with you comp function then `comp a b`, `comp a c` are both called where each time you are traversing the `_pixels` list of a twice. It seems like you would be better off calculating `dist` for everything then finding the minimum. Some one else who does these type of calculations more often then I can fill in better advise. If I was in your position I would either optimize step by step as a learning process or look at existing implementations to see how experts write similar algorithms. It is fairly common technique to write a program as obviously correct as possible and then optimize from there where each step is obviously a correct transformation. Then at the end of the process you should have an optimize version which hopefully is correct and can be [QuickCheck](http://hackage.haskell.org/package/QuickCheck) tested against the obviously correct version.
Its probably mentioned somewhere, but I would like to know more about how the cacheing works. I see there are two caches, memo and cache, why two? Is it an opt-in thing? Is there an example of the cache features in use?
I had it go from 83s to 23s just by switching to Vector and hoping the fusion rules would fire : http://lpaste.net/105409
Consider posting to codereview.stackexchange.com. The interface they provide is considerably better then reddit most of the time for these types of questions. The question and answers are license under [by-sa-3.0](http://creativecommons.org/licenses/by-sa/3.0/). http://codereview.stackexchange.com/questions/tagged/haskell
Lists are just that much slower than unboxed arrays. Switching to Data.Vector.Unboxed dropped the time from 84 seconds to 8.6. That's a matter of `import qualified Data.Vector.Unboxed as V`, replacing `[Int]` with `(V.Vector Int)` everywhere, switching to `V.foldl'` and `V.zip` in `dist`, and putting a call to `V.fromList` around parsing the pixel list. Performance is equivalent (faster if anything) with dist written nicely like dist !x !y = V.sum . V.map (^2) $ V.zipWith (-) x y `minimumBy comp` recomputes both distances for every comparison, doubling the work. Fixing that after moving to vector cuts the time in half, to 4.3 seconds.
Awesome. Yes, I plan on doing that. Since it is trivial to generate text from Q in TH. Thanks for the advice!
Alright, I'll definitely have to take a better look at lmqq! Thanks a bunch!
What is a good intro to using unboxed? I vaguely understand the concept but have treated it as "an implementation detail I can avoid dealing with". 
Have you thought about live-coding? Do you think it's practical with Haskell?
Definitely read about the technique before you assume that advice is relevant here. The type class approach has extensibility benefits at a minimum.
[Tidal](http://yaxu.org/tidal/) aims to do just that -- I think it's demonstrably practical, but I haven't given it any focus with this library simply because I'm not sure how it'd work. Tidal requires (or at least suggests) a specialized emacs configuration to hot-swap the code that is currently "playing" in order to enable live-coding. Bang is kept simple, which I think is good, but if there's a simple way to continue to allow users to use whatever editor they want while enabling live coding, I'd love to support that. 
I'm glad that Functional Geekery finally got a Haskell guest. Very much looking forward to this episode!
I wonder if you'd be able to make a simple metronome that you could bind instruments within ghci. I'm not terrible familiar with what type of *persistent* IO ghci is capable.
Since it uses unboxed vectors, your improved implementation http://lpaste.net/105413 is twice as fast with `-fllvm`; I expect this is what `skew` intended, but the time you mentioned made me wonder if you were using it: $ ghc -O2 attempt0.hs $ time ./attempt0 Percentage correct: 94.39999999999999 real 0m10.816s $ ghc -O2 attempt0.hs -fllvm $ time ./attempt0 Percentage correct: 94.39999999999999 real 0m4.853s (The earlier version is not appreciably improved.)
&gt; hmidi According to the hmidi hackage page: "See also the alsa-midi library for similar function under Linux. Please note that there was no effort made (yet) to be compatible with the other existing Haskell MIDI libraries. " So someone just* needs to make bindings similar to those made for windows but using alsa-midi? *I say just, but I realize this could be a huge task.
Thanks for posting. As LambdaBoy has mentioned I've moved my focus to blip, which is a bytecode compiler (and interpreter) for Python, compatible with CPython bytecode. I recently did a talk about berp and blip at the Melbourne Haskell Users Group. Here are the [slides](http://www.berniepope.id.au/docs/ImplementPythonInHaskell.pdf). I'll be doing a similar talk at the Melbourne Python Users Group in July.
I have a couple more that are on my list to reach out to in the near-ish future as well. I haven't done a whole lot with Haskell yet, and am just scratching the surface of it, so hopefully as I learn more about the language and ecosystem from learning Haskell, I will be able to cover it better.
I'm not sure if the Anchor guys follow Reddit regularly. You might ping @afcowie on twitter, or post a comment on their blog post.
Yeah I'm planning to teach my daughter programming starting with Haskell when she gets old enough.
There are a couple of comments about GHC.Generics and about one about the lens package, so here's an implementation of the blog's `getVars` function using GHC.Generics and lenses. http://lpaste.net/105426 While this version is more verbose than the SYB approach it also is more robust to changes. The program is explicit about what should be done at each type (however some of the instances use the default behavior of visiting all of the children) and which types should be supported. In any case, I'm just sharing rather than advocating.
Well, they might not have done as well in the coursework but it may also be that they were gaining a deeper insight in the end because they had a better model of what the Haskell compiler/compiled code was actually doing. Sometimes, having a deeper understanding can slow you down, especially given how school testing works. With something as high-level as Haskell, the concern is surely that you would have no low-level mental model at all, no idea of how the machine works on a hardware level etc..
The dataset from the [original competition](https://www.kaggle.com/c/digit-recognizer) can be found under the first link (need to register though), or alternatively [here](http://131.159.24.176/knn/) (for convenience ;-)).
thanks! I need to fix that.
Not at all. Imperative programming is basically "place oriented" programming (an abstraction over Turing Machines) while functional programming is "value oriented" programming (an abstraction over the Lambda Calculus). Lenses are still pure in Haskell.
Every call to `dataFetch` automatically uses the cache. You can optionally memoize things using `cachedComputation`. We *could* use the same cache for both of these in the implementation (indeed we did at one stage) but the reason they're now separate is that `dumpCacheAsHaskell` only dumps cached data fetches, and not memoized things. This is because it's the behaviour you want for "replay" testing - re-running the computation against cached data instead of going to the remote data.
Does the [State monad](http://brandon.si/code/the-state-monad-a-tutorial-for-the-confused/), which let you write (seemingly) imperative algorithms in pure code, undermine the whole notion of functional programming?
I really love the new Worksheets! http://jpmoresmau.blogspot.nl/2014/01/haskell-worksheet-in-eclipsefp-26.html
I like the Matrix quote in the title :) EDIT: a very well explained and easy-to-read paper 
You can get an easy almost 2x improvement by parallelizing the filter when you calculate numCorrect. Here's the modified code: https://gist.github.com/djv/3a31dcc044223213c3f1. It's using the vector-strategies package. $ ghc -O2 run.hs -fllvm -threaded $ time ./run +RTS -N1 Percentage correct: 94.39999999999999 ./run +RTS -N1 5.28s user 0.06s system 99% cpu 5.337 total $ time ./run +RTS -N8 Percentage correct: 94.39999999999999 ./run +RTS -N8 12.33s user 1.42s system 556% cpu 2.470 total
The difference between a boxed and boxed array is that the first is equivalent to int *arr[]; and the latter is equivalent to int arr[]; in C. So one is an array of pointers to ints, and other is a contiguous chunk of memory filled with ints. There's even more overhead in Haskell for boxed arrays because of the possibility that every int pointer could be a thunk that needs evaluating which adds an additional check for the status of evaluation of each boxed int. And for completeness, [Int] is equivalent to struct list_t { Int * head; list_t * tail; } Except that again each of those pointers might point to an unevaluated thunk so you end up with a lot of pointer chasing and thunk status checking. 
&gt; The difference between a boxed and UNboxed You forgot an "un-" there. Another explanation is here: http://www.haskell.org/haskellwiki/Arrays#Unboxed_arrays So, boxed arrays have much more overhead, but they can be used in lazy evaluation tricks for computing only the elements you need while unboxed array cannot.
I've been keenly anticipating this. Thanks so much JP!
While that has worked for me in the past, it didn't work for me this time (linking error, huh?). I've also heard people say that it's a bad idea because the maintainer of the brew formula doesn't watch Haskell development and doesn't respond to incidents like i.e. the Xcode 5 incident.
7.8.2 r6 merged in. brew cask update brew cask install ghc :)
Fill up your github! Personally, if I've got a couple of medium sized projects publicly viewable in a language, I feel comfortable putting that on my resume because I've got proof. Also, try to give a talk on some aspect of the language locally. I usually waver between poles on the value of github as a public portfolio, but for demonstrating competency in a new-to-you stack, it's hard to beat.
The order of the entries doesn't matter at all. Variance and the jackknife metric can be calculated very simply using just the sum and sum-of-squares of the data. square :: Num a =&gt; a -&gt; a square x = x * x var :: Fractional a =&gt; [a] -&gt; a var = aux 0 0 0 where aux n ssq s [] = ssq / n - square (s/n) aux n ssq s (x:xs) = aux (n+1) (ssq + square x) (s + x) xs jackknife :: Fractional a =&gt; [a] -&gt; a jackknife = aux 0 0 0 where aux n ssq s [] = (((n-1)*ssq/(n-1)) - ((n - 2)*square s + ssq)/square (n-1))/n aux n ssq s (x:xs) = aux (n+1) (ssq + square x) (s + x) xs 
Looks really nice!
Likewise! The gap since the last one had me a little worried, so it's great to see another episode. I can't wait to listen to it :-).
Liberal access memory? Honestly if you are learning haskell (like almost everyone using it ...) I would recommend to forget about your eclipse prejudices and give it a try.
After some extra checks, it's not haproxy, it's clever cloud monitoring system. I'm working on catching the exception to clean up the logs a bit.
I didn't try `-fllvm`, but I did fix comp. Actually, without `-fllvm` it's a touch faster (~4.1s vs 4.6s) to leave the training set as `[LabelPixel]` rather than moving them to (boxed) `Data.Vector`. Interestingly, that reversed with `-fllvm` (only 3.6s rather than 2.7s). Incidentally, the parsing is a bit cleaner but a few seconds slower with `cassava`, so I just left what you had. Here's a simple (not necessarily fastest) way to avoid double comparisons: mini = training V.! (V.minIndex $ V.map (\t -&gt; dist (_pixels t) pixels) training) It seems GHC doesn't recompile files if you just add or remove `-fllvm`, so you may need to delete `.o` files (or make copies of your `.hs` files) to properly compare. Overall, it's down to about 2.7s from the original 85, without doing anything too ugly. If you want to go farther, I'd look into `repa` - you should be able to represent the whole training set as a single `n` by `28^2` array rather than an array of pointers to arrays of `28^2` elements, and `repa` can also do some automatic parallelization.
Not sure if serious... This subreddit has over 16 thousand subscribers. 
Hmm, sounds like it could be possible. I'll look into it, thanks for your suggestion!
More! O_O
&gt; Merging transformer layers... &gt; &gt; The drawbacks of this approach are: &gt; &gt; 1. It is relatively boilerplate-heavy... &gt; &gt; 2. Since monad transformers don’t commute in general, you can’t always merge two StateT layers together... And also: 3 . You might need different combinations of state in your different monads. Well, the `HasInt` and `HasBool` approach partially addresses that - you define a separate monolithic state type for each monad, containing just the specific types of state you need for that monad. And make each state type an instance of only the `HasFoo` classes that you need for that monad. But then you run into the problem that you are selecting the state by its type, and you may have more than one state item with the same type. This is a general problem with the "extensible effects" approach. So far it looks like we're going down the wrong road. I don't see any advantage over the traditional pre-lenses approach: have your type classes define not record field lenses, but monadic get/put pairs for specific state items. And ask/local pairs for specific read-only state items, etc. Well, there's probably some way to do that as a lens-like thing. Looking forward to seeing what Roman has up his sleeve.
&gt; But then you run into the problem that you are selecting the state by its type, and you may have more than one state item with the same type. This is a general problem with the "extensible effects" approach. Right. But I can live with that. In my code that uses extensible effects I tend to define newtype wrappers for all pieces of state. So the code looks like do ... Messages msgs &lt;- get ... This improves readability, too, in my opinion.
&gt; It’s probably possible to do purely It's a darn sight harder to do without `IORefs` though, unless you know something I don't (entirely possible!)
wasn't there a post by you about just that? :D it surely is hairy.
&gt; It seems GHC doesn't recompile files if you just add or remove -fllvm, so you may need to delete .o files (or make copies of your .hs files) to properly compare. Overall, it's down to about 2.7s from the original 85, without doing anything too ugly. You can always add `-fforce-recomp` to the command line to.. force recompilations. 
I wasn't thinking the use of `Data.Vector` as opposed to `[]` would matter for `-fllvm`, but the use of `Data.Vector.Unboxed`. (`[]` will generally put pure ghc at an advantage, if I understand.) I was using this variant of the one thinkpad20 linked, http://lpaste.net/105454 . Avoiding the double comparisons with your `mini`, cuts the time in half, but with a similar ratio for `-fllvm` and not : `0m2.825s` vs `0m5.683s` 
Yes, that's why I say it's a harder ;)
When I try to run that I get &gt; ghc -O2 knn-par.hs -fllvm -threaded [1 of 1] Compiling Main ( knn-par.hs, knn-par.o ) &lt;no location info&gt;: Warning: Couldn't figure out LLVM version! Make sure you have installed LLVM ghc: could not execute: opt How did you set up your LLVM? I did a `brew install llvm` (not sure if you're familiar with OS X), but this message didn't go away. Edit: it works if I drop the `-fllvm`, and it's still twice as fast! Yay! But I would still like that LLVM to work... :( Edit edit: actually, it appears that the speedup was due to using the improved version of `mini` provided by skew. Without that, it's only a barely noticeable speedup :( But then again, I only have two cores on this machine.
what's alternative?
Sounds like it needs a new maintainer. I'd love it if homebrew were reliable for ghc.
I thought the method for plowing through a monad stack is something like `lift . lift . lift $ get`? Did I misunderstand the problem here?
That's solved, or at least made transparent. You need at most one lift now, and you try to hide those in the functions that work on your stack. 
The real problem with the `mtl` is that every monad transformer that is ever released has to implement instances for these type classes.
Why not just use `zoom`?
On my machine skew's version runs in ~5.1s (with `-fllvm`). The threaded version that I posted runs in ~2.9s on 2 cores and ~2.3s on 4 cores. Without `-fllvm` those same numbers are: 7, 3.8, 3.1s. It is a significant speedup in both cases. Btw you are looking at the last number that `time` reports, right?
This is really clever! I didn't think it was possible to do it without closed families.
You need to get the `llc` executable in $PATH. It is buried somewhere in the homebrew machinery; thus somewhere in my `~/.profile` is the equivalent of export PATH=/usr/local/Cellar/llvm/3.3/bin:$PATH Here I am using `using (parVector 100)` and skew's improved mini: http://lpaste.net/105463 On my macbook air, I get $ ghc -O2 attempt.hs -rtsopts -threaded -fllvm $ time ./attempt Percentage correct: 94.39999999999999 real 0m2.821s $ time ./attempt +RTS -N2 Percentage correct: 94.39999999999999 real 0m2.053s $ time ./attempt +RTS -N3 Percentage correct: 94.39999999999999 real 0m1.758s Why `-N3` can be better than `-N` or `-N2` on a 2 core machine, I don't understand, but it is familiar.
roche doesn't like lens.
The problem here is that the mtl classes are being used directly rather than as helpers for defining a set of classes that are relevant to the problem domain. mtl classes and transformers types shouldn't be showing up all over your code. There should be new classes with operations relevant to the problem you're solving and new types hiding the particular transformers you happened to use to implement those operations.
&gt; scheduleFetches :: [PerformFetch] → IO () HA! You found it! I worked on this project from the beginning and got to see the original prototype diff for Haxl. I was a Haskell newbie at the time, but was familiar with the domain, so I decided to sit down with my haskell books and pour through Simon's original diff until I understood every line. I hit the line of code (the scheduling of fetches) which wasn't quite the same, but quite similar to what it is now, and it stopped me cold. It took me almost half an hour to even figure out what it was doing, precisely. And it totally blew me away. It was a huge a-ha moment for me. There's so much power wrapped into that tiny bit of code. Coming from other languages, I was entirely unprepared for how "big" of an idea could fit onto a single, simple line of code. 
oh god what have you done
Does the author of this blog sleep? There's been a prolific amount of type-gymnastics posts from here in the last few days.
This is what happens when the quarter ends and I no longer have to teach a class. Also, when I ignore the machine learning research I'm supposed to be working on. :)
There's not so much reason to use this build from homebrew, it mostly just adds cabal and a GUI helper app that you shouldn't need. The revision numbers are not updates to GHC, just the other stuff that's included.
```{-# LANGUAGE CTHULHU #-}```
This isn't so bad. It just means the mtl is manually extensible, but not automatically extensible.
We'll take care of this one, I promise.
Yeah, Eclipse's API is unpleasant (let's use nulls everywhere, also screw thread-safety) and the build tools for its plugins are worse. Tycho is a bad joke. Oh, you wanted to use Maven to use existing Maven packages? (Literally the only goddamn reason you'd want to use it.) Sorry, to do that you have to get another Maven plugin to unpack the bundles and then repackage them in Eclipse's OSGi plugin format and even then your *automated* build system has to be invoked twice each time. So then either write a shell script or get another Maven plugin since Maven doesn't support running external processes out of the box so you can just have it run itself twice. Brilliant! In retrospect, using git submodules would be simpler.
I would say, not new classes. Once you get into a specific problem domain, you should just have the specialized concrete functions that apply to a specific data type.
The previous criticism of this approach was quite pointed, so I'm interested to see supporting argumentation from someone using it in practice. http://www.reddit.com/r/haskell/comments/1j9n5y/extensible_effects_an_alternative_to_monad/
In the post he specifically wanted to segment the operations so that it could be run in different contexts with different capabilities.
How would it solve the problem described in the article?
Good point.
Nice! That brings the Haskell code at the same level as the Rust implementation which was the fastest from all the blog posts. There might be an even better set of chunkSize and number of threads values. For the -N3 question, I know that the Intel processors in those Macs have some form of hyperthreading. What happens when you increase -N above 4?
I'm pretty sure he's working up to explaining the [comment he made on Twitter](https://twitter.com/shebang/status/475298081236201472): &gt; With help from @kosmikus managed to remove the functional dependency from mtl, using closed type families. It's a breakthrough. #zurihac
i am using it (even in production for one small thing) and not everything is golden. on the positive side, it is very easy to write some nice interpreters and because they feel like free monads, it's easy to write different interpreters for different scenarios. but... i can certainly feel the pain regarding type inference. i have some intuition now when some polymorphic functions will leave something ambiguous, but it is some cognitive overhead i did not have when using `transformers`. to illustrate the point the following mtl snippet works eff :: MonadState Int m =&gt; m () eff = modify (+1) but the equivalent `extensible-effects` one does not eff :: Member (State Int) r =&gt; Eff r () eff = modify (+5) my `log-effect` package works around some pain with type witnesses, which while ugly work fine.
it would be awesome if roman writes up something about layers (still not updated on hackage unfortunately) in a followup article. i always wanted to play with layers, but never did...
Probably years.
Where is `hoist` defined? No results for http://www.haskell.org/hoogle/?hoogle=hoist
 import Lens.Family.Stock (_1, _2) import Lens.Family.State.Strict (zoom) import Control.Monad.Trans.State.Strict example :: Monad m =&gt; StateT (Int, Bool) m () example = do x &lt;- zoom _2 get zoom _1 $ put $ fromEnum $ not x ... or just: example = do x &lt;- use _2 _1 .= fromEnum (not x) However, I consider `zoom` to be the more general solution and more in the spirit of your post.
Thanks for the fix! Now I have to go through all my HsQML projects and fix that.
Are they automatically tagged, or are you manually setting it up?
Right now, manually
I think it's pretty cool and I submitted a few links. Also, thanks for releasing the source! It could be helpful to others learning Yesod. Do you have any warnings or checks in place for duplicate submissions?
It is in the [mmorph package](http://hackage.haskell.org/package/mmorph).
I still think that in most cases concrete monad stacks form a better application foundation than polymorphic stacks. I understand this problem exists, but for me at least it's a very minimal pain in practice. A few extra explicit lifting functions can solve a lot of problems. Sometimes I have the feeling that Haskell programmers don't have enough love for concrete types. :)
http://www.dohaskell.com/tag/arrows The link to "arrows" is broken: "Wikibook: Arrows" Link is: "httphttps://en.wikibooks.org/wiki/Haskell/Arrow_tutorial://" should be: https://en.wikibooks.org/wiki/Haskell/Arrow_tutorial
Ha. Thanks. Good thing there's currently no way to edit the URL.
This is my own question on StackOverflow. I'm not sure of the etiquette in submitting my own question here too, so apologies if this is frowned on.
Can you explain why these instances couldn't be added in a separate package. Pipes.transformers or something similar?
Was exited to try it out, but was greeted with an very unresponsive editor, which was a pain to code in since it took way too long to process any keyboard input.
That would create [Orphan Instances](http://www.haskell.org/haskellwiki/Orphan_instance).
This looks great. I think as the site gets bigger then it's going to be essential to have some way to rank the links in each section. 
Have you looked at [**layers**](http://hackage.haskell.org/package/layers-0.1/docs/Documentation-Layers-Overview.html)? Longest piece of Haddock I've ever seen; even more than Tekmo's crazy `.Tutorial` packages. Anyway, provides a fascinating analysis of the problems in the various Haskell approaches to monad transformer stacks.
Ah, yes, I remember thinking 'Hey, cool, Tycho. Let's use that!' That was not a good day. The weeks after that were *spectacularly* unpleasant.
Now do this for standard deviation (or other estimators; skewness, kurtosis...) ;) And you don't get the subsample estimates. But yeah, you are right, for calculating just the jackknife of variance you don't need special trickery (well, the fancy summation methods help, of course). /u/bos should have mentioned that.
Maybe not entirely what you're looking for (still some *Free*s left), but here's what I came up with. Using *free* and *syb*. Note I removed some of the boilerplate you used on SO using *Control.Monad.Free.TH*, and use *iterM* in the execution function. I implemented a couple of optimizations: * Combine 2 consecutive *displayChar* and/or *displayString* calls into a single *displayString* * Loop unrolling for *repeat* commands up to 5 repetitions Demo source: prog :: Command () prog = do displayChar 'a' displayChar 'b' repeat 1 $ displayChar 'c' &gt;&gt; displayString "def" displayChar 'g' displayChar 'h' repeat 10 $ do displayChar 'i' displayChar 'j' displayString "klm" repeat 3 $ displayChar 'n' Here's the output for the demo program above: $ cabal exec runhaskell ast.hs Original program: Free (DisplayChar 'a' (Free (DisplayChar 'b' (Free (Repeat 1 (Free (DisplayChar 'c' (Free (DisplayString "def" (Pure ()))))) (Free (DisplayChar 'g' (Free (DisplayChar 'h' (Free (Repeat 10 (Free (DisplayChar 'i' (Free (DisplayChar 'j' (Free (DisplayString "klm" (Pure ()))))))) (Free (Repeat 3 (Free (DisplayChar 'n' (Pure ()))) (Pure ())))))))))))))) Evaluation of original program: abcdefghijklmijklmijklmijklmijklmijklmijklmijklmijklmijklmnnn Optimized program: Free (DisplayString "abcdefgh" (Free (Repeat 10 (Free (DisplayString "ijklm" (Pure ()))) (Free (DisplayString "nnn" (Pure ())))))) Evaluation of optimized program: abcdefghijklmijklmijklmijklmijklmijklmijklmijklmijklmijklmnnn Code at https://gist.github.com/NicolasT/e4fc20c36e220ea76900
Links collected on the Haskell Wiki are also useful. * http://www.haskell.org/haskellwiki/Blog_articles * http://www.haskell.org/haskellwiki/Blog_articles/Parsing * http://www.haskell.org/haskellwiki/Blog_articles/EDSLs * http://www.haskell.org/haskellwiki/Blog_articles/Monads * http://www.haskell.org/haskellwiki/Blog_articles/Exercises * ... there's more but can't list them all here Unfortunately most of them haven't been updated recently though. Maybe that's because few people know their existence?
The blog is unreadable on mobile because of the background image doing funky things.
Compared to SPJ's legendary clarity, Proctor's questions seem so disorganized...
Yeah, I was thinking somehing like (and this would be a hack) a global unsafePerformIO MVar to which you could send "actions" to register/unregister instruments that are currently bound to some sort of persistent metronome. Again, I'm not sure how much of that would actually work in ghci. But I think being able to use straight ghci would be really cool.
suggestions: * support other login way * add a reactive filter at the home
I'd like to see how many links are available under each tag as well, though I understand that might be a bit more work. I might have a look some time at the repo and see if there's improvements I can make =)
Though if I remember correctly that's because `lens` has a `uniplate` implementation baked into it.
Depends what part you're talking about. Specifically, `lens`'s `uniplate` uses Traversals and therefore is faster and less code (and works on arbitrary Traversals/is a Traversal). You can also do some of it without that part of lens.
After playing around with my own implementation, I've found that most of the problems with this approach are actually fixable. a) The Union type, and therefore the entire library, can be implemented without Typeable by storing an index into the type list along with the actual value. My motivation for trying this was to get regions working, but it turns out their still unsafe. b) With GHC 7.8, all the OverlappingInstances can be replaced with closed TypeFamilies. Inference issues (like the one ibotty pointed out) can be solved as well: type family StateType r where StateType (State s &lt;: r) = s StateType (e &lt;: r) = StateType r modify :: (Member s r, s ~ StateType r) =&gt; (s -&gt; s) -&gt; Eff r () modify = ... -- GHC infers: eff :: (Num (StateType r), Member (State (StateType r)) r) =&gt; Eff r () eff = modify (+5) The state type is now inferred from the list of effects. Of course, writing XXXType for every effect instance gets annoying, but it can be generalized (as I have done in my own package). This can also be done in previous versions of GHC, but the extent to which you need OverlappingInstances makes it look... unattractive. Regions are unsafe with this approach because there's nothing preventing you from combining a region effect with a threading effect. The `regions` package suffered from this initially, and there's a post somewhere on Haskell Cafe providing an example, but I can't seem to find it. Basically, if thread A can access all the resources in thread B, and B exits, then A may end up accessing a resource that was closed by thread B. Similar issues arise with exceptions: how do we ensure a finally block gets executed _exactly_ once when a nondeterminism effect could potentially be involved?
There is a reason for those n^2 instances. If you aren't careful and use the extensible effects model and handle the effects in the wrong order you just silently get the wrong semantics! e.g. Notice there is no instance of instance MonadWriter w m =&gt; MonadWriter w (ContT r m) in http://hackage.haskell.org/package/mtl-2.2.1/docs/Control-Monad-Cont.html Why? Because if you handle the `Cont r` "effects" and then go to handle `Writer w` effects then `pass` and `listen` simply do not pass the writer laws, because they can't! This isn't surprising, we're basically taking a product of theories without any checking of their associated laws, throwing it in a Codensity blender so it can be big enough to handle `Cont` and expecting everything to still hold. We don't write n^2 instances. We write slightly fewer, because the ones we _don't_ write are as important as the ones we do. The intuition you get that 'everything lifts' is a false sense of security given to you by the fact that Reader, Writer and State all commute.
We have a user group! See https://groups.google.com/forum/#!forum/toronto-haskell. Not that I'm ever around to attend the meetings :(
this is awesome! thanks so much for the link. And I know the feeling, I miss tons of the javascript meetups I'd like to go to because of travel and stuff
anything where the operations are all of the form MonadSomething m =&gt; a -&gt; m b is fine though. The problem with `MonadWriter` is that `listen` is not of that form (`MonadCont` is also a problem). 
Alas `catch`/`callCC`/`pass`/`listen`/`local` are all kind of useful. ;)
that they are. They just make life much more difficult when it comes to library design :)
Chrome on Android. You might want to disable the background image for mobile altogether, to save on bandwidth and load time. It is 1.5mb, too much for desktop browsing even :)
Thanks for this nice piece of software. I second viadley's comment about live-coding. This is what clojure's overtone allows and having the ability to do this with Bang in Haskell would be great! 
From the blog post: &gt; Since monad transformers don’t commute in general, you can’t always merge two StateT layers together. For instance, there’s no way to achieve the semantics of StateT s1 (MaybeT (StateT s2 Identity)) using only one layer of StateT. Monads do not commute in general but I thought since StateT and MaybeT are both `MFunctor`s it possible to swap the order arbitrarily and still have the same meaning for the type. hoist distribute from the [mdistribute package](https://github.com/Davorak/mdistribute) will swap the `MaybeT` with the lower `StateT` so the two `StateT`s are grouped on top. Then it should then be possible to translate it over to using `zoom` and one `StateT` transformer.
I've always wondered if Toronto had any of these
i am probably missing something, but how would that example work with multiple `State` effects? `StateType r` is parametrized to only r. if so, it is more analogue to `SetMember` from `extensible-effects`. type inference with `SetMember` is easy in `extensible-effects` as well. and: ~~where can i find your effects implementation?~~ i'd certainly like to have a look! found it [on github](https://github.com/YellPika/effin)
I'm sorry. I made a conscious decision to do the lexing via Haskell and the GHC API so that I would be sure it was correct in all cases, but maybe the price to pay in terms of performance is too high. Maybe also at the start there are some init work going on (scion-browser downloading from hackage, things like that) that may slow you down. 
good idea, thank you.
Is there any way you could make it a bit easier to install on windows? I have spent quite a few hours now trying to compile QT with GHC's version of gcc with no luck. HsQML it self is easy to install though :) HsQML looks to be the gui framework I have been looking for in Haskell. Well done!
Thanks, I knew there had to be something like this already in existence, I just couldn't find it. I asked around IRC a bit without any luck.
The github repo from the about page: https://github.com/mitchellwrosen/dohaskell
There are quite a few Haskellers around McMaster. A meetup halfway might be a nice idea.
You can take a look at the [`rest`](https://github.com/silkapp/rest) package we at [Silk](http://silk.co) are in the process of releasing. The main focus in on REST APIs, but the general concept is very applicable to other form of RPC-like protocols. Most of what you talk about is addressed: generic serialization to/form JSON/XML, automatic documentation generation, schema derivation, generation of client code, etc. We are still in the process of writing docs/tutorials, we expect to officially release soon. https://github.com/silkapp/rest
In [wai-routing](http://hackage.haskell.org/package/wai-routing) you can attach arbitrary data to your handlers and inspect them in order to generate API documentation. It is rather easy to combine this with [swagger](http://hackage.haskell.org/package/swagger) for example. 
I wonder why this gained traction, but the [silk page](http://www.reddit.com/r/haskell/comments/1vgar6/collecting_resources_about_haskell_herefpsilkco/) did not. I'm genuinely curious as to what causes certain submissions to gain community support and others to be shot down almost immediately. Is it the simplicity of this project? Is it that this has been open sourced? I have a few other guesses, but Ive probably speculated enough as is. I'm genuinely curious because the response to the other project was that it was duplicating functionality found in the wiki, which this seems to be doing as well. For the record, I appreciate both for different reasons. The silk one feels more organized and has nice previews. I like this one because its mobile friendly and has a "grokked" button.
Wow... the stuff at http://silkapp.github.io/rest/tutorial.html looks very intriguing in its current form already...
That's right. You can define a monad morphism that joins the two `StateT` layers: morph :: StateT s1 (StateT s2 m) r -&gt; StateT (s1, s2) m r
Interesting. Any reason they're around McMaster specifically? Is there a CS program there that integrates Haskell?
I've read up until the "Multiple Arguments" section, and still don't see the point of this. Where is the author going will it all? Is this an introduction to how Haskell gets compiled to C-- code? Is there going to be some unexpected inefficiency and a trick for working around it? Is it just a way for the author to convince themselves that they have a solid understanding of how boxed data gets stored on the heap while unboxed data is stored on the stack? I liked the [previous blog post](http://www.well-typed.com/blog/94/) much more: by the end of the introduction, it described interesting/surprising behavior, and then spent the rest of the post explaining why this behavior occurs. but I do not see the goal of the current post. I'm almost halfway through, but I don't see where we're going or why we'd want to get there at all.
I don't understand why the empty parameters still need to exist at all at runtime. Why can't `Proxy# -&gt; foo` have the same representation as `foo`? I suppose that for `RealWorld` tokens, we want to ensure that we still have a function, not an evaluated value, since it might have side effects.
Because semantically `\(p :: Proxy# ...) -&gt; undefined` is a very different thing to `undefined`. 
I'm trying to install eclipsefp. Ubuntu 14.04, ghc 7.6.3, cabal-install 1.20. I did it with a fresh .cabal and .ghc folders. Nothing elase was installed. After restarting eclipse it started doenloading and building haskell libs, and stopped with this error: Cabal==1.16.0/installed-c6e..., SourceGraph =&gt; Cabal&lt;1.7) rejecting: SourceGraph-0.2, 0.1 (conflict: buildwrapper =&gt; Cabal==1.16.0/installed-c6e..., SourceGraph =&gt; Cabal&lt;1.5) Backjump limit reached (change with --max-backjumps). Note: when using a sandbox, all packages are required to have consistent dependencies. Try reinstalling/unregistering the offending packages or recreating the sandbox. ------ Also what forum can i ask questions about eclipsefp? Is is haskell cafe? 
These issues seem like deal breakers. Do you happen to know if variations such as found in Idris address these complaints?
Congrats man! :) Happy life awaits the adventurous Haskeller.
I would love to install this but cabal insists that buildwrapper will break network and HTTP-4000 (seems like everything breaks HTTP-4000). Really can't afford to break network. scion-browser, it claims, will break hlint, ghc-mod, haskell-src-exts, and of course HTTP-4000. This is in windows using GHC 7.8.2 64 bit, cabal 1.20. I tried --reorder-goals and --updgrade-dependencies. No help. Very frustrating
I just came across MaidSafe, a company building a freenet-like platform: http://maidsafe.net/. They've opened their technology and patents. Maybe this is something you should target? There's an AMA thread [here](http://www.reddit.com/r/futuristparty/comments/27vk4k/maidsafe_is_creating_a_new_decentralized_internet/).
One language to look at would be [Rust](http://www.rust-lang.org/), which has various features borrowed from functional programming, such as algebraic data types, immutability-by-default, (limited[1]) higher order functions, and a strong linear type system for management of allocated resources. It's still in many ways an imperative language, but the functional parts of its heritage bring a lot to the table—in particular, the type system means that you get deterministic memory management (no GC) without explicit malloc/free, giving you type and memory safety without GC. Another language, much further along the functional spectrum, is [ATS](http://www.ats-lang.org/), which descends mostly from the ML family and also has a dependent type system. This means, for example, that you can express things like "did I allocate enough space for a null terminator?" in the type system, so failing to do so would be a compile-time error. [1]: Limited in that there are various restrictions on what you can do with closure types, as a consequence of the type system and memory model.
If GHC Core isn't low-level enough for you, take a look at [ATS](http://www.ats-lang.org/). It allows bit-twiddling like C yet is functional at its core. Other than that, you'd have to define "functional language" more rigorously to have a more precise answer.
Analogous problem is solved by optparse-applicative. That package is a command line option parser builder that lets you attach documentation and help for your command line tools written in Haskell. 
Hmmm, fair enough :) If you do read to the end hopefully there will be a surprising conclusion. Stating it up front with some real results would involve profiling. Feel free, I'd be happy to add it to the blog post :)
Thanks for the link, I didn't even know this page existed! I hate to say it but I think this gained more traction because it's much simpler. I'd love to keep adding useful functionality but, as I say on the about page, the site is essentially a bookmarks folder =) One idea I had recently - maybe it would be fun to have community-built quizzes for resources, and in order to mark a page as grokked you have to "pass" the quiz. It would probably fizzle out and become useless if not enough people were into it (need a steady supply of graders), but it would give more meaning to the grokked feature.
A semantic distinction due to `seq` tends to be reflected by an operational distinction whether or not we use `seq`. Here `let v = &lt;expression&gt; in \(p :: Proxy#) -&gt; v` will only evaluate `&lt;expression&gt;` once while `\(p :: Proxy#) -&gt; &lt;expression&gt;` will evaluate `&lt;expression&gt;` every time it is called (in principle; GHC might rewrite one to the other, but you can control this to some extent with optimization flags). Or by using a series of `Proxy#` arguments, you can give the caller fine control over exactly how much computation is performed when. Edited to add: In fact, here is an example from just today of fixing a performance regression in Typeable in GHC 7.8: https://phabricator.haskell.org/D19
They are executables. You can build them using the cabal sandbox support.
Maybe you'll want to look into [Binary Lambda Calculus](http://homepages.cwi.nl/~tromp/cl/cl.html) and [Unlambda](http://www.madore.org/~david/programs/unlambda/) and the like.
Aha! That makes sense. Thanks for the pointer! 
You can ask questions on http://sourceforge.net/p/eclipsefp/discussion/371922 or create issues on the github repo.
Funny, because if you have Cabal &gt;= 1.18 EclipseFP installs the execs in a sandbox. If you do the install yourself, just install into a new sandbox to avoid conflicts.
Thx, i'm right now trying to install buildwrapper with ghc 7.6.3. This is embarassing, i think i found what was the problem. I have a cabal freeze file for our projects (caba.config) and i copy it to all our projects subfolders. But it was also left in home folder I thoink that's what wsa preventing eclipsefp from correctly building its needed utils. I removed it from home folder and now reinstalling everything, and so far all works good. 
 constant_Int# :: () -&gt; Int# constant_Int# _ = 1234# What does # mean here?
That looks really nice! Is the version prefix in the URL optional? 
From the guys who made the 'House' OS in Haskell, there's a language in development called 'Habit': http://hasp.cs.pdx.edu/ It's got some interesting type-level features that I haven't seen in other languages mentioned here yet. I especially like their formulations of bitdata and typed memory regions. It hasn't got the full power of ATS's dependent types, but the ATS type system strikes me as a bit unwieldy and something that would take a good bit of time and practice to get comfortable with. Habit aims more at some specific problems rather than generality, which has its pluses and minuses. If anyone knows if the guys at HASP are still actively working on this, I'd be curious to hear how it's going, as there hasn't been any public output I'm aware of in a couple of years.
In general you can view the pass/listen/censor/local combinators as 'handler-like' affairs, so if you don't try for 1:1 feature correspondence there may be a better story. Also in a strict language "Cont is the mother of all monads". She is alas merely an unloved stepmother to lazy writer and lazy state, unable to supply their needs.
I suspect that all the crazy type stuff was written as a way to make the very nerdy joke at the end, I like your style. Congratulations on tying the knot! :)
Interesting and easy to grasp paper! Well worth a read :)
`Data.Vector.Mutable` is equivalent to `std::vector` for all practical purposes. It has constant time lookup, modification, and with a bit of effort has amortized constant time append. For reserve space and fast append you need to use `new`, `grow`, `write`, and keep track of the index for the last/next slot, but that's what `std::vector` does behind the scenes anyway. Bit surprised nobody's bothered to package that up with a nicer interface and stick it on Hackage.
Congratulations! :) 
[I did upload one](https://hackage.haskell.org/package/dynamic-mvector). I wonder though why the haddock isn't visible. Maybe I should upload again.
The # in `constant_Int#` means nothing special, it's just chosen to make the naming scheme consistent. The # in `Int#` also means nothing special, it just distinguishes the name `Int#` from the name `Int`. `Int#` is the type of an unboxed integer (as opposed to `Int`, which is the type of a pointer to something that's either a boxed integer or a delayed computation of some kind). `1234#` is the syntax for a literal of type `Int#`. You need the MagicHash extension in order to use # as part of an identifier or a literal. It doesn't have any other effect.
Doesn't Data.Vector.constructN do exactly what the guy wants? &gt; `constructN :: Int -&gt; (Vector a -&gt; a) -&gt; Vector a` &gt; *O(n)* Construct a vector with n elements by repeatedly applying the generator function to the already constructed part of the vector.
Do you mean "low-level" as in "close to the machine I'm typing this on" or "low-level" as in "building on very few fundamentals?" The canonical answer to the second question would probably be some kind of Lisp. If you disregard the Haskell standard libraries, then Haskell, too, is low-level in that sense. What makes Haskell high-level are the rich libraries, I think.
oh, I definitely meant low/high level as closer to/further away from machine code
Yes, it does.
As someone that barely understands lenses, this is terrifying.
That's unfortunate as building Qt in that configuration was also my intention. If I do succeed in making a Windows Qt build which works with GHC's MinGW out of the box then I'll make it available for download. Longer term, I've hope to help get a newer version of MinGW into GHC. For now, the best solution is to modify the GHC settings file. It's the "C compiler command" field of the GHC settings file located at, for example, "C:\Program Files (x86)\Haskell Platform\2013.2.0.0\lib\settings" which needs to be changed to point to Qt MinGW's gcc.exe. I need to provide clearer instructions on my site.
I've decided to tweak the implementation for a couple reasons, and ended up doing exactly this. (io-memoize-1.1.1 has been uploaded, and now includes an Eq instance.) It might be slightly faster to use IORefs in combination with the MVar, but as implemented, I can be confident that it is thread safe.
They used to build Lisp machines, and the Lisps they'd run on those was *very* close to the underlying hardware - car and cdr were actual registers in the CPU, etc. That's probably as low-level as you'll get. That said, "functional" is a paradigm more than a property of a language - if you stretch it enough, most any language can support a functional style, it's just going to be more painful than in a language specifically built for the task. I bet even plain x86 assembly could, with the right macros and conventions, be bent into a functional idiom...
Congrats!
I'm working on a dependent linear framework for assembly languages, which is about as functional and low-level as it gets :)
I wouldn't call typeclasses a low level feature.
I'm sure he thinks it's very kind of you to say so ;)
Ah, I understand what you mean. The ideas which Haskell is built upon are quite fundamentals from a theorical perspective: pure functions and the evaluation orders equivalence that it entails.
Exactly. And I'm sure you could design a microprocessor to work with that, but the ones we have aren't designed like that.
There's MCPL, a mix of BCPL and ML. I'm not sure how functional i'd call it really, but it is an interesting language. Spent a pleasant few weeks playing with it once. http://www.cl.cam.ac.uk/~mr10/MCPL.html
What I call a framework is an overlay over an existing language. In this case, I'm adding linear dependent typing (among other things) to existing assembly languages. "Dependent" means that you can encode arbitrary theorems about the outputs of your programs; "linear" means that you can encode arbitrary theorems about the resource usage of your program. I am of course vastly oversimplifying.
&gt; So now you can't write code for Free [State s, Reader e] that also works with Free [Reader e, State s] without passing around manual indices. I'm not sure what the problem is. If your code has the type `(Member (State s) r, Member (Reader e) r) =&gt; ... -&gt; Effect r a`, then it can work with both `[Reader e, State s]` and `[State s, Reader e]`. Whether I use indices or `Typeable` doesn't change much, except in the presence of multiple effects with the same type. &gt; In the second case, the problem remains that 'eff' doesn't pick an 'r', it merely puts constraints on it, and after you bind it, nobody else will choose it. Could you clarify by what you mean by "nobody else will choose it"? I was under the impression that the intent was that one should mostly work with constrained type variable instead of a concrete list of effects. This way, the order of the effects is irrelevant until you actually get to handling the effects.
Do you user Haskell for your ML work? I've been using C++/Python for it, but really would like to try out Haskell in that area.
&gt; but how would that example work with multiple State effects? Currently, the type I use to specify effect lists is slightly different from the norm: `data List a = a :+ List a | a :- List a | Nil` `:+` and `Nil` are the normal cons and nil types. `a :- r` means 'exclude', which basically says "I want to ignore the first instance of 'a' that occurs in 'r'". Using an additional function, `enable :: Effect (e :- r) a -&gt; Effect r a` (which is admittedly poorly named), you can create a scope in which the first instance of an effect is ignored. For example: -- Because I didn't have the foresight to add a proxy parameter to the enable function :/ enableReader :: EffectReader r l =&gt; Effect (Reader r :- l) a -&gt; Effect l a enableReader = enable foo :: Effect (Reader Integer :+ Reader String :+ Nil) () foo = do x &lt;- enableReader ask -- Gets the String value. y &lt;- asks show -- Gets the Integer value. return (x ++ y) 
If I have a constraint merely constrained to use `Num s =&gt;` for some `State s` constraint, e.g. `modify (+1)` nobody gets to pick `s` except defaulting or an explicit signatures. Your numbering scheme is different than the one Oleg used. He put all the instances into a total ordering. Now given a set of effects you get a canonical ordering to the sum type. Sjoerd Visscher built a version of the lookup that was able to skim through the effect set doing best match and take the first hit always if there was only one. That _might_ be enough to make type inference not suck for these, except when you are silly enough to have multiple states, etc, but it is a pretty baroque bit of type family machinery 
Ahh cool, thanks. I like to follow the guidelines, but it was getting me rather irritated. 
&gt;Thanks for the pointer! -_-'
There is no disadvantages if you can get Haskell in first try.
Advantages: 1. Less headache/adjustment time. Imperative programmers often run into walls because they relate concepts from their language into Haskell. 2. Cut the cruft and learn programming's "Holy Grail". This is a debateable point, of course, but Haskell is a language with very many positives and few negatives. The only one that comes to mind is "not very granular resource management" but even that may be mitigated, with time. Do you need to learn how to create 100 incorrect bridges before you are given the true method of bridge building? 3. Learn to problem solve and model programs and logic in a mathematically based way. When I started learning Haskell, I had a bit of "Category theory phobia". Haskell eased me into the concepts and now I don't know how I lived without it. Disadvantages: 1. You will have to use other languages at some point. 2. Haskell doesn't work on everything yet! 3. Haskell books often assume some minor imperative experience 4. ??? In all seriousness, this was all I could think of
Do note the disadvantages are more social ones, than Haskell problems :P
Advantages: 1. focus on decomposition/modularity from early on; 2. doesn't hide the deep connection between programming and mathematics; 3. no need for wavehanding "explanations" of invisible concepts such as memory, pointers, passage by references/value and in general what a compiler does. Disadvantages: 1. might demotivate students with a poor maths background; 2. students might be less inclined to pay attention because the approach is perceived as not "real world" enough; 3. more difficulty in reasoning about runtime performance.
&gt; Disadvantages: 1. You will have to use other languages at some point. That's not a problem per se. It's rather that you might have to use *lesser* languages, where you find yourself being frustrated that those lack many features you've become accustomed to which would make your job way easier. I like to think about this a bit like an [Allegory of the Cave](http://en.wikipedia.org/wiki/Allegory_of_the_Cave) in the context of programming languages -- once you've left the cave and seen the light of more advanced programming languages you'll have a miserable life having to go back into the cave to endure working with less advanced ones... :-)
I was vacationing in Vietnam in February, does that count? :)
advantage: you get to code in haskell! disadvantage: you don't learn how to do the low level stuff. 
As an intermediate Haskeller, I am completely confused by cabal. Why is there `cabal build` and `cabal install`, and which should I use in what circumstances? Why use `cabal install --only-dependencies` followed by `cabal build` when `cabal install` installs all the dependencies from my `.cabal` and builds my project too?
I did a computer science degree at the University of Oxford, and Haskell is the first language that anybody is taught there. The big advantage is that you learn not to think of a programming language as "instructions for your CPU to execute in sequence", but rather as a method of describing a mathematical result. The disadvantage is that, unfortunately, many programming languages *are* best thought of as sequential instructions for your CPU, so you'll be moving to a lower-level if you need to use any other language.
man, i wish i had a tumbleweed. I would hug him and pet him and squeeze him and call him george.
Visit Texas and we'll find you one.
It is a problem to have to use Java if you only know Haskell. It's less of a problem to have to use Java if you only know C#. It has nothing to do with one being lesser or greater than the other, it's simply about difference and similarities.
`cabal install` is to `cabal build` roughly what `make install` is to `make build` (for autotools projects). Notably, `cabal install` registers packages in the package database. Hence, installing your own project with `cabal install` is dangerous, since it makes two versions of each contained module available during build: One that is installed, and one that you are currently building. Generally, to build your project, you should **always** use `cabal sandbox init; cabal install --only-dependencies; cabal build`. `cabal install` is mostly for installing tools globally, e.g. `cabal install pandoc`, to install the latest pandoc to `~/.cabal/bin`.
heh. I didn't get here till March :) pity.
Thanks. Why exactly is it dangerous? I have developed projects before using both `cabal install` and `cabal build` during development, and never ran into an issue. Was it just luck? I guess at this point, I wish for better a better cabal interface. An argument that both installs missing deps and builds the project would be nice.
Ideally, "cabal build" would not only "cabal configure" automatically, but also install necessary dependencies.
Yeah, that can happen. Just make sure you're not ashamed of how your code is written, so that someone working on similar things or on the same project can just pick up your code and understand it easily. Following guidelines just for the sake of it isn't productive, but writing clear code that gets the message transmitted accross screens in the whole world is.
I'm in Hanoi, Vietnam. May travel to Da Nang next month
An assembly language is more transparent in the way it operates than Java is. Does this mean a student thinks an assembly language is more practical than Java?
Have you tried it also with `-fforce-recomp -fno-code`?
yes, will pm you when i'm there
Intel APX 432 which was designed in mid 80's had strong support for primitives used in garbage collected languages (a prerequisite at the time for anything conceptually more advanced than C), but the performances were abysmal, contrarily to their polar opposites, Von Neuman style RISC CPUs. Intel poured a lot of money in that ambitious experiment, and I suppose that because of its failure, it cooled down significantly their enthusiasm in doing other attempts in that direction. I don't know if there were any other designs based on these principles afterwards.
[Hume](http://www.hume-lang.org/) is a family of languages with the most abstract language, Full Hume, being a mostly-functional programming language, and the base language, HW-Hume, being a low-level language without functions and recursive data structures, akin to a hardware description language where circuits are described using boxes connected by wires. There's several languages defined in between the two extrema, progressively adding more and more features (for example, PR-Hume adds primitive recursive functions and inductive data type definitions). Hume's design allows you to impose a fairly accurate (space/time) cost-model on programs.
This doesn't sound like a problem for a first introduction to programming.
In a similar direction let's mention the [Reduceron](http://www.cs.york.ac.uk/fp/reduceron/), a research project which basically implemented functional programming on an FPGA.
A great little quick-start guide. But no "cabal links and resources" list should be considered complete without mentioning [SICP](http://www.vex.net/~trebla/haskell/sicp.xhtml).
I forget the name, but NVIDIA (?) recently announced a new LISP for GPU programming. There is a PDF hiding somewhere on the web. 
You're missing my point. Unfamiliarity will be a bigger initial obstacle than expressiveness. I'm not saying expressiveness is not a problem at all, just that it is small compared to unfamiliarity.
Even with java 8?
Great, just had a look. This is pretty much what I was about to implement anyway, so thank you for saving me some work! ;-)
i forgot to mention, learning the high level stuff first makes you lazy to learn the lower level stuff.
Sure you can recommend this to beginners! Though they have to be aware of what they are looking for.
I have heard that this is in the pipeline for an upcoming release of Cabal.
He doesn't actually need constant time indexing while building, of course. A list suffices. Using the last four elements is constant time. Convert to a vector at the end in O(n) to get constant time indexing.
https://research.nvidia.com/publication/nova-functional-language-data-parallelism-2 
Well, in most cases, you probably should be lazy about it, in the sense of waiting for those rare cases where you'll really need it and have a decent source of motivation. I think Haskell can serve as a really good metalanguage for generating low level code as well. I've helped on a project which put it to use in that capacity, generating very high performance PPC/Altivec code by more or less brute force searching through various orderings of instructions in loop bodies to pack as many instructions into each clock cycle as possible, keeping track of which units on the chip were available at any given point in time. We generated some vectorised code for computing sine/cosine pairs which operated at about 2.6 clocks/float. (For extremely unfair comparison, as I recall, the GNU math library's trig functions take around 200 clocks/float -- of course, they're unvectorised, and wouldn't even get inlined.) Also, for a more moderate sense of low-level, the FFI provides lots of facility for messing with pointers and explicit memory layout of data and so on, so it's possible to learn quite a bit of that sort of thing without leaving the confines of Haskell.
There's a difference between level of abstraction and difference in paradigm. C or D is high enough level for newbies while still true to the machine paradigm. Java loses on BOTH counts. :)
You seem to have a strong opinion on this so I won't argue!
&gt; Hence, installing your own project with cabal install is dangerous, since it makes two versions of each contained module available during build: One that is installed, and one that you are currently building. I've never had problems with this. &gt; Generally, to build your project, you should always use cabal sandbox init I disagree. I am usually working on one project and in this situation it's much better to not use a sandbox IMO. The ghci support for sandboxes is simply not good enough yet. When not using a sandbox, I can do "ghci src/Foo/Bar/Baz.hs" and only load Baz.hs and its dependencies. When you do this it makes it look like you are inside that module. All the module's imports are in scope. This makes it really easy to discover where a particular symbol came from by doing ":i symbol". Last time I checked, sandboxes + cabal repl did not give you this capability.
Just the sort of thing I would expect to hear around here. 
Ok, I should have clarified that I believe you *can* show students that Haskell or FP in general have real world benefits. For example: I teach first year CS/CE students functional programming in Haskell; one of the case studies is to use Gloss to do an Asterioids game. The problem is that some students might drop out of the course because of some pre-established notion that Haskell is not a marketable job skill.
&gt; I think they're saying it's easier to show a student the practicality of an imperative language I was thinking more in terms of "job marketability" rather than actual practicality... 
I'll be in Bali for 2 week in August, which is close-ish :-)
On that, I think we agree! When you said "perceived", I didn't think about preconceived opinions.
This is the culmination of a tremendous amount of work Tim Watson has put in over the last year+ on distributed-process-platform. I've been using the development branch for a good while now and I continue to be impressed with the features, design and implementation. If you were waiting for OTP in Haskell - it's here!
Yup. (This is with `lens` 3.10.2)
[Yes](http://www.haskell.org/haskellwiki/The_JavaScript_Problem).
Have a look at this wiki-entry: http://www.haskell.org/haskellwiki/The_JavaScript_Problem or is there something special about node.js you could not solve with a "common" h2js compiler?
Yes. In fact this is how most Haskell people are running these days. There has been a lot of excitement in the Erlang community, too, for getting Erlang to compile down to node.js. There were several discussions about it at last week's Erlang User's Conference. This will allow Erlang to be truly "web scale", and it would provide an easy path for JavaScript experts (of which there are many) to work with some of the problem sets Erlang is strong in. JQuery, of course, is also an important consideration, as pelotom indicated below. Haskell (or OcaML, or Erlang, or F#) plus JQuery would be an unbeatable combination for full-stack experts. Most languages will be Node.js, or at least asm.js, compatible in the future. As Brendan Eich said: "Never Bet Against Javascript" In fact, Intel is working on a new chipset that executes a subset of Javascript directly. No doubt the Haskell community will take note of this.
Nathan Sorenson covered the options in a recent presentation, and in the process has written a Haste+React version of to the TodoMVC project. (The submission should show up on todomvc.com under the Compile to Javascript category soon.) http://www.slideshare.net/takeoutweight/haste-and-tagless-final-style As pointed out in the slides, other HS2JS options have various tradeoffs depending on what your aim is, but Haste seems to be balanced for general use. 
Yes, I was just giving some food for thought. State is just a function s -&gt; (a, s) and the do notation that make monadic code "imperative" is just syntax sugar!
FWIW, I've found that the FP Complete IDE editor does a much better job of maintaining hanging indents, leading to easier to write (and hence read) left-to-right style. Definitely something I'd like to see improved in other editor modes. 
Would you happen to know of any resources for doing that kind of thing?
Not learning he low level stuff is the only real downside. I would love to hire people with Haskell skills, but I'd like to see some proof of knowledge of low level stuff. On the other hand I would also want knowledge of distributed systems and there functional is a good basis. So go for Haskell but do not ignore the low level.
&gt; SICP Thanks for the tip! I'll add it to the list =)
Yes I'm using the p2p back-end.
This is the sort of thing that `cabal exec` should make easier. You could either `cabal exec bash; cd src; ghci Foo/Bar/Baz.hs` or `cabal exec ghci -- -isrc Foo/Bar/Baz.hs`. Where the `--` is needed to separate ghci arguments from cabal exec arguments. That way you can have the convenience of sandboxes and the convenience of using the various ghc tools directly. There are a few problems with `cabal exec`, most notably https://github.com/haskell/cabal/issues/1800, so your milage may vary. But it would be good to get feedback on what other use cases it should or could support. 
Videos can also be found (and downloaded) here: http://video.s-inf.de/#FP.2005-SS-Giesl.(COt).HD_Videoaufzeichnung
Ahh, very nice. I had not heard about cabal exec.
Most people run Haskell via a NodeJS? Seems I've missed something. And now I'm trapped in a niche (running it natively) in a niche (using Haskell in the first place). :-)
So, I guess this is more a cabal question than a cloud-haskell question, but it seems relevant. Suppose I write a program that uses the "p2p" cloud-haskell backend. In my .cabal file, I can say that my program depends on "cloud-haskell", but is there a way to say that it depends on "cloud-haskell with the p2p flag set"? I haven't found anything relevant with a bit of googling, but it seems like it should be possible, right? Also, quick edit to point out that the real "meat" behind this initial release appears to be http://hackage.haskell.org/package/distributed-process-platform, the first release of the higher-level behaviour built on top of distributed-process. Congratulations!
It's kind of funny how all languages without IDE support claim that their language is so great that it doesn't need any IDE support ... RIGHT UNTIL the point in time where the language gets IDE support and every proponent reverses his/her opinion, silently.
What do you miss, compared to Scala's :j, :t, :k (and maybe :power)?
Rapidity and clarity of initial development, ease of long-term maintenance, "leveling up" of talent, efficiency, concurrency, parallelism, only "just works" language out there, makes it easier to recruit high-leverage talent, enhances loyalty of existing labor because they won't want to go somewhere that doesn't use Haskell after having learned it. Quality of libraries &amp; depth of ecosystem foundations. (ie, not twenty-something web developers making a community has an advanced form of pyramid scheme) More predictable project time-to-completion (insofar as it's possible, unknown unknowns) once experience with Haskell is established. Represents the future of software development.
I think this is something we're all struggling with. Haskell is a hard sell not because of any technical faults but because most other languages promise much more than they can deliver. There are too many people who say, "We should all switch to X. It will solve all our problems!" Which turns out to obviously not be true. Anyone experienced in the field knows to be cautious about listening to any such claims. My pitch is "Haskell let's you write better code, faster, and safer." which is dubious to anyone who doesn't already know Haskell. The even harder sell is the cost of training the rest of the team, which is extremely expensive. It took me about 1 year before I could write production ready Haskell code. It would not be nearly as difficult to sell if at least half of the team took the time to learn Haskell like you did. I highly recommend this talk for ideas on how to pitch Haskell: http://vimeo.com/72870631
Before actually using ciphers I can really recommend reading up about crypto protocols, for example in "Applied Cryptography" which is also linked as a PDF from Schneier's blog somewhere. It's too easy to subvert what you wanted to achieve using a cipher by using a broken ad hoc protocol.
Oh I see, you mean undermining of the sense of pedagogy. I actually think it would be better to teach students the virtue of restraint in using imperative code, but then again I'm heavily biased.
It sounds like your elevator pitch is fine, actually. All you need --- and you may have this already--- is a certain relaxed confidence. It's almost impossible to _persuade_ anyone of anything. But your experience as a developer they respect has value, and you're not alone. By the time they meet the third person who tells them that Haskell is awesome, it will just seem like a fact. So you don't need to prove that Haskell is superior to their language of choice --- a tricky problem, and hardly possible at a party. You merely need to describe its value to you. Remember that it's their story of discovering Haskell, and not yours of talking them into it.
I heard it was specifically a node.js chipset that Intel was working on.
Hmm. Libraries really should not depend on flags to alter their functionality or APIs. It makes them not play nicely with cabal at all.
What I've been saying is just a simple observation from my own use. I've found that even after having not touched a project in a while (months) I'm able to quickly edit the code and make an enhancement. It has happened to me many times where I'm able to add a meaningful feature in only 30 minutes or so. The implications for me are really clear, it lends itself to easy maintenance.
&gt; f :: a -&gt; a Challenge accepted. f = error "now what, punk!?"
I usually just say something along the lines of "It doesn't get in my way when I try to write code. With many other languages, I find myself trying to work around the limitations of the language. This rarely happens with Haskell. It's just a super-high level language. What Python is to C, Haskell is to Python. But safer and faster."
It is.
I very much agree, unfortunately the problem for Haskell adoption is that quite often the development time factor is what decides language, and quite often that's not in our favor if the libraries to do the thousands of mundane plumbing tasks the make of most of industry work just don't exist or aren't up as maintained as those of other languages. It's going to vary based on domain and task at hand, but the time it takes to do some silly third-party logic authorization task in NodeJS is going to be far less time than Haskell simply because it's been abstracted out into an existing library where likely no such library exists on Hackage. We have a beautiful language and probably one of the best engineered compilers ever, but for a lot of tasks the deciding factor is whether some silly OAuth library has decent documentation and a worked example that makes or breaks adoption.
&gt; Code is what wins arguments—there is no persuasion more powerful than “I already wrote it in Haskell, Funny stuff — This same argument is actually *polymorphic* in the language used. "Oh, we don't need to write *blah*. I already wrote it in PHP. And committed it to the codebase. Without discussing it with anyone! And it even boldly assert it works, mostly bug-free."
I prefer &gt; f a = f a
Don't you get #haskell and #haskell.au up there?
It's super easy to create a new function. When writing C++, I've found myself looking at 3 pieces of identical code (3 - 8 lines) that I've just written and thinking, "I should make a little function out of that." But then I think of the overhead - isolating the code, writing the function with all the boilerplate, checking out the header file, copying the prototype into the header, blah blah blah. So sometimes I just punt (and copy/paste that identical code again later). I know I'm not the only one guilty of this. In Haskell, my experience is completely different. It's so quick and easy to factor out a function that in a similar situation, I always make a new function. And later, instead of copy/paste, I call my new function. Each such refactoring is a minor improvement, but in the aggregate, it's a big deal.
[distributed-process-p2p](http://hackage.haskell.org/package/distributed-process-p2p) is a separate library which you can optionally use; but distributed-process does not use it. It provides node/service discovery features. There is also [simplelocalnet](http://hackage.haskell.org/package/distributed-process-simplelocalnet). One thing you *do* need to select is a network transport implementation, but distributed-process doesn't link to it directly. You'll create an instance of your transport using a function from that library and use that in node initialization. Presently I think there is just the [TCP](http://hackage.haskell.org/package/network-transport-tcp) and [ZMQ](http://hackage.haskell.org/package/network-transport-zeromq) implementations. edit: to actually answer your question though - I think the right way to do it is simply list distributed-process-p2p as a dependency in your .cabal file.
When I first heard about purity, laziness, and types they all either sounded strange or a pain. That's because they are complicated features. Your audience wants "benefits". Here are some benefits. Oversimplified for their benefit. 1) Correctness. Programs that compile in Haskell are more likely to be correct. Why? The compiler is extremely smart. How smart? The compiler types almost all your type statements automatically. Wow. How did they to that? A team of really smart PhDs has been working on it for over 20 years. (They also seem like really nice people too, but DON'T mention that. It will kill your credibility with ruby and c++ programmers ;-) 2) Speed. Haskell programs run really fast. Faster than Java, nearly as fast as C. Way faster than python. Why? Haskell is compiled and statically typed, just like C++ ;-) 3) Ease of refactoring. On a large project the compiler is so smart you just start making changes and the compiler tells you where to make the next change. 4) FB is using it. 5) At the moment, all the Haskell programmers are so smart you don't even need to interview them. Just hire them. But that won't last! (See 4.) 
Thanks. I'll work on this and make some edits to the post. If you have anything to contribute, it'd be much appreciated.
I really just learned it as I went, from the people I was working with, and from the documentation for the PowerPC chips we were targeting, so I'm not really very aware of the general resources which might exist about that kind of thing. It's been quite some time since I was working on that stuff too, so I'm not sure what the current state of things is. It was a project called Coconut being worked on by Christopher Anand and Wolfram Kahl and some others at McMaster University. A lot of the applications they were specifically interested in targeting were related to realtime processing of the data from MRI machines. It's not really the same thing at all, but another quite successful project using Haskell to generate lower-level code was Atom: * [Hackage](http://hackage.haskell.org/package/atom) * [Video Presentation](http://dmcc.acm.org/pres/?query=/dmcc///confdata/ICFP2008/2008-09-26_09h56) Atom is a Haskell library for writing programs which generate hard-realtime pre-scheduled C code for embedded control systems, avoiding the need for a realtime operating system. It's been put to use in writing the control software for hybrid hydraulic systems used for large vehicles like garbage trucks. From yet another direction, there's the Accelerate library: * [Hackage](http://hackage.haskell.org/package/accelerate) * [Chapter from Simon Marlow's book about it](http://chimera.labs.oreilly.com/books/1230000000929/ch06.html) It's a high level way of specifying data-parallel programs which can then be interpreted on the CPU (a reference implementation), compiled to CUDA and run on a GPU, or more experimentally, compiled to OpenCL for the same, or interpreted with the Repa backend for parallel CPU-based computation. I really think the strategy is quite a good one in general, of writing high-level libraries which serve as special-purpose compilers or "high level assemblers" to automate the boring or tricky-but-mechanical jobs that you would otherwise have to do while programming in assembly or C. When you really get down to the *very* high performance applications where you're trying to get everything out of the hardware you have, modern machine architectures really make it quite tedious for humans to do all the reasoning required to figure out how many cycles it'll take for a program to run, while it's much less difficult for a program to enumerate a bunch of possibilities and work out the costs of each.
Consider using `lens`'s uniplate, found in Control.Lens.Plated. It is faster (even if you don't write the Plated instances by hand) and composes with the rest of lens.
Forget what everyone else is saying. They're making language-y arguments that are targeted at language nerds like us. Your audience, tho, doesn't care about all these things except tangentially. Here's the correct answer: Strong types and purity make it easier to catch bugs during development, therefore making development faster (and cheaper!), and reducing the amount of post-release bug fixing that needs to be done, freeing up programmer time to work on other problems. Haskell lets you *get more work done* by way of *producing better code*. This is what VPs and CTOs will care about.
Haskell is not always faster than Java.
You have to be able to quantify it. I'm learning Haskell solely because my intuition convinces me it will be important. But you have to be able to say things like: Using Haskell will reduce overall development time by x percent as compared to C, python, java, etc where x is a significant improvement over existing languages. In other words, you have to be able to answer the question using metrics that the other "side" will respect. An executive generally won't care about the great type system, or the conciseness of functions etc. You can explain the reasons why Haskell is better afterwards but nobody will care until they understand/appreciate the bottom line 
The training and talent acquisition are points that have come up with a CTO friend who *likes* Haskell. Thanks for the vid. 
This is a good point. I try to stay away from the language-feature points, instead referring to readability and maintainability. Thanks.
I think pandoc is too big for beginner-indetmediate. Perhaps something like hakyll is more appropriate - also because it is conceptually simpler to understand the problems its trying to solve.
Haskell takes time, but you learn how to conduct software architecture from a function decomposition mind-set/philosophy. It gives you a "third-eye" that allows one to see farther into the architectural implications such as reuse and composability. This you won't get from imperative languages, and it can be applied to those later. I think this is the single most important advantage that outweighs all the others. There are possibly some other ideas at work here besides function decomposition - such as category theory and abstract algebra. After about a year of use, I'm still acquiring powerful language-neutral insights, originating from Haskell.
While many of us enjoy the "levelling up" aspect, I think a lot of people view it as being synonymous with "difficult", " impossible to be good at", etc. which are all bad things in the context of a pitch in a business.
Are you saying that the zero padding is a bad idea? Edit: Could not find the PDF for applied Cryptography but did find this guide online: http://www.di-mgt.com.au/cryptopad.html That suggests to me that I should change my method of padding generation so that it is less predictable. I like the suggestions that it makes.
Enterprise: powerful type system and purity lead to stronger guarantees, less bugs, and surprisingly good optimizations. Startup: Expressive language leads to fast prototyping. Program by writing the type signature and filling in the type holes, it practically writes itself. Engineer: Haskell is an elegant language with extremely strong support for abstraction.
He did ask for an elevator speech. To be absolutely correct, add: "If the function is total" to the claims. This is still a huge step up from arbitrary side effects. Related: [Fast and Loose Reasoning is Morally Correct]( http://www.cse.chalmers.se/~nad/publications/danielsson-et-al-popl2006.html) 
[uwotm8](https://i.chzbgr.com/maxW500/4351471616/h7A93B70D)
It's important to know the criteria that your target audience is going to be applying. In this case, VPs and CTOs won't much care about what the language is like, but rather, what it offers to the company in terms of maximizing productivity, reducing costs, etc. Any language that can allow the company to get a working product out there more efficiently is better. Everything else is irrelevant.
I'd pitch two features: (1) The stronger type system catches errors in compilation that other languages would require handwritten tests to catch. This saves substantial development time. (2) Unlike OO systems, the ways you assemble software components is based on sound mathematics - Category Theory. This lets you assemble code components together with a substantially smaller risk of unmaintainable spaghetti code. Together, you can do much better than traditional languages. For example, you can write code that the type system shows to have no side effects, and then safely run that in parallel across multiple cores with a trivial amount of work. EDIT: When you're feeling confident enough to add a little snark, maybe toss out the fact that compiler technology have developed a lot since the 1970s, and that compilers should now be doing a lot more of the grunt work (i.e. type checking) than they did then.
Oh yes, I intended mostly to make a joke.
XMonad is often mentioned when people ask for this.
When on the contrary, Haskell is a marketable job skill at a small number of *really really good* companies. :)
Yes, but then you'd need to be allowed to use the language to solve problems at your job (or project, ...) first. If you are not allowed to code in it, then either you need to duplicate work by recoding in your free time (and why would that be useful, you already solved the problem (as far as they (boss, manager, colleague) see)) or you need to force it down their throats. Neither approach is reasonable in a professional environment. Also, if you had time to redo that thing in your spare time, why did you not solve another problem in that same time?
I disagree, while pandoc is huge, most parts of it are very self contained, I managed to extend the rST parser without looking at more than two different modules. Hakyll on the other hand is fairly complex and intertwined, as a fairly experienced haskeller I had quite some trouble working on the source. 
...so what? Haters gonna hate :-)
1. It's true. For many areas where raw performance matters (games?). 2. Also true. Many libraries do not exist, lack documentation, are one man hacks or just simply don't work. 3. VIM is not an IDE. The only real Haskell IDE (written in HAskell ): Leksah, is already dead. 4. This is a direct reflection of point 2. There are no programmers so there are no libraries. Ever tried to set up SDL2 on Windows for Haskell (do a real job, something beyond monad masturbation)? Programming language is only this: a language - another layer to deal with when all that you need is to automatically send couple of emails to some subscribers. 
&gt;and the inevitable question comes up: "why Haskell?" You're lucky. I dream of having anyone I work with ever ask me "why" any of the stuff I'm into.
It's not object-oriented. People in industry are so indoctrinated into believing that OO is a silver bullet they think that any non-OO language is not suited for the "real world".
I'm quite eager to learn Haskell. [Here's me playing around](https://gist.github.com/gfixler/11363259), getting my feet wet 2 months ago. I found it fun, but in a kind of dry way. It felt like very nice syntax for defining things like recursion, and I really appreciated the elegance and terseness of pattern matching, etc. However, I still feel a [perhaps imaginary] huge divide between the little blips in my gist and anything big and useful. Also, I've been reading articles, wiki entries, haskell tutorials, and watching hour-long talks (5 by now, at least) on monads, and I still don't *really* grok them. I know *so much* about them now, but I still couldn't describe them, and I've never made or used a monad. One of the more frustrating things is that all of these things start out feeling easy, then become hard to follow, but more importantly, none of them feel at all related to the others. I feel very few common threads between any of the resources on learning about monads. It's like each seems fairly reasonable, even if I can't grok it all, but nothing each one is talking about seems to have been touched on in any way by any of the other sources. It's all disjointed information in theoretical pockets all around me. Brian Beckman's talk felt nothing like that burritos thing, which felt nothing like that spacesuits thing, which felt nothing like that 'gonads' talk (didn't make it through that one), and none of them feel like wikipedia's entry on it, and the Haskell sources also feel like whole new sets of information, and my coder friend who gets them explained them in yet another entirely new way to me. I have no grand, unified theory of monads in my head; I have only crazy babbling from 20 different people's minds, none of it related to any of the others. It's a phenomenon now for me. I'm likely the most interested in this level of coding at my office (maybe a couple of others - some folks have that deeper, CS interest), and I've been reading for awhile now, and I'm still just not there. It's not like Python, or Ruby, or even Clojure, which I could pick up and start doing all manner of things with in the first hour. There's much more formality, and almost 'classiness' to Haskell. I feel like I'm kicking around in my pajamas in Python, but I feel like I'm getting dressed up and going somewhere way fancier than what I'm used to when I fire up GHCI, and I don't know which fork to use (computer/placesetting pun!), or what I'm allowed to say in such polite company. OP says no one is interested, and then said "I come from a pure math background..." and I say "Well there's your problem." Do your coworkers have such a background? Do their eyes glaze over as you dive into things mathematical? Is Haskell simple to you, but very complex to them? Just food for thought.
&gt; why did you not solve another problem in that same time? Because it's your free time and you get to choose what to spend it on?
&gt; Many libraries do not exist Well, can't argue with that...
If I'm a VP or CTO, I think the following are needed to convince me: 1. A high level overview of why Haskell is better. (We already do this when we talk about purity and strong type system) 2. Case studies and Experience reports (preferably with real code examples): Prove to me that this things can work on the scale I need it to be. 3. Abundant Haskell applications: More applications means more developers, which means easier talent acquisition As it stands, We're lacking in #2 and #3, which are areas I'm trying to contribute to myself. On a side note, I would love to see more Haskell desktop applications (and mobile too!). I think many of us can attest that we've learnt a particular language (or got in this trade) because of some awesome applications we've seen. (C++ for games, C for OS, Javascript for websites). Imagine how powerful it'd be if we can say "You use XYZ a lot right? Yeah that's written in Haskell" 
what is the point of this post besides being a circle jerk? 1) it does, but not with that elitist attitude. if you start acting like you're better than someone because of the programming paradigm you use most often, that is a real problem. you should welcome outsiders, not belittle them. 2) this is an actual problem in some areas. many libraries aren't actively maintained. i can hardly think of libraries that have any documentation whatsoever, much less nice documentation. and listing types and functions isn't documentation by the way. if you want to do gui programming, don't even bother. 3) this is also true when compared to other language offerings. do you really need all that IDE tooling? i don't know, but other languages have it, i.e., all the places people could be coming to haskell from. 4) i don't know what you mean by that, unless you mean number of people programming in the language. and by extension, i guess you mean the community spirit and helpfulness. i've found that the F# community is a little more engaged in helping people and getting things done, whereas the haskell community, while nice, is much more aligned with separating themselves from "heathen" OO and imperative programmers. e.g., this post. 5) wut. due to (2), (3), and in some respects (4), i have moved elsewhere, that is to F#. i still learn about haskell and use it as a point of reference, but when it comes to getting done what i want done, F# has won out. i certainly miss the syntax of haskell, but the amount of libraries, particularly for gui programming, is highly welcomed, microsoft actually has pretty great documentation, and visual studio and xamarin are excellent IDEs. i can move about freely between windows and mac os x doing my F# learning, and so far, i've had none of the setup and documenation problems i've had with haskell.
The "pure FP is useless outside of niche applications, because it doesn't have state, but all our problems now are stateful" reasoning is still going strong, together with the "monads are just hacks to get I/O to work". It's a subproblem of #1, but probably the most important one.
Perhaps (un)related crazyness about using `loeb` strange loops to run spreadsheets: [Löb and möb: strange loops in Haskell](https://github.com/quchen/articles/blob/master/loeb-moeb.md) ([reddit discussion](http://www.reddit.com/r/haskell/comments/1qwjk6/l%C3%B6b_and_m%C3%B6b_strange_loops_in_haskell/)).
"Instead of 40 cheap devs, you have 5 expensive devs, and it costs you half as much. Your features will go up 10x quicker, in part because maintaining the codebase will be 1/10th as expensive in time." - to CFO "There's a massive pool of talent. Our latest posting on FunctionalJobs had &gt;120 qualified applicants for 5 seats even though we asked them to actually write some code to be eligible. Some of the guys were OK with taking threefold cuts in salary* just to work for us. And most of these guys are experienced with the full stack so when you pay for Haskell, you get security, dev ops and scaling for free." - to CTO But at the end of the day, I hired a "data scientist", he built many good things very fast and very quietly ("what do you mean it wasn't really built with Python and JS?"), and I got more budget to hire more like him when the noise of satisfied internal customers went upstairs. The above pitches are told to these people tens of times a week by consultants, devs ("hey, let's rewrite everything in Go! Google uses it and it's much faster than PHP!") and even opinionated people with wealth and fame. C-level people have learnt to ignore the noise and base their decisions on data. Cf last week's Game of Thrones episode when Sir Allison hands over to Jon Snow. Cf every VC/angel who says "I don't want to fund you until you have a product". *True story. But some financial institutions really do pay obscene amounts to get smart people to do boring things.
&gt; what is the point of this post besides being a circle jerk? Just posted some reflections and was hoping it would spawn some comments in the hope that some could be of help for us to increase the use of Haskell. And it did spawn comments :) &gt; 1) it does, but not with that elitist attitude [...] Well, I have stumbled upon these kinds of arguments against Haskell (and FP in general) for some years now. If reiterating them in a compiled list seem elitist I don't know how to otherwise discuss them. 2) I do agree that documentation for some packages is poor. 3) Sure, and there is IDE support in the forms of Leksah and eclipseFP. 4) My point is that I don't think lack of Haskell programmers is the problem. But some are afraid to use Haskell because there aren't as many haskell programmers as, say java programmers or python programmers. 5) This point is more of a "what's the next excuse"-kind of thing :)
&gt; It's true. For many areas where raw performance matters (games?). That's not really an argument against FP. That's an argument against anything that's not C++.
C++ is a language where you are the one who tells the compiler what to do. Most of the time idiomatic and good looking code in C/C++ is very fast. On the other side idiomatic code in Haskell is very slow. Sometimes orders of magnitude slower or does not hold theoretical complexity expectations ( O(n log n) becomes O(n^2 ), etc...). Actually the more beautiful and concise Haskell code is, the slower runs. Fast Haskell code is one of the ugliest things in the World.
I see Haskell as somewhere between imperative programming and logic programming. More declarative than the former but less so than the latter. Imperative code goes: first do this, then do that. Haskell goes: this is the definition if this and this is the definition of that. Evaluation order is not important. It is the golden middleground to me because I never really enjoyed logic programming very much. (I guess in another thread someone could write a list of arguments against logic programming posed by people like me.)
Dan Piponi also wrote a neat article on this: [From Löb's Theorem to Spreadsheet Evaluation](http://blog.sigfpe.com/2006/11/from-l-theorem-to-spreadsheet.html)
What is the difference between this and reactive programming? I often heard people using spreadsheets as an analogy to reactive programming.
The term "reactive" programming is not really that well defined. There are different abstractions that can be termed reactive, including spreadsheets, event streams or even actors. Programming with e.g. event streams you can express combinators such as "delay", which are not defined for spreadsheets, and in general you can work over multiple events from an event source. There are some different formulations of streams, based on (categorially) dualizing the synchronous enumerator interface, or by implementing something like Conal Elliott's FRP semantics [link]. Spreadsheet semantics can be derived as a special case of such an approach. There are other possible semantics for FRP (e.g. stream transformers). I think the "right" approach to FRP has not necessarily even been discovered. [link]: http://conal.net/papers/push-pull-frp/push-pull-frp.pdf
 For me, this redirects almost immediately to `http://www.findingresult.com/?dn=yourequations.com` (a bad ad?)
It seems that while the `Applicative` style is lovely for composing things in parallel, how would you incorporate choice? Obviously in games things need to change behaviour based on things that have happened in the past, but it's unclear to me if this can happen with `Applicative` (it feels like you would need at least a `Monad`).
Logic programming is about going from A to B whichever way it is possible (or not). If we assume that requirements are dynamic then speed, memory usage, latency and others are just library extensions or data descriptors for a large enough collection of algorithms. If you want speed, querying the code database will give you most performant code for a given set of constraints (if they exist in the db). The same goes for parallel or concurrent versions of algorithms. By specifying requirements compiler takes whatever is available and crates executable program thats fits the needs. These functions could be written in such low level languages as Haskell or C. I still don't understand why popular languages don't implement such trivial thing as computational complexity as an additional function description. This is one of the things that could help me a lot more to write better code than a type system. Type system is only a fancy spell-checker, compiler that is able to test and verify computational complexity of a function or a program is worth a lot more. 
Came for the trick, stayed for the wonderful discussion of the Expression Problem.
Also learned recently: tagless-final style, which eliminates the sum type and apparently tends to produce code that performs better. http://okmij.org/ftp/tagless-final/
I'm probably misunderstanding something, but the model update function in model = asPipe $ loop $ \(I i1 i2 i3 i4) -&gt; do return $ O (i1 + i2) (i2 * i3) (i3 - i4) (max i4 i1) seems to indicate that _all_ of the output cell values are recomputed when _any_ of the input values changes. It would seem more "spreadsheety" if a given output cell's value were only recomputed when the particular inputs that it depends upon changed...
Shouldn't that logic lie in the model, or have I misunderstood your MVC library?
For the meta advice: why not just start without pipes, monad transformers, lenses, etc. - it will not be as "awesome" and "abstract" but I guess it will work. After this grabe ONE of those things and try to rewrite using them. But thats just my opinion as a novice haskeller (who is surely not smart enough to put together all those) PS: a quick search found me this snippet: https://gist.github.com/owainlewis/4132852 that claims to just give you back a string - maybe that's a better starting point to get going fast without all the high-IQ stuff ;) )
I'm with you. One bad thing about all these fancy libraries is everybody thinks they have to use them. No, you can and should still write perfectly straightforward code in Haskell. If you can't understand your own code, something has gone wrong. If you can't even *write* the code, you're just going to start feeling stupid, which is really, really bad. I think this is part of why some people don't like Haskell; they are under the impression that it's not Haskell without all these crazy libraries and are missing out on how simple it really is at its core.
ECB is also insecure
Don't learn what monads are, make them :) Check out the [examples](http://www.reddit.com/r/haskell/comments/282yky/why_haskell_elevator_pitch/ci7h7z5) /u/pipocaQuemada gave and see if you can modify them. Maybe try composing some monads together with (&gt;=&gt;) from Control.Monad?
Yes, it updates all of them. This is why the final section mentions that it is not suitable for programs with expensive view computations, where you would want more granular rendering.
Are Conduit and Pipes not the right libraries for streaming HTTP? Not only were they first two recommended to me, but they both seem like they were created for this purpose.
&gt; I think this is part of why some people don't like Haskell; they are under the impression that it's not Haskell without all these crazy libraries and are missing out on how simple it really is at its core. I just had that discussion with a friend and this applies to him at least. When I showed him the core of Haskell and said, "The rest is pretty much just libraries" he wouldn't believe me at first. Then I reimplemented a lot of the things in the libraries using just the simple core I had shown him, and he was blown away.
I do try to start simple, but I don't think what you're suggesting *would* work. You're right that the easy versions of all the HTTP APIs always just return the complete body, and you're right that that's easier to work with, but it's also a different problem. I was trying to work with a streaming HTTP response, and working with an API that downloads the whole body doesn't seem to get me any closer to a solution. :) I think the advice is solid in general, though. It's just that often problems don't decompose to the cases that are easiest to work with in basic Haskell. And then I'm stuck trying to understand libraries like Pipes.Text.
I also forgot to mention that you can actually take the `Fold` logic and use it directly within the `Model`. This is what the `updates` function is doing internally as a convenience, but you could do it manually if you wanted to.
Both pipes and conduit don't really hide from you that they are implementing coroutine monad transformers, and until you can hand on heart say that you get all the material in the pipes tutorial, going off and using joe random pipes library is going to be a pain. Ditto for conduit. The composition operators for both don't hide the underlying types from you (I wish ghc could do a better job with that) because the 'nicer' types are just synonyms. If I were you I would use good ol' lazy io, then gradually layer in the fancier stuff once I had a working lib. Pipes takes a bit more intellectual effort than say generators in python, but it's more general and it's hard to hide that.
The equivalent would be if you and someone else are each maintaining programs of similar scope written in different languages. When someone suggests a feature that you think is a great idea 6 months since the last time you touched the application, how long does it take you to add that new feature? Especially if it requires changing an underlying assumption in your program, this is where Haskell *really* shines in a way that's obvious to observers.
Some suggestions: * [parsec](https://hackage.haskell.org/package/parsec) * [scotty](https://github.com/scotty-web/scotty) * [hlint](https://github.com/ndmitchell/hlint)
You're welcome.
every video on youtube (and vimeo and many other sites even including skillexchange) can be downloaded with youtube-dl.
Aren't Haskell sum types finally tagless under the hood anyway? I got that impression by reading the paper on STG.
I'm just wondering if `Updatable` might encourage too much logic in the controller. That was basically my first thought on your block post.
Good point about the link, I've edited it. This is my personal machine, on my home network. Checking with `wget` (bypassing my ad-blocking proxy), the page includes a line &lt;script src='http://tex.yourequations.com/' type='text/javascript'&gt;&lt;/script&gt; and `tex.yourequations.com` is now just a domain landing page, with a javascript redirect to the `findingresults.com` page. I've added yourequations to my proxy's blocklist, and it works now. This is the only website I've seen this problem.
I get mostly empty document for tex.yourequations.com &lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body&gt;&lt;!-- vbe --&gt;&lt;/body&gt;&lt;/html&gt; Given the url however there is a possibility that sigfpe was using a script previously located at tex.yourequations.com to render tex code but the domain expired and was bought by someone else. You up for sending an email to the author to look into it? If not I will.
This is why I wrote my other comment: you can manually unpack the final `Updatable` value to get back the `Controller` and `Fold`, and use the `Fold` to build your model. It only moves the logic into the `Controller` if you use the `updates` convenience function.
Well, isn't a significant part of the point of separative M &amp; C that the code is separated? Because it seems to me that with this approach, you still end up with too much logic in the controller, you just tear it apart at runtime and put it in the model there.
The goal of `mvc` is equational reasoning, not separation for separation's sake.
I still appreciate the discussion and feedback. I had the same reservation, too, when I was building it, but I felt it was worth releasing since I thought some people might draw inspiration from it.
Because that particular streaming library is much simpler than the others.
https://github.com/bitemyapp/learnhaskell I have no degree, no mathematical background, have not studied math. Before Haskell, I mostly used Python and Clojure. Stop reading/watching monad tutorials by people that don't understand monads or how to teach them. (Crockford, Beckman, et al.) Haskell is not difficult, it is unfamiliar. Use the guide I've been using to teach Haskell. Ping me if you need help.
A lot of the essential libraries have very small cores that have been lost to the past in favor of making them robust. For example I think the original monad libraries were far easier to teach before mtl and transformers. 
*Some things* require more work precisely because the abstraction is simpler. More work != harder to understand.
I had it too. First, to get HCodec installed, I used *cabal get* and I had to modify its source to get it compiled. (It was really simple, though.) But then I ran into a bug in *music-suite*: https://github.com/music-suite/music-score/issues/263 On the bright side, looks like the HCodec dependency will get removed: https://github.com/music-suite/music-score/issues/267
Things that are simpler almost always take more work to *use*. Because they don't have any complexity built-in, and your use case probably has some complexity to it. But it is usually easier to figure out how to build something out of simple things than it is to figure out how to build it out of fewer complex things, even if it's a bit more "work". What's actually more work--typing a few more characters, or racking your brain trying to fit weird type signatures together? Programming work is primarily done with your brain, not your fingers. I'm not saying you shouldn't learn to use Pipes or whatever, but it's best to master the simple stuff first, as it will make it a lot easier to master the more complex things.
Oh I realised that was the intent behind including that line. My response was what I would say in that situation.
The "tagless" usually refers to not tagging types. Sums still need tagging, as you can't (in general) statically tell what branch of the sum you're dealing with. As Haskell is lazy, you also have to store yet another thing: The evaluation state of something. Is it already in normal form or not? AFAIU GHC didn't use tags for that for a long time but function pointers, and they switched to tags because indirect jumps aren't exactly fast, on many architectures (especially if the architecture isn't smart enough to prefetch the jump). [Here's how it currently works](https://ghc.haskell.org/trac/ghc/wiki/Commentary/Compiler/GeneratedCode), and that involves tags.
Kinda related: I don't really believe FRP is 'solved' until we have fixed the big-state-node problem.
The tagless of "Tagless Final" refers to not having the syntax of your DSL represented at run-time via data constructors of a sum type but rather by a type class signature. The tagless of "Spineless Tagless G-Machine" are referring to how unevaluated thunks are stored.
I still think the best abstraction for this purpose is to use morphisms of type: a -&gt; ListT (State s) b ... and `zoom`. You basically limit each morphism to the minimum state it needs, then you unify them to agree on a common global state using `zoom`.
The thing is that Behaviour+Eventually (not Event) is the Curry-Howard of linear temporal logic, so it 'should' work well. Unfortunately it doesn't work as well as one would think.
I accidentally put https - if someone could change it to http, I'd be really grateful. http://www.thesoftwaredevelopmentlifecycle.com/?p=401
I'd get rid of the talk by Beckman.
I am waiting for this dependency change.
Last time I've heard of people encoding linearity inside haskell, I think they were using type positions instead of IDs. Something like this: produce :: Unique xs (a,xs) a consume :: a -&gt; Unique (a,xs) xs a liftU :: Unique xs xs' -&gt; Unique (x,xs) (x,xs')
&gt; I did no such thing. Explaining why you believe something does not demonstrate that the something in question is true. My argument was that tasks have some essential complexity to them; simple tools must be combined properly to meet the complexity of the task. That requires some extra typing, but is hopefully straightforward; if not, then perhaps the tools were *too* simple for it to be clear how to combine them. Complex tools already have the necessary complexity built-in to accomplish a certain set of tasks with a minimum of extra construction required, but it may not be clear how to apply them to a particular complex problem. You seem to be stuck on the `io-streams` vs `pipes` comparison. I was just making a general comment about the tradeoffs between simple and complex tools. I did not give my opinion on which of the two libraries was simpler.
I have never used the Pipes library, so I'm as much in the dark as you are. However, as an experienced haskeller, I am confident that I can figure it out, and as I do so I'll write down all my steps [here](https://gist.github.com/gelisam/c769d186493221d7ebbe). My apologies for the length of that document; like you, it had to work on it for hours, so there is quite a large number of steps. It's a long read, because I don't know which of those steps are likely to be helpful to you, but I hope there is something in there you can learn from!
FYI, your site doesn't work for me on android. It seems like the background image is being drawn over the content.
Thanks! It should be fixed now.
I think a better argument against this sort of alignment is that it can create worthless diffs if you need to add a new line or rename something.
&gt; I think you are conflating "more specific" with "simpler". IO () is not simpler than Monad m =&gt; m (), it is just more specific. Is this another subtle distinction like ["simple vs easy"](http://www.infoq.com/presentations/Simple-Made-Easy)? From what I remember from that video, Rich Hickey defined "simpler" as "having fewer moving parts". Is this also the definition of "simple" you are using? After watching the video, I thought I now understood what "simple" meant, but your example makes me doubt, because `IO ()` does seem simpler to me (as well as more specific). Thanks!
Ok, I will let you continue conversing with yourself then. Have fun!
I'm also a fresh Haskeller, so I'm not sure my advice is useful, but I can pass along a few things that have helped me sort things out. &gt; The first step is splitting a streaming HTTP response into lines I've found I have the easiest time when this is the *last* thing I do. Writing a pure core, quickchecking it, and playing with it in the REPL lets you get a sense for the shape of the program without dealing with the effectful machinery. Once that code starts making sense, you can start dealing with all the context around it one chunk at a time. (The whole point of pipes is that you should be able to decouple this stuff, so you might as well take advantage!) &gt; Pipes claims to have second-to-none documentation, though Pipes.Text doesn't. I've found a lot of popular libraries that seem to have crummy documentation because they assume you can recycle your intuitions for the types / typeclasses they use. In this case, Pipes.Text is assuming you already grok pipes, pipes-parse, free monads, and lenses. (According to the docs at https://hackage.haskell.org/package/pipes-text-0.0.0.11/docs/Pipes-Text.html plus my primitive knowledge of the pipes universe.) Which is incredibly useful when you know the abstraction, since there's almost nothing else to learn, but is an obvious problem for those who don't. When I don't understand something, I've learned to look for these things and use them as jumping-off points to do some reading. When I don't feel like reading, I've had surprisingly good luck trying to get the minimal piece that typechecks and then going back and trying to figure out what it's doing. Haskell being Haskell, compiling code almost always does something *meaningful* -- and I find it easier to generate a few of these and *then* abstract away from it to understand the primitives, instead of trying to frontload all the theory and then bang the code out.
That sounded painful. I would have spent a day on this, probably.
I apologize for the terrible pun. I guess I was being lazy when I posted -- but Haskell is a lazy language, and thunks are in fact the means by which that laziness is implemented. :P
haha man really could have used this like a week ago before my cloud-haskell-based project was due. excited to check it out tho
More write-ups like yours could be a useful tool for library authors to "tune" their tutorials and documentation. By the way, [Hayoo](http://holumbus.fh-wedel.de/hayoo/hayoo.html) indexes more functions than Hoogle.
While I like your mindset with wanting proof and all that, I think you might have suffered a misunderstanding here. /u/mightybyte and /u/pinealservo are different people. The former claimed io-streams is simpler, the latter just gave an explanation as to why simple tools can require more work. A rock requires more work than a hammer, a bike requires more work than a motorbike, an assembly language requires more work than a C, and so on. (Of course, for everything, certain assumptions are meant to be in place, including about what task is to be performed.)
Technically, IO () has fewer moving parts, because you get rid of the whole dictionary passing thing.
That's a really cool summary. I need to start doing that when I figure stuff out.
Isn't that what arrowized FRP is? There is no "big state", because everything is locally stateful. To me the problem isn't solved until we can keep using that technique *and* have push based semantics where it makes sense. From what I've seen, we only have pull based AFRP, which incurs lag and is extremely wasteful computationally.
Monad transformers are a PITA. In C you can just write imperatively without having to deal with all these lifting, performance, extensibility and library zoo issues. Haskell community still hasn't found a satisfactory way of combining effects.
I think a search option would be nice to implement. I have a bunch of haskell-related bookmarks myself, I want to submit them, but don't want to create duplicates.
I know this is a little late, but I think this is important. You should never do your own crypto! It is too easy to make mistakes. Pick a packaged solution whenever possible, and if you must do it yourself you should use a tested combination of ciphers, in the case of symetric encryption AES-GCM mode or AES-CTR mode with HMAC of ciphertext.
But it's not really a problem in the case when the whole package contains nothing but type instances.
Sure, in principle I agree with your advice, but what Haskell libraries should people use then to make this possible? I think this discussion would be more valuable if people that read it in the future had a course of action that they could take.
I agree. I mention that better methods will be explored in a future guide: &gt; We will just stick to simple ECB encryption and leave other encodings for a future guide.
In the case of cryptography it pays to be conservative. It is actually common to run gpg in shell for encryption, because that way you don't have to do it yourself. If I needed encryption in a Haskell library I would interface with an existing C library. This does not mean I don't think it is a good idea to develop native libraries for Haskell, I just think it needs to be said that you shouldn't do your own crypto. That we are even talking about modes of operations is a sign that we are too low level.
 produce :: a -&gt; Unique '[] '[uid] (Value uid a) consume :: Value uid a -&gt; Unique '[uid] '[] a How would this let you produce a second 'new' value? At the least you need to have it grow the list. produce :: a -&gt; Unique uids (True ': uids) (Value (Length uids) a) consume :: Value uid a -&gt; Unique uids (Use uid uids) a Of course here its awkward that we're working from the start of the list but counting from the back, and you need Length and Use type families to edit the list and turn the right entry from True to False. Also notice how consume needs to actually take a `Value`, not an `a` itself.
Thanks for the fun exercise, I've often seen linear types mentioned and briefly pondered how do-able it would be. Here's my attempt at doing something similar: http://lpaste.net/105618 * We use the same way of attaching refs to the monad like in ST. * Similar way of appending IDs and deleting them from a list. * Differing way of deleting from a list, I delete when `consume` is called with `delete`, you delete on the bind with `\\`. I'm not sure whether there's a difference. I've noticed that with explicit type annotations, it accepts: pPcC :: LinearT Z (Proxy Nil) () (S (S Z)) (Proxy Nil) () pPcC = do x &lt;- produce "Hello" y &lt;- produce 3 consume x consume y return () But without the explicit type annotation it's ambiguous. Maybe someone could make it inferrable with some more cleverness. But this isn't a bad start. I see that the same code works fine if immediately run: λ&gt; runLinearT (do x &lt;- produce "hello"; y &lt;- produce 3; consume x; consume y) 3 I note that it's also fun to change the type to: LinearT Z (Proxy Nil) a (S Z) (Proxy Nil) () In effect that allows you to restrict how many references someone produces inside the action. The `Nil` at the end forces every one to be consumed. Likewise, specify LinearT Z (Proxy Nil) a (S (S Z)) (Proxy (Cons (S Z) Nil)) () And it forces them to make two produces but only one consume, leaving the other produced untouched. Maybe a later computation will use it. That's pretty neat. 
&gt; How would this let you produce a second 'new' value? The key to that is in the bind operation: (&gt;&gt;=) :: Unique cs ps a -&gt; (a -&gt; Unique cs' ps' b) -&gt; Unique (cs ++ (cs' \\ ps)) ((ps \\ cs') ++ ps') b For example: produceTwo :: a -&gt; b -&gt; Unique '[] '[uid,uid1] (Value uid a, Value uid1 b) produceTwo a b = do x &lt;- produce a y &lt;- produce b return (x, y) consumeTwo :: Value uid a -&gt; Value uid1 b -&gt; Unique '[uid,uid1] '[] (a,b) consumeTwo x y = do a &lt;- consume x b &lt;- consume y return (a,b) example :: a -&gt; b -&gt; Unique '[] '[] (a,b) example a b = produceTwo a b &gt;&gt;= uncurry consumeTwo This compiles against the gist.
This is exactly why I can't stand 'just follow the types'. Thanks for the excellent write-up!
monad tutorials: not even once
Did not work for me unfortunately. Probably did something wrong though. Oh well :) Will try it again some other time. I have already put way to many hours in getting any of the GUI frameworks working.
I just started using cabal as a build system after coming from a project where I was using the GNU Autotools chain (autoreconf &gt;&gt; configure &gt;&gt; make). Setting Autotools up for the first time is like some kind of witchcraft, where you can have a cabal build system up and running for small projects in a couple of minutes. It is like a breath of fresh air. Yeah, Autotools is really powerful, but it needs a cabal-like ease of setup to bring it into the 21st century.
I'm not so sure anymore. While waiting for haskellnoob (what a misleading username...) to reply, I tried to imagine how `Monad m =&gt; m ()` could possibly have fewer moving parts than `IO ()`, and I found that it's not even clear which moving parts are meant: * `IO ()` computations are made of a large number of primitives, while `Monad m =&gt; m ()` only has return and bind. * A value of type `Monad m =&gt; m ()` represents many possible values, one for each concrete monad `M` we choose to substitute for `m`, while a value of type `IO ()` represents only one computation. * That one computation could behave in many different ways at runtime, whereas the value of type `Monad m =&gt; m ()` is pretty much guaranteed to just return `()` without doing anything else. * The type `IO ()` consists of a concrete type constructor, the unit type, and a type application. The type `Monad m =&gt; m ()` consists of a concrete typeclass, a type level variable binding, a type-level constraint, the unit type, and a type application. So I guess `IO ()` is simpler than `Monad m =&gt; m ()` in some ways, while more complicated in others.
There's always https://github.com/jwiegley/simple-conduit too.
That's because in C you can't provide rough-sketch specs for your program. Which is all good and well if you want to do stuff your computer can do automatically, but some of us would rather get on with working, and keep out masochistic tendencies in the bedroom.
&gt;I've found I have the easiest time when this is the *last* thing I do. Writing a pure core, quickchecking it, and playing with it in the REPL lets you get a sense for the shape of the program without dealing with the effectful machinery. Once that code starts making sense, you can start dealing with all the context around it one chunk at a time. Can't agree more! I've found this style of development works well for many languages and paradigms. In my experience: C#, ColdFusion, AngularJs, and Haskell of course. If things feel too complicated, they probably are. Retreat into the abstract bits of your system: the datatype declarations, the core algorithms. Then build outward to IO. This development style helps me not to loose my mind.
I tried something similar a while ago: https://gist.github.com/copumpkin/9967290
and? php sucks but in the end people care about what is created, not how it is created
Just refresh the page
...and your CTO will take the examples above and write some code to show you how he's trying to enter the brave new world... cto: "I wrote some functions to transform Strings" you: "don't use Strings. use Text" cto: "what? all of the educational material uses Strings. aren't they the default character sequence?" you: "yes but they are awful" cto: "remember when you told me haskell was perfect?" you:.........try OverLoadedStrings! cto: "I thought you said haskell didn't have nasty hacks?"
(2) is a fantasy. for any given problem, compare your *first pass* implementations in Java, Go and Haskell. almost certainly, Haskell will place a distant third, probably slower than perl. yeah yeah, /r/haskell and haskell-cafe are very helpful, but most people want good expected performance from moderate effort. /r/haskell is full of posts asking "why is this 5x slower than..."...and the solution is almost always relatively obscure your "boss" will eventually notice that haskell requires a much bigger time commitment to deliver the performance you would get from a first-pass in Go, a language any programmer can become productive with in just a couple of weeks
Ah, I didn't know about this tool! However, I think what I'm looking for is more likely to be found in some kind of project, rather than a library. I will have a look at what this shows, in any case.
I think you would always want more granular rendering. It's not really reactive or spreadsheet programming if you always loop all. 
s/not always/hardly ever/
base is great, Prelude was designed around now antiquated priorities and can (and should) be fixed.
There's something missing from both your explanation and the OP: what did you both want to do with those lines?
Hayoo looks great
Perhaps I can help. If you haven't already read this, you should read the `pipes-group` tutorial. All the lens and `FreeT` stuff is explained by that tutorial: http://hackage.haskell.org/package/pipes-group-1.0.0/docs/Pipes-Group-Tutorial.html I apologize that tutorial is not very discoverable. I should mention it in the documentation for `pipes-bytestring` and `pipes-text` (technically I only maintain `pipes-bytestring`, but I will also forward this to the maintainer of `pipes-text`). Second, you need to clarify what you are trying to do with the split lines. For example, let's say that you wanted to append an exclamation mark to the end of those lines. The solution using `pipes` would be: {-# LANGUAGE OverloadedStrings #-} import Control.Applicative ((&lt;*)) import Control.Lens (over) import Pipes import Pipes.Group (individually) import Pipes.ByteString (stdout, stdin) import Pipes.Text (lines) import Pipes.Text.Encoding (utf8) import Prelude hiding (lines) main = runEffect $ over (utf8 . lines . individually) (&lt;* yield "!") stdin &gt;-&gt; stdout Unfortunately, `individually` only works with the `lens` library, but if you prefer to use `lens-family-core`, you can instead write: over (utf8 . lines) (maps (&lt;* yield "!")) stdin &gt;-&gt; stdout This is mainly a limitation of `lens-family-core`, which uses a custom type instead of `Identity` (and I've petitioned Russel to fix this). I'm also working on a cookbook for these things, if that will help.
still happens after refresh. Goes away after a minute.
It's no different from other industries. Who cares if you make a good product as long as you make a lot of money off of it?
Yes, and furthermore Haskell makes it so hard to put backdoors (security defects) into your program. C makes this so much easier!
C has the IO type exclusively. You can program Haskell via IO exclusively too, and get code with certain similarities. But transformers let you do some nice things that C doesn't, indeed at the expense of convenience. * Transformers let you give nicer types that bind the behavior much more tightly * Transformers give you much more *power* than C (e.g: generators, exceptions, parsers, non-determinism, etc) 
Back when I experimented with postgresql-simple I wrote a few examples. You might be looking for something more realistic, but here's the article: http://blog.begriffs.com/2013/09/haskell-postgresql-simple-examples-part.html
Hackage doesn't just host libraries, it also hosts executables. In the reverse dependencies, I see that both amazon-emailer and hpaste are tagged as "programs", for example, and neither exports any module.
This is of value. /u/changetip $10
The Bitcoin tip for 17.886 mBTC ($10.01) has been collected by gelisam. **[What's this?](https://www.changetip.com/tip-online/reddit)**
I'm surprised to see how many people read through the whole thing! It's really long and boring, and probably only of any use to the OP. &gt; More write-ups like yours could be a useful tool for library authors to "tune" their tutorials and documentation. Except as you can see, I didn't spend any time reading tutorials, and only a small amount of time reading the documentation. Perhaps that was my mistake! **edit**: wow, many people seem to have found it non-boring after all! My post even has [its own Reddit thread](http://www.reddit.com/r/haskell/comments/287jx3/understanding_the_pipes_library/) now!
This is the first tip I've seen on reddit that's been over $0.01.
&gt; what did you both want to do with those lines? I wasn't interested in the lines per se, I was interested in connecting the three pieces which the OP had identified.
The [persistent-postgresql](http://hackage.haskell.org/package/persistent-postgresql) library is based on postgresql-simple. If you spend about 20 min. poking around the overview of [persistent](http://www.yesodweb.com/book/persistent) just to get a basic idea of how it works, then dive into the source code of the postgresql backend in persistent-postgresql, you'll get a solid view of a working library that uses most of the important features of postgresql-simple.
This is very old stuff. But I assume you re-posted it in the context of the [current thread linking to Tekmo's post about this](http://www.reddit.com/r/haskell/comments/284enc/haskell_for_all_spreadsheetlike_programming_in/).
Yes, Dan even explicitly shows the connection with `Applicative`. This was 8 years ago! I see that there is a new [reddit thread](http://www.reddit.com/r/haskell/comments/284s9q/from_l%C3%B6bs_theorem_to_spreadsheet_evaluation/) about Dan's post.
Yes; I was surprised this wasn't posted here already.
Just +pipes in the search in hoogle would have [yielded](http://www.haskell.org/hoogle/?hoogle=%2Bpipes+%3E-%3E) what you wanted. People run into this time and time again, I wonder if there isn't some better way to advertise how hoogle works.
[Hayoo](http://holumbus.fh-wedel.de/hayoo/hayoo.html) searches everything by default. 
And I didn't even know it was possible to receive tip on reddit! Thanks, @sfultong!
The problem is that your code doesn't run in constant space and will break on lines of infinite length, so that greatly reduces the benefit of using a streaming library. Here's an example of transforming lines in constant space (in this case adding an exclamation mark to the end of each line), using `pipes`: {-# LANGUAGE OverloadedStrings #-} import Control.Applicative ((&lt;*)) import Control.Lens (over) import Pipes import Pipes.Group (individually) import Pipes.ByteString (stdout, stdin) import Pipes.Text (lines) import Pipes.Text.Encoding (utf8) import Prelude hiding (lines) main = runEffect $ over (utf8 . lines . individually) (&lt;* yield "!") stdin &gt;-&gt; stdout That will work on large or infinitely long lines without any issues. Edit: People more interested in this topic should read my [announcement post for `pipes-bytestring`](http://www.haskellforall.com/2013/09/perfect-streaming-using-pipes-bytestring.html) which discusses why `pipes-bytestring` is designed this way. There are many features of `pipes-bytestring` and `pipes-text` which have no `conduit` counterpart. For example, taking the first ten lines of input is just: over lines (takes 10) stdin &gt;-&gt; stdout Try doing the equivalent thing in `conduit` such that it doesn't break on large lines.
If `gelisam` can provide details on what he was trying to do, I can give more insight onto what the idiomatic `pipes` approach is. For example, right now he's just breaking things up into lines and then concatenating them back together. The idiomatic `pipes` approach to do that is just: over lines id stdin &gt;-&gt; stdout ... and the lens laws say that `over f id = id`, so that just reduces to: stdin &gt;-&gt; stdout Of course, that's not a very interesting program, which is why I need to know what he was trying to accomplish.
Is that even in the [manual](http://www.haskell.org/haskellwiki/Hoogle)?
Like I said in my side note, there are problems with `linesUnboundedC`, and the right choice of proper abstraction will depend on what you really want to do. In this case, `lineC` and a helper function for looping until data is exhaustive is the best approach: {-# LANGUAGE OverloadedStrings #-} import Conduit import Network.HTTP.Client.Conduit main :: IO () main = withManager $ withResponse "http://www.yesodweb.com/" $ \res -&gt; responseBody res $$ decodeUtf8C =$ forever' (lineC stdoutC) forever' action = do mx &lt;- peekC case mx of Nothing -&gt; return () Just _ -&gt; action &gt;&gt; forever' action I'm not certain what your code snippet is doing, but if I'm correct in my guesses, this is the same concept: import Conduit import Network.HTTP.Client.Conduit main :: IO () main = stdinC $$ forever' (lineC $ concatMapC (\x -&gt; [x, "!\n"])) =$ stdoutC forever' action = do mx &lt;- peekC case mx of Nothing -&gt; return () Just _ -&gt; action &gt;&gt; forever' action There may be details I'm missing here, however.
This looks like an attempt to understand a large cathedral-like library bottom-up: looking at a source code using it, and sniping at the used pieces to get their types and try to guess what they do. This is an interesting approach and the resulting log is useful, but it should also be clear that this is probably *not* the best way to get familiar with a complex library on a highly specialized problem domain. A better approach would be to start reading the tutorials and documentation provided by the library (and if there aren't any, to complain to the author about it), to form a reasonable understanding of the core concepts and abstractions, and only then look at the code you want to work with.
Which is useful! On the other hand it doesn't do some of the cleverer type expansion, so searching by signature doesn't really work well at all.
There are two issues with your solution: * You had to define a custom one-off combinator (`forever'`) to get it to work. The reason I find this unsatisfying is that if you require ad-hoc looping combinators then you may as well skip the streaming library entirely and ask the user to write all of their streaming code by hand using these ad-hoc looping combinators. . * Your solution is does not generalize to more complicated problems. For example, it doesn't solve the second challenge I raised for how to forward only the first 10 lines. I would like to move away from narrow and disposable solutions towards more reusable abstractions.
No it doesn't, it provides unsafePerformIO specifically for such cases.
The main reason I asked is that the idiomatic way to do this in `pipes` is: over (utf8 . lines) id stdin &gt;-&gt; stdout ... but that's the same thing as: stdin &gt;-&gt; stdout
Transformer types are mammoth-sized and very hard to change. They also require writing complex unwrappers. And monad stacks are order-dependent. And not every monad transformation is a monad. Where is the power in all that?
Rust also, if you're willing to wait a year or two for it to become stable (perhaps after you learn it). Then again, this is a community of Haskellers; we *like* strange new languages that offer solutions to hard problems.
It sounds like you simply haven't used transformers correctly. When used correctly, the fact they are order dependent is a feature, not a bug. You sometimes want ListT of Either and sometimes EitherT of List. Both are different, useful monads. If you simply wrap your monad stack in a newtype, and provide lifters (or classes) to access the various layers *by name*, then it becomes trivial to change. All valid monad transformations are themselves monads. The power of combining arbitrary transformers in various ways is immense.
With a fold. `foldl (\n _ -&gt; n+1) 0`. Or alternatively, `sum . map (const 1)`. If you don't understand point-free style: length l = foldl (\n _ -&gt; n+1) 0 l length l = sum (map (const 1) l)
Thanks!
Completely unrelated to the topic, but most of the steps would be much easier in an IDE like visual studio. That whole ghci goo is exactly what good IDEs are for.
The point of unsafePerformIO is to create backdoors/security defects? What a sinister design.
I think what was tripping me up was that folds themselves are inherently recursive, so I thought my answer couldn't include them. I was wracking my brain trying to determine a solution that was non recursive at any level without manually defining an infinite integer set.
I think what is meant is defining it without explicitly using recursion. These kind of exercises usually come in tandem with the introduction of higher order functions. There should be something about a function which can be used to squash a list together into a single value somewhere.
I just wanted to say that your comment made "isomorphism" finally click for me. I knew what an isomorphism is from its roots (iso - equal, morph - transformation), but it never made "proper sense" to me until now. It must've been the mental image of a map between a data structure and some memory locations, everything corresponding to something. Thank you!
You should also mention `foldl'`, which runs in constant space.
However, in principle you can define a list as a fold, in which case you really aren't using recursion anywhere. Example: example :: (Int -&gt; x -&gt; x) -&gt; x -&gt; x example cons nil = cons 1 (cons 2 (cons 3 nil)) Then you "fold" the list just by passing suitable functions in place of `cons` and `nil`: length list = list (\_ n -&gt; n + 1) 0 Notice how neither `example` nor `length` are recursive.
No, which is my fault :(. I have plans to improve these aspects shortly.
There are two things I want to do: 1) make it easier to find out that you can search for additional packages; 2) make it unnecessary by searching more packages. I'm working on both, and unfortunately to get to where I am now has taken a lot longer than I expected :(
Any reason why `individually +pipes-group` returns no result ? Do I need to escape `-` somehow ?
Lists are a recursive data structure so you can't define length without having recursion somewhere.
I think the problem is that I haven't refreshed the databases recently. I am hoping to do that very soon. 
Yep, I'm in the process of migrating, but at the moment neither manual is a superset of the other.
That's pretty cool.
The only concievable way `unsafePerformIO` could cause a security vulnerability in the same sense as a C vulnerability (or even be put in the same ballpark, or hell, the same *sport*) is if you used it to derive a definition of `unsafeCoerce#`, which you then used unsafely. Which probably isn't ever going to happen because it requires an incredibly specific formulation with polymorphic references, and `unsafePerformIO` is never exposed directly, and pretty much always inside a library away from the user. I'm otherwise not aware of any other easy ways to violate type safety in such a way using `unsafePerformIO` (but they might exist). 'Unsafe' in Haskell typically means and is interpreted as "the semantics of my program could change, and it could break." Unsafe in C typically means "hackers now control my computer due to memory unsafety." Both are quite different classes of errors, as I'm sure you can tell. All that said, there are other ways you could introduce simliar classes of security vulnerabilities into a Haskell program. But `unsafePerformIO` isn't one of them, and out of all the ones that are, they're not exposed by default or ever encouraged to users for the most part. On the other hand, C doesn't help you here *at all* unless you go to great lengths.
Very cool. Also a nice way to show that a function is parametrically polymorphic.
Thanks - Thunks He'll be here all night, try the veal ;)
He mentioned one really important feature that I've personally wanted for a while: having the compiler apply type synonyms to simplify inferred types and error messages. That would greatly improve the usability of `pipes`, `conduit`, and `lens`.
Can you give an example of Haskell code that you think is fast, but ugly?
The gist was originally posted as a [reply](http://www.reddit.com/r/haskell/comments/28575l/how_do_you_learn_to_write_systems_in_haskell_and/ci7wuvx) to [this thread](http://www.reddit.com/r/haskell/comments/28575l/how_do_you_learn_to_write_systems_in_haskell_and/). The major source of difficulty came from plugging several disparate functions from different parts of the Pipes ecosystem together.
I found it very helpful to see the thought processes an experienced Haskell user goes through. But also, as I mentioned in the other thread, it's an indictment of the 'just follow the types' mentality, according to which this approach should be viable. Of course, I guess following the types effectively does imply being familiar with core concepts and abstractions first, though I think it's often presented more mechanically.
Just curious: why does our community need multiple hoogles? If FP complete is going to add features to hoogle, why not add them to the existing one or even have the existing one point to yours? I have to wonder if all these pieces of duplicated infrastructure are making it more confusing for the community as indicated by this post.
A list as implemented by Haskell or any language for that matter is recursive, the only way to get it's length is to recurse over it's structure. Even in a language like C chasing through the pointers of a linked-list is a form of recursion and you can draw a direct equivalence between that kind of logic and the ``length`` function in Haskell. Perhaps you want a different data structure, like a vector?
Agreed, cool. This is my first programming language and it's a steep learning curve, but every time I put something in my toolbox like this I get really happy.
I only read the intro on the Rust site a few days ago, and I am really excited about some of the stuff they are doing esp. with concurrency and their idea of 'ownership'. Definitely something I'll be checking out in the future.
http://stackoverflow.com/questions/2376981/haskell-types-frustrating-a-simple-average-function
You can contort my post and read it as an attack on your intelligence or whatever you want. It's not really my problem. Since you haven't actually defined what you mean by simple, or why you think this definition does not hold for the given libraries in question, or why it doesn't hold in the face of my post (where I think I clearly pointed *why* it is simple from a user POV, which you so easily ignored), then I'm afraid this discussion won't go anywhere - and will only boil down to perceived attacks on your intelligence as far as you're concerned.
Thanks for the reply. I was with you up until: mean :: Fractional a =&gt; [a] -&gt; a I definitely understand what you mean about not being able to take a list of *any* type because they have to be summable and dividable. That's actually why I figured the type declaration was incorrect. What I don't understand is the new type declaration. So type `Num` will allow summing and type `Fractional` will allow dividing but because it also sort of incorporates `Num`. What is `Fractional a =&gt; [a]`? I get the last part, that it returns type 'a'. Everything after that also is confusing to me. When I replaced my bad type declaration with `mean :: Fractional a =&gt; [a] -&gt; a` that actually didn't make it work. I'm sorry if I'm asking incredibly ignorant questions here.
For me it helps to think of the =&gt; as "implies"; if a is in the Fractional typeclass, then mean can take a [a] and return an a.
and to elaborate a little: a tip for dunnowins to know why Fractional and Num are required is to investigate the type of the functions they are composing to get their function. recall that ":t &lt;function&gt;" gives you the type in ghci. sum :: Num a =&gt; [a] -&gt; a (/) :: Fractional a =&gt; a -&gt; a -&gt; a length :: [a] -&gt; Int
You really have to go through the examples of any haskell tutorial. Reading them isn't enough, you actually have to do the exercises. This is more important than for most other languages, as haskell is very strict in what it will accept. Your problem is a good example of this. In most other languages, something along those lines would compile (without the type signature). However, haskell does not allow you divide a `Float` by an `Int`, it forces you to be precise when working with multiple number types. You have to manually convert types where necessary. `fromIntegral` can be used for this, by casting any integral type (ie whole numbers) into another number type (eg Float). Also, the type signature is not what you want. `[a]` literally means "A list of any type". So you could pass in a list of strings, or a list of bools, and your function must still work correctly. Obviously this won''t work with a mean function, as you have to be able to add the values within. If you want to return a `Float`, you likely want to just pass in a list of floats as well, making the new signature `[Float] -&gt; Float`. This would then have the definition `mean x = sum x / (fromIntegral (length x))` All of this is described in the [third chapter of LYAH, types and typeclasses](http://learnyouahaskell.com/types-and-typeclasses) in more detail. --- Haskell does take a lot longer to learn than most other languages for this reason - you have to have a firm grasp of the fundamentals before you can write anything useful, which isn't true for languages with ruby and javascript. However if you persist it will eventually click, and it will open up a whole new paradigm of programming for you. 
The `=&gt;` is just a restriction on the type variable `a`, so it means "`a` can be any type, so long as it is `Fractional`". The reason your code doesn't work is probably that `length` has a type of `[a] -&gt; Int` for legacy reasons, and there is a replacement in the prelude, called `genericLength`.
You should consider coming to the #haskell channel on freenode. If you do, I'm augur. But, to quickly address the error you mention: `length` computes an `Int`, but `(/)` requires a `Float` (at least, because you specified the return type as `Float`). Haskell does not automatically convert between numeric types like other languages.
Yup --- reading [the tutorial](https://hackage.haskell.org/package/pipes-4.1.2/docs/Pipes-Tutorial.html) first would have explained a lot and saved time, I think. I wish every library included a .Tutorial or .Example module!
Can confirm
 len xs = sum [ 1 | _ &lt;- xs ] probably not the most efficient, but it works.
Aren't type-classes covered by LYAH? Or did you stop before that?
Note Peaker's responses: my answer initially was a little incomplete!
And, for the readers - this, of course, is why the *One True Type*\* of `fold` is not, in fact, what we think it is, but one that more explicitly announces the church encoding that's present every time we use it, given a list as input: Prelude&gt; :t foldr foldr :: (a -&gt; b -&gt; b) -&gt; b -&gt; [a] -&gt; b Prelude&gt; let foldr2 z f g = foldr f g z Prelude&gt; :t foldr2 foldr2 :: [a] -&gt; (a -&gt; b -&gt; b) -&gt; b -&gt; b Prelude&gt; :t foldr2 [] foldr2 [] :: (a -&gt; b -&gt; b) -&gt; b -&gt; b Note that the type of `foldr2 []` is `(a -&gt; b -&gt; b) -&gt; b -&gt; b` which unifies perfectly with the example type of the list by Tekmo, given the equality `a ~ Int`. For any given list `x`, `foldr2 x` exposes the underlying encoding. In some realm of reality a 'proper'* version of `foldr` should have the list as its first parameter instead. \* I say this in jest, of course.
Don't worry, buddy. Haskell has a bit of a learning curve. I would recommend mastering functional programming (e.g. Lisp) before learning Haskell. Have you tried [Land of Lisp](http://landoflisp.com/)? It also helps to relate to concepts from imperative languages like C and Java. Have you tried [Real World Haskell](http://book.realworldhaskell.org/)?
Exactly! I wasn't trying to achieve a particular behaviour, I was trying to learn just enough of the library to figure out how to join a few existing snippets together, because that's what the OP was trying to do. Furthermore, my goal wasn't "understanding the pipes library" per se, but to demonstrate how one haskeller goes about figuring out how to use a library he is not familiar with. It could just as well have been conduit, or lens, or parsec, or any other library.
You can use :info or :i for short that will work on typeclasses, showing their definition and what instances are defined for it. This also works for data types, type synonyms, functions, and more. I have personally stopped using :t in favor of the far more useful (but more verbose) :i. 
While rather complex, `lens` is really cool and reading the source/reimplementing the core of it is very interesting.
Yeah, in retrospect it might have been easier to look for a tutorial. That's definitely the approach I would have taken if I had to learn to work with the lens library, for example, because that library is known for having confusing types. I didn't know much about the pipes library, so I used my default type-directed approach. It usually works much better than that.
While you're working on 2), couldn't you just add an example search to the home page that uses the +package syntax?
don't show them lenses then.
A thousand times this.
They are definitely covered and I know what a type class is. However when I have trouble reading type signatures and reasoning about what is going on in them and so frequently the response from commands like `:t (/)` are cryptic to me. I almost feel that I'd need to read much more about Haskell's typeclasses before learning anything else about the language.
Thanks for the advice; I'm definitely going to stick with it. Do you have a resource for some good examples of Haskell code aside from what is in LYAH?
I definitely will check out #haskell. TBH I've wondered if people there would be patient enough to answer very beginner questions. I'll make sure I do my homework before visiting.
That's so horrible yet so awesome. Don't get diabetes from all the sugar!
nah just come. I'll answer all your questions. :)
This is really awesome. Thank you.
Good question. I would have suggested also reading [real world haskell](http://book.realworldhaskell.org/read/) for the examples in it, as it has small but understandable full programs in it. It is a little out of date as it has nothing about lens or pipes/conduits. However, I feel for a beginner it is better to ignore those libraries to start with - it is possible to work without them in exchange for more verbose code. The next obvious place is just browsing the source of packages you are interested in on hackage. However, they vary greatly in how complicated their implementations are.
Once you get the knack of functional programming (lambdas and let, lists and recursive functions), then you just add a dash of declarative programming (pattern matching and records). Haskell's syntax may seem a bit weird coming from Lisp, but it's kind of a shorthand, so you don't have to type quite so many parentheses.
People are usually very good about being helpful to beginners on #haskell. If you do do your homework and have a simple concrete question, feel free to post on stackoverflow. The Haskell tag is very active and you'll almost always get an answer quickly.
Realize that Learning You a Haskell is a large undertaking. You can't do it in your spare time. If you have a job or go to school, forget it. Commit full-time for two months. LYAH is an amazing work but it doesn't scratch the surface. Get up in the morning and do cs194, scs240, Real World Haskell, Scheme in 48 Hours. Read every blog. Watch every video. Is it worth it? I didn't say that. Knowing how to program is not an advantage. You'll make more money with a weekend's worth of Python training. Import functools and never look back. My point: Learn You a Haskell for great Good!
Is there an alternate prelude with proper numbers, like `Rings` and `Fields`? Because I do find that the numeric typeclasses are poorly set up, and this kind of code is far harder to write than it should be.
In learning Haskell, and coming from a background of mostly dynamically-typed language experience, but also C/C++, I found that the numeric types were surprisingly hard to adjust to. And I developed a theory for this: Both the dynamically typed languages and "weakly typed" languages force you to think about types, even when they're not checking them, because your code won't work otherwise. But in the case of automatic conversion between numeric types, you actually *don't* have to think about what types intermediate numeric expressions have. Unless you are dealing with some specific kinds of problems, you can get away with your whole programming career never even considering it. And that's what I realized I had been doing. I never gave any thought to what the compiler was doing when it was casting between numbers. I just thought of them as either algebraic reals, or else integers (i.e., "pure" integers from math). And maybe I'd give a thought to overflow of the final result, but even that is rarely applicable. Anyway, you get used to it. Just pay specific attention to the types. Prelude&gt; :t sum sum :: Num a =&gt; [a] -&gt; a Prelude&gt; :t length length :: [a] -&gt; Int Prelude&gt; :t (/) (/) :: Fractional a =&gt; a -&gt; a -&gt; a So, ``sum`` is going to give you back whatever type your list has, and ``length`` is going to give you an Int. ``(/)`` wants a ``Fractional``, and you're dividing by an ``Int``, so you need to convert your ``Int`` into a ``Fractional`` before you divide. Simple. (Of course, as others have pointed out, you also need a ``Fractional`` constraint on your input list elements, because ``(/)`` has one; ``Num`` isn't necessary because ``Fractional`` implies it.) Anyway, don't expect this to be super easy right away just because it was super easy in other languages. The real problem is your brain has been trained to ignore something, and you need to re-train your brain to attend to it. But once you do that, it won't be hard. I mean, compared to learning to program, this is a piece of cake. It's just that unlearning old habits makes it slightly hard (and possibly extremely frustrating). Don't let frustration get the better of you! PS. I find it helpful to put all of the numeric conversions into ``where`` clauses: avg xs = sum xs / len where len = fromIntegral . length $ xs
There's already what look like good answers here, but here's my attempt. The problem you're having is basically one of type "strictness" and "dynamicness". You're used to languages that are dynamically typed, and less strictly typed. Often, that makes things a bit easier in the short term - but leads to hard-to-find errors in the long run. Haskell is strictly and statically typed. You're assuming that anything can be treated as a number (with a run-time error if it's not appropriate), and probably that all numbers can be implicitly cast to some representation that supports fractional values. Actually, you're assuming that representation must be `Float`, but even in dynamically typed languages it might be a rational type, or a decimal type, or there might be a choice of floating point types (single vs. double vs. extended precision). One point of strict static typing is that run-time errors like that shouldn't be possible. So although your function should accept a variety of types, it needs to specify exactly *which* types it can support - ie those that support numeric behavior, and either supporting fractional values or with a function to explicitly convert. Haskell specifies these requirements using typeclass constraints, but that's not quite chapter 1 material (in LYAH, typeclasses get some basic coverage in chapter 3, and a deeper explanation in chapter 8). Basically, different languages make slightly different things trivial, so coming from another language can deceive you about what exercises are reasonable early on. Haskell makes some things more difficult (for a reason), but also makes some things easier. You could get similar issues if you knew Haskell and were learning JavaScript. If you make up your own exercises, don't worry if you can't complete some of them at first - probably not until you complete the book. 
Thanks for the encouragement. There is *a lot* of info at that link!
I found the suggestions in the first answer of this thread really helpful. http://stackoverflow.com/questions/1012573/getting-started-with-haskell It offers detailed step-by-step objectives and good sets of exercises. 
I'm starting to learn that I have a style of learning. In step 1 I read a ton of things on a particularly difficult programming topic. In step 2 I feel overwhelmed and confused by the tons of new information. I despair, and can't remember how to even do basic programming, and fear that my life is over. In step 3 I wake up one day feeling great, and I can do a bunch of new things suddenly, and my old abilities have all returned. I'm somewhere in step 2 with monads right now, and you're right. I need to start applying something I don't really know yet, and let the abstraction emerge from repeated efforts thereof. Thanks.
[A tutorial on the universality and expressiveness of fold](http://www.cs.nott.ac.uk/~gmh/fold.pdf) 
It doesn't get mentioned enough, but I *highly* recommend the [Haskell Wikibook](http://en.wikibooks.org/wiki/Haskell). I think it is *the* best introduction overall, although some of the advanced chapters need some revision still. It's *exceptionally* clear and accessible. As a wiki, you can enhance your learning by *fixing* anything you think is confusing, and doing that will force you to be sure you know how to better explain it. But thanks to people doing that before you, it's already *excellent*.
It is not true that either foldl or foldr process the list "in reverse", and I wish people would stop saying that. With either fold, the first element passed to your fold function is always the first element in this list. The difference is that with foldl, the accumulator starts out with the value of the base case, and with foldr it is a thunk that evaluates to the rest of the fold. This means that a fold which keeps only the first element can avoid a lot of work using foldr, but will still traverse the whole list using foldl. If this is incorrect, somebody please jump in. I'd like to prove these statements in code but I'm a bus station about to head out. 
`toNum` does make a lot more sense. The only issue is there are two functions that convert things to `Num a =&gt; a`'s, `fromInteger` and `fromIntegral`. Perhaps they could be renamed `integerToNum` and `toNum`. The `integerToNum` is really only needed in the `Num` class definition, as a way of converting literals into the correct instance value, so the longer name isn't really a problem. &gt; And with apologies (really), that explanation doesn't help. See next comment for why. I didn't mean it as an explanation, but as an alternative to a mathematical name that might make more sense. The library api isn't really the appropriate spot to put a tutorial for a language concept, it is more there to refresh your memory, or to guide you on what it does. As to your second point, you are absolutely right. This is described very well in the [Abstraction, intuition, and the “monad tutorial fallacy”](http://byorgey.wordpress.com/2009/01/12/abstraction-intuition-and-the-monad-tutorial-fallacy/) article. However, it is still difficult to do this, as it is hard to "forget" what you already know and write to someone without your knowledge. For example, the [all about monads](http://www.haskell.org/haskellwiki/All_About_Monads) tutorial attempted to do this, but wasn't as successful in my view. 
It's actually the first tip I've given on reddit. Apparently it also works on github.
Which I why I suggested it should be called 'toNum' Given that it's trivial to define one function in terms of another, someone should create a module which provides better names for some functions. I'd start with things like first = fst second = snd 😉
I'm learning haskell atm, and like you I've been learning it on and off for a while. This series of videos (I started at Haskell 05 as it was linked in this subreddit actually) has been [really quite helpful.](https://www.youtube.com/channel/UC9ZJ-o00b2t79v6er1O-eBQ/videos)
I'm reading through Beginning Haskell and .. something I'm finding I really need to do is _slow down_.. It's taking me a long time to get through each exercise - something which can be discouraging at first - but each time I've gotten stuck, taken a long walk, taken time to think and bash my head against the REPL using :t, :info, and Hoogle.. I've come out the other end with a much firmer understanding. I think there'll be a point where things will click into place but for now it's still hard going. One thing which has really helped me since I've started doing it is breaking apart functions which I don't understand and playing with them piece by piece in the REPL - and then, going back and annotating the functions with comments. EG. "-- this takes a list of Foo and updates the records using Bluh" .. The book builds on earlier chapters, and it's awesome to have functions annotated with *my own words* (can't stress this enough!). The same goes for concepts like Functor. Keeping a notebook and trying to describe things in your own words will give you a jumping off point for when you want to refresh your understanding, and will test that understanding by forcing you to try and describe it.
Oh, I didn't know you're bitemyapp. I'm much more inclined to believe you about the video now - your guide was super useful, thanks!
I don't think we *do* need multiple hoogles, but I can tell you why FP Complete needed its own Hoogle: 1. We needed something to search our entire package database (actually, we have three separate package databases). 2. We needed something which integrated directly in our IDE. The service at /hoogle is just an added bonus we decided to provide the community. I did briefly discuss having haskell.org's Hoogle point to FP Complete's with Neil, but I don't remember why we decided not to go in that direction. I'd certainly have no objection to doing so.
`Fractional a =&gt;` is a Class Constraint and specifies the interface and behavior of the types `a` must conform to
Why is it exactly that you need to explicitly tie the knot instead letting laziness do it for you? 
I am normally a fast learner and have also had trouble, so this may help you too: http://prajitr.github.io/quick-haskell-syntax/
I am surprised you knew who bitemyapp was. Appreciate you taking the feedback in the spirit intended. :)
Int and Integer aren't actually in Fractional. For integer division you need to use `div`. So Haskell is similar to OCaml in that respect. (With the caveat that we can use other fractional types, like `Ratio`, with `/`.)
&gt;&gt; it can convert any integral to any other Num type &gt;Then it should have been called "toNum". Even that is weird because it can take something that's already a Num and turn it into a different kind of Num. IMHO, the problem isn't the name, but the fact that Haskell effectively has overloading from return-type. For someone learning Haskell this is a huge hurdle, and I'm still not convinced that the purported benefits are actually worth it.
Why are you wasting your time for something that is barely usable in the real world? (/) expects Float, but gets an Int. This is not your fault that Haskell is not clever enough - author of (/) was lazy enough to not implement Int as an argument. For me this is a sign of stupidity because Int has higher precision than Float and (/) should swallow it without question. Well, maybe he wanted to be clever, but type hell in Haskell made his task almost impossible so he gave up and left his dirty work for people like you. This attitude is taken exactly from C world. Whole C++ world is build around corner cases - just look at job interview questions - almost always corner case test. Haskell is the same. My advice for you is to stick to Clojure and use types where they're required. Writing one or two lines of tests is much more efficient than fixing type errors in Haskell using community as a debugger. If you feel being taken as a hostage by Haskell, but keep learning and forgiving - this is a sign of a Stockholm Syndrome.
Java 8 finally adds some much needed 70's technology but the base language is still over-verbose and extremely under-powered compared to most languages in modern use.
Perhaps you'd prefer the existence of a multiparam typeclass like this instead of Fractional (where (/) is defined)? class (Num a, Num b) =&gt; Divisible a b where (/) :: a -&gt; b -&gt; a It seems to me like it's correct while eliminating boilerplate -- it pretty clearly indicates 'and we coerce the second arg'. There's not a general way to implement type coercion, though -- we have no guarantee that any particular Num looks enough like any particular Num for it to be worthwhile, and for operations like multiplication and addition it's likely to violate commutativity. There's intentionally no way to overload a function without using typeclasses because that has the potential to introduce ambiguity -- and, even though I generally like pragmatism in most cases (my code's littered with 'coerce this type for me' typeclasses), I don't like introducing it at the expense of precision. There's a natural way to define them such that you don't necessarily create ambiguity, but that leads to its own problems which I'm not sure how to resolve without introducing special cases. That would look something like this (pardon my fundeps if they're incorrect): class Multiplies a b c |a b -&gt; c where (*) :: a -&gt; b -&gt; c -- this 'flipped' definition is circular, though, so it won't work (at least not without OverlappingInstances or something) -- How do you generalize the special case that would be necessary to make this work? instance Multiplies a b c =&gt; Multiplies b a c where a * b = b * a (You could still manually define the flipped instances, but it's kind of hard and it's very boilerplate heavy. You might be able to TemplateHaskell them out but that's cheating.) Even though some of these design problems -- if I'm bold enough to call them that -- are kind of annoying, in these cases (which are pretty rare) I'd rather trade a little expressivity for correctness, and that means not making numbers special enough to break the rules. And mind that all of the above has its own cost -- it's no longer possible to determine the resulting type of a lot of operations that are really very simple. map (+1) ([1, 2, 3] :: Int) could be any type that supports addition with ints. Really, though, I'm hoping someone writes a language sometime soon which does a lot of the boilerplate-elimination typeclasses do more succinctly and cheaply, but I'm not sure what that would entail. I'm not an expert but I think I'm expressing some common irritations. One last thing: let me just state for the record -- the Haskell type system, overall, has saved me work. It's allowed me to write less code and spend less time debugging the code I write, and that makes me very reluctant to throw the baby out with the bathwater because the numeric types are occasionally kind of annoying.
&gt; Int and Integer aren't actually in Fractional. For integer division you need to use `div`. But that function doesn't do the same thing: It *divides and truncates to an integer value*, as opposed to *divides and rounds to nearest floating-point value.* My point is, in Haskell, you can say `5 / 6` and `4.3 / 2` and the compiler will successfully evaluate those expressions to a numeric result.
I think I've unintentionally misrepresented folds here and I'm probably going to come back to the answer tomorrow and try to represent them correctly. When I said "in reverse" it was because it seemed like a very easy explanation especially given how I'd already described Dual as performing a Monoidal operation "in reverse," but I think it's probably worse to give a false intuition than to state the truth in a way that's confusing. If you've got any ideas of how to say it correctly that are less confusing, I'd be appreciative. (because I can't think of any right offhand even though my gut's telling me it shouldn't be very hard)
The reason you can say `5 / 6` is because `5` and `6` aren't actually integers in that example. They get silently converted to `5.0` and `6.0`. If you did something like let i = 5 :: Integer in i / 6 you'd get a type error.
`first` and `second` already exist and they mean something else. first :: Arrow a =&gt; a b c -&gt; a (b, d) (c, d) `second` is similar but for the other side of the tuple.
Most applications that I know of that are using postgresql-simple are not open source, sadly. That said, there are a fair number of commercial projects that I know of that are using postgresql-simple in production, and I get the sense that there are many more I have no idea exists. If you do run across (or write) a nice open-source project using postgresql-simple, by all means let me know! If you have any questions, feel free to ask me, either by sending me an email, catching me on IRC, or whatever. If there are issues related to documentation, by all means complain.
Without `#haskell`, I wouldn't be where I am today. The people there are *very* patient with beginner questions. If you don't understand, try to figure out what confuses you and keep asking questions about that! Another tip is that sometimes it helps taking a step back, experimenting with the things you've learned so far. It helps with learning the next thing that builds upon that.
Yeah, I agree. My first introduction to relational databases was via Progress 4GL, and while I despised the language, the relational aspects were actually pleasant to work with. I did do a bit of SQL programming in C, PHP, and Python, and found dealing with SQL to be nearly unbearable even if the language was more tolerable. (Well, I'm not so sure about PHP...) Postgresql-simple honestly is the first library where I've found that I actually don't mind interacting with RDBMSes, and I think the nearly automatic approach to marshalling and unmarshalling plays a very large role in that.
`toNum` immediately suggests it could be used like `toNum "745"` so it's not really any better than `fromIntegral`. `first` and `second` are already functions in `Control.Arrow` that are used frequently.
The thing with the "mathy" typeclass names is that generally those names were created by mathematicians in the first place because there wasn't already a good descriptive name for those things. We generally try to avoid typeclass names that look like Java classes.
Yeah, I want more abstraction too. And better end-to-end type checking. These two features seem to be somewhat in tension though, not least because static type checking in the presence of parameterized identifiers (like table names) seems like a pretty tricky thing. Also, as the schema can theoretically change without recompiling your program, I think you really need the ability to trigger a schema check at appropriate times. (e.g. at compile time, program startup, whenever a connection is made, periodically, etc.) Unfortunately there is no way to set up a notification of a schema change, your migration code would have to trigger a notification manually if you want to recheck immediately without polling. So, I suppose the first step would be to somehow derive a schema-validation function, ignoring cases that can't be easily checked, like dynamic sql and parameterized identifiers. Also, you'd probably want some way of controlling what parts of the schema are checked, e.g. to deal with cases where a single program connects to multiple databases (potentially with different schemas.)
Well, [lpaste.net](http://lpaste.net/) uses it I think :-) We also use it a lot at my company. And I do mean *a lot*.
Look for Mike Izbicki's latest blog entries. I think he mentions a tying-the-knot-ish technique at the type level at some point.
Like kqr says, numerical literals are type agnostic in Haskell. ghci&gt; :t 1 1 :: Num a =&gt; a You're not dividing integers with `(/)`.
Right. I didn't think about that. For most practical purposes, they work the same way?
Just a thought: if you are using ghc 7.8 then you can ask the compiler using type holes mean :: [a] -&gt; Float mean x = sum x / _ ../TestH.hs:47:18: Found hole ‘_’ with type: Float Relevant bindings include x :: [a] (bound at ../TestH.hs:47:6) mean :: [a] -&gt; Float (bound at ../TestH.hs:47:1) In the second argument of ‘(/)’, namely ‘_’ In the expression: sum x / _ In an equation for ‘mean’: mean x = sum x / _ So at least you know whatever you put in the hole has to be a Float. Of course, that isn't your only problem. I think type holes are not only a useful debugging tool but are also a very useful learning tool.
Yeah, you need a long list indeed to require `genericLength`. It says in the documentation it's a little slower too.
It's a standard iPhone; I just commute sometimes.
The lecture notes and exercises for this class are excellent. However, I would recommend them as a complement to LYAH (or RWH) rather than alternative because the lecture notes are really terse. Lecture notes are excellent for review and the exercise sets cover diverse topics and really fun to try. 
When I was learning how foldr and foldl acted differently, I came across these: * [foldl.com](http://foldl.com/) * [foldr.com](http://foldr.com/) Which helped a bit. What would REALLY help, which I discovered much later when studying ASTs, is a visualization tool for how the *execution tree* (is that the right term?) grows when folding over a list with a simple operation like `+`. It becomes really easy to see why `foldr` works on infinite data structures, but `foldl` doesn't -- try it!
I really enjoyed [this one](http://www.youtube.com/watch?v=YScIPA8RbVE). Maybe it's a bit more theoretical than you want on the list, but I think it's worth watching for existing Haskellers.
&gt; I still don't understand why popular languages don't implement such **trivial** thing as computational complexity as an additional function description. Because it's _not_ trivial? What's the computational complexity of a non-terminating function? Do we assign them a special value, O(infty) perhaps? But then we could write this: def halts(f, x): return complexity(f, x) != O(infty) &gt; Type system is only a fancy spell-checker Why don't you walk into the Coq or Agda communities and try telling them that their type systems are just fancy spell-checkers. &gt; [(spoiler: Haskell makes me puke)](http://www.reddit.com/r/lisp/comments/1fj0qf/lisp_vs_haskell/caf8cup?context=3) You do realize you're in /r/haskell, right?
&gt; At best, when faced with type errors, languages throw an error -- at worst, type errors go unnoticed until they generate unwanted effects in a running program. And yet Common Lisp and Python are the only languages of these (Haskell, Ruby, Scheme, ~~Python~~, JavaScript) that throws an exception when you try to divide floating point numbers by zero (which is a valid exception in IEEE if you trap it), the rest give useless Infinity values which produce useless NaN values and your program continues running merrily like nothing is wrong. **EDIT**: Python also throws an exception.
This is what division is supposed to do according to IEEE 754. Common Lisp is against the standard here.
IEEE 754-conforming implementations must provide optional traps for exceptions, such as divide by zero, overflow, etc, which a user can take advantage of to change control flow, like throwing a user error. [Language implementations](http://www.cs.berkeley.edu/~mhoemmen/lisp-matrix/www/floating-point.html) can take advantage of these traps, Common Lisp is not against the standard.
Isn't manifesting failure as values the Haskell way of doing things though? Don't know if I'd want to modify my control flow with division errors.
So almost all of the operations in `pipes-group` take list operations and generalize them to work on `FreeT`. The solution I'd recommend here is to generalize `zipWith` on lists to work on `FreeT`s. Then instead of using `individually` I would `zipWith` the delimited lines with a `FreeT ((,) Int)` (i.e. a `Producer Int`, but in `FreeT` form).
Usually those values are type-safe. So an error is distinguished from a proper value, like Either Error Double rather than an implicit NaN and Infinity in the Double which is tantamount to implicit null.
This should be called *from zero to dependent types in 2 minutes*
I've done this with encrypted/unencrypted passwords before. I like having two types there though (newtype EncryptedPassword = EncryptedPassword Text, newtype PlaintextPassword = PlaintextPassword Text)
I would more likely use [Phatom types](http://www.haskell.org/haskellwiki/Phantom_type) for this scenario. Although it sounds good on paper, for Haskell this pattern doesn't seem to be as useful, like in object oriented languages where data is passed freely left and right.
Conceptually, I find it easiest to think about `foldr` as acting "towards the right", as follows: I picture the seed element of the fold sitting to the right of the list, and then I picture the elements of list flying off the list towards the right one by one. As each element flies off to the right, it hits the current seed and is applied to it by the function. I picture `foldl` as the mirror image of that: the seed element starts to the left of the list, and the elements of the list fly off towards the left. Separately, I remember that right folds work lazily: the initial value you get is the last operation, the one where the left-most list element is applied; all the earlier operations further to the right are delayed in a thunk. That's why a right fold can work on an infinite list. Whereas a left fold happens strictly, all in one go.
Here's another variant using `zipWith`: len :: [a] -&gt; Int len xs = last (0 : zipWith const [1..] xs) or in pointfree style: len = last . (0:) . zipWith const [1..] BTW, the extra zero `0:` is to deal with the empty list case. 
I would prefer (/) to work as expected right off the bat. 
And this use case is actually one of the examples on the page you linked to!
&gt;And yet Common Lisp is the only language of these (Haskell, Ruby, Scheme, Python, JavaScript) that throws an exception when you try to divide floating point numbers by zero ? Python: &gt;&gt;&gt; 1.0 / 0.0 Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; ZeroDivisionError: float division by zero 
&gt; For me this is a sign of stupidity because Int has higher precision than Float and (/) should swallow it without question. No it's not. What's `3/2` as an Int?
Thats because ghci is just a demo version of the language. 
+1 for C#, I won't code in Java if I can avoid it but C# is probably the best widely used programming language.
4: no jobs :(
Did you try looking at the more practice-oriented [Ornaments in practice](http://morphis.me/link/ornaments-practice.pdf) draft first, which is linked from the posted article?
Ah, nice. I must've missed it when testing. Ruby and Scheme and JavaScript behave as Haskell does: chris@retina:~$ ruby print(1.0 / 0.0) Infinity chris@retina:~$ mzscheme Welcome to Racket v5.3.1. &gt; (/ 1.0 0.0) +inf.0 chris@retina:~$ nodejs &gt; 1.0 / 0.0 Infinity I now like Python a little bit more. For completeness, here's SBCL: chris@retina:~$ sbcl * (/ 1.0 0.0) debugger invoked on a DIVISION-BY-ZERO in thread #&lt;THREAD "main thread" RUNNING {1002ADB063}&gt;: arithmetic error DIVISION-BY-ZERO signalled Type HELP for debugger help, or (SB-EXT:EXIT) to exit from SBCL. restarts (invokable by number or by possibly-abbreviated name): 0: [ABORT] Exit debugger, returning to top level. (SB-KERNEL:TWO-ARG-/ 1.0 0.0) 
I did not have much faith in it, but so far it looks very readable. Thanks!
Given the conceptual way of thinking about left and right folds described above, here's how we can then write `foldl` and `foldr` in terms of each other. These solutions are not the simplest possible. But I find them easy to remember how to derive, because the derivation is a straightforward step-by-step process using only simple facts, without the mental gymnastics of the usual solution. First, let's write `reverse` in terms of each of `foldl` and `foldr`: reverse = foldl (flip (:)) [] reverse = let f x xs = xs ++ [x] in foldr f [] or, if we write `f` in combinator form, f = flip (++) . flip (:) [] The traditional exercise requires us to use only `(:)`, not `(++)`. Fortunately, `(++)` itself is defined as a right fold: xs ++ ys = foldr (:) ys xs so we have flip (++) = foldr (:) All together, we have reverse = foldr (foldr (:) . flip (:) []) [] Now we just use the fact that `foldl` and `foldr` work in opposite directions of each other: foldr f x xs = foldl (flip f) x (reverse xs) = foldl (flip f) x (foldl (flip (:)) [] xs) foldl f x xs = foldr (flip f) x (reverse xs) = foldr (flip f) x (foldr (foldr (:) . flip (:) []) [] xs)
I don't understand the intended usage of this. Can you give an example?
None of the changes you're suggesting would make any realistic difference to learning Haskell. What's actually happened here is that while learning, you ran into things you didn't understand, and one of the things you attributed that to were the names. You now believe that things could be improved by "improving" the names. However, there's no reasonable set of names that would have actually prevented an essentially equivalent set of misunderstandings - there's no shortcut to actually learning the semantics of the operations you're dealing with. In fact, it can be better for understanding for names to not attempt to be descriptive, because short names are never going to fully capture the semantics of the functionality they're naming. Lisp is an interesting case, with list operators like car and cdr. People learning the language often complain about them, but the reality is that they're terminology, not descriptions. Consider "monad" - someone smarter than me could probably come up with a good Java-style name for it like TypeClassWithLeftAndRightIdentityAndAssociativity, or whatever, but it wouldn't actually help you understand monads. The purpose of descriptive names is to act as mnemonics for the semantics, but you still have to learn the semantics, and learn the mapping between the mnemonic and the semantics. 
Ahh yes, I forgot about lpaste. Come to think of it, [ircbrowse](https://github.com/chrisdone/ircbrowse) is also using it. Chris Done might be the largest open-source consumer of postgresql-simple, especially for applications.
This describes what the situation was two years ago. It would be nice at least to mention some of the additional support for "dependent types emulation" available today, if not work actual examples into the text: data kinds, built-in type-level naturals, singleton types...
Rather than making a mess of things trying to use newtype Monoid instances and point-less style, I would approach the problem as the following series of transformations. -- Normal definition foldl_1 :: (b -&gt; a -&gt; b) -&gt; b -&gt; [a] -&gt; b foldl_1 f z [] = z foldl_1 f z (x:xs) = foldl_1 f (f z x) xs -- Name recursive portion foldl_2 :: (b -&gt; a -&gt; b) -&gt; b -&gt; [a] -&gt; b foldl_2 f z xs = aux xs z where aux [] a = a aux (x:xs) a = aux xs (f a x) -- Name the structure recursive call foldl_3 :: (b -&gt; a -&gt; b) -&gt; b -&gt; [a] -&gt; b foldl_3 f z xs = aux xs z where aux [] a = a aux (x:xs) a = rec (f a x) where rec = aux xs -- Move non-recursive parameters to right side of = foldl_4 :: (b -&gt; a -&gt; b) -&gt; b -&gt; [a] -&gt; b foldl_4 f z xs = aux xs z where aux [] = \a -&gt; a aux (x:xs) = \a -&gt; rec (f a x) where rec = aux xs -- foldr captures the structural recursion pattern for lists -- which was used explicitly above, so we can extract the -- two cases from 'aux' as arguments to foldr. foldl_5 :: (b -&gt; a -&gt; b) -&gt; b -&gt; [a] -&gt; b foldl_5 f z xs = foldr (\x rec a -&gt; rec (f a x)) (\a -&gt; a) xs z
(/) works exactly as expected. As well, the error message when you don't convert the parameters to a fractional type are fairly descriptive; it will point you to exactly the argument which failed and tell you why it thinks it is incorrect.
Fun (and evil). Of course the real solution is not to be in this situation in the first place. The library author should leave `someFunc` intact and add a new function `someFuncWithChar` in version 2. Don't break your clients without a very good reason.
It depends on your scheme. In mit-scheme, division by zero creates a floating point exception and dumps core... which is less that satisfactory. 1 ]=&gt; (/ 1.0 0.0) Floating point exception (core dumped) 
Per the intro, in particular *Relation with previous presentations*, the paper is really only claiming to be more accessible than a purely categorical approach. Which I can only imagine is true, if overstated.
In your example, the validate function is a smart constructor. . validate :: String -&gt; Either ValidationError CreditCard It's the only way to make a CreditCard (or Valid CreditCard AWS you have it). So, people normally call this a smart constructor and don't mention the newtype.
whats 3 / (2 as Int) ?
The first motivation behind that was from my 3D realtime engine. The whole scene is described through a pure interface (some kind of a `State` actually). The idea was to provide that monad (called `Scene`) in order to create a scene, and update objects (translations, rotations, scale, and so on and so forth). Over `Scene` comes another monad, you can call it `Render`, that wraps the render context (for instance **OpenGL** objects) in order to *reflect* the pure model. When something changes in the pure model, the `Render` monad changes to update the render. Then for instance, if you change the orientation of a light (it’s through a type called `Entity Light`), you can do something like that: instance MonadReact Scene Render (Entity Light) () where react op light = do -- update the light in the Scene -- update the representation of the light
Counterpoint: The more serious issue is that you were using floating-point numbers at all in your code.
Assuming that OP is the author. &gt; Constructing the value portion of the dependent type requires us to promote the **rational** numbers to a data type (this is the act of "faking it"). I think you mean natural numbers here.
It was a tough first Haskell book. I found Learn You a Haskell did a great job of getting me over the hump and into actually using the language. After that the Haskell Wikibook was and is something I could refer back to. Real World Haskell I found was good for the examples.
You answer, you are the one that wants `(/)` for Ints. btw, it's impossible. `1.5` is not an Int.
gtk2hs currently pulls essentially the typeclassing trick described here to deal with changes in the `Cabal` library (because `CPP` is not available at that stage of building the tools to build the tools). If a package as widely used and well-engineered as `Cabal` does it, I think there's really no hope for the "don't be in this situation" solution. Better to know a few such tricks.
You suggest never using floating-point numbers?
What is so surprising in / for Ints? I want floating point result, not an int. Why / does not take ints ? Who was so stupid or lazy not to implement this? I know exactly why it is like that, but I want to know your version. ;) PS. Haskell was designed with failure in mind. 
Thanks. I have a follow-up question: who would call this method? Is the idea to write scene-manipulation code which knows that it is being observed, without having to depend on a concrete observer? Something like this? getLights :: Scene [Entity Light] getTables :: Scene [Entity Table] jitter :: Entity a -&gt; Scene (Entity a) earthquake :: (MonadReact Scene r (Entity Light) (), MonadReact Scene r (Entity Table) ()) =&gt; r () earthquake = do lights &lt;- liftBase $ getLights tables &lt;- liftBase $ getTables forM_ lights $ react jitter forM_ tables $ react jitter 
Don't worry, you can still encode rational numbers once you can encode natural numbers.
I know, but I felt like giving a technical answer anyway.
Yeah, I seem to remember using the type class trick in a Cabal file as well at some point. Something getting an extra argument, so very similar.
I saw this when I was reading through the HSoM too and made the assumption that they meant without *explicit* recursion, so if you thought to do it with a fold yourself, I think you were correct. There aren't really any non-recursive control constructs in Haskell, so I don't think that the problem would have been solvable in Haskell without *any* recursion (barring solutions like /u/Tekmo's which uses an entirely different data structure).
Well, **I** want a Rational result, because Rationals are better. `(/)` can't read minds, so what should it return?
When I was learning Haskell, I was initially confused due to the syntactic similarity between type class constraints and the rest of the type. It helped me a lot to learn to read the type first, by itself, and then the type class constraints separately. For example, the type without constraints of division is simply: a -&gt; a -&gt; a Easy - something that takes two parameters of any type and returns a result of that same type. Of course, you can't divide every type, so we add the constraint: (Fractional a) =&gt; a -&gt; a -&gt; a 
Nowadays you can write [Vector in Haskell](https://github.com/llelf/NastyTyped/blob/master/Vector.hs) like a boss pretending it has deptypes. 
Minding that I think names that are shorter to type are a Good Idea for the same reason I think car and cdr were actually pretty good names. (they're three letters long, easy to read/pronounce mentally, the symmetry between the operations is clear just by looking at them, and you type them so often that it doesn't matter if they're obviously meaningful) Like you brought up, I think Haskell's algebraic names have a similar role: many Haskell programmers, I suspect, probably don't know or care the category theoretical definitions of functors, monads, or monoids and wouldn't be able to explain the derivations of the names, but they're just names and they're pretty easy to type, so what does it matter? I don't know what a good name would be, though, but I think there's probably quite a few. Pick your favorite pronounceable three-character string?
I teach a lot of Haskell. Use my guide: https://github.com/bitemyapp/learnhaskell You can get my email address off of my github profile. If you get stuck PING ME and I *will* help you!
You're right - and I did encounter those while learning about dependant types. I just didn't feel comfortable enough discussing them when I barely understand what they do.
Ah, fixed, thanks!
Cool, thank you!
For non-performance-critical code, `Rational` (or `Ratio Int`) is IMO better.
I feel angry when someone removes a function I was using; but I feel smart when I eliminate a deprecation warning :D Let your clients feel smart, if possible.
&gt;Error as an answer is unacceptable in any sufficiently sane (or simply done right) programming language. Give me an example of a programming language that divides Ints without rounding.
To be clear, we're definitely using the same Hoogle code base as everyone else has access to, just with a slightly tweaked UI to fit in with the rest of our site and to allow users to switch between databases to search.
I actually was aware that car/cdr weren't arbitrary names, but to anyone who's not a Lisp implementer they may as well have been. I don't have much to dispute in your next three paragraphs, but as far as a cookbook goes, I think there's a possible problem. To me it seems like the Haskell community is pretty divided still about the appropriate way to do a lot of absolutely basic things -- check out the systems programming post on Pipes for an example. It's a really big language with a really fractured userbase and I feel like even if a cookbook is a step in the right direction, to be useful the idea needs a little modifying. That said, I think there's a few points of basic agreement where you could probably write good instructional material where there doesn't already seem to be much -- everyone seems to like monad transformers even though I occasionally run into folks who really hate mtl, but when I first learned them it really came about just through screwing around with types. And you could probably use a cookbook format with specific examples to convey the general concepts in play, although at that point it's not really a cookbook. The real problem, I think, is that there's a pretty significant verge between basic Haskell and *useful* Haskell -- what LYAH and company teach really isn't enough to write effective code and some of the features that are absolutely basic in real codebases are kind of scary and hard to teach. I think this needs to be addressed somehow even though I think the answer has more to do with introducing abstract stuff like what I'm describing early than with presenting a specific problem/solution phrasebook. (apologies if this doesn't make enough sense -- I'm operating on six hours of sleep)
Curious: when did you read the Wikibook? It's been *substantially* revised and really cleaned up, especially the whole beginning track, within the last few months…
(Python 3?)
Lisp...: -&gt; (/ 3 2) 3/2 -&gt; (* 2 (/ 3 2)) 3 Proof (mathematically correct computation without losing precision): -&gt; (type-of 3) (INTEGER 0 536870911) -&gt; (type-of (/ 3 2)) RATIO -&gt; (type-of (* 2 (/ 3 2))) (INTEGER 0 536870911) I would expect from a math oriented language or advertised as academic one such as Haskell to behave the same or better. Instead of this Haskell drops its pants and says: "I'm dead"
I cannot agree more. Sometimes there's neither a deprecation warning, nor a Changelog detailing why the function was eliminated, or what could work as a replacement. [optparse-applicative](https://github.com/pcapriotti/optparse-applicative), I'm looking at you.
Tensor products are not something you talk about in type theory. I'm not even sure where you would have seen something like that. Category theory works with tensor products, though. They tend to appear in various forms of monoidal categories. 
No argument here. But some languages don't have the equivalent of Haskell rationals, and sometimes full-blown rationals are infeasible, so I think floating points numbers still have their place and time just like many other things. I don't think you disagree.
&gt; As for shortcuts, I understand (and agree in principle) but the fact of the matter is that people are able to learn most other languages by following examples, tweaking, getting things done and then going back and studying. That seems to not be the case with Haskell and I think it needs to be addressed if Haskell is to have a much wider audience. There are definitely things that would need to be addressed "if Haskell is to have a much wider audience." Some people would argue that that goal is not the top priority. Either way, I think it's tough to make a case that the names of operations like fromIntegral, fst, and snd are important issues to address. I stand by my point that you only think that because of other roadblocks you encountered while learning. &gt; Better names help with discovery I can agree with that. But again, I don't think in this case there's any strong argument. The discussion here has demonstrated that because of its genericity, there's no perfect name here: "toNum" has its own issues, just as "fromIntegral" does. If you understand the numeric type class hierarchy, there's nothing confusing or complicated about "fromIntegral" as a name. Consider the expression ```toNum (length x)``` - it's a little strange, because ```length x``` is in fact an instance of Num. We'd just end up having this same discussion with someone else who was trying to read too much into the names of operations. Either way, the reality is that to use Haskell successfully, you have to recognize that it's much stricter than other language when it comes to type conversion. This is particularly noticeable in the context of numeric types, and until you understand a bit about the numeric type classes, no amount of naming is going to compensate for that. Really, these are bikeshed / paperclip color issues - they're easy to opine about but they're of no real consequence. &gt; I argue that the entire noobie community would be orders of magnitude ahead of they were introduced to Monads through Justin Le's article than through what you find in LYAH or RWH That may be true. Completely separate issue though. 
Lists are defined recursively, so writing functions like that on list that don't use recursion *anywhere*. One way to avoid the problem is precisely Tekmo's, representing the list by its fold. But to move between that representation you still need to use some kind of recursion, in form of `foldr`. However, normally when people say "do X without recursion" they really mean "do X without *explicit* recursion": because using higher order combinators is cleaner and easier to understand. 
&gt; I don't know what a good name would be, though, but I think there's probably quite a few. Pick your favorite pronounceable three-character string? How about ```sont```: "some other Num typeclass". :D 
In D language you usually get nan, but you can also get an exception if you want: void main() { import std.stdio, std.math; real f0 = 0.0; // 80 bit FP auto r1 = f0 / f0; r1.writeln; // Prints -nan FloatingPointControl fpc; fpc.enableExceptions(FloatingPointControl.severeExceptions); // Generates hardware exception unless it's compiled with -O auto r2 = f0 / f0; } D doesn't have dependent types, but it has fixed size arrays, represented with the T[N] type, that in the latest version of the compiler allow safe code like this that calls optimized SIMD routines: void sumVect(T, size_t N)(in ref T[N] a, in ref T[N] b, ref T[N] c) pure nothrow @safe @nogc { c[] = a[] + b[]; } void main() { int[10] data1; // Initialized to zeros. int[7] data2; int[5] data3; sumVect(data1[5 .. $], data2[0 .. $ - 2], data3); }
&gt;What would REALLY help, which I discovered much later when studying ASTs, is a visualization tool for how the execution tree (is that the right term?) grows when folding over a list with a simple operation like +. Sigh. I have been begging for this because when I teach Haskell I end up having to teach people how to write out the spines themselves and this is often error prone as laziness/strictness isn't in the types of functions like (+).
As you can see from my name, I mostly write Python.
If you want to use the standard division operator in Haskell, (/) :: Fractional a =&gt; a -&gt; a -&gt; a, you need to pass in a Fractional type. If you look at the Fractional type (at least what is loaded by Prelude), you get: class Num a =&gt; Fractional a where (/) :: a -&gt; a -&gt; a recip :: a -&gt; a fromRational :: Rational -&gt; a -- Defined in `GHC.Real' instance Fractional Float -- Defined in `GHC.Float' instance Fractional Double -- Defined in `GHC.Float' Notice there are only two instances for Fractional, Float and Double, so you can only use a Float or a Double in (/). I agree this is a different way to handle basic mathematics, but it still makes complete sense.
Wow, great debugging!
This one is my favorite: Prelude&gt; let i = id; love = (&lt;3); you = 1 Prelude&gt; i love you True 
How did you get from "-O0 fixes it" to "this might be due to unsafePerformIO"? Is this something that's reasonable to assume?
Some other Num type you mean? I like it.
 data I = I deriving Show data Hrt = I :❥ String instance Show Hrt where show (i :❥ str) = show i ++ " ❥ " ++ str who = "u" (❥) = (:❥) ghci&gt; I ❥ who I ❥ u 
 λ&gt;i could care less &lt;interactive&gt;:29:1: Not in scope: `i' &lt;interactive&gt;:29:3: Not in scope: `could' &lt;interactive&gt;:29:9: Not in scope: `care' &lt;interactive&gt;:29:14: Not in scope: `less'
Dude. I sat, learning Haskell(I was having trouble understanding the State monad) on a saturday night a few years ago, and someone(who I'm pretty sure was chrisdone, even) explained stuff to me for like 2-3 hours in #haskell. These people will teach you. You *will* be assimilated. 
Personally I think it'd be neat if Haskell provided 'implementation matters' and 'implementation doesn't matter' numerics, similar to what it currently does with binary data types, for about this reason. However, I think there's still a pretty significant difference in actual meaning between operations resulting in a floating point number and and operations resulting in an integer. I'm not saying that Haskell shouldn't acknowledge this in the stdlib -- I'm describing a technique that could be used to acknowledge this -- *in the stdlib, without requiring you to substantially modify your code or reinvent the wheel yourself* -- as well as its drawbacks. You seem to be under the impression that it's not only a problem you shouldn't have to think about, but one that nobody, including the authors of the standard library (or stdlib extension) *who would be the sole implementors of this sort of change*, should have to think about. This is ridiculous: the developers of Lisp, while they didn't have to do it under Haskell's type system, had to think about what I'm claiming the implementors of such a design change would have to think about. If you were to design a programming language, you, too, would have to think about such things. *All I'm describing is a technique that could be used to formally describe such a design in the standard library.* **The problem with the possibility I'm suggesting is not that you, the user of the standard library, would have to reinvent the wheel, but that if it were ever implemented, it would a) make it hard to infer the types of simple expressions and that b) it would be hard to generalize to other numerics even if it's expressed for the existing numerics in the standard library. I've brought up both of these problems, in the specific, multiple times. What you are complaining about does not seem to have any real connection to what I've previously said. The way you seem to be misrepresenting what I've told you is starting to piss me off.** Now look at what you've made me do. I've broken out the crazy person formatting.
Because inlining a call to `unsafePerformIO` turns a pseudo global variable into a local one (of which you have several copies).
http://hackage.haskell.org/package/tagged or phantom types Reinventing the wheel as a Haskell user is a good way to avoid 90% of the benefit of being a Haskell user.
Hmm, that's a disappointment. I was really hoping for this paper to talk to an Haskell audience :-( So thanks for your comment! May I ask you (or anyone sharing your impression) if the presentation could be improved by : * writing the concrete examples in Haskell+GADTs? Agda? Coq? * coding the signature functors in Haskell+GADTs? Agda? Coq? * more generally, was the (stylised) syntax used in the article a hindrance to understanding? * was the motivation for indexed signature sufficient? * did you get (at least) the intuition for the operational (i.e., first) model of ornaments? * did you get (at least) the intuition for the Cartesian (i.e., second) model of ornaments? * in other words, at which stage did you lose touch with the material? Anyway, feedback (even partial) is welcome! 
I'm still reading it (and am pretty familiar with Agda so probably not exactly the intended audience). I just mentioned that to temper the expectation that it'd be immediately accessible—that might be discouraging. I'd love to update that later to say it's actually quite accessible once you get through the intro matter! :) Fwiw I've never read another paper on ornaments so it'll be a naive intro. I'll answer your questions once I finish.
Except that writing an `Eq` instance for that type still requires an `unsafeCoerce` in 7.8...
The exception is just a runtime IO exception, though. It gets thrown even by the prelude `/`. You can catch it, but it's clumsy because that's IO. Is there a way to do arithmetic with a monad like Either?
Is IDesc a typo? It seems like it ought to be Sig I?
https://github.com/llelf/NastyTyped/blob/master/Vector.hs#L13
`genericLength` is also useful if you have a lazy numeric type: data Nat = Z | S Nat deriving (Show, Eq, Ord) -- note: Ord instance relies on constructor order! instance Num Nat where Z + y = y S x + y = S (x + y) fromInteger x | x &lt;= 0 = Z | otherwise = S (fromInteger (x-1)) -- remainder of instance is an exercise for the reader GHCi: &gt; let reallyLongList = 1 : 2 : 3 : reallyLongList &gt; length reallyLongList &gt; 2 (infinite loop) &gt; (fromIntegral (length reallyLongList) `asTypeOf` Z) &gt; 2 (infinite loop) &gt; (genericLength reallyLongList `asTypeOf` Z) &gt; 2 True 
Upon hearing of the carol singers outside, the Haskeller said: do let in these for view :: (Applicative f, Traversable t) =&gt; (t a -&gt; Getting (f (t b)) (a -&gt; f b) (f (t b)) -&gt; (a -&gt; f b) -&gt; f (t b)) -&gt; These (t a) (Getting (f (t b)) (a -&gt; f b) (f (t b))) -&gt; (a -&gt; f b) -&gt; f (t b)
Reminds me of the one time where I was at a wedding and I had the realization, that the words "Just married" are actually a real world application of Haskell. (Notice the double meaning of "application".) Also to construct something which may or may not be controversial where you live: import Data.Maybe deathPenalty = Nothing ghci&gt; isJust deathPenalty By now you should see where this is going ;) If you wonder why deathPenalty is implemented as Nothing: It has been abolished where I live. This of course means, that this implementation may not be accurate depending on location, meaning that you may have to adjust it. Therefore given the correct implementation for your country the isJust function of Haskell will infer whether the death penalty is actually part of the given justice system or not.
`Free` / `operational` correspond to the simple idea that *impure* code can be represented by *pure* data. Instead, you define the set of operations as a simple data structure and then you can then *interpret* this pure data structure in any environment you want. /u/gelisam's idea is to make your game monad output entity changes into a simple log with entries like "change light 1's transform to ..." which you can then inspect in a separate observer to make the necessary changes in GL. Alternatively, during debugging, you could just use the log to print out all the changes made. Since the code is pure and haskell is lazy, if you're careful, the observer will end up running as a coroutine with the log-generation code, so the whole log won't be resident in memory, just the part you are inspecting at the moment.
It's very sweet that you care about it, if only a little bit.
Or even a great deal.
Hmm. Any hints?
I now feel sad for polyamorists who have 3 or more lovers :( 
&gt; I write a code in (MonadWriter w m) =&gt; m a instead writing in Writer w a. I only use transformers to implement typeclass with monad stacking. I like the idea, it seems very principled. Do you ever get situations where the order in which the transformers are applied matters, but you can't express this dependency via typeclass constraints? For example, with `StateT s List a` each branch will track its own copy of the state, whereas with `ListT (State s) a` the state is preserved after backtracking. Or is that what the `MonadBase` constraint is about? &gt; And I’m really curious why, actually, FRP libs use IO and that kind of stuff whereas it’s not directly related. That's strange indeed. Maybe they're implemented in terms of IO? Which FRP packages did you have in mind?
I find when I have these sorts of extensibility problems, the most elegant solution ends up being a fixed-point functor somewhere. I don't totally grok your problem, but I think possibly something like this could work? data GCL f guard = Alternative [GC f guard] | Reptitive [GC f guard] | Statement (f (GC f guard)) data GC f guard = GC guard [GCL f guard] Then your manipulation functions generally assume `Functor f`, or in more complicated cases, `Applicative f` or `Monad f`. data Exceptions a = Raise | Rescue a a deriving Functor data Variables name ty a = Declare [(name, ty)] a | Assign [(name, a)] That leads straight into the a-la-carte mechanisms for manipulating groups of functors. 
Consider your 'mean' example: Fractional is a type class, not a type. That's why toNum is a somewhat misleading name - it's more like toNumSubclass, in general.
I feel like there's a little terminology confusion in your response here -- I've never seen a type that implements a typeclass called a 'subclass', although I have seen a typeclass that requires its members to be a member of another typeclass (i.e. Choice vs Profunctor) called a subclass. I've always heard a type that instantiates a typeclass called an 'instance' or more often just a type.
fwiw, ime, category theorists just say "tensor" (e.g., "\* is a tensor") rather than "tensor product". Which makes sense since not all tensors are products in CT.
Maybe I can throw together a simple javascript thing that emulates foldr and foldl.com but instead of clicking on `...`, you click on the node of a tree and it expands. Something like that shouldn't be too hard.
Ah, but Haskell is invariant under your preference in lover arity. :) Prelude&gt; let we = id; love = map (&lt;3); you = [1,1,1] Prelude&gt; we `all` love you True
&gt; I've never seen a type that implements a typeclass called a 'subclass' I'm talking about inheritance between type classes, not types. The function could be named ```toNumSubclassInstance``` if you want to make it more explicit. &gt; I have seen a typeclass that requires its members to be a member of another typeclass (i.e. Choice vs Profunctor) called a subclass. Right, that's the subclass relationship I'm referring to - in OP's 'mean' example, between the Fractional type class and the Num type class. For more about this, see [Type classes and overloading](http://www.haskell.org/tutorial/classes.html), starting at "Haskell also supports a notion of class extension." &gt; I've always heard a type that instantiates a typeclass called an 'instance' or more often just a type. Yes, types are referred to as instances of a type class, or just types. But what I'm pointing out is that ```fromIntegral``` doesn't just convert a value to a specific type. E.g. in the 'mean' example, it converts the value to a type '```a```' which can be any instance of the Fractional type class. So, in attempting to rename ```fromIntegral```, we'd ideally want to capture the fact that the conversion it performs can result in a type belonging to the ```Num``` class or any of its subclasses. Hence ```toNumSubclass```. 
 impossible = ($ Nothing) ghci&gt; impossible isNothing
btw, if anyone wants to learn about things like gibbs sampling in a mooc format, you might try this: https://www.coursera.org/course/pgm (It was a bit more intense that some of the other coursera classes I've taken)
If you are looking for the closest analog of the intuitive concept of a tensor product in types, it would be the **values** of A * B. In linear algebra, a tensor product of two vectors x and y, in vector spaces X and Y, respectively, is a tensor x (X) y in X * Y, where X * Y is the vector space product; that is, a Cartesian product of the underlying sets, along with a product of vector space operations. Forgetting all of the machinery of linear algebra (vector sums, scalar products, axioms, ...), and looking just at the underlying types (generalizing from sets), the product space X * Y is just the Cartesian product, and the tensor product becomes simply pairing (x, y). If you want the product to be on types themselves, rather than terms, then I suppose this could simply be lifted up to pairs of types (A, B) where A:K and B:H, and K and H are kinds. 
Note that since applicatives are really monoidal functors, then in a sense the operation you can build `tensor :: Applicative f =&gt; f a -&gt; f b -&gt; f (a,b)` is in some sense a legit categorical tensor, and furthermore the product of two applicative functors is in some sense a tensor product. In both cases there's a genuine notion of bilinearity at play as well, enforced by the applicative laws.
It seems like you might get a much cleaner solution via `foldl'`, where your accumulator is what are currently using as the state. You then don't have to fiddle with ByteString `head` or `tail`, and can instead use an optimized implementation which does the right thing. I have not tested this at all, that's just my hunch when looking at this code :)
Alright: I understand your explanation although I think it's a little bit roundabout -- "to any Num" implicitly includes all subclasses, but "toNumSubclass" to me blurs the distinction between "type" and "typeclass." I don't think this is really something that's very important to argue about though, so I'll probably just leave it unless there's something you feel the urgent need to cover.
I've posted an answer using ST and a strict left fold, I hope that it proves useful to you. I think It returns the same data you need to print out but if not, I don't think it should be too hard to make it work based on what's there.
Oh, I see, something like: data UpdateAction = EntityMoved … | LightAdded … | Whatever … Ok, I read the article *Why free monad matters*. Genious. I guess this could be used to solve my underlying problem. But I’m not sure it can be used to reactivness. Thank you anyway!
&gt; I like the idea, it seems very principled. Do you ever get situations where the order in which the transformers are applied matters, but you can't express this dependency via typeclass constraints? It hasn’t happened to me yet, but I guess it could. &gt; That's strange indeed. Maybe they're implemented in terms of IO? Which FRP packages did you have in mind? Especially [reactive-banana](http://hackage.haskell.org/package/reactive-banana).
&gt; "toNumSubclass" to me blurs the distinction between "type" and "typeclass." Names like ```fromIntegral``` do the same, just implicitly, since Integral is a type class. It's implied that a name like ```fromIntegral``` means "from an instance of the Integral type class." &gt; "to any Num" implicitly includes all subclasses Yes. My reason for being extra explicit about the subclasses was that if the (rather dubious) goal is to try to make the name fully explanatory, mentioning Num alone could be confusing to a beginner because the result can be a type that belongs to a more specific class than Num, such as Fractional, or a specific type like Double, etc. &gt; I don't think this is really something that's very important to argue about though Hmmph, if we're going to design a language change that we don't think is a good idea, we may as well do it right! Based on this discussion, I've decided that the ideal name would be something like ```fromIntegralToSomeNum```. However, since this function's type returns a Num, we may as well drop the last part and call it ```fromIntegral```. 
`these` provides case analysis for `These` values, much like `either` does for `Either` values. The difference is that `These` values can have three cases – either the first value is present, or the second value, or both of them at the same time. these :: (a -&gt; c) -&gt; (b -&gt; c) -&gt; (a -&gt; b -&gt; c) -&gt; These a b -&gt; c `for` is `traverse` with its arguments flipped. It takes something traversable, such as a list or a tree, and then applies an applicative on each element and sequences its side-effects. for :: (Traversable t, Applicative f) =&gt; t x -&gt; (x -&gt; f y) -&gt; f (t y) `view` is the function in the lens library that takes a getter and an object and gets a field of that object. It's *simplified* signature (there's a more general one that /u/chrisdoner used) is view :: Getter s z -&gt; s -&gt; z I'm pretty sure `do let in` is a red herring in the sense that it doesn't affect the result. ---- To derive the signature, in the definition `these for`, we know that for :: (a -&gt; c) which means that a ~ Traversable t =&gt; t x c ~ (Traversable t, Applicative f) =&gt; (x -&gt; f y) -&gt; f (t y) Further, in `these for view` we get to know that b ~ Getter s z c ~ s -&gt; z where this `c` together with the previous `c` tells us that s ~ Applicative f =&gt; x -&gt; f y z ~ (Traversable t, Applicative f) =&gt; f (t y) so we can rephrase `b` as b ~ (Traversable t, Applicative f) =&gt; Getter (x -&gt; f y) (f (t y)) Now we have correct types for `a`, `b`, and `c`. If you'd want to, you can just plug them in in the signature for these for view :: (a -&gt; b -&gt; c) -&gt; These a b -&gt; c and get something that roughly looks like what /u/chrisdoner posted!
Yes it is. Thanks!
Just what i needed. Thanks much
I made something similar a while ago to track exceptions in code in a similar way to Java (the exceptions a piece of code can throw are a part of its type, and exceptions get removed when caught). I'm not sure if this is my most recent version but you might find it useful nonetheless: https://gist.github.com/axman6/9830049 I also had a version that worked using indexed monads but it's at home; I'll try to remember to paste it later tonight. It seems to me the easiest way to do what you're after is to keep a Nat counter for assigning unique values to each resource when you allocate it, and keep that value along with its type: data Val n e = Val e and allocate would be allocate :: a -&gt; Unique (n,ns) (Succ n,n ': ns) (Val n a) and consume would be something like consume :: (Contains m ns, Delete m ns ~ ns') =&gt; Val m a -&gt; Unique (n,ns) (n,ns') () Edit: Here is my latest version: https://gist.github.com/axman6/19adc08a809d919a2efb I've been meaning to write a blog post about it for a while but never got around to it.
Yep ... but can I savely infer this the other way around? Eg if -O0 removes the bug there is probably some unsafe global variable in the code?
Very sensible idea, I've added a bug report to do that soon: https://github.com/ndmitchell/hoogle/issues/72
I don't think this is correct in all the cases. The validation might be happening further down the road, or there might be multiple states in which the *object* can be. For example it could also be `Expired CreditCard`.
If it's any consolation, I though this was pretty funny. It's tough to be in the avant garde.
 D: Isn't there anything like this based om lambda calculus instead of TMs?
SKI calculus would be fairly nice and easy to represent with such a simple syntax.
Slides?
Sure, you could probably make an [unlambda](http://www.madore.org/~david/programs/unlambda/) dialect quite easily.
http://alissapajer.github.io/conferenceslides/flatmaposlo2014/#/
 $ dist/build/brainfuck/brainfuck Hodor ~/hodor.hodor Hello World! I beg your pardon. This is **not** how Hodor would say ‘Hello, World!’
No problem. We just have a rare kind of sense of humour. That can be considered a good thing. )
I'm not sure to understand your point.
Maybe the binary lambda calculus?
The proper Hello World program in Hodor should of course output ‘Hodor’.
Great example of a "real" functional server here. Building a scalable, functional server is so different than anything you would do in an imperative language. Could someone comment on the performance + scalability of this design? Other designs I've seen don't use a concurrent thread and process a clients message queue when the client sends a message (bringing the fork count down by 1 per client, or in this case, halving it). This sometimes works OK for i.e. games, but makes them less responsive. Do we need to worry about spawning a lot of lightweight threads waiting on resources (since they internally rely on things like kqueue or epoll), generally?
Oh, sorry, I got that part; I just don't get the joke. But now that I read it again, I think I get it now.
But... murder = ($ (take 1 ["innocent's"])) head deathPenalty = ($ (take 1 ["serial killer"])) head &gt; deathPenalty == murder False 
Not that there "probably" is. One thing -O0 does is disable inlining. If it fixes a problem, the root cause *might* have been the inlining, but maybe not. Looking for accidentally inlined global mutable values is quick and easy to do. Because of that, it's worth checking when the problem goes away with -O0. But it doesn't mean it's "probably" the problem.
loved the bit in "equal rites" (one of my favorites) in which pratchett explains that the librarian enjoyed the simplicity &amp; lack of stress that came with his only worry being about getting his next banana.
That's what I was going for with the `GclKnot` newtype. GclKnot stmt1 guard ~ GCL (stmt1 (GclKnot stmt1 guard) guard) ~ data { Alternative [...] | Repetitive [...] | Statement (stmt1 (GclKnot stmt1 guard)) } In earlier (unreleased) iterations, I've tried your solution too. The problem then was that I ended up with UndecidableInstances (because of `instance SomeClass (f (GC f guard)) =&gt; SomeClass GCL (f guard)`). I know that that's not necessarily a problem, but it also meant that, somehow, my Show instances only diverged ._.
Waiting for Guardians of the Galaxy to come out. I'll be curious to see if folks repeat this with "I am Groot." ;)
This is actually what the `individually` lens does. It's a `Setter` that points to the next level of a `FreeT`. So if you want to modify something 3 layers deep, you use: over (individually . individually . individually) However, I'm planning on making a switch to the `fuse` library eventually, which provides a faster `FreeT` replacement that makes the monad layer optional. This makes it much easier to write this code.
Can someone explain the Client{..} syntax? I've never seen that before. Example: sendMessage :: Client -&gt; Message -&gt; STM () sendMessage Client{..} msg = writeTMChan clientChan msg EDIT: Okay, so it appears to expose all the fields of the record so that they can be referred to just by their name. When was this feature added and what is it called?
At that time I've spent some time digging in code and have seen things like [this](http://hub.darcs.net/darcs/darcs-screened/browse/src/Darcs/Util/Download.hs#78). I had a stong suspiction the bug was hidden in download manager (a small detached part of darcs source). First I had an idea of too many threads spawning, curl breaking, etc. But after rebuilding project with **-O0** I've noticed only ~5 files got rebuilt (I've touched Download.hs right before rebuilding) and darcs started working correctly. One of rebuilt files was [Global.hs](http://hub.darcs.net/darcs/darcs-screened/browse/src/Darcs/Util/Global.hs). Right before opening that file for the first time I somehow knew what I expected to see there. In general **-O2** -&gt; **-O0** change does not necessarily manifest errors of exactly such kind. They can be: * wrong rewrite rules (but people usually know how to write them, thus rules are sane) * weird optimization/cross-module-CSE bugs [like this](https://ghc.haskell.org/trac/ghc/ticket/8425) None of them are easy to track down in big apps.
Your probably want enunPattern = [[1]] ++ map enunBlock (group (sndLast enunPattern)) as the definition of enunPattern, at least that should type check, though I don't know what your code is supposed to do. Pretty sure what it does is loop infinitely. Is this some kind of Project Euler thing?
resolved.
You might try writing type declarations for `sndLast` and `enunPattern`.
Possibly, but exploring and ruling out other approaches (tagged, phantom types) is better than making it up as you go.
Nice simple tumblr blog about Haskell from the POV of someone just starting out and becoming amazed. Very enjoyable. Yet - somehow, almost every topic turns out to be touching on something very controversial, presented with simple innocence. Is that intentional? Examples from some of the (currently) most recent posts: * [Yesod: Can Haskell Do Everything?](http://haskelier.tumblr.com/post/88852201648/yesod-can-haskell-do-everything) - Very nice simple "Hello world" example of a Yesod site. But you had better duck; the comments about Yesod relative to other Haskell web frameworks might start a major flame war (please people, be gentle). * [Being Lazy](http://haskelier.tumblr.com/post/87332360773/being-lazy) - Yes, Haskell's laziness is indeed really cool. But... this example isn't regular laziness. It's "lazy IO", which some people think is Evil Incarnate and should be Banned. I disagree, but it's definitely not as simple as it appears to be in this example. * [Point Free Style is for Cool People](http://haskelier.tumblr.com/post/86934475968/point-free-style-is-for-cool-people) - Point-free can indeed be very cool. But, hmm... First of all, if you're going for point-free, go all the way: remove the "point", i.e., the variable. Write it this way: `nZero = length . takeWhile (== 0) . reverse . map digitToInt . show` Here again, though, there are people with strong opinions about whether point-free style helps or hurts program readability. I'll take the liberty of expressing my own opinion on this last one (since I think I'm pretty close to the middle here): Point-free style for its own sake is a fun game, but not for real code. However, *combinator style* does help readability. It just so happens that combinator style code is often also point-free style, or at least has "less points". "Point-free style" means transforming an expression to remove all free variables. "Combinator style" means writing an expression as a pipeline of operations sequenced by function composition. Your example here is a great example of "combinator style".
&gt; The goal of type safety is to mitigate these errors. If a type-safe language encounters a type error, type safety ensures that the program does not run. Strict languages, like Haskell, perform these type safety checks during the compilation process This doesn't seem like a description of type safety to me, which is traditionally "Well typed programs do not go wrong" where "go wrong" refers to a "stuck state" or undefined behaviour. Also, I chuckled when a lazy language like Haskell was described as strict.
Well, at least our taste in programming languages is more mainstr... Oh, wait, never mind.
You have a mistake in your README. Your equivalent of "[" is "Hodor! Hodor?", not "Hodor. Hodor!".
Almost - you left a "`$`" in there which needs to be replaced by "`.`" The way you have it now doesn't type check.
And yet another one without the hack of converting the number to a string: nZero = length . takeWhile (== 0) . map (`mod` 10) . iterate (`div` 10) However, that only works if the input is `&gt; 0`. To handle also that case correctly it starts to get a bit longer: nZero = length . takeWhile (== 0) . map (`mod` 10) . takeWhile (&gt; 0) . iterate (`div` 10) 
Is that surprising? The second element of enunPattern seems to depend on itself.
I'm sure you meant to say [lazy k](http://homepages.cwi.nl/~tromp/cl/lazy-k.html), not unlambda.
Thank you for pointing this out! Fixed.
Note that even inside the recursive definition, `enunPattern` refers to the *whole* infinite list, not just the part constructed "so far". Applying `sndLast` to an infinite list is just not going to work. Are you trying to make a look-and-say sequence? If so this should work: enunPattern = [[1]] ++ map f enunPattern where f xs = concat (map enunBlock (group xs)) or less pointfully: enunPattern = [1] : map (concatMap enunBlock . group) enunPattern 
I'm no Haskell wizard, but when I tried to run your OpenGL code, I got this: opengl.hs:17:31: Couldn't match expected type `IO a0' with actual type `(a1 -&gt; Bool) -&gt; [a1] -&gt; ([a1], [a1])' In the second argument of `($)', namely `(break)' In a stmt of a 'do' block: renderPrimitive Points $ (break) In the expression: do { clear [ColorBuffer]; renderPrimitive Points $ (break); mapM_ (\ (x, y, z) -&gt; vertex $ Vertex3 x y z) myPoints; flush } Failed, modules loaded: none.
I wanted it to depend on the previous element. 
Haven't tested the Hodor version myself (no Haskell compiler installed at work), but I think this should work: * [hodor.bf](http://pastebin.com/BJtC1wWs) * [hodor.hodor](http://pastebin.com/b37Wp5Js)
Not a haskell wizard either, but I got it to compile: import Graphics.UI.GLUT myPoints :: [(GLfloat,GLfloat,GLfloat)] myPoints = [ (sin (2*pi*k/12), cos (2*pi*k/12), 0) | k &lt;- [1..12] ] main :: IO () main = do (_progName, _args) &lt;- getArgsAndInitialize _window &lt;- createWindow "Hello World" displayCallback $= display mainLoop display :: DisplayCallback display = do clear [ColorBuffer] renderPrimitive Points $ mapM_ (\(x, y, z) -&gt; vertex $ Vertex3 x y z) myPoints flush That is, the (break) meant "ignore this '(break)' and the upcoming newline"
Oh, of course. That makes sense.
The Control.Concurrent example doesn't look like valid Haskell (`putChar ' That '`).
Yes, I didn't know it was called a look-and-say sequence, but that's what I'm trying to do. I don't really understand the where clause but that does not work :(
Thank you so much for this. Edit: Yup, that was a fascinating read. It was so great to be able to see how you saw the problem and approached a solution. Edit: I thought I'd enumerate some of the strategies I noticed you using: * Search for functions and types with Google, Hoogle, and Hayoo. * Check types in ghci with :t. * Rewrite my snippet into a function that returns just the desired value (instead of adding more features to the snippet until it did everything). * Work with desugared types. * Read documentation when stuck. heh * Have written a similar library yourself already. :) * Reformat error messages to line up corresponding types. * Add type annotations to narrow the scope of compile errors. * Whatever strategy called for "replacing responseBody resp with fmap (const "foo") (responseBody resp)" (I don't understand what you were going for here yet, but it helped you get to a state where things compiled). * Know monad transformers. * Write sanity checks. * Know FreeT. * Whatever "computational interpretation of a free monad" and "container interpretation of a monad transformer" mean. P.S. Sorry I didn't mention which packages and modules I was using. That might have saved you a few minutes. :)
It's not, putChar should be putStr, the single quotes should be double, sdtout should be stdout, and Control.IO should be System.IO
Thank you for the example and links! I like the convention of having a .Tutorial module and I've been looking for them since I noticed the pattern. Not to say you shouldn't make a link. :) It's pretty clear to me from your code that I'm missing too many prerequisites to have ever written that on my own, because I never took notice of individually, &lt;*, or yield as functions to pay attention to in my reading! It's bizarre to me that this could be the case, since I don't remember being in that kind of position in any other language, but after this thread I'm about ready to accept that Haskell is just complex enough that some libraries are simply impossible to use without careful study. :)
&gt; my Show instances diverged Ugh, that sounds awful. I've had success with auto-deriving the Show instances using standalone deriving. If you're using a custom (pretty-printing?) show interface, that's more complicated.
Both Either and (,) are monoidal products on Hask (with the usual provisos) but there's a good reason to think of (,) as the tensor product. The defining universal property of a tensor product is that it's left adjoint to the Hom functor. In mathy notation, Hom(A(x)B,C)~=Hom(A,Hom(B,C)). For vector spaces, this is saying that a linear map over the tensor product can be thought of as a bilinear map and vice versa. For the category Set, (x) is the Cartesian product and ~= is the Currying isomorphism. Similarly in Hask, we have: curry :: ((a,b)-&gt;c) -&gt; (a-&gt;(b-&gt;c)) uncurry :: (a-&gt;(b-&gt;c)) -&gt; ((a,b)-&gt;c) Thus, (,) is the tensor product on Hask as well as Set and any other Cartesian closed category.
I certainly don't want to look a gift horse in the mouth and I did enjoy this episode. However, I think Functional Geekery would benefit for more upfront preparation of questions. The shows often tend to meander a lot and I feel like some questions are made up on the spot that probably shouldn't be.
`iterate` is a good way to make a list where each element depends on the preceding.
Thank you for the advice, I fixed it.
The Cartesian product of vector spaces is a "direct sum" (+), not a tensor product (x).
Does tumblr have rss somewhere?
I can't tell from the code what you're trying to do. If you let us know we might be able to help you get a working implementation. Consider this function fibonaccis = 0 : 0 : 1 : zipWith (+) (drop 1 fibonaccis) (drop 2 fibonaccis) This definition works because in the recursive part you drop at most two elements, then take the _first_ element, meaning you will look at most to the third element in the list. Now in this definition of fibonaccis we explicitly give the first three elements, so we can find out what those elements are. This means we can calculate the fourth element. But then we've found the fourth element so we can also find the fifth element, since that is defined looking only at the fourth element. This holds inductively, so this will produce an infinite lists of numbers. In your call to sndLast, you say we should drop one element from the _end_ of the list (init), the _look_ at the end of the list (last). But we don't have these values available as they have not yet been produced. This is why your program loops indefinitely.
Apologies if I came off as flippant! I think ``fromIntegralToSomeNum``, or maybe ``fromIntegralToAnyNum`` is appropriate, but fails obviously because of its verbosity and similarity to the existing name.
Here was my take on the same thing (not using `recursion-schemes`, though): http://5outh.github.io/posts/2014-04-30-hylomorphisms-and-treesort.html Nice article!
They do: &lt;http://haskelier.tumblr.com/rss&gt;. It's linked in the source: &lt;link rel="alternate" type="application/rss+xml" href="http://haskelier.tumblr.com/rss"&gt;
It seems that the Brainfuck version works great, but Hodor's one is stuck in an infinite loop... Don't know why yet.
Have the Haskell lint tools been updated to reflect this? 
You're welcome! &gt; * Whatever strategy called for "replacing responseBody resp with fmap (const "foo") (responseBody resp)" (I don't understand what you were going for here yet, but it helped you get to a state where things compiled). I had been trying to get the ByteString from the input and output type parameters to the result type parameter. Nothing was working, so I took a step back and tried to understand the purpose of the result type parameter. Typically, the type of the result parameter changes as the computation goes forward: f :: a -&gt; m b g :: b -&gt; m c f_then_g :: a -&gt; m c f_then_g = f &gt;=&gt; g Notice that the result type parameter for `f` is `b`, while the result type parameter for `g` is `c`. They are different. Since my working hypothesis was that `(&gt;-&gt;)` was like `(&gt;=&gt;)` but for `Proxy` computations instead of monadic computations, there was something very strange about the fact that `(&gt;-&gt;)` requires the result type of *both* of its arguments to be `r`. In order to improve my understanding of how `(&gt;-&gt;)` handles the result type parameter, I wanted to made an experiment in which I combined two `Proxy` computations which did have the same result type, but different result values. In retrospect I could probably just have used `return "foo" &gt;-&gt; return "bar"`, but at that point I didn't have a good intuition for how to create values of type `Proxy`, so I took the two `Proxy` computations I already had and applied a simple transformation to one of them so that they would have the same result type. &gt; * Know `FreeT` Actually, I knew `Free`, but not `FreeT`. &gt; * Whatever "computational interpretation of a free monad" and "container interpretation of a monad transformer" mean. Good, that means your brain has not yet been infected by the common "monads are computations" and "functors are containers" analogies which some people ([not me](http://gelisam.blogspot.com/2014/01/functors-are-computations.html)) find so misleading :) I thought using one of those analogies might help me visualize what `FreeT` meant, but that did not turn out to be useful in any way. What worked in the end was to inspect and expand the type of `runFreeT`.
Resolved. Everyone thanks for the great feedback. Just tryin' to help the Advanced Layman.
It still says sdtout :p
Why does iterate not work, like someone else suggested? enunPattern :: [Int] enunPattern = iterate f [1] where f xs = concat (map enunBlock (group xs))
I probably just did something stupid in my translation script. Here's the quick python script I wrote to translate BF to Hodor: http://pastebin.com/XzT6zH5N
Well I translated the BF version to Hodor too, but got the same result. Strange.
Am I crazy for liking this better? nZero n | n &lt; 0 = nZero (-n) | n &lt; 10 = 0 | n `mod` 10 /= 0 = 0 | otherwise = 1 + nZero (n `div` 10) (Converting the number to a list seems like the real "hack" to me.)
This definitely work, oerjan gave you definitions that used the same idea you initially tried to use to show you how you would do it correctly. But his solutions definitely worked, why do you think they don't work ?
Sometimes this is exactly what needs to be said. Thank you sir!
Would something like this work? import Data.List (group) sayGroup :: [Int] -&gt; [Int] sayGroup [] = [] sayGroup g = [length g, head g] sayGroups :: [Int] -&gt; [[Int]] sayGroups = map sayGroup . group lookAndSay = concat . sayGroups lookAndSayN n = take n . iterate lookAndSay 
I see, you're implementing the look/say sequence. You just want to do enunPattern = concat $ iterate (concatMap enunBlock . group) [1] [edit] My bad, I see you posted what you were writing already above.
Shouldn't that be fibonaccis = 1 : 1 : 2 : zipWith (+) (drop 1 fibonaccis) (drop 2 fibonaccis) ?
Technically, the `(&lt;*)` is not necessary. You can write `(m &lt;* n)` as: do r &lt;- m n return r It's only necessary to use `(&lt;*)` if you have something that only implements the `Applicative` type class and not the `Monad` type class. However, you definitely need to learn how to use `yield` if you want to use `pipes`. That's fundamental to `pipes` and you can learn more about the `pipes` fundamentals by reading this tutorial: http://hackage.haskell.org/package/pipes-4.1.2/docs/Pipes-Tutorial.html
In that case it would be: over (utf8 . lines . individually) (yield "Your prefix here" &gt;&gt;) stdin &gt;-&gt; stdout
I love the idea. Hodor !
That would be useful, but that's not what `individually` does. Just looking at the type signature, changing a `FreeT f ...` into a `FreeT g ...` requires touching all layers. Checking the source it's defined in terms of a recursive worker function. Trying it out: number :: (Monad m) =&gt; Int -&gt; FreeT (Producer Text m) m r -&gt; FreeT (Producer Text m) m r number n = over individually (\layer -&gt; yield (Data.Text.pack (show n)) &gt;&gt; fmap (number (n+1)) layer) &gt; runEffect $ over lines (number 0) (yield "A\nB\nC\n") &gt;-&gt; stdout 0A 01B 0112C Edit: More specifically, in the type Setter (FreeT f m x) (FreeT g m x) (f (FreeT f m x)) (g (FreeT f m x)) you see see the whole outer `FreeT f ...` turn into a `FreeT g ...` when your inner operation only changes one layer, and leaves the inner layers alone in the returned `g (FreeT f m x)`.
This doesn't work because what you get is a List of Lists aka `[[Int]]` but the type signature you give for `enunPattern` is `[Int]`. Everything else is perfectly fine. Adding the additional `[]` should fix the problem.
Well, let's see whether `deathPenalty` is more than `murder` &gt; deathPenalty &gt; murder True Apparently `deathPenalty` is not `murder`, it also can't be `Just murder` since those are even different types. Also that should be Maybe values in those lists, since you can never be 100% sure about those things.
If your work utilizes some sort of Streaming library you can maybe save that sentence.
Oh yeah, in that case you would have to manually recurse over the `FreeT`. Alternatively, you could define a `zipWith` for `FreeT`s, but right now there is no library that has such a function.
If this is the game that we are playing, then I am going to make Pikachu speak turing complete as well. pi &gt; Move the pointer to the right kachu &lt; Move the pointer to the left piii + Increment the memory cell under the pointer kaaa - Decrement the memory cell under the pointer chu! . Output the character signified by the cell at the pointer pika? , Input a character and store it in the cell at the pointer PIIIIIKAAAAA [ Jump past the matching Hodor! Hodor. if the cell under the pointer is 0 CHUUUUUUUUUU ] Hello world is left as an exercise to the reader.
I typed it in exactly and it didn't work, that's why I thought they don't work, but maybe it's the same as my solution, that it needs the type signature [[Int]]. I'll test it in a few hours.
wow, you're learning Haskell as your first language? very brave of you, I would say Haskell has the steepest learning curve of any language I've tried. If you can pull it off you'll be a stronger programmer for it, but don't give up on programming if you find that you can't get comfortable with Haskell. Haskell has some great properties, but languages like Python are about 100x easier to write code in (though of course compared to Haskell that code will be slow, error-prone and somewhat verbose)
This worked! Thanks 
There's some algorithmic trading firms out there that use Haskell. There's also a Haskell group within Facebook, but you probably need a PhD to get in
resolved. I guess sometimes the brain assumes things, and I genuinely thought it was called autto-parsec. thanks, bud! 
&gt; Is Hodor turing complete ? :p The *model* Hodor (syntax + semantics) is Turing-complete, just like many variants of Brainfuck. Implementations aren't, because they specify *behaviour*, not semantics. TL;DR Hodor.
Yeah that worked. I think I had that initially but changed it for some reason... thanks!
As mentioned by others, the SK-calculus is pretty minimalistic (fun fact: the SK-calculus was described by Mozes Schönfinkel in 1924, preceding Alonzo Church's lambda calculus by twelve years!). Unlambda and Lazy K are based on it. [Iota](http://esolangs.org/wiki/Iota) and [Jot](http://esolangs.org/wiki/Jot) are even worse; they are based around the idea that \x -&gt; x (\a b c -&gt; a c (b c)) (\u _ -&gt; u) and function application is sufficient to simulate the SK-calculus, and thus the lambda calculus.
resolved, I accidentally changed one and forgot about the other. 
To start with, [list] -&gt; first_item isn't actually a valid type for head. A valid type would be something like head :: [item_type] -&gt; item_type. I think a lot of it comes from mathematical conventions where there are typical (short) names for things: f, g, h are functions; x is an element of a list and xs is the rest of the list; x' is a modified version of x; that sort of thing. It's not such a problem when writing short functions (as many functions are), but when writing longer functions more descriptive names should be (and often are, in my experience) used.
&gt;head :: [list] -&gt; first_item Except that this type is wrong. There is one, unique function of this type, and it errors on any input. You could give it the type `head :: [list] -&gt; list` but that's plain confusing, since the return type isn't a list all the time. It's clearer to use the variable `a` since you don't know any of its properties. It's straightforward to call it a single letter, since you know nothing about it anyway. If you're consistent and use `a` and `b` for arbitrary members, `f` for functions or functors, `m` for monads, etc., it's plenty clear.
 head :: [list] -&gt; first_item isn't a correct type signature for `head`. Nothing like it is valid in any programming language I know that allows type signatures. The fundamental point is that the return type of `head` is the same as the type of the elements of the lists. Your "readable" example says that they're different. Instead of being "easier to understand" it lies about what `head` does (and won't compile). I can't imagine why you'd want to do this. The type signature is intended to tell you the types, not which element of the list is picked out for return. Giving variables "descriptive" names can inhibit abstraction. A good example is the `mappend` function in the `Monoid` type class. Someone thought it was a nice descriptive name. But it's only descriptive if you're working with the monoid of lists. Otherwise it's verbose and incorrectly describes the operation. It's confusing for anyone reading monoid code. BTW If you're looking at functions like `head` you may be looking at library code and it's in the nature of such code to be as abstract as possible so as to be as reusable as possible. Having said that, in places where there is a clear and unambiguous meaning for a variable, Haskellers often do use descriptive variable names. (Well, I often do in my own code.) If there were unambiguous English word for the monad operations, say, I bet Haskellers would have used it.
I don't think `a` is nondescript at all! `A` is the first letter in the alphabet, after all. It is also the canonical indefinite article in the english language, and it is the sound that naturally comes out if you just open your mouth and make noise, so it is the first vowel that babies tend to learn to pronounce. Oh, nondescript_ive_. never mind, i'll get me coat.
I'll look past the mistake in the example, and try to address the underlying question. I think there are three reasons. 1. I'm sure some of it is just cultural. Haskell has a strong connection to mathematics, both socially - many Haskellers are mathematicians - and in practice - Haskellers often communicate with each other through academic papers, for example, and the language explicitly deals with abstractions from algebra, category theory, and more. In mathematics, one-letter variable and function names are traditional. But this is really a trivial consequence of the other two reasons, so I wouldn't obsess about it too much. 2. Haskell (and mathematics) emphasizes defining things into small, relatively simple parts. While I commonly see 300 line functions written in Python at work every day, you'd have a hard time finding a Haskell function or IO action of that length unless it's either machine-generated or follows an extremely simple, repetitive pattern. When you sometimes write 300 line complex functions, you need descriptive variable names. But `head` is a one-liner, and its variable names don't actually matter, because you can glance at it and understand what it does. 3. Most importantly, Haskell emphasizes abstracting things. Suggestive naming is useful when the things you are defining are only applicable in a specific context, which your names suggest. But Haskell makes it really easy to generalize. It's ubiquitous in Haskell to see people write something for some type, and then later go back and generalize over the type, building a new abstraction (or even better, recognizing their code as just an instance of an old abstraction) that isn't tied to that specific task. You might even just remove a type signature from your existing code to see what the compiler infers, and it can be surprising to discover that you were writing something more general all along! At that point, all those suggestive names are a mistake, and get in the way of understanding. To elaborate, let's take the `head` function you talk about: head :: [a] -&gt; a What would you prefer instead of `a`? As others have pointed out, you can't name `a` something different in different places. So really, all that `a` means here is "some arbitrary type". You might argue that this is marginally better: head :: [element] -&gt; element But I don't see this as a significant improvement.
Well, first off those are not variables, that's part of the type signature. Second, what you're comparing it to would be the names used in the function definition. But with all the pattern matching done there, longer names would just stand in your way. On the other hand you could consider this a language convention, because in a compositional programming language like Haskell, you won't be able to give meaningful names for arguments of a function, consider: flip :: (a -&gt; b -&gt; c) -&gt; b -&gt; a -&gt; c flip :: function_with_two_arguments -&gt; second_argument -&gt; first_argument -&gt; result flip :: (first_argument -&gt; second_argument -&gt; result) -&gt; second_argument -&gt; first_argument -&gt; result Noisy and it stands in your way of quickly comprehending the function's type. Also what you're refering at, just happens with polymorphic functions. When you're looking over specific application libraries the types are concrete.
Hah, I originally had a type signature in my code but I foolishly deleted it to make it look more like your original code :P
It's nicest to start 0,1,1; then you get the nice property that `gcd (fib !! m) (fib !! n) == fib !! (gcd m n)`
&gt; Apologies if I came off as flippant! No no, I was just kidding around myself. Especially that last suggestion.
I asked that on Twitter before (https://twitter.com/solirc_/status/478077224185118720), but it did not get much attention. If you see any issues with having -Werror by default, please raise your voice on the pull request. If there are no objections, I would move forward on this.
Consider this example: findAfter :: Char -&gt; String -&gt; Maybe Char findAfter match_char (first_char:next_char:rest_of_string) = if first_char == match_char then Just next_char else findAfter match_char (next_char:rest_of_string) findAfter _ _ = Nothing But first off, the types in the variable names are redundant, so perhaps we shorten them to: findAfter :: Char -&gt; String -&gt; Maybe Char findAfter match (first:next:rest) = if first == match then Just next else findAfter match (next:rest) findAfter _ _ = Nothing This is better, but I think still obscures the structure of data being pattern matched on the first line and recursively used on the fourth line. One letter variable names let this come out clearly: findAfter :: Char -&gt; String -&gt; Maybe Char findAfter m (c:d:r) = if c == m then Just d else findAfter m (d:r) findAfter _ _ = Nothing Now something magical happens: Here it is very easy to see that this function is more generic, and hence useful in more contexts: findAfter :: Eq a =&gt; a -&gt; [a] -&gt; Maybe a findAfter m (c:d:r) = if c == m then Just d else findAfter m (d:r) findAfter _ _ = Nothing Notice that other than the type signature, the function is the same. Now, why use `a` in the type signature? Because we want to emphasize that this works for *any* type at all. 
I've been doing this for some time with pandoc, with no issues.
It's a mathematics thing. The information lies more in the structures rather than the names. Also mathematicians are symbol fetishists.
GHC Haskell programs are extremely efficient in this domain, especially with GHC 7.8.2's recent improvements to the IO multiplexer. Haskell threads are "green threads", i.e. they are userspace threadlike heap objects multiplexed on a running set of OS threads (the "HECs", or "Haskell execution contexts"), and the HECs pick up work using a work-stealing scheduler implemented in the GHC runtime system. Haskell threads have a very low runtime overhead, you can safely create millions of them without worrying too much. Re: I/O, most of the I/O you do in Haskell isn't actually blocking. File descriptors are opened with `O_NONBLOCK` and if a read or a write returns `EWOULDBLOCK`, interest is registered on the file descriptor in the runtime system's I/O multiplexer, the green thread blocks on a lock and is descheduled by the userspace scheduler, and another thread runs. When the blocking call to `epoll()` finishes in the I/O multiplexer OS thread, the lock is posted and the per-connection thread is woken by the GHC scheduler. Much of this happens without any kernel context switches between system threads. This is why so many of us like Haskell for this problem domain. You get event-driven OS calls but the user gets to think in terms of threads --- a lot better than callback spaghetti.
Hoogle can only search the packages it has been setup to search, and the only way to 'discover' any new ones is to search the package name database included in the search index. Searching for 'Par +monad-par' will work, but that would obviously require you to have already done a Google search to know in which package 'Par' is. One thing you could try is to use FP Complete's version of Hoogle, which is configured to search all of Stackage: https://www.fpcomplete.com/hoogle?q=Par&amp;env=ghc-7.4.2-stable-13.09 I'd also recommend to install a local version of Hoogle and just add all the packages into the default search index that you frequently use. Last time I did that I took some notes: https://gist.github.com/blitzcode/8123168
&gt; Well, first off those are not variables, that's part of the type signature. .... They are variables *in* the type signature. 
Why do people downvote this?
Might be of interest: https://gist.github.com/Piezoid/b4602e9d23f6888750ac I'll probably try to transform this into a package with Piezoid's permission sometime. I haven't tried it yet, but I've been using a similar script to get local hoogle search working, so it should work. I use hoogle locally with haskell-mode to auto-insert import statements for out of scope symbols.
All good points. I'd like to add that the length of a variable name, in any language, should be chosen in proportion to its scope. Type parameters, especially, tend to have a very narrow scope. That said, Haskell's community and culture tends to do a poor job spelling out the intended uses for type variables (in, say, Haddock docs). For instance, you will see `ST s a` in `Control.Monad.ST`. You can probably pass on the `a` parameter, saying "it's the monad variable" or whatever handwavey nonsense you tend to say. But what is `s`? Why is it not `b`? Now, I've never actually seen an answer written out anywhere, but to the best of my knowledge, the `s` stands for "store". Once you fix the `s` value, your `ST` command only works for *that particular store*. The magic of `runST` is that it may only run commands that have yet to fix which store. This amounts to being free of any stray refs.
Indeed, good naming convention comes because programs are complex enough to forget what variables refer to. Types tend not to get that complex.
The minimal complete definition for `Ord` is either `compare` or `&lt;=`. Just `&lt;` doesn't cut it. The reason you run out of memory is that `compare ` and `&lt;=` are defined in terms of one another by default, so if you don't define either of them you get an infinite loop. 
&gt; head :: [item_type] -&gt; item_type Intention is not to return type but one link of a list passed as an argument: head :: [item_type] as in_list -&gt; item of in_list e.g. to avoid result forging (cheating). Returned item must belong to the original list. Another thing is that naming function 'head' does not automatically guarantee that returned value will come from a head position. Haskell...
You might want to look into the span function from Data.List.... but looking at the definition of group (I'm a relative newbie, too), you made the right choice, it gets you closer, so you just need concat [[length ys, head ys] | ys &lt;- group xs] (And thank you, Loonybinny; this turned out to be fun to work on. It boils down to a neat little pointfree one-liner (three with the "import Data.List" and type declaration).)
If you are talking "abstraction levels" then Lambda calculus is the lowest you can go with a functional language. If you are talking "close to the metal" then Haskell can be both super low level (peek/poke/malloc/alloc) and super high level.
Most of the cost of software is in long term maintenance. Haskell dramatically reduces the cost of long term software maintenance. Why? Because it is hard not to write well maintainable code in Haskell given its strong type system and emphasis on purity. The key reason why C++/Java/C#/Ruby/... code almost always turn into spaghetti code (given enough time and people working on it) is because of "long distance effects": Subtle dependencies in one part of the code creating bugs in other parts of the code because of shared references to global or non-global MUTABLE objects.
In some accents, "a" is pronounced as ə.
That's a very cool function.
No, but the source code does... Types are propositions and programs are proofs of the types. There's only so much you can say in Haskell's type system about things like that; all the type [a] -&gt; a says is that the result will be the same type as the elements in the list, and you can infer that it is probably an element from the list (or a non-terminating value like an exception) and you can know that it is the first element by inspecting the definitons, i.e., the proof.
I suppose that she talk about how Haskell changed her mind, not her brain, since there is no CT scan of her brain before and after using Haskell. It is unfortunate how people mix both concepts
She is wrong by about one type universe
People have already commented about your types being incorrect, so I won't talk about it. I was like you at first, but then I learned to read and understand types, and to like generic types. I think a tool that shows instantiated types in your code helps a lot. I use emacs with flycheck, and insert () where I wan to see the type. I've never liked it, and hate the syntax as well, but you may be interested by labels from OCaml : http://caml.inria.fr/pub/docs/manual-ocaml-400/manual006.html#toc35 But I guess it is going against the Haskell way of doing like pointfree programming, curried functions, etc. 
[Which?](http://en.wikipedia.org/wiki/Weasel_word)
This is fixed, thank you!
My love for you is a pure function from `Soul` to `Soul`, stateless and total, oblivious to the `RealWorld`.
He really should have put an α there.
I think it comes down to the tension between concreteness and abstraction: "mainstream" OO-style programming encourages people to think about concrete objects from the real-world and model them directly as program entitites; simulations were the first sucess cases for OO programming back in the late 60s. Functional programming encourages thinking about abstractions and how they compose together rather than concrete representations. In the particular example about, the list can contain any type of value and understanding is not improved by giving the type or terms variable a longer name. Compare the two alternatives: head :: [a] -&gt; a head (x:xs) = x head :: [element] -&gt; element head (firstElement:remainingElements) = firstElement This is even more so if you consider polymorphic functions abstracted over more than a single type; for example function composition: (.) :: (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c f . g = \x -&gt; f (g x) What the above function does is purely structural and is best understood *without* any "meaning" attached to the types a, b, c or the names f, g, x. Of course this does not prevent people from using concrete descriptive names for concrete things, i.e. I'd write data Person = Person { name :: String, age :: Int } instead of data P = P { x :: String, y :: Int } But for abstract things it is IMHO best to avoid lengthly names because they are not really descriptive.
You state that the function has a derivative of 0 at all points where it exists, but in fact I recall proving at some point that it always has a right derivative equal to zero, and never has a left derivative. I'll try digging up the proof.
So you pronounce “apple” as `[əpəl]`? It's common for ə to replace unstressed vowels in English due to [vowel reduction](http://en.wikipedia.org/wiki/Vowel_reduction) (e.g. “America” and “Australia”) but I'd be very surprised to hear it in a full “a” vowel or the word “a”.
Ed Kmett had a nice comment on this when it came up a while ago: http://www.reddit.com/r/haskell/comments/1jga0d/sticks_stones_but_names_are_not_useful_to_me/cbefsyi
I have one new point to add. Please do not use underscores in Haskell variable names, because it adds difficulty to scanning the structure of the expression. Specifically, `first_item` looks much too similar to `first item`, which is a function application.
If you have a function foo :: [a] -&gt; a you know that there are basically 4 alternatives: 1. It returns an element of the list. 2. it loops forever. 3. it returns undefined. 4. it uses unsafeCoerce to create a value of type a Assuming that the function isn't straight up wrong or evil (i.e. cases 2-4), then you know it returns an item from the list.
However, he *is* right in that it is the first vowel babies tend to learn to pronounce; along with consonants p, t and m (maximum openness, maximum occlusion, maximum occlusion with open nasal pathway).
I turn it on project-by-project personally, as I only want it about 2/3rds of the time and I actually don't know how you can actually turn it back off if you don't want it. =/
I tend to like the applicative usage of attoparsec a little bit more: parserIP = IP &lt;$&gt; d &lt;*&gt; d &lt;*&gt; d &lt;*&gt; decimal where d = decimal &lt;* char '.' Note that you need it import `Control.Applicative` for `&lt;$&gt;` and `&lt;*&gt;`.
In short, it's for mental pattern matching and it's because a lot of the time the things we're naming are MUCH more abstract than the things you're naming in mainstream languages. I wrote a blog post about this awhile back. http://softwaresimply.blogspot.com/2011/12/whats-in-name-lot.html
Yes, I wasn't disputing the babies bit. To do so would be a category error: schwa is not an English vowel, so “first vowel that babies learn to pronounce” doesn't apply to it. :-)
I'm tracking that here: https://github.com/ndmitchell/hlint/issues/57
Not all Australian accents pronounce it əpəl, but some do. The New Zealand accent definitely pronounces it that way. But I was talking about the indefinite article "a".
don't forget to import (&lt;*) as well.
For /u/comrebi's benefit, you should be able to write the instance as compare = compare `on` clientId or something to that effect.
I hadn't used Hayoo in years until a few days ago. It's way better now and the results are really great.
Anyone care to compare/contrast with [WAVE](http://hackage.haskell.org/package/WAVE)?
Thank you for your intelligibly advice!! It seemed quite novice mistake. I've fixed and it worked as I expected. 
It looks concise and clear so that I rewrote the instance as you wrote. Thank you!!
I'm glad to see how I should have define that kind of data types. It seems to be critical thing so that I will keep what you taught me in my mind. Thank you!!
You'll be happy to know that bugs of this nature are now found at compile-time with GHC's [minimal definition checking](http://www.haskell.org/ghc/docs/7.8.1-rc1/html/users_guide/pragmas.html#minimal-pragma). It always bothered me that it was so easy to write incorrect instances for classes allowing choice over which functions must be implemented.
I rechecked my claims. They are right. The properties of this function are derived in Example 31.1 of Billingsley's 'Probability and Measure'. 
deriving `Eq` just makes a structural comparison, comparing matching constructors, and recursing on the fields. For phantom type params, for example, there will be no `Eq` constraint. The `Eq` constraint on the `a` in `Maybe a` is there because the recursive comparison of the contents of `Just` implies it. Now, if you try to do something like: data Foo = Foo (Int -&gt; Int) deriving (Eq) It will refuse, because `(Int -&gt; Int)` has no `Eq` instance. However, in your `Pair` case, you do have an `Eq` instance for pairs (you used `deriving Eq` in your `Pair` declaration). The fact your instance itself has a context of constraints just propagates these constraints forward, but the instance exists.
 list : {{A : Set} -&gt; Set list {{A}} = A first-item : {{A : Set} -&gt; Set first-item {{A}} = A head : {A : Set} -&gt; List list -&gt; first-item in Agda. :x
It works just like you think. The generated Eq instances just happen to be mutually recursive, just like the types.
Nothing to do with the deriving mechanism: instance (Eq a, Eq b) =&gt; Eq (Pair a b) where ... instance (Eq a) =&gt; Eq (EvenList a) where ... instance (Eq a) =&gt; Eq (OddList a) where ... All of these instances are as you'd expect. You can even make it into explicit dictionaries: type EqDict a = a -&gt; a -&gt; Bool eqPair :: EqDict a -&gt; EqDict b -&gt; EqDict (Pair a b) eqPair ea eb (MakePair a1 b1) (MakePair a2 b2) = ea a1 a2 &amp;&amp; eb b1 b2) eqEvenList :: EqDict a -&gt; EqDict (EvenList a) eqEvenList ea EvenNil EvenNil = True eqEvenList ea (EvenCons p) (EvenCons p') = eqPair ea (eqOddList ea) p p' eqEvenList ea _ _ = False eqOddList :: EqDict a -&gt; EqDict (OddList a) eqOddList ea (OddCons p) (OddCons p') = eqPair ea (eqEvenList ea) p p' So, your simple-minded view is correct.
Yeah, the code with explicit dictionaries is what I wanted to see, in fact I just wrote out the exact same thing myself and feel a bit ashamed for asking the question :-) The code is very intuitive, though it relies on laziness quite a bit. I guess I was trying to figure out how it would work in a strict language, and the answer is "use some laziness". Thanks!
Kind of loaded question. 
Would it help to see the code generated by "deriving"? $ ghc -ddump-deriv Main.hs ==================== Derived instances ==================== Derived instances: instance (Eq a, Eq b) =&gt; Eq (Pair a b) where (==) (MakePair x1 y1) (MakePair x2 y2) = (x1 == x2) &amp;&amp; (y1 == y2) instance Eq a =&gt; Eq (EvenList a) where (==) (EvenCons p1) (EvenCons p2) = (p1 == p2) (==) EvenNil EvenNil = True (==) _ _ = False instance Eq a =&gt; Eq (OddList a) where (==) (OddCons p1) (OddCons p2) = (p1 == p2) (I heavily edited the output to make it more legible)
Thanks! I didn't know about that flag.
Yeah, it looks embarrassingly simple to me now. Thanks!
minor nit: s/parser generator library/parser combinator library/1
What are you saying? Don't you like (.) :: (secondFunctionArgumentAndFirstFunctionReturnValue -&gt; secondFunctionReturnValue) -&gt; (firstFunctionArgument -&gt; secondFunctionArgumentAndFirstFunctionReturnValue) -&gt; firstFunctionArgument -&gt; secondFunctionReturnValue
That's really cool! Is this (hspec / hspec-attoparsec) only for unit tests? Or is there a way to verify input and output of parsing a file?
Your original definition works for negative numbers and your second defintion only works for positive numbers.
Parameterization. That said, just write the program first and find the extension points later. Haskell is quite good a telling you when you haven't completed a refactoring job, yet. So, refactoring is "easier". Evenutually you may want to dynamically load and unload (and reload) modules/plugins/addons, which is a bit of a pain in most languages, even ones that are more "established" than Haskell. ISTR Qt having problems with plugin unloading just before Qt 5 development started.