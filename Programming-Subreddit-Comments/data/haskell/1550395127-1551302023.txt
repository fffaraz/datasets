I much prefer punctuation at the start. I think part of it is that the punctuation is usually shorter, so it's easy to see both the punctuation and the names. If the punctuation is at the end, it's not much easier to see the names but a lot harder to see the punctuation. Another part might be that when I think it through in my head, my natural cadence is like "a, plus b, plus c" and punctuation at the end sounds like "a plus, b plus, c". I'm not sure if that's still a factor when the punctuation in question is like `&lt;$&gt;` which I don't think I have a mental pronunciation for.
I find 2 spaces sometimes feels like too little, and I have trouble seeing what indent level a particular line is at. I haven't spent much time with 4 spaces, though.
Manual formatting is something we should all avoid. It doesn’t matter how much it looks better in theory. Human formatting should never be an option. Use the tool like brittany and we need more supports and contributions to make it official. Just like go fmt, rustfmt, clang-format, black, prettier, and so on. 
&gt;Manual formatting is something we should all avoid... What is the advantage of making the code formatted similarly in all files? Why not just use a tool you like to format the code you are editing, and just leave it at that and let others do the same?
Any reason you used lacks constraints rather than scoped labels? 
Doesn't look like it handled command line parameters, though, right? I'm after an integrated solution
More indent space = more impetus not to nest so deeply = more effort to make simpler code = a good thing. I feel that this argument is always going to win out over an arbitrary preference for number of spaces. Besides, your preference flies in the face of at least [one study](http://www.ojr.org/070312ruel/) I found immediately (I've read others though) that find more whitespace helps the reader to identify groups/borders to easily skim-read bodies of text. You could argue that it's a different context I suppose, but I think people are likely to apply their reading skills/optimisations to reading code. As an amusing sidenote it looks like you can attract more male than female attention by putting ascii art cocks in your code. Gotta love eye tracking studies. Really though both your comment and mine are utterly pointless because people have these conversations about whitespace in every language and it always comes down to "this reads better" "no THIS reads better" :)
I was at the Haskell workshop in 2012. Is there anything like a 'Haskell workshop' today? I mean I think -- also in th epast -- Haskell Symposium moved more into the direction of a conference. So, is there any academic workshop, Haskell related, where I could publish with a student? Perhaps at "types" but I would prefer 8 pages.
I don't see now what I gain from freer monads compared to "record-of-functions" (or so called "Handler pattern"). The latter one brings me the same level of abstraction and modularity I need with less typing hurdles. On the downside there is a bit more syntax -- this corresponds to the effect declaration newtype Csv m = Csv { readRows :: forall i . (FromCSVRow i) =&gt; [CSVRow] -&gt; m i } -- a "handler" for the effect using another "effect" newCsv :: (Monad m) =&gt; FileProvider m -&gt; Csv m newCsv fileProvider = Csv { readRows = readRows' fileProvider } -- (part of) the implementation of the handler readRows' :: forall i . (FromCSVRow i, Monad m) =&gt; FileProvider m -&gt; [CSVRow] -&gt; m i readRows' fileProvider rows = do rows &lt;- readLines fileProvider Having to pass the \`FileProvider\` explicitly to \`readLines\` instead of just being able to call \`readLines\` because the effect is present or the \`MonadFileProvider\` constraint is there can be annoying to some because it is boilerplate (and can also be potentially abused to sneak-in a different implementation) but I'm personally fine with this. &amp;#x200B;
Recompiling is ok, what I find more annoying is to have to rewrite a 10 lines expression just because I want to change one line. This happens for example when * you want to try different scenarios for performance testing: "what happens if I switch to this Http client?" * you diagnose bugs: "Let's use a basic in-memory database to see if Redis could be the issue", "Let's switch the serialization back to JSON from protobuff" * write integration tests traversing 2 or more "layers" of your application and still want to mock what is at the bottom If I have to rewrite those 10 lines instead of just one saying "I want to modify just this" means that: * I might be less tempted to try a new idea * I might duplicate that code over and over and have more places to modify when the structure of my program changes (I have seen many examples of that)
Separating cosmetic changes from actual ones in version control is a hard problem, in general. Personally I try to always align things before I commit. Or to go back and edit commits to get the alignment right from the beginning before I merge. Weirdly, I kind of like putting the commas on the beginning of the line. To the point where I sometimes do it in other languages because it just reads better to me. Not sure why. I also prefer putting the dot at the beginning of the line in long chains of function compositions. As for violating orthographic conventions, I don't think that matters. This is not a natural language. And it's not restricted to Latin symbols. No idea where it got started though. I've noted that spj likes putting semicolons on the beginning of the line, so maybe the custom originated with the makers of the language? Or of the compiler, at least. 
It all looks great, but after reading about all the attention you paid to performance it's a letdown to see no benchmark comparison to `ByteString`. Do you think Warp could benefit from switching to `Bytes`? 
By "FωC" do you mean to ask why we don't need type abstraction (i.e., type-level lambdas)? The C (coercions/equations) in FC gives all the expressiveness you want via defunctionalization. - Defunctionalization for the win: https://typesandkinds.wordpress.com/2013/04/01/defunctionalization-for-the-win/ - The HKD pattern and type-level SKI: http://h2.jaguarpaw.co.uk/posts/hkd-pattern-type-level-ski/ - Haskell with one family: https://blog.poisson.chat/posts/2018-08-06-one-type-family.html I don't think there's a fundamental obstacle to have type-level lambdas and/or partially applied type families. One issue is that currently type application is injective `f a ~ g b` implies `f ~ g` and `a ~ b`, and this is not the case with type family application; the answer is to distinguish these two forms of application, and the current restriction of fully applied families is a limited realization of that. There has been some discussion about that on Haskell-café, and a dormant ghc-proposal. AFAICT, it's waiting for someone to take the idea to its conclusion. https://mail.haskell.org/pipermail/haskell-cafe/2017-May/127071.html https://mail.haskell.org/pipermail/haskell-cafe/2017-May/127070.html https://github.com/ghc-proposals/ghc-proposals/pull/52
I think a Haskeller with a few years of field experience will be able to bolt things very quickly even without any abstractions (though safety and simplicity will suffer to a degree), but it's very hard to hire or train these people, especially if you're under time pressure.
&gt; More indent space = more impetus not to nest so deeply = more effort to make simpler code = a good thing. I feel that this argument is always going to win out over an arbitrary preference for number of spaces. I have seen lots of code where this impetus does not win out. &gt; Really though both your comment and mine are utterly pointless because people have these conversations about whitespace in every language and it always comes down to "this reads better" "no THIS reads better" :) Yeah, I wasn't really trying to change anyone's mind. Just wanted to get some opinions on the matter
I personally limit myself to 74 characters to allow the Vim gutter ample space (it used to be 79, but I was in a huge C file one day and realised, oh crap, I have to take gutter into account). That’s just for my personal projects, though. I like having lots of windows side by side. At work, we use 130, which I’m also okay with, since I have a big screen at work. IMO, if you’re going over 80 (or 74–76, really), then you might as well start at 110 or 120. A 15 character increase is not worth the cost of going over the still standard 80x24 terminal window. Maybe it’s just me, but I like that small size as my default and just don’t want to change it.
I've been waiting for this.
I'm for a simplification of the string-bytestring-vector-boxed-unboxed conundrum. If there is an speedup in performance what can I see? That's great! 
There's a bench folder on the GitHub repos, each sub-folder contains a separated benchmark which can be built after install stdio, of course, there're much more things to be benchmarked though, we just haven't got that many labors. My personal wish is to finish a JSON module ASAP, then do a real-world JSON benchmark to see how our new ByteArray# based system works. &amp;#x200B; BTW, we welcome all kinds of benchmarks from the community, please submit your result if possible! &amp;#x200B; &amp;#x200B;
&gt; A 15 character increase is not worth the cost of going over the still standard 80x24 terminal window. Maybe it’s just me, but I like that small size as my default and just don’t want to change it. I share this opinion, and that's why I find it so strange to fix the limit at 90. I think it's literally the first time I see anyone recommend a 90 columns limit. But maybe limiting oneself to 80 columns or less is a Vimer thing. Or a python thing.
I don't know as I'm not the author.
I think it's a terminal thing; there are even people who don't use the terminal and still recommend it to be nice to your coworkers. As someone who sticks to 80x24, I say screw me and increase the line limit if you need to. We have big screens and it'd unreasonable of me to hold back your line length because I won't move past that 80x24 default.
How does this scale to bigger effect rows? What happens when you want to use the same file provider effect in many places as the same target for several effects? I suspect if you actually try to use this pattern for n&gt;5 effects you'll quickly decide it doesn't scale as nicely as you'd think!
For comparing with bytestring and vectors, \[here\]([https://github.com/haskell-stdio/stdio/tree/master/bench/data](https://github.com/haskell-stdio/stdio/tree/master/bench/data)) is a benchmark you can try to run. My own result suggests most of the combinators is at least competitive if no faster than bytestring's. But like I said above, we probably should write something bigger and benchmark for with some real-world data though.
Unfortunately it fails to build for me In file included from dist/build/Std/IO/UV/FFI_hsc_make.c:1:0: FFI.hsc: In function ‘main’: FFI.hsc:527:16: error: ‘UV_FS_COPYFILE_EXCL’ undeclared (first use in this function) /opt/ghc/8.6.3/lib/ghc-8.6.3/template-hsc.h:38:10: note: in definition of macro ‘hsc_const’ if ((x) &lt; 0) \ ^ FFI.hsc:527:16: note: each undeclared identifier is reported only once for each function it appears in /opt/ghc/8.6.3/lib/ghc-8.6.3/template-hsc.h:38:10: note: in definition of macro ‘hsc_const’ if ((x) &lt; 0) \ ^
&gt; I have seen lots of code where this impetus does not win out. Indeed! I personally find it a helpful nudge. &gt; Yeah, I wasn't really trying to change anyone's mind. Just wanted to get some opinions on the matter I like 4, I find it easy on the eye, I could get on board with Linus' requirement of 8 in the Linux kernel though for both reasons.
Great and sincere post the highlight the miseries of the current blessed alternatives for programming in Haskell. There are however alternatives that don't have such problems: the graded monad for example Today a Haskeller is like a truck driver which program and executes a route, But -unlike in other languages. he has to construct his own roads to begin with. Many of them enjoy it. Most of us that want to use Haskell to do things are not so pleased with that state of things. In practical terms, this makes haskell a very low level language (sorry). All the effects can be reduced to two or three: early termination, extensible state and continuations. An standard monad transformer stack that has the three effects and maybe has the type enrichment of the graded monad would solve the problem once and for all because ANY effect can be constructed by creating primitives that use these three effects without the need to add a new interpreter or an additional monad transformer layer.
&gt;What happens when you want to use the same file provider effect in many places as the same target for several effects This is "automatically wired" in one place with the \`registry\` library. &gt;I suspect if you actually try to use this pattern for n&gt;5 effects you'll quickly decide it doesn't scale as nicely as you'd think! Then the "constructor" for each "component" only declares the dependencies it needs and you generally should try to control how many are required. If you need more than n dependencies to provide a given service maybe you are missing a level of abstraction. In that sense this is not very different from writing an interpreter requiring the presence of other effects in the stack. 
This kind of feedbacks are exactly what we need since we don’t have that many building machines. Before filling an issue on our github repo, i’d like you to check again your libuv’s version, which should be greater than 1.14. IIRC the missing defines is added with exactly that version.
I do, for the same reason you said. There is no temptation to align operators which have no particular reason to be aligned.
Hi! I think it might be good to give you an update. After some very non intrusive modification to the code (basically adding strictness, inlining and specialization) the code went from &gt;3000ms to ~170ms. It seem that Haskell can definitely (and relatively easily) achieve reasonable performance, although it is not designed from the get-go for that purpose.
Nice to see a reply. It is in a sense senseless to write here, because you cannot argue with people who cannot read -- I don't mean you but the downvotes. There a two issue. 1.Many people, mostly beginners, write programs that GHC cannot optimized. A solution would be to either automatically solve those issues or to provide beginners a AI, that looks over their shoulders to give them advice. 2. Second, it is clear that many languages including and especially Haskell, perform very bad on very bad CPUs (every CPU we have that is). The very minimum is openly saying what a shit situation and to be greatly dissatisfied without getting too depressed at the same time. If you and others (and I in past did all the same mistakes) don't know how caches work, why Haskell adding 3 more indirection is a nightmare, and why 32kb Intel caches are a stupid idea, then we are just in a pop culture. In otherwords, learn about Hardware and build your own CPUs! if you are serious about software. 
Really do you need an specific monad for a "file provider"? a simple state monad can transport the file name. If the state monad is extensible, you have 90% of the effects provided by that single state monad including parsing. In particular, ALL the effects that Sandy example of an interpreter can be created by writing primitives that use that single extensible state monad.
When working on a team, it’s highly valuable for improving readability, if everything looks the same. When automatic formatting is not enforced, I very often see code in different indent levels and widely varying styles—consistency is not to be underestimated!
I don't think you can avoid traversing the structure twice (well one more than `f` does) here, so I do not think it is in recursion-schemes as a single call. If you limit `f` to be a `Fold` (from Control.Foldl) or `cata alg` for some algebra, maybe you can fuse the extra traversal?
I'd be interested what tradeoffs for using arrow syntax were. As far as I can tell the added introspection isn't really used so it could have been monad as well? As far as I can tell the type of animation with everything inlined is data Animation a b = Animation Duration (Duration -&gt; Time -&gt; a -&gt; (HTML, b)) type HTML = HashMap Text Text -&gt; Data.Binary.Builder.Builder
&gt;I do not agree that Applicative is the answer here If you have "applicative effects" you can keep several "effectful values" around and interpret them how you wish. In \`f &lt;$&gt; e a &lt;\*&gt; e b &lt;\*&gt; e c\` can use different interpreters to "execute" \`e a\`, \`e b\` and \`e c\` to eventually apply \`f\`, including executing them with a dedicated thread-pool. Why would this not work?
I guess it would. Perhaps I was unclear on what you were referring to. I read it as if you were saying that something like \`traverse foo \[1..1000\]\` should just concurrently execute \`foo\` over all 1000 items - but I was arguing that concurrency is far more nuanced than just sparking threads for every action. It sounds like that isn't quite what you meant though.
The original 3blue1brown python library doesn't use arrows so it's definitely feasible. It would be interesting to have both a monadic and arrowic (spelling?) API. The monadic combinators would be less powerful but the convenience might be worth it. Especially since the bulk of the source code just deals with SVGs and therefore doesn't care about the animation API.
&gt; arrowic (spelling?) "arrowized"
That's interesting to think about. I agree, I don't think you can avoid the extra traversal - thinking about this specific example, at least, processing the list by aggregating the maximum would give more complexity than just doing two traversals. I wasn't sure if recursion-schemes was strictly limited to functions that perform a single traversal, or more broadly just covers some relationships of algebras/comonads to functors, but that definitely makes sense. &amp;#x200B; Mostly, it just seems like a common, but general task - I can at least imagine also using it for things like getting standard deviations from the mean. Since the core of it's the relationship of an element to the whole, zippers and lens strike me as other places this functionality might already be hiding, but the types in both libraries are similarly a little opaque, so I was hoping someone could tell me if I was getting warm. I suppose I should probably just bite the bullet and do some reading. Thanks for the insight.
OK I didn't know about GADTs change in 06 and the fact that language extensions are not always mere extensions. Thanks for the details.
Author here. I prefer having such a constraint, especially for variants. I think repeated labels are more likely to arise from a programming error rather than from intent, so I'd rather disallow them.
&gt;Many people, mostly beginners, write programs that GHC cannot optimized. A solution would be to either automatically solve those issues or to provide beginners a AI, that looks over their shoulders to give them advice. Where could one find advice on that subject?
You could google for "ghc indirections". There is also a book "Parallel and Concurrent Programming in Haskell by Simon Marlow". There is Real World Haskell book' One can also check the (debian) benchmark game haskell programs such as n-body. Those programs run fast by using non-standard "prim" operation for those parts of the program that need full performance. If you are motivated and need a mentor, you can write me a PM.
If you mean the AI giving advice to beginners, that is not written yet.
If you are curious my Scala experiment with the \`Eff\` monad has an "Applicative" case in addition to the monadic one data Eff r a = Pure a -- execute an effect returning x and apply the continuation to get Eff r a | Impure (forall x . (Union r x) (x -&gt; Eff r a)) -- execute n effects returning x1, x2, x3 and apply a continuation to get Eff r a | ImpureAp [forall x . Union r x] ([x] -&gt; Eff r a) This works in Scala by being totally, horribly, untyped. I don't remember why I did not structure this like ImpureAp forall x y . (Union r (x -&gt; y)) (Union r x) (y -&gt; Eff r a) This would be more "applicative-like". I wonder if anyone tried this before, maybe /u/isovector would be tempted to try something similar in `freer-simple`?
Boehm-Berarducci is a CPS transformation (which I guess is an application of Yoneda) + currying. (a, b) = (forall r. ((a, b) -&gt; r) -&gt; r) = (forall r. (a -&gt; b -&gt; r) -&gt; r) --- On an unrelated note, &gt; forall r s . (b -&gt; r) -&gt; (a -&gt; s) -&gt; (s, r) ≡ (a, b) This is Yoneda for the (bi)functor `(,)` on the product category `Hask × Hask`: (forall r s, ((a, b) -×-&gt; (s, r)) -&gt; (s, r)) = (a, b) where `-×-&gt;` is defined as `((a, b) -×-&gt; (s, r)) = (a -&gt; s, b -&gt; r)`. 
Can I use this to animate 3d-ish stuff, so something like this: [https://cdn-images-1.medium.com/max/1600/0\*iqNdZWyNeCr5tCkc](https://cdn-images-1.medium.com/max/1600/0*iqNdZWyNeCr5tCkc).?
https://cocalc.com/ (which used to be the sage math cloud) has free accounts that give you an in-browser terminal and with ghc as well.
While you're here: the first-class modules example shows that your records are sort of impredicative. How far have you taken it? For example, in a fully impredicative system, if a function expects a `{ f : forall a. Ord a =&gt; a -&gt; a -&gt; Bool | r }` then I should be able to give it a `{ f : forall a. Eq a =&gt; a -&gt; a -&gt; Bool | r }`.
Your link’s broken for me but as it uses SVG so I don’t think so
isn't the framework for animating SVG-Graphics?
Here is the code for defining the category `cat1 × cat2` import Data.Kind (Type) import Control.Category type Cat ob = ob -&gt; ob -&gt; Type data (×) :: Cat ob1 -&gt; Cat ob2 -&gt; Cat (ob1, ob2) where (:×:) :: cat1 a1 b1 -&gt; cat2 a2 b2 -&gt; (cat1 × cat2) '(a1, a2) '(b1, b2) which is the product of `cat1` and `cat2`. Well not quite a `Category`.. `(.)` can be defined instance (Category cat1, Category cat2) =&gt; Category (cat1 × cat2) where id :: (cat1×cat2) a1_a2 a1_a2 id = ... (.) :: (cat1×cat2) b1_b2 c1_c2 -&gt; (cat1×cat2) a1_a2 b1_b2 -&gt; (cat1×cat2) a1_a2 c1_c2 (f1:×:f2) . (g1:×:g2) = (f1 . g1):×:(f2 . g2) but when we try to construct `id = id :×: id` we get id:×:id :: (Category cat1, Category cat2) =&gt; (cat1×cat2) '(a1,a2) '(a1,a2) the issue is subtle, but GHC isn't convinced `'(a1, a2) :: (ob1, ob2)` is equal to `a1_a2 :: (ob1, ob2)` (which is a type variable) so to define `id` we have to get rid of the pairs in `.. -&gt; (cat1 × cat2) '(a1, a2) '(b1, b2)` type family Fst (a1_a2 :: (ob1, ob2)) :: ob1 where Fst '(a1, _) = a1 type family Snd (a1_a2 :: (ob1, ob2)) :: ob2 where Snd '(_, a2) = a2 data (×) :: Cat ob1 -&gt; Cat ob2 -&gt; Cat (ob1, ob2) where (:×:) :: cat1 (Fst a1_a2) (Fst b1_b2) -&gt; cat2 (Snd a1_a2) (Snd b1_b2) -&gt; (cat1 × cat2) a1_a2 '(b1, b2) class (Category cat1, Category cat2) =&gt; Category (cat1 × cat2) where id :: (cat1 × cat2) a1_a2 a1_a2 id = id:×:id ..
Yeah, SVG’s are 2D. That link works now and it’s 2.5D isn’t it? The appearance of 3 dimensions but using 2 dimensions. Regardless should work for that use case yeah
ok, yeah, that's what i meant with 3d-ish.
Doesn’t Idris have built in Effects and Dependent Typing?
&gt; `getStatement` will take our transactions and, for simplicity, return a nicely formatted string which will be our statement. And here we see the crux of the problem: once we return `String` we lose our list of transactions! Looks like we'll have to return them too. Does `getStatement` affect the list of transactions at all? If not, then how is anything being lost? Couldn't the program just keep using the same list of transactions that it passed in?
&gt; I wasn't sure if recursion-schemes was strictly limited to functions that perform a single traversal, or more broadly just covers some relationships of algebras/comonads to functors, but that definitely makes sense. `gcata` is the most general single-pass fold; all the functions in the `Recursive` class can be written in terms of it and `project`. `gana` is the most general "single-pass" unfold; all the functions in the `Corecursive` class can be written in terms of it and `embed`. You can definitely use recursion-schemes to build multi-pass transformations, but "exotic" ones prepro/postpro/zygo show that by "decorating" your algebra, you can fuse many things into a single pass. (Also, doing interesting things with function values can also get you multi-pass behavior, since the functions you return can reflect the structure present in the first pass.) --- Control.Foldl is also all about single-pass folds, since `ReaderT [a]` ends up doing many passes, but it's pretty common to want to calculate statistics in that style: `avg = (/) &lt;$&gt; sum &lt;*&gt; length` for example.
That README is awesome. Can't have too many examples!
So I wrote this library for use in some personal projects but mainly for the fun of it. Will use it to dive into low(ish) level optimization in Haskell, really eager to learn more about that. Would love to hear feedback :)
I think your choice of the word "decrypt" is telling. Yeah, maybe there's a reasoning in play. (at least, I'd certainly hope so) However, to a person that doesn't know the library, it just looks like you're censoring a swear word. I picked Lens because it's a particularly egregious example that I know has lots of operators, but this isn't a specific criticism of the Lens library. The language allows it, and the author decided to name the function `&lt;&lt;**~` instead of `updateToPowerAndGetPrevValue`. The language is at least partially to blame here. &amp;#x200B;
I’ve run into this problem before. IIRC it’s because GHC doesn’t have many eta rules implemented for data kinds. You can postulate them with unsafeCoerce! 
``` In pure functions try to avoid let. Instead, use where. ``` why?
This is opening up a whole another can of worms (that AFAIK isn't that popular with Haskell users), but indenting with tabs solves that nicely. You just setup your editor according to your preferences and everybody is happy.
That syntax for records is sweet. Is it new or derived from a previous language?
To clarify: these are not with strats at Standard Chartered (my team). This particular link seems to be an old version of a job ad that was subsequently revised for clarity. I believe the underlying job is this one: [https://scb.taleo.net/careersection/ex/jobdetail.ftl?job=1900001343&amp;lang=en](https://scb.taleo.net/careersection/ex/jobdetail.ftl?job=1900001343&amp;lang=en) As the ad on the official SC website mentions, these are to deal with technology developed by strats for the Treasury Modelling team. I'm very happy to see our projects leading to the expansion of Haskell within SC and to new countries!
It certainly depends on the student, but Haskell Symposium accepts papers co-authored with students (including undergrads) with some regularity. I don't have statistics off-hand for you, but I know of several instances of undergrads publishing there. If you're looking for a lower bar than Haskell Symposium, you might try Type-Directed Development (http://tydeworkshop.org/). Details aren't posted yet, but it will be co-located with ICFP in Berlin this August.
The open record syntax looks really similar to purescript. Some of the record operations also look inspired by Dhall as well.
This is really cool stuff, well done! 
&gt;When working on a team, it’s highly valuable for improving readability, if everything looks the same. When automatic formatting is not enforced, I very often see code in different indent levels and widely varying styles—consistency is not to be underestimated! Ok. But why does it matter when you can format the code to what ever format you find readable, with the mere press of a button?
I agree that `updateToPowerAndGetPrevValue` can be done. And it probably reads better when you want to do it once. But when you want to chain them (and it is exactly what you do with `lens`) to navigate the structure, access and update multiple fields, operators can be nicer. It is the same as with more often used operators: much more convenient to write a &lt;&gt; b &lt;&gt; c &lt;&gt; d than a `mappend` b `mappend` c `mappend` d Or newEnv Discover &lt;&amp;&gt; envLogger .~ logger &lt;&amp;&gt; envRegion .~ region &lt;&amp;&gt; envRetryCheck .~ retryPolicy 5 probably reads better than its equivalent which would look something like fmap (set (envRetryCheck (retryPolicy 5))) (fmap (set envRegion region) fmap ((set envLogger lgr) newEnv Discover)) or even set envRetryCheck (retryPolicy 5) `fmap` (set envRegion region) `fmap` (set envLogger lgr) `fmap` newEnv Discover For a person who doesn't know the library, it does look unfamiliar. But then this person looks it up and gains familiarity, I think :) No one is born knowing `lens`, even E. Kmett had to work hard while inventing it :) The `lens` library starts being _very_ useful and safes _lots_ of effort once at least basic concepts of it are understood. So it is very much worths learning. And the operator symbols in it are not random, which helps a lot. I just think that the prepositions like "it has unfamiliar operators, so it is wrong full stop" is a bit dismissive. And "we should only use functions, not operators" is very dismissive. Operators are useful and I think that it is good that our language allows them :) 
Reformatting constantly becomes a problem when version control enters the picture. If I change 2 lines in a file, but my automatic reformatting tool touches an additional 500 lines in the same file, the actual changes get a lot harder to spot in the diff. One alternative to style guides / formatting rules would of course be to create some kind of formatting insensitive diffing tool. But that's a rather non-trivial thing to do, especially if you want one that works across multiple languages. AFAIK, no such tool exists at this time. 
This is some great work you are doing. What is the difference between `Data.Vector.Unboxed.Vector a` and your `PrimVector a`? I see that `PrimVector a` is based on `PrimArray a` while `Unboxed.Vector a` is based on `ByteArray`. But those are both based on `ByteArray#` and the documentation says they are the same except for the type argument.
That's more of a first book tho
"Ex"presso. *Flinches*
This looks really nice, I have a few graph-related ideas is like to work on so I'll make a note of your library!
Really nice work. Good documentation too.
You might need a monad, or an interface for accessing the file system and write tests which mock this access. Could you please expand your thoughts on using a graded monad for the example interpreter? What would be the various types?
Nice. Did you have a look at the Algebraic Graphs library by Andrey Mokhov? (https://github.com/snowleopard/alga) It has a really cool grammar for constructing and composing graphs. I like that yours makes it easy to draw something.
Is it possible to access cabal flags from `{-# LANGUAGE CPP #-}` without explicitly passing them with conditional `cpp-options`?
Ah yes. You are right. &gt; some kind of formatting insensitive diffing tool. But that's a rather non-trivial thing to do, especially if you want one that works across multiple languages. AFAIK, no such tool exists at this time. Why is that a non-trivial thing? Isn't it just a matter of normalizing both version using the same formatting tool, and diffing on the result?
It'd be good to see some examples of broken show instances. Currently when I look at the home page I have no idea what problem this solves.
`PrimVector a`'s heap representation is basically same with an unboxed vector from vector package, but combinators from `Std.Data.Vector` works on `Vec` class, which is a different abstraction from vector package's one. There're more combinators in stdio package than vector's too, we try to provide an interface similar to bytestring(which is more comprehensive than vector). In stdio sorting and searching is also provided. There're also some rewritte rules to accelerate `Bytes` (`PrimVector Word8`) type in stdio, which is important to get high performance.
Nice work!
Very nice application of property-based testing and FP in general. Could you give an idea of how many engineers/time did this work take? Also, did the transition go through without major problems?
It was presso once, but it isn't anymore.
Very nice. I like the lacks constraint. It's clean, obvious and very readable.
A `Show` instance must output lexically valid Haskell code, this is the assumption behind https://hackage.haskell.org/package/pretty-show for example. But https://hackage.haskell.org/package/uuid-1.3.13/docs/Data-UUID.html#t:UUID and https://hackage.haskell.org/package/time-1.9.2/docs/Data-Time-Calendar.html#t:Day don't like to play by the rules: ``` ghci&gt; Time.fromGregorian 2019 02 18 2019-02-18 ghci&gt; UUID.nextRandom 428e2abf-a1bd-436b-8084-f321357eedce ``` This means that a huge data structure that contains just a single `Day` or `UUID` can't be pretty-printed with `pretty-show`
you can set/get the file name and wathever you need in the single multistate monad , that may be a simple state monad which contain, for example, a (Map typeRep Dynamic) and then develop the interface over it: getFromFile :: NoNewMonad MyContent getFromFile= do FilenameForMyProblem file &lt;- getIt readFile file getIt= get &gt;&gt;= fromJust . M.lookup (typeOf FilenameForMyProblem) A graded monad can incorporate new effect in the type of the result while the computation is running without the need of runners. For example: https://github.com/dorchard/effect-monad So that getFromFile, in a graded monad could have this signature: getFromFile :: NoNewMomad (MyFileEffect:effs) MyContent so I can notify all the effects that a computation has been using until now. Yo can also stablish constraints between effects. For example, to make sure that `getFromFile` has the file name in my state so that fromJust ever succeed you can force a compilation error if it is not here: getFromFile :: (Member HasMyFileInState effs) =&gt; NoNewMomad (MyFileEffect:effs) MyContent 
True, I suppose. But how would you choose what format to normalise to? You could normalise to your preferred formatting, but then you would be unable to compare your diff to other peoples. Or you could normalise to some commonly agreed upon format, but then it might not correspond to your local formatting in a clear way. I feel like there might be a missing layer of indirection here. If instead of working on files, you could work on locally formatted views of those files somehow. Then everyone could set up individual rules for how they want to see things. Including diffs, probably. Might make it a little bit more difficult to communicate about the code though, since your view of line `x` might correspond to line `x+2` in someone else's view. It's not clear to me how to solve this in a way that doesn't introduce some new source of friction elsewhere. That's what I meant by 'non-trivial'. 
Make sure your code compiles, otherwise it won't work. Took me some time to figure out that one. &amp;#x200B;
I was going to say that [`Builder`](https://hackage.haskell.org/package/stdio-0.1.0.0/docs/src/Std.Data.Builder.Base.html#Builder) can be [*derived via* (`DerivingVia`)](https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/glasgow_exts.html#extension-DerivingVia) [`Codensity BuildStep`](https://hackage.haskell.org/package/kan-extensions-5.0.1/docs/Control-Monad-Codensity.html) until I noticed `AllocateStrategy` newtype Builder a = Builder { runBuilder :: forall s. AllocateStrategy s -&gt; (a -&gt; BuildStep s) -&gt; BuildStep s} it can still be derived but `via` an ad-hoc version of `Codensity`
&gt; A Show instance must output lexically valid Haskell code There is no such requirement on show instances. The instances that are derived by default do satisfy this condition, but that doesn't mean that all instances have to. A big problem for me is that ghci uses show by default for printing results, and for many large types this is just completely unreadable. So I change show to output something that I can understand. Python solves this by having both `__repr__` and `__str__`, where the former gives a syntactically valid representation, and the latter gives any human readable string. I think that something similar should be adopted for the Haskell world.
Curiously, Template Haskell has a `Lift` class that provides exactly that - bits of syntax to be injected in your code. Maybe we should use a printer for *those* instead, to get a "debug" structural dump.
Does that always work? What if the data type has constructors that are not exported, for example Data.Map?
I absolutely love interactive output on the site and now want to implement this for all my packages.
Please note I am not the author :) Asking in the comments there is probably more likely to get an answer.
`Lift` has the same restrictions as for `Show`: types that should be abstract can have custom instances with fake/smart constructors, and computation types (`(-&gt;)`, `IO`) do not have meaningful instances.
It took me a second to figure out why it was called Shower, because I wasn't pronouncing it as show-er in my head.
All the examples do it in the way you are trying to avoid. Why are you trying to avoid that way?
It's strange to me that we have macros for things like package versions, but no (?) such trivial things.
Hmm. Good point.
You mean the Monad instance of Builder? Nice to learn something new ; )
Hi, unfortunately I did not implement an impredicative system, this is an obvious improvement that I could do, perhaps Daan Leijens HMF would be a good choice? I'm not sure how the type inference would be affected. Instead all type variables are at the top-level and rank-n polymorphism is used to apply polymorphic arguments. In your example above, the function would have to expect (forall a r. Ord a =&gt; { f : a -&gt; a -&gt; Bool | r }). Records containing multiple polymorphic functions can end up creating a lot of top-level quantifiers, so it's not ideal, but it works.
&gt; There is no such requirement on show instances. Maybe not, but it's a property which many of us have come to expect. I hate Show instances which don't respect this property, they make debugging needlessly harder. For example, &gt; foo Just divide by zero Looks like a `Just` containing a thunk which, when forced, failed with division by zero exception, but no, turns out the Show instance for exceptions is just their error message. Fortunately I can use `:force` to get to the truth: &gt; :force foo foo = Just DivideByZero But wouldn't it have been easier if `show DivideByZero` returned `"DivideByZero"`? &gt; Python solves this by having both `__repr__` and `__str__`, where the former gives a syntactically valid representation, and the latter gives any human readable string. I think that something similar should be adopted for the Haskell world. I agree! I think `Show` should be used for debugging, and it should always output Haskell code which can be used to reconstruct the value, whereas [`TextShow`](http://hackage.haskell.org/package/text-show-3.7.5/docs/TextShow.html#t:TextShow) should be used to construct human-readable strings.
Flags are more complected than package versions.
&gt;But how would you choose what format to normalise to? Why does it matter? I mean, as long as you use the same tool on both versions, any difference after formatting both versions will be the actual code difference, right? Or am I missing something.... 
Well, I was thinking it would, in the sense that you'd want to be able to relate the information in the diff back to the actual (non-normalised) files you're working on. But maybe I'm overthinking this. 
Hi r/haskell! I am the lead engineer at [ITProTV](https://www.itpro.tv). We produce video training content for IT professionals. I am excited to announce that we are looking to hire a Haskell engineer! Here are some answers to common questions: - We are looking for all levels of engineers, from junior to senior. - Our office is in Gainesville, Florida. We have a strong preference for locals, but if you think you're a great candidate and you're remote, please reach out! (US only though.) - We actually do most of our work in Haskell. Day to day it's probably 70% Haskell and 30% legacy JavaScript, with that legacy part going down. - We've been [pairing promiscuously](https://engineering.itpro.tv/2018/12/07/our-first-experiment-with-promiscuous-pairing-is-a-success/) for a few months and enjoy it immensely! As a candidate, you should be comfortable pair programming. I would be happy to answer any other questions you may have. If you're wondering whether or not you should apply: Apply! We'd be happy to hear from you :)
I, personally use haskell just to make mathematical calculations, because it’s easier there, than in C. I have a file named functions.hs which I load everytime to Prelude.
Yep it's a pun on expression. I also really like coffee.
&gt; But even if it does, how would GHC know what an "in-place update" even *means*? `Vector` is a library type, after all, so GHC would have to untangle its data representation (which seems to be mainly a ByteArray# at the bottom, plus some auxiliary size information), and understand how the various functions interpret that byte array. This is a good point. I'm not sure what the best way to give GHC the ability to switch between immutable and mutable representations, but GHC should always be able to turn a function like e.g. updateMut :: MVector s a -&gt; Int -&gt; a -&gt; ST s () into updatePure :: Vector a -&gt; Int -&gt; a -&gt; Vector a simply by doing a copy-on-write, ie. 1. Copying the `Vector` input to `writePure` to a new (unaliased) location 2. Applying the in-place update (`updateMut`) to the newly copied `Vector` 3. Having the return value of `updatePure` point to the location of the updated `Vector` This, however, requires that the `MVector` and `Vector` have the same memory representation, so that functions that operate on an `MVector` can be used behind the scenes for functions that operate on a `Vector`. &gt; I don't know exactly how GHC type checks linear functions (has it even been merged yet?), or whether it would provide sufficient guarantees in this case. It has not been merged yet, no. But the working repo is available here: https://github.com/tweag/ghc/tree/linear-types. 
The goals of Dhall was what I was aiming for when I started it, but obviously Dhall is much more developed. Dependent types in Dhall give them a really nice simple record merge operation, but at the expense of type inference. I suppose Expresso is exploring the alternative design space of better type inference but with a more basic record system.
I use Haskell at work! The project I'm working on is a little daemon that runs various checks on the machine, and sends the results to a server, which can then send someone an email if one of the checks fails. This involves a domain specific language for specifying the checks to run, and some web programming with the `wreq` library. In general, I'd say that Haskell *really* shines when it comes to implementing compilers and interpreters for other languages, both general-purpose and domain specific. All in all, I'd choose Haskell for *most* tasks. The exception is super lowlevel stuff - like, if I wanted to implement myself a filesystem or something, I'd probably reach for Rust or C instead.
"Unconditionally works" does not mean anything at all, but even taking it at face value it's simply false. SPECIALIZE requires RULEs in order to work appropriately and match less-specialized cases, so it can replace them with specialized instances. Phase ordering for RULEs (as well as the complexity of the generated RULE LHS matching clause, created by the compiler) can impact whether or not things fire, and thus become specialized. (Furthermore, in very special cases such as `vector`, where things *do* match -- SPECIALIZE is still not aggressive enough, and there are fixes in the compiler for this.) And when it doesn't happen, you're going to have a lot of "fun" figuring out why (because RULE ordering is a "global problem", it's very easy for "locally optimal" RULES to screw up *globally* optimal choices) SPECIALIZE *is not* a magic bullet, but it will work most of the time. Multi-Stage Programming on the other hand is *guaranteed* to always work: because you are just running a program that generates another program.
Any time you want to write a program that generates another program, "multi stage" programming is useful. It's like asking "why are macros useful" in Lisp -- because generating programs (and programs that generate programs, and so on and so forth) is pretty useful! For instance, I recently wrote a small OCaml program that took simple SQL query plans, represented as a tree, and generated working OCaml code from them. All I did was very simple: I wrote an interpreter for a query plan, and then "Staged" it so that rather than returning a *result*, it returns a *program* that returns the result. This is effectively a way of turning an interpreter into a compiler; a kind of [Futamura Projection](https://en.wikipedia.org/wiki/Partial_evaluation). There is a paper describing this exact technique, but for Scala, available here: [Functional Pearl: A SQL to C compiler in 500 lines of code](https://www.cs.purdue.edu/homes/rompf/papers/rompf-icfp15.pdf). My approach was the same but I used OCaml instead.
Yes. Also: * It supports Vim, Emacs, and Atom * It has editor commands for lifting holes to the top level, which is one kind of refectoring. * It does aggressive erasure analysis. * Documentation is available is a couple of places, and while I basically always think documentation could be improved, it's not horrible. * TDD w/ Idris contains some common patterns, and the answers to the exercises are available from at least 3 sources (Official, Me, and at least one other solver) That said, Idris isn't product ready or, at least, I'm not ready to use Idris in production. I've encountered a number of performance issues that I have yet to resolve or really understand (one of which is in the type checker and severely impacts development). Also, basically everyone that does any proof work seems to eventually run into #4001 or #3991 and I don't think there's a standard work around. Finally, the elaboration/delabortion cycle that your code goes through between the input file and the error message or splice result isn't an isomorphism, which can cause (1) error messages that refer to variables or values that are not in scope, or rather in scope but not under that name and (2) editor actions that *introduce* errors into the code, where doing the obvious action "by hand" does not.
That's wild. Thanks for the extremely clear explanation!
https://github.com/haskell/ghcup ? or maybe https://docs.haskellstack.org/en/stable/README/ ?
Huh?.. ``` putStrln $ "The flag_name is " &lt;&gt; flag where #if FLAG_SET_flag_name flag = "set" #else flag = "unset" #endif ```
Thanks. I am going off of this tutorial : &amp;#x200B; [https://www.reddit.com/r/haskell/comments/3x5ivh/installing\_haskell\_on\_a\_linux\_amazon\_ec2\_instance/](https://www.reddit.com/r/haskell/comments/3x5ivh/installing_haskell_on_a_linux_amazon_ec2_instance/) &amp;#x200B; but i've gotten stuck in this repos loop
Did you know that you can replace the behavior that GHCI does? For example, you can have it use pretty-show instead.
Visa sponsorship - or whatever the heck its called in USA?
The library indeed doesn't provide an easy way to test your types. But you can define a test function yourself: type T = Maybe (Float, (Float, Float)) myAssertApproxEqual :: Float -&gt; T -&gt; T -&gt; Assertion myAssertApproxEqual eps x y = case (x, y) of (Nothing, Nothing) -&gt; pure () (Nothing, _) -&gt; assertFailure "msg" (_, Nothing) -&gt; assertFailure "msg" (Just (x1, (x2, x3)), Just (y1, (y2, y3))) -&gt; do assertApproxEqual "msg" eps x1 y1 assertApproxEqual "msg" eps x2 y2 assertApproxEqual "msg" eps x3 y3
Try `DataKinds`.
No visa sponsorship. Candidates must be US residents. We are looking to hire at least one engineer now. Maybe more; it's hard to say. Depends on the candidates. 
Yum with Ubuntu? 
Rust just had a timely split with their propaganda minister, so he may be up for new horizons now. Whadda ya think /u/steveklabnik1?
I split with Mozilla, not Rust ;)
[https://www.fpcomplete.com/blog/2018/11/haskell-and-rust](https://www.fpcomplete.com/blog/2018/11/haskell-and-rust) we're very fond of Rust too, but cannot promise it'd be the focus of your work. &amp;#x200B; I'm a big fan of what you've done for Rust. I point to your example and others in the Rust community when discussing with others how Haskell could improve! I think some are sick of me talking about y'all so much :)
Do you *need* to install Haskell? I was recently trying to get Haskell to work on Elastic Beanstalk; the approach I eventually used was to just compile my program on my local computer and copy the binary over.
Have a look at https://stackoverflow.com/questions/54720058/datakind-unions on Stack Overflow.
Yeah HMF works well and you don't sacrifice any inference for the regular HM fragment. It doesn't have qualified types though, so there's work to be done in adding full support (especially so examples like the one above work)
ELI(not an expert) how does one decide when to use an initial encoding vs a final encoding?
I am also not an expert, but my understanding is that an initial encoding is easier for humans to think about, at the expense of being less performant. Final encodings require weird higher-order rank-n continuations, but because they're all just functions, the compiler will happily fuse them with its existing machinery.
I agree completely. I was working for a while on a project to provide this called `present`: https://github.com/chrisdone/present It automatically derives code to convert data types to structured representations, which can allow for GUIs to print interactively like the browser console shows JS objects, and other languages like Common Lisp do. https://github.com/chrisdone/present#detailed-output Lazy output was also catered to: http://hackage.haskell.org/package/present-4.1.0/docs/Present.html#t:WHNF I kinda got stuck deriving instances for higher kinded types. It's not impossible or anything, I just ran out of steam. Maybe actually /u/dpwiz has a point - `Lift` is basically my http://hackage.haskell.org/package/present-4.1.0/docs/Present.html#t:Value type (but making more things representable). And the http://hackage.haskell.org/package/th-lift-0.7.11 package is capable of deriving instances automatically. It doesn't even matter if the type's constructors are in scope or not, TH penetrates module boundaries. Perhaps I could kick-start that effort again with `Lift` as a basis. Can it derive an instance for `StateT`? Can someone check? I'll take a look more tomorrow when I'm at a computer.
Meh. Took them only like 3 years to realize their mistake and finally do what they should have been doing from the start. But I guess better late than never. But hey, it'll be onward and upward from here! Right?
so half of the would be "promoting free materials to help the community" can you elaborate? 
Thanks! I've added an example.
If it compiles with GHCJS, then it's actually not that hard! Here's how we did it: * In the Shower repo there is a small GHCJS project that generates a textarea and listens to changes: [https://github.com/monadfix/shower/blob/master/js/Main.hs](https://github.com/monadfix/shower/blob/master/js/Main.hs). * You can build it with a one-line command by doing `nix-shell reflex-platform/shell.nix --run "cabal new-build"` (well, you need to install Nix first, but reflex-platform does that for you – just do `reflex-platform/try-reflex` first, once). * You'll get some JS blobs hidden in the dist folder. There might be a better way to get them out but I just grab everything under `dist-newstyle/build/x86_64-linux/ghcjs-8.4.0.1/shower-js-0.1/x/shower-js/build/shower-js/shower-js.jsexe/*.{js,js.externs}`. * Minify the output: `closure-compiler all.js --compilation_level=ADVANCED_OPTIMIZATIONS --jscomp_off=checkVars --externs=all.js.externs &gt; all.min.js`. * Include `all.min.js` and `runmain.js` into your page and off you go. We could also just build the entire site with GHCJS but I'd actually like to avoid doing that because a) static is faster and b) if we do a Clojure library next, integrating it into a GHCJS-based site will be just as hard :)
/u/snoyman, I am only a haskell noob/enthusiast, but I have followed this sub and other community updates for some time. I think that, while small, this is a great change that will remove ambiguity and hopefully help avoid some conflicts within the community. Thank you for all the work you do to improve the haskell ecosystem. 
From what I see, they are migrating the site to a new domain. Why should have it be done 3 years ago? Is there a problem with the current domain?
We will be continuing to offer technical articles, training materials, recommended learning paths and curricula, and contributions to open-source packages, with a special focus an addressing needs expressed by commercial users. Letting people know what's available, and where to look, will be part of this person's job. Also, making sure we understand what people in the community are asking for, and what users do and don't think FP Complete should be involved in providing. As Michael Snoyman announced today, we have also just launched an early version of [https://haskell.fpcomplete.com](https://haskell.fpcomplete.com) as an opinionated place to get information for current &amp; future applied Haskell users. Helping new commercial Haskellers to discover new content from this site and from our own blog would be typical tasks. Another example, time permitting, would be to go on social media and respond to questions looking for applied Haskell learning resources, with links to articles that already exist but perhaps the poster did not know about. This can include resources from anywhere in the community, though of course I will expect the person to be diligent about mentioning FP Complete offerings when helpful — and to notice when we should get out of the way because another offering is meeting user needs just fine. An important part of this person's job will be to identify community resources that deserve promotion. Curating the links to other Haskell community resources, and links between our own blog posts and other educational pages/sites, will be important. Even changing the layout or navigation of our whole website to be more helpful is a possibility. But I must not neglect another important category: teaching Haskell users about non Haskell resources that might be helpful to them. We have amassed quite a lot of knowledge around QA, around CI/CD, around deployment &amp; containers, around AWS/Azure and Kubernetes, around logging &amp; monitoring, around GovCloud and general DevOps — things that are not at all about core Haskell technology, but that may be of great use to applied users. Helping people to discover and take advantage of these resources is important too.
It's not worth relitigating everything, but yes, the were social problems with the existing domain, and the new name with fpcomplete branding is a huge step forward for the whole Haskell community. Thanks, Michael; it means a lot.
I wonder if the types are nicer if you avoid even mentioning the transformers being used: ------------------------------------------------------------------------------ -- | Run an effect, potentially short circuiting in its evaluation. shortCircuit :: (forall a. eff a -&gt; Eff (Either e a)) -&gt; Eff (eff ': r) a -&gt; Eff r (Either e a) shortCircuit f = transform E.runExceptT (E.ExceptT . f) {-# INLINE shortCircuit #-} Then again, maybe having the bind of `ExceptT` is more useful. Not sure! Cool blog post though!
It's very late at night as I'm typing this so it may just be my half asleep brain playing tricks on me, but this vaguely reminds me of the difference between the two encodings of the free (not freer) monad in `Free`. Is there anything similar to the [improve](http://hackage.haskell.org/package/free-5.1/docs/Control-Monad-Free-Church.html#v:improve) function for these constructs?
Since Michael literally said in this post that it "was a mistake," it sounds like you are in agreement. May I make a suggestion, in the interest of community spirit? When someone makes a change to correct a past mistake, could you perhaps find a supportive tone for your comment? If we Haskellers can't be nice to someone who realizes a mistake, admits it publicly, and corrects it, well, what kind of community do we want to be?
The blogpost says &gt; retain the technical content and educational approach provided by haskell-lang.org, **without the bad history that goes along with that name.** And here's some references to give you an idea what "bad history" is referring to: - https://www.reddit.com/r/haskell/comments/50389g/resignation/ - https://www.reddit.com/r/haskell/comments/4ghznv/improved_hpcaballess_wwwhaskellorg_in_the_works/ - https://www.reddit.com/r/haskell/comments/4ruqbl/new_haskell_community_nexus_site_launched/ - https://www.reddit.com/r/haskell/comments/4zzmoa/haskellorg_and_the_evil_cabal/ - https://news.ycombinator.com/item?id=12054690 - https://www.reddit.com/r/programmingcirclejerk/comments/4rv6xo/new_haskelllangorg_site_haskell_community/ - https://www.reddit.com/r/programmingcirclejerk/comments/502s4n/haskelllangorg_guy_blogs_about_the_evil_cabal/ - https://www.reddit.com/r/programmingcirclejerk/comments/4rv6xo/new_haskelllangorg_site_haskell_community/ 
Once again, the continuation monad for the win. 
Thank you
I don't think it's worth digging up this history here and now.
This is the approach given by [Freer Monads, More Extensible Effects](http://okmij.org/ftp/Haskell/extensible/more.pdf). It's implemented in [`freer-simple`](https://github.com/lexi-lambda/freer-simple) among other places.
But it's still 2.5x slower. Unless there is a significant boost to productivity or there is some other great benefit, I still don't see myself reaching for this in an real world scenario... In practice, performance does tend to matter (i.e. you're not sitting in IO all the time and even if you are, once the IO is done you want to be fairly quick). It seems strange to base your whole code on top of something you know is slow to start with. It's not even about premature optimisation: I don't really fancy rewriting the whole code once I do need the performance. It's quite different from replacing `ord` with `ordNub` as it's not easily swappable.
&gt; you could use non-monospace fonts on your blog without readers being dicks about it Could you please give some details on the system/browser you are using to reproduce this behaviour? We are using the 'Ubuntu Mono' font for code snippets using the special settings for different browsers depending on the version and supported types, but as we are not professionals in frontend stuff, sorry if this makes it uncomfortable to read :(
Great idea - it provides a clear and focused message. Here's hoping you and FP Complete will be very successful with it. &amp;#x200B; Small typo, on the "success" page: the need to *commercial support* =&gt; the need for *commercial support* 
The increase in testability and other benefits is worth it in my experience. The performance cost isn't even noticeable in comparison. And this was using it in production generating big bucks thanks to the code. 🤠
This is truly embarrassing for us Haskellers. I want to apologize on behalf of the community for the rude behavior of this individual. I think I speak for every true Haskeller that it's inexcusable to criticize a company that has been generously contributing so much to the Haskell community when nobody else considered Haskell commercially viable while not getting any appreciation and getting attacked continuously from certain individuals. Haskell wouldn't be what it is today without your levelheaded leadership fixing and improving Haskell's tooling which has finally become usable. You deserve a big thank you on behalf of the Haskell community! Finally I hope those individuals posting anonymously aren't holding any positions of power in the Haskell community and if they do I would urge them to reconsider their stance towards FP Complete and stop harming the community with their misplaced resentment. And if they can't get with the program they should consider stepping down and let somebody else take over who is more appreciative of what FP Complete has been doing for us.
Yes, for example [`operational`](http://hackage.haskell.org/package/operational). Also see [`free-operational`](http://hackage.haskell.org/package/free-operational) for the relationship between `free` and `operational` and what this has to do with [`Coyoneda`](https://hackage.haskell.org/package/kan-extensions-5.1/docs/Data-Functor-Coyoneda.html#t:Coyoneda).
Probably a couple lists and two fields for the intersections would work fine. If you want to enforce correctness using types, you'd need to use fixed length lists.
Is anyone else getting an SSL error on this site?
Too bad he gave in to bullying. haskell-lang.org was objectively superior
I use Haskell at work to write HTTP daemons and a few minor CLI tools. Works a charm. &amp;#x200B; The things I like the most about Haskell at work: * Ease of refactoring * Clarity over where IO/effects are happening * No global state * stack - such a wonderful tool &amp;#x200B;
&gt;Elastic Beanstalk Hey thank you. that's interesting. can you please elaborate on 'copy' the binary over?
Stop posting this shit. **No one** cares about Kelsey Coin.
Looks a bit like the account was hijacked from the post history
[removed]
&gt; Finally I hope those individuals posting anonymously Speaking of posting anonymously, who the heck are _you_, given that you've only posted on 3 threads about drama and apparently nowhere else in this subreddit, or on reddit at all?
So... use 'em for a fork?
We're well aware that Haskell is *x* times slower than Rust in plenty of cases, or slower than assembly, yet we continue to use it. Why? Because absolute runtime speed is not the only measure of performance. Maybe this lets me get software out quicker, or allows me to produce more reliable software due to testing, or allows me to architecture software better because it doesn't need me to define a lot of boilerplate that I'll ultimately avoid doing and be unnecessarily terse. I'm not saying those things are necessarily true, just that they *might* be.
This isn't the continuation monad, it's a reader monad carrying a natural transformation.
Why does it matter? *I* don't hold any position of power in the community. I do however consider it very interesting that you feel addressed by my comment and going for ad hominems. Wasn't your [overreach by acting without authority](https://www.reddit.com/r/haskell/comments/4ruqbl/new_haskell_community_nexus_site_launched/d57j02g) the very cause that lead to the creation of haskell-lang.org?
If you read the article, the content is all being moved to haskell.fpcomplete.com
Why are you not using plain asciidoc blocks? You can then use [https://github.com/wenkokke/unlit](https://github.com/wenkokke/unlit) to convert to plain hs for compliation. You can execute unlit as a GHC preprocessor.
Oh wow! That never crossed my mind, but yeah!
Initial encodings retain all structure in the value, which makes them great for analysis (for example, my `parsec-free` library turns the parsec API into an initial encoding solely for this reason). That said, you can use a final encoding to build up the initial value if needed, or vice-versa, so normally you pick whichever one has the properties you care about most (speed, ease of construction/analysis, etc) and translate as necessary.
It forward my mind because you're now almost at simple-effects ;) simple-effects carries a product of handlers, but you essentially carry a sum of signatures. There is some depending connection between the two that I haven't entirely fleshed out. Essentially the record in simple-effects is a representative functor over 'm', and the functor that you pass around is more like an index into that functor... Something like that! The only other difference is that you forall over m, but simple-effects moves that to be a type parameter like a transformer
For old.reddit readers who were confused like I was, -- + Best createFoo = Foo &lt;$&gt; veryLongBar &lt;*&gt; veryLongBaz run = runApp . runMtlStuff . compute $ someData
Tbh I read all of that and I'm still not sure what the fuss was about. HP was to include stack, but people wanted Stack to be exclusively front and center? That's not really cool, especially because the tool was brand new at the time, and the committee moves slower than many would like because it has longevity concerns which are harder to reason about. If stack were the preferred build tool, and we exclusively adopted it, then, looking forward 4 years where it's tipping over trying to handle Nix, it would be just a mess. Please consider that Gershom was acting with an eye towards conservative, as opposed to radical progress. Either way, it's useless drama to keep citing that PR, and unnecesarily continuing a fight that only fans of Snoyman seem to keep fighting. We're friendly and he's spoken about how he's asked people multiple times to stop talking about stack like this. It's only damaging. He even admitted his mistake in haskell-lang.org (and good on him for it), so please, chill.
end of an era
You could also create a local branch. Really, there are many options.
I assume there’s no stream fusion framework in yours?
Maybe four \`Data.Sequence.Seqs\` like [this](https://imgur.com/lqSlG3C)? Then it should be quite simple to implement the rotations. The balls could just be \`data Ball = Red | Blue | Black | Yellow\`.
This seems odd. You can’t have a package on Hackage depending on a git SHA specifically, and an application probably doesn’t need to handle library versioning. Are you writing internal libraries for work?
Somewhat related, a development practice that I really like is what Michael Snoyman does. Every PR includes a change log entry and cabal version bump, them gets immediately released. Wouldn’t work for every library (E.g. Amazonka releases all of its packages in lockstep), but works for a lot of them 
Have two lists and store the indices where they are glued together. That way you can rotate by shifting the indices of the glue at one side and changing the color at the glued positions in the other list. data Ball = Red | Blue | Yellow data Puzzle = Puzzle [Ball] [Ball] (Int, Int) (Int, Int) 
Thanks for the link!
That is a silly reaction. E_Hackett is 100% right.
Very well said E_Hackett.
Haskell really excels if your project can grow arbitrarily large, and undergo a long development, by a lot of different developers. 
I’ve actually got a good start on this. Adding more is fairly trivial at this point. I’ll try to post something this week.
Thanks for the links! Defunctionalizatiob is pretty powerful, I didn't realize it would be applicable here. In hindsight, it does make a lot of sense.
Neat! But doesn't pretty-simple ([http://hackage.haskell.org/package/pretty-simple](http://hackage.haskell.org/package/pretty-simple)) also work withnoncompliant show instances?
I mean, I appreciate the point you're making; it definitely sucks when people are being unfair like that guy was. &gt; I think I speak for every true Haskeller that it's inexcusable to criticize a company that has been generously contributing so much to the Haskell community when nobody else considered Haskell commercially viable while not getting any appreciation But we shouldn't hold *anyone* on a pedestal deemed "inexcusable to criticize." No one is un-criticizable. And I'd say FPCo gets quite a lot of appreciation. They definitely weren't the first company to consider Haskell commercially viable (not by a long shot), but they've definitely done a lot to open others' eyes, and I don't think their work would be nearly as popular if they weren't very much appreciated.
&gt; You deserve a big thank you on behalf of the Haskell community! When did we elect you as spokeperson for the entire Haskell community again?
Still, I don't like that haskell-lang.org redirects to FPco's website instead of a neutral point of entry to the community, which is what many people would expect to get, I think, from a domain name of this kind.
&gt; Does anyone know the historical justification for putting the comma at the beginning of the line? I think is comes from early do-notation, before the layout rules, when SPJ (?) and a few other GHC developers adopted a semi-colon first style (which may have actually inspried the layout, that effectively puts semi-colons just before the first token on the next line). However, I've also seen it in other languages that don't allow a extra-trailing-comma. It's not really that much more flexible than some following-comma styles (1 "special" line per block) but the line that needs to be handled specially when it is re-ordered is more noticeable. leading-comma: [ first , line , line ] following-comma: { line, line, last } extra-trailing-comma: { line, line, line, } Note that leading-comma is actually more vertically compact than following-comma, which might also have contributed to it's use. IMO, extra-trailing-comma (or in general extra-trailing-separator) should basically always be allowed by modern languages, even though it does make the parsing a little bit harder. I try and use it whenever I'm allowed.
I disagree. The IOCCC submissions are works of art. :) But, yeah, most of the time, team/leadership/BDFL should just decide on an auto-format tool and the options to use, and either it should be run automatically before every commit, or style should be checked as part of CI.
I agree the number chosen is weird. I prefer 78 myself, fits an 80-column real terminal (which... I sort of have to use sometimes) without possibly running into the gutter. That said, most Java styles use either 100 or 120 characters, and I've also gotten used to that. ISTR remember than more than about 120 characters is actually harder to read as your eyes wander up/down in the middle of the line. In any case, I'm not sure how you justify 90 characters. But, it doesn't really matter as long as every file is using the same line-length limit.
I prefer tabs, and a single-space for "half intended" things.
I also use a "half indent" for where. I also use it for case patterns. (And, in languages with switch/case, for case labels.)
I use 1.
&gt; open-source is not the same as public domain or non-copyrighted. Most open-source licenses require some level of attribution. So, yes, don't plagiarize.
Is there a writeup that compares Iteratees with pipes/conduit? I feel like the bind definition would add significant overhead if you nest them the wrong way and the Stream definition looks like it'd force lazy IO?
Sounds great! How about a demo link.
Literally, secure copy with `scp` or whatever equivalent EC2 uses.
/u/snoyberg any chance we could get this domain pointing somewhere else?
I don't think this is warrented in the short term, when there's probably a lot of material and links to the old site. Maybe once some time has passed and documents have mostly been updated to use the new urls, but for now I think it's ok to leave as is. 
I'd rather see the old site left up with a big banner at the top saying "THIS IS AN ARCHIVE" with no reference to any other site.
Hey, great work, and thanks a lot. I was ask by a colleague, to checkout this plugin, since he would prefer intellij over vscode and emacs for editing our Haskell code base. I am amazed by this tool. The only drawback is, that it takes intellij 5 minutes to load all the modules. We have around 200 modules and 30000 lines of code. In the event-log we see that the many modules are being loaded several times (one module 14 times for example). Is this a known bug, or a configuration problem on my behalf? &amp;#x200B;
Thanks all! I feel more confident that Haskell can be my primary at work. Appreciate your comments!
Unfortunately, I see potential legacy concerns with respect to `haskell-lang.org` links in the community that makes a redirect the most sensible option at this point. Perhaps this should be a staged process for an EOL to its usage. Stage 1 would be a redirect, stage 2 would be a big "WE'VE MOVED" or archiving banner as you've suggested, but for stage 3 I would want to see the domain donated to Haskell for future use. I realize the last one is asking alot, but I think it would be a great step towards diplomacy if it were to happen. 
I don't follow. What legacy concerns makes a redirect more sensible than a banner to start with?
Well, loading project simply cannot be too fast, so go ahead and report the issue at https://github.com/rikvdkleij/intellij-haskell/issues
Hmmm that's true. Maybe they should be switched around and do the redirect second.
And the credits go to @rikvdkleij, it's mostly his work :)
And the credits go to u/rikvdkleij, it's mostly his work :)
FPCo has passing customers that presumably use the materials on that website. Putting up a big THIS IS ARCHIVED banner could just cause confusion for their customers. In light of this, I think it's warrented to have a redirect for a period of time, until FPCo is sure their customers won't be impacted.
You are right! I created issue \[#393\]([https://github.com/rikvdkleij/intellij-haskell/issues/393](https://github.com/rikvdkleij/intellij-haskell/issues/393)).
Salary range?
*Woah!* It's your **4th Cakeday** lightandlight! ^(hug)
&gt; looking forward 4 years where it's tipping over trying to handle Nix, it would be just a mess I hope this doesn't attract more downvotes but it seems to me that Stack is past its prime. Stack keeps struggling to keep up with Cabal and modern GHC features. [Just take Backpack which is nearing a 2-year delay for example](https://www.reddit.com/r/haskell/comments/ahknz7/question_to_professional_haskell_programmers/eejbgsj/?context=1). So it was clearly the right decision to oppose the demand to put all eggs in one ~~Stack~~basket 
No, what does the error say?
&gt; Secure Connection Failed &gt; &gt; The connection to www.snoyman.com was interrupted while the page was loading. &gt; &gt; The page you are trying to view cannot be shown because the authenticity of the received data &gt; could not be verified. &gt; Please contact the website owners to inform them of this problem. Seems to be a Firefox-only thing. Works fine in links.
On EC2 you would just `scp` it over probably, as /u/ocramz said, but Elastic Beanstalk requires a proper docker image. What I ended up using was: FROM ubuntu:18.04 # For whatever reason I seemed to need these libraries RUN apt-get -y update RUN apt-get -y install libpq-dev RUN apt-get -y install netbase RUN apt-get -y install ca-certificates # Copy over the website binary &amp; required files COPY ies-website /usr/local/bin/ies-website COPY static/ /static/ COPY config/client_session_key.aes /config/client_session_key.aes COPY config/settings.yml /config/settings.yml # Expose port 3000 outside the image EXPOSE 3000 # Start the website on running ENTRYPOINT ["/usr/local/bin/website-binary"] Then you just zip everything up and deploy it on EB. The hardest part was actually testing the image locally; I was using PostgreSQL, and couldn't figure out a way to connect to the instance running outside my image. For EC2, there's a nice guide at https://ilikewhenit.works/blog/5 (that's the last article, dealing with Docker and EC2; the rest of the guide is pretty good as well). 
Sorry to sound like a grumpy old man but... &amp;#x200B; &gt;And due to historic reason, ByteString choose to use ForeignPtr which contain a sum type, which is harder to unpack. This is wrong. It was true originally. But we fixed it, literally over 12 years ago (in base 2.1 with ghc-6.6, released October 2006). `ForeignPtr` is a single constructor data type *precisely* because of this representation and performance issue. &amp;#x200B; [https://downloads.haskell.org/\~ghc/6.6/docs/html/users\_guide/release-6-6.html](https://downloads.haskell.org/~ghc/6.6/docs/html/users_guide/release-6-6.html) &gt;The ForeignPtr datatype has been altered to make it more efficient. There are also new functions mallocPlainForeignPtr and mallocPlainForeignPtrBytes which do not allow you to attach a finalizer to the ForeignPtr. The motivation for all these changes was the bytestring library, so we could save a memory indirection, unpack, and use the faster allocation functions (that don't have any finaliser).
Does it fail deterministically for you? It loads fine for me in Firefox 65. Perhaps it's a general connectivity problem, showing up as an SSL error when the SSL handshake gets interrupted?
Thank you for this, just the thing I was looking for.
Not the author, just wanted to get it to an audience outside -cafe.
It's hard to say exactly. We're looking for a wide range of skill levels (junior to senior), which means it depends on the candidate. I know it's not a satisfying answer, but we pay competitive market salaries. 
Works fine for me in Firefox too. Also SSL Labs is happy with it: https://www.ssllabs.com/ssltest/analyze.html?d=www.snoyman.com
I wasn't really planning on mentioning this yet, but I've been working on [https://github.com/harpocrates/pretty-ghci](https://github.com/harpocrates/pretty-ghci) which has similar goals (flexibility around suboptimal output). Couple interesting features: 1. Supports colors 2. Configurable 3. Detects terminal width automatically when possible (my GHCi shells are sometimes a bit narrow) 4. Output that lexes but doesn't parse will still get coloured. Oh yeah, and it pretty-prints Haddock formatted comments too (in preparation for when we get a flag for formatting the output of \`:doc\`)
Great. Might pick up Miso too. I'm curious what the source code of the main binary does. Any reason it's not included?
&gt;Maybe this lets me get software out quicker, or allows me to produce more reliable software due to testing, or allows me to architecture software better because it doesn't need me to define a lot of boilerplate that I'll ultimately avoid doing and be unnecessarily terse. Sure. Add to that existing code and libraries you have to interact with. If I could be as productive with Rust as I am with Haskell and I had no other reasons to use Haskell (say, existing codebase) then yeah I would be using Rust. (side note: In fact GHC is so very poor at optimising even simple numerical code that I have recently been writing snippets of code in C/C++, compiling them with clang, looking at assembly, holding my head in my hands and crying a little at how poor GHC did in comparison and then try to port the assembly back into Haskell so that it generates something remotely close to more efficient version. Damn right I would jump on Rust/C++ if I knew I could be as productive and I didn't have other requirements.) But the difference is that _once_ I have already picked the slow base language (Haskell) because of productivity, I don't feel the need to then apply another 2.5x slowdown around it as I don't feel that using effects over MTL would provide the significant enough productivity boost (if any). You can also _make_ Haskell go fast-ish if you try hard enough but you if your starting point is something inherently slow (say, `freer` thing), you have to gut that.
It says verified, but doesn't provide a neutral audit paper. Also, even if you managed to verify the assembly code. There are no guarantees about what GHC will produce. Bottom line: haskell is not very good for cryptography. 
Argh, I see, ForeignPtr unpack the `Addr#` into the constructor, I'll modify my post then. 
&gt; The maximum allowed line length is 90 characters. I closed my tab here. Sorry.
Yes, there's no implicit fusion. Quotes from stdio's doc: ``` The unpack, unpackR and pack, packN, packR, packRN are designed to work with build/foldr streaming fusion in base, thus it's OK to expect idioms like pack . List filter f . List.map . unpack to work in constant space. While Vector.filter . Vector.map will create intermediate vectors on the fly, which have different time/space characteristic. ``` Implicit fusion is not always preferable in array slicing operations IMHO.
What kinds of guarantees are you looking for? Are there languages you think are great for cryptography?
&gt; What kinds of guarantees are you looking for? Of course that I run the same code (as in machine code) as was verified. That is also why some parts of crypto code is written in assembly for critical (especially timing sensitive) parts. You don't want to rely on the compiler to do the right thing there. Compiler flags, version and whatnot might totally change what is actually produced. It reminds me a little bit of this thread at haskell-tor https://github.com/GaloisInc/haskell-tor/issues/23 which has a broader scope though (security, not just crypto... and I was very disappointed of the response). And here are some interesting discussions about cryptography in haskell: * https://mail.haskell.org/pipermail/haskell-cafe/2015-February/118059.html * https://leonmergen.com/on-the-state-of-cryptography-in-haskell-c272fb0b6478 * http://tunes.org/~nef/logs/haskell/19.01.14 (at around 23:07:49) &gt; Are there languages you think are great for cryptography? assembly If you want to introduce high-level languages to that problem, you need to do a lot of work. There is currently only one project that tries to do that (from high to low level), which is called everest: https://project-everest.github.io/ And they do not use haskell and pretty sure never will for the high-level stack, but F*, which is specifically designed for this task. And it's still incredibly hard with a lot of questions https://github.com/project-everest/mitls-fstar/issues/124
Is Haskell generally bad at security. Due to its use in banks I was under the impression that using it was fairly reasonable.
Not really bad, but cryptography is a very special field in security. And it has little to do with type system elegance. However, some things like information flow control can actually be nicely modeled in haskell: * https://hackage.haskell.org/package/lio * https://hackage.haskell.org/package/mac But I don't believe anyone picks haskell, because it's more secure than other languages. The only obvious security advantage that you get for free is that you don't get random memory errors like in sloppy C code. But a lot of languages have this property. However, with IORef and concurrency you can easily cause memory leaks and programs to crash, even in haskell. There was a nice post about it, but I'm unable to find it. Security is not something that happens by accident and rarely comes for free. Descriptive type systems can help in some areas, but it's not a silver bullet.
Thanks for the answer! So a language that isn't subject to memory leaks, say Rust, is consequently more suited for that purpose?
The mesh networking hardware we have operates at OSI level 3; as far as programs running on devices on the mesh are concerned, they're all plugged in to the same switch. Almost all of the services we run communicate through an application-level router that's responsible for prioritizing RPCs, and this router can peek at information about the physical mesh (e.g. which nodes are my "real" neighbors, what are the estimated edge costs) when deciding how to schedule traffic. &amp;#x200B; We spent a fair amount of time evaluating existing standards and their implementations, but found that none of them had the exact properties we were after. Additionally, many such frameworks tend to be quite opinionated about how distributed applications should be built, and we merely hold a different opinion.
That would rock.
It's going to be for cli, so it's somewhere in between. It's public and people need to build it, but it could be built with unreleased libraries.
["Do not try to change the State. Only try to realize the truth: there is no State."](https://i.imgflip.com/2u4udr.jpg)
It's deterministic but also I'm on an ancient Debian Firefox.
Thanks for the reply!
"Ungawa!" from Conor McBride's talk "Is a type a lifebuoy or a lamp?". Originally from the old Tarzan movies. I think it means "the solution is `traverseA`, do your thing, types!"
Let's not lose track of what is slower in free-monad-like constructions: the binding operation. This is only a part of your program, so to outright say "your program gets 2.5x slower" is a lie. It very much depends on the nature of what you're writing! If it really is the case that binds are what are killing you because there's no single hotspot of your code then yes, maybe this approach isn't best. However, there are plenty of other places that could be hotspots. IO is one common argument, but tight numerical code, walking through big data structures or parsing data/determining normal forms are some others I can think off of the top of my head. You probably won't be working with free monads here - you use specialised monads to do the job. We need to be very clear about what it is about this approach that is slow, and then carefully evaluate whether that even matters in our problem domain. &amp;#x200B;
I keep a record of similar quotes about functional programming: [https://github.com/gigobyte/Haskell#quotes](https://github.com/gigobyte/Haskell#quotes), I think it will be helpful for your talk.
(do you have an update for OSX? i've been working on getting static binaries on Linux this week)
I've recently come across [arithmoi](http://hackage.haskell.org/package/arithmoi-0.8.0.0)and am interested in using the **Math.NumberTheory.Moduli.\*** modules but cannot figure out the type level Mod wrapper. My goal is to be able to use the Mod type where the Nat value comes from variable e.g. a large prime defined at run time to be used along the lines of this: `q &lt;- readFromFile` `let k = 3 :: Mod q` or `newtype Elem = Elem (Mod q)` The docs say to use the [modulo](http://hackage.haskell.org/package/arithmoi-0.8.0.0/docs/Math-NumberTheory-Moduli-Class.html#v:modulo) function to create SomeMod and then pattern match to extract the Mod 'value'. I can't figure out how to get this to type check. [This](https://blog.jle.im/entry/fixed-length-vector-types-in-haskell.html) helped a bit but I cannot get a simple function to work. I've enabled `DataKinds ScopedTypeVariables TypeApplications` as specified. `process :: forall n . KnownNat n =&gt; Integer -&gt; Integer -&gt; [Mod n]` `process n m = case modulo n (fromIntegral m) of` `SomeMod k -&gt; sqrtsMod k -- Here k has type Mod m` `InfMod{} -&gt; panic "failed"` This fails with: `* Couldn't match expected type \`Mod n1' with actual type \`Integer'` `* In the second argument of \`($)', namely \`(n :: Mod m)'` `In the expression: Right $ (n :: Mod m)` `In a case alternative:` `Just (SomeNat (Proxy :: Proxy m)) -&gt; Right $ (n :: Mod m)` `|` `24 | Just (SomeNat (Proxy :: Proxy m)) -&gt; Right $ (n :: Mod m)` `| ^` `src\Main.hs:28:16: error:` `* Couldn't match type \`m' with \`n'` `\`m' is a rigid type variable bound by` `a pattern with constructor:` `SomeMod :: forall (m :: Nat). KnownNat m =&gt; Mod m -&gt; SomeMod,` `in a case alternative` `at src\Main.hs:28:3-11` `\`n' is a rigid type variable bound by` `the type signature for:` `process :: forall (n :: Nat).` `KnownNat n =&gt;` `Integer -&gt; Integer -&gt; [Mod n]` `at src\Main.hs:26:1-65` `Expected type: [Mod n]` `Actual type: [Mod m]` `* In the expression: sqrtsMod k` `In a case alternative: SomeMod k -&gt; sqrtsMod k` `In the expression:` `case modulo n (fromIntegral m) of` `SomeMod k -&gt; sqrtsMod k` `InfMod {} -&gt; panic "failed"` `* Relevant bindings include` `k :: Mod m (bound at src\Main.hs:28:11)` `process :: Integer -&gt; Integer -&gt; [Mod n]` `(bound at src\Main.hs:27:1)` `|` `28 | SomeMod k -&gt; sqrtsMod k -- Here k has type Mod m` `| ^^^^^^^^^^` I am absolutely frustratingly flummoxed because I haven't grasped type level literals yet so can't see how to apply them to this library. &amp;#x200B; &amp;#x200B;
[removed]
&gt; Of course that I run the same code (as in machine code) as was verified. [..] You don't want to rely on the compiler to do the right thing there. Compiler flags, version and whatnot might totally change what is actually produced. I'm not disagreeing with your general point, but for this particular paragraph, it seems more like a reproducible build system issue. You can always maintain the assembly directly, or alternatively you can also maintain a reproducible build recipe (e.g. via Nix) of C code or Rust or Haskell that on a given platform with a given environment and compiler version, produces the expected assembly code. You might prefer to just deal with assembly because it's a stationary target, than the moving target behemoths of GCC and GHC, but it's perfectly possible to get reproducible compiler output.
Given that “Real World Haskell” is a well-known book, that phrase appearing in the title of this book does look a bit odd.
nice! when I tried to do this, iirc, I got stuck on proving that a record had the same type as (its) two component records being appended. *sigh*, ai wish GHC had records (or even just type level sets, to help with the implementation of record libraries.)
That's a good question. I've not seen such a writeup but would definitely be interested to see one! &amp;#x200B; I'm not sure if many people actually use iteratees these days to be honest. I just thought they were an interesting topic for a blog as the types are quite simple but also instructive in terms of how you might go about implementing resource-safe, composable streaming I/O.
No, reproducible builds alone is not the problem. Now you also have to re-audit your critical code after every new GHC version or you blindly trust that the codegen did not change. 
We are. Chunking helps a lot in some situations.
My "red-black-record" package defines a type-level map as a red-black tree. Unfortunately the current version as a type-level bug :( I hope to solve it soon.
I've specialized a "polymorphic" quot from Slavoy Zizek "*When such division involves an “antagonistic” either/or (Good against Evil, freedom against oppression, morality against hedonism, etc.), there are, roughly speaking, two philosophical approaches to it: either one opts for one pole against the other, or one adopts the “deeper” attitude of emphasizing the complicity of the opposites, and of advocating a proper balanced measure or unity. Although Hegel’s dialectic seems like a version of the second approach (the “synthesis” of opposites), he actually opts for an unheard-of third version: the way to resolve the deadlock is neither to engage in fighting for the “good” side against the “bad,” nor to try to bring them together in a balanced “synthesis,” but to opt for the bad side of the initial either/or. Lacan made the same point in his seminar …ou pire: in the choice between “le père ou pire” (the father or worse), the ethical choice opts for what is worse. Of course, this “choice of what is worse” fails, but in that failure it undermines the entire field of the alternative and thus enables us to overcome its terms. (Say, in programming, in the choice between the organic unity of dynamic typing and the destructive terror of Haskell static typing, the only way to arrive at the truth is to begin with the “wrong” choice of destructive terror.)*"
A monad is just a monoid in the category of endofunctors, what's the problem? Someone's got to say that even if it doesn't completely fit your agenda.
Can't find the source but this one from Conor McBride -- I like to think of types as warping our gravity, so that the direction we need to travel becomes "downhill".
Any plans for describing frontend stuff?
A lot of these aren't Haskell but may be of interest * Category theory asks of ever type of Mathematical object: “*What are the morphisms?*”; is suggests that these morphisms should be described at the same time as the objects. (Categories for the Working Mathematician, page 29) * These two properties are used silently in their calculations emphasising a principle that I shall reiterate several times, namely: one should always endeavour to *design one's notation so that the use of the most important properties become (almost) invisible*. (Making Formality Work For Us) * My thesis is that HtDP has missed an opportunity to reinforce its core message, *that data structure determines program structure*. ([How to design co-programs](https://patternsinfp.wordpress.com/2018/11/21/how-to-design-co-programs/)) * So the challenge we address is this: *it should be possible for the programmer to write an explicit type signature for any sub-term of the program*. ([Lexically-scoped type variables [pdf]](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/scoped.pdf)) * *Abstractions obey the same hierarchy as relationships: great abstraction &gt; no abstraction &gt; bad abstraction*. ([hn](https://news.ycombinator.com/item?id=19012069)) * A key general result is a *[fully faithful functor](https://github.com/ekmett/hask/blob/master/src/Hask/Functor/Faithful.hs) reflects isomorphisms*. That is, if `F` is fully faithful and `F a ≅ F b` then `a ≅ b`. ([Basic Example of Yoneda Lemma?](https://math.stackexchange.com/questions/2030418/basic-example-of-yoneda-lemma)) * A lot of category theory can be considered a categorification of order/lattice theory ideas. ([Basic Example of Yoneda Lemma?](https://math.stackexchange.com/questions/2030418/basic-example-of-yoneda-lemma)) * Abstraction is the separation of data and computation. ([Data-Parallel Spreadsheet Programming](https://pure.itu.dk/ws/files/83711786/PhD_Thesis_New_Final_Version_Florian_Biermann.pdf)) A couple of mine (don't worry if they're cringe) * Write every type/kind signature in full; at least allow it. (there are proposals [`-XTopLevelKinds`](https://github.com/ghc-proposals/ghc-proposals/blob/master/proposals/0036-kind-signatures.rst), [`-XTopLevelSignatures`](https://github.com/goldfirere/ghc-proposals/blob/top-level-sigs/proposals/0000-top-level-signatures.rst) for this) * *Libraries, not lore*. Instead of playing a game of telephone with "every `Applicative` gives rise to a `Monoid` by lifting" I can point to [`Ap`](https://hackage.haskell.org/package/base-4.12.0.0/docs/Data-Monoid.html#t:Ap); documented, agreed upon name in a library that users can derive code `via`: [`derive (Semigroup, Monoid, Num, Bounded, ..) via (Ap f a)`](https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/glasgow_exts.html#extension-DerivingVia) From Ryan Scott * I'm of the firm opinion that all instances should be opt-in.
I just started working on implementing my row types proposal, I hope I can present a working version at ZuriHac
This is amazing. If you printed this on shirts, with like, Zizek snorting a line of code, I would buy it in an instant.
But that's not safe since `Any :: (ob1, ob2)` inhibits the kind of pairs, to do it safely you can [constrain `id`](https://gist.github.com/ekmett/b26363fc0f38777a637d) type ObjK ob = ob -&gt; Constraint class Category (cat :: Cat ob) where type Obj cat :: ObjK ob type Obj cat = Vacuous cat id :: Obj cat a =&gt; cat a a -- Vacuous :: Cat ob -&gt; ObjK ob class Vacuous (cat :: Cat ob) (a :: ob) instance Vacuous (cat :: Cat ob) (a :: ob) instance (Category cat1, Category cat2) =&gt; Category (cat1 × cat2) where type Obj (cat1 × cat2) = EtaPair &amp; LiftObj cat1 cat2 id :: (Obj cat1 a1, Obj cat2 a2) =&gt; (cat1 × cat2) '(a1, a2) '(a1, a2) id = id :×: id (.) = .. as before given -- EtaPair :: ObjK (ob1, ob2) -- LiftPair :: Cat ob1 -&gt; Cat ob2 -&gt; ObjK (ob1, ob2) class pair ~ '(Fst pair, Snd pair) =&gt; EtaPair (pair :: (ob1, ob2)) instance pair ~ '(Fst pair, Snd pair) =&gt; EtaPair (pair :: (ob1, ob2)) class (Obj cat1 (Fst pair), Obj cat2 (Snd pair)) =&gt; LiftObj (cat1 :: Cat ob1) (cat2 :: Cat ob2) (pair :: (ob1, ob2)) instance (Obj cat1 (Fst pair), Obj cat2 (Snd pair)) =&gt; LiftObj (cat1 :: Cat ob1) (cat2 :: Cat ob2) (pair :: (ob1, ob2)) class (cls a, cls' a) =&gt; (cls &amp; cls') a instance (cls a, cls' a) =&gt; (cls &amp; cls') a
Your example code and your error message don't line up. The error message is about `Right $ (n :: Mod m)` but you don't have that in your example code. Please make sure at share the parts of your code that the error message is about, and enough context for us to at least assign types to all the identifier in your code. A parenthesis seems to be in the wrong place here in `modulo n (fromIntegral m of)` which is also mentioned in your error message.
thank you, dude!
It depends on what you installed. The Haskell Platform has an uninstaller, but it should be enough to delete your local packages, which are in %Appdata%/ghc. You might also want to delete the Cabal-folder under %AppData%/Cabal &amp;#x200B; [https://www.reddit.com/r/haskell/comments/4uugov/how\_to\_completely\_delete\_haskell\_windows/](https://www.reddit.com/r/haskell/comments/4uugov/how_to_completely_delete_haskell_windows/)
Have you tried `cabal new-install` and `cabal new-build` in your project? If not, give those a shot before nuking the system.
What is the web framework being used as materials for the book..?
Just tried it, " Failed to build data-default-class-0.1.2.0." Something is really wrong :'D I think ill just nuke everything...
I load the .adoc directly into GHCi rather than compile the result to a binary. I could probably hook that \`unlit\` into GHCi, though, thanks — but what I wrote up is working fine for what I'm doing right now.
How did you install it? In any case \`ghc-pkg list\` will tell you which package databases GHC is using. if you installed the packages as user package then removing the folders it lists when you do \`ghc-pkg list --user\` will reset it. If you've installed them globally then removing what \`ghc-pkg check\` gives an error about with \`ghc-pkg unregister &lt;name&gt;\` should work. If you want to nuke everything remove all folders mentioned in \`ghc-pkg list\` and reinstall with whatever method you got the compiler with.
Thank you for your hard work! I am quite excited! 
I would go even further and claim that Haskell runs inside the ZizekT monad 
We can also eliminate basically any mention of `cat*` by making `Category` kind-directed class Category (ob :: Type) where type (--&gt;) :: Cat ob type Obj :: ObjK ob id :: Obj (a :: ob) =&gt; a --&gt; a (.) :: forall b c (a :: ob) . (b --&gt; c) -&gt; (a --&gt; b) -&gt; (a --&gt; c) Now I write the product category `(cat1 × cat2) '(A1, A2) '(B1, B2)` as an arrow `'(A1, A2) -×&gt; '(B1, B2)` because the categories are implicit data (-×&gt;) :: Cat (ob1, ob2) where (:×:) :: (a1 --&gt; b1) -&gt; (a2 --&gt; b2) -&gt; '(a1,a2) -×&gt; '(b1,b2) -- Note that categories indexed by objects -- Note that this is the type (ob1, ob2) :: Type -- not '(a, b) :: (ob1, ob2) instance (Category ob1, Category ob2) =&gt; Category (ob1, ob2) where type (--&gt;) = (-×&gt;) -- beautiful type Obj = EtaPair &amp; LiftObj id :: Obj (a1::ob1) =&gt; Obj (a2::ob2) =&gt; '(a1, a2) -×&gt; '(a1, a2) id = id :×: id (.) :: forall b1_b2 c1_c2 (a1_a2 :: (ob1, ob2)). b1_b2 -×&gt; c1_c2 -&gt; a1_a2 -×&gt; b1_b2 -&gt; a1_a2 -×&gt; c1_c2 (f1:×:f2) . (g1:×:g2) = (f1 . g1):×:(f2 . g2) with the same constraints as before class pair ~ '(Fst pair, Snd pair) =&gt; EtaPair (pair :: (ob1, ob2)) instance pair ~ '(Fst pair, Snd pair) =&gt; EtaPair (pair :: (ob1, ob2)) class (Obj (Fst pair), Obj (Snd pair)) =&gt; LiftObj (pair :: (ob1, ob2)) instance (Obj (Fst pair), Obj (Snd pair)) =&gt; LiftObj (pair :: (ob1, ob2))
I did stack new project, used cabal to install http (it failed because it wouldnt find something), i used stack install, then installed cigwyn64, fiddled a bit, repeated everything from start, and then it worked as in it didnt fail cause it didnt find the libraries. Also im running ghc -pkg list non my cmd and get "unrecognised flag: -pkg"
The home page of haskell-lang.org could point somewhere else (haskell.org for example) while other hyperlinks referencing to existing material could be left as they are now, maybe with a notice that the website is to be closed soon.
The home page of haskell-lang.org could point somewhere else (haskell.org for example) while other hyperlinks referencing to existing material could be left as they are now, maybe with a notice that the website is to be closed soon.
I'm terribly confused, you used `cabal-install` with a `stack` based install? and then installed `cygwin`? Those three things don't really mix. In any case if you're using `stack` then I can't really help you here as I don't use it myself. &gt; Also im running ghc -pkg list non my cmd and get "unrecognised flag: -pkg" It's `ghc-pkg` no space, it's a different program from the compiler.
awesome
I know this sounds terrible im just trying to figure stuff out. The cygwin was needed cause i was getting a package build error cause cabal couldnt find a linux command or smth along those lines
Ah, that sucks. If it’s trying to build but failing, then it seems like there’s more going wrong than just dependency hell. Unfortunately I can’t be of much help there, as I’m not that familiar with the low-level build process on Windows.
No, it's clearly that we've failed to show to do it properly. First things first, just remove all three. remove cygwin, remove stack, remove cabal, remove ghc. Remove any folders mentioned by `ghc-pkg list` Remove anything in `%AppData%\cabal`, `%AppData%\stack`. and remove `ghc` if you've installed it separately as well. Then start over. If you want to use a `cabal install` based workflow, you can install this via the The Haskell platform, (don't use 8.6.3, use an older version at https://www.haskell.org/platform/prior.html) which should give you everything you need. Please follow the additional steps in the page! they're important. or use `chocolatey` via `https://chocolatey.org/packages/ghc`, through this method you will need to install msys2 manually `choco install ghc msys2` should give you everything you need. If you want to use a `stack` based workflow. Follow the instructions on their site. None of these method requires you to use cygwin, and it's highly recommended that you don't!
The way I installed everything was through haskell platform. i have not downloaded anything else apart from cygwin as suggested on stackoverflow. I will remove eveything soon and give it another go as your suggesting. I hope it works. Thank you for all the advice!
Ah ok. Then platform should work, it comes with msys2. The reason it didn't work is that you likely didn't follow the additional step 2 that's required after download. See the website for that. But also avoid ghc 8.6.3 on windows, it's broken. Use an earlier one. 
Have you tried to nuke your OS? :)
Im downloading 8.0.1. Also If the instructions you mean are the config ones, yes I did follow them. Fingers crossed.
At this point it seems faster x)
Reading the table if contents, I think it's more like a standalone little webserver / webapp. 
8.0.1 is quite old. Use the 8.4 one. Should make some things easier 
&gt;Is a type a lifebuoy or a lamp? This is hilarious, thank you!
It's [scotty](http://hackage.haskell.org/package/scotty).
Yeah it was HTTP. Look now I put 8.0.1 initiated a new cabal project and the sample code build properly and executed which is further than what I have ever achieved before. I also bumped into this which is quite a funny read. http://deliberate-software.com/haskell-is-the-dark-souls-of-programming/ The guy seems to have similar issues to me, gave me a laugh. Anyhow what I wanna say is, I just wanna do a simple HTTP request to get acquainted with some stuff, do you have a particular lib to suggest? Or just go with whatever google pops? Cause they seem to be a few. I hope everything works fine from now on.
I don't understand the question. Main binary of what exactly? All of the code I typed is in the github repo. 
Automatic garbage collection frees you of thinking about when the life of a value ends; lazy evalution frees you of thinking when the life of a value starts.
Reminds me of a famous Dutch sketch: "if you not like your prospective son in law you should start to praise him to your daughter"
What would be the fastest implementation of the following? data Res = NotSure | CertainlyEqual unsafeCheckEqual :: a -&gt; a -&gt; Res This isn't what `reallyUnsafePtrEquality#` does. {-# LANGUAGE MagicHash #-} import GHC.Exts import Control.Exception main = do let a = [0 ..] b = a assert (0 == I# (reallyUnsafePtrEquality# a b)) (pure ()) let a = [0 ..] b = [0 ..] assert (0 == I# (reallyUnsafePtrEquality# a b)) (pure ()) Use StableName?
This is an amazing list. So much here I need to internalize and explore!
Although it may be somewhat worse with \`ghc\`, isn't this the case with \_any\_ compiler of basically \_any\_ language?
Hold on, take it easy, there are haskellers that would nuke their life for the sake of Haskell. And your experience isn't particularly [uncommon](https://www.reddit.com/r/haskell/comments/aba7gb/why_i_am_not_a_fan_of_cabal_or_stack/ecz2r6s/).
I use -1.
Don't use stack install (it's for installing executables, not dependencies for projects). Instead: * Run `stack new ProjectName` * Look in the newly created folder. If there's a file called package.yaml, add the dependency there. If not, add it to ProjectName.cabal. You can find guides for both formats on the internet. * Run `stack build` to build the project, then `stack exec NameOfExecutable`. You can find the name of the executable in package.yaml or ProjectName.cabal. * Run `stack ghci` to get a repl with your code loaded. 
It's not clear to me why this approach was chosen over Nix and \`patchelf\`. Maybe the project already used Bazel so this was less effort to integrate?
Sounds like a neat tool but why was this posted here?
The title itself addresses a very real concern, given that even in academic courses students are left with the impression it's impractical and removed from workaday needs. The more places you see haskell alongside 'real world' the better.
I would say that it's because there is mention to GHC in the text.
I was exaggerating but honestly i dont wanna criticize an ecosystem i dont know. But i have never had such an issue getting a simple dependency to run. Im attributing it to my own incompetence till i get more versed in haskell
Do you have more context around the last one? &gt; I'm of the firm opinion that all instances should be opt-in. I don't understand what exactly this means.
Looks interesting, will check it out.
Wonderful!
Some of mine: Better overshoot and import a venerated industrial-strength library than to roll your own patchwork of helper functions. Reach for the most powerful abstractions first; you're never going to go wrong with an `ErrorT e (RWST r w s IO) a`. Point-free code is like fire: kind servant, cruel master.
Parent was putting it politely. You don't want to name a book "Real World Haskell X" when there's already a well known book called "Real World Haskell" by another author. &gt; The title itself addresses a very real concern, given that even in academic courses students are left with the impression it's impractical and removed from workaday needs. Totally agree, happily there are synonyms for "real world".
Hope I'm not putting words in his mouth. It means that instances must be defined explicitly, he doesn't want deriving (MonadIO) to mean `(Functor, Applicative, Monad, MonadIO)`. I think the context was, I wanted to write a newtype that changes one instance, everything else it inherits from a `via` type, Ryan didn't like it
Not from Haskell but I feel like it applies, and was paraphrased by Wadler in a talk on category theory: &gt; There are very few things which we know, which are not capable of being reduc'd to a Mathematical Reasoning; and when they cannot it's a sign our knowledge of them is very small and confus'd; and when a Mathematical Reasoning can be had it's as great a folly to make use of any other, as to grope for a thing in the dark, when you have a Candle standing by you. -- _John Arbuthnot, Of the Laws of Chance, 1692_ Mathematics is your candle when you're in a dark room and need to find your way out. Haskell exposes a rich, sound type system to you which is sufficient to describe a great range of mathematical ideas. This helps you reason about your programs. And when you don't know exactly how to solve the problem you are facing it helps keep you honest by guiding you to think about your problem.
&gt; Haskell is the least-broken programming language available today. -- Havoc Pennington
I _highly_ recommend using Stack on Windows - not because it's particularly better than Cabal (they're probably much the same), but because it just makes everything so much easier on Windows. The nicest thing about Stack is that it comes with its own embedded MinGW environment, so you don't have to worry every again about any unknown Linux command!
[This file?](https://github.com/jasminzukic/Jibimba/blob/master/Play_Jibimba/Jibimba)
I also once saw someone say something like "Haskell is absolutely the worst—and only—popular non-strict programming language out there."
If you change from one format to a different format, it will be a bunch of changes in any versioning control system in use today. When you read a lot of code, especially written by different people, as is the case when reviewing code, are you suggesting one would have to pull down every change, format it the way you want to read it personally, and forego any meaningful diffs? That's not really an option, so you're stuck with whatever format the code was in, when it was committed. Additionally, settling on one common style, makes it much easier to switch codebases. When whole communities agree on one format, it's even more beneficial. Take e.g. the Elm community, where almost everyone uses elmfmt. You can jump into any codebase, and it'll look familiar.
&gt; reallyUnsafePtrEquality# From https://mail.haskell.org/pipermail/haskell-cafe/2017-November/128213.html &gt; The OP is correct in that a gc at the wrong time can lead to spurious &gt; positives. The key to this is that, if you force everything to be evaluated &gt; to WHNF (so you actually have the pointers) and then gc, you have some &gt; determinacy as to when the next gc will happen: force to WHNF first, gc, &gt; make sure any subsequent operations between that and your &gt; reallyUnsafePtrEquality either don't allocate or fit in the nursery --- and &gt; in this case, you can trust the result. Not sure the best way to force a GC, but WHNF can be achieved with BangPatterns, and the easiest way to avoid allocating between the GC and reallyUnsafePtrEquality# is just to not do anything between them. :)
Definitely interested in this book. Is it available for purchase?
Whoops, overzealous copy and paste. I've removed the other error about Right.
Don't forget the classic haskellism, "If it compiles, it's correct!" Definitely not completely true, and at this point its legacy might be more harmful than helpful. But it highlights a main idea of the philosophy of Haskell: the time spent "debugging" at compile-time is not time fighting the compiler (like it might be in other languages), but actually the process of making your code more and more correct.
&gt; No, reproducible builds alone is not the problem. I agree, and didn't state otherwise.
Both platform and stack come with msys2. Ghc ships with a mingw-w64 tool chain as the compiler relies on it for native code generation. None of the tools above use the mingw toolchains at as as ghc switched a long time ago to mingw-w64. 
I'd say so. The trade-off is whether you feel like creating assembly from scratch and auditing the result, or having it created for you by a compiler and auditing the result. My guess is if you're auditing the assembly output of your compiler, you're not likely to change anything in the recipe (flags, versions, etc) very often, and when you do, you'll perform a diff on the new against the old.
That's a nice quote, but honestly I've never felt "freed" by lazy evaluation. I've almost always had to start worrying more about thunks building up than I would worry about "when a value starts" in eagerly evaluated languages.
Awesome! Now do `beam` table &lt;-&gt; record!
cool! can you share a link to it?
Tweag has blog posts explaining why they like Bazel. If I wasn't busy now I would find and link them for you, but sorry I need to go back to focus. :(
Perhaps not exactly what you're looking for, but here are some amusing quotes I've saved: A language that doesn't affect the way you think about programming, is not worth knowing. - Alan Perlis getLine :: IO String contains a String in the same way /bin/ls contains a list of files. - shachaf Immuteability: The property of functional programmers that prevents them from shutting up about pure functional programming. - raganwald When the limestone of imperative programming is worn away the granite of functional programming will be revealed underneath. - Simon Peyton Jones 
&gt;Someone's got to say that even if it doesn't completely fit your agenda. ...do they reeeeeally, though?
I didn't know that - thanks for telling me! Maybe I misinterpreted what was happening. Also, I did mean MSYS2 rather than MinGW - I've always been a bit confused about the difference between the two. (I think the difference is that Stack compiles things inside MSYS2 by default, whereas with Platform you have to 'manually' switch to MSYS2 and then run Cabal from in there. But again, I could be wrong.)
The type you wrote process :: forall n . KnownNat n =&gt; Integer -&gt; Integer -&gt; [Mod n] means something you wouldn't want. This type means, the caller of the function determines type level natural `n` and passes two `Integer`s, then the function must return `[Mod n]`. Before diving into the deep hole, note that you can always unwrap `Mod m` to fall back to simpler type. process :: Integer -&gt; Integer -&gt; [Integer] process n m = case modulo n (fromInteger m) of SomeMod k -&gt; getVal &lt;$&gt; sqrtsMod k InfMod{} -&gt; error "???" Probably, what you want is "Pass two integers `n` and `m`, then return a value of type `[Mod m]`". This is a straight-out dependent type process :: Integer -&gt; forall (m : Integer) . [Mod m] ... which isn't possible in GHC. What we usually do is "There is a value of type `Mod mm` with some type level natural `mm`. `mm` happens to represent the same number to `m`." In this case, `SomeMod` represents said type. process :: Integer -&gt; Integer -&gt; [SomeMod] process n m = case modulo n (fromInteger m) of SomeMod k -&gt; SomeMod &lt;$&gt; sqrtsMod k InfMod{} -&gt; error "???" (The rest is for bonus points, you can stop here.) But wait, it is possible that `[SomeMod]` is too vague as a type. `[SomeMod]` can contain elements of many different moduli. You may want a guarantee that each element has same type! In that case, you can do something like this: data SomeModList = forall m . (KnownNat m) =&gt; SomeModList [Mod m] process :: Integer -&gt; Integer -&gt; SomeModList But again, what if you need same thing for `Maybe (Mod m)`, `Either [Mod m] (Mod m)`, `Mod m -&gt; Mod m`, etc? Defining every `SomeXXX` is a lot of work! There is a trick you can use. {-# LANGUAGE RankNTypes #-} process :: forall r . Integer -&gt; Integer -&gt; (forall m . KnownNat m =&gt; [Mod m] -&gt; r) -&gt; r `forall r . (forall m . KnownNat m =&gt; [Mod m] -&gt; r) -&gt; r` means same thing to "There is a value `[Mod m]` which satisfies `KnownNat m`, for some `m`."
(Deleted old reply because it was not "smart") You can use `someNatVal` function from GHC.TypeLits to lift value of `Natural` to type-level `Nat`. import Data.Proxy import GHC.TypeLits(someNatVal, SomeNat(..)) import Math.NumberTheory.Moduli main :: IO () main = do m &lt;- readLn case someNatVal m of Nothing -&gt; putStrLn $ "Failed! " ++ show m Just (SomeNat mName) -&gt; mapM_ (\n -&gt; print $ process n mName) [0..10] process :: (KnownNat m) =&gt; Integer -&gt; Proxy m -&gt; [Mod m] process x _ = sqrtsMod (fromInteger x) 
Msys2 is a posix like environment to allow porting of posix applications to windows. It provides things like bash, automake, autoconf etc. Msys2 also contains a toolchains, if you use that toolchain you get a posix application (using newlib as your c runtime). If you use the mingw-w64 toolchains with it you get a native windows application (using the Microsoft runtime as the C runtime). Technically speaking, cabal-install does not care what you use, as long as it's able to find a posix shell when it needs to. This is what the second step in the platform installation page does. It's simply informing cabal where to find a posix shell. The benefits of this is that you aren't subjected to the rules and signal handlers of the posix environment at all times. Native applications behave a bit weird under such environments in some cases. For instance when using mintty Windows signals won't get delivered. Which is why ghci for instance gives a warning on startup when it detects this. I'm working on a much simplified way to install things on Windows which I'll be publishing soon. A lot of times people overcomplicate the installations which lead to weird behavior of the compiler. 
&gt; Mathematics is your candle when you're in a dark room and need to find your way out. &gt; &gt; lovely
Thank you! &gt; A lot of times people overcomplicate the installations which lead to weird behavior of the compiler. Yes, I've found this to be the case as well.
Wasn't it `sequenceA`, not `traverse`?
Source: https://twitter.com/pigworker/status/130468980040269824?s=19
&gt; Reach for the most powerful abstractions first You don't believe in the "Liberties Constain, Constraints Liberate" aphorism?
&gt; The only obvious security advantage that you get for free is that you don't get random memory errors like in sloppy C code Lol, so like 95% of the horrifically exploitable bugs? And I think most Haskell programmers would agree it helps avoid logic bugs compared to even other high level languages. Also rust's _story_ as a language for a lot of situations is to just crash. It's not clear to me how memory leaks and crashing really relate to security. I think it probably depends on your domain.
First, "security" doesn't have any meaning outside of a particular domain, or threat model. maerwald is focused on preventing timing attacks which is peculiar in requiring verification of generated or handwritten code (obviously this is terrible; a haskell DSL that could generate code with verified timing properties would be much better, but I'm not sure that exists). Other than being theoretically very prone to sidechannel attacks I'm not sure why haskell wouldn't be well-suited to crypto, other than the usual reasons of libraries and mind-share. But the vast majority of horrific exploitable bugs come from memory corruption issues that haskell code simply doesn't have. the remaining come from logic bugs (and I think most haskell programmers would agree it excels here, compared to other high level languages).
Thanks this gets me some of the way there. I am still not clear on how to use `Mod m` in a type as I want to be able to 'hold on' to these values. Is the following possible? data K n where K :: forall n. KnownNat n =&gt; Mod n -&gt; K n ml = 4 mkK :: forall n. KnownNat n =&gt; Maybe (K n) mkK = someNatVal ml &lt;&amp;&gt; \(SomeNat mName) -&gt; K $ createMod 3 mName createMod :: (KnownNat m) =&gt; Integer -&gt; Proxy m -&gt; Mod m createMod i m = fromInteger i This fails with the below, how do I tell the compiler that I want n and n1 to be the same? * Couldn't match type `n1' with `n' `n1' is a rigid type variable bound by a pattern with constructor: SomeNat :: forall (n :: Nat). KnownNat n =&gt; Proxy n -&gt; SomeNat, in a lambda abstraction at src\Pairing\Fq.hs:156:27-39 `n' is a rigid type variable bound by the type signature for: mkK :: forall (n :: Nat). KnownNat n =&gt; Maybe (K n) at src\Pairing\Fq.hs:155:1-42 Expected type: K n Actual type: K n1 * In the expression: K $ createMod 3 mName In the second argument of `(&lt;&amp;&gt;)', namely `\ (SomeNat mName) -&gt; K $ createMod 3 mName' In the expression: someNatVal ml &lt;&amp;&gt; \ (SomeNat mName) -&gt; K $ createMod 3 mName * Relevant bindings include mName :: Proxy n1 (bound at src\Pairing\Fq.hs:156:35) mkK :: Maybe (K n) (bound at src\Pairing\Fq.hs:156:1)
/u/willtim One thing I've noticed is that case statements that consume variants are essentially equivalent to records, and the way you manipulate them is basically the same as the way you manipulate records. Have you considered replacing the special \`case\` syntax with a single function/operator that applies a variant to an appropriate record of functions. Here is an example of what i'm talking about in \`agda\`: ``` open import Level data List {n : Level} (a : Set n) : Set n where nil : List a _::_ : a -&gt; List a -&gt; List a _++_ : {n : Level} -&gt; {a : Set n} -&gt; List a -&gt; List a -&gt; List a (x :: xs) ++ ys = x :: (xs ++ ys) nil ++ ys = ys map : {n : Level} -&gt; {a : Set n} -&gt; {b : Set n} -&gt; (a -&gt; b) -&gt; List a -&gt; List b map _ nil = nil map f (x :: xs) = f x :: map f xs data Product {n : Level} : List (Set n) -&gt; Set n where unit : Product nil _*:_ : {a : Set n} -&gt; {as : List (Set n)} -&gt; a -&gt; Product as -&gt; Product (a :: as) data Sum {n : Level} : List (Set n) -&gt; Set n where select : {a : Set n} -&gt; {as : List (Set n)} -&gt; a -&gt; Sum (a :: as) next : {a : Set n} -&gt; {as : List (Set n)} -&gt; Sum as -&gt; Sum (a :: as) _=&gt;_ : {n : Level} -&gt; {as : List (Set n)} -&gt; {b : Set n} -&gt; Sum as -&gt; Product (map (\a -&gt; a -&gt; b) as) -&gt; b _=&gt;_ {as = nil} () _ _=&gt;_ {as = a :: as} (next y) (_ *: fs) = y =&gt; fs _=&gt;_ {as = a :: as} (select y) (f *: fs) = f y case : {n : Level} -&gt; {as : List (Set n)} -&gt; {bs : List (Set n)} -&gt; {c : Set n} -&gt; Sum (as ++ bs) -&gt; Product (map (\a -&gt; a -&gt; c) as) -&gt; (Sum bs -&gt; c) -&gt; c case {as = nil} y _ g = g y case {as = a :: as} (next y) (_ *: fs) g = case y fs g case {as = a :: as} (select y) (f *: fs) _ = f y ```
They don't have to, but they will.
Depends. One would however expect the book to be either from the same or affiliated author, OR from the same publisher (implying same standards and possibly same structure &amp; formatting).
Can this be used to run binaries on AWS Lambda that are NOT compiled used within the `amazonlinux` docker image? I recently spent a day or two tweaking our CI scripts to deal with this problem.
Unfortunately, no. If you have a definition `k :: forall n. KnownNat n =&gt; Mod n`, it means `k` is defined for all `n`, not for some `n`. In other words, `n` is specified when `k` is used, not when `k` is defined. Also, existentially quantified type variable (`m` in `SomeNat (mName :: Proxy m)`) can't escape the context it became visible through pattern match. -- This is invalid (Nothing can be valid type at ???) f :: SomeNat -&gt; Mod ??? f (SomeNat mName) = createMod 10000 mName -- This is valid f :: SomeNat -&gt; Integer f (SomeNat mName) = getVal (createMod 10000 mName) If you want intermediate variable of type `Mod m`, you must "hold on" it in the scope `mName` is visible. You can't define global variable of that type. f :: SomeNat -&gt; Integer f (SomeNat mName) = getVal finalAnswer where x = reallyComplexCalculation (createMod 100 mName) 200 y = reallyHeavyMath x 300 400 finalAnswer = x + y reallyComplexCalculation :: (KnownNat m) =&gt; Mod m -&gt; Mod m -&gt; Mod m reallyHeavyMath :: (KnownNat m) =&gt; Mod m -&gt; Mod m -&gt; Integer -&gt; Mod m It is a bit inconvenient though. For example, you can't use `TypeApplications` to give type including existentially quantified variable `m`, because it has no name which can be written in the code. To avoid this situation, you can use `RankNTypes` and split up `f` to two parts to give a name for existentially quantified `m`. -- Needs RankNTypes withKnownNat :: forall r . SomeNat -&gt; (forall m . KnownNat m =&gt; Proxy m -&gt; r) -&gt; r withKnownNat (SomeNat mName) cont = cont mName g :: forall m . KnownNat m =&gt; Proxy m -&gt; Integer g mName = getVal $ fromInteger @(Mod m) 100 + 200 + 300 -- You can use TypeApplications here func :: SomeNat -&gt; Integer func someM = withKnownNat someM g Existentially quantified type variable is confusing first time, but you'll get used to after you use a lot.
The main reason for that is that the problem clodl is trying to solve is deploying you libraries/executables in an environment that you don't really control. And that something that Nix is rather bad at (there are tools like [nix-bundle](https://github.com/matthewbauer/nix-bundle) which attempt to do the same thing with nix, but these aren't applicable in all cases). Another compelling reason for using clodl rather than Nix is that it produces much smaller closures because it only includes the .so files you actually depend on. For instance on a project I'm working for, clodl generate an archive file of 55MB while the nix runtime closure of the same executable would be at least 300MB (if only because it depends on GHC and the closure of GHC is already 200MB).
Oooh, that! That's just the compiled code from the server side. I didn't include the .stack-work folder from where I copied that executable. So yeah, the source code is in the JibimbaBackend folder
AFAICT a big part of it is the general distaste for orphan instances. This can sometimes be worked around by packages having a small "types-only" package which just defines types and type classes, but it's not always possible and can lead to an extra maintenance burden, so some package authors may be loath to do it. A second reason might also be the lack of ML-like module 'signatures', but there's something very similar in Backpack, but I'm not sure how usable it is at this point. It certainly has been adopted in the wider ecosystem, at least. (I'm hoping it will solve many of the problems, but as per usual such wide-ranging changes are slow to be adopted.)
It's [here](http://hackage.haskell.org/package/red-black-record). The [bug](https://github.com/danidiaz/red-black-record/issues/9) is solved in a [branch](https://github.com/danidiaz/red-black-record/tree/deletion), but I need to add more tests.
&gt; What would a HTTP client library have to do with ASN.1, for example? TLS.
It's only a problem if you ever compile one library and then throw away the results. If the dependencies are shared, like in stack or newer cabal-install, you quickly accrete a pile of most commonly used dependencies and one extra ASN.1 does not matter. -- Sharing [dependencies] is *not* caring!
&gt; Every language's community maintained package libraries has interdependencies, **but Haskell's has the widest and deepest I've seen** I take it you're not a JavaScript programmer :p
The old-locale package is a funny case. If I recall correctly, it got renamed to that at the same time as the old time package got renamed to 'old-time' to make way for the new 'time' library, which genuinely subsumed it. However, there was no new 'locale' package to go along with it -- maybe someone expected there would be? It happened long enough ago now that it's probably more annoying to change than it's worth. As for ASN.1, it didn't take me long to guess where wreq got that dependency -- it's via the tls implementation which http-client-tls uses. See for example the implementation of kxVerify here: http://hackage.haskell.org/package/tls-1.4.1/src/Network/TLS/Crypto.hs It can be a problem to have dependencies that are much too small, but so long as each one is substantial enough, it will mean that usually more than one set of eyes is looking at it. You do need to take some care with Hackage when picking your dependencies though -- some packages contain far better code than others.
You're absolutely right, as library authors AND community we should always re-evaluate the health of the ecosystem based on such considerations. However it's important to note that networking is a complex beast and from-scratch implementations of various protocols are bound to have many moving parts. Personally, instead of `wreq`, I've been using `req` for my web projects and have been very satisfied. It's based on battle-tested dependencies, stable and well documented.
Haskell: come for the recursion schemes, stay for the alien technology from the future
Cool! I wonder if there is any way I can help out? I love scotty and I learnt Haskell from using it so I might have some useful feedbacks from a beginner's perspective.
Strong types and purity make genuine modularity of functionality possible. So the Haskell ecosystem makes use of it in ways that other ecosystems may not. If stuff is stateful or if stuff is not fully and expressively statically typed, then there is much more risk of a dependency changing under you in a way that breaks things. In Haskell, often but not always, if the types continue to match, then the new version of the dependency will work just fine. There's still a relatively small quantity of packages deep at the root of many dep graphs, so its not like there's a _ton_ of "leftpad.js" libs around that could be taken over by a malicious actor. And as for maintainership, we also have active hackage trustees and an admin process to make sure that stuff keeps building with new releases, and that packages that fall into unmaintained states can have upload rights transferred to new people who volunteer as maintainers.
There's also the issue of redundancy and duplication of implementations. The ecosystem is made up of different competing abstractions and frameworks overlapping in purpose and concern. This isn't just about streaming libraries or HTTP stacks or XML libraries. If you're unlucky you can easily end up having multiple different base standard libraries from competing authors linked together in the same application resulting in humongous executables. Maybe at some point Haskell should define a canonical library for each task to provide a coherent story but I think that ship has sailed. 
Very true. A canonical monadic stack would be enough. And this is possible.
Look my hello world program in Hask... Wait I can abstract over strings, let me change it in a minute... Look my hello world program in Hask... Wait, i can obtain the stringabstract from a state monad wait a minute...
I use [`ghcup`](https://github.com/haskell/ghcup/) to manage my compiler, and `cabal` as my build tool, so nuking **everything** (except my projects, which can be nuked with `git clean -xfd`) is a simple `rm -rf ~/.cabal ~/.ghcup ~/.ghc`.
Use docker
Oh cool! I have to confess I haven't actually used pipes or conduit in a production setting. Do they really not support chunking?!
Thanks, I'll try this out. Does SomeNat always have to be used like this? If so what's the benefit vs. a type that carries the modulus at value level? 
&gt; Does SomeNat always have to be used like this? Yes. &gt; If so what's the benefit vs. a type that carries the modulus at value level? It is type-checked that there is no misuse between values with different modulus, inside the computation passed to `withKnownNat`. With a type that carries the modulus at value level, you have to perform validation at runtime.
Give my regards to Eddie!
My company is holding a Haskell meetup in Tokyo on Saturday, March 9th. It will be mostly people getting together and hacking on various Haskell-related stuff. Impromptu presentations and lightning-talks will be encouraged. All levels of people are welcome to join, from people just getting into Haskell to experienced developers. ------------------------------------------------------- The registration site (connpass.com) is mostly for Japanese meetups, but most of the site should be readable in English. If you have trouble figuring out how to register (or just have any questions in general), feel free to ask on here. Also, in case you're interested but can't attend this meetup, there are two other groups in Tokyo that hold regular Haskell meetups: - [Tokyo Haskell](https://www.meetup.com/Tokyo-Haskell-Meetup/) - [Haskel-jp](https://haskell-jp.connpass.com/)
Let's put things in persperctive. My largest Haskell projects have an order of magnitude less dependencies than any small Javascript one I start. (Yes, I've measured this.) Also, the Haskell libraries tend to depend on the same 100-ish packages, and types make it much less an issue than most other languages. That said yes, it's a problem. Dependencies some times break, and there is still a security risk, even with the types there. I think Haskell has the best trade-off of ecosystem vs. NIH of any language I've tried, but it's always good to improve.
If this has a reliable parser, I would love to switch [pretty-simple](https://github.com/cdepillabout/pretty-simple) over to using it. pretty-simple's parser is basically the simplest I could get away with writing. --------------------------------------------------------------------- I just tried testing one thing and it looks like Shower doesn't handle unbalanced brackets. Also, I didn't actually try it, but I wonder if Shower supports infinitely long input. That's one of the things that was often requested from pretty-simple (and a couple months ago someone finally sent a PR adding it).
You are right, I was thinking more of the standard scenario for using state where you both edit the state and return a value at the same time, e.g. a stack pop. For some reason at the time I didn't realise that my functions only did one or the other, so it does read a bit weird.
Addition can be used flip runs of bits. This post will describe how to perform such additions on large bit-vectors efficiently.
God I love bitvectors! Excited to another post from Haskell Works
&gt; There's no easy way to look at the complete dependency graphs It's easier than you think! It's even built into `stack`, see [`stack dot`](https://docs.haskellstack.org/en/stable/dependency_visualization/).
There's actually a library and tool devoted to querying and rendering the dependency graph in various ways: http://hackage.haskell.org/package/cabal-plan
RemindMe! April 20
I will be messaging you on [**2019-04-20 13:50:15 UTC**](http://www.wolframalpha.com/input/?i=2019-04-20 13:50:15 UTC To Local Time) to remind you of [**this link.**](https://www.reddit.com/r/haskell/comments/at2ogl/bank_kata_in_haskell_printing_a_statement_whilst/) [**CLICK THIS LINK**](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[https://www.reddit.com/r/haskell/comments/at2ogl/bank_kata_in_haskell_printing_a_statement_whilst/]%0A%0ARemindMe! April 20) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete Comment&amp;message=Delete! ____id____) _____ |[^(FAQs)](http://np.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^(Custom)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^(Your Reminders)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List Of Reminders&amp;message=MyReminders!)|[^(Feedback)](http://np.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback)|[^(Code)](https://github.com/SIlver--/remindmebot-reddit)|[^(Browser Extensions)](https://np.reddit.com/r/RemindMeBot/comments/4kldad/remindmebot_extensions/) |-|-|-|-|-|-|
Powerful abstractions have many constraints, many laws. Weak abstractions have few. Exactly because of their many laws, one can reason powerfully about powerful abstractions. It even applies to using dedicated structures like `Map` and `Seq` rather than witing Haskelisp; making instances of the case-by-case useful core type classes where appropriate, etc.
You shouldn't need to wrap primops like that, usually, unless you're trying to avoid some indirection (say, avoiding the check for 0 in mod or something). Your ltWord is also already exported by GHC.Word as ltWord64, which is defined in terms of GHC.Classes.ltWord (and is actually used in the definition for its Ord instance, so the specialisation thereof will produce the same code anyway). You should also probably use a datatype with strict fields and compile with -O2 - ie change (Word64,Word64) to data F = F !Word64 !Word64. The Word64's will unpack and you'll get fewer indirections.
How does it compare with `plusWord2#` primitive?
404
&gt; Using such types are fairly risky in high-performance code because the complexity of representing them in memory makes them slow. I naively would have thought a sum with two constructors would be specialized to a some representation of 0-1. Why is this not the case? 
&gt; *sniff* Thish ish ideology!
Haskell's standard library(Base) doesn't like other language (e.g. Go) with the concern of practical scenario.
The motivation for wrapping primops is given directly in the article: it simply makes the call site(s) cleaner so you don't have to muddle them with unboxing. It's a simple optimization for readability, and that is just as important as any performance optimization.
Yes, I notice it too! So sad, I was using it all the time, especially with the duckduckgo bang syntax: !hayoo (see https://duckduckgo.com/bang )
Works now ^^
you forgot the link to the job description ;-)
I think Go and Rust also do this, though maybe not to the extent that JS does. It seems newer languages that have a central package repository relatively early in their lifecycle tend toward smaller libraries, and larger, deeper, wider dependency trees. While I think the way we do dependencies could be made better (machine-checked / enforced SemVer, or dependency on canonical ABI/API), there's little to no incentive to intentionally break dependencies so the current systems actually work quite well.
It's okay to use Hoogle. Just use it by the following link: https://hoogle.haskell.org/ But **do not use** this one: https://www.haskell.org/hoogle/ Database for Hayoo is outdated anyway as I remember. And https://hoogle.haskell.org/ works great so far. Using it for more than a year and the UX, was able to search even for freshly uploaded versions of libraries.
Thanks! The book is not quite ready yet. But I've open sourced the code of the final project and preface for early feedback. [https://github.com/zhangchiqing/beginner-friendly-haskell-for-web-development/tree/master/a-simple-http-service](https://github.com/zhangchiqing/beginner-friendly-haskell-for-web-development/tree/master/a-simple-http-service)
A value of type `x :: Bool` may not be a concrete Bool, but may also be a thunk or bottom of some kind. This means it is a pointer to a thing, and not the thing itself. We call this an *unlifted, boxed type*. As a result you must actually scrutinize the value by evaluating it before you can see which alternative you take. This is really the most important point you need to recognize. On top of that, there are many other issues that interfere with such optimizations. One is that this evaluation must always happen, and it makes optimizations you think are "obvious" complicated. Consider a function like `f x = case x { True -&gt; ...; False -&gt; ...; }`. `case` must evaluate `x`, so `f` is strict. You'd think at this point, any time GHC calls `f`, it must be able to just pass `1` or `0`, right? Wrong. It must always check `x` for its evaluated representation, and that's because the *function* is strict, but the *call site* might not be. Consider a call site like: `map f [ isPrime x, True ]` In one case, you call `x` with a *thunk* `isPrime x`, but in another, you use a concrete, static value `True`. The question is: what code do you generate for `f`? In this case, it can never just assume it gets a raw value -- it must always check if it has been valuated, and if not, do so. It might be possible in some limited cases to do this automatically, but it is probably fragile. For example, if you unroll `map f` you may be able to specialize `f` at two different callsites, and avoid the whole problem automatically. (But that's not the optimization you were asking for.) This doesn't answer your direct question -- but what I'm trying to point out is that case/constructor evaluation has much more complex semantics than you may think, and optimizing it is a difficult problem to do in general. I do not know how unboxed sum types fit into this view. They may be a better choice for certain things like this.
Oh noes! Looks to be up now. Try it?
Colon is reserved syntax in YAML: you need to enclose the whole dependency string in quotes.
It's technically possible, but there is the social problem of figuring out who should determine which monadic stack is the blessed one, getting everyone on board with that decision, and erasing the old alternatives from the existing library ecosystem, including libraries that haven't seen any maintenance worth mentioning in years but are still being widely used.
I agree. For example [this](https://hackage.haskell.org/package/tagged-0.8.6) is a joke. You rarely use more than 3 lines of implementation from this library.
Why not remove the second one?
I understand; thank you for the answer! I did not consider that the `True` | `False` in the example core would still need to be evaluated. 
The problem also has to the with the width of packages. Recently I used `ABList`, which is basically a list with two alternating types. I think there is one single insignificant function it has that uses something in `linear`, which pulls in a bunch of crazy stuff such as cereal and lenses.
A good place to get support for questions regarding stack's usage that isn't covered by [the docs](http://haskellstack.org) is [Stack Overflow](http://stackoverflow.com) or another place where your issue may already have been reported is the [Stack issue tracker](https://github.com/commercialhaskell/stack/issues). &gt; it seems strange for stack to advise something that doesn't actually work You probably aren't aware but this is an unfortunate choice of words as unfortunately there are some trolls in our community trying to force the "Stack does not work" meme as a way to spread FUD about Stack. Please avoid wording implying that Stack might not work in order not to play into the hands of those trolls.
If you are looking for different skill levels, then give different multiple salary ranges. Presumably you've figured out how much you can afford, or you wouldn't be hiring. &amp;#x200B; i.e., Junior range: XX,XXX to XXX,XXX, Senior range: XXX,XXX to XXX,XXX &amp;#x200B; Because "competitive market rates", especially when you are in a particular part of the country that, AFAIK, does not have the salaries that places like NY/SF/etc have, but are possibly open to remote work, is a pretty wide open thing, and thus is somewhat meaningless. Like, competitive for a senior developer in Gainesville is maybe $80K -- what do I know? Whereas where I'm located (Boston), that would be pathetic. And I'm not saying that $80K would \_necessarily\_ be unfair (if I lived somewhere with a lower cost of living...), but at the end of the day, refusing to give even basic parameters conveys a basic lack of respect for potential applicants... because \_everyone\_ will have to consider the actual salary when deciding if a job is for them (well, aside from people who genuinely don't have to work, but optimizing for them is silly... and I don't think they look for jobs, lol), and forcing people to invest time before figuring out even a rough sense of that is just shitty.
What are the dependencies for that tool though? /s :)
I use this in Chrome: https://www.makeuseof.com/tag/create-custom-search-engines-google-chrome/ 'h foo' in the address bar is pretty convenient!
Please consider whether you are communicating in a respectful way.
Ah, that explains it, thanks!
/u/winterland1989 Maybe you can derive this via \`ReaderT AllocateStrategy (Codensity BuildStep)\`? Whatever, the boilerplate is already written, so...
If you permit me to play the devils advocate. Can this not also be seen as a testament to Haskell permitting a higher degree of modularity? Would be nice to do some metrics to back up this claim. 
Ah yeah, skimmed. Yes, I agree doing this generally is correct. Though using ltWord uses `isTrue#` which introduces `Bool` anyway, so I was just wrong.
Looking at the [`Monad` instance of `Church`](http://hackage.haskell.org/package/free-5.1/docs/src/Control.Monad.Free.Church.html#line-118), this seems to be the case. This is the bind instance of the fast `Freer`: https://github.com/isovector/too-fast-too-free/blob/91aad992db3b35401acf7335ef24dad39d481648/src/Eff/Type.hs#L44
\`base\` isn't a standard lib, as seen in python / .net / Java. It doesn't really perform the same purpose, and so you get a pretty large and thorny collection of interrelated defacto standard lib implementations. We could try to 'fix' this, but I don't see that happening without at least a few nasty verbal knife-fights and further fracturing of the ecosystem.
No server, I suppose
https://github.com/isovector/too-fast-too-free/issues/1
Yeah, getting a \`ghcup\` to work on windows would be a fair amount of work, but it would be *great*.
I don't think this is true. The stuff pulled in to give "default" instances is a very small base set usually, extending no further than the platform. Mainly I think we just have a lot of modularity in pure sublibs and a lot of libraries that provide \_precisely\_ types-only functionality.
No, that's not true. That library gives a datatype and a \_huge\_ zoo of instances. You almost certainly want all those instances lying around for potential use.
No, we should upgrade the old one. Neil's been a bit slow about it, is all.
Edward has a library for every implementation problem I didn't know I had until now.
I mean we're fortunate that e.g. Monad, Functor, etc. are in the base library, but there's still things like Aeson's type classes. Aeson is pervasively used, but good luck if you have transitive dependencies on incompatible versions. (There was one other example I was thinking of when I started writing this, but it's slipped my mind.)
There's still a significant compilation burden (and increased chance of having packages that cannot coexist easily).
Ding!
Update, all ended up working great! Thanx for the help!
Right, aeson is part of the small base set in my mind -- its basically "one step" outside of the platform. Transitive deps on incompat versions is a problem with packagers not taking care with their dependencies -- it has nothing to do with anything else. Its the same as incompat-versions of base, or bytestring, or anything else.
Is there a guide to generating the **Content** and **Index** sections of Haddock documentation? Everything in the docs appears to be about the *modules*. For example, my default generated Contents contain empty **Signatures**. I ohjnly see Signatures on Hackage when the package actually contains an hsig. Where is the documentation for modifying these package-level components of Haddock documentation? Thanks.
Could you link that answer so that I can downvote it and leave a comment directing future users away from that?
That may be so, but that feels an awful lot like defining the problem away. I think it's empirically demonstrated that it's a problem that isn't going to solve itself.
While I'm asking Haddock questions: for named libraries, Haddock generates documentation for `other-modules:`. Is this Working As Intended? library my-lib exposed-modules: Foo other-modules: Bar The documentation for `my-lib` will contain both `Foo` and `Bar`.
Excuse me? Why so negative about this?
No. You leverage your position of power to hide information from prospective candidates with the sole purpose of trying to drive that market rate down so you can get away with paying people less than they might get if they could compare offers equitably. You can't claim to offer fair market rates while simultaneously participating in a practice that manipulates that market. It's not just an unsatisfying answer, it's a predatory practice that we should absolutely stop normalizing.
Not meant as a reflection on you, I fell into the same trap. I just wanted to find the SO answer with bad advice and do my part to try to correct bad information.
I think the tagless-final encoding should be: class Person repr where person :: Int -&gt; String -&gt; Int -&gt; repr 
Ah, in that case, yes, I agree that the user should have to explicitly write out each of the typeclasses. Readability is diminished if GHC derives instance that the user didn't explicitly request.
I would definitely expect some similarity; they're related. If memory serves, "freer" is sort of like a `Free` that doesn't require a `Functor` instance. That is `Free f` is a `Monad` if `f` is a `Functor`. Freer drops that requirement, and is a `Monad` so long as `f` is of kind `* -&gt; *`. Which, iirc, makes it equivalent to `Free (Coyoneda f)` or something like that? It's been a while. In any case, I figured maybe if this particular "freer" monad is similar enough to `Free`, one could define a morphism similar to `improve` for it. One that recovers the direct representation (the `Free` type in `Free`) out of a computation involving the church encoding (the `F` type in `Free`). Or really a computation written against an abstraction over the two representations. That's kind of what `improve` does: uses the church encoding under the hood, but produces the other representation as the result. At least, that's how I remember it. Haven't played with these types in over a year. Anyway that's what I was pondering in my previous comment: does the `improve` function still work if we allow arbitrary types `f : * -&gt; *` as arguments instead of just `Functor`s? My guess would be yes, but I haven't investigated it.
Thanks for pointing me to the new primitive. Unfortunately my compiler (GHC 8.6.3) seems to not have it yet. I tried using addWordC#: ``` add :: Word64 -&gt; Word64 -&gt; (Word64, Word64) add (W64# a) (W64# b) = let (# r, c #) = addWordC# a b in (W64# r, fromIntegral (I64# c)) ``` but it is quite slow: ``` $ time ex-vector sum-bit-vectors -i ../hw-json/corpus/bench/78mb.json -i ../hw-json/corpus/bench/78mb.json --branchiness branchless3 3.450 ```
Hi, can anyone shed some light on how to solve this problem? fooman@pangea proj]$ nix-shell -p pkg-config -p zlib --run "cabal new-build" Build profile: -w ghc-8.6.3 -O1 In order, the following will be built (use -v for more details): - proj-0.1.0.0 (exe:proj) (first run) Preprocessing executable 'proj' for proj-0.1.0.0.. Building executable 'proj' for proj-0.1.0.0.. [1 of 1] Compiling Main ( src/Main.hs, /home/fooman/proj/dist-newstyle/build/x86_64-linux/ghc-8.6.3/proj-0.1.0.0/x/proj/build/proj/proj-tmp/Main.dyn_o ) &lt;command line&gt;: can't load .so/.DLL for: libz.so (libz.so: cannot open shared object file: No such file or directory) pkg-config --libs zlib works inside the nix-shell. I also tried --extra-libs-dirs to no avail. Also inside the proj.cabal file. Finally, I tried cabal new-build --verbose but I couldn't see where does cabal search for the libs. Thanks in advance. 
&gt; Now suppose I want to convert this to final tagless, I would start by creating a Person typeclass, Yes, but the class should actually be more like class Person repr where person :: Int -&gt; String -&gt; Int -&gt; repr Then you can easily define instance Person Event where person = Event 
I mean there's a ton of work on how to manage version bounds for dependencies well. That's what the whole hackage revisions (https://github.com/haskell-infra/hackage-trustees/blob/master/revisions-information.md) system is for, as well as the role of the trustees(https://github.com/haskell-infra/hackage-trustees/blob/master/policy.md), and also the matrix builder (https://matrix.hackage.haskell.org/#/package/aeson)! Not to mention that the nix-like cabal v2-build system also has gone a long way to avoiding diamond dependencies. My point isn't that there aren't problems with managing a complex ecosystem of version bounds. But there are also solutions, that put together, have thus far worked really well!
Automated leftover handling - not that I recall. Havens used pipes either.
FWIW's, DuckDuckGo's `!hoogle` shortcut points at the second link, not the first: https://duckduckgo.com/?q=!hoogle+a-&gt;(a,a) I suppose anyone could report it, but it might be more appropriate for a Hoogle maintainer to do it. 
Ah of course, it seems so obvious now! Each function on the typeclass would correspond to an option in a Sum type, if I am understanding now? So because \`Person\` is a product, the function in the typeclass would simply take multiple params? That makes much more sense, thanks!
please use preformatted blocks for source code, commands, and command output. You can even do it `inline` if the section is small.
Do you have a link to the code which produced those benchmarks? I see a `countDown` implementation which uses `too-fast-too-free` in your repo, but where are the corresponding `mtl` and `freer-simple` implementations?
I just hacked it into `freer-simple`'s benchmark which I happened to have beside me. I'll upload it if I remember!
Stack does not work.
Thanks, now that I know how you did it, it was easy to do the same on my machine. I must have done something wrong though, because I get the opposite results! ``` $ stack bench --benchmark-arguments '--output benchmarks.html' freer-simple-1.2.1.0: benchmarks Running 1 benchmarks... Benchmark core: RUNNING... benchmarking Countdown Bench/freer.State time 522.2 μs (512.1 μs .. 531.5 μs) 0.997 R² (0.995 R² .. 0.998 R²) mean 524.6 μs (515.3 μs .. 534.4 μs) std dev 32.16 μs (24.85 μs .. 43.26 μs) variance introduced by outliers: 54% (severely inflated) benchmarking Countdown Bench/mtl.State time 8.177 μs (7.975 μs .. 8.394 μs) 0.994 R² (0.992 R² .. 0.996 R²) mean 8.087 μs (7.891 μs .. 8.302 μs) std dev 701.4 ns (585.9 ns .. 844.3 ns) variance introduced by outliers: 83% (severely inflated) benchmarking Countdown Bench/tftf.State time 2.584 ms (2.540 ms .. 2.643 ms) 0.993 R² (0.987 R² .. 0.997 R²) mean 2.699 ms (2.646 ms .. 2.755 ms) std dev 191.4 μs (155.4 μs .. 235.7 μs) variance introduced by outliers: 50% (severely inflated) Benchmark core: FINISH ```
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/haskell_jp] [What's up with Hayoo?](https://www.reddit.com/r/haskell_jp/comments/ataqq6/whats_up_with_hayoo/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
So I just pushed a change, but it's weird. `stack bench` shows your results, but `stack bench --ghc-options=-O2 --force-dirty` shows mine---even though you have `-O2` in the package.yaml file.
&gt;Powerful abstractions have many constraints, many laws. What 'powerful laws' does front-loading with `ErrorT e (RWST r w s IO) a` give you again? &amp;#x200B;
I don't think the concern is primarily about compilation time or hard drive space, but about security. With so many dependencies and transitive dependencies, it's significantly easier for a malicious actor to gain access to one of them and have it go unnoticed.
Go write this editor extension and get back to us with your report about how easy it was to do.
make your own: but better.
You can write crappy code in any language. But, I've never seen a deeper dependency graph than I've sen in javascript.
`lens` in particular is a bit horrible. While I understand the reasoning behind lumping everything into one package, I don't think this is the best approach for such an amazingly useful package. Personally I prefer `microlens`, which is divided up into several smaller packages.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/linuxmasterrace] [Yet another day on Haskell dependencies](https://www.reddit.com/r/linuxmasterrace/comments/atcbre/yet_another_day_on_haskell_dependencies/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
Have you looked at [this thread](https://www.reddit.com/r/haskell/comments/arj7h6/expresso_a_simple_expressions_language_with/) at all? Personally I think Expresso's implementation is pretty damn nice.
Seems like you might find [Haskell lenses](https://mmhaskell.com/blog/2017/6/12/taking-a-close-look-at-lenses) interesting.
They don't will to, but they have
That probably means you're too worried about that, so you write your code as if you were writing in a strict language and don't take advantage of laziness.
I think that's the wrong way to approach Haskell. That way is a huge waste of the benefits of Haskell's type system. I start with the simplest way to solve a problem in Haskell, knowing that once the problem becomes more complicated and I need to inject more concerns, I can easily refactor my code to accommodate them. That's the opposite of the OOP philosophy for instance. They try to make things extensible from the beginning, because they know they won't have the courage to touch existing code when the time comes.
Its probably also worth raising an issue in the [Stack issue tracker[(https://github.com/commercialhaskell/stack/issues/).
News was maintained by chris done (the news section just mirrored haskellnews.org). He stopped maintaining it. If someone wants to volunteer to pick it up again, I'd love it! But as a one-person effort, it isn't representative of anything about haskell as a whole. In the meantime, the current website actually just doesn't link to that page anymore. *shrug*. But the main thing that you seem to be completely off-track about is the idea that ghc is only delivering bug-fixes. You picked a milestone for a minor point release! Minor point releases are definitionally and by the calendar but-fix releases! Look at the milestones for the next _major_ release and you'll see something entirely different! https://ghc.haskell.org/trac/ghc/query?group=status&amp;milestone=8.8.1 But actually, that's not representative either, because trac is _mainly_ a bugtracker, and _not_ for tracking of feature development, which happens elsewhere. These days, you can see feature development ideas discussed in part in the _very_ active ghc-proposals repo: https://github.com/ghc-proposals/ghc-proposals/pulls Finally, all your other complaints are about the _language spec_ and nothing else. Indeed, the language spec process has not done much since 1998! H2010 was only a modest improvement over the '98 report. But that tells us nothing about the health of the language or ecosystem -- after all, over that entire period Haskell went from an almost entirely research and teaching language into something used widely across a range of industries and applications, and in the form of GHC has evolved _drastically_. The main reason we don't have lots of work on the spec and it is hard to convince people to really spend time on it is that while having a new spec is nice in theory, without having multiple competing compilers which all seek to be compliant with it, it is really just a showpiece that is independent of the living process of development.
Hey, this seems like a really cool gig. Would love to pick your brain a bit, what is the best way to get in touch with you? 
Thanks for the GHC info. &gt; Finally, all your other complaints are about the language spec and nothing else. Sure! The way I see it, this stasis causes an increase in chaos, hacks, and friction to just use the language to get a job done. As you pointed out, GHC has been creating lots of _extensions_. IMO, this kind of fracturing of the language an ecosystem is poisonous.
There is no fracturing because there is no other competing compiler. There's no chaos and no friction because there is no other compiler for there to be friction with.
What makes ghcup any better than chocolatey? 
Your next step from here would be to learn about pattern matching on constructors.
Hi, yes I have thought about that and of course that is exactly how case is implemented internally. I guess I went with the current syntax to make it look more familiar, but I concede that is a dangerous path to follow, it also landed me with curly brackets! 
Do you mean something like changing the below code from: &amp;#x200B; \`\`\_to\_decimal binary\_list num | length binary\_list == 0 = num | otherwise = \_to\_decimal remaining updated\_num where remaining = Prelude.tail binary\_list updated\_num = (factor \* first\_elem) + num factor = 2\^(length binary\_list-1) first\_elem = Prelude.head binary\_list\`\` &amp;#x200B; to this: \`\`\_to\_decimal:: \[Int\] -&gt; Int -&gt; Int \_to\_decimal \[\] num = num \_to\_decimal binary\_list num = \_to\_decimal remaining updated\_num where remaining = Prelude.tail binary\_list updated\_num = (factor \* first\_elem) + num factor = 2\^(length binary\_list-1) first\_elem = Prelude.head binary\_list\`\`
Your title and the content of your post are almost completely orthogonal. I wanted to read discussion about ideas we could steal from other places, not a premature obituary, so I'm going to talk about that instead. Something that's been on my mind for a while is the amount of good software produced by people who think fundamentally differently than we do. Everyone here knows our approach - we succeed because we express our logic in the type system and the type checker helps us write sensible code. But what about other software like the Linux kernel? I depend on that every day, and for all its faults, it works really well. They have no almost type checker, I never see them talking about basic abstractions we use like semigroups or functors, and in fact the rules they do hammer with the same vigor that we do type safety seem downright nonsensical to me: someone discovers an obvious bug in an API and fixing it is technically a breaking change? YOU MAY NOT FIX IT, because it breaks userspace! Err.... *what?* And it seems like the more nonsensical it is to apply that rule, the stronger they enforce it. So as far as I can see their entire approach to developing software is completely orthogonal to our approach, and yet it... seems to work. But why? I don't really have a good answer, to be honest what they do seems like nonsense to me, which is probably why I'm here and not there, but I can't deny that their stuff works and I use it. The best I can come up with is that because of this "don't break userspace for any reason" rule at the cornerstone of their development process, they don't actually push sloppy code in the first place because they know they won't be permitted to fix it. In this sense, the rule is not so much of a statement about software as it is a punishment on careless development practice in the first place. I can certainly say that if I were never allowed to make breaking changes to my packages, I'd think a lot harder before pushing them. There's other communities that also seem to have succeeded in ways that I respect, too. Back when I was a kid, I played lots of GameBoy Advance games. That thing had what, a 16 MHz processor and 32 kb of ram? And yet everything ran smoothly at 60 fps, I never once had a crash even over years of playing. So how did they build software like that? I honestly don't know - I doubt they did it how we do in Haskell, and that art seems to have been lost in game dev today (Hearthstone on my iPhone crashes multiple times per hour). So yeah, I'm happy with how we do things here, but clearly there are other approaches to getting good results. I wish I could provide more insight into exactly how, but tbh I just don't know that much about how these other ecosystems work -- just that I don't recognize anything there at all.
{`aeson`, `profunctors`, `text`, `bytestring`, ...} in `base` 2020
Vis a vis GBA, I think the answer is they had a _ton_ of QA? And also a lot of the secret sauce was in having an engine that was very battle-tested where all the tricky bits went, which actually isn't too different from how we do it today? :-)
It handles installing multiple versions side-by-side very nicely. And also it is a lightweight script as opposed to a full package system (which isn't that big a deal, but for end-users I think they tend to feel it is). Chocolatey also doesn't handle getting ghc and msys all together and configured jointly to work nicely, which is unfortunate. Maybe it could? I mean, for someone that knows what they're doing this isn't a big deal -- but the problem is how do we make things as simple as possible and hard-to-go-wrong for someone who doesn't? (without losing any power or features or configurability along the way :-) )
This is great to know, but does anyone know why is Hayoo down?
&gt;They have no almost type checker... C/C++ does not have a type checker? &gt;And yet everything ran smoothly at 60 fps, I never once had a crash even over years of playing. So how did they build software like that? I honestly don't know Code ran directly/very close to hardware as opposed to one that ran on top of an endless pile of abstractions...
&gt; it handles installing multiple versions side-by-side very nicely. You mean like chocolatey? `choco install ghc; choco install ghc -m --version 8.4.2` gives you the latest and ghc `8.4.2` side by side. &gt; And also it is a lightweight script as opposed to a full package system (which isn't that big a deal, but for end-users I think they tend to feel it is) You mean like chocolatey? which is powershell wrapper around infrastucture and tools Microsoft developed and which are used by virtually ALL .NET developers in the world? &gt; Chocolatey also doesn't handle getting ghc and msys all together and configured jointly to work nicely You mean like `choco install msys2 ghc`? My nightlies already fully configure GHC in a much more sane way than any other installation of ghc on Windows https://www.myget.org/feed/mistuke/package/nuget/cabal-head and the only reason this isn't on the main package yes is because I'm waiting for the next cabal release with some fixes. &gt; I mean, for someone that knows what they're doing this isn't a big deal -- but the problem is how do we make things as simple as possible and hard-to-go-wrong for someone who doesn't? (without losing any power or features or configurability along the way :-) ) This is literally what chocolatey is about. Sane and easy defaults with configuration for power users. Now since we're comparing, it also provides: * Integration with most cloud based CI systems * Deployment of packages to remote machines * Ability to script new machine installs via boxstarter * Integration with Microsoft's own OneGet * Integration with NuGet Pkg restore allowing ghc to be a dependency in Microsoft build systems * Human hand moderated scripts (at least initially). * Automatic verification of packages to make sure no broken release happens * End-to-end security and integrity checks of packages * Virus scanning across multiple vendors to ensure packages are safe * Prevent privileged escalation attacks on users. * Ability to easily uninstall, or upgrade any component you want independently. Compatibility is enforced through version constraints. * Ensures that on uninstall your machine is left in a clean state. New GHC and cabal releases are added quickly, Usually on day 1 but certainly within the first week. So I really don't see what `ghcup` has to offer the Windows user here. 
Eesh. Can we do a bit better than this?
&gt; For people who hate Unicode syntax You’re making it sound as if it was an issue about aesthetics. It’s not. Using characters that your audience can’t find on their keyboards is a huge usability impediment in the sense that it causes completely unnecessary friction, in a place where you’re already starting at a disadvantage trying to explain to project managers and colleagues why on earth you’re doing this instead of YAML or JSON. To be fair though, the whole “load rest of configuration from this url” thing is basically a showstopper anyway, and since you seem to be convinced that this is a good idea to bake into a configuration language for some reason I don’t think I’ll even be trying to convince anyone else to use it.
I think you're basically right. I already realized that you could do side-by-side ghc and deleted that portion of my comment. Great news that your nightlies now get ghc and msys to play together. That's a huge advance! When I said "a `ghcup`" I didn't mean literally that tool -- i meant a ghcup-like thing. It looks like your hard work has gotten the choco packaging basically into that place. I hadn't realized how far along things were :-)
&gt;the whole “load rest of configuration from this url” with content-hashing, and the ability to normalize a configuration into a small (offline) value, this isn't an issue is it?
Agreed on both points, FWIW. Context: I've been evaluating switching various in-house configurations to Dhall, but these are both show-stoppers. Unicode less so, because there is after all a flag, but requiring eternal vigilance to avoid Load-From-URL sneaking into configurations accidentally (or maliciously for that matter) is simply not worth it. (I think Dhall's actually really nice for configuration, but see above...)
On the other hand, smaller, leaner libraries are easier to review.
My first suggestion is to use type signatures on all top level functions, it makes reading your code much easier. Then you used Int to represent a single bit which makes the logic for handling those bits a bit more complicated than it should be. You can introduce a bit type like this: `data Bit = B0 | B1 deriving (Show)` to clarify the logic (and so that you don't have to handle the cases where a bit is not 0 or 1 because you can't simple write those cases). Another thing in your `xor` function is that it's usually not a good idea to accept `Maybe Int` (or any `Maybe` values) as arguments, just take `Int` and map over the `Maybe` outside of the function. As AshleyYakeley mentioned you could use pattern matching, instead of things like this: `_get_init_or_empty curr_list | length curr_list == 0 = []` you can just write `_get_init_or_empty [] = []` I've created a cleaned up version here: https://repl.it/repls/DarkvioletKaleidoscopicCable
&gt; “load rest of configuration from this url” thing is basically a showstopper anyway I am a bit curious about why this is an issue for you? If you are worried that the content of the http import might change without you knowing you can use imports with a hash. This also has the the advantage of caching the import. If you have other security concerns, you can still use Dhall without any of the HTTP functionality. The Haskell implementation has a flag `with-http` that can be set to false: https://github.com/dhall-lang/dhall-haskell/blob/master/dhall/dhall.cabal#L365 I personally think this feature is not completely crazy. The import resolution is done statically before type checking and normalisation. But I'd be interested to know more about which security issues I might not have thought about! :-)
[removed]
What is the poing of having a language for configuration files?. It is supposed that configurations are declarative code of an higuer level interpreted by a program in order to avoid programming at a lower level. Now we can program a language that generates the configuration so we closed the circle in order to waste the time saved..... :(
I don't think `xs zipWith ys` has the same behavior as the original example--- you'll get. 10 xor 1 = 00, when it seems you want this to be 11
Even there, you're using head and tail where you should pattern match. You can bind `first_elem` and `remaining` directly: _to_decimal (first_elem : remaining) num = ... You may already know this, but the implementation also has higher time complexity than it needs to. You're recomputing length for each element, but you could pass it up through the recursion. I also think that recursion might not need to be explicit, the function looks like it can be written with `foldr`.
&gt; C/C++ does not have a type checker? Well, I just tried this #import "stdio.h" int main() { if('c') { printf("hello"); }else{ printf("blah"); } } And it compiles without warnings. So yeah, they technically have a type checker, but if Haskell considered `Char` and `Bool` the same thing, I'm not sure I'd get much use out of it. &gt; Code ran directly/very close to hardware as opposed to one that ran on top of an endless pile of abstractions. That explains the performance (at least some of it -- they had to somehow not leak memory, otherwise it would still have been slow. And memory use now seems to be worse than ever...), but it makes the lack of crashes even more surprising. So they were writing these real-time action games very close to the hardware and doing so reliably? *How?*
Oh that's true, the function assumes that xs ys are the same length.
I see chaos in error handling, records, strings, etc. Everyone creating their own boutique solutions.
But you don't need to type those characters, just use the ASCII equivalent and then have your editor reformat with \`dhall-format\` on save.
I understand everything that you have suggested except "just take the Int and map over the Maybe". &amp;#x200B; My Reason for doing this =&gt; I need to front pad zeros to a binary list for making them the same length so that they can XORED. &amp;#x200B; eg. \[1,0,1,0,1,0,1,0,1,0,1\] xor \[1,0,1\] is actually has a representation like this: &amp;#x200B; \[1,0,1,0,1,0,1,0,1,0,1\] \[Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,1,0,1\] &amp;#x200B; &amp;#x200B; &amp;#x200B; &amp;#x200B;
`State` imposes constraints on passing state by `let`-chains. `Writer` imposes constrains on passing side-channel data around. `Reader` imposes constraints on passing configuration parameters. `Error` imposes constraints on failure state `case`-chaining. And so on.
But you don't need to represent leading zeros as `Nothing` (especially if you use the Bit encoding) you can just use `0`
I'm not sure if you saw my reply, but you can avoid the padding and the `reverse` by swapping the endianness of your list. I.e., think of the list as starting from the right
Actually, swapping the endianness doesn't fix zipWith, since it still truncates. :( But you can use the tail to avoid padding. At a computer finally, so I'll upload my version in a moment.
Do you mean something like this =&gt; [https://repl.it/repls/PowerlessOnerlookedFact](https://repl.it/repls/PowerlessOnerlookedFact) However this gives the wrong answer because though you are reversing the lists it will only process till the length of the shortest list. ("one",\[B1\]) ("two",\[B0,B1\]) it gives the XOR of the above two numbers as B1. It stops at the first bit since the shortest list is 1 element long. Maybe I could write my own zipWith to handle this?!? (Is it a thing that I should be doing?!?!) Something like this -&gt; myzipWith :: (Bit -&gt; Bit) -&gt; [Bit] -&gt; [Bit]-&gt; [Bit] myzipWith curr_func ([]]:_) (y:_) = curr_func 0 y myzipWith curr_func (x:_) ([]:_) = curr_func x 0 myzipWith curr_func (x:xs) (y:ys) = (processed:remaining) where processed = curr_func x y remaining = curr_func xs ys The above is a classic problem I face when writing haskell code. Now I do not know how to check for myzipWith curr_func ([]]:_) (y:_) = curr_func 0 y The reason I resort to using maybe is because then I can check with the maybe monad. I don't know if I was able explain my exact problem to you.
the problem is *WYS is not WYG*. I can see how `forall` changing to `∀` is spooky, former one is a keyword, latter may look like an infix operator. Especially it's not obvious (especially for people without Haskell background) that ASCII equivalent of `∀` is `forall`.
Replace all instances of “execute a http request” with “execute arbitrary code, on potentially any machine connected to the same network as the machine trying to parse your config, and then maybe return a dhall config, or maybe not, it doesn’t really matter at this point because you just ordered 5000 burritos”.
Nice! I really like your bitsToInt too.
&gt; However this gives the wrong answer because though you are reversing the lists it will only process till the length of the shortest list. Indeed, I noticed this when writing [my version](https://repl.it/repls/PleasingPowerfulAbstracttype) &gt; Maybe I could write my own zipWith to handle this?!? (Is it a thing that I should be doing?!?!) This is absolutely something you should be doing! A huge part of the power (and fun!) of haskell is the ability to write "combinators" that hide implementation details. Let's go through your attempt: &gt; `myzipWith :: (Bit -&gt; Bit) -&gt; [Bit] -&gt; [Bit]-&gt; [Bit]` First thing I notice: We aren't planning to use the fact that we have `Bits` anywhere here, so we could instead write &gt; `myZipWith :: (a -&gt; a) -&gt; [a] -&gt; [a]-&gt; [a]` But! This type is wrong: Look at the type of [zipWith](https://www.haskell.org/hoogle/?hoogle=zipWith). We want the function we pass in to take 2 arguments, not one: &gt; `myZipWith :: (a -&gt; a -&gt; a) -&gt; [a] -&gt; [a]-&gt; [a]` Now: &gt; `myZipWith curr_func ([]:_) (y:_) = curr_func 0 y` Style: since _ is meaningful in Haskell, we usually use camelCase instead of snake_case. Also, unless there's semantic information (e.g., `logger`) we tend to prefer short, one word (or often, one or two character) variables. `function` or even simply `f` is more idiomatic haskell. And I've also changed `myzipWith` to `myZipWith` in this comment to reflect this style More importantly: it looks like you are confused on pattern matching syntax. The two types of lists are `[]` or `(x : xs)`--- the pattern in a pattern match should fit one of these two "patterns. Let's try with a simpler function: safeHead, which gets the head (or Nothing if the list is empty) safeHead :: [a] -&gt; Maybe a safeHead [] = Nothing safeHead (a : _) = Just a Going back to `myZipWith` case one becomes &gt; `myZipWith f [] (y:_) = curr_func 0 y` But this is still the wrong behavior: in case we we reach the end of `xs` we simply return *all of* the remaining `ys` &gt; `myZipWith f [] y = y` The second case is symmetric. Now the recursive case: Note that `remaining` is incorrect, since you are not actually making the recursive call. Putting this all together, (and renaming `myZipWith` to `zipWithAndKeep` because I think this name is more descriptive) we can abstract our new function from my version above, to get [this version](https://repl.it/repls/IdioticQuaintLivedistro)
I think the Java "best practices" crystalized around frameworks like Spring work quite well. The combination of favoring POJOs, dependency injection, and aspect-oriented-programming for cross-cutting concerns. I'm not sure what a "Haskelly" version of AOP would look like.
Thanks! I am very pleased with my bitsToInt, so it's nice to hear I'm not alone in that.
One thing I loved is lambdada-mode in Emacs. It replaces word "lambda" with lambda symbol upon display, but doesn't actually change the source, so you just use it in your python mode.
ok this make so much more sense!! This is exactly what I needed!! zipWithAndKeep :: (a -&gt; a -&gt; a) -&gt; [a] -&gt; [a] -&gt; [a] zipWithAndKeep f [] y = y zipWithAndKeep f x [] = x zipWithAndKeep f (x:xs) (y:ys) = (f x y) : (zipWithAndKeep f xs ys) Well yes kind of. &gt;More importantly: it looks like you are confused on pattern matching syntax. The two types of lists are \[\] or (x : xs)--- the pattern in a pattern match should fit one of these two "patterns. Let's try with a simpler function: safeHead, which gets the head (or Nothing if the list is empty) So I was confused about the fact if we can do something like this: myZipWith f [] (y:_) = curr_func 0 y using two different types of pattern matches in expression. &amp;#x200B; &gt;Now the recursive case: Note that remaining is incorrect Yes I just saw that(fixed it). I think this pretty much answers all my questions for now!!! Thank you so much!!!!!!
&gt; What is the poing of having a language for configuration files? It is supposed that configurations are declarative code of an higher level interpreted by a program in order to avoid programming at a lower level. This works fine in the beginning. Unfortunately you always end up with massively redundant config files, no sane way to reuse bits of config across different environments (think PROD, DEV, ...), etc. etc. I think one of the underlying problems is that all the different programs/systems that need configuring all have different ideas of how that's supposed to happen, you typically end up with a mish-mash of YAML, ini-like files, conf.d/\* files, etc. containing different subsets of the overall system configuration. With Dhall there's a real possibility of actually declaring everything you need in a top-down fashion and then deriving all the different subsets you need.
Thanks! I'll make sure to check those out! Regarding "does stack work", honestly, the build tool does all the "forcing of the meme" for me. Rarely do I have Haskell problems these days, instead I have stack problems. 
 &gt;So I was confused about the fact if we can do something like this: &gt; &gt; myZipWith f [] (y:_) = curr_func 0 y &gt; &gt;using two different types of pattern matches in expression. Any input variable can be replaced with a pattern, automatically "deconstructing" it. This even works inside of a pattern. For example, you could write a function which drops only the second element of a list as dropSnd (x : y : zs) = x : zs dropSnd xs = xs Or a function that does something to a bit sequence based on the first bit bitFunc (B0 : bs) = ... bitFunc (B1 : bs) = ... 
You can always ship normalized configurations to machines that have no network access. The normal form of Dhall expressions doesn't contain imports.
Hi, I'm trying to follow [this paper](https://eprints.nottingham.ac.uk/36159/1/paper.pdf) on functional reactive programming but I'm stuck on the second example in section 4.2. I got the first example (section 4.1) with the reader transformer up and running (see [revision 1 of this gist](https://gist.github.com/frosch03/bc0e3f50aa4919d65bf4d410d0d9f152/94b222d548bf8b739e91131cbd57e5f8c87a504b)). But with the next step I'm struggling. I can't figure out how to introduce a writer transformer correctly, I don't even get it to compile. [This second gist](https://gist.github.com/frosch03/bc0e3f50aa4919d65bf4d410d0d9f152/474f139a98e42a8bc3e689407642b2d52e546905) shows the example that I'm unable to compile and I put the relevant compiler output in a comment below. Actually the line 22 is the problematic one. The function `arrM addToLeftPlayerPos` isn't given in the paper and my version seems to lack some kind of `WriterT` transformer that the type alias of line 12 suggests. Any help on what a correct implementation of the `addToLeftPlayerPos` function might be, will be highly appreciated.
I think it's fair that there are scenarios where Dhall's ability to load config over HTTP is a show stopper. But in many cases it seems reasonable to me: &amp;#x200B; 1. Try normalising the config before deploying it. Then it can't make HTTP calls. 2. In many cases, you have to trust or inspect config anyway. If a bad actor can replace your config, they can often do much worse than make some HTTP GETs. 3. You really shouldn't be able to order burritos via HTTP GET. If you can, then to be sure, your dhall config that invokes that URL isn't helping. But it's not your only problem.
That approach has messed me up enough times that I now worry by default. I also don’t write Haskell anymore, but for other, non technical reasons.
&gt; You really shouldn't be able to order burritos via HTTP GET I too would rather live in a universe where everything is great and you can count on GET requests not possibly being able to do anything malicious, but the reality we live in is one in which an application does whatever it damn well pleases with get requests
This seems to me the typical problem of software engineering: then how do you know how to configure and define the formats of the different configurations? you hardcode it directly in DHall? That is not nice. Let's create a configuration file for that.
You don't *hardcode* it in Dhall. You *code* it in Dhall. Dhall -- by virtue of being an actual language with semantics -- is powerful enough to handle any configuration you might want. (Types, esp. Algebraic Types, help a lot here.)
If I can't edit with an ancient version of `vi` (not vim), across a 1200 baud serial connection, with incorrect terminfo, I can't use it as a configuration file. Production isn't quite that bad, but it's close. The next rollout will get us `vim`, but that won't be everywhere for several years. The terminfo is a constant problem, as the OS doesn't actually know about terminfo, and simply uses and undocument ANSI IBM variant that doesn't match any of the PuTTY settings, which requiring (in a truely IBM way) that various F-keys be used for application actions. I can always get 7-bit clean ASCII through to the remote side to hot-patch stuff. So, if there's any chance I might need to edit it in production, it needs to deploy in a 7-bit ASCII format. For JSON, YAML, and XML, this isn't a problem.
"Avoid success at all costs"
Source: http://james-iry.blogspot.com/2009/05/brief-incomplete-and-mostly-wrong.html
Ever seen javascript? 15 different libraries to do the same thing and half of them have major showstopping bugs, half of the rest are abandoned, and only one working implementation doesn't use jQuery. Haskell's package ecosystem has its problems, to be sure, but I'm unconvinced that diversity of solutions is one of them.
I’m a bit confused that people on that article seem to keep referring to Haskell as imperative. Since it only allows for a function to be a single expression I fail to see how to even write imperative code in Haskell other than monadic sequencing in do blocks. I’m not an expert in Haskell, I wonder if someone with more experience could clarify why all of these references to it being imperative.
yes and no no) you can learn and successfully use haskell being not a computer science guru or even being not a good programmer for that matter. You do not need to have a PHD in abstract math or anything of the sort.. with some patience and hard work (it still has steep learning curve) you will be successfull and you will learn a lot fun and practical things about computing yes) haskell can go deep... very deep. It is a rabbit hole which you can explore as much as you want, reading abstract math article etc... You do not have to, but you can. Therefore, a lot of very smart people is attracted to haskell, since you can always learn and be amazed and be on the age of computer science. Unfortunately, there is also some sort of elitism to this. Moreover, since those smart people are in the community it will always stimulate everyone to go deeper than they have to - you will always feel a noob.
Ok, I think `dhall` can normalize with `--ascii` to get what you want for deployments.
OP writes: "I don't want to offend,..." OP instantly offends: "but Hasekll is moribund." You then cherry-pick some discussions and incorrectly claim GHC is only in bugfix mode by choosing a minor point release. What were you attempting to accomplish with this topic? 
I don't really see anybody calling it that. "Imperative style", sure. It's not hard to port imperative code to Haskell. Compared to some other functional languages the use of a where-block comes very natural. 
What we're talking about in this thread is timing attacks. The tricky thing about timing attacks is how they work and what's required to combat them. A timing attack is where you want to find out a secret; you can do so by trying many different inputs and comparing how long each different input takes. It's actually possible to completely recover an encryption key using this method. An algorithm that's impervious to timing attacks must, then, take *exactly* the same amount of time regardless of input. In practice, this can be solved by either: * Making sure people run the exact same CPU instructions regardless of input. (How would that even work?) * Adding artificial delays to the algorithm so that every possible input performs the same as the pathological worst case. Libraries tend to do the second one, iirc. What's interesting here is that a higher level language will optimize the crap out of your code and any "useless" code that just sits there and spins the CPU for x amount of time is *particularly* liable to get removed. Rust suffers from this as well. This is why people tend to implement most timing resistant algorithms in assembly, so they know *exactly* how long something will take (well... mostly; assembly is kind of a lie with modern CPUs)
I would guess that /u/snoyberg has his SSL settings up too tight. Restricting yourself to ciphers that result in an A-rating will cut off people running older versions of browsers (they have to be *really* old, though; even IE8 should work fine) Puzzling that links works, though... Alternatively, maybe the version of Firefox you're using doesn't trust Amazon's Certificate Authority?
I see at list two references: &gt; Tutorials aren’t too user-friendly, though, plus its imperative background prevents new concepts from emerging. &gt; It’s (subjectively) easy to adapt your thoughts to code, it has a great balance of imperative and functional paradigms. None of them say anything about ease of porting imperative code to Haskell.
Looking at the feedback, it seems like `--ascii` should be the default and `dhall --unicode` should be a flag.
I think the first one is referring to Redux. The second one says that it takes cues from imperative languages, not that it's imperative. "Ones thoughts" are often imperative, as is plenty of pseudocode or other code you'd want to port. Obviously Haskell isn't imperative, but with its syntax it finds a balance. This is very true compared to say LISP. 
The suggestion was to compute the normal form of your configuration (on your build machine/CI server with network access) and then ship that. The normal form essentially inlines all imports into a single file (and then reduces it as much as possible).
It seems like /u/ocharles is getting valuable feedback here. However I'm concerned that he's getting voted down when he engages with the questions. I don't think that's the right way to respond if your only issue is that he hadn't completely Fu
fwiw GHC delivers a lot more than bug fixes; each new major release (which happens once or twice a year) brings a wealth of new features, a lot of them clamored for by the community. I recommend reading some release notes for major versions to see. Secondly yes, usually the answer is to program to GHC, not Haskell. But I'm not sure if that's a real problem or issue :)
Haskell can be imperative and have mutations. The difference is that this is not the default, and these features must be explicit, both at the type and value level.
(no)
Haskell is the language of investment. If you invest in learning and mastering the many forms of abstraction Haskell embraces, including their interactions with each other, the investment pays off in spades in terms of safety, readability, productivity, and maintainability. This investment is often undertaken by people academia, perhaps even some geniuses, however it is by no means limited to them. The community is full of other productive members who made the same investment and do not fit the title's description.
What's the motivation for setting this up? Just curious if there was a problem with a different communication forum or if this is a "sure, why not" thing.
It sounds like you're doing well so far. Two additional comments: - it really is better to use CamelCase. It makes spaces more visible and helps distinguish functions and arguments: `xor_lists bin_num1 bin_num2` vs `xorLists binNum1 binNum2`. Most people find the former difficult to parse. - Complimenting the advice to use pattern-matching instead of `==` wherever possible, use `case` when you want to apply a function and branch on the result In general the principal of DRY will serve you well in haskell. for fun here's a couple different versions of your first function, any of which would be fine: ``` -- don't repeat the predicate (this is my second bullet above) helper 0 = [] helper n = case n `mod` 2 of 1 -&gt; 1 : helper (n `div` 2) 0 -&gt; 0 : helper (n `div` 2) -- notice we don't really need the branch at all helper 0 = [] helper n = (n `mod` 2) : helper (n `div` 2) -- consider using divMod or quotRem, which will be a little faster (though a bitwise version would be even faster, -- unfortunately) and arguably a little clearer helper 0 = [] helper n = let (q,r) = n `quotRem` 2 in r : helper q -- a oneliner version that uses unfoldr to factor out the recursion. -- This is probably the version I would start writing but then decide ended up being -- a little too obscure/dense, and go with the version above import Data.List (unfoldr) import Data.Tuple (swap) helper = unfoldr $ (\t -&gt; t &lt;$ guard (t &gt; (0,0))) . swap . (`quotRem` 2) ```
Seems reasonably good for the set of people who don't like mailing lists nor Reddit.
Yeah. There is a thriving community of phpbb forum software, and I find it absolutely impenetrable. I just can't have a meaningful conversation on that kind of software because the layout is so hideous and the pagination makes it impossible to get up to speed on the convo. Email lists are better than bad web forums, but not much better. Nothing to distract you while you wait for an answer or next post. Discourse is quite a bit better, for sure. 
I don't think there was a problem with any of the existing forums (reddit, mailing lists, twitter, ...) but Discourse does offer some interesting differences/features compared to all of these other channels. For the record, it's not meant to replace anything that's already there. For example, some of the key differentiators when comparing it to reddit (since I think it looks similar to reddit at first sight) are: - it's self hosted and open source, so we don't rely on external services too much - people can use it in a "mailing list" mode Setting up a discourse instance turned out to be good idea in other language communities (Nix, Rust, Ocaml, Elm...) so we decided it was worth giving it a try as well.
This is a good argument for increasing the use of [SafeHaskell](https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/safe_haskell.html), so that dependencies can easily be audited.
Why are we bringing JS into the discussion? Just because it does not have as deep-rooted dependency as some of the JS projects do, doesn't mean Haskell programmers should be thankful or be satisfied with it.
I personally think it would be worth it, it would mean that any useful tools and abstractions people build for records can be automatically re-used for "case" statements. On the conciseness aspect, if you allow for Haskell-style function definitions (`f = \x -&gt; x` -&gt; `f x = x`) and specifically you support that syntax in records (which Haskell does not), then you get that conciseness back: let f = x -&gt; case x of { Foo x -&gt; x, Bar {x, y} -&gt; x + y } let f x = x =&gt; { Foo x = x, Bar {x, y} = x + y } or even if you have a `case` function with the record argument first (to mimic `LambdaCase`) and the variant second, you could even change the above to: let f = case { Foo x = x, Bar {x, y} = x + y }
You can checksum every URL fetch no? I don't see how this is different from fetching arbitrary dependencies from hackage.
I'd rather have no mandatory lack constraints, it's less general as the scoped labels. You can still use lack constraints for your API if you want. In addition to that it's not really possible to port an implementation to GHC. Be it Espresso or Purescript
Has there ever been a proposal to support one-line definitions? kMyConstant = 42 :: Int -- ^ The answer to the Ultimate Question. Currently, the above generates a `missing-signatures` warning and a parse error in Haddock.
See if there is any hope for Haskell Lang development
&gt; Ever seen javascript? Pointing to one of the worst cases out there and saying, "we're better than that one..."
[Betteridge's Law](https://en.wikipedia.org/wiki/Betteridge%27s_law_of_headlines) strikes again!
**Betteridge's law of headlines** Betteridge's law of headlines is an adage that states: "Any headline that ends in a question mark can be answered by the word no." It is named after Ian Betteridge, a British technology journalist who wrote about it in 2009, although the principle is much older. As with similar "laws" (e.g., Murphy's law), it is intended to be humorous rather than the literal truth.The maxim has been cited by other names since as early as 1991, when a published compilation of Murphy's Law variants called it "Davis's law", a name that also crops up online, without any explanation of who Davis was. It has also been referred to as the "journalistic principle", and in 2007 was referred to in commentary as "an old truism among journalists". *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/haskell/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
When dealing with regular maps and dictionaries and the like in Haskell and in other languages, it seems neither approach is used, and instead existing values are overwritten. This seems most intuitive to me, so i'm curious why that's not the approach taken. Instead of: f : forall r. (r \ x) =&gt; {r} -&gt; {x : Int | r} f = r -&gt; { x = 0 | r } Why not: f : forall r. r -&gt; {x : Int | r} f = r -&gt; { x = 0 | r } Where `{x : Int | r}` gives `{x : Int}` when `r = {x : Bool}` rather than failing to compile or adding a scoped `x` on top of the existing `x`. I realize this will affect deletion too, changing: f : forall a r. (r \ x) =&gt; {x : a | r} -&gt; {r} f = r -&gt; r \ x To something like: f : forall r. r -&gt; r \ x f = r -&gt; r \ x Where `r \ x` gives `{}` when `r = {x : Bool}` and also when `r = {}`.
Some great ideas! Thanks
Hey I know you guys, you use my ftp-client library. 
I agree. :)
You can always introduce monadic state into any functional language I guess, it's just haskell gives the syntactic sugar for it. Haskell used to be at the center, but ever since the industry took it over it seems to have gotten less academic and interesting and more practical. Which isn't bad.
TVision is legit, I've got a good friend there and they seem really nice in general. Plus, we need more Haskellers in Boston!
GHC has a proposal process that has moved faster than any other language I've developed in. I don't want to be overly optimistic, but GHC haskell has changed more in the past ten years, while maintaining strict backwards compatibility, which is something that other language communities, such as the venerable and eminently popular Python have not.
I'm an idiot and I like Haskell.
I think you a word.
You can also go the Clean direction and use uniqueness types instead of monads for state. I think bind (from Monad) and apply (from Applicative) are nice to use because they feel more general. Though, there is some argument for how Idris does do-notation, which allows indexed monads, or switching the monad mid-block with a natural transform bridge (it basically just looks for a bind that type checks).
Haskell makes me look less like an idiot.
If you want to feel more like one, try to write a decently performing regex using program :L
'if' is actually an interesting case. if does not trigger on "True" or "False" per se it triggers on !0. C does have a bool type, which works as you would expect. But the type is merely eyecandy for int '0' and '1'. and a bool variable is capped to 1. This is necessary because: int a = True + True; results in a being '2' &amp;#x200B; If you combine if and boolean logic in C it leads to funny results. e.g. if(2) -&gt; interpreted as True if(True) -&gt; considered True if(2 == True) -&gt; False &amp;#x200B;
 foreign "C" import "regcomp" foreign "C" import "regexec" ;) /s
Arbitrary dependencies from Hackage are on Hackage. They're not at `http://intranet/launch-nukes`.
&gt; with content-hashing Content hashing is irrelevant. The problem is that you have to do a HTTP request to even parse the config, by the time you check the result it's already too late. The problem isn't that you might get a wonky config, the problem is that your config parser is potentially hitting arbitrary API endpoints.
Interesting, I must check Idris out, thanks.
I see Discourse as mainly a Q&amp;A platform. In this scenario, it has one unfortunate effect: the questions that otherwise go to StackOverflow will end up on Discourse. But SO is usually better represented in Google Search results and, more generally, percepted as the main Q&amp;A tool.
One of the worst cases out there is also the most widely used language on the planet. I don't think you can dismiss that out of hand as evidence that this isn't an indicator of morbidity.
 class Person' repr where id :: repr -&gt; Int name :: repr -&gt; String age :: repr -&gt; Int Describes an open record type class Person repr where person :: Int -&gt; String -&gt; Int -&gt; repr Describes an open sum type Person' makes it easy to add new (required) fields Person makes it easy to add new cases. 
As a QA Engineer who works with Spring Java projects daily, I disagree firmly. The language isn't helping to ensure quality, and the best practices aren't helping to ensure quality. Ultimately, what causes the result of any software project to actually be 'good', regardless of language, isn't the language or the ecosystem, it's the QA practices put in place to make sure that the language and the ecosystem are being used to get the effect you want - It should be relatively unsurprising that the key to assuring quality is in fact quality assurance. There is a complement to that, in that some architectural patterns can be used that make QAs job easier or harder, but in my experience it's overwhelmingly the case that this is not the primary criteria used for selecting architectural patterns. The language or ecosystem can really only help QA (insofar as making QA more complete, not necessarily making QA faster or 'easier') is by enforcing or strongly pushing architecture with clean boundaries of abstraction and rigid parametricity. It is my experience that Java (as an ecosystem and a language) promises those things but does not deliver firmly enough on them to make testing it significantly different than testing JS or Python, with regards to completeness, if not necessarily with regards to 'ease' or velocity. 
But what's it evidence of? I want to spend my time with languages that do better. I'm not forced to use Haskell.
Can you share example code that reproduces the issue?
Certainly by the time GHC is invoked, the state of all flags in the package is known, right? That should be enough to automatically define macros for CPP
Fascinating! I've actually started promoting the use of a dynamic scripting language in my team to show them how much work it is to do right. This was because of a deadlock at work over the use of languages, in particular FP statically typed vs OO dynamically typed. If I'm proved right, good. If not: good, because I will have learned something, and at least the deadlock is broken. The above seems to be related, in a way I hadn't heard expressed before. A sort of "proof by contradiction" without knowing the precise theorem beforehand.
Sure, but you're changing the context of the conversation. 'Haskell is dead because X , Y, and Z prove me wrong' is not the same as 'Haskell has N problems that make it distasteful to me personally, convince me I should use it' 
Question to downvoters: I'm in the same boat as OP. Where can I get my Haskell code reviewed? 
OT, dumb question: how do people like to use mailing lists...? I used to read the Haskell Cafe digest, and read old archived threads but never really figured out an ergonomic way to use it. 
I like the article, but I find everything after subtype polymorphism lacks a bit of clarity, unless you already know the concept. E.g. for higher rank polymorphism there is no explanation why you would need the inner forall at all. It assumes quite some knowledge already. 
 kMyConstant :: Int {-^ The answer to the Ultimate Question -}; kMyConstant = 42 works in GHCi.
/r/haskellquestions ? I think there's also a code-review oriented stack overflow ?
Here's a sneak peek of /r/haskellquestions using the [top posts](https://np.reddit.com/r/haskellquestions/top/?sort=top&amp;t=year) of the year! \#1: [Best libraries on numerical linear algebra and statistics](https://np.reddit.com/r/haskellquestions/comments/aeknxj/best_libraries_on_numerical_linear_algebra_and/) \#2: [Is _Data_.Functor vs _Control_.Monad a historical accident?](https://np.reddit.com/r/haskellquestions/comments/8ovk1m/is_data_functor_vs_control_monad_a_historical/) \#3: [Don't understand function](https://np.reddit.com/r/haskellquestions/comments/9tl9lm/dont_understand_function/) ---- ^^I'm ^^a ^^bot, ^^beep ^^boop ^^| ^^Downvote ^^to ^^remove ^^| [^^Contact ^^me](https://www.reddit.com/message/compose/?to=sneakpeekbot) ^^| [^^Info](https://np.reddit.com/r/sneakpeekbot/) ^^| [^^Opt-out](https://np.reddit.com/r/sneakpeekbot/comments/afd0dd/blacklist/)
`dhall` is pretty new, but that's not how `nix` works. afaik, (but this doesn't always trigger), the downloaded content is cached, the url name and the hash should be enough to satisfy the cache. 
I agree, and IMO it could benefit of also showing a more formal definition of the meaning of polymorphism along with the casual one presented in the beginning of the post.
I like discourse for discussion that last longer than about a day. Reddit, Slack and Twitter are all awful for that, so having this is a good thing. The discourse page for Julia and Rust are both widely used for example.
What? haskell is for the lazy people like me. Compiler should do more work for me. :)
More auto-cheering. What can't be a language is a religion and a way of life. When this is the case, you need spiritual help. My suspect is that this is the case in a number of haskellers. These kind of people are the ones who make Haskell something very different from a programming language, which is a tool after all. These people who never create programs with a main for a purpose external to the language itself. That has happened with other languages in fashion in the past. My hope is that some other language becomes fashionable, so Haskell can get out of the "demonstration of genius" niche. 
I agree, a few explanations on how such polymorphisms are useful wouldn't go amiss either. Otherwise, the article is very nice with the comparisons between languages. 
I think that would be a good proposal.
That looks like `const` to me.
Other than bottom, like `f = undefined`? No. The `a` variable might even be instantiated to a type that has no values. Interpreting this as a logical statement, it's like having a proof that "if a is true, then b is true", and from this, producing a proof that a is true. That's not possible.
`a-&gt;b-&gt;a` is totally different from `(a-&gt;b)-&gt;a`
Tip: Let `a` be the empty type.
Yes, they are different.
I'm not sure I have a good answer, but the connection between CPS and Yoneda has been [noted before](https://reperiendi.wordpress.com/2008/01/26/yoneda-embedding-as-contrapositive-and-call-cc-as-double-negation/)
One would think not. You are asking for a function which returns some a when given an input function that takes some ```a``` and returns some ```b```. There is no way to generate an ```a``` when given such an input function. The closest you are going to get to this type signature is ```const```, but that is ```a -&gt; b -&gt; a``` (i.e., ```a -&gt; (b -&gt; a)```). There is a more elegant way to explain this using Curry–Howard correspondence, but I shall refrain lest I embarrass myself more.
I'm into it.
Thanks for your feedback. Given the main differentiator of this book is "Beginner-friendly", I will consider using "practical" instead.
Awesome post!
Worth noting that a slightly different type forall res. (a -&gt; res) -&gt; res can be seen as continuation passing style of `a`; isomorphic to `a` type CPS a = (forall res. (a -&gt; res) -&gt; res) lift :: a -&gt; CPS a lift a f = f a -- flipped function application (Data.Function.&amp;) lower :: CPS a -&gt; a lower cps = cps id If you flip `fmap @f` f a -&gt; (a -&gt; b) -&gt; f b f a -&gt; (forall res. (a -&gt; res) -&gt; f res) there the same pattern emerges (previously for `fmap @Identity`), now for any `f`, as [`Yoneda f`](https://hackage.haskell.org/package/kan-extensions-5.2/docs/Data-Functor-Yoneda.html) (`type CPS a = Yoneda Identity a`) type Yoneda f a = (forall res. (a -&gt; res) -&gt; f res) or type f ~&gt; g = (forall xx. f xx -&gt; g xx) type Yoneda f a = ((-&gt;) a ~&gt; f) lift :: Functor f =&gt; f ~&gt; Yoneda f lift = flip fmap -- flipped fmap (Data.Functor.&lt;&amp;&gt;) lower :: Yoneda f ~&gt; f lower yo = yo id
Here's the index and intro: https://link.springer.com/content/pdf/bfm%3A978-1-4842-3739-7%2F1.pdf
Has anyone read this already? Did you like it?
ah! No Servant?
what should i read to understand 'intendent audience' snippet well? i did some scala in the past and know clojure, but was never a functipnal programmer in professional setting. i need some shortcuts tho.
I'm reposting this email because I think that [`bytestring`](https://github.com/haskell/bytestring) is not the only core library that I wish would get a lot more love. [`text`](https://github.com/haskell/text) and [`containers`](https://github.com/haskell/containers) are similar cases in my mind. Apart from the maintainers' time constraints I believe these packages are difficult to contribute to because their omnipresence in dependency graphs causes cyclic dependency issues in their testsuites and benchmarks.
I wonder what tools are used as a foundation here. Since I don't see the mentions of any particular web libraries, I'm guessing this is a "from the ground up" book, but does that mean building your own HTTP server?
The apress page mentions it's using scotty, which is a decent not-too-many-batteries-included basis to start from. Sadly no servant from what I can see from the preview, but certainly looks interesting.
We use Haskell on the backend. servant and yesod in particular. No one pays us to write unit tests, and haskell is great at reducing QA spend.
I think that's just `Void`, but I don't have GHC on me to typecheck this: data Void = Void forall a b. (a-&gt; b) -&gt; a absurd :: Void -&gt; a absurd (Void f) = f (const ())
Awesome work on this one u/peargreen! I look forward to using it at work :) It would be nice to have the package name listed next to the file names on every result; if you're scrolling through results quickly I have to backtrack and scroll up to see which package I'm in :)
I do not think your characterization of kernel development is accurate. They are relying on the typechecker they have available. If you activate most GCC/Clang warnings you come pretty far. For example they are using structs as newtype-like wrappers, e.g., kuid\_t. Furthermore they are annotating pointers with \_\_user and \_\_kernel tags to prevent confusion. These are checked by additional static analysis tools (like an external type checker). Then they are using techniques like fuzzing and testing to a great extent, which is not the same as proving things, but cannot be dismissed. The paradigm of not breaking user space is comparable to maintaining a very popular haskell library, where many downstream users would complain if the API changes suddenly. In contrast to other operating systems, the syscall interface is the stable API. Other operating systems often define their stable API on the library level. While they might not be too much concerned about mathematical abstractions as we are in Haskell, there seems to be going on a lot innovations in other areas. For example BPF is like a mini compiler, verifier and virtual machine within the kernel. Furthermore I see much going on concerning concurrent datastructures, e.g. RCU. These things don't come out of thin air. There are theoretical underpinnings. So I don't see that their approach is "completely orthogonal" to the Haskell approach.
I'm not too sure about "As Haskell is not Object Oriented, subtyping would make no sense". It just really messes up type inference, constraint solving, and instance resolving. As such it is not a good fit for the Haskell we have, but I don't think it's got anything to do with being OO or not.
As an alternative viewpoint, notice that an element of such a type would provide an element of `Void`: exfalso :: Void -&gt; a exfalso = \case {} void :: (forall a b . (a -&gt; b) -&gt; a) -&gt; Void void h = h exfalso
This is relevant because this is how we "prove" that something cannot exist: a proof that you can write a function from your thing to Void is a proof that your thing can't exist.
Oh boy, that's a fun bug. On it.
Frontend?
&gt;to live outside the law, you must be honest \-- Bob Dylan, I believe in his talk on dynamic typing &amp;#x200B; &gt;They have been at a great feast of languages, and stolen the scraps. \-- Shakespeare, in that blog post about Anders Heijlsberg and Mads Torgersen &amp;#x200B; &gt;A custom loathsome to the eye, hateful to the nose, harmful to the brain, dangerous to the lungs, and in the black, stinking fume thereof, nearest resembling the horrible Stygian smoke of the pit that is bottomless. \-- King James, on deep inheritance hierarchies &amp;#x200B; &gt;You wanted a banana \-- Joe Armstrong, On Bananas
One of my favourite tricks is using `replicateM` to generate all binary sequences of length `n`: &gt; replicateM 3 "01" ["000","001","010","011","100","101","110","111"] At first it looks like magic, but once you understand what `replicateM` and the list monad do, it makes perfect sense! Anyway, it is easy to extend that to an arbitrary base, so I'd start with that. Okay, but one of those sequences is `"000"`, which is really just `"0"`, so that's not really a 3 digit number. Well, what do real 3-digit numbers look like? They begin with a non-zero digit! So let's tweak the expression so that zero can't be picked as the first digit. Again, this will make perfect sense if you know about both Applicative syntax and the list monad, and will looks like gobbledygook otherwise. &gt; (:) &lt;$&gt; "1" &lt;*&gt; replicateM 2 "01" ["100","101","110","111"] All right, almost there. Now that we understand the formula, let's turn this into a function. numbersOfLength :: Int -&gt; [String] numbersOfLength 0 = ["0"] numbersOfLength n = (:) &lt;$&gt; "1" &lt;*&gt; replicateM (n-1) "01" We can now call this function repeatedly in order to produce the numbers with 3 digits or more: &gt; take 15 $ foldMap numbersOfLength [3..] ["100","101","110","111","1000","1001","1010","1011","1100","1101","1110","1111","10000","10001","10010"] 
That's helpful to hear -- so even though they don't quite give types the same formal treatment we do, they are at least pursuing a similar goal of trying to get the machine to catch logical errors. In this sense, maybe we're not so different. To the last paragraph, I didn't mean to imply that nothing they do has any theoretical basis. It's just like you said, the compsci they keep their attention on is pretty different from the compsci we focus on.
&gt; The a variable might even be instantiated to a type that has no values. For example, use * a = `Void` * b = `()` Then, `f (const () :: Void -&gt; ()) :: Void`.
I am not implementing records at all. My changes are only the type level rows. You can implement either semantic with that as a library.
+1, really nice! Pressing enter in the search field should do the thing.
Fantastic, I will be studying this. Thank you.
Whether you do scoped labels or lacks constraints or neither when implementing rows will probably somewhat decide what the associated records do. Also I’m not sure how you can build a records library on top of the rows without some sort of bridge between them (the simplest bridge I can think of being a baked in record implementation). Perhaps if you provide type level arrays and value level products based on these arrays, then you could maybe piggy back off of that? Side note will these rows be available on both the type and the value level ala DataKinds?
ghci &lt;filename&gt;
 forall a. forall b. (a -&gt; b) -&gt; a ~ -- newtype Const x a = Const x forall a. forall b. (a -&gt; b) -&gt; Const a b ~ -- newtype Yoneda f a = Yoneda (forall b. (a -&gt; b) -&gt; f b) forall a. Yoneda (Const a) a ~ -- Yoneda f a ~ f a, given f is a functor forall a. Const a a ~ -- newtype Const x a = Const x forall a. a So your type is isomorphic to `forall a. a`, whose only inhabitant is `undefined`.
Hey thank you!
You might try http://repl.it I don't know if that's compatible with your class but it's a nice place to learn and try things.
While /r/haskell is happy to help, and I'm glad you seem to have gotten some help already, you might want to avail yourself of some office hours or something, because that's going to be much faster to get help turnaround quickly. Don't be shy; it's not an imposition, they're there anyhow.
thank you dude i'll take a look.
It's a little tough my university is a hour away from where I live but i'll try my best
Does anyone know what's going on with the Intermediate Haskell book? I haven't seen any updates since the last email they sent out last June.
Probably my last paragraph was a bit unclear. The problems I mentioned (compiler/verification and how to do concurrent datastructures) are very relevant in Haskell and not very different compsci. While the means vary, we are all solving the same problems! The only difference is that Haskell allows to express concepts more clearly and with a higher degree of formal verification due to types.
Benchmarks?
Since you are just starting, probably you need a good introduction and some basic usage. The first 2 chapters of the LYaHfGG book explain the basics to get you up and running: [http://learnyouahaskell.com/chapters](http://learnyouahaskell.com/chapters) ... this book is a good introductory resource.
Yes, this is the proposal: * https://github.com/ghc-proposals/ghc-proposals/pull/185
Pricey? Looks pretty cheap for a tech book 
u/saurabhnanda thoughts?
Don't know if you still need help with this but I was just doing a similar exercise and found it enlightening so I'm gonna write this out anyways. I'm only gonna talk about `fib2`, which I find more elegant and provides a good introduction to the `zipWith` function. The idea behind `fib` is pretty similar. &amp;#x200B; This is pretty straightforward once you understand what each of the functions mean. So these are both infinite lists of the Fibonacci sequence. Lists in Haskell are linked lists, which are a data type that where everything is either an empty list, or an object and a link to the next item in the list. `:` is the list constructor that takes in an object and a list and returns a list with the object added to the head. So `fib2` is being defined as a list that starts with 0, then 1, then the third element in the list is this function call to `zipWith`. `zipWith` is a pretty useful function that takes in a binary operator and two lists and returns one list resulting from applying the operator to pairs of elements from the lists, essentially "zipping" the two lists together with some function. In this case, the binary operator is addition `(+)`, and the two lists are `fib2` and `(tail fib2)`. `tail` is a function that returns everything but the first element, or "head", of a list . So `(tail fib2)` is just `fib2` but starting from the 1. Ok so that's what all the parts are. But how does this actually work? Here's where Haskell's laziness shines. Because everything in Haskell is computed lazily by default, Haskell won't actually compute anything until you ask for it, like when you print out results to screen. At that point it will compute any values it needs as it needs them. So it's perfectly fine to define part of a function in terms of itself or in some infinite data structure, as the rest of the values will be generated as needed. You can call `fib2` in GHCi and it will start printing numbers, but it will keep running forever until you manually kill it. To interact with infinite data structures, it helps to use things like `take`, a function which takes in a number *n* and a list and returns the first *n* items from the list. Ok so imagine we call `take 5 fib2`. GHCi will print `[0, 1, 1, 2, 3]`. The first 0 and 1 we manually entered, but how did it get the 1, 2, 3? `take` starts with the first item in the list, which is `0`. Easy. Ok, next item is `1`. No problem. Third item is `zipWith (+) fibs2 (tail fib2)`. Weird, but we can do this. `zipWith` is a function that returns a list, so we evaluate it to get the next item. The first item from `zipWith` is the first element of `fib2` plus the first element of `(tail fib2)`, which is just the second element of `fib2`. We already know the first is 0 and the second is 1, and that's all we need to calculate the third element of `fib2`, which is 0 + 1 = 1. However, we're not done yet! We want to `take 5`, but we've only got three so far. To get the fourth, you take the second item from `zipWith`, which is the second element of `fib2` plus the third element of `fib2` (second element of `(tail fib2)`). We just calculated the third element of `fib2` in the last step, which was 1, so we're all good to calculate 1 + 1 = 2. Finally, to get the fifth element, we add the third and fourth to get 1 + 2 = 3. At this point we've taken five, and hopefully you can see the pattern now as to how this generates an infinite Fibonacci sequence. &amp;#x200B; That's kinda a long explanation, but hopefully was helpful. Feel free to ask any clarifying questions. 
(servant co-author here) It does make sense IMO to focus on something more approachable than servant for such a book, where you're trying to reach the biggest audience in order to give them a good idea of what it's like to write a web application in Haskell in general. Beginner haskellers learning to use servant is not unheard of, far from that, but I'd definitely say most servant users are not beginners.
Yes I have. I enjoyed it a lot. Personally I found it fills a gap between basic getting started with fp in Haskell books and advanced topics. I had some issues starting to actually write applications in Haskell and this book helped me to clear up some things.
Yeah, I agree your opinion, and I think Servant can show the difference of webdev between other languages and Haskell.
IH is somewhat dead due to my borderline idiotic perfectionism where I end up fixing libraries and working on GHC instead of describing their quirks. Sorry. Also, this article is 100% Mark's writing which has not been approved for the book in terms of pedagogy, tone, etc., although it's got a lot of useful information. This is completely my fault but I got exhausted editing (rewriting) it and we agreed that Mark would publish it himself, it's his content that I failed to incorporare into the book.
If you have an internal GET endpoint that has adverse side effect and without auth, I think you got bigger issues than a configuration language that may load configuration from the internet (which can be checksumed!)
When you are at a command line prompt, one folder on your computer is called the "current directory". Just about every relative path you type inside the command prompt window - in ghci, in your text editor, anything else - is relative to the "current directory". When you first open the command prompt window, the "current directory" is your "home folder", whatever that means for your operating system (Windows, MacOs, Linux, whatever). To change to a different "current directory", use the \`cd\` command at the command prompt (type \`cd\`, a space, and the new directory, then hit enter). From inside ghci, you can do it without exiting ghci by using the command \`:cd\` instead of \`cd\`.
How does this work, exactly? My understanding of Haskell under Alpine is that you need to get a version of GHC that’s been build for that platform (presumably with support for musl instead of glibc). Since haskell.org doesn’t distribute these bindists, you’ll need to either `apk add ghc` (which only gets you 8.4.3) or bootstrap the compiler yourself. Even with the compiler though, `alpine:latest` on its own isn’t enough to run Haskell applications; at the very least you also need to instal `gmp` (unless you’re using a specially compiled version of GHC).
I [already gave you an answer](https://www.reddit.com/r/haskell/comments/atzlha/whats_the_quickest_way_to_generate_all_basen/eh4ipnl/?context=3) in your "at least k digits" post, it should be trivial to adapt it for the "at most k digits" case.
To resolve that point, I statically linked the dependencies. Otherwise this program won't work on Alpine Linux. FYI, the size of this container image is only 21.8MB. ``` $ docker images REPOSITORY TAG IMAGE ID CREATED SIZE examples-servant-examples latest 5c8a74945bf1 7 hours ago 21.8MB ```
I'm writing my master thesis right now. I'm using Nix for a few month right now and contributed a small bit to `home-manager`. I stumbled across NixOS because I like to read about haskell, but sadly never got into it as my "main tool" (and thus never got to learn it properly). But it heavily influenced my coding style in python and C. I'd argue that even if you do not get to use it as daily driver when developing, learn it to understand some concepts. It gets way more easy to reason about your code, even in other languages, in my opinion :) And to be honest: it is never too late to learn something. 
1. On average, if your company consists of more than 5 people you don't have any real control what is or isn't available on your intranet. Sometimes you have services running that were written 20 years ago by an intern who was just learning Perl, this stuff happens. 2. Intranet was just an example. Turns out, you're also pretty often connected to the internet. And nobody has any control about what's on the internet. 3. I don't know how often I'll have to repeat this, by the time you're doing a checksum it's too late. The dangerous part is executing the request, not the content of the config (which may not even exist). Maybe it's easier to understand if I put it in Haskell terms? What the Dhall interpreter is doing is, for all intents and purposes, `loadConfig x = checkResult (unsafePerformIO x)`
Ah, thanks! I should have checked the `package.yaml` first. It might be useful to note somewhere in the README that you’re statically linking `glibc` and `gmp`, for reference. You might find it interesting to check out `upx` (for compressing the executable) and the `split-objs`/`split-sections` flags for getting the image sizes down even further.
&gt;which has not been approved for the book in terms of pedagogy, tone, etc. It's Vlad's way of saying that the chapter actually sucks so badly he doesn't want to have anything to do with it :-P
I agree there should be a mode where dhall will not perform GET requests (though it may still satisfy includes from a side-effect-free local cache). I'm not sure it should be the default, but it should exist.
You might want a look at [this](https://gist.github.com/Elvecent/866d018a3e6140d001ef1d987b72c778) \- setting up Emacs for Haskell coding.
It does exist AFAICT, and as some others have said you could theoretically just use normalised configs everywhere... Thing is, if you're just normalising everything anyway and need to be super careful all the time you're not accidentally loading something with default settings... what's even the point? You know what else has an untrusted mode you can only run in sandboxes, and then produces configurations you can at least parse without causing arbitrary garbage to happen? Literally any program in any programming language that produces JSON output.
Maybe I don't buy enough tech books. I was comparing to my general cost of living, which might not be the best idea.
Thank you for your reply, I got the idea. 
&gt; Thing is, if you're just normalising everything anyway and need to be super careful all the time you're not accidentally loading something with default settings... what's even the point? I don't accept the premise. I can develop with all the features, and normalize in an area with specific levels of network access (somewhere in the CI chain), and ship "safe", normalized, ASCII versions to production. Even under the restrictions of your premise, dhall has a standard way of representing pure functions, which JSON and YAML are lacking. If all the calls to them are saturated, normalization will evaluate them, but that doesn't have to be the case.
Here's a way to do it that takes an arbitrary list as an alphabet rather than just using the numbers 0..4: -- Given an alphabet, return an infinite list where the nth element is the list of all strings of length n on that alphabet. strings :: [a] -&gt; [[[a]]] strings base = iterate (liftA2 (:) base) [[]] -- Given an alphabet and a length, return all strings on that alphabet that have at most that length. getDigits :: [a] -&gt; Int -&gt; [[a]] getDigits base max = concat $ take (max + 1) $ strings base
If you have a type representing your configuration, you can simply derive `Data.Aeson.FromJSON` (works with the `yaml` package too) for that type . You could also try Dhall, the corresponding class to derive would be `Dhall.Interpret`.
You don't have to use a generic "FromJSON" instance. Instead, create the idealized data structure you actually want, manually traverse the JSON and put the data into that shape. You can see this in Offset: https://github.com/positiondev/offset/blob/master/src/Web/Offset/Splices.hs#L97 `jsonToFill` just looks at what the Aeson constructor is for each field, but you could also look at the field name to figure out how to handle each part. So, your function could say, "if this is an object named 'SomeCommonKeys', then append the value to this list in my data structure". Or you could use "ID" and stick stuff in a specific index of an array. Happy to go into more detail if that doesn't make sense!
I'm wondering: what are the benefits of using EC2 instead of Elastic Beanstalk? I just used the latter to deploy a small website for the first time and found it a bit easier as you don't have to configure the instance(s), add storage or security groups etc.
Oh ye I think I see what you mean. I'm still not quite sure of what is possible with Aeson so wouldn't have thought of that... thanks so much! 
Why to use ec instances at all? If it is a static site you can host it through S3. 
Hey, I worked for a year with Jave + Eclipse before shifting to Haskell and don't worry, it will get better after a bit. The good thing is that the types are still there and the compiler messages, while initially tough to read, get much more readable and extremely helpful over time. DM me if you need any help with your setup or compiler messages. Maybe we can converse on slack or something. Good luck! 
I've been thinking about replacing my blog with straight Nix expressions; no static site generator involved. Nix is perfectly good for templating text files; the /etc directory in NixOS is based on this fact.
Fixed. Highlighting still doesn't work but that's being fixed as well.
would it be a good book for someone who knows haskell at some level, but not know "web programming" at all? 
Makes me think about generating one from Dhall somehow...
I believe if you set max-width on the images to 100% you won't run j to weird width issues on mobile. Currently everything runs off the page because the images are so wide.
Great example. thanks.
https://github.com/styx-static/styx
Oh sweet! I'll check that out :)
&gt; the compiler will happily fuse them with its existing machinery. Which machinery are you referring to? Both the inlining and the rewrite rules should apply equally well to code written in either style, no?
I receive posts to the mailing list like regular email, then `imapfilter` shunts them off to a folder so they're not filling my inbox. Then whenever I'm bored and not occupied with something else, I go read through any threads that look interesting, and replying to a thread is just replying to the email. I use `mu` and `mu4e` in Emacs, so it's easy to search for emails of interest, archived threads, etc., when getting the context on a discussion. I also recently pulled the entire archive of -cafe (at least back to October 2000, so I suppose there's a bit more to collect) and dumped it in a folder so I can keep it around for reference. I'm sure I'll never read it all (76,731 emails!), but it's fun to have.
`megaparsec` and `prettyprinter` have gotten a lot of work done for me, and I've already picked up a couple of nice improvements to my use of the former from skimming this. I'll have to digest this throughout the week. Thanks, Mark!
Aeson works by parsing JSON to an intermediate data structure called [Value](https://hackage.haskell.org/package/aeson-1.4.2.0/docs/Data-Aeson.html#t:Value), which is composed of HashMaps and Text and such—normal data types. You can pattern match on these to handle weird JSON like you're describing. I came up with something like this. Definitely a PITA; maybe someone else has better ideas? ``` {-# LANGUAGE TemplateHaskell #-} {-# LANGUAGE OverloadedStrings #-} import Prelude hiding (id) import Data.Aeson (withObject, FromJSON, (.:)) import Data.Aeson.TH (deriveFromJSON, defaultOptions, Options(..)) import qualified Data.Aeson as A import qualified Data.HashMap.Strict as HM import Data.Text (Text) import qualified Data.Text as T import qualified Data.Char as Char import Data.Traversable (for) data TheData = TheData { collection :: [CompleteItem] } deriving (Show) data CompleteItem = CompleteItem { id :: Text , key1 :: Text , key2 :: Integer } deriving (Show) data PartialItem = PartialItem { pkey1 :: Text , pkey2 :: Integer } $(deriveFromJSON defaultOptions { fieldLabelModifier = drop 1} ''PartialItem) partialToCompleteItem :: PartialItem -&gt; Text -&gt; CompleteItem partialToCompleteItem partial id = CompleteItem id (pkey1 partial) (pkey2 partial) -- Implement to check that IDs match some format if you want. isValidId :: Text -&gt; Bool isValidId _ = True instance FromJSON TheData where parseJSON = withObject "Collection" $ \o -&gt; do value &lt;- o .: "Collection" case value of A.Object hm -&gt; do let kvPairs = HM.toList hm listOfItems &lt;- for kvPairs $ \pair -&gt; do case pair of (idText, innerO@(A.Object _)) | isValidId idText -&gt; do partialItem &lt;- A.parseJSON innerO pure $ partialToCompleteItem partialItem idText _ -&gt; fail $ "Expected an a string key of idN and an Object, encountered: " ++ show pair pure $ TheData listOfItems _ -&gt; fail $ "Expected Collection to be an object; got: " ++ show value ``` For this JSON: ``` { "Collection": { "ID0": { "key1": "Some data1", "key2": 1 }, "ID1": { "key1": "Some other data1", "key2": 2 } } } ```
That is... fascinating. Unfortunate that there's [another styx](https://github.com/jyp/styx), though. I'll definitely have to look into this, though. Could be a fun thing to mess around with.
To be honest for a case like this (static files) I would go the other direction and use CloudFront. It's simple to set up, manages certificates just as simply as LetsEncrypt, and you don't need to maintain or patch any servers or worry about network outages like you would with a single EC2 instance.
Thank you!
Dude thank you so much. I'm busy studying right now but I'll hit u up if i need the help means a lot man. 
Dude this is actually what was a program for me for a long time. I figured it out but thank you for the indepth explanation you are awesome.
Thank you I am reading this along with some tutorials hopefully i get it down soon.
No. In the introduction, it said "You also need to have basic knowledge of Haskell. You should be familiar with the syntax and basic typeclasses like Applicative, Functor, and Monad. You should also know about Monad Transformer or mtl, like MonadReader. If you are unable to understand what the following code snippet does, then you might have a slight difficulty following along. " ```haskell hello :: (MonadReader String m, MonadIO m) =&gt; m () hello = do name &lt;- ask liftIO $ putStrLn $ "Hello, " &lt;&gt; name &lt;&gt; "!" newtype AppT a = AppT { unAppT :: ReaderT String IO a } deriving (Applicative, Functor, Monad, MonadReader String, MonadIO) main :: IO () main = flip runReaderT "World" $ unAppT hello ``` But you have another choice, "[Haskell in Depth](https://www.manning.com/books/haskell-in-depth)" 
that's what I'm doing. do you have any tips? (nix obviously has a great package manager in `nix`, but not many "libraries" pwr se, as far as I know, for stuff like that.)
Nothing in particular no, considering I haven't done it yet :P Most important general piece of advice I can give for Nix is: When things start getting large and complicated, learn to use `evalModules`. It's probably the best piece of Nix infrastructure out there, and I'd kill for a more properly typed equivalent (probably possible with that new Expresso language?)
thanks!
The [Waargonaut](https://hackage.haskell.org/package/waargonaut-0.6.0.0/docs/Waargonaut.html) package provides a "cursor" that you can use to move around and slice up weird JSON. There is a test example [here](https://github.com/qfpl/waargonaut/blob/master/test/Decoder.hs#L234) that takes an input JSON "array", and slices off individual elements as well as consumes the remainder of the list. You could define a `Decoder` for the smaller elements and then use the `foldCursor` function to repeatedly move in a specific way over your JSON input. Collecting each individual element as you go. I did something similar and I'll try to dig up the code for it.
I wanted to decode [this input](https://github.com/mankyKitty/hedgehog-webdriver/blob/master/protocol/webdriver.json), which is an "object" but I wanted to pull apart into a list. So I wrote smaller decoders for the similar bits, like [this one](https://github.com/mankyKitty/hedgehog-webdriver/blob/master/src/Protocol/Webdriver/Generate.hs#L164) and [this one](https://github.com/mankyKitty/hedgehog-webdriver/blob/master/src/Protocol/Webdriver/Generate.hs#L171). Then I could use [`foldCursor`](https://hackage.haskell.org/package/waargonaut-0.6.0.0/docs/Waargonaut-Decode.html#v:foldCursor) to combine those decoders with a "cursor" movement [like so](https://github.com/mankyKitty/hedgehog-webdriver/blob/master/src/Protocol/Webdriver/Generate.hs#L231), the decoder would then try to decode one of my components, add that to a list if it was successful, then move to the next one. Repeating until it reached the end of the structure. So for your input, depending on if you need the keys or not, you could have a `Decoder` like so: ```haskell data Item = Item { _lbl :: Text , _key1 :: Text , _key2 :: Int } itemDecoder :: Monad f =&gt; Decoder f Item itemDecoder = withCursor $ \c -&gt; do lbl &lt;- focus text c key1 &lt;- atKey "key1" text c key2 &lt;- atKey "key2" int c pure $ Item lbl key1 key2 collectionDecoder :: Monad f =&gt; Decoder f [Item] collectionDecoder = withCursor $ \c -&gt; do inCollection &lt;- down c foldCursor (flip cons) (D.moveRightN (Nat.successor' (Nat.successor' Nat.zero'))) mempty itemDecoder ``` If you want some more help we can try to bash out something more tested, I just threw this together. Hope it helps! :)
Purely functional languages do side effects all the time (forcing thunks and updating them). Granted that this is for efficiency reasons but one cannot decouple real world issues like efficiency and side channels the moment you are going to work of security. &amp;#x200B; So I would not say that moving to a purely functional processor (we do not yet know how that is going to work) is going to magically solve our security problems. In many ways it is like parallelism. We know that purely functional code can expose parallelism but it is not going to solve our parallelism problem magically.
Hmm, I guess you are right that purely functional languages actually do preform (minor) side effects when they are executed. However, purely functional program still can not detect timing. That's because the side effects they preform have no affect on their behavior, so they can not exploit thunk behavior to generate timing data. So an attacker with physical access could still use physical measurements to access the side channels, but the programs themselves could not access the side channels, which was the problem raised by Spectre (as far as I know).
The only purely functional program is one that you don’t run. What you’re suggesting is effectively a CPU that does not allow any hardware access (which is how you get environment values such as time, core temperature, fan speeds, etc). On the flipside you also won’t be able to set pixels on a display or play sounds on the speakers.
I think [dante](https://github.com/jyp/dante) has that feature.
Complete newbie here, how is NixOS related to Haskell?
EB is basically "app deployment as a service"; so it will spin up your application with multiple instances across availability zones, load balancing + auto scaling + probably other stuff I've forgot. EC2 is basically just a server and nothing else; if you want the other features of EB you'll have to set it up yourself. I guess it's the age-old trade-off: Using a service means you don't _have_ to care about everything (which is nice), but also means you don't _get_ to care about everything (which sometimes isn't).
It would require `Functor`, `Applicative` constraints
Why do you use OpenCL, rather than OpenGL or Vulkan? And does rendering via OpenCL mean that the images have to go via the CPU back to the graphics card to be displayed?
The \[intellij-haskell\]([https://github.com/rikvdkleij/intellij-haskell](https://github.com/rikvdkleij/intellij-haskell)) plugin offers that.
It seems to me like there are a couple of ways you can solve this. If you're interested in getting a list of records, you will need some manual massaging in your instances as the other comments describe(though it is beginning to seem like wargonaut might be easier to use for gnarly APIs). However, I think creating a newtype for your IDx keys with proper parsing logic to pull out the integers combined with an instance for `FromJSONKey` for that type will essentially give you a free instance for the type `data InnerRecord = .. newtype KeyType = KeyType { idNo :: Int } instance FromJSONKey KeyType where .. data TopRecord = TopRecord { collection :: M.Map KeyType InnerRecord }`
Nix (the package manager) / NixOS (The distribution using nix as package manager) have the goal of deterministic and reproducible system configuration. Basically the "pure and functional" aspects translated to the operating system. Thus, many Haskell developers who prefer such properties tend to use NixOS (as far as I have noticed, this might be biased). Also, nix uses a domain specific language to configure the system and describe packages. This one shares many properties like lazyness and it is very composable. Nix also has `cabal2nix` and can translate the dependencies to the packaging system of nix, which eases the integration into the nix ecosystem.
I rolled my own one-line implementation for this which uses a vim rg/ag/ack plugin: ``` nnoremap &lt;leader&gt;h :exec 'Ag -w --'.Fixc(&amp;filetype) shellescape(expand('&lt;cword&gt;'))&lt;CR&gt; ``` Basically I type `,h` when the cursor is on the word that I want to find uses of, and this runs `:Ag -w --haskell &lt;word&gt;` and lists results.
&gt; Why do you use OpenCL, rather than OpenGL or Vulkan? I don't think OpenGL or Vulkan have general enough compute capacity to do this. I chose OpenCL because it currently has the widest deployment. &gt; And does rendering via OpenCL mean that the images have to go via the CPU back to the graphics card to be displayed? There is the CL/GL interoperability that could prevent this. So far I have implemented this functionality but couldn't get it working. (Probably because I'm on a Mac.) The source files Interface.DrawTarget and Interface.InterfaceSDL are where this functionality happens. You can see there are two types of DrawTarget: HostBitmapTarget for transfer back to the CPU and GLTextureTarget for keeping it on the GPU. Unfortunately OpenGL is weirdly stateful and somewhat of a dark art. I was getting just a black output so I have just been using host bitmap so far. There is supposed to be OpenCL-Vulkan interoperability soon but that whole API is sort of up in the air right now. As for Metal, I'd love for someone to help me understand what Apple's plan for GPU-compute is. The state of cross platform GPU support is looking fairly bad right now thanks in large part to Apple, NVidia and other vendors no playing nicely together. But I think most of the work I've done here is pretty easy to transfer between various flavors of C, so I'm open to whatever platform is going to give the widest deployment. My whole goal has been to make it so that writing Haskell programs with rich vector outputs is easy and transparent.
Although I want to use haskell for everything, I think I will learn R or pandas as a substitute for spreadsheet capabilities offered by microsoft excel or libreoffice calc. For a quick exploration of a small dataset, examples on http://acowley.github.io/Frames/ look cumbersome.
Yes; I understand this. My question was more along the lines of: &gt; For such a simple website, what are the advantages of the extra flexibility which EC2 gives you? Surely it would be easier to simply deploy it on EB and let Amazon take care of all the other details?
Works for Desktops currently. Not supported for mobile-web
Complete newbie here, how is Nix or NixOS related to Haskell?
nice! could you share the code? :)
source code: https://github.com/abiduzz420/cis194/blob/master/sokoban.hs If any experienced Haskell developer can go through my code and provide feedback to help write idiomatic Haskell code, it would mean a lot to me :)
This is interesting. Will definitely check out this OS and the "functional, laziness and pure" aspects as part of OS reading. Thank you!
If you have any question (the learning curve can be a bit strange sometimes), ask on /r/NixOS or just come to the IRC (#nixos@freenode). The people there have always been very friendly and helpful.
Try [CodeWorld](https://code.world/haskell#): Haskell in browser I'm a Haskell newbie too. One of the things that's frustrating when moving to a new language is editor tooling. It's very difficult to figure out quickly what works best for you. When learning a new language, our focus should be on getting hands dirty with the language. I have wasted several hours trying to set-up my dev environment when starting with Clojure. Thankfully there's CodeWorld for beginners which allows you to run Haskell programs in the browser. I don't like installing plugins and modes on Day 1. But that's just me :)
Sure thank you very much for being kind :)
[...It appears that I might have an IQ of 5.](https://i.imgur.com/8ZdfYlC.png)
Next little project you could do is write a grammar for your levels and use monadic parsing to load them on the go instead hard coding them ! :)
Oh yeah nice. I haven't come across monadic parsing yet but yeah I am quite interested in doing compiler stuff using Haskell. Will try it out. thank you for going through the code!
Well put, though I guess it's possible to differentiate types of hardware access. Isn't spectre largely a concern when it comes to shared hardware on servers? Is it possible for providers to restrict hardware access in this way? (although this is orthogonal to designing a "functional" processor)
Cool - but how do I get back to level 5? I don't want to do them all again :(
I have also worked on the 'faster coroutine pipelines' encoding, my current code is [here](https://github.com/rubenpieters/Orthogonal-Pipes). Which extended the encoding to bidirectional pipes (as in the `pipes` library). We published this at PADL this year, the extended version is [here](http://www.cs.kuleuven.ac.be/publicaties/rapporten/cw/CW715.pdf). I also am doing some extra benchmarks compared to Spivey, I am implementing a use case similar to [this](https://github.com/yahoo/streaming-benchmarks). And even though the encoding performs worse for micro-benchmarks on some operations such as `map`, it still performs better overall in the yahoo benchmark. But these are still preliminary results.
Since there is a [real risk of Travis going down the tubes](https://www.reddit.com/r/devops/comments/at3oyq/it_looks_like_ibera_is_gutting_travis_ci_just_a/), does anyone know of a similar Haskell-oriented guide for other CI providers? Apart from some reliability issues, I haven't really had problems with Travis so far, but I think it's better to prepare a move now, than when it becomes urgent.
Can you share your derivation? It's likely that you just need to add `buildInputs = [ zlib ];` or similar to make it work.
damn, thanks for the warning. i hate the constant "acquire and destroy". I'm working on a project scaffolding tool, and I want to include a somewhat community-accepted continuous integration config file in new projects by default. Travis was that. Now I have to find a new CI service if I'm going to be implicitly recommending it to users. (p.s. I actually interviewed at a Haskell startup that was acquired not long afterwards. its product (afaik) was not only kept closed-source, but eliminated.)
I'm working on the `summoner` tool for scaffolding Haskell projects: * https://github.com/kowainik/summoner My blog post uses Travis CI config generated by the tool and explains design decisions behind it. Travis is quite simple and was pretty good so far. It's sad to hear about the situation... On my work we're using Circle CI for building Haskell projects. But, AFAIK, Circle CI might be not the best choice for open-source since they have limited free support.
As a person who just went through the tutorial, there was a case where the \\\\ operator unicode counterpart is not printable in my brower's chosen font, so I had to just copy and paste it to see how it worked. It is friction that doesn't need to be there. If I weren't already a haskeller I would have stopped right there. &amp;#x200B; However I definitely see how dhall could be useful to me for generating swagger / openapi definitions and ansible playbooks, so I definitely hope the edges are ironed out eventually.
You probably misunderstood me. I mean if you know haskell, but not "web programming". I have no problem with monad transformer or what not, but I am total noob in web development. The only thing I know is a tiny bit of HTML and css, to be able to modify static HTML/css templates. 
How hands on did you find the book? I've seen a lot of practical books talk for pages only to have a small, cobbled together example program at the end. It would be great to see a book that actually walks through building something and explains theory along the way. 
Haskell's implementation of laziness does a ton of relative jumps so it is actually significantly more vulnerable to specter. 
Here's a solution for Appveyor and CircleCI: [packcheck](https://github.com/composewell/packcheck/blob/master/README.md).
Inline and rewrite rules will fire, sure, but different ones! The compiler already has lots of machinery for dealing with function composition---but none for dealing with an arbitrary initial algebra.
I haven't used this workflow, but it seems that your project's root directory is *not* mounted `nodev`, so the unix domain socket nicely communicates out of the container.
If you are using Emacs, then I recommend "dumb-jump" [1]. In particular `dumb-jump-quick-look` which provides what you are looking for. I also use `ripgrep` on the command-line like this: rg -t haskell -p &lt;FUNCTION_NAME&gt; [1] https://github.com/jacktasia/dumb-jump
I don't think that's what they're looking for? They want to find places where a function is used, dumb-jump seems to be about finding definitions.
[Haskell IDE engine](https://github.com/haskell/haskell-ide-engine#installation-on-macos) supprts that, and it’s wirking really fine for me.
That is not true, I pointed out `dumb-jump-quicklook` because it shows definitions and usages. Please update your comment.
I just `ripgrep`. `rg myFunction --type Haskell`
This is the `shell.nix` file I'm using: { pkgs ? import &lt;nixpkgs&gt; {} }: with pkgs; stdenv.mkDerivation { name = "hn-terminal"; buildInputs = [ pkgconfig zlib ]; shellHook = '' #export NIX_PATH="nixpkgs=${toString &lt;nixpkgs&gt;}" #export LD_LIBRARY_PATH="${libvirt}/lib:$LD_LIBRARY_PATH" ''; } Here is the (code)[https://github.com/argent0/hn-terminal] just in case.
thanks!
Yes, here is the [code](https://github.com/argent0/hn-terminal). The problem seems to arise when linking.
yeah apparently, it resets the game. I will write the logic for it in a day or two. I just need to reset to the same level when `Esc` is pressed instead of level 1
Seconded, this looks like an excellent resource
Bad news. It would be good to know why. May be worth a ticket on GHC's Trac.
What about https://docs.haskellstack.org/en/stable/travis_ci/ ?
&gt; Stack does not work. Very mature. I rest my case...
&gt; Rarely do I have Haskell problems these days, instead I have stack problems. I don't think it's fair to claim that Stack doesn't work just because of some minor inconvenience you ran into which is probably easy to resolve. Or see it this way: If Stack didn't work why would the vast majority of applied users would prefer Stack over cabal?
I'm thinking a lazy trie or something like that.
``` import Text.Regex.Base (makeRegex, match) import Text.Regex.TDFA (Regex) match (makeRegex @Regex ".{3}") "foobar" :: [[String]] [["foo"], ["bar"]] ```
lol, you can undo the game state by pressing "u"
[Haskell Code Explorer](https://github.com/alexwl/haskell-code-explorer) supports this.
flyby while I'm walking out the door - `mapList`: it'd more idiomatic to define a `Functor` instance for `List`, and even more idiomatic to just reuse the existing `[a]` type for lists. 
`showIntAtBase 5 &lt;$&gt; [0..5^24-1]`
If you do useful work, there are always side-channels. There are several variants of spectre and meltdown which require different levels of access to a machine. But, roughly, it goes like this: - if you can control (just speculatively) which array indices are loaded, - and you can estimate even roughly how fast any part of your code is running - then you can exfiltrate arbitrary data from anywhere in memory, regardless of protection Examples: - a server that receives requests to run a script, and then runs that script (if the scripting language is sufficiently expressive, even if it's deliberately sandboxed in every possible way, there will almost certainly be ways to apply Spectre). The caller (over the network) can time how long requests take, even if the scripting language doesn't include timers. - the client loads JS from a third-party, and runs it on the client's computer. JS is heavily sandboxed; but Spectre can still get through this sandboxing, even with low-accuracy timers. By talking to the third-party server again (which is something that JS needs to be able to do to load dynamic content) you can obtain (low-accuracy) timers, again making exfiltration possible. The only way that a computer isn't vulnerable is if a potential attacker can't communicate *at all* with the outside world during their provided computation, *and* they can only run one computation ever (before memory is completely manually wiped), *and* the attacker isn't given any diagnostic information about the performance of their code [except possibly very coarse-grained measurements, like total runtime]. The solution is almost certainly a new way to protect memory (e.g. if you have "secure memory" that's never cached but therefore very slow to access and "main memory" which is effectively unprotected as far as reads go) or some other architectural change at the CPU level. A new language won't cut it.
Sidenote?
Sometimes I feel like a broken record, but, don't do this: "Salary is dependent on your experience. Stock options and other benefits as well.". Give \_actual\_ ranges. You're hiring at different experiences; fine, give different ranges. It doesn't take that much effort (I certainly hope any functioning business has done some analysis of what they can afford before hiring...). Seeing: Junior: £20K-30K; Mid: £30K-40K; Senior: £50K-60K Is \_very\_ different than seeing: Junior: £30K-50K; Mid: £50K-70K; Senior: £70K-100K &amp;#x200B; Asking someone to go through 5hrs of interview + an onsite visit (figure, a few days off work) before finding out that basic information is really just disrespectful of your potential future colleague! 
Well, I found it to be quite hands on. The whole book basically builds one project. I had a quite good understanding of the language. For me at the time I read it it was what I was looking. For. I.e just a shortcut to building a web app by seeing someone’s opinion on how to glue together basic libraries into a web app. I didn’t want to research a bunch of web framework sql access libs and so on. This it did provide.
&gt; unsafeCheckEqual _ _ = NotSure 
That doesn't even compile for me. &amp;#x200B; Fastest I was able to come up with is: &amp;#x200B; `import Text.Regex.PCRE` `import Data.List` `import System.Environment` `import qualified Data.ByteString` &amp;#x200B; `msk :: Data.ByteString.ByteString -&gt; AllTextMatches [] Data.ByteString.ByteString` `msk a = a =~ "A:\"([^\"+])"` &amp;#x200B; `main :: IO()` `main = do` `args &lt;- getArgs` `file &lt;- Data.ByteString.readFile "text3.txt"` `let list = getAllTextMatches $ msk file` `let quantities = Data.List.length list` `print quantities` This requires twice as much time as: `#!/bin/python3` `import sys` `import re` `def extract_obj(string):` `a=0` `for match in re.finditer("A:\"([^\"+])",string):` `a = a + 1` `return a` &amp;#x200B; `def main():` `with open(sys.argv[1],'r') as f:` `text =` [`f.read`](https://f.read)`()` `print (extract_obj(text))` &amp;#x200B; `main()` Both scripts count the occurrence of a string in a long document. That is an endless list of: `A:"1234"A:"1234"A:"1234"A:"1234"A:"1234"A:"1234"A:"1234"A:"1234"A:"1234"A:"1234"A:"1234"`
Enable TypeApplications and make sure you have the libraries installed. Saying “that doesn’t compile for me” is pretty useless btw. What I posted should be plenty fast. 
Superficially, nothing. You can use Nix to package software in any language or even many languages in one project, e.g. some higher level language with properly specified C dependencies. However, there is a lot of cross over between Haskell and Nix so in practice they are often seen together.
Fair enough. I looked at the readme for that function and it didn't sound relevant, but from a glance at the code it looks like it would be.
This looks awesome! Definitely gonna read through your paper and the code sometime this week. Have you done any comparison to Streamly? I usually see people compare to pipes and conduit (make sense, given their popularity) but Streamly has a really nice set of [benchmarks](https://github.com/composewell/streaming-benchmarks) and it looks pretty elegant as well as performant compared to pipes/conduit so it'd be interesting to see how the continuation based implementations hold up.
Sorry， I really misunderstood you. "The intended audience of this book is people who have basic knowledge of web development. You should know how HTTP works. For example, HTTP request, HTTP response, headers, cookies, etc. You also need to know a little bit about HTML, CSS, and Javascript. ", enjoy the book.
I like how you can undo past the beginning of a level into a previous level.
Minor inconveniences add up, see the stubbornness regarding `stack uninstall`. I get enough stack problems that frankly, I don't need more. And I never said that Stack was worse than Cabal, or did not work: merely, Stack is less clear (DWIM), significantly less so, than Haskell. 
Can you elaborate? From what I see this is Stack specific but the post describes the configuration for both tools, and it requires much less boilerplate.
Thanks for putting this on my radar, I might be able to pitch in. Slightly related, but I've been messing around with Haskell-related designs. I tried posting some of them here once upon a time, but they were mysteriously deleted, so I wasn't sure if it was appropriate. Maybe they're germane to this, so I might as well try again: * [A revision of the logo](https://heavyindustri.es/img/haskell/logo-revision-s1.png), which, by the way, I love. It's my absolute favorite programming language logo, but I've always felt its angles and coloring were just a *little* off, so I massaged them. * [The same, but purple](https://heavyindustri.es/img/haskell/logo-purple-s1.png). * [And with more color](https://heavyindustri.es/img/haskell/logo-colorful-s1.png)! * [A cheeky retro-styled poster featuring Mr. Peyton Jones](https://heavyindustri.es/img/haskell/poster-s1.png) 
3rd image seems very Kotlish
Is there a function in any standard library that's defined as either `if null x then y else x` or `if null x then [y] else x`, or something equivalent to one of those?
If you were to hoogle Coroutine, then follow the links to the [very beginnings](https://hub.darcs.net/blamario/SCC/patch/f5adae9d1ae0c867fdc64423aa82be182624e72d) of my [monad-coroutine](https://hackage.haskell.org/package/monad-coroutine) package, you would find very similar experiments. Eventually and very slowly I re-discovered free monads, used them to reorganize the library, and wrote [an article](https://themonadreader.wordpress.com/2011/10/26/issue-19/) about the design. I hope you find it useful. These days, I'd recommend you start with the [free](https://hackage.haskell.org/package/free) package. If you're only going to organize coroutines into pipelines, there are many alternatives to choose from: pipes, conduits, streaming... I'm not keeping up any more. 
I'm not very familiar with mount options. If the project root were mounted `nodev` would that prevent a unix socket from being interpreted?
I think the `Alternative` instance for `ZipList` does this. &gt; ZipList [] &lt;|&gt; ZipList [] ZipList {getZipList = []} &gt; ZipList [1] &lt;|&gt; ZipList [] ZipList {getZipList = [1]} &gt; ZipList [1,2,3] &lt;|&gt; ZipList [] ZipList {getZipList = [1,2,3]} &gt; ZipList [] &lt;|&gt; ZipList [4] ZipList {getZipList = [4]} &gt; ZipList [1] &lt;|&gt; ZipList [4] ZipList {getZipList = [1]} &gt; ZipList [1,2,3] &lt;|&gt; ZipList [4] ZipList {getZipList = [1,2,3]} &gt; ZipList [] &lt;|&gt; ZipList [4,5,6] ZipList {getZipList = [4,5,6]} &gt; ZipList [1] &lt;|&gt; ZipList [4,5,6] ZipList {getZipList = [1,5,6]} &gt; ZipList [1,2,3] &lt;|&gt; ZipList [4,5,6] ZipList {getZipList = [1,2,3]}
`pipes` is directly inspired by your article, so thanks! :)
[removed]
As others have already mentioned, the `dhall` package can be built with remote import resolution disabled. I believe that point alone addresses your concern
You can compile the `dhall` package to remove support HTTP requests by setting the `with-http` cabal configure flag to `false`
I wouldn't go so far as to say the feedback is conclusive that `--ascii` should be the default. Only three respondents complained about Unicode and two of them specifically clarified that the issue was the use of Unicode in documentation examples. Only one person flat out said that Unicode was bad without qualification. And this is three people out of a survey with 61 respondents. You also have to factor in that due to the way the survey is structured there is a strong sampling bias towards people who dislike Unicode. People who like Unicode aren't going to affirm its use when answering the survey. This is why you don't see anybody say "Keep up the Unicode, please!" because the survey never prompted anybody to affirm anything about the existing approach of the language. To properly settle the question of which output should be the default you'd need to poll both sides to see which format people prefer. That said, my intuition is that more people would probably prefer ASCII as Dhall grows more mainstream, but I don't think the survey feedback is strong evidence for that point.
This is also the case for `dhall`, too. You can point any `dhall` interpreter to a pre-seeded cache using the `XDG_CACHE_HOME` environment variable, and the hash attached to the import is the lookup key in that cache. In fact, you can even attach a hash to a `missing` to retrieve something from the cache and it will resolve correctly: ``` missing sha256:${HASH} -- Resolves to "${XDG_CACHE_HOME}/dhall/${HASH}" ``` This means that you can distribute a cache with a `dhall` expression. However, as others have pointed out, this is completely unnecessary because you can pre-normalize a Dhall expression before you distribute it, which is much simpler since the normalized form is import-free.
If your threat model is: "Somebody at my company might author an HTTP request against a dangerous intranet endpoint" ... then using Dhall to configure your program doesn't make you any more insecure. Presumably the host program that loaded the Dhall configuration file was written in a language with the ability to make HTTP requests (such as Haskell). Nothing prevents your developers from authoring those same unsafe HTTP requests within the host program written in a general-purpose programming language. If anything, Dhall is more secure in that it restricts the set of allowed HTTP requests compared to a general-purpose programming language.
I think this is slightly different. Your stuff seems to be about new monads specifically for coroutines, is that correct? I'm interested in doing coroutines directly in the IO monad (and possibly in ReaderT, StateT, etc. over IO).
Ohkay that makes sense. Thank you for your thoughts :)
Ohkay interesting thank you!!! I haven't read about Functors hence I am unaware but I will add a todo comment for it. 
\*feeling embarrassed\* Will fix it soon
(the author replied, and content caching is indeed relevant, as is normalization.)
/u/agnishom thanks for the ping. The chapters on the book seem to be covering the right material. Although, I'm not sure about the content of each chapter going by just the preview. For example: - The chapter on configuration talks only about environment variables. I would probably go with config files instead. - Logging talks only about Katip. `fast-logger` + `monad-logger` is my preferred choice, but Katip is also good. - Scotty for REST APIs seems too basic to me. 
Answering some questions. No, you don't need a PhD for doing Haskell, certainly. Most professional Haskellers don't. I think that most people know Haskell later, after being familiar with other languages before.
Nice writing! I used `intellij-haskell` plugin when I was starting with Haskell as I was comfortable with IDEA already. But, in my experience, it started hanging on medium-size projects (it was almost two years ago though, not sure about the current situation), so I moved to Spacemacs.
Cool. Thanks for your opinion. I will go through this sometime.
Yes, comparing to Streamly is a good idea. Though, I'm still trying to figure out how to correctly adapt the primes benchmark, since the api is a bit different from pipes / conduit.
&gt; it's self hosted and open source … I'm glad that was considered. I tend to avoid closed source forum software, to be honest, I just don't see the point of it especially when there are so many good alternatives.
&gt; From what I see this is Stack specific but the post describes the configuration for both tools You should read more closely &gt; The complex Travis configuration is intended for projects that need to support multiple GHC versions and multiple OSes, such as open source libraries to be released to Hackage. It tests against cabal-install, as well as Stack on Linux and macOS. The configuration is significantly more involved to allow for all of this branching behavior.
This looks like a great book and gets everything right from the start. This book has one of the best [Getting Started](https://page-one.live.cf.public.springer.com/chapter/10.1007/978-1-4842-3739-7_1/lookinside/000.png) intros I've seen giving easy to follow clear instructions "The easiest way to get started developing Haskell is by using `stack`" and quickly steering the reader away from `cabal` to avoid the common tooling confusion Haskell newcomers face. The book keeps up with this style and sticks to practical recommendations and promoting best practices such as using `hpack` ("Since there are some downsides to `cabal`, we use another tool, `hpack`, to manage the build configuration") or using `ClassyPrelude` ("However, the default prelude has some downsides." which ClassyPrelude fixes) while avoiding astronaut tech like Servant or lens ("`lens` is a well-known library in Haskell for doing data structure manipulation. However, if you are not familiar with it, you might find it a bit daunting"). 
If you want people to pay attention to one particular sentence, you should write more explicitly. The link you are referring to still doesn't give any explanations about `cabal` part, only `stack` specific moments are highlighted, so it's not completely fair to say that this Reddit post doesn't give any new information. And as I already mentioned the configuration in this post is still much easier. It doesn't require you to install manually a lot of stuff which is already provided by the CI environment. Moreover, it uses the `cabal new` commands which are reflecting the actual state of the project in terms of `cabal` (the one that (I think) you are speaking about does not).
It is increasingly frustrating to me that all these tools are transitioning to stack. There seems to be no concern or interest for supporting cabal anymore, and it's meant that the code I work with every day is unusable in pretty much any IDE/editor environment. Not every project uses stack, in some cases because they can't. I work with a million lines of production Haskell running on cabal-new because we have dependencies that are not easily configured in Stack anymore, and apparently this means I get to code like it's 1994 and I should feel lucky to even have syntax highlighting.
&gt; It is increasingly frustrating to me that all these tools are transitioning to stack. Don't be frustrated. This was bound to happen at some point. The ecosystem will converge to support one single tool and support for the other tool will fade away. I believe this is a good thing as it lets the community focus their energy on improving one single tool to become the best in class and we can all rejoice. &gt; we have dependencies that are not easily configured in Stack anymore Can you elaborate? Maybe there's something we can improve in Stack so you don't need to use cabal anymore and everybody benefits.
&gt; it's not completely fair to say that this Reddit post doesn't give any new information You're putting words in my mouth. Where did I claim that your post didn't provide any new information? 
I like the old one better, honestly. 
They have will to, but they don't.
Maybe the \`Haskell Language Server\` plugin for Visual Studio Code works for you? If I recall correctly, it should also work with cabal.
That poster is so cool. 
I thought it was neat, a super-undo. It may not have been intentional, but that doesn't mean it was bad.
I'm a novice Haskell learner. I'm currently going through Haskell Book and learned Trifecta parser library. It was very easy to learn and easy to write parsers for all kinds of texts. Error messages are so good. Give it a try. http://hackage.haskell.org/package/trifecta
Nope. -1 from me. Whatever the issue is. F#, nor Haskell are proper psychological therapies. Go see the psychologist. Talk about disinterest in work, diminished selfimportance, and despair.
agree. see a therapist or talk to someone, talk to hr or quit your job, etc. 
agree. see a therapist, talk to hr or quit your job, etc.
https://imgur.com/a/f2ktG9N It make my computer's fan yelling... 
A tool is a measly thing to worship.
What can a psychologist do if the you find the best practices in your industry failing you? I mean, wasn't that the source of their despair..?
It's \[Idera\]([https://www.ideracorp.com/](https://www.ideracorp.com/)), not "ibera". Travis CI is still featured prominently in their portfolio of testing tools. At least so far, it looks like the firing of lots of tech staff is swallowing the product into their existing org, not like they are shutting it down. But we'll see. And even if I am right, the free service for github projects might still be at risk.
How you dare to compare? Haskell is the true religion! Seriously: You were too centered in your work too bad. Now you are a hobbyst. That is very good. you mare experimenting the joy of doing something well. A cult to wathever language, like Haskell, or F# is something more obscure and pathological.
Oh no! I've been using Travis for most of my FOSS projects for years! :(
Great piece of writing. This is how Joseph K. would experience his absurd life if Kafka were to be born in our modern times. Yes, it's true, the moment you write code in any of the mainstream languages, you find yourself totally inside the crazy world of the "Symbolic Order". For Haskell is still a sane world, thou I don't know if it will remain so, Haskell is not immune I'm afraid 
though this does not belong to this sub-reddit : i gave a +1 for you; because you are passionate, respect your profession, seek for doing it right instead of sinking in [the swamp that software industry is today](https://libeako.github.io/c/ID_311875598.html) the story happened with me too, i also burned out, and functional programming held me; then i found haskell and lot of other things; i wrote a [book](https://libeako.github.io/c/ID_1371518733.html) about this journey to attract fellow coders out of the industry swamp &amp;#x200B; be happy with f# and when you eventually become bored with it then remember that functional programming is only a first step; learn haskell to drop you jaw 
Thanks! I seem to recall that when I originally found that picture of SPJ it was licensed for reuse with modification, but now I'm struggling to find evidence to support this. I suppose one would have to speak with the picture's copyright holder, John Peterson. Beyond that, I'm happy to release any Haskell-related designs under whatever the most liberal licensing is appropriate. If anyone has recommendations on that front, I'm all ears. I imagine some CC license would suffice. That is to say, if you or anyone else here like the poster, I have no reservations about how it's used in any case.
Aren't you still vulnerable to XSRF-like attacks, especially things attacking GET pages on an intranet? I \*suppose\* the checksum of imports is computed after they are reduced to normal form, so if that import changes and targets an URL in my intranet, it will be accessed before the checksum is validated, right?
The learning curve of NixOS is big and there aren't a lot of good material to learn it.
Is it the logotype you prefer, the symbol, or both? (On the first image, I mean; the following two are just one-off designs that I'm not pushing in any way.) I'm sure it goes without saying that I prefer the revised version as a whole, but the symbol in particular is what I set out to refashion. My rationale: I much prefer the slightly wider stroke width and more "upright" feel of the angles. It's closer to the weight of the text, so it feels a little more cohesive, and the slight bumps in saturation and hue brighten it a little. I realize design preference is mostly an emotional reaction, so it's a little silly to try to convince people with an explanation, but I figured I'd put it out there. (Also, I appreciate the feedback!) And as for the poster, I personally have no reservations about how it is reused, but see [this comment](https://www.reddit.com/r/haskell/comments/aur7hz/help_wanted_on_haskell_wiki_skin/ehbi7lc/) about the photographer. That probably doesn't clear things up, but I can try to get in touch with him and release it under CC.
Is it the logotype you prefer, the symbol, or both? (On the first image, I mean; the following two are just one-off designs that I'm not pushing in any way.) I'm sure it goes without saying that I prefer the revised version as a whole, but the symbol in particular is what I set out to refashion. My rationale: I much prefer the slightly wider stroke width and more "upright" feel of the angles. It's closer to the weight of the text, so it feels a little more cohesive, and the slight bumps in saturation and hue brighten it a little. I realize design preference is mostly an emotional reaction, so it's a little silly to try to convince people with an explanation, but I figured I'd throw it out there. (Also, I appreciate the feedback!) And as for the poster: thanks for the kind words. I personally have no reservations about how it is reused, how it's credited, or where it's hosted (assuming you or anyone else has any inclination to do something with it), but see [this comment](https://www.reddit.com/r/haskell/comments/aur7hz/help_wanted_on_haskell_wiki_skin/ehbi7lc/) about the photographer. That probably doesn't clear things up, but I can try to get in touch with him and release it under CC.
Is it the logotype you prefer, the symbol, or both? (Between the two options in the first image, I mean; the following two were just for fun and I'm not advocating them as replacements in any way.) I'm sure it goes without saying that I prefer the bottom, revised version as a whole, but the symbol in particular is what I wanted to touch up. My rationale: I much prefer the slightly wider stroke width and more "upright" feel of the angles. It's closer to the weight of the text, so it feels a little more cohesive, and the slight bumps in saturation and hue brighten it a little. I realize design preference is mostly an emotional reaction, so it's a little silly to try to convince people with an explanation, but I figured I'd throw it out there. (Also, I appreciate the feedback!) And as for the poster: thanks for the kind words. I personally have no reservations about how it is reused, how it's credited, or where it's hosted (assuming you or anyone else has any inclination to do something with it), but see [this comment](https://www.reddit.com/r/haskell/comments/aur7hz/help_wanted_on_haskell_wiki_skin/ehbi7lc/) about the photographer. That probably doesn't clear things up, but I can try to get in touch with him and release it under CC.
I had worked on many open source projects in 10+ languages (also including C#) before I discovered Haskell in university. Over the next 2 years I learned Haskell properly while in uni, so you could say I discovered Haskell quite late (compared to other programming languages). I decided that whatever thing I'd pick next, Haskell should be a big part of it because I find it's the most efficient way to get stuff done, and it makes me happy to be productive. After doing my masters project in Computer Vision, I considered doing a PhD in it, but decided against it (for now) to become a Haskell consultant (and do the Computer Vision things I had planned in my free time). These days you have a lot more choice when looking for a Haskell job. There are various interesting companies around, both consultancies and product firms. I recommend you to learn everything you find interesting, then figure out whether some of these things are "hard conditions" for you, then invest some time to become really good at them (or some subset of them that people would like to hire you for), and pick your dream job.
Take the definition of 'Coroutine': newtype Coroutine s m r = Coroutine { resume :: m (Either (s (Coroutine s m r)) r) } and instantiate `s for `(,) a` or whichever suspension functor you prefer and `m` for `IO`. You end up with newtype IOCoroutine r = IOCoroutine { resume :: IO (Either (a, IOCoroutine r) r) } In this case, every call to `resume` returns a value and an `IOCoroutine` continuation. You might say it [yields](https://hackage.haskell.org/package/monad-coroutine-0.9.0.4/docs/Control-Monad-Coroutine-SuspensionFunctors.html#v:yield) a value in `IO`. You could implement the same interface using `forkIO` and `MVar`, but what would be the benefit? 
Yes, there is a lot of emphasis on unit tests as well, and regardless of what language you use, it isn't a horrible idea to test your assumptions. Plus there are also implied performance expectations, though w/performance in general you start to specialize, and evaluate your abstractions and even choose your hardware with some care, including profiling. good performance, quick turn around, correct, pick two.
Good idea. At beginner, it is so much stuffs to learn and it takes time to learn each one of them. But maybe after learning all of it, I can be very good in one of them.
Look at hie and vs code. The former makes a strong case for being the tooling engine for Haskell for the foreseeable future
I have tried it, and so far, it hasn't. The cabal support does not appear to support v2. 
Does everyone benefit? Or just the commercial SIG?
Fetishism always fails to solve the problems to which it is addressed, but I think there’s a small bit worth holding on to in this (somewhat indulgent) narrative: some things beget the desire to work and some things don’t. This is important. One can go further and produce a whole cultural critique about why some tools are better or worse at this for their particular position in life (economics; risk; constraints; ideology), but it’s worth investing in (making) tools you can love. 
Thesis of the Turing-Church is where I worship. Watch as your logic becomes a language through Curry-Howard transubstantiation. --- I'm experiencing something similar, though not as severe. There's a lot more patterns and d-i in the code I'm working in than we really need, and the documentation is horrible, so none of the abstractions save me time, since I have to deconstruct them all to make any changes. One of the reasons I like Haskell is that it is easier to refactor, which means I can start small and simple, and add just exactly the complexities I need without to much worry as I need them. KISS is older than any GoF pattern, and truer than most other best practices.
If you read the article, they did talk to HR, and when they asked to be fired, they were given a raise.
Yes, it is possible to import a remote expression from the internet that transitively references an intranet URL. That potentially malicious URL has to be resolved at least once, either when prenormalizing the expression or when caching the expression for the first time.
Another approach might be going via `NonEmpty`: &gt; let f x y = maybe y toList $ nonEmpty x &gt; f &lt;$&gt; [[], [1], [1,2,3]] &lt;*&gt; [[],[4],[4,5,6]] [[] ,[4] ,[4,5,6] ,[1] ,[1] ,[1] ,[1,2,3],[1,2,3],[1,2,3]] 
Thanks for the clarification!
I thought that poster was for an upcoming [Barbican](https://www.barbican.org.uk/) exhibition.
I for one would prefer not to favor one tool over the other at this stage. I don't consider `cabal-install` and `stack` to be interchangeable. 
Whoa, thank you for introducing me to this. I'm going here next time I'm in London. Their posters [are great](https://shop.barbican.org.uk/products/siobhan-davies-dance-poster), and girlfriend is a preservationist who loves brutalism, so you might have just done her [birthday gift research](https://shop.barbican.org.uk/collections/shop-all-apparel/products/copy-of-brutal-tote-bag) for me.
There's also `[I` builtin to vim.
Only `hlint` and `ghc-mod`? In 2019? Sorry, it's HIE or bust for me.
I think the "even more idiomatic" aspect of just using the `[a]` for lists is more important than learning about functors. A functor is merely a polymorphic data type with a map function (something that takes `a-&gt;b` to `f a -&gt; f b`. Your `List` defines a `mapList :: (a-&gt;b) -&gt; (List a -&gt; List b)`, which makes it a functor with a non-standard name for the map function. Furthermore, it also defines implementations for `appendList`, `Listlength`, `filterList`, `contains`, and `nths`, which look like reimplementations of `(++)`, `length`, `filter`, `elem`, and `(!!)` respectively. The remaining list implementation it uses is `combine :: List Picture -&gt; Picture`, which looks like it is a specialized implementation of `fold :: (Foldable t, Monoid m) =&gt; t m -&gt; m` from `Data.Foldable`. Since `Picture` is a Monoid and `[]` is a Foldable, you can use `fold` directly instead of implementing it yourself. Reimplementing lists is a classic introduction to functional programming assignment, but idiomatically no one does it in production code, since lists are built in. Using the built-in list syntax will also simplify your code. For starters, it'll immediately eliminate 40 lines of code from your program. As an example of your current code has a value `allDirections :: List Direction` with a value of `allDirections = Entry U (Entry L (Entry R (Entry D Empty)))`. Idiomatically, I'd write that as `allDirections :: [Direction]` and `allDirections = [U,L,R,D]`. There are other changes I'd suggest, but they go beyond "use [a] instead of reimplementing lists", so aren't on topic here. 
It's basically my second home - there's *so much* to explore it's fantastic. Drop me a message if you want to meet up and gush over it's brutal architecture!
I like the first logo, the font looks straighter and more serious, very much close to the characteristics of Haskell.
Note that "purely functional code" is just a mental model to organize code and help us reason about it. In Haskell, we *use* purely functional code to *specify* effectful code (in a first-class way). Then the compiler/cpu etc. takes the code we specify, and then runs it. So in Haskell, purefuly functional is a tool used to design effectful actions.
What :o
Yeah I get your point :)
My biggest regret from college is never going to office hours. - I'm doing ok in a class: "Eh, I don't need to bother them, I'm doing ok" - I'm behind in a class: "It's my fault, they'll just tell me to knuckle down and do the work" It made it really awkward when I wanted to get references for job applications, and indulged my fear of judgement/failure and impostor syndrome in ways not good for my mental health. I am not you, but I encourage you to give it a try. If it helps, think of it like a mandatory meal plan. You're paying for it, so might as well get your money's worth.
Another place to get your questions answered is r/haskellquestions. Good luck!
The top one in the first picture? Now I'm getting really curious! I agree with this sentiment entirely, but I actually *didn't* like Raleway (the font used in the official logo, top design in the first picture) because I thought it was more whimsical-looking. So when I was redoing it, I settled into Aktiv Grotesk but also played around with [Neue Haas Grotesk](https://heavyindustri.es/img/haskell/logo-revision-s2.png) as an even more straight-laced third option. The version with Neue Haas Grotesk is actually my favorite, but I didn't think anyone would like it because it has an almost clinical/industrial feel. It's redesign is the top one in that picture, by the way, not the bottom—I labeled it this time.
Try category theory and different things *in* haskell: free*r* monads (optionally, with `Codensity`), "final" encodings. Try generalise optics using `Tambara`-profunctor. There is a lot of abstract things to do here.
Neat! I've been meaning to get into Haskell for a while now, but lack of high level tooling was making it difficult to stick to, as the closest language I'm somewhat comfortable in is Rust.
If you compile your project with `-ddump-rn-trace` then each usage is described in the dump with the module from which it was imported. One could build a system on top of that.
But your `IOCoroutine` is a new monad. I need to do coroutines directly in IO. For example, I need this function with this exact type: coroutine :: forall a b c d. ((a -&gt; IO b) -&gt; IO (a, c)) -&gt; (a -&gt; (b -&gt; IO a) -&gt; IO (b, d)) -&gt; IO (c, d) I really think we're doing different things, tbh. 
I have a BS in CS from U of Arkansas. I have a few Master's level credits from both UofA and the OMSCS program from GA Tech. I've written code in Agda, Idris, and Haskell, though never professionally. I do have a small number of changes in open-source libraries, like the Idris stdlib and recursion-schemes. I currently write Java, C, JavaScript, and Python for work. I found Haskell in 2009-10, before the latest report, but just barely, after I'd been out of school and a professional for a while. I use it when I can, and consider myself proficient in it, but haven't (yet?) shaped my career around it. If you want to pursue a PhD in the area, you sound equipped for it. Look through the last 3 years of ICFP and POPL papers to find universities with strong programs.
All of these features (&amp; more) can be set up on emacs. Here's a live coding video showing a bunch of cool emacs Haskell tooling being used in the wild: https://www.youtube.com/watch?v=CgiSfTshccE (hlint hints, intero, structured haskell mode, etc).
I am trying to use Data.ByteString.Lazy to split a ByteString at newlines. the following function gives this error ``` • Couldn't match expected type ‘GHC.Word.Word8’ with actual type ‘Char’ • In the first argument of ‘L.split’, namely ‘'\\n'’ In the expression: L.split '\\n' In an equation for ‘splitAtNewline’: splitAtNewline = L.split '\\n' | 63 | splitAtNewline = L.split '\\n' | \^\^\^\^``` Which is exactly the same code as the example in the documentation. What is going on here.
I'm just never going to use stack. At most it's a different CLI to cabal to me. Every other value proposition is fully subsumed by using Nix for me. I know I speak for plenty of others who see stack the same way :) So no, we are never gonna converge on stack.
I think this would do it: newtype F a b c = MkF (a, b -&gt; c) ioCoroutine :: ((a -&gt; IO b) -&gt; IO r) -&gt; Coroutine (F a b) IO r 
&gt; I believe this is a good thing as it lets the community focus their energy on improving one single tool to become the best in class and we can all rejoice. Why not Cabal then? If this advice were followed, then Stack would not exist! Instead, consider that healthy competition makes each better, which has been proven true for both Cabal _and_ Stack. It's neither terribly useful, nor good for the community to dismiss others' grievances with 'just don't be frustrated'. OP may have immediate concerns that a grandiose dream of one tool, one community will not fix. &gt;we can improve in Stack Do you work on Stack and contribute code? If so, I actually do have an immediate concern that can be addressed. LTS installs a new GHC regardless of my current set up with no warning. It would be nice for Stack to source the existing GHC, or at least put out a warning when not using my system's GHC version (see: the gitter conversation with Michael). 
Just wanted to chip into the conversation, as I see most people (to my great surprise) are apparently not so keen: I really like your revision! I never knew I wanted it, but now that I look at it I find your version to be noticeably more visually pleasing. &amp;#x200B; When I try to articulate why I prefer your version, I think it's because the `λ` and the `Haskell` text look more similar in your version. I see you already said some similar stuff in another comment, but to my impression &amp; in my own words: * I prefer the more "upright" angles in your `λ`. They feel (to me) more in harmony with the text. * I prefer your choice of font. Since the `λ` is styled in a no-nonsense, straight lines + sharp edges, sans-serif kind of way, I find that a similar kind of font looks better in combination. Also, the slightly brighter/more saturated colours I like too, feels to me that it "pops" a bit more.
It sounds like you mean "Reflex-DOM" specifically (Reflex itself could be used on your backend, for example). For \`MonadStore\` to make sense in a Reflex-DOM context, it shouldn't be using \`IO\` directly. While you have \`MonadIO\` in Reflex-DOM apps, it should only be used when you really have a good reason to do so, and only when wrapped with FRP based APIs (e.g. \`performEvent\`, \`newTriggerEvent\`, etc.). I don't know what your \`MonadStore\` class looks like, but chances are you'll want to parameterize it enough to work with both IO-based and FRP-based usage. If you were to use Reflex on the backend for interacting with your data sources then this would more homogeneous. A cop-out move would be to just run all your \`MonadStore\` actions inside a \`performAsyncEvent\` on the frontend.
For projects where I only deal with Haskell/GHC I generally use stack as it is good at what it does. However for bigger projects often with multiple compilers and/or languages nix is just far too good. Nothing stack can feasibly do will compete with it as its just not within stack’s design goals for good reason. For that reason I will never converge to stack, if I were to converge to anything it would have to be nix, but that also isn’t feasible in the near future as nix requires a lot more investment than stack, so I don’t want to have to force people to set it up just to get involved with Haskell. So personally I need stack and I need something to work alongside nix (cabal new-build) at the moment for fast incremental builds, as using nix + stack together makes no sense.
&gt; (e.g. `performEvent`, `newTriggerEvent`, etc.) I would be using functions like these. I think the `view` function I mentioned above is not the best example, I made an edit about another operation I would like to introduce. It is like view but returns an `m (Dynamic a)`, with additional constraints on `m` for Reflex. So on the client we can have reactive data coming straight from some data source e.g. a DB. &gt; but chances are you'll want to parameterize it enough to work with both IO-based and FRP-based usage Yes this sounds like what I might need to do. Are you aware of any examples of something like this, or how you might approach it. Thank you! 
I might end up writing Reflex specific functions, since they only have one option of data source to talk to anyway, over the internet.
I really like the third one with more color! Not as an official logo, but maybe something you’d throw on slides or posters :)
As long as it requires a multi-hour compile for each version of GHC you want to use it with, I really don't see that being the case. I'd even go so far as to say I hope it does not. The HIE install process is painful, and the only reason I put up with it was because l bought a sales pitch it didn't deliver on. 
As long as it requires a multi-hour compile for each version of GHC you want to use it with, I really don't see that being the case. I'd even go so far as to say I hope it does not. The HIE install process is painful, and the only reason I put up with it was because l bought a sales pitch it didn't deliver on. 
Having a \`Dynamic a\` on the frontend for your backend data will, of course, require either polling or push-based updates from the backend (the latter of course being much more elegant but much harder to achieve). There are numerous attempts at this design and `QueryT` was added to Reflex for this kind of use case. How to unify this and your backend is a different question of course. If you make it parametric on your functor over `a` then your backend could use something like `Queue a` or `STM a` to achieve a sort of low-grade reactivity. This seems reasonable enough but hard to know how it gets used on the backend.
They provided binaries at one point, that may return. Also, `make build-all` runs in about an hour for me for all supported ghcs. And the wrapper for vs code just works. Curious about what it didn’t deliver on?
But then they miss the chance of hiring a smart freshly-graduated Haskell-enthisiastic person for half of what they would pay them, simply because the candidate doesn't know what to expect.
The trouble is, for e.g. JavaScript developers, such an object is as easy to use as list (\`Object.entries\` will convert it into a list of tuples) – and sometimes it's even easier, because they can lookup for specific data without filtering the list. &amp;#x200B; This seems to be common problem and I am thinking that it should be easily doable to create a generic decoder, dedicated for such a structures. Once I am more comfortable with how things work in Haskell, I could contribute… Or someone wrote such a parser already and we just don't know it…
Thanks to /u/jaspervdj for keeping our GSoC program running so smoothly!
I am really confused by your comments here -- it seems like you want to run untrusted but non-normalized Dhall configurations for some strange reason? If you trust the author of the Dhall file with HTTP access, there should be no reason to care, and if you don't, you just require that the author normalize it first. In what case is there an actual problem?
You're welcome!
This is the main reason I don't use HIE. I'd love to, but it's been difficult to get working with any of my projects. It's a real shame because I consider it and LSP to be the future of editor integration for Haskell.
Thanks /u/mrkkrp.
Is there a standard library function that does the following : &amp;#x200B; x &gt;&gt;= f ++ ((x &gt;&gt;= f) &gt;&gt;= f) ++ (((x &gt;&gt;= f) &gt;&gt;= f) &gt;&gt;=f) I'd like to do this for an arbitrary n number of times and hopefully be able to use the result of the previous iteration for the current one.
How about `concat $ iterate (&gt;&gt;= f) (x &gt;&gt;= f)`? (Optionally adding a `take n` either before or after the concat)
For the sake of the argument, if we were to converge to a single tool shouldn't we rather converge on Cabal [which has been supporting features such as Backpack for nearly 2 years for which Stack to this day still doesn't have any support for](https://www.reddit.com/r/haskell/comments/ahknz7/question_to_professional_haskell_programmers/eejbgsj/?context=1)?
Probably a confusion between [split](http://hackage.haskell.org/package/bytestring-0.10.8.2/docs/Data-ByteString-Lazy.html#v:split) (the one that correctly uses octets) and [split](http://hackage.haskell.org/package/bytestring-0.10.8.2/docs/Data-ByteString-Lazy-Char8.html#v:split) (the one that confuses Unicode code points (`Char`) with bytes). That said '\n' is a small enough code point so that the truncation to a Word8 doesn't change it's scalar value.
I'm trying to learn Haskell by doing some course work in it. I have encountered a recurring problem where I find it difficult to express these kind of algorithms (see pic) in a functional way. Is there any general strategy how to approach these kind of programs? The nested loops and variable state are perplexing to me.
Thank you !
&gt; It is increasingly frustrating to me that all these tools are transitioning to stack. That might partly be my fault. Intero is GHCi plus extra bits; Intero for Emacs installs this binary automatically upon starting the mode, by running `stack build intero` which is a trivial way to get it installed at the same GHC version as the current project. Meanwhile, it uses `stack ghci --with-ghc intero` to run the process. These two things together--i.e. re-using what Stack already provides--brought the means to trivially install the tooling support needed, which `ghc-mod`, `hdevtools`, `scion`, etc. had always made a royal pain in the arse (apparently `haskell-ide-engine` is hard to install too). Meanwhile, it lets the user pick between packages in the project and their targets, using `stack ide targets`, which lets you re-use the concept of Stack's targets and projects. Previously: You had to install the tool yourself. It had to be the right version to match your IDE. It had to match your GHC version. It had to be configured to your package properly. It had to actually build (often you got a version bounds error, or a compile failure). Just using Stack removed that burden from the IDE writer (me). By and large people reported that it Just Worked(tm), usually with disbelief (that's the state of Haskell tooling) and continue to do so to this day. Initially intero the binary got installed for every single project (took about 20 seconds to build) but froze up the whole Emacs (still does that, on purpose), and people still used it (that's the state of Haskell tooling) because it worked. Today, Intero is only installed for the specific GHC version via `--copy-compiler-tool`, which still happens automatically, but just once every 6 months or something. Another case where Stack helped the workflow. &gt; There seems to be no concern or interest for supporting cabal anymore For the Intero for Emacs/Haskero/Intero-neovim/etc line that's probably true. But I don't think people are writing these integrations out of concern for others' well-being (entirely), they're doing it because they need it for themselves. So if the maintainer uses Stack, you can expect that their tooling just supports Stack. I don't use cabal or nix, so I'm not supporting them in Intero for Emacs. It's hard enough keeping up with the issues people bring up all the time with _one_ dimension of configuration, nevermind three. Apart from people on reddit, I don't interact on a day to day professional level with people who don't use Stack, so it's not on my radar. &gt; and it's meant that the code I work with every day is unusable in pretty much any IDE/editor environment. Not every project uses stack, in some cases because they can't. I work with a million lines of production Haskell running on cabal-new because we have dependencies that are not easily configured in Stack anymore, and apparently this means I get to code like it's 1994 and I should feel lucky to even have syntax highlighting. You get what you pay for, really. Seriously; a client paid us to write Stack and I was paid to work on Intero (but now maintain it for free). If you work at a company that has a million lines of Haskell then they are invested enough in Haskell and perhaps they can afford to pay someone to improve tooling for them? You can certainly pay FP Complete to improve Stack, or else to improve a particular IDE's support for cabal-new. 
May I ask if you use any specific library on your migrate-db executable?
Yeah I changed to ByteString.Lazy.Char8
I changed it to use Lazy.Char8 and it stopped complaining. All good now. So what was the reason for Haskell to move away from Strings as list of chars to introduce all this string type complexities? 
For great good and/or evil
Well, Haskell still has `type String = [Char]`, and that's fine for some programs. But, with that encoding, we are using 4 bytes for each code point, and then 8 bytes for each indirection, of which there are 2 per `Char` in the `String`, plus 1 or two more. Most network protocols and file formats are defined in terms of the octet/byte, not unicode code points. For ones that are, Haskell's `Char` was never how you'd want to read them. `Word8` is the (lifted) byte/octet. Using `String` which is based on `Char` was never *correct*. For Unicode you can continue to use `String` or `Text.Lazy` or `Text`, depending on how "chunked" you want your data. Each chunk costs one or two indirections, but it can increase sharing. You can also use more exotic containers with `Char` inside. Also `Text` also does some work around handling Unicode surrogate pairs correctly, while `String` doesn't and either would any general-purpose container that you just happened to stick `Char`s in. For raw bytes, in particular the buffers that C library and OS system calls want, we need a contiguous storage of (unlifted) bytes. I think you can get that today through places other than ByteString, but ByteString was purpose-built for that and speed. `ByteString.Lazy` is a bit like `Text.Lazy`, in that it is effectively a linked list of continuous chunks, giving some kind of happy medium. None of `String`, `Text.Lazy`, or `Text` would be appropriate for raw bytes. `ByteString`, `ByteString.Lazy`, and `[Word8]` would be inappropriate for Unicode strings. Suppose you were writing a non-streaming lexer. You'd open the input file (using a name that's a `ByteString` on Linux/MacOS), read a buffer's worth into a `ByteString`, and stitch all of those into a `ByteString.Lazy`, your unicode decoder be a internally-stateful fold over bytes, so it effectively takes a `[Word8]` and gives back a `String`, but each Lexme is best represented as a `Text` and the result of those whole lexing process a `Text.Lazy` (or maybe just a `[Text]`). Each type has a specific fit purpose that the others doesn't serve as well, the chunking/dechunking conversions are readily exposed. The switch between Unicode and octets requires you to pick an encoding, but once that is done it's also fairly simple.
Unfortunately `System.IO.withFile` won't work because it doesn't accept `MonadIO`. If you can live without it, this is one way to combine the two coroutines: main = pogoStick runIdentity $ weave sequentialBinder (weaveAwaitYield ()) (do h &lt;- liftIO (openFile "A" ReadMode) _y &lt;- await liftIO (hClose h)) (do h &lt;- liftIO (openFile "A" ReadMode) yield () liftIO (hClose h)) 
This is my preferred development environment as well because it supports navigate to library source code *inside* the IDE Shameless plug for my way of setting it up https://gist.github.com/androidfred/a2bef54310c847f263343c529d32acd8 
What's HIE?
How does Waargonaut compare to Aeson? I've only ever used basic stuff from Aeson.
Thanks for the detailed write up. I am new to coding and I didn't realize all this complexities behind the scene. Is Haskell somehow uniquely challenged when comes to strings? How does other languages deal with this? How does a close cousin, Idris deals with it?
Sure, but I'd rather do coroutines directly in the IO monad, so that I can use functions like `withFile`.
This situation has much improved recently
Java has two types for bytes vs. Unicode. The `String` type is always Unicode, though I've definitely seen it abused to hold bytes, since byte[] is more awkward to deal with and ByteBuffer wasn't in the standard library for a while. byte[] is always a single chunk, String is always a single chunk. You can put any of {byte, char, byte[], and String} in a linked list if you want, but you lose the string-ish API when you do that. Python 3 has different types for bytes vs. Unicode. Both are single-chunk formats in CPython and Jython, I think. Other implementations might do differently. [] is single-chunk (w/ one indirection), and I'm not sure there's a standard linked list container. Again, if you put them in a container, you lose the str-ish API. Python 2 has problems conflating bytes and Unicode and that contributes to the decision to stop maintaining it. Python doesn't have the char vs. str or byte vs. bytes distiction, which is sometimes weird, but does "simplify" other things. C has different types for bytes vs. Unicode, but wchar_t is such a pain, they often just don't support Unicode well (or always want it in UTF-8, which is somewhat compatible with the str* family of functions). Also, C contributed non-trivially to the confusion since the type that it uses for a byte is called `char`, though the age of C gives the hysterical raisins flavor to this. C++ string is really quite complicated, at least in the GNU libstdc++. It can be a single chunk or multiple. And if you understand the magic, it actually does okay at being polymorphic across both char and wchar_t. I'm pretty sure it does some internal mutation when you call .c_str() on a long one though. I'd say most languages expose two types, that are the single-chunk versions equivalent to `ByteString` and `Text`. Honestly, you don't want to do anything with Unicode strings in a language that doesn't have the separate types -- you can get some really weird bugs passing Unicode in the wrong place or double-encoding Unicode. I think most of the "smart" formats that will chunk/dechunk automatically do depend on internal mutation, and that's not very Haskell-y, which is why you get the `.Lazy` alternatives in Haskell instead (which are really just `[Text]` or `[ByteString]` but with the `Text`/`ByteString` API. (Also, Haskell programmers are unique in that they expect laziness to be the default in many cases.)
I'll be interning at Google this summer. Is it a good idea to apply? There's a project in the ideas list that I really want to work on.
That's a pretty broad question so I'll try to cover the main differences.. Waargonaut doesn't rely on typeclasses for encoding/decoding so orphan instances are no longer a problem. This also lets you have multiple encoders and decoders for any given type and you can use them as required. They're just values and functions so you can build them and pass them around just like anything else. There are typeclasses and Generics provided and they work as well as everything else, but I don't think that typeclasses are the correct mechanism for encoding/decoding a textual format like JSON. It also provides a zipper for the decoding phase. So you're able to very precisely move around the input and carve it up any which way you please. Like the problem that the OP talks about is a total non-issue for Waargonaut because having this cursor around the structure just lets you access what you need, however you need it. The decoder is built upon the incredible work in the HaskellWorks `hw-json` package that uses succinct data structures. So the decoder is nice and fast, it also doesn't require the entire structure to be built in memory first. There's more improvements to come for that too, so it should become even more efficient in the near future. There are optics and lenses all over the place so if you want to mess with your JSON using `lens` then you can do that too. You're able to provide your own parsing functions, so if you don't want to use the defaults of `attoparsec` then you're able to provide your own functions. Provided there is an implementation of `CharParsing` from `parsers`. ;) I'll stop rambling now... But hit me up if you have any other questions.
Unfortunately, if the internship overlaps with the GSoC timeline, it's probably not a good idea -- the time invested into GSoC projects should be more or less comparable with a full-time job, so I think it's unlikely to bring both to a successful end.
[Waargonaut](https://hackage.haskell.org/package/waargonaut) has the tools for this, you can pull things apart into a list of tuples or more precisely carve the input up into other structures courtesy of the zipper based decoder. :) Creating a generalised `Decoder` where the keys of the object you're navigating are given to the `Decoder` for the thing at that key position shouldn't be too difficult. All the building blocks are there already.
It uses persistent (and persistent-postgresql).
It’s best (and easiest) to not work on anything else during your internship. You’ll go through some legal orientation on the topic but I wouldn’t make any plans for major open source work over the summer. Googles non-compete has quite a reach.
It helps that UK is notorious for undervaluing engineers. So they have that going for them. 
"We'll send you a sample repository structured similarly to our real code base." I trust these are honorable men, and would never be fishing for free labor.
What is success worth to you?
This is true. My experience with NixOS is that it solves one problem, and breaks unix while doing it.
I'm a lazy idiot. Thank god for ghc.
You guys are right. Going to a uni this far away is new to me but it definitely doesn't mean I should give up getting any help from college. I'll try my best to get as much help as I can.
Thank you this is really neat.
After testing the UI a bit more I see that the /eval and /it keywords aren't working. Also I maybe should have mentioned that it will not yet accept any kind of punctuation. I will fix those two things soon.
Don't forget the part where they can justify underpaying current employees by obfuscating the payscale for their peers!
I am still learning NixOS in virtual box before starting using it as default operation system. Which kind of things does it break?
Wow, thank you for writing such a great explanation! Waargonaut sounds awesome. I'll definitely keep your library in mind for future projects :-)
Haskell IDE Engine :) 
Dead simple settings [don't seem to work:](https://travis-ci.org/amnh/PCG/jobs/499089111) `cabal: Cannot find the program 'ghc'. User-specified path 'ghc-8.6.3' does not refer to an executable and the program is not on the system path.` Was this tested before posting?
How competitive are these positions? I’m a big fan of open source and the idea of working with a lot of these organizations really excites me. Unfortunately though, I’m super inexperienced and can only really claim to be competent in Java. Does anyone have experience with this program? I’m a university student in their second year. 
This should do the trick [https://hackage.haskell.org/package/waargonaut-0.6.1.0/docs/Waargonaut-Decode.html#v:passKeysToValues](https://hackage.haskell.org/package/waargonaut-0.6.1.0/docs/Waargonaut-Decode.html#v:passKeysToValues)
&gt; Is it the fact that GHC is happy is enough to be sure it works? No, you can still have logic errors, space leaks etc, etc. But it is pretty amazing how often Haskell just works once it compiles, especially when rewriting working code.
I find this a little easier to follow; without linear/etc types, the "don't yield after receiving a `Left`" burden is still on the user, similar to yours. coroutines2 :: ( (a -&gt; IO (Either v b)) -&gt; IO u) -&gt; ( (b -&gt; IO (Either u a)) -&gt; Either u a -&gt; IO v) -&gt; IO (u,v) I agree that this does not seem "essential", but I'm not very familiar with the expressivity of coroutines. (I at least see an unpleasant encoding to get more than two coroutines via nesting here, so that doesn't seem like an expressive limitation.) Last my head was in that space, lifting this kind of limitation with `withFile` was one of the big reasons-for-being of pipes, conduit, etc. Are those mature packages in that error-prone space absolutely off the table? HTH.
I read through some of the documentation and I'm still not sure what problem this solves. Is this a query language + data structure as an alternative to an in-memory database? More flexible queries at the cost of them being slower? Something else entirely?
So in the end I've gone for this: newtype Suspended p q m a = MkSuspended { resume :: m (Either a (p, q -&gt; Suspended p q m a)) } class Monad m =&gt; MonadCoroutine m where suspend :: ((p -&gt; m q) -&gt; m r) -&gt; Suspended p q m r from which I was able to [derive `coroutine`](https://github.com/AshleyYakeley/Truth/blob/master/shapes/src/Control/Monad/Coroutine.hs). My `suspend` has no burden on the user, while `coroutine` reveals its burden with a fail statement (instead of blocking on an MVar). It's also more general, as `suspend` can open a file from `withFile` and return an IO action that closes it, while `coroutine` can't. I'm happy with this. You can see how similar my `Suspended` type is to blamario's `Coroutine`, which is a good sign. I'm doing this to solve one particular problem that came up in the way I'd defined a type, which I didn't want to redefine, so I don't really need the full power of conduits etc.
I think you are missing the point. It is quite famous that tooling is best in Emacs for Haskell. Learning a new language like Haskell is already time consuming. People don't want to also learn a new IDE/text editor (one that can be quite obscure for newbies). Many developers use intellij in other languages, are already familiar with it and it's shortcuts. This dramatically reduces the learning curve. Also, meaning no offense, it's a lot prettier, and you can discover features by clicking, something vi/emacs don't seem to facilitate. Most people don't want to invest 6 months/1 year learning both an IDE and a language, it's just too frustrating. And Haskell alone can get frustrating enough already when you learn it from an OOP background.
&gt; You get what you pay for, really. Seriously; a client paid us to write Stack and I was paid to work on Intero (but now maintain it for free). If you work at a company that has a million lines of Haskell then they are invested enough in Haskell and perhaps they can afford to pay someone to improve tooling for them? You can certainly pay FP Complete to improve Stack, or else to improve a particular IDE's support for cabal-new. Earlier in this thread I deleted a reply asking who really benefits from Stack, users, or the commercial SIG. I thought I was being too harsh. Perhaps I was mistaken. It would seem you’ve answered my question. 
Why in general should the community place its vets on a third-party tool from a commercial interest group, and not the open tool that actually comes with the compiler? It seems sort of absurd to me in retrospect. Imagine the effort that could’ve been put into cabal v2, if the community wasn’t being split to line FP Complete’s pockets. 
I've been exploring Haskell for this past half year and would be very interested in writing a proposal. I've read about the proposal on the official GSoC webpage where they mention that organizations might have their own required application format. I couldn't find any official one on [summer.haskell.org](https://summer.haskell.org), so I assume not. But to make sure, are there any application length limits or format requirements?
It looks like a knowledge base to me. 
Yes, it was tested before posting. Moreover, I use this configuration for more than 20 Haskell packages, and it works great so far. The reason your build fails is that you have the following line in your `cabal.project` file: with-compiler: ghc-8.6.3 That's why the build for GHC 8.4.4 fails. Your local `cabal.project` claims to use `ghc-8.6.3` while globally only `ghc-8.4.4` is installed. The other builds are failing due to actual compiler error that has nothing to do with the Travis configuration. I mentioned in my blog post that I can help with problems arising with using this config. This is what I did just now. I also mentioned in my blog post that these Travis settings might not work for all cases (in your case you have implicit configuration environment). I don't appreciate the fact that you're assuming that I'm too dumb to publish my work without testing and you don't think even for a second that something might be wrong on your side. This is a very toxic point of view, and it doesn't lead to a healthy discussion.
The next step is encoding of a Turing machine and SAT solving on NP problem instances.
A bit, but don't let that stop you from applying. Never sort yourself out :) 
&gt; Why in general should the community place its bets on a third-party tool from a commercial interest group, and not the open tool that actually comes with the compiler? Because the so-called open tool was in a terrible state and failed the community for too long. This was clearly articulated in [Why is stack not cabal?"(https://www.fpcomplete.com/blog/2015/06/why-is-stack-not-cabal): &gt; The fact that Haskell has a tooling problem is not a rumour, nor is it a fringe belief of disgruntled developers. In an effort to collect the data necessary to identifying the bottlenecks in the growth of the community, FP Complete conducted a wide survey of the entire community on behalf of the Commercial Haskell SIG. The results are in and the 1,200+ respondents are unequivocal: package management with **`cabal-install` is the single worst aspect of using Haskell**. Week after week, Reddit and mailing list posts pop up regarding basic package installation problems using `cabal-install`. Stack however went from 0 to fixing all Cabal issues in less than a year! That should tell you everything about why the community should place its bets on Stack. &gt; It seems sort of absurd to me in retrospect. Imagine the effort that could’ve been put into cabal v2, if the community wasn’t being split to line FP Complete’s pockets. This urban legend about FP Completely filling its pockets thanks Stack is totally absurd. FP Complete doesn't make any money from Stack. In the contrary developing and maintaining Stack costs money that isn't easily recovered. But unfortunately cabal was developed with other goals in mind so it made more sense to start from scratch and as we all know history has validated Stack's approach to be superior to cabal's. The only people splitting the community are those like you who try to paint FP Complete as greedy when all FP Complete has done over the year is contributing more than any other company to Haskell's ecosystem without getting the gratitude it deserves.
I did it last year, and I really can't speak highly enough of the experience.
Good stuff! All your top level functions (e.g. [https://github.com/witoldsz/semux-discord/blob/master/app/Main.hs#L31](https://github.com/witoldsz/semux-discord/blob/master/app/Main.hs#L31)) should have type signatures. &amp;#x200B; You don't need \`getRight\`, as in: \`account &lt;- getRight $ getAccount semuxApi delegate\` Instead you can do "irrefutable pattern matching": \`Right account &lt;- getRight $ getAccount semuxApi delegate\`, which calls \`Monad fail\` when the pattern match fails. So it has the same meaning as what you've done, but is more concise. &amp;#x200B; Should \`getLastCoinbase\` return an \`IO (Either String UTCTime)\`, instead of crashing?
Things have been greatly improved since, that's for sure. You're most welcome to give it another shot. I, for one, am editing a 30K LOC project (dependencies' source which is also downloaded and can be navigated on (!) is not included) with it, experiencing little to no lags and no freezes.
Nice to hear that! I will give it a shot.
&gt; Instead, consider that healthy competition makes each better, which has been proven true for both Cabal and Stack Oh yeah? So it's friendly competition when a well-known cabal developer actively sabotages Stack users ([here](https://www.reddit.com/r/haskell/comments/7i4ukq/stacks_nightly_breakage/) and [here](https://www.reddit.com/r/haskell/comments/7kt36c/lts_stackage_with_ghc822_released_today/drhiwvg/)) or when infantile [malicious Setup.hs scripts targetting Stack](https://github.com/tonymorris/do-not-use-stack) are crafted. Friendly competition for sure.
&gt; All of these features (&amp; more) can be set up on emacs. That's a bold statement. Does it apply to language-agnostic functionality like [Local History](https://www.jetbrains.com/help/idea/local-history.html) or [text-based HTTP client](https://www.jetbrains.com/help/idea/http-client-in-product-code-editor.html), or [proper task switching](https://www.jetbrains.com/help/idea/managing-tasks-and-context.html), to name a few, as well?
UK’s consistent with the rest of Europe. It’s the US that inflates their value. 
Thanks for the detailed write up! 
You're frustrated that your IDE situation in Haskell is not what you want, but I think this is putting your energy in the wrong place: &gt; Earlier in this thread I deleted a reply asking who really benefits from Stack, users, or the commercial SIG. I thought I was being too harsh. Perhaps I was mistaken. It would seem you’ve answered my question. FP Complete, who worked on a tool (stack) for a fee, and then released it open source, and have maintained it, along with accompanying infrastructure (stackage), _for free_, for years. Well Typed also fund a bunch of Haskell work and infrastructure (cabal, hackage and GHC), among other companies (Microsoft). There's no mystery or conspiracy here. If you want full time work you have to pay people full time. Good tooling doesn't fall out of the sky. Either you do it yourself or support people who will. 
I want proofs for two propositions about Haskell's `Functor`. 1. For all `Functor` `f`, `a, b :: Type`, `x, y :: f a`, and an injective function `j :: a -&gt; b`, fmap j x = fmap j y -&gt; x = y I think I almost got the proof for 1, only when `a` is an inhabited type. In that case, I can say there exists `k :: b -&gt; a` which satisfies `k . j = id`, and taking `fmap k` on both sides of assumption gives `x = y`. But I'm lost at when `a` is not inhabited like `Void`. 2. For all `Functor(?)` `f`, `a, b :: Type`, and `x, y :: f (a,b)`, fmap fst x = fmap fst y -&gt; fmap snd x = fmap snd y -&gt; x = y I wanted this to hold for any `Functor`, but I have a counterexample for it - this doesn't hold for any `Functor`. I want to know what condition I need on `f`. At least it holds for `Maybe` or `Reader e`. The counterexample is `f ~ Cont Bool`. x, y :: Cont Bool (Int,Int) x = Cont $ \k -&gt; k (0,0) &amp;&amp; k (1,1) y = Cont $ \k -&gt; k (0,1) &amp;&amp; k (1,0) fmap fst x = Cont $ \k -&gt; k (fst (0,0)) &amp;&amp; k (fst (1,1)) = Cont $ \k -&gt; k 0 &amp;&amp; k 1 fmap fst y = Cont $ \k -&gt; k 0 &amp;&amp; k 1 fmap snd x = Cont $ \k -&gt; k 0 &amp;&amp; k 1 fmap snd y = Cont $ \k -&gt; k 1 &amp;&amp; k 0 
Any particular reason that FP Complete (creators of stack and stackage) and Well Typed (cabal, hackage and GHC) seem to prefer to work on distinct tooling and infrastructure instead of joining forces? Would it have been possible for FP Complete to fund and support Well Typed to extend cabal proper with the needed functionality instead of inventing their own tool intended to replace cabal?
Please switch to LaTeX, its superior to Word and all its (re)incarnations. Check out [overleaf](https://pt.overleaf.com)
Thanks for this advice. I saved it as GitHub [issue](https://github.com/graninas/Functional-Design-and-Architecture/issues/1). I won't be editing the book in Word, it was a requirement from the publisher. For the first time I'll be using Google Docs to be able to share results immediately. But you right it should be converted to a more appropriate format on the post-production state.
Just give it some time. You'll get used to it and the points-free style will grow on you. 
Maybe your publisher has its own editing process (maybe even LaTeX?) You should ask him what format is suitable and if you can meet him halfway. 
Is there already an approximate but complete Table of contents? To have a feel of what would be in the book. 
&gt; to be able to share results immediately Overleaf and sharelatex allow exactly that.
Unfortunately I don't have a publisher now. I was writing this book during the 2016 year by the official contract, but the publisher decided to terminate the project (it was too long he said). So now I'm free in the decisions.
Yes, sure, there is a draft ToC that I need to rework. It contains 15 chapters but I think I should cut it to 10 chapters only. And also I got a fair amount of real world experience with the approaches I'm describing, so I have more topics to describe in the book. &amp;#x200B; [ToC draft](https://docs.google.com/document/d/1bh9Sa0rIGzU9Z88N_TJF6BtgHD_QLYdh1nK-yLKn_IU/edit?usp=sharing)
&gt; Stack however went from 0 to fixing all cabal issues in less than a year! Except it didn't fix them. It inserted itself as a middle-man between cabal and the user, and that development has only complicated the situation by adding another layer of abstraction. FPComplete didn't do this out of the kindness of their heart. That's not how capitalism works. It's not conspiratorial to question why they've put all this work into their own tool instead of contributing to the core tools, especially when down-thread I'm being told that the solution to stack not supporting my use-case is "Give FPComplete more money." The existence of v2 and it solving many of the same problems seems to point to the fact that this effort could've after all been put to use on the core tool instead.
My apologies. I appreciate you pointing out why my experience deviated from from your examples.
Judging by the style it looks like Manning.
Have you heard of Pandoc? It is a great tool that lets you convert from one rich text document type to another. Fun side note: it is written in Haskell. 
&gt; this means I get to code like it's 1994 It's not *that* bad. Even just Atom or neovim + ghcid goes a long way and takes no effort at all to setup. My preferred environment is haskell-mode for emacs, but admittedly there's a fair amount of bitrot there and I sometimes have to make random hacky changes to my workflow to make it not fall apart.
Can we see some example use cases?
My first instinct was 'use lens!'. But it isn't really worth it if lens isn't already used. My non-lens solution still feels pretty lens-y, though: data Foo = Foo { ident :: T.Text, key1 :: T.Text, key2 :: T.Text } deriving Show newtype TheData = TheData [Foo] deriving Show instance FromJSON TheData where parseJSON = parseFoos &lt;=&lt; validateStructure where validateStructure = isObject "IdList" &lt;=&lt; (.: "Collection") &lt;=&lt; isObject "Collection" isObject s = withObject s pure parseFoo idX values = Foo &lt;$&gt; parseIdent idX &lt;*&gt; values .: "key1" &lt;*&gt; values .: "key2" parseIdent i | Just rest &lt;- T.stripPrefix "ID" i = pure rest | otherwise = fail $ "format 'ID.*' for id's expected, got: " ++ show i parseFoos = fmap TheData . traverse (uncurry parseFoo &lt;=&lt; validateKeyValue) . HM.toList validateKeyValue (a,b) = (,)a &lt;$&gt; isObject "Values" b 
thanks for pointing that out, it's a serious omission. Junior (&lt;2 year exp): £40K-50K; Mid (2-5 year exp): £50K-70K; Senior(&gt;5 exp): £70K-80K I usually sort out salary requirements on the first call. It's also a waste of my time if we aren't in the same ballpark &amp;#x200B;
Yes, sure, I know about Pandoc :) That's a good idea actually. But you know the main problem is not styling or converting, but writing itself...
No free labour. It's a demo repo, not a real repo.. You would like to know more about the daily work and we would like to know more about your skills. Pairing on a demo repo with an engineer who already works here seems a good compromise. Sorry to hear you've had people extract free labour from you.
Well, yes, it was Manning. I have to be doing the docs restyling.
Interesting, I'll check it out then!
We don't have any requirements, but I would recommend students to follow [this guide](http://write.flossmanuals.net/gsocstudentguide/writing-a-proposal/) if you need inspiration.
It's a knowledge base, yes. There are lots of mind mapping apps that give you graphs where the nodes are phrases and the edges are unlabeled. There are a few where you can label the edges. That's as expressive as they seem to get. I wanted one where relationships could have any number of things (not just two) and involve other relationships. And then I needed a way to query it. This is those. 
Yes! Eventually ... I only just got this working, but once the workflow is a little faster and more expressive (right now it does not permit punctuation in phrases, which I need), I'll start using it.
Maybe the first common pain point that this solves is it lets you say things about the edges in a graph, in a searchable way. Data like these: ``` Cell X in this table is greater than cell Y because Cell Z is positive. Harry met Sally at the Renn Fair. The fact that this drug affects that disease is potentially money-making. One reason so-and-so plants are dying is there are no bees around here. ``` are difficult to encode in a graph. With a Rslt and Hash, not just encoding them, but then searching for them, is dead simple. For instance, this would encode the first statement: ``` /add /hash #cell x ##(is greater than) #cell y ###because #cell z ##is positive ``` and then this would find the reason for it (the statement to the right of "because"): ``` /find /eval /hash cell x #(is greater than) cell y ##because /it ``` Okay maybe not dead simple. I'm open to suggestsions. 
This confirms to me that you are being fed one-sided information from someone. /u/snoyberg has asked people not to speak about Stack like this and continue posting like you're doing. Both sides have actors that did not act ethically. Bringing Tony into this, who has nothing to do with the fight aside from a strong opinion, shows a disappointing lack of understanding of the situation. /u/sclv does his best, and is/was working without pay to keep things up and running, and you accusing him of sabotage (a dire take on the situation that was fixed almost immediately by him, with an apology and explanation) is not cool. It is not healthy or ethical to expect people to act as perfect automata. HVR and Snoyman have a well-known tiff over this, which resulted in Snoyman being banned from the cabal repos. If you dig, and you _ask questions_ about what happened, you will find similar links to shenanigans Stack developers and users engaged in, making your posts a useless and damaging perpetuation of a fight that no one wants to take part of.
&gt; more flexible queries at the cost of [speed] Currently yes, that's the tradeoff, but only because I haven't spent the labor-hours to optimize it that, say, Neo4j have. But I don't see any reason in theory that it couldn't be about as fast as ordinary graph or sql databases. I provided some use cases under [another comment](https://www.reddit.com/r/haskell/comments/av9jhz/an_extremely_general_data_structure_and_a/ehe0mll/).
Well, there's `hindent` and `stylish-haskell` too, but somehow I feel this won't change your view much, would it?
Awesome! I think the implementation part is very interesting but perhaps less lacking in other resources and thus less deserving of your efforts. But if you can put it in as well, the better! I am very much interested in your current 10 first chapters as they seem to be able to answer my main issue with Haskell : how to build big project when you don't have time to do bottom to top approach with a lot of refactoring on the way? Being able to carefully design a top to bottom architecture is something that I was able to do easily with imperative or OOP but that I find much harder with functional programming. Maybe it's only my lack of experience but it should be an interesting read either way! I'll see if I can support you on patreon (need to check my finances first!). 
&gt; Right account &lt;- getRight $ getAccount semuxApi delegate should be Right account &lt;- getAccount semuxApi delegate 
Why is \`String\` not an instance of \`Exception\`?
Thank you :) The first five chapters are already done, you can find them [here](https://drive.google.com/open?id=0B1Rdr1fbS6M9SjlKUk1zMVNjOVU). &amp;#x200B; There are some ideas I used in my real project, namely, Free monads. This approach allowed me (and my team) to create a comprehensive framework in Haskell for 4 months. With this framework, we created several applications that are multithreaded, support KV-database, have a safe concurrent state (with STM), have a configuration management system, are able to operate by network, and have many other features. The code is also testable, understandable and well-maintainable. The project is open-sourced ([here](https://github.com/graninas/Node)), and also I've described its usage, design and architecture in the big [article](https://gist.github.com/graninas/9beb8df5d88dda5fa21c47ce9bcb0e16). &amp;#x200B; Hope this will give you some insides for your task.
I think that's an interesting word choice: "inflates". Do you mean to imply that engineers do not provide value to the company worth the salaries that US companies pay their engineers?
Oops, yes
Those will indeed be cool :D Nearer on my radar are these: * A language for displaying query results. Currently all you ever see are the address on one side and the expression on the other. Eventually you'll be able to say things like, "If node X is in the relationship (X #is low-priority) then display it in gray", or "Make a column that displays a count, for each search result X, the number of (X #helps _) relationships." * A way to express implication, so that implicit relationships can be queried using only the explicit ones. * A way to express equivalence of relationships. If I write "x #likes y" and you write "z #enjoys w", and we merge our data, I'd like to be able to declare (if I think it's true) that my #likes and your #enjoys represent the same kind of relationship. * A way to encode things like each of those in the database itself. * A way to programmatically generate `Expr` values from natural language data.
Yep. HIE extension system is way beyond showing off the same old (if good) tools again and again.
I mean, come on, we finally **have** a single focus for effort where each new improvement will be reflected in all LSP-capable editors. Why waste time supporting only one of the pack, ignoring recent developments or trying to catch up?
I was thinking that in case of `Left …`, the `Right account &lt;- …` would throw an error that the result it not `Right`, while the `getRight` function I wrote – would throw an error describing what was the root cause.
I'm trying to figure out how to apply ghc's `-x` flag to files through Cabal. The problem is that the `-x` flag only applies to files which appear after it in the command line, while options provided through ghc-options are all appended to the command line after the files being built. I also can't use the flag in an OPTIONS_GHC pragma; ghc reports unknown flag in {-# OPTIONS_GHC #-} pragma: -x Any suggestions? 
&gt; Should `getLastCoinbase` return an `IO (Either String UTCTime)`, instead of crashing? Well, as of now, the app works like a script, so either way I would just `fail` that `Left` anyway… Was thinking about it a little: how should I handle all this if the app was an actual bot which is not supposed to crash. Almost anything can go wrong when querying remote services: should everything be wrapped within `Either` or some kind of `Result`… 
That is what I have observed when working with Elm: it was either failing the compilation or was working as expected. What a breath of fresh air…
ETAGS/xref?
Because understaffing, attempt to deliver consistent solution instead of constant catching up with the new trends and understaffing.
Probably to discourage libraries from throwing them. One string can't be distinguished from another by type, which it is primary way Haskell prefers to distinguish exceptions. Feel free to use this orphan in your applications: instance Exception String where displayException = id
That counterexample doesn't look like a counterexample to me. One of the premises (fmap snd x = fmap snd y) doesn't hold, so the implication is still true even though the conclution (x = y) is false.
Your **Wedge** reminds me of the [semi-iso](http://hackage.haskell.org/package/semi-iso) package. They also couldn't find an established mathematical name for that construction :)
Nice. I recognize that type as the "reactive monad" -- I know a group at the University of Missouri studied that several years ago, Harrison, Procter, et al. http://hackage.haskell.org/package/monad-resumption-0.1.3.0/docs/Control-Monad-Resumption-Reactive.html
Word is fine. https://reddit.com/r/Surface/comments/atr01z/_/eh3orht/?context=1 
Was hoping someone could straighten me out. I wrote an trivial function that takes some IO String input, tries to use readMaybe to initialize a `Maybe Day` via the Data.Time library. Then spit it out. I've managed to get things to the point where I can initialize a Maybe Day from user input, and it'll print it to the console. At 1), I understand here we've got a Maybe (Maybe Day) At 2), shouldn't maybeDay be "assigned" a value of (Maybe Day) that I can then use? At 3), finally worked out the type signatures and realized putting pure gets the `Maybe Day -&gt; IO (Maybe Day)`? ``` import Data.Time test :: IO () test = do putStr "Enter day: " day &lt;- readMaybe &lt;$&gt; getLine putStr "Enter month: " month &lt;- readMaybe &lt;$&gt; getLine putStr "Enter year: " year &lt;- readMaybe &lt;$&gt; getLine -- Gives me a type error about -- expected type: IO (Maybe Day) -- actual type: Maybe (Maybe Day) 1) maybeDay &lt;- fromGregorianValid &lt;$&gt; year &lt;*&gt; month &lt;*&gt; day -- So I figure I need to flatten the value returned from fromGregorianValid... -- If I add a `join` to flatten the `Maybe (Maybe Day)` I get error -- expected type: IO Day -- actual type: Maybe Day 2) maybeDay &lt;- join $ fromGregorianValid &lt;$&gt; year &lt;*&gt; month &lt;*&gt; day -- But shouldn't this just result in maybeDay having the type of `Maybe Day`? -- But ok, so I'm going to use pure to return it as an IO Day? That works, but -- I beat my head against the need for the pure call in order to get it into an IO. -- surely there's a more idiomatic construct I'm missing? 3) maybeDay &lt;- pure $ join $ fromGregorianValid &lt;$&gt; year &lt;*&gt; month &lt;*&gt; day -- Then this works fine print maybeDay ``` 
This has some similarities to first order logic which seems to be more expressive in some ways (e.g. quantifies) but less in others (esp. being *first* order). The use cases you mentioned seem to fit into the logic domain too. Unfortunately FOL is undecidable if it is not restricted in some way. This an advantage of your system. Therefore several description logic systems were developed with decidability and even speed in mind. But they are less expressive than FOL. A powerful DL reasoner is for example FACT++ (http://owl.man.ac.uk/factplusplus/) and a nice GUI is Protege (https://protege.stanford.edu). Maybe this helps to put your approach in context. 
Thanks for your answer. I thought about this in the meantime, I think I need to rephrase the question: Is the guiding principle behind *NOT* making `String` an `Exception` instance really proven to provide a guideline for good software practices? What's making it hard or wrong to hijack `Exception` for generic errors? Or maybe, is `ErrorCall` a candidate for the cases where I would throw a `String`? There are so many cases where no detailed exception type hierachy is required, and I just want to interrupt the control flow, with the option to either catch the interruption and try an alternative or exit with a nice error message, or catch the error to enrich the error message with some more context before rethrowing the error, and I find myself using `show` or `displayMessage` all the time. Of course there are enough reasons to use typed exceptions for the control flow, but that's often enough not the case. What I have read so far on Exceptions in Haskell, created the impression, that the distinction between *checked* and *unchecked* exceptions, commonly known in developer folklore, is somewhat reflected by typed *`MonadError`* exception handling and *dynamically* typed *`MonadThrow`* style exception handling. Since the later wraps exceptions in `SomeException` and allows generic handlers to print error messages and to leave the context (e.g. exit the program), and since I repeatedly find that boldly crashing instead of cowardly swallowing runtime exceptions is a healthier pattern in our software, I thought that __not__ making `String` an `Exception` instance is both dishonest and bad implicit advice. I saw many cases where a simple, generic and merciless exception handling provided great insight into what went wrong in production code, and I saw some cases where the handler would just restart a crashed computation with success, in many cases, the exception handling that helped me most, was focussed more on logging, clean shutdown and restarting/resetting the component that crashed, i.e. code that *was forward oriented* into a bright future, instead of having to carefully setup specific logging, cleanup and restarting procedures depending on the specific exception type.
The Tony Morris Setup.hs also seems like a pretty harmless joke. Calling it "malicious" is so goofy.
&gt; Is the guiding principle behind NOT making String an Exception instance really proven to provide a guideline for good software practices? I think so. Exceptions are a non-local control-flow structure; specifically, they are designed to be caught. Anything that makes it easier to catch the specific exceptions you can handle/recover from is good, and Haskell uses types to guide this. If you just want to print a message and kill the process so *that*, and don't engage the exceptions infrastructure. &gt; is ErrorCall a candidate for the cases where I would throw a String? That's basically what error does. `error` does use "impure exceptions", which are a slight complication on the `IO` based exception handling. You could use something like: errorIO = throwIO . ErrorCall Java has checked exceptions (Exception and non-RuntimeException decendants) and unchecked exceptions (Throwable and non-Exception and RuntimeException decendants). C++ has unchecked exceptions and exception-free code (std::nothrow). In both checked and unchecked, you name the type of exception you are dealing with for any handing/recovery, though not blind propagation. In checked, you also have to list exceptions you might propagate. In exception-free code, exceptions won't transfer control out of the code. Something like MonadError is checked. Something like IO exceptions is unchecked. Something like impure exceptions is severely unchecked. With impure exceptions, we don't actually have exception-free code in Haskell, though you can often pretend we do since pure code isn't supposed to leave evidence that it was run or not.
I did not find as much as I hoped, at least use `let`: https://repl.it/@sheyll/date-time
I'm on old reddit so your formatting is a little messed up. (Triple-backticks containing empty lines don't work on old reddit.) At (1) you should use `let x = expr` instead of `x &lt;- stmt`. Since this particular `do` is in `IO`, you only use `&lt;-` when you want to bind the result of an `IO` action. At (2) `join :: Monad m =&gt; m (m a) -&gt; m a`. `m` can't be two different things so you can't feed it an `IO (Maybe Day)` or a `Maybe (IO Day)`. You *can* feed it a `IO (IO Day)` (to get an `IO Day`) or a `Maybe (Maybe Day)` (to get a `Maybe Day`). At (3) `pure` or the older `return` are the idiomatic ways to lift a value into a applicative/monadic context. But, often they are written on a line by themselves. Here's my attempt at your code: test :: IO (Maybe Day) test = do -- do block in IO monad putStr "Enter day: " mb_day &lt;- readMaybe &lt;$&gt; getLine putStr "Enter month: " mb_month &lt;- readMaybe &lt;$&gt; getLine putStr "Enter year: " mb_year &lt;- readMaybe &lt;$&gt; getLine pure $ do -- do block in Maybe monad day &lt;- mb_day month &lt;- mb_month year &lt;- mb_year fromGregorianValid year month day {- ^^ no pure because result already in the right monad -} The last bit (with the nested `do`) could be changed to: pure . join $ fromGregorianValid &lt;$&gt; mb_year &lt;*&gt; mb_month &lt;*&gt; mb_day --- You could also combine the two monads into a single monad using the `MaybeT` monad transformer test :: MaybeT IO Day test = do liftIO $ putStr "Enter day: " day &lt;- readLineMaybeT liftIO $ putStr "Enter month: " month &lt;- readLineMaybeT liftIO $ putStr "Enter year: " year &lt;- readLineMaybeT MaybeT . pure $ fromGregorianValid year month day where readLineMaybeT = MaybeT $ readMaybe &lt;$&gt; getLine (Though do note that it handles "effects" in a different order; try entering a non-numeric month in one vs. the other.) HTH
&gt; Patreon page: https://www.patreon.com/functional_design_and_architecturePaypal donations channel: paypal.me/graninas Would one receive the same benefits while donating via Paypal as if one were to donate via Patreon? Which one do you prefer?
Does this have anything in common with [olog](https://math.mit.edu/~dspivak/informatics/olog.pdf)? (I mention it since categories can be thought of as generalizations of graphs which is what your system is) This looks super neat, I'm definitely going to take a look :)
Nice work! A couple misc things I noticed. You have: solution lastCoinbase where from = max 0 (lastTx - pageSize) txRange = (from, lastTx) solution :: Maybe Transaction -&gt; IO Transaction solution (Just coinbase ) = return coinbase solution Nothing = if (from &gt; 0) then findLastCoinbase from else fail "No COINBASE found" but I think you want to use a `case` statement, like this (notice you can combine guards and `case` which can be really powerful. case lastCoinbase of Just coinbase -&gt; return coinbase Nothing | from &gt; 0 -&gt; indLastCoinbase from | otherwise -&gt; fail "No COINBASE found" where from = max 0 (lastTx - pageSize) txRange = (from, lastTx) In DIscord.hs you have _ &lt;- httpNoBody request return () but this is better written `void $ httpNoBody`.