unsafePerformLawnMow
Whee, haskell golf. Here's mine: import Control.Exception import Control.Monad import Control.Concurrent import Data.Maybe import System.Process import System.Environment scheduler n ts = do s &lt;- newQSem n sequence [waitQSem s &gt;&gt; forkIO (t `finally` signalQSem s) | t &lt;- ts] replicateM_ n (waitQSem s) main = do as &lt;- getArgs cs &lt;- getContents scheduler (fromMaybe 3 . listToMaybe . map read $ as) [runCommand c &gt;&gt;= waitForProcess &gt;&gt; return () | c &lt;- lines cs]
I had checked the examples of the first release, but never got further, I don't remember why.
Seems like an awfully simple program to draw any conclusions. E.g. that the type system didn't help with correctness (this is expected since you're writing essentially imperative code - the meaning of your program is in sequencing, not in expressions - write something with more "business logic" and you'll see a different result).
Stop the presses!
Downloaded the last version and struggling to compile it, I don't have all the headers for Qt and Kubuntu 8.10's Adept Manager is awfull to search a package :( (or I'm stupid, a not so improbable reason)
It just lays around in the garage until you **tell** someone you've mown the lawn.
But qtHaskell itself is GPL
&gt; roconnor: [after a long -cafe thread on the suckiness &gt; of using math terms in Haskell] we don't use Integer &gt; anymore. Too abstract. It is now called CountingThingy. I had missed that one. ROFL !
&gt; My intention is to at some point encode these steps in a tool so that I can spew out Debian packages for all interesting packages on HackageDB at the press of a button. Of course that tool will be written in Haskell, and it sure won’t rely on Python for any part of the process ;-) Phew! I was worried for a little while.
Actually, it's not until some one looks at the lawn... even then it's only the parts that they look at (the lawn is a lazy structure).
And now we trace this back to the big bang. Apparently that was a thunk waiting to be evaluated. God looked at it and now (he|she|it)'s dealing with a universe-sized space leak.
Right, and since all programs will need to do some IO, simple programs have disproportiantely high contents of IO (this one does pretty much only IO). For larger programs the difference becomes more apparent because you'll write data structures and algorithms too.
I want the matching C# for Haskell programmers series please!
all those "classes" and "objects" are just named too scary, they should name them warm fuzzy things and warm fuzzy things instances.
This is a bloody awesome and enlightening example of using monoids.
This is probably one of my favorite Haskell articles that I've read to date. These articles show us less advanced programmers incredibly beautiful ways of writing useful code.
[Abstract](http://www.cs.kent.ac.uk/people/staff/oc/Talks/ifl2008.html)
if only I could get a haskell job as an advanced beginner.
Perhaps we can get this changed now that Qt is LGPL?
Yo dawg.
http://hackage.haskell.org/cgi-bin/hackage-scripts/package/thih As a package.
BEHOLD! THE POWER OF HINDLEY MILNER!
I like this post, but I always find these literate posts sort of hard to read with the code all spread out. I wish more people would attach source files at the end with the code formatted as they would have left it were they not also writing the code as part of a post.
Yep, and this is in the most general sense as well. Any preordered set, that is, a set S together with a relation &lt;= which is reflexive (that is, a &lt;= a for any a in S), and transitive (that is, a &lt;= b and b &lt;= c together imply a &lt;= c for any a,b,c in S) can be considered as a category whose objects are the elements of S, and which has a unique arrow a -&gt; b whenever a &lt;= b. Functors F: C -&gt; D from one preorder category to another are monotone maps, since they send arrows a -&gt; b in C to arrows Fa -&gt; Fb in D, so just reinterpreting this: if a &lt;= b in C, then Fa &lt;= Fb in D. (The functor laws trivialise.) Given two functors F,G: C -&gt; D, that is, two monotone maps, a natural transformation eta: F -&gt; G simply means that for every a in C, we have Fa &lt;= Ga. (And the commuting square again trivialises, because these are preorder categories, so if diagrams exist, they commute.) So a monad M is a functor C -&gt; C, that is, a monotone map, together with natural transformations: * eta: 1 -&gt; M, that is a &lt;= Ma for every a * mu: M^2 -&gt; M, that is, M(Ma) &lt;= Ma for every a This is the very definition of a closure operator. Moreover, by a similar process, it's fairly easy to see that adjoint functors provide a Galois connection. The fact that the composite of two adjoint functors gives a monad (or comonad, composed the other way around) directly gives the fact that the two parts of a Galois connection give rise to a closure operator (or interior operator, the other way around).
Haha. I'm EECS with CS concentration and I didn't take Java. I'd pick it up in a day if needed, but I see no use for it right now. On the other hand, I taught myself haskell because it's beautiful, although haven't used it in 'production' code yet. Drop job offers here -----&gt; `[_INBOX_]`
&gt; By analogous to newtype wrapping, I mean the following. Ah, that makes things clearer. I don't think I've seen anyone being explicit about those steps, but the repackaging is similar (and just as ugly :) &gt; I generally agree with what your response, however you perhaps focus &gt; too much on implementation specific details. Sure, dictionary passing isn't the only way (nor even the best way). But it is perhaps the easiest. Abstract algebra often defines things as a tuple of such-and-such, which are pretty easy to translate directly into dictionaries. N.B. I mean *conceptual* dictionaries, not records as an implementation strategy. The problem still remains that type classes in Haskell are defined as functions (rather than relations) from contextualized types to dictionaries of methods, regardless of how those "dictionaries" are implemented. While the newtype approach can be used to work around this limitation, it looses the elegance of Haskell IMO. It's like writing only monadic functions and making people use Identity and runIdentity if they want to get back to pure versions. Sure, it's doable maybe even correct, but it takes something which is novel and elegant (typeclasses; monads) and bludgeons them into service in places where they're not so elegant anymore. When trying to expose people to the novelty, this doesn't help our case.
I mentioned in a recent interview that I was learning Haskell in my own time. The (senior) interviewer asked: "Pascal?", and despite my further explanations I didn't get the job because I was "not cognisant with the latest technologies". 
Yeah I get that about half the time I mention it (which I do a lot :) ). For this reason alone I think I'm going to start refer to it as hask-ell (as in L). I'm surprised someone hasn't said something like "wow all twenty haskell users applied both times?" ;P
&gt; Only on MacOS does the LLVM package give you fast primitive functions, because that's the only platform that seems to have this as a standard. That's really a shame. I hope LLVM doesn't end up favoring OS X.
This fits with our experience (gamr7.com). Putting Haskell on top of the ad, is a good way to get brillant people.
Yes they are :) In general, though, the duplication of interface among modules is worrisome. Not the name clash itself, but that we don't systematize it at all, and there's no way to retroactively apply any sort of systematization.
Got any yet?
I agree ! The ability to implement algorithms working on a whole range of algebraic structures with type classes is mind-blowingly neat and useful !
And it would be nice if both qtHaskell and gtk2hs would be cabalized
Why not? If he is new to Haskell he is probably not new to programming.
Haskell programmers &gt; Chuck Norris.
Apple is favouring LLVM; i.e., they seem to put serious resources into it. That'll show.
Also see: http://web.cecs.pdx.edu/~kennyg/house/ I hadn't ran into this page before.
I've always heard it pronounced more like hask-ull. Does anyone pronounce it in a way that rhymes with Pascal?
Damn. I was looking forward to skimming the new docs. ;)
He is probably new to functional programming, though, and his first steps in Haskell should probably deal with things that functional programming is naturally good at dealing with. GUI programming isn't one of those things.
Someone want to have a go at a `par` monoid...?
The relationship to the mathematical formulation is somewhat indirect. If you use a language with a real module system like ML, then each monoid would be a different module that just happened to share a type. You'd have to manually invoke the operations out of the module, putting a lot more burden on the programmer for the common cases where Hindley Milner can figure out unambiguously what types are involved and plumb the dictionaries around for us. In Haskell, we just use newtypes to choose between different implementations when faced with multiple potential definitions for a typeclass over a type and because Wadler's magical typeclasses work so well for most of the cases, its a burden we rarely feel. On the other hand, an ML programmer is always thinking about the modules he is plumbing around.
My observation is that post-interview feedback is lousy at best.
&gt; As stated previously, House doesn't support file systems and the files must be loaded in memory by Grub. Then, you can do "run prog_name" in the shell. ok, now tell me why this shouldn't make me think that haskell is just an academic language not suited for real world applications.
Because this should make you think House is an academic OS not suited for real world use.
Why did you bother submitting this to reddit ?
It's quite a long paper (pdf).
&gt; I kind of wonder whether Haskell [which I do believe to be God's own language] is going in the right direction. Or rather, whether they shouldn't just bite the bullet and become a lazy version of Coq. The power of the system that Tom presented was pretty terrifying, and as one of the questioners noted, it's now the case that programmers have to do alot (e.g. provide proofs...) That's an interesting observation, but I'm not sure which wrong direction he thinks Haskell might be going in...too many experimental type system extensions which make it impossible to grok the whole thing without massive effort? I suppose that makes sense, but it's all optional. It's not the case that programmers now *have* to provide proofs, just that they can (or will be able to) if they want, which has to be a bonus.
Problem is people pronounce Pascal multiple ways as well. I've definitely heard Pask-ull before. And yes I believe Hask-ull is the 'correct' pronunciation. Still, I think in this case the exchange of correctness for clarity is a good one (rather unhaskellish sentiment tho)
ohh that was the idea, I got it wrong I'm sorry I thought it was a real OS. btw thanks for the answer, downvotes are less explicative lately.
Maybe I'm easily impressed, but after giving Parsec a whirl for a side project over the holiday, I was blown away. It's just so *easy*.
What do you mean exactly? Data Parallel Haskell already does what sigfpe is referring to in this post.
Not quite. (I've worked on the DPH project :) I was thinking more about a ParMonoid, that was pure, such that uses of `mappend` were computed in parallel.
Any takers? :)
I attempted this, and I now don't think it is as great as it sounds. The problem is that the only way to arrange for maximal parallelization is to accumulate the entire sequence of values (with the par monoid's `mappend`) then use a parallel divide and conquer strategy to fold the sequence to a single value. This is the only way to get any use out of it where you would otherwise just have sequential `mappend`s. This has obvious problems: all the input values are saved up during execution until the final value is needed, they are *still* not released if this is meant as an accumulating value of any sort, and such accumulating values must be recalculated every time they are needed. We could have a monoid where `mappend` simply evaluates its parameters in parallel, but then we still gain no benefit from sequentially `mappend`ing values such as in a list. This approach would really benefit most when applied to a tree. Then again, if we go to this much trouble, why can't we just make the `fold` algorithm over the tree special rather than the `Monoid` instance? In fact, perhaps this idea would be a lot nicer as a `Foldable` than as a `Monoid`.
[citation needed]. In my opinion, writing UI with Gtk2hs was a pleasure compared to any non-IDE-based GUI library I've ever used.
I wasn't aware it was ever dead...
Relational theory is where the idea comes from. I like to read → as ‘determines’, so that class Foo a b | a → b where ... Reads as a class Foo with parameters *a* and *b*, where *a* determines *b*.
gonna czech this out, been meaning to try out happs 
Here's the link in HTTP instead of HTTPS, so Firefox 3 won't complain of security certificates: http://www.joachim-breitner.de/blog/archives/317-darcswatch-uploaded-to-hackage.html
In this case, the code is intended to be a part of the explanation. In fact, it won't even compile as it is without a few amendments. I think that trading code for words has merits. For instance, I don't describe the algorithm for finding the n-th leaf in words because I think that such a description in natural language wouldn't be easy to understand either. Instead, I simply point to corresponding code. &gt; Given size annotations, we can now find the n-th leaf: &gt; &gt; (!!) :: Tree Size a -&gt; Int -&gt; a &gt; (Leaf _ a) !! 0 = a &gt; (Branch _ x y) !! n &gt; | n &lt; tag x = x !! n &gt; | otherwise = y !! (n - tag x) Of course, this requires that the code is simple and crystal clear, but that's the goal anyway. 
Neither was anyone else, but we learned today that it has, in fact, been orphaned for about a year. Lazy eval spilling over to real life. Welcome to Haskell.
Because that would be stupid?
Completely ripped off GitHub. Man, they are totally going to get SUED.
I know nothing about HAppS -- what makes it more innovative than Turbinado, as the article states? What does it use instead of a RDBMS?
Oh no, don't misunderstand my sentiment. I think having the code inlined with an explanation of what's going on is very useful. It's just that I like to jump around to reread different function and data type definitions, in part because the names used, while meaningful, aren't always descriptive of the behavior or components. I suppose I should really just get used to using the page mark feature of vimperator more.
Stealing ideas from RoR? Turbinado is hardly innovative.
Sued for what? Copying an idea? The US Supreme Court recently ruled that most patents on business methods and pure software are invalid - so even if github have patented their ideas, they're probably still OK.
HAppS is the entire web stack besides the operating system. That includes the web server, database, everything. Everything is stored in RAM, and the hard drive is used only for persistent storage in case of reboot. The database is nothing more than type-safe, transactional storage, and I must say it is fun to use. HAppS is very fast, supports multimaster already, and was supposed to have sharding soon, unless these rumors of HAppS being dead are true. It is *very* different from most other frameworks we have today.
Can't be true. I see darcs patches in the official repos as late as November 2008. darcs is a distributed VCS after all. It is likely that there is a ton of work on a few other machines that just has yet to be integrated with the mainline, although I haven't *actually* checked with the maintainers.
Ah, alright, I think I understand what you mean. Happens to me as well; at some point, enough new definitions have accumulated that having to scroll back to recall them is unavoidable. Not sure what to do here, this seems to be quite universal in technical/math articles. Reading a version on paper usually helps, I plan to add proper printing support to the CSS anyway. An idea for the screen would be to hyperlink definitions. Just for the record, can you remember the definitions which you wanted to look up? 
Well, one that I definitely wanted to try and... "mentally decode" was the `measure` definition in the `search` function presented at the end (applying it to just the tree type for example). So I had to jump back to the instance definition for the tree, which defines measure as tag, and then back again to the original definition of tag. I mean, of course the definition of tag is very simple, but I guess I don't have enough spaces in my head to remember it from earlier in the article.
Thanks, sounds interesting.
There's lots of interesting work being done in multi-core computing right now. The OS that I've been working on is written strictly for multi-core systems. If you don't have to support legacy, why do it? 
Have you heard about sarcasm?
Yes, I have heard of it.
sucks to post blogpost where someone spelled your name wrong.
There are patches that Lemmih has been committing in his free time. Lemmih was hired by Alex Jacobson to code. Lemmih is no longer coding full time. Yes some patches have been accepted but no major work has been done in awhile.
Doesn't commutation break the definition of the monoid?
But nothing necessarily wrong with that. Haskell does need easy to use Web frame works. Happs is bit too different. It would easily scare LAMP people away.
*shameless LOL*
Just say no to posting self-signed HTTPS URLs, thanks to Firefox 3's policy of spoonfeeding mashed security prunes to users.
What kind of things can you do if you require multi-core that you couldn't do otherwise?
It's not a matter of being able to do more, so much as it is the fact that we wanted to do something cutting edge. It's more of an extension of our commitment to supporting the latest and greatest than it is an expansion of ability. We can write things with multi core in mind. It's an [exokernel](http://en.wikipedia.org/wiki/Exokernel)... so we're already treading on a lot of fresh ground. In fact, multi-core scheduling is one of the things we're currently working on. Our kernel schedules one core like a champ, but we're working on it. 
Also, type synonym families are a more functional (as opposed to relational) way of doing this. The same class `Foo` could be: class Foo a where type Bar a ... and now everywhere you had *b* you now have *Bar a*. A concrete example: class Container a b | a -&gt; b where contains :: a -&gt; b -&gt; Bool becomes: class Container a where type Elem a contains :: a -&gt; Elem a -&gt; Bool
Why does it have to be a monoid? It seems that only associativity is used, so semigroup should be enough. Or did we use the neutral element somewhere?
Cummutativity is not a prerequisite for this. Only associativity.
D'oh, I think I misread compute as commute...
The problem with such approach is that you guys assume that the web application is the ONLY application that will have access to data. While in real life web application is just one of many windows into that data. RDBMS allows many applications share the same database, even such tools as Crystal Reports, that are widely used by department managers. While your MACID store will be unaccessable to anyone else except you. So, does HappS forces developer to use its storage, or can you develop in it, excluding MACID and using an RDBMS instead ? 
This time without self-signed certs.
Most large web applications end up using an architecture in which all other programs just use the web service itself as its interface to the data (via JSON, XML, whatever). Consider a heavily denormalized database as you would normally find in a large service. Every single program that interfaces with the database directly has to maintain the integrity of the data. This becomes quite impossible after a while, so the maintainers eventually suck it up and use the web service itself, putting all the code necessary to maintain the database in one abstraction. HAppS is designed for this right from the beginning. (And to answer your question directly, yes, you can choose not to use HAppS-State and use a RDBMS instead.)
what would be stupid? I didn't checked more about the project, I only did after [tommd's comment](http://www.reddit.com/r/haskell/comments/7rccs/house_the_haskell_os_lives_on/c076qg5) and then found this: &gt; House is a demo of software written in Haskell, running in a standalone environment. It is a system than can serve as a platform for exploring various ideas relating to low-level and system-level programming in a high-level functional language. [here](http://programatica.cs.pdx.edu/House/) which explains why this "OS" lacks something so basic as support for filesystems, which only makes sense if this project is not meant to be used by the general public. that's all guys, you have to talk more! not everyone on the web is trolling I really wanted to know what I meant on the original question because I keep hearing that "haskell is academic" and being an xmonad user I don't think that but then this article seemed particularly odd.
…I don't know the Markdown for sarcasm…
We could proactively do it? base-5.0? :)
As SPJ says, ‘avoid success at all costs’.
totally insane indeed. maybe I will be able to grok this in the morning.
while I understand how it works, I doubt I would be able to come up with this code myself.
Upmodded as a kubuntu user that would love to see things improve for his distro.
Just be lazy and it comes naturally :-)... E.g. to normalize a list (divide each element by the sum), you could do a pass through the list, divide each element by "some number" that's passed in, and also return the sum. E.g. norm :: [Float] -&gt; Float -&gt; ([FLoat],Float) norm [] div = ([],0) norm (x:xs) div = ( x' : xs', s + x ) where (xs', s ) = norm xs div x' = x / div This is completely trivial. You could call it by first computing the sum of the list and then pass it into norm as the "div" parameter, but because you actually return enough data to compute the average you can "tie the knot". let ( result, s ) = norm xs s in result So all you need to remember is for the "worker" to return enough information to compute the input, but while you're writing the worker you can pretend that the input was computed in a separate pass, and then you tie the knot at the end.
Ah, `measure` on trees. I could have left it out entirely and used `tag` instead, but then opted for inclusion because it has independent meaning as "combination of all `measure`s of the elements". At least, that's my shortcut for memorizing it; my head doesn't have enough space either. Hm, also, it's tricky to know what to memorize when reading it the first time. For instance, `head` can be forgotten immediately while `measure` on trees is worth keeping in mind. In any case, it's unavoidable that reading any article is hard work. :-) But the author can help to make it easier. Thanks for the feedback!
You do? Really? :-)
Well, I really wouldn't worry about it too much. Generally, I was just saying that while I do think literate programming is very worthwhile, having runnable, as-if-it-were-in-my-repo code to also look at can make comprehending the lesson easier.
From TFA: "However, if I wasn't clear enough, I want to make it clear that I'm only studying House as a hobby project." Sure. "just a hobby, won't be big and professional like gnu" right? I think I've heard this somewhere before...
&lt;/sarcasm&gt;
The game theoretic semantics: * `∃x.P` = "if you want your `P` you must ask me for an `x`" * `∀x.P` = "whenever you give me an `x` I must hand out a `Q`"
1. Monoids are general enough to be popular in category theory. 2. I take that by "neutral element" you meant "identity element". Of course you need identity elements, otherwise you can't make/initialize an empty structure.
It's like types too :- A+B = "I will give you either an A or a B - you can't choose, only one is available" A*B = "I will give you either an A or a B - you choose, both are available" 
Nice summary of the languages he presented. You could go on and on about how some pet language wasn't included, but it seemed to cover almost all the majors, except maybe PHP, but I can get behind that omission.
Cryptol has a Haskell backend. I wonder if we can populate the cryptography libraries cheaply this way...
It shouldn't be in the Haskell subreddit, and it doesn't seem totally informed (judging from the comments) 
Are you able to produce benchmarks? It is important that we not use O(n) memory or fall outside of 4x slower than OpenSSL for a pure crypto library. Obviously many users don't care about crypto speed much (darcs) while others wouldn't be happy even if its within 30% of OpenSSL. But I think many people wouldn't mind the trade-off if it allowed supreme portability.
Hey all. I wrote this because I wanted an easier/more efficient open source VPN to play LAN games with (which is why there's no focus on security or encryption...yet). All criticism is welcome (I'll take the criticism more seriously if it is also accompanied by patches).
Prophet Luke goes at it again.
Glad to hear we've got more options opening up. ODBC never really feels right to me. Although, I could have used this two weeks ago.
Actually, in this specific blog post, trees are defined so that there is no empty tree. But yes, I now see that in general we may want to allow an empty structure.
great post sigfpe, this owns
Hey guys, it would be useful for the Haskell reddit to know why posts are downmodded. Feel free to explain for what you downmodded a post, rather than just skipping it. It will help me improve quality and relevance. Thanks! &gt; up votes 5 down votes 3 Moments later, &gt; up votes 9 down votes 7 Now, &gt; up votes 10 down votes 8 That's more downmods than the entire Haskell reddit has received in months. Something fishy going on...
I'm having a hard time seeing the relationship between what Haskell is good for and the tags used by people writing packages using it.
The size of the tags indicates in what area multiple people have had success, or chosen to use Haskell. The data is taken directly from the category tags on Hackage. Let me know if you think there's something flawed in doing that. ---- *Awesome, I'm getting downmodded! That'll learn me for writing about Haskell. Good work!*
Great news. Curiously, when I submitted the news the day before yesterday, it was downvoted
He doesn't even quote *Programming Perl*, from where this "third virtue" come: &gt;We will encourage you to develop the three great virtues of a programmer: laziness, impatience, and hubris.
best post in a long time!
Really glad to see this finally happen. :] Cheers!
But did you [make the tag cloud with Haskell](http://www.dougalstanton.net/blog/index.php/2008/09/19/head-in-the-clouds/)? ;-) I don't know if Brent Yorgey's `diagrams` package has all the additions I made to cope with [my code](http://www.dougalstanton.net/code/diagrams-examples/). If not you can pull the changes from [my private repo](http://www.dougalstanton.net/code/diagrams-hack/).
Any chance you'll break this out into component libraries and an executable? I'm thinking something like: Nework.TunTap Network.Tunnel.Generic -- Scurry, but as a library ... and the executable And I just can't resist: "Yo Dawg! Sw17ch heard you like packets, so he put a packet in his packet so now you can decapsulate after you've decapsulated."
Yes, I'm planning on doing that. First, I'm going to write a thin C library that will talk to the various tun/tap devices cross platform. (Check out the help-win.c file, it's horrid stuff to get working. PS: If you don't use the overlapped IO, it takes multiple seconds to read a packet... I don't know why.) But yes, once that C library is written, I'll make Network.TunTap and then move on to different pieces from there. :)
It's the leap from "somebody used x to write code to y" to "x is therefore good at y" that I have trouble with. Disclaimer: I'm not saying that Haskell isn't.
This was written in 1994... what has the fallout been? Is this implemented? If not, why not?
I guess the problem described in the paper (specialisation across module boundaries) is the reason why it's not been implemented.
Specialization is done, but as mosha48 mentioned there are cross module issues. To manually alleviate cross module issues you might run into, you can use the [SPECIALIZE pragma](http://www.haskell.org/ghc/docs/latest/html/users_guide/pragmas.html) in GHC. In real life this problem does continue to show up. Just see [this recent example](http://www.mail-archive.com/glasgow-haskell-users@haskell.org/msg15537.html).
better suited to the general programming reddit.
no content
I'm a noob learning Haskell, and this turned out to be very helpful (sorry, skipped the Perl example). It does make me wonder, however, if maybe I'm not smart enough to be a Haskell programmer after all; I had to reason through that last function for a solid half hour, checking types of all the various things, trying out chunks in ghci, etc. But now I feel I have a solid handle on it and could explain it to someone else if need be. Question: when the problem was first presented, my impulse was to iterate through the list backwards, checking to see if the current was a prefix of the former. However, Haskell lists are singly linked, so you can't iterate through them backwards. Would this be a reason to use an array here, or is there really no performance problem with just doing `sortBy (flip compare)` as in the example? (In retrospect, I wonder if it would just be possible to build the list backwards in the first place, obviating my question...)
I get the same self-doubt all the time when learning Haskell, but I think (like your experience in working through this function) it's really worthwhile when you get it! Don't think you need an array: building up the list "backwards" by consing the new element to the beginning is a common pattern in FP style. In fact I mentioned that the result list was reversed respective to the Perl version precisely because I was building up like (item:list) instead of appending (@list,$item).
This is great! Whatever you may say about MySQL, it is ubiquitous. So it's really important to have a driver.
cool, although it seems that assert would be more convenient as assert :: (a -&gt; Bool) -&gt; a -&gt; a
Well, yes, but you can easily write that yourself. I call it "asserted" - it follows the naming scheme of an analogous monadic helper function I wrote, "guarded" (which corresponds to Control.Monad.guard).
You don't need a *global* variable. Furthermore, this pattern can almost be stuffed into a function as demonstrated here. memoFix2 f = h where h x y = table !! x !! y table = [ [f h x y | y &lt;- [0..]] | x &lt;- [0..]] binomial' :: (Int -&gt; Int -&gt; Integer) -&gt; Int -&gt; Int -&gt; Integer binomial' binomial n k | k == 0 || k == n = 1 | k == 1 = toInteger n | otherwise = binomial (n-1) (k-1) + binomial (n-1) k binomial = memoFix2 binomial' where memoFix2 has the same interface as Data.Function.fix, and "fix binomial'" produces the normal, non-memoizing, slow version.
[OCaml version](http://nopaste.biz/63845) for the interested.
Hm. Does that diminish the usefulness of this rewrite? i.e. if something you "asserted" fails, does the error point to what called "asserted", or just always point to "asserted" itself...
Good point - I didn't think of that. I guess I could implement it as a CPP macro instead (ugliness!)
I don't like that tabify. seems unfunctional. how about concatMap (\x -&gt; if all isSpace x then "\t" else x) . group if there was some base library fun for that pattern \x-&gt;if p x then f x else x, it would look better than english explanation. and this is haskell. when you can't explain/comment your code better than the code itself.
Well, the point here is that *lots* of people used *x* to code *y*, so we can infer something.
Lambdabot uses `if'` for that, but it doesn't seem to be part of any standard library.
Happstack (the successor to HAppS) is dropping the SMTP and DNS packages. Also, I think I addressed alot of the counterpoints in this article here: http://softwaresimply.blogspot.com/2009/01/happstack-interview-with-matthew-elder.html
HAppS did not include SMTP, DNS or IRC. And in-memory state was the defining feature of HAppS.
I love how SPJs energy comes across even in text :)
There wouldn't happen to be an audio or video recording of the panel?
OCaml cannot garbage collect shared mutable state but that does not mean it does not support SMP: you can still write parallel programs in OCaml. 
Using OS level processes, yeah? There is still no way to compile O'Caml binaries that run on more than one processor, right?
Can you provide a bit more motivation for it? i.e. what does it have that the alternatives don't?
The closest alternative is Hamachi. Hamachi is a really cool program--except when the Hamachi servers go down. I wanted something I could configure and control my self. I also wanted something that could make direct connections between members of the VPN so that traffic didn't have to hop across a server (Hamachi makes these direct connections as well). When using something like OpenVPN or vTun you end up with a star network instead of a fully connected one. Make sense? There very well could be more applications like this, but I wanted to see if I could write a VPN and if I could do it in Haskell (also, I couldn't find any others). :)
Thanks - I hadn't picked up on the star versus full connection thing. (And I hadn't heard of Hamachi.)
ah, one other thing I forgot to mention... Scurry doesn't have any centralized management. In theory (once I get routing working), the network can fracture in two and the pieces could grow independently of each other. There are a lot of non-standard problems that need to be worked over with this project... but it's a lot of fun. :)
Using processes, yes. I'm not sure what you mean by "compile O'Caml binaries that run on more than one processor". You just write OCaml code that forks processes, compile and run it and those processes run in parallel on separate CPUs. There are some simple examples on the shootout: http://shootout.alioth.debian.org/u64q/benchmark.php?test=regexdna&amp;lang=ocaml&amp;id=1 
Ah yes, another of my gripes with Haskell. Can someone more knowledgeable please tell me why I cannot (or if I can, how) re-define say the **+** operator for a type class, since it already 'belongs' to the Num typeclass? When I try to declare a typeclass with an operator which is present in one of the common typeclasses (Num, Ord etc.), I get an error to the effect of "already defined" .. I really wish there was an easy way for function/operator overloading in Haskell. Typeclasses are perfect, but the inability to refer to a function *from* a particular type class is kinda limiting.
that would be rather interesting: to consider each typeclass a namespace. I can think of no good reason why it should not be so, other than the fact that people are used to the way things are, and some new syntax would have to be invented. --- edit: actually, when I think about it more, I think either this idea would lead to more verbosity (having to specify operator namespace every time there was conflict for a particular operator, negating the advantages of the operator) or ambiguity in code that would reduce the advantages of static typing.
There is a way to do function/operator overloading. Type classes are it. If you want to reuse a name, you simply instantiate a new type in the type class and write the definition you want. The only real issue is that the standard library is pretty agressive about grouping names together which makes it impossible to overload just *one* of the names in a type class (e.g. I'd like the Num class to be split up, so that (+) would be defined on its own in an Additive class, say, then you could define + for any type without also having to make sense of the other members in Num like *) - changing the language to support ad hoc overloading (which is precisely the kinds of horror that type classes were invented to avoid) is a step back - some sort of class alias strategy which would allow us to break up Num while still allowing legacy code to work (they would refer to "Num" which would be an alias for (Addive a, Multiplicative a,... etc.)) would be a better solution.
yes, why have operators at all, besides for the sake of: - tradition - brevity I'm tempted to add readability to the list, but I wonder if that's not just a side-effect of the other reasons.
&gt;so that (+) would be defined on its own in an Additive class, say, then you could define + for any type without also having to make sense of the other members in Num like * Yes that is exactly what I want. I want to use just the + operator for some datatypes, and not have to define - * / etc. Making a new typeclass with (+) as the only function didn't work (I don't quite remember the exact error but it was probably similar to 'duplicate/ambiguous function'). For those wondering about the use-case scenario, one example is: I was writing an EBNF-like parser similar to Boost's "Spirit" library. I wanted to combine individual parser terms with **+**, **&gt;** and similar operators. Ended up having to invent crazy combinations like `&gt;&gt;&gt;` and `!&gt;&gt;` instead. The other was when I was writing a quick datatype/function library for 2d and 3d vectors (I know there might be "better" ways), and wanted to simply use + - * like MATLAB has, for vector operations, without implementing all operators in Num (many of which won't be valid on vectors/matrices).
I actually like that aspect. My only gripe is that some of these operators look plain ugly. Like the &lt;* operator from Control.Applicative. Probably because of it's asymetrical aspect. One thing is for sure, they make more sense than C++ operator overloading.
whoa, I just discovered a weird artifact in reddit comments --- why is the above text so bold and blue?
The reason is that the + symbol is already defined in the Num class, which is in the Prelude. You can choose to not include the Prelude either by passing a flag to ghc (-fno-implicit-prelude?) or by explicitly importing the prelude hiding the operator: import Prelude hiding ((+)) class Additive a where (+) :: a -&gt; a -&gt; a instance Additive [a] where x + y = x ++ y GHCi: *Main&gt; [1,2]+[3] [1,2,3] This is a bit ugly though since you'd have to do this everywhere you'd like to use your new Additive class...
It happens when you put a dashed line below it ------------------------------------ Markdown parses it as a header. 
How would type inference work?
I see, but then can I use types which are instances of the Num class? I mean how would the (+) from Num and the (+) from Additive co-exist?
either it would act like it was more dynamic or it would require namespace to be specified on collisions. Both ideas would be poor.
Good point. I think this could be one of the places where I'm willing to let go of type inference and let the compiler spit out an error forcing me to declare the parameters manually. After all if I'm using an overloaded operator, I'd probably know which one I want in any particular case.
if I were designing a language, it would not have keywords or operators.
No, the whole point of this exercise was to pretend that the standard definition didn't exist so you could write your own. So no, you can't mix it with the one you just hid. You could do: import qualified Prelude ((+)) And then use "Prelude.+" anywhere you actually mean the standard +. This is ugly though. But again, the point was to redefine + yourself, so then you're actually going to have to define it yourself for the types you want it to work with (Like Int, Double, etc.). In practice none of these are nice, so just use &lt;+&gt; or something for your Additive class and accept defeat until the Num class gets split up in Haskell 2012 or whatever.
OK I was beginning to think I was missing something obvious, but the bottomline is, we gotta invent these crazy operator combinations :) 
I wouldn't. Especially not for an operator that's as common as e.g. (+). I think this is a library issue, not a language issue. The standard library needs to split up the Num class and declare each operator in a separate class (possibly grouping logical things like + and - in the same class).
Ever heard of Forth?
Hey if the operators are too long you can always use unicode operators. x = f ⋚ g ⋨ h
It seems like you should be able to do something like: import Prelude hiding ((+)) import qualified Prelude ((+)) class Additive a where (+) :: a -&gt; a -&gt; a instance (Num a) =&gt; Additive a where (+) = (Prelude.+) But I can't get that to work.
It seems like you should be able to do something like: import Prelude hiding ((+)) import qualified Prelude ((+)) class Additive a where (+) :: a -&gt; a -&gt; a instance (Num a) =&gt; Additive a where (+) = (Prelude.+) But I can't get that to work.
It seems like you should be able to do something like: import Prelude hiding ((+)) import qualified Prelude ((+)) class Additive a where (+) :: a -&gt; a -&gt; a instance (Num a) =&gt; Additive a where (+) = (Prelude.+) But I can't get that to work.
When I said "does not support SMP", I could also have said "requires multiple OS level processes to make use of multiple processors". I am not sure why this thread has caught your interest.
`&lt;*` is asymmetrical precisely because it is the left-handed (also constant) version of `&lt;*&gt;` (conversely, there is also `*&gt;`) (&lt;*&gt;) :: (Applicative f) =&gt; f (a -&gt; b) -&gt; f a -&gt; f b (&lt;*) :: (Applicative f) =&gt; f a -&gt; f b -&gt; f a (*&gt;) :: (Applicative f) =&gt; f a -&gt; f b -&gt; f b 
If you want EBNF, I think the best thing to do would be to write a quasi-quoter that goes from EBNF to Parsec (or your parser of choice). whitespace = [$ebnf| (' ' | '\t')+ |] &gt; For those wondering about the use-case scenario, one example is: I was writing an EBNF-like parser similar to Boost's "Spirit" library. I wanted to combine individual parser terms with +, &gt; and similar operators. Ended up having to invent crazy combinations like &gt;&gt;&gt; and !&gt;&gt; instead. I like Haskell's version of operator overloading rather than C++'s precisely for this reason; `(&gt;)` will always be `(Ord a) =&gt; a -&gt; a -&gt; Bool`* unlike in C++, where it could mean anything. \* (modulo `import Prelude hiding (&gt;)`, which is unlikely, but obvious when it happens)
The thought just occured that, given a limited number of operators you can either: 1. Allow the operators to be overloaded to many various meanings (i.e. types) 2. Disallow multiple meanings but allow more operators to be defined (possibly as strings of existing operators) 1 is C++, 2 is Haskell :)
Even that doesn't give enough freedom. I was experimenting with my own version of a Unicode-symbol-based Prelude... I got stuck on a nice equivalent for `&lt;*&gt;`, `&lt;*` and `*&gt;`. What I really needed was something like 'combining left half-circle' and 'combining right half-circle', which don't exist (AFAIK). On the other hand there are some nice possible combinations; I came up with: ⋅ = $ ⊙ = fmap (= &lt;$&gt;) 
I think it may help with generality; `(&gt;&gt;=)`, while it does have a name (bind), means different things in different monads. Having an abstract symbol rather than a concrete one (say `concatMap`) helps me think in terms of wider usages. Plus it's nicer than using `x 'bind' f` :P (can't figure out how to get backticks in; usual \\ escape doesn't work)
I was a little surprised to find that Ints were automatically coerced into Float/Double without the need of fromIntegral. Is this a new feature or is this something that's been around for awhile?
Various script errors prevent me from commenting on the site itself. So: &gt; In fact, in both the Python and Ruby implementations, x and y need not be any kind of numbers at all. The only thing we know about x and y is that they should implement the "+" operator. Not quite. In Ruby, 1 + '5" gives an error: TypeError: String can't be coerced into Fixnum Ruby has a form of strong dynamic typing. 
Numeric literals defaulting to Double, you mean?
&gt; Like the &lt;* operator from Control.Applicative. Probably because of it's asymetrical aspect. Write much XML?
It worked for me after adding "-XFlexibleInstances -XUndecidableInstances". However it still seems useless because you can't add any other instances of Additive. Haskell ignores the class constraints when trying to figure out which instance of Additive to apply in any case, so it will always match "Additive a" even if there is another matching instance. [The GHC Manual](http://www.haskell.org/ghc/docs/latest/html/users_guide/type-class-extensions.html#instance-overlap) suggests that -XOverlappingInstances will help, but it doesn't.
I guess that would be it. I always have all the warnings turned on, so I've never dealt encountered that...
For a quick hack you can just do negate = undefined signum = undefined etc. But all of the `Num` functions can be implemented in a vector by mapping them to the individual elements, assuming the elements are a type of `Num`.
More like COBOL....
The fromIntegral call is still required, but it is implicitly inserted on all literal integers. In the add3 examples, you can see the type of the result being determined by the type of the second argument and GHCi's defaulting rules. Some of the more impressive examples of using Haskell involve computing different things depending on the type annotation of the output. If you enabled the ScopedTypeVariables extension, you can do this: Prelude&gt;let (k::Num a =&gt; a) = (3+3)::Num a =&gt; a Prelude&gt;k::Int 6 Prelude&gt;k::Double 6.0 Prelude&gt;k::Rational 6 % 1 
It was always like that and it's not that Ints are coerced to Double, it's just that integer literals in Haskell are polymorphic : try ":t 4" in ghci to see what I'm speaking about, it's type is : (Num t) =&gt; t
"Sick folds"? What age are you, 12?
Obviously there is still some work to do on the Haddock formatting, but I think its comprehensible. The main things on my TODO at this point is to benchmark (though I haven't decided how) and reconsider the API (I might just provide the IO method for adding jobs / reading results instead of accept IO actions for the library to call).
heh, I hate XML too but for different reasons.
Yes, I was referring strictly to the aesthetics of it.
Some short examples, perhaps in a blog post somewhere, would be very useful for people to get the basic ideas.
This is also the case in Python. The author is not implying they are weakly typed, just that in Ruby and Python, + is implemented by default for more types than numbers.
Both 1 and "5" "implement the "+" operator." So the author's claim would imply that they can be added. This is false, therefore so is his claim.
I'm of the opinion that examples in the documentation, maintained as such, are more useful than erratic blog posts.
In the future I'll probably make a firewall example for the documentation and a blog post. Hopefully I think of a more interesting but still concise example before then. In the mean time... fireWall :: (a -&gt; Bool) -&gt; IO (Chan a, Chan Maybe a) fireWall f = threadPool 8 worker where worker a = if (f a) then Nothing else Just a 
&gt; *undefined :: a* &gt; *undefined | False = undefined* &gt; Hell yeah. 
Do not even start me on F# syntax. Don Syme himself realized what a mistake they've made, adopting ugly ocaml syntax for the sake of compatibility, and ended up introducing #light pragma. But that still did not fix all the ugliness. So in the end they ended up with ugly language that is not even compatible with its ugly brother anymore. 
Well these struggling financial corporations have to get help wherever they can. BAILOUT!
That's a good point I'm willing to agree with - but examples are the first thing I look for to get a feeling for a new package. There are so many new packages that it is hard to find time to read the docs in detail or try it out in action. It's just my advice to package writers: short examples are the best advertisement.
Excellent, you should put this in the docs. Don't worry at all if it is trivial or contrived, a short example like this tells people in 15 seconds what it would take a few minutes to see by looking at the generated docs.
I find the use of using an number to represent a parallel data structure for the shape of the safe portion of the circular structure somewhat unsatisfying, because it doesn't seem to generalize particularly well. (The article mentions this too).
I can't get this to install though Cabal. It requires glib and gtk, but I can't figure out how to install them. I tried compiling gtk2hs, but it's failing with GHC 6.10... I wish I could try this, because it looks awesome.
gtk2hs isn't yet released for 6.10
You should use a release candidate of gtk2hs. There's probably link to it somewhere in their forums. 
Yay.
I've used some older versions of the same thing, getting it to work with gtk is the worst part. It was still fairly buggy, but quite promising.
I might have agreed with this, but no matter how hard I try my cabal-install remains hopelessly broken and unusable.
More info needed...
For months I couldn't even list packages because cabal would get halfway down the list and then puke out an error about some broken package definition. I eventually spent some time and solved this problem (I don't remember how) and immediately faced new issues: &gt; $ cabal update &gt; Downloading package list from server 'http://hackage.haskell.org/packages/archive' cabal: user error (Codec.Compression.Zlib: incorrect header check) EDIT: Removed gratuitous rant about my original post getting voted down.
I'm not a haskeller at all. And I downvoted you. Ever thought that your attitude might be a problem here ? 
Please make a bug report! In fact, I'm talking to the cabal-install author now on your behalf. It really is easy - as long as you let people know what is going on. &gt; You Haskell creeps sure are averse to reasonable criticism Providing no information about the bug, while sitting on it for 6 months, isn't criticism. It's just not how open source works. If you file a bug [here](http://hackage.haskell.org/trac/hackage/) it'll be fixed in short order. The zlib bug I believe if fixed by upgrading zlib (there was a missing header check).
I was expressing my frustration with the software that the article is celebrating. Am I doing it incorrectly?
By calling haskellers assholes and creeps ? By saying you have such a contempt and prejudice towards them that never even asked a question in first place ?
The article was claiming that Ruby didn't care about the type of the argument passed to the '+' method. &gt; In contrast, Python and Ruby, by design, avoid any upfront discussion of types and do not enforce any constraints on the user. But they do, and the type of the argument matters &gt; This is both powerful and (sometimes) dangerous. In fact, in both the Python and Ruby implementations, x and y need not be any kind of numbers at all. As message receivers, sure, but as arguments they have to be of a compatible type. The article seems to suggest that typing doesn't matter much in Ruby (and perhaps Python, too), when it's really that the typing is different, and matters differently.
The development version works fine though. I've been using it for a couple of weeks without any problems. darcs get --partial http://code.haskell.org/gtk2hs/
Don, what is a preferred way of installing haskell packages on Arch ? Is it cabal install, or pacman ? 
pacman for stuff in [community], then either yaourt or cabal-install, depending on your needs. I use pacman and yaourt.
ok, i'm confused. cabal-install works perfectly without any other step like pacman. And it automatically installs all the dependencies. As for pacman, let's say i downloaded an hdbc from community, makepkg it, and asked pacman to insall it. Will it automatically download and install all the required for HDBC packages ? or will it fail telling me that some required libraries are missing ? 
I had something similar when I reinstalled my OS but kept the old /home mountpoint. The ~/.ghc dir disagreed with ghc regarding what packages were installed so killing the ~/.ghc dir ended up letting me start from scratch and fix the problem.
cabal-install works perfectly, mostly. But it can't resolve Arch-specific C library names - yaourt can. That's the main difference. cabal-install is also a bit smarter with recompilation. pacman is only really for those that are distributed in binary form (namely ghc, cabal-install itself, Data.Binary and a few other things so far). 
You can get the prerelease of gtk2hs at: http://code.haskell.org/~pgavin/gtk2hs-0.10.0/
The new version is a big step forward. Click on add imports for any "not in scope" error and the import statements are added. That saves me hours... But I'm biased of course. 
Good moses, I need to get back into haskell development again.
Computing with homomorphic images is to me some kind of voodoo magic. I am always wondering how in heaven did they come up with the requisite image having exactly the properties they need for their program to work. I'd like to see less rabbits pulled out of this magic hat.
Here is a library for IDE-like functionality which is under development: http://github.com/nominolo/scion/tree/master Yi might use and contributue to it in the future, and it would be nice if Leksah could too.
does stuff installed with yaourt (or aursh) and stuff installed with cabal-install play well together, in terms of satisfying each other's dependencies?
Yes I will try using it for Leksah. 
You're thinking of darcs. The zlib check here is correct but unhelpful. The problem is that the download failed and the first time we notice it is that decompressing the partial or empty file fails the zlib checksum check (as it should). We should check more explicitly for the download being successful, eg checking that the amount of data we downloaded is the amount the server said it would send us. The error message we report should point out the cause of the problem (the failed download) and not the symptom (the zlib crc check failure).
Yes, this is annoying. The problem is that we've not dealt as gracefully as we should with future compatibility. What is happening is that your version of cabal-install is built against Cabal-1.4 which cannot parse certain constructs introduced in Cabal-1.6. So when doing a "cabal list" it has to parse every file and at some point it fails. The immediate solution is to upgrade, "cabal install cabal-install". The longer term solution will be for cabal-install to handle packages that need a later version of Cabal in a more graceful way. The zlib checksum failure is a result of the download having failed. Try doing update again. If it is a persistent failure we'll need more info.
cabal-install is still a pretty new piece of software and it sounds like you're using a fairly early version. Try: $ cabal install cabal-install You want to be using version 0.6.0. $ cabal --version cabal-install version 0.6.0 using version 1.6.0.1 of the Cabal library 
We have a bug tracker which is kept pretty up-to-date and we do respond to all tickets: http://hackage.haskell.org/trac/hackage/ Your particular problem is reported here: http://hackage.haskell.org/trac/hackage/ticket/480 Unfortunately, as I mentioned, we have no fix at the moment except to upgrade to the latest version (which is easy and should have no drawbacks). 
"It's not emacs." should cover it for emacs haters and lovers alike :P
Yes.
I'm glad people are thinking about this. What's performance like, and can we use strict fields for those Doubles? (this is a very performance-sensitive benchmark).
I have no idea what performance is like at the moment – I need a working FieldTrip, which conal tells me he's working on. As soon as I get one I'll give it a try. In all honesty, if it's within a factor 10 of the benchmark submission I'll be very happy – a factor 100 improvement in code clarity is worth a factor 10 speed decrease :). As for strictifying the doubles, I'll think about that when I look at its performance. I don't think this is submittable as a benchmark entry anyway – it depends on reactive and field trip, which don't ship with ghc.
Ah, yes, that is exactly the same problem as I had before. I guess I resolved it eventually by upgrading cabal. After testing last night, it seems that sometimes 'update' completes successfully and sometimes it takes a much longer time and eventually fails with the zlib error. 
Haskell is a hobby for me and while having a broken cabal was annoying, it wasn't a huge problem since I only really use Hackage for source code examples. I don't really have time to write bug reports for every program installed on my computer. Since I cannot even understand the source code for most Haskell software, I'm probably not the best person to do it anyways. 
Only the major Haskell event of the year ... :)
Is this useful for simplifying Haskell implementations I wonder? Only need to support one "magical" type class, and implement user defined type classes in terms of it. I'm guessing probably not, given the complexity of the magic typeclass and the need to "resugar" the types for the purposes of error reporting, etc. 
As far as I know, there aren't any purely functional widget sets out there (but there are only purely functional adaptations of imperative widget sets). Additionally, I believe I am taking a novel/unique new approach (in its simplicity) to managing the focus/cursor, and the widgets are capable of generating a user-visible definition of all available key presses that updates online.
+10, approximately, for not talking about rendering backends on the cafe.
Heh, funny you should mention that, as conal just gave me a push towards relinquishing my Draw monad in favor of a pure functional Image. However, this means I have to expose Font renderings in the functional part of the code, and that would require unsafePerformIO. I am considering a cafe post about it, but maybe I should hold it back? :-)
This is very very exciting. Alas, I only have a passing acquaintance with Haskell. Would there be some pointers to a design document or mailing list discussions related to this project? At a very basic level, how does one even build the project? ~/work/haskell/lui$ ghc *.hs Widget/*.hs HaskGame/*.hs results in: Accessor.hs:21:12: Module `List' does not export `nth'. ~/work/haskell/lui$ ghc --version The Glorious Glasgow Haskell Compilation System, version 6.8.2 
What is the purpose of `copy` in a referentially-transparent language?
Who is Oleg and how did he get to be so good? People like him and sigfpe make me want to both get better and give up. It's inspiring and frustrating at the same time. :)
In these examples, the homomorphism used is exactly the same as one would use in the non-updatable case (i.e., on a fixed string instead of a tree)
The expanded version seems much more complicated (from an implementation standpoint) than the dictionary-passing version... at least to me. But maybe the _theory_ is simpler if we only have to worry about one type class...
Sorry! I really should create a nice website for this. You should have SDL and SDL-ttf installed from hackage (And they, in turn, depend on the SDL and SDL-ttf libraries and headers being installed on your machine. On Ubuntu, you need libsdl1.2-dev and libsdl-ttf2.0-dev.) If you have cabal-install, you can install SDL and SDL-ttf with "cabal install SDL &amp;&amp; cabal install SDL-ttf". Then you can use "ghc --make main" to build the mainloop with the given example. Its not currently formulated as a proper library, but it soon will be, and then I hope to start putting it on hackage. Thanks for the feedback!
Wow. I really should learn Reactive some day soon, this was beautiful!
What I'm saying is, what is the motivation behind the construction of the bicyclic monoid? Moreover, why the formulation uses `max` instead of `min`, which I'd say is more natural given the shape cancellation imposes on strings?
Oleg is Chuck Norris. http://okmij.org/ftp/ 
Sounds like the download is timing out. As I mentioned above, we should have a more explicit check and report the problem and not the symptom.
NOTE: If you're using an x86/64 system, there's a bug in the SDL-ttf wrapper that requires fixing for use. On other systems, it should work fine.
Thanks for the help! Now I can compile &amp; run it. New playground, here I come :)
[Chuck Norris isn't Chuck Norris anymore](http://fucknorrisfacts.com/)
I do not consider those statements to be equivalent. Perhaps "does not support SMP from within a single process" would have been better. I picked up on this thread whilst searching for "OCaml". However, I could have sworn I had replied before... 
Cool! Makes me want to screw around with Sweep Line algorithms as well. Someone really needs to start up a geometry lib for haskell. I think maybe one of the main reasons this hasn't happened in a significant fashion is the Numerics hierarchy remaining unchanged.
Heh, I was looking for a snappy name to describe something I thought was cute yet dirty: any other suggestions? ;-)
That is the first time I have ever visited blogspot without having my retinas burned out by the bad layout
I wonder if an early enough INLINE pragma could make that problem go away? But probably not, because the line # has to come from somewhere.
Copy produces a list (`copy 3 "a" = ["a","a","a"]`), not copy the object.
 ``double ` backticks`` example: ``foo`bar``
Oh, right. So it's the same as `replicate`.
The [Torrent](http://github.com/youngnh/abhorrent/blob/55aa7d02d34c2dc62448c52b336e885adc8908ae/Torrent.hs), it does nothing. Looks like it's only gotten as far as parsing a .torrent file. No networking yet.
Yeah, abhorrent! 
Yes, but it wasn't the author who advertised it either. I'm happy to see net-centric Haskell projects pop up - hope this survives and thrives. edit: typo
Very true. At least it also looks like the author is working on it currently. As of writing this note, the last commit was 30 minutes ago.
btw, anyone got sdl+haskell+mac working? 10x :)
Bah, conjure can parse .torrents and actually download files! (As long as they're not more than a few gigabytes.)
&gt; not more than a few gigabytes ... what's the limitation? i've streamed lazy bytestrings terabytes in size...
This is moving amazingly fast! You guys make me feel old... Let's see here: * Alex starts http://happs.org/. 2005-ish? * HAppS burns through developers: musasabi, shapr, Igloo (now at http://well-typed.com) and finally Lemmih * No one understands happs * No one uses [WASH](http://www.informatik.uni-freiburg.de/~thiemann/WASH/), except Adam Peacock, who writes [a site in it](http://lambda-the-ultimate.org/node/2315), and gets hired by Credit Suisse... * glguy writes http://hpaste.org on happs, gets a job at [Galois](http://galois.com) ([hpaste2](http://moonpatio.com/fastcgi/hpaste.fcgi/) rewritten with takusen and galois libs, at the Blue Moon pub one sunday...) * Happs seems in decline * Lemmih cabalises happs, interest revives * Lemmih visits dcoutts, hackage 2 rewritten in happs. * [gitit](http://hackage.haskell.org/cgi-bin/hackage-scripts/package/gitit) launched by John Macfarlane. * Thomas Hartman launches http://patch-tag.com -- happs is back in the game, but still leaderless. * New Haskell web frameworks appearing at the rate of 1 a day ([turbinado](http://www.turbinado.org/Home/Index), [perpubplat](http://github.com/prb/perpubplat/tree/master), [riviera](http://wiki.cs.pdx.edu/forge/riviera.html), [salvia](http://hackage.haskell.org/cgi-bin/hackage-scripts/package/salvia-0.0.4), [kibro](http://hackage.haskell.org/cgi-bin/hackage-scripts/package/kibro), [ella](http://lukeplant.me.uk/blog.php?id=1107301693), what was that one launched yesterday? *ah, [yesod](http://blog.snoyman.com/2009/01/31/first-real-yesod-commit/)...) * People start [complaining about all the web frameworks](http://aftnn.org/journal/661) * Mathew Elder forks HApps as happstack - stay true to the vision! * Alex blesses Matthew as new king of happs * http://patch-tag.com switches to http://happstack.com/ * Matthew joines Thomas as partner in patch-tag Phew! Did I get all that? So what next? How can the "old guard" of haskell.org infrastructure and developers help?
I think the blogger and the referenced Greg Burri have buggy solutions. You can check this by running their solutions on input ps = [(-3,7),(-2,6),(-1,4),(0,1),(0,0),(1,4),(2,6),(3,7)] I posted another (attempted?) solution at http://haskell.pastebin.com/f65fb096 (You can convert to Greg's Point2D with map (uncurry Point2D) ps )
Will [hackage 2](http://code.haskell.org/hackage-server/) ever be used on hackage.haskell.org? Except the annoying ['DNS required'](http://code.google.com/p/happs/issues/detail?id=40) bug from the network package, I really liked it.
Yes.
LUI is now on Cabal: cabal update &amp;&amp; cabal install lui 
Did you try following the Mac OS X README instructions carefully? Maybe someone on #haskell (Lemmih there is in charge of the SDL bindings) can help? 
Ints being passed to hSeek, I think was the closest I got to a diagnosis.
Bah, [conjure](http://hackage.haskell.org/cgi-bin/hackage-scripts/package/conjure) isn't platform portable. I don't say that as a Windows user, but as a hacker who's hopeful halvmc will be merged with GHC soon and the Haskell community can create many application like VMs with little more than a recompile. Edit: Just to be clear, I'm not meaning this to dismiss the work done on conjure - just saying it doesn't fill the gap fully.
Hey, that's really nifty. Thanks for your work!
Did he translate C code to Haskell?
If anyone is interested. Thomas and Matthew are speaking about happstack next Tuesday (2/10) in Los Angeles.
Not having my own static IP (right now) and not being in a web-programming job I haven't played with happs or turbinado, but I must admit its getting tempting.
Yay.
Actually I started by translating the OCaml code to haskell. This is about my 4th or 5th attempt at the problem now. I think I should post about my evolution of the problem, it could be interesting. Stay tuned!
I could not grok it at all for the first time, but now it appears so plain to me. Moment of Haskell enlightenment, kind of.
&gt; HApps seems less than simple; Turbinado is all about simple Well, after comparing both source codes, I'd say HAppS source code seems more descriptive than Turbinado's. HAppS `main` function is awesome because it's the function that powers the whole website, whereas Turbinado's source code gives me the impression that the author is too afraid to go along with Haskell's syntax.
pics or it didn't happen! :)
is that a sarcasm period?
No.
These guys know how to move.
I'm ashamed to admit that I read the title without the m's at first, wondering what this could have to do with Haskell... :|
I've once submit a bug report for HLint, and the response was almost instantaneous. Really nice job.
I wish authors of blog posts gave at least a little bit of context, even if only a link to a prior blog post. I assume this is about the [n-body benchmark](http://shootout.alioth.debian.org/u32q/benchmark.php?test=nbody) in the [The Computer Language Benchmarks Game](http://shootout.alioth.debian.org/)?
stop wondering and the shame will fade:) besides, oleg can do better: &gt; instance (FApp fx a r, FApp r b c) =&gt; FApp fx (a,b) c where &gt; fapp f = uncurry (fapp . (fapp f)) if only that uncurry was unzip, then I'd understand that code. 
Hey, Haskell still cool. You evaluate later! **later**!
Thanks, I feel better now. :P
Yeah, sorry about that, didn't think anythig of mine would make it onto reddit, so i was sort of ranting/celebrating ore than anything. if you're interested in the history, check out http://axman6.homeip.net/blog/2009/02/n-bodies-evolution.html which i wrote after to document the evolution from where i started to where i am now.
I think this is slowly changing. It turns out that web servers aren't particularly complex to implement -- especially as a library -- and on today's dynamic web, it's not uncommon for the URL to have little to no relationship with the underlying file system. Given that almost all queries will end up being dynamic anyway, why suffer the overhead of a CGI-like interface? Do you really gain anything from some sort of mod_haskell running inside of Apache, other than added complexity and lots of features you'll never use anyway? In a production environment, these Haskell webservers (or Lisp webservers, or whatever) usually don't serve content directly to the internet, unless the number of users is small. Instead, they sit behind a caching proxy like Squid or even Apache itself. And I don't think there's anything wrong with this model. Look at Wikipedia -- the wiki software is heavily dynamic and implemented mostly in PHP, which is hardly fast. To deal with the load, they distribute it -- when you hit Wikipedia, you're actually hitting a Squid cache. If I were designing a web application today (and I'm not, so take it with a grain of salt) I'd do something similar and reap the benefits of having the whole system written in one language.
fmap.fmap.fmap is kind of intellectual masturbation.
BTW, Peter V's fmap.fmap.fmap email came from making sense out of my coding style. If you like it, or are still puzzling, you can find more of the story in *[Semantic editor combinators](http://conal.net/blog/semantic-editor-combinators)*. 
I'm not sure it is truly a coroutine unless pause is changed to yield and yield returns a value; however I think this could be done. (in such a case, then `pause = yield ()`).
If it works for what he wants then the rest is (English) semantics, but for what its worth the definition of 'coroutine' I'm used to did use 'yield' but never gave a result on yields, they were transparent to the language semantics and simply triggered the scheduler.
Oh okay. It's been so long since I've studied coroutines, I wasn't sure if yield was supposed to return a value or not.
I think this is [Unimo](http://web.cecs.pdx.edu/~cklin/papers/unimo-143.pdf) or [MonadPrompt](http://hackage.haskell.org/cgi-bin/hackage-scripts/package/MonadPrompt) in disguise.
I actually like that bug/feature as it allows me to see when a program is done starting
This kind of thing is exactly what Parsec was built for. I've cooked up this little example: import Data.Either import Text.ParserCombinators.Parsec match '(' = ')' match '[' = ']' match '{' = '}' match '&lt;' = '&gt;' phrase = do x &lt;- oneOf "([{&lt;" sentence char (match x) sentence = many phrase matches = either (const False) (const True) . runParser sentence () "" . filter (`elem` "()[]{}&lt;&gt;") With the possible exception of the final "matches" predicate, I think all of this is quite readable.
I wonder if compiling the code-generators for all archs will make cross-compiling easier?
Yes. That's part of the longer term plan which should eventually lead to being able to cross-compile.
I just go "oh hey, one of the workspace names just changed colour".
I wrote an implementation in Clojure, but Rich Hickey, the author of Clojure, was quick to come up with a more idiomatic version: http://paste.lisp.org/display/74934
It would be nice to see an alternative shootout where one could compare more "idiomatic" code from the various languages. Obviously these benchmarks have their place, but comparing more typical (i.e. unoptimised) use of languages could also be very enlightening. Of course, we then have the problem of defining "Idiomatic", "typical" plus a myriad of other issues that would cause it to be more of a passing curiousity than a useful comparison. 
Any efforts on cross-platform (i.e. not just arch but also OS)?
Generating proofs of equivalence between high level (Haskell-ish) specs, and C is pretty sweet, imo.
Woot, http://hackage.haskell.org/cgi-bin/hackage-scripts/package/WikimediaParser-0.1
There are still some #ifdefs in there to manage linux/darwin specifics for the other architectures. The OS differences are fairly small. Untangling the i386 and x86_64 code would take a day or so to do right. 
The goggles, etc.
What goggles?
Presumable this: http://encyclopediadramatica.com/Goggles
The ones which do nothing.
At least when he got to feeling nostalgic he didn't buy a bunch of old computer crap. I just got two C64s, a C128, an Atari 130XE, and a TI99/4a. I'm still thinking on adding a CoCo 3 to the stable, as it's the one popular home computer I never owned as a kid (my first business when I was in middle school and high school was buying, fixing, and selling computers, so I had almost everything at least once, including crazy rare crap like the Apple Lisa). Anyway, I probably should have just written a Perl 6 grammar for BASIC, or something, instead. It almost certainly would be a more useful way to spend my time than reviving a bunch of old 8-bits.
This is one of those things which don't look too horrible at first, but then... you... fromInte... preced... NOOO!!
&gt; Oh my Lennart! There, I fixed that for you.
But why, when people comapre anything to C, they usually use a loop conmstruct like: for (i = 1; i &lt; 100000000; i++) s += 1/i; 
Brilliant. Now where's the Hackage package for BASIC? :)
It's the `undefined` Monad! unChicken (Chicken x) = x unEgg (Egg x) = x instance Monad Chicken where return = Chicken . Egg . return (&gt;&gt;=) = (&gt;&gt;=) . unEgg . unChicken
Here's the paper for non-ACM members: http://www.macs.hw.ac.uk/~greg/publications/atamhb.damp09.pdf
Wow, thank you. This is by far the clearest an concise description of monads and the motivation for their use without resorting to confusing examples. General ideas need general explanations.
Thanks!
Okay, does anyone else find themselves spontaneously drawing connections between abstract haskell programming concepts and things in every day life? It's a filling akin to deja vu.
How is this better than [data-accessor](http://hackage.haskell.org/cgi-bin/hackage-scripts/package/data-accessor)?
It isn't. We stopped developing this once we found out about data-accessor, and I'm not quite sure why Sebastiaan released it... Erik
There is an EDSL back'd by GCC ?
If you're on Arch Linux, $ yaourt --noconfirm --aur -S haskell-basic Will get you a working native package for this :) Also, $ cabal install basic
Anyone use this in ubuntu? The networkmanager stuff is clearly design by a complete fuckwit. It requires a user application which runs as a gnome pannel tray app which requires you to be logged into gnome or kde to work I cannot understand what fucking level of retardedness leads people to tie the core funtionality of a unix-a-like environment to an X based application. At least solaris makes an effort with network auto magic. This leads to none of the other window managers being capable of working nicely with wireless net. Its all good if you are on ethernet but fucking hell. Who is pushing this shitification of linux.
http://wicd.sf.net http://www.archlinux.org 
xmonad supports networkmanager (and gnome trays) just fine, fwiw.
n
What is meant by "extensions to use it with Gnome and KDE"? Does that mean that you need extensions to use Gnome or KDE apps (like KWrite or Inkscape)?
To talk the GNOME configuration protocols, you enable that additional functionality in your config file. http://www.haskell.org/haskellwiki/Xmonad/Using_xmonad_in_Gnome
&gt; Does that mean that you need extensions to use Gnome or KDE apps (like KWrite or Inkscape)? KDE and Gnome applications work out of the box. The extensions enable extra integration with the KDE and Gnome desktop environments. This includes special handling of their taskbars and desktop windows and key bindings to their application launchers and session logout dialogs.
Yeah man, I fucking hear you. I had to set up a tiny upper taskbar region and run the gnome taskbar in it otherwise I was screwed. All the other wifi stuff just didn't work -- nm-applet is pretty much all I could find. ARGhh! It's literally the only reason I run gnome!
wicd doesn't work for me, at least not properly.
It's a sorry reflection of the state of software that a program not crashing or being generally riddled with bugs is the exception rather than the rule. At least there are languages like Haskell that are taking a step in the right direction by trying to make incorrect code harder, rather than easier, to write.
y
What seems to be the trouble?
Did you try wicd?
I've never had to deal with a wireless network, but I certainly don't understand why it should have to be any different to configure from wired network interfaces. That's rather disappointing.
\_|_
Is xmonad not crashing really all that unusual? I don't think I've ever had __any__ window manager crash.
because it has to save and manage authentication for the wireless networks you have already connected to. It actually works quite well but as I said... it all lives in some weird non root GUI thing.
Hehe... it's somewhat unusual, yes. That's part of why we wrote it in the first place, sadly.
Any game in which execution speed or memory use is a metric is going to encourage low-level optimizations that one might not actually use when writing a real program. Even the C entries aren't written the way most C is written. It's the nature of the game. In reality, shootout-style code (in any language) is only going to crop up in places that the profiler deems to be hotspots. But being *able* to write such code is very, very important. The point of the Haskell entries in the shootout is not that you would normally write your programs that way, but rather that you *can* write pieces of them that way if necessary.
I used this problem as an opportunity to show MonadLib, MonadLib.Derive, type classes, functional dependencies, using/creating Monad Transformers. I think that it works better as an example of some of these topics than as a full illustration, however. http://moonpatio.com/fastcgi/hpaste.fcgi/view?id=1278 
⊥
You tell me you've never had to use Windows XP? You must post your employer so I can remember to apply if I ever want to do (paid) work again. EDIT: More seriously, I've had Gnome crash on me fairly often. Particularly on a fresh Fedora 10 install, not sure why though and I don't really use Fedora anymore so I didn't pursue it.
There's a nitch market the XMonad team isn't getting right. They should make it easy to integrate XMonad with Compiz - cube spinning on workspace change and wobbly windows when the tiles are rearranged. For the two people in the world who would ever want such a setup!
&gt; They should make it easy to integrate XMonad with Compiz Both Compiz and xmonad are window managers, one can't run two window managers simultaneously.
I've had Gnome crash on me, but not Metacity. Apples with apples, please.
I think this is the first /r/haskell/ post I've ever downmodded.
I've had windows crash on me, but I don't know that I could attribute it to whatever the windows equivalent of a window manager is.
I've had gnome and kde crash on me, as well as xmonad. I've had the most luck with WMII, though it's crashed once.
My head hurts. :-(
Too small. I like big bottoms.
⟘ (And I cannot lie.)
Sure, I absolutely agree with you. I was just exploring the possibility of changing the metric to something more along the lines of ("niceness" of code)/performance. However, I do concede that in terms of performance generally all that will matter is a small portion of code, and then as you say, the ability to write heavy low-level optimizations in this section is incredibly important. Then to an extent the impact of good perfomance (in terms of uncharacteristic low-level optimisations) of the rest of the code is reduced allowing it to deafult to a more idiomatic style of the language in question.
Using it right now
Xmonad has a GnomeConfig helper configuration which makes it really easy to get xmonad to work with gnome.
Sure, but my 'apple' is comparing my configuration with others that I (and in this case, many others) use. If you want to restrict to just xmonad vs wm and not xdm + xmonad vs [g,k]dm + wm then sure, I haven't had many issues with the wm half of the setup.
It was a joke (obviously) but if it would type check better then I can rephrase it to discuss adding wobbly windows and cube-rotation directly into xmonad.
DM and WM are probably the least crash-prone parts. Gnome is a lot more than GDM+Metacity: it's gdm, metacity, gnome-panel, nautilus, gnome-settings-daemon, etc. And since XMonad only replaces Metacity, a lot of XMonad users (myself included) still use Gnome (or KDE) for everything else.
I start fbpanel on the workspace bound to alt-9 and run nm-applet there. Painless. (Not as good as sensible design, but painless.)
Was it poorly written? :/
Nah, I just regularly get stumped trying to read bits of Haskell code. In this case the succ function. I hope it's something I can get better at.
Wow, I thought that project was dead. It could be really cool when it's done!
If it is the first succ function, then don't worry to much about that one as it is *really* messy - the point is in the latter revisions of it (succ' and succ'').
Please no. Some of us use XMonad because it's quick, light, sane, simple, snappy. Adding glitzy transition effects would sort of crap all over that. Plus, wobbly windows? This is a *tiling* WM. Floating windows are the exception here, not the rule!
All y'all other hackers can't deny.
&gt; I cannot understand what fucking level of retardedness leads people to tie the core funtionality of a unix-a-like environment to an X based application. Actually this is a little misleading - the X-based parts of NetworkManager use IPC (D-Bus) to communicate with an underlying daemon.
There is no such thing as a "gnome tray". You just need to implement the Freedesktop System Tray specification (which I'm sure xmonad does). (Oh dear, am sounding like a FDO shill in this thread)
I agree with that. TA needs to evaluate the assignment and what he can see is a pseudo-random string of characters that the student claims constitutes a proof. What COQ accepts as input should not be called "proof", it should be called a verification script. In mathematics a proof is supposed to explain why an assertion is true, not only to verify that fact. So, next time choose a human readable proof language and a theorem proving environment that implements foundation compatible with the class. I suggest Isar and Isabelle/ZF.
I would be inclined to keep the list of the dead separate from the list of the living to ensure that they don't get mixed up: josephus init nth = (dead, last dead) where -- circular: alive gets fed back (alive,dead) = victim (length init) (init++alive) -- find victims and aggregate sequence victim 0 _ = ([],[]) victim n alive = let (f, ~(target:s)) = splitAt (nth-1) alive (alive',dead') = victim (n-1) s in (f ++ alive',(target:dead'))
Slightly improved: josephus init nth = (listOfDead, last listOfDead) where listOfDead = take (length init) dead -- circular: alive gets fed back (alive,dead) = victim (init++alive) -- find victims and aggregate sequence victim alive = let (f, ~(target:s)) = splitAt (nth-1) alive (alive',dead') = victim s in (f ++ alive',(target:dead'))
Primitive recursion for a (red) hands-on feeling: count k = go k where go _ [] = ([],[]) go 1 (x:xs) = let (dead,alive) = go k xs in (x:dead,alive) go j (x:xs) = let (dead,alive) = go (j-1) xs in (dead,x:alive) josephus n k = take n dead where (dead,alive) = count k $ [1..n] ++ alive 
"We explore folds and unfolds on lists, numbers and trees. In fact, a single generic definition of fold can be given once and for all such datatypes, and similarly for unfold. This fact has been promoted in the world of functional programming by Meijer and others [93]; for a tutorial introduction, see [44], or in a different style, [12]. However, such `generic origami' is beyond the scope of this chapter." I guess 93 is a reference to [Functional Programming with Bananas, Lenses, Envelopes and Barbed Wire](http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.41.125)? What are 44 and 12 references to? Are there other related resources?
&gt; We developed a formal semantics for a comprehensive subset of Python called minpy. The semantics are described in literate Haskell, which are compiled to an interpreter as well as a formal specification. How is this "formal"? How are semantics "described" in Haskell different from semantics "described" in C? What does it mean to describe the semantics? Does the fact that this is an academic master thesis by itself make it "formal"? Thanks, Confudido 
I'm starting to read this blog post about starting to read real world haskell. we'll see how it goes..
&gt; How are semantics "described" in Haskell different from semantics "described" in C? From what I can gather, they aren't. They're both precise, unambiguous descriptions of how the program behaves; unlike a natural language description. However, C would be a poor choice due to it's low level and imperative nature.
Everytime you do something like "x &lt;- [1,2,3]" in a do block, imagine it as if the code that follows splits up into three separate processes, each one with x meaning something different. take "do { x&lt;-[1,2,3]; y&lt;-[1,2,3]; return (x+y)} In one "world", x=1 y=1, in another x=3 and y could be 2 
Formal semantics is a branch of mathematics/computer science. Aspects of the execution of a program under formal operational semantics can be proven formally, eg. as mathematics. It is actually a very big deal to work out the formal semantics for a non-trivial language, because so many aspects of most languages behavior are inherited from their environments or tools. The specific claim this thesis makes is not that they've written a python interpreter, but that they've written a formal description of python which is sufficiently rigorous and complete that it suffices as an interpreter.
When you talk about proving aspects of computation, will the proof be verified by a computer or people? if people do the checking then I'm afraid it will be a colossal effort for big programs, probably also prone to errors in proof.
You should blog about that.
I started reading your comment but you lost me at should. so I went to blog about how no one should tell me what I should or shouldn't do
I think I'll tweet this.
These are all of cute, funny and insightful.
I'm sure going to comment on this..
It's easier to translate the Haskell implementation into a theorem prover. You would have to say though, that a Haskell embedding is only semi-formal, given we don't have a formal semantics for Haskell. If they stick to a subset easily embeddable in a logical framework, they might be ok, though.
Come to think of it, I'm glad I learned Haskell as part of a uni course, and not as I'd learn any other language. The lecturer was great, there were no WTF moments, only "oooh, that's sweet" moments.
&gt; I cannot understand what fucking level of retardedness leads people to tie the core funtionality of a unix-a-like environment to an X based application. There's nothing stopping you doing it yourself with wpa_supplicant or one of the alternatives.
When doing code reviews, you want a low WTF rate. When learning a language, on the other hand, higher is better.
Ok nice, but Haskell is not necessarily the best tool for that. The state machine in the thesis is defined as a set of rewrite rules, implemented in a subset of Haskell consisting mainly of pattern matching, guarded equations and a few auxiliar functions. Using a rewriting based language makes far more sense in my book. For instance Maude, with the advantage that reasoning about Maude programs is possible, since it has well defined semantics, a model checker and an inductive theorem prover. Not only that, but the resulting semantics are simpler and look far better, thanks to niceties as AC-matching. The rewriting logic project (http://fsl.cs.uiuc.edu/index.php/Rewriting_Logic_Semantics) does exactly that.
Hi, I'm Gideon, the author. You're right, a Haskell implementation is not the same as a formal semantics, since Haskell itself is not formally defined. Its not the Haskell sources that define the semantics but the document that is generated from the sources. It is formal only because the used notation is fully defined. In principle you should be able to trace definitions of all aspects back to basic (atomic?) definitions such as natural numbers. In practice a great deal of these basics are left out because they are assumed to be common knowledge. Perhaps the main difference between an implementation and a formal definition is in their respective applications. Formal semantics are used to prove properties of languages and related aspects, so they are structured is such a way as to allow this. For example, my operational semantics is based on rewrite rules of a abstract machine which is known to be a good way to structure proofs. Proving anything using the CPython implementation would be very hard indeed. I wouldn't even know where to start. An actual interpreter, on the other hand, would be written with performance in mind. The CPython interpreter for example, uses byte-code to speed things up. My semantics just 'happens' to be executable as well, but is terribly slow.
you sure it was haskell and not a visit to nearby candy shop?
Good post but the the WTF/Oh thing gets really annoying really quickly.
Cool. I have to admit I didn't read the whole thing - you lost me at the greek letters.. :) But it definitely sounds cool. So I guess for example you could prove that a sorting algorithm accomplishes sort and has a certain complexity etc. did you create such examples? Are the proofs verified by machine or by hand?
Don't forget the more direct solution :-) solve i n = i * (n + 1 - f 0 1) + 1 where f a b | b &gt; (n+1) = a | otherwise = f b (2*b) -- *Main&gt; solve 3 40 -- 28 -- *Main&gt; solve 3 3 -- 1 edit: off by one error 
Did DARCS rename to a recursive acronym when I wasn't looking?
Not 20 minutes ago I tried to install 0.9.13. Oh well. 
[PDF](http://unit.aist.go.jp/cvs/tr-data/PS06-011.pdf) (with non-screwed-up formatting/notation)
Odd the http://www.haskell.org/gtk2hs/ site still has the 0.9.13 version as being the latest...
Awesome!! This makes me want to go into a rage and do something irresponsible... like rewrite a cherished C app or two.
 *Main&gt; solve 3 3 7 ??
Perhaps but it wouldn't have got a single vote if it was written in a language nobody uses.
Bah, "Agda" not "Ada". :P Oh well, still interesting!
44 is [Jeremy Gibbons. Calculating functional programs. In Backhouse et al., acmmpc, pages 148-203](http://www.comlab.ox.ac.uk/oucl/work/jeremy.gibbons/publications/acmmpc-calcfp.pdf) And 12 is Richard Bird and Oege de Moor. Algebra of Programming. Prentice Hall, 1997.
It's up now.
Great, but it took long enough that I forgot why I tried to install gtk2hs (and failed) in the first place :-)
This just makes it that much more mind-warping to see how Haskell manages its performance figures in benchmarks.
Seriously. Ever write a hello world program in Haskell and view the assembly output? It's pretty huge compared to the C/C++ version. I'm aware that that's not much of a benchmark, but it's mind-boggling how such a huge amount of assembly produces such a small amount of actual output.
:-), Are you taking the course? Last years GADT lecture was pretty cool as well: http://www.cs.chalmers.se/Cs/Grundutb/Kurser/afp/2008/lectures.html#lecture7
GHC is a good optimizing compiler. A very aggressive one. And it has a fast runtime. Also, we get to use purity to our advantage (e.g. storing the constructor tag in the lower bits of the pointer to the closure...)
Is that 16 bytes to represent 3.3? How does that work?
nice! I'll be there. Get that mailing list up!
I'm taking this course right now :D
What the hell? &gt; hasktags is a simple program that uses simple &gt; parsing rules to find definitions of functions, &gt; constructors, and types. It isn't guaranteed to &gt; find everything, and will sometimes create false &gt; index entries, but it usually gets the job done &gt; fairly well. In particular, at present, functions &gt; are only indexed if a type signature is given for &gt; them. Sounds like `hasktags` should be be rewritten to use the GHC API.
16 bytes = 128 bits
Great! I'll attend.
These are bytes?? I thought they were bits? Those numbers are enormous if we're talking bytes and given they're divisible by 8 I'd have guessed them to be bits.
So its just expanding an 80-bit double precision float to 128 bits...?
This doesn't necessarily have to be the case. For example, compiling this code with [lhc](http://lhc.seize.it): main = putStrLn "hello" results in the compiler generating roughly this much C code (sans a few structure definitions)): void _amain(void) { return (void)b_umain(); } static void A_STD b_umain(void) { lhc_function_inc(); return ftheMain(); } static void A_STD ftheMain(void) { lhc_function_inc(); ftheMain_d2(c5); return (void)lhc_utf8_putchar((int)10); } static sptr_t A_STD A_MALLOC ftheMain_d2(sptr_t v8) { wptr_t v100000; lhc_function_inc(); v100000 = eval(v8); lhc_case_inc(); if (RAWWHAT(CLhc__Prim___x5b_x5d) == v100000) { return (sptr_t)RAWWHAT(CLhc__Basics___L_R); } else { wptr_t v100002; sptr_t v12; sptr_t v14; uint32_t v16; /* ("CLhc.Prim.:" ni12 ni14) */ assert(CLhc__Prim___x3a == GETWHAT(v100000)); v12 = ((struct sCLhc__Prim___x3a*)v100000)-&gt;a1; v14 = ((struct sCLhc__Prim___x3a*)v100000)-&gt;a2; v100002 = eval(v12); v16 = ((uint32_t)GETVALUE(v100002)); (void)lhc_utf8_putchar((int)v16); return ftheMain_d2(v14); } } So, really the code generated is fairly good (basically, all this does is loop through the string 'hello' and print every character, then it prints a newline and exits and the 'c5' variable is the beginning of the string) Of course, we're trying to move **away** from C, but this isn't that bad in terms of size and understanding (try looking at GHC's .hc file output for comparison.) Of course, you did say &gt; it's mind-boggling how such a huge amount of assembly produces such a small amount of actual output. Which I would say can probably be applied to the above C-snippet (~50 lines of code for just printing a string,) but hey, it's better than nothing. :)
Cool. I'm definitely planning on coming.
Yes, its a very old program. Should be trivial to rewrite.
Remember: 8 bytes is a pointer.
As long as Haskell remains awesome, it's not a big deal to me. I've just started learning assembly, so it's my natural inclination to produce some assembly code output to see what GHC decides to do with my main = putStrLn "Hello World!". After that it's my inclination to consider the output really massive just to print a string. Regardless, Haskell is still my favorite language so far.
I'd like this as a Haskell program, so us non-Emacsers can run it :)
rconnor, is the code available?
I have a non-standard tabstop set (in VIM), so indentation initially caused some confusion. Now I just always use a carriage return before I begin any block of code.
Also see the sequel: http://arxiv.org/abs/0805.2438
The haskell prototype lives at http://r6.ca/FewDigits/
As a mathematician who is frequently stung by many of the issues with the current numeric classes, this was a really exciting find. Is anyone here involved in the project at all, I don't see any of these changes in the status page? I'm also interested to hear what people who write non-mathematical code think of the proposal.
I second the motion.
I've never understood the indentation rules in haskell but it's the one thing that has never caused me any trouble.
Has anyone looked at this from a numerical analysis point of view? For instance, the RealFloat context on Complex is there to guarantee that / can be implemented in a good way. 
I'd like to hear of any such analysis - that constraint was why I never finished playing with Gaussians. Of course with Haskell, there is so much to play with... ;)
Nicely done.
It would be nice if it were possible to implement e.g. vector\*scalar, and vector\*matrix using any new class structure. This probably implies multi-param type classes and either fundep or AT...
Definitely a good idea. However, the inclusion of fromRational in the DivisionRing class would seem to limit you to division algebras over **Q**.
Seconded, and that's by design, I think. The indentation rules are sort of complex to state precisely, but that's only because they encode how you'd indent your code anyway if you *did* need to spell out all those braces.
Any plans for another hackathon in Portland?
Same here. I've never sat down and learned the rules, but I can guess how to indent things and it always works.
The [seminearring](http://conway.rutgers.edu/~ccshan/wiki/blog/posts/WordNumbers1/) looks more common and useful than the semiring. Do types rely on the ability to associate from both directions, or is a seminearring adequate for to describe them?
Tim Sheard's little-known language [Omega](http://web.cecs.pdx.edu/~sheard/Omega/index.html) is a Haskellish language that can do some interesting things with C-H.
I have tripped up on the if-within-do problem several times before I figured it out, I think largely because all other indentation appeared unambiguous enough for me to never need to read how it worked.
This is the natural way to define (/): (x:+y) / (x':+y') = (x*x'+y*y') / d :+ (y*x'-x*y') / d where d = x'*x' + y'*y' But what happens when x' and/or y' is &gt; 1e160 or x' &lt; 1e-160? Then squaring it will overflow (or underflow) and you get the wrong result. That's why the definition of (/) looks the way it does. 
Did you know about the [Numeric Prelude](http://hackage.haskell.org/cgi-bin/hackage-scripts/package/numeric-prelude)?
In any division ring, fromRational (p/q) = (1+1+...+1)/(1+1+...+1) \_________/ \_________/ | | p times q times
Then how do you typecheck things like: x :: Double x = 1 * 2 ?
I find it hard to imagine that Haskell' won't have multi-param type classes and quite unlikely that it won't have AT (or something similar). At the same time I do think vector\*scalar and vector\*matrix (if distinct from matrix\*matrix) probably shouldn't be using "\*".
It's great to see the package is getting some use!
Why not? It does in mathematics, and I can't see how it would lead to any confusion here.
&gt; instance Branchy ZipList where &gt; ifB (ZipList ps) (ZipList xs) (ZipList ys) &gt; = ZipList $ zipWith3 if' ps xs ys This doesn't appear to satisfy the Branchy laws. `ifB (pure True) (pure ()) (ZipList [])` is `ZipList []`, while the laws say it should be `pure ()` 
Huh, I never knew that foldl took a beer as one of its arguments.
Well, I just feel that * should not be used if you don't have a semigroup. 
 f &lt;*&gt; ifB b x y = ifB b (f &lt;*&gt; x) (f &lt;*&gt; y) This property won't apply to most Monads: IO, State, Writer, ST, the list goes on.
Aren't all containers in all languages misleading in this way?
Greg Buchholz's comment exactly echoed my thoughts: &gt; I'd venture that the height of hubris is reached when a Platonist tells a Constructivist what he (the Constructivist) thinks I wouldn't be able to articulate it so pithily. On the other hand, I think that the general idea is sound: construction is not containment as category theory includes nothing to be contained. But execution is lacking; what's the point of being so harsh in tone when rigor is lacking? Consider that: &gt; the value (1,2) is a primitive object that is the image of 1, 2 under the mapping ( ) could have been properly (and precisely) written with a little care for the use-mention distinction and the syntactical details of Haskell as: the value `(1,2)` is a primitive object that is the image of `1` and `2` under the mapping `(,)`.
But what if q = 0 in your division ring? For example, in a finite field of characteristic p. The function is not even well-defined, since (p\*x)/(p\*y) == x/y, but fromRational ((p\*x)/(p\*y)) is 0/0, while fromRational (x/y) may be defined.
Good point.
I must admit to quickly tiring of this blog. The author insists on pointing out terrible ambiguities in the language that somehow nobody has ever been confused by.
Yes. I think there's only one topological relationship in software: connection.
How can he claim that something is not a container without having defined what a container is?
Well that depends on what your definition of 'is' is.
FRP is great, FRP with GTK is great, but Grapefruit's examples look like pure line noise: http://softbase.org/grapefruit/darcs/main/grapefruit-examples/src/Examples/Grapefruit/
video http://www.youtube.com/watch?v=MugQXHUZPK8
Slick Willy, is that you?
Packaged up natively on Arch, http://aur.archlinux.org/packages.php?O=0&amp;K=haskell-grapefruit&amp;do_Search=Go
Another awesome post! Thank you sigfpe :)
I have tried taking the author seriously, and it isn't working. For someone who doesn't seem to understand Haskell or category theory, he certainly has a lot to say about both.
Not only that, but insists on educating us about these topics while simultaneously stating that they're "as far from a mathematician as it's possible to get" (quote from memory).
That's indeed cool. How did we all miss that before?:-)
Additionally: class ParamApplicative f where pure :: a -&gt; f s s a (&lt;*&gt;) :: f s1 s2 (a-&gt;b) -&gt; f s2 s3 a -&gt; f s1 s3 b and then have ParamMonad subclass this... EDIT: If we could have higher-ranked class constraints, we'd actually want: class (forall s1 s2. Functor f s1 s2) =&gt; ParamApplicative f where ... 
simp^H^H^H^H Oleg already did it: http://okmij.org/ftp/Computation/monads.html#param-monad
Exactly. It's even worse without the :: Double. It could be: (1 :: Vector) * (2 :: Double) :: Vector or (1 :: Vector) * (2 :: Matrix) :: Matrix or any number of other things.
Very nice. All the proofs are by `refl`.
Category-extras has [Control.Monad.Indexed](http://hackage.haskell.org/packages/archive/category-extras/0.53.5/doc/html/Control-Monad-Indexed.html) which covers Applicative and Monad. See also [this](http://comonad.com/reader/2007/parameterized-monads-in-haskell/) for more discussion (both about Oleg &amp; Edward's versions). Update: And see [this](http://crab.rutgers.edu/~pjohann/f14-ghani.pdf) from 2005, in which parametrized monads are used to implement hyperfunctions. (!!) 
Interesting, but what does it have to do with Haskell?
Thankfully, very litte!
sigfpe's gift is to present matters in an accessible way. By the way: &gt; I didn't contribute anything, this article is just advocacy.
I prefer Oleg's pure ideas and mind-blowing code than all that category theory mumbo jumbo by sigfpe
in the realm of pure ideas, you may enjoy: http://www.brics.dk/~hosc/local/LaSC-7-1-pp39-56.pdf
Closed type families would be type families that are explicitly declared to have types _a_, _b_, ... _z_ and no others?
I don't know what you mean by *a,b,..z*, but closed type families would work like normal functions, just on the type level. I mean, for open type functions like type family F a type instance F Zero = Int type instance F (Succ n) = Int -&gt; F n you are always allowed to add new cases like type instance F Bool = Char which is a bit silly if you plan to use `F` on type level natural numbers only. 
Does this mean fundeps will be getting dropped in some future release?
Every time I read something of his I do get a slight urge to kill. Have you worked out his crackpot index?
Fundeps are still really useful for defining bijections or families where there is more than one thing determined by a relation. class Foo a b c d e | a b c -&gt; d e, a b d -&gt; c e, a b e -&gt; c d, a c d -&gt; b e, a d e -&gt; c d, a c e -&gt; b d, b c d -&gt; a e, b d e -&gt; a c, c d e -&gt; a b is a pain in the neck to define with type families and these cases actually come up if you want something tightly enough defined that type inference is helpful for things like adjunctions, etc.
Yes. That way you can include a default case, because you know no one will extend your type family on you.
I think some time ago (a year or more) I read that it is planned to reimplement functional dependencies on top of type families. But I don't know if that's still being considered.
You may find that this understanding helps with the understanding of the codensity monad for a given functor. newtype Codensity m a = Codensity { runCodensity :: forall b. (a -&gt; m b) -&gt; m b } http://hackage.haskell.org/packages/archive/category-extras/0.53.5/doc/html/src/Control-Monad-Codensity.html#Codensity Is just the 'Just' case of this MaybeT and, hence, it's the equivalent encoding for IdentityT.
Agda always makes me smile.
I’m a few chapters into *Real World Haskell*. The author talks about tail call optimization as a compiler strategy that makes recursion practical without the potential to exceed the stack limits. I’ve seen this before in languages like Scheme, where a “simple” recursive function can be rewritten to have a tail call with an accumulator parameter that holds the function state. The example in *RWH* is directly translatable to the Scheme approach. However, in a lazy language, isn’t the accumulator parameter really an ever-growing unevaluated “thunk”? How does this eliminate the space leaks that tail call recursion is intended to prevent? Thanks. 
Haskell compilers like GHC use strictness analysis to recover strict tail calls from naive definitions (or you can explicitly state the strictness). When strict, no thunk needs to be used. Just as with type inference, it is best to state required strictness explicitly. go !n !acc = go (n+1) (acc*2) -XBangPatterns. An example I used yesterday, import Data.Array.Vector main = print . sumU . enumFromToU 0 $ (10^8 :: Int) where sumU is a tail recursive loop implemented via foldlU. Yields a loop after optimization of: $fold :: Int# -&gt; Int# -&gt; Int# $fold x y = case &gt;# y (10^8 of False -&gt; $fold (+# x y) (+# y 1); True -&gt; x Note how all the accumulators in the sum are now Int# -- i.e. strict ints that can be represented as machine works without a thunk. And the resulting assembly illustrates how strict recursion turns into a goto: $ ghc -O2 -fvia-C -optc-O3 --make C.hs fold: cmpq 6(%rbx), %rdi jg .L2 addq %rdi, %rsi leaq 1(%rdi), %rdi jmp fold So all good Lesson: tail calls are good. Tail recursion really needs strict accumulators. Strictness is easy to add.
&gt; However, in a lazy language, isn’t the accumulator parameter really an ever-growing unevaluated “thunk”? In the naive case, yes. Tail recursion with a lazy accumulator simply trades stack space for heap space. &gt; How does this eliminate the space leaks that tail call recursion is intended to prevent? In order to avoid space leaks, we must place some sort of "demand" on the accumulating parameter. This can be achieved by a pattern match, guard, seq, bang pattern or as a result of strictness analysis by your compiler's optimizer.
Should `((,) e)` be noted as an example of a functor that isn't pointed?
Closed type families are type families which can not be extended beyond their declaration (meaning new instances can't be created for that type family at just any time - you define a strict set of instances, and that's all there is.) Sometimes, we want closed type families, because we may wish for a certain invariant to hold (e.g. if you have two type-families `F1` and `F2`, and some arbitrary type `a`, we may want that e.g. `forall a. F2(F1(a)) == a`.) When you're allowed to extend a type family at any time (it is 'open') then these invariants can be broken, because you can add nonsense instances. For more examples &amp; related stuff, check out [Type Invariants for Haskell](http://tomschrijvers.blogspot.com/2008/11/type-invariants-for-haskell.html).
 return x = (undefined,x) &gt;:D On the other hand, there are some possible definitions for (&lt;*&gt;). Typeclass splitting time? :)
great! post more tips for haskell development in emacs. ideally would be something like http://www.cs.kent.ac.uk/people/staff/cr3/toolbox/haskell/Vim/vim.html but for emacs.
Finally, I was waiting for gtk2hs to work again.
who?
Hey. *blush* Thanks guys :) You can help me out by submitting stuff you find, too!
On the one hand I appreciate interesting Haskell posts. On the other hand, I don't like "Vote up if ..." posts.
dons is great, "Vote up if" posts are not. Please, let's keep them out of the Haskell Reddit.
Ditto.
I'm an official member of the dons fan club.
Anyone have a down-to-earth explanation of ((,) e) and ((-&gt;) e)? Those look like gobbledygook to me and don't seem to give a lot of useful information when I try to look at their types in ghci. Am I to take it that ((-&gt;) e) is just a different way of denoting a function that maps e to something else?
Beer: It's What's For Dinner! 
Probably the only "vote up if" post I won't vote down.
Good work, Don. Your posts are part of the reason I still read reddit, and frankly I'm a bit startled and delighted at how much currency and exposure Haskell has gained in the past few years.
You have now triggered my bad conscience, so I went into the dons page and upvoted everything I remember reading and liking. A small compensation for me being too lazy to upvote in a timely fashion. 
Wouldn't closed type classes be desirable on the same grounds?
This is gratifying. But still .. we need *more code!*
i was going for tongue-in-cheek, but i'm guessing that's how most "vote up ifs" start. i truly apologize and will use guards next time. dons :: Redditor vote::Redditor -&gt; Post -&gt; Post vote you | you `appreciate` dons = voteUp | otherwise = error "haskell is serious business" 
We can make an exception for dons this one time. Even though that involves a monad.
Fun fact: "dons" is the Dutch word for "down"/"fluff". And doesn't he all make us feel warm and fuzzy? ;)
I appreciate it, but I always downvote "vote up if" posts because they're obnoxious :)
We've shown we can crank out high-quality code quickly. But all this code is tieing the language down with backwards compatibility. There is a large list of non-backwards-compatible, but obvious fixes for the standard library, typeclasses, and so forth. We're not obeying the injunction to avoid success, and this will cost us.
I agree. Vote this post up if you do as well.
wouldn't it have been easier to just upvote them when you initially saw them?
 isAgainstUpvotePosts = fail "dons"
you mean Monad-y?
I make no exceptions. See the all time top reddit submissions -- "Vote up if" posts are a cancer that must be excised. vote :: Post -&gt; Vote vote post | "Vote up if" `isPrefixOf` title post = VoteDown -- further cases omitted
I have to agree. I strongly dislike typesetting code so it looks pretty by using symbols that are not available. I don't mind the use of Unicode, but then the exact code that is in a book/paper should work as is, and not after some translation. 
Seconded. Typeset code may look beautiful, but definitely gets in the way, especially if it is meant for beginners. However, highlighting code (e.g. with the listings latex package) can go a long way in making it flow better with text. Also, fixed-width fonts meant for print don't have to imitate early typewriter fonts. Something like Letter Gothic flows much nicer with main text than the CM tt font or Courier New. [See here for an example (PDF warning)](http://www.hvergi.net/arnar/public/ccshaskell.pdf)
I have that book at home. I don't think using mathematical symbols instead of the ascii operators in Haskell was a wise choice, but the book is very good if you can get past this.
Remember that Functor has kind * -&gt; *, that means that you must aply it to a type to get a functor. So for example ((-&gt;) e Int) == (e -&gt; Int) is a functor over Int and is of course functions that take anything and _return_ an int. Basicly the fmap of ((-&gt;) e) allow you to do something with the result of a computations. For example the silly function "doublelength = fmap (2*) length" will return twice the length of a list, it uses fmap in the ((-&gt;) e [a]) functor. The fmap instance is just a synonym for "(.)" I think. Why it's useful is a different question though, I'd use (&gt;&gt;&gt;) or (.) instead most of the time.
Thanks for that! I never even thought about being able to use fmap on functions as some sort of weird composition.
If you enable -fglasgow-exts (there's probably a more specific pragma for this feature), you can use unicode symbols in your code, and some are defined out of the box. [ x ^ 2 | x ← [1..5]] works in that case, but ↑ isn't defined by default (as of GHC 6.8.3). So the code snippet he mentions will work with a pragma and this definition added in: (↑) = (^)
it would be too easy:)
You also need a fixity declaration for ↑ (and to be picky there's an MR problem too). But yes, that's a way to do it. If you do it that way, a book for beginners also needs to explain how to enter those Unicode symbols.
Sorry, I don't appreciate the 'dons' Haskell Reddit posts. I appreciate dons' work with Haskell and Haskell is an amazing technology but I wouldn't mind knowing how Haskell is seen by the larger development community. Or maybe even by the non-developer community. Who are the people using Haskell in production environments? And it is good that we hear first word about anyone that writes a haskell application (my blog has appeared on reddit before as well). But it is certainly has a high noise ratio. Maybe interesting to some, but not that interesting to me. I use google if I really need a one-off code snippet or tutorial. Not to call you out personally 'dons', but I want to hear and only hear about Haskell being used where any other software engineering project is used. I read an article a while back about Lucene/Hadoop being deployed at Yahoo: An article about Hadoop: "Pages in the index: roughly 1 trillion links", "10,000 core Linux cluster" http://developer.yahoo.net/blogs/hadoop/2008/02/yahoo-worlds-largest-production-hadoop.html Kind of interesting, how did they do it. I read recently from Jonathan Schwartz from Sun saying that JavaFX has 100 million installs. I don't know, these just seem like sexier headlines. Or even with Linux, I used to love reading about what is being done with Linux from Linux Magazine or Linux journal. Very focused, in depth articles about Linux. And no, I don't always appreciate the marketing buzz heavy content on the Internet. In fact, that is a the last thing I gravitate towards, but I do like a nice, detailed article describing any technology, one that I can reference over and over again. Maybe something from the DDJ (get Haskell in the DDJ) or other mags. I hope that was constructive enough criticism. EDITED: OK, to be honest my post does not contain a whole lot of validity. I am not programming in Haskell right now. So, a flurry of Haskell posts may not interest me as an temporary outsider. But I will continue to and will use Haskell more regularly. But, when I saw this this reddit post, my original post was what came to mind.
Instead of creating vote-up-if posts, create a post, and put a comment inside it for people to vote up instead.
Yep, this threw me off too when I was reading the book.
^^^ this is all from the guy who won't stfu about clojure, btw 
Haskell != Clojure And I posted a couple of random, non content filled links about Clojure. The Gods will have to let me live. Note: I won't get into the religious fan-boyism. Because clearly, if I saying ANYTHING negative about a technology, the community or anything, that must mean that I must hate the technology. And I like a lot of dons' posts. Even when he posts some of my blog entries about Haskell. But actually, I DON'T hate anything to do with Haskell and programming in Haskell is a very rewarding experience. A productive programming language. With that being said, does this mean that I care to see every single thing about Haskell that appears on the internet, appear in the reddit subreddit. Not at all. I would love if DDJ did some magazine series on Haskell. Case studies. Or more in depth articles. But, is 'Haskell Programming Tips' something I want to read from the subreddit. Something that would be very easy to find through google? http://haskell.org/haskellwiki/Haskell_programming_tips I just wanted to clarify. I have this crazy habit of giving out my personal opinions when they may conflict with the tribe.
I also found the learning curve took a pretty steep ramp up at the chapter on parsers. I kinda lost my steam at that point and stopped reading it.
Also recently mentioned on [LtU](http://lambda-the-ultimate.org/node/3157).
Good catch. A full test program: &gt; {-# OPTIONS_GHC -fglasgow-exts #-} &gt; &gt; module Main &gt; where &gt; &gt; (↑) = (^) &gt; &gt; infixr 8 ↑ &gt; &gt; main = print [x ↑ 2 | x ← [1..5]]
Ok. BUt it is the Haskell subreddit. The kinds of general stuff sound more appropriate for proggit. Feel free to ignore posts, or submit ones you like.
Yea, I know. Just an observation. Glad, my response went better than I expected. This is how we can be civil in the software community. State your opinion, see the positions of sides without trying to rock the boat too much. Plus, I could be wrong because I am not programming haskell right now. If I were doing haskell more regularly then I would be very interested in regular updates.
You can ignore my post. I like the haskell reddit community. Keep the posts coming.
Fair points, but the book he's talking about (the Graham Hutton book) is one of the better ones around. It isn't a book for all beginners, but for ones who have had a bit of math, I think it is okay. Personally, I'm sad that everything is getting dumbed down in the industry. 
How do you find most of the stuff you post? RSS feeds? Or simply knowing everybody in person? Anyhow, great work!
As someone currently learning Haskell, having interesting posts in this reddit has definately helped to keep me motivated.
&gt; but the book is very good if you can get past this. I couldn't. I bounced around in the book to see if I could glean some concepts, but what struck me as a lack of real interest in getting readers to enter and execute running code give me little confidence in the book. The idea that I should use a look-up table to translate example code into actual characters I should use is mind boggling. I gather I am not the target audience, though, since so many others seem unfazed by this.
In the use.perl.org comments, someone wrote It's not an introduction to programming (Haskell as a first language is not really a good idea) I just can't see why this should be the case. As evidence, the first of three compulsory programming subjects in my IT/CS degree (at an Australian uni) was taught in Haskell. *All* the students who already considered themselves programmers (myself included) had trouble with Haskell (at least initially). The math guys did not have trouble. The remaining students broke down 50/50 into: 1) did fine 2) could never program anything in any language. Funny thing: the teacher introduced his own "simplified" IO library to "keep it simple" for first-timers... This turned out to be more trouble than it was worth: by halfway through the 3rd lecture, we'd switched to Monadic IO. As it was an introductory subject, we didn't cover topics such as GADTs, Existential types, Comonads, or Arrows. IMO, *every* programming concept (in any language) is alien to a complete beginner; almost nothing is intuitive first time round. Teach it right, and most of the barriers to entry melt away. 
I bought this book and I completely agree with him. The use of mathematical notation for the program listings is just plain stupid. Also, in one program listing the author uses a busy-wait loop to slow down the program! This is an awful introduction to programming in Haskell, and the fact that it costs $42 is an insult. [Here](http://www.amazon.com/review/R1B85RQMUXV0BM/ref=cm_cr_rdp_perm) is a link to the 2-star review I left on Amazon.
If this is one of the better ones then I'd hate to see the others. I wasted $42 on this book, and its been sitting on my bookshelf ever since. Real World Haskell is infinitely better.
I wasn't terribly impressed by Graham Hutton's book either. It's almost... I don't know, more of a Programming Language theory course book than it is intended to teach you how to use Haskell. It gets you to the concepts that make Haskell interesting, but you don't actually learn how to use them to do anything. I don't think too many people are going to be recommending it now that Real World Haskell is available.
Everyone who learns Haskell needs more than one book. Not all of them know it yet.
I made exactly this point about the typeset code in my review of the book. http://www.cs.nott.ac.uk/~gmh/book-review.pdf It was my second most significant complaint. The first one being that it used examples that only work with an old hugs (or non-default imports). However so long as one is aware of these issues, I think the book is still the best intro around.
I think the nice typesetting is fine, but the symbols have to correspond to the ascii ones closely. For example it's hardly going to confuse people to type "&lt;-" where they see a nice arrow. But the "^" vs up-arrow is really confusing. The worst one imho is typesetting "not" as "¬". It doesn't even work syntactically because it's an operator (and anyway, Haskell doesn't have any prefix operators except "-").
I posted this over in programming, but someone pointed me to this sub. I've just (2 days ago) started looking at haskell and going through tutorials. I've read numerous times that people have felt it helped their programming in other areas, even if they weren't doing functional programming. That piqued my interest, do any of you guys have anecdotes of how haskell has helped you in non-functional languages? 
For experienced users I think a bit of difference in the typesetting is OK, but not for beginners. Beginners have enough trouble with everything else being new, confusing them by unusable syntax is not going to help. 
yep, isn't he great? 
I may be an exception to the rule, but I have found that it has actually hurt me in other languages. I now want to write functional code in imperative languages, and the result is not very pretty. I do not enjoy programming in any other language anymore. :( To retract a little, I have learned a *lot* generally, especially about purity and composability. I now like to make many simple functions and call them one after the other rather than make many simple functions and stack them one on top of the other. The difference sounds subtle but drastically changes the flow of my code. I also try to design all my programs as libraries with thin layers of side-effecting IO on top, which I believe increases testability and makes my programs simpler.
I'd say that I've learned enough Haskell to consider myself *almost* intermediate, though I still can't write anything useful without asking at least one question in #haskell. I really enjoyed the learning process. It's very interesting and I can see the advantages of the language. It gave me an appreciation for FP. However, whatever the program stability advantages, the stability of the platform is *horrible*. The Regex changes between 0.72 and 0.91 (version numbers from memory, may be wrong) are an example of this. Most of the Haskell libraries and programs I wanted to use still needed 0.72. However the 0.72 libraries would not compile with newer base libraries. I tried to buy into the Debian packages, thinking they would be a bit more stable. However they were lagging so drastically that I couldn't get any help from #haskell. Then I went the other direction, deciding I would try my best to remain on the bleeding edge since that was what most of the experts seemed to do. The first step was installing GHC 6.10.1 from the binary packages. The installation script crashed my virtual server because it needed 190 MB of memory to run ranlib on the base library. Finally, once I got past the initial learning curve and began writing more real-life code, much of the beauty went out the window. When I would consult #haskell the consensus was that I would *need* non-standard modules from Hackage to obtain the same beauty I had in my exercise code. My conclusion: good language, good people, but I'll wait until they both get a little closer to the real world platform requirements.
So your point is: "I'm not doing haskell so please stop putting so much haskell in the haskell subreddit because I'm interested in programming in general, but if I were doing haskell I'd be interested"?
&gt; Finally, once I got past the initial learning curve and began writing more real-life code, much of the beauty went out the window. When I would consult #haskell the consensus was that I would need non-standard modules from Hackage to obtain the same beauty I had in my exercise code. Err... You know that not having a monolithic standard library which does everything you could possibly is actually a good thing, right? If you're waiting for the GHC team to import half of Hackage before you'll use Hackage, you'll be waiting a very long time.
I'm using lambdas everywhere in c# now, but I think that's more because of Ruby's blocks.
Python seems to manage. I've got no particular preferences either way, personally, but I've definitely found some dodgy areas in unexpected places. Having a decent batteries-included library is a Very Good Thing, but the maintenance headache that goes with it if you want to keep it up to date with the latest and greatest definitely isn't.
The language: Beautiful. All the advantages of statical typing without the ugly syntax that is used by C/Java/etc. Now that doesn't mean it's perfect (If it were up to me I'd add first-class records and reorganize the type classes in the Prelude, e.g. subdivide Num) but it's a joy to code in. Effect on other languages: Because Haskell doesn't allow unpure code like ML it forces you to think in a functional style. If you have so far only worked with imperative languages you'll learn a lot. The unfortunate side effect is that you'll start to notice the annoying behavior in those other languages. NullPointerExceptions? No pattern matching? No referential transparency? Get it away! The Haskell platform: Haskell greatest weakness and the reason I don't use if for all my projects. A lot of packages cannot be fully installed with cabal install, especially on Windows (Some examples: cabal-install, lambdabot, yi, gtk2hs (the binary installer always complains my ghc install is invalid)). With any luck this will be solved this year by the Haskell Platform. Overall: A lovely language that I would recommend learning to anyone.
http://monsters4bed.blogspot.com/2007/02/our-eyes-met.html Our Eyes Met Our eyes met across the distance between. The space was nothing, or so it would seem. Time stopped, for that one look, but eye contact was all it took for everything to change. Suddenly it felt strange that a face so well known could make me own I had never felt this way before - Yours was a face I could adore. Every night your face would appear before my eyes. It became so dear. My nights became sleepless then. I wanted to see you once again. I wanted to know if I was wrong that a person I'd known for so long could possibly be causing such electricity. Was it my imagination, or was it, maybe, something more? I had to know if it were true, that the feelings I had for you could be explained away as pure fantasy, or may they be based in reality? I had to see. And every time our eyes met I felt it there, and yet I still couldn't be certain, for that damn imagination crept in to falsify what passed between us. I... wanted to ask if you felt it too, but didn't know how to get through that veil of rejection, and so I felt only dejection. Then you were there no more and I was even more unsure. I didn't know why you wouldn't see me. I didn't know what the reason could be. I only know you weren't there. The loss of a dream I had to bear. The next time we came face to face still made my heart race, but I could see in your eyes - nothing. You'd said your goodbyes. And now I am hollow and can only follow my remaining dreams... my empty dreams because you're not there. 
His is a point about marketing. But we shouldn't shut out links to interesting technical content - we're not a corporation, we don't market Haskell by having a "community forum" solely consisting of a sanitised collection of puff pieces. That would be silly. We market Haskell by continuing to be awesome as a community, and write awesome code.
&gt; gtk2hs (the binary installer always complains my ghc install is invalid) I had no problems with this on Windows XP. It did complain at the end about older DLL's on PATH. It works when I have path appropriately modified.
I started this past Saturday with an install of Hugs and GHC. I ordered Real-world Haskell, and I've been reading a lot of online materials. My favorite tip so far is the concept of Currying. It blew my mind that you could write a that would work with one variable and a high-level command like map and then call it like any function with a list to the right, and it would know to put everything together in-place. Slick stuff.
Very similar to my story, except I haven't bought a book yet, i've been working through the 192 page "tutorial." Last night I looked down at the clock and realized it was 30 minutes after I wanted to go to bed, all spent while figuring out haskell :)
I tried to learn Haskell and now I spend all my time reading Wikipedia articles on Category Theory! Functors and morphisms and monoids! Oh my! *Results not typical
"So your point is: "I'm not doing haskell so please stop putting so much haskell in the haskell subreddit because I'm interested in programming in general, but if I were doing haskell I'd be interested"?" I am not doing haskell right this minute, but I try to learn from some of the blog entries without touching haskell code everday. You missed the part where my haskell blog posts have appeared here. Posted by dons.
"That would be silly. We market Haskell by continuing to be awesome as a community, and write awesome code." That is subjective. It is a little marketing. Maybe I have an issue with the amount 'I just downloaded Haskell and then I wrote a program, here is the program...appearing on the subreddit". Or the xml-bytestring-loader-for-utf16...version 0.0.0.0 release...appearing here. What I am kind of looking for are, in-depth articles and blogs that really look at some aspects of Haskell. For example, I just saw this on DDJ, about JForth. JForth doesn't have a large community but, this article appeared in DDJ and details a lot about the technology. http://www.ddj.com/embedded/207801675 
&gt; No pattern matching? Get it away! Oh, truer words have seldom been spoken.
I'm not convinced there's a simple type checking algorithm (and by algorithm I refer to something that terminates). 
I don't mind Hackage. Perhaps I made a poor wording choice with "non-standard modules." What I meant to say was "young, un-tested, and seldom-used modules." e.g. MaybeT. $10 says it makes it's way into the standard library within 18 months :)
The typesetting fails the copy paste test. It also implies that the pretty symbols should work when they actually don't. 
Personally I find it irritating. I like to be able to copy and paste things. Figuring out what symbols to use instead... not so bad. Actually having to do a manual swap... annoying.
There is, but for some cases it will require as input human written proofs.
&gt; "Vote up if" posts are a cancer that must be excised. Why?
&gt; Everyone who learns Haskell needs more than one book. ...but not necessarily more than one about Haskell. ;-)
geezusfreeek, not to hijack the thread, but I wonder if you might comment on what you mean here. Specifically, what do you have in mind when you talk about "call[ing] functions one after the other" as opposed to "stack[ing] them one on top of the other"?
A lot of imperative programmers will have function A call function B which calls function C which calls function D, but separation of concerns means it might often be nicer for function A to call function B, then pass the output of function B to function C, then pass the output of function C to function D. This keeps B, C, and D simpler and more generic, and also makes it more clear by looking at function A what is happening. This refactoring sometimes emerges naturally, but now I think about it a bit more explicitly than I used to. What made me think of this is function composition vs. larger functions in Haskell. The former is usually preferable.
I am putting this on my Google calendar for 16 August 2010, to prove you wrong. (I won't bet, since there's no reliable escrow who won't take a ridiculous percentage.) Note that I define standard library as whatever is included in http://haskell.org/ghc/docs/latest/html/libraries/index.html - that is, in the latest release tarball of GHC. We'll know soon enough.
This is a really excellent point, which I hadn't really thought about before. Thanks!
That's not really the normal definition of algorithm :) And does it know when it needs to talk to a human? 
This must be some new definition of "ridiculously easy" of which I've been previously unaware.
Reading that post is not even easy -- let alone ridiculously so.
&gt; ...by algorithm I refer to something that terminates. This is specifically for type-checking without inference? It's my understanding (but [IANAM][1]) that type inference is undecidable in general, though we seem to be pretty lucky most of the time. [1]: http:/// "I Am Not A Mathematician"
My take is that at this point, Haskell has enough substance. What needs to be dispelled is the myth of being "mostly for language theorists and people who like languages more than actually creating anything" (quoting a comment). So I'd look into well-structured documentation and nice looking websites.
I'm not sure what you mean by lucky. Languages like Haskell and ML have decidable type inference by careful design. You could consider it lucky that you can actually do type inference for such powerful type system. In general, type inference is undecidable, of course. What's even more lucky, I think, is that type inference with Hindley-Milner is practical. The worst case complexity is really bad, but it never seems to effect us in real programs. (Random fact: HM type inference is as powerful as Turing machines with finite tapes.) 
The YAHT is better if you skim it once I think. A lot of the stuff I was interested in was chapter 7, because that gets to the heart of a lot of lambda stuff. I skipped IO for now because I'm currently interested in getting the pure stuff down before I get into IO monads. Chapter 7 has some great stuff about overriding. I'm going to go with the Real World Haskell and skim the rest of YAHT. Sometimes YAHT assumes too much theoric background. Can't wait for the book!
GHC uses System F ([which is undecidable][1]) -- but it uses it to infer types for Haskell programs. I guess the Haskell definition restricts things sufficiently to prevent type-checking from taking forever? In all cases? [1]: http://en.wikipedia.org/wiki/System_F
I think you're mixing up the type system of Haskell and an explicitly typed intermediate language. Haskell uses an ML-style type system, which has been surgically extended to preserve the decidability of inference. GHC compiles Haskell code to an explicitly typed language called 'core'. This used to be just System F with some minor extensions (the addition of GADTs have made things a little more complicated). 
I *love* what the happstack guys are doing. Go go go!
The one thing I hate about Hackage: no sample code on the description page. 
Grr. Both the ruby sample and the haskell sample of "quicksort" are merge-sort.
I think the adoption issue is partially due to the relative lack of friendly tool integration. Textmate for example has exceptionally good Ruby support and shortcuts to most common tasks in one place to support a good workflow. There really isn't much along those lines for Haskell outside of Emacs / Vim. Even with Emacs and Vim, getting Haskell tools set up is a custom-done process with no out-of-the-box support aside from syntax highlighting. At the very least, we need to document typical tool setup specifically for major platforms; I personally have had very little success getting Vim or Emacs on friendly terms with outside Haskell tools.
No.
I found the article at http://people.cs.uu.nl/andres/LambdaPi/index.html to be a nice simple implementation of a dependently typed lambda calculus.
Hey, I got that too - it complained about a zlib1.dll belonging to the wireless software. What's a good technique to handle this without losing the wireless functionality?
You forgot partial evaluation! int foo(int x, int y) { return x + y; } int foo1(int x) { return foo(x,1); } The number of times I've started doing this in C makes me cry... especially when I have all that extra code I need to use to make it work. /me sobs in a corner and taps out his C...
I know. I also left out lazy evaluation, good type inference, automatically derivable type classes, ADTs, the massively convenient syntax, and probably several other things I'm forgetting. I didn't want to turn it into a "list all the ways in which other languages suck" post.
I would love to know what you do with Vim and what sorts of haskell development tools you have come across and use. (I just took a read through the hackage list and found a few tools I want to try)
Neither is quicksort as neither has the in-place property. It's true that it isn't fair to call the ruby one merge sort. But due to laziness the haskell one absolutely is far closer to an inverted merge sort than to quick sort.
I denied your assertion that the quicksort examples were mergesort. This is clearly false, independently of whether the examples are "real" quicksorts in terms of in-place-ness.
Don't put GHC or gtk2hs bin folders in the general path. Using a batch file, create a command prompt (or a Cygwin bash shell) with nothing else on the PATH variable, Just GHC stuff (and System32 stuff). When working with gtk2hs, use this shell. 
This seems like a nice app for stream fusion : stream a list into a mutable array (e.g. a uvector!) sort in place, stream back out to list.
&gt; Or I could use a *monad*.
Don't do it - you might build something useful!
Thanks, guys, for your responses. You answered my question exactly. Actually I just had to go about 30 more pages into the book to get the same info. 
Also see [Matthew Sackman's Session Types](http://www.wellquite.org/sessions/tutorial_1.html) also [Gabor Grief's Thrist type](http://heisenbug.blogspot.com/2008/09/hoare-triples-and-thrists.html) for more examples of "there-oughtta-be-a-type-for-this"
Well, like I said, I haven't had much success setting them up, but here's what I'm talking about: [Haskell mode for Vim](http://www.cs.kent.ac.uk/people/staff/cr3/toolbox/haskell/Vim). Of course, I don't usually use Vim, so I was having to start with no knowledge of how to get anything going. It was mostly just to see if Vim would be a more productive Haskell environment than Textmate. Your mileage may vary.
:%s/Programming/Haskell/g
I can explain why, having used both recently. In Haskell, marshalling and unmarshalling is done in Haskell-land. Conversion functions between C types and Haskell types are given by the implementation of the FFI. To deal with garbage collection, you mark functions "safe" or "unsafe" to indicate whether you will be calling back into Haskell. That's about all you need to know to dive into the spec and start using it. The OCaml FFI is a bit hairier. Marshalling and unmarshalling is done in C-land. This means that if your foreign functions are already written, you will be writing boiler-plate in both C and OCaml, sorry. More importantly, it means that if you are creating any new objects, you will have to call OCaml's allocators manually. The specs for these allocators are a bit touchy; you have to declare things in a very specific order and invoke things just right. The rules are straight-forward, but a little bit annoying. There are a number of things about the OCaml FFI that are slightly irregular, as well, and seem like the OCaml implementation sort of "bled over" into the FFI in an unfortunate way. (For example, foreign functions with less than five arguments are written differently than functions with more than five arguments, and foreign functions with more than five arguments must be written twice.) There's an odd distinction between primitives and blocks which I no longer recall, but beware! When the docs say integer, they might be referring to a primitive int or a block containing an int, and they must be treated very differently. The compilation ordering is a bit touchy, as well, but that kind of thing can be automated without too much trouble. Conclusion: the difference is mostly in cruft. As with several other things, my impression is that the OCaml version evolved to meet the changing and expanding needs of its users, while the Haskell version was intelligently designed. But then... I'm biased. =) I should point out that both specs are short enough to read in one sitting, and after a single read, you can probably already see a bunch of differences that will matter to you: http://www.cse.unsw.edu.au/~chak/haskell/ffi/ http://caml.inria.fr/pub/docs/manual-ocaml/manual032.html
As a somewhat historical note, let me add that the decision to perform all marshalling in Haskell-land was initially motivated by the fact that Haskell is a lazy language. Due to laziness, operations, such as inspecting Haskell values, are quite tricky in C-land. A Haskell value can always be a thunk (i.e., unevaluated sub-expression) that needs to be entered (i.e., evaluated) before it can be marshalled to a C structure. After some first experience with the FFI, we soon realised that it is generally a good idea to do everything in Haskell that can possibly be achieved in Haskell and to involve the foreign language as little as possible. I think this is interesting as it is another case where the unpredictable evaluation order of laziness has kept us honest. Instead of taking short cuts or giving in to premature optimisation (after all marshalling in C might be more efficient), laziness has forced us to adopt a clean design. The other -and much more significant- case is of course I/O, where the Haskell community had to evolve monads (instead of just sprinkling side effects all over the program as in OCaml).
The fusion won't help unless you do more array operations on the list though, right?
Honda63 is the OP. Honda63 messed up the second word in the question. Though I don't get the % and g since they aren't necessary to fixing the problem. s/Programming/Haskell/ would do. And I think posting this to programming would have gotten more responses, if it ever got upvoted enough. This isn't O'Caml stuff, but the answers here are likely to favor only positive experiences in Haskell.
The % isn't necessary, but in vi you need to invoke the command line with : to substitute.
Yeah, apparently he’s a vi-addict. But hey, so am I.
You need % if you are not editing the line you are on, like in my case.
Coolest TH macro of the year award goes to...
i'm trying to understand this. is the win here because we don't have to recurse as much? or where is the overhead we're avoiding?
Less jumps. More straightline code. I think it was not appreciated just how much of an improvement this makes to some GHC code.
Yes, and loop unrolling to depth 64 is probably a pessimisation for most non-toy examples. That said: cool macro! BTW, did anyone try the benchmark on gcc with loop unrolling turned off (and the rest of -O2 enabled)? I'm interested to see how much of the performance difference is attributable to loop unrolling itself. 
Given the asm I'd say this is a loop-unrolling benchmark. Real code wouldn't benefit as much from it as this does, but it would be nice if it was done.
What I wonder is that, with aggressive fusion yielding loops with tight innards, is there win or not for unrolling them. Fusion's good for getting tight loops, does it get better if combined with some unrolling?
Are there lessons here for [LHC on LLVM](http://lhc-compiler.blogspot.com/2009/01/why-llvm-probably-wont-replace-c.html)?
Apparently they "ignore" GC, which was lemmih's main concern.
I do believe there is a downmod bot running.
I'd like an LLVM backend for GHC!
My favourite part of this post is the flowchart. It's almost as cool as the narwhal currently adorning this reddit.
will llvm automagically give us haskell on arm?
Don't we [have that](http://packages.debian.org/sid/armel/ghc6/download) to some extent? I'm not sure if it LLVM has an Arm backend, but I imagine porting GHC to LLVM would be more work than improving the Arm backend for GHC as is.
Yes, a beautiful flowchart. But what scares me is that, though my first thought on how to solve the problem was explicit recursion, which I have little problem with, looking at combinerState1, I just glanced at getNext and thought, "Oh yeah, State monad." I must be starting to turn into a real Haskell programmer...
Silly contest, British educated English speakers being at a disadvantage... (little quiz: do you know why? :-)
because they might say naught instead of zero?
Nah, it's because we put an "and" after the hundreds. eg "one hundred and three". Edit: I'm not British, I'm Australian. We do things the same way.
It's worse than that - "and" is also used for 1001... 1099, 10001..10099 etc. Also in US English is 1100 always eleven hundred or do some say one thousand one hundred.
1)Lazily generate the textual representation of each number. Count the number of instances for each letter of the alphabet on each iteration. 2)After you've iterated over all the numbers, you'll have the count of appearances of every letter. Just find to which letter the 51 billionth occurrence belongs to. 3)Profit
US English users also use 'and' sometimes- it's just optional.
Because the British don't have a word for an American billion? (In fact, they can't even conceive of the *concept* of a billion.)
Fantastic article! This is a brilliant way to teach advanced Haskell and CS concepts, yet remains written in a very approachable voice. I can't wait to read part 2. Edit: apparently these were written in 2008. Here's the rest! **[Part 2](http://conway.rutgers.edu/~ccshan/wiki/blog/posts/WordNumbers2/)** **[Part 3](http://conway.rutgers.edu/~ccshan/wiki/blog/posts/WordNumbers3/)** **[Part 4](http://conway.rutgers.edu/~ccshan/wiki/blog/posts/WordNumbers4/)**
[Milliard](http://en.wikipedia.org/wiki/Milliard).
How do they bail out THEIR economy then?!
*whoosh*
Now, if this had to run under 1MB of RAM, this would be an interesting challenge.
Because of this bug in GHC: http://hackage.haskell.org/trac/ghc/ticket/2747
Shouldn't the tweets of the Haskell reddit be tagged with #haskell?
42 hehe
Is hiding and redefining + and \* considered ok in Haskell? I would have expected that they use some new operator name, like &lt;+&gt;, &lt;\*&gt; or similar. 
Maybe it's because I'm a haskell nub but I much prefer the original definition.
A slightly longer one-liner that just uses a simple fold: fillWith :: [String] -&gt; [Maybe String] -&gt; [String] fillWith ss = snd . foldl (\(x:xs,ac) -&gt; maybe (xs,ac++[x]) (\m -&gt; (x:xs,ac++[m]))) (ss,[])
In Haskell, the redefinition doesn't bleed out. edit: plus it was done to be consistent with the mathematical notations, which tends to be a good thing in these cases.
Proper type signature fillWith :: [Maybe a] -&gt; [a] -&gt; [a] fillWith = evalState . mapM (State . maybe (head &amp;&amp;&amp; tail) (,))
I wouldn't say it was *okay* but for pedagogical purposes it's better than introducing some other operator which doesn't cleave so closely to something you would recognise as multiplication. I think it's more about introducing the abstract algebra than solving the actual problem. I know I learned a lot from these posts.
And for reference, the [old results](http://shootout.alioth.debian.org/gp4/benchmark.php?test=pidigits&amp;lang=all) show GHC using 2.5 MB while Java Server uses 9 MB.
Is GHC buggier than the mainstream compilers like GCC and JavaC?
Fixed: Thu Nov 6 03:37:14 PST 2008 Simon Marlow
I doubt it. Why not have a look at how many bugs are open / closed though.
Specifically [the pi-digits GHC program compared to the #2 Java -server program](http://shootout.alioth.debian.org/gp4/fulldata.php?test=pidigits&amp;p1=java-2&amp;p2=ghc-1&amp;p3=java-2&amp;p4=ghc-1). Caveat lector - the benchmarks game doesn't really provide any opportunity to minimize Java memory use, we just the default settings.
By bugginess I mean the quality of the released software. What's broken in CVS before the release doesn't matter to me. But if something is fixed in CVS after the bug showed up in the official release doesn't quite make it OK.
The quality of GHC is high. People build companies on it.
&gt; People build companies on it. Is this the criterion of quality?
It's a criterion. One that shows people are willing to take serious risk betting on the quality of the Haskell toolchain. What's your criterion?
&gt; It's a criterion. One that shows people are willing to take serious risk betting on the quality of the Haskell toolchain. The buggiest compilers I've ever used were VC++6.0 and some early GCCs (they were very buggy for C++ code). I don't know about those GCCs, but people did build companies on VC++6.0. Imagine that! &gt; What's your criterion? Like I just said: bugs in released versions.
Check the GHC bug tracker. Besides this obscure GC bug that happened to affect a prominent benchmark, there's not been anything that has affected work at Galois for a long time. The releases are robust. But by all means, do your own analysis on the bug tracker.
as roconner points out, by the way, i was writing about a comonad, but not (formally) a zipper, but rather a pointed tree comonad: http://www.nabble.com/Re%3A-An-Alternative-Data.List.Zipper-p21523484.html 
&gt; &gt; What's your criterion? &gt; Like I just said: bugs in released versions. It's dangerous and/or misleading to look at bugs as the sole indicator of quality because not all bugs are known and not all bugs are equal. * Inefficiency is not the same as an error. * Some bugs are feature dependent. If there were a critical bug in Template Haskell, it wouldn't mean much unless you used Template Haskell. * Some bugs are problem dependent. E.g., hanging on to memory for too long while stream processing might only have a significant impact when working with streams over 1 GB in size. * Some bugs are implementation dependent. E.g., a problem with lazily reading infinite lists only crops if if your implementation lazily reads infinite lists. Doing a quality analysis is really difficult work, which is why a lot of people (me included) look at what others are staking on the technology. If a knowledgeable person is willing to bet a lot of time and money on it, it's probably pretty good. If you need it for a large project with specific needs, then investing time into research and testing is a good idea.
An easy one to tackle is regex-dna: * it is already parallelised [here](http://haskell.org/haskellwiki/Shootout/Parallel/RegexDNA) * And was very fast But it is a bit illegal due to the use of pattern matching for substitution, rather than regex subst. So modify substCh to use a regex lib substitution, and we're back in business. This is only a trivial part of the benchmark too, so all the hard stuff is done.
&gt; Doing a quality analysis is really difficult work, which is why a lot of people (me included) look at what others are staking on the technology. By this logic, we should all be using Java and C#
So... can someone help me out here? What's the point of an Arrow? To explain what I mean by that question, I am referring to the distance between the raw type signature and the way it is conceptualized by users. For example, it's one thing to understand Monad's type signature, and another to understand how they actually work. So, I understand the Arrow type signatures. Is there anything more to using them than just the raw type signatures indicate? The arrow papers seem to imply they actually have some sort of use, but the more code I read based on the arrow combinators the more it just seems to be a way of dealing with tuples that is a convenient shortcut when it happens to fit a problem but otherwise provides nothing of interest. This blog post seems to imply that there isn't anything much more there, too. This is in stark contrast to Monad, which is one way of making a pure FP language actually useful. So, am I wrong? Am I just looking too hard for meaning? Or is it just syntax sugar for dealing with tuples? I mean, that's nice too, but makes me wonder if it's worth the trouble.
No, by this logic, Java and C# aren't very buggy. Grandparent is making a naked appeal to authority though. I'm not able to judge the veracity of the GHC source though, because I've never studied it and I doubt I will ever have the time. As far as a metric goes, though, surely good design principles and high code quality are fairly useful as criteria.
Arrows let us build up computation *graphs* (like hardware circuits). If you have that need, an Arrow may well be the right abstraction. Examples of where this abstraction gets used are: hardware layout, gui abstractions, parsing.
I read the one sentence explanation and don't understand what this is for.
&gt; Caveat redditor ftfy
so is it 'wrong' or frowned upon to use them as convenient combinators when working with tuples? or is that good practice.
This post reminded me that I think explanations of the mechanics of abstract things like arrows or monads are really under-rated as a starting point for explanations. My brain can build up the abstraction on its own once I am comfortable with the nuts and bolts. Starting with a metaphor to introduce monads is just backwards I think.
No, I do it all the time. `first`, `second`, `(***)` and `(&amp;&amp;&amp;)` are awesome.
I sped regex-dna up, made it less illegal, parallelized it, and submitted it to the shootout a couple of weeks ago (they are slow). This is by no means the final word - I just wanted to improve things a bit. At your prompting here I've added all my submissions to the wiki.
Excellent. I see it [here](http://alioth.debian.org/tracker/?func=browse&amp;group_id=30402&amp;atid=411646) Seems like it is waiting for Isaac now. Good work!
Well, that really seems like a valuable use of your time. Now, on to the important stuff. Will version 2.0 randomly pick from any of the images on http://www.ascii-art.de/ascii/uvw/unicorn.txt?
The input file does not seem to be available any longer -- does anyone have a copy? Oh, the output is unavailable as well.
Input is from the 'fasta' program.
Hey, designing, writing and releasing this package, then making a youtube video of it took all of about 15 minutes. Hackage + cabal is easy, kids!
"This conference sucks and is now about Haskell"?
Well, at the bottom of the [page][1] they provide links to particular input and output -- links which are broken at present. I thought other folks working on this benchmark might have the files lying around. [1]: http://shootout.alioth.debian.org/u64q/benchmark.php?test=regexdna
Hey. This is Haskell. Shouldn't you make a narwhal package instead? :D
But you haven't answered my question yet! Where's my random pony images?
Why did you put that comment in quotes.
WAT
okay, what's with the narwhal? i mean, I know they are rad.
 cabal update cabal install pony So are we supposed to use cabal or apt? If cabal exists, why do distros package up haskell libraries?
Distros exist to distribute binaries, and to resolve other dependencies on the system. So use apt to get your haskell stuff that depends on C, or to get binaries (xmonad, cabal-install, gitit, haddock, ...) It happens that Duncan, primarily, has put together an awesome pseudo-package manager that is also portable. Use it if it fits your needs. It probably builds more stuff than your distro (unless your distro is Arch).
There's a video, btw, http://www.youtube.com/watch?v=Tu0iuHxL3z8 Enjoy! Ponies for everyone (narwhals in version 2.0!)
Just look at the subreddit's header and you'll see what I mean.
I don't think so. LHC will use LLVM but they are not expecting optimal performance. They'll use LLVM in the same way that GHC uses gcc, as a portable base line. They will then experiment with custom native code generation, to take full advantage of the GRIN approach. At least that's the plan (as outlined by Lemmih at the recent London HUG talk). Of course hopefully in the mean time LLVM can be improved to be a better target for FP, GC'ed languages.
Fock me, way neat...
W.T.F. !
&gt;I'm so tired of playing, &gt;Playing with this bow and arrow, &gt;Gonna give my heart away, &gt;Leave it to the other girls to play, &gt;For I've been a temptress too long. 
The haskell fanboys kill me sometimes.
Because of their use of forum memes?
OH snap, looks fun.
I just wish it hadn't been GPLd. I use Erlang at work. Now this isn't even an option for me, and if I want to do something similar to this, I'd have to start from scratch. If it were BSDL'd I could use it, and contribute, but now it's useless to me.
Yay! Documentation, finally! 
Haskell: making things I don't understand simple enough so that I can pretend to understand parts of them.
I finally get it!!!!!!!!
It's a classic. 
I think its easier to understand Functor, Applicative, Monad, in this order - as extensions of each other's expressive power.
I propose a new law: As Haskell becomes more popular, the number of monad tutorials on the Internet tends towards infinity.
There is also http://haque.nfshost.com/haskell-xmpp , which is different. And there is hacked lambdabot, which uses this library. It could be made available, if anyone interested.
Not sure why you have been downmodded for asking a perfectly legitimate question. Come on guys, mod for content, not disagreement. Anecdotally, I'd say I probably punish the poor GHC compiler as much as anyone on a fairly regular basis. I've run into two bugs in VERY new features in the entire time I've been using it, and neither of those prevented me from getting the code I needed to write out the door, both were caught at compile time by the compiler itself noticing that something was fishy, and both were fixed promptly within days by the folks at Microsoft Research. Also note that the only time I encountered those bugs was while working with the unstable HEAD branch of the compiler. By comparison I've had far more problems when dealing with the lunatic fringe of GCC pre-release builds. ;)
Clearly you should submit patches to the author!
It's a bit like emacs eval, or other window managers' scripting languages, but for the XMonad window manager. It's handy for quickly testing or refining code that eventually will end up in a config or an extension, but can be used for much more. xmonad-eval opens up a wider, more flexible world of interpreted rather than compiled interactions between XMonad and external scripts or programs.
cool, thanks
... or a reason to make Cabal smarter?
what will distros be for then? :-) Just bootstrap scripts for cabal-install?!
Ideally ;D
Will they provide value for situations where there are non-Haskell dependencies? (E.g., making sure that libcurl.so is installed before installing any Haskell libraries that depend on it.)
cabal-install still has it's uses for creating distro specific packages such as finding dependency chains and packages that need updating.
&gt; Just bootstrap scripts for cabal-install?! And install a haskell compiler, no? (also, as MechaBlue indicated, dependencies on non-haskell stuff such as bridge libraries, cabal doesn't handle that does it?)
ideally, we should get rid of linux as well, and just run everything off of House. (mostly kidding)
cabal install gtk2hs gtk2hs requires GHC 6.10. Install ? Y/N 
Wonderful article, and great work Ben!
Very cool stuff! I'd like to know why the scaling is so different on different arches.
Mailing list is up: http://groups.google.com/group/bostonhaskell
Maybe someone can give nice words of support for popularity and success of our little language :)
I like'em both. Haskell for the language. Erlang for the OTP libraries. If someone would port OTP to haskell, it would be perfect. (My haskell-fu would be woefully inadequate for this.) 
Is Either the best way to handle this? I lean toward something out of Control.Exception but I'm fairly ignorant in this area.
What happened to avoiding success at all costs? ;-)
I think you should pick languages according to your own taste and not popularity and success. Picking by the latter will put you in the middle of the road. And who wants to be there? You'll just get run over. :) 
Well, you need OTP _and_ message routing. Really, the latter is a bigger deal than the former.
What a nonsensical babble. While true in some theoretical sense, it's false in practice. There's always type Dynamic if you want to program with dynamic types. 
I am always suspicious of people invoking Godel to dismiss language features. 
A great question that has been asked before [http://article.gmane.org/gmane.comp.lang.haskell.libraries/6382](http://article.gmane.org/gmane.comp.lang.haskell.libraries/6382)
Am I reading this correctly, his program allocated 12 GB of RAM?
Note that it now uses [Language.C](http://hackage.haskell.org/cgi-bin/hackage-scripts/package/language-c-0.3.1.1)!
Ah, no. This is a common mistake. Done it myself. That value refers to garbage collecting. It probably only uses a few MB of RAM.
Ay, posting solutions is not encouraged. I don't think it matters too much with these old problems. I think everyone would appreciate if the new problems are left unspoiled though.
I meant, does this mean that over the course of its execution, the program allocated 12 GB of memory? I figured that at any one point in time it must not be more than a few MB.
You, my friend, have fantastic timing, this will save me a few dozen lines. :)
Yes, 12Gb over the life of the program; 6.3kb maximum at any time. Though this is hardly an efficient program (e.g. generating hundreds of random test cases takes time and space)
I've always heard about this isomorphism, but now I understand the basics. Its simpler than I thought it would be. Thanks!
OK, thanks!
my hope exactly! thanks for the upvote. will try to track comments here at reddit from now on.
or, (/2)
Well done Chris!!
What the hell language is this?
I would say [coq](http://coq.inria.fr/).
I thought the idea was to try to PREVENT that from happening?
I'm upvoting this because I think the documentation is quite good compared with that of most libraries on Hackage.
Also, give me an internship! (Please!)
I take it this code is about proving the calculation and less about dividing by two.
 let eleven = 12 in ... I also liked this quote quite a lot: &gt; Unfortunately, whoever designed [the Prelude] knew just enough mathematics to be dangerous and made a complete hash of it.
 -dno-black-holing Turn off black holing (probably doesn't work) I don't know what black-holing is but I don't like the sound of it and would like it turned off by default.
When I read the numbers on the mailing list, I was duly impressed. As a beginner Haskell, I'm glad to see there are ways around some of the perceived problems with solving problems in a functional language. This makes me think anything's possible.
What kind of problems?
it's too late for that
Ditto. Looks like a standard algorithmic improvement to me.
Probably he's referring to a mis-perception about lower complexity bounds due to the perceived absence of destructive updates? 
Isn't this linkjacking?
Nope.
Well-Typed is the company that is doing organisation for the IHG collaborative development scheme so I figure it's ok for us to announce it on our company blog as well as on mailing lists etc.
This was mostly a misunderstanding: http://hackage.haskell.org/trac/hackage/ticket/510 but the one real issue identified is now fixed: http://hackage.haskell.org/trac/hackage/ticket/512
The module in question provides both. A pure api that provides a parse error as a detailed structure and an impure convenience api that throws an exception (via Control.Exception).
I'm not talking about this problem specifically. When I talk with my co-workers they always bring out old saws about how you can't solve real problems with functional programming because it's all recursion. Or because functional programs don't do X where X is some sort of OO panacea (to them) that makes OO magical. Never mind the side-effects and black boxes and pure hell I always encounter when I touch OO, or the overly loose pile of spaghetti that are most well-used scripting languages.
[cabal install liboleg](http://hackage.haskell.org/cgi-bin/hackage-scripts/package/liboleg-0.1)
Haven't looked at it, but what's the difference between this and a list-based zipper?
Is this the same idea as [MonadCatchIO](http://hackage.haskell.org/cgi-bin/hackage-scripts/package/MonadCatchIO-mtl)? It looks similar.
For a moment there I thought you meant `cabal install oleg` and I thought "That's it, I'm learning Haskell".
Gee, I'll rename the package if that's what it takes :-)
It does admittedly cheat on the asymptotics. It is constant for practical machines, but only because Data.IntMap can't store anything larger than the machine's native integer size. Thats a bit like saying that searching through a string is constant time, because my machine can't store a string bigger than some constant. It is a nice implementation though.
Oh man... I'm disappointed. Doesn't that kinda defeat the purpose of a linked list, if it's based on a dictionary with a fixed-size key?
I cheer for any advocacy of formal methods, but do either of the liked voting schemes provide non-provability? I.e. isn't it possible for a voter to certify to a third party what his/her vote was?
It's pointless until ghc is ported to brainware though. But the day I can `cabal install oleg` *in my brain* will be awesome.
Metaphors are hard. Let's go shopping!
Maybe you should ;) -- Because DList contains the `pointer' to the current element, DList -- is also a Zipper 
Tiny, elegant source code + smart compiler + good codegen + excellent hardware == parallelism FTW!
&gt; updates the value in the current node in time bound by a small constant Isn't it bound by O(min(n,W)) as given in the IntMap documentation? Nice and efficient and all, but hardly the competitor for speed to the imperative version it seems to be claiming to be. 
Does data parallel haskell compile to mpi/etc for large multinode clusters?
Nope. It's GHC compiler and runtime support for shared memory multicores. Though one could imagine a cluster backend.
you mean: debian-haskell hacker ❤ xmonad ?
Has anyone done anything other than dot products with DPH?
exactly
So are we going to use this for deciding what the haskell logo is?
http://darcs.haskell.org/packages/dph/examples/
Are GpH and Eden available somewhere for download? Last I heard GpH and GdH were built for GHC 4.x or GHC 5.x, is that still true?
Yes, both of the protocols linked to from the posting provide non-provability (provided that the key used to create blank ballots remains secret).
I wonder what the new regex-tdfa module would do to the current regexp-heavy shootout benchmarks. As it's basically a drop-in replacement, it should be easy to modify the benchmarks and see them whoop :)
I wonder why they create a new TSO each time they do spark work, why not just let the TSO stay around until the spark queue is empty? That way if you're interrupted while running sparks by a runnable thread that just does a tiny bit of work and then blocks, you can reuse the TSO and keep running sparks, rather than having to create a new one from scratch. In fact, why not keep the TSO around forever? It's just one per HEC right? Also: having to log in to post comments on the blog sucks. Unless you can use OpenID of course.
It's much simpler that way. We don't have to keep track of a special spark thread per HEC, or worry about what happens when the spark thread blocks: it's just an ordinary thread.
Well, yeah. I guess it's just odd to see a direct link and a blog that quotes the direct link. My apologies.
It's great to see my favorite language getting more serious attention. I hope one day I can use Haskell at work.
I have no benchmarks to back this up, but intuitively it "feels" like it should be quite common for spark execution to be interrupted by "normal" work? Especially in real apps which is full of both normal concurrency *and* task parallelism (I could see how e.g. ray wouldn't suffer from it but it's probably not representative). And if those sparks are tiny, having to set up a new thread to execute just one or two (or N) of them might be a significant overhead (effectively disabling the batching optimization which was significant)... Again, guesswork... Also, any thoughs on user-mode scheduling in Windows 7? ConcRT is using it, might make sense to avoid having to kick off multiple OS threads just 'cause one of them blocks in a foreign call. I guess it wouldn't be as important in Haskell since most blocking are on the Haskell-thread level rather than on the OS-thread level?
True, with a mixed concurrent/parallel workload it may be that caching some TSOs to avoid creating new ones would be a good idea. But I'd like to see measurements to indicate that it's a bottleneck first, since it would add complexity. I haven't looked in detail at user-mode scheduling (I think I saw an early draft of a spec quite a while back). I suppose it might help for those blocking foreign calls, as you say.
While the issue has been resolved to allow both, I figured I'd toss my two cents in anyway. In general, it's better to build for the future. The number of people using 6.8 will continue to drop as more people move to 6.10 and beyond.
Wonder how many years it'll take before naive code eventually becomes defacto code.
Sorry about the typo in the title.
I think: do using (mbind, mreturn) { ... } can be replaced by a function record or tuple, as a middle-ground between that and full type-classes: maybeMonad = (mbind, mreturn) do using maybeMonad { ... } Also, wouldn't normal function records work reasonably well here, or at least better than completely specifically-typed functions? The holes and provisional pattern matches are exactly the same idea I had in mind, for how to have an interactive Haskell editor that keeps all the types correct at all times. Cool!
And why the word "using"? Removing that it would look exactly like Cayenne. :) Furthermore, if the ? works well you should be able to say do ? { ... } a lot of the time. 
If it gets as far as just "do ?", then I think you could remove the "do ?" too! I will have a play and see what happens... (Wouldn't it be nice if there was a mature full spectrum dependently typed functional language with all these mod cons... maybe one day... as it is we spend at least as much time playing with notation and fighting with the implementations as we do exploring what you can do with it...)
I don't mind the 'do' so much since it marks the start of monadic syntax. But I don't know enough about Idris to tell if you'd need it or not. 
Don't say say in the paper that the strategies are leaking memory? That may explain the GC problem. (?)
That is so cool. I'm really glad to see this framework getting some love.
The true liboleg would include the following definition: isItImpossible = False 
Like pointers?
Good point. I had the feeling I was being foolish.
I'll demo the logos in the title up until the voting week!
\#51 by Jeff Wheeler ftw!
Really, go read the paper. It's excellent. It makes me very hopeful for Yi, if it'll be using this principled approach to incremental parsing.
#100 is where it's at.
There's a lot of good candidates. But i have to agree that is the sharpest looking logo. 
wow! a lot of time and talent went into those.
my vote is definitely for that one. though I'm not sure if the YEAHHHH is necessary at all. 
I like #13, White lambda in red circle on black background. (Also reminds me of the ghostbusters logo.) The slogan shouldn't be part of the logo, and there should be one version with just image-logo, and one official logo + the text "HASKELL".
It looks like a Wipeout team logo. That's awesome.
I'd vote for it if only for the fact that lambdas are so tired. I can barely think of something more forgettable.
I like #61, the snowflake. It's friendly and fun. There are a lot of other functional languages that use lambda as a symbol (such as PLT Scheme) but here it's more subtle. 
It is pretty cool and powerful-looking. Looks like it should be on a running shoe or something. I just wish the examples weren't in somber greys.
Wow, that's ambitious. Extra points if the assembly is generated by Haskell.
Making a lamda look like snow is cute, but the question is what does snow have to do with Haskell?
I really like #34. It may not be "in-your-face"-haskelly (it does resemble a lambda, slightly), but it's simple (to draw on a napkin), easy to recognize, and not too busy.
&gt; Wow, that's ambitious. It's been done multiple times already though.
The history of the binary trees benchmark is here: * http://haskell.org/haskellwiki/Shootout/Parallel/BinaryTrees It's quite easy to write (and notionally to parallelise) in Haskell, as I point out here: * http://donsbot.wordpress.com/2009/03/04/playing-with-ghcs-parallel-runtime/ But unless you mess with the GC hints, * http://shootout.alioth.debian.org/u64q/benchmark.php?test=binarytrees&amp;lang=ghc&amp;id=3 it is hard to get it to efficiently parallelise. Maybe finer grained parallelism will help (could we even try permuting all possible `par` points.... ?)
Hmm, I wonder if you could write some kind of genetic algorithm to build this code -- or at the very least try different combination of par points... We should get shapr's Cell CPU collection to work on it... :/
Why don't we just add a -server flag to the ghc rts? :) 
Yes, I had the same thought today. I'm already doing that for inlining...
I guess, the real problem is keeping up with SimonM's upstream changes :)
-server is the default Java VM for the current benchmarks game hardware
So -server appears to just be a alternative set of defaults?
I'm not clear what you mean - for the current benchmarks game hardware it is *the* set of defaults.
http://book.realworldhaskell.org/read/
I think what he's asking is if the "-server" flag just sets some other properties for the Java runtime, i.e. larger heap etc.? So does that mean that Java is essentially getting a head start because they have a built-in "give me lots of heap please" flag and other languages don't? In other words if ghc adds a "-server" flag too that sets the heap to a large number, will that be enough to work around the current rule about not modifying the heap size? To put it bluntly: Why is "-H300M" for Haskell considered cheating, while "-server" for Java is not?
Well, I'm not really implying anything, just pondering the idea of if there are useful "server" defaults for GHC. I wonder how the current GHC defaults are arrived at.
Personally I don't think the benchmarks should have any rules about default runtime settings. I very frequently run GHC apps with different-from-default options (e.g. smaller initial stack size for programs with lots of tiny threads). That's just how you have to run apps in languages with sophisticated runtimes in the real world, so it doesn't make sense to arbitrarily restrict the options to whatever happens to be the default. I do understand that it makes it harder to stress specific things such as heap-growth, but it's not very realistic and if some language's have more beneficial defaults for a benchmark then they'll win on that rather than by any virtue that is applicable for real apps.
&gt; Why is "-H300M" for Haskell considered cheating, while "-server" for Java is not? 1) I've already said "`-server` is the default Java VM for the current benchmarks game hardware" but apparently that wasn't clear enough. On the current benchmarks game hardware there's no difference between java -server binarytrees 20 java binarytrees 20 On the current benchmarks game hardware all that `-server` flag does is stop Java fanboys insisting that the programs be run with the `-server` flag. 2) java does have a "give me lots of heap please" flag **-Xms300m** The difference between `-server` and `-Xms64m` [**should be obvious** to you.](http://shootout.alioth.debian.org/gp4/fulldata.php?test=binarytrees&amp;p1=java-2&amp;p2=java-2&amp;p3=java-2&amp;p4=javaxx-2) 
I think it would be nicer to be able to compile default RTS options into the executable itself, and this would probably be acceptable for the game.
Nope, it wouldn't be, afaik. Only whatever values are baked into GHC's RTS make sense, if we go by "whatever is the default"
They abound: [Learn you a haskell for great good!](http://learnyouahaskell.com/) [Write a Scheme in 48 Hours](http://en.wikibooks.org/wiki/Write_Yourself_a_Scheme_in_48_Hours) [Yet Another Haskell Tutorial](http://en.wikibooks.org/wiki/Haskell/YAHT) And, of course, the Real World Haskell book. Real World Haskell is a welcome addition to the Haskell world, since the examples are primarily everyday programming problems, where the other books deal mainly with toy examples or highly specialized problems (compilers/interpreters). Also, it is a truly complete treatment of how to approach problems in a Haskell mindset. For what had been such a low profile language, there are a lot of free, high quality resources for learning it. Nevertheless, if you use Real World Haskell, you should buy it when you are able to do so in order to support the publishing model they chose and to make it economically feasible to produce more Haskell books on the big presses.
I just wish they would give some indication that they were even reading the comments people leave anymore. I left a ton of comments on that book before it went to print (though undoubted after the print version had been finalized), and I have no clue if they're going to compile them and make any changes to the online version or publish an errata.
Also: [Haskell Tutorial](http://www.lisperati.com/haskell/) by Conrad Barski [Software Tools In Haskell](http://www.crsr.net/Programming_Languages/SoftwareTools/index.html)
With this comment, aren't you assuming that the reader knows what RWH stands for? And, if they already know what it stands for, then they wouldn't be asking this question, would they? Personally, as a reader I prefer english over a bunch of obscure or just-made-up acronyms.
Haskell is unique and cool. ;) But really, while the computer scientist longs to see Haskell accurately reflected in the logo somehow -- hence the multitude of symbols that use the bind operator -- symbols don't have to be so closely tied to the thing they represent. Incongruity can even be an advantage. Linux has a penguin. I read a critique by a marketing guy who thought that the penguin was brilliant since as soon as you saw anything computer-oriented with a penguin of any kind, you knew it was Linux-based somehow. (This was the late 90s when there was an explosion of new Linux companies. Nowadays it's a part of everybody's computing infrastructure, so, not so much in 2009.) Animal totems work well for that. So the narwhal isn't a terrible idea either, if it was less cartoony. So, we should ask ourselves not "does this logo capture the true nature of Haskell", which is impossible for a graphic to do anyway. But more like "is this a symbol that the Haskell community can rally behind, and does this logo stand out against the crowd of other languages"?
I agree that it is very appealing, but the lambda in a circle is IMO a bit too obvious. Plus there's a very popular video game, [Half-Life](http://en.wikipedia.org/wiki/Half-Life_%28computer_game%29), that uses a similar symbol.
You could have just said that it stands for Real World Haskell.
Errata for the printed version can be submitted [here](http://oreilly.com/catalog/9780596514983/errata/). 
Wow! Silently downmodded! 
Actually, under the Sun jvm, -server means a few things. The major one is that it indicates that you want it to more aggressively optimize your jitted code, in exchange for an initial compile/initialization penalty. I believe that it also used to change the garbage collector to a concurrent collector (instead of a halting collector), with different default settings for the generation sizes.
Would it be useful to vary *the defaults* as the hardware varies? Single cpu, sequential GC; multicore cpu, parallel GC? Lots of GBs, larger initial heap?
It's not really a book, but the more I keep on going through my little side project of learning Haskell, the more I find [the Haskell Wiki](http://haskell.org/haskellwiki/Haskell) of fundamental importance and absolutely one of the best tools available to newcomers. Highly recommended. Oh and by the way, [this](http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html) is also pretty neat :).
Yes, seems like something that could be detected at either compiler time, or an initialisation phase. There are all sorts of other useful defaults (cache sizes =&gt; array chunk size). Mmm..
We should have clearly documented processes for doing this.
More distribution libs plz!!
The big question is whether you are able to bring back things as useful as closures back to practice in mainstream languages. If you can't, calling Haskell a "rabbit hole" is appropriate.
Here's what I think are the reasons why binary-trees is slow in Haskell compared to other languages: 1. As you pointed out in your blog, dons, a small change to gc defaults improves thing hugely. This fixes the CPU utilisation problem, and I think the thread-local gc that the GHC people have been talking about will also help. I think that tuning ghc a little is the answer here. 2. I found that loop unrolling "check" by breaking it into three functions with 2 &amp; 3 inlined makes a big difference (about 10% in an allocation-heavy program). I think unrolling tight "loops" could be a general optimization in GHC. 3. The hugeness of the change that "loop unrolling" makes indicates to me that there's a bit of overhead in function "calls" that other languages don't have, and I am assuming that this is the price we pay for Haskell's extremely fast threads. 4. Some of the implementation use an object pool, so they are not allocating memory (in the traditional sense) at all. Haskell doesn't give enough control over memory allocation to allow this, and neither does Java. Comparing garbage collected languages, Java is only 2.4 times as fast as Haskell in elapsed time. Personally, my opinion is that the implementation of this benchmark is correct and that attempting to speed up the benchmark itself is wasted effort. I think that the effort needs to go into GHC, and I am aware that much of this is already happening. 
Closures yes. Things like cartesian closed categories and generalized monoids I'm not so sure about. I have no idea where to even begin translating such awesomeness into C++/C#/Java. Even F# seems weak in comparison.
A little over a week ago I took a peak at Haskell. I am not a very experienced programmer and just do it for fun. I am now sliding down the rabbit hole and my school work is slipping. Haskell makes me think in new an interesting ways, I love it.
got fanboyism?
No, that's a small question... The big question is how and when does Haskell become the mainstream language.
When a retrovirus selectively wipes out every programmer who has never written a proof for fun.
One of Haskell’s mottoes is ‘avoid success at all costs’.
Oh hi, you must be me.
[The Haskell Wikibook](http://en.wikibooks.org/wiki/Haskell) (not to be confused with the Haskell wiki) is very good.
Hey, I was him first!
For the past year, Haskell has been responsible for a large number of instances of my brain exploding. I love it!
Um, I mostly use programming languages as a tool to solve problems. If it helps me in an intuitive way, bring it on. If it's a bunch of self-indulgent esoteric concepts which take more effort to learn than what it saves, I'll look elsewhere. From an academic point of view, it could be exquisite, but from a practical point of view, perhaps not that awesome.
No you must be mistaken. It's me!
&gt; in an intuitive way how do you know that something unintuitive isn't practical? how do you know that it'll take more effort to learn than it saves? this is the problem.
you're on the haskell subreddit. 
I think it depends on the programmer and the problem at hand. What might be practical/intuitive for you is not for me (or in my circumstances). For example, `parsec` might be interesting to learn and fit in better with the ideals of haskell, but if `Boost.Spirit` via C++ gets my job done faster, then that's more intuitive and practical to me. I don't know why my previous comment is getting downmodded, since it was a general remark, not necessarily about Haskell or this article.
&gt; I don't know why my previous comment is getting downmodded, since it was a general remark, not necessarily about Haskell or this article. Tone and venue make it suggest that you believe that Haskell is: &gt; ...a bunch of self-indulgent esoteric concepts which take more effort to learn than what it saves...
LISP mainstream, Python mainstream, or Java/C# mainstream? Haskell could replace LISP because it has that rarified air and a power that is difficult to tame, though well worth it for those who can. Think Jedi Knight. Haskell probably won't replace Python and Ruby because they appeal a lot to people that want to start programming now and muddle out the design over time. They take care of the details, leaving the fun stuff to tackle. Think Han Solo. Java/C# won't be replaced by Haskell because of large corporate investment into personnel, training, and systems. It would take a lot to overcome the inertia. Think of the Empire with its legions of storm troopers. Han might be convinced to take some Force training because of the cool shit that Luke can do but his lack of patience will slow him down. The storm troopers will continue to miss the mark with poorly aimed pot-shots.
I just realized that I'm doing the opposite. Instead of trying to translate Haskell features into other languages, I've spent the last few years trying to express features from other languages in Haskell. If you really want to figure out how stuff works, your best bet is to figure out how to pseudo-code it out in C using pointers. (It works for me, at least).
I still hope Haskell will make an incursion into Python et al, because the speed/parallelism ratio is so much better, http://shootout.alioth.debian.org/u64q/benchmark.php?test=all&amp;lang=python&amp;lang2=ghc&amp;box=1
Not to sound like a complete ignoramus, but what does this library do? It sounds really cool and awesome but I'm not entirely sure...
I've been continually surprised at the uses I've found for "esoteric" Haskell features like arrows, infinite data types, etc. However, the main reason I use Haskell is because it is a very practically useful language. Type checking eliminates probably 95% of my bugs, compared to other languages (including statically typed ones like Java or C++). Higher-order functions, polymorphic functions, and type inference save me an enormous amount of redundant work, and allow me to translate concepts very directly into code. The libraries are exceptionally dependable and easy to use (although, documentation could be improved).
Haha, I tend to forget that an opinion, if it's against the majority, is automatically assumed irrelevant or even offensive ;) Well I *do* believe some parts of haskell and its associated libraries are exactly that, but that still doesn't stop me from using it for stuff where I find it's actually useful, right? If I subscribe to this subreddit, that already says I find it useful. The point is that you can say so for almost any language, as there's yet to be an all-encompassing programming language with which no one has any issues. So even if the comment *was* specifically a criticism of haskell or this article, I don't see why it has to be downvoted (so that no one happens to see it?).
yep, there is a lot of reinventing the wheel around this. we did this on our blog, and someelse did it at the same time (with a simpler approach IIRC). And now a third one... Proof if it was needed, that slowly introducing haskell modules/lib in a foreign code base could be *the* way to speed up adoption. Python had some much success because of the ease of embedding and extending the language. Embrace and conquer, sort of. Haskell should be more "link to us and have a taste of a modern fast language". 
Opinions without substance aren't good arguments - hence they get downmodded.
&gt; but if Boost.Spirit via C++ gets my job done faster, then that's more intuitive and practical to me. Give a man a fish...
And *that*, sir, is what I mean when I say some parts of haskell are self-indulgent. parsec is not in any way superior to Spirit, but of course haskellers and parsec users like to think their method is the better one. They are just *different* ways to do the same thing, and IMO Spirit is the more intuitive one (just check the syntax for building sequences of parser blocks: Spirit uses an almost straight-EBNF style, while parsec uses `do` blocks). On a related note, I think monads are totally unnecessary to create a text parser. A parser based wholly on algebraic datatypes and regular functions (maybe I'm not using the proper terms) is very well possible, and I had been writing something like that a few months ago, but lost interest. Maybe I should finish it.
You realize that most monads are built from *regular functions*? If the set of regular functions you have is structurally (EDIT: and semantically) the same as that of a Monad, you can make an instance and gain a lot of useful code that will work with your parser. 
Oh ,you can DO it, but without typeclass style polymorphism, what would it buy you in C? You would end up with a heap of boilerplate code to support your construction which would eliminate all of your gains. Now, C++ might be up to the task, but I fear the holy heap of templates that would support such a beast.
If you have an applicative functor applied to an instance of Num, it constructs an instance of Num for the application of the functor as well. I had to dig through the code to figure that out, though.
 Silence my clones or I won't let you use the Interwebs again! You know very well that you are all me.
Is this efficient enough to use for communication among Haskell RTSs in a closely coupled cluster?
We should be able to do it with Cabal. See http://hackage.haskell.org/trac/hackage/ticket/148 It suggests an approach like: name: foo version: 1.0 foreign_dynamic_library build-depends: bar other-modules: Foo That is a distinct kind of buildable from a Haskell lib or executable. It's a shared lib buildable. It does not export any Haskell functions, only the declared FFI exports. The ticket mentions Windows DLLs but the same applies for Unix shared libs.
I think I misunderstood. I was approaching it from the perspective of a thought exercise for the purpose of better understanding functionality, not from something that's intended to be used in a program.
way to go, duncan !
&gt;Comparing garbage collected languages, Java is only 2.4 times as fast as Haskell in elapsed time. True; however, Java runs on a virtual machine. For (a perhaps better) comparison, ATS compiles to native code and is [also garbage collected](http://www.cs.bu.edu/~hwxi/ATS/ATS.html), and the top ATS program runs in 5.87 seconds -- *seven* times faster than Haskell. EDIT: Scratch that, the ATS implementation says: &gt;the GC of ATS essentially serves as a recycling center for memory: The GC is not running.
Unfortunately, I doubt this is practical beyond toy programs... Actually I think the results would be more interesting on the nofib suite than the shootout game, to help the GHC team improving things for everybody.
I think this is almost certainly practical for production high performance modules.
Why is this unpractical for real apps?
&gt; ⇌ ♥
_Before you can do anything with the Erlang FFI, you minimally need to start up the Erlang Port Mapper Daemon (epmd)._ epmd: back in business! http://en.wikipedia.org/wiki/EPMD 
I still don't get it :(
This is a very important question, IMHO. The Erlang interprocess communication protocol could easily become a de-facto specification for the interaction of programs written in multiple different functional languages. (Or non-functional languages of course, but the impedance mismatch is definitely larger.) There's no reason Haskell couldn't be talking to Scala over this protocol with no Erlang in sight (except maybe epmd, which is a very small process by desktop or server standards, clocking in at under 2MB of memory total).
ok, as long as the modules are self-contained and options have local effects only. 
As a future PDX student, I am quite interested in this work. The paper does a nice job of not only summarizing what has been contributed, but also acknowledging where their work stopped too short or has yet to see the light. These issues include include: Performance/benchmarking, which was pointed out by Shapiro a couple times on LtU. I'm guessing this is what Kenny is working on with [Lighthouse](http://web.cecs.pdx.edu/~kennyg/house/). Uncertain memory usage, which will remain a difficult nut to crack. I think some people at PDX are involved in [Timber](http://www.timber-lang.org/) and probably for this reason... perhaps I'm wrong, I only seem Mark Jones on a couple of the papers, not sure how involved he is in the project. RTS assurance, which certainly seems to have consumed the plurality of PDX folks via the [HASP](http://hasp.cs.pdx.edu/) project. Unfortunately, the paper didn't give an update on the preliminary microkernel (L4) and hypervisor work ([PDF](http://web.cecs.pdx.edu/~rebekah/papers/hhv.pdf)) that was mentioned in past publications. This makes me question the vitality of those efforts. 
An example. Lets take a look at the anonymous reader monad. if 'a' is a numeric type then we can also treat b -&gt; a as a numeric type. where (+) :: Num a =&gt; (b -&gt; a) -&gt; (b -&gt; a) -&gt; b -&gt; a (f + g) x = f x + g x and the other definitions follow similarly. Now, its a bit of a hack, because in Hakell Show and Eq are superclasses of Num (blech) and we can't pretty print lambdas or decide equality of functions in general. This generalizes though, any applicative functor applied to a Num type could automatically be made an instance of Num through a very mechanical process. That said, some of the instances violate the preconceived mathematical notions that Num is trying to model. For instance the reader above was ok because the 'values' don't have any side effects, but if you move to, say, a writer monad, then the order of the arguments to +, *, etc. start to matter more because they define the order of side effects. OTOH, Num makes no guarantees with respect to associativity/commutativity, so they are technically OK. Edit: Fixed spacing
What about the parallel C program?
The artile. http://www.cse.unsw.edu.au/~chak/project/dph/ Still no link to benchmark code. Looks like C still wins by at least 20% on the dotp benchmark. I'd like to see the code. EDIT: removed reference to blogspam.
Use 4 spaces in front of code lines so their layout isn't destroyed: (+) :: Num a =&gt; (b -&gt; a) -&gt; (b -&gt; a) -&gt; b -&gt; a (f + g) x = f x + g x 
cool
It's not blog spam when it's the authors blog. Source for dph (and benchmarks) is here, afaik, http://darcs.haskell.org/packages/dph/ i.e. this is the Haskell parallel sumsq: sumSq n = sumP (mapP (\x -&gt; x * x) (enumFromToP 1 n))
Thanks. I'll edit my post.
I agree, this would be most useful if a bunch of people submitted their hardware/os specifics and the results of Acovea used on some set of standard programs. That may result in enough information to improve the magic SimonPJ heuristics for the inliner. I'm also curious if some particular factor changes the best thresholds for inlining? Perhaps cache size makes the most difference?
Aw man, where's the IRC quotes section? That's my favorite part!
People have already suggested the obvious ones. Depending on your current level of knowledge, you might find [Implementing functional languages: a tutorial](http://research.microsoft.com/en-us/um/people/simonpj/papers/pj-lester-book/) interesting. It's not intended to teach you Haskell, but it does teach a lot about how Haskell works internally, and in a way explains Haskell's approach to functional programming at the core level. 
For some examples, see the papers *[Beautiful differentiation](http://conal.net/papers/beautiful-differentiation)* and *[Denotational design with type class morphisms](http://conal.net/papers/type-class-morphisms)*, including guidelines for when these instances make sense semantically.
Hmm, sounds interesting, they probably require you to have completed a degree of some kind though :)
Dependent types go marching on. Sounds like a great project.
ditto 
Donnie Jones, Simon Marlow and I have been working on infrastructure for logging run-time events and a graphical viewer program called ThreadScope. Hopefully these features will make it into the next release of GHC. We hope the event-log viewer ThreadScope will be useful for the performance tuning of parallel and concurrent Haskell programs. You can see a few screen shots at the program's website http://raintown.org/threadscope Before making the release I thought it would be an idea to ask people what other features people would find useful or performance tuning. So if you have any suggestions please do let us know! Cheers, Satnam Singh 
I would assume that the C represents the target performance; the goal of DPH is to get the same performance with nicer and more modular high-level code.
Ehh, Quickcheck is useful, but it's utility is hit or miss. Quickcheck would not likely find problems with Euler Problem #54, even assuming a perfect oracle to test against.
Iono, but ganja makes it easier.
because drunk people are less functional
you got your monads in your morphisms
Very nice. Thank you very much!
Does it?
Ba-dum *tish*.
rather, why do some people, including me, opt to try coding in haskell under the influence?
Never code under influence without revision control!
I find the opposite. =D 
The "Freedom from state" would be a fantastic t-shirt!
I hear curry makes you sober.
not in my experience.
&gt; Yer come home drunk, and yer think yer can code. Yer sittin' there, coding, and yer thinkin' this is some hot-shit code, I'm a hot-shit coder. &gt; &gt; And then in the mornin' yer wake up with a huge hangover and yer look at the code and yer say what the fuck, this is shit code. As reported by my operating systems lecturer.
Nice. Lately i was wondering if such a thing would be possible - useful for catching size errors when manipulating vectors and matrices, for example.
 I find that the Ballmer Peak (http://xkcd.com/323/) occurs in Haskell as well. Perhaps you ended up to the right of it?
That's obvious - it's the side effects.
When first starting with Haskell, I found that alcohol helped. Maybe it was that it helped me loosen my procedural way of thinking. Now that I've got a better handle on it, I find that productivity is exponentially related to sharpness.
 $ git log commit f09f555f9d29b56587762350288c76b1e61c274e Author: Arnar Birgisson &lt;arnarbi@x.com&gt; Date: Thu Feb 26 00:14:52 2009 +0000 Beer 1 commit ae136c4357a9e8c2606d8ce4e231ca3db5274da9 Author: Arnar Birgisson &lt;arnarbi@x.com&gt; Date: Thu Feb 26 00:47:18 2009 +0000 Beer 2 commit 7e53ddc28126a74e7fb47174d78764341b05e67f Author: Arnar Birgisson &lt;arnarbi@x.com&gt; Date: Thu Feb 26 00:53:58 2009 +0000 Beer 3 commit 5a0a824d4bcbfbfcc50fcab186ce715e12d64ca3 Author: Arnar Birgisson &lt;arnarbi@x.com&gt; Date: Wed Feb 25 01:10:33 2009 +0000 Beer 4 + shot
&gt; Never code without revision control! FTFY
This is interesting but there are no numbers on the graphs. So for example, where it says "At about 7 sec..." we have to guess what the tick marks mean. &gt; The vertical lines are hardware threads... I can not be sure but it seems that _horizontal_ lines are hardware threads.
Sadly, it's still doesn't work on windows...
Fortunately, Linux is free! :P
Argh, no release notes?
My thoughts exactly - what's new?