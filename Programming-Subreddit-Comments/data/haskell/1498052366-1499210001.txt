We had two beginners in our company learning Haskell from "Learn you a Haskell for Great Good" and they had the same experience as you. What finally worked for them was http://haskellbook.com I would seriously recommend dropping everything else and going through that book. Also, what other language did you learn? Did you learn that by doing theoretical problems like those given in "99 Questions" on the Haskell wiki, or did you start building small useful tools with it? Say, a blog, or a reddit clone, or something like that? If the latter approach has worked for you wrt other languages, please use the same approach for Haskell as well. Not everyone's mind is geared towards learning by doing CS101 exercises.
Your Applicative instance is valid, but I wouldn't be surprised if QuickCheck can't check it due to its use of infinite lists. Your Monad instance is not valid, however. One of the Monad laws is `return a &gt;&gt;= k = k a`. When `return` is `repeatList`how could this ever be possible? In fact, I don't think such an Applicative instance would permit any Monad instance at all, because of the two laws: pure = return f &lt;*&gt; a = do f' &lt;- f a' &lt;- a return (f' a') Basically, when writing a Monad, it's easier to start with the Monad instance first, and write the Applicative instance for free by using those identities. This is guaranteed correct by construction, as long as you obey the Monad laws. instance Applicative List where pure = return f &lt;*&gt; a = do f' &lt;- f a' &lt;- a return (f' a') If you define your Applicative instance this way, the Monad instance you wrote is very nearly correct. You just need to define `return` such that the laws are obeyed; your `(&gt;&gt;=)` is actually fine. This isn't to say your Applicative instance is bad. It's actually the well known `ZipList` Applicative, which I think is somewhere in the `base` library. It's fine if you don't try to give it a Monad instance. But the laws don't allow a Monad instance to exist with that Applicative instance.
I am not sure what to suggest, instead I will share my experience. personally, I find it hard to use one resource and understand Haskell language using it. so what I have made is to focus on learning concept instead of reading a full book. generally, I have started using `Real world Haskell` and ofcourse I did not understand what a `Functor` is and what a `Monad` is, rather I have learned the very basics. in parallel, I started to focus on understanding each concept alone. lets say `functor`, it was ambiguous for me so I used many resouces to read about `Functor` as : * Learn You a haskell * Real World Haskell * programming with haskell - Graham latest edition and ofcourse * I have read many many articles about `functor` . you can follow the Haskeller on twitter, the usually share some important article. I did the same with `Monad` and I tried to read form several resources and blogs and asked questions on reddit. the haskell community is very beginner friendly.
"99 questions" is lousy for an introduction. It's a Haskell translation of a Lisp translation of Prolog questions. They are phrased in terms that often don't accommodate the fact that Haskell is typed, so they must often be translated into *different problems* before being solved. Furthermore, they are phrased in ways that Haskell users generally would not find idiomatic in the least, and request things that just seem *silly*.
I agree with what you say about LYAH, but I don't agree with your conclusion at all. Haskell is not a hard language. The core of Haskell is very simple compared to other languages, and learning Haskell is not harder than learning other languages. The problem is that the most popular resource to learn the language from looks really easy and innocent but is actually a really bad resource to learn from. The issues with it were mentioned many times in the subreddit and in this thread alone as well. All we need is to direct beginners to better resources. - [Use this to get started with Stack](https://haskell-lang.org/get-started) (and/or visit [this guide](http://howistart.org/posts/haskell/1/) later) - Follow [haskellbook](http://haskellbook.com) or the [haskell wikibook](http://en.wikibooks.org/wiki/Haskell) if you must - Find out more about [common libraries](https://haskell-lang.org/libraries) and [specific usecases or other tutorials](https://haskell-lang.org/documentation) - If you need some reference for a specific concept use [wiwik](http://dev.stephendiehl.com/hask/) - Write programs and read the source code of other programs Rust is not that different than Haskell in terms of learning curve either, it's just that the most popular Rust resource is pretty good.
If you know some C++, this episode from Bartosz Milewski: [https://youtu.be/i9CU4CuHADQ](https://youtu.be/i9CU4CuHADQ) is an absolute *must* see for someone learning Haskell. Also, check out his Haskell playlist, and be sure to look up C9 from Microsoft hosting Eric Meijer with an excellent intro to Haskell.
SECTION | CONTENT :--|:-- Title | Category Theory 3.2: Kleisli category Description | Kleisli category Length | 0:41:58 **** ^(I am a bot, this is an auto-generated reply | )^[Info](https://www.reddit.com/u/video_descriptionbot) ^| ^[Feedback](https://www.reddit.com/message/compose/?to=video_descriptionbot&amp;subject=Feedback) ^| ^(Reply STOP to opt out permanently)
Hi. You may also consider [axiom](https://github.com/transient-haskell/axiom), the GHCJS/GHC library that [haskell-do](http://haskell.do/) uses. It has an unified, seamless reactive model for server and browser. 
The above comment is a polite understatement! Let me formulate the non-humble version of that: Come to Zurich, it's amazing! Here you find: * ZuriHac, a yearly Haskell mega-event with hundreds of people (that's, like, 20x the number of Haskellers in the world ;)) * Regular HaskellerZ meetups with large attendee groups (often &gt; 30 people at the talks) * Multiple companies that are built on Haskell, and more people that work remotely with companies that use Haskell * Some of the highest quality of life (housing, salary, welfare, services, low beaurocracy, beautiful nature: lake and mountains) in the world
Great post. Thanks! &gt; I would assume that calling `uncurry f` would be generate slower code than `\(x, y) -&gt; f x y` but it turns out it doesn't. I haven't tried to figure out why, but I think it may be because one of the ghc authors is a huge fan of the `uncurry` function and thinks its important that it should be fast. The reason is actually much simpler than that. `uncurry` is a very small function and consequently GHC is quite eager to inline it. This essentially turns the code that you wrote into the code that you thought would be faster. 
This talk was fantastic. It was exactly what I was looking for. A first principles explanation with some history behind functional programming. I appreciate it. Thank you!
Hmmm... that's pretty neat. I also didn't know that was the name of what I was looking for. I just watched a video from another response that had an introductory video to graph reduction machines. Thanks for the response.
No haskell uses if then else
I really can't understand how people can learn a language by doing small exercises. I was never able to. I can learn something by doing a moderately sized project, but those 10 minutes exercises from books never did me any good. I do like the Learn you a Haskell because it has a sufficient set of reasonably self contained explanations for the biggest problems I got on my first Haskell project. My routine was, try hard to make it work -&gt; fail to understand something -&gt; go to the book and read the appropriate chapter -&gt; try hard to make it work again. Besides, natural problems do not usually push you into (or out of) any language feature, so you get to apply things when you are ready, not when the book author thinks you are. Anyway, learning Haskell is hard work. Good luck and do not give up, it's worth it.
Thanks for the link and explanation! I plan on (attempting) to read this paper. &gt;The truth was, it took months, years, to build these graph reduction machines. And they were large. It was impossible to keep up with the performance of silicon chips. So did it have more to do with the issue of trying to compete with the rate that intel could put out new chips? If you know, how did the Graph Reduction Machines fair in comparison to Intel chips back in the day? I'm just curious. Were they seen as a viable alternative? 
I had a similar experience - I liked the book until I didn't like it. About halfway through (around Applicatives) things stopped clicking automatically. The lack of exercises is the real problem. Moving from that to Real World Haskell worked wonders for me personally, but now I'd recommend Haskell from First Principles.
&gt; So did it have more to do with the issue of trying to compete with the rate that intel could put out new chips? Well the processing elements in the GRIP machine were commercial Motorola 68020 processors, but all the other stuff was built by hand, i.e. the communication layer and the intelligent memory units close the the memory use for graph storage. Dataflow computers were also seen as significant at the time. What killed special purpose dataflow computers in the 80s was the time it took to get tokens propagated through the communications network to the processing element it was to be matched on. So most of the time was spent merely communicating data, stalling computation, in dataflow computers. Maybe similar limitations were true for GRIP, Alice, and other graph reduction machines, at scale. Another point is that there are *distributed* parallel graph reduction machines in more recent time, again in software. Take a look at GUM: *GUM: a portable parallel implementation of Haskell* www.dcs.gla.ac.uk/~trinder/papers/gum-ifl95.pdf
 {-# LANGUAGE OverloadedStrings #-} import Database.PostgreSQL.Simple hello :: IO Int hello = do conn &lt;- connectPostgreSQL "" [Only i] &lt;- query_ conn "select 2 + 2" return i ([From the docs](http://hackage.haskell.org/package/postgresql-simple-0.5.3.0/docs/Database-PostgreSQL-Simple.html)) You can write plenty of useful programs without the need to know how to use monad transformers
No pay. No care.
Yes, that would be possible.
?
I would also recommend https://drboolean.gitbooks.io/mostly-adequate-guide/ since it has exercises and it's written using a language that you may actually get to put in practice at work (if you're more web inclined) I hope recommending studying FP using JS isn't considered a sin here :P
I've managed to achieve even better results (more than 2 times better) with unboxed vector of `Char` compiled with `-O2`: https://gist.github.com/vagarenko/d272148bbb83781908769550312407e0 benchmarking string/10000 time 83.13 us (82.93 us .. 83.32 us) 1.000 R¬≤ (1.000 R¬≤ .. 1.000 R¬≤) mean 83.10 us (82.94 us .. 83.30 us) std dev 627.9 ns (517.3 ns .. 804.0 ns) benchmarking vector/10000 time 30.57 us (30.49 us .. 30.64 us) 1.000 R¬≤ (1.000 R¬≤ .. 1.000 R¬≤) mean 30.49 us (30.45 us .. 30.55 us) std dev 165.5 ns (130.0 ns .. 227.0 ns)
What was your experience of reflex-dom apps on mobile?
I'm sorry. I meant how were your **web apps** on mobile? I don't mean native/hybrid mobile apps.
This is not that surprising though at big companies. In practice you aren't going to be spending time with HR day to day, so it can very much be a non-issue. If you really liked the team and had confidence about the workplace, then I would recommend you don't brush off the offer due to the HR alone.
It's not a sin! Whatever helps people learn FP is all right by me! But I do have misgivings about it. Learning functional programming involves teaching yourself to think totally differently. In my view the best way to forget everything you know about programming is to be _forced_ to do so. So I advocate that people learn to functional using a pure language. Then you can go back and apply your newfound powers elsewhere. Oh yeah, the other reason is that JS is terrible üòù
I mean 'a' instead of 't'
I found it by looking up 'skip locked' after encountering it in one of those docs you pointed to. Postgres keeps marching ahead with good things on the horizon.
Sounds like you're on the right track! Perhaps look into some libraries and contribute to improving them. Or consider doing your master thesis around a Haskell project (possibly even improving GHC).
London will still be in Europe geographically. Will it no longer be a good place for Haskell?
nice thanks, any beginner friendly tutorial to start with reflex?
The `LType` data type is another great example of the ["trees that grow"](https://www.reddit.com/r/haskell/comments/5iovx9/trees_that_grow_interesting_paper_about_extending/?) approach.
I agree that constraining yourself to using a language that doesn't **let** you go the imperative route is beneficial to learning FP, but in this case the pros of learning FP via a language that the reader might already be using and might also apply at work win, IMHO. I'm personally on the fence of whether to choose Elixir, Clojure, Elm or PureScript for my next language. I'm not really considering Haskell because I don't see myself potentially using it for consumer facing apps; but perhaps I'm setting myself for a chicken and egg situation with that mindset.
Are you, by any chance, familiar with the iOS/macOS community there; is it as vibrant as the Haskell one? (I'm migrating from that area to Haskell and thinking of moving to Zurich.)
Amazing work. That is another breakthrough. Sad that cool kids don't appreciate it. I'm sure that commercial companies will do.
of course it's not. it just show that querying a database in haskell can be just as easy in haskell as other languages.
I live in Zurich (immigrated 2 years ago from Germany), but have no idea about Apple communities.
I guess, but I have friends/family here in the US. It's attractive for a short term position but nothing persistent.
To put it poetically: Haskell feels like a house that hasn't been lived in. I get the feeling that there won't be as many libraries/suggestions/community as the alternatives might provide. But that's entirely perception, since I haven't actually tried to build an application with Haskell :)
But that doesn't really address the problem the person you are replying to was pointing out. It's not that you cant' find things that are as easy to do in haskell as in other languages, it's that there are whole classes of problems that are simple in other langues that aren't in Haskell, because to do them in Haskell you have to understand more complex things, like monad transformers. The argument isn't that there's nothing easy in Haskell, it's that many things that are easy in other languages are not easy in Haskell. Providing an example of something that's easy in Haskell does not address that point at all.
&gt; Haskell feels like a house that hasn't been lived in. Sorry I'm not sure I understand... and what libraries/suggestions/community are you refering?
I cannot address the general statement "Haskell is hard and other languages are easy" without concrete examples. The only example that was given was talking to a database, so this is what i responded to. Feel free to list examples where you got stuck so me and others can understand the pain of a beginner. There are solutions to these problems like more examples, better/more tutorials, more libraries, etc. But to understand the pain points examples are needed to drive the point home. General statements are simply not enough.
I think that's it, thanks. It's sad that such a modern language has this kind of problems... However sometimes moves depends not only on current state, such as Night Shade that takes exactly as many health points as user lvl is. In later games they can modify somebody's ability... There would be cycle between Pokemon and Move, so I'd have to split a lot more then.
A common tactic is to declare all three types in the same module, such as Pokemon.Types, and then have the other modules import it. Alternately, you can choose a different data representation. If `Move` is `Battle -&gt; Battle`, then you're allowing a move to potentially change all aspects of the battle, including which Pokemon are involved. That seems excessive.
Some moves in later versions can even switch pokemons (baton pass). I think Battle -&gt; Battle is the most natural option (or maybe some Event datatype?). But moves still need a lot of information about the battle to work properly 
This is honestly what got me interested in Haskell (and Swedish)
An example was given already -- any time you have to reach for a monad transformer. FWIW, I'm not a beginner and I'm not having trouble, I'm trying to help you understand situations in which I had trouble as a beginner and which I still see beginners having trouble all the time.
I would 100% apply if it was remote, or in San Diego, US.
You should read about functional programming concepts in general first, to a great extent, in my opinion. You should know what currying is, first class functions, composition, and what the whole point of functional programming is in the first place (hint: derived from math). Once you have an idea of why the paradigm is there to begin with you will see many of Haskell's inherent features that are overlooked by beginner Haskell tutorials (since they would naturally focus on the language and not the paradigm). when I first trying it out it was these concepts that helped get through the Haskell specific tutorials, even when they explain the same concept using Haskell.
When I started using Haskell I got cyclic module dependencies pretty regularly, until I converged on what I call the "types module design pattern". The gist of the idea is that you build modules that contain only types, associated instances, and pretty much nothing else. Then your app structure will be that everything flows outwards from the types modules. The types modules typically depend on almost no other modules in your application except maybe other types modules. And then everything else in your application depends on the types modules. Typically if I'm starting a new app, I'll start with just one module called `Types`. But sooner or later I end up splitting things out into pretty much one module per type. To use your example: `Types.Battle` `Types.Move` `Types.Pokemon` The design that you described makes these modules cyclic, so maybe you should just collapse them all into `Types.Game` or something like that. Since I started using this structure I rarely encounter cyclic imports, and when I do it's almost always pretty easy to break the cycle.
Boot files don't need to be avoided at all costs, but it is typically less convenient to use them than not to.
Pretty different. If you've used Haskell before and liked it, it's unlikely you'll like Elm. It cuts a way a lot of the abstraction in Haskell in favor of a simple model, and I found a lot of aspects of the documentation downright patronizing (admittedly not something which should turn you off an entire language, but it says a lot about the community). 
That's not a concrete example: monad transformers are redundant in Haskell except for when they're used to construct polymorphic values, in which case they're more reusable than the closest possible approximation in conventional languages.
Ok, nevermind then.
Hiring is hard and time-consuming where even a single "we want you/you want us" match that fails because of HR represents a huge amount of needless waste (time finding the candidate, time until the next match is found). The solution to a bad HR dept, which your future boss must be aware of already, is for them/someone else to be the "if you have problems with HR email me immediately" resource. This has been my uniform experience with new jobs (either future boss or friend on the inside is there if HR gets uppity) and I've come to expect the "email me immediately if you have any hiccups in the process" talk. If my future boss isn't invested enough to make the effort (even if I were to ask for help) then what level of support could I expect generally? How bad does the situation/potential upside need to be before they lend a hand. A bad HR experience is to be expected but one where your future boss/coworker isn't there to help as much as they can, even when asked, is a big fat red flag: either they don't care enough to help, or have just come to accept it and thus can't be bothered to even try to help. These flags may not matter for me -- e.g. it's a premier group that I really want to work for or the job has other perks (location/salary) -- but for a "I'm happy where I am but am getting bored and want something new" class job I'd probably walk away. That isn't to say this happened in OP's case -- they may not have asked for help, it could have just been OP's fault, the HR person was just new and terrible, or a number of other reasons -- just that a team's reaction to a bad HR dept can answer questions that you just can't get answers to without actually working there.
So, like nearly every other job of its type in finance? Salary is often listed as "Competitive". I actually made the faux pas (I've learned) of asking about pay in an interview for a position very similar to the one I'm in now. Either way, their (savagecat's) loss!
I think his question was not about Elm the language per se, but about its MVC-like architecture (which has been ported to other languages by means of libraries). Sorry for pointing that out but not being able to answer it myself. 
So react-hs works very similarly to how react and flux work in JavaScript. So you have a bunch of views that build HTML based off of store state, and things like buttons and such send actions off to stores, which update their state (and potentially do IO / send off other actions), and changes to store state automatically re-render the relevant views. You then have various other features such as view specific state. Reflex is an entirely different paradigm. Based on functionally reactive programming. It allows you to tie things together in a more direct way, by like directly attaching input text boxes and such to places where the data is outputted. From what I hear it is pretty cool, although the performance is generally not as good as react-hs currently. 
Woah, I never thought of `(-&gt;)` as something that could have instances. Thanks for your quick reply! I'll take your suggestion to heart.
Awesome thank you!
Ah ok I did get that pure function from the part about ZipList. Your definitions and insights make a lot of sense thank you for all the help!
Sounds like you need something like a stack template, I'm not sure that they have third party templates working yet. Maybe look for something like that.
That's what I use. When I want to try something out I just run `stack new &lt;name&gt; hpack-simple` (I'm newb so a) I have loads of these small projects and b) I find `.cabal` files inscrutable hence the hpack-simple template!). `stack templates` will return a list of all the templates. I'm sure you could write you own if you needed to have more control (I don't actually know if this is true by the way). 
For small exercises would recommend looking at [IHaskell](https://github.com/gibiansky/IHaskell), which would allow you to manage dependencies with stack. Then you can keep your imports per notebook and have a unified list of dependencies. You can also mix in markdown and write out the questions in the cell above which looks pretty nice. Unfortunately it doesn't work for Windows however and requires a small amount of setup.
Keep in mind that `(-&gt;)`, `(-&gt;) a` (which you can interpret as `(a -&gt;)`) and `(-&gt;) a b` (which is equivalent to `(a -&gt; b)`) have separate kinds: Œª&gt; :kind (-&gt;) (-&gt;) :: * -&gt; * -&gt; * Œª&gt; :kind (-&gt;) Int (-&gt;) Int :: * -&gt; * Œª&gt; :kind (-&gt;) Int Int (-&gt;) Int Int :: * (can't use generic type variables like `a` there) --- So only `(-&gt;)` can have typeclass instances with two type variables (like [Profunctor](https://hackage.haskell.org/package/lens-4.15.3/docs/Control-Lens-Iso.html#t:Profunctor)). `(-&gt;) a` can have typeclass instances with one type variable, for example [`Functor`](https://hackage.haskell.org/package/base-4.9.1.0/docs/src/GHC.Base.html#line-638) And as /u/ElvishJerricco posted above, `(-&gt;) a b` or `(a -&gt; b)` has a Semigroup instance. Would a Semigroup instance for `(-&gt;) a` be possible?
The points under "Writing Fast Haskell" made me a bit sad ‚Äì I'd prefer to have my higher order curry and eat it too! How much of an effect do each of these points have? In general I get a bit skeptical about received wisdom about optimisation, since it's often based on specific versions of compilers (or even specific programs that the compiler couldn't optimise due to complicated factors). See for example [this post by Ted Ts'o](http://lkml.iu.edu/hypermail/linux/kernel/0008.2/0171.html) on loop unrolling: &gt; It turns out that with branch predictions and the relative speed of CPU vs. memory changing over the past decade, loop unrolling is pretty much pointless. In fact, by eliminating all instances of Duff's Device from the XFree86 4.0 server, the server shrunk in size by _half_ _a_ _megabyte_ (!!!), and was faster to boot, because the elimination of all that excess code meant that the X server wasn't thrashing the cache lines as much. &gt; The bottom line is that our intuitive assumptions of what's fast and what isn't can often be wrong, especially given how much CPU's have changed over the past couple of years. And according to https://www.reddit.com/r/haskell/comments/6ifedr/on_competing_with_c_using_haskell/dj71zue/ , `fold'` *does* fuse (with `zip`, maybe not with everything that `foldr` fuses with?) and `ap` *does* inline and `String` can be fast in particular circumstances. I guess the main takeaway is to try it and profile, but who has time to try every single combination of methods? (Or perhaps the main takeaway is to write a blog post and let redditors write faster versions :))
&gt; are you interested in beginner even? 
[removed]
Unfortunately not, but it should be easy enough to find meetings or traces of a community online. :)
[removed]
Inspired by some nested comments (linked below) which are criticising or praising the No Cyclic Imports restriction I thought I'd add my two cents. Cyclic imports tend to indicate that your code is convoluted and that you should probably refactor to have more linear (or at least tree-like) import structure. For exactly the same reason I always try to avoid explicit recursion in my functions. https://www.reddit.com/r/haskell/comments/6io8fx/yet_another_import_cycle/dj7wmds/ https://www.reddit.com/r/haskell/comments/6io8fx/yet_another_import_cycle/dj7yja3/ https://www.reddit.com/r/haskell/comments/6io8fx/yet_another_import_cycle/dj879gs/
Clueless bot spam seems to be about: 1. Haskell the town/county, 2. Haskell the rugby player, and thus 3. Rugby stuff in general, and 4. Horse racing.
I don't even know what questions to ask. I'm just not catching on to the general layout of functions. I see some functions and try to understand them. I may understand some of the things it is doing, but not how the parts are working together.
I felt the same way about the book. It explains things briefly with no exercises then expects that you deeply understand it. Glad I am not alone in feeling this. I looked it up a bit and it just seemed like that was the definitive book for learning the language.
Well, it would still probably be helpful if you posted an example of a function you don't understand. Maybe someone can provide an intuition that would click for you.
Thanks, I think maybe your first piece of advice is the best for me. I jumped into Haskell with similar thinking to how I tackled other languages. "Let's get started and I'll have another language in my bag of tricks in a month!" I was certainly mistaken. Loved your advice though. Will be thinking about how to proceed at this point.
You could add all your dependencies to a single stack project then keep source files in `src` and load them individually: * Add dependencies to stack project's cabal file (add them under library section) * Run `stack ghci` in the project root * Load a file from GHCi with `:l src/&lt;file&gt;.hs`
When I first learned it was C#. I learned from following a course online making games in unity. So building small and then larger and larger programs. I have not been able to find anything similar for Haskell that seeks to teach by building moderate sized programs.
Are you using this for prod where normal users visit? Or just some private admin pages? I also like the idea of ghcjs, but the generated gargantuan js file scares me. Do you have a way to handle this issue?
I agree with everyone else here, in that Learn You A Haskell is not a very good resource past the first ten chapters or so. I'm also a Haskell newbie, and while I did initially learn from LYAH (up to about chapter 10), beyond that I didn't get much. That being said, here are some resources that did help me past the very basic stage: * Understanding functors and applicative functors : https://stackoverflow.com/questions/13134825/how-do-functors-work-in-haskell * Understanding monads : despite all the "monad as sock/burrito/pipe/wrapper" analogies, what finally helped me understand monads- practically speaking- was this: https://e.xtendo.org/monad#1 . * Selected chapters of Real World Haskell. I didn't go through the entire book, but I did refer to chapters of it for specific things I got stuck on (eg: I found the chapter on exception handling pretty helpful- no other Haskell resource quite explains how exceptions are handled in Haskell?) And finally- implementing things in Haskell, and asking/googling when things went wrong. I generally learn-by-doing anyway, so writing Haskell programs (I started off by trying some algorithms and competitive programming questions) and also looking at programs other people have written, helped a lot. I'm currently working on a small web app in Haskell, and tbh I've learnt more over the past month of writing the app than I learnt in six months of going through theory. There are quite a few sample programs/tutorials around, that you could learn from, like, for example, [this one](https://bollu.github.io/teleport/) Hope this helped! I hope this helped!
This is exactly the feeling we got after thinking about ambiguity errors: what we need is a more powerful defaulting mechanism -- maybe domain-specific -- more than error annotations.
I probably would not mind that, if it would allow me to avoid javascript. 
I think the answer is yes, but I'm not convinced that it's what we want. I think what we want instead is "safe sharing"; it should be okay to share a conduit, but it should not blow up our memory usage. There's some rambling about that in the later comments on https://ghc.haskell.org/trac/ghc/ticket/12620 , but it's still very much an open question. 
Is a special counsel ever appointed in such cases?
`MVar` makes fairness guarantees that `TVar` does not. `MVar` can also be used anywhere, whereas the prohibition on using `atomically` with `unsafePerformIO` or `unsafeInterleaveIO` should give one pause.
I meant at the actual level that calls your handler.
&gt; In Haskell? Most definitely.
Wow, that C implementation is hard to follow, did anybody manage to figure out why that version requires a lock? I thought the whole point of using a compare-and-swap was to avoid locking, so this post comes as quite a surprise to me.
There's a few different sources, some just from Haskell the city, some from horse-racing. I don't know much about it, so I don't really know how to answer your question other than 'probably'.
Only if the poster is a Russian Puppet.
Yeah pretty much. 
That's good to know. How does performance differ between the two for more CRUD heavy apps, where I am just rendering large lists of objects each with detail views and that can be edited and searched through and so on. 
&gt; What do you mean by this? `MVar` and `TVar` both require `IO`. See the [documentation for `atomically`](http://hackage.haskell.org/package/stm-2.4.4.1/docs/Control-Monad-STM.html#v:atomically): &gt; You cannot use atomically inside an unsafePerformIO or unsafeInterleaveIO. Any attempt to do so will result in a runtime error. (Reason: allowing this would effectively allow a transaction inside a transaction, depending on exactly when the thunk is evaluated.)
I don't understand the question. What is the relationship between imperative programming, Markdown, and Literate Haskell?
I don't recognize the type `ResponseM`, which package is this from?
The results between TVar and MVar are the opposite of what I would have expected. The chatter here and on irc is that MVar should perform better under write contention than TVar, because TVar makes optimistic assumptions.
"haskellCat"? Oh boy, this is going to be confusing. I'm "gelisam" almost everywhere, except on Twitter, where @gelisam is already taken, so I took [@haskell_cat](https://twitter.com/haskell_cat).
The `AtomicCounter` version has an advantage that hardware might exploit. Increment operations are commutative and can be reordered without changing the outcome. This decreases the needed synchronization burden. You also might want to add `atomicModifyIORef'`.
If you propose a semantics for `atomically` under `unsafePerformIO` I'll try to implement it ;D.
&gt; A more apt comparison would be `TMVar`. A `TMVar` isn't a separate primitive, it's just a newtype around `TVar (Maybe a)`. 
I prefere `Down` rather than `flip` because you get some similarities with the pattern for `sortOn`: sortOn ((,) &lt;$&gt; fst &lt;*&gt; (Down . snd)) l
How about: if the current thread is currently executing an outer STM block and an inner STM block is encountered due to unsafePerformIO, fail the current STM block, atomically execute the inner STM block, then retry the outer block.
Wow. So much for the "Haskell tax."
I want to understand why atomicModifyIORef acquires a lock. An explanation in terms of Haskell concepts would be clearer than an explanation on terms of C--, if possible. The author points to this dirty_MUT_VAR line as the part of atomicModifyIORef's implementation which leads to locking, but I don't understand that line nor the function inside which it is contained. The way in which I imagine that atomicModifyIORef works is that it reads the IORef, runs the function on that value, evaluating the resulting pair to WHNF, and then atomically compares the value in the IORef with the one it just read, and if it is the same, it swaps it with the first component of the pair which the function has returned, so possibly a thunk. If the value in the IORef is different than the one it ran the function on, it discards the pair and tries again. Since the function is pure, executing it more than once like this should have no consequences. Since the atomicity of the operation relies on the compare-and-swap, which can be performed atomically by modern CPUs, I don't understand why the implementation would also need to acquire a lock.
That would be great! For this week in particular, [24 days of Hackage: async](https://ocharles.org.uk/blog/posts/2013-12-13-24-days-of-hackage-async.html) is a good introduction. In general the package of the week isn't always something that's been around long enough to have a tutorial. For example, last week's was [generic-lens](https://hackage.haskell.org/package/generic-lens-0.2.0.0), which had only been out for a week! Not a lot of time to write tutorials :)
First, `atomicModifyIORef` is subtly different from what you describe. It does not evaluate the application of the function until after it has successfully CAS'ed the thunk in place. Importantly, the loop around the CAS does not allocate any memory (the C-- implementation is needed to ensure this). The lock from `dirty_MUT_VAR` should not commonly be taken. It ensures that the object gets on the right mutable list so the GC will do the right thing. This code path should only happen once per GC as the info table pointer on the object itself is updated to "dirty" to prevent duplicates on the mutable list.
I tried that, as it seems to be the best solution. However, I need to import one module which I wrote myself (used for parsing input) and it throws an error when I try to build it.
Does anyone really downvotes alternatives here?
Their dataset had 0.06% of Haskell jobs among 40k job offers in total. That's a little over _20 samples_. I doubt you can derive a statistically significant result from such a small amount of data.
I had the same thought, but still it's certainly not evidence in *favor* of the "Haskell tax."
This looks rad. Looking forward to playing with it. At worst, I bet it will serve for many as a gateway drug to Haskell. Their interop piques my interest, especially to Python - I wonder if we could steal it somehow?
I completely agree that this is not the right solution but it looks like linear types are on their way to make it into GHC somewhat soon while the status of the proper solution seems pretty vague so we‚Äôll at least have a workaround (if not sharing at all is ok).
"Average salary / popularity" encountered a divide by zero error.
You know, boring stuff like a job, a spouse, family or escaping rising authoritarianism and armed conflict :) Though, when you put it like that yours sounds good too. Haskell is indeed more than just a language.
I did a quick search through the Servant source and couldn't find any calls to `try`, `handle`, or `catch`. I'm pretty confident they're not catching `IO`-thrown exceptions.
Repost: https://www.reddit.com/r/haskell/comments/6idos2/understanding_resourcet/
Really? That's surprising, but nice!
A job isn't just the people you'll be sitting next to. You can't escape the attitude of the company in general. I think it's a bad idea to work somewhere you're viewed by the management as a worthless cog in a huge mechanism.
Whoa, my bad! I got here from /new. I didn't even notice the timestamp. This post was near posts from 4 hours ago. 
Correct! Though, in the post I write that we *only* can use linear operations on it which has a bit more to it. If we do that, hide the constructors and create it with some linear continuation, we can prevent aliasing. So yeah, it's a bit oversimplified for the sake of intuition because we usually can't guarantee that stuff isn't aliased on the heap and this is tricky to get around. I discussed this a bit with my mentor, and to get around the aliasing stuff we need to resort to idioms like this to really make sure: mkArray :: ( Array a -o Unrestricted b ) -o Unrestricted b ...which are neither clean nor particularly intuitive. :) 
It's a heuristic
Yeah, they do a great job of introducing a ton of more advanced concepts before you're ready for them. Not so you get overwhelmed, but just in passing so you can start to put pieces together. It makes it a lot easier to make sense of blog posts and discussion on here that's beyond my skill level.
I'm always curious what "very competitive" means. As an American, my experience with offers for jobs in this sector in London is that they are not.
Dependent types *and* Python interop? I've got to see this...
Oh I see. So this isn't a widespread problem; just one amongst the trustees. ~~That seems fine to me.~~
Oh, that is very interesting! I was of the understanding that `TVar`s were just used as mutable variables in single-threaded transactions. I have updated the post with your comment; I appreciate it!
Haha, I'm not on twitter so it should be fine :P
One rather nice thing about F-Algebras is that you can annotate the AST without writing new data types. If your data type is data Arith a = Plus a a | Times a a | Num Int Then you can, for example, annotate the tree with the computed value, by writing a function from `Fix Arith` to `Fix F` where `data F a = (Int, Arith a)`. I think some of the libraries dealing with recursion schemes would even let you write `Fix (Const Int :*: Arith)` or something.
little bit of all of the above. Some stuff about general city news, some stuff about horse racing. The more recent stuff was about the race, I think.
Great! I'd love to read it! Could you provide a link?
There is no general-purpose typecasting in Haskell that would give you what you want; you will have to find a specific function `:: a -&gt; ResponseM a`. I don't know which package `ResponseM` is from, but most likely, that package either defines such a function itself, or it defines a suitable instance for `ResponseM` that allows you to use an existing typeclass method like `lift`. Either way, I'd start looking around the module that defines `ResponseM`.
Good question! Worthy of a patch I think (for someone who has the time :).
Do you have some sort of Reddit plugin or something?
They're competitive for London!
I think that once you decide to use `unsafePerformIO`, the burden is on *you* to prove that everything *you use* is safe; not on the things you use. So I don't think libraries should put more than the minimum amount of effort into being safe under `unsafePerformIO`, because it's just an unnecessary burden.
Is the code of conduct available some place? [The Hackage trustees policy and procedures](https://github.com/haskell-infra/hackage-trustees/blob/7ce8b8fd43f939232d2843b71bf8f74b5e097af4/policy.md) doesn't cover `custom-setup` edits.
[Screenshot](https://files.gitter.im/theam/haskell-do/jR0L/image.png)
If it were a small to medium sized company I'd agree with you. But we are talking about a bank with 87,000 employees. In corporate life there will always be some cunts. That's the economies of scale. I worked at a large bank. One that is kinda known as a competitor to Standard Chartered, yet way bigger and more successful. On the first time I had to go into work (which was before my employment started), a member of their HR was rude to me in person. That was the only time I ever met a member of HR in person for the entire time I worked at that bank. After that day, until the day I left, I never met a member of HR. Ever. The tl;dr; is that the departments are far apart. HR might well be filled with the stereotypical cunts we all expect. But in corporate life two departments, or even teams in the same department, can work totally differently to another. &gt; to work somewhere you're viewed by the management as a worthless cog The comment above wasn't about management. It was about HR. That's sideways, not up, the ladder. Again just because HR might be rude or harsh doesn't mean you'll be dealing with that day to day. In fact I'd be *very* surprised if you had to deal with it often from HR. I want to labour this point. That is, if you had to be in contact with HR on a regular basis then there are separate issues going on. Issues which have nothing to do with how nice/nasty HR is. As a developer, it is not normal to need to be in constant contact with HR in a corporate environment. If you are in charge of head count then maybe it's regular then. Otherwise it would be unusual. Second in a business with almost 90,000 people, the size of Standard Chartered, you have to accept you are a bit of a cog. That's not trying to be rude. It's just they have almost 90,000 employees! If you want the security and other benefits of working at a big enterprise/corporate, then you will have to accept that. They may have the loveliest managers in the world, but you are still just 1 person out of almost 90,000 people. Third, HR departments tend to get very defensive once they reach a large size. This is partly to reduce their own load. They don't know who you are, and in some ways they don't care (because they have lots of work to do). So they will be demanding and a bit rude. This is pretty common. My point here is that there is nothing wrong with grinning and bearing the cunts in HR. If the normal workplace looks fine then I'd advocate simply jumping through their hoops and getting on with it.
its still covered by metadata only changes to constraints -- those constraints just happen to be in a custom setup stanza.
I do have Reddit Enhancement Suite for Chrome, but when I turn it off I see the same comment editor..
[The documentation](http://hackage.haskell.org/package/async-2.1.1.1/docs/Control-Concurrent-Async.html) for this library is pretty good imo and the intro explains the idea behind it well. You can also read more about it in [Parallel and Concurrent Programming in Haskell](http://chimera.labs.oreilly.com/books/1230000000929/ch11.html).
Industry and academia have been trying to make good visual programming languages for literally decades. I hope they've done their homework and actually looked at the research. A lot of "obvious" ideas are either just bad or have serious trade-offs that need to be addressed with other things.
I don't have it on (plain) Chrome or Firefox :(
&gt; It makes package identifiers (like package-name-1.2.3) mutable. Yes, the actual revision is not mutated, but there's no way to talk about specific revisions. For example, I can't say cabal install package-name-1.2.3 --revision 2. I used to think this was a big problem. I no longer do. (I changed by mind due to arguments on this subreddit, actually.) Revisions are very useful to keep the cabal-install solver working, so we need to keep them. Of course, if they actually mutated packages in place that would be a mess-- but they don't. So while tools like Stack right now treat `foo-1.2.3` as a mutable reference that can change between Stackage snapshots, this is actually a mindset problem that can be fixed by a change to Stackage. Stackage could go back to treating `foo-1.2.3` as immutable, and revisions could be declared as owned officially by cabal-install and any changes in the future will be entirely driven by the needs of cabal-install. (I'm not sure this is the right approach, it's just something I've been thinking about). This also would move towards fixing what I see as THE major problem with Hackage infrastructure: that cabal-install doesn't have a dedicated place for information it can own itself. Right now cabal-install cares a lot about things like preemptive upper bounds but there isn't a convenient place to put this info. So currently we ask (and are talking about forcing) library authors to keep it in their source code. If we separated Hackage into two levels (the bottom level being very basic infrastructure that's meant to be used by cabal-install, Stack, Nixpkgs, etc.) and the top level being owned entirely by cabal-install and the Hackage website consisting of package revisions, possibly build matrix issues, reviews/ratings of packages (which we have now though they aren't widely used) I think a lot of our problems would go away. Currently I think the animosity in the community is driven partly by a technical issue: cabal-install needs infrastructure like revisions to support it, but this infra is opposed by the Stack people, which is frustrating since cabal-install helps everyone because we all use the solver. And on the other hand the Stack people are afraid because they've built everything on top of Hackage, but they see Hackage as a scary, unstable place because it has a lot more in it than is needed to provide the bedrock of the package ecosystem. The solution to this is to make sure we have our abstraction layers right. At the bottom should be Bedrock Hackage -- a mapping of package names and versions to source code. Bedrock Hackage shouldn't know about stack, Nix, cabal-install, the Hackage website, any of that. This is what Stack should build on. Then at a higher level we should have the Hackage website and the information needed by cabal-install. These should be wholly owned by their own teams and run without any interference from the Stack people or anyone else.
Nice. Just to make sure I'm getting this, are we saying that Reflex is great and fast for making *websites* because there's less to load for websites (since a browser already has a JS engine) ‚Äî and that Reflex is slower for desktop/mobile apps because a JS engine has to be loaded? Or are we saying that Reflex will be slow on mobile, regardless of whether it's an app or a website?
Any example of "obvious" bad idea or trade-offs that need to be addressed ?
Of the research or the languages? [ThingLab](https://en.wikipedia.org/wiki/ThingLab) was already in existence by 1978. VL/HCC is a conference dedicated to visual programming language research, looking through their proceedings is a decent place to start: https://sites.google.com/site/vlhcc2016/ Or maybe you want examples of ideas that end up being a bad idea? Find a box and wire VPL and then try to make anything of scale.
**ThingLab** ThingLab is a visual programming environment implemented in Smalltalk and designed at Xerox PARC by Alan Borning. A conventional system allows a user to provide inputs that produce outputs. A constraint-oriented system, such as ThingLab, allows the user to provide arbitrary inputs or outputs, then solves for whatever is unknown. ThingLab is viewed as one of the earliest constraint-oriented systems. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/haskell/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot/) ^] ^Downvote ^to ^remove ^| ^v0.22
Yes, it works in most cases. You certainly feel cooler when you can understand Schweizerdeutsch, which happens automatically after some time if you are native German (for me it went slower because I speak English all the time). Special trick: If you want unmistakably clear communication, just speak English. Most people here speak it perfectly. Sometimes when walking through the city in the evening i can walk very far only encountering English.
While we often urge beginner and even intermediate Haskellers to never use unsafePerformIO, if the IO action you are performing really is referentially-transparent, for example if it implement ST or sparks, then it's perfectly safe to use it. Tracking IO and other side-effects in the types is only useful because it tells callers what to expect when they make that call. So when the implementation uses IO in a way which doesn't interact with any of the other side-effects the caller might care about, it's more useful to use a type which tells them that. Now, we know that using STM operations in an unsafePerformIO block interacts badly with any outer STM transaction within which the unsafePerformIO action might get triggered. Therefore, whoever puts STM operations inside unsafePerformIO is doing a disservice to their callers, by claiming that the call will not interact badly with any other effects, while it does interact badly with other STM effects. So nobody does that, at least not intentionally. The problem is that STM can be used to implement operations like sparks which really look referentially-transparent in almost every way, because they don't interact with any other effects *except* other STM effects, and so if someone is unaware of the implementation details, they might incorrectly use unsafePerformIO to expose a better API for those operations. Now, one solution might be to never use STM because you don't want your users to make that mistake, or to never use unsafePerformIO in order to be sure you never make this mistake yourself, and those approaches both work, but I think we can do better: we can fix STM to be compatible with unsafePerformIO. I have already suggested one possible semantics in another thread, but this discussion is giving me the inspiration for another semantics. By using unsafePerformIO, we are claiming that the IO block does not interact with any of the caller's effects. If that block uses any TVar which are accessible by the caller, then that block clearly does interact with the caller's actions on that TVar. So an unsafePerformIO block may only use new TVars which are only used in this block. And therefore, while one of the caller's STM transactions may overlap with the block's transactions, they will never conflict with each other! The only reason the transactions do interact, I think, is because the STM library is storing some global information, probably by associating some transaction information with the current thread, and that's how it notices that there is a nested transaction and doesn't know what to do. So I suggest that the semantics of the transactions in the unsafePerformIO block should be the same as if that block had defined its own STM implementation, with its own independent map from thread to transaction. To implement this as a single STM library, we could map threads to sets of transactions, and whenever there is a conflict, check which variables are involved to figure out which of those transaction should be retried. If everybody used unsafePerformIO correctly, the set of variables accessed by different transactions in the same thread should be disjoint, so the answer is well-defined. For extra safety, the STM library could detect when two nested transaction use the same variables and intentionally fail in the same way it currently does when it detects that it is used inside unsafePerformIO.
ive pushed broken packages before and later revised the .cabal file on hackage and the amount of potential mess and confusion is nowhere near worth the minor aesthetic niceness in a version number 
No we should not stop this. What we should do is strive towards having some sort of "virtual" global code base for Hackage. The problem that is pointed out here is one of discoverability. The change was hard to see. This can definitively be solved in the *Hackage UI*, but even better would be a world where all of hackage was collected into a large git repo. We need *more* fixes like this - fixes where *one person* can do *gloal reactoring* of all of Hackage. It's several orders of magnitude cheaper than having each and every developer do it. It will make it possible to improve our base libraries several orders of magnitude faster. We should *not* stop fixing other peoples packages! We only need better tooling to do so.
You can use `atomically` and `unsafePerformIO` together; as long as they're separated by `forkIO`
When you say "Javascript on mobile", is that mobile web, or does it include things like react native? Facebook obviously thought *Javascript* was fast enough on mobile, but WebView was not.
Random thought: perhaps some of the trepidation around bumping version numbers is due to the fact that they just keep visually piling up on Hackage. It feels wrong to publish a minor change, because a dozen or so such patches later, you've somehow got a library that _looks_ like it's old, hardened, and well-maintained. A little CSS to better hide/organize the versions of a package would go a long way.
This looks almost exactly like the design I cooked up for a presentation for a programming language design class. From the iconography to the node design. I guess I was ahead of the time.
Some people mistakenly believe that you have to accept a pay cut if you want to get a job coding in Haskell.
Because this is about the cabal constraint solver, sure its "their work", but it has wide reaching affects beyond their package, it is effectively meta data owned by the cabal install solver. It would be nice if we could separate such things from the package and cabal file itself though, that I could definitely see being very useful.
I think it's fine to *strongly* push to get version bounds fixed. But this can be done via github issues and pull requests just fine. There's no reason to take control over someone else's stuff when communication is a much more civil solution. Especially considering Stack, Cabal, and Nix all have ways to get around an upstream package having bad version bounds, should it come to that. &gt; It would be nice if we could separate such things from the package and cabal file itself though, that I could definitely see being very useful. That's effectively what Stackage and Nixpkgs are.
I would love to move to Zurich but I'm guessing that the rent there is quite expensive?
That is correct, everything is roughly 2x as expensive as in Germany, but the average Swiss salary is also 2x as high.
Yeah, some way of annotating the versions to indicate which ones are recommended or are deprecated or whatever... that would be nice.
The policies cover this situation and caution trustees against bound relaxation, exactly as you advise: https://github.com/haskell-infra/hackage-trustees/blob/7ce8b8fd43f939232d2843b71bf8f74b5e097af4/policy.md#2-metadata-only-changes-relaxing-constraints &gt; The trustees' view is that relaxing constraints should be done carefully, and ideally done by or checked by the package maintainers. Nevertheless there are cases where it is helpful. &gt; ... &gt; Trustees are expected to use this power judiciously and make sure they understand the packages involved and their APIs. In the first instance they should get maintainers to make changes. If maintainers are not available then they should use their judgement and consult with each other when in doubt.
If they're supposed to consult with maintainers anyway, why is this not just "Pull request until they prove unresponsive?"
I think it's true in general. Not many Haskell jobs. Lots of Haskell enthusiasts. It's simple supply and demand. There will be special cases. E.g. Edward Kmett wouldn't be a cheap hire. But I'm talking about your typical solid coder here choosing between say 99 Scala shops and the Haskell shop in their city.
Did you read the link that started this whole thread?
Julia goes so far as to be disingenuous a lot of the time. 
A good rule of thumb is that a sample of 400 is good. But either way, what's more relevant is the lack of a randomized sample than anything else. 
I don't even think Real World Haskell was a bad book, it's just very obviously outdated. 
&gt;Haskell feels like a house that hasn't been lived in. I get the feeling that there won't be as many libraries/suggestions/community as the alternatives might provide. Haskell has far more by way of libraries, *however*, those tailored to working with the DOM are not as mature as Elm or PureScript. But the quality of the libraries is a plus for Haskell for any sufficiently complicated app. For instance, I made a small DSL for generating text, and it compiled with GHCJS without anything special (i.e. no rewriting of anything). You can see it [here](http://polemic.vmchale.com/madlang). 
I'm curious what you mean by difficulty. Both universal qualification and row polymorphism are pretty easy to represent with ADTs. Do you mean you can't do it type safely, i.e. only valid programs are representable?
Eh, you can already recommend AND deprecate versions on Hackage... Just go to the maintain section of your package and you can click on "Preferred versions" or "deprecation" to set these...
Just out of curiosity, to my surprise, even atomicModifyIORefCAS execute a contention loop. isn't the CAS an hardware operation that no other concurrent operation will notice? Why then the loop? atomicModifyIORefCAS :: IORef a -&gt; (a -&gt; (a,b)) -&gt; IO b atomicModifyIORefCAS ref fn = do -- TODO: Should handle contention in a better way. init &lt;- readIORef ref loop init effort where effort = 30 :: Int -- TODO: Tune this. loop old 0 = atomicModifyIORef ref fn loop old tries = do (new,result) &lt;- evaluate (fn old) (b,val) &lt;- casIORef ref old new if b then return result else loop val (tries-1) Why the bool value in casIORef is necessary? why the CAS operation may fail? Is that failure frequent?
&gt; I think it's pretty naive to think that a whiteboard design session is able to capture all of the complexity of software design. The reason we have "thousands of lines of code scattered over hundreds of files" is not because we don't know how to be terse (Haskell being a prime example). It's because it really takes that much code to express every last detail of the design. I'm not saying that Luna looks like an example of a visual programming language well done, but it has its own ideas about organising code (as you can see in the `finalTouches` node in [the image near the "Visual profiling" section](http://www.luna-lang.org/assets/images/profiling.png)). I at least have some hope they don't believe that all code should be flattened into the same diagram. That never goes well. &gt; There's a reason mathematicians still use symbols to express their ideas. There's a reason R users learned to stop worrying and love its syntax.
X-Post referenced from [/r/nixos](http://np.reddit.com/r/nixos) by /u/regnat [Typing Nix](http://np.reddit.com/r/NixOS/comments/6j0cl5/typing_nix/) ***** ^^I ^^am ^^a ^^bot. ^^I ^^delete ^^my ^^negative ^^comments. ^^[Contact](https://www.reddit.com/message/compose/?to=OriginalPostSearcher) ^^| ^^[Code](https://github.com/papernotes/Reddit-OriginalPostSearcher) ^^| ^^[FAQ](https://github.com/papernotes/Reddit-OriginalPostSearcher#faq)
in some other thread answers, I have noticed that you are using `react-flux`, do you suggest `react-flux/hs` or `reflex`?
There's a big difference between OS package managers and language-specific ones though. The whole point of a distro/OS is to curate a recommended set of packages and make sure they work together well, so it's common (and in some cases, expected) for them to have patches to make everything work together smoothly. However, the point of a language-specific package manager is to simplify dependency management &amp; retrieval for development, with installation of executables as a secondary concern. Anything that makes development harder (such as making it harder to find the source you're actually consuming) works against that goal.
Something subtle you might not have realised: `stack build` builds and installs a package in a given project, which means the executable will only be accessible for commands running with the correct PATH. `stack install` installs them to the global PATH (`~/.local/bin` on Linux). The latter might be what you want, but if it's global then it's only going to work with one version of GHC. I'll also second the suggestion to use something Intero-based instead of ghc-mod - it has more functionality and seems to be emerging as the standard for editor integration.
I strongly disagree on the performance front - I got a good bit way through implementing a front end form generation library with react-hs before I had to abandon it due to performance problems. By contrast reflex had no issues, and I also found the style to be much nicer. Harder to set up though.
You should take into account that there have been great improvements to the library in both the bitbucket repo for react-flux and even more so in the react-hs fork which haven't made it onto hackage. 
Never attribute to malice that which is adequately explained by ignorance Never attribute to ignorance that which is adequately explained by bots (that being said: [If I was mod](https://www.reddit.com/r/haskell/comments/6i2n0z/rhaskell_moderation_applications/), I would not have deleted this post, because I haven't seen enough posts of this form to be confident that it's a really bot, and I don't want to risk removing something posted by a well-meaning human)
Here is [that document](https://github.com/SamuelSchlesinger/Quickterm/blob/master/doc/design-decisions.pdf).
You can get a general idea. But not quite, we really need to improve the react-hs documentation. 
Huh, interesting. I remember benchmarks saying differently a while back. 
The combination of "release + revision" is immutable. It's just that the Hackage UI and Cabal don't let you specify older revisions, but Nix does!
&gt; Why the bool value in casIORef is necessary? why the CAS operation may fail? Is that failure frequent? CAS is not a *swap* operation, it's a *compare* and swap operation. The idea is that you tell it which value you expect is already in the ref, and the CAS performs two things in a single atomically operation: (1) it checks if you were right about which value is already in the ref, and (2) if you were right, it performs the swap. So the boolean is the result of the comparison, it tells you whether you were right or not. Okay, so why do we need to perform this comparison? Wouldn't it be simpler to just perform a swap? Well, `atomicModifyIORefCAS` (and `atomicModifyIORef`) do not *write* a new value to the ref, they *modify* the ref. That is, they read the old value, apply a function to that value, and write the result back. While there is probably a hardware operation which atomically reads-increments-and-writes-back a value, this function can be any pure function, so there isn't a hardware operation which atomically reads, compute a pure Haskell function, and writes back the value. So we implement one in terms of CAS: we read the value, optimistically hope that nobody else will write to the ref while we compute the pure function, and then we compare-and-swap in order to write down the result. If the comparison fails, it means that another thread wrote a value in the ref while we were busy computing the function, so we have to try again by calling `loop`.
I've been a reasonably satisfied, fairly passive consumer of Nix in the past. My colleague set everything up, I just ran `nix-shell`. However, I've never understood how such a cool idea failed to notice that it could benefit from a type system far earlier.
Yeah exactly.
&gt; But a material CPU is something entirely different. It's just a complex network of semiconductors. You can interpret the influence of electrical charges in that network using terminology related to abstract state machines. But no matter how hard you squint, you didn't build a Turing-machine or even a finite state machine. All you're doing is unnecessarily straining your eyes. This reminds me of Searle's argument that computation is actually observed-dependent. If we set up a computer and left it computing the prime numbers, and then all conscious life was wiped out, the computer would cease to be computing anything. It only computes because we interpret it that way. At least that was my interpretation of Searle and your comment seemed to hit on that argument.
I just overlooked it and it looks cool. I have a proper look. Thanks
The similarities between "hell" and "shell" have been widely recognized.
I also like how Node.js and JavaScript are virtually always split in two. I just don't get it.
&gt; infinitely `-XTypeInType`
It looks like I simply had wrong permissions credentials.
I agree. I terminal application has to use ANSI or VT commands (like vi). A command-line application would be happy on an honest teletype (like ed). Which is why I read the title and was expecting something like https://github.com/awegmann/consoleui
&gt; Meanwhile in Reflex, the most direct code possible (wires are dependent on node positions) is efficient (each has an implicit callback on the node), because you can update the X/Y of the DOM node in-place and the X/Y of the wire's DOM node in-place, without re-rendering the whole node's logic or wire's logic (as in React) and then diffing on it. Does Reflex batch updates into e.g. the animation frame callback? I'm thinking of the potential performance problem in that if you have updates that cause reflows, then doing direct updates may lead to all kinds of nasty performance problems and jankiness, etc. etc. React mostly avoids this and AFAIUI the new Fiber backend for react should basically avoid all of these issues. (Current React *mostly* avoids them, but not quite always...)
Your example of retrying is legitimate but I must confess that seems like a very rare use case. Since you can't get STM's `retry` semantics in PG transactions your retries effectively become a tight loop. That's fine for cases like this (using random numbers as keys), but in most cases I wouldn't want a tight retry-loop *in the same transaction* like that and I'd have to retry the entire transaction in the hopes that some other writer changed something.
For some reason I always thought ApplicativeDo was simple syntactic sugar for purely applicative expressions. Now that I read the (quite approachable) paper it feels more like a really cool optimization, though. It also reminds me somewhat of arrow notation without the drawbacks of manually re-implementing scoping. Would it be possible to build a parser combinator library on ApplicativeDo that has the power of monadic parsers but still left factors whenever possible? Anyway, really gotta find an excuse to get into haxl.
&gt; Cabal don't let you specify older revisions *actually...* we do have `cabal get --pristine` and also [`cabal get --index-state`](http://cabal.readthedocs.io/en/latest/developing-packages.html?highlight=index-state#downloading-a-package-s-source) for that; it can be used to download a specific revision of a package (currently addressed via a timestamp), or roll back all packages globally to a specific state of the index including revisions that were in scope at the time, when [used with `new-build` or in `cabal.project` files](http://cabal.readthedocs.io/en/latest/nix-local-build.html#cfg-field-index-state). And there's more planned for future cabal verisons in terms of revision-addressability &amp; filtering. If somebody's interested to help us out getting those features implemented sooner, please get into contact with me!
Are there any frameworks that have adopted ~~Haskell~~Haxl? I mean, it could be cool to see it integrated into web frameworks, although I'm not entirely sure what it would mainly benefit :/ Edit: s/Haskell/Haxl/
&gt; I need a way for the C++ code to notify the Haskell when the queue becomes non-empty A value of type [`FunPtr`](http://hackage.haskell.org/package/base-4.9.1.0/docs/Foreign-Ptr.html#t:FunPtr) is a pointer to a Haskell function callable from foreign code, i.e. from the C++ side it's a C-style function pointer. You could call one of those from your C++ callbacks.
Absolutely, it is the **best** book on understanding concurrency and parallelism in Haskell, has compelling examples, and is written by an expert on the topic. I consistently reference it when building out code dealing w/ concurrency but I haven't had as much need to jump into the chapters on parallelism.
Well you're using an "up to isomorphism" equality there, which is fine, but that it's *not* the equality that the type checker uses. If you pass a `(String,Int)` to a `f : (Int,String) -&gt; ()`, the compiler will complain. And even an up-to-isomorphism equality, were the compiler to understand such a thing, still has its complications in that with respect to this equality, things can be equal in more than one way: i.e., your equality *contains information*, e.g., which isomorphism should the type checker use if you tried to pass `(Int, String, Int)` to `f : (String, Int, Int) -&gt; Int`?
I would also say another thing to consider is things like how higher kindled types interact with all this, things like functors and such very much do distinguish based on the way you order the types.
&gt; I'm also interested in the op's question as to why that law is justified in the first place; what reasoning exactly does it let us do when we don't throw it out? Refactoring for one. If I see `foo &gt;&gt;= \x -&gt; bar &gt;&gt;= \y -&gt; pure (x, y)` in my code I am going to want to switch to `(,) &lt;$&gt; foo &lt;*&gt; bar`, and in the presence of `&lt;*&gt; = ap` I can do that safely. Another is just that without that law `ApplicativeDo` is pretty dangerous.
I'm considering switching some things over to dhall, hopefully it can be done incrementally. http://www.haskellforall.com/2016/12/dhall-non-turing-complete-configuration.html http://www.haskellforall.com/2017/01/typed-nix-programming-using-dhall.html
Probably its the same situation as Lisp? To be fair, I never cared about a type system before Haskell, and I think that this is an effect of immutability.
&gt; Are there any frameworks that have adopted Haskell? You make it sound as if a web framework first springs into existence, and only then decides which language it's going to be written in. But it's the other way around! Once a language becomes popular enough, people start writing a variety of web frameworks (and many other common libraries) in them. Just google for "Haskell Web Framework", there are many.
I think he meant Haxl.
I think that comes down to the definition of `=`. If the data source guarantees that parallel and sequential evaluation are observationally equivalent I'd argue that `&lt;*&gt; = ap` does hold. Something like the `cmd` source could still be really useful, though, it just doesn't work at all with ApplicativeDo. I think the best way would be the explicit notation mentioned in the ApplicativeDo paper: do a &lt;- cmd "sequential1" (b, c) &lt;- (cmd "parallel1" | cmd "parallel2") cmd (a ++ b ++ c) but I don't think that is actually implemented
I'd highly recommend it, we had it as course literature for parallel functional programming. Didn't read the whole thing, but the parts I did was great. 
Interesting. Since it uses optimistic locking it can be potentially slower when there are a lot of concurrency over the same variable. I bet that the benckmark result should be quite different if there where different threads.
Right of course, that's what makes ApplicativeDo sound
Yea, once you see anything resembling static analysis in the applicative instance (concurrency, batching, [reordering](http://elvishjerricco.github.io/2017/03/23/applicative-sorting.html), etc), it's an immediate giveaway that the monad law is broken. It's *fine* if you define conventions that, when adhered to, make the breakage unobservable, but still not technically correct. &gt; why that law is justified in the first place Without this law, `Applicative` cannot be a superclass of `Monad`. The existence of `ap` is the proof that any given monad is an applicative, so any evidence of that proof (the superclass constraint) needs to be consistent with it.
Is it possible to, in some way, import everything from a module but rename one or two functions? Something like "import Map [null-&gt;nullMap, insert-&gt;insertMap]".
Ah! That makes a lot more sense in the context of this post :)
&gt; I bet that the benckmark result should be quite different if there where different threads. There are already 10000 threads in the benchmark, do you mean different IORefs? *edit*: wait, no, there are `getNumCapabilities` threads, and each of them does 10000 operations
Thoughts so far: 1. Comparing C# and Haskell seems a bit odd. Not that "Haskell for Java/C# programmers" isn't useful, but Haskell and C# are different enough that I wouldn't use Haskell on a C# project and vice versa. So I think it's also import to show what *types* of project you can do in Haskell that would be impossible in C# - e.g. a 1200 line window manager, or perhaps a small toy language. 2. "Getting" a language takes a long time. Sometimes I think it's important to provide some motivation and not just code comparisons. I realize that sometimes code comparisons *are* the motivation, but it's worth mentioning things like [corrode](https://github.com/jameysharp/corrode), [xmonad](http://xmonad.org/), and the like. Anyways, I did like your blog post. I don't know as much C#, but the Haskell was solid and it's always great to see people that are happy to be using Haskell. 
 import Map hiding (null, insert) import qualified Map nullMap = Map.nullMap insertMap = Map.insertMap maybe with a gensym for alias for the qualified import...
I've had silent modifications to my packages, with no notice, issue filed, or explanation. Accordingly, I am [asking them to not do it again](https://github.com/haskell-infra/hackage-trustees/issues/106).
Interesting, why would immutability make you care more about types? In untyped programming languages, I sometimes see developers add print statements to see an example of what a given variables can contain. If they see a string, they conclude that it's always a string, and I find it infuriating because since they have only seen a single sample value, the real set of possible values could be much larger or much smaller than the set of all possible strings. I guess it's hard to think in terms of types with granularities larger or smaller than "int" and "string" if that's what your language calls types. In any case. With a mutable reference, there is even more code which could affect the set of possible values to which that reference could refer: not just the set of all the callers, but also all the assignment statements because who knows whether there's aliasing and changing those reference also changes our reference. So there's even more uncertainty about what the set of all possible values could be, and types should be even more helpful, no?
Haxl's model doesn't make much sense for a web framework. It's much more useful for a set of clients to services.
I think that would be either impossible or *ridiculously hard*. In its current state, nixpkgs uses `fix` **everywhere**, which is the very crux of Curry's paradox and the reason that simply typed lambda calculus was developed. I rather enjoy the features that `fix` gives you in nixpkgs (`makeExtensible` being the prime example). But you do get nasty infinite recursion bugs from time to time.
Using FFI is a foregone conclusion and using `FunPtr` is probably also necessary. That much is clear. The thing I'm not clear about is how to do thread synchronization between C++ &amp; Haskell. E.g. how can I shared the same unnamed semaphore between Haskell &amp; C++? If there are no convenient libraries for such synchronization, I may have to roll my own but I would like to avoid that because with the intricacies of the RTS especially with regard to threads that I don't fully understand, there may be many unknown ways to make mistakes.
Ok. I expected forkIO somewhere. but it is implicit
&gt; You actually can't put the annotation on the right. Because some kind of argument from application of (,) , I'm guessing? Please explain: if you would be so kind, make the explanation accessible to someone with only an MS in Programming Languages and 30 years of Functional Programming experience. Not all of us are so smart as today's PL folks. &gt; I also think it's kind of silly to give up on a language over something like this Yeah, that's why the whole straws and camels (but made better with dinosaurs) thing above. I could easily write 10K words on the other reasons, and will if I can just find the time, but here's the tl;dr: laziness makes performance too difficult to predict, laziness makes debugging really hard, monads are linguistically horribly awkward for maintaining program state, the level of mathematical reasoning needed to understand current Haskell practices is too challenging for me, none of my friends I program with these days have any real interest in Haskell (maybe for the reasons I just listed). I'm maintaining my existing Haskell code, so there's that, I guess. But when I sit down to write new code today, I've found that I think about Haskell for a minute and then inevitably choose something else. I'm writing a lot of Rust right now and enjoying it quite a bit. It has some neat safety properties, while still letting me write code that looks on its face like a description of an algorithm and runs with predictable superb performance. I'm not taking some monastic vow of never writing new code in Haskell. I just have a hard time thinking of a situation in which I would. I've taught myself a tiny bit of Agda and looked at Idris and a couple of other things: if I'm going to treat code as a theorem, I might as well legit Treat Code As A Theorem, with full-on tasty Curry Howard. I'm honestly not sure it's harder than modern Haskell. &gt; yes, a mistake but not one that I've seen anyone demonstrate introduced a bunch of bugs. How would you even know? The bugs could only start being introduced after FTP came in, so the vast bulk of Haskell code out there won't have them: the typechecker used to save us from them. They won't normally cause runtime errors either, since well-typed Haskell programs (probably) don't go wrong. So you just have to hope that your tests are really really good. Of course, if your tests are really really good you might as well program in Javascript from a safety point of view. I suppose eventually someone's Haskell-Powered Space Rocket blows up and thus triggers a careful post-mortem that finds such a bug, but I'll be carefully out of range by then. There are (or so I was once taught in Programming Language School by a Great Language Designer, assuming I remember the lesson correctly, which I rarely do) three basic reasons to use a static type system: clarity of expression, enabling compiler performance improvement, and automatically proving correctness properties of programs. Once you give up on the third thing, you are left with the second ‚Äî in an age where Javascript is usually half as fast as C ‚Äî and the first ‚Äî have you tried to read the types in new Haskell code lately? Meh.
I wonder if this could work: - You can pass a Haskell function as a callback to C++. - C++ calls your callback - Your *callback*, in Haskell, writes to a message queue.
Sounds like a clean approach. I think the main issue is whether a Haskell function can be called from arbitrary threads created and executed on the C++ side. I scanned some FFI documentation and couldn't find any such restriction but I'm still not sure.
Yeah totally agreed! Let's get to that. Once we have a good module system, then that changes the technical landscape, which will alter the best practices available. Really, even just qualified reexports will fix the issues I have with `Map.empty` or `Set.singleton`. We should (with Template Haskell) be able to easily generate whatever permutations of this we please and reexport as we feel necessary. EDIT: This is now the most upvoted top level comment on the thread. I'm curious if there are arguments to be made in favor of alternatives that I'm missing.
I vaguely recall that was part of the Backpack project at some point ... maybe?
I really want scoped imports.
Noice!^as^the^reddit^kids^say.
[Attribute grammars](https://en.wikipedia.org/wiki/Attribute_grammar) are basically a way to specify tree traversals. You have _inherited_ and _synthesised_ attributes: inherited ones are passed from the root node down the tree structure, and synthesised ones start from the leaves and are passed up. At each node, you can pick a value for the subnodes' inherited attributes, and a value for the synthesised attributes to be passed back to the parent node. For a simple example, take a binary tree. (The same one as in the manual, because why not.) UUAG's data type syntax is slightly different because every child node has a name. data Tree | Node left :: Tree right :: Tree | Tip value :: Int An inherited attribute for a tree might be the distance from the root, and a synthesised attribute might be the total value. attr Tree inh distance :: Int syn sum :: Int Now to specify the traversal you use "semantic rules" to say what each node outputs in response to its input. To recap, you have the inherited attributes from your parent node, and the synthesised ones from your children. You have to produce a value for each inherited value for your children, and one for each synthesised node for your parent. Moving down the tree, the distance from the root increases by one each time: sem Tree | Node left.distance = @lhs.distance + 1 right.distance = @lhs.distance + 1 And moving up the tree the sum accumulates: sem Tree | Node lhs.sum = @left.sum + @right.sum | Tip lhs.sum = @value (These two `sem` blocks could also be merged.) This is just the basics, of course. Since attribute grammars are designed for traversing ASTs (hence the name), and abstract syntax tends to have lots of constructors, UUAG has a number of convenience features for handling such things. One example is default merge actions, where you essentially attach the pieces of a monoid to a synthesised attribute and it uses that on the children except where you say otherwise. And if I remember right, [UHC](http://foswiki.cs.uu.nl/foswiki/UHC) is written almost entirely using UUAG.
**Attribute grammar** An attribute grammar is a formal way to define attributes for the productions of a formal grammar, associating these attributes to values. The evaluation occurs in the nodes of the abstract syntax tree, when the language is processed by some parser or compiler. The attributes are divided into two groups: synthesized attributes and inherited attributes. The synthesized attributes are the result of the attribute evaluation rules, and may also use the values of the inherited attributes. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/haskell/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot/) ^] ^Downvote ^to ^remove ^| ^v0.22
I've poked around the /.stack folder, but wasn't able to find the installed packages, even though that is the exact location `stack path` led me to. Can you please specify exactly where in there I should be able to find them? Is there no built-in way to just list them? I will definitely check Visual Studio code out, haven't been impressed with the features given by Atom (especially how hard it is to bind package commands to hotkeys). Is it well supported on Linux (Ubuntu, if it matters)? 
&gt; arbitrary threads created aww that sounds really bad
Is there a reason why UUAG is not being used other than in UHC? I believe many other applications can benefit with a Attribute Grammar approach. Some thing like generating Persistant like DB models etc (everthing these days have to do with web programming).
Hmm, I was thinking about if Haxl would be able to batch SQL requests for example across multiple requests, such that you don't have several concurrent requests asking for the same data etc? And the caching seems also to be a beneficial point, if they implement cache invalidation at some point (I seem to recall that they didn't have that yet in the talks Q&amp;A, but I might be wrong). Like, there surely must be some aspects of a web framework/web app that could benefit from the implicit batching and parallelism?
&gt; Why I'm still skeptical of (,) a as a Traversable being a problem is that you have to 1. be using Traversable and 2. be using Traversable generically (s.t. one can accidentally pass in a tuple). The standard Prelude now uses Traversable (because Data.List does), and the functions from Data.List now take their parameters generically. So both conditions are met without the (perhaps novice) programmer having to do anything clever. If I see code like ``` let parts = splitAt n xs in (fst parts, length parts) ``` I'm going to guess that the programmer intended the far more sensible ``` let parts = splitAt n xs in (fst parts, length $ snd parts) ``` FTP changed the buggy code from a lovely static error to an ugly result surprise. Of course, the programmer should have written this using pattern matching ``` let (front, back) = splitAt n xs in (front, length back) ``` but the whole point of this game we play is that programmers are bad. If they were all good, we wouldn't need any help. Besides, once you go down that road you're tempted to keep going: ``` length &lt;$&gt; splitAt n xs ``` and now you've reached the Promised Land of Haskell, where only the Pure of Heart can play. Thanks for a nice discussion. Sorry I've been so ranty. I'll shut up now and go do something more constructive.
I hope that we can all agree that the outlines issue is indeed an annoyance. Not sure we can all agree that the package and its metadata are independent, as we hard code bounds into the `.cabal` file and that is usually bundled/stored together with the code in some VCS. stackage provides a separation approach here. The outlined problem I would hope could be improved by making cabal note loudly that package metadata has been modified, when it reads the specific revision: &gt; foo-1.2.3 at revision N: *what* by *handle* due to *reason* where *what* would be "relaxed upper bounds", *handle* would be the handle of the hackage trustee that made the change, and *reason* would be some url to an unmerged pull request or textual reason as "unable to reach the maintainer". However, I feel that package authors should have the right to deny metadata updates. After all it's their code, and they should be allowed to put restrictions on it as they see fit. I would envision a `.cabal` flag `permit-revision: bool`, which would default to `true` unless specified. 
&gt; If nix were strict, it would essentially be statically typed. I'm not sure I understand. What about library functions, where the call sites are not known in advance? And what about packages with lots of configuration options, where only one configuration is chosen by default? Wouldn't we only check a single path through the code and other paths could still be ill-typed?
Anyone fond of attribute grammars might like (or be horrified by) boost::spirit, which is based around attribute grammars. Compiler errors aside it makes writing parsers in C++ a breeze; it's like the attoparsec of C++.
http://packdeps.haskellers.com/reverse/haxl shows [snaplet-haxl](http://hackage.haskell.org/package/snaplet-haxl), but from the upload date, I can't tell whether it's maintained.
I never understood how Attribute Grammars were different from folds.
Default is when there is a value of *lts* in the field. If you install the plugin, the default value will be *lts*. If you give an empty value, the code will automatically assume the value of *lts* in it.
Cool, thanks!
Yes I know the async package, and saw the await and I realized that it was multithreaded but at some moment I lost the context. Maybe I have a split personality disorder.
It seems to me that they're like do-notation for folds in some sense.
I'm almost inclined to agree, but this only seems to work when the module has only one main type. It seems somewhat related to the ["avoid stutter"](https://blog.golang.org/package-names) advice for Go: &gt; Avoid stutter. Since client code uses the package name as a prefix when referring to the package contents, the names for those contents need not repeat the package name. The HTTP server provided by the http package is called Server, not HTTPServer. Client code refers to this type as http.Server, so there is no ambiguity.
&gt; import qualified Data.Map.Strict as Map While playing with Backpack, I remember being able to rename a concrete module belonging to a dependency, so that I could do this directly in all my modules: &gt; import qualified Map I don't know if that's an intended behaviour of Backpack. Possibly a bad idea anyway.
Is it not true that recursion-scheme stuff might end up traversing the tree multiple times for multiple attributes if we do not take care of how the traversing is done Particularly if we want a mix of inherited and synthesised attribute. Also I do not think the preprocessor part is that bad. Particularly if the alternative is to use something like TH. With some love I still believe that UUAG can be pretty powerful tool although I probably cannot pinpoint where to direct the love.
Amazing. You have to detail in the README the preconditions: Install tensorflow, add projece dependencies etc. Some people may try it and think that it does not work
Although, the cost of living is similar. And in US you are not limited to only a finance sector in order to get more or less acceptable offer. In London, you're basically trading a half (or more) of the salary if you want to get a job in other industry.
Any idea why you're so prohibitive about remote work? Especially for contract positions.
 &gt;line &lt;- getLine "abc" &gt;line "abc" Works in ghci but I want to find a way to input something similar in haskell for mac's playground but instead I get an error.
Is there a proposition somewhere for the improvement of the module system? As I see it, there are some incompatibilities between type classes and modules, but Haskell do not make full use of the design space. However, I don't see the specific points where it can do better. Does that stops at qualified imports?
My experience is that London pay is about 75% of Silicon Valley. And London is at least as expensive. 
So the problem is linked to Haskell for Mac, which is closed source software. As such, you should ask the creators, not the community, as we have no access to the internals of the program, being limited on the help we can give.
For a second you had me wondering why on earth you'd want to port Stack to Go...
I'm assuming this was made because of hackage's unreliable haddock builds. Are there any other reasons?
Visual Studio Code with Haskero plugin
Not a bad idea, but native upsert capability was recently added to postgres: https://www.postgresql.org/docs/9.5/static/sql-insert.html#SQL-ON-CONFLICT
I don't think seeing the listed packages will have any bearing on your problem. I've never needed it in years of Haskell programming. Visual Studio Code works great on Linux.
Click the link :-) No set location as yet, just a first meeting at a cafe to make future plans.
Consider coming to [c-base](http://c-base.org)!
Berlin! In all seriousness, there's information [here](https://www.meetup.com/Berlin-Functional-Programming-Group/events/241040383/).
While I do care about a hypothetical Haskell with a cooler module system, I'm mostly concerned with how I should write libraries *right now*.
... or when you have multiple data sources, no need to be Facebook scale...
had haskell for Mac also. I had similar issue in haskell for Mac, you cannot try it in playground, instead you can go to `target` in the head menu then click `run` this will open a console and the program will work as expected.
I migrated from `haskell for Mac` to `spacemacs` with `intero`
One thing to consider with libraries designed for open imports, is now adding a new name to the export list is a breaking change, and you must increment the major version number (`B` in `A.B...`). I personally am very much not a fan of open import style, partially just for the above, adding cool new functions is nice to be able to do completely freely, without worrying about breaking existing code.
What's the difference from the LLVM backend of GHC?
Is that because there's a possibility for colliding with a new term?
I'm getting a 404 for https://pixel-druid.com/blog/announcing-simplexhc/ now. :/
Yep, updated it. Should be up. thanks :)
What made you make that switch?
Lol. Emacs is pretty essential for Haskell (imho). Does intero give you an interactive repl for your project? &amp; Do you need to also load packages like hoogle and such?
This is very cool. Do you have any plans to upstream this in GHC? It'd be great if GHC had the best LLVM support natively as possible.
Great work Bollu, i'm really keen to see regular updates on the progress of this.
I use the cheapest option but to be able to compile I had to enable swap.
Compiling locally isn't an option, unfortunately. I'll try adding swap space. Thank you.
I used to think that, but then realized it's actually not that simple. Yes, Haskell enthusiasts far outnumber the available Haskell jobs, but I doubt you'll find many Haskellers who aren't also competent in a few mainstream languages. So Haskell job offers have to compete with the rest of the market. I can imagine there being a certain amount of Haskell tax, but it can't possibly be more than 5-10%.
That's because working in the front or the back end makes a bigger difference than the language choice. The challenges, technologies, roles etc. are very different.
Ordering, mostly. It's not hard to mix fields up that way despite the names appearing correct. Also that way generates shadowing warnings.
 if(n == 1) return 1; I think you mean if(n == 1) return accum
My single GHC binary instances usually eat around 0.5-1 GB. I rarely see them go above that. When I build something and do parallel compilation on 4 cores than ~2-4GB of usage is not unheard of. But maybe you'd be happy enough with single-core builds. Also, might you be willing to go into a bit more detail on why 'local compile &amp; rsync'-ing the result may not be an option for you? I use VMs extensively locally for many things, including building &amp; deploying, and it has worked well enough for me so far. - Is it perhaps that your local environment is even more RAM-constrained than the cloud environment? - Or you want to conserve laptop battery charge? - Or something else? 
Agreed. After quite a bit of experience both ways, I am convinced that `RecordWildCards` is almost always a mistake. It makes code harder to read and harder to maintain. The keystrokes it saves are not boilerplate, any more than declaring variables is boilerplate anywhere else.
Oh I see, shadowing the accessor. Yes, I'm not very awake yet.
I use Scaleway's servers for CI, i.e. building code (big projects with both Haskell and C++), Gitlab instance, etc. Specifically, C2L instance has 32G of RAM for 24 euro, and all 8 cores belong to you. https://www.scaleway.com/pricing/ The downside (and the reason for lower price) is that it uses Intel Atom C2750 server CPU, which's obviously slower than Xeons on DigitalOcean. But for CI purposes it's fast enough. Another downside is they have datacenters only in EU. Unfortunately I don't know any other company with compatible offering. Disclaimer: I am NOT affiliated with Scaleway in any way.
It opens another terminal window which is super ugly, I think I'm going to stick to visual studio code for now and may try emacs in the future.
Yep ... that's also the reason I can't use it at work :-(
Yes, I have. However my general plan so far was: - replace the textual ir with a bitcode ir - move the code gen eventually up one level from c-- to stg (I believe that is what ghcjs does, iirc my discussion with luite properly) As I'm currently focusing on cross compilation and template haskell, the llvm ir stuff hasn't seen as much attention as I would have hoped.
Normally you'd compile your deployment artefact on a build server such as Jenkins or Circle CI, then move this to your production server.
You can also get a 2 core 2gb of RAM VPS machines for 3 Euro or a 4 core 4gb for 6 Euro. I am reluctant to use Scaleway for production servers but they are definitely the most bang for the buck for development.
"Synthesized" attributes, i.e. things passed up the tree, are certainly a natural fold. But "Inherited" attributes, i.e. things passed down the tree, make expressing AGs as a fold a bit more complicated. You can express it with higher-order functions, but it's more of an encoding than a completely intuitive description of what they are. You also need laziness, or multiple traversals, to tie the knot between inherited and synthesized attributes that may depend on each other in a complicated way.
We're still going through the list, but ekmett was such a simple decision (I actually invited him the last time we appointed new mods, but he declined at the time), that he jumped the process a bit. I'm hoping to add two or three more after some more review, and there'll be a proper post about it when I've gotten everyone in.
Yes, I've read the paper. I do plan on implementing both and seeing what happens.
One more advantage of async is that it comes with its own bracket function: [`withAsync`](http://hackage.haskell.org/package/async-2.1.1.1/docs/Control-Concurrent-Async.html#v:withAsync). Usually `race`, `System.Timeout.timeout` etc. provide better ways to do what you want and `withAsync` is not necessary, except in one case I think `withAsync` provides the best solution: you have a timed action to signal a stop if the main process was not terminated, and killing the main thread is not an option. Something like: withAsync (threadDelay t &gt;&gt; signalCancel) $ \_ -&gt; mainProcess -- this shouldn't be interrupted! With `race`, `timeout` etc. `mainProcess` would be killed after `signalCancel`. In this pattern the timer gets killed when main process terminates in time, but otherwise both threads terminate gracefully.
I find deploying Haskell to Heroku is a much easier option ...
I always wondered why dropping to Cmm was necessary for the LLVM backend.
No, I usually prefer a universally quantified variable so that the user of the library does not need to use Void. However, you made me realize I had forgotten the universal quantification. Thanks!
Good to know that I'm not stuck being the only new kid on the block. =)
FWIW- the information asymmetry noted in that paper makes the eval/apply story pretty compelling. push/enter is mostly implemented because it is easy, not for speed.
A user could still pass a `forall a. IO a` to a function expecting an `IO Void`, though! What, then, is the difference?
Ah, you are right. I forget why I picked up this habit then -- I generally like to use quantification more than the empty type. Maybe in some circumstances it's relevant but here Void might be better. Edit: I've changed the post to use `Void`, since it seems better here.
I see. From what I remember, very few calls are actually non analysable statically. So, I believe they also mention that eval apply is *easier* to implement? I could be mis remembering.
It's a good pattern when `void` appears in positive position. In negative position prefer `Void`.
There is more to developing and deploying applications than having lots of RAM.
Over here in the UK Haskell seems to be doing a bit better. https://www.itjobswatch.co.uk/jobs/uk/haskell.do 
@quote FAQ memory &lt;lambdabot&gt; FAQ says: To build/link on low memory machines: use -j1, +RTS -M500m -RTS, and/or build fewer dependencies at once. Avoid swap, it's too slow.
That is not a useful answer. I asked "how come?". I would like to know what limitations they believe exist, not a non-answer like "there's more than just RAM".
Maybe they're using an iPad Pro or something? A tablet setup where they don't have a compiler locally. Or working from a computer owned by work/school and can't install?
So that OP doesn't have to bother to answer a comment that consists of a two-word question followed by a two-sentence presumption. It's something I'd appreciate myself.
The main problem is that you'll allocate more. That might make you run out of memory quite quickly and will also increase GC pressure. If I'm running tens of thousands of parallel computations it very quickly becomes unmanageable -- consider reading and processing 10k files in parallel, each 10MB.
Why did you decide to use IORefs (juggling your way around the unsafety of an `error`) instead of using a semaphore with numCapabilities fuel and forking 1000 threads (most of them blocked by waiting for the semaphore)? 
Another issue that we often face is parallelizing invocations of external tools -- Haskell is an excellent tool to orchestrate that, and obviously the runtime scheduler does not matter there.
I'm a bit confused by this. ApplicativeDo doesn't make anything lazier as far as I'm aware. Can you give a concrete example of something that is more defined with ApplicativeDo than without? (given a law-respecting Monad)
They are not catching: the exception will end up in WAI and not get logged. https://github.com/haskell-servant/servant/issues/309
The two versions (semaphore vs "slot list") give slightly different guarantees. Our slot list version guarantees that `each thread always tries to work on the next unworked element in the Traversable`. The semaphore version doesn't provide that guarantee, it can start start with the last element. This guarantee can be very useful: Let's say you're working down a dictionary of 100000 words, and at `neutrino` it crashes. Across multiple runs, the slotted version will always crash after roughly the same time. The semaphore version won't. It can be very useful to know how long it'll take until something crashes. So, in some way, the slotted version is "more deterministic", and the more deterministic something is the easier it is to debug.
I personally would like to get into this workflow someday, rather than local development. I usually needed 4gb when compiling on servers in the past. What would be awesome would be spot instances, that can very quickly clone a github repo and install selected GHC version, and have some preconfigured Emacs ready to go.
That's right. The Haskell thread scheduler only manages one resource for you: CPU. But not memory usage, open file handles, ports etc. The difference is critical: "How many threads are currently running" vs "how many threads currently have resources (of any type) allocated". Pooled functions give you a guarantee on the latter. By relying on just a scheduler, but having infintely many threads running, you will quickly run out of memory, open file handles, sockets, or other shared resources.
Thanks. I've added instructions now.
I *think* I may have been the one to coin the term "mini elm architecture" for Reflex, and I don't think the phrase is all that common among other Reflex-ers =P The idea is mainly that Reflex often leads to spaghetti code because people are trying to produce `Dynamics` that represent a sub-widget's state, while having that state be modified by a sibling widget's state. It just leads to a bunch of widgets gaining knowledge about each others' structure, which makes things harder to reason about. You can make things more composable by having a widget only broadcast the changes it would like to make to its state, and letting a larger entity decide how those other widget's actually interact with that state. So instead of `Event t otherWidgetInput -&gt; m (Dynamic t state)`, you do `Dynamic t state -&gt; m (Event t thisWidgetInput)`. Anyway, I think your type class and type families are kind of overdoing it. These classes assume that the `x` type encodes all the information you need, and that there's no environment you might need to shuffle around. You can get by if you add `m` as a parameter to the `Component` class, so that you can constrain on `MonadReader` or something, but you're still forced to limit yourself to `x -&gt; x` as your stateful function, which is really underpowered. You really just want a function from state, to something that can change the state, where you can use closures to encode environment, and where you can choose for yourself how to change the state. runElm :: (MonadFix m, MonadHold t m) =&gt; (change -&gt; state -&gt; state) -&gt; state -&gt; (Dynamic t state -&gt; m (Event t change)) -&gt; m (Dynamic t state) runElm f initial app = do rec state &lt;- foldDyn f initial change change &lt;- app state -- Return the state for good measure, but anyone following -- the Elm philosophy should not use the returned state as an indication of user interaction. return state -- EDIT: Or, for you point free folks: runElm f initial app = mfix $ app &gt;=&gt; foldDyn f initial I don't think it needs to be much more complicated than this. It encodes the desired structure, and is as flexible as can be. A convenient instantiation for the `change` type would be much like your implementation: `state -&gt; state`, such that `f` becomes `id` and you can compose events with `mergeWith (.)`. But you can also get much fancier [with more logical consistency](http://elvishjerricco.github.io/2017/04/01/nix-style-configs-in-haskell.html), allowing widgets to see a fully consistent view of what change is about to occur. Anyway, I think this is a much simpler implementation of the idea, which yields the same advantages, without imposing unnecessary restrictions on the structure of the app.
He doesn't have to answer. A question does not come with a gun to his head forcing an answer. Nor does it come with a gun to your head forcing you to post garbage. If you have something to contribute go for it, otherwise this is not productive.
Thanks!
Related work: https://github.com/nomeata/veggies
Yes, I can! Suppose I write bangy m = do (_, _) &lt;- m return () main = print $ isJust (bangy (Just undefined)) If `ApplicativeDo` is enabled, this prints `True`. Otherwise, it throws an exception. I think all will agree that `Maybe` is a law-abiding `Monad`. I believe the correct thing would be to impose a `Monad` constraint in this case; to relax it to a `Functor` constraint should require the user to write an explicit lazy pattern match.
I find Rust's system quite a bit easier to work with because it (effectively) defines a nested module for each type. And Rust has the same anti-modular typeclasses as Haskell. Haskell doesn't have nested modules which is hugely annoying.
It seems rare (in my limited experience), but this is not the first time I've encountered the positive/negative terminology. Can someone point me to some history for it.
That used to be my opinion as well, but in examples like [this](http://hackage.haskell.org/package/grammatical-parsers) any alternative would be much less elegant. 
I wrote a blog post on the topic: https://www.fpcomplete.com/blog/2016/11/covariance-contravariance
That looks like an Archlinux issue, I am not sure /r/haskell is the best place to ask (also, yes, this looks like a weird decision).
&gt; Thus, creating a thread should always be paired with some code that checks on it and tears it down if necessary. I tend to agree with the general sentiment here. Too often one tend to fork a thread assuming "it will stay there" up until the end of the program execution, which is not always the case. This is why I attempted to create something like my [threads-supervisor](https://github.com/adinapoli/threads-supervisor) library, so that at least I could be notified if a thread died and mostly importantly choose if and how restart it. I has to be said, though, that the particular use case I had in mind was long-running threads operating in a pub-sub fashion, and in that case `forkIO` worked quite well. For the average use case though, I thoroughly agree that `async` is the way to go: definitely I trust Simon much more than I trust myself when it comes to concurrency &amp; parallelism :P
For some reason, Archlinux switched to dynamically linked Haskell libraries and executables which means that if you want to install an executable you‚Äôll now have to install all libraries as well whereas they were previously linked statically. IMHO this is a big mistake for both people developing in Haskell since it means that you‚Äôll pollute your global package db and for people who just want to use an executable written in Haskell since they obviously don‚Äôt care about those libraries. Personally, I just removed everything except for `ghc` and `ghc-static` and use `cabal` and `stack` to install things.
I was talking about GADTs, i.e. exactly, with simple ADTs (or GADTs), it's difficult to built a representation allowing only well-typed terms.
Did you install stack manually? Because the Arch package also now [requires the whole haskell development ecosystem.](https://www.archlinux.org/packages/community/i686/stack/) 
I still have the static stack package in my pacman cache. For cabal, was that just `stack install cabal-install` or more complex?
What font are you using exactly? I got the symbol but for some reason it is very small comparing to the regular text
Did they switch recently? I just did a `pacman -Syu` the other day and it broke my xmonad, it can no longer find its libraries when I try to do `xmonad --recompile`. I tried reinstalling ghc, xmonad, stack, cabal-install; tried using the version of xmonad from cabal, etc. and nothing seemed to work. The only thing that worked was just recompiling xmonad manually through ghc. I thought this was something I messed up myself because it happened in the middle of a drastic overhaul of my `xmonad.hs`.
This choice will be less of a mistake the more haskell binaries you install. Haskell binary size is a real problem that limits use of haskell for system-level programming; as a developer of system-level software who prefers to use haskell, I'm glad to see a distribution trying to use dynamic linking. However, ghc is probably 500 mb or so, and it's probably only being pulled in to link against base and a few other libraries. Arch could probably improve this by splitting the ghc package into per-library packages. I also wonder if Arch Linix are only shipping shared libraries in the library packages; if those packages include .hi and .dyn_hi files rather than splitting those out into -dev packages, they could easily be 10x as large as they need to be.
Yep the switch was done together with the update to GHC 8.0.2 which got to [extra] on june 23th.
I think that was all.
As an experiment, I tried building the git-annex standalone tarball, which includes copies of all dynamic libraries it's linked against, with git-annex linked both dynamically and statically to haskell libraries. -rw-r--r-- 1 joey joey 66M Jun 26 06:52 git-annex-standalone-dynamic-amd64.tar.gz -rw-r--r-- 1 joey joey 51M Jun 26 06:59 git-annex-standalone-static-amd64.tar.gz So, if done correctly, dynamic linking does not need to increase distribution size significantly.
Honestly, this is all a much more compelling argument for avoiding `monad-control` than it is for sticking to the "`ReaderT` design pattern." `monad-control` completely lacks meaningful semantics and allows totally bogus logic like `concurrently (modify (+ 1)) (modify (+ 2))`. Using `ExceptT` instead of `IO` exceptions actually solves the problem of using `s0` in inappropriate places all the time with `StateT`.
[Been there, tried that](https://ghc.haskell.org/trac/ghc/wiki/ShorterImportSyntax). Still not sure why this proposal is languishing, because it seems so downright sensible.
I'm using `UbuntuMono Nerd Font Regular` from `UbuntuMono`. My terminal previously used simple `Ubuntu Mono Regular`.
Wow, I wasn't aware of the fpcomplete.com blog. I'm reading all the posts going back to 2012 now. Great content.
I'm not quite sure what you're suggesting. If you're not using `monad-control`, how do you `bracket` then / how do you do resource management in the presence of async exceptions?
`ExceptT e (StateT s m) a ~ s -&gt; m (Either e a, s)` I just meant that with `ExceptT` outside of `StateT`, state continues to thread, and using `catchError` will have the state behave much more predictably. Of course, if you just use `mtl`-style constraints, you have no guarantee that the `ExceptT` is on the outside, so you don't know much about the interaction between it and `StateT`. But stuff like that is why I don't generally use the `MonadError` constraint, and instead tend to just use `ExceptT` very ad-hoc and specialized.
I seriously doubt that this saves space even if you install all haskell binaries in arch, so many projects have a ton of dependencies, and a lot of those aren't going to be shared. GHC also, as far as I know, is *way* better at optimizing statically linked programs, so this is probably a performance regression for most of these packages. &gt; I also wonder if Arch Linix are only shipping shared libraries in the library packages; if those packages include .hi and .dyn_hi files rather than splitting those out into -dev packages, they could easily be 10x as large as they need to be. My understanding is all the haskell libraries are packaged with their haddocks.
No, it's intentional. People have been complaining for a few days now and the response from the maintainers has been pretty clear.
Oh, yea. I'm not at all trying to claim that `ExceptT` is a drop in replacement for `Control.Exception`; right tool for the job etc. etc.. My main point was that `monad-control` seems a poor solution to this problem as well, since it has virtually no meaningful semantics, and enables bogus logic.
&gt; have a purely IO layer for resource/concurrency management which does all the worrying about exceptions, and then stack the more straightforward semantics above that From how I understand this, this wouldn't allow you to use `bracket` only at the lowest level (like `liftIO $ bracket ... ... mycode`), which would mean you'd have to drop down to `IO` any time you want to do anything with resources, so you can never practically work in your transformer stack (because most things need `bracket`, such as opening a database handle, network connection, file, spawning a thread, etc)? &gt; but the finalization is untimely (waits until the end of your program), so I don't see it as ideal. Not ideal / interesting "solution"? This sounds more like "completely broken" :o Releasing resources at the end of your program sounds like not releasing them at all.
What is this /u/snoyjerk account about? :-/
Nope! They use pre-built binaries, but treat haskell dependencies as dynamically linked libs for some reason.
I think you're overestimating how often you need `bracket`. There are generally two classes of exceptions I care about in an app: ones I don't care about, and ones I do. So whenever I call a function that might throw an exception that I care about, I catch it *immediately* (as in, within the `IO` given to `liftIO`) and turn it into an `Either`, such that I don't need to use `bracket` to handle the failure case. For exceptions I *don't* care about, my lower level pure `IO` code uses `bracket` to release resources. I pretty much never have a monad transformer stack that outlives my resources, because those are far better managed by `IO`. A good example is a websocket server. When you obtain a connection, you should be running in pure `IO`. From here, you set up a simple loop to handle incoming messages, and you manage the resources needed by the routines that you dispatch those messages to. For the exceptions those routines care about, they will catch them themselves as soon as possible. For everything else, the loop will catch the exception and try its best to keep the loop going. Otherwise, the routine gets to use its handy dandy transformer stack and doesn't have to worry much about resources.
Doesn't hapistrano also compile things on the server? Atleast that's what it used to do when I looked at it last.
&gt; So whenever I call a function that might throw an exception that I care about, I catch it immediately Wait, this is not possible: You seem to be ignoring asynchronous exceptions. In the presence of those, _any_ function might throw an exception. Above, I asked specifically about "in the presence of async exceptions". Your approach doesn't seem to address that. &gt; I think you're overestimating how often you need bracket. As Simon Marlow explains [here](https://simonmar.github.io/posts/2017-01-24-asynchronous-exceptions.html#some-parts-of-the-code-can-be-really-hard-to-get-right), "**any** kind of resource that needs to be explicitly released" needs a `bracket`. Let's look at the websocket server example. I believe you are sugggesting something like: main :: IO () main = withWebsocketConnection $ \conn -&gt; runMyMonadStack handler conn handler :: ExceptT ... StateT ... IO () But what do you do when, for example, some of the websockets messages require you to open a file and stream contents from it? For example: handler = do msg &lt;- recvMessage case msg of ... -&gt; ... ("streamFile", filename) -&gt; do withFile filename $ \fileHandle -&gt; do ... BLOCK A: ... more websocket operations here ... withFile :: FilePath -&gt; (Handle -&gt; IO a) -&gt; IO a withFile file f = bracket (open file) close f Here, `withFile` opens a resource (a file handle), so it needs to use `bracket`. From how I understand your approach, it would force you to drop down to plain `IO` for the entirety of `BLOCK A`, so you could not work in your monad stack for the majority of your websocket server.
You could always write a type family that constrains the transformer stack so that ExceptT can only be on the the outside. Then your MTL functions just get an additional constraint (ExceptTOnTheOutside m). On the other hand, you might argue that the caller of your function should be able to decide which ordering of transformers they want.
Not sure about that. But I use it only for copying my local binaries and other files to the server for deployment.
The Arch Linux maintainers have always had a really bizarre stance towards packaging Haskell-based packages. Every Haskell-based package somes with the full source code of the package (including libraries that it uses) and all of GHC. This would make sense for Gentoo but the Arch Linux package manager provides binaries.
X-Post referenced from [/r/programming](http://np.reddit.com/r/programming) by /u/FrozenXZeus [When competing with C, fudge the benchmark](http://np.reddit.com/r/programming/comments/6jko9n/when_competing_with_c_fudge_the_benchmark/) ***** ^^I ^^am ^^a ^^bot. ^^I ^^delete ^^my ^^negative ^^comments. ^^[Contact](https://www.reddit.com/message/compose/?to=OriginalPostSearcher) ^^| ^^[Code](https://github.com/papernotes/Reddit-OriginalPostSearcher) ^^| ^^[FAQ](https://github.com/papernotes/Reddit-OriginalPostSearcher#faq)
I wonder if there is way, perhaps by extending the language, to get lifted IO with proper semantics. I think as it stands now, `foo :: Config -&gt; IO a` is much easier to reason about than a monad transformer stack with IO on the bottom.
&gt; Wait, this is not possible: You seem to be ignoring asynchronous exceptions. No that's not really the point I was making. My approach to async exceptions is that resources ought to be allocated in that pure IO space, which *does* use bracket to safely handle async exceptions. My comment about catching exceptions immediately was meant for when an HTTP library throws a synchronous exception to indicate a network error that I care about. Point being: When exceptions are semantically meaningful, catch them straight away. When they're pathological, like most async exceptions are, plan ahead for them in the IO layer, but don't submit yourself to antipatterns like `monad-control` for them. In your file streaming example, I would not recommend opening the file from inside any kind of complex transformer stack. I would say the resources you need should be allocated in as close to a purely IO stack as possible.
I'd like to see how this compares when using the LLVM backend. EDIT: Also how it compares to a C version that isn't broken for unicode.
Is it really better to write Map.insert than insertMap ?
I guess I should be emphasizing "close to pure IO" rather than "pure IO." Like, obviously doing resource allocation in a logger or Reader context is fine. But I think transformers like that are rare. StateT or Pipes certainly aren't one of them.
so wait, are you saying that `MonadBaseUnlift` (which captures the statelessness) is "close to pure IO"?
&gt; On the other hand, you might argue that the caller of your function should be able to decide which ordering of transformers they want. What would the argument be? If one ordering leads to incorrect behaviour, using precise types to prevent incorrect usage sounds like a good idea. &gt; You could always write a type family that constrains the transformer stack so that ExceptT can only be on the the outside. Then your MTL functions just get an additional constraint (ExceptTOnTheOutside m). Oh, that sounds like a good idea! Here's a suggestion to make it even better: instead of constraining the ExceptT to be on top of *everything*, how about only constraining it to be somewhere above the StateT layer? With a concrete monad transformer stack, you can add extra layers using `lift` and `hoist`, but you can't change the order, so the callee's stack must be a subsequence of the caller's stack. This is good, because the order of the transformers can be crucial to the correctness of an algorithm. Such A-must-be-above-B constraints would make it possible to express that kind of requirement in the more pleasant, `lift`-free world of mtl style. We could also express a variety of finer-grained requirements: for example, we could finally express in the types that the position of ReaderT doesn't matter, because it wouldn't have any such constraints, while transformers for which the order is relevant would have some.
I've had plans to do Haskell portions of what was eventually implemented as Rubato for awhile. If you find yourself having similar plans, ping me. 
Maybe? Not sure. Not as familiar with `MonadBaseUnlift`.
C is faster if you write it wrong! If anything, this is an argument for using Haskell. Eek. 
Wait. While the two first articles talk about the performance of a pure Haskell solution and a solution using FFI with C, this author compares it against a pure C solution. 1.- Undoubtably, C is going to be faster than Haskell, especially in those small snippets that, as the author mentions, the compiler can optimize. Plus, GCC is an incredible efficient compiler nowadays. 2.- if this algorithm can be trivially parallelized, then it could use some parallelization strategy using pure data in Haskell too
Would be happy to host this at SoundCloud!
Have a small working example of how to implement redux in haskell w/ ghcjs: https://github.com/dmjio/miso
I too was about to ask why -O3 for gcc and -O2 for GHC. 
Yes, it interprets any number higher than 2 as 2. You can even pass `-O11` for spinal tap performance.
Oh cool TIL!
It was more of a question for my part. I think I'm comfortable with it if the situation is that it's a valid Applicative assuming some other class is lawful and that you don't mess around with the internals (though maybe it should only be exposed in an `Internal` module?). We only ever care that laws are observably true with respect to the API we're given.
Wait, what? Since when is -O3 meaningful? https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/using-optimisation.html#o-convenient-packages-of-optimisation-flags https://github.com/ghc/ghc/blob/af9612bf862daaa99384eefa3059054053ecbee8/compiler/main/DynFlags.hs#L2324 I remember when they put the clamping in there so that -O3 would do the same thing as -O2. Before that -O3 would just silently have no effect whatsoever. ---- Edit: The input optimisation level is also clamped to 2 when generating LLVM options. Passing -O2 to GHC results in -O3 being passed to the LLVM compiler. See the source code here: https://github.com/ghc/ghc/blob/b2b416014e4276ebb660d85c3a612f7ca45ade78/compiler/main/DriverPipeline.hs#L1468
Cool! How best to get in touch?
See my comment [here](https://www.reddit.com/r/haskell/comments/6jlln8/when_competing_with_c_fudge_the_benchmark_xpost/djfb1u6/). 
Well, when criticizing a benchmark, ignore its goal. Because the original benchmark goal was deciding about importing some functionality by FFI or writing it nativelly. I fail to see how the speed of a C program is relevant.
&gt; This is literally exactly what criterion corrects for. Criterion is far better than whatever the author chose to implement ad-hoc to benchmark C code. x1000
Oh weird. I read somewhere in the documentation that the optimization level gets passed to LLVM. If I find it again, I'll file a bug report. 
&gt; `EitherT MyError IO` is a little bit smelly, because "unchecked" exceptions can be thrown and caught in `IO`. Only if `MyError` has an `Exception` instance, and even then is can be good to call out specific exception types -- especially if you'd done your best to make sure the `Right` case does not throw `MyError`. &gt; Using `mtl` instead of `transformers` Watch your performance though. If the compiler has problems making the monad stack concrete, explicitly passing all the instance dictionaries around can be costly.
Well, if the author wants to _not_ measure FFI calling overhead, and stay in C, then he can't use criterion. Also, criterion is less necessary in C, where run-time is much more regular than in Haskell (for example, no GC), so that one can often get meaningful results with primitive benchmarking approachs / without statistical relevance checks. In this case this is certainly true: None of us has any doubt that the benchmark is accurate or the C code is faster, as the measured results are evidenced by the assembly analysis. So in general, yes, criterion is great, but in this case, it isn't better or necessary. And you could interpret the article's complaint of &gt; Running the benchmark under an extremely short amount of time as either "doesn't know that criterion can handle that well" or "is aware that criterion can handle that well but still makes a sensible claim, because the amount of time may be so small that it's unclear whether the C code is benchmarked or the FFI overhead".
I hope someday this changes. I am sure there are some rare jobs in the complex corners of Google, Facebook, (or somewhere like IOHK), where programmers are constantly switching between challenging new problems, but for most positions it seems like the most variety of problems are during the interviews. I might go back to academia someday if the right opportunity arises.
The correct solution is to invent a bracket-like operation (along with its own type class) having the semantics you want on a case-by-case basis in order to allocate the resource in the new monad you've constructed. Typically, this will involve implementing the bracketed operation for each of the monad transformers you might be using, in terms of itself, on the underlying monad, and then implementing it for IO directly. In my experience, monad-control, while it *looks* like it ought to be helpful in doing this, just makes it harder to get those operations right than it would be writing them by hand explicitly. Sometimes it gives you the right thing, but often it gives you something which doesn't mean what you want, but has the correct type. Also, to hide the fact that you've used monad transformers at all should always be a goal. You can certainly still have code which is polymorphic in a choice of monad satisfying certain constraints, if that meets your needs and there's more than one monad that fits the bill. But abstracting the implementation of the monad is generally a good idea. Thus if you have to think much about a "transformer stack" (I hate that term), you're probably writing code which is going to be a mess later, if you ever have to adjust the implementation of your monad.
Man, that's horribly disappointing...
http://www.cs.huji.ac.il/~ornak/publications/stoc17.pdf - This abstract about the intersection of graph theory and formal verification methods seemed the closest to relevant to what some Haskellers might encounter (e.g. implementation of SMT solvers). I didn't manage to attend that talk. I asked the presenter to post here if she has a video.
The `-O2` flag is oddly in the [`stack.yaml`](https://github.com/FrozenXZeus/HammingHaskellC/blob/master/hamming-haskell/stack.yaml#L67-L68)
By "on a case-by-case basis", do you mean once for each call, because different situations require different semantics for this bracket-like operation? e.g., sometimes we want the exception to roll back the state, and sometimes we don't? Or do you mean that the implementation will be subtly different for each transformer stack, and that we should write one bracket implementation for each *stack*, as opposed to doing part of the work in each transformer and combining those parts using something like MonadBaseControl? If the later, those implementations could be put in some `BracketMonad` type class. And if so, I'm wondering if `bracket` is the right method to put in that type class, i.e. whether other methods-with-an-IO-in-a-negative-position like `try` and `catch` and `withFile` can be implemented in terms of `bracket`, and conversely if `bracket` can be implemented out of simpler methods like `mask` and `try`.
I mean for each monad transformer, we should implement an instance of our new bracketed operation's type class, and we should think carefully about the logic present in each of those instances, because while it's often simple, it's easy to get wrong and *does* involve some free choices. The trouble with monad-control is that it tries to do this generically for an arbitrary bracketing operation. It gives you some kind of choice regarding how the bracketing operation ends up being lifted, but that might not be the correct choice for that operation. It's something which really needs to be handled with a bit more care usually, in a way which depends on the meaning of the operation we started with, and how we want the continuation we're supplying to interact with everything else that's going on. Also, half the time, applying monad-control ends up being a bit fiddly, and in my experience it's usually not too much of a syntactic savings over just writing what you mean. The meaning of the end result is also less easily understood. If you're using monad transfomers correctly, you won't be allowed to implement the operation at the call site, because you either won't know which monad you're actually working in, or at least you won't know how the specific monad you're working in has been implemented. In very rare cases, this can be frustrating, but the alternative of exposing the implementation of the monad in use typically carries far more potential frustration with it (at least if the usage of transformers spans more than a few lines of code).
Posted by the author (not me) on Haskell-Cafe; &gt; After years of pondering this idea (in various forms), and several rounds of discussion on several forums, I've written it up. &gt; "This proposal tackles the thorny topic of Overlapping instances, for both type classes and Type Families/Associated types, by annotating instance heads with type-level apartness Guards. Type-level disequality predicates appear in Sulzmann &amp; Stuckey 2002; in the type-level 'case selection' in HList 2004; and in various guises in Haskell cafe discussions in following years. &gt; This proposal builds on the apartness testing implemented as part of the Closed Type Families work."
This is pretty dumb in my opinion. It means that you can no longer just install ghc and then run 'ghc Hello.hs' because ghc can't compile anything (statically, which is the default) without the static platform libraries. I think users have a reasonable expectation that running the compiler with the default flags should just work out of the box. Having to install a separate package for this is pretty silly. If they changed the GCC package so that 'gcc hello.c' no longer worked, I think people would be pretty surprised.
Geniplate is maintained: [geniplate-mirror](https://hackage.haskell.org/package/geniplate-mirror)
Except then it might never have happened.
Though to be fair, bad `mtl` performance is still far better than the likes of Python or Node.
Thanks, I never heard of it, I already checked `react-flux` but it is more like flux rather Than `redux` thats why I was looking for alternative, miso looks promising 
Does -fllvm give freebie performance gains at the cost of longer compile times consistently? I've never played with the llvm backend before since there doesn't seem to be much enthusiasm for it in the community.
Could we remove this post from ANN? it's taking up prime real estate on the subreddit and the discussion is pretty much dead.
When I worked at Enthought I felt like I did a solid amount of actual thoughtful programming, including reading papers and fun prototyping. At Google the problems are of a different nature. Time is spent thinking about things like, "How can we reliably deliver email to billions of accounts without spending billions of dollars?" and "How do we rollout changes worldwide safely?" It's "bigger" but I'm not sure I can say it's more fun or even more interesting.
I think in most cases it's the better backend, but I haven't messed with it myself. I do wish https://hackage.haskell.org/package/llvm-general had newer releases. I can't seem to get the old releases to work for me; seg. fault at runtime for even a trivial program. :/
"better" as in more performant? If so, why do people not use it more often? I know it has slower compilation times and may not be as much a performance increase as we'd like due to mismatch between GHC and llvm optimizations. Still, for a release build any non-trivial performance increase would probably be worth it, assuming correctness is maintained. 
"better" in a few ways, not just better performance, but a wider selection of final binary formats, more well-typed "bytecode", a larger community, a better optimization target (than Cmm; Core and STG layer optimizations would be unaffected by the switch), etc. There are tradeoffs, and I'm glad the Cmm backend exists, but I think it may be time to use a more general framework, and LLVM isn't going away soon.
So, I think the syntax could be reused, but apartness definitely has a different flavor than today's existing constraints. Specifically: there isn't really "evidence" of this constraint, because it is always treated pairwise with another apartness claim, never on its own. I think this is crucial. Lots of people have thought about how to do inequality constraints in the past and not really made progress.
I hear that. I think it makes sense for some contexts and not for others. I'd prefer to make both variants available, as Conduit does, but that's a decent amount of maintenance overheard.
This has been resurrected as [llvm-hs](http://hackage.haskell.org/package/llvm-hs).
LLVM typically gives significant performance improvements for code that is numerically heavy, however the native code gen typically does a little better for non-numeric code. 
That kind of sounds exactly like the ReaderT pattern.
The blog post gives concrete examples of confusion with functions like finally in the StateT transformer. I'm struggling to see how this comment is relevant.
Using Accelerate [(results)](https://gist.github.com/tmcdonell/7a162e107e34504698252d04f64fc0d2) gives the same performance as C (for larger array sizes, anyway).
I'm having this very discussion with the author on the /r/programming thread right now. Why did they claim that the benchmarks couldn't be verified when they didn't even do approximately the same thing? 
Why don't they just make `-O10` optimise more? 
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [erikd/exceptT-demo/.../**with-stateT.hs** (master ‚Üí 51da1bf)](https://github.com/erikd/exceptT-demo/blob/51da1bf29bbd919241e1cfdfa60517b0a78b3929/main/with-stateT.hs) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply djghbjc.)^.
If someone did us the service of providing a helpful and interesting link, they earned the upvote karma, regardless of any other less helpful activity in their history.
Do you know where the videos will be posted?
&gt; criterion is less necessary in C, where run-time is much more regular than in Haskell (for example, no GC), so that one can often get meaningful results with primitive benchmarking approachs / without statistical relevance checks. This is completely untrue.
I am also waiting for them. Monitor https://twitter.com/composeconf!
From the perspective of bind the `[x]` in `m [x]` is just a value like any other. To compute `m a &gt;&gt;= (a -&gt; m b)` we need to get an an `a` which we can only do from the `m a`. We can't interleave monadic computations into the pure value we want so we have to evaluate the `m` part in entirety before we can continue. This doesn't mean that the `a` has to be fully computed and in normal form, just that it has to be a pure value now. (I am using evaluate pretty loosely here but you hopefully get what I mean.) We could create something like: nestedEffects :: m [m a] runEffect :: m a -&gt; a streamingEffects :: m [a] streamingEffects = fmap (map runEffect) nestedEffects Which is roughly how lazy IO works. That is probably a bad idea, though, and a more principled abstraction like pipes or conduit would be much nicer to work with. Slightly off topic: I seem to recall that it is faster to pass arguments explicitly if you are using a worker function anyway since ghc doesn't have to wrangle the environment. Is that still the case?
So awesome, thank you! Now is the time to write a roguelike in haskell :)
&gt; If the you're expecting the returned list to use enough memory to hold all its contents (which I have no idea why you wouldn't) Oh OK. For some reason I assumed the OP wanted streaming. If not then my only objection is the repeated appends to the tail. &gt; &gt; Why do you have the constraint `HasApp m`? Surely `Monad m` is enough &gt; &gt; Because `getRemoteSublist` has `HasApp m`. I meant on `runUntilNothing`. That doesn't need `HasApp m`. 
Oh, I'm sure it doesn't *need* one. I'm wondering why it's been given one that's overly specific.
Nice. I know what library I'm playing with over the long weekend.
I think that you'll be much better off by profiling your code for performance and memory consumption--profiling is an empirical exercise. To that end, you may find this link useful: https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/profiling.html
This exists :-) https://lambdahack.github.io/
I strongly disagree with this. `StateT` makes perfect sense as a monad for purely accessible thread local state. `ReaderT (IORef a)` is a type for IO-accessible state available to all threads in the monad. They're fundamentally different. The `ReaderT (IORef s)` makes it difficult for threads to have their own local state, by making the initial fork annoying. localIORef &lt;- newIORef &lt;=&lt; readIORef =&lt;&lt; ask local (const localIORef) . async $ do ... The `StateT s` makes it difficult to have the local state changes be made global, by making the return-from-fork annoying. x &lt;- async $ modify (+10) -- x :: Async (StM (StateT Int IO) ()) -- x :: Async (Int, ()) (plusTenned, ()) &lt;- wait x They're both *useful*, they just have different semantics, and you need to know which one you want.
If you're going to consume the list, it might be better to write a fold style: foldPages :: Monoid m =&gt; ([MyData] -&gt; m) -&gt; IO m foldPages f = go mempty where go acc = do page &lt;- getPage if null page then return acc else let acc' = acc &lt;&gt; f page in acc' `par` go acc'
I love brick.
Why is that? (Is there some article about this usage of `Void` vs. type variable?)
&gt;Here's a simple recursive function call to do this, but we're not really sure if it's going to "hold on" to a lot of memory, or will it be (tail call?) optimised by the compiler. Any thumb rules on how to understand the runtime characteristics of this kind of code? There's already been a lot of debate about pipes/conduit, but both are excellent libraries and they solve exactly this problem. So use them! The Haskell ecosystem is one of the "soft" strengths of the language, but it's still a strength. Further, note that your constraint includes `Monad m` - I assume that this is necessary? `Monad` is Haskell's abstraction for "stuff where it matters what order you do it in", among other things, hence applicative parsers being faster than monadic ones. So, as the other poster has said, this would almost certainly use lots of memory.
Have you seen [EventWriterT](https://github.com/reflex-frp/reflex/blob/50305c797c41a27660b74f543e204e902c086bbf/src/Reflex/EventWriter.hs#L55)? It might be useful for implementing something like this!
Can someone help me out here? I'm very confused. As far as I understand it, `bracket` patterns are for ensuring the timely release of resources if an exception is thrown. But isn't this what finalizers attached to weak references are for, for example, [`mkWeakIORef`](http://hackage.haskell.org/package/base-4.9.1.0/docs/Data-IORef.html#v:mkWeakIORef)? Don't these finalizers make non-memory resources act as though they were garbage collected and thus make all this `bracket` stuff unnecessary? What am I missing? 
&gt; You could even have the value of the elements themselves be in the types. This would work for literals like `[1,2,3]` but not if you have an expression like `[x,y,z]` in which the shape of the list is known at compile time but the elements are only known at runtime.
It's not an annoyance, it's a bug when one version number refers to two versions of a package.
And `pipes`: loop pageNumber = do mresult &lt;- lift (getRemoteSublist pageNumber) for_ mresult $ \result -&gt; do each result loop (pageNumber + 1) And `streaming`: ... eh ... same code as above! And `list-transformer`: loop pageNumber = lift (getRemoteSublist pageNumber) &gt;&gt;= \case Nothing -&gt; empty Just result -&gt; do select result loop (pageNumber + 1)
&gt; Reflex does plenty using weak references, and they've said that getting that to work right and efficiently is a pain. That's good to know. Reflex is typically running as Javascript though. I'd be very interested to hear from anyone else who's tried managing resources using weak references in GHC's runtime.
Are you open to remote? 
Wow, that's indeed quite hairy. Here's how I would write it, is it less intimidating? step :: Game -&gt; IO Game step g | g ^. paused = g | g ^. dead = g | otherwise = die g' `orElse` eatFood g' `orElse` move g' `orElse` g where g' :: Game g' = g &amp; frozen .~ False orElse :: Maybe a -&gt; a -&gt; a orElse (Just x) _ = x orElse Nothing x = x
And remote needs to qualify how remote (same time zone, same nation, same continent, same planet).
Yeah, totally agree to be honest. I kinda sped through the ``Snake`` module. I also typically don't like to use `&lt;*&gt;` on lists and instead `fmap ($ val)`, but in this case it's a little uglier: $ getFirst . mconcat . fmap (First) $ fmap ($ g &amp; frozen .~ False) $ [die, eatFood, move] Eh maybe not idk. But yeah, could use a little cleanup, maybe I'll do that tonight. Or I could just remove the implementation from the tutorial :)
I like this! My `ifThenJust` is terribly ugly, `orElse` is both more succinct and clearer. I think it's equivalent to `flip fromMaybe`. As you've written it, the first two cases for `paused` and `dead` would need a `return` to type check.
I guess I'd really only prefer a list of functions if it *had* to be a dynamic ruleset, otherwise nothing is lost with making it static. Coupling this with First makes me feel this block would be resistant to changes and would have to start over from scratch if things had to be tweaked slightly.
&gt; `paused` and `dead` would need a `return` to type check. oops! I didn't pay attention to the type signature of `step` and inferred its type to be `Game -&gt; Game`, and the types of `die`, `eatFood` and `move` to be `Game -&gt; Maybe Game`.
Does anyone know if there's a relationship between Brick and React and The Elm Architecture? The resulting designs are strikingly similar from what I can tell (at the high-level). Maybe they are only similar because this is just a natural design one will come to when reasoning about how to build a controllable and sane UI/TUI/GUI?
&gt; We definitely are open to considering remote candidates. Is this a sufficient description?
&gt; We require that all candidates interested in applying are capable of reading at least the first paragraph of this ad :D
You may want to see [HaskellTools](http://haskelltools.org). Though it is not ready yet.
Reads nicely with the named expressions, but this doesn't check whether the game is paused or dead
Just fixed it. :)
Something I would love to see, is how make larger UIs with `brick`. It was not clear to me how I was suppose to compose smaller pieces into larger ones.
Much better. * That is why modules are invented for. * Decorating the names with the module name to avoid name-collision is a redundant solution. Redundancy is bad.
Ah, that makes sense. Thanks!
My goal was beginner friendly implementation of one function more for the benefit of newcomers. In fact as far as I can tell you're fairly consistent with your style which I think is pretty important so I probably wouldn't have changed anything.
I'm sorry, was there a question? (Downvoted.)
Use these types for time regardless of location, when you don't care about leap-seconds (which you don't): * `UTCTime` for actual times * `NominalDiffTime` for differences between times, i.e. durations Use these types for the ways people refer to time: * `Day` for something like June 27th 2017 * `TimeOfDay` for something like 5pm * `LocalTime` for a `Day` with a `TimeOfDay` * `TimeZone` for a time zone offset (not actually the time zone itself, sorry) like -0700 * `ZonedTime` for a `LocalTime` with a `TimeZone` Use this for fast access to your system clock (from version 1.8): * `SystemTime` You probably won't need these: * `AbsoluteTime` and `DiffTime` when you *do* care about leap-seconds. * `LeapSecondMap` for tracking the leap-seconds * `UniversalTime` if you want to use the Earth as a clock
Nothing to add to the job portion of this but I've used the libsbp haskell library and it was amazing. The SwiftNav multi was incredibly fun to use! Worked perfectly. I was surprised to have a supported haskell library! Thanks for the awesome library and hardware!
I sure hope they use Haskell on Mars. I sure wouldn't want to find an error in pretty much anything...
Firstly well done on the interesting apps and blog post! We need more of these Haskell blog posts in general, and I hope you understand my comment as how to make your work even better than it already is rather than a criticism of what you've done. Regarding mixing `$` and `.`, well, it's my opinion that chains of `.` are always better than chains of `$`, because `.` is associative. Beyond that, mixing those operators breaks up the flow of the reader and makes it less obvious that's it's a linear pipeline. If it were up to me I would have just written it (before refactoring) as step :: Game -&gt; IO Game step g = (fromMaybe (return g) . join . ifThenJust (not $ g ^. paused || g ^. dead) . getFirst . mconcat . fmap (First)) ([die, eatFood, move] &lt;*&gt; [g &amp; frozen .~ False]) but I prefer the refectored versions even more.
&gt; Worked perfectly. I was surprised to have a supported haskell library! Are you referring to http://hackage.haskell.org/package/sbp ? In its current form I'm afraid to say that it is *not* a well-maintained Haskell library. It doesn't even succeed a simple `cabal install sbp`, as it lacks any useful dependency specification. That's also why Hackage fails to build documentation as the dependency specification doesn't allow the solver to find a sound install-plan. And if you look at https://matrix.hackage.haskell.org/package/sbp you notice that except for the earliest releases, most releases suffer from inaccurate dependency specifications. And even if you manage to be lucky and find an install-plan that happens to compile you still wouldn't know if it's a semantically sound configuration. Needless to say it would take Hackage Trustees substantial effort to infer accurate version bounds for all those releases, which is why this package has rather low priority for us right now, even though it keeps using up community resources.
&gt; This is a lot clearer I think. Perhaps someone else can improve it further. Sure! 1. `firstJust :: [Maybe a] -&gt; Maybe a` is a specialisation of `asum :: (Foldable t, Alternative f) =&gt; t (f a) -&gt; f a`, so step g = fromMaybe (return g) $ if (g ^. paused || g ^. dead) then Nothing else asum $ fmap nextState [die, eatFood, move] where nextState :: (Game -&gt; a) -&gt; a nextState f = f (g &amp; frozen .~ False) 2. It is sometimes useful to picture the `fromMaybe` function as a keyword that opens "a `Maybe` block". If we do that, we see that what we have is essentially a block with only a single line of code in it. Sometimes, that's what we want, but in this case, it's missed potential! By viewing it as a block of code, we can also picture the `guard` function as "exit the block in a failure condition if this condition is met" (somewhat like a `break` keyword in other languages). step g = fromMaybe (return g) $ do guard (g ^. paused || g ^. dead) asum $ fmap nextState [die, eatFood, move] where nextState :: (Game -&gt; a) -&gt; a nextState f = f (g &amp; frozen .~ False) 3. Since we have stuff in a `do` block now, we might as well use a `let` binding. step g = fromMaybe (return g) $ do guard (g ^. paused || g ^. dead) let unfrozen = g &amp; frozen .~ False asum $ fmap ($ unfrozen) [die, eatFood, move] 4. Screw it, let's remove the `map` application entirely! step g = fromMaybe (return g) $ do guard (g ^. paused || g ^. dead) let unfrozen = g &amp; frozen .~ False asum [die unfrozen, eatFood unfrozen, move unfrozen] 5. Aaaand personal preference on code formatting style. step g = -- step is a function whose result depends on g fromMaybe (return g) $ do -- on failure in the following block, return g unchanged guard (g ^. paused || g ^. dead) -- paused or dead counts as failure conditions let unfrozen = g &amp; frozen .~ False -- unfrozen is g except not frozen asum [die unfrozen, eatFood unfrozen, move unfrozen] -- run the functions, pick the first success ‚Äì or fail Hey, Haskell is a great imperative language! 
Nice article! Why does step need to live in IO?
 getRemoteList = void $ runMaybeT $ for_ [1..] $ lift . CL.sourceList &lt;=&lt; MaybeT . lift . getRemoteSublist or to go one further: getRemoteList = void $ alaf MaybeT traverse_ (traverse CL.sourceList &lt;=&lt; lift . getRemoteSublist) [1..]
Martian Haskeller, something to think about.
In the second example, I would not call "composition" what is accretion of state and rewriting. Suppose that instead of a snippet you have a third part library in binary format. You can't do that. Please don't use composition for what it is not. Call it prettification or sugaring by polimorphism, but not composition. If that qualifies as composition, then Object Oriented programming is super-composable, since it does not need rewriting to handle multiple states.
Is there any reason why constraints are not used to solve overlapping instances ?
Thanks! 
It is definitely possible that "Composable" is not the best word. &gt; prettification or sugaring by polimorphism :thinking_face: &gt; Suppose that instead of a snippet you have a third part library in binary format. You can't do that. What does this mean exactly? Does this apply to the examples I gave?
Why stop there? class Has p f a b where has :: p a (f a) -&gt; p b (f b) As [/u/floatboth points out](https://www.reddit.com/r/haskell/comments/6jy8yu/the_has_type_class_pattern/dji5e1p/), [Data.Has](https://www.stackage.org/haddock/lts-8.20/data-has-0.2.1.0/Data-Has.html) is already most of the way there!
It's not really arguable -- it just not timely enough for scarce resources like network sockets and file descriptors.
It's possible to be a well-maintained Haskell library without dependency bounds. You're ignoring [their installation instructions](https://github.com/swift-nav/libsbp/tree/v2.2.6/haskell#install-from-hackage), which tell you to use Stack with the LTS 6.25 resolver. 
I love this. There's a broader point here too about the way people use Lens. I'm an intermediate Haskell coder (have written production Haskell at work), but I've avoided Lens intentionally because it makes code *impossible* to read, particularly with the profusion of operators.
I feel strongly that if your package does not build with `cabal`, it should not be on hackage.
Your welcome! Thanks for the encouragement!
I mean yes, because the former involves a perfectly safe qualified import. Whereas the latter either involves a very unsafe unqualified open import (now your users need to pin down the minor version, or you have to consider adding a new function a breaking change and increment `A.B`), or it requires adding `insertMap` to the import list. So the latter is either unsafe or creates extra bloat that the former doesn't.
Cool! Will this generate libraries that can be linked in native applications? 
I actually don't know. Taking a wild guess, I would say that it operates on the CMM level since it is easier to lower to JS, than the abstract STG machine model would be. Then again, this is just a guess. Perhaps GHCs STG contains vital information that they need to lower to JS. I'd like to know myself.
I mean that if you have a binary library that manages a state a, you can not use that trick to make it work also with your state b. 
Any reason for not going `Has p f s t a b`? It can be useful for polymorphic types.
Thanks, appreciate that. After seeing it written out, I agree with you on `.` over `$`, it does read as a nice linear pipeline. Now I'd like to ask a really dumb question... in a situation like this, what does associativity grant us? Is there a particular refactoring example that is made easier if your operators are associative?
Thanks! If you eat food, you need a new random food location. I also took a shortcut by making the sub-actions `die`, `eatFood`, and `move` all of a unifying type `Game -&gt; Maybe (IO Game)`, but really, only `eatFood` needs to live in `IO`. Quick &amp; easy, but maybe not the most idiomatic approach.
Thanks, great tips in there. I'll be sure to reference this if I make another tutorial. I've got lenses all over the place in this one, as I wasn't really thinking about experience levels, but of course, a tutorial's only going to be more useful if it can target a broader audience.
https://gist.github.com/saurabhnanda/1d9a9659a7681ac5268e9212bd4f4389
&gt; Note that since different Nix packages are generated than what is shipped with nixpkgs, there is no binary cache. What can be done to make binary caches available? This is, I think, the killer feature that could make Nix popular.
When is general availability?
He says "pff stab", so he doesn't seem to care
That's an interesting one!
Someone just has to do the builds for entire Stackage snapshots and push them to some cache that people use. I'm guessing stack2nix doesn't support nixifying a whole snapshot yet though.
Yes, you can this way, but you have to play with modifications of code that may be non local to your code. Suppose that you use a third library C that is the one of your company and you want to make that composition reusable for everyone. You need to add additional Has... instances to the central code of the company for each new state, make versioning, recompilations and tests affecting all the code and programmers of the company You say it: &gt; You would like to write: foobar = do flag &lt;- foo if flag then bar else return 0 Without further ado. That would be IMHO true monadic composition. But you can't, since monad transformers do not compose: &gt; but it won‚Äôt type check, because foo needs an Int environment and bar needs a String environment. 
Isn't that the point of the post? *If* you use the pattern *then* it is composable? I feel like we are in violent agreement?
This is the real question. One wants to make one‚Äôs app not just look and feel 99% like a real native app, but actually *be* one. I‚Äôm not sure how it is on Android, but on iOS and macOS this is a must IMO.
This is definitely a huge must on Android. Google has spent a lot of time and effort making very compelling APIs and wrapping things very tightly into the Play Services ecosystem. If your app doesn't link into native infrastructure, it's going to be crippled functionality wise in a lot of areas.
Stupid bot. Prolly not even written in Haskell
Thanks for the Matterhorn mention! We have been working on that for almost a year at this point.
Brick author here - thanks for this very nice intro article! It's nice to see people getting value from the library. :)
I have a few interesting Haskell problems to work on, and might be interested in paying a few hundred bucks to get them solved. Do you have any interesting in deep learning or mathematical optimization?
I‚Äôm not quite sure. It might just be to make the implementation more efficient. At this point there is probably also a reasonable amount of code written with the current behavior in mind so changing it might break some things although it seems like code that‚Äôs currently compiling should still be compiling.
Love this. I'd certainly participate myself as well. Have you guys got a timeline to get started? Is there anything blocking this?
&gt; what does associativity grant us? Exactly as /u/enobayram says in the sibling comment, parts of chains of associative compositions can be spliced out and transplanted to somewhere else.
&gt; As far as I can tell, nobody has been banned. And yet, [Herbert *has* been blocked](http://i.imgur.com/A5cLn8I.png). (He helpfully sent me a screenshot.) You can't see this fact unless you are the affected account (in which case any attempt to respond, create an issue or fork the repository responds as in the image) or the one doing the blocking. To everybody else, it just looks like that person stopped responding, so your statement is a tautology. =) &gt; Regardless, how does this relate to their job posting? Knowing how an organization interacts with the rest of the community is something that I personally take into consideration when considering a job offering. YMMV.
"no binary cache" just really means no public/single binary cache. If your whole team works with the same `stack.yaml` and has a Hydra server setup running `stack2nix`, I believe you should share binaries.
Hey funny you should mention it, we've got a team where I work using Opaleye, and many of us would love to see a blog post which introduces the profunctor product default stuff. It's left many of us scratching our heads.
We have already started. Do write to me at saurabh@vacationlabs.com if you'd like to participate. 
Well, matters can be improved a little, I think. I'm pretty sure these fundeps are reasonable to impose for traversals: class Has p f s t a b | s t -&gt; a b, s a b -&gt; t, t a b -&gt; s
This is incorrect, AFAICT. The entire discussion was muted, not a specific target at one individual. I use this feature regularly in Stackage when too many users are involved and I don't want people getting spammed. __EDIT__ I was tired when I wrote this. With some coffee in me: the term is "lock conversation," not "mute." __EDIT 2__ I stand corrected, see below.
Interestingly, both `aeson` and `servant` are (co-)maintained by some of Hackage Trustees...
You should read up on what [blocking a user entails](https://help.github.com/articles/blocking-a-user-from-your-organization/) and compare this to how [locking conversations](https://help.github.com/articles/locking-conversations/) relates before jumping to faulty conclusions. There's a lot of things you don't know about what happened here visibly and not so visibly; here's some of the actual facts: - https://github.com/swift-nav/libsbp/issues/413 was *not* locked and is not locked as of writing (if it was you'd see it in the UI as an event in the event-timeline of the respective issue-thread). - https://github.com/swift-nav/libsbp/issues/416 was locked by mfine 15 hours ago - I was "blocked" from the organisation https://github.com/swift-nav (this means I can't fork any repos, nor open issues, nor comment, nor watch any repo in there, etc) shortly after my last comment to #416 (the conversation was not locked at the time) - Because I was blocked from interacting, I asked Alan to file the PR #422 in case this was something personal and I started consulting with the other Trustees - https://github.com/swift-nav/libsbp/pull/422 was locked by mfine 15 hours ago 
&gt; .. attempting to even open a dialogue about your packaging decisions .. This is not a dialogue, it's a notification of *expectations* from certain people. it usually come with vague disguised threats of "or else". what a great sense of community indeed.
Interesting post! this is exactly my `data-has` package designed for. The main usage to me is to combine it with mtl to get clean extensible Reader(recall the ReaderT design pattern from snoyman for example).
I thought `nixpkgs` already tracked Stackage? Why not directly use the binaries provided by the Hydra farm? As in, if you type `cabal2nix` you actually get packages from a stackage snapshot. So I don't really see what role this tool fulfills
I stand corrected, thanks for the information. I didn't realize you could block a user from an organization. I look at available settings on projects often, and have never seen anything about blocking someone. It didn't occur to me that such a setting would be available at the organization level. Useful information, thanks!
&gt;:( [Here is a picture of a kitten to cheer you up](https://s-media-cache-ak0.pinimg.com/736x/2f/1b/ce/2f1bce3c8e028dacbb77ef675c08ca32--adorable-kittens-adorable-animals.jpg)
Or simply an infinite list of next food locations in the game state.
One way or another, you need to establish some layer of trust between the cache and the user's producing binaries. Either that needs to be explicit (as it is now), or you need some distributed trust mechanism. I don't know the first thing about blockchain, but isn't it's purpose something along those lines? Though I guess this would imply having many users rebuild for trust's sake anyway, which at least partially defeats the purpose.
I mean simon can speak for himself, but I think you're misreading his comments in one specific sense. He's talking about what the norms would be _once_ we had some sort of automatic bounds inference of the sort that was being discussed in place. That's not the world we live in now, because that proposal hasn't come to fruition. The proposal isn't "change norms on hackage". The proposal is "do a whole bunch of technical work to change how things work to be much nicer, and in such a situation, have a new set of norms." I support some version of such as a proposal, as do a lot of people. But we're not there. And invoking support to such a proposal to imply an attitude towards the norms we have now with the tech we have now doesn't seem to really capture the spirit of things.
I did say "almost". The main exception I know of is when you are building an EDSL where for some reason the terms need to be record fields. We came across a use case like that at work, and your example also falls in that category.
I don't mind learning new interesting stuff, though I don't have experience with that.
Some sort of integration with "stack script/runghc" would be very flexible: https://haskell-lang.org/tutorial/stack-script
Nice trick with passing the constraints using type application. Had no idea that was even possible!
Impressive, is the rendering performance ok? I always wondered if Rasterific could handle real-time load.
Got my hopes up thinking this was either a compiler extension or some really clever trick I didn't know about. In the end it's basically the same as https://github.com/mikeizbicki/ifcxt
Same here! And apparently you can also use `Proxy @a` instead of `Proxy :: Proxy a` (I imagine that `undefined @a` would also compile?). Explicit type application just gets cooler the more I see examples of it in use; it's also an essential tool in Eisenberg's work on `-XDependentTypes`!
What did the post say?
My personal take on various environments I tried for developing in Haskell, ending up using VS Code with ctags and running `stack build` and stuff from its terminal and without using Haskero or Haskelly because they didn't work well for me (and neither did Sublime-Haskell nor atom's ghc-mod based plugins)..
I think this approach is more general. I'm not sure what use cases will get adopted in wild ... if any. It's not a feature I thought I had. FWIW I think many users would prefer to tackle the use cases in the post by using helper type. For example: data ShowOrDont a b = ShowThis a | Dont b instance Show a =&gt; Show (ShowOrDont a b) where show = \case ShowThis x -&gt; show x Dont _ -&gt; "_" But maybe not?
I don‚Äôt think a library should only be buildable with a specific tool, much less with a specific snapshot. Sure it works, but I wouldn‚Äôt call it ¬ªwell maintained¬´.
I think you mean `instance Show a =&gt; Show (ShowOrDont a b) where ...` `ifcxt` is neat!
Yes interesting types are a separate and desirable feature.
&gt; (I imagine that `undefined @a` would also compile?) Interestingly, in `base-4.9.1.0`, it doesn't! &gt; :t undefined @Int error: Expected kind RuntimeRep, but Int has kind * This is because the type of undefined is no longer `forall a. a`, but [rather](http://hackage.haskell.org/package/base-4.9.1.0/docs/src/GHC.Err.html#undefined): undefined :: forall (r :: RuntimeRep). forall (a :: TYPE r). HasCallStack =&gt; a undefined = error "Prelude.undefined" I'm not familiar with [RuntimeRep](http://hackage.haskell.org/package/ghc-prim-0.5.0.0/docs/GHC-Types.html#t:RuntimeRep), but it has values like PtrRepLifted and UnboxedTupleRep. I'm guessing that normal types like Int require PtrRepLifted? &gt; :t undefined @'IntRep @Int error: Expecting an unlifted type, but Int is lifted &gt; :t undefined @'PtrRepLifted @Int undefined @'PtrRepLifted @Int :: Int &gt; :set -XMagicHash &gt; :t undefined @'PtrRepLifted @Int# error: Expecting a lifted type, but Int# is unlifted &gt; :t undefined @'IntRep @Int# undefined @'IntRep @Int# :: Int# Indeed. And I'm also guessing that this more general type makes it possible for undefined to be used when an unlifted value is expected? &gt; :{ | let simpleUndefined :: a | simpleUndefined = undefined | | expectInt# :: Int# -&gt; () | expectInt# _ = () | :} &gt; expectInt# simpleUndefined error: Couldn't match a lifted type with an unlifted type &gt; expectInt# undefined *** Exception: Prelude.undefined Indeed again! Our last expression type-checks, indicating that undefined is indeed a valid placeholder for an unlifted value. And then the expression fails at runtime, because even though expectInt# is ignoring its input, unlifted arguments are evaluated strictly.
Well... I've had an overwhelmingly positive experience with this sub... When I was a beginner, I found some of the posts/comments a little overwhelming... but they weren't written for me. I'd like to know what Snoyman feels warrants the hostility.
This is due to the levity polymorphism improvement, yes? Intriguing stuff! 
I usually fumble for a minute finding all the functions I need to do this, when writing tests. I usually find it useful - `UTCTime (fromGregorian 2017 1 2) (timeOfDayToTime (TimeOfDay 14 05 00))`
A lot of the bad stuff I see on this subreddit seems to be people disagreeing over what's best for the community (which is mostly just unhelpful meta-discussion) and people promoting other, much smaller, communities (which causes needless fragmentation).
Without knowing libsbp specifically, I think there is a tension some people face when wanting to have others be able to view and use their code, without having enough time/resources to actually interact with the community or maintain it for anything but one's own specific use case. Specifically with respect to Github, it would probably be best served by having a private repo, then a public mirror that gets updated every few months, and encouraging any potential users to fork, as you note. The alternative of companies not publishing their code publicly at all feels worse.
Well, I've been writing code since before we got reference queues, so it was sometimes reasonable.
I like to spell your `orElse` as `&lt;|&gt;`. More concise, just as clear IMO. And anyway, `orElse` is a bit jarring because it is commonly used for something else, in the [stm](http://hackage.haskell.org/package/stm) library.
[removed]
It should be an option, and not the default. Most people are not focused on system-level software (although I do highly appreciate your work). For anything other than system-level, statically linked plus [upx](https://upx.github.io/) gives executable sizes that are very reasonable.
But `(&lt;|&gt;)` is even more commonly used for something else, the `(&lt;|&gt;)` from Alternative! Notice that my `orElse` has type `Maybe a -&gt; a -&gt; a`, not `Maybe a -&gt; Maybe a -&gt; Maybe a`, and therefore guarantees that at least one branch succeeds.
Hey cool! That's awesome. Helping people is cool. One quibble. Rather than instance (c || Eq SlowWrapper) where resolve = \_ r -&gt; r Define instance d =&gt; (Ord SlowWrapper || d) where resolve = \_ r -&gt; r Basically, what you're stating with the latter is "`SlowWrapper` doesn't have an `Ord` instance, so `(Ord SlowWrapper || d)` is only valid if `d` is." On its own, like in your code, it doesn't make one difference the way or the other. This keeps `||` predictably left-biased. That means that in `c || d`, it won't even try to evaluate `d` unless `c` is false. Just like in value-level programming how `True || undefined` doesn't throw an error. If someone else had `instance (c || Eq SlowWrapper)` in scope, they might be surprised when `(Show SlowWrapper || Eq SlowWrapper)` used the `Eq` behaviour, even though `SlowWrapper` has an `Eq` instance. Being left biased also helps avoid conflicts - what should GHC do if we specify a constraint `(Ord FastWrapper || Eq ShowWrapper)`? Thanks so much for giving me a chance to explain this more. It lets me know I need to go back and do some rewriting to get my ideas across, and that's feedback I *really* need and appreciate.
Thanks for the summary. It would be even more helpful if we could find the specific posts he's talking about, and discuss how we could have done better in those specific circumstances. Here's what I could find in the recent posts; the intention, of course, is not to point fingers but to collectively learn from our and others' mistakes. The finger tree example is obviously an exaggeration, but might refer to this [comment about dynamorphisms and chromomorphisms](https://www.reddit.com/r/haskell/comments/6i6cc7/fast_hashmap_with_mutable_values/dj3w1pm/) as a response to a self-professed beginner who was asking about a faster hashmap. The word "dynamorphism" links to an article which explains the concept, so I think it's clear that the commenter doesn't expect the beginner to understand those words and is helpfully guiding them towards some new knowledge relevant to their interests. Sadly the linked article is far from beginner-friendly, so if somebody could please write a beginner-friendly introduction to chromomorphisms, we'll do better next time :) The "adamant stylistic opinion" about `f . g $ x` probably refers to this "[mixing . and $ like this is nuts](https://www.reddit.com/r/haskell/comments/6jsxrc/an_introduction_to_brick/djhc8zu/)" comment. While I agree that this is a bit strongly-worded, this wasn't directed to a beginner. On the contrary, this was part of a discussion about helping a blog author to make his code less scary to beginners! So is the lesson here that we should always be thinking of the beginners who will read our comments, even when none of the participants are beginners? I think I understand the source of the problem, but I don't see how it can be resolved: if we limit advanced conversations to private messages so that beginners don't see them, then non-beginners which aren't part of the conversation won't be able to benefit from it. We want to be both beginner-friendly and non-beginner-friendly! I don't know which "completely incorrect technical statements" is being referred to, but I have sure received undeserved upvotes for [incorrect technical statements](https://www.reddit.com/r/haskell/comments/6akuet/type_class_with_two_type_variables_or_probably_im/dhfn9sr/) in the past. Obviously it would be better if none of us ever made mistakes and if, failing that, others caught our mistakes instead of upvoting them. So I guess the lesson here is to do more research to validate whether our technical statements (...and those we upvote?) are correct? I'm guessing that the "rampant derailing of discussions" is [this comment](https://www.reddit.com/r/haskell/comments/6idm2g/how_length_function_produces_this_output/dj6455q/) inviting a beginner to ask a question leading to a predictably-controversial discussion about the Foldable and Traversable instance for tuples. The comment ends with a smiley, so it was clearly intended as a joke, so, easy lesson: if the joke will be understood by other non-beginners but not by the beginner to whom you're telling it, it's probably not funny enough to be worth telling.
&gt; I mean simon can speak for himself, but I think you're misreading his comments in one specific sense. He's talking about what the norms would be once we had some sort of automatic bounds inference of the sort that was being discussed in place. Good point. I should be more clear about what I'm arguing. I think following community norms is good, and keep upper bounds on my packages myself (well, either in source or in the revisions). I'm just pointing out that Swift Nav is breaking a norm we plan to remove soon anyway, which I think puts it in a nicer light than if they were doing something like spamming Hackage.
Well yes, I *did* mean the `&lt;|&gt;` from Alternative. And structure it to match. When you want to guarantee success you either end with `pure` or wrap the choices in a `fromMaybe`. There are a few variations of that style in other posts here. But I see now what you mean, `flip fromMaybe` is an interesting infix combinator for when you want to guarantee success.
Agreed, it's funny because overloaded literals are one of the places where type ambiguity issues occur most! Type application should really work on all literals.
&gt; Haskell has the power to provide remarkably strong correctness guarantees with a surprisingly small amount of effort by using a combination of tests and types, using each to accommodate for the other‚Äôs weaknesses and playing to each technique‚Äôs strengths. üíØ
There is a [ticket for this](https://ghc.haskell.org/trac/ghc/ticket/11409), there are other examples where it fails like [labels](https://ghc.haskell.org/trac/ghc/ticket/11352) and the [empty list](https://ghc.haskell.org/trac/ghc/ticket/13680)
I agree that this reddit is not good for beginners. neither is any other place. I see a lot of attention seeking not related with technical worthiness or didactic value because Haskell has become a way of life for many people who otherwise would not find meaning for his life. The beginner friendly community for me is a place where haskell could be treated not like the Philosopher's stone that catapult you to the penthouse of the Ivory Tower, but as a programming language without fear of being lectured on category theory and where doing IO is not a sin. Just a programming language, like Python or Javascript.
Is [snowdrift.coop](https://wiki.snowdrift.coop/) currently accepting and needing some development? If so, I might be interested in sponsoring some work their direction. I'd love for snowdrift.coop to really be active. I already contribute to stuff on Patreon, and "kick-start" some open source projects, but I think the snowdrift.coop approach is a much better model in many cases. But, I'm hardly ever in a position to contribute time to snowdrift.coop.
This subreddit (and freenode#haskell) are the only reason I was able to get really into Haskell, when I was new. AFAICT, most posts are better for newcomers (once you've been here awhile, there's much less new ;) ) 
Would be nice to know why. Never was a fan of implicit arguments 
Stack is all you need! And if you want the full experience, you should try the new experimental Linux distribution called **StackOS**. Its core system consists of Stack embedded directly into the Linux kernel. Best of all, you don't even need Systemd anymore!
This looks really interesting, but I'm wondering how it differs from [HaLVM](https://github.com/GaloisInc/HaLVM). Edit : It looks like Haskus runs on the Linux kernel where as HaLVM runs on the Xen hypervisor.
There is no such thing as StackOS. Not sure if /u/peggying was just making a bad joke or was trolling.
The news issue is very annoying. I have notifications on because the sub is so good and it's a little dissapointing to find football or carcrash news
Pretty excited to attend this, glad Haskell.sg is back :)
BTW- the actual notion of a coproduct is actually an admissable concept in the poset of constraints and its a somewhat weaker condition than this. (c + d) would be the glb of the two constraints. if c :- r and d :- r, then (c + d) :- r with the appropriate universal property to be a coproduct. Notice this is using :-, not =&gt;, so this proper coproduct actually doesn't let you distinguish the path you took, and isn't useful for this usecase, but e.g. you could still use to show stuff like (Monad f + Traversable f) :- Functor f, even if constructing the morphisms x :- (x + y) and y :- (x + y) require unsafeCoerce or reflection shenanigans or extending the language.
sadly those seem to be snoyman's favorite kind!
The fact that he seems to think that it's a **problem** is very telling. I'm glad that this sub doesn't cater to people who aren't proficient in haskell. I probably wouldn't get as much out of it if it were snoyman-approved ü§¢
You don't even need Hydra *per se*. A Nix cache is ultimately just a file server, so you can have your existing CI system push binaries to some web host. At work we use Jenkins and Artifactory for this‚Äîvery enterprisy!
That town increasingly intrigues me (:
Cool! Definitely nice to remove the `IO` from all those functions and makes the overall flow a little cleaner. However it does seem a little odd to enforce the existence of that infinite list in the `Game` record without help from the type system... but, it's a just a toy program anyway and I do like the idea. [commit ref](https://github.com/samtay/snake/commit/eafdc2332fcb18c4d12d2f7aad29bb49d0e0cdd3)
And to me this seems like another bad community comment. &gt; "Don't send beginners here" is, either way, an overreaction - beginners are beginners, but they're not toddlers, and assuming basic levels of reading comprehension and some social skills is not outrageous. Someone is providing feedback on how they feel things can be improved. He didn't comment: "Don't send beginners to /r/haskell. They assume both basic reading comprehension and some social skills.", and yet that's the straw man you chose to put up and tear down. [This](https://www.reddit.com/r/haskell/comments/6k9rxm/rhaskell_considered_harmful_for_newcomers/djklyde/) was a constructive post on tying to accept feedback and improve. vs. "We're fine how we are, he just doesn't get us".
How do you express this in code?
Still waiting on them, sorry... I will definitely post them to /r/haskell when they're available and also through @ZuriHac on twitter
Now, it's blog post official! As the creator of `test-fixture` and co-author with Alexis, I really like where this is going and hope it surpasses `test-fixture`. `monad-mock` encourages a healthy balance between something free-monad-like for testing and writing mtl style for running code. The use of GADTs solves a major gripe.
Right, but then that leads to all the issues we know and love with long-winded and funnily-formatted import stanzas. Which aren't "issues" as such - just things we love to bikeshed ;)
Interesting. So this is history repeating and his projects were already strongly polarizing the community 5 years ago? If you replace Yesod and Snap with e.g. Stack and Cabal respectively in that article and ignore the web-specific parts it would still fit today's situation.
Yeah, maybe there's still hope he can rekindle that spirit he had 5 years ago.
&gt; He didn't comment: "Don't send beginners to /r/haskell. They assume both basic reading comprehension and some social skills." And I never said he did. I did paraphrase this bit: &gt; Please, if you see someone considering getting more involved with Haskell, send them _somewhere else_. fpchat.com is an option. ...as: "Don't send beginners to /r/haskell." Which, I believe, is a reasonably accurate summary. The "reading comprehension and social skills" part is not part of that summary, this part is about how Snoyman comes across in that twitter thread. I see statements like these: &gt; That's definitely one of the big problems. "How do I lookup a value in a Map?" "You should read this paper on finger trees" &gt; Another is rampant derailing of discussions with **things that scare newcomers away.** &gt; It's not the kind of discussion that **new people need to see,** and the voices there are so adamant that people are sure it's vital to grasp. ...and I can't help but think that this is horribly patronizing, and that's where the "assume basic reading comprehension and social skills" comes from. It's not a strawman, you just misread my comment and took it for a paraphrase. Anyway, I believe that: 1. For better or worse, this is reddit, not stackoverflow, and those who come to /r/haskell for help should be expected to know, or learn, how the medium works. In other words, don't blame reddit for being reddit, or /r/haskell for being a subreddit, and don't assume that beginners lack the social and intellectual skills needed to deal with the idiosyncrasies of the platform. 2. I strongly disagree with the notion that withholding information from learners is a good idea. Structuring information is one thing, but I don't agree that there is anything wrong with providing lots and lots of additional information, and assuming that the reader can tell the difference between "vital information you need to understand right now" and "additional information that could either help you understand, or confuse you, or just give you more food for thought, or might just be provided for future reference or further study". Finally: &gt; "We're fine how we are, he just doesn't get us". That's not the point I meant to get across. Rather, "We're mostly fine how we are, there is always room for improvement, but overall, /r/haskell and the Haskell community as a whole are insanely helpful, Snoyman's criticisms are harshly exaggerated and ripped out of context, and going on a rant like this demanding beginners be kept away for their own sake does more harm than good".
 (MonadReader e m, HasBarEnv e) =&gt; m Int Why not MonadBarReader m =&gt; m Int ? The `e` type variable looks completely useless here. Also, ~~Carthago delenda est~~ just pass `Bar` as an argument :)
There are always links to nice posts I missed during the week. Outstanding work!
Defining both in the class makes it so you can't use reflectiony tricks to generate these magically in more general situations.
I'm really surprised to hear this! Are network sockets and file descriptors really more scarce than memory?
I think it's a bit sad you got downvoted so harshly. Although I generally disagree with your tone here your underlying values could be beneficial for our community.
Oh how can anyone not love /r/haskell after comments like this?!
Yes, very sad that this would be downvoted and intolerance of dissenting opinions is a much bigger problem with this subreddit than anything that appeared in the tweet, in my opinion.
I can't help but conclude that the infights in the Haskell world are so vicious because the stakes are so low. And that's really sad.
Can you say what suggested a disguised threat of "or else" in those GitHub discussions?
I think there is a Stream datatype somewhere which is like a List but without the empty case. So in other words, it's an infinite list. :)
Have seen Luna about a year ago - still in the same pre-alpha state... What have changed?
I'd strongly assume that a good portion of downvoting targets the non-constructive nature of that tweet (and the blatant promotion of some other platform) rather than the "dissenting opinion".
Thanks. I think that someone has to do the job
So what? This is Object Oriented Programming rediscovered for the Nth time. OOP was invented just for GUIs with events. What needs to be discovered is the FP way
Yes! Good call. [Done](https://github.com/samtay/snake/commit/6ee19c4b4b800c95f86b6c574ca0e78c6c6f2370). Love this subreddit.
Much more. You typically only get 1024 per process.
But they haven't downvoted the tweet. They've downvoted discussion of the tweet, which is something else entirely.
Well you can increase it, but we're usually talking maxes of 16K (at the *very* most, I think the most I've actually seen is 2048 in practice). There *are* costs to these things.
Interesting. I wonder why this is. Off the top of my head I can't think of a reason to have it any less than a 32-bit int!
Currently it only has instances for tuples, I guess you could write an instance for Generics‚Ä¶
Bug fixed! Now it's actually a little *too* picky (treating pattern matches on newtype constructors as strict). Hopefully that'll get ironed out. Also, there's still some weirdness around existentials that I suspect can be fixed by a minor adjustment, but I could be wrong about that.
An Accidental Blook ? Is that a typo?
I think it's intentional: 'blog' + 'book'
monad-mock isn‚Äôt really a testing framework, it‚Äôs just a tool for running monadic code in a pure way. It‚Äôs designed to be used with existing testing frameworks, so you can use it with hunit, hspec, quickcheck, or anything else that provides basic test assertions.
The [paper](http://www.cse.unsw.edu.au/~chak/papers/spritekit.pdf) accompanying the talk is also really interesting. I'm glad experts like Chakravarty and Keller are looking into these issues. Here are some random thoughts I had from reading the paper: 1. The way state is modeled on the Haskell side has to be kept lock step with the state of the Objective C universe which means it has to emulate its quirks as well. At least in my case this was pretty hairy because sometimes the underlying C++ setters/getters would do more than just set and get that one property when called. This approach requires you to read the underlying source pretty carefully which also means binding to upgrades becomes way more annoying. In the end I gave up on it for these reasons. 2. Subclasses as sum types means that users can't re-use a third party SpriteKit or write a custom one without tacking onto the end of that `Node` data type (Fig. 5) and re-compiling. 3. The part of the API where it "repeats all the fields of the Node constructor" (Fig. 5) gets really cumbersome in practice because you're writing Hungarian-notation Haskell. Also you can't write any polymorphic code over nodes that, for example, have a `position` property. I initially took the same approach too and it has upsides (vastly faster compile times, compatibility to older versions of GHC, and type signatures that actully help) but after writing a few hundred lines of demo code I couldn't stand my own API so I went a different direction. Gtk2Hs also solves this now using OverloadedLabels. 4. Use of `reallyUnsafePtrEquality` to determine if a scene graph has changed without forcing the thunk is really freaking cool! 
Is the original markdown available for this? I'd like to make an EPUB.
I think /u/pigworker made it from their SO answers, so you might be able to scrape that. 
I wrote a blog post about [generating mazes in Haskell](http://jelv.is/blog/Generating-Mazes-with-Inductive-Graphs) a while back. It's probably not *exactly* what you're looking for‚Äîit's more a tutorial on working with graphs and randomness in Haskell‚Äîbut it could be a great starting point for doing more complex things with mazes.
Reddit conflates the two. It's another quirk of the platform. I suspect that if somebody put up a self post with a discussion about the criticisms it would not get downvoted like that‚Äîat least if the tone of the post wasn't too acrimonious.
It's (at least partly) because various POSIX APIs require passing and traversing arrays of size MAX_FDs as parameters, notably select(). Others are linear in the "number of FDs you are interested in" -- which obviously may rise precipitously the larger MAX_FDs is. Basically: Blame bad/legacy APIs, but there's no realistic way of changing it at this point.
This is great, thanks. Way over my head in many cases, but it contains insights very difficult to get otherwise.
love the metaphor of thinking of gaps in knowledge as unevaluated thunks
Hi Michael, I do [mention in the documentation of bracket](http://hackage.haskell.org/package/lifted-base-0.2.3.11/docs/Control-Exception-Lifted.html#g:9) that you should use `liftBaseOp (bracket acquire release)` if your `acquire` and `release` computations are in `IO`. 
&gt; this comment about dynamorphisms and chromomorphisms as a response to a self-professed beginner who was asking about a faster hashmap. The question was about implementing a particular dynamic programming algorithm (it was in the question, if not the title). Asking for a faster mutable hashmap was an example of an X-Y problem. Now, sometimes ST or IO is faster, but a dynamorphism should have been attempted, and as far as I can tell wasn't. Also, dynamorphism is a good thing to learn; it's a tool that is in too few persons' toolboxes. At least, that's my defense and I'm sticking to it.
mcbride? never a typo, always some pun (or portmanteau).
I find the bashing of "academia" (or, in the above post, "Ivory Tower") in response to questions of beginner accessibility rather distasteful. Academia is a place where difficult problems are worked on and, at the same time, where beginners are taught; but it is also a place where the value of pedagogy and adapting one's discourse to your audience are well-understood and practiced. I don't think it is correct to assume that bad or overly-complex explanations are caused by academia. This is especially doubtful in the Haskell community that realized the *positive* success of getting *non-academic* people interested in difficult, advanced, technical topics. One of the major producers or advanced technical content around, Edward Kmett, is not an academic -- and that's great! If someone talked of industry people (or the free software community) in terms half as simplistic as the way academia is described in this thread, people would (rightfully) ask to avoid condescending comments and to make an effort to better *understand* the value of individuals and groups on the other side. We should not let "academia" become a cliched insult like "Ivory Tower". There is enough science-bashing in the world already.
I, for one, welcome our new overlords.
Yikes, sorry for the radio silence on the packaging question! I've just gone ahead and commented on the PR: https://github.com/swift-nav/libsbp/pull/422. (Thanks to those who brought up their concerns.)
I retract all of the terrible things I said about each of you. :-) Actually, thanks for your service!
I wouldn't read too much into this single comment by /u/metafunctor. If you read what he/she writes over a long period of time you can notice that it's rather unpleasant trolling with the nontheless laudable aim of improving the practical impact of Haskell (not diminishing the impact of academia or anything else).
Do you mean because Haskell is currently little used in industry people will fight over the smallest thing?
In fact my comment was more relevant to other mentions of "academic" and "academia" in this thread, but I felt this particular comment thread was more appropriate as it was already meta- and you mentioned toned issues. But yeah. (I don't personally believe that being unpleasant is effective in improving things. I didn't find the first message in the thread particularly unpleasant either.)
Why?
Ban me Edit: Coward
Rewrite rules are actually the coolest feature in GHC. In other languages I constantly find myself wanting them in order to resolve the tension between providing a good API and good performance.
same. I read this daily when learning Haskell.
my field names are almost always mangled (prefixed with an underscore for lens and/or the type for disambiguation), and I almost never use them as functions, so bindings aren't being overwritten. otherwise yes, shadowing is dangerous, even with static names and types, and should be minimized/eliminated. 
I guess this is a bit more convenient than https://stackoverflow.com/search?q=user%3A828361+%5Bhaskell%5D+is%3Aanswer
&gt; We're in the process of upstreaming the toolchain improvements we made to make this possible into GHC, nixpkgs, and reflex-platform (all BSD-licensed) so that they can be used easily by everyone in the community (and become an official part of Haskell). We're also providing financial support for /u/angerman's work on making Template Haskell available on that toolchain, which will close the last serious gap in usability of the cross-compilation support. serious gratitude for this
Why was /u/hvr_ blocked from the organization?
That doesn't excuse them blocking /u/hvr_ completely from the organization.
I would avoid strings. For an application, I generally consolidate things into a single error type containing structured error information, like: data Error = ThingNotFound ThingName | MismatchedThings Thing Thing | Context Doc Error | ‚Ä¶ Plus instances of `Pretty` or `ToJSON` or whatever for different output formats. This has the advantage that it‚Äôs easy to give codes or names to each error so they‚Äôre more searchable and less sensitive to wording. For a library, I make one error type per ‚Äúmodule‚Äù (in the sense of a subsystem, not a literal Haskell module) or distinct thing that can fail. I generally don‚Äôt use exceptions, but these sorts of types are also the ones you might give `Exception` instances to. You can also wrap the `Either e` in a `newtype` for your application and derive the `Functor`, `Applicative`, `Monad`, etc. instances with `GeneralizedNewtypeDeriving` so that your code is less sensitive to changes in how you handle errors, maintain state, etc.
I just tried it with evince 3.22.1 and it worked fine on Debian sid. It's probably a font issue. Try it with zathura (a pdf viewer with a vi slant), which uses a different rendering engine. If it's the same it's almost certainly a font issue. I just ran `strace` on zathura and it's using `/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf` and `/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf` which are both part of the `fonts-dejavu-core` package. But if you're not using a Debian based distro it may well be a different package name. Interestingly I also ran evince with `strace` and it's only using `/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf`. 
You can also use [classy prisms](https://gist.github.com/nkpart/c3bcb48c97c5ded6e277) with that approach, so you can constrain your error-producing functions to only deal with the relevant subset of your overall error type. 
If you're going to use the same error type everywhere, you might as well just throw exceptions. The point is to constrain what might go wrong as much as you can locally.
I am running evince 3.24.0 on latest Ubuntu. Zathura displays it okay and both programs seem to use the same fonts: Edit: Nevermind, I cleared the font cache and it works.
Welcome
If you do, could you post it here?
Classy prisms are really nice
Ban everyone.
Welcome!
Yes, exactly. There's an argument now on Twitter because someone dared to criticise a company that posted a Haskell job. Can you imagine that in the Java world? Any criticism of a specific company would have been drowned out by the thousands of job adverts.
Thanks, that's been very informative! Is there any chance binary-serialise-cbor may catch up to Store's performance? Conversely, is there any chance Store may be able to catch up to binary-serialise-cbor's more compact on-disk format? (I'd like to remind everyone to please don't engage in PVP sniping like last time or any other form of manifestation of the ongoing well-typed vs FPComplete in-fighting. Thanks)
Author of the post here. This is something I wrote up when I read and understood the Data.Modular package authored by Tikhon Jelvis and thought of sharing with wider world. Corrections, omissions etc, welcome!
I'm a bit puzzled because it seems that one of the new moderators has never posted on /r/haskell. Did I make a mistake?
By the way, does this help? https://github.com/tomjaguarpaw/haskell-opaleye/blob/master/Doc/Tutorial/DefaultExplanation.lhs 
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [tomjaguarpaw/haskell-opaleye/.../**DefaultExplanation.lhs** (master ‚Üí 14094b8)](https://github.com/tomjaguarpaw/haskell-opaleye/blob/14094b8595a215070ea3cc1b289b69af89543271/Doc/Tutorial/DefaultExplanation.lhs) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply djn3vq1.)^.
Oh, that is an awesome idea. So classy prisms vs classy lenses is basically the difference between foo :: (HasNetworkConfig r, MonadReader r m) =&gt; m a foo = do netConfig &lt;- view networkConfig And foo :: (CanBeParsingError e, MonadError e m) =&gt; m a foo = do throwError (_ParsingError # myParsingError) ? That seems like a really clean alternative to Control.Exception.Safe for non-IO code.
That's right. The class would be called `AsParsingError`, and if you import `Control.Monad.Error.Lens` you can do throwing _ParsingError myParsingError to throw the error.
Is that bad? I don't see, why being a (frequent) poster is required to be a good mod.
Nice post! I did the same [in PureScript](https://github.com/hdgarrood/purescript-modular-arithmetic) not too long ago. One suggestion: &gt; For example, we want to take any integer i and interpret it as a number i `mod` n, i.e. as a member of the set ‚Ñ§/n. I think the set you mean is normally written ‚Ñ§/n‚Ñ§; I don't think I've seen anyone use the notation ‚Ñ§/n before, but if I did see it, I would guess it meant the set { x / n | x ‚àà ‚Ñ§ }. Also, typo: So, we create a Num instance for *out* Mod type. Should that be *our*?
I just got very confused because I knew about Control.Exception.Lens.throwing :: AReview SomeException b -&gt; b -&gt; r But not Control.Monad.Error.Lens.throwing :: MonadError e m =&gt; AReview e t -&gt; t -&gt; m x Especially because I filed the Control.Exception one under *do not use* since it throws impure exceptions. Having both of those under the same name seems like a very lens thing to do. The MonadError one seems super useful, though. Thanks!
Look through Haskell libraries, see how much discussion has happened in recent GitHub pull requests. Start contributing to ones with lots of discussion, even if you aren't very interested in the library. What you want most are experienced developers, available to mentor you. Go to the ghc irc channel, ask them for beginner projects. I would forget about the $300 stipend, it will narrow your options and delay you from contributing, leaning sooner. Maybe create a Patreon account and explain your goals and create a second post here and some people might contribute there.
I know it is annoying to suggest this, but it has gotten to the point where I would contribute to a Patreon or Kickstarter page to see Snowdrift get more development effort. It would only be temporary for bootstrap phase.
Funny, the exception / error handling code is one of the few places in the lens api that actually duplicates names. The only other places I can think of are some identical naming between the explicit strict or lazy text optics, and similar duplication in strict vs. lazy bytestrings for those who want to get away without the classes. The Control.Exception.Lens and Control.Monad.Exception.Lens code (and I think one other variant) are not exported from the core Control.Lens API because of similar strong feelings on the part of others in the lens community in all directions. That and exporting them with random name manglings wouldn't fit the rest of the API. 
[It's on github now](https://github.com/pigworker/so-pigworker) ;)
Could someone describe in short how _Kythe_ differs from _Language Server Protocol_? I understand that things are different. But amount of text, complexity and new information hard to comprehend at the beginning...
Others have covered why to not use strings... but why would you *ever* use ByteString for "descriptions" of anything? ByteString is for binary data
I don't post super often either, I'm primarily a lurker. All mods are subject to removal in the event of abuse, so I'm not super worried. My primary concerns were timezone availability and ensuring that their post-histories didn't include like... nazi shit. 
Sorry, I only meant not at all optimized for newcomers but overall sensible and great for experienced users. By and large I really like the lens api's.
Here I don't know how I could do much better. I could clutter the world with duplicated names or I could provide less functionality.
Further insight to the topic: * [Compiling to categories](http://conal.net/papers/compiling-to-categories/) * [Haskellcast with John Wiegley](http://www.haskellcast.com/episode/013-john-wiegley-on-categories-and-compilers)
`arithmoi` package uses similar approach to modular arithmetic (https://github.com/cartazio/arithmoi/blob/0ca8b8126cbc208933f1a802d942208fbebfe937/Math/NumberTheory/Moduli/Class.hs). Design notes and comparison with `Data.Modular` may be found at https://github.com/cartazio/arithmoi/pull/56. 
Thank you. You are right, I fixed the post with your suggestions. 
Hey finally your post made past the spam checker. Great 
Thanks.
Aha, yeah, thanks for your help in the IRC :)
[removed]
Well, *this* is a surprise (especially since /u/jfredett hasn't personally told me yet :-p). I have been a constant lurker and occasional poster on /r/haskell for several years now, and have been using Haskell professionally and in leisure for close to half a decade. I hope I was selected for better reasons than just the fact that I live in UTC+0200 ;-) I'm glad that I finally have the power to summarily delete posts about [James Haskell the rugby player] (https://en.m.wikipedia.org/wiki/James_Haskell) when I see them at odd hours, when the Americans are still fast asleep. 
[removed]
[removed]
I was going to send out personal mails, but I, like a good Haskeller, am quite lazy. :D 
A quick scan of the article, and it looks interesting. However, we probably encode a lot more information at the type level to provide more *type-safety* and *correctness-by-construction* guarantees. More so we can even encode intermediate states (nee scores) into the model. When I get some more time, I shall try to remember and play around with the model and see what we can do to add in more type-level guarantees. 
I just had a brief scan of the code, and I'm by no means a pro, but is there a reason why your functions to manage recipes (like `add`, `view`, `list`, and so on) are of type `[String] -&gt; IO ()`, given that they all ignore the `[String]` argument? Would it not make sense to either separate the management of the recipes from the IO (so have a type for a collection of recipes, and have the outermost layer worry about marshalling that to and from disk), or to make the functions just of type `IO ()`? (I think that the former - having a pure database like internal API - is nicer). EDIT: I see `remove` uses that argument - this makes a bit more sense now. Still, it would be reasonable to split the IO out of those functions, as well as not making all these operations the same type. Instead of using a lookup function like `dispatch`, you could just have a larger `case` block.
Thanks jfredett and new mods! This should help improve our signal to noise ratio.
I used to follow /u/taylorfausak on Twitter but stopped because he was part of the annoying anti-/r/haskell, anti-cabal, anti-hackage, anti-haskell.org crowd... Honestly being a moderator of this subreddit is not a very influential or important role in this small community, but /u/taylorfausak is the not the right person for the job. Downvote me if you disagree. I'm not a troll.
Mods are allowed to have opinions. They can still do their jobs just fine even with strong personal views on unnecessarily-delicate issues. 
Assuming you have evidence that he is "anti-/r/haskell" and are not merely extrapolating for rhetorical effect, comparing Scientific consensus with the social contract on this subreddit is disingenuous. And unlike the subjective truth of anthropogenic climate change, how things work here and how people feel about certain things is forever in flux, and ultimately a social construct. And no, this won't become one of *those* threads...
Hmm.. Some sound insight! I do like the idea of removing the IO aspect of the functions to keep them more "pure." You're right in that usually it ends up being a function that produces a `String` that then just gets applied to `putStrLn`. I'll definitely play around with this, thank you!
I think they all use the Model-view-controller pattern in some way, which is often the least painful way to build UIs :) 
One way to improve this would be to use a specific data type for options and optparse-applicative. Then the dispatch function and the [String] -&gt; IO () won't be necessary. It would probably also be better to use a specific format for serialization instead of Show and Read. I know Read has been recommended against. There is aeson and yaml to take care of that, and they aren't difficult to use. Comments or separate files would be nice to delineate what code handles command line arguments, serialization, pretty printing and logic. Nice job for your first project.
There is no firm plan as yet, but it's highly unlikely that it will involve removing **all** version bounds from cabal files. The search space is too large for automated tooling to infer dependencies in the absence of any hints at all. Lower bounds are sensible and everyone should be using them, but speculative upper bounds will likely become unnecessary.
All moderators will be kept under scrutiny by me for as long as I'm around to scrutinize (well, all the mods I've appointed anyway, which I think is most of the remaining ones, /u/dons is the only one w/ higher power than me). If they go astray, they will be corrected, the job here is not to take a position, it's just to do the janitorial work and keep the yelling to a minimum. I appreciate the concern, and please be assured that I'll keep the same even keel I always do. For the record, I use cabal and stack interchangably, I like haskell.org well enough I suppose, and I am quite pro-/r/haskell. I think you all are just lovely people, really.
What can you do with it? I guess kythe is a data format for a graph of tokenized source code, but I can't find tools that people have written to make use of it.
From what I've seen, Z/n, Z/nZ, and Z_n (subscript here) all seem to be acceptable ways to write the ring of integers modulo n.
[removed]
Can I ask where you've seen Z/n? I just thought it was a bit odd because in the notation I've come across, if R is a ring, then R/I only makes sense if I is an ideal of R.
I think it's mostly out of laziness. In both my algebra and number theory courses my professors used Z/n over Z/nZ.
Ah ok, good to know, thanks!
Thank you! I've actually been solving Project Euler problems with Haskell for a little while now, but this is my first foray into a Haskell program that is larger than just a few lists and functions :)
For a trivial example, here's some code I have which converts a stream of floats to little-endian 16 bit ints, or vice versa. This one actually translates pretty easily to lists, since I can use `foldMap` for the encoding, and something like `[f l h | [l, h] &lt;- chunksOf 2 input]` for the decoding, with the `chunksOf` function from Data.List.Split. However, when dealing with larger chunks where pattern matching isn't feasible, it seems that I either have to use `length`, resulting in an extra pass over the chunk, or use a fold that tracks the current index, whereas with `Plan` from `machines` I can simply do `replicateM &lt;size&gt; await`. Writing it out now though, it occurs to me that this may very well also result in multiple passes over the data, since it has to construct the list in full to know for sure if it can return any part of the list. I hadn't considered that earlier. Maybe it'd be better to just collect data into vectors when I need to deal with chunks of data at a time, and then concatenate the results back into a list, that way at least the length check doesn't take an extra pass? I can't just keep the data stored as chunks the entire time, since different functions need different sized chunks to work on. import Data.Bits import Data.Int import Data.Machine import Data.Word clip :: Float -&gt; Float clip sample = min 1 (max (-1) sample) toInt16 :: Float -&gt; Int16 toInt16 sample = if sample &lt; 0 then floor (32768 * clip sample) else floor (32767 * clip sample) fromInt16 :: Int16 -&gt; Float fromInt16 sample = if sample &lt; 0 then fromIntegral sample / 32768 else fromIntegral sample / 32767 pcms16leEncode :: Process Float Word8 pcms16leEncode = repeatedly $ do input &lt;- await let sample = toInt16 input lo = fromIntegral sample hi = fromIntegral (shiftR sample 8) yield lo yield hi pcms16leDecode :: Process Word8 Float pcms16leDecode = repeatedly $ do l &lt;- await h &lt;- await let lo = fromIntegral l hi = shiftL (fromIntegral h) 8 sample = lo .|. hi yield (fromInt16 sample) 
This talk blew my mind. Highly recommended. The TL;DW: Conal wrote a compiler plugin to desugar haskell into applications of primitive operators, and if you do this over a closed cartesian category you can even get rid of things that you'd expect to be fixed syntax, like lambda abstraction. Then your new interpretations for the same programs are just new instances of `Category` etc, instead of having to rummage around in GHC's guts yourself.
Posting at least once would have been nice!
That's an extremely unfair analogy. Especially given that, in my opinion, haskell.org encourages tooling and developmental platforms that are actively harmful for people new to the language (i.e. Haskell Platform). Taylor has been one of the most encouraging and open advocates for mainstream adoption of Haskell as a practical software development language, and he hasn't shied away from criticizing things that impede its progress on that front. It's because of people like him that I was able to not only learn this wonderful language but advocate for its use in professional settings with confidence. I'd greatly appreciate it if this community could avoid personally attacking him, and others like him who, who just want to help Haskell succeed. EDIT: /u/HaskellHell has since deleted the original comment, so I'm including a link to the recovered text for context: https://i.imgur.com/jCVMUHu.png 
That was really interesting! I'm not sure if I got all of it, but it seemed that the main idea that allowed it to work is replacing the expressions of lambda calculus with point-free composition of functions. I've just started learning about combinatory logic, and it seems very similar. Is there any relation between these two approaches?
The best I can think of is Shed Skin. It has some insane performance, but you have to give up some python features (as expected).
That's certainly useful, but in my experience almost no one sees it. Most everyone just grabs `lifted-base` and uses its `bracket`, and of that group, most don't even read _that_ documentation. I'm not completely convinced that the type signature in lifted-base should actually change, but I think it's the only way people will notice that there's a state discard going on here.
No no, keep your name. You show great potential. ^Most ^likely ^just ^coincidence, ^though
Wow, this reply is amazing, I can immediately see how in this case it's just a matter of thinking about the units involved in the problem and how to transform them in various ways. I guess this is what folks mean when they say "work from the types to the implementation". Thank you so much! I'm going to spend some time on it this evening, do you mind if I come back with questions?
Wow, that is an excellent post. You're right that it wasn't *exactly* what I was looking for, but that's only because what I was looking for wasn't exactly what I wanted -- this is even better! I love that graphs are related to mazes... never thought about them that way. Thanks for sharing this awesome resource!
Also Simon Meier. It's just a nominal form of the [birthday paradox](https://en.wikipedia.org/wiki/Birthday_problem).
The typeful restatement of the birthday paradox: the Simon paradox... :P
&lt;3 this is so great, thank you!
The Oleg surplus is more surprising to me.
Its short for Simonoid Simonads are just Simonoids in the category of endofunctors
Agreed. These would be an easy contribution to make to the [GitHub repo](https://github.com/pigworker/so-pigworker) that was shared earlier in the comments... Maybe I'll spend some time on that soon.
I know of Oleg Kiselyov and Oleg Grenrus. Are there other Olegs of note?
Simonads are just Simonoids in the category of olegunctors with banalenses.
Have you thought about using stack? As your project grows, it might be a good idea to add src and app directories to organise your code too. I would also consider using Text instead of String.
Two seemed unusual.
Sure, no problem.
A few items you could add to `Contributing.md`: * Your thoughts about using libraries which aren't included in the Haskell Platform (required by some of your future plans, but something you might not want contributors to go overboard with) * Your thoughts on GHC extensions (none of the future plans absolutely require any, but some of them would be very useful for some the future plans) * Some people prefer `import qualified Data.Map as Map`, and others prefer `import qualified Data.Map as M`. Since your source doesn't yet use any qualified imports: you could mention which style you prefer.
It's a fairly common Russian name.
Don't use strings or anything string-like. *Always* use an error data type. The main problem with strings is that client code can be written that does say pattern matching on the error strings or parts thereof. The when you change the error string, that code *sliently* fails. If on the other hand you change an error type, client code will either generating a warning (eg if you add a new error constructor) or fail to compile (you added or removed fields from an error constructor). 
&gt; you might as well just throw exceptions. Oh please, no!
Also Simon Michael. Simon Ms are strong with us.
It's actually a title, awarded for contributions to functional programming. Simon Peyton Jones was just Peyton Jones until Haskell happened.
[Check with Conor first](https://twitter.com/pigworker/status/880922886973906945), I'm not sure he'll accept such a PR.
Congratulations all. I do however notice that none of the moderators are in a Asian time zone. I'm in a UTC +10 time zone and I did apply.
No
Well then I think we should be asking where all the Garfunkels are. Maybe the Scala community has them.
I've revised the introduction and motivation sections following your feedback, removing the lengthy API discussion/comparison. Hope you like the new version: https://github.com/snowleopard/alga-paper Thank you! The paper will be presented at Haskell Symposium. 
Another thing: since your project is mainly a learning exercise for beginners you probably don't want actual code from someone who's already writing a compiler in Haskell, but if someone does the code for the "Translate into languages other than English" goal I'd be able and more than happy to translate all your strings into Mandarin.
Great talk. Easy to follow.
Not a response, but this might be useful : State of the Haskell ecosystem [https://github.com/Gabriel439/post-rfc/blob/master/sotu.md#front-end-web-programming]
[removed]
Heck, we've got multiple Bartosz's now, too.
Seems like a legit post to me. I have approved it. :-)
So to be clear, this video is about re-implementing a traditional Unix shell in a functional language (Haskell), not creating a new shell which has functional characteristics (i.e., something like a souped up GHCi)?
tl;dr if you have a `Monad` you can derive `Applicative`, `Functor` and in turn derive `Num`, `Floating`, `Fractional`, `Semigroup`, `Monoid`. data V3 a = V3 a a a deriving Functor deriving via WrappedMonad Applicative deriving via WrappedApplicative (Num, Floating, Fractional, Semigroup, Monoid) instance Monad V3 .. with safe coercions, among other things.
First, the basics. `HUnit` is a library. As with most other programming languages, Haskell has systems in place for managing and automatically downloading and building third-party library dependencies. If you haven't already, you should familiarise yourself with `cabal-install` or `stack`, and create a basic, small project with a test suite. For example, at a bare minimum, you can install [the `stack` software](https://docs.haskellstack.org/en/stable/README/), whip open your favourite terminal emulator, and type this in to get a bare-bones project with an `HSpec` test suite: stack new myawesomeproject Next, you need to figure out how to use `HUnit` instead of `HSpec`. This SO answer should point you in the right direction: [Haskell unit testing](https://stackoverflow.com/questions/20331209/haskell-unit-testing). Note that `cabal-install` the program is not quite the same thing as `cabal` the library. The `stack` program is similar to the `cabal-install` program (which is invoked simply as "`cabal`" on the command line) but uses the `cabal` library to perform its most important functions. So don't get too confused about whether advice from 4 years ago is still true today: either way you have to fiddle with a `.cabal` file to set up your project. Haskell is not as confusing as Node in this respect. Then, to run the tests, run `cabal test` or `stack test` in your terminal depending on your setup -- both should get the job done. This should be enough to figure out a workflow, and know what terms to Google to find further information. :-)
Yeah this talk was pretty mind-blowing to watch, the ability to go from `\x -&gt; x^2+8*x` to a diagram which represents it, and the derivative of the function, to the VHDL circuit, to the combination of all of these so you can have automatically generation of circuits for the derivative of a function and then produce the diagram showing what the circuit would be is just incredible. I really want to see this go somewhere. 
Looks interesting, what sort of help do you need? I've been thinking quite a bit about related problems lately. The recent changes in Swift look quite interesting, I've been curious about things like how well reversing a Text value works when combining characters are present.
Writing idiomatic code is, like in any other language, a matter of experience and exposure. Write a lot of code, read a lot of code, immerse yourself in the community, and you'll develop taste and intuition. An important part of it is switching from imperative thinking ("what happens next") to equational reasoning ("which things are equivalent, what can I substitute"). It takes a while to sink in. On top of that, a bit of more specific advice: - Read all of the Prelude, including source code. - Look through the modules in `base`, and dive into the things that look useful or interesting. - Use `hlint`. Its suggestions are usually pretty fantastic, sometimes unexpected, and they can lead you to a lot of those tiny little functions you would otherwise be tempted to implement yourself, because they are difficult to discover. - Use hoogle's type search feature: often, the function you want already exists, and can be found based on its type alone.
Oleg Grenrus is Finnish.
There's been a lot of finalisation work on the binary-serialise-cbor package (including a split into a few new packages, including `cborg` for dealing with CBOR encoded data and `serialise`, intended as the replacement for `binary` as the default serialisation library for Haskell data which is based on `cborg`). There's a lot to love about CBOR, and this package, not least of which that it's based on a RFC'd standard which is seeing some use in a few domains. One thing I really like is the decoder being run inside ST, so the building of vectors can be really efficient (since unknown length arrays are possible, you can use the standard grow-by-2x O(1) algorithm to do a zero-copy vector generation). CBOR is incredibly elegant and efficient, and some of the decisions made in cobra/serialise mean libraries like safe-copy are not as necessary as they used to be - the idea of adding or changing constructors in a type is well supported by the conventional encoding for Haskell data types. Hopefully there'll be a release some very time soon (I was hoping it would be this Friday but there seems to be a few more issues to sort out).
Currently my work flow is like this: find the APIs missing from bytestring/text/vector, implement they with new design, and benchmark it. If you want to join, you can send patch in unit of one to dozen APIs and i'll review and merge. I also need help with testing, the bytestring/text/vector 's test are quite fragile, i haven't come up with a testing frameworks for this library yet. As for text reversing, it's quite easy, i have [implemented them](https://github.com/winterland1989/stdio/blob/master/Data/Text.hs#L310) already, and it's much faster than old text. I spend quite a lot of time try to optimize the [new utf8 codec](https://github.com/winterland1989/stdio/blob/master/Data/Text/UTF8Codec.hs).
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [winterland1989/stdio/.../**UTF8Codec.hs** (master ‚Üí 7cf9063)](https://github.com/winterland1989/stdio/blob/7cf906385b5038c3f1740916e1a28564547b022a/Data/Text/UTF8Codec.hs) * [winterland1989/stdio/.../**Text.hs#L310** (master ‚Üí 7cf9063)](https://github.com/winterland1989/stdio/blob/7cf906385b5038c3f1740916e1a28564547b022a/Data/Text.hs#L310) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply djojo8x.)^.
In fact, I have dual citizenship
Yeah. I found the idea of putting parser combinators and libraries like [async](http://hackage.haskell.org/package/async) to work in a "mundane utility" quite appealing. I wonder if the code is available somewhere.
When I was a beginner, my main strategy when I needed to build something I *felt* should exist was to build it first (to help with my understanding of it) then post it here and ask for alternatives.
hlint is the best
Don't know but the GHC 8 branch seems to have changed within the last month or so: https://github.com/ghcjs/ghcjs/tree/ghc-8.0?files=1
[removed]
[stackage](https://www.stackage.org/) can be seen as a curated collection of packages/libraries. You might also want to look at the corresponding tool [stack](https://docs.haskellstack.org/).
[Sorry, not sorry.](https://www.youtube.com/watch?v=IDhz_mVcVCQ)
SECTION | CONTENT :--|:-- Title | Simon &amp; Simon theme Description | From Seasons 3 or 4 Length | 0:01:04 **** ^(I am a bot, this is an auto-generated reply | )^[Info](https://www.reddit.com/u/video_descriptionbot) ^| ^[Feedback](https://www.reddit.com/message/compose/?to=video_descriptionbot&amp;subject=Feedback) ^| ^(Reply STOP to opt out permanently)
Hackage is the package database for `cabal`. A user running `cabal install` on a maintained package and having it fail is not acceptable. If more people are going to create packages that only work with `stack`, that is a problem that the Stackage maintainers need to deal with. (Though I see that this particular package is not even available on Stackage)
It's not really a new `Text` if it uses a different encoding, is it? Anyway I suspect the tradeoffs that make `vector` and `Text` slower than this library are quite deliberate, I'd be interested to see what /u/bos thinks.
Testing a text library is tricky. Make sure to test also against major languages such as Chinese where a UTF-8-based text library will take a hit. It's easy to fall into the trap of Western bias. But you are in China, so I am optimistic that you will do a good job.
One aspect differ this new design is that no implict fusion. The motivation is very simple: compact data structures, e.g.arrays. is faster facing sharing, and we share thing a lot in haskell. The whole vector idea is about slicing arrays, so a stream representation simply does not make sense. But i did try hard to make this new library work with build/foldr fusion in base though, e.g. unpack/pack are good producer/comsumer. To make fusion happen, simply write `pack . XXX . YYY . unpack` where `XXX` and `YYY` are function working on list.
Yeah, that's true. The hard part is case-mapping and normalization. Currently i put my hope on [utf8rewind](https://bitbucket.org/knight666/utf8rewind). Since i'm not a fan of FFI. I might choose to borrow code from [unicode-transforms](https://github.com/harendra-kumar/unicode-transforms), and its tests for sure.
Nice. I enjoyed the video.
Ooh, I'd not heard of stack. I'll look into this, thank you! I definitely also planned on figuring out some organization to the code, but having never done this before I figured I would start by just throwing it all into the main file and figuring out which parts could be abstracted to their own modules later down the road. What are the particular advantages of Text over String?
According to How Many of Me.com [1] there are "5,163 different first names in common use" (in the US). They are not equally distributed, but if we do assume that, using the general n(d) form of the birthday problem with d = 5163 we would need only 85 people for the probability of two people having the same first name be larger than 50%. As the names are not equally distributed, the number should be even smaller ... :-) [1]: http://howmanyofme.com/
Guess the cat is out of the bag. Apologies the documentation is a bit sparse at the moment, that's being worked on. Cool examples are here: - [todo-mvc](https://d3u8rq3uy5wnb9.cloudfront.net/) - [mario](https://s3.amazonaws.com/aws-website-mario-5u38b/index.html) - [svg](https://d2dwfl7f3j7of0.cloudfront.net/) ghcjs haddocks: - [link](https://d10z4r8eai3cm9.cloudfront.net/) There was some cross-post on [/r/haskell_jp](https://www.reddit.com/r/haskell_jp/comments/6jylo7/dmjiomiso_a_tasty_haskell_frontend_framework/) which asked a question about "isomorphic javascript" which we could address here. What is *"isomorphic javascript"* or *"universal javascript"*? It's a little more than just sharing templates on both client and server. It's true miso *does* share the same templating language across the server and the client. - When rendered on the server (w/ ghc) it becomes a `lucid` template suitable for delivering to the browser. - When rendered on the client (w/ ghcjs) it becomes a virtual DOM. I think the best way to explain what it is, is to explain what it does. The "isomorphic" part occurs in three phases, The first phase is when the browser receives the pre-rendered template (from server) on initial page load and constructs the DOM - this is great for SEO and fast page load, as the end user will see content immediately. The second phase (when the javascript has loaded in the browser) occurs when the client creates the virtual dom in memory (from the same template as the server - since the template is shared). The final phase (where we connect server and client) occurs by traversing the actual DOM and copying the pointers into the virtual DOM (since our virtual dom holds mutable references -- this gives us a performance advantage during diffing and also allows us to route all events through the virtual dom and call pure haskell functions). This completes the circle. The assumption is that if one uses the same template on both server and client, the DOM and virtual DOM will have the same form, allowing one to copy the pointers safely. There's still quite a bit more to do, but `miso` is already being used. Immediate todo list looks like this: - Allow for advanced optimizations w/ closure-compiling - Finish child reconciliation algorithm (based on [kivi](https://github.com/localvoid/kivi/tree/master/lib)) - Additional tests (uses `phantomjs`) - Getting started documentation Ambitious road-map: - **miso-native**, construct native applications using miso In regards to the name, `miso` was a play on the word `isomorphic`. Although, per /u/igrep, `uni` appears that it could also be a suitable name, and might indeed be more tasty than `miso`. So a name change may or may not be in order :) Shout out to /u/stepcut251, /u/eacameron, /u/luite2, [the reflex team](https://www.reddit.com/r/reflexfrp/), and Boris Letocha of [Bobril](https://github.com/Bobris/Bobril). 
[removed]
Without the monomorphism restriction, you will encounter counter-intuitive performance issues. ### A short story Imagine we have a somewhat expensive computation. &gt; fib 0 = 0 ; fib 1 = 1 ; fib n = fib (n-1) + fib (n-2) It's really expensive! &gt; fib 27 -- Takes a few seconds. 196418 So we decide to cache the result by binding it to a variable. &gt; x = fib 27 -- Bound but not used yet. A thunk. Now we just need to evaluate the thunk once. &gt; x -- Takes a few seconds the first time. 196418 So the next time we use it, we get the evaluated result immediately... But wait, this is not right! &gt; x -- Still takes a few seconds! 196418 ### Troubleshooting Look at the type of `x`. :t x Num t =&gt; t `x` is in fact polymorphic, and can be specialized at any type with a `Num` instance, which contains implementations for `fromInteger` and `(+)` used in `fib`. Under the hood, `x` is actually a function `Num t -&gt; t`. Every time we call `x`, as we do above, we specialize it (GHCi automatically defaults to `Integer`, but in a real program an appropriate type will be inferred from the context), and implicitly pass the `Num Integer` dictionary for `x` to actually perform the `fib 27` computation, from scratch. To avoid repeating that computation, we specialize `fib 27` when the variable is declared: &gt; y = fib 27 :: Integer &gt; y -- Takes a few seconds. 196418 &gt; y -- Instantaneous. As expected. 196418 I hope this little story shows how always picking the most general type can lead to problems: one would expect `x` to be a simple number but it actually ends up being compiled to a function. The monomorphism restriction prevents this counter-intuitive behavior by default. We only generalize polymorphic functions with type class constraints for declarations like `f a = ...` with at least one argument (`a`) on the left of `=`, and otherwise we make a declaration with no argument `x = ...` monomorphic *unless there is an explicit signature*, as the unsuspecting user most commonly expects it to correspond to a thunk which will be evaluated at most once.
`Int^String` is a type, i.e. it's an object of the category. `Hom(String, Int)` is a collection that exists in the metatheory, not inside the category.
Having peered behind the scenes of this project for a long time, there are two comments I'd like to make. 1) The implementation is very solid. The code is clean and dmj spent a lot of time paying attention to performance bottlenecks and memory allocations and ensuring it is not a memory hog. 2) If you like having HTML/XML syntax in your source code, it is easy to use [hsx2hs](http://hackage.haskell.org/package/hsx2hs) with Miso. This glue code is probably a bit out of date, but should be easy enough to update: http://lpaste.net/356623 `hsx2hs` is just a quasiquoter that provides syntactic sugar. Instead of this: viewInput :: Model -&gt; T.Text -&gt; View Msg viewInput _ task = header_ [ class_ "header" ] [ h1_ [] [ text "todos" ] , input_ [ class_ "new-todo" , placeholder_ "What needs to be done?" , autofocus_ True , prop "value" task , attr "name" "newTodo" , onInput UpdateField , onEnter Add ] [] ] You can write something like this: viewInput :: Model -&gt; T.Text -&gt; View Msg viewInput _ task = [hsx| &lt;header class="header"&gt; &lt;h1&gt;todos&lt;/h1&gt; &lt;input class = "new-todo" placeholder = "What needs to be done?" autofocus = True value = task name = "newTodo" [ onInput UpdateField , onEnter Add ] /&gt; &lt;/header&gt; |] And it will be desugared something similar to the first version.
That's neat. It's defunctionalization (see [this post by Richard Eisenberg](https://typesandkinds.wordpress.com/2013/04/01/defunctionalization-for-the-win/)) where actual type constructors are symbols for themselves. Here's a slight generalization. type family ($) (x :: k) (y :: k1) :: k1 where 'Id $ y = y (x :: k1 -&gt; k1) $ y = x y or even type family ($) (x :: k) (y :: k1) :: k2 where 'Id $ y = y (x :: k1 -&gt; k2) $ y = x y but that one will have trouble reducing `'Id $ y` as it will only do so if the kinds match (`k1 ~ k2`), but that might not be inferrable in general.
This is an exact re-implementation of reactjs inspired frameworks. When using reactjs and other reactjs inspired frameworks I found that modularity and encapsulation are practically impossible to achieve. Every component has actions and data it renders. Unfortunately the MVC model all these frameworks implement forces all components share the same giant structure for their actions and for the data. So every your component will be aware about all actions in your applications (not just the ones relevant to it) and it will have to be aware about a giant data structure that holds the entire state of your app, not just the part of it relevant to this component. Another weak point of reactjs based frameworks is that input does not work out of the box. In order to simply type into the text field or click a checkbox or select something from a dropdown you have to: - Define a keypress Action (in one part of your code) - Define a Hanlder for that action to capture the input (in other part of your code) - And finally wire that dispatcher to the keypress event of the edit box in yet another part of your code. When you have a complex web app with hundreds of data entry elements on your screen spread through many tabs, this gets old really fast. This is why after working with reactjs frameworks both in ghcjs (react-flux) and purescript (thermite) I finally bit the bullet and learned reflex. Now I can make a completely self contained components that I can reuse across any applications. Components that are aware only about their own actions and only about their own data. Components that have normal input working out of the box without me defining any code to capture it. 
`Just`, as a function, does correspond to a natural transformation between the identity functor (which is distinct from `Data.Functor.Identity`) and the `Maybe` functor. The `Functor` type class only represents type constructors which are functors, but there are many other functors mathematically, and the identity functor is a trivial example. There may even be some which you can't represent at all in Haskell. Not every morphism (function) is a natural transformation. Remember that a natural transformation between two functors F, G : D -&gt; C is actually given by a *family of morphisms* indexed by objects a of their common domain D. For every a in D, we have m(a) : F(a) -&gt; G(a) (in the category C). A polymorphic function between two Haskell `Functor`s (the type class), `f : F a -&gt; G a`, is one way to define a function for every type `a`, with the proper commutative diagrams, but it's not the only way.
stm is good. I don't know whether a single `TVar` will be sufficient for your purposes, but if not, one of the points of stm is to allow you to define your own fine grained concurrent data structures to reduce contention.
I'd say it's more of an exact re-implementation of Elm, but has a different virtual dom representation (allowing for isomorphic js) and performs event delegation (as opposed to binding to DOM nodes manually). The way Evan answers the component question is here: https://guide.elm-lang.org/reuse/
Define a toy function to simulate hard work. &gt; fib 0 = 0 ; fib 1 = 1 ; fib n = fib (n-1) + fib (n-2) &gt; fib 27 -- takes a while 196418 Compare your `fix` implementations on &gt; take 3 $ fix (\xs -&gt; fib 27 : xs) [196418,196418,196418] The second one should be faster, as `(\xs -&gt; fib 27 : xs)` is only applied once (with its result as its input `xs`). Memory usage is also an issue. Start up GHCi with `ghci +RTS -M100M` to limit space usage. &gt; xs = fix (\xs -&gt; () : xs) &gt; length (take 100000000 xs) In the first `fix`, as you force evaluation of the list `xs`, a new cons-cell is created for each element (the end of the list is perpetually an applied function, thus an unevaluated thunk), and you easily run out of memory. xs = fix (\xs -&gt; () : xs) = () : fix (\xs -&gt; () : xs) = () : () : fix (\xs -&gt; () : xs) = ... In the second `fix`, the tail of the list `xs` is just a pointer to itself. (And the GC takes care of `take`.) xs = () : xs At a high level, both `fix` have the same denotational semantics, so you will see the same result, but this semantics does not account for time and space usage. In order to keep control of performance, it's better to compile them differently.
Have you seen http://haskelliseasy.com/ ?
Do you know about the `map` function? Is there a particular reason you have to write a tail recursive version specifically?
I think this turns out to be more trouble than it's worth. /u/edwardkmett probably knows.
Have you seen this? https://wiki.haskell.org/Monomorphism_restriction &gt; Oversimplifying the debate somewhat: Those in favour tend to be those who have written Haskell Implementations and those against tend to be those who have written complex combinator libraries (and hence have hit their collective heads against the restriction all too often). It often boils down to the fact that programmers want to avoid legalese, and language implementors want to avoid cruft. 
Happstack, because roughly five years ago when I started using it it seemed simpler than Snap and Yesod, and I haven't really updated my web app since.
Haskell from first principles (haskellbook.com) is excellent and thorough. Large book though. I haven't looked at this but I've heard good things about the haskell data analysis cookbook: http://haskelldata.com/
This is currently an unimplemented [proposal](https://ghc.haskell.org/trac/ghc/ticket/2893), with the same motivating example as yours. Some previous related discussions here: https://www.reddit.com/r/haskell/comments/68bqo3/why_doesnt_forallf_give_you_the_instance_you_have/ https://www.reddit.com/r/haskell/comments/5sovad/is_there_such_a_thing_as_higherranked_constraints/ https://www.reddit.com/r/haskell/comments/5tod9o/are_there_any_plans_to_allow_functor_bifunctor/ https://www.reddit.com/r/haskell/comments/11y0eb/motivating_explaining_and_improving/ https://www.reddit.com/r/haskell/comments/6465y0/parameterized_monoids/
Sure - then it could just be a fork.
Looks good. Any chance you might want to share efforts with the [foundation](https://github.com/haskell-foundation/foundation) effort? Paging /u/vincenthz...
I recognise /u/aaronchall from Stack Overflow, where he is a mod; he also runs the Haskell chat room over there.
As a very vague starting point, a lot of people like http://haskellbook.com/
As a very vague starting point, a lot of people like http://haskellbook.com/ 
OK, well that's good to know. There's ultimately no reason that moderators shouldn't be distant or disinterested third parties. It might even be a benefit. I was just a bit surprised.
Have you contacted the developers of vector/bytestring/text? They've been working on those libraries for years AFAIK. It would be cool to hear their take on this particular endeavor.
The first reason is that they have different laws, the same for `Alternative`. The second is that we cannot have existentials in constraints. This can be simulated with ForAllF in the `constraints` package.
I agree. I think miso is an excellent implementation of this style of framework, but I do have the same concerns as you about the underlying idea. miso is similar to an framework I implemented named isomaniac. I implemented a WYSIWYG editor using isomaniac and, indeed, ran into all those issues. I tried reflex, and while it does deliver on encapsulation, it seemed very unwieldy in other ways. I'm afraid I don't have a clear criticism of reflex. In my limited experience, it seemed like it made easy things hard, and it jumbled up the application logic with the view logic in a way that made it hard for me to visualize what was going on with the layout. I am chugging away on a less-is-more framework, but it is not yet ready for consumption. The underlying idea is to stop trying to abstract away from the DOM, and instead embrace it. You can create your own custom widgets (in Haskell), and they emit events that you can listen for with `addEventLister`, just like native widgets. That gives you the ability to have normal &lt;input&gt; working out of the box, and you can easily swap in a &lt;custominput&gt; and everything still works. components can be nested as well. It's tempting to build a clean, elegant UI on top of the DOM, but I am not sure it is a good idea. Either you have a nice clean implementation, but you only support a subset of the DOM. Or, part of the implementation is clean, but then you have all sorts of kludges and backdoors that allow you to access the other stuff in a rather ugly way. For something simple, like a TODO app, I think it is easy to create a beautiful looking framework. But if you are trying to re-implement Google Docs, I think you start to run up against the limitations pretty fast. That said -- most people are not implementing Google Docs. So, perhaps something like miso is the right answer for some category of applications. Certainly many people have implemented applications in purescript, react-flux, elm, thermite, reactjs, and other similar frameworks. I think the implementation is solid, and perhaps there are ways to address my concerns that will be developed. One of many things I do like about the miso is that the templating functions are very straight-forward and easy to modify. It seems much more accessible to a non-Haskell web template designer. Especially if you use the `miso-hsx` stuff I pasted in another comment. 
&gt; You can create your own custom widgets (in Haskell), and they emit events that you can listen for with addEventLister, just like native widgets. That's exactly what reflex allows you to do. You are right that with reflex developers often are lost on how to structure their application at large. That often leads to common mistakes. It is the same reason reactjs has developed flux to structuring the application design. Reflex needs something like that. Either as a design pattern (a folklore that teaches how to design apps) or if it is possible to capture the right abstraction in some form of a library or framework like Elm Architecture then maybe that. 
I want this to be a thing
[PureScript](http://purescript.org) has a few [different backends](https://github.com/purescript/documentation/blob/master/ecosystem/Alternate-backends.md), including a couple that are based on Python. They aren't complete as far as I can tell, but it could make for an interesting way to go.
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [purescript/documentation/.../**Alternate-backends.md** (master ‚Üí b7bc681)](https://github.com/purescript/documentation/blob/b7bc681a1ecf45ed76a92769123bb24a196c170a/ecosystem/Alternate-backends.md) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply djouj5c.)^.
I keep thinking that this conference is in Ottawa
Note: `MonadPlus` and `Monoid` aren't necessarily the same for a given data type. Consider `Maybe`. As an aside, being a monoidal monad is a real, but completely different thing, which haskell monads satisfy. Higher rank constraints are an admissable thing our Constraint kind, they just aren't implemented in GHC. If you want to play with them today you can use: http://hackage.haskell.org/package/constraints-0.9.1/docs/Data-Constraint-Forall.html
How did I find it if it was removed?
Luite is still alive and well, he was even funded (as a contractor for doing GHCJS development) last time I spoke to him (Feb). 
Hey, I'm not saying it's a good option, but it's strictly better than the proposal.
 &gt;That said -- most people are not implementing Google Docs. A few years ago, we had to work out a proposal for an online postcard editor that had to support uploading up to twenty large (~25MB) images, WYSIWYG support, and front and back of the card support. Some templates had forbidden areas you couldn't put stuff on. There were a few more minor requirements, but that was the gist of it. If every framework had to implement *that*, I'm pretty sure you could see its true colors pretty fast.
Since `V3` is representable we don't need to define `Monad`, instead we can use the wrapper [`Co`](https://hackage.haskell.org/package/adjunctions-4.3/docs/Data-Functor-Rep.html#t:Co) instance Representable V3 where type Rep V3 = ABC index :: V3 a -&gt; (ABC -&gt; a) index (V3 a b c) = \case A -&gt; a B -&gt; b C -&gt; c tabulate :: (ABC -&gt; a) -&gt; V3 a tabulate f = V3 (f A) (f B) (f C) So from a single instance we get all of these instances (for [technical reasons](https://ghc.haskell.org/trac/ghc/wiki/Roles2) we must write `instance Distributive V3 where distribute = distributeRep` by hand, I haven't implemented support for `MonadReader ABC` yet) data V3 ... deriving via Co (Monad, Applicative, Distributive, Apply, Bind, MonadReader ABC) deriving via WrappedApplicative (Num, Floating, Fractional, Semigroup, Monoid) lots of fun stuff
I thought it would be fun to show people the (slow) progress I've been having :) 
[removed]
yea it does look pretty sweet.
I actually think we should have a Haskell Libraries Hackathon at the [Haskell Library](http://haskellopera.com/).
I've heard nothing but bad things about haskell data analysis (and most things from pakt publishing), as much as I wish there was a genuinely good book on data analysis in haskell. haskellbook.com ftw
No man, No one noticed, until now. You are the first! 
I think it's pretty safe to say that GHCJS isn't going to go away any time soon. In the (unlikely, I think) event that the project were to collapse, it would probably be taken up either by upstream (GHC HQ) or downstream (one or more companies relying on it). It's too important now.
Honestly, regular ghci works pretty well that way already. I use it to solve basic shell problems all the time. 
My first thought when seeing the title was: "isomorphic to what?!" After reading the blog post, it's still not very clear to me what it means (maybe I should read it again when less tired). Is there a connection to the mathematical notion of isomorphism?
&gt; Unfortunately the MVC model all these frameworks implement forces all components share the same giant structure for their actions and for the data But people seems to enjoy that kind of giant states. &gt; You are right that with reflex developers often are lost on how to structure their application at large. That often leads to common mistakes. I'm the author of Axiom. I think that Axiom overcome these problems with better composability and a simpler programming model. https://github.com/transient-haskell/axiom But many people ask me how to reproduce the MVC model with axiom, to program like Elm and React even if they loose composability and they have to redraw everything for each event that happens. So some effort is being done to implement a non composable, Elm-like model, with virtual-DOM on top of Axiom. It has been too much exposure to the MVC model during so much time. Perhaps the next generations of programmers would be able to make better use of it 
https://hackage.haskell.org/package/stm-containers
Lack of information on development of GHCJS is very problematic. Seems to be no transparency into development and future plans. Did one project with GHCJS, but most recently doing Purescript because of GHCJS uncertainty. Purescript development is open and active. Actually have official releases, a changelog, and responds to issues. 
At what point, if any, will we be able to do the following: newtype A = A Int deriving (Eq, Ord) toAMap = coerce :: Map Int a -&gt; Map A a In other words, since the Ord instance on A is derived, we know that `compare a b = compare (A a) (A b)`, so we can `coerce`. Currently we have `mapKeysMonotonic A`, and pray that it compiles to a no-op. 
The main reason you need to write a `Distributive` instance by hand is simply that `distribute` and `collect` have defaults defined in terms of each other! You're right that there's a technical reason the coercion approach won't work. It's kind of sad in this case; if the `Distributive` class simply dropped the `distribute` method, it would work just fine. The latest version of `distributive` also offers `genericDistribute` and `genericCollect`. Note that it's generally better to define `collect` than `distribute`; the next version of `adjunctions` will offer `collectRep`, but you can also write it yourself: collectRep :: (Representable f, Functor w) =&gt; (a -&gt; f b) -&gt; w a -&gt; f (w b) collectRep f w = tabulate (\k -&gt; (`index` k) . f &lt;$&gt; w)
Maybe that's true... But it is nice that if you build-deps something that relies on text, you now have text compiled in case you need more low-level control, and text can be shared with new packages. I don't believe it is trivial that this would reduce the total compilation time for larger projects. 
I think this would be great. There is even an issue on the stack but tracker for it: https://github.com/commercialhaskell/stack/issues/117
After a day or so with no downvotes replies nor upvotes I checked how the post looked from a different account - the text said "[deleted]". So I figured that it was "shadow-banned".
I don't think that's too likely. Today, we *could* offer `liftCoercion :: Coercion k1 k2 -&gt; Coercion (Map k1 a) (Map k2 a)`, which would let you use your knowledge of instance compatibility to coerce nicely, but unfortunately doing so cleanly would be *quite annoying*. If `Map` were a newtype, we could write such a function anywhere the newtype constructor is visible. But for *datatypes*, the role annotation applies even within the defining module. So there are two ways to implement it today: 1. Make `Map` a newtype. This is certainly possible, but requires either a. Writing a bunch of boilerplate coerced functions that I don't personally feel like writing. b. Using pattern synonyms to work through the newtype, committing to a still-fresh GHC-only language extension. 2. Use `unsafeCoerce`, exposing a perfectly safe interface with some ugliness under the hood, and potentially blocking up the optimizer to some degree.
Last year I wrote a maze generator in Haskell which let the user choose between most of the algorithms described in that book, but unfortunately I no longer have it (or most of the contents of that hard disk)
GHCJS is really just a back-end for GHC along with a JS FFI. It doesn't have all the organizational infrastructure of a big project because it isn't one. It may need to grow just a bit, but I don't think that's a reason not to use it.
It's borrowing usage of isomorphic in the javascript community, which means loosely that templates/application logic use the same code for the server-side and the client-side. Whether or not it's related to the mathematical notion, the term as described has reached critical mass in the javascript/web app community. [Isomorphic Javascript](http://isomorphic.net/javascript)
Their book about high performance haskell hits all the major bases, but I also got it on sale for only $5. Paying the full normal price for it is maybe too much.
String is useful since it's included in the prelude. Since it is just a list of chars. You also use functions from Data.List (and type class instances defined for List). Unfortunately, representing strings as lists of Chars has a large performance overhead. 
Code is available here https://github.com/markhibberd/xsh the workshop/baseline branch is what you want to start with. The master branch has some answers and working code for a basic implementation. 
This is part of why using the Haskell library packages distributed with Debian is so nice.
I think OP is talking about having each individual package precompiled and available, Nix-style, not just distributing finally linked binary programs. So it should cover what you're talking about
This is brilliant. Right now we have GND to coerce an instance for the base type to an instance for a newtype. But with this proposal implemented, we could do the inverse! `coerce` really doesn't care in which direction to coerce, so why not?
Although on balance I very much prefer the Reflex approach, is the following actually true: &gt; So every your component will be aware about all actions in your applications (not just the ones relevant to it) and it will have to be aware about a giant data structure that holds the entire state of your app, not just the part of it relevant to this component. Lenses solve this particular problem fairly well imho. 
&gt; Purescript development is open and active. I tried Purescript for a while but I eventually got sick and tired of the build systems -- yes, that's plural, which is part of the problem -- constantly running into trouble. :-/ At this point the choice for me is between GHCJS and Elm; Elm works well and has nice tooling but you need to write so much boilerplate to do anything that it gets a bit tiresome after a while.
[removed]
i would love this, right now its often that i just have to put my laptop down and go do something else while it works
Perhaps. I've yet to see a haskell framework with that approach. The only framework I used that had lenses to solve it was thermite in purescript. And that comes with its own set of problems. Purescript for example does not have metaprogramming tooling (like template haskell). So you cannot derive lenses. You have to define them manually. And you have to do it separately for data and for actions. So 2 lenses for each component. Obviously a lot of boilerplate. Not only that, but they do not compose actually. So you have to define a lot of intermediate components all the way with all their lenses until you reach to the level you need. So yeah, can be done but involves even more boilerplate. Not fun. And then the types get crazy. We used thermite on some apps and we do not like it. In fact a simpler approach with a giant data structure is at least much easier to code and get things done (like pux or react-hs or miso here).
Is there a reason that this might not be possible now, or not desirable or has development just not gotten to this feature yet?
Does this count?
Glad to see this finally getting some public exposure! I built a simple chess demo with it long ago before it was released. I also wrote the same demo in Elm. While JS code generation of Elm is always going to be superior than GHCJS, I can say I much prefered writing in Haskell + Miso than in Elm. /u/dmjio spent a ton of time trying to make the API really clean and it shows.
[Coconut](http://coconut-lang.org/) with it's [Mypy integration](http://coconut.readthedocs.io/en/master/DOCS.html#mypy-integration) might just do the trick.
It's probably safe to say it's unrelated to the mathematical notion.
Also a small demo written in a much more ancient version of Miso: https://github.com/grafted-in/product-chart-demo
No isomorphism anywhere. Node community use it because it sounds cool.
Just wait, they'll use "Monad" next and then things will get *really* interesting...
Also a beginner here (and suspect I'll feel like one for quite some time)... When solving a problem, I'll work it out algebraically in comments and find that the solution typechecks, but sometimes it's ugly. So it might be helpful to remember that although you might be 3/4 of the way through a thick Haskell book and into more abstractions, you still need to remember to use all of the language features available to you that you learned way back when. Did this a few days ago - correct solution in horrible nested parenthesis was converted to a let expression so the contents of a resulting tuple could be easily manipulated. Get the sense that making it concise and readable is part of the exercise. Agree with tdammers, that exposing yourself to lots of code and coding will help. I'll start forgetting things if I get tunnel vision working only in the book. 
God... I read "week" in the table of content as webpack. And for a long time was thinking what the fak it was doing there... This is a disease and i need help. I will wait till book is complete and will definitely read it, thank you for your work!
Yeah, i'd like to hear that too. Although I'm pretty sure this design is the right way to go, I need some identity.
Thanks for sharing. Keep it up!
RemindMe! 2 Days
There's a couple of type checkers out there for python, I'm assuming using the type annotations of Python 3. There was also a version of Ruby that was statically typed and was type-checked, but all I remember of it was installing it incorrectly.
Foundation has a much wider scope than mine though ; ) It also has a policy to not rely anything other than base. So i have to change lots of design to get my effort into foundation.
Code is here: https://github.com/conal/concat
&gt; For example, in 2 * x + 3, the multiplication depends on the addition having been done, so forcing the multiplication also forces the addition. You mean `2 * (x + 3)`, right? &gt; We can sa wha
Ah, the troubles of editing such a large thing while distracted. This is why I want lots of proofreading. Fixed.
I'd have though `ClassyLenses` would be a perfect fit for this kind of thing. What do you mean they don't compose in Purescript? In any case I agree on Reflex being more modular, even though for the time being (that is, until we figure out some best practices around structuring Reflex apps), it has its own set of problems
:D
This looks great!
That reverse looks like it suffers from the problem I was describing - you'll end up applying combining characters to the wrong character - reversing `"√•a"` would give `"√•a"` not `"a√•"` as you would expect (afaict). You can have arbitrarily many combining characters, so to do reversing properly (for one definition of properly) you need to be able to copy an arbitrarily long chunk of text unreversed into the destination. Really you probably need several different reverse functions. See http://unicode.org/faq/char_combmark.html for details. Also, your function `decodeCharLen#` looks like it should be possible to write without branching... I'll have to consult my copy of Hacker's delight and see what I can come up with =) Edit: Came up with a branchless version: decodeCharLen :: Word8 -&gt; Int {-# INLINE decodeCharLen #-} decodeCharLen (W8# w1#) = let i# = decodeCharLen# w1# in I# i# -- | The unboxed version of 'decodeCharLen' -- -- This function is marked as @NOINLINE@ to reduce code size. -- decodeCharLen# :: Word# -&gt; Int# {-# NOINLINE decodeCharLen# #-} -- This branchy code make GHC impossible to fuse, DON'T inline decodeCharLen# w1 = case w1 of w1# | isTrue# (w1# `leWord#` 0x7F##) -&gt; 1# | isTrue# (w1# `leWord#` 0xDF##) -&gt; 2# | isTrue# (w1# `leWord#` 0xEF##) -&gt; 3# | otherwise -&gt; 4# -- Branchless version decodeCharLenBL :: Word8 -&gt; Int decodeCharLenBL (W8# w1#) = let i# = decodeCharLenBL# w1# in I# i# decodeCharLenBL# :: Word# -&gt; Int# {-# NOINLINE decodeCharLenBL# #-} decodeCharLenBL# w1# = 4# -# (w1# `leWord#` 0xEF##) -# (w1# `leWord#` 0xDF##) -# (w1# `leWord#` 0x7F##) And the test: &gt; all (\x -&gt; decodeCharLen x == decodeCharLenBL x) [0..] True (it's lovely when you can do exhaustive tests)
Shouldn't that be theSimonParadox = maxBound+1 :: Int ?
Thank you (both of you) for the explanation!
I have to agree on that. Nothing wrong with choosing fancy names for things. Sometimes they stick (like Dynamic Programming). 
I see, you mean composition aware reversing not codepoint reversing. I should add document on current reverse. The plan is to add `Data.Text.Unicode` module to handle these context related operations such as composition aware reversing, case-mapping , etc. But i don't think turn them on by default is a good idea though, it will add quite a lot overhead, the old text package don't do this for the same reason i think. BTW, If you want to help on unicode handling please join! A complete set of haskell unicode toolkit is definitely wanted!
I'm building with Pulp and haven't had any problems at all, but then I'm also only using Purescript libs. Setting up build system for GHCJS can also be quite problematic: it needs _all_ the tools listed in README, some versions of NodeJS simply don't work, and no hints about where things went wrong. Once you can build with GHCJS it works really well and quality of (Haskell) libraries are better than Purescript. Getting exact GHC quality type checking and error messages for frontend dev is really great.
Imho `cotraverse` should have been the main method of `Distributive`. 
Nice! can you add simple benchmark and make a PR please? It will make my day! If the performance is improved, then just replace the old branchy decodeCharLen implementation.
It's a good point about required organisational infrastructure, but actually more asking for communication and updates about the project. Not even an official release yet. It's a great project and my experience using it was good, but really would benefit from being formalised a bit. Is there any way of following development of GHCJS other than browsing github repo?
You can go further and [define a method](https://gist.github.com/sjoerdvisscher/8461461) with type: `(Functor f, Applicative g) =&gt; (Key t -&gt; f a -&gt; g b) -&gt; f (t a) -&gt; g (t b)` And if you want to take that even further I guess you end up with something like [indexed profunctors](http://oleg.fi/gists/posts/2017-04-26-indexed-poptics.html).
I hope there is no simony going on.
You could use `stack2nix` to easily set up a shared binary cache for your collegues: https://www.reddit.com/r/haskell/comments/6k0ya9/stack2nix_first_public_release_0130/
Use it for your next project. learn while you do. Commit mistakes, rewrite. Read when you need it. Don't be brainwashed by purists with perfect and perfectly useless snippets. Be motivated by your problem not by your books or your gurus. Use IO and imperative style as much as you want. Use an straight style. Discover for yourself. Learn and use Haskell to do what you need for your work. Don't use it to learn how to create and display more useless snippets. 
&gt; forces all components share the same giant structure for their actions and for the data That is not true in reactjs. If you feel like a particular Haskell+reactjs frameworks force you to do that, it's a shortcoming of that frameworks and not react or Haskell. In fact, it's possible to create reflex-like reusable components if the framework is done right. 
You are not only downvoting the discussion of the tweet - you are also downvoting the link to the tweet. But both of those are constructive. The one thing you are *not* downvoting is the tweet itself.
This is really cool and i hope you manage to finish it!
 What does it mean to be roguelike in this context? 
&gt; Benchmark result says this's far from practical usage though (WE REALLY NEED SSE IN GHC NCG PLZ) What can we do to vote for this at GHC HQ? It was worked on actively for a while, then it fell into the backlog for a while. When does it look like this will actually make it into GHC?
To be like the video game [*Rogue*](https://en.wikipedia.org/wiki/Rogue_%28video_game%29).
**Rogue (video game)** Rogue (also known as Rogue: Exploring the Dungeons of Doom) is a dungeon crawling video game by Michael Toy and Glenn Wichman and later contributions by Ken Arnold. Rogue was originally developed around 1980 for Unix-based mainframe systems as a freely-distributed executable (Public domain software). It was later included in the official Berkeley Software Distribution 4.2 operating system (4.2BSD). Commercial ports of the game for a range of personal computers were made by Toy, Wichman, and Jon Lane under the company A.I. Design and financially supported by the Epyx software publishers. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/haskell/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.24
That will need quite a lot of manpower IMHO, the current API design in `ghc-prim` definitely need some tweak. The most complex thing is not about the SIMD itself, but how to take advantage of it though.
Second to this. Luite came to China four month ago, and we have several talk, he is a brilliant hacker! He also make a talk on GHCJS at my company(DiDi tech). I remember he said it's his daily job to ensure GHCJS's availability, because there are companies relying on it.
I've done some benchmarking, and the results are interesting - intersperse and length get about 10% faster, but the branching reverse is twice as fast as the branchless one (and twice as fast as `text`'s). I think that one thing that should be changed in the benchmark is to use a better piece of text which has a more representative set of characters. The w3's unicode example file may be useful for this: https://www.w3.org/2001/06/utf-8-test/UTF-8-demo.html Edit: I have benchmarked this using a new test string which makes good use of many different kinds of unicode chars. the results can be found at https://codepen.io/Axman6/pen/VWxjrr where `fooBranch/text foo` is the `text` version, `fooBranch/stdio foo` is the non-branching new version, and `fooBranch/stdio fooBranch` is the version using the original branching code. What is weird here is that the branchless version is faster for `intersperse`, slightly slower for `reverse` (which `text` is much faster for) and much slower for `length`.
Hey Edward, I just watched your talk to see the simd stuff you are up to - very interesting! Thank you! Do you have a small code sample which shows how the simdified code looks like, built from those template expression trees? Concerning Haskell - how would you implement the compilation step? You create a dsl to build up an expression tree operating on vec/varying/etc which is then lowered by a custom compiler to c--/llvm? or can you somehow use ghc on the higher level to do the compilation you want? maybe even add specific primitives to ghc?
You pretty much wind up with code snippets that look like foreach(1,100,[&amp;](auto i) { if_(i % 2 == 0, [&amp;] { ... }, [&amp;] { ... }); }); for loops turn into `foreach` calls, and if statements into `if_` calls. I have some extended snippets. I'll see about adding them to the repository. Re: Haskell I was looking at two approaches before I went off to play with C++. One builds an EDSL in haskell with a varying type that i treat as a deep EDSL, then compile through llvm at runtime. Another approach actually tries to evaluate down to the appropriate bits of GHC.Prim to get LLVM to do things, and would fall back on calling custom foreign prims to do operations that our core isn't currently capable of expressing. Unfortunately due to the way we handle registers now, the latter step makes a mess on the Haskell stack and loses almost all performance benefits. The key thought to make the second one work, was to build a custom link time optimization pass and then run it over the llvm-assembled object files to do inlining for the `c10` calling convention. (In fact, this might be worth doing as a general inlining pass during linking anyways, and bolting into ghc, so that ghc can inline small continuation frames across module boundaries and expose a bit more to llvm for optimization.)
Thanks for detailed report. One thing to note is that `reverse` need a branch after decode a char length which may render branchless code useless(since the branch miss-prediction will be paid anyway). Reversing UTF-16 text is faster for w3's unicode is surprising though, maybe it has something to do with UTF-16 only need to branch at most once when decoding a codepoint. I'll try to see if we can make UTF-8 faster for w3's sample. Edit: in last commit i refract my text benchmark to use w3's sample text, but `stdio` reverse runs as fast as the `text` one on my machine, so i'd like to ask you to share your benchmark code to see if there's something going wrong ; )
FYI: This talk isn't actually about transients. It's about 3D graphics in C++.
You'd actually be amazed at how many conversations the community has on this exact point. It's like the FT proposal.
But they're extremely behind, aren't they?
Yes, that's true. Reactjs components have internal state. But many reactjs *inspired* frameworks in ghcjs and purescript do not have that. 
I was originally going to talk about my transients code, but then I realized it was the end of the last day of the conference, and nobody there was going to care about bit twiddling tricks when they were all ready to go have some drinks and go home, so I pulled a bait-and-switch.
You mean they're not the "latest and greatest" version of each library? No, instead they're a known-good, stable set that actually works :)
In https://lokathor.gitbooks.io/using-haskell/content/roguelike/primer.html you show the reader a function type signature with a constraint before they've seen any type signature at all or heard of currying. Do you plan on changing this? I get that there might be reasons not to.
This will be seriously awesome when you finish it!
I think that GHC's nondeterministic outputs is the obstacle here. Lot's of progress already made to achieve interface determinism. Still no binary determinism, which is very hard to achieve. See [DeterministicBuilds](https://ghc.haskell.org/trac/ghc/wiki/DeterministicBuilds). However, on you local machine stack already builds a version of a library once and stores in cache. That version is reused across builds of different project on the same LTS and sometimes even across LTS versions. 
Actually about SIMD programming in C++, but it's not the most focused talk I've seen him give.
Can we recover `index` from that?
‚Ä¶ and therefore they all suck. To the point where I had to extend one of the purescript frameworks and teach it about the react component internal state. Without it the framework was unusable for even a medium size website.
[slides](http://conal.net/talks/teaching-new-tricks-to-old-programs.pdf) 
But stack does cache the compiled libs. Unless you are changing the solver practically for every build I do not understand why it takes so long for you to compile on consecutive builds. 
&gt;There is a lot of unnecessary waiting for packages to compile every time a package is pulled down. How often is that? I understand there's initial cost you are paying, but any subsequent build just uses cached compiled files. 
I used lenses as keys, so you get that for free, see `get`. 
Function types are talked about in the Types section above, including that the -&gt; arrow is what signifies a function type. I could put some more examples in a code block to make them stand out, but they're there. I don't think I use the word Currying but I do explain how it works out in the Declaration section, along with talking about the possibility of partial application. I'm not sure that adding too much vocabulary right away is good. For example, Alpha Equivalency is mentioned, buy not until its really needed in Week 2.
I'd like to introduce all the major roguelike features. Really, once you get the RNG going you're most of the way over the difficulty curve. You can use StateT or MonadRandom for a lot of things. I suspect that I should touch on Lenses at some point. So, RNG Dungeons / items / creatures, permadeath, grid movement.
"Often" may mean once every couple of weeks or so. I know when I used Stack, I'd always start new projects on the latest resolver, which is a problem since I frequently start projects that I never finish =P
I don't think this is a problem. Nix gets away with it without issue.
At that point, you may as well just use Nix =P
reminds me of banana brackets.
I was reading your "OpenGL - Getting Started" tutorial. It looks really good and I'm going to have to try it. Thanks, and I hope you keep working on these helpful tutorials.
[slides](http://lambdajam.yowconference.com.au/slides/yowlambdajam2017/Tweedale-PerformantPolymorphism.pdf)
I had begun converting the first lesson of the next arc on learnopengl.com, but then this roguelike thing came up. I plan to get back to the opengl stuff once the roguelike work is over. I might also do things with Network, like irc and discord and such.
[removed]
what is the difference between ETA and Frege?
I managed to give a more focused version of this at Zurihac, where I remembered to include a number of ancillary points that I was kicking myself over not having made at LambdaJam.
Then it should be able to be derived, although the current code doesn't handle associated types import Linear (E (..)) -- ... newtype WrappedRecord r a = WrapRecord (r a) instance Record r =&gt; Functor (WrappedRecord r) where fmap :: (a -&gt; b) -&gt; (WrappedRecord r a -&gt; WrappedRecord r b) fmap = .. instance Record r =&gt; Distributive (WrappedRecord r) where distribute :: Functor f =&gt; f (WrappedRecord r a) -&gt; WrappedRecord r (f a) distribute = .. instance Record r =&gt; Representable (WrappedRecord r) where type Rep (WrappedRecord r) = E r index :: WrappedRecord r a -&gt; (E r -&gt; a) index (WrapRecord fa) (E key) = get key fa tabulate :: (E r -&gt; a) -&gt; WrappedRecord r a tabulate f = WrapRecord (runIdentity (trav (\l _ -&gt; Identity (f l)) (Const ())))
Version bounds always were are kludge. Everyone who has used Stackage has seen the light and doesn't look back anymore to having to maintain those arbitrary bounds in their .cabal files. Stackage proves that you can defeat cabal hell without *any* version bounds at all in your .cabal file. Version bounds are the cause of cabal hell and they don't belong into .cabal files. Period. And without version bounds there's no reason for mutating package references. And best of all, without cabal mutations there wouldn't be any [PvP harassing trustees](https://www.reddit.com/r/haskell/comments/6jv15h/haskell_infrastructure_swift_navigation/djqpqls/) anymore! In short, version bounds are the root of the evil cabal. So I don't get why you keep imposing busy work on Stackage users for supporting the harassment and broken tooling haskell.org keeps forcing on the Haskell community. 
You probably didn't get many responses because there have been many similar threads in the past. Consider reading through recent discussions about "Haskell Programming from first principles" and other learning material. I have been meaning to look into iHaskell eventually, with respect to interactive programming tools. EDIT: Diehl's (http://www.stephendiehl.com/posts/haskell_2017.html) and Gonzalez's (https://github.com/Gabriel439/post-rfc/blob/master/sotu.md) surveys might be of interest to you, for finding something to practice your skills with, after working through introductory material. 
Eta compiles GHC Haskell. Frege is its own language.
Were does one go to learn more about this type of stuff? Anything other than Bartosz' blogg?
I only read the rest later. I still think the one argument function/partial application discussion belongs before the mention of typeclasses and constraints. To be clear -- with the amount of information you're pushing at once, it's already hard to do as good as you're doing. Props for that.
Well Debian Stable was on GHC 7.6 until a few weeks ago, so you're looking at about 3 years old.
Wikipedia's reasonably comprehensive, but may not be the best introduction. There have been a few posts here on recommendations for category theory books over the years. Perhaps you can find them on the search?
It does has a bit wider goals, but clearly 95% of stdio goals are what I would expect foundation to be when it's mostly complete. every other foundation's goals after that is extra. As to dependency, stdio doesn't seems to depends on anything critical, so the claim of design change is mostly false. (primitive is a bunch of one liners and mostly wrapping the equivalent ghc-prim, so it's mostly convenience).
the foundation door has been open from the beginning; I for one is happy to discuss anything in where to go with the organisation and the project; The small technical details, which the author disagree with (and rather take this chance and reimplement thousands of lines of lowlevel code from scratch) are completely dwarfed by the shear size of this kind of project.
"it would be a shame if something would happen to your package". Most of those implied "threat" has been done directly by email, there's nothing on github apart from those same ominous warnings dialed way down.
Yes I'm interested to see what the community does with this, I already have some simple tricks that are useful for exploratory programming. One is deriving `Show` for any type (using [`Blind`](https://hackage.haskell.org/package/QuickCheck-2.10.0.1/docs/Test-QuickCheck-Modifiers.html#t:Blind)) newtype Endo a = Endo (a -&gt; a) deriving via Blind (Show) Or defining newtypes whose instances can always be derived newtype Bogus f a = Bogus (f a) instance Functor (Bogus f) where fmap :: (a -&gt; b) -&gt; (Bogus f a -&gt; Bogus f b) fmap = error "Bogus fmap definition." More in part 2!
Just came across this the other day, it may be of interest: https://github.com/billpmurphy/hask "Haskell language features and standard libraries in pure Python."
Nix also goes to great pains to achieve "deterministic-like behavior"; similar to how things like Ansible and Puppet aren't guaranteed deterministic but allow you to reason like they are. Not sure how much that affects it, but I'd imagine it plays some role here.
It's not really that painful. Basically, a package is safe to fetch from a cache if all its dependencies were also fetched from the cache. But even then, as long as the `.hi` files are deterministic (which I think they are in several recent releases of GHC) then there's no nondeterministic inputs to GHC anyway, so it just actually doesn't matter. The only way it would matter would be if you cared whether the objects used to link a binary executable are actually the objects in your Nix store, which sounds like a hard thing to care about
Is it weird that, for me, one of the most exciting things about this paper is closed type classes?
It is just naming. Has nothing to do with actual flux / redux library in js world. Simply because in a pure functional language you already have all you need without any library. Yes, react-hs is more like using redux framework in js world. Except you do not need any separate framework, it is simply part of the react-hs framework. 
I do think foundation's goal consumed mine, but one problem with foundation is that its scope is too much wide IMO: a new transformer, a new time(not long a ago, i just made PRs to time), a new random... It's like rebuilding whole new Rome. There're also lots of concrete design issues which make me uneasy, for example, there're too many type families in foundation. But I want to provide a bytestring style APIs which is simple and clear, and i want to seperate text and bytes to make type application less needed. I also don't want to support `Addr#` based vector from the beginning, and take mmap as a file not a pure data structure. Aother one is i still want to reuse as much code as possible from packages like primitive, deepseq and so on. It's quite unreasonable to have a policy like don't rely anything other than base, can this policy be changed? Maybe these small technical details may seems irrelevant in the context of such large project, but i think it is these building blocks add up one by one which make the project, my current goal is to polish every single piece, after all Rome was not built in a day ; ) 
I have a bit of conflict at the minute... with a C++ gamedev background I am **severely** prejudiced against GC's (and I get the impression haskell may involve a lot of *pointer chasing*, which has been a severe hazard on some platforms), ... but the extreme elegance of the language in other ways makes me want to persevere with it. (and I know it's elegance orthogonal to memory hints, coming from the way the type system &amp; inference works). In theory, I'd like a language where you can entirely separate a description of *pure behaviour* from the *mapping to time &amp; space* (e.g. annotations that may affect the performance but cannot affect the actual result). I understand the argument below that 'most of data is beyond the reach of the GC' i.e. 90+% will be textures and vertex/index arrays; actual state code could indeed *easily* be copied every frame. Even a lot of dynamic state might be particle arrays which I'm sure we could deal with specially. I think I would have far more confidence if there were explicit 'per-frame' temporal hints that could be given, e.g marking out the beginning and end of 'evaluating the next game state', even if these hints are things that an implementation may choose to ignore; So long as the hints are accurate and expressive they should unambiguously help (not necaserily a "trace everything" hint, rather "trace everything that may have been generated since the last call".. or simply, "This is a point where we know the temporaries are at a low water mark") I'm told "invoking a full GC" is considered hazardous in other languages, but doesn't Purity give haskell some extra ability to make assumptions .. e.g. it can rule out cross-references between entire regions (the game state might point at level data, but the level data will never point at the game state; the 'next frame' may point at bits of 'the previous frame', but 'the previous frame' will never point at 'the next frame' ... etc etc etc) 
another restriction on state data might be networking - you need a state reducible to a small enough amount that can be compressed and transmitted for syncing a new player . a lot of what you see could be pure-functionally evaluated from some minimal state.
4mb of data x 60fps for perspective , the machines have bandwidths orders of magnitude above that, and consume it reading bulk graphics data. I don't have numbers at hand today but back on the old xbox360 i recall we had 512mb and the theoretical bandwidth was enough to traverse a big chunk of that every frame, although for sure in practice pointer-chasing code slaughtered the machine. the point is 4gb out of 512gb - the graphics rendering pulling in textures and vertices, evaluating skeletons, and physics code traversing collision meshes etc is still going to consume the lions share of bandwidth. of course GC tracing might be a tricky traversal (lots of pointer-chasing?) even within the game-state , i wonder if it can take advantage of data that is known not to contain pointers (e.g. vector maths types.. arrays of matrices etc) If it was possible to do some sort of 'trace and compact' on the 4mb that copies it all in one go.. (at a clearly marked point where the intra-frame temporaries are known to have been discarded) that should be viable IMO.
Can you elaborate more on how you do this?
 Welcome! Hasklling the Novice from `RealWorld`! To escape, you must obtain the Orb of Lambda at the bottom of the dungeon. You are in a good shape. You are full. You see a stack of `Arrow` on the ground. You pick up a stack of `Arrow`. You found an unidentified scroll labeled as `Monad`. As you read the scroll of `Monad`, it crumbles to dust! It's a monoid in the category of endofunctors! You seem confused... You found a book of GHC Extensions! You've memorized GADTs! You have 2 skill slots open. You see a Glorious Haskell Compiler! It's extremely dangerous! It's resistant to type errors. It's fast. You cast GADT! You summon a well-typed Expr! GHC emits a compiler error at you! You are confused! You try to perform IO unsafely, but GHC blocks it! GHC tries to handle an existential constructor in patterns! GHC's brain explodes!!!!!!! GHC dies! You see some coredump on the floor. Your GADT disappears in a puff of smoke! Your GADT is garbage collected! A mystical Edward Kmett comes into view! He is wielding a (+18) `Prism`! Edward s t a b s you with a `Lens`!!!! !!! LOW HEALTH WARNING !!! You throw an `Arrow` at Edward, but he finds that it is not a lawful instance! Edward is unaffected! Edward casts categorical corruption on you! You are sucked into the Abyss of `Void`! You die...
I was with you until this: &gt; You are sucked into the Abyss of `Void`! That's `absurd`.
Sure. I keep a catch-all faux stack project with a bunch of packages I find helpful for text manipulation. In that project, I just make a subfolder with some input, usually some logfiles or similar, and use mostly Text and Map to shuffle data around and answer basic 'awk' or Perl style questions, like sorting data into buckets by criteria, measuring rates of occurrence, etc. It's not quite as flexible as all of coreutils, but I find it much easier to trust the results of my analysis, and it's often easier for me to think of the problem in Haskell than in other tools. If I run into a repeat problem, I just transcribe snippets from my history into a file and make it a module. If I run into something that really needs performance for some reason (like a massive amount of data, usually) I pull out that module into a separate project, spiff it up a little, and compile it. It's probably not a workflow that'd work for everyone, but I find it super useful on a daily basis.
If someone is willing to do the work to add this to [reflex-platform/cache.nix](https://github.com/reflex-frp/reflex-platform/blob/develop/cache.nix), I will host it. Everything specified in that file is uploaded to nixcache.reflex-frp.org whenever a new version of reflex-platform is pushed to develop; this stuff is welcome to tag along.
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [reflex-frp/reflex-platform/.../**cache.nix** (develop ‚Üí fe95713)](https://github.com/reflex-frp/reflex-platform/blob/fe95713153ebd4e0a97ac8caabbcf7bb1a951bb6/cache.nix) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply djr3zn7.)^.
The more I thought about it, you're right. I bumped Typeclasses below Definitions
I... want to use some of these in my game now.
Agreed, though I do understand it's a *lot* of work to do project updates for the masses and such. It would be very nice to at least get a little bit of very-high level status once in a while -- just the usual "what remains to do before '1.0' and/or 'full integration with the ecosystem', how you can help, etc.". GHCJS is a game-changer, and it really deserves more promotion. (Though I would add that it may need a bit more effort on making the output more optimal wrt. size before I'd recommend using it for anything that's going to run on mobile. That said, it's been a while since I tried it so maybe, it's improved on that front? &lt;=== See, this is the kind of thing that could also go into a status update :) )
I have 2 questions: * what about creating loosely coupled application architecture using miso. * what about compatibility, is it composable and till what extends?
- Loosely coupled architecture Hmm, is it possible to be more specific here. I'm not sure I understand. I'll reiterate what Evan says about architecture https://guide.elm-lang.org/reuse/ - Composability Haskell functions compose very well, as do lenses. I can see the `update` function turning into a lens playground where one can zoom into specific pieces of state and update them (this approach has been fruitful for some examples). I think Prisms could be used for dealing with actions as well. The nice thing about Haskell is that due to its type system, it's more expressive than Elm, so it's yet to be seen what will be possible. I'm excited to see what others come up with. Good application architecture in both Haskell and Elm holds purity as paramount, this allows for equational reasoning and ultimately refactorability. IO in miso (like Elm) is constructed as a pure value and evaluated later in response to events. IO isn't allowed in the view function at all. This was extremely important as it enables the view to be shared on the server. This paves the way for isomorphic javascript which can relieve the user of long perceived load times (which is definitely a problem with GHCJS even after closure compiling).
This constitutes an extremely serious allegation and I am not aware of any such directly threatening emails sent by trustees. Assuming this isn't merely an attempt to disseminate [FUD](https://en.wikipedia.org/wiki/Fear,_uncertainty_and_doubt) for political reasons, I urge you (&amp; others) to report such perceived incidents to me and /u/ndmitchell (or SPJ if you prefer) directly/privately so we can investigate and clear up what factually happened.
Sounds interesting, could you say more ?
Alternatively just report to me alone. I would like to see any such emails. 
Thank you, regarding the loosely coupled architecture, I would like to share with you this [video](https://www.youtube.com/watch?v=b5pFv9NB9fs&amp;feature=youtu.be) , the talk is about how to create loosely coupled architecure in `JS` however, I think what is important is the concept here and the same could be applied to `Haskell` edit : sorry for not mentioning a written explanation, but I find that the speaker is eloquent and expressed the idea a quite well
Very exciting, thanks for the article! I'm having a couple of issues building this though. Is there perhaps a docker image that has a working version or does anyone have any ideas how I can fix the errors below? The issues I've had were 1) Building ghc: The hoopl submodule link is getting a 404. I changed it to https://github.com/haskell/hoopl.git. I'm hoping that will work 2) Building with stack. Use "stack exec -- which ghc" to get the path to ghc and then use "--with-ghc". This seems like it will work 3) Building **libffi** I get these two errors, which may not be fatal? clang-4.0: error: unsupported option '-print-multi-os-directory' clang-4.0: error: no input files 4) Building GHC fails to "find system libffi" ^ This is the one that I'm stuck on currently. I'm setting $LIBFFI to the output dir from the previous CC command i.e. the "--prefix" I'm building on arch, with sysroot gcc from ripi version of 4.8.2 Thanks
You will all be replaced by a simple script in due course of course. In the meantime be vigilant and good luck...
Hi Thanks for mentioning axiom, its nice to have a library that help creating isomorphic application. however, it is not clear for me how to structure or reason about the program architecture in `axiom` 
The AST used by http://haskelltools.org/ might help you. From their home page: &gt; ##### Keeps formatting &gt; The representation of haskell-tools contains the information about the exact format of the source code. Comments and layout is not lost during the refactorings.
I'm happy I answer any questions but in general Manuel took me from 'write lots of tests when you have time (and hope that it works)' to a more maths based proof style of program (i.e. using type systems to hold data).
Haskell-mode for Emacs is amazing.
That will be quite useful! Thanks
&gt; `Edward s t a b s you with a Lens! It hurts!!!!` This is absolutely the best thing.
I dunno if this is what haskelltools is based on, but I think the goal of the `ghc-exact-print` library is to annotate the GHC API's AST with the information necessary to recover the exact input source. That might be a good way to insert comments into the AST without changing formatting.
Would [simplexhc, the STG -&gt; LLVM compiler that's WIP be an acceptable fit?](http://github.com/bollu/simplexhc). It's a one-man hobby project as of now, but I have a bunch of ideas for where it can go!
I think you need to use the `ExactPrint` stuff in HSE, https://github.com/haskell-suite/haskell-src-exts/blob/master/src/Language/Haskell/Exts/ExactPrint.hs There are two ways to use HSE. If you are just generating code for the compiler to consume, there is the simplified mode where you don't worry about comments and layout. But if you want human readable stuff with comments, then you need the ExactPrint stuff. In HSE all the data types are parameterized like this, data Name l = ... And I think that `l` parameter is part of how you use the `ExactPrint` stuff. Sorry my answer is vague -- I am aware that this functionality exists, but have never used it, so I can't say much about how well it works. 
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [haskell-suite/haskell-src-exts/.../**ExactPrint.hs** (master ‚Üí 90110c3)](https://github.com/haskell-suite/haskell-src-exts/blob/90110c3504503593c3016e5a07f07d9bb3d49a9b/src/Language/Haskell/Exts/ExactPrint.hs) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply djrn6oc.)^.
That only works once you already have formatted source code (`SrcLoc` info) with comments in it. I don't have formatted source code, let alone with comments. In order to use `ExactPrint`, I'd have to fill in the formatting info for both the AST and the annotations. Basically, I'm looking for help with that part.
It looks like the HSE AST already can be annotated with exact formatting information (including comments: `Language.Haskell.Exts.ExactPrint`). I still need something to fill in the formatting info (`SrcSpanInfo`) because all I have is an AST annotated with some `Text`s.
It confused me dearly. I was looking all around the codebase of an "isomorphic" framework looking for the definition of the isomorphism or better explanation. Ended up asking and got the explanation I gave you.
Debian stable is ridiculous. It has nothing to do with Haskell.
 decList [] = [] decList (x:xs) = (x-1):decList xs although decList = map (subtract 1) is much more idiomatic. 
Found this on youtube this morning. Chris Allen (bitemyapp) refactoring the Haskell recipe manager
Thanks for all the work /u/deech Any updates on the look and feel? Updated screenshots maybe?
Look-and-feel is currently the same. I was hoping to get to it a while ago but I've been playing whack-a-mole with cross platform build issues and other little things. Theming is the next big thing I'm working on so hopefully that will address it.
Ok, thanks for the update :)
with these changes would fltkhs the easiest way to get up and running with opengl graphics programming in haskell now?
Is there a video?
No, this has to stop! This just another attempt to [*silence and tone-policing people speaking truth to power*](http://i.magaimg.net/img/wey.jpg). Resolving this quietly behind closed doors is precisely what haskell.org wants to save face. But the Haskell community deserves to know the truth about what's in those emails. We want to form our own opinion rather than being fed some dubious explanation dismissing this as some kind of misunderstanding. If there's rotten apples in our community we need to hold them accountable and flush them out!
Why did you choose FLTK? I don't mean any criticism with this question, I just don't know much about GUI frameworks and would like to hear your thoughts.
&gt; But i don't think turn them on by default is a good idea though, it will add quite a lot overhead, the old text package don't do this for the same reason i think. That‚Äôs not true. `text` properly handles this, as it should. The whole *point* of a text datatype is properly handling unicode; otherwise you‚Äôre not dealing with text, you‚Äôre dealing with a sequence of bytes. Advocating for dealing with a sequence of bytes because it works for ASCII is silly and harmful. If you create a ‚Äútext‚Äù datatype that doesn‚Äôt actually properly handle text *by default*, I would not use it, and I would actively discourage other people from using it. Call that type `ByteString`, not `Text`.
Are you leaving fren?
You should be able to combine brick and readline, switching between them as two modes‚Äîsay, by having some readline commands launch brick which then exits and returns to the readline REPL.
AFAIR he wanted to have the lowest amount of dependencies for easiest builds, and FLTK fit that bill. 
I have some of the reasons in the [docs](https://hackage.haskell.org/package/fltkhs-0.5.3.4/docs/Graphics-UI-FLTK-LowLevel-FLTKHS.html#g:1) but I can flesh it out a little: * FLTK is pretty small and fast. The [Haskell demos](https://github.com/deech/fltkhs-demos) take 10's of megabytes of RAM. Even if that number jumped 20x for a real app we're still lower than what my Twitter and Slack tabs alone consume in the browser and even then still about 10x lower than your standard Electron app. * Compared to other toolkits it's quite flexible; while the default look-and-feel is ugly the widgets themselves are quite easy to customize and I've exposed all this functionality on [Haskell side](https://hackage.haskell.org/package/fltkhs-0.5.3.4/docs/Graphics-UI-FLTK-LowLevel-FLTKHS.html#g:17) (see the 'Overriding C++ Methods' section). For example, see the Haskell port of an [altimeter widget](https://github.com/deech/fltkhs-altimeter). * Not just the look-and-feel but FLTK allows me to hack the event loop itself, for example, I can [integrate FLTKHS with Reflex](https://github.com/deech/fltkhs-reflex-host) quite easily. Another example is the `OpenGLRaw` integration in the [demo](https://github.com/deech/fltkhs-gl-demos/blob/master/src/cube.hs) I linked above. * So the point is that the FLTK community have done the hard work of providing a uniform API and very easy installation (this is a biggie) over multiple platforms and we can build our own aesthetics and semantics on top with few compromises. FLTK itself isn't going anywhere and the community is still active and responsive. I really wish great looking themes were available because then this whole project would be a much easier sell. But on balance the toolkit provides so much of what I was looking for in terms of primitives and flexibility I thought it was well worth the investment. Update: some people have asked about other micro toolkits like [Fox](http://www.fox-toolkit.org/). The reason I went with FLTK was that it was the only small toolkit that also had a [GUI builder](http://www.fltk.org/doc-1.3/fluid.html) which is now pretty much integrated with [Haskell](https://github.com/deech/fltkhs-fluid-demos), if you really wanted to you could write your entire Haskell app purely in Fluid. 
I consider both Vincent and Herbert friends. I wish to silence neither. While they may disagree, I consider that a temporary blip obscured by lack of beer - nothing more. If they want to air their differences in public or private I am happy with either. But context is often missed when things go public before they are ready - it's not always the best answer straight away - but it is always the best answer in the long term. 
From what I've seen, FRP is a pretty good (not sure if it's *the*) FP way. Are there aspects of FRP that still feel un-FP to you?
Oh, cool! I didn't know we can have fine grain control using STM. How can I do that? Do you a have a pointer to something that I can study?
Great idea, thanks! :)
I think if all you care about is OpenGL, simply using [OpenGLRaw](https://hackage.haskell.org/package/OpenGLRaw) to pop open a window is probably the easiest way to go. If you're needing an app with buttons and sliders and so on and only care about Linux [Gtk2Hs](https://github.com/gtk2hs) is pretty easy to get up and running and also provides OpenGL integration. For cross-platform apps I think FLTKHS is currently the easiest.
It was also the first GUI library for me that I got running by simply following the build instructions for Windows. (Not that I tried all of them but I did try a few) It doesn't sound like much but that alone is an achievement to me. 
Assuming haskell code resides in directory `haskell-tool`, put following code into your `CMakeLists.txt`: execute_process(COMMAND stack setup WORKING_DIRECTORY ${CMAKE_CURRENT_SOURCE_DIR}/haskell-tool) add_custom_target(haskell-tool ALL stack build WORKING_DIRECTORY ${CMAKE_CURRENT_SOURCE_DIR}/haskell-tool) `stack setup` will only run when the project is configured, it will not run on subsequent `make`s. Beware that stack build directory will be inside source directory, not build directory as cmake users will likely expect. I'm not sure what you are going to with your built tool. Install? Try this: install(CODE "execute_process (COMMAND stack install --local-bin-path ${CMAKE_INSTALL_PREFIX}/bin WORKING_DIRECTORY ${CMAKE_CURRENT_SOURCE_DIR}/haskell-tool)") 
I will definitely need to consider a cross-platform version of my Gtk + OpenGL app, this will be a valuable option, thanks!
I don't really have any answers about why it's slow. - The type system is still strict. I think it just means that tail-recursion doesn't buy you as much as you thought. - Compiling with no optimizations is pretty fast. (`-O0`, while `stack` seems to use `-O1`...?)
I don't have good references to read, but my idea is that instead of an immutable data structure in a single `TVar` that every thread fights for, depending on your application, you can have multiple independent `TVar` for each job, and one or a few "master threads" to monitor them.
Can we all just take a chill pill please?
Your claims are trivially false since version bounds can be ignored and therefore having them is never worse than not having them. Not that I care one way or another about the PVP. Some people like bounds, some people don't. We've all got to be able to work with each other's preferences.
Thank you, it's nice to confirm that the type system is still strict. I was able to narrow down the compilation speed issues to a minimal test case of heaps of @a `shouldBe` b@ with the same a's and b's. This just uses the Eq and Show code. I didn't want turn off all optimizations, but I noticed that a {-# NOINLINE #-} (or strangely enough INLINABLE) at polymorphic recursive functions (like [here](https://github.com/louispan/data-diverse/blob/88858f8aa92c9e7210d36ac3b53c6a0bb64a269e/src/Data/Diverse/Many/Internal.hs#L1179)) seems to help speed up compilation. Maybe it takes too much memory for GHC to simplify recursive polymorphic functions. Then I realized that GHC compiled slowly for the same test case for standard tuples, so I figured that data-diverse wasn't that much slower after all. 
Thanks!
I am dealing with codepoint not ASCII bytes, but we are talking composition char here, which old text simply do not handle.