Absolutely every build system does this. [Use `-Werror`](https://www.reddit.com/r/haskell/comments/bbkt3s/cabal_newbuild_without_changes/eknetft/) if you want warnings to be treated as errors.
Big thumbs up for live coding. Nerve-racking! :)
You can try passing \`--ghc-option=-fforce-recomp\`, but I think that will rebuild everything including (local) dependencies.
I really appreciate your will to help!
Is it really surprising FPComplete would resort to such petty actions?
&gt; whereas the experienced shall have their conceptions challenged by a different type of programming. Maybe tell a bit more about what kind of programming we'll learn about? With what I've read up to that point, I am assuming that this "different" type of programming is simply functional programming, and thus that I won't learn much by reading that book.
I listened to the first 10 seconds for you so you don't have to: HAMT means "hash array map tree"
Right, the book leans towards types and functional programming. And yes, there will be less to learn if you already know a lot about this, at least until we get to the more advanced topics.
Actually: has array mapped trie The "trie" part refers to the fact that after hashing, the location in the tree is determined by considering successive prefixes of the bits from the hash.
I've often used Writer to build lists or strings in a nice syntax, so I whipped this up to try to replicate your string literal format to some extent: https://gist.github.com/mtolly/a077a6a0bb91f4f044ca0222fa8e0ce9 It does require a function call for lines that aren't just a string, but still cool I think. Also you could replace IsString with Num for a list of numbers, but it'd be one of those hack instances without numeric ops defined...
I've been using `unlines` on lists of strings to make multi line strings. Does anyone else have any good tricks? I like the QuasiQuoter method, I'll have to try that next time.
Isn't this more of an implication? Because the argument required by \`&lt;\*&gt;\` or \`ap\` is \` f (a -&gt; b)\` and the function required by \`fmap\` or \`&lt;$&gt;\` is \`a -&gt; b\`, promoting an \`a -&gt; b\` to \`f\` and using \`ap\` on it should be equal to just using it with \`fmap\`
What's the impact on compile time ? (e.g. compared to mtl)
It‚Äôd be one thing if it is just for fun, but we know that there are plenty of people who believe it to be real. It‚Äôs not snooty to be worried about astrology‚Äôs harmful effects to its serious practitioners (and those around them). The last job posting is at /r/haskell/comments/8953h8/costar_astrology_is_hiring_a_haskell_developer_in if anyone‚Äôs curious.
Lawful `fmap` is unique. `pure f &lt;*&gt; x` definition satifies `Functor` laws. That kind of uniqueness oflawful implementation is rare, e.g. not the case with Applicative. Therefore `Monad` class documentation has ‚ÄùFurthermore, the `Applicative` and `Monad`operations should relate as follows: ...`. In other words, it‚Äôs an additional requirement to check, but with `Functor` you don‚Äôt need to: you cannot write lawful Functor and Applicative instances which would disagree.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/haskell_jp] [How to derive pure f &lt;\*&gt; x ‚â° fmap f x](https://www.reddit.com/r/haskell_jp/comments/bcasn0/how_to_derive_pure_f_x_fmap_f_x/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
Given the applicative laws, we find that \`fmap x = pure &lt;\*&gt; x\` obeys the functor laws. \`\`\` fmap id = id -- law 1 fmap id x = id x fmap id x = x pure id &lt;\*&gt; x = x -- identity fmap (f.g) = fmap f . fmap g fmap (f.g) x = fmap f (fmap g x) = pure f &lt;\*&gt; (pure g &lt;\*&gt; x) -- definition = pure (.) &lt;\*&gt; pure f &lt;\*&gt; pure g &lt;\*&gt; x -- composition = pure (f .) &lt;\*&gt; pure g &lt;\*&gt; x -- homomorphism = pure (f .g) &lt;\*&gt; x -- homomorphism = fmap (f.g) x -- definition \`\`\` Therefore if \`f\` is an applicative functor, then by the applicative laws, \`f\` is also a functor where \`fmap x = pure &lt;\*&gt; x\`. Sorry for any mistakes, typed on mobile.
I was thinking about how you would structure some form of plug-in architecture in an Haskell application. In something like Python it's common to have modules register themself to hooks in the application. Like flask and the @app.route or some global variable somewhere. In Haskell I had a few ideas and wanted to know you guys had any comments or other recommendations. First was to have each plugin expose a structure of hooks it wants too use, like data Plugin = Plugin { onErrorLog :: Maybe (String -&gt; IO ()) , httpRoutes :: Maybe [(Route, Handler)] , ... } and then for each plugin run them through some registering in main. You could also turn this around and call from main an activation function in each plugin with something like activatePlugin :: (StructOfIORefs -&gt; IO ()) -&gt; IO () that would let the plugin add itself to the list of plugins for each hook modeled as a bunch of IORefs. It's probably also something you could do with top-level IORefs and/or Template Haskell, but I didn't look closer at that. Thoughts?
i spent a large part of my career trying to shoehorn what i know from haskell into imperative languages. it *almost* never paid off in the long run, especially in the context of a team, because i ended up pushing a big rock up and down a hill. i really don‚Äôt want to discourage you but that‚Äôs been my experience. good luck!
My $0.02 is to suggest that you look into using Purescript...it has really excellent, low-overhead FFI with JavaScript, the generated code is quite readable and you will have ALL of the expressiveness of Haskell (if not quite all of the expressiveness of GHC). The libraries are great, too. It can be a very big leap in your productivity individually and in a team.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/ocaml] [\[Call for Papers\] Functional High-Performance and Numerical Computing - ICFP 2019](https://www.reddit.com/r/ocaml/comments/bcbexm/call_for_papers_functional_highperformance_and/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
Instead of this: ``` google :: Plugin google s = return $ pure $ Action (T.append "Google " s) 2 $ openUrlAction $ T.append "https://google.com/search?q=" s ``` why not: ``` google :: Plugin google s = pure $ pure $ Action title 2 action where title = "Google " &lt;&gt; s action = openUrlAction $ "https://google.com/search?q=" &lt;&gt; s ```
 const newState = { ...state, options: state.options.map((option, i) =&gt; i === optionIndex ? { ...option, values: option.values.map((value, ii) =&gt; ii === valueIndex ? newValue : value ) } : option ) }; For Old Reddit folks.
I find this a bit confusing: ``` data Result = Action { shownText :: Text , priority :: Priority , action :: IO () } ``` Why is the constructor name different than the type name? Why not `data Action = Action { ... }`?
You don‚Äôt need `RebindableSyntax` for this ``` s = do "FOO" "BAR" "NOM" ```
&gt; Or the code is fine, I just need to be more familiar with functional programming/immutable style? I don't think it's fine. I assume updating a nested array in Javascript is an O(1) operation, but this code copies (which will be O(n)) and then traverses (which will be O(n) again). It's also 9 lines long rather than 1. Do you *need* immutability here?
I originally planned to have multiple results, but then decided that only one is fine. Good point, though.
That wasn't written by me. I originally planned to have both query and title as Strings.
Reformatting for mobile users or old reddit users: -- [] instance pure x = [x] f &lt;*&gt; x = [ f' x' | f' &lt;- f, x' &lt;- x ] pure f &lt;*&gt; x = [ f' x' | f' &lt;- [f], x' &lt;- x ] = [ f x' | x' &lt;- x ] = map f x -- ZipList instance pure x = repeat x f &lt;*&gt; x = zipWith ($) f x pure f &lt;*&gt; x = zipWith ($) (repeat f) x = ... = map f x -- I don't remember the name, AdditiveList pure x = [x] [] &lt;*&gt; x = [] _ &lt;*&gt; [] = [] (f:fs) &lt;*&gt; (x:xs) = f x : map f xs ++ map ($ x) fs -- (it's lawful, check!) pure f &lt;*&gt; x = [f] &lt;*&gt; x = case x of [] -&gt; [] (x:xs) -&gt; f x : map f xs ++ map ($ x) [] = map f x
My first language was Haskell, I love functional programming, and my team uses TypeScript. Even with the improvements compared to regular js, I don't try and push all positives of Haskell into TypeScript, because it simply isn't designed that way. I do often use methods like `map(x)` though, and use constant values unless the value should change at some point. Avoiding side effects makes it easier to understand what a function does. But I don't use things that the language isn't designed for, or that imperative developers would not have encountered in other TypeScript code. One of my colleagues even replaced a ternary operator with an equivalent if-else structure - their reasoning that when the branches are verbose a ternary operator is hard to understand. To me personally, I read ternary operators just as easily as if-else structures - but this college is an excellent dev and if he prefers if-else structures for readability then I will avoid ternary operators with verbose branches. It pays to remember you aren't just coding for a machine, but also for your team members.
Arrays are not good persistent / immutable sequences; creating the new version is O(n). Arrays are excellent transient / mutable sequences updates are O(lg N). If you do need both persistence and these nested updates, you should switch to a HAMT or some other sequence implementation that gives O(lg n) persistent updates. I know Javascript doesn't have clear / enforced IO / ST boundaries, but if you can isolate the transient structure / mutation otherwise, you could stick with the Array data structure.
Quite different results: % ghci GHCi, version 8.4.4: http://www.haskell.org/ghc/ :? for help &gt; :{ | do | "FOO" | "BAR" | "NOM" | :} "NOMNOMNOMNOMNOMNOMNOMNOMNOM" &gt; :set -XRebindableSyntax &gt; :{ | let (&gt;&gt;) = (:) in | do | "FOO" | "BAR" | "NOM" | [] | :} ["FOO","BAR","NOM"]
I also use `unlines`.
Not sure, but would love if you could help me find out!
It looks like this might be code from a React app, in which case immutability is important for state updates.
Nested updates get messy in Haskell too. In Haskell I would use lenses to make updates more manageable. There are are lens libraries for JavaScript - but instead of lenses I think that a more JavaScript-friendly option is [immer](https://github.com/mweststrate/immer/blob/master/readme.md). With immer you write updates in an imperative style, but instead of the structure mutating in place the updates that you write are used to produce a plan to make an immutable update. You get the benefit of an immutable data structure, and the code is easy to read for any JavaScript developer. I saw others comment that copying arrays is an expensive O(n) operation. I want to point out that that does not matter at all unless your arrays are large. It looks like you are working on a state update in a React component. I'm guessing the arrays you are working with will contain at most dozens or hundreds of values. If you do need immutable updates for large arrays I suggest using the [Immutable.js](https://immutable-js.github.io/immutable-js/) `List` type, which is designed for that use case. But I think that is likely to be overkill for cases like React component state values. Don't worry about performance until you have a demonstrable problem.
Navigating to source works just fine in Intellij-haskell. Together with navigation keys (go back, go forward, go to file/symbol) it helps my team a lot in learning Haskell.
This is really important. Paying a O(n) price on every update in your javascript app will be a terrible experience. I've seen talks on Elm, where they do exactly this pattern, and it really makes me cringe. I am not sure how easy it is to get persistent data structures in javascript. If I'm not mistaken, one needs laziness for O(log n) performance. So you would have to implement laziness yourself, and that won't be as easy as in Haskell.
changeOptionValue can be itself a mostly pure function (although it appears to be void?) even though internally it operates in an imperative fashion. Why not deep copy your array and then use the usual indexers to update it? We don't always get our beautiful, fluent, pure functions when implementing functions in imperative languages, but they can be pure from the outside, and that's pretty good. If you really want to retain the functional approach in your JavaScript, you might look into [fp-ts](https://github.com/gcanti/fp-ts) and you can use [lenses](https://github.com/gcanti/monocle-ts).
Does IntelliJ-Haskell still not have auto-indent?
What do you mean by auto indent? Auto format? It does have auto format (based on stylish-haskell and hindent). You can even configure to automatically reformat on Git commit ;)
That's neat! I wonder if your approach is considered acceptable because it doesn't use `RebindableSyntax`, or bad because it sort of introduces its own semantics for the `do` notation. Also, what's up with the `a ~ ()`? Why not just like this: instance (IsString e, ()) =&gt; IsString (ListBuilder e ()) where
Note: I don't know a lot about this. I have been playing around with this today: {-# Language FlexibleContexts #-} {-# Language DataKinds #-} module Test where import Data.HList import Data.Maybe newtype OnErrorLog = OnErrorLog { onErrorLog :: String -&gt; IO () } getOnErrorLogs :: (HOccurrence OnErrorLog l l', HOccursMany' OnErrorLog l') =&gt; HList l -&gt; [String -&gt; IO ()] getOnErrorLogs = map onErrorLog . hOccursMany newtype HttpRoutes = HttpRoutes { httpRoutes :: [(String, IO ())] } getHttpRoutes :: (HOccurrence HttpRoutes l l', HOccursMany' HttpRoutes l') =&gt; HList l -&gt; [(String, IO ())] getHttpRoutes = concatMap httpRoutes . hOccursMany emptyPlugin :: HList '[] emptyPlugin = HNil putStrLnPlugin :: HList '[OnErrorLog, HttpRoutes] putStrLnPlugin = hEnd $ hBuild (OnErrorLog putStrLn) (HttpRoutes [("test", putStrLn "test")]) reversePlugin :: HList '[OnErrorLog] reversePlugin = hEnd $ hBuild (OnErrorLog (putStrLn . reverse)) plugins = hConcat $ hBuild reversePlugin emptyPlugin putStrLnPlugin main :: IO () main = mapM_ (\onErrorLog -&gt; onErrorLog "Hello World!") (getOnErrorLogs plugins) I think it is very interesting, but I don't know if I would use it in actual code.
That'd be the most obvious way, I think. But `unlines` is completely analogous to `mapM_ putStrLn` in my example. My idea is not about mapping a list of strings to a single string, but about defining lists in code.
I mean [this functionality](https://github.com/rikvdkleij/intellij-haskell/issues/156).
What happened to branch misses in the `no_lto` column of the summary table? It's value is of order 1e8. Very interesting study though. The effect of LTO is actually slightly larger than I would have thought. If you are looking for the source of the runtime improvements I would look at the code generated for the GC. Of all of the code in the RTS this will have by far the largest effect on runtime.
If you compile an unregisterised compiled (e.g. pass `--enable-unregisterised` to `configure`) the old C backend will be used.
Oh, my bad, I misunderstood! No, it's not 100% functional yet. However I've found it's a small price to pay for navigation to source, including library sources. If this is a show stopper for you I guess it's not ready yet. I have yet to find a better IDE for Haskell :D
These limits would appear with all the alternatives for a simple reason: the signature of bind which states that the result of the bind composition should have exactly the same monadic signature than the two operands. bind :: m a -&gt; (a -&gt; m b) -&gt; m b There is no way to aggregate effects except adding a `runnEffectxxx` for each new effect, and this runner breaks any possibility of composition and modularity. There are two alternatives: either you use a graded monad that let you change the type of the result. bind : n a -&gt; (a -&gt; m b) -&gt; s t Or you stop trying to take an account of effects at the type level, which is most of the time what haskell programmers do at a certain point for practical reasons. For example, this computations do not annotate the CallMom effect, wich evidently executes: callMyMom -&gt; MomName -&gt; IO ()
It is still normal Monad do notation so nothing too odd there. The `~` constraint is because the do notation's `&gt;&gt;` doesn't constrain the monadic return type, so it has trouble finding the instance: ``` ‚Ä¢ Ambiguous type variable ‚Äòa0‚Äô arising from the literal ‚Äò"************** INFORMATION **************"‚Äô prevents the constraint ‚Äò(IsString (ListBuilder [Char] a0))‚Äô from being solved. Probable fix: use a type annotation to specify what ‚Äòa0‚Äô should be. These potential instance exist: instance IsString e =&gt; IsString (ListBuilder e ()) -- Defined at Main.hs:13:10 ``` I tried fixing it with defaulting, it might work but I wasn't able to get it.
You lost me somewhere in the middle. Why do we need to "convert" \`Database m\` into \`Database (Traced m)\`? Isn't our initial \`Database m\` implementation already polymorphic in the \`m\`?
Yes I'm working with React ... ! Trying to do immutability in React so that it's more consistent with adding Redux later on...!
Sounds like a good use case for Haskell. Look at the "async" package, it provides useful functionality. The book "Parallel and concurrent programming in Haskell" is a great resource, especially the concurrent part. It was legally accesible in the internet, last time I checked. Instead of prepending each JSON payload with its length, perhaps you could simply serialize unadorned JSON objects in the connection. You should be able to parse them with the help of a streaming library like "conduit" or "pipes".
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/haskell_jobs] [\[JOB\] Co‚ÄìStar is hiring Haskell programmers in NY](https://www.reddit.com/r/haskell_jobs/comments/bcgf60/job_costar_is_hiring_haskell_programmers_in_ny/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
I want want to do FP style programming in JS, have a look at the Ramda library.
TBF it's a strange nitpick I have that drives me crazy. I don't think the majority of people would care.
Laziness isn't necessary for all of the Okasaki implementations. The implementations given in ML alongside the prose contain explicit laziness when it is necessary.
What is the tool you‚Äôre using to view assembly? It kinda looks like Vim colors but how do I get it to draw arrows for jumps?
Lenses really do help here, at least in Haskell. Both for preventing traversing the structure twice on a modification and composing a deep access.
It's [Radare](https://rada.re/r/). It's a really lovely tool once you get used to all the keybindings.
ghc's output may go through a C compiler, but it's essentially impossible to optimize. If you follow the actual compilation phases instead of just throwing random flags at it, you'll see it barely does anything. Similarly, it's not possible to optimize for different x86 versions. So -march=native doesn't do anything either. (There was a different compiler jhc where this could be effective‚Ä¶ does it still work?)
I mean, it's pretty much just Alan Zimmerman by himself. He creates hie, and various plugins for editors. I think it's a great effort, but tooling might need money at this point. I'd just stick to ghcid unless you want to lean on something that relies on 1 person to fix.
oh, I didn‚Äôt know it‚Äôs just one person! he must be some kind of god then ;)
I mean: the number of effects that you may track in order to codify invariants at the type level can be infinite. The effects may be independent of the monad transformer machinery or free monad interpreters. For example I can use the CallMom effect to make sure, at compilation time that I invoke CallMyMom only once in a computation, but this effect is is not associated with a monad transformer neither a free monad interpreter. However you can not codify that type level invariant using the current monadic system that uses runEffect. If you track effect in the type system them you need a bind composition that allow mixing them. if not, the type level effects don't allows anything beyond assuring that each effect has his runner and nothing more.
warnings don't stop compilation. The warnings didn't disappear, the module just isn't recompiled unless something changes.
Yeah he's a boss. Great beard.
Sounds like a cool gig. Been working with obelisk in my spare time. &amp;#x200B; Good luck with the search!
since it seems performance is a concern, i would recommend using https://github.com/haskell-streaming/streaming over `conduit` or `pipes`
This is an incredible opportunity, and a really great group of folks.
&gt; What happened to branch misses Weird, two columns got switched when I was fiddling with the table in dev tools. The value should be `-1.3%`. others look right. &gt; If you are looking for the source of the runtime improvements I would look at the code generated for the GC Yeah this ended up being much more about trying to figure out how the heck gcc LTO worked than about ghc. Now that I'm not in the weeds anymore some obvious followups that might be interesting: - Use `perf record` and `perf diff` to actually look at which parts of the code were most affected (though LTO seemed to rename symbols etc.) - try to realize these small gains in the GHC tree, without being concerned with deferring compilation (i.e. using LTO when compiling haskell programs) Thanks for reading.
Because `m != Traced m` If you're calling a function that requires the Database and Http to have the same m then you need to align the monads.
&gt; Similarly, it's not possible to optimize for different x86 versions. So -march=native doesn't do anything either. I was mostly focused on the RTS. So with this ghc branch you can essentially defer compilation of the runtime and some `base` C libraries, etc. until you're ready to compile your haskell, and these can be compiled altogether. But you're right that the haskell code is opaque to the linker/compiler (though I'm still not quite sure how this barrier works)
What I'm saying is that you don't just have a \`Database m\`, you have a \`forall m. Database m\` (kind of, impredicative types are broken). &amp;#x200B; I realize what I'm saying isn't really concrete enough to respond to. Hopefully I can come up with a demonstration of what I mean when I find some time.
I think you should mention whether or not you're able to sponsor visas! :)
We're willing to sponsor visas, but it's often a very difficult and lengthy process, which can make things challenging for both us and the candidate. It's not a blocker for us, but it's something everyone needs to go into with realistic expectations!
do you mean, I should add this option --enable-unregistered to the ghc-options of test-suite?
Yes, we are both able and willing!
Here's a shortcut for testing the lawfulness of `AdditiveList`: type AdditiveList = WriterT (Sum Int) [] toAdditiveList :: [a] -&gt; AdditiveList a toAdditiveList [] = WriterT [] toAdditiveList (a:as) = WriterT $ (a, 0) : map (,1) as fromAdditiveList :: AdditiveList a -&gt; [a] fromAdditiveList = mapMaybe (\(a,n) -&gt; if n &lt;= 1 then Just a else Nothing) . unWriterT `WriterT (Sum Int) []` has a lawful `Applicative` instance, and `fromAdditiveList (toAdditiveList as &lt;*&gt; toAdditiveList bs)` has the same semantics as the /u/phadej's implementation.
One really have to think hard to get what‚Äôs happening here. :) Using `data NOT = None | One | Tons` would make it a bit more to the point. Clever, in any case.
Obsidian is a great group of folks; it's always a pleasure to work with Ryan, Ali and the team. I'd very much encourage everyone to apply if interested!
I think the use of `m` in two locations is the sticking point here. Read it like this: you have a `Database m` and a `Http (Traced m)` (same `m`) and you need to call a function that takes a `Database n` and `Http n` (same `n`). It is true that the `m` is "for all `m`" and the `n` is "for all `n`", but it is not true that this allows us to say that `m == Traced m`. That would be like saying that `Int == List Int`. Does that make sense?
\[though thanks for trying to help with advice, but\] i think that this is not a proper solution, but a hack
Wow obsidian has grown much bigger than I remember. Excellent company and excellent people
I don't have an example on hand right now, but basically the C output from ghc looks nothing like a regular program - it's just a lot of pushes onto the heap pointer. IIRC, it doesn't do calls either but instead function pointers to go between Haskell methods. And if you have constants (like a big list of numbers) in the source, it's not constant in the compiled version but a function that pushes all the values to the heap and returns. There's reasons for this but the result is‚Ä¶ not ideal.
Can you comment on any of the following as they relate to the position: - salary range - healthcare plans - vacation policy - continuing education/community activity allowances (e.g. books, conferences, etc.)
&gt; Lawful `fmap` is unique. As a footnote, it is worth mentioning that this uniqueness [is due to parametricity](http://haskell.1045720.n5.nabble.com/Clarify-relationship-between-Functor-and-Applicative-tp3400944p3400974.html), as /u/fumieval suspected. &gt; I don't remember the name, AdditiveList I didn't know about this one, thanks! In return, here is a fourth one: -- Least common multiple instance pure x = [x] _ &lt;*&gt; [] = [] [] &lt;*&gt; _ = [] xs &lt;*&gt; ys = go xs ys where go [] [] = [] go as [] = go as ys go [] bs = go xs bs go (a:as) (b:bs) = a b : go as bs
Oh so here I'm dealing with the native code gen, so the barrier is that object code compiled from Haskell is opaque to the LTO machinery because it doesn't contain GCC IR. Ghc had a "via C" backend but I think that's been removed
Is it possible to make GHC see an implication constraint as satisfied, when the antecedent is an equality constraint that's statically known to be false? I.e., is there any way to get this silly example to compile: {-# LANGUAGE QuantifiedConstraints, TypeFamilies, ScopedTypeVariables, TypeApplications #-} import Data.Set (Set) import qualified Data.Set as Set c :: forall f a. (a ~ Bool =&gt; Functor f) =&gt; f a -&gt; f a c = id d :: Set Int d = c @Set @Int (Set.singleton 1) (It currently fails with `Could not deduce (Functor Set) from the context (Int ~ Bool)`.) I think it'd be possible to use the tools from `constraint` to convince GHC, if https://gitlab.haskell.org/ghc/ghc/issues/14937 were added.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/haskell_jobs] [\[JOBS\] Obsidian Systems is Hiring](https://www.reddit.com/r/haskell_jobs/comments/bclvvj/jobs_obsidian_systems_is_hiring/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
This looks like great stuff, /u/isovector!
Then I think nested arrays aren't a good choice as a data structure. Arrays are much less useful in a pure setting because updates are very expensive. You're much better off using a tree-based data structure where the price of purity will be O(log n) rather than O(n).
&gt; Don't worry about performance until you have a demonstrable problem. I agree with this in principle, but changing your central data structure in a mature project written in an untyped language can turn out to be impossible in practice.
They don't because unlike errors they don't block compilation, and without flags to change the behavior specified, ghc and cabal will try to not recompile things that don't need it.
I didn't reply at the time, because I didn't do most of the work, so let me just comment generally now. My feeling is it was a bit less work, but maybe not dramatically less. Shorter cycles mostly means less library version divergences, which makes life easier. The other change we have done lately is rebasing the current major lts release to newer minor ghc bugfix releases, which results in more stability also for the ecosystem (rather than forking a new major lts release). We will likely see lts13 move to ghc-8.6.5 soon.
I tend to agree a `--force` build option could be useful. I also want a way to make `cabal install` show warnings.
Thanks for the detailed writeup!
I‚Äôm not gonna say a regular list literal isn‚Äôt readable, although I‚Äôm personally not very fond of the brackets and commas in this situation. But you seem to be focusing only on readability. I have two additional reasons: writability and diffability. Adding or removing a line is easier with ‚Äúmy‚Äù syntax and can never give rise to a parse error, and list literals result in less clear three-line diffs for one-line changes (at the start or end).
Sounds like a really neat stack, thanks for sharing! Have you hit any performance issues? Any hard to debug problems you've experienced?
Good points. &gt; `RebindableSyntax` is a very big hammer to wield for such a small problem. Is that necessarily a bad thing? I tend to see lists of 10‚Äì20 extensions in real code bases. &gt; I have never seen Haskell code like this. Coming across it in the wild would make me do a double take. That‚Äôs definitely an important thing to consider. I wouldn‚Äôt do any of this crazy stuff outside a very limited ‚Ä¶ spatial scope, if you like. For example a module containing only a configuration list with an explicit type signature. &gt; There are a lot of ways to accomplish the same thing using less powerful constructs. For example: `numbers = map read $ unwords "5 9 12 16"`. I don‚Äôt understand this example at all, though. No syntax highlighting. No typechecking. Even syntax errors wouldn‚Äôt be caught by the compiler. Type of items must be in `Read`. Risk of runtime errors. &gt; You could even write your own quasi quoter to do that at compile time. I have never tried this, so I don‚Äôt know how easy this would be compared to the `(&gt;&gt;) = (:)` trick. Perhaps the most useful use case for my trick is equational reasoning, for example: defineJoinUsingBind :: Monad m =&gt; [m (m a) -&gt; m a] defineJoinUsingBind = do join \mma -&gt; join mma \mma -&gt; mma &gt;&gt;= id (&gt;&gt;= id) []
\&gt; Now for biggest pain points. Interacting with large amounts of random data types is more painful than it needs to be due to lack of extensible rows/records/variants. &amp;#x200B; Have you tried some of the existing extensible record libraries? Although I guess their usability and compile times are not quite there yet.
So, I want to make some summary of what I've done. &amp;#x200B; First of all, I want to apologize for the word "sucks" in my question. What I meant really is "didn't meet my expectations". But taking into account that this software is developed only by one human being, I can say for sure that this is exceptionally good software and I didn't mean to offend anybody with my question. &amp;#x200B; Second of all, intellij plugin for haskell is not so cool as I thought from the first time. The only killer feature of it is navigating to libraries code but could be solved in vscode as well (later about that). I even didn't understand how I make it work for the first time, but in other cases it worked just randomly and besides I needed to use the whole ide for that. I like to develop software and see if I produce any warnings which is not possible with this plugin though I understand that it's a tremendous work. &amp;#x200B; Finally, I will continue to use vscode (maybe swith to emacs - seems like it's a cool editor as well) with HIE. It allows to show all the warnings (like non-exhaustive pattern matches) by adding \`-Wall\` to \`ghc-options\` in \`package.yaml\`. Env starts fast enough and I guess it's occasional slowness is acceptable for me. Also I use \`codex\` to generate tags for dependent packages and it allows to imitate the behavior of intellij-plugin though not as much smooth. But believe it or not it allows to find function which haskell-intellij plugin fails to find. &amp;#x200B; Thanks everybody for support and help with this question!
I've seen benchmarks that show that [streamly](http://hackage.haskell.org/package/streamly) is the fastest Benchmarks: https://github.com/composewell/streaming-benchmarks https://github.com/composewell/concurrency-benchmarks
My proof of concept is about running a program which uses `hint` on a machine on which ghc is not even installed. Running the executable outside of `stack exec` is a much easier goal! You just need to use `unsafeRunInterpreterWithArgs` to pass ghc an extra `-package-db` argument pointing it to your package database. See [how I do it in hawk](https://github.com/gelisam/hawk/blob/60882f7181cc014fd2f303c189073f03502af803/src/System/Console/Hawk/Sandbox.hs) for instance.
Wow, I think posts like these are immensely valuable. Thank you! &amp;#x200B; Would you mind telling us a little about your IDE setup? I use Haskell at the backend and I've been very happy with vscode+haskell-ide-engine. I've been tipping my toes into reflex-platform and obelisk for a while, but at the end of the day, I get disheartened after a while of trying to get the IDE integration on top of all that build configuration magic. It's true that perfect IDE integration isn't everything, but it really helps when you want to do stuff for fun. It's also a great support when you're going into an unfamiliar domain (like frontend for a backend dev).
Dunno about MOOCs, but codeworld has some pretty good haskell exercises. Maybe those plus a book of your choice?
Use immerjs, which gives you an imperative-looking API but to the outside works with pure, immutable values. It does this by use of ES6 Proxy, but that's an implementation detail you don't need to know. All you care about, presumably, is that all values are immutable, and the API is pleasant to use, which this gives you. &amp;#x200B; \`\`\` import produce from "immer" const newState = produce(state, draft =&gt; { draft.options\[optionIndex\]\[valueIndex\] = newValue; }) \`\`\`
show has type `Show a =&gt; a -&gt; String`. It is a pure function (no IO). putChar has type `Char -&gt; IO ()`. It is an impure function that prints the character. By saying `show HardTile = putChar hardTile`, you're goinf to get a type mismatch since the RHS has type IO (), but you want String. instead, the RHS should be `[hardTile]`, since String is just [Char].
A string that show should produce is haskell is simple a list of chars that would mean that you could do ``` show Hardtile = [hardTile] ``` etc
That's because the type of putChar is putChar :: Char -&gt; IO () It's a function that takes a Char and returns an (IO) program that prints that character to the console. But you are trying to implement show :: Char -&gt; String Where String = [Char]. That is: show :: Char -&gt; [Char] So in other words you want to create a singleton list containing only that one character: show HardTile = [hardTile]
&gt; try to realize these small gains in the GHC tree, without being concerned with deferring compilation (i.e. using LTO when compiling haskell programs) Precisely; this would make for a nice project.
still printing code instead of the character itself. Sorry, i don't think i've made myself very clear: for hardTile = '‚ñí' it prints "\\9618" instead of "‚ñí"
As others pointed out, `show` is a pure function and not responsible for `IO`. However here's some advice regarding your code: It seems like all the implementations `softTile`, `block` etc. are just duplicating what `show` is supposed to do. If this is the case, you're better of just writing these in the `Show` instance implementation, so `show HardTile = "‚ñí"` and so on. If not, you may want to declare the types in one line rather than splitting it up into many, many lines - so something like `hardTile, softTile, ..., winningTile :: Char` followed by their implementations, it's the same semantics but imho more readable and maintainable.
thanks for the answer, but i'm still getting "\\9618" instead of "‚ñí" when calling show HardTile
Should this be unstickied now that the student application period is over?
&gt;Every problem has a solution. \[..\] ‚Äì [Obsidian Systems](https://obsidian.systems/#contact) &amp;#x200B; [Are you sure?](https://en.wikipedia.org/wiki/G%C3%B6del%27s_incompleteness_theorems#First_incompleteness_theorem)
Yes, you do because you're only calling `show`. If you want the UTF8 to be displayed properly, you must call `print`/`putStr . show`: [Try it online!](https://tio.run/##PY9NDoIwFIT3PcWDFbjgBmw0JG5cYeLCGNOUYhv6l1IkJp5CE@7hFTwKF6kF1N3M5HvzMgy3DRXC@wo7DJsgEUAOW2yrPRc0mDuUunZ/sxaaNEvcc0fYLAtp3K00mCzMgSvF1eV7U1HLr8FCoTqJEFetw4pQKJnu54/QM2onsp2SHExnKWSQxOPwyMfh@X7BKoYoSkNYWy2XHiQxV4GW2OzOkJjOlc4GYipJ4fhbAFl28v4D "Haskell ‚Äì Try It Online")
Just type `"‚ñí"` in GHCi and you will get `"\9618"`, however if you type `putStrLn "‚ñí"` you will get `‚ñí`.
https://exercism.io/ has a Haskell track.
Nice write up. I would love Haskell to support extensible records in a first class way also. In the mean time you could check out [composite](https://github.com/ConferOpenSource/composite). It‚Äôs a convenience wrapper around `vinyl`that has integrations with other stuff as well like json, opaleye, ekg, swagger, and a few others. There is a small example server in the repo that is useful for getting a feel for how the ecosystem works together. Pros: - As you mention extensible types are awesome when paired with SQL queries, and pretty good to use in more general cases as well. - we used it in production in a code base of non-trivial size and I know it is being used in other production code bases now (though in smaller ways). That is to say that compile and run times are not wildly off the wall, although everyone defines acceptable differently - the maintainers are still around and will respond to pull requests Cons: - Transforming from haskell records to composite records is ugly so if you don‚Äôt commit using them throughout your system you my find they aren‚Äôt worth the conversion costs - the project is not really being actively developed right now - While some people that use it do so professionally, they might number in the single digits
https://github.com/data61/fp-course is a really good course with tests to check your implementation
Awesome works. I noticed the site's JS (all.js file) is a little huge (2.4 MB after gzip, 420k loc) and my first concern of use GHCJS in production is [the cost of JS](https://medium.com/@addyosmani/the-cost-of-javascript-in-2018-7d8950fbb5d4) üòÇ
Solved it! Thanks!
Codewars is great!
Thanks! I know it's a little late, but `polysemy` now has a [solution](https://hackage.haskell.org/package/polysemy-0.1.0.0/docs/src/Polysemy.Internal.html#line-175) to [your old bug on needing `mfix`](https://github.com/TaktInc/freer/issues/7#issuecomment-363900421).
[https://www.futurelearn.com/courses/functional-programming-haskell](https://www.futurelearn.com/courses/functional-programming-haskell) It's a good MOOC meant for beginners.
This instance is what I would call the 'R' instance. R has a tendency to do this, except it cuts itself off after the longest instead of the LCM.
I use (and recommend) [Dash](https://kapeli.com/dash) as a documentation management tool. It is cross-language (so I've got docs for all my work-related Scala libraries installed too), lets you install any docs from Hackage (or a bunch of other places too), lets you very easily search for pretty much anything. For Haskell, it basically pulls down a local copy of the Hackage-hosted Haddocks for the libraries you requested. That means that good old Haddock hyperlinked sources are just one search and then one click away.
As far as I am aware everyone uses either Vim or Sublime, and none of use any particularly fancy plugins, just some language agnostic basics. The compiler is running in a different tab and will tell us any errors that occur, which seems to work quite well in practice as tabbing back and forth is almost instant due to keyboard bindings. This is not to say none of us would get any value out of an IDE or more intelligent plugins, but that none of us have really felt any pain due to the lack of such things. Maybe at some point I‚Äôll try and get some Vim IDE plugins working and see if it makes a big difference.
Some perf issues here and there. The majority of which are overly complex / unoptimized SQL queries, it‚Äôs rarely been directly caused by Haskell. The weirdest and hardest to debug perf issue was probably when the site would lag while scrolling, but only for a friend of ours and not for any of us. The reason was because on his browser/OS the onScroll handler would fire extremely quickly, which would trigger the top level handler, which would trigger an equality check on the state, which was too expensive at that frequency. Miso fixed this issue by doing a fast pointer equality check before the deep equality check.
I have looked into them, but one of the main places I would want then is for DB interaction, which would require Persistent to adopt them too. That‚Äôs why I just really want a baked in language level solution, so that all libraries will ubiquitously agree on a single solution. And as you mentioned the usability and compile times weren‚Äôt to the level I was hoping.
Yeah that is a cost we deemed acceptable, but I realize it‚Äôs not for everyone. We could/should run it through closure at some point to bring down the size some more. I have high hopes for GHC-&gt;WASM to help with binary size and further runtime improvements.
Thanks, will check it out! I briefly explained [here](https://www.reddit.com/r/haskell/comments/bco8he/comment/ekt7306?st=JUFSPD6L&amp;sh=9966e4ea) why we haven‚Äôt adopted a library level solution so far.
This is so good. Have you considered adding this to regex-tdfa's README, and have the package include the README so it appears on Hackage?
You just never know when you are done, unless you exercise literally every code path (not just line of code).
The main benefit of plugins over basic vim for me has been getting types of expressions and correctly auto completing fields. If you aren't feeling that pain then don't worry about it. ghcid in another terminal is 90%.
Everyone is gushing about the stack, but I just wanted to say that this is really cool product and I hope you succeed.
Thanks, really appreciate it!!
&gt; less clear three-line diffs for one-line changes (at the start or end). With leading commas it's only at the start. Also, I think growing the diff by 1 modified line (or 1 adding and 1 removed line that are nearly identical in the unified diff format) is a vastly overblown problem. There a lot of other common formatting that can blow up diffs by several more factors.
Thank you for your comment. I would pick Haskell without any tooling support over any other language any day of the week, but I'm getting so much value out of vscode+hie that I'm very much spoiled at the moment.
Great cheatsheet. I had no idea tdfa was polymorphic by the output type. That's really neat, and also explains some minor frustration I had with it a while back (where's my /g ?)
Just spitballing here, but you could consider using lazy IO. The idea is to build an infinite tree representing the links between your web pages, and only perform the requests for those web pages when your crawler demands it. This lets you separate the ‚Äúhow to get a page‚Äù code from ‚Äúwhich pages to get‚Äù and ‚Äúwhat to do with the content‚Äù code. ``` data Crawl = Page { html :: HTML, links :: Map URL (Either Error Crawl) } crawl :: URL -&gt; IO (Either Error Crawl) crawl url = do response &lt;- simpleHTTP (getRequest url) let html = parseHTML response let urls = findURLs html links &lt;- traverse (unsafeInterleaveIO . crawl) urls return $ Crawl html links findURLs :: HTML -&gt; [URL] findURLs = ‚Äî ... ``` I‚Äôm on my phone so this probably doesn‚Äôt even type check, but hopefully you get the basic idea.
I don't see how a plain old record can easily become a useful monad: the kinds do not match. Maybe you need to look at what operations you apply on this record, though. What you can start with is decouple the pure computations (extracts, filters) from the IOs (requests), and leverage the *Functor IO* instance to adapt intermediary results. Also, you'll be well-advised to think a bit your application architecture and how the logic flows (e.g., whether or not you're entirely done processing a page prior to fetching other pages will significantly change the complexity level). For a simple case you can have something like thread = forever $ dequeue &gt;&gt;= fetch &gt;&gt;= process &gt;&gt;= enqueueN where .... For more complex cases you'll want to reach for `async` or even `Haxl`.
Seems reasonable for an astrology app. This isn't Google.
Likewise! I took another look at http://polimorphic.com and signed up. I can see this is a wonderful initiative and would probably teach me a lot if I used it for a bit. I can feel there's a lot of clever tech working behind these deceptively simple-looking web pages. From what you've told us about it I have confidence that it will keep getting more featureful and robust. On the down side, right now browsing around (in latest Firefox) it feels really slow. Page transitions are very slow.. pages often start out empty, new content pops in slowly, sometimes with a loading spinner, sometimes with no visual warning, etc. I'm expect you're aware of this and there are probably good reasons. If you have time it would be great to hear more about what they are. As a fan of this on multiple levels it would be great to see it be lightning fast.
Ah yeah we need to test more on Firefox. As far as I am aware Firefox has the worst/slowest JS engine, as for example even on my mobile phone on mobile safari the page transitions are very fast. Yeah we definitely have some missing loading spinners. I should browse around on Firefox, if needed with some intentional throttling, and look for all the places they are missing. I should also look through where Firefox is spending most of its time. Perhaps closure compiler could speed some of that up. Page transitions don‚Äôt involve a whole lot of complex code, as no api calls are run until the new page is loaded, so I‚Äôm worried that it‚Äôs GHCJS + Firefox having suboptimal performance.
I actually do remember looking at `hawk` - I tried that approach, but it turns out that Cabal sandboxes [aren't relocatable](https://github.com/haskell/cabal/issues/462). Besides, I can't assume that GHC is installed on the user's machine (although I suppose I could include it within the installer).
You should probably review the literature on the utilitarian ReaderT pattern in Haskell as well as Matt parsons blog post on the three layer cake.
haskell-ide-engine will soon support Obelisk projects.
Ah, two weeks late for this New Yorker since I just started a new job :/
Great news!
If you're calling into C++ to manipulate some object, then this doesn't seem like a Haskell question to me. But it depends on the interface of your C++ library, if it returns you some kind of data structure that you want to persist until the next call, then you can put it into an [`MVar`](http://hackage.haskell.org/package/base-4.12.0.0/docs/Control-Concurrent-MVar.html#t:MVar) at the program start, and work on it using `modifyMVar` in your request handlers.
The C backend is not gone; it's just not supposed to be used. GHC is normally built in "registered" mode, which means it generates unportable code that depends strongly on a (set at build-time) target architecture. You can only enable the C codegen by building GHC yourself in "unregistered" mode, at which point it will output (mostly?) portable code. The hope is that you only use the C codegen on a new architecture until you write a real native codegen.
I just ran your `all.js` through `google-closure-compiler` just out of curiosity and brings the file size down only about 25% (16.6MB -&gt; 12.9MB). That's kind of unfortunate‚Äîwhen I ran it on my production 30K LoC Elm project it reduced the size by nearly 80% (1.6MB -&gt; 360KB). Looks like this is just a fundamental cost of using GHCJS.
Yeah it does seem somewhat fundamental to Haskell-&gt;JS. Elm looks somewhat interesting but it almost seems to be trying to follow in Go‚Äôs footsteps, aiming for as little flexibility and expressiveness as possible, with the lack of typeclasses and similar.
I found [CIS194](https://www.seas.upenn.edu/~cis194/fall16/) to be very helpful. The entire course is project driven. But you may also need to go through some alternate text like First principles or slightly lighter book like LYAH or Get Programming with Haskell book, alongside. P.S I'm also beginner too. These have helped my learning process. Looking forward to do do data61/fp-course soon.
It works very well, but you need all that cargo cult stuff and complicate what is inherently imperative and straightforward with a lot of monads runners lifters lenses, semigroups and wathever is in fashion? You have plenty of stuff in the Haskell literature.
Why use this instead of property graph or triple store like neo4j, datomic, janusgraph
I've never seen this package before- the polymorphism in `(=~)` and `(=~~)` seem really cool, rather than having 20 different functions with different names, that you can never remember what exactly they do.
Look like you want to cargo cult your code. Don't complicate things, please
Parallel programming is always hard, and GHC is to some extent written in a procedural style. Further, it is quite rare that simply adding a few strategic `par`s helps significantly - effortless parallel Haskell is unfortunately still more dream than reality. In a larger context, threading a single GHC instance may also be detrimental to total performance, in the case where the build system is running multiple GHC instances concurrently.
is it that procedural ?
&gt; regex-tdfa only supports a small set of special characters and is much less featureful than some other regex engines you might be used to, such as PCRE. This disappointed me at fist, but then I thought to myself: This limitation should be considered a *feature*. If I need these more advanced regex features, I shouldn't use regex in the first place; I should use parsers. Regex only for simple stuff; parsers for everything else. (Exactly what you say at the end.) Great article!
I'm not enough of an expert on GHC internals to say for sure. While there is obviously a lot of pure code in GHC, many of the passes run in the IO monad, and use IORefs and such to maintain various bits of state. It's unclear to me how much of that is isolated benign state, and how much is significantly affected by evaluation order - which is *exactly* why it's hard to parallelise an impure program.
Disclaimer, I haven‚Äôt done any FFI, so the situation might be different for FFI, but you should take a look at the [State monad](https://hackage.haskell.org/package/transformers-0.5.6.2/docs/Control-Monad-Trans-State-Strict.html).
GHC [does support parallel compilation](https://ghc.gitlab.haskell.org/ghc/doc/users_guide/using.html?highlight=j#ghc-flag--j[%E2%9F%A8n%E2%9F%A9]). When passed `-j&lt;n&gt;` GHC will try to compile non-dependent modules in parallel. In practice this often ends up being too coarse-grained to extract a significant amount of parallelism, however. Another note on using `-j` (or any other parallel Haskell program, for that matter): GHC's default garbage collector parameters are tuned for single-threaded performance. This manifests as a relatively small nursery size which, while good for cache locality, tends to result in frequent synchronizations between capabilities in a parallel program. Synchronization between cores is expensive. Consequently, it's often helpful to increase the nursery size (often significantly). I would recommend running parallel programs (including `ghc` when run with `-j`) with `+RTS -A32M` as a starting point.
GHC is also slightly non deterministic in code-gen (or was when I looked at it last?). Even if we somehow modified the code to run in parallel, that would only make the situation way worse (but faster!) I'd imagine step 0 to parallelizing the compiler would be achieving deterministic code-gen which is a fairly large project in of itself.
This sounds great, along with the rest of the conference. I really wish I had holidays to use to visit Poland and learn with you guys.
This looks like what I wanted - I'll give this a go, cheers! :)
I'm not awfully familiar with Monad transformers (I think that's what they're called?) at the moment and it seems a little overkill for what I'm trying to do. I think \`MVar\`, mentioned by enobayram, is what I'm looking for. I'll definitely look into the State monad at some point though, thanks for the suggestion :)
I was responding to the "when I install my program (using `stack install --local-bin-path bin` part of your question, not the "I'm trying to distribute a project I've written using Haskell" part. Try to solve the easier problem first!
To expand on that, I suggest putting \`ghc-options: -j4 +RTS -A32m -RTS\` in the \`program-default-options\` of your \`\~/.cabal/config\`. I have it there, the speedup is significant and you shouldn't have any issues with memory exhaustion (I haven't got any so far) if you have at least 16GB of RAM.
Why doesn't GHC default to a bigger nursery size when using `-j`?
&gt;that would only make the situation way worse (but faster!) The history of computers in a nutshell.
For completeness, Patrick Thomson (aka importantshock) announced this release [here.](https://twitter.com/importantshock/status/1117452652076589057)
Looking up symbol definitions globally (outside of your own project) really needs to exist for Haskell.
404
Mostly just want to make things more composable and modular
Good question! Here are [most of the reasons](https://github.com/JeffreyBenjaminBrown/hode/wiki/Hode-vs.-property-graphs) I can think of.
You can write single-file scripts with cabal too: https://hub.darcs.net/vmchale/fastcat/browse/shake.hs#1
I don't know. But in case it helps, the [README for Nike's hal](https://github.com/Nike-Inc/hal) claims 20% execution overhead vs Rust. Ok that probably doesn't help. I imagine there would be little to no overhead specific to Haskell since it is compiled (and can be optimized) as opposed to languages that have to load a bunch of stuff dynamically at runtime.
Well, I found [this](http://learnyouahaskell.com/making-our-own-types-and-typeclasses#algebraic-data-types) explanation good. Also the book per se is good introduction to Haskell, so you might want to read it from the start.
Looks like it's Mac only.
In general we are rather reluctant to make these sort of policy decisions for the user. A reasonable nursery size for a 32-core server will be much different from those on a dual-core laptop. In the particular case of the `ghc` executable I suspect we could improve the default behavior for the typical case of a 2-to-8 core machine compiling a few modules in parallel. However, this would take someone stepping up to do some benchmarking to find a reasonable set of parameters.
Hey r/haskell! Here's the second installment in the Haskell coreutils series. This time it's a platform independent `which`. Thanks for all the feedback and discussion on the previous post!
Why +RTS .. -RTS?
Another great entry in the series. Thanks for this!
Monad transformers are a fairly valuable tool. To implement the MVar solution, I'd strongly recommend using the reader monad transformer, so that you can implicitly have the MVar carted around with your stack. This sounds like a project that's complex enough that you might want to rip the band-aid off and learn how to use transformers - it's something you'll want to learn eventually and this is a fairly simple bit of architecture that would serve well as an introduction.
For programs complied by GHC (such as GHC itself) it indicates that the parameters inside should be passed to the runtime system instead of to the program itself.
These are great, thank you!
Instead of filtering on `doesDirectoryExist path` and then filtering on `elem file &lt;$&gt; listDirectory path`, it would be faster and more accurate to simply filter on `doesFileExist (pathJoin path file)`‚Äîfaster because the directories could have thousands of unrelated files, and more accurate because you might not have list permissions on the directories. Also, `findExecutable` and `findExecutablesInDirectories` are already in `System.Directory`. I suppose you‚Äôre probably aware of them and avoided them for the challenge of reimplementing the functionality, but pointing them out might be useful to the readers.
Are there any resources or heuristics for estimating the needed nursery size given n cores?
There is [Zeal](https://zealdocs.org/) as cross-platform alternative. It actually dash's repos as a source. It's been working great for me on linux.
Thanks for pointing this out! I briefly considered this, but clearly didn't think about it long enough üôÇ I do know about the library functions, but you're right, mentioning them would be nice for the readers.
Thanks!
I have a branch to make the codegen byte-deterministic even in presence of parallel compilation (`-j`) and the incremental compilation resumption (`--make`). I'm doing it by making the `Unique`s be generated with a seed based on the hash of the module name. It is almost working: A big project I'm testing it on now differs in only 8 bytes in the executable. There are 2 lines of code in the GHC source code that I haven't quite figured out how to change correctly. Right now that project is on hold due to lack of sponsor, and I've already sunk a lot of free time into it. Ping me if you want to fund finishing it :)
&gt;I was responding to the "when I install my program (using `stack install --local-bin-path bin part` of your question, not the "I'm trying to distribute a project I've written using Haskell" part. Well, in my case both problems are exactly the same, since I don't have a global Haskell installation (I access GHC, other utilities etc. through `stack`). In order to distribute an application, I typically install the executable somewhere on my hard drive (using e.g. `stack install --local-bin-path bin`), then copy over all other files required to make it work, then package these files into an installer. &amp;#x200B; (I'd better edit my original question to clarify this...)
I've updated the article with your suggestions. Thanks!
The `State` monad is explicitly for local, single threaded, immutable state. It is completely inappropriate for what you want.
In Haskell, we have "reference types" - examples include `IORef`, `MVar`, and `TVar`. These are mutable references which have different performance and concurrency characteristics. AN `IORef` behaves mostly like you'd expect a mutable reference in Python or Java to behave. `TVar`s and `MVar`s are designed around concurrent programming, and offer interesting tradeoffs.
Oh, thanks for the info! Didn't realise it was single threaded. How does the immutability work though? Surely it changes the state of what it has stored?
Yeah, I've used MVar to solve my issue already :) Thanks for all the useful info! I might look at the different reference types you've mentioned here, haven't looked at the differences.
&gt;GHC is also slightly non deterministic in code-gen (or was when I looked at it last?). Even if we somehow modified the code to run in parallel, that would only make the situation way worse (but faster!) For what it's worth the kind of non-determinism that happens in code-gen should not be a show stopper for parallelism. As far as I know it's limited to generated label names, and sometimes slight control flow changes derived from that. Deterministic code gen is still worthwhile, but it's not something I see holding back parallel compilation.
I understand this is just for fun, but a few remarks: * exit codes are not correct (which returns exit code of failed program names or -1 if no arg was supplied) * does not understand tilde (which interprets it and looks up $HOME env variable) * doesn't work with slashes (on `foo/bar` which looks for an executable bar in the directory foo, relative to the current dir, also works with full paths) * no error messages
Under the hood, `State` is implemented as: newtype StateT s m a = StateT { runStateT :: s -&gt; m (a, s) } type State s = StateT s Identity This models mutable state as a function that accepts a value of type `s` and returns a value of type `(a, s)`, where the `a` is the "result" of the function and the `s` is the "new state." The `Monad` instance for `StateT` threads the state through each computation. instance (Monad m) =&gt; Monad (StateT s m) where sa &gt;&gt;= a2sb = StateT $ \s0 -&gt; do (a, s1) &lt;- runStateT sa s0 (b, s2) &lt;- runStateT (a2sb a) s1 pure (b, s2) It's important to notice how we are threading the state through. It is an entirely ordinary Haskell value of type `s`. The functions that "modify" state are really accepting an `s` as an input and returning a different `s`. modify :: (s -&gt; s) -&gt; StateT s m () modify func = StateT $ \s -&gt; pure ((), func s) The "old" `s` isn't mutated.
Thanks for the comments! I don't understand your second and third points though, what behavior are you expecting? Tilde will be interpreted by the shell, and not passed to the program. Exit codes are typically 0 - 255
In addition to the move to Azure for Stack (which has been very nice), I've been slowly moving a bunch of my projects over to Azure CI as well, and I've been quite happy. If anyone's interested in more information on how to do that, we have a page on the Stack documentation dedicated to Azure CI: https://docs.haskellstack.org/en/stable/azure_ci/ Which is also linked from the blog post.
&gt; Thanks for the comments! I don't understand your second Tilde is not interpreted by the shell if it's used inside PATH. &gt; and third points though As already explained, if you pass `foo/bar` 'which' will look for an executable bar inside the directory foo. &gt; Exit codes are typically 0 - 255 Well, if yous see POSIX, then all values are possible: http://pubs.opengroup.org/onlinepubs/007904975/functions/exit.html But it translates to 255. The manpage specifically mentions -1: https://linux.die.net/man/1/which
Pretty much none, as there isn't any JIT compilation or anything like Java's classloading required
You continue searching for other versions of the same file after finding the first success in the PATH, but then only report the first one. This is a subtle waste of effort, but a real one.
I love this series so much! Very interesting
Well, `which` isn't actually in POSIX. It is neither a [shell special built-in](http://pubs.opengroup.org/onlinepubs/9699919799/utilities/V3_chap02.html#tag_18_14) nor a [normal utility](http://pubs.opengroup.org/onlinepubs/9699919799/utilities/V3_chap02.html#tag_18_14).
Well, the RTS does have to be initialized, but I think that's rather fast, esp. compared to JVM or CLR.
Yes, I wasn't saying that it is POSIX. I was referring to the `exit` function, which explains exit codes.
I haven't noticed it, or at least it's been overshadowed by the costs of AWS getting the infrastructure in place (+attaching to a VPC, if you're in one)
How big do the executables turn out to be?
The only thing that's come to mind is "warming up the GC". My faint memory of "dons + an RTS option" eventually dredged up this blogpost from years ago https://donsbot.wordpress.com/2010/07/05/ghc-gc-tune-tuning-haskell-gc-settings-for-fun-and-profit/ The `-A` and `-H` RTS options have interesting effects, depending on how your program uses heap. HTH.
I saw graph pointing out stuff like c is worst relative to something like python/js
Haskell is already extremely hard to understand and has a really high barrier to entry. Some of that complexity is necessary but that means we need to trim complexity fat elsewhere. As neat as this trick is I think it's one of those things that are overkill for the problem and makes haskell harder to understand for beginners (who already have a lot to learn). Diffability is not the end of the world, if you get a parse error just fix the parse error?
Done
Let me rephrase my question a bit: is compile time linear with the size of the stack of effects ? I'm asking that because I've used [OpenADT](https://hackage.haskell.org/package/open-adt-1.0/docs/Data-OpenADT.html) and [Extensible ADT](http://hackage.haskell.org/package/haskus-utils-variant-2.5/docs/Haskus-Utils-EADT.html) to represent and transform the AST of a DSL, but compile time degraded a lot when there were more than 10 different types of AST nodes (from seconds to minutes). I would think that I can use polysemy instead of EADT/OpenADT, but I'm concerned with the compile time.
But... last evaluation! What's causing the excess work to be computed? And what's the beginner-friendly change to fix it? (Thank you in advance)
Problem 1.) (Not quite what I mentioned) You do all the work to find all the answers, _then_ you decide to bail out early with an exit code before reporting any of the answers you've found so far. On the other hand, you could abort earlier the moment you know that any of the responses isn't possible. Problem 2.) (More what I mentioned) getPaths &gt;&gt;= mapM addFileToPath &gt;&gt;= filterM doesFileExist &gt;&gt;= filterM runnable is asking if every file exists that is in the path that has the right file name, not just finding the first one and bailing early. The easiest way to fix them is to do both recursions manually.
TFW when Ed Kmett code golfs your verbose 72-line program down to a simple `foldM` operation...
Recently there's [haskell-code-explorer](https://github.com/alexwl/haskell-code-explorer). Alternatively - though for Haskell-only use it could be overkill - you could use [haskell-indexer](https://github.com/google/haskell-indexer) combined with [underhood UI](https://github.com/TreeTide/underhood) . ([golang demo](https://codeunderhood.com/#/file/kythe:%2F%2Fkythe%3Fpath=kythe%2Fgo%2Findexer%2Findexer.go/151))
Use `putStr` or `putStrLn` on the result of `show`.
I'm not going to bother to fill out the whole survey, but at least, where I work, we mostly build web applications that don't really do such a large amount of physical calculations that would warrant it. There are a bunch of difficulties in using such libraries though, for example, in the one case in recent memory where I can imagine such a thing applying to the situation, it would have necessitated converting back and forth from Doubles in order to apply a linear regression from the 'statistics' package (which did most of the work, apart from a simple distance-from-latitude/longitude calculation). Also, that code was very stable the moment it was written, and basically never got touched again after it passed QA the first time. The places where you want such a library is in cases where a common class of bugs for you is unit conversion errors -- or cases where any such error would be so entirely unacceptable that an ordinary QA pass wouldn't result in enough confidence that everything was right. If I was working on code that involved numbers representing physical quantities with different units all the time, I'd certainly want *something* in that regard. It just doesn't seem to come up all that often for me.
Units of measurement are fully-integrated into the F# language. It would be interesting to see what uptake is like in that community vs others. In other languages, where you will never see it unless you look for it, it often doesn‚Äôt occur to folks to even try to employ units of measurement. It‚Äôs a bit like database normalisation. Everyone agrees it‚Äôs a good thing to keep things atomic. But then it never occurs to anyone to store an email as two columns. Even with units of measurement km and ms are not the important things, as it‚Äôs vanishingly rare to interact with the real world. Counts are where things get weird, e.g. fitsInCar :: Count Person -&gt; Count Seat -&gt; Bool Yet as with normalisation UoM folks often ignore this.
I'm confident that my [`Union` type](https://github.com/isovector/polysemy/blob/071b5dd38a5743069277643703f603fb68343ac9/src/Polysemy/Internal/Union.hs#L43) has asymptotically better compile times than the `VariantF`s found in `OpenADT` and `ExtensibleADT`. If that's all you're looking for, then yes, polysemy will definitely help. The actual zero-cost boilerplate machinery of the monad instance relies on GHC inlining everything away. I'd assume this still compiles in `O(n of effects)` time, but with large constant factors.
[CodeSignal](https://codesignal.com/) allows you to solve problems in Haskell, and test directly on functions instead of requiring to go through stdin/stdout like most other sites. Nothing Haskell-specific in there, but plenty of exercises at least.
How much overlap with the New York work hours are you looking for? I'm based in Eastern Europe, for example.
I've been playing around with this idea in JS for a bit (although obviously I get no inlining and there's no type system to direct anything): [https://gist.github.com/masaeedu/177e158087a446e8d4a7758de2f2194c/](https://gist.github.com/masaeedu/177e158087a446e8d4a7758de2f2194c/). Given a labeled stack of functors in the category of monads you can simply lift each an appropriate number of times relative to some non functorial base. The tradeoff is that you can have multiple transformers of an identical type in the stack.
This was the original purpose of [Apps Hungarian notation](https://www.joelonsoftware.com/2005/05/11/making-wrong-code-look-wrong/), before it was corrupted by the Windows team into the Hungarian notation that everybody hates today. Of course, in Haskell, it would be more idiomatic to use a newtype for this. But in most languages, there's no good way to make a newtype in a way that's transparent and sensible. (You can technically do newtypes with a struct in C, but it's very clumsy and there's no guarantee that compilers will optimize it away. Java, Python, and many other object-oriented languages _definitely_ lose performance using a newtype pattern.)
I think units of measure only encapsulates part of the kind of logic you want when working with measurement quantities. Another is some sort of subtyping: for example, it makes sense to say `2 kg of oranges + 3 kg of oranges = 5 kg of oranges`, but it does not make sense to say `2 kg of oranges + 3 kg of apples = 5 kg of oranges`, despite both of these being mass. I think the mass `of whatever` is important here in helping detect logical mistakes, as I've been bitten by this exact kind of bug before. Similarly, in a game you might have scores for player 1 and player 2: `10 points of player 1 + 5 points of player 1 = 15 points of player 1` would make sense, but it should not make sense to say `10 points of player 1 + 5 points of player 2 = 15 points of player 1` -- you should need to cast the points up to some common superclass first, then say something like `10 points of top + 5 points of top = 15 points of top`. And of course, once you start down this rabbit hole, there's tons of other fun things to consider, like the fact that measurements have significant digits (really significant *bits* and a separate magnitude term) and error distributions, and when you combine them, you should really do this the mathematically correct way, which gets... fun.
Have to implement your own caching... that's a pretty core feature missing for a CI service. Looks like they're actively working on it, though. https://devblogs.microsoft.com/devops/adding-caching-to-azure-pipelines/
What about in the case of UI layouts? There are several competing units, such as pixels, inches and cm. What is your opinion of units of measurement libraries in this setting?
I've started using Azure DevOps (with Pipelines) for a new project at my company and have to say I am quite impressed. Still a few minor places that could use some polish, but hopefully time smooths that all out. Glad to see other people in the community adopt it as well!
You're not very often doing computation with those units though. For the most part you write constants, and through flexbox and media queries, the browser does 100% of the calculations.
If they are, what prevents getting them into code and do a little autodetection on startup?
You mentioned that you are using S3 for caching in the blog post. Was egress cost a concern here? I have a few LTS snapshots on my machine that range from \~200MB - \~800MB. If you download these for every build (and if you build every (pushed) commit) then this could quickly add up for busy projects.
&gt; I am currently looking at the lack of adoption of UoM (Unit of Measurement) libraries [...] If you've ever used Haskel UoM libraries Since you want to understand why there is a _lack_ of adoption, wouldn't it make more sense for you to ask people who chose _not_ to use those libraries? In my case, it's because I don't feel like I'm writing the kind of code which would benefit from it. I can't remember the last time I wrote code which involved meters or grams, for example. I'm definitely using seconds, though, and would benefit from writing something like `threadDelay 1s` instead of `threadDelay 1000000`, so I could be convinced to use a library which helps with that.
Started filling out the survey then realized it didn't have the options that were applicable. All the problems with different units I've seen have involved code bases from different developers which obey different conventions on units and certainly won't have all standardized on one UoM library.
This is not what I‚Äôm talking about. F-Sharp took the newtype/phantom type idea and integrated it into the language such that the type-inference engine could infer that the type of an expression `2.4&lt;m&gt; / 1.2&lt;sec&gt;` Was `float&lt;m/sec&gt;` and the value was `1.2&lt;m/sec&gt;` See here for more: https://fsharpforfunandprofit.com/posts/units-of-measure/ F-Sharp is considerably ahead of Haskell in this regard.
Sorry, I was responding to your comment about counts. The original paper on Apps Hungarian describes how Word's source code uses prefixes like "cb" to denote a Count of Bytes, which was distinct from, say, an xl (Layout X coordinate) despite both variables being ints. To use your case as an example, I might write in C: BOOLEAN CPFitsInCarWithCS(int cp, int cs) And if I see it being called like this: if (CPFitsInCarWithCS(cpGuests, cpDrivers)) { /* ... */ } Then I can tell by the prefixes that it's wrong, even though the compiler lacks the ability to enforce this at the type level.
&gt; Are you guys uncomfortable with this piece of C-type code? &gt; &gt; static final double c = 1079252849; &gt; static final double SPEED_OF_LIGHT = 1079252849; &gt; static final double SPEED_OF_LIGHT_IN_KM_PER_H = 1079252849; Nope. Implied units are still standard practice in my industry (point of sale) -- look how UPOS handles weights, for example. The first one probably wouldn't pass code review. The second one probably would. The third one definitely would. Of source, I'd prefer everything be in m/s, but there are almost certainly advantages to these particular units in the rest of the code.
I have never felt the need for this since unit of measurement errors are infrequent and easy to spot as they result in vastly incorrect results. Also, it feels very tedious to write units every in the program.
I have to admit ignorance here. I didn't do the implementation or analyze the costs involved. For the projects which I _have_ rolled out Azure for, I didn't end up using cache-s3.
I would say the most interested users would be scientists, but: - most scientists consider code something secondary in their work; sometimes even a burden - most scientific code is not touched anymore after the article is published which does not contribute to the situation. For those who care about code, performance can be a problem. This is where type-driven approaches for unit checking can be nice.
 NASA lost a satellite bound for Mars when the mid flight course correction rocket burn duration was wrong. Turns out that one contractor used English units and another metric. The two values were close in magnitude; so there wasn‚Äôt any weird behavior during testing. One can assume that someday NASA and DOD will demand that the code they pay for uses units-of-measure.
So we should all carry around pointless units because one project got something wrong that should have been caught during integration testing? I don't exactly see how the effort of carrying around units pays off.
New to Haskell. Best source to learn up to date Haskell?
&gt; Back in September, Microsoft announced Azure Pipelines, a new CI/CD service that integrates with Github, provides unlimited free build minutes, a 20 hour time limit for jobs, and supports all three major platforms (Linux, macOS, and Windows). What's the catch?
Real World Haskell if you want a book, otherwise 99 Problems + one of the Haskell Cheat Sheets (google "Haskell Cheat Sheet") for syntax.
This is a great question, but I second the suggestion to look at F# for reasons why someone might not use units of measure. If your program only has one or two opportunities to tag a quantity with a unit of measure (such as the `threadDelay` example), you may not want to take a new dependency, add that to your packages description, add an `import`, and possibly turn on a language extension. That friction swamps too many opportunities to involve units of measure. As for those of us with more than one or two opportunities per program to benefit from units of measure, any ceremony needed when calling library code expecting `Double` or `Int` is not only a burden, but also an opportunity to introduce bugs in the unit tracking since I am now doing too much of it manually. If I‚Äôm manually tagging the result of library code with units, I need extensive testing to make sure my understanding of the library‚Äôs use of units is correct, and at that point the units of measure in my types are not much better than writing the units in comments. None of these complaints are essential, but they add up to a negative feeling about power vs weight in today‚Äôs Haskell.
You should check [intero](https://haskell-lang.org/intero)
This is pretty much all you need. I also use [https://github.com/lassik/emacs-format-all-the-code](https://github.com/lassik/emacs-format-all-the-code) for code formatting.
thanks guys, I'll check
It's trying to get people tied to their "devops" site which is some sort of experiment in how bad you can make a UI.
I've used [Haskell Programming from First Principles](http://www.haskellbook.com) to help a number of folks become productive and happy users of Haskell.
This topic comes every once in a while. Recently, * [https://www.reddit.com/r/haskell/comments/bb4stn/to\_kata\_haskellen\_evangelion\_learn\_haskell\_the/](https://www.reddit.com/r/haskell/comments/bb4stn/to_kata_haskellen_evangelion_learn_haskell_the/) * [https://www.reddit.com/r/haskell/comments/b9hom1/learning\_haskell/](https://www.reddit.com/r/haskell/comments/b9hom1/learning_haskell/)
\&gt; As I understand it, functions are normally either pure, or with side effects (meaning their runtime depends not only on the arguments). Actually, a function's runtime is the only thing that isn't a side-effect (unless you count non-termination as one). A side-effect means that a function's **result** depends on something other than its arguments, or that it does something besides returning a value. The following are side-effects: * reading from IO (and doing something with it), * writing to IO, * utilizing an randomness (either a "true" RNG like some device the measures radioactive day or something, or a PRNG that's not declared as an input argument), * mutating its inputs, * starting threads, * throwing an exception, * not returning a value (e.g. returning null). &amp;#x200B; If you have a function that's totally pure, then the only thing it can do is take a series of arguments and return a single value, and the arguments totally determine what value that is. Because it can do nothing other than computing a deterministic value, it's said to be referentially transparent, meaning that, if f(2) returns 4, then you can replace any call to f(2) with the constant 4 without altering the behavior of the program. &amp;#x200B; The important thing about the side-effects is that they're invisible, i.e. you, as a caller, have, in principle, no idea that the function will cause them, just by looking at its signature. In contrast, (most) effects in Haskell are visible, e.g. if you have a function f :: IO Int you know that it may utilize IO due to the presence of the "IO Int"-type. If you have another function g :: Int -&gt; Maybe Int you know that it may not return a value (the equivalent to returning null) - though whether it does can still only depend on the Int it gets as an input. Maybe, IO, \[\] (list; non-determinism), etc. are effects - visible effects. As for Applicative vs. Monad, the difference is that monadic functions can decide to change the path of computation depending on the values that they get, whereas applicative computations cannot. For instance, suppose you have two lists of numbers X and Y and you want to add each number from X to each number to Y, and return the list of combinations. You can do this with an applicative in the following way: (+) &lt;$&gt; [1,2,3] &lt;*&gt; [4,5,6] --result: [5,6,7,6,7,8,7,8,9] However, this applicative-(+) cannot decide to abort or do something else if it encounters, say, the number 5 in any of the lists. Each number will be combined with each number, end of store. Monadic computations, however, can do that: combineButFilterOutFive xs ys = do x &lt;- xs y &lt;- ys if y == 5 then [] else return [x,y] --result: [5,7,6,8,7,9], because the 5 from ys is ignored Similarly, you could try to read two numbers from the console: --note: read may fail, but just for example's sake (+) &lt;$&gt; (read &lt;$&gt; getLine) &lt;*&gt; (read &lt;$&gt; getLine) The applicative-(+) can't decide to abort early, so you'll have 2 attempts to read from the console. However, with a monad, you could decide to stop if the first line reads "quit": tryAddButQuitOnCommand = do x &lt;- getLine if (x /= "quit) then return () else do y &lt;- readLine return $ (read x) + (read y)
And you just made my builds twice as fast. Thanks!
It's worth noting that even though throwing an exception is a side-effect, exceptions can be thrown from pure code due to [Asynchronous Exceptions](https://simonmar.github.io/posts/2017-01-24-asynchronous-exceptions.html) and Lazy I/O.
Thanks !
Effectful functions are still pure. It just means that the output type of said function has some kind of IO property, which means you can express code that will have effects on the real world inside of a pure function without side effects. This magic was discovered in [this paper](https://core.ac.uk/download/pdf/21173011.pdf). These "effects" have different laws they need to hold in order for them not to break the properties of composition, and the different laws that they obey are what creates the different flavors of effects, i.e. Monads or Applicatives.
&gt; pointless units Unit Analysis (a.k.a. Dimensional Analysis) is a common tool used by many people that would be impossible without units, so they aren't **pointless**. --- https://mentalfloss.com/article/25845/quick-6-six-unit-conversion-disasters -- a good hit on Google for: loss of life caused by programming errors involving units of measure
In that paper and in similar contexts, "effect" is used with a more general meaning than just side-effects; rather, it refers to whatever extra things are introduced by an applicative functor and/or a monad. The connection is that `Applicative` and `Monad` make it possible to use those things implicitly (think, for example, of how you can interpret a do-block in different ways depending on the instance you happen to be using) without having to resort to actual side-effects. A while ago, I did [a longer write-up on that for a Stack Overflow question](https://stackoverflow.com/a/49132391/2751851), including references. &gt; Is there a difference between applicative-effectful and monad-effectful? As far as usage of the word "effectful" is concerned, I don't think so. Among those who insist on a difference between effectful functors and non-effectful ones, the most popular criterion for distinguishing seems to be sequencing, and both applicatives and monads fit the bill with respect to that.
Use `Map` if the lookup might result in a `Nothing` and the domain is large(ish). How about the following? statement = choice $ zipWith (\x c-&gt; x &lt;$ char c) [Inc ..] "+-&gt;&lt;,." To make the `[Inc ..]` work you will need to pull apart your constructors into something like `data Stmt = Atom Atom | Loop [Stmt]` and `data Atom = Inc | ... | Out deriving Enum`: [Try it online!](https://tio.run/##TZBBS8NAEIXv@yseodBE2/yCNCDqoSAYrOAh5rCm02Sx2Q2bqa3S/x5n0wpe3j525nuzs60ePmm/H0fT9c4zXunEaaH9QLVSaqtZ445dhxXWtsYZDxT0pWHRp13QtRV5PrACtuTNl7EN4kd76BbYtO6YXFM23LGkTGGTCO9cjzIUqv9woJTqvWsKATptvzG7INkshxZTIDvnFzxc7cUUknBsyZOcuDatULfO1CT4j@nfDLeI30@olzlOAkpVe9QJyrBamlaIbpd5tkijKWNKlYwP4iORRTy1z8t58mcrsdMzleq0sdLbe2MZKfrwgYgvO2Q3ILdLEA28NTbCKsvQEN87y2R5GMdSxpYyt6p@AQ "Haskell ‚Äì Try It Online") Of course, you could also just explicitly list the constructors yourself: [Try it online!](https://tio.run/##NVBNT4NAEL3vr3ghTUqV8guAS72QmEisiQfksNIpbIRdsoxSTf87DlQvb2ey72u31eMHdd08m35wnvFCF44L7UeqlVInzRpH7hkpclvjigda8LlhwcfzgrkVePpk2Z0bUC70SgEn8ubL2AbH1k1KDd41hdj02n5jA82uL5Bcs5sq2WToZChEOLXkSU78kVLUrTM1ierHDK@GW4RvF9T7DBcRyq32qHcopWEk/SJpF0m3KLeR9KoQ3O@zJIqD1XNNEc934onIIlzl23K7@x8rGde2SvXaWOEO3lhGjGH5F4S3pyR3IHfeIRj5ZGyANEnQEB@cZbI8znMpsaXkVtUv "Haskell ‚Äì Try It Online")
What you're looking for is mutable state. There are lots of popular options depending what your specific needs are STRef/IORef, MVar, TVar, TQueue, etc. MVar's work a lot like mutexes, as such they can block, just something to be aware of.
In the sense the OP refers to, "effectful" includes things like `Maybe` and `State`, which do not involve IO nor true side-effects.
Oh ok, then it would be the delaying of computation under certain laws I guess. Effect is pretty broad and some languages like PureScript have used it to denote IO types.
Thank you so much! This looks really clean and exactly what I was looking for. I guess I finally have to learn about `&lt;$` and `&lt;*` :p
A pure function can be thought of as taking an environment and producing a value. Anything other than this is a side effect. For example, an imperative function that mutates state can be thought of as taking an (environment, state) pair and producing a (value, state) pair. The side-effect of this function is that it produces something *besides* the value, in this case the new state. (This is related to a field of study called denotational semantics, and specifically [Felleisen's extensible semantics](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.25.5941&amp;rep=rep1&amp;type=pdf).) The most direct embodiment of this in Haskell is the State monad, whose `runState :: State s a -&gt; s -&gt; (a, s)` takes an initial state and produces a value and a new state.
No worries! Here's what's going on modulo type class constraints (these both require a `Monad` while `(&lt;*)` works with `Applicative` and `(&lt;$)` only requires a `Functor` instance): ma &lt;* mb = do a &lt;- ma mb return a a &lt;$ mb = do mb return a Enjoy your brainfuck interpreter :)
In this sense, it basically means "whatever some applicative and/or monad gives you" -- and yup, "effect" does have more than one meaning. [The SO answer](https://stackoverflow.com/a/49132391/2751851) I linked to in my other comment covers that in some detail.
"Effects" is a very broad and informal term, and it's more of a "semantic" thing that you use to give meaning to your types. It's an abstract term for general things you can "sequence" after the other. The important thing in this context is that the notion of effects is "first-class": we implement it within the language (usually), and they are treatable as normal values in Haskell. For example, the effect of "failure" in Maybe is implemented using ADT branches. The effect of "logging" in Writer is implemented using ADT products. Applicative (and Monad) can be thought of as a way of *unifying* the interface of different sorts of "effectful" things. They unify the idea of effects that you can *sequence*. *Applicative* unifies the common pattern of "sequencing" effects one after the other. This sort of sequencing comes up in many different abstract notions of "effects", and Applicative can be thought of as a unifying interface to all "sequenceable" effects. *Monad* unifies the common pattern of "branching" effects. The idea of deciding "which effect" to sequence depending on the results of the previous effect comes up in a lot of different situations, and Monad can be thought of as a unifying interface to all effects where this makes sense. All together, "effects" is a very abstract word that really means whatever you want it to mean. However, a lot of different effects follow the same sort of usage/interface pattern. Applicative and Monad are ways of unifying this common usage/interface pattern that a lot of these things have a notion of. Effects can mean *whatever you want it to mean*, but if the thing you are talking about is "sequenceable", then you can bring it under the unifying Applicative interface. All of this is contrasted with "side-effect", which in Haskell typically refers to effects that aren't manipulatable as first-class values; they are implicit and live outside of the language of Haskell, and are often associated with the underlying runtime system. Under this understanding, side-effects can't be directly unified with Applicative or Monad, since they aren't first-class values.
Interesting! Does this mean `&gt;&gt;` is a remnant of when `Monad` wasn't dependant on `Applicative`? Since it appears to do the same thing as `&lt;*`
It is, but do note the order: `(&gt;&gt;)` is not `(&lt;*)` but rather `(*&gt;)`
Do you consider calls to `error` and `undefined` to be exceptions?
That's how they are implemented, now. But, both functions predate generalized [`throw`](https://hackage.haskell.org/package/base-4.12.0.0/docs/Control-Exception.html#v:throw) (instead of [`throwIO`](https://hackage.haskell.org/package/base-4.12.0.0/docs/Control-Exception.html#v:throwIO)). IIRC async exceptions basically grew out of [`throwTo`](https://hackage.haskell.org/package/base-4.12.0.0/docs/Control-Exception.html#v:throwTo) or before even that, [`killThread`](https://hackage.haskell.org/package/base-4.12.0.0/docs/Control-Concurrent.html#v:killThread)
If UoM libraries are written well, there's actually no machine cost to "carrying" around data, because everything happens in the typechecker.
I posed the question because depending on the answer, the previous comment ranges between 'not even wrong' and 'very misleading'.
You still need conversions when using general purpose mathematical libraries or reimplement them as type-generic functions which opens a whole other can of worms and is some times not possible in a sensible way. You need a language with a sufficiently complicated type system to support lugging around unit annotations automatically. After programming in Haskell for too long, I believe that complicated type systems are not a good idea for professional software development because they encourage programmers to seek complicated meta programming solutions through the type systems instead of writing simple code. Incidentally, three of the most used programming languages for scientific computing (Fortran, C, and Python) do not support complicated types.
"Effect" isn't really well-defined, at least not in my mind. It's primarily distinguishing "effectful" friends from mathematical functions, but in a weird way because representing effects is a lot about finding a different context where there is a mathematical function that can be identifier with the effectful function. Is partiality an event? Is heading up the CPU an effect? Is allocating memory as effect? Is parallelism? Now, *once* you've decided what a is an effect, then defining a side-effect is easy. It's any effect that the compiler / language doesn't track (in the types or otherwise).
If you don' t like enforcing things in the type system, why are you hanging around the haskell reddit!?
I guess you decide to create a thread: https://www.reddit.com/r/haskell/comments/bdiu82/i_want_to_learn_haskell_from_a_book_and_was/ Remember, this thread is for "questions you feel **don't deserve** *their own threads*". You should not both ask a question in the Hask Anything **and** create a new thread for that question.
&gt; If you don' t like enforcing things in the type system, why are you hanging around the haskell reddit!? Laziness? ;)
&gt; If you don' t like enforcing things in the type system, why are you hanging around the haskell reddit!? Because I like to talk about programming from different perspectives. &gt; (also -- you can track units in a really lightweight way for some purposes with just newtypes and nothing fancy at all! just because there are complicated solutions doesn't mean you can't get very important benefits with simple ones too.) If you have the whole machinery of operator overloading and parametrized types, then perhaps. However, there is still the issue that the language needs to support that (also, operator overloading where both operands are of different type with non-trivial semantics for what matches) and that it must all boil away during compilation without inhibiting compiler optimisations. Note that this does not solve the issue of interfacing with libraries not cast in the same unit idiom.
I prefer the zipless alternative for clarity: ``` statement = choice [ Inc &lt;$ char '+' , Dec &lt;$ char '-' , Rgt &lt;$ char '&gt;' , Lft &lt;$ char '&lt;' , In &lt;$ char ',' , Out &lt;$ char '.' ] ```
At some point things get so abstract that we start using the word "effect" to refer to any sort of semantics that any type has that goes beyond just functions and application. At the point you go "huh, it sounds circular to call something an 'effect' just because it's a thing that distinguishes this specific applicative functor from the identity functor" then you've definitely grokked it, IMHO. It's why we talk about `Maybe` or `State` being "effects" even though any computation you can do with them is isomorphic to some computation with pure code‚Äîthey have applicative functors that are not `Identity`.
[https://hackage.haskell.org/package/dimensional](https://hackage.haskell.org/package/dimensional) and [https://hackage.haskell.org/package/units](https://hackage.haskell.org/package/units) are two libraries in Haskell that are relevant to the discussions here.
I ended up writing basically that. This was my final function: statement :: NodeParser statement = choice $ map (\(c, s) -&gt; s &lt;$ char c) [ ('+', Inc) , ('-', Dec) , ('&gt;', Rgt) , ('&lt;', Lft) , ('.', Out) , (',', In) ]
A couple of hours a day should suffice.
* Salary Range: Depends on several factors. I'd be happy to discuss your expectations and circumstances with you individually. * Healthcare: We provide healthcare to our employees, who are expected to make no monthly contribution but are still responsible for co-pays and the like. Employees' spouses and families are covered in the same way. * Vacation: Again, this depends. Some people prefer more compensation others prefer more vacation time, and we're amenable to various arrangements. * Continuing education: We don't have a formal programme in place, but we frequently send employees to conferences and purchase books and other materials that employees request. We recently had a contingent of people at a conference in London, which was nice because several of the attendees were remote and hadn't met in person before! We also have monthly internal tech-talks that employees spend on-the-clock time preparing for, delivering, and attending. For employees who are remote, we also encourage them to visit our office in New York at least once a year and and we cover all the expenses related to such visits. * Other notes: * Sick days don't count against vacation days (though sick leave for extended periods requires some special handling) * Parental leave offered * Flexible work-from-home policy
&gt; A side-effect means that a function's result depends on something other than its arguments, or that it does something besides returning a value. Is't this wrong? A function can return a value that depend only on its arguments, and still cause a side effect, for example, mutating one of it's inputs. Right?
It seems that by "effects", the haskell community generally means the stuff that in implemented in Applicative/Monad instances. For example, for Either type, it is the logic that checks if the incoming value is a Left value, and immediately returning that aborting the remaining operation.
I don't have a strong opinion either way, but I'd love to understand what you mean all the same.
The perception of `error` in the Haskell ecosystem is very different from how exceptions are perceived in other languages. It's different from exceptions in Haskell even. The main distinction is, you're not supposed to use it as part of your control flow. Not even for exceptional control flow. It's there for the cases "This is impossible to happen, but I won't prove it with the type system" (people will call you out on it if you do this out of laziness and not due to your case being particularly hard to model) or "the caller is responsible for making sure the input is in the domain" (people will call you out on it if it is easy to enforce the actual domain via types) in which case you're supposed to call your function `unsafe`.
Looks really clean, nice. Tangent just to provoke thoughts: I waffle back and forth about whether to prefer that (popular) pattern or choice [ f '+' Inc , f '-' Dec ... ] where f c s = s &lt;$ char c It's a minor epiphany that `(,)` is just a particularly generic choice of such an `f`.
I think OP would classify mutating one of its arguments as part of the "function's result"
Let me just say that I've done what I describe. It was simple, with simple types and no fancy typeclasses. It meant that I had to sometimes use different operator names than usual for e.g. scalar multiplication. But it also meant that I was saved from a _ton_ of bugs and confusion at compile-time, because I was working in a system where numbers came in many different magnitudes (i.e. sometimes representing thousandths, sometimes representing hundreds) and with different meanings (absolute values vs. percentages, quantities vs. flows), and making everything explicit let me keep track of what was going on with compiler assistance. So I am not much interested in abstract speculation about why such a thing might be bad or painful to use. I used it, and it was good, and easy to use.
The book you name is certainly one of the most recent and up to date
...except that book is *really* dated now. Kurt‚Äôs *Get programming with Haskell* feels like an upgraded version, with a ton of practical examples.
Even including that in "result", the "result" can only depend on its arguments, and still be impure, right? My point is that pure and `one without side-effects` are slightly different things. A pure function 's return value depends only on it's arguments, and it does nothing more than returning a value. A side-effecting function is one that can return a value and can change the state of the world. A function can depend on some global state, and still might not cause any side effects ie change the global state.
No, depending on global state is also regarded as an effect.
A pure function is one that returns the same output for a particular input. For example, `plusOne x = x + 1` is pure; the output of `plusOne 1` is always `2`, and so on. Another example of a pure function is `divide m n = if n == 0 then throw DivideByZero else m / n`. `divide 4 2` always returns `2`, `divide 12 4` always returns `3`, and `divide 1 0` always returns `bottom`. `bottom` is a value that inhabits every type, and has nothing to do with asynchronous exceptions or lazy I/O. Raising an exception is one way to create `bottom`, but you can also create it using infinite recursion- `let x = x in x` is semantically equivalent to `throw DivideByZero`. Catching exceptions, however, would be a side-effect (that's why it's only done in `IO`). To see why, imagine we tried to write this function: `isBottom : a -&gt; Bool`. `isBottom 1` would be `False`, `isBottom undefined` would be `True`, and so would `isBottom (throw DivideByZero)`. But what about `isBottom (let x = x in x)`? It would spin forever. In other words, `isBottom (let x = x in x)` is `bottom`. This means that `isBottom` isn't a pure function, because `isBottom bottom` doesn't always give the same answer.
Yes, that worked for me too. Wall clock time for a full compile after "stack clean" went from 181 seconds down to 102 seconds, with CPU usage hitting 400% (i.e. all 4 processors fully utilized) and staying above 300% most of the time. CPU time went up from 182 seconds to 217, presumably because of the decreased cache locality you mentioned. I put your suggested GHC options into my project cabal files as I have other options I'm using and I'm not sure how the various ghc-options fields will interact.
Thanks, this is a great answer. Especially the part that talked about the differences between Monads and Applicatives was really eye opening. To make sure I understand it right; Maybe would comprise the *effect* of *failure*, List one of *nondeterminism*, IO of *side-effect*, State of *statefulness* (and Reader and Write of some wonky statefulness), right? &amp;#x200B; OT question; does functor have something to do with effects as well? I understand it is a bit weaker than Applicative; could it be described like "allows you to chain non-effectful functions with effectful ones"? So we'd get: sequencing non-effects with effects -&gt; sequencing effects with effects -&gt; sequencing effects with effects, conditionally. &amp;#x200B; And one more question. Is there something that would come after the "sequencing effects with effects, conditionally" part? I.e. is there something more powerful than a Monad?
Semantically, `IO` is pretty much equivalent to a `State` monad using `RealWorld` as its state, so using you definition of a side-effect as a _"a function's result depends on something other than its arguments,"_ computations in `IO` do not have side-effects, because the state of the entire outside world is given as an argument.
I was about to say that! It only means more people are getting interested in learning Haskell.
By that logic wouldn't that mean that no functions are pure though, since an asynchronous exception be thrown to any thread at any time causing any pure function to return bottom in some cases and not others?
Also, separately, is it correct to think of `bottom` as a single value like that? I mean I know that all of those examples are bottoms, but a) `isBottom` will always return the same bottom given the same bottom... and b) all functions of `a` to anything that attempt to do something with the `a` value (eg not `const`, but `id`, `replicate n`, etc) all exhibit the same behavior (returning different bottoms when given different bottoms).
Just a remark, I read this post and tried to switch our application to compiling in parallel with the \`-j\` flag. &amp;#x200B; Quite surprising, builds started failing! &amp;#x200B; Turns out, when there's Template Haskell involved, things can go extremely wrong. We have a global `IORef` that accumulates functions from \~10 modules. The way this works is that at the start of the module, the `IORef` is reset to empty. Every definition in the module then inserts an entry into this `IORef`. Then, at the end of the module, all the entries in the `IORef` are collected. &amp;#x200B; As you can imagine, once GHC tried to compile these modules in parallel, chaos ensued, where functions defined in one module would be collected in another.
\&gt; A function can return a value that depend only on its arguments, and still cause a side effect, for example, mutating one of it's inputs. Right? That's why I added "does something besides returning a value". I suppose you could classify writing to IO as not being a side-effect if you don't care about the external world (logging would be an example).
I guess "effect" is a bit of a confusing word here, granted, but as I always understood it, reading from global state is a side-effect as well.
I use stack almost exclusively. Also, I turn on intero via \`M-x intero-mode\` only when I need to. Here's the config (just search for "stack") [https://github.com/k-bx/dotfiles/blob/master/dotemacs.el#L473](https://github.com/k-bx/dotfiles/blob/master/dotemacs.el#L473)
Hahaha, you got us!
Correct. This is a real concern in certain multuthreaded contexts. Although, I wouldn't call it "returning bottom". No value is returned at all. And even if we put aside multithreadeness, we will still need to somehow deal with the fact that our process might be interrupted or killed by the OS. So functions can't be *truly* pure in a real world setting. It's a very handy reasoning tool though. Knowing your function can only crash and burn for external reasons (async, signals, hw failure, etc) is considerably better than nothing.
My apologies for having mislead you. In my Sunday morning haze, my reading of your question was that you wanted to store the server‚Äôs state (e.g. running/stopped) on the client. In a single-threaded client, you can use `State` to share this global state within your client. However, since you were obviously talking about a server, an approach like that described by /r/IronGremlin would be appropriate.
&gt; IO of side-effect No. IO of *interacting with external systems*.
I would say that's a bug in your template Haskell, and not anything else.
No worries! From this thread, I've learnt plenty about the state monad (and I did actually end up using it elsewhere!) and I've solved my original issue mentioned here. Even if your reply wasn't directly useful for this problem, it has still been helpful :)
Well, it's certainly a bug once parallel compilation is enabled. &amp;#x200B; I would say that we are abusing TH and it led to an interesting error. Enabling parallel compilation is not something you'd usually expect to suddenly break things. Combine this with the fact that the error messages from the compiler can be very hard to follow to the root cause when using TH\*, it can lead to a situation that's difficult to resolve. Though I'm not complaining, this was a fun bug :) &amp;#x200B; \* Here, for instance, since there were some underscores involved at the start of the variable names, GHC produced an error regarding typed holes.
Sure, we have to understand and account for these things when building systems, but generally speaking when we're talking about Haskell we understand pure functions to be functions that don't have side effects. See [Fast and Loose Reasoning is Morally Correct] (https://www.cs.ox.ac.uk/jeremy.gibbons/publications/fast+loose.pdf).
&gt; In computer science, an operation, function or expression is said to have a side effect if it modifies some state variable value(s) outside its local environment, that is to say has an observable effect besides returning a value (the main effect) to the invoker of the operation. https://en.wikipedia.org/wiki/Side_effect_(computer_science)
https://old.reddit.com/r/haskell/comments/bdk8hq/effects_vs_side_effects/el0qbxl/
&gt; A side-effect means that a function's result depends on something other than its arguments I was addressing this part of your comment &gt;A side-effect means that a function's result depends on something other than its arguments I know that you had followed it by "or blah blah blah..", but that does not make the preceding clause right.
I was taking a look at hode yesterday and quickly found myself wanting to express implication relationships. E.g. if I'm using hode to keep track of a lot of files (notes, videos, papers, music, etc) I would like to be able to say `#video ~/v/lecture.mp4 ##about game_development`. Then I would also want to be able to find it if I'm querying for `#video /_ ##about technology`, but all videos that are about technology shouldn't turn up when querying for game development, of course.
&gt; Regarded by who? For example Flemming Nielson and Hanne Riis Nielson, or like any researcher in PLT in general and effect systems in particular.
&gt; abusing TH :(
You probably understood them wrong...
I see Functor as providing a way to alter values inside a semantic context (where that context my be that of failure with Maybe for example) without needing to worry about that context's semantics. I'm interested to see what other responses you get though!
What is the difference between having a side effect and interacting with external systems?
I felt like I grew as a programmer when I hit the insight you are getting at here, that there is an inside-out and outside-in way of looking at these things. From the outside, `[a]` is just a data structure with lots of elements of type `a`, but from the inside it's a non-deterministic effectful computation that outputs some `a` from a set. I think being able to switch between these two points of view is an important skill if you want to write Haskell effectively. &gt; is there something more powerful than a Monad? Well, every capability you add on top makes your abstraction more powerful (and more restrictive on its implementatoins). You can see `MonadPlus`, `MonadZero`, `MonadReader`, etc. as additional capabilities that impose additional structural requirements on anyone who wishes to implement them. But for some reason they don't *feel* as fundamental as the hierarchy of Functor/Applicative/Monad.
One of the most important takeaways from this is that IO becomes an *effect* (a first-class value) inside Haskell, and *not* a side-effect. In other languages, IO is done as a side-effect; it's not a value that can be manipulated and composed and operated on purely. In Haskell, IO is represented by a pure value. A function like putStrLn :: String -&gt; IO () is a pure function, since it takes a string and returns the *same* IO action every time, for any string (in specific, the IO action that prints that string). A value like getLine :: IO String is a *pure value*: You get the *same* IO String every time you use it. You get the same IO action every time you use it. In Haskell, IO becomes a first-class manipulable value, and not a side-effect. To be specific, IO represents [I/O (input/output) effects](https://en.wikipedia.org/wiki/Input/output). &amp;#x200B; In regards to Functor -- in this context, if you interpret a type as representing an "effect" abstractly, then Functor interfaces like fmap are combinators that are required to **leave the effect** ***unchanged***. So with types like IO, Maybe, Either e, Writer w, State s, etc., fmap is an **effect-preserving transformation**. It's something that you can use on any action to just change the "result" value while guaranteeing that you won't change the effect. fmap for Maybe keeps the failure/non-failure, for Writer w it keeps the long unchanged, for State s it keeps the state unchanged, for IO preserves the IO actions of the original value. This means you can write something like `fmap length getLine :: IO Int` and be able to trust that the resulting IO action will have all of the exact *effects* as `getLine`, but with just a different result value.
That's what I meant, but nicely formulated, thanks! I much prefer the "semantic context" instead of "effect", too.
*Side* effects aren't tracked in the type system.
That's too bad! Hopefully our paths will cross some time in the future.
&gt; Or may be you can provide some citations... ..sure.. &gt; Nielson, Flemming; Nielson, Hanne Riis (1999). Type and Effect Systems (PDF). Correct System Design: Recent Insight and Advances. Lecture Notes in Computer Science. 1710. Springer-Verlag. pp. 114‚Äì136. doi:10.1007/3-540-48092-7_6. ISBN 978-3-540-66624-0. I will even quote the relevant part of the paper: œï ::= {!œÄ} | {œÄ:=} | {new œÄ} | œï1 ‚à™ œï2 | ‚àÖ % ::= {œÄ} | %1 ‚à™ %2 | ‚àÖ œÑb ::= int | bool | ¬∑ ¬∑ ¬∑ | œÑb1 œï‚Üí œÑb2 | œÑb ref % Here œÑb ref % is the type of a location created at one of the program points in the region %; the location is used for holding values of the annotated type œÑb. The annotation !œÄ means that the value of a location created at œÄ is accessed, œÄ:= means that a location created at œÄ is assigned, and new œÄ that a new location has been created at œÄ. The typing judgements have the form Œìb `SE e : œÑb &amp; œï. This means that under the type environment Œìb, if the expression e terminates then the resulting value will have the annotated type œÑb and œï describes the side effects that might have taken place during evaluation. As before the type environment Œìb will map variables to annotated types; no effects are involved because the semantics is eager rather than lazy.
Where do we put these options if using Stack? I tried to put them in `ghc-options` in `configure.yaml`, but that didn‚Äôt work.
So "(A or B)" and "not A" implies "not B"? ü§î
Sorry. Here "effect" seem to mean something else. Sure, you can treat global state access as an "effect" if you want your type system to track it (to guard against it or something). But that does not mean it is a "side effect". https://en.wikipedia.org/wiki/Side_effect_(computer_science) It should have been clear earlier itself what I am talking about when I included this link earlier in the thread..
&gt;So "(A or B)" and "not A" implies "not B"? ü§î "Not A" implies "Not A", No one said "Not B". Do you agree "Not A" then? Seriously. I find this thread quite stupid. So I would like to end it, you can have the last word for all I care...
[removed]
I like this idea a lot, but would likely rename `f` to something like `(|-&gt;)` which is even more readable: choice [ '+' |-&gt; Inc , '-' |-&gt; Dec ... ] where c --&gt; s = s &lt;$ char c But that's a matter of taste, lots of people don't like operators too much.
It is the same thing. &gt; It should have been clear earlier itself what I am talking about when I included this link earlier in the thread.. Wikipedia isn't always that good on advanced PLT stuff. Do you have some more academic source for why you would think there is this distinction, or is it just something you have decided on your own?
I think it just makes sense for them. They own GitHub, so they will push GitHub + Azure Pipelines as an integrated solution. CI support of Windows is not great, so they will try to get people to use Azure Pipelines as a way to encourage better support of Windows. Nobody would jump on board if it was Windows only, so of course they need to provide Linux + macOS support in order to be enticing.
Forgot to mention: dental coverage and commuter benefits in NYC.
&gt; is it correct to think of bottom as a single value like that? It's correct, however I don't know if it's necessary. I suspect that `bottom` is somehow unique, or unique up to isomorphism. A single bottom value is useful analysing strictness. A function `f` is strict in an argument if `f bottom = bottom`. So in your example `id bottom = bottom`, but `replicate n bottom /= bottom` (e.g. `replicate 3 bottom = [bottom, bottom, bottom]`). Having multiple bottom values would complicate the definition of strictness (but I don't know if that's a reason not to have them).
the big apple! the city that never sleeps!
Thanks for this! It's the exact kind of material I'd love to see more of in the community --- "I was doing this,, and then switched to a new library, and here are my thoughts on it."
haskell is too lazy to sleep
omg
&gt; RIO exports first/second from Arrow not Bifunctor &gt; I make frequent use of mapping over Left values with first. I never need the Arrow versions. I‚Äôd agree - bitunctor is way more useful, so I‚Äôll try to get round to opening a PR on that, unless someone gets to it first. &gt; In my opinion, the env style is no better or worse than a constraint on the overall m. There are certainly concrete differences on either side, but I personally don‚Äôt notice either way. I‚Äôm now offloading a bit of head-space to a library, so all things being equal, I call it a win. Re generalizing the m vs the env, I think that RIO‚Äôs way discourages using non-Readerlike transformers such as StateT or ExceptT both of which have unpredictable and unintuitive semantics when combined with I/O exception throwing. The only standard transformer that‚Äôs useful and behaves predictably is ReaderT, and you have the ReaderT already in RIO. üëå
Me too! It‚Äôs valuable for other potential users or non-users but also for the author to receive the feedback and maybe make modifications.
There's a few layers of meaning here that mix in weird ways, so just to clarify: Interaction with external systems is (abstractly) a type of **effect**. It's just one *type* of effect, among many others. However, this effect can be *explicit* (by being a normal first-class value), or it can be *implicit* (by being a side-effect). So the comparison you are making is mixing up different axes of comparison. We have: 1. Interaction with external systems as explicit effects. 2. Interaction with external systems as implicit effects (side-effects). 3. Explicit effects that don't have anything to do with interacting with external systems 4. Implicit effects (side-effects) that don't have anything to do with interacting with external systems. &amp;#x200B; IO in Haskell is #1 on that list. I/O in most other languages is #2 on that list. &amp;#x200B; Here is a table: &amp;#x200B; ||Explicit (values)|Implicit (side-effects)| |:-|:-|:-| |Related to external interactions|Haskell IO|I/O in other languages| |Unrelated to external interactions|Maybe, State s, Writer w|Non-IO Exceptions, etc.|
wow
This looks a lot like encoding effects in an HList, where your `get*` functions are the effects and your plugins are the interpreters. You might be interested in something like [polysemy](https://github.com/isovector/polysemy).
First of all your example expression won't type, you probably mean \`fmap length (Just \[1,2,3\])\`. You could use the following, but it won't pretty print as you wished: &amp;#x200B; \&gt; :set -XTemplateHaskell \&gt; import [Language.Haskell.TH](https://Language.Haskell.TH) \&gt; runQ \[e| fmap length (Just \[1,2,3\]) |\] AppE (AppE (VarE GHC.Base.fmap) (VarE Data.Foldable.length)) (AppE (ConE GHC.Base.Just) (ListE \[LitE (IntegerL 1),LitE (IntegerL 2),LitE (IntegerL 3)\])) &amp;#x200B; There might be some package on hackage which does some pretty-printing, though I couldn't find anything on \[hoogle\]([https://hoogle.haskell.org/?hoogle=Exp%20-%3E%20String](https://hoogle.haskell.org/?hoogle=Exp%20-%3E%20String)) with a quick search.
The closest thing I know of is the GHCi trick described in [this Stack Overflow answer](https://stackoverflow.com/a/40333460/2751851).
Thanks, this is very close.
&gt;I think that RIO‚Äôs way discourages using non-Readerlike transformers such as StateT or ExceptT both of which have unpredictable and unintuitive semantics when combined with I/O exception throwing Definitely a good point. You're right that `RIO`s way discourages those foot-guns, but the trade-off is that it *encourages* running any bare `IO`. With my old `MonadApp` way, I chose not to give it a `MonadIO` instance at all and that forced me to perform any `IO` always within some defined effect member function. With `RIO`, I need to be disciplined about not just `liftIO`\-ing anything anywhere. I totally land on the side of `RIO` in this trade-off, but I wanted to mention it.
That's another perfect answer, thank you. You really have a talent for explaining things! (kind of a shameless plug: would you mind looking [into my new issue](https://www.reddit.com/r/haskell/comments/be1av4/function_execution_gets_progressively_slower/)? I'd appreciate your view on it. It's not as interesting as this one, unfortunately)
I enjoyed reading this article very much, and glad to see it out there. Thank you to the original author. You know something that threw me off from the post though, is this: ``` class HasGitHub env where runGitHub :: ... -&gt; RIO env ... ``` It seems like in the [ReaderT Design Pattern blog post](https://www.fpcomplete.com/blog/2017/06/readert-design-pattern), the `Has` prefix was reserved for typeclasses that are meant to restrict the environment to having some piece of data. For example: ``` class HasUserName env where getUsername :: env -&gt; Username ``` And typeclasses that perform IO would then be prefixed with the `Monad` in the typeclass name: ``` class (Monad m) =&gt; MonadGitHub m where runGitHub :: ... -&gt; m () ``` At the end of the day, a typeclass is a typeclass, and the names certainly don't matter, but I bring this up because this provides a great opportunity to ask the community if I understood the ReaderT Design Pattern blog post correctly. Also, something that may or may not be related to the above, what is a "capability", and where can I read more about it? Thanks folks!
I did not read the problem properly, sorry; but I can see two \`++\` calls on the \`fill'\` function. (++) has linear complexity, it needs to re-create the first list from beginning to end. Maybe using something like \`Data.Sequence\` or another data structure with a faster concatenation operation would make things faster.
I see that a noticeable part of the blog post is devoted to the logging situation in `rio`. I wonder, whether `co-log` can make things simpler or nicer here ü§î * https://github.com/kowainik/co-log
When I tried RIO I remember logging was not obvious at all. Overall RIO felt very complex and difficult to use and sometimes you just want to print something but I couldn't find any obvious way to do so. If you ctrl+f print in the prelude you find nothing for example.
An example. Consider: let x = print 42 in do x; x If evaluating `print 42` has a side effect of printing, this prints `42` once. In Haskell, it prints twice. It takes something outside of evaluating Haskell expressions to note that 'hey this is two `print 42` chained together' and do the actual work.
Compositional Graphical Logic sounds amazing!
Good to know, I'll check it out. Thanks!
Can I write a predicate that will tell me if a datatype is an instance of a class? For example: data A = A hasShowInstance :: a -&gt; Bool hasShowInstance x = ... &gt; hasShowInstance A False The following would clearly work if the datatype was an instance of Show, but if not I can‚Äôt even call the function as I get a compile-time error: hasShowInstance :: Show a =&gt; a -&gt; Bool One idea I had was to parse the data returned by ghci&gt; :i A but it‚Äôs not clear to me if this can be done? Sorry for the bad formatting, I‚Äôm on my phone. PS, a solution of any level of hackery is welcome. Thanks a bunch!
Docs can definitely be improved, and we definitely do this stuff differently from `base`. There are reasons for this around efficiency and correct handling of character encoding, which is [a common problem](https://www.snoyman.com/blog/2016/12/beware-of-readfile). In any event, to address the common use case, we added `runSimpleApp` at some point, so you can now do something like: #!/usr/bin/env stack -- stack --resolver lts-13.17 script {-# LANGUAGE NoImplicitPrelude, OverloadedStrings #-} import RIO main :: IO () main = runSimpleApp $ logInfo "Hello World!" This gives an idea of the bare minimum to fully buy into the RIO approach: * Enable `NoImplicitPrelude` and `OverloadedStrings` * Import the `RIO` module * Set up some environment, with `SimpleApp` being a good choice for simple applications (surprise surprise)
Good point, will try. There's no reason this would gen slower progressively, though, right?
`(++)` only needs to traverse it's first argument, so it's okay to write `a ++ (b ++ (c ++ ...))` since the final list will only be traversed once, but it's not okay to write something that ends up `((a ++ b) ++ c) ++ ...` since any given part of the list would be traversed a number of times equal to the number of concatenations that happen after. This means it's okay to use `foldr (++) ""` to concatenate a list of strings, but not `foldl' (++) ""`, and it's okay to use `(++)` to build lists as long as you don't also use `(++)` to build the left argument.
You need to be careful when using `(++)` to create lists that you don't also use `(++)` to create it's left argument. Tail recursion also isn't much of a thing in Haskell, at least not when dealing with lists and other recursive data structures. If you're building an accumulator that you're then reversing when you reach your base case that's a clear sign that you should just emit your element as you go. I.e, don't write `foo n acc = foo (n-1) (n:acc)` but just write `foo n = n : foo (n-1)` If you need to concat something to the end of a list you can send it in as an argument to the function making the list and have that function just return it in the base case instead of the empty list. I think this is known as the list builder pattern. I rewrote your `fill'` function using these ideas. It typechecks, but since I'm not familiar with your problem I didn't test it so it might put things in the wrong order. fill' :: Int -&gt; Seq -&gt; String fill' n Seq {aa = aa, gaps = gaps} = let result = go (sortOn fst gaps) (zip [1 ..] aa) endString endString = replicate (n - length result) '-' in result where -- Take sorted list of gaps, enumerated list of chars and an accumulator string go :: [(Int, Int)] -&gt; [(Int, Char)] -&gt; String -&gt; String go _ [] end = end go [] str end = map snd str ++ end go gps@((start, leng):gs) ((i, c):xs) end | start &lt;= i = -- There is a gap before this char, "splice" it in -- (++) will traverse the result of the replicate once more -- this can be improved by writing your own replicate function replicate leng '-' ++ (c:go gs xs end) | otherwise = -- The next gap is somewhere after this char, it's safe just to copy it c : go gps xs end
&gt;Wikipedia isn't always that good on advanced PLT stuff. You are saying that the concept of "side effect" is something discovered recently? Interesting....
no
You mention that your algorithm is blazing fast if you do not use the ```fill'``` function. I am assuming that you use some version of Needleman-Wunsch or Gotoh, or some other variant of dynamic programming for the forward phase of your alignment. Are you still forcing this phase? I implement such algorithms by having 2 (or more, if multiple alignment is required) inputs of unboxed ```vector```s. The output of the forward phase will be a flattened array in ```O(n^2)``` or more general ```O(n^k)``` steps. Backtracing should be ```O(n)``` in general and takes roughtly 1% of the execution time of such an algorithm, even accounting for the somewhat slow handling of the list-based backtracing structure. That way, the original inputs are always available as the input vectors, while the backtracing structure contains the information necessary to have the optimal alignment(s).
Would have made more jokes about evaluating the ROI on RIO but other than that, solid write-up :) Definitely took a while to arrive at RIO's exact pattern in Servant, and love that the abstraction exists. Seems like there's some space there to contribute a recipe back for other REST-minded folks.
You are not making any sense. Sorry.
You are the one making **side effect** out to be something special. I maintain that it means the same thing as **effect**. In the end people are interested in distinguishing pure functions from those that have effects. Making up a third category (your side effects) consisting of all effects, except reading of state makes no sense.
Why, oh why, didn't they call it a coconference rather than an unconference?
Actually, I'm doing a kind of evolutionary algorithm and this `fill` is part of my scoring function (it is used when scoring the column-by-column similarity). I tried to use vectors, but as the gaps frequently change (as part of the evolution itself), the vectors had to be copied every time after mutation, and it was really slow.
&gt;Tail recursion also isn't much of a thing in Haskell, at least not when dealing with lists and other recursive data structures. Is that a thing specific to this example, or does it hold in general? E.g. I thought usually it's better to use foldr than to write the recursion by hand (even though maybe not in this case, where I need the list reversed). &gt;I rewrote your function using these ideas Thanks for the code, I'll try it out! Other commenter suggested using Data.Sequence in order to speed up the appending. What do you think about that? Is there any overhead which I'd need to take into consideration? (I already rewrote the code once, to use Vectors; little did I know that they would slow it down ten fold because the had to copy the whole thing at every append. SO I'm asking just to save myself hour(s) of useless work.)
I'm finding it very useful to put together talks on Haskell. Similarly writing documentation for packages that interest me is really helpful for learning new things.
Is ```fill``` part of your scoring function, or do you want to score how good the alignment is? If what you want is always ```score . fill``` it should be possible, I think, to rewrite it in such a way that stream fusion removes intermediates. You should start by writing a function that does not create the aligned sequences but rather calculates their alignment score. However, any details would depend on a more explicit description of what you actually want to do (and that it is not homework ;-)
It is a part of it for now, but I'll change the scoring function soon (the current one doesn't work as well as I hoped it would); the new one will be based on substitution matrix, similar to how Needleman-Wunsch operates. Then it would be possible to always chain `score . fill` together. Are there any specific things that I should have in mind while writing the new scoring function in order to make it eligible to stream fusion? Even some references/pointers are good enough. It's not a homework per se. It's a semestral project for a nonprocedural programming course. I chose the theme; I study bioinformatics, so it seemed cool to do MSA rather than, say, sudoku solver (the usual Prolog/Haskell stuff). It's a little harder than I anticipated, but it's fun!
I was concerned by this as well. As someone who has dreams of jumping from Scala to working professionally in Haskell, this wasn't a great result.
Is the ‚Äò1s‚Äô syntax even currently doable? OverloadedNums would be a nice extension (if even possible)
&gt; In the end people are interested in distinguishing pure functions from those that have effects. Exactly what I thought. Thanks for clarifying. I am out of here.
I am grateful for Scala because it is where all the posers and hipsters are now. If it weren't for Scala they would be here. Avoid success at all costs.
Yes, I just noticed the loop looking at the code myself. As you said, it's an easy fix, just send the desired length instead of the string itself, and subtract in the recursive cases. &gt;Tail recursion also isn't much of a thing in Haskell, at least not when dealing with lists and other recursive data structures. &gt; &gt;Is that a thing specific to this example, or does it hold in general? E.g. I thought usually it's better to use foldr than to write the recursion by hand (even though maybe not in this case, where I need the list reversed). The tail recursive thing is something that holds in general I'd say, though it's not a hard rule. Usually when you're constructing something you want to return a constructor as soon as possible, not accumulate the structure until you've constructed all of it. This way it's up to the consumer of the structure to decide how much of it to consume and it enables infinite structures and other lazy goodies. It doesn't matter if you use the existing fold functions or write recursive functions yourself, that's a separate concern. Foldr is not tail recursive but foldl' is.
Disclaimer: this area is a bit new to me as well and I also had trouble finding my own direction in this regard when I was making the changes I ended up documenting in this post. Setting aside naming for now, the difference between `MonadGitHub m` and `HasGitHub env =&gt; RIO env ()` is an important distinction. A non-`RIO` construction that is the same "style" as the latter could be `(MonadReader env m, HasGitHub env) =&gt; m env ()` \-- perhaps this is a better way to show it, to draw that specific distinction without bringing `RIO` into it at all. 1. `MonadGitHub m` is a constraint on the overall `m` 2. `(MonadReader env m, HasGitHub env)` is a constraint on the environment accessible through `Reader` (which is the only constraint on `m` itself) FWIW, I'd call this "MTL-style vs Reader+Capabilities". A thread above ([https://www.reddit.com/r/haskell/comments/bdy0ba/evaluating\_rio/el1upiu/](https://www.reddit.com/r/haskell/comments/bdy0ba/evaluating_rio/el1upiu/)) does a good job talking about some trade-offs here: With (1) you can easily add more things on `m` such as `MonadState` or `MonadCatch`, which can get you into trouble with unintuitive behaviors if/when you also have async exceptions (which are always possible). This style also needs my concrete `AppT` stack, instead of just `App`. With (2) you're discouraged from that and there is design pressure to stay within something safer, where all your effects are on something you access via `Reader`. `RIO` then just goes all-in on accepting that `IO` has to happen by concretely replacing what might be `(MonadReader env m, MonadIO m)` with `RIO ~ ReaderT env IO`, which is (IME) your only sane (production) instantiation anyway. The second distinction you're drawing is between what I have: class HasGitHub env where runGitHub req :: GH.Request a -&gt; RIO env a instance HasGitHub App where runGitHub req = doTheRealGitHub req And what might be more in line with the ReaderT blog post (see `envLog`), if it were updated to use the `Lens'` approach of the newer `RIO` docs: class HasGitHub env where runGitHubL :: Lens' (GH.Request a -&gt; RIO env a) env data App = App { -- ... , appRunGitHub :: GH.Request a -&gt; RIO App a } instance HasGitHub App where runGitHubL = lens appRunGitHub $ \x y -&gt; x { appRunGitHub = y } bootstrapApp = do -- ... pure App { -- ... , appRunGitHub = doTheRealGitHub } The latter makes the `Has`\-naming make more sense, I agree, but it seems weird to do it this way: * I have no reason to ever *set* `appRunGitHub` on `App` * It's not as "clean" (subjective, I know) to share `appRunGitHub` between `App` and `StartupApp` * Usage is odd: &amp;#8203; something :: HasGitHub env () something = do run &lt;- view runGitHubL run createPullRequest -- vs something :: HasGitHub env () something = runGitHub createPullRequest I could be missing something, but I like my style better. As for naming, `Has` still seems to fit IMO: "This `env` has GitHub" works equally well if the instance just defines the effect runner directly or some `Lens'` to get it. Hope this helps!
Rust has an amazing eco-system I would love for Haskell to have: https://www.quora.com/What-are-the-worst-parts-about-using-Haskell
And a function that relies on some state can't be pure, as its result would not only depend on its parameters, but also on the state. Therefore reading state must be considered an (side) effect, if the term should hold any meaning.
&gt; Can I write a predicate that will tell me if a datatype is an instance of a class? No-ish. Types and classes and instances "don't exist" at runtime, semantically. That said, I think there are a few experiments on hackage that pile on the GHC extensions to the point where it's not really Haskell that do provide something approximating an `hasInstance` predicate.
&gt; When I tried RIO I remember logging was not obvious at all ... sometimes you just want to print something but I couldn't find any obvious way to do so. If you ctrl+f print or putStrLn in the prelude you find nothing. I'm not sure if this is their true intent, but I consider `RIO`'s prelude not a general purpose Haskell prelude but a prelude *for application developers*. And in the interest of encoding best-practices for that use-case, you shouldn't be using `print` or `put*` in an application, you should be using a proper logger. Given that perspective (which, if true, could be conveyed better in the docs), it seems "obvious" to me that you'd want to reach for `logInfo` to "just print something". Trying this may give you the "no instance `HasLogFunc` error message, which may be opaque or frustrating to a newcomer, and from here you'd have two paths: 1. Find `runSimpleApp`, intended as the "Just Works" path 1. Figure out how to give your own `App` logging (1) is featured pretty prominently in the docs these days, so I think if you were to try RIO today, you'd be less confused and might have an easier time. (2) is IMO where the docs are most lacking right now, which is what I focused on in the post.
See, I would've gone for [the Duran Duran reference](https://open.spotify.com/track/43eBgYRTmu5BJnCJDBU5Hb).
he he he...can't stop?
Who?
I'm not enough of an Haskell expert to comment on this, but to me it seems like Haskell does not fit any real niche opposed to other functional languages. Elixir, Clojure, Scala, hell even Elm or functional TypeScript have their own niches, what is one thing Haskell does really well in production?
It's not unusual to get a lot of unexplained downvotes when stating something about haskell, even if it's some undeniable technicality backed up with sources. I sometimes worry that it might be the _way_ it is said (not pedagogically enough maybe?) or that I'm not being relevant enough (haskellers seem like the kind of people who would actually use reddit votes as they're intended). But I've notices that.
I can relate to this. I've only dipped my toes into haskell so far - enough so that it influenced my programming in other languages a lot - but the tooling confuses me a lot. I stumbled across NixOS because of Haskell and switched to it as my daily driver - but I still do not understand "what's required" to start a haskell project (and maybe use some dependencies) and generally get around with the tooling. I know about https://github.com/Gabriel439/haskell-nix but can't really wrap my head around it.
I can think of two areas where Haskell is significantly different from the languages you mention. One thing that Haskell does that none of the above do is build standard Windows and Linux binaries that run fast and interoperate with and link to C/C++/etc. code. (Actually, I guess Reason does this via OCaml, but it sounds to me as if most people are compiling Reason to JavaScript.) A bigger point is that the type system (in GHC, anyway) is far more advanced than Elm, Scala or Reason. (The others are even further behind.) Particularly, once you understand its links with algebraic structures it's a world of difference when it comes to things like control flow and state handling: new control structures are something you code up rather than something built into the langauge. (But perhaps Elm does this to some degree.) But the first isn't very exciting and the second, while amazing and something you never want to give up once you've gotten good with it, is difficult to learn because it's so massively different from current popular programming paradigms. Probably an enormous number of C++ applications would be better written in Haskell, but making inroads in that community is pretty tough. (After all, it's people using C++ in the first place, right?)
[Check this out](https://youtu.be/iSmkqocn0oQ?t=22), Simon Peyton Jones answered himself. The tl;dr is the other bunch of languages in production niches is moving slowly towards Haskell and imbibe its features, but not vice versa.
I strongly disagree. Haskell is very suitable for every thing you might think of regarding Scala, Clojure and even Elexir. In fact, it's better to choose Haskell if you want to make your code really reliable. &amp;#x200B; What about frameworks, consider this one I've created for distributed massively multithreaded applications with concurrent state, logging, DB and other features out of the box: [Node Framework](https://github.com/graninas/Node). I can imagine how much time and efforts I would need to write the same level applications in other languages.
Haskell‚Äôs tooling is quite awful. I‚Äôve tried to install a bunch of dependencies only for stack to do the equivalent of shrugging and giving up. Reading non trivial code is kinda hard. I‚Äôve tried repeatedly to write a backend in Haskell and I always have to contend with out of date code, with a ridiculous amount of syntactic sugar and confusing idioms. The beginner story for Haskell is getting better and better, but intermediate is still very hard. Compare this with Rust where the tooling is excellent, the documentation is overall pretty solid, and the language encourages you to slowly add idioms into your code (don‚Äôt get error handling? Okay just use a match).
Thanks for your reply. Would you mind pointing me in the direction of those packages? I‚Äôve been looking but am yet to find anything.
MSA in bioinformatics is indeed an interesting topic ;-) Going towards substitution based scoring, possibly with affine gap scores will indeed be much better for realistic alignments. Up front, depending on what you want to do, a genetic algorithm for MSA might not be such a good idea, but as a semester project you probably have discussed with your advisor what the topic is to be; and why not trying to get MSAs cheap via some heuristic. That being said, you have inputs ```X_s(i)``` and gaps ```G(k)``` as (unboxed) vectors -- I have "replaced" your inputs structures with something more efficient. You then want to have a ```go``` function that primarily folds over the ```G``` structure. Basically, at each ```k```, you take the tuple of indices ```(k_pos,k_len)``` and score accordingly. Use of ```Unboxed.foldl'``` on ```G``` and ```Unboxed.(unsafe)Slice``` should be fast enough. There is actually a bunch of optimized algorithms for these kinds of things on hackage. ```text-metrics``` has fast non-backtracing levenshtein, and I have lots of things under ```ADPfusion```.
https://hackage.haskell.org/package/ifcxt
nevermind
From the methodology section: &amp;#x200B; \&gt; We used data from last year‚Äôs survey and trends in tags on Stack Overflow to identify which technologies to include on the survey this year. We prioritized popular and fast growing technologies, considering which smaller or shrinking technologies we could remove this year. &amp;#x200B; So I think they considered that Haskell simply didn't have enough activity on SO to be mentioned in the survey at all. Their methodology for determining which languages belong (are people asking a lot of questions on tags) is pretty bad, imho, but there you go.
Nix is neat but it seems utterly unnecessary for using Haskell. Did you actually have any problems with stack?
As for the "motivation" part, I find the topic of genetic algorithms fascinating, so I wanted to try it out, but for the lack of imagination, I chose MSA. I found some papers which report good results using genetic algorithms for MSA, though. The main use case (once I get it to work, that is) will be improving the alignments made by MUSCLE or similar. Thanks for the tips. Currently, I'm storing the original sequence as a String (will change it to Vector Char) and a list of gaps. That's because I change the gaps all the time (as part of `mutate`), so if I only had a String with the gaps already included, I'd have to rebuild it after every mutation. The downside is I have to splice the gaps into the string once I want to score the alignment. Do you think this data model of `Vector Char` and `[Gap]`, with `mutate :: Gap -&gt; Gap` and `score = compareSeqs . splice` is appropriate?
Haskell tooling is either a mess or lacking. Neither are really attractive, which is why I wouldn't create any personal projects in Haskell :/ A real shame, since the language itself is pretty nice.
This would be a nice feature to add to `ghci`
I am not arguing the fact that is suitable, I'm arguing the fact it lacks a clear niche as the other aforementioned languages.
&gt; the type system (in GHC, anyway) is far more advanced than Elm, Scala or Reason Scala's type system is not remotely as clean as Haskell's, but arguably similarly advanced. IME you have the same kind of expressive power in both languages. &gt; new control structures are something you code up rather than something built into the langauge For example, that's something that's done in Scala all the time too. When you write `someOption.getOrElse(e)`, the expression `e` is not evaluated unless the option is empty. All you need to implement that is by-name arguments.
Totally agree. I had a couple critical notes regarding Haskell but decided not to voice them. Instead, I'd really like to see some real world examples. Like running a stack of microservices on top of Haskell.
Unfortunately I saw many times how some people are complaining that "stack is not working", and that makes bad advertisement for stack.
Huh, I'm not super plugged into the Haskell community online, but we use it for a few production programs at work and have not run into any issues with stack. It's lived up to the promise of creating simple, reproducible builds across a variety of machines. We've got people who've never used Haskell building our programs with stack. What I will say is everytime I do peek into the online Haskell community I tend to see a lot of unnecessary political drama and I wonder if that's the source of these "stack does not work" notions.
Yep, you guessed it right. The root of this opinion lies far away in the emotional and political field not in the tech field. There is a dissent in the Haskell community that makes me very sad. This harmful collision of interests is also a source of toxicity in the community.
&gt; The tail recursive thing is something that holds in general I'd say, though it's not a hard rule. Basically the rule is to prefer being productive instead of tail-recursive, but when you can't be productive be tail-recursive. Productive is a short way of saying that all recursive calls are lazy; reducing the result to WHNF would *not* apply the function recursively. Normally, this means the recursive call is an argument is a constructor, but constructors can be strict and they also aren't the only way to be lazy. Of course, if you know that you are going to reduce the result to NF, tail recursion might out-perform productivity. (It also hints that you may need to help out the strictness analyzer, since laziness isn't going to help.) --- reverseTR :: [a] -&gt; [a] reverseTR = reverseOnto [] where reverseOnto xs (h:t) = reverseOnto (h:xs) t reverseOnto xs [] = xs reverseP :: [a] -&gt; [a] reverseP = reverseOnto [] where reverseOnto xs [] = xs reverseOnto xs (h:t) = h' : t' where (h':t') = reverseOnto (h:xs) t --- &gt; null $ reverseP [1..] False &gt; null $ reverseTR [1..] ^CInterrupted. --- (Reverse might not be the best example.) Laziness and productivity compose well. Strictness and tail-recursion (or other totality) compose well. Other combinations compose less well.
Also take a look at [**-ddump-parsed-ast**](https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/flags.html#ghc-flag--ddump-parsed-ast)
Consider not lacing your comments with arrogant, condescending remarks such as "How does that even make sense..?", or "You probably understood them wrong...", or "I know that you had followed it by 'or blah blah blah..'". In addition to being quite unpleasant to everyone else, it tends to backfire if it turns out you were mistaken.
I once did that, you know, being nice and all, and I found that behavior, while appear to help short term, only helps the world at large to become a dumb place in the long... So, may be you should consider doing the same, if you chance upon stupid stuff, in the internet or out of it.. Good day!
ok
Oh, also, [here is a place](https://github.com/mtolly/onyxite-customs/blob/5a106d2/haskell/src/Reaper/Build.hs#L502-L562) in my code where I used Writer in this way. I like the `o` and `x` as function names since they look like bullet points, and of course you can have them take whatever parameters are needed.
And also a good book for me, I'm reading it now (page 70 recursion.... )üòÖ
Not enough activity on SO: Because all your questions about monads and burritos are aswered as nauseam elsewhere ; -) Haskell: no questions left!
Or several Java apps. Or several back-end libraries.
There really should be more community effort towards Frege or Eta.
Umm Type Classes?
And it's *the* truth
&gt; Scala's type system is not remotely as clean as Haskell's, but arguably similarly advanced. With path-dependent types it's more advanced than vanilla Haskell (without some dependent types plugin). Haskell's typeclasses win a lot on clarity vs Scala's implicits (especially when you're emulating Haskell's class A =&gt; B).
One of the biggest reasons for this is probably because Reddit is one of the main centers for Haskell discussions, and Stack Overflow is secondary. Maybe this should be one point of work for the Haskell community?
It might also be worth posting more detail about the larger problem you're trying to solve. It seems fairly likely to me that this is an [XY Problem](http://xyproblem.info/).
Yeah, the nix fanboys derailed haskell ecosystem pretty badly. It is ridiculous to hear advises for haskell newcomers to install nix or even entire nixos just to start programming with haskell. It adds yet another layer of complexity without giving much (if anything at all) to newbees. Most people just trying out haskell should stick to stack as the easiest bootstrap option that works consistently both on windows and on several popular linux distributions, without requiring any additional installs or cryptic documentation. There's also plain cabal that I hear became much more usable in it latest (cabal-new) incarnation. But I know nothing about it.
I think one of my only concerns with RIO is that RIO is a newtype, rather than a type alias. I do understand that this probably makes type errors easier to grok at a glance, but it makes RIO less "automatically compatible" with other libraries. The stronger argument in favor of RIO as a newtype is probably the MonadState and MonadWriter instances that it has (which differ from the (Monad m =&gt; ReaderT r m) instances). But I don't ever hear anybody talking about them, so I have a hard time feeling "sold" on the concept.
Adding on to this, the article mentions that RIO "is not compatible with monad-logger", which makes me wonder why RIO doesn't provide the obvious (instance (HasBlah env) =&gt; MonadLogger (RIO env)). Should RIO be considered a competitor, rather than a compatible library, to monad-logger, in terms of providing logging features?
Haskell is a general purpose language, suitable for almost all tasks, and excelling over other languages for almost all purposes. It does not need a ‚Äúniche‚Äù
There is definitely no need to throw around demeaning language about this. Haskell already had the tooling flame wars, and it didn't make the community better. Now we're trying treating each other with respect and kindness. It's the new in thing.
To be honest - I stumbled across NixOS because of haskell, but did not installed it because of haskell. I just find the concept behind it interesting (and the community is pretty newbie-friendly).
Intero tends to be the mode of choice. If you don't want a full IDE, or need something more malleable and without the vendor-lock, then consider incorporating `stack` with `smart-compile`. The former is great if you want to set and forget, the latter is great if you want quick, repl-driven feedback via a command of your choice (like `stack build --fast`)
Is there any tutorial for using SDL Textures in OpenGL? I haven't been able to find anything showing how to use both at the same time, and whenever I attempt to call SDL.Video.Renderer.glBindTexture I get an error stating that that operating is not allowed. Other than that everything OpenGL and SDL I've tried works fine, including drawing quads, triangles, etc.
I'm basically not used to any dependency management (besides pip, but not really in depth) and somehow do not find the time to get into it. It's not really the fault of stack, it is more a problem of me not being able to use it without reading "much" beforehand. I'd guess the same problem would be existent with cabal.
Indeed. The other languages have lambdas, STM, monads, folds, streams... So the programmers can use these features for their needs without having to endure the condescending supervision of the functional ideologues. I find the haskell community, at least the most visible one, less fun and more repetitive, trying to do the nth reinvention of the wheel and perpetrating the same errors every now an then. Tooling would not be a problem if the language would offer something unique. But would a Java developer pass trough the Calvary of Haskell tooling for having setters and getters, which is the most exciting feature publicized nowadays in Haskell?
Recently I was marking a piece of coursework where students had to write a simple compiler in Haskell. I wanted to perform some automated tests on their code to save doing it by hand. This essentially involved running each student's top-level compiler function on some programs I'd written and comparing their output with mine. I decided to use the hint package to do this, largely because I've used it before so I already had a basic framework for loading in a file, interpreting functions, etc. However, the one thing I hadn't really thought about was `Eq` instances for the datatypes used by the compiler. Some students had defined instances for the relevant datatypes as part of their solutions and others hadn't. I could use standalone deriving to generate the instances that were missing, so all I needed was a test to determine whether the datatypes in a student's file supported the `Eq` instances I required or not. To solve it, I used the catch method I described in my initial question above. This worked but I wasn't happy with it. And so I was hoping for a more robust solution.
Thanks! I'll take a look.
I wrote elsewhere in here &gt; RIO‚Äôs way discourages using non-Readerlike transformers such as StateT or ExceptT both of which have unpredictable and unintuitive semantics when combined with I/O exception throwing and threads. The only standard transformer that‚Äôs useful and behaves predictably is ReaderT, and you have the ReaderT already in RIO. I think the MonadState and MonadWriter instances are neat but I‚Äôm not sure I‚Äôll ever use them. ü§î Maybe, but they‚Äôre not a big selling point.
So you have to create many specialized liftIO's . And this extra work done for no reason, except for having longer type signatures that makes your code more advancy and Haskelly.
Ah, I see. I don't have any better suggestions then, but I actually think the approach you're using is appropriate for this case -- it's not a requirement that you need to test class membership dynamically during the runtime of the code in which the data types are declared, it's a meta requirement that you need to deriving missing instances if they aren't declared and it seems (to me at least) like attempting to compile (therefore implicitly assuming they are declared) and catching to handle the case where they aren't is approximately the right way to do this.
My feedbak about the last frankenstein from Michael Snoyman: Preludes: uninteresting ReaderT: superfluous Classes are not effects. they are interfaces Is pretty: NO. It is ugly and long. Some average haskeller with little experience will find this pretty. But The 10th time that a programmer use your primitives will seriously think in the way to kill you. In the long term you would try to kill yourself using it too. It is also superfluous. See my other comentary here.
&gt;So, may be you should consider doing the same, if you chance upon stupid stuff, in the internet or out of it.. I'm no stranger to that. It's just that I find it is almost never necessary to throw barbs while doing so. In fact, not throwing barbs tends to be more effective, as you avoid wasting energy on petty personal squabbles. Besides that, there is a time and a place for everything. An innocuous thread like this one, where folks are just attempting to clarify a concept, is not an occasion to right great wrongs. We are all on the same boat, trying to make sense of this stuff as best as we can. There is no need for snideness.
I used to hang out on the tag, but the SO interface didn't make it friendly. (Lots of links to outside the tag.) I also have chosen to mostly avoid SO, as it was a bit of a time sink for me.
&gt; But would a Java developer pass trough the Calvary of Haskell tooling for having setters and getters, which is the most exciting feature publicized nowadays in Haskell? Did, and would again.
`&amp;|` takes `(Cursor node -&gt; [a])` as its first argument, and you're giving it a `[ Cursor ]`. I think you should just use `map (attribute "href") (getLinks doc)`. BTW, if you're comfortable with `lens`, I would recommend trying `xml-lens` since it lets you do this kind of thing with the standard `lens` approach instead of custom functions.
thank you so much for the suggestion, I'll try it. yeah I've read about some suggestion of using lens, but I'm not quite comfortable using it yet.
None of the languages you mentioned succeeded. In fact some of them are already showing signs of stagnation and deteriorating use. Haskell on the other hand is getting wider and wider recognition in the industry at large. Haskell is not a niche language, it is a general purpose programming language of the next generation.
Stack Overflow was good 10 years ago, now it is dead in terms of good programmers (for the most part). Currently, reddit is active, but people will migrate away once the beginner programmers rule again.
stack is a cool tool in theory but spending just 10 minutes with rust would make anyone want better than stack, everything just kinda works, it doesn't need multiple articles to explain what everything does to new people, and still seems to have good enough reproducibility for builds (just having version specifiers like rust or even npm seems to go a long way)
I don't think it's a good idea to focus on appeasing Stack Overflow or any other single entity. Although this survey can be influential, it's not a deciding factor in anything other than someone's personal opinion. I think if we focus community efforts on Making Haskell more accessible to the mid level devs, we will see a much bigger payoff. (We've done a good job making it accessible to the beginners already.)
There's pretty much 0 reason I'd use Scala or Clojure for greenfield projects over Haskell. Their only use imo is integrating with existing Java projects. And Haskell is a general-purpose FP language. If I were to write a web service, I'd use Haskell. A game - Haskell (with some pain but still). Command-like tool - Haskell. It works pretty good for lots of things, and the language itself is so much better than every one you listed that I wouldn't consider any of them on language merit alone.
This reminds me of [this tutorial](https://adriansieber.com/ukulele-fingering-chart-cli-tool-in-haskell/) about writing a cli ukulele chord visualizer.
Ooh, interesting post. Seems a little bit inelegant though, especially considering the chord fingerings are hard coded. Although, the chord diagrams from this post look a lot prettier than mine, I might have to take some inspiration.
Thanks. But it's too verbose and still not very clear how the expression evaluated.
Disagree. Eta isn‚Äôt Haskell, contributing to Eta won‚Äôt benefit Haskell. If it weren‚Äôt for the language fork, and instead just a compiler form like GHCJS, then I would agree.
[removed]
You're basically constructing the list in an order, and then going over the entire list again to reverse it. Why not just construct the list in reversed order? I mean, if you're already going to sort it, sort it how you want it to be sorted. Maybe use `Down`? : [https://hackage.haskell.org/package/base-4.12.0.0/docs/Data-Ord.html#t:Down](https://hackage.haskell.org/package/base-4.12.0.0/docs/Data-Ord.html#t:Down) sortBy (compare `on` (Down . riskCreatedAt . snd))
https://wiki.haskell.org/GHC/AdvancedOverlap
This is great. Here's some feedback just after reading `README.md`: 1. It would be nice to allow having a Cherchord config, with a different default instrument, for example. 2. I'm personally used to guitar tabs being printed horizontally. An option to do so would be nice. 3. Is support for [`*sus` chords](https://en.wikipedia.org/wiki/Suspended_chord) planned?
**Suspended chord** A suspended chord (or sus chord) is a musical chord in which the (major or minor) third is omitted, replaced usually with either a perfect fourth or a major second although the fourth is far more common. The lack of a minor or a major third in the chord creates an open sound, while the dissonance between the fourth and fifth or second and root creates tension. When using popular-music symbols, they are indicated by the symbols "sus4" and "sus2". For example, the suspended fourth and second chords built on C, written as Csus4 and Csus2, have pitches C‚ÄìF‚ÄìG and C‚ÄìD‚ÄìG, respectively.Suspended fourth and second chords can be represented by the integer notation {0, 5, 7} and {0, 2, 7}, respectively. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/haskell/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
This is very cool! Looks like you can give it custom tunings. Could be useful for finding chords when I play slide on an open tuning. I guess that gives me a feature request idea: Restrict the number of fingers you can use (I have one or more less when playing slide guitar!)
FWIW, I don't think most Nix advocates recommend it for beginners. I consider it an intermediate or even advanced technique for working with Haskell. I don't start Haskell projects with Nix; I switch to Nix once I want something cabal-install or stack can't cleanly handle (almost always happens; e.g. applying patch files to deps or pinning system libs), or once it's time to deploy (NixOS is the sanest way to deploy IMO).
1. I'm pretty against config files that clutter up the users' home directory, but I'll consider it 2. Currently working on overhauling how chords look, so this probably wouldn't be too hard to add. 3. [Done, thanks.](https://github.com/Aearnus/cherchord/commit/6042f7ea5462b30660b22978940e7a1b47b529f5)
&gt; I'm pretty against config files that clutter up the users' home directory, but I'll consider it The norm is to put it in `$XDG_CONFIG_HOME`(e.g., `~/.config/`) instead of `$HOME`.
Regarding new control structures, I was talking more about things like: remainingCells :: GenParser Char st [String] remainingCells = (char ',' &gt;&gt; cells) -- Found comma? More cells coming &lt;|&gt; (return []) -- No comma? Return [], no more cells This function has state threaded through it, has exception-like error handling, and makes decisions, running different code based on those decisions. It's using an extremely specialized control structure (`GenParser` monad) that was written to take care of all this, so one can just write simple combinators that fit into this structure. Haskell is full of this: you just give the normal case and let custom-written control structures take care of almost all your error handling and other decision making. Specifying "else do this" is done in just one place, rather than over and over again as in other languages. Even this level of stuff gets buried under further layers of abstraction, where you end up with those control structures being used in a full CSV parser that looks like just: csvFile = endBy line eol line = sepBy cell (char ',') cell = many (noneOf ",\n") eol = char '\n' (These examples are not special in any way and probably not even particularly good; I just pulled them out of *Real World Haskell's* [Using Parsec](http://book.realworldhaskell.org/read/using-parsec.html) chapter because that's what happned to pop up when poking about the 'net.)
Sure, but it has literally nothing to do with learning Haskell. It's like recommending everyone switch to XMonad
Honestly I think drive-by complaints like this all over the place are the most annoying aspect of the community
Well this is a fairly depressing thread.
Thanks for your reply! I agree that testing for the existence of instance declarations is the right thing to do. I don't know what else could be done save writing a tool like a compiler plugin. I think my main gripe is with the idea of purposefully generating errors and then catching them. I don't think this is good practice, but I could be wrong? In my implementation, I didn't want to parse error messages and so was blindly catching any error and assuming it was caused by the test function. That's also bad form as what if a different error occurred at the same time? But I'd prefer not to purposefully throw errors in the first place. In case you're interested, the links provided by /u/Syrak and /u/jberryman explain how to implement a test function in a nicer way (in my opinion). Using the ifctx library (linked by /u/Syrak), my `hasShowInstance` function now looks like this: &gt; hasShowInstance :: forall a . IfCxt (Show a) =&gt; a -&gt; Bool &gt; hasShowInstance a = ifCxt (Proxy :: Proxy (Show a)) True False
The fact you're reading r/haskell means that your above an average java dev.
The first step necessary to fix things is to recognize what is in front of the eyes.
Same here! Esp. as it's supposed to be just a platform for Q&amp;A but it too became an opinion shooting range, so we already have reddit for that.
Thanks this is exactly what I was looking for. How "hacky" do you think this kind of approach is?
I thought I'd looked all over Haskell's wiki... Guess not! Many thanks this is exactly what I was looking for.
It is a tragedy of our times that even asking "How does that make sense" is considered as "throwing barbs"! Thanks to that attitude, we have comments spouting stupid/incorrect stuff as top voted comment in a sub dedicated to a language where correctness considered paramount.. &gt; right great wrongs What does this mean exactly?
This is true. What's also true is that you have a very trollish attitude to intersperse reasonable advice with demeaning comments, such as: &gt; the programmers can use these functional features for their needs without having to endure the condescending supervision of the functional haskell ideologues neither the error headaches of the ghc compiler, made for robots I think we could all learn from each other and improve, if we started from a position of curiosity rather than being judgemental. Your trolling doesn't help anyone and is in fact annoying. If you really are a troll, give yourself a pat on the back, mission achieved. Otherwise, please, be better.
Two months ago I tried to get accelerate to run. Gave up after 2 weeks. Since then I always laugh when I read the suggestion to use stack. Closest I got was installing nixOS... In general every few years I check the state of Haskell array computation libraries, notice that exactly nothing has changed, try it anyway and run against the incompatible version wall. Rust's tooling actually deserves the praise it gets (even in this thread), but I don't like Rust :)
As far as understand it aims to be syntax and semantics compatible to a high degree and it can utilize packages already on hackage (which is an important boost vs. Frege in viability for becomming useful in commercial projects). The main point is that by being a JVM language it can be used/introduced in enterprise projects that are built in Java (in theory) quite seamlessly (package for package). I think that's a major benefit for wider adoption. Note, I was commenting on a statement that poinzed out this advantage of Closure and Scala. Eta (ought to) have access to be both to the Java ecosystem and Haskell ecosystem. It's nowhere like production-ready though (also pretty much a one-man project, as far as I understand). Maybe language fork was necessary (human ressources wise) but with crowded brainpower the community could bring it back to standatd Haskell compiling into JVM (language *extensions* are obviously necessary for Java interoperatibility). Disclaimer: I'm not affiliated with Eta, nor did I ever use it in fact).
So you are a hobbyist haskeller who spend the week ends for years to master the many many "modern" and "idiomatic" dialects of Haskell and after those years you return to your office and don't understand why your coworkers stick to Java and don't want to hear about Haskell?
So you are a hobbyist haskeller who spend the week ends for years to master the many many "modern" and "idiomatic" dialects of Haskell and after those years you return to your office and don't understand why your coworkers stick to Java and don't want to hear about Haskell?
I see what you did there! Kudos for the Plato's Cave ref!
no real need to be concerned; this survey result shows reality inaccurately; jobs in haskell are growing nicely, the haskell ecosystem is live and healthy, and haskell fans are more determined then ever - in my opinion
&gt; haskell fans are more determined then ever I don't consider this to be a good thing. In my opinion fanaticism and the [overselling](https://www.reddit.com/r/haskell/comments/8jn95d/state_of_haskell_2018_report/dz2ulw7/) that goes with it doesn't reflect favorably on Haskell's reputation. Instead we should let Haskell's benefits speak for themselves without resorting to touting.
Ooh, is it possible to use such a technique to improve the output of ghci, to, say, print out a type signature hint instead of an ugly error when you try to evaluate a function?
&gt; In my opinion fanaticism and the overselling that goes with it doesn't reflect favorably on Haskell's reputation. First thing to recognize is that there is not a single Haskell community anymore; there are different parties with different agendas, not always aligned. Compiler contributors, type theorists, library authors, software consultancies, vendors, reddit randos, are generally represented by different people, and use different arguments for motivating their use of the language.
On a scale of hackiness from 0 to 10, it's a solid 10 :)
However there are many of us who do use this "messy" tooling on a daily basis, for work and personal projects, so perhaps it's just a matter of trying a bit harder? I don't know, try asking questions or reading the docs?
It's the Weekly Haskell Tooling Pileup !
Is that `Eq` instance only used to test other things, or is their existence itself a part of the requirements (as in, students are going to lose points if they don't have it?) If the former, a dirty but simpler hack than ifcxt would be to derive an instance marked `{-# INCOHERENT #-}`, which will only be picked up if students didn't already derive it.
I really like the approach of taking the output and then deriving an input that \*should\* produce the output, but I'm curious about the likeness with real-world inputs. Your alternating black/white frames are about a significant change as one could imagine between frames, but in the real-world that's not really what happens. For example, as one use case of Komposition is to help recording screencasts, we could imagine that typical input is actually a large desktop where only the mouse cursor is moving, or a few characters are being inserted every *n* frames. I'm curious what your thoughts are on that. Personally, I think I worry too much about testing the system under exact load, rather than targeting individual properties - it's clear that these small tests alone help you derive and maintain at least *some* correctness, I suppose the question is whether that correctness translates over to the user's input.
That's also the biggest issue I have with Haskell (and what also turned me away from Java, and to some extent Python). I use Debian (Linux distro) which already has since the mid-1990s a really advanced package dependency system, but instead of working with the system tools, language packagers feel the need to re-invent the wheel, and in the end you have no native repo for up-to-date tools and libraries, as well as a bunch of language-specific hacks that do a really poor job of package dependency management and can also screw up your system-installed packages. And this is not specific to Debian, either. Other distros and OSes have equally-good package installation systems that are completely ignored by the language makers. That said, I still really enjoy programming in Haskell, despite these avoidable frustrations.
Yes, this is possible: [https://gist.github.com/mathandley/256ba845641660c19071a545b06f256a](https://gist.github.com/mathandley/256ba845641660c19071a545b06f256a) &amp;#x200B; The code above uses the IfCxt library, which can be found here: [https://github.com/mikeizbicki/ifcxt](https://github.com/mikeizbicki/ifcxt)
Looks nice, thanks!
&gt; It is a tragedy of our times [...] I'd say this has very little to do with "our times". It is age-old common courtesy. &gt; What does this mean exactly? That this is not a battleground for the ultimate fate of rationality, or anything grandiose like that. Not treating it as a battleground leads to conversations that are both more pleasant and more productive.
Looking at the traverse function I can't seem to arrive at the type signature using sequenceA and fmap. &amp;#x200B; By definition we have : \`\`\` traverse f = sequenceA . (fmap f) \`\`\` where the signature of traverse becomes: \`\`\` (Traversable t, Applicative f) =&gt; (a -&gt; f b) -&gt; t a -&gt; f (t b) \`\`\` When manually writing the types out (of sequenceA . (fmap f)) by inserting in the composition function: \`\`\` (.) :: (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c \`\`\` I end up getting the type signature - which doesn't match. \`\`\` t a -&gt; f (t b) -&gt; t a -&gt; f (t b) \`\`\` I can't really see how we can get rid of the 't' in 't a' above such that it looks like the signature for the traverse function. I also realised that the same thing happens with (flipped) bind and join + fmap. When trying to derive: \`\`\` (=&lt;&lt;) :: Monad m =&gt; (a -&gt; m b) -&gt; m a -&gt; m b \`\`\` from: \`\`\` bind' f = join . fmap f \`\`\` Can anyone tell me how to arrive at the correct type signature?
Looking at the `traverse` function I can't seem to arrive at the type signature using `sequenceA` and `fmap`. By definition we have : `traverse f = sequenceA . (fmap f)` where the signature of traverse becomes: `traverse :: (Traversable t, Applicative f) =&gt; (a -&gt; f b) -&gt; t a -&gt; f (t b)` When manually writing the types out (of `sequenceA . (fmap f)`) by inserting into the composition function: `(.) :: (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c` I end up getting the type signature: `t a -&gt; f (t b) -&gt; t a -&gt; f (t b)` I can't really see how we can get rid of the `t` in `t a` above such that it looks like the signature for the traverse function. I also realised that the same thing happens with (flipped) `bind` and `join` \+ `fmap`. When trying to derive: `(=&lt;&lt;) :: Monad m =&gt; (a -&gt; m b) -&gt; m a -&gt; m b` from: `bind' f = join . fmap f` Can anyone help me to do it correctly - what am I missing?
The instances were only required for my tests so students didn't lose marks if they hadn't defined them. I tried using `{-# INCOHERENT #-}` but the datatypes were too simple for this to work. For example: {-# LANGUAGE IncoherentInstances #-} module A where data A = A deriving Eq module B where import A instance {-# INCOHERENT #-} Eq A where A == A = True Results in a GHC error about duplicate instances. Is there some way to hack around this?
Thought as much! haha :)
Welcome!
For what it‚Äôs worth, `rio-orphans` provides [this particular instance](http://hackage.haskell.org/package/rio-orphans-0.1.1.0/docs/RIO-Orphans.html#v:-36-fMonadLoggerRIO). I believe it‚Äôs maintained separately to prevent `rio` from requiring a dependency on `monad-logger` directly.
Very good observation and question! I did plan to write something about this, but it seems I forgot. Anyway, I agree that the derived input is not very representative of screencast recordings. What I tried to do at first, with generated pixel values within certain ranges and hitting the edge cases (e.g. 99% equal pixels), was an attempt to generate more realistic input data. The generators became quite complex, and I got into the fun shrinking problems I described in the post, so I fell back to this simple approach with alternating frames as a starting point. &amp;#x200B; That said, having more realistic input would give more confidence. But what would be tested better would actually be the "frame (near-)equality" function, not the other stuff going on in the folding function. Maybe testing the equality function in isolation on more realistic pixel data, which wouldn't even have to care about still or moving segments, just two frames, could be a start. I think in the longer run I'd want to go towards what you're describing even for the full classifier tests, but haven't felt compelled to do so quite yet. &amp;#x200B; Thanks for the great feedback!
Oh damn, I forgot it would be outright rejected. One possible workaround would be: instance {-# INCOHERENT #-} (A ~ a) =&gt; Eq a where A == A = True Yet another idea would be to use Template Haskell, as there seems to be a way to query instances, but I haven't tried it: https://hackage.haskell.org/package/template-haskell-2.14.0.0/docs/Language-Haskell-TH.html#t:Info
Stack is not perfect but it is a big improvement. My primary languages are Common Lisp and Python, but I also really enjoy using Haskell. So, I am not an expert but I tend to only update my projects‚Äô stack configuration every 6 to 9 months. When I do update, I don‚Äôt like to sit at my laptop waiting for all the builds. Once all my projects are updated to new library versions then edit/compile/run cycles go fairly fast. Also, I really do most of my development in ‚Äòstack ghci‚Äô. Also as a 30 year Emacs user, I have switched to VSCode for Haskell editing.
I am fairly fluent in Haskell and I find the code I write to be easy for me to modify, etc. But other people‚Äôs code? I know what you mean, I will start reading someone else‚Äôs Haskell code and it is like running through mud. My advice is to decide what features of Haskell you want to use in your own code, learn the libraries you need, and don‚Äôt try to master Haskell like people whose PhD thesis was on Haskell. Haskell is a fun language but select a subset and have a uniform way to set up slack configuration files for ll your projects.
Ah yes. You are right.
This works a treat! I'll have a look at the TH link too. Thanks again for your help.
Scratch that, you can get the same functionality in two lines using overlapping instances: instance {-# OVERLAPPABLE #-} Typeable a =&gt; Show a where show = show . typeOf
As soon as you need a package that is not in the package set or an older version of that package, things stop working. At least that has been my experience. &amp;#x200B; Maybe I just hit some corner cases or I should have read the documentation better, but it left me a bad impression of the idea of package sets in general.
Well, I spend the weekends and evenings I wanted to and it did take years, but I wasn't in a rush; I put some stuff on Hackage, and used what I learned in Haskell to also learn Agda and Idris and produce some worthwhile stuff there, too. I basically wouldn't call any of it "pains", though I guess GADTs and DataKinds definitely has some sharp spots when I was learning them. I continue to write Java, Python, C, and JavaScript, though I will talk about Haskell to any of my co-workers that has a problem that Haskell's type system (or lessons gleaned from it) might be good at addressing. We deploy to an odd OS, so before this year it would have been difficult to impossible to use Haskell for those deployments, so I haven't been pushing it. We also build on a products with a lot of surface area, so much of Haskell's advantages are counter-balanced by interoperabilty concerns. That said, I have several Haskell programs that help me manage internal resources. I think Haskell actually made be a better programmer overall, *because* sometimes it makes me less happy with my first pass Java/C/Python/JavaScript implementation. And I, plus ESR and John Carmack, think it is a language worth learning *even if* you never use it in production.
Maybe; I was stuck writing Java 6 when Java 9 was the latest release, and even now we can't deploy anything newer than Java 8. There's all kinds of things that I'm at least out of date on, syntax, APIs, modules, etc. Plus, I know that *in my office* there's at least one developer that produces better Java than I do. Part of the reason I like Haskell is because GHC makes me look smart, since it catches so many more varieties of errors at compile time. I try and learn into that -- use types to make as many errors as possible compile-time instead of run-time.
&gt; Maybe I just hit some corner cases or I should have read the documentation better, but it left me a bad impression of the idea of package sets in general. I don't think that should give you a bad impression. It actually leads you toward the primary feature of curated package sets: effort is focused on the experience working within the set. So your experience working within the set is much better, but your experience working outside the set is slightly worse. I thought most of the stackage infrastructure was open source; if your company / you have a different package set you need to focus your effort one (rather than a stackage release), they've given you a bunch of tools to help you focus effort of the package set(s) you need.
The Debian Haskell team is actually doing great, and cabal (old style) plays well with it, or as well as one can expect (similar experience to pip, e.g.). Stack wants either curated experience to be separate from any OS specifics, but I still find it doesn't actually disrupt Haskell (compilers/packages) installed via dkpg/apt, it just decides to install it's own stuff in the project director(y/ies) and ignore what's in the Debian repos.
That's really cool. But it's still a bit weird sometimes, like for `(+3)` it assumes it's an `Integer -&gt; Integer` for some reason, and `id` on its own doesn't work. I've managed to get more-or-less what I want by simply putting the following in my .ghci: instance Show (a -&gt; b) where show _ = "" :set +t which works for both `id` and `(+3)`. The only downside is it spams the type on every output, which is actually not so bad really.
&gt; The Debian Haskell team is actually doing great, and cabal (old style) plays well with it, or as well as one can expect (similar experience to pip, e.g.). True, and my rant wasn't intended to criticise in any way the amazing work that's being done already in this area (especially as I'm not currently contributing myself). &gt; Stack wants either curated experience to be separate from any OS specifics, but I still find it doesn't actually disrupt Haskell (compilers/packages) installed via dpkg/apt, it just decides to install its own stuff in the project director(y/ies) and ignore what's in the Debian repos. Ok, I'm glad about that, but it's still then downloading and compiling multiple copies of libraries for no reason.
I'm mostly uncomfortable because it should be expressed in m/s (it's then defined as exactly 299792458 m/s (and then could have been a long int)), but I'm also uncomfortable that they rounded it when one more digit of precision would have provided the exact number according to the definition (1079252848.8 km/h). I'm also slightly uncomfortable that Java code is classified as C-type code these days.
&gt; for no reason. It is for a reason. It might not be one you find particularly convincing, but it is so that it can be managed by stack, including GHC version, flags, and specific dependencies. I was particularly upset the first time stack decided it wanted to install *the same version of GHC I had just pulled from the Debian repos*, but you just have to understand that part of how stack provides its particular experience is by controlling all those things. It's a trade off; depending on what you are doing the stack way or the Debian way might be better.
I'm mostly annoyed by it building everything from scratch every time, taking a lot more time and resources than downloading binaries would, but I understand the trade off they've made there.
Another thought: I wonder if it would be possible to express the chord search logic in something like [miniKanren](http://minikanren.org/) (which has no maintained or done Haskell implementation I don't think). This would allow you to run the search "backwards." Instead of fixing the input to instrument + chord, you could fix it to instrument + fingering and the same code would be able to find the chord (if any) that the fingering is. For fun, you could also fix chord + fingering and have miniKanren generate tunings :) Reminds me of the classic miniKanren example of writing a type-checker in it. You can then run it with different parts fixed and turn it into a type-inference program (fix program + environment) or a program generator (fix environment + type)
I disagree - this is hardly a core feature. However, did you know that GHCi can support custom user-defined commands (which you can plop directly into your \`ghci.conf\` so that they are always available)?
I thought there was a global cache, so as long as you are using the same stackage release, you can share binaries (and GHC) between projects. But, I haven't used stack a lot.
Pretty interesting. Thanks for the hlint enhancements.. and my natal chart seemed pretty good!
I find I generally have to eagerly alpha-rename type variables so they are distinct or I end up incorrectly unifying. `f :: Applicative f =&gt; a -&gt; f b`; `fmap :: Functor g =&gt; (c -&gt; d) -&gt; g c -&gt; g d` so, `fmap f :: (Functor g, Applicative f) =&gt; g a -&gt; g (f b)` (`c -&gt; a`, `d -&gt; f b`). `(.) :: (x -&gt; y) -&gt; (e -&gt; x) -&gt; e -&gt; y`; `sequenceA :: (Traversable t, Applicative h) =&gt; t (h w) -&gt; h (t w)` so, `sequenceA . fmap f :: (Traversable t, Applicative f) =&gt; t a -&gt; f (t b)` (`x -&gt; t (h w)`, `y -&gt; h (t w)`, `e -&gt; g a`, `g -&gt; t`, `h -&gt; f`, `w -&gt; b`) The substitutions / unifications I did are in parens.
If there's an easy way to implement this in ghci userspace, I'm all for adding it to my ghci.conf!
I wrote "something like" `threadDelay 1s` precisely because I know that this syntax is invalid.
There used to be a solver feature that would use cabal's solver to figure out how to integrate non-packageset deps well into the existing set, but sadly that bitrotted and was subsequently removed.
If the function gets slower, while the size of the inputs stay the same, that may be a space leak due to lazyness (or a compiler bug). You could try strict bytestrings instead of strings.
Thank you for your answer - I really appreciate it. I am however a little uncertain about your derivations because I don't see you arriving at: `(a -&gt; f b) -&gt; t a -&gt; f (t b)` (Which is the type signature for traverse and the type of what GHCI outputs for `fun f = sequenceA . fmap f` and `(sequenceA .) . fmap)`) when inserting your substitutions into `(.)`,I get: `(.) :: (t (f b) -&gt; f (t b)) -&gt; (t a -&gt; t (f b)) -&gt; t a -&gt; f (t b)` Which should simplify to?: `(t a -&gt; f (t b)) -&gt; t a -&gt; f (t b)` Which is the same I got in the first place. However I don't see that your signature for `sequenceA . fmap f` takes a function (`(a -&gt; f b)`), so I might have misunderstood everything.
Why does the base libraries of Haskell not provide a class that \*just\* provides \`fromInteger\`. I propose we call it \`IsInteger\` in the spirit of \`IsString\`? It would be similarly useful to have \`IsRational\`.
I did not like the empty propaganda in that FPComplete report either. But what i said \["haskell fans are more determined then ever"\] is a simple, relevant, objective, true \[IMO\] statement.
&gt; I don't see you arriving at: &gt; &gt; (a -&gt; f b) -&gt; t a -&gt; f (t b) That's the type of `traverse`. But, `traverse f = sequenceA . fmap f`, not `traverse = sequenceA . fmap f` (invalid expression, variable `f` not in scope). My type derivation is for `traverse f` (although it is simple to "undo" the abstract application to derive the type you want) &gt; when inserting your substitutions into (.),I get: &gt; (.) :: (t (f b) -&gt; f (t b)) -&gt; (t a -&gt; t (f b)) -&gt; t a -&gt; f (t b) You've forgotten that I already gave `(.)` both it's arguments. The first argument is `sequenceA`; the second argument is `fmap f`. Drop the first two arguments from the type above and you get the correct type of `sequenceA . fmap f`, `t a -&gt; f (t b)`. &gt; However I don't see that your signature for sequenceA . fmap f takes a function ((a -&gt; f b)), so I might have misunderstood everything. It doesn't, `f` is that function.
A good type class has laws. A great type class has laws that are free theorems.
&gt; Reload it with nix-shell shell.nix. This will need to re-build your Hoogle database, which takes around 2-3 minutes. Note that lorri looks to be a good tool for automatically doing this in the background for you, though I haven‚Äôt tested it out yet. Specifically with functions like `callCabal2nix`, lorri doesn't work correctly as of now: https://github.com/target/lorri/issues/22, which means you'll have to restart lorri manually if you add Haskell dependencies. &gt; I would get through cache issues, installing the [HIE] version corresponding to my GHC version, linking that to my project, [...] I've just recently started a new smallish project for providing HIE Nix builds for all GHC versions (which is in fact non-trivial), as a replacement for [hie-nix](https://github.com/domenkozar/hie-nix) which only provides 2 versions. I hope to finish this soon, it would solve the annoying problem of GHC version mismatches for good.
Particularly by a known troll.
Thanks for the read! &gt;Specifically with functions like callCabal2nix, lorri doesn't work correctly as of now Good to know; I'm assuming that means lorri won't, in general, catch updates you make to your .cabal file without some triggering change in the nix file? If so that's a bit disappointing -- in active project development, there's not much I would want it to reload for me. &gt;I've just recently started a new smallish project for providing HIE Nix builds for all GHC versions I would bet that's non-trivial, but sounds like good work! Are you providing cached versions of all HIE/GHC combos or what? Btw thanks for your help with my past HIE issues.
Why do you want to do this? There are a _lot_ of packages on Hackage - are you sure you want to download them all?
I found this post interesting as it is indirectly asking to improve the state of using declarative programming without the need to think about the many shortcomings we have today. Is there still hope of solving those warts?
The code and tools that run Hackage are all open source. See here for how to set up your own local hackage mirror: https://github.com/haskell/hackage-server/blob/master/README.md In particular, there is a tool there called hackage-mirror that mirrors packages from one server to another. Searately, there is also a tool for mirroring hackage into an AWS S3 bucket (FP complete does this for stackage). It‚Äôs a few years since last update though so your mileage may vary. http://hackage.haskell.org/package/hackage-mirror
I think I understand. But how would I 'undo' the abstract application? The type of `(sequenceA .) . fmap` (no `f` given to fmap yet) is `(a -&gt; f b) -&gt; t a -&gt; f (t b)` According to GHCI. However I don't really know how to handle the double `(.)` when inserting - so that I can check that for myself. I guess I am confused about how the type `(a -&gt; f b)` emerges (`(a -&gt; b)` becoming `(a -&gt; f b)`). Does it just necessarily need to be that way because of what sequenceA is expecting (`t (f b)`).
https://mail.haskell.org/pipermail/ghc-devs/2015-September/009958.html
Lossy, your comment ID had a Happy Number in it! The Happy Number was 91, and your comment ID was el91uds. Here's a link to what Happy Numbers are: https://en.wikipedia.org/wiki/Happy_number, and if you're willing to risk YouTube links, here's a video explaining them: https://www.youtube.com/watch?v=kC6YObu61_w. Comment ID's are unique 7 character strings which identify comments in the sea of Reddit. I'm a bot, beep boop. Downvote to delete this comment.
Something like this would be useful. I just skimmed the proposal so have no comments. You might be interested in https://github.com/timbod7/adl
Does stack make any attempt to make sure the user has the right system libraries installed to build GHC?
[The result](https://identicalsnowflake.github.io/Cantor.html) ([lib](https://hackage.haskell.org/package/cantor-pairing)) of my overthinking the question "which types are really just integers ü§î"
`IsString` is still quite useful for desugaring.
&gt; The gold standard is often said to be something like ReaderT Context IO. You just need the ability execute and mutate The post seems to ignore both extensible effects and mtl-style. These are *the* reason effects are better in Haskell than other languages. This is *the* problem with the ReaderT "design pattern"; following it everywhere results in utterly imperative, mutating code. Ultimately this is why I'm a fan of the [three layer Haskell cake](https://www.parsonsmatt.org/2018/03/22/three_layer_haskell_cake.html). I've never had a serious problem with it, and it's saved many hours.
I do find that a lot of my real-world code ends up imperative-ish in some flavor of transformed IO, but still, as someone once said, Haskell does make a pretty great imperative language. That said, I do think there are places where our entire paradigm just falls flat. Many real-world problems are modeled nicely by state machines, but working with state machines in Haskell is so painful that I often find myself shoehorning my problem into other, less-inspired spaces (*cough* FRP) just to avoid working with them. They just don't "fit" correctly into our programming model, so you end up having to do some hacky thing like making run-time assertions to verify that you actually put the pieces together in the right way, and writing code like that is a poor developer experience. It's frustrating because there is already a rich taxonomy of state machines and graphs, but I don't know of any nice way to tap into those ideas using our infrastructure. I want a compiler and type checker that will making working in those ecosystems pleasant.
&gt; but working with state machines in Haskell is so painful that I often find myself shoehorning my problem into other, less-inspired spaces ( &gt; cough &gt; FRP) just to avoid working with them Could you elaborate on this? In my experience, state machines have been really nice to represent in Haskell, and FRP has frequently made for a wonderfully declarative expression of these kinds of problems.
&gt; I do find that a lot of my real-world code ends up imperative-ish in some flavor of transformed IO, but still, as someone once said, Haskell does make a pretty great imperative language. I feel the same to an extent. I am currently writing scheme interpreter using the wiki tutorial "Write Yourself A Scheme in 48 Hours." This is my second Haskell project as part of learning Haskell and FP. I am facing difficulty wrapping my head around the transformed IO. Most of the functions deal with `IOThrowsError` which is not something I want. Having tinkered with Clojure in the past, my biggest takeaway was to have clear boundaries between pure code and impure code(mainly IO). It's not as easy as it sounds as its a fine line. Right now my aim is to refactor the codebase and code that's dealing with my logic, as pure as possible. When I started with Haskell I felt that may be I'm not handling IO operations properly or Exceptions for that matter. But when I see the code for Scheme interpreter too, it gives me the same feeling. I still think I am not right and that there's better way to deal with IOs and error handling in Haskell, where you can write series of pure functions and in the end feed it to an impure function at the boundary of your program. I would love to know thoughts from experienced Haskell developers on how they deal with these pain points when writing Haskell code.
Does anyone know of a simple, "Hello World"-type tutorial for using cabal (with the v2- commands ideally) to build a project that uses c2hs? &amp;#x200B; I've been banging my head against unhelpful error messages for a few hours now, and once I've simply got something incredibly simple to build, then I can go from there.
Really? I've never been able to model even simple things successfully with it. I always end up having to handle signals from widgets I know shouldn't even be on the screen, having nonsensical empty values in my signal types etc. etc.. For example, a radio button set might start out empty, but once a value is selected, it can never return to the empty state, but this is never (in any FRP system I've tried) properly expressed in the data model - it's just some unencoded metaproperty that this `Signal (Maybe a)` starts out `Nothing` and eventually becomes `Just _`. In contrast, an actual state machine should have no difficulty properly representing this. Further, a properly-encoded state machine would be inspectable. I should be able to look at my little diagram I've encoded and assert (ideally, prove to the compiler!) "there is a path between state A and state B", or even ask stuff like "what is the shortest way a user could get to screen B from screen A?" But even without worrying about that, to me the fundamental abstraction of FRP focuses on all the wrong things (which, to be fair to FRP, is no fault of its own - I think it's just improperly applied to domains it was never intended for). The formalism is based on something like a function from `Time -&gt; a`, and that looks nothing like the semantics an unbiased viewer would expect when looking at an app design. The original app designs I receive typically look like a bunch of screens connected by arrows. That looks like a graph. There's no "time" variable anywhere in there, and I think an unbiased observer would be puzzled why we should even mention such a thing in our coding model. Finally, and this is my own personal quirk, I have a strong interest in truly declarative, JavaScript-less interfaces (partly intellectual masturbation, but partly because I detest the things sites tend to do when I enable JavaScript). My crowning achievement is this [playable Sudoku in pure CSS](https://identicalsnowflake.github.io/sudoku.html), which is generated from a state machine model. My original attempts to model even simple widgets in Haskell fell flat (I couldn't even get past a click-through permutation widget), as my typeless attempts were too buggy to even debug, and my attempts at type-safe state machines using singletons and indicator types crushed me under their weight (it's not called hasochism for nothing!). I ended up doing all the state machine modeling in Agda, where it does at least work nicely, but I'm not happy with it living there because none of my other software lives in Agda, so I can't actually get what I wanted - a unified web framework (backend + frontend) with no JavaScript. *sigh* Someday.
I like the critique on Haskell, especially on Haskell limitations. To overcome these we need more "alienation" through better theory - I'm looking at the "free revolution". What it is not acceptable is relapsing into old habits, imperative style, unsafePerformIO, IORefs, STRefs kind of doing things
Yeah I hope this issue with lorri can be fixed at some point, I'm not using it because of this. And yeah, this project of mine will provide cached builds (for Linux, Darwin maybe too) of all GHC versions along with some functions to select the versions you need and combine them into a single derivation.
No. We rely on GHC's build system to indicate missing or invalid programs and libraries.
Have you seen https://github.com/isovector/polysemy ? What do you think of it? It looks pretty cool to me, and I'll soon give it a try
If you look closely he is the top commentator on the associated reddit thread ;-)
I'm having trouble understanding the three layer Haskell cake, this blog stops short of actually assembling one. Could someone kindly point me to a simple instance of this in action?
Ah thanks! Thread for reference: https://reddit.com/r/haskell/comments/bbqzrd/ann_polysemy_higherorder_noboilerplate_zerocost/
More than 5 years ago, if I had to pinpoint 3 pain points in Haskell, I would have mentioned: * Records * Monad transformers * Too many string flavors I am amazed that somehow what were vague intuitions still hold today ;-)
This is in Purescript, but it's *very* well documented and explained in associated blog posts. https://github.com/thomashoneyman/purescript-halogen-realworld
In case you are interested in some tech details: controls by knobs: 1 - master volume 2 - kick - crossfade between two patterns 3 - degree of drum complexity variatins (bbcuts mix) 4 - clock ticks volume 5 - mid-pads volume 6 - high pads volume 7 - play pad or arpegios 8 - x second row 9 - pads - volume and volume of low-deep pad 10 - kick volume 11 - snares and hats volume 12 - atmospheric noises volume 13 - cut off of filter (affetcts pads or arpegios, moogladder) 14 - play major or minor chord 15 - change the timbre from mild to raw analogue 16 - resonance of the filter
I've made this synth to support the piano performance. The idea was to make knobs-only continuous synthesizer. So all transitions happen with knobs. I was wandering how far I could take this. I've reocrded a demo of it and I'd like to share it with you. All sounds except clock-ticks and kick, and snare glitches were synthesized with library csound-expression and synth Csound under the hood. I've actually played with it live with piano as a solo instrument. In case you are interested in some tech details: controls by knobs: 1 - master volume 2 - kick - crossfade between two patterns 3 - degree of drum complexity variatins (bbcuts mix) 4 - clock ticks volume 5 - mid-pads volume 6 - high pads volume 7 - play pad or arpegios 8 - x second row 9 - pads - volume and volume of low-deep pad 10 - kick volume 11 - snares and hats volume 12 - atmospheric noises volume 13 - cut off of filter (affetcts pads or arpegios, moogladder) 14 - play major or minor chord 15 - change the timbre from mild to raw analogue 16 - resonance of the filter
thanks!
Which Haskell library are you using to interface with csound? Pads are nice.
&gt; But how would I 'undo' the abstract application? If `f x :: a` when `x :: b` then `\x -&gt; f x :: b -&gt; a` and since `f` and `\x -&gt; f x` have the same type (eta-equivalent), `f :: b -&gt; a`. &gt; I guess I am confused about how the type (a -&gt; f b) emerges ((a -&gt; b) becoming (a -&gt; f b)). It doesn't. You can't pass just any function as the first argument of `traverse`. It has to be an `a -&gt; f b`, not just an `a -&gt; b`. I covered the unification for passing an `a -&gt; f b` into `fmap :: Functor g =&gt; (c -&gt; d) -&gt; g c -&gt; g d` in my first reply. Now, it turns out that you can pass some unusual stuff through there, since the `Applicative ((-&gt;) e)` instance exists. &gt; However I don't really know how to handle the double (.) when inserting - so that I can check that for myself. "pretend" it's two different values, alpha-rename the types do all the variables are distinct, and plug through the same way you'd go if there weren't two calls to `(.,)`.
Mostly, which way is up? Is layer 1 the innermost or outermost layer in this cake? That is, would we have something in main that calls, main = runAppT myApp Where \`myApp\` is a Layer 1 AppT from the blog. Or is it the other way around?
&gt; Haskell l I use csound-expression: https://github.com/spell-music/csound-expression
Nice! I wonder if it can be a extended with binary tagged field encodings.
actually pads are synthesized with haskell code too) only I've prerendered them to files to save some CPU
Historical reasons. Though, there is GHC proposal for that: * https://github.com/ghc-proposals/ghc-proposals/pull/124
Yes! I plan to implement this -- a way to indicate transitive relationships, and also symmetric ones, and then make queries that use those facts. I'd also like to encode a way to search over "synthetic relationships" that aren't encoded, but can be deduced from, the data. (I don't really have a roadmap for getting synthetic relationships, but for transitive and reflexive ones I do.) Would it be more proper Reddiquette for me to post updates on the state of Hode here, rather than in new posts?
I read this as a pop-up warning
While the OS/distro dependency tools are fine for handling dependencies for particular releases of apps that the OS/distro vendors want to distribute to users, they're utterly inadequate for actually developing those apps. This is why _every_ language and ecosystem has its own tools for this: * C/C++: CMake or whatever, plus invariably a lot of extra custom build system code for the application * JavaScript: Node/Yarn/whatever * Python: Pip/distools/setup.py/etc. It may not make sense, but application development is a very different world from application distribution. You want Stack to do your development in Haskell so you don't have to worry about what's on your particular OS, and the OS/distro vendors will deal with making it work on their OS with the dependencies they want to include.
You mention you have been learning it. But have you been using it? I started learning it a year ago (give or take) and after a few months I thought I was now familiar enough with all the concepts you mentioned. And I also had this feeling of "So what?". That was until I started actually coding applications (web apps, CLIs...) in Haskell. I hit the second Haskell wall: using it to solve real world problems. I knew what an applicative was, yet I never saw where to use those. Same for monads. Same for purity. Same for many other concepts. It took me some additional months of actively coding in Haskell to feel more confident. And now I think I see the effects you mentioned (though I'm definitely on the noob side of the spectrum). It helped me A LOT for my other projects (mainly Java). I always try to separate side effects from pure code as soon as we start discussing architecture, and up until we code every single feature. I use property tests and applicatives (yes, in Java) on a daily basis. Interestingly, my Java team even started reinventing the concept of Reader/State monad without knowing what a monad is, just by applying together basic things like immutability I helped them getting familiar with. They also started looking for an easier way to apply nested changes to immutable structures in an easy, composable way. Imagine their reaction when I explained lenses to them! This is all thanks to Haskell and my months of coding real world applications with it, more than theory learning. If you've already used Haskell to solve real world problems and still don't see any benefit from it in other languages, I'm sorry, this won't help you :( Side note: now my team is slowly migrating our Java codebase to Haskell ;-)
Let's put it this way: the three-layers idea is good and works (thanks god we've come up with at least something that works), but is not obvious, as you can see just from the comments below. And the obvious things (and they are often also reasonable things imo) about monads that "should" work do not work well. That's the main point of the post. But after all, it's just a rant, I'm surprised it ended up here :-P
Thank you for taking the time to write such a detailed response. Learn something new every day!
I'm not sure what is the total size of all the stuff and I'm not sure whether I have enough space on my Mac, If you know the total size, plz let me know. if 100GB, then obviously I don't have enough space on my Mac for that,
!remibdme 3h
!remindme 3h
Just wanted to say I came away with the same confusion, I've not yet found the time to just have a go and work or out myself!
I will be messaging you on [**2019-04-19 20:26:19 UTC**](http://www.wolframalpha.com/input/?i=2019-04-19 20:26:19 UTC To Local Time) to remind you of [**this link.**](https://www.reddit.com/r/haskell/comments/bezf4b/help_support_chs_files_with_haskell_ide_engine/ela63ek/) [**CLICK THIS LINK**](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[https://www.reddit.com/r/haskell/comments/bezf4b/help_support_chs_files_with_haskell_ide_engine/ela63ek/]%0A%0ARemindMe! 3h) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete Comment&amp;message=Delete! ela684u) _____ |[^(FAQs)](http://np.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^(Custom)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^(Your Reminders)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List Of Reminders&amp;message=MyReminders!)|[^(Feedback)](http://np.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback)|[^(Code)](https://github.com/SIlver--/remindmebot-reddit)|[^(Browser Extensions)](https://np.reddit.com/r/RemindMeBot/comments/4kldad/remindmebot_extensions/) |-|-|-|-|-|-|
I may be in the minority here, but I'm not sure learning Haskell makes you a better JS, java, python, etc. programmer. And if your team or projects rely on languages other than Haskell than you might be better off just learning more about their wider ecosystems. Learning Haskell has been more of a sickness for me than anything. It struck me so deeply that its "The right way to program"^(TM) that it makes it really hard for me to go back to Python or anything else. And since a large part of being a better programmer is being able to collaborate with others and no one I know ever wants to start our next project in Haskell, well... &amp;#x200B; That said, and again I'm not sure how much the following translates to other languages, here's some things that made me a hopeless Haskell zealot. Some good entry level reasons for learning haskell as an end in itself. * map, filter, fold: No more for loops. I had just debugged a MATLAB program which did a filter type loop and got the indexes mixed up. It would have been avoided using a higher order 'filter'. * Types: I think it was a R. Hoare quote to the effect that "program logic follows the structure of data". Haskell was the first language I saw that made good use of Sum types and it blew my mind. Following this, learning to pay proper attention to type signatures was also illuminating. Designing Haskell data types and functions for processing them is a great way do decompose a problem. This might actually be something that helps in other languages too, though you'll probably be forced to use less expressive types. * Theory: You can't get far in haskell without encountering some references to a journal article in the docs of a library. I don't need any convincing that a mathematiclly based technology will be more robust and powerful, long run.
&gt; Ultimately this is why I'm a fan of the three layer Haskell cake (a combination of the ReaderT pattern and mtl-style or extensible effects). Haskell: making easy things hard and hard things hard, since 1990!
Slowly
Types. Types, types, types. In pretty much every intro language that's taught these days (I'm thinking Java, C++, Python, &lt;something&gt;script, or Matlab/R), types aren't heavily emphasized. They're either only considered when the program errors at runtime or some pretty piece of decoration that stops your program from compiling. Even if this isn't particularly true, that's basically how it's treated in every introductory course I've seen: the reason your program won't compile is because you need to add the `const` keyword here, yes it's annoying, no there's no really good reason to do this aside from the fact that &lt;some standard library function&gt; requires it. Haskell is certainly not the only language that has this feature, but it was the first language that taught me to think of a program in terms of types instead of code. In a simple Haskell program, you can often work out what code should go somewhere just by figuring out what the type of the transformation is. This is something that nobody ever taught me in my classes, and would probably have taken me many years to learn in a language like C++, but in Haskell, it's almost a natural way to program.
"[T]he time I‚Äôve spent wrestling with [Haskell] has not been wasted; it has challenged my preconceptions, shown me some possibilities I hadn‚Äôt seen before, forced me to develop a practical grasp of some concepts [...] that were previously only theory to me, and in general shook up my thinking. That‚Äôs valuable in itself." -- [Eric S. Raymond](http://esr.ibiblio.org/?p=1796) --- John Carmack talked about it in his [QuakeCon 2013 keynote](https://www.reddit.com/r/haskell/comments/6uarai/john_carmack_on_reprogramming_wolfenstein_3d_in/). --- "This is the 'intuition of functional programming'. With this intuition, you can see any problem and think of it as a series of small functions, the result of the combination. If you can fully grasp this method, you can realise the maxim, 'Big things become small[...']" -- [Audrey Tang](https://www.techrepublic.com/article/famous-developers-reveal-the-programming-languages-theyre-glad-they-learned/) --- Write in C, write in Lisp, write in Haskell, write in C#, write in Groovy, write in Agda. Experience the multi-dimensional spectrum, and expand your toolbox, so that when/if you get to choose the tool, you pick the best one, and don't (unknowingly?) compromise. Haskell is the most practical language with pervasive non-strictness, so I feel good recommending it even if I don't know your programming history.
`esqueleto` uses a type class to classify most if it's functions. However, removing the type class appears to have nearly 0 problems. Due to the way the fundeps are aligned, it would appear to be impossible to reuse any part of it to eg write an instance of `Esqueleto` for a non-`persistent` SQL backend, or to have `postgresql` specific queries. The type class also offers UX problems. I'm running into an issue at work where the type is somehow getting fixed to `Esqueleto Ratio SqlQuery SqlBackend`, which is causing a massive cascading error. Concrete types would fix that right up.
"Fascist typing" I've never heard a more accurate way to describe Haskell's type system.
here is the best book [http://learnyouahaskell.com/starting-out](http://learnyouahaskell.com/starting-out)
Awesome! No idea about the reddiquette. Maybe time to start a new sub? r/hode seems available. Though I don't think r/haskell would mind updates every now and then, maybe, I'm not a regular here. If it's ok with the sub rules I guess you'll get an indication from up/down-votes as you go.
Are you asking about the source code that runs and operates the hackage server, or are you talking about the source of all of the libraries hosted on hackage?
Recursion schemes are a neat way to approach this... f = (. delta_gaps) . (curry . ghylo distCata distFutu alg $ uncurry coalg) where alg Nil = [] alg (Cons tstr (Identity dstr)) = tstr ++ dstr coalg str [] = Cons str $ Free Nil coalg str ((n, m):t) = Cons tstr . Free . Cons (replicate m '-') $ Pure (dstr, t) where (tstr, dstr) = splitAt n str delta_gaps :: [(Int, Int)] -&gt; [(Int, Int)] delta_gaps = (ana (uncurry coalg) . (,) 0) . sortBy (comparing fst) where coalg _ [] = Nil coalg n ((m, c):t) = Cons (m - n, c) (m, t) un_delta_gaps :: [(Int, Int)] -&gt; [(Int, Int)] un_delta_gaps = ana (uncurry coalg) . (,) 0 where coalg _ [] = Nil coalg n ((m, c):t) = let n' = n + m in Cons (n', c) (n', t) It still uses `(++)` but the way the algebra is applied it will nest correctly. `un_delta_gaps` is not needed, but might be of use. GHCi&gt; f ['A'..'Z'] [(n,n) | n &lt;- [1..25]] "A-B--C---D----E-----F------G-------H--------I---------J----------K-----------L------------M-------------N--------------O---------------P----------------Q-----------------R------------------S-------------------T--------------------U---------------------V----------------------W-----------------------X------------------------Y-------------------------Z" it :: [Char] (0.01 secs, 727,248 bytes)
&gt; they're utterly inadequate for actually developing those apps. Having been on both sides and in the middle (need to distribute someone else's library to a someone else's OS), that's just wrong. CPAN, CRAN, PyPI, Hackage, and all the rest could be easily replaced by apt and apt-src repositories and dependency resolution, even local builds from source would work fine. The .cabal files (or equivalent) are basically is same as dpkg control files, which is why Debian can often get to a point were packaging of "pure Cabal" packages are mostly one command + testing. &gt; It may not make sense, but application development is a very different world from application distribution. Again, having been on both sides and in the middle, it's really not. It's dependencies (both build and runtime), version ranges, too many assumptions, and actually not that many flags that matter. The build tools do change, but dpkg is neither tied to nor does it replace 'make' (or `ghc --make`), and neither is rpm or nix. The real problem is that using an existing package management framework is seen as being OS-specific, even though RPM/Yum/etc. and Dpkg/Apt/etc. are not really tied to an OS. Also most developer still are using MS Windows and Mas OS X which don't have package managers so they aren't actually that used to using them. They are primarily focused on global installs, and developers benefit a lot from local environments to which things are individually installed, even if there's a shared cache; but, both rpm, dpkg, and nix can be used for source-based installs in a scoped environment. As a Debian user, I gotta say that I think RPM would actually be the best package manager for your next language. (It seems like more of the RPM internals have been turned into library calls; the command line is a great interface for users, but it's actually a pretty poor inter-program API.) You may have to wrangle it a bit, but *please* don't create yet another package manager for your new hot language; shape an existing one.
Thanks, I will look into it. The reason I don't see the connection is that I don't think the plugins are monadic effects (they are not even functors). The plugins are just values which I want to compose and index in a type-safe way. And I believe that libraries like polysemy deal with monadic effects just like mtl does. But maybe there is indeed a connection that I am missing. I was looking more at libraries which implement extensible data types, such as compdata and vinyl and HList.
Why JSON-specific? I would guess it's possible to do this for any data type.
The choice for nix has nothing to do with stack (stack or cabal both works with or without nix). I do find confusing and awkward that there are two different command line tools (stack and cabal). It has been argued many times that both tools are complementary. I still hope that one day both will fusion behind a single interface (IIRC it might happen but it won't be soon).
It does seem like using an invertible grammar per version instead of the migrations, would nicely compose given they form a category. There are already many quite general examples in the wild of this, including libraries such as `boomerang` and `JsonGrammar`. A more modern generalisation as well a S-expression implementation: * http://hackage.haskell.org/package/invertible-grammar * https://hackage.haskell.org/package/sexp-grammar JSON grammar: * https://hackage.haskell.org/package/JsonGrammar * Andres L√∂h: Write one program, get two (or three, or many) - https://www.youtube.com/watch?v=w43kve1zeoI The 'original' paper: * http://hackage.haskell.org/package/invertible-syntax * http://www.informatik.uni-marburg.de/~rendel/unparse/
Yes, that's the whole "we're different and special and we need to be treated specially" problem. No, you're just software and can be treated just like any other software and the solutions for which have already been solved many years ago.
This video would have been much easier to watch without the 2005 era video effect
I'm a novice Haskell programmer. I've more or less hit a wall trying to understand HTTP + Aeson, but I've managed to make a few useful CLI apps. My biggest takeaway that I've applied to other languages is functional purity and reducing/eliminating state altogether. I really like [this article written by John Carmack](http://gamasutra.com/view/news/169296/Indepth_Functional_programming_in_C.php) on the subject.
I'm almost certain it would be too much for a reasonable computer (although I don't know for sure). Why do you want to do this? This sounds a bit like an [XY problem](http://xyproblem.info/) to me.
Please indent your code by four places so that reddit preserves its formatting.
done, Just figure how to indent code in reddit, it is very non OBVIOUS how to indent code.
&gt; it seems to me the author tried to define Three functions: &gt; &gt; 1. (.*.), prefix operator &gt; 2. `on2`, infix notation &gt; 3. f , just ordinary function No, that code only defines `on2`. `groupOn` receives a function as input and names it `f`, while `on2` receives two functions as input and names them `(.*.)` and `f`. So there are two functions named `f`. In the same way you can write 1 `plus` 2 as syntactic sugar for plus 1 2 you can write x `plus` y = x + y as syntactic sugar for plus x y = x + y So the backticks around `on2` indicate that it is `on2` which is being defined, not `(.*.)`.
I focussed on JSON, because that was the format I needed a solution for. I've taken the idea of \`safecopy\` and applied it to JSON, and there were plenty of areas which needed a solution specific to JSON. I don't how to what degree it is generalizable, but I'd love to hear any concrete thoughts about it.
Hmmm, very interesting packages and other links. Haven't heard of invertible grammars before, though they all seem isomorphic, and I don't know if that's necessary/wanted. I'll keep this in mind and see if it makes sense after using this in production for a while. Thanks for all the references ;)
Dude this is sick! Please make more music!
Same way how a sergeant makes you a better soldier.
What maths I should study in college that would make me better understand Haskell?
If you only grab the latest version you can go far. It's mostly compressed text files. E.g. aesonhas only 250kb. Most will be even smaller. But I would just grab the latest version of the X most popular ones. Unless there is a really good reason for needing all of them.
I have admit I haven't built any non trivial project in Haskell yet I think I'm in the same position as you were when you hit the second wall in Haskell I'll try your approach but I'm afraid it will take me very long time do something non trivial properly in Haskell haha
map, filter, fold are available in almost all popular language now. Types and many theories you may only be able to apply in other functional languages because it's quite different with OOP languages. I guess understand the basic of things in Haskell isn't enough what I lack is in-depth experience of using Haskell
The second wall is easier than the first. It does get much easier, you just have to keep at it til the lightbulbs start to come on. I also strongly recommend just browsing through the apps that people announce on this sub. Most are fairly small projects that are pretty easy to absorb, and show you some solid patterns.
But developing applications _is_ differerent and special when compared to simply running applications. I'm guessing you've not done this and that's why you don't understand the massive differences. Let's take just one of the simplest cases. In your "use the OS packging system for all dependencies," how do you check to see if your simple Python script works on all versions of Python from 3.4 through 3.7, and on the (as yet unreleased) 3.8? Do you actually go out and install separate copies of every OS you want to support and do rebuilds and tests on each one?
Ok, so it sounds as if your complaint is that the dependency tools use different package and repository formats. That's a much more fair complaint, but dependency management tools such as Stack or NPM do a lot more than what yum or apt do. Trying for a common package/repo format would be interesting, but I am doubtful that it would be easy in practice (different languages and systems need rather different metadata, for example) and it's not clear to me what would really be gained by this. Have you seen an example where someone has tried this? Even something as simple as, say, changing pip to be able to use RPM packages and servers?
I don't buy the different metadata argument.
Can someone explain exactly how does this code avoid duplicate computations?
Logic. Types are propositions, terms are proofs. There are connections to category theory, too.
Here is the same code rewritten in a different way. This might make it easier for you. groupOn :: Eq b =&gt; (a -&gt; b) -&gt; [a] -&gt; [[a]] groupOn f = groupBy ((==) `on2` f) where g `on2` h = \x y -&gt; g (h x) (h y)
Are you still planning on sending a PR with Arch Linux instructions?
What *obvious* things about monads don't work?
Layer 1 is your thin wrapper around IO adding state and as such should be treated similar to how you treat IO. So your example of sticking it directly under main is correct. Layer 2 provides your domain specific layer abstracting interactions with internal state and the world and, when in production, wraps and is implemented in terms of layer 1 (or implemented using a more pure abstraction when facilitating testing). Layer 3 is your pure code operating on the data accessed through layer 2. The goal then is to push everything into the most highly numbered layer as possible (ie into the highest abstraction)
I though it would be boring, just hand tweaking knobs..
In case you are interested in some tech details: controls by knobs: 1 - master volume 2 - kick - crossfade between two patterns 3 - degree of drum complexity variants (shuffle amount, affects clock tick and snare+hats) 4 - clock ticks volume 5 - mid-pads volume 6 - high pads volume 7 - play pad or arpegios 8 - x second row 9 - pads - volume and volume of low-deep pad 10 - kick volume 11 - snares and hats volume 12 - atmospheric noises volume 13 - cut off of filter (affetcts pads or arpegios, moogladder) 14 - play major or minor chord 15 - change the timbre from mild to raw analogue 16 - resonance of the filter
Thanks man! I hope so
The core of your error is that putStrLn expects a String as input, instead you are giving it something of the type "Io (Either Error (SearchResult Issue))"
Thank for looking into the error. But how do I convert my function's result to the appropriate action type, just to be able to print the results to the console?
What's the definition of SearchResult and Issue? You'd need to either define a function that prints something of one of those types, or a function that converts one of those types to a string. Then you'd also need to handle the case where fetch... returns an error
You'll want something like: (I havent run/typechecked this, but it's a start) handleError :: Either Error (SearchResult Issue) handleError Error = "whatever you want to return when there's an error" handleError (SearchResult x) = show (SearchResult x) main = do resultFromFetching &lt;- fetchHelpWanted thingToPrint &lt;- handleError resultFromFetching outStrLn thingToPrint
The error tells you exactly what is wrong: `putStrLn` expects an argument of type `String`, but `fetchHelpWanted`'s type is `IO (Either GitHub.Data.Definitions.Error (GitHub.Data.Search.SearchResult GitHub.Data.Issues.Issue))`. So you need to find a way to glue the two together. Let's dissect the right-hand type from the outside in. The outermost type constructor we have there is `IO`; we'll call its argument `a` for now. So we have `putStrLn :: String -&gt; IO ()`, and `fetchHelpWanted :: IO a`. For now, let's assume we have a function `s :: a -&gt; String`, so we can turn an `a` into a `String` (or, alternatively, turn `putStrLn` into a function of type `a -&gt; IO ()`). This leaves us with a function something like this: `IO a -&gt; (a -&gt; IO ()) -&gt; IO ()`. Does that look familiar? Oh boy, it happens to be the exact type signature of `(&gt;&gt;=) :: Monad m =&gt; m a -&gt; (a -&gt; m b) -&gt; m b`, just specialized to `IO` for `m` and `()` for `b`. OK, so far so good; we still need to write `s :: a -&gt; String`. `a` is actually `Either Error (SearchResult Issue)` (fully-qualified names reduced for clarity). Now, if `Error` and `SearchResult Issue` both have `Show` instances, then `Either` will also have a `Show` instance, and we can just use `s = show`, which would give us: `fetchHelpWanted &gt;&gt;= \result -&gt; putStrLn (show result)`. Or, if you prefer point-free style, you could just write: `fetchHelpWanted &gt;&gt;= putStrLn . show`. Or you can take the pointful form and apply `do` sugar: `do { result &lt;- fetchHelpWanted; putStrLn (show result) }`. Now, the `Show` instance we get may not be ideal; you'll get something like `Left (Error "the error message")`, when really you'd want something closer to `error: the error message`. But that's really just a matter of writing a better formatter function (`s` in the example solution above). HTH.
Thank you very much for the detailed explanation.
Haskell is somewhat based on category theory
Raspberry Pi + SSH
[Why learning Haskell/Python makes you a worse programmer (2006)](https://lukeplant.me.uk/blog/posts/why-learning-haskell-python-makes-you-a-worse-programmer/)
You're missing the let in the definition of on2 which is what differentiates it from the normal on function.
The let in the on2 function binds the result of f x before the y argument is taken so f x will not be recomputed for every y.
Ok. So when you're distributing a Haskell library via RPM, where do you store the information about which version of GHC it's built for?
So `let` binding can introduce some memoization? Guess I have to read some of that manual now.
Here's an example to illustrate: expensiveFunction () = last [0..10^8] main = do let x = expensiveFunction () print x print x print (expensiveFunction ()) print (expensiveFunction ()) When running this code you will notice that it takes some time, then it prints 10^8 two times in a row, then it takes some time again, then it prints 10^8 once, then some time again, then 10^8 finally. You see that the `x`'s are shared (i.e. they point at the same memory address), while the two calls to the `expensiveFunction` are executed twice and not shared. Some important terms are partial evaluation and sharing.
Targeting an audience has been tricky for me. There are two groups I would like to target: potential devs and potential users. The only people who could help develop it are Haskellers. The people most likely to want to use it would be personal knowledge base enthusiasts, but I haven't found a/ big collection of such people anywhere.
Got it, thanks for the illustration!
I've found a more extensive source: https://old.reddit.com/r/haskell/comments/k4bq9/sharing_in_haskell_how_the_let_and_lambda/
So from what I got, `groupBy` has somehow to share the partial applications of `on2` in order to benefit from the `let` binding. Looking at the definition of `groupBy`, I don't see this.
Hi Depending on the type of complexity you fancy, you may go to Yesod (for a heavyweight, opinionated framework that says that you will use templates, MVC and a SQL database) or to Snap (a lighter, unopinionated framework). &amp;#x200B; For the frontend, I would try to skip it, because it adds complexity. But, if you really need it, I would go with a standard HTML/CSS/Angular/React for two reasons: * GHCJS has been a pain in the past. Hopefully now it's better, but I wouldn't expect it to be. * You are already experimenting with a big change in programming language and framework for your backend. Common wisdom suggests you shouldn't try to do too much experimental stuff at the same time in order to not be overwhelmed. So experimenting on the backend while keeping the frontend in "known" territory sounds like a decent tradeoff.
Kudos for actually writing/documenting how to use the thing instead of the usual "It is all in the type!" excuse.
Thanks! This package had a very pragmatic reason to be made, so I wanted other people to be able to make as much use of it as possible and have it be as clear as possible.
For Debian it's in the dependencies. It also provides a specific ABI as a virtual package. % aptitude show libghc-recursion-schemes-dev Package: libghc-recursion-schemes-dev Version: 5.0.3-1+b1 State: not installed Priority: optional Section: haskell Maintainer: Debian Haskell Group &lt;pkg-haskell-maintainers@lists.alioth.debian.org&gt; Architecture: amd64 Uncompressed Size: 2,602 k Depends: libghc-base-dev-4.11.1.0-5dd74, libghc-base-orphans-dev-0.7-66f93, libghc-comonad-dev-5.0.4-f8103, libghc-free-dev-5.0.2-d8cde, libghc-template-haskell-dev-2.13.0.0-87d93, libghc-th-abstraction-dev-0.2.8.0-613e0, libghc-transformers-dev-0.5.5.0-b5d2f, libatomic1 (&gt;= 4.8), libc6 (&gt;= 2.2.5), libgmp10 Suggests: libghc-recursion-schemes-doc, libghc-recursion-schemes-prof Conflicts: libghc-recursion-schemes-dev:i386 Provides: libghc-recursion-schemes-dev-5.0.3-d2f08 Description: generalized bananas, lenses and barbed wire Base functors for fixed points, fixed points, folding, unfolding, refolding, Mendler-style iteration, Elgot (co)algebras, and Zygohistomorphic prepromorphisms. This package provides a library for the Haskell programming language. See http://www.haskell.org/ for more information on Haskell. Homepage: http://github.com/ekmett/recursion-schemes/
Sounds ok, what would removing the `Esqueleto` type class imply? Just having the methods of that class as functions, and keeping the other classes? Also, `Ratio` isn't a monad, right? How would `Esqueleto Ratio SqlQuery SqlBackend` work? Did you mean `Esqueleto SqlQuery Ratio SqlBackend`? (seeing as it's `Esqueleto query expr backend`)
If this is your first Haskell project, I'd maybe advise using [`scotty`](https://hackage.haskell.org/package/scotty) for the backend. And like /u/javcasas said, just do the frontend in what you're familiar with, for now. Just take it step by step. &amp;#x200B; But if you haven't really made anything in Haskell yet, I really liked figuring out how to find prime numbers when I started my first Haskell executable. Then optimise it, maybe add a DB to store the ones you found and to pick up where you left off, handle shutdown gracefully, and then maybe make a \`scotty\` app that you can query using \`curl\` to fetch stuff from the DB? &amp;#x200B; I don't know what your proficiency in programming is, so this may be too easy, but I'd still advise you to take small step by small step, instead of jumping into big projects. (Just my two cents. I wish you success in your endeavors, whatever they may be ;) )
While I can agree on Records, I consider the "problems" with monad transformers and "too many string flavors" as essential complexity, so I don't see them as problems. (That said, I am on the lookout for as approach to "effects" and "layering" that isn't monad transformers and is better, but none of the effect systems I've dealt with were that, yet.)
In the groupBy function you can see that `eq` is partially applied (in this case it is only given one of its two arguments): -- | The 'groupBy' function is the non-overloaded version of 'group'. groupBy :: (a -&gt; a -&gt; Bool) -&gt; [a] -&gt; [[a]] groupBy _ [] = [] groupBy eq (x:xs) = (x:ys) : groupBy eq zs where (ys,zs) = span (eq x) xs -- here ^^^^^^ And in the case of groupOn: `eq = (==) \`on2\` f` This is like the `expensiveFunction1 8` in my example: it takes two arguments, but it can already compute a part of the solution when given only one argument, in my example this part of the solution is last [0..10^8] which just evaluates to 10^8, and in the case of `groupOn` the part of the solution that is calculated is `f x` which might be a very expensive operation just like `last [0..10^x]` in my example.
You can see the tradeoff between space and time in this example: import Data.List import Data.Function groupOn :: Eq b =&gt; (a -&gt; b) -&gt; [a] -&gt; [[a]] groupOn f = groupBy ((==) `on2` f) -- redefine on so we avoid duplicate computation for most values. where (.*.) `on2` f = \x -&gt; let fx = f x in \y -&gt; fx .*. f y groupOn' :: Eq b =&gt; (a -&gt; b) -&gt; [a] -&gt; [[a]] groupOn' f = groupBy ((==) `on` f) largeInexpensive :: Int -&gt; [Int] largeInexpensive x = replicate 100000000 1 ++ [x] smallExpensive :: Int -&gt; Int smallExpensive () = last [0..10^8] main = do -- print $ groupOn largeInexpensive [1..100] -- uses lot of memory -- print $ groupOn' largeInexpensive [1..100] -- print $ groupOn smallExpensive [1..100] -- print $ groupOn' smallExpensive [1..100] -- uses lot of time
You can see the tradeoff between memory space and cpu time in this example: import Data.List import Data.Function groupOn :: Eq b =&gt; (a -&gt; b) -&gt; [a] -&gt; [[a]] groupOn f = groupBy ((==) `on2` f) -- redefine on so we avoid duplicate computation for most values. where (.*.) `on2` f = \x -&gt; let fx = f x in \y -&gt; fx .*. f y groupOn' :: Eq b =&gt; (a -&gt; b) -&gt; [a] -&gt; [[a]] groupOn' f = groupBy ((==) `on` f) largeInexpensive :: Int -&gt; [Int] largeInexpensive x = replicate 100000000 1 ++ [x] smallExpensive :: Int -&gt; Int smallExpensive = \x -&gt; last [0..10^8] main = do -- print $ groupOn largeInexpensive [1..5] -- uses lot of memory print $ groupOn' largeInexpensive [1..5] print $ groupOn smallExpensive [1..5] print $ groupOn' smallExpensive [1..5] -- uses lot of time
&gt; Sounds ok, what would removing the Esqueleto type class imply? Just having the methods of that class as functions, and keeping the other classes? Based on my read of the PR: Yes, exactly
Haskell disciplined me to decompose problems into "purely functional" aspects, those dealing with state, and those dealing with IO, by making it easy (and to some degree necessary) to do so, and making it clear how to reason about the distinction. This approach means that I now think about code and algorithms in a different way, no matter in what context. It also encouraged me to _think_ recursively even if sometimes in other languages it is more efficient to code iteratively.
`Ratio` isn't a monad, but it is higher kinded - `data Ratio a` and `type Rational = Ratio Integer`. This means that using `Rational` somewhere in my code in the wrong place caused it to infer that `query ~ Ratio`, and that error propagated further than it should have.
Even if it doesn't change over the lifetime of the program? If there were a `timeProgramStarted :: Int` at the top level, then any function that depended on it would be pure in the sense that any two calls to it in the same program, when given the same arguments, would return the same value. But would it still be better served for the programmer as `getTimeProgramStarted :: IO Int`?
As the original author of the code, I find it somewhat confusing with binding a pattern to an operator. I'm assuming I copied it from somewhere, but don't know where...
Please no video effects next time ;-)
&gt;I‚Äôd agree - bitunctor is way more useful, so I‚Äôll try to get round to opening a PR on that, unless someone gets to it first. Honestly, I think it's a better pattern to use `left` to do so, as it makes it a lot easier to understand at a glance. Unless you have other bifunctors you're using, I'd recommend using the arrow version and just changing all relevant `first`s to `left`s (and `second`s to `right`s).
The code for the `on` function in Data.Function in base uses the same trick and even the same name, so I think that is the source.
This argument ("we can't prove it will work the way we want if to we do it your way") gets made time and time again when excluding certain valid and widely accepted programming constructs (Such as also often happens with the people defending Rust), but as gets proven time and time again, the only way to truly prove a non-trivial program will work as expected without resulting to compiler intrinsics is to use dependant types (or alternatively, design-by-contract, which is really just a more restrictive variant of dependent typing). Indeed, theoretically, it would be possible to create complete dependant type definitions for all arguments and return values in your program, and in a language with a type system as sophisticated as Haskell, this is certainly possible. Yet more often than not, neither side of the argument actually want to put in the effort to implement such types, and with good reason. `NonEmpty` is an exception in this regard (probably because it's both a common type dependancy, and because its easy to implement) and it shows just how non-trivial and limiting dependent types really are in Haskell and most other programming languages. How to define a list that contains exactly ONE element, for example? Or exactly N? Or `min (length a) (length b)`, like with `zip`? And this simple scenario is just the tip of the iceberg; in Rust, I have already found several constructs common in other languages that can't even be expressed in Rust. At least Haskell's type system got THAT right. As Idris has shown, creating a fully dependant type system is quite possible, and not even that hard. If this was really all about type safety, we should all be using Idris instead. My point is, you can't argue that type dependencies have to be enforced, while at the same time acknowledging the lack of support to construct arbitrary type dependencies. If types like NonEmpty could be cleanly expressed in Haskell, there would be little reason to argue about whether or not to use it, but as it stands, the NonEmpty/maybeHead solutions are just as hacky as the original error-based one, albeit more desidable in certain circumstances.
What you're doing \*is\* returning all the unique elements of a list -- \`\[1,2,3\]\` is all the \*unique\* elements (removing all duplicates of \`1\`). If, on the other hand, what you want is all the elements that \*are unique\* (this is a subtly different property -- the former is "all elements present in the list no duplicates", this is "all elements present \*that are not duplicated\*), then you should take a closer look at what this code is doing. Particularly, in the recursive case, notice that you \*always\* prepend \`x\` into the result of the recursive call. Is that what you want to be doing?
The definition you have here basically removes any duplicates from a list. (like `Data.List.nub`) What you want to do is count all occurences of elements and remove the groups that have two or more. So the easiest solution would probably be: `filter ((&lt; 2) . length) . group` (filter/length/group all from `Data.List`) There are more efficient ways to make such a function, but if you're not highly optimizing for efficience (like you need to do this on a million element list or something) the above function is probably what you want.
I'm the latter, but considering doing my own hobby implementation of your system in another language (don't know or want to learn Haskell as my next language.) I imagine that the taskwarrior people may be interested in your system. They do some very solid development work for complex task management.
Hey, if it doesn't really change any functionality, I'm super fine with this. We use `esqueleto` in our codebase too, but I doubt this will have any impact on queries we wrote.
Curious to see an example of an optimised version for this problem.
Just realized my example doesn't do what I thought it did (`group` does not group ALL duplicates found, only the consecutive ones). I'd probably use `Set`s, since those never contain duplicates (by definition): ```haskell uniques :: [a] -&gt; Set a uniques = go mempty mempty where go uniqs _ [] = uniqs go uniqs dups (x:xs) = go newUniqs newDups xs where (newUniqs, newDups) | x `Set.member` dups = (uniqs, dups) | x `Set.member` uniqs = (x `Set.delete` uniqs, x `Set.insert` dups) | otherwise = (x `Set.insert` uniqs, dups) ```
When I was learning, I have no idea how the Haskell skills help me in C++/Java or other main stream languages. But after I know more about Haskell, I realize Haskell can help your thinking the "STRUCTURE" of the problem rather than thinking the "small thing" such as "loop, index, i++, index = length -1" In Haskell, We seldom use "index, loop, i++, i--.. etc", all you need is: map, foldr, foldl, head, last, init, tail, take, drop, etc.. non of the functions has "index" or "i++", "i--" on it. so that you can apply the whole list as "STRUCTURE", and come up new "STRUCTURE" sometimes it is hard to describe in words... I try my best to describe it..
In servant, is there a simple way to generate the URL to an endpoint (e.g. in order to return a "callback url")? In other frameworks this is called "reverse routing".
Oh snap. I didn't realize I've been looking at an alternative definition: ``` groupBy :: (a -&gt; a -&gt; Bool) -&gt; [a] -&gt; [[a]] groupBy _ [] = [] groupBy p' (x':xs') = (x' : ys') : zs' where (ys',zs') = go p' x' xs' go p z (x:xs) | p z x = (x : ys, zs) | otherwise = ([], (x : ys) : zs) where (ys,zs) = go p x xs go _ _ [] = ([], []) ``` Thanks again, it's all clear now.
Haskell is expecting an `otherwise` case below the three you already have. Even if you've mathematically covered all possibilities, the compiler can't check that.
Which of these three cases will 2019 fall into?
I see, thank you very much for that! :D
Haskell uses [type defaulting](https://www.haskell.org/onlinereport/decls.html#default-decls) to resolve cases where concrete types of numeric literals cannot be infered - and by "default", it's set up to use `Integer`. And then, reason why `id` doesn't work is simply that there isn't any way to infer it's type (`a` in `a -&gt; a` is totally ambiguous), which is needed by `typeOf`...
This is not true, the non exhaustive patterns error is due to there actually being non-exhaustive patterns at runtime. Not all years fall into one of those three categories. Also the exhaustiveness warnings that are enabled with -fwarn-incomplete-patterns only check if all constructors are matched while pattern matching, it won't check guards or if statements.
This is unrelated to your question, but your values are flipped. Ignoring the other cases, `mod y 4 == 0` means the year is divisible by four, so it is a leap year which should have 366 days, but you return 365 in that case.
&gt; My point is, you can't argue that type dependencies have to be enforced, while at the same time acknowledging the lack of support to construct arbitrary type dependencies. This argument basically extends to "if we don't have full dependent typing, we might as well all use dynamic languages". I'm guessing you don't agree with that. In my experience, lists model exactly what I want 80% of the time. If NonEmpty can cover 80% of the remainder, then it seems reasonable to use it. Btw it's often very possible to express more complicated invariants without reaching for dependent types (or GADTs or anything like that). For example, if your function expects two lists with the same length, why not instead take a list of pairs as an argument?
Is safecopy still the best option for migrations (for normal datatypes), too? It's what I use, and it works well - but after a while I have an enormous migrations file with many many different versions of old datatypes and Migrate instances. I saw some work from Andreas Loh some time ago on generic migrations, but it doesn't seem to have turned into a usable solution yet? [https://www.andres-loeh.de/dgdm-ifip.pdf](https://www.andres-loeh.de/dgdm-ifip.pdf)
&gt; "if we don't have full dependent typing, we might as well all use dynamic languages" &gt; why not instead take a list of pairs as an argument
&gt; "if we don't have full dependent typing, we might as well all use dynamic languages" In it's current state, if we were to force dependant types on Haskell users, we would indeed end up with a language must like dynamic languages where we'd have to check every type cast we make (or risk a runtime error). That's the opposite of what I want to happen to Haskell. If we instead added dependent typing into some places but not others, we would end up back where we started, where we would either have to explicitly assert the assumptions we have about our program whenever we convert a non-dependant type to a dependent one, or hope our program does what we expect it to without runtime checks. Theoretically, dependent types make your code safer, and even in a language like Haskell, dependent types have its uses, but you can't argue that they should be the default because they "improve the stability of the code" when you're either: 1. Changing the point at which an exception is thrown (`fromList :: [a] -&gt; NonEmpty a`), or 2. Changing the programming interface to force explicit runtime error checking (`headMaybe :: [a] -&gt; Maybe a`) These methods are no different from unit testing, or whatever other methods you use to prove that your assumptions are correct (even checking your code by hand). - Just like assertions and unit testing, dependent types move the point of failure, which can be a good thing if you know what you're doing, but otherwise, this means nothing. - Faking dependant types is useful for documentation purposes, but then again, so are comments, or unit tests. - The only way you can truly say that dependant types improve safety over alternatives is if they are first-class, or if you at least use them to guarantee assertions you made in a non-trivial program (since those are hard to test correctly). - Using dependent types that way gets really bloated in most languages though (including Haskell) making them generally not worth the effort. To reiterate my point: Dependent types are fine, but you shouldn't force them onto your users when your users might prefer to test their software in some other way, and might not even be able to express their requirements using your dependent types. &gt; Btw it's often very possible to express more complicated invariants without reaching for dependent types I agree with this, and I think that if you strive for completeness, for most languages, this is the best way to ensure your program will always do what you want it to. You should always prefer first-class types over a dependent type hack. In some cases, though, converting between different types results in unacceptable CPU/memory usage.
What I don't get is what dependent types have to do with this whole discussion. NonEmpty isn't even a GADT. It's a plain old Haskell ADT that encodes in the most obvious way the invariant that there's at least one element in the list. It's just an additional invariant you can add to your functions, or an addition requirement you can expect from the inputs. And it doesn't just move the runtime check, it can also reduce the number of times the check has to be done since you can propagate the information further. Even if it did just move the check, it moves it sooner in the program execution which is a huge win.
Funny. Do haskellers have something against JSON and mongodb?
As somebody who just recently picked up Scala and is learning functional programming. The comments in this thread are interesting! I always assumed Haskell was just some old school functional programming software that people used for fun, may have to give it a try
If you don't intend to ever mutate a value, why make it mutable?
What is the function supposed to do?
&gt; Not all years fall into one of those three categories. You're right; I hadn't looked at what he posted close enough. &gt; I think you are alluding to the checks that are enabled by -fwarn-incomplete-patterns I just meant they're not casing on a sum type or something so the compiler isn't going to know you've covered everything until you put a catch-all.
Are you trying to write `eval`?
It's supposed to be similar to be a very crappy SAT solver. So, the ands would be set to * and the ors to +. So the "function" would be inputted two ints (Zero/One) where it would resolve to either a Zero (UNSAT) or One (SAT).
I have not heard of Eval, but reading the Hackage page it might be what I need, thank you.
Sorry I didn't mean to refer to any specific package, but if you found one that's good I guess :-) If you're interested in writing a parser, I'd highly recommend the megaparsec [megaparsec](https://hackage.haskell.org/package/megaparsec). If you're just parsing `Int -&gt; Int -&gt; Int` functions it should be relatively simple.
Isn't it a possibility to write a specific grammar using PEGs or a common lexer/parser? Because what you describe is kind of a language. Maybe it is an overkill, but if you want to keep the project growing, it could be better. Maybe Happy and Alex package could be a start.
Your type signature indicates that you're returning a `Float` but you're actually returning a `String`. I suggest you create a type to represent all the possible marks, and then return a value of that type. If you'd instead like to return the calculated mark number with a chance of their being an error, I suggest you learn about `Maybe` or `Just`. You could set your return type to `Either String Float`, returning `Left "your error message"` or `Right 100.0`. You can get your program running by creating a `main` function and using your `calc_mark` function from there.
I recently re-visited Haskell on AWS lambda (with [https://github.com/seek-oss/serverless-haskell](https://github.com/seek-oss/serverless-haskell)) and was quite impressed. I currently have a project where the backend uses Servant, deployed with nixops, but will probably move it to serverless since it: * will be free (my functions should be low traffic) * has good offline testing support (launched with \`sls offline\`) * lets me focus less on entry point wiring (provided by serverless / API gateway / etc) and more on fun Haskell functions If it helps, here's my recent exploration [https://github.com/cah6/seekoss-serverless-test](https://github.com/cah6/seekoss-serverless-test). See app/Main.hs for the main Haskell code. Lambdas seem like a good solution for all your points; note that the serverless-haskell library will build via docker so that it generates an executable suitable for the Amazon Linux machine type that lambdas run on.
Your bonus points calculation should go into the where clause, not where your guards are. You also need to define what bonus points should be when `value1 &lt;= 50 &amp;&amp; value2 &lt;= 10` is _not_ true. Also, what are `points_from_exam1` and `points_from_exam2` supposed to be? You're using them, but they're not defined anywhere. Also, it's spelled `otherwise` not `otherweise`.
Maybe I'm just not as well versed in SAT solvers, but what would "&amp;|" do to the two `Int`s? Would it logical-AND the two inputs to produce an output then logical-OR both the inputs to create another output? How would it combine the outputs? Or is does one of the inputs get folded back in? Or do we work "from the right" first? So, far the closest I can get you is: f :: String -&gt; Int -&gt; Int -&gt; Int f "&amp;" = (*) f "|" = (+) f _ = error "Behavior under-specified."
Hot on the heels of my last post, here's the next! This is more or less what the previous ones have been leading up to. Give it a read, especially if you've been wanting to give Haskell on the frontend a try but haven't been sure how to get started, and let me know what you think!
Yea, I should probably do that. I'm actually starting to feel like I should keep learning Haskell for now, before I try any projects
Hi thanks so much for the reply. I am going to look into Snap and I'll stick to the more standard frontend.
Sweet! Will reach out. Thanks, Andre!
Doing projects is the best way to learn in my opinion. You'll only encounter things you'll need. It's a 'learn by need', rather than a strict approach.
Hi thanks so much for the reply, I'll check out scotty for the backend. I think the prime number example would probably be a bit too easy for my programming proficiency, although it would provide a good way to get used to working with a db and writing a simple server. Thanks for the well wishes :)
I tend to alternate. Head the spec until my head is full, then start a project, and refer to the spec as soon as I get confused just long enough to get clarity. After I "finish" the project, I go immerse myself in the spec for a while again; try and read with new eyes, and see if I can get more into my head this time. Repeat ad satisfactio.
Hi thank you for the reply! I have no prior experience with serverless, but it seems like a good way to abstract out the stuff I'm not interested so I can focus on writing Haskell. For my use case, I imagine it would be free as well. I'll give it a shot :)
That's kinda what I done when I was learning more Python last summer.
Nice! Glad to see my skeleton is of some use :) &gt; I tried this on the default ‚Äúhashicorp/precise64‚Äù Vagrant box with an internet connection of ~100 Mbit/s (fixed to match my usual speed with this) running on my 2016 Mac and it took about 30 minutes This is odd. I tried the same, and it only took ______________ &gt; Wiring in Warp If you're using a recent enough reflex-platform, I think you can just set the `useWarp = true;` option in your `default.nix`, and reflex-dom will be rebuilt to use warp by default for the desktop target. You shouldn't have to do anything at all in your frontend Haskell code, and shouldn't need to import jsaddle-warp manually. &gt; Pinning a library that has a Nix expression &gt; `servant-reflex = pkgs.haskellPackages.callPackage ./nix/servant-reflex.nix { };` This is not correct. If you use `pkgs.haskellPackages.callPacage`, you'll be providing `servant-reflex` with deps from a different haskell package set. You should use `self.callPackage` to make sure it uses the same package set.
I've reached out to them [here](https://groups.google.com/forum/#!topic/taskwarrior-user/Q_f_Os_wdBk). Thanks, Andre!
Here's a simple stack machine for you to think about / play with: type Env = [(Char,Int)] type Stk = [Int] type Err = String err :: Err -&gt; Either Err a err = Left interpret :: Env -&gt; String -&gt; Either Err Stk interpret e s = loop e [] s loop :: Env -&gt; Stk -&gt; String -&gt; Either Err Stk loop e stk [] = return stk loop e stk (c:cs) = do newStk &lt;- cmd e stk c loop e (cmd e stk c) cs cmd :: Env -&gt; Stk -&gt; Char -&gt; Either Err Stk cmd e (x:y:stk) '+' = return (x+y : stk) cmd e (x:y:stk) '-' = return (x-y : stk) cmd e (x:y:stk) '*' = return (x*y : stk) cmd e (x:y:stk) '/' = if y == 0 then err "division by 0" else return (div x y : stk) cmd e stk c | isdigit c = return (read (c:[]) : stk) cmd e stk c = do v &lt;- fetch e c return (v : stk) -- lookup :: Eq a =&gt; a -&gt; [(a,b)] -&gt; Maybe b fetch :: Env -&gt; Char -&gt; Either Err Int fetch e c = case lookup c e of Just n -&gt; return n Nothing -&gt; err ("variable " ++ show c ++ " not found.") test = interpret [(a,3),(b,4)] [] "ab2+*" -- a [3] -- b [3,4] -- 2 [3,4,2] -- + [3,6] -- * [18]
Thanks, I'll have a look at that
Nice! Glad to see my skeleton is of some use :) &gt; I tried this on the default ‚Äúhashicorp/precise64‚Äù Vagrant box with an internet connection of ~100 Mbit/s (fixed to match my usual speed with this) running on my 2016 Mac and it took about 30 minutes This is a bit longer than I'd expect. I tried it in the same vagrant on my 2013 macbook pro, and it only took 10m. &gt; Wiring in Warp If you're using a recent enough reflex-platform, I think you can just set the `useWarp = true;` option in your `default.nix`, and reflex-dom will be rebuilt to use warp by default for the desktop target. You shouldn't have to do anything at all in your frontend Haskell code, and shouldn't need to import jsaddle-warp manually. &gt; Pinning a library that has a Nix expression &gt; `servant-reflex = pkgs.haskellPackages.callPackage ./nix/servant-reflex.nix { };` This is not correct. If you use `pkgs.haskellPackages.callPacage`, you'll be providing `servant-reflex` with deps from a different haskell package set. You should use `self.callPackage` to make sure it uses the same package set.
How is it failing? The Hackage CI https://matrix.hackage.haskell.org/#/package/accelerate and travis CI and appveyor CI compile fine. Are you not able to reproduce either of their compilation runs?
Your skeleton and the project-development readme were indispensable! While writing this I was worried it might be too much of a straight repeat of that but I think it came out with enough additional information to warrant being out there too. &amp;#x200B; Huh, I thought I had tried just setting useWarp without anything else and it didn't bring it up how I wanted. Does it matter whether you use Reflex.Dom or Reflex.Dom.Core, in that case? And what port does it default to running on? Side note, might be good to add the default port to [https://github.com/reflex-frp/reflex-platform/blob/develop/project/default.nix](https://github.com/reflex-frp/reflex-platform/blob/develop/project/default.nix). In any case I'll try it out and update the post if it works. &amp;#x200B; Gahhh using \`self.callPackage\` explains a lot of the issues I was having. I thought that it was just using the overwritten function definition, not the overwritten package set. Just updated appropriately.
Yea you need to use `Reflex.Dom` for `mainWidget`; `Reflex.Dom.Core` exposes the jsaddle backend agnostic version, whereas `Reflex.Dom` exposes one tailored at configure time. But other than `mainWidget` and co., they expose the same symbols.
My observations with monad stacks with IO at has been that whatever problem they are attempting to solve is hardly worth the effort of maintaining the solutions. IMO functions in `IO` are often the best approach even if imperfect. I wish if nothing else `IO` functions were the starting place and if there is a truly a worthwhile monad stack decomposition it could be added later.
Make an interpreter https://stackoverflow.com/questions/23233969/sat-solving-with-haskell-sbv-library-how-to-generate-a-predicate-from-a-parsed/23234919#23234919
I don't really remember. First of all it's not accelerate but its actual ptx gpu backend that's usually the problem. And then there is the interplay with other dependencies and their version restrictions. I think it was along the lines of repa and juicypixels or sth. I can tell you next year when I have my annual phase of wasting time on HPC Haskell :)
Fair enough. I usually cope by replicating any of the mentioned CIs, but indeed, this is not exact science. Good luck next year. :)
I've never used `safecopy`, but the concept seemed to work well with what I was looking for with JSON. If you really want to stop supporting old versions, any stored data of older versions can easily be migrated to the new ones by just going over your entire dataset (or just the old versions if you have a way to filter it) and, in the case of `safe-json`, just `safeFromJSON` to your current type, and store it back where you got it from. After that, you can remove the old data type in your code, together with the `FromJSON/ToJSON/SafeJSON/Migrate` classes, and you're back to just one representation again.
Good tip indeed, maybe doing manual version checks by looking at the CIs is the way to go next time...
Thanks for writing these. I'm interested in exactly these topics and this is going to help me alot. I was going through the first blog post yesterday and skimmed through the second, but something came up. I'm going to continue where I left off soon, and I'll probably have more to say latter.
I'm trying to use `Three Layer Haskell Cake` to think about the structure for this Lisp interpreter I'm writing. I'm having a hard time understanding what falls into a `Layer 1` vs `Layer 2`. Here are all the actions my program does: ``` 0. Load configuration data for the intepreter (for example, the log level) into `ReaderT`. &lt;- Layer 1? 1. Read input from stdin, filepath, or a REPL into `Text`. &lt;- IO so does this go in Layer 1 or Layer 2? 2. Parse `Text` to `Term`. &lt;- This is pure so Layer 3? 3. Evaluate `Terms`. &lt;- This is also pure so Layer 3? 4. Write logging and evaluation results to Stdout. &lt;- IO so Layer 2? ``` So Layer 2 would consist of a bunch of typeclasses like: ``` class Monad m =&gt; MonadInput m where readFilePath :: FilePath -&gt; m Text readStdin :: m Text readRepl :: m Text class Monad m =&gt; MonadLog m where log :: LogLevel -&gt; Text -&gt; m Text ``` Do I also use typeclasses to define my `Layer 3`? Such as.. ``` class Monad m =&gt; MonadParse m where parse :: Text -&gt; m Term class Monad m =&gt; MonadEval m where eval :: Term -&gt; m Term ``` Or is `Layer 3` just ordinary functions with class constraints from `Layer 2`? Lastly, is `Layer 1` your `main` function where you setup your environment, execute `runAppM`, and execute all your calls to external services/io?
What your parser-function is currently doing is a simple form of term-rewriting (replacing "&amp;" with "\*" and "|" with "+"), which is different from evaluation, which gives a string an interpretation (an arithmetic interpretation in this case). The usual way to do this is to first transform the string into a syntax-tree (not also that you have no parsing of numbers) and to then create an an evaluator which reduces this syntax-tree into an int. Parsers can be written quite easily in parsec and evaluation-functions just fold expression-trees into single values (I didn't check this and I'm writing this from memory): -- Definition of the expression-tree data Expr = And Expr Expr | Or Expr Expr | One | Zero --Atomic parsers for one, zero, and, and or (and and or return lambdas with two arguments for the subtrees) one = char '1' &gt;&gt; return One zero = char '0' &gt;&gt; return Zero and = char '&amp;' &gt;&gt; return And or = char '|' &gt;&gt; return Or --Parser for the whole formula (note: the case of empty imputs and whitespaces is not considered). formula :: Parser String Expr formula = do firstOperand &lt;- one &lt;|&gt; zero (operator, secondOperand) &lt;- many $ do operator &lt;- and &lt;|&gt; or secondOperand &lt;- one &lt;|&gt; zero return $ \x -&gt; operator x secondOperand return $ foldl' (\acc x -&gt; x acc) firstOperand --Run the parser and return an Expr if the parse was successful. parseFormula :: String -&gt; Maybe Expr parseFormula s = case (parse formula "" s) of (Left _) -&gt; Nothing (Right expr) -&gt; Just expr --Evalute an expression-tree. This has nothing to do with parsing. evaluate :: Expr -&gt; Int evaluate One = 1 evaluate Zero = 0 evaluate (And x y) = min (evaluate x) (evaluate y) evaluate (Or x y) = max (evaluate x) (evaluate y) --Chain the parsing and the evaluating. parseAndEvaluate :: String -&gt; Maybe Int parseAndEvaluate s = evaluate &lt;$&gt; parseFormula s You can get more fancy with this (using ExprF to get rid of the manual recursion in evaluate, a more tolerant parser, etc.), but this should suffice for the basic task of evaluating an boolean formula. As I understand your problem, it's not a SAT-solver, though, because SAT means the evaluation of a formula of the form `Exists[x1,...,xn] F(x1,...,xn)` for bounded existiential quantifiers where xi can be 0 or 1, and for a quantifier-free F. evaluate above is only good for determining the truth-value of F(x1,...xn) (if you've already set all xi to 0 or 1 by hand). To turn this into an (inefficient) SAT-solver, you would have to extend your parser &amp; expression-tree to accept variables, then generate all combinations of all the values of x1,...,xn, and then run evaluate for all of them until you find one which evaluates to 1. You can use the list-monad to generate the combinations (mapM (\\\_ -&gt; \[0,1\]) and the setting of the variables is left as an exercise to the reader. ;)
I feel like I should warn you: if you're looking at `System.Eval.Haskell` from the `plugins` library, **do not use it**. According to https://www.reddit.com/r/haskell/comments/6pu7ch/differences_between_hotreloading_plugin_libraries/dksah4j?utm_source=share&amp;utm_medium=web2x, "it's pretty much dead". I think you should try the `hint` library instead - I've had very good results using it.
So great explanation and helps beginners a lot to read type in Haskell.
Hm. Yes, I'm seeing now how you could use dependencies and lots of version numbers in the file path to handle things pretty much all the version-related stuff. How about the lists of exposed and hidden modules?
Sometimes its the big things like minimizing state and separating effects. Other times it is simple things like realizing the value of partial application even when it isn't convenient. For example in pl/sql &amp;#x200B; \`declare handle number := library.get\_handle;\` `procedure applied(arg number) is` `begin` `library.action(handle, arg);` `end applied;` `begin` `action(1);` `action(2);` `action(3);` `end;` &amp;#x200B; `aaa`
Those would be in the source package, although I'm not sure they are exactly needed. For C libraries Debian uses symbols files generated by scanning the build outout (for C libraries the .so files).
Results: [https://github.com/fumieval/serialization/blob/master/report.md](https://github.com/fumieval/serialization/blob/master/report.md) &amp;#x200B; Overall, winery is about as fast as those, or slightly slower.
I don‚Äôt think recommending megaparsec to beginners is a good idea. As someone with a decent understanding of how monastic parsers work (which OP does not appear to have), I had trouble figuring out how to use it. As a first timer, I don‚Äôt think it‚Äôs a bad idea to roll your own recursive decent parser. It may be ugly, but you‚Äôd learn a lot. Also, I think OP would get a lot more out of writing their own monad instance for a parser, as they would learn a lot more that way.
[removed]
I'll have a look at that as well then.
Yeah I think you're right, my bad. While I don't think megaparsec is as difficult as it looks, you're right that people should write their own first to really understand what it's all about.
Thank you, I'll read that too
Look for anything on the theoretical foundations of computer science. Lambda calculus, data structures and algorithms, etc. As others have mentioned, if your university has it, you can check out category theory, but if not, you can try algebra (the kind where you deal with groups, rings, etc., not the kind where you do 20 exercises plugging values into the quadratic formula). I was about to say the least useful stuff is probably the analysis/calculus/stats side of things, but that's... still really useful, it's just less related to the underlying abstractions in the core Haskell ecosystem.
But isn't the `let fx = f x` in the on2 definition seems to be just evaluating on what x is when f is used which is roughly the same with this version?
I'd recommend forgetting `Control.Arrow` altogether for this purpose. Bifunctors have: * Common types like `(,)` and `Either` * Follows the same pattern as `Functor`, `fmap` becomes `bimap` * Has supportive abstractions like `Bitraverse` which follows the same pattern as `Functor` I used this just the other day, [to rename an AST that had two parameters](https://github.com/chrisdone/prana/blob/2c99e704cf92b5ec324e097377755241141c7d0f/prana-ghc/src/Prana/Rename.hs#L87-L93). This abstraction has more than paid for itself.
Thanks, these are informative and thoughtfully written! As an aside, not sure why but the `rm -rf .git` and `rm -rf backend` really made me laugh -- gotta be careful not to rm my / while following the tutorial :p.
Well, remember that there may be no package with the build output for a particular system; it's very normal (and not just with Haskell) for developers to build dependent libraries from source. It's things like that that make me suspect that metadata may be incomplete if we were to use `apt` packages to replace the current package format and package servers for Haskell Stack and Hackage, Python's `pip` and PyPI, Ruby's Gems, NPM/Yarn and their servers, etc. etc. Were you thinking that every development system (including Windows) would be downloading a set of platform-specific binaries and libs for Apt or RPM or whatever, and `stack`, `pip`, `npm` etc. would be making native calls into those, or were you thinking that at least some platforms (especially the interpreters) would be writing their own implementation of the Apt/RPM/whatever libraries that are the standard package format for everything?
Real talk: your reflex skeleton saved my dissertation. Thanks so much for releasing and documenting it so well!
Just at the 'filter' section the article cuts off halfway through a sentence and the whole document repeats...
Thank you, just fixed :)
Now do one with `foldMap` :) * `sum = getSum . foldMap Sum` * `elem e = getAny . foldMap (Any . (== e)) * min is something with Option and Max newtypes * delete and filter can be realized with the list monoid * `reverse = getDual . foldMap (Dual . pure)` (No guaruntees, I'm in my phone)
Could be a cool think to blog about next. Thanks :)
I fell like I want more commentary about whether each implementation is as performant as the fastest implementation. I think it is in some cases and isn't in others (at least in Haskell. I suspect JavaScript none of them are because of extra function calls.)
I'd love to read your dissertation if possible!
Performancewise some of these functions are really really bad(think of all/any) but I didn't want to write an article about performance.
Is there any reason to use foldl and not foldr?
Combination of both. Cabal/pip would use rpm specs, and download and apply rpm binary packages, which will likely be arch and OS specific. Initially the package names would be independent from any OS, but Hackage/PyPI work with systems using rpm for other purposes to primarily avoid package name conflicts and ideally allow use of PyPI/hackage as "just" another source of rpms for global install through rpm/yum.
In these examples actually yes. I wanted to focus on the functionality and the fact that this is also possible with JavaScript. I have many JavaScript devs at friends and they will read the article. So to not confuse them more I've used foldl because the arguments of the iteration function are in the same order as the Haskell one.
Link to a repo? I have found a few you projects, but nothing worth learning a new language for. Haskell have very robust type system, which enableas fearless refactorings and aids well in domain modeling, it's also lazy - meaning Haskell tries hard to keep values as black boxes to be filled in at the last moment. Really last one. E.g. you can use a value that will be assigned in the future, or can simulate infinite structures transparently, or can write your own control structures without wrapping everything into awkard functions. There is a tone more. You may wish to watch a few shorter presentations about Haskell on YT to get the taste, if undecided.
That's as un descriptive as we could make it while keeping it true ;) trove of knowledge needed to unpack it, and then extra trivia on top.
that makes sense, I do think some parts of the post could be much more natural with foldr (like the head' function for instance). In particular, head works with infinite lists while head' doesn't. Also, foldr could allow you not to iterate through the whole list in functions like any/all.
Yeah you are right. I mean, I could have written something about that it's not performance oriented and stuff. To add something: many functions don't work on empty list where the prelude ones would.
Generally speaking, nothing wrong with having lots of functions. However, a lot of these functions are already available (or could use existing functions to make their purpose more obvious). Vague notes: - Conventionally, functions are named in `camelCase`, rather than `snake_case`. - Your `etaoin` can be more succinctly stated as `zip "eariotnslcudpmhgbfywkvxzjq" [1..]`. Any time you want to annotate a list with an index, this is a very nice trick. - `count` is `length . filter (==a)` - Recall that `if...then...else` is an expression, so you could write your substitution function as `substitute a b = map (\c -&gt; if c == a then b else c)` - Since you're working exclusively on lists, definitely read through all the stuff in `Data.List`. For instance your `tuple_insert` is exactly [`insert`](http://hackage.haskell.org/package/base-4.12.0.0/docs/Data-List.html#v:insert).
thanks!
&gt;...but Hackage/PyPI work with systems using rpm for other purposes to primarily avoid package name conflicts... This is getting quite interesting. So are you saying that there would be a global namespace for all packages for all systems? Which one of [CentOS](https://rpmfind.net/linux/rpm2html/search.php?query=zlib), [NPM](https://www.npmjs.com/package/zlib) and [Hackage](https://hackage.haskell.org/package/zlib) would get to use the name `zlib` for their `zlib` package? What would the package be called for the other systems, and how would we deal with backward-compatibility for that? (I'm pretty sure I must have misinterpreted something somwhere here, since this sounds pretty ridiculous in the way I put it, so please bear with my confusion here.)
&gt; So are you saying that there would be a global namespace for all packages for all systems? That would certainly be the ideal. I don't know that we'd ever get there, but it would be a good goal. Tools like pip/cabal could operate on a "view" of all packages starting with a negotiated prefix, if they preferred that UX.
I am currently writing a new Haskell book: [A Type of Programming](https://atypeofprogramming.com). It's still in its early stages, but it should help you build a strong foundation for anything else you read out there :)
1) give [docs on Data.List](http://hackage.haskell.org/package/base-4.12.0.0/docs/Data-List.html) a good read. A lot of functions you implemented are present there. There are non-obvious advantages in using library implementations as library implements rewrite rules for said implementations, improving performance. Also, the utilities provided by said library is well-documented, well-behaved and well-known. 2) There is no problem with having a lot of small functions in a module. There is, however, a problem with implicitly exporting all functions from a module. It is a good style to provide explicit export list. One of the reasons is that by using explicit export list, exposing only what this module is meant to expose, you make life of the compiler easier. 3) It is also a good style to provide type signatures for all exposed functions, and in doing so you do well. It helps with reading the code and reduces the amount of words needed for comments.
Once you learn Haskell, you think in functional programming paradigms. I learned programming through Java and perhaps it‚Äôs a mindset issue but I just wrote OO code that I was never happy with. Haskell becomes your replacement for pseudocode and formalizes some mathematical intuition as well. If you decide to skip out on Haskell: I would still recommend taking a surface level dive into the history of LISP, Haskell, Scala, elixir or anything FP just to supplement your skill set as a programmer. I‚Äôm paraphrasing ‚Äúthe dogma of mathematics is to retrieve pages from god‚Äôs book of perfect theorem‚Äù - Paul Erd√∂s and frankly you can write VERY elegant code with Haskell ONCE YOU GET OVER THE BUMPS IN THE BEGINNING In summary: exposure to Haskell (or any programming language that you feel drawn to) is a great step to take and will help you become a great programmer. Final note: if you have an interest in music/music theory: there is a book written by one of the minds behind Haskell called ‚Äúthe Haskell school of music‚Äù. Programming is more fun to learn when you have something to build hence I wholeheartedly recommend this resource. Happy coding and I wish you the best on your journey.
I don't have a concrete answer for that but have you learned about the Cont monad? [http://www.haskellforall.com/2012/12/the-continuation-monad.html](http://www.haskellforall.com/2012/12/the-continuation-monad.html) It looks very similar to what you want.
Nice work! I've written a library to do this where I work as we use a lot of JSON that has an informal specification. The tricky part was validating that the migrations are safe since our format is inconsistent due to the lack of validation/specification to begin with. Haskell has been essential to writing this tool. The amount of code required in a language with a less expressive type system to get the same confidence in its design and correctness is hard to think about.
I liked the video effects
You might also want to submit this to haskell-cafe [https://mail.haskell.org/mailman/listinfo/haskell-cafe](https://mail.haskell.org/mailman/listinfo/haskell-cafe)
Thanks, will do!
This is how I approach things: * write code inline * if it aids understandability, or in the service of DRY, factor out portions of a function to a `where` clause * if those definitions need to be re-used across functions or exposed for testing then move to the top level and export * I might also preemptively factor out a function if it is *very* general (like what you find in `Data.List`), and might go in a utility module later I think it makes your code harder to understand when code is moved to the top level for no concrete reason. Another thing I'd encourage (again on the theme of DRY): don't parameterize recursive functions by values that don't change between calls, instead close over those, e.g. [https://github.com/glimacs/classic-cryptography-toolbox/blob/master/Cryptanalysis.hs#L139](https://github.com/glimacs/classic-cryptography-toolbox/blob/master/Cryptanalysis.hs#L139) instead: getHighestLetters highestScores = go where go [] = [] go scores |elem (snd (head scores)) highestScores = fst (head scores) : go (tail scores) |otherwise = getHighestLetters (tail scores)
`hlint` is one of the best teaching/discovery tools that I've ever seen in any language. Say what you will about any other tool in the ecosystem, but when `hlint` says "hey, use traverse here" or "hey, this is just a concatMap", it feels pretty magical.
Oh cool! If you have any opinions about `SafeJSON`, do tell! Does it do something different than your library? Could anything be improved?
That makes sense - thanks!
A little background on my Haskell experience... I took a class in college that had one unit on Haskell programming. I was really interested in functional programming, but didn't really see the uses of it in "the real world." I decided to look into it again about a week ago and fell totally in love with it! I've been hacking away at this little program, Regress, both for fun/learning purposes and so that I can use it for some projects at my work. Obviously, since I've only been working with Haskell for like a week the code base is probably not the best that it could be. Baby steps, right? :)
Glad you decided to give Haskell a second look! Quick thoughts from browsing: * you generally want to put the type signature close to (read: on the line above) the function itself * should probably put a space between IO and (); I'm pretty surprised IO() compiled, since I'm pretty sure IOString wouldn't * I think your definition for `convert` could just be `convert = map read` since the type you're reading to (Double) can be inferred. In this case, it probably doesn't need to be defined Other than that, I think what you've written is fairly idiomatic, or could go either way in styling depending on who you ask. I hope you keep at it, there's lots to learn!
`foldr` is much more natural than `foldl`. It sounds like `foldl` is more similar to JavaScript's `reduce`, but it would nice to see an comment that `foldr` should be preferred. Also, I think simplifying your lambda functions would better demonstrate the simplicity of a higher-order approach. E.G. * `(\acc _ -&gt; acc + 1)` ~&gt; `(+1)` * `(\acc curr -&gt; acc + curr)` ~&gt; `(+)` * `(\acc curr -&gt; if item == curr then True else acc )` ~&gt; `((||) . (item ==))` I get that you are trying to show similar looking code the the JavaScript examples, but I think showing both the ones you have now and then the more idiomatic, higher-order version would really drill in the point.
Looking forward to it!
&gt; should probably put a space between IO and (); I'm pretty surprised IO() compiled, since I'm pretty sure IOString wouldn't There's nothing particularly surprising about this, it's just how the language works. `IO()` works for the same reason the parser doesn't get confused by `a+b` rather than `a + b`.
&gt; didn't really see the uses of it in "the real world." Yeah, I think the main problem is still a lack of really very visible real world users. There are industrial users of Haskell, but to me it seems most of them are into middleware data processing things which is important, but not very sexy. There are nowadays not that many things which I *wouldn't* use Haskell for, but that you *can* use Haskell for most things isn't obvious at all to an outside observer I guess.
doesn't [unliftio](https://www.reddit.com/r/haskell/comments/98xcc2/weird_unliftio/) make monad transformers composable? As lenses do records. Strings are a pain though, yeah I agree with that.
Just do it elm architecture style, it's trivial to build a state machine in that, because it's basically a big switch case statement. Yes clients usually think in screens, but screens suck for UX. I want to jam everything together because it's a nicer design. Besides if you keep on changing screens why even bother with client side scripting? Why not use plain HTML style links and forms. That's much easier and the state is formalized by HTTP.
Thanks for the tips!! I‚Äôll go ahead and change those around when I get off of work later tonight :)
Unliftio limits you to using only specific types of monads and monad transformers; no Cont / ContT for example.
A better `head`: `head = foldr const undefined`
Shouldn't the first one be `((+1) . const`) ?
Practicing code golf will teach you all sorts of interesting things about how Haskell is parsed. For example, this is a valid definition: f"a"=5 and so is this: f'a'=5 but the first one defines a partial function that is defined only for the input `"a"` and which returns `5`, whereas the second is creates an identifier named `f'a'` which has the value `5`... not a partial function which accepts only the character 'a' as one might expect.
I‚Äôm keen to try this now! I‚Äôm a Pure Data user but I prefer to handle complexity in Haskell, so this library is music to my ears... (excuse the pun) ;)
Great article! How does RIO compare with Classy-Prelude? Where lie the tradeoffs?
You are absolutely right. That's what I get for writing without actually jumping into GHCi. The last one was getting a bit lengthy for a point-free function anyway. To be honest, I would have broken it apart into `any (item ==)` and of course `any f = foldr ((||) . f)`. Funny my original ordering is correct for `foldr`. I'd like to pretend I was thinking of `foldr` but in truth I just didn't proof read ;).
Do you sponsor visas? :) It's always nice to announce this
I'm dumbfounded. I don't know why this has happened since Haskell incorporated the most cellebrated, the killer feature of functional language: getters and setters implemented in dozens of packages with hundred of modules. ah, and now we have semigroups, foldable and traversable, which allows endless play with your favorite toy lists. don't forget that. if that is not attractive for die hard programmers what else could???
It's nice to see the exploration of the range from initial to final of DSLs at work here, but these days when I see the word "Performance" in the title of a talk I expect to see some numbers that I can reproduce. I didn't see anything of the sort in the talk. If anyone in contact with the original author could ask him to provide a link to some reproducible benchmark, so that you could put it in the video description, that would be great. &amp;#x200B; Discussions about performance without any numbers tend to generate lore.
When I ask for the type of **length . filter**, I get: (length . filter) :: Foldable ((-&gt;) [a]) =&gt; (a -&gt; Bool) -&gt; Int (a -&gt; Bool) would be the function passed to filter, with the Int being the result, right? What's with the funky ((-&gt;) \[a\]) type constraint?
Let's bring some context here in order to understand what's going on: 1. The type of the `filter` function. **Note** how I place `()` in the type definition. `-&gt;` is right-associative. In simple words: `a -&gt; b -&gt; c` is the same as `a -&gt; (b -&gt; c)`. You can think for now that all functions in Haskell have exactly one argument and return exactly one value: filter :: (e -&gt; Bool) -&gt; ([e] -&gt; [e]) 2. The type of the `length` function: length :: Foldable f =&gt; f x -&gt; Int 3. The type of the composition operator: (.) :: (b -&gt; c) -&gt; (a -&gt; b) -&gt; (a -&gt; c) Now we just need to solve the unification problem! Or just pretend that we are GHC. So let's try to match types. After applying the dot operator to `length` and `filter` we notice: (b -&gt; c) = Foldable f =&gt; f x -&gt; Int (a -&gt; b) = (e -&gt; Bool) -&gt; ([e] -&gt; [e]) From here we see that: a = (e -&gt; Bool) b = [e] -&gt; [e] c = Int Now you can see why the result type is: `(e -&gt; Bool) -&gt; Int)` (modulo variable names, I used all unique type variable names to prevent confusion) (([e] -&gt; [e]) -&gt; c) = Foldable f =&gt; f x -&gt; Int And from here we can observe that: ([e] -&gt; [e]) = Foldable f =&gt; f x `[e] -&gt; [e]` can be written in prefix form like `(-&gt;) [e] [e]` (because `(-&gt;)` has kind `Type -&gt; Type -&gt; Type)`). Type variable `f` should have kind `Type -&gt; Type` so from here we see that: (-&gt;) [e] = f [e] = x
Luckily, /u/isovector is on Reddit, so we can just ask him directly :)
Thanks :) One of the biggest difficulties I'm having is working out (intuitively) which way to bounce my eyes to follow the varying associativies and precedences. You'll forgive me for this, being mostly a lisp programmer. I'm not used to having to think about these sorts of things ;)
[removed]
Too easy? Why do you not want it to be easy?
I might try this on Windows later, but ZeroMQ as a dependency for a REPL?
There are a couple of reasons for the ZMQ dependency: * I needed some sort of messaging infrastructure for the Haskell and Python parts of ptGHCi to talk to one another, and ZeroMQ abstracts a lot of the tedious bits * More importantly: in the future I want to support ptGHCi as a kernel for Jupyter notebooks - and Jupyter's wire protocol is based on ZeroMQ.
I wish more intermediate-to-power-users would document and discuss somewhere their practices, lessons learned, preferred library combinations.
It's not finished yet, but I'll send it to you when it's all done! I used reflex just to provide me with a stable ghcjs (probably did stuff wrong). The project itself is a Haskell library for making presentations and interactive content using FRP - sort of a crazy person's LaTeX for PowerPoints!
Looks amazing from the README! I'm trying to install this on Windows, but can't get it to work. Before building it turned out I needed to do \`stack exec -- pacman -S mingw64/mingw-w64-x86\_64-zeromq mingw64/mingw-w64-x86\_64-python3-pyzmq\`. Once I built it, I ran it using \`stack exec ptghci\` (I had to use \`stack exec\` to get it to recognise \`stack\`'s installation of \`zmq\`), but then I get this error: &amp;#x200B; C:\\Users\\bradn&gt;stack exec ptghci Could not find platform independent libraries &lt;prefix&gt; Could not find platform dependent libraries &lt;exec\_prefix&gt; Consider setting $PYTHONHOME to &lt;prefix&gt;\[:&lt;exec\_prefix&gt;\] \*\*Engine stopping\*\* Fatal Python error: initfsencoding: unable to load the file system codec Traceback (most recent call last): File "&lt;frozen importlib.\_bootstrap\_external&gt;", line 1219, in \_path\_importer\_cache KeyError: 'C:\\\\Users\\\\bradn\\\\Documents\\\\Haskell\\\\ptghci\\\\.stack-work\\\\install\\\\fd0322d0\\\\share\\\\x86\_64-windows-ghc-8.6.4\\\\ptghci-0.1.0.0\\\\pybits' During handling of the above exception, another exception occurred: Traceback (most recent call last): File "&lt;frozen importlib.\_bootstrap&gt;", line 983, in \_find\_and\_load File "&lt;frozen importlib.\_bootstrap&gt;", line 963, in \_find\_and\_load\_unlocked File "&lt;frozen importlib.\_bootstrap&gt;", line 906, in \_find\_spec File "&lt;frozen importlib.\_bootstrap\_external&gt;", line 1280, in find\_spec File "&lt;frozen importlib.\_bootstrap\_external&gt;", line 1249, in \_get\_spec File "&lt;frozen importlib.\_bootstrap\_external&gt;", line 1221, in \_path\_importer\_cache File "&lt;frozen importlib.\_bootstrap\_external&gt;", line 1197, in \_path\_hooks File "&lt;frozen importlib.\_bootstrap\_external&gt;", line 1447, in path\_hook\_for\_FileFinder File "&lt;frozen importlib.\_bootstrap\_external&gt;", line 102, in \_path\_isdir File "&lt;frozen importlib.\_bootstrap\_external&gt;", line 87, in \_path\_is\_mode\_type File "&lt;frozen importlib.\_bootstrap\_external&gt;", line 81, in \_path\_stat EOFError: Thrown from Haskell &amp;#x200B; What's happening here?
There is [a benchmark folder](https://github.com/isovector/polysemy/tree/master/bench) which I [contributed](https://github.com/isovector/polysemy/pull/3) to the project, but I haven't ran it since the project was called too-fast-too-free, and at the time I had some [concerns about whether I did it right] (https://github.com/isovector/polysemy/pull/5).
&gt;What's happening here? To be honest, I got about as far as you did when I first tried running on Windows then figured I was Doing It Wrong but someone with more experience dealing with stack and its bundled MSYS environment on Windows may have more luck. I've opened an issue [here](https://github.com/litxio/ptghci/issues/1). I think the first few lines are they key -- for some reason, when the Python interpreter is instantiated the library paths are not getting initialized properly. I need to dig in further to figure out why this may be happening.
This is a fair argument. As far as I know, no real-world applications exist built out of free monads, so it's hard to get any sort of real-world benchmarks. We can write micro benchmarks, but they're never going to tell us anything conclusive. Personally, I'm of the camp that the O(freer-simple) is fast enough for most real-world applications, and so I've been doing this performance work as more of a proof of concept for the doubters more than anything else. To that end, my performance testing consisted of inspecting the generated core of the interpreters, and manually coercing the library into something that would reliably generate code that can case-of-known-case away. The library as it exists today is the expression of that; it's not necessarily *fast* so much as amenable to being fast if you [add a few core todo passes](https://gist.github.com/isovector/e4832512ec9c73bff94432a7a58470f9#gistcomment-2872671). This can be done via a core plugin in library code. My exploration down this hole exists in the form of a [gist](https://gist.github.com/isovector/e4832512ec9c73bff94432a7a58470f9), discussion on the [GHC bug I filed](https://gitlab.haskell.org/ghc/ghc/issues/16473) and some [inspection tests](https://github.com/isovector/polysemy/blob/master/test/FusionSpec.hs#L29) proving that the intermediate representations inline away. All of these claims are conditional on [!668](https://gitlab.haskell.org/ghc/ghc/merge_requests/668) being merged. If you have any concrete suggestions for how I can add more proof of perf to the library, please let me know!
Interesting. I'm not too good with Python so I'll leave that with you, but I know a bit more about stack's MSYS. I don't think that's the problem though (unless I didn't install the python3 ZMQ bindings properly). From now on I think I'll put any discussion about this on the GitHub issue thread.
What is the industry standard for restful Haskell APIs?
Any thoughts on how to improve?
 foldl (+++) "" (reverse x) = Data.List.unwords x I usually use `quotRem` instead of a loose `div` and `mod`, because it is faster, but in this case performance is not an issue. `x ++ [y]` is slow (O(length(x))). So reverse (toDigits x) is just very silly performance-wise, but again in this case performance is not really an issue. You use a lot of `Int` and `String` and tuples, try making your own data types: data Suffix = NoSuffix | Thousand | Million | ... etc data Ones = Zero | One | Two | Three | ... data Tens = Zero | Ten | Twenty | Thirty | ... data Hundreds = Zero | One | Two | ... data EnglishNumberPart = EnglishNumberPart Hunderds Tens Ones data EnglishNumber = [EnglishNumberPart] -- comment about if it is big or little endian (I like little endian) Or if that is too much work you can use newtype wrappers: newtype Ones = Ones Int newtype Tens = Tens Int newtype Hundreds = Hundreds Int This will improve the readability of the types.
I tried, and ultimately failed, to start a project at work using Haskell. I may write about it some day. However I did end up with a group of interested people at work to teach Haskell to. We meet up regularly once a week and have lunch together. We've been building a web application and occasionally follow diversions into theory or side projects. One or two of my more enthusiastic students have gone on to write their own Haskell programs and libraries. As they are primarily employed to write Javascript or Ruby on the job this was a huge step. At least one of them shared with me the reason why they stick with learning Haskell: It helped them to write better Javascript. Once they were used to composing functions together in Haskell they immediately saw the benefit of that pattern and it has helped them write code that is more succinct, compose-able, and generalized. It has helped them to better understand how to *think* in types so that when they are using tools like Flow to annotate their code or deciding how to structure their programes they are more effective. In contrast to other programmers on our team who have not taken up Haskell, learning tools like Flow is much more difficult and frustrating. They don't understand how to use the type checker and see it as a nuisance instead of a boon. They tend to write code that is much more procedural, that mixes side effects, and is thus harder to test... their code is less compose-able, it doesn't tend to get reused as much in the code base, and it is often resistant to refactoring (instead accruing lines of code months later when requirements or business logic changes). I've come to believe that regardless of whether you think types are useful or important, they're there and languages differ in how much they expose the language of types to the programmer. If you can't see the types then you end up writing code that either discovers them at run time or encodes them in some informal manner. I think the more expressive the type system, the better and that soundness matters. Haskell's type system isn't perfect or even finished... it's evolving... but it's so much better than everything else that's out there in the "main stream" right now. Honestly I don't like the maxim that, "learning X will make you a better programmer." I've went down that road twice: first with Common Lisp and more recently with Haskell. It tends to put people off by making them feel bad that they're not as good as you for not learning Haskell. The desire to improve one's skill and knowledge is a personal journey and we don't need to measure whether Haskell will make you a better programmer than non-Haskell programmers. There are good, practical reasons for using Haskell and if it helps you or makes you happy then write more code using Haskell, tell more people about it, teach people, and enjoy it.
Haskell-Ide-Engine has a lot of list. Currently not really refactoring, e.g. extracting an expression into a where clause, but renaming should work. It is under heavy development right now, so expect a lot of improvements over the next months!
Servant, probably.
Vim can use HIE to get 1 and 2. --- I don't use an traditional IDE; I use vim, and some plugins but I haven't yet added communication to HIE as part of that. I really do need to spend some time getting Vim and HIE working together well and write it up somewhere.
&gt; I usually use quotRem instead of a separate div and mod, because it is faster, but in this case performance is not an issue. You should use `divMod` to replace `div` and `mod` or `quotRem` to replace `quot` and `rem`, otherwise you are not just changing performance, but also semantics.
`[a]` isn't an array in Haskell, it's a list. Data.Array has arrays, though they are mostly replaced by the vectors from Data.Vector.
Well, I'm also usually working only on positive integers, so the semantics won't change.
The only place you use `toDigits` is in `digitGroups`, where it is coupled with a `reverse`. It also uses the relatively inefficient `++` operator. You can get rid of the reverse and the `++` by doing toDigits :: Int -&gt; [Int] toDigits 0 = [] toDigits n = (n `mod` 10) : toDigits (n `div` 10) The `digitGroups` function works to group the digits into triplets, and takes care to deal with uneven lengths. It suggests that what you really want is not to convert your number into digits 0-9, but into "digits" 0-999. So that makes `toDigits` toTripleDigits :: Int -&gt; [Int] toTripleDigits 0 = [] toTripleDigits n = (n `mod` 1000) : toTripleDigits (n `div` 1000) intToTriple :: Int -&gt; (Int, Int, Int) intToTriple n = (hundreds, tens, units) where hundreds = n `div` 100 tens = (n `div` 10) `mod` 10 units = n `mod` 10 digitGroups :: Int -&gt; [(Int, Int, Int)] digitGroups n = map toTripleDigits $ toTripleDigits n I would be inclined to see if there was another way to deal with the `+++` operator, in much the same way that /u/ishmandoo suggested `unwords` instead of `foldl (+++) "" (reverse x)`. In this case, and with these usages, I'd be tempted to use `unwords` as well, so you'd have (for instance) toWords2 (2,a) = unwords ["twenty", toWords1 a] However, while I don't particularly like `toWords3, toWords2, toWords1`, I can't see a compelling way to improve them. Even going to `unwords` as suggested above doesn't look significantly better to me. I'd like to split the generation of "twenty, thirty, ..." away, so that we have `toWords2 (t, u) = tensWords t +++ unitsWords u` Perhaps something like this: tensWords :: [String] tensWords = ["", "", "twenty", "thirty", "forty", "fifty", "sixty", "seventy", "eighty", "ninety"] unitsWords :: [String] unitsWords = "", "one", "two", "three", "four", "five", "six", "seven", eight", "nine" teenWord :: Int -&gt; String teenWord 10 = "ten" teenWord 11 = "eleven" teenWord 12 = "twelve" teenWord 13 = "thirteen" teenWord 15 = "fifteen" teenWord 18 = "eighteen" teenWord n = (unitsWords !! (n `mod` 10)) ++ "teen" tensWord :: Int -&gt; String tensWord n | n &lt; 10 = unitsWords !! n tensWord n | n &lt; 20 = teenWord n tensWord n = tensWords !! (n `div` 10) +++ unitsWords !! (n `mod` 10) hundredsWord :: Int -&gt; String hundredsWord n | n &lt; 100 = tensWord n hundredsWord n = (unitsWord !! (n `div` 100)) +++ "hundred" +++ (tensWord n `mod` 100) I'm just not sure that's an _improvement_, per se, just different.
&gt; Long type level lists
&gt; Long type level lists I do that all the time, but I'm a Sagittarius so I can't help it.
On my Mac, the first time I ran 'ptghci,' I got the same stack trace as above. Switched into a Haskell project directory, got the following: `**Engine stopping**` `Fatal Python error: initsite: Failed to import the site module` &amp;#x200B; Ran again as 'stack exec ptghci', got the following: `**Engine stopping**` `Error processing line 1 of /usr/local/opt/python/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/matplotlib-3.0.2-py3.7-nspkg.pth:` I just ran it twice in a row as 'stack exec ptghci', in the same place, and got two different messages. `Fatal Python error: initfsencoding: unable to load the file system codec` and `Fatal Python error: initsite: Failed to import the site module` Swear to Oleg, I'm getting a different message every time I run it.
I've used both vim and spacemacs. Spacemacs does most of those things out of the box at the cost of some startup time.
Sounds pretty cool. Do you know a place in which I can start learning it?
As a vim user, I do not really want to switch to spacemacs..
Spacemacs can be very vim like if you want it to be. And it supports almost your entire list of requirements without much trouble at all. I really think you should at least give it a try...
For GHC to track that many constructors would require many more than 2‚Å∂¬≥ bytes of information, which means that there's no way it could be compiled except on a 128-bit machine. Also, no human could keep track of that many constructors, or maintain code with that many. So it stops being an issue long before you read the fromEnum limit.
I wonder how the div/mod version compares to toDigits :: Int -&gt; [Int] toDigits = map (read . pure) . show
&gt; For GHC to track that many constructors would require many more than 2‚Å∂¬≥ bytes of information. Apparently yes, but in theory the compiler could figure out that the type can be emulated by using `Integer`. However, I guess that would be one of the many directed (towards certain code) optimizations which in reality don't make a difference and hence nobody bothers to implement.. &gt; Also, no human could keep track of that many constructors, or maintain code with that many. Yeah, it's just a thought experiment really. So GHC is (justifiably so!) deliberately ignoring this "issue"?
Show uses `quotRem` internally, it might be slightly faster because it uses unboxed values, but then reading it back to digits again seems very wasteful to me.
&gt;As far as I know, no real-world applications exist built out of free monads, so it's hard to get any sort of real-world benchmarks. We had a couple web services running on [`freer`](https://github.com/TaktInc/freer) in production at Takt. All very IO-bound though. Probably still in production is my guess too.
&gt; We have a `Planets` effect that calculates positions of astronomical bodies. Made me grin :D
This probably isn't the right direction in which to look for optimizations but then perhaps... import Data.Char toDigits :: Int -&gt; [Int] toDigits = map (subtract 48 . ord) . show
The source of the program alone would be &gt; 2^63 bytes (9.2 exabytes)!
It's not an IDE, but vim can do most all of these things natively and quite nicely: 1. `:vimgrep` in source directory. This will populate the quickfix list, which will allow to see all usages and quickly jump through them. What's more, you can run a command on each entry in the list with `:cdo`, which is useful for renaming functions or doing other tricky bits of editing programmatically. Haskell usually doesn't have a lot of symbol shadowing, so it works pretty well, in my experience. 2. Generate a tags file either with `ghci` (can be done programmatically from stdin) or something like `hasktags`. Once you have that, you can use `&lt;C-]&gt;` to jump to the definition of the symbol under the cursor, `&lt;C-t&gt;` to pop back up the tag stack. Vim has a lot of powerful features around tags (such as completion), all of which you get for free when you make a tags file. Pro tip: use a file watcher program such as `entr` to automatically regenerate the tags file when you save a file. 3. Since Haskell has really simple syntax (and is quite terse), it's very amenable to refactoring using the technique I mentioned in (1). You can populate the quickfix list and use a whole suite of commands for manipulating the entries. `:s` is probably all you'd ever need 99% of the time though. For more complex refactoring, you can record your refactor in a macro and execute the macro for every entry in the quickfix list. There's really no limit to what you can do with this. 4. Should work out of the box. 5. If you use `stack`, as of v8.1 vim ships with support for building your project with `stack build` and populating the quickfix list with errors (vim actually can do this for many, many languages using something called "compiler plugins"). You'll need to enable this functionality by executing `:compiler stack` and `set makeprg stack\ build` in vim or (preferably) putting those commands in `.vim/after/ftplugin/haskell.vim` so that they will execute whenever you edit a Haskell file. Once you have it set up, you can simply invoke `:make` to compile the project and populate the quickfix list with errors. 6. This is something vim can't do without plugins, however you can set vim's `formatprg` to a formatting tool such as `brittany`. This will let you format code using the `gq` operator. You can even format the whole file with a simple autocommand every time you save, if you so wish. Vim also has settings for non-language-specific styling rules, like restricting the line length to 80 characters (`:h textwidth`).
That's probably faster, but `show` is still very complex, look at the source code of `showSignedInt`: https://hackage.haskell.org/package/base-4.12.0.0/docs/src/GHC.Show.html#showSignedInt, and the `itos` function below it. Another reason that I don't like this is that it converts to an intermediate type which is completely unnecessary. I would implement it like this: import Data.List (unfoldr) import Data.Tuple (swap) toDigits = unfoldr uncons where uncons 0 = Nothing uncons x = Just (swap (quotRem x 10)) in
At least, none that I have access to to run as a benchmark :)
Thanks for the comments, guys. I'm studying them.
Similar - a refreshingly varied set of error messages on mac, including just a sad `**Engine stopping**` requiring a `kill -9`, or fd:52: Data.ByteString.hGetLine: end of file fd:50: Data.ByteString.hGetLine: end of file ptghci: UnexpectedExit "stack ghci " ""
Neat write-up, very approachable.
I switched over as a somewhat novice vim user and found it to be surprisingly faithful. If you've got muscle memory built for some feature that evil mode doesn't support, I could see that being a legitimate reason to steer clear, but I'd urge you to give it a spin if you haven't yet - it's really quite good.
Super cool. We tried a similar approach at Takt, but got bogged down in the details. Looks like you've solved all the problems we had --- looking forward to trying `Compat` the next time I need to version schemas!
Might as well file a bug!
&gt;For GHC to track that many constructors would require many more than 2‚Å∂¬≥ bytes of information Why so much? I don't know much about GHC internals, but you should be able to compress it to 2^(63) *bits*, because a value of type `T` can only ever be one of those constructors and not multiple at once.
Unfortunately I don't think we can right now, but I'm trying to confirm for sure and will update if we can.
 If your program is important, like peoples lives depend on it, it behooves the programmer to use all available tools available to ensure the correctness of the output; and ensure that the junior college drop out the management hires to "update" the program two years later does not end up causing a catastrophe. Eventually there will be an international standard on how to specify the units in large data sets. If your program is at all useful, imagine yourself on the witness stand testifying in a law suite; it will be great fun (for the spectators) to watch you attempt to persuade a hostile lawyer about "pointless units" and that "integration testing" was sufficient.
IMO, it's not a particularly interesting or worthwhile comparison because `RIO.Prelude` does so very little: * Re-exports safe functions from `Prelude` * Re-exports commonly-useful modules (e.g. `Control.Monad`) * ... that's it? Most of `RIO`s essence is the `RIO env` Monad. The fact that it comes with a slim, unassuming prelude is a bit of an incidental bonus. That said, I very much prefer `RIO` over `ClassyPrelude` because the approach taken by `ClassyPrelude` doesn't work for me. All I find are worse errors and type ambiguity. But if you're into the philosophy behind `ClassyPrelude`, you're going to prefer that over `RIO`, which intentionally does none of the classy things.
Ran into a different error in macOS. I have raised an issue for the same https://github.com/litxio/ptghci/issues/4
Rethinking `Enum` to be something more inspired is the basis of my [cantor-pairing](https://hackage.haskell.org/package/cantor-pairing) library. The underlying idea is that you can encode arbitrary information in an `Integer`. Just make a generic instance: import GHC.Generics import Cantor data MyType = MyType { value1 :: [ Maybe Bool ] , value2 :: Integer } deriving (Generic) instance Cantor MyType and use `fromCantor :: Cantor a =&gt; a -&gt; Integer` and `toCantor :: Cantor a =&gt; Integer -&gt; a`! Note that this does *not* require your type to be of finite cardinality, merely that if it's infinite, you didn't choose a "too big" (uncountable) infinite.
Vscode maybe
Indeed. using `ReaderT Context IO` is like I'm completely done with monads transformers, free monads and that shit. I would really use IO and IORefs, but I want to accepted as the kind of cool hipster that I am, so i use this that add the minimum level of complexity and disturbance"
I'm talking about normal, everyday programming, not √¶ronautics.
I use Visual Studio Code with extensions: Haskero (1,2,3,4,5), Haskutil (3), hlint (6) and stylish-haskell (auto-formatting).
Thank you for this answer, this is pretty great (much nicer implemented than what I would have done, if I had to work around this limitation)! While this question was merely an experiment out of curiosity rather than an actual use case for it, may I ask when you needed this?
Bombshell dropped at 29:26 about the relationship between `ReaderT` and `Freer`.
It‚Äôs more of a curiosity than anything practical, but sometimes the function enumeration comes in handy. For example, it makes it very easy to answer questions like ‚ÄúAre all functions with the type `Bool -&gt; Bool -&gt; Bool` associative?‚Äù (They‚Äôre not, but most of the ones people can name off the top of their head are!)
I disagree with both ideas, but for completely different reasons. First, `!` for partial functions (i.e., functions that may evaluate to some kind of bottom, whether that be a pattern match failure, an exception, or nontermination). The problem is that this is impossible to do completely right, because Haskell is Turing complete, and bottom inhabits every type - practically, this means that while there are expressions that are obviously bottom (such as `case 1 of { 2 -&gt; () }`), there are also ones for which bottomness is undecidable (the Halting Problem, essentially), and there are functions for which decidability depends on the decidability of their arguments. So if we were to adopt this `!` suffix, then that would suggest, incorrectly, that functions without it are total - but we can rarely fully guarantee this. And, worse, due to Haskell's non-strict evaluation semantics, it's not even obvious where things are going to blow up, or whether they will blow up at all. Take, for example, `repeat`, which produces an infinite list, which, if evaluated fully, is bottom - so `repeat` on its own is technically partial. But due to non-strict evaluation, we can take a finite portion from the beginning of this infinite list, and evaluation stops there, so `take 10 . repeat` is *not* a bottom. Does that mean `repeat` should be `repeat!`? Likewise, `(1, error "nope")`, if fully evaluated, will throw an error, but if we say `fst (1, error "nope")`, then everything is peachy. In short, the inconvenient truth is that Haskell is not a total language, and we can not usually be completely sure that our programs are total. On to `?`. I'm opposed to this one for two reasons. First, what's so special about `Maybe` that it deserves a suffix of its own? There are dozens of other types that could also use one - lists, `Either`, `IO`, you name it. And many libraries out there will introduce their own types that are domain-specific isomorphs of one of those, like for example the typical `data ParseResult a = ParseError ErrorInfo | ParseOK a`. Should libraries introduce their own suffixes for those? And the other reason is that this would be redundant; the information is already there, in the types, and unlike a suffix, which would be a manual effort, the types are enforced, and often even inferred, by the compiler. We're not in the business of avoiding compiler errors; we're in the business of using compiler errors to write better code. We can even provoke compiler errors (or warnings) as a means to extract information from the compiler: for example, we can use "type holes" to make the compiler dump the inferred type for us as a warning. E.g., suppose you wrote a function `foo = putStrLn . ("Value is: " ++) . show`, and you're lazy to write out its type - well, just write `foo :: _`, hit "compile", and copy-paste the type `Show a =&gt; a -&gt; IO ()` from the error message. The reason these suffixes are popular in many Lisps is exactly because Lisp doesn't have a type checker; you have to either verify correctness by empirical experiment (run the code a lot and see if you can catch it producing incorrect results), or you have to do the consistency checks yourself; and since humans aren't computers, we need all the help we can get, including little tags on identifiers that tell us certain key aspects of their expected types. "This may crash", "this may be `nil`", "this will return a boolean", "this is a dynamically-scoped variable", stuff like that. But in Haskell, the compiler does that job for us, so we don't really need to clutter identifiers with that information. The only situation where it does make sense is when we have both a "wrapped" and an "unwrapped" version of the same value in the same scope, e.g.: `foo mVal = let val = fromMaybe "yay" mVal in print val` - here, the `m-` prefix says "this is the `Maybe` value that gets passed in, and `val` is the "de-Maybe'd" version". But the purpose is not so much remembering that `Maybe` is involved at all, but rather just to tell the two identifiers apart in a meaningful and easy to remember way.
I see, I don't understand how you're inferring from the enumeration that not all functions `Bool -&gt; Bool -&gt; Bool` are not associative? If it's worth it, maybe you could create a new post introducing this library. NB: How about `True || (undefined || undefined) ‚â° (True || undefined) || undefined` ;P
Maybe I should have been more clear, but my suggestion is not for this to be an absolute rule, nor is it supposed to in any way replace the type system. It's just supposed to be an additional thing that libraries could generally follow when appropriate. Also `?` returning `Either` or similar would also be fine, just generally `?` to mean "safe but might return an error-ish state for you to handle". Likewise `!` would just be for cases of clear intentional partiality such as a literal `error "foo"` call halfway through the function, not a perfect safety net. The fact of the matter is that if we want a `minimum` that returns a `Maybe`, a partial `minimum`, and a `minimum` that uses some other type aspects to make things safe such as `Bounded` or `Foldable1` then we NEED either a suffix or a prefix to avoid name collisions. The same applies to a wide variety of functions that naturally support a partial variant, a total variant with Maybe or Either I am simply trying to replace an `unsafe` prefix or `Partial` suffix or `May` suffix or whatever would be done currently with a simple `!` and `?` which are already used for operators. If you really are against the proposal entirely, then what are your specific reasons for wanting to disallow `!` and `?` completely from identifiers, and also how would you like `minimum` and it's several variants to be named?
Cf. https://hackage.haskell.org/package/safe-0.3.17/docs/Safe-Partial.html if you've not seen it before. I agree that the naming is irritatingly ad-hoc, often inconsistent, and that missing partial/complete versions is a problem, but don't really like the proposal as is. I think my gut response is that these "obviously partial" functions are retained mostly for compatability's sake, and less-burdened alternative preludes rightly disinclude them. Another thought, when working with lenses the difference is often clear from eg. `^?` vs `^.`.
So ignoring backwards compatibility you wouldn‚Äôt have `head!` or `minimum!`? That‚Äôs fairly reasonable although I have some follow up questions. In such a situation what would you want people to do if they do genuinely want the partial version? Perhaps explicitly use `error` and `undefined` such as `fromMaybe undefined`? How would you differentiate between `Maybe`/`Result` versions and type restricted versions that can‚Äôt fail? Honestly as I type it I‚Äôm realizing that often the specific way in which the type is restricted gives rise to a natural name, such as `supremum` or `minimum1`. So maybe that‚Äôs not an issue.
I made a [post introducing the library](https://identicalsnowflake.github.io/Cantor.html), although it‚Äôs more about explaining the overall idea than demonstrating how to use it.
Agreed! I also have a good Emacs setup for Haskell but for the last year or so I prefer VSCode.
&gt;`toCantor :: Cantor a =&gt; Integer -&gt; a`! /r/unexpectedfactorial Though actually, what would the factorial of a type be?
Have you considered contributing to [IHaskell](https://github.com/gibiansky/IHaskell)?
It looks like you're [communicating with a GHCi subprocess](https://github.com/litxio/ptghci/blob/9d33af637e3018d29af73f331c1dc951967f4bd6/src/Language/Haskell/PtGhci/Ghci.hs) instead of using the GHC API. This is really interesting and I look forward to seeing whether that helps or hinders you in adding more complex features. It definitely seems more robust to multiple GHC versions, which is great.
Also ruby. Because reasons....
Super cool solution. I wonder how much of this can be translated to manipulating data in a database at a distance (migrating the schema through SQL instead of downloading, transforming, and uploading in pure Haskell).
It's a lot more limited than that; UnliftIO doesn't even support StateT nor ExceptT! It only supports `ReaderT r IO` and Monad transformers which are isomorphic to it, e.g. state implemented using IORefs, LoggingT, etc.
I don‚Äôt think it‚Äôd be that hard, I think you would just need a suitable choice of CompatF that has a Monad instance with the right behavior. If you can get a Monad instance that composes schema migrations in the right way, the migrate method can return a SQL statement for a given record that migrates the record to the latest schema version. Seems worth a closer look to me.
I'll have to investigate... thanks for the reply! We already have a method of schema migration at work but it isn't as elegant or safe as I'd like. I just need to figure out a performant way of doing it, and SQL in Postgres is the fastest way.
to get `a * (a-1) * (a-2) * ...` you'd need subtraction on types, and i haven't seen any definitions of that (not sure if a sensible CAN exist either ‚Äì `a + (-a) = 0`, meaning it must be uninhabited, but for an inhabited `a`, `a + _` is inhabited as well, so we get a contradiction)
My goals are a bit different than IHaskell. IHaskell completely replaces GHCi and implements only a subset of GHCi commands and capabilities. When you run IHaskell, you are running in the IHaskell package context ([link](https://github.com/gibiansky/IHaskell#where-are-my-packages-ihaskell--stack)). You can't just cd to your project directory and do \`stack ghci\` or \`cabal new-repl\` like normal. ptGHCi is just GHCi with a fancy wrapper -- so it should work as expected out of the box. On the other hand, IHaskell supports various fancy in-notebook displays (inline images and HTML) that may be difficult/impossible to support without "taking over" like IHaskell does (or maybe not - I haven't looked into this in detail yet).
This is really cool. Great concept and excellent explanation of the type work you had to do to get there. I'm still no expert on type-heavy programming but I feel like I get closer every time I read an article like this!
Thanks! I found the constraints package brain-melting when I first encountered it, so I wanted to write something up once I finally found a practical-ish use for it.
Clearly I need to work on the start-up error messages... :-o I suspect the reason you're getting a different message each time is that the Haskell thread is dying and raising an asynchronous exception in the Python interpreter, which dies at a random moment in execution with a misleading traceback. I need to get access to a mac to see if I can replicate this.
I can neither confirm nor deny that it is still running in production, but yes that is a good guess :).
I think I've heard of difference types before. It's basically a type with certain values forbidden. For instance, in a system with difference types, the type of `quot` would be: quot :: Integer -&gt; (Integer - 0) -&gt; Integer This shows the constraint that the second argument can't be zero. So `a!` would contain, if it isn't 0, an `a`. Then (assuming `a` isn't 0 or 1) it would have an `a - 1`, which is an `a` with one value forbidden. The most obvious choice as to which value to forbid is the first one. Then it has an `a - 2`, forbidding the two previous values, and hang on, this looks familiar. It's basically a permutation. So `a!` would be the type of permutations on `a`, or invertible functions `a -&gt; a`. And that pretty much is the definition of factorial, isn't it?
Because it needs to keep track of, at minimum, the name and type of each constructor.
I was really into jetbrain's projects
You should try out atom with the Haskell IDE plugin
You can do this in straight Haskell98 with polymorphic recursion. type Tree = Tree Identity data Tree‚Äô f a = Empty | Node a (f (Tree‚Äô (Pair f) a) data Pair f a = Pair (f a) (f a))
[removed]
I'm quite satisfied with Atom + [Haskell IDE Engine](https://github.com/haskell/haskell-ide-engine)
I can't find the source code tarball in the download page :(
&gt; Emacs - Because I use vim... Spacemacs.
https://downloads.haskell.org/~ghc/8.6.5/ghc-8.6.5-src.tar.xz
404 :(
Oh, I see - so the proposal isn't really about adding Hungarian suffixes per se, just about allowing `?` and `!` in non-operator identifiers. I still don't buy the cost/benefit tradeoff here though. The cost is substantial: we would have to further complicate the lexing rules, and there would be two more special cases new learners would have to face. And, even worse, it would have to be a breaking change, because right now, `foo!bar` lexes as identifier `foo`, operator `!`, identifier `bar`, but after the change, it would lex as identifier `foo!bar`, so any code out there that uses operators without whitespace around (which I believe is a lot) would break - or the change would have to be a language extension, but we already have way too many of those. And meanwhile, the benefit would be tiny - the only thing we would win is two more characters that could be used in cases where disambiguation is needed. And the way you envision that disambiguation isn't even the best one, usually, because the `!` or `?` tag isn't semantic. What do I mean by that? Well; suppose you have a function `sort :: Ord a =&gt; [a] -&gt; [a]`, and now you want to have a flavor that, instead of relying on the `Ord` instance, takes an explicit comparison function: `(a -&gt; a -&gt; Ordering) -&gt; [a] -&gt; [a]`. So what do we call that function? We could invent a suffix to signal that it takes a function, so, idk, maybe `sortF`? But that's not semantic, because our domain is not "Haskell lists and functions", it's "sorting lists", so a better name would be `sortBy` - and that's exactly what `base` goes for. As far as the `unsafe` or `Partial` markers go; these are absolutely fantastic exactly *because* they are so awkward. **THAT IS THE POINT**. Their awkwardness is a subtle hint that you probably don't want to be doing this. As for `minimum`; the situation we have isn't ideal, it would probably be better to have one of the following types: - `minimum :: Ord a =&gt; NonEmpty [a] -&gt; a` - `minimum :: Ord a =&gt; [a] -&gt; Maybe a` - `minimum :: Ord a =&gt; a -&gt; [a] -&gt; a` (this is essentially the `NonEmpty` flavor spelled out) - `minimum :: (Ord a, Monoid a) =&gt; [a] -&gt; a` (not a huge fan of this one though) And then the current `minimum` should be renamed to `unsafeMinimum` to make it awkward, or maybe `minimum1`, similar to `foldl1` and friends (because that's essentially what it is: `minimum1 = foldl1 min`). None of that is realistic though, unless we come up with a new breaking-change version of `base`, and I don't believe there is sufficient consensus to do that. Not yet, anyway.
Does it? I thought types were erased at runtime and names of constructors are kind of unimportant. You just need to know which one it is.
But the compiler needs more than 2‚Å∂¬≥ bytes to compile the program. And even more if it's got derived instances.
you're experiencing a CDN cache issue. just wait for the stale cache to be purged. or add a trailing / to the url.
&gt; As for minimum; the situation we have isn't ideal, it would probably be better to have one of the following types: I think the type I already gave were pretty optimal, definitely better than the `Monoid` approach, if we omit the partial version and don't allow for `?`/`!`: minimum :: Ord a =&gt; [a] -&gt; Maybe a minimum1 :: Ord a =&gt; NonEmpty a -&gt; a supremum :: (Bounded a, Ord a) =&gt; [a] -&gt; a &gt; And then the current `minimum` should be renamed to `unsafeMinimum` to make it awkward Please no, that is part of why I made this post, if you say `unsafe` you better be warning me about something worse than `_|_`: `unsafePerfomrIO`/`unsafeCoerce` etc. &gt; or maybe `minimum1`, similar to `foldl1` and friends Again please no, and again part of why I want something more commonly accepted like `!`, that `1` suffix is super useful for the `Foldable1` class and similar concepts. If I see `blah1` I want to safely assume that it's a total function that uses types to guarantee a non-empty argument, and I hate that `foldl1` isn't named `foldl1!` or similar to make that distinction clear.
I just have one correction: the `repeat` function isn't partial -- the infinite list that `repeat x` produces is *not* the same thing as bottom. Rather, it's the limit of this ascending sequence: _|_ &lt; (x : _|_) &lt; (x : (x : _|_)) &lt; (x : (x : (x : _|_))) &lt; ... This might be an infinite list of bottoms in the worst case, but if x is fully defined, then it will be as well.
Got it, thanks!
&gt; I'm guessing I don't understand the basic syntax at all.. It seems so! quadratic :: (Int, Int, Int) -&gt; Int -&gt; Int This means, roughly, that the `quadratic` function takes two argument, a tuple of 3 ints, and another int, and that it returns an int. The correct definition should be: quadratic :: (Int, Int, Int) -&gt; Int -&gt; Int quadratic (a, b, c) x = a * x * x + b * x + c You should really start by the beginning, and pick a tutorial.
You don't need to use a tuple. Something like: quad :: Int -&gt; Int -&gt; Int -&gt; Int -&gt; Int quad :: a b c x = ...
First, for integers, you want the operator `(^)`, not `(^^)`. Second, the variable `x` has to come from somewhere. Should it be a fourth piece of input to your `quadratic` function? Third, your type signature doesn't quite match your function definition. Assuming that `x` should be a fourth input, there are two obvious ways to fix it: quadratic :: Int -&gt; Int -&gt; Int -&gt; Int -&gt; Int quadratic a b c x = a * x ^ 2 + b * x + c main = do putStrLn "Ergebnis: " print (quadratic 2 5 7 3) Or: quadratic :: (Int, Int, Int) -&gt; Int -&gt; Int quadratic (a, b, c) x = a * x ^ 2 + b * x + c main = do putStrLn "Ergebnis: " print (quadratic (2, 5, 7) 3) The first one is more conventional than the second, but both work. The first is a function of four arguments, each of which is an integer. The second is a function of only two arguments, where the first argument is a tuple containing three integers, and the second is an integer. Does that make sense?
Thank you; yeah. I actually found some great things on youtube. But I thought playing around with it before watching those would be easier. Anyways, thanks a lot!
Thank you, makes sense :D
Kakoune [http://kakoune.org/](http://kakoune.org/) is not that well known - yet :) It's a bit like vim but in kakoune you first select objects and then decide what to do with them. It has highlighting, supports h-i-e, and it can use/utilize/interact with command-line tools and works reasonably well with tmux. E.g. for the 1, you can select all occurrencies at once and edit them so that you visually see what's happening. Haven't tried h-i-e yet but I'll guess that it may give you the 2 and it possibly supports tags (there is ctags-mode, haven't tried it yet). The 6. is accomplished with hlint-util that shows markings next to the lines needing attention. Please take a look at [http://kakoune.org/gallery.html](http://kakoune.org/gallery.html) where you will see some pictures.
&gt; Wouldn‚Äôt it be even cooler if this worked for every `Applicative`? [`Ap`](http://hackage.haskell.org/package/base-4.12.0.0/docs/Data-Monoid.html#t:Ap) can help you. ``` Prelude Control.Lens Data.Monoid&gt; getAp mempty :: [Sum Int] [Sum {getSum = 0}] Prelude Control.Lens Data.Monoid&gt; ala Ap foldMap [[1,2], [3,4], [5,7,11 :: Sum Int]] [Sum {getSum = 9},Sum {getSum = 11},Sum {getSum = 15},Sum {getSum = 10},Sum {getSum = 12},Sum {getSum = 16},Sum {getSum = 10},Sum {getSum = 12},Sum {getSum = 16},Sum {getSum = 11},Sum {getSum = 13},Sum {getSum = 17}] ``` Also for example, the `Monoid` instances of `Maybe` and `[]` are **not** induced by their `Applicative` instances.
You cannot print and read input in pure functions (Int -&gt; Int and so on), so you should divide the arithmetic and IO operations. Try to type :t putStrLn in ghci interpreter and watch the type it shows.
I agree with you in spirit, and I'd love for this to be possible, but the issue is that it's a breaking change. Like other people have mentioned, today "foo!bar" lexes as "foo ! bar". This gets especially thorny if you would allow arbitrary characters in a name (and not just ?, !, and ') since with lenses, it's extremely common to emulate OOP syntax with stuff like "a^.b.c.d". If we would look at other languages for a moment, Agda - a Haskell derivative, but is total and meant for formal reasoning - actually tries to address this issue. Any character can be part of a name, and in order to get infix operators, it uses a very interesting system where you can make infix/postfix/suffix operators out of *anything*, by dropping underscores into the identifier. For example, classic multiplication is defined as _*_ : ‚Ñï -&gt; ‚Ñï -&gt; ‚Ñï and can be used both as a traditional function `_*_ 2 3`, but also infix: `2 * 3`. In fact, if-then-else is also just defined as a function, and can still be used in an idiomatic way, thanks to this system! if_then_else_ : ‚àÄ{a} -&gt; Bool -&gt; a -&gt; a -&gt; a if true then 1 else 2 The issue with this is the same as the one your proposal would bring in Haskell: you can't write `2*3`. Agda interprets that as its own identifier, and complain violently about it not existing. This makes it imperfect, as for idiomatic reasons, you sometimes really want to do that.
I feel that I must tell you that Java and Haskell are quite opposed in the sense that the first one has not been designed with "Functional Programming" in mind, and surprisingly, thanks to this paradigm, that Haskell has been able to connect with one powerful concept in mathematics : Category Theory ( [https://ncatlab.org](https://ncatlab.org) ). This has a tremendous impact of how you can code in Haskell, but also how you can quickly get lost without a Category Theory background as in the basic following example: &amp;#x200B; Prelude&gt; return "Hello" &gt;&gt;= putStrLn Hello Prelude&gt; import Control.Monad Prelude Control.Monad&gt; (join . fmap (putStrLn)) (return "Hello") Hello Prelude Control.Monad&gt; &amp;#x200B; I believe that you should follow this thread: [https://www.schoolofhaskell.com/school/starting-with-haskell/basics-of-haskell](https://www.schoolofhaskell.com/school/starting-with-haskell/basics-of-haskell).
&gt; hang on, this looks familiar. It's basically a permutation. that's a cool connection! but I've got some issues with the "`x` with some values forbidden" method: &gt; The most obvious choice as to which value to forbid is the first one. many types don't have a notion of "first" though (or ordering at all), so you'd need an `Enum` constraint somewhere, possibly on both types. that doesn't really fit an operator that's supposed to be really generic like `+/Either` and `*/(,)` are. There's also the problem with `-(-a) = a`, which expands to `0 - (0 - a) = a`. how would you "forbid" values from `0` (which is empty), and then somehow get them back out again? where do those "negative" values go?
&gt; you can quickly get lost without a Category Theory background I don't think this is a good thing to say to a beginner. I agree that having a place for abstract mathematics in your heart helps greatly in Haskell, but not because you can't understand Haskell otherwise, but because Haskell lets you actually apply those ideas directly. So I would state the same sentiment positively, as in, you can learn Haskell just like any other language, knowing that it comes from a very different paradigm, but you can additionally unlock a lot of potential if you combine it with abstract mathematics.
&gt; I'm not a fan of the unsafe prefix for partial functions, as they aren't truly unsafe in the language-semantics-violating way. To me, `unsafe` means, don't lean on the types and go RTFM.
&gt; So ignoring backwards compatibility you wouldn‚Äôt have head! or minimum! ? I would not. &gt; In such a situation what would you want people to do if they do genuinely want the partial version? Perhaps explicitly use error and undefined such as fromMaybe undefined ? Well, in this situation there wouldn't \*be\* a partial version. If one wrote it oneself, because I concede that often program logic dictates that in fact eg. a key must exist without it having been encoded into the type-system, then yes, `error "something identifiable"` over `undefined`, and then it's obvious that the programmer is themselves responsible for the behaviour. &gt; How would you differentiate between Maybe / Result versions and type restricted versions that can‚Äôt fail? The common practice seems to be the suffix `1` as you've observed. I guess it's not the worst. Cf. eg. [https://github.com/ekmett/semigroupoids/issues/49](https://github.com/ekmett/semigroupoids/issues/49) [https://github.com/ekmett/semigroupoids/issues/26](https://github.com/ekmett/semigroupoids/issues/26)
&gt; &gt; you can quickly get lost without a Category Theory background &gt; I don't think this is a good thing to say to a beginner. It's a false and extremely unhelpful thing to say to anyone about Haskell. For example, I've worked with each of the following Haskell experts and I'm pretty sure they'd say they know nothing about category theory: * Neil Mitchell * Don Stewart * Lennart Augustsson * Simon Peyton Jones Let's get rid of this notion that Haskell requires category theory. Knowing about categories (let alone category *theory*) makes one a tiny bit better at programming Haskell, not much at all.
*(accidentally deleted my original reply :/ )* &gt; So `a!` would be the type of permutations on `a`, or invertible functions `a -&gt; a`. that's a lovely connection! but many types don't have a notion of "first", so such a `(-)` would need an `Enum` constraint somewhere, which doesn't feel right since `+/Either` and `*/(,)` have no constraints.
First of all, the type signature would be: isPrime :: (Integral a) =&gt; a -&gt; IO Bool As you cannot read files without using the IO type, and the Eq constraint is not enough (things that aren't numbers cannot be prime numbers). Yes, each time you call the function and execute the IO action, the file will be read. It's possible to call the function and throw the resulting IO action away, but that would be pointless and probably isn't what you meant. Instead, to only read the file once, you could do this: main :: IO () main = do p &lt;- readFile "primes.txt" let primesList = map read (words p) -- I added the call to words, otherwise it doesn't work print (isPrime 347 primeList) print (isPrime 635 primeList) print (isPrime 843 primeList) isPrime :: (Integral a) =&gt; a -&gt; [a] -&gt; Bool isPrime x primes = x `elem` primes
Prelude&gt; Just "an information" Just "an information" Prelude&gt; :t Just "an information" Just "an information" :: Maybe \[Char\] Prelude&gt; :i Maybe data Maybe a = Nothing | Just a -- Defined in ‚ÄòGHC.Base‚Äô instance Applicative Maybe -- Defined in ‚ÄòGHC.Base‚Äô instance Eq a =&gt; Eq (Maybe a) -- Defined in ‚ÄòGHC.Base‚Äô instance Functor Maybe -- Defined in ‚ÄòGHC.Base‚Äô instance Monad Maybe -- Defined in ‚ÄòGHC.Base‚Äô instance Monoid a =&gt; Monoid (Maybe a) -- Defined in ‚ÄòGHC.Base‚Äô instance Ord a =&gt; Ord (Maybe a) -- Defined in ‚ÄòGHC.Base‚Äô instance Show a =&gt; Show (Maybe a) -- Defined in ‚Äò[GHC.Show](https://GHC.Show)‚Äô instance Read a =&gt; Read (Maybe a) -- Defined in ‚Äò[GHC.Read](https://GHC.Read)‚Äô instance Foldable Maybe -- Defined in ‚ÄòData.Foldable‚Äô instance Traversable Maybe -- Defined in ‚ÄòData.Traversable‚Äô Prelude&gt; :i Functor class Functor (f :: \* -&gt; \*) where fmap :: (a -&gt; b) -&gt; f a -&gt; f b (&lt;$) :: a -&gt; f b -&gt; f a {-# MINIMAL fmap #-} \-- Defined in ‚ÄòGHC.Base‚Äô instance Functor (Either a) -- Defined in ‚ÄòData.Either‚Äô instance Functor \[\] -- Defined in ‚ÄòGHC.Base‚Äô instance Functor Maybe -- Defined in ‚ÄòGHC.Base‚Äô instance Functor IO -- Defined in ‚ÄòGHC.Base‚Äô instance Functor ((-&gt;) r) -- Defined in ‚ÄòGHC.Base‚Äô instance Functor ((,) a) -- Defined in ‚ÄòGHC.Base‚Äô Prelude&gt;
Thank you for your clear answer!
IMO, `head` and `unsafePerformIO` are equivalently dangerous; they both allow me to subvert the type system so even if it were a consistent logic, I couldn't trust any of the proofs written in the language. I've also never been a fan of the Lisp-y, ! (impure) and ? (query) suffixes. That said, I'm all for adding symbols to identifiers and requiring additional whitespace (ala Agda) and for removing partial functions (also ala Agda).
I would love to be able to use more symbols in identifiers. I used Ruby for a while and grew to like the `!` and `?` suffixes even if they weren‚Äôt perfect. Haskell already has special cases for things that could be operators, like `@` and `#`. Ultimately I would really prefer requiring spaces around operators so that identifiers could use any symbols they want. For example, I vastly prefer the Lisp-y `x-&gt;y` over `xToY`.
I don't know if this is a solution to your actual problem, but generating these prime numbers is very quick and could be done at program startup. This would be a bit faster than reading a file, I think, and also less error prone.
Old Reddit formatting: Prelude Control.Lens Data.Monoid&gt; getAp mempty :: [Sum Int] [Sum {getSum = 0}] Prelude Control.Lens Data.Monoid&gt; alaf Ap foldMap id [[1,2], [3,4], [5,7,11 :: Sum Int]] [Sum {getSum = 9},Sum {getSum = 11},Sum {getSum = 15},Sum {getSum = 10},Sum {getSum = 12},Sum {getSum = 16},Sum {getSum = 10},Sum {getSum = 12},Sum {getSum = 16},Sum {getSum = 11},Sum {getSum = 13},Sum {getSum = 17}] Prelude Control.Lens Data.Monoid&gt; mempty :: [Sum Int] [] Prelude Control.Lens Data.Monoid&gt; foldMap id [[1,2], [3,4], [5,7,11 :: Sum Int]] [Sum {getSum = 1},Sum {getSum = 2},Sum {getSum = 3},Sum {getSum = 4},Sum {getSum = 5},Sum {getSum = 7},Sum {getSum = 11}]
I don't understand. Are you trying to say that you need to know category theory because of `Functor` and `Monad`?
You need not to know CT per say, as well stated by other people in this post. But as a beginner, know that some people may have had that kind of mindset when programming. For me, this is the most amazing feature of Haskell: [https://wiki.haskell.org/Functor](https://wiki.haskell.org/Functor)
Yes, it's great! But if you say you need to know category theory to use Haskell it 1. is false 2. scares people off
Knowledge is always good !
And if you want to use Peano numerals, you don't have to define exponentiation, you can let the data structure define it: ``` type Tree = Tree' ('S 'Z) -- the root is either empty or has 2 branches data Tree (n :: Nat) a = Empty | Node a (Bin n (Tree ('S n) a)) data Nat = Z | S N -- Bin n contains exactly 2^n values data Bin (n :: Nat) a where Leaf :: a -&gt; Bin 'Z a Branch :: Bin n a -&gt; Bin n a -&gt; Bin ('S n) a ``` Alternately, you could move the empty constructors into Bin: ``` type Tree = Tree' 'Z type Tree' n = Compose (Bin n) (NonEmptyTree n) -- Bin n contains 0 to 2^n values data Bin (n :: Nat) a where Leaf :: a -&gt; Bin 'Z a Empty :: Bin 'Z a Branch :: Bin n a -&gt; Bin n b a -&gt; Bin ('S n) a data NonEmptyTree (n :: Nat) a = NonEmptyTree { value :: a, children :: Tree' ('S n) a } ```
This was just an example for handling of data in files. It could be a config file for a game or whatnot.
We really need a bot that will do this automatically.
Hey haskellers, &amp;#x200B; Here's a Pandoc filter I put together to simplify writing technical documents. Instead of generating figures in matplotlib separately, this filter will run Python code blocks as scripts and capture the output, inserting it in the document. This is ideal to keep figures and documentation up-to-date. I've made sure that it is compatible with [pandoc-crossref](https://github.com/lierdakil/pandoc-crossref), in the hope to (one day) replace raw LaTeX for my PhD thesis and articles. I've also integrated this with [Hakyll](https://jaspervdj.be/hakyll/); you can see an example of this on my blog, e.g. [here](http://www.physics.mcgill.ca/~decotret/posts/two-temp-model.html). The idea for this tool was inspired by [pandoc-include-code](https://github.com/owickstrom/pandoc-include-code/). Let me know what you think!
Thanks for letting us know. As /u/Phyx mentioned this was a CDN issue. I've flushed the CDN again; the index now looks fine on my end.
A slightly more realistic scenario is to use Int8 instead of Int. In which case the answer is simple: it wraps around in exactly the same way as `(fromIntegral 129) :: Int8`.
An alternative to reading the file is to embed it into your program binary (e.g. with [https://hackage.haskell.org/package/file-embed](https://hackage.haskell.org/package/file-embed)). It makes it somewhat easier to work with it from pure code and avoids a whole class of issues (file not found, etc.). However it is less flexible if you need to update the file without recompiling your code.
Are you sure it's the save behaviour? `succ (127 :: Int8)` throws an exception `*** Exception: Enum.succ{Int8}: tried to take \`succ' of maxBound`.
Nice blog post! I really like `Semigroup` and `Monoid` instances for the the `(-&gt;)` arrow. I especially enjoy how easy it's to define custom comparators for data types (using the `Ordering` monoid as well). It's extremely tedious to define custom comparators in something like Java or C++... data Error = Error { errorLine :: Int , errorPos :: Int , errorPath :: FIlePath } instance Ord Error where compare = comparing errorPath &lt;&gt; comparing errorLine &lt;&gt; comparing errorPos Moreover, this is actually how the idea of the [co-log](https://github.com/kowainik/co-log) logging library started. Once you have a logging action like this: newtype LogAction m msg = LogAction { unLogAction :: msg -&gt; m () } Then `Semigroup` and `Monoid` instances come naturally: instance Applicative m =&gt; Semigroup (LogAction m msg) where LogAction l1 &lt;&gt; LogAction l2 = LogAction $ \msg -&gt; l1 msg *&gt; l2 msg instance Applicative m =&gt; Monoid (LogAction m msg) where mempty = LogAction $ \_ -&gt; pure ()
Note that there are other possible `Monoid` instances for `IO`, and you are lucky that the implemented one does exactly what you need. Otherwise it would compile but fail in run time. That is why I usually use monomorphic version of `mempty` is such cases (i.e. `Text.empty` in this case.) It is essentially the same issue like with the `Foldable` instance for tuples. In general, when I see polymorphic function used where monomorphic one will work, I look for hidden abstraction. In this case I'd extract the `mempty`\-related code into a `lenient` function. Like this: lenientReadTextFileUtf8' filename = lanient (readTextFileUtf8 filename) lenient :: (Monad m, Monoid a) =&gt; m (Either e a) -&gt; m a lenient m = either (\_ -&gt; pure mempty) pure =&lt;&lt; m Than way we are not trading type safety for keystrokes anymore. Actually we are using the full power of parametricity!
No, all `(-)` requires is a concept of definable equality, and `!` doesn't even need that. `\f x -&gt; f (negate x)` is a member of `(Int -&gt; Int)!`.
Most of what you say is true, except this: &gt; You can't just cd to your project directory and use `ihaskell` as you would `stack ghci` or `cabal new-repl` and have things work as expected. That's exactly how I used IHaskell until I switched to a Nix-based approach. You can navigate to your project directory, run `stack exec -- jupyter notebook`, open a new notebook, and have things work as expected. See [here](https://github.com/gibiansky/IHaskell/issues/792#issuecomment-349186483) for more details.
This is awesome to know about! &gt; if you need to update the file without recompiling your code This is usually the use case when I put data in a file rather than in the source code.
Also one can easily grep for \`unsafe\` - which is really useful if you want to quickly audit your code.
I personally don‚Äôt like space-less syntax, even for lenses, as then things like `foo^.bar.ix 5.baz` look quite weird, and it looks too cluttered.
`unsafePerformIO` can cause catastrophic and extremely hard to debug bugs just about anywhere in your program that even indirectly uses it. `head` just crashes in a predictable way with an error message. They are leagues apart in terms of danger.
`unsafePerformIO` can cause catastrophic and extremely hard to debug bugs just about anywhere in your program that even indirectly uses it. `head` just crashes in a predictable way with an error message. They are leagues apart in terms of danger.
This article uses the term "inductive," but it only discusses one, non-inductive type, Maybe... "Inductive" means that the type is recursive. (I believe that "inductive" implies that the recursion always has a base case?)
The instance (Applicative f, Semigroup a) =&gt; Semigroup (f a) where instance would overlap with any other instance with that kind. So it would make newtype wrappers like (Ord a, Bounded a) =&gt; Monoid (Max a) impossible.
Feel And See Haskell Basics https://github.com/jdelouche/FeelAndSeeHaskellBasics
might be. with the `Enum` stuff, i was referring to this bit: &gt; The most obvious choice as to which value to forbid is the **first** one.
0 category theory background, still haven't gotten lost. I found Haskell easier to learn than Java - I started with JS and got lost on the way to learning Lisp.
It also, rather more damningly, for instance destroys the ability to write `[a]` as the free monoid on `a`.
I agree. Inductive types are a subclass of recursive types. Recursive types (or recursive anything) are those whose definition mention the thing being defined. They are quite natural, people program with them everyday. But of course, formally, recursion is quite a hairy topic. Inductive types are a class of recursive types, based on the notion of well-foundedness (or, to oversimplify, finiteness). Induction provides a formal way of interpreting and reasoning about recursive definitions ("proofs by induction").
You can think of an inductive type as building recursively a larger structure from a base constructor, e.g.: &gt; data Nat = Zero | Succ Nat &gt; data List a = Nil | Cons a (List a) You can think of the above as typed initial encoding. Its dual is final encoding as in typed final tagless encoding.
I meant "the first one" as in "the one that was chosen first". Having a value of type `a` means that we've proven `a` is inhabited. Then, you tuple it with `a - 1`, excluding the value we just chose; this proves that `a` is inhabited by at least two different values. Then so on for `a - 2`, `a - 3`, and so forth until we exhaust `a`. Note that we don't have to do the exhaustion process one at a time, we just need to show that: * For all `x` and `y` in `a`, `x ‚â† y` implies `f x ‚â† f y`, and * For all `y` in `a`, there is an `x` in `a` such that `f x = y`. So while the original conception was a type with `Enum` or something similar, it can be extended beyond that point.
Then how will I get that sweet comment karma!? /s
Honestly I'm not convinced the "assign a random number then sort" actually has more skew than generating random numbers modulo numbers other than powers of 2.
The issue persists for me, although I can use the extra-slash workaround. In case this helps debugging, here are some HTTP headers: * Stale index: curl -vvv downloads.haskell.org/ghc/8.6.5/ * Trying 2a04:4e42:1b::431... * Connected to downloads.haskell.org (2a04:4e42:1b::431) port 80 (#0) &gt; GET /ghc/8.6.5/ HTTP/1.1 &gt; Host: downloads.haskell.org &gt; User-Agent: curl/7.47.0 &gt; Accept: */* &gt; &lt; HTTP/1.1 200 OK &lt; Server: nginx/1.14.0 (Ubuntu) &lt; Content-Type: text/html &lt; Content-Encoding: gzip &lt; Via: 1.1 varnish &lt; Content-Length: 587 &lt; Accept-Ranges: bytes &lt; Date: Wed, 24 Apr 2019 23:22:44 GMT &lt; Via: 1.1 varnish &lt; Age: 65162 &lt; Connection: keep-alive &lt; X-Served-By: cache-dfw18639-DFW, cache-hhn1542-HHN &lt; X-Cache: HIT, HIT &lt; X-Cache-Hits: 1, 1 &lt; X-Timer: S1556148164.052495,VS0,VE3 * With extra slash: curl -vvv downloads.haskell.org/ghc/8.6.5// * Trying 2a04:4e42:1b::431... * Connected to downloads.haskell.org (2a04:4e42:1b::431) port 80 (#0) &gt; GET /ghc/8.6.5// HTTP/1.1 &gt; Host: downloads.haskell.org &gt; User-Agent: curl/7.47.0 &gt; Accept: */* &gt; &lt; HTTP/1.1 200 OK &lt; Server: nginx/1.14.0 (Ubuntu) &lt; Content-Type: text/html &lt; Content-Encoding: gzip &lt; Via: 1.1 varnish &lt; Content-Length: 746 &lt; Accept-Ranges: bytes &lt; Date: Wed, 24 Apr 2019 23:26:14 GMT &lt; Via: 1.1 varnish &lt; Age: 52002 &lt; Connection: keep-alive &lt; X-Served-By: cache-dfw18630-DFW, cache-hhn1521-HHN &lt; X-Cache: MISS, HIT &lt; X-Cache-Hits: 0, 1 &lt; X-Timer: S1556148375.508707,VS0,VE10 My understanding (mostly from [here](https://docs.fastly.com/guides/performance-tuning/understanding-cache-hit-and-miss-headers-with-shielded-services)) is that the CDN's "shield cache" is still stale. Not sure how to purge it though. :/
Probably easier to think about this as 1*2*3...*a No need to substract
Here are my thoughts: use a strict left fold. Tail call optimisation is not that important in Haskell. ``` import Data.Foldable dfac1 :: Int -&gt; Int dfac1 n = go 1 n where go acc 0 = acc go acc 1 = acc go acc n = go (acc * n) (n - 2) dfac2 :: Int -&gt; Int dfac2 n = foldl' (*) 1 [n, (n - 2) .. 1] ``` `dfac1` is not really tail optimised. it tries to evaluate `go` but ends up creating a chain of thunks in the accumulator. ``` go 1 9 = go (1 * 9) (9 - 2) go (1 * 9) 7 = go ((1 * 9) * 7) (7 - 2) go ((1 * 9) * 7) 5 = go (((1 * 9) * 7) * 5) (5 - 2) ``` etc. If you use a strict left fold, you won't have this problem. Each iteration is evaluated straight away.
To avoid potentially expensive calls to init and last what you want is a data structure called Zipper: https://wiki.haskell.org/Zipper. For text it's going to be "everything before cursor position", "what's under the cursor" and "everything after cursor position in reverse order". In this case cursor move can be implemented by operating on lists heads only.
Thank you, the only problem is im preparing for a test that will ask to tail optimize a function similar to double factorial which is why I asked.
Here's a recursive function which does what you want: shiftRightN :: Text -&gt; Int -&gt; Text shiftRightN t 0 = t shiftRightN t n = let shifted = shiftRight t in shiftRightN shifted (n-1) Here, when `shiftRightN` is called, it shifts `t` once, then recursively calls `shiftRightN` again with the shifted version of `t`; since we've already shifted `t` once, we decrement `n` in the recursive call. The `0` case is the *base case*: if we want to shift 0 times, we don't actually want to shift, so we start So we get: shiftRightN t 3 = shiftRightN (shiftRight t) 2 = shiftRightN (shiftRight (shiftRight t)) 1 = shiftRightN (shiftRight (shiftRight (shiftRight t))) 0 = shiftRight (shiftRight (shiftRight t)) (Note that I would normally write `shiftRightN` without the `let`: shiftRightN :: Text -&gt; Int -&gt; Text shiftRightN t 0 = t shiftRightN t n = shiftRightN (shiftRight t) (n-1) I left the `let` in for pedagogical purposes only.) In fact, you can generalise this pattern: applyN :: Int -&gt; (a -&gt; a) -&gt; (a -&gt; a) applyN 0 _ = id applyN n f = f . applyN (n-1) f Using the definition above, we could define `shiftRightN = flip $ applyN shiftRight` (we need the `flip` to reverse the order of arguments). `applyN` is an incredibly useful function which for some reason is not in `base`. In case you don't know how to read it, the type signature basically says that the second parameter of `applyN` is another function which turns a value of type `a` into another value of type `a`; `applyN` returns something of the same type. For more information on recursion, have a look at [the relevant chapter](http://learnyouahaskell.com/recursion) of _Learn You a Haskell_.
I feel I should really know this by now, but: if that's an initial encoding, what would be a final encoding of `Nat` and `List a`?
Thank you so much! you've helped me learn recursion with this thank you!
I highly recommend Learn You a Haskell.
I think you missed the `0` base case in your refactoring. I also agree that you might want some additional strictness annotations. I'd do it like this: doubleFact :: Int -&gt; Int doubleFact = doubleFact' 1 where doubleFact' a 0 = a doubleFact' a 1 = a doubleFact' !a n = doubleFact' (n * a) (n - 2)
&gt; Does FRP leverage more performance for the game itself? In which ways do you expect FRP might make your game faster? Nicer abstractions often come at a performance cost unless a lot of effort is spent optimizing it away, so I would expect the opposite. &gt; What is the better approach: implement by myself or use a library? Making FRP fast is more difficult than it sounds, so I would use a library whose author cares about performance, like reactive-banana, in order to benefit from the efforts which have already been poured into the problem.
yea your right I did forget it. ended up fixing it thanks
You're welcome! Along with /u/solinent, I would also recommend LYAH - it's how I learnt Haskell.
The education. The ease of adoption.
What tutorials are distinctly missing?
To be honest, for me it‚Äòs the fear of laziness and lack of tooling. Maybe even too much focus on CT topics.
I would like to use ghci as server which I can write to from stdin and read from stdout. Is there a recommended way to doing this? My goal is to have a supervisor server control ghci and dynamically load and execute modules as needed.
Why would Haskell make sense for businesses? It is a specialized language, with a very different style to conventional languages. If Haskell was significantly more efficient and fast when compared to other languages like C++, then I could maybe understand adopting it into a software ecosystem of a company. As it stands theres no pragmatic reason to use Haskell outside of an academic environment, in my opinion.
Try this for a beginner resource: [https://wiki.haskell.org/Learn\_Haskell\_in\_10\_minutes](https://wiki.haskell.org/Learn_Haskell_in_10_minutes)
A faster compiler would be great, but I think the best thing to do is open soirde
It is a general purpose language, so I don't quite see how it is specialized. And considering the ubiquity of python I'd say that efficiency is often less relevant than it is made out to be.
lolwut
When I peruse other subreddits I often notice that people really care about IDE support and tooling. While I personally don't even use live linting and am totally fine with constructing my compile-feedback cycle from tools like `ghcid`, `entr`, `fd` and so on, others aren't. So having a one click install language server that just works and can do typical Intellij things (completion, refactoring, linting, compiler feedback) would make the language a lot more approachable to some folks. Apart from that I also believe that there is no good resource for learning Haskell since most existing resources focus aren't pragmatic enough in their teaching methodology. In a nutshell: teach monads by just showing how to use them. People don't need to understand and reimplement the type class internals right away, even though that's unfortunately how most tutorials start. Then there's the - compared to JS - abysmal *soft* documentation and the twelve thousand language extensions. Although with regards to using a common set of extensions and such I have great hopes for what fpcomplete are doing with RIO.
Anything that is capable of reducing the learning curve. I'd say there is a general lack of Haskell resources on popular educational websites-- such as Treehouse and Pluralsight. There is the general perception that "Haskell is hard" and that it is "for academics" and that it is "useless for general industry work". Shifting the perception is difficult-- but whatever can be done to cause the shift is something that is missing from the ecosystem.
It has no traction. There is very little common ground between the features and reasons on why something is wide spread. Do you really think that PHP is great language? Investing in Haskell infrastructure is very expensive and has no economic validation.
You'll recognize it once you see it. So, Church numerals for Nat and Church encodings for lists are some examples of final encoding.
I'm just gonna give this a big "nah" and move on rofl.
IDE support, definitely. The common steps to learn/discover a new language are: 1. Find a tutorial 2. Start following the steps in your IDE to get compilation feedback, syntax highlighting, documentation, navigation... 3. Level up 4. Start small toy projects 5. Start a real project 6. Optional. Work with this language for money (either by bringing this language to your work/team, or by finding a job with this language) Haskell fails at step 2 :( Which is interesting because all the other steps work nice with this language. A big issue is, an important part of Haskellers is used to Vim/Emacs, so that's what is recommended everywhere for Haskell. The thing is, in mainstream languages, nearly nobody uses those editors. They use Intellij/Eclipse, or VSCode for simpler editors (often for dynamic languages, I have noticed). To gain traction, Haskell must be able to onboard all those developers, and help them transition. Learning a new language is already a challenge, Haskell even more because it is so different. The one thing new developers don't want to do is also invest time learning a new IDE/editor just to be able to get basic features like navigation. Given how rich Haskell is, I think it benefits more from an IDE than an editor (code navigation to libraries, documentation, powerful refactors, etc.). And these days, Intellij has much more traction than Eclipse. My final answer would thus be: contribute to improve Intellij-haskell, which is so far the best in terms of features for Haskell.
I'm certainly no vim poweruser, but I've been using vim for quite a while at this point and I feel like spacemacs does all the things I use frequently in vim. That said I have existing experience with Lisp dialects, so picking up basic elisp to do some simple things has not been hard for me. However it was much easier than trying to do anything meaningful in vimscript - and this extensibility is why I'm continuing to use spacemacs. Features that I want that it lacks, I'm confident I can learn to add myself in time. I never felt this way with vimscript.
contribute to the Haskell ide leksah [https://github.com/leksah/leksah/wiki/download](https://github.com/leksah/leksah/wiki/download) the last release was in 2016
That's interesting, I'll have to give it a shot.
If you're interested in generating permutation algorithms from sorting algorithm, you might like reading [All Sorts of Permutations](https://www.informatik.uni-kiel.de/~sad/icfp2016-preprint.pdf).
- Support projects like Eta (Haskell for the JVM) - support functional solutions for problems that are not copies of imperative OOP solutions with added "type-safety" - support tooling that make full use of a new infrastructure called internet like other languages
&gt; Is it that some organizations are doing great work that can scale their efforts with funding? Well, probably the most effective way to improve Haskell overall is to fund the non-profit Haskell organization which is operated by volunteers: See https://wiki.haskell.org/Donate_to_Haskell.org
There's a lot of entry-level stuff out there, any number of Monad tutorials and stuff that explains the syntax of the language and some basics of functional programming. What's missing for me is intermediate-level guidance on how I'd actually go about writing a real-world application. (Vitaly Bragilevsky is apparently writing a book right now, so maybe that'll change.) Part of the problem is the conflicting parts of the ecosystem, e.g. stack vs cabal (and cabal-new). Also not obvious is the choice of libraries. There are Parsec tutorials out there, but apparently people no longer actually use Parsec. Attoparsec and Megaparsec assume you already know Parsec and just tell you what's different. A lot of the tutorials are outdated, and no longer contain relevant information. I kinda wish there was an updated, opinionated guide for a bunch of libraries that doesn't assume anything and just tells you what to use for a given task and teaches you how to use it. Basically a newbie like myself is entering a heated discussion that's been going on for decades, and just trying to figure things out on their own. I'm at a loss when to actually use an Applicative in my toy program, while people around me are discussing Lenses. There's a lot to Haskell, which makes it lots of fun, but also very daunting.
This post mostly talks about implementation details, what sort of benefits or changes can I expect ad an end user?
`BangPatterns` and `go !acc 0 = ...` and there won‚Äôt be thunks. Essentially the same what `foldl‚Äô` does.
One follow up question I have is what your opinion is on operators like `^?!` and `!!` and `!`, should they continue to exist or should they likewise be phased out?
I believe there are some unique features in Haskell to be mentioned, even to beginners, that you cannot have in other non-functional languages. Let me thank the aforementioned people for having given us such a beautiful techno. I mean functoriality https://wiki.haskell.org/Functor : Prelude&gt; fmap ((+1) . (*2)) (Just 5) Just 11 Prelude&gt; ((fmap (+1)) . (fmap (*2))) (Just 5) Just 11 Prelude&gt; do x &lt;- Just 5; return (((+1) . (*2)) x); Just 11 Prelude&gt; do x &lt;- Just 5; do y &lt;- return ((*2) x); return ((+1) y); Just 11 Prelude&gt; And GADT https://en.wikibooks.org/wiki/Haskell/GADT: Prelude&gt; :info Maybe data Maybe a = Nothing | Just a -- Defined in ‚ÄòGHC.Base‚Äô instance Applicative Maybe -- Defined in ‚ÄòGHC.Base‚Äô instance Eq a =&gt; Eq (Maybe a) -- Defined in ‚ÄòGHC.Base‚Äô instance Functor Maybe -- Defined in ‚ÄòGHC.Base‚Äô instance Monad Maybe -- Defined in ‚ÄòGHC.Base‚Äô instance Monoid a =&gt; Monoid (Maybe a) -- Defined in ‚ÄòGHC.Base‚Äô instance Ord a =&gt; Ord (Maybe a) -- Defined in ‚ÄòGHC.Base‚Äô instance Show a =&gt; Show (Maybe a) -- Defined in ‚ÄòGHC.Show‚Äô instance Read a =&gt; Read (Maybe a) -- Defined in ‚ÄòGHC.Read‚Äô instance Foldable Maybe -- Defined in ‚ÄòData.Foldable‚Äô instance Traversable Maybe -- Defined in ‚ÄòData.Traversable‚Äô Prelude&gt; Prelude&gt; do x &lt;- Nothing; do y &lt;- return ((*2) x); return ((+1) y); Nothing Prelude&gt;
Unfortunately reactive-banana does *not* have a great performance profile at the moment: [https://github.com/HeinrichApfelmus/reactive-banana/issues/140](https://github.com/HeinrichApfelmus/reactive-banana/issues/140). That said, there is definitely low hanging fruit (ha!) to improve the status quo.
I'm working on making the features in [this article](http://elbear.com/my-ideal-developer-toolset.html) a reality (I wrote it). Right now I'm looking at what I can use for the editor (VS Code or plain Electron). If you want to help, write to me.
Improve HIE (Haskell IDE Engine) would be a great idea. I think a good IDE-experience is important especially for newcomers. &amp;#x200B; I think improving HIEs speed and stability would be great and really benefit the usability! I don't think newcomers need super-advanced features but a rock-solid experience.
I‚Äôd love to see more blog posts about how people are running their Haskell apps in production. Command line utilities are well studied, but how about web-focused server-powered applications? - What do deploy artifacts look like? - Are you having success with a particular PaaS provider? (like App Engine or Heroku) or does deploying Haskell require something else? - What monitoring tools (services, libraries) or even just common patterns work well to observe a Haskell-based service? - It would be interesting to see an example going from ‚Äúwe observed this bug in production‚Äù to identifying the cause and fixing it (ie how do you debug a Haskell service; are there tools like sentry for collecting stack traces and exceptions?) It‚Äôs possible that the answer to any or all of these are ‚Äúit‚Äôs no different from a web application in another language‚Äù but in that case it‚Äôd be nice to go through the motions for Haskell anyways to emphasize that it‚Äôs the same.
lenient :: (Functor f, Foldable t, Monoid b) =&gt; f (t b) -&gt; f b lenient = fmap fold