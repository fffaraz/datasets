[The perfect mix of Haskell and Clojure](https://www.haskell.org/)
I literally came here to say this. Because it's true.
[I could not resist.](https://www.reddit.com/r/Clojure/comments/7gudan/lux_the_perfect_mix_of_haskell_and_clojure/dqmx0kz)
Are you familiar with the topological semantics? In which negation is the interior of the complement? 
What does trailing underscore mean in variable names?
Usually it's a naming convention to denote that returned value is ignored, instead you get unit `()`. Compare: replicateM :: Applicative m =&gt; Int -&gt; m a -&gt; m [a] replicateM_ :: Applicative m =&gt; Int -&gt; m a -&gt; m () traverse :: (Traversable t, Applicative f) =&gt; (a -&gt; f b) -&gt; t a -&gt; f (t b) traverse_ :: (Foldable t, Applicative f) =&gt; (a -&gt; f b) -&gt; t a -&gt; f () Used to ignore the result of computation if you don't need. Consider the following example. You want to print sting `"Hello, World!"` 100 times in the terminal. Of course, you can write this line 100 times. But it's more convenient to use standard functions. However, if you use `replicateM`, you will end up with list of 100 units. putStrLn :: String -&gt; IO () print100 :: IO [()] print100 = replicateM 100 (putStrLn "Hello, World!") Usually you can't do anything useful with list of units. So instead of `replicateM` it's better to use `replicateM_`. print100 :: IO () print100 = replicateM_ 100 (putStrLn "Hello, World!") Since pattern with ignoring the result of the function is used very often, it has separate naming convention. Also, sometimes when you ignore the result of the function, you can write more efficient implementation. And you won't recieve annoying warnings that you discarded unused value in `do`-notation.
Sorry, the spam filter caught this. If you're still looking for help, I'd recommend r/haskellquestions or Stack Overflow. 
Sorry, the spam filter caught this. If you're still looking for an answer I'd suggest checking meetup.com: https://www.meetup.com/find/?keywords=haskell&amp;mcId=c94101&amp;radius=50
Sorry, the spam filter caught your post. I just approved it. 
Is that something that reddit does automatically or do the admins define filters?
Sorry, the spam filter caught this. I think this question is better suited for Intero's issue tracker: https://github.com/chrisdone/intero/issues
A little of both. I'm not sure why your post got caught. 
Ah, my question was a bit unclear, it was more about the trailing underscore in record fields like data Person = Person { pid :: Integer, personName_ :: String }
&gt; That would let us put subscript numbers on operators too Yeah, "üëª" is allowed in infix operators but "‚ÇÅ" is not :( 
I believe a Haskell compiler would be _allowed_ to perform that kind of optimization, but I'm pretty sure ghc does _not_ automatically parallelize your code, in part because there are many ways to parallelize code and many of them make the code slower, not faster. Which libraries are you using, maybe some of those are smart enough to do some parallelization for you?
If you run `cabal list --simple-output pandoc | awk '$1=="pandoc" { print $2 }`, that should print all versions of pandoc available to you. If you see the version you're looking for, that's great. Then install it with `cabal install pandoc-${version}
I think the spam filter caught my posts, if any admins are seeing this. Everyone at the Haskathon yesterday said they couldn't see this post on r/haskell, but could once they went to my profile. To them, the post body just says [removed], but I can still see the post in full. 
One important aspect of reading Haskell are the instance declarations, because a lot of functionality is packed there. For example the instances for [Monoid](http://hackage.haskell.org/package/base-4.12.0.0/docs/Data-Monoid.html) or [Data.Functor.Compose](http://hackage.haskell.org/package/base-4.12.0.0/docs/Data-Functor-Compose.html). Paraphrasing the Typeclassopedia, "the patient student of instance declarations will uncover many profound secrets".
It may happen that you already have libraries installed that restrain the Pandoc version. Maybe you can try cleaning the Cabal cache?
When you don't specify which version you want, cabal uses constraint-solving to pick the most recent version which will work with the version of the libraries you already have installed, including your version of ghc. So if you want to install the latest version, you might need to uninstall some libraries you have previously downloaded (the easiest way to do this is to delete your entire `~/.cabal` folder), and maybe to install a more recent version of ghc. Try `cabal install pandoc-2.5` in order to to see which already-installed libraries `pandoc-2.5` is conflicting with. What is this I hear? This behavior is annoying? The cabal developers agree! They first implemented [sandboxes](https://www.haskell.org/cabal/release/rc/doc/users-guide/installing-packages.html#sandboxes-basic-usage), which is a way to install executables and libraries inside a local folder instead of `~/.cabal`, so that the versions installed inside a sandbox only affect which versions you can later install inside that same sandbox, not which versions you can install on your entire machine. More recently they have introduced [new-install](https://www.haskell.org/cabal/users-guide/nix-local-build.html#cabal-new-install), which makes sure that installing executables doesn't affect which versions you can install in the future, and takes a modern equivalent of a sandbox as an argument when you install libraries.
If you allow the program to use multiple cores, GC will be done in parallel by default. It is possible that this is what you are seeing. This is not always positive, and can be controlled with RTS flags.
I don't see a problem with the following: `mapReplace :: a -&gt; (a -&gt; Bool) -&gt; [a] -&gt; [a]` `mapReplace def f = map (\x -&gt; if f x then def else x)` `replaceAll5sWith0 :: [Int]` `replaceAll5sWith0 = mapReplace 0 (==5) (replicate 20 5)` which would give you 20 zeros in the list.
I think you mean "If runState was `s -&gt; s`"
Your comment [here](https://www.reddit.com/r/haskell/comments/afckoe/why_i_no_longer_believe_in_computational/edyuttp) clarified the issue for me. I didn't consider how classical disjunction could result in unrestricted jumpbacks in the resulting program. I was thinking the issue with LEM were localised so any branch where you prove absurdity was one you'd want to give up anyway, but I can see that this can go on indefinitely, amounting to a program that is fundamentally busywork should you be able to intuitionistically prove `A` or `Not A` in the first place.
The maniac forgot to put the implied liability disclaimer in shouty caps in order to "comply" the with requirement that they be conspicuous under the Uniform Code of Commerce. Kidding aside, the license very hard to read and I'm failing to comprehend the idea of "monetizing" a compiler but OK.
I would use `zipWith (\i x -&gt; if p i then x else 0) [0..] xs`, or if you really want to use list comprehension, `[if p i then x else 0 | (i, x) &lt;- zip [0..] xs]`, which may involve a nested list comprehension if your `xs` is itself generated by a list comprehension. As you can see, I am computing the index; there is no dedicated syntax for accessing the index at which the current element would end up if it doesn't get filtered.
I see brackets, I run. Also [the license](https://github.com/LuxLang/lux#whats-the-license) makes it essentially useless.
Aren't these all different languages? Reflex is Haskell, Elm is its own language, and Mithril is JS. If you already know Haskell, you probably don't want Elm. It is a much more limited type system, which is great for being simple enough to not scare off JS devs. But if you're used to typeclasses and monads it will just feel frustrating. Also, modern Elm isn't quite FRP, so if that's what you're looking for it's probably not for you. It's still declarative though.
Glad I could be of help! The "localised LEM" you're describing seems to me like delimited continuations, where you delimit how much an effectful computation can capture of the current continuation, in such a way that "from the outside" it looks pure. reset C[shift k. E] =&gt; let k = (Œªx.reset C[x]) in reset E This lets you have a computation that's locally effectful/"locally classical" but that's still pure/intuitionistic from the outside. The exact details on typing elude me, but when properly answer-type polymorphic, you should be able to type the term `call/cc k. E = shift k'. let k = (Œªx.shift g.k' x) in E` which lets you use Peirce's law locally in `E`: reset C[call/cc k. E] =&gt; let k = (Œªx.abort C[x]) in reset E reset C[abort v] = reset v
My understanding is that GHC does not do this all by itself, though you may be using libraries that use parallel features. See [Parallel and Concurrent Programming in Haskell](https://web.archive.org/web/20180102151434/http://chimera.labs.oreilly.com:80/books/1230000000929/pt01.html).
Purescript too :P See the Haskell Wiki on [The Javascript Problem](https://wiki.haskell.org/The_JavaScript_Problem) if you want to collect some more
The framework there is Miso, right?
I'm trying to understand the Free monad, but running into some issues. I've been reading [this post](http://www.haskellforall.com/2012/06/you-could-have-invented-free-monads.html), but I'm a bit confused on why the author needlessly parameterizes the type `Toy b next`, when it could easily just be using `Char` in place of `b` and `Toy` in place of `next`. Why make the data type have unconstrained parameters and then use `Fix` to try to constrain it? Maybe I need to read up a bit more, but it seems like it's just parameterizing for the sake of being able to define a functor for it.
&gt; If you already know Haskell, you probably don't want Elm. But you still might. Elm gives you a very accessible way to write frontend code that others on your team might appreciate, without having to touch the Haskell backend. Furthermore you get a great development server and its super easy to setup.
Pretty sure miso is for ghcjs
Take a look at [hackett](https://github.com/lexi-lambda/hackett) too
Oh, I'm not aware of a way to do it "inline". You have to have a type annotation to actually give the variable a name. (You don't get to use the name from cpara_SList right now, because you are not yet unifying with that type.) IIRC, Rank-2 types aren't really covered by H-M (although GHC uses OutsideIn instead of H-M, again IIRC.)
&gt; I'm a bit confused on why the author needlessly parameterizes the type Toy b next, when it could easily just be using Char in place of b and Toy in place of next. Firstly, It's not that simple. `Toy Char Toy` isn't any more valid than `IO IO`. That's not even a type error it's a *kind* error! Secondly, it's a *toy* example; it's done the way it is not for any particular productive use, but rather because it the something the rest of the prose "plays" with. Finally, being able to generalize in a particular direction is often a good thing. It may not be appropriate for every project, but know how to generalize/parameterize on a particular aspect is another "tool in the toolbox". BTW, almost everything is a Functor, and the things that aren't are instances of the Const Functor, so it's not exactly shoehorning. ;)
You can't statically check for membership of open type classes. Though, if you figure out how to do that (which for some weird reason I think I saw a blog post about once), you can write that type family with the help of the DataKinds extension applied to Bool and an If type family,
Sorry, I should have been more clear. His toy language definition is data Toy b next = Output b next | Bell next | Done and I'm saying I don't see how the type needs to be parameterized at all. Like say we had declared it as data Toy = Output Char Toy | Bell Toy | Done That seems like a pretty semantically similar conception of the "language" that the data type defines, but it doesn't have any type parameters. Wanting to be able to output multiple types makes sense, but I don't get the `next` definition I guess. And it seems like the functor definition for the type at least *seems* fairly trivial (it doesn't seem to change anything about the underlying data besides what kind of `next` it's parameterized on). I guess the question that brings up for me is: why is it useful for the data type we define for our language to be a functor? Like especially with some non-trivial language, what utility does having a functor defined provide us? Also looked at the Const functor, and that seems interesting. I'm still fairly new to Haskell (I'm coming at this originally from Scala, and not terribly advanced FP), but does that `newtype` declaration basically declare a type-level function from any type `a` to `Const a b`?
It just doesn't seem to see past 2.2.1, even though it goes up to 2.5 in Hackage ): $ cabal update Downloading the latest package list from hackage.haskell.org $ cabal list --simple-output pandoc | awk '$1=="pandoc" {print $2}' | tail -1 2.2.1
 $ mv ~/.cabal{,.bak} $ cabal update Downloading the latest package list from hackage.haskell.org $ cabal install pandoc-2.5 Resolving dependencies... cabal: Could not resolve dependencies: next goal: pandoc (user goal) rejecting: pandoc-2.2.1, pandoc-2.2, pandoc-2.1.3, pandoc-2.1.2, pandoc-2.1.1, [...] pandoc-0.43, pandoc-0.42, pandoc-0.41, pandoc-0.4 (constraint from user target requires ==2.5) Dependency tree exhaustively searched. I'm using GHC 8.0.2, but looking at https://github.com/jgm/pandoc/blob/2.5/pandoc.cabal, it doesn't seem to be constrained on it. $ ghc --version The Glorious Glasgow Haskell Compilation System, version 8.0.2
Never saw trailing `_` in record fields. Probably author of the package where you saw this code can clarify his intention. I'm only aware of the naming convention for leading `_` in record fields :)
I've tried deleting `~/.cabal` as suggested by others, but it didn't seem to help..
That's unfortunate :(. If it were possible, one could provide a neat API that automatically does the best thing.
Yes. But does that help with explaining why it would be contactible?
Contactible? 
Autocorrectable.
&gt; When I run `cabal install pandoc`, it pulls in version 2.2.1 even though it goes up to version 2.5 in Hackage (I did run cabal update beforehand). This sounds like you either have an old `cabal` version installed (pre 2.0); if possible, please use `cabal-install` version 2.4 (which supports all GHC versions 7.0 through GHC 8.6) Alternatively this because you have a stale `~/.cabal/config` file which forces `cabal` to access Hackage via the legacy non-secure index format. Given you already wiped your `~/.cabal` folder I suspect it's the former, i.e. your `cabal` version that isn't recent enough. 
Ah, that sort of makes sense to me. It seems to me like they are equivalent in "pure" proving power (correct me if I'm wrong there), but I guess you gain some the additional computational content that is potentially useful.
Ok, give me a little while (a day?) to write a better answer. Ultimately the homotopy structure is different from the topological structure, so I don't think there's any reason the "interior of the complement" should be contractible. (or maybe there is, I'd like to be proven wrong). 
Here's what I'm using --- nothing crazy, :-) ``` build-depends: base &gt;= 4.7 &amp;&amp; &lt; 5, aeson, aeson-pretty, attoparsec, base-unicode-symbols, basic-prelude, bytestring, directory, filepath, hspec, interpolatedstring-perl6, parsers, process, split, string-conversions, tagsoup, text, time, unordered-containers ```
Well, I think it's pretty great. It's definitely positive in this program.
Miso has been a fantastic experience for my team and I. Would definitely recommend. 
The perfect mix of Haskell and Scheme!
&gt; I don't see how the type needs to be parameterized at all Well, you can at least see that the parameterized version is more flexible than the non-parameterized version, right? `Output 45 readLn :: Toy Int (IO String)` is not expressible with your non-parameterized version. Sometimes the parameterization is useful, other times it may not be. All turning complete languages are intra-convertable, so you don't **need** any feature not in something super minimal like the SKI machine or the (untyped) lambda calculus. &gt; why is it useful for the data type we define for our language to be a functor? It means there's some context that can we can operate under without disturbing it. For `next` we can change what "happens next" while preserving the single action that the rest of the `Toy` represents. All (uniformly) recursive data is a/the fixed point of *some* functor, and it turns out any operation on the recursive data values can be described as either aan embeding into or a projection from the functor and a universal recursion scheme. Perhaps this got lost in translation but, a Free Monad is the free monad *of / generated by a particular functor*. So, somewhere along the line you'd need to find a functor. --- Toy examples really aren't there to be questioned. They are just toys for the prose; that *is* their purpose. They aren't meant to be optimal, efficient, or at all practical outside of the context that introduces them.
Ah nice, thanks. My system cabal-install is 1.24, and even though I had installed 2.4 locally, I never actually added it to my PATH... I have now and it‚Äôs correctly pulling the latest pandoc. 
Wow, this looks like a bug. Otherwise I wonder why does the typechecker fail in such an obvious way? 
Indeed. I had forgotten about the interior of the complement perspective until you mentioned it. It would be really interesting to hear how to reconcile it with the point at hand :)
Ableton link tempo synchronisation for music - [https://ableton.github.io/link/](https://ableton.github.io/link/) &amp;#x200B;
Well, your CPU utilization is higher, but is it completing the task more quickly?
Just submitted idea that is not related to GHC but more about writing an application in Haskell :) * https://github.com/haskell-org/summer-of-haskell/pull/85
Thanks for pointing out the languages are different! I should have been more clear, what I'm referring to is the differences in how the frameworks work irrespective of language differences. Eg Elm seems to be based on some kind of event subscriber architecture, is that how Reflex works too?
Did you try Elm at all before going Miso?
I did not. I really wanted the code sharing and the full feature set or Haskell so I never really gave it real consideration. Also things like ‚Äúisomorphic‚Äù rendering are cool
Well, hspec runs its tests in parallel, but I assume it's your program which is mysteriously running stuff in parallel, not your tests?
https://ncatlab.org/nlab/show/contractible+type, though maybe it should be mere proposition (https://ncatlab.org/nlab/show/mere+proposition)
Mixes are never perfect. Mix is a compromise where you take the best parts of each side...and throw them away. 
May be he just want to use JVM. 
&gt; Perhaps this got lost in translation but, a Free Monad is the free monad of / generated by a particular functor. So, somewhere along the line you'd need to find a functor. Right, I understood that the Free Monad is a monad generated for a particular functor, but I didn't understand the utility behind it being a functor. But your explanation helped make that clearer. &gt; Toy examples really aren't there to be questioned. They are just toys for the prose; that is their purpose. They aren't meant to be optimal, efficient, or at all practical outside of the context that introduces them. I'd agree to some extent, but I was also trying to figure out the details of what a realistic mini-language looked like and how the Free monad enables one to be built. Also possibly how more realistic mini-languages might differ in construction from the toy language. Thank you for taking some time to explain that to me. It seems like you have a lot of knowledge on the topic (as well as on PLT in general). Do you have any advice for learning more functional programming / Haskell / PLT, or any specific resources that you used? 
Hmmm what about that leading `_` in record fields..? What does it mean, not some convention to mark private fields right?
https://gist.github.com/Icelandjack/5afdaa32f41adf3204ef9025d9da2a70#constraint-synonym-encoding-or-class-synonym
You're all wrong. &gt;&gt;&gt; ((lambda random: ''.join ... ((lambda xs: (random.shuffle(xs), xs)[1]) ... (list("Haskell" + "Clojure")))) ... (__import__('random'))) 'ljlsuHekeroCla' 
The hardest part for me was the difference between type-classes and interfaces. I‚Äôve been a Java and c# dev, so when I stepped into Scala I was sort of caught in this strange world where I wanted to define interfaces for my abstractions. So I‚Äôd have something like: ```interface MyAlgo &lt;I,O&gt; { O do (I I) }``` Then I realised I could do this: type MyAlgo I O = I -&gt; O So once I stopped confusing type-classes with interfaces, it all started to click. I mean they are sort of similar, but you don‚Äôt need BOTH! From my c# work I‚Äôd already paid the cost of learning about ‚ÄòSelectMany‚Äô and its pals. And Linq forces you to learn about expr trees... So now: from Scala to Haskell as personal development. I love the moments where you see a higher order abstraction, and code just falls away. 
When compiled in `-threaded` mode, even a simple `interact (unlines . fmap reverse . lines)` takes 150% CPU on my machine, and that's definitely not because the program is parallelized. Probably wasting time on the parallel GC. When I recompile your program without `-threaded`, it completes in 2 minutes instead of 3, so no, it's not really a positive in this program :)
Haskell. A perfect mixture of haskell and haskell. Dont need anything else.
No. Haskell (purely functional programming in general) currently only makes it _easier_ to parallelise things, but not automatic. You have to put parallel programming constructs in to your code for that: * For pure code, that's [`par`](https://hackage.haskell.org/package/parallel-3.2.2.0/docs/Control-Parallel.html#v:par) and things built upon it * For IO based code, that's [`forkIO`](https://hackage.haskell.org/package/base-4.12.0.0/docs/Control-Concurrent.html#v:forkIO) and things built upon it (e.g. the [`async`](https://hackage.haskell.org/package/async) library)
When it comes to data processing as for your use case, I can also very much recommend `unliftio`'s [Pooled concurrency functions](https://hackage.haskell.org/package/unliftio-0.2.10/docs/UnliftIO-Async.html#g:9) that we added recently.
I said the _real_ mix of Haskell and Clojure... Perfection.
Cool! Now we just need a *"Perl for Readers"*.
I've usually seen it as convention to avoid scope issue, as record fields are in global scope and so if you have `data F a = { _insert :: a }` or something, you can then have a different function called `insert` Perhaps there's some interactions with lenses as well? 
Yep! The tests definitely run in parallel which is great, as well as compilation. I went back and tested the app: https://imgur.com/a/zbEMiJ1 All that 'red' in the CPU bars means system / kernel work, I believe. So here's a theory: GHC is auto-parallelizing the file I/O.
Hey! Thanks for giving it a shot. You can run the program too, if you first download the HTML files by just running `app/download.sh`. FYI, I went back to verify --- here's what I see: https://imgur.com/a/zbEMiJ1 I suspect GHC is parallelizing the file I/O, because of the red in the CPU bars.
I'll check it out - thanks.
Yeah, that's what I thought. Here's what I'm seeing: https://imgur.com/a/zbEMiJ1
Auto derivation of lens instances use a convention where the field name starts with an underscore.
This is not a bug, but a feature, namely *let generalisation*. GHC wants to infer the most general type for `m`, so in this case the type `forall t. t` (or, as foralls are implicit, simply `t`) is the most general type for the locally-bound hole. Say you had the following program: foo :: a -&gt; b -&gt; (a, b) foo x y = (m x, m y) where m = _ Now it wouldn't make sense to say that the type of the hole is `a` or `b`, as it must be some more general type that allows `m` to be used for both `x` and `y`. Nevertheless, I agree that it would sometimes be more useful for such a hole to have the type inferred from its usage site, instead of the type inferred from its definition site.
Why not just create a local dummy package?
I'm afraid I don't follow what you're asking; you mention IO with various file formats is good to have (ok), but then remark about IO strictness being a problem (why?), and ask for a language extension for doing what exactly?
Loading arbitrary source code from the internet sounds like a gigantic footgun and a sure security liability, no matter what "young programmers" might be wanting.
[Halogen](https://github.com/slamdata/purescript-halogen) is one.
In python, *everything* regarding "interacting with the outer world" is really easy. In Haskell it is not. (Strictness was not meant as in lazy vs. strict, but more as in a bondage&amp;discipline attitude towards programming). First, should we strive to make interacting with the outer world as easy as with Python? Not sure about that. Second, how? Much less sure about that, since I am still a noob in Haskell.
&gt;So... HoTT instead? That just results in ¬¨¬¨. FTFY 
I‚Äôve only finished the first chapter of the HoTT book, so if there‚Äôs a joke or a reference here, I‚Äôm not getting it. :)
It's a very lame attempt at a joke involving a very old emoticon that nobody uses anymore. :) L
The post mentions that Haskell is used to implement crypto. How is this done? Is there a safe DSL which is used to generate code, which is resistant to side channels? Alternatively Haskell could call native crypto primitives. Or is Haskell used only for prototyping?
Why is `;` used instead of newlines in the GHC source code? I see it both in `case` expressions and in `do` blocks. I haven't seen it used in any Haskell libraries, so I wonder why it's used in GHC.
Personal preferences and maybe some cross polination with C habbits? ; is valid expression separator in Haskell so that machine generating code is simpler.
&gt; Do you have any advice for learning more functional programming / Haskell / PLT, or any specific resources that you used? Definitely keep asking questions. But, also don't assume the loudest answers (like mine, say) are correct. I still sling Java and Python for work, and I have a grand total of one, deprecated package on hackage. So, most of my knowledge is theoretical. Types and Programming Languages by Pierce (TaPL) is my go-to book for types in general, though it doesn't get you to dependent types. Okasaki's Purely Fuctional Data Structures (PFDS) not only has some useful implementations that avoid mutation, but also really breaks down how to reason about laziness, I think. I take those two books almost everywhere. The Typeclassopedia is a good Haskell reference, especially for type classes that were not already covered in the Haskell Report. The Haskell Report is a good specification, and never underestimate the value of going back to the spec. (Though, GHC has diverged from the report ever since the AMP merge.) "You Could Have Invented Monads" is my favorite monad tutorial. Simon's papers on STG (the abstract machine used by GHC) and OutsideIn (the type inference used by GHC) are also interesting, but I haven't internalized them yet. They refine the reductions provided in the report and H-M (covered in TaPL) respectively. There are other important papers, too, so embrace the PDF and don't expect everything to be HTML-ified.
&gt; I was also trying to figure out the details of what a realistic mini-language looked like and how the Free monad enables one to be built. Do another top-level ask for a example of using a free monad in a production-quality package. I don't have one. I understand the theoretical value, but I haven't needed it, so I haven't used them in practice -- I just build the monad I need from the parts in transformers.
It's possible that some of the GHC developers predate the layout. I don't know when it was introduced (it was part of Haskell when I joined / in the 1998 report) but, it was actually based on a semi-colons first (aligned with braces) style that was used by a few people for do notation (and later some lets): do { var &lt;- stmt ; y &lt;- again ; return pexpr }
the term "event subscriber architecture" is vague. i guess it could refer to FRP, but really in FRP you're setting up a circuit, so that you never would have to imperatively call a method "subscribe". there is a lot of academic literature. you gotta start from the beginning if you want to understand it. it's really apples to oranges. apples and oranges are both edibles, but if you ask me for a comparison, you still have to specify what you goal is, to give a meaningful comparison. see https://softwarerecs.meta.stackexchange.com/questions/336/what-is-required-for-a-question-to-contain-enough-information
Not if the address is well known by the programmer and is a risk that the programmer should take if he switch on it. At last, every software is downloaded from the internet. It is nothing new. Other sucessful languages, use that and it and it is not a great concern. On the contrary: an URL is an open and clear statement, right in the source code, that a precise address is used to load some other code. This is not the case in the case of software package managers, that configure the download addresses in third party configurations. Additionally, nothing has zero risk. Even choosing Haskell or any other language, for that matter, implies a risk whose importance depends on the experience, goals etc of a programmer or a company. Let's leave give each one the freedom to choose and take the risk associated to their decissions.
It would also be good to look at `do` notation for this, and Applicative (`liftA2` and `&lt;*&gt;`).
Sorry, the spam filter caught this post. I'd recommend asking on r/haskellquestions or the Intero issue tracker: https://github.com/chrisdone/intero/issues
GPLv3 lowercased the disclaimer initially, but then Eben or one of the other lawyers found some level of support that failing to CAPS it might be problematic so they put the CAPS back. You might kid; but the FSF decided it was a serious issue.
Eta language = GHC 7.10 on the JVM.
Just posted to /r/haskellquestions. Chris Done seems to have a policy of no nix questions so I'll use that as last resort.
I'm trying to upgrade my project from Pandoc 1.9.x to Pandoc 2.x (specifically 2.2.1 which in nix 18.09), and my Markdown -&gt; HTML conversion started escaping HTML tags. This is what it looks like in a REPL: -- pandoc 2.2.1 -- Compiled with pandoc-types 1.17.5.1, texmath 0.11.0.1, skylighting 0.7.3 import Text.Pandoc import qualified Data.Text as T runIO $ (readMarkdown def (T.pack "&lt;!--FOO --&gt; *awesome* &lt;b&gt;boss&lt;/b&gt;") &gt;&gt;= (writeHtml5String def)) -- Right "&lt;p&gt;&amp;lt;!--FOO --&amp;gt; &lt;em&gt;awesome&lt;/em&gt; &amp;lt;b&amp;gt;boss&amp;lt;/b&amp;gt;&lt;/p&gt;" I'd like Pandoc to NOT escape to \&amp;lt; and \&amp;gt;, but keep it as-is. If I just use the Pandoc command line, however, it works as expected: $ pandoc --version pandoc 2.2.1 Compiled with pandoc-types 1.17.5.1, texmath 0.11.0.1, skylighting 0.7.3 $ pandoc -f markdown -t html &lt;!--FOO --&gt; *awesome* &lt;b&gt;boss&lt;/b&gt; (Above is the input, which I then &lt;Ctrl-D&gt; to generate the output below) &lt;!--FOO --&gt; &lt;p&gt;&lt;em&gt;awesome&lt;/em&gt; &lt;b&gt;boss&lt;/b&gt;&lt;/p&gt; Anyone know what's going on?
"I don't have function *filp*" - made me laugh out loud. :)
Do you find that maintainability suffers as your project grows over time with miso? It seemed like you'd eventually have a pretty massive type representing all data communication and a corresponding monolithic render function. I'd be curious to hear thoughts on how this pans out in practice - I've only used miso in toy code. Thanks!
You're only able to use the result of your splices, the `appConfig` in this case, in a different module.
Hi, one of the Unison devs here. I think the idea of "the codebase as a purely functional data structure" is something that's very general and could be useful for any language. (When we're happy with how it all comes together we'd like to publish something on it.) My hope is that this idea starts to become the norm for new languages once people see how incredibly awesome it is. :) But I also suspect it would be hard to retrofit an existing language to do it. I never want to say something is impossible but it's easier to start with a clean slate since this stuff touches like every aspect of the language and its ecosystem.
Thanks! I've given it a quick try and indeed that does satisfy my requirements. I need to smooth out a couple of things for my use-case, namely, easy mapping from a Vinyl record to hvega DataRows, and some simple workflow to look at the output. The first should be mostly straightforward except for mapping the richer universe of types which might be in a record to the types available in hvega.dataRow but I can probably come up with a simple typeclass to handle dates and times and numbers and defer the rest to a show instance. Or something. The second issue requires more thought. Maybe I need to try IHaskell? For now I am just writing out an entire html document with the script embedded. Which, if streamlined enough, could work for me as well. 
This makes sense, although I think the `forall t . t` is a kind of degenerate case in the sense that there‚Äôs never any sensible construction of that type so I‚Äôd rather just toss that generalization and use the more constrained one. But yeah, good point, I can see how it came up with that now.
For real, you're not allowed to use the [containers](http://hackage.haskell.org/package/containers) library? Well, reimplementing those basic data structures would be a lot of work, so I would use less efficient data structures such as association-lists. [`lookup`](http://hackage.haskell.org/package/base-4.12.0.0/docs/Prelude.html#v:lookup) is in `Prelude`, you can use that as a poor man's [`Data.Map`](http://hackage.haskell.org/package/containers-0.6.0.1/docs/Data-Map-Strict.html#t:Map). Now you can define your graph as follows: give each node a different Int, and store the edges as an association list from a node to its list of neighbours.
Is a "cursor" the same thing as a [zipper](https://en.wikipedia.org/wiki/Zipper_(data_structure))?
Thanks.
Great write-up! Side question - what do you use to draw graphs like this? https://user-images.githubusercontent.com/4276606/50770531-b6a36000-1298-11e9-9528-caae87951d2a.png
We could even make this *functional* style readable: &amp;#x200B; "Sequence expressions, returning value of last expression" do = lambda *exps: exps[-1] do_ = lambda *_: None module = type("module_import", (), { "__getattr__": lambda _, name: __import__(name) })() "Define variables in scope of the input function" let = lambda **vars: ( lambda f: FunctionType( f.__code__, dict(vars, __builtins__ = __builtins__, module = module, do = do, do_ = do_, ) )() ) let ( random = module.random, string = list("Haskell" + "Closure"), )(lambda: do ( random.shuffle(string), ''.join(string), )) &amp;#x200B;
Thanks! I'm using draw.io whenever I need to draw some graphs or flowchart diagrams.
This is great, thanks. I've seen so many Halogen vids but still have issues with those ridiculous function types.
Yeah, component types get pretty hairy because they also have knowledge of the behaviors and outputs that their child components have. In the end it leads to supremely predictable code but the types can be irritating -- visually, if nothing else. &amp;#x200B; Halogen 5, the upcoming version, makes lovely use of PureScript's row types to reduce the issue somewhat, but I don't see a future in which Halogen's types get much smaller than they are.
Why not `(-1:)` before sorting?
To answer my own question... The [Ext\_raw\_html](https://hackage.haskell.org/package/pandoc-2.2.1/docs/Text-Pandoc-Extensions.html#t:Extensions) extension needed to be enabled for the Markdown reader options. This will make Pandoc parse the Markdown into this AST (note the \`RawBlock (Format "html")\` nodes, whereas before they were being parsed as Str nodes): Pandoc (Meta {unMeta = fromList []}) [RawBlock (Format "html") "&lt;!--PREAMBLE\ndate: 2018-01-30\npostTitle: \"My first blog post!\"\ntags:\n - awesome\n--&gt;",Para [Str "There",Space,Emph [Str "twenty"],Space,RawInline (Format "html") "&lt;em&gt;",Str "twelve",RawInline (Format "html") "&lt;/em&gt;"]] &amp;#x200B;
How does PureScript compare to Elm?
They have different philosophies for functional programming for the web. Elm aims for simplicity, usability, and turning JavaScript developers into functional programmers. They do an admirable job and the marketing around Elm is fantastic. PureScript aims for power, flexibility, and a sound theoretical foundation, and it tends to be folks already convinced about functional programming (or often Haskellers). Accordingly, Elm is lovely to learn and use especially on small projects. It eschews features like type classes, type-level programming, and deep interop with JavaScript to keep the ‚Äúsimple‚Äù goal in focus. PureScript is harder to learn, but has those features (and more), which really shine as applications get larger or if you need to interop with say an existing React codebase. Since most large PureScript apps are rewrites from JavaScript that tends to matter quite a bit. Either choice is just fine, but as far as production applications go, I think PureScript has the better mix of features despite the steeper learning curve.
[removed]
I had to drop in say thank you for the work on this. I think these kind of resources are critical to increasing adoption of languages such as Haskell and PureScript.
Thank you! I completely agree, and I hope to see more like it in the future.
I‚Äôll make a big reddit post shortly explaining our tech setup and a bit about the product itself. I‚Äôve been meaning to do it for a while and I do think that it is very scalable and fun to work with. In short everything is extremely modular. Each component gets its own state (if desired) and its own view and its own handlers, and the parent just has to handle the components outputs and feed it it‚Äôs inputs. Each component is only responsible for itself and handling its direct children. 
Thank you for the extensive reply. I'll look into PureScript then üòÉ
I was initially distracted by the `RIO` bit, so for the benefit of the other commenters: the problem is that `makeClassy` generates the reflexive instances `HasServerConfig ServerConfig`, `HasClientConfig ClientConfig`, `HasAppConfig AppConfig`, and `HasEnv Env`, but not the transitive instances `HasServerConfig AppConfig`, `HasClientConfig AppConfig`, `HasServerConfig Env`, `HasClientConfig Env`, and `HasAppConfig Env`. As a result, when running `foo` by instantiating `env` to `Env`, the `HasAppConfig Env` instance is not found. There is a quadratic number of transitive instances and only a linear number of reflexive instances, so it's surprising that someone would spend the time to implement `makeClassy` in order to save their users the trouble of writing that linear number of reflexive instances, while knowingly leave those users the burden of writing a quadratic number of transitive instances. So maybe I (and the OP) misunderstand the purpose of `makeClassy`?
Negativity (contravariance, negation itself) is a tricky thing. Instead of using it directly we can try to encode it in a more positive/constructive way: For each proposition/type P that we want to work with, we work with a pair of propositions/types: aP - affirmation of P and rP - refutation of P. We'd better make sure that they can't be proven at the same time! This is so called Chu construction. We'll denote the two related types with $ aP / rP $ (this is not a pair!). Now the negation can be defined in hopefully less controversial way. Chu pair of negation of $P = aP / rP$ is: $~P = rP / aP$. Now, how are conjunction and disjunction of a Chu pair defined? You might want to try out write it out before reading below, there's more than one solution! One (more constructive) answer is: * P ‚àß Q = (aP / rP) ‚àß (aQ / rQ) = ((aP, aQ) / Either rP rQ) * P ‚à® Q = (aP / rP) ‚à® (aQ / rQ) = (Either aP aQ / (rP, rQ)) Another (more classical) way do define conjunction and disjunction is: * (aP / rP) ‚àß (aQ / rQ) = ((aP, aQ) / (aP -&gt; rQ, aQ -&gt; rP)) * (aP, rP) ‚à® (aQ, rQ) = ((rP -&gt; aQ, rQ -&gt; aP) / (rP, rQ)) For instance, in order to disprove classical (P ‚à® Q) you don't have to choose which of P, Q has to be disproved. You just have to provide an algorithms that turns proof of one of them into refutation of the other. *Notice that for both definitions we have ~(P ‚àß Q) = ~P ‚à® ~Q !* Which one is correct? Here comes the twist: with linear logic you don't have to choose! The former corresponds to an additive sum and product (typically called plus and with), while the latter corresponds to a multiplicative sum and product (typically called tensor and par). One of my favorite application of Chu construction is [Positive Set Theory](https://en.wikipedia.org/wiki/Positive_set_theory) that has two separate set relation symbols ‚àà and $\\bar{‚àà}$ which mean respectively that element 'provably belongs' and 'provably not-belongs' to a given set. Recommended reading: [Linear logic for constructive mathematics ](https://arxiv.org/abs/1805.07518)
Thank you. 
That makes 3 of us. Glad I'm not alone. /u/edwardkmett , do you have the insight into makeClassy we are missing?
Thanks for all the feedback! I'll discuss with my advisor and hopefully keep y'all posted.
No, HoTT is not the answer here. Linear logic is. PTAL my post below. 
HoTT is not the answer here. Very surprisngly Linear Logic is. PTAL my post below.
Thanks for your detailed explanation. I'm a Haskell newbie and it's the first time I'm using the `lens` package but I've been using classy optics a lot in Scala and it works a bit differently (as in I get all the transitive instances derived). I don't know if I get it, do you think `makeClassy` should derive the transitive instances as well? --- OTOH what are your thoughts on deriving such instances as follows? ``` {-# LANGUAGE FlexibleInstances #-} {-# LANGUAGE UndecidableInstances #-} instance (HasAppConfig env) =&gt; HasServerConfig env where serverConfig = appConfig . _server instance (HasAppConfig env) =&gt; HasClientConfig env where clientConfig = appConfig . _client ``` I only heard that the type inference might not be great by deriving instances with the undecidable flag on but so far I haven't had any issues so I'm wondering if there's anything else I should be aware of. Also, this is a small example, my application is much bigger so it might not be correct (didn't try to compile it) but this is the approach I'm using in my app. Appreciate your time :) 
I'm still fooling around with the idea, feedback and PRs welcome! I found myself really wanting a grid-style lib which I could use with Control.Comonad.Representable.Store, so this fills that niche now.
One of my favorite functional pearls from the last couple years described a data structure for doing random sampling with replacement efficiently. This post describes some improvements to the asymptotics (I think!) and some other possible uses. Feedback welcome!
Or in Haskell, if you had callCC :: ((a -&gt; b) -&gt; a) -&gt; a then you could define lem :: Either a (a -&gt; b) lem = callCC $ \cont -&gt; Right $ \a -&gt; cont $ Left a 
Unless one of the libraries you use uses one of the functionalities I mentioned, what you see is parallel GC. Garbage collection is parallel when compiled with `-threaded`. Sometimes that makes things faster, sometimes not.
Thanks for the package! This is definitely a space I've been trying to figure out a good interface for as well. And thank you for not calling them tensors :)
Glad I'm not the only one! Let me know if it's missing anything, I assume there's a bunch of combinators I've looked over so far, and I'm curious if folks will need adaptability on the underlying vector it uses? The next challenge is how to allow loading one of these of arbitrary size at runtime... I think it's possible using existentials, but it's far from easy üò¨
From what I understand, one major purpose of \`makeClassy\` is to clean up export lists; instead of exporting lenses for every single field, they can just export \`HasServerConfig(..)\` instead. The ability to abstract over all things that "have this field" is a nice side effect of this.
makeFields has something closer to the behavior you're looking for here. The real problem is that makeClassy doesn't have enough context to correctly automatically derive the transitive instances you want it to make here, nor a reason to know that there aren't two copies of a thing inside it (or which the user will introduce later in such a way that it shouldn't have an instance.) You can use slightly different methods to build HasFooConfig classes yourself that have appropriate superclasses, but you have to wire up part of it by hand or give in and embrace the pain of makeFields at present.
I agree. I think first class rows, sums and products will be huge for exploring this aspect of Haskell that is currently awkward. Namely talking structurally about Haskell types and truly having first class manipulation of them. Generic / deriving is great but we can do much more and in a much cleaner way. For example even the concept of case statements could be made redundant. Given a value of type `Sum { A = Int, B = String }` you can fully replace a case statement with a value of type `Product { A = Int -&gt; a, B = String -&gt; a }` and a function / operator that applies the former to the latter to get out an `a`. (`Sum r -&gt; Product (map (-&gt; a) r) -&gt; a`) There are a wide variety of things that would go from needing compiler support / TemplateHaskell to being fairly easily definable in libraries, given a decent set of primitives.
It's not \*too\* bad, actually :) I can submit a PR with a couple of potential approaches if you'd be open!
Probably a super simple mistake (I'm a complete newbie to Haskell) but why am I getting this error Main.hs:5:1: error: parse error on input ‚Äòmain‚Äô | 5 | main :: IO () | ^^^^ for this code module Main where import Answer import System.Environment main :: IO () main = do args &lt;- getArgs putStrLn . show . smallestPositiveInteger . map read $ args
[removed]
How does it compare to `hmatrix`?
Isn't your indentation broken? Delete spaces before imports.
\&gt;as far as production applications go, I think PureScript has the better mix of features despite the steeper learning curve. &amp;#x200B; What is the size of the compiled js output like? For Elm I think it is really small. If Purescript's output is substantially large than that of Elm, that alone is going to eliminate it from the competition. And last time I checked, for a medium sized project, it was not even close. And the thing about turning javascript devs into functional devs is pretty great. It is great if you can strap on some programming capabilities on a great front end dev. Because the compiler has your back, and make sure that the newbie programmer won't mess things up. But good luck teaching those front end skills to a good functional programmer. Last time I checked, there is no compiler that can check the alignment of some html elements or that the they have not used some stupid color scheme... So that also is a big deal wrt real world production application. So I think Elm has placed itself in a very sweet spot with respect to real world production browser applications. &amp;#x200B; &amp;#x200B; &amp;#x200B; &amp;#x200B;
The installation instructions did not work for me.. &amp;#x200B; `$ yarn build-serve` `yarn run v1.3.2` `$ pulp --then 'parcel build assets/index.html &amp;&amp; http-server dist' build --to dist/app.js` `/bin/sh: 1: pulp: not found` `error Command failed with exit code 127.` `info Visit` [`https://yarnpkg.com/en/docs/cli/run`](https://yarnpkg.com/en/docs/cli/run) `for documentation about this command.` &amp;#x200B;
In an old design doc they had on [monads](https://github.com/input-output-hk/cardano-sl/blob/2f0f9855d26a0b7b4ff34653d5bf4e63546d1f93/docs/monads.md), IOHK defines capabilities as any effects that aren't intrinsic to a monad. /u/ephrion seems to use the same definition in his Three Layer Cake model, but if I'm understand correctly, he also says that they're in layer one. Or he meant that capabilities are defined in layer two but implemented in layer one. I'm not sure. You seem to define them as layer two, judging by your \`Capability.\*\` modules, and the guide you wrote on this. All this to say, it's unclear. And none of these seem to explain what their relation is supposed to be to the third layer. There's a clear progression from one to two, but how do you get to business logic from that? And how is that everything becomes massively less complex when you go from capabilities to pure functions? It doesn't make sense. The cake needs to be rebaked. 1. pure functions &lt;-- no state 2. monads &lt;-- state 3. capabilities &lt;-- dependent states (monad stacks, sortof) 4. business logic &lt;-- mapping from external state to internal state (DSL) Putting pure functions at the highest level seems completely backwards to me. Business logic is where you define a DSL for how external agents talk about the internal state of the system. It's even implied in that it's called \*business\* logic, meaning that it's the type of things that non-technical people can talk about, people that are strangers to how the internals work. And of course, you can abstract over how it gets interpreted with a free monad or tagless final or whatnot, so it has the same property of capabilities in there being multiple possible implementations on lower layers. Of course, pure functions can be polymorphic, which looks similar in its multiplicity, but it's still lower order. A list that can hold any type is lower order than, say, an AST that can have multiple valid meanings. Not to say that the cake is a lie. It has been extremely useful for structuring my Haskell applications. But it needs fixing. And it needs to go higher.
OMG, this is totally awesome! Thank you so much for creating this great learning resource, and for sharing it with us! 
Meta question: why are you referring to logics, when the topic is type theories? Is a type theory necessarily based on a specific theory of logic? And is there a one-to-one relation between them, or can a single logic produce multiple type theories?
But you still have to deal with the bureaucratic message tagging, right? And by that I mean, having to tag each message at each level of the component tree between the sender and the root. I think things like that are what /u/stilbilek was referring to. And I don't see how Haskell could provide any sort of shortcut, unless Miso is doing something clever. It's pretty much endemic to the Elm architecture, and loathsomely so.
Ah yes that is true, although the boilerplate is IMO pretty tame. Plus if you want separate pure view code and impure handler code it seems like then this seems pretty fundamental, the handler for the component needs to run its child handler (with said tagged action) and it needs to handle the output of that. So code like this: ``` case action of FooAction fooAction -&gt; do fooOutput &lt;- first FooAction $ Foo.handler ... case fooOutput of Foo.Bar -&gt; ... Foo.Baz -&gt; ... ``` Certain aspects of the tagging may feel redundant such as needing to map over it with things like `first FooAction` or `FooAction &lt;$&gt;` in places, as you won't need to do such a thing with FRP, but this is a very small amount of the boilerplate. The significant boilerplate in the handler code itself has fairly little noise and most of the code is doing the very useful and essential task of choosing what inputs to propagate to the child handler and what to do with the various possible outputs.
Interesting work. Tree fold is definitely interesting. I wonder if there are (natural) things where only foldl make sense and not treefold. 
What's the alternative though? Isn't that inherent in classical reasoning? 
If you want computational classical logic and won't bulge on any matter, you might want to [try and go modal](https://queuea9.wordpress.com/2013/08/12/whats-so-nonconstructive-about-classical-logic/). You can't commit to any irrevertible effects in a classical world, but that also means that until you *do* commit you can do whatever classical reasoning and control effects you want. Whenever you commit to an effect, you take a necessary "step forward in time" from which control operators can't save you anymore. Then, constructive logic is valid across all time, while classical reasoning is constrained to a "single" point in time. The OP article surprised me, because I read about this idea first from OP's blog. If you don't care much about classical logic, but care about control operators, you shift your eyes towards delimited control (and algebraic effects and effect handlers, I suppose). If you care about classical dualities but also strongly care about constructivity, you turn to classical linear logic, as mentioned multiple times in this comment section. I learnt about this from here, and it's preposterous in its ingenuity. You notice that intuitionistic negation is a non-constructive notion of "refutation" of a statement, and that often it's better to *define* a construction of what it means to refute a statement (e.g., rather than taking the negation of equality, one usually asks for an explicit [apartness relation](https://ncatlab.org/nlab/show/apartness+relation)). Taking the idea of needing to construct both demonstrations *and* refutations to the heart, you end up working with types/propositions `P` as pairs of "intuitionistic" types/propositions `(P+, P-)` such that `¬¨(P+,P-)`. Working out the details of this gives you classical linear logic. For a better account on this, read [this post from this thread](https://www.reddit.com/r/haskell/comments/afckoe/why_i_no_longer_believe_in_computational/ee2y0it/) or [this article from the nCat Caf√©](https://golem.ph.utexas.edu/category/2018/05/linear_logic_for_constructive.html)).
I‚Äôm interested in working on a project like this for GSoC. It seems like something the Haskell community could use. How can I apply to work on this project as a student?
No idea! This is the first proof of concept for the idea, I actually don't do a ton of linear algebra outside of some matlab from uni, so that'll be a fun thing for me to learn. I mostly wrote this because I've wanted this type for doing cellular automata stuff, but I figure it probably works for matrices too! The Grid type is really just a newtype of Vector with a bunch of instances though, so if hmatrix is performant we can probably just borrow or re-export a lot of the same operations! The nice thing is that this presents an opportunity to unify and extend hmatrix from only 2D and 3D to *D üòÑ I'd love some help on it if you have ideas!
treeFold only works for functions with type (a -&gt; a -&gt; a) while foldr is more general and words for function with type (a -&gt; b -&gt; b).
Definitely! I've gotten close to getting something working, but have had trouble getting GHC to understand that a list of KnownNats is an instance of Dimensions 
Remember that type class resolution only matches on the part on the right hand side of the `=&gt;`, so your `(HasAppConfig env) =&gt; HasServerConfig env` instance isn't saying that _if_ there is a `HasAppConfig` instance for `env`, there should also be a `HasServerConfig` for that `env`, it is saying that _every_ `HasServerConfig` instance is obtained via a `HasAppConfig` instance, which is not what you want.
I've been on/off working on something similar (https://github.com/edwardwas/sized-grid), but yours seems to have a way simpler use facing API. You have you're own coord type but haven't defined many instances on it (like Num or even Semigroup). Was this an active choice or something on the todo list?
The function ÀãlistArrayÀã takes a pair of indices as it‚Äôs first argument: The first index and the last index of the array. As you need to give a two dimensional array to ÀãluÀã, your indices are pairs themselves and you need to give a pair of pairs as the first argument to ÀãlistArrayÀã, say ÀãlistArray ((1,1), (m,n)) [‚Ä¶]Àã for an (m * n) matrix. (I cannot quite explain why you get that specific type error, though.)
`Array (Int, Int) Double` is an array with indices of type `(Int, Int)`. Try `listArray ((1,1), (3,3)) [1..9]`, for example, to construct a 3x3 matrix.
&gt; if there is a `HasAppConfig` instance for `env`, there should also be a `HasServerConfig` for that `env` Right, that should be represented on the typeclass definition correct? ```haskell class (HasAppConfig env) =&gt; HasServerConfig env where (...) ``` &gt; which is not what you want Unfortunately, this is all I can do since `makeClassy` is the one generating the typeclass but not the instances I need. Anyway, I'd argue that in this case it doesn't really matter as it does what I need.
Sounds really great! I'll look into it, I'd love to help
Haven't thought about it too much yet, the coords are type-restricted finite numbers, how should they behave in the case of overflowing their dimension? What's a negative coord look like? What behaviour would you propose for semi group? Addition doesn't seem terribly useful to me, but maybe I'm missing a use-case? I would like to figure out some sort of Foldable or traversable or something for the coord type, but since it's heterogeneous it's a little tricky to find an ergonomic way.
I have separate newtype instances for finite numbers - one where they are clamped between the valid ranges and one where they behave as if on a torus so they wrap back to zero. It's mostly useful for working with anything that cares about the neighbourhood around a certain cell: I can't think of a nice way of finding the mean of a cell and it's neighbours without instances for the coord for example.
Taking a look at your Lib it's quite surprising how similar they are! Looks like we made a few different choices though ; I'd thought about different index types like you have, but decided to just leave that up to the user. Also I forgo the Focused Grid in favour of just using Control.Comonad.Representable.Store üòÑ Cool to see we both thought of the nested list stuff too!
Yup, these are handy when doing image processing stuff, I've considered adding the same with a single DataKind stored on the grid itself!
Thank you, this fixed the error. Although I still don't get the desired result. Do you happen to know anything about the Matrix.LU library?
The plan with FocusedGrid was to introduce some way of overlapping them, so you could write convolutions as smaller grid of functions, but I never actually figure out a nice way of writing that. Using my own datatype for indexing gives some nice stuff, but the typeclasses are a bit of a mess and introduce some really ugly constraints. 
You should be able to do convolutions using Control.Comonad.Representable.Store by mixing extend with "experiment" over a smaller grid containing neighbouring coords üòÑ That's my next area to work on, here's hoping it works out ü§û
Any function which can be written using `foldl` *or* `foldr` can be writtern using `treeFold`. I went into it a little more in the previous posts, but for `treeFold` to work the operation effectively has to be a monoid operation. You can have conversion at either end (like you have with your `map`). What you basically want is a list homomorphism.
No, and I don't know what the desired result is. I was just giving an example of how to construct an element of the proper type.
You may be interested in Simon Marlow's keynote from last years HaskellX: https://skillsmatter.com/skillscasts/11654-keynote-how-to-deploy-your-haskell-code-hundreds-of-times-a-day
&gt; that should be represented on the typeclass definition correct? No, that would also say that every `HasServerConfig` instance must also have a `HasAppConfig` instance, which is still not what you want.
It's okay, your tip was very helpful anyway.
The ‚Äúlearn‚Äù section is unreadable on mobile for me. (Safari; iOS 12)
First of business: release the Haskell [bees!](https://www.youtube.com/watch?v=xAhuSDRIDHE)
&gt; I still don't get the desired result What is the desired result? Wikipedia gives the example [ 4 3 ] = [ 1 0 ] * [ 4 3 ] [ 6 3 ] [ 1.5 1 ] [ 0 -1.5 ] And I get &gt;&gt;&gt; lu (listArray ((1,1), (2,2)) [4,3,6,3]) array ((1,1),(2,2)) [((1,1),4.0),((1,2),3.0),((2,1),1.5),((2,2),-1.5)] that is, lu [ 4 3 ] = [ 4 3 ] [ 6 3 ] [ 1.5 -1.5 ] which I am guessing is a fancy way of packing both of the resulting triangular matrices into one? 
What if the first input function of foldr is not associative? For example: data Tree a = Fork (Tree a) a (Tree a) | Leaf makeUnbalancedTree = foldr (\a b -&gt; Fork Leaf a b) Leaf How would you implement that using treeFold?
Would love to read about your experience once you've tried this! IHaskell would give you a feedback loop, but it's a bit fiddly to set up. I would try something with ghcid, since you can pass it any command that runs whenever it detects a code change, like `ghcid --command "stack build &amp;&amp; stack exec bla"`. Replace the stack commands with `cabal new-run` or use [scripting](https://haskell-lang.org/tutorial/stack-script) with `stack runghc -- HelloWorld.hs`. Whatever produces the image artifact you want to look at. You can even send your browser a refresh command (`xdotool` comes to mind) for maximum laziness.
Yes, basically the property you need is associativity.
Since the cursor is non-empty itself, it would be nice to convert from cursor to `NonEmpty` list as well to have more guarantees, i.e.: rebuildNonEmptyCursor :: NonEmptyCursor a -&gt; NonEmpty a
Nice :) It's good to have simple introduction material like this to make it easy to get things running.
Good. With `(-1)` added, this can be solved with `maximum` alone, no need to sort the list: maximum . filter (&lt;= b) $ (-1) : liftA2 (+) keyboards drives
[removed]
For the last part, I think it‚Äôs because it‚Äôs looking for an instance that would let it produce an `(Int,Int)` from the literal `1`. 
[Curry-Howard correspondence](https://en.wikipedia.org/wiki/Curry%E2%80%93Howard_correspondence) -- type systems and logics are the "same thing" viewed different ways. Propositions become types, and proofs become (well-typed) terms. Lambek also extended this to add a categorical view. My understanding is that is it a 1-1-1 isomorphism, but that many type systems results in logics with soundness issues and some logics result in type systems with normalization problems. (This is actually useful when you a picking / designing a logic / type system; you modify the logic to fix soundness issues then change it into a type system and modify the type system to fix normalization issues then change it into a logic and repeat until you get all the properties you want on both sides [or exhaust yourself].)
The weird license is a serious turn-off. But to be fair, it doesn't look like a *crazy* license. The restrictions on commercial use are rather subtle, which is a bad thing for potential users. It looks like the intent is to prohibit SaaS commercialization, in the spirit of AGPL. Also, the forum selection and choice of law clauses (under "Litigation") are very strange. If for any reason you want to breach the license, just set up your principal place of business in some obscure country, and nobody including the original authors will be able to do anything about it without staggering expense, because they can't sue you anywhere else, under any other laws.
Kind of loosely coupling, late binding and some ghc lib magic?
GHC is supposed to be good for multithreaded code. But whenever I tried, the speedup was a lackluster. I used Intel chips (up to 64 cores). Maybe GHC scales better on threadripper 2 CPUs?
I mean a 'guesstimate'. And obviously code that does use SIMD.
&gt; Last time I checked, there is no compiler that can check the alignment of some html elements or that the they have not used some stupid color scheme I think if you could express some harmonious relations between colors at the type level, you could probably make sure they don't use a stupid color scheme. Probably requires dependent types, though. As for alignment, [GSS](https://gss.github.io/) (sadly dead) used the Cassowary constraint solver, which was pretty cool.
I agree. While I am a fan of free software, I also understand that commercial licenses are needed to monetize things or as a means of protection from competitors. However if there is a free alternative to a product, I would just switch to the alternative. In this case, assuming that Lux offers some valuable features (or even competitive advantage for a business) over Haskell/Clojure, those advantages are diminished by the license. For a compiler it makes sense to be as free as possible, to give people a trustworthy platform to build on. Commercialization has to happen differently, via finding a cooperate sponsor, donations, service offerings or additional products. Just look what Eta and Clojure are doing. Maybe the author will reconsider his decision given that he started with the MIT license.
Hi! Is a remote application a possibility?
Hey, do you take remote or contractors?
Hi! We'd love for the person to be at least partially in Belgium, but we'll evaluate case by case to see if working together is feasible. Thanks!
Hi! We'd love for the person to be at least partially in Belgium, but we'll evaluate case by case to see if working together is feasible. Contractors are fine. Thanks!
Is there a complete guide anywhere for running GHC on ARM? I'm trying to use it on a raspberryPi. Got ghci working but when I try to install anything through stack I get a series of error messages similar to: `/tmp/ghc5456_0/ghc_6.s:251:0: error:` `Error: selected processor does not support \`movw r7,:lower16:Cabalzm2zi4zi0zi1_DistributionziSimple_defaultMain_closure' in ARM mode` I'm on Raspbian, and have llvm for armv7 in my PATH. This looks very similar to [this](https://stackoverflow.com/questions/30201508/why-cant-i-install-any-packages-with-ghc-7-8-4-on-raspberry-pi) and [this](https://www.reddit.com/r/haskell/comments/35bw0b/at_last_debian_unstable_has_working_arm_ghci_and/cr5obnh), but the fixes there don't work for me.
Somewhat relevant benchmark: https://qbaylogic.github.io/benchmark-compilation/
Thanks for your interest in our project! According to the GSoC 2019 timeline, official student application period begins in March 25. * https://developers.google.com/open-source/gsoc/timeline Though you can contact mentors earlier :) I found this blog post with description of steps how to apply for GSoC very interesting and useful! * https://medium.com/@i.oleks/how-to-apply-for-google-summer-of-code-95c1bfcd41a5
You're welcome! Thanks for your feedback! Feel free to ask any followup questions if you would like to discuss the library or have some confusion with using it :)
A type theory is just a logic with judgements of the form "the term _ has type _" (_ : _). A logic is just a type theory where terms are proofs and types are propositions. Sometimes people will state this equivalence is an isomorphism, but there are some issues with that: consider that there are *two* proof terms for the derivation of (A or A) from A; a logic will tend to ignore the distinction. In general, logic focuses on provability where type theory focuses on proof; extracting a proof from provability is nondeterministic (if there are several proofs). It's common to ignore the distinction for convenience
MPJ speaks quite like SPJ, which checks out and is pretty awesome :D
Wow, what a timing! We just talked about this problem a few hours ago when investigating this segfault (https://ghc.haskell.org/trac/ghc/ticket/16186). We even talked about including it via the linker, and now you present just that solution. Thanks!
Congratulations! :)
[removed]
That's good to know, and I see that the Google Sites preview agrees with you. I will try to coerce it into not squishing all the embedded documents. Sorry. Can I encourage you to try again on a large screen for now?
IMO this should be implemented on the Cabal level. Relevant tickets: https://github.com/haskell/cabal/issues/142 https://github.com/haskell/cabal/issues/839.
What a timing indeed! 
[removed]
Not for my use case: I want to store TH generated files into the executable.
Don't see why it'd be impossible to embed dynamically generated files using the interface proposed in the tickets I linked.
This is a joke answer: use PHP, hot reloading on file save üòÇ
Is this groq? I‚Äôm too lazy to register with the site to find out. 
Links your GitHub and pulls right through. Easy peasy
yes
You're right, it's a pretty standard way of packing LU matrices.
How is this different from the list monad or other combinatorial monads? The first example can be written q = do a &lt;- parents 2 n &lt;- children a guard (n /= a &amp;&amp; n /= 2) return (a, n) &amp;#x200B;
Okay I'm lost here then. What is it that I want? :D
Okay awesome! Thank you! Do you plan on being a mentor for this project?
I think you will find it improved now. There is a significant amount of distortion in the code boxes on the phone, but I can't do anything about that (for real; Google Sites is great and easy, but not very configurable).
Got ihaskell working. It was indeed fiddly! Nix and a lot of determination did the trick. Finally got one plot to display. Which was cool! I‚Äôll have more time Thursday to try to do something real. I‚Äôll report back then. It‚Äôll all be smoother for me if I build a bit of interface to Frames/Vinyl, where all my data gets loaded and manipulated. Thanks!
Oooh ... Can you write an existential quantifier (rather than a universal) in the list monad? If so you may have saved me a lot of work :)
I think the point is that type class search is not the ideal way to do this, and something more explicit is probably a better idea. `instance ClassA a =&gt; ClassB a where` means "There's a ClassB instance for any a, but when you use that instance you need to find a ClassA instance for a" and NOT "If there's a ClassA instance, I can provide a ClassB instance, for any a.". (And `class ClassA a =&gt; ClassB a where` actually bakes the ClassA dependency into the dictionary.) You *could* use an OVERLAPPABLE instance, and that may actually be the best approach. But, I would strongly encourage to just pass around the `ALens' a ServerConfig` (or similar) instead of using the `HasServerConfig a` constraint (after type class instance resolution, they are basically equivalent). It's easy to over-use type classes in Haskell (and implicits in Scala). They can results in really tight syntax but can be problematic in a number of ways.
Is there any reason why `[plutus| \(x::Int) -&gt; x+1 |]` wouldn't work, instead of `$$(PlutusTx.compile [|| \(x::Int) -&gt; x + 1 ||])`?
Oh, of course. Thanks!
If it didn't scale well on intels, it won't scale better on threadrippers either.
Wonderful! I‚Äôve used `file-embed` for embedding test data into functions shared between test suites, and was also surprised at how CPU-intensive (and slow) it was. Good to see this can be improved significantly.
If the problem with the `file-embed` approach is GHC's handling of large string literals, would it be possible to simply speed those up? That seems like a more elegant solution.
&gt; IMO this should be implemented on the Cabal level. Why? What are the advantages?
No need to rely on TH when it's just a static file you're embedding, for example.
Even if TH can't be used in all contexts, we could use the same argument to say "no need to rely on Cabal"
The thing is: it's not a string we are manipulating but a binary file. Any solution that embeds a binary file in a textual form in a source file (C, asm, Haskell, whatever) or in an AST (TH created primitive strings) will be slower than just including the file when we create the .o (it is just a raw copy from the embedded file to the object file). However, GHC could also fall back to this approach automatically for large strings to make them bypass some stages of the pipeline (code generator, etc.). One thing we can do is to make this approach "first class" in GHC by providing GHC API/TH API for it. This is Step 3 in https://ghc.haskell.org/trac/ghc/wiki/StaticData
I've added a [ticket](https://ghc.haskell.org/trac/ghc/ticket/16190) to track the idea of trying this technique to improve compile time of large string literals.
Avoiding TH is (mildly speaking) a more common concern IRL. Plus Cabal has more control over the linking process, so it can use platform-dependent logic like [invoking the resource compiler on Windows](https://docs.microsoft.com/en-us/windows/desktop/menurc/about-resource-files).
RemindMe! 2years
You can wrap any classical statement in double negation to make it true constructively, this is called Goedel-Gentzen translation or Glivenko's theorem.
Thx!
Recently, the Haskell code explorer was discussed: [https://www.reddit.com/r/haskell/comments/9layin/ann\_haskell\_code\_explorer\_tool\_that\_helps/](https://www.reddit.com/r/haskell/comments/9layin/ann_haskell_code_explorer_tool_that_helps/). But I don't think it supports a collapsing feature yet. Maybe something could be integrated there. The other possibility would be via editor plugins, for example haskell-ide-engine. But then I am not sure if the language-server-protocol is powerful enough to support such a feature. One other thing: In Haskell it might not be too useful if you look inside a definition of a library if you are just using the library. It might cloud the superficial understanding at first. For example if I am working with a certain abstraction (e.g. parser combinators), I might not be interested in the inner workings. I am relying on laws and maybe some complexity guarantees given in the documentation. This is the power of abstraction. However to study a code base, or want to replicate or modify the internals, the look inside would still be very useful. Maybe Smalltalk differs, since they use shallower or abstractions or are not relying on laws?
Maybe /u/deech could chime in. The talk was discussed here before: [https://www.reddit.com/r/haskell/comments/9x2is1/what\_fp\_can\_learn\_from\_smalltalk\_i\_aimed\_quite\_a/](https://www.reddit.com/r/haskell/comments/9x2is1/what_fp_can_learn_from_smalltalk_i_aimed_quite_a/)
Sure, we're going to be mentors for this project! So, if you want to contac us earlier, you can just write us to the email on to the GitHub: * https://github.com/kowainik
Wow groq uses Haskell. I'd totally apply if I lived in the US
I don't understand, what would be an example of a program using a universal quantifier?
I find this job soooo appealing as I am a C++ fanboy (its how I pay the bills) and super enthusiastic about Haskell, albeit an advanced beginner. Sadly I lives in the UK -- yeah, Brexit.
And thus list comprehensions? ```haskell q = [(a, n) | a &lt;- parents 2, n &lt;- children a, n /= a &amp;&amp; n /= 2] ```
You can't use tuples for this---tuples are typesafe, which means that a 2-tuple is a completely different thing than a 3-tuple. The compiler will not allow you to make a list that contains both 2- and 3-tuples, nor will it allow you to write a function that sometimes makes 2-tuples and sometimes makes 5-tuples. What you can do instead is to make a list of lists. Lists are distinct from tuples in that they can be any length they'd like to be :) 
Thank you, I see what you mean. I'm just not super sure how I'd make it so that it works for different values of N. That's mainly where I'm stuck
You can do it recursively. A four element permutation is all of the three element permutations appended to every individual element. The base case is zero length permutations which is the empty list.
For what you want, you're going to need a bit more than list comprehensions. Essentially what you want to do is take a value from a list `n` times and compile that result into a list. Understand that in a functional language, code is data. If I want to do something n times, I can create a list `n` elements long, and execute each element in the list in sequence. This is what the `sequence` function does for you. The first step is to create a list of `n` functions that we will run in order. To do this, we use the `replicate` function: ghci&gt; replicate 5 [0, 1] [[0,1],[0,1],[0,1],[0,1],[0,1]] ghci&gt; replicate 3 [1, 2, 3] [[1,2,3],[1,2,3],[1,2,3]] Now all we need to do is take one element from each of the lists and compile the results into a list. Luckily for us, the `sequence` function takes care of this for us, so we can define our function: ghci&gt; permute n list = sequence (replicate n list) ghci&gt; permute 3 [0, 1] [[0,0,0],[0,0,1],[0,1,0],[0,1,1],[1,0,0],[1,0,1],[1,1,0],[1,1,1]] Which can be more succinctly written as: ghci&gt; permute n = sequence . replicate n 
I had a very similar experience. I started out in Haskell and switched to Rust for the minecart problem (Day 13) after getting pretty burned out on mutable unboxed vectors of ints in ST from all the previous "simulation" challenges (I did a few from 2017 as well which had the same flavor). Tried Day 14 in Haskell again but never got the performance I wanted even with mutable ST vectors. Ran OK in Rust, but not a terribly educational experience. Up until Day 15 I'd been doing these like "morning crossword puzzles" spending about an hour before work; a couple of them took a second look later in the evening. Day 15 hit just when my wife and I had flown to a very nice tropical beach for vacation, and while I had my laptop I took a look at the rules and just groaned. The worst sort of imperative book-keeping exercise. So I didn't make it past Day 15, which is disappointing as I saw from previous year's archives there were often some little language interpreters and virtual machines among the later puzzles.
I saw that as well. But now I prefer spending my efforts on real and useful material. :)
The existential quantifier is "there exists". The universal one is "for all". I should also have asked you about nesting. Here's an example of a program that uses both: ``` Find all x such that (universal) there exists some y such that (existential) for all z (another universal) the predicate f(x,y,z) is true. ``` Also the package in the title will let you mix those with conjunctions and disjunctions arbitrarily, so things like this: ``` Find all x such that all of the following (conjunction): There exists some y such that at least one of the following (disjunction): For all z, the predicate f(x,y,z) holds. There exists some w such that the predicate g(x,y,z) holds. There exists some y' such that ... ``` 
&gt; That seems like a more elegant solution. Elegant in what sense? There is no need to put the file through the parser.
It does not involve the FFI or hacking the build system (any more than Template Haskell already is), but is done merely by strengthening facilities already in place. Further, it might also help other tools that generate Haskell and embed large string constants (doesn't e.g. Happy do that for its parser tables?).
Yes exactly what I had in mind. I'd love to see explorations in this space. Having language support for exhaustive construction seems like noise compared to solving the \*root\* problem.
Awesome! Thank you so much!
There should be a way to immediately step into this off of any GitHub page (like sourcegraph does for other languages). It would be extremely useful.
Very late reply, but the first two paragraphs under "FORMAL AND INFORMAL STRUCTURES" capture my thoughts on this pretty succinctly. &gt; Contrary to what we would like to believe, there is no such thing as a structureless group. As I said above (and elsewhere in this thread below), my belief is that we implicitly form these hierarchical structures of interaction in lieu of formalized structure, and that codifying the structure allows people to navigate it (hopefully) with fewer ills associated with poorly communicated intent and expectation. In this case of a Code of Conduct, by explicitly stating what acceptable conduct is for an individual interacting within a group, everyone comes to the table with the same expectations of interaction. That way someone who joins a community at `t = 0` doesn't have a significantly different view of acceptable behavior as someone who joins at `t = +2 years`, when perhaps the community has arrived at a new consensus as to what's acceptable in a way that's opaque to the newcomer.
Flatbuffer serialization support for Haskell would be great. Also a Produktion ready grpc implementation based in http2 would be welcome. Just a few ideas.
The way you manipulate the results of IO actions in haskell is typically by using &lt;$&gt; (fmap from functor), &lt;\*&gt; (apply from applicative) or &gt;&gt;= (bind from monad) to combine them with other functions and IO actions. [Do notation](https://en.wikibooks.org/wiki/Haskell/do_notation) is a special syntactic sugar that is often easier to use than these operators (and likely a good place to start (but it is important to understand that it does ultimately just desugar to them).
I think that, in retrospect, your point doesn't stand up to scrutiny. Steve Klabnik recently left Mozilla and the community reaction was certainly more negative towards Mozilla than it was to Steve. On the whole, their policies seem to set _exactly the right tone_ for minority advocacy given that they are getting a diverse group of contributors interested in (and contributing to) advanced systems programming and practical applications of programming language theory. --- From my perspective, the responses in these types of threads on r/Haskell recently have included a hell of a lot more gaslighting than anything I've observed in the Rust community to-date. - equating _asking others to be nice on the internet_ with an infringement against their right to expression - framing fostering growth of diversity is actually oppressive to the existing base of contributors - disregarding the damage of hurtful or offensive communication as and wishing that people would just "develop a thicker skin"
Please do. I‚Äôd be very interested in reading it. 
In that case, the thing to do is make your game logic pure and just pass the result of that roll in.
The linux kernel is changing (very slowly) it's API for time: https://lwn.net/SubscriberLink/776435/664f2f0b0b6fc9f5/ Presumably GHC and/or some libraries will need to be updated to use 64bit time.
These folks are really fantastic to work with. If you're in the market for a Haskell job in NYC, I definitely recommend applying.
How do I pass the internals of the io monad into a pure function?
I think you have it backwards. You don't want to pass IO around, you generate the random number in IO and pass it into your pure logic.
This is what I mean: gameLogic :: GameState -&gt; Int -&gt; GameState gameLogic oldState roll = ... -- produce the next game state main = do ... roll &lt;- randomRIO (1, 6) let newGameState = gameLogic oldGameState roll ...
Well I‚Äôm not sure you‚Äôre responding to my point, which was that [Mozilla uses the pretext of minority advocacy to cover for hostile business practice and abuse of their users](https://reddit.com/r/slatestarcodex/comments/98qwav/_/e4kf0ay/?context=1) and to silence anyone who tries to discuss this by having their Diverse employee make the announcement and conflating anger at the policy with bigotry. Frankly, that kind of horseshit makes me steam, and the fact that half of the people involved in Rust seem socially aloof enough to not see that sort of thing happening makes it even worse. For whatever reason, somehow the Haskell community manages to be quite the opposite with respect to the latter point. People here are pretty keen on reading between the lines, sniffing out trolls and hostile behavior, hypocrisy, and calling out exploitation of people who are too socially impaired or kind to push back against people taking advantage of them. Yes, we have people get angry sometimes (it‚Äôs honestly not that often‚Äîthere‚Äôs far more pontificating about ‚Äúthat one time so and so got angry and blew it‚Äù than there is incidences of people actually getting angry and blowing their top, but I digress), but to me that‚Äôs a sign of real-ness: we‚Äôre not all just pretending to be nice because there‚Äôs a gun pointed at our head saying be nice. So I don‚Äôt know man. If the Rust community makes you feel at home, then I‚Äôm happy for you‚Äîdifferent people like different things. But to me, everything there feels fake. I feel much safer here in the Haskell community.
Haskell code not scaling well to multiple cores is a Haskell software problem, changing your CPU to that of a different vendor which works byt the same principles will have no effect on it. Fixing it requires changes in https://gitlab.haskell.org/ghc/ghc and perhaps libraries, not on your mainboard.
Does this work though? I've tried variations on it and it seems like it tells me that Gamelogic doesn't take IO. Maybe I've been doing it wrong
Thanks! Sorry that I've forgotten to much of the context to make an interesting reply.
Yes. The memory architecture is a bit different, but again all CPUs of today are badly designed. And the question is if GHC could even benefit from a difference, because it depends on the compilers below it (eg C, assembler). Complete dissagree that it is only a Software problem. I believe building your on Hardware is key and comparably easy today. Then Hardware and Software (GHC), can go hand in hand. One can build Hardware especially suited to run GHC programs.
Yes, it works. When you write a do-block, it gets translated into a large expression made up of anonymous functions and a couple of operators. For example, this: do roll &lt;- randomRIO (1, 6) let newGameState = gameLogic oldGameState roll pure newGameState Gets translated into something like this: randomRIO (1, 6) &gt;&gt;= (\roll -&gt; let newGameState = gameLogic oldGameState roll in pure newGameState) The `(&gt;&gt;=)` operator has - in the context of IO - the following type: (&gt;&gt;=) :: IO a -&gt; (a -&gt; IO b) -&gt; IO b Here, `randomRIO (1, 6)` has type `IO Int`, and so `a` must be `Int`. Hence: (&gt;&gt;=) :: IO Int -&gt; (Int -&gt; IO b) -&gt; IO b The second argument to `(&gt;&gt;=)` is the function `(\roll -&gt; ...)`. Because the function is supposed to have type `Int -&gt; IO b`, we can infer that `roll` must have type `Int`. So the `&lt;-` arrow in the do-block allows us - by using the `(&gt;&gt;=)` operator - to use IO values as though they were normal values, but *only* if we promise that the result is still an IO value.
Well, I didn't try it (I'm at work) and sadly it's been a hot minute since I last worked with Haskell in earnest, but I'm pretty sure it works. You'd need to post your code for me to be able to see if/what you're doing wrong, but see this line? roll &lt;- randomRIO (1, 6) Notice how it's **not**: let roll = randomRIO (1, 6) The difference is that while the latter is just good a old fashioned binding, the former can be thought of (if you're thinking of do-notation as a kind of imperative programming language) as "pulling out" the value from the monad wrapper. It desugars to: randomRIO (1, 6) &gt;&gt;= (\roll -&gt; ...) In the IO monad the type signature for that funky operator is: (&gt;&gt;=) :: IO a -&gt; (a -&gt; m b) -&gt; m b so you can see how the right hand side gets access to the wrapped value.
Day 1: https://gitlab.com/roelofwobben/aoc2015/blob/master/Day1/src/Lib.hs#L45 this function can be simplified to `floorEnds = fmap last . convertToEither` https://gitlab.com/roelofwobben/aoc2015/blob/master/Day1/src/Lib.hs#L30 this function can remove a bit of duplication: ``` toParenList (x:xs) = f x &lt;*&gt; toParenList xs where f = \case '(' -&gt; Right (Open:) ')' -&gt; Right (Close:) _ -&gt; Left "input invalid" ``` Day 2: nothing to say here Day 3: https://gitlab.com/roelofwobben/aoc2015/blob/master/Day3/src/Lib.hs#L30 again, you can remove code duplication here: ``` parsePosition (Position x y, set) dir = let pos = Position (dx dir x) (dy dir y) in (pos, S.insert pos set) where dx East = +1 dx West = subtract 1 dx _ = id dy North = +1 dy South = subtract 1 dy _ = id ``` https://gitlab.com/roelofwobben/aoc2015/blob/master/Day3/src/Lib.hs#L37 foldl is bad for performance, always use foldl' from Data.Foldable Day 5: nothing to say
Thank you! That makes a lot of sense
Do you consider remote / contractor outside of the US ?
Yay! Incidentally, this also works for a lot of other types - any type that is an instance of the Monad typeclass. Examples are Maybe, List, Either, State, and many others. All the magic is in the definition of the `(&gt;&gt;=)` operator, which is different for each type. 
&gt; Complete dissagree that it is only a Software problem. But we _know_ key reasons why GHC Haskell scales badly, we _know_ it's a software shortcoming. One reason is stop-the-world garbage collection: If you have e.g. 40 GB resident memory (likely if you have 48 cores on a big system), then collecting once will take a few seconds, and that can result in all threads being stopped and doing nothing. Another reason is bad cache locality: If everything is represented as pointers to pointers to pointers, then cache locality will likely be bad and your CPU will wait on memory most of the time ([this talk](https://www.youtube.com/watch?v=rX0ItVEVjHc) shows quite nicely some of these aspects). There are many resources that talk about many of those issues. Some examples: * Bad scaling of GHC itself: https://trofi.github.io/posts/193-scaling-ghc-make.html and [#9221](https://ghc.haskell.org/trac/ghc/ticket/9221) * GHC's upcoming new concurrent GC: https://www.youtube.com/watch?v=7_ig6r2C-d4 * https://mazzo.li/posts/haskell-parallelizing.html Of course you can plan to design hardware that works around these software bugs, but it'll likely be much more effective to just work directly on the bugs. Modern CPUs can easily process 10-40 GB per second; if your application doesn't display that performance, there's likely something going wrong somewhere between app and down to (not including) hardware.
What do you mean? You have access to the result, just do whatever you want with it? I must not understand the question. Here's an example of me doing something different depending on the result. Is that the kind of thing you want? main :: IO () main = do result &lt;- randomRIO (1,6) case result of 1 -&gt; do putStrLn "doesn't count, try again!" main 6 -&gt; putStrLn "amazing!" _ -&gt; putStrLn $ "you rolled a " ++ show result
super cool! Looking forward to the result, I might even install ihaskell for the occasion :)
Yes, if it is legally possible and not too different in time zone. Or if your skills match exactly what we need.
Dumb question, but do you folks hire interns? I just started my masters in Math and am tracking towards a career change to CS after I'm done and have been interested in learning Haskell and functional programming in general.
Great write up. As someone who has used Dhall to drive configuration of a couple of small side projects, all of the quality of life changes mentioned in the post have been a huge improvement. I'd like to use Dhall for additional ops related projects, but the remaining annoyance is really the lack of first class map syntax. I understand the reasons for wanting to preserve the opaqueness of `Text` - but pretty much every other source or target configuration syntax relies heavily on `{ key1 = a, key2 = b, keyN = c, ... }` and in Dhall we end up with 'reserved' keys and special cases for deserialising associative lists such as `[{ key = "key1", val = a }, { key = "key2", val = b }, ...]` or similar. I honestly wouldn't be too heart broken if text did have some opaque (to the user) `Eq/Hashable` instance, or if the `{ key = val, ... }` syntax was desugared into an assocative list, etc.
We unfortunately do not at the moment, but certainly want to setup an internship program sometime in the future. There may be opportunities to collaborate on individual OSS projects and alike, however.
Ah well, it's my fault for not logging into reddit for a few months üòÖ
&gt; I am not sure if the language-server-protocol is powerful enough to support such a feature. IIRC, you can tunnel just about anything through LSP, so in principle it could be supported. Supporting it in a way that's not a special snowflake? No idea.
Right on! Thanks for the information and the quick reply. It's weird to be thinking about internships at 30, but I have to start somewhere. I'll keep an eye on your site and keep an eye out for any internship program news. Yeah, after I get a little more acquainted with Haskell I'm planning on trying my hand at doing some open source contributions if practical and course load permitting, then seeing where that leads. Any recommendations for important OSS projects you're aware of? Thanks!
That's cool, I just recently started to actually understand how the bind function works but was unsure how do-notation related to it and your example made it crystal clear, I appreciate it!
There's really quite a lot of OSS work happening in Haskell, you'd have no trouble finding something to your liking. I'd recommend picking an area of interest (web frameworks, FRP, etc.) and looking into what's out there. Searching reddit is actually a pretty good starting point - you'll run into useful announcements.
Vagif is a joy to work with, don't pass this opportunity up. 
This is really awesome. As someone who is really optimistic about Purescript it's so good to see real live Purescript project. One question on testing. I see there are no tests in the project. Do you feel that its less important now that you have a strongly typed Programming language? I mean that's how I feel with Haskell. Before with dynamic languages I felt I needed to do it mostly because of anything unexpected that could happen. So I wasn't really only testing the functionality I was more building a wall so I would be notified anytime in the build when it broke. Now I feel I rarely have to write them
Not: STW GC is only a performance issue for latency-sensitive applications. It isn't inherently bad. GHC iirc optimizes its GC for throughput and does a pretty good job. And I know the best throughput GC on the JVM is a parallel STW collector. So depending on your performance goals and workload, a STW collector could give you better results!
I was able to extend Dhall with generic Maps. No need for constraints within Dhall: Instead, I just assert that the Dhall AST (with extensions) is `Ord`. So you could even put Dhall functions in there as keys if you really want to (it just won't make sense). Here's some example usage (with a map from `UTCTime` to `Natural`): https://github.com/ramirez7/dalek/blob/master/test/Dalek/Exts/Map/TheSpec.hs `UTCTime` is also an extension. And this was all very experimental stuff and has drifted from Dhall HEAD. I didn't add map literals since Dhall's parser extension didn't make it possible. I didn't implement it, but it'd be easy to have `fromList` in there, which could be normalized pretty eagerly.
Yes, you don't need nearly the test suite you'd need in a fully-JavaScript frontend, but at work we do have some PureScript tests. We test the sorts of things that the compiler doesn't check: we'll do snapshot tests to make sure we don't inadvertently change the HTML rendered by a component, and integration tests, and that sort of thing. But most of the code base has little to no tests written for it and tends to Just Work. The only reason tests are omitted from Real World Halogen is that I didn't have the time after prioritizing writing + documenting the app. Plus the application is complete, so the only real source of future bugs (change!) is absent. I'd like to write some, though, especially tests that show off using a test monad instead of the application monad. It'll have to wait for another stretch of time when I've got the hours for it, though :)
I haven't actually read the original IOHK writeup! I took the term from Parson's blog and my understanding of it there, but I agree with you, the "cake" isn't as clear as it could be. In my application I only have monad stacks -- the application monad is `ReaderT Environment IO` -- but a simple ReaderT over IO is pretty thin as far as stacks go. So I might collapse the monads &amp; monad stacks layers together in a typical application I work on. The way I understand this is to have actual effectful code out at the edges (performs the request, etc), then a layer in the middle which represents this highly-effectful code but is pure and hides away the implementation details (capabilities), then a core layer which is just pure code. Not all of that pure code is 'business logic', so that's misleading, but the idea is simply to keep effects out of the equation. We might all have different interpretations of capabilities, the three layer cake, etc., which is why I agree it'd be better to have an agreed-upon idea of how to structure these applications and what terms to use to describe that.
totally, understood. This repository is extremely well documented and well structured. Thank you so much for your work!
Hey thanks! I appreciate it!
I'll say this, it would fit the bill for being simple ;)
If you're used to IDE's Visual studio code is great. It has a couple of Haskelll support extensions, mainly Language Server/Haskell IDE engine and Haskero. Haskelll IDE engine is still relatively young, and afaik theres no pre-built packagesso getting it working might be a bit overwhelming. However if you do, it's quite comprehensive. Haskero I think downloads the tools it needs when it boots, so should be seamless to get going with.
Ah brilliant I've used VSCode before. So would you recommend Haskero?
Thanks Armando, I remember you sharing `dalek` when we were both at Formation - it had just slipped my mind. Using `fromList` seems acceptable, although it'd be nice if the parser could be extended to provide map literals. I still feel this is something that merits addition to the standard as it's a recurring theme in a language targeting 'configuration'.
I'll throw out a straw proposal and let me know what you think of it: * Add first-class language support for homogeneous maps (let's say with hypothetical `{{` brackets, but could be any syntax) rather than using association lists with reserved field names * Provide a keyword to convert from a homogeneous record to a homogeneous map (i.e. `toMap` or whatever) * Treat homogeneous maps as opaque (i.e. they can be converted to JSON/YAML in the obvious way, but if you want to access a field you need to do so on the original record before conversion to the homogeneous map) The main thing I'm trying to avoid here is partial field lookup functions on the homogeneous map if a total field access on the original record is possible
VS Code with the Haskell Language Server extension is wonderful. The only requirement is that you need to manually install the haskell-ide-engine (HIE), which takes quite a bit of time. The instructions are clear though. Checkout the haskell/haskell-ide-engine github repository to see all the great features. 
ghci has a lot of commands
Thanks! I hope to add the tests soon!
Do you offer any opportunities for students who are about to graduate or recent grads? 
We also enjoy using Dhall configuration language! In our case, we use it to generate `.yaml` file with custom HLint rules for our own alternative prelude. Helps to remove **a lot** of boilerplate. See the following blog post for more details: * https://kowainik.github.io/posts/2018-09-09-dhall-to-hlint
Actually I'd say try to set up HIE first, since it's the most fully featured of the bunch, and still under heavy development, so only going to get better. **https://github.com/haskell/haskell-ide-engine/** Installing it basically comes down to cloning the repo and running one of the build scripts. It does take a while to build though. If you run into problems though, definitely give Haskero a try.
I found (the efficient) fulcrum really annoying to prove with Coq. But, as a novice, I am unsure if it is because of me, Coq, or the problem itself, but I was surprised it was so tricky. However, I feel this article falls short of addressing the initial problem Hillel Wayne sets : this is no evidence! While I feel that what is written is true, this might just be confirmation bias.
I've been interviewed by PieSync. They seemed to believe that haskell is not useful as a standalone language. I was asked several times if I thought any program can be written in haskell. They were also promoting it in tandem with go. As an experienced haskell I am convinced haskell is a great general purpose language. Of course there are constraints like in any garbage collected language, so it wouldn't work in an embedded environment with low memory, or hard realtime constraints. But otherwise, it's not only suited, IMO it's one of the best general purpose languages. I've had this discussion also with other experienced engineers (not haskellers), who believe that because of purity, doing side effects is at the best painful. My experience is that it is the opposite, the ability to isolate and structure effects, makes it much easier to create complex programs, and being more disciplined about state and side-effects, the program stucture becomes more clear.
It would be an option, but then we need to provide a custom Haskell parser etc. (Also remember all TH dependencies become dependencies of the final binary, *even if* they are only used at compile time. 
Thank you for the examples, they help a lot.
Is there a reason for the extra identifiers: * let in (indentation could be used instead) * &lt;&gt; around sum types * \ in lambda expressions The language feels overely syntactically cluttered. 
It's amusing how similar that `Tree` looks to the DOM API, where each node knows about both its parent and children. And perhaps the world would be a better place if like your package, the DOM API also did not support any update operations.
FFI is unsound by design, so the answer probably is ‚Äûto no degree‚Äú.
Personally I like vim. [Y](https://wiki.haskell.org/Vim)ou can make it do what you'd like with [scripts](https://github.com/eagletmt/neco-ghc).
Dhall is turning out to be a beautiful language. My biggest hope is that we can get general evaluation faster this year. I've been working on and off on \`dhallix\` (\`dhall\` + \`nix\`), which would be Dhall configuration of Nix derivations. Unfortunately, performance on Dhall's side makes this currently infeasible ([https://github.com/dhallix/nix-derivation/issues/8](https://github.com/dhallix/nix-derivation/issues/8)) - just evaluating the derivations to build GCC from an environment bootstrapped with \`busybox\` takes over 3 minutes. &amp;#x200B; My other plan for Dhall this year is to [dhallql](https://github.com/ocharles/dhallql) into some kind of usable state. I've got some rough ideas around this, but the idea of being able to send functions to the server feels like it could be absolutely killer. A big source of noise in my job is just building client/server interfaces, and having to find the sweetspot of a server that exposes the information I need without exposing so much that it grinds to a halt (and I throw all the information away on the client side). &amp;#x200B; Thanks to all the contributors for making Dhall what it is today - I think the future is bright!
This looks really cool, thanks for sharing. I might have a play around.
i found that most advanced solutions \[vim, emacs, vscode, atom\] require much learning or installation of \[unsafe\] binaries; i wasted a lot of my time trying these; hence instead at the end i settled with a very simple but surprisingly capable editor : "geany"; it syntax highlights, knows multiple line editing, can be configured to build on a shortcut, jumps on next error, remembers which files were open in the previous session, has rudimentary code completion; and it is very economical : packaged on all linux distros, needs only 50 MB to run with an empty file, launches instantly, everything works instantly without any delay
The `where` clause defines a new layout section, which is to be indented as much as the next following line. In this case, your `import`s are indented, so you would have to indent your `main` code as much. I suggest just removing the indentation before `import` (it's not necesasry or idiomatic): module Main where import Answer import System.Environment main :: IO () ...
I am not convinced this is a good idea for API design. While it may often seem clever and convenient, it often ends up as a massive headache later. Explicit is better than implicit.
They have different underlying implementations. From the documentation: &gt;The implementation is based on *big-endian patricia trees*. This data structure performs especially well on binary operations like [union](http://hackage.haskell.org/package/containers-0.6.0.1/docs/Data-IntMap-Strict.html#v:union) and [intersection](http://hackage.haskell.org/package/containers-0.6.0.1/docs/Data-IntMap-Strict.html#v:intersection). However, my benchmarks show that it is also (much) faster on insertions and deletions when compared to a generic size-balanced map implementation (see [Data.Map](http://hackage.haskell.org/package/containers-0.6.0.1/docs/Data-Map.html)). &amp;#x200B;
Ok I've got it building now. Thanks for all the help :)
Wow that's interesting. I've never really taken much notice of Geany before due to the more feature rich ides available for Java etc I'll go check it out!
Thought I would give you an update - HIE with the VSCode plugin is exactly what I was looking for - thank-you for the suggestion :)
`ghci` is a classy REPL. Neil Mitchell;s [`ghcid`](https://github.com/ndmitchell/ghcid) builds on `ghci` to provide (near) realtime feedback on your latest compiler run and tests. Low investment regarding installation/configuration, high pay-off.
The dafny proofs look really interesting. But I feel that this is in part because the language has built in support for integer arithmetic and array operations. If you try to do these proofs in Coq, Agda or Idris they become messy because you have to make all this reasoning explicit. Maybe LiquidHaskell can help here? This also means that there is a lot of room for improving the tools for proving functional programs, in terms of ergonomics and of having a nice standard library. I also wouldn't cal the dafny programs fully imperative. For example, the leftpad example produces a new sequence, it doesn't modify the input in place
No problems :) Enjoy learning Haskell, you won't regret it!
32 cores times 2 seconds is a minute of CPU time doing nothing. Of you can split your 32G residency problem into 32 1G problems and orchestrate 32 processes, you'll get more done in the same CPU time. But that's a workaround.
Atomicity of side effects would help here: have A output its side effects to a temporary location/file/etc., and do not move the output into its final location until after B completes successfully.
It's certainly possible, but we'd ask that you demonstrate an ability to produce meaningful code in Haskell. Often this is best achieved by pointing at any OSS work you may have done or toy projects in github/etc.
One session? Keep the focus tight, make sure you actually have time to get to some of the cool stuff. For example, one of the strengths of functional programming - especially in haskell - over imperative languages, is how easy it is to chain functions together in various way. So you could teach them: * The basic syntax for defining functions * Type signatures, with focus on function types * Partially applied functions - show them how it works out with the (-&gt;) type constructor being right-associative, while function application is left-associative * The (.) operator, with examples (chain some maps and filters, and have the functions you're mapping and filtering with also be composed from other functions - simple example: `foo = map (*2) . filter (not . even)`) Leave out custom types, explicit recursion, typeclasses, etc. Keep in mind that this is only an example - you could pick a different topic to focus on. My point is that if you only have one session, it's best to pick one thing and get far enough that they can actually see how it's cool and useful. A lot of FP techniques emerge from limitations that can be frustrating for someone who comes from imperative languages, *until* you get to the point where suddenly, thanks to those limitations, the code becomes incredibly concise and elegant. So make sure you have a chance of making it to that point.
Sorry it is actually a few sessions, anyway thanks for the advice ! 
I don't know the answer, because I've never used Turtle before and so I don't know the specifics of what you mean about prompts. But I will say that in general your solution shouldn't need to have a lot to do with Turtle, given that Shell has all the nice typeclasses defined. So if you can write the function for `[Line] -&gt; [[Line]] `, which I think is what you want, then you can use `fmap` to lift that into Shell. And, you should be able to use sequence(A) to turn `[Shell a] ` into `Shell [a] ` So really you're looking for spans in a list of strings, which no longer has to worry about Shell or Turtle and you can look through the list functions to see what tools you have available. Unless I'm misunderstanding. 
yes
Looking into Turtle a little more, it looks like `Shell a` is not a single `a`, but a stream of them, which makes your type definition make more sense. I don't think that changes my answer, but I'd have to look deeper to make sure. 
Could you give an example of a "headache" you have in mind? If HashMap was implemented using this strategy for keys and values, then I think it would mostly be a performance benefit.
Sure, but would that be expressive enough? The reason rust is good at memory management is not because it forces you to deallocate everything you have allocated before your function terminates, it's because its type system tracks the lifetime of your values and thus guarantees extra stuff about the memory which was allocated outside the function and deallocated inside, and about the memory which gets allocated inside the function and deallocated outside. Since Haskell doesn't support that kind of lifetime tracking, I doubt inline-rust even allows you to call rust snippets which make interesting uses of lifetimes, I bet you can only call rust functions which deallocate everything they allocate before returning to the Haskell code.
Can you give a minimal example of what you're trying to achieve? Since `Shell` contains no parallelism you can simple intercalate the names of the shells with `pure` (or prepend to every atomic `Shell` you use, whatever you consider as atomic).
In the general case, I don't think this is possible. In a simple case, imagine you have an microcontroller. It may take one move instruction to change the pins from a single gpio bus. If you need to change the values of two pins from separate buses, it may take two instructions. If power is interrupted in between, you may have a problem. Solutions could include: 1. Change the two pins to belong to the same bus, so they can change simultaneously. 2. Using pull-up or pull-down resistors so that if the microcontroller fails, there is a default value for each pin which is safe. 3. Using a battery backup etc. Note that there are no software solutions. In this case, this is a limitation of the hardware, so no amount of software wrangling will fix it. Generally speaking if you want power safe software, consider writing your programs so that every `IO` action can be performed safely individually. i.e. write you program so that `A` can be performed without catastrophe.
I like [this talk](https://www.youtube.com/watch?v=b9FagOVqxmI), which focuses more on high-level "what is Haskell good at/for" and gives people enough to wet their whistles without getting bogged down _learning_ it.
Dhall makes a point to not be indentation sensitive because it means whitespace becomes semantic. Making it far harder to have language bindings (which are very important to adoption. I remain convinced that php and JavaScript's super easy to/from json support did wonders for making json as prevalent as it is today) `&lt;&gt;` Is how type script does it and is a very familiar syntax. It also makes parsing much much easier. Plus it frees | to be used for more things later. Not sure what's inconvenient about the brackets? I'll admit to being slightly biased here. I'm not even sure how dhall would do lambdas without `\`. Would fat arrows like JavaScript or |x| like rust be preferable? Not sure how they would make the syntax less cluttered. My inkling here is that the syntax ends up feeling cluttered because of the type annotations everywhere. I don't mind it, obviously, but someone unused to it can certainly see it as overly verbose. I imagine that as bindings to popular projects become more comprehensive, we'll see more and more types wrapped up in convenient accessors and the type annotations will start to become a lot more helpful.
The only thing I can see making this not as useful to some is that homogeneous maps are pretty rare in json from what I can tell. Far more often you'll see a config file with `{ "foo": 1, "bar": "true", "baz": "always", "thing": [ "./dist", "src/**"] }` and so on. Unless I misunderstood what you meant by homogeneous? Perhaps an ability to "gradually type" things by being able to type a map as holding values of `&lt;Text, JSON&gt;` (for example) where the text values can be accessed directly and the rest are opaque JSON. As for partial field lookup functions, accessors for records of sums are already inherently partial; I forget whether dhall let's you write those or not...
The annoyance might stem from the fact than the output of the shell is consumed in a "push-based" manner, using a `FoldM`. "Group by"-like operations have a more "pull-based" flavor. I have a library called "streaming-eversion" that transforms `Stream`-consuming functions into `FoldM`s. These `Stream`s from the "streaming" package support `groupBy`. Perhaps the function `Streaming.Eversion.evertMIO` could help?
Wow there's a lot of haskell job! Haskell is finally mainstream!!!
This is something that needs to be taken care of above the application level. You need to engineer your tasks so that A and B are idempotent (e.g. Can be run more than once without trouble) then you can look at using systems which guarantee "at least once" semantics, like Google cloud pubsub or Kafka. Good luck!
 type family QuantK ob :: (ob -&gt; Type) -&gt; Type where {} type Quant = KindOf QuantK can be used for newtype Forall :: Quant where MkForall :: (forall xx. f xx) -&gt; Forall ob f data Exists :: Quant where MkExists :: f xx -&gt; Exists ob f universal :: Forall Type [] universal = MkForall [] existential :: Exists Type [] existential = MkExists "123"
 type family IndexedBy ob :: ob -&gt; Type where {} type Indexed = KindOf IndexedBy encodes kinds `type Indexed = (forall ob -&gt; ob -&gt; Type)`, before we could only express them as data ProxyOf ob :: ob -&gt; Type where .. data ProxyOf (ob :: Type) :: ob -&gt; Type where .. but now we can write data ProxyOf :: Indexed where MkProxyOf :: ProxyOf ob (a :: ob) type T = Type type TT = T -&gt; T data TypeRepOf :: Indexed where Rep_Int :: TypeRepOf T Int Rep_Bool :: TypeRepOf T Bool Rep_List :: TypeRepOf TT [] Rep_Maybe :: TypeRepOf TT Maybe
You definitely cannot do this for arbitrary IO actions, but you could define a more restricted type of computations which only allows you to express computations which take the necessary precautions. For example, you could define a bunch of actions which all have a corresponding anti-action which undoes the side-effects of the action, such that it is always safe to run the anti-action regardless of when the power cuts within the execution of the action, including before the action does anything. Anti-actions must therefore be idempotent. Also make sure that the output of each action is serializable. Now you can write a forward interpreter which writes the output of each action to the disk before moving on to the next action. If the power cuts, first run the backwards interpreter: skip over each action for which we have a recorded output, using that recorded output to continue the program, and once we reach an action for which we don't have the recorded output, run the anti-action for that step, and continue the program from there. As a bonus, if you change your mind about which program you meant to execute, you can also roll back all of your old actions all the way to the beginning and execute your new program instead!
From the [proposal](https://github.com/ghc-proposals/ghc-proposals/blob/master/proposals/0035-forall-arrow.rst#3effect-and-interactions) we allow higher-rank examples of this. So the following is a higher-rank kind data S :: Indexed -&gt; Type where AtTypeRepOf :: S TypeRepOf AtProxyOf :: S ProxyOf Consider [`(:==)`](https://github.com/ekmett/eq/blob/master/src/Data/Eq/Type/Hetero.hs#L73) (heterogeneous Leibniz equality, this is a crazy example don't worry) we can make the "context" visible newtype (:==) :: forall k k'. k -&gt; k' -&gt; Type where HRefl_ :: (forall (xxx::Indexed). xxx (k) a -&gt; xxx (k') b) -&gt; (a :== b) but we can also make the different kinds we witness equality of be visible newtype HEq k k' :: k -&gt; k' -&gt; Type where HRefl_ :: (forall (xxx::Indexed). xxx (k) a -&gt; xxx (k') b) -&gt; HEq k k' a b and we get type family HEqK k k' :: k -&gt; k' -&gt; Type where {} type HeteroKind = KindOf HEqK newtype HEq :: HeteroKind where HRefl :: (forall (xxx::Indexed). xxx (k) a -&gt; xxx (k') b) -&gt; HEq k k' a b
Reminder that &gt; type-level `forall`s don't float &amp; &gt; **GHC never infers a higher-rank type** (or kind) &gt; directly from [Richard Eisenberg](https://ghc.haskell.org/trac/ghc/ticket/13399#comment:6)
&gt; indented as much as the next following ~~line~~ token. FTFY 
Figured it out; need to write a custom fold over the shell \&gt; foldIO ghci (Fold.FoldM step beg end) :: FoldM m a b where \&gt; . -- m is a Monad \&gt; . step :: x -&gt; a -&gt; mx \&gt; . beg :: m x \&gt; . end :: x -&gt; m b can't seem to get it to
Just curios what are the benefits in using a vector instead of a list? 
In this case it was slightly simpler because the container widgets from gi-gtk-declarative used vectors, so I didn't have to convert from lists to vectors. Less important perhaps, the modification when toggling `completed` on a to-do item is O(1). `snoc` is still O(n).
[removed]
I believe the memory models of Haskell and Rust are compatible if we observe these rules: 1. Any value passed from Haskell to Rust is immutably borrowed from the Rust POV 2. Any value passed from Rust to Haskell also passes ownership from the Rust POV 3. Any call from Haskell to Rust is `unsafe` from the POV of the Haskell FFI This is a bit conservative. I'm not sure if there's a way to express in Rust the more relaxed rule that we can return to Haskell a value owned by Haskell. Everything in Haskell is immutable &amp; managed by the garbage collector. Rust is never allowed to mutate a value also referenced in Haskell. Rust is also not allowed to retain references to shared memory after an FFI call returns. Haskell is not allowed to move shared values during garbage collection. I believe the rules above are sufficient to fulfill these properties. In practice, any function that doesn't fit these rules can be made to fit with a wrapper that copies the input or output. 
Thanks! 
While a lot of work is going into it, haskell editor tooling is still extremely shaky. The state of the art for always works, 100% of the time works, doesn't stop working, is ghcid: https://github.com/ndmitchell/ghcid If the other fancier tools start to flake on you, you can at least fall back to ghcid.
I've been running a weekly lunch session at work to teach, learn, and share stories/projects around Haskell. It's mostly new people who have 0 experience with Haskell. We decided to work on a small-scope project of shared interest together and focused on practical things... getting the build tools, setting up the development environment, running tests, etc. I'd use every other session or two for background on theory -- monoid, functor, applicative, and then monad. Then we'd get right back to the practical work of writing a working program. It has been very instructive and had inspired at least one of my charges to write their own project in Haskell over the holidays.
Trying to install package \`Frames\`. Stack is using older dependencies (\`Vinyl 0.6\`) when I have newer one installed. How do I make stack do what I want
IHaskell wasn't so bad with Nix. But it was fiddly to add my local dependencies, though that might have been because I suck at Nix. Anyway, I'm taking your suggestion of a ghcid workflow to produce html. It's working nicely. I've built some beginnings of a Frames wrapper around hvega types, see [https://github.com/adamConnerSax/Frames-utils/blob/master/src/Frames/VegaLite.hs](https://github.com/adamConnerSax/Frames-utils/blob/master/src/Frames/VegaLite.hs) for more. Basically just allows translation of a frame row to a Vega-Lite row with minimal fuss. For an example of the resulting syntax, see [https://github.com/adamConnerSax/incarceration/blob/master/explore-data/colorado-joins.hs#L161](https://github.com/adamConnerSax/incarceration/blob/master/explore-data/colorado-joins.hs#L161) (which won't compile right now because I'm fighting with an Indexed Monad about my Html setup...) My only comment so far, related directly to hvega, is that it might be nice to make it harder to do the wrong thing. I'm not sure what exactly that means yet but I've managed to have code compile and run and produce no plot because I used faceting wrong or some such. It's be good to elevate some of that to type errors. But I haven't used it enough to see how that would happen yet. 
yes
According to Xavier Leroy, yes: "Claim : purely functional programming is the shortest path to writing and proving a program". The gap between proving left-pad/insertion sort and proving properties about an industrial size code base in a real programming language is so enormous that I'm pretty happy with making an appeal to authority. &amp;#x200B;
Stack doesn't use the global or user package database. All pakages are "installed" per-project. Add the dependencies to need to `extra-dependencies` (IIRC) in your stack.yaml file.
yes
Why does whitespace sensitivity make language bindings harder to implement? You could always just call \`groupByIndent\` on the raw code, and then work with it like before. Yes, using fat arrows without parentheses would be cleaner (\`x: X =&gt; foo\`) I don't really mind the explicit typing. Especially if it makes compile errors very clear.
&gt; The gap between proving left-pad/insertion sort and proving properties about an industrial size code base in a real programming language is so enormous that I'm pretty happy with making an appeal to authority. I admire Xavier Leroy too and I agree there is a big difference. That said, I would love to see numbers on how many formally verified LOC have been written in (say) SPARK vs Haskell (or Coq or F*). Unfortunately, many users of these are in aviation and defense so I don't see them making numbers available publicly anytime soon.
In general, lists also pollute the cache, whereas vectors are contiguous in memory. Hardly a performance bottleneck in this case though. :)
For compatibility with `echo`, perhaps something like this would (I haven't tested it though, only compiled it): import Turtle data GroupState x = GroupState ![Line] !x groupLines :: (Line -&gt; Bool) -&gt; Shell Line -&gt; Shell [Line] groupLines break (Shell f) = Shell (f . adapt) where adapt :: FoldShell [Line] r -&gt; FoldShell Line r adapt (FoldShell step0 start0 done0) = let step (GroupState ls x) line = if break line then do x' &lt;- step0 x (reverse ls) return (GroupState [] x') else do return (GroupState (line:ls) x) start = GroupState [] start0 done (GroupState ls x) = case ls of [] -&gt; done0 x ls -&gt; step0 x (reverse ls) &gt;&gt;= done0 in FoldShell step start done `adapt` is a function that transforms a `FoldShell` by wrapping it in another `FoldShell` that performs the grouping operation. The state of the new `FoldShell` is the state of the original one plus the list of accumulated lines, which is sent downstream when a breaking line is encountered. Defining these kinds of fold transformations (sometimes called "transducers") is less intuitive than transforming streams. I have a [library](http://hackage.haskell.org/package/streaming-eversion) for mapping transformations on pull-based streams into transformations on push-based folds, but it wasn't applicable here because of a particularity with `FoldShell`.
&gt; Why does whitespace sensitivity make language bindings harder to implement? Because it makes writing a parser for the language much less trivial. Most languages don't have some groupByIndent and when parsing files, you really don't want to have to do multiple passes over the file to figure out where everything should be (imagine a 6k+ LoC file. Making it as easy as possible to parse this in close to linear time should be a strong goal). It also makes it much harder to figure out if something is an error semantically, syntactically, or correct but misspelled or indented wrong. &gt; Yes, using fat arrows without parentheses would be cleaner What if the function takes multiple arguments? `a: A, b: B, c: C =&gt; foo` gets really really hairy to parse and figure out; not to mention it means you now have to support arbitrary backtracking. If we decide that `x =&gt; foo` is valid but `(a,b,c) =&gt; foo` is necessary for multi arg functions, now you're making the syntax of the language inconsistent and opening up the door to making it easier to create an ambiguous parsing situation in the future. Not to say that fat arrows are a terrible idea, but I find them unconvincing in a language where one of the main tenants is that the language should be very easy to parse (efficiently) and implement host bindings for.
&gt; Little useful Rust code is 100% safe Rust, and most useful Rust code performs C FFI calls to some C library Where are you basing that? I've seen plenty of libraries that are 100% safe Rust. Or do you mean that if safe rust calls a library function which contains unsafe code than that code becomes unsafe? In that case, Haskell is similarly unsafe as damn near everything in Haskell touches `unsafePerformIO` "at some point".
This is impossible in general. A trivial example would be A = launchTheMissiles However, there are a couple of practical options if you can restrict what your IOs are able to do: - Store all your mutable state in a database (ACID). - Make everything idempotent. It sounds simple, doesn't it? Unfortunately, while designing your own systems to be idempotent is *reasonable* (in terms of effort), in practice you'll usually have to interface with all sorts of external systems which *aren't* idempotent.
It's easy then to see that "atomicity" is just a theoretical abstraction: * any IO takes a finite amount of time T, * blackout may occur any time before T
I was about to ask why this was in `acme`, but the README has a great explanation that's worth reading in case anyone clicked right to the Haddocks first.
It's a bit of a quibble but it's a stretch to say that you *need* Iris's variety of separation logic to verify Rust/ST. 
Why not monad first then applicative?
Someone had to write software to make either of those options function. I get advising someone not to re-invent the wheel, but I feel that this comment as phrased feels like telling someone that only the mystics are capable of such a feat, and that us lowly plebs should not try, as such things are beyond our ken.
Yes. This isn't a computer science problem, it's just wearing computer science clothes. If Alice is trying to write down two chapters in a story, and they only get halfway through chapter 2 before someone shoots them in the face, Bob isn't going to write the same chapter 2 that Alice would have unless Alice can encode enough information about what Bob needs to write, precisely, before Alice gets shot. Bob may still finish the book in some way though. He can be smart enough to know that when Alice only wrote `Andy fa`, and then the rest of the page is just a blood splatter, that this is not enough information for him to accurately reconstruct that page, so he should start over. Maybe Alice wrote several draft copies of the book, or notes, and deposited them in safety deposit boxes that Bob has access to. Bob can go get those notes and have a clearer picture of what he needs to do to finish the book. The more information Alice stored about what they were going to write, the more accurate a picture Bob has of the final chapter. Perhaps this book is not a novel, and it is just a record of solving a particularly difficult math problem. In this case, Bob may yet write a book that would be exactly equivalent to Alice's original work, since there is a known set of concrete rules that can be applied to Alice's partial work. In summary, you can't get perfect redundancy on any process that gets interrupted midstream. Even if the process is completely idempotent based on the input, 'Alice' can 'get shot' in the middle of recording that input. There is always some measure of failure. But you can make something _resilient_ to failure by accurately and concretely recording historical state, and ensuring that the process responsible for resuming that state is capable of making sensible choices when it encounters partial input.
Note also that all `Monad`s are also `Functor`s, so, you can do: ``` fmap (gameLogic someState) (randomRIO (1,6)) ``` or ``` (gameLogic someState) &lt;$&gt; (randomRIO (1,6)) ``` and get a result of `IO GameState`. This works in much the same way and for exactly the same reasons that it would work if you used a type of `Maybe GameState`, and instead of `randomRIO` you just had a function that return `Nothing` for some inputs. Note also when you're doing this that IO is still lazy, like most stuff in Haskell, so if you're trying to cart the result of one random computation around to multiple places, you may accidentally end up freshly generating a new value in a ton of places. Don't feel bad if you get stumped on that one - it stumped me really hard! IRC is a great place to ask for help for that kind of thing (see the sidebar on this subreddit). 
)))))))nil)
So I am trying to convert a composite(composite-base/composite-opaleye) Db record to Haskell level record ```haskell getSomeData :: proc () -&gt; do routeForSchedule :: Int -&gt; Select (Record DbRoute) routeForSchedule i = limit 1 $ proc () -&gt; do route &lt;- selectTable routeTable -&lt; () terminal &lt;- selectTable terminalTable -&lt; () schedule &lt;- selectTable scheduleTable -&lt; () restrict -&lt; view pId route .== view pRoute schedule restrict -&lt; view pId schedule .== constant i restrict -&lt; view pId terminal .== view pTerminal route returnA -&lt; route runRouteForSchedule :: Connection -&gt; Int -&gt; IO [Route] runRouteForSchedule conn = fmap unwrap . runSelect conn . routeForSchedule where unwrap :: [Record DbRoute] -&gt; [Route] unwrap = toListOf (each . rsubset . _Unwrapping Route) ```
For 1, you additionally need to make sure that the Rust reference does not outlive the Haskell object. Otherwise, I think this analysis is spot on. `ForeignPtr`'s are also useful for Rust values now in Haskell land, because you can attach finalizers to them in Haskell land (which are bound to the Rust land `drop()` calls).
Reformatting for old reddit: withLensesAndProxies [d| type HName = "name" :-&gt; Text type PName = "name" :-&gt; Field PGText type PAge = "age :-&gt; Field PGInt4 type HAge = "age :-&gt; Int type PId = "id" :-&gt; Field PGInt4 |] type DbSomeOne = '[PId, PName, PAge] type SomeOne = '[HName, HAge] someTable :: Table (Record Someone) (Record Someone) someTable = Table "someTable" defaultRecTable getSomeData :: proc () -&gt; do data &lt;- selectTable someTable -&lt; () restrict -&lt; view pAge data .&lt;= 12 returnA -&lt; data runRouteForSchedule :: Connection -&gt; Int -&gt; IO [Record SomeOne] runRouteForSchedule conn = fmap unwrap . runSelect conn . routeForSchedule where unwrap :: [Record DbSomeOne -&gt; [SomeOne] unwrap = toListOf (each . rcast)
My point is that even though the program is doing nothing (or rather, it's solely performing GC), throughput can still be optimized (and is! As I mentioned specifically with Java. Same situation, same performance profile). If all you care about is throughput, maybe a 2s pause every so often is best if it still means over a long period you are more productive than a low-latency GC.
In a project of mine, I have lots of instance declarations like this: class Key (k :: Symbol) (t :: RBT Symbol Type) where type Value k t :: Type field :: Record f t -&gt; (f (Value k t) -&gt; Record f t, f (Value k t)) branch :: (Variant f t -&gt; Maybe (f (Value k t)), f (Value k t) -&gt; Variant f t) class KeyHelper (ordering :: Ordering) (k :: Symbol) (t :: RBT Symbol Type) where type Value' ordering k t :: Type field' :: Record f t -&gt; (f (Value' ordering k t) -&gt; Record f t, f (Value' ordering k t)) branch' :: (Variant f t -&gt; Maybe (f (Value' ordering k t)), f (Value' ordering k t) -&gt; Variant f t) instance (CmpSymbol k' k ~ ordering, KeyHelper ordering k (N color left k' v' right)) =&gt; Key k (N color left k' v' right) where type Value k (N color left k' v' right) = Value' (CmpSymbol k' k) k (N color left k' v' right) field = field' @ordering @k branch = branch' @ordering @k The `Key` typeclass delegates its functionality on `KeyHelper` and adds a "discriminator" argument of kind `Ordering`. This is a trick to avoid overlapping instances. The problem is that in the instance declaration I seem to be invoking `CmpSymbol k' k` in two places: in the preconditions and in the associated type family. For type families that are costly to compute, this might slow things down. Is there a way to avoid this duplication?
Whether a library is 100% safe Rust code is irrelevant if it has a dependency that uses unsafe Rust or C FFI.
Yes, pretty much. Just because one puts unsafe code or C FFI behind a library the code does not magically become safe. There is a paper that proves that iff you are able to prove that a Rust library (that might use unsafe or C FFI) safe, the Rust safety proves that safe Rust code using that library is safe.
What is a "formally verified LOC" though? The question I always ask is "formally verified with correct to what?" What is the spec? Absence of run-time errors? Some high level (functional) requirement? Another way of looking at this: every line of Haskell is proven type safe. You can express properties of comparable sophistication in the Haskell type system to what can be expressed in SPARK. So, why treat the SPARK proofs as special? I use Coq, Haskell, and FramaC professionally. If it were just about functional correctness, and not resources usage, I would *never* use imperative languages. Neither the productivity nor the assurance case for imperative verification is comparable to what is available in terms of everyday tools to functional programmers. Like, it isn't even close. For the record, I thought the original puzzle here was super wrong headed. The challenge is writing down the specs, not writing down the programs. Indeed, the simple functional programs which solve the first "leftpad" problem is *as good spec as one can reasonably come up with*. leftpad c s l | length s &gt;= l = s | otherwise = replicate (l - length s) c ++ s Okay, that isn't quite a formalization of the spec, since "do nothing" isn't a functional description. But, yeah, that is the spec, and the program. Okay, maybe not 100% the spec. The subtraction isn't in the english spec as written. So, we should probably prove that...but, is this really a good job turning that tweet into math? method LeftPad(c: char, n: int, s: seq&lt;char&gt;) returns (v: seq&lt;char&gt;) ensures |v| == max(n, |s|) ensures forall i :: 0 &lt;= i &lt; n - |s| ==&gt; v[i] == c ensures forall i :: 0 &lt;= i &lt; |s| ==&gt; v[max(n - |s|, 0)+i] == s[i] the first two are nice enough, but the third is a pretty awful way of expressing that it is `padstring ++ inputstring`, and it is not at all obvious that it is correct. The second problem "Unique" is slightly more interesting, but it is still most of the work to express the statement of correctness. Indeed, given a literal interpretation of the tweet, the identity function satisfies the requirement (since it returns the "unique elements"...it just might return them multiple times). The Dafny code is not particularly compelling, as its answer to this is ensures forall i, j :: 0 &lt;= i &lt; j &lt; |b| ==&gt; b[i] != b[j] but what does that mean? How do I know *that* captures the right thing? How do I know it doesn't have an off by one error? In Coq, I would instead probably say Fixpoint all_different (ls : list T) := match ls with | nil =&gt; True | (x :: xs) =&gt; ~ In x xs /\ all_different xs end. which is much clearer, IMO. Although, admittedly, less verbose. Of course, I *could* write the definition used in the Dafny forall b n n', n &lt; length ls -&gt; n' &lt; length ls -&gt; n &lt;&gt; n' -&gt; nth n ls b &lt;&gt; nth n' ls b except that is actually wrong. I said why earlier, but I leave it as an exercise. In any case, the actual implementation is at least as nice in coq as it is in Dafny. Proof might be a little longer, but that has more to do with the example being in Dafny's sweet spot w.r.t automation. OTOH, the last example, fulcrum, is a loser for functional based verification. And the part that makes it so is that it is the part about resource usage.
Thank you for these worked out examples. The video is a great companion too. I usually prefer a document to scan through and copy examples from; but, the video is concise, motivated, and short (just like the post). Awesome! It's inspired me to play around more with this library for personal projects. BTW, I think this line \`todos = map toggleComplete (todos s)\` in the last code block should be \`todos = mapAt i toggleCompleted (todos s)\`. I look forward to the upcoming examples too. Thanks!
What‚Äòs `ob`?
It's a type variable / kind variable. He's calling it `ob` because he's thinking of objects of a category.
Ah, now I get it!
&gt; The Dhall wiki contains several useful educational resources for learning the language. The organization of the wiki closely follows the guidelines from this handy post on writing documentation: &gt; &gt; What nobody tells you about documentation That link (http://www.haskellforall.com/2019/01/What%20nobody%20tells%20you%20about%20documentation) is 404.
The kind of `ob` is `Type`, `ob` can equal `Type` (`Type :: Type`) but it can also equal `Type -&gt; Type :: Type`
The broccoli example is brilliant [https://youtu.be/8TD-20Mb\_7M?t=3188](https://youtu.be/8TD-20Mb_7M?t=3188)
I can understand that viewpoint but I'm not sure I would dismiss the benefits of rust just because an FFI is invoked. "Unsafe" in Rust and Haskell simply mean that "this code is not checked by the compiler to uphold the invariants the language takes for granted"; often you're still in a better position to write more correct code than if you wrote that unsafe portion in C. By pushing the unsafe code down as far as possible, you minimize your attack vector greatly. Now, FFI between Haskell and rust will always be complicated because they're very different languages and have to communicate through the least common denominator of C, which means very little useful information can make it across the barrier. And of course, as you alluded to, just because something is written in Rust or Haskell doesn't mean it's perfect and without flaw; something important for us all to keep in mind, especially when advocating their benefits. That being said, due to the nature of rust, I would expect for most projects using the FFI that, even with the additional complexity, the amount of unsafe code actually decreases when using Rust in the FFI code since the big risks are now only the barrier glue code + any unsafe Rust code + any unsafe Haskell code instead of the barrier glue code + (every single line of FFI code) + any unsafe Haskell. In general, I would consider "safe rust" at very much the same general level of safety as "safe Haskell", so if the FFI was used with only safe rust and the project was entirely in safe Haskell, you could reasonably assume to narrow "suspect code" down to just the FFI glue code; definitely an improvement to me. I guess what I'm getting at is that I see "pushing the problem down" as a strict win, just like I see "eliminating side effects from 90% of the code so I only worry about it at the edges of my system" as a strict win :)
`(~&gt;|)` is not the best to indicate visibility, any ideas? Visibility doesn't apply to `(-&gt;)` so there's no need for `(-&gt;|)`, we could even adapt `(~&gt;.) to mean visibility for polymorphic functions even if Linear Haskell takes `(-&gt;.)` ah who cares
The [README checklist](https://github.com/ddbeck/readme-checklist) mentioned in the talk, for writing a README file
Those two statements don't prevent atomicity. Atomicity is that you see *either* the old state *or* the new state and *never* see some in-between state. So, even though writing 1 byte to the SDD does take a finite amount of time, as long as when power is restored you still see either the old byte or the new byte the I/O was still atomic.
It's not failing on `{` _or_ `}`; It's actually failing on `{-1}` because the `{-` bit looks like the start of a comment to the haskell parser. Just write it as `{ -1}` and it should work.
awesome:).. thanks so much
The issue I see with that is that Haskell has a notion of true generativity. Namely two identical source files in different libraries are not in the same if they declare any types or typeclass instances. I don‚Äôt know how you expect two different imports to the same url (or worse, two URLs that aren‚Äôt identical but that resolve to the same endpoint and content). Also how do you expect imports inside the downloaded file to work?
Does this sort of source splicing exist in any other languages/environments/tools/emacs?
Hmm, that's more challenging than it looks! You might be able to use [stuck type expressions](http://gelisam.blogspot.com/2017/11/computing-with-impossible-types.html) to prevent ghc from evaluating your onTrue and onFalse expressions, but I'm not sure how to get them unstuck afterwards...
Personally, I would figure out how to avoid the non-termination. I type checking to be decidable.
It sounds like neat work. I would encourage candidates to do their research, think about their priorities, and (esp in this labor market) take the opportunity to practice vigorously negotiating their salary.
What's up with all these Haskell jobs this week. (BTW hi /u/chessai ^^ )
Very nice! Once more, great job Oskar!
I can vouch that anyone will learn a lot working with the Layer 3 team. They are great guys. 
What is your GitHub username?
Yeah, I was thinking that when I posted.
I am about to graduate as an undergrad in Computer Science. Are there any position for students like us? 
You could try defunctionalizaton instead -- the right-hand side doesn't really matter, as long as it ends in `Type` and mentions `a` and `b` type a &gt;-&gt; b = (b -&gt; Type) -&gt; a -&gt; Type type family ($) (f :: a &gt;-&gt; b) (x :: a) :: b data BOOL :: (() &gt;-&gt; k) -&gt; (() &gt;-&gt; k) -&gt; (Bool &gt;-&gt; k) type instance (BOOL f _) $ 'False = f $ () type instance (BOOL _ t) $ 'True = f $ () 
Of course! It's an internship position. 
Sorry for the confusion. I was looking for a full time position as my graduation is in May 2019. 
It's certainly something we can look into. Doesn't hurt to send me a resume at dcartwright@layer3com.com. Thanks!
Ok. Thank you. 
Guys, wait, this is big news - Did you know that 'difficulty' is SUBJECTIVE?
Note: This requires SharedArrayBuffer to be enabled in your browser. More info here: https://webghc.github.io/2019/01/18/state-of-webghc-january-2019.html
Thanks for posting an update - I was actually wondering about how it was going the other day! Nothing more to add outside of that I'm excited to see where this heads :)
I doubt this will be useful to you, but I know people use laziness at the *Scala* type level programming via the `Lazy` type from `shapeless` https://static.javadoc.io/com.chuusai/shapeless_2.12/2.3.2/shapeless/Lazy.html
I'm trying to learn profiling and can't figure out whats going on here. Can someone help me out? Source: [Day14b.hs](https://github.com/cjay/adventOfCode2018/blob/master/src/Day14b.hs), [Profile](https://gist.github.com/cjay/08e0d82df71fa2b65cd5ab0d4bad223f). Theoretically fastIndexBoxed should be faster than naiveIndex, but it isn't. The profiler output indicates that fastIndexBoxed takes 21.3% time, and I couldn't figure out which subexpression is causing that. Manual SCC annotations didn't give more info. The State monad ops seem to take no significant time at all, they don't seem to be the problem. Btw, fastIndex is a bit faster than fastIndexBoxed, but with profiling on it's the other way around. Runtime reported in the profile seems to be very inaccurate. Btw 2, the mutable-vector variant I wrote first is here [Day14.hs](https://github.com/cjay/adventOfCode2018/blob/master/src/Day14.hs). It's faster by roughly a factor of 4 or 5.
I appreciate the update, thanks!
&gt; who knows, maybe I can help even. Talk to /u/angerman :) He's currently experimenting with TH support. The difficulty comes from the way that GHC usually dynamically loads code to run TH, which is much less trivial on WebAssembly. Sounds like Mortiz has a pretty good plan though.
Thank you! I'm glad you enjoy the formats and found inspiration from it. The snippet is corrected now, thanks for reporting.
This is really exciting! Fantastic work! &amp;#x200B; Perhaps this is a good time to remind us how WebGHC and [Asterius](https://www.tweag.io/posts/2018-12-20-asterius-todomvc.html) differ?
There are many good ideas and tips in this talk. Well worth a watch for any type of technical writing, not only Haskell documentation.
When will rust allow following code : \`collection.set(key, collection.get(key) + foo)\` ? Right now it raises an error with mutable and immutable on one line...
I don‚Äôt argue that interfacing with Rust or other languages adds value, it does. But they question is whether it adds memory safety. Memory safety is a provable program property and it has to be provable to be useful. The whole point of C FFI, independently of which language one interfaces with, is to do things that can‚Äôt be proved. So my point is that one cannot obtain or maintain memory safety by using C FFI. That applies to both Rust and Haskell. For Rust there is a proof that states that if you prove that the C FFI code is memory safe, then safe Rust that uses it is also memory safe. But that‚Äôs it.
Still, I do not think that the implementation of indentation based `let in` (with globally fixed number of spaces for one block) would be more than minor inconvenience when creating new language binding. Also last time I checked, dhall had only single argument functions, so it would be `a =&gt; b =&gt; c =&gt; foo`, which is easy to parse again. Another option could be the use of `\` and `Œª` with new line: ``` Œªa Œªb Œªc foo ```
Is this supposed to work on my (chrome) android phone? I tried and I just have a white screen.
White screen...
The compatibility table of SharedArrayBuffer isn‚Äôt too good. Is there no other way to emulate the needed feature?
Aren‚Äôt arrays spineless? So isn‚Äôt a vector immutable, spineless container?
The code is 7MB and takes &gt;40 seconds to load on fast 3G üòÇ‚Ä¶ for a todo app, which makes you wonder how big an app of average complexity would be.
Since the page is blank on my iPhone, color me unimpressed. 
It takes about 6 seconds on my MacBookPro to show anything. Any idea what that delay is? In the network tab, I can see that it downloads the 7MB in 1s, so I don't think it's due to downloading.
I don‚Äôt know how you expect two different imports to the same url (or worse, two URLs that aren‚Äôt identical but that resolve to the same endpoint and content). I think that there are the same problems than happens importing from a disk file. In which way are they different? only in that the check for matching between file name-path with the module name inside the file should not be applied. Also how do you expect imports inside the downloaded file to work? By recursively calling the same mechanism as is used now with files. If you think about it, it is like adding the internet protocols (http:, ftp: ipfs: perhaps in the future) for retrieving files, besides the "file:" protocol
&gt; Note that SharedArrayBuffer was disabled by default in all major browsers on 5 January, 2018 in response to Spectre. Chrome re-enabled it in v67 on platforms where its site-isolation feature is enabled to protect against Spectre-style vulnerabilities. source: [MDN](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/SharedArrayBuffer)
Recommended action: try adding the following to your `extra-deps` in `/home/stephan/.stack/script/nightly-2019-01-15/config.yaml:` derive-monoid-0.0.1@sha256:4a8abdf346820d6cc7c966a572fa5ccac7a623ac737cbab93ebf386f3a25c779
I did that, same error. what you tried that solution?
The type level evaluation order is unspecified, so it‚Äôs best avoid defining your own control structure functions, like IfThenElse. It does involve some, often ugly, rewrites. 
i've met halogen couple of months back and i've built the frontend for my new side project with halogen. i love the safety it brings. i've got a long way to go with haskell and purescript though.
Hi. I have a problem since s-cargot is not available in stack nightly. Could you add it? 
That's pretty odd. What browser do you use? For me on Firefox, the download is almost all of the load time
Please see my other comment: https://reddit.com/r/haskell/comments/ahhmtn/this_page_is_rendered_by_reflexdom_compiled_via/eeel6ck
Please see my other comment: https://reddit.com/r/haskell/comments/ahhmtn/this_page_is_rendered_by_reflexdom_compiled_via/eeel6ck
I'd assume most of that is the runtime, so a simple hello world wouldn't take that much less, and a complex app wouldn't take that much more than that (at least compared to one using $JS_FRAMEWORK)
Please see my other comment: https://reddit.com/r/haskell/comments/ahhmtn/this_page_is_rendered_by_reflexdom_compiled_via/eeel6ck
Yea codesize is one of my top priorities for WebGHC going forward. As I said in the article linked elsewhere in this thread, it's about an order of magnitude worse than I'd like after shrinking (though surprisingly close to GHCJS before shrinking). We've got some plans to fix this though.
[removed]
Unfortunately not. The RTS relies on blocking to function, and this is the only way to do that and wait for data from the main thread. We'd have I rewrite a lot of the RTS if we wanted to not rely on SharedArrayBuffer; which is certainly a possibility if it doesn't get re-enabled in the future. But WebGHC won't be in a production ready state for a good while, so I don't mind relying on this experimental feature until WebGHC is no longer considered experimental. By that point hopefully it will be re-enabled, or else we'll have to look into that RTS change.
Ah ok, this is better than expected. So you think in theorey this could be solved, but sharedarraybuffer is just the current solution?
Basically, yea. I'd much rather stick to SharedArrayBuffer, so hopefully it gets widespread re-enabling in the next year or so. But if that fails, I still think we can work with it.
Yes. It‚Äôs better to have the CV communicate that you‚Äôre a programming polyglot, if in fact you are, than pass the idea that you‚Äôre a specific language developer. It‚Äôs also good to highlight the amount of experience with the different languages. Having Haskell and Common Lisp, is specially useful if you‚Äôre looking to find a job doing FP, even if it ends up being Scala or Clojure.
Just out of interest...SharedArrayBuffer is a JavaScript API, isn‚Äôt it? So you need to cross the WS/JS border for every blocking call?
The difference between hello world and reflex-todomvc is about 300%. Hello world is a 3M binary, and reflex-dom is 8.8M. Of course this is all before shrinking. I'd wager a typical large webapp would probably be 15M or less right now (before shrinking), but that's just an estimation.
Yes but that's better than crossing the userspace &lt;-&gt; kernel border for every blocking call on Linux, so I don't consider this a limitation. Plus the WebAssembly proposal for threading includes a way to bring these routines into pure wasm, so at that point we won't need to cross that border anymore.
1. nix for dependencies 2. emacs with dante for editing 3. ghcid for immediate feedback 4. hg/git for source control 5. buildkite for ci/deployment 
Maybe this might help? [https://blog.poisson.chat/posts/2018-08-06-one-type-family.html](https://blog.poisson.chat/posts/2018-08-06-one-type-family.html)
The answer to "Is _X_ good for my resume?" Is always yes/no/maybe. It's essentially a meaningless question because it depends on who you're sending the resume to. Resumes will be seen by HR and interviewers and what they think is a good idea to put on a resume doesn't necessarily match up with what anyone else thinks is a good idea to put on a resume. Spend some time researching the culture of the company you're applying to if you're unsure. In this specific case: It's not likely to hurt, however unless the position had something specific to do with either of these I'd recommend not putting it into a prominent position. Speaking as someone who's been involved in a couple of interviews I'd prefer if the resume was to the point - i.e. if you just list a bunch of technologies that doesn't tell me a whole of useful information. I might quiz you about something on the list if it looks interesting to me, but most of the time I'd just skip over that. Emphasise things you have _significant_ experience in that you can back up when asked about it in an interview. That being said, you likely won't have much concrete stuff to put on a resume straight out of uni, so you can probably keep it in without it becoming too cluttered.
- stack - spacemacs + haskelly-layer (was using intero earlier) - ghcid - git - gitlab CI with a gitlab-runner running on a dedicated Hetzner server with a bunch of custom code to build our app-specific Docker containers, etc.
Yes they are. I even mention that fact in the [Circular](https://github.com/gelisam/acme-circular-containers#circular) section of the README.
Ah, that makes sense!
1. nix for dependencies 2. yi for editing 3. ghcid for immediate feedback 4. cabal (new-build and new-repl) for building during dev 5. git for source control 
I'm case it wouldn't get re-enabled, couldn't blocking be emulated under the RTS level e.g. with callbacks? Therefore making it possible to completely avoid having to change RTS code?
I use vim, ghcid, and grep. I'm not too unhappy with the "grep" part, I tried spacemacs+intero and it's great when it works, but it doesn't work reliably-enough for me, so I am currently contemplating [Haskell Code Explorer](https://github.com/alexwl/haskell-code-explorer). My colleagues use a variety of different tools, including neovim, TextMate, Emacs, Spacemacs, Visual Studio Code, ripgrep, Intero, and Haskell Code Explorer. We all use stack (because our codebase doesn't contain the version bounds which would be required to use cabal), Jenkins, and Kubernetes.
Use single quotes: https://www.haskell.org/haddock/doc/html/ch03s08.html#idm140354810770608
By the way, you can indent your entire code block by four spaces instead of wrapping each line with backticks. it will look like this
Thanks
&gt; I found the solution my self: It seems to better use cabal for now and don't use stack. &gt; The typo above is that the following is correct "--package s-cargot". But "s-cargot" is not in nightly. But stack script has no means whatsoever to use "s-cargot" then, because it is not in stack and stack script disallows the use of "extra-deps". While I think using cabal is also a fine solution, I don't think it is correct to say that `stack script` doesn't support your packages such as `s-cargot` which are not in stackage. Rather, `stack script` doesn't support `extra-deps`. You can, however, create a custom snapshot which includes `s-cargot` in its `packages` section (rather than in the `extra-deps` of a `stack.yaml` file): $ cat Example.hs #!/usr/bin/env stack {- stack script --resolver my-snapshot.yaml --package s-cargot -} module Parser where import Data.SCargot main = do putStrLn "hello" $ cat my-snapshot.yaml name: my-snapshot resolver: nightly-2019-01-15 packages: - s-cargot-0.1.4.0 $ ./Example.hs hello 
If the typecodes are more or less constant, I'd go with the first version, as that would encode your format more directly as a type. Alternatively, you could go with `TypeFamilies`, `TypeApplications` and `ScopedTypeVariables`: data Block a = Block (BlockContents a) class BlockType a where typeCode :: Word8 -- or use Data.Proxy if you don't want to use TypeApplications type BlockContents a data Type0 instance BlockType Type0 typeCode = 0 type BlockContents Type0 = Word32 data Type1 instance BlockType Type1 typeCode = 1 type BlockContents Type0 = [Int] data SomeBlock = B0 Type0 | B1 Type1 getBlock :: (Binary (BlockContents a)) =&gt; Get (Block a) getBlock = lookAhead $ do c &lt;- get when (c /= typeCode @a) mzero contents &lt;- get pure $ Block contents getSomeBlock :: Get SomeBlock getSomeBlock = T0 &lt;$&gt; getBlock &lt;|&gt; T1 &lt;$&gt; getBlock Code not checked for compilation; should be close. You might want TH to avoid this verbosity, but I think this is fine for a few type codes.
Same delay on my macOS 10.13.1 (High Sierra) with Chrome 71.0.3578.98
* Nix + cabal new-build for package management and builds * Gitlab for CI running on our own machines (dramatically better than Travis/Circle/etc) * Spacemacs + ghcid for editing and development * Ripgrep for code search...a big improvement over grep/ack/ag
At Capital Match - * nix for deployment * cabal new-build * emacs/dante for me (previously vscode), and emacs/CIDER for the clojurescript frontend, another colleague uses gvim, the other intellij * git on Bitbucket * Jenkins for CI * Trello for task organisation * Slack and WhatsApp for comms
stack. atom with ide-haskell. I used to use ghc-mod, but I needed to move to the latest GHC version, which it didn't support. Also as my source code grew it was becoming unusably slow. bash for miscellaneous scripting. Inno Setup for creating Windows installers.
Would [jenga](http://hackage.haskell.org/package/jenga) help with the version bounds issue?
It's good to have it, if you can talk well about it. What you want to avoid is saying or implying you are proficient in language X and then having an interviewer dig in, only to find you aren't. Sometimes people list their proficiencies and familiarites separately to avoid this. Good luck in school and in your career! 
Ah, I see. Thanks for the clarification! Yes, you're right about the memory safety for sure. I think I got tripped up when responding when you mentioned safe rust instead of upholding memory safety constraints; I see where you were going with that now :) It would be fascinating if there was an equivalent proof for Haskell (is there one at all, even for non FFI Haskell?), then using memory safe rust (ie safe rust + proven C FFI) would be much easier to show that the entire pipeline was sound.
I value tools that enable productive workflows over the medium to long term. I know I have the right tool when things break - how quickly can I get the job done. The following ‚Äújust-work‚Äù when something goes wrong (updates, etc), Vim (in tmux) with - hdevtools or ghc-mod used with ALE - guttentags for jumping to definitions - hscope (optional) or grep to find ‚Äúwhat uses x‚Äù - stack (hands down a better choice for us) - great at managing project-specific builds, including my dev-related installs (e.g., hdevtools) Notes 1. We have dependencies both inside and outside of the stackage repositories. 2. My not including nix is not a comment regarding the tool. We have thus far not required more than what I have described. Way back I started with ‚Äòhaskell-vim-now‚Äô. Relics of that experience likely still exist. I consider it a solid, well documented starting point. Check out the authors in depth videos on how to use these tools including the use tags and hscope. - E
Not really. The RTS makes system calls that it expects to block and return some data. Making those system calls behave asynchronously would require changing the RTS to use them as such
I have some janky vim support for working with tags---it might help over just using grep. nnoremap &lt;leader&gt;st :! (cd `git rev-parse --show-toplevel`; hasktags **/*.hs)&lt;CR&gt;:set tags=&lt;C-R&gt;=system("git rev-parse --show-toplevel")&lt;CR&gt;&lt;BS&gt;/ctags&lt;CR&gt; Runs `hasktags` in the root of the git repo and then sets vim's tag file to the generated `ctags` file. Works pretty well!
The spacemacs haskell layer is still using intero though? 
I use stack/hpack and Neovim. For quick feedback I use a python script [1] that wraps ghci and act on command sent from neovim (for ex to run the :reload command on file save), and also controls neovim (to set status bar color to indicate a compile error or to open a error location in neovim etc). [2] is a screen recording of this script in action on source code of 'Stack' tool. I use RipGrep [4] for searching code from neovim and use a tool called fzf [3] with vim plugin for quick file navigation from within the editor itself. [1] https://github.com/sras/ghci-remote [2] https://youtu.be/cwUzDjgaI1c [3] https://github.com/junegunn/fzf [4] https://github.com/BurntSushi/ripgrep
Well, it's not really an issue for me as I have learned to appreciate stack, but thanks for the link, looks like a useful project.
I think the key thing you are missing is that Haskell‚Äôs imports aren‚Äôt really ‚Äúfile based‚Äù, they are package + module based. It‚Äôs cabal / some package manager‚Äôs job to figure out exactly what the contents of that module is. Currently two modules are considered to be ‚Äúthe same module‚Äù is they have the same module name AND they are from the same package. So if you wanted this import from url thing you‚Äôd need to define exactly what it means for two URL imports packages/modules to be the same. It would probably be easier to instead allow for URL based package imports in the cabal file. How would you recursively call a simple `import Foo.Bar` for some random web file download at some URL? Would it go back to searching for it locally. And again I must emphasize that you really shouldn‚Äôt think of current Haskell as using anything remotely like `file:`.
$15/hour is not attractive for skilled Haskell programmer. I suggest minimum of $22/hour. 
What a pointless comment.
So awesome to hear everything progressing forward! :) I‚Äôm so happy that people are working on this, and excited to see the outcomes of both WebGHC and Asterius. I imagine the learnings from both approaches, with the different constraints and goals, will provide lots of valuable learnings for the whole of the community! Great work guys!
That's sick, loving the purity of a blank page. Don't ever `unsafePerformIO` to spoil the perfection.
stack, ghcid (on and off), vim. I use ack a lot... :/ Jenkins + GitHub/gitlab for CI.
Thanks! And thanks for your work on WebGHC. 
Regarding your comment on advanced optimizations failing for miso project builds, Advanced optimizations perform variable renaming which currently break miso‚Äôs external js. This can be overcome by accessing variables using string notation so they won‚Äôt be renamed. (i.e. o[‚Äòhey‚Äô]). Compiling with -DEDUPE and regular optimizations are currently bringing the size down a good bit. I‚Äôve found no one complains about this if the isomorphic (prerendering) features are used. At that point payload size is only paid for once, and transparently in the background. All subsequent page visits fetch from the browsers cache, and versioning the all.js file ensures newer versions of the app downloaded immediately when deployed.
What a pity Chrome on mobile devices don‚Äôt have the right extension. 
Oh wait, the link I post for review by peers on Reddit needs to actually...function? Cut me some slack, it works great in 8.1% of Chrome releases and let's not forget the "UC Browser" for Android too!
If it‚Äôs easy to do, maybe you should add some kind of test that will generate a simple error message if the browser is not capable enough. 
Yea I‚Äôm hopeful that SharedArrayBuffer will leave experimental status before WebGHC does. There‚Äôs still things we can do to stop relying on it if it doesn‚Äôt, but it‚Äôd be harder to do
That‚Äôs a good idea.
Yea trivial prerendering is one of the best parts about using Haskell on both the front end and the backend. I‚Äôve not used miso in a production environment, but I‚Äôve seen the technique do wonders for reflex apps.
Should be noted that WebGHC is without a doubt still in experimental stages. I think it‚Äôs fair to use an experimental browser feature for such a thing. This post is more about showing what it‚Äôs capable of, not how stable it is.
Hi, I agree. That's why $15 is the starting rate for interns who have no prior knowledge of Haskell. We pay more to those who already have experience with Haskell. This is to offset the fact that our developers need to spend more time with those who know less.
I don't get payed to waste time on tools that don't work. TLDR: Stack + Intero is the best. Period. Word of advice, don't listen to those telling you to use cabal. Been there. I tried using cabal but it's a huge waste of time as most tools require Stack to work. In a couple months Stack will blow that experimental cabal new-build mess out of the water with their new vastly superior Pantry store architecture. I really wanted to see cabal succeed but I don't think there's any future for it anymore. They had their chance but failed to deliver. Gitlab for versioning control and for CI Gitlab's pipelines work great with Stack. 
I use vim (inside tmux) and have mappings for hasktags (for jumping to definition), hlint, dash (I am on macos and dash is pretty nice for searching through docs), ack (with ripgrep), stylish haskell. Ghci, ghcid and yesod devel. It is worth mentioning trydactil firefox extension for vim bindings and sometimes I search docs with hayoo. 
* (spac)emacs for editing (with ag for code search) * git for VCS * nix for dependencies and reliable builds * cabal new-repl for development * hydra for CI I've experimented with dante and ghc-mod for IDE-like features but so far nothing has been easy enough to set up reliably (especially in an arbitrary Nix Haskell package set). I'm hoping haskell-ide-engine will pull through here eventually. The other big issue is CI. Hydra is garbage but has the advantage that it natively understands Nix.
Finally someone using Yi. Would you mind explaining a bit the big advantages of Yi over another one? What is your feeling using Yi? (I'm a heavy vim user for now... And I add a bonus question: are the advantages still in Yi if I'm using it with the vim bindings?)
Not full time on Haskell, but mysetup is: - vim 8.+ With some custom packages - ghcid for auto reload basically with the warning enabled - cabal - git - debian for the rest I would say...
I think that you can import files from different folders without notion of packages. For example: ./Foo/Bar/Baz/Source1,hs ./Foo/Bar/Source2.hs and these two sources are there, without any package, neither cabal config etc. ``` haskell module Main where import Foo.Bar.Baz.Source1 import Foo.Bar.Source2 ``` How the concept of (inexistent) package is managed there? if they are considered of the same package because share the same folder, let do it also with URLs if module names share the same namespace. Do that produces conflcts? spawn an error. I know that this is not very thoughful but I'm sure that there are ways to deal with it. package URL's for cabal is a nice idea and I'm all for it ,but it is orthogonal to this feature. Of course I know that the "file:" protocol "as is" is not used in GHC, since there are no notion of retrieving protocol GHC, since currently there are only one. &gt; How would you recursively call a simple import Foo.Bar for some random web file download at some URL? Would it go back to searching for it locally. I don't understand exactly what you mean. URL caches can be used that's right.
IIUC, Pantry is not new functionality, it‚Äôs merely a performance optimization (in fact, unless there was a change since I last checked, it‚Äôs actually removing functionality by limiting to one hackage repo).
So, yi has vim and emacs keybindings. I use fully vim keybindings. The primary advantage to using yi is the ability to configure it in Haskell, and not vimscript or elisp. There are a couple disadvantages, such as not already having a wide array of plugins already available to you, and the maintainers not having time to keep up with the project all the time (it's large and they make 0 money from it). It's fast, (not noticeably slower than vim), and the vim keybindings are mostly complete. They have haskellMode and first-class support for other languages as well. I'd say the number one disadvantage is not having the wide array of plugins. As someone who doesn't use much more than vanilla vim + ghcid, this doesn't bother me very much.
Thanks I will give it another try then. I use heavily vim built-in (because I m half of the time on another host as a sysadmin), and I don't have so many plugins. I will see the results :)
- I start projects with new-build and switch to Nix as soon as I need anything nontrivial. - I don‚Äôt use editor integration, but if I did I‚Äôd use haskell-ide-engine. Instead I just stick to new-build in a nix-shell and ghcid for dev cycles. - I use Hydra for CI but I‚Äôm not particularly happy with it. I won‚Äôt switch to Hercules because the backend is closed source and I can‚Äôt self host it (same reason I won‚Äôt use cachix). - I usually use github but I‚Äôd really rather be using self hosted gitlab. - AWS and NixOps for deployments. NixOps is the worst... except for all the alternatives :P
You can use https://github.com/chessai/yi-chessai, follow the instructions there
Do you have some pointers on how to achieve pre rendering / "iso-foo" rendering with reflex ?
Basically just make your frontend code a library and use [Reflex.Dom.Builder.Static](https://github.com/reflex-frp/reflex-dom/blob/develop/reflex-dom-core/src/Reflex/Dom/Builder/Static.hs) on the backend to generate HTML to send down. Just include a script tag for your JS and it should take over once it loads.
Numerics and Haskell, two of my favourite topics as well. Let me start with some personal considerations: numerical analysis _is_ hard; the finest minds in mathematics and engineering each contributed just a few ideas each to it. This said, Haskell is a great language, but not made for numerical analysis. Arguably, being a general-purpose language while at the same time being good at specific domains would quite a feat (Julia and most of all Matlab are not general-purpose languages IMO), so implementing these things is bound to feel awkward at least in the beginning. What Haskell gives you instead is a huge bag of tricks for representing, composing, and abstracting out computation. Let's be concrete: many numerics textbooks present algorithms in heavily imperative pseudocode. In Haskell? copy that almost 1:1 into a `do` block. Golub and Van Loan use mutable memory vectors in their pseudocode? Manipulate MVectors in the ST monad (https://hackage.haskell.org/package/vector-0.12.0.2/docs/Data-Vector-Mutable.html). Whenever you are done with mutating memory in-place, you can freeze that up into an immutable vector and let the garbage collector take care of the details. Haskell, by enforcing at the type level the separation between code that is "pure" and code that has "side effects" lets you neatly decompose your algorithms, and reason about functionality with confidence. For linear algebra in Haskell there are a number of choices, but the venerable HMatrix package ecosystem is a great starting point (https://hackage.haskell.org/packages/search?terms=hmatrix). But this is only the beginning: some people have explored various advanced language features in order to e.g. not having to think about coordinate representations of vector spaces , or representing general function spaces that are only evaluated at specific points when needed. This is the more mind-bending side of Haskell, which is interesting to know but perhaps too of a long detour if you want to pass a uni exam. At any rate, I hope this helps you at least a bit, and for further similar discussions we have a dedicated community (datahaskell.org): https://gitter.im/dataHaskell/Lobby
In miso, pointers to the DOM are copied into the virtual DOM after the page is loaded. This keeps the server and client in perfect sync. In reflex, how does the FRP graph become aware of the DOM nodes that already exist due to pre-rendering? 
Reflex just redraws the whole page once the JS is loaded IIRC. Obelisk may have something smarter but I'm not sure.
You know professional Haskllers such as guys from FP complete also use inline-c for high performance number crunching. Just saying you have the option.
Vim, stack, ghci, ghcid. I do my work in a terminal. We've only barely started our first haskell project, and it's not in production yet, so I can't really say anything about that end of things yet.
I haven‚Äôt played around with cabal-less ghc in a while, but it looks like essentially everything not in a package is in a ‚Äúmain‚Äù package and thus equality is still based on ‚Äúpackage‚Äù + module name. My question is what would happen if you imported `example.com/Foo/Baz.hs` and it contained `import Foo.Bar`. Would it search locally for it or would it search in `example.com/Foo/Bar` or what? I still see a lot of issues left. One is how to handle the caching aspect. Would you have to recursively traverse every url import and check if the file contents for all of them are the same every time you compile? Also if two files imported the ‚Äúsame‚Äù module in two different ways the types and classes would not be the same. This also sounds like a nightmare for dependency management and versioning unless you basically guarantee that the content at the URL never changes (like my hash suggestion). 
Emacs for editing. Ghci for fast feedback. Internal google tools for dependencies, building, source control, continuous integration, and testing. 
Isn't the point of `stack script` to have a self-contained single file script? In that case requiring an additional custom snapshot file fails to meet the goal of a self-contained single file script. Enter Cabal. No need to wrangle with resolvers or custom snapshot files. Just this single file contains enough information for a working Haskell script: #!/usr/bin/env cabal {- cabal: build-depends: base, s-cargot -} module Main where import Data.SCargot main = do putStrLn "hello" 
Nice! I didn't realize `cabal` was now supporting self-contained scripts too, I thought the OP meant they switch to a full-blown cabal project.
I'm not the author of `s-cargot`. [You could try cutting the author an issue?](https://github.com/aisamanra/s-cargot/issues?q=is%3Aopen+is%3Aissue)
Thabks. 
As u/rampion suggested, it looks like defunctionalization is the way to go here. Package [first-class-familes](https://hackage.haskell.org/package/first-class-families) (thanks [u/padaccred](https://www.reddit.com/user/padaccred/) and [u/jonathanlking](https://www.reddit.com/user/jonathanlking/)) provides lazy version of IfThenElse (called Unbool), as well as many other combinators. Thank you all for your help. Also, I highly recommend Sandy Maguire's book [Thinking with types](http://thinkingwithtypes.com/) made many things clear for me and also explains this trick.
It's more like type-level computation than type checking. Given set of root types I want to compute set of all user-defined (which mean they are not members of some set of "primitives" or special cases) types that transitively are components of these roots. Some of the involved types are mutually recursive. In order to stop recursion I have to check if I've already seen the type. Maybe I'll write blog post about it when I finish.
* Sublime Text for editing * Stack for dependencies and building * `ghcid` with [ghcid-sublime](https://github.com/nh2/ghcid-sublime) for fast feedback * `ghci` * `git` on all projects currently * CI/CD and issue tracking depends a lot on the project and customer. I'd claim most have code on Github or Gitlab, and for CI/CD, Gitlab looks most common right now among these projects. For my own projects, and for a few of our clients, I also use * [Reviewable](https://reviewable.io) for code review (by far the best in my opinion) * Jenkins, TravisCI * `nix` + `nixops`
This is good advice. Also, if you can expend the free time, work on some Haskell projects, ideally open source. To provide some encouragement that it's possible: I've learned most of my technical Haskell skills in my free time aside university (also by choosing it for uni projects where I could). After doing that for a while, I could go directly to work at Haskell projects in industry, and now I'm a Haskell consultant. Make sure to learn and use practical libraries. https://haskell-lang.org/libraries has a nice set of tutorials on some one tends to need often for building real-world applications. Also, visit Haskell conferences.
In another subthread here I've [given a recommendation](https://www.reddit.com/r/haskell/comments/ab8ypl/monthly_hask_anything_january_2019/eehkb7l/) on libraries. Consider all concepts used in those, and understand them. Then you will have covered lots of ground and will be able to generalise your knowledge to many other libraries and problems.
At Tsuru: custom shake based build system (originated from pre-stack days, better at avoiding recompilation and compilation of unused stuff), private gitlab instance, vim, emacs and sublime are used by different people. Build system supports ghcid and hdevtooos and a custom "typecheck only don't compile anything except for strictly required for TH stuff"
linux (ubuntu) editor: emacs in terminal haskell IDE: intero git stack web framework: yesod 
Currently the DOM is rendered again, but soon a feature is going to land in reflex-dom which uses the DOM created by pre-rendering. (This -&gt; [https://github.com/reflex-frp/reflex-dom/pull/275](https://github.com/reflex-frp/reflex-dom/pull/275))
This is the standard proof that it is computable whether a continuous function on the Cantor set, accessible only through queries, is constant.
- git/GitHub for all the source code. - cabal new-* for development (also Stack, but we are actively getting rid of Stack in all the projects). - VSCode + HIE as an editor. Most of my colleagues use them, some use VIM + HIE, some use Emacs + HIE. - CircleCI for CI/CD.
&gt; we are actively getting rid of Stack in all the projects May I ask why? Is it a technical issue that could be fixed in Stack to keep you from doing that?
For the benefit of anyone who, like me, had to read this several times, the sentence should be parsed as &gt; This is the standard proof that (it is computable whether (a continuous function on the Cantor set, accessible only through queries), is constant). 
Yes, put Haskell or Common Lisp in your CV, you'll probably and up writing code in some stupid mainstream language. But you'll perfectly fit the industry. Isn't the history of software development just a chronology of pragmatism? &amp;#x200B;
OK, here are some of the reasons, both team-wise and personal. We think that with "cabal new-*" Stack is not really needed anymore. For what we need "Cabal" does everything better and simpler, except for "automatically" providing GHC. Cabal cannot do that, but we consider it a minor problem since installing all the required GHC versions once takes a few minutes (for each of us, devs), and then it is not a problem anymore. We found Stack not very convenient when authoring libraries and working with them. Two "issues" here: 1) After publishing a library on Hackage we'd have to wait for 15-20 minutes before we can use it with Stack. This is due to Hackage indices replication. Granted, 15 minutes is not much, but it is annoying enough. After 15-20 minutes we can reference the package from Hackage, and them in a few days we'd change the way it referenced again when it is available on Stackage. All this feels like unnecessary and artificial frictions. 2) When working on a library, as one of CI/CD steps, we'd like to make sure that it can be built and it works with _the latest_ versions of its dependencies. When something breaks, we'd like to investigate and either fix our stuff or fix constraints. Stack is a blockage here because we'd always build against what is on the snapshot, which can be far from latest from Hackage. When working on applications we use "cabal new-freeze" so the "snapshot"-ish thing is still there, without Stack. For the cases where we need absolute guarantees in builds predictability, we'd use Nix. Which, again, Cabal now supports out of the box (and which we haven't yet tried, TBH). In other words, we feel that Stack was very valuable for us before Cabal introduced "new-*" commands and before it was able to reference packages from Git. We couldn't live without these features, but now Cabal can do it. Today we feel that _to our team_ Stack introduces a layer of complexity without giving much back. Now my _personal_ reasons which my colleagues may and may not share (I honestly haven't discussed them). It is about new features that Cabal adds. For example, multiple public libs in a package. I personally think it is a great feature, and I'd love having it. But I saw the point raised by, I believe, Michael Snoyman (I apologise if my memory plays me) in which he was strictly against it. One of the reasons was that it would complicate Stack, and he wouldn't like to have to add support for it to Stack. I feel at this point that difficulties in maintaining Stack are kind of holding us back (or are trying to do so), and are trying to deny me a valuable feature :) I am slightly concerned with this going forward, too. Will Stack try to hold back features because it is hard to maintain (or other reasons)? If I stay with Stack and Cabal introduces a feature that I like, will I be able to access it in a meaningful timeframe? To me personally moving back to Cabal after years with Stack was quite a pleasant experience. It feels faster, the iteration friction is definitely faster, CI is simpler, the file format now supports cool features such as glob, imports for common settings (I don't need to use hpack anymore! win!), multiple internal libraries... Lots of really good stuff! If only modules were automatically discovered and added to the cabal file the same way hpack does it ;) But to me, it is not a big deal comparing to getting rid of package.yaml, and can probably be solved as a feature of Haskell IDE Engine... 
As mentioned by /u/rampion, defunctionalization seems the way to go. However, at first glance it seemed a bit more involved than what I have seen before; Another way, as proposed by this blog post: https://blog.poisson.chat/posts/2018-08-06-one-type-family.html type Exp a = a -&gt; Type type family Eval (e :: Exp a) :: a data IfThenElse :: Bool -&gt; k -&gt; k -&gt; Exp k type instance Eval (IfThenElse 'False onTrue _) = onTrue type instance Eval (IfThenElse 'True _ onFalse = onFalse I prefer this style slightly better as for some reason I prefer the notation. IIRC (and, as noted in the blog post) the previously posted "defunctionalization" style is known as `Apply`, where as this is know as `Eval`. They are closely related, and I strongly recommend reading Lysxia's blog post!
Incase you are not aware, the Haskell community survey will give you a much larger sample than the people who choose to respond here (caveat emptor, it has its own biases): https://taylor.fausak.me/2018/11/18/2018-state-of-haskell-survey-results/ The raw data is available, so you could slice it according to people who say they are paid to work with Haskell :-)
This won't even load on my phone (Pixel 2 with Android 9). I think 12 seconds is long enough to wait for some kind of content.
It appears to me that there are two camps: 1) nix + cabal-new 2) stack My experience has been that stack was a revelation. Previously, cabal sandboxes were a pain in the neck and although they were much better than the past, still tricky. Once stack arrived, many things became much simpler. For many, possibly the most important benefit was reliable windows builds. That alone was awesome for me/us. A few things since then have stack less relevant for us. Firstly, the haskell/nix story is very very good. Secondly, Cabal itself has improved dramatically and thirdly windows has pretty good support for nix/haskell through WSL. It would be nice to be able to easily create windows binaries from haskell code through nix, but for the moment, WSL gets us by. This has mostly caused us to give up on stack. The dependency management (and integration with deployment etc) makes nix very compelling. I was asked this week if we were still providing updated windows binaries of a particular tool and I prevaricated, but came down on the side that the users best approach was to install WSL and use nix to get our latest versions. TL;DR; stack was/is awesome, but for us, nix/cabal has overtaken it and mostly WSL gets us by on windows. 
The reason it doesn't render on your phone is that we're using an experimental browser feature (`SharedArrayBuffer`). Considering WebGHC itself is definitely still experimental, I think it's fair to use experimental browser features that require manual enabling. Hopefully `SharedArrayBuffer` leaves experimental status before WebGHC does, but if it doesn't we can fix that with some custom RTS code.
&gt; I feel at this point that difficulties in maintaining Stack are kind of holding us back (or are trying to do so), and are trying to deny me a valuable feature :) I am slightly concerned with this going forward, too. Will Stack try to hold back features because it is hard to maintain (or other reasons)? If I stay with Stack and Cabal introduces a feature that I like, will I be able to access it in a meaningful timeframe? Take Backpack as a poster child example. Backpack has been supported by cabal-install since 2017. Fast forward to today: It's 2019 and neither Stack nor Stackage have any support for Backpack. If that is any indication...
I went through this book a couple of years back while learning haskell and it was a great learning experience. Recommended! 
Have you read "Haskell Road to Logic, Mathematics and Programming" and could compare these two?
- Nix + cabal new-build for package management and builds. There is some stack, but we're using it less and less. - Gitlab for CI running on our own machines - Emacs + dante + dir-locals shims to get nix to work properly. - Git for VCS 
Interesting to see how many people are happy with nix+cabal-new*, I'll have to give it a try.
I'm not sure I understand how the constructed `cntEx` implies equality for all possible `a -&gt; r`. You write "the value of the counterexample at a is r" what does that mean? My best understanding is that we try to answer with every possible `r` for all the finite amount of queries and then compare if the result was the same.
One avenue I explored it to create a new associated type `Next'` like this: class KeyHelper (ordering :: Ordering) (k :: Symbol) (left :: RBT Symbol Type) (v :: Type) (right :: RBT Symbol Type) where type Next' ordering k left v right :: Ordering type Value' ordering k left v right :: Type instance (KeyHelper (Next' LT k left v (N color2 left2 k2 v2 right2)) k left2 v2 right2) =&gt; KeyHelper LT k left v (N color2 left2 k2 v2 right2) where type Next' LT k left v (N color2 left2 k2 v2 right2) = CmpSymbol k2 k type Value' LT k left v (N color2 left2 k2 v2 right2) = Value' (Next' LT k left v (N color2 left2 k2 v2 right2)) k left2 v2 right2 `Value'` is implemented in terms of `Next'`. But here my intuition fails me. Are multiple occurrences of the associated type in a signature "shared"? Or is the type-level computation redone each time? In the latter case, we are no better than before.
You can use \`$\` to avoid using this many brackets &gt;This is the standard proof that $ it is computable whether (a continuous function on the Cantor set, accessible only through queries), is constant. &amp;#x200B;
Unfortunately not. I'll say that DMUAC is very accessible and can be approached with very little prior understanding of mathematics and logic. On the other hand it doesn't explore the topic at a very deep level but it will give you a thorough foundation to pursue the subject in more detail. 
Thx! I was just about to buy HRtLM&amp;P... Man.... Choices choices lack of time! :D
This is cool. With a different, non-classical interpretation of Eq, this whole thing is a lot cleaner, more efficient, and doesn't require a finite codomain: class Eq a where type Logic a :: Type infix 4 == (==) :: a -&gt; a -&gt; Logic a newtype Cont r a = Cont { runCont :: (a -&gt; r) -&gt; r } instance (Eq r, Eq a) =&gt; Eq (Cont r a) where type Logic (Cont r a) = (a -&gt; r) -&gt; Logic r Cont x == Cont y = \cont -&gt; x cont == y cont ex1, ex2, ex3 :: Cont Bool Integer ex1 = Cont $ \ib -&gt; (ib 7 &amp;&amp; ib 4) || ib 8 ex2 = Cont $ \ib -&gt; (ib 7 || ib 8) &amp;&amp; (ib 4 || ib 8) ex3 = Cont $ \ib -&gt; (ib 7 || ib 8) || ib 4 eqs :: [Bool] eqs = map ($ even) [ex1 == ex2, ex1 == ex3, ex2 == ex3]
FYI a quick Google search will let you download DMUAC for free so you can preview it before buying :-) 
The [`Eq`](https://ghc.haskell.org/trac/ghc/ticket/10592#comment:12) I want :) perfect for codata instance Eq b =&gt; Eq (a -&gt; b) where type Logic (a -&gt; b) = a -&gt; Logic b (==) :: (a -&gt; b) -&gt; (a -&gt; b) -&gt; (a -&gt; Logic b) (f == g) a = f a == g a
`Eq (Cont r a)` can be [derived via](https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/glasgow_exts.html#extension-DerivingVia) `Eq ((a -&gt; res) -&gt; res)` {-# Language DerivingVia #-} newtype Cont res a = Cont ((a -&gt; res) -&gt; res) deriving Eq via ((a -&gt; res) -&gt; res) or simply with [generalized newtype deriving](https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/glasgow_exts.html#extension-GeneralizedNewtypeDeriving) newtype Cont res a = Cont ((a -&gt; res) -&gt; res) deriving newtype Eq
Personally I am fine with type checking that might not terminate. If you write a partial value level function you could cause a crash in production, but a partial type level function is much less dangerous, type checking will just hang / reach a depth limit and then you can debug it from there. 
I published my assorted notes and solutions to the exercises on https://github.com/adamschoenemann/dmuac when I went through it a couple of years ago. Maybe it could be of help to someone. 
Yeah, and you can get some cool stuff with the following use of lattices: -- | Meet semilattices class Eq a =&gt; POrd a where inf :: a -&gt; a -&gt; a infix 4 &lt;= (&lt;=) :: b -&gt; b -&gt; Logic b b1 &lt;= b2 = inf b1 b2 == b1 infix 4 &lt; (&lt;) :: Complemented (Logic a) =&gt; a -&gt; a -&gt; Logic a b1 &lt; b2 = inf b1 b2 == b1 &amp;&amp; b1 /= b2 instance POrd b =&gt; POrd (a -&gt; b) where inf f g = \x -&gt; inf (f x) (g x) f &lt;= g = \a -&gt; f a &lt;= g a -- | Lattices with a lower bound class POrd a =&gt; MinBound a where minBound :: a instance MinBound b =&gt; MinBound (a -&gt; b) where minBound = const minBound -- | Lattice orders class POrd a =&gt; Lattice a where sup :: a -&gt; a -&gt; a infix 4 &gt;= (&gt;=) :: a -&gt; a -&gt; Logic a b1 &gt;= b2 = sup b1 b2 == b1 infix 4 &gt; (&gt;) :: Boolean (Logic a) =&gt; a -&gt; a -&gt; Logic a b1 &gt; b2 = sup b1 b2 == b1 &amp;&amp; b1 /= b2 instance Lattice b =&gt; Lattice (a -&gt; b) where sup f g = \x -&gt; sup (f x) (g x) class (Lattice a, MinBound a) =&gt; Bounded a where maxBound :: a instance Bounded b =&gt; Bounded (a -&gt; b) where maxBound = const maxBound class Bounded a =&gt; Complemented a where not :: a -&gt; a instance Complemented b =&gt; Complemented (a -&gt; b) where not f = \x -&gt; not $ f x (&amp;&amp;) :: Lattice a -&gt; a -&gt; a -&gt; a (&amp;&amp;) = inf (||) :: Lattice a -&gt; a -&gt; a -&gt; a (||) = sup -- | Lattices that support implication, but not necessarily the law of the excluded middle class Bounded a =&gt; Heyting a where infixl 3 ==&gt; (==&gt;) :: a -&gt; a -&gt; a -- | A generalisation of the Boolean algebra class (Complemented a, Heyting a) =&gt; Boolean a where Now, something like the following is more succinct/readable: &gt;&gt;&gt; filter ( (&gt;= 'c') &amp;&amp; (&lt; 'f') || (== 'q') ) ['a'..'z'] "cdeq"
Is use of haskell in google public? 
* cabal new-* * emacs + ghcid * private gitlab * git All on Linux &amp; FreeBSD
Neither has a particularly strong FP story as far as I know. C# arguably is a bit better in that regard, but they're both imperative OO languages at heart.
i struggle to think how Java might be considered an FP-supporting (let alone, -oriented) language ....
Nice! In miso this is the hydration (pointer copying) logic: [https://github.com/dmjio/miso/blob/master/jsbits/isomorphic.js](https://github.com/dmjio/miso/blob/master/jsbits/isomorphic.js) Having the virtual DOM structure be equivalent to the DOM is very convenient, and allows hydration to be accomplished in one linear pass. How is the mapping from the FRP graph to the DOM recovered?
C# for sure, but it's not amazing. LINQ query syntax is like crappy `do`-notation, so you can do monadic parsing and whatnot with handy syntax.
Imperative *pseudo*-OO languages.
I think that C# is probably a little more mature in its support for functional techniques. For example, it had support for lambda expressions way before Java. They also seem to add more and more functional elements (like pattern matching types) to each new version of the language. The developers of LINQ say they designed it to be monadic in nature. Don't forget that with .NET you also get access to F#, which I'm really finding to be a very enjoyable language to code in. It's not pure like Haskell, but I think that the syntax would feel pretty natural to someone with a Haskell background. It even has its own version of do notation. No typeclasses though, which is something I hope they'll add one day.
I would definitely agree with this: C# does include quite a few FP features, but FP is still not exactly easy. Other FP features included in the latest release (C# 7): pattern matching, lambda expressions and first-class functions, and expression-bodied functions.
?? But `Phrase` here _is_ the type. Why would you want to see the data constructors of a type when looking at the type?
"Show me the definition of this word" is, like, one of the most common and useful things that I expect my editor to be able to do. In this case, the definition of `Phrase` (the type) is: ```haskell newtype Phrase = Phrase BS.ByteString ``` so that's what I'd expect the editor to show me. I would expect that same behavior even if the constructor had a different name from the type, regardless of which one I was hovering over. Imagining this `data` declaration: ```haskell data Foo = Bar Int | Baz String ``` I would expect that *entire* source string to be shown when I hover over `Foo`, `Bar`, or `Baz`, because that *entire* source string is the declaration of each of those three words.
It's not FP-oriented, but they've added things like lambdas and streams since then.
Indeed, but - and this is a genuine question - wonder whether those things are enough to say that Java essentially/significantly supports FP?
No, can't really relate. I only very rarely want to see the full definition of a symbol every time I look at it, and if I wanted to see the definition I'd just jump to its actual source location (which Intero can do just fine).
What should happen if you hover over `Data.Map.Map`? Do you _really_ want to see data Map k a = Bin {-# UNPACK #-} !Size !k a !(Map k a) !(Map k a) | Tip If you don't, what should the rule be for when to show the definition of a type?
Note the distinction between "on hovering" and "every time I look at [a symbol]" - you seem to be assuming that these popups (which are widely implemented in many editors, btw, and not in any way a new thing) would be appearing all the time for every symbol on the editor's screen, when in fact the point of "hovering" is that it's a dedicated (and sorta slow) mouse input, maybe analogous to "moving your cursor onto a word, and then running a command bound to a key" if you do everything with your keyboard.
Okay, so the idea is that `cntEx []` will either find a counterexample to the statement "for all f :: a -&gt; r, arr f == arr' f", or if one does not exist it will be some arbitrary total function. If such a counterexample exists, I will call `cntEx []` *the* counterexample. Otherwise, *the* counter example will be undefined, and `cntEx []` will just be some random function. `cntEx guess` will find *the* counterexample assuming it takes on values described by `guess`, if it exists. First it checks if its argument is described by `guess`, in which case it just outputs that. Otherwise, it does a "proof by cases" so to speak. For each possible `r`, `cntEx guess a` will check if `cntEx (a,r):guess` is a counterexample. If so, that means it is *the* counterexample (by the property we are assuming `cntEx guess` has), and so the value of the counterexample on `a` is in fact `cntEx ((a,r):guess) a == r`. If no such `r` exists, we have "proven by cases" that *the* counterexample exists. That is because the value of *the( counterexample at `a` has to be some `r`. We can perform this proof since the type `r` is finite. In this case, `cntEx guess a` can be anything any value; we just are not permitted to leave it undefined. So `cntEx guess` will either be *the* counterexample if it exists, or some arbitrary function otherwise, assuming `guess` is accurate. `[]` is always vacuously accurate, so `cntEx []` will have the correct behavior.
Yeah, if I hover over `Data.Map.Map`, if source is available, I'd like to see it, ideally also with a notice about where that source is coming from. A lot of the time source for external dependencies is not available, and many tools (broadly across other programming languages; I have found Haskell support to be disappointingly lacking) choose to instead show generated documentation based on the source, like Haddock, and to distribute documentation in a form readable by the compiler and tooling in the official package repositories.
1. Stack 2. Emacs (but use whatever you want) 3. `stack ghci` for regular poking/inspecting 4. ghcid for rapid refactoring 5. git Avoid IDE back ends.
If I understood this correctly, then if I were to create a continuation that calls `f` some `m` times (at different points) and `r` has cardinality `c` then the runtime of certifying that no counterexample exists would be `m^c`, so exponential, right?
* cabal (new-build obviously) for builds/testing/benchmarks * vim * nix/hydra for CI * git 
Not the poster but * Introduces new bugs while fixing old bugs * No support for cross-compilation whatsoever * I strongly prefer nix-style builds to snapshots * No support for big features (like Backpack) two years on * No support for multiple libraries * YAML files are annoying and ugly and I'd rather write cabal files Basically, stack's NIH syndrome has caught up with it, and they're no longer willing to try for feature parity with `cabal`. Paired with the fact that `cabal new-build` has a slightly better model than stack snapshots, and there's really no reason to use stack in 2019.
Another formulation: class Searchable a where -- | Takes a predicate @p@. If there is at least one value of type @a@ -- which satisfies @p@, return that value. Otherwise, -- return any value of type @a@. epsilon :: (a -&gt; Bool) -&gt; a instance Searchable Bool where epsilon p = p True -- epsilon p = if p True then True else False instance (Eq a, Searchable r) =&gt; Searchable (a -&gt; r) where epsilon p = go [] where go guess a = case lookup a guess of Just r -&gt; r Nothing -&gt; epsilon (\r -&gt; p $ go ((a,r):guess)) instance (Eq a, Searchable r, Eq r) =&gt; Eq (Cont r a) where (Cont arr) == (Cont arr') = pointEq $ epsilon (not . pointEq) where pointEq ar = arr ar == arr' ar 
Ocaml does this with emacs, it's extremely useful if you're working in a code base that you didn't write.
&gt; nix + cabal-new There's a nice little middle ground between cabal new-build and full on Nix, for people who don't want to get into the complexity of Nix. You can use Nix just to install GHC. This is pretty low friction for people new to Nix, and I've found it to be the most reliable way to get GHC by far.
At least. The version I gave is actually way worse than that do the duplication of work. I think with enough memoization you could get it to not do that, though.
This is amazing! Almost completely usable. &amp;#x200B; I managed to break it! Reproduce by adding some (50?) todos, then click between 'Completed' and 'Active'. `jsaddle Results decode failed : "\NUL\NUL\DC2l{\"tag\":\"Callback\",\"contents\":[661,{\"tag\":\"Success\",\"contents\":[[],[{\"tag\":\"ValueToNumberResult\",\"contents\":345},{\"tag\":\"ValueToStringResult\",\"contents\":\"\"},` `error, called at src/Language/Javascript/JSaddle/Wasm.hs:84:16 in jsaddle-wasm-0.1.0.0-1NIGCaophmoLa7FMzWC6dd:Language.Javascript.JSaddle.Wasm` &amp;#x200B; &amp;#x200B;
Thanks for the report! Think you could open an issue on [jsaddle-wasm](https://github.com/WebGHC/jsaddle-wasm)?
Done, thanks for all the good work!
They are both so far away from FP that it is much more important which job you can find rather than opinions of people on this sub on their "FPness". Just look at the local market, see if most companies are Microsoft based or not. There are some local markets in US for example where Microsoft still rules small to midsize business so, dotnet is the ticket to get the job. Java on the other hand is more used in very large corporations or in open source. As for introducing FP to your job, believe me, it is much easier to simply bring FP language after you established yourself than try to change people you work with in existing ecosystem (java or c#). They will fight you tooth and nail. 
cabal new-build nix (via reflex-platform - only because it provides an easy way to pull in reflex and ghcjs). vscode git
Haskell novice here. Is [this guide](https://github.com/Gabriel439/haskell-nix/) with the cabal new-* commands? I decided to try switching since I use nixos anyways. If there's any other tutorials out there please share. :)
As others have said, C# is definitely more functional than Java. On the other hand, it‚Äôs much easier to integrate Scala into Java projects than it is to bring F# into C# projects, and Scala has a more mature ecosystem than F# does. Basically if the question is C# vs. Java, go for C#, but if the question is CLR vs. JVM, go for the JVM.
Language Server Protocol with [HIE](https://github.com/haskell/haskell-ide-engine) "kinda" does what you're asking. I said "kinda" because Phrase is being a type. It will show the `newtype Phrase` But you can jump into the definition and look at all constructors available.
Seeing as to how there is no universal consensus of the definition of FP itself, I'd say yes.
So *any* programming language can reasonably (fsvo "reasonably") be said to be FP-supporting? (i'm indeed aware of the lack of consensus around the definition of FP, but i'm intrigued as to whether there's more agreement around the point at which things move from "grey area, this might or might not be FP" to "really not FP".)
very helpful, well thought out reply and i‚Äôm sorry but when read ‚ÄúFPness ‚Äúi laughed out loud... haha you said penis.
I will play the devil's advocate and say that it is often easier to ask for forgiveness than ask for permission. Personally this is the only way I have managed to introduce new tech into the workplace. Yes, you can spend time and effort to convince everyone and come to an agreement, but 99% of the time it is not worth it. 
My guess is OP is thinking Java becomes Scala or Clojure or Cotlin, i.e. JVM, or something similar. Similarly guessing based on wording of post that OP is probably a junior or new programmer and doesn't understand the scope around the differences and difficulties in the migrations or the complexity of how management will perceive said changes. 
Fair warning based on your post, please don't think you can go introducting FP into your work code without management buy in. OO programmer skill sets aren't necessarily transferable to FP programmers, it's a completely different way to think about code IME. Plus, there are a lot of OO programmers that don't ever want to touch FP. I'm not one of them but as a programmer, I don't feel it's your place to determine the slow refactoring into another language. You're not the one that has to hire your replacement. In the end, you'll end up creating this miasma of systems running different languages that become mission critical and also has no one that has the skill set to maintain. &amp;#x200B; &amp;#x200B;
I myself am flummoxed by various programming communities claiming FP based on their own variation of the term. By that measure, it looks like the vast majority of modern mainstream languages are "functional" to some degree. I wish there could be an unambiguous, commonly accepted definition of the term.
C#, but that's not saying much because it's still pretty far from FP. In most places, the JVM ecosystem seems to have a lot more jobs in comparison. Check your local market. Many Java gigs will make use of libraries like Rx, Vavr etc which better enable FP. The JVM ecosystem includes other languages like Kotlin (which is popular and has a really good functional library, Arrow) and Scala, which is pretty FP.
Was thinking the same. But browsers now support file hashes on linked resources so you don't actually need to trust the third-party content distributor. Maybe something similar could be done here. Still not sure this feature in general is all that desirable, but this should fix at least the security concern.
I've used F# for a while at work, and after learning Haskell it feels like being severely restricted. Not having higher-kinded types makes me really sad.
If you strive to a more FP-oriented ecosystem at work, the language doesn't really matter (in this case especially); given the discipline, you can write pure functions, immutable data, etc. in any language. The main criteria in this regard is the willingness of the team to practice FP. If they are OOP acolytes, your chances of writing FP code there are bleak, regardless of the language.
cabal new-build VS Code with HIE or Geany (on a system where VS Code doesn't work) ghcid hlint git glade as GUI editor &amp;#x200B; Works even on the ancient SLES11.
 instance (Eq a, Searchable r) =&gt; Searchable (a -&gt; r) really captures the nature of the situation at hand. Nice
For little advanced features - try using [Intero](https://haskell-lang.org/intero) with emacs. Almost zero setup - it automatically installs backend program in your stack environment.
s/cotlin/Kotlin
&gt; with "cabal new-*" Stack is not really needed anymore &gt; Stack introduces a layer of complexity without giving much back. I beg to differ. What layer of complexity? Most tooling doesn't work with the experimental "cabal new-build" feature yet. So I'd wait before jump ship. By the time new-build is not experimental anymore and tooling has added support Stack 2.0 will have been released already and will dispel many of the reasons you had for preferring cabal.
It‚Äôs not a secret that there are some Haskell users within Google. But the individual projects can be secret. 
Nice! Send a link here once you have it compiling or an image to show
Why should it be faster? fastIndexBoxed seems to be doing so much more work: a lot of redundant checks at every iteration, and repeated vector appends.
1. `cabal v2-*` 2. Emacs + [Dante](https://github.com/jyp/dante) 3. `hlint` 4. `stylish-haskell` 5. Private Gitlab instance for Git/Issues/CI 6. `cabal v2-freeze` when cutting reproducible releases
I once tought it is correct, but it is not correct: &gt;&gt;&gt; Cont (\ib -&gt; ib 1) == Cont (\ib -&gt; ib 2) True == Cause I inserted `traceShow` to understand what gone wrong. instance (Show a, Show r, Eq a, Eq r, Finite r) =&gt; Eq (Cont r a) where (Cont arr) == (Cont arr') | (everything :: Flist r) == Empty = True --Special case (Cont arr) == (Cont arr') = pointEq $ cntEx [] where pointEq ar = arr ar == arr' ar cntEx guess a = case lookup a guess of Just r -&gt; r Nothing -&gt; case [r | r &lt;- toList everything , let guess' = (a,r) : guess , traceShow guess' $ not . pointEq $ cntEx guess' ] of (r:_) -&gt; r [] -&gt; head $ toList everything The output was: &gt;&gt;&gt; Cont (\ib -&gt; ib 1) == Cont (\ib -&gt; ib 2) [(1,False)] [(2,False),(1,False)] [(2,True),(1,False)] [(2,False)] [(1,False),(2,False)] [(1,True),(2,False)] True What this mean? The first 3 lines means this algorithm searched the counterexample of `\ib -&gt; ib 1 == ib 2` from `ib 1 = ???`, and finally found `ib 1 = False; ib 2 = True` is a counterexample. The 4-6th lines means search started from `ib 2 = ??`, then found `ib 1 = True; ib 2 = False`. As a result, the constructed "counterexample" is `cntEx [] 1 = False; cntEx [] 2 = False`, thus this fail occurs. It needs to memorize constructed counterexample for each call of `cntEx [] _`. To do this, I think `unsafePerformIO` is needed somewhere.
Currently with Backpack it's only possible to move things around in a such way that you don't need to add extra `import` statements if you want instances (only need to change `package-name.cabal` file), but this requires to have 2 packages per instance and work closely with Backpack.
Not that I want to see the source, but the rule could be whether the constructors are exported or not. If they are exported, they should be considered as part of the public facing API :-)
Do you have example of commands and/or `.nix` configurations that show how to install GHC with `nix` and use it with `cabal` in this way?
Maybe. But what it really adds then? We used Stack for better dependencies sharing (compare to the "old" Cabal), for building dependencies from Git... Now we have it without Stack. Stackage, which is still, and will be the main feature of Stack. As I tried to explain in my message, we found that it is not what we need and there are some extra complexity and development friction to work around it. Bringing Nix into the picture we have this ground covered, without Stack. Again, at no point I am saying that Stack is bad or anything like it. I just tried to explain why after years of using it we've decided that it is not what we want _in our team_. For us, the new Cabal does what we need simpler, easier and now. YMMV :)
I have both; they're both very good, but I would say DMUAC is more accessible while HRtLMP would IMHO only benefit readers/students that more math-savy to begin with. &amp;#x200B;
Our tool stack at Holmusk: * `stack` for builds * Terraform for deployment * Docker * Circle CI * `ghcid` for immediate feedback from the compiler * Spacemacs for editting * Elm for frontend * Dart + Flutter for mobile applications
Oh thx for an info. I'll start with the DMUAC then. 
Thanks For The Suggestion. We'll definitely consider it.
Thanks themilitia. Do keep a track of our upcoming version, We'll definitely improve it.
Could you post this as a main posting/discussion to r/Haskell? I think this is a core issue and should have the visibility since google summer of code starts soon, and this would make perhaps a good project?
Typeclasses make it so that my code doesn't compile, as well as building up definition of a function for different cases(sorry for the unprofessional term), example: tell :: (Show a) =&gt; [a] -&gt; String tell [] = "The list is empty" tell (x:[]) = "The list has one element: " ++ show x tell (x:y:[]) = "The list has two elements: " ++ show x ++ " and " ++ show y tell (x:y:_) = "This list is long. The first two elements are: " ++ show x ++ " and " ++ show y 
Why is this marked as NSFW?
 example of ghci response: Prelude&gt; { Prelude| tell :: (Show a) =&gt; [a] -&gt; String Prelude| tell [] = "The list is empty" Prelude| tell (x:[]) = "The list has one element: " ++ show x Prelude| tell (x:y:[]) = "The list has two elements: " ++ show x ++ " and " ++ show y Prelude| tell (x:y:_) = "This list is long. The first two elements are: " ++ show x ++ " and " ++ show y Prelude| } &lt;interactive&gt;:7:17: error: parse error on input ‚Äò=‚Äô Perhaps you need a 'let' in a 'do' block? e.g. 'let x = 5' instead of 'x = 5' Loading the module to ghci and running the function works. trying to run it with stack gives an IO error. I just realised it was a mistake on my part, on how I realise this whole thing works, perhaps someone can explain? 
I think I missclicked or reddit added it automatically. I removed it.
This says something about Rust or Haskell...
Thanks for taking the time :)
The branch with the vector appends is only chosen about 200 times for the given input. I'd expect it to be irrelevant for the performance. The vector stuff is done to avoid the !! from naiveIndex. What redundant checks are you referring to? I doubt that vector bounds checks are worse than walking the whole list of chunks all the time, which gets up to 200 entries long. My main concern is learning the profiling though. So generalizing that: When profiling shows that a function takes a bunch of time, and none of the subexpressions are responsible for that time, what can I do to find out what's going on? Could leakage of thunks from another function be the cause? If so, can I track them down using profiling? If you take a look at the profiling output I linked, you see that fastIndexBoxed takes 21.3% individual (non-inherited) time. The vector ops and the divMod are listed separately, so they don't contribute to the 21.3%, right?
There's a library that provides Haskell bindings to Tensorflow but I haven't done anything with it yet: https://github.com/tensorflow/haskell
Thank you Form posting auch a nice Job offer.
I worked in the Strats team once. I can recommend it!
&gt; By the time new-build is not experimental anymore at this point all you're doing is shitting on cabal...
new-build is hardly experimental at this stage. It's going to become the default very soon. What tooling doesn't work with new-build other than intero?
Look around how filesystems implement journaling and relational databases do the [ARIES](https://en.wikipedia.org/wiki/Algorithms_for_Recovery_and_Isolation_Exploiting_Semantics) algorithm. It can't always be done if you cant replay stuff from the journal. &amp;#x200B; &amp;#x200B;
This has nothing to do with type classes. If you want to write a multi-line definition in ghci, you need to start it with `:{` and end it with `:}` (on their own lines).
`shell.nix`: with import (builtins.fetchGit { url = https://github.com/NixOS/nixpkgs-channels; ref = ‚Äúnixos-18.09‚Äù; rev = ‚Äú50f41ea2fcf86def32799f75577a4fe5cfd1132e‚Äù; }) {}; mkShell { buildInputs = [ ghc /* whatever else you need */ ]; } In a shell in the same directory: nix-shell
Wait you‚Äôre trying to bridge Haskell and Rust so you can sort a list of numbers??
Rust should be perhaps 6 times faster. I sort 100k or 500k lists of length 20.
Is this in any way related to [Seemingly impossible functional programs](http://math.andrej.com/2007/09/28/seemingly-impossible-functional-programs/)?
&gt; The branch with the vector appends is only chosen about 200 times for the given input. To really confirm that, consider adding `{-# SCC "vectorAppend" #-}` to that branch, immediately after `else`. That will instruct GHC to profile it separately, then you can check its entries column in the profile. 
First would be to make sure you're using some array-based organization in Haskell, If you're using the standard [Int] you're going to lose on the serialization and deserialization into that anyhow. Second, if you can send the numbers over in any sort of bulk operation, rather than one at a time, FFI time will amortize down to basically nothing. The question then is whether you can gain back the time copying to and fro, vs. a possibly in-place algorithm simply implemented in Haskell. While there are a lot of sorting algorithms in the world, in general, they aren't that hard to implement if handed the algorithm. That will depend on a fresh new slew of details, like, how big are these integers? Does Rust have something that uses SSE specialized on ints? (I dunno.) Do you have benchmarks showing the sorting is definitely much faster than what you can get with, say, 3 hours trying to implement the target sort in Haskell? (Note I'm coming at this from a purely engineering perspective, not a "use Haskell for everything" perspective. If bridging to Rust is the best solution, go for it. I can easily imagine scenarios where it is. But it is a significant enough cost, in complexity if nothing else, to be worth taking at least a few minutes to see if you can put together a pure Haskell solution, just to keep the language count down.)
Whoops, sorry about that. Should have tested that case. You can fix that though by replacing `cntEx guess'` with a function that returns `cntEx [] a'` for `a'` less than `a`. That way, due to purity, later examples need to be consistient with future ones. That requires `Ord a`, though.
Confirmed, that part takes 0% time. I went further and added SCC annotations to every expression in fastIndexBoxed. Source and Profile link are updated. There are still a few percentages coming out of nowhere. fastIndexBoxed has 2.1% more than the top level expression (SCC FIB_all) it contains, which just doesn't make sense. FIB_all itself has 6.7% non-inherited that can pretty much only come from the &gt;&gt;= that is behind the scenes of the do-block. Maybe I should manually desugar the whole thing. 
&gt; Design, implement, test, and maintain key functionality in GHC Web backends, such as GHCJS and Asterius. Is there any particular reason there's no mention of the [WebGHC](https://webghc.github.io) project? Does the position also cover working on WebGHC? 
Pseudo? Can you elaborate?
LINQ is such a godsend. It really helps the OO go down.
The focus on GHCJS and Asterius relates to the internal use of these projects. WebGHC is currently not on the roadmap. 
Java et al. implement *some* OO ideas, but not all of them, and not some of the most important ones. Smalltalk-80 is something of a "reference implementation" of true OO, and treats every aspect as a truly self-contained object that interacts with the rest of the system through a global messaging system. It is well worth looking into, as it exemplifies some very interesting ideas, such as "politeness" (objects *ask* other objects, there are no "imperative" commands).
&gt; No finance knowledge is required. You might want to explain what Strats means in this context. Is it [this](https://www.investopedia.com/terms/s/structured-repackaged-asset-backed-trust-security-strats.asp)?
It's not that! Strats is just the name of a team. You can just consider it an opaque identifier.
Makes sense. While I got your attention... are there technical benefits of Asterius over webGHC that make Asterius a better fit for IOHK's needs? And what determines whether you use GHCJS instead of Asterius or vice versa for a component?
I'm not sure what GHC developer really means, I thought that would be the compiler developers themselves. Is this some subset of Haskell developers?
You could look into making the Julia and Rust inline bindings (e.g., like "r-haskell") industrial strength. E.g., benchmark how long it takes to sort a list of numbers by going through the Rust ffi. Because rust has pattern defying quickstep algos that Haskell doesn't have, etc. 
Hasktorch! https://github.com/hasktorch
try: `module Main where` `import Answer` `import System.Environment` you shold not indent the 2nd and 3d line 
With GHC developer, I mean people who have experience hacking GHC; i.e., Compiler engineers familiar with GHC. Does that clarify it? Re website, sorry, seems to work for me in Safari and Firefox...
It would be nice if GHC programs would execute on risc-v chips (which can be used for embedded stuff. I guess you can compile via LLVM, but I don't know -- probably the hard part -- is getting the GHC runtime to work, or? (You could also compile to JS and run that on the esp32. Or you use a cheap arm chip for embedded stuff.)
&gt; With GHC developer, I mean people who have experience hacking GHC Okay, that's pretty clear. &gt; Re website, sorry, seems to work for me in Safari and Firefox... I'm using Firefox 64.0.2
A major concern with WebGHC is code size. The requirement for the SharedArrayBuffer is also a concern. It also requires a much more complex toolchain. The future for cross-platform compilation is surely WebAssembly, but GHCJS is more mature right now. 
I see. Encapsulation, Inheritance, and Polymorphism were drilled into my skull in CS1. But how does that differ from an actor model?
Ooo. A cryptocurrency company! That's sure to go places! /s
Who are you, people with 2 years experience writing compilers? 
All work is going to be as part of the existing GHC-related open-source projects and benefit everybody in the community who is interested in deploying to the Web. (Sweet deal if you ask me.)
You'd be surprised at how common it is to write compilers of some sort. There are many unknown little languages and unknown little compilers in addition to the heavy weights that everybody knows.
I won‚Äôt be surprised since I am quite familiar with the hobby. I am also familiar with many of those unknown little languages. another class if compiler writers are academics. the language in your wanted ad hints at professional experience writing compilers. I was wondering if this particular subset of users exists here and would love to hear a little about their professional experience. your great talent of explaining obvious things was noted though, thanks. 
My talent seems to be lacking as you got me wrong. I am neither referring to the hobby nor am I referring to the academics Well, truth be told, I am referring to some of the academics. Don't forget that large parts of GHC itself were written by academics. But to the point, many obscure languages are written by professional compiler writers. Actually, I'd wager, most professional compiler writers implement obscure languages (or at least, languages that are not Java, C, C++, etc). I am writing this as a professional compiler writer ‚Äî now, you have heard from one ;)
great knowing you! thanks for the intro. can‚Äôt wait to work with people like you!!!
Philip Wadler is part of the IOHK team. Heard of him?
If you have experience and interest in hacking on GHC, this is a great opportunity regardless of whether you believe in cryptocurrency as a technology or not. Since I do have experience hacking GHC, this is a job I might apply for if not for the fact that I already work for IOHK on the actual cryptocurrency.
I just checked, I have the same version. Very odd. Could you try again? Maybe a temporary glitch?
I my last job (working in Haskell on data science at scale) we wrote a number of Domain Specific Languages (DSLs). I have also hacked on GHC. Writing these DSLs was probably about 5% of the work I did at that company. Experience in hacking on GHC and general compiler engineering experience helped immensely. I would not consider myself a professional compiler engineer, but it is a role I think I could step into relatively easily. 
yes, I saw op posted videos and other materials by him 
There is actually a more fundamental problem SharedArrayBuffer is trying to solve (apart from thread wait). A web worker thread can be sent data in only two ways, with a 'onmessage' / 'postmessage' callback, or a SharedArrayBuffer. In our wasm web-worker we cannot use the 'onmessage' way as we need to read the data while executing the RTS, whereas the callback will be called only after the RTS process has finished execution.
An oldie but a goodie. When learning Haskell, this was a great resource for me for understanding how monads arise in so many places in practice.
Please consider whether you are communicating in a respectful way.
At 13:50, [the documentation of `zygoHistoPrepro`](http://hackage.haskell.org/package/recursion-schemes-5.1/docs/Data-Functor-Foldable.html#v:zygoHistoPrepro) is given as an example of especially-poor documentation. I didn't write its documentation, but as the current maintainer of the recursion-schemes library, I feel like I should take a moment to explain that `zygoHistoPrepro` is a joke, and the joke _is_ that it is incomprehensible. The wiki page has the same joke, which is why it is also incomprehensible. I am working on some [improved documentation for recursion-schemes](http://gelisam.com/files/comonadic-recursion-schemes/Data-Functor-Foldable.html#v:zygoHistoPrepro) which explains the joke, but of course if you need an explanation of why it's funny, it probably wasn't very funny for you to begin with :( 
What kind of data type has the kind : (*-&gt;*) -&gt; *-&gt;* I know that : :k Maybe :: *-&gt;* data MyType a b c = MkType a b c :k MyType :: *-&gt;*-&gt;*-&gt;* I just can't seem to find a middle ground example that combines both of these.
The main thing that makes Haskell fundamentally more capable is the way it controls side effects. For a function to read or write mutable memory, sockets, or disk, it has to say so in its type signature. This is tremendous for library authors because so many more constraints can be encoded at the type level. The STM library, for instance, provides nice transaction-based concurrency. Rather than relying on locks, transactions are replayed when there is contention. The structure of the library prevents you from stepping on yourself by executing a non-replayable effect as part of a transaction. Another example is that you can craft a tiny little monad that is "things you are allowed to do inside a database transaction." MySQL does not support nested transactions, so it's trivial to prevent engineers from running a transaction from within another transaction. Something else I've done in the past to write a little unit test harness to fake real I/O. The way I set it up, the code under test is not permitted access to "real" side effects. Basically, the compile fails if you write code that is not fully unit testable. All your tests are fast and they never intermittently fail. This is pretty nice to have in any mission critical application that nevertheless needs to be changed constantly.
Fantastic, I wish there were more libraries for text rendering in Haskell. As far as I could see this library uses font atlases, is that right? I've been meaning to give text rendering a go, although I had in mind to try some resolution-independent approaches. Patrick Walton put up a nice [list of various approaches](https://github.com/pcwalton/pathfinder/wiki/Related-approaches). Personally I'd be quite interested in giving a go at something like the algorithm Eric Lengyel uses for Slug ([paper here](http://jcgt.org/published/0006/02/02/paper.pdf)), as it works directly with (quadratic) B√©zier curves avoiding triangulation algorithms altogether. I have to finish my current project first though! 
Compilation times and the fact that I have to resort to some weird \`seq\`-based magic trick in order to get the JHC compiler to not fail randomly on monadic \`do\` blocks (look in the code for examples). At some point, the amount of time necessary to compile and link just became too much and I stalled on it.
This is from a while back, but beam is a rather thin (IMO) wrapper over the underlying database library. Mainly, it's meant for expressing queries, not handling connection establishment and management. Thus, you'll get back whatever exception that library throws, either postgresql-simple or sqlite-simple or mysql-simple.
Thanks Schell! Great stuff.
i only dabbled in scala before i started learning haskell, but the (almost trivial) reason to abandon scala was syntax. While seemingly nobody talks about it, it think haskells syntax lends itself way more nicely to the things you want to in functional programming. It takes a while to get used to (also, don't try to understand everything immediately), but it's just so much nicer for FP than a C-inspired language.
Thank you :) Yes, this uses an atlas. Using the raw geometry and something like loop-blin for beziers is an option but it takes a bit longer to generate that geometry including kerning, etc. in general though the are sooooo many ways to pet a cat.
Thanks :)
How long did it take to do a full compilation?
It has a much cleaner theoretical foundation and it shows. Its abstractions are more abstract and more elegant. Example: In scala functions are first class citizens. You can assign a variable with a function. like `var = function` But wait. This does not assign the variable. It executes (and causes side effects) the functions and assigns the return value. Haskell is a) lazy b) not side effect full that this distinction is not meaningful. (Besides termination; but here haskell has the more powerfull and more intuitive semantic) Curry: In scala your function can have one parameter list with multiple parameters, or multiple parameter lists with one parameter each and everything in between. In Haskell a distinction between these alternatives would not make sense and there is no distinction between these. Getters and (Setter or Withers). You have to decide what you want, and you end up with the wrong ones. When writing code you don't know if your methods manipulates a object or if it returns the result. In Haskell, everything is constant, no ambiguity. And yes, this is not a lack of a feature, but a fantastic feature in itself. It seems like it takes freedom away from you, but in reality you can anything you would do in scala, but you get much stronger grantees about your code, allowing abstractions that give you more expressiveness in the end. Types: Scala is stuck with the JVM and it wants to keep compabilty. This brings object, any and all this ugly stuff. The type system of java is suprisingly odd. Even proving that it is sound is a major undertaking and AFAIK it has only been proven for a theoretical subset of java without generics. Haskell type system in constrast is clean, simple, straight forward even with what java calls generics. The result is once again, a clearer langue, clearer abstractions and a type interference, in constrast to scalars poor excuse for one. OOP: Scala has, AFAIK no specification how objects, classes and all that stuff is supposed to work. Haskell OTOH has type classes, a feature simlar to hip languages like swift and rust and ad hoc polymophism. That combined with immutability gives you all you wanted from oop, without the hassle.
Scala is an object oriented language at heart, and I find it makes functional programming a bit cumbersome - things that are clear and (subjectively) elegant in Haskell is often a bit cluttered in Scala, for me anyway. There's also no purity. You can do a lot of things with libraries like scalaz or cats, but I can't shake the feeling that I'm working against the language. Subtyping hampers type inference, which makes many things unnecessarily verbose. That goes for sum types as well, which are simulated with inheritance. Even functions are simulated, using a trait with a method. The details elude me at the moment, but some limitation about polymorphism means you often have to use methods directly anyway. But then you can't use the function composition operator... Speaking of which, lens composition in monocle requires specific operators that depend on what kind of optics you compose (not sure why), whereas in Haskell it's just the regular function composition operator. These are just some gripes off the top of my head, I could go on. As for the oposite, Scala does object orientation and "better Java" better than Haskell, especially since it's so tightly integrated with Java that it doesn't need an FFI. That gives you access to commercially backed battle tested libraries like Akka, or even pure Java libraries with relatively little pain. As for "ascending", it really depends on what you want in the end.
Does it give you great joy to spend so much energy being a dick to people who have done you no wrong? Seriously, if this post was *so* offensive to you, why didn't you just ignore it?
I have never used Scala, but I have used Ocaml, another mainly functional language. The reason I switched from Ocaml to Haskell was that I saw Haskell's strict control over side effects as a distinct advantage. Over 10 years later I still think this is a advantage.
So much awesome news lately! :) I honestly never expected so much focus to come on getting GHC on the web. It's always had mostly a niche community in our already niche community. Best of luck with finding devs for the position! (haven't really hacked on GHC before..) 
Purchased, thanks!!
I wonder the same thing, how sad it is the time and energy spent shitposting. 
It‚Äôs funny reading this as a third party observer and seeing how wildly off you are in your interpretation of OP‚Äôs tone.
We discussed most of these issues in [this thread](https://www.reddit.com/r/haskell/comments/ahhmtn/this_page_is_rendered_by_reflexdom_compiled_via/). TL;DR: I think codesize and SharedArrayBuffer are solvable problems, probably requiring less work than implementing an RTS from scratch. Plus SharedArrayBuffer is not a problem at all for non-browser environments like NodeJS or hosting a smart contract system. &gt; It also requires a much more complex toolchain. Counterpoint: That toolchain is more powerful, and it plugs into more infrastructures more easily. Building Reflex-DOM apps, for instance, proved fairly trivial since it plugged into Nixpkgs so well. You're going to need the same toolchain anyway if you're going to support C code.
I don't get the idea of that fix. Could you explain a bit more?
Okay, so the idea is that `cntEx guess'` would be replaced with this function: func a' | a' &lt; a = cntEx [] a' func a' = cntEx guess' a'
I tried that modification on your code. [...] Nothing -&gt; case [r | r &lt;- toList everything , let guess' = (a,r) : guess func a' | a' &lt; a = cntEx [] a' | otherwise = cntEx guess' a' , not . pointEq $ func ] of [...] It goes to infinite loop and aborted with &lt;stack overflow&gt;. Then I tried a random shoot: replaced `[]` with `guess`. That version seems working. I have totally no idea whether/why that is working though.
Derp, talking out my butt I guess. Good that that your version seems to be working though.
&gt; non-browser environments like NodeJS In such environments native compilation is usually available, no?
I love SonicPi, so I‚Äôm going to have to spend some time with Tidal. Very cool. 
This is really interesting!
it seems to only build on 8.4 atm? :( https://matrix.hackage.haskell.org/#/package/typograffiti
I've spent 3 weeks to look around (not full time). The results where: a) Haskell has significant scaling issues that won't be fixed in the near to medium future. The comment goes along the lines of Haskell can't scale beyond 4 threads/cores (today's CPUs have 64 to 120 threads) https://www.reddit.com/r/haskell/comments/agbjzd/is_amd_threadripper_2_performance_better_than/ee80jmb b) Haskell is not good for numeric data c) Haskell is not good for performance critical stuff in general (hence the commercial haskell companies always bind to commercial or possibly C FFI code, according to the CEO of fpcomplete d) The "maintainer" of the vector-algorithm has been looking for some replacement who has time to fix stuff, because he said he has no time e) any code that optimizes cache use (also branch prediction) will always beat haskell code by a very high margin. The reason the fastest Haskell and rust, etc. lib use insertion sort is because it has the best caching aspects, not because of the "algorithm" (for n not too big). f) if AMD would implement SIMD as efficient as Intel, one could at least use SIMD (which Haskell supports in a partial manner, the last time I lchecked). But since AMD is ahead in the thread count, and I might get an AMD CPU soon, optimizing for SIMD doesn't make sense to me ‚Äì however, a very naive SIMD implementation is still a lot ahead to anything that doesn't use SIMD If you think just for fun you want to implement a pattern defeating quicksort in Haskell, I would be glad to join that effort.
I've had some issues with continuation indents, have you found any workarounds (sorry to revive a dead thread) 
/u/merlin_thp Just released a new version which has Num instances for Coord, etc. I leave the Modulus vs Clamp decision up to combinators instead of having multiple Coord types and it seems to work okay so far. I also added some pretty cool automatic convolution combinators! Just use a type application to provide the window size and it'll run functions on surrounding contexts for you! Also added an arbitrary sized grid permutation combinator; e.g. `permute @[1, 0]` does a 2D matrix transpose, but it scales to any size or dimension of grid! Check it out! http://hackage.haskell.org/package/grids
Do you have benchmarks for [vector-algorithms](https://www.stackage.org/lts-13.4/package/vector-algorithms-0.8.0.1) vs. Rust? Where are you getting the "6x" estimate from?
Looks like the 8.6 problems are some monad fail stuff, shouldn‚Äôt be hard to fix.
Hero
One of the reasons some people are interested in WebAssembly (particularly for smart contracts) is that it's a host agnostic platform that's well sandboxed. Native compilation is not compatible with this.
Awesome. I'm impressed with it so far.
...is that the only time you've heard of Philip Waller?
1. Typeclasses are typically more convenient than 'implicit'. 2. Nicer syntax. 3. Enforced immutability. 4. With GHC extensions, a lot of types you can't represent in Scala, even some dependent typing.
Lil Data, affiliated with the label PC Music (hyperkinetic super fun post ironic pop music) uses TidalCycles a lot. PC Music and haskell are two of my favorite things and it‚Äôs really cool that there‚Äôs a connection between them, though it makes me feel a little less unique lol.
It would take 5 - 10 minutes, which got really tiring for a hobby project where you have to do print-like debugging (JHC has no symbolic debugger, to my knowledge). The development cycle just got to be too much. If you can reduce this, I would take up the project again. 
Pretty cool though I personally find Renick Bell to create more interesting sounds
1-3: +1 Re 4: Actually, I think Scala's path types have been sort of informally shown to be equivalent to Pi types. ISTR a video with a back on forth between an Idris developer and a Scala expert and while the Scala was generally longer, it was able to make the same types of guarantees. It also seemed that the Scala code size and the Idris code size was a at most linear function -- which means the approaches would scale, even if they weren't ever as succinct.
Haskell * Does compile on my rooted phone - and on a raspberry * Produces a native executable, not a VM-language * Is non-strict, so the compiler has _the right_ to rearrange your code and skip execution Scala * Failed to compile a trivial program before the end of the day * Needs a JVM I stopped using Scala because of the huge compilation times on small hardware.
I'm just getting started with haskell and have a really simple question regarding comment convention, specifically with block comments. I understand that anything between `{-` and `-}` will be interpreted as a comment. The default behaviour in my vim configuration is to start each new line within this comment block with ` - `. Is this a vim thing or how multi line comments are conventionally written in haskell?
Is latest beta (from alpha channel or GitHub) affected?
You also need to throw in some version bounds at https://hackage.haskell.org/package/typograffiti-0.1.0.1/dependencies
In what country do you get 'employed' on paper and does that country have some form of social benefits programme? 5 days paid sick leave is really ... low
Firstly and most importantly, it is very impressive what you have done with WebGHC! Great work! However, I don't quite agree that you discussed the issues I mentioned in the thread that you reference. You do acknowledge the issues, but I don't see a clear path to technical solutions. In particular, I am very sceptical that you are going to get away without major changes to the RTS (to get good space and runtime efficiency). Moreover, you'll most likely need to fiddle quite deeply with code gen and/or some of the downstream tooling, too. (Also, comparing to GHCJS for code size is a low bar. I was also missing runtime performance numbers.) In any case, I'd love to be proven wrong about these issues being very hard nuts to crack. 
[removed]
The Funk Monad over Shuffle Triplets
When you're talking about changes to the RTS, would these changes be beneficial to native code, or is it some sort of fine tuning that would be beneficial for WASM but detrimental for native performance? I would rather end up with a single RTS, not two. Bonus question: if you are to implement a new RTS, have you considered Rust for the purpose? It would offer memory safety, I think.
Can you talk about what you are building? What does a typical day look like? What are the hours like? Salary? I am moving to NYC next week and am looking for a position
I am talking about changes to the RTS that introduce WASM-specific code, for example, by way of #ifdefs. Hence, it may be one code base, but they are still independent code paths with the associated maintenance overhead. It is just not realistic to expect that, for example, a GC implementation optimised for an unrestricted native arch is going to perform well on a managed runtime. Re Rust: it is a nice thought experiment, but given that the GHC toolchain, if anything, is already too complex with too many dependencies, I am not sure it is worth the trouble.
I think I understand it now! [Very rough proof sketch of "probably working" version is actually working](https://gist.github.com/viercc/3e1811f332fb3753652486800babc419) (Note that the above gist uses `Searchable`, but it is not essentially different than your `Flist`.)
&gt; I am very sceptical that you are going to get away without major changes to the RTS (to get good space and runtime efficiency). Moreover, you'll most likely need to fiddle quite deeply with code gen and/or some of the downstream tooling, too Both of these points seem like conjecture, and I don't see any reason to believe them. If the RTS needs major changes to get good efficiency, are you arguing that native GHC does not have an efficient RTS? I don't think efficiency is one of the reasons we'd have to modify the RTS. An actual reason we'd have to modify it is to eliminate SharedArrayBuffer. That goal may *seem* like something that'd require codegen changes, but I believe the Haskell / Cmm code is high level enough that mere changes to the RTS can eliminate all blocking performed by any non-c-FFI code. Even if changes to the RTS are more major than I'm anticipating, major changes to an existing RTS are still a much more acceptable cost than writing an RTS from scratch as GHCJS and Asterius do. Writing your own RTS is an easy way to lose a lot of the man hours that have gone into making GHC efficient and stable. I see no reason we'd need to fiddle with downstream tooling. The toolchain we've developed is specifically designed to avoid this problem as much as possible. Admittedly, cabal-install could use some shortcuts for cross compiling, but the technical part of the problem is already solved. For instance, we needed nearly zero changes to nixpkgs to build things as complicated as Reflex-DOM and Miso apps. &gt; Also, comparing to GHCJS for code size is a low bar. I was also missing runtime performance numbers This is true. But the other reasonable bar (comparing to native codegen size of GHC) isn't much better, and it's very difficult to beat that bar using only the Cmm-&gt;wasm layer. I think GHC has inherent Core-level problems at the root of the codesize issue, so any Haskell-&gt;web solution will need to solve this problem. Performance numbers are an area I intend to explore soon. I've done a little bit with the aeson benchmarks and found WebGHC to be faster than GHCJS in all of those. I'll make a blog post when I have better numbers though. Plus, our plans to switch to GHC's LLVM backend should improve both performance and codesize dramatically. We'll still have trampolines until wasm provides a tailcall instruction, but I think this will be the only major perf difference from native, and any Haskell-&gt;web solution will have this problem.
&gt; It is just not realistic to expect that, for example, a GC implementation optimised for an unrestricted native arch is going to perform well on a managed runtime. Why? The restrictions placed on wasm are mostly about sandboxing, not anything that would impact a GC. GHCJS having to provide its own GC to cooperate with the JS GC has been a major perf problem. The WebGHC GC seems to run identically to the native GHC one
In terms of types, how do you think Eta addresses the limitations of and the compatibility with the JVM?
I agree that can work too. A lot depends on the maturity of the software development process. If management knows what they are doing then things like the build process are automated and no code makes it to production without things like PRs and code reviews. Kind of hard to sneak something in with a mature software development process that focuses on automation, communication, and teamwork. If on the other hand you're at a company like OP and they are still figuring this stuff out, then you might have a much better chance of just doing it. But if you're going to do that, probably best to not talk about it. OP could have just delivered the solution without mentioning Haskell. Repeat a dozen times and now the company has a portfolio of assets in Haskell. Might also get you fired though. I would personally rather just be transparent about what I'm doing.
We're working on a quite diverse set of projects so specifics about the day/what you're building vary a lot. My hours in the London office are usually 9-17. I encourage you to send an email to get to know more!
As someone who works at IOHK on a compiler, I say just go apply there if you're interested in compilers and web. The entire community will benefit from this fully open-source work.
While generally correct, that depends a lot on what "latency-sensitive applications" means here. There are many things that become completely unworkable at 2-4 seconds latency, even basic web server use cases. Consider a Haskell server that does some significant processing or has many concurrent websocket clients connected; having "the occasional 4 seconds hang" is pretty devastating here.
In one of the links I provided, https://mazzo.li/posts/haskell-parallelizing.html, we discuss how we implemented a distributed particle filter. Its main goal was throughput to finish a 10-minute simulation as fast as possible. But To do so, it needed to perform many iterations of jobs being sharded out to a cluster, running there for ~10 ms, and being combined back before the next step could run. So that part was latency sensitive: One of the many machines being in a 1-second GC would make all other threads wait for the additional 990 ms. If you have many machines, this is likely to happen for one of them, so in that example it would total throughput of the overall system by 100x. Here the workaround was indeed to have each machine run multiple independent processes so that each one's heap would be small and the worst case of GC time bounded. But it was effort to do this workaround, it would have been nicer if Haskell didn't have that problem.
That's a nice idea, but I'm not sure it's realistic to be addressed in a GSoC. It's a decade-old issue and many ghc experts have commented on it (https://ghc.haskell.org/trac/ghc/ticket/9221). It would be tough to demand from a student to fix a hard problem like this within a few months.
Monad transformers: `MaybeT`, `StateT s`... `Compose f`, `Sum f`, `Product f`... (from `Data.Functor.*` in base)
I don't understand what you are trying to say here. WebGHC using the native GHC collector does result in related situation as with GHCJS, does it not? The Haskell land GC has to cooperate with JS GC, right? To get around that two garbage collector problem, you need a single GC along the lines of the WebAssembly proposal https://github.com/WebAssembly/proposals/issues/16 How do you think you can make use of that WASM proposal with the approach you are proposing?
I'm pretty sure path types aren't equivalent to full Pi types but rather the kind of stuff you can do in GHC with singletons and GADTs.
WebGHC makes sparing to no use of the JS GC. GHCJS's GC has been problematic in the past for two reasons: 1. It maintains its own heap with its own GC, but still relies on the JS GC for deallocation. This inherently causes double the pause times, as the entire heap is traversed twice (once for each GC). It also limits the allocation rate and throughput. And it creates less predictable pause distributions with no ability to manually trigger the JS GC. 2. Being maintained by much fewer developers, and used by much fewer users, the GC has been a little buggy. WebGHC (and presumably Asterius) by contrast, only requires a very small JS heap. All the data managed by WebGHC's GC is binary data in linear memory, so it's managed only by the GHC GC running in wasm. There are no JavaScript objects backing Haskell objects. The WebAssembly GC proposal seems nearly worthless to me. No GC is suitable for all languages, and wasm is supposed to be guest language agnostic. For instance, JS's GC would be awful for GHCJS if GHCJS hadn't implemented it's wrapper GC. The JS GC cannot do essential GC optimizations such as [selector thunk optimization](https://ghc.haskell.org/trac/ghc/wiki/Commentary/Rts/Storage/HeapObjects#Selectorthunks), so GHCJS does that itself. And it still can't achieve native GHC's lightning fast allocation speeds, which I believe WebGHC does get (though I haven't measured this yet).
Yay, I purchased two immediately (one for me, and one for someone else somewhere down the road)! Seriously thank you so much for writing this book. I am so appreciative, and I haven't even read it yet! I'm excitedly waiting for them to arrive!
As I wrote above, I'd love to be proven wrong. In any case, I am not convinced that rewriting the necessary parts of the RTS is such a big deal. Moreover, that provides the opportunity to integrate with forthcoming features on the WASM roadmap like support for GC and multi-threading. Moreover, any WASM feature that you want to use, you need exposed through LLVM. This leads to tooling dependencies and delays. We are seeing this already with WebGHC's current inability to use the LLVM backend right now. (Just look at the tooling grief that the LLVM backend all by itself has caused GHC over the years.)
You've done your homework. My apologies for having to ask the "is it plugged in" question, but as I'm sure you've seen on the Internet, the answer is quite frequently "no". In which case, I'd reiterate my first point; if you're talking about running on a 64-core system then you've clearly got the RAM to hold a few thousand of these in memory at once. If you can send them over in bulk, your FFI costs amortize to basically zero. I'm saying "if" because I recognize the possibility that these could be 100% serial in nature, in which, uhhh, bummer. But likely there's some sort of parallelism that can be exploited to send these over in bulk.
I guess, this is were our technical approaches diverge: you regard anything in WASM beyond the MVP as useless to WebGHC, whereas I'd prefer to take the opportunity to influence how WASM develops to make sure that it provides support that is useful to Haskell. After all, WASM is still malleable.
Haskell has a vibrant community, with fans from the academia, many very smart people are in and around Haskell
&gt; In any case, I am not convinced that rewriting the necessary parts of the RTS is such a big deal I think you're underestimating how difficult it is to produce a working, stable, and efficient RTS. Consider the countless man hours that have been put into GHC's, especially the highly tailored GC. &gt; that provides the opportunity to integrate with forthcoming features on the WASM roadmap like support for GC As I said in the other comment, you don't want that GC. It will perform absolutely terribly for GHC and it will not support necessary features like weak references. &gt; and multi-threading I don't follow. Why is this a barrier in WebGHC? We'll simply implement the subset of pthreads that we need in the same way that Emscripten does and we'll get `-threaded` for free. Heck, if we could figure out how to tear down Emscripten's tooling and extract its runtime, we could do this on chrome today. &gt; Moreover, any WASM feature that you want to use, you need exposed through LLVM. This leads to tooling dependencies and delays. While this is true, I don't see it as significant. LLVM gets new wasm features pretty instantly.=, and wasm/LLVM already have almost everything that GHC needs. &gt; We are seeing this already with WebGHC's current inability to use the LLVM backend right now. Note that this is not an *inability*, it was a conscious decision on my part to avoid needing to implement `ghccc` in LLVM. I didn't want to have to juggle RTS *and* codegen bugs at the same time while getting started. Now that we have a pretty good RTS, implementing `ghccc` in LLVM is my next goal, and I suspect it won't be a significant barrier. &gt; (Just look at the tooling grief that the LLVM backend all by itself has caused GHC over the years.) Yea, but Moritz has been making strides with his llvmng backend, which will solve the majority of those issues. This is the branch I intend to start with for WebGHC's LLVM backend.
As a full-time Haskeller, I agree so much with this! The terse syntax means that you're building on-the-spot DSLs all the time. And you don't do anything fancy even, you just create a binding for a partially applied higher order function and you get something that would virtually be indistinguishable from a keyword to a non-Haskeller. Something like: ``` let abc = either toJSON somefunc a &lt;| b = maybe someotherfunc ``` Sets the scene for concisely describing what you want in the following lines. 
&gt; you regard anything in WASM beyond the MVP as useless to WebGHC I think that's an overgeneralization. Certainly I'm eagerly awaiting threading, [host-bindings](https://github.com/WebAssembly/host-bindings/), and [tail-call](https://github.com/WebAssembly/tail-call/). I just have to be realistic about expectations for the GC proposal. Haskell's GC is very specialized niche and I cannot see a path forward that allows Haskell to use the wasm GC efficiently.
Haskell plans to implement real dependent typing, in the core of its type system; Scala plans only some path-dependent thingy
Can you describe the gap between "GHC with singletons and GADTs" and "full Pi types" other than syntax?
I'd be very interested in seeing this video, I've dabbled a bit in Idris...
What os do you use? I'm guessing definitely not windows. 
What version are you using on phone? I'm currently stuck on 8.0.2, tried upgrading but didn't find any info about ghc on arm for later versions.
NixOS at home, Ubuntu at work
I'm pretty sure it was [Scala vs Idris: Dependent Types, Now and in the Future](https://www.infoq.com/presentations/scala-idris).
Personally, I find this ` - ` prefix on comment lines useless, so I remove it on the first line, and vim doesn't try and add it to the next lines. I'm pretty sure there's a way to turn that comment formatting off, just an I'm fairly sure it's a vim behavior adopted for C++/Java `/* */` block comments.
Thanks for the purchases and the kind words! I'm happy it's being read!
Very interesting, thanks for the demo. I noticed that if I rapidly enter todo items by banging on the keyboard, it sometimes breaks: https://ludios.org/tmp/todomvc.png https://ludios.org/tmp/todomvc2.png (Chromium 71.0.3578.98 on NixOS master)
Looks like these two issues: - https://github.com/WebGHC/jsaddle-wasm/issues/5 - https://github.com/WebGHC/jsaddle-wasm/issues/4
Well, your version is basically the same as the one in https://www.cs.bham.ac.uk/~mhe/papers/exhaustive.pdf (definition 4.4) when applied to `not . pointEq`, so if you want a formal proof, you can use the one found there.
Though if you do this everywhere you get spectacularly awful compile times.
&gt; Curry: In scala your function can have one parameter list with multiple parameters, or multiple parameter lists with one parameter each and everything in between. In Haskell a distinction between these alternatives would not make sense and there is no distinction between these. That Haskell's approach is more elegant or more abstract in this case is not at all obvious to me. Of all the things to mention, why this?
Hi! OP here. I'm still new to Haskell, but I wrote up what I thought was useful while trying to implement RSS &amp; Atom feeds with hakyll. Hope it helps someone!
At the very least, it sounds like it would be nice if the RTS allowed the programmer to shard up the heap like you were doing with multiple processes. A similar type of solution as compact regions in a way. StrawmanAPI: ``` newHeap :: IO Heap usingHeap :: Heap -&gt; IO a -&gt; IO a ```
Thank you for the pointer. I skimmed that and it looks like my "random shoot" was the correct one. I'll read it more carefully later.
AFAIK it's an abbreviation of "Strategists". Strats are, or work with, Quants to develop pricing and other algorithms to support traders or to do algo\[rithmic\] trading.
Oh my! Thank you so much for this. Going to add to my posts (some on hakyll, itself! e.g., https://robertwpearce.com/hakyll-pt-3-generating-rss-and-atom-xml-feeds.html). Would you know how to easily generate a `onedark` theme? I looked at filling in all the colors in a pandoc template, but that was difficult, and I eventually gave up.
7.6.3, I'm afraid I can't help here :) root@localhost:~# ghc --version The Glorious Glasgow Haskell Compilation System, version 7.6.3 And for stack 1.9.3 : root@localhost:~/tmp# stack setup ... Downloaded lts-13.4 build plan. I don't know how to install GHC for (Linux,AArch64), please install manually 
Great to see another south american haskeller! Since you are using docker with arch linux, how big are your docker images? We are using ubuntu as our base image and our images are about 170 MB, using 'stack image container'.
I'm working on [Advent of Code 2018 Day 8](https://adventofcode.com/2018/day/8) and [my solution](https://github.com/shterrett/advent-2018/blob/master/src/Day8.hs) is fine. It includes the following types: buildTree :: [Integer] -&gt; (Node, [Integer]) processChildren :: [[a] -&gt; (b, [a])] -&gt; [a] -&gt; ([b], [a]) This looks suspiciously monadic, and so in a [separate branch](), I gave that a shot data Monoid a =&gt; Consumer a b = Consumer { results :: a , source :: b } deriving (Show, Eq) instance Monoid a =&gt; Monad (Consumer a) where return b = Consumer mempty b (&gt;&gt;=) (Consumer a bs) f = let (Consumer a' bs') = f bs in Consumer (mappend a a') bs' which changes the above signatures to buildTree :: [Integer] -&gt; Consumer [Node] [Integer] and removes the nead for the `processChildren` function; substituting `foldl' (&gt;&gt;=) (Consumer [] ds) (take' nc $ repeat buildTree)` in the `buildTree` function. This also works, but it "pollutes" the functions with the extra singleton lists. I'd appreciate a theoretical and aesthetic evaluation of the two options and any other pertinent advice. Thanks!
/u/gelisam This is fantastic! I was actually contemplating creating haddock comments myself to force myself to understand this library better. Is there some way I can help you get that documentation merged upstream? E.g. review some PR somewhere, or try out the code locally, report some typos somewhere etc.?
Thank you so much for sharing how you built out your blog, it‚Äôs a big help to walk through someone else‚Äôs project in such great detail. Really appreciate it. 
Here's a gap: Full dependent functions allow writing a function that takes an integer $n$ and returns a function with $n$ arguments, with $n$ only known at compile-time. With GHC, this can't be done if you want the number of arguments to be checked by the compiler. So, for example, you might want a function with type $\Pi_{n:Int}
Yes, that's what's going on.
Update: I'm going to take another crack at writing up a theme like https://github.com/tajmone/pandoc-goodies/blob/master/skylighting-themes/breeze-dark.theme and then storing the theme and output.
In haskell, If I have a function that I want to use as a curried function, I can just do it without any problems, and the syntax is the same for every function. In scala, I need to call a function depending on how it was defined. Yes you can still partially apply a function even if it wasn't written with multiple parameter lists, but the syntax changes based on how the function was defined. I can define two functions in Scala that have identical semantics but have different syntax required to call them.
I believe you can actually do this with singletons today. It's late so I can't some up with an example now, but I'll work on it.
You can do that in Haskell, too (modulo bottom at tuple types), we just don't.
&gt; But I feel that this is in part because the language has built in support for integer arithmetic and array operations. If you try to do these proofs in Coq, Agda or Idris they become messy because you have to make all this reasoning explicit. There are many theorems about integers in Coq's stdlib, so this is just tedious (and yes, messy). That was not what I found hard when proving fulcrum in Coq however!
I had this functionality using hdevtools + vim-hdevtools a while ago but switch to hdevtools + ale since then
Thanks for your quite interesting discussion @chak und @ElvishJerricco! At the end I've the slight feeling that a language with a GC might not be the best for targeting WASM. Even just having any kind of runtime already seems to complicate things quite a bit. 
We also use CCI for building/packaging/releasing Haskell stuff. No blog posts yet, but this stuff works quite well, have a look: https://github.com/haskell-works/hw-circleci-orbs
&gt; I stopped using Scala because of the huge compilation times on small hardware. Yeah, but at least you can trivially compile a `.jar` on your machine then copy it over (instead of having to build a cross-compiler from scratch)... &gt; Failed to compile a trivial program before the end of the day I don't like Scala much, but this seems a bit unfair. GHC's non-termination is pretty terrible too. that said, `implicit`'s and `Lazy` make it way too easy to send the compiler hunting down an outrageously large search tree. 
&gt; I stopped using Scala because of the huge compilation times on small hardware. How do you manage to build anything Haskell on small hardware? I tried `stack build -j1` but stack would either thrash or be killed by the os. Does cabal work better?
Just that the semantics of the type level language are not the same as, and do not contain, the value-level language.
There's a couple [Poppy](https://www.cs.cmu.edu/~dga/papers/zhou-sea2013.pdf) implementations in Haskell, which is a succinct dictionary structure, meaning it's a structure sized at roughly the information-theoretic minimum while still providing efficient rank/select queries ([big video about this](https://www.twitch.tv/videos/291249101)). [Information-theoretic minimum](https://en.wikipedia.org/wiki/Succinct_data_structure#Entropy-compressed_dictionaries) here means if I have a bitstring of length `n` with `k` 1s, then there's only `n choose k` possible bitstrings like that, and so I can just write down that number as a compressed representation of the original bitstring. The more biased your bitstring is towards 0s or 1s, the more compression you get. Succinct structures are supposed to be roughly proportional to this size, while also providing efficient rank/select ops. But this is not the size I'm seeing in either of the Haskell Poppy implementations. In both [this one](https://github.com/haskell-works/hw-rankselect/blob/master/src/HaskellWorks/Data/RankSelect/CsPoppy.hs#L87) and [this one](https://github.com/ekmett/succinct/blob/master/src/Succinct/Dictionary/Poppy.hs#L89), they actually store the original bitvector untouched inside the Poppy structure! And as far as I can see, it's [used when computing rank](https://github.com/haskell-works/hw-rankselect/blob/master/src/HaskellWorks/Data/RankSelect/CsPoppy.hs#L117), which means it's not just there for decoration. Needless to say, when I tried this on my sparse bitvector, the actual size of Poppy was not anywhere near what I expected it to be. So I think I've missed something here, either in my understanding of the original concept of the structure or in the API for how to use this. What am I missing?
I use cabal - with cabal sandboxes, isolation of librairies work without needing a specific GHC each time (it's a good thing, but overwhelming on that hardware) Mostly to compile projecteuler trial solutions, but Scala was completely unusable - Haskell being nicer than Python and Node, .. and functional.
&gt; hunting down an outrageously large search tree Fair enough, and I often provide type annotations for my functions. I'm talking from a usability perspective - Scala just didn't work. Maybe I could have forged my source files in some way to help the compiler.
\&gt; Oh my! Thank you so much for this. Going to add to my posts (some on hakyll, itself! e.g., [https://robertwpearce.com/hakyll-pt-3-generating-rss-and-atom-xml-feeds.html](https://robertwpearce.com/hakyll-pt-3-generating-rss-and-atom-xml-feeds.html)). &amp;#x200B; Thanks! Glad you found it useful. &amp;#x200B; \&gt; Would you know how to easily generate a \`onedark\` theme? I looked at filling in all the colors in a pandoc template, but that was difficult, and I eventually gave up. &amp;#x200B; I don't see an automated way to do that. &amp;#x200B; \&gt; Update: I'm going to take another crack at writing up a theme like [https://github.com/tajmone/pandoc-goodies/blob/master/skylighting-themes/breeze-dark.theme](https://github.com/tajmone/pandoc-goodies/blob/master/skylighting-themes/breeze-dark.theme) and then storing the theme and output. &amp;#x200B; Nice! Keep us posted
Depends on what you mean by "in production".
You don‚Äôt need anything fancy to use Haskell in production. I first used Haskell in production in 1995; it was a much simpler language back then, but still perfectly adequate. 
I started to look at haskell about 10 years ago, I think I started to use it first in prod about 5 years later. And I think I knew only a small part of what I know today about the language. I used Haskell for what it is the best in class in my opinion; parsing + streaming + concurrency. I really started to be able to write prod ready program when I really started to write a program for the prod. I learned what I really need during the creation of that program. And mostly I never experienced any blocker of any sort. I think you can start to make quite great and prod ready‚Ñ¢ programs by only knowing about 5% of the total amount of knowledge about Haskell ecosystem. And I think the best starting point to write "prod ready‚Ñ¢" program in Haskell would be that blog post: https://jaspervdj.be/posts/2018-03-08-handle-pattern.html Along with this example project: https://github.com/jaspervdj/fugacious I would have loved to have that ressource back then.
I was tinkering with it for about a year on personal time before I felt like I could get away with using it at work without anyone having the perception that it was slowing us down. So I used it for a project at work that I was working on solo at the time. Have not had to use typescript in any meaningful capacity since then. Haskell is a wonderful language but it‚Äôs learning curve is no joke. I was the most senior developer at the time so it was very important that I could manage the perception of my work output. So I could probably have tinkered for a lot less than a year before I could write a full app in it that was ready for minor league production, but quite likely not at the rate that I could have in TS which would have severely hurt Haskell‚Äôs prospects at work politically. The situation was quite different for our other devs on Haskell projects because they had the benefit of me having done some of the bushwhacking. So most of them had only been introduced to the language about 3 months or so before they were completing features in existing code based of mine. So the real question is about how much support you have from your environment. If you have team members already productive in it you‚Äôll have a way easier time then if you‚Äôre trying to introduce Haskell to the workplace for the first time.
Learning Haskell has been a series of walls for me. Before each wall, I think "This is hard, maybe I don't need to learn it, why is it so complicated." Eventually I force myself to understand it (or something just clicks.) After each wall, I think "this is completely natural, I couldn't live without it, I pity programmers who can't make their lives simpler with this." Some examples of my "past walls": * IO * laziness * monads * software transactional memory * parser combinators I never learn my lesson about future walls (I still go through procrastination and anguish instead of just staying calming and learning it). Some examples of "future walls": * the state monad * Stack / Stackage * lenses As for your question, I started using Haskell at work once I understood IO - just for simple tools - but they were still very useful to me. These days I use Haskell for nearly all side projects. Currently at work I'm using Scala (wishing it were Haskell.)
`Consumer` is also called the writer monad, and it is implemented in base for `(,)` https://hackage.haskell.org/package/base-4.12.0.0/docs/Control-Monad.html#t:Monad
I studied Haskell off and on for like 5 years (mostly off) and after I had convinced my boss to use Elm for a new project I later convinced him to use Haskell because it‚Äôs just ‚ÄúElm for the server‚Äù. When I started the project I had no idea what I was doing I just picked a framework (Yesod) and put things where it said to put things and prayed it worked. So I had production code before I really ‚Äúknew‚Äù the language. Over the last year and a half I‚Äôve had the opportunity to learn the language and libraries and extensions far more then I would have just reading books like I was before. I don‚Äôt know when I become completely confident, but the ‚Äúif it compiles it will work‚Äù saying gave me quite a bit at first and I‚Äôd say for the most part that saying is true. These days we have people who come out of a JS/web boot camp, learn Elm, then help with our Haskell project within a few months time span. Are they confident? I assume so.
Confession: Personally it took me around 5 years to get confident with haskell. I used to be ashamed to admit that, as I see some people reach the level I am at within a year or two. But I just learn differently I guess. In the sense that : I can open up a codebase and understand what's going on. I know when to use what extensions ( I think?) and I know how to sort of structure an application. Most importantly, it took me a lot of time to not be scared to look up things in documentation or to ASK people things. In the beginning of Haskell I struggled with a lot of 'basic' things. I didn't understand the difference between foldl and foldr, didn't have a good grasp of laziness, couldn't work with monad transformers. Things take time to sink in and to click. What did give me an enormous boost of confidence though, was that you \_dont need\_ all the advanced stuff to be productive. I just started hacking on projects, eventhough I didn't even fully grasp was recursion was (which turned out to be a great strategy, as its way more fun to use pre-defined building blocks like fold, map, traverse, than writing recursion manually). many of haskell's important concepts only sinked in way later for me. But that didn't stop me writing fun stuff. I made some games, built some stuff in yesod, made some CLI tools. It was fun. So my advice is: Be confident, eventhough you think you know nothing. Because haskell is already pretty productive right from the beginning. I knew nothing for a very long time, but that didn't stop me from writing fun projects
I worked for a small marketing agency when I first released a Haskell tool in production. I had been learning Haskell (as a first language) for about a year. The application simply took in various CSV files, parsed and combined the data, and then applied various processing or scoring to it. For example, it might take data from Ahrefs, DeepCrawl, and Google Analytics to understand which keywords were bringing competitors traffic and bringing our client sales and not too competitive to invest in. Reasonably simple stuff! Someone else might have put out the first version of the tool in Python without any raised eyebrows. It worked reliably and saved us a ton of time, so more Haskell went into production: a reporting dashboard with Haskell / PureScript, more automation tools, a miniature web crawler and link index like Ahrefs / Google, and so on. I had gone through Haskell Programming from First Principles by the time I began writing these tools. But I didn‚Äôt understand lenses, monad transformers, any language extensions more complicated than OverloadedStrings, and I wrote some terrible code. But the code did its job, and that kept Haskell in production. I subscribed to a comment I‚Äôd heard from Michael Snoyman at the time: treat Haskell like a boring, safe language that‚Äôs excellent for writing correct software quickly (when you‚Äôre writing it for work), not as a beautiful, elegant, fascinating language that deserves only perfect code and abstractions. That helped me avoid paralyzing myself. The gist of all this is: Haskell went into production fairly quickly after I learned the language, and it took nothing fancier than the first 17 chapters or so of HPFFP (up to Monad).
As long as it takes you to become really comfortable with lens. Comfortable and willing to apply them anywhere possible.
While it's certainly interesting to hear ideas that improve scalability of smart contract systems, I find it difficult to pin down exactly what Fae is. The documentation was very hard for me to read. It seems like it's trying to both explain the Fae concepts and operations while also the parts of Haskell it makes use of. Yet after going through both the reference text and the tutorials Fae, remains nebulous to me. I'll try to elaborate on how I found it lacking below. To be fair I did not run the docker containers and didn't try and inspect how they work. As such, the place of Haskell is described as being just an implementation, Fae (sometimes?) as a VM, yet there is no description of any DSL primitives, and the ["Formal Specification"](https://github.com/destenson/ConsenSys--Fae/blob/master/docs/Specification.md#smart-contracts) elaborates that "everything is a smart contract". The system is also independent of a consensus mechanism (e.g. proof of work, central server, what have you.) To what extent does the system rely on the consistency of the Haskell type system? The escrow tutorial talks about not exporting a newtype constructor as a means of introducing scarcity, but with no apparent representation of contracts and escrows beyond their names, ids, and arguments etc. how do different actors know what code to execute? Are they expected to have shared the contract definitions out-of-band and identify contracts by name only? (So as such transactions are given meaning only inasmuch as the concerned parties endow it with their signatures? In spite of my confusion, this looks like promising idea) Would it be fair to characterise Fae as a network protocol description that can be used as part of a decentralised smart contract system, rather than an alternative to ethereum? With so many essential pieces of infrastructure left abstract (underlying consensus mechanism, haskell as an (incidental?) implementation language), what useful properties can I derive from statements such as "App a uses Fae", "App b uses Fae"? Can I expect any interoperability between the two? Is "using Fae" just a technical implementation detail? As such this project looks like it has some interesting ideas, but it's a bit hard for me to really tell how the parts fit together. Best of luck with it though.
Why it's more composable? That's the part I don't get. With schemas, is mostly map manipulation (and in that sense, we can use any tool that does it in Clojure, even external libraries). As for generative testing, I do agree but there are libraries that tie prismatic-schema with test.check...
Pardon me for side tracking, but I was surprised to see the state monad as a future wall, with monads in general as a past wall. I'm curious what is the missing link there - what is it about State in particular that needs to be learned separately from Monad?
Asking is a huge win. r/haskell and the functionalprogramming slack channel have been critical resources to learning quickly. When in doubt ask. Don't get discouraged by the smart-ass responses that some people will give you because there are just as many if not more people who genuinely wish to help you.
"When I write in most programming languages, I must constantly accept that my program will never be robust in all the ways I want it to be, and I might as well give up before I even start. Haskell‚Äôs greatest weakness is that it tempts me to try" --Alexis King
Author of the post here, I have found one blog which teaches you Haskell by building Scheme: https://en.wikibooks.org/wiki/Write_Yourself_a_Scheme_in_48_Hours
Here's how I build, test, and distribute binaries using Travis: https://github.com/ChrisPenner/haskell-stack-travis-ci
&gt;I had convinced my boss to use Elm for a new project I later convinced him to use Haskell because it‚Äôs just ‚ÄúElm for the server‚Äù. When I started the project I had no idea what I was doing I just picked a framework (Yesod) and put things where it said to put things and prayed it worked. So I had production code before I really ‚Äúknew‚Äù the language. Either you‚Äôre exaggerating how little you knew or you are one lucky son of a bitch.
Funny. Your title says "confident", but you are asking about "comfortable". I was confident using Haskell in production after about a week. It was an existing project. Between the compiler and code reviews, I knew basically nothing I could do could really mess anything up too badly. So I was confident that I could search for a solution, even if things felt alien. Real comfort took about 3 months of daily production use. Not that I knew everything at that point. I just understood enough of how things quit working that I was able to fix mistakes, and I knew my blind spots well enough that I could figure out what I needed to learn before starting the task that needed it. 
Looks like this is a bit more involved than I thought. If I want Skylighting to work the same way as what you did &amp; the blog post you referenced, I'd need to do something like this and get it in there: https://github.com/jgm/skylighting/blob/3238154b390da1fe62a89ab1b3820c1dedd9366b/skylighting-core/src/Skylighting/Styles.hs#L24-L64. Perhaps more than I can do right now... TBD
Technically, even Rust ships with a runtime lib (`std`). Due to the lack of libc in Rust's wasm toolchain, they've had to reimplement most of that runtime specially for wasm. A GC is essentially just a library and the compiler generates code that calls it :P
It was the first ‚Äúreal world‚Äù thing I‚Äôd done. I read through LYAH but hadn‚Äôt ever really done a ‚Äúreal program‚Äù ... there was a lot of reading the Yesod book and googling and learning done. But I suppose you are correct in that I had at least read some things and done smaller (like maybe 100 lines at most) programs. I didn‚Äôt even really understand that the language had extensions but figured out real quick that when the compiler said you needed one to just put the language pragma thing up top to make things work. So far that project shows the growing pains but still works and hopefully soon will be refactored a bit which I have no fear in doing ;)
Awesome post about a particularly non-trivial, incredibly useful model testing library! For anyone interested in an example of this library in action, check out Adjoint's `libraft` library. `quickcheck-state-machine` is used to model check the example raft implementation the library provides: https://github.com/adjoint-io/raft/blob/master/test/QuickCheckStateMachine.hs
I doesn't
1. nix for dependencies 2. emacs for editing 3. flycheck / direnv-mode for immediate feedback (I highly recommend the latter for use with Nix). sometimes I use ghcid when I can't be bothered to set up a .envrc file. 4. cabal (old-style) for building 5. git for source control
Another option would be to use the `State` monad, so that buildTree :: State [Integer] Node Then instead of `processChildren`, you can use `sequenceA`. Even better `buildChildren` can be replaced by `replicateM`.
Well, not that easily. (There's some way to do this, but you end up with existential types, which are harder to deal with. And this cannot be used to make equality types (like the type EqFoo : (Eq f) =&gt; f -&gt; f -&gt; Type such that if x == y then EqFoo x y == () but if x /= y then EqFoo x y == Void).
Different monads do different things and have different implementations, e.g. Maybe, Either. The thing that makes them monadic is how they join together. I can bind together a bunch of functions returning Maybe into a single function which returns Maybe. The same goes with Either, IO, STM, Parser, Async, etc. The reason I mentioned the State monad as something that I don't understand is: * It has a really short implementation, yet I can't write it down from memory, or reinvent it from first principles (like I can with Maybe and Either). * Despite being quite a beginner concept (I think?), it hasn't been a roadblock at all for coding in Haskell.
I totally relate to this. The "walls" are an excellent explanation for it. 
Thanks for your legitimate concern. We don't intend to fix the proposal in this thread, but al least my purpose is to demostrate that it is feasible and it is worth doing it. &gt;I haven‚Äôt played around with cabal-less ghc in a while, but it looks like essentially everything not in a package is in a ‚Äúmain‚Äù package and thus equality is still based on ‚Äúpackage‚Äù + module name. I did'nt know it. Let's assign URL files to the Main package (or the Internet package) then. &gt;My question is what would happen if you imported example.com/Foo/Baz.hs and it contained import Foo.Bar. Would it search locally for it or would it search in example.com/Foo/Bar or what? &gt;I still see a lot of issues left. One is how to handle the caching aspect. Would you have to recursively traverse every url import and check if the file contents for all of them are the same every time you compile? caching should be transparent and an optimization. Whit this criterium, my intuition says that it fixes that kind of issues. &gt;Also if two files imported the ‚Äúsame‚Äù module in two different ways the types and classes would not be the same. Unlike in the case of files, The URL path has no relation with for the module name. the module name should be the string inside the file between module and where and should not match with any segment of the URL Path. For example: the URL `http://server/a/b/c.hs` c.hs could contain: module Control.Monad.JohnStack where .... This also sounds like a nightmare for dependency management and versioning unless you basically guarantee that the content at the URL never changes (like my hash suggestion). That is very critical in the case of URLs for Cabal since dependencies are at the package level. Basically it translates the responsibility of versioning and coherence fully to the package author. But in the case of URL for GHC, It is less a problem, since that kind of feature is more intended for development or research. Rapid iteration in any case. In many cases the virtuality of this functionality would the opposite of the other case: The possiblity of importing the latest changes (that may be daily) without the cumbersome of communicating files or file versions manually. If the working group need some formal versioning, there is no problem in adding version info to the path, since, as I said before, the path has no significance for the module name: For example: http://server/foo/versions/2.1.3/johnst.hs , johnst.hs has the module name: module Control.Monad.JohnStack where ....
No amount of reading made me confident or comfortable using Haskell in production. What did that, was building things and putting them in production. You don't have to understand how a monad stack or a lens interface really works before you can use one that someone else has built and stuck in a library. Pick a project that has strong support on hackage -- a web service, reddit bot, etc. -- and just try to get it up and running. Once you have an established baseline, _then_ look for ways to make the code incrementally more elegant with language extensions and better abstractions.
For what is worth, I think I managed to make it a little better by generalizing a bit the type of the trees: data Tree f a = Leaf a | Branch a (f (Tree f a)) thing :: (Applicative f) =&gt; (a -&gt; s -&gt; (f s, b)) -&gt; s -&gt; Tree f a -&gt; Tree f b thing f s (Leaf x) = Leaf y where (_, y) = f x s thing f s (Branch x ts) = Branch y tt where (ss, y) = f x s tt = (thing f) &lt;$&gt; ss &lt;*&gt; ts cothing :: (Applicative f) =&gt; (f s -&gt; a -&gt; (b, s)) -&gt; s -&gt; Tree f a -&gt; (Tree f b, s) cothing f s (Leaf x) = (Leaf y, s') where (y, s') = f (pure s) x cothing f s (Branch x ts) = (Branch y ts', s') where fs = fmap (cothing f s) ts ts' = fmap fst fs ss = fmap snd fs (y, s') = f ss x &amp;#x200B;
I'm waiting for [Kabal](https://en.wikipedia.org/wiki/Kabal_(Mortal_Kombat)), the Cabal for the Netherrealm. 
Your question reminds me of the beginning of a talk I watched recently on youtube that was an introduction to other types of functors. The presenter asked his audience at the beginning: "Who's familiar with Haskell syntax?" "Oh good - quite a few" "How many of you are familiar with Scala syntax?" "Oh, cool. Well my slides are in Haskell because that was the only way to make it fit on slides". [https://www.youtube.com/watch?v=JZPXzJ5tp9w](https://www.youtube.com/watch?v=JZPXzJ5tp9w) &amp;#x200B; For me the Haskell syntax is a big appeal over Scala. &amp;#x200B;
I was half-way through "Learn you a Haskell for Greater Good" when I found a full time Haskell job, I barely knew monads. However, my coworker was extremely helpful &amp; knowledgeable, and there was already existing codebase with a good structure &amp; types, I was able to follow along quite easily after pairing with him for a few weeks. I think it wasn't after 2-3 months that I felt quite confident contributing to the codebase. 
I'm trying to set up a neovim environment that uses vim-lsp and the haskell-ide-engine (hie). For the most part this seems to be working but as I type "import Data.Aeson", I get no completion suggestions and I get an error message "LSP: Could not find module ‚ÄòData.Aeson‚Äô Perhaps you meant Data.Version (from base-4.12.0.0) Use -v to see a list of the file..." at the bottom of my editor window. I am able to compile the file without any problems so I know the Data.Aeson is installed. The aeson module differs from other modules in that it was not installed by default so I explicitly installed it on the command line . Maybe I have to rebuild some symbol cache or database after installing a module but I can't find any documentation to that effect. I'm working on a Linux machine. Thanks for any helpful comments/suggestions.
I kinda wish you could `cabal install ghc` :P
It took me about six months of full time effort to get a minimal web application with enough features to put into production, working alone in a small technology company. I am assuming you are considering attempting something alone, since you are asking your question here. I could have gotten small applications in production sooner if I had focused on simple command line applications first, and then expanded that effort into a web application. I would invest some thought as to whether using Haskell in production will get you to where you want to be eventually. What type of systems do you want to build? What ecosystems are being used to build those systems? Certainly, you can build almost anything in Haskell, but building up expertise in an area that interests you will be fastest if you are working under mentors using tools that those mentors prefer.
I was using Haskell in production long before I was really comfortable with it, haha‚ÄîI‚Äôd been using it for less than a year I think before getting a job writing Haskell full-time. My coworker taught me stuff, I taught him stuff, we levelled up together, it was good. Sometimes it‚Äôs most effective to just go for it and learn as you go.
&gt; Is there some way I can help you get that documentation merged upstream? You just helped :) A big part of how I allocate my open-source time is based on user feedback, so now that I know that at least one person is waiting on this, I'm putting that review back to the top of the pile. I will let you know once the PR is up if you want to look for typos or if you have some further suggestions.
The "entropy-compressed dictionaries" you mention are only efficient when you have information about k that changes the a priori distribution of bit vectors. The preceding paragraph and the poppy data structure don't make such an assumption, so the information theoretic lower bound to store n bits is simply n bits, and the goal is to minimize the overhead on top of that. In section 2.1 in the poppy paper, they summarize the general approach. In particular: &gt; we should be able to do counting directly upon the original bit array. A few lines later, they explain the general algorithm, the last step involves directly counting in the bit vector.
Cool.
You may enjoy Phillip Wadler's "Monads for Functional Programming." He implements a State Monad there and if you follow the paper and work up the code examples (and get it to compile) you may find it gets you over the hurdle.
You can use [hint](http://hackage.haskell.org/package/hint) to load your code, you'll get an error if it doesn't type-check. import Control.Exception import Language.Haskell.Interpreter -- | -- &gt;&gt;&gt; mapM_ print . lines =&lt;&lt; readFile "TypeChecks.hs" -- "typeChecks :: Char" -- "typeChecks = 'a'" -- &gt;&gt;&gt; typeCheck "TypeChecks.hs" -- Right () -- -- &gt;&gt;&gt; mapM_ print . lines =&lt;&lt; readFile "TypeError.hs" -- "typeError :: Int" -- "typeError = 'a'" -- &gt;&gt;&gt; Left e &lt;- typeCheck "TypeError.hs" -- &gt;&gt;&gt; mapM_ print . lines $ e -- "TypeError.hs:2:13: error:" -- " \8226 Couldn't match expected type \8216Int\8217 with actual type \8216Char\8217" -- " \8226 In the expression: 'a'" -- " In an equation for \8216typeError\8217: typeError = 'a'" typeCheck :: FilePath -&gt; IO (Either String ()) typeCheck filePath = do r &lt;- runInterpreter $ do loadModules [filePath] case r of Left (WontCompile (GhcError e:_)) -&gt; pure (Left e) Left e -&gt; throwIO e Right () -&gt; pure (Right ()) For parsing Haskell code into an AST, I've used [haskell-src-exts](http://hackage.haskell.org/package/haskell-src-exts) in the past. Looks like there is also [haskell-src-meta](http://hackage.haskell.org/package/haskell-src-meta), which parses the source into a different AST, and even a type-checker, [haskell-type-exts](http://hackage.haskell.org/package/haskell-type-exts)!
Ya I did think maybe the n choose k thing was about the *additional* weight on top of the original bitvector, but stuff like this sentence in particular made me think that wasn‚Äôt the right interpretation: &gt; Unlike general lossless data compression algorithms, succinct data structures retain the ability to use them in-place, without decompressing them first. That really sounds like my original interpretation to me, but... yeah, clearly that‚Äôs not what the libraries are doing. I guess I could try to compress my sparse bitvector before putting it in Poppy, but then I lose the ability to index into it without decompressing it first, which... I thought was the whole problem Poppy was trying to solve.
I had a good hard look at IHaskell, even made some relatively large contributions (like making it compile with ghc 8.6) but I never got to a stage where I could actually use it the way I was aiming for (visualisation of data in other larger Haskell projeccts). The IHaskell setup is just incredibly finicky.
So I _finally_ got around to trying this on my local Windows machine using Stack, and I can't quite get it to work. I've copied over all the requisite files, but I keep on getting the following error: Left (GhcException "can't load .so/.DLL for: mingw32.dll (addDLL: mingw32 or dependencies not loaded. (Win32 error 126))") I've tried looking it up, but it seems that this error is only ever seen when using the SDL2-Haskell bindings. Do you have any idea what's going on here?
‚Äú...treat Haskell like a boring, safe language that‚Äôs excellent for writing correct software quickly (when you‚Äôre writing it for work), not as a beautiful, elegant, fascinating language that deserves only perfect code and abstractions. That helped me avoid paralyzing myself.‚Äù This is a great insight
When you switch to Nix, do you do mean that you do this by enabling nix in `~/.cabal/config` and then using cabal as described in the [Cabal-Nix integration guide](https://cabal.readthedocs.io/en/latest/nix-integration.html)?
I second this except for the "kinda" part. It actually works as expected and I just made a video demonstrating some features, including the one you're asking for: https://www.youtube.com/watch?v=RJP6X9bQ-lY You also get autocompletion, code actions (suggestions), jump to definition, etc. https://github.com/haskell/haskell-ide-engine#using-hie-with-vim-or-neovim I have published my `vim` config some time ago but it might not be correct, needs to be updated with my current setup (will do it soon). Enjoy :)
With Herbert's excellent [PPA](https://launchpad.net/~hvr/+archive/ubuntu/ghc/+index?batch=75&amp;memo=75&amp;start=75), you're quite close: apt-get install ghc-8.6.3 
Type checking typically happens early in a compilation. I'm not sure whether eta needs to involve the JVM with its type system.
`nix-shell -p ghc` is my go to for when I need to quickly futz with something, otherwise I have some expressions in projects that also set up all the extra things I want, like ghcid, ghc-mod, hoogle, etc.
It sounds maybe weird, but I will say from the beginning. But I was able to do what I wanted only after ~6 months of Haskell practice. I think you can go to production easily because the language handle side effect and performance very nicely. So if you succeed to do what you want, most of the time (and I compare directly to python or other very free language), it's production ready.
Never, to be honest. It is relatively easy and straightforward become confident and fluent in *Haskell*. However there is de-facto the only implementation, with its constant (breaking) changes, wild extensions amply abused in essential packages and non-existent idiomatic and unified coding style and practice in libraries APIs. There is no issue with self-contained development solely based on core and stdlib, however the more you depend on hackage/snap resources the more gets your work f*cked.. 
Unfortunately that doesn't work with new-build currently, so no I don't use that. Luckily, all it does is automate putting you in the nix-shell, so it's not a burden to do it manually.
Yeah, my only global install is ghcid, since it makes one assumption; me having GHC. Everything else goes into a nix shell. I avoid global installs like the plague. 
I haven't used ghc on a Windows machine in a long time, but if I remember correctly, mingw is the terminal emulation system which gets installed along with ghc so that ghc can e.g. call gcc to link your program. I don't remember if the executables produced by ghc also require mingw or not, but I wouldn't be surprised if they did. I don't remember what's the equivalent of an rpath in Windows, but I think by default all executables look for their dlls in the system folders and in the directory in which the executable is located. So I would make sure that mingw32.dll is present in the target machine in one of those two locations.
My docker images are huge, almost 600 MB. I just looked it up, and while an Arch Linux desktop installation is supposed to be "less bloated" than Ubuntu, Docker images are the opposite. I think these may be the reasons: - Ubuntu Docker images are based on Ubuntu server, which is probably way smaller than desktop. - Arch Linux packages are bigger than Ubuntu's because their are compiled with almost all flags enabled, so that they have all the features without the user having to recompile it. Also Debian/Ubuntu have `-dev` packages to distribute C header files separately. Arch Linux bundles all files in the same package. - The way Arch Linux handles Stack is suboptimal. The package manager downloads a huge amount of Haskell packages used as "Stack dependencies". All of those packages are now part of the image. In this case Arch Linux works for me because it matches my development environment. if I were to work on something else I'd probably go with Ubuntu or Alpine Linux, which is my favorite distro for production images.
You are welcome! If anything is not clear, or you just want to ask anything about the implementation, feel free to file an issue at my [GitHub repo](https://github.com/GAumala/blog)
I think we should be a bit careful with terminology here. We are checking against a model, but we are not [model checking](https://en.wikipedia.org/wiki/Model_checking) in the traditional use of the term. The exact difference, or if we could use the same state machine specification for both, is not clear to me. There was recently a related [question](https://old.reddit.com/r/tlaplus/comments/ag5ong/gut_check_tla_state_machine_simulation/) on r/tlaplus in which pron98 gave some insightful answers on the topic. I think your application, raft, is particularly interesting because it has a TLA+ model that has been model checked, but still it seems useful to do state machine model testing to check that the implementation is correct. But it feels kinda wasteful to have two similar state machine models and two different tools...
It's from 2006, isn't it a little outdated? 
This looks nice! Thanks for sharing. Distributing Haskell binaries with GitHub releases seems very useful. I might try it to deploy my Scotty app binary.
Are there some good resources to get started with `nix`? 
&gt; It should probably be pointed out that this is an opinionated piece: there are other ways to set things up than we present here. I think this approach is a step in the right direction. Having an executable mock that we know matches the implementation seems very useful. You could for example implement a mock of your web service, spin up an in-memory web server that uses the mock to serve requests, you can then give to your front-end developers (or other developers that depend on the service), they can use that for their development, and then finally once the real back-end is implemented you can check your mock against it. Something similar should be possible for any other kind of stateful modules. I hope that we soon can support this pattern better in the library itself!
It doesn't really use any fancy Haskell features, so not especially. However, I do think there are a few \`(n+1)\` patterns but as I recall those didn't trouble me particularly and a quick google search informed me that they were phased out.
What was particularly lacking?
If you need to use "idiomatic" haskell with all his cargo cult in production, the responses is: Never. 
The Nix Pills series is good and Gabriel's github examples on getting started with nix.
The RST-style headings in your README.md don't render properly on Hackage. 
| Finally, `quickcheck-state-machine` is not the only library providing this functionality in Haskell; in particular, [hedgehog](http://hackage.haskell.org/package/hedgehog), an alternative to QuickCheck, does also. It would be nice to know how the two solutions compare? I'm not asking for an alternative mock-file-system implementation on top of hedgehog, an educated opinion would be enough. 
As I recall, "model checking" is a proof technique: you write the model in (or extract the model to) some simple language where over which you have an automatic proof strategy for the property you want.
Hi I'm completely new to programming but would like to learn. I would like Haskell to be my first language. What should I do to get started and what are some good starting projects?
The Nix Pills series was a little too low level for my taste, last I checked. It focuses on the fundamentals, which is nice, but builds up all its own Nix code and doesn't use nixpkgs. So you're left wondering how to use this darn nixpkgs thing.
Hey there! It all seems very interesting, but I believe I am not up to task yet (and still haven't finished Uni). Is there any chance you are looking for interns? I checked the site but couldn't find anything.
Isn‚Äôt this kind of the point of stack? I must be misunderstanding somewhere. Can someone set me straight?
Well technically you are not doing what OP is asking. To do that, you need to go `IO AppConfig` and hover AppConfig to get what information you can get without jumping to the definition. The feature the OP is asking is not variable -&gt; type You are hovering over local variables to see which type they are. But rather type -&gt; data constructor
About the code that is safer in Rust, I like the explanation that Haskell type system brings a better logic safety in that your code won't generate the wrong result, while Rust has better IO safety in that your code will run in a way that makes sense. Anyway, why is IORef so prominent on a base library, instead of hidden on some package you must import?
Check the sidebar. 
If you've used Haskell for maybe you know like me you appreciate that it's a mathematical character that it comes straight from the lambda calculus right. I found out about Penna types I kind of wanted more from this language but you know there's not a PI in Haskell right nobody can use a PI type here. So what do I do about it all right well I had a point know I add a whole bunch of language extensions mostly to increase the expressiveness of the compile the type system and I'm gathering together a whole bunch together that I typically use. Some of them the ones in red are ones that I've worked on the ones a blue or others and they all kind of work together to give something that I call. I like to call it dependent Haskell because when I program with these languages extensions I feel like I'm programming in a dependently typed language alright and so I want to explain that how that works to you and I'm going to do that by showing you an extended example of what I consider to be a dependently typed program written in Haskell right. So you might be wondering why do all this why do you want to have dependent types in the first place all right and and there are lots of reasons the reason for today the motivating my example that I'm going to show you is because we want the type checker that's Haskell's type checker to know about our application to know about our domain that we're working with. Know more [Svitla Systems software consulting company](https://svitla.com/) &amp;#x200B;
Stack is a separate tool from cabal-install, with a different feature set (notably including stackage-by-default and GHC installation, and lacking backpack/sublibs). For users who need cabal-install, this is a convenient way to help with GHC installation.
Yeah, this seems like an attempt at emulating some of Stack's features with cabal. I don't get you'd want to use this imperfect substitute if you can just use the real thing instead.
[http://haskellbook.com/](http://haskellbook.com/)
It was just far, far too difficult to set up and use. 
It was just far far too difficult to use. For instance, ll the libraries being used need to be built with exactly the same version of GHC as IHaskell and I often use different versions of GHC with different projects.
Thanks for the notice. I tried using # headers but the README still renderers incorrectly. I'm not sure what's the cause.
&gt; and lacking backpack/sublibs Please don't spread misinformation about Stack. Internal libraries work perfectly fine in Stack now.
I was actually referring to [the ability to have multiple public sublibs](https://github.com/haskell/cabal/pull/5526), but forgot that I'm using a development version of cabal-install and that this hasn't made it into a release yet :P Sorry about that. [Backpack is still unsupported in Stack](https://github.com/commercialhaskell/stack/issues/2540). Regardless, my comment was more about explaining that cabal-install and stack are separate, so it's nice to have solutions for installing GHC for cabal-install.
What other language has this feature? 
They have different feature sets. You can't act like Stack is doing legitimate work when Stack users get cabal-install features, while acting like cabal-install is merely imperfectly emulating Stack when cabal-install users get Stack features. Honestly the tools are growing ever closer to being identical in feature sets.
There's some links in the sidebar for Learning material. I never went through "Learn You a Haskell", but I hear it is a good first, free resource. "[Haskell Programming from First Principles](http://haskellbook.com/)" came out after I was no longer a beginner, but it is my go-to recommendation for a first, free resource[1]. If you have any questions about the language that aren't mentioned there, I recommend jumping into the "[Haskell 2010 Report](https://www.haskell.org/onlinereport/haskell2010/)"; it isn't written with accessibility or pedantry in mind, but rather precision and detail, so most people aren't going to want to use it as a first resource, but it's more authoritative than other resources. Once you've gone through one of those, I recommend actually writing some code, and perhaps playing around with your code-compile-debug cycle a little. Sites like Hackerrank, Codeingame, Codewars, Cyber Dojo, Project Euler, etc. can be a source for small problems to tackle with your new language. Get comfortable with what you know; this is not a learning stage but a practicing one. From there, I do still recommend "Real World Haskell", even though some of the examples no longer compile. "[Parallel and Concurrent Programming in Haskell](https://simonmar.github.io/pages/pcph.html)" is also a great guide. The "School of Haskell" is also fine. I think the "Haskell Wikibook" is a better reference than a learning guide, and while it's not as authoritative as the report, it does get updated much more frequently. While you are reading some of those beginner-to-intermediate references, if you think they apply well to one of your early practice programs, it can be good to immediately apply the new knowledge to a familiar program. Once you've got at least one of the beginner-to-intermediate resources read, you can definitely start grabbing libraries from hackage, learning them from the docs / source, using, and improving (or replacing) them. You can also start reading some of the papers with Haskell example code (and depending on the libraries you pick from hackage, papers may be better documentation than the haddocks). Between resources / projects, check in with your workflow, and see if you can optimize it better. While it isn't targeted at learning Haskell (you stated goal), I cannot recommend "[Type-Directed Development with Idris](https://www.manning.com/books/type-driven-development-with-idris)" too much. It really is the best printed resource for the advantages of type-first programming, and how to do it. Much of the specific material isn't going to work with Haskell, since the type system of Idris includes values, and we don't get that in Haskell, but the general principles can be used in Haskell (and other languages). [1] I have difficultly recommending you purchase this resource. While I do think we'd have more Haskell resources if we made them profitable, there were some problems during the production of that particular book that make me believe the money might not be going to the best places.
https://www.reddit.com/r/haskell/comments/ab8ypl/monthly_hask_anything_january_2019/eev9t4o/?context=10000
Depending on your mathematical background https://homepages.cwi.nl/~jve/HR/ and https://www.google.com/search?client=firefox-b-1-ab&amp;q=thinking+functionally+with+haskell might be interesting. I haven't finished it yet but another good book on Haskell's advanced type system features: https://leanpub.com/thinking-with-types
Hi ! I think the best way to learn Haskell is to start a project of your own in it. A command line application perhaps, which does some interesting ingestion of data/processing/output, to get a feel of ways to separate pure and "effectful" computation.
I think the core concept is generally agreed to be higher order functions, functions which can take other functions as arguments. If you can't directly pass and call a function without some degree of ignorance about the implementation of that function, you can't reasonably claim to be a language that supports FP. Whether or not a given language qualifies as a functional language is a point of hot debate, but that debate centers around whether you consider a functional language to be one whose use centers around FP, or whether it should just apply to languages that support the use of FP in some non-trivial way. Discussion on the topic should probably include clarifying which camp you belong to, else, it's just an obnoxious series of pedantic call outs. The rest is generally open to interpretation, although my take is that if one can't honestly see the difference between lisp and python regarding FP, and think these languages belong to the same paradigm, one is being deliberately obtuse.
You should use ghcid!
Thanks for your response. I appreciate the time it must have taken you to look at the materials and write such a thorough commentary; I'm afraid my own reply is going to be even more thorough. Wall of text to follow... First of all, I want to disavow the github repo that you link under "Formal Specification": it appears to be a fork of a really ancient state of Fae that I have abandoned/moved beyond long since. The actual source is not public, for now. I am a little mystified that you find a description of the DSL (such as it is) lacking, since it's described pretty thoroughly in the [Reference Manual](https://sites.google.com/consensys.net/fae/learn/reference-manual?authuser=0). Still, that could very well be difficult to read for someone else, though I have tried not to make it so. The place of Haskell in Fae is dual: * As the implementation language * As the contract language They are interdependent, but at least theoretically separable. Perhaps that's only theoretical; the implementation depends fairly seriously on the ability to capture Haskell closures and not just data types. Not to mention the use of the type system. Fae is independent of a consensus mechanism, as you say. It runs transactions in the order provided to it, and it has the ability to branch from any point in the transaction history; therefore, it can handle transactions as provided by a blockchain complete with competing sibling blocks. But it doesn't care about that, because it does no more than manage the evolution of the state that the transactions manipulate. It runs *post-consensus*; it is the job of the transaction distribution system to make sure everyone has the same transactions in the same order (or partial order, anyway), and it runs them in such a way that everyone then gets the same results. Which is just to say that it runs them lazily. You ask how actors know what code to execute. To understand this you should think of Fae as an expanding Haskell executable that progressively links in new modules; the modules are distributed as source code as part of the transaction messages, and are named after the transaction IDs. A contract is going to be a function defined in one of these modules, placed into Fae's storage by one of the API functions, and represented there as a Haskell closure. Literally, contracts are Haskell functions. Everyone has the same modules under the same names, and when a contract is referenced by ID, that ID describes exactly which transaction (and hence which module) was run to create the contract and where in its execution that happened, so everyone is led to the same contract function definition. There is a part of Fae that is not exactly Haskell, which is the description of a transaction: its entry point, the contracts it calls, and the signers' identities. This is actually important, and forms the only thing I'd actually call a DSL, because it is a limited language that cannot be abused by malicious actors. Fae does require the Haskell type system pretty deeply; that wasn't the original intent (I wanted to leave open the possibility of implementations in other languages) but it has come to be that way, particularly as I worked out what was necessary for escrows to actually represent value. * At the less deep level, contracts are well-typed functions, and so are the transactions' entry points (what is called the "transaction body"). This is important because it means that I can use the `Read` typeclass (and in particular, its derivable instances for any common, concrete data type) to parse the contract arguments in a way that doesn't allow some malicious transaction author to insert code outside the control of the author of the contract they are calling. * The above is also nice in the same way that strong typing in Haskell is always nice for expressing intent and structure. There is actually a significant element of dynamic typing, but this is resolved automatically and presents a statically-typed facade. * At the more-deep level, escrows (which are basically the same representation as contracts) are well-typed too, and this is exploited by the use of private type constructors to prevent people from defining their own escrow'd values outside the control of the escrow's intended API for creation and usage. This parenthetical comment: &gt; (So as such transactions are given meaning only inasmuch as the concerned parties endow it with their signatures? In spite of my confusion, this looks like promising idea) is a little unclear to me, but to answer it in the way I know: transactions do have to be signed (this is not a new idea), and the required signatures can be required by the transaction author(s) and can be multiple in number (this is a new idea). Those signatures, or rather, the identities they encode, are available inside contract code as a way of enforcing access and ownership control. An important use, by the way, of multiple signatures, is to prevent malicious actors from sending money (i.e. an escrow) containing a divergent computation in its history to some contract. The contract owner can block delivery of payment to the contract without their signature, and can then analyze or simulate the payment to figure out if the computational burden is acceptable. This is how Fae can avoid having gas to limit computations; instead, users limit their exposure to computations. The characterization you suggest is fair, though I would prefer to say that it is a protocol for a shared execution environment that happens to be managed via a distributed network, hopefully but not necessarily decentralized (because remember, Fae doesn't care about the details of the network). I have moved away from the provocative "alternative to Ethereum" language, so I would definitely agree with that proviso: although it could operate standalone, I am presenting it as an attachment (accessory, allegory, some other word starting with 'a' ...) to Ethereum. To answer your last question: if I had an Ethereum dapp and said it "uses Fae", then I would mean that it treats Fae as an oracle that is connected to Ethereum and feeds it information that is computed somewhat out-of-band, in the sense that the Fae computations are lazy with respect to Ethereum and don't add to the computational burden of running Ethereum. One verifies the oracle by participating in this optional side-chain. If I also have some other app that "uses Fae", they will be in the same system; it's not just a programming technique, but also a shared state and environment. The apps could, in principle, interact via Fae transactions that form a universe in the same way that Ethereum transactions form a universe.
Complimentary point, in my experience, this mostly comes down to co-worker buy in and not management buy in. And using a tool in a multi paradigm context needs to be justified for good reason. 'I think better this way' is a stance I appreciate, but it's a poor excuse on a collaborative effort if your colleagues don't. Consistency and team cooperation is probably more important than clarity on large project teams - code is always somewhat obtuse and complex, if it sticks to patterns, that stays manageable, even if it's distasteful.
Erik, I don't think it's accurate to say you made it compile with GHC 8.6. [I did that](https://github.com/gibiansky/IHaskell/pull/902).
i think it might depend on what you would consider to be "first-class" support?
A good question, but I'm not sure I can answer it. I'd expect the language to have exactly three fundamental constructs, one for each paradigm. Everything else can be placed in the standard library.
Might be Idris. It's a functional language with lots of logic based in dependent types and imperative constructs like IO.
Go and Javascript, for example
I *think* Shen allows you to create your own typing rules and is quite minimal so maybe you could make something like this in Shen. I don't know if something like it already exists though.
If you like coding puzzles, you could try solving Advent of Code problems in Haskell. Good thing is there are lots of repos with which you can compare your solutions once you're done. If some problem feels too tedious, skip it and come back later :). Won't help you learn how to make (for example) webapps in Haskell, but you'll certainly learn how to implement some algos, pick the right data structures, using pattern matching effectively and creating your own data types to model the problem.
Sorry, yes, I agree. Most of the project did compile with ghc 8.6, but the whole IO layer did not and that is what I fixed. &gt; none of the other Haskell GUI projects seem to have gotten this right yet either. I agree completely. I love the potential for this kind of tool in Haskell, but IMO none of the existing projects (and I probably have not looked closely enough) have come close to meeting that potential. 
Curry https://www-ps.informatik.uni-kiel.de/currywiki/ It is functonal al logic programming. It is a Haskell with added logical varibles with Prolog like matching. Since it can execute monadic code, it supports imperative programs too.
The problem is that mingw32.dll is completely nonexistent! The name was the first thing I looked up, and it appears that it is not provided anywhere, and in fact only ever occurs in GHC error messages.
[Three Layer Haskell Cake](https://www.parsonsmatt.org/2018/03/22/three_layer_haskell_cake.html), all the way. This is an awesome structure that revives Haskell's purity advantage even in highly IO-driven workloads.
asterius is very early in development and doesn't even have a garbage collector atm
This is great! I'm going to pass this on to some of my "interested in FP" friends!
It‚Äôs a nice read and accessible to me as a beginner, thanks!
Thanks! That's good to know. I re-implemented using `State` from above, but I'm glad to know what this is called.
Thanks! I re-did it with `State` and it's much nicer. https://github.com/shterrett/advent-2018/blob/master/src/Day8.hs
Possibly [Mozart/Oz](https://www.info.ucl.ac.be/~pvr/mozart-oz.pdf). Bonus, it has a well regarded book that walks you through building a minimal muliparadigm language from scratch, describing the various tradeoffs that could be made, and you end up with Mozart/Oz at the end.
As a tree of typed DSL. The root is using the IO DSL, as that is forced upon us by the type signature `main :: IO ()`. I express some of my program's behavior in IO, but most of my program is defined in other, more specialized DSLs. The immediate children of the IO root are other DSLs which run in IO, via run functions such as `atomically :: STM a -&gt; IO a`, `runStateT :: StateT s IO a -&gt; s -&gt; IO (s, a)`, `display :: Color -&gt; Picture -&gt; IO ()`, `compile :: (forall t. Frameworks t =&gt; Moment t ()) -&gt; IO EventNetwork`, or even just `pure :: a -&gt; IO a`. Some of those DSLs use Monad transformers to add more side-effects to my base IO DSL, but others, such as STM, remove side-effects, and yet others, such as event loops and frp, introduce a completely different execution model which isn't based on monadic side-effects. Those DSLs consist of many primitives and combinators, some of which takes arguments; Ints and Bools, but also IO actions, it more complex things. In this way the tree grows deeper: yet other DSLs may be used in order to construct those arguments, and so on for the arguments of those DSLs.
The example on the virtue of laziness section actually shows a disadvantage of lazy evaluation regarding buggy code, IMO. On a strict language, that error would happen right away and quickly fixed. However, in a lazy language, buggy code like that could linger on for a long time, until some marginally related change forced `complicatedFunc x` to be evaluated. Until you find out it's actually an old bug, trying to figure out what change made your program crash would be a very frustrating endeavor.
It should compile now, though you would need to make sure to get the submodule when you clone it, since one of the data files is in there. Here are some resulting images: https://raw.githack.com/Data4Democracy/incarceration-trends/dev_co_aclu/Colorado_ACLU/4-money-bail-analysis/adamCS/moneyBondRateAndCrimeRate.html https://raw.githack.com/Data4Democracy/incarceration-trends/dev_co_aclu/Colorado_ACLU/4-money-bail-analysis/adamCS/moneyBondRateAndPovertyRate.html I like it! Next I'm going to work on being able to click each of the points on the chart above and get a chart of the things in the cluster. Which would be very cool. Thanks for the helpful library! A question: in most places, the use of a column name (from the data) is typed, e.g., FName or PName or MName. But in the case of filtering by a range, FRange, the name is just a Text rather than being typed. Doesn't really matter, I guess, but I am trying to ties things together so that I don't ever use actual text, but instead functions that get the text from a Frames column name and it makes more sense if they are typed. 
I wouldn't equate syntactic sugar with imperative paradigm. I would go as far as saying that optimizing syntax to facilitate passing state around using monads is inherently more functional-friendly, in detriment of an imperative approach.
I guess you could make an esolang that has: 1. A type for horn clauses, and way to declare them. They would support constraints involving pure functions. 2. A type for statements, a way to declare them, and a way to execute them. Statements can also evaluate pure functions. 3. A type for pure functions, which may be defined using logic-constraint programming (via the horn clauses) or functional programming, and can output statements which can then be executed. Another nice feature would be transactional memory. Basically, you would have a subtype of statements called "transactions", whose only side effects are to alter the global state of the program. A pure function could simulate a transaction, but then revert its state changes. It may be able to capture the state changes made, which could then be applied "for real" by a statement. You might also be able to incorporate logical programming into the transactions using assert statements (which the logic solver would try to satisfy).
This is no different from writing crappy code that gets called rarely in any other language, and it's why testing is just as important in Haskell as it is anywhere else.
Hi /u/Faucelme, I've seen quite a few of these Generics and Record fixing libs recently, and have heard a lot about SOP too, just curious what sort of things people are actually using these for? I don't think I've ever actually needed to dynamically create a data type like this; do you have examples of things you've needed SOP, generic surgery, or your new Lib for?
This is a great point. It's not a good idea to let completely unused code sit around‚Äî`complicatedFunc` should be removed from `f`. I'm torn about whether (in general) I'd rather let laziness ignore things that are currently unused anyways, or get an error the first time I run the code (as opposed to when I make a change that causes the bad behavior to actually matter). The immediate error has some long-term value, as you say. On the other hand, the post is about how Haskell might eliminate specific errors we'd see in other languages, and that is what's happening here, however facilely. I don't think non-strictness is a very big win for reducing bugs.
Oh you're right, I misunderstood the request.
From the perspective of at best an intermediate Haskell programmer, laziness comes across as a double-edged sword. On the one hand it allows for nice amortization/performance, and on the other it can cause memory leaks or performance issues in places I wouldn't have guessed. 
&gt; On the other hand, the post is about how Haskell might eliminate specific errors we'd see in other languages, and that is what's happening here, however facilely. I'd like to object to that on the grounds that you introduce the function goodOrBad :: Int -&gt; String goodOrBad n = if isThree (sum [1..n]) then "good" else "bad" isThree "three" = True isThree _ = False as an example of an error. If Haskell didn't have a type system (or check types), this code snippet would contain the same sort of error that `complicatedFunc` has: an error that would be only sometimes caught at runtime. You could easily conceive of a situation in other languages where `isThree` took an `Int` and returned a `Bool` sometimes and a `String` other times, which would also conditionally blow up. If Haskell were strict, the error from `complicatedFunc` would always be caught at runtime, which would be at least better than being conditionally caught. The way I see it, the whole point of having types in Haskell and trying to avoid impure functions is to try and prevent runtime errors, not to hide them behind laziness.
It's nice to have simpler options like this that don't offer so much that some people don't need. These days the purpose of reflex-platform is less about merely being able to use GHCJS, and more about special optimizations, extra build targets, and the binary cache. Given that, here's some of what you miss out on by not using reflex-platform: - The binary cached GHCJS is much nicer than its ridiculously long build times, and getting libs this way too is quite nice. - reflex-platform provides a version of `text` which is dramatically faster for GHCJS (plus all the library overrides to adapt to the internal modules changing). - It also provides fairly trivial support for cross compiling to mobile devices and building with GHC for native apps and faster dev cycles with various jsaddle backends. PS: Why do you check a tarball of the GHCJS source into your repo? Couldn't you instead refer to the archive tarball of a commit of GHCJS, like `https://github.com/ghcjs/ghcjs/archive/&lt;REV&gt;.tar.gz`?
https://github.com/haskellnews/haskellnews/issues/75
&gt; PS: Why do you check a tarball of the GHCJS source into your repo? Couldn't you instead refer to the archive tarball of a commit of GHCJS, like https://github.com/ghcjs/ghcjs/archive/&lt;REV&gt;.tar.gz? That repository is not mine.
I don't understand. As a user, I'd much rather get the code from the official GHCJS repo than from someone else's. Are you saying you had to make changes to the source?
Any lisp can support other paradigms'through the use of macro's, and I'd pick scheme for being minimal. For example using mini kanren for the logic part.
I think by logic he means prolog style. AFAIK idris doesn't support that?
I think you're going to have to live with one of those three as the "real" paradigm and the other two available in some context. Haskell libraries furnish you with "assignables" and state or Prolog-like nondeterminism, but you have to enter a context to use them. The outermost context is functional. The operating system is like this too, in a way, when you type `ghci` at the shell, you enter a functional context, but the OS itself is imperative. You can always implement language B in language A and access it, but again, you begin in a context of one paradigm and enter an inner context of the other.
It sounds like this is the PR you mean: [ihaskell-widgets: Make it compile with ghc 8.4](https://github.com/gibiansky/IHaskell/pull/927). &gt; none of the existing projects (and I probably have not looked closely enough) have come close to meeting that potential I think I've looked pretty closely, and as far as I can tell, [`hyper-haskell`](https://github.com/HeinrichApfelmus/hyper-haskell) and [`haskell.do`](https://github.com/theam/haskell-do) are the other alternatives. Neither project is pure GHC (haskell.do uses GHCJS which is an interesting choice), which I personally think is the source of most installation woes, they are missing many features I take for granted in IHaskell, and additionally neither project seems to support GHC 8.6 at all.
Is setting `extra-deps` in the global `stack.yaml` considered a "setup smell", is using a global yaml a "setup smell"?
Hey just to let you know that your blog is doing weird scroll bar things on FF https://imgur.com/a/z0KKcyj The fix in CSS: pre.sourceCode, div.sourceCode { overflow: auto; }
^(Hi, I'm a bot for linking direct images of albums with only 1 image) **https://i.imgur.com/rl6Qf4i.png** ^^[Source](https://github.com/AUTplayed/imguralbumbot) ^^| ^^[Why?](https://github.com/AUTplayed/imguralbumbot/blob/master/README.md) ^^| ^^[Creator](https://np.reddit.com/user/AUTplayed/) ^^| ^^[ignoreme](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=ignoreme&amp;message=ignoreme) 
A couple of belated and poorly considered thoughts: OTOH your proposed `toMap` in conjunction with `toList` and `fromList` to get at the underlying association list would be ideal. Most of my use case(s) revolves around operators (sysops, devops, &lt;industry-trend-here&gt;) specifying dynamic keys - currently via association lists. Despite the general confusion/ugliness, this is required (rather than a record/mass projection) because it allows (my) library code to fold/traverse/map the inputs. An operator would then specify a record with `aeson`-like `Value` typed fields (or whatever makes sense for the configuration) and then be required to use `toMap` to feed library code with the correct type, such as `Map Text Value`. This allows the familiar record syntax as well as something 'heterogeneous' but well-typed within the specific configuration format. Within a library, `toList` can then be used to fold/traverse/map, while `fromList` can be used to recover the more desirable serialisation of a `Map`. 
I don't understand the mechanism either. I just follow instructions contained in https://github.com/matchwood/ghcjs-stack-dist
Thanks a bunch! This should be fixed now.
Ah my bad. Thought you meant the GHCJS repo wasn't yours, not the repo in the post.
No problem! Can confirm it's fixed -- I also checked Chromium and it looks good (it probably always looked fine in Chromium).
You can do some Prolog style stuff with Elaborator Reflection
Sometimes there's a need to have a record type just like another, but where all the fields come wrapped in some functor. Typically because we have to deal with some kind of validation failure, or we want ton construct some kind of parser. See [this](https://stackoverflow.com/questions/53942479/adding-maybeness-to-a-haskell-data-type-with-record-syntax) SO question, or [this](https://github.com/well-typed/generics-sop/issues/47) collection of SOP-related questions. There are two main way to do this. You can change your datatype and add the wrapping manually, and then recover the original datatype as a special case. This is sometimes called the [Higher Kinded Data](http://reasonablypolymorphic.com/blog/higher-kinded-data/) pattern. Or you can, like in generics-sop, generate a "generalized representation" from the base type using generics, and work on that. Some other use cases: - We want to parse a record from JSON, where one particular field has a non-standard FromJSON instance, but we don't want to re-write the full parser. generics-data-surgery is quite good for this. - We need to repeatedly deal with subset of a record's fields and we do not want to define each subrecord independently. There was a [reddit thread](https://www.reddit.com/r/haskell/comments/a7asi8/how_to_deal_with_the_records_problem_when_writing/) about this recently. - We want to ensure that we parse all the branches from a sum type and we don't forget any. There was another recent thread about this but I can't find it. - We want to build a generic JSON parser, but one in which the object keys are given as aliases instead of being deduced from the fields' names. - generics-sop gives a more "uniform" generic representation of a datatype than conventional generics, and once you get the hang of the api, it can be more pleasing to work with it. - When using a Reader to carry around "handles" for effects in monad stacks, it is frequent to want to remove the dependency on the *concrete* record that carries the handles. Usually some kind of lens-based solution is adopted (the "makeClassy" pattern). Using extensible records would be another approach. - [Monolithic sum-type error types can cause problems](https://www.parsonsmatt.org/2018/11/03/trouble_with_typed_errors.html). (My library would need to implement key deletion to help properly with this, I think.) 
Worth noting that we have an upcoming reflex/reflex-dom hackage release (long overdue!), so you should soon be able to hack on reflex projects with just `cabal new-build` - without having to clone them as submodules
I‚Äôve not tried to teach anyone programming, but I would have thought something with visual results, especially for children, would be best e.g. silly little websites in JavaScript, as there‚Äôs much more immediate feedback. Then, once they get hooked, leading into something like Haskell would probably be easier. Having an appreciation for why compilers and type systems are helpful and not just an annoyance, understanding monadic IO from the perspective of promises, etc
To me, laziness shines when talking about it's benefits, and I almost never encounter "bugs because const was strict" type of errors in other languages.\*. To that end, I personally prefer to emphasize refactoring and composition as the primary benefits in terms of reducing errors. Because Haskell is lazy (and pure), you can always refactor any value out to it's own expression and it'll be the same, semantically. This isn't true in basically any other language. I can't tell you how many times I've wanted to refactor something in rust and ran into the borrow checker because it's not lazy, or in JavaScript when I need to abstract things out by hiding them behind arrow functions and calling them to hack in laziness and keep the refactoring semantically equivalent. (So, it turns out that you *do* frequently encounter the "const isn't lazy" thing... It's just tricky to recognize it for what it is unless you've been using a lazy language a lot and flipping between it and a strict language frequently)
I just tried https://github.com/matchwood/ghcjs-stack-dist/blob/master/ghcjs-0.2.1.9009021.tar.gz It doesn't build. It used to work.
&gt; You don't need reflex-platform to use GHCJS or reflex-dom I can do you one better, you don't need Stack/Stackage to use GHCJS or reflex-dom either! :-) I've been working on a PPA for GHCJS at https://launchpad.net/~hvr/+archive/ubuntu/ghcjs by which you can treat `ghcjs` similar to how you'd treat your `ghc` installations having multiple GHC/GHCJS versions side-by-side. I.e. for an Ubuntu LTS release (make sure you have Nodejs v6 or later; see PPA's README), simply sudo add-apt-repository ppa:hvr/ghc sudo add-apt-repository ppa:hvr/ghcjs sudo apt-get update sudo apt-get install cabal-install-2.4 ghcjs-8.4 and then you can either add Joachim's [GHCJS Hackage overlay](https://hackage-ghcjs-overlay.nomeata.de/), or use Git dependencies; here's an example `cabal.project` to get you going: with-compiler: /opt/ghcjs/8.4/bin/ghcjs compiler: ghcjs packages: . ------------------------------------------------------------------------------ -- reflex-0.5 has no proper Hackage releases yet; use Git deps until there is source-repository-package type: git location: https://github.com/ghcjs/ghcjs-base tag: b8d51f65ae1921b2f031710bf75e17f216de442a source-repository-package type: git location: https://github.com/reflex-frp/reflex.git tag: 185e4eaca5e32dfeb879b4bc6c5429c2f34739c0 source-repository-package type: git location: https://github.com/reflex-frp/reflex-dom.git tag: 8e615a8a57cbb492f73dc9e6966c0cb865679c4d subdir: reflex-dom-core source-repository-package type: git location: https://github.com/reflex-frp/reflex-dom.git tag: 8e615a8a57cbb492f73dc9e6966c0cb865679c4d subdir: reflex-dom source-repository-package type: git location: https://github.com/reflex-frp/reflex-dom-contrib.git tag: 2a0eb6105ba68de4ca9be309c38ff902093b923e -- these are patched in the ghcjs distribution constraints: unix installed , directory installed , process installed , time installed , filepath installed And then you can develop your reflex-dom/GHCJS app just like any ordinary Cabal project; `cabal v2-build`, `cabal v2-test` and so on. You can also use GHCJS on Travis CI as well as other cloud CI services this way! Joachim [blogged](https://www.joachim-breitner.de/blog/742-WebGL%2C_Fragment_Shader%2C_GHCJS_and_reflex-dom) about using GHCJS for WebGL demos and how to setup automatic deployment via Travis without the need of Stack or `reflex-platform`, see e.g. https://github.com/nomeata/ghcjs2gh-pages 
Whoohoo!
[CodeWorld](https://code.world) uses a ["teaching variant" of haskell](http://help.code.world/2539841/I-thought-this-was-supposed-to-be-Haskell) which has the properties you describe 
I am using this in production for http://kaleidogen.nomeata.de/, including automatic CD via Travis.
how would they talk to other children, though?
The robot [in this story](https://drive.google.com/file/d/0B-qIu_nqxaMoeHVxYl9CaEhzRG8/view?usp=sharing) seems to get along okay speaking mostly Haskell to the children around it.
I've been teaching Haskell to children for about 8 years now. Someone else in the thread mentioned [CodeWorld](http://code.world]), which is the environment that I built for doing so. Here's what I learned. First, the general idea works out okay, but not as smoothly as you might hope. There's a semi-persistent myth among functional programmers that people with no previous programming experience will find functional programming easier ("their minds haven't been spoiled" or whatever) because they have not learned an imperative language. But this is ignoring that children are taught to think imperatively from a very early age. For instance, when we teach elementary school children to parse simple math expressions, no one says "multiplication binds tighter than addition"; instead, teachers say "multiply first". There's something pretty deep about the human need to turn things into procedural knowledge. Now, learning to think declaratively is extremely useful, and worth the time even by itself; but don't expect it to be easy. Second, you don't want to teach all of Haskell. Type classes are confusing. Polymorphism is confusing. Currying is confusing. Monads are very confusing. You shouldn't trust anyone who claims that 10-year-olds won't struggle with these things. I solved this by using a custom prelude with uncurried functions and monomorphic types. I recommend the same. You're welcome to use CodeWorld if you like. It's the best choice I'm aware of for learning Haskell at an early age. The Guide button at the bottom of the page has enough of a tutorial to take up plenty of your time with a 10-year-old. Let me know if you're interested in other resources, too. If you give up on Haskell, there are also some resources using Elm, ML, and Racket that I'm aware of and you might find useful. Just ask.
Second that. From ground up. Robust explanations as to why things are the way they are. Plenty of references for even more detail. Last but not least a lot of stuff is explained by solving some problems and deriving actual abstractions, so that developer can do the same if they forget the thing. Best for people who like to have things explained to them.
Of course is a good idea and the way to do it is by not patronising children - assuming that they're some little hedonists always in the search for the next immediate gratification, ready to abandon as things get just a little harder. On the contrary, it is the perceived difficulty of pure simple formal systems that makes them carry on with passion. Teach them Haskell as you would teach pure math, you never know how far you can get and try to keep them as far as possible from stupid industry practices and all that professional programming boolshit bacause that would ruin their world
i hope [my book](https://libeako.github.io/c/ID_1371518733.html) is useful, though it is not specifically about Haskell, it is more about theory
Pssst.
Interesting stuff. I am curious by what you mean when you say "multiplication binds tighter than addition"?
Could you open an issue for this?
&gt; Why do you check a tarball of the GHCJS source into your repo? The repo is mine. I'm not 100% sure what you are referring to. Do you mean why have the repo at all?
Emacs + `stack build --fast --ghc-options="-j +RTS -A32M -RTS" --file-watch` for my `haskell-compile` command, just sits in a buffer continuing compiling. Intero is optionally turned on when I spend a lot of time in few modules. Docker/Jenkins for a per-branch CI, nothing too specific to Haskell really.
Can you not reproduce build failure?
No sorry. I thought the repo was OP's
The `ghcjs-0.2.1.9009021.tar.gz ` file is the GHCJS source, no? Why check that file in and refer to it via github url in `stack.yaml` when you could instead refer to the GHCJS repo's archive tarball?
Easy, just use `IO`.
Really cool!
If only it was only a 2-3 month delay. Stackage was stuck on servant-0.11 for over half a year! - servant-0.11 was released on 2017-05-24 - servant-0.12 was released on 2017-11-08 - StackageLTS 10.0 was released on 2017-12-13 still using **half a year old servant-0.11**! It took em till StackageLTS 11.0 which got released almost **another half a year later** on 2018-03-12 to finally update to a newer version of servant! wtf 
I did try out CodeWorld for a training I'm doing at work, but it's not really Haskell. The compiler forces you to pass tuples for arguments for everything like `foo(arg, arg)`. So I had to decide against it for teaching _Haskell_ as a language. For teaching a first language it seems nice. For teaching Haskell to adults I've had success starting out with [Duet](https://chrisdone.com/toys/duet-delta/) because it has a substitution stepper on the right hand side. I think this is the clearest way to show how evaluation works and to understand what your program is doing. I think the essential missing part is to have a small picture API similar to CodeWorld that would make the learning process more fun, and more fun for kids. Ideally, the stepper would show small thumbnails of the picture in each step to really visually see what's going on.
You might also be interested in Pyret - https://www.pyret.org/pyret-code/
&gt; LTS is useful if you view the act of upgrading between 0.0.1 versions as low risk (which it isn't) In what situations is it high risk? &gt; or you find it easier to fix multiple distinct breaking changes when they are overlapped (which it isn't) I don't think it needs to be an either-or situation. You can default to stackage LTS but also have an extra stackage nightly job in CI (whose failure is only a warning in CI) so you get to know about breaking changes relatively sooner.
It means, for instance, that the expression `2 * 4 + 5 * 3` is `(2*4) + (5*3)`.
There's a typo in the URL you link to for CodeWorld: it reads as "http://code.world\]", note the stray "\]".
Extremely interesting comment. Thanks
Ok, so you are questioning why this exists at all. &gt; when you could instead refer to the GHCJS repo's archive tarball? If only things were so simple! GHCJS is not developed with stack, and stackage snapshots are not tied to GHCJS compiler versions. This means that there is a mismatch between what stack wants when it tries to install GHCJS and what the vanilla GHCJS source provides. If you try to do what you suggest stack just won't build GHCJS, or if you get lucky and it does, there is no guarantee that the patched boot packages that GHCJS uses will be at the same version as the snapshot you are using. And it isn't even as simple as simply changing boundaries, because sometimes there are breaking changes in dependencies, and in the case of changed boot packages, the diffs that GHCJS uses to shim them for GHCJS will be out of date. For this reason stack pretty much always needs to use a customised repack of GHCJS, and this repo attempts to provide those.
I know. :)
Slightly after the fact (I haven't written Haskell professionally for about \~6 months now, but I had a three-year stretch writing it for money): - [Mafia](http://github.com/haskell-mafia/mafia) for build (which is basically a wrapper over cabal-install, and some git submodule management on the side). - vim for editing, using codex for tags, and ghc-mod for type inspection (though I barely use the latter). - ghci (wrapped by Mafia), with a tmux command to make it reload when I hit save in my editor. - A simple made-in-house CI builder called [Boris](http://github.com/ambiata/boris). - Hoogle (CLI, and an internally-hosted version of website that allows searching some privately-loaded libraries.) 
&gt; It used to be the case that there were hard time limits (maximum one month) Good to know! The main reason I don't put my packages on stackage is that I had heard that we had to upgrade our packages to the rest of the system within a much shorter time frame, like one week, and I was worried I wouldn't be able to keep up. One month is much more reasonable, I guess I'll put my packages on stackage after all!
What is the build failure? What happens? I don't have CI set up for this.
Similar reasons to why I opened https://github.com/commercialhaskell/lts-haskell/issues/143
Status seems not to have caught up yet https://status.haskell.org/
&gt; I am open to suggestions and/or contributions to improve the situation. &gt; &gt; * The configuration parser is built on aeson and has extremely poor error messages. I recommend [`aeson-better-errors`](http://hackage.haskell.org/package/aeson-better-errors)
&gt;assuming that they're some little hedonists always in the search for the next immediate small gratification, ready to abandon as things get just a little harder. On the contrary, it is the perceived difficulty of pure simple formal systems that makes them carry on with passion Is this based on personal experience, or even better some kind of study? Because the average child of 10 years old might just be starting with abstract thinking. Trying to get a kid struggling with abstract thinking to deal with variables would probably go over well because it's pretty basic. However trying to get into more difficult abstract thinking could be a waste of time for you and the child. So while your suggestion is well-intentioned it would be helpful to understand if it is coming from a place of experience or if you are just guessing.
what would be an example of a moderately complex application designed like this, and how does it contrast with the three layer haskell cake?
https://filebin.net/19vusrw1ryro78ft is the build failure.
I have also become bothered by this. Megaparsec 7 took several months to make it in, because various dependents did not support it. It is probably a hard problem (with no consistently right answer) to decide when to remove dependents in order to accomodate a new major version of some package. Intuitively, I would say that it is best to always update as quickly as possible, because users can just hold stick to a previous nightly if the packages they need get removed. (This policy could be changed during times when an LTS is being prepared.) However, I have only epsilon experience running a package manager, so I might well be wrong. Fortunately, it's fairly easy to add missing packages to `stack.yaml`.
I don't think Haskell is the best first language, even though the idea of functional first is probably fine. I'd recommend javascript because it has a very low barrier to entry and they can just run it immediately in a browser and see results. You can still teach a bunch of functional concepts: callbacks, closures, functors (e.g. with map), but without a ton of frustration because your code won't compile. 
Great suggestion, thanks!
I was not questioning why this exists at all. Using GHCJS with stack is a good goal. I was only asking why a source tarball had to be checked in. If you need to change GHCJS (you shouldn't with 8.4/8.6 btw), then you should fork the GHCJS repo and refer to your fork's archive url rather than tucking a tarball into this repo. That way people can see your commits, and you don't have to check large assets into your repo.