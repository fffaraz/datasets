IDE features with Windows support, preferably a Language Server protocol implementation so that multiple editors can benefit from it.
There is already a LSP engine for Haskell: `haskell-ide-engine`.
Would you mind offering a few details of how you use `entr` and `fd` in conjunction with `ghcid`?
I use this for single file Advent of Code hacking `fd 23.hs | entr stack ghc /_ -- -fno-code -Wall -Werror` which recompiles the file with the given options whenever it changes. I don't actually use `ghcid` together with the other tools, since it does the whole recompile (or rather recheck) on its own. So with `ghcid` it would simply be `haskell ) ghcid --command "stack ghci 23.hs"` and for standard stack projects just `$ ghcid`. There really isn't any magic involved, so sorry if this is underwhelming ^_^
The feeling I got from most of the prominent, free teaching resources was that haskell was like some whimsical puzzle to solve. I don't want to knock these resources, they're good for what they are, and they are definitely needed, but they could do with being balanced out with something more hard-nosed and practical. The best example I can think of is the Rust documentation. They really seem to take documentation and training materials seriously. They have a full book on their website which they keep current. Rust also has the Rustnomicon which describes the weirder, less safe features of the language and makes it clear to you that these are things that you should not do unless you have a very good reason to. Haskell documentation on the other hand, doesn't seem to make this distinction.
&gt;Support projects like Eta (Haskell for the JVM) Eta is definitely an amazing project. I've always been a bit disappointed that it hasn't received the attention it deserves. On the other hand, I suppose it's only really useful if you need to interoperate with Java or otherwise make use of the JVM for some reason. &gt;Support true functional solutions, Not copies of imperative OOP solutions with added "type-safety" Could you give an example of the problem here? I will readily admit to being unfamiliar with the majority of Haskell libraries, but the ones which I do know certainly don't seem like 'copies of imperative OOP solutions'. &gt;Support tooling that make full use of internet, like other modern languages How does Haskell not make 'full use' of the internet now? Haskell has plenty of amazing web libraries already, and I'm not quite sure what other parts of the internet could be utilised that aren't already.
You have to build it from source and I still can't install it on my Windows machine. That's not how you make user-friendly tools. Same goes for Nix.
Folds can implement all recursion over lists but are pretty low level. So if it's beneficial to replace explicit recursion with folds then it can also be beneficial to replace explicit folds with more abstract combinators: import Data.Maybe (mapMaybe) removeUnderscore :: String -&gt; String removeUnderscore = mapMaybe step where step '_' = Nothing stepc c = Just c Also, a huge advantage of folds (and combinators based on folds) is fusion. The if you combine fold consumers with build producers ghc can remove all list allocations which can easily speed up code by an order of magnitude.
I love that paper! I'm always trying to figure out the link between it and permutations parsers.
“git ls-files” is also a great way to provide a watch list to “entr”. (Sorry, I’m mobile and can’t do formatting well.) Recently I’ve bounced back and forth between entr and watchexec for roughly the same scenarios. I like a lot about both, so maybe check them both out if any reader is on the market for “watch for file changes, then do something automatically” tools.
Admittedly an imperfect source but the StackOverflow yearly survey shows 25% of respondents using Vim, right in line with IntelliJ and more than Eclipse. 5% report using Emacs. So not “nearly nobody”, at least out of their sample set. https://insights.stackoverflow.com/survey/2019
What do you mean? If you take all the possible configurations for 3, and use them to sort "abc", you get: freqs = Map.toList . Map.fromListWith (+) . map (flip (,) 1) xs = [1,2,3] ys = sequence [xs,xs,xs] zs = freqs (sort (map (map fst . sortOn snd . zip "abc") ys)) &gt;&gt;&gt; mapM_ print zs ("abc",10) ("acb",4) ("bac",4) ("bca",4) ("cab",4) ("cba",1) In other words, one permutations (`"abc"`) is fully *twice* as likely as any other.
I edited my response to be more compromising, thank you. Unfortunately the SO survey does not provide the detail per language, this would have been quite interesting. I keep thinking in strongly typed languages, an IDE brings much more value to the developer than a text editor.
Thank you for posting.
Thank you for replying.
True, but I just use `rg --files` which also takes `.gitignore` into account
This submission has been randomly featured in /r/serendipity, a bot-driven subreddit discovery engine. More here: /r/Serendipity/comments/bh7uta/foldilocks_an_inghci_tutorial_aimed_at/
&gt;I suppose it's only really useful if you need to interoperate with Java or otherwise make use of the JVM for some reason Don't forget the powerful argument: "It makes management feel safer about migrating a tiny portion of code to this technology". Unfortunately many developers need management approval for new technologies/languages. Being able to package in a JAR (thus seamless experience for deployment/tooling) can be the difference betweek "Ok, let's try that" and "No, it's too risky". &amp;#x200B; Of course, once the whole codebase of an application is migrated to Eta and doesn't use any Java library, just drop Eta and move to Haskell ;)
I think Leksah is rather dead, nowadays people turn towards Intellij/VS Code for IDE/text editors...
FYI Stack + Intellij-Haskell works fine on Windows, I use it at home!
http://rikvdkleij.github.io/intellij-haskell/
Well, that's a good reason too :)
I wonder how well the sharing actually works, for non CI stuff. E.g. \`\~/.cabal/store\` isn't relocatable (yet?), so if you have different usernames: no luck.
Isn't this what ghcid is for?
We just started using it at work. Easy readability win!
Personally, I've started with [Learn you a Haskell](http://learnyouahaskell.com/), followed by [book at Wikibooks](https://en.m.wikibooks.org/wiki/Haskell). LYAH may not always educate the best practices, but it's relatively easy and fun :)
&gt;So GHC is (justifiably so!) deliberately ignoring this "issue"? More or less, but ignoring this "issue" by default might be a better way to put it. &amp;#x200B; There are lot's of things which fall apart if you have \`|x| &gt; maxInt\`. Not just in GHC but also at the assembler/linker/object file/os level.
I took the benchmark I contributed to polysemy, generalized it to use two effects (Reader and State) and to compare more implementations. Most importantly, I moved it outside of the polysemy project in order to alleviate my concerns that maybe GHC had more optimization opportunities inside a project than across projects. [Here is the code](https://gist.github.com/gelisam/be8ff8004cd701a084b6d64204a28bb6), and [here are the results](http://gelisam.com/files/effect-systems-benchmark/benchmark-ghc-8.6.4.html). According to those results, `transformers`, `mtl` and `fused-effects` are all zero cost, `freer-effects` is like 100x costlier, and `polysemy` is 4x costlier than that. That sounds pretty bad for `polysemy`, but I used a stock version of ghc-8.6.4, and /u/isovector claims that we need to merge his patch into ghc in order to see the performance benefits, so the next logical step would be to re-run my benchmarks with that patch. /u/isovector, do you have a git repo with that patch already applied, so I can use [stack's new ghc-git-repo feature](https://github.com/commercialhaskell/stack/pull/4655)?
\&gt; I don't know much about GHC internals, but you should be able to compress it to 2\^63 *bits*, because you only need one bit to know if it's a certain constructor or not Even assuming that's possible, and worthwhile you still end up with 2\^63 bits of live information. Which is far more than most regular system can handle.
&gt; There are lot's of things which fall apart if you have `|x| &gt; maxInt`. Not just in GHC but also at the assembler/linker/object file/os level. Makes sense, I'm only familiar with C/OOP compilers and have yet to dig into how translation of a Haskell program works. There I am aware of (some) limitations when going for the extreme. But since I'm a novice in this field I guessed GHC might at some point traverse the new datatypes and figure out where it can transform it into a fancy `Integer` (or `Int{8,16,32}`). It seemed to me that this could be a sound optimization, keeping these types on a very low-level. In such a case this "issue" would vanish (of course others will persist), though it would still be problematic how to generate the responsible source code. However meanwhile, I learned that this is not the case. Thanks for the reply!
Because using exponentials with base 10 to express large numbers is bad?
I agree, this is a great extension - I often make typos with `threadDelay` because it's in micro seconds (often to the point of opting to write something like `60 * 100000`).
People will hate me because of this, as it's a bit ugly, hackish and un-Haskell-ish solution, but actually safe and works nicely in practice: use global variables :) import qualified System.IO.Unsafe as Unsafe primeList :: [Integer] primeList = Unsafe.unsafePerformIO $ do txt &lt;- readFile "primes.txt" return $ map read $ words txt isPrime :: Integer -&gt; Bool isPrime x = x `elem` primeList This will load the file once, the first time you use it (while this not guaranteed by the Haskell stantards, that's what happens in practice). You can also create global mutable variables the same way (which you should only use with some self-discipline, but sometimes they _are_ useful): globalVar :: IORef MyType globalVar = Unsafe.unsafePerformIO $ newIORef "not initialized yet" This you can then access from the IO monad with `readIORef` and `writeIORef`, but you don't have to pass the reference around.
Because 20e6 is too...easy?
Also, `-XNumDecimals` lets you write integers like `1e6`.
https://github.com/commercialhaskell/stack/blob/master/ChangeLog.md#unreleased-changes
https://github.com/commercialhaskell/stack/blob/master/ChangeLog.md#unreleased-changes
Just so people know, following their Nix build instructions on the Github page will actually build 0.17, a more recent release, so seems like perhaps they just aren’t keeping the Github up to date at the moment.
Not sure exactly what you’re referring to, but like others said Haskell is a general purpose language. A couple of the major benefits it offers are relatively higher confidence about the correctness of your program and increased transparency of the code base.
 &gt; 0_0/ 0_0^0 0.0 `O_o`
\+1 I always wonder if there is reasons to have not used \`Double\` in second for \`threadDelay\`. Most of the time we care about delays in seconds, second is the international unit and the precision of a \`Double\` has more precision for small values. I'm not sure we really care about a \`threadDelay\` of two years and 1 microsecond.
You probably want to change your type signature from `Int -&gt; Int` to `Natural -&gt; Natural` so your function is well defined for all inputs and avoids nunetic overflow errors.
Maybe don't call your function `show`? Alternatively, you could hide the builtin show like this: import Prelude hiding (show) and then reimport it qualified like this: import qualified Prelude now you can use `show` to refer to your `show`, and `Prelude.show` to refer to the builtin show.
You can't have `variables` take a special variant of `Expr` where strings are `Var`s as input, but you can use [the `IsString` typeclass](http://hackage.haskell.org/package/base-4.12.0.0/docs/Data-String.html#t:IsString) to make `"x"` equivalent to `Var "x"`: {-# LANGUAGE OverloadedStrings #-} instance IsString Expr where fromString = Var
Hopefully HSE will catch up soon! Can't `stylish-haskell` any file with NumericUnderscores, QuantifiedConstraints, DerivingVia, etc...
First: Rasterific, the most imoportant Haskell lib (also: NileHs, GeziraHs) Second: Hint style program execution Three: A state-of-the-art LLVM backend Four: The WebAssembly backend.
You added 'deriving Show' to the type declaration, and that already generates a function 'show :: Expr2 -&gt; String' that's clashing with the one you defined by hand. You could remove the 'deriving Show's, rename your 'show' as something else, or better yet, use it to implement the Show instance instance Show Expr2 where show = {- your implementation here -}
Unless we miss something it should work. We do some special treatment for these `~/.cabal/store` paths in `package.db/*.conf` by substituting home directories. Please give it a try and open a GH issue if you have any problems. It is also in our interest to make cache shareable!
This.
Along with Rust, you can look at the Elixir, Ruby, JavaScript, and Python communities for guidance. The amount of resources are immense. They cater to various learning styles, at various levels of understanding, in various first-languages, and for various problem spaces (not just web, not just compilers, etc). Beyond that, they have very approachable language. The language of academic white papers can be difficult to parse for people of less know-how. Surely, the white papers are incredible resources of knowledge, but sometimes it's best that you teach a child from a child's perspective.
I wish I had caught this proposal to suggest that literals like `1_000_00` trigger a warning. (Or are there some people that would intentionally use a number of digits other than three between each underscore?)
&gt; actually safe Not the way you did it. You are going to need to `{-# NOINLINE #-}` pragmas or you'll read the file multiple times and `primeList` may act like it has two different values depending on where it is used. &gt; global mutable variables *Especially* in this case, be sure they are monomorphic. Otherwise you'll have one name tied to a *family* of global variables.
It is able to be considered specialized because both functional programming in general and haskell specifically are not widely used. What percent of programmers know haskell? Not many. This makes for a problem for companies because it limits who can be hired to fill software positions, and there really isn’t any reason to unnecessarily limit who you can hire based off of a programming language choice which: doesn’t improve runtime efficiency, and doesn’t improve development time (like python) This feels like a cult of a sub all of the sudden, like I enjoy coding somewhat in Haskell, but honestly no one here seems to respect outside opinions.
It is able to be considered specialized because both functional programming in general and haskell specifically are not widely used. What percent of programmers know haskell? Not many. This makes for a problem for companies because it limits who can be hired to fill software positions, and there really isn’t any reason to unnecessarily limit who you can hire based off of a programming language choice which: doesn’t improve runtime efficiency, and doesn’t improve development time (like python) This feels like a cult of a sub all of the sudden, like I enjoy coding somewhat in Haskell, but honestly no one here seems to respect outside opinions.
I think that if you had expressed your critique with more nuance people would not have downvoted you. For example &gt; As it stands theres no pragmatic reason to use is a very sweeping statement. There are obvious and pragmatic reasons to use Haskell, even if it's only for the great compiler and type system. Apart from that though, you can't really consider a language specialized because it's not widely used. By that definition any language starts out specialized. I understand your other concerns and I think that your criticism isn't unreasonable. It's certainly debatable if development time is something you want to optimize for. As a professional front end developer I can say that we're super quick at churning out features and we then spend a lot of time maintaining those features because JS is generally not a language that helps you prevent bugs.
I like this. Since as types, `0 ~ Void` and `1 ~ ()` and `2 ~ 1 + 1`... we can think of the factorial of any sum type as the product of all the partial sums in that type. So, for `data Color = Red | Green | Blue` then `Color!` would be isomorphic to ColorFact defined like so: data ColorR = Red data ColorRG = Red | Green data ColorFact = ((), ColorR, ColorRG, Color) That gives something of the right size, at least. I think for non-enum types you'd get something more complicated, though.
A layman way to explain it is that the dot operator is mostly applied to single-argument functions. Filter takes two and that is why the signature gets out of hand.
Is this position yet to be filled? I sent you a PM but you may have missed it.
I can't get that running either, but even if I did, intero is suboptimal, I used Haskero in VSCode before and it was very slow compared to similar tools for other languages and sometimes it just randomly stopped reporting errors, if you have a project that doesn't compile and restart your editor it won't be able to report anything. Same thing if you don't have valid syntax - it just gives up. So far ghcid is the only properly working Haskell tool but it doesn't support things like go to definition, find references or auto-import, which are desperately needed for any large project. It's not like popularity is the problem, I also write Elm and Rust and those language have very good tooling. Don't even get me started on Stack vs Cabal.
Vim is prelevant editor option on headless linux servers. Smart web devs will learn it to avoid char-at-a-time of nano and the like. But that's usage not preference ;)
Indians. They write a trillion as 10,00,00,00,00,000.
This is exactly it, I didn’t realize I could just implement my function definitions under my instance declaration. Thank you.
I messed around it hiding but I don’t think that’s what I needed, but that you for your help!
Yes, Intero is sub optimal because it needs your project to compile when it starts, this limitation is sometimes annoying (though once my project is started, Intellij runs for weeks before I restart it, so it's a minor issue). From then on, it's a smooth sail for everybody in my team. Why can't you get it running on Windows? I'm not sure what you mean by "very slow", the development experience is rather good (of course not as good as Java dev) for my whole team. And Intellij-Haskell brings go-to definition, find references, proposes ad hoc imports, jump from/to test file, etc.
Thank you for your hard work!
Lack of tooling I understand. I think the fear of laziness is largely not important. I've been coding Haskell in production for about 1.5 years and have never encountered an issue where laziness screwed me over. I say this not to try and invalidate the feeling so much as give you some reassurance if that is one of the main reasons you don't do it.
This one I'd like to understand better. A lot of people seem psyched about JVM stuff in general, but I've never seen the appeal. What about the JVM is attractive over native binary outputs?
No mention of backpack :(
I would be super excited about eta if it were haskell but it isn't, and seemingly for [no actual reason](https://eta-lang.org/docs/faq#eta-not-haskell) other than that the authors felt the haskell label carried baggage.
Calling something a cult is not really an argument. You seemed to make claims that Haskell is outclassed on every axis by at least one language and that it brings nothing to the table that is at all valued by industry. And on this, I feel obligated to challenge you. I think that is incorrect from my personal experience with running Haskell in production at a business that is hyper concerned about the bottom line. Our Haskell services routinely ship fewer defects, which in an industry like finance (which I personally am in) is critical. &amp;#x200B; So, if your opinion was "I see no reason why I would choose it given my circumstances which are...\[circumstances\]". That is an opinion worthy of respect. But you said "As it stands there's no pragmatic reason to use Haskell outside of an academic environment". This goes from an argument of existence to an argument of totality. The standard of proof on that is much higher and you did not provide it. That is why you were downvoted, not because you were making legitimate criticisms.
No economic validation would mean it would have died out years ago. The fact that the ecosystem is thriving 20 years later is implication that the economic validation is nonzero. You could attempt to make the argument that other languages have gotten more economic validation and that would be correct. But anything worthwhile requires investment.
Can you provide some clarity on what you mean by "soft" documentation. I feel like I intuitively understand what you mean but I want to be sure.
I'd prefer if the notation was `20'000'000` as 20_000_000` reads really weird.
I don't know much about Elixir, but compared to the others, I think Rust is more relavant in that it is a small-ish community for a language that stl hasn't reached the mainstream, and which is seen as being difficult to learn. Rust's reputation for being difficult is well deserved, yet the people who use it love it. It's constantly rated as developers' favourite language and I don't think that is just because it is well designed and innovative. It's because the community do a great job of explaining why it is the way it is, and the benefits you get from the extra work you have to do up-front when you develop applications in Rust.
This is wicked, thanks for putting in the elbow-grease here /u/gelisam! Here's the patch repo: https://gitlab.haskell.org/trac-isovector/ghc/tree/wip/16473-again --- it might need the [coretodo change](https://gist.github.com/isovector/e4832512ec9c73bff94432a7a58470f9#gistcomment-2872671) to `SimplCore.hs` too.
Sure! I actually like the documentation provided by types as can be found on hackage/stackage. It's compiler enforced and if you know what you're looking for and just want to know the essentials it's great. What we don't have enough is documentation such as the [react docs](https://reactjs.org/docs/getting-started.html) or [styled components](https://www.styled-components.com/) or simply the Rust stdlib documentation. Where it's explained why you would want to use a library. How to get started. How to install it, typical use cases, gotchas and so on.
It's good to ask this question and get familiar with the answer, because what Spock's doing here is really common (even if they do use different machinery than many other introductory resources use to accomplish it). If you're new to Haskell and found this library opaque, don't worry. I am not especially new to Haskell and it took me a lot of effort to work out how Spock works. There are lots of reasons why it does what it does and some of them are good, some of them are bad. Please allow me to reproduce some relevant bits of your sample for narrative purposes below. You've given the compiler the type of a Spock application type that has your state type specified. This is how `getState` knows the type of the object it's returning. It's encoded in the `SpockM` context. You actually provide the value in your main method: ```` main :: IO () main = do ref &lt;- newIORef 0 spockCfg &lt;- defaultSpockCfg EmptySession PCNoDatabase (MyAppState ref) runSpock 8080 (spock spockCfg app) ```` From that point onward, the compiler knows that you're using `MyAppState` as the state parameter in all `SpockM`'s associated with this. If they mismatch, it will not be well-typed. Your app has this type explicitly stated: ```` app :: SpockM () MySession MyAppState () ```` I might recommend that you were to create an alias for this, like `type MySpockAppM v = SpockM () MySession MyAppState v` to help keep the clutter down and reduce potential refactoring issues later on if you use the first type parameter (which is useful in compile time verification access and state control). So when you call `getState` in your app context: ```` getAndUpdateCount :: ActionCtxT () (WebStateM () MySession MyAppState) Int getAndUpdateCount = getState &gt;&gt;= \(MyAppState ref) -&gt; liftIO $ atomicModifyIORef' ref $ \i -&gt; (i+1, i+1) ```` You can see your custom type carried in there. Spock's types are a bit hard for a newcomer to follow here, but if we look at the type of `getState` we see it's part of a `HasSpock` typeclass: ```` class HasSpock m where ... getState :: m (SpockState m) ```` We can then look to see if ActionCtxT's type and see it's a real doozy: ```` newtype ActionCtxT ctx m a = ActionCtxT { runActionCtxT :: ErrorT ActionInterupt (RWST (RequestInfo ctx) () ResponseState m) a } deriving ( Monad, Functor, Applicative, Alternative, MonadIO , MonadReader (RequestInfo ctx), MonadState ResponseState , MonadError ActionInterupt ) ```` But note that it's got an RWST buried in there, and the M it's going to wrap over is one that will have an instance for getState. Spock's mechanism for doing this is complicated, and it doesn't help that the docs aren't universally updated (and that the library itself seems to be in a somewhat unbuildable transition point right now), but the *essence* of what it's doing is fairly normal. It's creating a wrapper around a Monad `m` that surfaces a result value `a` from the wrapped monad, and it is adding a `ctx` phantom type which is used for static type computations. If we chase through the code for a bit we can see that ultimately we're appealing to `WebStateT` which [has an instance for this typeclass](https://github.com/agrafix/Spock/blob/0c267ebca98900c2c78ac2ad207b867ff0aafb39/Spock/src/Web/Spock/Internal/Monad.hs#L17). Summarizing, getState is run in a context that `HasSpock` which appeals to an underlying ReaderT that carries the value of your type. `getState` refers to the typeclass dictionary to find out how to extract the value.
I'm surprised that any package with `data-files` works, e.g. `alex` or `SVGFonts` (I mean, any package using those) as the paths are hardcoded into the library code (in `Paths_$pkgname.hs`).
&gt; But since I'm a novice in this field I guessed GHC might at some point traverse the new datatypes and figure out where it can transform it into a fancy Integer (or Int{8,16,32}) Constructors ARE represented at runtime as essentially a number + some bookkeeping information required by the GC. But it's always Int-sized. Larger numbers are not really required so noone tries to do map them to that range. Lower sizes would be possible but currently ALL heap objects have a uniform memory layout so changing that would increase compiler complexity quite a bit for likely not much of a gain. Bottom line it's not a dumb idea. But the potential payoff is small compared to spending the same effort on improving other parts of GHC.
It's such a ridiculous attitude that I was going to tell you that you got wooshed by a troll, but apparently they were serious.
That actually doesn't quite do what the OP is asking for. doubleFactorial :: Natural -&gt; Natural doubleFactorial = foldl' (*) 1 . join ((enumFromThenTo . bool 1 2 . even) &lt;*&gt; (bool 3 4 . even)) -- or, more clearly, -- foldl' (*) 1 . (bool &lt;$&gt; enumFromThenTo 1 3 &lt;*&gt; enumFromThenTo 2 4 &lt;*&gt; even) -- or, even more clearly, -- foldl' (*) 1 (if even n then [2, 4 .. n] else [1, 3 .. n]) All that aside doubleFactorial = product . go where go n@(even -&gt; True) = [2, 4 .. n] go n = [1, 3 .. n] is probably what I'd want to write.
China and other cultures in that area (Japan, Korea, Vietnam) use groupings of 10^(4).
Yup, Indian here, can confirm. It's a thousand, a lakh, then a crore.
Japanese traditionally use 4 digits in a grouping: * 1 = Ichi * 100 = Hyaku * 1000 = Sen * 1_0000 = Man * 100_0000 = Hyakuman * 1000_0000 = Senman * 1_0000_0000 = Oku But, you'll also see 3-digit groupings in modern Japanese.
Thanks for the correction, I always forget those pesky pragmas. I edited the original post to reflect this. On the second point, yeah, polymorphic `IORef`s are basically `unsafeCoerce`. But that's also true if they are not global, and there is no need for `unsafePerformIO` either.
You'll see 漢字 used for digit groupings sometimes, too, such as &gt; 1億2345万6789 Also, this is probably specific to Chinese, where 万 is pronounced wàn, but people will use the Latin character W to represent the myriad, e.g. &gt; 50W = 500,000
If you attach a random number from 0 to 2^32-1 (or 2^64-1) to each element, and sort, that gives you a small error, because there can be a collision. Getting random numbers from 1 to 3, you grab a random number from 0 to 2^32-1 and modulo 3. But the three possibilities have slightly different probabilities.
because you're currying a function of two arguments, one of which is itself a function?
I mean Double is a terrible (but sometimes very practical) type that it makes sense to try and avoid. Perhaps Fixed would be a better type to use.
Isn't the keyword you're looking for to maintain state between solver calls, "incremental solving"?
&gt; the best thing to do is open soirde What's "open soirde"?
&gt; Three: A state-of-the-art LLVM backend What's wrong with the existing LLVM backend? What would a state-of-the-art backend add?
\[Aura\]([https://github.com/aurapm/aura/tree/master/aura](https://github.com/aurapm/aura/tree/master/aura)) uses \`freer-simple\`, but there's a PR to port it to \`fused-effects\`.
You need to use the query mode for this, and you need to *stay* in the query mode for the entire interaction, i.e., you cannot "save" the state across separate calls as you put it. (Incidentally, this is precisely why we have the query mode, so you can do incremental solving like you've described.) http://hackage.haskell.org/package/sbv-8.2/docs/src/Documentation.SBV.Examples.Queries.AllSat.html is an example of how to structure such an interaction.
Concerning a "data oasis" as you mentioned: haskanything.com and https://guide.aelve.com/haskell might be of interest.
Cool! Thanks for the heads up!
One thing that probably informed the decision was the fact that the arbitrary underscore notation is supported in some other languages. At least Python and Ruby, from what I've checked. Supporting quotes or commas would be a more complex change to the parser, presumably.
Just to chip in my two cents: I've had to deploy a couple of small Haskell programs at work recently and ended up using Docker as a de-facto deployment strategy that "just works" everywhere. I've had a lot of success using Nix to produce the deploy images; the Docker support in Nix is a godsend for producing minimalist working images with minimal effort. At that point it's just plugging it into whatever Docker support your cloud provider has. I can't speak to what monitoring tools are best to use, and I'd love to see more content here. Stuff like hooking up a Haskell web app to Sentry, or being able to remotely open a GHCI console on a running production application would be amazing.
The feature request issue: https://github.com/commercialhaskell/stack/issues/2540 Too bad the GSOC submission deadline is over already; this would've been a good one for a GSOC student to pick up, imo.
Yeah, we don't do anything for Paths (and I am not sure if we can, but maybe...) We also don't account for non-deterministic builds in GHC, which we are investigating now. If you have any suggestions or insights please let us know, it'd be helpful!
The parser can already handle quotes in identifiers and given that the Haskell parser has no relationship to the Ruby parser, I wonder why this should be any harder.
They're also being added to JavaScript, the [numeric separators](https://github.com/tc39/proposal-numeric-separator) proposal is already Stage 3.
Do you know if the interface file format would allow us to somehow update the path inside it? If so then it can be done quite easily...
This is probably the case because n^0 = 1 for all numbers n, even 0 itself. Thus you end up with 0/1, which is 0. Unless you're reacting to something completely different that flew straight over my head...
What kind of work do you do that you use Haskell?
A lot of the integers in my day job are monetary amounts in cents, so your exact example is the exact way I’d write “$1,000.00”.
Ah thank you it is good to know what to search for!
Thank you for the reply! I was trying to structure my code based off of that example however the problem I am having is that I cannot introduce all of my variables at the top of the function as is shown in that example. This is because I do not know how many variables will be in the AST that I am given. Thus I kept looking through the library and found the Data.SBV.Dynamic module which looks to be exactly what I need since I need to introduce variables at run-time. However I am not sure if there is a way to integrate SVal's with the Query interface. For example constrain takes an SBool not an SVal. I also looked at using allSatWith (to limit the results to 2) however I am unsure how to convert a CW into its underlying value. This is because I cannot pattern match on the constructor because it is in an internal module. I know there is a fromCV function but is there a fromCW function as well? Let me know if you have any questions.
I wouldn't recommend using the dynamic interface unless you have a need for types that are not directly present in SBV. (Such as bit-vectors of some odd-length, like 23-bits or something.) There are other use cases for the dynamic interface, but you're better off not using it as they don't give you the type-safety that you get from the regular SBV API. From your description, sounds like you want to use the symbolic/query monad transformers; which allows you to use your own monad as you create symbolic variables and execute queries. See this example:http://hackage.haskell.org/package/sbv-8.2/docs/Documentation-SBV-Examples-Transformers-SymbolicEval.html
Long ago I wrapped that function (along with some others like timeout) with one that takes Time.NominalDiffTime.
yes, exactly
&gt; this would've been a good one for a GSOC student to pick up, imo. It still can be! I think it's safe to say there's going to be another Haskell GSOC in 2020...
I co-founded Mercury, a bank for startups based in San Francisco. We’ll be hiring again in the next couple of weeks!
huh, phone did not send the message I thought it sent
Anything which uses the GHC API and \`ghc-paths \` will also not work.
I don't know if proper relocation could be done without some support in `Cabal` the library See e.g. - [https://github.com/haskell/cabal/issues/4097](https://github.com/haskell/cabal/issues/4097) - [https://github.com/haskell/cabal/issues/5551](https://github.com/haskell/cabal/issues/5551)
[Release notes](https://downloads.haskell.org/ghc/8.8.1-alpha1/docs/html/users_guide/8.8.1-notes.html) suggest 8.8 is a relatively minor update over 8.6, is that correct?
Technically, Maybe _is_ inductive. It has an induction principle: `fromMaybe`. But I agree that it's a degenerate example.
well there is a thing called the Information tecnology industry that uses it.
There a number of notable developments that this changelog misses (see [this issue](https://gitlab.haskell.org/ghc/ghc/issues/16603)), including: * The final phase of the `MonadFail` proposal has been completed, so `MonadFail` is now re-exported by the `Prelude`, and `fail` is no longer a method of `Monad`. See [here](https://gitlab.haskell.org/ghc/ghc/wikis/proposal/monad-fail#adapting-old-code) for a general template of how to adapt your code. * GHC now supports [visible kind applications](https://github.com/ghc-proposals/ghc-proposals/blob/793540827bdd9af72bea210f203e3f340cde683c/proposals/0015-type-level-type-applications.rst). * GHC now supports [explicitly binding type variables](https://github.com/ghc-proposals/ghc-proposals/blob/793540827bdd9af72bea210f203e3f340cde683c/proposals/0007-instance-foralls.rst) in type family instances, data family instances, and `RULES`. * There have been some `template-haskell`-related updates as a result of the two bullet points above.
It's worth noting that this alpha release contains at least one major bug not present in earlier releases: [#16603](https://gitlab.haskell.org/ghc/ghc/issues/16449). So far, I've only ever been able to trigger this when building the `FontyFruity` package, but it's possible that it could affect other code that uses `Data.Bits.setBit` as well.
`stack` downloaded that repo but failed to download its submodules, and compiling ghc on my machine was a sufficiently traumatizing experience in the past that I'd rather not go down that path, sorry. I guess I'll wait for an official release, but by that point this Reddit thread might be locked :(
The GHC developers tell me LLVM is buggy, making it unusable. If we had a good LLVM backend, we could profit from LLVM. Just to mention the example of vectorization that is missing in GHC (AD1), and which could be added in LLVLM. AD1: there is some support for SIMD in GHC and the LLVM backend, but it is useless in ints current state.
The issue with lazy evaluation is that just putting a function call in tail position doesn't necessarily optimize the way it would given strict evaluation. Sure, when you're calling \`doublefactorial' 9 0\` it ends up being tail-recursive and builds up the result in a simple loop instead of being a function call every iteration, but the actual result that's being built up is \`((((9 \* 7) \* 5) \* 3) \* 1)\`, not \`945\`, and reducing \`((((9 \* 7) \* 5) \* 3) \* 1)\` is \*not\* tail-recursive, so you still end up doing the inefficient thing. &amp;#x200B; TCO only works if you are strict in the accumulator value, which happens automatically in strict-by-default languages (most other languages), but in haskell you have to be explicit about it. With \`-XBangPatterns\` you could write \`tailRecursive n !acc = tailRecursive (n-1) (acc\*n)\` or you could use \`seq\` as in \`tailRecursive n acc = let acc' = acc \* n in n \\\`seq\\\` tailRecursive (n-1) acc'\`
I think the best version would just be `doubleFactorial n = product [n, n-2 .. 1]`
That is much nicer, yes. :)
I'll just run it for you on my branch when I get a chance and report back.
Your comment is top level, but doesn't look like a question. If you meant to reply to another comment, you might delete this one and try again. If you meant to ask a question, I didn't understand you.
&gt; The issue with lazy evaluation is that just putting a function call in tail position doesn't necessarily optimize the way it would given strict evaluation. Doesn't matter; the test is on writing tail-recursive stuff, not writing stuff GHC will optimize well. For lazy functions, it's better to be productive than tail-recursive anyway.
Well, yes. At the moment we have identified the following cases: 1) Executables that use Paths_*. For example, `alex`. These are "unfixable" because paths are inside an executable. 2) Libraries using Paths_*. This feels really dirty because it "silently" makes a binary distribution for applications that are built with these libraries to be really hard (or impossible). I am not sure if it can be fixed by updating paths within the `.hi` files, or maybe it won't be enough because of `.so`... At the moment I doubt that anything can be done here. 3) Everything else ("normal" packages). We are trying to detect cases #1 and #2 by looking if the package has anything "unexpected" in its shared data folder. If there is something that suggests that package might be using `data-files`, then this package is cacheable but is only restorable when the target path matches. The tool will detect it and will act accordingly. We think that not many packages are actually using `data-files`, so we hope that the impact of the tool skipping them in a shared cache scenario is not catastrophic and that there is still some good in sharing "normal" packages :) But caching works well for things like CI (which was our primary driver) where the path is always the same. We'd be interested in any suggestions in how to improve cache sharing further, if possible, of course :)
I guess that's fair enough, but the only two reasons for learning about tail recursion is TCO and it being on a test, and the only reason to put it on a test is TCO.
Like already mentioned upthread, reddit's markdown doesn't do three backticks codeblocks. Four spaces should be used instead: lenient :: (Functor f, Foldable t, Monoid b) =&gt; f (t b) -&gt; f b lenient = fmap fold
In your .cabal file set license to \`NONE\`
This seems like something to bring up on the Cabal [issue tracker](https://github.com/haskell/cabal/issues), since 3.0 isn't even out, yet. Additionally, from looking around in discussions on said tracker, it looks like Cabal uses the [SPDX License List](https://spdx.org/licenses/). To that end, you should be able to write something like `license: LicenseRef-Private` or something like that to make Cabal happy.
Sure, the professor/instructor might not have a good reason to put it on the test, but telling that to the student doesn't prevent the student from having to deal with the tail recursion questions on the test. Probably though, the class is taught in Haskell, but is covering referntially transparent programming techniques in general, so while Haskell and TCO don't actually click that often, you can see learn how to convert a function to tail-recursive form in case you want to do so in another (likely strict) language.
Another note I was going to make. From the 2.0 ChangeLog: &gt; Internally, Stack has changed many datatypes, including moving to Cabal's definition of many data types. The pantry-related changes to Stack's internals -- particularly, using Cabal's definition for more things -- are likely to have made these internals more amenable to implementing backpack support.
Sure, but that would mean waiting another year for backpack support.
I've [generated a stack.yaml](https://github.com/DanBurton/stack-setup-info-gen/blob/master/output/stack-ghc-8.8.1-alpha1.yaml) with the appropriate info for installing this ghc alpha. Stack users can try it out as outlined in this gist: https://gist.github.com/DanBurton/a0a29685f2ce1a9528d0160e21f56ea7
&gt; reddit's markdown doesn't do three backticks codeblocks New Reddit does. Old reddit and (some?) mobile apps don't. works on old and new reddit ``` works on new but not old reddit ```
"GHC now exposes a new primop, traceBinaryEvent#. This primop writes eventlog events similar to traceBinaryEvent# but allows the user to pass the event payload as a binary blob instead of a String." Am I misreading that, or are those two names identical?
Get an error message when?
I think it should be "similar to traceEvent#"
As in. If you remove the mention of `license` and `license-file` from your `$pkg.cabal`, it seems to work: ``` [FL973] ~/Documents/public-haskell/boring master % git status On branch master Your branch is up to date with 'origin/master'. Changes not staged for commit: (use "git add/rm &lt;file&gt;..." to update what will be committed) (use "git checkout -- &lt;file&gt;..." to discard changes in working directory) deleted: LICENSE modified: boring.cabal no changes added to commit (use "git add" and/or "git commit -a") [FL973] ~/Documents/public-haskell/boring master % git diff boring.cabal diff --git a/boring.cabal b/boring.cabal index 48a0abe..0211475 100644 --- a/boring.cabal +++ b/boring.cabal @@ -10,8 +10,6 @@ description: homepage: https://github.com/phadej/boring bug-reports: https://github.com/phadej/boring/issues -license: BSD3 -license-file: LICENSE author: Oleg Grenrus &lt;oleg.grenrus@iki.fi&gt; maintainer: Oleg.Grenrus &lt;oleg.grenrus@iki.fi&gt; copyright: (c) 2017 Oleg Grenrus [FL973] ~/Documents/public-haskell/boring master % cabal new-build Resolving dependencies... Build profile: -w ghc-8.4.4 -O1 In order, the following will be built (use -v for more details): - boring-0.1.1 (lib) (first run) Configuring library for boring-0.1.1.. Preprocessing library for boring-0.1.1.. Building library for boring-0.1.1.. [1 of 1] Compiling Data.Boring ( src/Data/Boring.hs, /home/ogre/Documents/public-haskell/boring/dist-newstyle/build/x86_64-linux/ghc-8.4.4/boring-0.1.1/build/Data/Boring.o ) ```
I don't remember. I have many problems with cabal 3.0 due to: https://github.com/haskell/cabal/issues/3585 I use cabal 3.0 without config files, so not being able to specify dependencies from the command line is problematic, since there is a bug in Rasterific that needs a custom fix on my local machine. Also, is there a way to specify that "cabal configure" means "cabal v2-configure" in cabal 3.0? few problems with cabal 3.0, the biggest one is this:
Giving it a try! I just stuck it in an overlay like self: super: { all-hies = import (fetchTarball "https://github.com/infinisil/all-hies/tarball/master") {}; } and then stuck `all-hies.latest` in my packages and it's chugging along! Thanks for the hard work! Is it fundamentally just adding more supported versions, or are there other differentiating features? Also rather nice to have the shorter `hie` rather than just `hie-wrapper`. :)
I'm not sure what you're talking about. You can workaround 3585 by doing ``` echo 'packages: $cabalfileloc' &gt; cabal.project cabal v2-configure ``` If *without config files* means without `cabal.project`, then I suggest you to rethink that choice, and use project files. If you mean without `$pkg.cabal` file, then I really don't know how you are using `cabal-install`. If you want to use very low-level `Setup.hs` like interface, check `cabal act-as-setup`. Unfortunately `Setup.hs` and `cabal` have their commands named the same, **but they are very different, and incompatible**. Also in `cabal-install-3.0` commands are by default `v2-*` variants. But `cabal-install-3.0` isn't yet released, so which exact version you are using, maybe it's simply an old one?
From a usage perspective it's pretty much just more versions. There is however a very good update script as well, which can handle any new HIE version, which will do fancy things like searching for nixpkgs version that provides the GHC version we need. In the future there might be a regularly updating master version too if you want to live on the edge.
I wrote this some time ago https://github.com/llelf/numerals λ⟩ putStrLn $ spellFi 654321 kuusi­sataa­viisikymmentä­neljä­tuhatta­kolme­sataa­ kaksikymmentä­yks λ⟩ putStrLn $ spellFr (Just Feminine) 77771 soixante-sept mille sept cent' soixante-et-une
Considering that about 80% of my config is overlays to pull in newer versions of things, the edge is the *only* place I live. I'll have to read through that fancy update script to see if I can use parts of it to keep my overlays updated.
I've opened [an issue](https://github.com/Infinisil/all-hies/issues/2) for this. For a start I've only decided to provide stable HIE versions because there's a new release every month anyways, and updating is very time and CPU consuming.
Totally understandable, and AOK with my current use of HIE. Thanks again for the work!
Can you paste your Cabal file? It looks like you're locking down the versions of `base` and `transformers` in an incompatible way.
If you want a parallel sort "the hard way" (i.e. involving lot's of advanced features), check out slide 56 in [this presentation by Conal Elliott on (among other things) sorting networks](http://conal.net/talks/fp-parallel-2016.pdf)
I am using the latest cabal (docs 3.0) without ANY config file in my system, also no $pkg.cabal file. I have a data base with commands that run on the command line, and they build and run code; they build the temp file "local.env" that holds the configuration. This works, except when hackage packages have bugs. If you think carefully, not having config files is just the extension of not having global state. If you have 10 or 20 config files (as cabal usually does), you just have a big mess of global state.
All ghc versions downloadable via ghcup (the error messages vary slightly). Cabal file (use either link): https://github.com/DanielG/ghc-mod/blob/master/ghc-mod.cabal https://pastecode.xyz/view/c3955e5e
Based on that Cabal file, the absolute newest GHC this will compile with is 8.2.2 (and the oldest supported by `ghcup` is 8.0.2). See [this](https://gitlab.haskell.org/ghc/ghc/wikis/commentary/libraries/version-history) for a breakdown of boot libraries by GHC version. You're seeing this because the GHCs you have installed can't provide `base &lt; 4.11`, or the boot version of `transformers` for that release. rejecting: ghc-8.6.4, ghc-8.6.1, ghc-8.4.4, ghc-8.4.3, ghc-8.4.1 is the key line. If you want to build this with a GHC from `ghcup`, you must use GHC 8.0.2 or GHC 8.2.2. That said, `ghc-mod` is part of [`haskell-ide-engine`](https://github.com/haskell/haskell-ide-engine), now, which does support newer GHCs. You may want to use that, instead.
Isn't a database just global state?
ERROR MESSAGE with ghc 8.2.2: cabal: Could not resolve dependencies: [__0] next goal: base (user goal) [__0] rejecting: base-4.12.0.0, base-4.11.1.0, base-4.11.0.0 (constraint from user target requires ==4.10.1.0) [__0] trying: base-4.10.1.0/installed-4.1... [__1] next goal: ghc (user goal) [__1] rejecting: ghc-8.6.4, ghc-8.6.1, ghc-8.4.4, ghc-8.4.3, ghc-8.4.1 (constraint from user target requires ==8.2.2) [__1] trying: ghc-8.2.2/installed-8.2... [__2] next goal: transformers (user goal) [__2] rejecting: transformers-0.5.6.2 (conflict: ghc =&gt; transformers==0.5.2.0/installed-0.5...) [__2] rejecting: transformers-0.5.5.2, transformers-0.5.5.0, transformers-0.5.4.0, transformers-0.5.2.0/installed-0.5..., transformers-0.5.2.0, transformers-0.5.1.0, transformers-0.5.0.1, transformers-0.5.0.0, transformers-0.4.3.0, transformers-0.4.2.0, transformers-0.4.1.0, transformers-0.3.0.0, transformers-0.2.2.1, transformers-0.2.1.0, transformers-0.2.0.0, transformers-0.1.4.0, transformers-0.1.3.0, transformers-0.1.1.0, transformers-0.1.0.1, transformers-0.0.1.0, transformers-0.0.0.0, transformers-0.5.6.1, transformers-0.5.6.0, transformers-0.5.5.1, transformers-0.5.3.1, transformers-0.5.3.0, transformers-0.5.0.2, transformers-0.4.0.0, transformers-0.2.2.0, transformers-0.1.0.0 (constraint from user target requires ==0.5.6.2) [__2] fail (backjumping, conflict set: ghc, transformers) After searching the rest of the dependency tree exhaustively, these were the goals I've had most trouble fulfilling: transformers, base, ghc, ghc:buildable
That's the same message. Are you sure it's using 8.2.2?
I am getting exactly the same error with the following Dockerfile: `FROM ubuntu:bionic` `RUN apt-get update &amp;&amp; apt-get -y upgrade` `RUN apt-get install -y curl wget libgmp-dev libbz2-dev libreadline-dev software-properties-common locales-all locales libsecp256k1-dev` `RUN apt-get update` `RUN wget https://github.com/ethereum/solidity/releases/download/v0.4.25/solc-static-linux` `RUN chmod +x solc-static-linux` `RUN mv solc-static-linux /usr/bin/solc` `RUN curl -sSL https://get.haskellstack.org/ | sh` `COPY . /echidna/` `WORKDIR /echidna` `RUN stack --version` `RUN stack upgrade &amp;&amp; stack setup &amp;&amp; stack init &amp;&amp; stack install` `ENV PATH=$PATH:/root/.local/bin` `RUN update-locale LANG=en_US.UTF-8` `RUN locale-gen en_US.UTF-8` `ENV LANG en_US.UTF-8` `ENV LANGUAGE en_US:en` `ENV LC_ALL en_US.UTF-8` `CMD ["/bin/bash"]`
Yes. The error message for ghc 8.0.2 $ ghc --version The Glorious Glasgow Haskell Compilation System, version 8.0.2 ´$cabal new-install Resolving dependencies... cabal: Could not resolve dependencies: [__0] trying: binary-0.8.6.0 (user goal) [__1] next goal: ghc (user goal) [__1] rejecting: ghc-8.6.4, ghc-8.6.1, ghc-8.4.4, ghc-8.4.3, ghc-8.4.1, ghc-8.2.2, ghc-8.2.1 (constraint from user target requires ==8.0.2) [__1] rejecting: ghc-8.0.2/installed-8.0... (conflict: binary==0.8.6.0, ghc =&gt; binary==0.8.3.0/installed-0.8...) [__1] fail (backjumping, conflict set: binary, ghc) After searching the rest of the dependency tree exhaustively, these were the goals I've had most trouble fulfilling: binary, ghc ´
Nice, thank you for this! Curious, what's preventing darwin builds from being cached? Is that something that will be possible in the future?
Hmm. If `cabal new-build` works but `new-install` doesn't, that does sound like a bug. Report it at https://github.com/haskell/cabal/issues. One thing to try before that: Does `cabal new-install .` (note the `.`) give you a different result?
***ALSO:*** What does "base-4.0.0.0, base-3.0.3.2, base-3.0.3.1 (constraint from project config TODO requires ==[4.12.0.0](https://4.12.0.0))" mean? Does "TODO" in cabal mean the cabal programmers left a "TODO" in the debug output message????
Probably lack of a Darwin machine to build on. I may try to throw it at my cachix cache. /u/Infinisil how big does this end up being for cachix?
I love this question so splunked a small bit. I don't think this functionality is exposed. &amp;#x200B; The client uses a \`HasClient\` class which builds the path as part of a larger Request that is never exposed externally. You could make a similar class to HasClient with instances for \`:&gt;\`, \`Capture\`, \`KnownSymbol s =&gt; s\` etc and re-construct the webroute. &amp;#x200B; See [http://hackage.haskell.org/package/servant-client-core-0.16/docs/src/Servant.Client.Core.HasClient.html#line-573](http://hackage.haskell.org/package/servant-client-core-0.16/docs/src/Servant.Client.Core.HasClient.html#line-573) for example. &amp;#x200B; Oh, it seems the server has a similar design: [http://hackage.haskell.org/package/servant-server-0.16/docs/src/Servant.Server.Internal.html#line-643](http://hackage.haskell.org/package/servant-server-0.16/docs/src/Servant.Server.Internal.html#line-643)
&gt; constraint from user target requires ==8.2.2
Hmm, that's true. I can't figure out why it would be trying to use an 8.6.x `transformers` unless it's not really using 8.2.2, though. Weird.
Stack has `—-file-watch` which I think does what you’re saying with fd and entr
yep :) I think this constraint comes from `cabal.project.local` or `cabal.project.freeze` or somesuch
Agreed. I occasionally disagree with `hlint`, but that's what `.hlint.yaml` is for.
+1 to all of this. Exactly my process, start to finish.
&gt; However, to first understand monads, one needs to understand the functor and applicative classes and how they relate to each other and to monads. Is that really the case? Adding `Applicative` between `Functor` and `Monad` makes sense a posteriori, after discovering its many use cases. But for a newcomer who's learning about monads for the first time, the distinction between `Applicative` and `Monad` is likely to fly over their head. "Applicative functors" is also not as natural a concept in category theory compared to monads. The concept of monad can be defined abstractly without much extra structure from the underlying category. For applicatives, the type of `(&lt;*&gt;)` contains a `m (a -&gt; b)`, so it seems you need exponentials to describe that directly... A case could be made for `Functor`, but I think `Applicative` is a distraction in a general explanation of `Monad`. &gt; join is a function that exists in the Haskell standard library, but for whatever unknown reason you are not allowed to define monad instances in terms of it, although it would be possible. The main reason is that it would make `Monad` incompatible with `GeneralizedNewtypeDeriving` and `DerivingVia`. [Although there is a workaround using `QuantifiedConstraints`](http://ryanglscott.github.io/2018/03/04/how-quantifiedconstraints-can-let-us-put-join-back-in-monad/), it is an incredibly hacky-looking solution at the moment (and I'm not sure what it would take to improve it).
is Eta inferior in performance to Haskell? Does it not work well with the built-in garbage collector or something?
My take on Monads is that 1. It is just an interface with two methods, and there are some properties these methods should hold. 2. It has special syntactic support in Haskell. The do notation. The rest is all implementation details on how this particular interface can be used to achieve certain things in a functional language. I think most people can do without that, at least, don't spend a whole lot of effort on it. I mean, you can get a lot of stuff done in Haskell without churning out new Monads on a daily basis.
Upon re-reading the post, I agree that the part about applicative could be omitted. The main reason I had it in there is because I like the "sliding scale of power", as the wiki calls it, since it helps show that there is a trade-off when you go from applicative to monad as you gain more control but lose generality, which narrows down the use cases for monads. It was also one of the articles that helped monads click for me. But just as you said, it has the potential to do more harm than good, so thank you for your suggestion. Also, I did not consider that there would be a technical problem with join. I assumed that since monads are defined in terms of join in category theory it should be completely possible to carry that over to Haskell but that the reason they had not done it was because bind plays to the intuition of monads being computations. Thank you for telling me, I will include it in the post as an edit.
I actually do have a Darwin machine, but it's my laptop that's running NixOS usually :) The cache is currently about 2GB, and because a lot of libraries will be shareable with following HIE versions, I'd only expect this to go up by only about 1GB per HIE release. I'll try building Darwin myself this weekend to throw it up into the all-hies cache.
Oh this is very exciting!
&gt; My take on Monads is that &gt; 1. It is just an interface with two methods, and there are some properties these methods should hold. &gt; 2. It has special syntactic support in Haskell. The do notation. This is certainly an *accurate* explanation, but I doubt it's a helpful one. If I didn't know anything about monads, a detailed version of this explanation would leave me wondering "ok but why is this important and how do I make use of it?" I don't think it effectively addresses the confusion around monads.
Having an understanding of the common `Functor`, `Monad` and `Applicative` are quite different beasts. Perhaps I can show you my understanding of both. `Applicative f` means that we have a (pointed) functor that supports a function `f a -&gt; f b -&gt; ((a , b) -&gt; c) -&gt; f c`, meaning we can combine two computations yielding `a` and `b`, using any pure function, into a single computation of a `c`. `Monad f` means that we have a (pointed) functor that supports a function `f (f a) -&gt; f a`, meaning we can - interpreting `f x` again as some computation yielding a `x` - "join" a computation yielding a computation of an `a` into one single computation yielding an `a`. Regarding the usage of pointed from above, this is just fancy talk for saying we can inject a pure value into the computation `a -&gt; f a`, called `pure` and `return` respectively. With this we can prove that every monad indeed is applicative: == given just these two operations return :: a -&gt; f a join :: f (f a) -&gt; f a == we can deduce (&gt;&gt;=) of Monad &amp; then Applicative (&gt;&gt;=) :: f a -&gt; (a -&gt; f b) -&gt; f b m &gt;&gt;= f = join (fmap f m) dayMult :: f a -&gt; f b -&gt; ((a, b) -&gt; c) -&gt; f c dayMult fa fb abc = fa &gt;&gt;= (\ a -&gt; fmap (\ b -&gt; abc (a, b)) fb) As an exercise you can prove that the above formulation of Applicative corresponds to the definition with `&lt;*&gt;`. A hint: see if you can define a function of type `(a, a -&gt; b) -&gt; b` and try to use that. The other direction should be straight forward with what you are familiar with.
&gt; Another example is the statement that "Monads are computations". Sure, you are working in a programming language. Everything is a computation. What is so special about the Monads? The "monads are computations" picture is not arbitrary. Rather, it stems from works such as [*Notions of computation and monads*, by Eugenio Moggi](https://core.ac.uk/download/pdf/21173011.pdf). Here is a relevant quote: &gt; The basic idea behind the categorical semantics below is that, in order to interpret a programming language in a category C, we distinguish the object A of values (of type A) from the object T A of computations (of type A), and take as denotations of programs (of type A) the elements of T A. In particular, we identify the type A with the object of values(of type A) and obtain the object of computations (of type A) by applying an unary type-constructor T to A. We call T a *notion of computation*, since it abstracts away from the type of values computations may produce. There are many choices for T A corresponding to different notions of computations. While the idea of "functorial contexts" doesn't have a genealogy as clear as that, it ultimately points to a very similar distinction between values and how they are presented in a program (as elements in a data structure, as results of a function, etc.). Even the oft-maligned "functors are containers" metaphor (which the OP does warn against) [can be given a sharper formulation](https://bartoszmilewski.com/2014/01/14/functors-are-containers/).
I'd say: \- A good heterogeneous Hashmap implementation (Hmap has bugs) \- A definitive solution to the record problem \- better module system (but backpack is probably a good solution here, just waiting for stack to support it) And soft doc. HIE is really good.
&gt; A good heterogeneous Hashmap implementation (Hmap has bugs) I'm a bit surprised that the lack of a proper heterogeneous maps is considered a blocker in Haskell? In what kind of applications are such hmaps essential? &gt; better module system (but backpack is probably a good solution here, just waiting for stack to support it) Why are you waiting for stack to support Backpack when you could already be using it with cabal?
&gt; A good heterogeneous Hashmap implementation (Hmap has bugs) I'm unclear what this would look like. If I were doing it in a dependently-typed language it would be indexed by a homogenous Hashmap from the key type to `Type`, and I could use that to type hget (hetrogenous-get) as: defaultVoid : Maybe Type -&gt; Type defaultVoid = maybe Void id hget : (key : k) -&gt; HMap k tm -&gt; Maybe (defaultVoid (get k tm)) and we could type hput (hetrogenous-put) as: hput : (key : k) -&gt; {v : Type} -&gt; v -&gt; HMap k tm -&gt; HMap k (put k v tm) But, I'm not exactly how you'd do this in Haskell. (Or really why; I'm always frustrated with Python `dict`s and JS objects "losing" my type information.) Do you want to engage the `Typeable` machinery to do some run-time tag comparision between the stored value and the expected type? Is the HMap API correct, but it just has implementation bugs (that of course you raised as issues on their tracker)? Do you also want to be hetrogenous on the key types?
Last I checked it was based on an older version of GHC, so it hasn't gotten any of the optimizations that have happened since the fork. Also, laziness doesn't exactly play well with the JVM (or didn't; that might have changed since 8). Even impure languages like Scala could get into performance issues (and problems blowing the stack, though I think variation of the "Operational" monad can be used in the RTS to trade stack for heap as needed).
In the _Monads_ section, the text says “but has two more functions defined for it: return and (=)” and then “(=)” once again. I think you may need to escape the `&gt;` with backslashes if you don’t wanna use inline code (which I would prefer: `(&gt;&gt;=)`).
&gt; Adding `Applicative` between `Functor` and `Monad` makes sense a posteriori, after discovering its many use cases. But for a newcomer who's learning about monads for the first time, the distinction between `Applicative` and `Monad` is likely to fly over their head. This is a rather tricky pedagogical problem. I have always liked the old Wikibook approach of taking on monads as early as reasonable (and, in particular, before covering applicatives) precisely for the reason you mention. With the AMP, however, I feel `Applicative` became just too ubiquitous to go by unmentioned early on, and so I wrote [this](https://en.wikibooks.org/wiki/Haskell/Prologue:_IO,_an_applicative_functor) as a compromise (the detailed discussion of `Applicative` still goes after the monad chapters).
I was going to make a comment about `(*&amp;*) :: Applicative f =&gt; f a -&gt; f b -&gt; f (a, b)`, but for the purposes of this thread your remark about what I would call "the `liftA2` presentation" covers the key point.
I think we had a pretty good crowd on G+, but that's dead and gone. If you are on MeWe, feel free to join my group instead. Not advocating MeWe in particular, but I joined to chase some of my non-Haskell friends that left G+, and it has a similar interface; it was decidedly missing a public Haskell group, though. :)
This is a good exploratory post, but I would be remiss after reading it not to point out that there's a simpler technique to sidestep the messiness (and the need for any multivariable stuff). We already have the chain rule, so we know how to take d/dx ln(f(x)). Also, we know how to take d/dx e^(f[x]). So, we can rewrite a^b as e^(ln(`a^b`)). Then, using log rules, this can be rewritten as e^(b ln a). Therefore, you *could* just write d (Pow u v) = d (E (Mul v (Log u))) You could also manually expand the RHS if you want, but there's no particular need (except maybe a little bit of performance).
Also a clever solution, thanks for this. Expanding out the RHS seems to yield the exact same code that I wrote, albeit more directly. As far as the method in the blog post goes, I think that it makes it more obvious that changing `u(x)` and `v(x)` doesn't change the structure of the solution.
That doesn't look hacky at all to me. QuantifiedConstraints makes it pretty clean. Keep in mind that the proposed solution isnt that users need to write this on their own, but that GHC would (hopefully) derive this.
I have a very concrete list of Haskell tasks where you can help with time and money, both large and small: https://github.com/nh2/haskell-todos Quoting two large tasks from this list that I especially care about: * Making GHC deterministic, producing bit-identical output * Solving the `[TH]` recompilation problem For these I already have a almost-working GHC patches, but need funding to complete.
There's a bug in the currently released cabal-install where new-install will pick up constraints from the global ghc env file, when it shouldn't. So there may well be a file in `$HOME/.ghc/arch-os-version/environments/default` or the like.
Curious, how hard would it be to be able to save values / functions and automatically load them again?
&gt; I doubt it's a helpful one. It is at least, terse. &gt; If I didn't know anything about monads, a mere explanation of the rules and syntax would leave me wondering "ok but why is this important and how do I make use of it or come up with my own useful monads?" The thing is, it did not entice you into believing that monads are this all powerful entity that you can move mountains with. The rules and the syntax should be enough for you to look into the code of some Monads (I would suggest Maybe, Either and then the Reader) and figure out how it works, and thus build an understanding yourself, that is, if you care. Then you would implement your own Maybe, Either and Reader. This method works better than reading a 1000 monad tutorials out there. And It would save you from utterly useless noise such as... &gt;What I especially want to emphasize is that applicatives is a subset of functors and that monads are a subset of applicatives. This means that monads are specific kind of applicative with some added functions and that applicatives are a specific kind of functor with some added functions. In practice this means that when you write code for monads, there are more things you can do but if you write code for functors and applicatives, your code is more general and can be used in different instances since there are more functors and applicatives than monads. I mean no offence to OP, and instead I think they are a victim of the very tutorials and the aura of magic that sadly a newbie entering the haskell community encouters.
&gt; The "monads are computations" picture is not arbitrary Was not actually questioning the accuracy of the statement. But just trying to convey how it might appears to the intended audience of the post.
What is `Pi op` for? It just seems to represent a power of pi. Why not have a `Pi` constructor (with `d Pi = Const 0`) and use `Pow Pi u` instead of `Pi u`? In my experience pi is more often multiplied than raised to a power.
IPython has a %store magic command that does something like this. The problem is, in Haskell most values are not serializable unless they derive an instance of one of the serialization typeclasses -- and there are many competing serialization packages (cereal, binary, flat, ...). And of course function values are not generally serializable. I use %past/%rerun to restore values and definitions after a :reload or restart. Note that you can rerun commands from past ptGHCi sessions (use `%past -n 100` to see the most recent 100 commands including those from past sessions).
Are you required to enable Nix support in `stack.yaml` to use this version of HIE?
I'm eventually going to use this to write a library for arbitrary precision real calculations using Taylor series. That was what the "stay tuned" was referring to at the bottom :P Had a few people suggest to me that the `Pi` constructor should multiply by pi since it's more common, and I'm considering that.
You can pass --destdir to change the directory that cabal actually writes to. Essentially out-ot-source, even if the executables needs to be run in the source.
Thanks, Got it! It actually is `--builddir=DIR`. I guess `--cabal-file=FILE` is for multiple target/config.
&gt; Please create a ... `cabal.project` file referencing the packages you want to build. Have you tried that? $ cabal init -m -n -p test $ mkdir build &amp;&amp; cd build $ echo "packages: .." &gt; cabal.project $ cabal v2-build all
This also work! I haven't use `cabal.project` before and have no idea what it do. Will look into it.
Nope, this repo just gets you a HIE build, which should be usable anywhere and is not restricted to Nix builds
Nix, pantry and the new cabal nix-like store all seem to share a lot of ideas on first glance. It's not clear to me what the core differentiators are. Could you perhaps elaborate a bit more on that?
What do you mean with "Same goes for nix". Is nix even supported outside of BSD-style systems?
That's neat. Yea, I thought that taking advantage of the history might be a good workaround. You could also alias things in the history, so it kinda looks like you have a `save`.
If your code depends on \*any\* external code, then not having a config file means that you \*must\* be depending on some implicit state. A \`.cabal\` file makes that state explicit, and allows it to be automatically reproduced in different environments.
Thanks for the info. It was a big help, but I think what really clicked it for me was looking at the simpler [ReaderT](https://hackage.haskell.org/package/transformers-0.3.0.0/docs/src/Control-Monad-Trans-Reader.html) Here we have the monad defined as follows instance (Monad m) =&gt; Monad (ReaderT r m) where return = lift . return m &gt;&gt;= k = ReaderT $ \ r -&gt; do a &lt;- runReaderT m r runReaderT (k a) r fail msg = lift (fail msg) So when I do `ask/getState &gt;&gt;= f inputs` I'm basically freezing my inputs to `f` and creating a new function that takes the state as input. Eventually this new function gets applied to the state and fills in the blanks I had in `f` to evaluate to my result?
Awesome
I included some initial comments. Will take a look again at the logic later.
thanks!
You should probably never invoke the `Plus` constructor directly, instead have a `plus` function which cases off on the arguments and falls through to `Plus` if nothing matches. Also there is a great deal of replicated code between all the cases of `d` that could be cleaned up by using a more table-driven approach.
Because The Committee™ wanted to have `:` for lists, grossly misjudging which would be more common in source files.
I know it's with the benefit of hindsight, but I can't understand how they could arrive at that conclusion at the time while getting so much else right
&gt; Tail call optimisation is not that important in Haskell. `foldl’` _is_ tail-call. That’s why it performs well for number crunching code. TCO is just as important in high-performance Haskell as it is in any functional language.
Quoting [*A History of Haskell:Being Lazy With Class*](http://haskell.cs.yale.edu/wp-content/uploads/2011/02/history.pdf), subsection 4.3: &gt; We adopted from Miranda the convention that data constructors are capitalised while variables are not, and added a similar convention for infix constructors, which in Haskell must start with a colon. The latter convention was chosen for consistency with our use (adopted from SASL, KRC, and Miranda) of a single colon : for the list “cons” operator. (The choice of “:” for cons and “::” for type signatures, by the way, was a hotly contested issue (ML does the opposite) and remains controversial to this day.)
I’m guessing it’s too late to change it because it’s not backwards compatible, correct? Oh well. Everything can’t be perfect. I still love Haskell :)
The payoff wouldnt be near enough to justify the cost. Would you rather have new features, or fixing annoying, but ultimately inconsequential mistakes?
I see. I definitely want more cool features!
Writing code entirely without type annotations was a common practice in ML-like languages of the late 90s (still is outside Haskell, for that matter). Perhaps people were just reveling in the then-new experience of having Hindley-Milner type inference available. It was only later that most people realised that type annotations on functions are a very good idea.
Pure speculation, but perhaps they assumed that the explicitly writing out type signatures would be less common than it is in practice. After all, in Haskell98 and Haskell2010, you don't technically have to write almost any type signatures (except where polymorphic recursion is involved). I don't know when the "write a type-signature for every top-level binding" rule became popular, but it certainly makes makes \`::\` show up a lot. And with \`DataKinds\` and \`KindSignatures\` in play, \`::\` shows up a ton.
That’s interesting. Type annotations are very nice. I couldn’t see myself writing Haskell without them.
GHCi's stdin and stdout probably aren't suitable for this. It would probably be better to have a socket for communicating between the supervisor and the server. But even this will have problems, as GHCi can have issues with e.g. multithreaded code or memory leaks across :reloads. GHCi is not intended to be a production tool; just a develepor convenience. So I'd recommend against the idea entirely. GHC does support dynamically loading Haskell modules though, so you may want to look into that
&gt; the PVP↔SemVer FAQ section. ... seems to be missing. (bad link?) --- If we are going to change the PVP, why not just fully align with SemVer and provide specific guidelines for how the language agnostic terms in the SemVer specification correspond to Haskell specific API changes?
&gt; the PVP↔SemVer FAQ section. &gt; ... seems to be missing. (bad link?) It's in a different file: https://github.com/haskell/pvp/blob/b40b7ace7c203fdf285b15c8fb464b3cc5c99707/pvp-faq.md
are typeclasses compatible with SemVer?
Sure, you just have to keep in mind that all instances are always exported and can cause compatibility problems even if they don't have a name. SemVer is pretty simple: 1. Incompatible change -&gt; bump MAJOR; 2. Forward-compatible change -&gt; bump MINOR; 3. Backward-compatible chnage -&gt; bump PATCH. You can of course do larger bumps if you want.
Because there are thousands of existing Haskell packages with PVP versioning, not to mention code and tools written to this assumption. (Also, PVP existed before SemVer.)
Unless `0.*.*`, then no rules.
Is it bad practice, or problematic in some way, if I use an alternative Prelude for a library? I want the library to be portable and not require that people using it also use the alternative Prelude. I want to use Relude if that makes any difference.
thanks
Does anyone have any experience with a particular SAT-solver library that they would recommend? I can see that there are a few options but I'm not sure which one to go with
Can I pick option 2? [https://github.com/ghc-proposals/ghc-proposals/pull/118](https://github.com/ghc-proposals/ghc-proposals/pull/118) :D
I find it aesthetically nice to have `::` since it often pairs with one or more `-&gt;`'s and having them both be two characters long eases layout.
I've happily used SBV many times. It's fleshed out, has a responsive maintainer, can leverage not just SAT but SMT solvers with powerful theories, and the types are really well designed. The other SAT libraries I've ran into were just that - SAT - and I usually want SMT. OTOH, if I wanted a SAT as a library instead of access to an external dependency (like requiring the Z3 binary or library) then I could see myself seeking out other options.
I write my type signatures like foo :: ( Blah m , Wow m ) =&gt; One -&gt; Two -&gt; m Three so quick &amp; dirty `grep "foo ::"` works
I actually don't think that this choice was wrong, if you consider how much repetition of each of these things might occur on a single line. If you're doing multi-element pattern matching on lists, you might have a few :'s in quick succession, where :: would be much more awkward. By contrast, it's rare to have more than one type annotation on a line (and practically impossible to have more than one type declaration). So it almost never feels onerous that the notation for that is two characters instead of one.
Type *declarations* are nice, but type *annotations* are still pretty rare in Haskell code. I'd expect the case where you have more than one type annotation on a line to be a good deal rarer than the case where you're doing more than one list cons.
On the whole, not too shabby. I'd maybe advise to try and factor out more functions so as to keep your code D.R.Y. (or DRY-er). Try to keep functions short, if possible and not counter-productive. That way they're easy to reason about. For example, your `tools` function: - The entire printed menu can be factored out as a function (e.g. `toolsMenu`) - All numeric choices can be their own function. (e.g. `"0" -&gt; letterFreq ciphertext`) That way, the code is much more readable; for others reading it, and for you in a few weeks/months. Also, small nitpick, but you don't have to enclose something in parentheses if it's just one thing: `map (snd) list === map snd list` / `take (size) s === take size s`
This is true. Now that I think about it, there a definitely times when you have more than one list cons on a line. Especially when using it to deconstruct lists.
I think that any breakage is overblown if everyone switches to SemVer over a small period of time (like a year). Old bounds written against PVP will still work.
This was a funny but informative read! Thanks for posting.
Thanks for pointing this out. I didn’t think about formatting. I agree that (::) is better when you consider that (-&gt;) and (=&gt;) are two characters long.
It's still very common to leave them off in OCaml and F#. I honestly don't quite get why.
As far as I know, no. An application or library using Prelude can use a library that uses an alternative. Of course, they will be forced to pull in the whole transitive dependency tree. But, my understanding is that most alternative preludes only depend on packages are a relatively common.
In DAML (a GHC fork) we've added the ability to use single colons behind a Language flag. It's a relatively small patch and it'd be nice if we could upstream it one day. [Example here](https://github.com/digital-asset/daml/blob/master/daml-foundations/daml-ghc/tests/Fib.daml)
That’s cool! I’m gonna check this out later.
In Agda, you get the best of all worlds! foo : ∀ {n : ℕ} → ℕ → ℕ → ℕ I don't think `UnicodeSyntax` gets you quite all of the way there.
There's something about the double colon that is particularly satisfying and sets it apart from other syntax. `:` doesn`t have near the prestige of `::` and types have require the prestige of`::`
 foobarbaz : Foo -&gt; Bar -&gt; Baz This seems fine to me
Is it possible to make the following ~/.ghci snippet conditional on the availability of the `pretty-simple` package, or at least to silence the warnings/errors it causes when `ghci` is started in an environment where that package is not available? ``` :set -package pretty-simple import Text.Pretty.Simple (pPrint) :set -interactive-print pPrint ```
That's the point. There are thousands of packages spread over hundreds (or maybe thousands) of authors. Many packages are maintained, but don't need to be updated frequently. You're just not going to get everyone to switch over a small period of time. So your premise is false. Now your tools won't know how to distinguish SemVer packages from PVP packages. It will be a complete mess.
This is, though, definitely the wrong answer to the question of *why* the choice was made. It's well documented that the choice was made because the language committee felt that the convenience of `:` was better spent on the list constructor. It's probably safe to say that the vast majority of Haskell programmers believe it was a mistake, but it's not too costly a mistake to leave around, and extremely costly to fix.
The simplest answer is "Because they made a mistake."
Given that lenses in Control.Lens are valid traversals, is there a preferred way to discard the result of the applicative action in a similar vein to traverse\_ as opposed to traverse.
An important change wrt SemVer in this draft is that SemVer allows (and suggests) pre-release versions to be tagged with a string-part after the patch version (like `2.3.4-rc1` or `3.1.4-beta`) while this PVP draft explicitly disallows this.
Spacemacs has "Look at all usages of this function(or variable)", "Look at definition of this function(or variable)" and refactoring? I don't like how you have to use ctags to do these in vim.
Spacemacs has "Look at all usages of this function(or variable)", "Look at definition of this function(or variable)" and refactoring(Requirements 1, 2 and 3)? I don't like how you have to use ctags to do these in vim.
 It's the strictness, not the tail calls that makes `foldl'` fast. `foldl'` is actually implemeted by `foldr` for lists, which does not use tail calls.
&gt; Now your tools won't know how to distinguish SemVer packages from PVP packages. They don't need to. They just use whatever version bounds are listed. If they are PVP version bounds they will be honored; if the are SemVer they will still be honored. You don't have to adjust any old package or tools; but new version and new packages use SemVer and matching bounds.
&gt; What value will be gained by switching? Consistency. SemVer is used in a broader context. You might as well ask "Why should the U.S. switch to metric?"
Other than [void](https://hackage.haskell.org/package/base/docs/Control-Monad.html#v:void)?
GHC extensions get close enough to dependent types to make them very important sometimes. If you stick to H-M types, they are less important since the correct type is "always" inferred correctly.
I never understood people doing this. How do you constantly type nonstandard characters?
It's not a bad practice but you should be a bit careful. This depends on a way you would use the custom prelude. You can see that we described three ways to import Relude into your project (you can check in [here](https://github.com/kowainik/relude#get-started-)). If you're using the option with `NoImplicitPrelude` and add `import Relude` into each module of your project then there should be no issues uploading such project on Hackage and others would be able to depend on that without any problems. But if you use the option with `base-no-prelude` and create `Prelude` module of your own then there are few points you should keep in mind. You should add `Prelude` module into `other-modules` section in your `.cabal` file. Otherwise, if you push `Prelude` module as `exposed-modules` it would spoil the environment for other packages that would depend on yours. But note, that modules in `other-modules` section can not be used in other stanzas of your project.
You can type arbitrary Unicode characters on any keyboard if you know their code (try googling it). But people most likely set up their editors to substitute -&gt; for → and \N for ℕ or something.
Wow thank you for such a detailed answer! And than you for making Relude; it's made my life using Haskell so much easier! :-)
http://neilmitchell.blogspot.com/2018/11/counting-cost-of-colons-in-haskell.html
I do stick type signatures on things not because I’m afraid of the compiler getting it wrong, but because I know I’ll get it wrong sometimes. And I’d rather have the resulting type error at the definition rather than the use site.
With VSCode I use the latex-input extension. I type \\to and it converts to →.
PVP is a Haskell specific policy. it **defines** what is (or isn’t) breaking change etc. SemVer is open: we’d debate to the end whether something is a breaking change. In other words PVP defines more semantics than ”Semantic Versioning”. For example Rust seems to have an additional document, to comlement SemVer: https://github.com/rust-lang/rfcs/blob/master/text/1105-api-evolution.md
Ok, in my quest to clarify I found traverseOf\_ which is exactly what I was after.
Compose key
&gt; why not just fully align with SemVer Because the PVP is aesthetically more pleasant than SemVer, and avoids the horrible `0.*.*.` corner case. In the PVP, the major version number consists of two components, while in SemVer, there is only one component for the major version: * PVP: `*MAJOR.MAJOR.MINOR...* * SEMVAR: *MAJOR.MINOR...* In practice, this means that SemVer packages often go multiple digits (Firefox, Chrome, Electron, …), whereas in Haskell, you can use `1.0` to denote a semantically complete package, rather than having to use, e.g. `17`.
I wouldn’t say it’s controversial. It may have been at the time of writing, but now it’s pretty obvious Haskell got it wrong. :p
Use font ligatures! https://github.com/i-tu/Hasklig
I have moved over to using (:) for type signatures when drafting code on a backboard or on paper. It's much nicer and cuts down the noise. Doing dots is actually quite time consuming with human writing.
Haskell uses two colons because its types are twice as good as most other languages ::p
\&gt; I don't know when the "write a type-signature for every top-level binding" rule became popular Probably as Haskell programs became bigger. It stops incorrect type inferences from propagating far from their source.
The emacs mode for agda has an extensive input mode that lets you type basically LaTeX-like commands (`→` is `\r` and `⇒` is `\=&gt;` for instance) and get the unicode version.
You're assuming one is "right" - why? It's purely arbitrary.
A newbie question: does HIE require that I use Stack? All my projects use exclusively Nix and cabal.
Thank you, Tom. This is really helpful.
I believe that's exactly what I proposed. &gt; fully align with SemVer and provide specific guidelines for how the language agnostic terms in the SemVer specification correspond to Haskell specific API changes Similar to Rust, we'd have a Haskell document that provided more concrete semantics to SemVers syntax and abstract semantics.
Yeah, type annotations (not just at the top-level) are great for moving errors around until you find where you can the compiler really disagree about the types.
Agda and and Idris would like a word.
Feel like before or around the time I started learning it. ISTR people encouraging me to use top-level type signatures even though one of the big features of Haskell was it's powerful type inference. That was over a decade ago.
I'm personally using HIE with cabal and Nix exclusively, no nope :)
[removed]
"most"
I believe the kind of consistency you are talking about has very little value in this situation. People can learn new things. The PVP is not hard to wrap your mind around. A.B = major, C = minor, D = patch. &amp;#x200B; Your proposal is actually a significant net negative in terms of consistency because it creates a lot more internal inconsistency than it gains us in terms of external consistency. It's very easy to remember "haskell &amp; hackage = PVP, elsewhere = SemVer". It's dramatically harder to remember which package is using which version scheme, remember to tell people which version scheme you are using, etc. &amp;#x200B; Furthermore, SemVer itself is actually less consistent. The whole 0.\* has no rules thing is just a mess. This is like saying, "I only care about things building reliably some of the time." No thanks, not interested in that. &amp;#x200B; SemVer is a perfect example of the kind of bad-ideas-becoming-popular pattern that Haskell rejects as a general philosophy.
That's even worse. Now humans have to keep track of that. And it's very non-local. It's not like one author decides to make the switch and they can bundle all the necessary changes in one release. When one thing switches, it's other packages all over the place that need to change.
In OCaml you usually have type signatures in *.mli file, no need to specify them again in the corresponding *.ml file.
Thanks for the post. I have no intention of developing on Windows (even though I like the OS), but I have great respect for anyone who goes through such an arduous process :P
Otoh unicode arrows are terrible for readability :( It's been several months now since I almost completely switched to \`-&gt;\` arrows in my Agda projects.
That's because people still choose to make it difficult. `choco install ghc msys2` and you would have had the same environment.
There will soon be new Haskell Platform release with GHC-8.6.5; so if you won't want to try **right now**, you may wait a little. Screw it, try right now.
I don't think this will give you the same environment. It will install `ghc` and `msys2` but it won't configure them for you. The whole point of this guide is to show users where's what and how all the pieces interact together. Also, you can't have multiple versions of `ghc` with choco as far as I know so there's that. Personally I use [scoop](https://scoop.sh/) but after introducing cabal, stack and pacman I think another package manager would be a bit much, not to mention that it would hide some important details about ghc and msys2 which would go against the purpose of this guide.
Well, it's not really arduous. From my experience, Windows doesn't use widely different concepts from Linux. Problem is, people use Windows but they don't really take interest in how it works, then they switch to Linux because it's cool, and since it's the tradition (and kind of expected from you) they actually learn how to use the system. In this guide other than installing `msys2` and `wsl` (to make GHCJS easy to use) I've just shown how to install packages, add folders to your path, make symbolic links and such. Same old stuff I do on Linux every day. Point is, for some reason even more experienced Linux people forget (or they don't even consider) that they can do pretty much everything on Windows that they can do on Linux. Only real difference in my opinion (and what is holding Windows back) is the lack of `sudo` command.
The whole guide makes the process much too complicated, as the previous poster said "arduous process". The only configuration you need with the chocolatey packages is to edit the cabal file to fill in some directories. The cabal 3.0 package will do that for you. In fact the nightlies already do. And to start with, the current platform has a ghc in it that doesn't even work on Windows. 8.6.3 is completely DOA. Your guide is called "how to set up a development environment on Windows" not how components interact. For the purpose stated in the title it's simply overcomplicated.
And to clarify, I don't really have a problem with the content of the post itself as an educational or documentary source. You clearly put a lot of work into it, so good job on that! It's the title that I have an issue with as it really does give the impression that setting up haskell on Windows is that hard.
I can confirm this, that book is **fantastic**!
So, I finally managed to get `hint` working with dependencies on my computer! I essentially used the same technique you used in `hawk` (that is, using `unsafeRunInterpreterWithArgs` with `-package-db`), but instead of finding a sandbox in an unknown location I simply hardcoded the path. The big unsolved problem for me now is distribution. I see two options: 1. Get the user to install the relevant packages themselves inside a known sandbox using `cabal` (possibly using a script inside the software to run all the various commands). 2. Figure out how to make a redistributable sandbox, then package it inside the installer. Approach (1) would be easier to program, but harder for the user, since they need to have `cabal` installed on their machine. Then again, this prerequisite may not be too unreasonable (especially if I dress it up with a nice dialogue box saying something like 'to use Haskell you must install the package manager first'). I do know that this approach is popular amongst LaTeX helper software, so it's definitely workable. Approach (2) would be superior for the user, but I'm not entirely sure if `cabal` supports redistributable stuff on Windows. In general I think I'll have to do a bit more research to see what works and what doesn't.
Hm.. ok, somebody is cranky today :) I'm pretty sure Cabal can't download \`pkg-config\` for you automagically or \`cairo\` library. I will cover cabal in the future guides as well as working with git repositories and such, but that wasn't the focus of this guide. Also, installing 8.6.3 was just for the demonstration purposes and completeness sake because I wanted to show where one can find the minimal installer. Later I go on to install \`8.4.4\`. Shame you missed that.
Exactly, don't want to delay publishing this guide ;) I later install 8.4.4, this was just to show where one can find the minimal installer.
Well, I guess we have differing opinions on what counts as setting up development environment :D
Ease of development also means that it's easy to create your own version of something if you don't like the existing choices :).
Given the widespread use of .Internal modules (which I think is a good thing), or other APIs that aren’t intended to comply with a semantic versioning style, should this document carve out an exception for those?
Have you done any field theory? It might be helpful to think about pi and e and other transcendental numbers as adjoints to the rationals analogous to variables. You might be able to encode algebraic irrationals in terms of their minimum polynomials.
excellent work !
Thank you so much for this example it really helped me see what I was doing wrong! Specifically the alloc function, I have my reduction function working now. Thank you again for all of your help and maintaining this great library!
I am unfamiliar, do you have any references?
&gt; there are like 10 cms and web frameworks. and 234524 effect systems, for that matter
&gt; Also, you can't have multiple versions of `ghc` with `choco` as far as I know so there's that. Actually, [`choco install`](https://chocolatey.org/docs/commandsinstall) has a flag for just that: -m, --sxs, --sidebyside, --side-by-side, --allowmultiple, --allow-multiple, --allowmultipleversions, --allow-multiple-versions AllowMultipleVersions - Should multiple versions of a package be installed? Defaults to false. So unless the [Chocolatey GHC package](https://chocolatey.org/packages/ghc) wasn't properly packaged you should be able to say something like choco install ghc --version 8.6.5 -my choco install ghc --version 8.4.4 -my choco install ghc --version 8.2.2 -my To install the last 3 major GHC releases side by side.
I feel like it is still easier to just use a vm rather than brute forcing a shitty os.
To be fair, their power doesn't come for free: type-checking in those worlds is *so slow* compared to Haskell I don't know if I'd be able to write real-world software. At least Agda's caching is smarter than Haskell's, but still, if you make a change in a deep module, be prepared to go make some tea before you can do anything useful again. In contrast, in Haskell, I can make a change somewhere deep in my data model and have my entire project re-type-checked in a few seconds.
&gt; It is just an interface with two methods, and there are some properties these methods should hold. As far as I remember this is how I learned monads. I learned that it was a type-class with some special syntactic support, I studied the behavior of the individual instances (`IO`, `Maybe`, `Either`, `[]`), and I practiced desugaring manually to get familiar with the `do` notation. The general intuition has come slowly by itself, I don't remember having to put any special effort into it. None of the monad tutorials made any sense when I was a beginner. Luckily I had read somewhere that I should avoid monad tutorials. In hindsight, it was great advice.
Having `cap :: [Char] -&gt; [Char]` `cap xs = map toUpper xs` `rev :: [Char] -&gt; [Char]` `rev xs = reverse xs` why does `tupledBind :: [Char] -&gt; ([Char], [Char])` `tupledBind v = (cap v) &gt;&gt;= \a -&gt; (rev v) &gt;&gt;= \b -&gt; return $ (,) a b` and `tupledBind = cap &gt;&gt;= \a -&gt; rev &gt;&gt;= \b -&gt; return $ (,) a b` yield different results? When calling `tupledBind "hello"`? I am having a bit trouble understanding how the argument gets applied. I thought the second one would behave as the first one - but it does not. &amp;#x200B; Also if we have `tupled :: [Char] -&gt; ([Char], [Char])` `tupled = liftA2 (,) cap rev` I see that `liftA2 :: Applicative f =&gt; (a -&gt; b -&gt; c) -&gt; f a -&gt; f b -&gt; f c` for functions becomes `liftA2 :: (a -&gt; b -&gt; c) -&gt; (a -&gt; a) -&gt; (a -&gt; b) -&gt; (a -&gt; c)` so the tuple is `c` and the string input is `a` and we get something like `tupled = \a -&gt; (cap a, rev a)` Right? So I guess I'm just confused with how this works in a monadic context instead.
&gt; I am still amazed by all the hard work and progress made on effect libraries but I worry that the excitement of novelty hides what is really important when building applications: &gt; * a proper distinction between interface and implementation &gt; * an easy to wire and replace components There's one final thing provided by all of records of monad-polymorphic functions, mtl, &amp; free monads: * The ability to statically restrict what effects are even possible to do. All three of those options solve this, but there are ergonomic trade-offs between them all. In my experience, the extensible coproduct+free monad approach is the most pleasant and thoughtless option as a user. The internals are more complicated for sure, but using it is so easy. I feel like I end up jumping through so many more hoops with mtl.
This is great. Stepping back further: with docker it's pretty trivial to spin up half a dozen services and actually test the code paths you care about. Since you should be doing that sort of testing anyway it's worth identifying more concretely what this kind of abstraction is buying you. At least to the extent effects libraries (committing to one) carry certain costs and risks.
but then surely you wouldn't want rewrite a framework if you want specific api or features out of it.
Just use spacemacs with Dante + ghcid.
Probably a place to start is the ghc wiki. Wiki entry for cmm: [https://gitlab.haskell.org/ghc/ghc/wikis/commentary/rts/cmm](https://gitlab.haskell.org/ghc/ghc/wikis/commentary/rts/cmm)
The fourth point is why haskell and monad stacks are great: I can do crazy abstracting while being assured that everything is under control (because types). And I second the point on ergonomics: it matters very much how effortlessly I can swap out the implementation should I want to. Using an abstraction where I know that changing my mind later will cost me I feel like a stormy clouds are approaching on the horizon (to steal a metaphor from "Zen and the art of motorcycle maintenance").
Have been taking any classes in Haskell? If not why are you asked to write a word processor in Haskell as your first assignment??
But I think the double-colon gives the entire procedure of typing more solemnity, makes it more of a ritual. /Beware - here comes the type signature!/ Having just one colon feels ..weak :p
In the second case you’re using the `(-&gt;) a` instance of `Monad` because you’re calling `&gt;&gt;=` with *functions* (`cap` and `rev`) as the left argument: cap, rev :: [Char] -&gt; [Char] (&gt;&gt;=) :: Monad m =&gt; m a -&gt; (a -&gt; m b) -&gt; m b a ~ [Char] m ~ (-&gt;) [Char] (cap &gt;&gt;=) :: (a -&gt; m b) -&gt; m b ------ --------- - --------- - ([Char] -&gt; [Char] -&gt; b) -&gt; [Char] -&gt; b This `Monad` instance behaves like `Reader`, so the argument `"hello"` is passed as an implicit argument (the “environment”) in `&gt;&gt;=` calls. What’s happening in `cap &gt;&gt;= \a -&gt; rev &gt;&gt;= \b -&gt; return $ (,) a b` is that `cap` receives `"hello"` as an argument, `a` is bound to the result of `cap "hello"`, `rev` also receives `"hello"` as an argument, `b` is bound to the result of `rev "hello"`, and the final return value is simply a pair of the two `("HELLO", "olleh")`. Whereas in the first example, `&gt;&gt;=` is in the list monad, so it acts like `concatMap`, and you get `a` bound to *each* character in `cap v`, `b` bound to *each* character in `rev v`, and the result is a list of pairs of every `a` with every `b` (a Cartesian product): tupledBind "123" == [ ('1', '3'), ('1', '2'), ('1', '1') , ('2', '3'), ('2', '2'), ('2', '1') , ('3', '3'), ('3', '2'), ('3', '1') ] If you wanted to write this in point-free form like the second, but producing the same results as the first, you could use the applicative combinators: tupledBind = liftA2 (,) &lt;$&gt; cap &lt;*&gt; rev -- or: tupledBind = liftA2 (liftA2 (,)) cap rev The outer `liftA2` or `&lt;$&gt;`…`&lt;*&gt;` is in the function reader applicative, while the inner one is operating on lists: tupledBind = liftA2 (liftA2 (,)) cap rev -- by ‘(-&gt;) r’ instance tupledBind = \v -&gt; liftA2 (,) (cap v) (rev v) -- by ‘[]’ instance tupledBind = \v -&gt; cap v &gt;&gt;= \a -&gt; rev v &gt;&gt;= \b -&gt; pure (a, b)
So `entr` seems to be http://eradman.com/entrproject/, but what is `fd`?
https://github.com/sharkdp/fd
Well packages on hackages are open-source. Open an issue or a pull-request to discuss a specific feature. You just have to watch out for the license, but generally I think you should be fine if you use the modified version privately.
I too would solve this particular problem with a streaming-oriented solution. Of course, not all problems fit that mold. It looks like the creation of the `Input` should involve some bracketing or resource management. Close open handles on exception and all that. Right now all values seem to be read in one go, which isn't optimal.
Just so you know: all papers will contain errors. It could be a brain fart by the author, a typo by the editor, perhaps a scanned paper with failed ocr, etc. You should not expect papers to be ground truth. Papers are always human communication, so think about what's written!
I wonder if it would be more feasible to use LLVM IR (GHC can output it, iirc) and then transform it to python bytecode or whatever.
I meant if the language is so easy to use to refractor code, wouldn't ideally there be just one cms/web framework, instead of people rewriting this stuff.
Well, I do like Linux a lot but after using it for years I've concluded that I'm unable to control my self and I always end up working more on customizing my OS rather than using it for actual work. On Windows I don't have such urges. Nothing was really brute forced here. You can summarize the whole guide as: 1. Install Haskell 2. Install MSYS2 (which I consider the same thing as `base-devel` package group on some Linux distros) 3. Use WSL so that we don't have to compile GHCJS from scratch since the work has already been done for us by HVR. (I might make a native Windows GHCJS release in the future making WSL unnecessary but I didn't have the time right now) If you are concerned about the length of this guide, this is simply because I've put some effort into explaining some details I deemed important.
You can do: import Prelude hiding ((+)) And then define a + operator that does whatever you want. Alternatively, if the issue is that you want to make + work on some custom type, you can define a `Num` instance for your type: instance Num MyType where a + b = ... a * b = ... abs a = ... signum a = ... fromInteger i = ... negate a = ... And now it'll work like any other number, so for example stuff like `sum` and `product` will work on it as well.
Very little is "built in" in GHC Haskell. It's all library code. You're completely at liberty to say something like (+) :: [a] -&gt; [a] -&gt; [a] (+) = (++) and then do something like [1..10] + [1..4] -- [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4] This will lead to some ugliness like having to say `4 Prelude.+ 6` to use normal addition, but nothing's stopping you from doing it.
That's cool. Is it possible to switch the default "active" version of GHC? The one which is active when you call `ghc` from the command line, or do you have to use the absolute path to specific version each time?
Just for fun, run ghci and define `2 + 2 = 5`. It's that easy!
Ease of refactoring does not mean that there is always "One-true way(TM)" of doing things.
I agree. This the standard answer I give whenever anyone tries to explain what a monad is by conjuring examples. The question though is why is this monadic pattern so pervasive? Is there a reason for *the unreasonable effectiveness of* monads in solving problems.
C-- isn't used outside GHC native code generator. Besides, it is a bit too lowlevel, you probably should aim at STG code or even Core level. You probably could give a loot to [ghcjs](https://github.com/ghcjs/ghcjs), ghc to javascript compiler built on top of ghc.
Surely they're not 10. I don't see cms using dsl or something, and only 2 web frameworks do it, other than that with basically functional composition isn't it just matter of wrapping code to something that agrees with you. I looked at yesod and the authentication module isn't terribly robust.
&gt;I always hit the ergonomic ceiling of manually passing dictionaries around in any medium+ sized project. &amp;#x200B; That's why a different way of passing things around with [registry](https://github.com/etorreborre/registry) where the overall "wiring" is done for you while still being overridable. And there is also a way to [switch to "typeclass mode" locally](https://github.com/etorreborre/registry/blob/master/doc/boilerplate.md) in order to avoid having to pass parameters around.
Yes indeed, this is not a production-grade example! However things are modular enough that it is possible to enhance that first solution with minimal effort.
&gt; But even this will have problems, as GHCi can have issues with e.g. multithreaded code or memory leaks across :reloads. GHCi is not intended to be a production tool; just a develepor convenience. Funny I remembered something about Facebook using ghci for hot reloading, tried to Google it, and [found your comment asking about the same thing](https://www.reddit.com/r/haskell/comments/6pu7ch/differences_between_hotreloading_plugin_libraries/dkskh00/).
Adding logging, metrics reporting to Haskell is super clean. That is a huge net benefit of the language not a downside. Functions are written in small pieces and can be lifted to monads or applicatives that do the logging, metrics and reporting. The logging, metrics and reporting code is isolated in the program and works on many arbitrary functions. The functions meanwhile are written as if they were working on pure mathematical abstractions. And often a single line of imperative code simply invokes the one in the context of the other.
\&gt; Problem is, people use Windows but they don't really take interest in how it works, then they switch to Linux because it's cool, installing msys2 and wsl has nothing to do with learning how to use windows. In fact both these tools allow you to run unixy tools on windows, so why would any developer bother using windows when these tools are shipped by default in other unix oses?
[removed]
As /u/jaxan0 said, don’t expect papers to be error free. However, you can always send a list of errors found to the corresponding author. If the correspondence is polite, most authors are happy that someone is paying so much attention and attempting to improve their work.
&gt;Presumably declarative langs speak about what happens rather than what developer told compiler to do. I can't speak for other languages, but Haskell doesn't behave like this: you can't write Haskell which just goes 'make this happen' and leave the computer to figure it out. You still have to write the little fiddly bits! However, Haskell excels in nicely packaging those bits away (which I believe is essentially what /u/JeffB1517 is trying to say in [his answer](https://www.reddit.com/r/haskell/comments/bio9ff/haskell_considered_nice_declarative_lang_but_how/em1wzku?utm_source=share&amp;utm_medium=web2x)). So you can easily get Haskell code which looks like this: Map.filterWithKey (const . not . isLocalLibrary) (packageDependencies pkgConfig pkgDesc) This is a [line from a randomly selected file](https://github.com/commercialhaskell/stack/blob/dfbf85ad7e8af5b01cf7b51367290870ffc2c90e/src/Stack/BuildPlan.hs#L151) from the first large Haskell project I could think of; I'm fairly sure you can read it without knowing the language too well. It certainly looks declarative, in that it feels a lot like saying 'make it happen' (or in this case, 'make it filter the local libraries from the dependencies'): all the other bits are defined elsewhere. This separation of concerns apparently makes logging, metrics etc. very easy in Haskell: you can define effects like those elsewhere, run them in your `main`, then be able to sprinkle logging/metrics statements throughout the application and have the details taken care of in a separate part of your program. (I say 'apparently' because that's just what I've heard; I've never personally worked on a Haskell application which has needed either of these.) &amp;#x200B; (As an aside: I've always felt that the term 'declarative' is so vague as to be useless, and is too often used only as a synonym for 'not imperative'. Looking at your definition above, I feel confident in saying that there is not a single general purpose language which satisfies this definition (logic programming languages aside; they're a special case). Looking at [Wikipedia's list of declarative languages](https://en.wikipedia.org/wiki/List_of_programming_languages_by_type#Declarative_languages), most of them are single-purpose DSLs like SQL, XSLT or QML. This makes sense: if you want to be able to write 'make it happen' and have the computer figure out the details, your domain has to be small enough to be able to do this easily.)
Saying "it's that easy", while technically true, seems a little misleading. λ» 2 + 2 = 5 λ» 2 + 3 *** Exception: &lt;interactive&gt;:1:1-9: Non-exhaustive patterns in function +
Haskell is not particularly declarative. It just so happens that it is very well suited to write DSLs. A lot of packages and frameworks as such have that feeling and are very "type heavy". Doing anything non trivial on your own, however, will lead you down a totally non-declarative path, requiring you to study and understand a lot of details about types, libraries, GHC... You may end up writing a kind of declarative style API in the end... or you won't. It's not really a language property in my opinion. It's a property of APIs.
Sure I agree, I did try to contact Dr Wadler first but his publicly listed email addresses don’t work. I just wanted to mention these errors somewhere. I see the paper was corrected some time ago with other errors so there’s no reason it couldn’t be again to avoid confusion for future readers.
I am using Haskell for toy projects and [IntelliJ-Haskell](https://github.com/rikvdkleij/intellij-haskell) plugin has improved in last year a lot (very bad IDEA support was the main reason I didn't touch Haskell for a year). It has a bunch of minor issues (mainly: annoying focus stealing, occasional few seconds freeze, sometimes sluggish error highlighting), but it now resembles a proper IDE - highlighting, navigation, docs, simple refactoring, suggesting imports, formatting. I have just recently finished a tiny CLI utility ([timg](https://gitlab.com/monnef/timg)) written in Haskell using IDEA, and the experience was **a lot** better compared to what 1-2 years ago was available (easy setup, no unrecoverable-by-restart random breaking of whole project and/or plugin configuration, not so much relying on browser and dumb search functionality). I think it is a sufficient IDE for people who don't write Haskell professionally.
FWIW I contacted Prof. Wadler with an error in a different paper a while back, and he created a blog post for it: [http://wadler.blogspot.com/2014/10/errata-please.html](http://wadler.blogspot.com/2014/10/errata-please.html). Not sure how effective or discoverable this is but, hey, it's the closest to an official errata page for his papers that I know of!
This will make a good joke: \`\`\` \&gt; let a + b = if a == 2 &amp;&amp; b == 2 then 5 else a Prelude.+ b \`\`\`
Nice, thank you!
It's fairly well defined if you mean "declarative programming languages": https://www-ps.informatik.uni-kiel.de/~sebf/haskell/dp-overview.pdf
You may be interested in the following: [Tackling the Awkward Squad:monadic input/output, concurrency, exceptions, andforeign -language calls in Haskell](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/07/mark.pdf).
Thanks for the answer, quite helpful! &amp;#x200B; You are probably right, I shouldn't have used word "declarative", alas it's only alternative approach I know exists to imperative langs. Prolog and such are more suitable to this definition. &amp;#x200B; It's just so I'm used to Java/Python and I am tired of seeing code well-thought and designed becoming mess after a few changes. I was wondering if it's the thing in the foreign land
Aside: if you want to compose a 1-argument function on the left with a 2-argument one on the right, the standard idiom is to throw in another level of `(.)` or (as I prefer) use `fmap` in the `(-&gt;) a` functor, which is equivalent: count f xs = length (filter f xs) -- by definition of (.) count f = length . filter f -- rewrite to prefix count f = (.) length (filter f) -- by definition of (.) count = (.) length . filter -- re-add infix count = (length .) . filter -- or use ‘fmap’ to “map over” an argument count = fmap length . filter Alternatively, you could pair the arguments in a tuple so the pipeline goes back to being a simple linear composition, but the result isn’t as pretty imo: filter :: (a -&gt; Bool) -&gt; [a] -&gt; [a] uncurry filter :: (a -&gt; Bool, [a]) -&gt; [a] length . uncurry filter :: (a -&gt; Bool, [a]) -&gt; Int curry (length . uncurry filter) :: (a -&gt; Bool) -&gt; [a] -&gt; Int count = curry (length . uncurry filter)
You're welcome. Feel free to get in touch via regular email if you've further issues, or use the github issue site for sbv if you find bugs!
Oh, sure. I've terminated a number of Idris projects because type checking started to take tens of minutes, and Idris' caching is so much worse than Agda. I think you should be able to stitch together the fast part of H-M and OutsideIn for most of the code, and then only engage the slower, more complete DT systems to bridge the gaps... But, yeah, proof-verification can take a while. :)
Man, I'm glad I switched to Linux for my work computers, too. Windows is such a trash OS. Last time I tried, getting a working GHCJS was a couple of trivial commands on Debian. Still, I know other can't or won't use Linux for some reason, so I'm glad this guide exists.
&gt; I always end up working more on customizing my OS rather than using it for actual work. Use Gentoo at home for ~3 years. &gt;:( That's what beat that out of me. I realized to was spending more time fiddling with the OS than *using my computer*, I switched to Debian and outside of some play time with XMonad have been able to focus on the real task in Linux.
 % ghci GHCi, version 8.0.1: http://www.haskell.org/ghc/ :? for help &gt; let 2 + 2 = 5 in print $ 2 + 2 5
Why? The ease of refactoring doesn't change human interaction. Some people don't play well with others; some engineering trade-offs have to be done early, and even have good, long, productive discussion, the trade-offs I need may not be the ones you need; sometimes it's just a question of following the leading edge or having long-term stablity. 100s, if not 1000s of protestant sects use the exact same book. Even if the cost to refactor Haskell code was zero (and it's low, but non-zero), we'd have more than one solution for a *lot* of things.
I learned this out of Hungerford's *Algebra* but without knowing your math background it's hard to know what to suggest you read. Can you tell me more about what you've done in math? &amp;#x200B; I'll just pitch it here roughly the way I'm thinking about it. I'm just making a wild guess at your level of background, so let me know if what I write is familiar to you already or over your head, and I might be able to communicate it better or suggest a reference. &amp;#x200B; The gist of what I'm thinking is that it might be useful to think of "indeterminates" in general as being symbols you can't reduce to an algebraic expression of rational numbers. Then some of these indeterminates will be variable and some of them will be constant (like pi and e). &amp;#x200B; First: an algebraic number is the solution to some polynomial with coefficients in Q, the rationals. That roughly means that it can be expressed purely using fractions of integers, integer exponents and integer roots. A transcendental number is something which is not the solution of any polynomial with coefficients in Q. For instance, you might need an infinite power series to express it, like for e. &amp;#x200B; One of the basic operations in field theory is to take the rational numbers Q and then to "adjoin" an indeterminate *x,* which is more like a constant than a variable. You'd write Q\[*x*\] to represent the polynomial ring with coefficients in Q using variables *x*. So 4x\^2 + 3x - 7 would be in Q\[x\], for instance. Only finite-length polynomials are in Q\[x\], not any infinite power series. This looks already a lot like what you're doing with the symbolic variables. &amp;#x200B; The next thing you do is to adjoin not a variable, but an algebraic number like sqrt(2). This is written Q(sqrt(2)), and it's just Q with all of the algebraic expressions involving sqrt(2) added in (so we have (5sqrt(2))\^3 + (75/22)sqrt(2), for instance). But it's actually the case that Q(sqrt(2)) = Q\[x\] / (x\^2 - 2). The RHS is the polynomial ring Q\[x\] where we have sent every element in the ring ideal generated by x\^2-2 to zero. We can think of this kind of like declaring that the variable x is such that x\^2 = 2, or x = sqrt(2). This gets complicated because there are always multiple zeros of these polynomials, but never mind that for now. &amp;#x200B; The thing that comes out of this is that when you want to adjoin, e.g., pi to Q, you can't do it by this Q\[x\] / (ax\^n + ... + bx + c) business. The best you can do is say Q(pi) = Q\[x, y\] / (xy - 1) and just declare by fiat that x represents pi and y represents pi\^-1. Transcendental numbers have no algebraic relationship with the rational numbers, unlike for algebraic numbers like sqrt(2). &amp;#x200B; So if you want perfect-precision symbolic manipulation involving transcendental numbers and variables, it might be useful to think of them both as "indeterminates" which have been added in to your system of rational numbers. They will just have different behaviours when interacting with the differentiation function. This may be less useful for e because of the special interaction of exponentiation and differentiation. But I think it may be a helpful simplification, at least for transcendental numbers like pi which don't have weird properties vis-a-vis differentiation.
I think you're right haha
Well, this is kind of a different discussion, but... I consider msys2 something akin to the `base-devel` package group which usually does not come with most distros by default. Msys2 provides native Windows binaries / libraries and it's unixy only in the sense that some binaries it provides also exist on unix systems. I think that we can both agree that if the software compiles on both windows and linux and is useful and familiar, why not reuse it? Compiling GHCJS is a major pain both on linux and windows and the only reason I'm using WSL is to avoid long compile times and procuring various dependencies. Again, if the work has already been done for you, why do it again :D
Did know ghcjs which is made by a friend of my friend but IMHO it's a bit heavy.. I'll firstly follow Anrock623's comments to start with LLVM IR transpilation, and your information about dealing with STG or Core can be helpful, too. Thanks anyway.
&gt; Very little is "built in" in GHC Haskell. It's all library code. Sort of... GHC gives hardcoded special treatment (especially in the way of optimizations) to some of that library-defined code. Your own version of `(+) :: Int -&gt; Int -&gt; Int` will work just fine, but it may not be constant folded as aggressively as the `(+)` in the `Prelude`.
I stand with you in the mire of downvotes. The Linux switch was a good career move for me too.
Could you link to a coproduct+free example? I'm still learning to use mtl and struggle to imagine alternate approaches by description alone.
It's in Scala, but [this talk](https://www.youtube.com/watch?v=M258zVn4m2M) is what taught me about the coproduct+free approach. Stuff like `freer` &amp; `polysemy` are extensions to this idea.
A simple and minimalist CLI framework like yours would certainly be a worthwhile project. Making it a library shared by your other projects means that they automatically benefit from further bug fixes and new features to the framework. --- One thing that bugs me is that there seems to be a correspondence between options and paths, which can be lost if they go in different lists. type Options = [(String, Path)] mainOpts :: Options mainOpts = [ ("Hello", hello) , ("World", world) , ("Exit", exit) ] -- Find somewhere else to put the "default" last element of the original mainPaths, -- or have processOption retry the current menu in all cases.
[Data types a la carte](http://www.cs.ru.nl/~W.Swierstra/Publications/DataTypesALaCarte.pdf)
i agree with you completely, thanks for the hint
I would recommend taking a look at optparse-applicative and finding ways to make it easier to use for simple projects and/or beginners. This might mean writing some tutorials, contributing better/more documentation, or writing code that provides simplified interfaces to it. By approaching it this way, you get things like command completion for free, and simple projects won't have to switch frameworks as they grow into more complex projects. Plus, you'll be helping make an already-pretty-awesome library even better.
Since you're getting a lot of criticism on this, I'd just like to say that when I was starting out I would have killed for a guide like this. I had pretty much exactly the experience you described, where learning Haskell was fun and easy, but actually trying to do things with it was a nightmare. I also run into exactly the same issue with Cairo and pkg-config, and since at the time I'd basically never touched Linux I had no idea how to fix it - iirc I ended up downloading a binary from github somewhere and destroying my system path in the process, and I ended up having to uninstall pretty much everything Haskell related and redoing everything using stack. A tutorial like this would have saved me so much time!
Yes I think this is a good idea for sure. One thing I would strongly recommend, similar to @ryantrinkle is looking at preexisting command line parsers such as `optparse-applicative`, shich is the one I currently use, and `cmdargs`, which is another very popular one. But perhaps even look outside Haskell at Clojure, Rust etc to find out what makes them easy/hard to use. If you're writing a slim cmdargs parser in particular I think you should be very opinionated about *how* it works, which means you need to impose restrictions and I think knowing both the interfaces for the programmer as well as the way they present to the user is really useful for choosing the right restrictions. One general pointer that I agree with would be what @Syrak said that things should be as colocated as possible. Furthermore what I havent seen yet, But I'd be interestred in is using something like anonymous, extensible types to represent arguments. For instance the \`aeson\` library parses JSON into a generic `Value` type first which you can treat like generic JSON. The same way you could parse the Options into a generic option structure and then let the user decide how rigorous they wnat to be about the actual values. In particular the `superrecords` library springs to mind as a potenial target. Or simply creating `Map String (Maybe String)` values
Looks good. I'll have to give it go later.
Thanks for the very in depth explanation. That sounds like a much better way to represent these transcendental numbers than what I have going right now. Just checked out a copy of Hungerford's _Algebra_ from the library. I'm 5th semester into a math degree &amp; it seems like something I could probably handle if I took it slowly.
I feel your pain. Fortunately most blog posts these days link to their repo, so we can relentlessly fix typos and the like.
 foo = do let bar = do {- ^ the body of bar must be indented beyond this point -} here -- good not here -- bad bar
Is `pure ()` indented enough? This seems to compile for me: foo :: [()] foo = do let bar = pure () bar
I just checked my copy and it lools like Chapter V Section 1 should have everything you need. You may need to look at the definition of ring ideals if you haven't seen those before, but the ring theory probably isn't essential to see the basic stuff happening with fields. If you can, take the time to read the appendix to V.1! It shows why you can't construct e.g. the trisection of a 60° angle or a cube with volume 2 given a cube of volume 1 using ruler and compass. It's a surprising application to geometry based on the basic field theory concepts.
The record-of-functions approach is pretty close to just manual mtl-style. Operationally they're literally identical except mtl-style is optimized better by GHC.
&gt;It's just so I'm used to Java/Python and I am tired of seeing code well-thought and designed becoming mess after a few changes. I was wondering if it's the thing in the foreign land I'm not sure there's anything which can stop this process altogether. However, Haskell does have one unique strength: refactoring is incredibly easy. A common aphorism in Haskell-land is 'if you refactor and it compiles, then it works', and I've found this to be true in my own experience. Basically, Haskell is an incredibly strongly-typed language, so if you refactor something, then you can usually just follow the type errors to find all the other bits you need to change. What this means in practise is that if you have messy code in Haskell, it's very easy to refactor it into another well-thought-out design; by contrast, in another language, you may not be able to do this quite so easily.
I still think the term is not well-defined. In particular, it looks like your linked document (not sure whether to call it a 'book' or 'paper') falls into the same trap which I talked about above: &gt;I've always felt that the term 'declarative' is so vague as to be useless, and is too often used only as a synonym for 'not imperative'. Now quoting from your document: &gt;Programs written in traditional languages like Pascal or C are imperative programs \[...\] By contrast, declarative programs describe a particular class of problems itself. The task to find a solution is left to the language implementation. This conflates the two definitions of declarativity which I mentioned above: 1. 'Declarative languages focus on describing the problem, rather than how to find the solution' 2. 'Declarative languages are those which are not imperative' The problem with this is that many languages called 'declarative' only satisfy one definition. For instance, Haskell satisfies definition (2), but not definition (1). On the other hand, your link seems to assume that these definitions are equivalent.
I don't think that's true. `(+)` at `Int` is defined [in `GHC.Num`](http://hackage.haskell.org/package/base-4.12.0.0/docs/src/GHC.Num.html) as `I# x + I# y = I# (x +# y)` (and `Int` is previously defined as `data Int = I# Int#`). I strongly expect that there's no special treatment for `(+)` at `Int` or any other type; rather, it inlines and GHC knows how to constant-fold (etc.) the (necessarily) not-library-defined `(+#)`.
Cool idea, I like it! One suggestion that could help readers is to have a repository to clone for this or otherwise some explained way to have a "batteries included" way of testing it out. You mention testing with `stack repl --package lens` but that doesn't actually work as-is because the text package hasn't been loaded and your data types &amp; lenses aren't defined.
I would suggest to not use the lens operators, but the function names. There is no benefit in using the operators for training/learning purposes. It just makes the thing overall harder to read and follow.
&gt; costly Genuine question. One may first use an extension: `-XListIsTwoColons`. Then code could be written to automatically convert to the new version. Maybe raise a warning if the code is compiled without `-XListIsTwoColons` and then roll out the new syntax. It could take time but it would be better than having a language that can't evolve. Right? PS: I'm not advocating for the change tough.
Looks like you are right for `Int` in particular (probably because it is such a tight wrapper around `Int#`), but not for `Integer`: https://github.com/ghc/ghc/blob/1abb76ab8e32e7be224631506201d1beec62a5c2/compiler/prelude/PrelRules.hs#L1240.
I think there's value in having a few integration tests with the whole system, just to verify that the moving bits stick together. But I think the idea is that those tests should always pass, because it's not fun to debug failing integration tests. You want to catch the bugs with the pure tests as often as possible, because they're faster to run, they're reproducible and you can play with them in a repl. Not to mention they enable things like property tests.
I think you're making judgements based on the first page. The document goes on and give many examples of declarative coding as well some higher-order concepts, also demonstrated in Haskell, to make it ergonomic to humans.
That acts on `gtInteger#` rather than `(&gt;)`, but then `gtInteger#` is [defined in Haskell](http://hackage.haskell.org/package/integer-gmp-1.0.2.0/docs/src/GHC.Integer.Type.html) (with a note at the top of the file about constant folding).
That's a good idea. I wrote this under the assumption that readers would already know to do that upon seeing certain types, since there's an assumption that readers already have a baseline level of Haskell experience, but I suppose there's no reason not to make the exercises easier to play with. Thanks for reading!
Duly noted. The main reason I elected to use the operators was to tie into the last section on the various update operators, but I'll probably use the function names if I write anything else on lenses.
My bad: wrong link. Look a couple lines higher to \`plusInteger\`. The point it that these functions have extra special constant folding (that is more than just \`INLINE\`).
Whoa, weird, I was not expecting that. Thanks for clarifying. So if I switch to 4 space indentation instead of 2, will it always avoid cases like this?
The indentation level of the `let` bindings is determined by the position of the first non-whitespace token after the keyword. This is generally true for all indentation-aware blocks, so: let bar = do -- ^ indentation starts here pure () -- Not indented enough let bar = do --^ indentation block of "let" starts here pure () -- Works fine --^ starts new "do" block at same indentation foo = 23 -- Doesn't work because this isn't valid syntax in a "do" block let bar = do --^ indentation of "let" starts here pure() -- ^ indentation of "do" starts here foo = 23 -- Works fine because it's inside the "let" block not the "do" block My advice is to use an editor that's aware of Haskell's indentation rules and/or always use hanging multiline blocks.
hmatrix
Could you give a specific example from the document? I've looked through the whole document now and I can't find any examples of declarativity in Haskell. However you're probably right in saying I'm making judgements based exclusively on the first page.
I am somewhat qualified to comment on this because I wrote the Java equivalent (netlib-java, the linear algebra backend to Spack) and my opinion after all these years in the trenches is that it is best to wrap the native calls that you want to use, when you want to use them! Honestly. It sounds like NIH but there are so many design tradeoffs that any intermediate library has to make that you're best just using your own application's criteria as needed. That way it's even easier to swap between CPU and GPU backends with a little bit of CPP. Just be careful that you know how to pass `ByteString` pointers and that you're not allocating more than you need to.
H. is not declarative but classical imperative language, like C or Pascal: you have not variables unification (only binding), you can not evaluate expressions in both directions, because they are functions and are not relations, you have not any backtracking or solvers but only what you wrote explicitly, just like in C or Pascal, you can not retrieve facts as assertions, etc.
&gt;Functions are written in small pieces and can be lifted to monads or applicatives that do the logging, metrics and reporting. The logging, metrics and reporting code is isolated in the program and works on many arbitrary functions. the same as in any imperative language where you can pass a function/function pointer/procedure name/class instance/whatever to the same one (high-order-something). PowerShell: \`Measure-Object { ... }\`. No any monads! :)
&gt; the same as in any imperative language where you can pass a function/function pointer/procedure name/class instance/blocks/whatever to the same one (high-order-something). Yes. Haskell's typing system makes those higher-order somethings easier to write more reliably. But passing a function pointer is all you are doing the same thing. Haskell isn't magic.
Thank you for all the hard work you have contributed to Haskell. u/monoid_mary, you will be sorely missed!
I often hear that Haskell is good for DSLs (eDSL I suppose). It's not true in comparison with Tcl/Tk or Prolog: in Prolog you can write as in natural English, in Tcl/Tk you can have any nested language, but in Haskell you will have some weird operators, back-ticks and so on noise.
Thank you. I like it. Also I think one might want to take a look at \[let-lens\]([https://github.com/data61/lets-lens](https://github.com/data61/lets-lens)) for complementary resource.
You can hack that (at least with \`brittany\`) by putting empty comments at the end of the columnar lines. Then they won't be collapsed to a single line. Ugly but works when needed.
This is a good idea.
&gt; to write more reliably this is a very controversial statement. I can control types in C# (or Java, Scala) in the same manner as in Haskell when I pass delegates/events/parameterized instances to some method/constructor (sure, not just raw pointer).
We have a good test case. Java has introduced Optional. This doesn't work well (or at all) on most data structures or code. While the equivalent in Haskell (the Maybe Monad) is about 4 short lines of code and works on all functions and datatypes reliably. It has been in use for decades and used in a huge percentage of Haskell code so these claims to adaptability are well documented. Certainly the authors of the Java standard libraries are skilled Java programmers, much moreso than the authors of Gopher who wrote Maybe were. So the difference isn't skill.
but we talked about safety of high-order-functions and their analogues and it's not related to Maybe/Optional
[https://cs.anu.edu.au/courses/comp1100/assignments/02/](https://cs.anu.edu.au/courses/comp1100/assignments/02/) can someone help me with task 2
I was talking about **reliability**. If you can think of a better analogy I'm open to it. This is a good test in practice of the reliability of higher order functions. How comparatively easy they are to implement in Haskell vs. how comparatively difficult they are to implement in Java (and other Algol based languages). You literally have a pair of higher order functions which do precisely the same thing. Both widely support. One was reliable and easy to create the other was not reliable and so far no one is even quite sure how to create it in a way that is genuinely useful.
Another good source of exposure to category theory is in algebraic topology, where a lot of the ideas were first used. The examples will not be as directly applicable, but they are fun!
Remember that it's not just the sandbox you'll have to make location-independent, it's also the GHC installation. My proof of concept demonstrates both that [changing the location of the sandbox is not very hard](https://github.com/gelisam/deploy-hint/blob/master/with-ghc.docker#L38), and changing the location of the GHC installation is possible, but harder.
What is the difference between: public bool hof(Func&lt;string, int&gt; f) {...} and hof :: (String -&gt; Int) -&gt; Bool What is more reliable?
Is the following iterative or declartive? &gt; map::(a→b)→[a]→[b] &gt; map f[]=[] &gt; map f(x:xs)=fx:map f xs The greater question is lambda calculus a declarative or imperative.
second one, certainly &amp;#x200B; because in java method signature does not tell if method treats null in special way or not, afaik H in this case would not allow ever passing absent value
thanks, this what I was told already :D sorry again for saying that
Is it me, or are salaries in London hopelessly low?
`Todo.Core` doesn't use Servant at all. [`Todo.App`](https://github.com/chicagohaskell/servant-presentation/blob/master/src/Todo/App.hs) does, and uses [`serve`](https://hackage.haskell.org/package/servant-server-0.16/docs/Servant-Server.html#v:serve) (a peer of `serveWithContext`). It uses [`enter`](https://hackage.haskell.org/package/servant-server-0.11/docs/Servant-Server.html#v:enter) (now deprecated) to convert the `TodoApp` into a `Servant API`.
Neither. Its a tie. But that's not really the full power of a higher order function. In Haskell you would most likely do something like: hof :: (Show -&gt; Integral) -&gt; Bool Which is not something you couldn't do above but people don't tend to. That habit of maximum generalization and the strong support for it is what makes it easier to create higher order functions like Maybe that work on all data-structures and their associated functions under all circumstances.
What have you tried so far? Do you understand the hints given? Do you know how draw `Picture`s at all (ignore the turtle for now)? I recommend writing `initialState :: TurtleState` based on the sepcification "Assume that the turtle starts at (0, 0), facing north (straight up), with the pen down (on the paper)". I recommend writing `drawCommand :: TurtleCommand -&gt; TurtleState -&gt; Maybe Picture` and `stepState :: TurtleCommand -&gt; TurtleState -&gt; TurtleState`. The first will calculate any draw stroke, if any, from a single command. The second will update the state based on the command (change position, rotation, or pen up/down). Now, you should be able to use these pieces to write `foldCommands :: TurtleState -&gt; Maybe Picture -&gt; [TurtleCommand] -&gt; Picture` as a recursive function. To determine the arguments for the recursive call you'll use `stepState`, and combine the output of `drawCommand` with the input `Maybe Picture`. From there, `runTurtle` is nearly trivial, you just have to provide `foldCommands` with: `initialState`, an empty / grid only picture, and the commands that were given as input.
C# and Java don't have HKT, so some of the things we can have the type checker verify in Haskell, can't be verified in C# / Java (and generally require an downcast somewhere).
Tcl/Tk can't guarantee the DSL programs are well-formed, Haskell's type system can.
Low compared to ... ?
Depends on implementation of the command, for example asm { … } will send its content to assembler, critcl::cproc something {…} sends to C compiler and will make type-checking as well
C# and Java have own unique features which are missing in Haskell, it is not related to the discussion.
In Haskell functions signature does not tell if function can raise exceptions and what type of exceptions there are, but in Java they tell (forget "pure" function `head`). And?
Came to say the same thing. &amp;#x200B; Check out: [App.hs#L34](https://github.com/chicagohaskell/servant-presentation/blob/master/src/Todo/App.hs#L34) and you'll see the usage of [serve](https://hackage.haskell.org/package/servant-server-0.16/docs/Servant-Server.html#v:serve) which as mentioned above is a friend of [serveWithContext.](https://hackage.haskell.org/package/servant-server-0.16/docs/Servant-Server.html#v:serveWithContext) &amp;#x200B; You're comparing versions of `servant` that are quite different.
&gt;That habit of maximum generalization and the strong support for it is what makes it easier to create higher order functions like Maybe that work on all data-structures and their associated functions under all circumstances. Did you mean \`maybe\` function? Or \`Just\` term? &amp;#x200B; You can be very generic in Java/C#/F#/Visual Basic# like in Haskell, you can use type parameters as in Haskell and constraint them with interfaces, base classes, as value objects or references objects only, with default constructors, in F# - with static methods and concrete signatures, etc which is absolutely impossible in Haskell. &gt;To use a String-&gt;Integer function to construct a Bool you essentially have to have a specific string to feed to the function. Depends, you try to speculate about the logic of the function, but it can be paradoxical or very simple, *types do not say anything* (it is a pity that Haskell fans often do not understand this, considering that the type is enough documentation). &gt;And there is already a large library of all sorts of libraries associated with Writers. Do you mean \`Writer\` monad instances? Do you know the number of Java or .NET libraries in comparison with Haskell? Or their quality?
Software engineer salaries in Europe tend to be much lower compared the US. While for many cities that's justified due to lower cost of living, that isn't the case in London unfortunately.
Reflex-dom, but without the PR and less libraries
I do not think they are same
What are some application frameworks? Currently I only know of [eve](https://hackage.haskell.org/package/eve)
Are there any complete (builds, includes example tests for IO/non-IO) examples of using Matt Parson's Three Layer Haskell Cake? See [https://www.parsonsmatt.org/2018/03/22/three\_layer\_haskell\_cake.html](https://www.parsonsmatt.org/2018/03/22/three_layer_haskell_cake.html)
I don't know about any generalized application frameworks like Eve appears to be, but there are a lot of great frameworks for building specific types of applications, eg: - [Obelisk](https://github.com/obsidiansystems/obelisk) for web apps - [Brick](https://github.com/jtdaugherty/brick/blob/master/docs/guide.rst) for Text UIs - [Helm](http://hackage.haskell.org/package/helm) for SDL based Games
This is contrary to the textbooks on which I studied. And there was written: * there are declarative and imperative languages. * imperative languages are: FUNCTIONAL, procedural, object-oriented, and other blah-blah. So, as I know, Haskell is functional, so it's classical imperative language by definition.
It's imperative, because you wrote the algorithm: how to execute mapping. You did not declare some bidirectional relations between input and output and no algorithm behind the scene who generate an algorithm to execute mapping. It's simple evaluation from the one side to another, pattern-matching is just syntax-sugar for *switch* construction, you can write the same with "if" in Python, with flexible pattern-matching in C# - both languages are not declarative as well as Haskell with the similar code - is not. Main difference is: declarative forms/constructs/languages allow bidirectional evaluation because they are based on *relations* (it's a term from logic) and *not on functions*. Also you have in the logic - *logical variables*. With *unification*. Haskell (like lambda-calculus) has not logical variables and does not support unification. It's not a question about implementation: these are terms in the logic and they should exist in the language.
&gt; Depends, you try to speculate about the logic of the function, but it can be paradoxical or very simple, types do not say anything (it is a pity that Haskell fans often do not understand this, considering that the type is enough documentation). OK give me an example of a function which takes a) (String-&gt;Int)-&gt;Bool b) is consistent (i.e. non-random) across runs and machines c) Is not constant (always false or always true) d) does not work via. application of a string &gt; Do you know the number of Java or .NET libraries in comparison with Haskell? Or their quality? Yes I do know the number and quality. I've worked with them many times. Those languages have Haskell beat stone cold on number and quality of libraries. That's not the point of discussion. The point of discussion is the ease on 3 of the 4 cases from the OP and how easy those 3 of the 4 are to do in Haskell. So we are focusing more narrowly.
`const 0::String -&gt; Int` does not need to have a specific string to feed to the function. Also there are a lot of other possibilities: f :: String -&gt; Int f (' ':_) = 0 f s = length s which is surjective too, so input strings are not specific at whole.
Actually "map" has, in relation to all lists of [a], is a functor. A function is a fundament relation between (a -&gt; b) -&gt; (f a -&gt; f b). That's what map in the context of lists define. No one is arguing that you can't implement the above in any imperative language--that's irrelevant to my question. On the to the next question: is lambda calculus declarative or imperative?
Of course, they are not. I was referring only to the most important aspect: "No Need to Write JavaScript"
What are you trying to do? What isn't working? What have you tried doing to resolve it?
Correction: Obelisk is for both web apps (which includes backend server) *and* mobile apps. :-)
`show` \*drops mic\*
This is way above average for europe. UK average for (non-junior) software engineer is ~45k. I've seen junior positions for 25k and less.
Eh, 70k is still a lot; At least enough to easily afford living comfortably and saving a decent amount while doing so, even in London.
You're right of course... I've updated my post accordingly.
As others said, Reflex-DOM is a frontend framework you can use. Specifically, you can use [https://github.com/obsidiansystems/obelisk](https://github.com/obsidiansystems/obelisk) to create a template Reflex-DOM app with a backend and support for mobile builds in about 1 minute. \`ob run\` gives you instant reload of your app both frontend and backend.
About that: is there a non-operator function for getting, besides "view", which is abstract over the reader monad one lives in? This abstraction makes the type a little harder to understand...
&gt; const 0::String -&gt; Int That isn't a definition of `hof` it is rather a specific value to feed to hof. As is your `f`. I asked for a definition of hof meeting criteria (a)-(d)
If you're going to go the route of making it into a repo, maybe it would make sense to have one branch for operators and one for functions, or perhaps find a way to support both in one branch to make it easier for users.
It's always a bit odd to read about averages "for Europe", when the average salary between European countries differs by as much as 20x, and between EU countries by 10x. https://en.wikipedia.org/wiki/List_of_European_countries_by_average_wage
Thank you, this is very helpful!
That's odd - I always thought that imperative was the opposite of functional.
Yeah. Here are some numbers. £85k/year gross is about £4,776/mo net (after income tax). From Numbeo: &gt; You would need around 6,155.57£ (7,965.28$) in San Francisco, CA to maintain the same standard of life that you can have with 4,776.00£ in London (assuming you rent in both cities). In the state of California an income of $140,000/year would net you $95,136 which is around that $7,965.28/mo goal. So earning £85k in London is like earning $140k in SF.
let me list what method signature does not tell: if it mutates state of an object it called on if throws runtime exceptions (on par, alright) if it interacts with real world if interacts with global state if treats null params if returns null &amp;#x200B; I as a Java dev I never bluntly use API people tell me to "just use", because I can't trust because I can't see purity, I have to go into implementation details all the time because of how poorly Java let developers communicate. &amp;#x200B; so talking about reliability, signatures may look similar, but number of things they tell differs vastly, hence reliability
GHC runtime contains garbage collector and uses a lot of esoteric tricks, I doubt they are directly portable into python bytecode. Becides that, If you want for your project to be complete, you have to do more than merely make new backend for the codegenerator, you also need to port `base` package. AFAIK, there is a porting guide, but it wants some specific primitives from the target runtime. I think it is harder to expose them through LLVM IR layer.
Drops mic lol ok kanye
map $ ++ $ show $ mylist im drunk
I'mma let you finish, but {-# LANGUAGE OverloadedStrings #-} module Main where import qualified Data.Text as T data MusicVideo = MV { artist :: Text } deriving Show data Greatness = Bad | Okay | Great | Greatest deriving (Show, Eq, Ord) type GreatVideo = (MusicVideo, Greatness) musicVideos :: [GreatVideo] musicVideos = [(MV "TSwift", Great), (MV "Beyoncé", Greatest)] greatness :: GreatVideo -&gt; GreatVideo -&gt; Ordering greatness = comparing (Down . snd) main = do let video = head . sortBy greatness $ musicVideos print $ T.concat [(artist . fst) video ," had one of the " , (T.pack . map toLower . show . snd) video , " music videos of all time!" ]
First time I've heard about it, but it seems like a neat spot of the-on-the-client vs on-the-server spectrum. I'd like to disagree with the comparisons to ghcjs and reflex. As much as I am a fan of these technologies, the main strength of LiveView seems to be simplicity. You could argue that obelisk(fantastic project) makes it simple enough, but think of how suitable Haskell is for an implementation of LiveView! Image where we could be if we had a few years of Haskell community activity in that direction.
I want to know how are the following definitions translated into the core language of ghc. ```hs f=(+) g a b = a + b h = (\ a b -&gt; a + b) j = (+1) . (*2) k a = a * 2 + 1 m = (\ a -&gt; a * 2 + 1) ``` Which of them has overhead?
How exactly would you use that to get the desired result. I do not really understand instances or type classes.
That actually looks to be on the higher end for full time :( Set LinkedIn job search wide to worldwide, US roles are advertising 200k USD, rest of the world highest just over 200k USD and they are hard to come by. It’s depressing, the cost of living excuse doesn’t stand in London either. Only way to make money in London is contracting,
You can ask GHC to output desugared Core with `-ddump-ds` or optimized core with `-ddump-simpl`. You may also want to pass `-dsuppress-all` to make the output more readable. You can find more info about these options in the GHC manual. I'm not going to make vague guesses about which one of these is more efficient. Keep in mind that GHC's optimisations work across modules, so looking at the Core produced for these definitions will not give you the full picture. Finally, any differences between the definitions you gave are most likely very minor if they have any impact at all.
We shit posting now?
Well, with my knowledge of java, C++, Python, I think f and h is different -- f is plus, and h has a call to plus. Am I right?
I mean, of interest to haskell community. Its a good video. Something wrong?
It's a stale meme whose shelf-life formally ended when Ganz died, and this particular instance is not funny enough to overcome the tastelessness of the trivialisation of both Bruno Ganz' excellent performance in the film, and the subject matter of the film in general.
Thank you very much!
&gt;is lambda calculus declarative or imperative? Firstly, I feel I should reiterate: declarativity isn't the opposite of imperativity. Thinking about it some more, I feel that people are committing the fallacy of [affirming the consequent](https://en.wikipedia.org/wiki/Affirming_the_consequent): while it is true that an imperative language cannot be declarative, it is not true that all non-declarative languages are imperative! Now, to answer the question: I believe that the lambda calculus is neither imperative nor declarative. To start, it certainly isn't imperative: imperative languages require step-by-step evaluation, but lambda calculus can be evaluated in any order (as far as I know; please correct me if this is wrong). However, I would argue that lambda calculus is not declarative either. As mentioned above, my personal litmus test for declarativity is whether you can write 'just do it' (in some form) without specifying exactly how to do it. And lambda calculus fails this test miserably: in order to do *any* sort of useful work you have to manually define the integers, addition, predecessor, booleans, etc., which is the *opposite* of 'it just works'. Not even assembly language requires that level of attention to detail! In fact, starting from the above argument, I would further propose that the functional languages are those which are *neither imperative nor declarative*; that is, they are the languages which are insensitive to evaluation order (*not imperative*) but still require all details to be carefully specified (*not declarative*). Thus we have a three-way distinction between languages: * **Imperative**, where evaluation order matters * **Functional**, where evaluation order does not matter * **Declarative**, where the idea of evaluation order does not even make sense
I did not post this in order to antagonize the community. It seems though that some took offense. And although i do not intend to argue, i stand behind this posting, so i offer the following counterpoint: it’s funny. I saw a conference in which, after his talk, Phil Wadler tore open his shirt to reveal a lambda man super hero outfit. Irreverent. Has no one here read anything from McBride? One of the first things that really sucked me into Haskellland was a pun he made with a line from Shakespeare in Kleiski arrows. If not for that i might still be reading some bone dry IEEE article on info theory. Irreverence has been a part of the Haskel community. It engages people like me who try to read Hinze but our only take away is a quote from the lord of the rings. Irreverence belongs here. At least a bit. Haskell got roasted. We all love haskel. Lets have a laugh.
Nope
&gt; Irreverence has been a part of the Haskel community. I get that, and I don't feel this comes off as "antagoniz[ing] the community" at all. Mostly, I think it's just that memes aren't really a thing in this particular subreddit.
There's separately training in Applied Haskell and Introductory Haskell, before and after the conference, respectively; and a Haskell hackathon on June 9 (Sunday).
Actually the way LiveView works is amazingly similar to how how Reflex-DOM works when run under jsaddle-warp. This is not really oriented at production apps, but remarkably similar. It is, however, very much like how mobile and desktop builds work for obelisk projects. You're right, though, that the production oriented nature of this is different. Reflex-DOM + Obelisk actually have all the tools in place you'd need to do this, since they natively support server side rendering and make it quite easy to pick where and when you want portions to be rendered there.
foldr ((++) . show) "" \[1..10\] I'm new to Haskell; pinch of salt required.
perhaps `concatMap show [1..10]`
&gt; The main reason I elected to use the operators was to tie into the last section on the various update operators That's a fair concern. My take on that for [the Wikibook chapter](https://en.wikibooks.org/wiki/Haskell/Lenses_and_functional_references#State_manipulation) was using the prefix names exclusively until about two thirds of the way through, then having a dedicated section saying "oh, BTW many of those things we have just seen have operator synonyms", followed by briefly covering the `State` manipulation operators such as `%~` (which, like those in your last section, don't have prefix analogues), and finally by carrying on using prefix names wherever possible.
No, there isn't. *lens* mostly doesn't provide specialised versions of combinators. If we take that vantage point, the asymmetry stems from there not being a way to make `^.` work with `MonadReader`.
Can you say me one reason why combinator logic or lambda calculus or object calculus should be declarative? Sure, lambda calculus is super primitive form of calculus which is classical imperative evaluation: from arguments to the result without any declarations. I enumerated a lot of features of declarative languages and Haskell/lambdas don't match any of them. Haskellists always confuse pattern-matching with declarative programming.
Why order does not matter in FP? It does matter everywhere: one of the reasons why monads were introduced in FP. But why evaluation order matters in imperative languages? Compilers ofthen change order of execution if no explicit dependency (like in FP) and if you remember the behaviour of the CPU cache, picture becomes more-more complex. And it's in heart of modern imperative programming: any embedded developer working with DSPs, for example, should remember about it. You touched very interesting subject. FP fans often lies, aspecially Haskell fans. And if you remember in 90s we heard often: FP is the future because multicore comes and FP will naturally and implicitly parallelize! Today we know that Haskell is not more "parallel" then C# or Chappel or Python or whatever :) And automatically parallelization is not more simple in Haskell that in C :) And again: evaluation order in C is free too - if you have not explicit dependencies, compiler can change it like in Haskell (I think it does it more often in C then in Haskell due to optimization of registries usage).
Good)
I \*dream\* of a functional language geared towards data science
what do you mean by "inspecting the context without touching the value"? from a quick look, `match` kinda looks like `either :: (a -&gt; r) -&gt; (b -&gt; r) -&gt; Either a b -&gt; r`, i.e. an eliminator/`case`-alike, in which case "touching the value" would be the whole point.
You can check our example of the `three-layer` implementation for web applications: * https://github.com/holmusk/three-layer Though, our current architecture is slightly different, though, the general idea is the same.
Thanks, your article is a real gem! Just take a look of the registry-lib and in 5 secs saw the link to lib that shows [how different approaches compare to each other](https://github.com/etorreborre/effects) with three computational effects (logging, randomness, and mutable state). The approaches are * A bespoke monad * A standard monad transformer stack * A free monad * The Eff monad from the "extensible effects" framework * A [Registry](https://github.com/etorreborre/effects/blob/master/src/Modules.hs) using the [registry](https://github.com/etorreborre/registry) library &amp;#x200B; **Another gem!**
unclear why GHC can't optimize h to plus because h a b = (+) a b
£70k is enough to be comfortable but if you’re looking for more I don’t think Haskell is the right choice to make.
The [Servant cookbook](https://haskell-servant.readthedocs.io/en/stable/cookbook/using-custom-monad/UsingCustomMonad.html) mentions that you should use the `ReaderT` monad to pass down internal configuration like databases and such. However, the second project seems to just pass down the `Environment` [object down to all of its handlers](https://github.com/bradparker/servant-beam-realworld-example-app/blob/master/src/RealWorld/Conduit/Web/API.hs#L23-L28). Is it basically the same thing as described in the cookbook?
This is using lists, using sets for keeping track of the duplicates would be more efficient: removeDuplicates :: [Int] -&gt; [Int] removeDuplicates xs = removeDuplicatesHelper xs [] where removeDuplicatesHelper [] _ = [] removeDuplicatesHelper (x:xs) found | elem x found = removeDuplicatesHelper xs found | otherwise = x : removeDuplicatesHelper xs (x:found)
Any particular reason why you don't want to use Map? Also you can format the code using [markdown syntax](https://www.reddit.com/wiki/markdown#wiki_code_blocks_and_inline_code)
I mean, it's a meme. Personally I'd rather keep meme culture out of /r/haskell.
It is not. 1) our AIprofessor told us that he implemented a basic prolog in around 300 lines of Haskell. 2) Haskell's type resolution at compile-time is basically Prolog.
I've needed to print the contents of a list prefixed with the element order number, and did this: indexList :: [a] -&gt; [(Int, a)] indexList l = zip [1..(length l)] l Mind you I'm not an Haskell expert, and there are probablly one million better ways to do it.
Please [format](https://www.reddit.com/wiki/markdown#wiki_code_blocks_and_inline_code) your code properly.
`zip [1..] l` would work too
and it wouldn't even force the whole list spine into memory all the time and hang on infinite inputs
True, and now that I think about it, I’m not even sure why I’ve limited the list size by the length, I should probably remove it.
Time for /r/haskellmeme
Have you learned about pattern matching and list recursion?
Good use case for mapMaybe / catMaybes !
Just to clarify - You mean create wrappers on the fly depending on my use-case around the library I linked in the main post (hblas - Haskell bindings for OpenBLAS)? If you mean creating native Haskell bindings around OpenBLAS on the fly, that sounds rather tedious and sounds like a lot more effort than even re-creating the hblas library from scratch.
Yup, you got it.
&gt;Why order does not matter in FP? It does matter everywhere: one of the reasons why monads were introduced in FP. But why evaluation order matters in imperative languages? Compilers ofthen change order of execution if no explicit dependency (like in FP) and if you remember the behaviour of the CPU cache, picture becomes more-more complex. And it's in heart of modern imperative programming: any embedded developer working with DSPs, for example, should remember about it. You're right - I think that my neat picture of 'evaluation orders matters/doesn't matter/doesn't make sense' was just too neat to be true. Given what you've said, probably a better picture of my ideas would be given by this: * **Declarative**: The idea of evaluation order cannot be easily defined * **Non-declarative**: The idea of evaluation order can be easily defined * **Imperative**: Programs are structured primarily as a sequence of lines which are evaluated in a particular order * **Functional**: Programs are structured primarily as nested function calls which are insensitive to evaluation order (i.e. gives the same result irregardless of the order in which the functions are evaluated) &gt;You touched very interesting subject. FP fans often lie, aspecially Haskell fans. I don't think this is a reasonable statement to make at all - I feel that most Haskell fans are fairly aware of what Haskell is good and bad at. Besides, *ad hominem* attacks aren't particularly convincing. &gt;And if you remember in 90s we heard often: FP is the future because multicore comes and FP will naturally and implicitly parallelize! Today we know that Haskell is not more "parallel" than C# or Chappel or Python or whatever. And automatically parallelization is not simplier in Haskell that in C :) I don't think I know enough about parallelism to discuss this topic reasonably. Besides, I don't see how this is relevant to the rest of your argument.
Type classes are ubiquitous in Haskell, so I recommend learning about them early on. That being said, they are not necessary when writing your own functions on your own datatypes, only when using functions from existing libraries, including the built-in functions like `(==)`. My example uses the `IsString` type class, but that's an implementation detail, you can think of it as some magic which allows `And "x" "y"` to mean `And (Var "x") (Var "y")`. It's only syntactic sugar, it's not an extra constructor on which you have to pattern-match inside `variables`, you just pattern-match on `Var s` as if the magic was not there.
Hi! Author here, and I must admit, I was a little perplexed when I saw your question too! Oopsies! Imagine you have `f ~ (,) s` corresponding to some state. In this case, we can use `match fst` to get whatever state is bundled up inside of the `OpenSum` . Or if `f ~ Maybe`, you can ask where the `OpenSum` has a value via `match isJust`.
(Reformatting for old / mobile reddit.) &gt;&gt; assoc 1 "a" [("a",1),("b",2),("c",3)] 1
I discovered an unexpected difference between `cabal new-build --enable-profiling` and `stack build --enable-profiling`, where both `stack.yaml` and `cabal.project` point to a bunch of local packages. The stack-built executable appears to have a cost center for every top-level function in every local package, whereas Cabal puts the cost centers only in the current package. I think I prefer Stack's way overall, but I'd like even better if I could choose which of the local packages are to have cost centers assigned. Is there a way to do that with either build tool? Barring that, is there a way to make Cabal behave like Stack here?
 removeDuplicates = nub ;)
Judging from the documentation it seems like cabal supports [fine-grained per-package control over the profiling detail](https://cabal.readthedocs.io/en/latest/nix-local-build.html#how-can-i-profile-my-library-application)
I meant write wrappers around BLAS / LAPACK as needed. The reason I don't blindly recommend something like `hblas` (without additional context) is because you'll end up hitting linker problems when trying to build it across machines. Different OSes ship with different subsets of BLAS/LAPACK. Also, take a look at how `hblas` manages temp storage, is this something that you need to consider for your usecase? People typically use BLAS/LAPACK when they want to get the best possible performance, so I would not want to presume that creating a temp array per routine call would be appropriate for your usecase. If your usecase is complex enough, then yes, consider writing C to call the BLAS/LAPACK (or GPU equivalents) with whatever setup/teardown you need, which is usually just lots of calls to the hardware. This might also be a sensible approach to take if you already have a numerical algorithm that is written in C or Fortran that has optimal memory management. For example, one of the Explicit Lancos algorithms from ARPACK.
Since \`OpenSum\` is kind-polymorphic, there is something else \`match\` can be used for. Here's a GADT which can hold zero, one, two, or three copies of \`a\`: &amp;#x200B; data UpToThree a n where Zero :: UpToThree a 0 One :: a -&gt; UpToThree a 1 Two :: a -&gt; a -&gt; UpToThree a 2 Three :: a -&gt; a -&gt; a -&gt; UpToThree a 3 &amp;#x200B; Now suppose we know that the value we have is one of a finite number of cases; say, that it's not the \`Zero\` case. We can use \`OpenSum\` to represent the fact that \`oneToThree\` could have one, two, or three copies of \`a\`, but definitely not \`zero\`: &amp;#x200B; oneToThree :: OpenSum (UpToThree String) '\[1, 2, 3\] oneToThree = UnsafeOpenSum 2 (Two "foo" "bar") &amp;#x200B; Since we know that values of type \`OpenSum (UpToThree a) '\[1, 2, 3\]\` have at least one element, we can use \`decompose\` to write a function of type \`OpenSum (UpToThree a) '\[1, 2, 3\] -&gt; NonEmpty a\`. But we can also write functions which don't care about the fact that we have at least one element, like \`toList\`: &amp;#x200B; toList :: UpToThree a n -&gt; \[a\] toList Zero = \[\] toList (One x) = \[x\] toList (Two x y) = \[x,y\] toList (Three x y z) = \[x,y,z\] We could again use \`decompose\` on our \`OpenSum (UpToThree a) '\[1, 2, 3\]\` and call \`toList\` in each of the cases, in order to write a function of type \`OpenSum (UpToThree a) '\[1, 2, 3\] -&gt; \[a\]\`. But it is simpler (and more efficient) to use \`match\`: strings :: \[String\] strings = match toList oneToThree &amp;#x200B; That is, \`match\` can be used to weaken the constraint that \`n\` has to be in \`'\[1, 2, 3\]\`, to the weaker constraint that it has to be one of the values allowed by the constructors of \`UpToThree a\`, that is, 0, 1, 2, or 3. We could use existential types to represent this as "a value of type \`UpToThree a n\` for some \`n\`", and we could eliminate that existential type using a function which works for all \`n\`. Or we can skip that intermediary step by using \`match\` to call the function on the \`OpenSum\` directly.
I'll try it, thanks!
 getIndexOf :: String -&gt; [(Int, String)] -&gt; Int getIndexOf s [] = -1 getIndexOf s ((i,s):_doesntMatter)) = i getIndexOf s (_notS:rest) = getIndexOf s rest
Do you need to preserve the order of the original list?
Horrible on mobile...
What are people using for vim syntax highlighting and indentation of Haskell code nowadays?
I've just submitted 98 pull requests on GitHub to make them buildable on GHC 8.8.1 alpha1 as well as GHC 8.6.4. A large portion of changes are done by scripts so there are probably many mistakes.
Really great explanation.
I prefer servant for routing and handlers, Lucid for HTML, Clay for CSS and depending on how you plan on writing your JS either GHCJS+JSaddle or vanilla JS. TBH though the CSS on my pages is usually so minimal I just write it by hand - but I’ve had good experiences with Clay
Yesod is great. It handles all this stuff for you fairly nicely, but it's also modular enough that you can swap things out if you prefer other solutions (eg it's easy to go from Hamlet templates to Lucid if you want).
it's not too bad, could be better but not horrible
That's pretty cool! How does it infer the new dependency version ranges?
As we've been doing, I blindly bumped the upper bound for packages that are bundled with GHC (e.g. base, template-haskell, time)
Can we see the scripts used for this?
Great post! Two clarifications/elaborations come to mind. If you're optimizing some hot loops, these points might be relevant. HTH. The static argument transformation can be a huge win because it ultimately enables specialization (by first enabling inlining). But, SAT may also have a downside: the `go` function is heap allocated at each call site. Sometimes the inlining doesn't help, or specialization doesn't fire, or etc and the SAT incurs more allocation, which can be relatively expensive. More relevant info here: https://gitlab.haskell.org/ghc/ghc/wikis/late-lam-lift (Nice work, Sebastian! Excited for paper.) Last I checked, ("big") list literals are not unfolded. `foldr (+) 0 [1,2,3]` is not deforested to `1+2+3+0`.
Yesod has the "Shakespearean Templates" languages: Hamlet (for HTML), Cassius (for CSS), and Julius (for JS). That said, I think Cassius and Julius were much more limited compared to Hamlet.
&gt; I think most websites should mostly work without JS enabled. Take your upvote!
You can actually...*still* use Reflex-DOM. You can simply use it's prerenderer to only generate static HTML. Of course, Reflex-DOM is probably bit overkill for that by itself, if you ever decided to do JS via Reflex-DOM you'd simply switch your constraints and you'd be off.
Looks pretty nice on my iPhone... but could definitely be better
Nobody knew [Hackage Matrix Builder](https://matrix.hackage.haskell.org)?
Just use Yesod. I have videos of myself working on Yesod apps on my youtube: [https://www.youtube.com/c/bitemyapp](https://www.youtube.com/c/bitemyapp) &amp;#x200B; You're welcome to email me if you have questions, although I can't promise I won't use the Q&amp;A format as fodder for a blog post :) &amp;#x200B; My GitHub [https://github.com/bitemyapp](https://github.com/bitemyapp) always has my email address.
I'm a simple person. I see \`sequence . map f\` and I want \`traverse\`.
Interesting about SAT. I believe the last benchmarks I saw had it at 20-30%, so very valuable there - but that was quite a while ago. Yes, big literals are not deforested. When I talk about \[1,2,3\] I'm talking about what happens at runtime. Which bit made it sound otherwise?
&gt;and depending on how you plan on writing your JS either GHCJS+JSaddle or vanilla JS. Can you elaborate on this part? Thanks :)
One could argue whether it's a library or framework, but [turtle](http://hackage.haskell.org/package/turtle) for shell-style scripting
Let's think this through. You say you have removeDuplicates :: [Int] -&gt; [Int] removeDuplicates l = reverse (helper [] l) where helper :: [Int] -&gt; [Int] -&gt; [Int] helper seen [] = seen helper seen (x:xs) = helper seen' rest' where seen' = ... rest' = ... OK, I can see where that is going. It looks like the idea is that `helper` takes two lists, one of integers that have been "seen", and one of integers that haven't been examined yet. When all the integers have been "seen", then it just returns that list. When all not all the integers have been "seen", it... that's what you are supposed to figure out. You've got three things to play with to decide what the new `seen'` and `rest'` are: You have the list of things currently `seen`, you have `x`, the head of what hasn't been `seen` yet, and you have `xs`, the remaining things other than those. `x` seems to be the focus of what you are looking at. It seems to me that you should somehow move the current thing you are looking at, `x`, to the `seen` list, and remove it from the `rest` list. The easiest way to do that would be to cons it onto the head of `seen`, like helper seen (x:xs) = helper seen' rest' where seen' = x:seen rest' = xs But that won't solve your problem. That would make removeDuplicates simply copy the list. If only you knew of a way to conditionally add `x` to the head of `seen`. I hope that's a suitable hint. I would probably tackle the problem a different way. I'd write it something like: removeDuplicates :: Eq a =&gt; [a] -&gt; [a] removeDuplicates [] = [] removeDuplicates [a:as] = a:removeDuplicates (filter (/=a) as) The function `filter :: (a-&gt;Bool) -&gt; [a] -&gt; [a]` takes a list and "filters out" the elements that don't match the predicate. The first argument, `(/=a)` is a partial application of the not-equals operator, and works as a function that is true if its argument is not equal to `a`. This means we remove duplicates by taking a list `(a:as)`, keeping the `a`, and to the rest, remove duplicates after removing all copies of `a`. `filter` is built into the standard Prelude, so it's a standard library function akin to elem. But it, too, is not hard to write. It would look something like: filter :: (a -&gt; Bool) -&gt; [a] -&gt; [a] filter _ [] = [] filter p (a:as) = if (p a) then a:(filter p as) else (filter p as) Filtering an empty list just gives you an empty list. Filtering a non-empty list is basically a matter of including the head of your list if it passes the filter predicate, and filtering the tail.
[https://reflex-frp.org/](https://reflex-frp.org/) is an example - last I checked, it worked fully without JS.
If order or resulting list does not matter, you can use: import Data.List removeDuplicates = (map head) . group . sort
If you just want to compile it you can just do: fun3 :: (String -&gt; IO ()) -&gt; IO () -&gt; IO () fun3 = undefined But of course that's not too useful as it will crash if you try to use it. You could instead do: fun3 :: (String -&gt; IO ()) -&gt; IO () -&gt; IO () fun3 _ _ = pure () which won't crash if invoked but still isn't very useful...
If you'd rather write javascript with Haskell you can use the [JSaddle](https://hackage.haskell.org/package/jsaddle) library - think of it as javascript in Haskell (because that's exactly what it is). If you'd like a bit more structure and help you can use [JSaddle-DOM](https://hackage.haskell.org/package/jsaddle-dom), which wraps and describes the browser DOM in terms of jsaddle functions. There are three hurdles working with jsaddle and jsaddle-dom: * provisioning GHCJS * learning the jsaddle combinators like `jsg`, `js`, `js1`, `js2` ..., `fun`, `function` - you also need to know a little bit of `lens` like `(^.)` * getting over the state of documentation in jsaddle-dom If your site is going have very little javascript and that javascript doesn't have to share types with Haskell then GHCJS+jsaddle is really overkill. You will get to ship much faster if you just write vanilla javascript. I liked Scotty. It was my goto router thing until I discovered [servant](https://docs.servant.dev/en/stable/). Servant has you write your routes at the type level, which has lots of cool benefits. One being that your handlers return types as results, just like any other monadic computation. If your route accepts JSON encoding then that type need only provide a ToJSON instance - then your handler will be creating that type based on whatever input it has been given by the route (captures and queries). This makes your handlers simple monadic functions from the route's captured variables and query variables to the types of your website. I never had much luck with Yesod, it didn't fit my preferences, but I tried it out very early in my Haskell career so that could be the main reason I didn't like it. It also has its own quasiquoted DSL for "all your needs" but I found I liked working in regular Haskell more, hence my choices of Lucid and Clay. If all your pages are written in Lucid's `HtmlT` monad then templates are just functions of `a -&gt; HtmlT m ()`. Then you can set up your servant routes to accept HTML as a content-type using [servant-lucid](https://hackage.haskell.org/package/servant-lucid). You then provide a `ToHtml` instance for those your types and now you can serve both JSON and HTML. It's really easy and elegant when you put it all together. But if you want a one-stop-shop framework with a big book you can use Yesod. I'm not sure if Snap or Happstack have books that go along with them.
g isn't a function, so you can't use $ with it. You probably meant `g &gt;&gt;= f "dog"`
You're passing `f "dog"` to `g`, which is of type `IO ()` and doesn't take any arguments (as the error says). One way to get that code to compile is call them in sequence (call `f "dog"`, and then on the next line call `g`). If the type signature was `fun3 :: (String -&gt; IO ()) -&gt; (IO () -&gt; IO ()) -&gt; IO ()`, `g` would be a function that takes the `IO ()` returned by `f` and returns `IO ()` and your code would compile.
&gt; and jsaddle-dom: * provisioning I think you meant to have a bulleted list there. I'm not sure about common-mark, but the old.reddit markdown requires a list stand alone as a block, so it can't be in a position that would join it with previous text. E.g. testing: * 1 * 2 * 3 yields: --- testing: * 1 * 2 * 3 --- but, testing: * 1 * 2 * 3 yields: --- testing: * 1 * 2 * 3 ---
All of those look fine on my phone. But I am using the new Reddit on my desktop.
I can not understand the lens hysteria. It solves no real problem. Introduces a LOT of boilerplate and make compilation times unbearable. It does not impress experienced programmers in any language. It is no coincidencia that since the advent of lenses Haskell has been down in the list of favorite languages? Really accessing fields in structures is so hard problem of computing as to receive the attention that it receives?
Try: https://old.reddit.com/r/haskell/comments/bjhv7x/what_options_are_there_for_nonspa_singlepage_js/em914ez/
What does Haskell have to do with it?
Thanks for the link, though as long as everybody knows there’s three things and you can see those three things, we’re golden.
 strToIo :: String -&gt; IO () strToIo s = print s funThatJustDoesIo :: IO () funThatJustDoesIo = print "world" fun3 :: (String -&gt; IO ()) -&gt; IO () -&gt; IO () fun3 funWithOneArg funThatJustDoesIo = do funWithOneArg "hello" funThatJustDoesIo main :: IO () main = fun3 strToIo funThatJustDoesIo
What makes list literals big?
Sweet! I'm currently just dipping my toes into the water playing with miso. Generally I like it pretty much but one thing makes my head scratch. I'm used to have a very short turn-around time from writing some frontend code to seeing it in the browser (e.g. with Angular's \`ng serve\` it's literally just hitting Ctrl+S in the editor and after 1-2secs the browser would refresh and I would see my changes) . &amp;#x200B; Do you just rebuild the application every time and restart it or have you found a way to use ghci do that for you? What are your turn-around times?
The only one of these I like is the qualified module import syntax.
Aren't they in the repo they posted?
Not that I can find.
1. Reversing colon meaning is really just such a minor syntactic point for pretty much no tangible gain, and lots of potential pain with breaking code examples and having inconsistent code style between different projects or even modules within the same project. 2. I don't see how this is better at all actually. It's also somewhat problematic that there's no brackets in the inline version of `with` and they're `;` delimited; Usually `;` outside brackets delimits declarations. 3. Again, not sure how this is an improvement. 4. I guess that one's OK?
Matrix builder is good for testing packages already published to hackage. Haskell-CI is good for testing your packages against upcoming versions of ghc, but leaves you to do the legwork of finding all of the patches to your dependencies that are needed. (Tangentially, I wish more than just Travis were supported.) What this project adds is that dependency patching part so that you don't have to do it yourself. I think it's a fantastic addition to the ecosystem and sorely needed.
This wouldn't compile.
I'm fine with that, but I think the "Inline function return type annotations" would actually improve code more, specially with local (\`let\` or \`where\`) function declarations. &amp;#x200B; I'm not sure why 'Record “with” syntax' would even be considered an improvement. &amp;#x200B; I'm also not sure 'The “new colon convention”' is worth all the breakage. Old packages get compiled all the time, so we'd have to support both syntaxes for years at least.
Yes. I can't zoom and it shows only one third of the text on the screen. Horrible.
&gt;I don't see how this is better at all actually. It's also somewhat problematic that there's no brackets in the inline version of with and they're ; delimited; Usually ; outside brackets delimits declarations. No, usually ; outside braces just uses implicit braces - just like it does here. You can put in the braces (just like you can in a do statement), and you can use newline or ; (just like in a do statement). In every way, it's exactly the same as all other layout, because it \_really is\_ using the same layout as everything else.
&gt;I'm also not sure 'The “new colon convention”' is worth all the breakage. Old packages get compiled all the time, so we'd have to support both syntaxes for years at least. There's no suggestion of deleting the old. Supporting both isn't a huge amount of work, it's pretty tiny. And it's a language extension, so individual packages/modules can opt in/out on a case by case basis. I think you're overestimating the cost. As someone who has used the single colon for types, and was initially unconvinced it was worthwhile, I have to say that in practice it makes a noticeable improvement. It's not earth shattering, but no one ever wants to go back.
&gt; the legwork of finding all of the patches to your dependencies that are needed. &gt; dependency patching part so that you don't have to do it yourself HEAD.hackage does that for me.
No library functions please
Why is there no Bayhac 2019? I thought I remember seeing a few weeks ago that it would be happening later in the year, like July or August.
&gt; Which bit made it sound otherwise? Skimming your post again, I'm not seeing an indication one way or the other. I think it was the use of literals in your examples juxtaposed with the discussion of compiler transformations, inlining, and rewrite rules that initially caught my eye.
Swapping : and :: is ingenious when you make (syntactically) Haskell-like language, which is however not Haskell. It’s so strong visual difference, it’s a lot more unlikely you’ll mix Haskell code with your new language code. And that’s IMHO important if there are semantic differences, i.e. not all Haskell tricks work as is: changing colons would trigger a switch “now I’m not writing Haskell, so ...”
Yes and i cant use library functions
It does do this well for a number of packages. I'm not sure what the process is for selecting/creating patches, though, or if it welcomes contributions. The format of a cabal overlay is also more of a black box for me. A bunch of git submodules on GitHub, on the other hand, is a format that I can understand easier and feel more capable of contributing to, if I so choose.
I'd like this more if we could not steal syntax with a new keyword.
Looks fine on my phone, can scroll around and zoom as I please. I suggest you browse websites with anything other than a blackberry
That's cool, thanks! This kind of let's us inspecting the value by pattern matching because the kind is known. But still, why would I use it with an open sum, practically? Do you think that using it with things like singletons could also have some value?
That is an ingenious idea! It's not the reason we did it though... we aren't that smart. We had a previous language that used single : for types, so it was a way to move to something off-the-shelf without changing too much at once.
I think a keyword is required to introduce layout. Not much that can be done about that.
Thanks! `Maybe`, `Either` or some sort of a custom state/action is what came to our minds too, but we couldn't say how actually practical it is... Is it accurate to say that `f` allows us to "tag" a value in an open union?
That's cool and I see how it can be an improvement. But what I am afraid of is that both syntaxes reading Haskell would become more difficult: now when I see single or double colon I'd have to think about what meaning it has in this place. Surely, it is not a huge mental effort to realise the context, but it is something that needs to be done. Same as with the other proposals: we introduce a new way of writing the same thing and now we have to read both, and think what to use when maintaining code, and haddock looks different, etc. We already have it with the constraints syntax where you could write (X, Y) =&gt; B -&gt; C Or X =&gt; Y =&gt; A -&gt; B And it doesn't seem to be great from the point of view of readability and consistency.
I have a regular android phone.
Strange, I can't zoom and I'd have to swipe constantly because the lines are long.
Sry
Writing `case ab of A x y -&gt; …; B x y z -&gt; …` or `do q; r; s` is handy in GHCi, and can be a nice way to make things more compact, provided they’re unlikely to change—although personally as a matter of style in committed code I always include braces when using semicolons, except perhaps on rare occasions with `let`.
Could use "of".
I found this point-free version of concatMap (I read that this isn't how concatMap is actually defined, but ignore that if you will for the moment): concatMap = (concat .) . map what's with the parentheses and all that? If it's just calling map on the list, and then concat, what's wrong with just: concat . map ? I assume it's something to do with the types, as in Scheme: (define concat-map (compose flatten map)) is hunky-dory. Thanks :)
&gt; a language extension Ugh. How many of these before it's unacceptable to call the language you are working with Haskell. Seriously, if we actually want to fix the language, we need a new report. I want *Haskell* to improve, not just GHC!
Right idea, wrong implementation. Singe `g :: IO ()` we can throw away the result changing `g &gt;&gt;= f "dog"` to `g &gt;&gt; f "dog"`. Like so (notice you don't need do for the single line monadic action): `fun3 = \f -&gt; \g -&gt; g &gt;&gt; f "dog"` Alternatively, if you want to avoid the lambdas you could write: `fun3 f g = g &gt;&gt; f "dog"`
&gt; But still, why would I use it with an open sum, practically? There are many situations where it is useful to define a type which is similar to another type, except with fewer values: `NonEmpty a` is a subset of `[a]`, `Natural` is a subset of`Integer`, etc. Similarly, `OpenSum Identity '[Int, String, ()]` is a subset of `Dynamic`, and `OpenSum (UpToThree String) '[1,2,3]` is a subset of `Some (UpToThree String)`. That is, while you can always define a custom type representing the subset you are interested in, `OpenSum` is a generic mechanic for representing a certain kind of subsets, namely those which restrict a type parameter to a finite number of values. My `UpToThree` GADT is a bit artificial, but I think it illustrates the idea well, so I'm not sure what else you want me to say. That I once used `OpenSum` while implementing a "real" app like a web server or a video game, something like that? &gt; Do you think that using it with things like singletons could also have some value? I specifically avoided using a singleton as my example GADT because a singleton is typically used to link a type variable with a value-level variable, and doing so only makes sense if that type-level variable is also used by some other type constructor. For example, it would make sense to have a function of type `SingNat n -&gt; Vec n a -&gt; IO ()`, but the type `SingNat n -&gt; IO ()` has little benefit over the simpler type `Nat -&gt; IO ()`. So if I write `OpenSum SingNat '[Z, S Z]`, there is no type variable like `n` which may occur in e.g. `Vec n`. Now that I have written it down, however, I can now see that `OpenSum SingNat '[Z, S Z]` is in fact a very useful type: it's the type `Nat` restricted to a finite subset of values. case, using `match` to pattern-match on the constructor would tell you the exact same information as using `decompose`, namely, it would tell you which of the available
I doubt a barmaid is going to understand what you wrote.
Is there a way to pattern-match on nested records without temporary binds? I.e. ``` data Foo = Foo { someField :: Int, ... } data Bar = Bar { fooField :: Foo, ... } f :: Bar -&gt; Int f Bar{ fooField{someField} } = someField -- fooField{someField} is made up syntax ```
I really dislike `X =&gt; Y =&gt; A -&gt; B`.
You're confusing a monad and a monoid.
Could i use elem to check if x is in rest and if it is add it to the head of seen?
If you want a function that does what your type signature implies: ``` assoc :: Int -&gt; String -&gt; [(String, Int)] -&gt; Int assoc def key = fromMaybe def . lookup key ``` If you want a function that does what the title of this post implies: `Data.List.elemIndex`
As /u/AshleyYakeley suggests you could just reuse an existing keyword.
They are one-time things so they are rather ugly and no longer useful. Unfortunately I've discarded many of them.
There are good (unofficial) Haskell bindings for TensorFlow contributed by Google staff. I can usually build the latest version and experiment with the examples without too much trouble, except getting it running with a GPU.
I think I get what you're talking about as I was minimizing the endofunctor part, right? &gt;Monadic operations can't be parallelized, almost by definition. What about [Control.Monad.Parallel](http://hackage.haskell.org/package/monad-parallel-0.7.2.3/docs/Control-Monad-Parallel.html)? &gt;This module defines classes of monads that can perform multiple computations in parallel and, more importantly, combine the results of those parallel computations.
 f Bar{ fooField = Foo{ somefield } } = someField I think.
&gt; I assume it's something to do with the types Yep. Work through the type of `concat . map` and you find it's (a) not what you want and (b) different from `(concat .) . map`.
I used uMatrix to black all the JS requests from my Chromium, and while the site is small, it does appear to work fine.
While on the topic... Why can't we have a way of matching a pattern where pattern failure is a definable behaviour? I'd like to be able to do: ``` getThing :: [String] -&gt; Pattern (a, b) getThing = ~case ["Thing", a, b] -&gt; (a, b) ``` The syntax is just an example.
I just like to think of them as conputational contexts. If I'm asked to elaborate, I talk about lifting (\`(a -&gt; b) -&gt; m a -&gt; m b\` and \`a -&gt; m a\`), selecting (\`m a -&gt; (a -&gt; m b) -&gt; m b\`), and nesting (\`m (m a) -&gt; m a\`).
I'm dubious about 2, but I like the others. But I'm afraid 1 will sadly never happen.
That monad supports parallelism by specifying functions similar to bind that take functions of multiple arguments. The bind operation of the monad typeclass takes a function of one argument, and it essentially acts as a sequencer.
&gt;I started with "Monads are monoids in the category of endofunctors." Personally, I don't think that's the best place to start at all. I doubt that even most Haskellers would be able to adequately explain what this means - I certainly can't. If I were to explain monads to a layperson, I would start with the importance of controlling effects (e.g. `IO`, `Maybe` etc.), then introduce functors and then monads as a way to sequence effects without needing something of type `m a -&gt; a`.
Now that I'm thinking about `Control.Arrow`, `+++` is pretty nice too: example3 :: (Bool ? Ordering ? Int) -&gt; (Bool ? Ordering ? Int) example3 = \case False -&gt; True True -&gt; False +++ \case LT -&gt; EQ EQ -&gt; GT GT -&gt; LT +++ \case n | 0 &lt; n &amp;&amp; n &lt;= 5 -&gt; -n n -&gt; n - 5
Sorry, I don't understand this. What happened? I am using Firefox on Linux.
I'd approach this by first building a function that simply applies `f` over and over and produces the full (infinite) list of outputs. Its type would be the same (`iterate :: (a -&gt; a) -&gt; a -&gt; [a]` if you want to make it polymorphic, which it should be without any extra work). Doing this would require a recursive function that makes the list, first putting the current value of x, then appending the recursive call. After you do that, you could just add a base case to that function that checks if `f x == x` and returns just `[x]` in that case. (also if you make `fixPointL` polymorphic you need `Eq` in the type, like this: `fixPointL :: (Eq a) =&gt; (a -&gt; a) -&gt; a -&gt; [a]`)
Generally, when I start having Eithers inside Eithers (or Maybes inside Maybes, or etc) is the point where I start writing custom data types. Consider: data Foo = Foo Bool | Bar Ordering | Baz Int example :: Foo -&gt; Int example (Foo False) = 0 example (Foo True) = 1 example (Bar LT) = 2 example (Bar EQ) = 3 example (Bar GT) = 4 example (Baz n) | n &gt;= 0 = n + 5 | otherwise = n Don't be afraid to introduce new datatypes.
Oh, I'm not. But I think I introduce new datatypes much quicker for type sums rather than type products, and I think the reasaon behind that is syntactic, not semantic.
It would save alot of typing to add LANGUAGE pragmas.
Now imagine a Haskell where case statements have a type that includes the patterns they match: example4b :: (Eq a, Num a, Matches '[0,1] arr) =&gt; arr a Bool example4b = \case 0 -&gt; False 1 -&gt; True example4o :: (Eq a, Num a, Matches '[2,3,4] arr) =&gt; arr a Ordering example4o = \case 2 -&gt; LT 3 -&gt; EQ 4 -&gt; GT And a way to combine partial matches: ghci&gt; :t Left . example4b `orMatch` Right . example4o example4b `orMatch` example4o :: (Eq a, Num a, Matches '[0,1,2,3,4] arr) =&gt; arr a (Either Bool Ordering) Then we could define an inverse for `(|||)`: (---) :: (forall arr. Matches ps arr =&gt; arr a b) -&gt; (forall arr. Matches qs arr =&gt; arr a c) -&gt; forall arr. Matches (ps ++ qs) a (Either b c) f --- g = Left . f `orMatch` Right . g infixr 2 --- Making something like this possible: example4 :: Int -&gt; (Bool ? Ordering ? Int) example4 = \case 0 -&gt; False 1 -&gt; True --- \case 2 -&gt; LT 3 -&gt; EQ 4 -&gt; GT --- \case n | n &gt;= 5 -&gt; n - 5 n -&gt; n
I'm also dubious about 2. In particular, it doesn't sit well with GADT syntax, and I'm increasingly convinced that GADT syntax is the right syntax for algebraic data types.
So far I just found out if I **append** command `" | head -1000"` to some command such as "top" =&gt; "top | head -1000" =&gt; then I get **return** from my **runSh "top | head -1000"**
I hope someone can come up with a better solution.
https://old.reddit.com/r/haskell/comments/bjew32/how_to_search_a_list_and_return_the_index/em7k2ia/
Check out [digestive-functors](http://hackage.haskell.org/package/digestive-functors)! It's pretty old-school in that it expects the user to submit a form and then the server responds with html, rather than a more modern ajax-based interaction, so that sounds right up your alley. I like how it combines pieces which include both the frontend presentation and the backend validation parts; that seems much more composable than the modern approach in which adding a field requires separately adding a new widget to the frontend, a new validation to the backend, and a new field to the intermediate json representation.
For what it's worth, I'm in favor of an option to swap colons. It may not be used much in idiomatic Haskell, but I'd definitely make the swap in CodeWorld, where I'm only using GHC by accident and actually care more about matching math syntax. (Even there, I'd probably do some kind of hack, like try parsing it both ways, and use the old syntax if the module parses that way and not the other way. But that's just a matter of compatibility. I'd swap over the teaching materials, and in a few years I would deprecate and remove the backward compatibility hack.)
Proposal 3, while it's an improvement, makes me wonder if instead of piecemeal adding this one expression type in function declarations, there's a more systematic way to interpret expressions on the left-hand side of a declaration. Perhaps not, but this proposal has the smell of "here's one more edge case", and I can't help expecting to see the next edge case in a different proposal. Less important, perhaps, but should `f x = ...` be legal while `(f x) = ...` is not?
In the "endofunctor" part the category in question would be Hask, the universe of Haskell types with functions as morphisms. (Note that strictly speaking it's not a category at all but it's convenient to think so.) And monoids are thus formed of functors Hask -&gt; Hask where computing the binary operation means reducing a functor `f . f` to `f` (that would be `join :: Monad m =&gt; m (m a) -&gt; m a` in Haskell).
Come on, you keep posting (homework?) questions in which you state the problem but don't make any effort solving it, you just leave the implementation completely blank. We're happy to help you to learn Haskell, but so far it doesn't seem like our efforts have actually taught you anything? Tell us what you've tried and where you got stuck, because so far it just looks like you want us to write your homework for you.
Just because C# and Java have unique features does not mean higher-kinded types are not related to discussion stemming from your comment: &gt; I can control types in C# (or Java, Scala) in the same manner as in Haskell when I pass delegates/events/parameterized instances to some method/constructor Seems very relevant to me.
For what it's worth, your first code block above is far and away easier to read that the later alternatives. The repetition doesn't really cause any problems.
I don't think there's anything known as a barmaid anymore, so saying a barmaid would understand is true, trivially.
You're probably right, but the point that I was trying to make is that the OP's definition is still far too technical for a layperson in my opinion.
That's a much nicer way of saying what you said before!
I can't speak to the dynamic linking issue, but I would point out that static linking is possible with proprietary code and the LGPL as long as you provide linkable object files. Really the only thing the LGPL cares about is that end users can replace the LGPL parts themselves; it doesn't really care how. That said, I don't know how much of a pain it would be to provide linkable object files for haskell programs.
There's just noone working on windows: FLOSS developers prefer linux anyways, and commercial ones slant heavily towards server software. As such it might be that the fix is actually easy *for a windows dev*, but as there's nearly zero of those around in the community, it hasn't been done yet. &gt; like f# or Scala. Rust has excellent windows support.
The issue with libgmp is quite well-known. Haskell can run with its own replacement implementation. It might be a bit less efficient. But it sounds like this is not the main problem here...
&gt; 4. Module qualified syntax Hum, I'd instead make qualified the default, like in Elm. I really struggle to read other people's code when it uses unqualified imports, or doesn't explicitly import things. It's hard to know where anything comes from!
Haskell’s composition operator is only for linear pipelines of functions, which always have one input and one output. This is how you can get to the point-free version by hand: concatMap f xs = concat (map f xs) concatMap f = \xs -&gt; concat (map f xs) -- (\x -&gt; g (h x)) = g . h, g = concat, h = map f concatMap f = concat . map f concatMap = \f -&gt; concat . map f -- (\x -&gt; g (h x)) = g . h, g = (.) concat, h = map concatMap = \f -&gt; (.) concat (map f) concatMap = (.) concat . map -- Using a section instead of a prefix call concatMap = (concat .) . map Although I prefer to write it like this: concatMap = fmap concat . map Since `fmap :: Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b` setting `f ~ (-&gt;) x` (the `Reader` functor, but without the `newtype` wrapper) gives `fmap :: (a -&gt; b) -&gt; (-&gt;) x a -&gt; (-&gt;) x b`, or `fmap :: (a -&gt; b) -&gt; (x -&gt; a) -&gt; x -&gt; b` in the usual notation, which is equivalent to `(.)`, but also looking at `fmap concat :: (x -&gt; [[a]]) -&gt; x -&gt; [a]` you can see how it lets you “map over” the extra argument to `map` so `concat` acts on the result of `map f xs` rather than the function resulting from just `map f`. You could even write `fmap (fmap concat) map` but imo that’s a step too far. ;) The `(-&gt;) x` applicative is useful for point-free code generally, especially in conjunction with the `Control.Arrow` combinators. For example, to combine some fields of a record, you might write code like this: data WorldPoint = WorldPoint { px, py, pz :: !Double } data ScreenPoint = ScreenPoint !Double !Double type Projection = WorldPoint -&gt; ScreenPoint orthographic, perspective :: Projection orthographic = ScreenPoint &lt;$&gt; px &lt;*&gt; py -- or: orthographic = liftA2 ScreenPoint px py perspective = ScreenPoint &lt;$&gt; ((/) &lt;$&gt; px &lt;*&gt; pz) &lt;*&gt; ((/) &lt;$&gt; py &lt;*&gt; pz) -- or: perspective = liftA2 ScreenPoint (px &lt;/&gt; pz) (py &lt;/&gt; pz) (&lt;/&gt;) = liftA2 (/) Haskell isn’t really built for writing complex point-free code; for that, you may be interested in concatenative languages which use (left-to-right) composition instead of application as the default, so e.g. `concatMap` could be defined as just `map concat`.
You say you've been trying for days... Well, what have you tried?
1. It triggers the perfectionist in me that it's double colon but it ultimately doesn't matter that much. It could be that it's easier for newcomers to understand the relationship between normal math functions and haskell functions if there is a single colon but I doubt it. 2. With does make it semantically clearer what's going on but I don't like when syntax rely to much on whitespace. Maybe it could be `r with {foo = "bar"}`? 3. Don't understand this one 4. Make it instead that you qualify imports by default and then make the programmer explicitly import specific functions. This would also help stopping library designers from introducing more operators as they'd be tedious to import. Win-win.
That's bad. I have no idea what happen. How can I prevent this problem? Hope reddit have fix on this issue soon.
have you tried `cabal`'s `foreign-library` component?
It's how it's done in Purescript. I really disliked it at first too, but I have to admit it is nice for when you have a lot of constraints with long names that won't fit on one line neatly (particularly with mtl-style constraints). For example: foo :: forall e m a . MonadThrow e m -- You can also add inline comments for constraints this way =&gt; MonadAsk Env m =&gt; Bar -&gt; m Baz
Exactly. GHC compiles to good ol object code, so it's absolutely not a problem to supply an object code library(ies), which may be relinked against different LGPL part (I did this in past).
The way we as a community improve Haskell is by making language extensions then sometime later putting those as on by default in a haskell report.
Yep, suspect that would work!
2 is nice in practice once you fix records so they are useful. However, it's the one where we might be discovering a problem (records have non indentation {} and no indentation layout), but might not have hit on the perfect solution.
In other languages there is more of a distinction between sums and products, and mixing both in one construct is considered a bad idea. I think of 'with' as the record version of GADTs
Proposal 2 does allow what you describe. It's just the {} are optional, like do etc
Ty that is very helpful
&gt; There's just noone working on windows: FLOSS developers tend to prefer linux anyways, and commercial haskell users slant heavily towards server software. Actually, there are a number of Haskell developers using Windows, and in fact SPJ is employed by Microsoft Research. Dynamic linking being a second class citizen is a problem on Linux too, and where actually most programs *are* dynamically linked (to shared libraries that actually get shared).
It was my impression that Microsoft Research pays SPJ to do whatever he wants as long as his office shares a water cooler with that of the .NET people. &gt; Dynamic linking being a second class citizen is a problem on Linux too It's working perfectly fine, but ABIs are necessarily different between even minor versions of libraries, as well as different compiler versions. Non-nix distro infrastructure was never designed to deal with that.
Fewer jobs, so the spread of possible incomes isn’t going to be as wide. Choosing niche programming languages and environments to specialise in is restricting a lot of possible opportunities.
It doesn’t terminate... Run “top” manually in your shell. It should stay open. Using “head” will truncate after the first n lines of stdout, so it will return.
I did manage to get [https://github.com/tensorflow/haskell](https://github.com/tensorflow/haskell) running by using an older LTS with stack on its own. The problem lies in getting it to work with a IHaskell kernel, as the two seem to have different version requirements for a common dependency. As it is, I don't think the type system is *as* big an improvement for data science workflows as Jupyter Notebook, so it would make more sense to dump Haskell than dump Jupyter.
As much as I want to like this, when I look at the middle case in `example2` my instinctive reaction is to wonder "is that `Left . Right` or `Right . Left`?
Monad is just a fancy name for flatMap. - [Hitler](https://www.youtube.com/watch?v=ADqLBc1vFwI&amp;feature=youtu.be)
Totally. Even for experts that slogan is not completely clear. To define a monoid, we need a tensor product. What is the tensor product for functors? We can choose: pointwise Cartesian product, or function composition. (It’s the latter.) So if you want to understand monads through that slogan. There is so much to uncover first...
I quite like #3, the type and name of a value are strongly related to each other, so it makes sense to have them closer together. In practice, I've absent-mindedly changed the order of a function's types while forgetting the names more often than I care to admit. Not game-changing but nice and easier for a human to parse. It's essentially a list of tuples rather than a tuple of lists.
[Wadler's Law](https://wiki.haskell.org/Wadler%27s_Law)
If you want to understand the sentence "Monads are monoids in the category of endofunctors.", you have to understand categories, monoids and endofunctors first. I suggest you to slow down and tackle each of these concepts separately. Category theory is hard even for mathematicians. It takes time to digest. That said, you don't need to understand the definition of monads in order to **use** them. For example, you can start from the `Maybe` data-type, and learn what happens if you chain multiple Maybes with `&gt;&gt;=`. Then you can learn `IO`, `Either e` etc., play with `do` notation, learn how to desugar it. You can develop complete Haskell programs without knowing what a monad is. In fact, there are plenty of experienced Haskell developers who don't know category theory but can write advanced applications and libraries.
Thinking out loud: if for whatever reason we are compelled to have `example` take nested eithers, pattern synonyms (or perhaps view patterns, if you specifically want to use a `Foo` type) might be helpful: {-# LANGUAGE LambdaCase #-} {-# LANGUAGE PatternSynonyms #-} pattern Foo b = Left b pattern Bar o = Right (Left o) pattern Baz n = Right (Right n) exampleP :: Either Bool (Either Ordering Int) -&gt; Int exampleP = \case Foo False -&gt; 0 Foo True -&gt; 1 Bar LT -&gt; 2 Bar EQ -&gt; 3 Bar GT -&gt; 4 Baz n | n &gt;= 0 -&gt; n + 5 | otherwise -&gt; n
If products were distinct -- they could all be unlifted like newtype, which would be pretty great. * (a,(b,c)) would be isomorphic to (a,b,c), so we could get rid of the bazillion tuple types * we wouldn't need newtype anymore OTOH: * pattern matching on a product might cause more thunk allocation * `seq` on products would make no sense, would need to decide what it even means
The 'top' program has parameters `-b` and `-n` for use in scripts. For example, this here makes 'top' just print the process list once and then returns immediately. top -bn1
oof wasn't careful enough, sorry
You can emulate the updates in (2) with `-XRecordWildCards` in the following way: updateRecord :: Rec -&gt; Int -&gt; Rec updateRecord r@Rec{..} newInt = r{..} where intField = newInt
Sorry if this is obvious to you, but you can't have `(---)` as an operator because `--` is comment syntax!
Not to turn this into a thread of monad tutorials, but my *informal* description generally goes something like: &gt; A monad is a context in which you can run some computations. These contexts can have entirely different meanings. The meaning comes from the definition of the *monadic combinator* which is either `(&gt;&gt;=)` (bind) or `join`. This describes how we can evaluate the computation. Which is then followed by a couple of examples... usually `Either`/`Maybe` and `List`. More involved examples (eg. `IO`) are explained with reference to their semantics rather than the actual construction of `(&gt;&gt;=)`.
Yesod is great. The worst thing about it is that there's no good way to make something Small but Robust. It's fairly easy to make something small just by combining stuff in the obvious way. And big, robust things are easy because the scaffolding is good. But there's no middleground. I think one of my next projects will be to provide a SMALL template which can be used to make readable projects which are still robust and well-constructed.
The problem is that GHC doesn't even make a token effort to maintain a stable ABI across minor version changes (or even option changes).
I often think of the quote by Von Neumann: "In mathematics you don't understand things. You just get used to them." So instead of going through the definitions and try to explain them. Just use monads! Write your own monads, etc... And some day, you are used to them!
I've been working on this for a few months now, and I think it's ready to share at this point. The program runs as a Command Line program, and is capable of downloading torrent files. I've tested it "in the wild" and it seems to work decently. The feature-set is pretty basic atm, but should be easy to expand further.
That's not the point though
As far as I’m aware this is the only BitTorrent client in Haskell, so this is pretty nice.
Wrong. Check this, for example: http://jlouisramblings.blogspot.com/2010/04/haskell-vs-erlang-for-bittorent-clients.html
I see sorry
[https://github.com/ghc-proposals/ghc-proposals/pull/220](https://github.com/ghc-proposals/ghc-proposals/pull/220) proposes to make qualified the default.
Thanks for the awesome talk, it's re-piqued my interest in free monads. Mostly just pinging you to see if you've run these benchmarks yet, and if you have any idea how far away your changes are from getting into GHC.
Your starting point "Monads are monoids in the category of endofunctors." is just a curious observation written as by Saunders Mac Lane in Categories for the Working Mathematician. The comment is preceded by several chapters explaining monoids, categories and functors. There is an intuitive definition of what a Monad is. Its a Functor where the values can be constructed in a super natural way. That is, for every type **a** there is a function **u\_a:a -&gt; M(a)** such that for any other function **f:a -&gt; M(b)** there is a function **f':a-&gt;b** such that **f:a-&gt;M(b) = M(f') o u\_a: a -&gt; M(a) -&gt; M(b)** That is, its so good that every other function from **a** into **M** can be refactored using it and a mapped function. If you are in a nice enough category everything else follows using duality and some trickery (though its been to long for me to remember exactly how) &amp;#x200B; For me, the hard part of grasping any concept in math is accepting that its just what the definition says, nothing more and nothing less. This is usually impossible to achieve by trying to explain it away, math definition are already simplified as much as possible by their nature. The only way for me to get used to them is to use them until I accepted they can not be anything more that what they are. Not sure if that helped..
I kind of get it, but it reads weirdly for me. It feels harder to tell what's a constraint and what's an arg, and it makes me think suspiciously that somehow the first constraint is constraining the second. I just don't really see how it's much better than: foo :: forall e m. ( MonadThrow e m -- You can also add inline comments for constraints this way , MonadAsk Env m ) =&gt; Bar -&gt; m Baz I don't really use `mtl`, so maybe the benefits aren't as obvious to me.
That’s one reason I had the value-level `?` paired with a type-level `?` - whatever the fixity was, it’d match.
Right, but as I can’t yet have GHC list matched patterns as part of the type, it’s a bit moot.
Fair point!
That makes sense if it's the programmer seeking out specific languages to work in, but not if it's the employer preferring work be done in a specific way. Regardless, this isn't a Haskell-only problem. London comp is low across the board from what I've seen.
Can you explain some more ? Why is a small Yesod app not robust ?
I guess my definition of "robust" was a bit hazy. A small (eg. one-file) Yesod app will work fine, but it won't have some useful features like configuration loaded from file; or hot-reloading of code during development; or database integration with sql pools. It's quite a lot of effort to introduce those things and it's all done for you in the scaffolding.
try http://hackage.haskell.org/package/haskeline or http://hackage.haskell.org/package/repline
Pretty cool
I'rs been 9 years (since the last report; *much* longer for some extensions). When is later?
There were lots of attempts done on this front in the past, but this is probably the most complete one.
&gt; I have no idea what happen. You used a formatting that is not supported by old.reddit (or some of the mobile apps). &gt; Hope reddit have fix on this issue soon. Reddit has stated that there will be no updates to the old.reddit code, in particular the comment rendering. I don't know about mobile. I suggest you use a formatting that works with old reddit. I've tried switching to new reddit several times, and it is strictly inferior; and greatly inferior to old.reddit + RES. Also, I used the old paging behavior (instead of infinite scroll) to limit my time on reddit. I'm trying again, but I think I will need to switch back because the unread comment count isn't showing up on threads.
I propose we use 'TSEP' as type separator and 'LSEP' as list separator, replace every instance of each in hackage, then let the client distribution decide on his own preferred symbol by a path variable. With some GHC/cabal-install/stack magic to do so transparently, this solution is backwards compatible and will surely improve the situation. Jokes apart, 2 is interesting, 4 helps a bit but is pushing the problem to the other end, 3 feels like should be valid haskell. All 4 are nice decisions for a new language, but IMHO some are just too much mental work for the community at this point (1 particularly).
&gt; There's just noone working on windows: There are at least 1 working occasionally on windows: SPJ. However, IIRC, Tamar Christina (a.k.a. phyx) is the main (only?) workforce on windows compilation issues.
 getThing :: [String] -&gt; Pattern (a, b) getThing = case of ["Thing", a, b] -&gt; error "Incomplete negative pattern match; i.e. matched" _ -&gt; (a, b)
I've never looked at core before, but this is the output of `-ddump-simple -dsupress-all`, so it looks like he is right: -- RHS size: {terms: 2, types: 1, coercions: 0, joins: 0/0} f f = + $fNumInteger -- RHS size: {terms: 6, types: 3, coercions: 0, joins: 0/0} h h = \ a_atx b_aty -&gt; + $fNumInteger a_atx b_aty
Used in any real context it will be inlined an optimized identically. I doubt you could replace one with the other and produce assembly that differed, but would be curious of your results if you try.
You are indeed correct, this: foo :: Int foo = h 3 6 + g 5 7 produces this: -- RHS size: {terms: 14, types: 3, coercions: 0, joins: 0/0} foo foo = + $fNumInt (+ $fNumInt (I# 3#) (I# 6#)) (+ $fNumInt (I# 5#) (I# 7#)) It makes sense that it would be further optimized at the use site, but that didn't occur to me since this is my first attempt at viewing core and Solonarv's introduction said that "-ddump-simpl" would produce "optimized core" so I naively assumed that was the end of the story.
OK, I gave it a go using NOINLINE and no optimization. &amp;#x200B; With \`h = \\x y -&gt; x + y\`: &amp;#x200B; \`\`\` Foo.h\_info: \_c1bP: leaq -24(%rbp),%rax cmpq %r15,%rax jb \_c1bQ \_c1bR: movq %r14,%rax leaq GHC.Num.$fNumInt\_closure(%rip),%r14 leaq stg\_ap\_pp\_info(%rip),%rbx movq %rbx,-24(%rbp) movq %rax,-16(%rbp) movq %rsi,-8(%rbp) addq $-24,%rbp jmp GHC.Num.+\_info \_c1bQ: leaq Foo.h\_closure(%rip),%rbx jmp \*-8(%r13) .long Foo.h\_info - Foo.h\_info\_dsp \`\`\` &amp;#x200B; and \`f = (+)\`: &amp;#x200B; \`\`\` Foo.f\_info: \_c1cm: leaq -16(%rbp),%rax cmpq %r15,%rax jb \_c1cn \_c1co: subq $8,%rsp movq %r13,%rax movq %rbx,%rsi movq %rax,%rdi xorl %eax,%eax call newCAF addq $8,%rsp testq %rax,%rax je \_c1cl \_c1ck: leaq stg\_bh\_upd\_frame\_info(%rip),%rbx movq %rbx,-16(%rbp) movq %rax,-8(%rbp) leaq GHC.Num.$fNumInt\_closure(%rip),%r14 addq $-16,%rbp jmp GHC.Num.+\_info \_c1cl: jmp \*(%rbx) \_c1cn: jmp \*-16(%r13) .long Foo.f\_info - Foo.f\_info\_dsp \`\`\` &amp;#x200B; So indeed, in the narrow context we do get different assembly bu both ultimately jump to \`+\`. We have to enable some optimization to recover the original form.
What are the serverless deployment best practices for Haskell and which cloud providers are supported in 2019?
Your explanation doesn't minimize the endofunctor part - it doesn't do anything at all with it. You have a solid grasp of a monoid, but you've latched on to "A monad is a *monoid* in the category of endofunctors" and run with it, and the notion has led you astray. If you want to know what a *monad* is, you have to start thinking about it's distinguishing features from other classes of things. In Haskell, that's the `&gt;&gt;=` and `join` functions, which are interdefinable: ma &gt;&gt;= f = join (fmap f ma) join mma = mma &gt;&gt;= \ma -&gt; ma They have laws that need to be followed. Find out what it means - in code - for the laws to be violated, and how that could violate expectations you might have about the code. Figure out types that don't have `Monad` instances. Why not? What is the problem?
At our work we are using [serverless-haskell](https://github.com/seek-oss/serverless-haskell) and bunch of `amazonka` packages (depending on needs) to deploy AWS Lambdas. Works good so far :+1:
First one in this half of the decade.
First one on this month
I would also suggest these packages! I’m unsure if there is a good standalone “REPL tutorial” for haskell, but Stephen Diehl’s WYAH book has a [chapter that builds a simple one](http://dev.stephendiehl.com/fun/006_hindley_milner.html#interactive-shell).
I... got downvoted for admitting that I don't know things about HEAD.hackage? Perhaps the downvoters could instead explain "here's how you contribute to it", "here's where you can read about the format of it", things like that?
Some of these things are explained on the project's github page: https://github.com/hvr/head.hackage I'm not quite clear on why the tagline is "This is not the Git repo you're looking for", because it does seem to be the git repo I was looking for, in this instance.
&gt; For me, the hard part of grasping any concept in math is accepting that its just what the definition says, nothing more and nothing less. That's the hard part of maths for pretty much everybody. Your ease at doing this is directly proportional to your mathematical skill (though not necessarily your education). There's been some psycological testing, though nothing incontrovertible, to confirm this common intutuion.
A really common function I end up writing in almost every project: both :: (a -&gt; c) -&gt; (b -&gt; c) -&gt; Either a b -&gt; c Makes this way easier, you just nest calls to 'both'. The functions are easy to read and understand at a glance, and it saves a fair amount of boilerplate. I find most syntactic issues along these lines can be solved with similar methods, and get similarly good results. I strongly feel that new syntax is a bad way to approach this challenge, unless it could be built to support a much broader lens-like concept, and even then I am on the fence about adding special syntax to support the case. One of the things I really like about Haskell, and most functional languages, is how consistent and straight forward the syntax is. It keeps my solutions straightforward and easily portable to new contexts. It also means that I can understand any term level function, no matter how complex, as long as my foundational knowledge is good - there aren't many rules, and everything has to follow them. I don't need to go dig into the GHC docs for a language pragma to understand what's happening at the term level. I even found do notation to be a barrier to learning until I understood the rules for desugaring the syntax. I think the benefits outweigh that cost for that case, but unless your idea is as powerful as do notation, I'm probably going to vote against it.
Do you know if there's an easy way to omit all the compiled object code using stack?
fwiw `both` is available in the `Prelude` as `either`: λ&gt; :i either either :: (a -&gt; c) -&gt; (b -&gt; c) -&gt; Either a b -&gt; c -- Defined in ‘Data.Either’
All my code works in GHC8, with existing language pragmas `LambdaCase` and `TypeOperators`. This is purely library level stuff
What would this do? It looks like a and b are undefined on the last line.
Huh, that's surprising. You can terminate a sequence of `--` with any *other* symbol, but extra `-` are interpreted as part of a comment.
Cabal (which is ultimately what stack uses) already compiles your individual modules to object code. You can find them at `&lt;your-project-root&gt;/.stack-work/dist/&lt;target-platform&gt;/Cabal-&lt;cabal-version&gt;/build/`
Yeah, it's a weird quirk. Just thought I'd mention it, but for some reason it's worthy of downvotes? This website makes no sense /shrug
Years ago when I was doing Windows dev with Haskell and stack, it was possible to tell stack that you wanted a version of GHC with integer-simple instead of integer-gmp ([https://docs.haskellstack.org/en/stable/yaml\_configuration/#ghc-variant](https://docs.haskellstack.org/en/stable/yaml_configuration/#ghc-variant)). /u/deech probably knows a lot about this since he's done tons of great work getting FLTK working on Windows with his FLTKHS bindings.
Er, yeah, it's definitely ill-typed. I'm not sure what a negative pattern match with variables in supposed to do anyway -- not un-bind them?
I'm interested in the idea of tests which include some kind of verification that if the code was wrong, the test would fail. For example, the project I'm working on has a lot of tests which are like, "do A with user 1, then do B with user 1, check the output is X. do A with user 1, then do B with user 2, check the output is not-X". And those are pretty decent tests of our permission code. But sometimes there are multiple reasons why B might give not-X (e.g. if B requires permissions on two different entities), and we want to test that all of them are in place. But I can edit the code and remove either one of those reasons, and the test will still pass. Or for a simpler example: "this function should always return a sorted list". If your quickcheck tests don't generate very good random input, maybe the function only ever returns `[]`, and you're not really testing the thing. If you think of that kind of thing, it's fairly easy to avoid when writing the tests. But then maybe you change your `instance Arbitrary` later on and your tests silently stop working. It's a little more complicated, but possible, to write a separate test just to make sure your `instance Arbitrary` is acceptable. That's... probably okay? But I feel like somehow putting it in the test itself would be even better. (Perhaps something like, the test is a tuple (setup, target, verifier, adversary). For 100 random instances, we check that `verifier $ target $ setup instance` always succeeds; and that `verifier $ adversary $ target $ setup instance` sometimes fails. Then if `adversary` is `reverse`, we ensure there was some non-empty output.) Can anyone point me to things that have been previously written about this idea?
There are alternate builds of GHC using \`integer-simple\` instead of \`integer-gmp\`. That solves the GPL issue. (But it if you need large integer calculations there could be performance issues.) A common approach to GUI apps nowadays - in general, not just in Haskell - is to use a browser as your rendering component. As an example, the popular Slack desktop app (written in PHP). There are many others. Haskell has very strong support for this approach, with several excellent and power frameworks. There are several other native GUI libraries besides gtk2hs, but I'll let others elaborate.
I **can not** see option: **-b** on my MacOS man top: SYNOPSIS top \[-a | -d | -e | -c mode\] \[-F | -f\] \[-h\] \[-i interval\] \[-l samples\] \[-ncols columns\] \[-o key | -O skey\] \[-R | -r\] \[-S\] \[-s delay-secs\] \[-n nprocs\] \[-stats keys\] \[-pid processid\] \[-user username\] \[-U username\] \[-u\] &amp;#x200B; try: top -n100 but top still does't terminated
A friend of mine worked on a similar project: [htorrent](https://github.com/nicksanford/htorrent).
Yeah it's cool learning about other people's attempts at the same thing, I'm definitely no pioneer here. Without trying to one-up nick's work I'd note that this project supports a good deal of the missing features he lists, including some important ones like choosing pieces by rarity and which peers to unchoke. I don't mean any condescension or disrespect, just trying to accurately outline the differences and completion statuses between projects. Hats off to your friend for getting a working downloader much faster than I managed to do lol
Having unlifted tuples and \`seq\` requires parallel evaluation. If you \`seq\` a pair you need to \`seq\` both parts of the tuple in parallel and terminate if/when one of them terminates.
What do you want that pattern Thing :: String -&gt; String -&gt; [String] pattern Thing a b = ["Thing", a, b] doesn't give you?
Yeah, `seq` is probably bad :)
Hm, my example was misleading. The idea was just to be able to provide non exhaustive patterns so that instead of a `case` statement returning `Maybe a` it could return `a` directly. Here's a better example: ```haskell instance Pattern (Maybe a) where match = Just miss = Nothing getThing :: [String] -&gt; Maybe (String, String) getThing = of ["Thing", a, b] -&gt; (a, b) ```
That nice and sobering to hear. Nice that i am not alone, sovering since i suck at it😅
It doesn't allow you to handle match failure.
[http://hackage.haskell.org/package/fin-0.0.2/docs/Data-Fin.html](http://hackage.haskell.org/package/fin-0.0.2/docs/Data-Fin.html)
I totally didn't see the whole second half of your post somehow. I hate that it's infix, but I think that's a personal reaction, not a reasoned stance.
Goddamnit, my hoogle-fu is weak. This has plagued me for years. Thanks.
 getThing ["Thing", a, b] = Just (a, b) getThing _ = Nothing I'm really not sure that a partial case construct specifically tied to `Maybe` is valuable enough to get syntax. Not only is it generalizable to more than maybe (see below), but it also feels (to me) like mixing partially and totality in an uncomfortable way. getThing :: MonadFail m =&gt; [String] -&gt; m (String, String) getThing x = do ["Thing", a, b] &lt;- pure x pure (a, b)
Is there a performance difference between foldr :: forall f a b. Foldable f =&gt; (a -&gt; b -&gt; b) -&gt; (b -&gt; f a -&gt; b) foldr cons nil as = appEndo (foldMap (Endo #. cons) as) nil foldr :: forall f a b. Foldable f =&gt; (a -&gt; b -&gt; b) -&gt; (b -&gt; f a -&gt; b) foldr cons nil as = coerce (foldMap @f @(Endo b) @a) cons as nil
so you just use em-dash instead, `(—)`!
&gt; things are usually linked statically No, most distros (and especially the most popular ones in both the desktop and server space) categorically, overwhelmingly ship dynamic libraries and dynamically linked application for everything they provide to users, for a number of reasons, the most important being that they allow 'in situ' updates in case of things like a security flaw in a commonly used library. (This is possible because they abide by an ABI that is guaranteed not to break.) This is in fact a trade off of the Nix approach: I love it, but it's undeniably a flaw that a Debian user can get a critical security update for their whole system in 5 seconds while a Nix user may be stuck for 12 hours on the cache or 5 hours compiling things themselves. Have fun recompiling mesa and your entire workstation desktop environment. Application developers will often ship static binaries that can be used "everywhere" for simplicity and so users can easily get up to date binaries -- but the overwhelming trend for distributions is dynamic linking for everything possible. Finally Windows is "complicated" but only because we ship a static copy of libgmp on Windows with our binary distributions. You "only" need to instead ship a dynamic DLL of libgmp and make Haskell programs depend on that, and ship it to users so they can replace it. gtk2hs is a more unfortunate case. In such an instance, you really do want dynamic Haskell libraries. Or you're stuck with giving people object files to relink with. Neither is very good, IMO.
Nice to have. I wonder how it deals with greatest fixed points? aleph_0 :: Nat aleph_0 = S aleph_0 natToFin :: Nat -&gt; Fin aleph_0 natToFin Z = FZ natToFin (S n) = FS (natToFin n) finToNat :: Fin aleph_0 -&gt; Nat finToNat FZ = Z finToNat (FS fn) = S (finToNat fn)
Nope - at -O1 they both give identical code.
great news thanks for checking Neil, it could be written [`foldr = flip . foldMap @_ @(via Endo)`](https://github.com/ghc-proposals/ghc-proposals/pull/218) then
To be clear: Simon does, in fact, use Windows for quite a lot of his GHC and Haskell work. But he is not a "windows systems hacker" -- a 'prerequisite' for many of the stupidly complex technical issues that arise from such features -- anymore than the average Linux developer is a "linux systems hacker".
You can convince GHC to accept aleph0 at the type level by putting it in a type family (and turning on `UndecidableInstances`)... type family Aleph0 where Aleph0 = S Aleph0 ...but if you try to use it anywhere the typechecker loops. FZ :: Fin Aleph0 {- • Reduction stack overflow; size = 201 When simplifying the following type: A Use -freduction-depth=0 to disable this check (any upper bound you could choose might fail unpredictably with minor updates to GHC, so disabling the check is recommended if you're sure that type checking should terminate) • In the expression: FZ :: Fin A In an equation for ‘it’: it = FZ :: Fin A -}
I'm reading this as: - a small yesod app will have less features than a large one (obviously) - adding the large-app scaffolding to a small yesod app is a bit of a hassle ? - the large-app scaffolding is massive (is it really ?)
Can we lift it without an separate type family? I'd like to (ab)use DataKinds to do something like: lift :: Nat -&gt; 'Nat lift Z = 'Z lift (S n) = 'S (lift n) ... even if I have to CPS it or something. It seems like I should be able to (re)use existing infrastructure for lifting a statically known `Nat` value to the type level.
That's what [`singletons` library](http://hackage.haskell.org/package/singletons) can do with *Template Haskell* &gt; The library was originally presented in Dependently Typed Programming with Singletons, published at the Haskell Symposium, 2012. (https://cs.brynmawr.edu/~rae/papers/2012/singletons/paper.pdf) **Version 1.0 and onwards works a lot harder to promote functions**. See the paper published at Haskell Symposium, 2014: https://cs.brynmawr.edu/~rae/papers/2014/promotion/promotion.pdf.
I was hoping something lighter-weight (and definitely WITHOUT Template Haskell), like [`reify`](http://hackage.haskell.org/package/fin-0.0.2/docs/Data-Type-Nat.html#v:reify). I think SNat and SNatI with be available at `aleph_0`.
&gt; Unless you're talking about Haskell code Hopefully obviously, I'm not about talking about xmonad linking libxcb dynamically, but xmonad linking dynamically to utf8-string, containers, etc: Its haskell dependencies. As far as haskell linkage is concerned, the xmonad that e.g. ubuntu ships is statically linked.
I think it works with mingw, haven't tried it, but my point was that Nix is almost always recommended for Haskell development and yet it doesn't support the [most popular primary OS by far](https://insights.stackoverflow.com/survey/2019#technology-_-developers-primary-operating-systems).
 natToFin :: Nat -&gt; (forall n. Fin n -&gt; r) -&gt; r natToFin Data.Nat.Z cont = cont (Data.Fin.S Data.Fin.Z) natToFin (Data.Nat.S n) cont = natToFin n (cont . Data.Fin.S) Can be given `aleph_0` (as the value) and it works as well as one might expect. It can also be given `Data.Fin.toNat` as a continuation and, again, works as well as one might expect. (Although, it would be nice for it to be lazier. :/)
Damn I swear there was a Haskell library that would validate your tests by iirc subtly tweaking the code under test and ensuring the tests failed. Google is failing me. Maybe this was a generic or llvm bitcode tool... It's a great idea in any case!
1. I definitely prefer `:` for types and `::` for lists, but I don't see this happening anytime soon due to backwards compatibility. 2. Honestly I wish GHC/Haskell left "standard" records alone and stopped trying too hard to improve them, and then focused on switching over to extensible Rows/Records/Variants/Sums/Products (Sums and Products are positional whereas Records and Variants are based on Row).Haskell with every extension in existence is still worse for interacting with Rows/Records (IMO) than [Expresso](https://github.com/willtim/Expresso) even though it's pretty minimal and still has it's own room for improvement (look at current github issues for my personal desires). 3. Sure I suppose, don't think I would use it personally though. 4. Personally I would like the idea of records and modules to be unified as much as feasible (some fundamental differences like generativity that will be hard to overcome), so syntax like `{foo, bar} = import Foo.Bar` or `FB = import Foo.Bar` or `{foo = fbFoo, bar = fbBar} = import Foo.Bar` and something like `{..}` for open imports (extensible records + `{..}` sounds complex so maybe just for modules).
I'd personally like: {foo, bar} = import Foo.Bar FB = import Foo.Bar {foo = fbFoo, bar = fbBar} = import Foo.Bar Ala [Expresso](https://github.com/willtim/Expresso).
The one thing that irks me, but that I don't have a good solution to, is that the symbol at the beginning of the line is associated with the *previous* line rather than the current line.
I'm not sure that's the best argument, as it basically means once a language with X semantics claims useful piece of syntax Y, then unless you mirror X's semantics you can't use Y. If I could go back I would definitely try and convince Haskell to go with `:` for types.
I'm personally not sure about GADTs becoming the standard, they are pretty fantastic and powerful, but I would like the "standard" way of doing sums and products to be via extensible Rows/Arrays.
I feel like the right approach to products is to have them be backed by extensible rows, I particularly quite like [Expresso](https://github.com/willtim/Expresso)'s approach. I would also like extensible products backed by arrays for purely positional products. It would have the same benefits you mentioned and should be pretty nice to work with.
As I mention [here](https://github.com/willtim/Expresso/issues/14) the way I would personally like to approach this is via extensible records/variants and a function like: case : Record (map (-&gt; c) as) -&gt; (Variant bs -&gt; c) -&gt; Variant (as + bs) -&gt; c Your specific example is sugar over a couple layers of pattern matching but for a more simple example: data FooBar = Foo Int | Bar Bool your approach: getThing : FooBar -&gt; Maybe Int getThing = ~case (Foo a) -&gt; a becomes: getThing : FooBar -&gt; Maybe Int getThing = case { Foo a = Just a } (\_ -&gt; Nothing) With some nice benefits such as if you omit the second argument of `getThing` you can actually compose it with a second "partial pattern" and if you cover all your cases between the two then you don't need to return a `Maybe`, you can essentially just put `absurd :: Variant Nil -&gt; a` in the hole at the end and the compiler will guarantee it is safe. Also since it's just a regular old function you can do various other first class manipulation of it that you couldn't otherwise do.
&gt; specifically tied to Maybe Maybe is an instance of Pattern in my example. Is the MonadFail example supposed to trigger `fail`? I can't get it to work.
[removed]
Yep.
I’m guessing the ones that aren’t are implies and variants of it.
An alternative to /u/phadej's library `fin` is the [`finite-typelits`](http://hackage.haskell.org/package/finite-typelits). While `fin` uses Peano numerals, `finite-typelits` uses an opaque newtype together with GHC's builtin type literals. I've been using `finite-typelits` for quite a while now and it works excellently.
There is closed http://hackage.haskell.org/package/closed
I want to work through project euler for fun and haskell practice. Since I haven't done a "real" project before in Haskell I'd like to bundle my solutions together into a multi-file app that like, runs and times all the problem solutions or something. How should I go about this? Make a `EulerProblem` typeclass and implement it for each problem?
Is there a type like this in any standard library? newtype Foo x = Foo x instance Semigroup (Foo x) where x &lt;&gt; _ = x
While it seems useful at first - I looked into pull request for iteratee library (https://github.com/tsurucapital/iteratee/pull/1) some commits make sense, some commit don't make any sense at all (https://github.com/tsurucapital/iteratee/pull/1/commits/e4856eaefe229b9bf6142f328f7d1cc987446ec8). If remaining 97 requests are of similar quality - you just wasted a bunch of time for a bunch of people.
Currently traveling, so haven't done too much work on this front. The changes are like an inch away from getting merged into GHC afaik, as soon as I can get them to stop breaking GHC after the latest review changes :)
Supposedly in 2020, but I doubt that'll happen, given it [seems to have stalled](https://github.com/haskell/rfcs/issues/15). Perhaps it's out of date, but the [project board](https://github.com/haskell/rfcs/projects/1) paints a bleak picture.
&gt;Is the MonadFail example supposed to trigger fail? Yes, that's the desugaring for pattern-match failures on the left of (`&lt;-`) in do blocks. Working example: GHCi, version 8.4.4: http://www.haskell.org/ghc/ :? for help &gt; do { Left x &lt;- Just $ Right "123"; pure x } Nothing
Yupit’s called First: https://hackage.haskell.org/package/base-4.12.0.0/docs/Data-Semigroup.html#t:First
heres what i have: fixpointL :: (Int -&gt; Int) -&gt; Int -&gt; [Int] fixpointL f x = if (f x == x) then [x] else [f x]++(fixpointL f (f x)) when used like this fixpointL collatz 3 it outputs this [10,5,16,8,4,2,1, 1] but its supposed to be [3,10,5,16,8,4,2,1] what am i doing wrong
Oh, thanks for that. I hadn't quite understood the MonadFail connection.
Update: Turns out that not all versions build on darwin, see https://github.com/Infinisil/all-hies/pull/4 for further updates
There's this: https://old.reddit.com/r/haskell/comments/7mrqkk/chrisdonechaoticghc_chaotic_version_of_ghc/ ...but it appears to be gone. Maybe /u/chrisdoner could say why.
Very cool project. Nice work!
For syntax highlighting and indentation while typing, I like `neovimhaskell/haskell-vim` with the "classic" colours option. It really fixes the default Christmas tree effect you get and makes the colours match other languages. I use Solarized Dark and it looks much more correct. For automatic indentation, I use `Chiel92/vim-autoformat` with hindent.
I use `finite-typelits` a lot too. For more general types of "bounded" numbers (upper or lower), there's also [`refined`](https://hackage.haskell.org/package/refined).
I saved this comment, but I am a little sad to see that nobody actually commented on this. I mainly followed [this article](https://mendo.zone/fun/neovim-setup-haskell/) to produce my setup: * NERDTree (file browser) * haskell-vim (syntax highlighting) * Intero (IDE-dev server) * Neomake (for running extra tools like hlint) Things I still run into: * Suggestions * Autocomplete * Text box from Intero is sadly too small to read the full error message
In the `else` branch, try replacing the `[f x]` with `[x]`. Other than that, it looks correct. Also, instead of `[x] ++ ...`, you can use `x : ...` - makes it a little shorter.
If it's easy to reproduce it never hurts to open a [ticket](https://gitlab.haskell.org/ghc/ghc/issues/) &gt; Is Haskell just not viable commercially for non-linux operating systems? Windows seems like a major second class citizen when it comes to Haskell development. I think it's **viable** but still a second class citizen. Issues on windows do pop up but tend to be of a nature you can work around. But something like F# will definitely have better Windows support.
Phys is definitely the main driver for windows. But there are a few other people who occasionally fix things.
Here's what I use : * enomsg/vim-haskellConcealPlus * alx741/vim-hindent * nbouscal/vim-stylish-haskell
Now that we have `MonadFail` is there any reason not to have a proper `MonadFail` instance for `Either` in base like the one defined in `relude`? instance IsString str =&gt; MonadFail (Either str) where fail = Left . fromString ping u/vrom911 u/chshersh
It was proposed to add this instance to the `base` library before, however, library committee rejected the proposal: * https://gitlab.haskell.org/ghc/ghc/issues/12160#note_162703
Hmm.. at https://mail.haskell.org/pipermail/libraries/2018-October/028996.html it says there's only weak opposition to the `IsString` version. Strong opposition is against instance MonadFail (Either [Char]) instance e ~ String =&gt; MonadFail (Either e) In https://mail.haskell.org/pipermail/libraries/2018-October/028992.html the suggestion is voiced to introduce some custom `Error` class in place of the `IsString` class: &gt; If we decided we really wanted something, then building a class that was just for this purpose might work, sort of an updated version of the old 'Error' class from transformers, but now limited to just the failure string so it has no extra baggage. Maybe that's a way forward then?
here's a strawman proposal class Error a where fromFail :: String -&gt; a class Error e =&gt; MonadFail (Either e) where fail = Left . fromFail
I'd like to add that I think the \`Monad\` constraint and name \`MonadFail\` was a mistake. There's no reason for this type-class to require \`Monad\` as a constraint. &amp;#x200B; The only listed \`MonadFail\` law is too weak: fail s &gt;&gt;= f = fail s &amp;#x200B; fail s &lt;\*&gt; f = fail s
Nice observation, but isn't failing a bit of smell to be avoided. It doesn't look like the kind of thing that we'd particularly like to encourage in Haskell.
There is now also the `integer-openssl` projects to provide a non-copyleft, fast implementation. It was started last MuniHac. There are a few tasks remaining to complete it: https://github.com/ch1bo/integer-openssl/issues/3 /u/foucaltfanfic, if you intend to sell proprietary software on Windows, and do not want to solve the technical bits to allow end users to swap out the LGPL libgmp object file, you may want to invest in this project instead to make the process easier. You could work on these items, or come to next MuniHac (where I hope this project will be worked on again), or look into the offer I posted there to have a consultant complete it for you (I think the project is really cool and would like to see it completed).
“avoid (success at all costs)” =&gt; “accept (failure at some costs)”
Sounds like [MuCheck](https://hackage.haskell.org/package/MuCheck).
I had the same impression. IIRC [pipes-safe](https://github.com/Gabriel439/Haskell-Pipes-Safe-Library) has always been kind of a problematic module in the design space of pipes. Not sure if it means that resource management/termination is not fully solved in this space but it looks like a difficult part of it. The [operational](http://hackage.haskell.org/package/operational) package works kind of alright but as soon as you throw exceptions into the mix it seems to fall short. Anyhow I would love reading more about this aspect because I have the feeling it is not as simple as it sounds.
I misread the title and thought, "what's happening in four weeks?"
Here's what the link points to: instance IsString str =&gt; MonadFail (Either str) where fail = Left . fromString This isn't just for those who are too lazy to click the link; on mobile at least, my browser displayed the whole file and while I could see from the URL that it was line 70 which was supposed to be highlighted, who has time to count that high?
I would be glad to have an extension for reversing the meaning of colon. I'd probably use it in my application code but not in my library code for a while.
[AllZip instances](https://hackage.haskell.org/package/generics-sop-0.4.0.1/docs/Generics-SOP.html#t:AllZip2) are quite long so they overflow and cause the horizontal scrollbar.
i use my fork of `neovimhaskell/neovim-haskell-syntax` and `ghcid`. i've fallen down the rabbit hole of trying to find / make good tooling before but it's not worth it imo. also, i have a cool toy neovim plugin that uses ghc to highlight haskell syntax https://github.com/goolord/neovim-haskell-syntax i couldn't really figure out how to use the msgpack rpc to do syntax highlighting in real-time, so it's useless beyond the novelty of it.
Thanks, but I'm interested in Nats
Thanks! For my taste, a bit too much type-juggling for my simple use case
Oh good! Thanks! Reading it, I'm surprised u didn't come up with that definition. It's so simple
I want the colors [@HandyHaskell](https://twitter.com/HandyHaskell) uses
You should just do this tbh https://exercism.io/tracks/haskell
FWIW I'd rather not use Left as an exception; it's just a constructor to pattern match against later. I personally prefer using `throwM` (from `exceptions.Control.Monad.Catch`) and write an application-specific exception sum type.
There isn't really. Make a module like Data.Either.Fail and publish it on hackage, so we all an benefit
Yeah, ISTR a HAskell tool like that. It strongly reminded me of Jester (for Java) / Pester (for Python) -- they would go through the bytecode (IIRC) and swap out conditionals for True/False constants, and re-run the tests. If the test still passed, either they weren't sensitive to that conditional (and weren't testing it), or as the authors of Jester found to their surprise one day, that the conditional check was unnecessary for correctness.
&gt; With an `Applicative` constraint, the following law would be more appropriate: The problem with that is that `fail` is also meant to abort / avoid the later / to the right effects as well. The `Applicative` operator `&lt;*&gt;` can't do that and follow the Applicative laws. IMO, `fail` and `MonadFail` and in exactly the right spot.
Lol. Luddite.
It's not so much stalled as [blocked](https://mail.haskell.org/pipermail/haskell-prime/2018-December/thread.html) but there is still [some hope](https://mail.haskell.org/pipermail/haskell-prime/2019-April/004442.html)
In `rust`, there is a `Result t e` type that is functionally equivalent to `Either` but semantically used for wrapping results. It's more obvious how this is a monad (it's the "success" parameter) and then you code with no exceptions . Works really well in practice. How would something like this compare to MonadFail?
In addition to `Fin`, another type that I occasionally find useful is `&lt;`: ```haskell data (m :: Nat) &lt; (n :: Nat) where LZ :: 'Z &lt; 'S n LS :: (m &lt; n) -&gt; ('S m &lt; 'S n) ```
Not if the `Eval` class from Haskell 1.3 were re-introduced, but that would require solving some thorny problems. https://github.com/ghc-proposals/ghc-proposals/pull/27 https://github.com/blamario/ghc-proposals/blob/eval-class/proposals/0000-eval-class.rst
When I try to compile my Haskell code the compiler tells me it can't find module "Tokens" and module "Grammar". I have both of these modules in the same directory as the haskell file I am trying to run. my Main.hs: module Main where import Tokens import Grammar import System.IO import System.Environment import Control.Monad.State import Data.Map (Map) import qualified Data.Map as Map Tokens.x: { module Tokens where } Grammar.y: { module Grammar where import Tokens } I haven't included the code in the files above, because it's just way too much and I don't think it would be of any use. I don't have any experience with haskell and other functional languages any help would be greatly appreciated. Thank you!
why not reuse `IsString` (`Error` doesn't seem to add anything, semantically)?
thanks!
* `Tokens.x` is not a Haskell source file, which should end in `.hs`. * `Grammar.y` is not a Haskell source file either. Perhaps you forgot to run `happy Grammer.y` and `alex Tokens.x` before running `ghci Main.hs`?
Also, looks like this was generated with an unreleased version of Haddock. In the version that will be released, there is a menu option to collapse instance lists, hiding long instances and removing the horizontal scroll.
Yes, that was it! Thank you very much!
I was onced an avowed vim user but spacemacs in evil mode has won me over. It seems to have all of the niceties of editing in vim with the wonderful ecosystem/configuration of emacs. I've done almost no configuration of it and I'm happy. Worth a shot if you can't find something vim-only that quite meets your wants.
I think so, thanks!
I think the most brilliant thing I've read on monads is that monads are contexts to describe non deterministic computation. Look something like pure (+) &lt;*&gt; Just 6 &lt;*&gt; Nothing ... It is very concrete but if you think in a function &gt; psum x y = pure (+) &lt;*&gt; x &lt;*&gt; y :: Maybe Integer &gt; psum (Just 6) (Just 10) Just 10 &gt; psum (Just 6) (Nothing) Nothing It is pretty clear you are describing computation of multiple possibilities at once. The value of this is clear and trivial, and the benefits go beyond a simple sum. The problem with the mathematical definition is that even if it is exact it is also useless to understand the purpose of what is describing.
Hi all, I've posted this job add a few times before, but we're hiring again! Here are some updates since we were last hiring: * We've launched to the public! You can open a business bank account at mercury.co * There's a little press about us here https://news.ycombinator.com/item?id=19694077 * We're growing fast now! In the two weeks since we've launched, we've had hundreds of new accounts opened and millions of dollars in deposits. * We're now up to 31,605 lines of Haskell code! Our backend is 100% Haskell.
The substitute law I posited clearly shows aborting / avoiding the later / to the right effects: fail s &lt;*&gt; f = fail s
Come on man, we just finished downvoting this into oblivion the other day.
This article reads like three articles by different authors after one another, but it contains a lot of useful information. Quick question: Is anyone using the special arrow 'do-like' notation in practice?
Looks like a great opportunity for first Haskell job!, sadly no remote position. &amp;#x200B; Mercury looks nice :)
A good first understanding, I would say. Note also that we do can use `(.)` if we first import [`Control.Category`](https://www.stackage.org/haddock/lts-13.19/base-4.12.0.0/Control-Category.html) which offers the class class Category cat where id :: cat a a (.) :: cat b c -&gt; cat a b -&gt; cat a c and for every Monad `m` there is an instance (where `id = return` and `(.) = &lt;=&lt;` with the [`&lt;=&lt;`](https://www.stackage.org/haddock/lts-13.19/base-4.12.0.0/Control-Monad.html#v:-60--61--60-) from `Control.Monad`) of [`Kleisli m`](https://www.stackage.org/haddock/lts-13.19/base-4.12.0.0/Control-Arrow.html#t:Kleisli)! Of course, we also have an instance for the good old function arrow `Category (-&gt;)` recovering the usual function composition you are used to.
&gt; Looks like a great opportunity for first Haskell job!, sadly no remote position. Hey Arguser, we are hiring remote (just updated the post to reflect this), but currently only for US-based individuals. I expect to continue to hire engineers in the fall and hopefully we can do international employees then.
That's great to hear, thanks!
I'm not familiar with `Control.Category.` It seems interesting though, i'll check it out. I was referring to: `(.) :: (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c`
A reason is that the original purpose of `MonadFail` — handling failing pattern matches in `do`-notation — only makes sense in `Monad`. (Yes, `ApplicativeDo` exists, but fallibly pattern-matching, like any branching, on the result of an action requires `Monad`.)
You didn't say what your proposed instance for `Validation` should do, but the natural way to do it would violate this law — the point of `Validation` is that errors are aggregated, rather than everything to the right of an error being ignored.
&gt; The `Applicative` operator `&lt;*&gt;` can't do that and follow the Applicative laws. ? Any monad that obeys `fail s &gt;&gt;= f = fail s` will obey `fail s &lt;*&gt; f = fail s` because of `(&lt;*&gt;) = ap`.
Don't-- it's inefficient
And, `Applicative`s aren't allowed to do that. (eff1; pure f) &lt;*&gt; (eff2; pure x) is required to be (eff1; eff2; pure $ f x) or (eff2; eff1; pure $ f x).
&gt;The way I see it is that Monads are an interface for custom function composition. [You could have invented Monads!](http://blog.sigfpe.com/2006/08/you-could-have-invented-monads-and.html)
Which framework or library do you use for Haskell?
I'm down for either one, but I prefer just reusing `IsString`, since neither has real laws.
&gt;Our backend is 100% Haskell. That immediately makes me wonder: why not frontend as well? :-)
Yes, custom function composition (for functions that work between your values) is a good way of understanding them. As you saw, things become fairly clear when one writes \`a \~&gt; b = a -&gt; m b\`, and then one just has \`(&lt;=&lt;) :: (a \~&gt; b) -&gt; (b \~&gt; c) -&gt; (a \~&gt; c)\`: You've just redefined what it means to compose a "function" in your category (i.e. between values of your newly defined type (\`m a\`)). &amp;#x200B; The only reason \`&gt;&gt;=\` exists is because it's easier for programmers to sometimes think of "feed a (special) input into a (special) function", where the input itself can be of this newly defined type, than it is to think of "raise the function, run, and combine the output's effects". Thus \`x &gt;&gt;= f\` feeds \`x\` into \`fmap f\`, and then gets rid of \`m (m a)\` via \`join\`.
Our backend uses Yesod to serve JSON, and we use Persistent and Esqueleto for database access. As with any large Haskell project, we use quite a large number of libraries, like amazonka, cryptonite, etc. We do tend to avoid trickier stuff like lens, though.
Never heard of "Generalist Engineer" before. What does that entail?
I answered a similar question about using PureScript awhile back, these were my thoughts: https://www.reddit.com/r/NixOS/comments/9teh5j/mercury_is_hiring_an_engineer_san_francisco/e9iyze1/?context=3
Doesn't HandyHaskell just use Carbon? link: [https://carbon.now.sh](https://carbon.now.sh/)
Thanks!
Hey Chris, it's a more common role in a startup environment where people end up wearing more hats. For us it's a reflection that our ideal candidate is willing to work across the stack (so for example, if they're making an admin page they don't need someone else to do the frontend), but also that we're willing to hire people who wouldn't call themselves a "Haskell engineer" or a "Typescript engineer"—if someone is just a good engineer in general we'd want to work with them. In practice, I'd say our team has: 1 engineer who does Haskell/Nix stuff 1 engineer who does just Haskell 3 engineers who do frontend + Haskell Our CEO does a little Haskell but mostly frontend 1 frontend engineer
Interesting, thanks for the explanation
Its used for yampa, an frp library.
I like programming but I don't know a ton about the whole process behind making a software. What's the advantage to having one person working on a bunch of different parts of the design like that? It seems like specialization is the opposite of what you're doing. Not trying to sound rude, just curious.
IMO `String` (or `Text`) is a bad choice as an error type. A better choice is sum type. Using a sum type allows pattern matching further up the stack instead of having to parse an error string (which may silently change at some later date).
&gt; This article reads like three articles by different authors after one another That's because it pretty much was :) I rewrote the first half of it some time ago, but only did comparatively minor adjustments to the discussion of the parser example. [The companion tutorial chapter](https://en.wikibooks.org/wiki/Haskell/Arrow_tutorial) is originally from a third author still (Stephen Blackheath, known for the Sodium FRP library).
In the case of a startup it is usually more beneficial to hire a single generalist for $X rather than several specialists for $YxN. There is only so much money to go around for salaries, and someone who can do all the things (at least in the beginning) tends to be more valuable than someone who can only do one thing. For example, someone who can write a single vertical feature with no outside help: Writes a frontend page, wires up the JSON and routes, writes the backend API and business logic, writes the supporting database schema, and maybe even blurs the line into DevOps - pushes the code through CI/CD, builds and deploys server infrastructure automation, hooks into a log server to debug the new feature, adds new monitoring, etc.
There's definitely specialization, but there are lots of practical concerns like: - If one person is on vacation, and the part of the code that they wrote causes the site to go down, can anyone solve it? More grimly, this is known as the "bus factor"—how many engineers can get hit by a bus and your engineering team can still functions. - It makes scheduling things more difficult. If you have 5 engineers, 4 are busy, there's a new bug that needs fixing, it's no good if the last engineer can't work on the bug. - There's specializing in a particular language, but also vertical specialization. Sometimes doing the front and backend together for a project is good to do. Specialization has benefits too, like being deeply aware of ongoing developments in a library for example. In practice, we have lots of specialization, but at a startup there's also a need for generalization too.
Oddly enough, I've found that it requires very little type-juggling. At the very least, it certainly won't require *more* type-juggling than any of the other suggestions here.
Is this a good way of showing the difference between &gt;&gt;= and &lt;=&lt; (I'm playing a bit fast and loose with notation)? x &gt;&gt;= f = join . fmap f x = join $ fmap (Int -&gt; Maybe String) (Maybe Int) = join $ Maybe (Maybe String) = Maybe String g &lt;=&lt; f = join . fmap g . f = join . fmap (Int -&gt; Maybe String) . (Int -&gt; Maybe Int) = join $ fmap (Int -&gt; Maybe String) (Maybe Int) = join $ Maybe (Maybe String) = Maybe String
 λ. data Foo = Foo { bar :: Int, baz :: Int } deriving Show λ. foo = Foo 1 2 λ. foo Foo {bar = 1, baz = 2} λ. foo{bar=3} Foo {bar = 3, baz = 2} λ. foo{bar=3}{baz=5} Foo {bar = 3, baz = 5} λ. case foo{bar=3}{baz=5} of Foo 3 5 -&gt; "yup" "yup" -- Proposed: case foo of bar = 3 of baz = 5 of Foo 3 5 -&gt; "please no"
[removed]
&gt; It feels harder to tell what's a constraint and what's an arg That's actually the point. Under the hood, constrants _are_ just args with a compiler-supplied value (instance libraries).
Sort of, yes. There's a step in the second one, when you go from `.` to `$`, where you make an `Int -&gt; Maybe Int` become a `Maybe Int`. That bit is not really happening in `g &lt;=&lt; f` because you're not feeding it any input, it would happen in `(g &lt;=&lt; f) x` when you feed it `x`. If you just have `g &lt;=&lt; f` by itself, then what you end up with is `Int -&gt; Maybe String`, because you haven't given it that `x` yes. You can actually check this on GHCi: ``` $ ghci Prelude&gt; let g = undefined :: Int -&gt; Maybe String Prelude&gt; let f = undefined :: Int -&gt; Maybe Int Prelude&gt; :m +Control.Monad Prelude Control.Monad&gt; :t (&lt;=&lt;) (&lt;=&lt;) :: Monad m =&gt; (b -&gt; m c) -&gt; (a -&gt; m b) -&gt; a -&gt; m c Prelude Control.Monad&gt; :t g &lt;=&lt; f g &lt;=&lt; f :: Int -&gt; Maybe String ``` Which is what you said :) You can also check algebraically that `(&gt;&gt;=) = (join .) . flip ((&lt;=&lt; return) . fmap)`, that is, that `x &gt;&gt;= f` is just `join $ (fmap f &lt;=&lt; return) x`, and that `(&lt;=&lt;) = flip (flip . ((&gt;&gt;=) .))`, that is, that `(g &lt;=&lt; f) x = (f x) &gt;&gt;= g`.
Yeah I meant to put `(g &lt;=&lt; f) x` , my bad.
Update: It provides caches for Darwin too now :)
The former doesn't follow from the latter. (do { Nothing; pure sum }) &lt;*&gt; (do { Just (); pure [1..5] }) = do { Nothing; Just (); pure $ sum [1..5] } as you say, but... do { Nothing; Just (); pure $ sum [1..5] } = Nothing anyway.
Regarding naming: you can use imperative in function names to describe the transformations they make on data, since it's not ambiguous whether they update (compare, for example, Python's `sorted` vs. Haskell's `sort`. This means something like `alphaMaker` might be clearer if written `makeAlpha`.
First off, great first effort. It's clear that you put in work trying to get this cypher to work properly. We have a type system that makes creating types very easy. Why not use these types to make your program more friendly? You could create some type `Vigenere = Encode | Decode` that you could use in `vigenere :: String -&gt; String -&gt; Vigenere -&gt; String`? The curly brackets are unnecessary for Haskell and a little unidiomatic. You may want to familiarise yourself with the indentation rules for haskell. They can be a little confusing, but they will become natural with practice. I see you are familiar with `zip`, did you know there is another function `zipWith :: (a -&gt; b -&gt; c) -&gt; [a] -&gt; [b] -&gt; [c]` which zips and maps at the same time? This could be useful in a couple of places. Since the cipher is only looking at individual letters, you could write the encoding/decoding function with `zipWith` and save yourself the trouble of creating an `alphabet`. Here's how I would go about solving this problem: ```haskell import Data.Char toInt :: Char -&gt; Int toInt c = ord c - 65 fromInt :: Int -&gt; Char fromInt n = chr ((n `mod` 26) + 65) encodeChar :: Char -&gt; Char -&gt; Char encodeChar a b = fromInt $ (toInt a) + (toInt b) encode :: String -&gt; String -&gt; String encode message password = zipWith encodeChar message password ```
It’s called wikibooks, of course it’s probably written by 3 authors.
Instantiate `cat` to `(-&gt;)` and that's exactly what you get, [modulo morals](https://www.cs.ox.ac.uk/jeremy.gibbons/publications/fast+loose.pdf): instance Category (-&gt;) where id x = x (.) f g = \x -&gt; f (g x) Voila, you've defined the category Hask in Haskell.
I think that it’s the same as “full stack programmer”
oh man, if only I lived in the US :(
&gt; spacemacs in evil mode has won me over How long have you been using it? I switched back after giving it nearly an year. If I remember correctly, it is the little incompatibilities (Don't remember the specifics) that made me switch back, and also because of Neovim. Because it was better terminal support that made me switch to Emacs in the first place. Neovim solves that issue completely for me, so much so that I just open neovim even when I just need a bunch of terminals.
I found this title to be very misleading. The post is just the basic explanation of the IO monad as world-&gt; (world,a).
I've never seen the explanation I presented in text before. I came up with this "abstraction" by interpreting the original paper in order to make sense of what it meant when it said "World" contained the whole world. Where have you seen this? I'd read more about it.
https://wiki.haskell.org/IO_inside is quite a nice guide, particularly the [section where it explains `RealWorld`](https://wiki.haskell.org/IO_inside#Welcome_to_the_RealWorld.2C_baby).
That is well-written. The baton analogy is nice. I think it adds to the explanation presented by the original paper.
Thanks for updating the wiki! ❤️
It took me ages to make the connection with lifted composition, only by approaching it from the categorical perspective did the kleisli arrow make sense. Is interesting that that’s the part that made monads click for you. I would recommend reading up on the relationship between monads and comonads now if you haven’t already, comparing (return, join) with (extract, duplicate) and you can see how the lifted composition works in reverse.
There is a somewhat official page for it. [https://wiki.haskell.org/IO\_inside](https://wiki.haskell.org/IO_inside) &amp;#x200B; GHC IO machinery isn't entirely built-in into compiler. Some bits can be read in sources of GHC-prim package (GHC.Types module) They are built using unboxed values (ghc extension), unboxed tuples (ghc extension) and two 'magical' (i.e. built-in into compiler) values (State# and RealWorld), also documented in GHC-prim (in early versions of GHC they were documented in GHC manual). This machinery builds 'face' for impure functions imported via FFI and impure primops, to force compiler to order their invocation. This is possible because unboxed values expose deep internals of GHC runtime. Simplifying, ghc-compiled program has a stack for values and function call, GHC primpops operate with top of said stack and unboxed tuples represented a slice of that stack. Since GHC program contains only one data stack, all operations with it have to be ordered. "Magical" RealWorld and State# values help to organize the process. I suspect, it is possible to do it without 'magical' values, but I'm not certain.
It was indeed produced with an unreleased version of haddock, in order to prevent some problems with the type signatures in the currently released version. However, I'm not seeing anything particularly strange with the output, and trying to re-build docs with the current ghc-8.8 branch of Haddock leads to results that look mostly the same.
Nice! Hoping to make it; it was great meeting you at BobKonf!
Another example of using HKD to assemble a configuration parser can be found in [this gist](https://gist.github.com/danidiaz/40e1b380ce842d7423acc7e38ff341e4) (the `externManagedOpenEnv` value). The code uses different helper libraries.
&gt; Quick question: Is anyone using the special arrow 'do-like' notation in practice? It seems to be the default way to write queries in opaleye (a postgres DSL)
Apologies for the late reply, and for the rather imprecise wording (I'm still getting to grips with a lot of this, and the notation is no exception) but I think (hope) I now understand my error: concat . map would wind up as a function which, after applying the first argument to map (the function to be mapped over the yet-to-be supplied list) would then send the new, partially-applied function (that still needs a map argument) to concat, which would of course fail as concat takes a list-of-lists. On the other hand: (concat .) . map would instead wind up creating a function which, after applying the first argument to map (the function to be mapped over the yet-to-be supplied list) would then **compose** the partially-applied function with concat, which would line up, as that partially-applied function takes a list, maps the already-supplied function over it (which presumably returns a list-of-lists) and then composes **that** function with concat. Again, sorry for the imprecise wording but I'd really appreciate it if you could let me know if you think I'm now understanding what's going on. That's how I interpreted your answer. Not literally, but, after staring at it for a while and thinking that's what I came to understand and hopefully it's what you were trying to convey. Thanks! :)
Your project looks fantastic, sadly as the others already said, you are only taking remote people living in the US :-( , is it because of US immigration policy or is it a timezone concern or something else :-) ?
A few suggestions: * It might be better to split `vigenere` into two separate functions for encoding and decoding. Although they share some logic, using a `Bool` argument is likely to create confusion as you have to remember whether `True` means encode or decode. * Where possible, it is cleaner to use pattern matching instead of guards. The big example in your code is unJust, which would be more idiomatic as: unJust (Just 26) = ' ' unJust j = chr $ maybe 0 (+ 65) j * You are using lists as lookup tables, either looking up by an index, or finding the index that corresponds to a value. There are a few reasons that I'd recommend avoiding this. For one, it's quite inefficient, since you have to traverse the list to do lookups. It can also be a bit error prone (for instance, with `!!` you need to be sure that the index is in bounds). And lastly (but perhaps most importantly), it's often simpler to define the lookup function directly. For instance `tabulaRecta !! x` could simply be replaced with `alphabetMaker x`. * With `passIx`, this can also be avoided. `keyedMessage` can be rewritten slightly as: keyedMessage = zip (map passIx [0..]) (map toUpper message) What `(map passIx [0..])` is doing is just looping the list `numPass`. We can define this more simply as loopedNumPass = numPass ++ loopedNumPass or instead just use `cycle numPass`. * As u/tiny_supper pointed out, it would probably be helpful to define character-wise encode and decode functions. It would probably make sense for these to take the character of the password (rather than the numeric conversion of it). letterToInt :: Char -&gt; Int letterToInt letter | 'a' &lt;= letter &amp;&amp; letter &lt;= 'z' = ord letter - ord 'a' | 'A' &lt;= letter &amp;&amp; letter &lt;= 'Z' = ord letter - ord 'A' | otherwise = 26 intToLetter :: Int -&gt; Char intToChar n | 0 &lt;= n &amp;&amp; n &lt;= 25 = chr $ n + ord 'A' | otherwise = ' ' encodeChar :: Char -&gt; Char -&gt; Char encodeChar pass msg = intToLetter $ letterToInt pass + letterToInt msg `mod` 26 encode :: String -&gt; String -&gt; String encode pass msg = zipWith encodeChar (cycle pass) msg
This nesting of applicatives inside record fields is a good idea, it that it lets you pack all the layers logic related to a component into the corresponding field, without having to disperse it across the code. [sop-core](http://hackage.haskell.org/package/sop-core) has a [type operator version of Compose](http://hackage.haskell.org/package/sop-core-0.4.0.0/docs/Data-SOP.html#t::.:) that looks nice in signatures, for [example](https://gist.github.com/danidiaz/40e1b380ce842d7423acc7e38ff341e4): `Star Parser A.Value :.: Managed :.: Reader r`.
I have mostly made my living for 4 years as a deep learning practitioner so it is easy to understand why I would want to connect libraries like TensorFlow to my favorite languages like Haskell, Common Lisp, and Racket. What I have mostly settled on is sticking with Python and packaging up the models I most need (often not my own, but off the shelf things like Bert) into Python libraries with associated executable shells. Now I just have very thin client interfaces for my favorite non-Python languages. I am documenting this in a book Python Intelligent Systems that should be published in a few months. The advantage of this approach is rapid development in Haskell, Racket, etc. where I don’t have to wait for TensorFlow to spin up for each prediction.
This is good feedback. Thanks for taking the time to parse this and make suggestions!
The third extension is called "Inline function return type annotations", but it seems to allow type annotations for arguments as well? I strongly dislike this kind of syntax, and it is one of the main reason I find Scala function declarations unreadable. I think it's very useful to have a clear visual separation between the type of a function and the formal parameters. Most of the times I only care about the type of a function, and not at all about the parameters names. The visual separation of current Haskell allows me to spot the signature and read it instantly.
My pleasure :) I still have a quite beefy todo list there. I guess the parsers example from this chapter could be a good place as any to start...
I, on the other hand, find it a little disappointing that folks seem to be downvoting it just because of the title.
It would be awesome if you could write a little bit about your dev experience, specifically have you encountered less bugs during QA/Testing vs. say Ruby/Rails? Did you onboard beginner Haskellers? How quick were they able to contribute to the codebase?
Compared to developing at a previous company using Rails, we absolutely have less bugs. There are no bugs from typos or nil exceptions. Haskell also makes it easy/rewards you for doing stuff like using NOT NULL/FK constraints in the database which helps too, relative to the previous company. I’d say we have 1 completed onboarding of a new haskeller, but he’s the best programmer I know so that’s hard to judge. Our CEO has learned some too and can do projects in it with a lot of coaching. This is definitely a major weakness to Haskell. On the other hand, the “if it compiles it works” phenomenon means I can trust a beginner’s code pretty well.
Sorry :(. I hope to hire international in the fall
Hey nhenin, that choice isn’t coming from me directly but I’m told it’s somewhat of a headache operationally. I think as we get a little larger we will hire internationally to have 24 hour coverage; hopefully that’s soon!
Yeah I can imagine, thanks for your reply :-)
Yeah I can imagine, thanks for your reply :-)
The first sentence implies that there exists a map from `(s -&gt; a, t -&gt; b)` to `forall f g. (Functor f, Functor g) =&gt; (g a -&gt; f b) -&gt; (g s -&gt; f t)`. By specializing with identity functors, that implies a map from `(s -&gt; a, t -&gt; b)` to `(a -&gt; b) -&gt; (s -&gt; t)` But what if `t = Void`? This map cannot exist. What am I missing here?
That’s exactly right. :)
GHCi would've answered this question for you in less time than it would've taken to make this post. But yes, the answer to your question is yes, and you probably want to use the `let` keyword .
You need to use guard notation to accomplish this, the correct syntax would be something like this: case x + y + z of var | var &gt; 0 -&gt; print "case 1" var | var &lt; 0 -&gt; print "case 2" _ -&gt; print "case 3"
If what you want is a conditional with more than two cases, you can use the `MultiWayIf` language extension (enable by putting `{-# LANGUAGE MultiWayIf #-}` at the top of your source file, or by writing `-XMultiWayIf` inside ghci), once you did that you can write ``` if x + y + z | var &gt; 0 -&gt; something | var &lt; 0 -&gt; somethingElse | otherwise -&gt; yetAnotherThing ```
&gt; GHCi would've answered this question for you in less time than it would've taken to make this post. GHCi would've told him that his construction is syntactically invalid - which presumably he already knew. It wouldn't have told him what to do instead.
The general solution to this is guards, as another comment already describes. But for your specific case, there is a better answer: print $ case compare 0 $ x + y + z of GT -&gt; "case 1" LT -&gt; "case 2" _ -&gt; "case 3"
You could also write case x + y + z of var | var &gt; 0 -&gt; sth | var &lt; 0 -&gt; oth | otherwise -&gt; mth which highlights that the `case`-statement does not do any pattern-matching even more and could be replaced with a `MultiWayIf`: let var = x + y + z if | var &gt; 0 -&gt; sth | var &lt; 0 -&gt; oth | otherwise -&gt; mth
If you want to give a name to an expression, you should use `let`, not `case`. And if you want to branch on multiple boolean conditions, not on multiple patterns, you should use MultiWayIf, not `case`: do let var = x + y + z if | var &gt; 0 -&gt; putStrLn "greater than" | var &lt; 0 -&gt; putStrLn "less than" | otherwise -&gt; putStrLn "equal" Or just regular nested `if..then..else` expressions: do let var = 3 if var &gt; 0 then putStrLn "greater than" else if var &lt; 0 then putStrLn "less than" else putStrLn "equal"
I haven't bothered to check. It might very well be that all list literals are "big".
I personally like the indent. I like being able to tell at a glance where the scope begins and ends. And if I move code in or out of a do block I'd like the version control diffs to communicate that accordingly.
What happens in a case like this: example = do path &lt;- getHomeDirectory withFile (path &lt;/&gt; "foo") WriteMode $ \h -&gt; do writeStuff h doMoreStuff If you translate that into: example = do path &lt;- getHomeDirectory withdo h &lt;- withFile (path &lt;/&gt; "foo") WriteMode writeStuff h doMoreStuff Then how does the compiler know which lines of the do-block should be part of the function passed to `withFile`?
What? No. Scope is important, especially using the bracket/withFoo pattern.
I did something similar about 8 or 9 years ago when I first tried to learn Haskell and I ended up just defining the answer to each problem as a value of type `Integer`. I only ended up doing about 20 of the problems but none of the ones I did returned anything that required a different type, so I just ended up with `euler1 :: Integer`, `euler2 :: Integer` etc. Of course I wasn't very comfortable with IO yet so I ended up defining some of the larger inputs as constants in my code as well. If you wanted to read these at runtime you'd of course need to use functions instead of values. I think if I were to do it nowadays I'd probably write them as unit tests with something like `hspec`.
&gt; The underlying motivation for that goal is to avoid inflating a git diff because adding some context function incidentally also requires increasing the inner code's indent level. I don't understand how this is an issue, the only situation in which this could be an issue if you're measuring work by diffs which is inherently wrong.. Anyways, you're looking at the wrong place, the solution is to use `git diff -w &lt;commit&gt; &lt;commit&gt;`.
With the [managed](http://hackage.haskell.org/package/managed-1.0.6/docs/Control-Monad-Managed.html) library, one can write this: managedExample = runManaged $ do path &lt;- liftIO getHomeDirectory h &lt;- managed $ withFile (path &lt;/&gt; "foo") ReadMode liftIO $ work1 h liftIO $ work2 h
It can be important if you have a lot of downstream patches... although I doubt this is a problem often enough to warrant something like this.
Sorry, I didn't want to sound like a downer haha. And if you guys might be hiring in the fall, that's only a few months from now :D Will definitely apply then
Incidentally, I'm also playing similar ideas here [https://github.com/FongHou/generic-data/blob/master/test/HKD.hs](https://github.com/FongHou/generic-data/blob/master/test/HKD.hs) . But I was following u/isovector's HKD https://reasonablypolymorphic.com/blog/higher-kinded-data/ , and use generic-data library (with u/Syrak's help. Thanks! :)
Thinking that &gt; IO a is a reference to a function is misleading, especially when if makes you think that that function is a regular haskell function therefore supposed to be pure. That being said, when I learned Hakell I didn't immediately realize the «world snapshot» explanation wasn't what was really going on with the code once compiled, and it bothered me until I found out.
&gt; I don't really see how that removes recursion? `Expr` is defined in terms of `Expr`, e.g. in the constructor `Add Expr Expr`. Whereas `ExprF` is not defined in terms of `ExprF`, e.g. the constructor `AddF a a` does not refer to `ExprF`. &gt; I don't quite see how they can be different? What do you mean? those are two different expressions, and they have different types. What did you expect instead? &gt; if you had a Maybe you'd get [...] and so forth? Yes. The inhabitants of `Fix Maybe` are `Fx $ Nothing`, `Fx $ Just $ Fx $ Nothing`, `Fx $ Just $ Fx $ Just $ Fx $ Nothing`, etc. You can nest as many occurrences of `Just` as you want.
Moreover, since ExprF itself is not recursive, the F-algebras defined for it are not recursive. The "recursiveness" is isolated in the reusable Fix type instead (separation of concerns). Note that if you sprinkle the definition of evalF with Fx, its type becomes Fix ExprF regardless of how deep you nest the expressions. The resulting mess can be somewhat alleviated by smart constructors.
Going from \`Expr\` to \`ExprF\` is like isolating one "layer" of the recursive type \`Expr\`. Once we've isolated that layer, we can do a number of things. &amp;#x200B; So let's start slow. \`Expr\` is a recursive data type because it references itself in its own definition. We'd like to "remove" that recursion, or, really, just get access to the information contained in \`Expr\` that doesn't interact with recursion. We do that by eliminating all of the recursive bits. &amp;#x200B; \`\`\` data Expr = Var Int | Add Expr Expr | Mult Expr Expr data NonRec = Var Int | Add | Mult \`\`\` &amp;#x200B; The problem with just \_removing\_ them is that we've lost flexibility. There's something interesting going on when Expr references itself. Instead of removing, we can just \_parameterize\_ those holes &amp;#x200B; \`\`\` data Expr = Var Int | Add Expr Expr | Mult Expr Expr data NonRec = Var Int | Add | Mult data ExprF x = Var Int | Add x x | Mult x x \`\`\` &amp;#x200B; Now, it should be clear that \`NonRec = ExprF ()\`. The parameterization gives us many ways of using \`ExprF\`. For instance, we could stick two "layers" together &amp;#x200B; \`\`\` type Two = ExprF (ExprF ()) &amp;#x200B; ex1 :: Two ex1 = Var 3 &amp;#x200B; ex2 :: Two ex2 = Add (Var 2) (Var 3) &amp;#x200B; ex3 = Add (Add (Var 2) (Var 3)) (Var 4) \`\`\` &amp;#x200B; Note that \`ex3\` is not of type \`Two\` because it has 3 "layers". &amp;#x200B; To recover \`Expr\` from \`ExprF\` we need to offer not two or three or any finite number of layers: we need to create a type which offers infinitely many layers. In other words, the equations below all hold &amp;#x200B; \`\`\` Expr = ExprF Expr = ExprF (ExprF Expr) = ExprF (ExprF (ExprF Expr))) = ... \`\`\` &amp;#x200B; We cannot do this with any finitely presented type. We need to recover recursion. \`Fix\` is a type which does just that &amp;#x200B; \`\`\` newtype Fix f = Fix { unFix :: f (Fix f) } \`\`\` &amp;#x200B; Notice that this definition implies all of the following equations &amp;#x200B; \`\`\` Fix f = f (Fix f) = f (f (Fix f)) = f (f (f (Fix f))) = ... \`\`\` &amp;#x200B; so it's exactly the right form for what we're looking for. &amp;#x200B; \`\`\` type Expr = Fix ExprF \`\`\`
There's already a response on several of your questions but regarding this: &gt;The main problem I'm having is catamorphisms and **why we have them**, say we have: Catamorphisms are a generalization of folds in a recursive/inductive data structure. But isn't the \`foldr\`/\`foldl\` family already a generalization? They are, but you can think of catamorphisms as a next level abstraction powered by category theory. &amp;#x200B; So why have a generalization that's powered by category theory and it's not easy do understand when we have other fold generalizations? Because category theory grasps very well the notion of universal constructions and universal properties, and happens that "folds" can be formalized in category theory by using F-algebras. So catamorphisms happens to have interesting properties like the universal, the fusion and reflection laws, etc. and provide a methodic way to study and develop algorithms (see ana and hylomorphisms) just by studying the recursive datatype. &amp;#x200B; There's a very good source book that's called Algebra of Programming that introduces every topic I talked about here and it's a classic for functional programmers/thinkers
Could you elaborate? It is a pure function because it’s taking a snapshot of the universe as an argument, which was what I was trying to communicate in the post.
Neat! This reminds me a lot of my adventures with the [rank2classes](hackage.haskell.org/package/rank2classes) package. `barbies` looks kind of like a `rank2classes` specialized to records with fields whose types are of the form `f Foo`. Will have to check that out.
I used it back when I was working on a project that use opaleye, and I found it very nice. Ill-explained all over the web, but nice when you get your head around it.
I believe you can essentially already do this, since Haskell does not require you to actually increase the indentation https://prime.haskell.org/wiki/NondecreasingIndentation. You just don't get the binding on the lhs, which I think is good enough if diffs are your concern.
It's the "rest" of the `do` block -- all of the following lines in the same `do` block. So the two `example`s in your comment are not equivalent. Does that make sense?
I didn't intend the keyword to change any scopes. Would you pose an example where you think scope is changing so we can discuss? How about: do m withdo x &lt;- f n o That would desugar to `do m; f (\x -&gt; do n; o)`. The same as do m f $ \x -&gt; do n o
Yes, `git blame -w` can help too. Neither of those options are as precise as just making a commit that doesn't change whitespace in the first place when it doesn't need to, though. If a commit just adds an exception handler, then its diff should just be the addition of that handler, not all of the old code in its scope that did not itself change -- it still raises exceptions, they just get caught sooner by the new code. That's the opinion I'm starting from. Thanks for sharing your thoughts.
I haven't managed it. Please share if you do.
I'm getting a bunch of uninterpretable type errors when I replace patterns with their equivalent pattern synonyms. Can anyone tell me what's going wrong? Code and errors in this gist: https://gist.github.com/LSLeary/d873b20e73aa1896ac4552de4e1b5753 GHC 8.6.3
Thanks for leading the charge on this angle. I agree that the indent can be nice to have sometimes at a glance. In my experience, those are the examples where you couldn't get much from `withdo` in the first place, like in the comment by /u/Tayacan. The first `example` there is equivalent to the following, where `withdo` isn't changing much. example = do path &lt;- getHomeDirectory do withdo h &lt;- withFile (path &lt;/&gt; "foo") WriteMode writeStuff h doMoreStuff If the `withdo` keyword were more familiar, I do think both of your sentences could still be true. The scope is just the rest of the `do` block, which is apparent at a glance. With `withdo`, the diff would still show the addition or subtraction of handlers/brackets/etc, but it would not show all the code in that scope, unless it also had actual changes in it. That seems right to me, since that code still for example raises exceptions; the only thing that changes is where those are/aren't caught, which is what would show up in the diff. On the other hand, if the handlers already exist, and you're moving code into or out of their scope, then `withdo` doesn't really affect that -- all of the moved code would still be in the diff. There's a lot more subtleties to talking through all this than I anticipated! Please forgive the big reply.
I believe the issue is not with changing scope, but rather with seeing scope, as in [lgastako's comment](https://old.reddit.com/r/haskell/comments/bknxw1/new_sugar_to_avoid_indent_with_bracket_idiom_in_do/emi4vly/).
Yep! That's a particularly nice way to use what I called "the `ContT` layer", when that's an option.
The paper I link to in my post has a more thorough and clear rundown of this, I think it makes for an interesting and approachable read.
I struggled with this for a while and I find that my understanding and to come together once I started using this stuff. I wrote about it here http://shmish111.github.io/2019/04/13/recursion-schemes-patterns/ in case it helps.
I remember having had similar trouble to grasp what was meant by "removing recursion", and how it was tied with `Fix` and everything else. Once it clicked, I wrote [a post](https://duplode.github.io/posts/whats-in-a-fold.html) which you might find helpful -- in it, I have tried to go through it very slowly, one trick at a time. For something more condensed, [tel's comment here](https://old.reddit.com/r/haskell/comments/bkolte/trouble_understanding_falgebra_and_catamorphisms/emihks3/) explains it very nicely.
I honestly don't feel this way, but this is because I've read a few papers on GHC RTS and find reading GHC.Types listing easier. Reading how GHC RTS works makes understanding things like IO a lot easier.
 GHCi, version 8.4.3: http://www.haskell.org/ghc/ :? for help Prelude&gt; let withIt a k = k a Prelude&gt; :{ Prelude| do Prelude| withIt 1 $ \a -&gt; do Prelude| withIt 2 $ \b -&gt; do Prelude| withIt 3 $ \c -&gt; do Prelude| pure (1 + 2 + 3) Prelude| :} 6
But if you want clicks you will need to have a clickbaity title..
Does this setup need haskell ide engine or anything?
Ah, wow. I never thought to leave the \`do\` in there. That is totally sufficient for my goals. Much appreciated! Just a disclaimer to the world: I don't plan to use this in real work :)
Better alphabetMaker (I think, tell me if it doesn't do what you want): alphabetMaker n = take 26 $ drop n $ cycle [A .. Z]
RemindMe! 142 days "Check [mercury.co](https://mercury.co) positions for international hiring"
I will be messaging you on [**2019-09-24 03:32:15 UTC**](http://www.wolframalpha.com/input/?i=2019-09-24 03:32:15 UTC To Local Time) to remind you of [**this link.**](https://www.reddit.com/r/haskell/comments/bkc4v6/mercury_is_hiring_a_haskell_engineer/emje8h0/) [**CLICK THIS LINK**](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[https://www.reddit.com/r/haskell/comments/bkc4v6/mercury_is_hiring_a_haskell_engineer/emje8h0/]%0A%0ARemindMe! 142 days ) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete Comment&amp;message=Delete! ____id____) _____ |[^(FAQs)](http://np.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^(Custom)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^(Your Reminders)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List Of Reminders&amp;message=MyReminders!)|[^(Feedback)](http://np.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback)|[^(Code)](https://github.com/SIlver--/remindmebot-reddit)|[^(Browser Extensions)](https://np.reddit.com/r/RemindMeBot/comments/4kldad/remindmebot_extensions/) |-|-|-|-|-|-|
Hey! I think this was a really interesting problem to tackle. I'm not a Haskell expert by any means. I think that when considering *idiomatic* Haskell, it's a good idea to consider starting with some kind of structure and piping that through a series of transformations. encrypt :: Char -&gt; Char -&gt; Char encrypt x y = chr . (+65) . flip mod 26 . subtract 130 -- 2 * 65 $ ord x + ord y decrypt :: Char -&gt; Char -&gt; Char decrypt x y = chr . (+65) . flip mod 26 $ ord y - ord x vigenere :: (Char -&gt; Char -&gt; Char) -&gt; String -&gt; String -&gt; String vigenere e p = zipWith e (cycle p) . map toUpper . filter isAlpha This will just extract the letters, convert them to upper case. It could be easily adapted to maintain spaces and numbers in the message.
Are there scholarships available for low-income people?
See also [cloneAdapter](https://hub.darcs.net/roconnor/lens-family/browse/core/src/Lens/Family/Clone.hs#58)
Ooh that's a better idea, having the encrypt/decrypt functions be arguments to the cipher function, instead of having a toggle.
I've almost finished listening to this series: http://www.haskellcast.com
Nice blog post! We are using similar ideas in `summoner`. However, one slight modification that we came up with: we introduced custom enum (called `Phase`) to have more control over the structure of config. * https://github.com/kowainik/summoner/blob/master/summoner-cli/src/Summoner/Config.hs
I do use it, but it is through `autozimu/LanguageClient-neovim`. So no, the plugins I listed above do not require HIE :)
Yes. We have a limited number of volunteer tickets available. For more infromation, email us at [info@composeconference.org](mailto:info@composeconference.org) describing your situation and background in FP.
I must be mistaken somehow, but I don't see how that gives any extra control, the type family gives you pretty notation, but isn't it the same as using Last and Identity at the end of the day (modulo some identity unwrapping)?
[A generally accepted rule of thumb is three major GHC releases. ](https://www.snoyman.com/blog/2018/07/stop-supporting-older-ghcs)
&gt; But hold on a sec, if IO a is a reference to a function, what parameters does the function take? If it doesn't take any parameters, wouldn't any two invocations of a function be equivalent? You are mixing here pure functions as they are in haskell with conventional "function" concept in imperative languages. `IO a` is like the latter, but not like the former (except you invent the "World" pseudo-value). "Action" is a better term.
That rule of thumb was derived from the idea that you'd want to support a ~3 years range worth of GHC releases for various reasons (such as e.g. be able to support the respective GHC versions that ships with current popular stable Linux distributions to allow for idiomatic workflows with `cabal new-build` involving a hybrid mix of debian-packaged haskell libraries together with installed from Hackage). For reference, Debian 9 released in 2017 and bundles GHC 8.0; The latest LTS release of Ubuntu 18.04 was released in 2018, and also bundles GHC 8.0. However, due to the accelerated GHC release cadence, the 3-release-window rule has now become effectively a 5- or 6-release-window rule in order to satisfy that rationale. And personally I go way beyond that, and try to support all GHCs back to GHC 7.0.4 or GHC 7.4.2 when easily possible; see e.g. - https://matrix.hackage.haskell.org/package/OTP - https://matrix.hackage.haskell.org/package/HsYAML - https://matrix.hackage.haskell.org/package/cryptohash-sha256 - https://matrix.hackage.haskell.org/package/uuid - https://matrix.hackage.haskell.org/package/text - https://matrix.hackage.haskell.org/package/resolv - https://matrix.hackage.haskell.org/package/pipes-brotli ...
Why do I have to make the GHC installation location-dependent? Doesn't `hint` come with its own GHC? (Sorry for the late reply - for some reason Reddit didn't notify me of your reply.)
I am mixing the two types, dipping in and out of the functional world and what it’s compiled down to. But I am very intentionally making the argument that in “the lie” IO a is a perfectly normal pure function that takes in a simulated universe and returns a new universe with all of the “side effects” embedded within it.
What's going on here is extremely subtle. Basically, your patterns are *requiring* that the type argument to `HList`/`HSum` be something of the form `a ': l`, rather than *providing* a proof of that fact like the GADT patterns do. I recommend you read the [GHC User's Guide's section on pattern synonym types](https://downloads.haskell.org/~ghc/8.6.3/docs/html/users_guide/glasgow_exts.html#typing-of-pattern-synonyms). It explains the details of this pretty well and the last example, in particular, is very relevant. For your specific example, replacing the pattern synonym type signatures with the following should work. pattern (:~~) :: () =&gt; al ~ (a ': l) =&gt; a -&gt; HList l -&gt; HList al pattern Here' :: () =&gt; al ~ (a ': l) =&gt; a -&gt; HSum al
Great Job!
TDD!
https://raw.githubusercontent.com/aiya000/vim-ghcid-quickfix/master/sample.gif
[Lambda cast](https://soundcloud.com/lambda-cast) Nice for beginners. They go topic by topic. Was eye opening for me sometimes. [Magic read along](http://www.magicreadalong.com) Various topics. Quite advanced. Like the hosts.
IMHO presenting it as "the state of the universe" like some tutorials do is more confusing that it needs to be. I for one used to think that explanation was crazy, but the "real one" wasn't always in those tutorials. I think they should have started with the conclusion of your blog post: That's it's a trick to make sure the function calls are not optimised away and correctly sequenced. Also, it is a function in many haskell implementations, like GHC, but it's not really a pure function because many compilers will treat them in a special way (for example according to the IO inside wiki page, on the Yhc implementation "The lack of the World on the right-hand side of the function can only be done because the compiler knows special things about the IO type, and won't overoptimise it." But although many implementations use some kind of state monad for IO, according to the Haskell report, " The IO type is abstract ". Therefore, we maybe shouldn't use GHC's or YHC's or JHC's (etc) implementation to reason about it, even if many haskell compilers have similar implementations. So when you look just at IO a as an abstract type, there's no arrow so no function there. Something of type IO a could be just a value. We're not sure. That is why in my opinion thinking of a value of type IO a as a regular haskell function might be confusing until we learn about the whole story of the implementation we're using. That's what you clear up in the last part of your post.
With this approach users of the data type are restricted to only these two options: `Last` and `Identity`. When I sad _control_ I meant _control over instantiations of the type variable_.
\&gt; Are there any stats about what versions of GHC are in common use? A reasonable idea is to check which libraries are packaged by oldest supported releases of Ubuntu and Debian. Going with that. still supported Ubuntu 14.04 LTS was packaged with GHC 7.6, so legacy branch for at least this version should be maintained and get bugfixes . Similarly, the latest Ubuntu LTS is packaged with ghc 8.0.2, so this version is the earliest you should take for given on developer machine.
That's unfortunate, I really dislike the idea of sticking with python :-P
The class [BareB](https://hackage.haskell.org/package/barbies-1.1.2.1/docs/Data-Barbie-Bare.html#t:BareB) in [barbies](http://hackage.haskell.org/package/barbies) can be generically derived and may do what you want, if I understand your example correctly.
hint depends on the ghc library, which does all the compilation etc., so you don't need to have a ghc executable installed. However, a ghc installation consists of more than just the ghc executable, it installs a lot more files, and the ghc executable and the ghc library both use those files at runtime. In my proof-of-concept, I figured out exactly which files those are and which changed I need to make in order to move them to a different location.
The "3 major releases" rule is about GHC itself - GHC uses this rule to make sure that any GHC version, including the next upcoming release, can be bootstrapped from the current or previous release. But unless you are working on GHC itself, or one of the "boot libraries" that GHC itself depends on, it's not a super meaningful rule. In practice, you will want to support GHC's further back than that; for example, right now you would only have to go back to 8.2, and you wouldn't even have to support 8.0. How much further back, though, depends mainly on your use case and target audience.
Ahh I see!
I do a podcast called JavaScript To Elm. While it’s often about Elm, I do a fair amount of Haskell learning, Rust, Elixir, and anything else that comes up as interesting. Check it out. https://jstoelm.com/ I’d love to know what you think.
You could try the tensorflow bindings for haskell.I have not used them yet though, so no idea what the status of the project is. https://github.com/tensorflow/haskell
&gt;Have you used any other Haskell library with LSTMs? I used [backprop](http://hackage.haskell.org/package/backprop) to implement a LSTM network for sentiment analysis: https://github.com/ziocroc/scraps/blob/master/haskell/sentiment-analysis/Model.hs
No RNN example available, so I guess no one checked that this work or was unable to deliver working example ;) [https://github.com/tensorflow/haskell/issues/57](https://github.com/tensorflow/haskell/issues/57) Also the LSTMs and GRU are implemented only in some forgotten branch and left there alone unmaintained: [https://github.com/fkm3/tensorflow-haskell/blob/80f1edab29fa01e5f46c8853722d9eacd2f0d5e1/tensorflow-ops/src/TensorFlow/RNN.hs#L42](https://github.com/fkm3/tensorflow-haskell/blob/80f1edab29fa01e5f46c8853722d9eacd2f0d5e1/tensorflow-ops/src/TensorFlow/RNN.hs#L42)
I have made this python script [1] that really streamlines reload+error/warning navigation for me. Difference from ghcid are 1. Does not rely on file system watches for files changes, instead depends on the editor to send a reload command (using vim/nvim auto commands) on file save. Actually you can send any command to the wrapped ghci instance via the ip/port where the script is listening. This allows me, for example, to explicitly send a ":load" command to set the module that will be loaded/reloaded, on every file save. 2. Don't have to keep a separate window ghcid window open because the script can control status bar colors to indicate success/warnings/errors. 3. Since the script parses the output and populate the quick fix window of the editor with errors/warnings, you can use vim's native keybindings to jump/navigate between errors. 4. Can work across virtual machine/docker boundaries, the editor adapters that control the editor, can be configured to handle file mappings to translate from virtual machine/container path to host file paths in editor. [1] https://bitbucket.org/sras/rcrepl/src/master/
That was a wonderful series. Sadly Chris stopped recording it in 2017. I really hope either Chris or someone else picks it up again.
[Software Engineering Daily](https://softwareengineeringdaily.com/category/all-episodes/exclusive-content/Podcast/) is pretty cool. I think I have listened to most of them now. It's mostly focused on software architecture and high level design.
I'll lightly recommend CodeWars, HackerRank, and CodinGame as providing concrete tasks to use your Haskell skills on. I'll recommend Cyber-Dojo for practicing many languages, including writing your own tests.
I listen to Making Sense podcast, Small Beans, and Poetize the News with Doug Shields. In between content, I listen to a lot of Audiobooks.
[removed]
&gt;However, I don't really see how that removes recursion? It doesn't, it makes it more structured, by using an existing scheme with well-known properties. &gt;I don't quite see how they can be different? This is your most unclear question. `ExprF` is supposed to be the structure of one "layer" of `Expr`, so they are going to be quite related. Fix f = Fx (f (Fix f)) (You left out a close paren.) &gt;I know that it's purpose is to generalize recursion but I don't understand how, for instance if you had a Maybe you'd get: If you really want to know over GHC deals with recursive types, you'll have to dig into something more GHC specific. Suffice to say, it doesn't recursively expand the type inline without limit and get stuck. As far as the *values* of `Fix Maybe`, it is possible to enumerate them. I won't do that here, but some examples include: * `Fx Nothing` * `Fx (Just (Fx (Just (Fx (Just (Fx Nothing))))))` * `let next = Fx (Just next) in next`
The World variable is simply in order to force the lazy graph reduction algorithm of haskell execution to execute the first argument of bind before the second, so the sequencing is assured. Nothing more. The Clean language used this same strategy in the open. The monad does it in the inside. Please don mystify things. We have enough mambo jambo, enough buzzword and enough myths in functional programming.
I'm listening weekly to [http://corecursive.libsyn.com](http://corecursive.libsyn.com)
https://media.giphy.com/media/1Z02vuppxP1Pa/giphy.gif
This was an amazing explanation, thank you! Just one thing, for the ex1 :: Two ex1 = Var 3 Would I be right in saying that Var 3 is of type ExprF x which then because of the type Two becomes ExprF(ExprF x) ? But then wouldn't that mean for the ex2 = Add (Var 2) (Var 3) Var 2 and Var 3 are of type ExprF x but Add adds just two x's?
I looked at this library recently and I think the release version has a non functioning LSTM -- could not see how to train it with the state changes, it seems to be treated like a regular layer. The github head seems to have a functioning version but I am not sure why it is not released. I got distracted and did not use it in the end.
This was [previously asked 6 months ago]( https://www.reddit.com/r/haskell/comments/9qpgaw/any_haskell_or_programming_related_podcasts_you/). Podcasts from that thread that were not mentioned here (I approve of): * [Functional Geekery](https://www.functionalgeekery.com/) * [Type Theory Podcast](http://typetheorypodcast.com/) These are not strictly Haskell podcasts, but the only strictly Haskell podcast is Haskellcast.
I also checked the Github version, reinstalled it locally and tried to run the shakespeare example. With no success. But somehow the author managed to get those generated sentences at some point. I also suspected that maybe it worked in some previous revision, so I picked up one from before some big changes in code structure. The results I got are still the same.
Yeah, I worry about this "problem" when considering using a wiki as a medium of teaching/explanatory-style documentation. It's quite nice to have a documentation page use a single voice, but that's really hard when it's a wiki with multiple contributors. I guess that could be resolved by having a doc management team which monitors recent wiki changes to integrate it into the normal/standard doc voice.
Thanks! Normally I'm quick to go to the user's guide, but I thought I was familiar enough with pattern synonyms that I didn't consider I might be missing something like this.
Maybe check out hasktorch (https://github.com/hasktorch): very much in-development, but I’ve had success with cnns and mlps, getting equivalent results to reference pytorch implementations. Haven’t tried rnns yet, but I wouldn’t be surprised if it’s possible. Be prepared to learn a lot about type literals, existential quantification, etc, but I’m finding it very satisfying.
The ref to the old question is gold! Thank you!
Right, those kind of platforms are good to get your hands dirty and learn new languages by practicing. Yet I find making the next step very difficult. How can you move to something real that can give you experience in production code ( or similar) so you can state ( in your resume) that you know haskell for real. It's a very general question that might apply to any case of someone learning a new programming language outside a working environment, but since I really got into Haskell as well...
You could probably do it with foldr or foldl, if that's what you mean. Something like: modifyArray xs arr = foldl (\arr' x -&gt; ...) arr xs Where `...` should be replaced with your array update code. Note that I haven't tested this, as I'm not at a computer right now.
Without recursion it’s impossible; but you can create a higher order function and separate the recursion from what you’re doing at each step (like what `foldr` does with lists)
You are saying to create my own higher order function? or to use foldr?
You can hide behind `iterate` maybeParent (Just node) = parent node maybeParent nothing = Nothing myNodes = iterate maybeParent Then just `map` whatever you want on that.
Make a 'hub' like tool for gitlab... or CLI access to any API at all really. &amp;#x200B; For example this could result in you using: 1. A CLI library (optparse-applicative, simple-opt-parse, or similar) 2. An HTTP library for requests 3. Handing and parsing responses, JSON parsing for the good stuff &amp;#x200B; It can be a really small program that's totally operational and grow as you develop more functionality. * Want to avoid command line arguments to start with? Find just do a hacky case over the first arg. * Can't stand the number of JSON forms from the API? Support one or two, or borrow from one of the existing packages. * Don't want to worry about error cases? You're the user, throw non-200 responses as exceptions till some user decides to catch them later for pretty errors.
That's weird. In my test, I was able to run `hint` with dependencies successfully despite not having a global GHC installation (I manage everything via `stack`) or manually copying any of those files across. Maybe `cabal sandbox` manages that stuff automatically?