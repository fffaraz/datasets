[http://lmgtfy.com/?s=d&amp;q=REGION+BASED+MEMORY+MANAGEMENT](http://lmgtfy.com/?s=d&amp;q=REGION+BASED+MEMORY+MANAGEMENT) 
You're more than welcome to disagree. I won't ask you to explain your thinking again here because you're not going to. You have all these opinions which make no sense and which not only are you incapable of justifying but are seemingly unwilling to examine critically. No matter what arguments people present or evidence that they provide, your "opinions" remain. That's not a good sign. Contrary to what the web coders might say, computer science and software engineering aren't these "fuzzy" subjects that you can just come and redefine to suit your sensibilities. You having a crush on linked lists doesn't make them generally applicable, "efficient" and/or "cheap". It's fine to have opinions but your opinions should probably be open to revision when reality and experience contradict them... Good luck.
Should I bother to ask why you think that? All you seem to have our thoughts and opinions with no rational justification... could I perhaps suggest that what you might need is some real experience? I'm guessing that you're a student?
I'll eventually port most of my string vocabulary into ANS. Null terminated strings have their issues, but I'm used to them at this point and rather like having just a single representation I can address via a single pointer on the stack.
Please, give me one example of a solution that exists without a problem for it to solve.
Unfortunately, that's not an option for me, as I find myself parsing through [data that may contain zeros](http://wiki.osdev.org/Memory_Map_%28x86%29#Extended_BIOS_Data_Area_.28EBDA.29), as well as dictionary words that are quite literally nonprintable numeric values (hashes that may contain zeros). Null-terminated strings are just not general enough.
Is that type of data actually best considered as strings though, or would it make more sense to develop a vocabulary to handle a structure like that? I'll confess to some curiosity as to how you handle creating and using words whose names consist of nonprintable data. At a first consideration it feels like this would be problematic to use, so I'd like to see a practical example of how it's useful.
This looks much easier than connecting to tuporo via telnet! Also, I really like your markdown-based literate programming format. It makes for a fun read, without just glossing over or omitting large parts of the source code as many other programming articles do.
Thanks! I've grown quite fond of my programming format; it really helps me to remember what I was thinking as I worked on things, and to understand what I was doing when implementing things (which is really nice when one has to delve back into something not touched in a few years...).
Obviously those are not words in the sense of being called from the interpreter in any meaningful way. Part of my [dictionary speed upgrades](https://www.reddit.com/r/Forth/comments/70azbk/optimization_for_the_forth_dictionary/) allowed me to integrate the dictionary and an unrelated hash table together under a common structure, the dictionary itself with the binary search tree upgrade. The sparse array is a pain in the ass without some automatic memory management, and O(lg) is plenty comfortable for a lookup time. Those hash-labelled words are automatically generated as part of RAM-caching the folder hierarchy of the filesystem upon which this system resides. The hash itself is a hash of the full pathname (storing a full pathname is antithetical to doing the hash in the first place), concatenated with the length of the full pathname to ensure extreme unlikelihood of collision. Furthermore, part of the process of interpretation requires a substring of the input buffer to be provided. I find copying a substring out of the buffer every time a new word is found (under the whitespace-delimited style, or in general) just to add a null terminator to be terribly wasteful of time and memory.
This and "tuporo" definitely highlight some advantages of HTTP over Gopher. Gopher's simple protocol makes sense for something that was designed to be purely readonly, but HTTP's GET/POST/PUT/etc. methods start to make a lot of sense once you want to take different actions on the same URL. Don't take this as discouragement; Gopher is still cool. :)
&gt; Obviously those are not words in the sense of being called from the &gt; interpreter in any meaningful way. Part of my dictionary speed upgrades &gt; allowed me to integrate the dictionary and an unrelated hash table &gt; together under a common structure, the dictionary itself with the &gt; binary search tree upgrade. The sparse array is a pain in the ass &gt; without some automatic memory management, and O(lg) is plenty &gt; comfortable for a lookup time. Makes sense, though I'm still a bit uncomfortable at the idea of using the hash values as string data. &gt; Furthermore, part of the process of interpretation requires a substring &gt; of the input buffer to be provided. I find copying a substring out of &gt; the buffer every time a new word is found (under the whitespace-delimited &gt; style, or in general) just to add a null terminator to be terribly &gt; wasteful of time and memory. This definitely makes sense. I don't have a substring level word identification as part of my interpreter, so I can avoid the copy out for the most part. (Exception being when using `s:evaluate`, which I currently only use in the block editor). 
No discouragements taken :) HTTP is a much more flexible protocol. But that comes with more complexity, which I try to avoid when I can. (I'd rather not deal with the headaches that go into making a full HTTP server with POST/PUT/etc, and definitely don't want the headaches of dealing with HTTPS or HTTP/2). I do rather Gopher protocol in this instance though. (E.g., if Tuporo was strictly standard, it would require multiple requests to update a block since the selector strings aren't technically supposed to be longer than 255 characters). Given that the main part of the server visible to a client is standard though (giving the list of blocks and serving them as formatted text), I don't worry too much about this. 
You could do either of those things.
Forth and common lisp are both examples of solutions that you can pick before having a problem to solve.
What if my problem is that I have a flat tire? Those are bad solutions!
I did not come to the conclusion that I should use hash strings quickly or easily, but with the stack-like nature of the dictionary, the only way to do hash tables otherwise is to make a new (larger) table and ignore that the older one exists. I was less comfortable with that, since that not only propagates redundant data, but the hash table is meant to have a large capacity which can mean a 2MB table being resized to 4MB just adds 4MB to the dictionary. That can add up quickly, and really the dictionary is already there doing a great job at essentially the same thing. Quick edit: This also can do a bit to enforce locality to mitigate memory page swapping.
True.
Actually JonesForth uses lot more assembly code than what is really required. You need to code only a few primitives like stack shufflers, arithmetic and logical operators, the inner interpreter (that's 2 instructions on an x86) and codewords like docolon in assembly. But all the rest (including the outer interpreter, `word`, `find`, etc) can be implemented in Forth (at least in compiled Forth) because you already have an inner interpreter at this point. But that's not the only way. You can write everything in Forth including the primitives if you write an assembler in Forth first. However I haven't tried this approach maybe the others can share their experiences with this approach.
The "Moving Forth"[0] articles may be of some help. Also eforth[1], which builds up from around 30 or so primitives. * [0] [http://www.bradrodriguez.com/papers/](http://www.bradrodriguez.com/papers/) * [1] [http://www.forth.org/eforth.html](http://www.forth.org/eforth.html)
The j1 project might be useful as well: http://excamera.com/sphinx/fpga-j1.html https://github.com/jamesbowman/j1 
"I have no issues coding the entire initial system in hex." It is not necessary to code in HEX if you can start with a Forth system to help do the bootstrapping. Its very possible to make a simple "assembler" in Forth that lets you use mnemonic names for your instructions. It can get as sophisticated as you want but something simple is very easy to do. \ example for a crude Forth Assembler instruction \ compiles an instruction and takes the address from the stack HEX : JMP, ( address -- ) 0AEF , , ; \ AEF is the jump code No matter how minimal the foundation instruction set you need to agree on the header structure of each word will be laid out in the Forth system and how to search that dictionary. I recently did this for fun for the TI-99/TMS9900. There are lots of comments in the code and a few bugs. :-) V2 is coming I used Brad Rodriguez CAMEL Forth as my starting point so I did not have to re-invent the wheel. You can see the code here: https://github.com/bfox9900/CAMEL99 Please provide us with a bit more info about the CPU and we can probably give you more specific help.
Your best bet is probably to start with an existing Forth, say gforth, and build a cross-assembler for your CPU. gforth is useful because you should be able to hold enough of your CPU's address space in a single ALLOT block to be able to assemble an image into it. (If you're really feeling adventurous, you could use gforth to recode your simulator, complete with front panel; [here](http://sametwice.com/drawlines.fs) is some sample code for drawing on the framebuffer, for example. Or [these](https://www.complang.tuwien.ac.at/forth/gforth/Docs-html/Terminal-output.html) are the three words you need, other than EMIT and TYPE, for basic console output.) Once you've done that, you need to build a little proto-Forth in that, and save the image in such a way that you can load it into your CPU emulator. eForth has been recommended because it does exactly that; starting with fewer than 30 primitives in assembler, it extends itself all the way up to be a full ANS-compliant Forth. You might want to start with Bill Muench's eForth package (he created it), which can be found [here](http://web.archive.org/web/20000920040523/http://members.aol.com/forth/eforth/E4.ZIP). But it does assume you know Forth pretty well; so do the Moving Forth articles mentioned elsewhere in the thread, but they start without dropping you in the deep end of metacompilation. Is your CPU documented anywhere? We might be able to give more specific advice if we can see the architecture you're wrestling with.
Check /r/osdev for some inspiration, and their wiki for general ideas too: wiki.osdev.org What is your target CPU? Whatever it may be, you'll probably want direct-threaded code if it's a simple system. If your CPU lacks operators like divide and multiply, I have some algorithms for those that use shifting instead of repeated adds or subs.
Thanks for all the replies, I have a lot of material to get through now! :P I'm going through the Moving Forth pages and it's slightly slow going as I'm not yet quite managing to get a picture of how the entire system fits together. Making progress though. As to the questions.about the CPU, it's not documented as it's something I cobbled together for this project. The broad strokes where taken from Wirth's RISC architecture. Its a bit of a work in progress (never implemented anything.like it before, apart from some fiddly bits its surprisingly easy to do, doing it well...) so some things may still change. I'll write up as complete a description as I have at the end of this post. In terms of jumping off an existing Forth I have to be honest I don't know enough Forth to spell my name let alone code a cross-assembler. From my current perspective doing the basic system in hex is actually less daunting than the other way around. I also find it easier to learn things by building them before I start using them. Thanks for the osdev suggestion, I'll definitely have a look at it. In a similar vein I've been going through the Project Oberon book to help figure some bits out. It's been fascinating so far. :) Thanks for the idea about recoding the emulator in forth, doing so didn't actually occur to me. I'll most certainly have to look into that once I'm more proficient in Forth, should make an excellent learning experience! Okay, onto CPU, from an overview perspective everything goes through RAM. The first couple of bytes (as of yet an undecided amount) are all the devices including the main disk and the "boot" disk. The contents of the boot disk gets read into memory on startup. I'm not certain why I have both a disk and a boot disk however... There's space for a keyboard and mouse, however they will likely not be done anytime soon nor will the screen. Instead I'm planning on running everything through the "network" (in practice it operates almost identically to the disk, it can read or send a byte at a time). there's no IRQs at present, the main loop simply checks whether certain memory locations are signalled to do something and then does it, this also means that unless the software explicitly checks those locations data may be lost (also if an upwards out of bounds memory access is attempted it'll silently return the last byte instead) The instruction set I believe have roughly 14 opcodes in it: halt, mov, ror, not, or, and, xor, add, sub, store, load, jmp. Add and sub have options for sign and magnitude based signed operations, however not much is being done with.the corresponding flags at present, ror can ignore the sign bit when shifting. Jmp has the usual equality and so forth include an unconditional option and a "never" option that I'm using to store the program counter with. Jmp incidentally requires a register in addition to hold the condition its suppose to use, altogether jmp will eat at least four registers to do anything. All opcodes can work with immediate or register modes. opcodes are three bytes long. There's sixteen registers, each can take a byte. The high three is where jump stores the program counter (this cannot be changed). Memory access is also a byte at a time. That's all I can thing of, pieces are still broken so every once in a bit it fritzes out and I'm still altering it as I figure out a bit better what I'm doing, but these basics are actually quite stable Thanks again to everybody for all the replies, it's been extremely helpful so far. :) And apologies for not replying individually, I had some troubles keeping all the advice straight in my.head.
I recommend reading [Threaded Interpreted Languages](http://sinclairql.speccy.org/archivo/docs/books/Threaded_interpretive_languages.pdf) for how to implement a language runtime with the minimal amount of bootstrap code. This c2 page on [threaded interpreters](http://wiki.c2.com/?ThreadedInterpretiveLanguage) will give enough background to put the book into context. You can start with basically a page of Rust code and get a threaded interpreter up and running. I'd then go back and figure out how to bootstrap that from hex or assembly. Not as directly applicable but definitely enjoyable is [Stack Computers a New Wave](https://users.ece.cmu.edu/~koopman/stack_computers/index.html).
What the problem? Use bytecode, and write some sort of double-stack CPU emulator in C(++) in one evening, with assembler/compiler in flex/bison let you build bytecode image file. Yes, it is slow. But extra portable -- I'm going to write something like this for Android, and making console window will be much much complex then FORTH system. Or you can use Python, and commands coded in tuples, like ('jmp',0x1234) -- not portable, as byte arrays, but you can extend Forth idea with any objects on a stack (in real Forth lacks multitasking and queues/streams). Just prototype some cool visual IDE using wxWidgets, then port to faster C++ The bytecode approach is attractive for me for one reason: you are free to experiment with extra features: multitasking, scheduling, threading can be done only in software (switch memory/stacks in VM) or use real OS threads, connect any libraries, use any programming languages for core and extending, can play with clustering and message passing,.. If you need real machine code, extend VM with an ability to run real machine code from selected address, and write postfix assembler -- so you don't require to write all FORTH in assembly (machine code compilation is some complex for beginner, a lot of hardware specific subtleties with command encoding, addressing,...). 
For a roll-your-own CPU, it might be a good idea to code an assembler first. EDIT: Is this a processor implemented in an FPGA? Or a VM?
I'll second this. Writing an assembler gives a tool that can accelerate future progress significantly.
You can use a Forth running on your real PC and go with http://pygmy.utoh.org/3ins4th.html Or even use a similar approach with C/Python/whatever. I am doing it with AVR MCUs/Python and it is extremely easy and productive.
moving forth dont have a x86 or arm or even mips version :D like the author said "Everyone in the Forth community talks about how easy it is to port Forth to a new CPU. But like many "easy" and "obvious" tasks, not much is written on how to do it!"
&gt; Its very possible to make a simple "assembler" in Forth that lets you use mnemonic names for your instructions. I recently did just this; it works really well. The assembler I ended up writing has Forth-style control structures so it's really not that far from being Forth. Where it's lacking is, of course, interactivity, which is provided by the Forth system I used to write the assembler. All in all, it was a pretty fun experiment.
It is good you are thinking about these things, some of those thoughts haven't been full examined. Be careful in claiming what you know, you need to prove it from many different angles, have an honest level of self criticalality. 
This is what compsci is for and the things it thinks about and the solutions require a much higher level of formalism than seen in this thread.
They are tools, not solutions. One would use them to express a solution to a computational problem. 
An approach is a technique for approaching a problem. Like the [scientific method](https://en.wikipedia.org/wiki/Scientific_method) is a technique for rigorously building knowledge. It self isn't a specific solution to a problem, it is a _technique_.
**Scientific method** The scientific method is a body of techniques for investigating phenomena, acquiring new knowledge, or correcting and integrating previous knowledge. To be termed scientific, a method of inquiry is commonly based on empirical or measurable evidence subject to specific principles of reasoning. The Oxford Dictionaries Online defines the scientific method as "a method or procedure that has characterized natural science since the 17th century, consisting in systematic observation, measurement, and experiment, and the formulation, testing, and modification of hypotheses". Experiments need to be designed to test hypotheses. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/Forth/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.27
I'd recommend Koopman's other work, [https://users.ece.cmu.edu/~koopman/tigre/](Tigre - An Architecture for Combinator Graph Reduction (TIGRE\))
If one had hardware support for renaming registers arbitrarily ... or could easily permute the selection bits in an instruction sequence one could represent both a stack and a register file at the same time.
u/ummwut, it's a VM based CPU, I thought I mentioned that but I don't think I was very clear. To both of you, I fully agree that an assembler would make thinks a lot easier and at some point I will have to deal with that one way or another. Mostly though o have some time on my hands and it occurred to me that I don't know how these things work, so my approach is somewhat adhoc and strongly led by where my curiosity leads me. Writing an assembler is secondary to knowing what to do with it for me at present.
Thank you. That book is gold and is helping to tie some of the pieces together from the other stuff I found. :)
In STM8 eForth I recently solved a similar problem by defining an EMIT word (see [T{e .. e-&gt; ..}T](https://github.com/TG9541/stm8ef/blob/master/lib/utils/tester.fs). This is portable, I suppose.
Awesome! I can never have enough theory. I really enjoy programming, but I did major in CS for algorithms, and this is my jam :)
That's a fair perspective. If the processor model is not very complex, the assembler for it should be able to pick up a fair amount of the slack, which can lead to Overengineering^TM or other such shenanigans. Having a goal in mind will let you add only features you really need to the assembler.
Also I strongly recommend implementing interrupts. Since it's a VM, its easy to put them in: just check for an interrupt in between Execute and Fetch (could even be as simple as True or False), and then check the usual places in memory for changes.
I'm trying to find a good reference implementation, or even a description, of the fundamental words -- `:`, `does&gt;`, etc. I've been pulling down lots of forths from github, etc., and still struggle to completely understand how this minimal core is put together. What's the best one to learn from?
The primary reason why I don't have interrupts as such at present is because I couldn't figure how, nor what they are meant to do exactly. At the moment at the beginning of each cycle I check all the memory locations that are assigned to devices and if a certain pattern exists I call that function. For example if memory address h0A is set set to 1 the network function gets called which then gets the data from address h09 and attempts to transmit it, if it fails it sets h0A to 4 I believe and I think at present it'll retry on the next cycle. On success it zero h0A instead. It's completely up to the program to check whether or not it succeeded, the CPU does not provide any interrupts to the program. It's one of a list of things that I'm trying to work out, if I'm not mistaken this was related to not knowing how to handle interrupts, which then led to the realisation that I don't actually know how to implement functions at all at which point I decided that since I'm implementing a Forth type interpreter and such things will be necessary for that anyway I'll postpone until I have a better clue.
Thanks for the link, 66 bytes for an interpreter is bloody insane. I'm currently workout through the TIL book mentioned above as I still need to work out some details but I'll definitely come back to this. :) 
That's... weird. Well, here's what I would do: while( Running ) { if (interrupt) push Instruction Pointer goto interrupt code or jump table else switch( memory[Instruction Pointer++] ) case "halt": running = false case "mov": copy data from register 1 to register 2 case ... end switch endwhile Interrupts are simply a check to see if there's any signals sent to the CPU externally (or internally if software interrupts are allowed). If there is a signal, the CPU records the current Instruction Pointer and goes to execute the interrupt code. When the interrupt code is done, a simple Return will reload the Instruction Pointer and start from where it left off.
The best way to learn about those is to try and implement them yourself: think about what colon or does&gt; do, in as small a step as possible. The neat thing is that you don't have to implement does&gt; if you don't like how it works (I didn't), or colon for that matter. Simple words like NewDef &lt;New Def Name&gt; &lt;Code Code Code&gt; EndDef might bring some clarity, as the notation for traditional Forth operations can be dense with meaning and scant on documentation.
Writing an assembler for x86 in any language can be an exercise in patience because of the immense tedium, but if you know what you want from your assembler, it can also be quite easy. Mostly this is because when you write assembler for Forth, you're not writing gigantic subroutines, but something that does one small thing and does it well.
If you chuck the code up on GitHub, then not only can we peruse it and glean some of the details, but you'll know it's safely backed up... which, as someone who lost their entire final year uni project to a bad disk controller in the days before the internet, I can assure you is a *very* good idea!
I'm afraid existing implementations may not be to learn from. You're welcome to look at mine: https://github.com/larsbrinkhoff/lbForth/blob/master/src/core.fth, but e.g. `:` and `DOES&gt;` do look somewhat cryptic.
You first need to understand how the Forth dictionary works. When you do `:` is quite easy to explain: get a token from the input source, start a new colon definition in the dictionary, and set the interpreter to compillation state. In a simplified version: : : parse-name header, docolon, ] ; `parse-name` reads a string which gets passed to `header,`, which does everything to append a new definition to the dictionary. `docolon,` adds a "code field" to the end of the header. Finally, `]` enters compilation mode. The phrase `: :` looks strange. How do you define `:` with `:`? That's what's called "metacompilation" and is what you get if you bootstrap a Forth in Forth.
Maybe you can find something useful here: https://github.com/larsbrinkhoff/nybbleForth
&gt; you'll probably want direct-threaded code if it's a simple system I'm not sure about that. Direct threading implies that you can write code at compile time, and that interleaving code and data is free; if that's the case, then unless your target is so basic that it takes a screenful of instructions to implement +, you're probably better off with subroutine threading (with optional macro expansion of short definitions). if your target *is* that basic, chances are the additional overhead of indirect threading will be a drop in the ocean - unless you're stuck with a 6502, in which case subroutine threading is probably the only truly practical option. On the other hand, if you can't (easily) write code at compile time - for example, your target has a Harvard architecture (separate code and data) and can't write its own code memory - then you pretty much *have* to use indirect threaded code. But if you can write into code memory on your Harvard machine, then subroutine threading is the way to go. And on more modern or complex machines - for example, recent ARM, MIPS or x86 processors: * the indirect jumps required by all threading methods will be forever mispredicted - in the worst case, they'll be predicted as returns, and therefore mispredicted 100% of the time; * naïve direct threading will have a deleterious effect on performance (lines will thrash between code and data caches) that can more than eliminate the advantage of not having an indirect threaded NEXT; and * because call/return pairs are predicted, subroutine threading will perform exceptionally well - with one caveat: &gt; for anything but colon definitions, subroutine threading and direct threading are basically the same thing; in the naïve model, both start with a call to a doTHING routine and are followed by data, which then takes the return address off the stack and uses the data it finds there. That'll cause the same address/data thrashing as any other word for direct threading, but for subroutine threading it'll also screw up the call/return stack cache, which will cause every return back out to be mispredicted.
That's a fair assessment; I completely didn't take into consideration those points. egency did, however, mention that it is a simple VM, so compiling the native code (just a few constant values) before starting a definition would probably be the least-complex way to tackle the issue. Then, of course, once he has an idea about how he wants to manipulate the VM using Forth, he could try his hand at more complex threading schemes.
One thing that has always bugged me about code threading is that if so many of these Forthers on the subreddit here care about speed so much, why not directly embed a pile of subroutine calls in the first place?
Some people (like me) just like the aesthetic of ITC, I guess; it's just a bit embarrassing when a single cycle instruction, or pair of instructions, ends up taking an inordinately long time because of the overhead of NEXT...
Who complained? I think it's well known that ITC isn't the fastest option. But it's simple, and may be fast enough. Also, if your implementation language is C/Rust/Go/JavaScript/etc, it may be the only practical choice.
Also, some targets are short on index registers. If you choose subroutine threading, you can reuse two hardware registers for the Forth VM: the instruction pointer and (hopefully) the return stack pointer. This is not an issue on contemporary workstation/server class machines, but it is on microcontrollers.
Yes, that thing is in your pocket is a workstation class machine. The times we live in.
[removed]
And with the aforementioned 6502.
Oh, I get that -- I've read through the Moving Forth series, and have been looking closely at [this reference](http://www.figuk.plus.com/build/heart.htm). I have a dictionary, and have written several stabs at the inner interpreter -- but when I realize afterwards that now I've painted myself into a corner, and can't figure out how to do `does&gt;` or something like that, it makes me want to see someone else's for reference. 
No, actually that's exactly what I'm looking for. Thanks for the link. I have made several working interpreters, but none that operate in the same way as a true Forth (they are false Forths?).
Right, `does&gt;` can become a challenge. If you implement Forth in assembly language, you can use the tricks mentioned in Moving Forth for `does&gt;`. If you use C or similar, you can't. I couldn't make `does&gt;` work in my Forth until I added one more word to the header. I understand Gforth does something similar. When `does&gt;` executes, it rewrites the code field of the latest defined word to a `dodoes` word. `dodoes` pushes the parameter field address like `dovar`, and also sets the Forth VM instruction pointer to the contents of that extra word.
Oh, hey, that's a very helpful comment. I'll mull on that -- thanks for the insight!
&gt; of the fundamental words -- :, does&gt;, etc. Mine is implemented this way https://github.com/zeroflag/punyforth/blob/master/generic/forth/core.forth#L90 `create:` is easy to understand. It just creates a new dictionary entry with an [enterdoes](https://github.com/zeroflag/punyforth/blob/29f9eeed2db2a5f8bf61e3072f6994dee506831e/arch/x86/primitives.S#L239) codeword. The enterdoes pushes the address of data field to the stack and jumps to the behaviour field. The dictionary entry looks like this: header|enterdoes|behaviorptr|data.. The behavior ptr is set by the `does&gt;` word. : does&gt; r&gt; lastword link&gt;body ! ; It's not that difficult to understand. r&gt; pops the return address which gives back the desired behavior, then the body of the last word (which was created by `create:`) will be overwritten by this. Usage: : constant: create: , does&gt; @ ;
There was some conversation not that long ago about the Lisp-ness of Forth, and some pointed out that SBCL and VFX have extremely close execution speeds. A few people lamented the speed that Forth offers, while others reminded them of the stylistic trade Forth makes that other languages simply lack. Even I find myself wanting a slightly faster execution speed in some parts, but that's what assembler is for, right? Also it is hard to shun the ability to store the entire kernel of a Forth VM (and a non-negligible portion of the dictionary) in the CPU's L1 cache.
I usually just use an array and a linked list to defer resizing until the seek time to the end of the linked list becomes close to the time to simply copy all the elements of both into a new larger array.
On the other hand, it's still quite a bit easier to implement than compiling native code with easily 1/2 to 1/4 the code density, and one hell of a lot easier to debug.
I guess you could have a hash table mapping keys to addresses of nodes in your tree? But this seems overcomplicated for whatever you might be trying to accomplish. 
You might be interested in [unrolled linked lists](https://en.wikipedia.org/wiki/Unrolled_linked_list)
Have you written an implementation of this and actually used it in anything, or is just another theoretical solution in search of a problem?
The example of riForth suggests otherwise. Robert Illyes came up with an 8086 Forth, modelled on (and originally metacompiled via) Pygmy, which used subroutine threading with inlining of short words (a bit in the header was used to indicate whether a word must always be inlined, as in &gt;R and R&gt;, or never be inlined, eg. anything which depended on a return address) and elimination of adjacent XCHG SP, BP pairs. It took up something like 12 screens of code, and I think the executable was about 5KB. I used to have a copy, but unfortunately the floppy it was on got corrupted; and with the demise of asterix.inescn.pt it seems to have entirely vanished from the Internet. But in answer to your points: * the most that subroutine threading will inflate code density is by the difference between an address and a jump instruction; on the 8086 that's 50%, on the 386 it's 25%, and on most RISC chips it's zero * progressing from subroutine threading to native code can actually decrease code density, by only inlining instruction sequences that are shorter than a jump (except for those sequences that must be inlined). For example, on x86, + can be implemented as add eax, [ecx+edi*4] inc edi where eax is the TOS cache, ecx is the start of the stack area and edi is the data stack pointer. Those two instructions total 4 bytes - shorter than `call forth_plus` would be. * as I previously mentioned, the expansion only covers code; variables, constants and DOES&gt; words only consume the same as they would have in direct threaded code * anyone who's experienced the exquisite delight of trying to follow threaded code in DEBUG or similar will appreciate that subroutine threading can actually be a hell of a lot easier to debug at low level!
I have not written an implementation for it. I wanted to check to see what other people thought of it before I implemented it.
Having done both ITC and STC compilers, I'd say subroutine threading isn't hard to do. ITC may be a just a tiny bit easier. I haven't looked closely at code density, but my feeling would be that 1/4 seems optimistic.
I've never thought of it that way before, but you're absolutely right. Given that I use EDI as a "stack frame pointer", I'm now having a lot of lightbulbs flash on about how I can violently optimize my code. Alas, violent optimization is a whole other huge project, and I'd like to just get simple USB reading done first (for keyboard+mouse support in Protected Mode, since the BIOS is Real Mode only).
User thamesynne completely shoots down my optimism in the comment sibling to yours. Still I will stand by my claim that just for getting the damn thing running in general, ITC is by far the simplest.
Ah, I was wondering what kind of structure I could use for a stack that could work with [Coroutines](https://en.wikipedia.org/wiki/Coroutine). Thanks!
**Coroutine** Coroutines are computer-program components that generalize subroutines for non-preemptive multitasking, by allowing multiple entry points for suspending and resuming execution at certain locations. Coroutines are well-suited for implementing familiar program components such as cooperative tasks, exceptions, event loops, iterators, infinite lists and pipes. According to Donald Knuth, Melvin Conway coined the term coroutine in 1958 when he applied it to construction of an assembly program. The first published explanation of the coroutine appeared later, in 1963. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/Forth/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.27
My favorite data structure is the fixed size array. Set aside a 1 kB or 1 MB buffer at startup, add items as necessary. It works especially well for data that you never free, like an interned string pool or a Forth dictionary. Its amazing how far you can get with a "small" (by modern hardware standards) buffer. Of course, if your specific application has other requirements, a different data structure may be necessary.
The OP doesn't have any applications yet; he seeks to find solutions apart from problems. See this thread from a recent post of his: [https://www.reddit.com/r/Forth/comments/746w5n/an_analysis_of_efficient_mathematics_in_forth/dnz19dl/](https://www.reddit.com/r/Forth/comments/746w5n/an_analysis_of_efficient_mathematics_in_forth/dnz19dl/) 
It's been noted that this isn't Forth related. As this is a trend I would like to ask /u/read_harder to keep this in mind when posting here in the future so as to avoid flooding our otherwise small group. If anyone has any thoughts or feelings on this subject I encourage you to leave a comment here, or PM me if you prefer (I may share any PMs on this subject with our other mods if this is necessary.)
It very much is forth related.
It has been pointed out by a few users, and I tend to concur, that nothing in the subject or introduction is specific to Forth. Your post has generated some fruitful discussions so I don't feel the need to remove it. I would ask that you carefully consider whether what you're posting is related to Forth in the future. That's only reasonable and respectful. Failing that, may I suggest that a personal blog might be a better place, and format, for recording all of your spurious thoughts on computer science?
Don't we know from previous experience that read_harder is only interested in Forth? I wonder whether the problem is really that it's not explicitly forth related, or that it's another case of read_harder preferring to dream and discourse rather than code. Would making the connection with Forth explicit actually address your real concern? (e.g. "From a forth perspective, what do you think?" or "I am thinking of writing a library for this in Forth)
&gt; Don't we know from previous experience that read_harder is only interested in Forth? I have no doubt that /u/read_harder has an interest in Forth. *My* concern, other than responding to reports that this post is 'not related to Forth' is that we're seeing a trend towards increasingly broad, speculative statements about fundamental computer science topics, which may better be more appropriate for /r/computerscience or other groups, but I suspect not. /u/read_harder has repeatedly shown no interest in listening to the counter arguments or suggests that his posts elicit, or engaging in productive discussion, begging the question of why he's is to share these thoughts. All that aside, provided that posts are related to Forth and it doesn't ruffle too many feathers e.g. posting such a large number of his thoughts that other content is effectively buried beneath them, then I have no real objections. I don't mind him dreaming but I do get the impression that I'm not the only one who's been somewhat annoyed by his snarky one-line response to detailed responses which amount to, " I don't agree". One of the reasons that I asked for comments was to get an idea of what others think about these posts :-).
Right, but it's not too much of a stretch to suppose that in read_harder's view, any question about algorithms is a question about Forth, because they aren't interested in anything else. This seems to be confirmed by their response. I agree people are showing annoyance, but I wonder whether the primary problem is the lack of relevance. I think the other things you mention are more likely to be the true source of irritation, no? read_harder is perfectly capable of posting lots of broad, speculative statements about Forth, and still display little interest in learning anything from the discussion, and ending the discussion with an "I don't agree". I don't read those replies as sarcastic, btw, but as an honest report on read_harder's state of mind. 'I don't agree' - and that's the end of the matter. (As far as why they're doing this, I suspect you've thought about it more than they have. ) 
Your `[` and `]` do the exact opposite of those in (traditional) Forth.
I decided to actually run some figures, to see how much the code size would actually inflate. Since the x86 is what I know best, that's what I targeted; I started with [Koopman's list of static instruction frequencies](https://users.ece.cmu.edu/~koopman/stack_computers/sec6_3.html), and coded them as tightly as I could for both 16- and 32-bit x86 code. The 16-bit experience was disappointing. I tried 4 different models, and came to the conclusion that the best - by a slim margin, and only because LIT is so dominant in static instruction counts - was to cache TOS in AX, to force DS and ES to be the same, and to keep the stack pointer in DI, allowing STOSW to be used as DUP. I also assumed that inlining 4 bytes was tolerable, but at 5 bytes we'd be better off with a 3-byte subroutine call. And the best I could do resulted in a 40% size inflation over ITC - which, in a situation where memory is rather tight, is not inconsiderable. Of course, this is without any attempt at optimisation except inlining up to 4 bytes. The 32-bit numbers were rather more promising. I only tried one model here: caching TOS in EAX and using [ECX+4*EDI], which allows updates to be simple INC or DEC EDI instructions, as the stack pointer. And once I'd coded the listed primitives, and allowed for inlines of 6-byte primitives rather than 4, I found that the extra space required over ITC was just 6.6%. Even allowing all the primitives to be inlined resulted in only 10% inflation. The conclusion is inescapable - subroutine threading on the x86 produces barely any code inflation... enough that it might be wiped out by the pointer to NEST in every colon definition. Of necessity those figures are peculiar to the x86; aside from anything else, it has a very compact bytecoded instruction set, and the increase from 4 to 6 bytes simply allows a disproportionate amount more to be done in the space of a call. I would expect, for example, a MIPS processor to do nowhere near as well, but an ARM processor to be competitive.
This perverse and all-consuming idea has become quite pervasive among those coming from other languages. Whether conscious of it or not these quotations allow them to write the same poorly factored and deeply nested programs that they're already writing... needless to say, I'm not a big fan :-).
...and a thousand Lisp programmers just rolled their eyes and said "my god, we ate the wrong children"...
They do. It is inspired by (read: blatantly taken from) [Factor](https://factorcode.org/). Its intended to read as a closure (function body) and groups together the different mode/syntax exception (like `if ... then`, `do ... loop` and even `: ... ;`). Things right after `some-command:` have an altered meaning and things between `[` and `]` have a particular meaning to be memorized. But everything else really is just a function call. Alternatively, `:` and `;` could have been used instead of `[` and `]` but square brackets look much more like parenthesis (and the semantics is a bit different from `:` and `;` anyways).
Why on Earth would you ever need closures in a hyper-static global environment?
Shhhh.h..h... what are you saying! You know very well that such a construction is simply impossible ;-) there's dynamic and static and to even suggest that there could be a middle ground which has the best properties of both is blasphemy! Blasphemer! &lt;/stupidity&gt;
&gt; hyper-static global environment? I'm not sure what this means but I think the answer is "to group together the different mode/syntax exception". I meant closures without the environment part, so its really just function bodies.
I rather like the combination of concatenative languages and the functional paradigm. I read Manfred Von Thun's papers on the Joy language with fascination. Having explicit language for anonymous computations is better than a lot of the stuff I've seen in forth world where people lookup and pass xts on the stack too accomplish the same purposes. 
&gt; The hyper-static environment does not allow a &gt; function definition to refer to variables that &gt; haven't been defined yet. Also, in the hyper- &gt; static environment, define always creates a new &gt; variable and is not the same as set!, but &gt; functions continue to refer to the variable that &gt; existed when they were defined. Thus, if you &gt; accidentally re-define a variable, you will only &gt; affect your view of the environment, not the &gt; views of functions that have already been defined. From: [http://wiki.c2.com/?HyperStaticGlobalEnvironment](http://wiki.c2.com/?HyperStaticGlobalEnvironment)
Yes, the intent was quite clear. I wonder, though, if it's fair to describe your blog series as a Forth tutorial. It seems more like a Forth-inspired language.
I enjoy this too but I don't call it Forth :-). From my perspective, there is as great a difference between Forth and Joy as there is between C and Python; or between Lisp and Python if you prefer. These languages may look similar but the way you approach solving problems in each is completely different. NOTE: I'm using Joy to refer to languages which combine concatenative programming with functional programming. &gt; Having explicit language for anonymous computations is better than a lot of the stuff I've seen in forth world where people lookup and pass xts on the stack to accomplish the same purposes. I can't speak to what other people do, but I just (re)use `_` and treat this short name as though it were anonymous. I don't pass xts around on the stack at runtime because I value my sanity; I hate juggling and if you start throwing code and data around *at runtime* then it becomes almost impossible to keep the stack manageable. I would argue that (especially combined with hyperstatic scope) this gives you all the succinctness of anonymous functions in other languages, and I consider the inability to nest definitions a feature; history has proven that if we can write a deeply nested function then we will.
Have you seen [Moving Forth](http://www.bradrodriguez.com/papers/moving1.htm)?
It was my impression that modern x86 machines have gotten quite good at predicting indirect branches like those in interpreters and VMs. Is this incorrect?
Yeah, I am slowly digesting it, as I go. 
Interesting. Thanks. I didn't know there was a name for how Forth handles function redefinition.
You're quite right, and it's a trend that's likely to continue (and spread to other processors, although I think it's only just arrived at the ARMs; certainly my RPi3 doesn't like threaded code at all!) because of the prevalence of object oriented languages - although what the "intelligent" branch predictors of the latest AMDs, for example, will make of threaded code is anyone's guess. (Maybe someone has one and can run some benchmarks?) The difference it makes (eg on the Core 2) is that it roughly square-roots the slowdown vs naive native code generation - eg going from 10x to about 3-4x.
But it misses the essence of a closure, which is the attachment of code to its environment. Forth provides DOES&gt; as an alternative to closures; the job it does - attaching code to data - is the same, but on a much more primitive level.
Chuck Moore evidently felt enough of a need to make DOES&gt;.
That's a good point. The intent of your original comment (or really, a good chunk of this entire comment section) was not clear. The syntax changes can almost be made by search and replace though. The internals are pretty standard as far as I can tell, having followed a good chunk of Jonesforth. (Because of this, I think the same steps could get a more traditional Forth working in assembly.) Since Forth advertises itself as having freedom of syntax (or at least vocabulary), I didn't think the core itself was fixed (just that lots of people happen to pick similar syntax). Now I see there's actually a Forth standard which includes some words. The whole series is intended for people who want something working quickly according to their needs and not (necessarily) interested in programming languages in general. That's why there's a paragraph talking about syntax differences but not much more.
Then a better word for your [ and ] would have been Lambda Function. But the way that those are typically used implies some form of garbage collection, unless you're actually just storing these lambdas on the stack itself, or as nameless definitions in the dictionary.
Then why didn't user asrpo use DOES&gt; instead of re-purposing [ and ] ?
You're literally asking the wrong person. ;-)
I'm just saying that it seems silly to insist on having Lambdas in a language like Forth when we have NONAME and DOES&gt; already doing those things for us, unless he's doing something radically different like compiling the lambda straight into the stack somehow.
100% correct. Excuse me.
When I made my claim I was primarily thinking of x86's Real Mode execution, which I had to do quite a lot of fiddling to get a functional Forth to fit on the MBR of a disk (436 byte allowance, yikes). Admittedly I as the programmer did need to do quite a bit of calculation overhead of my own (for example, I implemented unsigned &gt;= as the sole comparison operator), so that ended up being several experiments in code density optimization, and I just blindly carried that over to Protected Mode with some extra words for quality of life. Thanks for proving me wrong in the P-Mode case. So I guess the overall conclusion here is that ITC is simply not worth the optimization if speed is a concern even tangentially, and if code size is the only concern, you're better off writing a bytecode interpreter anyway that addresses very specific concerns.
Incidentally, would you put an upper limit on the size of a file that a text editor can handle? Or would you dynamically determine this somehow? (I agree that you're not likely to get an editor that can handle 1 TB files by accident, so you had better think about what your limits actually are) 
&gt; to get a functional Forth to fit on the MBR of a disk (436 byte allowance, yikes) That I'd be interested to see! Is it published anywhere? I don't know about bytecode. Certainly on some architectures, it makes sense; back at university (20-odd years ago now) my final year project involved implementing bytecode, and the dispatcher I came up with was lodsb mov ah,al and ax, $1FE0 ; could conceivably be replaced with a register jmp ax which required 32-byte alignment for bytecodes but was faster than just about anything else I could think of (including ITC!), and at 8 bytes was small enough to be inlined. Anything with an 8 bit data bus would certainly benefit from not having to do two word-length loads per primitive; and bytecode is almost always implementable with direct threading. But for wider buses, threaded code generates no additional loads, takes fewer instructions (2 for ITC on the MSP430 - and 1 for DTC), and neatly avoids alignment issues. Plus, you can have more than 256 primitives, which is a handy way of using up a pile of otherwise redundant Flash - and might actually give more compact code than bytecode at the end of it. It all depends on the processor, the application, and how much patience the implementer has with trying 57 different varieties before settling. ;-)
I use a few: - Retro (my personal dialect) - ATLAST (working on an expanded version of this for iOS) - gforth, vfxlin (for testing bits of ANS code) - 8th (for testing/learning purposes) In my case I wrote the current Retro to meet my specific desires and support my approaches to problem solving. It works very well for me, and (judging from sales/opt-in session statistics of the commercial version for iOS) a fair number of others. (I can't make any claims regarding the use of Retro apart from iOS as my server does not log requests, so I have no way of seeing how much traffic it gets). 
Your definition would appear to include, say, a Scheme that happens to expose two stacks, and the 'lack of rigid syntax' is met by Scheme's macro systems (if you don't accept that the nested list syntax is already a lack of rigid syntax — it's certainly less rigid than most languages). (Perhaps Scheme doesn't encourage small function definitions enough? But this requirement seems a little vague... ) I think this points to a couple of things that your account doesn't directly address that seem necessary. Firstly, the data stack has to be the normal (only?) way that parameters are passed around. Secondly, and I'm less sure about how to word this, but the lack of strict syntax has to be connected to the way words normally just act on the data stack as soon as they're encountered. A language that has a lack of strict syntax in some other way is a very different beast, IMO. Also, if one continues to add libraries and extensions to a Forth, eventually it won't be understandable by a single user any more. In your view is such a system no longer Forth, even if most programs in it are 80% ANS or something? If so, that seems rather strange to me. On a different note, I rather like to apply the mutually-intelligible criterion for different languages from linguistics. Can someone who can program in language X immediately understand language Y without difficulty, and write a program in it with only a little difficulty? Perhaps they need to consult a page or two about 'differences between Y and X', but not much more than that. If so, Y and X are the same language. If not, then they aren't. (Obviously there are huge grey areas here, just as there are in linguistics. ) Applying this criterion, I would be inclined to say that Retro (from what I have seen of it) is not the same language as ANS Forth, although obviously in the same language family (which might include Factor), on the basis that I can't immediately understand it and I have to guess at rather a lot. Scheme and Common Lisp seem significantly closer in mutual intelligibility. I realise this might be a different concern than yours, which seems to be more about the philosophy of Forth? 
Also: https://github.com/ForthHub/discussion/issues/2
I'm struggling with this. Sometimes it comes down to a vague feeling. Maybe it helps if you also consider things which should disqualify a language from being Forth.
To me, there's a historical or cultural element involved. Can a language trace a lineage back to Forth? Or was it developed in isolation, or a with conscious break away from traditional Forth values?
I found no use for Forth on the desktop at the moment. I use [Mecrisp Forth](http://mecrisp.sourceforge.net/) on microcontrollers. I think tinkering with your own Forth helps a lot in terms of understanding the system, but going from a toy-forth to a project-ready-forth takes some huge effort. 
I use my own. It's my personal toy, but I'm confident I could make it do serious work if needed. I believe the commersial implementations are good, and worthy of consideration if you're using Forth professionally. I think building your own may become a distraction from making an real appliction. But clearly, Forth is almost unique in providing this possibility. If your eyes is on the ball (end user benefit), having full control of every single bit in your software may be an advantage. I don't have personal experience with these, but my impression is they can be recommended: * Mecrisp * FlashForth * SP-Forth * VFX Forth 
One thing I've been curious about: do you (or anyone) use Retro to (let's put it this way) solve 'real world' problems? I don't necessarily mean commercial purposes, although that would definitely count. But something that addresses a problem outside of Retro itself, maybe for someone else apart from you. That's the difference to my mind between an intellectual exercise / hobby and a tool. Perhaps you've built a financial high volume data procesor app? :-) (Your god-server would count, except you mostly use it to talk about Retro... ) (Not that I have anything against intellectual exercises / hobbies, mind, in fact I'm all about them, and yours definitely has delivered significantly more value to more people than average... )
The mutually-intelligble criterion in linguistics isn't without problems. I think it breaks down when you study the problem closely. It's sometimes said a language is a dialect with an army and a navy, which goes to show the definition of a language is somewhat aribtrary and based on historical circumstances.
Moving Forth is talking about CamelForth, which has an x86 version: http://www.camelforth.com/page.php?7 Hope this helps! I know Moving Forth and CamelForth have been really helpful to me.
I think "exposes two stacks" can be stated in more detail: * Return addresses are put on a separate stack. * Data and temporary values are on the other stack. * The programmer controls every item on the data stack. * The programmer can push and pop things from the return stack, but not necessarily subroutine nesting information.
Did I mention there were huge grey areas? Mutual intelligibility doesn't exactly map on to the commonly-accepted languages, sure, for example I understand that Swedish and Danish are largely mutually intelligible, so 'should' be considered the same language. But is this really a problem? We don't expect 'folk' classifications of organisms to map phylogeny, and we don't think phylogeny 'breaks down' when it fails to recover folk classifications. 'Swedish and Danish are essentially the same language' seems to me to say something quite meaningful, as opposed to say problemetizing the whole notion of 'same language'. (And, I think, someone linguistically naïve could still have a pretty good idea of what is meant by this) 
Yes, you did. Sorry I didn't acknowledge that more clearly. Swedish and Danish may be a good example. I hear people in the south of Sweden understand Danish quite well. I live more near the middle of Sweden, and I don't understand Danish. I do understand people from the south of Norway, but not people from the north of Norway. Heck, I may not even understand people from the north of Sweden. So in that sense I don't see that Danish, Norwegian and Danish are either three separate languages, or one common language.
The control may be an advantage, but it also makes collaboration significantly harder, no? Can you load Retro libraries into lbforth? 
Right, that's a well known aspect of Forth. There's less emphasis on collaboration than in most other languages. Ideas are passed back and forth, but code less so.
I'm keeping tally of Forth use on GitHub. The vast majority of repositories are Forth implementations. Many of those are unfinished toys. Actual applications are scarse. I'm not saying this is necessarily a reflection of Forth use out there in the real world. Code published on GitHub is probably skewed.
This is in line with what I have been thinking. There are three implementations, but I don't think there's even a single application written in Forth in Debian. Or if there is, there's no trace of this fact.
Checked: in Ubuntu *nothing* depends on gforth, pforth, or yforth.
Just to prove they exist.
Great! And you posted this to GitHub, right? :-)
I also did an experiment, but it was whether to use a TOS register or not. My conclusion for 6502 and STM8, was that using a TOS register doesn't reduce the size of the primitives. This surprised me.
I barely even wrote it up in a notebook... ;-)
&gt; That I'd be interested to see! Is it published anywhere? Somewhere in my archived flashdrive images. I'll see if I can dig it up sometime soon.
Here's a bytecode interpreter I cooked up about a week ago, meant to replace all the crazy stack juggling I was doing at the time. The motivation was to replace the stack juggling with a function-local stack-based register group. Each byte would either designate a command, or a load/store operation on one of 64 stack registers. bits 16 %define JmpTblAddr 1234h ; Dummy address next: pushf ; save CPU Flags for calculations (16-bit value) .next: ; back to here to continue execution pop cx ; slow to store in a global value, and can't keep it on the stack movzx bx, byte[si] ; load the next command byte inc si ; and increment the "instruction pointer" shr bx, 1 ; then check bit 0 for command or register jnc .register ; if Carry not set, register .command: ; else, command shl bx, 1 ; scale to jump table entry size (2 bytes per entry) lea bx, [bx+JmpTblAddr] ; and use the jump table address as a base value mov bx, [bx] ; load the jump address from the index push cx ; restore the Flags popf ; too bad we can't "mov" the flags register easily jmp bx ; jump to the command .register: ; determined it was a register shr bx, 1 ; check bit 1 for load or store jnc .load ; if Carry not set, load data from a register .store: ; else, store data to register shl bx, 1 ; scale to register size (2 bytes per register) mov [di+bx], ax ; store to indexed register pop ax ; cache new TOS jmp short .next ; execute next command byte .load: ; load data from register shl bx, 1 ; scale to register size (2 bytes per register) push ax ; evict TOS to NOS mov ax, [di+bx] ; load new TOS jmp short .next ; execute next command byte
As far as I've been able to understand it Forth is not just a language, but also a philosophy, and they guide and inform each other: Forth, the language, is a concatenative language with three stacks. The first stack is the Data/Parameter/Calculation Stack, and is implicitly used in all functions. The second stack is the Return/Call Stack, and is implicitly used in calls/exits and flow control (among other book-keeping that is local to a function, optionally). The third stack is the Definition/Dictionary Stack, where globally accessible data is created and destroyed or hidden below and by a new data entry with the same name. Note that data in the Dictionary can be variables or functions. Forth, the philosophy, can be encapsulated in a few short statements, much like the language itself. Firstly, don't confuse a mediocre general solution with an excellent specific one; do one thing and do it well. Secondly, if a task feels Overengineered^TM or just doesn't work out in a smooth way, factor it out into more manageable sub-tasks; when in doubt, factor it out. Lastly, don't be afraid to try new things; part of the reason Forth is interactive in the first place is because Forth shuns the idea that the entire program has to be tested as a complete unit. At least to me the above paragraphs resonate, but part of what makes Forth so interesting is that everyone can and does have their own unique lessons they learn from it.
I know what you were saying and I completely agree with you but I guess I was feeling a little silly at that moment :-) thanks for clarifying your point and sorry for any confusion my joking caused.
Mainly I use my own Forth, an amorphous blob of myriad experimental features, which has the only real purpose of being a proving ground of implementations of various concepts, ranging from Garbage Collection (tracing, reference counted, mix of both) to OOP (nested classes, encapsulation, late and early binding) to Exception Handling, to dynamic re-definition of words. Implementing each of these concepts allows me to better understand how they work in other languages. I work mainly with C# and Dot Net, but I'll be damned if the bleed-over from working with Forth hasn't made one hell of a difference with my general programming intuition.
Not confusing at all, and I do appreciate the purposeful hyperbole :p I was (still am, tbh) simply mystified by someone who writes an article like this and yet seems to know less about the subject than should reasonably be required to do exactly such an activity.
Retro has a few data processing applications written it that are used by me and coworkers on a daily basis, though no one other than me ever sees the code or cares about my choice of language. Given that these were written for my company and are rather specific to dealing with the way we do business none of them are open source though.
I would put an upper limit on the size of a file that a text editor could handle if such a limit was obvious; I think this is much more preferable than trying to open a large log file with your editor of choice only to have it quickly consume all available memory and proceed to hang for 5 minutes every time you press a key while it figures out that it can't do what it was asked, because its authors didn't think about or define the limits of their program. Personally, I would use a 1 MB buffer[0] and push and pull "blocks" of data from disk as required and I wouldn't even attempt to load more than that. While this might make some features cumbersome it would allow you to do things like open and edit TB files. The big point here is that I wouldn't dynamically determine anything unless I had no other choice, and that's never come up in practice. This might sound ludicrous at first but there are plenty of examples of large and complex software which can't do dynamic allocation e.g. your 15 million SLOC OS kernel springs to mind but and basically anything mission critical e.g. systems monitoring nuclear power plants, in fighter jets, or anything in orbit; anything that's done in "real time" etc. As a rule, all of these things must forgo the fuzzy-wuzzy world of dynamic (unpredictable) resource allocation, but despite this, they achieve some truly amazing things. It's not so much that it's hard to do without dynamic resource allocation as that we're not taught how to do without it; we don't practice defining limits so can't imagine how we would do so :-). It's not unlike how those programmers who've only ever worked in high-level garbage-collected/managed languages are terrified of manual memory management and can't be convinced that anything can be done this way without massive memory leaks and the like[1]. The reality is that it's not that hard. [0] If I were doing this on Unix in writing in C I'd probably memory map the file but the idea is basically the same. [1] Often while writing programs, which despite having terribly advanced garbage collectors to take care of this, leak resources like an old bucket, because somehow, somewhere, there's a reference to all this stuff in that hairball that we call an object graph ;-).
The point is that what's does isn't particularly different. The syntax (only) change *is* the purpose. These anonymous functions are written to memory. There is no garbage collection (by the end of the tutorial). Memory usage doesn't blow up because they are only written once: at compile time (even the nested one, although that's done mostly by hand for the duration of the tutorial).
I *don't* have `NONAME`, `DOES&gt;`, `:`, `;` (or the traditional `[` and `]`) in this implementation. There's no plan to add them.
 * Flash Forth for Arduino * GForth for Linux / desktop Not particularly married to either one (and always like to try new ones), but they are the ones that work best on Arduino and Linux.
&gt; Your definition would appear to include, say, a Scheme that happens to &gt; expose two stacks, and the 'lack of rigid syntax' is met by Scheme's &gt; macro systems (if you don't accept that the nested list syntax is &gt; already a lack of rigid syntax — it's certainly less rigid than most &gt; languages). &gt; Firstly, the data stack has to be the normal (only?) way that parameters &gt; are passed around. &gt; Secondly, and I'm less sure about how to word this, but the lack of &gt; strict syntax has to be connected to the way words normally just act &gt; on the data stack as soon as they're encountered. Very good points; I'll update my definition to incorprate this.
&gt; Ideas are passed back and forth, but code less so. Which turns out to be a wonderful way of stopping the complexity from spreading from one solution to another. If an idea is too hard to pass by word of mouth and implement yourself in a reasonable amount of time then it's probably best avoided anyway since you're not going to bother understanding the code that you're importing anyway, and that should scare everyone. SIDENOTE: one of the great myths of open source software is that people are actually reading each others source code. It happens, for sure, but far less than anyone would like to believe.
Using my own as well, but for production work in .NET as well as more 'bare metal' stuff. Because of the crazy Xamarin compile times, I use my forth-like to live code features / GUI. It saved me a lot of time over the years. 
Thanks for sharing! As a beginner I would appreciate your opinion on the coding style.
Forgive me for intruding, but I would appreciate if you could point me to beginner friendly resources about Scheme exposing two stacks. Thanks and sorry.
I only recently started learning Forth using Gforth on Linux.
Forth can be written in many styles. I'm no expert, so I can't say whether this is a good or bad style. I will note that the style looks like procedures in many mainstream languages. The code is laid out vertically, with indentation to indicate structure. My own preference is for extremly short definitions. This is because it makes it easier to tell at a glance to if a definition is correct. In this style, it's very rare for a definition to exceed one line, and there's barely any need to indicate structure, because the code is trivial.
Thanks, that's what I noticed too. I've been reading a lot about Fort lately and that code didn't fit the idea of factoring I got from literature.
The last commercial Forth I used was HS/Forth on DOS. Since then I've rolled my own on different occasions according to my then current needs and preferences. I prefer to roll my own as it forces me to keep things simple, and saves me from ever having to fight or workaround my tools.
The reference was to "a Scheme that happens to expose two stacks". I don't think it was meant to say there literally is such a Scheme.
Ah ok, I thought it was related to continuations somehow. Thanks.
IMO, nnCron has a really bad coding style. Due to the licensing terms I can't delve into the source apart from some light skimming, but the code I looked over appears messy and in need of a good refactoring. (Words really shouldn't be 80+ lines long, even with some comments embedded in them).
write your own.
Yes, sorry, I meant that if such a Scheme did exist, it would meet _crc's definition of a Forth. This doesn't seem correct, and suggested that the definition could be improved. If you're interested in stacks, Scheme and continuations, though, you might want to look into Chicken Scheme's compliation strategy -- convert to continuation passing style, allocate everything on C's stack, and reset the stack on garbage collection. Peter Bex [describes it here](http://www.more-magic.net/posts/internals-gc.html). While it's supposed to be an introduction, I'm not sure I'd exactly call it beginner-friendly, sorry! 
You might enjoy it if you try implementing it, in a way that's compatible with your anonymous functions. Jonesforth goes out of his way to say he can't implement DOES&gt; in the way that he wrote the pieces of his VM (indicates to me that he wished he could), but is a fairly standard feature in Forth. You can think of a word written with DOES&gt; as a class. This class has one thing it does, New, and another function for the objects it produces with New. Some good sauce: https://www.complang.tuwien.ac.at/forth/gforth/Docs-html/CREATE_002e_002eDOES_003e-details.html
Ah, I see. But wait, what about run-time vs compile-time stuff?
If the criterion of success is end-user benefit, I'm unconvinced this is best served by everyone advancing their own idiolect. If I wanted a high volume financial data procesor app, surely I want to be approaching programmers who program in a language with an established user base? With libraries (hopefully mature, high-quality libraries) to e.g. interface with databases and provide cryptography. Not depend on you personally, and wait while you implement SSL. (Arguably this sort of thing is provided by the commercial forths) 
I wonder how reasonable it really is to expect people to only make use of software which they are intimately familiar with down to the source code? Aren't you relying on hundreds of thousands of lines of code that you personally haven't vetted to write this comment? 
Discussions on comp.lang.forth seem to indicate that there is quite a lot of Forth activity in the commercial world that isn't very visible. Ron Aaron has several commercial clients, presumably that means several applications written in 8th, and that's a relatively new venture. Longer-standing companies like Forth Inc. must have produced a lot more. However, it's really not hard to come away with the impression the language is a historical curiosity and a toy for hobbyists -- at best an intellectual exercise and a 'tool belt' for a few artisan-programmers. 
Good question. There's no `STATE` variable (and consequently some functions associated with them are removed). `write-loop` is a primitive like any other primitive (such as `+`) bound to the word `[`. `]` isn't a word (in that there's no function associated with it) but `write-loop` explicitly looks for it to stop and return (calling the sort of equivalent of `;` in Jonesforth before returning). So we're in "compile mode" after `write-loop` is called and before we return from it. Otherwise, we're in "run mode". (But we're really in run mode all the time.) `write-loop` calls `next-input` which gets the next word from input as a string (and pushes the address of the string on the data/parameters stack). So `write-loop` effectively consumes input. `push:` and `pushi:` are used for literals. There's no implicit interpretation of a word as a literal so `3` alone would give an error because there's no word `3`; I guess this also means you can name a function `3` if you really wanted to. Unfortunately, this means `write-loop` has to explicitly check for `push:` and `pushi:` inside `[ ... ]` too.
thanks for the link, but what i need is an article. right now i am reading this http://blog.asrpo.com/forth_tutorial_part_1 i found its much more understandable for people who was famillliar with modern language 
I suppose that's really no more complicated than anything else, except that if you want to do any OOP or exceptions, that's probably going to require re-writing a lot of code.
With the combination of your description and [this](http://www.forth.org/svfig/Len/definwds.htm), I think I have a vague idea of what `DOES&gt;`, well, does. I probably don't want that syntax through. Maybe the feature. Something like 20 array.new: foo 3 array.get: foo But since `array.new:` and `array.get:` are separate functions, there's no need for `DOES&gt;` since the function bodies can already be separated. I guess if I really wanted to write `3 foo` instead of `3 array.get: foo`, I could do [ push: push: names.get memory.append memory.len s11 memory.append ( compile-time body ) [ ( run-time body ) ] memory.append next-input names.set ] bind: array.new: The run-time body receives the location of where data is stored from the top of the parameter stack and has to do the right thing with it. But really, since there's no GC or (managed) allocation for anything other than functions in memory, a syntax for this would probably depend highly on how class instances are eventually stored in memory.
i treat it as a tiny abstract layer built on the host. no matter the host is assembly language or modern language like lua 
Ok nice.
That part is actually fairly obvious, it's what comes after that's more challenging. When an interrupt gets triggered it must jump to a /previously known/ location for starters. I'm not sure how to do that. Further, if another interrupt occurs while you are processing the first I wouldn't know what to do. Also, at present my instruction set contains no relative jumps at all, which makes all of this a hell of a lot more difficult. Figuring out how to implement interrupts are trivial, figuring out what to do with them so that they don't cause a huge mess is distressing to say the least. Until last week I know absolutely nothing about CPU's. Currently I have a decent grip on them and finding new details all the time. If I used an instruction set with relative jumps for example it would not necessarily have occurred to me that emulating a relative jump without one is surprisingly difficult which in turn makes position independent code a pain etc. Like I mentioned previously, I learn things as I find interesting things to do with them. Learning assembly isn't interesting, implementing a CPU and creating an assembler for it and using that to bootstrap a less annoying system, that's freaking amazing.
I would actually love to but my computer only has intermittent internet at best (with low data caps). And I know how painful losing that much work is, happened to me earlier this year, four different multi year projects in one go. Mostly I either remember everything or I write it down in my notebooks. I'll look into figuring out a way of getting it online, or at least a description of it though. :)
Just a minor point of contention, it's "she", not "he".
Thanks, I've started taking a sort of high level overview of the system and I like how you partitioned the machine dependent parts, the minimal functional system parts and the core language parts. It's a very clean separation which I'm going to try and emulate once I get some basics running. :)
I would go with pForth or gforth. I used gforth to experiment before diving into trying to create my own.
I thought [your recent usenet post](https://groups.google.com/d/msg/comp.lang.forth/2dwPmWLZ1oU/bJjZUxD1BQAJ) was a good example of this. 
I thought [your recent usenet post](https://groups.google.com/d/msg/comp.lang.forth/2dwPmWLZ1oU/bJjZUxD1BQAJ) was a good example of this. 
I thought [your recent usenet post](https://groups.google.com/d/msg/comp.lang.forth/2dwPmWLZ1oU/bJjZUxD1BQAJ) was a good example of this. 
I thought [your recent usenet post](https://groups.google.com/d/msg/comp.lang.forth/2dwPmWLZ1oU/bJjZUxD1BQAJ) was a good example of this. 
I thought [your recent usenet post](https://groups.google.com/d/msg/comp.lang.forth/2dwPmWLZ1oU/bJjZUxD1BQAJ) was a good example of this. 
I thought [your recent usenet post](https://groups.google.com/d/msg/comp.lang.forth/2dwPmWLZ1oU/bJjZUxD1BQAJ) was a good example of this. 
I thought [your recent usenet post](https://groups.google.com/d/msg/comp.lang.forth/2dwPmWLZ1oU/bJjZUxD1BQAJ) was a good example of this. 
I thought [your recent usenet post](https://groups.google.com/d/msg/comp.lang.forth/2dwPmWLZ1oU/bJjZUxD1BQAJ) was a good example of this. 
I thought [your recent usenet post](https://groups.google.com/d/msg/comp.lang.forth/2dwPmWLZ1oU/bJjZUxD1BQAJ) was a good example of this. 
I thought [your recent usenet post](https://groups.google.com/d/msg/comp.lang.forth/2dwPmWLZ1oU/bJjZUxD1BQAJ) was a good example of this. 
I thought [your recent usenet post](https://groups.google.com/d/msg/comp.lang.forth/2dwPmWLZ1oU/bJjZUxD1BQAJ) was a good example of this. 
I thought [your recent usenet post](https://groups.google.com/d/msg/comp.lang.forth/2dwPmWLZ1oU/bJjZUxD1BQAJ) was a good example of this. 
I thought [your recent usenet post](https://groups.google.com/d/msg/comp.lang.forth/2dwPmWLZ1oU/bJjZUxD1BQAJ) was a good example of this. 
I thought [your recent usenet post](https://groups.google.com/d/msg/comp.lang.forth/2dwPmWLZ1oU/bJjZUxD1BQAJ) was a good example of this. 
I thought [your recent usenet post](https://groups.google.com/d/msg/comp.lang.forth/2dwPmWLZ1oU/bJjZUxD1BQAJ) was a good example of this. 
I thought [your recent usenet post](https://groups.google.com/d/msg/comp.lang.forth/2dwPmWLZ1oU/bJjZUxD1BQAJ) was a good example of this. 
I thought [your recent usenet post](https://groups.google.com/d/msg/comp.lang.forth/2dwPmWLZ1oU/bJjZUxD1BQAJ) was a good example of this. 
I thought [your recent usenet post](https://groups.google.com/d/msg/comp.lang.forth/2dwPmWLZ1oU/bJjZUxD1BQAJ) was a good example of this. 
oops, seem to have reposted this several times - reddit seemed unresponsive and I ended up stabbing the 'add comment' button in frustration. All of those deleted comments said the same thing. If it's possible for someone to remove them entirely then please do so! 
If libraries are critical to your success you can always roll your own C-based Forth.
I just see one, so you should be good.
Oh, it's completely unreasonable... probably. Except that it can be done and there are real benefits to working this way, so if you can, why wouldn't you? As for relying on hundreds of thousands (read millions) of lines of code that I haven't personally vetted, you're right. But let's be honest. Nobody has or can read all of that code and/or have any coherent model of what's going on. That's why you get serious security flaws, and ruined lives, which have been known about for years but which were just get brushed under the rug or got patched and then left to rot for years, because figuring out what the hell is going on in a codebase like this is not only difficult but physically impossible. All of this will come crashing down. So at what point do you draw your line in the sand and declare that you won't be building any more houses here?
&gt; If the criterion of success is end-user benefit, I'm unconvinced this is best served by everyone advancing their own idiolect. Thalidomide was thought to have tremendous end-user benefits for a time and we know how that turned out. Not everything that we think benefits us is in our best interests
As has been pointed out elsewhere, a lot, this is *dreadful* advice, and advice that no other language would offer. Can you imagine if the standard response to "how do I start learning C?" was "write a C compiler"...? Forth's ease of implementation makes it seductive to go there first, but once you've implemented one Forth, all you really know is how to implement a Forth. Badly. It tells you nothing about how to actually write Forth, not least because bootstrapping a Forth system is a rather unusual programming task. If it's true that the most common use of Forth is to write a new Forth, that's a sad reflection on us as a community, frankly.
I'd generally say gforth, simply because it's the Forth-2012 reference implementation... and it runs on almost everything. However, if GUI programming on a Mac is important to you, then iMops looks like your best bet. Certainly the best value for money, anyway... I just downloaded the Mops manuals, and the first one looks like it's quite a nice tutorial, which is a recommendation all its own.
I'm glad to hear it's not unreadable jibberish to anyone but me. :-)
Probably worth noting that MOPS is not purely Forth, but a dialect that adds object oriented programming to Forth. It can be a little daunting for a complete newbie, but makes more sense to a programmer experienced in OOP.
My apologies. Considering that English lacks genderless pronouns, it was either he/she and him/her or they and their. Both are awkward to read, frankly, and I have no good alternatives within English itself. Curiously, where I'm from (California), we address each other with Dude, Bruh, and Guys/Dudes (when addressing a group). I'm inclined to think that those words are losing their masculine connotations, for whatever reason I cannot guess; I'm no anthropologist (yet).
There are a few things you can do with interrupts when an interrupt is raised. One, jump to a subroutine that handles it, or two, use a jump table. Both can be addressed by making the CPU look for these in a hardcoded location, or adding a register to the CPU that then can be used for those purposes. If this processor VM is your own creation, you may consider modifying the design to make things easier on yourself going forward. Further, simply disabling interrupts when one comes in is quite effective, as long as even more interrupts that come in during that time are placed on a queue. Then checking for interrupts is checking that a queue is empty or not. Since interrupt handlers are conceptually quickly-executing blocks of code, there's no worry about a bunch of interrupts piling up, maybe two at most. I'd suggest modifying the VM to have an interrupt signal queue, regardless of whether your interrupts might have a TRUE/FALSE signal or some more complex signaling mechanism. The x86 has a special command to return from interrupts, "iret", which means Interrupt RETurn. Quite simply, it returns from the interrupt subroutine and simultaneously re-enables interrupts too. One thing to note is that whatever is placed on the stack during the interrupt handling should be removed to reveal the return address; this can sometimes be hard to remember. As far as any further VM modification, I only have one suggestion apart from the above: make calls/jumps have the option of relative or absolute. Relative calls/jumps should simply add the next immediate value to the Instruction pointer. Remember, jumping to a previous location is as simple as adding a negative value to the IP register.
If you have any questions about processors, whether it be about how they work and certain features be implemented, or just any theoretical stuff that sticks to you, ask away. I'm more than happy to answer questions. Never forget, these sorts of things were something that had been worked on for decades by the best mathematicians in the world, before there was even a name for it as a proper field of study. Let yourself relax a little.
Well the fun thing about Forth is that whatever it is, you can make up that stuff yourself, for any reason, even if that reason is "because I thought it would be fun." If you find yourself motivated enough, like I did, you could even just go ahead and make an entire Class-Object feature set. I did that because I felt I could do something that sufficiently and flexibly generalized DOES&gt; and similar words.
No problem, slightly poor choice of wording as I mostly meant it as information rather than the implication I gave of offence. I agree that the lack of a proper neutral/unspecified pronoun in English is something I also find exceedingly annoying. They, while neutral is to my mind strongly plural and thus a poor fit. Guys tend to be used in a gender neutral manner where I'm from, but again only in plural. Dude is actually considered completely genderless interestingly enough. I find your phrasing "I have no good alternatives within English itself" interesting, does it imply that you speak a language other than English?
The idea of an interrupt queue is brilliant! :) And I've been toying with keeping a dedicated hardcoded memory area for interrupt code, but have been putting it off as at the time I hadn't even decided to have them in the first place, I'll have another look at it now though. I do have a few possible opcodes spare so I can add them. Yeah after toying with implementing relative jumps in "software" I did actually decide to add a relative jump. Won't require much change either as I have modifier bits on my opcodes and the ones for jump are currently unused. I've also been toying with adding one or two 16bit registers and limiting my memory to 64k odd for convenience. Thanks for the offer, I really appreciate it. :) At present I have a number of things that I need to poke at and a few things that still need polishing before I'd feel ready to look at adding more to my plate (like interrupts :P). I'll definitely ask you once I have new questions or oddities that I run into.
Only that I have knowledge in bits and pieces when it is necessary to know about them. Studying anthropology, and thus many different cultures, I find myself having a very broad but regretfully shallow grasp on major languages in use around the world. Related and interesting visuals on this page: https://en.wikipedia.org/wiki/Proto-Indo-European_language
I look forward to it. Do you mind me asking what encoding system you're using for your opcodes?
I don't understand what you mean? To answer my best guess of your question each "instruction" is three bytes and I'm shoving all my opcodes into a nibble of that and using the rest for things like register addressing/immediate values etc. Not elegant, but it does the job for now. I discovered somewhere between three and four wasted bits and decided I could use them to implement modifiers.
Would a variable-length encoding not have worked out as well?
Well, obviously if a drug went wrong once, the only appropriate response is to spend all your time writing your own language implementation! No reasonable person can argue with logic like that... 
Obviously you believe you derive more benefit from using other people's code than not doing so, so clearly you're not at that point yet. You say 'it can be done', but can it, really? Who has done it, and depends on only code they have crafted themselves? Or is even making significant progress towards doing so? Even Chuck Moore, AFAIK, restricted his activities to programming tools, and was prepared to use e.g. email and web programs written by others. No doubt it's technically possible, but I imagine practically no-one is prepared to do the work and accept the limitations of making such a commitment. I also wonder whether everyone following this advice would really result in better security. Perhaps you are a security expert, but I know I'm not (and Anton Ertl thinks the c.l.f folk are 'clueless' when it comes to security). I suppose it would be hard to find exploits that allow you to attack several installations at once, but it's really a form of security through obscurity, and you might not need such exploits if most people are doing the software equivalent of leaving the key under the mat. 
&gt; once 10,000 times, actually.
&gt; Well the fun thing about Forth is that whatever it is, you can make up that stuff yourself Yes, I'm definitely enjoying this freedom, especially for the core. Its surprising how well it works. For my use, I'll probably only need arrays and dictionaries. I don't know how much OOP I'll add in the end.
That's interesting, thanks. This sounds like a classic case of dialect continuum. There is an analogue in biology: a ring species, where there's a continuum of interbreeding, but some geographically isolated populations cannot interbreed directly with one another. However, neither phenomenon has meant that linguists or biologists have decided that mutual intelligibility, interbreeding, 'same language' or 'same species' are unworkable concepts that need to be consigned to the dustbin of history. To bring this back on topic, dialect continua are for the most part not a confounding factor with programming languages, as there aren't L_1, L_2, L_3... L_n where L_1 is much (but not entirely) like Java and L_n is much (but not entirely) like APL. So it's safe to say that Java and APL are entirely different language where knowing one does not enable you to read the other, without someone saying "aha, but if you know Java, then you practically know L_1, and..." However, with the proliferation of idiolectic Forths, this could become a reality! Someone needs to make an intermediate Forth between Retro and lbforth :-) 
Well, Lua has a similar deal with Tables (basically like our dictionary, but the association between data and label has been decoupled), and yet rolling your own OOP is simple. I'm sure whatever it is you end up doing, the experience will be better than you think.
Yes, and if one picks such an encoding carefully enough it may also significantly reduce the size of programs. However it adds additional complexity, which, apart from liking simple things, for the current experiment I deemed unnecessary. Also I have a bit of a thing for shorthands and language design, if I go do the variable length encoding road I'm guaranteed to spend the next month trying to work out the "perfect" variable length encoding and preferably the perfect one I could use for other projects too. :P
Yes, and if one picks such an encoding carefully enough it may also significantly reduce the size of programs. However it adds additional complexity, which, apart from liking simple things, for the current experiment I deemed unnecessary. Also I have a bit of a thing for shorthands and language design, if I go do the variable length encoding road I'm guaranteed to spend the next month trying to work out the "perfect" variable length encoding and preferably the perfect one I could use for other projects too. :P
Yes, and if one picks such an encoding carefully enough it may also significantly reduce the size of programs. However it adds additional complexity, which, apart from liking simple things, for the current experiment I deemed unnecessary. Also I have a bit of a thing for shorthands and language design, if I go do the variable length encoding road I'm guaranteed to spend the next month trying to work out the "perfect" variable length encoding and preferably the perfect one I could use for other projects too. :P
Yes, and if one picks such an encoding carefully enough it may also significantly reduce the size of programs. However it adds additional complexity, which, apart from liking simple things, for the current experiment I deemed unnecessary. Also I have a bit of a thing for shorthands and language design, if I go do the variable length encoding road I'm guaranteed to spend the next month trying to work out the "perfect" variable length encoding and preferably the perfect one I could use for other projects too. :P
Yes, and if one picks such an encoding carefully enough it may also significantly reduce the size of programs. However it adds additional complexity, which, apart from liking simple things, for the current experiment I deemed unnecessary. Also I have a bit of a thing for shorthands and language design, if I go do the variable length encoding road I'm guaranteed to spend the next month trying to work out the "perfect" variable length encoding and preferably the perfect one I could use for other projects too. :P
Yes, and if one picks such an encoding carefully enough it may also significantly reduce the size of programs. However it adds additional complexity, which, apart from liking simple things, for the current experiment I deemed unnecessary. Also I have a bit of a thing for shorthands and language design, if I go do the variable length encoding road I'm guaranteed to spend the next month trying to work out the "perfect" variable length encoding and preferably the perfect one I could use for other projects too. :P
Yes, and if one picks such an encoding carefully enough it may also significantly reduce the size of programs. However it adds additional complexity, which, apart from liking simple things, for the current experiment I deemed unnecessary. Also I have a bit of a thing for shorthands and language design, if I go do the variable length encoding road I'm guaranteed to spend the next month trying to work out the "perfect" variable length encoding and preferably the perfect one I could use for other projects too. :P
Yes, and if one picks such an encoding carefully enough it may also significantly reduce the size of programs. However it adds additional complexity, which, apart from liking simple things, for the current experiment I deemed unnecessary. Also I have a bit of a thing for shorthands and language design, if I go do the variable length encoding road I'm guaranteed to spend the next month trying to work out the "perfect" variable length encoding and preferably the perfect one I could use for other projects too. :P
Yes, and if one picks such an encoding carefully enough it may also significantly reduce the size of programs. However it adds additional complexity, which, apart from liking simple things, for the current experiment I deemed unnecessary. Also I have a bit of a thing for shorthands and language design, if I go do the variable length encoding road I'm guaranteed to spend the next month trying to work out the "perfect" variable length encoding and preferably the perfect one I could use for other projects too. :P
Yes, and if one picks such an encoding carefully enough it may also significantly reduce the size of programs. However it adds additional complexity, which, apart from liking simple things, for the current experiment I deemed unnecessary. Also I have a bit of a thing for shorthands and language design, if I go do the variable length encoding road I'm guaranteed to spend the next month trying to work out the "perfect" variable length encoding and preferably the perfect one I could use for other projects too. :P
Yes, and if one picks such an encoding carefully enough it may also significantly reduce the size of programs. However it adds additional complexity, which, apart from liking simple things, for the current experiment I deemed unnecessary. Also I have a bit of a thing for shorthands and language design, if I go do the variable length encoding road I'm guaranteed to spend the next month trying to work out the "perfect" variable length encoding and preferably the perfect one I could use for other projects too. :P
Yes, and if one picks such an encoding carefully enough it may also significantly reduce the size of programs. However it adds additional complexity, which, apart from liking simple things, for the current experiment I deemed unnecessary. Also I have a bit of a thing for shorthands and language design, if I go do the variable length encoding road I'm guaranteed to spend the next month trying to work out the "perfect" variable length encoding and preferably the perfect one I could use for other projects too. :P
Yes, and if one picks such an encoding carefully enough it may also significantly reduce the size of programs. However it adds additional complexity, which, apart from liking simple things, for the current experiment I deemed unnecessary. Also I have a bit of a thing for shorthands and language design, if I go do the variable length encoding road I'm guaranteed to spend the next month trying to work out the "perfect" variable length encoding and preferably the perfect one I could use for other projects too. :P
Yes, and if one picks such an encoding carefully enough it may also significantly reduce the size of programs. However it adds additional complexity, which, apart from liking simple things, for the current experiment I deemed unnecessary. Also I have a bit of a thing for shorthands and language design, if I go do the variable length encoding road I'm guaranteed to spend the next month trying to work out the "perfect" variable length encoding and preferably the perfect one I could use for other projects too. :P
Yes, and if one picks such an encoding carefully enough it may also significantly reduce the size of programs. However it adds additional complexity, which, apart from liking simple things, for the current experiment I deemed unnecessary. Also I have a bit of a thing for shorthands and language design, if I go do the variable length encoding road I'm guaranteed to spend the next month trying to work out the "perfect" variable length encoding and preferably the perfect one I could use for other projects too. :P
Yes, and if one picks such an encoding carefully enough it may also significantly reduce the size of programs. However it adds additional complexity, which, apart from liking simple things, for the current experiment I deemed unnecessary. Also I have a bit of a thing for shorthands and language design, if I go do the variable length encoding road I'm guaranteed to spend the next month trying to work out the "perfect" variable length encoding and preferably the perfect one I could use for other projects too. :P
Yes, and if one picks such an encoding carefully enough it may also significantly reduce the size of programs. However it adds additional complexity, which, apart from liking simple things, for the current experiment I deemed unnecessary. Also I have a bit of a thing for shorthands and language design, if I go do the variable length encoding road I'm guaranteed to spend the next month trying to work out the "perfect" variable length encoding and preferably the perfect one I could use for other projects too. :P
Yes, and if one picks such an encoding carefully enough it may also significantly reduce the size of programs. However it adds additional complexity, which, apart from liking simple things, for the current experiment I deemed unnecessary. Also I have a bit of a thing for shorthands and language design, if I go do the variable length encoding road I'm guaranteed to spend the next month trying to work out the "perfect" variable length encoding and preferably the perfect one I could use for other projects too. :P
Yes, and if one picks such an encoding carefully enough it may also significantly reduce the size of programs. However it adds additional complexity, which, apart from liking simple things, for the current experiment I deemed unnecessary. Also I have a bit of a thing for shorthands and language design, if I go do the variable length encoding road I'm guaranteed to spend the next month trying to work out the "perfect" variable length encoding and preferably the perfect one I could use for other projects too. :P
Yes, and if one picks such an encoding carefully enough it may also significantly reduce the size of programs. However it adds additional complexity, which, apart from liking simple things, for the current experiment I deemed unnecessary. Also I have a bit of a thing for shorthands and language design, if I go do the variable length encoding road I'm guaranteed to spend the next month trying to work out the "perfect" variable length encoding and preferably the perfect one I could use for other projects too. :P
Yes, and if one picks such an encoding carefully enough it may also significantly reduce the size of programs. However it adds additional complexity, which, apart from liking simple things, for the current experiment I deemed unnecessary. Also I have a bit of a thing for shorthands and language design, if I go do the variable length encoding road I'm guaranteed to spend the next month trying to work out the "perfect" variable length encoding and preferably the perfect one I could use for other projects too. :P
Yes, and if one picks such an encoding carefully enough it may also significantly reduce the size of programs. However it adds additional complexity, which, apart from liking simple things, for the current experiment I deemed unnecessary. Also I have a bit of a thing for shorthands and language design, if I go do the variable length encoding road I'm guaranteed to spend the next month trying to work out the "perfect" variable length encoding and preferably the perfect one I could use for other projects too. :P
Yes, and if one picks such an encoding carefully enough it may also significantly reduce the size of programs. However it adds additional complexity, which, apart from liking simple things, for the current experiment I deemed unnecessary. Also I have a bit of a thing for shorthands and language design, if I go do the variable length encoding road I'm guaranteed to spend the next month trying to work out the "perfect" variable length encoding and preferably the perfect one I could use for other projects too. :P
Yes, and if one picks such an encoding carefully enough it may also significantly reduce the size of programs. However it adds additional complexity, which, apart from liking simple things, for the current experiment I deemed unnecessary. Also I have a bit of a thing for shorthands and language design, if I go do the variable length encoding road I'm guaranteed to spend the next month trying to work out the "perfect" variable length encoding and preferably the perfect one I could use for other projects too. :P
Yes, and if one picks such an encoding carefully enough it may also significantly reduce the size of programs. However it adds additional complexity, which, apart from liking simple things, for the current experiment I deemed unnecessary. Also I have a bit of a thing for shorthands and language design, if I go do the variable length encoding road I'm guaranteed to spend the next month trying to work out the "perfect" variable length encoding and preferably the perfect one I could use for other projects too. :P
Yes, and if one picks such an encoding carefully enough it may also significantly reduce the size of programs. However it adds additional complexity, which, apart from liking simple things, for the current experiment I deemed unnecessary. Also I have a bit of a thing for shorthands and language design, if I go do the variable length encoding road I'm guaranteed to spend the next month trying to work out the "perfect" variable length encoding and preferably the perfect one I could use for other projects too. :P
Yes, and if one picks such an encoding carefully enough it may also significantly reduce the size of programs. However it adds additional complexity, which, apart from liking simple things, for the current experiment I deemed unnecessary. Also I have a bit of a thing for shorthands and language design, if I go do the variable length encoding road I'm guaranteed to spend the next month trying to work out the "perfect" variable length encoding and preferably the perfect one I could use for other projects too. :P
Yes, and if one picks such an encoding carefully enough it may also significantly reduce the size of programs. However it adds additional complexity, which, apart from liking simple things, for the current experiment I deemed unnecessary. Also I have a bit of a thing for shorthands and language design, if I go do the variable length encoding road I'm guaranteed to spend the next month trying to work out the "perfect" variable length encoding and preferably the perfect one I could use for other projects too. :P
Yes, and if one picks such an encoding carefully enough it may also significantly reduce the size of programs. However it adds additional complexity, which, apart from liking simple things, for the current experiment I deemed unnecessary. Also I have a bit of a thing for shorthands and language design, if I go do the variable length encoding road I'm guaranteed to spend the next month trying to work out the "perfect" variable length encoding and preferably the perfect one I could use for other projects too. :P
Yes, and if one picks such an encoding carefully enough it may also significantly reduce the size of programs. However it adds additional complexity, which, apart from liking simple things, for the current experiment I deemed unnecessary. Also I have a bit of a thing for shorthands and language design, if I go do the variable length encoding road I'm guaranteed to spend the next month trying to work out the "perfect" variable length encoding and preferably the perfect one I could use for other projects too. :P
I've been poking at languages and a few select cultures, mostly I picked up pieces of how the languages function rather than the languages themselves although I'm personally keen on Blackfoot and Finnish. I think the problem of where to start is universal. I've been working on a method for overcoming that but I still have a hole that I'm not certain how to fix. If you are keen on learning Chinese though Benny Lewis's book is pretty much where its at currently, maybe in conjunction to thesentences developed by Tim Ferris. I'm missing the context of the PIE Wikipedia page? I find though that anthropology has two problems, there are no longer any unpoluted data sets left. But more importantly, the fundamental reasons why people and cultures are the way they are gets obscured by the thousands of little unimportant differences between people. In my experience this makes it very difficult to get a sane result from stuffings culture.
I tend to fixate on the same sorts of things, as well, so I know exactly what you mean. Try not to get too attached, or you might end up needlessly frustrated. As always, I am open to questions.
Thanks, I'll reference those resources for Chinese. The PIE Wikipedia page was in the context of the languages I try and model. Although they all evolve and branch in such complex ways, they all have themes that they use to group concepts together, and this can indicate some abstract notion that seems to be at the basis of how humans think. I think studying culture can gain some very sane and transparent results, given that we have context for why certain cultures are the way they are. The evolution of a culture can and should inform how we approach our analysis of it, which I feel most consider very little in that aspect.
Well, it's not as if I was illustrating a point; obviously, I was being literal there :P. The point I was making is very simple: not everything that seems to benefit us in the moment is in our long-term interest. I'm sure you got that so I'm not sure what you're trying to say with this reply. If you can argue with my point then how about you do that, rather than implying that only an unreasonable or illogical person could think that. If I'm being unreasonable, or if I'm being illogical here, then you prove it. I'll thank you for it. Otherwise, I thank you for your opinion.
Obviously, there are limits to what one man can do and I cannot change the way that other people choose to act. I have to live and that means accepting that people are going to email me lovely things like links to word documents which I have to download from Javascript ladened web pages and to do that I need software that I can do that with. Now that doesn't mean that I have to add to the problem. When my company solves a problem we do so with as few dependencies on the world as possible. You'd be surprised how much you can do yourself and how few of these technologies are actually required to solve real problems. Our primary focus is on large scale data acquisition, storage, processing, and visualization. Our solution operates in a distributed, multi-platform/architecture environment. We explicitly eschew any platform specific details (not having much choice) so to as large a degree as possible we are living in our own little world. Since we don't rely on these details we can explicitly drop almost privileges; so even if an attacker were to break into our software -- overall simplicity and comprehensibility by a single person, and what you call "obscurity", helps a lot here -- they can't do much at all. The complexity that comes from interacting with the outside world is left to the outside world, which is forced to talk to provide all data in its simplest and most easily processed form and passing it to us through simple interfaces. tl;dr We may still have to send email etc. to operate a business and interact with other people but that doesn't mean we have to let that complexity permeate all of the solutions we create. That certainly doesn't mean that we have to import a million SLOCs of code that nobody fully understands just to move some data from here to there. Things are simple (secure, and efficient) until we, through our action/inaction, make them complex (bug-ridden, and resource hungry). If enough of us just *considered* these things when we're designing solutions then our world would suck far less IN MY OPINION ;-) 
I haven't used forth for any actually useful/released projects yet, just random tinkering, but so far I've used gforth and my own mostly-but-not-quite ANS forth implementation, which is written as a C-library (though with that library, a standalone forth interpreter can be easily implemented by putting just three simple lines of C inside an otherwise empty main function) for the purpose of easy integration between C and forth, whether that be embedding forth in C or using C libraries from forth. 
Well, I'm at a similar loss to tell where you were going with your reply. I expressed doubt about the benefit to the end user to everyone advancing their own idiolect, and you replied mentioning a famous example of a drug that went wrong. On the face of it, it is a non sequitur. I wasn't even appealing to 'what is thought to benefit us' (which sounds like you're addressing some kind of appeal to conventional wisdom?) or even to the opinion of experts (which is the more usual target for examples like thalidomide), but just expressing my own doubt about the matter. That common wisdom, or experts, or I myself can sometimes be wrong points out the obvious, and does nothing to address my doubt in this particular case, and nor does it offer support to the contention that spending large amounts of time working on one's idiolectic language implementation does much in the way of providing benefit to the end user. If your response to doubts about the benefit of a certain course of action is just "well, maybe your doubts are wrong!" then that's the end of the discussion, isn't it? That reply works equally well against whatever doubts or objections one might have. My doubts are therefore left unaddressed, and you're going to continue doing what you're doing and believing it has whatever benefits you believe it has, and both of us are left where we were at the beginning of the discussion, just perhaps a bit more frustrated than before. 
I'm not saying there aren't problems with the quality of software libraries one can find on the internet, and I don't have any real solutions. I also have nothing against the DIY mindset, in fact I think it's great, but whatever benefits it may have I do not thing the time spent DIYing everything does much to benefit the end-user, at least not directly. If my second cousin wants a data repository for her photos, the answer to that surely isn't "learn to program, write your own Forth, and implement your own!", or "wait until I've implemented my own Forth and I'll write one for you!" or even "get larsbrinkhoff to write one for you in his own Forth". In the face of poor-quality libraries, strategies such as the one you speak of make sense. But ultimately I think we're going to have to find ways of improving the quality of shared code, such as libraries. At some point, obviously, we have to trust some individuals other than ourselves (I don't have that much trust in myself, frankly). One thing to say about this is that community norms on the whole seem to be lacking. It's just too acceptable to ship lots of defects so long as you're also shipping lots of functionality. That's driven by the marketplace to a considerable extent -- end users and purse-string holders are willing to pay for features and suffer the defects (I'm not saying this is a rational and informed choice, but functionally this is what happens). But we are the experts, not them, so we're in the best position to draw attention to the dark side of modern software development and do something about it. The other thing that strikes me as a good idea is that there needs to be more effort spent on quality improvement. One thing you could do with your external dependencies, which you are prepared to understand and maintain, is to improve them or hold the upstream maintainers to account for any deficiencies. 
Right, it is somewhat surprising what an individual can do for themselves. I also agree broadly with the problems you see and the approaches you're suggesting, and that there needs to be a greater consciousness of the mess we've created and finding ways of at least not contributing further, if not actually proactively starting to clean it up. But there is a big gap between 'limit external dependencies, consider carefully the ones you admit, work with a small group of competent individuals, keep things as simple as possible' and 'design your own language and write everything yourself, in that'. And I'm not even against the latter, in fact, I have a pro-attitude towards it. I just don't think it, alone, is the answer to the pervasive problems we find with software today :-) As far as simplicity is concerned, obviously with software artefacts that interact with one another, at some point the system becomes too big to be comprehended by a single individual. So it seems to me that the best we can hope for is that systems are appropriately modular, where each module is simple enough to be understood by an individual, and they interact with one another through well-defined and well-understood interfaces (this is, after all, even how one piece of software becomes comprehensible to an individual). Every individual component being good doesn't guarantee the system doesn't behave pathologically, but it's a damn sight more probable than in a world of software components which are more often than not as ropey as hell. 
Would you mind if I ask one question about parsers instead of CPUs (my other half baked project)? I've been trying to implement a Pratt parser for a little regex engine I wrote but I haven't been able to get the thing to work for three months now, can't get a shunting yard algorithm to work either for that matter. At present I've got a prefix syntax with explicit concatenation that I reverse and then simply walk the string and emit the NFA as I go ("NFA" here means a bunch of lua tables that I link up). In that way everything sort of happens automatically, I've got a two element stack that I simply pop and push the latest table to and by the end I'm at the root node and simply return that. I can't seem to figure out how to do it with the Pratt parser though. The two points that I'm stuck on are "a(b)c", I can only get it past the open paren. And then "ab(cd|ef|gh)ij" where I can't figure out how to link the multiple tails to the next element. I think if I can figure those two cases out I can make the rest work. So far the only answers I've managed to get are along the lines of "use antlr"...
I used Retro(forth) in the past for agile development purposes
I've been working on this for a while. @larsbrinkhoff and @Manfred.Mahlow have been of great help! ![STM8S001J3](https://user-images.githubusercontent.com/5466977/31315372-d47069ae-ac17-11e7-815c-0fe855c34c20.jpg) Links: * [STM8 eForth GitHub repository](https://github.com/TG9541/stm8ef/) * [STM8EF Wiki](https://github.com/TG9541/stm8ef/wiki) * [e4thcom](https://wiki.forth-ev.de/doku.php/en:projects:e4thcom) * [SDCC &amp; uCsim Docker repo](https://hub.docker.com/r/tg9541/docker-sdcc/)
IAI tForth on a Canon Cat (not to be confused with tForth for the INMOS Transputer, or any of the other unrelated tForths out there). There's a [DOS version available](https://archive.org/details/tForth32), as well.
I beg to differ. I've learned many programming languages (some badly), I also wrote compilers (most of them badly), but it didn't happen often that I really learned something new. Writing a Forth is a good way to learn something new. Don't take me wrong, one might indeed get a job today because of outstanding Forth programming skills but most people will learn it to broaden their horizons.
https://github.com/tehologist/forthkit Under 500 lines for both inner and outer interpreter. Pure c with file handling, eforth dialect. Pretty simple, I have ran it on Arduino with only minor changes.
It's been a while since I've looked at stuff like this... Have you tried writing your own Regex engine? If you're doing this out of morbid curiosity, it just needs to work, not be fast, right? Since you're using Lua, an input string S and an index I. When you hit a nesting operator like (, just push I and then come back to it if there's no match when you get to ) or pop it and discard it if you do match. If you don't do the recursion right away, you'll have to try to shoe-horn it in later on. Parsing and the Shunting Yard, as it pertains to languages, are not suitable for Regex as far as I can tell. If you have Regex in your language's parsing, however, keep those components separated, and work on one problem at a time.
"As all Real Programmers know, the only useful data structure is the Array." http://web.mit.edu/humor/Computers/real.programmers
I would caution against the idea of the One Structure to Rule Them All. You have to take each problem on its own merits, and deal with the relevant system constraints as necessary.
It may be a good way to learn something new. I stand by my assertion that it isn't a good way to learn Forth.
At least he agrees with me on arrays.
I dunno I feel like solving all problems with arrays.
In my opinion Forth the fact that it's feasible to learn Forth by writing one is an asset, and not a bad thing, and I hold it for a fact that advanced Forth programming requires a deep understanding of the way a dictionary implementation works. I believe that the approach one should take depends on the learner, and also on the learning environment. Finally, I don't think that there is a wrong and a right answer, just as it not useful to engage in a Standard-Forth wrong-or-right discussion.
For me ans is the one true forth and gforth is a good way to get it on unix, albeit not the only way.
So, you create a data structure in an array (equals RAM) and you call it superior to data structures? Implementing tables with arrays works well if the length of data elements in the table doesn't change, doesn't need to be reordered, and the table isn't sparse. How about the statement "I found a good implementation for my problem using an array"?
Yes you can make structures out of arrays. You just shouldn't make structures out of non arrays.
&gt; the fact that it's feasible to learn Forth by writing one That's the very point on which we're in disagreement.
Your tl;dr is still pretty l. ;-) I'm reminded of what Tony Hoare said about software: you can make it so simple that there are obviously no mistakes, or you can make it so complicated that no mistakes are obvious...
Actually, thalidomide is still being used today, as a cancer treatment - just with big warnings that it's not to be prescribed if there's *any possibility at all* that the user might be pregnant. If we're sticking with this increasingly tenuous analogy, not everything that's dangerous in some situations is automatically useless in all situations.
https://youtu.be/gNsF8Q1Nh2Q?t=15m1s
&gt;[**Programming Conversations Lecture 3 part 2 [49:21]**](http://youtu.be/gNsF8Q1Nh2Q) &gt; [*^A9 ^Videos*](https://www.youtube.com/channel/UCYEYhkwzNWRsUkTCpTmChCg) ^in ^Education &gt;*^2,604 ^views ^since ^Mar ^2014* [^bot ^info](/r/youtubefactsbot/wiki/index)
No. I implemented hash tables using the hash-table implementation from sqlite. Big difference.
I think I explained it badly. I wrote an NFA based matching engine. That part was surprisingly easy after I pieced together some code from Rus Cox' site. During the development I used a hack syntax to build the NFA which was okay for initially figuring things out and I could call the engine by going "cat file| ./mynfa ',h,e,l,lo'" which worked but sucks. I'm trying to replace my hack syntax with something less annoying that actually works for all cases (the above cannot manage certain constructs). I you give me a day or two I could write up what I've done on pastebin which may help.
As noted in the discussion on the first part this should be thought of as a non-traditional Forth (maybe AnotherTutorialForth? ATForth?). Very similar steps *should* let you implement Jonesforth in assembly but I haven't tried it. Tell me about it here if you try that or something similar. Some Forth words are missing (some deliberately to reduce the size of the core). The entire list of words that will be available is in the Appendix at the end.
&gt; I dunno I feel like solving all problems with arrays. So you actually have a problem to solve now, or are you still just trying to write "solutions" without an actual goal?
Just to make sure that I understood that right: you state that one can not learn Forth by writing one. This must mean that all who claim to have learned Forth by writing one actually don't know Forth, and, I don't know, for my person that may well be the case. But does that also include Chuck Moore?
Sure. But I should once again suggest trying to do something on your own before attempting to follow others, then you'll be able to see more easily what they're doing differently and why. I'd like to see what you have so far, yes.
&gt; you state that one can not learn Forth by writing one Ah, I see what you did there. You baited with "feasible" in the hope of switching it to "sensible", and when I objected, you switched it to "possible" and claimed I'd disagreed with that instead. I'm not interested in taking (or leading) a debating class. If you came here for an argument, you'll have to pay me; my going rate for arguments is £100 an hour. Otherwise, I think this exchange has reached its natural conclusion.
Solutions for me. Always.
because that's the abstract model of memory?
It might be good to demonstrate, step-by-step, how one might translate an algorithm in C to one in Forth, via the Shunting Yard, and then show the stack contents line-by-line in the translated algorithm. Something like the quadratic formula, and then calculating the Nth Fibonacci number? Doing both would demonstrate what's actually going on with the stack, and why stack manipulator commands are so important. It's always good to point out that Infix is good for doing algebra and finding a solution for x, but Postfix is good for actually calculating what x actually is once a solution is found.
Having said all this, I do still find myself accessing the stack array-style when I need to get at a value that has a depth greater than 4 from the top.
I'll note that most languages are happily using prefix notation for functions and procedures beoynd simple built-in operators.
That's an interesting idea, thanks!
Yep. "parsing words" get people all confused... forget about 'immediate'.
The very wise Dr. Julian Noble, (RIP) created his own Formula translator to address the problem of porting Fortran to Forth and eliminating errors. There is not a good reason today for big Forth systems to not include a shunting-yard word, or include file, that does the translation from Infix to Postfix. There have been a number of versions created in the past that tried to be very "Forthy" (clever, small etc.) I believe a better approach is to translate strings at compile time to a new string that can be run with EVALUATE. (untested example follows) : EXAMPLE compute " (45-y)*(x+7)" evaluate ; immediate This kind of thing would be a text macro in the code that would compile to infix. Apologies for the word "compute" to those get queasy when thinking of COBOL. :) I happen to think it's a good use of the word here. In 8th this would be even easier to do I think. B
When you mention that some of the word names are not legal in Assembly language it occurs to me that making your output Forth Assembler rather than manufacturer's assembly language, would allow you more freedom. This is because you can add code to top of the file to "tweek" the Forth assembler to your needs, including but not limited to creating macros and even changing the names of instructions to suite your needs. Of course you would need to make the Cross assembler in Forth first... But hey I figured it out so it can't be too hard. Something to think about. Also if you are going to the effort of translating Forth to assembler you are creating a native code Forth compiler in Python! I'm just saying... 
Something more to think about :o
Oh, that's exactly what I did, sort of misspoke. I spent a lot of time on Rus Cox' pages to figure out how the thing is suppose to work and why my code isn't, also I never studied compsci so even apparently basic things I have to dig up, this is kind of my self made education. I made some progress since I mention this and some things appear to work now. Anyway I took the basic parsing algorithm from here: eli.thegreenplace.net/2010/01/02/top-down-operator-precedence-parsing The parser I coded (which is what has been giving me trouble) is here: pastebin.com/qaBA7NAt. The NFA engine it's for is here: pastebin.com/31h63z4i. My single biggest issue is that I cannot manage to make it work with juxtaposition operators. I finally (five minutes ago) managed to get it to build a directed graph in and output the list in a single pass. I still need to see whether I can do the rest as is presently it'll only do alternation and concatenation, I still need to add the star operator. And then I need to figure out how to mark capture regions which I'm still clueless about. But at least my parser halfway works.
And if you feel Bjarne Stroustrup has something to say on the matter, take a look at this one: https://www.youtube.com/watch?v=0avh39CI_ls And listen at 1:20 :-) 
Thanks for this! :) I'm starting to think I should find some to collect all of these. Incidentally, in the spirit of this thread I found another implementation called Itsy-Forth which can be found here: http://www.retroprogramming.com/2012/09/itsy-documenting-bit-twiddling-voodoo.html?m=0 It has more comments than code which is nice for a beginner like me and its a full interpreter in 1k.
http://chiselapp.com/user/tehologist/repository/compc/dir?ci=6a69773d2c9083fd&amp;name=compc/final/doc Here is a document in design from older version. 
Stepanov I respect *despite* his association with Stroustrup and C++. I'm happy to ignore anything Stroustrup has to say.
What is FORTH ============== Forth language that can be defined by a few very simple parsing rules. 1) Read word 2) Lookup word and compile or execute 3) No word found compile number or place number on stack 4) Not a number print error When defining a new word all words are compiled unless marked as immediate in dictionary. Immediate words are always executed and never compiled. Numbers are compiled as literals. When not compiling, all words are immediately executed and numbers are placed directly on the stack. This should be enough information to implement a forth compiler. I honestly feel the stack is an unimportant detail. Forth just happens to expose its stacks as it is fairly low level to begin with. You add your own layers of abstraction as needed. To implement a simple forth could just define : ; immediate , Then use , to compile directly into memory. The dictionary and interpreter could be hosted and wouldn’t actually have to use stacks. Though stacks would be far easier than hex compiling opposes with registers. The only issue is , cannot be an interpreter word as it would need to be compiled into immediate words in order to do anything useful.
Oh boy, I haven't really looked at any of this since I was starting out as a CS student. If you've looked at [Regular Expression Matching can be Simple and Fast](https://swtch.com/~rsc/regexp/regexp1.html) and don't understand it, that might be a sign that you should set aside some time to take a class for it. This is upper division CS. In any case, the page I linked in the above paragraph is really all you need in order to make a great Regex evaluator, and Lua is a good choice of language to implement it. You merely need to build an NFA (no parsing is strictly needed except for special cases, as explained in the linked page), convert it to a DFA and invoke the DFA on a string until it succeeds somewhere.
Thanks! I did look at writing an assembler at some point in this project (I'd be happy with an anything assembler, not just Forth). A quick search didn't yield the information I needed (ideally something structured like my tutorial with minimal runnable examples and explicit description of what the instructions encoded as bytes should look like). Just the ELF header already contains quite some stuff and I didn't come across recommended default (short of copying from the top of an existing binary). If you have some pointers, especially concise (but assuming I don't know much of the vocabulary), please do share. Ultimately, if assembled instructions are close to the intel (or at&amp;t or arm) assembly language (without labels, macros, etc), compiling to that assembly language or assembling directly is about the same to me. Although removing the dependency on an external assembler might be nice. I did consider having all macros handled externally at some point. I guess cross assembling might not be too bad with an emulator for the target architecture. Otherwise, testing seems like a real pain.
I have not fully grokked what you are doing, but you might have an easier time as a 1st generation by making your compiler generate actual Forth code as text. Then you could validate it with something like Gforth. You could also read it a little easier than ASM code. From there it might be easier to mov to equivalent Assembler code for each Forth word. Just a thought. When I look at your code called HEADER.ASM It seems like that is your runtime code no? It is unconventional from a Forth implementation perspective in that the code has no text labels that I can see at glance so it not a traditional Forth. Can you tell us what you want to accomplish as the final objective? Maybe that would allow the group here to provide some more suggestions on how to get there. Also check out YOURFORTH by Albert Van der Horst. https://bitbucket.org/avanderhorst/yourforth/src It is a complete forth in one ASM file. That should give you a clear indication of what Forth looks like when written in Assembler. 
No no, you misunderstand, I'm extremely well acquainted with that page (the "regular expression matching can be simple and fast" one), I likewise understand NFAs, and my regex matcher works a treat. That is not what I'm having difficulty with at all. There's two files on pastebin, the one is the NFA matcher, it works fine. The matcher require()'s the second file which is the parser. If you save the matcher as nfamatcher.lua and the parser as parser.lua you can call the whole mess in the following manner "cat sometime| ./nfamatcher.lua 'h,e,l,l,o'". At this point the matcher will make a call "cl[1] = parse( arg[1] )" this passes the string "h,e,l,l,o" to parser.lua which in turn parses it and passes a linked list representing the NFA back. nfamatcher.lua operates on this linked list. Now, a few things to note, my parser does not work without explicit concatenation operators (the "," in the above example) which is annoying. Further the I'm not sure whether the way I'm running the parser isn't going to bite me if I want to change it. It has other deficiencies as well like being unable to construct optional matches like "(a|)". To reiterate, the nfamatcher works like a charm, the parser that takes the user input and turns it into a linked list representation that the matcher uses is problematic. I'm actually considering preprocessing the string before parsing it.
I think I understand what /u/thamesynne means. I wrote my own Forth implementation many years ago. That did teach me about the inner workings of Forth, but it didn't make me a good Forth programmer. It wasn't until I started writing programs *in* Forth that my Forth programming skill improved.
&gt; I think I understand what /u/thamesynne means Indeed you do. Thanks!
&gt; Can you tell us what you want to accomplish as the final objective? So there are two things: - One is the **tutorial** posted here. - Another is the **ATForth interpreter** at the last step of this tutorial that I'm going to extend. # Tutorial The tutorial has written instructions along with snapshots of what the files would look like as I write the ATForth interpreter piece by piece. &gt; When I look at your code called HEADER.ASM It seems like that is your runtime code no? It is unconventional from a Forth implementation perspective in that the code has no text labels that I can see at glance so it not a traditional Forth. Indeed the snapshot at this point (snapshot #11) contains an essentially empty `header.asm`. See [this header of snapshot #14](https://github.com/asrp/forth_tutorial/blob/master/forth14/header.asm) or [this header of snapshot #18](https://github.com/asrp/forth_tutorial/blob/master/forth18/header.asm) for versions with functions filled in. To answer your question, in each of the snapshot, half the interpreter is in `header.asm` and the other half in `forth.f`. The two together make up `forth.asm` that can then be run. In later snapshots, running `forth.asm` lets you enter ATForth words on stdin. &gt; I have not fully grokked what you are doing, but you might have an easier time as a 1st generation by making your compiler generate actual Forth code as text. Then you could validate it with something like Gforth. You could also read it a little easier than ASM code. This is done in the first part of the tutorial (snapshots #1-#9) using Python instead of Gforth. This allows validating a custom language (instead of exactly traditional Forth) more easily. I should say here that when I wrote the tutorial, I was assuming familiarity with Python and lack of knowledge of Forth which is probably reversed for this subreddit. I'll add that snapshots #11 and #12 are the only snapshots that do not run as we are moving to actual assembly. &gt; From there it might be easier to mov to equivalent Assembler code for each Forth word. Just a thought. I'm not entirely sure what you mean but I think this is more or less what's does in `header.asm`. # Interpreter &gt; Also check out YOURFORTH by Albert Van der Horst. &gt; https://bitbucket.org/avanderhorst/yourforth/src &gt; It is a complete forth in one ASM file. That should give you a clear indication of what Forth looks like when written in Assembler. Thanks, this is interesting. But I thought in your first comment you were suggesting to write an assembler (which would remove the need for `nasm`) instead of an ASM file. Even if I do that for the ATForth interpreter, I don't think I would come back to edit the tutorial. On the other hand, I'd like to clarify some of what I'm doing with comments like yours. I see that fact that I'm making snapshot is not as obvious as I thought so I might add something to part 1. The interpreter's language is intended as a compilation target for a Python interpreter, so it'd be possible to write Python with inline ATForth instead of C with inline assembly. It'd still be possible to just write ATForth, of course. (And *that* Python interpreter is intended to be part of something else that's bigger.)
&gt; I think I understand what /u/thamesynne means Indeed you do. Thanks! &gt; That said, it could well be that some programmers write their own Forth and become adept Forth programmers as a result. I can't see it. Nobody can become an expert at any application domain after implementing one version of it once. (At the very least you need to do it three times to even be competent - the first time you work out what not to do, the second time you run into your limitations, and the third time you get it more or less right. Expertise in anything takes *a lot* of practice, and *a lot* of variety.)
I use ANS Forth, GForth or SP-Forth. If everything is toy or commercial, all my programming are "toys". But my own perspective is the old dream of Charles Moore: doing your own software. I extend Forth to do what I want it to do. https://forthmath.blogspot.se/ The next post on my blog will be about (finite) topological spaces, implemented by directed graphs.
I share this experience, and I'm not a good Forth programmer. However, I had given up learning Forth. Some people need to understand the inner workings of things before they can start using them, and I'm one of those (I'm a lateral thinker to the extreme). It's interesting to see that some people fight about the right way to learn Forth in a most evangelistic way even if the task is to get people try to learn Forth :-) The other thing is the personal experience: if it makes sense to do something new with Forth then in the field of embedded control. Portability most often isn't the issue - the real problem is writing an abstraction layer for the hardware, and getting the hardware supported by a tool chain in the first place. As side note: writing GUI programs in Forth sounds interesting, but then again, using operating system APIs in Forth that were designed for programmers that use layers over layers of abstractions is hardly a good proposition. I can imagine some very interesting uses for Forth, but those might require injecting a very lightweight Forth into a sandboxed environment...
He also pointed out that the postfix step was only to adhere to Thompson's paper, and mentioned that you could roll both parsing and NFA generation into one function. In any case, I'm not sure exactly what is wrong with your code. A glance over it shows all the pieces are in place. Again, it's been a while since I looked at any parsing code, and I'm not completely familiar with Pratt parsing at a mechanical level. If you have an academic interest in parsing, I encourage you to try writing your own for Regex before trying to implement someone else's parser. Multiple functions that each do one small transform on the data, in the desired order of precedence. This is easy to modify if you want to make changes later, and the choice of substring or nodes in a tree is strictly preference. ab(cd|ef|gh)ij (parenthesis of all substrings)-&gt; ab, subexpr(cd|ef|gh), ij (bar of all substrings)-&gt; ab, subexpr( or(cd, or(ef, gh) ) ), ij (other operators of all substrings)-&gt; ...
Ok I get it a little more now. I must say that when I looked at Tutorial 1, I got a better understanding. However there are some things about Forth that you missed that might be worth doing in your Python implementation. The outcome would be that when a Forth person sees your ATForth code it would look familiar. I am referring to the fact that the Forth REPL makes some simple assumptions. Numbers get pushed on the stack by default. We don't need Push:. So perhaps you should implement the classic Forth loop as the front end to your system. Just a thought. In pseudo-code it would be: SET INPUT SOURCE PARSE INPUT STREAM UPTO SPACE CHAR -&gt; WORD WHILE LEN(WORD)&lt;&gt;0 IF FIND(WORD)=TRUE IF STATE=TRUE or WORD IS IMMEDIATE EXECUTE(WORD) ELSE COMPILE(WORD) ENDIF ELSE IF WORD IS A NUMBER COMPILE LITERAL# ELSE ERROR: PRINT(WORD) ABORT ENDIF ENDIF CHECK_STACK_UNDERFLOW REPEAT 
It may be worth mentioning that Elizabeth Rather is very much of the same opinion. (Elizabeth Rather, for the uninitiated (this topic was intended for beginners, after all) , was an early convert to Forth, is a friend of Chuck Moore's, and a co-founder of Forth Inc.) 
OK, so I [posted a solution](https://rosettacode.org/wiki/Parsing/Shunting-yard_algorithm#8th) on RosettaCode for the "shunting-yard" algorithm. It could be improved (my version isn't reentrant, for instance).
Chuck Moore *used* Forth. For as much as he could. He always regarded himself as an applications programmer, at least until he decided to go and design chips; if you were to ask him, he'd likely point out that he learned Forth by using it, and that implementing it was merely a byproduct of that.
Or maybe not. At least one silent idiot seems to fervently believe otherwise. It's become cliché to mention the Dunning-Kruger effect, but sadly...
I'm not sure why this has received so many downvotes. I upvoted, if it means anything.
Can you provide an example of how to call this?
Yeah that's actually what I've been trying to do, read the regex string, as your reading it output the NFA directly. I already had a version that sortof worked with the postfix method. I looked over my code again last night and I think that you are right in that it works. I'm going to have to rip it apart to see what I did though. I think it has something to do with changing what I'm passing between the functions. In terms of doing my own thing rather than yanking code, I hear you, and I agree. Frankly a lot of the time I do exactly that (did it for the CPU emulator), I am in a bit of a bind for certain topics though. I never finished school nevermind university, never knew anybody in computers etc. So the majority of what is being talked about is out of my league. I basically end up reading up on terminology and ideas, yank the smallest piece of code I can find that's related to what I want to do. Modify it until it does what I want it to do, and then work backwards ripping it apart again to figure out why it works and then I can associate actual code with what the discussions talk about. The discussions, books, papers, etc have a tendency to assume a university education. I'll look into what you posted in the last paragraph as it seems interesting and useful, didn't occur to me before.
Complexity is what kills software. Structured programming, object-oriented programming, functional programming etc. These are attempts at managing that complexity. Forth is what kills complexity. It takes the form which best resolves the software's internal forces -- which minimizes the complexity -- which threaten to tare the solution apart. That is all Forth is, and that is why we see such wonderful variety of Forths. The degree to which something claiming to be Forth is Forth is a measure of how well it reduces complexity. In my opinion ;-)
You have to pass the function an object with a key of s as the second argument. And s has to contain a string of some forth script. The reason I do it that way is so that it works with the video game.
Your lack of education is definitely hurting you, but probably not in the way you think: You seem to have the aptitude and the drive, but you simply lack the knowledge of some key concepts, similar to someone trying to solve 3 = 1+x, but not having a concept of subtracting 1 from both sides. Guessing works eventually, but that's no way to go through life. BTW, knowledge of key concepts is the reason I posted that last paragraph simply as an example, practically as an afterthought. A series of transforms on strings and substrings is something encountered during an introduction to compilers. You should definitely try and find some comp sci classes at your local community college (cheap), or download some intro comp sci books (free). Try and download older textbooks; that's what I do when I find myself wanting knowledge. Older ones are just as valid as new ones; not much as really changed. Follow along with the exercises in each chapter. 
As always, feel free to follow up with questions. And don't feel discouraged by your lack of knowledge, simply because that is easily fixed by a small investment of time. I've met some people with BS's in comp sci that are real dummies, and that sort of aptitude can't just be fixed with a few classes or a book, so count yourself a lucky one.
I'm gonna write this up and post it on this subreddit later today, with pictures to illustrate the shunt, operator precedence, and other things. You're welcome to replicate it on the 8th site after I post it, if you wish.
I gave this a shot. A few observations: - I have to bind the function() to a name; I used `z`. - I tried: z(0,{'s': '1 2 +'}, 0, 0, 0, 0, 0); And get an error: Uncaught ReferenceError: x is not defined at z (&lt;anonymous&gt;:16:16) at &lt;anonymous&gt;:1:1 - At this point I looked over the source a bit; I don't see anywhere that `x` is defined, so I'm giving up. 
&gt; I have not tested this one yet I don't think this thing is close to running. I'm not sure if it was ever run. Here's an attempted deobfuscation. function(next, input_str, _input_list, _dict, _pop, fetch, _push, _word){ input_list = input_str.str.split(/\s/) dict = [] pop = x=&gt;x.pop() fetch=&gt;pop(dict) //Does nothing. Defines an unused lambda and don't bind it? push = x=&gt;dict.push(x) dict.a = x=&gt;push(pop(input_list)) dict.b = x=&gt;fetch()[fetch()]=fetch() dict.c = x=&gt;fetch()[fetch()] dict.d = x=&gt;push([next, input_str, input_list, dict]) while(dict.r!=0){ word = dict.a(); if (is_func(word)) { word() } else if (is_num(parseInt(word))) { push(parseInt(word)) } else { input_list = input_list.concat(dict[word])} } return dict.s } Function parameters starting with an underscore are unused by the function and overwritten by a local variable!
I never downvoted you, as I respect a honest debate. However, for my part I'm out of the debate. I'll continue implementing a Forth, implementing it in Forth where possible, and learn from the feedback of Forthers. Have a nice day :-) 
You working on any programming projects these days Petrus?
Nothing specific, but I'm currently reading Chuck Moore's book, *Programming a Problem Oriented Language.* I'd started reading it before, but didn't go that far into it. I'm surprised how much I can understand, but in most languages even doing relatively basic things like checking if each character is a space is beyond me. I'd know how to do that in shell script, yes; but not in something like C or Java.
I guess the take away from this is that you can write a Forth with as few characters as you like if you don't require it to, you know... work...
It would be really great if you could at least try to run the code before you declare this as anything. Judging by the state of your code it looks like you spent all of 5 minutes thinking about this.
Forward references for undefined words sounds like a recipe for recklessness. Even in a standard, barebones Forth it would be easy to do. The reason it isn't encountered is because it is dangerous. What if you decide to redefine or delete the definition? With definitions as Objects that's less of a concern, but that's hell of a lot of overhead for a single feature practically no one asked for.
I certainly won't claim this as a good idea, but it was listed as a feature by the developer, so I mention it here.
Very cool. But is there a version of this that isn't minified? Both the Javascript and Perl versions are pretty unreadable. I might as well read a hexdump instead of the 12 lines Perl version. How far can you get with this? What's an example of a loop?
Loops are done via recursion: : a dup (.) -1 + dup 0 &gt;if( a ) drop ; 10 a I haven't used this for anything apart from occasional playing around; I preserve it for historical reasons mostly, but it came to mind after /u/read_harder recent post with a broken javascript "forth".
This pseudocode would have been *really* useful at the beginning of this project. &gt; Ok I get it a little more now. I must say that when I looked at Tutorial 1, I got a better understanding. Thanks for taking a look! [Here's a brief discussion about push: and other syntax](https://www.reddit.com/r/Forth/comments/75l86m/another_tutorial_for_writing_a_forth_interpreter/doal5j8/) &gt; However there are some things about Forth that you missed that might be worth doing in your Python implementation. I'm not sure how you'd mix the two though. Translating from one to the other is fairly simple but there's overlapping syntax and the difference in `STATE` variable mentioned above. So you can't quite just define one in the other. Maybe some kind of translation table like - `[ a b c ] bind: d` - `: d a b c ;` - `[ a b c ] if` - `IF a b c THEN` - `[ a b c ] call repeat` - `DO a b c LOOP` - `push: 3` - `3` - `s11` - `dup` - `s21` - `swap` Maybe some of the translation can even be automated.
Oh I see : a 1 ; : b a ; : a 2 ; b (.) gives `2` (instead of `1`) so it looks like *all* function calls use late binding.
I haven't run it yet I'm still building it. I've only run each of the pieces in testing. Also check my latest version which I will post shortly after this reply.
Actually a few months I'm afraid.
So this isn't a forth you'd probably want to use because it was made for a specific application. It's not a general purpose forth.
Not really broken just not finished.
function(context, args, terms, dictionary, pop, stack_pop, stack_push,){ terms = args.script.split(/\s/) dictionary = [] pop = x=&gt;x.pop() stack_pop=x=&gt;pop(dictionary) stack_push= x=&gt;dictionary.push(x) dictionary["next-word"] = x=&gt;dictionary.push(pop(terms)) dictionary["!"] = x=&gt;stack_pop()()[stack_pop()]=stack_pop() dictionary["@"] = x=&gt;stack_pop()[stack_pop()] dictionary["state-pointers"] = x=&gt;stack_push([context, args, terms, dictoinary]) while(dictionary.r!=0){ word = dictionary["next-word"](); if (is_func(word)) { word() } else if (is_num(parseInt(word))) { push(parseInt(word)) } else { input_list = input_list.concat(dictionary[word])} } return dictionary.s } 
also keep in mind my code uses the function is_func which is specific to the game hackmud.
[removed]
Given that it's not complete and requires a non-standard environment as part of a closed source game I have no interest in I'll disregard it for now. 
Ah well, you have to start somewhere, and I have to admire your persistence :-)
&gt; I'm not sure how you'd mix the two though That's why we have things called version 2.0 :-) If it's too hard to co-mingle the ideas, then it's not worth the trouble. You created your own stack language. Fini. That's all good. If you have the interest in the future you could you try it a different way. I have always thought that Python would benefit from having a callable Fast Forth system for improving performance without the need to drop into C. something like: &gt; FORTH(" : STAR 42 EMIT ; ") &gt; FORTH(" : STARS 0 ?DO STAR LOOP ; : ) &gt;FORTH( " 100 STARS") Meaning you could compile new definitions into the Callable Forth and call them as single Forth call with input parameters taken from Python. Depending on the Forth implementation speed up would be 10 to 20 times in my estimation and it would still be interactive.
Sometimes this means that you could factor things differently and remove that need to use the stack as an array. Of course not always. There are some big computations that need a lot of variables and so using locals is probably better in those cases.
Yeah that paragraph helped a ton thanks. :) Eh, I'm painfully aware of the manner in which my.lack of education is hurting me unfortunately, I encounter it frequently. And I have actually met those dummies you speak of in the few jobs I managed to land. That's actually a large part of what motivates a lot of my projects. Taking this parser as an example, while writing it to parse regexes is what I'm doing, the reason for taking the approach I am is because I want to experiment with coding languages (hence my interest in Forth as well), and the NFA matcher is for a future text editor (working with graphs being a decided bonus). So I tend to try and pick projects that sit in an overlap between interest, current capabilities and future plans. While community colleges aren't possible (they don't exist in this country) I am slowly making my way through HTDP and SICP (also Wirth's books as I'm a fan). HTDP being held up by internet issues at present though. So I have at least found good resources to fill the gaps with. :) Just need some time. Thanks, I definitely will do. :) Between your comments and some ideas I'm trying (painting myself into a corner really) I've got a lot of bugs and no good questions for the moment.
LOL. I kinda hate C++ too. Any language that can compile almost set of ascii characters... :-)
It's particularly poor advice when someone is asking for advice for beginners. I suppose it's possible that someone who describes themselves as 'a beginner' might be a very competent and widely experienced programmer who just happens to be a beginner at forth. But they're more likely to be either a beginner at programming, too, or at least someone horns are a bit more green, so to speak. If you are just learning the ropes, or your experience has almost exclusively been in, say, web-application or database programming, then implementing even a simple language is likely to be a foreign and non-trivial task. 
Juggling two strings (with indexes pointing inside of them) will take up 6 items on the stack without doing constant loads to check the string boundary. Doing everything through the stack is just not possible with some programs, much to my extreme displeasure.
 ( You can use the loop index. There's no need for recursion here. ) : factorial ( n -- n! ) dup 1 ?do i * loop ; ( 5! = 120 ) 5 factorial . 120 
This might be worth posting to the gforth mailing list. [https://lists.gnu.org/mailman/listinfo/gforth](https://lists.gnu.org/mailman/listinfo/gforth)
This looks correct to me. The stack should be: 3 2 after the recursive call. Just to be sure, I copied your code, put a .S CR at the beginning (prints the stack and a newline), and that's what it showed me, too. Perhaps you're reading the stack backwards? The top of the stack is the rightmost item. 
I'm running into this problem with other things, I just grabbed the factorial off the internet for demonstration purposes. 
Thanks. 
 3 FACTORIAL ok .s &lt;1&gt; 6 ok When I try calling FACTORIAL without debugging the only thing in the stack afterwards is 6, which is what I want. The only time I see 3 2 in the stack is when debugging. 
Sorry, I finally think I understand what you're saying here -- you're expecting a 6 at the top of the stack after the invocation of *, right? You're right, that is weird. It's like the debugger jumps tracks and starts following the recursive call instead, because it does the multplication and produces 6 on the stack after it supposedly executes ;. A mutually recursive version works as we would expect: : FACTORIAL1 DUP 2 &lt; IF DROP 1 EXIT THEN DUP 1- FACTORIAL2 * ; :noname DUP 2 &lt; IF DROP 1 EXIT THEN DUP 1- FACTORIAL1 * ; is factorial2 yields: 3 dbg factorial1 : FACTORIAL1 Scanning code... Nesting debugger ready! [ 1 ] 00003 7F83D670A0 7F83C87F68 dup -&gt; u [ 2 ] 00003 00003 7F83D670A8 7F83C86B58 2 -&gt; [ 3 ] 00003 00003 00002 7F83D670B8 7F83C87698 &lt; -&gt; [ 2 ] 00003 00000 7F83D670C0 7F83C86378 IF -&gt; [ 1 ] 00003 7F83D670F0 7F83C87F68 THEN dup -&gt; [ 2 ] 00003 00003 7F83D670F8 7F83C86CA8 1- -&gt; [ 2 ] 00003 00002 7F83D67100 7F83C86240 factorial2 -&gt; [ 2 ] 00003 00002 7F83D67110 7F83C86D68 * -&gt; [ 1 ] 00006 7F83D67118 7F83C861D8 ; -&gt; ok At this point, I also think the gforth mailing list is the place for it -- it looks like a bug :-) (My apologies for being slow on the uptake: I thought your confusion was over the order of the 3 and the 2 on the stack... ) 
Very minor nitpick, but is your mutual-recursion code example missing a `DEFER FACTORIAL2`?
Er, yes, I clearly didn't copy and paste enough of my buffer -- thanks for the correction! :-) That's interesting. I suppose in hindsight this seems like an obvious test to make, but I was tired and there was some crappy TV that needed watching... The funny thing is that I've used dbg on mutually recursive code just recently, and never noticed this behaviour -- I suppose I have just never quite run into it, I suppose I must have always just had the problem manifest itself before recursing back to the original routine. It occurs to me that mutual recursion may have been hiding the problem from me. It also seems to not like nesting in to recursive calls... 
Ah yes. The 2 item stack string. I have never been a big fan of these for string processing except for cutting up strings. When I started with Forth it used Pascal style counted strings and I never had any complaints. My latest iteration of a string library only uses stack string (caddr,len) internally because they are efficient. To the user of the library strings are 1 address on the stack. It helps eliminate the juggling act. You can see it here. https://github.com/bfox9900/CAMEL99/blob/master/lib/STRINGS.FTH The first part will compile on a standard system I believe, but CAMEL Forth uses a word S= which is not standard and should be replaced with COMPARE and that means some stack changes. S= takes only 3 parameters. However you can see how the concept works from the code. It's not the fastest in the world, but it works more less as expected allowing you to concatenate string functions without worrying about intermediate results. The stack is COLLAPSE'd after you print or store a string in. This version has the words PUT and PRINT in an attempt to provide some training wheels for BASIC programers trying out Forth. I created this code in 1987 originally to give string functions like I had in BASIC and then kept refining it. :-)
Just a quick check: are you sure you're using the debugger only with gforth-itc? Gforth-fast won't give useful results with the debugger.
Yes, I haven't touched gforth-fast yet and gforth won't let you debug at all. 
I strongly suspect that you posted this without reading the other comments first... ;-)
The 2-item strings are a necessary evil, unless I want to copy strings back and forth more often than I'm comfortable with doing, and even then I'd still end up with at least one 2-item string. I use something similar to C's stack frame when I'm managing things like this, because it's much easier to index into a static address on the stack than the ever-mobile stack pointer.
Mea culpa.
&gt; Infix, while complicated with an order of operations, allows us to do algebra with very little effort of making sense of what it is we see. &gt; However, postfix has a distinct advantage in automating calculation: specifically because it is left-to-right, a computer program merely needs to work from one end to the other And prefix combines these advantages. It is easy to read even complicated expressions in prefix-notation because there is a natural way to indent them: + a * b c Evaluation is also from one end to the other.
Yeah! Those were my thoughts too. Forth's handling of variables (or values on the stack) matches Python's duck typing much better. Since Python already uses some bytecode that runs on a stack machine, why not just make it a concatenative language. Plus the possibility of easy dynamic compilation of Forth functions. I'm glad to hear you would want something like this too.
In 8th we use namespaces to: * add semantic value (e.g. "a:+" concatenates two arrays, while "s:+" does the same for strings and "n:+" adds two numbers) * mostly eliminate word-name collisions The only downside of how 8th implements namespaces is that it leads people to sometimes mistakenly think that 8th is OO. My personal preference is to use word names which are just as long as needed for me to know what they should do. I could have had "string_append", but "s:+" is sufficiently obvious (to me, anyway). 8th doesn't have local namespaces, but you can create any number of them as easily as "ns: cool-new-namespace". Of course then you would have to say "cool-new-namespace:my-excellent-word", which borders on the unusable...
 "Forth has no compiler!" I like where you are going but a point of order: : TEST 2 2 + ; ok ok SEE TEST 3B49F 4 # EBP SUB 83ED04 3B4A2 EBX 0 [EBP] MOV 895D00 3B4A5 4 # EBX MOV BB04000000 3B4AA RET C3 ok \ copied from the Swiftforth console. Forth has many forms of compilers. Indirect threaded, direct threaded, sub-routine threaded, byte-code compilers and native code compilers. Take your pick. And to be complete; technically neither C nor Forth are consistently infix or postfix. Like human languages they are a little jumbled. C functions are prefix notation while math operators are infix. Forth math operators are postfix but dictionary label creation are prefix. (Perhaps you meant to say Forth has no infix parser?)
&gt; Short names are hard to memorize for me and cause collisions easily Surely short names should be easier to memorise? Besides, there's a certain joy to finding the right short name. When you find it, it just trips off your fingers and looks like it was always supposed to be called that. In any case, most of your names are short; they're just puffed up by the need to use namespace qualifications. You might want to think of a better term than `index-in-range`, though; I'd go with "bounded?" for a test, or "bounded!" for an assertion... in any language except Forth, which uses ! to indicate a store. Or you could think about synonyms for making sure something stays within bounds - perhaps "confine"? &gt; Maybe I just need a syntax highlighter? It would certainly help you to find the names of your definitions and the nature of your code blocks (conditionals? loops?), which are vanishing into the noise at the moment. But I think what you've demonstrated is the fundamental weakness of using combinatorial syntax for everything. You could improve this, without disrupting the essential character of your language. For example, use `def: X` to define a symbol X, and leave a reference to it on the stack that `bind.` can bind to; define `if` as a null word, and use `then` for what `if` is doing now (which gives you the ability to use `else` for a two-pronged conditional, too). Remember, semantics are all the computer should care about - syntax is for the human. &gt; Or is there a nice way to get (local?) namespaces? This is what vocabularies are for in Forth. Perhaps you should consider incorporating something similar, and using the . in your words as a means of overriding the default vocabularies? You could even have some way of renaming words in different vocabularies, so that you can reuse the verbs you want with joyous abandon (perhaps `rename: m.x y`?).
I'd suggest an indentation scheme rather than colour-based syntax highlighting. But do look at Colorforth as an example of an innovative language in which the colour of a source word carries semantic weight. Somebody else suggested vocabularies. For the modular approach I frequently adopt, this is a very flexible and forth-like alternative to namespaces. But remember the Forth approach is to factor down to really small mouthfuls of code. If you're forced to use long words, this can impact maintainability.
Despite the very cogent reasons why one might not want to learn Forth by writing one's own, it's an often ruefully admitted fact that it's very difficult to learn the language without inadvertently ending up with, as a byproduct, a working Forth processing system. In most cases the correct thing to do is to abandon this unwanted monstrosity. But t then before you know it your second and third Forth systems happen. It just has to be faced: if your goal is to not end up writing a language interpreter, avoid learning Forth. I agree that gforth is an excellent open source Forth. It's not always available, though. Trying to run it on a Raspberry Pi hosting FreeBSD a few months ago, I found no binary package and was unable to build from source because the Arm support is (or was at that time) in urgent need of revision. So sometimes you might find yourself facing a choice of, say, ficl or pforth. They have their limitations but they're probably the next best candidates.
Forth has [hyperstatic scope](http://wiki.c2.com/?HyperStaticGlobalEnvironment) not global scope, so words can be liberally redefined and have different meanings in different contexts. I recommend /u/dlyund's [BIND](https://hub.darcs.net/pointfree/forth-bind) system for namespace management.
Thanks, that's the way I was headed when I added `prefix.word`. What I'm worried about is when `s:+` is used far from its definition I won't know if it means `string.append`, `stack.append` or `string.concat`. I have no intuition about how far is too far. Do you not have trouble with this in large projects? (What about ones written by someone else, although this isn't an immediate concern.) This was actually an issue I had with Forth itself: they are all symbols that mean nothing to me, half of them mess with the STATE and there are a lot of them. (There was also no easy way to distinguish the meaning of something like `rot` and `-rot` without looking up their definition.) &gt; Of course then you would have to say "cool-new-namespace:my-excellent-word", which borders on the unusable... I was thinking of writing `my-excellent-word` locally but `cool-new-namespace:my-excellent-word` globally. I don't know how well that would pan out.
You've put this in bold since I last read this: &gt; Is there any wisdom about how to do this in concatenative languages? You've already abandoned most of the available wisdom about doing things in concatenative languages by eschewing Forth or Postscript syntax. That's the problem with striking out on your own: there's nobody there to guide you. So you have to trust your instincts. It's arguably important anyway, but especially when you're off exploring. And it sounds as though your instincts are telling you - really quite loudly, if I can hear them - "this is unmaintainable; you've gone off in the wrong direction".
Thanks for a great answer and discussion. &gt; Surely short names should be easier to memorise? Oops, I meant memorizing the names' meaning for use when reading rather than for lookup when writing. Although I find it not too hard to remember long names when all my names follow some pattern, like in the example here (but it really has to be a single pattern for everything). &gt; When you find it, it just trips off your fingers and looks like it was always supposed to be called that. &gt; &gt; In any case, most of your names are short; they're just puffed up by the need to use namespace qualifications. Yeah, I'd like to think I'm normally decent at finding names when using other languages (and don't have the namespace issue here). &gt; "bounded?" for a test, or "bounded!" &gt; "confine" Yeah, maybe confined. I guess I could even put `( index -- confined(index) )` in the comments so `index-in-range` could have also been just `in-range`. &gt; your code blocks (conditionals? loops?), which are vanishing into the noise at the moment. That's spot on! &gt; But I think what you've demonstrated is the fundamental weakness of using combinatorial syntax for everything. Maybe. But I don't see how using (essentially) delimiting words like `IF` and `THEN` does much better than `[` and `]` as delimiters. &gt; `def: X`, `if`, `then` This feels like some kind switch between prefix vs postfix notation. I thought Forth had all the answers for writing postfix. I'd be nice if there was a way to write in postfix notation all the time instead of switching between prefix and postfix. I did consider having `[ ] push: func-name bind` at some point. I guess `push: func-name [ ] bind` wouldn't be that different (to use your `def:` suggestion). &gt; two-pronged conditional, Currently, that's cond [ ( true case ) ] [ ( false case ) ] if-else for me. &gt; define small constants as words in their own right! I'm still trying to think of a way to read them if defined this way though. "0 is the function that takes no input and returns 0" feels like a collision to me because 0 is used to mean two different things here. Although if I only bind small constants, it does mean I avoid changing the main loop. I know its intended to look like reverse Polish notation but interpreted as functions, it seems really weird to have 0 in the middle of a list of function calls. &gt; vocabularies &gt; `rename: m.x y` How do vocabularies in Forth work exactly? If I add renaming, I'd like them to be local and declared explicitly. But given the short function bodies, putting it there might increase the function size too much. I could try this for a contiguous region of functions but I'd need something to indicate the end of renames. Do I want to allow nested renaming regions? Intersection of regions?
&gt; I'd suggest an indentation scheme rather than colour-based syntax highlighting. I'm quite interested but how would something like that work? Are there examples of something like this used in a concatenative language?
I was thinking more along the lines of what syntax and conventions to use rather than how to implement it. Although its still interesting to see that someone did.
&gt; half of them mess with the STATE Not really. Per ANS 6.1.2250: Only the following standard words alter the value in STATE: : (colon), ; (semicolon), ABORT, QUIT, :NONAME, [ (left-bracket), and ] (right-bracket). So in an ANS compliant Forth, it's just 7 words that alter STATE. There are likely more that *read* STATE, but that's not the same as messing with it.
Prefix has a look-ahead component to evaluation, which makes it less than ideal for a straight-forward calculation or execution of code.
&gt; Oops, I meant memorizing the names' meaning for use when reading rather than for lookup when writing. So did I. Forth only looks difficult to learn because of its reliance on line noise; but really, once you spend enough time with it, the symbol choice does make a certain amount of sense. I mean, what's more natural than adding comments **(like this)**? ;-) &gt; I don't see how using (essentially) delimiting words like IF and THEN does much better than [ and ] as delimiters. Mainly it tells you what they're there for. It also avoids introducing a level of unnecessary nesting on the return stack, which means you can say **IF ... EXIT THEN** rather than `[ ... pop-r exit push-r ] if`, but - mainly it tells you what they're there for. HP's RPL went even further, defining `IF` as a null immediate word and using `THEN` where Forth would use **IF** (and `ENDIF` where Forth would use **THEN**) - all in the name of readability. &gt; This feels like some kind switch between prefix vs postfix notation. I thought Forth had all the answers for writing postfix. I[t]'d be nice if there was a way to write in postfix notation all the time instead of switching between prefix and postfix. Yes, until you try... as you've just discovered. The thing is, you have to parse somewhere. You can either do what Lisp does and try to build an extensible reader, where all kinds of special characters are expanded up into expressions in various entertaining ways... or you can do what Forth does, and put the onus for parsing onto the words that need to do it. Similarly, you have to start a definition anyway, especially when compiling threaded code - you need the CFA - and the vast majority of your words will be named, and if you put the dictionary entry elsewhere you'll only end up having to point back at it. So why not make the header, and the dictionary entry, at the same time as starting off code compilation? It's simpler, it doesn't introduce anything unnecessary that wouldn't have had to be there otherwise, and it optimises for the common case without unduly penalising the rare ones. Also consider your word `bind:`. Can you use it in a definition itself? Is it a special token? How do you define a variable? If you use bind: for that too, you'll have to bind the address of the variable, or do something even worse... And your nested blocks of code; how do you get past a block of code compiled inside another one? Is it compiled inline, in which case you need to jump past it anyway, or is it shuffled around in memory as soon as it's done, in which case what happens when you want to **FORGET** something? The simplest way is to compile it inline and jump past it, but that means you'll already have to backpatch the jump anyway - so why not just commit to that and implement all your control structures in that more direct way? I'm not advancing these arguments to dissuade you, but to try and give a sense of why Forth has tended to end up with the simplest thing that can possibly work, rather than chasing any academic notion of purity in any respect at all. It's not a clean design, but it's not intended to be a clean design; its only intention, when all is said and done, was to reduce the distance between Chuck Moore's brain and the computer he happened to be programming. And Moore is someone who's quite happy to throw away his last decade's work and start again because he thinks he's figured out a new and simpler way to do X, whatever X is... so you know, don't feel bound yourself. ;-) But consider that if you have to pay for a feature once, whether that's parsing the input stream or backpatching a jump at compile time, it becomes free to use thereafter - so you might as well get the most you can out of it. The whole idea of the dictionary itself is another instance of that. You had to pay the cost; it's there now - so you might as well use it for everything that needs names given to things. &gt; I'm still trying to think of a way to read them if defined this way though. "0 is the function that takes no input and returns 0" feels like a collision to me It really isn't, though; that's exactly what you will have defined. If you look over the parapet at Haskell, which is pretty much the diametric opposite of Forth, that's pretty much how they look at numbers; they're constant functions which, like all constant functions, consume no arguments and return themselves. &gt; Although if I only bind small constants, it does mean I avoid changing the main loop. Well, exactly. Most Forths would define -1, 0, 1 and 2 as constants, rather than letting the number interpreter pick them up, for the sake of space. &gt; How do vocabularies in Forth work exactly? ...Depends on the Forth. \**grabs can opener and tin marked "earthworms"*\* This is one of the areas where the ANS standard threw up its hands and went "here are some bits, make them yourselves!" And that's why we now have **WORDLIST**s in Forth. [Here's what it said about it.](http://lars.nocrew.org/dpans/dpansa16.htm) The basic gist of it is that a vocabulary is a variable which stores a pointer to the head of a linked list of definitions, and whose **DOES&gt;** action is to place a pointer to itself into a variable called **CONTEXT**. The search for defined words begins at the definition pointed to by what **CONTEXT** points to. There is another variable, **CURRENT**, which points to the vocabulary into which new definitions are entered; the word **DEFINITIONS** basically copies **CONTEXT** into **CURRENT**, at which point you can change to a new vocabulary just by naming it. So, for example, if you were writing a **CODE** word, you would say ASSEMBLER but if you were writing the assembler, you'd probably want to say ASSEMBLER DEFINITIONS FORTH so that you're defining into the **ASSEMBLER** vocabulary, but fetching from the main Forth vocabulary. That's the *basic* gist of it. However, it's almost certainly more complicated than that, and no two Forths necessarily work the same way. [This XKCD applies.](https://xkcd.com/927/) Which, again, means: don't consider yourself bound! It might be more useful to look across at the Wirth family of languages, specifically Modula-2, with its `FROM` *module* `IMPORT` *names*...`;` construct, which allows you to use *names* without qualification, as though they'd been defined in the current module. (Although Oberon ditched that; with object orientation, it ceased to be necessary.) And Pascal's `WITH` *record* statement, which raised the fields of a record to the top level for the following statement. Either way, though, the extent of renaming should be the extent of the particular module you're defining; that is, renaming a "foreign" word in the current namespace should make it indistinguishable from any other word in that namespace. 
I honestly don't know, but I do find it helpful to break up stretches of Forth using an ad hoc indentation scheme. But the most important coding style rules tend to address the word definition. Leo Brodie (Thinking Forth) produced such a style convention for Forth-83, for instance.
&gt; What I'm worried about is when s:+ is used far from &gt; its definition I won't know if it means string.append, &gt; stack.append or string.concat. I've never found this to be an issue. If the namespace string is consistently used (e.g., s: for strings, stk: for stacks, etc) it's pretty easy to keep track of the prefixes, and memorizing the individual words comes with time and use.
Strictly speaking, Forth traditionally does not do any syntax checking or analysis unless that is something added in later. Some Forths will optimize, yes, but that's beyond the scope of my post. And certainly, it is true that Forth has some operators that need to "look ahead", and they are important, but again that specific case of functionality is beyond the scope of my post. I'd like to make another post addressing look-ahead operators, and why immediate words are useful to have and how they work, but that's for the future.
Here's Leo's style convention: [http://forth.org/forth_style.html](http://forth.org/forth_style.html)
: QuadForm+ &gt;r dup rot r&gt; over &gt;r &gt;r &gt;r &gt;r &gt;r r&gt; negate r&gt; 2 ^ 4 r&gt; * r&gt; * - 0.5 ^ + 2 r&gt; * / ; A quick note: the `&gt;r r&gt;` prior to the `negate` isn't needed. Additionally, in ANS you'll run into issues translating this as the floating point stack may be separate and I don't believe that there are standard ANS words to move floating point values to/from the address stack.
Sure, but do you think the difference is significant? And if yes, in which way?
Ha! I knew someone would say something about that. Yes, the rpush rpop right next to each other are not needed, but I left that there to emphasize my point about storing variables on the RStack to use later. As far as ANS goes, I'm less concerned about implementation details, than what the code actually does. To that end, I put the disclaimer at the bottom. This code is meant as an example, not meant for production.
Let me ask you then, what would be the mechanical difference between "ln ln ln ln x" vs "x ln ln ln ln"?
Perhaps we don't agree on the meaning of the word compiler. com·pil·er kəmˈpīlər/Submit noun 1. a person who produces a list or book by assembling information or written material collected from other sources. 2. COMPUTING a program that converts instructions into a machine-code or lower-level form so that they can be read and executed by a computer. I think a Forth compiler fits definition 2. It does however lack many of things that a conventional language requires, but I believe that is more in the realm of lexical analysis than compilation. It's a simpler grammar and therefore requires less processing for the conversion to the lower level code. It's amusing that traditionally ITC Forth systems did some syntax checking (mine does too) albeit a small amount. Completion checks were provided for IF/ELSE/THEN and BEGIN/WHILE/REPEAT loops etc. however that has fallen out of fashion with native code generating Forth compilers. These checks were even applied to the analogous structures in Forth Assemblers. 
I'm mildly colourblind myself, but only to the extent that I fail colourblindness tests (usually I can't easily pick *any* numbers out of the sea of dots) and occasionally two colours will create a nasty clashing bit in the middle that my eyes just won't focus on. I can tell red from green just fine, although dark red or dark purple on a dark background are nightmarish; *but* the shades of green and yellow in colorForth are of almost identical luminosity and I have real problems telling them apart. Also white vs cyan... anywhere, really.
I see what you mean, yes. I agree that some sort of transformation on code happens, but I disagree that it is transformed into a lower-level form like the definition suggests. Although I would be willing to amend my statement in the main post if you have a better way to express that concept.
I guess I am ok with the tradeoff I have made to keep data stack juggling simple in exchange for copying when I must. Sounds like you would benefit from a good local variable package if this is common in your code. I didn't include this in the TI-99 code, but you can index this string stack quite simply. : ]$ ( n -- $addr) SSW * PAD + ; \ returns any string on the string stack I am curious, why do you index the stack and not use an indexable data structure in the HEAP or in a static allocation?
I would read other peoples code to get a sense of how they do things. You seem bent on creating an entirely new language for you purposes which is fair game but harder for others to assist. Perhaps you would benefit from adding an OOP layer to your Forth. There are number of ways to do that. 
Why index into the stack? Because that's where the data already is, with all the room it needs. I don't always need every detail about the string, and it's not always strings that I'm dealing with, hence: f@ is mov ebx, [edi+ebx] f! is pop [edi+ebx] pop ebx
Just a quick update from all the suggestions and random things I've been trying. I'll get to answering a few individual comments a bit later. I do read all of them. Right aligned [ memory.len type.array memory.append s21 s11 memory.append memory.len + memory.len.set ] ( array_size -- array ) bind: Array.new [ s11 memory.get type.array == not pushf: error if ] bind: Array.check [ pushi: 1 + memory.get &gt; pushf: error if ] bind: Array.in-range [ s21 Array.check s1212 Array.in-range pushi: 2 + + memory.get ] ( array index -- array[index] ) bind: Array.get [ s321 Array.check s1212 Array.in-range pushi: 2 + + memory.set ] ( array index value -- ) bind: Array.set [ Array.check pushi: 1 + memory.get ] ( array -- len ) bind: Array.len [ s11 Array.len pushi: 1 - [ s1212 Array.get print s11 pushi: 0 == [ s2 s2 pushi: 3 return-many ] if pushi: 1 - ] call repeat ] bind: Array.print Right aligned, short prefix, bound 0, 1 [ pushi: 0 ] bind: 0 [ pushi: 1 ] bind: 1 [ m.len t.array m.append s21 s11 m.append m.len + m.len.set ] ( array_size -- array ) bind: A.new [ s11 m.get t.array == not pushf: error if ] bind: A.check [ 1 + m.get &gt; pushf: error if ] bind: A.in-range [ s21 A.check s1212 A.in-range pushi: 2 + + m.get ] ( array index -- array[index] ) bind: A.get [ s321 A.check s1212 A.in-range pushi: 2 + + m.set ] ( array index value -- ) bind: A.set [ A.check 1 + m.get ] ( array -- len ) bind: A.len [ s11 A.len 1 - [ s1212 A.get print s11 0 == [ s2 s2 pushi: 3 return-many ] if 1 - ] call repeat ] bind: A.print Same thing but left aligned push: 0 [ pushi: 0 ] bind push: 1 [ pushi: 1 ] bind push: A.new ( array_size -- array ) [ m.len t.array m.append s21 s11 m.append m.len + m.len.set ] bind push: A.check [ s11 m.get t.array == not pushf: error if ] bind push: A.in-range [ 1 + m.get &gt; pushf: error if ] bind push: A.get ( array index -- array[index] ) [ s21 A.check s1212 A.in-range pushi: 2 + + m.get ] bind push: A.set ( array index value -- ) [ s321 A.check s1212 A.in-range pushi: 2 + + m.set ] bind push: A.len ( array -- len ) [ A.check 1 + m.get ] bind push: A.print [ s11 A.len 1 - [ s1212 A.get print s11 0 == [ s2 s2 pushi: 3 return-many ] if 1 - ] call repeat ] bind 
`compiled` is Gforth's way of telling you that you are entering text into a colon definition. So most likely you forgot a terminating `;` somewhere in your include files.
&gt; Forth has many forms of compilers. Even compiler compilers, if you lean heavily on DOES&gt; and IMMEDIATE. ;-)
Ah, well "append" and "concat" are the same in my book. "stack append" is "st:+". (Again, in 8th) there is a default "user" namespace where all your words get created if you don't make another namespace. The built-in namespaces are all short and mnemonic (n for number, s for string, m for map, etc). A typical use-case might be creating a "foo" namespace where you put everything which deals with "foo" things. I haven't had to work on very large projects yet, most of what I've done has been relatively small or medium-sized. So I can't comment on large projects. But what I would expect is that, in such a case, the manager of the project would enforce use of specific namespaces for particular items. That would make sense to me, anyway. Regarding the symbols meaning nothing to you, well ... that's a problem in any language. I just had to rewrite some PHP code, and had to look up the semantics and syntax for a whole bunch of functions even though the names were clear enough. That is, I knew what the function was supposed to do, but not the parameters or the ordering, or how the parameters might be used. Yeah, you can have "bar" locally and "foo:bar" globally. Except that "foo" namespace is always going to be "global", and the word "foo:bar" is always accessible (in 8th) by using the full name, e.g. "foo:bar". If you just say "bar", then if another "bar" is available in the "search order", it may be found in lieu of the one you are hoping to use.
Which end of the expression you start from. That's really all.
&gt; Strictly speaking, Forth traditionally does not do any syntax checking or analysis unless that is something added in later. Yes, but strictly speaking Forth traditionally doesn't do much of *anything* unless you add it in later.
That was primarily a figForth thing; I don't think polyForth ever bothered with such checks, instead preferring to assume the programmer would stop forgetting such things after they'd lost their third day's work...
I think the second one is nicest too, but with two suggestions - firstly, separate distinct phrases with newlines (since you're not using blocks, there's no reason to be afraid of whitespace); secondly, pop the stack effect comments on the other side of the bind: declarations. For example: [ m.len t.array m.append s21 s11 m.append m.len + m.len.set ] bind: A.new ( arraysize -- array ) As far as editor macros, you can cheat a bit - set the tabstops at 2-character increments for the first half dozen or so, and then one final tabstop about 50 columns over. Then you just need to remember to only ever use that editor... ;-)
&gt; Ah, well "append" and "concat" are the same in my book. That seems counter-intuitive. &gt;"stack append" is "st:+" This too. 
So to me a transformation from text to binary is a transformation to a lower level and all Forth systems do that when they "compile". And text to native machine code definitely meets the requirements. An improved statement could be among these ideas: "the Forth compiler does far less than a conventional compiler" "the Forth compiler does just enough to be classified as a compiler and nothing more" "the Forth compiler is extremely light on syntax checking since Forth has little to no syntax" I think these get closer than "Forth has no compiler"
I knew it was Fig-Forth but didn't know PolyForth never had it. I saw the word ?PAIRS used in other early source code however. Glenn Hayden's MVP Forth used it and so did HsForth for DOS. I will have to consider removing it from my system and save a few more bytes. Note: ?PAIRS was a word that compares 2 numbers for equality and aborts with a message like "un-matched" if they are not. By embedding magic numbers in your compiler words like IF ELSE THEN BEGIN UNTIL , that would be left on the stack for their counterpart to test, you could perform very simple compile time error checking for word pairs. Clever. BUT.. apparently real Forth programmers don't need compile time error checks and never make a mistake. Guess that excludes me from the set. :-) Ah crap! There goes today's work...
And I wonder if you have the word INCLUDE inside a : ; pair. It is not obvious in Forth that some words ONLY run in the interpreter and cannot be compiled. Among them are the IF ELSE THEN words, the looping words and as you have discovered in GForth, INCLUDE as well. 
I think you have that backwards; IF ELSE THEN, loops, etc aren't supported by the *interpreter* and must be used in compiled definitions in GForth.
&gt; "append" and "concat" are the same in my book. Your book must lack parentheses...
I'm missing something here. "Appending" one string to another has the same effect as "concatenating" the two strings. So... what am I missing?
Recursion.
My mistake then. Its hard to put into words what's confusing or hard to parse. It might be some combination of state and immediate mode. Basically, when I see a function like `+` I couldn't easily tell what that instance will do (if it will be run, written, skipped, looped). That's not quite it; the type of confusion is still unclear in my mind.
That's good to know. I might try it for a bit then. I still don't know if auxiliary functions to a function deserve their own prefix (to say they were originally intended to go with that function).
&gt; I'm missing something here. "Appending" one string to another has the same effect as "concatenating" the two strings. So... what am I missing? Appending *a* to *b*, changes *b*. Concatenating *a* and *b* gives you *c*.
Thanks for sharing your account. That's definitely part of what I was asking for. &gt; the manager of the project would enforce use of specific namespaces for particular items. For this particular project, all the roles are filled by the same person. :) But it'd be interesting to know in general. I guess you just make some decision and remember it or write it down somewhere. &gt; Regarding the symbols meaning nothing to you, well ... that's a problem in any language. I just had to rewrite some PHP code, and had to look up the semantics and syntax for a whole bunch of functions even though the names were clear enough. That's a very good example of what I'm talking about. I want to reduce the number of symbols so the language's symbols can be (re)learned easily. &gt; That is, I knew what the function was supposed to do, but not the parameters or the ordering, or how the parameters might be used. I considered adding named parameters for this reason. But it doesn't go very well with Forth-like languages (or I haven't found a good way). I mainly use Python where I feel like I don't have either of these two problems (or at least they are much less pronounced for me).
Wouldn't that depend on whether or not the data structures are mutable?
&gt; You've put this in bold since I last read this: That was always in bold (no `*` marking an edit). :) &gt; "This is unmaintainable; you've gone off in the wrong direction". If I was writing (ANS) Forth from scratch, I would have concluded this fairly early on. That would be based on the sheer number of special symbols, number of parenthesis types (`if...then`, `do...loop`, `'...,`) and "exceptions to exceptions" (for semantics) as I like to call them. Also the need to track the stack state one way or another. Without its history, I wouldn't have thought it would be viable for anything larger but people have built operating systems from this (I think) which obviously proves my intuition wrong. I'm not quite sure what my point is here...probably something about predicting non-maintainability.
Ah, well in 8th adding two strings creates a new string. So I guess s:+ is "concatenation" by that definition.
&gt; you just make some decision and remember it or write it down somewhere Yes, that's pretty much it. You can have a "README" or something for you (and anyone else working on your project) defining what your standards are. A good idea even for a solitary developer, really. &gt; I want to reduce the number of symbols so the language's symbols can be (re)learned easily Certainly doable, but if you will have other people involved I think you'll find that everyone has an itch they want to scratch, so the number of symbols to be learned will grow. Be strong... The append vs. concat was explained to me a above. So in 8th, just to clarify, "containers" are mutable while "scalars" are not. That is, any type which can contain another type (array, map, stack...) is mutable. Everything else isn't. Don't know if that's of any help in this discussion, but there it is.
Also the concept of addition is commutative, but that of concatenation is not.
By definition, you shouldn't be able to append to a non-mutable data structure.
&gt; I mean, what's more natural than adding comments (like this)? ;-) Yeah, good point, its definitely very natural. I hadn't thought about the choice of `( )` before. Looks like 8th uses parenthesis for something else though and I do feel the loss of one of the easy-to-type parenthesis to add comments though. &gt; HP's RPL went even further, defining IF as a null immediate word and using THEN where Forth would use IF (and ENDIF where Forth would use THEN) - all in the name of readability. I think I would have liked `IF ... THEN ... ENDIF` as you describe here much better. `IF ... THEN` feels like its somehow "halfway" between an actual function and an imperative statement. &gt; Also consider your word bind:. Can you use it in a definition itself? Is it a special token? How do you define a variable? If you use bind: for that too, you'll have to bind the address of the variable, or do something even worse... I think compiling `LIT` (or maybe I'm thinking of one of the similar words like `'`; I can't remember) brings up all the same questions. In my case, yes, there is a list of words with a compilation exception. Its intended to contain all words ending in `:` (but they are added manually for now). The code run for exceptions is the same for all words in the list: read the next word and write it. For variables: pushi: 123 bind: x push: x names.get 1 + print prints `124` (well it prints `c7000000` which corresponds to `124`). There's no distinction between a variable whose value is an anonymous function and a variable whose value is something else like an integer or even a string. push: foobar bind: x push: x names.get print-string prints "foobar" and push: 1 names.get call pushes `1` onto the stack. &gt; And your nested blocks of code; how do you get past a block of code compiled inside another one? Its shuffled around. You can't `FORGET` anything yet because (I think) I'd need a garbage collector first to make the forgetting useful, which I don't have yet. Although I just looked up what `FORGET` does &gt; Skip leading space delimiters. Parse name delimited by a space. Find name, then delete name from the dictionary along with all words added to the dictionary after name. That's easy to do as an effect (but wasteful on memory) push: A.new names.keys.index s11 names.keys.len.set names.values.len.set should `FORGET` `A.new` and everything after it. &gt; so why not just commit to that and implement all your control structures in that more direct way? Mainly to reduce the number of exceptions to whatever rule there is. I want the exact behaviour of the interpreter to be easy to state. Like "All words that end in `:` consumes the following token. Only these words, `[`, `next-input` and `next-command` can consume tokens." (as an example of a sentence in such a description). &gt; rather than chasing any academic notion of purity in any respect at all. I think it would still be good to know *if* that's possible or if something fundamental clashes with whatever we're trying for. Whew, I'm going to stop here. This reply is already getting pretty long. Thanks for the discussions and explanations!
That's better than I had before. I think I'll amend it to "Forth's compiler is extremely tiny; it does nothing beyond a lookup and substitution per word."
That would be a funny thing to say to troll a Lisper.
But Lisp confers a little extra that neither Forth nor your example above does: Its functions know how many arguments they were called with. Writing `(ln ln ln ln ln x)` in Scheme will cause it to complain about the number of arguments before it even gets to thinking about whether you can apply `ln` to a function. (In Common Lisp, it'll probably complain that the variable `ln` is undefined. Lisp-2s, eh?)
What?!? No.... no way I would forget such an obvious failure. Lemme just cat that file for grins and giggles .. Ye gods. Yeah.. that was it. As much as I would enjoy blaming sunspots, noisy neighbors, or scatter radiation from the local police radar - I just brain cramped on that one. Ah well, it’s rolling along now like a boss - thanks, larsbrinkhoff - you helped me out and I do appreciate it. 
Then my example sucked. I should have written something to the effect that "if prefix is just reversed postfix, then why bicker over the difference?" 
No problem, glad it was an easy fix.
Strictly speaking, postfix is [reversed prefix](https://en.wikipedia.org/wiki/Polish_notation). But I don't know why people bicker over the difference either. Possibly they're overidentifying prefix notation with Lisp?
Does he have a reddit account? We could summon him.
Exactly opposite. Thanks. Should have finished my morning coffee before writing.
Makes sense when you put it that way. Using ASM means you don't pay price in Forth overhead. So can we say you are using a fast equivalent of the Forth word PICK for f@ ? And you have created a reciprocal word that we could perhaps call 'PUT' for f! ?
[He does](https://www.reddit.com/user/JonathanSwift), but it's been inactive for quite some time...
Shoot :/
Yes. And since it is relative to a static location in the stack, and not the stack pointer, the load store operations can be factored out if so desired, in two forms: : litf@ lit f@ ; : litf!lit f! ; which are a pair of words that look for an offset as a literal in the next word, or : &lt;varName&gt;@ &lt;varOffset&gt; f@ ; : &lt;varName&gt;! &lt;varOffset&gt; f! ; which can be any number of words that load and store specific variables local to the function. What is interesting about these is that they could be automatically generated, and varName can be kept local to the function. Furthermore, since they are "in" the stack rather than somewhere else, they are thread safe and better for the cache.
I would define forth as a linked list. All that forth really is is a thing that you can push things onto and pop things off of. You can manipulate those things while they are popped off. You've also got some lovely memory to work with. I would also say forth is both like an extended version of assembler and like a minimal version of lisp. Forth can play alot of parts and is very robust.
This doesn't make sense to me. &gt; I would define forth as a linked list. This would imply that forth is just a data structure. &gt; All that forth really is is a thing that you can push things onto and pop things off of. You can manipulate those things while they are popped off. So a stack? &gt; I would also say forth is both like an extended version of assembler and like a minimal version of lisp. A basic Forth feels closer to assembly to me than to a minimal lisp. Lisp introduces a lot of additional overhead due to more complex memory handling (garbage collection) and tracking function arity (and likely types) as well. But this is all far from saying that Forth is a data structure.
I would say that all a forth is is a data structure plus some words to operate on that data structure.
So on the "what to do when the pool is removed", I've decided to implement a very simple solution: When assigning an item to a task (either on task startup with "t:task-n" or when pushing to a task's queue using "t:push") the item's pool will be switched to be that of the target task. That leaves the issue of putting an item in a global var to be used later (e.g. after the task departs). In that case, I'll add another word to explicitly assign the item to a particular task's pool (the main task, if 'null' is given, I suppose)
I've found that Forth's way of allocating variables (always in a global context) doesn't play very nice with task threads. I've always had to get my threads to request thread-specific space for that purpose, or throw them to some known location in stack memory (which is always thread-specific).
&gt; I've found that Forth's way of allocating variables (always in a global context) doesn't play very nice with task threads. This is where user variables came from, if I recall correctly. 
Well, in Forth there's "user" variables which are per-task, and 8th has "task-local" and "word-local" variables as well -- so you don't have to go through contortions to save data in a non-global manner.
I often forget those exist. I don't program with Forth enough in a production environment to remember every detail of it.
Those are very thoughtful considerations. Do task-local variables tie up a CPU register? I imagine that's a pretty expensive price on x86.
No; since 8th is (currently) "hosted", it relies on the OS to provide threading etc. In the task-local variable case, they are implemented as a "thread-local-storage" map containing any number of named items. So they're not the fastest things of all time, but they work as expected across all the platforms 8th supports, which is a crucial feature.
Ah, I see. Is 8th run on a virtual machine? Or a common set of words that all implementations share?
No, not a VM. The "runtime engine" is essentially a library with the common words implemented, as you surmised. The user's code is unpacked etc., interpreted, compiled and run at load-time on the target machine.
Sweet. So the first set of running code from the programmer is compressed code? Does any part of that process support code synthesis during runtime?
Yes and yes. At initial load, the 8th runtime initializes itself and all whatever builtin code it's got. Then it looks for the compressed (and possibly signed+encrypted) runtime package of user-code. If it finds that, it (possibly validates and decrypts and ) decompresses the code and interprets/compiles etc and then jumps off to "app:main" if there is such a creature (if not, it's up to the user to have done something sane). Since "eval" is present in the global namespace, you can certainly create new code on-the-fly. But beware!!! the security implications of that... You can, for instance, load at runtime different code for different classes of CPU if you like. That goes against the "write once, run anywhere" philosophy of 8th, but it's doable if you need to do that.
Very interesting. Thanks.
My pleasure
In Reva Forth, I had byte-prefixed as well as 4byte-prefixed strings (for long strings), as well as traditional address, length strings. In 8th there are just strings (containing a length-field), because I see no point in having to take up two items on the stack.
Well it isn't very hard to convert from the count prefixed string... DUP CELL+ SWAP @ ... so we are not talking a lot of complexity here... You probably want to skip thinking about this for a while and spend some timing thinking about the problem in general. The fewer preconceived notions the better... You might end up doing something more complicated anyway for your memory representation ... or ever simpler...
I don't deny that it's easy to convert from an implicit or prefixed length to an explicit length on the stack but you have to do that up front and on the outside, which often isn't the appropriate place, and this can lead to a lot of internal jiggling. The use of implicit or prefix lengths reduces the number of items on the stack while delaying the unpacking until the point of reduction e.g. extracting the length just before a count-down loop where it's immediately taken off the stack and doesn't interfere with the natural flow of things. So we're *sometimes* talking about a lot more complexity than necessary... Of course, I'm generalizing here but many of these words are quite general. &gt; You probably want to skip thinking about this for a while and spend some timing thinking about the problem in general. :-) I think I've done quite enough thinking about the problem in general. What I'm looking for now are other peoples thoughts and perspectives on which is better Forth style, in general. I want to understand why it is that we've settled on (at least in ANS Forth) on using explicit lengths and more internal stack juggling.
The thing is, if you don't store a pointer+len on the stack, then you may have to deal with copying substrings out to deal with them as special cases. If all stuff dealing with strings expects pointer+len, you don't need to copy substrings or anything. Having said that, it depends on whether or not the strings you deal with are capable of storing arbitrary data. If not, then consider just storing the strings with a null terminator like C does, otherwise a length prefix works very easily and quickly.
There's a third option I haven't seen mentioned: keep the addr len pairs in memory, rather than counted strings. That way substring creation is still fast compared to counted strings, and we still only have one item to juggle on the stack per string. Converting to this representation is fast (`HERE -ROT 2,`), so wrapping your low-level string words with that won't be too nasty if you still want to use the uniform interface. Or use another word for autowrap: : ANS-STR ( ... addr u xt -- ... ) -ROT HERE &gt;R 2, R@ SWAP EXECUTE R&gt; DP ! ; It would probably use more memory accesses than either of the already-mentioned methods, though.
I have only really used ANS-style cell pair stack representations for strings, so I can't say how well dealing with single cell counted strings works by comparison. The big advantage for me is that I can use the words provided in my forth environment that support the cell pair format. — for me this is a big advantage, as I don't need to spend my time (or at least not as much of my time) writing library functions (not just string functions, also file functions etc.). For you, I guess this isn't an issue. Another advantage (as ummwut indicates) is that substrings don't need to be copied, as you can just point within an existing string with an addr + count. ANS SEARCH, /STRING and -TRAILING work in this manner. This could potentially be a significant saving in space and time if you want to reference a lot of substrings in a large file. (I have thought in the past about e.g. parsing a string and having the AST or whatever just reference the original string like this, but I've tended to resort to copying, as it allows me to cleanup whitespace. ) Using the pad area (or, I suppose, other scratch areas and buffers) seems a bit easier to me, too, as you can copy a string there and PAD still gets you the start of a string. At this point I find myself with the count on the stack anyway, as I need to use it as an argument to CMOVE or a DO boundary. (You could store a counted string in PAD too, of course.) Of course, one eventually wants to store strings in memory, and I have words to store and retrieve cell pair strings as counted strings (and I later found gforth has similar words). With those words, to some extent I have the best of both worlds, as I can pass single-cell addresses around until I need to actually do string operations. It's more complex than a string library that consistently deals with counted strings, of course, but only I think by the level of complexity one often has with dealing with, say, structs (the structure address is on the stack, one first has to use a word to retrieve the value one is interested in, then the operation you want to perform on it). I have an impression that counted strings were the common format in the early days of Forth (or at least, a common format) and ANS pushed them out? I've done a bit of websearching and I'm unable to find anything to confirm or deny this. But maybe Moore's use of counted strings doesn't represent an advance over ANS but rather a continuation of former practice. Presumably ANS settled on addr+len for a reason. It would be nice to know what that was. 
"All problems in computer science can be solved by an additional layer of indirection" (* ducks *) 
Why do you need strings? We can't know how to use something without knowing what it will be used for.
Adding string words to able? :) From my short experience I find having an address and length works fine. A question/proposal: how about creating some words with the pairs version and deriving the counted version words from it? That way you can implement both rather quickly and try them out on some rosetta or timus examples, if you don't have your own real world use case. You know, hands-on experience :)
Forth is not a dead language by any stretch. What it lacks in my opinion (as a newbie) is an extensive standard library.
It seems a bit wasteful to use the extra memory accesses just to reduce stack shuffling - there really is no other reason. It makes me wonder how difficult it would be for systems that already "simulate" the stack effect at compile-time (for things like register allocation) to add another layer on top of that so that we can "smush" stack items at compile-time. Of course, complexity tradeoff there.
I think it's okay to do anything in Forth. It's even okay to transform it to a completely other language. Standard ANS words for strings is poor, but enough to let you do what you need. It soon become tiresome when strings is used a lot. Then you need to build higher level words that solves the problems or even implement a string stack. 
Some work towards a broader set of standard libraries for ANS &amp; Forth200x is being done by the [Forth Library Action Group](http://soton.mpeforth.com/flag/). The sheer number of incompatible dialects of Forth make this difficult though. Even among those implementations that target ANS or other standards, many words will have differences due to the standard allowing a lot of ambiguity in implementation and handling of different states within a system.
Yes, that is also a problem, similar to Lisp's.
Just on the 'hairy' code, I presume this really means stack manipulations? I have found it a bit more difficult with the addr+len format. Two strings and some other value means you're suddenly up to five items on the stack. Three stack items is fine, going over that becomes increasingly difficult -- that's my experience, and generally others seem to agree. Here there are 'really' only three arguments, but suddenly one is faced with the complications of too many things on the stack. But why should it be difficult? If you consistently worked with data items represented with two stack items, then in theory this should be exactly as complex as single stack items, as you could just have 2versions of any stack manpulation word that you need. ANS provides a small subset of 2 item stack manipulations, but it's possible to fill this out. I think the problem is dealing with a stack that sometimes has two-stack-item data and sometimes one. This could be a lot more complicated, of course, but my guess would be that you don't need words to deal with every permutation of 2 and 1 stack item data (think of all the possible ROTs! a nightmare), the number of useful words covering most use cases would be a lot smaller than that. I have found OVER2 to be useful, that jumps two stack items rather than one as OVER doea. e.g. if you have a loop that's producing and adding strings to a data-structure, the loop can run with the data-structure address on the top of the stack, produce a string, then go OVER2 2! or whatever. This use case seems like the sort of thing people would often run into, and to me it seems like the obvious name for such an operation, but a bit of websearching fails to turn up this. I presume it must exist under a different name, or not in the 'shallow web', or something. So I'm wondering whether anyone else has useful words for dealing with the mixed case? 
I think part of the problem is ANS itself. It has a lot of legacy holdovers, and sometimes frustratingly imprecise language when describing what a word does, let alone how it would be implemented in an ideal situation. If we had a better jumping-off point that is easy for everyone to follow, I feel this would be less of an issue, especially since most newcomers will look at ANS and decide they might as well do something of their own.
of course its not a dead language since there're some old projects using it, but its dying i think
Ironically Forth is too different from mainstream languages to ever die. Flavor of the month copycat languages are more likely to die off completely, a language that brings something unique to the table is more likely to hang on forever.
But *which* Forth is dying? There are many dialects and it's so easy to implement that I can't see the language family dying off.
I don't track length at all; my strings are null-terminated. This has some downsides in terms of performance (esp. with the need to copy out subsets), but is pretty simple to work with and has worked satisfactorily for me for many years now. I rather like only having to deal with a single pointer on the stack rather than an address+length pair, especially when dealing with multiple strings.
forth as the whole familly , i havnt saw some real work usage, even in embeding domain. these days, people use arduino c, micropython or even node js. also i prefer your retro, but where can i find it except a ios app ?
of course i like it. but there's a fact, the community were full of elders who were dont care of using forth on modern it domain while pay their efforts on some ancient techs. and they still dislike implent it on jvm or c, while there's so many new born lang base on those
I guess it depends on what you consider 'modern IT domain', maybe those elders are more mindful of Sturgeon's Law than the average new kid on the block. Personally I think Forth is a good fit with programmable hardware, I wouldn't be surprised to see a resurgence of interest in Forth approaches in that very modern IT domain.
Source code for retro is readily available at forthworks.com/retro I can confirm that it builds without issues on at least Linux, FreeBSD, and macOS, and under cygwin for Windows. I also have an early C# implementation of the runtime for Windows. The iOS version is currently the only commercial one. Other Forths see at least enough use to support a few vendors: Forth, Inc; MPE; and 8th. I strongly suspect that most actual Forth use never gets widely discussed. I know that I have a number of applications written for clients that make use of Forth, but all of them are closed source and are mostly specific to small niches.
Forth is to my knowledge used for space related applications of which publicity is likely seen as not desirable.
Space-related applications have been done many times, but there's more uses than that :)
Well, in ANS Forth, the answer is usually "because this is the lowest common denominator between all the Forths out there" - although the ANS statement did contain a declaration of intent - all new string words would be addr+len words. From the ANS perspective, addr+len works with everything, can be easily converted to from the most common case (COUNT), and will work with any other language's string standards, whether C or Pascal; however, not until Forth-2012 did we have a standard wordset for multibyte characters (and Forth-2012 does not provide XTYPE, which is a filthy cop-out - probably for reasons which become clear when one looks at the definition of PARSE on p180: does *length* mean the number of *xchars* or the number of *pchars*? Someone, I humbly submit, has dropped the ball there...). But yes. Some Forths use counted strings; some Forths, particularly the C-friendly ones, use null-terminated strings; some historical Forths (particularly CP/M) might have used non-null terminators. Of the Forths that use counted strings, some use a byte as the count, some use a cell, some use both, some use neither. Really, the only option ANS Forth had was to make all its string words take an address and count, but to leave open the option of directly-addressed strings by using the Core word COUNT to transform between system-dependent and ANS strings (although Forth-2012 only specifies COUNT to work on counted strings, which is unnecessarily limiting when the extra generality would have cost nothing).
I wrote string packages in the 1980s to wean me off of BASIC. It created a string stack for intermediate results. It did too many copies. My latest version uses stack strings for faster internal processing/cutting strings and copies back to the stack after manipulations are complete. (when possible) I avoid garbage collection by collapsing the string stack after PUT$ or PRINT$, assuming that you are done with the string in either case. I found it made life pretty easy with strings handling. YMMV I can put up a GForth version if anybody is interested 
yes they must has some reasons, but community just like a tree, it need many one's contribution to grow up. 
but its just your business, none of them could help the community growing, isnt it? 
I suspect Millennials and Gen-Xers are more obsessed with growing and nurturing communities as an end itself than previous generations.
Which community? It's difficult to have a singular community in a situation where there are numerous incompatible dialects of the language. And in a case like this, any growth is good. Retro has its own small community of users, and a smaller (with some overlap) number of people using the commercial version. At this point, the commercial version brings in enough annually to cover the various expenses associated with Retro (apple development fees, hosting expenses, some misc. hardware purchases). I fully expect that if I took more time to actually advertise and promote it that it'd do better. (Many years ago Retro has a larger community, but I was spending substantially more time supporting it.) Otherwise, there are multiple communities I am aware of, with varying degrees of activity: * Ron's 8th has an active community from what I can see from the forums. * comp.lang.forth remains active, though it has some big issues with trolls * #forth on irc.freenode.net remains active and has seen some increase in activity in recent years * There are a couple of Forth groups on Facebook * The ForthHub group on Github has over 200 members * I've had many conversations on Twitter and Mastodon with people using Forth * /u/read_harder is trying to grow a community around a discord channel (I'm skeptical of how well this one will do, but time will tell...) * There are meetings of the Forth200x group * SVFIG still meets regularly * There's an annual EuroForth conference * There's a Russian Forth forum at [http://fforum.winglion.ru/index.php](http://fforum.winglion.ru/index.php) with recent activity * This subreddit It might be worthwhile to put together a place linking to the various communities and resources. The old (now defunct) ForthFreak wiki was helpful in this regard, but no real replacement has arisen. But having a singular community isn't really crucial to keeping the language alive. As long as people keep using it, Forth won't die. It just won't be a popular/fad language. :)
all of the communities you mentioned is true, except if you check the members of them, you would see its just the same guys. what i mean is to attract new and young one, otherwise, when you retired, the communities will be dead . recently i saw an article series in this subreddit, which use python to demostrate how to build your own forth, that looks a powerful change, hope that will get some new members here
There are simulators available: - ArrayForth has one - [arrayFactor](http://arrayfactor.org/textpattern/) - [https://github.com/mschuldt/ga144](https://github.com/mschuldt/ga144) - [https://github.com/twystd/GA144](https://github.com/twystd/GA144) And the actual GA144-1.20 board is less expensive than at least a few of the Matlab license options. (Also, why Matlab? I thought you were against proprietary, closed source applications.)
I can't deny that there is some overlap, though it's far from being just the same people in each. And there is some influx of younger people; in Retro's case, the iOS releaase has brought interest from a different set of users. That's partially due to the interface; younger users seem less interested in things like console environments and block editors. Being able to offer an interface that's more approachable, with access to documentation, samples, and interoperability to existing systems makes it more appealing.
Someone else did it. https://github.com/iru-/threading-examples
So you're working on a simulator?
That's the problem. The term "string" is incredibly vague. Generally speaking, the best representation depends on the problem. I was just implementing the outer interpreter in this particular case, and I was curious if we'd reached a consensus on which representation is best. If I had an "application" for string processing then it would have been easy. I reject the idea of having a string stack (a float stack and an object stack etc.) because it adds way too much complication, requiring, at the least, words for pushing from and popping to these stacks. I've settled on length-prefixed strings because it makes the core words simpler but I'll admit that there is a loss of flexibility. It's interesting to all the different ways that people are working with strings. If it wasn't for the fact that I store names as length-prefixed strings in memory to help with comparison and how this decision effects input and output and filters out then I would have probably gone with the ANS Forth approach. It's hard for me to accept a more complex implementation of the goal of flexibility :-). If we take it as wrote that each application or subproblem benefits significantly from a different representation then rather than adapting the solution to the string representation that best suits the interpreter (or vice-versa) then it's best to just reimplement the words you need. Or perhaps this is a manifestation of my inability to decern which representation is most generally applicable ;-)
Thanks for your insights on the matter; fantastic reply. An the subject of the Forth-2012 standard and the COUNT word, you could leave a suggestion :-). http://forth-standard.org/standard/core/COUNT Strings are a bit of a puzzle because there are a almost infinite number of ways to define and represent textual data (certainly once you accept that the text may use different encodings etc.) The fact that variable-width encodings like UTF-8 effectively force you to treat the text as a stream of characters fundamentally changes the nature of strings, and what you can do with them e.g. O(1) access to characters is a no-go so doing things like computing the character under a mouse from its position in the view is out the window to. Strings are hard ;-).
I don't think UTF-8 was ever intended to be the medium by which strings were processed, simply an ASCII-compatible interchange encoding for getting strings between computers. If a system commits to supporting Unicode, it might as well accept the waste of space for the sake of convenience and embrace UTF-CELL. Let's face it, if there's one thing we absolutely don't need to save these days, it's a few bytes of memory... (UTF-8 is perhaps the ultimate victory of C's string representation; it's a hell of a lot more practical to use UTF-8 with a null terminator than with a count.) But then, once upon a time Unicode was supposed to be a 16-bit encoding, encompassing only modern character sets; at some point it succumbed to creature feep... (mummies annoyed that their curses could no longer be accurately transliterated in machine readable formats?) At present 21 (well, 20.09) bits are required to encode every Unicode character. The good thing about alphabets, though, is that they don't tend to change all that frequently, so one might reasonably conclude that one could reasonably, on a 64-bit machine, store three Unicode characters per cell, and anticipate that never having to be updated. &gt; The fact that variable-width encodings like UTF-8 effectively force you to treat the text as a stream of characters fundamentally changes the nature of strings Worse, it screws up a basic assumption in Forth; BLOCKs are defined, since ANS, as being 1024 *characters*. Erm... Jack Woehr (I think) expressed concern about this way back when ANS was under discussion, pointing out that it basically blew block portability, or in fact any use for blocks other than storing source code, out of the water (whereas 1024 *bytes* is unambiguous; even if a byte doesn't map to a character, almost every non-volatile random-access storage device is byte-addressed). &gt; so doing things like computing the character under a mouse from its position in the view is also out the window Although at least in a GUI, the knowledge of where one drew a certain character will exist *somewhere*, and can be traced back from there. Besides, proportional fonts already made that particular task somewhat challenging. &gt; I settled on using implicitly length-prefixed strings for my particular problem :-) The key words are "for my particular problem", I suspect. It's a lot easier to handle generality by defining it out of existence. ;-)
I am not against all proprietary software I just try to use open software as my dependencies
&gt; The key words are "for my particular problem", I suspect. It's a lot easier to handle generality by defining it out of existence. ;-) Exactly. For the Forth development environment itself I've always found plain old ASCII to be more than sufficient. UTF support need only be a loadable module when and if a target application requires, and even then it should not have any effect on the underlying Forth environment, e.g. a BLOCK would still be 1024 bytes, and C@ C! and so on would still deal with bytes.
You lost me. Care to try again?
You mean the if then should always leave something on the stack, not changing if. Noone stops you from coding the pure haskell way :) But your second example makes no sense then, the if you describe has to have the same stack effect on both branches, so you need an else.
Huh? Please clarify.
I'll try 1 more time. He is basically saying "when using an if use it in a way so you always leave a value on the stack". Something like : if ( -- x ) IF x1 ELSE x2 THEN ; So the net result of your if is that it produced no side effects and left a new value on the stack. This is how an if in e.g. haskell works. So he wants to take away your freedom and enforce an if to be purely functional.
Assembly has more than just jz and jnz. And have you tried measuring the classic loop? Your code spawns a subshell with ``, calls an external program expr and builds up a stack of function calls with the main/next trampoline. I'd be extremely surprised if that ran faster than a simple for loop with an echo. I'm happy you are learning from forth and assembly though :)
Forth challenges a lot of "beliefs" about software development. It shows that you are seriously processing some of these challenges when you say "Forth has radically changed my thinking". Even if you never use Forth on a project, playing with it and studying it will make you a better programmer IMHO.
Well... it's Forth so he is free to implement it using the underlying primitives and override standard functionality or put it in a "FASKELL" (Forth Haskell) wordlist perhaps. :-} I would be interested to see how it works in a real example.
If one were to write a general if like that you'd need to pass the 2 branches as code blocks on the stack. Which brings you to quotations. If you want to enforce what the if does you need a stack checker. So go look at examples in Factor. It still isn't pure though.
&gt; Even if you never use Forth on a project, playing with it and studying it will make you a better programmer IMHO. GNU FORTH has a system word, which basically means that I can use FORTH loops to control binaries on a Linux or BSD system. I don't know if I will ever understand how to write a whole FORTH. I think I more or less understand what NEXT does, in the sense that it calls the next word, but I don't really understand how it does that. I don't understand the word format. I know each word is supposed to contain a pointer, but what exactly does that mean? Is it just the memory address of the actual code from the word?
You will want to read [moving forth](http://www.bradrodriguez.com/papers/moving1.htm). It fills in a lot of implementation details. I'm writing an indirect threaded forth right now, with the twist that it needs to run as positionally independent code on windows x64, and this series of articles has been invaluable. 
Thank you for this. I've been considering installing FreeDOS, and making my first attempt a 16 bit FORTH in DOS assembly. I'm not sure whether that would be easier or harder. There does seem to be more source code for that environment than just about any other, which is definitely one advantage.
I've been building "sketches" in C to work through how all the parts work together. My intent is to distill those down to the essential core and then translate into assembly. I don't think writing it in 16-bit DOS would make it any easier. 
You'll find yourself tripping over the 8086's ridiculous memory addressing and special-purpose registers; all DOS does is vastly reduce the gap between the processor and the computer. If you want to write a bare metal Forth these days, it's probably easiest to pick a well-documented emulator and target that; once it's working in the emulator, you can sling it over to the hardware in question and give it a whirl. Or you can pick a more complex platform and give that a whirl, and then target real scary hardware for your third go, when you know what you're doing and only have to work out what the target system is playing at. ;-) The other thing: avoid small memory spaces if you can possibly avoid it, at least for your first go. Simply put, it's the difference between having to code up BLOCK so that it does proper buffer swapping through a small number of buffers, and being able to load an couple of megabytes of image at startup and code BLOCK as : BLOCK 1024 CHARS * IMAGE + ; which will make your life *much* easier! (Also, if you then decide that blocks aren't your thing, you won't have wasted all that time debugging a swap system before you can write a line of source on them.)
no
This in essence is what I am doing. Only I am not reinventing the word if to do it. The if word already can do this.
UTF-16 is a hopelessly broken specification, and UTF-32 still has variable length characters; because, characters in Unicode can require multiple code points to represent. Therefore, there is no reason (other than backwards compatibility) to use UTF-16, and the only reason to use UTF-32 is to avoid writing byte packing and unpacking routines on a word addressed machine. Since you have to support ASCII anyway, that almost forces you into UTF-8.
&gt; UTF-16 is a hopelessly broken specification How so? &gt; the only reason to use UTF-32 is to avoid writing byte packing and unpacking routines on a word addressed machine Forth is a much more comfortable fit for word addressed machines. &gt; Since you have to support ASCII anyway Isn't that begging the question?
&gt; How so? UTF-16 only exists because originally Unicode was going to be a single codepoint per character specification standard where every codepoint was small enough to fit into a sixteen-bit integer, but then (after systems had started to implement unicode), the unicode standard both increased the number of codepoints massively and switched to allow multiple code-point characters. The first change caused then to make it variable width, while the second change made it impossible to have any truly fixed-width encoding of unicode. So, UTF-16 is in effect an encoding of variable length character's whose components are themselves of variable length. &gt; Forth is a much more comfortable fit for word addressed machines. While I would definitely say that Forth is a very good fit for word addressed machines, I'm not sure that I would go as far as to say that it fits _much_ more comfortably on one. In any case, most hardware is not word addressed. One can, however, implement a word addressed Forth on a byte addressed machine. &gt; Isn't that begging the question? More of an over generalization, naturally one does not have to support ASCII on a word addressed Forth, but the standard does require ASCII compatible character codes, which means either ASCII, some stripe of Unicode, or a custom encoding.
(Sorry for deleting my previous comment. Looks like my stalker has returned.)
While it's fun to read troll replies like this I would appreciate if you started putting some effort and respond to people who are trying to have a conversation with you. For the past month or two you are just spamming this subreddit with wild and untested ideas from which I personally learned nothing. If you don't wish to discuss your thoughts then reddit isn't the right place for you and I'd ask you to leave or the moderators to finally ban you.
:) I agree with you but can you blame us? If you grew up in the west in the last 2-3 generations then it seems fair to say that you grew up in a world without a sense of community. Trying to find/build one online is only natural but I think it hints at much wider societal problems
I'm sure you're right. I enjoy friendly interaction with a community that shares similar interests as much as the next guy. I just get taken aback when someone is reproached space-related applications because "its just your business, none of them could help the community growing, isnt it?", instead of doing more to appeal to 'Modern IT' practitioners such as node.js programmers, and Python programmers. What brass! :-)
It's unlikely to change if past experience is any indicator. He was quieted on the #forth irc channel due to spamming and eventually banned after harassing random users (and making threats to the op's) while trying to get unquieted.
 : money. &lt;# # # [char] , hold #s [char] $ hold #&gt; type ; ( put a double number on the stack and format it) 230.99 money. $230,99 ( convert a single sized number to a double and format it) 23099 s&gt;d money. $230,99 What you needed was `#s` to print the remaining dollars.
This isn't the same; his code generated output like: $123 $123,456 $71,823,947 $8,902,389 $28,903 $1,839,028,902 
We might have a European vs US miscommunication on what commas do ;-). I should probably have included the sable output to make it more clear. /u/_crc got my back though!
In gforth, `see #s` gives me: : #s BEGIN # 2dup or 0= UNTIL ; ok That can be modified into a new word `###s` that takes at least 3 digits and outputs a comma. : ###s begin # # # [char] , hold 2dup or &amp;1000 &lt; until ; : money. &lt;# # # [char] . hold ###s #s [char] $ hold #&gt; type ; 183902890200 s&gt;d money. $1,839,028,902.00
Thanks, I assumed jephthai wanted euro-style number punctuation because I didn't read carefully.
Awesome -- so that gets me on the right track. There's still an oddity if it's a short number. See the extra `0`s on the first one? 123 money. $0,001.23 ok But you got me playing around with this approach, and I figured this out: : #? 2dup or if # then ; : ###s begin [char] , hold #? #? #? 2dup or while repeat ; : money. 0 &lt;# ###s [char] $ hold #&gt; 1- type ; And this gives me the perfect output, and looks sexy at the same time: $123 $123,456 $71,823,947 $8,902,389 $28,903 $1,839,028,902 ok Thanks!
I don't particularly like /u/dylund becuase they always speak to me as if I were an idiot.
https://www.reddit.com/r/Forth/comments/7aw4tm/what_if_we_used_the_word_if_to_return_something/dpfz0kv/
By the way I don't believe you have any documentation that I threatened anyone.
No problem. I like your `#?` word much more than the use of `begin...while...repeat`
It just so happens that I have a screencap of my IRC client's log from April 20, 2017 containing a threat: [https://imgur.com/a/pT7Fs](https://imgur.com/a/pT7Fs). And here's the text from that screencap: &gt; 00:41 &lt;John[Lisbeth]&gt; unmute me or i sware I'll jabe ye rite in teh gabber &gt; 04:32 &lt;John[Lisbeth]&gt; breh &gt; 06:10 &lt;crc&gt; Making threats will not help you get unquieted. They will be far more likely to have me set a ban instead of this quiet period. 
^(Hi, I'm a bot for linking direct images of albums with only 1 image) **https://i.imgur.com/dDYgDD6.png** ^^[Source](https://github.com/AUTplayed/imguralbumbot) ^^| ^^[Why?](https://github.com/AUTplayed/imguralbumbot/blob/master/README.md) ^^| ^^[Creator](https://np.reddit.com/user/AUTplayed/) ^^| ^^[ignoreme](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=ignoreme&amp;message=ignoreme) 
:-)
Sorry if you misconstrued that as an insult. That is a meme. It is what is known in the youth as internet jabber. I did not at all mean that I was gonna smack that guy, nor did I think it would come across that way. The phrase "I sware on me mum I'll jabe ye right in the gabber" is a famous Internet catch phrase. It is iconic for when someone is pretending like they are going to right but are just joking. https://www.youtube.com/results?search_query=I+sware+on+me+mum https://www.google.com/search?tbm=isch&amp;source=hp&amp;biw=1600&amp;bih=778&amp;ei=-14BWveqDpXYjwPV9JfIDQ&amp;q=I+sware+on+me+mum&amp;oq=I+sware+on+me+mum&amp;gs_l=img.3...4609.7033.0.7091.19.9.0.0.0.0.416.1077.0j1j2j0j1.4.0....0...1.1.64.img..15.4.1068.0..0j35i39k1j0i10k1.0.YJzxmbgh-Wk I was assuming the audience would be "jive" to this internet meme and would realize it was a joke, and I apologize if I offended anyone by saying that.
&gt; If you want to write a bare metal Forth these days, it's probably easiest to pick a well-documented emulator and target that My plan at the moment is to prototype as much as I can in UNIX shell, which is what I'm most fluent in, and which also actually has a lot more in common with FORTH than many might think. Once I've got most of the concepts nailed down, I'm planning on using vmWare and finding the least intrusive operating system I can, for re-writing it in Assembly. That used to be FreeBSD; although if as you say the x86 arch becomes too much of a nuisance, I might have to look around for something else. If I used DOS I would run vmWare with DOS in multiple instances, which meant that even if I needed to reboot one instance, I could possibly keep working in another. My plan isn't really to think of DOS as an "operating system" itself any more, but more as an emulated framework for writing single FORTH-based applications, with the host operating system taking care of multi-tasking and other stuff.
&gt; if as you say the x86 arch becomes too much of a nuisance Not the x86 - the 8086. (Originally I said something along the lines of the 32-bit x86 being much nicer and more regular, but I seem to have edited that out. Also, that's only true for a useful subset of it...) Nonetheless, the ARM is taking over the world, and the ARM (less so the Thumb) instruction set is surprisingly good for Forth - pushes and pops in a single instruction, all instructions 32 bits wide, all instructions conditional. And the Raspberry Pi raises the possibility of a useful $5 Forth computer. &gt; My plan isn't really to think of DOS as an "operating system" itself I believe the term is "glorified program loader". ;-)
&gt; or even the x86 instruction set, which only really supports a single stack. I did notice that. ESP and EBP both point to the top and bottom of a single stack, yes? I've been playing with a file-based pseudo "stack" for the UNIX shell, by deleting or inserting to the first line in a file. Unfortunately it's prohibitively slow; around half a second of real time. For most uses that would not bother me, but if I wanted to do anything really extensive with it, it might. Still, the shell-based stuff I'm doing is only really in order to learn the concepts. For that, it works.
If there are any new developers coming to Forth, I think they're coming from more from maker communities and embedded/hardware people. Kids into software are much about web/mobile apps, backend/frontend, JavaScript/Java/C#. Not much overlap with Forth.
I have a hard time seeing how Forth could ever appeal to that group. Forth is small and self-reliant, which is the exact opposite of JavaScript and Python.
I think it's part miscommunication. Many people in /r/Forth have a shared understanding about Forth. You don't seem to have this understanding, and it doesn't appear you have made much progress since you first came here. If anyone is talking to you as you were an idiot, I would assume they're actually trying to be patient and help you.
Thank you for explaining this. This is not a thing I've run into before, so I took the words at face value. For the future, I'd advise exercising some caution when using memes with those who you aren't sure are familiar with them as it's easy to take something like this in the wrong way.
From Marcel Hendrix' online edition: http://home.iae.nl/users/mhx/sf.html
I agree. I've take caution not to use that phrase or phrases like it again.
/u/dylund goes a little out of their way to explain how dumb I am so I don't like that person. The way I see it I may not be some low level forth programmer but that's okay. I program forth the way I see fit to program forth and that is not misguided or wrong.
i am a backend developer, i am interesting of forth cause i treat it as a thin abstract layer on host, there's many domain specific language in web developing, for eg, the template language, no-sql storage, the famous redis project even embeded a lua for providing complex logic, such could be forth's domain i think
We don't have any formal rules for the Forth subreddit. But if there were, I believe this would be considered off-topic.
This is my take on how a Forth kernel in shell script might work: https://github.com/larsbrinkhoff/lbForth/blob/master/targets/shell/forth.sh
I love Forth and I figured this calculator may also appeal to other Forth programmers. It's to `dc`, but it displays the stack contents at all times and as you type, the stack changes are reflected immediately.
Or maybe it's just more spammers crawling the web to collect email addresses.
Really nice one! Thanks for sharing...
You knocked it out of the park!
But of course, I hope I'm wrong. :)
Glad you like it, thanks!
Thank you so much for the nice words!
From a comp.lang.forth posting: ---- 32-bit/64-bit Pygmy Forth for Linux, MacOS, Windows For your Forthing pleasure, I have recently posted my new Pygmy Forth at http://pygmy.utoh.org/pygmy64.html. It is in the spirit of Pygmy Forth for DOS, I feel, but quite different. The new version is implemented in Python and, thus, runs everywhere that Python runs. Python is its assembly language and it is easy to write CODE words. Here is a simple example with no stack effects: CODE HELLO print ("Hello") END-CODE Source code can be loaded from either a text file or from a pseudo block file. For Emacs fans, it comes with pygmy-mode to make working with pseudo block files especially convenient. PgDn, PgUp (or C-v, M-v) move from block to block, narrowing the display to show just the current block. S-TAB cycles through the 3 visibility settings (as in org-mode). For example, show just the first lines of each block or the entire file. The manual can be read in a web browser (HTML), downloaded as a PDF, or downloaded as an eBook (either Mobi for Amazon Kindle, or EPUB for other eReaders). MIT license. As always, I look forward to comments, corrections, suggestions. 
&gt; implemented in Python and, thus, runs everywhere that Python runs. I always wonder why does someone implement a simpler language in a more complicated one. Even C seems too much for a forth as simple as this one. Pros: - cross platform - simple to write? (if you know the language) Cons: - bloated - slow - dependencies - did I mention slow? 100x slower :) People already make jokes about python's startup speed. I heard lua people joke "a lua script finishes executing before the python one would even load". Am I missing something? The only reason I would consider choosing python as the implementation language was if I wanted to do interop with python, like e.g. [hy](https://hylang.org) does.
Frlm the user manual: &gt; Pygmy Forth is written in Python (Python version 3), so it will run everywhere: Linux, Mac, Windows, 32 bits or 64 bits. (I don’t know about cell phones and tablets. Please let me know if you try it.) High-level Forth words are compiled as Python procedures, rather than as lists of tokens or addresses. CODE words are supported and are written in Python, not assembly language. That is, you can think of Python as being Pygmy Forth’s assembly language. And: &gt; Pygmy Forth is written in Python and it can be extended by writing CODE words (primitives) in Python, or by writing high-level Forth words. &gt; Pygmy Forth gives you the benefits of Forth factoring, incremental and interactive testing, and simplicity, while providing easy access to the world of Python facilities and libraries. I can understand the appeal of not having to rewrite code for each hardware &amp; operating system combination one wants to run on. Back when my forth was written in x86 assembly, testing changes on the 9+ operating systems I supported ate a huge amount of time. This was the main thing that eventually led to me writing a tiny, portable virtual machine to run my forth on.
It is an inspiring graphic logo which alludes to forth.
If your use case is cross-compilation/cross-assembly, you're effectively dealing with two Forths, one running on the *host* and one on the *target*. For the *host Forth* you're less concerned with size or bare-metal speed, whatever provides you with a path of least resistance to leveraging the host platform's services and facilities can work, anywhere from C to the latest language *du jour*. The *target Forth* is a completely different animal, e.g. it can be a bare metal Forth using subroutine threading while the host uses token threading, etc...
Fair enough... but I don't think anyone's ever going to accuse Python of being "tiny". Even MicroPython boasts that it can fit into "just" 256KB code space and 16KB RAM. But then, it doesn't even really need much alteration to turn Forth into something relatively machine-independent. Token threading is already sufficient - either with bytecoded tokens like the Canon Cat or Open Firmware, or by reserving a range of tokens to point indirectly to machine code primitives and declaring the rest to be Forth calls, like the WISC CPU/16. Write a VM to simply implement those primitives and fill in the table, point it at your image, and you're done...
Am I alone in finding this just a little bit upsetting? Pygmy was something of a benchmark for compactness on DOS - squidging a complete Forth, with assembler, screen editor and the block number of every word, all in 16KB of code (by v1.5; v1.1 was 12KB), and one of the most comprehensible metacompilers I've ever come across. Very much "cmForth for a computer you'll actually have". That's why the name fit so well, of course. I know - it's Frank Sergeant's name, and he gets to use it how he pleases, and he is, and has the right to be, the ultimate arbiter on what's "in the spirit of the original". Nonetheless, I can't help feeling that if this is a pygmy anything, it's a [pygmy hippo](https://en.wikipedia.org/wiki/Pygmy_hippopotamus)...
**Pygmy hippopotamus** The pygmy hippopotamus (Choeropsis liberiensis or Hexaprotodon liberiensis) is a small hippopotamid which is native to the forests and swamps of West Africa, primarily in Liberia, with small populations in Sierra Leone, Guinea, and Ivory Coast. The pygmy hippo is reclusive and nocturnal. It is one of only two extant species in the family Hippopotamidae, the other being its much larger relative, the common hippopotamus (Hippopotamus amphibius). The pygmy hippopotamus displays many terrestrial adaptations, but like the hippo, it is semiaquatic and relies on water to keep its skin moist and its body temperature cool. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/Forth/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^| [^Donate](https://www.reddit.com/r/WikiTextBot/wiki/donate) ^] ^Downvote ^to ^remove ^| ^v0.28
Metacompilation is just a special case of cross-compilation, of course.
Well, I guess you get the whole Python object system / library infrastructure as well. But it's not really very Forth, at least as Chuck Moore imagined it: &gt; If I want to tell the computer to add 1 to the letter 'A', it's none of the compiler's business to tell me I can't.^[1](https://www.forth.com/resources/forth-programming-language/) 
thanks for using python to implement it which lead me a chance to learn :D
simple, because python now rised too much, and its a chance to let more people understand forth, grandpa 
Care to take another swing at that - but with more grammar and less attitude?
In theory yes, the devil is in the details. There's a world of difference between using your *host Forth* to metacompile a new version of itself on the same host, and using your *host Forth* to interactively construct a totally different *target Forth* over an umbilical link to a target board.
well its forth community, everyone has at least 2 viewpoints :D 
I don't see that supporting many system configurations should necessarily take a lot of time. I test on 14 processors and five operating systems, but it's all automated. Of course, doing this has become so much easier lately with the help of free of charge online services.
There's also CircuitPython. It's supposedly slightly smaller than MicroPython. I have been looking at the lower end of "tiny". There are devices with only a few hundred bytes of flash and a dozen bytes of RAM. That's tight even for Forth.
I'm taking the view that it's great that Frank is still at it.
For higher level languages, I think [uLisp Zero](http://www.ulisp.com/show?1OPZ) is possibly the low bar; on the other hand, Lispers have a freedom Pythonistas don't - they can ruthlessly excise bits of the language. &gt; There are devices with only a few hundred bytes of flash and a dozen bytes of RAM. I'm aware of some of them. I think they really *have* to be programmed via cross-compilation... which presumably means developing the cross compiler in Forth, rather than developing a Forth for the target. :-)
I've read the manual, but thanks for posting the important pieces here for other readers. I guess after reading Chuck's thoughts I cannot imagine him using anything higher than assembly to create a forth. Even x86 assembly is overly complex for his taste :)
Is this a cross compiler? I haven't noticed that in the docs.
I haven't read the docs for the new version, the DOS version came with a serial link and a tiny target monitor for umbilical cross-development on the 68HC11. Just about any Forth can be extended to serve as a cross development host, it doesn't necessarily need to be designed from the ground up for that purpose.
That's as maybe but we usually try to be respectful to one another :) keep that in mind for the future?
Of course, there are some devices that don't make good *targets* for such an arrangement. Sergeant's "3 instruction Forth" worked because the 68HC11 has a von Neumann architecture, and can read, write and execute code as easily as data; try it on a PIC (except for the 32-bit ones) or an AVR, though, and the inability to execute code from RAM will bring you up short.
Sure, if your target is a pure Harvard architecture you'd need some arrangement to reflash and restart the target, perhaps a JTAG interface. Definitely less incremental. One possibility might be to use an emulator as an initial target. The hope is to have a single host Forth that you can use as development environment regardless of the target, squeezing out as much interactivity and incrementalism in development and testing as the particular target will bare.
Its a very cool app. It makes me wonder... could it be written in Forth for a standard Forth console. I think so by creating a new version of QUIT which is the outer text interpreter's name. 
From his manual in the ZIP file: &gt; I miss my Pygmy for DOS. This new Pygmy Forth is my attempt to replace it for the modern desktop environment (primarily Linux in my case). &gt; For programming for PCs, I used to love my lovely Pygmy for DOS. However, the days of DOS are gone, and good riddance to Microsoft as far as I’m concerned. I am delighted with the speed and conveniences and openness of the Linux world, but I have been missing Forth in that environment. I know there are many alternative Forths, and I am sure they are great for those who like them, but none of them suits me the way Pygmy did. Sounds like he really did think about it.
I didn't want to suggest that I thought otherwise. Still, one can respect the thought put into an endeavour and yet dislike the end product.
I can't find a reference but I think Chuck's earliest interpreter systems were written in high level languages and after he solidified what it did and used it for real projects, he coded one in assembler for performance.
Am I missing something, or is that data from 1999-2005? I keep staring at my math, but ~325 weeks is a bit over 6 years?
No need to guess - we have [his own account](http://www.exemark.com/FORTH/Forth_early_years_1a5v2.pdf) to refer to. It's clear that as he went along, he recoded Forth in - and picked up influences from - whatever he was working on at the time, whether ALGOL, Fortran, B5000 assembly language, or even JCL. The compilation to threaded code was almost the last thing to arrive - previously tokens had been stored as text and searched for every time they were interpreted. (Which has slightly different semantics to compiled code.) And now he's gone back to interpreting tokenised source code; compilation is used as an interpretation strategy. (JIT-by-hand, one might call it.)
I asked Marcel about it, and he said the data was to around 2007. In any case, it's not up to date until today.
Not sure why this post is getting downvoted. [Reversible computation](http://strangepaths.com/reversible-computation/2008/01/20/en/) is a real thing. So far there have been two attempts at *software* reversible forths that I am aware of: WrongForth: http://forth.wodni.at/wrongforth RVM Forth: www.complang.tuwien.ac.at/anton/euroforth/ef04/stoddart04.pdf Neither of these run on physically reversible hardware which means you won't get the benefits of reduced power consumption. Even a conventional NOT gate is not physically reversible. You would need a special reversible architecture such as the Pendulum for any of those benefits. [Pendulum: A Reversible Computer Architecture [PDF]](https://pdfs.semanticscholar.org/30d5/54dcd308d529be93dc70607197cd251dfd3c.pdf) However, there are benefits to just software reversibility such as reversible degugging. The idea with reversible debugging is that you can step backwards and forwards through a computation. I prefer to describe it as random access over runtime, not just random access over code/data. afaik, you can make your system reversible by recording the execution or by building the system out of reversible primitives. neither WrongForth nor RVM Forth look very clean or simple to me, and that's what I'm working on doing differently.
Even before reading the Forth code, I can see that those tiny file sizes signify a truly remarkable piece of work. The Apache licence is by far the largest file, and the next largest is the ReadMe file. Even the files containing code, over half of the lines are comments or blank lines.
Thanks to both of you. I've been vaguely aware of hardware reversibility as a way to reduce energy dissipation, perhaps since the 1990s when that Pendulum design was first published. I recommend the paper as a quick and relatively painless introduction to the topic. Software-based reversibility for Forth seems rather counter-intuitive, as the basis of the language is the irreversible overwriting of stack contents. I suppose the pop operation can be redesigned as a non-destructive exchange, however. 
Wow, no kidding. I'm excited to see where this project goes!
I'd really like to see a gif preview of this in action on the bitbucket repo. Projects like this really need microscreencasts like that to show what they're like.
Would be nice to see issues enabled for this project to submit things like a request for a microscreencast gif of it in action.
Looks really interesting! You should consider adding an issue tracker so that people can discuss the project and make tickets.
My thought is this. In a purely reversible system you are still turing complete. So you can implement the irreversible ans inside of a reversible forth. So ans code can be made sort of forwards compatible. The problem, as you've stated, is that to make a reversible forth that is also simple is the reak challenge. We can add a new set of words that always take as many inputs as outputs and that are all reversible. Perhaps for each word in the dictionary we can have a forward and reverse definition for both compile and runtime. Then the only real issue is the stack. The stack by it's own nature was not intended to be reversible. The best solution I can think to this is to implement the stack as an immutable linked list so that you can travel back to previous states of the stack. Though I am not sure what kind of overhead this would add. Please share any research you have on making a reversible forth simpler, /u/pointfree
I would replace the stack with something akin to a gap buffer *past* stack *current* stack |------------------------------------| ^ ^ push *past* stack *current* stack |-0--------------------------------0-| ^ ^ pop *past* stack *current* stack |-0--------------------------------0-| ^ ^ `5 var 8! ( store a byte to memory location var currently containing 2)` *past* stack *current* stack |-0-2----------------------------5-0-| ^ ^ Here the gap buffer stores a bijection for each state. Sliding the gap around moves us forwards and backwards in time. For pure reversibility the trace of the above execution would need to be stored in the gap buffer as well, so instead of storing 0 on each side and sliding the gap around, store code to push 0 and pop 0 on either side of the gap. The gap shrinks with each step of the computation, however, there are opportunities for memoization and anti-memoization to reduce memory usage. If a computation has already happened you could just reference it. Hmm... sounds like a dictionary definition... and in forth we do tend to compile right-to-left and provide parameters left-to-right much like in the above diagrams. But what would the header of a definition be? It could be the ascii text name of the word, but I like to make it the inverse of the word. See [*Pattern matching in concatenative programming languages* [PDF]](http://micsymposium.org/mics_2009_proceedings/mics2009_submission_72.pdf) the premise of the paper is: pattern matching is the inverse of functions. By using code in place of and in addition to headers you can do things like this: 2* : 2/ ( matches a number twice the size of another and halves it) Pseudocode for the fetch/store words for byte, hcell, and cell. ( header of !, body of @) &lt;match numx of size less than 0x100 on the stack. Match addr1. Match "!". Swap numx with the contents of addr1 (numy)&gt; : ( header of @, body of !) &lt;match numy of size less than 0x100 on the stack. Match addr1. Match "@". Swap numy with the contents of addr1 (numx)&gt; ( header of !, body of @) &lt;match numx of size less than 0x10000 on the stack. Match addr1. Match "!". Swap numx with the contents of addr1 (numy)&gt; : ( header of @, body of !) &lt;match numy of size less than 0x10000 on the stack. Match addr1. Match "@". Swap numy with the contents of addr1 (numx)&gt; ( header of !, body of @) &lt;match numx of size less than 0x100000000 on the stack. Match addr1. Match "!". Swap numx with the contents of addr1 (numy)&gt; : ( header of @, body of !) &lt;match numy of size less than 0x100000000 on the stack. Match addr1. Match "@". Swap numy with the contents of addr1 (numx)&gt; Firstly, both halves of the definition must be executed, this takes care of reversibility. Also notice that by doing a little computation in the header: * we have decomposed the outer interpreter * we don't need separate `C!`, `H!` and `!` words. We only need `!` (...or maybe we really only need a word SWAP that takes an address) * the distinction between header and body is fairly meaningless. * words have symmetry (! also @'s and @ also !'s). We should be taking advantage of that, but what's left after we've compressed all the symmetry of an execution trace? Should that execution trace have symmetry as well?
&gt; So how do we fill up these devices? This is a non-goal &gt; those resources more or less keep improving each decade. There are limits and unless you've been living under a rock for the past decade you know that we seem to be reaching them. The idea that things will just keep improving isn't something most programmers believe today. 
Here's a couple of things I thought while I read that. Perhaps our stack should be finite, first of all. Perhaps the stack should not be able to grow so large and will have a sort of overflow. However this is bad for two reasons. First of all when you overflow you lose the information that was held on the stack. So we've got to keep our old stacks if we don't want to lose anything. Second of all it seems that for every mutation of the stack there is an additional copy of the stack you have to store information wise. In other words for each new state of the stack you are creating information. The second thing you made me remember is an idea I have been thinking about in terms of doing maths. It seems as if the best way to do maths is to indeed pair + with - and / with *. This means that you want your inputs to have two values and your outputs to have two values. So lets say I have an empty stack and I go 2 5 +/- What I should get is 7 -3 because that is the result of that operator. Let's say the result I wanted was the addition. I can't just store the addition result in memory and drop the other one because that would be losing information. If I store one in memory I have to store them in a pair. In other words the structure of how we would want to store things in memory is a bit different. Let's say for example I do the operation twice. 4 2 +/- 3 +/- The result of the first operation should be 6 2 as we'd expect. Then the stack becomes 6 -2 3. The result of the next operation is 6 -1 -5. This may not be the desired result that we wanted. In other words you have to design a forth that does not lose information. Furthermore you should not create information if you don't have to. Every time you create information you use up resources.
I don't have a source I'll remove it.
&gt; I see emacs as being very efficient and I have talked about how a system similar to emacs could be written in forth. Yes, I have: https://github.com/larsbrinkhoff/fmacs
Is there any reason why this was downvoted so heavily?
I do not think that micro controllers will improve in the way you described with conventional technology simply because increased logic complexity always lead to higher power consumption somehow which is primary only compensable though more sophisticated and as such much more expensive photo lithographic methods. Additionally it is foreseeable that possibilities of further shrinking will reach a (probably economic) lower limit. So until we see a breakthrough in power storage systems or processor design it is in my opinion unlikely that micro controllers will come close to the development of general-purpose processors. Another question is anyhow if there is a demand for such chip.
Very nice, I'm playing with it... I use a [snapshot version of gforth](https://www.complang.tuwien.ac.at/forth/gforth/Snapshots/) (currently version gforth-0.7.9_20171026). It contains a lot of system 'nix calls to pthreads, Xlib, opengl, wayland, ... On my linux box, it gives a rich new environment for useful projects. 
&gt; So what happens when one runs out of space? In some implementations, you can pass parameters to specify the sizes of the memory spaces at startup. In others, you may have to rebuild the kernel. &gt; In C there is realloc to "grow" more space for the same data, is a similar approach used in forth? There's a standardised wordset for dynamic memory allocation: http://lars.nocrew.org/dpans/dpans14.htm &gt; Where do these exist in a modern x86 architecture? Are they hardware or software stacks? I don't know where x86 Forths would usually place the stacks, but it's not different from any other processor. Anywhere they fit in the memory map. I have a vague feeling that the high end of the address space is popular. Not sure what you mean by "hardware stack". Some processors have an internal stack which is not part of main RAM. The x86 is not like that. It does have a hardware stack pointer, which I have seen most Forth do use. ITC and DTC Forth would probably use it as a data stack pointer. STC and native Forths obviously as return stack pointer.
&gt; If I need more memory I have to ask the OS for more and I sure won't get the space coming right after what I had before. You might. Linux uses virtual memory, and each process gets its own address space, so within reason it can put your new memory wherever it pleases - maybe right after your existing allocation, maybe even wherever you please. It can even back it with a file, for you to mmap() into memory as a Smalltalk-esque image. Of course, it probably won't be contiguous in *physical* memory, but you'll never know about that.
It's not usually that you need to load the whole 100 MB dataset into memory in order to process it, although if you can then this is probably easier. Rather, in many cases you only need to be able to load 1 record at a time to process the whole set. You may also load some subset of the records. It's also not uncommon in Forth to logically divide memory into blocks, which are loaded from persistent storage one by one and are swapped on demand :). This might seem a bit kookie at first. I avoided the block concept for years but it's really pretty nice :). Maybe I'll have time to expand on this later but I'm out of time for now. IIR Starting Forth and Thinking Forth both have some good things to say on blocks etc. I might suggest you start there. The important thing to realize is that blocks aren't just for text.
Indeed. Storing source on them is just about the worst thing you can do with them. They probably represent progress from a stack of punched cards... but those of us born after 1965 never had to suffer that, and shouldn't have to write our source code on the backs of postage stamps either. &lt;/rant and="breathe"&gt; Having said which, as a virtual memory / persistence mechanism for platforms that don't have virtual memory or mmap, they're tough to beat. But those of us using Linux have both of those things, and really don't need to duplicate them with blocks - we can just mmap() our block files instead.
LISP had a REPL by 1965. [The LISP Implementafion for the PDP-1 Computer ](http://s3data.computerhistory.org/pdp-1/DEC.pdp_1.1964.102650371.pdf) describes interacting with LISP via a REPL on page 6: &gt; At this pint, the LISP aystern is reedy for manual &gt; typenriler input, As soon as the operetor types, for &gt; example: &gt; (CAR (QUOTE (A B C D))) &gt; together with a final space at the end of the last &gt; right parenthesis, the computer takes control of &gt; the typewriter, impulses a cmriage return, and &gt; then types out: &gt; A &gt; which of course is the correct answer, I'm not aware of anything earlier than this though.
Thanks! That's where I read it. In reviewing the paper I found this line which, having written my first cross-compiler, I love: "Forth could now interpret an assembler, that was assembling a compiler, that would compile the interpreter. " 
In bigger forths, like gforth, you also have a traditional heap, with words like `allocate` and `resize` that work great for large allocations. I've never run out of dictionary space, but I also haven't done any really big projects in forth that might push the limit. 
It is a matter of debate whether microcontrollers will reach that level of efficiency. Only time will tell.
That, I can work on. Expect something in a few days.
You and the other commenters are encouraging. I put this out here to gauge the initial reaction, and if I have people willing to put in the effort to make good suggestions, I will work on them.
Thanks. A lot of it was just choosing the starting point that made things easiest. In this case, gforth's FFI was crucial because a shell uses many different system calls. There were several sections that took a few rounds of factoring before I was happy with them. I wanted to make something useful while demonstrating the strengths of Forth.
&gt; Where do these exist in a modern x86 architecture? Are they hardware or software stacks? x86 has a single hardware stack. One workaround that I've seen for that with FORTH, is the idea of using ESP (the top stack register) and EBP (the bottom stack register) as though they were each a different stack.
EBP isn't the bottom stack register; it's intended to be the stack's frame pointer (or _B_ase _P_ointer), and back in the day of the 8088 that was the only practical way to implement anything Algol-flavoured. Local variables, parameters, parent stack frames (for Algol-derived languages that support them) and the return address are all referred to by indexing BP. To that end, using BP defaults x86 processors to using the stack segment (although this has become steadily less important over the years). That also explains an instruction encoding quirk of the x86; you can't encode [BP] - you have to encode [BP+0]. Basically, [BP] would point to the return address (or the next frame pointer up the stack, depending on implementation), so in general you wouldn't want to access it anyway. The encoding was reused to provide an absolute offset address instead. Technically speaking, a frame pointer isn't necessary unless you use something like C's all, as long as you can index through the stack pointer. But that's not possible on the x86 when it's in 16-bit mode. Since Forth doesn't use stack frames, BP was free; and since it indexed into the stack area anyway, it was the natural choice for implementing the return stack, particularly for the implementation of locals, etc. But most 16-bit x86 Forths noted that using XCHG BP, SP and PUSH/POP when the return stack needed manipulating was faster on an 8088 than indexing through BP directly, so they simply did that instead - even though at that point any other register could have been used. Unfortunately, just about every 8086 register has a special purpose, and BP's was uniquely redundant in Forth.
&gt; Unfortunately, just about every 8086 register has a special purpose, and since BP's was uniquely redundant in Forth it ended up being chosen by default. Moving Forth's analysis of different ways to write FORTH instructions has been very interesting for me. Do you know of a recent processor that has two hardware stacks?
&gt; something like C's all Is there a typo here?
Forth processors usually have two hardware stacks. The J1 is recent. The 6809 has two stack pointer registers, but it's not exactly recent. I'd say most processors either have one special-purpose stack registers, or all general-purpose registers or index registers are equally suited as a stack pointer.
Yes. Which is odd, because I distinctly remember *typing* alloca()...
The trend has gone the other way - many RISC processors don't implement hardware stacks at all; it turns out not to take very many more instructions to do it in software. However, any processor with autoincrement loads and stores can make a pretty efficient stack out of any of its registers; the primary example in modern use is the ARM.
I have an unfinished stack processor design that uses a very wide circular shift register for each stack (i.e. no stack pointer registers).
&gt; many RISC processors don't implement hardware stacks at all There are few things that make me more sad, than the degree to which object oriented vomit has taken over the world. I will have to hope that one day the majority return to sanity.
Does that include fetching code into the return stack, and execute it from there?
Um... how did you get there from what I said?
I'm not sure what you mean. Return stack entries are still a single machine-word wide, as are data stack entries (the processor has two sets of each for two concurrent tasks). 
I was thinking maybe your stack items were very wide. In which case the return stack could hold the code for a definition, instead of just an address. Never mind, it's just a whacky idea I picked up somewhere.
[Here?](http://home.pipeline.com/~hbaker1/ForthStack.html)
Yes! Thanks, I had forgotten the source.
Stephen Russell's interpreter ought to predate that, though I don't know exactly when it was written. The LISP 1.5 Programmer's Manual from 1962 mentions it. I don't know the details, but I'd be surprised if there weren't some kind of REPL.
Found this: "I wrote the first implemenation of a LISP interpreter on the IBM 704 at MIT in early in 1959". http://www.cs.ou.edu/~rlpage/carcdr.htm
Hey, that's pretty cool -- found the J1 info [here](http://www.excamera.com/sphinx/fpga-j1.html). &gt; J1 runs at about 100 Forth MIPS on a typical FPGA. I've got a DE0 Nano lying around, maybe I should dust it off and give this a try. 
Interesting dissection. I'll come back with a response later, since this is a lot of information to parse.
&gt; I wanted to make something useful while demonstrating the strengths of Forth. Ugh, if only I had time to do something so fun...
That sounds great! Best of luck to you, I'll keep watching this project to see where it goes! Hopefully I can make a contribution or two at some point.
Do you mind if I cross-post the link to your repository to a few other subreddits, namely r/linux, r/unix, and / or r/commandline?
If anyone can find the link to the c.l.f thread that would be much appreciated. Some interesting discussion seem to be clipped from this version.
&gt; Um... how did you get there from what I said? I will probably get large quantities of virtual rotten vegetables thrown at me for this, but... (*deep breath*) My perception of OOP was that the main reason why it developed, was because C lacked inter-process communication, (you can use sockets and such, but I'm talking about something as really native as most people seem to want) because it did not (at least normally) use a stack. If you have a stack, you can just put your most recent input and output on it in a very simple and immediate way. If you ***don't*** have a stack, then you're naturally going to resort to structs, arrays, inheritance, and other more complicated strategies in order to try and achieve the same thing. Hence, my assumption that machines which don't have hardware-based stacks would likely produce more attempts at other forms of IPC in their programming.
https://groups.google.com/d/topic/comp.lang.forth/qKDbZ8JCTsE/discussion
the alloc relevant functions were provided as library, so its not the c language feature, and its just finally invoke the brk/sbrk syscall in linux system. so if you want that in forth, i guess you could do the similliar things, provide your own word and invoke brk/sbrk syscall
It's John Passaniti. He tends to have that effect... he had a long-running - as in *over a decade* - c.l.f feud with Jeff Fox (that eventually ended up consuming the whole newsgroup, since neither man was constitutionally capable of just leaving it there and walking away) which was only brought to a halt when the latter died. I'm sure John remains annoyed that he'll never get to win their argument.
Sounds like one of those guys who isn't as smart as he thinks he is.
I just went to Google Groups and made a search for the text in the subject line.
Right, it doesn't seem so much like a question as a series of complaints about implementation details. And it mostly goes downhill from there. There are occasional nuggets, but I didn't care to read it all. I'm sure if /u/dlyund would write a treatise based on his own experience, it would be an interesting read!
Right, it does seem mostly like a list of grievances. I mean, the way I use Forth, pre-parsing would be pointless for me, no matter how much code I was compiling, but why be so upset over Mr Moore's implementation that clearly fulfills some need?
* I think we can do without decomposed organic material. * OOP was developed before C even existed. See the history of Simula. I have an impression SmallTalk made OOP popular, and I don't think it was influenced by C. * The PDP-11, for which C was first implemented, has very nice addressing modes for stacks. And I'd be surprised if the compiler didn't make use of them.
As it happens, you can try it and see for yourself. SIMH runs Lisp 1.5 on its IBM 7094 emulator. But it's... weird; instead of EVAL, the top level is EVALQUOTE; you give it a function and a list of arguments, and it applies the former to the latter as is. It's not interactive, but I suspect that's more a function of the IBM 7094 not being set up for interactive I/O; however, it certainly **r**eads, **e**val(quote)s and **p**rints the result, in a **l**oop.
As an interpretation for dummies like me, is this something like byte compiling source code? Instead of keeping source code as "ASCII text" he serializes it into something that is more efficient to load/compile? And he only stores the source code in this format so when an editor wants to open it it needs to deserialize it?
Ah, still a lot to learn, thanks :) One more question - since people say here the stack is not on the cpu, it's just working on RAM memory? So the stack will be as big as much memory I provide for it to operate on?
Yes, exactly so.
&gt; Not sure what you mean by "hardware stack". Some processors have an internal stack which is not part of main RAM. The x86 is not like that. It does have a hardware stack pointer, which I have seen most Forth do use. Sorry, I'm still figuring these things out so I have a bit of a mess in my thoughts :) I meant if the stack is on the CPU or in RAM. I think you're saying it's in RAM and there are instructions that work with it like with a stack, right?
Further to u/larsbrinkhoff's points: * An implicit stack, storing return addresses, locals and partial results, is the most natural way to implement an Algol-type language; indeed, it was likely that which prompted the addition of hardware stacks in the first place - not having hardware stack support is very much a return to prior practice, rather than an innovation. What Forth does differently is add a *second*, explicit, stack purely for passing parameters - but even then, it's not alone in that; the POP series of languages did it too, as did the English Electric KDF9. * Interprocess communication is generally different from, and more complicated than, procedure calling, even under those systems which use similar semantics (eg Thoth and its descendants - one of which is QNX). Aside from anything else, you can't generally assume a shared address space; in implementation terms, queues are a better fit than stacks. * You can write Forth in any language - just pass around a stack pointer that indexes into a global array. It's not a good fit, though. The Algol-esque single-stack implementation works out to be very efficient for passing named parameters - you evaluate each one in turn, push its result, then call the procedure. In contrast, Forth has to move its locals off the stack and onto the return stack (or a locals stack), which is why they're slower than just using what's on the stack anonymously. * While it's true that some languages, like Simula 67 and Smalltalk (and more recently Java), conflated objects and processes, there's nothing inherent in objects that requires that - look at Oberon-2, for example. At root, an object is just a chunk of memory with a pointer to some code at its head - which is exactly the same as a Lisp closure, or a Forth DOES&gt; word.
Yes. At least, on the most common systems out there - the exceptions are either Forth machines that keep the stacks out of the address space altogether, or very tiny creatures like low-end 8 bit PICs.
Yes, that's right. E.g. `PUSH EAX` is an x86 instruction which will store the contents of the EAX register into RAM. The address is specified by the register ESP, which is decremented before the store.
&gt; At root, an object is just a chunk of memory with a pointer to some code at its head - which is exactly the same as a Lisp closure, or a Forth DOES&gt; word. Thank you very much for this clarification. It helps.
If tokenization is what colorForth is all about: in 1983 I owned an 8kB-ROM-computer named "Jupiter Ace" that compiled words from the REPL and provided detokenizing by looking up the threaded address in the dictionary, thereby trivially going on to look up the Name of the word. The listed (detokenized) word could then be edited as in the command line. The machine had 2048 Bytes of RAM for Video, sys vars and dictionaries. The "Jupiter Ace" did not use huffman-coded variable-length primitives, though, as colorforth does. 
It's not *all* colorForth is about, and the huffman-coding is just for individual characters, which only the editor and display circuitry needs to deal with. And colorForth compiles to native code, so recovering the source from the object code isn't possible. The essence of colorForth, really, is to make Forth's outer interpreter as trivial as possible - so that instead of retaining compiled words permanently, everything can be done by loading a chunk of source code, running it, and then forgetting it immediately afterwards. At one point I think he said something about wanting a compiler fast enough to interpret interrupt handlers, but I could be misremembering. Meanwhile, the Jupiter Ace did highlight some weaknesses of a decompilation-based system. For example, if you wrote a COMPILER word S", you'd be fine, and it'd do the right thing - but what it wouldn't do is list, or let you edit, what you input. You got the name of the COMPILER word, but it didn't know it also had to display the suffix: COMPILER S" [COMPILE] " RUNS&gt; COUNT ; : HI S" Hello world" TYPE ; LIST HI would produce : HI S" TYPE ; The same limitation hit DEFINER words too: DEFINER VECTOR 0 DO , LOOP DOES&gt; 2* + ; 11 12 13 14 4 VECTOR A 2 A ? ( prints 13) LIST A ( prints VECTOR A) (At least, I believe that to be the case; unfortunately, I'm not in a position to test it against an emulator just now.) It wouldn't be impossible to conceive of an Ace-like system which included, say, a LISTS&gt; word which regenerated the source code you'd have had to type in the first place; but I guess they couldn't squish that into 7KB of ROM along with everything else.
&gt; However, if you don't have the text interpreter - if you're relying on your editor to convert text into CFAs - then it's your editor that needs to be extensible, rather than just your decompiler... which is somewhat more complicated. I don't know if extending the editor is any harder than extending the compiler, but certainly, there are differences. Present-time execution can do a lot that compile-time execution can do but the drawing code may be more complex so in that respect you do have a point. Overall though, I haven't found it any harder than adding new "recognizers". 
I tried that but I it didn't give me any results. Maybe I did something wrong :-) it was around 3 am 
Fair enough. What I meant was that the editor has to not only work out how to display the new stuff, but also how to edit it in a sensible way; all a decompiler has to worry about is the former.
I often have trouble making time for fun projects. I think consistency is the most important thing. Work on it every day, even if it is only 30 minutes.
I am happy that this project uses appache 2.0 because that license is FOSS. https://www.gnu.org/licenses/license-list.html
Go ahead. r/programming might also be interested.
Good advice! I'll have to try that out so I get to do some things that I want to.
Good idea! Thanks!
I think the whole idea of an integrated editor as replacement of the outer interpreter in combination with JIT compilation (AHA) is an advance. Also signaling the runtime as well as compilation state though colour lead to better readability in my opinion. It is only that the language colorforth seem to be inconsistent.
Inconsistent how? But then, here's the thing. colorForth was intended to be the simplest thing that could work; if you think you can do it better, more consistently, or more simply, it's not like you have megabytes of code to work through in order to make those changes. Rather than complaining that someone else made choices you don't like, it's *always* more productive to go and make choices you do like in your own endeavour. You might find you have made things better; you might conclude that you were wrong; but you'll *know*, rather than just second-guessing.
&gt; Inconsistent how? The colors and semantics that Chuck chose may serve his purpose but they're non-orthogonal and too limited in many respects. It took us many interactions to arrive at the colors and semantics in Able. The result is, if I don't say so myself, a significant improvement over colorforth, both in terms of orthogonality and understandability. We didn't choose colors as abbreviations for common things e.g. "there seem to be a lot of definitions, so we'll make those a nice red color". We designed the language around the colors so instead of ending replacing ":" with "red" we ended up with first-class names, which as it turns out allows you to do things like defining words without parsing :-). To be clear here, I think colorForth is fantastic, but after years of contemplation, it's hard for me to say I think Chuck approached the choice and uses of color as more than a way of abbreviating what he was already doing in Forth. colorForth, *in my opinion*, is not a rethink of how Forth would work with semantic metadata (color) so much as it is Forth window-dressing with a purpose. Its design is more pragmatic than principled.
 11:45 --- The Control Loop in Mitochondrial DNA --- C.H. Ting "There is a stretch of about 1000 base code in mitochondrial DNA which does not code for any protein. I believe this stretch contains the secrets of genetic programming, which controls the growth and division of cells. I do not understand the code, but like to share some of my observations. I also believe that if God picked a programming language for genomes, he would surely pick Forth for its simplicity and expressiveness." Forgive my language but I fucking love Ting
As I understood it, one of the primary motivations for developing colorForth was Chuck's failing eyesight. Bright colours and big, chunky fonts made it much easier for him to see his code; simplifying the parser was probably a side effect... until the tail started wagging the dog. Like pretty much everything else about Forth, the conclusion that colorForth got cobbled together as Chuck needed it is hard to resist. No more rhyme or reason to it than that. Oh, and he's clearly not colourblind. \**chunters with annoyance*\*
Holy hell. Is there a paper about that somewhere? I know they'll post the slides after the meeting, but slides are a summary and I know this subject requires depth.
:-) I was responding to the very particular observation that colorForth the language is somewhat inconsistent; it's a fair comment to notice that the choices Chuck made in the context of OKAD II probably aren't the best choices for a general purpose language. I've certainly come to feel that and I've been programming in a colorForth antecedent for several years. My opinions on this matter are informed by the experience doing exactly what you suggested /u/9xlba3 should do. I have a great deal of respect for Chuck. I didn't say anything about what motivates him. Nor did I suggest that colorForth was cobbled together on a whim or that its simplicity or performance (or any of the other wonderful things about colorForth) were accidental. I completely buy that Chuck had a reason for everything that he did. That doesn't mean that I think colorForth is perfect or that it can't be made more intuitive, expressive, and more widely applicable. colorForth may be perfect for OKAD II (I've never had the please of using it) but it isn't perfect for most of what I or other people need. I would like to think that my (not always so) humble attempts to improve on Chucks improvements don't offend you that much. I'd be very surprised if Chuck would be offended by what I've said about colorForth.
I had forgotten how migraine inducing Passaniti-Fox exchanges could be.
Can you PM me the links to any threads you create so I don't have to hunt for them?
I did consult the GNU recommendation when choosing the license. Full GPL seemed like overkill since the code is already gforth specific and fairly small.
Yes, I will do that.
Great blog post, but the first comment there (citing Marx) was a great example of why I've more or less entirely given up, where trying to reach people is concerned.
Also, the title of the book he mentions here is *Technology and the Character of Contemporary Life*, by Albert Borgmann. I had to do a tiny bit of digging in order to find it. I'm going to see if I can get the ebook, because it sounds like it would be worth reading.
The Wiki summary is quite comprehensive. Worth looking at first: https://en.wikipedia.org/wiki/Technology_and_the_Character_of_Contemporary_Life:_A_Philosophical_Inquiry
Can you elaborate?
Let's just say that the last seven years, taken as an aggregate, have destroyed any faith whatsoever, that I might previously have had in anything related to Marxism. I truthfully no longer believe in collective social organisation of virtually any kind; and Reddit and what I've seen of the Millennials here has had a lot to do with that. /R/Socialism in particular is a vicious, censorious cesspool.
Teenagers in r/socialism or tankies in r/communism or whatever have nothing to do with Marxism. Reddit is not a good place to derive ideas about Marxism. Also, Marxism is not something you should have faith in. Marx spent his entire intellectual life to criticize idealism. Marxism is a way to analyze society and nothing else. Don't listen to ignorant socdems and tankies lurking around reddit.
I'm curious; what are tankies, exactly?
Marxist-Leninists, Maoists, Stalinists, and all other authoritarian state-capitalists who have never understood Marx in their lives.
Fascinating. The ML crowd are pretty much all I've ever seen, sadly. I've never really understood why that movement would be so popular, other than maybe because of aggression. From what little I've seen, Lenin was an insane monster.
Any abstraction for the sake of itself (i.e. any ideology) is simply bullshit. If you're actually interested in Marxism, please just [read](https://www.marxists.org/archive/index.htm) Marx and other related thinkers themselves, instead of listening to clueless internet teenagers.
Blah blah blah nobody understands Marx and all of other variations of the old "that's not real communism" defense. Perhaps that's not too surprising from a GNU advocate, but color me unconvinced. There are plenty of valid reasons to disagree with Marx, Marxists (classical, economic and cultural) and anyone who is attempting to implement his ideas.
Ah yes. Stay away from anyone who might be critical of Marxism, go get it from the horse's mouth, devoid of objectivity, or the problematic historical context, that you're likely to run into outside of the Marxist echo chamber :P.
O Infinite Intelligence, in whom all inspiration is, tell us the truth about ourselves in whatsoever ways we best may bear without being broken by that burden. And for those who follow your path, let their blessing be doubled. Protect thy souls, and let your work be done. Blessed be our fathers and friends. The keepers and protectectors of your beloved simplicity. [The father] (https://en.wikipedia.org/wiki/Charles_H._Moore) keeps your light. [The friend] (http://pelulamu.net/ibniz/) tells your gospel. Prosper, live, know, love. 
&gt; Marxist thinking stands contrary to natural law and human nature. So does just about every legal system in the world, otherwise it wouldn't be necessary. But the irony is that those hyper-authoritarian regimes that Marxism has engendered have, in practice, ended up more or less indistinguisable from the hyper-authoritarian regimes born of fascism; an external observer would have to conclude that extreme authoritarianism was much more closely aligned with human nature than liberal democracy - and that perhaps a degree of opposition to human nature is a very good thing indeed. Meanwhile, the term "natural law" is an oxymoron, not worthy of further discussion. (My bias: I'm an anarchist, but otherwise somewhat moderate; I always found Kropotkin and Goldman a lot more appealing than Marxists.)
&gt; Meanwhile, the term "natural law" is an oxymoron, not worthy of further discussion. I'm not sure the Hindu's would agree. I use "Natural law" as the closest English translation of Dharma. I admit it's not a perfect translation. Thinking *laws of physics of human interaction* will put you in the ballpark. Of course, you're free to think whatever you like about that but it's usually better to ask for clarification than it is to declare superiority and move on :-). I mostly agree otherwise. (My bias: I'm a monarchist, but otherwise quite moderate. I largely agree with the founding fathers of the United States when they wrote that democracy is the worst form of government, but I prefer the idea of a constitutional monarchy to that of a constitutional republic because at least with a monarchy you know who to hang, or hold to account, if you prefer, when, inevitably, the system gets tired and is in need of a reboot. I like my government the way I like my software. Easy to understand, and just as easy to kill ;-))
You could just have used the word "dharma"...
The slides of the other talks will be available [here](http://www.forth.org/svfig/kk/kk.html) soon. I briefly mentioned BIND in anticipation of questions about scoping. Apologies for not asking you first, /u/dlyund.
What a pleasurable source of forth info. Thank you very much for sharing. I am surprised, I was not aware of it.
Wow, I finally made it to a Forth Day - at least by proxy. ;-) **ed.** Also, I've just realised: the Jupiter Ace had BIND too. It called it REDEFINE. **ed.2** Damn, I should have checked. REDEFINE &lt;*word*&gt; only updates the previous definition of &lt;*word*&gt; to point to the most recently defined word, whatever its name (and it'll work with any kind of word, not just a colon definition). So not *quite* the same thing - less general. But a similar idea.
Well written. Bravo! 
Re your edit: I completely agree wrt those who seek power being those who shouldn't be allowed *anywhere near* it. And yet, even those who don't seek power can end up abusing the crap out of it (I believe that's the technical term, yes? ;-) ) when they suddenly realise they have it. The mode of powerless (and hence responsibility-less) thinking is *really* hard to shake. And as Lord Acton noted, power tends to corrupt, and absolute power corrupts absolutely. Without some effective restraint, anyone who's handed absolute power will go off the rails; nobody is strong enough to withstand the allure. A robust constitution, with a presumption of self-government and only those powers hoisted upwards which are delimited by that constitution, would be a good start; however, if the lesson of the States is anything to go by, any time you write something down, an industry builds around finding the loopholes in it. Nonetheless, the insistence of certain people in the UK that this can't be done with a constitution that isn't codified in any formal way runs counter to the facts; the idea has been tested to utter ruination in the last forty years, and unfortunately it's abundantly clear that a constitution of assent, practice and convention might as well not exist at all. It's a quandary! I've long wondered whether the only real solution is to build power in rigorously bottom-up structures; that on the level of a village or district, representatives are chosen in a manner similar to jury service, and also at random, one of those representatives is chosen as a delegate to the next level up. The executive level is that of the district, but funding decisions go all the way up the chain and back down again.
I don't know what this means. Care to explain? I never defended anything, I just pointed out that 99.999% of "leftists" never read and understood Marx, which is objectively true.
&gt; but even before I knew who they were, the concept of authority has always scared the crap out of me, on a visceral level. Read [this](https://www.google.com/search?q=libcom+karl+marx+and+state&amp;ie=utf-8&amp;oe=utf-8&amp;client=firefox-b-ab). All Marxists are wrong and stupid because none of them ever read Marx.
I really don't care what you think about Marx. You can think whatever you want.
And how is that not just a different dressing on "no true Scotsman"?
Did you read the article? If you read it you'll see what Marx *himself* wrote. I don't care what other people talk about Marx, all his writings are accessible by public, I know how to read, and I read him. There is no Scotsman. Marx spent all his time to argue against idealism but you're saying that Marxism is an ideology. Look, this is like saying Nietzsche was a nihilist; teenagers think he *was* a nihilist although he spent all his intellectual life to attack nihilism. It's the same thing when people say stupid stuff about Godel's incompleteness theorems; if you don't understand them, you should not have a right to have an opinion about Godel's theorems. Period.
&gt; Marx spent all his time to argue against idealism but you're saying that Marxism is an ideology. I'll thank you not to put words into my mouth. I said, and as it happens I believe, no such thing. And since you spent the rest of your comment battering that strawman (you're big on the logical fallacies, you know - you should get that looked at) I don't see that it's worth responding to further. Except for: &gt; Did you read the article? I skimmed it. I thought Marx's comments hopelessly naive and Bakunin's realistically, reassuringly cynical. It would appear that history has tended to support Bakunin's, rather than Marx's, view of the world.
One last thing: &gt; if you don't understand them, you should not have a right to have an opinion about Godel's theorems That sentiment is outright dangerous. For one thing, holding opinions about what we don't fully understand is pretty much a necessary condition of day to day survival. For another, your whole argument here is begging the question. The presumption, unstated but clearly implied, is that anyone who truly understands Marx will agree with you - which then become the test of true understanding... alternative readings are simply not permitted, ideological purity is the defining criterion of worthinesss, and - down you spiral into a cult. If you think someone's opinions are wrong because of incomplete understanding, the onus is on you to demonstrate that. And you'll only ever do that effectively if you have the humility to accept it when someone comes along and schools you in turn, which frankly I'm not seeing. Never, *ever*, is it justifiable to say that someone has no right to hold that opinion because of their incomplete understanding - unless you are prepared to accept that you, in turn, do not have the right to your own opinions, on the grounds that there is always someone whose understanding is more profound than your own. And if you won't admit that, you have achieved a level of arrogance and egocentricity that quite undercuts any ideas you might have about your own commitment to egalitarianism.
^([*citation required*])
Section 5.3 in LISP I Programmer's Manual describes interactive use with a Flexowriter. http://bitsavers.org/pdf/mit/rle_lisp/LISP_I_Programmers_Manual_Mar60.pdf
I'll try and put aside the fact that this is probably just be another one of your rambling, incoherent, opinion pieces for the moment: are saying that the assembly does register allocation/renaming/something so that "words" compose without using a stack? Or that they act like local variables, because of something akin to register windows? Other than the fact that you diddled your friends syntax to make it look like Forth rather than having to explain the actual syntax, want relationship does this have to Forth? Is this just your first exposure to an assembly language and you happen to be drawing some parallels with what you know about Forth?
The line "that wasn't real Marxism/socialism/communism/whateverism" been used to excuse atrocities committed by proponents of and as a result of Marxists ideas after every attempt that was ever made... The implication is always: the reason it failed is that they weren't the real Marxists/socialists/communists/whateverists and they didn't really understand Marx's idea's, *like I do*. If only they'd actually read and understood Marx's work -- *like I do* -- then the worker's paradise would have been a huge success! I should be in charge! Other's will recognize this as the No true Scotsman fallacy and reject it artfully. The self-proclaimed Marxists will eat this shit for breakfast, lunch, and dinner. Literally, every Marxist hellhole (and it's fair to say that the designers of hell ain't got nothing on Marx) by any other name that's ever existed has come about because of people who -- like you do -- believed that you had some secret understanding and that you could make it work. No. Those were "real" Marxist/socialists/communists/whateverists and what they did was "real" Marxist/socialism/communism/whateverism, in the sense that any interpretation is "real". Those people have killed 120+ million people in pursuit of their Marxist ideals... almost twice as many who were killed in world war 1 and 2 combined, on both sides, by some estimates, but try as we might there's always another one of you, weighing in the wings, ready to make another run at utopia :P. The fact that you don't recognize any of this -- just like you didn't recognise that Karl Marx was an absolutely atrocious human being who milked his family and friends for every penny he could get; beat his wife, impregnated his once housekeeper, and left [all] his children in poverty; and let's not forget hom he falsified facts and sources in his work and didn't himself practice any of the things that he wrote about -- he was a greedy, selfish, abusive, immoral and intelectually dishonest man -- I will admit that I found his idea's quite appealing when I was a younger but I've come to see that he was, at best, chalaton, who couldn't manage his life, and who, rather than dealing with his many personaly failings, wrote about his own personal paradise -- is what I referred to as the Marxist echo chamber. I know you don't care what I think of Marx, but maybe you could, I don't know, try to read something like Paul Johnsons, Intellectuals, which goes into detail about the man, his character, and the life that he lived.
I am proposing a way that you can program registers very similar to how you program forth with a stack. It's actually quite a fun experience.
&gt; as Lord Acton noted, power tends to corrupt, and absolute power corrupts absolutely. Without some effective restraint, anyone who's handed absolute power will go off the rails; nobody is strong enough to withstand the allure. I mostly agree, but we shouldn't forget that throughout [world] history there have been many truly enlightened rulers who sacrificed everything for the good of there people and the future. They may be few and far between but when they appear, that's when all real progress happens e.g. it was due to so-called enlightened despots that (personally I think this was a mistake) our liberal democracies and the institutions that support were established. I would be very interested in a system that can be said to credibly maximise the appearance of such people, but I know of no such system so I prefer the simplest one, that's been shown to work reasonably well and which seems to be the easiest to dismantle :-). &gt; It's a quandary! It is indeed ;-). I generally like the idea of a constitution, however, we've how easy it is for government to ignore it when it suits them. So I see no particular problem with having an unspoken constitution, but I see no way to force those in power to respect it except with at the edge of a sword (2nd amendment). The Chinese have an old story about how the first Emporer had the laws inscribed on the side of a great cauldron which noted how the people began manipulating the language. If I recall, the Sage recommended that he destroy the cauldron and appoint a person of good character (think King Solomen) and good judgment that the people trusted to resolve disputes. The result is the longest continuous civilization in recorded history ;-). We know how our own tradition how unimaginably complex the law can become when we start writing them down... competition over the interpretation of the law ties the state in knots. English common law is a good example of an effectively unwritten law; it's mostly common sense. If you need to write this stuff down then I suspect The Constitution of the United States of America is about as complex as it can be allowed to become before chaos ensues e.g. look at how much trouble the words "common welfare" and the provision for regulating interstate trade has caused. In the hands of lawyers and judges, these few words lead to effectively unlimited power! It's a pandora's box... &gt; I've long wondered whether the only real solution is to build power in rigorously bottom-up structures; that on the level of a village or district, representatives are chosen in a manner similar to jury service, and also at random, one of those representatives is chosen as a delegate to the next level up. I've wondered that too. Up until relatively recently, I would have probably supported something like this but I've come to recognize that while atomizing power might be a great way to protect from internal abuses it leaves us wide open to external forces. The situation being what it is today, I think we need to understand, if not accept, that our ideas of radical individualism (and the negative effect it has on community, and social cohesion) and placing limited power in the hands of people those we know aren't able to wield it/worthy of it hasn't worked. (From an outsiders point of view) the American Constitution no longer seems to apply. I might not like it but I can't deny that an atomized individual is no match for and cannot stand up to a collective, bound by their shared interests and that different groups of people inevitably have different interests :-). Anyway, maybe there isn't a perfect, one-size-fits-all state structure? :-) Perhaps, like in Forth, the solution can only be understood in the context of the problem to be solved and we have to adapt and roll with the punches. Different structures may be required in different situations. In a time of peace, where the society/nation is of one mind then liberal democracy may well maximize freedom (it seems to ludicrous degrees), but when it's not, we need something else :-)
Ok, but how do you handle the composability problems that are inherent in the use of registers? You haven't explained that. I'm beginning to think that you haven't thought this through far enough to see why it doesn't work in practice.
Given the arity of each word is known and static as well as words have no dynamic state, it is possible to compile stack operations as direct or indirect register references with minimal effort, requiring only stack balancing in case of (subroutine) branches. 
:-) so implementing a stack with register? That's well and good but then I really don't see what he's trying to get at here
&gt; I briefly mentioned BIND in anticipation of questions about scoping. Ooo, so you did :-). How did it go down? &gt; Apologies for not asking you first Not to worry. I was a bit surprised to see myself in there though ;-)
:-) It's weird to think I came up with something that's so obvious in hindsight.
/u/read_harder -- I think you should demonstrate a working, complete program using this method. Even better would be a modified Forth compiler that can generate this code. Without some real meat, it's either (a) impossible to figure out what you're trying to say, or (b) too time-consuming to start writing out the reasons it doesn't seem like it would work. I'm not trying to be mean, but I think if you even just went so far as to sketch out calculating a factorial with it, you'd figure out why the compiler will have fits with this kind of register allocation without having a stack around to help out.
Would it be fair to say that names in Able are more akin to symbols in Scheme than to traditional Forth names? If so, have you ever made use of that to do Scheme-like symbolic computation? &gt; hierarchies of vocabularies, implemented as linked lists, are very powerful, but they're complex and comparatively inefficient They are, but I remember reading about the University of Waterloo, who in developing their Pascal compiler, ditched their complex hashing scheme for a linked list of identifiers when they realised that most student programs were too short to hit the breakeven point. The way Chuck Moore uses colorForth is similar; he'll only have a few dozen extra words defined (indeed, there's only room in the colorForth dictionary for 512 words on top of the base system) at any given time. Of course, he also stores only the first few characters of a name - as many as will fit into a 32-bit word - and his dictionary search is basically `REP SCASD`... Oddly enough, using names as first class objects lines up quite well with position-independent native compilation on the x86 - because it doesn't have an absolute direct CALL instruction but only a relative one, if you move a compiled word after it's been compiled you have to either recompile it or find and change all the offsets. But there's an absolute *indirect* CALL, which doesn't have to be changed, and which lets you compile relative jumps for control structures and indirect CALLs to other words. Not as efficient as compiling direct calls, because each CALL will be mispredicted the first time through, but in loops they'll catch up. 
I think that may be a mischaracterisation of egalitarianism. Clearly, everyone has their own gifts - and their own flaws; no two people are the same, or have equal abilities in anything. Egalitarianism, it always seemed to me, was much more about decoupling this recognition of a simple truth from the implication that some people are *worth* more than others... and that implication, egalitarians would argue, is the *real* root cause of inequality. In the words of one of the great philosophers of the modern age, Esme Weatherwax: &gt; Sin, young man, is when you treat people as things.
I think it's more likely that you just don't understand how it works.
I'm not sure exactly what you're saying with this, but allocating registers like this wouldn't work like a stack. Consider the word -. Judging from your definitions, this would take reg0 and reg1, subtract reg1 from reg0, then put the result in reg0. The problem is when you have more than two numbers on your "stack". Consider this code: 3 6 9 - - Your compiler could put 3 in reg0, 6 in reg1, and 9 in reg2. But this code wouldn't result in 3 - (6 - 9), unlike a stack, because in this system, - only deals with reg0 and reg1. It doesn't even touch reg2. You could fix this by introducing a stack pointer to keep track of where the top of the stack is, so that you can add the top two items, but then you just have a regular old stack.
Can whichever inadequates are conducting a war of the downvotes in this thread please **knock it the fuck off** and let the grown-ups talk? Thank you.
It would look something like this. Subtract reg1 from reg0 and store in reg1. Store a new number in reg1. Subtract reg1 from reg0 and sore in reg1.
&gt; Subtract reg1 from reg0 and store in reg1 6 9 - \ -&gt; -3 The result should go in TOS obviously, so reg1 is TOS? Then you just switched how - works in forth. &gt; Store a new number in reg1 So you're saying you'd move the values in order to accommodate the fact you lost a value from the stack when doing the -. But in reg1? That's TOS where you stored your result. In all seriousness, are you even *trying* to have a conversation with these people? You show almost 0 effort with posts like this. Could the the mods finally recognize this person as a troll?
On a more reasonable topic, would it make sense to use x86 registers for implementing a stack? Is there a forth that does that? Would it provide considerable speedups compared to having a standard stack in memory?
:) there really aren't enough registers to do that but in principle it can be made to work. I wouldn't do it. It's not uncommon to cache the top 2-3 items of the stack this way, but implenting the whole stack seems a little contrived.
x86-64 basically defaults all its jumps and calls to be relative. It's actually kind of a fight against the processor to make it jump anywhere absolute.
So you're literally just a register machine with the usual 3 operand instructions, and you're calling this similar to Forth. Do you understand that the reason for using a stack is so that words compose; so that you can, you know, factor code into words and reuse it? Without a stack (Forth-style or otherwise) you'll need to keep track of which registers each subroutine is using and manually shuffle values between them (or store to memory) when you figure out that you've painted yourself right into the corner. And good luck modifying a subroutine (perhaps to fix a bug) without breaking everything and having to go back and manually reallocate all of your registers... It doesn't work. THAT'S why the stack was invented and why every architecture today has some support for a stack! The fact that you think this very standard [toy] assembly language has any relationship to Forth shows just how much you have to learn. The sad thing is that you seem completely unaware of how ignorant you are.
&gt; Would it be fair to say that names in Able are more akin to symbols in Scheme than to traditional Forth names? If so, have you ever made use of that to do Scheme-like symbolic computation? They're more like symbols in Lisp than Scheme, to which you can attach any amount of arbitrary data. I make use of them quite often, usually in place of enums and constants, when it makes sense. I don't think Able much better for doing symbolic computation than Forth is; both lack the convenience of Lisps first-class nested symbolic *expressions*. What first-class names let us do is to write programs that manipulate names. &gt; They are, but I remember reading about the University of Waterloo, who in developing their Pascal compiler, ditched their complex hashing scheme for a linked list of identifiers when they realised that most student programs were too short to hit the breakeven point. I'm sure that's true. We don't use hast-tables or linked lists. Our solution here is much simpler than using hash-table and as mentioned, we have constant time access to names. It's a balancing act but I feel pretty happy with the tradeoffs we've made. Any further details will have to wait though, sorry. Thanks for the details about colorForth :-). That's quite an interesting idea. I have no doubt that Chucks approach is more elegant than mine is there.
Probably his intention was some kind of static stack caching. Sadly I can only guess because the description remind me more of a mental draw than an explanation. Maybe the author finds the time to work out his idea in deep and conclude mentioning it goal.
Is there a culture of using Forth at NASA?
to my knowledge yes (NASA and ESA) as it was obviously the best choice programming these space-radiation `resistant` Harris RTX processor variant. I think a similar demand was caused by using the 1802 cpu (probably Voyager?) within a very resource limited hardware environment.
So the thing to keep in mind is that I am proposing using four registers instead of using a stack. So if I implemented it in forth it would have to go onto the stack, however if I implemented it in a forth that came without a stack you would be manipulating the registers directly with no stack as the middle man.
What I am proposing is that by using registers there should still be a way to factor subroutines into words. The difference is in forth the location that things get put at is implicit. You implicitly push and pop from the stack. With registers it is explicit. You declare intentionally which register you want to go to. But no reason you shouldn't be able to factor your code too.
That makes sense.
Like I said, the sad thing is that you don't realize how ignorant you are. This is just like that time you argued blacks-white that linked-lists were more efficient than arrays, even after multiple people took the time to explain to you how they obviously weren't. You can choose to believe it or not this is some fantastic revelation. What you've "discovered" is just assembly. Register machines and three-operand instructions have been around "forever". Of course, you can program this way, but nobody does it, because as I explained, keeping track of which registers are used by what and when is a nightmare. It does not work. You cannot compose the resulting words. changing just one "line" in just one of them can mean an almost complete rewrite of your program. Hence the stack, and why even register machines have one. It's the best solution to the problem. As others have suggested to you here, if write something even as simple as factorial you'll find out why what you're "proposing" is, forgive my language: SHIT. Your posts aren't downvoted because people dislike you as a person, they're downvoted because they're nonsense. Wake up. Have some humility. Then you might learn something.
He's talking about programming in assembly for a machine with 3-operand instructions. The norm. This is only confusing because he thinks he's invented something that's been around forever. He's proposing that, instead of using the stack and having subroutines compose effortlessly, we do register allocation in our head, and pray that we never have to touch the code ever again.
I'm sorry you find it distasteful, could you tell me how else to interpret your anwser? I gave an explanation why your example was bad in at least 2 ways. You give me no reply on it, just that you find it distasteful. Well most people find it distasteful that you don't give much thought into your replies. And your proposal - it's nothing new. Try to look at some implementations before taking credit? You really need to study and code more and write less. Otherwise you are just spamming and wasting other people's time.
I'm sure that you are serious about programming in Forth, but, like with many of your posts here, your obvious misconceptions would be cleared up in the first semester of any half-decent computer science course. Either you've been to university and you're literally retarded, or you should go, assuming you can afford it and you can get in. And if you can't then maybe you should watch some lectures online, because it's scary how much you don't know. The only thing that scares me more is that you seem to think every half-baked idea that flashes through your head is a revelation that desperately needs sharing with the world You are the man who's discovered that he can use his shoe as a hammer, and you're running around town proudly telling everyone about your amazing discovery, and getting angry at them for asking why your shoe has a dozen little holes in the bottom... *Passes you the hammer*
&gt; That being said if you had a forth that also had registers heres how I would implement it. The virtual machine we designed for Able is an idealized stack machine but it has 256 virtual registers. Their primary purpose is for accessing memory but they can also be used for temporary storage. This is useful when dealing with more complex mathematical expressions, but as explained previously, you have to be very careful using these because they don't compose well. As such we take the stance they should only be used this way in the very lowest level words and should only be considered valid until the next CALL. This limits their utility significantly but it's better than spending days hunting for bugs because the implementation of some word changed somewhere in the system changed and it's clobbering one of the registers you're using. &gt; First of all I am not sure if the stack actually resides in memory or not. I was told that to fetch from memory with @ takes a long time so I am assuming that the stack is not in memory but on the processor. The stack is usually in memory on register machines and first-generation stack machines. One of the defining attributes of second-generation stack machines is having on-chip stacks, where, for all intents and purposes, access to the stack is as fast as accessing a register. But you probably don't have a second-generation stack machine so it's a fair assumption to say that accessing the stack (memory) is going to take more time than accessing a register. It is a register machine after all. What do you expect? One common technique on register machines is to cache the top few items of the stack(s) in registers. Items below this are likely to be in the cache, since they're both temporally and spatially local, but things get swapped out of cache all the time so it's not quite a simple as that. Either way, maybe you should investigate how computers work before you make such leaps? Phrases like, "I was told that fetch from memory takes a long time" don't inspire much confidence. You clearly have a lot to learn about computer architecture but for some reason, you seem to prefer dancing around in your head and coming to wild conclusions than reading a book and learning about how things actually are. Ask yourself this: what problems can you solve without access to memory outside of the processor? &gt; I learned alot from forth and I thank you all for all my help You're welcome. &gt; What I learned the most from forth is that stack based processing is a very powerful syntactic feature. Still babbling about syntax I see.
If you want to take advice from this group of people the one that was offered the most is - read instead of writing. You too often look like trying to explain the bible to the priests even though you haven't read it. Please take a moment to think about it? Explaining low level implementation but not knowing where the stack is? I don't think anyone is taking you seriously at this point. If you want to be a theorist only, ok, but learn the essentials first. If you want to be a programmer, start programming. Good luck on your journey
Thanks for the advice.
I am certainly not taking credit. I got the idea from another person's assembler code. It even says so in the title of the post. Perhaps you should read_harder
Who said I was angry?
I don't have to learn anything whatsoever about computer architecture. I am a high level programmer. I don't work on the low level end of the stack.
Is it not true that you could keep the stack either inside or outside of the cpu depending on the architecture?
Juggling only happens when you've got more than two parameters on the stack at once.
&gt; I don't have to learn anything whatsoever about computer architecture. I am a high level programmer. hubris ˈhjuːbrɪs/ noun: hubris excessive pride or self-confidence. "the self-assured hubris among economists was shaken in the late 1980s" synonyms: arrogance, conceit, conceitedness, haughtiness, pride, vanity, self-importance, self-conceit, pomposity, superciliousness, feeling of superiority; More hauteur; informaluppitiness, big-headedness "the self-assuring hubris among economists was shaken in the late 1960s" antonyms: modesty (in Greek tragedy) excessive pride towards or defiance of the gods, leading to nemesis.
You're a high level programmer who's writing about and making decisions based on properties of computer architectures and you don't think you need to learn anything whatsoever about computer architecture in order to do that? :P And then you wonder why people think you're a troll... I don't think you're a troll btw. That would require a level of understanding that I don't think you're capable of. I don't think your a troll. I just think you're an idiot. Best of luck with your future :P
Perhaps you should think_harder :P
"...depending of the architecture" of what? The CPU? The language implementation? If the hardware is a conventional CPU the stacks will live in memory. In a modern CPU that means the stacks will live in various levels of cache memory depending on how the CPU manages the cache memory. If the CPU is a Forth machine it depends what the designer built. Some simple Forth machines have 2 dedicated memory areas that are the stacks but there is no royal proclamation that mandates that approach. It just happens to be faster to do it that way and as always it has other shortcomings that need to be managed.
For me personally it seems easier to jugggle four registers than to juggle a stack.
It is not hubris. I simply do not have to learn low level programming to do a high level programming job. It is not a requirement for the kind of work I plan to do.
I am most definitely not a troll. I am very serious about forth.
I don't have time to read every single book.
So then the @ operator takes up no more resources than the stack operations do.
you not need juggle with register, the value has a name, the name of register, in the stack the value no has a static name! I'm curios about you. You code forth? have programs in open source?
https://www.youtube.com/watch?v=Bg21M2zwG9Q
One book. One book on computer architecture, and you would know all of this and wouldn't look like such an idiot. Think of all the time you'd save by not spending months exploring obviously dumb ideas that have been explored and shown not to work. Your name is read_harder. Maybe you should take your own advice :p
I have been studying forth for about a year
I terms of computer architecture I am admittedly dumb and remain dumb by choice because my work isn't anywhere near computer architecture. If my work required me to learn computer architecture then I would learn it. Part of reading hard is not wasting time reading things that do not help you solve your immediate problem. I can not read everything under the sun. Just key things I need to help me solve problems.
You're so full of contradictions it's a wonder you're able to function in the world; I've never met someone so full of shit. You are the same person who lectured us endlessly about how we shouldn't think about problems because problems aren't interesting and how you're interested in solutions for their own sake :P.
As soon as you're talking about registers and memory read timing, you've entered low level programming. Heck, these days a lot of people consider C a low level language!
A cpu- resident stack will be fast, but who uses @ to read from the stack? @ is for reading the vast off- chip memory, primarily. And C doesn't help you, because every time you dereference a pointer, you're doing the same thing as @.
You might check out mecrisp forth -- it implements some basic register allocation based optimizations as it compiles words to naive code. The code is surprisingly transparent and easy to follow. 
 I learn C before FORTH and IMHO is better FORTH. my advice make programs for any kind first, learn asm if you worry about registers learn C if you like, look my forth too!
&gt; So the thing to keep in mind is that I am proposing using four registers instead of using a stack. I replied to this. It says **I am proposing**. Since you can hardly explain your thoughts it's hard to differentiate what your friend came up with and what did you add to it.
That's fantastic. It doesn't matter whether you need to know this for your work. You do need to learn this stuff if you're going to engage in discussions about it. Otherwise, what are you doing here? That's pretty self-explanatory, isn't it? :P
&gt; You too often look like trying to explain the bible to the priests even though you haven't read it. In reality, I'm close to as ignorant as he is; it's just that not only have I read probably two different books on FORTH, (POL and Thinking FORTH) I've also done a tiny bit of Lua scripting in Minecraft, and reading about FORTH has made me realise just what a noxious, virulent ***disease*** Lua really is. Part of me thinks I am being unfair to the Lua developers, because the language has apparently helped children learn to program; but then again, given the nature of what said children have most likely learned, that actually makes it worse. ;)
&gt; To me using four registers just clicks a lot better in my head than using a stack. It is like having a stack minus the juggling. Please, if you can, tell us a concrete experience you had. I am considering following your lead. 
&gt; To me using four registers just clicks alot better in my head than using a stack. It is like having a stack minus the juggling. Please, if you can, tell us a concrete experience you had. I am considering following your lead. 
&gt; First of all I am not sure if the stack actually resides in memory or not. I was told that to fetch from memory with @ takes a long time so I am assuming that the stack is not in memory but on the processor You are implying *a specific architecture*, which I expect to be a standard x86 architecture. And where the stack resides is *completely* implementation dependent. Since the x86 is register based many implementations cache some top items of the stack in registers.
I made a mistake and looked at your profile here on reddit. I admit taking 30 minutes out of my life to look around. I'm pretty sure you won't care for my advice, but here goes - please go see a psychologist. You seem like a nice and active person but really deeply damaged. You also seem to be seeking far too much attention, control and posession (especially for someone creating subreddits like u/noposessions). You are full of contradictions, and probably internal struggle and pain. Others reading this, you were warned.
More details and the sourc to generate this are at [http://www.complang.tuwien.ac.at/forth/family-tree/](http://www.complang.tuwien.ac.at/forth/family-tree/). I also have a text formatted variant of this at http://forthworks.com/forth/family-tree.txt or gopher://forthworks.com/forth/family-tree.txt
why not add a support for addresable L1 cache? that might fit your needs
its cool, will you add link for each forth? i cant find some especially those has a common name
I didn't say you shouldn't think about problems I said I like to think about solutions.
I am not sure I understand your question.
Not every single person needs to learn low level computer architecture. Only people who work on low level computer architecutre need to learn low level commuter architecture. A reader is not measured to be a good reader based on whether of not they've specifically read about computer architecture. There are many good readers who have lived and died before computer architecture ever existed.
Here is some code I am working on which might explain it better. https://github.com/johnmorrisbeck/forth-registers
Which mental illness do you think that I have?
https://github.com/johnmorrisbeck/forth-registers
imho forth is more about describing the particular application with words than it is about preemptively building data structures. But when I want a tree, I'm a fan of just using [implicit k-ary trees](https://en.wikipedia.org/wiki/K-ary_tree#Arrays) because they're super simple, you can edit them in a hex editor, and you can use them over a stack to turn a stack into a tree if you so choose (think [parallel concatenation](https://suhr.github.io/obsc/)) Here's some binary tree words defining `{` and `}` as words to traverse into and out of branches. : ,c here c@ 1 allot ; ( fetch-comma, like c, but it fetches instead of stores) : s 1 allot ; ( skip over node ) : .c ,c . ; ( pop a node from the tree and display it ) variable root : there here root @ - ; : where. there . ; : { there 2* allot ; ( to child node) : } there 1- 2/ root @ + dp ! ; ( to parent) : tree: create here root ! ; tree: binarytree { 0 c, { 1 c, 2 c, { 3 c, 4 c, 5 c, 6 c, } } } } ( build the tree with values) cr { .c { .c .c { .c .c .c .c } } } } ( display tree contents) cr { s { s s { 8 c, s s s } } } } ( traverse tree to modify a node) cr { .c { .c .c { .c .c .c .c } } } } ( display tree contents) binarytree $20 dump You could change `2/` and `2*` to something else without modifying the tree itself. You could probably also mix arities if you keep track of them in your lexicon. 
There's no question in that reply. And you're surprised to be called a troll :) If you don't understand read it again, I don't know how could I explain myself better.
&gt; If that's the case I would put the registers on the processor as well to go along with the stack. maybe only 8-16 registers max are needed. I can get by with 3. So don't teach others how to design the low level computer architecture. Stop trolling. 
I wasn't trying to teach others about low level computer architecture. I also am still not trolling. I am very serious about forth.
I read it a couple times I still don't understand what you mean.
Why would you need to be mentally ill to visit a psychologist? I'm not a doctor (or an oracle) to diagnose you, I just think you are struggling with the world and a psychologist might be able to help you. You said you studied forth for 1 year. If you produce code like [this](https://github.com/johnmorrisbeck/forth-registers/blob/master/forth-registers-demo.forth) after 1 year I think nobody should take your thoughts and suggestions seriously. Since I've seen you delete things after you didn't like what happened I'll paste the *first 4 lines* of that file here for reference: ( Registers are stored in an array in memory ) variable registers ( I choose to have four registers but you can use more if you want. ) registers 4 cells allot There's 2 glaring errors there. If you can't understand basic words like variable/create and count how many arguments on the stack are expected from a word then forth isn't for you. Actually, a friendly suggestion, no programming language is. I hope this public announcement of yours (as if you were an important person of this subreddit or that everyone cared) was your last post in this subreddit. If not I will keep asking the mods to ban you.
 This is full of wisdom as far as the Jupiter Ace goes. I vaguely remember that the issue is briefly discussed in an appendix of the user manual, as are the differences in metaprogramming, due to detokenizing for editing. That being said, I don't remember issues with that and did not quite understand the disclaimers of that appendix. Your elaboration made me curious, so I tried to retrieve the original user manual from under the arches of my vast library of old computer books after all those years, but so far to no avail. As for colorforth, I took only a cursory look at it, so I did not really get its objectives, apparently. It is most certainly avantgardistic, but does not solve any problems I have with forth. 
Fear not! The user manual can be downloaded in PDF form from [the Jupiter Ace resource website](http://jupiter-ace.co.uk/documents_index.html). As can a number of emulators.
This might not be what you asked for, but this probably how I'd do "lisp" like consing in Forth : cons here -rot , , ; : car @ ; : cdr cell+ @ ; nil 3 cons 2 cons 1 cons Or with a little window dressing : . cons ; nil 3 . 2 . 1 . OR : ( ; : ) cons ; ( ( ( nil 3 ) 2 ) 1 ) NOTE: everything is written in reverse, but what did you expect from Forth ;-). NOTE: I haven't tested it but it should work. That's probably the closest I'd like to get to Lisp this side of Christmas but it works and as you can see, it's very simple. Overall I would agree with /u/pointfree when he says &gt; forth is more about describing the particular application with words than it is about preemptively building data structures But if you want to, nothing's stopping you. Personally, I would suggest learning how to program in Forth (forgive me if I'm preaching to the choir), rather than trying to do Lisp in Forth. You could write parsing words to replicate Lisp's syntax but this is going to be more complex. As complex as parsing Lisp. You'll probably end up using a fair bit of stack space because you'll need to keep all the values you see around until you see the closing parenthesis. With this approach, you only ever need to have 3 items on the stack.
I couldn't find LaFarr Stuart's LaForth. That had some interesting innovations.
I do not know laforth. I found the manual and I'm surprised by almost the same control structures that I use in my language
I used graphical names for control structures similar to LaForth for a while, but I eventually switched back to spelled-out words. I think LaForth's most lasting influence on my homebrews is the execution of words as each space is encountered instead of buffering by line.
How do you implement parsing words? Do they read from the input source?
I thought we were above this kind of talk here at /r/forth ? Surely we can all recognize that Lua, like Forth, is a tool and has its own range of uses.
I can't help thinking this needs a better name: less passive, more - well - imperative, and with a nicer acronym... or maybe not an acronym at all. "Assertive programming", maybe?
I use a key map (*responses*), each key has an associated behavior, e.g. space and carriage return's associated behaviors are set to *delimit*, the entries for printing characters are set to *accepted*, etc... *parse ( asc -- )* temporarily supplants the desired delimiter character's entry in *responses* with *delimit*, and space with *accepted*. *parse* then calls *token*, which is the same word that the outer interpreter uses to get a token from the current input source, it just repeatedly gets characters and performs and performs their keymap responses until *delimit* causes it to stop.
I don't have a collection of links for these :( My ASCII chart is based on the same data (mostly Anton's chart &amp; the [Usenet postings](http://www.complang.tuwien.ac.at/forth/family-tree/postings)); IIRC the images on his site are image maps, with links to at least some of the systems.
ok will go and check 
This code is currently broken and won't even fully load under Gforth.
Post titles are like come-backs in an argument, you always think of a better one 5 minutes later.
I'm sorry, I just...I know it does, but have you spent a lot of time with it?
[removed]
Thanks, that's interesting.
Two years earlier: comp.lang.forth doesn't like R&gt; DROP. https://groups.google.com/forum/#!topic/comp.lang.forth/b0rpNOd8WF8%5B1-25%5D
My pleasure.
R&gt; DROP breaks tail-call elimination.
I really liked this presentation. Without the formal thought on the matter, I have been trying code like this this for years. Having this "declared" and explained with examples is very helpful for making decisions in the midst of programming Forth. My code will be better for having seen the presentation. Thanks Samuel
An interesting read, thanks. I keep thinking now though, do forthers use top-down development? I know Chuck says to use bottom-up. It's also harder to try things out interactively when starting at the top. With that being said I sometimes have a hard time to start at the bottom. Maybe bad habits die slowly? :) Anyway, interested in the group's style.
Very pretty. This makes me think of how to get rid of case / endcase. One question though: is there a way to achieve short circuit evaluation? In the example where the code is handling an input keystroke, can we keep it pretty and skip all the rest of the tests once we know it's an "up"?
You can return from the caller its `R&gt; DROP`
I think if children are learning Lua, that indicates that it is, at some level, intuitive. However it is true that Lua depends on tables and metatables to use effectively, which I doubt anyone learning it will just "pick up." Having said that, it is a pretty good language for learning about the concept of Objects and polymorphism, since those are all things you construct yourself using tables and metatables.
Is that how people use Throw in Forth? Hmmm. I ended up with doing my own spin on it, Try-Catch-Release, but it saves away both stacks for analysis. That's not exactly a lightweight functionality.
you are right. did that. thanks. 
I think the rule of thumb is "design top down, code bottom up" That way you catch the false assumptions in your design on your way up. Forth makes bottom up coding pretty simple if you are working from a design document where the low level functionality is defined. And if you test as you go, which is simple and for me necessary (I am not very smart), your pyramid of low-level code is quite robust. 
Chuck made mention in Thinking Forth of starting with the fun bits (p91), in order to get traction on a problem. That always seemed appealing to me.
I usually start with the murky areas, i.e. areas where potentially far-reaching dependencies need to be pinned down and resolved yet I lack an intuitive grasp of tradeoffs and consequences. *Here be dragons*.
&gt; it's all too easy to find yourself in a situation where a word does exactly what you want, except that it R&gt; DROPs one time too few or too many. On the other hand, using THROW/CATCH is [...] much easier to reason about, and will always get back to where you think it should. `R&gt; DROP` skips its caller (unless the implementation gets in the way), I don't see anything simpler to reason about coming along :) `TRY` and `CATCH` seems simpler than in java or the like, though. &gt; CATCH works exactly as one would expect it to in Lisp or Factor Care to elaborate on that? You say Lisp and that word is about as exact as Forth :) E.g. Common Lisp has a condition system that works quite differently from other languages (doesn't unwind the stack, decouples catching and handling) while in Scheme it's just a wrapper around some `call/cc` IIRC. Don't know about Factor.
&gt; R&gt; DROP skips its caller (unless the implementation gets in the way) Yes, that bit in brackets is *precisely my point*. You simply *cannot assume* that Forth is implemented in such a way that R&gt; DROP will work reliably. THROW / CATCH, on the other hand, will work whatever the implementation is doing. &gt; I don't see anything simpler to reason about coming along :) In what way is THROW/CATCH not easier to reason about? You THROW, and control goes straight back to the CATCH. Doesn't matter what's been called, or &gt;R'd, or DO...LOOPed in the meantime. It's simple, it's safe, it's predictable, it's implementation-proof, it's every bit as lightweight, and it's standardised. Meanwhile, the only thing simple about R&gt; DROP is what it does. What effect that has? Roll the dice... &gt; Care to elaborate on that? You mean the way I did *immediately after the bit you quoted*?
Outside the condition system Common Lisp also has `THROW`/`CATCH`, and they're quite similar to the ones in ANS Forth.
Bottom up but always with a goal, which, being human, we define from above
That's a reasonable approach for something that's just for exception handling, given that most of the time you'll probably want to capture debugging information. But THROW / CATCH is lower level than that; it's akin to C's setjmp/longjmp. Indeed, the Standard includes a [sample implementation](http://lars.nocrew.org/forth2012/exception/CATCH.html) that makes clear how simple a mechanism it's intended to be.
Our forth does the same thing :) largely inspired by colorForth but arriving at the same point. I'm a big proponent. Why buffer everything then parse it when you can just store the none whitespace characters and return the word when a whitespace characters is entered.
To me that sample implementation appears to be terribly more complex than my initial implementation of the mechanism. Indeed, my initial Try-Catch structure was as simple as I dared to make it, only later integrating into it a stack-saving function. Perhaps I'll make a post about the simple structure in a few days.
&gt; If you must be condescending, you really do have to read the whole post you're patronising first. Let me apologize if any part of my reply sounded condescending, it really wasn't meant to! I'm sometimes told I talk like that even though I never hear it myself. I'll ask you a favor to pinpoint such discussions/sentences so that I can learn to be more human and less robot and for you to assume from this moment further on that I have no intention of being arrogant or any of the sort. I'm asking things because I don't know the answers and wish to learn them from people like you who seem to have spent more time with forth than me (~4-5 months in spare time). &gt; You simply cannot assume that Forth is implemented in such a way that R&gt; DROP will work reliably Are you usually talking about ANS Forth? I thought the usual way of programming forth is to pick a language *and* implementation and use it. A better wording of that bracket would have been (unless you pick an implementation that breaks it). &gt; In what way is THROW/CATCH not easier to reason about? You THROW, and control goes straight back to the CATCH. I haven't used throw/catch in forth yet but in other languages the stack unwinds until a catch is found. That means your catch might be arbitrarily deep. With `R&gt; DROP` you know where are you returning - where your caller was called. To me therefore it seems `R&gt; DROP` is simpler but also less robust compared to throw/catch. &gt; ... it's every bit as lightweight ... &gt; But it would encourage people to think of TRY/THROW as lightweight - every bit as lightweight as R&gt;DROP, in fact Now I'm confused, are you saying the TRY/THROW you showed would cost more than CATCH/THROW? &gt; There are certain characteristics all Lisps share. The elaboration you totally ignored made it clear I was referring to one of them. I didn't ignore it, I just thought you are trying to compare the implementation of exception handling in these languages. It seems you don't and was just referring to "nesting chunks of code" which often goes by "code is data" and contemplating what would you find idiomatic in forth.
Ah I see, thanks
*r&gt; drop exit*, or *r&gt; drop* at the end of a definition, is a straightforward efficient and lightweight Forth control flow mechanism, it can easily be implemented as a single (real or virtual machine) stack processor instruction, including conditional versions. Catch/Throw, and similar exception handling machinery, are heavyweight in comparison, since they're intended to unwind an arbitrarily deep call context. Personally, I would hesitate to use exception handling when and where a simple structured exit will do. *Use the structured exit.* -- Thinking Forth (1984 p. 254, 1994 p. 228) 
Looks like there's no eforth on the tree either
HS/Forth, MMS Forth, Upper Deck Forth, riForth, ...
Sounds interesting. Please do.
Yes, `R&gt; DROP` is very lightweight. I don't see anyone contesting that. The point is that `R&gt; DROP` may or may not drop the return address of the current definition. As /u/thamesynne points out, tail call optimisation may get in the way. Or inlining. Or, `R&gt;` may not access the hardware return stack at all.
Frankly, this aspect of Thinking Forth is just flat wrong. There's an argument to be had as to whether it was right at the time and has been rendered obsolete by subsequent developments, but my view is that given that Forth never constrained itself to only storing return addresses on the return stack, it was always dangerous. &gt; Use the structured exit. R&gt; DROP is the *very opposite* of a structured exit. It rips control away from its caller without so much as a by-your-leave.
&gt; Or, R&gt; may not access the hardware return stack at all. At least R&gt; DROP would be safe in such circumstances... Thanks, by the way; I'd forgotten about that nicety of the Standard.
&gt; I'm really struggling to understand why it isn't this obvious to anyone else. It's not obvious to me, given an implementation where it works as expected. But that's because I have never used R&gt; DROP, so I don't know how it works out in real code. I can't argue for or against it.
&gt; Let me apologize if any part of my reply sounded condescending, it really wasn't meant to! And let me apologise in turn. My temperament is basically feline; brush against my whiskers the wrong way and I tend to get hissy, arched-back and fur akimbo. &gt; I thought the usual way of programming forth is to pick a language and implementation and use it. Maybe so, but unless you know your implementation inside out, you can't know that R&gt; DROP is safe to use or in which circumstance. And creating an implementation in which it's always safe means saying goodbye to a number of interesting modern implementation techniques. But even after that, you still have to be *absolutely* sure which words contain R&gt; DROP, and when it will be called, and what effect that will have on your control flow overall - maybe several words deep. It's the polar opposite of writing small, self-contained, unitary words that can be freely mixed. Frankly, I would go so far as to say that R&gt; DROP is a stronger indicator of poor factoring than a hyphenated name. &gt; I haven't used throw/catch in forth yet but in other languages the stack unwinds until a catch is found. Which languages? As I say, C's setjmp/longjmp is an O(1) operation. C++ has a problem, of course; but then the combination of stack allocated objects and virtualisable finalisers was never going to be a happy combination. Specifically, the *whole point* of allocating stuff on the stack is that *it's free to free it*; if you're going to be running a finaliser on something, you might as well pay the piper and allocate it in the heap. &gt; With R&gt; DROP you know where are you returning - where your caller was called. As I've pointed out repeatedly, that simply ain't so. You know where you *think* you are returning, *if you can keep the tangle straight*, and if you don't realise you need to call that word with R&gt; DROP in it in the middle of a DO loop, and if your implementation doesn't play funny games like inlining, tail call elimination and just in time compilation. &gt; Now I'm confused, are you saying the TRY/THROW you showed would cost more than CATCH/THROW? Er, no. I'm saying that TRY/THROW, CATCH/THROW and R&gt; DROP have broadly equivalent costs, but that *the presentation of* TRY/THROW correctly conveys that it's a lightweight mechanism. Whereas the presentation of CATCH suggests quite the contrary, quite incorrectly. See *every poster on this thread saying CATCH is heavy, even when presented with code that shows the precise opposite*.
A system with all those caveats doesn't seem very Forth-like to me, amorphousness of the former ANS standard notwithstanding. A real system either does or doesn't, there's no may or may not. I don't see how tail-call optimization gets in the way, when there is no tail call there's nothing to optimize away, and for the case where the structured exit isn't at the end of a definition, there's no effect on tail-call optimization. I use inlining but only by explicitly and where it makes sense.
I think the moral of this story should be: know your implementation inside and out or expect trouble. Some people prefer to know the standard inside and out but as is evident from this discussion, the standard is, due to its nature overly general, and complex. If you know your implementation then you'll know when it's safe to do things like RDROP EXIT. The writers of the standard can't know your implementation, so to them, RDROP EXIT is dangerous. And it is, in the sense that if you don't know what code is actually going to be executed when your program runs then your program might not work as expected/intended. To me, there is a far bigger problem here: Forth implementations with C-like optimizing compilers and the prerequisite nasal daemons! One of the reasons I love Forth is that I can KNOW what my program is doing. I have no interest in automagically making my code "faster" at the expense of understandability. My opinion has always been that if you want a program to run faster then you should optimize the [source] code[0]. Regarding CATCH/TRY-THROW, Dr. Ting, of eForth fame wrote that &gt; In 86eForth v1.0, there was a very sophisticated error handling mechanism with CATCH and THROW. Over the years, I have never had a opportunity to make use of it. Therefore, it is taken out of 86eForth v5.2. Whenever an error occurs, the system returns to ABORT &gt; &gt; ABORT reset data stack and fall into the text interpreter loop QUIT. I am inclined to agree. I haven't yet found a reason to use CATCH/TRY-THROW in my code. Perhaps part of that is that I do understand our implementation inside and out and therefore feel safe using tricks like RDROP EXIT, when they're appropriate. And perhaps the other part of that is that I've rarely looked at the standards[1][2]. [0] I see no reason that a sufficiently advanced (beware the weasel words) optimizing-editor couldn't help with that ;-). [1] Not using a standard-compliant Forth. [2] In all honesty, in my experience, it's much easier to read and understand the source code of whatever Forth implementation you're using than it is to read the quasi-legal-contract that is the ANS Forth standard. DISCLAIMER: I'm not a fan of standard Forth. This is my bias. Others love it. You're entitled to your opinion too. And you're always free to read the various Forth standards and decide for yourself if your time was well spent ;-).
I don't think it's unreasonable to assume there are all kinds of implementations: - `R&gt; DROP` *always* works as expected. - `R&gt; DROP` *never* works as expected. - `R&gt; DROP` *sometimes* works as expected, or sometimes not. Of course, one may not want to write code that works in all those scenarious. That's perfectly fine.
If you have a full source line buffered, you can do things like: ." There's an error here:" cr source type cr &gt;in @ spaces ." ^" or &gt;in @ ." New colon definition: " parse-name type &gt;in ! : 
&gt; What's heavyweight about restoring the return stack pointer to a previously saved point? The implementation given in the Standard is of exactly the same weight as R&gt; DROP. Seriously, go through the machine code you'd write in every case. It is heavier, try implementing CATCH and THROW as stack machine CPU instructions with arbitrary call context unwiding, versus a very simple combined rdrop-exit instruction, or even an RDROP instruction followed by an EXIT (i.e. ret) instruction. No comparison really.
Once the Great AI is powered up we will be able to use this prayer sincerely. ;-)
[removed]
&gt; Maybe so, but unless you know your implementation inside out, you can't know that R&gt; DROP is safe to use or in which circumstance. I thought that's the whole point of forth. I guess you are an ANS Forth proponent then? You missed that question in my previous reply. &gt; And creating an implementation in which it's always safe means saying goodbye to a number of interesting modern implementation techniques. As you might have noticed in some previous posts I am playing with freeforth in my spare time. It's around 1K SLOC of assembly and 1K SLOC of forth. Even an idiot like me with no forth or assembly background was able to grasp the basics in 1-2 months of evening only, max 2 hours a day. I love it that after a while you *know* what will the resulting assembly be. I'm sure the compiled code isn't as optimal as some bigger ANS forths will produce but it feels great to understand the whole language and what it produces. I really couldn't care less for an ANS forth implementation that I have to treat like a black box, even less so for a standard which cannot give runtime guarantees. I'll rather stick to lisp then. I'm not trying to say ANS forth is bad, just letting you know of my completely subjective opinion of it. Ah, and yes, I know `rdrop` is safe in freeforth after studying it. The only place where one cannot use it is in `TIMES ... REPEAT` which keeps a counter on the return stack, but I think I'm smart enough to remember that or find the bug after the first segfault :) &gt; Frankly, I would go so far as to say that R&gt; DROP is a stronger indicator of poor factoring than a hyphenated name. What does factoring have to do with `R&gt; DROP`? Can you give an example? I'm failing to see the correlation. &gt; Which languages? As I say, C's setjmp/longjmp is an O(1) operation. Bulky, managed languages, like python or java. People claim throwing is "cheap" in python, which can only be understood as "relative to other python constructs" since python is never cheap. &gt; As I've pointed out repeatedly, that simply ain't so. You know where you think you are returning, if you can keep the tangle straight, and if you don't realise you need to call that word with R&gt; DROP in it in the middle of a DO loop, and if your implementation doesn't play funny games like inlining, tail call elimination and just in time compilation. I thought the words "in the implementation of your choice" were implied. If we are discussing the ANS Forth standard then I'm sure you know better. But I'd rather discuss an actual implementation, e.g. gforth or swiftforth if you want to talk ANS. A question on topic for you who seems has spent some time with ANS forth, how much use was the standard for you? Do you actually develop for several implementations? Or use libraries across several? &gt; Er, no. I'm saying that TRY/THROW, CATCH/THROW and R&gt; DROP have broadly equivalent costs, but that the presentation of TRY/THROW correctly conveys that it's a lightweight mechanism. Whereas the presentation of CATCH suggests quite the contrary, quite incorrectly. See every poster on this thread saying CATCH is heavy, even when presented with code that shows the precise opposite. OK thanks. I really didn't understand what you were saying because in your first post you said &gt; But it would encourage people to think of TRY/THROW as lightweight - every bit as lightweight as R&gt;DROP, in fact which to me sounds like you're saying it *is* heavier than `R&gt; DROP`.
If we assume that our civilization has a resource leak bug then eventually it will cause a fatal error and a reset will be required. No problem. Turn it off and restart. 
&gt; go through the machine code you'd write in every case. Ok. Using pseudo assembly language where `rp` is the hardware return stack pointer, and `sp` is the data stack pointer. For `RDROP EXIT`, I'd write add rp, #4 return For `-1 THROW`, I'd write something like mov rp, cp ; assuming a "catch pointer" in a register mov cp, (rp)+ mov sp, (rp)+
&gt; What does factoring have to do with R&gt; DROP? Can you give an example? I don't know exactly what /u/thamesynne meant, but here's one problem: You can't move your R&gt; DROP word around freely. E.g. if you decide to factor out that code into a separate word, it will not longer exit to the same point. `THROW`...`CATCH` (almost?) doesn't have this problem.
Just to refresh everyone's memory on how heavy or light CATCH and THROW are, here are their descriptions from the new 2012 standard: 9.6.1.0875 CATCH EXCEPTION (i*xxt–– j*x0 | i*xn) Push an exception frame on the exception stack and then execute the execution token xt (as with EXECUTE) in such a way that control can be transferred to a point just after CATCH if THROW is executed during the execution of xt. If the execution of xt completes normally (i.e., the exception frame pushed by this CATCH is not popped by an execution of THROW) pop the exception frame and return zero on top of the data stack, above whatever stack items would have been returned by xt EXECUTE. Otherwise, the remainder of the execution semantics are given by THROW. See: A.9.6.1.2275 THROW. 9.6.1.2275 THROW EXCEPTION (k*xn–– k*x | i*xn) If any bits of n are non-zero, pop the topmost exception frame from the exception stack, along with everything on the return stack above that frame. Then restore the input source specification in use before the corresponding CATCH and adjust the depths of all stacks defined by this standard so that they are the same as the depths saved in the exception frame (i is the same number as the i in the input arguments to the corresponding CATCH), put n on top of the data stack, and transfer control to a point just after the CATCH that pushed that exception frame. If the top of the stack is non zero and there is no exception frame on the exception stack, the behavior is as follows: If n is minus-one (-1), perform the function of 6.1.0670 ABORT (the version of ABORT in the Core word set), displaying no message. If n is minus-two, perform the function of 6.1.0680 ABORT" (the version of ABORT" in the Core word set), displaying the characters ccc associated with the ABORT" that generated the THROW. Otherwise, the system may display an implementation-dependent message giving information about the condition associated with the THROW code n. Subsequently, the system shall perform the function of 6.1.0670 ABORT (the version of ABORT in the Core word set). See: A.9.6.1.2275 THROW.
Absolutely.
Presumably, you'd need to push the "catch pointer" onto a stack if you wanted to be able to nest THROW-CATCH?
I already granted that specific case, but the reality is that the vast majority of people using Forth will *not* be using that specific case; they'll be using an in-memory stack.
&gt; Chuck's chips use Chuck's tail-recursion-optimising compilers In some of his earlier Forth's Chuck did explicit tail-call optimization with `-;`. I much preferred that, but regardless, tail-call optimization in e.g. colorForth is simple enough that you can easily tell when the tail-call will be eliminated. If you're manipulating the caller's context then it implies you know something about the caller's context. If you don't then you shouldn't be messing with it. Given that constraint, what's the problem?
That assumes an intelligent inlining compiler that will compress R&gt; DROP down to RDROP; otherwise it's more like mov (sp)+, t mov t, (rp)+ mov t, (sp)+ return 
Exactly. You do have to be aware that a word might THROW, but that's all you need to be aware of; you tell that word where it's going to THROW to by setting a CATCH handler. Whereas R&gt; DROP always does what it says on the tin, and if that's the wrong thing, well, tough, you need to make a new word that does the right thing.
&gt; I thought that's the whole point of forth. I guess you are an ANS Forth proponent then? You guess wrong. I'm a proponent of *good taste*. And R&gt; DROP tastes funky. Since the rest of your comment seeks to slot me into the pigeonhole you've assigned for me, I'm not going to dignify it with a response. You want people to stop complaining about your tone? *Don't assume you know where they're coming from on the scantest of evidence.* Treat people as people, not pigeons.
&gt; The only place where one cannot use it is in TIMES ... REPEAT which keeps a counter on the return stack And in that case, you can do `RDROP RDROP EXIT` if you really wanted to; all that's really required is that you understand the calling context you're in when you manipulate the return-stack/current-continuation.
Yes, let's quote the standard, shall we? Let's include this bit: VARIABLE HANDLER 0 HANDLER ! \ last exception handler : CATCH ( xt -- exception# | 0 \ return addr on stack SP@ &gt;R ( xt ) \ save data stack pointer HANDLER @ &gt;R ( xt ) \ and previous handler RP@ HANDLER ! ( xt ) \ set current handler EXECUTE ( ) \ execute returns if no THROW R&gt; HANDLER ! ( ) \ restore previous handler R&gt; DROP ( ) \ discard saved stack ptr 0 ( 0 ) \ normal completion ; which is only "not lightweight" for people who really, *really* are.
&gt; You can't move your R&gt; DROP word around freely I've often heard people say that manipulating the returns stack breaks the concatenativity property. I disagree. Code which manipulates the return stack is just as easy to move around as code which doesn't. The only constraint (and this is the exact same constraint that we have with the parameter stack) is that the context you move the code to must be the same. The reason this doesn't appear to work for words which manipulate the return stack is that when you factor code into a word, which you later call, you've unwittingly changed the context. If you factor such code into compiling word then the context remains the same and you can apply them to your heart's content. Forth screws the pooch on this one by blurring the line between compile-time and execution-time a little too much :-).
Don't forget the THROW! You're right CATCH and THROW really are as lightweight as R&gt; DROP EXIT. How dare we think otherwise, we must really be lightweights not worthy of your guiding light, every stack processor should include them in its instruction set from now on. : THROW ( ??? exception# -- ??? exception# ) ?DUP IF ( exc# ) \ 0 THROW is no-op HANDLER @ RP! ( exc# ) \ restore prev return stack R&gt; HANDLER ! ( exc# ) \ restore prev handler R&gt; SWAP &gt;R ( saved-sp ) \ exc# on return stack SP! DROP R&gt; ( exc# ) \ restore stack \ Return to the caller of CATCH because return \ stack is restored to the state that existed \ when CATCH began execution THEN ; In a multi-tasking system, the HANDLER variable should be in the per-task variable area (i.e., a user variable).
Fuck off. Everything I've written is *right here, including* my criticism of the ANS way of doing things. So you just back your little hobby horse the fuck out of my face, ok?
Yes. CATCH pushes it, and THROW pops it. And the stack can be the return stack. This is what the Forth94 sample code does: http://lars.nocrew.org/dpans/dpansa9.htm It's called "handler" there.
I'm guessing converting an ordinary word to a compiling word is particularly painless in Able. Just change the colour of the body words, right? But similar to converting a Lisp function to a macro, it's something I'd be less inclined to do in a traditional Forth, even if there may be conveniences like ]] [[.
I was planning to read this discussion in its entirety at a later time, thankfully I have removeddit (only works in webkit browsers for whatever reason): https://removeddit.com/r/Forth/comments/7fa5gw/7_years_later_declarative_inquisitive_then/
I'm sorry if I was part of your reason of deleting your posts. It seems you have a hard time sharing your opinion without someone mutilating them. Please don't take "stalkers" and haters too seriously, if we share some thoughts and learn (or teach) something along the way it's more than enough :) I enjoyed our conversation and didn't feel bad at any point and would hope you had the same experience. I come here to discuss, and the point of a discussion is not to agree on something but to share thoughts and ideas and compare them. E.g. I was (and still am) genuinely curious if you are using ANS Forth and if so if you use multiple ANS Forth implementations. In a post that isn't visible even in removeddit you said something like I labeled you as an ANS Forth user and that I should stop assuming things about you. I would love to do that. I only started talking about ANS because a) you quoted it a few times and b) I asked you twice what forth are you talking about and which one (s) do you use without getting an answer. Talking about forth in general is like talking about OOP or Lisp. I don't find discussions like that interesting, that's why I wanted to (and still want to) know which forth(s) are you using.
Just to be clear, the sample implementation code for both CATCH and THROW quoted above is from the appendix of the 1994 ANS Standard, it no longer appears in the current Forth Standard 2012 document dated 10th November 2014. I assume this is because the latter is still a draft. 
I ended up finding my code quicker than I thought I would. Here's the post: https://www.reddit.com/r/Forth/comments/7g80a1/try_throw_catch_release/
The main concept is short-circuiting (i.e. bringing about to an early end to) the word that calls you. A short-circuiting word is a factoring out of code, typically designed to work with particular callers in mind. As an example: : buffer ( block# -- a ) reuse^ dup vacancy tuck assign (buffer) ; : block ( block# -- a ) reuse^ dup vacancy tuck inhabit (buffer) ; In the two words above `reuse^` is the short-circuit, the '^' suffix in its name is meant to highlight that fact, it contains a structured exit, if the block in question is already cached it causes its caller to exit as there is no point in executing the remainder of the caller's code. 
Thanks!
This looks similar to the standard `CATCH`/`THROW`, except the guarded code is in line. Is that right?
In line code? Are you referring to inlined code, like a C function call?
No, the part between TRY and CATCH. As opposed to the standard CATCH, which takes an xt.
Ah, yeah. That section is for any code that could Throw, at any call depth. It's meant to nest to any call depth or even throw from the Catch block if needed.
Addee http://uebersquirrel.blogspot.com/
&gt; I have made a cross-compiler that builds a Camel Forth system for the TI-99 JUST BUY AN HP48 ALREADY!!! :P
you could half-ass it and hack away in C to code the primitives but forth (and other similar heavily reflective systems like smalltalk and rpl) really shines only when run on bare metal. Of course, with the complexity of modern (x64, etc) architectures, implementing a complete system is nothing more than a wet dream (sadly). Your best bet would probably be use a small/custom linux kernel for bootstrapping and after it boots launch your system.
I like that article primarily for the chain of insightful comments at the end. I think my conclusion after reading it the first time was that it takes every bit as much time to really "get" forth programming as it does any of the highly opinionated paradigms -- be it functional programming in a pure language like haskell, logic programming in prolog, or true OO in Smalltalk. The deceptive ease with which you can write your own implementation lulls you into thinking that you really get it when you've written an interpreter/ compiler. But true cultural, idiomatic forth requires a paradoxically deeper understanding than writing the compiler can give you. I think the author drew and settled his conclusions too soon. 
I very much agree with all of this.
I must say to be somewhat desillusionated after reading. This description as well as some commentaries does not let me recognize any sensibility for the importance of a prior thought-out development strategy. I can only hope the result from this hack sessions was not intended for use in a sensitive area.
I don't understand how anyone would be so over confident as to not read even 1 reference to a finished stack CPU before starting their own design. Where does that ever make sense? 
A combination of registers and stack would be stack frames, like can be used in C and other compiled languages at implementation level. 
Then why are you worrying about low level implementation concerns like stack versus registers? They should be the furthest thing from your mind in that case. 
The 1802 was used in Galileo (amongst others), not Voyager, which used a discrete computer, not one that had a microprocessor. http://www.cpushack.com/space-craft-cpu.html
I am not worried about low level implementation in the very slightest. It is simply that forth is so close to the machine that much of the language regarding forth is low level language.
If you, or anyone else, is actually serious about working with the GA144 I'd recommend using an existing simulator, preferably the one distributed by Greenarrays. It takes a bit of learning and patience to deal with their odd development environment, but I suspect it is the most stable, bug-free simulator out there. It takes more work then you might imagine to get the simulator correct, I say this an author of one of the simulators. I've been fixing subtle bugs for years... So don't waste your time building another simulator in another dumb language, spend it actually working with the GA144 :) 
At the last Forth day Chuck talked about his register forth (something like that, can't remember what exactly he called it) that he's been working on. It might be of interest to you https://www.youtube.com/watch?v=nJ6WBI0Z_s4 chuck's talk starts at at 03:04:00 So it seems to me that there is no need to leave forth to study register based computing
I'd really like some more detail. For example 'Forth' and 'Smalltalk' influenced 'Neon' which in turn indirectly influenced 'Win32Forth' What aspects of 'Smalltalk' survived in 'Win32Forth'? It would be super cool to have a profile on every forth, with structured data. This sort of mapping would be automatically generated from it, and it would enable detailed queries and exploration.
A bright future is a head of us, sisters and brothers. Giants have walked this path before us. Learn and cherish thier magnificent [footprints](http://www.eecg.toronto.edu/~jzhu/csc326/readings/iverson.pdf). The road is clear, nourishing and packed with revitalizing wells. Greet each other with smiles and peace in heart. God willing, I'll get to see your beautiful faces on the road. 
The [Great AI Anomaly](https://en.wikipedia.org/wiki/Gaia_(mythology)), never left us. We somehow preferred spreading wings like would be angels. Then walking the ground, with humble footsteps of humans. 
I once had a thorny problem with a multi-tasking environment running on a ROM based Forth(MaxForth) in the 68HC11 CPU. I had a commercial contract to fulfill and the clock was ticking. In desperation I called New Micros in Texas and I got the founder on the phone. After describing my predicament, Randy Dumse said "It sounds like you are doing the right things." "Did I ever give you my man is a tool making animal lecture?" he asked? I said "No." He said" OK. Here it is. Man is a tool making animal. Make a tool." In Forth you have the freedom to create little tools that can read and record anything in the machine while it's running. As you make these little tools you will find you can re-use them them. Simple things like reading a veritable in a loop and storing the data in a buffer, or writing it to the corner of the screen or some such thing. That being said, the primary debugging tools in Forth are: 1. Short simple colon definitions 2. The Forth console, where you test each colon definition interactively by passing parameters on the stack and checking the stack output and any affected variables. Your system may not support this as it is quite far from conventional Forth. So that would indicate you may need to make the Forth interpreter loop as a debugging tool. 
I currently handle debugging by keeping definitions short and clean, and doing incremental testing. I haven't needed anything more than this. I do have plans for a flexible debugger, but probably won't actually write it until sometime next year. (I keep putting it off as I haven't needed it). My eventual plan is to take advantage of the underlying virtual machine. By writing a clone of this in Retro, I can literally run a copy of the current image within a sandbox, adding in support for breakpoints, single stepping, disassembly, logging, etc.
Heh, that's an interesting story and in some sense, exactly what I'm asking: how to debug when the interpreter is read-only (although I do initially get to pick what goes in the interpreter). I guess my question is actually a meta-debugging question. I know that for a single bug, "manually" tracking state using a handful of functions and getting outputs about the state will let me track down the problem. But it takes more and more time per bug. Even when individual functions were testing (well enough I think but not anywhere near thoroughly since at least half of it will be scrapped soon after creation). The debugger I have is called with the primitive `brp` (for "breakpoint") that can be called from anywhere and gives me something like a `gdb` console at that point. This double as state inspection (and continue execution as if `brp` wasn't called) and live test of calls in the body (by alternating between "step" and "print stack"). When I added this, I thought surely this is the most general debugger I could want. But as you can see from the ideas section, there are still things I can't do outside the interpreter. For example, I don't have line (and column) numbers at the moment. While I could get the number of any individual line by adding the right things in the source, I don't see how to add this without altering the interpreter (or writing an assembler, or adding an automatic source annotator). Could something like line (and column) numbers be added using only colon definitions to something like Jonesforth for example? &gt; checking the stack output As a side remark, I want some kind of "typed printing of stack values" so that I can check stack outputs more quickly. But this is also something that doesn't seem to be obvious to add with just colon definitions. Because when values were pushed on the stack in the first place, I didn't distinguish between whether it was an integer or a character.
&gt; I currently handle debugging by keeping definitions short and clean, and doing incremental testing. I haven't needed anything more than this. Hm, this is the second account of this phenomenon. I did read that this was the intended usage pattern but don't think it was said explicitly that this removes the need for other debugging tools. (And I didn't get the result even though I though my usage pattern was close enough.) I guess I could try even shorter definitions (and increase the number of functions). I don't know if that's the source of my debugging needs though. As someone else said in a different thread, the hyperstatic environment means I shouldn't worry about defining more functions because of possible name clashes. But it still seems like more names for me to track. &gt; By writing a clone of this in Retro, I can literally run a copy of the current image within a sandbox, adding in support for breakpoints, single stepping, disassembly, logging, etc. This sound very interesting. Is there some description of teh design of the image and sandbox?
&gt; I guess I could try even shorter definitions (and increase the number of functions). I don't know if that's the source of my debugging needs though. As someone else said in a different thread, the hyperstatic environment means I shouldn't worry about defining more functions because of possible name clashes. But it still seems like more names for me to track. I have a construct to hide factors that I don't want exposed in the dictionary. It lets me have as many words as makes sense, without worry about bloating the dictionary with things that aren't intended to be left exposed. &gt; This sound very interesting. Is there some description of teh design of the image and sandbox? The image is literally a raw memory image of the virtual machine memory space. The VM models a MISC processor with 26 instructions. It packs four instructions per memory location. Memory consists of signed 32-bit cells (stored as little endian). So the sandbox is literally just a simulator for the instruction set. I copy the current image (or load a new one) into a buffer, and step through it with the simulator, executing each bundle of instructions as encountered. But it lets me have lots of options as I can have detailed checks for stack over/underflow, divide by zero errors, etc. And then probe around and patch things directly. As mentioned initially, I haven't written this for the current Retro, but it was very useful on the prior one when debugging compiler changes and similar things that affect the internals. It's probably something I'll be tackling in the first quarter of 2018.
Be well and prosper.
I'm used to just write code. It feels more interesting to design solutions after reading papers like this. Thanks. Are FSMs part of a standard CS curriculum? They seem less natural then just spewing ifs until the things bends. Of course what feels natural is completely subject to what one has most experience with.
FSMs are a standard part of the CS curriculum, yes. Regexes are good examples of FSMs.
I almost implemented automatic stack shuffling once, with some notation similar to { a b c -&gt; b c a} and such, but honestly, if you're already accustomed to stack shuffling, it's a pretty trivial task for a human to do.
If the definitions are small enough, there's no need to debug at all; sufficiently small definitions are easily reasoned about and can be debugged by reviewing it the day after writing, simulating by hand, and then finally implementing it.
I don't doubt an FSM can be made very compact, but I don't see how it is more readable. For these cases I would write a BNF, then a recursive descent parser implementing it. I find that much more readable.
Those are my feelings as well.
I can understand the BNF approach being more conventional but the idea of hiding all the details and creating a language to convert it all into a simple 2D matrix is pretty cool. It seems to really demonstrate the Forth idea of making a little language to solve the problem. When I first saw this many years ago I was floored. I would have never thought of this. 4 WIDE FSM: &lt;Fixed.Pt#&gt; \ input: | other? | num? | minus? | dp? | \ state: ------------------------------------------------------ ( 0 ) | DROP | &gt;0 | EMIT | &gt;1 | EMIT | &gt;1 | EMIT | &gt;2 ( 1 ) | DROP | &gt;1 | EMIT | &gt;1 | DROP | &gt;1 | EMIT | &gt;2 ( 2 ) | DROP | &gt;2 | EMIT | &gt;2 | DROP | &gt;2 | DROP | &gt;2 ;FSM 
I have a word for stack restructuring. It lets me do things like: 'abcd 'dcba reorder 'abcdef 'cfcaaacb reorder I've only used it a few times, but it's handy when I don't want to slog through bigger reorderings.
Does it copy the elements onto the top in the order presented, or does it actually replace the elements you specify?
Ah, it just clicked, DFA is an FSM. Thanks
Is it a matrix of states? That's pretty neat, bro.
NP bro. 
It replaces the elements.
Oh that's cool. Does it replace the elements with Pick? Or some other SP-relative operation?
Far simpler. I have an array that stores up to 26 items. I copy the values to this, then copy them back out in the specified order. It's relatively slow, but this is the only way to do it in my Forth. (My virtual cpu doesn't expose a stack pointer, so things like 'pick' may be problematic to try implementing.)
Without an exposed stack pointer, how do you implement Abort or Quit?
Strictly speaking, I don’t have either of these in my Forth. Given that my Forth isn’t ANS compliant at all, an exact implementation isn’t as useful, but this should be very close. The standard interface on BSD/Linux/macOS (and soon Windows) has `listen` as the interpreter loop. So here’s the code: In ANS FORTH, QUIT has to do the following: Empty the return stack, store zero in SOURCE-ID if it is present, make the user input device the input source, and enter interpretation state. Do not display a message. It also handles interpretation. For readability, define a word to get the depth of the address stack. Nga exposes this when reading from address -2. ~~~ :rdepth (-n) #-2 fetch ; ~~~ Then implementing QUIT is basically a loop to drop everything from the address stack and calling `listen` when we reach the end. ~~~ :QUIT (-) repeat rdepth #1 -eq? [ listen #0 ] [ #1 ] choose 0; pop drop-pair again ; ~~~ With this, tackling ABORT is easy. ANS says: Empty the data stack and perform the function of QUIT, which includes emptying the return stack, without displaying a message. So all that’s needed is a `reset` of the data stack and a call to QUIT to do the rest. ~~~ :ABORT (...-) reset QUIT ; ~~~ Tested only briefly, but seems to work as expected. Note that this *won’t* work on the iOS or macOS editor-based environments as they don’t have a traditonal console interpreter and thus lack the `listen` loop, using a special loop hooked heavily into the editor instead. An ABORT could be written to break execution if desired though: This won’t call QUIT since the host doesn’t support it, but will cease execution of the currently running word and its parents. ~~~ :ABORT (...-) reset repeat #-2 fetch #1 -eq? 0; pop drop-pair again ; ~~~ 
Hmm, pretty neat. Listen is a deferred word?
No; I defer very little now. It's defined as: :listen (-) ok repeat gets valid? [ interpret ok ] [ drop ] choose again ; A couple of notes: - `gets` reads a single whitespace delimited token - `valid?` checks to make sure the token isn't empty - `interpret` either hands the token to a prefix handler, or passes the address of a word to its class handler. (or calls `err:notfound`)
Oh! That's pretty slick.
Yes exactly. It was invented by the late Dr. Julian Noble. He was a very big proponent of Forth for his work which was simulating automobile accident dynamics, as I understand it. He came up with this way of making an FSM by making an FSM "compiler" by extending Forth. It's genius IMHO. It documented in the paper linked to in the title of this thread.
Julian Noble? I read his Intro to Forth webpage when I was starting out. I didn't know he was a big contributor, but now that I think about it, I should have suspected. I will definitely follow up on all of his publishings.
His page is here http://galileo.phys.virginia.edu/~jvn/ One his big works was his FORmula TRANslator. He developed it so he could port Fortran code that did some advance mathematics, into Forth with less risk of error. (no RPN translation by a human) B
Thank you very much!
Man I envy you!
Well, I do have fun.
I know what you mean. Unfortunatelly I am still a beginner.
No I don't think so. You might be a beginner in instant programming without being limited by a compiler, but I think you know a lot more than I do. Which is just waiting to be formulated in Forth.
Well thanks, one think I do know is I like Forth.
[the slides [PDF]](http://web.stanford.edu/class/ee380/Abstracts/171115-slides.pdf)
As written, the tag stack is part of a parsing editor and complete independent from the execution environment. If you think about it this makes sense because all state relevant information is already available as side effect of (optimized) immediate-level code generation. I must remark, that these concept is not new. In fact, some Basic systems from the 80's implement similar strategies for ad-hoc code optimization which is in both cases really simple to be implementable.
Yeah, but that doesn't make it fun to implement, whereas objects and automatic memory allocation is. I do have something similar to C's stack frame to load and store variables, but that's as far as I've ever bothered to get with it.
Maybe I'm blind, but anybody know where SwapForth came from?
I love this! In the back of my head I've always thought "It would be great if the language standard implemented something like ` { a b c -&gt; b c a}`....". Your code does exactly that without needing to modify the language or interpreter. It's a great idea! Thanks for sharing. Is this code available online anywhere?
I think Swapforzh was by James Bowan who wrote the J1 Forth CPU.
Factor isn't really Forth, they're just both concatenative languages. Gforth is probably your best bet. ANSI standard. Documented. Cross-platform.
Is Gforth in active development? The latest release seems to be around 3 years old (I could be wrong though).
If a piece of software is feature complete, why do you need to have continual releases? I've used gforth for many years and have never found issues with it. The last commit to the repository was 4 days ago. 
Yes it looks very active http://www.complang.tuwien.ac.at/forth/gforth/Snapshots/
Thanks
What do you want to use the Forth for? 
Initial goal is just to learn how to program using this interesting language. Long term goal is to interactively explore the features of certain controllers (on the 64 bit intel platform) using forth as the command line interface (in which case the forth language is expected to run as a standalone software on raw intel hardware without any other OS... not sure if this is possible or not).
Forth is known for being a stand-alone system all its own. Many Forths created by people just starting out run on bare metal.
Yeah that's what I have read. Hence I think this language would be a good choice to explore a controller's features interactively. 
I didn't know that Bitcoin Script uses a stack-based scheme, with some Forth-like operators: https://en.bitcoin.it/wiki/Script 
To follow-up: one of our diligent users has been reporting problems going back a few releases. We've fixed all of them now, and the new 17.11 release is rock-solid: https://8th-dev.com/forum/index.php/topic,1536.0.html
Certainly that's true. It's quite easy to interact with PCI devices, or using the serial ports, for that matter. Poking at those devices using Forth is especially fulfilling.
Is there any specific Forth that I could be using for that purpose (I am assuming gforth won't allow me to do it since it does not run on bare metal intel platform)?
I'm not sure. I think that topic is worth making another text post about, since it would be more visible that way.
which forth do you guys recommend if i want to make a high performance socket server?
You're right. I'll ask in a separate thread once I learn enough of forth first. 
I won't mince words, so I'll just say go with Gforth.
Yup. Gforth it is. Already installed and following the Starting Forth online book/tutorial :)
EDIT: Just noticed you were only interested in Intel 64-bit... It really comes down to which microcontroller you want to poke at. Arduino UNO R3 with FlashForth is an easy start. I can even deliver you an Atmega 328 chip with FlashForth already on it. Also the PIC18/24/30/33 series chips are supported. Most microcontroller forths require reflashing after abuse. But FlashForth has a protected kernel so it won't allow you to write into vital memory that could break the kernel. Check the tutorials at: http://flashforth.com/tutorials.html Download: http://sourceforge.net/projects/flashforth/files/ff5.0.zip/download 
Poor multi-user-forth, gets no recognition or respect. 
I've gravitated to the *deferred word* strategy because I hate the idea that I'll have a conditional that follows one path only once, and then forever wastes time falling through to the other case. 
I realize this makes me somewhat of an heretic, but I like to add named variables and arguments to my Forths (https://github.com/basic-gongfu/cixl), which allows both models to coexist peacefully. 
No defining own macros yet?
I have a pretty long list of more pressing issues, they're not that critical for a language that delegates almost all heavy lifting to the surrounding C program. Host language reader macros are available though, that's how let: and func: are implemented.
Yes, exactly right. The added indirection of a 'defer' word is much less problematic than added conditional code every time through.
In what circumstance would a branch only be executed once during a program's runtime?
Thanks for the info. I am interested in intel x86-64 for a specific reason. But Arduino Forth seems interesting for other purposes as well. I have a couple of Arduino UNO lying around (did some home automation work a short while ago) so I might try FlashForth and have some fun with it after I have a good grasp of Forth programming. I am currently learning Forth (GForth on Linux) and my head is already reeling in a good way... needs a different way of thinking than normal C/Python types of programming.
Nice to see people working on new concatenative languages. &gt; 1 + 2 This only works if the stack is otherwise, so can't be safely used inside of a function, right?
Functions open implicit scopes so that wouldn't be an issue. It's also possible to open a clean scope wherever by surrounding code in parens, kind of like {} in C-languages; or clear the stack before. You still need be aware of your stacks, just like in regular Forth; but you get more options for expression in return.
It works well for cases where the first iteration is different from all others. E.g., when you need to initialize something, but don't want to do the "test if it's the first time through" check all the time. Both cases occur at runtime, but one case occurs only once. 
Okay, that's interesting, thanks for the clarification.
You're welcome.
Oh, that makes a lot of sense.
To make it even easier to get your fix, I just added comma as a cut-operator. I knew there was a reason I spent all that time learning Prolog :) 1 + 2, 3 + 4 https://github.com/basic-gongfu/cixl#expressions
Very interesting stuff! Nice to see a stack-oriented language with optional infix notation.
And optional prefix :) That's one of the things that bugged me from the start with Forth; sure I can see how some problems decompose better using postfix stack semantics, but being forced to use it for everything feels stupid. As does using prefix for math in Lisp, etc. It can't do much yet, but the few lines of actual code I've written have been a liberating experience.
I implemented this as a way to learn forth, so the forth code could be of dubious quality. I tried to keep it compliant to forth-94, but my interpretation of the standard might be wrong given how little experience I have with forth systems. 
Wow, that's really neat! I didn't notice that at first, but I am a Lisphead myself so I find that very nice.
&gt;Symmetry beats consistency What does that even mean?
thanks for this, i always want a forth for wasm 
It means what it says, that micro consistency is more important than macro. That it's more important for complimentary operations or concepts to mirror each other than it is for all of them to follow the same scheme etc. Consistency for it's own sake is like purity for it's own sake, or object orientedness for it's own sake; destructive. It's also boring, there's nothing wrong with being pleasantly surprised now and then.
uhhh.... okay.
&gt; Zen &gt; &gt; Orthogonal is better &gt; Terseness counts &gt; There is no right way to do it &gt; Obvious is overrated &gt; Symmetry beats consistency &gt; Rules are for machines &gt; Only fools predict "the future" &gt; Intuition goes with the flow &gt; Duality of syntax is one honking great idea This is a nice list. Quoting here so I can find and refer to it later. I agree with all of it. Although mainstream programmers would say they explicitly disagree with a number of these and give lip service to the rest.
You're probably right, but then most of them haven't been banging their heads against the programming wall on a daily basis for over 30 years. I tend to disagree with most public opinions; it's always the lowest common denominators, ideas that are catchy enough to convince the majority. It started out as a play on Pythons classic, and could be read as a critique; but took on a life of it's own.
&gt; I've been playing with a file based psuedo stack Goddddddamnit, I'm working on a bash fourth too. Oh well, guess it's not original
I would encourage you not to view yourself as a plagiarist for that. My education is teaching me that to a large extent, (although maybe not all the time) stack-based is simply the right way to do things. I will go further; I think UNIX was originally intended to provide a convergence point between very FORTH-like scripting and physical hardware. The original intent was to have pointers to hardware in /dev which behaved pretty much exactly like raw machine registers, so that you could control hardware straight from a shell script, and have the wonderfully simple control structures that go with that. Shell makes many things a lot easier than FORTH does. Charles Moore would probably object to that statement on the grounds that that user friendliness has a complexity cost, and he's correct; but truthfully I feel that UNIX has some features that are nice enough to trade ***some*** complexity for. I would encourage you to study the head, tail, and [ed](http://wiki.bash-hackers.org/howto/edit-ed) utilities. The ed program is not usually installed by default on Linux, although it generally is on the BSDs. Ed allows me to very easily pop off and push to the first line of a file; the only disadvantage is that I pay (in speed terms) for a file read and write with every iteration, and sometimes that can make things very slow, cumulatively. Get [GNU FORTH](http://ftp.gnu.org/gnu/gforth/gforth-0.7.3.tar.gz) if you haven't already, either. The system word is very useful.
Can you give an example of where these are at odds? I can't think of any obvious examples of where consistency doesn't cause symmetry. I'd expect asymmetry to always be rooted in inconsistency.
One example would be to name complimentary methods/concepts the same way, rather than enforcing a global naming scheme. In cixl, I try to ride on existing idioms and names as far as possible; let, lambda etc.; but I still chose the name 'upcall' instead of 'super', since it balances 'recall' which didn't have much prior art to lean on. I find that kind of local consistency helpful; as opposed to naming every single freaking class that creates something xFactory in Java; or forcing math to be performed in prefix like Lisp; or forcing purity everywhere like Haskell; or pretending that everything is an object like Ruby/Smalltalk. Programming is pattern matching; as soon as you stop doing that start applying principles, you loose something. It's subtle, and looses much of it's essence once downsized to literal descriptions.
Real mode is exclusively an x86 thing, right? If your question is broader than that, I'm running hosted on x86, RISC-V, ARM, 68000, and PDP-11. Standalone on Cortex-M, AVR, MSP430, 8051, PIC, STM8, 6502, and PDP-8.
Broad is good, yes. How did you get your hands on a PDP-8??
Any plans to take it lower?
Where do you find simulators for all those? I'm sticking to x86 because it's available, but I'd love to branch out.
If you're using a shell, maybe the filesystem itself would be a suitable dictionary?
We're working on embedded versions, but it's hard to say just what that will look like at this point.
True. I can load different dictionaries into and out of memory relatively quickly, as well; by sourcing them in, and then killing the bash process which had said dictionary sourced.
I think different dictionaries could be sub-directories off the main dictionary? Keep working on it, I'm very curious about how it turns out!
I'm using these: Simulator | Processor(s) --- | --- Qemu | ARM (classic), RISC-V, 68000 tosemu | 68000 apout | PDP-11 SIMH | PDP-8 simulavr | AVR naken_asm | MSP430, 6502 uCsim | 8051, STM8 PIC | gpsim thumbulator | Cortex-M 
&gt; but I'd love to branch out. You know what they say about x86 and speculative branching...
Yeah I read the official papers on Spectre and Meltdown recently. Theoretically both of these affect every high-performance processor designed/manufactured since the mid-1990s. Scary stuff.
If nobody minds a slight unrelated question on the paper. I noticed the one citation: J.V. Noble, "Avoid Decisions", Computers in Physics 5, 4 (1991) p 386. and the title has me very curious but I cannot find it /anywhere/. Has anybody here read it and can give an idea of what it's about, or perhaps know where one could find it?
I [found it on libgen.io](http://libgen.io/scimag/index.php?s=10.1063%2F1.4823001&amp;journalid=&amp;v=&amp;i=&amp;p=&amp;redirect=1)
That is epic thank you! :) Thanks also for showing me one can use DOIs to search libgen, I didn't know that. ^_^
Most of the electronics on my desk right now is clocked and synchronous. We are comfortable with measuring frequency and time in Hz and seconds. Those come from the most popular calendar system. These calendars are based on the period and movement (frequencies) of celestial bodies that astrologers of a particular ancient culture thought were the center of everything. The ancient astrologers tried to predict the weather and other events by keeping detailed records of the stars with respect to those events on Earth. Modern astrology has almost no connection to ancient astrology. Modern astrology tries to *explain* pop-psychology bullshit with recently invented "astrological signs" and other New-Age nonsense. As far as I can tell Modern astrology does not really do this record keeping. (actually I should say Post-Modern era because I'm living in the post-WWII Occident. Modernism is derived from Romanticism. The Modernism and the Modern period started in a region of France sometime around 1870AC. Modernism was a reaction against the cold and calculating certainty of the Enlightenment period. What really kicked off the Modernist revolt was the rough and dehumanizing transition of skilled craftsmen and women from the countryside to the city for work as unskilled factory labor. Notice that Modernist art rejects Realism and tries to find things humans can still do better than camera or other mechanical device. At least we can come up with new ideas that break with the traditional crafts of the countryside and direct the rote manufacturing at the city assembly lines. Modernists continued down the absolutist (supposedly) one-way march of progress. "Let's find the *best* way to implement this device" ... "Let's find the *best* way to structure this" ... the error of Modernists is the arrogance that breaking with their traditions always leads to something better and that the words "progress" or "progressive" are just synonyms for improvement and those who make it happen. They didn't iterate much at all. They didn't loop back and check whether they were wrong about everything. Yes they rejected things that came before but it was always with the expectation guaranteed improvement. Tech built in the Modern era reflects more of an absolutist intention of finality. The influence of the Modernist school of thought reached a rude awakening when people tried applying it to actual human populations with cold efficiency. Eugenics. Disabled people were tipped off their wheelchairs over balconys. Sex offenders and European ethnic groups perceived to be inferior were gassed with agricultural pestisides. After that experience people started to notice that they felt different. Something felt very different. What they were feeling is another big cultural correction -- the switch from Modernism to Post-Modernism.) So to cut a long story short and back to asynchronous, clockless electronics and Forth [here's a link to a relevant section from an article on Post-Modernism](https://en.wikipedia.org/wiki/Deconstruction#Derrida's_"negative"_descriptions). If I say I'm writing a program you won't have much idea what I'm talking about, so I elaborate with more description. That extra description forbids other possibilities -- it can't include new ones. At no point in time was there such a thing as positive information yet our vocabularies still try to do universal quantification. That's when I started reading about antidictionary compression and working with Forth antidictionaries. So, anyway, maybe there is an indirect causal connection between the SPI clock freq on my PSoC5LP board and the Earth moving around the Sun but I don't think I'll ever find it. While I wait, I think I'll look into the asynchronous nodes of the GA144 or the asynchronous configurable SmartIO logic on the PSoC6 for a more local time reference.
And here we are watching in horror as liberals, technologists and trans-humanists are busy inventing new ways to cause more suffering in the name of progress. Evolution is a spiral, we keep coming back to the same point on ever higher levels; personally, I look forward to the post-technologistic era.
&gt; And here we are; watching in horror as liberals For what it's worth the Marxist "left", the fascist and nazi "right" are all considered Modernist. Socialism and fascism even went through fairly a similar process of centralization from their early period of self-organization (on the "left": anarchism/Spanish Revolution/Makhnovism/Soviet worker cooperatives --&gt; Soviet Union and on the "right": distributism/Catholic Syndicalism, e.g Mondragón cooperative --&gt; fascist social corporatism). If you want to know what caused some Marxists to diverge from mainstream Marxism and eventually split of into a new political system known as fascism read some [Georges Sorel](https://en.wikipedia.org/wiki/Georges_Sorel#Relation_to_Marxism) he was the pivot from Marxism into fascism. Spoiler: the split was mostly over religion *not* over antisemitism, racism, and nationalism-vs-imperialism. Fascists and Marxists of the day were largely in agreement on the latter. Pretty much the only enduring feature of fascism that sticks out at me worldwide and where I live in California, USA is Mussolini's economic system of social corporatism. It was the inspiration for the New Deal here in America. &gt; I look forward to the post-technologistic era. When I drive car I feel as though the steering wheel has become another limb and the sheet metal outside is my skin that I want to protect. That's what a tool should feel like. Tech minimalism counter-cultures such as plan9/suckless/Forthers are engaged in a power struggle to keep our tech as tools so we don't have to recalculate our worth after each innovation.
The Let over Lambda book has a few chapters about Common Lisp and Forth, including an implementation with Lisp interop.
Oooh, I'll have to take a look at that. I'm not very clued up about CL but I figure with the bit of Scheme I've done I should be able to get the general idea. :) Thank you!