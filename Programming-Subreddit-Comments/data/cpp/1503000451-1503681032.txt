Another one that I've run into a few times... The destructor for std::thread cannot be called on that thread. This can happen if for example a thread running inside a ThreadPool object has a shared_ptr to that ThreadPool, and the ref count goes to zero. A good way to get around this specific example is to have a join() member function on the ThreadPool that calls join on all threads it owns. ThreadPool::join needs to be called from a non owned thread. 
Fascinating, thanks. I remember once reading something about how clang's `set` didn't technically meet some requirement, and it was related to their choosing to have a default constructor. I think I agree with this approach, a noexcept move constructor -&gt; default constructor is just so important.
Yay it fixed some annoying false-positive intellisense errors with templates.
There's a fair bit of work to do to get CppCoreCheck integrated with CMake. We've investigated what it would take, and have some plans, but no committed timeline as of yet. 
From what I understand (N)RVO allows the compiler to construct the returned value in the place it will be returned in. So the whole point is that neither copy nor move take place. This can obviously only happen with one value, so if you conditionally return different variables/instances it would apply only to (at most) one of them.
This is correct.
It can use a thread pool
I'm not sure about 12, what if two threads do this concurrently? 
As far as I know, only `std::async (std::launch::async | std::launch::deferred)` can use thread pool. 
Here we go! I didn't realize this was out there. Here's some library-ish support: https://github.com/lewissbaker/cppcoro
I run into this all the time!
Link for 2017: https://docs.microsoft.com/en-us/visualstudio/debugger/just-my-code Can we have support to have the natstepfilters loaded from the local directory like .natvis files are?
These are the frames I wish we could skip: std::_Invoker_functor::_Call&lt;.*&gt; std::invoke&lt;.*&gt; std::_Invoker_ret&lt;void,1&gt;::_Call&lt;.*&gt; std::_Func_impl_no_alloc&lt;.*&gt;::_Do_call std::_Func_class&lt;.*&gt;::operator()
Who forgets to use a mutex?
You can detect RVO by using a class that prints when it's copy constructor or move constructor is called. [Here's a simple example.](http://coliru.stacked-crooked.com/a/995c7db926b96c38)
I don't really see the use for `std::future` even with `then` et al. At that point why not just use callbacks directly? Better yet why are we even comparing and contrasting them all when we can have them all using the [universal model for asynchronous operations](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2013/n3747.pdf) present in Asio and the Networking TS?
It can, but the *as if* wording in the standard means all thread_local variables must be reinitialised when the thread is reused, which makes a conforming thread pool implementation more complicated than it should be
On number 15, you made a small mistale int val is declared in the scope of the if statement so it cannot be processed afterwards
Well, it does, as it turns out... While you can probably find an implementation that allows you to handle this case, (1) I couldn't find any; (2) standard is ok with std::terminate in this case
Problem is that standard doesn't mandate any behavior in this case -- so you can't write a program that handles it on any compiler. For example, GCC doesn't preallocate space for every thread -- it's emergency buffers can serve no more than 64 threads. If you are interested in this topic, check https://groups.google.com/a/isocpp.org/forum/#!forum/std-discussion 
That's what happens when you do lock-free programming.
**Mistake #0: Sharing Data** If you don't share data between threads, at least half of the other mistakes go away. Don't be afraid to copy data in order to avoid sharing. EDIT: read-only sharing is fine (doesn't need mutex etc). But when one thread is mutating, try to figure out what really needs to be shared (limit the size of data being shared) and then also consider if it can just be copied.
I'm somewhat sure the suggested fix for mistake #8 is wrong, at least for C++14. You can use [std::lock](http://en.cppreference.com/w/cpp/thread/lock) to acquire multiple mutexes.
** Mistage #0: Assuming synchronization is not needed ** Example: SomeFoo* someFoo; ... //By multiple threads //No need to to guard. We either have new foo or old foo. Both should be fine. What can go wrong? someFoo = getNewFoo();
&gt; 3. Making it immovable. Most ownership will occur through a customized optional wrapper that allows moves by emptying out the optional (note that you can't use std::optional for this). Do you have any references to further discussion/implementation of this? It seems like the best possible approach...
Simplest fix: Don't create new threads.
I have to admit I kind of hate the way futures/async work in c++. Async seems like it would be really great for fire-and-forget .. well .. async things .. but with the future blocking the originating thread when it falls out of scope even if you don't care about the result...*groan*...
Honestly disappointed that list was in order. What a missed opportunity. 
I think I'm too used to how traditional threading works...can someone tell me why I would want to block for asynchronous calls? Or, if these calls need to block, why are they not synchronous?
&gt; future returnd
Quite sure each thread should have its own global stuff. 
It's not blocking. Taking a simple example: std::future&lt;void&gt; foo() { do_something(); co_await bar(); do_something_else(); // might need `co_return;` here; I'm more familiar with C#'s async/await } Conceptually, execution proceeds normally until `co_await` bar is reached. Now the `bar` call is going to take some time, so `foo` returns an incomplete future to its caller and schedules a continuation. When the future returned by `bar` completes, it runs the continuation (`do_something_else`). Then `foo` finishes and the future it returned earlier is marked as complete. Now imagine if `foo` is something called from a message loop. While `bar` takes its sweet time to run, control returns back to the message loop and the UI doesn't hang. Really, the caller of `foo` can be anything that uses the returned future, whether that be through `.then` to schedule a continuation, `co_await` to propagate the behaviour upward, `.get` to block, or something else. All you're saying is that you need `foo` to finish before continuing, but you don't want to block the thread. Edit: Possible code fix
std::future makes handling exceptions easy.
nope, unless it's marked thread-local (and then it would not be useful to communicate with the main thread)
&gt; Don't be afraid to copy data in order to avoid sharing. Is it that simple though? You either share read-only data, in which case you don't have all those issues anyway. Or you share data you write into, in which case you very likely want to read those writes in other threads, meaning that copying the data would not help, either.
Flip sides: Read-only sharing by N threads works great, is safe, and easy to do. Similarly, shared-memory communication has *much* higher performance than message-passing when the performance is necessary. Just conceptualize it as hardware-accelerated message-passing (because it is), and you'll be fine.
I wondering if forced asynchronous programming for certain APIs should be in there. Man. I needed point A to point B to point C, and one time, it was hard since point A was forced asynchronous 
&gt; Isn't std::async (std::launch::async)basically required to create a new thread by the standard and so Microsoft implementation is non-conforming Yes, and we have this fixed. But the fix isn't ABI compatible, so it won't ship until the next major release of the libraries. Sorry :)
&gt; Mistake # 8 : Not acquiring multiple locks in the same order Actually (I learned relatively recently) that enforcing a lock ordering is actually suboptimal. See /u/HowardHinnant 's paper here: http://htmlpreview.github.io/?https://github.com/HowardHinnant/papers/blob/master/dining_philosophers.html I implemented Howard's algorithm for our STL in VS 2017 15.3, and libc++ uses that algorithm. I believe (or rather, have been told that) libstdc++ does something slightly less efficient but that still works. You should consider use of std::lock and forget about trying to maintain the right order.
Sharing data is not the problem, unsynchronized potentially-mutating access is. If you can forget to hold a mutex, or a rw lock, then put the data behind an abstraction that forces you to take the lock to be able to access it. If avoiding bugs by incuring a performance cost were alright, I wouldn't honestly be using C++.
For instance most modern game engines work like this : an object isn't a set of fields fixed at compile time, but an aggregate of components: lighting, mesh, physics, sound, etc etc. And these components can vary at run-time. 
Thanks for the lists. Great read. What I find most striking is that even experienced programmers can't seem to agree on the problem/solution. To me the whole area are still very fuzzy, is still perhaps immature, still evolving and has really not settled yet with best practices. What I would like to see is a state-of-the-art small sample application showcasing concurrency/parallel programming, something in line where user can start/stop/cancel/resume tasks and see progress feedback for each of them. If anybody know of good examples please post links. Perhaps this can only be done properly after C++20 when library extensions has matured.
Here is the link: https://developercommunity.visualstudio.com/content/problem/96411/impossible-to-ignore-warnings-from-system-librarie.html
I prefer the OP's, which (you know, as a bonus) actually explains the points.
Article has some cool tips, but inclusion of some very obvious things is odd.
The following code does not compile in MSVC with **/permissive-** set in the compiler options: https://wandbox.org/permlink/VONfGA3fEqjDILB2 template &lt;typename T&gt; struct wrapper { T value; }; template &lt;typename T&gt; struct traits {}; struct statement { template &lt;typename T&gt; T get() const { return traits&lt;T&gt;::get(*this); } }; template &lt;&gt; inline int statement::get&lt;int&gt;() const { return 1; } template &lt;typename T&gt; struct traits&lt;wrapper&lt;T&gt;&gt; { static wrapper&lt;T&gt; get(const statement&amp; statement) { return { statement.get&lt;T&gt;() }; } }; int main() { statement s; return s.get&lt;wrapper&lt;int&gt;&gt;().value; } Error in line 24 "return { statement.get&lt;T&gt;() };": main.cpp(24): error C2187: syntax error: ')' was unexpected here main.cpp(26): note: see reference to class template instantiation 'traits&lt;wrapper&lt;T&gt;&gt;' being compiled I would greatly appreciate a fix or workaround suggestions (except removing **/permissive-**, obviously).
maybe try with return { statement.template get&lt;T&gt;() }; instead ?
This is the best C++ IDE (both for Qt projects and CMake projects). I have questions though, do you know when they are going to switch to Clang 4.0 in their clangcodemodel?
Yes, this seems to work! Thank you very much.
A lot of the points are invalid when writing modern C++ (e.g.using locks).
&gt; When you rename a symbol, you are now offered to also rename files with the same name. This is a big one for me. Having to rename files manually was a pain.
https://www.codetriage.com is a good starting point.
I get how and why I would use async tasks and threads, I've written my fair share of thread pools and asynchronous task queues and the like! I suppose what was lost on me here was that the whole function itself seems to be asynchronous and it's calling more asynchronous functions within it, which makes more sense. E.g. I call out to `foo()` from another thread and it can perform the sequence it needs to perform.
Any predictions, when this toolset update will be released? We have the same problem and I'll have to find a way to reinstall 15.2 over the weekend without triggering an update. Very inconvenient, especially since I only installed 15.3 because I couldn't modify the previous installation otherwise.
I would like to use QtCreator (the only IDE with CMake server support, refactoring tools and a clang based parser!), but I cannot stand the way multiple open documents are handled. Say I have two classes open, each in one window. When I Ctrl-Left click a member function of the other class, it does not focus the other window and jumps to the definition, it opens the same file again in the same window. Is there a way to change this behavior? I also don't like the absence of tabs and the cumbersome way to create a split screen. I think Visual Studio is the only IDE that I tried and got it right by simply drag/drop the tabs.
&gt; Mistake # 13: Using threads to simulate Asyn jobs when std::async will do &gt; If you just need some code executed asynchronously i.e. without blocking execution of Main thread, your best bet is to use the std::async functionality to execute the code. I don't see how I can use `std::async` in practice, the `future` destructor blocks, as does `future.get` so this cannot be used in a GUI nor to generate a server response. It will block the Main thread, which is exactly what you want to avoid.
I agree. I have been using code alignment in huge code bases for several years and it is definitively a big + in readability/maintainability. 
&gt;This is the best C++ IDE... [You haven't heard about it](https://www.gnu.org/software/emacs/).
The part that's not clear to me is whether bar then (possibly) runs in a separate thread, or is it like node.js and is there only one thread?
If you are willing to go a little more keyboard focused, the keyboard shortcuts for managing splits are convenient. "Ctrl+e,3" for split vertically, "Ctrl+e,f2" to jump to definition in other's split. I always navigate to files using the locator or jump to definition, so lack of tabs has never bothered me.
I assure you, we have. Emacs isn't actually a great ide...
Thank you!
I have been (and am) Emacs user (and gnu fan) for long time. But I have always hated childish people who try to change subject of an unrelated discussion to Emacs(or vim in that matter).
Having thought about it more, there are some issues with a customized optional wrapper; it would be a bit hard to make really elegant. But a more common solution (that you're probably already aware of) is to simply use a `unique_ptr` to the uncopyable object. There's an indirection of course but I've rarely have that be an issue. This allows ownership transfers by moving the `unique_ptr&lt;File&gt;` itself, but it allows functions to accept `File&amp;` which must always be valid. Another approach that I've taken on several occasions is the notion of "handle" classes. In this case, the owner of the file/pipe/etc resource is an optional owner. However, you can't directly do any operations through the file/pipe class itself. Instead, you have a function wherein you request a handle class. This function could either throw, or return an `optional&lt;FileHandle&gt;`, in case the object doesn't currently own a file or isn't able to open a handle. The `FileHandle` class can be unassignable to make it handler to have a `FileHandle` dangle past the end of the lifetime of the corresponding `File` object. The nice thing here is that functions can now accept a `FileHandle`, instead of a `File`. In essence moving the responsibility for checking whether there is really a file present, up the call stack as much as possible. This is very similar to passing things by reference instead of pointer to functions that don't want to ever receive null. Basically our owning class still encodes the optional semantic but we provide a second class that encodes the a non-owning, non-optional semantic. So, in this approach, `File` is equivalent to `unique_ptr&lt;File&gt;` from the previous approach, and `FileHandle` is equivalent (roughly) to `File&amp;` from the previous approach. Which makes more sense really depends on your use case. I've found the handle approach to be really awesome in some situations because the handle class can do things in its destructor as well. Hope that helps!
This seems to work, thanks! I just looked it up in the settings. This is really well hidden.
&gt; both for Qt projects and CMake I use it exclusively for plain C++ projects using qmake, and I find it immensely useful for that as well.
The author of types like `std::future` gets to decide. That's the beauty of C++ coroutines. It specifies only how the language constructs are lowered into calls to the user-defined types in play. So you can give it the semantics *you* want.
&gt; When I Ctrl-Left click a member function of the other class ctrl-k m member_name (of course generally the first few characters are enough). Also even though there is no visible tab list, you can cycle through documents with ctrl-tab.
&gt; then put the data behind an abstraction that forces you to take the lock to be able to access it. which is darn simple with c++17 : #include &lt;vector&gt; #include &lt;mutex&gt; auto get_data() { static std::vector&lt;int&gt; data; static std::mutex m; return std::forward_as_tuple(data, std::unique_lock{m}); } int main() { auto [data, _] = get_data(); data.push_back(123); }
Other than `if constexpr` though, what is the main gain here? You get operator overloading which is nice, but that's only a very small set of cases (really equality/inequality is the only commonly used trait that I'd represent with an operator). Compare: else if constexpr(type(t).is_integral()) with else if constexpr(std::is_integral&lt;T&gt;{}) The only differences are that you don't need this weird type macro, and that you use `T` instead of `t`. I'm not opposed to being convinced of the value of `type`/`Type` but it's not evident from this example. Also making `is_integral` a member is a huge mistake. It should be `is_integral(type(t))`. Having all the traits you need on some monolithic class just doesn't make sense, users of `Type` cannot modify it.
BTW C++14 constexpr still produce ICE https://godbolt.org/g/r7qPMg https://developercommunity.visualstudio.com/content/problem/47646/ice-in-c-compiler-c14-constexpr-related.html?childToView=96940#comment-96940
There is a small typo in one of the titles. `true or flase type`
**Company:** [think-cell](https://www.think-cell.com) **Type:** Full time **Description:** Do you believe in beauty when it comes to programming? Do you have a vivid interest in elegant algorithms? Are you fluent in C++? If so, we would like to meet you. Here is what we offer in a nutshell: * A wide array of extremely challenging C++ development tasks * An international team of brilliant minds * A working environment that makes this team stay and grow * Enough time to make sure that every detail of your solution is perfect * A flat organization and plenty of room for your ideas * No scheduled meetings * Family-friendly working hours, no deadlines, no overtime * Support for relocation * A competitive salary from the start and a raise to EUR 120,000 annually after only one year think-cell is a fast-paced software company in Berlin, Germany, with a focus on developing graphics products that stand out from the crowd. More than 550,000 users world-wide rely on our software for their daily business as it makes creating graphical presentations so much easier, faster and more enjoyable. Among our customers are many renowned consulting companies and large international corporations. We do not have to make compromises with regard to code quality and beauty, because think-cell is profitable and has no outside investors. We are willing to go the extra mile of developing sophisticated algorithms and refining our user interface, and we are proud of our many happy customers. The fact that the company is owned and managed by seasoned computer scientists certainly contributes to a working environment that makes exceptional developers come and stay. **Location:** Berlin, Germany **Remote:** no **Visa Sponsorship:** yes **Technologies:** Language * Everything we do is C++. Even our customer portal is written in C++. There is some Assembler glue code where it is necessary, and our build scripts are written in Python, but other than that think-cell is all about C++. * Naturally, we use C++11 features like lambdas and rvalue references throughout our codebase, and have switched to C++14 where our compilers support it. * We fund the working group for programming languages of the German Institute for Standardization (DIN). Some of our employees are members of this committee and vote in the international standardization process of ISO/IEC C++. Library * We use Boost throughout our code, e.g., Boost.Spirit for parsing. * We have our own range library, in the same spirit as Boost.Range or Eric Niebler’s range-v3, but going further, for example, by unifying internal and external iteration. We gave a talk about it, and most of the code is public. * We develop our own cross-platform library to support Mac and Windows with a single code base. * We have our own reference-counting and persistence libraries to save and restore whole object trees. * We have an extensive bug reporting infrastructure. Assertions and error checks stay in the release code, and our software automatically reports bugs to our server. The server analyzes the bug, categorizes it and files it in a database that all developers can access. If an update fixes the bug, the user can download the update directly from a bug response web page. **Contact:** Send us your CV at hr@think-cell.com 
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/6uikym/help_me_understand_size_type_please/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Well, I'm mainly exploring how far it can reach by replacing type-based operations with constexpr value-based ones. I agree the function being a member is worse than being a standalone function. There are 2 common use cases in TMP: type transformation, and static dispatching, currently I'm focusing on the first part. I believe by "downgrading" type operations to (compile time) value operations, it encourages the use of regular programming language features, such as functions. Adding const / volatile to a type in TMP is implemented with type alias in a template class. With a type value, it would become a constexpr function that takes a type tag and returns a type tag of the result type, like this: template&lt;typename T&gt; constexpr TypeTag&lt;const T&gt; add_const(TypeTag&lt;T&gt;) { return {}; } It doesn't stop here. Think about type lists. How would the interface of such type list look like in TMP? using L2 = Concat&lt;Remove&lt;L1, Head&gt;, Ts...&gt;; something like this? Then how about this? typetag&lt;T1, T2&gt; + typetag&lt;Ts...&gt; - typetag&lt;T1&gt; //Result: typetag&lt;T2, Ts...&gt; or this? tlist[tlist.length() - 1] //gets last type tag Basically, it is the potential of downgrading syntax complexity that attracts me. Meta classes become functions, specializations get replaced by overloads, and also by wrapping types into values, we gain the hidden type layer again, that can be useful themselves e.g. TypeTagList&lt;...&gt;::operator[] would get back TypeTag&lt;&gt;
Okay, fair enough. I think the example you present though is a bit too bare bones to really make your point. Needs to present more contrast/examples I think. Also the macro you present is very confusing, plus realistically such a macro name would never be allowed due to clashes. If you're going to make it value based, why don't you make it look value based instead of this weird `type` syntactic sugar? You can use template variables to get rid of a bit of the cruft: template &lt;class T&gt; static constexpr auto type = TypeTag&lt;T&gt;{}; if constexpr (type&lt;T&gt; == type&lt;long long&gt;) { std::cout &lt;&lt; "hello\n"; } else if constexpr(is_integral(type&lt;T&gt;)) { std::cout &lt;&lt; "world\n"; } Etc. Using a macro has significant downsides, I don't think you'll be able to persuade people to use a macro to get rid of a couple of curly braces. Realistic macro usage requires long names (prefix with the library name) to avoid collisions, so using macros to avoid a few characters is not a good policy.
thanks!
I guess something like typetag or type_c from Boost::hana would be a better name. The main reason to have a macro (that coincidentally is allowed to be the same as variable template) is to support expressions rather than types. Alternatively, it would have to be implemented as a function with a different name, and it would inevitably evaluate the expression. Otherwise we would have to write `typetag&lt;decltype(expr)&gt;`. Probably not enough confusing, but still another layer of complexity.
Counterpoint: 90% of the time, I don't actually care what concrete class foo is, I care about the concept foo represents. This should be clear from your naming scheme/context clues anyway. Another counterpoint: Yes, sometimes auto makes me spend time hunting down what class something is. But not having auto makes me spend time doing mindless changes in refactors, and I find auto saves me more time than it costs.
This is a nice list, and a useful one. However, like /u/ntrid, I'm a little concerned that some very simple issues are mixed together with some very deep ones. This strikes me as a nice article that could easily be split into three nice articles, each of which would be better focused than this one. &gt; Mistake # 1: Not using join() to wait for background threads before terminating an application This is important. It is also part of Threading 101, and anyone who does not understand it has no business being allowed anywhere near production multithreaded code. Also, anyone who doesn't grok #1 thoroughly probably has no idea what issues like #16 and #17 are even talking about. &gt; Mistake # 8 : Not acquiring multiple locks in the same order Now it gets interesting. It is true that consistent lock acquisition order is a tool for avoiding deadlock. However, if I were doing code review and I saw a thread acquiring multiple locks, then I would ask the coder, "Are you sure that simultaneous holding of multiple locks is really part of the best design?" And, "Are you aware of the dangers inherent in a thread simultaneously holding multiple locks?" Also, consistent acquisition order is a good tool, but it is not appropriate for every situation. And the idea that someone might use it as a way to avoid deadlock without having to understand just what the threads are doing -- that gives me the willies. &gt; Mistake # 10: Using mutexes when std::atomic types will suffice Well, there are mistakes, and then there are *mistakes*. #10 involves a significant performance issue. OTOH, multithreaded code has the potential for devious &amp; subtle bugs, and if a programmer is so concentrated on avoiding those bugs that he forgets that atomics are generally faster than mutexes, then I say, "Good for him!" His heart is in the right place. Any performance issues that pop up can be dealt with later, *after* the code is working. 
I also see a problem with `auto foo = ImReturningSomethingButYouDontKnowWhatMuhaha();` but it can be solved without removing `auto`. You may be arguing that `auto` encourages better communication and naming.
There's a dropdown at the top of each split allowing you to select any other open file. I find this much more useful (and a better use of space) than tabs.
Well, yes, I'm arguing that the type should be used from an amibiguos function: `auto foo = whatAMI();` // WTF is foo!? vs `Cat* foo = whatAmI();` // Oh, it's a Cat*!!
My keyboard is `std::ready`!
Why not auto cat = getMeACat();
When you can, sure. But you don't always have the luxury of naming/renaming methods/variables.
If people don't name their variables and methods sensibly, would they name their types sensibly?
Darn simple sometimes equates to darn inefficient. Here every reader gets a write lock, which can be extremely costly. Do not do that.
Even a badly named type is more informative than `auto`.
You make a good point about `auto` saving you more time than it costs and I can see how that would affect your opinion on it. I am on the fence if it costs me more time or saves me more time. I suspect it saves me more time but it's probably like a 60/40 split, which is not ideal.
`typedef int ImSomethingButYouDontKnowWhatMuhaha;` 
So now I'm typedef'ing in code I control but the original name is still used in code I don't. Which means we now have two names for the same type. That does not sound ideal.
On one hand, true. On the other, if your recommendation is to skip using the official tool, why have the official tool?
Just used `typedef` for brevity. class ImSomethingButYouDontKnowWhatMuhaha { // You need to read my implementation to understand me. };
&gt; I don't actually care what concrete class foo is, I care about the concept foo represents. This is important. When you use the almost always auto style, you get a bunch of benefits, starting with C++17 there are no exceptions to that anymore (thanks to guaranteed copy elison), and starting with Concepts, we can express what our code actually needs properly: InputIterator first = vec.begin(); InputIterator last = vec.end(); return std::find(first, last, 42); In other words, I see `auto` as `template&lt;T&gt; concept auto = true;` (that annoying `bool` syntax was dropped, right?) And once clangd is ready, we will have wider support for correct type deduction in text editors and IDEs.
ITT a great point by someone who works with other people's code countered by people who only work on their own code.
&gt; Here every reader gets a write lock, which can be extremely costly. AFAIR there are quite a bunch of benchmarks that shows that the overhead of shared_mutex itself is generally not worth it vs just locking every time. even then, it can just be #include &lt;vector&gt; #include &lt;mutex&gt; #include &lt;shared_mutex&gt; #include &lt;thread&gt; class my_data { std::vector&lt;int&gt; data; mutable std::shared_mutex m; public: auto get_data() { return std::forward_as_tuple(data, std::unique_lock{m}); } auto get_data() const { return std::forward_as_tuple(data, std::shared_lock{m}); } }; int main() { my_data m; std::thread t([&amp;dat=std::as_const(m)] { dat.get_data(); }); auto [data, _] = m.get_data(); }
If you have all the locks in one place, std::lock is great. I'm usually not in that situation. Code base A protects its state with a mutex, code base B protects its state with a different mutex. There isn't any code that has access to both mutexes. Ideally, you don't nest the locks at all, but if you must, then you need to enforce a lock order.
I got it working! At least with VS Solution instead of the folder view. cmake_minimum_required(VERSION 3.9) project(asdf) function(enable_vs_guideline_checker target) set_target_properties(app PROPERTIES VS_GLOBAL_EnableCppCoreCheck true VS_GLOBAL_CodeAnalysisRuleSet CppCoreCheckRules.ruleset VS_GLOBAL_RunCodeAnalysis true) endfunction() add_executable(app main.cpp) enable_vs_guideline_checker(app) 2&gt;c:\users\mh\documents\testproj\main.cpp(5): warning C26490: Don't use reinterpret_cast. (type.1: http://go.microsoft.com/fwlink/p/?LinkID=620417) 2&gt;c:\users\mh\documents\testproj\main.cpp(4): warning C26494: Variable 'x' is uninitialized. Always initialize an object. (type.5: http://go.microsoft.com/fwlink/p/?LinkID=620421) 2&gt;c:\users\mh\documents\testproj\main.cpp(5): warning C26496: Value pointed to by 'y' is assigned only once, mark it as a pointer to const. (con.4: https://go.microsoft.com/fwlink/p/?LinkID=784969) It can probably be enabled in the folder view using the enviroment variables/compiler flags approach. Edit: I got it working in the folder view, but now it also checks all the systems headers: cmake_minimum_required(VERSION 3.8) project(asdf) set(ENV{esp.extensions} cppcorecheck.dll) set(ENV{esp.annotationbuildlevel} ignore) set(ENV{caexcludepath} "%include%") function(enable_vs_guideline_checker target) target_compile_options(${target} PRIVATE /analyze /analyze:plugin EspXEngine.dll) endfunction() add_executable(app main.cpp) enable_vs_guideline_checker(app) /u/AndrewPardoe This also checks all the system headers. I tried prepending `caexcludepath` with `.esp`, but that didn't help. Are you sure this disables the checker for system headers? Or is this something CMake related?
Are you saying that serializing all readers is somehow benign compared to allow them to read concurrently? The snippet I commented on is a scalability disaster.
I don't get what you're saying. If you don't know what's the type of an expression, what does `auto` have to do with this? How is `auto` to blame? If instead of auto foo = func(); you had T foo = func(); does that reveal to you what the return-type of `func()` is?
When you're dealing with containers, iterators, and smart pointers, auto generally works fine because there is a well known backing concept. I'm usually not dealing with those. For example... auto person = lookupById(id); If I need to modify the code following that line, I probably want to know what kind of operations are reasonable on 'person'. For that, I'd like to look at the class declaration, or declarations if there is a lot of inheritance involved. With auto, you need to find out what type is returned by lookupById before you can even find the class declaration.
**Company**: [Nitro!] (https://www.gonitro.com/about/jobs) **Type**: Full Time **Description**: We make documents smarter! At Nitro, we are changing the way the world works with documents, and leading the digital transformation of the world’s largest companies. Today Nitro is the #1 replacement of Adobe Acrobat, and we’re leveraging our success to build the next generation smart document platform that is revolutionizing document productivity, corporate security and sustainability. We are looking for C++ Engineers who are not only developers but are also investigators, code divers, bug bashers and all round troubleshooters. If you like problem solving, puzzling out the whys and wherefores of complex systems then this job is for you. **Location**: Dublin, Ireland The role is open to all EU citizens. We will provide relocation, if needed. **Remote**: No **Visa Sponsorship**: No **Technologies**: We use C++11 and C++14 with both Linux and Windows. Looking for Windows development experience. **Contact**: Please reach out to me joty.chahal@gonitro.com
`auto` obscures information. In the second example you gave, I know `foo` is a `T` but in the first one, I have no idea. 
Game developers generally use ECS for this. This fulfills the need for this sort of object mutation, with good performance.
&gt; the only IDE with CMake server support, refactoring tools and a clang based parser Does CLion not satisfy this because it (from what I remember) uses it's own parser?
Copying the data is not a performance cost, it is a performance win. Blocking on a mutex is a performance cost. Lock-free is a performance cost compared to separating data. Contention is a performance cost. Of course, like everything in C++, the answer is "it depends". But computers actually copy bytes fast. Contention is slow.
Putting type names in function names sounds awfully like Hungarian notation
If you want to avoid deadlocks, I would suggest making your lock-holding be smaller and isolated, or your lock-grabbing be more obvious. Imagine your code once main() (or whatever function calls get_data()) gets bigger and bigger over time. And that lock is held the whole time.
You know `foo` is a `T` but you don't know what `func()` returns. If you want `foo` to be a `T` regardless of what `func()` returns, you say `T foo = func()`. If you want `foo` to be the return-type of `func()` you say `auto foo = func()`. And if you want to know what that type is, you go and look. You don't write `T foo = func()` to communicate that `func()` returns a `T`. That is a *horrible* idea. If you want `foo` to be of the return-type of `func()`, and you say `T foo = func()`, then I argue that what `T foo = func()` obscures is worse than what `auto foo = func()` obscures, never mind that it may well be incorrect and introduce a bug or a performance penalty.
Yes. It still lacks many C++14 features. And I *think* it also parses the CMake cache instead of using the server mode. Not sure about that one, but it is probably a lot less complicated than writing a C++ parser.
You copy a snap-shot, work on the snap-shot, merge in the answer (if there is a result to merge). So, like all C++, "it depends". But often the "work" takes time, the merge is fast (or non-existent). ie rendering - render a snap-shot of the doc. It is out of date, but that's fine. The result (the render) doesn't get merged back in anywhere, it is just shown and thrown away (well, recycled).
yes, read-only sharing is fine. I should edit my post. I understand what you are saying about "hardware-accelerated message-passing", but it also tends to lead to poor code separation and bugs (and holding locks too long, etc). Sometimes it is worth it, sometimes not.
I agree with that. My point is that we are almost to the point where we can replace `auto` with something better. I can write `Person p = lookupById(id)` to express in the code that we want an object that satifies `Person` instead of wondering if it *has to* be `young_person` or it could also be replaced by an `old_person` without resorting to classic polymorphism and interfaces. Once we are there, gcc already is and soon the other compilers are, AAA really is "Almost Always Concept" and `auto` means "I really don't care".
&gt; You know foo is a T but you don't know what func() returns. If I browse to some code and I see: `T foo = func();` then I know `func()` returns `T` because the code compiles. My entire gripe is based on the idea that I'm working on a project in a team environment, where we have nightly builds and uncompile'able code doesn't last long. The points you make may be valid on a project that a single person is working on. Of course if I am the sole developer then I will make sure my naming conventions are informative and make sense, but as I've mentioned, you don't always have control over the entire codebase. I am not saying `auto` should never be used. I'm just pointing out instances where I don't think it should be used.
It's like autocorrect, you're never quite sure if it's helping more than it's hurting ;P
Why do you think that is the case? On github alone there's roughly 5,000 active C++ repositories (according to some brief searching). Surely a fair portion of those repositories could use additional developers, no?
&gt; Game developers generally use ECS for this. well, yes, exactly: https://ibob.github.io/dynamix/#ecs
Good point. That's why at our company we only allow auto when you need it (lambdas, templates, etc). Readability trumps writability every time.
No, you know that `func()` returns something that is *implicitly convertible* to `T`. Sometimes this difference is critical.
I think /u/wilhelmtell is referring to implicit type conversations in the post above. If foo is type T all successful compilation tells you is that there is an implicit type conversion between the return type and T.
That's true. Although you'd somehow need to arrange for those two external locks to always be looked at in the same order which can be challenging :/ 
&gt; If I browse to some code and I see: `T foo = func();` then I know `func()` returns `T` No, you don't. If you do, that line of code fooled you. It may have conversion going on there, and you'll never know until you explicitly look, exactly because it compiles. struct T { T(S s); }; S func(); // ... T foo = func(); This happens all the time, and is part of the reason we have `auto` in the first place. That silent conversion there can mean loss of information, as often happens in conversion. struct S { int x, y; }; struct T { T(S s); int x; }; S func(); // ... T foo = func(); It can mean side-effects you haven't fully reflected on, as is often the case with functions in a language that allows for side-effects. It can mean a silent performance hit, as is often the case in conversion. char* func(char*); // ... std::string foo = func("hello"); It can mean any number of things when you call a function, because functions can do anything. If you want a conversion, that is perfectly fine. To me, `T foo = func()` expresses that. It says, “I want `foo` to be of type `T`, so make sure that is the case”, which, in turn, entails a possible conversion. To say `T foo = func()` when you absolutely don't want a conversion, but you merely assume that `func()` returns a `T`, is exactly saying one thing and meaning something else. Never mind that your assumption may either be wrong or repeat (duplicate) code. There is a time and place to say what a function returns, and it's not at each and every call-site. We already usually repeat this information twice, at declaration and at definition. There's no need to make it worse.
I completely agree with you there. In my experience code is read way more often than written. This includes reading code that was written years ago by you or someone else. Reading code is done to understand the code, to maybe modify small parts. Thus a lot code is read and only small parts of it are modified. Therefore I try to make my code easy to understand and do not focus on making it easy to refactor. I still do a lot of refactoring though and I don't think AAA would have helped me much. So in case of auto that means I use it where specifying the type makes reading harder. Like iterator types, template code ... Arguing that some IDEs show the type on hover is not an argument for me. Because it would mean that I have to hover lots of variable names, which is more than just reading.
Then you will also be annoyed by all dynamically typed languages such as Javascript and Python.
If your program stops working then is that really handling an out of memory situation? Seems to me like this is still an issue of overall design and resource usage and not about whether or not your process still runs after receiving an allocation failure, even if it's not doing anything useful. If you're really running in a memory constrained environment, state that upfront and design your system to work with that in mind. Don't just run without care and then respond to any generic allocation failure at any point in the code. The error handling opportunities there are so much more complicated.
Scala programmers had to deal with his over a decade ago. The solution is common sense, possibly encoded into a coding style guideline if necessary. Just as we make variables descriptive to make the code readable, we declare types explicitly when needed to make the code readable. Inferred typing is simply a new potential way to obfuscate code. But it's also a way to tighten up code in those cases "where the type is obvious" as you say. https://docs.scala-lang.org/style/types.html#inference
I'm not sure I follow the text in the link. There is no inheritance in ECS. There is no dynamic polymorphism or virtual calls there. The strong point of ECS, apart from composing objects at runtime, is the cache-locality. All the objects in the game lie consecutively in a matrix, or an array of arrays. To access the objects, systems iterate over them linearly, rather than doing random jumps in memory to deal with one object after another. I haven't looked at DynaMix. Is it cache-friendly?
Sure, I should have made it clear that the function's name should be suggestive of its result, and not actually use the return type's name in its own name.
What does a type name really give you though? If you're intimately familiar with the code knowing the return type is object X, may give you enough information on what to do with X, but at the same time you likely already know that function Y returned an object of type X. If you don't know anything about the code and need to know what the return type of the function is to know what to do with it, you'll already have to look up the return type anyway to find out what you can do with it... so what have you really saved yourself, maybe one minor step of not having to look at the return type of the function, and jumping directly the the return types definition? 
Yep, I love C++ but really don't like Python/JavaScript
&gt; No, you know that func() returns something that is implicitly convertible to T. Sometimes this difference is critical. This is a valid point. However, `T` still tells you more than `auto`.
This is how auto should be used. Just for complex types that are obvious from context, iterators, map pairs etc.
&gt; There is no inheritance in ECS. Depends on the definition you use I guess. Unity3D is an ecs but with inheritance and virtual calls. 
Not even in for loops?
You would still need to do that even if you explicitly named the type. Knowing the type doesn't tell you what operations there are on it unless it's a familiar type, at which point the context of the code should tell you what the type is already. The thing is, I agree with the idea that auto shouldn't always be used, but everything you mentioned is also relevant when the type is explicit.
How often do you run into the possibility of implicit type conversion issues like that?
This is why we have the "explicit" keyword. At my workplace we always use explicit when defining such constructors.
What if you have to do something insane like pair of maps of pairs of shared pointers? Auto is much better than typing that every time. I've actually started to use templates just to hide complex types, but I'm not sure how good an idea that is yet (i.e. I construct the return type as a defaulted template parameter that isn't deduced, and then I can just write vector&lt;U&gt; Foo( T first, T second) And use U in the function body to make those types. 
Any plans for remote? Also, you have very alarming reviews on Glassdoor - firing multiple engineers in short periods. You constantly advertise this position - do you have a high turnover?
Well, yes, I am annoyed. There the types additionally depend on the runtime conditions...
autophobia https://www.youtube.com/watch?v=V4DkJtT2jdE
Implicit/silent conversions are not exactly good practice either, so I'm not sure your reasoning that "and is part of the reason we have auto in the first place." is solid.
CAExcludePath should cause warnings to not be emitted for files on the path. The way you've set it is the standard way to set it. There may be something funky with regards to CMake. I'm not sure. But I know the folks looking into CMake support have said that there's a good amount of work to get this integrated with CMake in VS. 
This is a good article that lays out some of the pros and cons. http://www.acodersjourney.com/2016/02/c-11-auto/ 
The issue I'm referring to is that the tool doesn't scale down perfectly. It's a funnel that gets bug reports--duplicated bug reports, non-reproducible bug reports, absolutely crazy bug reports, and actionable bug reports--sorted down to the dev who can fix the bug. There are many potential failure points at each step in the bug reporting process. The people who first see the bug see it at the VS level. The funnel narrows until it gets to the right dev. Every step of this process can result in a bug being misrouted, misunderstood, closed incorrectly as not actionable, you name it. You--and everyone on /r/cpp--are lucky enough to have a direct link to people on the team. You're also presumably smart enough to recognize that, say, undefined behavior doesn't indicate a compiler bug. That's why the people who frequent /r/cpp and other forums invite you to send us bug reports directly (after putting them in the tool, because that has other benefits for us.) It's not within my power to say we need the tool or not. I can tell you that I couldn't cope with every person that thinks they have a bug sending me mail. I can also tell you that the tool is far from perfect. But it's improving--believe it or not--and from my point of view it's better to have it than not have it. *Edit: Hit the wrong button early on. Edit is to finish the comment.*
There's a few different things to cover here. How does an open source project attract new contributors? What advise should be given to individuals wanting to contribute to open source in general? What conditions are created to entice the interested users in the first place? Lastly, what should be done to streamline the first contribution tasks by various projects? If you haven't gone through the literature it's interesting to get in the mind of both maintainers and contributors via some of the studies you can find via google scholar. (I'd start with searches like "open source motivations") My personal stance with regards to potential FLOSS contributors is to recommend that they should look at libraries and applications they already use. If someone is enhancing a project that they already use, then IMO they're more likely to enjoy the process and contribute again in the future. With that said not all projects are equally accommodating of green contributors. New contributors do add a fair amount of work to the projects that they try to help as the ropes generally need to be explained to them and in some cases they are very inexperienced in the language that they want to contribute with. Contributing guides for larger projects help streamline this process, but I'm skeptical that the time investment needed to make them makes sense for medium to small sized projects. 'up-for-grabs' and 'beginner' tags help direct infrequent contributors, though the chance of a green FLOSS contributor understanding the convention is slim (IMO again). Bouncing to the comment on "Tell me, how can I help?" interaction, I'd say it's important to understand that from a project's standpoint it can be interpreted as "Please teach me how to work with the technical and social organization which makes up this project with relatively small contributions back (if any)". So, per the idea of how to attract newcomers to open source, I'd say you create interesting projects which meet some, but not all of the users expectations/requirements, then welcome others, teach them, and give them fun tasks to work on. This does run the risk of the project having an ever expanding scope, more bugs, less maintainer dev time, and lower levels of polish, though managing a project for a collection of hobbyist is a difficult balancing act.
I'm still struggling with the whole auto-thing. At first I didn't like AAA. But hey, the Wise Masters want us to use it so I've done some source in that style. Now I'm still not sure if I like it or not. And then you get all those variations... Should I put 'const'? I put const on everything else that can be const, so it's probably best to also put it on 'auto' variables. But should I also put const on things that can only ever be const (like const references returned from functions)? And things that are returned by reference and are not particularly amenable to copying, require an additional &amp;. But things that come in pointers do _not_ require an additional *. You can write it, though - and so far I feel it is a bit clearer that way. But if I find a small bit of type information clearer, am I implicitly also saying that more type information (i.e. a typename instead of auto) is also better? As I said, I haven't decided yet if I like it or not. Except for very long names, like iterators. Then I totally love it. 
The thing is that there are two (vastly) different things that people call ECS. * Type A: Index in buffer. Used in Unreal, Ogre and many other engines. Non-polymorphic. Data-driven. Used to supply subsystems with a cache-local array of data nodes to work on. * Type B: Interface to component. Used in Unity and several other frameworks. Interface-driven. This is very similar to DynaMix. It relies on inheritance and polymorphic calls. The main differences are how intrusive it is, and its coupling focal points These two things can be used both in a single piece of software, as mentioned in the link above. I personally am a fan of calling ECS the type A thing. This is not DynaMix. It can be used with the library but is an entirely different pattern with different goals 
He'd biased answers there t- oh, this post is 4 months old...
Nevermind the downvotes, it did make some of us smile! 
Thanks for clarifying. The culture/"nature of the language" certainly does play a role in how new contributors can be onboarded and new codebases certainly have a steep learning curve for C++. My own experience has indicated that many (C++) projects would benefit from more/more-consistent contributors. For a few the projects I would imagine the additional load of one-time new contributors may be unwelcome if they don't tend to contribute in the future. Per listing specific projects I could likely get to 50-100 projects (C/C++) that I've interacted without a problem. This would be including many projects which are not 'active' and require new developers to help maintain them. For several of my own projects I've tried to implement policies to attract new devs (as the project can benefit and teaching can be enjoyable) on a variety of simple bugs/features/issues with mixed results.
Dynamically typed languages have a *lot* of problems, auto isn't nearly so bad
I recently found [type_info::name()](http://en.cppreference.com/w/cpp/language/typeid) which can be called like `typeid(foo).name()` However, [some compilers](https://stackoverflow.com/a/4465907) (gcc is what I use) implement decorated names and need to be addressed. There's `c++filt -t` for this. [Here is an example](https://ideone.com/7hzla0) Note: I deliberately chose `long unsigned int` because it's what I was running into. If you were to run `./foo | c++filt -t` then you'd get a human readable name. 
My own FLOSS work focuses more on the application side of things than the library side, so these examples may not fit your interpretation of "for C++ community to use", but here are a few examples that I quickly threw together within a very limited domain: - https://github.com/lmms/lmms - https://github.com/zynaddsubfx/zynaddsubfx - https://github.com/ardour/ardour (it has 1-2 developer paid by project donations, so this may be in violation of your rule 2 depending upon intent) - https://github.com/JuliaLang/julia (partially C++, and they have plans in the future to have paid developers, but I don't think they've reached that stage) - https://github.com/rncbc/qtractor (contribution guidelines should be on their webpage) - https://github.com/grame-cncm/faust (there are several subprojects under this project which should cover all rules)
Quite often when `T` is a numeric type or `std::string`. Probably the most common form of it I've seen is `size_t foo = functionThatReturnsInt();` where later refactoring eliminates the temporary variable, and with it the conversion to `size_t`. `auto` forces you to make the cast explicit.
This is a big deal. Major props to the LLVM team. Being able to use Visual Studio for debugging and still have the same compiler on all three platforms is very exciting. I'm curious to see what kind of linking speed improvements we'll get with LLD on Windows as well.
Have you heard about [ed, man](https://www.gnu.org/fun/jokes/ed-msg.html)?
I'm very excited for this new linker, hope it'll be faster than msvc one. A couple of questions: * Does it work with msvc-generated .obj and .lib files? * Is there a switch like /DEBUG:FASTLINK and /DEBUG:FULL or it can only create full pdb file? * It seems that msvc linker is horribly slow without generating some cache-like pdb named like vc140.pdb during compile time with the help of mspdbsrv.exe. Does lld need it to work in reasonable time or it doesn't use it at all? * MSVC 2017 is practically unusable for large projects with /DEBUG:FASTLINK because it creates pdb index at first break instead of link time (and does it much slower than linker). Is it the same with lld or it always creates index? * Does it work with wonderful option /Zo (enhanced debug info in release build) and does clang-cl have this option? I tried to do some testing on our project but got multiple warnings "warning : symbol scopes are not balanced in ..." and the final error "Type server PDB was not found: Unable to load PDB. Make sure the file exists and is readable.". And linker used like 10GB of ram. Guess it's time to file a bug. P.S It worked for a smaller project! But lld apparently forgot to add a link to the pdb location and debugger couldn't find it without some help. 
&gt; What if you have to do something insane like pair of maps of pairs of shared pointers? using GiveItAName = std::pair&lt;std::map&lt;Foo,std::pair&lt;std::shared_ptr&lt;Bar&gt;,&gt;&gt;,Baz&gt;; That way you only have to type it once. But, really, I think there needs to be a middle ground between Almost Always Auto and Only Auto When Strictly Required. There's tons of cases where `auto` really simplifies life and should be used. It's a useful tool and should be used with discretion. To me, `auto` means "I don't care what the type is." If you care, write it out. If you have to look up what operations can be done on what a function returned, you probably don't want `auto`. If you're using intellisense to see what type was returned, you probably don't want `auto`. But if you're just going to pass the result of one function to another it's just fine. I think most of the AAA proponents underestimate just how much people care about types, creating more exceptions than instances that follow the rule. After that, there's a couple other times where `auto` should be used. Avoiding needless repetition (`std::shared_ptr&lt;Foo&gt; p = std::make_shared&lt;int&gt;();`) and not writing out horribly complex types that are only used once or twice, as you pointed out.
There's a reason people don't write web pages in C++. If you want to be a contrairian enjoy learning the hard way.
Sorry to be pedantic... `gcc` doesn't provide `c++filt`. It's an application that's part of GNU Bin Utils. And, it's weird to say it's a "terminal command". It's an application, no coupling to a terminal/interpreter or anything. 
I agree. `auto` can obfuscate some potentially useful info; and so one should be careful not to overuse it. I use it for iterators, and... well that's pretty much it.
When reading code afterwards, the type can be somewhat relevant. It's name and the expression used to declare it should be the most revelant things. Names should tell what is this thing and how it is obtained. The actual underlying type is irrelevant. The type tells you what? Some name that can be put in the variable name? A way to Ctrl+Click on the type to go see the implementation? That's a tooling problem. You should not change your code to make your tool work. Then the type tells you what you can do with that variable? No! It only tell you the type. To know what you can do with it, you still have to go see the header of that type. The names of your variables and the expression should be clear enough to know what you should do with it. Also, what about templates? The return type of the function can depend on the arguments you send to that function. So... If you have code like this: auto foo = received_foo(bar); Then if `received_foo` is a template, then let auto there, but it's not, use the concrete type? What if you use the concrete type everywhere and then suddenly you want `received_foo` to be a template, you have to refactor 2500 lines? No thanks. I'll choose clear name meaning + auto over concrete type everywhere + meaningless name without questions.
Sean Parent did a good presentation on concurrency [Better Concurrency](https://www.youtube.com/watch?v=zULU6Hhp42w) and one of the things introduced is to avoid explicit threading and focus on tasks and task stealing along with the relative performance of a few methods. 
&gt; Debugging with PDB is extremely responsive given that the debugger does not have to index symbols upon startup LOL at this! The dbghelp api is horrendously slow and without an additional cache layer it's pretty much unusable for any kind of performance.
Any language where the excuse for 'auto' is that "well, the *real* type is too hard to write, and besides, you wouldn't be able to read it anyway"..... is not a well-designed language. 
If all you care about is the concept, then why not use Python? 
I guess they meant shorter startup times. On linux, initial debug info load in gdb (without `--gdb-index` option passed to linker) can be quite large and it's quite annoying.
2 is maintained by myself. The paid version is for the user interface (not in that repository), not the core audio synthesis engine linked.
Actually, the way Intellisense works on recent Visual, and the way it should work on all IDEs is that it should just compile the current source in the background. That operation should give him all the type infos it needs by itself. And compiling a single file (without doing optimisations or any codegen for that matter) shouldn't take much time at all, even on a 500000 lines codebase. Unless you mean 500000 line files which is a bad idea by itself :p Or you include everything all the time which is a bad idea too. The only "problem" is that .h files should all be able to compile cleanly by themselves for this to work but this isn't often tested.
Just like comments can lie to you when they get out of sync with the code they refer to, explicit type declarations can lie to you when they get out of sync with the value used to initialize them. I would rather have to look up that information than trust a type declaration that could be misleading.
You mean for (auto i = etc etc)?
It's good practice for types you own, but as soon as you start using other people's types (including many in the standard library) you need a different strategy.
We just tend to typedef long complicated types.
Often I care about the type of a variable, and I care that it matches the type of the value I use in initialization. In those cases, `auto` means I care about the type.
Yeah. Web developers are idiots that can't handle memory management and ownership.
Hmm couldn't you just comment next to the line what data type it is?
That is exactly right... *if* you are taking all the locks you will need at once. That strategy does not work when you nest lock acquisitions, and then you do need a lock ordering discipline such as a lock hierarchy.
This opinion is so ineducated that it is surprising you know how to post on reddit. Edit: after checking your comment history I got it, you are a nasty troll.
That's backwards, in my view. `auto foo = bar();` means "I don't care what type `foo` is, just make it wherever `bar` returns." Turn the initializer into a literal with `auto foo = 5;` and that basically means "I don't care what `foo` is, as long as it's an `int`," which is stupid way to write code.
That's an OS.
&gt; I got some odd stares (to put it lightly) when I suggested that we just ask Microsoft if they would help us out. But ultimately we did, and… they agreed! This doesn't really surprise me. And anybody that gave you an odd stare didn't follow MS at all over the past few years and still has this old, now mostly obsolete image of MS in their head. They've changed a lot, they have employees browsing this subreddit, helping people, taking C++ bug reports, they're actually listening to developer's feedback, they're very active on the ISO C++ committee, and they've made quantum leaps with VS2013, 2015 and 2017 in terms of C++. I could list many more things. I hope these people learn their lesson from it: Just ask, before enclosing yourself in a wall of prejudice. Just ask, the worst that can happen is someone says "no". If you don't ask, you'll never know. (And no, I am not associated with MS in any way.) Nice work done to the clang PDB team. I for sure would not ever give up the VS debugger, so this is great news. :-)
Yes but then you are polluting some namespace with typedefs. That isn't ideal either. What I want, in such a case, isn't a typedef that lives somewhere, I want to say "in the context of this function, Foo is this horribly complicated type", but *before* the function is defined. Like the auto foo() -&gt; dependent_type {} syntax, but assigned to a name, like auto foo() -&gt; complicated_type = dependent_type { complicated_type x = ... }
Use const with auto if you want to ensure that it is const. If the thing is “naturally const”, no problem. If the code should get refactored in the future so that it is no longer “naturally const”, then your code still works the way you intended.
As for tabs, I've found that splitting the Projects pane with an Open Documents pane is a reasonable substitute.
It depends on application. In some it is very hard to deal with OOMs in meaningful ways, in others -- trivial. An example of latter is a server that accepts connections, starts a thread for each one, that thread reads and interpret commands -- on any exception it unwinds everything, closes connection (probably with a message, if resources allow) and exit the thread. Such server works perfectly fine in constrained environment -- OOM simply kicks unlucky user out without affecting the rest (or having to restart server and having everyone to reconnect).
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/6ukzvf/what_are_some_modern_ways_of_creating_c_web_pages/dltnmu8/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
This needs to be up-voted by more people so it can be seen by more people.
90% of the time I don't give a shit what the type is. auto is a win for me.
Comment in the front of the line, and remove auto. Also forget the //.
I would argue if you don't know what the return type is, you probably shouldn't be making assumptions about it. So not knowing is your answer.
:-/
No I don't want help, in fact I don't plan to write a c++ web application (I am not crazy!), I just want to know what others know about this, it's just an idea that came through my mind, I want to know if there are some third party libraries for this, or some is planning on something, you never know what you can find, I often get asked at school if there's some technology for this, and I just don't wanna say a plain "I don't know"
There is less new with `auto` than some ITT seem to think. Generally, `auto` is template code. If you have no issue with writing a function template, I see little reason why you'd have an issue with using `auto`. I haven't seen anyone saying that template&lt;typename I&gt; I next(I iter) { // ... } is obscure, or that oh-no I don't know what `I` is. I haven't seen anyone asking that instead it should be int* next(int* iter) { // ... } “so that now we know what the types are”. It makes no sense to say that. These two pieces of code say entirely different things. Yet, there is virtually no difference between that template and `auto`. The `I` is effectively a “named `auto`”. `I` is a deduces, inferred, type. We use `I` and not a concrete named type because we want exactly the type of the argument passed, and we don't want any conversion to anything else. `I` means the type of the argument. If it were an `I const` parameter then `I` would mean the type of the argument, except with `const` stripped, and similarly with `&amp;`, `volatile`, and `*`. It's called collapsing, and Scott Meyers has good explanation of how it works. It's the same with `auto`. When you see an `auto`, think of it as a `T` parameter of a function template. We have no moral issues using one, and we shouldn't have moral issues with the other. We should see they are one and the same. * I realize there may be differences between template parameters and `auto`, IIRC. But in many senses they are analogous. IIRC then in polymorphic lambdas in particular they are exactly the same.
Because I might care about satisfaction of the concept being checked at compile-time. Oh, and performance.
Another counterpoint: if you don't know what the function does or returns, then you should probably look at it anyhow. Jump to function, jump right back, 2 keystrokes in almost any environment. 
Yeah I think the trick with auto is to only use it when the type can be obviously inferred from the immediate surrounding code, otherwise I feel it hinders more than it helps. I recently inherited a large CPP codebase that used auto like crazy and it was a PITA to decipher, even with VS/Intellisense/VassistX. Like most features in CPP it can be abused, but I'm glad it's there.
It's called a fundraiser. By the end of the year the source for the **optional add-on** will be released. Anyhow, you seem to be interested in maintaining your position by continually adding restrictions, so I won't bother you further.
I gotta agree with you. The worst that I'm seeing is using auto&amp;&amp; in every range loop. People need to stop doing that even for primitive types. If you're iterating over a vector of ints, just specify int as the type like this: for(int id : idVector) { if (isVisible(id)) doStuff(id); } 
I think it comes down to whatever has the least surprise. If using auto would be confusing don't use it, if it doesn't matter do. Like in a template function I would say it almost always makes sense to use auto unless I was trying to force the type. But at that point using an implicit cast would be more surprising and a static_cast is probably better as it is explicit what I meant to do and not that I made a mistake. The thing about reference though is that it is needed with or without auto. As for const, I would put it as that is more explicit and tells someone else that within this scope that value is const. I am a fan of auto but mainly because I am thinking of the interface and operations and not the what. Assuming someone hasn't gone and changed the semantics of a function (e.g. save_all, does a delete_all) it is usually ok.
&gt; I use it exclusively for plain C++ projects using qmake Me too. qmake for me is a cross-platform build system that has a sane and easy to follow syntax, a great gui, and just seems to work.
I often use tabs to attach files to windows and to group them. This doesn't really work with the Open Documents pane.
I mean it's no secret that Microsoft is very involved in the C++ community. Hell, ask /u/STL here! I'm also not affiliated to MS in any way, fwiw
So same feature set as the last beta? I was hoping they'd fix the horrible project view for cmake
If you're using an IDE anyway, just use refactor-rename. And if not, typedefs cover some cases. I'm personally not 100% anti-auto, I just limit it to loop specs and lambda types.
We're actively working with libc++'s maintainers to improve their test suite (I've submitted over a hundred patches, for both conformance issues and VC-specific issues like warnings), and I just sent out for review my first patch to Clang's compiler driver (admittedly to deal with DevDiv's internal directory structure for the VS toolset, which is a self-inflicted problem).
Why do you care about GCC 5? It's on 7 now, you know?
Heh, thank goodness I've been so lazy about cleaning up an old project I have laying around. It sounds like it'll be a lot more convenient now. ... Hm, at this rate, it'll be even easier if I let it fester for another year!
let me show you http://www.cplusplus.com/reference/typeinfo/type_info/name/
&gt; ReadFifyThousandRecords();
I ran into an extreme case of that in Ruby, where the thing being returned was actually an object that was stored in a string and modified before being returned. Moreover it was an ActiveRecord object, which is the worst sort of object, and it was being modified in the string because there was an unlikely possibility that someone might one day change the database instance name and having self-modifying undebuggable code was clearly the way to handle that.
I agree. I think auto is going to end up like goto in a few years. auto overuse is death to readability, and in serious software projects readability is usually the most important feature of code. 1. Item 2. Item
Currently, it is difficult, especially in latency-sensitive applications. You *can* use [`wait_for`](http://en.cppreference.com/w/cpp/thread/future/wait_for) with a small value, but that is subject to the clock's jitter (either via hardware or OS interrupts). The real solution is to wait for executors to come in C++20 (maybe?).
Great points all around. Some are very basic, but it's good to have them all in one place for folks just coming into parallel programming (particularly to the standard library's version). I do have a couple of comments: &gt;Mistake #11 Why no love for [boost::thread_group](http://www.boost.org/doc/libs/1_64_0/doc/html/thread/thread_management.html#thread.thread_management.threadgroup)? Assuredly, TBB and PPL are much more sophisticated and offer a tasking model, but they are separate installs or not available on all platforms (PPL on linux, for example). &gt; Mistake #13.1 Don't forget to capture the `std::future` from `std::async` else the `future`'s destructor will eliminate all asynchronicity. This was a surprising "gotcha" for me when I was first learning about it.
Could you elaborate on this more? I feel most folks here would consider C++11 to be the "modern C++" to which you refer, yet a great many features involving locks were added to the standard library in C++11.
Unless it was a type you were already familiar with.
It is odd how they shared partial dump of code on github. I would have expected more complete code and NDA. You know like in case of samba.
Yes, that.
Yep -- "not optimal" != "doesn't work" :).
Particularly because we could document in the code what type we have with the type system You *could* solve this problem by using functions that make it significantly more explicit what their type is, but it seems like at that point that people are coming up with backwards reasoning to justify using auto somewhere instead of just using the type. Why should I have to guess based on the function name (which may be inconsistent) when the type can't lie as easily?
I worked on a codebase recently where 100% of the types were auto, and that was the recommended style, written by one guy When I pointed out that it was making it extremely difficult to understand what any of the code does, the official reason was that "its easier to refactor" Ok... but A. you absolutely should not be relying on auto to get you around functions having api breaking return type signature changes, and B. it makes it so much more unnecessarily difficult to figure out what's going on because now you have to look up absolutely every single type auto foo = some_bar(); might be obvious to you, but it is not obvious to the developers coming into your project I do sort of feel like people advocating auto 99% everywhere just haven't really worked on a large codebase with multiple other people. Understanding well written code is hard at the best of times, understanding code written while slightly drunk (both parties) with 0 types in and function names rushed due to production schedule is.. challenging at best
&gt; roughly 5,000 active C++ repositories This seems.. too small?
filesystem path `c_str()` returns a different type depending on platform, auto is a life saver in terms of having portable code
Clearly the right answer is: auto foo = func(); static_assert(std::is_same&lt;decltype(foo), T&gt;::value, ""); Edit: maybe a decay would make things even better...
CatFactoryFactory
If it interests you, fold expressions let you be a bit less obtuse: std::string out{head}; // Should probably be an ostringstream with &lt;&lt; instead of +=, although the static assertion is a bit limiting in that case. (out += ... += (what + tail)); return out ; Going a step further, the static assertion condition could be something like `(std::is_convertible_v&lt;strings, std::string&gt; &amp;&amp; ...)` or `std::conjunction_v&lt;std::is_convertible&lt;strings, std::string&gt;...&gt;`. I'm failing to find a case where the convertibility check fails and your other checks succeed. For starters, `is_base_of` is already true if the types are the same, so the `is_same` check is redundant.
Complaints with Hungarian notation date from a time without auto though
I use auto for iterators and that's about it. Maybe for chained types. Overall I see no point in hiding variable types and I think it increases the odds of a bug as you lose one of the fundamental checks - what the human expects vs. what the compiler thinks. For example, int x = "Hi"; won't compile, but auto x = "Hi"; will.
There is a few c++ libraries for it in most cases the performance wont help as web latency still leaves you waiting on things but if your trying to reduce overhead insanely you can its how allot of modems and routers have the web interface served just google c++ cms or c++ web frameworks
There is another PDB API that rarely gets mentioned for some reason, which is the [DIA SDK](https://docs.microsoft.com/en-us/visualstudio/debugger/debug-interface-access/debug-interface-access-sdk). It's been bundled with Visual Studio for as long as I can remember, and it's vastly superior to dbghelp in terms of performance when it comes to resolving call stacks and whatnot.
interesting, thanks! did not think about that is_same is redundant, but you are right that there is no implicit conversion to string is a feature in the context of my actual use case, I do not want to decide how to handle float/double exactly, but of course, there are several variations of the function possible. This `(out += ... += (what + tail));` looks very interesting, but fail to compile with gcc 5.3, at least how I use it. would you be interested for fork the sample code http://rextester.com/RTKTU48562 and show me how this is supposed to work? 
!remove
OP, A human moderator (u/blelbach) has marked your post for deletion because it is not appropriate for r/cpp. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/6ugy53/attracting_new_people_to_open_source/dlu47lk/,%20was%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Yes (at least in userspace!): * https://askldjd.com/2011/03/06/performance-comparison-on-reader-writer-locks/ * https://www.arangodb.com/2015/02/comparing-atomic-mutex-rwlocks/ * https://woboq.com/blog/qreadwritelock-gets-faster-in-qt57.html unless you *only* have readers (but then why bother locking at all). The problem is that "to allow them to read concurrently" is a complex algorithm in itself. There was also an interesting paper last year where it was shown that in some cases, having a *single* mutex for an entire program would sometimes be faster than having many mutexes being locked concurrently, one for each "different" data one would like protect.
&gt; And that lock is held the whole time. Don't know about you but my general pattern is : void some_func(...) { .. do stuff .. { auto [data, _] = m.get_data(); .. } .. do stuff .. { auto [data, _] = n.get_data(); .. } } this is what RAII is for. With the snippet I propose, this would be replaced by : void some_func(...) { .. do stuff .. { auto [data, _] = m.get_data(); } .. do stuff .. { auto [data, _] = m.get_data(); } }
[Here's one](https://wandbox.org/permlink/6rZkSP24M8WDgzq6). Fold expressions are C++17, and GCC only started supporting them in GCC 6. I know it's not 5.3, but at least they're a part of the language to consider.
&gt; A. you absolutely should not be relying on auto to get you around functions having api breaking return type signature changes why though ? I did very easy refactors in multiple-hundred-kLOC codebases thanks to this.
&gt; If you're iterating over a vector of ints, just specify int as the type like this: and then someone changes idVector from std::vector&lt;int&gt; to std::vector&lt;std::size_t&gt; and you get conversions every time
Since implicitly casting an unsigned type to signed should trigger a warning and you should treat warnings as errors you would find it and then be forced to make a decision about isVisible and doStuff as well (since they probably also takes an int as first argument).
wow, excellent, thanks a lot!
Public APIs need to be kept stable
Hm gotta try that then... Not sure why dbghelp doesn't use that if it's so superior though?
&gt; Flip sides: Read-only sharing by N threads works great, is safe, and easy to do. Beware of lifetimes though; ideally you'll use `std::shared_ptr` or similar so that each thread is an owner.
&gt; It's not within my power to say we need the tool or not. I don't want to unload on you exactly because of this, but my last experience with the current reporting tool made me swear of reporting bugs unless they are REALLY, REALLY critical to me. Compare this to WSL, who use GitHub issues, their bugs are searchable, formatting does not get murdered and issues can be crosslinked. Admittedly, I expect WSL to have fewer bugs reported, but I would expect that some smart labelling and assigning could get the same quality of filtration going on GitHub as happens on the internal tool. e: *Also I am not the only person I know that pretty much swore off bug reporting through the tool, because it is too much of a PITA.*
`std::range_error` is the wrong exception type for this kind of violation because it is derived from `std::runtime_error`. The correct exception type is `std::logic_error` or one of its derivatives (`std::domain_error` springs to mind). I also don't like how the default constructor sets the value to Min; this causes unexpected behavior when calling a function with aggregate initialization: `f({})` Here, I would expect the argument's value to be 0 (for builtin types) which isn't guaranteed when using your `constrained` type. In the `acceptable_limits` example you've provided in `main.cpp` the value would be -3. Lastly, you should to use `constexpr` and `noexcept`.
Good feedback, thanks. The current implementation is a 10-minute proof of concept... still a lot to improve :)
&gt; The tools I use for initial planning aren't really so different from what the Ancient Greeks used to solve tricky problems. I usually open a text editor and Oh yeah, the real LPT is always in the comments! So what text editor did the ancient Greeks use?
What does it return: Cat, Cat&amp;, Cat\*, const Cat&amp;, or const Cat*? or would you prefer getMeAConstantReferenceToCat()?
&gt; there is no language or library construct to reflect constraints This is what Contracts aims to fix, and it's possible that the first part could be done for ~~C++ 2020~~ C++2a.
The removal of mandatory type information encourages better communication? 
In the cases of `Cat` and `cv Cat&amp;`, it doesn't matter as `auto` has copy semantics. Now, if it's a pointer, your code won't compile if you use normal member access instead of pointer member access.
Great, need to try this out in our projects!
It's still extremely poor from a code readability standpoint. Indeed auto has copy semantics so it will resolve references to `Cat`, which is fine if that's what you want. Otherwise you're performing an expensive copy every time you just need a reference. &gt; Now, if it's a pointer, your code won't compile if you use normal member access instead of pointer member access Sorry, That's not feasible at all. I'm not going to rebuild our 200kloc+ codebase just to figure out whether a type is a pointer or not.
I don't think it's as lenient as what you're looking for, but I think that you should use types for this.
This is somewhat similar: https://github.com/foonathan/type_safe
Most APIs are not public.
Oh no... the Hungarian notation is back...
&gt; you're performing an expensive copy every time you just need a reference. In that case, I use `auto&amp;`. I agree that `auto` is not helpful when there's no helpful information from the other side. Functions like `make_{shared,unique}&lt;T&gt;`, `unique_ptr&lt;int&gt;::get` etc, are an example of how `auto` helps with redundancy reduction. Though it wouldn't make sense, for example, to use `auto` in places where it changes the type to something you don't want. Given `using Status = variant&lt;Ok, NotFound, Expired&gt;`, both following codes don't resolve to the same thing: auto result = Ok(...); join_status(result, NotFound(...)); Status result = Ok(...); join_status(result, NotFound(...)); The former won't compile given `join_status(Status&amp;, T)`. Though, you could just as well write it like `auto result = Status(Ok(...))`, respecting the *name -&gt; result* syntax (e.g. `using alias = T;`, `auto foo() -&gt; string`, `auto s = Status(...)`). Now, I'd say it's a rare case that your function's name won't help with semantic meaning at all. Usually you look up the documentation/prototype to know if a function returns a pointer, or a reference to something. When writing down the type becomes redundant, `auto` makes it better to read code. When you can't reason about some code without the type, making it explicit is the right thing to do. Simply ruling out every `auto` in your code isn't sensible.
&gt; http://www.cplusplus.com/reference/typeinfo/type_info/name/ You're suggesting that while reading code I, if I need to know the type of an `auto` declared variable I should: 1. add some code to print the type using the handy `type_info::name` function (seconds) 2. compile (potentially several minutes) 3. run the code and get it to the points of where my newly added output line is (potentially several more minutes) 3. sift through the output to find what I added (even more time wasted) Surely you can see the downside to this approach. 
See [contract programming in D](https://dlang.org/spec/contracts.html). AFAIK, there is something like this planned for the future standards of C++.
Bounded_type initially looks like what I have in mind, but then bounds have to be specified during construction, they are not part of the type itself... can't therefore be used in, for instance, in paremeter declarations.
Yes, a specific type in each case would solve it all, but type proliferation and repetition would end up being problematic, just the way it was when you had to write functors for everything, before lambdas.
I'm not going to argue with you. I personally would love to have something like Bugzilla for MSVC bugs. I'm just saying that feedback about our feedback tools might be more effective if addressed towards the VS org itself. (I will note that WSL is by orders of magnitudes a smaller team than Visual Studio. And I'll also note that when I entered a WSL bug as an issue, it ended up as a direct email conversation between me and the WSL dev--exactly the kinds of conversations I like to promote with developers and devs on my team.) 
Interesting read, thanks.
Doesn't look like it: template &lt;typename T, bool LowerInclusive, bool UpperInclusive, typename LowerBound = constraints::dynamic_bound, typename UpperBound = constraints::dynamic_bound, typename Verifier = assertion_verifier&gt; using bounded_type = constrained_type&lt;T, constraints::bounded&lt;T, LowerInclusive, UpperInclusive, LowerBound, UpperBound&gt;, Verifier&gt;; Looks to me like you very well can specify the bound as part of the type and that a runtime bound is just the default.
 Maybe you can do both: template &lt;typename U1, typename U2&gt; explicit constexpr bounded(U1&amp;&amp; lower, U2&amp;&amp; upper, decltype(lower_type(std::forward&lt;U1&gt;(lower)), 0) = 0, decltype(upper_type(std::forward&lt;U2&gt;(upper)), 0) = 0) : lower_type(std::forward&lt;U1&gt;(lower)), upper_type(std::forward&lt;U2&gt;(upper)) I certainly need to look further into this. Thanks for the tip.
Notepad++ probably, it's referenced in Plato's dialogues.
A hearty congratulations to /u/zturner_ and the LLVM on Windows team!
An NDA would only be needed in the case where Microsoft was sharing private, proprietary information with another person or company. The PDB format is proprietary--so Microsoft didn't have to share anything--but there's no reason to share anything privately with the LLVM folks. If it's being shared, it can be shared openly. 
And then someone else joins your project who isn't intimately familiar with the code and has a much harder time understanding what's going on
I am still waiting for faster debugging in Qt Creator. We are developing a big project in our company, using Qt libraries. We use Qt Creator for development, but sadly, the debugging is extremly slow. Application startup time in debug mode are long, setting/unsetting a break point is sometimes fast, but sometimes extremly slow, taking minutes! Reading values of local variables can take minutes, sometimes they just disappear. Stepping over can again take minutes. Setting a breakpoint in templated code is buggy, it causes random hangout of the application, as if it the breakpoint was set on the wrong address. It is also impossible to set the break point for only one template specialization. When we want to debug a non trivial issues, we are forced to use Visual Studio, attach it to the process and debug it there. But again, this causes wasted time, as you have to manually open the file in Visual Studio, set a breakpoint there, code navigation is bad in VS, ... I hope there will be a good debugging support one day... 
Those `decltype` lines are just SFINAE for making sure the types you give the constructor can be used with the concrete bound types.
&gt; When you can't reason about some code without the type, making it explicit is the right thing to do. Simply ruling out every auto in your code isn't sensible. I'd agree with that. My comment was mainly aimed towards those who adopt the 'always auto' style. It's fine when common standards and practices will tell you the return type with absolute surety; like `make_unique`, `make_shared`, or that `begin()` and `end()` pairs should always return an iterator for example. But it's always a convenience / readability tradeoff. Sure, I could use `auto&amp;` or `auto*` instead. Now if someone changed the modifiers on the function I'd have to go back and fix the code, so that gets rid of the 'not having to refactor' advantage. And I *still* don't know the type. In the long run it ends up being more of a hassle to use than anything.
Yes, but the lower and upper parameters are the actual bounds, right?
I think that you're mistaken. There are a ton of features in the language to support using types like this. For example, you could define a one-off type with an implicit conversion from double that throws an exception if the double is negative. But "type proliferation" has always seemed like a good thing to me, not a bad one. Liberal use of templates and auto take most of the boilerplate and repetition away, and you're using the type system for what it's intended for: to impose constraints on your data.
Ok sure, but then why not share full thing, but stripped out bits.
&gt; Liberal use of templates and auto take most of the boilerplate and repetition away Exactly. I want to do away with even more repetition. Instead of writing more classes dealing with these kind of situations. I wish I could just say: using orientation = constrained&lt;double, 0.0, 2*M_PI&gt;; instead of: class orientation { //... }; 
I rarely need to know the exact type that auto is. It is just noise most of the time so I use auto most of the time. 
Could be a ton of legal baggage around specific components. Maybe some patented technology or something brought from a third-party.
template &lt;int min, int max&gt; class Constrained_Double { double val; public: Constrained_Double(double d) : val(d) { if (d &lt; min || d &gt; max) { throw // pick an exception type } } Constrained_Double() = delete; operator T&amp;() { return val; } operator T() { return val; } } EDIT: forgot to mention the obvious drawback that here, your boundaries have to be integral. You could templatize a factory on the type you want to constrain, and specify the constraints on a factory instance.
&gt; Here, I would expect the argument's value to be 0 (for builtin types) which isn't guaranteed when using your constrained type But... then the one and only invariant of the class (not holding a value outside the defined range) would be broken. I understand a non-zero default value is somewhat counterintuitive, but to me it would be even more confusing to have a default value outside the defined range. 
&gt; Lastly, you should to use constexpr and noexcept. Where would you use constexpr further? 
You make it sound like, before auto, we always had the type defined at the site of an assignment. But we've never seen a backlash for assigning things to member variables. Or reassigning to variables after their declaration. Do you only use const variables? Because that seems to be the only way I can think of for you to guarantee type info at assignment. So if you are against auto, you must be against member variables and non-const variables? I bet you aren't ;) There are plenty of things I dislike about c++, but I'm pretty happy about auto.
I would imagine they're only used for the `constraints::dynamic_bound` case and that the static ::value is used otherwise.
In my experience, changing the return type was a blessing, because the semantics were almost the same, I didn't need to change the rest of the code that was using that.
[N4415](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4415.pdf), *Simple Contracts for C++*.
I tend to shy away from using the `auto` keyword, mainly since it hides the types of a variable from a programmer. I work in plain text editors like (neo)vim with very few plugins. Nothing that tells me what the type of a variable by just hovering over it (like with intelli-sense). I think it can also creates issues like so: auto x = 1; // This is an integer auto x = 1.0; // This is a double where as you could do this and a compiler would accept it float x = 1.0; // double will cast down to a float float x = 1; // int will cast down to a float The only exception that I make for myself are: 1. Does it save me on a ton of typing? 2. Is it used in conjunction with a very well known programming pattern? 95% of those two cases for me are covered for iterators. The hell I want to type out `std::vector&lt;std::string&gt;::const_iterator iter;`. When it's very well known that the `begin()` and `end()` methods of a container will return iterator objects.
Note the OP, but couldn't you use [`if constexpr`](http://en.cppreference.com/w/cpp/language/if) and [`static_assert`](http://en.cppreference.com/w/cpp/language/static_assert) for compile-time checking (or is it already doing that, can't tell :/)?
&gt; auto means "I don't care what the type is." The clincher is, who is "I"? If one works on a team, the team shouldn't care. How does one know should the team, at large, care? And even if it one works alone, 6 months after the fact, one might (or not) care.
That's pretty much the implementation I proposed at the end of my post (see my GitHub link), but I included a generalisation of the limits allowing to workaround the integral limitations on the parameters.
Excellent point. Maybe the phrase should be "nobody cares what the type is but the compiler." The threshold for a human needing to know is very low, and should be considerate of reviewers and maintainers in the future.
/u/DavidDavidsonsGhost is very close to correct. Not so much something bought from third parties as much as code that's made its way into multiple products and legal agreements and and and...
As usual, the context is king. First off, in a good codebase, the type of the variable will be reasonably easy to know from a casual read. It doesn't always need to be exact. Second, with polymorphism (both runtime and compile-time!), type isn't really knon even when one types it out. Third, there's a question of implicit conversions (it's not true that in T val = foo(params), return type of foo is T. Fourth, if this is about navigating a large scale codebase, then... knowing the type name there doesn't necessarily say much, not without further navigation. tl;dr the post is overly critical, but doesn't go further than a possibly temporary personal preference. It fails to look at a wider picture. 
On the flip side, installing Visual C++ for Win32/64 Native Development now pulls in all of the UWP SDKs, *because CMake.* Was just using this to learn stuff, but I've uninstalled it because my SSD is small. I can't be bothered to install another GB of SDKs, just because I've updated an IDE.
dbghelp is a very low-level "core" API in the Windows SDK while DIA is a high-level COM interface to a developer-oriented toolset. 
Simply don't have default.
but then auto doesn't really take anything away unless the function/method is badly named, which isn't a problem with auto.
Yeah and Microsoft has and controls the source for both completely. I'm just trying to figure out why they would leave an inferior implementation in their "core" (totally isn't core) used by windbg... I still have to test though, if the DIA is really much faster I'll just use that instead.
What are "type trains"? ;) Of course type traits with a typo.
&gt; many (perhaps even most) Windows developers will only give up the Visual Studio debugger when it is pried from their cold dead hands. If someone offers something better/faster, I'd probably switch.
But the real return can be converted to type one wrote. You only know the return value can be converted to the explicit type. 
Yes, you can also specify an integral constant like type for the bounds.
But it's still significantly more informative than auto, now you know what type you're dealing with rather than having to look it up
No, we're not. You're not “*just a bit pedantic*” when you dodge UB. I find it easier to deal with this abstractness when I think my code will reach a controller on a Malaysia Airlines flight or something. They're still searching you know, and the 239 families are all still in pain and agony.
alternative is to attach gdb, print at the line, but I see the difficulty with it being a runtime tool.
No, you want each system to be as reliable as econimal. Spending unbounded effort making system X go from 99.999% to 99.9999% only makes sense if system Y, upon which system X depends, is anywhere near 99.999%. If Y is 99.99% reliable, that change in X will disappear in the noise of Y. Reliable systems do not rely on complex subcomponents being as reliable the system as a whole. Anything complex is treated as failure prone, and is engineered around. A process shutting down is a clean event, much more sensible that the things that *will* go wrong in any program with 100s of threads throwing exceptions around. It is something that will happen; someone working on making a reliable system must already be dealing with it. 
Uh... Thanks for clarifying for me what I want, boss! I was clearly under strange delusion. I am sure they use similar principles when writing Linux kernel... Oh, wait -- it is Windows! :)
Assuming a perfectly readable codeline I suppose thats true. 
&gt; Constrained_Double() = delete; You don't need that.
Oh goodness, no. Please tell me you're joking. People who do that should never touch a computer again. 
Sorry, but no. That's completely upside down. No way is specifying the actual type less readable.
All of your proposed solutions as well as the ones in the comments are beyond bloated. Just pass in the primitive type directly and put an assert in the function body. This of course assumes that the data doesn't come from IO, in which case you can just do the checks prior to calling the function.
fixed, thanks!
This is specifically addressed in [footnote 2](http://videocortex.io/2017/salami-method/#fn:2).
There are actually several reasons why one might do this instead of catching them earlier. 1. If you want to log any errors, the logging interface may be more accessible at the platform specific layer; 1. Similarly, as described in the article you might want to e.g. convert a C++ exception into a JVM exception, and this is a natural place to do this. 3. You can have them there as the last protective measure against exception leaks (that might have crept in during later development or 3rd party dependencies); 4. The standalone functions C-API is important for several reasons, not just the C aspect of it (e.g. lifetime managements etc.). 5. The implementation of the API functions (though not [ABI] the signatures) may as well be C++. No reason not to. These are are non-mutually exclusive - and of course may be more or less relevant depending on the actual platforms you are targeting.
The point is that the lowest common denominator between *many* platforms is strictly C types and nothing more (some primitive types and *maybe* PODs and arrays). If you can get away with passing richer types, then by all means do (e.g. between ABI compatible toolchains as mentioned in the rest of this thread). But you should keep in mind that extending to other platforms and language bindings might not be possible with these richer types. Similarly, even Emscripten which supposedly "knows" about e.g. `std::string` actually causes multiple data copies to and from this type. Passing raw C-style memory is significantly more efficient.
I'm planning to make the constructor(s) constexpr. Also, I didn't know about `if constexpr`... will investigate and consider it.
Good point.
Well, the whole point of this thing is to specify attribute, variable parameter and return value constraints in declarations, not within the definitions. Please refer to the core guidelines section I mentioned.
&gt; No way is specifying the actual type less readable. It depends on your definition of "readable". But I guess many people will think this statement is too extreme. 
In my opinion the first one is more readable, its just getting used to the different literal specifiers. There is no less information, and it is presented in a more readable fashion (imo)
Do you have a IDEphobia video?
In real life you encounter code bases where a lock is taken, some code is executed, an other lock is taken, etc... Of course those code bases are full of potential deadlocks, but funnily enough some of those programs actually run quite well and don't encounter actual deadlock too often. Anyway in some cases the way to fix that mess gradually is not to merely teach about how std::lock fixes that for you, because the locks we are talking about might not even be compatible with that (yeah, you understand we are talking about a legacy code base after all) but very well to go back to the basis with the programmers and teach them about deadlocks and locking orders. In other cases, for example in operating systems, you typically want to stick to a fixed order.
It can be challenging esp if a code is already a mess written during several years by people not even knowing about this subject. Otherwise, it is typically easy: just document it everywhere, pay especially attention to callbacks, and you are done.
Rw locks are not often scalable. If the time while locked is big and they can sleep, they might be ok, otherwise you need to be wary of them.
GCC 7 ships with a `std::variant`. GCC 5 doesn't. I'd argue that OP's implementation is most useful to those who want to try `std::variant` but have to use GCC 5.
&gt; `std::optional` can be viewed as a container having zero or one element. That's like saying a pointer could be considered a container, referencing memory or nullptr. I can't imagine where treating either like a container would be wise or produce readable code.
You have a range of `optional&lt;T&gt;`s. You flat-map it and now you have a range of the contents of all of the engaged optionals. For example, you have a bunch of things you want to try to parse, and you need to continue with the results of all the ones that are parsed successfully. Edit: This is basically what Kotlin's [`filterNotNull`](https://kotlinlang.org/api/latest/jvm/stdlib/kotlin.collections/filter-not-null.html) is. Rather than container semantics, it treats its form of optionals (i.e., nullable types) specially in the library.
Out of curiosity: Why would you want to iterate over an optional&lt;T&gt;?
If you need iterate over optional, it's probably better to use std::vector, which also provides ownship semantics.
I think this could be quite useful, especially when dealing with optionals and containers in templated code, because we could access both in an uniform way, without to implement special code to handle the optional.
Nope. You got an idea for one?
Not really but it should be something with Vim/Emacs ;)
&gt; Does it work with msvc-generated .obj and .lib files? Yes. If it didn't, there'd be no way to link against MSVCRT which is obviously a non-starter. Our object files and library files are intended to be binary compatible. For example, you can take a clang-generated .obj or .lib and MSVC's linker will accept it as well, just as we accept theirs. &gt; Is there a switch like /DEBUG:FASTLINK and /DEBUG:FULL or it can only create full pdb file? Currently we only support /DEBUG:FULL. It's possible we could support /DEBUG:FASTLINK in the future, but my hope is that our /DEBUG:FULL will already be fast enough that you won 't notice :) &gt; It seems that msvc linker is horribly slow without generating some cache-like pdb named like vc140.pdb during compile time with the help of mspdbsrv.exe. Does lld need it to work in reasonable time or it doesn't use it at all? We don't use it at all. We're already seeing improved link times over MSVC without it, so we have no plans to implement this, but if we do start running into performance issues, we'll have to explore various other options to speed up time. Note that while compile time pdb generation has some advantages, it also has some inherent downsides. For example, it doesn't play nicely with distributed build systems. So there are pros and cons to each method. &gt; MSVC 2017 is practically unusable for large projects with /DEBUG:FASTLINK because it creates pdb index at first break instead of link time (and does it much slower than linker). Is it the same with lld or it always creates index? Can you elaborate? For example, chrome and chromium developers use /DEBUG:FASTLINK as part of normal dev, and they report improved link times over /DEBUG:FULL. What do you mean by "at first break"? &gt; Does it work with wonderful option /Zo (enhanced debug info in release build) and does clang-cl have this option? I imagine if you take /Zo compiled object files with MSVC and try to link them with LLD it will work, but to be honest this is not a scenario we've tested. If you file a bug about it it will help me not forget :) clang-cl does not have this option, at least right now (again, a bug could track this, although no promises when it would get prioritized).
Can you elaborate? What specifically is slow? I can think of some things like running the x command in WinDbg and then returning after lunch to find it still working with no way to cancel, but that's a WinDbg UI issue. Is there a specific API call that's unusable?
That's pretty much what they did, right? The full thing, with stripped out bits. Unfortunately those stripped out bits means it won't compile. 
&gt; I tried to do some testing on our project but got multiple warnings "warning : symbol scopes are not balanced in ..." and the final error "Type server PDB was not found: Unable to load PDB. Make sure the file exists and is readable.". And linker used like 10GB of ram. Guess it's time to file a bug. &gt; P.S It worked for a smaller project! But lld apparently forgot to add a link to the pdb location and debugger couldn't find it without some help. My guess is maybe you used /Zi and then linked with LLD? This is supposed to work, but we haven't really tested it in detail, so it's very possible there's a bug here. But yea, file a bug and I'll take a look.
 #include &lt;optional&gt; #include &lt;vector&gt; int get_sum(const auto&amp; container) { int res = 0; for(int val : container) res += val; return res; } int main() { get_sum(std::vector{1,2,3,4}); get_sum(std::optional&lt;int&gt;{}}; get_sum(std::optional{123}); }
Remember that you are free to make global begin() and end() templates that match any std::optional. Generic code should pick up those.
IIRC, DIA is built on top of dbghelp.
It's very common, specially in languages where the concept of optional is implemented.
You can use range-for loop instead of if statements to inspect an `optional&lt;&gt;`. For example: for (auto&amp; val : opt) { // use val } instead of if (opt) { auto&amp; val = *opt; // use val } 
Rust has their Optional type implement Iterator so that they can use the iterator chains (ranges in C++). If the optional has a value, then the processing is applied. If not, then it just returns an empty optional, all using the same iterator methods.
I looked at the proposal for std::optional, n3672, and found this relevant extract: &gt;Optional objects serve a number of purposes and a couple of conceptual models can be provided to answer the question what optional&lt;T&gt; really is and what interface it should provide. The three most common models are: &gt;1. Just a T with deferred initialization (and additional interface to check if the object has already been initialized). &gt;2. A discriminated union of types nullopt_t and T. &gt;3. A container of T's with the maximum size of 1. -snip- &gt;Model (2) treats optional&lt;T&gt; as either a value of type T or value nullopt, allocated in the same storage, along with the way of determining which of the two it is. The interface in this model requires operations such as comparison to T, comparison to nullopt, assignment and creation from either. It is easy to determine what the value of the optional object is in this model: the type it stores (T or nullopt_t) and possibly the value of T. This is the model that we propose. &gt;Model (3) treats optional&lt;T&gt; as a special case container. This begs for a container-like interface: empty to check if the object is disengaged, emplace to engage the object, and clear to disengage it. Also, the value of optional object in this model is well defined: the size of the container (0 or 1) and the value of the element if the size is 1. This model would serve our pupose equally well. The choice between models (2) and (3) is to a certain degree arbitrary. One argument in favour of (2) is that it has been used in practice for a while in Boost.Optional. So std::optional is not modelled after a container, explaining the choice of interface. However, reading the rationale and looking at the current interface, I don't see any obvious barrier to extending it to provide begin/end/size and whatever useful container-consistent facilities are desired, so perhaps this is something that can be proposed in the future.
No, you are not. You are only permitted to add specialisations to std::-namespace function templates for user-defined types, NOT for std-namespace types. You can get away with it if you are doing it for a std::optional&lt;SomeUserDefinedType&gt;, but that would be less useful. See here: http://en.cppreference.com/w/cpp/language/extending_std#Adding_template_specializations
Even that's talking about class templates, not functions, so the way to extend std::begin/end for a user-defined type would be to have member functions picked up by the general purpose std::begin/end... But the statement at the top of that page is pretty clear!
Plus most refactoring does not change APIs (or should not).
You could just as easily point out that `int x = i / 5.0` might be an unintentional implicit conversion from double to int, whereas `auto i = i / 5.0`has the correct type regardless of the type of i. In your example, it's highly likely that the auto example will fail to compile at some other point later on. In my example, the implicit conversion threw away information permanently, and if the type of i changes later, too bad. My point is, what he human expects is a source of bugs and not something that the compiler can check in all cases, because of conversions.
Thank you for your answers and for your work on lld! I've found that the error message was because one .lib was compiled with debug info but it wasn't present on my machine. MSVC linker only warns about it instead of an error. About speed - it's definitely faster than /DEBUG:FULL already, but after quick profiling I've found several places that are easy to fix and gave nice speedup for my project (from 2.40 to 1.30 min). Do you accept pull requests (and how to do it, never had worked with llvm codebase)?
I said global, nothing about adding to std namespace. Wouldn't recommend that.. Something along these lines: https://wandbox.org/permlink/1rgRNw3D8jS1Kz5T
Definitely! Check out the code by following [these instructions](https://llvm.org/docs/GettingStarted.html#for-developers-to-work-with-a-git-monorepo). Then create an account on our [code review system](https://reviews.llvm.org/). Upload the patch there and add llvm-commits as a subscriber and myself as a reviewer. If you need more help you can ask here or on the llvm-dev mailing list. Thanks!
I would rather write special case code for std::optional than do something like that. Constructing temporary std::optionals for non-optional types isn't desirable just for the illusion of a generic interface. This feels like the worst of all worlds. 
If you need an optional, please don't use a vector. Heap allocation, can't use in a boolean context, doesn't express intent, and introduces throwing on construction / copying even if T does not. 
Yes the implicit ctor of optional will cause trouble. I agree on that.
I'm not aware of the situation with Julia, but the D interface has a number of limitations. Most importantly, most useful C++ libraries now exist as template libraries, and (correct me if I'm wrong wrt to Julia) but nothing interfaces well with that. Many C++ types have semantics that cannot be brushed under the carpet - for example does a std::string type deal with move-semantics or limit the usage to pass by reference. With C it's fairly simple and well defined. My usual approach is to simply define a C level interface to any C++ code I want to be accessible portably.
Yes, but it glosses over the details far too much - emscripten is not a typical conversion layer, it targets asm.js as a backend for a C++ compiler.
Most back ends will support a C ABI. If they support only a C interface then, indeed, no std::string passes there (as mentioned/alluded in the footnote). 
I'm not going to read anything until you fix the [UB](https://github.com/cyberguijarro/constrained/blob/master/constrained.hpp#L9) in your proof of concept.
UB?
I think you're basically thinking of functors; Haskell's `Maybe` and Scala's `Optional` behaves this way. The core problem is that, although it makes sense from a mathematical (e.g. category theory) and convenience perspective, when it comes to imperative languages like C++, it's just hard to read: for (auto value : optional_value) std::cout &lt;&lt; value &lt;&lt; '\n'; is no better than: if (optional_value) std::cout &lt;&lt; *optional_value &lt;&lt; '\n'; That's really all. 
https://stackoverflow.com/questions/228783/what-are-the-rules-about-using-an-underscore-in-a-c-identifier
You could overload (in your own namespace) non member `begin` and `end` to allow the idiom.
I don't think anyone would use it this way directly; the more likely usecase is in generic code where the algorithm is range-centric and you don't necessarily know you have an `optional`.
Since range-for loop does not perform ordinary unqualified lookup, this would work only if said namespace is associated with the template parameter `T`. But what about `std::optional&lt;std::string&gt;`?
If your code is inside the same namespace you implemented the `begin` and `end` function, you don't need ADL. If you have many namespace, you can put `using namespace mynamespace::rangeopt` do it enables the for loop.
&gt; That's like saying a pointer could be considered a container, referencing memory or nullptr. No no no, pointer doesn't *contain* the element, unlike optional.
The APIs for querying line/symbol information by address specifically are slow (SymGetLineFromAddrW64, SymFromAddr). I implemented all kinds of nasty hacks in x64dbg to make it workable, but if you start stepping around chrome with debug symbols it's definitely noticeable...
First code block under **Defining a reference** &gt; int refA = &amp;a; Should be `int &amp;refA = a;` 
Thanks!. Corrected it.
Sorry, but that's just crazy talk. There is no situation in which the first one is more readable. There's no type information in the first two lines and in the third line, the type info is not where it usually is to anyone who's known the language up until C++x11 (or even later with constexpr)
Interesting, I wouldn't expect that to be particularly slow given how the records are structured internally (I think you can binary search them, for example). I'd be surprised if DIA vs dbghelp would be faster there, but I guess it's possible it has an extra caching layer that makes subsequent lookups more efficient than the first.
I think you have a good point about implicit float/int conversions, because that has been a weak spot in C++ for a long time, which is why we should be writing int x = {i}; now (but most people still don't out of habit). But it's a wide world out there, with a lot of classes that have limited types that they can cast between with constructors, etc. Auto eliminates that check in the system and gives you something that might even compile and run but be horribly bad. One of the strengths of C++ is how the type system finds so many bugs at compile time rather than run time... IMO, it's a weakness to throw away all that type checking and moving more towards the Python or JS model.
Your last sentence is a mistake, C++ with or without auto is statically typed. Auto does not imply, or move closer to, dynamic typing. It does not move type safety away from compile time, for that reason. All it does is move most of the decision as to the type of a variable from the programmer to the compiler. Usually the two would have agreed. The only time they will not is when the programmer desired an implicit conversion. What you posted before was about something else entirely - catching a programmer error, where they wrote the wrong code, and caught it because they tried to assign it to a variable of an incompatible type. My point is that this class of error cannot be reliably caught in this way, because of the existence of conversions, and actually I don't think in reality it's a big problem anyway. 
&gt; Your last sentence is a mistake, C++ with or without auto is statically typed. I didn't say it wasn't. But I see auto as an attempt to move more in the Python and JS direction, which I disagree with, philosophically speaking. &gt;It does not move type safety away from compile time, for that reason auto x = foo_factory(); x.foo(); foo_factory has a bug in it in where it returns a Bar with a .foo method rather than a Foo with a .foo method in it. The Bar foo() is almost identical, except 1 out of 100 times it will return a number one higher than it is supposed to. If we had written Foo x = foo_factory(); we would have caught it at compile time, because there is no implicit conversion available between Foo and Bar. But because we used auto, it will compile and run just fine, but introduce runtime errors that will frankly be a pain in the ass to discover. This is a somewhat contrived example, but I've seen this class of bug actually occur repeatedly because there was a mismatch between what the programmer thought the type should be and what the type actually was deduced with auto. 
I'm finding it really hard to imagine a real world scenario where this could realistically happen, and I've certainly never come across it. I'd be interested in seeing an example if you happen to find one. Generally speaking, it would be difficult to introduce a bug where an interface returned the wrong type because basic unit testing and review will catch that. As will casual inspection. 
1. `flag` is just a struct containing the C enum. So `flag::flag1` being a C enum is convertible to an int, there is no type safety in that direction (which is why Boost doesn't like it, plus they don't like the macro based solution, but I like it because it prints with no hassle). But `struct flag` won't accept construction from anything but `flag::flag_enum`, so it's safe in the sense that you can't accidentally construct the bitfield from anything but the enums. 3. It is as described in the usage: `if(myflags &amp; flag::flag1 &amp;&amp; myflags &amp; flag::flag2)`, though you really should write `if((myflags &amp; flag::flag1) &amp;&amp; (myflags &amp; flag::flag2))` for clarity. 
&gt; I'm finding it really hard to imagine a real world scenario where this could realistically happen, and I've certainly never come across it. I'd be interested in seeing an example if you happen to find one. Different functions for float vs. double, and having it change when the programmer replaced: float x = 5.0; with auto x = 5.0; And similar examples for char * and string.
This type of post again? C++ is absolutely relevant. Those who say it is not are (generally, IMO) web developers whose bottleneck is the network. If you want to get in with graphics, C++ and Vulkan might be a good point for you. DirextX is still used, but I know a number of places are looking for Vulkan developers which are a rarer breed. Game development is has a variety of components. Do you want to make games or make game engines? If you want to make games and not worry about the math behind it, then go grab Unity or the Unreal Engine and use it rather than reinvent the wheel. If you want to do engine development, then get ready to learn some math so you know what you are programming. Web development using databases and such are generally easier to do because Java, C#, Javascript, etc. have frameworks built to to much of it for you. C++ less so. C++ isnt used in just niche application spaces. Yes, compared to C# and Java is may excel in games, but a good C# developer could beat a bad C++ programmer in performance. You can use C++ for desktop apps, web stuff, embedded systems, etc. The real questions are: What can't you do in C++?, and What would be better in other languages? Errors in Template Metaprogramming are sometimes hard to parse through without a good compiler. 2 - Yes and no. If you write correct code that uses language features that VS 2017 supports, then you will get good code. If you use unsupported things, then no. Same with GCC and Clang. Same with Java, C#, Python, etc. 3 - I personally have found C++ is a less competitive field for jobs compared to Java. Programming schools churn out mediocre Java developers which you then compete with. It also increases the supply of programmers which keeps salaries down compared to C++. 
Anyone that told you C++ is obsolete, only for game developers, or system development is someone you shouldn't listen to. C++ might not be as prevalent as Java and C but it still powers a massive majority of the world. Even Microsoft went back to it for the core of the windows GUI and os after an attempt to push it all to managed c#. 
Also, looking at your post history, I am really confused. What do you want to do? Are you trying to change careers and pick between SysAdmin, Game Developer, or Web Developer? Were the answers to this same question before not useful to you? https://www.reddit.com/r/programming/comments/6ia6e8/is_it_worth_learning_c_today_in_2017_need_expert/
How could those cases introduce such subtle bugs? 
check the sidebar
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/6uz6vz/the_best_way_to_learn_c/dlwhxgy/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/6uz0u5/is_c_obsolete_today_in_2017_need_expert_advices/dlwipqc/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
&gt; This type of post again? No :p
&gt; How could those cases introduce such subtle bugs? Overloaded functions. So switching to auto caused it to bind to a different function than before. Code still ran, but with runtime bugs that were a pain to track down.
I think I follow. So by changing to auto, and calling a function with that variable as the parameter, you called the 'double' overload of that function rather than the 'float' overload? I can see how that could happen. But first, that is completely different to anything you've been talking about so far. Second, if one of the overloads has a bug, then testing will catch that bug. It's hardly fair to blame that on auto. Any code not using auto, calling the broken overload, will also have the bug. If you have a function with float / double overloads whose behaviour isn't buggy, but rather differs in terms of expected behaviour, then that is a poor design. It is highly likely that such designs can be improved by taking advantage of C++'s type system, i.e. don't just use raw float/double, use a wrapper.
Why not make all objects a range of 1?
Haskell treats Maybe the same way.
Last time this came up (20 days ago) I said: "size 1 container" is a bad model for optional Containers don't - propagate assignment operator= - propagate operator&gt; et al - compare with their element type (ie Container() &lt; element()) - use operator* to get the element - convert to bool - ... The model for optional&lt;T&gt; is "T with an extra special value". But that's not the right model either. The right model is "controlled lifetime. Warning: assignment will assign or construct." Using a `for` loop on optional is just asking for misunderstandings. What you maybe want is some kind of support for monads in an `if` or maybe a new `with` statement, or similar. Maybe pattern matching. 
&gt; But first, that is completely different to anything you've been talking about so far. Second, if one of the overloads has a bug, then testing will catch that bug. No, they were completely correct. It's more subtle than that. The double version was returning (again, I'm simplifying) a long long whereas the float version was an int (64 bit -&gt; 64 bit and 32 bit -&gt; 32 bit) which is obviously a rich source of indeterminate behavior down the line. All of it caught at runtime instead of compile time. &gt;But first, that is completely different to anything you've been talking about so far. It's the same thing. There was a human check on correct behavior when there was explicit typing, but you lose that check when you switch to auto, and what the compiler deduces is not always the same thing you deduce with your grey matter. 
Forgive me, but nothing you're saying is convincing me that auto is really involved here, it just sounds like a very error prone design. You shouldn't rely on human checking. 
Your variables' types _should_ match their respective initializers' types; `auto` just makes it trivial to enforce this. I.e. the fact that your initializing expression and your data type don't agree is itself a bug, and had _that_ bug not been present then switching to `auto` wouldn't have caused a problem.
&gt;You shouldn't rely on human checking. I'm not saying you should exclusively rely on it, but it certainly provides an additional level of protection and you lose that level of protection with auto. The whole point of the compiler in C++ is to find mistakes that the programmer made in writing his code, as much as possible. When you remove those clues from the compiler, you will increase the number of mistakes that escape the compiler check and propagate to runtime bugs. I don't hate auto, but I do think that a lot of new C++ programmers just use it because they came into the language from Python or JS and want to make "var"s instead of having to specify their types in advance. 
Do you think that function templates should always be called with explicit template types? Because you are effectively arguing against any kind of type deduction. I think that is a very bad idea and ignores all of the benefits this has. It sounds like you got burnt by a bug, you decided this was the root cause and it turned you off auto for this reason. I don't think it's a strong argument. If you had simply said that overuse of auto makes code less readable it would be sufficient. 
I have found that forcing myself not to care what concrete class foo is has changed how I write code, for the better. 
&gt;It sounds like you got burnt by a bug, you decided this was the root cause and it turned you off auto for this reason. It's not just the one bug, and it wasn't my personal code. I work with a lot of newer programmers, so I can directly see the benefits of explicit typing when working with them. The benefits of auto are a lot more nebulous. &gt;Do you think that function templates should always be called with explicit template types? Because you are effectively arguing against any kind of type deduction. No of course not. Templates are different from auto. For example, having multiple types with .foo() methods is exactly the sort of thing you can do with templates, with a template function calling whatever foo() that the T passed in has. Outside the scope of the function, however, you usually know what the variable type of the parameter you're passing in is, and if you don't, then the same sort of arguments apply. I don't see how obfuscating type data ever results in better programs being written. (I can see how it can help with *refactoring* code, but not in writing *correct* code.) I do think that templates should have reasonable constraints, like making sure that T has to be an integral type if the templated function is using T as an integral type. Again, it's about providing useful information to the compiler so that it can catch bugs and not accidentally compile something that results in run-time indeterminism, which is basically the devil.
There's nothing wrong with string s = "Hello World". It's common usage, despite the lhs type not matching the rhs type. That's why we have constructors in C++ that handle common implicit conversions like this. When you eliminate the type data on the lhs, you can no longer check to make sure that the variable that you thought it was supposed to be has a legal conversion from the type the compiler deduces the rhs to be. You just get a variable of the rhs's type, and lose a valuable source of type checking as the result. If the lhs and rhs always had to be the same type, then we might as well throw anything except copy constructors out of C++, and basically the entire STL while we're at it.
Yes, implicit conversions are a thing, but since you seem to be arguing in favor of explicitness, I don't see how you consider them a _good_ thing... ;-] There's also nothing wrong with `auto s = "Hello World"s`, which despite use of `auto` is _more_ explicit than what you're promoting, since the initializing expression is already a `std::string` and zero conversions are involved. If you want explicit code, don't rely on implicit conversions – give your initializers the correct type to begin with. After you do, as though magically, you'll likely find that explicit types don't matter so much.
There are ways in which it helps in writing correct code. Most importantly, it prevents accidental implicit conversions, as I've already alluded to. This is important in generic code, especially. "better" in general is more subjective, and I'm not going to repeat every single argument for and against auto here. Supplying / not supplying the template parameters for a function template is, I think, precisely equivalent to the issue of auto variables in the sense that I could reformulate your float/double overload bug in different terms and end up arguing that you should always supply explicit function template arguments. And that is intuitively wrong. We're just used to not doing that. 
I think most subscribers/visitors to /r/cpp already know this information, and while you have obviously tried to write something decent, the information contained in your article could also be learned from an online course or from a book. I don't feel like these types of posts really add anything new to the conversation here at /r/cpp.
To avoid confusing newcomers I prefer to write the "&amp;" close to the type: int&amp; refA = a; Otherwise, to the untrained eye, looks like the operator to get the address. The same for "*": Close to the type when declaring a pointer, close to the variable name when dereferencing. 
Swift doesn't have `Optional` implement any container protocols, but does have some of the container functions like `.map()` and `.flatMap()` implemented specifically for it.
Doesn't that fail for plain old `int`s anyways?
&gt;Yes, implicit conversions are a thing, but since you seem to be arguing in favor of explicitness, I don't see how you consider them a _good_ thing... ;-] Actually what I'm arguing for is giving the compiler the information it needs to catch bugs. Auto removes an important source of hinting. &gt;There's also nothing wrong with `auto s = "Hello World"s`, which despite use of `auto` is _more_ explicit than what you're promoting, since the initializing expression is already a `std::string` and zero conversions are involved. If you want explicit code, don't rely on implicit conversions – give your initializers the correct type to begin with. After you do, as though magically, you'll likely find that explicit types don't matter so much. The compiler uses constructors to determine what type combinations are legal. By removing the left half of the equation you just have to sort of hope the right side is correct. I'd rather have the higher level of safety.
How is two constructors better than one constructor? Again, avoiding conversions altogether is a step towards correctness, and clarity. EDIT: To expand, specifying a type instead of allowing it to be inferred is creating the opportunity for implicit conversions where there would be none otherwise. I.e., you're _introducing_ a potential class of bugs and/or inefficiencies.
It's a somewhat decent beginner introduction to various facets of multithreading with C++. To nitpick... &gt; On the performance front, Kurt Guntheroth found that creating a thread is 14 times more expensive than using an async. This quote, and the number, are taken out if context. About mistake 1: threading stuff is easy, unthreading it is hard :-). There is **no** correct way to stop threads but to make their code stop in a timely manner, e.g. by inspecting some flag or synchronization object and then `join()` them. Solution 2 in mistake 1 is of **exceedingly** small usefulness - it only works on systems where the OS cleans up everything after a process **and** there's no I/O left to do after detaching the thread (making sure of that is equivalent in difficulty to joining correctly, see above). The "runnable/waitable" terms are weird. This is normally called CPU and IO-bound code, I think.
Your post might be more valued at /r/learncpp .
&gt;How is two constructors better than one constructor? Again, avoiding conversions altogether is a step towards correctness, and clarity. Because some forms of implicit conversions are perfectly sensible. &gt;EDIT: To expand, specifying a type instead of allowing it to be inferred is creating the opportunity for implicit conversions where there would be none otherwise. I.e., you're _introducing_ a potential class of bugs and/or inefficiencies. Whereas hiding type data can introduce even worse bugs if the mental model of the programmer doesn't sync with what the compiler produces. auto x = {3}; generating initializer lists (in '11) instead of an int being an easy example of how even seasoned veterans could be surprised by these sorts of C++ trivia. It was such a problem they had to fix it in the standard. Specifying int x = {3}; by contrast ensures you know x is an int without any surprises and allows the compiler to double check your work.
You are missing the "ordinary unqualified lookup is not performed" part of my post. Allow me to bring in more context. This is the relevant part of [stmt.ranged], with emphasis added: - otherwise, *begin-expr* and *end-expr* are `begin(__range)` and `end(__range)`, respectively, where `begin` and `end` **are looked up in the associated namespaces (6.4.2). [Note: Ordinary unqualified lookup (6.4.1) is not performed. —end note ]** So, you do need ADL. Declaring `begin` and `end` in another namespace and then bringing them in scope with `using` will not work with for-range loops.
So `get_sum(opt);` effectively does `opt.value_or(0)`? This seems too ... idiomatic.
 &gt;Supplying / not supplying the template parameters for a function template is, I think, precisely equivalent to the issue of auto variables in the sense that I could reformulate your float/double overload bug in different terms and end up arguing that you should always supply explicit function template arguments. And that is intuitively wrong. We're just used to not doing that. I'm not sure you can. Suppose we have a templated function that takes a generic floating point parameter x and returns an integer of the same bit length. Then in main we call this function with float x or double y - we know exactly what version of the function will get called since the type data isn't obfuscated. The only risk is from calling it with a literal, but they'll usually check at the moment they write the code, whereas the auto change introduced a bug into already working code. 
So how do you flatten a range of optionals into a range of T? If optional was a range, that's just a range of ranges (some of which are empty), and using range-v3 this is trivial. If optional is not a range, any solution I've seen sucks.
What I don't like about the loop is that it's not really a loop. The body is executed at most once. So, it might confuse readers. What I *do* like about the for range loop on this case is that the optional's name is only used once and you don't have to use a method (operator*) which invokes undefined behavior if its precondition is not met. So, this pattern avoids the potential error of checking and dereferencing different objects by mistake. 
&gt; for (auto value : optional_value) &gt; std::cout &lt;&lt; value &lt;&lt; '\n'; &gt; &gt; is no better than: &gt; &gt; if (optional_value) &gt; std::cout &lt;&lt; *optional_value &lt;&lt; '\n'; Replace `optional_value` with an expression with side-effects. The "for-range" version would still work unchanged, while the "if" version requires you to introduce a new variable. So you end up with this: if (auto optional_value = f(); optional_value) std::cout &lt;&lt; *optional_value &lt;&lt; '\n'; which is not less hard to read than the for-range version. 
&gt;Unfortunately, as of today, any of the major compilers support the feature. I assume that's supposed to say "none of"
In the second case, you actually end up with this: if (auto optional_value = f()) std::cout &lt;&lt; *optional_value &lt;&lt; '\n';
While I don't like the fact of tightly coupling the programming language with its tools (i.e. Java), most IDEs out there should in fact be able to show you the type of auto variables on a mouse hover. This is trivial to implement using the `libclang` API which means that it can be easily brought in into a non-IDE environments as well (i.e. [Vim](https://raw.githubusercontent.com/wiki/JBakamovic/yavide/images/type_deduction.gif)).
&gt;Unfortunately, as of today, none of the major compilers support the feature. There's some more details about Microsoft's plans to support them here: https://www.reddit.com/r/cpp/comments/6t4kse/c17_features_and_stl_fixes_in_vs_2017_153/dli67aw/ Basically a lot of the parallel algorithms are slower than the serial versions, and par_unseq will not be implemented - I'm not really sure how it can be for anything with a predicate etc, and for basic stuff vectorization can be automatic anyway, no need for a special policy.
/u/jimgries I just created a new CMake project (with a very minimal CMakeLists.txt and only a singel .cpp file) to test this and it, and it still seems to use MinGW. Here is the output when I open the folder for the first time: https://pastebin.com/wapPaq3j The .cpp file contains #include "foo.h" (which is a non-existing file) and an empty main function. When building, the error doesn't appear in the error list. This is the output when trying to build the project: https://pastebin.com/gXrjtYTY If you want the files, here they are: https://www.dropbox.com/s/znxhbbzwuhvdsfe/vsNinjaTest.7z?dl=0
Interesting tool, i will give it a try :)
Go in the options &gt; Debugger &gt; CDB Paths Look at the Symbol Path text field Now save them just in case And then clear them This should provide a faster debug process!
As I mentioned in a previous thread, all the best anti-auto posts contain toy examples with rubbish naming. If that's normal code for you, then don't use auto. Otherwise, your code should express the concepts it uses in its naming, and the concepts should be uniform across an abstraction layer. That is, `ImReturningABob()` should definitely return whatever counts for the Bob concept in your layer of abstraction, be it an int, a string, or a Bob. Likewise, `ITakeABob(x)` should take an int, a string, or a Bob respectively. 
Why is compiler support needed for this? I thought it only effects the STL? 
Libstdc++ had parallel mode for ages
Every language seems to define the requirements for fold/reduce/accumulate/combine differently: https://en.wikipedia.org/wiki/Fold_(higher-order_function)#Folds_in_various_languages But C++ is different in a pretty unique (and IMO wrong) way in that they require the **commutative** property for reduce. I get that not having to synchronize the order for recombining sub-reductions might make it faster but then you lose the ability to parallelize a large class of useful reductions for free. Most programming language with a paralellizable fold (that I know of) only requires associativity. Explicit example for those not familiar, let's say we have an operator * with signature (T, T) -&gt; T and we want to calculate the following reduction: a * b * c * d * e * f * g * h which with explicit parentheses looks like: (((((((a * b) * c) * d) * e) * f) * g) * h) If we know our operator is associative, we are allowed to reorder the parentheses however we like, which means we can chunk up the work for individual threads like so: (((a * b) * c) * d) (((e * f) * g) * h) And then combine them back into a final result and it will still be correct: ((((a * b) * c) * d) * (((e * f) * g) * h)) The only additional thing commutativity buys us is the ability to combine them without caring what order the threads finish their chunks in: ((((e * f) * g) * h) * (((a * b) * c) * d)) This happens to be correct for integer multiplication/addition/etc but not for a large class of useful operators like matrix multiply, sequence concatenation/joining, etc, that are only associative but not commutative. tl;dr; I think reduce should only require associativity to conform with other programming languages and to enable a larger class of reductions. 
Coming back to this thread one month later now that the 15.3 is officially released. It seems the support for 128- and 256-bit vector types for new instructions is missing. Example of missing intrinsic: _mm_cmp_ps_mask This brings the compare-to-kmask support to xmm and ymm registers. There are other gaps as well but just to get started ALL of the 8, 16, 32 and 64 bit signed and unsigned compares are missing that should be there. Am I simply missing some compiler flag that is documented somewhere? 
We talked about something like this at the last ACCU Bay Area meetup. Interesting!
I put it on the right. This is one place C++ went wrong, in my opinion. The original intent was "declaration mirrors use". That is, you have: int a, *b, c(); and the expectation is that all of these expressions on the right evaluate to the type on the left. (i.e. `a` is an int, `*b` is an int, `c()` is an int.) Using `&amp;` for reference broke that (not that I can think of a better way off the top of my head, since references are invisible in the language), and C++ has never recovered. That's why nearly every coding standard has the "one declaration per line" rule, because that's where the "avoid confusing newcomers" gets moved to when you put the notation on the left.
&gt; The original intent was "declaration mirrors use". This was true in 1970s, but it has long been broken. E.g. how does int f(void); mirror its use? It can't be called with `f(void)`, can it?
He probably meant compiler collections, including STL
Right, even in integer space, reordering isn't safe if it can introduce overflow.
I am curious how this plays out when the predicate is the bottleneck and not just a pure memory bound reordering.
I don't think that use case is important enough to warrant making optional a range. If that use case _is_ important, make a template function that does it for you.
You can find the reddit post of the benchmark with comments [here](https://www.reddit.com/r/programming/comments/6v33e4/benchmark_of_major_hash_maps_implementations/) (and [here](https://tessil.github.io/2016/08/29/benchmark-hopscotch-map.html) for a direct link to the benchmark). I developed the library mainly as an alternative to the [hopscotch-map](https://github.com/Tessil/hopscotch-map) library which suffers from two problems: * With a poor hash function, hopscotch hashing can quickly suffer from clustering in the neighborhood of a bucket causing extensive rehashes. * When we want to store the hash alongside the value, we have to reduce the size of the neighborhood which may deepen the previous problem. Linear robin hood hashing doesn't suffer as much of the first problem and can easily take advantage of the alignment of the bucket to store the hash (as it only need a few bytes for bookkeeping) and will do so automatically in some cases. On the other hand, it doesn't do as well with a high load factor. So well, yet another hash map implementation. If you're a bit lost with all these hash maps, you may want to look the [Which hash map should I choose?](https://tessil.github.io/2016/08/29/benchmark-hopscotch-map.html#which-hash-map-should-i-choose) section of the benchmark.
It is what makes non-auto codes easy to write. It helps Edit: it is what makes emails unreadable. Mostly when you're drunk. It helps no one understands that s***f
I always thought range for loops used `begin` and `end` normally, but never tried extensively. Thanks for clarifying that for me. I didn't understood why I got downvoted. I guess we still learn every day!
Can't you do it with `v | view::filter([](auto&amp;&amp; opt){ return opt != nullopt; }) | view::transform([](auto&amp;&amp; opt){ return *opt; })` (or similar)? It's longer than a single call to flatten/join, but not incomprehensibly so.
Sure but 'v | view::join' is way nicer.
It is, but it's also a lot less obvious what it's doing.
It is not about optional, or any, or variant, or future, or... it's about having to learn N incompatible APIs to do the same thing. Not that having N APIs to do the same thing is a bad thing, but I at least would like to have a single API and ranges is the only one that C++ has and simultaneously makes sense.
At work we have a use-case where we sometimes want to run an algorithm several times with different data. Is there any implementation out there that keeps the allocated memory for the hashmap when you clear your hashmap? Something like a cache invalidate method maybe.
I think a monadic interface is what we need then. Maybe Ranges is the closest we have for now, I guess. But it probably isn't ideal.
Most hash maps will not reduce their `bucket_count` on clear in a way similar to `std::unordered_map` as clear must be noexcept (we thus can't allocate a smaller bucket array, we would need to keep a smaller bucket array on the side). So just pick any hash map using open addressing (`tsl::hopsctoch_map`, `tsl::robin_map`, `ska::flat_hash_map`, ...) but not `google::dense_hash_map` which does reset the bucket array to its minimum size. The hash map will then just use placement new into the bucket array.
Cool! Thanks for the quick reply!
Do you think that it would be possible to make a bit more benchmarks for 0 - 1000 elements ? I'm often in this map size ballpark and need to find the a given key with the smallest possible read latency. Also you may be interested in implementing a [PATRICIA trie](https://cw.fel.cvut.cz/wiki/_media/courses/a4m33pal/paska13trie.pdf) (special case of radix trie; see also https://stackoverflow.com/a/15906358/1495627 for a nice explanation), I think that it would fit well with your marvelous set of containers :) 
The only times I've ever found predicates to be slow is due to them having to dereference things - which is just memory bound again.
That is legacy C style syntax where `int f()` meant a function with an unspecified number of params while `int f(void)` meant a function with no parameters. You really should never write the `int f(void)` style in modern C++. https://softwareengineering.stackexchange.com/a/287002
Unless one knows that optionals are ranges of zero or one elements. But yeah, even then, it could be more obvious.
That would be ideal, but I don't think C++ is the best language to go down that route.
&gt; I care about the concept foo represents Concept foo = something_that_models_Concept(); aka existential types are not supported in C++.
Scala supports existential types, with allow you to write: Concept foo = returns_something_that_models_Concept(); It doesn't tell you the exact type of `foo`, but it does tell you what you can do with it. Rust also supports this in nightly (`impl Trait`) but C++ does not really support this[*]. [*] although it does have some support for existentials since C++14.
I do this as well, but mainly because in my mind, the &amp; is part of the type (refA does not have type int, it has type reference to int). I want to see the whole type, and not have it split up awkwardly with a space. Which is also why I dislike how references and pointers in comma separated declarations work.
Unfortunately the current benchmark is difficult to adapt for such a small number of elements. But I did a quick test with random integers and large strings with google benchmark. You can find the code [here](https://pastebin.com/73rLaN69) and the results [here](https://pastebin.com/6Tk98BHq) (better view with raw). With all having a max load factor of 0.5f and power of two modulo, the three main speed-oriented hashmaps (`tsl::hopsctoch_map`, `tsl::robin_map`, `ska::flat_hash_map`) have more or less the same performances on this kind of small set of data. There are some small variations from one test to another, but too small to be significant. More tests should be done (there just seems to be a problem with `google::dense_hash_map` but I don't have the time now to investigate). Used Clang 4.0. Thank you for the appreciation. Yes I know about the PATRICIA trie, I ended up to decide to go with the HAT-trie route, but I may one day implement it to compare different tries (but it will not be before months and will depend on my mood :)). 
acceptor is an `io_object` that uses `io_service` / `io_context` to dispatch the async operations. It is lot more involved as it involves putting the tasks in the operation queue and stuff like that, but those are the finer details. The `io_service` itself could be using 1 or more threads (depends on how you do it in the client code) for running the event loop. So, to answer your question, `async_accept` does not create a new thread, the completion handler is executed in the context of the `io_service`, which could be the main thread or some other thread where you have called `io_service::run`/`io_service::poll()_one` from. You can change the code to use a `unique_ptr` instead of `shared_ptr` if you can see to it that there would be no life time issues i.e you don't end up using a pointer in the completion handlers that are already deleted due to some other event/action.
excellent. subscribed.
So going by what I skimmed from the code its a bit like a genetic algorithm: mutating a population of configs according to their fitness based on edit distance it would cause? It seems like a fun 'optimisation' problem to tackle that actually can tell you something usefull about your codebase.
Yet again: boo!! No, we do not like this.
oh, I see. So, I would have to make something like a thread pool. each with its own io_service running like this : (example)[https://stackoverflow.com/questions/7957059/boostasio-io-service-thread-pool]. I'm guessing it would be safer for a session class to use shared_ptr? So, I'm trying to develop a video server on tcp. I am wondering if it would be bad design to make a statemachine in the session class to handle handshake.
Stacktrace looks quite similar to https://github.com/bombela/backward-cpp
Both are noisy, but the second one is noisier.
&gt; Can't agree. The second one explicitly tells the type while the first one is implicitly deduced. What does guarantee to you that constexpr auto name = "xxx"; is the same after a some years? What if the standard changes and it is deduced as std::string (or another string/character type) instead? Trust me, you will be long dead of old age before that can even be considered a possibility. 
Yeah I personally hate the default constructor for deserialization. I'd rather see either `MyClass(DeserializationContext &amp;)` or some crazy macro that expands out to be the parameter list of the regular `MyClass(Params...)` constructor. I've tried writing the second one as a variadic template similar to `std::apply` but it does require someone to know all of the parameters and fields. I considered at one time going full on crazy and having every object just be a `std::tuple` and then making all functions free functions to work with that in order to avoid this problem. Maybe the solution is that every object is composed of a `std::tuple` (so you can expose the tuple's type for apply to be used) and it just acts on the fields as if they were members.
I have a problem with anybody pretending they can master unsafe languages full of potential UB everywhere to the point they think it is perfectly reasonable to code safety critical systems with it. I don't remember who, but they were a prominent figure, explained recently that those who pretend they are good enough to avoid all UB just pretend that because they are not actually *that* good to figure out it is nearly impossible outside of toy projects. So I'm glad you try hard to avoid all UB and stick to the standard, but IMO it is a vain fight when it comes to being able to write serious systems in the modern age. Just use C++ for video games and the like, and switch to a safe language that does not try to actively kill everybody for your serious projects, if you have such risks. Doing otherwise would be irresponsible. 
Can I ask why?
Stacktrace looks interesting, but as with so many other Boost libraries I'm missing a clear, concise overview. Yes, it gives access to stack traces... But in this case I believe it would also be interesting to know _how_. Does it require you to annotate the source, or build with specific settings? Does it read compiler-specific files to get the information? If so, what compilers are supported? etc.
Backward-cpp works only on Linux.
You can find this info here: http://www.boost.org/doc/libs/1_65_0/doc/html/stacktrace/configuration_and_build.html
&gt; each thread can have at most one in flight Wrong! (I can't believe I missed this one) You can have as many active exceptions in given thread as you like (limited by stack size and implementation details).
Simple rule in my work code base, which I believe is a rational compromise (I have to admit bias, it is my rule). If the type name is on the right hand side of the assignment, you may use auto. No other case is accepted. 
Who let the trolls out? 
Well, if you associate a session with a connection which is bound to one of the `io_service` from the pool, I am pretty sure (Though I do have some doubt at the back of my mind) that you would not have to worry about your handlers getting executed on other threads and thus avoid race conditions in your state machine. So, if by design you can guarantee that your session object can outlive the states and asynchronous handlers, then you can use `unique_ptr`. I would suggest to start with `shared_ptr`, it would be less headache and then later if needed go with `unique_ptr`.
&gt; the locks we are talking about might not even be compatible with that I don't know of a useful locking primitive that doesn't provide equivalents of lock(), try_lock(), and unlock(), which are all that is necessary for using std::lock. You don't need to use it with `std::mutex` -- any type meeting `BasicLockable` works. &gt; go back to the basis with the programmers and teach them about deadlocks and locking orders If you're "going back to the basics" (and therefore unlikely to be in a legacy codebase) then maintaining a locking order is less efficient than the algorithm that `std::lock` uses. See Howard's article. &gt; In other cases, for example in operating systems, you typically want to stick to a fixed order. Unless you have some constraint that prevents you from doing so sticking to a fixed order is worse. I don't see anything about operating systems which makes them different from traditional applications which would make a fixed order somehow better for them.
&gt; In real life you encounter code bases where a lock is taken, some code is executed, an other lock is taken, etc... Such code can probably refactored into "a lock is taken, some code is executed, the lock is dropped, std::lock takes both locks, some other code is executed", etc.
And yet they list this feature as not yet implemented.
We aren't implementing `par_unseq` because it only has meaning if you're using something like ConcRT (where workers don't have thread identity), which we tried once and turned out to be a disaster (because people mixed ConcRT with built in synchronization primitives like `CRITICAL_SECTION`, `SRWLOCK`, mutants, or events which results in deadlocks). The description in the standard "parallelized and vectorized" refers to GPU like architectures where one thread continuing to make progress can prevent other threads from completing any work (since all the threads have to run in lockstep). Since we're targeting CPUs and anything that gets vectorized needs to be explicitly recognized as a vector pattern by the BE, there's a lot less benefit for us. I could easily see an implementation like CUDA taking advantage of `par_unseq`. 
There are circumstances you can create where parallelism is faster (e.g. copy a `vector&lt;string&gt;`), but we think they are likely edge cases. We don't plan to parallelize them at this time but that doesn't mean we won't ever parallelize them. If the case for smaller N wasn't so much ridiculously slower (orders of magnitude) we probably would have opened that can of worms. (1.6x slower was at N being something fairly big like 10'000'000 doubles).
in one part of the chat tcp server code, they have this for the async read : boost::asio::async_read(socket_, boost::asio::buffer(read_msg_.data(), chat_message::header_length), [this, self](boost::system::error_code ec, std::size_t /*length*/) { if (!ec &amp;&amp; read_msg_.decode_header()) { do_read_body(); } else { room_.leave(shared_from_this()); } }); Does the Async_Read read up to header_length then drops out, or does the Async quit after it receives w.e from the tcp stream? the docs don't say much lol 
The release notes state that MP11 is a new library, but its header files appear absent?!
Not directly related to discussion, but perhaps you would find it interesting to know there's a live compiler (much like godbolt or wandbox) that aims to make benchmarking and sharing results a bit easier. Check out http://quick-bench.com/
Thanks! I had only been thinking in CPU terms, having it have more meaning in GPU code could make sense. I guess we wait and see if it gets implemented in practice, or whether it will end up like atomic consume - theoretically sound but hard to implement and hard to use correctly.
Does this fix build with vs2017's /std:c++latest ?
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/6v5i6k/questions_on_tcp_asio/dlyiv8h/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Only PolyCollection and Stacktrace are new libraries. MP11 isn't even mentioned in the changelog. 
No, you'll have to manually remove inheritance to std::unique_function and ignore the compiler unknown warning. That being said it's easily done. Also there are related bugfixes available on GitHub for several boost libraries. Otherwise (once patched) you can totally use it or even compile boost with VS2017 even .3. with latest or C++17, I'm doing that in my project.
Or, for that matter, not generate warnings with MSVC 15.3.1?
So you're mad that it doesn't somehow fix bad code magically for you?
&gt; 217% difference on my machine by simply avoiding the copy of the vector. In C++11 (or newer) environments it is even marginally faster to disable RVO: &gt; This is due to Move Semantics, which is the subject of the next post. Doesn't a move always do the same or more work than an elided copy? You still have to call the constructor to create the object you are going to move to, right? I'd be curious to see the actual code you were benchmarking, but I don't see it provided on the link. 
make sure not to actually say what the heck it actually is anywhere in your wall-o-text.
Because co_ at the beginning of a keyword, having to have 'await' in your language at all....
From http://www.boost.org/doc/libs/develop/index.html: "The release includes 3 new libraries (Beast, Mp11, Sync) as well as updates to many existing libraries." I guess this is for the next release then.
Those will be new in 1.66; the 'develop' page's header just hasn't been updated yet. 1.65's release notes are here: http://www.boost.org/users/history/version_1_65_0.html
Ah ok, I had been tracking that develop page. So another 3 months before swapping out Boost.MPL for Boost.MP11.
For those who don't know what robin hood hashing is, this blog bost is well written: https://www.sebastiansylvan.com/post/robin-hood-hashing-should-be-your-default-hash-table-implementation/
After reading at lot of blog post, I got a question. Is there a reason why the gcc/clang/visual implementation still use the old implementation of unordered_map instead of something much more efficient like this one?
It strikes me how low priority VS 2017 is for everybody involved with Boost. That compiler warning has been there for ages (ok, it's not a biggie). But even worse the compile errors. VS 2017 Preview has been out for months, I'd even wager to say more than half a year from the top of my head, and nobody bothers to fix anything. This really leaves a sour aftertaste for the supposedly high quality of Boost libraries.
I've seen newcomers write `int* a, b;` in the full expectation that b is now a pointer to int, since the type is written as `int*`. I'm also not a big fan of putting things like 'ref' or 'ptr' in variable names. It's like Hungarian all over again.
90% of the time I'm modifying someone else's code (or my own that I wrote in the past), so I have no clue what foo is supposed to do/can do, and thanks to auto, I don't even know what foo is. I like auto in theory, I dislike it in practice. Large refactorings are way less common for me than reading random pieces of code, and anyway I find that people (including myself) tend to overestimate the time spent manually making repetitive changes because it's not something they want to do.
Made the switch this week, coming from visual studio code. The latter stopped having any autocomplete for me after the latest update, updates every month sound good unless you spend the first week of that month with a non-functional IDE. I didn't know before that QtCreator can work based on code files in a directory tree as opposed to getting information from cmake/qmake, it just works and it's easy to add rules for building and debugging. Superb experience, glad to be back.
It is on each library maintainer to fix warnings for their library, and until a compiler is up onto the regression test infrastructure, what isn't seen tends to not get fixed. This applies to libraries properly maintained of course. About half of them have insufficient maintenance.
Also, Stacktrace bends over backwards to not make the mistakes most other stacktrace libraries make. See the review manager reports (by me, incidentally) at: - http://lists.boost.org/boost-announce/2017/01/0486.php - https://lists.boost.org/boost-announce/2017/03/0496.php
&gt; So there’s no way of binding reference to NULL. lol int *p = 0; int &amp;i = *p; and voila, a reference bound to null. 
Anyone knows the performance penalty of using Stacktrace ? (cpu / memory usage)
My understanding is that the warning currently only appears with VS2017.3 which why released while this Boost version being released. So it's ok, it will come next version. Also the other issues only appear if you don't use the default VS settings, which is currently `/std=c++14`. In this case it's totally fine. 
Because the standard doesn't offer them much choice (even more with C++17 and the bucket interface). The main problems are iterator invalidation and the strong exception guarantee. The iterators are only invalidated on rehash and on delete (only for iterators to the deleted elements). The insert, rehash and erase operations also guarantee to leave the hash map in the same state as before the call if an exception happens (with support for move-only types that throw an exception). These conditions are similar to `std::map` which make `std::unordered_map` and `std::map` easily switchable. These conditions make open addressing implementations impossible to conform to the standard. On rehash, we have to move the values from one bucket array to another, what happen with move-only types with a move constructor that may throw? We can't have a defined behavior (for example the [`push_back`](http://en.cppreference.com/w/cpp/container/vector/push_back#Exceptions) of `std::vector` waives the strong exception guarantee with these kinds of types). Even worse with robin hood which put more constraints on the type of the values (nothrow swappable and nothrow move/copy constructible) Concerning the iterator invalidation, hopscotch hashing and robin hood have to move values around on insert (and delete for robin hood with backward shift deletion) making it impossible to not invalidate the iterators even without a rehash. Last point, open addressing doesn't do well with large objects difficult to copy/move around, while it doesn't matter for `std::unordered_map` which just have to move pointers to nodes around. In the end, chaining just work well for most cases on all operations (find, find miss, erase, rehash, ...) while open addressing can go badly wrong in some cases with a poor hash function. But it would be nice to have an open addressing hash map implementation in the std, separated from `std::unordered_map`.
Thanks, can be useful to tests structures part of the standard. But it doesn't seem easy to use if you want to benchmark external libraries (would need to copy the implementation beforehand).
But vim has youcompleteme.
&gt; RAII is a very idiomatic concept in C++ that takes advantage of the essential property of the stack (look up on your arm, or at the upper body of your spouse) Not a native English speaker; what does OP mean here? Is this some kind of joke? Minor nitpick on the rest of the content: instead of coming up with 'SmartPointer' it would imo be less confusing to just say 'one such smart pointer in the standard library is unique_ptr and here's what it's implementation looks like'
I don't think youcompleteme shows the type of auto variables though. Or does it nowadays?
Clang's lld linker no longer likes boost coroutine: ``` libboost_coroutine.a(stack_traits.o): relocations pointing to SHF_MERGE are not supported ``` (This is clang 4.0 on linux. 1.64 works with lld, and 1.65 works without lld).
&gt; Not a native English speaker; what does OP mean here? Is this some kind of joke? It's a reference to a previous part of the article: &gt; You can re-read this a couple of times, maybe tatoo it on your forearm if needed, and print out a T-shirt to your spouse reading this statement so that you can be reminded of it regularly.
Would it help if every class had a method that returns a tuple of references to all members?
I think the warnings have been there since the initial 2017 release but I'm not 100% certain. &gt; VS2017.3 which why released while this Boost version being released. Not really, the Preview has been available for months if not half a year or more. You have to see the implications of this: It means that nobody will be able to use Boost with VS 2017 with `/std:c++17` until the next Boost version is released (&gt;3 months)!
Indeed. As usual someone mentioned a boost. 1.65.1 release to be possible but usually it doesn't happen.
I've only recently seen examples of these reviews, they certainly boosted my opinion of boost. Excellent work.
How it came that Boost 1.65 does not support MSVC from VS 2017.3? It was released a week ago, but wasn't it enough to update Boost.Config? I mean, the last known and checked version is 19.10.25017. MSVC version from 15.3 update is 19.11.25506. Now we have to see the warning about unsupported compiler until December.
Compile with D_HAS_AUTO_PTR_ETC=1 and you should be fine
&gt; it's Minor nitpick - should be "its" in this case. [Helpful page for its/it's](http://www.its-not-its.info/).
Ha, got me there. I don't usually make this mistake but apparently when I do it's at the worst time imaginable :]
This: template &lt;typename T&gt; constexpr is_float = std::is_same&lt;T, float&gt;::value; is missing a type for `is_float`. Either `bool` or `auto` would work well. This problem reoccurs in the later sample: template &lt;typename T&gt; constexpr is_float = std::is_same&lt;T, float&gt;; You may want to also mention that VS2015 Update 2 and later support variable templates (Disclaimer: I'm a Microsoft employee.) 
Well with the recent improvements in the C++ STL boost has become way less important, so it doesn't surprise me that they might have less devs working on it. Plus the whole open source bias.
The Intel compiler supports it also in the new version: https://insidehpc.com/2017/05/parallel-stl/
Because "supporting" probably means more than "updating Boost.Config". Don't they need to do all kinds of testing?
&gt; The only additional thing commutativity buys us is the ability to combine them without caring what order the threads finish their chunks in Commutativity is also necessary to enable vectorization, since the code you want for `reduce` to come out as something like: vecRegister = load_contiguous(first); while (a vector register sized chunk is left) { first += packSize; vecRegister = add_packed(load_contiguous(first), vecRegister); } // combine vecRegister's packed components etc., which given ints and SSE registers and a * b * c * d * e * f * g * h gives something like (a * e) * (b * f) * (c * g) * (d * h). Most other languages aren't doing explicit things to make vectorizing their reduction possible. And nothing says we can't add a noncommutative_reduce or something like that in the future if someone comes up with a compelling use case. 
Page 27, when it's talking about the while and for loop, it misspells C++: &gt; By using modern C+, this can be transformed into something like this:
&gt; with a focus on runtime extensibility and compile-time type safety and clarity. The goal of ECS as far as I know is performance along with runtime extensibility. If performance is not a prime concern for this library, why ECS?
Performance is not a prime concern **for now**. Although there are other methods that allow for runtime extensibility, we found an ECS to be the clearest and most flexible. Although performance hasn't been the focus until now, we wanted to set up interfaces that would let us easily optimize the code later on.
&gt; It was released a week ago And had a preview version for many months.
Any speculation on the announcement?
Finally sensible Google C++ style guidelines?!
Hm, I am quite fond of static/automatic/dynamic storage classes as per the C standard. Stack/heap isn't it.
thanks for the hint! even if I use this code in production, it is still not final, you could want that is also works with wstring , than it should work with a version of `std::basic_string&lt;T&gt;` as wanted , means, one additional template parameter and `is_base_of` might be the right check. 
Other peoples' experience probably differs but I have actually never received training and I've really never seen it done very well if at all. Even interns often just get tossed in as a cheap labor force. Which I guess is appropriate since that's what the industry is like. So I'm very curious what sort of answers you get. As a senior dev of some years I feel I should be better at knowing how to train...but I've just always been thrown in the deep end, thrived...and so I've never really seen training or participated in it. I mentor and answer questions...but training? It's foreign to me.
`unique_ptr` has been invaluable in my Vulkan wrapper/rendering engine code: Vulkan can be pretty picky about the order in which resources are initialized, so `unique_ptr` gives me granular control of initialization order whilst taking care of any possible worries about memory leaks that being said, there are still cases where I do have to call `reset()` on the pointer, as resource destruction order is another thing Vulkan is picky about. 
I **strongly recommend** updating to VS 2017 15.3 (just released!) before attempting to use variable templates in production code. It contains fixes for many compiler bugs involving variable templates.
You don't need a webpage to learn the distinction – this isn't like affect/effect where both words can go either way. "It's" ~~always means "it is"~~ is always a contraction ("it is" or "it has"); "its" always means the possessive. End of story. 
&gt; "It's" always means "it is" Or "it has".
Fixed; thank you.
That rationale of why commutativity is needed makes a lot more sense! But shouldn't it be flipped? Vectorization is a very specific form of parallelism (I feel like even with commutativity the code still can't always be vectorized?). You would rather special case that with a "commutative_reduce" and fallback to core-level parallelism in the general case (which only requires associativity and being able to split up the data). 
I plan to compile a list of coding techniques / practices which can help improve the code (faster, safer, lesser bugs) with minimal time investment. Basically maximize the gain in minimum amout of time. Such a list can be useful for programming beginners and people trying to modernize their codebases. Using twitter so that the responses are concise and to the point, minimizing time ;) What I have now is pretty short, only 3 recommendations to be precise but I hope that there is a lot more we all can collectively document
At my current job it seems to be either: 1. You need too much training so we don't hire 2. You can fend for yourself and have people you tap on the shoulder when you need a hand, at this point you'll either get the minor guidance you need or a mentoring session to bring you up to speed
`co_` is a necessary evil, but what is the problem with `await`? What is a better alternative?
Great read as I'm just starting to learn cpp. Looking forward to part 2! 
Why, yes, it's doubleplusgood, that! Not even thinking about it, normally, but stands out like a sore thumb when something out of the ordinary is needed. Just like exceptions : that rare catch clause stands out like a sore thumb!
It's actually the same, heap is dynamic, stack is automatic and static is the same. The difference is that C++ adds better support for complex data types. A destructor is just a way to tell the compiler how to cleanup you data type, along with freeing the memory, something C only knows how to do for intrinsic (ints, floats, etc) types. It has very little to do with the fact that you allocate in the stack (automatic) or the heap (dynamic). And the "proof" is that you still have to call delete (the equivalent of free) on dynamic allocated stuff.
&gt; If you need to write a type traits, let's say is_float, here is how you would maybe do it in C++11: Writing a class that has a nested `::value` is not a type trait, as a type trait needs to be a `integral_constant`, which is why the second choice is more correct, which could be simplified, in this case, to: template &lt;typename T&gt; using is_float = std::is_same&lt;T, float&gt;; &gt; And then you would use your traits to do something specific based on that information. For instance with a very basic example: And that example can be written in C++11 as: template &lt;typename T&gt; void test(T t){ if (is_float&lt;T&gt;{}){ std::cout &lt;&lt; "I'm a float" &lt;&lt; std::endl; } else { std::cout &lt;&lt; "I'm not a float" &lt;&lt; std::endl; } } &gt; If we rewrite our is_float traits with variable templates, we have the following: Assuming you meant to write it as: template &lt;typename T&gt; constexpr auto is_float = std::is_same&lt;T, float&gt;::value; That does not simplify code. It may save two characters in the example above, but if we are writing a predicate(perhaps to filter a tuple): auto floats = filter(tup, [](auto x) { return is_float&lt;decltyp(x)&gt;{}; }); Using your variable template, it would need to be written as: auto floats = filter(tup, [](auto x) { return std::integral_constant&lt;bool, is_float&lt;decltype(x)&gt;&gt;{}; }); &gt; No more ::value everywhere The `::value` wasn't necessary in the first place, however, the `std::integral_constant` will be necessary in some places as you stripped off the type information. Its much better to write the variable template as: template &lt;typename T&gt; constexpr auto is_float = std::is_same&lt;T, float&gt;{}; And then the predicate would be written as: auto floats = filter(tup, [](auto x) { return is_float&lt;decltype(x)&gt;; }); And your original example as: template &lt;typename T&gt; void test(T t){ if (is_float&lt;T&gt;){ std::cout &lt;&lt; "I'm a float" &lt;&lt; std::endl; } else { std::cout &lt;&lt; "I'm not a float" &lt;&lt; std::endl; } } 
I tried that, I believe when I did that there were other errors popping up, so I gave up.
What's "the whole open source bias"?
Check the CPPCoreGuidelines. It will save you the bother. 
Naturally people who work on open source code prefer open source platforms. Windows support consistently lags behind Linux in these projects. (Not really a positive or negative phenomenon, just one that makes sense.)
For simple things like for_each and fill in parallel I am finding that somewhere between 100,000-&gt;1,000,000 and for for_each, doing just a simple mod operation it was between 10,000 -&gt; 100,000 doubles. This is with a simple task queue for each core(4 with i7-7500U 2 full/2hyper) with stealing and the queues are ready to go when a task is added. But this is also threading and I am sure I f'd up somewhere. 
thanks for the benchmarks!
In the first code example, `a`, depending on the calling convention, may be stored in a register instead of the stack. This should be noted :)
OP, see https://github.com/isocpp/CppCoreGuidelines/blob/master/CppCoreGuidelines.md.
Speculation follows because it is fun. The way Google's system works (based on presentations given) is that you can find all usages of any function and atomically change every one of them at the same time as the implementation. What if this could be done over all code bases. If you trawl all of Github (and all the other places code is hosted) and have a massive farm of hardware, you could detect all (public) usages of any code. Thus you could create an automated machine that files a PR on every repo in to world at the same time as you change the code. This could work, I guess, but it does not scale at all. There are tons of repos that do not live on the edge and where simply getting a PR merged takes a long time. So that can't really be it. But there is a different way. Suppose you write a clang-rewriter (or whatever it was) rule that does the change to any code base. Then you feed them to the compiler on every compilation. Thus it would automatically update every old usage of the code into the new one transparently. This is not without its share of problems. As an example you'd need to be able to tell which version any random project is coded against to be able to tell whether you need to apply updates from version X to head or from Y to head. It can be done with a bit of opt-in metadata in each repo (or parsing autoconf checks, but let's not go there) but then the problem is how to get projects to have that info. But if you do have that (or can fake it), it could work. Maybe.
I haven't kept up with the Google C++ guidelines the last ~2 years. I know that they weren't great 5 years ago or so but have improved a lot. Can anybody who has kept up with them, summarize what they think the major remaining pain points are? Either things that are overly restrictive, or disagree with the standard library/core guidelines style (please don't mention naming conventions, whitespace, etc). Also things that have very recently improved.
Smart developers use statics, stack, and `std::vector`
Point them at any operational documentation required to get them set up, then point them at some easy bugs and let them go ham. Code reviews make sure the code they come up with is sane and that they understand the subsystems they're working in.
From memory: - do not use exceptions - from that: do not use constructors that can fail but instead have an init method that you must call manually and check errors on that manually The latter is especially nasty because it means that such classes must be able to represent an invalid state. Exceptions in constructors means that only valid objects may be constructed.
Hrmm, I wrote something similar for allowing the creation and sharing of types between C++ and JavaScript. Basically you create primitive types in C++ but then you can override virtual methods in javascript to create new derived types. if I get some time maybe I"ll look and see what you did and see if I can apply any of it.
Which is not as terrible as it sounds once you consider factory functions, which can return either-a-constructed-object-or-a-notion-of-failure. This is quite ubiquitous. Partially constructed classes (with the weird invariants that follow from them) are frowned upon, both in and outside of Google. :)
Mmm, works fine for me. Not using all the libraries of course. So might not work for all of them. 
I wonder how GCC's IR compares to LLVM's when it comes to usability, e.g. which would be easiest to target, ignoring documentation.
&gt; Which is not as terrible as it sounds once you consider factory functions, which can return either-a-constructed-object-or-a-notion-of-failure. Sure, but all of those have their own limitations. If you return an `optional&lt;ClassName&gt;` then the return value of the function is larger than just returning `ClassName` and you need to do one extra move. If you return a (smart) pointer, then the classes can not live on the stack which means an extra memory allocation per instantiation. Sadly, everything is a tradeoff. :(
I agree that the best alternative to exceptions (or better than exceptions flat out in some cases) is a *private* constructor and init function, and a public static `make` function that returns an `optional` or similar. But this doesn't seem to be what Google advocates.
The author is trying too hard to be funny.
Thanks. Its clear to me now.
No training so far. Just throw me in and help when they see I need it or I ask for it. They recommend books to read on my own time but there is no training for it. I've been told the code reviews will be brutal (in a constructive way) and that's how it'll go. 
Does Google have a C++ coding guideline? I know about the [Google C++ Style Guide](https://google.github.io/styleguide/cppguide.html), but that's a style guide, not a coding standard. And I know that Chrome has a coding standard for code inside of Chrome, but that's app-specific, not Google-general. Rules like "don't use exceptions" might make sense in a specific situation (like coding in Chrome) but not as a fundamental deletion from the language. Also, [Titus Winters has offered his insight](https://github.com/isocpp/CppCoreGuidelines/issues?utf8=%E2%9C%93&amp;q=is%3Aissue%20author%3Atituswinters%20) on the [C++ Core Guidelines](https://github.com/isocpp/CppCoreGuidelines). I don't see Google going off and creating a new C++ guideline. It should be an exciting announcement though!
I'm not sure by what measure it's a style guide (a rose by any name) and not a coding standard. It goes far beyond naming conventions and whitespace. Banning exceptions or certain kinds of multiple inheritance are not matters of "style", but definitely a standard, for any reasonable definition I can think of.
I don't remember all too well, but it does complete auto typed variables without problems.
&gt;co_ is a necessary evil No, it certainly is not. Even in other languages with this misfeature of `await`, it isn't necessary, and it isn't necessary here. At the worst you could make it `_Await` and put a macro in `&lt;await.h&gt;`... &gt;but what is the problem with await? What is a better alternative? What is not a problem with it? Do you enjoy annotating every single function call with an ugly keyword when you could just.. not do that? I don't want to annotate everywhere in my programme that I *don't* introduce parallelism, I want to annotate everywhere in my programme that I *do* introduce parallelism. With threads, everything is implicitly sequential and you have to be very explicit when you want to not be sequential. That's the right way of doing things. We already have threads. This silly way of doing things means we'll need to reimplement all the library functions ever written that take callbacks to create a new version of each `f` called `async_f` that calls its callback with `co_await`, for example. These problems were all covered in Chris Kohlhoff's paper. That you haven't read it is incredibly concerning.
I wrote a tool like this a few months back and have been working to clean it up to put up on GitHub. Hope to have it up in the next couple weeks. Awesome effort here though!
With a mod operation that wouldn't surprise me for more cores to be faster -- divisions and mods are fairly expensive and there are a limited number of divider units available to each core. That's why we *are* parallelizing `for_each`.
&gt; Vectorization is a very specific form of parallelism Not to the interface exposed by the parallel algorithms. The only difference is that vectorizing has essentially zero overhead while threads have comparatively extreme overhead. &gt; You would rather special case that with a "commutative_reduce" I disagree. I think as the parallelizable version of accumulate that lives in `&lt;numeric&gt;` this thing needs to be easy to map onto vector hardware.
Smart developers know when, where, and why use smart pointers. Stupid developers just use them.
This is very helpful. Thanks!
I absolutely love Boost, but nowadays there is a lot of duplication between Boost and the standard. What I would like to see is that functionality that migrates into the standard, also migrates out of Boost - because having so much duplicated functionality is just not a good thing to have. It wouldn't be too much of a stretch to believe that libraries that have a large degree of duplication with the standard (or, in other words, that now mostly exist as a way to hack newer C++ features into older compilers) are also the least likely to see maintenance (after all, those older compilers aren't changing anymore). Trimming duplicated functionality should therefore also reduce any problems in this area. 
Attn. anyone using VS2017 (or 2015): For some years I've maintained a set of Boost sources for personal projects that now has ~40 patches applied, the majority of which are MSVC-centric (a couple affect Clang and others are plain bug fixes). General changes: - C++17-related fixes (`auto_ptr`, `unary_`/`binary_function`, etc.): Algorithm (C++14 `equal`), Functional (hash), Hana, NumericConversion - MSVC workarounds added/removed (mostly removed, as MSVC has evolved to become more compliant): Align, Serialization (Archive), Format, PolyCollection, Pool, Proto, TypeErasure, ScopeExit, TypeIndex - General bug fixes: Algorithm (string), Asio, Chrono, Container, Context, Coroutine, Coroutine2, DateTime, Detail.WinAPI, Fiber, Filesystem, Process, Range, SmartPtr, Spirit, Stacktrace, System, Thread, UUID (`random_generator` overhaul) - Applied MSVC's opt-in EBO ([`__declspec(empty_bases)`](https://blogs.msdn.microsoft.com/vcblog/2016/03/30/optimizing-the-layout-of-empty-base-classes-in-vs2015-update-2-3/)) to some types I've encountered that benefit (definitely _**not**_ exhaustive) - Config - `BOOST_NO_CXX11_SFINAE_EXPR`, `BOOST_NO_CXX14_CONSTEXPR` are _**not**_ defined for VS2017.3; these two changes are experimental and may cause problems (I haven't encountered any) - Fixed incorrect logic re: detecting C++17 mode for MSVC compiler and Dinkumware stdlib headers - Abstraction for aforementioned EBO support - Boost.Build: fixed some 64-bit issues, cherry-picked some changes from 'develop' - Additions - [Boost.MP11](http://www.boost.org/doc/libs/develop/libs/mp11/doc/html/mp11.html), current ~~'master'~~ 'develop' - Boost.Range: 'move' algorithms/adaptors Links: - [Diff excluding 'additions' listed above](https://gist.github.com/dodheim/ea55e6e25e2f2db96e68273112f89144) - [Diff including 'additions' listed above](https://gist.github.com/dodheim/aeafdb2680bf1de575db42857675bb1c) - [7z archive (CRLF line-endings) with patches pre-applied](https://www.dropbox.com/s/ghrzhmaz0yvc50f/boost_1_65_0_dod.7z?dl=0) This is entirely unsupported and unofficial, but if you want to make the most of Boost with bleeding-edge MSVC then these patches might help you out. (cc /u/doom_Oo7 and /u/sumo952 in particular, whose questions prompted me to package all this up) EDIT: Updated to use MP11 'develop' (which contains relevant MSVC changes), Config 'develop', and Spirit 'develop' EDIT2: Updated to use current 'master's for Process and Thread EDIT3: Updated to use current 'master's for DateTime and SmartPtr
That's true but that doesn't make it easy to remember. Normally 's is used for both contractions and possessive. The web page provided a couple of mnemonic devices to help people remember which is which.
Don't get me wrong, I think the vectorization stuff is great and I am not arguing against it. Like you said, it's easy to support both and select the appropriate algorithm depending on what properties the operator has. My main gripe is with how things are named. `std::accumulate` is a non-standard name for what's better known as fold or reduce in other languages (which is not C++'s fault since the canonical terms were still in flux back then). But now that we are introducing a `reduce`, why continue this trend of nonstandard definitions and not match what everyone else is calling a parallel reduce? This being in &lt;numeric&gt; is a great reason to focus on the numeric processing use case (even though functional programmers will use it for a lot more than that). But to redefine the well-established requirements of reduce just to fit the numeric use case *is* backwards to me.
Does this guide ban exceptions? I didn't realize that. I've not read through all of this one. It at least starts out as a style guide. 
I have to assume LLVM is. I mean its IR and its design of it being used as a library, etc would probably make it easier than gcc. Which (unfortunately IMO, llvm isn't gpl'd), gcc, made stupid decisions out of fear that proprietary compilers using gcc would become very common. valid but unfortunately I think that sacrificing technical capability for a ideological reason is stupid in 99.99 percent of cases. i am thankful for llvm as it kicked both gcc and vc++ into shape. sorry for going on a tangent lmao 
I participated in C++ training when I wasn't on a C++ product. Didn't retain a single bit of it. When I left my last job, my feedback on that matter was that they should survey the department several times a year and get feedback on what sort of training individuals would like. Then perhaps they could get targeted classes for smaller groups or find a few interested in going to conferences and report back. But tossing everyone from fresh college grads on Python projects to grizzled driver devs into an intro to C++ class was a waste of money.
Still an improvement on what stupid developers did before.
Thanks! I will have a look
I've long called for a Boost 2.0 which consists only of the "new", well maintained libraries. But the community isn't there on that, so it remains as it is today. BTW libraries duplicating the standard often see *more* maintenance than other libraries because very often it was the Boost library maintainer who got that library into the standard in the first place, something which takes years of effort, so they tend to be of the type of personality who commits for the long term. Also, core libraries like that tend to be dependencies of other libraries, so they get a lot more attention. If a Boost library is not a dependency of lots of other Boost libraries, that's where the real problems with maintenance tend to creep in eventually.
I don't code much in cpp, when would it be desirable *not* to use them?
Hehe, I do understand that perfectly: it's their baby, and they are not about to throw all that beautiful code away that they spent so much of their life on. But at the same time, your kids do grow up and leave the house and start living their own life... And sometimes it is ok to lean back, and enjoy the feeling of a job well done and a great service rendered to the community as a whole. And I wouldn't necessarily call it Boost 2.0. I'd call it Boost17 - which will in due time be followed by Boost2x. 
In `Timer.h`, why are `m_expirationTime` and `m_elaspedTime` `float`s? What is the actual interval for each timer? Seconds? Milliseconds? Nanoseconds? I think a better type to use would be an unsigned integer of some bit length depending on your needs (64 bit for extended periods). You can use milliseconds for more precision but it's not likely needed for your particular use case. Even though you're just inc/decrementing the numbers, they still get run through the floating point processor (more expensive). You may want to take a look at [std::chrono](http://en.cppreference.com/w/cpp/chrono) though I'm unfamiliar with the performance impact you may incur vs just using integers. Since your system already has a clock you can save on inc/decrementing and instead get the clock and test whether it has passed a threshold. Edit: You may also want to lock down your types as types like `float` and `int` have different sizes on different systems.
That dereferences NULL, though; isn't that UB at the moment you write `*p`?
There is none... which seems like a problem. New developers are pointed at the source tree and told to run. This isn't helped by the fact that the most recent documentation is about five years old... better make friends on slack!
I've found that even when large companies invest greatly in their intern programs, the generic new hires with a little work experience (0-5 years) are left to fend for themselves. It's as if that segment is too old for the intern fanfare but too young to really have a crystal clear idea of what they want to accomplish in their career at BigCo.
Most of the time a reference is better. 
Same experience here. Also curious. To add, I had to separate good practices from the bad, and fight the latter.
If there's a language where code reviews need to be brutal, yeah, C++ it is.
Welp, I didn't realize that it wasn't showing signs of life! I hear from Kenny a couple three times a week. And the GitHub repo seems to be reasonably active for a project of its size. [Heck, there's even an Issue entered about how responsive the team is](https://github.com/Microsoft/cppwinrt/issues/228)! When you're working at a place the size of Microsoft it's always hard to judge the line between being informative and carpetbombing with thinly-veiled advertising. I think we try to stay far on the cautious side of the equation--at least the C++ team does. That caution means if you want to know what we're doing any more than what we're broadcasting, you'll just have to ask. No worries--the worst we can do is keep quiet :) 
That's not an uncommon idiom in google code. Even so, it doesn't play nice with inheriting and/or delegating constructors (you have to write boilerplate).
You're absolutely right, it was fixed last night. I mentioned VS now, thanks. I'm so used to my libraries not being able to compile on Windows, that I have a tendency to forget it :s
Nitpick: `except&lt;T&gt;`
Hi. I disagree that all type traits need to be integral_constant. Yes, in the STL they are, but the concept of type traits is more general than the STL. There are advantages of using integral_constant of course, but I believe that if you don't use anything else than the value member (or the varaible itself), a type traits does not need to be integral_constant and maybe, should not be integral_constant. In my opinion, type traits is simply a very general concept that allows to get compile-time information regarding a type. Nothing more, nothing less. The way to implement is then totally open. 
Thanks.
If you base your work strongly upon polymorphism, references are often no option.
as far as I can tell that doesn't do nearly the same thing. static_print allows for template&lt;typename T, int s&gt; struct test { static_print("The template ", ::test, " has been instantiated as ", test, ". By the way, s + 1 is ", s + 1); }; int main() { test&lt;int, 3&gt; y; return 0; } Resulting in: &gt; The template test has been instantiated as test&lt;int, 3&gt;. By the way, s + 1 is 4
Did you happen to take a look at Clang?
When whatever you are doing does not involve free store object creation and destruction. You don't need a smart pointer to examine or modify an existing object if you don't mess with its lifetime.
yeah, this doesn't add up (maybe an issue with a benchmark).
Still better than raw pointers!
I am the author of [ODB](http://codesynthesis.com/products/odb/) so I am biased, but: auto storage = make_storage("db.sqlite", make_table("users", make_column("id", &amp;User::id, autoincrement(), primary_key()), make_column("first_name", &amp;User::firstName), make_column("last_name", &amp;User::lastName), make_column("birth_date", &amp;User::birthDate), make_column("image_url", &amp;User::imageUrl), make_column("type_id", &amp;User::typeId)), make_table("user_types", make_column("id", &amp;UserType::id, autoincrement(), primary_key()), make_column("name", &amp;UserType::name, default_value("name_placeholder")))); &gt; Too easy isn't it? No, I find this tedious and error prone. If you change your schema or class and forget to manually update the mapping, it is a runtime error. // SELECT * FROM users WHERE id &lt; 10 auto idLesserThan10 = storage.get_all&lt;User&gt;(where(lesser_than(&amp;User::id, 10))); auto cuteConditions = storage.get_all&lt;User&gt;(where((is_equal(&amp;User::firstName, "John") or is_equal(&amp;User::firstName, "Alex")) and is_equal(&amp;User::id, 4))); &gt; No raw string queries Uh, I would rather use raw strings than an interface like this. For comparison, here is what these queries look like in ODB: using UserQuery = odb::query&lt;User&gt;; auto r1 = db.query&lt;User&gt; (UserQuery::id &lt; 10); auto r2 = db.query&lt;User&gt; ((UserQuery::firstName == "John" || UserQuery::firstName == "Alex") &amp;&amp; UserQuery::id == 4); 
nice, thanks! 
&gt; though I'm unfamiliar with the performance impact you may incur vs just using integers. std::chrono::duration == int64_t. There is an overhead in debug mode, but in release mode it's the same.
glad to hear that because otherwise I was running on some pretty incorrect assumptions.. but ones that made a lot of sense, so I didn't want to give them up. This is much closer to what I expected (admittedly it's a worst-case type for move semantics): http://quick-bench.com/3X3yQ958YQtPZlumsH9Pa7ANqho
It supports only SQLite - that said, it could be fine for a project based upon it; but business applications need a database with network and multiuser support in general. Perhaps it's just a start and more databases will be supported?
I feel like the focus on smart pointers w.r.t. memory management is a bit misleading. Articles about how memory management is done in C++ should talk about containers, too. Smart pointers are not the only example of RAII. Plus, if you're going to show a `SmartPointer` implementation make sure that it does not violate the rule of three! This is why we can't have nice things! (But yeah, it's a bit of a shame that in 2017 C++ compilers still won't warn about the use of implicitly declared and compiler-generated copy operations in case the user wrote their own destructor. It's deprecated since 2011 for f's sake. What good is the deprecation of a "feature" if no compiler warns about its use?)
We do [Dailies](https://www.fluentcpp.com/2017/04/04/the-dailies-a-new-way-to-learn-at-work/) to pass knowledge around the company. It's motivating and we've seen a impact on the quality of the codebase.
Is ODB able to generate C++ classes from an existing database?
Raw pointers are great. Just don't use them for ownership.
No, at least not yet. We get this request periodically but this is a very hairy problem since there are thousands of different ways to map a set of tables to a set of C++ classes. And I am not talking about simple things like which string type or smart pointer to use but rather which tables are classes, which are containers, and which a relationships, etc. ODB can generate a (very canonical) database schema from your C++ classes though and this seems to be what the majority of users want.
Why? I though that the only two things a reference cannot do were re-assignation to another object (so no swap, …), and be assignation to nullptr. I don't see were polymorphism can't be used with references.
&gt;You may also want to lock down your types as types like float and int have different sizes on different systems. Formally that's correct, but I don't think support for ancient or exotic systems is really going to be an issue in a my-first-game type scenario. Let's keep some perspective here: there is absolutely nothing out there that this code could run on that doesn't have 32-bit, IEEE-754 floats, and the odds of running on a system where int is anything other than a two's complement, 32-bit integer are also vanishingly small. Besides, there is no way to get it 'right', is there? Either you go with fundamental types like int, and are thus forced to work with whatever size they have, or you go with fixed-size types like int32_t, and get to deal with the possibility that a target architecture might not support them (not that that is ever going to happen, but in a formal sense it is a possibility). And typedef'ing your own type to mean 'int32_t' doesn't rescue you from that: if the type exists you might as well have used int32_t, and if it doesn't there is no way to define it yourself and any porting effort would still have to go to a wider type - which is what you would have gotten if you had used int to begin with. 
Most of the time a reference cannot replace a smart pointer.
If the smart pointer was used for a good reason, sure; but the point the GP was making was that naive devs might, eh, _overuse_ use smart pointers a bit...
Visual Studio has been completely free for these kinds of projects for several years now ("VS Community Edition" - not the old Express!). Yes I know, "free" is not equal to open source. But with regards to VS, there's not much that bothers me by not having the source. And the general IDE experience and especially the debugging experience makes you so incredibly productive. FWIW "Linux" lags behind in many things as well, Ubuntu 14.04 (LTS), which still many people use, has what as default compiler, gcc-4.8 I believe? And 16.04 (LTS) now has gcc-5 if I am not mistaken. Better than 4.x, but still. So: I'm really not sure whether &gt; people who work on open source code prefer open source platforms is true. I, at the very least, choose the best tool for the job. And that's often VS.
Wow, really cool! Awesome of you to share this. I wonder whether any boost developer or maintainer will pick up these patches. My past experience unfortunately leads me to the negative view that none of these or only a small subset will make their way into a 1.65.1 or 1.66.0. Maybe what Boost needs is a paid part-time position for someone that does exactly stuff like this.
The standard says dereferencing a null pointer is undefined behaviour, but the reality is that *p forms an expression without side effects and thus it is not actually dereferencing anything. It is only when evaluating *p that the dereferencing happens. In practice, I haven't seen any compiler, even embedded ones, do anything about *p when p is null, which means that, in practice, null references are possible. 
If you just pass an (polymorphic) object around as parameter, then you can use references. But if you want to use it as field within another object, you must use some sort of pointer. Just imagine some kind of *dynamic* strategy, that you wanna provide into another object. As composition arises often, it is typical use case for business logic. It depends, what you are doing in C++ I think.
Nice project with a potential however in terms of usability and ease of use it's not there yet for me. I recommend to take a look at 2 interesting projects in this area - [gigabase](http://www.garret.ru/gigabase.html) and [sqlpp11](https://github.com/rbock/sqlpp11). In short gigabase is easier to use, adds more type safety and comes with some important features not found in your library (like unlimited structuring of table columns, R-tree). But it's actually the whole local db engine so it's not compatible with SQLite. Sqlpp11 is closer to what you are doing but it offers creating type safe expression trees which also read easier then your query expressions and independence on underlying database. 
With smart pointers I have gone through four phases so far: 1. I moved to smart pointers and picked up std::shared_ptr because it matched how I thought about pointers. I was not really ready to think hard about all the ownership rules and all that. Eventually I got there and I started to think as hard about ownership as much as I cared about memory leaks and exception safety. 2. I changed my code to std::unique_ptr and if in rare cases I needed to allow others access to the pointer for some reason I passed it as a raw pointer. Then I had a few cases at work where people did what they thought were right and stored this raw pointer, then other developer decided to delete it and then I changed my methods. 3. My third try at this I wrapped the raw pointer output from std::unique_ptr in an observer_ptr/guard_ptr that allowed access to the object as normal but prevented deletion without some serious work to circumvent it (not impossible but almost any review would catch it). Then I finally read about reference_wrapper and the methods around them especially combined with rvalue references. 4. Now I only rarely use pointers at all and I try to make it so that if I pass stuff around I use references and std::reference_wrapper instead of my observer_ptr or any other pointers. Ownership and deallocation is handled by the smart pointer and the move to "almost always references" has made my code much safer. Is my code better for it? I don't know but I think that from a safety stand-point it is better and seems more readable (it also seems to confuse IDEs less). Smart pointers are a very good idea, but less pointers including smart pointers in my APIs has made them safer and fairly clear to read for both people and IDEs.
Yeah I'm fine with it. Would I like some formal training? Of course am I happy to get my code combed over is by line to improve my practices? Of course. 
Does this mean I won't have to use wacky C++ CX/WinRT to launch an app on UWP? If so, I'm looking forward to it! Having a mishmash of non-C++ code on top of a C++ project feels a bit dirty.
That is already the case if you don't need to odr-use the variable. This compiles: #include &lt;cstdio&gt; int main() { constexpr auto i = 0; constexpr auto f = [] { constexpr auto x = [] { return i; }; return x(); }; std::printf("%d", f()); } 
I am the author of [QxOrm/QxEntityEditor](https://www.qxorm.com/) : if you want to create automatically C++ classes from an existing database, you could try [QxEntityEditor](https://www.qxorm.com/qxorm_en/manual_qxee.html). This is based on Qt, but QxEntityEditor is flexible enough to generate what you want with an embedded [Javascript engine](https://www.qxorm.com/qxorm_en/manual_qxee.html#js_engine) to customize your generated C++ classes.
This looks like using deduction guides as a pseudo-concept. If we approach it like that, we could imagine passing a set of concepts to expect onstead of a single type and implicitly having the concept of convertible-to that type. If `converts_to&lt;T&gt;` is a concept, then `expect&lt;converts_to&lt;T&gt;&gt;::e` would be the "newfangled" `expect&lt;T&gt;::e`. Overly verbose I admit, but suddenly we can do more, like expect&lt;inc, stream_out, add&lt;int&gt;&gt;::e x=some_function(); where we expect `x` to support those operations. 
I trained some people at my old job. I had one come in with little to no programming experience. First week he just followed some web-courses. Can't remember which ones. Second week, we tossed him in the deep end. We gave him some tasks we needed done. I then sat next to him and described the task. I gave him a concrete example and then some pseudo-code. When he was done coding that, I sat down with him again and let him walk me through his code. Then I suggested refactorings. He then did them and we went through his code again. The idea is that people much better from actual tasks. So if you have a part of a project which isn't time critical and isn't too big, it could be used for teaching.
And nice it is. Do you think it's feasible in principle in the ORM arena to move from generated code to a nongenerated library using a present or future form of C++ reflectivity or other language extension? 
In case you are still looking for more examples or references: I have some notes/example_code/references in https://github.com/BartVandewoestyne/Cpp/blob/master/examples/C%2B%2B11/return_value_optimization.cpp (haven't checked this in a while though...)
You get the error because lambdas were previously not allowed to be `constexpr`. (I believe GCC's error message is quite clear.) This changed in C++17. [See on SO](https://stackoverflow.com/questions/6420085/is-constexpr-supported-with-lambda-functions-expressions#6420127)
That's true, but init functions just don't play well with anything. You have to deal with the pre-initialized state, and it can mess up the order of constructor/destruction of objects that may depend on each other. 2 stage initialization is horrible. But all this is exactly why the best solution in most cases is to use exceptions, and why it's so painful that Google does allow them.
&gt; This looks like using deduction guides as a pseudo-concept. You are correct. If we have deduction for alias templates similar to what we have for class templates, then we can implement the "type supports operations" part of concepts using alias templates with the same syntax as concepts. The `iterator` and `range` alias templates in the blog post are examples.
I was specifically talking about pointers to unmanaged resources. If you're using pointers to pass around or manipulate temporary objects then that's fine, but you can often use containers and/or references instead
Do you still have to use the Windows Store or install certs and use powershell to use WinRT?
In the standard, a type trait is [defined as](http://eel.is/c++draft/meta.rqmts) a class template that derives from integral_constant.
Someone cares to elaborate ? I'm pretty lost with all the different APIs ... Is this just header files to use C++ within Metro apps ? I also remember reading things about C++/CX a few days ago (was looking at UWP programming), is it the same thing or .. ?
Which may have well been the case imho. Nowadays we live in a world where companies have figured out oss is better when it comes to their internal tooling, but you need only look at how the environments for languages as old as C(because gcc is older than Cpp I believe) to see how much proprietary tooling they have/had compared to C/Cpp (or rather, what the proportion of proprietary vs oss was). But the C++ environment has a lot of proprietary tooling, the amount of which would have been much greater where it not for gcc's gpl licensing. Among other things you can thank it for not having to use proprietary IDE's and profilers like the Java guys. The problem with proprietary tooling is that it will cover x% of the market and only y% will work towards oss tooling, if proprietary tooling is harder to make (e.g. because the best compiler is under gpl) than the y% increases.
I think dynamic introspection is still too limited in C++, but maybe I'm wrong. For example, the [Verdigris project](https://woboq.com/blog/verdigris-qt-without-moc.html) which is an impressive header-only library to replace the Qt moc process (so no file generation, just new C++ features). But you still have to register yourself all classes/properties in some way.
Boost approximately achieves one breaking change every five years. In 2012 that was the git migration. In 2017/2018 it'll be the cmake migration. So, if the pattern holds, the next window for what you want will be around 2022.
Last time I checked using XAML and developing components that are expected to be consumed was a big no with it, making C++/CX still the better option.
&gt;Coming from a C background, we all know the &amp; op means pass by reference when passing arguments to a function. Well, in C++, it does even more. &amp; takes the address of something which is a pointer right? (which is pass by value, where your value is a pointer). AFAIK C doesn't have any concept of pass by reference
I think you're right; in this scenario overly specified types are overkill. However, there are other options besides locking them down to specific bit-widths such as `uint_fast32_t` and `uint_least32_t`. It can be helpful to use these types it indicate your intention.
In the company I currently work for, we don't really give "training" to newcomers, rather we start with doing pair programming. This means the new programmer puts the hands on the code almost from the day 0, supported/supervised by a senior/experienced member of the team. Rules, tools, libraries and other things to know are explained the first week. We try letting the newcomer work on her own as soon as possible, generally on a small task of a bigger project, code reviewing the job day by day. Since we work in a niche, some of us developed particular skills that newcomers cannot be endowed with (or it happens quite rarely). The risk of reinventing the wheel is high, for this reason we cannot hire people demanding to work in complete autonomy from the first week. From the mere technology point of view, in our industry it's very important to hire people who know well at least one or two main technologies that we employ. "Knowing well" depends on the position we try to fill. For example, it's very unlikely for us to hire an experienced C++ developer who completely ignores C++11. Clearly, exceptions exist, but generally we tend to hire people already skilled on some key technologies that we daily use. About training/learning in general, our software teams have some budget for books, online courses and conferences. We don't have rules and the budget is not public, we just ask and, in the best case, we get it.
This is native C++ binding to the WinRT &gt; I also remember reading things about C++/CX a few days ago (was looking at UWP programming), is it the same thing or .. ? Or... No .NET, no CLR, down to metal C++
Until very recently Microsoft products were only designed for deployment to Microsoft platforms. I'm sure this was a huge limit to adoption. 
I think of this more as a (benign) fork than a breaking change, and just to be clear: I'm not saying the duplicate code needs to be eradicated from the internet. There is definitely still a role for that for people with older compilers. However, that should not also imply that people with modern compilers must also use Boost-style smartpointers, lambdas, move-emulation, regular expressions, optional, and whatever else is in there that is now also in C++17.
Maybe, but would you seriously use types like `uint_least32_t` for what is, at this time, a purely theoretical benefit? I suppose we should be glad it is 'only' 14 characters, given that the language also gave us `std::unordered_map&lt;std::string, std::string&gt;::const_reverse_iterator`, but still... 
You're reading my mind here! One big problem we can see by reading these comments is that good looking documentation is presumed to be good documentation. The major problem with most documentation is structure, content, too much irrelevant material and missing required material. Addressing this will make the job of writing documentation easier - not harder - and will provide something that is more helpful to users. It seems like an unglamorous, tedious afterthought. But it's not! I fear that not enough of the people who would benefit from this will attend. Hopefully I'm wrong.
The process I proposed was that a v2.0 structure be created which could support libraries existing in both the v1.x and the v2.x collections. The v2.x structure would fix many of the problems in the v1.x structure (for a list, search boost-dev, but essentially C++ 14 would always be turned on and C++ Modules and cmake used throughout) and it would provide a migration path for those library maintainers on a time schedule which suited them. But as I said, there isn't support for that. There wasn't even consensus on cmake, the SC had to enforce a decision, and there remain very significant question marks over when any cmake migration might be completed. It certainly won't be in 2017 anyway, and even 2018 looks unlikely. It's easy to migrate 80% of Boost to cmake, but that 20% will be very painful with lots of unpopular decisions required same as with the git migration. As someone who helped out with the git migration and received some of the blowback from that, I feel for those doing the cmake migration. I definitely won't be contributing to that personally, too much pain.
The Coroutines TS has seen lots of changes at WG21 recently. Backporting those changes into the compiler is disruptive and will take time. Also, the MSVC compiler is now much more aggressive at optimisation. So no wonder that there has been instability. In the end, you should not rely in any way on experimental features, especially not in any code you might use for a serious purpose. Even in AFIO, which I don't expect to be ready for anyone to use until 2019, I haven't enabled the Coroutines TS support in it because I don't want anyone using AFIO with Coroutines until clang lands its support for them, and AFIO is an *alpha* quality library. So be conservative, and patient!
Very nice! However, your indentation scheme needs to take a chill pill. It nearly ruins your "too easy" example. EDIT #4000 (now properly formatted): using namespace sqlite_orm; auto storage = make_storage( "db.sqlite", make_table("users", make_column("id", &amp;User::id, autoincrement(), primary_key()), make_column("first_name", &amp;User::firstName), make_column("last_name", &amp;User::lastName), make_column("birth_date", &amp;User::birthDate), make_column("image_url", &amp;User::imageUrl), make_column("type_id", &amp;User::typeId)), make_table("user_types", make_column("id", &amp;UserType::id, autoincrement(), primary_key()), make_column("name", &amp;UserType::name, default_value("name_placeholder")) ) ); 
"At 42, they ask us to declare every variable we want to use at the top of the function. I think it really helps to know all the variables that are going to be used later so that you can already guess the logic behind the function." This is really really bad advice in C++ (and indeed most modern languages). It is a hold over from days when it was considered good style for a function to have a single point of exit. In C++, introduce variables just before they are used - ideally at the point they are assigned a value. It's not so important with basic types, but as you start to use instances of classes - bear in mind that destruction occurs in reverse order of construction, and RAII works best with this discipline. It also avoids all use-before-initialise bugs, and can be hard bugs to find in production code.
I couldn't find any information online about TTD with C++ Can anybody point me out to a name of a book, application or website?
Hey /u/zturner_ , First of all, thank you and the team for your hard work. I just tried to use lld at work on our project, but ran into an issue. Whenever the build system comes to the link of our executable, it fails with the following error: `error : Type server PDB was not found: Unable to load PDB. Make sure the file exists and is readable.`. I can see that it produced `MyExe.exe.tmpxxxxxxx`and various other files associated with the build. Dll files seem to have been built without problem. I'm not sure exactly what the problem is, since it is supposed to produce the `.pdb` file too ? I also gave it a try with a pre-existing `.pdb` from `link.exe` but without luck.
MSFT will not admit this publicly but my guess is that 32 bit support for coroutines is low priority. They do not want to break old code compiling for 32 bit but I guess they assume all the cool kids that want to use coroutines will target 64bit. Reasons for my guess: If the problems are as bad as you say it is actually hard to miss it during testing, so it was probably ignored.
From the rest of the comments, let me explain a little bit about what C++/WinRT is. Note that I'm not even real a consumer of C++/WinRT, nor of WinRT. I've just been building tools for it since the days when WinRT was designed. Everything below is heavily biased and interpreted by my point of view. Read the links if you want the truth. (Or come work for the MSVC or C++/WinRT teams. We always need good people!) The [Windows Runtime](https://en.wikipedia.org/wiki/Windows_Runtime) (WinRT) is a new COM-like API that allows targeting from a variety of languages (JavaScript, .NET, C++). This is possible by creating "projections" of the API into each language. The Windows Runtime also provides object brokers that are used for many purposes, the most common being a security sandbox. WinRT APIs have a rich metadata--essentially the same metadata used by .NET. When WinRT was developer it borrowed heavily from the .NET metadata design. Given the common metadata design and their shared roots as "a better COM" WinRT and .NET should work together brilliantly. For C++, there were a few options: either create all the code for the projections and let the compiler sort out what's needed or create a set of language extensions that let the compiler handle projections for you. As I understand it--I was on the .NET team at the time, having just left the C++ team--the first option wasn't viable because the C++ language itself didn't have the necessary facilities. Even today with all our fancy constexprs and enable_ifs the code Kenny creates is an insane stress test for our compiler. (That's why I hear from Kenny more than I hear from my mom.) So we went with the second option: take C++/CLI, strip away all the .NET dependencies, and wire up the compiler to create those projections as needed. That's what we call C++/CX. At the same time, Kenny was off on his own creating [C++/WinRT](https://github.com/Microsoft/cppwinrt): essentially, option one. The C++ language progressed, and Kenny made some design decisions that were very, very good, and eventually Windows hired him to do this for real. Where we are now: C++/CX is still supported but the MSVC team is putting all of our weight behind C++/WinRT. Given the C++ language we have today it's a better way to program against WinRT. And yes, I think WinRT is just Windows Store right now--taking heavy advantage of the runtime broker functionality. But WinRT really is a better COM than COM. It's a very general API design and I look forward to it being used more broadly across our products once we can program against it in Standard C++. *Edit: WinRT works outside of Windows Store: apparently Adobe is using it for Photoshop, as well as a couple of other software packages.* *Edit 2: Qualified the statement about how well .NET and WinRT work together as there are always bugs.*
Yes, you're absolutely right :) In the standard library, a type traits is defined as integral_constant. It does not change the fact that a type traits is itself a concept broader than just STL type traits and that there are several perfectly valid ways to implement them. 
Well, gcc is also not really "designed for deployment to Microsoft platforms" so if you want to deploy to Windows (often &gt;90% of your userbase), it's hard to ignore that. Sure there's gcc for Mingw etc., but it all comes with their own caveats.
&gt; That you haven't read it is incredibly concerning Incredibly presumptuous of you... I hate co_ with passion and IDK if await will be a good or bad language feature( I am guessing good, but not 100% sure), but to claim that Niebler did not read something just because he does not agree with it is not fair. 
Please feel free to send the bug reports directly to me. I am sorry you have the impression that the quality is getting worse. In MSVC we have a backend coroutine implementation that is spread between the middle optimizer and the platform specific codegen part. So, some bugs might only occur in x86, but not in amd64/arm or vice versa. We are looking into evolving the backend to have a unified middle-end implementation like we did in llvm that should increase codegen quality and robustness. Until we get there, we are fixing the bugs in the current implementation as they are reported. The bug you reported earlier missed 15.3 by a little bit, currently it is on track for 15.4. I am looking at the corsl bug on x86 release that you mentioned in this post, I'll send an update after I debug it.
&gt; To add, I had to separate good practices from the bad, and fight the latter. I don't even fight it anymore. Work is work, it's gonna be a shit show...and fighting for good practices just got me into too much trouble. And it's been through multiple jobs so I guess it must be me, but the practices I see in the field are just such shit and nobody wants to do it differently or learn why it's shit...so whatever. I leave the good practice to the code I write at home. Like I was mentioning to someone just yesterday: I have more process at home where I'm working by myself...a team should do more but I just don't see it most of the time. I consider myself pretty lazy and messy about things like unit testing and shit...and I still am way more diligent at it that people in the real world...and nobody wants you to tell them they're doing it wrong. Meaning I *should* be getting mentored in this shit really but I can't even find people willing to do what I do :p What REALLY gets to me is that they even fight you on your own attempts at good code quality. I Learned to Stop Worrying and Love the Bomb
I only use C++ on Windows when my .NET code needs an extra help, when I need to interact with native CLR APIs, or when Microsoft decides it is the only way to access Windows APIs (e.g. DirectX on UWP). So after the radio silence about C++/WinRT on the Visual C++ blog since last October, and the focus from all UWP teams (including the new Windows.UI.Composition engine) on .NET Native for their demos, I kind of though C++/WinRT did not make it through. Maybe it is time for a Visual C++ blog post about actual status and roadmap?
Good suggestion, thanks.
[Clang's linter has it.](https://clang.llvm.org/extra/clang-tidy/checks/cppcoreguidelines-special-member-functions.html) I agree that the compilers themselves should have it, though.
&gt; It's been an invaluable debugging tool for software developers and escalation engineers within Microsoft for many years. We’ve spent the last couple of years improving performance, scalability, and usability, and are excited to finally be able to release a public preview of Time Travel Debugging. Sounds like this is the public release. ["It's not available yet. Wait for @CppCon :-)"](https://twitter.com/JamesMcNellis/status/900197627962298373)
I don't know about TTD, but there is Mozilla's "rr" for that kind of debugging: http://rr-project.org/ Github link: https://github.com/mozilla/rr
Two problems: 1) in `test_shared_future()`, lambda closure object lifetime ends at the end of the loop, however, the coroutine is resumed later when the loop is over and any captured variables in the closure object are potentially overwritten: for (int i = 0; i &lt; 10; ++i) { [&amp;](int i) -&gt; winrt::fire_and_forget { co_await corsl::resume_background{}; ... uses shared_future, counter and event from the capture after resume after lambda is gone ... }(i); // lambda is gone here } To fix this, make it a stateless lambda, for example: for (int i = 0; i &lt; 10; ++i) { [&amp;](int i, auto &amp;counter, auto&amp; shared_future, auto&amp; event) -&gt; winrt::fire_and_forget { co_await corsl::resume_background{}; ... uses shared_future, counter and event from the capture after resume after lambda is gone ... }(i, counter, shared_future, event); // lambda is gone here, but it is fine, since it is stateless } 2) winrt::fire_and_forget need to implement `unhandled_exception` (used to be `set_exception`). Since Nov 2016, Technical Specification has changed and now `unhandled_exception` is mandatory member. Visual Studio is too permissive and let the non-compliant code compile. Please add to `fire_and_forget promise_type` an `unhandled_exception` defined as follows: template &lt;typename ... Args&gt; struct coroutine_traits&lt;winrt::fire_and_forget, Args ...&gt; { struct promise_type { // vvvv --- add this void unhandled_exception() noexcept { std::terminate(); } ... }; }; Let me know if you have any other problems. (edited: formatting and typos)
Thanks for the explanation, it's much more clear. So C++/CX really has absolutely no dependencies on .NET ? What are the features used that you couldn't provide an alternative for in standard C++ ?
that's exactly what I was looking for thank you!
Thank you very much for looking at the problem! I will fix the things you mentioned and post an update here. 
Fixing these two issues seem to fix it. It looks like missing `unhandled_exception()` in `future`'s promise type was causing exception-related issues. I will do more tests in the nearest future and will post here if there any other issues. Why does Visual Studio compiler allow for older syntax after incorporating new one?
I was under impression that long time ago, in VS 2015 era, Microsoft has announced that coroutine support was out of beta and declared stable.
Using floating-point for `m_elapsedTime` is perfectly fine, and typical in game code. Values like this are typically small and so well within float precision, and used as scale factors on various quantities which are also float, so int32/64 would incur many extra conversions (and possibly some divide-by-constant terms). Note you can still use `std::chrono::duration&lt;float&gt;` for strong typing, correct conversions etc. Naming is ok if it's seconds (ie base unit of time), if it something else (like ms) should be named appropriately. But since it's floating-point there's no reason not to use seconds. 
If using the Windows 10 SDK is an option for you, it works for me (at least 14393 and later).
That would be great! Having to teach new developers that they always have to modify newly created project files by hand to be able to compile a solution is pretty bad. RAM usage got pretty high after I believe one of the Visual Studio 2015 updates (which is not a problem for us with the 64-bit toolset).
Right, that's the case presently; the point of this post is that those will no longer be the case by the end of the year. :-]
Yes, they were stable, but coroutines are still going through standardization, and the standards committee makes changes. It's unfortunate that we didn't have an `/experimental` switch when we did coroutines like we have for modules and concepts, but that's what it is. We've learned. 
Coroutines specification evolved and our compiler mostly kept most of the previous design iterations intact. (bool returning initial/final suspend, auto type deduction, 'return' instead of 'co_return', etc. Now that official TS document is published by ISO, we will bring it to full compliance (possibly with warnings to ease the pain of transition for existing customers).
This subreddit is for articles that are written in English.
"Absolutely no dependencies" is squishy. The compiler loads a .NET DLL to help us write the WinRT metadata. Because the WinRT metadata is so similar to the .NET metadata, it was vastly easier to reuse the C++/CLI pipeline. Binaries compiled from C++/CX do not have a runtime dependency on .NET. What features had to exist before C++/WinRT was really possible? Expression SFINAE, enable_if, constexpr for starters. C++ is a vastly improved language these days. 
Just to let you know that nuget still hangs during installation of this on my personal machine, but on a machine Intel lent me access to to test some of their whizzy new hardware, AFIO compiles without ICE using your nuget compiler. Looking forward to that compiler hitting Preview, I have a few nice compiler parse failures to report to you :).
I read this in Gor's voice and it was as quite pleasant as his talks.
I'm currently on this exact path and on phase 3 without knowing it. I'll give "almost always references" a shot instead of a crazy observer_ptr hell. Thanks.
Well, guess MS should fix it but on one hand, simply don't build 32-bit programs any more. The percentage of 32-bit Windows users is about 5%, and 4.5% of those are XP users which is a dead and unsupported OS, so disable it it project settings ;)
&gt; but I believe that if you don't use anything else than the value member Yes, for some implementation detail a raw boolean can be used. However, if a library is going to provide a compile-time predicate it should be an `integral_constant` as you can't predict how the user may use the predicate. &gt; In my opinion, type traits is simply a very general concept that allows to get compile-time information regarding a type. Nothing more, nothing less. The way to implement is then totally open. In general, when I think of a type trait, I assume its implemented as it is in C++ or boost. So, normally, I check the compile-time predicate with `static_assert(some_trait&lt;T&gt;{}, "")`. Sure, it doesn't need to be a `std::integral_constant`(it isn't in boost), but it should keep the same "interface". 
I don't know why Microsoft would be reluctant to admit that. I've been deliberately disabling 32-bit builds on all my projects for years (to the point that I get endlessly irritated every time VS automatically sets up 32-bit targets for new projects...). I guess there are embedded environments where you'd need 32-bit builds, but even then, the architecture is likely so much different from anything else you'd be otherwise doing that you probably can't depend on most newer C++ features to begin with.
Yes, my opinion is that Coroutine TS is the best thing happened to C++ recently and Gor is the Man who basically created and grown the baby! The second one is Kenny Kerr who brilliantly applied it to Windows Thread Pool in what later became `cppwinrt`.
What's your reason for using shared_ptr for nullable columns? It seems a bit heavy-weight for that purpose.
no, you can't and you're almost certainly not using MSVC in the first place. we roll a kludgineered on some of our embedded projects at work, and its quite a different toolset compared to the toolset I use for my application dev work.
It looks like the latest compiler has been updated according to new TS, for example, requiring mandatory `unhandled_exception` promise type member function, while still silently allowing "old" `set_exception`. The problem is that in 32-bit optimized release build this results in bad code gen without any warnings or errors. Fixing the code according to Gor's instructions seems to fix all the issues I'm having so far. He also tells that the next compiler will at least provide a warning on using deprecated coroutine machinery.
It's like developing a web site and deciding to drop support for some old browser or version: it really depends on your intended or existing target audience. And remember that there are a lot of Intel Atom-based PCs with 1 or 2 gigs of RAM on which running 64-bit OS is often not worth it. And embedded may also have to run on 32-bit OS due to legacy 32-bit-only dependencies only available in binary form.
If I may suggest some examples of excellent documentation... The Postgres documentation, online at www.postgresql.org, is really great: well-organized, you can find everything you need, and easily switch between multiple versions as well. For me this is the golden standard for programming documentation. And much older, but also great: the Amiga Rom Kernel Reference Manual: Libraries &amp; Devices (2nd edition) (you can find it online if you want). It is from an earlier age of computing, and it actually explains things like "windows", a "mouse", and all the internal stuff that make up a modern operating system, in terms that actually allow you to learn about all that. For me it was one of the books that really taught me about programming, and I haven't seen its like since. 
PR speak... There are no low priority bugs because that sounds bad although everybody working in SW industry realizes that it is unfortunate reality... And for embedded and modern cpp... you may want to see some of Odin Holmes talks :D 
Are we missing something? &gt; like we have for ... concepts It would be nice to play with concepts in MSVC! My guess: maybe at CppCon?.. 
Feel free to report them on the NuGet compiler. Just make sure to supply a `cl -Bv` so we know the version of everything. Also, the NuGet package is **HUGE**. You might have to adjust a timeout on the NuGet client to install it properly. I can't install from my home internet, I have to install from work. And yes, we really should split the packages up :) 
Yeah observer_ptr (and raw pointers indicating non-ownership) sneak into your code because of their convenience but really you keep having to check for null in your APIs because nullptrs can still be passed in. The references force a good discipline about ownership and lifetimes. I have so far found a few potential bugs where I assumed that the observer_ptr could never be null which in deeper analysis was not true. I am still working out how to go "almost always references" in as many places as I can and I have found where I used to for example compose objects with moved unique_ptr's I now often just accept a moved version of the objects. I am still working out how to best handle the entire virtual interface / plugin case which would remove even more of my pointer use.
Windows Store is an option, also they made a package installer for appxbundle files. What installer does is nothing more than running a powershell script (running the script even does the job more succesfully, I think bundle installer is not fully there). However, appxbundle installation does require developer mode to be activated.
He didn't say he didn't agree with it. He said he didn't know what the problems with `await` were. Yet they were covered in that paper. So he knows what they are, if he's read it.
You can give http://www.vivox.com a shot. They are voice communication platform and service. Mostly used in video games. They have some pretty big clients like Bethesda, CCP, Epic (Unreal), and wargaming.net. They have a free service for development and low concurrent user numbers. Disclaimer: I used to work for Vivox, but I no longer work for them and I am not affiliated with them in any way.
No, no concepts from MSVC at CppCon. Sorry that I implied that our support was more than it is. We have started concepts, but only just barely started. I don't think a dev has touched the code in months. We wrote a tiny bit of concepts support as a way to inform ourselves about how expensive it will be to support the TS. It's not being actively developed in any way. Here's the limit of what works today, and for the forseeable future. You can require that something is itself (but you can't actually test that it is equal to itself--that doesn't work yet!) C:\tmp&gt; cl /c /experimental:concepts .\concept.cpp Microsoft (R) C/C++ Optimizing Compiler Version 19.11.25506 for x64 Copyright (C) Microsoft Corporation. All rights reserved. Experimental features are provided as a preview of proposed language features, and we're eager to hear about bugs and suggestions for improvements. However, note that these experimental features are non-standard, provided as-is without support, and subject to breaking changes or removal without notice. See http://go.microsoft.com/fwlink/?LinkID=691081 for details. concept.cpp C:\tmp&gt; cat .\concept.cpp template &lt;class T&gt; concept bool Identity() { return requires(T a) { }; } Edit: Shameless blog link on [how to use Windows Subsystem for Linux to get concepts inside of VS \(using g++\)](https://blogs.msdn.microsoft.com/vcblog/2017/02/22/learn-c-concepts-with-visual-studio-and-the-wsl/)
in a few month - yes
I've worked on multi-million user voice solution that uses Vivox. It's pretty top notch and scales for real. 
In my case, it will probably be roughly 60 concurrent users. I also need to have conference rooms. Based on what I see for the free version (5000 concurrent users), I guess that you use their cloud?
What kind of performance are you getting on a parallel sort. I am getting up to about 2.75X speedup on sorting large numbers of int64_t's.
One clarification: I'm told that three major software products in development are using C++/WinRT to access WinRT functionality *outside* of Windows Store apps. One is Adobe's Photoshop, another's a Microsoft product (not a Windows-org product), and the third is also a name you would know but that I haven't been told I can mention. So I'm completely wrong that WinRT is just Windows Store right now. It is proving itself to be more generally useful (as it should be.)
LPT: phrase all thorny bugs as coroutine issues so Gor can debug them for you
Absolutely love ODB. Best ORM i've used across any language. Any news on when 2.5.0 is expected?
&gt; Where we are now: C++/CX is still supported but the MSVC team is putting all of our weight behind C++/WinRT. Given the C++ language we have today it's a better way to program against WinRT. I can't wait to hear the story this time. I remember some *raging* threads on MSDN forums about C++/CX in which many end-users basically told Microsoft they were out of their gourd with C++/CX, while Microsoft personnel were adamant that C++/CX was the best option all around. E: And any poor soul who has tried to program UWP in C++ using WRL will surely (and sadly) attest to that. Meanwhile, here comes Kenny Kerr independently developing C++/WinRT, and now the marching tune is "MSVC team is putting all of our weight behind C++/WinRT." I personally always found it hilarious that the "better COM than COM," highly touted as being developed in C++, needs to go to this level of drama and trauma just to be consumed in its own native language. Anyway, Microsoft has so muddied the story with WinRT, COM, C++, UWP...I don't think you can ever fix it. It will certainly be entertaining watching you try though. Good luck. 
Depends on number of cores you have :) https://twitter.com/MalwareMinigun/status/887205454274744321
Since you are on /r/cpp maybe you might like CNTK? https://github.com/Microsoft/CNTK
I would appreciate if you could make ATL and MFC a separate package. It seems the nuget package size increased a lot since their addition.
Clarifying a bit, C++/CX is also fully native, it's just a language extension
It does depend on some .NET/CLR DLLs which provides metadata generation (I believe)
Please tell me that you add all the repro cases to the test suite (yes I know this was a half-pebkac). I'm still very much uncomfortable with using this in production since we'd have to go all-in with hundreds of coroutines in a 300kloc codebase and we'd be royally shafted if it broke again.
This looks great, but I'm curious - why does the peak CCU matter for voice coms in-game? I would've thought you'd route that through your game server. I understand needing it for something like party chat, cross-game chat, etc, but in-world?
I've looked into this a lot. Your best options are [MXNet's C++ API](http://mxnet.io/api/c++/index.html), [tiny-dnn](https://github.com/tiny-dnn/tiny-dnn) for a small, standalone library, [dlib](http://dlib.net) for a powerful but kind of ugly metaprogramming based API or [Caffe2](http://caffe2.ai) (very good, see tutorial [here](https://github.com/leonardvandriel/caffe2_cpp_tutorial)). If you don't really need to write the model architecture in C++ but just want to run inference on it from C++, you should write your model in TensorFlow/Caffe2/Keras in Python and export the graph and load it from C++ (if at all possible, use this option!). TensorFlow peeps are also working on a [C API](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/c), which I believe is relatively stable.
Teams grow and learn, but you must also consider that situations change as well. Every decision we made appeared to us at the time to be the best for our developers. That's not to say we didn't make mistakes: in fact, the opposite is true. But I can't say that we wouldn't make the same decisions given the same situations today. Show me a company that doesn't have a history of mistakes and I'll show you a two week old startup that's headed for disaster. 
Is your main concern that ATL/MFC is big, or that you never use it? What if we split the package by the target architecture instead?
It creates the metadata so the component can be inspected from clr languages, but the component itself is just c++
I concur. If all you need is to train a NN then I would recommend using Keras to train it. It will make using the GPU transparent. However, the problem on how to export the Keras model to a graph will arise, although I'm sure it shouldn't be too hard to export it.
&gt; Is your main concern that ATL/MFC is big, or that you never use it? I think it's big (mostly because my internet sucks), but most important, i don't use it. &gt; What if we split the package by the target architecture instead? I am only interested in the x86 and amd64 targets. I always delete the other targets anyway. So yeah, that would be nice.
My work has a mentor program for interns. They get paired with a full time engineer, usually senior or above and they will teach you habits of the company, look over your project, and hopefully get you to 'production' level of code if you're not there already. Generally most students are from top 10 cs schools so most of them are close. For new hires it's a slightly different process but similar.
Depends, you can call WinRT apps on your "Win32" app. About UWP app, yes, you need a cert. 
You should remove the Debug binaries and user project files from the repository. 
You could always start with visual studio and look what libs he use and show him that it works fine on linux too. Certainly GLEW or GLM. Anhways, computer graphics is mostly maths. There's good chance you'll just end up writing shaders.
Sounds like a plan! Thanks! I just hope I don't get developer cancer after using Visual studio!
If you provide the strategy on construction there is 0 problem using a reference.
Of course there is: You have to maintain the reference at the creator's site! If you rely on some sort of factory, if will go out of scope earlier than the produced object.
Visual studio is a great IDE
Have a look at [undo](https://undo.io/) - in particular [undodb](https://undo.io/products/undodb/). It just works on Linux, though.
I assumed that the context was about non-owning references / pointers hence the owner was elsewhere anyways.
Better than using Vim + terminal, which are not an IDE?
Removed: spammed to multiple subreddits, no significant relevance to C++, poster hasn't contributed anything else.
There is no better or not. Studio is just comfortable, thats all
I understand. Will give it a try!
Thanks! Our main design goal was to have as little magic and bloat as possible. So this is definitely rewarding to hear. &gt; Any news on when 2.5.0 is expected? Yes, it is long overdue, sorry. But it is coming, hopefully before the end of the year. 
I liked https://github.com/tiny-dnn/tiny-dnn
There are pluses and minuses to this. If the course uses directx for graphics at any point your gonna have a much easier time using Windows to build it. If its opengl or writing your own graphics code then your right it's just as easy to use Linux. But there is nothing wrong learning another environment, it may even help you in the future, I prefer developing on Linux but the majority of my work I do in Windows. Give it a go, learn something different and worse comes to worse you develop on Linux then cut and paste to Windows for the final build. On a slight aside, try the visual studio code editor (not the ide), that's a really good editor/debugger in Windows and Linux. 
The GPU drivers are better on Windows afaik. Can't you use msys2 to get both up to date drivers and a Linux environment? 
&gt; the respective compilers These days that's not just msvc anymore [1], so you have a third choice actually: VS with Gcc or Clang should work as well. Though if the instructor gives you project files you'd have to at least modify the used toolset and possibly some compiler options as well. Then again, as others said, depending on the graphics used it might just not even build with anything else than msvc. [1] : https://blogs.msdn.microsoft.com/vcblog/2017/03/07/use-any-c-compiler-with-visual-studio/ 
In my previous internship, when someone new came (either a new intern or a new employee), a lot of 1 hour slots was schedule by all the other employees. The goal of each of those meeting was to present 1 part of the job, done by 1 of your future co-worker. I really liked this approach, because it was easy to do for the previous employees (they had 1-2 hour to reserve to do the presentation, witch is easily manageable), while being really valuable for the newcomers (they could discover their future co-worker, have a lot of different point of view, …). We were ~30/50 employees in the building. EDIT: obviously they tried to group 2/3 newcomers if possible by delaying the training by 1-2 month if they knew that another newcomers were coming in a near future.
From my personal experience with academia - I think you should worry less about which libraries and environments you're shoehorned into and more on the core study they're trying to teach. It doesn't particularly matter if you're using DirectX on Windows with Visual Studio, as long as the fundamentals of Computer Graphics are taught in an agnostic manner. The environment is a set of tools which turns that knowledge into a practical application, it's not the focus of the course. More importantly - you can use this as an opportunity to get to grips with something outside of your comfort zone. Being a one trick pony will not do you any favours going forwards.
That's crazy insane. Though, I think I'd much rather run a dos cross-compiler from a modern host.
He is probably a bad/inexperienced coder (as many Profs in academia are) and he's probably using old tools &amp; libraries and for sure nothing cross-platform compatible. But for a course, it doesn't matter too much. Is he a good Computer Graphics teacher? Then yes by all means take the course. Learn about Graphics! Just take all the code with a grain of salt. As a matter of fact Visual Studio is awesome and I do all my coding with it. But probably much different than your instructor. If one uses Visual Studio, you should use CMake and make sure everything works on all platforms. So one may do all their day-to-day coding in Visual Studio, but everything works as well on Linux on gcc and clang, and another contributor to my project may in fact use Linux/gcc/vim or something and it all works fine. In fact proper code should be set up to compile on CI like AppVeyor and travis. But this is for your own projects, it's too much to ask for the course. Just be aware the course will teach you about Graphics, not coding.
See my other post here - it also depends on you using VS properly: Meaning, with CMake, and making sure your code is fully cross-platform compatible. Using VS doesn't mean you got to do the vendor/platform lock-in (i.e. don't use VS project files, use CMake). As for the course, if you're not familiar with this dev stuff yet I'd advise you to just take the course project files as is and work with them, and then on the side for yourself give VS + CMake a proper try. Please don't say things like "I just hope I don't get developer cancer after using Visual studio" and then asking whether it's better than using Vim + terminal. That's just idiotic, sorry for the language. VS is an awesome IDE, you just have to use it correctly. And then some people like it, some don't. As with everything in the world. Neither gives "developer cancer" (that's a pretty dumb expression anyway, sorry). For me, personally, I'm 3 times more productive with VS than with Vim + terminal. I can't understand all these people thinking that they're really productive with Vim + terminal and then I see how slow they actually code and that they do printf debugging. Always gives me a laugh. That's not so say, that if you use Vim + terminal correctly, there's certainly better ways to debug, but nothing comes close to the VS debugger.
visual studio is a great IDE, you just need a bit of time, you might be trying to achieve simple things the linux way wich makes them complicated on VS, for example idk... trying to compile from a terminal when you can just press the build &amp; run button or something like that. Modern tools are made to be more easy to use and efficient, vim is great for "ssh'ing into a distant server" but on a GUI, I think using a complete IDE like visual studio is simpler : you can write your code, intellisense warns you about errors before even compiling and the auto completion make you write faster, you also have an intuitive debugger, a complete performance analysis set of tools with graphs and stuff... and even a package manager if you're lazy (I would not recommend it tho) and that's probably like 10% of all the features
also Visual Studio is one of the most used/popular IDEs, if you work in a company with other people, you're probably not gonna use vim most of the time
We will be using openGL. Yeah I guess nothing wrong in learning something new!
Yes, I love the theory and mathematics behind them much more. 
I have been trying to use C++ tensorflow as well but there's pretty little documentation available for it.
I have made similar experiences that at my University people who do mostly computer graphics/vision related stuff tend slightly more to use Visual Studio. I **assume** a strong reason for this is that OpenCV is very popular here and there is a great plugin to view cv::Mat during debugging in Visual Studio. Also NVidia offers powerful plugins specifically for Visual Studio.
I don't buy the argument that it allows you to guess what the function will do either. It actually just confuses me, having to remember what 10 variables are at the start of the function in order to read the code is just strange. 
&gt; The compiler ignores uninstantiated template functions Not sure if I understand what you mean, but it is not supposed to do that.
This is an interesting idea, though i think there are two things to look in to. First, I don't think other compilers share msvc's ignoring of uninstantiated functions. Second, you should keep in mind the preprocessor, because if it doesn't have advantages over that, it is just a trick.
This is probably one of the worst advice they can give you for c++. If you declare all variables without immediate initialization, you will eventually forget to do it one day and you will be in trouble. Furthermore, declaring a variable without initialization call the default constructor and not all type are default-constructible, and not all type have cheap default constructors.
I did some testing using msvc 15.3 release ltcg (with pdb): Memory usage seems to be stable (binary size increases by 1Ko using lto) My micro benchmark was actually faster when using stacktrace... Test : fibonacci with a signal handler registered. Call std::terminate() for indexes &lt; 2 and write a stacktrace to file I am just sad that it doesn't compile with /c++latest
Shame its not an open sourcetrail though. :/
One tool that allows you to portably ignore parts of the code is `constexpr if`. Did you try that?
Care to explain in what way is your class, templated or not, not ignored? If you never instantiate an instance of `Mutex&lt;PlatformWhatever&gt;`, linker will take it out of the generated executable. I just made a small test over here (MSVC '15), checked the generated executable with dumpbin, I don't see evidence of what you're saying. Are you sure you're looking at the release (optimized) build? (I tried with the default options for "Release" of MSVC).
This looks potentially useful. How well does it handle very large and complicated codebases? Like Unreal engine for example?
And 5000 concurrent for the free version is still a big number, so it sounds like you are using their server.
Yeah, that's a good idea. But only C++17. If nothing helps I will consider using that.
To be fair, this should work in Debug mode
I wish it was free for non-commercial use. A lot of tools have taken this approach or at least make it free to those in education. 
It should? My understanding is that then not much is taken out. Have links?
It is free for students and OpenSource developers, please have a look at our discounts in the lower section of the our store page: http://sourcetrail.com/buy-license
Maybe "ignore" is not the best term. The following code compiles using MSVC: template&lt;class Foo&gt; void foo() { abcdefg(); } `foo&lt;Foo&gt;()` is not instantiated and`abcdefg` is not defined. I basically want the same behaviour for not instantiated classes and their members.
Currently we scale well to about 5M LoC. For larger codebases you can exclude certain directories from indexing, or separate it into multiple projects.
Oh, awesome! This is a new option, yes? Last time I was interested in Sourcetrail I didn’t see these options! Thank you 😊 — I will definitely leverage this tool
Thanks! Yes, it's new since we ended our Beta in June.
What a pun
What I mean is losing debugging capability is bad. Whatever approach is used to solve a problem should not make large compromises on maintenance. Losing debugging is too big of a deal breaker
MSVC is non-compliant in this regard because it doesn't have two-phase lookup.
What you are looking for is called "two phase lookup", which should have been in c++98 but is still not implemented in MSVC https://blogs.msdn.microsoft.com/vcblog/2017/03/07/c-standards-conformance-from-microsoft/
Sublime Text's 'Go To Definition' isn't too bad, and most other popular editors/ide's (vim/emacs/qdevelop/eclipse just to name some) can do it as well possibly with the help of a plugin, usually something ctags based. For vim for example: https://stackoverflow.com/questions/635770/jump-to-function-definition-in-vim
you could set up some nice aliases containing grep to speed up the process if you have to type out lengthy grep commands to get the results you want. 
I use gnu-global/gtags with vim and I'm pretty sure it's better than ctags or cscope. It's definitely not top notch IDE level in terms of not getting confused by macros or virtual methods and so forth, but I personally don't care.
&gt; How do you approach/study a new large C++ project on a linux machine? The easiest would be for you to use an IDE. I can recommend [Eclipse](https://www.eclipse.org/downloads/eclipse-packages/) with C/C++ intergration. Simply import the source code as a new project. Everything will get indexed and you can jump to definitions, headers and classes by the press of a key. Even though I prefer using an text editor when writing code, I use Eclipse a lot for exactly the purpose you describe, studying a C++ code base or library.
If you can run Windows at the same time as Linux, then [Visual Studio has support for Linux development](https://blogs.msdn.microsoft.com/vcblog/2017/04/11/linux-development-with-c-in-visual-studio/).
QtCreator will do that, only, I think you need to have the project described in CMake. netbeans is an easier-to-use IDE than Eclipse, at least in my experience. And it uses normal Makefiles. 
You can use CRTP for this: // basicmutex.h // All common stuff is here. // Only implementation that deal with // platform specific stuff is called in `T` template&lt;typename T&gt; struct BasicMutex { void test() { // This is allowed to exist, // Even though no class has test_impl // Validated at instanciation static_cast&lt;T*&gt;(this)-&gt;test_impl(); } }; // mutex.h #ifdef _WIN32 #include "windowsmutex.h" #else #include "unixmutex.h" #endif // windowsmutex.h struct WindowsMutex : BadicMutex&lt;WindowsMutex&gt; { private: friend BadicMutex&lt;WindowsMutex&gt;; void test_impl() {} }; using Mutex = WindowsMutex; Now, everywhere in you code, you only use `Mutex`. The implementation of the mutex is chosen in the header, and all common stuff and the public interface is in `BasicMutex`. Edit: used better `ifdef`
I recommend CMake for project description and configuration. Use your favorite text editor for editing. If you want advanced code navigation, try QtCreator or KDevelop. Both are really good and support CMake.
Along with qtcreator and grep, I would add doxygen with the EXCTRACT_ALL variable set to YES so that it will build indexes for undocumented objects. Furthermore, if you have graphviz package installed, you can enable HAVE_DOT and COLLABORATION_DIAGRAMS that provide visual info on class relationships in addition to hierarchy. 
Eh? How is tjis about debugging? But even if it was , building in release does not preclude debugging, it makes it less comfy.
What about Fann? I use it in my research and I find it adequate Edit: Flann -&gt; Fann
You should definitely give [KDevelop](https://www.kdevelop.org/) a try. If your project is cmake or Makefile based, you will get perfect code browsing facilities thanks to the clang based code model behind the scenes. There also is an [AppImage](https://www.kdevelop.org/download) that works pretty well out of the box.
Also AFAIK they are implementing or at least planning to implement two phase lookup so this may get broken in the future
Visual Studio Code has a pretty decent file search system as well. If you want to deal with setting up proper CPP support it will let you browse with 'go to definition/declaration' support.
So sad that an essential part of WinRT, the support of a native XAML-UI, isn't available to Non-Store apps. I know that there is the Desktop-Bridge option using two separate EXEs communicating via AppService but this is still only possible for Store-Apps (side-loading is really not an option for commercial software). In the end we native desktop developers are left with no other UI-Option than adding .NET/WPF into the native mix which adds a lot of complexity and bloat to the application. It speaks for itself that even Microsoft now uses Chromium to implement the new VS-Installer. Isn't this absolutely crazy? UWP-Apps would gain a lot more traction when Microsoft would allow to use the XAML-Stuff in native desktop apps (and therefore also allow the traditional way of distribution by having downloadable installers). Then using Kenny's great C++/WinRT to implement that would be so cool ... just dreaming ... 
Will it be possible to write standard C++ apps (no C++/CX) with XAML, for the desktop, outside of the Windows store? The GUI story for new desktop Windows apps is incredibly confusing to me.
NN's are rather frustrating in the C++ world. It seems like the bulk of things are running in python and lua. For a bit I was working on my own library because I was just frustrated with the state of things. But I found https://github.com/clab/dynet. It's not perfect but it's usable and doesn't treat C++ as some sort of afterthought.
Yeah, there's a reason all the videos on YouTube about "How to solve all of the world's problems in three lines of TensorFlow" show Python code. TensorFlow is not a C++ library. It's a Python library. With parts that happen to be written in C++.
QtCreator with qmake or cmake. qmake is simple and easy to learn. You may start with qmake and later move to cmake for complex projects.
Maybe not helpful since I'm on a 12 core Xeon computer with 64GB RAM and SSDs... SourceTrail took shy of 3 minutes on an incomplete scan with errors: 1,831,737 lines of code, 3107 files, 96682 symbols, and 309255 relations.
This is also why static_assert can be used for invalid cases in templates using MSVC but not other compilers.
Mind telling what you don't like about Eclipse? Because that would be my answer. QtCreator is (also) a great C++ IDE that can be used for more than just Qt projects. You should really try it.
I use Kdevelop most of the time and is fantastic. As well, I've used Qt Creator. 
My experience is there's no silver bullet here. I use netbeans because it's the best, in my opinion, but it still leaves a lot to be desired. It also does okay with my remote building workflow, which a lot of other IDEs don't. 
I would rather go with an editor and use of command line tools directly with a build system of your choice. You will make your students a favor in the long run. IDEs hide too many details which are very important ... Even more so for beginners. Once they get a grasp how things work under the hood they will be able to switch easily to any IDE if they decide to do so. Other way around will be more painful. OT: Amongst IDEs on Linux, I think KDevelop does a good job if you're happy to pull in quite a few Qt dependencies.
i don't like eclipse because 1. it crashes a lot, displaying useless error massages like - null reference exception. it ends only if you reinstall it 2. also, you need to save the file before build, 3. the debugger is ugly, 4. all the "perspective" concept is ugly and make a lot of troubles. if you close a window or change it position by mistake, only god will help you restore it 5. it is fit for java programming, not for c++ 6. the intelisense not always working 7. go to definition not always working I can write more but its all ok if you use to work with eclipse and know how to handle it but if the students are practicing with it the keep asking about all the above 
You can try to get free CLion licenses for your students: https://www.jetbrains.com/buy/classroom/?product=clion
intelisense? Anyway, thanks for your explanations. Check out QtCreator then. I think it offers a more consistent experience.
Why vscode isnt even mentionned here ? I work with Cpp17 features and I can debug without a bug. (Kek). Its smooth and highly customisable since you have tons of plugins available and every settings are in a json editable. The command-palette is also a mustHave in 2k17 imo. You wont have to learn every single shortcuts to be productive. It has git integrations and a terminal too. I highly recommend this one. 
intellisense. (auto complete code etc.) I'll try qt, thanks 
can you tell us how did you install vscode to support c++? which plugins you installed?
You're trying to be clever here, but there's really not any advantage to it. At best, your compile times will be longer due to header only programming. At worst, an underlying compiler change, or the compiler used by a different platform, will suddenly break all your code and you'll be in for a huge refactor. All cross-platform codebases I've seen use the processor because it's standardized and all platforms will support it. `constexpr if` is part of a slow move towards eliminating the need for the preprocessor, but we're a long way from that. Maybe in 10 years the story will be different, but for now just use the preprocessor.
Using ifdefs exclusively is not an option for me. Or what do you mean by "use the preprocessor"
VSCode is an Electron-based app and it's depending on GTK 2. Either is enough for me for not considering to pull this misery to my PC.
Training is overrated(internal or by external "experts"), much better practice is to hire people who know their stuff (or are smart and willing to learn) and having high coding standards(testing, tooling, code review).
During my first programming class in the university we were taught Vim. Never looked back ever since. You can use Vundle with several plugins (YCM for latest Clang-based C++ support, vim-fugitive for git integration, some others if you like). Hands down, that was the best programming class I ever had. Emacs is cool, too, some might prefer that. The point is that if they're already using Linux then using an advanced text editor + command line tools would make the students understand Linux better and become better engineers. I think it's great learning experience, I would certainly vouch for that.
!remove
OP, A human moderator (u/blelbach) has marked your post for deletion because it is not appropriate for r/cpp. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/6vspbi/looking_for_the_best_free_ide_with_linux_support/dm2qyoe/,%20was%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/6vk2q2/voice_communication_sdk/dm2qz9f/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Even more: QtCreator supports "generic projects" without any project files at all. This is nice for quick browsing projects from MS Visual Studio for example.
What's the advantage of your library over fmtlib, which is popular, well tested and claimed to have similar features?
I use [Qt Creator](https://www.qt.io/ide/) for my C++ in linux and windows development. A right click menu looks like this[1]. You can switch between symbol and its definition by right clicking on the symbol and clicking "follow symbol under cursor". You can get a list of all places where a method/symbol is used by clicking on the method/symbol and selecting "find usages". Qt creator is a pretty decent IDE. [1] http://imgur.com/a/VLe6W 
Simplicity and compile times ggformat is 500 lines of code vs 6300 for fmtlib. You can read and understand everything in ggformat in a couple of hours. ggformat has 100 lines of code and some C includes in the header, vs 5k+ and half of the STL for fmtlib. Code using ggformat compiles significantly faster. ~~edit: It also looks like fmtlib has no allocation-free API for writing into fixed size buffers. ggformat only provides an allocation-free API and it's trivial to build a dynamic API on top of that (like, 5-10 lines of code to integrate with your dynamic string class).~~
Well most serious things are run in Python, true, (or via Caffe 1 ugly prototxt "DSL"), but most of these frameworks are developed using C++ :-) Just not very beautiful/modern C++, haha!
For somebody who cares not about web can somebody explain if this library is a big thing? I mean I know what tcp/ip is and I see use for libraries like that in Boost and I know what http is but I never considered important for C++ devs to have http library....
The readme is empty, is there a summary somewhere to read? What makes them useful or otherwise interesting.
there is no readme for all libraries but each lib is documented in its sources. you can find for example in this file: https://github.com/emeryberger/Malloc-Implementations/blob/master/allocators/dlmalloc/dlmalloc285/dlmalloc.c 
Unfortunately stacktrace simply doesn't seem to work for me on msys2 gcc 7.2, I get no symbols printed or anything, and the header only configuration breaks with errors about undefined references to detail/to_string Edit: Apparently the fixes did not make it into 1.65, checking out from source may resolve this https://github.com/boostorg/stacktrace/issues/28
eclipse always seems like the epitome of bloatware to me
Try CLion. The best alternative to MSVC I can find on Linux (and Mac).
Yes, I mean using defines and ifdefs. Why isn't it an option?
I think that basing the new Windows-Runtime on a "COM on steroids" was a good decision. I personally like COM a lot (well, more the ideas behind it, which are IMHO very modern; not necessarily the way of programming connection points, monikers etc with ATL :) and there must be something about this almost 30 year old technology to have survived all trends. Now with the language projections you don't see the "ugly" parts very often, you can program it very naturally in your favourite programming language. That said IMHO it would have been a lot wiser to open WinRT to Non-Store-Devs, too. There are still so many native Win32-Apps out there which require installing a service and which can't use the new API. Me and my colleagues would love to bring Fluent-Design to our (quite successful) application but it's just not possible. So now we're thinking about using the browser (Chromium CEF) for our new UI like so many others do now (incl. Microsoft with VS-Installer and VS-Code); it will work for sure, but it is big, slow and memory-hungry. But if you're running out of options this might be the way to go ...
&gt; edit: It also looks like fmtlib has no allocation-free API for writing into fixed size buffers. ggformat only provides an allocation-free API and it's trivial to build a dynamic API on top of that (like, 5-10 lines of code to integrate with your dynamic string class). fmtlib does have an allocation-free API, you just have to use [`fmt::BasicArrayWritter`](http://fmtlib.net/latest/api.html?highlight=array#_CPPv2N3fmt16BasicArrayWriterE). Example of use: char buffer[32]; fmt::ArrayWriter writer(buffer); writer.write("{} {}", 1234, "abcd");
You should point this out in the README then. Also, if fmtlib is so much code, surely it must have some features your library doesn't have?
I also want to ask the same thing. But it's good to have other options. 
As for fmt compile times, I can easily link to a shared/static lib. So this argument doesn't have much weight.
You use their servers. I don't think you can stand up any of your own servers with their server SDK without a commercial license.
&gt; #ifdef _MSC_VER Just note that this is probably a wrong ifdef if your goal was to only include the specific header on windows.
Well spotted :)
Code::Blocks and CodeLite
Ok... Listen, I'm sure you did a great job on writing something useful or nice or whatever, but your presentation definitely needs some work. Because what we see is this: - Title: "... malloc ..." My reaction: "shouldn't this guy be in the C forum? I don't use malloc, so this is not interesting to me in any way." - Article: nonexistent. You missed a great opportunity here to explain what you did, why it is better than alternatives, and why we should really be using it. Some information like "I did all these amazing C++ memory allocators, and they are 5x faster than the next best alternative for workloads X, Y, and Z!". That makes people take notice. - Repository: no information on what is actually in there. Here was another opportunity to explain what you did, why it is great, and how we could use it. Also, the statistics on the repository don't inspire a great deal of confidence: one contributor, ten commits, and they all happened around 5 years ago. - This comment: you don't seriously expect people to start reading source code just to figure out what it is, do you? Pretty much nobody needs "some useful malloc implementations", because pretty much nobody in the C++ community uses malloc. The odds of delving through an entire repository in the hope of digging up enough useful comments, when you cannot even be bothered to write a short introduction, are negligible. - From the file you linked: "Thread-safety: NOT thread-safe unless USE_LOCKS defined non-zero When USE_LOCKS is defined, each public call to malloc, free, etc is surrounded with a lock ..." I'll write that one down as "not useable in a modern, multi-threaded environment, and if you do it is going to be painfully slow.". 
You still have to include the headers, and especially the STL headers are gigantic. Some time ago I added iostream/map/vector/string to every file in my 80k LOC project and it took twice as long to compile, and fmtlib pulls in way more than that.
&gt; Title: "... malloc ..." My reaction: "shouldn't this guy be in the C forum? I don't use malloc, so this is not interesting to me in any way." you can LD_PRELOAD an implementation though
I'm sure I can. But the question is, why should I? 
sometimes for better performance (see jemalloc, tcmalloc), sometimes for detection of memory errors (checked malloc, etc), sometimes for benchmark (count how much time is spent in malloc, etc)
Everyone's talking about QtCreator so I made a small vid to showcase the different useful keyboard shortcuts : https://vid.me/jNrsK Notice how the "find all references" feature is near-instantaneous in comparison to VS's (this codebase is ~160kloc)
Other languages have HTTP and WebSocket built in, why not C++?
You may want to look into PCHs... lol
It supports user defined types, but it's not type safe! It uses C style elipses functions... At least with the built in printf, the compiler can give you warnings. I guess if compile/link time is more important to you than whether abort gets called at runtime, be my guest? Coming up next, all those nasty templated STL headers replaced by void* data structures. Compile times will be much improved. Edit: so apparently I'm wrong :-). Jumped the gun from the docs.
Wow. This is a huge caveat.
Do you happen to know why the C++ parser does not import defines and compiler flags using the CMake server (although [it uses the server mode for some things?](https://phabricator.kde.org/D4095)) Is it still a work in progress? Edit: I am using KDevelop and CMake snapshots.
PCH are not really too easy to use and cross-platform compatible (yet) unfortunately - thinking of an easy way to use them with CMake without having to do manual scripting. Not possible yet, so that's a huge obstacle to using PCH.
Using the STL over C includes is not really a disadvantage though. On the contrary, I find it often a sign of good quality C++ code. The STL is type-safe etc. Your library looks more like a C library to me to be honest, which I would not use in any modern C++ project. (Oh and it's not header-only, this is important to some people, including me.) In any way it's a cool project and I am sure it will be useful to many, so it's nice that you make it available! :-) It looks well done.
They're very easy in VS at least. I guess not if you need cross-platform. I can't really imagine coding without PCHs again, everything just takes so long to build.
Its also not true, It does use variable template arguments, not C style varargs.
The documentation doesn't match the source. The difference between variadic templates and old-style varargs is critical and cannot be glossed over in documentation.
I have had no issues using clang on Windows (linux hosted clang running on WSL, linking against VS and Windows libraries and emitting Windows targets).
meh, documentation documents usage, not implementation. I agree that I wouldn't have omit that, especially since the 'documentation' looks like actual function definitions. But critical? Just to people who want to criticise but are too lazy to read the code. Or the full documentation for that matter. Next paragraph, basic usage, gives a strong hint: ggprint( "hello {}\n", 1.23 ); // hello 1.23000 How would you implement that with C style varargs? 
I have nothing against it, I just wonder if this is a "common request" library or something more specialized.
C++ should have had a standards-like HTTP and WebSocket library a LONG time ago. It is embarassing that it took this long to get it. 
From the github readme: "runtime performance is not important". Well, you are a library, not the user of that library. Perhaps it's very important to me. It is more accurate to say that runtime performance has not been measured or optimised, and users can select between formatting libraries with that as one piece of information to help them. 
&gt; They're very easy in VS at least. And with GCC, and with Clang, and with Intel C++; sounds like CMake is the only problem here...
I cannot tolerate ambiguity in documentation. Any hint of "you know what I mean", "just read the code", etc. and I'm going to go find another dependency that will treat my time with respect.
The project I'm working on is in the early stages and could wind up in embedded devices. As such I'm gonna try to stick with C++ so the code can easily be compiled for different systems or relatively easily transferred to a microcontroller with a C++-like language. But I'll check out those libraries for sure.
Definitely gonna look into that one.
Adding that to my list to investigate
&gt;NN's are rather frustrating in the C++ world. It seems like the bulk of things are running in python and lua. That makes no sense to me. C++ is known as an incredibly popular language with incredible power and efficiency. Python has a reputation for being the "quick and dirty scripts" language. Lua I guess I'm less familiar with but I doubt it could rival C++. It's really weird that a language that's almost tailored to complex and resource-intense tasks isn't being used for NN's, which could easily have dozens of nodes and hundreds of synapses for deep learning nets. Edit: Forgot to mention I'll check out dynet.
Can use both floating point and fixed point numbers (actually both float, double and int are available) I can't trust someone who uses the word 'both' for three items on the front page of their website, which really sucks because it looks like it's a really good resource otherwise :/
My interest is now piqued. Will take a look!!
You should seriously consider `constexpr if`. MSVC will fix its two-phase lookup issues soon. 
cotire was really easy to use in my experience.
Yes, Captain Obvious, all those things could be true and thank you for answering the rethorical question. You'll notice, however, that we do not know _which_ of those things is true, assuming of course that any of them are, because the author completely omitted this actually rather important information from both his submission and the library itself. We could presumably dig this out of the source ourselves, and run benchmarks and tests. But I, for one, am disinclined to do so: life's too short to review random pieces of code pointed out to us by complete strangers on the internet, without any kind of description of their supposed benefits, in the hopes of randomly finding a solution to a problem I might have with performance, detection of memory errors, benchmarks, or whatever. If I need any of these things done I'll start with a search for best-of-kind implementations, which I identify because the author typically proudly explains what he made. For example, here is the very first line on the jemalloc page: "jemalloc is a general purpose malloc(3) implementation that emphasizes fragmentation avoidance and scalable concurrency support." Oooh, that sounds good! I'd like to give that a try! Here is the very first line of the tcmalloc page: "TCMalloc is faster than the glibc 2.3 malloc (available as a separate library called ptmalloc2) and other mallocs that I have tested." That also sounds great! Why am I not using this? Now contrast that with this submission. I'd quote the first line, but there isn't one, so we are left completely clueless as to what this is supposed to be. So I'd like to invite the author to update his article with a description, and some text on why it would be interesting to us. Maybe five lines of text - surely that's not asking too much? 
Is it so hard to run tests on a new compiler?
use samba to make code available to Windows (or simply copy it to Windows machine), create fake solution, add all source files to solution. It is not going to be ideal, but Intellisense will largely work.
If you include fmtlib's format.h, 2/3 of preprocessed code will come from &lt;string&gt; and its transitive includes. Much of C++ code includes &lt;string&gt; anyway so I don't think not including it will buy you much. fmt doesn't pull in &lt;iostream&gt; (unless you explicitly included the header for iostream support) or &lt;map&gt;.
If you're building your app in an electron sandbox without trouble, why can't you build it an windows store sandbox? The latter is super feature rich.
Yea I second that, all the windows 10 demos and GitHub samples now are C#. I was actually really bummed that the new fluent design docs only reference .net. Show some love this way too please 😍
While I fully agree with the sentiment that we should do something about excessive compile times, I don't think avoiding standard library includes at all costs is the right solution. Variadic templates, which your library uses, can be a bigger contributor to the issue. For example a nontrivial improvement to compile times in [the fmt library](https://github.com/fmtlib/fmt) was achieved by [replacing template recursion with array initialization](https://github.com/fmtlib/fmt/pull/243).
One cool thing about cppwinrt that I'm excited about, is that clang is also a real option. Especially now that it supports coroutines and pdb generation. 🎉
Windows store doesn't allow apps to install a service. I understand this because MS wants to control stuff that is running in the background and that could drain the battery. But this restriction leaves out a lot of great desktop programs. Electron is basically a very large Win32-Application which hosts a HTML/Javascript-Engine. And as it is Win32 you can choose the way of distribution and installation.
I use Eclipse mostly for Python and HTML and find it to be one of the most frustrating IDE's yet very powerful. I suspect that is why you find equal amounts of love and hate for Eclipse (even from the same person). My biggest frustration with Eclipse comes with doing an update and then having something that worked fine just before the update break. That happens way too much for my taste. So what I'm saying is Eclipse is great but you can also get screwed over by just doing a simple update to the installation.
If this changes when you can reflect attributes then reflecting attributes shouldn't be made possible.
C++ is actually being used, though. The libraries are *all* written in C++. Their user-friendly beginner-friendly easy-to-use interfaces are Python libraries on top of those C++ libraries.
Smart developers hide their pointers in the implementation of their classes and never let them leak to the public interface.
&gt; "runtime performance is not important" In this case, iostreams will suit purpose better. No additional dependency and full documentation is available.
Why do you explicitly turn off compiler optimizations [here](https://github.com/mikejsavage/ggformat/blob/master/ggformat.h#L124)?
It takes a while, but most importantly it takes a while to fix potential regressions that are introduced. Certainly more than a week. There's no rush, really. 
I assumed people who cared about how it's implemented would look, but noted and I shall mention it in the docs
&gt; Yes, Captain Obvious, all those things could be true and thank you for answering the rethorical question. Not everyone on reddit knows that this is even possible to do, so in my opinion this is always interesting knowledge to add. &gt; Now contrast that with this submission well... there is a folder with malloc implementations like it says. Some have a readme (like jemalloc) and the others pop up in the first few google result, eg ottomalloc, omalloc, etc
Compilers are very slow at optimising the code (edit: more specifically the huge mountain of code) generated by variadic templates. I wanted to avoid tanking compile times over something that has 0% impact on the final runtime performance in any normal usecase edit: also keep in mind that much of the heavy lifting is done by sprintf, which will have been compiled with optimisations!
I still identify as a C programmer :&lt;
&gt; in any normal usecase also known as "I know better than you". Formatting often show up in profiling in my experience.
It's quite normal to not use the STL (especially not &lt;string&gt;) in games!
&gt; thinking of an easy way to use them with CMake without having to do manual scripting. Use cotire: https://github.com/sakra/cotire include(cotire) add_executable(myapp ...) cotire(myapp) and you get PCH, unity build....
If your project compile time doubles by including vector, string and iostreams, what you have is a C project. I'm exaggerating for effect, but my point is that I think in reality the majority of real world code will include at least two of these a lot of the time anyway, so saving their inclusion is not beneficial. Plus, who's to say that any one of those is a requirement for any given formatting library anyway. 
That is a really strange reasoning IMO. Did you try to compare the compiler output with and without optimizations? I am sure there will be a significant impact on generated assembly with optimizations turned on. Edit: What I meant here is that this is a library code supposed to be used by many others ... this is expected to be as performant as it can be. Putting a caveat on performance should really be explicitly noted in the documentation.
Am I missing something, or is there no self-allocating call? (ala `asprintf` or typical use of `std::stringstream`) Is it at least safe to call `ggformat(nullptr, 0, ...)` to get the size of the required buffer fairly cheaply?
For a non editor based approach you could try opengrok to create a searchable db of the code. 
You're right, and your ggformat(nullptr) idea is what I had in mind. (I just fixed a bug with that) You can see a similar example in ggprint_to_file: https://github.com/mikejsavage/ggformat/blob/master/ggformat.h#L148 or template&lt; typename... Rest &gt; std::string ggformat_to_string( const char * fmt, Rest... rest ) { size_t space_required = ggformat( NULL, 0, fmt, rest... ); std::string result; result.resize( space_required + 1 ); // +1 because ggformat always writes a null terminator ggformat( &amp;*result.begin(), space_required + 1, fmt, rest... ); result.resize( space_required ); return result; } seems to work for std::string but I expect writing to `&amp;*result.begin()` like that is not kosher :)
There is [`string::data()`](http://en.cppreference.com/w/cpp/string/basic_string/data) for that
Hey, that's a great blog post, thank you! A few remarks: * I would've loved to have a couple more sentences about `boost::scoped_ptr`. Why was it not included in the standard, is its usefulness too limited? How is it different from `std::unique_ptr`? * I think one or two new pointer types are being discussed of being standardised, aren't they? I don't remember what it was but read something about that posted in this sub. Maybe mention that as well?
Herb Sutter's meta objects/classes might also end up producing WinRT metadata. Surely the list will grow as the experience keeps improvising. Although C++/CX was a start, that ISO C++ projection is being targeted seriously is great.
- Does not play nice with the Linux standards like pkgconfig. - Cross-compilation is an horrendous pain in the **** - Does not respect standard variables like LD_PRELOAD - Requires JAVA!!!!! - The standalone file bazel is nothing more than a zipped file In conclusion: It is a great tool if you are reinventing the wheel in your projects because you have a ton of engineers at your disposal. Otherwise meson, cmake, autotools or manual Makefiles are your friend (yes, even manual Makefiles are better) 
wish there were language support for them .. it becomes alot of _ptr code around a large code base. Im thinking mostly for function parameter definitions and creations .
Thanks for the suggestions, I'll look into that. There is one thing I can answer right now though: the difference between `scoped_ptr` and `unique_ptr`. `scoped_ptr` doens't even have a move constructor, so it's trapped into a scope. `unique_ptr`, on the contrary, can for example get out of a function with the help of its move constructor.
&gt; And since you get the ownership, this gives you confidence that you are free to modify the value of the pointed to object. &gt; But since you are the owner, you are allowed to safely modify the pointed to object, and the rest of the design should take this into account. I think this is very misleading. Whether and when you are free to modify some object is determined by the contract you are implementing, not by the fact that you own the object through unique_ptr. You may well be not allowed to modify the object at all without breaking the contract, or conversely you can be required to modify the object under certain conditions. unique_ptr really does just two things: 1. It will delete the pointed to object when it is itself deleted (or when explicitly told to). 2. The unique_ptr object itself cannot be copied, but can be moved. There is no magic behind unique_ptr that gives you the right to do whatever you want with the object and be sure that nothing will break. I understand that this is an introductory article, but still it shouldn't make overly broad claims that are easy to misinterpret.
I don't get how language support could make things better. Care to elaborate?
There is language support for not explicitly naming types: auto.
`scoped_ptr` is the simplest form of smart pointers. I would say it is the example of most direct application of RAII principle. Once it exits the scope, pointer beneath is freed. Copy construction &amp; assignment is not possible. There are no tweaks one can use through its interface to customize the behavior, neither one can _transfer_ the `scoped_ptr` out-of-the-scope. On the other hand, `unique_ptr` is a smart pointer which takes the advantage of move-semantics introduced by C++11 standard and, in contrast to `scoped_ptr`, it does allow move assignment but _only_ on rvalue references. As an extra, it provides a couple of converting constructors (i.e. one for `auto_ptr`), and possibility for clients to define their own custom deleters.
I'd say explicitly passing smart pointers around is quite rare. Usually you just pass the underlying variable around by reference 
I use this on Mac, very painless with no setup and very sensible defaults. It's also free for students.
verbosity
use Qt/QML
You don't need language support for that. The decision to spell the smart pointer `xxx_ptr` instead of simply`xxx` was deliberate. They could have used any other name but those were chosen because they are good names (for some definition of "good"). You can always use typedefs to use different names if you don't like the standard ones.
They certainly aren't as good as `*` and `&amp;` are. I was very disappointed when Rust got rid of `~` (which previously meant essentially `unique_ptr`) and I think that some C++ code would be a lot more readable if I could write `~T` instead of `unique_ptr&lt;T&gt;`.
&gt; I think that some C++ code would be a lot more readable if I could write ~T instead of unique_ptr&lt;T&gt;. I beg to differ
Just like pointer has * 
for historic perspective, take a look at the original smart pointer proposal from 1994 proposing auto_ptr (at the time, noncopyable, and essentially what is now known as scoped_ptr) and counted_ptr (now known as shared_ptr) http://www.open-std.org/jtc1/sc22/wg21/docs/papers/1994/N0555.pdf 
Sure, but even if you don't use std::string, the header will still likely to slip in via transitive includes unless you develop everything in-house or very strictly control what third-party libraries do. Also compare how much overhead compilation of &lt;string&gt; adds to your build time. I doubt it's a serious problem unless the rest of your code is really trivial.
I see your point, but (tangentially related) I'm a bit sad that I had to do this *reinterpret_cast&lt;uint32_t*&gt;(reply.data()) to get a uint32 from a void* without using a C-style cast. It's less ambiguous, sure, but it's a bit harder to parse at a glance.
I just wanted to say that I really enjoy your blog. I appreciate the time you take to produce easy-to-read yet informative content, and I sure wish that there were a lot more guys like you writing blogs.
&gt; When WinRT was developer it borrowed heavily from the .NET metadata design. WinRT and .NET work together brilliantly. Except for the memory leaks: https://social.msdn.microsoft.com/Forums/en-US/ecbe74c9-d6ae-4c66-b0f6-6a942451527e/uwp-platform-issue-memory-leaks-in-uwp-c-applications?forum=wpdevelop
so, have you found the binary? 
You probably mean "can answer" ;-) Thanks! I see. So probably it's a relic from the past too (when there were no move constructors) and should be deprecated. There's probably no legitimacy in having both, even though there might be use-cases of unique_ptr where its move c'tor is not needed.
&gt;In the end we native desktop developers are left with no other UI-Option than adding .NET/WPF into the native mix which adds a lot of complexity and bloat to the application. You can use the Windows API directly. No reason to add .NET to the application.
I don't find it very expressive when languages use a lot of these symbols like `~` or C# or something use `^` and this kind of stuff. What does it mean? You have no idea - you need to learn it. It's hard enough for beginners to learn `*` and `&amp;`. It probably just boils down to being able to read easily what you're used to.
Visual Studio Code Allows opening a dir, without setting up any projects. Can parse, understand and navigate C++ even when directories are not set up. (You get better navigation/auto-completion if you do, but it's not required). It's available on all platforms so you can use the same editor/config everywhere. And ripgrep on mac/Linux. I assume you asked about navigating an existing project you're new to. If you mean starting a totally new project, then qmake or cmake (as many other people recommended). 
&gt;setting up proper CPP You only need to install the C++ "extension" (hesitate to even call it an extension, it's pretty core). Navigation is available even without setting up include dirs etc.
You probably want to run the training on something that integrates cuDNN and then just exports the weights. I'm always surprised dumping the weights isn't well documented, but I'd be surprised if any of the Python things didn't allow you to dump them out. I've used the original Caffe and NVCaffe for this, which has a (not all that well documented, but very usable) C++ API to get the weights into our C++ application, and then dump them into a format for our inference engine (which we just wrote ourself).
Much of the fmt library code is comments that are used to generate the [API documentation](http://fmtlib.net/latest/api.html) and don't contribute significantly to compile times. The actual LOC count for the main header is 2.6k and the largest header it includes is `&lt;string&gt;` (for `std::string` formatting support). &gt; Also, if fmtlib is so much code, surely it must have some features your library doesn't have? Glad you asked =). Here are some of the features the extra code brings you: * Full Python-like formatting including positional arguments * Printf-like formatting * Better portability and legacy compiler support including C++98/03 support * Fast concatenation-based [write API](http://fmtlib.net/latest/api.html#write-api) * One of the [fastest available integer formatters](http://zverovich.net/2013/09/07/integer-to-string-conversion-in-cplusplus.html) * Wide string support * std::string formatting support * [Date and time formatting](http://fmtlib.net/latest/api.html#date-and-time-formatting) * [std::ostream support](http://fmtlib.net/latest/api.html#std-ostream-support) * [Formatting of system error messages](http://fmtlib.net/latest/api.html#system-errors) * Format string syntax extensible for user-defined types * Variadic template code bloat prevention Printf, date/time and ostream support are in separate headers, so you don't pay for this functionality if you don't need it.
If that would be true, why on earth there was a need for smart pointers? 😈
Yes it was "can" that I meant :)
Hey thanks !! And don't hesitate to let me know if there's something in particular you'd like to read about.
Smart pointers should be quite rare as function parameters. So if you have this: shared_ptr&lt;whatever&gt; p = ... f(p); and f is void f(shared_ptr&lt;whatever&gt; p) { p-&gt;do_this(); p-&gt;do_that(); } you are making your life miserable for no reason. That f() should be shared_ptr&lt;whatever&gt; p = ... f(*p); and void f(whatever&amp; obj) { obj.do_this(); obj.do_that(); } Smart pointers should be function parameters or return values **only when ownership is moved around, or shared**. I think that a vast majority of function does not do that, they just want objects to play with.
Right, I see what you mean. I agree that unique_ptr doesn't prevent anyone else from accessing the pointer and modifying the object. When you read a piece code though, don't you expect that the owner of a resource (so the unique_ptr) would be more likely to modify it than the other contexts that can access it? Just asking. I'd be interested to know your opinion about the message conveyed by the code, beyond the technical spec of unique_ptr.
0. Should have used `static_cast`. Your cast is not portable. 1. The above should be rare, and if you need to do it too often, chances are, your're doing something ~~wrong~~not in a simple way. To me, this is one of those things: exactly because they are so verbose, I think harder to make better code so that I don't need to do them. For example, your example above comes up when consuming in-memory binary streams. Well, why not: const T&amp; next&lt;T&gt;(void*&amp; stream) { const T* p = *static_cast&lt;const T*&gt;(stream); const T&amp; result = *p; stream = ++p; return result; } and then uint32_t data1 = next&lt;uint32_t&gt;(p); uint32_t data2 = next&lt;uint32_t&gt;(p); float y = next&lt;float&gt;(p); etc. (Better abstractions already exist of course; point is, random casting does not happen easily in clean code.)
You can use `static_cast` in that situation. And the super explicit casts are a nice syntactic wound that screams you're probably doing something fucked up. 
Smart pointers are great, but they are way overused. Function signatures should not contain smart pointers unless you really want to transfer or share ownership.
I totally agree - but I think this is not so rarely the case as you have stated it 😉
&gt;And since you get the ownership, this gives you confidence that you are free to modify the value of the pointed to object. Eh, that's weirdly said. So I pass a reference to this `unique_ptr` somewhere, how do they know they shouldn't modify the pointed-to object? Same for passing `*p` (a reference). `const` is the related concept, but not really to smart pointers.
You are right, of course. My example comes from a bit of code that just reads one uint32 return value from a byte stream coming from the network for debugging purposes. So it's not like it's part of something critical, and I could just as well have used a C-style cast.
&gt; don't you expect that the owner of a resource (so the unique_ptr) would be more likely to modify it than the other contexts that can access it I wouldn't make any conclusions on who modifies what based on the ownership. My C++ experience mostly comes from the Chromium code base and although I didn't try to measure the correlation between ownership and modifications, subjectively it didn't occur to me that it might exist, or that it is even relevant. Usually object A owns object B via a unique_ptr (so that B is conceptually part of A) and exposes B via something like `B* A::GetB()`. Anyone who can call GetB() on A can modify B, in the sense of calling non-constant functions on it. And most of these objects are "functionality" objects, not "data" objects, so the question whether invoking a certain functionality element will modify object's internal state is largely up to the object itself, and not very relevant to the invoker. P.S. I wasn't even talking about technical enforcement of anything, my point is that the very concept of ownership is more about responsibility to maintain and eventually delete a resource, not about freedom to do whatever you want to it.
I have an application where converting doubles to text is a serious bottleneck (times counted in minutes, and 90% of the time spent on converting doubles to text). You wouldn't happen to have any pointers on fast implementations for that, would you?
Please elaborate, what do you mean with "Windows-API"? Win32? I talked about developing a modern UI with responsiveness, transition effects, fluent-design, ... there is no Win32-API for that! You would need to implement your own framework using low-level API like GDIPlus, Direct2D etc.
I'd very much like to see language support for this some time in the future. That being said, it's rather hard to emulate in code. I've actually been tinkering with it recently: https://gist.github.com/mechacrash/d345e653a3c7880d8fde47b0e6439f3a and https://gist.github.com/mechacrash/39bba179dcb23f47cbd4d5c44924e976 (please keep in mind, this is toy code, it sucks, it's messy, it's unfinished, etc.) compile-time composition of switch/case would be very powerful. It would allow compilers to make the same optimisations they currently do (generation of a jump table, function combination and splicing, etc.) while allowing programmers far more expressive code. I'd love to hear if anyone else has been working on something like this and see what they come up with. I'm mostly using this as an excuse to try new C++17 features!
The point of long names for casts is exactly for that: harder to parse at a glance. You don't want casts like that to be ignored or go by unnoticed. Using `reinterpret_cast` could just as well mean code smell (could trigger undefined behavior), and I'd rather really not glance over it.
As a workaround, generation of several if statements could be used: `std::initializer_list&lt;int&gt; ({(i == Is ? (ret = h&lt;Is&gt; ()),0 : 0)...});` it seems clang even able to generate switch table in this case: https://godbolt.org/g/ryZtwn
This is a link to a training seminar, not a blog post.
You make a very good point.
[Take a look at dyno.](https://github.com/ldionne/dyno)
https://github.com/google/double-conversion &amp; https://github.com/miloyip/dtoa-benchmark
This comes up every now and again on the std-proposals list; recently https://groups.google.com/a/isocpp.org/forum/#!searchin/std-proposals/variadic$20switch/std-proposals/e6zXuQryeCw/QfpW3RNbCQAJ (and there's plenty of links to previous discussions there as well). As far as I'm aware it's never gotten further than an idea; no-one has so far taken it as far as writing and presenting a paper.
thanks, certainly interesting; but I think thats runtime-polymorphism only (i'll take a look in detail, i imagine it boils down to creating interface objects) - what I'm really after is the ability to add compile-time resolvable member-functions outside the class, e.g. bolting more helper functions onto std::vector or whatever (inheritance doesn't cut it)
You're taking the table-of-function-pointers approach? It's elegant, but unfortunately it doesn't appear to be transparent to optimizers (clang or gcc). The preprocessor approach is horrible but has better code generation at present.
`std::visit` is complicated because it needs to support visiting multiple variants at the same time, e.g. `std::visit(visitor, variant1, variant2, variant3);`. I'm not sure to what extent variadic switch case can help.
Now maybe it's my understanding of the smart pointer and the language that is lacking but won't the constructor in class House { public: House(std::unique_ptr&lt;PileOfWood&gt; wood); ... attempt to make a copy of the unique pointer given as an argument, which is forbidden?
I stand corrected...
Sounds similar in spirit to my [formatxx](https://github.com/seanmiddleditch/formatxx) library, though with some different trade-offs. In general, it looks to have almost identical core concept. formatxx ended up needing to grow `wchar` and `printf` support for back-compat for a large commercial codebase I have to support, which sadly did add a deal of complexity. It still needs some cleanup to external interface before it'd be something I'd consider "ready for the public" but it's definitely battle-tested and hardened. Performance and compile times were both key motivators. We were replacing boost.format, and found fmtlib essentially unusable for us (due to a combination of its error-handling semantics, it's compile overhead, and its reliance on STL types) so it's basically a heavily stripped-down version with a refocusing on what we care about.
A lot of game developers are _extremely_ specific about avoiding those transitive dependencies on the STL. (Not all, certainly; we definitely use it.) One of my projects coming up is going to involve a lot of search-and-destroy for code relying on those headers so we can nuke them. Using `&lt;string&gt;` or the like in translation units that have a dependency on a third-party library is one thing; it's not like we need to include Scaleform or whatever in every TU. Most of the code is all gameplay, graphics, physics, networking, etc. which has zero need for STL strings, doesn't make extensive use of third-party libraries (outside a few specific TUs, again), and uses our own containers with a plethora of advantages in our uses over the STL containers (e.g., our completely reimplemented `vector` which exists solely so it compiles faster and has less overhead in unoptimized debug builds).