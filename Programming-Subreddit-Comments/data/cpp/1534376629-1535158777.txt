Well in that case, I think the best for you is to go for Java on Intro to CS and talk to the professor of Data Structures and see if using Java is acceptable (there is little reason for not). If they want to assess your knowledge of data structures, the language is of little relevance.
Yeah but it also have been several years that reflecion have been in the work. I mean it's either fast and probably wrong, or long and less wrong. I understand the frustration though.
I said in the language, not in the compiler.
We're sorry you hit this bug and other issues in the past. Right now we're gathering more data points to assess servicing 15.8 with the fix for the particular constexpr bug you hit. As you yourself noted, even patch fixes carry their own associated risk. In particular, we're wondering about the extent to which it broke your constexpr callback mechanism. This bug manifests with 1. a local constexpr symbol initialized by 2. a constexpr function taking an rvalue pointer-to-member-function of 3. a class with multiple inheritance. In your own codebase, were either of those workarounds possible to use? We appreciate your candid feedback.
I usually give up on builtin C++ enums and roll my own solutions instead, which is kind of annoying. 
Apologies for the spam. This update to CLion EAP via the Toolbox trashed my VMoptions back to default, and performance is quite unusable. It's at `370M of 2195M` for the bottom mem usage window and clion is taking up `25% cpu` consistently in Task Manager. I will be taking the opportunity to play some more with vmoptions and stress-testing. The default config of `-Xss4m` is way too high. I immediately got "out of memory" errors from Clion via default configuration. `-Xss256k` immediately solved that issue. My testing method is: Note cpu/mem usage -&gt; Change 1 option -&gt; Invalidate caches, restart CLion. -&gt; note new cpu usage -&gt; reset config item 
We have a pre-commit check that any single-argument constructor must be marked 'explicit'. There might be a way around it for cases where you really did want an implicit conversion, but I never needed to reach for it.
No std::net (C++20 maybe no std::net) No std::net::http 
Again, it‚Äôs not true. Read carefully: the language standard certainly does allow a compiler to provide extensions that don‚Äôt change the meaning of standard-compliant, no-UB-having code. 
Must variant stay as a library feature only? Why not add support of full featured language sum types in the future?
So you would like to treat conversion from string to string_view as an error? If thou ate talking about conversion from long long to int, most compilers will all ready emit a warning, that you can treat as an error.
Good point. üëç
&gt; `&amp;&amp; Ret &lt; Number` Why do people keep doing this?
I kind of don't want any of this. C++ has too much syntax already. All I really want is a standard ABI. Can we get a standard ABI some day? 
To be honest, that sounds like overkill. With restrict you simply add a qualifier and scope the restricted pointers appropriately. I can't think of a case where I've used restrict where it would have been useful to specify limited aliasing. It sounds a bit much like MSVC's __assume(), which in theory allows for informing the optimizer of arbitrary assertions, but in practice is only good for __assume(false) or asserting that a pointer is or isn't null, since it isn't specified or guaranteed that any other expression will do anything. The ranges covered by a pointer may also be unknown to the function, such as a generic lookup routine. 
I'm sorry to say, but the standard will never be clairvoyant.
Should this compile? special_int length1 = 1; special_int length2 =2; special_int lengthSum = length1 + length2; How about this? special_int id1 = 1; special_int id2 =2; special_int idSum = id1 + id2;
This is not the first time it happen to me I have submitted pleanty of bugs. I am not been a troll here. Could you guys opensouce your test suit so that people can contribute. And btw this time the compiler crashes with very simple constant expression functions. 
Is it spam?
No. The constructor would be explicit which means you would need to construct it from the int explicitly if that's how you wanted to create the special_int. Also, the 2 examples you gave are identical?
&gt; it's most likely a breaking release. Finally, let's hope they don't forget to fix the std::deque (which I was told would happen at the moment of an ABI break) and drop boost::deque (another one bites the dust).
STL said it's not an ABI break, so no EBO, no `deque` fix, etc. üëé
WTF, when? back to boost::deque, the deque is a great container, but the vc-one is just, nowadays, no good.
I think that's a reasonable path forward. I'm reminded of lambdas, actually. Boost did a lot of work to make lambdas as a library feature, and that works well enough. But that process taught that lambdas should not be in the library, they should be in the core language. Looking back, that was the right way to go. For `std::variant`, the decision was to keep it as a library feature ... but experience is showing that this might have been a mistake. I don't think it's too late to deprecate it and make something better. What I object to is the idea that to much is being done in the standard library in general. While this is a counterexample, the language as a whole is better off if most things stay out of the core language, even if individual features might be better in isolation.
Running your lambda through a shitload of TMP machinery is not free. `()` is clear enough for me and works with `constexpr` and doesn't _murder_ compile times.
&gt; Floating-point std::from_chars() is now available in C++17 &lt;charconv&gt; and is approximately 40% faster than the UCRT's strtod/strtof. It has been extensively audited for bitwise correctness (with no bugs found, in either charconv or the UCRT). fluentcpp wrote about this, he was very enthousistic (and so am I).
Syntax wise yes. Functionality wise that's up to you and how you want your id to operate. There is no such thing as an "id" in C++ so it's up to you to say if 2 things you call an id can be added or not. All it would be telling the compiler is: this walks and talks like an int but can't interact with ints.
I'm not following you. The standard says assignment operators should copy everything in the class/struct or move everything in the class/struct. It can just as easily generate an operator&lt; that compares everything in the class/struct using &lt;. I'm saying I want the compiler to do that for me if I tell it so. Something as simple as: bool operator&lt;(my_class&amp;) const = default;
That's neat. I'll have to try that out. I'd still prefer it was some existing type_trait implementation but that's at least generic enough that I don't have to re-write it for every usage.
&gt; in the meantime, use &lt;ciso646&gt; for the same effect ... I see that &lt;ciso646&gt; will be removed, will the alternative operator representations move to &lt;version&gt;, or are they just going the way of the dodo. I would regret that as with the advent of universal references, there are just to many `&amp;&amp;`'s and writing `and` just strips out the ones that aren't ur's. 
It wouldn't cause bugs, it would cause undefined behaviour. And this type would undoubtedly allow for quite a bit of performance improvement as well. This once again seems a case of C++ choosing the wrong default. The grandparent is right: the vast majority of functions never get any aliasing pointers. The tiny minority that needs them should be marked up with `[[may_alias]]` or something similar. 
How would that improve things? What do you expect to be able to do that you cannot do right now?
&gt; It wouldn't cause bugs, it would cause undefined behaviour. These usually go hand-in-hand.
How would the compiler know how you want to compare user types? It's simple for wrappers with single members but if you have a Person class with 10 different variables including strings and books, how should the compiler know how to compare them?
Arguably, while id's technically aren't really numbers in the sense that you'd want mathematical operations on them, in practice you will still end up with various tasks that needs them anyway. Things like finding the maximum of all present id's plus one. 
Extremely hard to debug bugs, that is!
Also, pretty much every expression involves an implicit cast from an lvalue expression to an rvalue as many work with an rvalue. 
&gt; It wouldn't cause bugs, it would cause undefined behaviour. Unless your compiler's manual defines its behavior (which would make restrict pretty useless) UB is always a bug. &gt; And this type would undoubtedly allow for quite a bit of performance improvement as well. Have you any measurements on real world applications that supports this claim?
Yep. That was my issue as well.
If you have something like using distinct special_int int; You could do something like: printf("value: %d", static_cast&lt;typename std::underlying_type&lt;special_int&gt;::type&gt;(my_special_int)); 
You wrote a ton of words about it but I still have absolutely no idea what it is.. even after reading your response to the top comment. 
Binary-stables interfaces is a concern for interfaces, the language is irrelevent. Is it common? I've worked in places where breaking interfaces could be a career limiting move. I can still run an app written on a Win95 machine today on a Win10 machine. That's because MS take it seriously at least.
It is very sad, that `await` is still a keyword when the code is compiled with /await flags, even the TS states for a long time that the keyword will be co_await. Even under /permissive- this version reports still errors. Gor wrote to me a while back that this would be fixed in 15.7.0, but it seems it is still not. I just flagged this [bug report](https://developercommunity.visualstudio.com/content/problem/312318/c-await-is-still-a-keyword.html)
The problem I see with `restrict` is: Where would you put that in modern C++? You usually don't have any raw pointers anymore, but `array`, `vector`, `unique_ptr` etc. You'd need to define semantics of `restrict` for those too, which would be hard.
I rarely use pointers or non-const references in my C++, so... actually, probably not. Would still be nice to have in the standard, though, for those who do.
 bool operator&lt;(const Person&amp; other) const { return this-&gt;firstName &lt; other.firstName &amp;&amp; this-&gt;lastName &lt; other.lastName &amp;&amp; this-&gt;dateOfBirth &lt; other.dateOfBirth &amp;&amp; this-&gt;gender &lt; other.gender &amp;&amp; this-&gt;address &lt; other.address; } If that's not what you want: define it yourself. If all you want is to be able to put it in something like std::map and have it compare unique if all values are unique then it "works out of the box."
The language matters because of name mangling. Those are C interfaces, though. Even the IWhateverInterface is COM faking it, isn't it? I've never had the pleasure of working with it or having to maintain compatibility for that long, so correct me if I'm wrong.
The Standard doesn't permit deque&lt;T&gt; to be given incomplete T.
For expressions not involving named function calls, [the placeholders](https://www.boost.org/doc/libs/release/libs/hof/doc/html/include/boost/hof/placeholders.html) in Boost.HOF work nicely and don't kill compile-times too much.
Yes. I mentioned `const` because `const` itself does not help compiler optimization but compilers do analysis to on both `const` and non-`const` variables to check if a variable is modified or not, and optimize it if possible.
I figured. Although if that sizeof(T) wasn't there it technically works fine :D (at least the MSVC version does).
Actually you took Iain's response too literally, and he criticizes your intended meaning (the one visible in code). It makes a lot of items incomparable. For example if two instances have the same firstName, but one person has bigger lastName and smaller dateOfBirth, then neither A == B nor A != B is true. Actually none of the comparison operators will return true. So I don't think it would work well with map at all. Better option would be to create lexicographical order if having any order at all is what you seek. But again it would be very error prone to have such implicit order. More so that such comparison would depend on order in which members are defined. The other problem is that comparing pointers that don't point to the same array/object is UB so it doesn't have well behaved operator&lt; logic.
Using lambdas like that is a great way to initialize const variables, regardless of the "if".
I understand your pain, but `std`stuff like `std::variant`has to work for basically every corner cases, thus the bloat (although hopefully it should be reduced if all the parameters are simple enough, maybe we'll see it in later implementations). It's a bit like the enum situation: while it's rather simple to write enum-to-name for an enum like `enum class DayOfTheWeek { Monday, //...`, they have to account for cases like: `enum class MyValue{ Value1 = 1, AlsoValue1 = 1, //...` (which mean some transformations won't be bijections, etc.) Hopefully the refection stuff will allow, though I fear about the interface.
Nice ad hominem. You know nothing about me or what I have worked on and for how long.
Bah yes I meant lexographical ordering. I‚Äôm so used to writing equality operators I wrote the example less operator wrong.
I suggest you edit your post with "using the lexicographic order" or: return std::tie(this-&gt;firstName, this-&gt;lastName, this-&gt;dateOfBirth, this-&gt;gender, this-&gt;address) &lt; std::tie(other.firstName, other.lastName, other.dateOfBirth, other.gender, other.address); The others posts' disagreements stem from that. My 2ct: default-contructors added implicitely was a bad idea, make them opt-in. (`bool operator&lt;(const Person&amp; other) const = default` would be necessary activate the operator)
I see 2 ways enum to string would have to work: one is compile time and one is runtime. Compile time can handle if you have multiple enums with the same underlying value and runtime can‚Äôt. It could reject compiling or just give back the first name. I don‚Äôt see enum to name being useful when you have multiple enums with the same value. You‚Äôve essentially said you don‚Äôt want a name mapping at that point.
Hello, Thank you for your reply ! For the moment shiva is simply a game engine on which you can attach / load systems. These systems are the logic of your program. So your program will depend on the implementation of your systems.
&gt; I'm really wondering if you've ever worked on any non trivial software Same reply as [this](https://www.reddit.com/r/cpp/comments/97ct55/have_lambdas_helped_you_write_better_c_how/e4a6gwr/) guy. Feel free to stick your ad hominem where the sun doesn't shine. I have not once mentioned your evidently subpar understanding of C++ design patterns: we're neither in r/Qt nor r/ObjectiveC here. &gt; If you consider a separate subclass for every button handler a viable approach ... he said, while implementing a function for each of the actions triggered. &gt; it's also that you need to propagate context to those handlers, scattering the logic across multiple places just to get around language limitations You're doing literally the same but either your ego doesn't let you realize it or, worse, you purposefully deceive. You're calling outside functions instead of member functions. You're using a signal-slot pattern in a language that wasn't designed with that goal. All the while introducing an external library that's not even part of the standard. And you **dare** to claim that my 40 line example is complicated while telling me that your code - which needs about 5 files just for the environment to make it work - is verbose? There's a good reason your "example" isn't backed up by a cpp.sh link. Give me a break. &gt; [excaliboor's example is] not just that is verbose &gt; I never called [airflow_matt's example] clear So you insult my work, get on a high horse and pretend to do a better job, and then admit your own job is as "bad" as mine. During all this time you keep talking about C++11, pre-11 limitations, and lambdas - changing the subject to make your argument seem stronger. This is not about lambdas nor C++11, stop diverting the topic. This is about member function pointers. They are an anti-pattern and code smell. Considering that we both agree that lambdas are the modern way to go, I'm done with this thread.
This is about defaults - just as the default generated assignment operator doesn't always exhibit the semantics you want for your particular type. If you want something different, than the default you write your own. Details don't take away your ability to write your custom comparison when needed. FYI: Default comparison with actually be introduced in c++20
&gt; I don‚Äôt see enum to name being useful when you have multiple enums with the same value. You‚Äôve essentially said you don‚Äôt want a name mapping at that point. Indeed, it's normal to have a downgraded behavior in such case, but I guess they hesitated on the proper working, because they would still need to implement one (you would need at least 2 size; and would you iterate on the names/symboles, or on the values - or pairs of those). But yeah, It's something I've wanted for a long time too, good thing I'm using Qt at work.
Well we can hope that some compiler rolls an early implementation like they did with modules.
Name mangling is one part. On embedded, due to binary file size requirements, you may only have the optional of linking by ordinal. Best of luck if exported functions get rearranged. Adding a field to a struct? sizeof() returns a different result now. Adding a virtual function? Same thing. Everyone using your lib will have to recompile. Change function arguments? Bang, your customers are dead. Blood, sweat and tears indeed. The need to maintain BC can turn a simple one-liner bug fix into a very emotional journey instead. It's really impressive that Microsoft have pulled it off so well.
What /u/dodheim said already.
The "what's wrong with it" is regarding refactoring - what if another field is added? The `operator&lt;(...) = default` would be so much better in that regard.
&gt; No user-defined built-in types &gt; &gt; Yes I know the name is a contradiction. A user-defined type that walks and talks like a built-in type but is not one of the built-in types purely for compilation purposes. Simply put: I want to make "special_int" where it is an int from the code generated perspective but it doesn't interface with standard ints. The thing you describe here has been referred to as *strong type aliases*.
Just updated to 15.8 and found that if constexp still does not work with enum classes well. Here is the issue I posted several months ago for 15.7: [https://developercommunity.visualstudio.com/content/problem/267419/if-constexpr-enum-underlying-type.html](https://developercommunity.visualstudio.com/content/problem/267419/if-constexpr-enum-underlying-type.html) # 
I'd *far* prefer lack of potential aliasing to be specified via contracts rather than `restrict`. `restrict` is a sledgehammer. I'd like to be able to tell the compiler that parameter A might alias B, but will never alias C, for example. Or that parameter A will only ever alias parameter B plus fixed offset X. Incidentally, WG14 are strongly considering importing contracts from C++ into C. I suspect they'd endorse a better `restrict` there too. Finally, I'm not sure the `expects` contracts clause is the right one. Expects implies checking may be done at runtime. What you really want is a new contracts clause, `assumes`, which guarantees no runtime checking unless in audit mode. Chances are high I'll be proposing `assumes` next year in any case, so I can write `assumes: clobbered(data, length)` and such for LLFIO.
No package management/build system complaint though.
Yes, and there's a way to implement that already. In a way that let's everyone create an int-like type that behaves exactly the way they want it to.
**Company:** [Wikitude](https://www.wikitude.com/) **Type:** Full time **Description:** Wikitude is the leading augmented reality platform for phones, tablets, and smart glasses with over 1 billion app installs. Our main product, the Wikitude SDK enables developers to create cross-platform AR apps with Image Recognition, Object Recognition, Location-Based AR, Instant Tracking and other exciting AR features. *Your role:* You will work on Wikitude‚Äôs C++ based core SDK as well as on the Android native implementations. Responsibilities will include all aspects of software development from design to coding and testing. *We're looking for you if you have:* * Applied and proven experience in developing software * Excellent knowledge and experience in C++ *Answering YES to one or more of the following statements will be considered a plus:* * Experience in development for mobile operating systems (Android) * Experience in 3D render engines * OpenGL and 3D programming * A passion for apps and development for mobile platforms **Location:** Salzburg, Austria (English as working language) **Remote:** Possible for highly qualified candidates. **Visa Sponsorship:** No - must have EU working permit. **Technologies:** We use C++11/14 on Mac mainly, while we run the software also on Windows and Linux. Some internal tools are written in Python and depending on the platform you work on you will be in contact with Java (Android), Obj-C (iOS), C# (Unity). Any additional experience in any of the following will be beneficial:‚Ä¢ OpenGL/Graphic engines etc‚Ä¢ Development for mobile OS (Android, iOS, UWP)‚Ä¢ JNI **Contact:** Interested? We look forward to getting your CV and answering any questions you might have via the email [jobs@wikitude.com](mailto:jobs@wikitude.com)
And this code breaks as soon as you add something that should not really be considered part of an objects external state. There's a reason auto generation of copy ctor/assign is deprecated under certain circumstances.
But how often do you really end up with a type that you actually want to behave exactly like an int? My ints usually represent something, and that something determines what operations I want to allow on them, which means I rarely want them to be represented as something int-like. If you want to have your special_int, just go implement your special_int template, and then you can instantiate as many different special_int types as you want in one line of code: using id = special_int&lt;struct id_tag&gt;;
/u/Rseding91 /u/patatahooligan These look really simple and useful void f(explicit int); using explicit volume_litres = double;
Library can jump as high as it afforded by language. While cpp will have this prehistoric preprocessor, messing around with libs are waste of time.
Fixed it; I had over simplified it.
&gt; Same reply as this guy. Feel free to stick your ad hominem where the sun doesn't shine. I have not once mentioned your evidently subpar understanding of C++ design patterns: we're neither in r/Qt nor r/ObjectiveC here. ObjectiveC has no signals and slots; It does have blocks though and selectors; Qt needs preprocessing through MoC (at least for older compilers that can't compile verdigris), libsigc++ is pure c++ that has versions usable pre c++ 11, which was what my original post was about &gt; You're calling outside functions instead of member functions. What? Nope. I'm calling member functions. Just what do you think sigc::mem_fun stands for? First argument is instance, second is function name. Those *are* member functions. And they have access to the rest of the class members and thus share the same context. Unlike your example where every callback subclass is separate, you need to propagate the context and also manage lifecycle of another three objects. &gt; So you insult my work, get on a high horse and pretend to do a better job, and then admit your own job is as "bad" as mine. Just because I don't think sigc++ especially version predating variadic macro support was particularly clean it doesn't mean I consider my example as bad as yours. Nowhere near. So it needs another library to work? And? Button will need another library, thread pool and run loop will need another library. But adding a library to project is something you need to deal with once (or perhaps once per platform), but writing separate subclasses for every tiny handler in your code will go through out your entire project, just because you ignored all more practical and scalable solutions while clinging to a first semester OOP design pattern. &gt; This is not about lambdas nor C++11, stop diverting the topic. Yes it is. In comment above I specifically said you don't have the luxury to consider pointer to member function code smell in pre-lambda c++. And then I backed it with concrete examples where pointer to member functions make things significantly easier in situations where you don't have lambdas.
no on both counts
That's what I mean. What we need is a standarized way to import/export API and a better dependency model than includes.
Disregarding the fact that you're bringing another language on a C++ related thread, I have to ask. Why are you importing stuff right in the middle of the function? Why do you need to do `if(is(T == enum))` instead of simply `if(T == enum) `? (Is that what concepts look like in D?) This also looks like a rather poor implementation of enum to string. You should have a way to get an element from `EnumMembers!T` (ideally this woukd be a map) in easier ways than looping over everything. `return __traits(allMembers, T)[I]`? And last but not the least concerning: `assert(0)`?
&gt; Edit: found the post of [the story I related above](https://blogs.msdn.microsoft.com/oldnewthing/20050412-47/?p=35923). "Hello, this Raymond calling from Microsoft. Our systems indicate there is a problem with your computer" I hope he didn't ask for the user to install TeamViewer!
&gt;conversion to string is already possible, you can define functions and operators for your `enum class` (for example `to_string`). This is always the default argument for requests like this. Yeah, of course I can write my own functions, because C++ is a programming language. The question is why doesn't the language provide safe and efficient functions for tasks like this, but lets everyone write their own?
Assuming you're looking to make some cash the MS Office suite might be a good bet, I know plenty of people that got mildly rich that way... granted, it's probably not as profitable nowadays. Some game engines might also work, for example Unreal.
Apache, nginx?
There are many (Googling for "C++ SDK" or so might be a start) Anything specific you are looking for?
What I'd really like is __the__ right way on writing install targets. When I was researching on writing install targets, basically every repository I examined had its own way of doing it...
std::experimental::is\_detected is almost as easy as the std::has\_function suggestion you proposed. Adding to the library vs compiler, it would be great if both is\_detected and enable\_if where to be implemented by the compiler in order to speed up compile time.
 Correct. However our usage is with a 75 type variant with near the entire code base interacting with that at some level. We just don‚Äôt use variant in most places because it‚Äôs overkill most of the time or has performance problems.
Have you looked at Boost Hana? http://boostorg.github.io/hana/index.html#tutorial-introspection-is_valid
The day we removed our last dependency on boost involved ‚Äúmuch rejoicing‚Äù so unless boost::hana managed to make something better than sliced bread we‚Äôre steering clear of the compile time abomonination that is boost :)
Most music production software (Ableton Live, Cubase, Pro Tools, etc) allow a few different types of Audio and Midi plugins. I've used [JUCE](http://juce.com) to good effect to write audio plugins and can't recommend it enough.
I think this question is best asked on r/cscareerqustions. While it's certainly *possible* to earn that on the internet, it's unlikely. Most C++ shops will want you on-site, especially if you don't have much experience. C++ is not a language that one can get good at in just 60 hours of study and consequently you're likely to be required on-site for further mentoring and training.
I'm not talking about any of that. No contracts and full time stuff. You perform a task, you get paid via Paypal. 
&gt; what do you think sigc::mem_fun stands for an anti-pattern
&gt; all of the bloat that std::variant has By "*bloat*" you mean correct behavior rather than making arbitrary assumptions about types as your variant does?
Why would you work outside an IDE? Even people I've seen working with vim always have it configured to emulate modern IDE behaviours and Features... I don't think it's a reasonable argument.
IMO a common build interface should be quite simplistic and leave it up to the build system and/or package manager to figure out dependencies, versioning, compiler/toolchain choices, target platform etc etc. I would really like to see your approach and which philosophy you are starting from! Do you have anything ready to be shared?
`&lt;?php echo "System" ?&gt;` correct spelling is "ecosystem".
I think the Itanium ABI was supposed to be this, but of course MS wants to do things their own way. Sure would be nice though; it‚Äôs obnoxious to have to wrap everything in C APIs. 
Whether you need or not, how would you test your plugin without the software?
Does it have to be commercial? Sometimes I browse GitHub and set the language to C++ to find interesting libraries, I‚Äôm sure you could find full apps to work on that way. Nothing‚Äôs stopping you from writing C++ and interfacing with a C API either, so something like the gimp could work. Idk it‚Äôs hard to say without narrowing it down a bit based on your interests. Even stuff like the Windows shell has a lot of customization points, Stardock has made a business of this, and there‚Äôs Rainmeter for open source.
Congrats on the 15.8 release. I've successfully tested on both code at work (maybe half a million to a million lines, if I had to guess) and at home (about 100K lines) with no problems. In general, I've been extremely pleased with the VS team since the low point - in stability and UX - of VS 2012. I've been using your compiler and IDE professionally since Visual C++ 5, so I have quite a few versions to mentally compare against. In general, I like the faster cadence of releases the past few years. Bugs and regressions are nothing new, unfortunately, especially in a product this complex, and while I'm not excusing them, I understand how difficult it must be not to introduce them in corner cases. You're probably more likely to hear from people when they're reporting bugs, so I just wanted to let you know I'm quite pleased with the way Visual Studio / C++ team is making forward strides in adding useful features, addressing issues, and improving compliance with the rapidly changing C++ standard. 
I've written Markov chains that make more sense than you do.
Return nothing 
In thinking further about this, the predicate we want is probably `disjoint`, and would always be used in the affirmative. The thing compilers want for optimization purposes is to know that distinct arguments have no overlap, so they can transform loops that operate on all of them without losing hidden data dependences.
/u/kalmoc, I think we're in agreement - right now, I believe that `restrict` is necessary for that, contrary to the claim /u/umCCCS made that those arguments being different types would be sufficient to infer the lack of aliasing.
Cereal does not, as far as I know, support optional json members.
Sorry, I meant to reply to your post one further up (about restrict nor being well specified). I do however agree with you that TBAA is not at all a substitute for `restrict`.
Pardon my ignorance, but what is dev16?
But it will. The C++20 draft has integrated Herb Sutter's "Consistent comparison" proposal (aka spaceship operator). One of its features is the ability to "default" the operator: `... operator&lt;=&gt;(const T&amp;, const T&amp;) = default;` This of course comes with the usual caveats regarding defaulted functions - sometimes they do the right thing out of the box, sometimes they don't. When the default version does what you need then you can save yourself the trouble of writing it out. This isn't really different to the assignment operator. 
How would this work vs this current code to add boost::optional support: namespace nlohmann { template &lt;typename T&gt; struct adl_serializer&lt;boost::optional&lt;T&gt;&gt; { static void to_json(json&amp; j, const boost::optional&lt;T&gt;&amp; opt) { if (opt == boost::none) { j = nullptr; } else { j = *opt; // this will call adl_serializer&lt;T&gt;::to_json which will // find the free function to_json in T's namespace! } } static void from_json(const json&amp; j, boost::optional&lt;T&gt;&amp; opt) { if (j.is_null()) { opt = boost::none; } else { opt = j.get&lt;T&gt;(); // same as above, but with // adl_serializer&lt;T&gt;::from_json } } }; }
Isn't that largely because of the rather ill-advised visit thing, though? std::variant at its core is just a union with better support for constructors and destructors. I don't see how that could cause significant overhead. Maybe I'm just using it wrong? In variant-using code I usually just switch on variant.index(), rather than trying to painfully switch on type. But then, I don't try to emulate inheritance by stuffing huge numbers of classes into a single variant...
The next version of VS. It's currently Dev15.
Can you explain how it works? All you set is an attribute [[interesting]]?
Aww ... now it's approaching all of the other solutions I found in size/complexity.
But then you can pass special_int to something taking int/float and it compiles when it shouldn't.
Rhino 3d
Sure, author here. tinyrefl is another case of a libclang based reflection library for C++, but I focused the design of the library so that metadata parsing and generation is not tied in any way to the user facing reflection API, actually the provided API is completely optional. The idea is that the parsing and codegen tool is one thing, and the API is other thing. The generated code describing reflection metadata is written as C/C++ macros, which users can give different meanings. The provided static reflection API is just an example of this, but the project has more examples, like a Boost.Fusion adapt struct example backend, or a Boost.Hana adapt struct backend. My idea is that anyone could integrate reflection metadata in the best way for them. For example, if you're interested in enum to string conversions only, it's fine, write a backend (The set of macro definitions) that does just that. The project also includes full CMake integration so that integrating the codegen tool in existing CMake projects is as simple as invoking one function. The CMake integration does all the work (Find compiler options, include dirs, dependencies, etc) for you. Finally the provided reflection API is (or should be, please report an issue otherwise) fully constexpr, with utility functions ranging from member variable visitation of an object to serialization from/to std::tuple. BTW for people who does not know cppast, cppast is a C++ wrapper of libclang by /u/foonathan that does a great job hiding most, if not all, of the pain of using libclang.
&gt; I understand your pain, but &gt; `std` &gt; stuff like &gt; `std::variant` &gt; has to work for basically every corner cases, thus the bloat (although hopefully it should be reduced if all the parameters are simple enough, maybe we'll see it in later implementations). At the same time, one of the tenet of C++ is *you don't pay for what you don't use*. 
(in C++ &gt;= 17). Personally I'm fine with IILE/IIFE idiom, everything looks unfamiliar until you've seen it used a few times.
&gt;If you can parse code and generate code... that's enough to create reflection. Exactly, I would love if more people get into writing custom C++ tools with libraries such as cppast. 
The output should be human readable and pretty ‚Äî I always make those things output code such that you could abandon them at any time. But the build process complication is IMHO always a strawman. Come on, how hard is it to add an extra custom tool step in any environment you can think of: it‚Äôs very simple in VS/msbuild, plain makefiles, cmake, qbs, qmake, scons, heck even oddities like aegis don‚Äôt make it hard at all. It‚Äôs a few lines to add the tool and build step in all cases, pretty much. Almost any non-toy project will use a multitude of tools during the build and that‚Äôs not something to worry about. It‚Äôs normal and should be leveraged not dreaded. 
I just hope that the existence of std::variant won‚Äôt make the committee passive (or even hostile) to introducing sum types as a first class language feature...
Unity 3D and Auto Desk Fusion 360 are 2 that I can think of
I'm not on Twitter, but I'd like to go to meet some [East const'ers](http://slashslash.info/petition). "We few, we happy few."
&gt; AKA Concepts. This will be included in C++20. I'll believe it once it's published. Concepts were for some time part of C++11, heavily implied to be a part of C++14 by multiple people after that, definitely promised for C++17, I've lost any trust in the committee that they won't vote it out before publishing again.
There are dozens of us!
The issue with those is that this is an idea that sounds good on paper, but if you look closer at it, you will find that it is inherently impossible to provide that in a meaningful way. The closest thing you will ever get is one that we already have: `enum class mytype: std::uintXX_t{};`. This is REALLY not a limitation of C++, it just that the semantics of something like it will not add up. For practical purposes, you can write libraries that provide it for the cases that you will likely care about, however. I've written [this one](https://github.com/Florianjw/type-builder) a couple of years ago. (Just saw the naming-scheme of the enum-constants, yuck! I was young(er) and inexperienced!)
This, along with a standardized build system and package manager, would truly modernize the language.
FYI, you can self-assign user flair to identify yourself as a Boost dev. See https://www.reddit.com/r/cpp/comments/4tm8k9/user_flair_is_now_available/ for instructions.
What if you have two smart pointers that don't alias? How'd you use `restrict` there? In C++ trend is to move away from raw pointers.
Thanks!
Totally, I didn't talked about it, but I feel we're going somewhat away from that (I believe `std::shared_ptr` has some mandatory mutex, which is a performance loss in a mono-threaded software). Although maybe it can be fixed for `std::variant` internal (but not the API)
No, C++11 has C99's fenv library, but not the core language required to support it. It also happens to be one of the two C99 features ignored by both gcc and clang, so it doesn't seem to come up.
&gt; In your own codebase, were either of those workarounds possible to use? Sadly these bugs don't happen in my codebase but in one of the libs I use (https://github.com/woboq/verdigris). I *could* spend one hour or two to fork it and change all the places where it is used but I think that I'll just stay on the previous release of VS for now.
Looks like an issue with the \_\_underlying\_type intrinsic and constexpr if. An easy workaround could be something like: ```c++ template &lt;typename T, bool b = std::is_enum_v&lt;T&gt;&gt; struct underlying_type { using type = std::underlying_type_t&lt;T&gt;; }; template &lt;typename T&gt; struct underlying_type&lt;T, false&gt; { }; template &lt;typename T&gt; using underlying_type_t = typename underlying_type&lt;T&gt;::type; ```
Ok. Thanks. I remember seeing it on cppreference and then in some recent patches to clang so I wrongly assumed that it was also for C++.
&gt; you're bringing another language on a C++ related thread Since a number of features of D have found their way into C++ since C++98, I felt it was apropos. &gt; Why are you importing stuff right in the middle of the function? It's a common technique in D programming, the idea is to minimize the scope of all symbols in use. &gt; instead of simply if(T == enum)? The [`is` expressions](https://dlang.org/spec/expression.html#is_expression) can do a lot more than just equality. &gt; in easier ways than looping A fair point. The __traits is a general purpose tool in D, not something specifically created for enums. It's used for all kinds of unanticipated purposes. One could also use the metaprogramming capabilities of D to turn that loop into a switch, which would be efficient at runtime, without changing the core language. The idea is that with adequate metaprogramming and introspection features, core language features are less necessary. &gt; assert(0); If that is reached, that means the value was not one of the valid values of that enum, which presumably would be a programming bug.
!removehelp
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/97rrhp/what_commercial_application_allowing_write/e4bfcmd/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
&gt; recent patches to clang wow, is someone taking on https://bugs.llvm.org/show_bug.cgi?id=8100 ?
std::shared_ptr uses atomics as far as I know. Not that that's any better if you don't plan on using it in a threaded environment.
Yeah, that's it. There were also issues with earlier `std::mutex`implementations: https://stoyannk.wordpress.com/2016/04/30/msvc-mutex-is-slower-than-you-might-expect/ so, for `std::variant`, we may need to wait a bit for such bloat issues, though it may be too complex. IMHO it's the issue of the " you don't pay for what you don't use" - the cost is `runtime`cost, but that created a `code complexity`cost which, added to the need of (mostly) backward-compatible code, is preventing/has prevented some cool stuff (static reflection, etc.)
There is a proposal replacing RETURNS with `=&gt;`. But the macro isn't that bad.
Yeah, it "It's that bad" but that's also a sad statement. I'll still probably end up using it. So thanks :)
Wow I like this a lot. It seems so intuitive. Anyone notice any possible issues with this?
You mean... apart from being a _massive_ language change?
So long as the data you want to reflect isn't compiled out.
Before `emit&lt;S&gt;(e,....)` returns, all functions connecting the signal `S` from the emitter `e` from thread that called `emit&lt;S&gt;` will have finished executing. In addition, the signal invocation and the arguments will be queued in all other threads that meet the following conditions: * The thread has explicitly created its own `thread_local_queue` object, and * the thread currently has at least one connection for the signal `S`. With this, the job of `emit&lt;S&gt;` is done. Independently, when a thread calls `poll` (or `wait`) on its `thread_local_queue`, all signals queued since the last time are emitted locally (synchronously).
At least at first glance, it doesn't look to me like that will cause a problem either. The lookup for `adl_serializer&lt;T&gt;::to_json` is trivial--it's the very same template currently being instantiated, so it doesn't depend on anything like ADL to find it. When that gets instantiated, it's just like the base case: we have a template that's passing some T, and using ADL to find the `to_json` (or `from_json`) in the namespace where `T` is defined--but what it's finding there is a function that explicitly names the type `T` rather than matching because it's a template that can match any arbitrary `T`.
Thank you, that's helpful!
I feel that the paper is meant more as food for thought than as standards fodder. A position paper or something to set direction. And direction is needed - don't forget that the Vasa sank because no-one took charge of design. Type-based meta-programming was never by design, it emerged and evolved from templates. Each new standard has iterated and evolved around that core. Today there are many choices for how to do type-based programming - template pattern matching, traits as conditions for constexpr if with auto deduction of return type, the newer value-based style of meta-programming helped by variable templates and lambda expressions, concepts and constraints will bring even more choices. A good time to stand back and get some perspective. There are so many ideas in this paper that some might stick and have a chance at incremental adoption.
Is this similar to RX ?
Probably not really what you're looking for, but have you looked at d? It has most of those features.
If you're talking about [https://github.com/ReactiveX/RxCpp](https://github.com/ReactiveX/RxCpp), there is some overlap, but the big difference between Synapse and other libraries is that any object can emit Synapse signals, e.g. you can emit a signal from an `int` object, if you needed to. If two contexts (happen to) have access to the same object, any object, they can use it as an emitter to communicate with each other thorugh Synapse signals.
&gt; ... don't forget that the Vasa sank because ... At this point, people really do use that paper to mean literally anything. &gt; Today there are many choices for how to do type-based programming ... ... and here's one more! Mind you, I'm not saying that it's a good way or that it's a bad way. I'm just saying it's a new way, and it's a large paper. 
I have wanted something like this for a very long time. I was considering designing my own language to get it. Now it seems it might end up in my favorite language anyway.
This seems like stuff that's all been posted here in this subreddit, plus ads.
Lvalue to rvalue conversion is its own thing, so you're correct
Agreed.
I have to say, after using many C++ different signal libraries, this one easily looks like the best! The idea of emitting a signal using some identifier value reminds me of GObject's signals a bit...
For interop with native queuing primitives, you also need a signal from the queue that can be hooked up to whatever ‚Äúwake up the event loop‚Äù method is there. This is of course a thread-local connection. Perhaps that already exists? I haven‚Äôt browsed the api yet. 
FWIW, I strongly disagree with the approach of Better Enums, because it doesn't define an enum but an enum like class. This makes switch case, and templating on it by value impossible. It's also a pain if you are looking to "upgrade" an existing enum as it's not backwards compatible. I've been working on a library of my own, and it's basically finished (with example code), I just need to add some documentation. When you use the macro in my library, it defines a 100% vanilla enum (or enum class). All the reflective functionality is implemented non-intrusively: [https://github.com/quicknir/wise\_enum](https://github.com/quicknir/wise_enum). It's standalone (though I'm considering throwing in an optional implementation, because my API uses one... right now I use std::optional if compiled with 17, otherwise the user can define what to use).
Could you be more specific on what bloat you actually mean? The biggest problem with variant at this point in my eyes is that when you visit, you get code less efficient than switch case. This is because currently, surprisingly, compilers will not turn a constexpr array of function pointers into a jump table. This should be overcome soon though, I think.
For smart enums, I'd suggest giving my library a shot: [https://github.com/quicknir/wise\_enum](https://github.com/quicknir/wise_enum). I thought about the issue a lot. It's basically complete, just missing documentation but it's quite a small library and there's example code which should make things pretty clear. It provides all the functionality you listed (as constexpr functions), and other useful things (a type trait so you can easily enable\_if on the enum being smart). One of the key points of the library is that when you use the macro, you get a 100% vanila enum (or enum class). So, no surprises, changes, or exceptions to backwards compatibility for vanilla non-reflective usage. It also has no dependencies (except that it needs some kind of optional-like class for its API, that could however be changed if it were really a deal breaker for someone).
Compilation time, visiting, and every get/set operation is checked even in release to be valid. There's no option to disable the checks and tell it "no, this is always correct stop wasting CPU time checking it". Also comparison operators on the variant can end up doing dynamic dispatch instead of direct comparison.
What if I re-order the members of my class?
Can it be used together with Qt's event loop? 
In Qt signals when emitter and receiver are in different threads, by default the emitter creates an event in the receiver's thread event queue instead of invoking some function directly. That event is then taken and handled by the event loop in receiver's thread to make the invocation thread-safe. 
Better Enums [is usable with switch statements](http://aantron.github.io/better-enums/tutorial/SafeSwitch.html) What do you mean by upgrade though? Adding more values? Converting to another type? I'll have to check out your library at some point
I didn't read the thing in details, but ADL for types does sound like a nest of funky surprises.
Extensions are not part of the language, the point of the language is to have the same things available in different compilers and thats the core of the issue. Like for pragma once you would have to have all compilers implement the same extension with the same syntax to make it work (and pragma once doesn't even work the same way in all compilers).
 typename CodomainOfValueType = RemoveCvReference | ValueType | CodomainType; We Haskell now? typename CommonType(typename T, typename... Ts) { for (typename U : Ts) T = CommonType(T, U); return T; } Ok, this looks really good. I like the proposed Concept &gt; Type &gt; Object way of thinking. int i; // type object ForwardIterator I; // concept type
How do people behind core actually verify new language? Is there any strict, confident mechanism to confirm that new syntax does not bring any ambiguities?
This looks kind of similar to what [zig](https://ziglang.org/documentation/master/#Generic-Data-Structures) does.
&gt; In variant-using code I usually just switch on variant.index(), rather than trying to painfully switch on type. But then, I don't try to emulate inheritance by stuffing huge numbers of classes into a single variant... .... that's not what you are supposed to do at all. This will break as soon as your variant changes. You should use std::visit instead : . struct { void operator()(int x) { std::cout &lt;&lt; "int: " &lt;&lt; x &lt;&lt; "\n"; } void operator()(const std::string&amp; x) { std::cout &lt;&lt; "string: " &lt;&lt; x &lt;&lt; "\n"; } } vis; std::variant&lt;int, std::string&gt; v = "hello world"; std::visit(vis, v);
that's one of the most beautiful insults I've ever read
 #include &lt;variant&gt; #include &lt;cstdint&gt; void foo() { std::variant&lt;int8_t, int16_t, int32_t, int64_t, uint8_t, uint16_t, uint32_t, uint64_t, float, double&gt; var; std::visit([] (auto v1, auto v2, auto v3, auto v4) { }, var, var, var, var); } let's compile it : $ time clang++ -std=c++1z -c foo.cpp 41,91s user 1,45s system 99% cpu 43,512 total $ ls -l foo.o 19M 17 ao√ª 11:05 foo.o $ nm -A foo.o | wc -l # more or less counts the symbols in the object file 30038 
&gt; So you would like to treat conversion from string to string_view as an error? frankly, yes. Had enough string_view bugs due to [this](https://foonathan.net/blog/2017/03/22/string_view-temporary.html)
&gt;This will break as soon as your ... changes I took out the word 'variant' because this is a bit of a universal truth: as soon as you change stuff, you will have to change other stuff to match. We have tools like encapsulation to ensure that such a change does not result in an uncontrolled cascade of problems. 
Unfortunately a lot of the changes in 15.7 and beyond have increased the size of the package around 2 GB, and this is just too big even for the MyGet servers. These changes are: more lib support for ARM and ARM64, and then all of the libs with both no mitigations and the /QSpectre mitigations. Unfortunately the scripts that produce the packages aren't yet part of the standard build or deployment (work in progress) and so I've been swamped getting them updated / refactored to support all these changes. Next step is to figure out how to divide up the package into an appropriate components (size vs complexity of config / download) to come in under the size supportable by MyGet. If I omit the /QSpectre libs we drop the package down to 1.1 GB, but that is still too big. So my only option is to get the non-monolithic packages working. Sorry it's taking so long
I have concerns regarding how well this scales in larger programs. What would be the best approach in something like the following scenario? Consider a program with a bunch of buttons, each button doing some distinct thing when it is clicked. The buttons only differ by the text on them and by what should happen when it is clicked. Now as far as I understand either all receivers will get all clicked events and they will have to filter these on their own somehow, meaning that some kind of meta-data has to be passed via the clicked signal and matched in the receiver. A second approach is a button class template where you define the signals it can emit in the template parameters. Am I missing some other approach? Neither solution is really scalable in my opinion: in the first case you will call a bunch of unrelated (for that specific button) receivers, and in the second case each new signal will add a new template argument that must be handled by all instances.
**Company:** [Couchbase](https://www.couchbase.com) **Type:** Full time **Description:** Built with the most powerful NoSQL technology, the Couchbase Data Platform was architected on top of an open source foundation for the massively interactive enterprise. Our geo-distributed Engagement Database provides unmatched developer agility and manageability, as well as unparalleled performance at any scale, from any cloud to the edge. Couchbase, one of the NoSQL industry leaders, is looking for Senior Software Engineers in our Manchester design centre. If you want to be part of the big-data revolution we may just have what you are looking for... **Location:** Manchester **Remote:** No **Visa Sponsorship:** No **Technologies:** We use C++ on Linux mainly. Familiarity with SQL and NoSQL databases a big plus as is Open Source software development practices. **Contact:** If interested, you may email CV/questions to [georgina.protopapas@couchbase.com](mailto:georgina.protopapas@couchbase.com) or for further information on our jobs, please look at our careers website-[https://www.couchbase.com/careers](https://www.couchbase.com/careers)
That depends on the price you have to pay for that, though, which was my point to begin with. If there is a huge overhead for the code generation (in terms of time, space, or both), using the feature becomes a trade off rather than an obvious benefit. Compilation times are already too large for C++ as it is; at this point I'm not happy about introducing new features into my code base that will cause that to grow even further. 
I'm not sure what the trick is for switch case. Perhaps implicit conversion? Upgrading, I just mean you have a library with a normal enum, used extensively. At some point, you want to do something reflective. You can always change the enum to be defined using my library's macro (upgrade is to be reflective), and be confident that all existing code still compiles.
I guess that's a fair point for those that care about binary size (I don't), though I find many people like to make a thing of it when they have no good reason to.
or just void f(double x, double y, double z) { //... } void f(double x, double y) { f(x, y, x+y); }
that does not exactly work that way. Once a member function/variable is referenced it gets ODR-used, which prevents the compiler to erase it from the existence... (The exact optimizations, inlining at call sites, etc, is another story) Think about it: If the API does use of pointers to members (which is the case of the provided static reflection API) those are ODR-used, so no issue there. In an hypothetical case of a metadata representation that does not ODR-use anything directly, say a reflection backend that just JSON-ize all metadata and loads functions at runtime using dlopen() for example. Same issue: If no symbol was defined named like "function f" the symbol loading code will tell you. It's exactly the same that would happen if you reference (ODR-use) that function with no definition, a linker error. The difference is that you catch the error at runtime.
Note that optimizations should not affect here, since we work at the AST level to extract metadata. Anyway, tinyrefl-tool is run with the same compilation options, to ensure the code "looks" the same way to libclang and your compiler.
I'm not the author of Better Enums but as far as I'm aware, it gracefully degrades to an integral type. Possibly via implicit conversion. I don't remember specifically having any issues with swapping regular enum classes with the Better Enums macro though when my workplace was evaluating it. That was a while ago though so it's entirely possible that what you say is correct. It was specifically picked though because of the C++98 compatibility (yes, I know, it was awful).
&gt; how you have incorporated lambda use case in your code and what benefits you achieved. Are you kidding me? I wrote a whole library based upon it! [WinLamb: A modern C++11 object-oriented library to write native Win32 programs](https://github.com/rodrigocfd/winlamb) It's possibly the best change I've ever seen in C++ since I started using it.
&gt; It can just as easily generate an operator&lt; that compares everything in the class/struct using &lt;. If I understand you correctly, what you are saying is, if I have a struct struct S { int a; int b; } S1, S2; then `S1 &lt; S2` iff `S1.a &lt; S2.a &amp;&amp; S1.b &lt; S2.b`? This doesn't work. Take `S1{0, 5} and S2{5, 0}`. Now S1 &lt; S2, S1 == S2 and S2 &lt; S1 are all false. It can work in the == case, but it doesn't work for ordering. Even in Haskell, which inspired the spaceship operator proposal in C++, if you instance the Ord typeclass, you need to define one of the comparison operators.
I‚Äôm curious, why do you output to std::cerr in your example file rather than std::cout?
No
Nice but you forgot to put a license on it, so I cannot use this at work, too bad!
&gt; [...] all the default parameters have to be at the end of the arguments list of a function. This can make an interface less natural, because arguments are no longer grouped in a logical order. Instead, they are grouped in a technical order: the non-default parameters first, then the default ones, which can be confusing at call site. How this can be confusing? If you need more complex default value handling: - use monads (optional, variant etc) - take only 1 parameter which is a class that encapsulates parameter invariants - use more overloads like /u/Sopel97
If i worked with someone that put 20 lines of bullshit templates that had to be processed in every file including it, just to recreate harder to read function overloads, I'd lose my damn mind. 
`auto c = synapse::connect&lt;my_signal&gt;(&amp;emitter,` I think you have a typo in your tutorial? Shouldn't that be `connect&lt;print&gt;`? 
Why would it be used? Are we talking about reflection of a binary within itself? Reflection can also be used to query *other* binaries/modules, and in those situations this wouldn't work, as anything that isn't referenced is eligible for elision unless they are externally visible. So, external reflection can work but in limited circumstances (*far* weaker than, say, Java or C#), though internal reflection should work well enough with LTO (to prevent intra-TU elision) since you are effectively adding references. This is also very sensitive to changes in compiler settings/ABI/runtime environment. My hope would be probing a DLL/SO for functions/data, equivalent to using reflection to probe/modify another package in Java. Purely internal reflection is seperate, but I don't quite see why a seperate AST pass is necessary - the compiler already has all this data, and there's no reason it cannot encode the necessary information in an object file.
You see, by giving this simple solution that anybody can understand, you miss out on showing off your C++ expertise by writing lots of template code, creating a github repository to host your code and beef up your online profile, and then blogging about it.
Wouldn't it be easier to just use `to!string()`?
&gt; I guess that's a fair point for those that care about binary size (I don't) that's because you never had to load multiple gigabyte executables in a debugger or you never hit windows' 65535 symbols limit
&gt; At the same time, one of the tenet of C++ is you don't pay for what you don't use. That was never true for the standard library (except of course if you don't use it). You just can't make general purpose types that are optimal for every usecase. Imho, the standard library far too often tries to strike a balance between usability, safety and performance and fails miserably 
You know that you'd have the exact same problem shown on the linked page when you use `const std::string&amp;` as a return type right? If you hand a view to someone (be it a pointer, a reference or a view type) to someone, you better make sure the object you are viewing outlives the view. And yes, it is a shame that current tools don't warn on string_views that get immediately invalidated.
Thanks kalmoc, you're correct. You'd use a single signal type (e.g. `button_clicked`) and connect each receiver to a button. Only that receiver will be called when its button is clicked.
It seems the readability is the main reason for lambdas, right? Could it improve something else than readability?
&gt; That was never true for the standard library (except of course if you don't use it). I know, which I've always found odd. A standard library is by definition the foundation of most of the language ecosystem; not following a core tenet of the language is an odd choice. &gt; Imho, the standard library far too often tries to strike a balance between usability, safety and performance and fails miserably I agree. I personally wonder why the standard library so often tries to cater to the weirdest edge cases, instead of putting its foot down and announcing "too weird, would require compromising performance". For example, look at the lengths `std::variant` goes to avoid allocation in the presence of throwing move constructors. Is that really necessary? Why not `static_assert` that the types are noexcept move constructible?
I hear this argument... and then I imagine what the language would be like if we had standardized on a build system and package manager in the mid 90s.
I‚Äôm no C++ expert, but IME it‚Äôs just been for convenience and readability.
I think that it would be useful to have. Some have pointed out that modern C++ typically involves much less raw pointer usage which is of course true! I don't think that the typical application developer is who would make the best use of this keyword though. I think Library development is where this truly could shine. Libraries which wrap raw primitives could certainly make good use of this. I love the idea of your everyday developer being able to compile against a new version of a library there already using, and get a slight speed boost just because the compiler has been given an opportunity to a slightly more efficient code in that library.
The GitHub repo is a mirror. I do development, CI, etc on gitlab, but I'm fine if people open issues and PR on github
Simply to be as-is from the OP post. The point was not the contract anyway. 
I have on a regular basis to the former, and to the later I've never worked on Windows, no. It's not really a big deal, at least in gdb.
Very interesting, I did not know about the difference in buffering between the two, could be very useful to keep in mind. Thanks!
Thanks very much for the update, Paddy! For my own purposes, I used the dailymsvc package to test for compiler errors/regressions in my own code, with an emphasis on the front-end; so for me, all ARM/ARM64/`Qspectre` stuff is extraneous. But I'm quite certain my usecase isn't the only one so I appreciate the thought you're putting into doing things correctly. :-]
Commendable goal, but an std::map associating the cold part to the hot part? I hope it's really cold... Anyone familiar with how https://github.com/electronicarts/EASTL/blob/master/include/EASTL/bonus/tuple_vector.h works? I'm not. It's new. I'm assuming it implements an vector-of-tuples interface over a tuple-of-vectors implementation. Then there's the famous [data-oriented "using" feature of Jai](https://www.reddit.com/r/rust/comments/2t6xqz/jai_demo_dataoriented_features_soa_crazy_using/) that lets you split an class into a reference to two multiple without changing the syntax of any code using that class. From there you can move members back and forth across the split without changing any existing code.
&gt;Anyone familiar with how &gt; &gt;https://github.com/electronicarts/EASTL/blob/master/include/EASTL/bonus/tuple\_vector.h &gt; &gt; works? I am! :) There are a couple other things I wanted to have merged in before I make a separate thread about it. The interface exhibits roughly as a vector of tuple structures (most accesses basically being via a tuple of references) but yeah, the data layout is like a tuple of contiguous arrays, with the benefit that all of the data is managed as a single allocation. There is a [readme in the docs folder](https://github.com/electronicarts/EASTL/blob/master/doc/Bonus/tuple\_vector\_readme.md) and the [tests demonstrate various parts of it in action](https://github.com/electronicarts/EASTL/blob/master/test/source/TestTupleVector.cpp)
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/97cybp/stared_my_first_programming_job_but_i_think_im/e4df7zm/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Interesting idea. There are some other implementation deficiencies, though. For example, I think there is no reason to store `std::unique_ptr&lt;ColdData&gt;` in the global map instead of just `ColdData` objects. 
&gt; At this point, people really do use that paper to mean literally anything. I wasn't even aware it was a paper. I thought people were just unusually familiar with the foundered Swedish warship.
or in c++17: void f(double x, double y, std::optional&lt;double&gt; z = {}) { z.value_or(x + y); } 
I think that adds an unnecessary branch. Let's not make a static problem a dynamic one.
I wanted to show the mechanism.
Is it important if any error is meant to crash whole application? Is it still ok to use "modern" features such as smart pointers if app is crashed? Whats difference between malloc and shared_ptr if app is always expected to crash?
https://wg21.link/p0977
I like it, but people get mad at me when I do stuff like this.
It wasn't a problem for me, /JMC does seem to default on for debug configurations in both new projects and my existing ones that use vcxproj/property sheets.
&gt; Is there any strict, confident mechanism to confirm that new syntax does not bring any ambiguities? If there were it would make the perfect compiler :)
[This](https://github.com/facebook/folly/blob/master/folly/ScopeGuard.h) will get you there. I have a stripped down version that is about 50 LoC. 
Is this an abstraction of the classic struct of arrays used to improve vectorization performance? In such a case that's so cool!
Do you benchmark and demonstrate real performance gains? Otherwise their displeasure is justifiable.
My 2 cents: Use c or c++ write the library it self, then provide a binding with the other language.
You can write it in c++ and use llvm to recompile it to C
&gt; It's not really a big deal, at least in gdb. well, I can hardly justify to my boss waiting 3 - 4 minutes for each debugging session to start.
[CppCon 2017: Michael Price ‚ÄúFunction default arguments: Slingshot or Shotgun?‚Äù](https://youtu.be/NeJ85q1qddQ)
This. Most likely that means writing it in C and providing a C++-wrapper. C++ can be a quite bad fit for embedded due to memory bloat and lacking compiler support.
I was wondering why he did so as well
Yes , write twi.
I guess one advantage is that it saves copying the cold data when vector elements are reallocated. If the cold data is large that could potentially make a difference. It might also help cache locality when looking up the data in the map?
Would have liked to see comparison with the pointer solution. Also: Is your global map thread safe? Do I have to lock a mutex everytime I construct, move or copy an object? How is performance impacted if I fill a vector of those things?
\&gt; C++ can be a quite bad fit for embedded due to memory bloat When we're talking about a machine learning library, I'd assume it's a fairly capable embedded platform, so it probably has a reasonable amount of memory and a GCC / clang port.
If you: - always delete the file (even if the program crashes midway) - don't need anyone else to open it - are on a POSIXish platform (i.e. not Windows) Then the simpler solution is to delete the file in the constructor. Then you don't need to store the file name at all and your object's size becomes `sizeof(int)`.
Is adding signals to any random object really that much of a use-case? The examples you give about 'synapsifying' C callbacks and GLFW events require writing a lot of boilerplate code and as far as I can tell could be achieved by writing similar boilerplate/wrapper code with any other (intrusive) signal library. The feature of being able to add signals to any object also forces you to be non-intrusive, for which I don't see any upsides. IMO, it just makes it hard/impossible for clients to discover what signals an object exposes, without trawling through its source code; with intrusive signals you could just take a look at the header. I also don't understand why the `connect` functions return a `shared_ptr`. It seems to me that the ownership of the returned `connection` object is very well defined; wouldn't an `unique_ptr` be a better match? Better still would be not to require an alloc for each `connection`, of course...
Pretty sure they don't intend doing machine learning on an attiny or something.
And it won't affect reallocation since the map is static
Have you tried using `variant`, but without `visit`, switching on `index`? These 40 lambdas are no free lunch and are no alternative to pattern matching.
it doesn't matter if we turn on some reasonable optimization. Modern compilers should optimize nearly all overhead introduced by C++. it might end up depend OP's skill set, should pick the most familiar language, then properly do some optimization and profiling.
Not sure how this helps C-only platforms. They have no use for the binding if they can't compile the lib itself.
Was also thinking about this, this is very thread-unfriendly since it advocates heap-based global state, however because the chance of accessing the cold data is assumingly rare, so under this condition it is very unlikely to see data races across threads. 
&gt;due to memory bloat Assuming you're talking templates here, what is the difference between writing a template function and writing that many C functions for each type you want to support?
Even though they are rare, you need some form of synchronization and even though access to the data is rare, you still might need to update the mapping (on move/copy). I'm not saying it isn't worth it (it almost certainly is) I'm just asking if those effects can be neglected in practice and/or they employ some nifty tricks in their actual implementation, because I have actually a similar problem and was considering a similar technique. 
There's no. This guy is just parroting bullshit he read somewhere. 
&gt;but a std::map associating the cold part to the hot part? I hope it's really cold... I wonder how it would perform with a better optimized data structure ([sparsepp](https://github.com/greg7mdp/sparsepp) or Judy arrays). 
Thats just bullshit. Yes some features like exceptions, RTTI introduce runtime overhead. And yes throwing templates at every problem in existence (aka TMP) might result in larger executables. All these things can be avoided though. Using a reasonable subset of C++ (RAII, overloads, constexpr) can really help for large embedded projects.
&gt; I guess one advantage is that it saves copying the cold data when vector elements are reallocated. Which vector? The implementation uses `std::map&lt;void*, std::unique_ptr&lt;ColdData&gt;&gt;`, there's no vector. And given you already pay for memory stability when using `std::map`, you might as well use it.
&gt; however because the chance of accessing the cold data is assumingly rare, so under this condition it is very unlikely to see data races across threads. That's... a surprising argument, really. If the data is accessed frequently enough that a data-race is likely, then thread-safety is necessary. If the data is accessed infrequently enough that a data-race is unlikely, then thread-safety will have little impact on the program performance. In either case, you're just better off using proper synchronization.
Any recommendations on a C++ URI parser? I've been starting with the one baked into the Microsoft C++ REST SDK. [https://github.com/Microsoft/cpprestsdk](https://github.com/Microsoft/cpprestsdk)
&gt; are on a POSIXish platform (i.e. not Windows) Isn't it supported by some recent-ish update to Win10?
Comeau C++ compiler back in the day could be used to compile c++ code to c. I dont think it is alive anymore though...
Are you targeting C, or is C just a way to make your lib usable from python?
I get that you sometimes could want this... but motivating it with *file descriptors* of all things!? Those file descriptors are most likely going to end up in a system call each time you access them and what is that going to cost? Now compare the cost of the system call with the cost of the cache miss and reevaluate your effort vs. performance improvement. &gt; with zero space overhead Maybe within the object - but the space overhead for the application is definitely significant. Also, your benchmark doesn't consider the extra initialization cost. Then there is the choice of benchmark size which conveniently shows the best results by having the small data fit in a typical L3 cache whereas the large data does not. Now, this can surely be useful, but I really wonder what your actual use cases were where you saw the benefit. I highly doubt you get any measurable improvement with file descriptors.
There isn‚Äôt any difference between them, the difference is that c++ relies on templates for a lot of the nice things. So by using c++ you will generate more code in compile-time. This can ofc be prevented but it‚Äôs much easier to accidentally inflate the executable. I‚Äôve seen a difference of 20-30mb in a 100mb executable between a very ‚Äúmodern‚Äù codebase and one less modern even though they are very similar in functionality. This is just one data point though so it should be taken with a grain of salt. It‚Äôs very difficult to track down the actual reason for the bloat though. 
In my experience (codebase with 1-2M LOC on msvc, clang and gcc) you do end up with a quite sizable portion of the final binary being template generated code. It absolutely depends on the programmers and how closely they look at it during development. 
The question is: Is it bloat or would you have written the same functions anyway by hand. E.g. a separate instantiation of the same function template for short, int, long and long long is probably bloat. Having separate installations of the same algorithm for a vector and a list is usually unavoidable.
While largely true, I have the feeling that many people overestimate the capabilities of modern compilers - or underestimate just how much work a modern c++ library throws at them.
I totally understand why people overestimate the compiler since you often don‚Äôt really have to care anymore today. It‚Äôs also really hard to understand sometimes what exactly is going on. When writing code for the PS2 or the PS3:s SPU you couldn‚Äôt include some headers because they increased the code size too much even though you didn‚Äôt use anything from them.
I don't know. At least in old versions of Windows you could not delete a file that was open.
You can delete files that are shared for deletion (which isn't on by default) but the standard way is to set the delete on close flag, which will work even in the event of a program crash
Java
Defining signals intrusively creates coupling which is sometimes inappropriate. I could give you a specific example, but the general use case is when two systems have access to the same object, and need to communicate with each other *about* that object. A special case of this is when the object is of a third-party type, in which case adding signals to that type is impossible, not just inappropriate. Another use case is when you want to avoid coupling with some API, for example Qt. It is desirable to be able to implement libraries that can be used with Qt without coupling with the Qt signals/slots system. Synapse facilitates this interoperability: [https://zajo.github.io/boost-synapse/#\_emitting\_signals\_from\_objects\_of\_3rd\_party\_types](https://zajo.github.io/boost-synapse/#_emitting_signals_from_objects_of_3rd_party_types). About the ability to hook up C-style callbacks: the boilerplate code you're talking about is written once. In the GLFW example, you `#include` the small header with the meta handlers and then you just call `connect`. To do a similar thing with another library would require to implement what Synapse does. For example, if using Signals2, you'd have to find a way to associate signal objects with GLFW windows and manage their lifetime in-sync (there can be multiple dynamically created GLFW windows). Well, that's Synapse. The reason why Synapse uses `shared_ptr` to manage the connection lifetime is that the user is sharing (with Synapse) ownership of an internal data structure. In turn, that uses `shared_ptr` in order to allow persistent connections when the emitter or the receiver are passed to `connect` as `weak_ptr` (or, equivalently, `shared_ptr`). In this case connect returns `weak_ptr&lt;pconnection&gt;`.
No, I mean, if you have a `std::vector` of these objects (this being the reason to use the class in the first place), and the elements get reallocated, the cold data needs to be remapped because the key (the object addresses) change. If this is a pointer, it can be done more quickly than if it were an inline object.
The ordering thing is pretty easy: just do it in definition order. In this case, you could use `std::lexicographical_compare`, though it's probably faster to do it with `std::array` or `std::tuple` like this: `return std::make_tuple(S1.a, S1.b) &lt; (S2.a, S2.b)`. With reflection you could probably make that work automatically. I do think it deserves to be the default if you don't define anything though. 
Hey, I'm a C++ analysis engineer at Semmle, and worked on some clang-based tools in the past. I'd expect the third example to be significantly more painful in clang; the 20ish lines in the post are all that was written for this query. My experience more generally has been that QL as a language is much easier to write than C++, which means faster turnaround for rule development and makes it easier to add additional cases to the rules for false positive reduction. However, where QL really shines is with inter-procedural analyses; one good example would be the interprocedural data flow used in the [work](https://lgtm.com/blog/apple_xnu_nfs_boot_CVE-2018-4136_CVE-2018-4160) that our security team has done with user-controlled overflows in Apple's XNU kernel. We also have support for analyzing other languages with QL; currently the list is C/C++, C#, Java, JavaScript/TypeScript, and Python.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/98h6io/help_is_there_a_way_to_run_c_program_when_opened/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
&gt; not pass code review at my company. ok?
Question about your cmake integration with your ```tinyrefl_tool``` function. A quick review looks like you connect the code generation build step to the target using your util ```add_prebuild_command``` which looks pretty good. I'm curious if there's any further background on this and if there are any limitations. It looks like it will identify a change to the tinyrefl tool and re-run it, but is this going to detect a change to the header and re-run the tool? I think I'm missing how the generated file is linked back to the ```${ARGS_TARGET}```, or will this be run every time before a build? add_prebuild_command(TARGET ${ARGS_TARGET} NAME "${command_target_name}" COMMAND ${TINYREFL_TOOL_EXECUTABLE} ${header} -std=c++${CMAKE_CXX_STANDARD} ${definitions} ${includes} ${compile_options} WORKING_DIRECTORY ${CMAKE_CURRENT_SOURCE_DIR} COMMENT "Generating tinyrefl metadata for ${ARGS_TARGET}/${header}" DEPENDS ${TINYREFL_TOOL_TARGET} ) 
yuck. &gt; auto _ = finally([&amp;]() { f(i); });
What is a "C only" platform here?
Before lambdas a lot of common STD functions such as for_each, copy_if, and transform, to name a few, weren't all that useful. You two have to define a function somewhere else which broke up the logic of your code and then refer to it at the call site. this really discouraged any programming style except for writing for and while loops. 
I mean, you can... just not *only* with malloc. `int *iptr = new (malloc(sizeof(int))) int;`
&gt; but in practice is only good for __assume(false) or asserting that a pointer is or isn't null, since it isn't specified or guaranteed that any other expression will do anything. Untrue. I am able to use the *rough* equivalent `#define __assume(c) if (!(c)) __builtin_unreachable();` in GCC quite heavily, and in embedded in makes a *huge* difference. It can be used to mark certain parts of data as being only 0, or masked a certain way, or such, which prevents additional operations (critical on 8-bit CPUs like AVR). Heck, there was one place where the codebase was using an `int8_t` to specify step direction (it also only ever stepped one at a time), so it was basically doing `location += step_dir`. Adding `__assume(step_dir == 1 || step_dir == -1)` completely changed codegen for that, and for the better.
You can take a look at [RESTinio](https://bitbucket.org/sobjectizerteam/restinio-0.4). It supports [routing mechanism](https://stiffstream.com/en/docs/restinio/0.4/expressrouter.html) similar to Express.js.
Thanks for the answer. The interprocedural data flow sounds really cool.
True, but depending on what you are doing, it is also much harder, so you might - unnecessarily- jump through all kinds of hoops and then realize, all the effort. Btw.: Even deterministic systems (e.g. avionic systems) are sometimes allowed to use the heap (typically during startup). Of course that heap is usually not implemented by your general purpose malloc / free you find on a normal linux system.
Definitely seems like a bug or at least an oversight when there are things you can't express according to the standard. On an unrelated note, as I'm not familiar with the authors library, why is there a need for this proxy? Seems to me that lambdas solve the same issue, or of course I'm overseeing some complexity here. One point I have to disagree with though: int (*func)(foo&amp;, int) = proxy&lt;&amp;foo::some_method&gt;; &gt; Change foo&amp; to void* and you have a nifty way to interop with C. It looks neat, but I disagree with the statement that it is a nifty way to interop with C. From a usability and readability standpoint I'd much prefer a lambda or a simple function wrapper. Everybody understands those as long as they are familiar with the basic syntax of C++, while the snippet above is pretty far removed from day to day C++ in my opinion. Not only that but from the perspective of writing the code, is it really that much more work to write a function wrapper or inline lambda?
Also, isn't there something about lambda's/etc. hacing C++ linkage even when converted to a pointer? So not technically well-suited for C interop (though in practice it probably doesn't really matter).
Can you explain what does the right side do?
Ah! I see. The OP "cheated" here by disabling copy/move. This may be a good strategy, since copies are going to be relatively expensive. If you want a full-featured implementation, however, I agree that a degree of indirection may be necessary for performance.
Found the comment I've based this on: https://www.reddit.com/r/cpp/comments/88mmjk/visualcpptoolscommunitydaily_can_support/dwm09qo/
Only copy is disabled in the OP's implementation. Move is implemented in exactly the way you might expect!
That's what I get for answering from memories. The code is much less efficient than I thought then, though again it's using no 3rd-party dependencies there's no much choice. --- And actually, move is certainly not implemented as I might expect: &gt; explicit OutOfLine(OutOfLine&amp;&amp; other) { *this = other; } &gt; OutOfLine&amp; operator=(OutOfLine&amp;&amp; other) { &gt; global_map_[this] = std::move(global_map_[&amp;other]); &gt; return *this; &gt; } This is rather sub-optimal and not very idiomatic: 1. C++17 introduced [`std::map::extract`](https://en.cppreference.com/w/cpp/container/map/extract) specifically to avoid allocations in such a scenario. 2. The move constructor should not compile (missing `std::move` around other); and as a matter of style I'd prefer not use default construction + assignment to implement move-construction, as it in general less efficient. I would, therefore, argue for a rewrite: explicit OutOfLine(OutOfLine&amp;&amp; other) { auto nh = global_map_.extract(&amp;other); nh.key() = this; global_map_.insert(std::move(nh)); } OutOfLine&amp; operator=(OutOfLine&amp;&amp; other) { std::swap(global_map_[this], global_map[&amp;other]); return *this; }
A bug in the C++ standard?!!! http://www.youtube.com/watch?v=SjbPi00k_ME&amp;t=0m10s http://www.open-std.org/jtc1/sc22/wg21/docs/cwg_active.html http://www.open-std.org/jtc1/sc22/wg21/docs/lwg-active.html :-)
The standard has more bugs than you can shake a stick at.
In C++17 it's possible to write very short code that automatically "lifts" a function into a lambda, can do it for member function pointers too I'm sure.
 yacl::Setting *root = yacl::Config::parseConfigFromFile(config_path + "/simple.yacl"); It's really weird to return a raw pointer here. Why aren't you just returning a normal object? It also doesn't seem like the config isn't statically typed, which for me at this point is probably a requirement. 
[removed]
&gt; It's really weird to return a raw pointer here. Why aren't you just returning a normal object? All settings allocate on heap, so I just return raw ptr. Better option its to return some object kinda of unique\_ptr, in future I'll make some SettingHolder and return it, so you dont need to delete in manually. &gt;It also doesn't seem like the config isn't statically typed, which for me at this point is probably a requirement. All fields are statically typed, you can check it here [https://github.com/Lallapallooza/YACL/blob/master/include/YACL/field.h](https://github.com/Lallapallooza/YACL/blob/master/include/YACL/field.h)
It's been seven years since C++11. There's no excuse to return a raw pointer that not only must be deleted, but must be deleted using a special function because the destructor does not delete the children. 
Well what I meant was that at best, you'll see it in the next standard. Still you're most likely right... if it really is a bad language bug. Does my example really deserve to get elevated to a status where it gets to be retroactively fixed? I'm not sure. Anyway I'll probably prepare a DR in the next couple of days but I still realize the issue is not that severe. It's relatively obscure and you can work around it in several ways.
Well, I forgot we have templates. I work on a c-like C++ code base, and don't use templates very often.
do you have an example of this?
Greetings! After listening to your valuable feedback I've done some changes in the library interface to [reduce the usage of macros](https://github.com/Donerkebap13/DonerSerializer/tree/development#how-to-serialize) when it comes to serialize/deserialize stuff. Also I added the posibility of define serialization methods for thirdparty objects such as [SFML types](https://github.com/Donerkebap13/DonerSerializer/tree/development#how-to-serialize-thirdparty-types), for example. I hope you like it and, again, all feedback is welcome! :D
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/98l8hx/theres_an_error_on_this_cout_statement_please_help/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
\&gt; Better option its to return some object kinda of unique\_ptr, in future I'll make some SettingHolder and return it, so you dont need to delete setting manually You should just return an object directly. If necessary it can hold a unique\_ptr internally but there isn't much reason to expose that to the user. I'm having trouble understanding how it's statically typed. yacl::Setting *root = yacl::Config::parseConfigFromFile("config.yacl"); int var1 = *root-&gt;field("var1"); std::string var2 = *root-&gt;field("var2"); Whatever the type of the return of \`root-&gt;field(const char\*)\` is, it can't depend on the value of a passed parameter. So, the type you get back on the second and third lines has to be the same. How can this be statically typed then? It's also weird to need to dereference there, btw. You should really need to see much \`\*\` in a library like this.
1. What does this library solve that any json or yaml library does not? 2. Raw pointers...
What's not to like about replacing macros with template functions? Good job! 
&gt; What I value the most is RTTI You mean RAII
What's wrong with json?
But the generated code is really fast!
Field.h contain overloading for all types, if you miss with type exception will be called. [https://github.com/Lallapallooza/YACL/blob/master/examples/example2.cpp](https://github.com/Lallapallooza/YACL/blob/master/examples/example2.cpp) You can see it at example2.cpp
That's not statically typed. What do you think the "static" in statically typed refers to? A statically typed config is one where you try to extract a key that doesn't exist, and you get a compilation error. Obviously, to have a statically typed config you need to state the schema somewhere. 
&gt; You'd need a - fully paid - language design team that just makes a decision at some point to achieve that. Vectors now start at 1. 
Over the years I've personally found few needs for something like this, despite having been certain I would need it. :) The only times I've really needed C-style NUL-terminated strings is when inter-operating with certain legacy APIs, particularly those that weren't smart enough to add a length-delimited API already. Thankfully a lot of popular libraries - even C ones - have partial or full support for length-delimited APIs, like PCRE and Lua and so on, though certainly not all. The most significant outliers I've run into are the system APIs on the major platforms, e.g. POSIX and Win32 and such. In the case of Windows though, I've found I have to translate any internal UTF-8 strings into UCS-2 strings *anyway*, so the NUL-terminated status of the original application's string is irrelevant as the conversion routines support length-delimited buffers just fine. Due to the need for portability, any POSIX implementations of similar APIs end up being abstracted the same way, even though an actual conversion may not be necessary, and thus a NUL-terminated buffer can be used. The bonus of that approach - compared to what approaches like this `str_view` do - is that the conversion buffers can all be stack-allocated. That means no calls to `new`/`malloc` and corresponding deallocation functions, at least in the common cases. The OS routines are most often for things like paths and other IO which have fixed limits imposed by the OS. Even when no conversion is required, the overhead of copying a string into a stack buffer to NUL-terminate it is mostly invisible compared to the cost of the IO routines themselves since we're mostly talking about things like `open` or the like which are expensive calls. In those cases where the strings *may* be of exceptionally large length, it's still possible to use a stack buffer for common "small" string sizes and only allocate temp space for truly big strings. That temp space can also be cached and reused with a little care, too, for some types of applications. The C++ standard library itself handles or will handle all those details for the most common use cases anyway via `string_view` overloads for things like filesystem and IOStreams and regex etc.
Sorry for my ignorance, but how does this differ from or improve upon https://en.cppreference.com/w/cpp/string/basic_string_view
And the best thing about using your approach is that it avoids yet another string type!
Ok, so my config dynamically typed
Not op, and on mobile so forgive typos. Not sure, but I think they mean something like this: template&lt;typename T&gt; auto lift(T c) { return [c](auto ... args) { return c(args...); }; } Obviously needs some work if you want it to deal with rvalues.
&gt; The OS routines are most often for things like paths and other IO which have fixed limits imposed by the OS. Be careful though; IIRC Win32 MAX_PATH is 260, but you can now opt-in for longer paths (and that does not changes MAX_PATH). If you code could be applicable for such contexts (not all are: consumer GUI probable will never give a shit about extra long filenames for ex) it should be generic, or at least support your own saner hard limit even under Windows (4096 maybe). And honestly if you are going to do FS OS calls, an extra dynamic alloc is the least of your worries...
You're quoting the pre-C++ 11 standard there. Unless you're specifically targeting very old C++ code, you can use objects with non-trivial constructors and destructors in unions now. You've got a value type stored in your Field class. In your class' constructor and destructor, switch on the type and use placement new and explicitly call the destructor of the union member, and then you won't have to use all those raw pointers throughout your code. Generally speaking, if you're writing modern C++ and you're using new and delete and raw pointers with ownership semantics, you're probably doing something wrong. 
Lmao this guy and his pumpkins
Ah.
Cool nonsense title
C++ has enough legacy code laying around that I'm guessing it'd be more or less impossible to remove the less desirable parts of the language without a hard fork in the language. If you're starting from scratch and throwing away backwards compatibility, you might as well go beyond just keeping the best parts of C++ and start incorporating fun new things (Rust being the go-to example, I suppose). Interestingly, Wikipedia says Rust first appeared in 2010, so one could make a case that Rust is doing exactly what you suggested.
Interesting, but your same-named, GCC-specific macro is unrelated to the Visual C++ __assume() intrinsic that I mentioned. It is also still unspecified whether GCC's optimizer will actually react to that assertion, so it has the same problem that you have to figure out by experimentation whether a particular expression pattern will have any effect. For the original subject, the question is whether compilers and programmers would actually use the ranges to do fine-grained disambiguation between pointers or just do an aliasing/no-aliasing determination. 
The committee ensures the whole industry approves the changes. Not that it doesn't have its pitfalls, but it stops stupid shit like that. 
Aren't they oranges?
 template&lt;typename T&gt; auto lift(T c) { return [c](auto ... args) { return c(args...); }; } Tried to format it... 
&gt; if it was created from a string that is not null-terminated: c_str() creates a local, null-terminated copy of the string upon first call. ..but what if the underlying string changes?
So, I had C++ in my data structures class a few years ago, and we did a bit of templated programming (all our algorithms were type agnostic), but I have to say I never really got it. So this post reads very complex to me, and I'm wondering what resources you all would suggest for getting to the point of being able to grok templates?
Incidentally the library needs a Review Manager for the Boost review. Anyone with knowledge of the problem domain willing to volunteer?
This has very unpredictable behavior, and may surprise it's user. It's smart, but a bit too smart. A code using str_view now suddenly can have completely different complexity depending on whether it had \0 or not. It doesn't really go with the spirit of not paying for things we don't use.... Certainly it can find it's place in an internal utility library, and we can adopt such thing, but call it something else - like StringPiece, etc. as it's not anymore just a view - str_piece maybe?
To a first approximation: template class is a _type function_ that takes types as input parameters and "returns" (i.e., generates) a type. For example, `vector&lt;T&gt;` is a "function" that you can "call" (instantiate) with some type `T`. When instantiated with, say `int`, you get `vector&lt;int&gt;` which is no longer a _type function_ but a plain _type_ though with a weird name including angle brackets: a vector that holds integers. Similarly for template functions: it's a type function that generates new functions.
Definitely lambda functions. They are so elegant and useful when used in the right way.
You don't need the reinterpret_cast: signal.bind ([my_class_instance] (int arg1, float arg2, const std::string&amp; arg3) { my_class_instance-&gt;my_method(arg1, arg2, arg3); }); 
If you capture, the lambda won't be assignable to a function pointer. You will have to use std::function or similar which will be slower.
The picture is called `pumpkin_toss.jpg`. Try right click and "view image".
`constexpr` anything, template aliases and variadic templates, `decltype`. Other things like `auto` and range-based for loops are nice. Lambdas are huuuge. Here is a consise [cheat sheet](https://github.com/AnthonyCalandra/modern-cpp-features) to serve as refresher.
Move semantics? For many kinds of things (especially those that hold external resources), it makes no sense to copy them, but moving them around is reasonable. Without C++11 move semantics, we probably would construct the object on the heap and hold a (copyable) pointer to the object. Also speed is improved because we can steal resources from objects that are about to be destroyed - many times this avoids needing to allocate additional heap memory.
I think some of the other suggestions made the language a lot more usable in general and as a language user I appreciate them a lot more in most day to day coding, but as a library implementer variadic templates introduced an area of functionality that didn't have a robust alternative.
Besides what other people have said, inline initialization of struct and class members. struct Example { int value = 0; }; This can be incredibly elegant and save a lot of code, and has cut down the number of constructors I have to write by a lot.
All added after C++11.
Apart from the language features, the standard library being expanded is great: `unique_ptr` is the prime example. I also appreciate the effort in `filesystem` and similar libraries focused on solving cross-platform issues; and other "basic" things like `regex` that every language should have at a fingertip. They are not *needed* for very large apps, but to write small tools or small apps here and there, they are *invaluable*. Otherwise, I have to choose another language or a scripting one. Also, a great deal is the better compilers and tools that we got in the last decade. It is way nicer to program in C++ now than back then. Much faster computer hardware also helps with the really big compilation times. There is a major area left to solve yet, in my opinion (and it is one that cannot be solved by other means): Modules and Build systems (they go together).
What I appreciate: - lambdas - multithreading support - filesystem - unique and shared pointers
Wait, so before you had to declare members in ‚Äúlive‚Äù code or capture lists instead of having them like: Class myclass{ public: int counter = 0; };
Link for those (like me) who didn't knew about it: https://en.cppreference.com/w/cpp/language/if#Constexpr_If
For std algorithms 
You had to set them in the constructor
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/98rzbf/question_about_beginner_oop_design_patterns/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Although they are not out yet. For me its going to be Concepts.
callbacks
You had to do this: struct Example { int value; Example() : value(0) { } }; 
&gt; you can use objects with non-trivial constructors and destructors in unions now. (you have to call the constructor and destructor manually though)
I wish `return` was optional in lambdas.
For me personally it's unique_ptr and lambas. They're just used everywhere in code and are so handy, and no manual new/delete anymore. And then range-based for (just so convenient!) and variadic templates (I rarely write code by myself that uses variadic templates but they make the code of libraries that I use so much better). For C++17 I would probably say &lt;filesystem&gt; and `if constexpr` but it'll take 6-12 month or so more until C++17 is widespread enough to unconditionally use it.
What do you mean by this? 
 [This](https://github.com/mhogomchungu/sirikali/blob/master/src/siritask.cpp) source file from one of my projects show most of how i use lambdas in C++. ps: please don't comment about my code style, thank you.
Just allow `{ a &lt; b; }` instead of `{ return a &lt; b; }` since a lot of lambdas are tiny one-liners.
That cheatsheet looks terrific!
&gt; Most big c++ projects had already implemented equivalents, Kind of - you can't properly implement a unique_ptr without move semantics
Agreed. Generally, lambda syntax is still far too verbose. The only question within your particular suggestion is how to tell the compiler that you are only interested in the side effects. 
backwards compatibility? anyone? :D
I think you misunderstood the suggestion. It has nothing to do with side effects. The idea is to omit return keyword, so you can write `auto f = [](a, b) -&gt; a &lt; b;` Java does it like this: You can write `x -&gt; { return 2 * x; }` or `x -&gt; 2 * x`. These two are equivalent. In rust, I believe you simply omit return and semicolon from last line in block to make entire block an expression that evaluates to that line. Same effect as in java, except even more versatile.
To me this is total madness. I think many people in the c++ community drastically over-estimate the performance benefits of move in the common case, and in the cases where it really matters, it's not hard to implement your own zero copy strategy. Having move semantics is nice, but there are so many other powerful new things, move is not even top 5 for me. #1 is probably lambdas.
Do note, that the implementation of smart pointers is much easier due to move semantics (especially unique\_ptr)
More important than the performance improvement is imho the better ownership control move semantics slow.
I never hear about tests/unit tests involving lambdas. I guess the rule of thumb is if you need to create a test don't make it a lambda?
&gt;instead of an std::vector, where all code is basically duplicated for each type Modern compilers fold identical code into one, take a look at "COMDAT folding".
- RAII with move semantics - `auto` - lambda expressions
This is still C++11
For THE most important feature, it needs to be said again: smart pointers. Most other features are very nice-to-haves. Unless you're working in something like small embedded systems, real time, etc. (and even then unique pointers are close to zero cost), smart pointers should be a requirement in modern C++ code. 99% of raw new and delete should be flagged in peer review
Some of C++17 features: - init statement for if and switch reduces scope: https://en.cppreference.com/w/cpp/language/if - nested namespaces can be separated with :: https://en.cppreference.com/w/cpp/language/namespace
Implementing a zero-copy strategy might involve some backing storage space and having your algorithm operate on pointers. But with move semantics, you don't need this additional storage space, which makes code more clearly express your intent, and arguably easier to read and understand. Now I can `std::sort` a list of vectors or dump vectors into a `std::priority_queue` - the code can clearly expresses intent and yet it will work efficiently. Speaking about move semantics though, I wish we had relocability and trivial relocability semantics already. Most of the time when move semantics is used, what we actually want to express is a relocation of the object.
Or Pythagoras. err. I mean Seeplusplusagoras.
No it‚Äôs not the only reason. The reason we have move semantics is because sometimes it conceptually doesn‚Äôt make sense to copy an object. The reason we have unique_ptr is because we want to communicate there can‚Äôt be more than one owner. And auto_ptr is not the only alternative. Take a look at the Singleton pattern.
I don't normally post much on reddit, but I couldn't agree more with `constexpr`, variadic templates, and templated and non-templated using-declarations alike being absolutely wonderful additions to the language. At this point I don't know how I'd live without the metaprogramming facilities those provide.
Higher order functions and currying.
Just note that 11 is an older standard now. 14 &amp; 17 are fairly well supported by mainstream compilers.
in Java they solve this by checking whether the lambda has curly brackets or not, `x -&gt; x + 2` returns `x + 2` but `x -&gt; { x + 2 }` returns nothing
Which version was this added in?
It's what some people would refer to as "running gag". Many subs have this type of insider humor, don't take everything so seriously.
The article shows only some basic results - searching for 10000 or 100 letters from the end. It would be great to get more results, I'm happy to see your feedback! (Author here) There's already one test run in the comments on the site.
what is the difference between Synapse and Boost.Signals?
Going off your comment I think contacts will be another major feature that will change how we write and design code. 
To be honest, I don't think C++11 was as revolutionary as many say. Yes, move semantics and constexpr and SFINAE are all pretty awesome. However, IMO, what REALLY made the "Modern C++ Revolution" happen was teaching people to correctly use destructors. RAII is the KEY to Modern C++, and is 95% of what makes C++ great.
Wait till you try `if constexpr` from C++17. What would have been four different template specialisations with a lot of copy-paste code for me became one template class with a simple `if constexpr` block in the middle!
It is not (only) about performance. Without the move semantics, non-copyable types can't be stored in STL containers. I'd say that move semantics are the only revolutionary post - C++98 feature. The others are mostly nice to have.
1) Fixing std::allocator and marketing it's usefulness 2) Lambdas 3) std::thread and std::async 4) Move semantics 5) Variadic templates and perfect forwarding 6) std::chrono, user defined literals, &amp; constexpr
There is something I'm missing here: why should I not be able to use RAII (and use goto instead) just because I can't use exceptions?
Rust and I believe Ruby (though it's been a while) use a semicolon to denote it's the end of the statement. No semicolon means it's the value of the expression. ``` // Rust some_func(|p1, p2| { let x = p1 * p2; let y = p2 + 5; x + y // implicit return }); some_func_2(|p1, p2| { let x = p1 * p2; let y = p2 + 5; x + y; // pretty much never makes sense, but this will return (), which is similar to void in C++ }); ``` ``` # Ruby (it's been a while since I've worked with Ruby so probably mistakes) some_func do |p1, p2| x = p1 * p2 y = p2 + 5 x + y # implicit return end // but you can also some_func do |p1, p2| x = p1 + p2 y = p2 + 5 x + y; # returns nil end ``` Of course, both of these languages are expression oriented in general, so this kind of stuff works in anonymous blocks or normal functions as well.
I agree, and I think this was a reply to the post one further up. Right?
&gt; Also, a great deal is the better compilers and tools that we got in the last decade. It is way nicer to program in C++ now than back then. Ten years ago my opinion was that almost everyone people who started to learn programming with C or C++ was making a mistake, and that the (admittedly few) universities using that in their intro courses was insane. To me, there's just too much "distraction" in those languages from *learning programming*. To me, learning programming is about learning to break down a problem and specify it precisely in a formal language. Things like memory management, learning to diagnose buffer overruns and similar, in the case of C in particular an anemic standard library -- these aren't *learning programming* really, they're learning to deal with what are today the particular quirks of those languages. Still pretty necessary to learn at some point to go beyond a coding grunt, but I think they detract way more than they add. I still think that the above applies today, but I no longer think it's *insane*. I think one could actually build a very compelling intro programming class around C and/or C++ (not sure what I think about the and/or here) when you combine it with modern tools. Teach "always use high warning flags" and require assignment submissions compile cleanly with some chosen set. Teach, *from Day 1*, "use `-fsanitize=address` as nearly a first-line defense when something is going wrong and you don't quickly see why", and maybe even for purposes of the class suggest turning it on *standard* during development and/or require that any tests you run as part of grading are on an asan-enabled build. Bring in the other sanitizers as well.
[something like this](https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/statements-expressions-operators/lambda-expressions) you mean?
It may help to say "type factory" instead of "type function". I know this is not that big of a difference, but C++ programmers are often used to functions that aren't mathematical functions.
for what it's worth, I would absolutely hate this. There's a point where we take away too much verbosity, and are left with a hard to parse symbol soup. Keywords help keep things readable.
How do you signalise an error from a constructor?
I want `default` to be useable to indicate I want a default parameter injection. `foo(1, default, 3);` And I want named parameters.
I'm saying that __assume() is a poorly designed language construct because there is a large gap between what you can provide and what will actually work. The documentation for it provides no examples other than __assume(false), and though it sounds flexible, even relatively simple expressions have no effect: https://gcc.godbolt.org/z/nUEpQl Similarly, allowing the programmer to specify ranges for alias overlap is potentially powerful but also useless if the compiler doesn't make use of that detailed information. I don't have much confidence in compilers to consistently do this when the range bounds are complex variable expressions. If the range syntax would be the _only_ way to specify non-aliasing between two pointers, then that is a lot of unnecessary burden on the programmer compared to just 'restrict'. 
Isn't that still C++11? Shouldn't the example be: struct Example { int value; Example() { value = 0; } };
&gt; C (and C++) compilers are becoming notorious for exploiting the notion of undefined behaviour Kinda, but this statement makes it sound like as if compiler authors always do this on purpose to suit their own needs rather than others'. The reality is that compilers have to contend with vastly different architectures, that have esoteric functionality. So either you trade performance for strictly enforcing well defined behaviour everywhere, or generate code that maps to the underlying hardware the best as possible. For signed integers, it seems that the language people opted for the latter, mostly because signed integer arithmetic is heavily used, and thus would require a lot of boilerplate for mitigating overflow conditions. &gt; Personally, I feel that I would much rather have trap on overflow than wrap. That is, I would rather that a program crash instead of continuing with either undefined behaviour or a potentially incorrect value Depending on how this is implemented, I tend to lean on the "disagree" side. Mostly because a number of CPUs don't really offer hardware exceptions for singed overflows, and thus checks must be done in code, which is expensive. Also because I think such exceptions should be enabled as part of a tooling option, and not part of a language feature. Much the same can be said about division by zero situations, floating point arithmetic blowing up, null/bad pointers, and so on. I think the bigger issues are things like unsafe casts between different flavours of integers, where sign extensions might not be enforced. Then you get horror shows, where bit-wise logic ops are mixed with arithmetic, and a few static casts thrown in between for a good measure. In my experience, this where most of my integer bugs where discovered. Overflows/underflows not so much in comparison.
&gt; That is, I would rather that a program crash instead of continuing with either undefined behaviour or a potentially incorrect value, either of which could be a security issue. 99.999% of my integer wrapping bugs were actually with unsigned integers (e.g. size_t), for which the behaviour is perfectly defined - I believe that both unsigned and signed should trap (given adequate compiler flags, and that's what -fsanitize=undefined actually provides !) and that applications that really require 2's complement semantics integers (e.g. hashes, etc) should have a specific wrapping_uintN_t type.
Threads. Ever wanted to make a cross-platform program with threading? All the other stuff is good but personally I like having a standardized way to do threading more.
IMO Meyers' Singleton is one of the most important modern C++ techniques, and the C++11 language feature "magic statics", which provides for thread-safe initialization of static variables, is therefore pretty important as well
You don't. You wrap everything in factory methods and return std::optional everywhere, or you have two stage initialisation where the second stage can fail. Not advocating this at all, by the way.
How would this look to a linker? Would the use of placement new prohibited in with such structures? For example if you have resources (strings/bitmaps/data) in a .rodata data section, could the structures still be used or would you need some new layer. Seems like using structs containing autos in source for a DSP would also be particularly problematic in my limited understanding.
&gt; https://gcc.godbolt.org/z/nUEpQl `-O3` isn't a meaningful flag for MSVC. If you use the correct flag (`-O2`), you will see that [it most certainly has an effect](https://gcc.godbolt.org/z/dkyVU-) - note that `bar` now just returns 1 instead of performing a comparison.
Not sure how you'd qualify posting the same nonsensical comment on every blog post as fun. Given how controversial the comments are and how often they get reported, I don't really think they belong here. Once or twice, sure... but 6+ times?
You just wish that you had pumpkins.
You are ignoring the main point of the complaint: Modern computers go fast beyond just saying: Let's implement overflow as what ever the corresponding assembler instruction happens to do on the particular platform (be it wrap around, trap, saturation etc). They use the knowledge that overflow isn't allowed to happen in a legal c++ program to prune branches and simplify expressions which can lead to arbitrarily strange behavior, when the program turns out top violate that assumption/contract. Personally, I don't have a problem with that, but only if there are clear benefits in significant real world code and thats what I haven't seen so far. Assuming that real world code is bug free and thus the c++ programmer doesn't care what happens in case of bugs is a somewhat problematic assumption. I mean, how many programs really verify that no possible (malicious) input can lead to an overflow somewhere in the belly of a utility function somewhere down the call stack? How many do it correctly?
Or you just never fail.
I think the big ones are: * shared/unique/weak pointers. * threads and locks. * making move available for library functions. * (C++17) optional * strongly typed enums. (I actually use them now. I used to avoid them like the plague. I did not include move semantics themselves as I think they are syntactic sugar.
NSDMI, because it saved so many lines of code, and eliminated so many forgotten initialisations. Also, I'm surprised to see nobody mentioning \`override\`. My only regret is that it hasn't been made mandatory.
To be honest, destructors are a bit overrated. Yes, they are the best thing ever for memory management and some other operations that typically don't fail (e.g. computation) or we don't care if they fail. On that point, I agree and I am the biggest fan of `unique_ptr` and friends. However, for many problems, destructors cannot be used at all since you need to handle error conditions on release. This point is understated many times.
Those two are syntax sugar. While I am grateful we have them, I am afraid they do not introduce big improvements :(
From what I can tell, initializer lists were added in C++ 2.0 -- 1989 -- and were recommended practice in C++98.
Sure, but you can debug a lot more than language level errors, and I posit the same thing applies to them -- it's better to start off debugging algorithmic problems than language problems.
Really? I could have sworn C++ Primer said that was a C++11 feature.
Sorry that's just where most of my C++ knowledge comes from. Thanks for the clarification. 
&gt; I believe that both unsigned and signed should trap (given adequate compiler flags, and that's what `-fsanitize=undefined` actually provides !) and that applications that really require 2's complement semantics integers (e.g. hashes, etc) should have a specific `wrapping_uintN_t` type. Which is the reason why after using unsigned types so much, and being bitten by overflows regularly (what do you mean, `5u &lt; -4`?), I now agree with Stroustrup (?) who stated that sizes, indices, etc... should have used signed integers, and unsigned integers should be reserved when wrapping behavior is actually desired (ie, not often). A single bit is generally unnecessary, and it's much easier to realize that `-1` is a bogus size, rather than deciding whether `65535` is. 
auto keyword for types, and range based for loops. Look, I know other folks have objectively better answers about stuff that changed the way C++ works. Stuff that made it easier to write more Correct code and such. My answers are really just syntactic sugar that don't fundamentally change the language semantically. But those are the two tweaks that made C++ pleasant to write for me. And pleasant to read! Iterators were always kind of a brilliant idea that looked ugly. Actually dealing with them was always kind of a gross pain. The code was super verbose compared to old school C for loops with an int as the "iterator." And all the extra code made it less obvious what was happening, which made it more of a slog to debug when it was doing something wrong. for (auto i : some_collection) {} is terse without being obscure. And it's what made me love C++ again. And for all the theoretical goodness of differentiating std::shared_pointer and st::unique_pointer rather than just having a std::auto_pointer -- I wouldn't have been writing more correct code in C++11 without the syntactical sugar, because I wouldn't have been writing as much C++.
Absolutely not. Initializer lists in constructors are way older.
&gt; Kinda, but this statement makes it sound like as if compiler authors always do this on purpose to suit their own needs rather than others'. I would argue that in the end, compiler authors are trying to please their users. Users of C or C++ seem to pick the compilers generating the fastest code possible (that they are willing to afford), and therefore compiler authors strive to generate the fastest code possible. In the case of C and C++, it seems a reasonable trade-off: there's no lower-level portable language to turn to if speed is necessary! Of course, whether there is an actual performance gain, and whether such a performance gain actually requires undefined behavior or could be achieved with only implementation defined behavior... is a whole other question.
&gt; or you have two stage initialisation where the second stage can fail. Game industry 101
Yes, making it mandatory would had made the code much clearer.
I have... contradicting thoughts on the topic. I am doubtful of the performance gains enabled by Undefined Behavior, and therefore would rather have a perfectly defined behavior: Wrap OR Trap. I would note that this is the choice that Rust made; by default its Debug binaries will Trap on overflow, whereas its Release binaries will Wrap, and a flag can be used to switch back and forth between the two behaviors. It does not seem to meaningfully impact the speed of Rust binaries, unlike bounds checking. However, between Wrap and Trap, I have a hard time deciding even before considering the performance impact: - On the one hand, Trap has my preference from a developer's point of view: if there's a bug, I'd like to be informed as soon as possible. - On the other hand, Wrap is, ironically, closer to the mathematical ideal of integrals. As mathematically expected, `2u - 3 + 1 == 0`! That is, temporary overflows in modulo arithmetic can compensate for the lack of an infinite bitwidth. I find it awkward when an expression is mathematically correct, but must be broken down in multiple expressions with run-time switches to avoid temporary overflows depending on the values of its inputs. And when I consider that Trap, unfortunately, incurs a rather significant performance overhead in current implementations (`-fsanitize=...` are designed for debugging, not hardening, so not particularly optimal); I suppose Wrap is the least evil choice.
It'd be useful to have separate timings for construction of the search object. Knowing that overhead would help decide when the more complex searches were worth using.
anyone knows how to separate this? probably we'd have to ask compiler/library people.
Well, maybe we can agree both extremes get overused at times. For example, even though I think string has too many member functions, I argued in LEWG that starts_with and ends_with need to be member functions, because free functions would have usability issues: starts_with(foo, bar); // ??? which is which? foo.starts_with(bar); // obvious 
Yeah it's a great cheatsheet. A year ago, I was going to create one for C++17 until I found this one.
Even if this is an unpopular opinion, it does not deserve the downvotes. Move semantics may not be the most important part of modern c++ for many workflows -- we've used it for decades without. It's not hard to see other things being more applicable to certain situations. We should encourage discussion even if we don't agree. Downvoting this stuff hides the insightful commentary on this thread that follows. 
ah... you can actually do that: the ctor of the searcher performs that preprocessing see cpp reference (as it was suggested by @STL) &gt;Constructs a boyer\_moore\_searcher by storing copies of pat\_first, pat\_last, hf, and pred, setting up any necessary internal data structures. 
You can remove the (?) after "Stroustrup". CppCon https://www.youtube.com/watch?v=Puio5dly9N8 First mention is at 9:50, and then it is talked about in more detail later on. 41:08 for the long answer 1:02:50 for where they just give the short answer: ‚Äúsorry‚Äù
&gt; And when I consider that Trap, unfortunately, incurs a rather significant performance overhead in current implementations (-fsanitize=... are designed for debugging, not hardening, so not particularly optimal); I suppose Wrap is the least evil choice. Personally, I'd prefer to pressure CPU manufacturers to start introducing trapping integer operations and define it that way, even though it'd take a decade or two to cycle into use. That's a security argument: *fail safe*.
&gt; In my opinion, a compiler should not by default optimize based on the belief that UB will not occur. Congrats, you just prevented register-allocating variables. The problem is there's no reasonable way for a compiler to discern intent. For example, suppose a compiler removes code based on UB. The problem is, there are plenty of times when I *want* it to remove code because the UB *actually* can't happen. My half-serious statement on this position is that the compiler *does* have the QOI setting that you say you want -- it's called `-O0`.
Can you provide examples on this and why register allocations can not be performed? Notice that I do not want my compiler to avoid executing code involving UB, only not to optimize based on it. If that is the case, I am willing to change my opinion. ;-) Can we agree that in a statement like if (a + 1000 &lt; a) { ... }, the fact that this compiles without a compiler warning is at least a problem that in the ideal world should be solved? 
What do you guys think of the alternative declarations for functions/members? I.e., which do you prefer: class A { auto foo(int x) -&gt; void; }; or class A { void foo(int x); };
I feel like people forget this one because its so obviously a correct extension to the language that its just fallen immediately into place and been forgotten about that its a new feature
&gt; Can you provide examples on this and why register allocations can not be performed? What I mean is something like the following: void escape(int *); int write_to_array(int index, int val) { int x; escape(&amp;x); x = 0; int array[100]; array[index] = val; return x; } Current compilers will, of course, optimize this to just a call to `escape` and then `return 0;` -- they know that `x` has the value 0 at the return. I'd argue this is incorrect if you can't optimize based on UB. The `escape(&amp;x)` call means that `x` must have an address. In the absence of UB and on this architecture, there will be some value of `index` for which `&amp;array[index] == &amp;x`, so for that value of `index` assuming that `x` has the value 0 after the array assignment is incorrect, so any optimizations based on it having the value 0 is incorrect. I guess you could technically argue that a variable that's never address taken shouldn't have a guarantee, even in the absence of UB, that they'd be located in memory, but it's pretty easy to regain that assumption in other ways too. Basically, any memory write to a computed address would result in clobbering the entire abstract memory state and cause the compiler to need to generate code that reloads everything from memory again. &gt; Can we agree that in a statement like if (a + 1000 &lt; a) { ... }, the fact that this compiles without a compiler warning is at least a problem that in the ideal world should be solved? In that specific example, yes. However, with some minor changes -- no. For example, put `if (a + b &lt; a)` instead and have some other optimization prove that `b` is 1000? Totally should optimize based on it. Chris Lattner talked about this in [a blog post a while back](http://blog.llvm.org/2011/05/what-every-c-programmer-should-know_21.html): &gt; **Why can't you warn when optimizing based on undefined behavior?** &gt; People often ask why the compiler doesn't produce warnings when it is taking advantage of undefined behavior to do an optimization, since any such case might actually be a bug in the user code. The challenges with this approach are that it is 1) likely to generate far too many warnings to be useful - because these optimizations kick in all the time when there is no bug, 2) it is really tricky to generate these warnings only when people want them, and 3) we have no good way to express (to the user) how a series of optimizations combined to expose the opportunity being optimized. and then elaborates on each of those thnigs.
XML Master Race!
`(a + 1000 &lt; a)` evaluates to `false` at compile time, as it should. The compiler/optimiser doesn't know or care if you wrote exactly that or whether it ended up with that expression after several passes of template instantiation, constant propagation, compile-time evaluation, etc. That these sorts of inferences can be done is a very good thing for performance. Of course there is nothing stopping a source-level static analyser giving you a warning like "expression is always true/false". I believe 'register allocation' might be in reference to some other forms of UB, such violating aliasing rules, without which any write through any pointer or reference can potentially change any variable, forcing it to be reloaded from memory. Or perhaps that race conditions are UB, without which any non-local variable could be changed at any time by other thread. "optimize based belief that UB will not occur" is exactly what UB is - it is a contract between the programmer and the compiler. As a programmer you promise not to do certain things (which in general cannot be detected at compile time), and the compiler will generate nice, fast code on that basis.
Yep, C# also has nice concise lambdas.
Is there a vim mode?
Thanks for adding wide string support.
I'm on Mac, which settings did you change?
Hmm, sorry, just wonder... Can you say a bit more about how decltype make difference? 
This wouldn't turn it into Perl, just put it in line with other major modern languages. Oh, don't forget that you'd be getting rid of curly braces too!
And, again, personally, I find the way those other languages express themselves to be very difficult to read and prone to mistakes. Saying we should "just put it in line with other major modern languages" can be countered by "If all of the other major modern languages jumped off a bridge, would you jump too?". We don't need C++ to be other languages. We need C++ to be C++. Many a time I've corrected an intern or jr. engineer's use of syntax sugar that looks like it does the right thing that doesn't. Sometimes removing verbosity is good, and other times it causes direct, measurable, harm to my personal bottom line. I think the level of verbosity for lambdas is bordering on not enough verbosity. E.g. I find the notion of not specifying return type of lambda to be of *debatable* value. I'm on the fence about it. And I certainly didn't forget about getting rid of the curly braces. I consider that a significant negative, which directly contributes to me disliking the idea.
Post C++11 things didn't improve! They just fixed a lot of the ambiguity in things and tried to make things a bit more predictable. Half the problem with C++ is the programmer, not the language. C++ makes it too easy to screw up, and some devs like to use every language feature available for no reason. I hate C++ \*because\* it is too easy to screw up. I use it as nothing more than glorified assembler written in English. \^\_\^ Classes, STL, and generics? Pffft! Crutches for those who can't think.
Why is that a win? Less typing for the sake of less typing? Sounds like a great way for a junior engineer to screw something up and give me more work to do, without actually adding any new capabilities to the language. [](x, y) =&gt; (x + y) To me, in my head, this parses as: Weird array operator noise? Equal to or greater than? X+Y Not a lambda which returns x+y. [](x, y) =&gt; (x + y) [](x, y) { return x + y; } They come out to basically the same amount of typing. If you're just looking to have the syntax sugar add noexcept(noexcept(whatever)) to your lambda, go talk to the folks who are working on noexcept(auto). That's the proper way to accomplish this, not adding symbol-soup to the language. 
Also Bjarne Stroustrup: "People use OOP when they shouldn't, and fail to use it when they should."
I'm a C guy using a C++ compiler, and I know it. :P
Actually I find it is those who have least understanding trying to use every language feature. I work on large projects and do fine with just the basics. Most of what is available in C++ just seems to be a crutch or something for those who can't think.
If someone can't figure out how to indent their code to make it readable, they shouldn't be writing software. Something I read a loooooong time ago: if you can't \*read\* your code, how do you expect to write \*reliable\* code?
This guy's blog gets posted *all* *the* *time*, and it's really tiresome. Some posts are interesting. Others feel dry and incomplete. I take solace in this running gag. I'll always upvote it.
*If you can't throw an exception and can't use final_action (finally) from the guideline support library, you have a problem.* I don't buy this. You don't have a problem. It doesn't take a rocket scientist to implement your own gsl::finally/final_act.
No. Header files are for code, not documentation. Give me a readme of your file structure and a broad overview of what each function does, at least.
C++ is unsafe? More like: the user using C++ is unsafe. ;) C/C++ are only hard/"unsafe" if you don't understand what the heck you're doing. The first programming courses should be in assembler. It will give a solid understanding of what the computer is really doing.
The real problem is the use of Java as a first programming language. More to the point: it requires less knowledge by the tutor to "teach" and just screws up the student's understanding of software engineering. They get taught to use program features without questioning why they're doing what they're doing, rather than thinking.
-server -Xss256k -Xms4G -Xmx4G -XX:NewSize=1G -XX:MaxNewSize=1G -XX:ReservedCodeCacheSize=512M -XX:SoftRefLRUPolicyMSPerMB=50 -XX:+UseConcMarkSweepGC -XX:+UseParNewGC -XX:+UseBiasedLocking -XX:+UseCMSInitiatingOccupancyOnly -XX:+CMSClassUnloadingEnabled -XX:CMSInitiatingOccupancyFraction=70 -XX:+ScavengeBeforeFullGC -XX:+CMSScavengeBeforeRemark -XX:+CMSParallelRemarkEnabled -XX:ParallelGCThreads=8 -XX:MaxTenuringThreshold=15 -XX:SurvivorRatio=12 -XX:+AggressiveOpts -XX:MaxJavaStackTraceDepth=0 -XX:-OmitStackTraceInFastThrow -XX:+ExplicitGCInvokesConcurrent -XX:+UseStringCache -XX:+UseFastAccessorMethods -ea -Dsun.io.useCanonCaches=true -Dsun.io.useCanonPrefixCache=true
Does it handle `string_view` gracefully, now? I remember a year or two ago it had compilation issues with the experimental support of it
Next you'll say 'Dodo bird Master Race!" ;)
You can by swapping it with a null unique ptr. Passing ownership into a function is messy but you could still do it
Well, that's what I meant by "properly". Sure, you can essentially put the move functionality into nsmed functions and / or tagged copy constructors, but the result is far less convenient to handle.
Have fun figuring out the type of some weird templates without it. Or even for something simple like a `std::map`. You want to have a custom comparator, and you can do that with a lambda and a `decltype(mylambda)` in the template parameter (and there's no other option there actually, because lambdas don't have types that are writeable manually.
Serious question: do people actually write better code, or code that just looks better?
Unfortunately, Reddit doesn't support those kinds of code blocks. I've taken the liberty of reformatting your comment. ----------------------------- Rust and I believe Ruby (though it's been a while) use a semicolon to denote it's the end of the statement. No semicolon means it's the value of the expression. // Rust some_func(|p1, p2| { let x = p1 * p2; let y = p2 + 5; x + y // implicit return }); some_func_2(|p1, p2| { let x = p1 * p2; let y = p2 + 5; x + y; // pretty much never makes sense, but this will return (), which is similar to void in C++ }); # Ruby (it's been a while since I've worked with Ruby so probably mistakes) some_func do |p1, p2| x = p1 * p2 y = p2 + 5 x + y # implicit return end # but you can also some_func do |p1, p2| x = p1 + p2 y = p2 + 5 x + y; # returns nil end Of course, both of these languages are expression oriented in general, so this kind of stuff works in anonymous blocks or normal functions as well.
What is the benefit of this over a zstring_view that is always null terminated? I don't understand what situations you wouldn't need it to be null terminated but you'd want to preserve that information somehow. Basically I don't see the need for a "smart" version vs havein string_view and zstring_view. 
The compiler is not required to do anything special for __builtin_unreachable and restrict, either. They are all just hints.
Can it parse json iteratively (eg give me array elements one by one without reading the whole file first like python-ijson does)?
We only enable \`string\_view\` support for C++17 compilers. Then, it should work.
Yes, this is possible via the newly introduced SAX interface.
Nice work, thanks! Also "Finally, the JSON parser is now non-recursive (meaning it does not use the call stack, but std::vector&lt;bool&gt; to track the hierarchy of structured values) which allows to process nested input more efficiently." std::vector&lt;bool&gt; is in my experience pretty horrible when it comes to efficiency since every read creates a temporary object that pretends to be a reference to a bool, since it is internally represented using one bit per bool. Changing to std::vector&lt;int8_t&gt; or similar might give you a speedup and it avoids the traps of the unfortunate std::vector&lt;bool&gt;
Well, that‚Äôs okay with me. The only time I ever used `vector&lt;bool&gt;` was in a generic context, and it was enough to put me off ever doing so again.
&gt;Do you know, what DRY stands for? Don't Repeat Yourself. \*repeats calls to is_valid()
The potential pitfall of it being unexpectedly slow is also a drawback.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
[http://quick-bench.com/leAYXQJembIatTGbB8\_I\_BheZww](http://quick-bench.com/leAYXQJembIatTGbB8_I_BheZww) benchmarks are sometimes tricky/not representative, but this at least gives an idea :D 
What about a wording similar to the definition of *trivially copyable* as in \[class.prop\]: &gt;A *trivially relocatable class* is a class: &gt; &gt; \- where each move constructor ([\[class.copy.ctor\]](http://eel.is/c++draft/class.copy.ctor)) is either deleted or trivial, &gt; &gt; \- that has at least one non-deleted move constructor and &gt; &gt; \- that has a trivial, non-deleted [destructor](http://eel.is/c++draft/class.dtor)[.](http://eel.is/c++draft/class.prop#1.3.sentence-1) Or what about or more permissive one: In \[class.copy.ctor\]: &gt;A *relocation eligible move constructor* is a move constructor which is either trivial or is a member of a class declared with the `[[trivially_relocatable]]` attribute. In \[class.dtor\]: &gt;A *relocation eligible destructor* is a destructor which is either trivial or is a member of a class declared with the `[[trivially_relocatable]]` attribute. In \[class.prop\]: &gt;A *trivially relocatable class* is either a class that is declared with the `[[trivially_relocatable]]` attribute, or a class : &gt; &gt; \- where each move constructor ([\[class.copy.ctor\]](http://eel.is/c++draft/class.copy.ctor)) is either deleted or is a *relocation eligible move constructor,* &gt; &gt; \- that has at least one non-deleted move constructor and, &gt; &gt; \- that has *relocation eligible,* non-deleted [destructor](http://eel.is/c++draft/class.dtor).
Good point. I shall have another look.
Thanks! Where do I actually have to set these?
Actualy I failed to do what I intended, so a permissive recursive definition would be: In \[class.copy.ctor\]: &gt;A *relocation eligible copy/move constructor* is a member of a class declared with the `[[trivially_relocatable]]` attribute or is not user-provided and: &gt; &gt; \- class X has no virtual functions ([\[class.virtual\]](http://eel.is/c++draft/class.virtual)) and no virtual base classes ([\[class.mi\]](http://eel.is/c++draft/class.mi)), and &gt; &gt; \- the constructor selected to copy/move each direct base class subobject is a *relocation eligible copy/move constructor* &gt; &gt; \- for each non-static data member of X that is of class type (or array thereof), the constructor selected to copy/move that member is either trivial or is a *relocation eligible copy/move constructor*; In \[class.dtor\]: &gt;A *relocation eligible destructor* is a destructor, member of a class declared with the `[[trivially_relocatable]]` attribute or is not user-provided and: &gt; &gt; \- the destructor is not virtual, &gt; &gt; \- all of the direct base classes of its class have *relocation eligible destructor*, and &gt; &gt; \- for all of the non-static data members of its class that are of class type (or array thereof), each such class has a trivial destructor or a *relocation eligible destructor.* In \[class.prop\]: &gt;A *trivially relocatable class* is either a class : &gt; &gt;\- where each move constructor ([\[class.copy.ctor\]](http://eel.is/c++draft/class.copy.ctor)) is either deleted or is a *relocation eligible move constructor,* &gt; &gt;\- that has at least one non-deleted move constructor and, &gt; &gt;\- that has *relocation eligible,* non-deleted [destructor](http://eel.is/c++draft/class.dtor).
There was 1 more interesting bug which we got rid of in C++17: - it was not possible to create a type alias to functions with dynamic exception specification We no longer have dynamic exception specification so the problem is gone.
both clang and GCC can warn for this (-Wsign-compare) - that's a fairly common warning.
I echo the view that a null termination aware string view is pretty much useless in the real world. The only use case of any size is for filesystem paths, and https://wg21.link/P1030 *std::filesystem::path_view* ought to cover almost all of them. `path_view` also is zero termination aware, and takes care of UTF conversions where necessary. So far, committee feedback on it is positive, so it may stand some chance for C++ 23.
Do you have some public example code for this? In principle I agree. Essentially I can always find a situation, where an otherwise horrible construct is the best match. On the other side, I prefer hard checkable rules (don't do X) over "avoid ... " even if that rule isn't optimal in some edge cases. "Don't use goto" is such a rule, But in the end, if it generates actual business value - well, there are much worse sins you can commit in SW development.
Github is great: https://github.com/ned14/llfio/search?q=goto&amp;unscoped_q=goto I should stress that I don't claim that each of those is the ideal use case. Sometimes I am lazy just as much as the next guy. But I also don't sweat it too much, as you very accurately said, there are much worse sins you can commit in software development than occasional use of `goto` (which, incidentally, everybody understands well, which isn't the case with many template metaprogramming constructs). 
I have a problem with parsing floats, everything gets rounded, any idea what's the problem ?
Great! Hope you enjoy it. Let me know if you'll have any issues with RESTinio. 
Mandatory dependencies are: * [ASIO](https://github.com/chriskohlhoff/asio) (or Boost::ASIO) * [nodejs/http-parser](https://github.com/nodejs/http-parser) * (fmtlib)(https://github.com/fmtlib/fmt) There are optional dependencies to enable extra features: * Zlib for [compression](https://stiffstream.com/en/docs/restinio/0.4/compression.html) * PCRE/PCRE2, Boost regex for different regex engines [https://stiffstream.com/en/docs/restinio/0.4/expressrouter.html#regex-engines] * OpenSSL for [TLS support](https://stiffstream.com/en/docs/restinio/0.4/tls.html).
The tool is always run (the prebuild command in the cmake integration is a cmake add_custom_command() internally, which are always run if the target they depend need to be built. It is the tool itself which detects whether a whole reparse is needed (simple timestamp check). So what you should see is that the generated headers are regenerated whenever their source headers change. If that's not the case please ping me with an issue in the repo.
Thanks for the reply. All these dependencies is a deal breaker for me to try a new library. I tried to evaluate a couple of websocket libraries just a few days ago and ended up with a very tiny wrapper around winsock to get something working before spending a day or more trying to compile and link all the dependencies of other libraries. When I see a new library with all these dependencies, my thought is that the chances that it will work well enough to be worth the trouble are very slim. Calling something 'header only' when it is going to require figuring out cmake error, include paths etc. from half a dozen other large libraries is a huge misnomer. There is a link called uWebsocket that is very similar, at least to the course details of this project.
Honestly this is complete bullshit. When the standard considered threads did not exist, compiler supported them. What tons of people do not understand, is there are TONS of different kind of UB; and it the current situation has shown that even compiler writer have sometimes missed that subtlety. So of course we are going to take shortcut when talking about that mess, requiring that compiler optimize **less** based on UB. But it's not our fault that so different things have been grouped under the same umbrella, despite some of them having nothing in common. It's a shortcoming of the standard. As for UB that can not actually happen, yes, it exists; just if you want to build actually reliable systems, you have to **actually prove** that the situation will not happen. It merely being written as forbidden in a footnote of a 2000 page standard that 1% of the programmer read is **not a proof in any sense of the term!** Modern safe languages are competitive despite not having taken that clueless approach, btw. Arguably there is still a gap. I predict it will diminish. I also predict that the market will eventually be tired of the 50% of vulns caused by unsafe languages. 
We use `double` to store floating-point numbers internally. What exactly is your issue? Could you open an issue at GitHub, preferably with example code?
You have to take the current situation into account: compiler do not exploit all UB, yet a non negligible proportion of programmers think since a few year that they already exploit far too much. So the visceral reaction of requiring a complete lack of UB related optim is understandable but misguided (because in the C and even more in the C++ context, that request would be actually quite meaningless). But the opposite absolute indiscriminate defense of all UB related optim as a good thing, per contract (the Standard) between the programmer and the compiler is likewise missing the big picture. The big picture includes existing code bases. And UB based vulns, hitting the industry over and over. Engineering is not pure math and ponies. Especially when we are talking of a language standard that is not written in a formal language, and even more when part of the problem is very much that it tells us that it is acceptable to stop all thinking in some situations, and simply pretend that they absolutely do not exist instead. So we are not going to have a Standard with radically less UB any time soon. That means that compiler writers will actually will have to act and think responsibly themselves. And they already know how to do it when they are forced to. But nobody sane should think this means that we want that e.g. buffer overflows to suddenly be well defined over night. Simply I'm starting to have heart attacks when I see discussions and talks about origin of pointer tracking *including when casted to integers and back*. And that the tone of the discussion is **not** that the tracking should stop when casted to an integer, but merely that we should invent yet another manual laundering device to gently tell the compiler to not emit COMPLETE SHIT. Oh, this means we would have basically *no way* to port existing actual system code to new conforming compilers, btw (manually identify all the places? come on; you know some will be missed, and that will cause hard to find bugs). Or when I hear people emitting the notion that maybe one day it could perhaps be a good idea to strip char from its universal alias property. Yeah right; RemindMe! 50 years "Char is not an universal alias anymore! Youpi! More bugs to fix!" IMO persisting in that kind of approach even after we saw that it basically failed as far as reliability is concerned, will eventually kill the language. 
I will be messaging you on [**2068-08-21 12:53:44 UTC**](http://www.wolframalpha.com/input/?i=2068-08-21 12:53:44 UTC To Local Time) to remind you of [**this link.**](https://www.reddit.com/r/cpp/comments/98sxuf/wrap_on_integer_overflow_is_not_a_good_idea/) [**CLICK THIS LINK**](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[https://www.reddit.com/r/cpp/comments/98sxuf/wrap_on_integer_overflow_is_not_a_good_idea/]%0A%0ARemindMe! 50 years ) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete Comment&amp;message=Delete! ____id____) _____ |[^(FAQs)](http://np.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^(Custom)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^(Your Reminders)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List Of Reminders&amp;message=MyReminders!)|[^(Feedback)](http://np.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback)|[^(Code)](https://github.com/SIlver--/remindmebot-reddit)|[^(Browser Extensions)](https://np.reddit.com/r/RemindMeBot/comments/4kldad/remindmebot_extensions/) |-|-|-|-|-|-|
I found this last year when working on a project that needed a WebSocket server and client. Too much dependency-heavy stuff (with heavy dependencies) that seemed to be impossible to build, especially on Windows; too much stuff that looked rather painful to integrate with libuv on account of its expecting to be able to call `recv` (or equivalent). So in the end, I just wrote one. The WebSockets protocol is rather weird in places, but it turns into code neatly enough, and it's not at all painful to work with using libuv's callback-based style. There's a good test suite in the shape of [the Autobahn test suite](https://github.com/crossbario/autobahn-testsuite) that's easy to get running. 
I‚Äôd just skip the union - the memory savings is going to be pretty trivial, and offset by significantly reduced potential for bugs. If you really want to keep it all separate, make Field virtual and subtype for different types of values. 
Well, it is an engineering approach, taking suitable tools and build a thing upon them. How many folks out there can build something as ASIO (with all its portability and considerable performance)? Despite it has a single maintainer it was in many aspects developed by the community. And even stronger arguments for not to reinvent the weal is OpenSSL or regex libs. So, yes, RESTinio is not a self-contained lib, it benefits from other open source libraries, which are well tested, efficient and portable. But I agree that putting a bunch of external libs under a single build tool is in most cases a pain in C++ world. It can in some sense be cured by tools like Conan or Vcpkg, but very likely once upon a time, you'll want a lib that is not there yet. Well, it's separate discussion though.
wow! great timing. I needed this..
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/993pek/c_reactive_programming_book/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Complete avoidance of dependencies in a C++ library is not a great one. Two of the three mandatory dependencies are header-only - the third one, nodejs/http-parser, is pretty vanilla.
Variadic templates instantly scare off everyone in my company from looking at my code. It is like a light switch. The second I add them, my code gets way less review attention. I personally love them, but they do look terrible and we must acknowledge that there are a ton of people who are extremely competent engineers who want nothing to do with them.
The redesign does support it, which is why I use it. I feel bad because I know everyone not on the redesign can't see it, but it's just so incredibly convenient I can't help myself, especially when I'm on mobile (which I was).
Looks good so far. I like the flow of your article and appreciate the quick jump straight into examples. Keep it up! I use cmake with qt for cross platform apps. I‚Äôm exited to read future articles. (Mac, Windows) My wish-list for future articles: - packaging for deployment/distribution (cross platform, optionally including qt dependencies) - statically building qt from sources and linking to that - translations - QML - optimization flags for release build for msvc/clang/etc..
I don't use C++ much anymore, the bulk of recent programming has been in Python, and that is more casual programming than anything. In any event I have to agree with your point about people least able to understand a feature to be someone to use said feature and then damn C++ because they don't grasp the feature. On the other hand I wouldn't call most of C++ features to be a crutch. Rather they have many features that are useful to people that might be writing libraries, complex software or other focused issues. General programming doesn't need to use all of these features and if they do it should be implemented by some one capable. In a way C++ invites people to program beyond their capabilities, but that isn't a bad feature of the language. What would be great (it is coming very slowly) is to see the committee devote one release of the standard that focuses not on the language but rather the libraries. One of the reasons I use Python is that it is pretty fleshed out with a good standard library. Most of those libraries abstract out the operating system so you can avoid platform specific code.
Thank you! Oops... you're right! :)
Yes, if you want to be uselessly pedantic, the compiler is not required to do anything at all related to performance because it is not part of the observable behavior of the abstract machine defined by C++ that limits the 'as-if' rule. These features are, however, are highly effective on the compilers that support them. 
Singleton is often an anti-pattern.
Sorry to be cheeky, but since there's a wish list going... Would it be at all possible to see advice on using CMake and Qt to not only build for both Windows and Linux, but to _cross compile_ for Windows targets from Linux? It'd be really great to virtualize our build environment, but the Windows builds make this very difficult. Or is this barking up the wrong tree?
And still ugly compared to real modern way of assembling build targets like buck, bazel, gn, please.build or pants... This still looks ugly no matter what: target_include_directories(Foo PUBLIC ${PROJECT_SOURCE_DIR}/public PRIVATE ${PROJECT_SOURCE_DIR}/src ) It just doesn't flow really well - and doesn't signal me when I have to use the UPPERCASE and then not. 
Thanks digging up the reference!
Like most warts in C++, cause C did it. Though I recall there is a proposal to change it, probably as part of Herb's consistent comparison proposal, so that signed unsigned comparisons will give the correct result.
&gt; In my opinion, a compiler should not by default optimize based on the belief that UB will not occur. This is, unfortunately, a very simplistic view of compilation. An optimizer is *dumb*. Or most specifically, an optimizer is a relatively good (heuristically) pipeline of hundreds of very dumb, very simple, individual optimization passes. [Check LLVM's list of passes, for example](https://llvm.org/docs/Passes.html). Optimization on Undefined Behavior is a perfectly normal, regular occurrence. It's also very necessary for performance (in general). Why? Because the key enabler for optimization is inlining. Inlining brings context. For example, Inlining allows realizing that whole parts of the inlined function are unreachable for the particular set of arguments, which in turn allows realizing that whole parts of the surrounding functions are now unreachable. And within the optimizer, it's impossible to know whether such optimization was intended, or not, by the developer. Note that even `javac` optimizes on Undefined Behavior. It's just ubiquitous. --- &gt; In my opinion, a compiler should not by default optimize based on the belief that UB will not occur. What is the impact of Undefined Behavior on performance? Well, we have partial answers. GCC and Clang both come with a set of `-fsanitize=...` flags. If you choose `-fsanitize=undefined` and `-O3`, you will eliminate many (but not all) cases of Undefined Behavior, and yet the optimizer will do its best to produce the fastest code possible. Wonderful, no? Except that the resulting performance is not exactly stellar. Numerical benchmarks, notably, suffer greatly. What of the other sanitizer flags? **Much much worse.** The memory footprint balloons up, the execution slows down to a crawl. Once again, check the page: - [AddressSanitizer](https://clang.llvm.org/docs/AddressSanitizer.html): slowdown **2x**. - [MemorySanitizer](https://clang.llvm.org/docs/MemorySanitizer.html): slowdown **3x**. - [ThreadSanitizer](https://clang.llvm.org/docs/ThreadSanitizer.html): slowdown **5x-15x**, memory overhead **5x-10x**. - [UndefinedBehaviorSanitizer](https://clang.llvm.org/docs/UndefinedBehaviorSanitizer.html): slowdown minimal (except on numeric code). And the cherry on the cake: they are mutually incompatible with each others. It is not possible to active all of them at the same time; even if the performance was bearable. With this kind of performance overhead, you are better off with Java. It'll be both safer and faster.
Well, x86 had INTO, but no one used it and it was removed in x64.
Dude, do you honestly expect people to accept+learn a private/unusual config file format? There no 3rd-party tools for this format (and there will never be) and there is no Python/Java/YourFavoriteLanguage bindings...
Thanks for sharing! It would be awesome if you actually build a simple Qt project with CMake from scratch. That way we can all learn and practice!
Or with a newer version of CMake, `target_compile_features(target PRIVATE cxx_std_11)` to do it in a target-specific way.
&gt; &gt; &gt; target_include_directories(Foo PUBLIC ${PROJECT_SOURCE_DIR}/public PRIVATE ${PROJECT_SOURCE_DIR}/src ) the "${PROJECT_SOURCE_DIR}" part is unnecessarry if you put the CMakeLists.txt at the proper place : target_include_directories( Foo PUBLIC public PRIVATE src) 
If you are so concerned about build problems, why don't you simply use a packet manager to install those dependencies (and maybe the lib itself).
If we are talking modern change, you want neither of those
The all-caps are used to specify "keyword arguments," by CMake convention. The values following an `ALL_UPPERCASE` argument are the values corresponding to that keyword. Just remember this rule and it becomes much easier to understand.
That is exactly what it's proposed in the article. The set(CMAKE_CXX_FLAGS ... version is meant as an example for "old" cmake code
What resource do you suggest to someone who wants to learn Qt ?
Is there something along the lines of Herb Sutter's Exceptional C++ books, but in the realm of templating? I want to learn but it be nice to have some motivating examples/problems other than just blindly trying to make something random work.
Maybe I should - which package manager contains this library and all of it's dependencies with up to date versions?
Cool, that's two out of six, one of which is boost
Qt official documentation and examples. Really.
Not yet. A NeoVim integration is planned, but last time I tried the NeoVim API, there were some issues. I'll check again next summer and see if things have improved. Relevant issue: [https://gitlab.com/cppit/jucipp/issues/163](https://gitlab.com/cppit/jucipp/issues/163)
unless i misunderstand, this would change the return type of all lambdas that used to be void-return. 
Neither is tied to boost, only three of the six dependencies are required and all can be installed via package managers and if you do serious web stuff you probably end up with a dependency on Openssl anyway.
The build tooling situation with Libraries is the worst part of C++. The rest of the world is spoiled with gradle/maven/go,etc. vcpkg and hunter look like the best routes forward so far - now it's just a matter of getting the rest of the C++ projects in the world using cmake. 
CMake honors CFLAGS and CXXFLAGS. https://cmake.org/cmake/help/v3.12/manual/cmake-env-variables.7.html
I'll wait for the best part of CMake + Qt: installing the target and shipping Qt libraries too
I hadn't noticed him until now, but I very much appreciate the articles! They can be a very good read and it's the reason I'm here.
Well it didn't today on the project I was trying to compile; so I'll pin the blame on a poorly written CMakeLists and not on cmake then. ;-) 
This is a somewhat surprising quirk of C++. I'm not convinced it needed a 1,000 word article though.
Yes, of course, I agree that that is the "basic source character set", but why is it not subject to revision?
Same, I had to visit that username to confirm the OP's statement.
Please ask this over at /r/cpp_questions
This set represents pretty much everything that is within easy reach on a US keyboard (with the exception of \` and @). Adding additional characters would require specialized keyboard layouts, specialized editors, or both, something I suspect a lot of people will not appreciate. The @ character also plays a role in some dialects of C, and as I understand it they didn't want to introduce a gratuitous incompatibility with those languages. 
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/996f5d/why_does_cmaths_sqrt_give_sqrt400000000640000000/e4l9poz/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Ok, that generally makes sense, but mean just $ is also on US keyboard too... I can just imagine a shorthand template syntax that looks like this: void Foo($T arg1, int arg2, $T arg3); Which would intuitively mean that arg1 and arg3 are the same templated type. But such constructions would only be doable any backwards compatible way if the language branched out a bit on what characters are part of the basic set. I'm not suggesting the use of the dollar sign specifically here, just an illustrative example. It seems to me after usage of some characters outside of the c++ basic character set, has not negatively affected the success of other languages.
is that the oranges guy? :p
Good points, I do feel like those are surmountable concerns, but they are definitely worth noting.
There was a proposal trying to use $ for reflection afaik.
You mean pumpkins? I don't think so. But who knows...
As johannes mentioned, other related languages used those characters for exactly the reasons you described, because they weren't used in C or C++ and so wouldn't conflict with anything. Now the C++ committee doesn't want to change that and introduce conflicts. The only three characters that are available are `@`, `\``, and `$`. `$` is used by some C++ implementations as a special character in identifiers. `@` is used by Objective-C++. `\`` is used in some tools for internal names.
I suppose as a follow-up, it occurs to me that digraphs and trigraphs are in themselves an attempt to deal with these types of concerns. Perhaps the deprecation of trigraphs is an indication that they aren't as worrisome as previously thought?
It's not. Pumpkins guy is pretty heroic too.
Arthur O‚ÄôDwyer, his blog: https://quuxplusone.github.io/blog/
Oh. I read and answered too quickly. I equated oranges with pumpkins. Not really sure who orange guy is.
Yeah, the article boils down to: "Did you know this compiles? " if (int a = 0) a = 1; else a = 2; "Neither did I. Seems like a bad idea." Ah well, it's not like the internet has a word count limit. Can anyone think of a legitimate reason to use this scope feature? I'm drawing a blank. This seems more of an "anti-feature", in that it seems far easier to think of how it might cause a bug instead of being genuinely useful.
Yeah I can't think of a great example. But this C++17 feature is similar and useful: if (int foo = bar(); foo &gt; 5) { fooIsBig(foo); } else { fooIsSmall(foo); }
I like the posts and the gag.
But he's the pumpkin guy?
You gotta give things time to flourish into a beautiful spring meme.
Maybe something like: ``` if (auto maybe_initialized = get_obj(needle)) { maybe_initialized.foo(); } else { maybe_initialized.init(); maybe_initialized.bar(); } ``` ? Not sure how common the corresponding design would be though.
We commonly have multiple build directories with different compilers and cmake configurations. That doesn't work if the only allowed build directory is "build".
The structure of `build/` is not mandated. For example, you can use `build/Clang-6.0-Debug`, `build/GCC-7.3.0-Release`, or whatever else you may need.
for a practical, definitive and immediately available solution visit safe numerics at GitHub: https://github.com/robertramey/safe_numerics Robert Ramey
I think you have a fairly nice document. A couple of my own thoughts: &gt; 1. Compelling reasons to change the name of a directory or file. I am in the ```thirdparty/``` camp, currently for no compelling reason. I may switch to ```extern/```. &gt; If a project does not support CMake embedding, or you prefer to import the dependency in a different manner, for a dependency FooPackage, write a deps/FooPackage.cmake file that does the import, and include(FooPackage.cmake) from the deps/CMakeLists.txt. I typically have a section of ```include(UseFoo.cmake)``` for every dependency which has the details for the configuration of the dependency, including the options. Maybe my way isn't great since it hides the options in each ```UseFoo.cmake``` file, but it makes the root ```CMakeLists.txt``` look a lot less busy. &gt; Subcomponents (Hint: Don't) You say don't then outline pretty close to what I do in my own projects. I just don't see the purpose in suggesting not to have subcomponents. My structure is slightly different: src/apps/* src/libs/* apps are typically having an ```add_executables```, usually one for each front-end (cli, http, gui, etc.). My first read-through I didn't see anything motivating me to change from this structure, but maybe I missed a reason. Overall I think it is a nice doc.
Re: separate source dirs for executables and libraries An earlier version of the docs included the recommendation that `src/bin/` have on source file per executable, to keep entry point code separate from main library code, and main library code would appear in `src/lib/`. There was a _huge_ amount of backlash on this one so I scratched it and now there is just a single `src/`. The one compelling argument I can make for switching is that this is trying toward a de facto standard. I would prefer to have exe/lib sources be split, but everyone I consult with thinks the idea is absolutely unacceptable. The recommendation against subcomponents is that I have never felt a project was improved by using them, and they've only caused me and others grief. Except for very large projects, I don't find them compelling.
Thanks!!! I'll try to keep this in mind - I don't deal with CMake files directly, but indirectly enjoy their power through vcpkg :) - It's a bit like STL - I would really not love it if I have to write an maintain STL-like code (or boost), but won't mind using it hehehehe... 
You have an example about using a `libs` folder to contain library subcomponents (different formats for a serialization lib). How about multiple executables?
Executables don't present the same issues you might find with multiple libraries, so those would just go in `src/` and link to their relavant subcomponents.
I'm a fan. Do you happen to have an project somewhere I could browse for a more practical example?
That's not de-facto if the majority is not using it... &amp;#x200B;
&gt; I would add clarification about what to do with multiple main binaries too as this doesn't seem to be clear with the single src folder. [You aren't the first](https://www.reddit.com/r/cpp/comments/996q8o/prepare_thy_pitchforks_a_de_facto_standard/e4lgnhx/). I'd prefer to split the exe and lib sources, but it seems to be pretty unpopular. &gt; `build` is a bit unfortunate as it will collide with Bazel files. Ouch. That's compelling I'd say. Unfortunately, `build/` is _hugely_ popular, so it may be a "or use `&lt;other-name&gt;` if you use Bazel." I've also considered `_build` or `out`. No compelling difference, although `_build` is less likely to conflict with anything and makes it clear that it isn't a regular directory.
on larger projects it becomes important to split headers into `include/` _But not all headers._ Just those headers that are used outside that "group" of files. ie the API headers for that group. Things that are only used with other things in the same group, can all be within the same folder. ui/ include/ui/ button.h widget.h src/ button.cpp widget.cpp windows_hacks.h windows_hacks.cpp impl_stuff.h impl_stuff.cpp backend/ include/backend/ ... src/ ... The `ui/include/ui` is weird, but that means App.c can do add `ui/include` to it's include list, and do `#include "ui/button.h"` in its code. Also, if you are into namespaces, button should be in ui namespace, and namespace name should match folder name. (I assume much of this is in your doc, haven't read yet)
Don't mean to necro but is there docs about a clang source to source rewritter
the compelling argument against "deps" is just that it is too short to not have people making incorrect guesses. I've always seen third_party (or 3rd_party, etc) or extern. Also, some people separate third_party to mean "not this company" whereas "extern" just means not this project (ie can include 3rd party but also pieces you get from other teams - ie any code you don't typically edit/own yourself)
future de facto
This matches fairly close to what the doc proposes.
Regarding this point: I'm independently using that exact structure for all my projects right now, notable for debug and release-build and it works great.
It's important for libraries since those are often consumed by others, but it also applies to application projects. The recommendations still stand for generating multiple executables. There's was quite a fight both in the Slack and IRL with a co-worker over whether there should be some separation between executable sources and non-executable sources within a single project.
which is now a phrase I will somehow use in a proposal some day, see it anyone notices
Some unordered notes: - Why not `vendor` instead of `extern` or `deps`? - Why not `data` instead of `rest`? I feel `data` is more neutral than `res`. - I do not really see the use case for `contrib`, it seems to be the same as subcomponents in `libs` after all - I would be for separating libs and executables (personnaly, I use a `lib` directory for libs and `src` for executables, but I could change my mind) 
I will try to use that next time I want the company I work for to change technology to something in early stage.
One less level of indentation? It's not amazingly useful but there's some times it's a natural way to write something.
There're debates over the naming of dirs. Some compelling, some not. I may throw up a poll since the naming isn't significant, but there is notable division. I'm getting the same sense for `contrib/`, but I'm not convinced against it. It's not mandatory, so most people might just not have one. The desire for lib/exe separation is common. It warrants further discussion.
Yeah was going to mention STL too. Always there to clear up a std library confusion.
`operator&amp;` is overloadable.
Re: tooling: I'm going to be encoding a lot of this in a tool, so stay tuned! It's not just about the having the least resistance for any particular migration: The cumulative resistance of adopters should be minimal. For me, that means taking the "average" of many projects and encoding them such that most people only need to rename or move a few files, rather than a single project being "blessed" and having everyone rename and moving slightly more files than if taking the "average." This doc isn't completely fabricated from scratch, but by enumerating what seems to be most common amongst the community.
So where do I find its implementation. I checked the object's class and found: `inline ostream&amp; operator &lt;&lt; ( ostream &amp;os, const Hit&amp; h) { os &lt;&lt; "Hit &lt;" &lt;&lt; h.getT() &lt;&lt; ", " &lt;&lt; h.getNormal() &lt;&lt; "&gt;"; return os; }`
if `operator&amp;` isn't in the class definition then it isn't overloaded and `if(&amp;object)` is pointless since the test will always be true.
Why is it always true?
Because the address of something can never be 0
But does it then check that the address exists? Also how can `if` take an address?
`if(&amp;object)` is the same as writing `if(&amp;object != nullptr)` It doesn't say anything about the validity of the address, just whether it is null or not.
So it's checking that the object exists?
No, it's not doing anything. The test will *always* be true.
If you can get the address of the object then it exist for sure.
`object` exists. It cannot not exist.
But it can be NULL or some other object?
Excellent summary!
I did something similar and simpler since it's really basic and needed in a lot of my work's application code. However I'm not familiar with template meta programming so unlike your implementation I use macro and static std::vector&lt;enum_type&gt; to represent range. And it does not work if you need to assign enumerator's value. Still try to check your wise_enum and above better-enums to see if I can improve my version though. Usage is like this DECLARE_SMART_ENUM(Color, GREEN, RED); //inside macro declared enum class Color { GREEN, RED }; //so use std::underlying _type&lt;Color&gt; is possible. //also declare auxiliary class SmartEnum&lt;Color&gt; //and function ToString(Color c) and ToColor(std::string s) auto color = Color::RED; std::cout &lt;&lt; "Color is " &lt;&lt; ToString(color) &lt;&lt; std::endl; assert(color==ToColor("RED")); assert(SmartEnum&lt;Color&gt;::Size()==2); //iterate range using range-based for //SmartEnum&lt;Color&gt;::ToRange() return a std::vector&lt;Color&gt; //which is { Color::GREEN, Color::RED } for (auto color : SmartEnum&lt;Color&gt;::ToRange()) { std::cout &lt;&lt; "Color [" &lt;&lt; ToString(color) &lt;&lt; "]" &lt;&lt; std::endl; } Some problem bothers me is that if you declare inside a namespace and use it in other namespace (very common in library and its user), the usage become this: //library.h namespace lib { DECLARE_SMART_ENUM(Color, GREEN, RED); } //client #include "library.h" auto color = lib::Color::RED; //ToString is ok with ADL? cannot check code, at home now std::cout &lt;&lt; "Color is " &lt;&lt; ToString(color) &lt;&lt; std::endl; assert(color==lib::ToColor("RED")); assert(lib::SmartEnum&lt;lib::Color&gt;::Size()==2); for (auto color : lib::SmartEnum&lt;lib::Color&gt;::ToRange()) { std::cout &lt;&lt; "Color [" &lt;&lt; lib::ToString(color) &lt;&lt; "]" &lt;&lt; std::endl; } I just compromise that in this case the code will look like above. I think *lib::ToColor* is OK since client is using *Color* in *lib* namespace. But *lib::SmartEnum&lt;lib::Color&gt;* is ugly. I wish I can find a way to make it only need to say *SmartEnum&lt;lib::Color&gt;*.
If you just want to hack something together and don‚Äôt want dependencies: https://github.com/yhirose/cpp-httplib
Other than following an ancient Unix-y convention, I still don't see the purpose of abbreviating `source` to `src`. It's a bit slavish to convention, similar to the silliness of applications which insist on including a File menu even if they don't manipulate files at all. It also rubs against the grain of those of us who prefer consistent CamelCase, not just in code, but with files and directories as well. I know upper-case is anathema in Unix-land, where Filename != filename, but it's near-universal in Windows-land. That being said, honestly, I'd rather see a standard library layout develop, even if it favors a particular style I don't prefer and which encourages good tooling, rather than having a free-for-all mess. The only realistic chance of this catching on is if it seems close to an already defacto standard, which it seems like it is. I might even be willing to rename my `/Source` folder to `/src`. Srsly.
FWIW, trigraphs have been removed, not just deprecated. 
With my library, you can use the macro inside the user namespace. That addresses the verbosity issues, I think. Why not just use my library? It's less for your work to maintain, it's boost license, and I'm happy to address any issues.
Thanks for all your hard work keeping this sub interesting.
What's the alternative? A top level \`include\` folder? If that means the file describing your library in libs/ui will have to reach out of its folder, that's a big no-no for isolation.
I sense a lack of pedantry, so let me quickly interject that 0 can be a valid memory address. Interestingly, \`&amp;object\` would still be required to convert to \`true\` in an if-clause even if \`object\` has address zero, since 0 wouldn't be a null pointer on such a system.
In Linux projects, there is often a `share` directory, where config files and stuff like that reside, or other files that a library or exe requires to run. Since this is so common in Linux systems, would it not make sense to have that directory in the project layout as well?
NULL is not an object. It is a specific *pointer* value that acts as a sentinel for "no object."
It doesn't even need to be installed, can just download the tar.gz from cmake.org and unzip, no root or anything required.
&gt; Why not just use my library? It's less for your work to maintain, it's boost license, and I'm happy to address any issues. Why is wise_enum has three headers to use (as a library) and ise_enum_generated.h file size is 1.44MB? Is it "lightweighted"? I may be mistaken since I did not really tried your library. But before download that would be my concern if I want to use it. My implementation is just a simple 50 lines header. Also most usage in my work's code base did not need full fledged compiler time info with constexpr taken care, just need a simple reflective iterative enum. my first impression about better_enum 1. like you said, not a genuine enum class 2. 1000 lines template header, I'm not sure if it hurt compile time (I know it has performance listed) 3. a simple header library, I think it's good for ordinary user to use it as a library
Hi nlohmann! Your library is a huge time saver and makes my code so my easier to read. One use-case I run into a lot is mapping enums to serialize as non-integers such as strings. I know its not truly modern C++, but I wrote some ADL template specializations and a helper preprocessor macro to make it much easier and less redundant to specify this mapping between an enum and a set of JSON values like so: enum Foo { eVal1 = 10, eVal2 = 45, eVal3 = 1 eVal_default = -1, }; JSON_ADL_SERIALIZE_ENUM( Foo, { {eVal_default, nullptr}, {eVal1, "one"}, {eVal2, "two"}, {eVal3, "three"}, }); nlohmann::json j = eVal1; assert(j == "one"); nlohmann::json j3 = "three"; assert( j3.get&lt;Foo&gt;() == eVal3); nlohmann::json jPi = 3.14; assert( jPi.get&lt;Foo&gt;() == eVal_default ); Would something like this be a useful contribution to your library?
If you have the object, it exists. Pointers are nullable, you can‚Äôt have a null object unless you have a user defined state of being null, like optional.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/9981sj/what_does_checking_for_ifobject_do/e4lsio6/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I nearly wrote `nullptr` but decided 0 would be clearer for OP :-)
This is the purpose of the`res/` directory, although there is some debate to name it `share/`, `data/`, or something else entirely.
Okay - `res/` I would've associated with "resources" files, and the likes of `.rc` files. But I guess that's what config files exactly are. The one thing I don't like about the name `res/` is that it's easily confused with "results", which is also often abbreviated as "res". Furthermore: Why abbreviate an already not-too-long word like "resources" - better be explicit and avoid confusion (and allow some domains to have a `results/` directory too - if you abbreviate, you'd end up with `res/` and `results/` - not pretty.) Depending on the domain of the library/application, "data" is also a little bit something else (for example, importantly, data (or at least some type of data) would be kept separate from configs). I think `resources/` or `share/` would be best, while `data/` would probably also be ok but may have a slightly different purpose.
The generated file is to support all the different numbers of enumerators. Macros don't support looping of any kind out of the box, so if you want to do something beyond forward the VA\_ARGS into another structure, you need to either do that, or use recursion. Recursion is what Better Enum uses; the file may be smaller but I'm not sure if it will compile faster or not. If you are concerned about the size and only use smaller enums, you can easily run the included python script to generate a replacement that e.g. only goes up to 20, 40, 60, etc, however many enums you want and it will be much smaller. The three headers are just to provide a bit of separation, I don't see why it matters. It's still a header only library; the only thing you need to do is clone the repo and include the main wise\_enum.h file. So I think it is just as much a "simple header library". Compared to your 50 line implementation, beyond being able to give values to individual enumerators, it will produce better assembly, and avoid dynamic initialization. Your vector&lt;enum&gt; are dynamically initialized global variables, those are a real headache. Take the shortcut now, and you could be dealing with obscure segfaults in 6 months. &amp;#x200B;
You can`set_target_properties(foo PROPERTIES CXX_STANDARD 14)`to get C++14 support. I think CMake will error out if the compiler doesn't support it. 
For standard (and thus often used) names I prefer terseness over explicitness. 
IIRC 14.04 has a cmake3 package. Also, if it is an x86 platform you can just download the binary and at it to your path (building it wasn'tcomplicated either last time I tried). It is really simple. 
I don‚Äôt visit this sub often but it always makes me happy to see people putting in effort to keep places on the Internet active!
For example: add_library(mylib) target_sources(mylib PUBLIC "${CMAKE_CURRENT_LIST_DIR}/fancypublicheader.h" PRIVATE "${CMAKE_CURRENT_LIST_DIR}/really_ugly_impl.cpp" ) target_include_directories(mylib PUBLIC $&lt;BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}/..&gt; $&lt;INSTALL_INTERFACE:include/mylib&gt; PRIVATE ${CMAKE_CURRENT_SOURCE_DIR}) This will allow ```really_ugly_impl.cpp``` to specify ```#include fancypublicheader.h``` while both internal targets linking to it will need to specify ```#include "mylib/fancypublicheader.h"```, and external targets will find the header at the installed location ```.../include/mylib/fancypublciheader.h``` and if they set their include path to the root include, will specify ```#include "mylib/fancypublicheader.h"```.
How about inviting him to cppcast ?
Google for it. There are small examples out there too. 
`include` can only be optional in projects without an API consumer by the user (of a library, etc.). Big enough projects may have an internal APi that supplements the external one ‚Äî then there‚Äôs a valid question of how to separate them. `include/private/` is one way I can think of, `src/include/` ‚Äî another. 
In this doc, the external includes are kept in `include/`. If `include/` is not present, then the headers in `src/` are considered external includes. If `include/` is present, any headers in `src/` are the private headers. Both `include/` and `src/` are added to the internal include path of the library.
The doc _discourages_ subcomponents, but it don't ban them. And by "discourage" I mean "think twice about using them." Of course, huge projects like Qt and Boost need to subdivide themselves. The proposal has provisions for that (See the `libs/` dir).
Even then, I consider in-source builds to be sheer insanity and a holdover from times when the tools were so inadequate that out-of-source builds were painful to implement and maintain. These days, there‚Äôs no reason whatsoever to have builds done within the working copy itself. 
I've actually used `source/` in the past, but I have no strong feeling either way. I'm going to throw together a survey to answer some of these naming problems, as a lot of people have voiced opinions on them.
I guess the naming is confusing. By "de facto standard," I'm not referring to "community convention," but "a standardese-style document that hasn't been put through the grinder of a standardization committee." There is no requirement to use the term "de facto" other than not being a fiat truth. I could scribble a nonsense project layout in the sand on a beach and still call it a "de facto standard," but I would also be a crazy person.
I personally really dislike having an assignment and condition on the same line. I just do like: if(int foo = bar(); foo &gt; 5) { fooIsBig(foo); } else { fooIsSmall(foo); } 
Why are you building in your source folder?
Yeah, I'm half-kidding about the folder names - hopefully the last line indicated that. Actually, I think it's less important making everything the same name, because a tool should be able to handle `source` or `src` or (heaven forbid) even `Source`. I mean, internally, that's really just a variable name, right? Just suggest "recommend" names, and make the user do a bit of configuration if they really want something different, I guess. I think what's more valuable among your proposal is the standardized *layout*. The fact that there IS a root-level folder with the source in it, one for public header (optionally), a separate folder for resources, for utilities, for tests, for resources, for docs, etc. Anyhow, keep us posted on your progress. I'd be interested to know what comes of your efforts. 
I went in expecting to hate this, and I came away absolutely agreeing. This is a really great standard layout, in my opinion.
Under the section *Subdirectory: cmake/* it says to add the following line: list(APPEND CMAKE_MODULE_PATH "${CMAKE_CURRENT_SOURCE_DIR}/") Is this a typo and actually meant to read: list(APPEND CMAKE_MODULE_PATH "${CMAKE_CURRENT_SOURCE_DIR}/cmake") Or does the include command look into subdirectories called cmake when searching for modules?
Robert Mueller is looking into it.
What about the code size? There are lots of posts that say "templates tend to increase code size" (myth?). What about the performance impact. I think this [post](http://www.drdobbs.com/cpp/why-code-in-c-anymore/240149452) has some valid point towards C++.
In a comment somewhere, I had previously suggested \`"@"op\` for special interpretation as the creation of a new operator. &amp;#x200B; I've thought of a name now: User Defined Operator Notation for New Operators and Overloaded Definitions Leading to Extensible Syntax. UDON for short. 
No cons for me. I never have had any issue with it. Pro: It keeps all in one place.
The new syntax requires you to write this: ``` if (auto result = get_expected(); result) use_value(result.value()); else log(result.error()); ```
It just isn't an issue anymore with the .*ignore files. I find it easier for both navigating and keeping context of deployments relevant to a project. X projects each with Y builds, I prefer a folder structure: ‚îú‚îÄ‚îÄ‚îÄproject1 ‚îÇ ‚îú‚îÄ‚îÄ‚îÄbuild-triplet1-dbg ‚îÇ ‚îú‚îÄ‚îÄ‚îÄbuild-triplet1-rel ‚îÇ ‚îú‚îÄ‚îÄ‚îÄbuild-triplet2-dbg ‚îÇ ‚îî‚îÄ‚îÄ‚îÄbuild-triplet2-rel ‚îú‚îÄ‚îÄ‚îÄproject2 ‚îÇ ‚îú‚îÄ‚îÄ‚îÄbuild-triplet1-dbg ‚îÇ ‚îú‚îÄ‚îÄ‚îÄbuild-triplet1-rel ‚îÇ ‚îú‚îÄ‚îÄ‚îÄbuild-triplet2-dbg ‚îÇ ‚îî‚îÄ‚îÄ‚îÄbuild-triplet2-rel ‚îî‚îÄ‚îÄ‚îÄproject3 ‚îú‚îÄ‚îÄ‚îÄbuild-triplet1-dbg ‚îú‚îÄ‚îÄ‚îÄbuild-triplet1-rel ‚îú‚îÄ‚îÄ‚îÄbuild-triplet2-dbg ‚îî‚îÄ‚îÄ‚îÄbuild-triplet2-rel versus ‚îú‚îÄ‚îÄ‚îÄproject1 ‚îú‚îÄ‚îÄ‚îÄproject1-build-triplet1-dbg ‚îú‚îÄ‚îÄ‚îÄproject1-build-triplet1-rel ‚îú‚îÄ‚îÄ‚îÄproject1-build-triplet2-dbg ‚îú‚îÄ‚îÄ‚îÄproject1-build-triplet2-rel ‚îú‚îÄ‚îÄ‚îÄproject2 ‚îú‚îÄ‚îÄ‚îÄproject2-build-triplet1-dbg ‚îú‚îÄ‚îÄ‚îÄproject2-build-triplet1-rel ‚îú‚îÄ‚îÄ‚îÄproject2-build-triplet2-dbg ‚îú‚îÄ‚îÄ‚îÄproject2-build-triplet2-rel ‚îú‚îÄ‚îÄ‚îÄproject3 ‚îú‚îÄ‚îÄ‚îÄproject3-build-triplet1-dbg ‚îú‚îÄ‚îÄ‚îÄproject3-build-triplet1-rel ‚îú‚îÄ‚îÄ‚îÄproject3-build-triplet2-dbg ‚îî‚îÄ‚îÄ‚îÄproject3-build-triplet2-rel
The new syntax _allows_ you to write that; it isn't mandatory.
Seriously, the Pumpkins in that picture look orange-sized
But it's the by far most common layout I see. Except in the corporate world of course where it's all wild west.
The biggest difference I spot compared to a conventional layout is to have a subdirectory in src/, that's highly unusual and I'm not sure what purpose that serves. The only reason you have a subdirectory in /include is to provide a namespace for 'include' directives. This is the conventional layout libfoo/ src/ class.h class.cpp include/ libfoo/ public_header.h 
Conan and bincrafter have all of them.
I've seen a legitimate use of this by Andrei Alexandrescu in [this talk](https://vimeo.com/171704579#t=2505s) at 41:45 I have since used it in my projects a couple of times. In my case it was for an allocator, that frees all allocated memory at the end of its lifetime. With a macro that looks like this #define TEMPORARY_MEMORY_BLOCK(allocator) \ if(auto _once = false) { \ } else \ for(auto allocator = MyScopedAllocator(); !_once; _once = true) you can then use it like this: TEMPORARY_MEMORY_BLOCK(allocator) { char* memoryA = allocateStorage&lt;char&gt;(allocator, 100); char* memoryB = allocateStorage&lt;char&gt;(allocator, 100); char* memoryC = allocateStorage&lt;char&gt;(allocator, 100); // ... // everything gets freed at the end of the block automatically } // the same thing, but doesn't look as good imo since you have to insert a manual empty block to scope a variable { auto allocator = MyScopedAllocator(); char* memoryA = allocateStorage&lt;char&gt;(allocator, 100); char* memoryB = allocateStorage&lt;char&gt;(allocator, 100); char* memoryC = allocateStorage&lt;char&gt;(allocator, 100); }
To me this is the single biggest issue plaguing c++ today because it prevents standardization around tooling to easily handle dependency and build management. Other lesser languages have much better tooling around this such as PHP with composer.json files, Node with package.json, so on, etc. C++ struggles on this because there is simply no defacto standard, and the ones that do exist are too commercial that there is no ecosystem around them. My pet hate is that I can't just make some kind of c++.json file or something and then run some command to download all the dependencies and have it building/linking my project without issues on any supported OS the same way I can in other languages. I really appreciate the work you're doing here and hope it leads us all to a much better place.
I find it practical to have a subdir for every used namespace. For `namespace foo` I put the files into subdir `foo`.
This sounds interesting. Could you please open an issue at [https://github.com/nlohmann/json/issues](https://github.com/nlohmann/json/issues) ?
name space pollution, the same name can be reused without additional efforts. besides it makes declaration more local if(int i=get1()) { dosmth1(i); } if(int i=get2()) { dosimth2(i); } I like to use 'it' for temporary iterators, 'i' for counters. 
The std namespace is quite big and "using namespace std" includes the whole namespace unnecessarily. For test programs, it shouldn't matter. But for real production code it's always better to just pull in stuff you actually need. Hence the explicit std:: infront of each usage of the std library. It's also easy to figure out where the method belongs.
Project layout guidelines should not be tied to how a particular build system (cmake) works. I use VS for builds which means in-source builds by default. Making it do otherwise is possible but a waste of effort for no gain.
This should not be part of the language. It can be part of cmake though.
Err, that's a missuse of "de-facto standard". It literally means "everyone is doing/using it but no authority officially said it was the way". All other use are misleading and honestly I don't see any project using half of what you describe in the doc. I would be you I would replace "de facto standard" by "proposition as standard" or something like that and would send it to SG15.
It's far from being the common layout except the include directory, from what I have and can still observe, both in closed and open source. Also you'll have to provide some actual technical rational (for example, rely on constraints from a defacto standard package manager, which is not the current situation but people like Build2 devs and Conan devs work on that) before something like that to be approved. OR you have to make it de facto, which do not happen because you decided to use the word.
Those are pumpkins!?
Hear hear! Seconded.
What about projects that are, say, 80% C++ that compiles to a python module and the other 20% is python? I don't see anything mentioned that explains how these are supposed to work.
You start noticing specific users once you use RES. It displays a colored box of your total upvotes and allows to set custom label. There are some users I always see with strong greenish box.
you should not build in the source tree in the first place. the build dir is not part of the source. 
I briefly googled Windows Docker stuff but Windows' virtualized build tools/environments just feels lightyears behind Linux and I don't really want to be a trailblazer if I can help it :)!
Agreed. Why I would argue that any new project should use its own namespace. The top level namespace is crowded and name collisions likely.
From my experience with CMake it is usually nice to have multiple build/ directories. For example build64/ and build32/ or build_static/ and build_shared/ One thing I don‚Äôt see covered is where commonly-used project files go. Where would you place your Visual Studio sln and Qt pro files?
&gt; DO NOT place headers at the root of `include/` or `src/`, except for posisbly a single "include everything" header for the case of simple libraries. This. This is the thing. Whenever I work with multiple libraries, I have something like this: #include &lt;LIBA/core.hpp&gt; #include &lt;LIBB/stuff.hpp&gt; #include &lt;LIBC/something.hpp&gt; and I just hate when some lib recommends me this: #include &lt;SDL2.h&gt; // not SDL2/SDL2.h I messes up paths in the build tree and messes stuff in include dir - at worst case I have to put all SDL files in one directory together with other libs directories. Instead of having directory of libraries I have directory of some libraries and copy-pasted mixed multiple other libraries.
That would be good to see, with the proposal it's the only thing that I feel might not scale well. The proposal seems to target small projects (of which many follow a similar structure already), however large projects is where I feel the mess starts, and where using some tools become much harder.
&gt; Making it do otherwise is possible but a waste of effort for no gain. It's very simple to do. You can even do it in bulk using `Directory.Build.props` without changing every project file (you may have to remove an already set output path).
What about .build? We use 'build' currently to bundle our build related helpers (e.g. build/cmake, build/make, build/ci, etc)
Well I meant that if you only have a top-level namespace foo, dont have a foo dir in src
Every single open/free software I've seen either uses this scheme for a random mess. Here is the GNU guidelines https://gcc.gnu.org/onlinedocs/libstdc++/manual/source_organization.html which roughly follows the proposed scheme.
This is about the directory layout, not about coding style.
Why not?
That's a little bit too compilicated for my taste. What's wrong with allowing `build*/` as the name for build directories?
Apart from mentioned compatibility reasons, we still have space for new operators - for example: `%%`, `^^`, `?&lt;some symbol&gt;`. Maybe even second spaceship operator: `|-|`.
I'm a bit surprised that people who hold their blongs don't post there by themselves.
It should be fairly unambiguous though, which `res/` is not in my opinion. (it may depend on the particular domain you're coming from, but as C++ is used across pretty much any domain...)
In general, you probably want to use a profiler. Did you try the one integrated into Visual Studio 2017? For Linux there might be good alternatives too but I haven't seen one so easy to use and neatly integrated as theone in VS. Only if that is not enough, I'd go about integrating a special library for that task.
It's so terse it only takes 14 lines to declare a type!
But what a powerful type it is!
NeoVim's support for external buffers is quite new. I suspect there is no addons yet that makes use of this. That is why I probably will wait a year or so before looking into this again.
You can use 'build/debug' etc.
Hm, any advantages to use this concreate code `target_compile_options(Foo PRIVATE -Wall)` ? I mean if you build several application, plus several librarires, you want warning flags exactly the same for all projects. Then why set warnings flags for each project separately?
Also why this strange way to deals with standard? Why not: set(CMAKE_CXX_STANDARD 11) set(CMAKE_CXX_STANDARD_REQUIRED True) set(CMAKE_CXX_EXTENSIONS False) ? Again if you has huge Qt project (which consists from several applications and libraries), why deals with c++ standard for each target, and not setup globally?
My point is: If it is standard and commonly used, every one knows what it means (you also know what memcpy/strcmp aso mean). Not saying res is the optimal choice here, but if I had to choose between res and result for a common folder name I'd choose res.
*whoosh*
&gt; and be prepared for even more pedantic corrections... Yes, please :D But regarding &gt; what happens is not that the address gets converted to an integer, and the result compared to 0. i'm pretty sure I never claimed that this would happen? It's a bit of a red herring anyways, because the expression under discussion wasn't `if (&amp;object == 0)` but just `if (&amp;object)`, and that does not have any `0` that could get converted to a pointer. Instead, the value of the expression `&amp;object` already *is* a pointer, and that pointer undergoes a contextual conversion to bool.
This is the layout that I use now. I wish I learned it 15 years ago. It seems so obvious now... Works perfectly with modern cmake!
Would #define TEMPORARY_MEMORY_BLOCK(allocator) \ for(auto _once = true; _once;) \ for(auto allocator = MyScopedAllocator(); _once; _once = false) work then?
\*\*Company:\*\* \*\*[Summitto](https://summitto.com)\*\* \*\*Type:\*\* Full time \*\*Description:\*\* Summitto is an award-winning startup building the largest invoice registration network of the world. The purpose? Helping EU tax authorities to \*\*eliminate 50 billion EUR in annual invoicing fraud\*\*. If you‚Äôre excited to build and design \*\*open-source\*\* software which will be used by \*\*millions of companies\*\*, we are looking for you! We're hiring junior √°nd senior developers at the moment. Experience with cryptography is a plus, but not required! \*\*Location:\*\* Amsterdam \*\*Remote:\*\* No \*\*Visa Sponsorship:\*\* yes \*\*Technologies:\*\* C++11, C++14, golang, python. \*\*Contact:\*\* [careers@summitto.com](mailto:careers@summitto.com) questions are always welcome!
Being simple to do does not mean it should be done. Changing defaults always incurs a cost in some way or another. I have a solution that is a mix of C++, C++/CLI and C# projects where C++/CLI references C# assemblies. Plus projects shared across solutions, some of them in different repositories. Maybe your suggestion works flawlessly, maybe it breaks things blatantly or subtly. However, changing this requires an exertion of effort (both changing the defaults and testing that nothing broke in the build) for no gain, so the whole endeavor is a net loss.
As some who uses multi\_index quite a lot, this is well-received.
You could put it all on one line if you want to. And you were a sadist.
This looks really good! I gather the idea is that stuff in 3rd_party would follow the same pattern? That would be important to me. I really appreciate the time and effort that you put into this. It could really make life a lot easier. It's funny because in many ways, this could go a very long way to making C++ much easier to use as a whole. Especially with interoperability with other libraries.
&gt; Why not? The big no-no is generating files into the source tree itself. It makes for messy source management. You end up with a whole bunch of ignore rules (if you're lucky) in your VCS, and inevitably someone ends up committing the build artifacts into version control. It also makes it harder to clean up a build that's not "perfect". If you can delete a single directory and get a fresh build environment, great. If it requires running an invocation of `git clean` in some form or another, you're eventually going to lose work-in-progress. That said, it's usually fine to have a `build` directory in your source directory as long as it (and all subdirectories) are ignored. Just don't generate files into the source directories themselves. 
&gt; I have a solution that is a mix of C++, C++/CLI and C# projects where C++/CLI references C# assemblies. I'm using this in a project that has all of these. It even requires some x64 artifacts for the x86 build. It's so much cleaner than littering bin and obj directories everywhere, especially since the differ between x86 and x64. The defaults are far from sane. &gt; a proposal that wants to be "standard" should not tie itself to one particular build philosophy. Of course it shouldn't, but for MSBuild-based projects this works fine.
There's two distinct flavors of in-source build: 1) Those that actually put build artifacts/generated source in-directory with the source files themselves. 2) Those that happen to be in a directory that is a subdirectory of the source tree. The first is insanity. The second is effectively an out-of-source build, because it's trivial to ignore with your VCS and (should) be trivial to do outside the source tree itself, anyway.
TeamViewer is hiring C++ Devs! We have 2 open positions: \- Software Engineer C++ : [https://jobs.teamviewer.com/en/job/software-engineer-c-m-f/](https://jobs.teamviewer.com/en/job/software-engineer-c-m-f/) \- Senior C++ Engineer with focus on Security: [https://jobs.teamviewer.com/en/job/senior-software-engineer-m-f-goeppingen/](https://jobs.teamviewer.com/en/job/senior-software-engineer-m-f-goeppingen/) Apply now or contact us [here](mailto:jobs@teamviewer.com), if you have questions! &amp;#x200B; Have a good day. Stav
This looks fantastic to me. You've managed to remove all of the noise!
Do you write for loops in the same style too?
Perhaps, if you're sure that all the applications and libraries within the project (and in the future) will need a C++11 compiler it's fine to do it the way you've suggested. However, imagine that some of the standalone applications don't require a C++11 compatible compiler, and you one day decide to build them on a platform/target which doesn't have a recent compiler. In this case you'll have to deal with the `set(CMAKE_CXX_)`-lines which otherwise wouldn't be needed. It's a bit like global variables or singletons in code: eventually they might lead to problems.
I think I'm missing some context here. What do we gain from all this?
Your structure seem nice, but would require a small structure change for my project. In my game engine, I separate my sources into modules. Each modules can ship public headers, sources, assets (resources like shaders and textures or json databases). So the directory separation is mainly done at the module level, but look a lot like what you proposed. Also one thing I do different: entry points each have their directory. It contains the main then maybe a class to bootstrap the game. I also have a tool executable that is in its own directory. So my structure look like this: myengine/ - CMakeLists.txt - extern/ (generated by package manager script) - res/ (not committed, generated from asset folders) - src/ - myengine/ - moduleA/ - assets/ - include/ - sourceA.cpp + modulesB/ - app/ - console/ - main.cpp - game/ - main.cpp 
&gt; It's a bit like global variables or singletons in code: eventually they might lead to problems. Not sure, that analogy is plausible. The problem of global variable/singletone is in code lines that use it. If many lines of your code are implicitly depend on global state this is hard to manage. But this `set(CMAKE_CXX_)` do not actually use anywhere except generated ninja/make files, but I can just regenerate them and that's all. I have no things like `if CMAKE_CXX_STANDARD == tra-la-la` (pseudo code) anywhere in my code, and why I should have them? &gt; imagine that some of the standalone applications don't require a C++11 compatible compiler Why I should have such use case? If it is live project, then any reason to not use `c++11` if compiler support them? If it is support only project, then I just remove it from `workspace` and will use standalone cmake project to manage it.
FWIW, I don't use cmake, modern or not. (Nothing against it, besides the typical complaints, just don't need it on current job.)
Our software modules (each module is a single instance of a library, executable, Python packages, Jar-file et.c.) are structured similarly, but we support multiple languages in the same software tree so we've tried to keep a base structure which is language-agnostic, thus we stuck the include directory inside src/: &lt;module&gt; ‚îú‚îÄ‚îÄ src ‚îÇ ‚îú‚îÄ‚îÄ include # only for languages with a preprocessor like C/C++ ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ &lt;module&gt; # same structure as when installed ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ &lt;public headers&gt; # only public headers are kept in include ‚îÇ ‚îî‚îÄ‚îÄ &lt;sources and private headers&gt; # sources may be organized in levels as well (Java, Python) ‚îú‚îÄ‚îÄ test ‚îÇ ‚îî‚îÄ‚îÄ &lt;unit test sources&gt; # Unit tests ‚îî‚îÄ‚îÄ &lt;build script&gt; # Build script 
You can use C++ on a lot of boards (supported by GCC) if you avoid exceptions, RTTI, std library containers other than std::array, threads, etc. Basically do not link to libc++. Almost all of the std algorithms work fine, and there are various fixed size or stack allocated vector/map/list implementations that you can drop in. Note that in the end you may have to add some linker flags to stub out or ignore certain symbols that you only encounter during catastrophic failure, i.e: `--wrap=malloc` in your link flags, etc.
If we were to allow `@`, anyone that wanted to complain about not having that symbol on their keyboard wouldn't be able to email us about it anyhow.
Absolutely agree. 
I've always used and seen it written `3rdparty`. 
I don't understand the point of splitting public and private headers in the repository. The public API is the files that are `install(FILES`-ed by CMake. They may even be generated (`GenerateExportHeader`, project-wide defines, etc...).
Fair enough, I guess in your circumstances it won't be a problem. I've worked with projects that can't use C++11 compilers because the platform was old enough to not support it (some embedded systems). However, only a couple of the applications in the project were needed for that platform. This use case was what I was referring, although I realise that's not that common.
This is apparently caused by a bug in -ftree-slp-vectorize (i.e. "-O2 -ftree-slp-vectorize" is enough to generate the strange code).
The gain is purely in terms of brevity and reduced redundancy when defining multi-index containers. 
I wonder if it would be possible to get GCC to perform multiple optimization passes, and choose the best result.
Unless their email client supports trigraphs.
Funny how people always like to complain. The example is intentionally verbose to make you see the difference. You can compact the definition to just the essential lines: using phonebook = multi_index_container&lt; phonebook_entry, indexed_by&lt;ordered_unique&lt;key&lt;&amp;phonebook_entry::phone_number&gt;&gt;, ordered_unique&lt;key&lt;num_calls&gt;&gt;, ordered_non_unique&lt;key&lt;&amp;phonebook_entry::family_name, &amp;phonebook_entry::given_name&gt;&gt;&gt;&gt;;
This one? https://github.com/yse/easy_profiler
So uh, for those that can't read this, what is happening exactly?
Components are an overloaded term, and often used for the individual pieces provided, e.g. smdutil::Thing is a component. John Lakos has been thinking about this stuff for a few decades, the results of which are at [https://github.com/bloomberg/bde/wiki/Physical-Code-Organization](https://github.com/bloomberg/bde/wiki/Physical-Code-Organization) In that nomenclature, what you're calling components or subcomponents correspond to package groups or package. Package groups are generally the unit of release, a discreet library. Although not outlined there, there is a notion of a stand-alone package, which does not have sub-pieces. For a package the name corresponds to the `namespace` used. The group itself is a logical namespace, and the packages within share the prefix of the group. This is the sort of thing you have to worry about with a few thousand people working with loose coordination where you do want to be able to compose their work. The equivalent of the src directory is the groups dir. Internally we spell it that way, `src`, fairly often. `.cpp`, the matching `.h` and the `.t.cpp` test driver travel together in one directory. There's no provision for actual private use headers, ones only ever included from an implementation cpp file, other than convention. The reason to consider sub parts early is that it's very difficult to do later. Trying to tease out a clean DAG can be hard. There's also the issue of deployment layout vs development layout. In deployment, for example, we deploy all headers 'flat' into a single directory, and inclusion is by the unique name with no path. `#include &lt;smdutil_thing.h&gt;` At internet scale, when we get good package management, we'll probably need paths to be part of that. The question is do we relax the uniqueness requirement on the basename and path prefix it, or rely on multiple `-I` flags and hope collisions are manageable. Whatever scheme is adopted, it should be used consistently. Using a component should be the same syntactically whether you are using it from a development layout or a deployment layout. 
GCC is generating more CPU operations on a higher optimization setting.
Perhaps? It's strange that he has only 3 comments. Hasn't replied to this thread either.
Ah, so these just are wasteful operations without any wizardry involved. 
Rule of thumb when reading assembly is that less assembly is better than more assembly. It's obviously a rule laden with exceptions, but it'll do for now. O2 means optimization level two. O3 is optimization level three, i.e. even more. The expected outcome of O3 is therefore that it should optimize *at least* as well as O2, and hopefully more. Instead we're seeing that it outputs *more* assembly, which according to the rule of thumb above is worse than less assembly.
Can't create an account currently. But it's good to be aware of this as it's quite basic code widely used for multiple returns. 
None really. I copied the phonebook code from Boost.Multiindex documentation, which is pre-C++11. 
Actually, you typically tend to see more instructions on O2 than on O3, because optimizations that have a size/ performance tradeoff (e.g. loop unroling) are usually only enabled on O3. Of course here the additional code is just harmful in any way. 
If you use the project as a subproject, then you are using the non-installed version and can access private headers if they are in the same directory as public ones.
Tanks, that is a much appreciated simplification. I'd use multi-index much more, if it wouldn't have so many boost internal dependencies.
Sure, but here it's using more assembly to vectorize operations, which could be a net gain (in the contrived example it doesn't seem so, but if this were in a loop it might be better)
The subdirectories of `third_party/` will be taken from their upstream sources, so their structure is not prescribed, nor is it recommended to change the upstream sources without a compelling reason. If an upstream project in `third_party/` follows this pattern, that's the upstream project's prerogative, but it would be hugely beneficial. Part of this doc is to allow easy embedding in someone else's `third_party/` or other package management solution.
Same here. Went to the basement to grab my pitchfork, ready to throw it. Started reading: *nod*, *nod*, *nod*. *Sell pitchfork. Good as new.*
The doc allows submodules via the `libs/` dir, which has mirrors of the root layout. There is an open discussion on how to place executable source files within the structure that makes sense. I'll be posting a follow-up on this topic.
Well afaik mentioning a user in as post doesn't ping them. It's only if mentioned in a comment. So possible they didn't see this?
I don't do header splitting either, but it's common enough that I added an optional prescription for it.
 build/ 32/ 64/ shared/ static/
I've followed John Lakos for a while and read and considered a lot of his practice. There is some impedance mismatch between the terminology I use in the doc and Lakos's terms, but nothing unmanageable. The most notable difference is that this doc does not propose the `.t.cpp` file for tests, rather preferring a separate directory for tests. I did this because I almost never see a 1:1 correspondence between source files and test code, and I have found keeping them in a separate directory makes it simple to exclude/include them from the build. I jump straight to using subdirectories for namespaced includes exactly for the mentioned reason of needing to avoid name collisions and make it clear what library owns which `#include`. The doc recommends that each library maintain its own include tree and they be added to the compile with a `-I`-flag-per-library
Don't worry, I laughed.
To be clear, standard layout is only a *first step*. The next necessary steps are: 1. Standardizing build/test description. Having the choice in build tools is great, but it's painful for integration when each dependency requires a different build too; a single build description understood by multiple tools would be the best of both worlds in this regard. 2. Standardizing package description. Once again, when each dependency is packaged differently, fetching it is really annoying. The whole `third_party`/`extern` directory should be *unnecessary*.
Same deal. Sorry nlohmann-json, but `&lt;json.hpp&gt;` has to be fixed.
Well, 'buggy' is relative in the context of gcc, but to be fair for the last few major versions it has worked well, and code with -O3 (optionally with -funroll-loops on top) *does* perform significantly better most of the time *for the appropriate algorithm &amp; data*. A single inlineable return like this is probably just a cost/benefit mis-estimation gone wrong. The -O3 "misoptimized" code can be slightly improved again by adding -march=native, so not all is lost. :D 
I think `data` is a bit too abstract. Perhaps `assets`?
Indeed, this is pretty C++ centric and interaction with other languages would be great. I work with projects that mix Java/Python/C++ in a single repository and it's unclear at the moment what the guideline should be for packaging that.
While I think it's good to respect existing convention with regard to naming, I think this is also an opportunity to improve on that convention by at least being consistent with abbreviations. Personally, I think it's better to be more explicit than to be more terse. With that in mind, I don't understand why `source` is abbreviated `src` saving 3 characters while `include` isn't abbreviated to `inc` which would save 4. I say either abbreviate both or neither.
It would ruin `break` and `continue` if you were already in a `switch` or loop.
Yep that makes sense :)
Thank you for the kind words. I specialize in the tooling department of software development, so this is what I really like to do. I'm hoping I can help people encounter less friction in using C++ in the future.
exactly my thoughts, we should better go with extern or external. Because All of the dependencies are external, but not all are third party (by some definition of third party being \`developed by an entity other than the original vendor\`) Unless you have another definition of what third party software is. 
Is there anything except smart use of \`auto\` non-type template parameters? (which is great, I'm just wondering if I'm missing something)
Did anyone check if it's actually slower?
&gt; This doc encodes exactly what I see as the most common layouts. I'm not saying 80% of projects use it, I'm saying 20% of projects use it and everyone else is just vomiting their source code all over the place with no rhyme or reason. Fair, although I disagree that everyone else layout would be necessarily messed up. A lot of applications have their code in a directory structure which is not called src because there is no point in adding a src directory. Maybe consider that to be one of the points that, if taken into account by your proposal, would make it closer to something like a de-facto standard. I don't see specific reasons to not allow having all the code in the root directory as long as it's not a published library. It's not even bother build systems. &gt; Approved? By whom? I'm not seeking some committee's blessing. I'm seeking the community's blessing. Fair enoguh. You are trying to achieve something like semver or utf-8 everywhere. &gt; I feel like you're being contrarian for the sake of it. Sorry if you feel that way, that's not what I meant. Let's ignore the "defacto standard" term and focus on what you want: There are indeed patterns common to more than 50% of the open source projects and maybe closed source projects too. However your proposal, you say it yourself, reflect like 20% of projects (and feels a lot like assuming GUN style is what everybody use, which is far from being the case, but I can see the point if you use only linux for example) and I agree with this opinion (from working with open source and closed source software all the time for 15years professionally now, omg). (side note: github is NOT enough at all IMO as a reference, most people putting code there are already biased in several ways) I meant that you could modify your current proposal to reach that 50% (which is what you are trying to achieve here), and then it would become de-facto indeed. I'm saying it's far from it for several reasons. On the top of my head: - there is no reason to prevent people to have all code source in the root directory ALTHOUGH I would not allow it in all situations, for example for published libraries or for tests (note: I'm saying, convince me with tech arguments I'm not seeing if you want me to agree that your proposal is better than allowing that). - the proposal assume that some directories are optional, but it does not rely on contexts, which make the point a little moot: I would organize a project radically differently depending of it's for internal company tools, public library, public executable, a collection of tools or executable etc. - there are several directories that make no sense to me, but you are modifying for clarity and I didn't read the modifications yet so maybe it improved. Basically it lacks a convincing rationale. If it was specifically for the context of publishing code in something like a package manager, then it would make sense to have "some" rules. Out of this specific context, I'm not convinced that forcing layouts would help anyone. (and I regularly work with java/android, kotlin and C# where layout is necessarilly specified, so I know how it feels when you do have strong specifications, but it's still not convincing me one bit). So basically, you're on the right path but I disagree with the current proposal content. Please work on convincing me. 
I cannot envision any way in which this particular example would be faster or the same speed.
It's used by, I think, Autotools to insert values at configure time. Also, afair, some other tools like CVS use it. There could be issues with some `$tokens` left over, then causing issues with compilation. At least I think, those were the issues raised and I'm not sure, how pobable that is, but I'd guess standards people have to be careful.
&gt; impedance mismatch EE turned software?
Is MultiIndex still pulling in MPL when used with C++17? The MPL dependency was getting fairly problematic for me with Boost.Variant and overriding the MPL vector/list sizes to 30/40 since it imposed obscure constraints on the include ordering. Replacing Boost.Variant with C++17 std::variant or mpark::variant removes the main culprit, but I'd like to excise it completely.
Compilers have some sort of cost analysis, in which they base the decision of performing a particular technique using a combination of weights. The problem I imagine is that the cost estimation is tricky and changes from a particular processor architecture to another.
Seems like a regression from 6.3 -&gt; 7.1 https://godbolt.org/z/y5_zvi 
&gt; The desire for lib/exe separation is common. It warrants further discussion. In fact, it's not really lib/exe separation, it's more multiple targets separation, targets meaning libraries or executables. In the case when the project only build a single target, everything can be in `src`, but as soon as you have multiple targets, you need subfolders in `src`. I don't think that goes against your proposal. It is a way to be flexible and if people want an `app` and `lib` subfolder in `src`, they can, nothing prevents them to do it. 
&gt; then external and third-party mean the same thing. in my eyes it certainly does. &gt; (e.g. third-party and first-party games). I frankly don't know what a 'first-party game' is.
&gt; .../Dutch/Netherland/... We have two votes? Awesome!
Why doesn't charconv support string_view natively in the from_chars overload set?
&gt; .../Dutch/Netherland/... We have two votes? Awesome!
The calling convention for integer is unfortunate when it comes to vectorization. See how it compares to floating point types for clang: [https://godbolt.org/z/QrP0VD](https://godbolt.org/z/QrP0VD). I find GCC's result for float even more surprising. There is no reason for it to copy to scalar registers and back.
Getting multiple libraries in the same source directory is risky business, but possible. That's venturing into the realm of subcomponents. Check the section on `libs/` which addresses that.
&gt; since when has C++ not been strongly typed C++ has always been statically typed, but whether it is "strongly typed", it depends on what anybody thinks "strong typing" means. I personally don't consider C++ type system "strong" as it allows for implicit conversions, array decays, etc.
Reading back at it I have few questions: - What does it better than vector? What are the tradeoffs? - Why the generation is needed? You want to offer functionality to check for deleted items? - Where I would use it over other containers? - Comparison with colony and vector on function complexity guuarantees?
This example is pretty bad. It is basically taking a value from a general register, moving it into xmm0, copying the lower bits to the upper bits, and then moving the values from xmm0 into two general registers again... Rather than just copying the value to two general registers.
&gt; I frankly don't know what a 'first-party game' is. One published by the same company that makes the console. Mario is a first-party game because both it and the console are Nintendo. Mass Effect is third-party because EA made the game, but MS or Sony made the console.
Honestly in this case apart if you have negative costs somewhere, I really can't imagine what is happening in order to produce that kind of results :p 
Honestly the generated code is a complete disaster. It won't probably ever makes sense (from a perf POV) even if you put it in a loop.
Sure. Obviously it sometimes fails, thus I'd like an -fbrute flag that will try _all_ techniques.
I'll take my project as an example. I think `libs/` is unsuited for my needs, or maybe I understand it incorrectly. Most of the game engine is in modules. The main products is many small components. I don't think I should not put my main source code into libs as if it was an external source library source embedded in the project. My structure for that is fairly simple. I have `src/&lt;project package&gt;/&lt;module&gt;/` it also reflect how include should be done. I put `src/` as include directory, so including should look like this: `#include &lt;package/module/header&gt;`. So if a module include something from another package elsewhere or including something form another module, it has the same way of thinking: `package/module/header`. Then when implementing a game with this engine, it's pretty much the same way. All the modules in the game are in `src/&lt;game name or subpackage&gt;/module`. So there's no special treatment here: including stuff from a module or other package is done the same way: `gamename/module/header`.
I presume that it either: 1. Is *always* preferring the vectored form. 2. The operation that did the split of the arguments so they could be vectored occurred *after* the phase that would have recombined them otherwise. 3. The recombiner wasn't capable of coalescing the arguments.
&gt; I'd use multi-index much more, if it wouldn't have so many boost internal dependencies. uh ? there is even an out-of-boost version: https://github.com/Alexhuszagh/multi_index
You mention adding the `BUILD_TESTING` option manually. How about including CTest instead? https://cmake.org/cmake/help/v3.1/module/CTest.html says it does add this option for you, so no need to do it on your own.
I would have hoped that the cost of going to a vectored form would have been considered. And even heuristics to never even attempt it on small and probably even medium-sized stuff, if needed. If the vectoring is done completely in the abstract without even considering anything of the ISA, well, it would seem frankly unfixable (I mean, if we want robust results, and not playing a whac-a-mole game on that topic during the next decade) without a gigantic refactoring... 
I'd say the names ARE (a great) part of this. If you know it always is `src`, then tools have an easier job and users an easier life not needing to define those "variables".
I am 86% sure I'm not a bot. There's a video [0] where I'm trying to recruit more readers for r/cpp, and admittedly my delivery was pretty robotic, but that's *mostly* because I'm Scandinavian. (But I guess that's just what a bot would say, right...?) Thanks for the shout-out /u/emdeka87 (and everyone else!), but let's not forget the people who are writing blog posts, trip reports, articles and so many cool open source C++ projects. Without them we wouldn't have any links to discuss here, so we'd have to get right back to work! [0] https://www.youtube.com/watch?v=xDEGpKJ62lI
Yes you can do that *intentionally* but jpakkanes point was doing that *accidentally*. And I do agree on that: Having the public headers in a separate folder does help. And the argument of matthieum makes that even more worth: When you have the convention of splitting them, tools would know, which headers to install, which to add to private and which to public. Isn't that the whole point about a standard layout? To make it easier for tools to do more based on information of convention?
Same here: `third_party` sounds to much like "other people", while `external` is simply an external code. The difference is that the former refers to owners while the latter to location.
Interestingly, you get the expected results for most `-march` choices... `-march=skylake` works right, for instance.
I think that it's missing heuristics data, as adding even `-mtune=skylake` makes it go away.
I think that it's missing heuristics data, as adding even `-mtune=skylake` makes it go away.
I'm building everything with mtune skylake on my side. I might try to write a minimal repro later, and experiment with a few parameters. 
Vector has no stable identifier for elements. On erase you either shift all the elements (very expensive) or move the last element into the one being removed, ie swap+pop. In both cases, the index for at least 1 other element changes, which means you can not guarantee the location of an item, requiring a search to find it again. With slot map, this is not the case, each element has a unique key that identifies the element for it's lifetime and the generation counter makes the key invalid after that. As you asked, this can be used to check that the element has been deleted. You would use it over other containers if you have a traversal heavy workload (iterating over the collection of elements) that also needs the ability to do random accesses of specific items, such as with a map. An alternative implementation can be optimized for lookup heavy workloads while still providing good traversal performance. The complexity guarantees are O(1) for insert, erase, and find, except when inserting requires an allocation. Additionally, these are consistent cost O(1). The container overhead is consistent, unlike with colony or map implementations which have amortized O(1). 
`-march=core2` doesn't fix it unfortunately. `native` is not really a good choice when you are compiling code to ship :)
That's not a good way to get people involved. If I have to email "them" (who? What email address?) Then wait for a reply, and then fill in a bug, I'm more likely to not bother submitting the bug. The MS compiler has a one click fork for submitting bugs in the IDE.
It was added very late in the C++17 cycle, so there wasn't time for LEWG iteration over "where should we use string_view". In fact, the feature was fixed in a post-C++17 defect report (that added the charconv header and made it implementable). This could easily be added in the future.
Aside from the reason given by others (unexpected effects by importing too much) there is another reason: For a tutorial or help article using explicit names means that things are explicitly clear and easy to follow. It also allows readers to copy the code and pasting it will work, even with snippets (well, almost, `#include` might be missing)
I assumed that OP had already tried to create an account and failed. I‚Äôm guessing you have not done so, because you would have seen a message along the lines of ‚ÄúAccount creation disabled due to spam. Contact &lt;admin&gt;@gcc.org‚Äù. That has the email address and the justification for the policy, which I think is pretty reasonable. Also, I‚Äôd guess that most people who want to submit compiler bugs actually have a problem in their code. I‚Äôd say those people who give up at the slightest obstacle are even more likely to have a bug in their code, not a compiler issue. Weeding them out seems like a plus to me, not a minus. Microsoft is selling a product with their compiler. They make it easy to submit bugs because their customers want that.
Thanks guys, that's very good to know :D
the actual use case for it seems very niche
The amalgamated header is somewhat a build artifact, even if a primitive one. Amalgamated headers are somewhat a workaround for the issue the issue of lack of package management and distribution in C++. Having a `single-include` dir is perfectly reasonable in the right circumstances. I'm aware of several libraries that do this: Crow, Catch, and nlohmann/json are the ones that come to mind. The reason for segmenting tests into their own dir is, indeed, for simplicity in disabling them. I know there are advocates of having tests live in `src/`, but I'm not sure how common they are. I'm going to be doing a more formal survey soon and I'll include this question in there.
The purpose of the division into `libs/` is to prevent header collision. If your components can be consumed piecemeal, you do not want the headers from one component bleeding into other components. The source directories in `libs/*/src` will still mirror that in `src/`. It would be a matter of separating the components that are intermixed in `src/` into their distinct libraries. This could be tool-assisted if necessary. Your include directives would look the same within your sources, but the paths to the actual files will be different. As example, this: &lt;root&gt;/ src/MeowEngine/ Renderer/ Render.hpp Render.cpp Loader/ Loader.hpp Loader.cpp Becomes this: &lt;root&gt;/ libs/ render/src/MeowEngine/Renderer/ Render.hpp Render.cpp loader/src/MeowEngine/Loader/ Loader.hpp Loader.cpp In both cases, a user will include them the same way: #include &lt;MeowEngine/Loader/Loader.hpp&gt; #include &lt;MeowEngine/Renderer/Render.hpp&gt;
&gt;I almost never see a 1:1 correspondence between source files and test code, I had this discussion. I think the answer was roughly, "You could do that, but you would be wrong." Lakos has very firm opinions. I think of it more as accommodating sensible styles. I have found that distinguishing test code from published library code is useful. Another dimension is published mock bases. We are still working on this. But for gmock it works better if the interface owner publishes the mock base. Otherwise everyone else is routinely broken. OTOH, you don't want an accidental mock in prod. 
Even though it was in the standard a while ago it still takes production code time to catch up. Surprisingly, I still find a demand for "modern" C++ education.
I was literally asking on our internal chats about this today. Awesome timing!
Lmao, this guy and his pumpkins.
That looks like a whole mess of shit to me.
I'm not aware of any compiler that the following will not evaluate the if block to true: int* p = nullptr; int&amp; r = *p; if (!&amp;r) { // executes } Reason being that while this is likely undefined, the compiler cant always detect it (e.g. p initialized by the return of a function). This is a trivial enough example that most compilers will allow it and behave as expected. Not all warn at default warning levels, but most will at a sufficient level.
:O TIL
Seriously, please stop doing this. This is not a meme sub, this is a sub about discussing C++. It was funny the first few times this was posted, but posting this to literally ever single thread should be a bannable offense.
"works on my machine" 
decltype is the way to piggy-back on the compiler type inference system. Basically, compiler HAS to figure out type of expression/function/inner class, and you could just pick it from compiler and use it
Perhaps you could add this to the MSVC standard library implementation before the committee gets around to looking at it. 
Great!
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/99jftt/willing_to_help_out_a_beginner_with_c/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I tried to find the meaning of "modern". One of the thing I googled is "contemporary vs modern", and Google highlighted this article about interior design: &gt; "**Modern** design" refers to the specific time period between the early to mid-twentieth century. ... &gt; "Contemporary design" doesn't refer to a specific period of time, it's constantly changing to reflect the popular styles of present day design. &gt; Modern Design Versus Contemporary Design - Mid Century Modern ... https://www.elledecor.com/design-decorate/trends/a13098062/contemporary-vs-design/ So, I guess it's up to C++ historians to define the Modern Age of C++? I consider RAII, strong typing, and compile-time programming as **timeless** qualities or ideals rather than modern. (Whether they are executed well is another question.) The purpose of many of the **contemporary** features and practices is to better achieve these timeless ideals. If you find a piece of C++98 code quite modern to a certain extents, it is probably because it has achieved the timeless qualities of C++.
This is super useful, thanks. 
Tangentially is there any way to have multi_index use flat backing stores like vectors or flat_maps?
/u/ljdawson, I've been having lots of rendering issues with code in this subreddit. Theres lots of "nbsp" for a lot of symbols, but the code renders fine in the window where you preview a post your'e replying to. Thanks again for all your work on Sync, one of the best Android apps out there. **Device information** Sync version: 16.5 Sync flavor: dev View type: Fixed height cards Player type: ExoPlayer Push enabled: false Device: hero2qltetmo Model: samsung SM-G935T Android: 8.0.0
Examples: [the preview render](https://i.imgur.com/LJFoo8g.jpg) [what the post looks like](https://i.imgur.com/T6K7KVs.jpg) Note the line of code below the include directive in both images.
[The documentation on `__builtin_clz()`](https://gcc.gnu.org/onlinedocs/gcc/Other-Builtins.html) says: &gt; Returns the number of leading 0-bits in x, starting at the most significant bit position. If x is 0, the result is undefined.
oops, thanks
Best part is that it is usable in constant expressions. This can be (ab)used to provide a sort order for types which lets you make `T&lt;A, B&gt;` and `T&lt;B, A&gt;` resolve to the same type. I wouldn't count on that working unless all TUs are compiled with the same compiler, but if you can guarantee that, it can be handy.
I generally avoid adding non-standard extensions to production code unless there is a very good reason.
I am not planning to use python here. But you use C++ to make lib usable from python using Boost::python.
Eigen kind of does this using `assert` statements. You still get a huge list of template errors, but the first will be a useful hint like ‚ÄúYOU MIXED MATRIX TYPE YOU NEED TO EXPLICITLY CAST‚Äù and the location of the error will be somewhere need the end of the error list.
Self-promotion is sort of discouraged by reddit rules.
Making use of string\_view would help avoid some calls to strlen() that the char\* version of from\_chars suffers from. I think that's the main reason.
Nice trick, I learnt it some time ago from ctti library (https://github.com/Manu343726/ctti)
This trick is implemented in Boost.Core in a platform-independent way. See https://www.boost.org/doc/libs/1_68_0/libs/core/doc/html/core/typeinfo.html
Thanks for you information. I will consider use it if we need something involve compile time information in future. My company code is not doing much meta programming. I know my implementation is dynamic initialization but since we don't have other global variable initialization involve with it I don't meet segfault from my SmartEnum in my two year development span. (but met once from some lazy variable rely on unnamed namespace static variable initialization, so I purged most global /static variable that not expect zero initialization from my project) Also I found a workaround that use alias in macro using EnumName##SmartEnum = SmartEnum&lt;EnumName&gt;; So it becomes lib::ColorSmartEnum::ToRange(); instead of lib::SmartEnum&lt;lib::Color&gt;::ToRange(); My implementation is relative more maintainable for my colleagues. (TBF, I check and it's actually about 100 lines now) And since I limit my SmartEnum cannot have skipping values, I can do something like use it for vector index in GUI, give min and max value, convert from vector/array index back to Enum guarantee corresponding enumerator.
One can always use a user-defined allocator that uses a vector as its backend, but the result won't guarantee element contiguity. `multi_index_container` is a node-based container like say `std::set`: the same constraints apply.
This is technically doable, of course, but to be honest I don't see that much incentive in basically doubling the maintenance work for a relatively small benefit in terms of, mainly, compile speed.
This layout matches Boost. That big enough for you?
I've implemented both integer and floating-point from_chars() and I can tell you that there are zero calls to strlen(). from_chars() isn't a null-terminated API, so strlen() is inapplicable. On the other hand, from_chars() is a pointer-range API, so it is exactly equivalent to string_view (we subtract the pointers to figure out how many characters are available to consume).
Every time I learn about one more Boost library which I never knew existed and solves some problems I did not yet encounter.
Sounds interesting. Can you say more?
Just out of curiosity: is Wt used in any major website? 
Why is `decltype((x)) = int &amp;`? I mean, what difference does the parentheses make? 
If you don't explicit reserve space, someone will be squatting on it when you come for it later.
If you use parentheses, then the rules of decltype say that you get a reference if the expression is an lvalue. Without them, you get just the type.
Most uses of Wt I know of are deployed as an internal application or as a management interface on a device. Wt isn't really being used as a framework for making websites (it can be, the official site uses Wt). It's rather used to develop highly interactive UIs. So yeah, public-facing deployments of Wt do exist, but they're rare. I don't know what classifies as "major" there. [webtoolkit.eu](https://webtoolkit.eu) itself is probably one of the most popular public-facing ones.
This is last quarter's thread, you may want to try this quarter's.
There are some `std` class names that, to me, are almost like reserved keywords because of the ubiquitous use, such as `vector` and `wstring`. So what I'm doing lately is importing these names in a specific header file, [like this one](https://github.com/rodrigocfd/flac-lame-frontend/blob/master/src/std.h), so I don't have to write the `import`s over and over again.
**Company:** [Systra](https://www.systra.co.uk) **Type:** Full time **Description:** We are looking for a Software Developer to join a small team developing market leading traffic simulation software. All experience levels open. We offer interesting and challenging work on a product sold internationally with a focus on usability and core functionality. We use modern compilers and tools, with regular hours and no on-call requirements. **Location:** Edinburgh, Scotland **Remote:** No **Visa Sponsorship:** No **Technologies:** C++17 &amp; C# on Windows. sqlite/OpenSceneGraph/CMake/GitLab **Contact:** ukcareers@systra.com
MS make it easy to report bugs by everybody. Even users of the "community" edition. And oh it is kind of ironic. Because it used to not be the case; and in those days, it used to be the case that we could report bugs more easily to gcc. I once had an account created by emailing "&lt;admin&gt;@gcc.org" It took *at least* a few day, but I think it was more like a week. So maybe that was a reasonable rational, but that's certainly not a reasonable delay. 
So yeah, depending on march it can be even worse than the initial reporter, for example: // -O2 -march=westmere struct foobar { long l; int j, k; }; foobar fret(long l, int j, int k) { return foobar{ l, j, k}; } https://godbolt.org/z/tlV0y9 
That is interesting. I wonder how much of the elision features in C++ is due to an ancient smart choice of how the calling convention returns values. 
I don't really see it being about compile speed, but more about improving robustness. When things succeed or fail depending upon a hard to control include ordering, the MPL is making things very fragile. I'd very much like to eliminate it entirely. The global tweakable macros like `BOOST_MPL_LIMIT_VECTOR_SIZE` do not play well with MPL being used by multiple components in a single translation unit, and in a header-only component they are even nastier. While I can appreciate the maintenance burden concerns, it might be time to draw a line under the C++03 version and move to a new implementation which is rid of these legacy problems. I'll certainly look at the suggested alternatives you pointed me to, these are very much appreciated, thanks.
`|-|` Ah, yes. The TIE fighter operator.
Any text editor and command line is all you need. Pick the build (or build generator) system and you're ready to go. IDEs hide away too many details and concepts which are crucial to understand, especially to beginners.
This question has been answered numerous times. Also it's off-topic for /r/cpp
&gt; since when has C++ not been strongly typed? Since always? ``` std::vector&lt;int&gt; vec; vec.at(-1); ```
Deffinately check out the YouTube channel TheChernoProject. He uses visual studio. 
Thanks bro &lt;3
It really kicks ass. Both Qt and Wt show how good C++ can be when the API is right.
You haven't heard of Qt or you think it's a bad example?
Command line text editor and compiler are how I learned. Worked out for me. Sorry for your downvotes.
Geography is not my strong point. :P
You would be surprised how hard it is to keep a connection like that up for long enough to discuss a paper, and to get all the tech working properly to make it happen....! It is a bit of a chore and takes some time, so it's definitely only recommended if it really, REALLY needs to happen.
Awesome! doctest is my go-to testing framework. 
Using C++ for web dev. What could go possibly wrong.
End result in vast majority of cases is a "developer" who doesn't know what the translation unit is, neither he/she knows how to effectively sort out the compiler and linker errors, very often doesn't even know the difference between a compiler and linker or what the build system is and what is the purpose of it. And many other things which make those people very inefficient when they stumble upon a problem which is not covered automatically by an IDE or are all of the sudden found themselves in an environment where for example custom build system is being used.
many of the points there need to be reviewed again... I started paying attention only to the most immediate releases and most necessary features. There is something else the standard forbids but doctest does anyway to achieve its compile times - forward declaring ```std::ostream``` in the ```std``` namespace itself and not including ```&lt;iosfwd&gt;``` - there is [a reason for that](https://slides.com/onqtam/2017_cppcon_doctest#/49) and it practically works everywhere
My personal experience.
So the basis of Doctest is undefined behavior that happens to work now, but can stop at any moment? Why would any serious project depend on it? 
Well it's all about tradeoffs - doctest wouldn't cost 10-12 ms to include - but much more like 100ms+ if I included ```&lt;iosfwd&gt;``` and then it wouldn't make sense to include it in a 1000 file project everywhere anymore - it would be too much of a compile time hit. The issue with the identifiers starting with an underscore - that I can fix. For the pedantic users wanting ```&lt;iosfwd&gt;``` - there is an [optional config option](https://github.com/onqtam/doctest/blob/master/doc/markdown/configuration.md#doctest_config_use_iosfwd) so they don't invoke UB.
Have you considered adding overloads to allow for void returns? `return TRUE` or `return 0` adds little value to the code.
Well we don't really need to know anymore, thanks.
Idk, what could go wrong? 
Some french dude forgot to translate his comments
That must have been many, many years ago, and so is pretty much irrelevant. The GCC bug database used to be open for anybody to register directly through the web UI, but it was subjected to several massive spam attacks (fake bugs being filled with adverts for IT support, pretty repairs, and other spam nonsense). I personally spent **days** dealing with the spam, on multiple occasions. During that time I got no work on GCC done at all. Since then we've got better tools for dealing with spam (and blocking accounts) in Bugzilla, but it didn't completely solve the problem. The best solution we have is to add a manual step to creating a new account based on some blacklists and filters. If you want an account just try creating one, it might still work (it tells you account creation is limited, but you can still go ahead and try, and it might work). If it fails, it tells you who to email to get an account created manually. There is a team of 4-5 of us who deal with those requests and you rarely have to wait longer than an hour or two. So yes, it's far from ideal, but the alternative is that lead maintainers of major components of GCC spend their time deleting spam instead of improving the compiler. So sorry if you can't wait an hour or two to file your bug, but I guess it wasn't that important then.
You don't even have the relevant flag set. Submit that as a seperate bug.
I know that optional types are all the rage right now, but don't the same performance considerations exist for them versus C-style error codes versus exceptions? On most ISAs, exceptions are vastly faster when rarely thrown.
Also makes awful hacks like `#define synchronize(...)` and other block-scoped hackery easier. Still cannot easily inject context information into allocators for debugging, though.
Could turn the else-branch into an error case.
I‚Äôm not expert on the performance characteristics of the different approaches. I do believe /u/14ned gave some talks about this in relation to boost outcome and my impression was that c error codes and expected/optional do exhibit similar performance characteristics so you could certainly use the same argument vs exceptions. Personally I find that they are useful in different applications. One example is that expected is good when the direct caller has knowledge about how to handle the error, while exceptions are good for letting someone much further up the call stack handle it. I also work on an embedded application and just enabling exceptions used up more then 5% of the available flash memory, which was quite excessive so using an expected type instead reduced this overhead.
Wow, there's a night mode too!? You're a hero.
nVidia?
There is one inconsistency left: You have \`doc\`, \`include\`, \`util\` but also plural \`examples\`, \`extras\`. Make them all singular and done :) On the rest: As described \`external\` conveys the meaning better than \`thirdparty\` (location vs owner) and \`extras\` is not really clear...
Aleph0 &amp;#x200B;
In my wrapper of from\_chars, it's the first function here: [https://github.com/Ebenezer-group/onwards/blob/master/src/wrappers.hh](https://github.com/Ebenezer-group/onwards/blob/master/src/wrappers.hh) I call strlen() to provide the range. If I already have a string or string\_view, the call to strlen() could be avoided.
s/C on Sea/C**++** on Sea/ - it's a c++ conference
&gt; So the basis of Doctest is undefined behavior that happens to work now, but can stop at any moment? Would you stop taking the road from your home to your supermarket because your city can block it at any moment ? 
ye, just lets completely overwhelm newbie developer, who is struggling with hello world. Amazing idea!
Why not just call it "deps"?
The `libs/` section explains why they should be split. It is to compartmentalize and prevent headers bleeding on each other, as well as aiding browsing and tooling analysis. Each `libs/` dir has its own `src/` (and maybe `include/`) directory. If you use `libs/`, the top-level `src/` is disrecommended. I'm writing a doc that should go into more detail. Watch out for it in the coming days.
I'm writing a more formal doc that is going to fix some pluralization issues. It will also better describe `extras/`.
Your analogy lacks the city clearly forbidding usage of that road before blocking it. 
So if even Boost doesn't conform to the standard, why not change the standard or fix the bug in compilers? 
Well now that I've tried it in godbolt I see it only works correctly in clang, which must the only one I'd tested this on before. GCC doesn't consider __PRETTY_FUNCTION__ to be constexpr and MSVC ICEs. You can see the code (and compiler errors) at https://godbolt.org/z/kXjUhR.
I'd be curious to see an example of this. Got one?
Most of the time you are not interested in the time at run time but at compile time. Since in general you are interested in the type when you have to struggle with template, auto, and decltype and you are lost and do not know which type you have at hand. At this stage, the program often does not compile, so a run time type information does not help. By modifying the example a little bit you get the type at compile time in an error message. template&lt;class T&gt; void type_identifier() { static_assert(sizeof(T)==-1, "type_identifier"); } #define EXPLORE(expr) \ type_identifier&lt;decltype(expr)&gt;(); see at [godbolt](https://gcc.godbolt.org/z/cuGBsc). Note: Only the first occurrence of the type is flagged at an error. So the multiple occurrences of "int &amp;" in the example are flagged only once. MSVS flags the first type, only. However, this should be sufficient in most cases, since you are in general only interested in a single type, which you just cannot figure out. 
testing one two three
one mississippi two pumpkins
[removed]
one Mississippi, two pumpkins
Undefined behavior in the standard is not necessarily undefined behavior in a given version of a specific compiler. Boost does all that special casing so its users don't have to.
Still hope JetBrains would add Doctest runners to their tools (Resharper++ and CLion) one day.
In the general case, anything which uses mapped memory. Anything which uses shared memory. Most uses of C casting. Lots of stuff is UB in the current standard. Even a malloc implementation, and Boost has several memory allocator implementations. In the specific case, the _MSC_VER selected code paths are particularly rife with UB. I remember once cloning an instance of malformed code, as in, code which could not legally compile, which took advantage of a quirk in MSVC's template engine to implement typeof(), which at the time was extremely useful as GCC had been implementing that as an extension for years. But it abounds in Boost. Very bright authors generally, top 1%.
There are several good-to-have prerequisites for that - stable interface, an XML reporter (hopefully both will come with 2.1), and requests from our users. So far not a single request both in R++ and CLion issue trackers.
&gt; Your analogy lacks the city clearly forbidding usage of that road before blocking it. If UB was forbidden it would cause compiler errors.
That is a nice review of the feature that digs a little deeper than a quick overview.
Optionals work this way! if( auto opt_result = get_opt_value() ) { some_other_method( *opt_result ) ... }
No, the standard describes compile time errors as "ill formed expression", which is different from "undefined behavior". With the latter the compiler can do whatever it wants. 
&gt; With the latter the compiler can do whatever it wants. sure, and thankfully no known compiler does stupid stuff when you forward-declare std classes or add your own classes to namespace std.
I suggest you add one or two sentences to your post before the link. There's not enough to help me decide if I want to know more so I just don't pursue it.
If both parties have a good and stable internet connection, it's usually not too big of an issue (except for the regular issues with cameras or microphones... :-)). If either party doesn't have a good connection or a dodgy machine, yea, unfortunately it can be really hard - Skype, Hangouts, and virtually any other tool I tried, they all struggle with low bandwidth. Teamspeak or Mumble are literally the only tools that work in that scenario but they don't support video and require a central server to be set up. I think it's pathetic in my opinion that given the incredible tech we have today and how much we rely on it, yet video conferencing is in practice very often still an unsolved problem...
-&gt; void is implicit by the compiler as well, no need to type it :)
&gt; In some cases, this can actually provide a performance benefit. Quite often comparison operators are implemented by writing `==` and `&lt;`, then writing the other operators in terms of those rather than duplicating the code. This can lead to situations where we want to check `&lt;=` and end up doing an expensive comparison twice. This automatic rewriting can avoid that cost, since it will only call the one `operator&lt;=&gt;` rather than both `operator&lt;` and `operator==` . Although you can usually achieve the same performance by implementing operator&lt;=(a, b) as !operator&gt;(b, a). Really the most you can say is that the spaceship operator is easier to get right. Sometimes it will be slower than binary comparison operators. This is because equality is sometimes a cheaper test than less-than, and the spaceship operator cannot take advantage of this. For example, consider a comparison on std::deque&lt;int&gt;::iterators according to which is earlier in the container. Equality just means comparing whether they refer to the same segment and offset. Less-than is only slightly harder if both iterators point to the same segment, but if they point to different segments you may have to scan the container to see which segment comes first. In this case you'd probably define operator==() and operator!=() as well as the spaceship operator. (For some reason examples similar to this occur quite a few times in my code.)
Start from the summary of changes on Wikipedia for each of C++11, C++ 14, and C++17. IMHO these are the best, most succinct. Look up terms, library facilities, etc., on the two stdlib reference websites, and code small test programs that take and dissect one issue at a time.
MSVC is going to frown upon forward declarations of std stuff.
works fine here: https://gcc.godbolt.org/z/EYyvy1
A tour of C++ is a quick read and a nice book to get back into C++.
I'm talking about the future, since I am from the future.
What I don't like about the design is that there is AFAIK no way to define strict equality and weak ordering at the same time: You are basically forced to decide whether you want equality or equivalence. It would have been better to split those, even at the cost of a more complicated API.
I applied flair to the post (as titles cannot be changed, even by mods).
Just wait until we have fully user-defined operators. `auto operator -----------&gt; () // long pointer deref`
Even easier than the other suggestions, as long as you don't mind using `()` instead of `{}` for your code blocks: #define TEMPORARY_MEMORY_BLOCK(allocator, ...) \ do { \ auto allocator = MyScopedAllocator(); __VA_ARGS__ \ } while (0) TEMPORARY_MEMORY_BLOCK(allocator, char *memoryA = allocateStorage&lt;char&gt;(allocator, 100); char *memoryB = allocateStorage&lt;char&gt;(allocator, 100); char *memoryC = allocateStorage&lt;char&gt;(allocator, 100); ); 
Compelling motivating example for such a mix of operations?
Sure. But if that's the end result, it won't be because they didn't start out with CLI. I would personally consider those to be intermediate topics (Stroustrup doesn't introduce translation units in his TCPPPL book until Chapter 15) and are not expected to be learned off the get go.
IMHO the hard part here is to come up with really compelling examples for weak orders, since once you have one, there will still usually be a notion of equality that is different from equivalence. * Consider some kind of vectors whose ordering is defined by the regular norm. In that case (0,1) and (1,0) are equivalent and may be ordered either way when sorting; It would still be useful to be able to check whether they are equal or not. (Granted, adding `.norm()` and comparing that might be better.) * Alternatively consider the comparison of sets: A set A could be ordered before a set B it A is a strict subset of B, which is a relation that satisfies the requirements of a strict weak-order. There will fo course be many elements that are unordered and therefore equivalent to each other (perfectly fine for weak-orders) but clearly not equal. 
Hey, if I want my Hello World to take 3 days to compile, that's my business.
Wt is great! I have done training to use Wt, and people are amazed by its power developing a fully interactive website in C++. An example of an application done with Wt, r/http://trokam.com **Thanks**, RockinRoel for Wt!.
I do. I don't see the problem, as long as you only post it once, and it's high quality.
Well, I guess you could use a "spiked right through" operator to write ----obj-&gt;member with a bunch of unary minuses. Off topic: Can someone tell me where to read more about this: &gt; if (auto cmp = std::compare3_way(t, rhs.t); cmp != 0) I tried googling for it but didn't turn up anything. It's clear enough how it works, I just want to know which standard it was (will be?) introduced in, or if it's a nonstandard extension.
[Experimentally yes](https://developer.codeplay.com/computecppce/latest/computecpp-with-ptx). 
I'd say for a fundamental library like this, compatibility to c++11 is rather desirable - to many other projects out there that (for whatever reason) are stuck with c++11 for now. Would be a shame, if they could not use this library. 
Ah, thanks -- I was searching for "multiple statements" and should have searched for "[initializer](https://skebanga.github.io/if-with-initializer/)". Do you know, - Is it limited to one other statement? - Must the other statement declare a variable? (I see it need not *assign* anything.) I guess "yes and yes" because it adds the variable to the scope of the `if` statement.
It's actually called compare_3way, and has a page on cppreference
Wonderful, thanks for the correction and thanks for the tip!
Great series! I've been using CMake for about 8 years now, and I pity newcomers having to sift through the Internet trying to learn modern CMake. This playlist will definitely be something I give people asking for advice. Would you mind sharing what tools you used for creating your videos? I've been interested in creating educational videos for a while; I just don't know where to start.
My company's motto is "Enjoy programming again." To me that means using 2011 and newer features of C++ and working on on-line code generation. I'm willing to [help someone on their project](http://webEbenezer.net/about.html) if we use my software as part of the project. 
Okay thanks! most of my problems tends to come from syntax errors and just small errors that i assume will get lesser and lesser the more i program, usually stuff like operand no=t found for &gt;&gt; and adding an extra : in a class call somewhere
If you're like me, then you're gonna go from "oh hey Lambdas are cool I guess" to "HOLY FUCK IMMA USE LAMBDAS FOR EVERYTHING THERE AINT NOTHING THEY CANT DO"
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
How do you keep track of all those? RSS feed?
The only use I could think of for &lt;=&gt; is to embed comparison in math formulas. In other cases it seems even more confusing and dangerous with its implicit conversions (if I got that part right).
[This](https://www.youtube.com/watch?v=wLq-5lBc7x4) talk clarifies at lot of myths and facts on Embedded programming using C++. It says that C++ is not widely supported as C.
Here is the performance data: https://bitbucket.org/hmbd/hmbdc-rel/wiki/Home
What is the situation with the AMD driver support on Linux? Last time I checked, ComputeCpp required an outdated and proprietary driver stack due to (I believe?) missing SPIR-V support in Mesa. Is there any hope to use ComputeCpp on a modern open-source AMD driver stack?
What does Cb in the method names stand for?
Who is Codeplay and what is an SYCL and why is version 1.2.1 of SYCL important?
Some are even stuck with c++98. It was actually a pretty tough decision by the author to drop c++98 support. He still mentions explicitly that version 1.2.9 will continue to have it. &amp;#x200B;
Ok, I see. So maybe `libs` is not a well chosen name for this kind of usage, as it is not reserved to libraries. Maybe `components`, `parts`, or something else.
Indeed. I think this is the right policy by now for libraries that don't want to leave their 98 users in the rain: Move to a newer standard but provide easy access to the last c++98 version and maybe even patch it when necessary. But unless my income depends on it, I'd not be willing to write new features in c++98 anymore (even c++11 gets imho pretty annoying), so I totally understand the author. 
&gt;But if that's the end result, it won't be because they didn't start out with CLI. Of course but in my experience it strongly correlates with it. CLI simply forces you to understand these things and IMO it makes you a favor in the long run. &gt;I would personally consider those to be intermediate topics (Stroustrup doesn't introduce translation units in his TCPPPL book until Chapter 15) and are not expected to be learned off the get go. For me it's 101 üòÄ Probably because I've seen too many times people "debugging" ODR issues for days with having no idea what is going on.
Looks like it's short for callback.
TIE spaceship fighter `operator|-|` anyone?
Thank you for the question! I actually wish examples stopped using \`\`\`using namespace std;\`\`\`, because people add that to production code where it can be harmful. The std namespace contains A LOT of symbols, some of which are very common words (here's some: [https://en.cppreference.com/w/cpp/symbol\_index](https://en.cppreference.com/w/cpp/symbol_index)). And by common words, I mean the type of words that people are likely to use in other libraries or in their own code. You would be surprise the amount of hours I've spent chasing compiler errors in CI builds due to some side-effects of promoting any namespace to global. Also the standard reserves the right to add any names to the namespace at any point. Imagine you are in a project that uses \`absl::string\_view\` ([https://abseil.io/docs/cpp/guides/strings](https://abseil.io/docs/cpp/guides/strings)), some .cpp file does \`using namespace absl;\` and \`using namespace std;\`. The second you switch to a compiler that supports \`std::string\_view\`, good luck with the errors. Now, there are obviously mixed opinions on the matter, and CppCoreGuidelines is actually not against \`using namespace std;\` ([https://github.com/isocpp/CppCoreGuidelines/blob/master/CppCoreGuidelines.md#sf6-use-using-namespace-directives-for-transition-for-foundation-libraries-such-as-std-or-within-a-local-scope-only](https://github.com/isocpp/CppCoreGuidelines/blob/master/CppCoreGuidelines.md#sf6-use-using-namespace-directives-for-transition-for-foundation-libraries-such-as-std-or-within-a-local-scope-only)), but as always, read the fine print: * \`using\` directives should be at local scope (.cpp file, or even inside smaller scopes). DO NOT use them in header files. It can cause compile errors in file that include it, or result in the compiler/linker choosing a different implementation than the developer intended. * \`using namespace std;\` only makes sense when you are a) using LOTS of symbols from the std:: namespace to the point where std:: everywhere looks verbose, and doing an \`using std::xxx\` for each symbol would result in a lot of extra lines b) You are NOT using/including another header file outside the standard library. Everytime I see libraries / examples that do things like \`\`\` using namespace std; using namespace cv; \`\`\` I cringe. Yes, OpenCV does not duplicate any types/names from std, so this is safe. But most people use other libraries too, and unexperienced developers have the tendency to do \`using namespace\` for every namespace they are using, thus increasing the chances of name collisions and defeating the purpose of the namespace system. &amp;#x200B; &amp;#x200B; &amp;#x200B;
Please dont. This is production code poison. You are right in what you are saying: they are "almost" like reserved keywords but they are \*not\*. There is a reason why namespaces exist. In a code base that is designed to survive time (and by that I mean: use newer compilers, newer versions of the standard library, newer versions of any other dependency that it uses, or new dependencies altogether), this should be avoided at all costs. There will ALWAYS be that one case where you do any of these things I've listed and you will get a compiler error that someone will have to spend time and fix. Sometimes they're not obvious at all. Leave it up to the .cpp level to decide where \`using std::vector\` is the right thing to do. Most people these days dont have any issues with being explicit. &amp;#x200B;
Bitsery received quite a bit of attention from WG21 due to P1026. People were generally surprised at how fast this sort of serialisation library can be. However, as I said during Rapperswil, I think we can do even better. Bitsery right now is a memory to memory serialisation library. I think we can eliminate that memory copy in a wide subset of possible C++ object types. Last month I raised some proposals for changes to the C++ memory and object model on std-proposals as a first attempt, those got shot down pretty quickly. But I intend to try again for Kona. So basically please keep doing what you're doing. You're an inspiration to a lot of people to go as far as is needed to reach an iostreams v2. Thank you! 
We want to introduce inline namespaces for ABI compatibility.
&gt; what features would you like to see implemented next? An option to exit test cases using return when exceptions are disabled. Ability to register global callbacks for test case entry and exit. It might already be possible to hack this one together using reporters, but i'm guessing it won't be too pretty. Ability to execute one from each of many sets of subcases. [Example proof of concept](https://godbolt.org/z/a9M_56).
Not sure if we are talking days here. Combinatorial explosions quickly lead you to a place where the age of the universe isn't enough to try all combinations (I've no Idea if this is the case here). It might however be feasible to e.g. compare O2, O3 and Os. The question is then only at which granularity.
It does not perform implicit convertions. You can compare only with -1, 0, 1. Non-literals and other literals will not work.
Wow, i'm excited that this library got attention from WG21! I would also want to note, that quite a big part of the performance drain is actual call to std::memcpy (I know it is implementation defined, but bear with me), I got around 20% performance (gcc, clang) increase simply replacing std::memcpy(data, std::addressof(*tmp), size); with *data = *reinterpret_cast&lt;T*&gt;(std::addressof(*tmp)); but as far as i know it is UB, but there is something to keep in mind for compiler implementers.
Does GCC, Clang, or MSVC support SyCL ?
[ComputeCpp](https://developer.codeplay.com/computecppce/latest/getting-started-guide) appears to require gcc.
Thanks for the info. Much appreciated! I'm looking forward to more videos from you.
On a slightly different subject, this approach for serialization is indeed very powerful and in a way similar to what did boost and other -- except that I prefer the boost API approach where types are deduced by overloading; it is then mainly a way to statically introspect members (and because it is explicit, you can do variation like exclude some and transform others), after that it is usually somewhat easy to copy the data with very light code, and then of course it will perform well, why would it not? Now in simple cases, which are often the bulk of the work, the serialization templates are actually boring, because they merely restate all the members of a given class. What would be great for that are meta"classes", or in general more support for metaprog and introspection.
It's slow when small. If you have a huge one it will be faster simply by virtue of more of it being in cache. 
There is [ComputeCpp CE for Windows](https://developer.codeplay.com/computecppce/latest/computecpp-ce-for-windows) but I'm not sure what it means and if it's up-to-date.
Oh believe you me, we are sick of discussing the meaning and consequences and surprises of `memcpy()` :) But genuinely, members of SG12 found a lot of interest in your library due to the consequences on low level object creation, and our proto-Memory-SG discussed it wrt to future persistent memory support. I remember somebody browsing through your source code during a discussion. So thank you. We're definitely working on making this stuff a LOT better than it currently is. Right now libraries such as yours can only be as fast as `memcpy()`, and it should be possible to exceed that if we fix the language and memory model problems roadblocking better optimisation. Hopefully by C++ 26, unless surprises turn up, or WG21 shoots down the entire endeavour. 
&gt; file(GLOB ‚Ä¶) Stopped reading after that. 
I prefer the more powerful TIE/Int {-o-} and TIE/Adv {&gt;o&lt;} operators. Sometimes gotta go with the TIE Bomber operator {oo}.
I want a serialization library that treats deserialization as a factory function, rather than working in terms of an output parameter. This convention is awkward, as it inevitability introduces two-phase initialization in some form or another. In the past, I've preserved meaningful construction by deserializing into a fluent-style builder class and calling to construct thereafter, but it feels like a band-aid for an API issue. ```cpp std::stringstream ss; { cereal::BinaryOutputArchive oarchive(ss); const auto foo = Foo{...}; // requires meaningful construction oarchive(foo); } const auto foo = [&amp;]{ cereal::BinaryInputArchive iarchive(ss); auto builder = Foo::Builder{}; iarchive(builder); builder.construct(); }(); ```
*puts into todo list for language extensions*
If you are writing code in a header (for example a template or inline function), you can add the `using namespace std;` as the first line of the function to not have to qualify `std::` everywhere inside the function, while still qualifying everything in the rest of the header. This technique is especially useful when you manipulate two namespaces in a file, but some functions only use one. If you put the `using namespace` in the functions themself, it will be really clear without having to qualify everything.
What is the motivation to generate those classes on every run? If the protocol changes, chances are high, that you must manually handcraft the changes anywhere at the seams to the protobuf world. Wouldn't it be better to create the generator and parser code on demand only? 
regarding your first point - that would only work if the asserts are in the test case function itself and not in some other called function. I'll keep this request in mind! second point - the reporter interface is meant to serve this need as well - listeners can be easily implemented - will be fully fleshed-out for version 2.1 the third one is interesting - will think about it as well, thanks!
I just wanted to see if I could do it. If I leave it in my solution I would wrap it in a "if !debug" type of statement.
Right. Many CMake best practices advise not to use file(GLOB).
Well, I certain that the function in the official repo ( https://github.com/Kitware/CMake/blob/v3.6.3/Modules/FindProtobuf.cmake#L112 ) is much better than that blog's one. Official version is pretty good, especially pb.{h,cc} files are regenerated only if protobuf binary or .proto sources are changes.
As I said before, I have stopped reading after seeing file(GLOB), so I have no idea what the author is doing (whatever he's doing is wrong anyway), but in my experience with the protobuf modules, the files only get generated at build time and only if the proto file changed. compared with C++ compilation, the generation time is relatively zero. Also, because they're generated files, it is not something that you want to commit into git, and you usually generate the files in the "build/" folder, for that reason. The changes that you have to make are in your code anyway, you never touch those files.
hmbdc is owned by Hummingbird Code Software LLC, and not a open source project, although most part of it is in open source header files that the user can modify.
`auto operator dÕÆÕäÃêÃíÃøÃÖÕÇÃåÕÉÃëÕäÃâÃìÃíÕÉÕõÕùÕûÃ¥ÕùÕñÕñÃüÕöÕÖeÕ´Õ¨ÕßÕØÃøÕØÃÜÕû“âÃªÕÖÃ©Ã©ÃñÕöÃ£Ã∫ÕôÃüÕïÃüÃ±Ã≤ÕéÕôrÃáÃÉÃéÕëÃÉÃÜÕãÕÜÕ©ÕÑÃÅÕ´ÃèÕßÕäÕóÃÇÃΩÃöÕÄÃ¥ÃúÃ•ÃùÃóÃüeÕåÕ•ÃçÕèÃ•ÃüÃ•Ã≠Ã∞Ã•ÃôÃ™Ã£ÃπÕáÃñÃòÃôÃ≠ÃÆÕìÃ≤fÕ¶ÕÉÃæÕëÕëÕêÕÉÃöÕíÃÄÕ©ÕëÃáÃíÕ™ÕÉÕÄÃµÕ°Ã•ÃüÃ±Ã¨ÕÖÕÖÕâÃñÃ©ÃôÕéÃòÃπÃØeÕÆÃÜÕ®ÃîÕÑÃ¥ÃïÃ¥ÃùÃûÃ†ÕçÃØÃªrÕ´ÃåÃâÕòÃ¥ÕÄÃúÃ≤ÃñÃ≤eÕÜÕØÃÅÃèÃìÕãÕ¶ÕëÕ®Ãç“âÃ®Ã∑ÃüÃ•ÃúÃÆÃ≠Ã™Ã§ÕìÃ¶ÃñÃ¶ÃóÃ§ÃØnÕÉÕ§ÃÑÕåÕóÕÉÃïÃ§ÕñÃºÃ§ÕÖÃ∫Ã≥ÕïÕâÃ±Ã∫ÃôÕôÃûÃ∞Ã≥cÃΩÕÇÕõÕ©ÕíÕûÃ¢ÃØÃªÕéÕàeÕ§Õ≠ÃΩÕ´ÃÖÕ§ÃÇÃöÕ¢Õ°ÕÅÕöÃòÃ≠ÕîÃôÕôÕçÕîÃÆÃªÕçÕÖÃ∞ÃùÕÖ ()`
Is it something like C++AMP?
I think your subset example is a partial_ordering (which has an distinct unordered result https://en.cppreference.com/w/cpp/utility/compare/partial_ordering) rather than a weak_ordering (which doesn't). While the difference between partial and weak is clear and important, the difference between strong and weak is very wishy-washy. It relies on how you interpret "comparison-salient state". In my view, that means whatever the type decides the best default behavior for comparisons is, which makes it a circular definition that makes all orderings strong. I really don't find the strong vs weak distinction to be meaningful, but I also don't subscribe to the cult of ==. I'm fine with it meaning whatever the type designer thinks is the most useful meaning of that operator is. We do however seem to be missing a way to declare a type that supports partial_equality with no ordering.
Computecpp is just fine even with only SPIR 1.2. Mesa lacks any though. Fglrx is indeed the most "assured" choice then, but AMDGPU-PRO (or eventually even just its separate opencl component) should be just fine too these days. ROCm should \*possibly\* going to implement it, but there are no certainties. 
That long list of error messages tells you how you got to that point and are often highly useful. 
https://en.wikipedia.org/wiki/Codeplay (they are like the compute platoon of Khronos) https://en.wikipedia.org/wiki/SYCL#Comparison_with_CUDA https://web.archive.org/web/*/https://www.khronos.org/assets/uploads/developers/library/2017-supercomputing/SYCL-and-OpenCL-State-of-the-Nation_Nov17.pdf#page=11 1.2.1 might seem like a minor release, if it wasn't this is the [first time](https://www.khronos.org/conformance/adopters/conformant-products/sycl) something could actually got certified to support it. 
Good idea! Throw in a PR and I'll be happy to review it, thanks :)
[removed]
I do not think about object construction that much, in the end what really matters is internal object representation, which will be overriden anyway. So probably something like this would be enough: template&lt;typename S, typename T&gt; T createAndDeserialize(S&amp; s) { auto res = Access::create&lt;T&gt;(); s.object(res); return res;} The idea is that, Access is friend of T, and T has private constructor, and thats it, you got the idea:) just need to create this Access::create function.
[removed]
Lmao, this guy and his solid articles.
I think one of the points of the blog article is that we can have a _better_ and _shorter_ error message that _also_ points exactly to the relevant part, and only to the relevant part.
I think you are saying the standard library doesn't do customization points for named functions very well. I mean, C++ supports the syntax to do customization points with named functions. --- The other problem you identify is the lacking reification/reflection problem, right? Your hash should really be friend std::size_t hash( Widget const&amp; widget ) { return hash_combine( hash(widget.members)... ); } where `widget.members` is a magic sequence (that doesn't exist in current C++) that generates a parameter pack of the widget members. (plus some SFINAE) We can get close by implemeneting `friend auto as_tie( Widget const&amp; )` which returns a `std::tie` of the members, manually written. Then we can reuse this for many different kinds of "for each member". But this is only close, as you still have to maintain `as_tie`. The `auto&amp;&amp;[a,b,c] = *this` also gets close, but you cannot `auto&amp;&amp;[...args] = *this;` and get the pack of members. 
All of your code is _exactly_ backwards. `(year % 4)` is true for 1, 2, 3 but not 4. You probably intended `(0 == (year % 4))` There's also a big performance problem with the code. If you assume the input `year` is going to be evenly distributed across a given range of years (i.e. 2001 is just as likely as 2000 is just as likely as 1999) then the order of conditional testing should be reversed. 3 out of every 4 years can be eliminated with the `year % 4` test, but in this example you do that test last. So even though `1999 % 4` tells you that it's not a leap year with one conditional, we actually test `1999 % 400` and `1999 % 100` before we test `1999 % 4`, so that's 2 more branches than are actually needed. In fact, the leap year test is a bad example if you're trying to argue between sequential `if` and `if/else` blocks, because leap year testing naturally maps to _nested_ `if` blocks, because each subsequent test is a special case of a previous test having passed. Therefore the better formulation of the function which corrects the inverted test and minimizes the number of branches the average input goes through would be bool isLeapYear(int year) { if (0 == (year % 4)) { if (0 == (year % 100)) { if (0 == (year % 400)) { return true; } return false; } return true; } return false; } 
That still resorts to two-phase initialization, but providing an additional constructor is a good idea. It could be used to bootstrap single phase initialization with some really ugly sfinae hackery... ```cpp template&lt;typename T, typename IArchive, std::enable_if &lt;is_iarchive&lt;IArchive&gt;::value and std::is_constructible&lt;T, IArchive&amp;&gt;::value, bool&gt;=true&gt; T deserialize(IArchive&amp; ia){ return T{ia}; } template&lt;typename T, typename IArchive, std::enable_if &lt;is_iarchive&lt;IArchive&gt;::value and not std::is_constructible&lt;T, IArchive&amp;&gt;::value and std::is_default_constructible&lt;T&gt;::value, bool&gt;=true&gt; std::conditional_t&lt;true, T, std::void_t &lt;decltype(std::declval&lt;IArchive&amp;&gt;() (std::declval&lt;T&amp;&gt;()))&gt;&gt; deserialize(IArchive&amp; ia){ T t{}; ia(t); return t; } template&lt;typename IArchive, std::enable_if&lt;is_iarchive&lt;IArchive&gt;, bool&gt;=true &gt; Foo(IArchive&amp; ia) try: field0( deserialize&lt;decltype(field0)&gt;(ia) ), field1( deserialize&lt;decltype(field1)&gt;(ia) ){} ```
Lmao this compiler and his error messages
In a template instantiation chain, pointing to the error often isn't the relevant part, though, as the actual logic error causing the syntax error can be buried multiple stages down. Also, without the ability to print types in a static_assert, you lose a lot of valuable information.
BRB writing my "NOODLE (Nilly-willy Object-Oriented Definition of Language Embellishments) Code Considered Harmful" paper.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/9a0s63/clion_help/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Not sure why this was downvoted. Agree 100%.
They support Linux too. There is also triSYCL as another implementation.
I remember reading SPIR support is planned for the next major Mesa version (18.3, I believe), but perhaps it was just wishful/hopeful thinking. I managed to install the ROCm stack on a vanilla 4.18 kernel, ran some OpenCL and HCC examples and everything seems to work fine with the open-source stack (``amdgpu`` + ``amdkfd`` on the kernel side, I think the Mesa userspace bits are not relevant for ROCm, are they?). I hope the dust settles soon. There's lots of good stuff for non-CUDA compute coming down the pipe, but right now the situation is awfully confusing, and getting to the point were you can finally run some computations is way harder than it should be.
&gt; but you cannot `auto&amp;&amp;[...args]` ... yet? [P1061](https://wg21.link/p1061)
The article should have explained _why_ operators are better extensions points. 
In the immense majority of cases, the error will be in your source folder, not in /usr/include, though
I'm all for stuff that hides system include messages - but that's usually at the tool level so it can be customized as needed. I don't want the code enforcing a lack of error messages.
&gt; I remember reading SPIR support is planned for the next major Mesa version (18.3, I believe), but perhaps it was just wishful/hopeful thinking. Uhm.. You are right by chance. What you are very likely thinging to is GL_ARB_gl_spirv (SPIR-V) landing for vulkan-opengl compute interop. Which anyway is still not there after a year of works. We are talking about opencl here though.. Which *actually* **is** getting [something similar](https://patchwork.freedesktop.org/series/40634/). Unfortunately Khronos is being a [total prick](https://github.com/KhronosGroup/OpenCL-CTS/pull/3) with pierre.. And for as much as I know those patches might go nowhere. &gt; (amdgpu + amdkfd on the kernel side, I think the Mesa userspace bits are not relevant for ROCm, are they?). Amdkfd should \*be\* ROCm (which has nothing to do with mesa, which at most has clover)
Little pedantic, since it's not an ultra-responsive application but try replacing your use of endl with "\r\n". Would be cool to see if you can notice a difference. :)
Awesome work! I wonder if we have a runner / support in VS2017 yet? It's awesome having auto discovery and running of tests in the IDE, after all. One of the big points for/against testing frameworks for me.
[removed]
I don't see that much use of C++11 in there at all. You could look into using `&lt;random&gt;` instead of `srand` and range-for loops when looping through your board. Also, some basic documentation / comments here and there would help readability. Result looks good though, especially like the "font" for 2048.
Never send `'\r'` to a text-mode stream; the entire point of text-mode (which is the default for streams, which I find silly) is to take care of that for you in a platform-independent way. `'\n'` is how you do a newline in C++, regardless of platform.