Just a reminder that development of CMake is volunteer driven. Sean makes many criticisms which are already well known, and some of them even have designed solutions. However, there are few people who contribute to improving CMake in a way that would improve what is written above. If anyone wants to help, there are instructions for a junior job here: https://www.mail-archive.com/cmake-developers@cmake.org/msg16399.html and I can provide more to anyone who wants to contribute.
The project looks pretty cool at first sight and I have a few suggestions about it: *1. In the github repo you should at least put a Makefile, Visual Studio project file , CMake or something to make it easy to build. *2. Put some screenshot in the README.MD, if a recruiter is looking at your github account he/she might be to lazy to compile and run it. Make it look like the coolest game ever and Blizzard is envy at your project :D I looked a bit at the code and it looks good. Great job. 
You are correct that the particular speedups are somewhat arbitrary, and depend on various factors such as number of elements, element ordering, individual element size, predicate speed, etc, etc.. I think any experienced dev knows this. That's not really the point though. The point is that some standard libs are doing unnecessary work, and that extra work has a cost. The particular cost my vary depending on the circumstances, but it's still wasteful.
I agree that a 'contains' function would be nice, and it seems like an oversight that none exists. Everyone has to make at least some assumptions based on the semantics of methods though. Or do you profile every single method from every API before you use it?
Maybe you are right, in my head it's reasonable that count will keep on searching for values BUT after reading your #3 blog post I ask myself why count should be different from what I ASSUME find is doing. B.T.W. nice catch on find.
&gt; All that sounds really great :) :) &gt; Do you have any plans for WebSocket or HTTP Session Management ? I've implemented WebSocket and HTTP session management in a previous project of mine (Tuf√£o). I'll try to integrate [WebSocket support from Vinnie Falco's Beast.HTTP](https://github.com/vinniefalco/Beast). We've setup a mailing list to collaborate more: https://groups.google.com/forum/#!forum/boosthttp-dev On the topic of HTTP Session Management, I'll try to implement it from scratch (although I intend to revisit Tuf√£o's implementation), but I think the request router's feature has a higher priority.
Good to know my app was at least useful to someone =) 
Just in case my remark was not reallyclear (because it seems it was not), let me clarify a point. Let's say that you have your code as now, and I do this: class SomeResource { // MIght be unique_ptr if it makes more sense, depends on the resource shared_ptr&lt;Resource&gt; _impl = Resource::factory::create(); // or args passed throught he constructor. public: void only_public_operations() { _impl-&gt;operations(); } }; This is how most RAII-based code are implemented when dealing with special acquisition/release code. It allows the user to do this { SomeResource resource; // no fricking smart pointers in user code resource.public_operations(); } // release And it allows you, the author, to implement SomeResource whatever you want, with the semantic you want (which might not match exactly the semantic of the internal resource being managed) with or without factories, without impacting the user. Providing this is easy and help both the author and user. Otherwise, you are impacting the user which is a bad sign for long-term code and makes the tool a no-no for long-term project (in my experience). But do as you will. :) Maybe for the next project indeed. Note that SFML does this and do use OGLContext so it is not a valid excuse (because it can be done with any kind of resource really, as it separate how the user use it from how it is manage internally).
For information: Each make_shared/make_unique is a `new` call, aka a dynamic allocation. Most modern engines (I do not count Ogre as modern, even Ogre 2.x) try to limit these allocations in various ways, most notably pooling, arena and allocator techniques. The whole idea is to allocate big blocks at the beginning and avoid allocations inside update loops. Also, copies of shared_ptr require changing the value of an atomic, which prevent optimizations around the copy code and is far slower than a normal poitner copy. Ah yeah last point: shared_ptr cost is not negligeable, even on current PCs. When you make a game, all the resources available are good to help make the game smooth. If a gamedev gets sloppy with allocations and cost considerations of shared_ptr, they might end with a slow or, worse, stuttering game.
Why bad form? map::insert uses pair&lt;iterator,bool&gt; to signal if the insert succeeded. 
I think he means everyone but developers, hopefully. I hate working with UI's where point and click takes so much time. If I can do it via command line then I don't need a UI.
Static variables are a bit of a tricky issue; I'd recommend re-evaluating to see if you really need them. However, if you are going to use them, then you should be aware of something that most developers (including many of the ones on this thread) are not aware of: you should *never* have non-trivial class or namespace level statics variables. That is, variables that have constructors and/or destructors, are very dangerous to have as class or namespace statics. For starters, it's hard to guarantee exactly when the constructor or destructor will get called. More importantly, on linux, when you use a combination of static and shared libraries you can easily end up with situations where you have two copies of the static variable, and one of them is double destructed. You can duplicate this on Linux with as few as 20 lines of code. The correct way to do non-trivial statics is with a function and a static local: static std::vector&lt;AdBanner&gt; m_banners; // bad // good static std::vector&lt;AdBanner&gt;&amp; getBanners() { static std::vector&lt;AdBanner&gt; banners; return banners; } Also, obviously most style/indentation stuff is up to taste, but you may not want to indent on namespaces. It really just wastes vertical space, and it's very very rare in style guides to see indentation on namespaces.
bitset2 already has a function `data()` (not mentioned in the readme, yet), which gives access to the underlying array&lt;ULLONG&gt;. I thought about implementing a constructor taking two iterators, but I did not come up with the idea of using integers with different width.
 template&lt;typename T&gt; T&amp; instance(){ static T t; return t; } generic singleton
The fix seems a little too specific. Why not fix `equal_range` for these containers? That then generalizes to any other algorithms implemented in terms of `equal_range`.
Works great if you only need one singleton of each type, ever. Of course you can add another template parameter as a "tag", but at this point the boilerplate is approaching the lines of code of the original...
On "why HTML/CSS?" You will need to declare / define your UI in any way. It could be sequence of declarations in your source code like: window* mainWindow = ...; mainWindow.addChild( new WidgetA (...) ); mainWindow.addChild( new WidgetB (...) ); or you will use some other means provided you by each platform, like DLG resources in Windows or XAML in WPF. MacOS, Linux/GTK use their own UI definition formats. QT - its own, and so on. In that sense you can consider HTML as just a convenient way to define a tree of UI elements - pretty much each developer knows what HTML/XML is. HTML/XML has good support of development tools - all modern IDE's and source editors. As it is a text you have support of CVS support out of the box and so on. In the same way as HTML/XML defines semantic / structure of your UI, CSS defines its style - concrete rendering / appearance. The same UI (DOM) tree can be styled differently for each platform , screen resolution, user preferences, etc. Like for people with disabilities it can be styled with contrast colors, large font sizes and so on. Sciter goes a bit further with CSS from conventional browsers. If your markup looks like as: &lt;list&gt; &lt;li&gt;foo&lt;/li&gt; &lt;li&gt;bar&lt;/li&gt; &lt;list&gt; then in CSS you can define not just visual appearance of such a list but also its behavioral style: list { behavior: VirtualList; color: red; } or (on different platform / device) list { behavior: ListWithTouchSupport; color: blue; } where VirtualList and ListWithTouchSupport are names of native "controllers" - C++ classes responsible for handling events, rendering and life cycle of such DOM element: class VirtualList : public sciter::event_handler { virtual bool attach(HELEMENT self) override; virtual void detach() override; virtual bool handle_mouse(EVENT_MOUSE&amp; evt) override; virtual bool handle_key(EVENT_KEY&amp; evt) override; ... } Such a behavior can be defined as in native code (C++, Delphi, Go, Rust, Python, etc) as in script. Essentially your UI is just a tree of universal DOM elements. Some elements have behaviors attached to them. All those &lt;input type="text"&gt;, &lt;textarea&gt;, &lt;select&gt; are plain DOM elements in Sciter with corresponding behaviors attached. As of grid layout you've mentioned. From the very beginning Sciter has `flow:grid()` feature - grid layout manager that works in the same way (of course) on all supported platforms: Win/Lin/Mac and others that are coming. CSS in Sciter is extended by features designed specifically for desktop / UI support - various layout managers, popup elements, HTML defined windows and dialogs, etc. It's really a bit different entity than a browser wrapped into some widget that's pretty much only capable to render long tape of formatted text in isolated sandbox. If you are OK with SQL as a DSL to define and manipulate data sets then you can treat HTML and CSS as DSLs for UI. In this respect CSS selectors (https://developer.mozilla.org/en-US/docs/Web/Guide/CSS/Getting_started/Selectors) can be treated as a convenient query language working on dynamic UI tree structures. And check this http://sciter.com/from-skeuomorph-to-flat-ui-evolution-of-one-application/ This application survived almost 10 years with the same structure and code base. From Windows 2000 to Windows 10. From Skeumorphism to flat Metro UIs. From 800x600px screens to 4K monitors. Just because of right architecture decisions separating concerns - UI (HTML/CSS/script) and main logic on their own layers. 
Thanks for your insightful reply! It seems that Sciter indeed tranforms vanilla HTML/CSS into something much more usable for UI. I can see many parallels to QML. I need to do some research then and see how things are in the Electron camp. ;)
Usually .NET Forms, so I tend not to pick this if I want the project to be portable. But it is a quick and easy way to get a Windows GUI done.
That may be true for public versions of compilers, but there's nothing that says that Google-internal forks aren't modified to implicitly assume all code is noexcept since the entire environment at Google is compiled without exceptions. I don't actually know. I'm just saying it's possible they do that.
Since you dont mention http anywhere, why not use zeromq along with cppzmq (c++ bindings)?
http://www.bookfinder.com/search/?author=Gaddis%2C+Tony&amp;title=Starting+Out+With+C&amp;lang=en&amp;st=xl&amp;ac=qr
it was deliberate, it was just not in good enough shape for 17, and there was not enough time to 'beat' it into shape. IIRC it was however forwarded to be included ASAP after 17, i.e. LEWG is happy with the design, and as soon as the wording is ready and C++17 is out of our hands, the full committee will vote on it. 
It's an open source project, so jump in and help out!
I'm practically the last (open source) maintainer left ¬Ø\\\_(„ÉÑ)_\/¬Ø
I remember years and years ago that my company switched to using the Dinkum STL libraries that supported block allocation, and therefore didn't incur the same performance penalties on doing lots and lots of tiny allocations. I'd assumed that MSVC STL had updated since then (early 2000s). Is this not the case, and/or is this an unrelated problem? 
In the STL style, taking two iterators (and maybe a [range](https://github.com/ericniebler/range-v3)\) should be enough; one can easily provide adapters for any source data type, rather than cluttering up the class with a bunch of variations on construction.
Ty but I just need for a college class I am taking
if anyone knows how to acheive that with ImGUI ill happily implement it. afaik imGUI keeps things like text scrolling to itself.
&gt; A major (the only?) downside of this is that they cannot robustly handle memory allocation failure, instead these projects are forced to crash if sufficient memory is not available. - It's not true that exceptions are required to handle out of memory errors. You can use `new (nothrow)`, or you can use `malloc`, as well as many other options - Using exceptions doesn't necessarily mean you can handle out of memory errors. For example, under typical configurations, programs running on Linux will be killed by the OS rather than having memory allocation fail. - There are other downsides to not enabling exceptions: you can't use libraries that require exceptions; You lose out on the better support for structured error handling that exceptions provide; Exceptions, at least in some cases, perform better than inline branches and error code checking; Exceptions can make correctly handling errors much more readable. See http://exceptionsafecode.com
/u/fnupvote89 and /u/Som1Lse - I've checked in a fix for an upcoming release of the Visual C++ libraries. Now the STL won't lead the compiler down the wrong metaprogramming codepath (the diagnostic is still pretty lame, but at least I don't leak _Unforced).
Could this article be considered a re-discovery of what Boost.Preprocessor is? There is a lof of dark magic in there.
Haha prettymuch, which is why I listed it as an example of a time when I don't use "normal" C++. :¬¨)
They are really old, there has been some work done in getting libc++ working again on windows, but to my best knowledge libc++ currently doesn't link properly on windows.
Basically, &lt;xhash&gt; has not had performance work done on it in a long time, and still has a bunch of vestigial pieces used to support the nonstandard stdext::hash_map. We started doing serious perf work again relatively recently; e.g. several performance fixes shipped in VS2015 Update 2 and Update 3.
Given that this is the preprocessor, why are the __ tokens needed? What's wrong with just: #if has_include(&lt;stdio.h&gt;) Or even better: #if exists(&lt;stdio.h&gt;) ? We don't worry about #if defined(foo), because defined is not "taken" like a C/C++ keyword (eg for) would be. You're free to have, eg: #if exists(&lt;stdio.h&gt;) bool exists = true; #endif
[Sorry I just broke your link](https://github.com/llvm-mirror/libcxx/commit/1fceb5e53d3e39b1167cc023c266876999e9c4fc). Those results are *super* old and are no longer relevant in any sense. Currently the library doesn't even build on Windows, even when using an LLVM toolchain. However with the help of /u/STL we have been improving the portability of the libc++ test suite and hopefully that will cause the library to follow.
The video linked [here](https://www.reddit.com/r/cpp/comments/4we762/do_any_of_you_use_c_for_small_programs/d66j0m1) has some cool examples of [Cinder](https://libcinder.org/) that made it look pretty good.
I just don't quite see the point. Sure you can sometimes do conditional includes a bit easier, but usually you still have to do the proper detection for the environment when you're actually using stuff from the header: #if __has_include(&lt;windows.h&gt;) #include &lt;windows.h&gt; #endif ... #if _WIN32 someWindowsFunction(); #endif This just makes very inconsistent style, and you run the risk of having only one of your #if conditions being true. And I don't think you should detect environment solely based on includes either because who knows what headers compilers might have for compatibility. I would still prefer the style where you detect the environment in one place only and define your own constants based on that. #if _WIN32 #define MYLIB_WINDOWS 1 #endif ... #if MYLIB_WINDOWS #include &lt;windows.h&gt; #endif ... #if MYLIB_WINDOWS someWindowsFunction(); #endif 
FYI, we enabled user flair, so you can mark yourself as a libc++ dev.
Cool, I didn't actually realize that CMake is volunteer driven. Do you have any idea why the `cmake-lua` project died? That sounds to me like it would have been a good idea. The `cmake` backend, finding libraries, working well on all platforms, mostly works in my experience, and certainly better than competitors like `scons`, again in my experience, but the `cmake` language itself is agony. I don't have enough insight into the project to understand why an effort like `cmake-lua` didn't take off, would really like to understand what the obstacles were. See e.g. http://playcontrol.net/ewing/jibberjabber/cmake_lua.html http://lua-users.org/lists/lua-l/2008-02/msg00403.html https://www.reddit.com/r/cpp/comments/4flb8z/fighting_through_a_cmake_hell/d2a1ln9
RIP Timothy Treadwell http://www.imdb.com/title/tt0427312/
Yes bears are dangerous in general.
FWIW, boost has a thread barrier implementation using mutex + condition variable as /u/STL recommended. The reason it's not provided in the STL is that there hasn't been a proposal. Multi-threading only started coming in with C++11 so I'm sure at some point someone will get around to writing a proposal. http://www.boost.org/doc/libs/1_40_0/boost/thread/barrier.hpp
Is that headed for C++17 or the next one?
I know, but I'd rather have a specialized type with meaningful member names or functions. It (pair) works, but you get things like pair&lt;iterator, bool&gt; result = ...; if(result.second) use result.first-&gt;second; 
I'm currently writing a class called ````AdBannerSelector````, and previously, I put the constructor for my ````AdBanner```` class as private so that no other code could construct an ````AdBanner```` object. This plays nicely because I could put value validation code in my ````load()```` function instead of inside the constructor. Should I just suck it up and make my constructor public, or declare my ````load()```` function (which is now a member function of ````AdBannerSelector````) as a friend function?
You can use std::tie to make this more palatable, and it actually looks quite nice and readable with that. std::tie(it, found) = ...; if (found) // use 'it'
I wouldn't make the constructor public if nothing else is supposed to construct it. A friend isn't a bad solution. There's also another option: make an AdBannerInterface interface class in the public header, and declare the actual AdBanner class (implanting the interface) in the cpp file where only the AdBannerSelector can see it. Then the constructor could be public without other people bring able to construct it. A friend is the easier option by far.
I doubt we will in this case, but sometimes see a header with #define nice_name __nice_name (e.g. __Bool in C, and stdbool.h)
Hell, your Windows.h could be provided by a cross compiler and you are actually on linux anyway.
1. I don't feel competent for doing benchmarks since this requires a multidimensional analysis. I observed (as expected) that gcc optimizes the code much better than clang. Anyway, I think there is some room for performance improvements within bitset2. 2. Implementing functions like is_subset_of should be possible. Surprisingly to me I did not think about shortcuts. I wonder, if the compiler applies shortcut optimizations for, e.g., operator== like it is currently implemented. I will try to figure out but expect the [KISS principle](https://en.wikipedia.org/wiki/KISS_principle) to be best here.
Take a look at this blog. Here often describe the open source projects and their errors http://www.viva64.com/ru/b/
I am, does she have a website or something?
Graphics programming is just not about learning APIs, such as OpenGL, DirectX, or Vulkan. It's about familiarising yourself with the concepts and fundamental techniques in computer graphics. If you are interested this topic, purely from an academic perspective, I suggest you to write a software ray tracer. It's a very simple and elegant algorithm and it's fun to write. Start off with ray/primitive intersections, like spheres, planes and rects, maybe triangles even. Model different BDRFs, starting with Phong, then some of the more fancy ones, such as Cook-Torrance. Implement reflection and refraction. Implement shadows. Implement caustics. Speed up the ray tracer with space partitioning techniques. Once you done all that, time to get more serious and try accelerating your renderer. Use `std::thread`s to split up your compute load across many cores. Perhaps contemplate to do some of this work via OpenGL shaders. 
LB-- I made a repo like that also once, but the thing is * What I really want is, *not* the ubuntu /r/toolchain/test package, I would like to have the gcc 6 standard library also installed when I use gcc 6 * When install clang, would like to use libc++ with it, and the matching version... I don't know a way to do this right now other than docker, or possibly like, if all this shit was converted to a chef recipe and we contributed to the "contributors" section of travis chef cookbooks. I know that some other languages have a custom cookbook not maintained by travis, but it's hard to figure out, *1* why C++ doesn't, *2* if it would be possible to use it after it was contributed or if there's even more resulting work in travis backend required, *3* unknown unknowns...
Yes, but it's in Dutch and French. If that's okay for you I'll PM the address and some more information. Otherwise I'll give you some pointers and an email adress (which is fine in English). She basically embroiders text on other stuff, including baby things. So you could go with something like 'When I grow up, I'll write C++'. Just keep in mind to keep things quite short :')
I'm dutch myself so that's quite alright
Very useful information
An ostrich, obviously
&gt; As the example in OP's video shows, there are multiple posix compatible environments, each their own distinct definition. All of that can be reduced down to a single #if __has_include(&lt;foo&gt;) statement, which will work on some future unknown environment, which may also offer posix compatibility. There is some validity to the argument, but I just think it's an extremely brittle way of detecting the environment. (Of course macros are too, but slightly less so.) You cannot be sure that the header only exists on fully posix compliant systems. MSVC has some posix headers but afaik the posix compatibility is very limited, and you would usually want to use windows api instead. Or maybe there are environments with completely unrelated headers with same name etc. &gt; Just because _WIN32 is defined, doesn't mean you have APIs in &lt;windows.h&gt; exposed to you. Sure, you can have a windows compiler without Windows headers (although I would consider that a badly configured build environment). But that's besides the point. If our application has no other way of functioning on Windows other than using winapi, then we have to assume that the header exists. We can't just say "oh it's not available, let's use something else then". The code just rightfully fails to compile without windows.h. And as I said earlier, the reverse is also true. Just because windows.h is available it doesn't mean we want to compile using it. Cygwin has windows.h but doesn't define _WIN32 unless you're crosscompiling with cygwin-mingw or something, so your code has very different semantics than in my example. 
~~Regarding why I couldn't use ````emplace_back()````, I'm assuming that despite a function being declared a friend function, ````std::vector````'s ````emplace_back()```` is not allowed to access a private constructor?~~ Edit: I guess I'm restricted to ````push_back()````.
clickbait?
If you want a project: Write a 3d software renderer and only use libraries that enable you to put the rendered bitmap on screen and receive mouse input.
Yeah, it's not exactly neat or simple, but most of it is just stuff to implement std::uncaught_exceptions, if you have C++17 you can delete it. The big benefit is that it also supports `scope(failure)` (and `scope(success)`), so you can stick operations onto the stack that only execute if there is (not) an exception. It avoids horrible nested try catch blocks where you have a series of operations and each needs to be unwound/released in case of failure. Obviously in most cases RAII is better, but this comes in handy occasionally. Like when calling c-ish librarys that you aren't using enough to make a RAII wrapper worthwhile (which is what I thought ntrel2 was referring to, perhaps I misunderstood).
I guess my argument boils down to the following question: Which is more important, knowing about the availability of the platform, or knowing whether you can code against a particular API? I would argue the latter is more immediately useful. 
How about the book "C++ for Kids" or "C++ for Toddlers" or if you whan only a baby cloths as a gag gift a babysuite with the famois c program hello world https://www.amazon.com/CafePress-Hello-Infant-Creeper-Bodysuit/dp/B00MFGJPSK/ref=sr_1_cc_1?s=aps&amp;ie=UTF8&amp;qid=1470750352&amp;sr=1-1-catcorr&amp;keywords=c%2B%2B+for+toddlers
Crucial insight: &gt;The standard does not define storage **location**. It defines storage **duration**. The best books (or whatever) are those that nicely explain what you already know.
Why is this stuff part of the compiler proper? It takes forever to get these features standardized and ubiquitous which means for any serious cross-platform development, one usually can't even consider using these features for years. But if these features were some small stand alone preprocessor-like layer, or some other tool independent of the compiler, then features like this could be used immediately - even with C++98 compilers (or C compilers).
Ctrl+F, "free store", eye roll. Literally nobody uses this terminology except the C++ spec and pedants who just read the spec and think they're the first ones. In the real world stuff is really stored on the stack and the heap, they really grow towards each other, and that's all you actually need to care about
I don't think that's a good assumption -- they might use something like `std::expected` or `std::optional` or similar composite types to represent "return value, if possible".
99% of the time (except for highly technical topics like function call ABIs), the terms "stack" and "heap" are already widely understood to be shorthand for referring to automatic and dynamic storage duration respectively. I'm all for being technically correct, but this post seems needlessly pedantic.
STL maintainer here. We never say "free store".
I'd say this post is mostly aimed at the people who *don't* know that. It's an introduction to storage duration and how that is defined by the standard. There is certainly value in promoting the use of technically accurate terms for the layer of abstraction a C++ developer should typically be working at.
I still don't understand the purpose of barriers. Creating "thundering herds" of threads all trying to compete for the same resource seems like performance suicide.
Simon did a talk based on this article at the latest C++ meet-up in Edinburgh that I organise. It was well received and had some great feedback, so many thanks to him! If you're interested, you can get the slides on the [C++ Edinburgh website](http://cppedinburgh.uk/).
üëç
Python also had the immense advantage of a much easier install process and a decent cross platform package manager. A typical small script at work for me would be to read a binary file and output some interesting properties in cleartext, perhaps do some basic plotting. Sure I can do that with C++, but I'll need some libraries and rather quickly i get to the point where a CMake script is needed for the installation. If I want to share this basic utillity with some moderately technically literate collegue Id probably end up spending a few hours installing whatever dependencies are needed on his specific OS. All of this is simply so much easier with Python.
[Thread bears](https://www.google.com/images?q=bear+cross+stitch), though?
&gt; much easier install process Agree with everything else, but I might have to disagree with you there. For users, a c++ program is just a single binary, generally no installation needed, especially if you statically link. But python has multiple versions, multiple versions of dependencies, 6 different ways to install packages, is a bit of a pain on Windows, OS X comes with some weird default version, and some stuff kinda works if you have the wrong version, other stuff doesn't. I actually think this is one of the biggest pain-points with python, it's hard to package something for a user especially if that user isn't really interested in developing python.
On OS X, gl.h is found at `&lt;OpenGL/gl.h&gt;`. On most other platforms, it is found at `&lt;GL/gl.h&gt;`. Currently you either have to hardcode this difference based on the platform, or use a configure script to check which one exists. There are unfortunately countless similar examples of headers existing under different names or locations on various platforms.
FreeType2 actually *requires* that you include its headers in this way. There's a top-level header that you include which then defines macros which you use to include the other headers you need. FT2's API is kinda dumb.
Very informative tutorial, information is well on point. 
It's a relatively rare use case where the need is to ensure that concurrent iterative work occurs in lockstep fashion. It doesn't necessarily have anything to do with competing for resources. E.g. imagine a ray-trace rendering system where the output images are broken up into tiles where each worker thread is assigned a tile. You might use a barrier to ensure that frame X is complete before work on frame X+1 is started. 
Stack and heap grow towards each other - on which platforms?
Here are two alternative method, but i think ifs are ok. http://ideone.com/GGGTTN
I never thought that option #4, having the dev compile it themselves was all that rare. But then again I have installed Gentoo Linux; what do I know?
Hi Vittorio, Thanks for the feedback. INTERFACE libraries and IDE integration are definitely a gap in the CMake offering. There is work that would need to be done in CMake itself to make the Qt experience better in general. Having said that, in this example, all that is needed is to list the header files as part of the library and use my option #4. https://github.com/steveire/vittorioromeo.info/commits/master Here's what I see in QtCreator: http://www.steveire.com/interface_sources.png (BTW, this is the implementation of what I suggested here: http://stackoverflow.com/questions/27866669/preventing-cmake-generated-makefile-for-optional-header-only-library-from-compil )
What do you call the memory that std::unordered_map allocates to on default construction? /trolling
I used QT with its QML and quick design stuff. I have never really done UI programming before, and the concept of widgets seemed alien and clunky to me. But it seems they're a very well established concept within UI programs. Am I just missing something? Can you recommend anything for me to read to get familiar with the general nature of ui programming?
Neat. Could you post the differences it makes to compile time (which is my biggest issue with Boost, CImg and other header only libs) with the different approaches, and versus precompiled headers? I found that using precompiled headers shaved off about a third of the cost of including CImg on my Raspberry Pi 2.
I always used bubble sort during my programming exercises when I was still in college. Thanks for this tutorial! Very easy to understand.
Kinda late to the party but Facebook's open source C++ library (Folly, https://github.com/facebook/folly) uses exceptions.
Well, I'm not really well versed with UI programming either, but this is my understanding: Basically you got two important things, the event loop and the graphical items (widgets) (also some "meta-widgets" like layout containers). Widgets create and respond to events (clicked, update display etc.), in Qt this event mechanism is called [signals and slots](http://doc.qt.io/qt-5/signalsandslots.html). Things like timers can also create events when they fire, of course. The instance which normally (always?) hosts the event loop is the [QApplication instance](http://www.ics.com/designpatterns/solutions/eventloop.html). It might be worthwhile trying to create a simple UI without QML, but instead creating some basic widgets by hand and connecting them manually.
Recommended reading on the topic: Scott Meyers - Effective C++. Item 35: Consider alternatives to virtual functions.
The long-form manuals are the canonical source of what is idiomatic and how things fit together: https://cmake.org/cmake/help/v3.6/index.html#reference-manuals If you want to see a real-world, packaged-into-linux-distros, has-dependencies-and-used-as-dependency library using all of the Modern CMake stuff, see my Grantlee libraries: https://github.com/steveire/grantlee/ 
The first link I already know. It's the CMake help as Web pages. Nothing wrong with that, just pointing out. I'll check out your repo, thanks for the link! 
&gt; They ignore the talk proposal and just treat it as an invitation to rant/vent about whatever they hate most about CMake This is example of bad developer behavior, but somewhat understandable. CMake is not very straightforward about it's features. And syntax is... well you know about syntax. After working with other languages like JS (npm), Java (gradle\maven), Python (pip), Go - I simply can't force myself to use it anywhere but professional projects. qbs\premake all the way for me. Still I respect it as "de-facto" standard, tho. But where C++ made progress towards "simplification and straightforwardness" and "deprecating" things (raw "new"? HELL NO) CMake on other hand is still looking very "makish". &gt; https://cmake.org/cmake/help/v3.5/manual/cmake-buildsystem.7.html I agree that we need a good CMake "cookbook" that extensively covers every every aspect and possible quirks. Something like cppreference but for CMake. That would be nice. I know that I can look into github projects, but I would prefer not to. P.S. How is CMake daemon project btw?
I think the article is creating problems for it to solve. The init and destroy methods are common antipattern, they are in the same category as singletons. Useful when you have no other choice, but in that case, if you are not really careful, expect difficult bugs. If you don't use init and destroy, but actual constructors and destructors, you have no problems with function call order. 
&gt; CMake does not trigger the red fury in people, "the CMake experience" does. My point being: Once the red fury is triggered one way or the other, people just talk about what they hate even if it's off-topic or completely unrelated to a talk proposal, for example :). That also happens for a 'Modern CMake' talk. &gt; 99% of programmers just want to set up a static/dynamic/header-only lib project or a binary project, adding dependencies, and get a command to run automatic testing, compile debug/release builds, generate documentation/coverage information, and maybe run some static analysis. It's important to remember that major and minor CMake development is volunteer driven. Many small improvements to it come from the community with each release. Larger topics generally come from a group of about 6 or so developers according to what they need or think is interesting. &gt; Instead compare any of that to the actual way people learn CMake. There are a lot of people with a lot of CMake knowledge in the community and also in this thread. Submit talks to conferences, share what you have learned, and most of all, submit coherent content for the upstream documentation.
Although the author is correct that the language is lacking, there are people who have found ways around the problem as he describes it. For example, Unreal Engine's build system enforces calling of base class virtual functions when they must be called by the base class implementation. Eg. If you don't call `Actor::Tick()` at any point in `MyActor::Tick()`, then an error is generated during compile time. Admittedly though, it would be cool if the language could provide a tool to enforce something like this, rather than relying on a... let's call it, "interesting" build system, in the case of UE.
Thanks ! was good
Why on earth would you think this subreddit is appropriate for this question?
&gt; My point being: Once the red fury is triggered one way or the other, people just talk about what they hate even if it's off-topic or completely unrelated to a talk proposal, for example :). That also happens for a 'Modern CMake' talk. That is sad. Is the snake that bites its tail: "I hate CMake because its documentation is bad but a talk that explains how to use CMake is not interesting".
Because C++?
&gt; For C++ questions, answers, help, and advice see r/cpp_questions or StackOverflow. in the sidebar
&gt; If you don't call Actor::Tick() at any point in MyActor::Tick(), then an error is generated during compile time. interesting, how is that implemented?
The relevance between the two... Are you here to argue or help? there is relevance between the two, but you don't seem like you really care about that, you're just bashing me with your delusions of attempted logic.
Sure, but why? I haven't ever used that for anything other than making a destructor (implementation required) abstract. For destructors, the language enforces the call sequence. For everything else, you're back to the "when do I call it" question. Plus, it is not obvious from a header file which method you can call and which lacks the definition.
The extent of my knowledge is that I believe this is implemented in the "Unreal Build Tool". UBT is basically the UE tool that builds UE projects, and does things like a pre-compilation that compiles UE specific reflection details for UE classes in the project. So I think as some part of the process, perhaps during pre-compilation or other reflection processing, UBT would perform the check. Honestly, I have no idea about any specifics and I'm not sure I want to know lol. Although it generally seems to do a good job, I find the UBT slightly frightening.
The article is complete right. I seem this issue plenty of times. Usually I have seem it solved via naming conventions. But it is far from ideal. It is time to mature the concept farther. 
Not exactly. They call functions ~~from~~of the same class, which are more than likely to get overridden. And as these virtual functions are private: they cannot call the functions they override. In the end, it's the other way around: we call function ~~from~~of child classes, or ~~from~~of the same level (when not overridden). EDIT: fix a _lost in translation_ mistake (that may explain this discussion)
I use them a lot! I would claim that this concept is quite important for class based OOP and fosters good design. As C++ is a very feature rich language, of course you can often strive for templates instead of relying on runtime polymorphism. But that does not make ``pure virtual`` methods or just ``virtual`` methods second class citizens üòâ Imho the article is just false concerning the overall topic. Calling a base class method could make much sense and is completely harmless within properly designed class relationships. The Liskov substitution principal: calling a public method must never violate the contract! If you strive for a LSP compatible design, you will not run into trouble.
good ideas, right direction. 
I edited my post to more explicitly as the question: what happens when the base pure virutal function is explicitly called (as I understood /u/cpp_learner to mean)? What happens when `Derived::foo()` calls `Base::foo` if `Base::foo` is pure virtual?
&gt; And as these virtual functions are private: they cannot call the functions they override All other languages I know of don't allow one to override private virtual functions, so I think the NVI solution is unique to C++. 
... How does _not_ standardizing this feature mean it's more likely to become ubiquitously available more quickly? That makes no sense. &gt; But if these features were some small stand alone preprocessor-like layer Do you realize that this feature is part of the preprocessor, and the preprocessor already is a stand-alone tool? If your platforms' preprocessors don't implement this feature then there's still nothing stopping you from using or writing one that does. And if you don't want to do that then you can still use the usual trick to start using this feature everywhere immediately: #ifndef __has_include #define __has_include(X) 0 #endif With this you can use `__has_include` to detect headers and you'll simply treat compilers that don't support `__has_include` as though they don't have the headers you're checking for.
There's the ABC++ (http://inedo.com/abc). I never saw it, so I can't judge on its quality, but the idea seems exactly what you're looking for.
[you're totally right](https://ideone.com/yu2sgG) and it's a shame you're being downvoted for it
The problem is simply that implementation inheritance requires deep understanding of the implementation you're inheriting. That means it's prone to errors when it's used without that understanding. There's no way around that. All kinds of relationships can exist between classes and member functions in an inheritance hierarchy. The article is talking about just one: overriding methods having some requirement as to when they should call the overridden method. What about all the others? (E.g., just read the documentation for the virtual functions in iostreams.) Do we need ways to encode and check all of them? Is the one relationship that the article discusses that much more important?
you're making your destructor pure virtual? class foo { virtual ~foo() = 0 {}; };
Yup. This means I don't ever want an instance of foo created, even if I don't have another method I could make pure virtual.
In most cases compiler/linker can detect pure calls and give an error. But it's possible to call pure virtual if it's done during base class construction. It's based on that fact that the vftable pointer isn't fully initialized yet at that point. On g++ this gives a segfault: struct Base { Base() { g(); } void g() { foo(); } // Pure virtual call when g() is called from Base(). virtual void foo() = 0; }; struct Derived : public Base { virtual void foo() override { } }; Derived d; Note that without wrapping the call in g() compiler can detect the pure call and give an error. It still might if it's really smart.
I find this... interesting. Requiring `foo()` to be overridden while providing a base implementation could be useful, I think. Off the top of my head, I'm thinking default error behavior that the derived class could call, or default condition/bounds checking. I'll have to ponder this quirk. 
The linker or runtime errors are what I was remembering. I didn't know about being able to provide an implementation of a pure virtual function (defining it). Thanks for the wonderfully detailed example!
&gt; If this feature, and features like it, which don't require full compiler integration, were initially conceived and tested as a tool separate from the compiler, I could be using it right now on compilers from 5 years ago, instead of having to wait 5 years for the systems I support to eventually get this feature. You can use it right now with compilers from five years ago. I don't get why you think you can't, or why you think that specifying this feature as part of the preprocessor stops you from using it. &gt; &gt; If your platforms' preprocessors don't implement this feature then there's still nothing stopping you from using or writing one that does. &gt; If you read the comments you replied to, I have. Okay, so just to be clear, you're saying that on these old platforms with old compilers that don't implement `__has_include` themselves, you have used a tool that implements the `__has_include` feature. Either you wrote that tool yourself or you just took one of the existing tools and built it to run on your old platforms. Do you see the contradiction between saying on the one hand that having `__has_include` as part of the preprocessor prevents you from using it with old compilers, and on the other hand saying that you have actually used it with old compilers? &gt; And besides that, why should I have to write one? If the original spec and tool were written more independently You don't have to write it yourself, just use the ones that have already been written. What's stopping you?
[This paper](http://www.cs.cornell.edu/~srm/publications/EGSR07-btdf.html) provides a good intro to BRDFs and Microfacet Theory. Sadly it is still quite math heavy, but I'm afraid that's unavoidable in computer graphics.
Why is QMutext faster than std::mutex?
&gt; You can use it right now with compilers from five years ago. I can? My bad, I didn't realize there was already an implementation independent of a compiler. Why didn't you say so? Link please? &gt; I don't get why you think that specifying this feature as part of the preprocessor stops you from using it. The specification doesn't directly, but the fact that it will probably only be implemented by compiler authors (as part of the C++17 spec) instead of as an external tool (this is the whole culture of C++ development and language advancement I was talking about before) means I either have to rip it out of the compiler myself or write it a second time, and writing it a second time is easier (but not as easy as it should be - if it was implemented just once, usable by everyone, no matter the C++ compiler or language level they were using). &gt; Do you see the contradiction between saying on the one hand that having __has_include as part of the preprocessor prevents you from using it with old compilers, and on the other hand saying that you have actually used it with old compilers? What I said was, I can't use it with old compilers without reimplementing it. Of course I can use whatever feature I like if I'm willing to implement it myself, but suggesting that is not really an honest and constructive way to have a discussion. &gt; You don't have to write it yourself, just use the ones that have already been written. What's stopping you? A link to such a standalone implementation would be appreciated, if one exists already?
Why is FNV so slow? Is it because it folds in each byte at once?
yeah it's safe. don't use it though -- you'll only confuse the other people who also work on the codebase. also i dont think this will do what you want it to do. you still have to implement the method in your derived class... like, this won't compile: struct bar { virtual void foo() = 0 {} }; struct baz : bar {}; you only get your default behaviour if whoever implements your interface calls the base function in their override. and once you encourage people to start doing that you get all sorts of order-of-execution headaches (like what if they do X before they invoke the default or Y after, how do i prepare against these, etc.).
that's madness! why don't you just make the constructor protected?
Don't worry, it was a pet project of mine (with occasional contribution by a friend). And I forgot the details. IIRC I wanted to have some "kind of static" function that can be called from base instance of the class and return some meaningful default data, while still enforcing all derived class to provide their implementations. Some sort of variation of java default methods I think (I could be wrong, it was about two years ago).
&gt; I can? My bad, I didn't realize there was already an implementation independent of a compiler. Why didn't you say so? Link please? I did say so: "Do you realize that this feature is part of the preprocessor, and the preprocessor already is a stand-alone tool?" [Here's][1] [facebook's][2] stand-alone C preprocessor. Of course there's no rational reason to discount the C preprocessors that are implemented by compiler authors. `cpp` on my system is just a symbolic link to a compiler, but that doesn't mean it doesn't work perfectly well as a stand-alone C preprocessor. There's no need to do something silly like rip the preprocessor out before trying to build it on your platforms. Just build the whole thing and then only use it as a C preprocessor. ‚ëÜ cpp #if !__has_include(&lt;foo&gt;) "I'm a C++ preprocessor!" #endif ^D # 1 "&lt;stdin&gt;" # 1 "&lt;built-in&gt;" 1 # 1 "&lt;built-in&gt;" 3 # 327 "&lt;built-in&gt;" 3 # 1 "&lt;command line&gt;" 1 # 1 "&lt;built-in&gt;" 2 # 1 "&lt;stdin&gt;" 2 "I'm a C++ preprocessor!" ‚ëÜ cpp --version clang version 4.0.0 (http://llvm.org/git/clang.git 0bbca21c016b51d8019d380edf5879bc7827d0f5) (http://llvm.org/git/llvm.git c038ba915ea613b2444dd0419a35c96ac8f68733) Target: x86_64-apple-darwin15.6.0 Thread model: posix [1]: https://github.com/facebookarchive/warp [2]: https://code.facebook.com/posts/476987592402291/under-the-hood-warp-a-fast-c-and-c-preprocessor/
Those are not standalone tools that contain the features we were discussing. Those are complete preprocessor replacements, or worse, a complete second compiler I need to install. How could you seriously suggest that instead of small standalone tools, I should just install a second compiler. I bet clang doesn't even support the platforms I'm discussing, but I bet a small simple has_includes resolving program would.
I suppose you mean "of the base class" rather than "from the base class", which would explain why some commenters are confused. (Same for your other comment below).
Yep, `call_once` is a better model for that.
This'll come quite in handy. Bookmarked!
Probably because of this https://www.reddit.com/r/cpp/comments/4hoyzr/msvc_mutex_is_slower_than_you_might_expect/
As part of full disclosure: I'm the author of sol2, I posted my library here before, and I spent a lot of time assuring people "sol2 is fast". Now I can say that, WITH NUMBERS! :B Some notes on the implementations: - templates are as fast as macros / writing things out by hand, when you want to call functions / member functions / variables using them, which is neat - luwra / oolua are pretty fast due to being macro-based for class and function stuff (the macros resolve to templated things) - slb3 makes me cry and I still don't know why it crashes in half of the benchmarks but its a crap library so I don't really mind in the end, because it's old and I hope it goes away - throwing an exception, catching it, and then returning a boolean based on the catch to indicate success or failure is a BAD IDEA (c.f., "kaguya" in "optional") - it turns out from sending e-mails to a lot of the authors of these libraries that a good handful are actually academic / pet projects not to be taken too terribly seriously... which explains why even some of the more popular ones (high number of github stars, blogpost mentions, etc.) have such questionable performance - if you're the author of one of these other frameworks and I did not do your library justice please go to the lua-bench repo linked at the top of those benchmarks and open an issue yelling at me
Working at bytelevel instead of larger blocks and a lack of vectorization.
Many things are static in many ways. An `auto` variable is arguably static (at one address) for its entire lifetime. When it appears at another address later, it's not really the same variable at all. The same even applies to heap-allocated storage. Everything goes away automatically unless you've failed to properly handle ownership. Sometimes the automation include user (or library) written code, particularly in destructors. For example, an object referenced by a unique_ptr goes away automatically when the unique_ptr does - but that's "dynamic" heap storage. Less of an issue, but I fail to see how the English "dynamic" is more/less appropriate to heap allocation rather than stack allocation - except for the historical convention, of course. Basically, "stack" and "heap" are/were just data structures with different restrictions on usage patterns. The heap is more complex, the stack is managed more directly by the CPU, but they both arguably do automatic/dynamic allocation of memory. Basically, the storage duration terms are not self-explanatory. Explaining things - good. Encouraging people to use the awkward terms that are only used by C++ standard pedants instead of the common terms that are widely used and understood, for better or worse, even outside of C family programming languages - not good. But of course it's a pet-peave based rant - a personal obsession, and I'm still (just) sane enough to know that obsessives really shouldn't be taken too seriously. 
&gt; I'm suggesting that if you don't like a stage of the compiler that your platform provides because it doesn't have some feature you want then you can swap it out with another one. And I'm suggesting that this is not workable in the real world on real platforms that real people support, because I need features that my native compiler's preprocessor provides. I can't implement those features in some new preprocessor that you suggest I just switch over to because some of those features do require tight integration with the compiler. And I can't implement the new features I'd like to use in the system compiler's preprocessor. &gt; you can already swap in a new implementation of it if you really want to I can't though... &gt; What granularity do you want? A single feature per executable? That's just not reasonable. I'd like for features that could exist outside any particular compiler implementation actually do exist outside of any particular compiler implementation. Then it'd be usable in more situations. Whether it's one executable per feature, or some collection of features in a single executable, that's fine. But it should be independent of the existing toolchain. That doesn't seem crazy at all. &gt; When that gets standardized you'll probably complain about features being added to the pre-pre-processor, which takes forever to be implemented on whatever obscure platform you're targeting, and really we need a small, standalone pre-pre-pre-processor in which to implement C++20 features. Please, avoid the strawmen arguments. If there really was such a way to get features independently of the compiler proper (and, therefore, independently of any standardization process), then the features would be immediately useful across all the compilers people use. The most useful features would graduate to standardization, if required, but that would have no bearing on whether I could use them today and not wait 5-10 years. Why would I complain about that? That's exactly what I think should happen...
The title is misleading. This isn't a benchmarking C code vs lua scripts that are interpreted by various libraries. This is a comparison of marshaling data to a variety of lua interpreters. I have no clue why you chose to use the term "plain c", perhaps "lua5.3.3" would have been better.
Hadn't heard of this, looks superb. I'm wondering -- with such a superb speed profile, and being header only and because it's obviously doing all its work at compile time, does it have a similarly impressive object code overhead?
I researched into those, neither convinced me. CppCMS seemed outdated, Treefrog looked limited in what it offered (but it might be that I didn't found a sample app showing up what I needed), and Wt seemed overkill and not very modern, I wasn't going to delve into dealing with the UI in C++, it looked something that a desktop application programmer would like to use, but my background is different.
It would be great if I got pointers into what I did wrong instead of getting downvotes. Or a simple, "yeah, those areas need some improvement".
Although I'm not sure exceptions are completely analogous to panic!, this comment makes things a lot clearer to me. Thanks!
Win32 API. Old-school, but fabulous, omnipotent and perfectly insane-architectured. Everything else is for wimps.
&gt;Many things are static in many ways. An auto variable is arguably static (at one address) for its entire lifetime. Here, you're just trying to give another meaning to the word static, different from that chosen by the standard. I mean, ok, but why?! &gt;Everything goes away automatically unless you've failed to properly handle ownership. Sometimes the automation include user (or library) written code, particularly in destructors. For example, an object referenced by a unique_ptr goes away automatically when the unique_ptr does - but that's "dynamic" heap storage. Here, you are mixing program (and library) logic and standard-speak. I mean, ok, but why?! Note, BTWe, that in C++ (and C), an automatic variable really doesn't have much to do with the CPU stack and all to do with the {} scope where it is declared - it really does not exist past that. &gt;Basically, "stack" and "heap" are/were just data structures with different restrictions on usage patterns. The data structure terms, particularly heap, have not much to do with the same words in language runtime implementation. If anything, that's a reason not to use them in this context. I see that you're ranting, but frankly, it is unfair without offering some alternative, and knowing about storage classes is important.
&gt; Funnily enough people actually do swap out preprocessor implementations in the real world. Only people who either don't use any compiler-specific preprocessor features, or people who have the time and energy (like Facebook) to reimplement everything they use in the new preprocessor. I you define "workable" for the average developer differently from how I do. &gt; [More strawman arguments about "magical portability", "not being in C++17 means it isn't carefully specified", etc] Please, try to have an honest discussion. Nothing I'm suggesting prevents anything you are arguing for. It only increases the flexibility and lets people like me access the features now, instead of 5+ years from now. If you want to keep the culture of C++ development the same, no thank you indeed.
im sitting here thinking 'what the hell? lua is faster than c in some cases?'
The "exceptions for boolean results" thing sounds atrocious. Zero-cost unthrown exceptions of modern compilers go down the drain when that only happens 50% of the time...
I have always assumed heap originated as a punny way of expressing "not the stack". The fact that it also suggests an actual data structure was a non sequitur in this context.
I don't think C++ is usually the right choice for web development.
&gt; This is example of bad developer behavior, but somewhat understandable. In my experience running program committees for C++ conferences, I have noticed a tendency for people to look more critically at talks about build tools. However, for both C++Now and CppCon we are aware of this and we pay special attention to talks about build tools to ensure that we have a balanced program.
Having worked on some microbenchmarks, this looks like a broken benchmarks framework to me: https://github.com/ThePhD/lua-bench/blob/master/lua%20bench/src/plain_c.cpp#L14 meter.measure([&amp;]() { int x = 0; for (int i = 0; i &lt; repetition; ++i) { lua_getglobal(L, "value"); int v = static_cast&lt;int&gt;(lua_tointeger(L, -1)); x += v; lua_pop(L, 1); } return x; }); It is not a good idea IMO, for sound benchmarks, to allow the loop variable to be transparent to the optimizer. You should use something like google benchmark framework to obfuscate the value of the loop variable. And you should not rely on integer additions here to be the side-effect -- depending on how you compiled lua, this could all potentially be inlined, partially inlined, etc. You should use things like `DoNotOptimize` and `ClobberMemory` from google benchmarks API https://github.com/google/benchmark/blob/master/include/benchmark/benchmark_api.h#L220, otherwise afaik the benchmarks are pretty meaningless. I had some experience with microbenchmarks from benching a different collection of libraries. Also there is a nice talk by Chandler Carruth that you might want to watch: https://www.youtube.com/watch?v=nXaxk27zwlk When you are benching something extremely complex like lua, it's going to be pretty hard to examine any generated assembly from your bench framework. It might be possible, I wouldn't rule it out. But if you aren't using established tools, and there's no evidence that you checked generated assembly to see what you are actually benching, I view the results with great suspicion. It's really tricky to benchmark C++, and you can easily get outsmarted by the optimizer. I found it to be quite counter-intuitive and finnicky actually... Edit: I looked now at docs for Nonius, I guess that you are hoping that Nonius will do all that for you? But then why are you iterating and collecting side effects yourself manually?? Shouldn't it be more like meter.measure([&amp;]() { lua_getglobal(L, "value"); int v = static_cast&lt;int&gt;(lua_tointeger(L, -1)); lua_pop(L, 1); return v; }); or something? At the very least? Note that even in this case, I'm not sure it will measure what think you are measuring. But it doesn't make any sense AFAIK to have one set of repetitions inside nonius and one outside.
As I mentioned somewhere else in this thread, Stephen's talk was not rejected because it was about CMake; it actually received some extra attention because it was about CMake. We receive a large number of submissions to CppCon and we cannot accept all the talks we'd like.
Heck, I wrote my own compliant FastCGI library in C++ (and it handled multiplexing, though no httpd seems to).
I guess not, it's not a very complex task though, there should be some good libraries to make it a viable choice.
How does it compare to `std::shared_timed_mutex`? Looks the same to me.
Thought this might be of use to somebody. I also have [a benchmark](https://github.com/emilk/emilib/blob/master/examples/rw_mutex_benchmark.cpp) showing how `ReadWriteMutex` can be up to 100x faster than `std::mutex`when you have many threads reading the same data.
&gt;isn't the OS about die or kill your process anyway? There are platforms that are completely happy to deal with OOM, and don't kill user processes when that occurs.
Now if it only could be named qt::read_write_lock, and be available as part of a synchronization library without the Qt behemoth...
Cool! Any hints or tutorial on how to use the latest version on travis-ci?
&gt; Here, you're just trying to give another meaning to the word static, different from that chosen by the standard. I mean, ok, but why?! The point of the rant was that the original article seemed to me to be complaining about the terms people currently use and encouraging people to use terms from the standard that no-one uses rather than terms like "stack" and "heap". Even if you found perfect terms to advocate, I'd complain because of the pet peave about people trying to control the language and the fact that when different people in different niches all successfully advocate different "better" terms, the result is that no-one knows what anyone outside their niche is talking about. But if you argue that the mention of standards-related terms was just part of the explanation and not intended as dictating what terms people should use generally, you'd instantly win. I realised my comment was out-of-place soon after posting (reading something into the original article which probably isn't really there) but I've been out. I should probably stop here, but... &gt; The data structure terms, particularly heap, have not much to do with the same words in language runtime implementation. What I said about the stack and heap being data structures with different restrictions is 100% accurate. I think you're thinking that within the field of data structures, "stack" has one unambiguous meaning, "heap" has one unambiguous meaning, and these are the meanings you'd learn in a basic algorithms and data structures course. That, I'm afraid, is false. Both terms are ambiguous, even within the field of data structures. A CPU stack is a data structure, with some aspects defined by the CPU, the compiler and/or the ABI it's following etc. Dynamic memory allocation is managed using a data structure which is called a "heap". A CPU stack (with stack frames etc) is at least vaguely related to the stack data structure you learn about in a basic algorithms and data structures course, though of course not really the same thing unless you can somehow believe that varied different-sized stack frames are all heterogenous elements. So it's a different data structure, but still a data structure. C and C++ even have some standard library functions for low-level fiddling with aspects of that data structure, e.g. the `va_arg` etc macros for reading variadic function arguments (from the current functions stack frame within the stack data structure). Of course the standard doesn't describe it in those terms, the point of the standard library is to hide the underlying implementation details, and there are some very weird platforms out there, etc etc. The heap used for dynamic memory allocation is also absolutely a data structure - not a priority queue data structure, "a" data structure in a vague and varied sense (just like the priority-queue meaning) but still a data structure. The priority-queue usage seem to be older, but one theory about why the term gained a second meaning is because an early version of Lisp used a priority-queue-style heap somehow as its dynamic-memory-allocation heap. Certainly the use of "heap" referring to a data structure used for dynamic memory allocation goes back to at least 1971. Of course I didn't know much of that until I found [this StackOverflow question](http://stackoverflow.com/questions/1699057/why-are-two-different-concepts-both-called-heap). 
do thread bears poop in the woods. Cyclic barriers... Countdown latches etc... so many ways to do that. Go has WaitGroups but you can dynamically grow em.
Rad! The new version still has some serious hiccups with uniform initialization, though. :(
This couldn't have come at a better time. I was just working on a lua C library for the first time, and all the stack juggling was quite frustrating. I spent an hour on it when I remembered seeing this on reddit earlier, and voila - I can just throw in some structs that get managed automatically at exactly the same speed as before. It's absolutely amazing. What impressed me the most is that usertype structs can just return other usertype structs, and the system will automatically handle that. I just tried that after being unable to find anything about how to do this in the docs, and it.. just worked. Wonderful job!
You continue to be wrong where you make assertions (my compiler does not support has_includes and it is not 1000x harder to do so externally despite you writing that 4? times). I'm not asking people to do more work. Just different work with more benefits. I suppose I should thank you for proving my point better than I could. The fact that some compilers had this feature in 2009 and mine won't until perhaps 2022 says it all. I thought I'd give you that last chance at an honest discussion, but there's too much hyperbole here to continue. I tried in good faith at least.
Yes!
Hi, I haven't done anything graphic related for 8-7 years, but I could create a distributed photon mapping + realistic image renderer using the book from the link below, I couldn't find a more complete and clearer book about the matter yet. http://www.pbrt.org/ 
I don't think that's possible.
Ancient ones. Modern platforms go through a `mmap` / `VirtualAlloc`-like mechanism. Modern platforms have these fancy "thread" things which mans there's more than one stack. ;)
The people who run QNX pretty much hate developers. They don't seem to realize that being friends with developers is the way to enjoy a long prosperous future. This comes as no surprise as they are basically a blackberry company and blackberry only saw telcos and huge corporations as their customers. The end user was just some tool who was forced to use their product. We all saw how well that worked out. 
This sounds like what [hunter](https://github.com/ruslo/hunter) does. With the use of [ExternalProject](https://cmake.org/cmake/help/v3.6/module/ExternalProject.html) you get the dependencies as subprojects and everything should just compile. All you need is CMake and a C++ compiler.
The biggest thing I've run into is that there's no Linux equivalent of pulses especially delivering timers via pulses. Also if your applications are anywhere near real-time you'll find it Linux is not as responsive as qnx. On the good side qnx send to have pretty good posix compliance.
The second they make any system calls at all, things won't even link, so if it has any calls to malloc or any of those things, it just won't work. You really have to recompile from source.
Looks awesome, I can't wait to give it a try. Do you happen to have a script to set it up in travis-ci? (e.g. I can clone the github repo in travis but it would make my life easier if I can just then execute a script within the repo that just sets it up) &gt; In the last post I‚Äôve complained about libclang and it‚Äôs limitations. Is there a reason why you are not using libtooling instead of libclang? 
There are bools only in Locks and not in mutexes. Locks are only used from one thread so it's safe to use simple boolean for storing information whether Lock is currently locking
&gt; people trying to control the language Well, now... For me, it's about knowing what is talked about by adhering to a common terminology. &gt;I think you're thinking that within the field of data structures, "stack" has one unambiguous meaning, "heap" has one unambiguous meaning, and these are the meanings you'd learn in a basic algorithms and data structures course. That, I'm afraid, is false. Both terms are ambiguous, even within the field of data structures... [citation needed] You follow the above talking *exclusively* about a CPU stack. A CPU stack is not about data structures, you're just trying to shoehorn it in for some weird reason. You seem to think that, by repeating words "data structure" close to "CPU stack", it somehow becomes similar to a tree [data structure], array [data structure], whatever [data structure]. It does not, and the major difference is that code operates on these structures day-in, day-out, using operations on instances of those structures, whereas code does not do that with a CPU stack. Rather, it is the compiler and the language runtime who operate the CPU stack. Look... My conclusion is that you're just purposefully making a mess for whatever reason. Go ahead, I won't listen nor reply anymore.
Love CMake
Nonius uses a do-not-optimize / memory clobber for anything returned from the function, so that's not a concern (which you mentioned in your edit). I did watch the Chandler Carruth talk, and decided to use Nonius instead of Google Benchmark because it's interface was nicer and I did not have to manually engineer (or fail to engineer) a clobber / no-optimize function. I loop a few times to produce stable numbers: not looping at all caused a variance between runs that fluctuated so violently reporting them was absolutely meaningless, not even by demanding 500 samples for each singular benchmark. The actual calls to Lua (Lua 5.3.3, compiled into a DLL) serve as a compile-time barrier here for the optimizer here, meaning that we measure any (possibly inlined) boilerplate the library produces, plus the non-negotiable calls every framework makes to the underlying API. If they do less or more calls, it shows up, and if that prevents some optimizations due to being a DLL call that can't be inlined with Link Time Optimization or other, then that also shows up as well.
Useful information, thank you. The sorts of projects I've got in mind for code-embedding Lua are hardware-embedded (lot's of "embedding" in this sentence); and of course every byte counts there. "It depends" is a good enough answer, as it probably means if one feature is really expensive, it can just be avoided. I'll definitely be checking out sol2 though, thank you for the post and information.
RIP when you can't edit the title anymore. I guess it helps prevent Clickbait but MUH.
I've no experience of QNX, but moving platform-specific code, without extensive rewriting, from one OS to the other, and hacking it to build against a compatibility layer instead of closed-source libraries ... I don't think this will solve your problem of making maintenance easier.
&gt; The actual calls to Lua (Lua 5.3.3, compiled into a DLL) Maybe you should mention that in your report then? A lot of projects, including all the ones that I ever used with lua, actually statically link lua in, which may allow for LTO. I guess I'm more interested in performance in that case. Usually when people bench things they enable as many optimizations as possible -- I guess maybe using lua as a DLL is not that uncommon. But if you have to configure it at all, like `LUA_32BITS` or if you need to fix a size for `LUA_EXTRASPACE` then you probably end up statically linking it. &gt; I loop a few times to produce stable numbers: not looping at all caused a variance between runs that fluctuated so violently reporting them was absolutely meaningless, not even by demanding 500 samples for each singular benchmark. Shouldn't you be able to configure that from within nonius? Like, ask Nonius to do 500 times as many loops or something? &gt; I did watch the Chandler Carruth talk, and decided to use Nonius instead of Google Benchmark because it's interface was nicer and I did not have to manually engineer (or fail to engineer) a clobber / no-optimize function. If you end up with a situation where you are doing `x += v;` to collect side-effects manually from a loop... then you are indeed engineering your own `clobber / no-optimize` function.
So question for /u/steveire/ why is it that the transition of Boost to CMake got stuck in limbo? Is Boost.Build that much better? Or just plain inertia and very hard to port everything?
You introduced the confusion with the beginner algorithms course meanings of stack and heap. I never even mentioned those until you did. You'll note I've already admitted a major error in my rant, even though it was relative to a "rant" that I'd already referred to as a "pet peave" and "obsession" that I'd already hinted wasn't quite sane. How many clues do you need to not take something seriously? But still, I probably read something into the original article that wasn't there and got triggered for no reason, and I already admitted that. Of course just because it was never really meant that seriously from the start, and just because I admitted that I shouldn't have posted in the first place, doesn't mean everything I mentioned is wrong. I just admit I'm wrong when I believe I'm wrong, usually not otherwise. You seem to think I'm the only person who ever refers to the CPU stack and memory allocation heaps as data structures. I already posted a link that proves that wrong (mainly for "heap", but e.g. there's also a reference to the CPU stack being "an actual stack" - though I don't agree it's literally the same thing) and includes a number of citations in various answers/comments, including to classic algorithms and data structures textbooks (Knuth, Cormen et al). That's WRT the ambiguity and the dynamic allocation meaning, not just the beginners data structures course meaning. There's also references to van Wijngaardens work on Algol, the source of my 1971 date - the original documents referenced aren't linked (or even named) admittedly. Even so, through that whole StackOverflow answer, no-one claims that either a CPU Stack or a dynamic allocation heap isn't a data structure. Stuff by/about Burroughs CPU stack (IIRC they're credited with the invention) tends to say "stack mechanism" rather than "stack data structure", but still, you only need to refer to a definition of data structures - they are all variations on "a means of organizing data in storage/memory". Which a CPU stack certainly is. [This from CiteseerX](http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.297.9640&amp;rank=6&amp;q=burroughs%20stack&amp;osm=&amp;ossid=) is an vaguely interesting read about this "stack mechanism", including operations on and invariants associated with that data structure (described in different words). 
It's still an interesting article. I was about to start an unapologetic, border-line rude, bashing process when I dove into the code to see what stupidity was going on in the plain C version. Thankfully it was only the title that was confusing :)
&gt; The problem is every project having to deal with there being dozens or hundreds or however many tools with varying levels of support across all platforms Where do you get these ideas from? There is no massive world-ending problem today with the external tools required, and the community is moving in a good direction with respect to cross-platform build and dependency tooling without standardization backing it up. So I think you are imagining issues where they don't exist. You can't possibly believe that adding more simple tools is going to destroy everything (you seemed to have no problem suggesting switching preprocessors without a second thought, yet even that suggestion flies in the face of your current basis for rejecting the idea that non-core enhancements could start out as standalone tools). &gt; Somehow you think you'd get better support from dozens or hundreds of independently maintained tools Where did I say I'd get better support? I'd love to be in a position where I had the tool at all, even if the support was non-existent. Do you know how many tools aren't well-supported but still very useful? The tools I'm talking about would be simple anyway. They'd be easy enough to get working (probably easier to get one tool working than to integrate this feature into different compilers) and they wouldn't have this giant support requirement that you are imagining up for some reason. And even if they did, the whole entire point of having non-core features released early and often as standalone tools is that if the feature is proven useful, the community will support it, improve it, find its weaknesses, and refine it. And if they don't, you can skip the standardization process alltogether, because no one really wants your feature to begin with. &gt; Without the feature being standardized, you'd never get this feature. So how did I get all the other features that exist and aren't in the standard? Please. &gt; So be thankful that the process has been sped up so that you get it in 2022 instead of never, as would be the likely result we followed your suggestion. What a bunch of nonsense. The plethora of existing tools that have nothing to do with the standard contradicts this statement and pretty much your entire argument. As I said before, this hyperbole and line of discussion is just not contructive. Good day, and good luck.
&gt; Where do you get these ideas from? There is no massive world-ending problem today with the external tools required Right, there's a problem, but it's not a massive, world-ending one. Your suggestion makes the problem worse. That's my whole point. &gt; and the community is moving in a good direction with respect to cross-platform build and dependency tooling without standardization backing it up. By having things like CMake become defacto standards. Your suggestion retards and even reverses the progress already made. Suddenly we'd have to do the same thing with hundreds more tools. &gt; You can't possibly believe that adding more simple tools is going to destroy everything (you seemed to have no problem suggesting switching preprocessors without a second thought, yet even that suggestion flies in the face of your current basis for rejecting the idea that non-core enhancements could start out as standalone tools). That doesn't follow at all. Yes, having every project cobble together their own custom toolchain from hundreds of random tools, from a constantly expanding set of tools which support random subsets of platforms, running them in random orders, would make things worse. Today, with standardized tools, it's somewhat possible to swap out the standardized tools, preprocessor, compiler, assembler, linker, because they're standardized. Sometimes people make use of features only in one implementation or another, but often source actually supports conditional usage of such features so that they work with other standard tools. Not always, but often enough to make using different standardized tools realistic. People have actually done it. &gt; Where did I say I'd get better support? Better support as in it supports your platform, as opposed to not supporting your platform. You're imagining that all these hundreds of tools would target your platform, when you're already complaining about tools not supporting your platform. &gt; The tools I'm talking about would be simple anyway. They'd be easy enough to get working (probably easier to get one tool working than to integrate this feature into different compilers) and they wouldn't have this giant support requirement that you are imagining up for some reason. So you'd be porting these hundreds of tools to your platform manually anyway. Maybe getting any individual one working would be simpler than getting one tools that implements hundreds of features. The problem is you need to get many if not all of these external tools running (i.e., you need to get every single tool used by every project you want to build), so you can't just look at the effort for porting one tool. &gt; And even if they did, the whole entire point of having non-core features released early and often as standalone tools is that if the feature is proven useful, the community will support it, improve it, find its weaknesses, and refine it. And if they don't, you can skip the standardization process alltogether, because no one really wants your feature to begin with. I already pointed out how this is not a benefit over the existing process: we already get non-standardized features implemented early and tested before they get standardized. Remember how I pointed out how a feature that just got standardized in C++17 has been available and in-use since at least 2009? You deflected that with some non-sequitur about how tools never get ported to your platform, but my point remains: external tools provide no benefits in terms of implementing and using features long before being standardized. &gt; So how did I get all the other features that exist and aren't in the standard? Please. Well you're the one complaining about not getting features. Tell me the platform and I'll look into it for you. 
[SIGGRAPH University - Introduction to "Physically Based Shading in Theory and Practice"](https://www.youtube.com/watch?v=j-A0mwsJRmk) (video) is an excellent intro with minimal math. There is a follow-up in the first section of [this video.](https://www.youtube.com/watch?v=zs0oYjwjNEo)
Naming preference has nothing to do with legacy or namespaces.
I am 100% convinced that, if this was a newly developed library, the developers would not choose the prefix naming scheme. It's a remnant from C times when this kind of stuff was sadly necessary. Namespaces offer a much better way of (hierarchically) modularizing, and to signal membership to a library/module. It's not a preference; it's just sane to adhere to the paradigms that the language design strongly advocates.
Ignoring Reddit's url redirector for a second, at least we know where we're going beforehand with this url, unlike those bit.ly, url shorteners etc, that track you around the internet.
"Fancy pointers"?
There's no 1-to-1 mapping in the general case. template&lt;class T&gt; void f(std::remove_reference_t&lt;T&gt;); f(0); // what's T? int, int&amp;, or int&amp;&amp;?
A smart pointer is a pointer that scores highly on standardized tests. A fancy pointer is a pointer that wears a top hat and a monocle. But seriously, allocators can say "when I allocate stuff, you should point to it with this class type that resembles a pointer". If you thought custom allocators were obscure, fancy pointers are a million times more obscure. We've had partial, untested, broken support for fancy pointers for a long time. libc++'s tests have more coverage for fancy pointers, so when I harnessed those tests, that finally prompted us to fix and complete our support.
You are convinced. It's your opinion. There are tons of libraries and languages which employ both namespaces and different naming scheme. You just act as "naming Nazis", as the commenter above put it. Posting stupid irrelevant opinionated comments ignoring the important things. It's a kin to the "big/little endian" debate (about the eggs, not bytes).
Libraries that support GPUs often represent pointers into the GPU's discrete memory space with fancy pointers. See e.g. `thrust::device_ptr`.
&gt; What you're not getting is that that's been a huge struggle that's ongoing. It's way better than the alternative: waiting until someone standardizes something that you can't use on your platform for decades and doesn't meet your needs. &gt; You seem to be comparing this to porting only a single external tool, when as I pointed out the correct comparison would be with porting every external tool. First, porting the tool I'm suggesting is just about trivial. It'll use what, one OS API? stat()? And second, the fair comparison here is porting only the tools I need (not every tool), which is where the effort should be placed - assuming there was a porting effort even needed, the ones interested in using the tool should be doing the work. Under your suggestion, everything has to be ported to a platform before any of it is usable, and the folks doing the porting have to port things they don't care about. &gt; Things were glacial before, then they sped up and now they're moving pretty fast. Correlation, not causation. Things could be moving faster now because there's competition in the space (Rust, Go, etc) or because battery life and energy usage is important again (mobile, embedded IoT) or for any number of other reasons. Also notice that I never said standardization was bad - in fact I believe it to be good - so you are arguing yet again against a strawman. My argument is that tools should be smaller, more flexible, and standalone where possible early on in the process, and become part of the standard later in the process. I'm not arguing that nothing goes into the standard ever (which of course would be a silly position to take). So why do you keep arguing against a point that I'm not making, over and over? In an honest constructive discussion, you would not do that. &gt; But some things should be. I never said otherwise. I'm saying some things should be and some things should not be. You are saying all things should be. &gt; I'm just describing the reality of what would happen if what you suggest were to become widespread practice. It is already wide spread practice. None of that stuff has happened. I don't have to port hundreds or thousands of tools (which is a stupid assertion by the way, that there are or would be that many required by a project), I only have to use the few I need. And they are already ported - why you ask? - well because they were standalone, flexible, and people wanted them to work on these platforms. Win-win-win. &gt; People would develop tools and support just the platforms they care about. That's how it is now. That's how it should be. Only when something becomes useful to everyone should it make it into the standard. And before it makes it into the standard, if it is possible for it to be a small flexible tool that people can use and port and play with, it should be. &gt; The whole thing would be a nightmare. This is how it is today. It's not a nightmare. The FUD is outstanding though. 
There's a great new HTTP + WebSocket library that's out there called Beast (disclaimer: I am the author). Its Boost licensed, header-only, and depends only on Boost. Its being used on production servers operated by Ripple (http://ripple.com). Check out Beast here: https://github.com/vinniefalco/Beast Documentation: http://vinniefalco.github.io/beast/index.html WebSocket bench/test reports: http://vinniefalco.github.io/autobahn/index.html One page HTTP/WebSocket examples: http://vinniefalco.github.io/beast/beast/intro/example.html More Examples: https://github.com/vinniefalco/Beast/tree/master/examples Asynchronous HTTP server: https://github.com/vinniefalco/Beast/blob/master/examples/http_async_server.hpp Beast integration with rippled: https://github.com/ripple/rippled/tree/develop/src/ripple/server/impl It handles sending and receiving HTTP messages (and WebSocket) so you can use it to build a client or server, the APIs are symmetric. One thing I should point out, it doesn't manage the connection for you. So you have to write the bit that creates the listening socket and keeps track of all your active connections. That's fairly easy though, if you know how to use Boost.Asio, and there are plenty of examples on the Web. Beast also comes with an example asynchronous web server that can serve files on your local directory so you could use that as a guide. The author (me) is very responsive to GitHub issues and emails so the support is pretty good. There's a Gitter for live chat as well. I'll be presenting a lightning talk at CppCon 2016 in Bellevue, Washington (September 18-23) and available to answer questions or have discussions on Beast, Boost.Asio, or multithreaded socket server design in general. See you there!
Would the #include directive do what you want?
One thing though. What do you mean about 2 different .cpp files. My main contains the include stuff and the int main() line then all the code to execute in braces below that. 
Qt is LGPL so you can use it with a closed source project as long as you dynamically link you are fine.
Are there any reasonable alternatives?
&gt; The STL now avoids using thread-safe ‚Äúmagic statics‚Äù except when absolutely necessary, improving codegen. What is the issue here? Is this something an efficiency-minded user should endeavor to do as well? (I seem to recall this being asked and answered to some extent previously, but I can't remember where now...)
We need a preprocessed repro + command line. (This is far FAR faster for us to deal with, than "just download and build project X".)
It's related to a compiler inefficiency that was fixed (although the fix didn't get into Update 3). Magic statics implies TLS usage, which while cheap, can be more expensive than just not having the thing be static. For example, calling QueryPerformanceFrequency() is so fast, you may as well just do so directly, instead of attempting to cache the result.
So, you'll have your main.cpp file and a functions.cpp file, or whatever. In you function.h file you do #ifndef functions.h #def functions.h and then at the bottom of that file you do #endif. Then in the functions.cpp file you do a #include functions.h and write the actual implementation of the functions in that file. Then in your main.cpp file you also do #include functions.h. This is how you can include one file in another, you have to tell the compiler to go look for it. 
Here is one of mine. I wrote a custom string class String.h #ifndef HOMEWORK_5_STRING_H #define HOMEWORK_5_STRING_H #include &lt;string&gt; #include &lt;vector&gt; #include &lt;boost/algorithm/string.hpp&gt; using namespace std; namespace homework5 { class String { public: String(); String(const string&amp;); String(const string&amp;, const string&amp;); void SetString(const string&amp;); string GetString() const; String ToLower() const; String ToUpper() const; vector&lt;String&gt; Split(); unsigned int GetLength(); private: string mString; string mDelimiter; const string kDelimiter = " "; void SetDelimiter(string); string GetDelimiter(); }; } #endif String.cpp #include &lt;cmath&gt; #include "String.h" namespace homework5 { String::String() { this-&gt;SetDelimiter(kDelimiter); } String::String(const string &amp; aString) { this-&gt;SetString(aString); this-&gt;SetDelimiter(kDelimiter); } String::String(const string &amp; aString, const string&amp; delimiter) { this-&gt;SetString(aString); this-&gt;SetDelimiter(delimiter); } void String::SetString(const string &amp; aString) { this-&gt;mString = aString; } string String::GetString() const { return this-&gt;mString; } String String::ToLower() const { return boost::to_lower_copy(this-&gt;GetString()); } String String::ToUpper() const { return boost::to_upper_copy(this-&gt;GetString()); } vector&lt;String&gt; String::Split() { vector&lt;string&gt; parts; boost::split(parts, this-&gt;mString, boost::is_any_of(this-&gt;GetDelimiter()), boost::token_compress_on); return vector&lt;String&gt;(parts.begin(), parts.end()); } unsigned int String::GetLength() { return this-&gt;GetString().length(); } void String::SetDelimiter(string delimiter) { this-&gt;mDelimiter = delimiter; } string String::GetDelimiter() { return this-&gt;mDelimiter; } } main.cpp #include &lt;iostream&gt; #include &lt;string&gt; #include &lt;boost/date_time.hpp&gt; #include "String.h" using namespace std; using namespace homework5; int main() { String hello("Hello darkness my old friend I've come to talk to you again", ","); for(auto&amp; w : hello.Split()) { cout &lt;&lt; w.GetString() &lt;&lt; " " &lt;&lt; w.GetLength() &lt;&lt; endl; } return 0; }
So /std:c++14 will be forever broken because people can't specify a simple flag on their build systems? How about EBO? Will it be enabled by the default in the new version, or it'll be forever behind __declspec(empty_bases)?
I've decided to Google "fancy pointers". This was at the top: http://www.cursors-4u.com/ I guess they are *really* obscure if nothing about them is positioned higher than some crappy site with things probably no one uses anymore :D 
&gt; But in 2023, will you care so much? Maybe when the c++23 switch is broken also ;)
Right, I only got that impression because the project was still hosted at sourceforge, using svn and stuff. That and not finding a lot of documentation or posts online gave me the idea it was an inactive project, but I seem to have it wrong.
Yes, if making an MFC application. If not and you are creating a "native" (that is not .net or universal) application, I think not. But one thing you could do is to create an MFC app just for editing the rc file and then bringing in the rc file changes to the non-MFC app.
Dialogs (and the dialog editor) are not specific to MFC; they are a Win32 concept, MFC just makes heavy use.
Did that involve making the constructors of `std::tuple` conditionally `explicit` by chance?
Using /std:c++latest breaks ppl.h (Parallel Patterns Library) due to a single use of `std::auto_ptr`. I can work around it but thought you could pass this on to the PPL maintainer(s).
Awesome! 
/u/Ivan171: What /u/STL said about EBO. But in general, /std:c++14 will forever be "broken" because a large set of developers can't change their build environments. That's a reality: Microsoft is all about backwards compatibility. Supporting enterprises that are entrenched in their ways may be the right decision for the business or it may be the wrong decision. Regardless, it's the reality we operate in. I would *love* to ship a compiler that stays on the bleeding edge of the standard. And I know a ton of you would love to use that compiler. But we also have to take care of the customers who just don't want--for whatever reason--to change anything about their code. 
Just giving you a hard time! No complaints here with all of the improvements. RemindMe! 12 Aug 2023 "/std:c++23"
&gt; It's way better than the alternative: waiting until someone standardizes something that you can't use on your platform for decades and doesn't meet your needs. That hasn't been the only alternative. Many features are available and used long before they're standardized. &gt; First, porting the tool I'm suggesting is just about trivial. You're still talking about porting just one tool. &gt; the fair comparison here is porting only the tools I need (not every tool), which is where the effort should be placed There you go. And don't forget that all the tools you're porting are also software which will be using external tools. So you have to port the entire dependency tree. &gt; Under your suggestion, everything has to be ported to a platform before any of it is usable, and the folks doing the porting have to port things they don't care about. And the benefit is that everything is made available, and you get an integrated tool without the unusable morass of dependencies between hundreds of 'standalone' tools. In the meantime you just write portable code targeting the previous standard. &gt; Also notice that I never said standardization was bad - in fact I believe it to be good - so you are arguing yet again against a strawman. I never said you said standardization was bad. Since I didn't make this argument I guess this is your own strawman. &gt; My argument is that tools should be smaller And massively more numerous, with all the problems that entails. &gt; more flexible Well you've _said_ 'more flexible', though they wouldn't necessarily actually be so. &gt; and standalone With plenty of inter-dependencies, nonetheless. &gt; I'm saying some things should be and some things should not be. You are saying all things should be. I never said that. What was that about "honest, constructive discussion?" &gt; It is already wide spread practice. If what you're advocating is already the widespread practice, then why are you describing it as a change in the culture of C++ development? If what you want is already widespread practice then you should just be satisfied that things are going exactly the way you like. &gt; None of that stuff has happened. I don't have to port hundreds or thousands of tools (which is a stupid assertion by the way, that there are or would be that many required by a project), Well, I said "dozens or hundreds" and that seems a reasonable estimate since you affirmed that a single executable per feature might be the way to go. How many features are there in C++? &gt; I only have to use the few I need. The dozens or hundreds you need, as well as all the tools that every one of those tools need, remember, and so on, recursively. &gt; And they are already ported - why you ask? - well because they were standalone, flexible, and people wanted them to work on these platforms. You'll be the only one doing the porting, while everyone else sticks with their monolithic compilers. &gt; That's how it is now. That's how it should be. Yes, and it's problem, but one that's manageable at current levels, for the most part. Multiply the number of tools by the number of features you want implemented as standalone tools, this problem is hugely magnified, pushing it far beyond 'manageable'. &gt; Only when something becomes useful to everyone should it make it into the standard. Well that's nonsense. There's plenty of stuff that is and should be in C++ but which isn't useful to every C++ developer. There are developers who don't use virtual functions, or exceptions, or dynamic memory allocation. &gt; And before it makes it into the standard, if it is possible for it to be a small flexible tool that people can use and port and play with, it should be. You say "it should be," but you haven't even once actually mentioned the costs. You've only imputed benefits and denied that there are ever or could ever be any problems. A judgement on that basis is no good. &gt; This is how it is today. It's not a nightmare. You should make up your mind: are things today the way you want them to be, or do you want change such that the balance between standalone tools vs. integrated tools shifts in the direction of more standalone tools? If what you want is no change, then fine. If what you want is a change toward more standalone tools, then you can't conclude that just because things aren't a nightmare pre-change, they won't be a nightmare post-change. 
Perhaps look at proxygen. https://github.com/facebook/proxygen Facebook's http libs. They are amazing. I know of a couple of ad tech doing real time bidding on top of those libs. They are BSD licensed Ive used them successfully in a commercial product. Super clean and easy to read code, the docs are bad FYI. 
Hah, I can imagine. 
I am the library that walks like a man.
Just to be clear, are you sure that you need this web service to be embedded and not to be an external services? It's not clear from your post if you are intending this application to be Internet-facing or if this is an internal/local application that's just using a browser for UI purposes. If it is going to be Internet-facing, this is the sort of thing I'd highly recommend layering a bit. An NGINX reverse-proxy over a Python/C#/Java/Node/PHP front-end service that communicates to the back-end process using more traditional means. This isn't even so much about C++ as it is about good Internet application architecture. The layering assists with caching, responsiveness, request queuing, and other necessities to avoid accidental/malicious denial-of-service no matter what language the back-end is written in.
&gt; thus for different `T1`, `Closure&lt;T1&gt;::template Nested` must be a different template Even if limited to class templates, that only holds if `Nested` is a direct member of `Closure` and not a member of say, `ClosureBase`.
Depending on your definition of reasonable, sure. Premake 5 for instance has had a lot of success particularly in the games industry. Some of the complaints I levy at CMake apply to Premake as well, though (and it gets a few of its own certainly). I wish I knew a perfect alternative, because then I could focus all my build energy on just using that instead of fighting CMake nonsense, and I'd probably be way less bitter about build systems. :)
&gt;Function templates in locale code now defend themselves against overloaded comma operators. I'm amazed, that we have a language so complex and powerful, that some parts need to defend themselves against others. Out of curiosity, have you seen reosonable usage of overloaded comma operators^^¬©evil-tm
Just download Qt and its VS plugin, don't use MFC, I promise you'll hate it.
The question is how people who think autotools and boost build are superior to cmake because they ***hate*** the cmake syntax managed to learn C++ in the first place. If you find the answer you will also be able to explain Donald Trump and his supporters. Short answer is that human stupidity is endless.
No, this is not Internet-facing. It stays firmly in the LAN.
Aah, cool! Well, the repos won't have version 1.75, at least not travis's ancient 12.04 and 14.04 distros. That's a bit bad. So it'd still be nice to have some instructions. But I guess the answer is "just build it yourself". Just annoying to add another X minutes to the travis build cycle... :-) Maybe there's a ppa. But that's kind of what I was saying: Would be awesome to have that on the cppcheck homepage, so that you don't have to research all that by yourself. I don't think my use-case is very exotic, on the contrary. But I'm just a bit nitpicking here, cppcheck is a great project, thanks to everyone involved! I've encountered a lot of msi's and installers, even those that presumably have /q or /quiet switches, that in practice do not work on AppVeyor... (quite annoying!). Hopefully this one will work ;)
I just found slides of another talk I did, but had forgotten about: http://www.steveire.com/WhatWhyHowCMake.pdf
Good question! `/std:c++14` was designed to mean **C++14**, just like with GCC or Clang. However, by the time everything was ready to ship, the VC team realized that it had already shipped a [handful of C++17 features](https://blogs.msdn.microsoft.com/vcblog/2016/06/07/standards-version-switches-in-the-compiler/#c++14). So, as /u/STL and /u/AndrewPardoe observed, the VC team had the choice between going with some notion of purity and break customers who had already been using those features, or allow those features in the C++14 mode and say "it is C++14 plus a couple of C++17 things that shipped earlier". The team went with the latter, for practical backward compatibility reason. The discussion in this forum has put an overemphasis on the exceptional stuff, making it sound as something else. You (and everybody else following) should think of `/std:c++14` as meaning C++14, for the most part and forget about the exception -- unless it is your job to overworry about the exceptions :-) Note that in the practical compiler trade, this isn't unusual. For example, I am told that the next version of GCC will have the `if constexpr` feature implemented for C++17, but will also make it available in C++11 and C++14 mode with a "pedantic warning". VC does not have "pedantic warnings" in the compiler, but it appears to have it on its blog posts, hence the discussion here :-)
thanks, interesting read ! too bad for all the salt !
For all practical purposes `/std:c++14` is "C++14 mode" and was designed to mean that. You should use it like that. There is a couple of additional C++17 features, but you shouldn't worry about them. There is no plan to add any C++17 feature to `/std:c++14`.
weird, `/quiet` is a feature of MSI (which is just a package format, like .deb), so I would have thought that it'd always work.
The C++14 switch isn't broken. Not, last time I checked :-)
Regarding your design, I think it would be better to encapsulate all the difference between `Slow*` and `Fast*` inside the `*Mutex` and have only one pair of `*Lock`s (templated). It would be even better if your `*Mutex` classes model [`SharedMutex`](http://en.cppreference.com/w/cpp/concept/SharedMutex) concept of the standard library, so the user can use it as a drop-in replacement of [`std::shared_timed_mutex`](http://en.cppreference.com/w/cpp/thread/shared_timed_mutex) and [`std::shared_mutex`](http://en.cppreference.com/w/cpp/thread/shared_mutex).
Did you benchmark against [`std::shared_mutex`](http://en.cppreference.com/w/cpp/thread/shared_mutex) from C++17 (available in a couple of implementations already)? I think timeout feature is what makes `std::shared_timed_mutex` so slow.
No, you and others explained the situation very well. Thanks.
It might have been an .exe or some other Windows installer. I remember having problems with several well-known formats. Maybe you're right and MSI wasn't one of them.
&gt; Many features are available and used long before they're standardized. And those features are only available in one or two compilers, instead of as separate tools. Which is fine if the feature is so tied to the language that it has to be inside the compiler, but for features which do not have to be so closely tied to the compiler, I think it is bad to artificially do so for no real benefit. &gt; I never said that. You sure are implying it, because I suggested some features that could be available outside the toolchain should be, and you are doing everything in your power to invent ways to argue against it. So which is it? Do you think every feature should be part of a giant compiler toolchain, and nothing independent? Or are you going to keep demanding to have it both ways? &gt; I said "dozens or hundreds" and that seems a reasonable estimate since you affirmed that a single executable per feature might be the way to go. How many features are there in C++? How many features that could be standalone tools? Probably not as many as you keep imagining. &gt; If what you're advocating is already the widespread practice, then why are you describing it as a change in the culture of C++ development? Because not everyone is following the widespread practice - namely those who are putting these small features only into large compiler toolchains and standards, instead of smaller tools that could be more widely used. Have you not been reading this discussion? Do you just respond to each sentence as you read it, instead of understanding the whole? Because that's the only explanation I have for why you keep repeating your arguments, talking us in circles, hammering on strawmen, and not making much progress.
The cppcheck build is fairly fast so shouldn't hold you up for long. But if you wanted it faster you could also build it for the travis-ci infrastructure and host the pre-built binary on a web server. Then as part of your setup just do a wget to pull it down.
/u/jube_dev, /std:c++14 is on by default. Moving the features to /std:c++latest would mean that someone relying on these features would be broken by default.
Maybe. I remember Qt as the major competitor to GUI libraries like wxWidgets, with the added inconvenience that you have to go through a preprocessor. And if I go to the website today, the first thing I read is "The future is written with Qt. A modern user interface that is beautiful on every screen (...)" So, yeah, I wouldn't exclude the possibility that the messaging is off. I might be wrong concerning the monolithic statement. Can I just choose to use (i.e. compile and link to), say, the synchronization part of the library that contains the QReadWriteMutex? If so, then Qt should maybe be marketed as a "lightweight collection of libraries" instead. But I'm not sure that this is the case... Also, I just tried downloading the latest stable version on my Mac, and the thing wants me to go through a whole damn installer, when all I'd want is just a bunch of translation units and header files to use in a project... Is there an option to just "git clone qt" and go from there with CMake?
You can safely ignore most everything else I said, then. :)
Could you add your library to homebrew, it would be easier to install. 
Dialogs are resources and dialog editor is part of resource editor. But compared to c# forms windows dialogs are quite limited and much more difficult to work with. I have to agree, if you want to have C++ GUI Qt is, despite its weight, one of the few options that you won't be pulling your hair over. You can also try giving WTL a go, there are some clones on github. For one of our projects we've been using custom fork of [vaca](https://github.com/dacap/vaca), I liked the overall design and the fact that that compared to Qt or even MFC it is very lightweight, but it required way too much fixing. 
And most importantly when these URL shorteners go tits up articles and information linked to are not lost. Think of all the forum posts that are now mainly useless because an image hosting service goes broke.
I develop primarily on Windows so I am not familiar with homebrew other than, its a system for installing packages (?). If someone wants to take the initiative and add Beast to homebrew, I fully support them! 
This is hearsay but apparently there is one person (the current boost package maintainer or something like that) that hates CMake and "vetoes" every effort on it by saying she/he'd no longer do the job in that case (fair enough, it's her/his free, unpaid time!). But apparently this went so far that not a single CMake-like file was "allowed" in the repo (not sure that's still true today). And there is nobody else that would take over the job, so things are stuck.
You're right, but this problem is specific to template aliases, so I don't think it applies to nested classes.
Are you looking for something like this: http://www.resedit.net/screenshots.htm ?
I think that ship has already sailed for template argument deduction, and it would be no exception in this case either. Alias templates are already completely ignored when it comes to deduction. So, for instance if you have: template&lt;class T1, class T2&gt; S; template&lt;class T1&gt; A = S&lt;T1, void&gt;; template&lt;template &lt;class&gt; class T&gt; void f(T&lt;int&gt;); You'll never get `f(A&lt;int&gt;{})` to deduce `T` = `A`. As soon as you write `A&lt;int&gt;` it becomes `S&lt;int, void&gt;`.
For those who aren't familiar, this is an implementation of the C++11/14 standard library from the LLVM folks: http://libcxx.llvm.org/
You might want to read "Physically Based Rendering" by Pharr, Humphrey and Hanrahan. It's an excellent introduction to a lot of concepts in computer graphics. [The book's website](http://pbrt.org/)
&gt; Dammit, yup, you're right It's an obscure enough point that nobody has ever given me a satisfactory answer when I use it as an interview question. &gt; Are you talking about how libc gets chuncks of memory from the kernel at a time, or something else? Yeah, the C spec doesn't really say anything about how malloc gets memory, just that it can keep track of giving memory to an application. So you could theoretically build a libc that just has a giant static char[MAX_INT] or whatever and have your malloc implementation only use that predetermined static buffer. It'd mostly be a "stupid computer tricks" kind of neat hack, rather than anything useful. But technically you could do it without malloc ever resulting in a syscall that crosses into the kernel. &gt; Also, aren't we presumptuous that it runs on libc at all? Heh, yeah I suppose that's true. When you build a kernel and the like, you typically build without linking to any standard C library, since those libraries typically depend on services from the kernel. So for example the Linux kernel has stuff like its own kernel equivalent of printf. I'm not really familiar enough with QNX to say exactly how the standard C library is implemented over there, or how it would interact with my Linuxy assumptions.
Your post has been automatically removed because it appears to be help/homework related. If this has been in error please message the moderators. *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Yes, this is what I am looking for. Thanks!
Will y'all release a list like this for compiler bugs fixed in VS 2015 update 3?
OSX behaves very similar to Linux in this regard
Sorry to bump in here - what is the status of `std::optional` feature? It seems there is no implementation yet even in `experimental` namespace (despite it being voted into the standard) and I haven't seen it in current list of supported/unsupported features of C++17.
&gt; But technically you could do it without malloc ever resulting in a syscall that crosses into the kernel. What about stack space, doesn't libc have to request stack space at the top of the program, or is it "handed" to libc (or any other program [though how many programs don't depend on some libc anymore]) as part of the startup process? 
Good idea - that seems much better, but I'm still beating GCC6:s `std::shared_mutex` by about a factor 3x-4x *EDIT:* Some numbers (more in benchmark linked earlier): 10 reads per write: std::mutex std::shared_mutex FastReadWriteMutex SlowReadWriteMutex 1 threads: 0.023 0.049 0.016 0.016 Œºs/access (lower is better) 2 threads: 2.935 0.575 0.333 0.336 Œºs/access (lower is better) 4 threads: 3.866 0.817 0.379 0.374 Œºs/access (lower is better) 6 threads: 3.874 1.611 0.380 0.379 Œºs/access (lower is better) 8 threads: 3.956 2.044 0.371 0.372 Œºs/access (lower is better) 10 threads: 3.953 2.238 0.370 0.371 Œºs/access (lower is better) 
It's already in the [VC++ daily build package](https://blogs.msdn.microsoft.com/vcblog/2016/04/26/stay-up-to-date-with-the-visual-c-tools-on-nuget/), so presumably it will be in the next VC++ 2015 update. &amp;nbsp; ^(Unless it's in the daily build by mistake and I've just ruined it for everyone... ;-])
&gt; this problem is specific to template aliases No, this "problem" existed before template aliases were even in the language because of specialization.
```static char[MAX_INT]``` would be allocated on the stack. I was merely curious where libc gets the ~8MB of stack space from without a call to the kernel. 
Will there be some sort of micro-update for Intellisense? I'm testing the ````/std:c++latest```` switch and printing macros such as ````_HAS_AUTO_PTR_ETC```` show different values than what Intellisense reports. Intellisense even claims that ````_MSVC_LANG```` is undefined, but compiling is fine and printing the macro shows it is actually defined and has a value. https://gist.github.com/RElesgoe/5945dc432380ab29d4cc0ece63bc0537
That's platform-dependent. On Windows, a 'section' is added to the PE header telling the OS to reserve (and possibly commit) that amount of address space when the module is loaded.
Depends what you need. If you're only on windows, use the Windows API, it is well documented.
Sorry, I was being specific without mentioning it. So, the "problem" is specific to aliases. If C++ had no type aliasing mechanism, then template argument deduction would always be decidable and unambiguous (though you couldn't do much with metaprogramming then...), am I wrong? Note that my use-case is unrelated to aliases, and the two discussions are orthogonal.
&gt; am I wrong? Yes, because of specialization.
This will only be on Windows. I am leaning towards CryptoAPI since it's pretty much built in
If you think you might ever consider porting to a different platform, use openssl.
Been listening to a few episodes of this recently and liking it. Good work. Not my timezone to catch it live though - have fun!
Why are you signaling condition under a lock?
I don't have experience with clang, but some of the errors cppcheck found that none of the other tools found were bugs like "you're closing this file descriptor in this path, but not in the other one". Other than that I don't recall any of the tools (klocwork, gcc, qa-c++, cppcheck, cl /analyze) being much better or worse in terms of defect detection and false positives.
Good question - I really should be modifying the shared variable (`_num_readers`) under the lock instead. Will fix, thanks!
The `else` branch in `try_lock` should return false, right?
CMake is just an alternative among many. C++ is THE systems programming language if you do not use C. That is why people learn C++ but do not want to learn CMake in many cases. I could explain, without being a supporter, anyway I am spanish, why Donald Trump has supporters. Without agreeing with what he proposes I can see why in some cases. The short story is that he is perceived as a strong individual and noone will tell him what to do, whatever that choice is. :)
Good catch - fixed!
you also get CryptoAPI fixes and updates though windows update, with openssl it's all on you (on windows anyway)
They had some trouble rewriting/porting the plugin to the VS2015, but they've released the beta recently: http://blog.qt.io/blog/2016/08/11/from-visual-studio-add-in-to-qt-vs-tools-beta/
Btw, this is unofficial package and can soon (or already) be replaced by [this one](http://blog.qt.io/blog/2016/08/11/from-visual-studio-add-in-to-qt-vs-tools-beta/)
&gt; Right, because the benefits to having a stable toolchain What stable toolchain? &gt; No, you're just erroneously inferring it There is no other interpretation. You are arguing this hard against an almost trivial external tool. &gt; &gt; How many features that could be standalone tools? &gt; All of them You think all C++ features could be implemented by external tools? Independently? Ok, I'm sorry, I can't keep discussing things with you. Good day, and good luck (a second and final time).
How is `f2` supposed to work? In the closure class, `Nested` isn't a typename, but a template, so it doesn't fit the function.
https://llvm.org/bugs/show_bug.cgi?id=19708 Don't modern compilers do loop unrolling automatically?
excellent writeup. this is information I remember learning in school but it never really stuck until just now.
Your post has been automatically removed because it appears to be help/homework related. If this has been in error please message the moderators. *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Since XP is unsupported and a security risk anyway, it should not be used as an argument anymore. Or should I argue against OpenSSL since it does not compile on an Apple II?
I'm surprised that it's so difficult. libc++ compiles just fine to wasm with binaryen (without multithreading support). I wouldn't mind a preview version for Windows with the same limitations.
Sadly, there are still many systems that use XP or Server 2003 or XP Embedded. But I am surprised OpenSSL does not compile for the Apple ][ ;)
Specialization only makes it more complicated, the problem is what /u/tcanens succintly points out: &gt; There's no 1-to-1 mapping in the general case. Template aliases are not required for this (they just make it shorter to write): template&lt;class T&gt; void f(typename std::remove_reference&lt;T&gt;::type); A couple of things interact to make deduction of `T` an impossibly hard problem to solve: - `typename std::remove_reference&lt;T&gt;::type` can trigger an arbitrary program to run at compile time (which might not terminate). - With template argument deduction you want, for a given program output (a type), find the program input (the type arguments) that produces that output; this is already very hard. - In this particular case, you don't even know the output that you want! You have a program (`std::remove_reference(T) -&gt; U`), and some constraints (`A -&gt; U` where `A = {int, int&amp;, int const&amp;, volatile, ...}`), but you want to find both the input `T` and the output `U`. - Even if you could find all of the possible solutions (which might be infinitely many), you would then need to pick the best one for some definition of best, and then there is still the chance that you get at least two that are equally good resulting in an ambiguity (and requiring the user to specify the types directly to resolve it). The last two points make this both almost impossible to solve, and not worth solving at all. Specialization is just what allows to build meta-programs like `remove_reference` very easily. A different easier example would be: template &lt;typename T&gt; struct A : std::true_type { using std::true_type::true_type; }; template &lt;typename T&gt; void foo(A&lt;T&gt;) {} foo(std::true_type{}); // What's the type of T ? where the problem of determining `T` can be restated as: &gt; Find the best `T` such that `std::true_type` can be converted to `A&lt;T&gt;`. There are infinitely many best `T`s that are equally good, which one do you pick? The only way to make this work is to pin down a single `T`, either through the function arguments: foo(A&lt;int&gt;{}); // this pins down the input so you can find the output or via the return type (with the Concept's TS or some future extension like it): auto foo(A&lt;T&gt; a) { return a; } A&lt;int&gt; a = foo(std::true_type{}); // this pins down the output so you can find the input But this still wouldn't be able to help you in the `f(0)` case, since there for a single input you have many outputs, and for a single output you have many possible inputs. Imagine that you try to pin the `T` in the last example with: A&lt;auto&gt; a = foo(std::true_type{}); Even though you have a constrain on `A&lt;T&gt;`, that still is not enough to pin down a particular `T`.
Interesting. Since you also seem to be targeting Apple platforms, a benchmark comparison with Accelerate.framework would be nice. 
Depends what's meant by &gt; C++ native win32 applications in VS 
&gt; I'm amazed, that we have a language so complex and powerful, that some parts need to defend themselves against others. Amazing, yes. But it also makes it less popular for general usage and ends up being more of a specialized language used by a minority of developers. 
Apparently, KFR is better optimized and has smaller compiled code (better fits into the cache). There are many reasons. Anyway, all code is public, so everyone can check implementation details and compare.
Do let me know how it goes! If something goes wrong I generally fix things really fast.
FFT algorithms, especially highly optimized ones, aren't really trivial codes, so it would take quite some time for anyone not intimately familiar with the algorithm to come to any sort of meaningful answer. And that's not even considering the FFTW folks [couldn't even full answer why it was the fastest back in the day](http://fftw.org/faq/section4.html#whyfast).
I think the idea was that it isn't possible to prevent a commercial project from using gpl code if they comply with the license. So the commercial license of this is only required for closed (or otherwise not gpl compatible) source code regardless of commercial intent.
You can look into [ragel](http://www.colm.net/open-source/ragel/). I've been using it to write lexers and it is quite powerful.
Thanks for the suggestion. I will look into it.
FFTW is basically dual licensed as well, if you don't want your product that uses it to be GPL, you can purchase a commercial license.
But it doesn't dictate if you can use it commercially. The FSF used to sell boxed versions of GCC, for instance.
You might want to take a peek at Boost's Spirit and Xpressive libraries. Additionally, the C++ standard library has regular expressions, if that's sufficient for your needs. Ragel and ANTLR are two other popular tools that might be useful to you. Also, Flex has a command-line parameter that will generate a re-entrant parser.
Yes, that was pretty clear in the text quoted, but just as clear is the misstatement that you can not use the GPL code if your product is commercialized. That's just unenforceable.
[ragel](http://www.colm.net/open-source/ragel/) or [re2c](http://re2c.org).
lexertl sounds tailor made for what you want.
Ah, I see your point. Yeah, I don't see how they can say that unless they are assuming that GPL is unsuitable for every commercial library. I skimmed their [license](https://github.com/kfrlib/kfr/blob/master/LICENSE.txt) and didn't see any specific exclusions, but the thing is 674 lines, and I don't have time nor expertise enough for a more in depth analysis.
What was meant is probably that you can buy out of the viral license with hard cash. Company lawyers don't like GPL. Money solves that problem.
Unfortunately we can't turn off locales as easily and that's what is currently breaking the build. The goal is to work past that and allow it to build w/o threading support.
Sigh. The point is you can not demand that people choose the commercial license for a commercial product. People are free to use the GPL license as long as they comply with its requirements. EVEN IF THEY ARE USING IT IN A COMMERCIAL PRODUCT. Therefore the quoted text above is wrong, you do not "need" to purchase a commercial license simply because you are using KFR in a commercial product as the text states. You only need to purchase a commercial license if you are unable or unwilling to comply with the terms of the GPL license.
Sure but I wouldn't call the analysis excellent, I don't even know if that would work. For example now that I've thought a bit more about it I think that doing this in a reusable way with `for_each` won't work because one cannot break out of it. Probably when somebody tries it, some other issues with this approach will appear :/
Yup.
reply
Low effort troll.
Moderator warning.
I thought FFTW considered things like cache organization when creating a 'plan'.
If I just create an new project, set up something that reproduces it does that work? How would you like it submitted? To be clear, a new project with no dependencies.
mingw is still linking with the Visual C++ 6.0 CRT. It isn't surprising that an 18 year old CRT has bugs.
We are interested in benchmark data if folks are willing to submit it :).
It supports both, at least experimentally. `http_listener` demo: https://gist.github.com/SeanCline/6005128 (not my code)
Hi, I just want to say thanks for reporting this. I was just about to report this on Connect before I saw this Reddit post.
Great! Looking forward to it. And please make it more accessible than the std::experimental::filesystem implementation which is near impossible to build right now. Edit: To clarify it a bit, I would like to see libc++ being distributed as part of the windows installer package.
You might also consider converting your parser into a recursive descent parser. Doing it the first time requires a bit of thinking but the result is nice and clean.
Why is `std::experimental::filesystem` more impossible to build? That's not how it should be. If you're running into build errors I would like to know about them. 
No build errors. I managed to build the library once but it did not install the binary despite these options being set: -DLIBCXX_ENABLE_SHARED=OFF -DLIBCXX_ENABLE_EXPERIMENTAL_LIBRARY=ON -DLIBCXX_INSTALL_EXPERIMENTAL_LIBRARY=ON -DLIBCXX_ENABLE_FILESYSTEM=ON (LLVM/clang/compiler-rt/libcxx from trunk) Edit: What would be the most appropriate place to discuss these problems? A libcxx mailing list?
if you want the features in gcc 5 and 6, then 6.1 is the latest, if you don't, then 4.9.4 is the latest with the gcc 4 features. fairly simple really. If you want to write good c++14/17 and aren't using clang then 6.x is likely what you want
There are multiple active release branches. If there are significant bugs in 4.9.3 then a 4.9.4 release will be made to fix them, even though the current branch is 6.1. Not everyone can use the most recent branch for complicated reasons. If you are one of the people that has to use the 4.9 series, then having that bugfix release really helps, because you can know with relative confidence that upgrading from 4.9.3 to 4.9.4 won't introduce any new features or regressions, only fixes; that cannot be said of upgrading from 4.9.3 to, say, 5.4. 
For quite sometime I was under the impression that if I want C++11 features I have to use GCC 4.8 and up. So when looking for an upgrade from 4.8 to 4.9 I begin seeing versions 5.0, 6.0 and 7.0 !! My reaction was this can't be right, these might be a fork perhaps of GCC? It is all clear now. Thanks.
Yeah, I noticed it was experimental and limited, I was looking for something a little more capable, with support for server authentication and some basic content serving (not that Poco had a lot in that regard, but it had some).
http://semver.org/ is very popular right now. You increase the top number whenever you make breaking changes.
Get Stroustrup's "A Tour of c++" latest edition (for c++11/14 goodies). Thank me later.
That is terrible advice. If you have a class that needs to have virtual member functions (there are other options, which are often better suited to the problems, and researching those is a good exercise especially for Programmers coming from Java), then you probably need to also mark your destructor, though even that is not a absolute rule.
For example, if you use std::make_shared, it will always call the destructor of the object non-virtually, and for the correct class, even if the last pointer to that object before it is freed is a base. If a class is only intended to be used via shared_ptrs, it doesn't need a virtual destructor even if it has other virtual functions. That said, having a virtual destructor can help with user error (and with silencing compiler warnings) and it doesn't really cost much when you already have virtual functions in the class, so it's not really worth breaking the general rule of virtual functions -&gt; virtual destructor.
I wouldn't call it "like mad." The previous versioning system was arguably increasing far too slowly. 4.0.0 was released in 2005. If they hadn't made the change in policy, then 4.10 would have been released in 2015 and 4.11 in 2016. That would have made the 4.x series eleven years old, which is far too much given the amount of changes and added features over that decade-plus. The release policy was already based on a yearly schedule, so this just means we get a new major version every year each spring. 2015 -&gt; 5.x, 2016 -&gt; 6.x, 2017 -&gt; 7.x, and so on. It even happens to conveniently line up with the year number. It's nothing close to the 6 week release cycle of Firefox and Chrome. 
The example code compiles without warnings and even runs and produces the expected result, but it has a fatal flaw (a dangling reference which reads and writes invalid memory). Edit: ITT: People who don't understand C++, and defend it blindly.
It seems that I can copy these words and paste it under any other example code without changing a single letter. That doesn't mean this claim is valid, of course.
Your post has been automatically removed because it appears to be help/homework related. If this has been in error please message the moderators. *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
The map is passed by value not by reference, so the map called "vars" in add_local is destructed at the end of the function. The function returns a reference to the value added to that map, thus it returns a dangling reference.
That, and `value` is bound with `auto`, not `auto&amp;`/`auto&amp;&amp;` ‚Äì double-fail.
That CRT DLL is present *because* mingw stamped that dependency into so many binaries. Not because anything we ship actually uses it.
In this case it binds by reference to a local value, which returns a dangling reference. To clarify, when you do `AUTODECL [x, y] = z();` what you end up with is something like AUTODECL __hidden = z(); auto&amp; x = get&lt;0&gt;(__hidden); auto&amp; y = get&lt;1&gt;(__hidden); If `AUTODECL` is just `auto`, you've got a reference to a local (and we all know what returning a reference to a local is). With `auto [key, value] = *itr;`, you effectively have auto __hidden = *itr; auto&amp; key = get&lt;0&gt;(__hidden); auto&amp; value = get&lt;1&gt;(__hidden); The correct semantics would be to have `auto&amp; __hidden = *itr;` or `auto&amp;&amp; __hidden = *itr;`. As I said.
I'm not sure what you're getting at with z() and all that, that seems to be another situation that's not really related to this. Are you arguing that even if the map was passed by reference it would still be wrong because the variable "value" would be local to add_local? (which you said in your previous comment)
I second that, we need OSX/iOS FFT/iFFT comparison.
It applies no matter what value category `foo()` has. There's a special rule to handle arrays so that this doesn't fall afoul of array 'decay', but otherwise `auto [i, j] = ...;` will do exactly `auto __hidden_object = ...;`, regardless of the value categories involved. This means that `auto` continues to make copies of things, consistent with other parts of the language. For example: auto a = foo(); // make a copy of foo's return value. If foo returns a reference then copy the referenced value for(auto e : container) // e will be a copy of each container element. Modifying e will not modify elements in the container [](auto a){} // the parameter will be passed by value to the lambda.
I've always thought that for most interfaces, you bump the first number when there are API changes. In the case of compilers, I guess this would map to the first version that implements support for a large number of features in a new standard.
&gt; I'm not sure what you're getting at with z() and all that, that seems to be another situation that's not really related to this. It was a symbol-for-symbol analogy to the code in the video; I'm not sure how to make it any clearer. &gt; Are you arguing that even if the map was passed by reference it would still be wrong because the variable "value" would be local to add_local? (which you said in your previous comment) Arguing implies it's subjective; I'm _stating_ it. ;-] [\[dcl.decomp\]¬∂1](http://eel.is/c++draft/dcl.decomp#1) has the wording for non-arrays, there's nothing ambiguous here: any ref-qualifier must be specified explicitly, none is implied.
This tutorial from thenewboston channel is awesome. https://www.youtube.com/watch?v=tvC1WCdV1XU&amp;list=PLAE85DE8440AA6B83
Oh no, a program had a bug! Surely the language cannot be taken seriously.
Whichever source you pick from here, get one based fully on C++11 and onwards. If you're starting a fresh new project, detach yourself from old style C++, as modern C++ (and the standard library that comes with it) lets you write code that's safer, faster, easier to read, write and maintain. I found http://en.cppreference.com/w/ to be actually a great reference for picking up C++11/14 from rusty C++ knowledge.
GCC Has parallel mode but if I remember correctly it wasn't designed for Parallel TS and has been available for a while. If you want to check [link](https://gcc.gnu.org/onlinedocs/libstdc++/manual/parallel_mode.html)
`constexpr if` is more constrained than the initially proposed `static_if`: - restricted to block scopes. - restricted to appear only within templates. - always going to establish a new scope. - required that there exists values of the condition so that either condition branch is well-formed. You can read the proposal there: http://open-std.org/JTC1/SC22/WG21/docs/papers/2016/p0128r1.html 
Does the interpreted language, where you forgot the single character, run that path of code correctly most of the time? And read and write invalid memory? No? Then you clearly didn't understand the problem being discussed. The buggy code in this example is being executed, not skipped over. And it appears to execute fine. And it reads and writes invalid memory while executing. Until your interpreted language example has those same characteristics, it is nowhere near the same thing.
Oh no, someone can't distinguish between different bug severities! Surely the comment cannot be taken seriously.
Basically I implemented a recursive `then` function in C++14 that acts pretty much like JavaScript's `Promise.then` but type safe and so forth. EDIT: And even though it appears complex, all the static inline functions boil down to just a few statements. It's just so much easier than doing it manually every time you want to trigger an action after a future. 
you could also try downloading and modifying the CodePlex Parallel STL project to run on non-Microsoft system this was the basis for the Parallel Algorithms TS. If it uses window or Microsoft dependencies just try to use tbb for some help 
[removed]
If anyone is curious what the other stuff is in `main`, I'm writing a C++14 wrapper around libuv to add thread-safety, type-safety, memory-safety, etc, etc, it's pretty awesome.
What is the `#include "uv++.hpp"`?
Can confirm - I use this library myself and it works wonders.
Yeah, I know. libuv's lack of a lot of things I figured would be common sense has irked me quite a bit. It's so incredibly frustrating that the event-loop isn't thread-safe. I'm sure with my experience with it now I'll end up writing my own event loop implementation in C++17 eventually.
Nice! That will definitely make it more useful.
As an alternative, does anything prevents you from submitting your library as a Boost project? Nice work BTW, I'm using it right now at work and I love it.
Thanks! I guess nothing prevents me from submitting the library to Boost if this can be done without adding extra dependencies (currently the library is self-contained and I'd like to keep it this way). But what is the advantage of doing this?
Thanks!
http://web.stanford.edu/class/cs106l/course_reader.html This is course reader for Stanford's CS106L. Very very good.
My email is on the page you linked. ;-) 
I use it when my program runs too fast.
I know about both of them. And all the other TSs and Boost libraries. It's just that I wanted something right now, and without having to intermix the standard library with Boost too much. Mixing std::future and boost::future is so annoying. I chose to write this wrapper for libuv because I was bored and it annoyed me how limited libuv is in its basic C API form. uv++ is actually rather powerful with what I've written, despite libuv' shortcomings. Plus it gave me an opportunity to do some really neat stuff, like the then implementation that can recursively resolve futures with like no overhead.
For the advantages: It would greatly increase the availability (many organisations have a "no third-party libraries except boost" or similar policy), increase publicity (I didn't know about this library before, probably would if it was part of boost), create an opportunity for peer review by knowledgeable people, and there is a lot of precedent for libraries moving from boost into the standard.
The only thing thing I think should be changed or properly worked around before including it into the standard is this: https://github.com/fmtlib/fmt/issues/235 (it's not solved completely despite it's status). Returning error code as a signed integer is pretty common in c/c++ world, more so, the negative hex numbers could be quite surprising for C/C++ programmer. So there should be built-in way to print any integer in a hex form as it's hex unsigned representation.
Me too - I love it. I would very much like this to be part of the standard. 
Please don't remove the ability to use fmt standalone nor the use of CMake!
I'm 100% behind the idea of getting something _like_ this in the stdlib. We sorely need it. This particular library needs some iteration to put it into good shape for a proposal. Feedback for changes you'd need to make for a proposal: The interfaces must have `error_code` modes for environments that disallow exceptions. `FMT_THROW` indicates that this library hard aborts on errors if exceptions are off and so is not (yet) suitable for the stdlib. `fmt/string.h` and types like `ArgMap` indicate that allocator support has been utterly ignored, and so this library is not (yet) suitable for the stdlib. Other than that, most of what I see is just a need to retrofit to C++17 (e.g., using `string_view`, use the standard `lower_camel_case_convention` for everything except `Template_parameters`), and so on. I also _highly_ recommend that you keep in mind that this library has no possibility of getting in before C++20, so try to target language/library features you expect might land then. e.g., use Concepts in the library proposal, use Ranges where it makes sense, etc. The proposed stdlib component has zero need to support older standards because it will never be retroactively added to older standards, so don't feel constrained by C++17 or current compilers.
Thanks for the feedback. I absolutely agree that this will need several iterations for the standardization. Targeting newer standards will actually make the implementation much simpler because a lot of code is there for compatibility reasons. Regarding allocators, they are supported in [some parts](http://fmtlib.net/latest/api.html#custom-allocators) but not everywhere.
http://www.agner.org/optimize/ And then measure, measure, measure.
Ah, I missed that subtlety, thanks for pointing it out. This makes things much less trivial indeed. Just curious, what's your stance on breaking the fmt API, or adding an alternative one in addition to fmt::print? The variant `fmt::print("Hello {:#x} {}").format(s)` as proposed in the issue wouldn't be too bad IMO, or maybe the somewhat more peculiar `fmt::print("Hello {:#x} {}")(s, 4)` would work. 
So, never?
Not the `constexpr` itself, but wouldn't you essentially need to write a template-based string parser? This is what I think would create huge compile times. Compilers already do checks, but they're specialized and like you aren't running interpreted C++. I love templates in C++, but it's sad that to leverage its full power means the compile times skyrocket. Features like concepts and possibly modules are bound to greatly reduce this overhead though.
Sounds like you still cannot use it for conditional member variables, so we still need to do inheritance tricks just to get conditional member variables, which is really lame.
In what compiler? Perhaps MSVC is just really bad at TMP.
It was a "feature" in older Microsoft compilers. The feature has been removed by default to make the compiler more standards compliant.
Personally I don't find the alternative API particularly appealing but I'd definitely accept it as an alternative to the current API (without breaking it) if someone submitted a PR =).
If I'm reading this correctly they patented the idea of a keyword that consists of multiple words. That's completely absurd, there's a ton of prior art for that. I've personally dealt with a VB6 parser that treated "End If" as a single EndIf keyword. Claiming that it's specifically for adding a new keyword to an existing language isn't really helping. This is not novel to "a person having ordinary skill in the art". How do these kind of patents get across someone's desk?
This functionality is mainly intended to replace `printf` with something safe and extensible. It complements IOStreams and can reuse overloaded `operator&lt;&lt;`. I am not sure if the more specialized functions from fmt even have to be included.
Didn't know `str.format` was controversial =). The only complain that I've heard is that there are too many ways to format something in Python after they added string interpolation.
&gt; I meant by that comment that declaring a formatting function such as fmt::format as constexpr is of limited use because other arguments (not format string) may not be constant. If you are targeting a proposal you should mention this, since there is room to improve the language to allow this. For example, one could allow overloading a function on "constexpr", that is, depending on whether it is executed in a constant expression or not. That would solve your problem and many others. For example, currently, you often have to choose between making something `constexpr` by choosing a slower run-time implementation to allow it being used in constant expressions, and writing a faster implementation that, due to language limitations cannot be constexpr. 
Main advantange: peer review. Lots of people with a lot of C++ experience will take a good look at your library (and documentation), and will give you a lot of constructive feedback about how to improve it. This will make the library better independently of whether it gets accepted or not. Another advantage is that Boost is generally available systemwide in all systems. This will make your library way easier to use (it will just be there), giving you more users. Some of these users might contribute to make the library better for everybody. 
std::error_code is not a global error code. Take a look at the filesystem library recently incorporated into the working paper for examples. For instance: bool create_directory(const path&amp; p); // throws bool create_directory(const path&amp; p, error_code&amp; ec) noexcept;
looks very similar to boost::format Any advantage of yours over that? http://www.boost.org/doc/libs/1_61_0/libs/format/doc/format.html
You make a great point! I'll make note of that in the annotations. As for sizeof(), it's true it's not essential but it is important to understand the fundamental differences between data types and this is one of the clearest ways I've found to illustrate it. I don't claim to know everything but I'm trying my best. Thanks for your insights!
&gt; If you cannot use exceptions, nobody prevents you from using "some other library" that is similar API-wise but uses error codes We're not talking about `fmt`, we're talking about a hypothetical `fmt`-like library to be proposed for the standard library. The same standard library that added `std::error_code` and `std::error_condition` for a reason. &gt; or even encouraging your standard library implementors to offer you an alternative Or encouraging proposal authors to offer us the alternatives standard-blessed interfaces that C++11 and onward are advocating. Like I'm doing. :) &gt; Designing new language features for "C++ dialects" is not going to make achieving consensus any easier. Thankfully, consensus on the _library_ error codes feature we're discussing was achieved 5+ years ago when C++11 was ratified. Consensus on the _library_ feature of a `fmt`-like library is going to be predicated on using the modern standardized idioms for dealing with the unanimously-supported exceptions-disabled dialect. &gt; But a global error code? I think perhaps you're very confused about what [std::error_code and std::error_condition](http://en.cppreference.com/w/cpp/error/error_condition) are.
The key is to have standard support for making it possible to have a UDL for compile-time strings. The author of Boost Hana is working on getting that standardized. Then you add a suffix to the format string and voila. I'll come up with an example later. 
&gt; picoseconds lol. Optimisation in finance is in the order of the hundred of nanoseconds ~ microsecond area. Picoseconds is a completely incorrect order of magnitude for this.
How does your library deal with unsigned chars? The Internet is littered with disappointing posts where the authors realize that they need to cast to make sure the unsigned char is registered as a number rather than a character. For example: http://stackoverflow.com/questions/1674284/boostformat-question
For reference, 100 picoseconds is 10 Ghz. 1 picosecond is 1 THz. The fastest CPU in the Guinness book is currently ~8Ghz, a record set 5 years ago by a team from AMD focusing on achieving the record. In other words, there's not a whole lot of room to move beyond tens of nanoseconds of improvement (if that). *EDIT: Talking about single-threaded improvements. You can exploit multi-threading &amp; SIMD to get beyond that. I guess with super-scalar CPUs you might also be able to get to nanosecond improvements on today's CPUs too, but I imagine it would be very tough; to measure let alone take advantage of the CPU in that way.
Never heard of that one before. Can you confirm that it behaves like the new format specifier checking from 2015? Is there any difference between the two?
It's really cool that you're on here! The C++ community is very approachable and friendly. It makes me wish I had enough skills to contribute...
Visual Studio .NET (2003) was the version that had the "half-open" for scopes by default, as a transitional default mode, and 2005 was the version that turned /Zc:forScope on by default. Pretty sure that this code would fail to compile in VC6 with a duplicate definition error. Not sure about .NET (2002), since everyone seems to have intentionally forgotten that release. There was an amusing but obscure bug in the 2003/2005 compilers such that certain patterns of function template instantiation would cause the compiler to forget that /Zc:forScope had been set. As a result, people could accidentally write code like in the OP even if the project had been explicitly set to build with that flag. It was fixed in VS2008. 
I haven't heard of an alternative to Concepts. It was rejected in its current form and awaits certain major and minor design changes before it could be included in a later standard (see ["Why Concepts didn‚Äôt make C++17"](http://honermann.net/blog/2016/03/06/why-concepts-didnt-make-cxx17/)). One of the major proposals to be considered is ["One Concept Definition Syntax"](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0324r0.html).
&gt; lower_camel_case_convention That's snake_case is it not? and lowerCamelCaseIsLikeThis?
Interesting. My colleague and I were really surprised that this code was checked in, but apparently this behaviour was really common. 
This appears to only work with /analyze in VS2015 update 3; it unfortunately does not seem to be able to trigger the C4473 warning that occurs in normal builds with printf(). This was noted as a limitation when the latter was introduced: https://blogs.msdn.microsoft.com/vcblog/2015/06/22/format-specifiers-checking/ 
&gt; Detraction of libuv The thread is a bit weird. Yes, libuv does not have multi threaded event loop. And if you're building HTTP server that needs to scale, that's definitely a problem. But for other applications that might be perfectly alright. CFRunLoop is single threaded. QT main loop is single threaded. GLib main loop is single threaded. Having single main thread and knowing that callbacks from async IO are going to be delivered on main thread makes things much easier. For many applications IO is never the bottleneck. I'm currently working on application using libuv (with custom c++ wrapper). Libuv is used for I/O and is integrated with platform specific runloops, so all I/O and GUI callbacks are executed on single thread. The overall experience is pretty good.
As far as I know, it stays ahead, since it's not on the Boost release schedule.
Check this snippet on code review http://codereview.stackexchange.com/questions/85031/compile-time-printf-style-format-checking
oh, okay ! I thought that boost's version was "upstream".
Good point about peer review. Regarding the availability, fmt is already available prebuilt on many systems including Debian-based, Fedora/RHEL, OS X with Homebrew and other.
It is similar in spirit, but the API, syntax, and implementation are quite different. The main difference is that fmt uses function call API similar to printf's instead of overloaded operators. Also fmt's performance is much better both in terms of speed and compiled code size.
Multithread / SIMD improves throughput, not latency.
We worked around this by having `#define for if(1) for` in a VC++6 code base I worked on in the early 00s... bad times...
I didn't statically link it, no. If you are working with something that needed to be tied to the libstdc++ on your machine vs. amazon's I guess you'd need to do that. You could also build it on Amazon Linux instead.
[Generalizing Overloading for C++2000, Bjarne Stroustrup, PDF](http://www.stroustrup.com/whitespace98.pdf) - linked from Stroustrups [publications](http://stroustrup.com/papers.html) page. There's also a reference to "B. Stavtrup: Overloading of C++ Whitespace. Journal of Object-Oriented Programming. April 1, 1992.", but no link. 
Yeah, that's my thought. I don't care if the event loop itself is single-threaded. That's perfectly fine for many things. Although running multiple event loops in multiple threads would be neat, it's not something the average application needs. What I've been more concerned about is *thread-safety*, which is much more important. libuv doesn't allow you to interact with the loop from anything other than the thread the loop is running on. It doesn't attempt to make any operations mutually exclusive or atomic. What uv++ (my library) is trying to do is exactly that. It might be a tiny bit slower from other threads, but it makes efforts to synchronize the loop state between threads so you can queue up whatever you want without having to worry about deadlocks and/or races. Plus I've put a lot of effort into managing memory allocation in uv++, trying to iron out as much undefined behavior from libuv as possible, so you can basically do anything so long as what you're working with is "alive" (not deallocated). And if you try to work on something that is not alive, it'll throw a well-defined exception instead of segfaulting or double-freeing.
It's a decent editor but needs better vim mode support: https://visualstudio.uservoice.com/forums/293070-visual-studio-code/suggestions/7752447-vim-style-keybindings
IIRC you need to install a C++ plugin or something like that.
IMHO this is off topic here. There are cases where C/C++ have enough common ground that an article about C can be useful for C++ programmers. Particularly things with optimization. But I've already seen on quite a few occasions, discussions on unions and reinterpret_cast where it emerged that there were substantial differences between UB in C and C++. So I think this article is really just misleading for anyone compiling with a C++ compiler; it's probably 80 or even 95% correct and applicable, but it's not clear where the discrepancies are. So you may as well just read a comparable article for C++.
&gt;and which before C++11 was static and not thread local errno was always* thread local *always, as in, before C or C++ standards became thread aware **on sane platforms, at least
Pretty impressive how corporations can encourage smart people to waste their time.
Yeah, I noticed you use boost lockfree for that. I just used single linked list with std::atomic pointer head. That's enough to schedule tasks from other threads without having to lock anything. As for the allocations, all my wrappers are intrusively reference counted. I'm not a huge fan of shared_ptr.
The latter ;)
The newest release adds/changes * new constexpr operators &lt;, &gt;, &lt;=, &gt;= * new functions zip_fold_and, zip_fold_or * performance improvements for operator== and rotate functions * bug fixes
Of the information presented, do you have any specifics about what may be incorrect/misleading? Much - or all - of this applied to a C++ compiler I used ~3 years ago. It was GCC based and we hit plenty of bugs related to type pruning and aliasing. Most of what I see in this article directly covers those issues. A C++ specific one isn't a bad suggestion but this looks like it covers cases people may still hit today in C++. I'm curious what specifics have changed in most recent compiler/language versions.
Almost everything in that article is specific to C and either does not exist in C++ at all (effective type) or is substantially different (aliasing and type punning). It's also not quite right about C's strict aliasing rules: character types are not the only exception.
Just want to say I love `fmtlib` (or as it's still used in my environment, `cppformat`) and I would love to see such functionality as an integral part of the standard library.
I see no mention of utf8 here...utf16le can be very frustrating..
Wait, I never knew Boost.Format had a bad rep. Is it actually bad? I saw it being recommended by a guy on StackOverflow, so I though it was okay to use it.
Please don't write nonsense headlines like this
Fair enough. When I wrote the above comment, I was thinking purely in term of instructions, not at a higher level.
Changing the encoding used for strings is entirely unrelated to making the framework more modular, so I don't know why you'd expect to see any mention of that here.
summoning /u/pfultz2
Once upon a time, Qt was a simple GUI library. Now it is like an operating system's developer kit, it includes everything and the kitchen sink. I just want a simple, clean and effective c++ gui library. Can I please have that? It doesn't exist...
You can only do small subset of forward_list functionality atomically so using atomic pointer in it wouldn't do much good. But it's enough to prepend callbacks and then switch list to empty on main thread when you want to fire the callbacks (don't forget to reorder them :) As for libuv callbacks, I don't think it will call any once you close the handle, except for close callback that is.
True, but since my uv++ Handle base class is separate from libuv handle types (uv_idle_t, uv_*_t, etc), they needed to be allocated separately so in the case that a uv++ Handle dies outside of the main thread, the libuv handle pointer will live long enough for it to be closed on the loop-thread. And that needed a bit more lifetime management for the user data and continuations, which the callback might actually want a reference to the originating Handle and could be called in the time between the Handle dying and uv_close being called on the loop thread, so the callback could be invoked without the Handle existing, which is weird. A good example is the Idle handle, which is run constantly in the event loop. There is a good chance it will be called after the Handle close stuff has been queued up, and if it needs a reference to the original uv++ Idle handle, I needed to account for that. So yeah, basically having to deal with multiple objects that may or may not be deleted and making sure it works in any order is a headache. That's why I've mostly settled on using weak\_ptr for references that are allowed to die. Perhaps not the best, and I may optimize it for hot functions (like the Idle one), but at least it won't segfault when the developer does something weird in multiple threads.
Maybe this is what you are looking for: http://nanapro.org
That Qt is divided into modules doesn't invalidate what I said.
Thanks for the link, I'll study it, it seems interesting. Edit: not clean enough in my book. Things noticed [right off the bat](http://nanapro.org/en-us/blog/2016/05/an-introduction-to-nana-c-library/): * lower case identifiers. I want my identifiers like class names and such to easily stick out. I don't like classes with all lowercase names. * classes don't prefix their setters and getters with 'set' and 'get', making it difficult to simply select the appropriate function from an intellicence popup. * layout is done via some form of html. Not good in my book, for various reasons. * a component is inserted to another one via a constructor call, but a label is inserted to a layout via operator &lt;&lt;, in the above example. * layouts are not components. So I have to keep two mental models in my head, regarding the gui's layout: one for components and one for layouts. * what does the 'layout::collocate()' method do? if I can't tell what a method does easily, then it probably is the wrong abstraction. * why does a form need a 'show()' method? just show it on exec(). * where is memory management? the examples allocate the components on the stack. Now, let's see some more examples... edit2: adding items to menus is done via ...text. Menu items are not objects!!! I don't think nana passes my quality test. I don't think I'll be using it anytime soon (unfortunately). Thanks for the link anyway. 
What? it's not an april fool's joke???? color me impressed.
&gt; Furthermore, containers is something Qt shouldn't have done. I accept strings, since it's tied to the gui, but not containers, and certainly not the moc, networking, threading, xml, and the lot. moc talks is a demagogy too: moc is a foundation for the selling feature - signals/slots. moc doesn't affect your workflow if you add that one 'automoc' line in the CMakeLists. Don't like networking or xml - don't use that module. Networking and threading came from the need to support multiple OS, so shame is on the state of C++ library (C++ networking, still !!!) and on 'POSIX-compliancy' of certain OSes. Btw, containers - same reason, but it's ok now, because I don't remember being forced to use them.
&gt; No, it's not. Signals/slots can easily be done without moc. Uh... no. Especially considering that moc allows to reflect on them (see http://doc.qt.io/qt-5/qmetaobject.html ). Maybe in C++20 moc won't be needed anymore but until then it's either moc or [uglier macros](https://woboq.com/blog/verdigris-qt-without-moc.html) if you don't want to run an external preprocessor... 
Only because "it's what c and c++ library code used from the beginning".
There are now (v0.2-1 onwards) pre-built binaries available for Travis CI and Windows. For Travis you just need to install Boost 1.55 and a recent libstdc++, then there is a script to automatically fetch libclang and the standardese binary, details can be found in the readme.
&gt; No, it's not. Signals/slots can easily be done without moc. Ok, where is Qt and where is GTK now (the one without moc)? Btw, the next-gen Qt GUI needed some kind of C++ reflection for bindings, so moc worked out for that too. &gt; requires me to be aware of it, first of all, then it adds pseudo-keywords to the language, which is a crime against humanity No proper reflection in the language. So, perfectly reasonable decision. Other compiler-specific reflections/property-systems of the time haven't survived, but the Qt system did. Because it's simple, portable and useful. &gt; No, networking and threading came from the need to sell support for networking and threading. It has nothing to do with multiple OSes. Also, networking came with the HTTP. And threading came with the GUI, because it's a key to the GUI responsiveness (they just made threading API public). &gt; No, a language shouldn't have to provide everything in its standard library. Yes, and nobody who does GUI is allowed to provide any library except the GUI. And web-server people are allowed to contribute network libs, but not threading. And 3D engine guys are not allowed to publish GUI... &gt; Nope. There was nothing majorly wrong with std containers (except for the lack of an unordered map/set, which was later fixed), and this has nothing to do with GUI. I've heard that compilers and their stdlibs were garbage at the time. &gt; software is not built by lone wolves. You seem to not understand that. Yes, it's hard to understand what do you mean by things like 'lone wolves' and 'kitchen sinks'. Be more concrete. If the 'no lone wolves' means 'other people on the team always do stupid things', then there are other libraries for that: PTlib and Poco. These are just evil - always trying to swallow your whole project.
&gt; So why should Qt include it and not provide said functionality as another library? Yea of course. But they fairly modularized it... And are trying to improve on that. Nobody can get everything right at the first time. It is how it is. &gt; I don't see why networking and threading should be in the standard. &gt; The problem is more like there isn't a standard library repository for c++ than anything else. Totally agree, that is a problem. But still the "basics" should be in the standard library, for the sole purpose that it is available out of the box, without getting anything from any repository. Look at other major languages, Java, C#, you install the JDK and you have networking, threading, and much more. No need for getting something from a repository. This makes developing _and_ deploying software so much easier. (No, in general I'm not a Java fan at all!)
It's a question to your OS, not to the library.
&gt; Um ...yes. The only reason reflection was required on this was because it was the easy way out for building a GUI editor. Um... no. Reflection is hugely useful in Qt. For instance you can declare methods / callbacks in C++ and directly access them from javascript with QML afterwards, without the slightiest hint of boilerplate.
&gt; A gui library should be just that, a gui library. And Qt5Gui is just that, a gui library. Qt is an application framework. 
Not if you mark something with `no_serialize`. If I parse with libclang I do the rules of what gets serialized and what not. I don't see the problem
While I would very much like a standard library for GUIs and networking, I am glad C++ does not have one, yet. With the recent switch to various TS groups where new standard library component are developed independently of the core language, I am very much looking forward to what they produce. I am also very glad to have multiple compilers and standard libraries to detect deficiencies, either in my code or the implementation of the standard libraries. Something you will not get with many other languages which are made up from The Compiler and The Library. Also, do not forget, once you add a feature to the standard library it will be very hard to get rid of it if down the road it turns out to have been badly specified or had unintended consequences. The conservative approach C++ uses is much appreciated by me, but the way they now leverage TS groups makes for a good compromise between speed of adoption of new standard library features and the stability of the standard.
You might want to take a look at [clReflect](https://github.com/Celtoys/clReflect) which [does what you want](https://bitbucket.org/dwilliamson/clreflect/wiki/Marking%20Primitives%20for%20Reflection) using Clang.
Unless it serializes ANY object without additional coding (which no one expects it will), I doubt it will be useful. Existing solutions at least provide flexibility.
&gt; So why should Qt include it and not provide said functionality as another library? This does not make sense. Qt already provides networking as another library (libQt5Network). If this isn't modular enough, you can even disable specific classes from Qt when building it : http://doc.qt.io/qt-4.8/fine-tuning-features.html 
 struct node { node *p1; node *p2; } Is that a doubly linked list, a binary tree, or a binary directed acyclic graph (DAG)? If it's a DAG, how are you avoiding serializing out two copies of any given node? 
Accelerators seems to be the broader term that also includes other shortcuts like CTRL+ESC or shortcuts with shift. I meant specifically the ones with ALT+Letter. But yea, that's probably it!
Definitely agree. And, having multiple compilers and standard library _implementations_ is in my opinion an orthogonal concept and has nothing to do with how much and what is or is not in the standard. In terms of _implementations_, competition is indeed good!
Thanks a lot for the link! I will check it out.
Evangelism is a long journey. Java or C# have marketing, school formation... So every developper who agree c++ is the answer should raise c++ alternative as often as possible. Nobody would take the risk on a one guy, one time opinion to move something to another technology. 
Even if that's the case (which is not, I don't believe there was a std container problem that was blocking Trolltech from using std containers in its library), after 98 they should have dropped their container library.
It's not about me liking it or not, it's about making the code more readable. So it's a technical point after all. 
Love the editor itself, but last time I tried c++ indexing it was rather disappointing. 
Are you aware of any c++ compiler not supporting type puning? It's quite commonly [used](https://github.com/WebKit/webkit/blob/808e5ac12f787b3ca99056803e40df42554030db/Source/WTF/wtf/StdLibExtras.h#L136) so I'm really curious is anyone is actually shipping compiler not supporting this.
Yes but not naked pointers
I mostly only use clang and it supports it, but this won't necessarily hold in the future. `std::variant` got accepted into C++17, is implemented as a recursive union, and since it is a vocabulary type compilers might want to optimize it heavily (which might include optimizations that exploit undefined behavior). Clang might start warning about type punning using unions soon (at least for the cases that can be detected within a single TU). Note also that type punning using `std::memcpy` is not UB, only type punning using access to an inactive union member is. That particular webkit function could have been writen safely using `std::memcpy` without invoking undefined behavior: template &lt;typename ToType, typename FromType&gt; inline ToType bitwise_cast(FromType const&amp; from) { // no need for UB (or big cojones) static_assert(sizeof(ToType) == sizeof(FromType)); ToType to; std::memcpy(&amp;to, &amp;from, sizeof(ToType)); return to; } If type punning using `std::memcpy` generates worse code than the one using unions they should file a compiler bug. 
Yeah, I meant type punning through union (I also linked example in webkit's WTF). I don't have issues replacing it with memcpy if there are any practical problems with it, it's just that for now I don't see any.
There are some studies actually that give snake_case a slight advantage with regards to readability. But both are equally readable - it's personal preference.
These things are not black and white. I would just use the non UB version and if it ever shows up as a bottleneck somewhere I would then worry about it. But I can understand why a lot of projects choose the union versions that work today without problems on all compilers. If the code is performance critical replacing it with the non-UB version might be tricky, since it might generate different code and be slower (or faster, who knows without benchmarking).
They didn't have a cool of a CI system back them as they do now. It's not that big of a deal to make sure that the feature dependencies are correct. You don't need to test all combinations.
Pretty awesome. Is it possible to run that locally? Can you add CTRL+Enter to "Submit" code on the page? Kinda cumbersome to click with the mouse each time :-)
Shift + Enter will submit the code. Issue to make this clearer here: https://tree.taiga.io/project/njlr-jyt-fiddle/issue/4
Why do Qt-related posts always bring up some lengthy, off-topic discussion about the framework? I mean, we GET it: you think Qt is a bloated, highly-coupled piece of trash. Why don't you just downvote the post and move on to whatever you think is better?
They don't serialize raw pointers because they don't convey any ownership semantics. Attempting to deduce that is also a non-trivial problem that would complicate their library significantly. So you can either: * Use std smart pointers. * Construct your own smart pointer for the given context and write a custom serialization function. * Use their BinaryData wrapper if you're dealing with a blob of memory. * Use a handle-based system over pointers. This is more applicable if you're working in a game development environment and need a solution for referential integrity.
Currently it is just the standard library. We plan to integrate projects that are well structured (e.g. https://www.conan.io/ packages) in the future. Once we release the offline version you will be able to link any library. Register for the beta here: http://jyt.us13.list-manage.com/subscribe/post?u=a3756f5e475cb6820f59c0201&amp;id=4fb2c54383
&gt; We plan to integrate projects that are well structured Does this mean boost?
It's probably slower than everything. There are [some benchmarks](https://github.com/fmtlib/fmt#benchmarks) in `fmt`'s documentation, it's not pretty. Boost.Format uses iostreams internally, so whatever it does will always be slower. From a cursory look at `fmt`, it seems to be mostly using the `printf` family internally.
Did just that and got a lot of helpful information and advice. Started writing a paper =).
Can we integrate headers into it? Or would we have to paste them at the top?
fmt implements its own formatting except for floating-point where it uses `s(n)printf`.
Interesting. Compile-time checks is a big project though so I'll probably leave it until after submitting the paper with the current proposal.
It will work in simple cases, but imagine doing something like date/time formatting with it. It will quickly become unmanageable, even C++ I/O streams fell back to using a mini-language in `put_time`. BTW your example can work in fmt if you define `hex`, `oct`, and `bin` appropriately.
It is one of the options. Another is to implement a custom formatting function (which I still need to document).
I Agree, the compactness of the URL is nice. Our product is a bit different though since you can interact with the code in the REPL. 
Awesome thanks!
I forsee QT going down the same path as Boost, that is eventually many of it will be part of the standard. Might take C++25 or greater for that to happen thou 
Oh of course. It's up to you whether this is worth working on. If you're lucky, someone else might want the feature enough to add it, in which case there's at least a starting point. 
Btw, if I understood correctly, you can only "unpack" everything by copy (`auto [a, b, c]`), by reference (`auto&amp; [a, b, c]`) and maybe fancy universal ref &amp;&amp; (not sure about this one). But why it was made so? Isn't it a little limited? In the example you want to change only one element, but you acquire reference to all elements. Wouldn't syntax such as `auto [&amp;a, &amp;&amp;b, const c]` which would translate into `auto &amp;a = ...`, `auto&amp;&amp; b = ...` and so on) be more powerful and useful?
I can see from the blog post that you can "unpack" a struct into a structured binding? That mean that you can actually make a list of members of a struct? If yes then you can just take an arbitrary struct, extract it's member and put them all in a tuple to get free hash, equal comparison and generated hash function? Seems like compile time reflection for struct to me!
In most jobs I think that would be true but I can imagine game dev and a few other specialized fields where you create your own internal formats to mirror your objects. When you throw out ideas like human readability and cross platform readability then pure memory serialization also starts to sound like a performance improvement. 
Is there a way to cycle previous terminal entries? Like up/down arrow in bash/cmd.
&gt; Included in this is capturing by r-value reference (`auto &amp;&amp;`). This is capturing as a [_forwarding reference_](http://en.cppreference.com/w/cpp/language/template_argument_deduction), not an rvalue reference (i.e. it will bind to lvalues as lvalue references).
You are correct, apologies
The proposal explicitly says this is not proposed. I'm not sure what the final wording will be though. That said, attempting to do this with clang-4.0 yields an error #include &lt;iostream&gt; struct Foo { int i; char c; double d; }; int main() { Foo f { 1, 'a', 2.3 }; // unpack the struct into individual variables declared at the call site auto&amp; [ i, std::ignore, d ] = f; std::cout &lt;&lt; "i=" &lt;&lt; i &lt;&lt; " d=" &lt;&lt; d &lt;&lt; '\n'; return 0; } &gt; main.cpp:15:19: error: expected ',' or ']' in lambda capture list &gt; auto&amp; [ i, std::ignore, d ] = f; &gt; ^ &gt; main.cpp:15:11: error: type 'Foo' decomposes into 3 elements, but 4 names were provided &gt; auto&amp; [ i, std::ignore, d ] = f; &gt; ^ &gt; 
http://milianw.de/blog/heaptrack-a-heap-memory-profiler-for-linux
Unfortunately, both of those links are not what I am looking for. The paper I am looking for is standalone, and though it accomplishes much of what the Concepts TS seeks to fulfill, it did not use any features of the Concepts TS.
The problem is that you need to know the number of members in the struct in order to use the binding, meaning you can't write a generic struct unpacker. AFAICT, you can't do this in a SFINAE context to try 1,2,3,... members.
valgrind is the defacto memory leak detector on Linux. You should just be able to run your app under it with no additional arguments and find the leak. If you don't have luck with that you can add additional arguments which will make it run a lot slower, but track a lot more. Eg: `valgrind --leak-check=full --track-origins=yes myapp`
The vim plugin has improved immensely over the last few months. It was effectively unusable when initially released but isn't too bad now.
Indeed... and I don't think you can use structured binding with parameter pack either... But if someone find a way to know the number of member in a struct, it would be possible
This belongs to /r/cpp_questions 
If we could, we'd [never](https://github.com/apolukhin/magic_get/blob/develop/include/boost/pfr/core17_generated.hpp) need to use this new syntax ever again.
How does `tuple_size_v&lt;T&gt;` work? Wouldn't the type still have to specialize it? Edit: Never mind, I'm dumb. I've even seen this technique used before in Boost.DI. The count can be obtained by a successful aggregate initialization. This actually can be tried over and over with SFINAE. I had thought about decomposition with SFINAE when all I needed was the count.
Does not work with clang (4.0.0-r277442) on windows Assertion failed: !isNull() &amp;&amp; "Cannot retrieve a NULL type pointer", file D:\src\llvm_package_277442\llvm\tools\clang\include\clang/AST/Type.h, line 612 when compiling first example. UPD: clang compiled from trunk works. 
Hmm. Try compiling with something like `-ftemplate-depth=5000000` maybe and see if it helps.
Tried it, didn't work, see my edit. The depth shouldn't ever go that deep ever, as it converges fairly fast.
I edited my post with more info: Command line args: g++ got.cpp -O3 -o got Even using ```-ftemplate-depth=5000000 -fconstexpr-depth=500000``` still results in the error. The recursion should only go down to around level 300 even when calling it with ```got&lt;100'000'000'000'000'000&gt;::values```
&gt; I was concerned due to C# being an interpreted(even as bytecode) language and it potentially being a huge performance hit C# is generally fully Just-In-Time compiled, and the modern tools offer the ability to fully compile Ahead-Of-Time for your target architecture as well. &gt; it appears that through the use of static and dynamic libraries, C# programs can implement C/C++. Now obviously by including bits of C/C++ in a C# program, your program will not be as portable as a pure C# program, but it's still very interesting. By "implement" I think you mean that C# can consume C/C++ code. There are a few ways to do this, but a common one is [P/Invoke](https://en.wikipedia.org/wiki/Platform_Invocation_Services). Compile your native code into a DLL and give it clean (i.e. C-like) public interface and consuming it from C# is quite easy. There's also language extensions like C++/CLI and C++/WinRT that make it easy to interface C# and C++. &gt; So my question: how common is it to use C# as a framework for C++ programs Depending on what you mean, yes. Microsoft has gone out of its way to enable this use case. A number of game studios write C# tool sets around their C++ engine core, for instance. The very popular Unity3D engine also has a C++ chocolate center wrapped in a C# candy shell.
Yep. I just tested it. On my end it doesn't seem to want to compile for any got&lt;N&gt;::values greater than 120.
The trick in this particular case is to think of it in terms of the nth element, the n-1th element, the n-2th element, etc, etc. If you can see how the templates create all the n and n-x elements, then you understand template recursion
&gt; Where did I not do it, they all have initalizers. Your _declarations_ have initializers; this does not obviate the need for _definitions_. Adding a definition for the base template makes it link on gcc: // use decltype instead of auto in the declaration constexpr static const decltype(_next_struct::values) values = _next_struct::values; // ... // out-of-class definition template &lt;size_t v, class T, int64_t... vals&gt; constexpr const decltype(got&lt;v, T, vals...&gt;::_next_struct::values) got&lt;v, T, vals...&gt;::values; [Online demo](http://coliru.stacked-crooked.com/a/48aaa5d3c88e9bd2)
&gt; Constexpr-ness, or the presence of an initializer, does not change the general rules for static member data, you still need a definition, but you only provided declarations. Dammit, you're right. I don't know how i'd go about defining it without having a couple lines that are 4000000 characters long. Edit: According to [this](https://stackoverflow.com/questions/34053606/understanding-static-constexpr-member-variables) (if I'm reading it right), ```constexpr static``` data members can be defined by an initializer list.
Well goly gee, you got me :)
If you didn't see the other reply, go take a look. It's totally possible.
Ah alright, thanks. /u/dodheim provided me with an example way to define the variable. I was very worried about having to define it at every single level, but it seems to work if I only define the definition of the top level to get it to link. Thanks again for the help! Edit: It would've helped if I realized that /u/dodheim... was you. :)
See /u/dodheim's comment for a solution that works perfectly :)
Check out .net native, it compiled down to machine code, bypassing any concern for IL or jit costs. https://msdn.microsoft.com/en-us/library/dn584397(v=vs.110).aspx Typically, apps that target the .NET Framework are compiled to intermediate language (IL). At run time, the just-in-time (JIT) compiler translates the IL to native code. In contrast, .NET Native compiles Windows apps directly to native code. For developers, this means:
Sure. I get that; but that mini language is as far as I understand not part of fmt by default. You are limited to the python syntax with d for an int for example. As far as understand you can't in a type safe way introduce a new letter -- or range of letters. I.e. fmt::format("{:YY-MM-DD}", my_date); Would never work, unless I miss something. You can't extend the base set with new format specifiers. So that creates two problems in my opinion. For some types you'll have to use separate helpers or member functions (like dates) with their own mini language. And secondly the problem of type mismatch, a user specifying a 'd' while providing a float. If you take out the types from the fmt mini language and just focus at positioning I think the verification becomes a lot easier (only argument count) and there are no 'special' types as far as fmt is concerned. For C with its varargs the mini language makes sense because you must be able to get the real type somehow, but for C++ the compiler knows. Even without {:d} you would know the argument is an int -- so that doesn't help. It only makes the problem harder in case the corresponding argument is not an int. Also in experience I find that not having a type in the format string makes changes easier because with it you often have to change both format string and argument if its type changes. Without type that's less often an issue. Say you're moving from an int to double for a value.
Tons of great information, thank you. 
They generate the same assembly: https://www.reddit.com/r/cpp/comments/4yd1nu/effective_types_and_aliasing/d6o6tmp
Get out. This is amazing. Give me C++17 already. Admittedly the all-or-nothing approach to values/lvalues/rvalues in the bindings limits the power of this, but it's still awesome nonetheless.
I personally don't get why you'd want use printf or your function at all. We have std::cout with its stream operator and std::string with its plus operator to directly create the wanted string/output... Why use harder to read strings with replacements instead of directly write the variables where they're supposed to be?
&gt; This is really useful. Can I just make one usability request? &gt; I'm trying it on OSX and the text editor prompts to go to a line number when you hit Cmd+L, but Cmd+L is normally the key to focus the address bar. Ctrl+L is usually better for that on OSX. &gt; I assume this is some default that Ace sets, but it's a bad one :( Well spotted. Issue here: https://tree.taiga.io/project/njlr-jyt-fiddle/issue/8
Or, with a bit less code and without recursive templates: template &lt;typename... Ts, std::size_t... Indeces&gt; std::size_t hash_tuple(const std::tuple&lt;Ts...&gt;&amp; tuple, std::index_sequence&lt;Indeces...&gt;) { const auto hashes = std::initializer_list&lt;std::size_t&gt;{(std::hash&lt;Ts&gt;{}(std::get&lt;Indeces&gt;(tuple)))...}; return std::accumulate(hashes.begin(), hashes.end(), std::size_t{}, [](std::size_t acc, std::size_t h) { return acc ^ (h + 0x9e3779b9 + (acc &lt;&lt; 6) + (acc &gt;&gt; 2)); }); } namespace std { template&lt;typename... Ts&gt; struct hash&lt;tuple&lt;Ts...&gt;&gt; { size_t operator()(const tuple&lt;Ts...&gt;&amp; tuple) const { return hash_tuple(tuple, std::make_index_sequence&lt;sizeof...(Ts)&gt;{}); } }; }
Yes, look at this SO question. http://stackoverflow.com/questions/4948780/magic-number-in-boosthash-combine
Here you are: [Regex Crossword Solver on GitHub](https://github.com/antoine-trux/regex-crossword-solver)
Thanks!
As far as add-ons go [Visual Assist](http://www.wholetomato.com/) is fantastic. It has abilities like toggling between .h/.cpp files, going to the declaration/definition of a function from anywhere it is used, etc. It also has powerful refactoring tools like renaming functions/classes, adding/removing function arguments, stubbing out definitions based on declarations, etc.
Binding to a forwarding reference allows both rvalues and lvalues, so I don't see any limitation there; I would love be able to mix const and non-const, personally.
Cereal doesn't serialize what they point to if I remember correctly. I'm not sure how it would either unless it it was able to use the type or grab the size of memory it points to from the heap. 
The limitation is this: You can't write ```auto [a, &amp;b, &amp;&amp;c]``` as mentioned in [another comment](https://www.reddit.com/r/cpp/comments/4yk36l/c17_structured_bindings/d6od5yh). Agreed, const/non-const mixing is also useful.
Aah I see. A bit of a shame but makes total sense. Thank you very much for posting that!
Yeah, that uses the same approach; odd that it doesn't explain how it works in the documentation (as that's the interesting bit).
Oh well debugging using breakpoints is the most basic thing you can do, not sure there's anything one can learn there... except maybe conditional breakpoints.
Forwarding references (like `object` in `to_tuple`) are usually being `std::forward`-ed. Are there any cases when auto&amp;&amp; [p1] = object; vs auto&amp;&amp; [p1] = std::forward&lt;T&gt;(object); would give different result? If there is no difference, are there other cases when `std::forward` is not mandatory for forwarding reference? 
&gt; n! configurations possible I think it's 2^n.
Most of the things I consider invaluable to develop in VS are not free... but here it goes. Visual Assist makes VS amazing in everything IDE related: searching, better definition linking... It's kind of a must for me. Also I use IncrediBuild, which in a workplace environment lets you use all of the computers connected to an IncrediBuild server to compile. In big projects it's just amazing. If you don't have a server though, it is still useful since it gives you a visual representation of the compilation process, and improves it anyway by sharing the work load between the cores of your CPU (or threads).
While there are some nice add-ons, I honestly don't think there are any must-haves really. Visual Assist like some mention is really cool (although I personally haven't used it for many years so I don't know how big a difference it is nowadays), but not free and not life changing. Base VS installation is really useful as is, and I'd say using it like that is a good starting point. 
Just saying that the act of debugging is different than terminal. Not hard but something you should get used to.
Very nice! I played around with it for a bit and tried separating out the number-of-members calculation and made the maximum number of elements configurable via the preprocessor: http://melpon.org/wandbox/permlink/j42rOBXQfcj1WACz
Yes, I didn't mention that the library seems to be updated for C++17.
You could have at least pointed to CLion if you were going to completely ignore what OP was asking for.
Well, this still is C# and could be a lot better tool to learn than Visual Studio for a longer/healthier career. My position is the polyglot programmer is the new norm and the future. So learning one IDE platform that will work cross-platform and cross-language may be a better use of his/her time. Once Rider is released, I'll never use Visual Studio again.
In C&gt;=99 TC3 both cases should generate the same code. If you find a case in which this does not happen, fill a compiler bug. 
**Extensions:** * Visual Assist (obviously) * Tabs Studio (can include both .cpp and .h in a [single tab](http://i.imgur.com/tH1Aggt.png), so much better for organization) * Productivity Power Tools * Code Alignment * VSColorOutput * [Tab Group Jumper](https://github.com/mrdooz/TabGroupJumperVSIX) (hotkeys to switch between tab groups) **Hotkeys I use frequently (they're not all defaults, and some are VAX's):** * Alt Shift O (Global): OpenFileInSolutionDialog * Alt O (Text Editor): OpenCorrespondingFile (.h/.cpp) * Alt M (Text Editor): ListMethodsInCurrentFile * Ctrl T (Text Editor): NewVerticalTabGroup * Ctrl Alt ,/.: MovetoNextTabGroup * Alt ,/.: Jump Left/Right (TabGroupJumper) * Alt Up/Down: Move selected lines up/down * Ctrl Up/Down: Scope Next/Prev * Ctrl L: Delete Line * Ctrl Shift W: Close all tabs * F4: BuildOnlyProject * F6: CollapseToDefinitions * F8: Go to next error * Ctrl F8: Go to next location * Ctrl Shift C: Create Implementation * Ctrl Shift Down/Up: Next/Previous Highlighted Reference * Ctrl Shift Enter: Line Open Above * Ctrl Enter: Line Open Below * Ctrl Tab/Shift Tab: Next/Previous Tab (TabsStudio) 
I don't know, sorry - I don't code in C# :-)
&gt; the act of debugging is different than terminal Not really - a lot of people code in the terminal and do debugging with breakpoints (gdb, cgdb, ...). In that sense VS debugging in principle is the same (it just does it nicer and it can just do much more in addition to that). If you talk about people that code on the terminal and don't debug at all, oh well.. we're not really talking about these people are we?
Yep, me too! :D I read it in the VS release notes blog post though! But I consider that already more advanced than the simple "debug using the break points" that was mentioned in the post I replied to.
I use all of their IDE's depending on the project I'm on, including CLion. Once Rider comes I'll be using their IDE's exclusively. I also use ReSharper whenever I use Visual Studio. If you like ReSharper than what it provides is basically what you get for all the other languages that the Jetbrains IDE platform supports. I do agree that JetBrains has an uphill battle for CLR languages, but that's partly why I posted in order to help them get the word out. And, for the record I don't work for them... I'm just a big fan. NOTE: You are correct, I didn't notice that the focus was C++, but even if I had I would have posted the link to CLion. Regardless the thing to understand is that there are real alternatives to the monopoly that is Visual Studio.
Maybe an implementation or help with the current main proposal for serialization in C++ would make your efforts more successful? - Last version of the proposal: http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0194r1.html - Work in progress proposals: https://github.com/matus-chochlik/std_cpp_refl - Apparently there is an experimental implementation ongoing somewhere but I can't find it so far; Just to clarify: once we have something like what is proposed, generic serialization could be written very easily and in a very controllable/fine-tune-able way for the user.
Weird thing to say considering that Qt is a cross platform library. QString uses utf16 on all supported systems, independent of the native encoding. 
There's a great add-on for vim-style editing if you're into that. It will even use C:/Users/username/.vimrc if you've got some bindings already.
How about `to_struct` to be able to convert in both directions? I'm wondering will compiler optimize `to_struct(to_tuple(...))`? :)
2015 seems to have stolen some of those source/header toggles and a simple version of the rename tool. 
I think we need something like: auto... [x] = y; return make_tuple(x...);
What are the applications? Can't say I've ever wished to convert a struct to a tuple, honestly.
Reflection, eg. automatic serialization.
&gt; Tabs Studio How does that work? A lot of the time I split my editor and keep a .h on one side and corresponding .cpp on the other, especially for refactoring or new code. Would you just have to turn that whole feature on and off to do that?
Try this state of the art tool: http://typegrind.github.io/
EDIT: Yep, as /u/scatters is saying, `std::make_from_tuple` with braces will do it... namespace detail { template &lt;class T, class Tuple, std::size_t... I&gt; constexpr T make_from_tuple_impl( Tuple&amp;&amp; t, std::index_sequence&lt;I...&gt; ) { return T{std::get&lt;I&gt;(std::forward&lt;Tuple&gt;(t))...}; } } // namespace detail template &lt;class T, class Tuple&gt; constexpr T make_from_tuple_using_braces( Tuple&amp;&amp; t ) { return detail::make_from_tuple_impl&lt;T&gt;(std::forward&lt;Tuple&gt;(t), std::make_index_sequence&lt;std::tuple_size_v&lt;std::decay_t&lt;Tuple&gt;&gt;&gt;{}); } { struct s { int p1; double p2; }; auto s_ = make_from_tuple_using_braces&lt;s&gt;(to_tuple(s{1, 2.0})); assert(1 == s_.p1); assert(2.0 == s_.p2); }
One may agree with your project layout but you should definitely not do _in-source_ builds. It's highly recommended you move your build and install ("output") directory one level down.
Provided all build files are output to the same base folder(s) that doesn't include any code and that is in the .gitignore I don't think it needs to be one level up. However I would have 2 suggestions: * if possible I would not hardcode the build folder and would allow users to choose it. Whether that is a default build folder as proposed or fully out of source directory as you prefer. * Try to only have one base folder for all generated artifacts. I.e don't have code/build and code/output folders. Instead have them under one path 
Below is the structure I use: - bin/: built project binaries. - build/: generated project files + objs. - docs/: maybe Doxygen generated? - share/: resources to be bundled. - include/: all project headers. - extern/: libraries that are to be built. - tests/: code for unit &amp; function tests. - src/: all the source code (- headers). - .gitignore: do not track bin/, build/ and extern/. - .gitmodules: fetch libraries to extern/. - premake.lua: generates to build/. - readme.md, license.md Basically, you then just call premake5 (gmake | vs2015 | xcode) to generate the project files to build/. I'm running a Unix-like system, so after generating this I'd call make -j8 -C build/, to build my targets to bin/. I usually have at least two targets, the program itself, and then its respective test suite (using Catch.hpp), maybe some documentation target too? The premake tool is magical, the syntax is gold compared to CMake (albeit a bit more restricted in its feature-set). 
Sorry, but no; union casting works only for standard-layout structs with a common initial sequence, which rules out any variadic tuple (since they have to use either recursive or multiple inheritance). We've already required that the struct type be constructible from a braced-init-list of its members, so we can just use `std::make_from_tuple` (possibly hacked to use brace rather than paren construction).
I totally agree, but there is no template context to unpack.
No, that works fine.
The problem is that tuple layout is implementation dependent: [gcc](http://melpon.org/wandbox/permlink/TBBzeZc2E0GzM7xA), [clang](http://melpon.org/wandbox/permlink/Fw0LrhbWvSLT0Nuz). Also I think that accessing inactive union member in C++ is UB (even if it is not true, I'd better be safe).
Yeah, just after I wrote that I realised that `std::make_from_tuple` uses parens instead of braces. It's easy enough to copy the reference implementation and switch parens to braces, or just use /u/chr15_'s implementation above. 
&gt; I am quite interested in potential applications. Has anyone ever used such "pattern" for something actually useful in c++? I find this to make the code really verbose and unclear for nothing.
Right. With any introspection/reflection there's going to be a tension between functionality and subverting class semantics. I think that although to_tuple/to_struct is only a very primitive form of introspection it'll still have to be pretty cautious, so that means as soon as a class has constructors etc that means it should only be introspectible on an opt-in basis. What do you think? 
You should be emulating C++ in JavaScript, not the other way around.
This one's a good one, too. http://cpp.sh/
I'm not advocating for or against this technique - but... * How is this "more verbose" than the same code with the class outside the context? * How is this less clear than the same code with the class outside the context? Generally, it's good practice to keep the scope of any symbol as small as possible, and this technique (local classes) seems to be a possible tool to accomplish this with minimal changes to your code. I have no idea whether I'll ever use it in practice, but I also don't see a reason to rule it out either.
For _any_ tuple it is super easy to to write code that e.g. loops over all its elements, reads/writes them to disk/network/json/..., generates other types (e.g. generate a tuple of arrays of the elements), ... Writing this type of code for _any_ possible struct is "hard", and often, a bit painful to use (requires that users adapt their structs to make them look like tuples). Having an easy way to obtain the tuple representation from a struct (and converting back) allows you to easily use all the code that operates on arbitrary tuples, but on structs.
I cannot live without Resharper C++ - give it a try -&gt; https://www.jetbrains.com/resharper-cpp/
No shadow building in a separate folder? Edit: o you are using the build dir for project files, not compiled build output.
They share the try-catch and assert mechanisms. You can also weakly model inheritance too. I think `instanceof` allows for a really nice implementation of polymorphism. I think you can also weakly emulate interfaces as well if you `instanceof` pass a class with throwing implementations of the functions.
Local classes do have some restrictions, such as not being able to use automatic storage duration variables from the surrounding scope without passing them through a constructor. This is a problem if the constructor needs a specific set of parameters. I don't think there's a non-hacky way around that.
Wow, I guess c++ is more subtle than I believed , and it's quite amazing to see what type deduction allows
 If you have say an FFI interface and a series of functions to translate the values in order to pass them across the barrier. With a tuple thats kind of trivial.
YMMV, but this is what works for me. You should make all of your projects install properly. So headers go into $prefix/include/$project, libraries go into $prefix/lib/, etc, where $prefix is the same place for all of your projects. The waf [gnu_dirs](https://waf.io/apidocs/tools/gnu_dirs.html) documentation has a decent overview of where you can put everything. If you are more partial to CMake, it also makes it easy to have a proper install. Then you will not have to include third party sources. It is just another dependency and your configure step will find it (you do have a configure step, right?). You might still have a mega-project which pulls in all of the dependencies and hard codes the configure invocation, but each project will still be self contained. You might have to enhance third party build tools to install in a reasonable place. I find that it is only small projects that have not done the legwork to handle installs properly. Since they are small, it is straightforward for me to do it myself. This also means that you can put the headers together with the source. I am not a big fan of having to look in two very different places when I have to update function signatures. The install script handles the complications of separating out the headers from the implementation.
Ah, fair enough.
You can return an object of the class, and the reference needs storage, so... if you want your class to have constructors, then yeah, you need to pass the reference through constructors to be able to use it in the class. But if you don't need constructors like in the following example, then no, you don't need to change anything: // Returns an anonymous object with a dangling reference: auto foo() { int a = 2; struct Bar { int&amp; b; }; // no need to change any constructors return Bar{a}; // just use direct initialization }
The point of `instanceof` is in calling code. const func = derivedInstance =&gt; { assert(derivedInstance instanceof BaseClass); // appropriately call methods from BaseClass }; The point was that `instanceof` lets you declare, hey, this needs to possess at least this segment of the prototype chain which is why I say it's nice for polymorphism.
What area is your development in?
Full-stack web developer. Currently know C#, JavaScript, Java, Python, Elixir fairly well, and a few others slightly. Edit: why am I getting downvoted...? Is it because I stated I'm a web developer?
Turing complete features, no other language has so many.
Game development is broad topic. What are you interested in particularly ? Seeing you know C# i would recommend to try Unity first. &gt; I can pick up C++ and get going quickly I don't think it's possible to do quickly if you want to get into game development in C++. In most cases they use C++ like C with classes. You would need to know about memory management, memory layout etc. This is not something you going to get quickly if you struggled with that before. You could also look at UE4 engine and blueprints. 
If you want to use a reference within a class, the reference must either be a static or non static data member, in the static memory segment of your binary (i.e. a global), or an argument of the method. A variable in some function stack frame will go out of scope at the end of the stack frame. So you need to pass it to the method. That method (which doesn't need to be a constructor, but it could be). &gt; being able to use automatic storage duration variables from the surrounding scope The moment that stack frame goes out of scope, you would be using a dangling reference from within the class. So I don't see how any other alternative to the current status quo would make sense. No magic can fix that.
Beside the extensions already posted by others: [clang-format for VS](http://llvm.org/builds/) Formats your code based on a .clang-format file, couldn't live without it!
Thanks for your advice. I would rather not use Unity and I'm okay with taking my time learning C++.
It's kind of cheating to do it this way. The real way is something like this: #include &lt;string&gt; #include &lt;iostream&gt; enum Operation { Print }; auto make_base = [](std::string const &amp; id) { return [id](Operation op) { switch(op){ case Print: std::cout &lt;&lt; "Base " &lt;&lt; id &lt;&lt; std::endl; break; default: std::cout &lt;&lt; "Invalid op" &lt;&lt; std::endl; }; }; }; auto make_child = [](std::string const &amp; id) { auto base = make_base(id); return [base](Operation op) { switch(op){ case Print: std::cout &lt;&lt; "Child ";break; }; base(op); }; }; int main() { auto base = make_base("base"); auto child = make_child("child"); base(Print); child(Print); } 
This can be used to shorten symbol names when doing stuff like expression templates. Basically, since a lambda expression has a unique type, the local class created inside a single instantiation of that lambda's `operator()` is unique too. Therefore, even if the local type would normally have complex template parameters, the compiler is free to generate whatever symbol it wants, and that symbol is usually (but not always, depending on the compiler) shorter than the type with full template parameters. This can result in shorter symbol names, which is important for some template-heavy libraries.
What is your end goal ? Learning C++ and doing game development may not be both achievable at the same time. Except if you are envisioning to work in a team or on a very simple 2D or text-based game. You would be better off looking for existing engines / frameworks / etc that exist for the kind of game you want to do and learn from there. 
I know I'm a little late to the thread - however, I was wondering /u/aearphen, how would I use CMake to include the library as a dependency with it fully installed? So far, I've got the find_package(fmt REQUIRED) line added. Do you know, what are the libraries defined as to include in the target_link_libraries directive?
Many abstractions are. Non-virtual member functions are exactly the same as calling functions with pointers (C++'s `thing.do(with, these)` vs. C's `thing_do(&amp;thing, with, these)`), and more efficient than storing function pointers as struct members for ad-hoc virtual function calls. C++'s templates allow its `sort` to be fundamentally faster than C's `qsort`.
I have a similar structure except sans the `extern` folder so I'm curious how your structure maps to binary outputs. For me the files in `include` and `src` implicitly build the library (dynamic shared object) that the project is all about. Anything that produces executable binaries ends up in `bin` and links to the library built. I also occasionally include a `libs` folder that builds a dynamic shared objects meant to be dynamically loaded (i.e. `dlopen`). In your set up what does `src` build and what does `extern` build?
What you want isn't well defined. For example should a GUI kit include facilitates to play movies? How about sounds?
That's cool, thanks for the link.
Can you give an example? How are you supposed to refer to local variables within a class method in that context (if its not by reference?).
One way to get into it is to get Unreal Engine 4. It's free to use and there is documentation for using c++ with it. Beware that it's got extra stuff added to c++ like garbage collection and reflection so it might not look like your everyday c++ at first sight but it allows modern c++ stuff freely. Plus its a cool fun engine to play around with. https://www.unrealengine.com/what-is-unreal-engine-4 If you want something simpler that will allow you do things with a big more control, then you can use libraries like SFML... http://www.sfml-dev.org/ or SDL2.... https://www.libsdl.org/ These two libraries do pretty much the same thing and allow you to do things like create windows, textures, grab gamepads, play audio etc. You might want to look at EASTL. It is Electric Art's Alternative to the Standard Template Library. https://github.com/electronicarts/EASTL 
It involves making a copy.
Many things you said ate already built in Visual Studio I think. Toggling between .h and .cpp file is Ctr+K, Ctrl+O. Going to definition is F12. Or Ctrl+, (Ctrl+comma) Renaming is Ctrl+R, Ctrl+R Actually I haven't tried manipulating function declarations so that may be something useful of visual assist. 
I use c# and c++ on a regular basis and as Sean said using a C Interface is the most clean and simple option (search for the DllImportAttribute and you'll find tons of examples) I am however not all too happy with using c# as the frontend technology because of a lot of quirks and code repetition. The next thing I would want to try is using C++ as the backend and chromium embedded as the frontend so that I can use HTML and Javascript which I have the feeling is more future oriented than wpf or windows forms. Another alternative to using direct pinvoke or managed c++ wrappers to communicate between a c# and c++ project would be to use a messagepassing framework like zeromq to do communication. I've successfully used this to embed a c++ 3d framework into wpf. However as I see it there is no silver bullet when talking about c++ integration into c# and all of the possible solutions have pros and cons pinvoke: Clean, Fast, however you are going to have a hard time if you do not use a c interface and want to use c++ objects clr/managed c++: You have to create wrappers for your native objects can bei alot of overhead, there are alot of quirks that you have to get rid of during developement (managing native AND managed memory) message passing: Slow because of serialization, however you get built in networking capabilities. 
No idea why you got downvoted - seemed the correct answer to me. I learnt a long time ago not to worry about such things in online forums. Another book that maybe worth considering is Stroustrup's Programming -- Principles and Practice Using C++, while some aspects may be "too simple", i.e. aimed at absolute beginners, it still does teach idiomatic modern C++ fairly well, and later covers memory management, pointers etc. for when you need to get your hands dirty. As stated by u/nerdcorerising below, C++ Primer is also worth a look. Be careful not to get "C++ Primer Plus" which is unrelated and a freaking awful book. 
I'm not sure why the down votes. It might be because writing game programming is an incredibly broad topic and learning C++ at the same time is going to create some headaches but nevertheless, kudos for adventuring. I would recommend a more recent C++ book, something that covers C++1x+ as it has so many useful features over the older standards. (/u/nerdcorerising hit it on the nail with C++ Primer). Have you done any game development before? Send me a PM if you get stuck with anything with C++/Game dev, I would be happy to help.
Wow! That surely looks promising. We do have MSLOC code base in C++ which is 20+ years old. And this is almost exactly that we want!
Really interesting discussion(s). Thank you!
If your project is compilable with Clang, I can highly recommend [sourceweb](https://github.com/rprichard/sourceweb). It basically indexes the project via your standard build system and gives you a window that lets you instantly jump around the codebase.
How's that different from YCM, Eclipse or MSVC indexing my code base? Also, part of the point in this project is that your build system can have a skewed view of your project's actual dependencies - the bigger it is, the more skew you can have and the worse any build-system dependent output will be.
So this only works for CMake, not good old GNU make ?
The first two paragraphs sounded like there's a genuine questions coming. Then, it turns out it's "just" an ad for a new tool. I felt quite a bit cheated. But since the tool is open source, it's ok I guess. It looks quite nice actually. Thanks for making it open source!
So you keep project libraries source in src/ along with the source for the tools you ship along with it?
Plugins would definitely explain why there's no link towards them - as then you'd have to ship a plugin to get the stuff to work. Plugins also imply runtime dependencies, and those are not detected with this approach. You should have dependencies *towards* the interfaces they implement though. That conversion error means that your graph is too wide for a PNG file - and they have an upper bound on the width of 32767 pixels. So your image is a relative 100000 pixels wide - probably because most of the nodes are actually separate and Dot typically puts them side-by-side. That also means that the image will be *very* wide and narrow, so you will need to zoom in quite a bit to see anything at all, and you will be scrolling a lot. So the graph option does help, but it's full of nodes that are laid out side by side. You can filter the file by hand if you feel like it, or you can use some of the other functions to analyze what it's reporting. As suggestions: - outliers will inform you of components that are outside of typical software trends. I think the default settings are fairly reasonable but you can add a config file to modify them. It also tells you which components are in the cycle (as that's not typical software). - graph-cycles is one we use more than graph, because it outputs only the cycles. The graph drawn by Dot for this is *much* more useful, in part because you know that everything's connected in this graph. - graph-target is also helpful, because it omits all those empty projects and plugins and reduces your graph size, but keeps one specific target in view. - ambiguous may help identify ambiguous include statements. This happens a *lot* in software and will cause your build system to be unstable, or auto-completing tools (Eclipse, YCM, MSVC) to not know which header you're actually including somewhere. Note that it ignores ambiguous includes completely (!) to avoid signalling false cycles, but it does include them in used header files (so it doesn't flag files as unused when they *could* have been included somewhere). - shortest is one I love to find out *why* a component links to another component, especially if the second component should not be linked to the first one at all. This helps for cycles (to find out which include statements cause a link) but also for links that are just odd (such as a media player linking to your email backend, for example).
How do you detect "components"? In my project it detects just one component despite having twelve add_library() in CMakeList.txt
So it works without CMakeLists? If yes, great, if not, then "CMake projects only".
Tag each folder that contains a library with a file called "CMakeLists.txt" that's empty. That's enough. No CMake used.
One of the first things was to get the build system into such a state that the stated dependencies are as they should be (it can regenerate your cmakefiles with --regen), that spurious dependencies are removed and that includes are no longer ambiguous (check with --ambiguous). Then find out where you have cyclic dependencies and solve them in one of four ways (Remove one link, extract common part, chop in half with A1 -&gt; B -&gt; A2 or merge completely). This in our case already required a few bits of reengineering, where a design or architecture part had to be completely recreated as the original design just about required cyclic dependencies. Then, find dependencies that are logically wrong. Start removing those and keep vigilant of how many things you drag in. Every link should have a good rationale why you have it. And then you have a maintainable usable software system. You can then use those contained libraries to create software and know what you will drag in, and why. As for the large software system, they also take some time to clean up. We're at a pretty good place right now though - we're using it more to automatically recreate cmakelists when we change dependencies than for most of the checking functions, so our system is already quite able to cope with changing modules. We've also removed nearly all cycles and for all remaining ones we have plans in place to remove them on very short term.
There is [a whole book on it](https://www.amazon.com/Working-Effectively-Legacy-Michael-Feathers/dp/0131177052). The tl;dr is you write a bunch of unit tests. Treat the legacy system as a black box with inputs and outputs. Write tests that cover all of those inputs and outputs. Once you have good code coverage you are free to refactor. You could replace your reimplementation of unordered_map with the real version. If the tests pass you are golden. Of course, the real trick, and the really hard part, is to push back and never let those hacks get into the code base in the first place. Since no one person owns the code, and turnover also causes many hands to touch it, the only way for it to work is to be company policy. There needs to be strict code reviews that reject hacks and messy code. It also needs to be OK to miss as sprint release due to rejected code. If it's not OK, well then have fun with the spaghetti code. 
[removed]
Seems like a tool I would be very interested in using. Is there any way to list the components it finds? I'm having some trouble, and I get "Component does not exist" for everything I try. EDIT: So it seems like my the errors because I use qmake, not CMake. Any easy way to use this tool on qmake projects? I would love qmake support.
It finds components by looking for CMakeLists.txt files. It names them as per the folder they're in, with slashes replaced by dots. Does qmake have an equivalent "this folder contains a project" tag file? If not, it'll not be usable. The only thing it uses the files for is to identify what to see as a component - so you could try tagging components with an empty cmakelists.txt and see what it says. That's how I tried it on Chromium, which also has no CMakeLists. As to listing the components - good point. Hadn't thought of it. You can get a list with --graph which outputs a Graphviz graph that contains it in text format, so that's a way to get them.
To my great surprise you can [find it with google](https://scitools.com/). Looks like they also do dependency analysis, but at a price.
&gt; Java and C# are not especially large languages This is actually not the case. They are both *bigger* than C++ ([from this comment](https://www.reddit.com/r/cpp/comments/2v98qq/so_how_big_is_the_c_language_specification/cogyzq2)): C++ 430 pages language itself Java 780 pages C# 545 pages (This may well be the case, however, that they are more consistent and thus perceived as simpler or smaller.)
An honest question: is this code base a huge pile of copy pasta? It seems it would be pretty hard to reach that kind of code size without it.
I'll add a TL;DR. Thanks for the tip!
I added an accurate one.
Misread. Deleted my comment Maybe I didn't misread. It's early and the kid didn't sleep well last night. I'll try to run it this week and give some feedback 
The main library is called `fmt`, so to link with it you'll have to do: target_link_libraries(&lt;your-target&gt; fmt)
Wow, that does seem to be old C++. The `&lt;iostream.h&gt;` header is from *before the days C++ was standardized*. Before 1998, that is. Roughly 20 years old. In technology timescale, this is eons ago. If you can, you should find a toolset that supports at the very least C++98, and not code for C++ that is older than that. Because, if you do, whatever it is you learn, might well not be transferable to other toolsets, like when you switch from Windows to programming for the Mac, or Linux, or Android.
I worked on the Google codebase some five years ago. Very little copy paste there - and millions of lines of C++ code. It simply does an awfully large number of disparate things...!
If you're writing one now make it suitable for VR and 3D gloves so you can move nodes around too. Would be excellent actually - especially given the size of some graphs. PS: I haven't tried this on libc++ directly, perhaps something you can check? May have to remove part of the blacklist intended to make it skip standard library headers... ;-)
thats a great argument for copy pasta code!
The binding doesn't change the value category for object, so you still need to forward it.
Are you aware of the Boost Serialization Library? It addresses all the point's mentioned here - and many more as well.
So it's faster and more memory efficient than boost and gcc? That's really impressive if true
We generally make each internal library/binary build as a debian package with proper dependencies, so there are no folders for third-party libraries. * src/: sources and internal headers * include/: public API (only for libraries) * tests/: tests * etc/: configuration files, resources, etc. if required * Makefile: We only build for linux, depending on your needs and tooling this will be configure.ac or CMakeLists.txt
I guess that is the price to pay if you want to be compatible with older compilers. Sure, it would be much easier to support only the latest compiler versions, but it would also prevent some developers from using it. I could definitely trim the #defines, many are not used, but I don't think most people care too much about the implementation, if it performs well.
To be fair, though, this is the best ad for a tool I've seen in a while. I'm sold.
I keep reading this as "20 million year old code", and go "Huh?"
Yes, the [issues](https://github.com/codedocs/codedocs/issues) on GitHub is the place to look. Dot is installed and working, by default some of the graphs are being made. Currently, I am expanding the number of doxygen features available substantially, so in the not to distant future, pretty much all the doxygen options related to html generation will be available. The current list of working options can be found on the GitHub [wiki](https://github.com/CodeDocs/CodeDocs/wiki)
Can you share what the output based on the Chromium code base looks like?
Recently, I've just used dense_hash_map, since it seems to be the best open source one (and I don't do very much C++ work nowadays; working on a Unity game). But writing a simple [coalescing hashmap](https://en.wikipedia.org/wiki/Coalesced_hashing) should yield significantly more efficient results than unordered_map. It's possible this has changed since the last time I tried speed testing.
dense_hash_map is the speed champion, but it uses a lot of memory, up to 6 times the memory needed for the hash entries themselves. However, if memory usage is not an issue, dense_hash_map is an excellent choice.
solarized dark for vim, gvim and QtCreator.
I don't get it, why can't you just do: if (!map.insert({ "hello", 3 }).second) std::cout &lt;&lt; "hello already exists\n";
It's just a simple example showing off syntax. If it helps, imagine they did this instead. if (auto ret = map.insert({ "hello", 3 }); !ret.second) std::cout &lt;&lt; "hello already exists with a value of " &lt;&lt; ret.first-&gt;second &lt;&lt; "\n";
How does this differ from the Graphiviz/dot callgraph capability already in Clang/LLVM? How does this work on C code? I see you've already addressed that code duplicate-detection tools were previously used. I'd like to hear about this, too. 
How about this? using mutex_lock = std::unique_lock&lt;std::mutex&gt;; if (mutex_lock lock(mutex, std::try_to_lock); lock.owns_lock()) { //... } //mutex unlock vs. this { mutex_lock lock(mutex, std::try_to_lock); if (lock.owns_lock()) { //... } } //mutex unlock
Your post has been automatically removed because it appears to be help/homework related. If this has been in error please message the moderators. *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I agree that this is a much more solid example of the usefulness of this feature. I shall update the article. Thanks for the input! 
but couldn't that also be solved by using a lambda function?
Thanks for posting this. I've gone through a similar process for my smaller project. I no longer worry about how to perfectly format some piece of code, I can just write the logic and run clang-format afterwards.
Still don't see the advantage besides avoiding a couple of braces. It just moved the *actual* condition far from the `if`, reducing the readability. 
It could, doesn't mean it should though. Depends on your coding style and in my opinion this makes it less verbose than with the lambda function.
Code duplication detection was mostly using Coverity on the full code base, as well as normal review process. Coverity finds many instances of code duplication already, and humans are pretty good at recognizing a pattern they've seen somewhere else if it isn't identical enough. Do you have links to what LLVM/Clang can output? Note that this isn't callgraphs, but include-level dependencies. If you want to split up a code base, you will need to actually not include any headers from another unit.
I just meant that I was suggesting an alternative to VsCode which is similar in spirit (i.e. an easily extensible editor, with language specific plugins for more IDE-like functionality) that meets your requirement of vim emulation. Sorry if unclear.
I use [gruvbox](https://github.com/morhetz/gruvbox) ([dark mode, medium contrast](https://camo.githubusercontent.com/2fcf604967167347f15ca8be125d32b18db9bc28/687474703a2f2f692e696d6775722e636f6d2f476b496c38466e2e706e67)).
 ([](auto lock) -&gt; void { if (lock.owns_lock()) { //... } })(std::unique_lock&lt;std::mutex&gt;(mutex, std::try_to_lock)); lol yes it is more verbose
This is good advice, and indeed is what Boost does, however I was keen of having the whole thing be a single header file to make trying it and installation easier. 
All you're really asking for is a library that allows loading an image _asynchronously_. Search for that, specifically ‚Äì you'll find plenty.
I don't think you understood what I said. This is commonly called remap. It combines normalizing a value and linear interpolation into one function/name. The original poster said "lerp" which commonly describes only half of the functionality in "remap". 
It isn't a legacy, using only remap for everything is wasteful. Look at any shading language and you will see the two separated.
Nice article, thanks for sharing. For #3, this is naturally achieve when you write APIs in a layered approach (starting with a pure functional layer). The complex multiplication function could be written in a pure function which knows nothing of the Complex class, it simply takes the components it needs as parameters (a_real, a_imag, real, imag). Then Complex's member function calls the pure function with its members. The member caching is achieved naturally this way, without creating ugly temps (the parameters become the temps) and I believe the API is more powerful/easier to test this way.
&gt; We experimented with customizing ClangFormat to match our existing rules. The ClangFormat code was easy to work with, but ultimately, the ongoing cost of maintaining a fork is not worth the effort to match our old format. Instead, we adapted our existing rules to match what ClangFormat was already capable of. We strongly recommend that you do the same. I gave up on ClangFormat for now, because it does introduce some ugliness and does spoil some intelligently formatted code. Without customization it would make our code base worse. Might get back to it eventually, other auto format tools are not perfect as well.
I hear you, and I'm not really in a position to criticize. Just for readability I would be strongly tempted to split it up into multiple header files, even if they were all included via a single include file, because the hash logic itself is such a small part of the code. You've done the moral equivalent by breaking up the header into sections with comments delineating the separation. I'd just prefer that to be preprocessor *output* instead of input. I'm sure there are plenty of people who see it the other way around.
Sure, but it just seems silly that it's THE linear interpolation function if it can only work in the domain 0.0-1.0. However, naming is hard.
[XCode](https://en.wikipedia.org/wiki/Xcode), a free download from Apple.
Your post has been automatically removed because it appears to be help/homework related. If this has been in error please message the moderators. *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
In this case naming isn't hard, because these operations have had common consistent names since the 80s. 
Oh sorry, I didn't notice that you were talking about a different IDE instead of VS Code.
oh cheers, I'll give that go tomorrow.
QtCreator CLion (commercial)
[QtCreator](https://www.qt.io/ide/), and sometimes Xcode's profiling tools.
Same here, I just can't manage to have it do : void a_function(int an_arg); void another_fun( int first_arg, std::string second_arg, some_context&amp; context);
do you use the debugger function?
do you use the debugger function on Xcode?
no, I [debug mostly from within QtCreator](http://doc.qt.io/qtcreator/creator-debug-mode.html)
You can make a cmake where you offer the user to choose to concactenate all the stuff into a single header for his project or to build a clean solution where each file has its place. It's just one more step for the user as he actually has to run the cmake to concatenate the lib into a single header. Well. I wouldn't mind, really, especially if I don't have to open a solution and click build_all and install afterward ;) . The user would even be able to make the choice of his platform specific stuff so that the header file would be... lightweight :D
Yeah, I'd just have a makefile do that work for you and bundle the expanded file in to release packages.
None of them ever are. But for what it's worth, you can disable clang format for a block of code. I personally don't even do that. I just gave up all opinions about how code should look, and accept whatever the tool perceives as good looking. You know, it used to drive me nuts that clang-format thinks this void too_long_a_name::very_long_too( some_type p) { foo(); } Looks good. But not anymore. I don't care, it's by a tool and therefore consistent, and that's all that matters.
If the format is flexible what you probably want to do is look at EXR. Many image formats have a legacy 32 bit size parameter which means that they can't handle images of over 4GB. Exr if used uncompressed or with zip scanline compression should allow you to load up specific parts. Don't use the other compression formats like wavelet, regular zip, etc. There are two libaries that I know to deal with .exr - the main library is the most powerful, but a bit of a pain. The TinyEXR library you can find on github is much easier to work with but might not have all the features you need. 
That is a good suggestion, and I will do that if the repository becomes more complex. At this point I am trying my best to keep it as simple as possible. I think being able to just copy the header and use it immediately is very appealing. 
I actually can't find any worthwhile examples of LLVM's output, although the documentation for it is online.
You need to read a basic tutorial on programming
The program that I use to program programs in C++ is a program designed specifically to program in C++, so it makes sense to use this program to program programs in C++ ‚Äî [QtCreator IDE](https://www.qt.io/ide/)
I can't get the example to make sense..
What the fuck. Part of the parameter list and part of the function body at the same indentation level just beneath each other. Not just ugly, but misleading. Nope, I'm outta here.
Awesome news! Would be great if you can also include Boost and cinder as optional components as well :D
We certainly use command line stuff to prep our own dev/test VMs so it's there. I'm not sure how close the current command line stuff is to the final spec though. (For example, loc and offline install are not there yet) I'll ping Tim Sneath and ask.
I¬¥m trying to run this code: #include &lt;iostream&gt; #include &lt;cstdio&gt; using namespace std; int main() { // insert code here... int a,b,c,sum; cin&gt;&gt;a&gt;&gt;b&gt;&gt;c; sum=a+b+c; cout &lt;&lt; sum; return 0; } But when I run CMD+R , it doesn't say anything about putting input, know why?
By looking at it, Your code is solid and works. Although if you want to display something like: "Enter number 1: " and the user enters it, you will need to 'cout' it, then 'cin'.
Can ClangFormat do Whitesmiths? I'm asking... for reasons.
So I have to use cout before cin, then cout again? So it doesn't work like my code is?
include &lt;iostream&gt; include &lt;cstdio&gt; using namespace std; int main() { // insert code here... int a,b,c,sum; cin&gt;&gt;a&gt;&gt;b&gt;&gt;c; sum=a+b+c; cout &lt;&lt; sum; return 0; } But when I run CMD+R , it doesn't say anything about putting input, know why?
Unfortunately not, though it appears that someone gave it a shot (there's an open review on reviews.llvm.org https://reviews.llvm.org/D6833)
I'm doing the same thing (coming from web development). I bought a bunch of books and online courses but the things that have helped me the most are: [SoloLearn's C++ Course](http://www.sololearn.com/Course/CPlusPlus/) This app has been a great way to learn the basics of C++ and get the ball rolling. It teaches piece by piece and makes you fill in the blanks to prove understanding before you can move on. I've been learning Unreal Engine 4 as a way to make learning C++ fun. Unreal 4 has an amazing set of project templates that give you a very basic game to work with. UE4 also has a wealth of tutorials online that can help you get started quickly. I started learning Unity last year and I will say that Unreal 4 will get you started significantly quicker. You can make games with UE4's Blueprint system without touching a line of code. 
Eclipse CDT 
Clion, and xcode for when I'm on a different machine without my license info.
What about if ((int i = f()) % 2 == 0) { /* doesn't compile*/ } And if you remove the parens you don't get what you expect: if (int i = f() % 2 == 0) { /*i is the equal to f() %2 == 0, converted from bool to int*/ }
Hi. The state of c++ coverage reporting is not great unfortunately. Personally, the better reports I've had are the reports from Sonarqube with sonar-cxx plugin. However, the plugin is a bit limited in the c++ features it supports. Aside from this, I would stay with gcov -&gt; lcov, it is the most easy tool, even if not perfect. As for the code that is just let as white (not executable ?), I've had the same issues with gcov and lcov but I've not find out the source of these problems. You could try with llvm/clang now that they have code coverage support. 
 Package 'Win10SDK_10.0.10586.212' failed to install 2016-08-23T07:31:11 : Error : Failed to install product. [installerId: SetupEngine, productId: Microsoft.VisualStudio.Product.Enterprise, installationPath: 'C:\Program Files (x86)\Microsoft Visual Studio\VS15Preview', error: undefined at Error at SetupEngineAdapter.handleError (C:\Program Files (x86)\Microsoft Visual Studio\Installer\resources\app\lib\Installer\Adapters\SetupEngineAdapter.js:316:31) at C:\Program Files (x86)\Microsoft Visual Studio\Installer\resources\app\lib\Installer\Adapters\SetupEngineAdapter.js:127:45 at process._tickCallback (internal/process/next_tick.js:103:7)] Well that's a useful error.
I am using [desert-warm-256](https://github.com/rainux/vim-desert-warm-256). [Screenshot-cpp](https://pablohernandezcerdan.files.wordpress.com/2016/08/dessert-warm-256-colortheme-cpp.png)
Actually, the tool itself worked like a charm. It really took just a few seconds to process our code and it produced a rather comprehensive graph. But then the dot said it's "too large for cairo-rendered bitmaps" and the bitmap it produced is not really helpful with the scale it had to resort to :-) Anyway, the .dot itself is very helpful just as it is, I already saw some unexpected "oranges" with grep. Great tool!
If you have cycles (--stats will tell you) you can get the cycle graph for just the things in cycles (--graph-cycles). You can also get the outlier information (--outliers) for things that look odd (tiny component, huge component, unused library, never-included header, ...) and paths from one component to another (--shortest, to see if there is any, and to find out why). See the wiki for more arguments it accepts. Given that it's meant for *large* projects, you can put multiple arguments after one another and, other than commands that modify how the project is seen, get results faster.
I'm really interested in what the analysis of chrome and LLVM looks like.
yeah... there's still some cache stuff and other unneeded dependencies we will remove before we are done. how long did it take, if I can ask?
"Hundreds of developers"..... mind blown :P
Toyed a bit with it and it looks like it's really good for dictionary kind of tasks, where you only add elements and never or rarely delete. Lookup is very fast. Iteration is very fast. But heavy duty insert+lookup+delete cycle is even slower than in case of std::map. Btw, unordered_map that comes with VC2015 is surprisingly fast (except for iteration, which is not surprising at all).
I am excited to hear that! My biggest gripe for Windows development is how painful it is to deal with libraries when on my Fedora system I can do a simple dnf install foo and it "just works" without any problems. Even with the NuGet package manager things are not as nice as they could be. 
[It doesn't](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0305r0.html).
Desert
Nice write up! The `std::` and `boost::` containers provide pretty strong guarantees with respect to iterator invalidation. Which guarantees does your container provides.
Just wondering aswell, as I am in the same position, can you self-teach yourself and get a job as a computer game programmer?
True that, I remember argument formatting, long expression formatting, and macro formatting was broken there. 
http://zed0.co.uk/clang-format-configurator/
For me it's too little too late. But okay, I'll go along: *neat!* Now let's see them completely *uninstall* it. 
Yeah I noticed that.
My favourite Base16 is [Mocha](http://i.imgur.com/OkRyzdC.png)
This is a pretty harsh reaction to a 3 line sample, and one that appears to not be an actual clang-format output (I suspect the person wrote down something from memory). I put that code block through clang-format with all default settings, but with a lowered column width to the point that it wrapped just the argument. Here is the result, which is pretty decent: void too_long_a_name::very_long_too( some_type p) { foo(); } As others have noted, there are tons of parameters to tweak, so if you want it wrapped differently, then you can do that. That said, there are times where I don't get results I'd like. I either learn to live with it, or I tweak the settings a bit, or I add the no-format command to the code there. Clang-format has also been getting a lot of improvements, where it learns to handle certain edge cases better. (Example: https://github.com/llvm-mirror/clang/commit/983e29fb810ac65bdfadd316ac5c67215f3e182b)
I've brought this up a number of times, but few people on my team seem to be receptive of the idea. Some even said they don't trust automated tools which modify code. We have big issues with our code as well, such as certain people preferring to use tabs over spaces for indentation.
I tried to do that in my previous company, but it would have been impossible to get close to what their existing code was, and more, there was no way to not get it to ruin existing code. In particular, there were lots of lists of fairly long enums: enum class Foo { thisIsPrettyDarnLongButExplanatory, notAsLong, somethingElse }; And there was no way to tell clang-format "one item per line please" which means that it tried to push as many items per line as it could - but that number was "usually 1, occasionally 2, or 3" making it basically unreadable. (You mentioned a way to disable clang for blocks? How is that done??) There were other things as well - for example modifiers like `static` and `virtual` tended to appear on the previous line as so: static int countWombats(); I never loved that format to be honest, but others did, and I did see the point of it (the method names were pretty long). To be honest, I might have been willing to do that just to have completely automated, canonical formatting, but literally everyone else on the team said no, and I think I was secretly relieved. 
There are scenarios in which a free user/company can use express but not community due to the different licensing. I doubt people would use it for any other reason. 
Yes - it will be in C++17
Yes my company is that pathetic. However even if the company would be smaller than 250 PCs and less than $1 million USD revenue there is another clause which comes into play. &gt; In non-enterprise organizations, up to five users can use Visual Studio Community [Reference: Scroll down to Usage for organizations](https://beta.visualstudio.com/vs/community/) And that is pretty strong limitation. So there is no hope for using community edition in a company.
That's a pretty good suggestion, thanks!
Not that it's particularly useful, but with some preprocessor magic I've used that trick to build an aggregate that names fields from a tuple. #include &lt;boost/preprocessor/control/if.hpp&gt; #include &lt;boost/preprocessor/facilities/empty.hpp&gt; #include &lt;boost/preprocessor/punctuation/comma.hpp&gt; #include &lt;boost/preprocessor/seq/for_each_i.hpp&gt; #include &lt;boost/preprocessor/variadic/to_seq.hpp&gt; #include &lt;iostream&gt; #include &lt;tuple&gt; #define ARG_MACRO(r, data, i, elem) \ BOOST_PP_IF(i, BOOST_PP_COMMA, BOOST_PP_EMPTY)() elem(std::get&lt;i&gt;(x)) #define ATTRIBUTE_MACRO(r, data, i, elem) std::decay_t&lt;decltype(std::get&lt;i&gt;(input))&gt; elem; #define ADAPT_FIELDS(...) \ [](auto&amp;&amp; input) { \ struct nested { \ nested(std::decay_t&lt;decltype(input)&gt;&amp;&amp; x) \ : BOOST_PP_SEQ_FOR_EACH_I(ARG_MACRO, _, BOOST_PP_VARIADIC_TO_SEQ(__VA_ARGS__)) {} \ BOOST_PP_SEQ_FOR_EACH_I(ATTRIBUTE_MACRO, _, BOOST_PP_VARIADIC_TO_SEQ(__VA_ARGS__)) \ }; \ return nested{std::move(input)}; \ } int main(int, char**) { auto thing = ADAPT_FIELDS(foo, bar, baz)(std::make_tuple(1, 2, 3)); std::cout &lt;&lt; "foo: " &lt;&lt; thing.foo &lt;&lt; "\n"; std::cout &lt;&lt; "bar: " &lt;&lt; thing.bar &lt;&lt; "\n"; std::cout &lt;&lt; "baz: " &lt;&lt; thing.baz &lt;&lt; "\n"; } Kind of a poor man's structured bindings
I'm dumb about modern C++... is that possible?
awesome. thanks.
we usually don't ship any editions except enterprise until RC. I'll pass this feedback along. offline install scenarios are still under development, but we are actively working on it. 
It's funny, so many people complain about iterator invalidation bugs, but after years of workin excessively with STL I have yet to encounter one. Makes you wonder if my usage of iterators is too conservative.
I'm a bit confused by your comment, but here is how I'd implement it: The functor returned by `get_` would be constructed so that it contains the function name (and a pointer to the client), so that when its call operator is invoked, it would call `client-&gt;call(stored_func_name_, std::forward&lt;Args&gt;(args)...);`.
Really sounds like a problem with your company, and not something MS could do anything about (or should do for that matter probably). Keep on convincing your manager :-)
The `rpc::client` class has a template member function called `call`: https://github.com/rpclib/rpclib/blob/master/include/rpc/client.inl#L4 It doesn't need to know about every possible ways it can be called, because that is always known at compile time. So the compiler will instantiate, say, `call(string, int)`, `call(string, double, double)`, `call(string, string, custom_type, int, whatever_t)` as needed by the calling code.
you could always clone this and chromium &amp; run the tests yourself
[onedark](https://github.com/joshdick/onedark.vim)
With C++17, you've got nested namespaces, so editors can pretty naturally do it on their own. That said, there'll be some confusion if you have namespace A::B { int foo(); namespace C { int fooHelper(); } }
Wouldn't it be more productive to use it and change your convention? You know it's subjective anyway?
Yeah I was just suggesting that adding iterator invalidation detection as an option (e.g. by defining a macro) would be an interesting project. Most STL libraries offer something like it in one form of another, so it is not unheard of.
I use the c++ program.
[tender](https://github.com/jacoborus/tender.vim) with [color_coded](https://github.com/jeaye/color_coded)
Look very simple and clean (at least API). I'm not sure how well it would perform with other libs (like others mentioned, I'd love some benchmarks!) but for some simple applications it's definitely something I would check out.
Hi there. I've got C++ Primer 5ed. It's the best introductory book I have read on C++. A perfect prelude to Meyer's masterpieces. You can check the "how much of the language it covers" by reading the table of content, for example via [Amazon's Look Inside](https://www.amazon.com/Primer-5th-Stanley-B-Lippman/dp/0321714113). By my experience, it totally worth the money, specially if you don't have previous C++ exposure. Don't be afraid for the "primer" it contains some advanced topics too. Edit: Somebody has taken the hassle and [published](https://github.com/Mooophy/Cpp-Primer) the responses to the exercises. 
The reason is that `decltype` has two uses: inspecting the declared type of a particular identifier, and inspecting the type of an expression*. These are two different things and they're needed in different contexts. The C++ specification's language is just its way of distinguishing `decltype(identifier)` and `decltype(expression)`. There's nothing special about parentheses, and in fact the spec doesn't need to say "unparenthesized _id-expression_" or "unparenthesized class member access". It could simply refer to _id-expression_ and "class member access", because if you surround an _id-expression_ or class member access with parentheses then the result is a _primary-expression_, and the condition "if `e` is an _id-expression_" no longer applies. I imagine they specify 'unparenthesized' simply because people usually don't expect parentheses to have any effect, but in this case they do (simply by changing which particular grammar production is used inside the `decltype`) and they wanted to be clear about that. As an alternative the committee could have defined `decltype` to only take an identifier or class member access and then defined another keyword like `exprtype` to handle general expressions. No one would be confused about why `decltype(id)` might produce a different result from `exprtype(id)`, `exprtype(id)` would be the same as `exprtype((id))`, and `decltype((id))` would be ill-formed. However, this would have required another keyword, which the committee is reluctant to add. Perhaps the next language to do "C++ but without all the warts" will have two different keywords for these two functionalities. \* Technically it's the expression's type with an appropriate reference modifier based on the expression's value category (essentially performing the inverse of what's done when an identifier is used in an expression: reference modifiers are removed and the value category is determined).
Ah! I think I have asked this question all wrong. I currently own C++ Primer and I agree it has been an amazing experience so far in learning different aspects of the language from it. Was probably quite a silly question because I should really research this sort of thing myself. 
Agreed on the benchmarks (it's on the issue tracker). It seems like a pretty hard problem though (to craft a benchmark that gives meaningful results that can be compared across the different libraries).
if `some_vector`'s size is `MAX`, then the access will be out of bounds if the loop didn't break early...
Huh? That would lead to compilation errors, semicolons inside parentheses are a syntax error anywhere except for in a `for`
Don't really buy this, the transpiler could make: { int i; for(i = 0;.........) { body } } without breaking the "crazy thing" you suggested, or anything else I can think of right now! 
It's not only for pathetic companies. I work at a place where we do "&gt;$1 Million US Dollars in annual revenue", we are 10 years old, and we never have been profitable (this is in a very particular area). Also, we are a public company. So we basically have to make reasonable savings when we can, and under certain circumstances using Express instead of Professional is absolutely appropriate (well, for us it helps that it is absolutely not our main OS and compiler env...) 
so what about a process with 12 threads? Where do the stacks grow?
Your code is a syntax error; a body for a pure virtual function can only be expressed out-of-line.
Simplest scenario: Write simple "echo" client and server with each library. Test time needed to send and receive 10 millions commands/results. Not best idea, but very simple and good to start with.
Seems good. Don't know how many times I just have code like this: bla bla bla... { auto v = bla.lock(); bla.blaa(); } 
The most important thing that libclang brings to KDevelop is *stability*. As a long-time KDevelop user, I would guess I have seen around 1000 crashes in the KDevelop hand-rolled parser `DUChain____` stuff (mostly endless loops). I wish that was an exaggeration. KDevelop 5 has been stable (for me).
reported... thanks :)
Your post has been automatically removed because it appears to be help/homework related. If this has been in error please message the moderators. *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Additionally, as the Committee considers it to be a defect report against C++14, instead of a true feature in C++17, we will be enabling it unconditionally (i.e. in /std:c++14 too). This didn't make it into VS "15" Preview 4, but will appear in the next build.
You mean like highlighting? Xcode does it by flashing the matching braces as you move your cursor past one of them with your arrow keys.
Ah, thanks! :D But I practice with a lot of different problem challenges. And for each task I want to save my code to compile and run it for later. How can I do that? I tried to create new cpp file in the same folder, but it seems like it always run the main...
Is there a link to the defect report? I thought this was part of the Ranges TS at first, which then got moved to C++17.
Let's say you are working on 3 problems, `task1`, `task2` and `task3`. You could put them in the same project as separate functions, then invoke whatever you are working on from `main`. The ones you are not working on could be commented out. int task1(int argc, char **argv) {...} int task2(int argc, char **argv) {...} int task3(int argc, char **argv) {...} int main(int argc, char **argv) { //return task1(argc, argv); //return task2(argc, argv); return task3(argc, argv); }
&gt;[**S4E02 Prezbo Soft eyes [1:23]**](http://youtu.be/OeGWnL_QJ9o) &gt;&gt; &gt; [*^The ^Wire ^Ph.D.*](https://www.youtube.com/channel/UClP9XW5ao88DlPocjFVTEyQ) ^in ^People ^&amp; ^Blogs &gt;*^6,644 ^views ^since ^Jan ^2013* [^bot ^info](http://www.reddit.com/r/youtubefactsbot/wiki/index)
Hot diggity that's confusing. It makes sense, but only in a particularly c++ standardese sense
The problem is that the `main` function doesn't know that `task1` function exists, because the compiler parses the file from top to bottom. What you need to do is forward declare `task1` above the function body of `main` //Forward declare task1 function int task1(); int main() { return task1(); //Compiler now knows that task1 exists somewhere } //Define task1 function int task1() { //Do stuff } Another option is to put the `main` function very last in the file. And as for this: &gt; `int argc, char **argv` This is optional, it allows you to access command line argument passed to your executable. 
is there a shortcut to close all?
Try /r/learncpp or /r/cpp_questions
&gt; The second terrible part of fork is that it forces terrible design decisions on the operating system The only thing that forced a design decision on the operating system here was the choice to support posix funtionality. Case closed. Nobody has to support fork if they don't want to.
It's true that a heap data structure can be used to help manage free store. Nonetheless, my understanding of the term heap is that it was used to refer to the free store in the sense of it being an unordered collection of data without a singular point of access (as opposed to a "stack" which is an ordered collection of data accessed at the top).
&gt; What I see now looks like it's going to be even better than what the old versions had :-) Visual C++ 4.0 with the "run from CD-ROM" option installs in just under 40MB. I think their current *installer* is bigger than that. (VC4 still installs and runs under Windows 10... and running the compiler off the CD-ROM drive is amusing.) 
But `(a)` is a happier expression. Look at those cuddly little cheeks.
Thanks STL. Maybe I'll stick with your gcc distro for toy things for now :) Kind of defeats the purpose of making it lightweight and be able to install the separate components if you need to install the other large ones to make it work. 
it's a real pitty they don't provide a windows build.
Brad Pitt is an actor and not a oscar winner. Brad Pitt and Leonardo Dicaprio are both men.
I use vi for small projects, and Xcode for something that requires organization.
[juCi++](https://github.com/cppit/jucipp)
Wow! This is amazing! :-D Hahaha!
There is support for qmake but not for a bunch of other Qt specific stuff. The custom signals/slots keywords aren't accepted yet, for example. [More info](http://kfunk.org/2016/08/23/whats-new-in-kdevelop-5-0/)
Yes, we're able to open qmake-based projects now. Just try it! If there are problems with resolving includes, you can always add include paths manually (you'll get a popup asking you to do so). This works like a charm.
Note though that in Qt 5.x, there is little reason to use the signal/slot keywords. Just use the new-style connect syntax, it's much better anyways.
So which is better now: kdevelop or qtcreator?
i think he means that you should add msgpack as an [external](http://stackoverflow.com/a/5205785) to your repo, so it pulls the original repo whenever someone clones your project.
You are right, but it doesn't stop redditors to downvote you.
It seemed to me that some posts in this thread imply that everything in the forked process has to know that there can be `fork`, and that it could be executing in the child or parent. I'm saying: no, it doesn't. Your five million lines of code need not know that there can be `fork`. Only the two-hundred lines that are involved in the actual forking. The others will just lay there passively and not hurt you.
Since Qt 5.7 there are ~~macros~~ [helper functions to alleviate this pain](http://doc.qt.io/qt-5/qtglobal.html#qOverload)
I still don't understand how it works. Aren't all local entities required to include encoding of all parent scopes and therefore all template arguments of type you are passing to lambda? At least in Itanium ABI.
By the way, in what situation do you even need to use decltype to inspect a type of an identifier?
But what about [Structure initialization](http://en.cppreference.com/w/c/language/struct_initialization) for your first example? The code below will work in c++03: struct S { int i; }; int main() { S s = {1}; return s.i; } 
was posted here yesterday by the author of the tool
Thnx
`task5` is supposed to return an `int` value. Your code doesn't return anything.
Edit: As /u/bames53 correctly points out: I wasn't up to date and only aware of an older decltype proposal that got changed on the way to the C++ ISO spec. Aren't there actually *3* cases? const int i; decltype(i) // const int (#1) decltype((i)) // const int&amp; (#3) decltype(std::move(i)) // const int&amp;&amp; (#2) decltype((std::move(i))) // int (#3) In decending order of priority (whatever matches first): 1. declared type of a variable/reference/data member (unparenthesized!) 2. declared return type of whatever a function call resolves to (unparenthesized!) 3. type and "lvalueness" of an arbitrary expression (*never* resolving to an rvalue reference) So, decltype treats top-level unparenthesized function calls differently and not as an expression in that it gives you the declared return type of that function whereas `decltype` in its expression mode (#3) does not distinguish between prvalues and xvalues (the identity aspect).
Don't be discouraged. If you are on Windows, you can download Visual Studio from Microsoft. I think they have a free version now, for students and people that want to learn or develop free software. In fact, most people that develop for Windows develop with Visual Studio. So try that instead.
You can connect to slack teams using an irc client if you'd prefer. The team admin only needs to enable the feature. 
I've seen an example: If you want to make a polymorphic lambda forward something to another function: [](auto&amp;&amp; x) { foo(std::forward&lt;decltype(x)&gt;(x); } In this case it's useful because we don't have a name for the declared type of x. That actually makes me want to use a macro like #define FORWARD(x) ::std::forward&lt;decltype(x)&gt;(x) to save some noise. And since C++14 (or 17?) you can omit the return type of a function auto blah(int x, double y) // return type omitted { // build and return result of a possibly complicated type ... return ...; } int main() { auto z = blah(1729, 3.14159265); // if you need the type of z, use decltype :) } 
`return 0;` should be enough. I recommend you to read through C++ fundamentals and tutorials: http://www.cplusplus.com/doc/tutorial/ http://www.learncpp.com/ 
I said macro but it's not actually one, it's a constexpr variable : template &lt;typename... Args&gt; Q_CONSTEXPR Q_DECL_UNUSED QOverload&lt;Args...&gt; qOverload = {};
If you have any question on silicon for your comparison, send me an email at mynickname@gmail.com. Also, you may want to check the teckempower benchmark implementations : https://github.com/TechEmpower/FrameworkBenchmarks/tree/master/frameworks/C++ It features implementations of the same benchmark with several frameworks. By putting implementations side by side, you can see how frameworks compare in term of readability, expressiveness, verbosity, etc.. The silicon version is here: https://github.com/TechEmpower/FrameworkBenchmarks/blob/master/frameworks/C%2B%2B/silicon/techempower.hh 
u still could fork the msgpack repo and link it as a tagged version of yours? (u can use a specific commit as external... it doesnt have to be HEAD)
No, it still "works". Note that it's an "object-like" macro, not a "function-like macro" ([ref](http://en.cppreference.com/w/cpp/preprocessor/replace)). #define for if(1) for for (int i = 0 ; i &lt; 10; ++i) is preprocessed into (just tested with GCC 6.1): if(1) for (int i = 0 ; i &lt; 10; ++i) Thus limiting the scope of `i` to the `for`-statement even on VC++6.
Nope, there is no case #2 as you outline it. `decltype(function(...))` will always be the same as `decltype((function(...)))`. Also decltype will return rvalue reference types when an expression is an xvalue. (lvalues turn into `&amp;`, xvalues turn into `&amp;&amp;`, prvalues turn into no reference modifier.) `std::move(i)` will return a `const int` and have the value category xvalue, so `decltype(std::move(i))` and `decltype((std::move(i)))` should both be `const int &amp;&amp;`. --- Edit: I just looked at [n2343](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2343.pdf), the paper originally introducing `decltype` and it describes exactly your three cases. However the actual C++11 spec is as I've described: &gt; The type denoted by `decltype(e)` is defined as follows: &gt; - if `e` is an unparenthesized _id-expression_ or an unparenthesized class member access (5.2.5), `decltype(e)` is the type of the entity named by `e`. If there is no such entity, or if `e` names a set of overloaded functions, the program is ill-formed; &gt; - otherwise, if `e` is an xvalue, `decltype(e)` is `T&amp;&amp;`, where `T` is the type of `e`; &gt; - otherwise, if `e` is an lvalue, `decltype(e)` is `T&amp;`, where `T` is the type of `e`; &gt; - otherwise, `decltype(e)` is the type of `e`. &gt; &gt; _-- N3337 [dcl.type.simple]/4_ It looks like the original definition of `decltype` didn't handle xvalues, and when that was added the special case for getting the declared return type of a function was deemed unnecessary.
I /think/ TIFF supports this, at least in the uncompressed case. I would try looking for a format where you can just memory map the file and then you don't need to worry about the ROI, since the blocking "load" call can complete as soon as the pages are allocated.
Why happened to just using IRC? Freenode's ##C++ might be one of the best channels out there!
No, real comparison should be with gRPC (http://www.grpc.io/about/)
The code navigation in KDevelop 5.0 is 100% accurate, even for complex template code, because it is done by a compiler. As a code browser, kdev5 is the perfect tool imo and I can unconditionally recommend it. It even does things like tooltips + highlighting for operator overloads: http://i.imgur.com/bP8Hrz8.png
Use the AppImage, that was built on CentOS 6. If you *really* want to build it yourself on CentOS 6, do the setup done in this dockerfile: http://files.svenbrauch.de/kdevelop-linux/Dockerfile and then something like this build script: http://files.svenbrauch.de/kdevelop-linux/kdevelop-recipe-centos6.sh But it will build things for ~10 hours.
We have some refactoring code (extract method, etc) lying around but it's not in the stable branch. KDevelop does provide generators for overriding functions and generating function prototypes, which are available from the completion widget. Just invoke code completion (Ctrl+Space) in a class inheriting from something, or in a .cpp file #including a .h file with unimplemented methods, and execute the "Override Foo" / "Implement Foo" item.
Whoa! Thanks for sharing that benchmark, it has everything I hoped for on such a framework comparison. You are amazing!
Off hand I don't know of any non-contrived examples of needing an identifier's declared type as opposed to an expression's type, but I would be surprised if there really are no good uses for this sort of introspection.
10k files should be fine unless your system has like 2 GB of RAM. We did have some performance problems whe people started loading the whole linux kernel into it, but that's more than 10k files. Try it :)
I don't see the problem with this group. Is not like the other communication channels are closed. To me this is increasing the reach of the C++ community to Slack.
You are correcto. 
Yes, but I see no reason to do that. You can't use the library without msgpack so all this would do is require an extra step for the compilation.
IIRC, this was not the case historically, but I don't know for which version exactly. Actually some old Express SKU did not come with a Windows SDK built-in, and you could write simple console programs out of the box. I hope I'm not remembering wrong.
Completely possible, and if I'm not it was probably only 2005 anyway...
**Company:** [FireEye, Inc.](https://www.fireeye.com) **Type:** Full time **Description:** We are building the endpoint agent platform that powers threat detection and mitigation across Windows, OS X, and Linux endpoints. **Location:** Charlotte, NC **Remote:** No **Visa Sponsorship:** No **Technologies:** Our product is comprised of C (kernel code), exception-denying C++98/03, C++98/03 using libraries like Boost, and C++11/14. We are focused on C++11/14/17 and modern libraries as we move forward. Python 2 is used extensively for test code. Other tools we use regularly are git, CMake, JIRA, and Test Rail. **Contact:** PM me here if you are interested or have questions. 
in the return type of a function template, e.g. `template &lt;typename A, typename B&gt; auto add(A&amp;&amp; a, B&amp;&amp; b) -&gt; decltype(a + b) { return a + b; }`
Yeah it is great to see departments of MS be so open and social. I know it is extra work for you all but it really is a fantastic service to people like myself. The development tools department is without doubt an example the rest of MS would benefit from emulating for such things. You have all been superb over the past few years compared to the decade of silence we had before ;)
Y'all are aware how confusing and dumb the year/version thing is, right? Also, seconding the thanks for staying engaged on reddit. :)
I am aware, which is why I'm careful to explain it whenever I have to talk about a major version before its year branding has been announced.
That's not inspecting the type of an identifier though, that's inspecting the type of an expression.
oh right, my brain skipped that part &gt;__&lt; nevermind then
&lt;optional&gt; was implemented and checked in by Casey Carter, but it didn't get into the compiler front-end and STL's development branch WCFB01 in time to make the Preview 4 cutoff (several merges from WCFB01 are required before code can get into the VS release branch). Even if it had gotten into the release branch, we realized today that we had forgotten to update the new installer's machinery to pick up the new header and put it on the user's hard drive. The next build of VS "15" will include &lt;optional&gt; with the new installer appropriately updated.
According to my knowledge, we're continuing to support that, yes. (I forget which branch it picks up the toolset from, since I have a WCFB01-centric view of the world; IIRC it's a release branch that's a few steps removed from where compiler/STL development happens. But changes will continue to flow into it as usual.)
Marketing-controlled version names are pretty universally a source of annoyance and confusion when talking about upcoming versions of products.
&gt;Specifically, VS 2015 and VS ‚Äú15‚Äù will have the same major compiler version (19) and their STLs will be binary-compatible So no EBO on by default it seems. What about those `iostreams` performance changes which couldn't be fixed before new VS release due to compatibility issues?
I figured out how to make iostreams floating-point parsing 17x+ faster, and shipped it in Update 2. [Read all about it here.](https://blogs.msdn.microsoft.com/vcblog/2016/04/14/stl-fixes-in-vs-2015-update-2/) You're welcome. (WCFB02 has a more aggressive version of the fix, ripping out tons of dead code, but that needs to wait for the bincompat break.)
Can't use any of this until CUDA works with the latest version of MSVC. Can you guys yell at them?
I keep my feature tables for the compiler and STL continually updated. I didn't publish them for Preview 4 because they aren't too impressive yet (adding just a handful of features since Update 3), but I expect to publish them for the next build. VS "15" is currently in a Preview state, and is not supported for production use (i.e. it does not have a "Go Live" license, which usually appears for an RC release). I believe that the quality of the compiler and STL is monotonically increasing, though.
&gt; (You might think, "but &lt;optional&gt; is a leaf header, who cares that it was voted in during the 2016 calendar year, you could still add it to the 2015 product". But implementing &lt;optional&gt; has exposed compiler bugs which we've needed fixes for.) And then I might think, "but wouldn't I want an update for bugfixes anyway?" &amp;nbsp;&amp;nbsp;^;-]
Emacs and xcode installed clang++. Sometimes I use Mac Ports LLVM too.
Yeah, I was hoping that VS "15" would be that big milestone "throw everything away and start anew (figuratively speaking)" VS release. Like with all the bincompat breakages, with proper new compiler and all other goodies. And I think everyone got used to every new major VS release being incompatible with the previous one in one way or another (irrc, MS broke bincompat between minor version too sometimes). While VS2015 is great, making VS "15" release compatible with it could bite users later than proper major WCFB02 is released, since it'd be much harder for people to move.
I can bench*mark*...
JSON would be a bit unintuitive. You don't have the names of the members that correspond to the values, so you would need to use a JSON array instead of an object.
`decltype(std::move(i))` and `decltype((std::move(i)))` are the same. Redundant parentheses make no difference here, the only special case is when the argument is only an identifier (perhaps with a class member prefix). 
pcl (point cloud library), wonderful library, great features - packed full of C99 so it doesn't port to vs2015
Make a game on your own time, with at least 15 minutes of game time in it. Show it off to people. If it's good, most places will hire you on the spot after looking at it. Also, modding existing games is a great way to be able to show off a complex finished project without needing to do everything from scratch.
I don't know the details, but I don't think so. For having tested it a while ago, I do know that MSVC will happily generate a local type based on the unique id of the lambda, which is very short. Clang and GCC, however, still include the template parameters in the name if I remember correctly.
name one company that doesnt do this..
how much does Mark weigh?
changelog of which version it breaks bin compat with would be nice.
Back in the day I used chilkat for ftp, yuck. It works, but closed source.
just announced 1 day ago: https://www.reddit.com/r/programming/comments/4z7qdf/grpc_is_now_10_and_ready_for_production/ that would be nice target to run against... 
Have you tried using the clang with msvc codegen toolset for that library? I imagine that should fix the problem!
OpenSSL. It's a complete mess, or it was back in about the 1.0.0 times . Security problems everywhere, abject lack of documentation. There are much better options. 
Qt. Poor performance on windows and buggy apis now owned by a contracting outfit slowly modifying licensing to force you to pay for it again...
Seriously. I don't know why people on /r/cpp love their std's so much.
What do you think is the best way to write a cross-platform GUI if you still want to write lots of code in C++? At this point I lean toward HTML5. But then again, I hope I never have to make another GUI for as long as I live.
I'd say fltk
With every release, they move some formerly commercial-only modules into the open-source distributions. Qt 5.5 got Qt Quick Enterprise Controls, Qt 5.7 got Qt Charts, Data Visualization, Virtual Keyboard, Purchasing and the Quick 2D renderer. Qt 5.8 /5.9 will get the Quick Compiler. They renewed their [licensing deal with KDE in the beginning of the year](https://blog.qt.io/blog/2016/01/13/new-agreement-with-the-kde-free-qt-foundation/) to bring the licensing of Qt more in line with the philosophy of the Free Software movement. So, how do you feel they are bugging you into a commercial license?
Yeah, it generally forces bad C++ on you. Lots of casts, outdated inheritance patterns and that memory management nonsense. But I'd like a comment from someone in the game business because from what I've observed this seems to be the industry standard, like "vanilla C++ is unsafe and error-prone so we have to work around it". 
Fuck I had forgotten about chilkat.. those are some memories I didn't need back
You will find many technical books are generally a nightmare on kindle.
A language is a tool used to tackle a task. As all tools there are some that work better for some tasks than others, so it is always a good idea to have several in your mental toolbox. I personally like C++ as it allows for a wide range of different approaches to a problem, all built into one language. That makes it a extremely powerful language to use, but also one that is rather hard to learn. If you embark on the quest to master C++ one year should get you to a level where you have a basic grasp on the language and won't embarrass yourself when applying for a job:-) To learn the language I would look for a book covering C++11 (or even 14 if you can get one). Then I would recommend to look for an open source project with an established code review process and start to contribute to that. The review provides invaluable feedback from more experienced programmers on your code and you will pick up additional skills (source control, working with bug trackers, etc.) along the way.
Yeah, I saw it. A bit unfortunate timing on my part. 
Think about what kinds of programs you want to write. Based on that, choose an appropriate language. Learning a language just for the sake of it is pretty boring, and very hard to follow through on. * Do you want to write web applications? Javascript for the browser side of things, Javascript with NodeJS or Python for the server (if you need a server-side at all). * Do you want to write Windows GUI applications? C# is probably the best way to go. * Android or iOS? Java and Swift respectively. You can use C++ under the hood here, but that's more of an expert topic. * Do you want to write your own Linux commandline/GUI tools (web scraping, utility tasks, ...)? Consider Python, Ruby, Go for the an easy start. You can use C++ here, but I'd only consider it for larger, performance-critical applications. * Do you want to write your own operating system kernel, your own high-performance database engine, or other low-level system tools? C++ is the way to go. C++ allows you to write applications that are more or less impossible to do in other languages. It comes with a price tag though. C++ is a very complex language and "ease of development" is not one of its strengths. So pick a language that facilitates the kind of projects you are interested in doing!
For me it's Poco. It's poorly documented and what is there is vague. The behaviour is often not intuitive and that's before you encounter their bugs.
&gt; And finally if I invested 10-20 hours per week for the next 12 months C++ is not a gig. It's a career. I personally love it. It's a complex but beautiful language where mastering the complexity is rewarding. You will understand computers better if you learn C++, than if you learn Java. If you understand C++, you will understand the underpinnings of Java. If you understand Java, ... Well, you *can't* really understand Java, without understanding at least C. C++ allows you to have finer grained control, and to express yourself more than Java. Java feels constricting to me. Then again, if you want to benefit from the ability to express yourself, you need to have something to *express*. This means you need an advanced understanding of the language, not intermediate. You won't have an advanced understanding of C++ in 12 months. Intermediate, with 10-20 hours per week, yes.
It seems likely I'm not getting a joke. But just in case OP might interpret this literally &amp;ndash; "soul-crushing" is not an adjective I would use, and work in C++ is useful and well-paid.
VTK. It's really powerful and feature-packed, but here is how to [display a simple cube](http://www.vtk.org/Wiki/VTK/Examples/Cxx/GeometricObjects/Cube) ; besides, the bugs are numerous and many things didn't work as advertised in my experience.
Damn, property trees seem like a good idea on paper :( But yes, and I think that many libraries would benefit from foregoing the 1990s borland compiler-specific hacks... it would make the code immensely more simple and readable
The licensing has changed many years ago.
Totally agree! Hint: every time you want to use wxWidgets - just forget about it and use Qt. Works excellent in 100% cases.
Shouldn't you regret using MSVC instead?
 Any chance std::variant makes it into the RTM?
Thanks for digging this up! I guess I must have looked at an earlier version of the decltype proposal only. You're right about #2 being unnecessary if the "expression mode" also gives you rvalue references for xvalue expression.
It has been implemented, again by Casey Carter, and should be in the next build.
/r/cpp_questions
Is the name still optimized if the struct is named? I assume it would also be possible to use anonymous struct, with all the restrictions this implies (only aggregate types).
The best defence is a good offense. Write your code so the UI can be replaced. I had to do this and converted a HTML5 interface to native which would not have worked had it not been for a good design.
MFC, hands down the worst API ever. 
well, I spent hours on this and still could not.
Thank you, I've considered using PCL in the past. I'll stay away from it now. It's a shame it doesn't even work on VS2015.
From the code, it looks like it draws the control with the style information from the operating system : https://github.com/qt/qtbase/blob/dev/src/widgets/styles/qwindowsstyle.cpp https://github.com/qt/qtbase/blob/dev/src/widgets/styles/qmacstyle_mac.mm Also, see : http://www.slideshare.net/qtbynokia/how-to-make-your-qt-app-look-native
I think it might be even worse than that. If I remember correctly, GCC 6's implementation of *random_device* defaults to using the Intel *RDRAND* instruction when available, which we have every reason to suspect has been backdoored by the NSA.
Right but doesn't mean it's a native control. I'm looking at the code and it's just drawing the button on a bitmap. It's not using `CreateWindow`.
Probably related to this bug: https://gcc.gnu.org/bugzilla/show_bug.cgi?id=63809
Apache Axis C++ for SOAP (plus a wrapper library for it). Hard to deploy, people on the team are angry because it needs your application to be compiled as a library/plugin. So now using KDSoap for that.
unfortunately that wasn't a flexible parameter. It's also not a c++ library!
A lot of people (usually from India) still use Turbo C++. It's infuriating.
I swore to never use it again!!! Basically MFC is lame on purpose. Microsoft could have done the best toolkit in c++. They just chose not to, for other purposes.
This is one good example of a library that desperately needs a C++14 wrapper. I guess with some clever use of metaprogramming some polymorphic cases would not even have vtable runtime overhead.
I stand corrected. I confused this with creating objects using factory functions, which IIRC is the standard way, not new. 
What I found fascinating with Boost::graph is that to get 3 vertex, 4 edges and compute something trivial like a MST, I had to go through 4 hours of tutorial
Not completely regret but ImageMagick. It's a great library but it has some horrendous leaks
I'm just saying it's strange to regret using a good library when the problem is in your broken compiler.
Sadly, you got the wrong C++ Primer. "C++ Primer Plus" is a cheap attempt to cash in on the popularity of "C++ Primer" and is totally unrelated. "C++ Primer 5th edition" is highly recommended.
If you want to add something new to your VTK-based visualization, you usually have to dig around 30 mins+ in the reference documentation and take a guess which method/class does what you want - then, after another 30 mins of trying to get it to work, you notice that you have to add some other kind of filter/mapper/etc... to the pipeline before being able to use the new feature. Furthermore, if you have a specific problem it's almost guaranteed that you won't find somebody else who posted the problem (let alone a solution) on the internet. Nevertheless I don't know another library with a comparable feature set.
open scene graph. 
If you are using Qt, you can use the [QCommandLineParser](http://doc.qt.io/qt-5/qcommandlineparser.html). But since you do not mention Qt, this is probably of little help...
I have found [Boost.Program_Options](http://www.boost.org/doc/libs/1_61_0/doc/html/program_options.html) to be both flexible and easy to use. However, before doing a rewrite, have you considered keeping your tool in Python and writing the performance critical part in C++ using Python's FFI? There are a few [tools](http://docs.python-guide.org/en/latest/scenarios/clibs/) to help you with that. 
A control is much more than just its visual, it has behaviour (and animations, etc). I can‚Äôt comment on Qt specifically but cross-platform UI frameworks have mostly gotten this wrong in the past. Java‚Äôs Swing is a particularly terrible offender in this regard. Using native controls obviously comes with a lot of baggage but it provides the best UX because it behaves 100% consistently in the way that the user expected. Furthermore, even just getting the visual correctly is really, really hard. I‚Äôve emulated Windows XP controls (and several iterations of menu styles) myself back in VB6 and later in .NET, and they fail in countless ways. And none of the many libraries I tried ever managed to anticipate an OS upgrade that changed visual style (even if just slightly). Even Microsoft itself got this wrong: several of the first versions of Visual Studio drew their own container controls and had subtle visual errors around the borders that their own QA team missed. They were reported by a friend of mine (and subsequently fixed).
here is a stackoverflow thread http://stackoverflow.com/questions/1600399/are-c-libs-created-with-different-versions-of-visual-studio-compatible-with-ea Some parts may link
To answer your ninja-edit (:p), honestly, on Windows there is no such thing as native anyway; even MS's "latest and greatest" in-house technology for making Win32 apps, WPF, [doesn't use native controls](http://stackoverflow.com/questions/16251670/are-native-windows-controls-still-used-in-net-guis).
WPF can‚Äôt use native controls because (like Java‚Äôs Swing) it supports operations that aren‚Äôt supported by Windows‚Äô native controls (at its most fundamental, the fact that it uses vector graphics and uses DirectX rather than GDI and hence supports zoom). IIRC WPF was originally meant to completely replace native controls. Of course this *completely* failed.
[This library](https://github.com/Taywee/args) was posted some time ago and it looks interesting. 
[Boost.Program_Options](http://www.boost.org/doc/libs/1_61_0/doc/html/program_options.html) if I already use boost. All other cases, it's this header-only library: [cxxopts](https://github.com/jarro2783/cxxopts.git).
Exactly that! cxxopts is simply a much lighter version than boost po. Unless you already boost, I would strongly advice using cxxopts. 
You ask this in the C++ forum, so the answers you get will probably be a bit biased :) Broken analogy time: consider web development being similar to a hand-held drilling machine: easy to use, compact and you can do a lot with it. C++ and Java compared to that would be more an industrial drill: more difficult, requiring specialized knowledge and requiring more training but much more powerful. In web development you can do quite a lot without touching on algorithms, compilation and API design, refactoring (among other things). If you want to move to C++ or Java _because focusing on html, css, javascript, php, etc is too much_ then just algorithms (or just API design) **may be too much as well**. Another thing that may not be visible from where you are looking is that you have at least two parts here: learning the language and becoming proficient with it. This is a bit similar to the difference between learning a foreign language and being able to write a captivating novel in it. Learning the language is easy. Using it properly can take years. If you invest 10-20 hours per week for the next year, at the end you will be a beginner ( not in your list :) ). After this you will need experience - and lots of it, before you become ... well ... experienced with the language :). This applies equally to C++ and Java, but Java has a fewer quirks. That said, you probably would be able to get an entry level (or maybe even decent) job using C++ after a year of this, but do not expect gaming industry/performance critical/life support systems stuff. On this then, you will need to learn the other 1001 details needed for an IT job (managing your development tasks, writing maintainable code and following coding conventions, debugging, documentation, estimating your effort, working in a team, source control and so on). You can learn these by trying to use them in your project, by following tutorials and so on). In short, you are on the right track for this, just don't expect that 10-20 hours per week for a year will bring you to the end of the journey.
&gt; wxWidgets [...] native widgets. I thought this would be great: native L&amp;F for users, efficient drawing, low footprint. Well, all this is indeed true and wxWidgets remains the only library to provide native L&amp;F, to the best of my knowledge. &gt; wxWidgets has a horrible API This is arguable. It's definitely not as good as it could be, but I know of only a few examples of classes with really bad API. I wonder which one(s?) did you have in mind? &gt; It basically started as an MFC wrapper called wxWindows This is not really true. It was "inspired" by MFC but was never a wrapper for it and was a cross-platform library ("wx" == "Windows and X11") since the very beginning. The name was changed only because of a threat of a lawsuit from Microsoft and is completely irrelevant. &gt; I also realized later on that it wasn't doing native widgets on some platforms: it was using its own custom-drawn wxUniversal implementation, especially on GTK and OS X. Sorry, this is not true at all. There are a couple of widgets that simply don't have native equivalents, but all the usual controls are implemented natively in all major ports (MSW/GTK/OSX) and wxUniversal is something completely different and not used at all on any desktop platforms. If you've managed to somehow build it, I understand your disappointment.
Good points. I should have noted that I'm not looking for high end critical job opportunities. As long as I just get in with a company and then just take it from there. Also, I have watched a few YouTube videos and quite a lot of people said algorithms would be used to an extent but not heavily. Only of you're programs really depend on that stuff. Which probably in a company setting they expect you to know them.. Now, on the other hand, you mentioned web dev and I agree. In fact, in my case it would probably make more sense to do web dev currently as it can bring in money faster since there are a lot of freelancing jobs available for it. But for some reason, and (I don't know why) I feel like I should do C++ or Java. Anybody been in this boat before?
I agree it's a career. And that's why this early in my learning stage I want to decode firmly what I want to do. That way I can just focus and practice. With whatever language I go with, I definitely want to make it into a career.
Read the sidebar...
We're using the Templatized C++ Command Line Parser Library - [TCLAP](http://tclap.sourceforge.net/). Header only, MIT licensed. 
does it allow serialization to a class (without implementing the boilerplate yourself)? For example, in Newtsoft Json.NET (obviously c#), you can specify the variable names and types as they correspond to the Json and you get a struct/class of the members. Obviously as C++ doesn't have reflection the usage pattern wouldn't be the same even if they did. IMO dict like access is not the most useful (although the api looks much nicer than the mongocxx driver format of collection["var"].get_utf8().value.to_string())
Boost program_options, have been using it for years and can definitely recommend. Had I to chose again, I would most likely go for a header-only non-boost solution though! Maybe this one https://github.com/Taywee/args or this one https://github.com/docopt/docopt.cpp or this one https://github.com/jarro2783/cxxopts ... something that supports VS2015, clang and gcc. And multi-options (like multitoken and `vector&lt;path&gt;` arguments like boost::po).
I had the outrecuidance (looks like this is an english word indeed) to tell this to Eric Niebler once after he validated a bug report; he replied me that if I was unhappy with the software I just had to improve it myself, since, you know, it's open source. I guess that's what they mean when they say that because you are right it doesn't mean you are not being an asshole?
Well, neither Qt nor wxWidgets are UI libraries, they are application frameworks, providing you with most things you need. UI might be a big part of it, but both also support non UI applications such as servers. Both have multi threading, containers, sockets, ... Archives is one of the few things which is only supported by wxWidgets. I know, its a corner case.
Technically, it doesn't: this isn't allowed by the C++ standard, it just compiles. UB declared by the standard and UB declared by some class author, are fundamentally different. For starters: everybody knows that it is UB to use a pointer after delete, so people take care to prevent that and there are tools to detect that. But to know that use after move is UB, you have to look at the documentation of that type. And if we follow that argument, C++ has no type safety at all because it isn't Rust. But I could be more precise and say that before every object created without violating C++ rules was valid but now thanks to move semantics, there is a way that doesn't violate the C++ standard to create an invalid object.
Is wxWidgets that bad? I've found it easier to learn and easier to build than Qt (mainly since Qt dictates your build tool).
Worst library ever you say? Trying to get the Stun/Turn client/server running for a client years ago, using the implementation of resiprocate.org: https://www.resiprocate.org/ReTurn_Overview It was not really meant for our use case, which had nothing to do with VOIP. The library also came with an old version of boost of its own, and nearly no docs, except one example.
If you're using indices as names, then you might as well use an array. You can have an array of arrays just fine. Anyway, this is definitely a hack until the Reflection TS pulls through, but it's a really cool hack.
Part of the problem I have with some of the boost libraries is that they're complex enough for you to doubt yourself when you find a bug. I don't usually have the time to spend hours to figure out if I'm truly messing up or if it's just a bug.
I have a C++14 wrapper around `vtkUnstructuredGrid`. You just need to: vtk::writer&lt;Nd&gt; writer; writer.push_back(cube); writer.push_range({triangle0, triangle1}); // ** writer.write(file_name); // writes unstructured grid to vtu file // writer.draw(window); // draws the primitives to a window The main problem is that even working with VTK primitives is weird (due to the class hierarchy, static methods for construction, ...), so I ended up writing my own geometry library and mapping between my types and the VTK ones in the writer. I don't think it would be easy to offer a full C++14 API over VTK, because... it just wasn't designed that way. ** This could be nicer but its not worth the trouble. Some geometric primitives like cube can be ranges of e.g. vertices, faces, or edges... So one needs to differentiate between types of ranges...
&gt; I moved to Win32 API. Why would you do this to yourself? It's only slightly better than MFC, and with all of the old C-isms from when it was built.
Moc is just a boilerplate generator, and the tooling for integrating it in the build process is quite alright imo. You could use CopperSpice instead, I guess, but Qt is the best/least bad choice still.
Oh! For some reason I always assumed that the objects in JSON arrays all should have the same type! TIL! (In retrospect, that doesn't make sense!)
Not C++ though :-)
How do you package your .exe? Just put it into a .zip file?
I don't know of any simple way to know which libraries are in maintenance mode, is there one? Also, I think it would be nice to officially deprecate the features that are not widely used and age badly (I spent a lot of time trying to work with subgraph, but it is an experimental feature that should be presented as such). Anyway, you have my wholehearted support for a modern rewrite of this library :) Regarding the use of property_tree as a json/xml parser, I don't think I am insane per se, but that's the problem with users, they don't know what's inside the library until they have actually used it. You get a lot of results when searching for "json parser boost", and they all point to property_tree. With hindsight, all it says is that there is no proper json parser provided by boost, but I kind of assumed there would be. Is *that* insane? I know now that it's wrong.
Well - I used it with a C++ program. Fair point though.
&gt; At the bottom of it you define macros for try/catch/throw. At the bottom of it I define macros for restartable/restart_case/invoke_restart. &gt; You also seem to use thread_local for many things. Why? Many?!! Only for the one thing, for the pointer to the stack of signal handlers, which is living on the call stack. Since each thread has own call stack, no wonder why the pointer to the top of the stack of signal handlers is thread_local. &gt; At a glance, I have no idea what you are trying to do here because I don't know Lisp I wish I didn't mention Lisp in the header, because restarts are not an exclusive feature of Lisp and the word "Lisp" seem to scare seeplasplas-coders. If you want to get an idea, visit the second link in the README, there is no Lisp there.
Don't you have to use qmake to build your project? Edit: What I meant was that it's much harder to compile Qt apps without qmake or qtcreator.
That's not necessarily true. Generally with LGPL you can link statically as long as you distribute object files so that users can relink you application against their own qt build.
Xerces, Apache's XML library. All I needed was the ability to write and read little XML files for internal use. Xerces is big. Ridiculously big. And heavy. Reallllly heavy. Ohgodwhy...
Yeah of course, but I'm assuming we're talking about the object.
&gt; big. Ridiculously big. And heavy. Reallllly heavy. Sounds a bit like XML... ;-]
Qt
I do not understand why people complain about moc.
Unless I missed something, the documentation is very unclear when it comes to not using qmake or qtcreator. I might try out Qt again though.
What? Seriously? I still shudder at the thought of having to inherit everything from RWCollectible and put it all on the heap.
One issue I have with QtCreator is that many template types aren't identified properly, especially return types of methods from the standard library. So you can't use auto-completion with them.
&gt; socket my_socket(‚Ä¶); &gt; socket your_socket(std::move(my_socket)); &gt; do_sth(my_socket); I mean, this is why you generally *don't* use std::move. If you hadn't, the compiler would recognize that it needed to use the copy constructor instead of the move. I don't think pointing out a manner by which you can over-engineer a solution that produces a bug counts as "move semantics weakening the interface guarantee"
Just use PySide or PyQt, in that case. Much easier than putting a message queue between them.
I used cmake, but I did need to add a special MOC line to the cmake script to generate the mocs (and then add those mocs to the build). Other than that though it was a painless experience. 
&gt; Adding the two move operations was a bad idea and is a breaking change. How is it a breaking change? The example code you provided wouldn't have even compiled without the move operators. Writing code after the fact that doesn't logically maintain invariants is not the fault of the type implementing the move operators. Regardless of what the `socket` move operators actually do, what do you expect socket my_socket(‚Ä¶); ‚Ä¶ socket your_socket(std::move(my_socket)); ‚Ä¶ do_sth(my_socket); ... to even mean? Somebody had to write that code and had to think it meant something. Whatever they thought, they thought wrong. The fault is not that somebody implemented `socket` move operators, the fault is that somebody used `std::move` without understanding the implications. I think of `std::move()` as a necessary evil -- sometimes you need it but refactoring the code to avoid it entirely is usually a better solution.
Yes, that is what I meant. But if I remember correctly vectors of basic types weren't a problem, rather more complex types like map iterators, tupels etc. I think the clang code model did a great job in general when I tried it but its performance (time to update highlighting etc.) dropped rapidly with many includes and lines of code in a single file.
Just recently, I have started writing a command line parsing library for C++, [here](https://github.com/pfultz2/args). It requires C++14 and is single-header right now. It uses the visitor pattern, so commands are written like this: struct cli { int count; std::string name; template&lt;class F&gt; void parse(F f) { f(count, "--count", "-C" args::help("The number of times name is printed")); f(name, "--name", "-N", args::help("The name to be printed")); } void run() { for(int i=0;i&lt;count;i++) std::cout &lt;&lt; name; } }; int main(int argc, char const *argv[]) { args::parse&lt;cli&gt;(argc, argv); } Also, subcommands are supported as well, and can be written like this: struct cli : args::group&lt;cli&gt; {}; struct init : cli::command&lt;init&gt; { init() {} void run() { std::cout &lt;&lt; "Init command" &lt;&lt; std::endl; } }; struct delete_ : cli::command&lt;delete_&gt; { delete_() {} void run() { std::cout &lt;&lt; "Delete command" &lt;&lt; std::endl; } }; int main(int argc, char const *argv[]) { args::parse&lt;cli&gt;(argc, argv); } It still a WIP, so its lacking docs and a few more features. 
&gt; The layout API is a buggy mess, and you cannot hide a widget. I'd never defend the layout stuff, since it can be a real nuisance,but what do you mean by the second part of your statement? `QWidget::hide()` and `QWidget::show()` do exactly that. If your problem is how that shuffles the layouts around, that [was fixed in Qt 5.2](http://doc.qt.io/qt-5/qsizepolicy.html#setRetainSizeWhenHidden).
Learn C or C++, not and.
I assume that somebody wants to move the socket and then accidentally reuses it.
There is no Boost multi-map ‚Äì what library are you referring to? Boost.Bimap, Boost.MultiIndex, Boost.MultiArray..?
PySide doesn't support Qt 5 though. :( I'll probably look into PyQt, but QtCreator probably won't help me as much there as with C++ Qt, will it?
&gt; I assume that it was written after move semantics are added. A "breaking change" cannot break code that has never been (and never _could_ have been) written. The move operators themselves are perfectly legitimate and don't break a single thing. Yes, you're potentially introducing a new "moved-from" state for the object -- but that state is only externally observable _iff_ you invoke `std::move`. Structure your code to leverage move semantics without invoking `std::move` and everything is beautiful and nobody ever gets hurt.
&gt; The move operators themselves are perfectly legitimate and don't break a single thing. No, I agree with the writer. By adding the move semantics, you've added a new possible state for `my_socket`, "empty". This new state means that all the old code - which breaks on the "empty" state - needs to be updated. Now all clients of `my_socket` need to check for "empty" before calling any methods on it! This change _does_ break code elsewhere. I'm not at all seeing why you think this isn't so. 
It's undefined behavior. By that definition of "allow", C++ "allows" you to do all sorts of terrible things that will result in unspecified but potentially very bad behavior. Nearly all the time we're trying to generate well-formed C++ programs with no undefined behavior so in practice that sort of behavior is "not allowed" - by careful programmers, not by the compiler.
In some sense this is quite logical. But then you're going to need a rule of... seven or eight...! This means potentially three types of constructors: * Copy constructors * Move constructors * Destructive move constructors And complexity issues fanning out everywhere. I think this is too much...
It should be uniform, but not dependent on the OS.
&gt;Structure your code to leverage move semantics without invoking `std::move` and everything is beautiful and nobody ever gets hurt. I totally agree to that statement. But C++ currently isn't protecting you from writing code that uses std::move in a breaking way, and that's my point. Move semantics make a hole in the type system, know it is your responsibility to ensure that you make no mistakes. 
&gt; This change does break code elsewhere. I'm not at all seeing why you think this isn't so. that's because you're talking about something unrelated
[PySide2](https://wiki.qt.io/PySide2) does, though. I'm not sure how far along they are for full support yet, but it's been made real citizen, at least, and they're working on it. I think my corworkers use PyCharm for all their work, which includes PySide. I'm not sure how much tooling there is, though.
Looks... Quite raw. :(
I think what I'm saying is I would've liked to have seen the second half of your post focus on avoiding `std::move` rather than "moved-from" states and default constructors. The onus for correct code is on the guy who ignorantly types `std::move`, not the guy who (safely) adds move operators to a class that didn't have them before.
Qt however gets often into uncanny valley territory, where things mostly look and feel right, but are a bit off. Also on OS X all the tab animations are missing and there is not reasonable way to implement them. So when using Qt I actually prefer for the app to look somewhat different, it's really not such a big deal (and lot of pro apps do it), as long as the controls look sane, polished and recognizable.
Our Filesystem TS implementation is part of the STL's DLL, msvcp140.dll, which is linked implicitly. WCFB02's Standard Filesystem implementation will also be part of its STL DLL (name to be determined), so users won't have to take any special action. And static linking will continue to be supported.
Yeah, I'm not quite happy how the post turned out
There isn't, but that's not relevant.
He's talking about the point I tried to make, albeit I did it poor. /u/mcmcc is talking about something else.
Yes, I think so, there's limited overlap--and the newer books mostly build on top of the older (as opposed to replacing them. Scott addresses this in the aforementioned blog post (https://scottmeyers.blogspot.com/2011/03/effective-c-in-c0x-c11-age.html).
Any code that calls any method on `my_socket` without checking for this new state, "empty", is now broken. So this means _if you are writing a library_ then your code is definitely completely broken. Your code might not call `std::move` but a client of your library might, and you have no way to prevent that. --- That should be definitive - I don't have to prove it's broken for every possible programming task, just one very common one. But honestly, even if you're talking about one binary, I consider the code to be broken - or at the very least, there's a serious trap that needs to be documented in big red letters. What you're saying is that code is correct today, but if anyone at any time later in your codebase ever uses a move on this class - and not all moves use `std::move`, you know - then all the code becomes broken - silently and invisibly and perhaps by something very far away in the code. If I'm using a class, and there's a potential and valid state to that class I do not check for and which would lead to undefined behavior, I consider this a defect - even if today there is no code that leads to that state. There is plenty of production code of mine that's over ten years old floating around in use today, and I believe this attitude is a good part of the reason why. (And no, I don't have "empty" checks everywhere. I typically have one at the top level, and all other code, which can't be reached from the outside, has the precondition of "not empty".)