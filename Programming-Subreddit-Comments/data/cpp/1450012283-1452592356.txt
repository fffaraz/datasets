&gt; (for example, if you are developing a library, a Boost dependency is undesirable). why ?
Because it adds a big-ass dependency to your library. If someone wants to use your library and are not already using Boost, they will have it as a dependency now (or most likely, they will choose a different library that does the same thing without Boost).
This big-ass dependency is one package manager call away on *every* OS...
Now you have three dependencies: Boost, Nuget and VS (if nuget integrates with VS in C++ projects already. If it does not, then you still need to integrate the library into your build process manually so it's not much better than unzipping it.) A library is not like a standalone application: setting up the build environment is *not* a one-time thing. You are imposing the cost of setting up the dependencies on everyone who wants to use your library and now their software transitively carries the same burden that yours did. All hoops they need to get through to build the library will decrease the chance of them using it (both because it sucks fiddling with the build process and because they don't want the same for their library). Keep in mind that this is in answer to your question regarding why Boost is undesirable as a dependency for libraries. I'm not against Boost in general and not even against it for libraries, if it's justified. In answer to your edit that I saw after I posted my comment: &gt; besides, weren't we talking about a header-only dep ? Yes, it is header only, but it's not like you can just copy string_ref.hpp and be happy. It depends on lots of other headers and it's not trivial if you choose to deploy it with your library. All because you need a relatively simple class you can use.
Is it really true that most compilers only activate the auto-vectorizer at O3? No auto-vectorizer at O2? That's really surprising to me.
Well, the nice thing is that the string literals are evaluated at compile time. This means that only the shortened string need to be stored in the binary. I don't have energy right now to put something together, but you can test out g++'s assembly output with [Godbolt](https://gcc.godbolt.org/). I'm rather certain only the necessary parts of the strings will be stored in the binary.
What's with the const pass-by-value arguments?
This was something I use to do in my code *all* the time just to enforce some kind of const-correctness in my code. If it's not meant to change, enforce it! It was until recently that I thought more about it and thought that it probably doesn't really matter, so I no longer do it.
Well, it could make a difference. Read the top two answers to this question, https://stackoverflow.com/questions/136880/sell-me-on-const-correctness. It's a similar practice for thing such as: if(nullptr == myPtr) vs if(myPtr = nullptr) Things like this make the intent of your code clearer.
I recently discovered an issue where MSVC produces the right result, libstdc++ silently fails and libc++ throws an exception. As somebody who's been anti Microsoft since the mid 90s, I have to say I was impressed.
That's exactly why we wrote CTTI https://github.com/Manu343726/ctti, which does the same trick but at compile time
Yes in theory, but if you use a sufficient warning-level (which you should anyways), your compiler will complain about it one way or another.
Function implementation maintenance - when a parameter is const, you know it's not being changed inside the function. Same as doing void f(whatever) { const type var(blah); // var doesn't change inside f ... } As [the other guy said](https://www.reddit.com/r/cpp/comments/3wq7gv/advice_use_list_initialization_and_constructor/cxyhndo), the inconvenience is that this becomes part of the function interface, which is noise, and can also lead to an interface change (say that you need to modify the value later). So it can be useful a little bit, but it's also inconvenient. I personally don't do it and wouldn't like guidelines that require it much. 
This is really cool, thanks for sharing.
&gt; For example, we can use any of the following four different ways to define an int variable named example_int and initialize it to 0 : Five actually: int example_int{};
&gt; What if packets drop? they drop! thats why using UDP is common for streaming where some data lost does not matter much. however, if you use UDP for something else you must come with your own schema of counting and accounting for loss and what to do. TCP send acknowledge on each package. 
It is an immature library but it performance is excellent. Please check it out
Seems limited to me as you have to declare the structure beforehand. Also i don't see support for optional and null values. Also why a modern C++11 library uses malloc/free? .... Since you claim that the library is performant, why not add some numbers by adding your library to [nativejson-benchmark](https://github.com/miloyip/nativejson-benchmark) and publish the results of the benchmark?
Clang itself is written in C++. `libclang` is a C wrapper for Clang. `libclangmm` is a C++ wrapper around `libclang`. Isn't it weird?
&gt; Only C++ is supported. It has full support for QML/Javascript as well, and supports syntax highlighting for a gazillion other languages (it has a python and glsl plugin as well, but I don't use them so I don't know how much they do). &gt; Darkish theme (not everything is dark). You changed from "default" to "dark" in the settings? What is not dark? 
What C++ is missing is C#'s extension methods as well as an ability to omit both the capture list as well as the types of argument names in a lambda function. These features combined would make ranges much easier to use.
I don't use QML/Javascript that much. Does it support node.js ? Syntax highlighting is very different from supporting the language (In my mind). QtCreator is an IDE so it would need the completion feature, syntax analysis and everything. Do you have a link for the python plugin ? I am very interested, I will finally be able to get rid of pyCharm~~ It could at least provide a way to easily add custom interpreters/compilers. (I guess you might be able to override the default behavior manually but I would not want to do it for each of my projects) Thanks for the "dark" settings, when did they add it ? It is not perfect yet. The project tab is unreadable. 
We'll be working on the issue with generated cmake files here: https://github.com/cppit/jucipp/issues/121
https://www.youtube.com/watch?v=PVYdHDm0q6Y
I've found Atom to be a bit of a performance hog as well. Runs pretty bad on my late-2013 rMBP. I tend to stick to Sublime at the moment.
Yes, but in many situations, the benefit in speed you might get from writing your own protocol on top of UDP isn't worth the extra time it takes to write and test it. TCP has a lot of features to make it reliable (duplicate rejection, data reordering, etc.) built-in that are useful for transferring files, and which you would have to rewrite to use in a UDP-based protocol. You might get a speed boost, but unless you *need* that boost, there's no point reinventing the wheel.
Probably so it can be distributed as a binary - C has a well defined ABI, C++ does not
&gt; I don't know what they're complaining about, this is fantastic and better than CLion. wat
Looks like the [Q_GADGET](http://doc.qt.io/qt-5/qobject.html#Q_GADGET) macro might do what you're wanting to do-- at least in Qt5.
A bit unrelated, what did you use to create/generate that documentation page (http://midifile.sapp.org/class/)? It is definitely some of the most usable API docs that I have seen before.
From the documentation I read "The Q_GADGET macro is a lighter version of the Q_OBJECT macro for classes that do not inherit from QObject but ..." so what about the Foo classes in our legacy codebase that *do* inherit from QObject and for which we want to provide fake versions? I don't see how the Q_GADGET macro can be of any help there... I also forgot to mention that I'm working on legacy C++98 code using Qt 4.8.X... so C++11/14 or Qt5 solutions are not (yet) an option.
Oh, yeah you're right. I guess I misunderstood what you were trying to do.
[IDE](https://en.wikipedia.org/wiki/Integrated_development_environment): &gt; An IDE normally consists of a source code editor, build automation tools and a debugger. Most modern IDEs have an intelligent code completion. A text editor is not an IDE, and you wouldn't download an IDE expecting, or wanting, a text editor, by default. I do agree on source file placement. They could easily put all the cmake stuff in a different folder.
How about adding a `QObjectImpl` that inherits from `OObject` and implements `QObjectInterface`, then your classes can just inherit from this to get the implementation. Otherwise I'd just bite the bullet and make `FooInterface` derive from `QObject`. This could get nasty if you want multiple interfaces per class, however :)
You might want to consider investing in a better laptop then, mine last fine.
It may very well be my laptop's battery, this is considerably lighter. That's my point, I find the CLion interface too cluttered. It's too heavyweight imho, but I can see that if you want a fuller featured IDE, then it is probably more along the lines of what you are looking for.
Emacs.. 
You tried laptop mode? I know it is in Idea but don't have a CLion license to check if CLion has it also?
Jekyll
Evil can be that text editor, if you must.
Evil can be that text editor, if you must.
If you're want to move it then you wouldn't declare it const. And if you did declare it const then there might be a reason you don't want someone to move it.
Const by value does give optimizations. Herb debates that in those cases const refs do as well.
Again, it's just more featureful than I generally prefer. This is lightweight, and has just enough features for me to avoid getting lost navigating the UI. In any case, it does do libclang integration better than vim and emacs, which I've switched between recently. Alternatively, I like this in particular because it is an open source project, it doesn't seem to have any particular outstanding issues that I have a problem with.
It took me a bit to understand how to pronounce the name of the project and still I would be hard-pressed to remember how to write it. Why not call it Juicy++? It's a lot easier to the eye without any weird capitalization and people will immediately know how to pronounce it and still get the pun.
Can't find package `mingw-w64-x86_64-gtksourceviewmm3`
It is a new package from some months back, upgrading your system with for instance pacman -Suy will fix this most likely. 
But we are talking specifically about const *value* parameters in [this thread](https://www.reddit.com/r/cpp/comments/3wq7gv/advice_use_list_initialization_and_constructor/cxyaku1).
mom: "hey I made you kids some cookies" kids: "YOU DID IT WRONG WAAAAA"
2025: C++ finally implements the Haskell standard.
Hmm. Will this work with iterators? `std::accumulate()` is all well and good, but sometimes something terser would be handy.
Heh, things you learn. I went through the documentation for streambuf and ios_base [again](http://en.cppreference.com/w/cpp/io/basic_streambuf), and well, its just as horrendous as I remembered it to be :) I think I will stick with getline for console IO and stdio for files :)
This is actually about something that Haskell cannot do at all, since it lacks variadic functions. Regarding containers: `std::accumulate` has been in the standard for ages and is pretty much exactly `foldl` and can trivially be used as `foldr` by passing in reverse-iterators.
This is more of a compile time feature for heterogenous containers like std::tuple. You will continue to use accumulate on homogeneous lists. 
&gt; Because this is a QObject-derived class, it can use methods like setObjectName and objectname You should consider QObject in Qt code as you would consider Object in java code : there is not really a point in trying to escape it.
The [C++14 generic lambda syntax](https://en.wikipedia.org/wiki/C%2B%2B14#Generic_lambdas) makes argument types significantly less noisy.
No MSVC build is not quite platform independent, tried msys2 but failed.
The goal is supporting MSYS2 on Windows, as it has 800+ precompiled library and software packages, and thus make it easy to compile programs using open source libraries in a manner similar to Linux and OS X. 
MSYS2 install is working, you should upgrade your system and follow the install instructions. 
Earlier i could easily upgrade to the latest Qt libs using the Maintenance tool but now it asks for a long into the Qt account and needs a commercial license to update the libs and QtCreator. *all good things come to an end.*
As /u/doom_Oo7 suggests, you should probably just make the interface the QObject. Also, don't forget that when deriving from QObject (or its descendants) to use the O_OBJECT macro, so moc can create the correct metadata. The following works, and in my opinion is more idiomatic Qt: #include &lt;QDebug&gt; #include &lt;QObject&gt; #include &lt;QMetaObject&gt; class FooInterface : public QObject { Q_OBJECT public: virtual ~FooInterface() {}; virtual void doFooStuff() = 0; }; class Foo : public FooInterface { Q_OBJECT public: virtual ~Foo() {}; void doFooStuff() { qDebug() &lt;&lt; "Foo::doFooStuff()" &lt;&lt; "\n\tClass:" &lt;&lt; metaObject()-&gt;className() &lt;&lt; "\n\tName:" &lt;&lt; objectName(); } }; class FakeFoo : public FooInterface { Q_OBJECT public: virtual ~FakeFoo() {}; void doFooStuff() { qDebug() &lt;&lt; "FakeFoo::doFooStuff()" &lt;&lt; "\n\tClass:" &lt;&lt; metaObject()-&gt;className() &lt;&lt; "\n\tName:" &lt;&lt; objectName(); } }; int main() { FooInterface* fakeFoo = new FakeFoo(); fakeFoo-&gt;setObjectName("Fake foo."); fakeFoo-&gt;doFooStuff(); FooInterface* realFoo = new Foo(); realFoo-&gt;setObjectName("Real foo."); realFoo-&gt;doFooStuff(); } #include "main.moc" Which outputs: FakeFoo::doFooStuff() Class: FakeFoo Name: "Fake foo." Foo::doFooStuff() Class: Foo Name: "Real foo." If you forget the Q_OBJECT macros, the class names won't report correctly and other Qt magic won't work right.
Installing Visual Studio updates has always been mind-bogglingly slow.
Nice, thank you!
For anybody else wondering what CPP in this context is, it seems to be "Chinese Cast Polypropylene Film".
This was a bug in Qt 5.4's Maintenance Tool IIRC. Newer versions ask for an account, but you can just select "Skip" to update/install without an account.
Not ever. In 2012 and 2013 versions installer worked fine on ssd disk.
The CrystaX page lists some improvements over the Android NDK, but doesn't list what NDK version it compares to. I wonder how well the Android NDK has caught up in terms of STL and C++11/14 in the most recent version. I think their current compiler is gcc-4.9 and a quite recent clang. It would be really interesting to have an up-to-date, more detailed comparison table. As it stands now, for lack of detailed comparison information, I would use the Android NDK first and see if that has everything I need, before considering CrystaX. So please please add this :-) That aside, it looks like an extremely awesome project with a lot of manpower behind it. I might try just for the fun of it ;-)
Yes, same here. Shaving off 2 characters is not motivating enough...
Well, you're right. Having more detailed description of the project, better documentation, etc - without any doubts, would be better for the project. We just don't have enough time for that. But we definitely will improve it. Answering your question, we're comparing latest release of CrystaX NDK with latest one of Google's NDK (r10e). Google's compilers (gcc-4.9 and clang-3.6) support C++11/14 good, but the main problem of Google's NDK is not compilers. The main problem are libraries - libc, and based on it C++ Standard Library implementations (GNU libstdc++ and LLVM libc++). This is what we address in CrystaX NDK, and what makes our support of C++11/C++14 better. As far as I know, Google works hard on improving their NDK, and probably in 2016 Q1 we'll see updated NDK, with many things improved.
IMO learning a bit off Haskell really helps if you want to do serious template stuff in C++. [Bartosz Milewski](http://bartoszmilewski.com/) has a great blog which should get you started
Did you follow the instructions at https://msys2.github.io/? Remember there is a step where you need to restart the terminal. 
how is c++ going to have typeclasses?
2013 Update 2 took close to 8 hours to install for me (on an SSD), and I don't think any of them took under an hour.
Hm, I need less that 1 hour to install VS 2015 Update 1 on HDD using off-line installer.
Making FooInterface derive from QObject has indeed been suggested by some people, and at first sight it looks like a nice solution. However, the only thing that I'm worried about is what happens if for example the Foo class needs to implement multiple interfaces, which then would all be derived from QObject (as user Porges also points out). This could lead for example to a situation where Foo implements FooInterface and BarInterface, both being QObject derived 'classes/interfaces'. I'm wondering if this would cause trouble (cfr. the Diamond Problem: https://en.wikipedia.org/wiki/Multiple_inheritance#The_diamond_problem)... My educated guess is that it wouldn't lead to ambituity as long as FooInterface and BarInterface don't override methods from QObject. Am I thinking correctly?
Are there precompiled binaries somewhere?
I've installed Linux with full dev environment faster than MSVC2015, and that didn't even include SP1. I have no idea what it's doing, but it's not efficient.
For me, it was the only way it worked. Updating an already-installed version failed me.
The standards foundation (Stroustrup, Sutter, and co) is for const everywhere (everything that should be immutable). It's more important in modern C++ then ever because of concurrency. To the question "is it faster?" the answer is: it can be in very specific situations. https://isocpp.org/wiki/faq/const-correctness https://github.com/isocpp/CppCoreGuidelines/blob/master/CppCoreGuidelines.md#S-const
Encapsulation instead of inheritance :) Have your object be `class MyFoo { Foo foo; Bar bar; };` or any kind of derived pattern - unique_ptr, shared_ptr... 
I installed 2015 with Update 1 two days ago using the web installer. Took about 15 minutes, including the download. 
´accumulate´ uses iterators, which are more general than containers.
My CTO, a longtime widows programmer, just commented last week how quick and easy it was to set up our dev environment. He literally learned *how* to install Linux, installed Linux, and had our code building in less time than it takes to install VS.
I see the name CrystaX 100 times but no explanation of what it is when that should be the first thing on this page.
And unfortunately I have a mechanical hard disk :(
Yeah, I made the mistake of starting that install process one morning. Blew my whole day. Unfortunately VS 2015 SP1 is still a crash-fest for me with a mixed C++/C++/CLI/C# codebase.
Thank you, we need help with the install.md for various platforms, and especially if there are differences in the apt-get commands for the different 14 and 15 versions. On the positive side, we did use boost::regex for the Ubuntu &lt;15 and Linux Mint users (having gcc4.8 as the standard gcc install, which does not support std::regex). 
&gt;Full UTF-8 support Even with regexes? As far as I know, support for UTF8 in boost-regex is pretty unwieldy.
No, it's a bad habit and adds noise. Const is a implementation detail not needed in the header. 
Most programmers are not aware that a value param can be const in the definition and non const in the declaration. 
It does not become part of the function interface. That's the point; a value param should be non const on the function declaration. For the function definition, the value can be marked const as an implementation detail. This does not change the signature. 
Sounds quite complicated, to be honest. Why does the new scene need to be created on change? Could the scenes not be created beforehand and accessed by their name, if need be? 
Quick and not compiling sample code... template &lt;typename SceneType&gt; SceneType * createScene() { return new SceneType(); } To register statically, template &lt;typename SceneType&gt; struct MyAutoRun { MyAutoRun(const char * name ) { YourFactory.registerScene(name, &amp;createScene&lt;SceneType&gt;); } }; // this is out of main function static MyAutoRun&lt;FirstScene&gt;("First"); static MyAutoRun&lt;SecondScene&gt;("Second"); Edit: add name to code
Did a quick test, and it works. Our regexes are only used towards C++ and cmake sources, we never search for a multi byte UTF8 character.
Ok, some more questions: 1. What does change_scene actually do internally? 2. Why not create the scene using smart ptr, as well? E.g. std::make_shared&lt;Scene&gt;(args)? The scene will be deleted as soon as it's no longer referenced.
So 中 doesn't get matched by "..."? I'm asking this based on [this question](https://stackoverflow.com/questions/15882991/range-of-utf-8-characters-in-c11-regex).
Have a look at the [factory](https://en.wikipedia.org/wiki/Factory_method_pattern) pattern. In essence, you don't want to register *instances* by name, you want to register *producers of instances*. You won't get around using some macro or other preprocessing to link string names to the actual producers, but it's not too difficult. Something like this might work: using SceneProducer = std::function&lt;Scene*()&gt;; std::map&lt;std::string, SceneProducer&gt;&amp; registeredSceneProducers() { // Creating the map in a function and returning it like // this prevents problems with initialization order. static std::map&lt;std::string, SceneProducer&gt; registry; return registry; } bool registerSceneProducer( std::string name, SceneProducer producer ) { registeredSceneProducers()[name] = producer; // Return a value here so we can use static initialization in the macro below return true; } #define REGISTER_SCENE_PRODUCER(className) static const bool className##_REGISTERED = registerSceneProducer(#className, []() { return new className(); }) Scene* createSceneByName( std::string name ) { SceneProducer producer = registeredProducers()[name]; if (producer) { return producer(); } else { return nullptr; } } The `REGISTER_SCENE_PRODUCER` macro above declares a global static variable that is initialized upon application startup. To initialize it, the `registerProducer` function is run, registering a producer as a side effect. Usage: class SecondScene { // Stuff }; REGISTER_SCENE_PRODUCER(SecondScene); 
True, but we do not have symbols like that inside the boost::regex() parameter. You might be right and there still might be issues with this, but we have at least not yet experienced that. 
It has been quite some time since I last wrote something like this. It is also pseudocode-ish so it probably won't work right out of the box. But the idea is like this: create scene you want to map to an identifier, register this with the manager with the appropriate identifier, change the current scene with change() and then, when done, deallocate manually or automatically (when manager goes out of scope). { Game_scene scene {stuff}; Scene_manager manager {more_stuff}; manager.add("Game", std::move(scene)); // Manager owns this. // or: manager.add("Game", Game_scene{stuff}); // Manager owns. manager.change("Game"); // You could also do this is in add(...). manager.remove("Game"); // If you need to destroy beforehand. } // Should destroy everything since we transfered ownership. You can also make so when you do change() or the like it will automatically add the desired scene depending on the name of the scene. For example: .change("Game-1") would search for the token "Game" and then automatically create a Game_scene object if there isn't one that has been assigned to the identifier yet.
Would you want to reuse the instance of an already created class like a singleton or something ? Or would prefer to create a new instance of it every time when asked for ? 
This seems promising... It is not actually exactly what I wanted to do, because I should have a file which contains all the static pointers for each scene...So I could just use my approach, by adding manually each scene in a different file. However, given the fact that I'm probably going to do this since I'm struggling to find other solutions, your idea is much cleaner and readable than mine
The search and replace regex user's would be using is using gtksourceview's regex engine. gtk have supported utf8 for a long time. Just tested it, and the only issue I had was that the replaced text was incorrectly selected after replace. Adding this to issues. 
Parsing cmake files and for instance figure out indentation after if, else if, else, and so on. 
Then it seems like a minor issue indeed.
perhaps installing the whole thing packaged together is faster? Dunno..
Try this: #include &lt;iostream&gt; #include &lt;string&gt; #include &lt;map&gt; #include &lt;functional&gt; class Scene { public: Scene(){}; virtual ~Scene(){}; protected: private: }; class SceneManager { public: SceneManager():instance(nullptr){}; ~SceneManager(){ if(instance) delete instance; }; template&lt;class T&gt; void register_scene(const std::string&amp; name) { scenes[name] = []()-&gt;Scene*{ return new T(); }; } void change_scene(const std::string name) { if(instance) delete instance; instance = scenes[name](); } protected: private: Scene* instance; typedef std::function&lt;Scene*(void)&gt; func; std::map&lt;std::string, func&gt; scenes; }; class FirstScene: public Scene { public: FirstScene(){std::cout &lt;&lt; "Hello FirstScene!" &lt;&lt; std::endl;}; ~FirstScene(){std::cout &lt;&lt; "Bye FirstScene!" &lt;&lt; std::endl;}; protected: private: }; class SecondScene: public Scene { public: SecondScene(){std::cout &lt;&lt; "Hello SecondScene!" &lt;&lt; std::endl;}; ~SecondScene(){std::cout &lt;&lt; "Bye SecondScene!" &lt;&lt; std::endl;}; protected: private: }; int main() { SceneManager scene_manager; scene_manager.register_scene&lt;FirstScene&gt;("FirstScene"); scene_manager.register_scene&lt;SecondScene&gt;("SecondScene"); scene_manager.change_scene("FirstScene"); scene_manager.change_scene("SecondScene"); return 0; } 
Somehow sinking a day into installing windows and VS just to check out what's new in Windows land does not feel like a productive use of time. VS is a good development environment but it's not that good :)
I'm a UI programmer working in the games industry. Most of the stuff I write is ActionScript with C++ glue code. There are no hard problems to solve in UI. Even if you find some, nobody will pay you to solve them. Instead, they will pay you to fix horrible UI logic written by your predecessor. And to make the button bounce when you click on it.
I liked devising algorithms to render vector graphics (I even did this multi-core when available).. that makes me sad :(
I'm not sure whether I misunderstand or merely disagree, but this seems much more convoluted than just using tag dispatch. Both implicit inheritance conversions and SFINAE are used together to get the same effect as tag dispatch. Why not just use tag dispatch? If you use something like experimental::is_detected, then the detector is literally a one liner for each method, exactly the same as the convoluted trailing decltype, but much more readable. Also, the first example changes semantics slightly when the trailing return type is added. It went from always returning size_t, to returning whatever the user wants. &gt; The most elegant way is a templated struct with a member constant. Will a template variable work here? This notion of something that's templated but always evaluates to false is nice, I'll definitely be stealing this.
&gt; Microsoft’s compiler produced internal compiler error on this part of code. Did you file a bug? ;-)
This is the way we need to be thinking. For all the wonderfulness being added to C++ these days, to my thinking it still has a glaring deficiency: it offers poor support for composable components. So we need to be trying out ways to write such things, putting together libraries of them, and seeing which methods work best and what core-language/standard-library modifications might be most helpful.
The link is down - does OP have a mirror?
Yep, this is the textbook use case for the factory pattern. I also seem to recall that the first Game Programming Gems book covers this and more in its section(s) about data driven design, but it's been a lot of years since I read it. Even though the factory pattern (oddly enough) isn't covered, http://gameprogrammingpatterns.com/ discusses a lot of design pattern that are relevant for game developers. 
I have plans to do so - I have several cases for them.
 I solved "I like" problem for myself by creating Sciter engine (http://sciter.com). Each real programmer should have something of his own I believe, something for your soul. You have that option too - to create that kind of UI by yourself as your own application / project. Or to create library, framework, whatever of UI transition / motion primitives. As of UI transitions in general... modern "flat" UIs (e.g. Metro, Material) are moving towards more sketchy / simple UI transitions/animations. Those that can be handled by CSS and scripts. A bit far from real physics and skeuomorphism in general. That's why I don't think that you will find many active projects implementing such UIs to chose from. in pure C++ I mean.
I agree there's still architectural problems to be solved, but that's only tangentially related to programming the UI itself.
Sorry for the extremely late reply, I never got a notification. I ended up using historical data from the last 3 months. But I will still check this out, definitely want to improve the project. Thanks for the help!
reminds me of the iterators in Rust. I hope C++ gets UFCS. Not so keen on overloading 'operator |' for this. Seeing that sort of thing makes me think its' getting too convoluted, *"time for a new language?"*, but I know C++ can basically do what I'm interested in. In rust you just write 'blah.iter().map(|x|{...}).filter(|x|{...})... etc (although thats' all done with traits). With UFCS you'd just write those high order functions map(..) filter(..) taking ranges as the first param, and instantly available method-call syntax would make it easier to write chains. Of course you can still say ```filter(map(blah,[](){}), [](){})```. it still works, just a little harder to read &amp; write. When rolling my own collections I'm highly tempted to just stuff the appropriate high order functions in as member functions (I don't need every permutation); of course that makes my code incompatible with everyone elses. UFCS would just make the world a better place all round. Less incentive for NIH, because you can extend some elses classes without needing to come into conflict about what should &amp; should be in them.
&gt; Instead of performing iterations each of them will produce composition of actions for single sequence element. isn't this a perfect case for expression templates ?
FYI, a fix has been checked in for Update 2.
Another great implementation is [cpplinq](https://cpplinq.codeplex.com/)
Well, purpose of the project is to provide comprehensive development kit for Android, allowing peoples develop in any programming language, not only in Java, as Google dictate. As important part of this purpose, we're making behaviour of the underlaying libraries (libc, libstdc++, etc) and compilers as standard as possible, allowing just re-use existing code which is already working on other systems - GNU/Linux, iOS, etc. This is described [here](https://www.crystax.net/en/android/ndk), maybe not ideally, but really better than I can say in two words.
&gt; comprehensive development kit for Android THAT makes perfect sense of everything, thank you. It is certainly something I will look at if I work with Android. 
Sciter was created as an embeddable engine specifically for the UI of applications. I've added there features that cannot be implemented in browsers in principle. Browser is a secured sandbox at first, and only at second it is a renderer of web pages. Like in Sciter you can declare DOM element to be rendered outside of the main window ( e.g. http://terrainformatica.com/w3/sciter-tooltip.png) Thus you can test in FF only basic HTML/CSS constructs. But Sciter SDK has so called DOM inspector and script debugger. As also there are third party "F12" tools similar to what FF or GC have, check: http://sciter.com/developers/development-tools/ 
I'm guessing this is already filed. I saw what seems to be this same ICE come up somewhere within the last week.
Steve from MSVC here. Have you filed any connect bugs on the crashes? what scenarios are failing?
that c++ code is just gross, so verbose and unclear
Not quite a fair comparison, you have the two lambdas predefined, you're missing an assignment to a variable and there's no specification of the output container format (the into_vector). With predefines: auto inc = [](auto x){return x+1;}; auto even = [](auto x){return (x%2==0);}; Compare: into_vector(tr | tfilter(even) | tmap(inc), input); into_vector map (+1) . filter even $ [1..10] 
Category theory for programmers is basically mathematics. If you are just looking for Haskell, [here is a series](https://www.fpcomplete.com/school/starting-with-haskell/basics-of-haskell) by Bartosz. This will probably be easier to start on.
Reminds me of ... bash. :p
if c++ had single expression lambdas without braces - something like arrow syntax from C# it would be a bit nicer IMO. Wonder why it's not included - it could even have some shortcut to variable capture like =&gt; can be [=] &amp;=&gt; can be [&amp;] :)
I strongly believe the reverse hazard is worse: people needing to write (and maintain) wrappers to fall through, and clutter up classes with excess functions. As a compromise I have a suggestion that UFCS could require an explicit 'this pointer' e.g. ```void bar(Foo* this,...)``` - then when you see ```my_foo.bar(x)``` you can search for ```class Foo```, or ```bar(Foo* this```. or ```bar(.\*this```perhaps if you didn't know the type. This would have the added benefit of making refactoring back &amp; forth (moving code in &amp; out of classes) easier. most people will just use it through IDE's. (UFCS methods can be listed later for anyone worried about menu clutter) The thing about '|' is the meaning has become so overloaded. It's bitwise OR. its' dot-product. Now its' pipes aswell. What are your eyes supposed to tell you.. plenty of times you might want to OR or 'dot' results from functions. if there was another operator like F# |&gt; it might be different.. but we already have the member-call syntax in C++ which gives similar flow.. why don't we just enable that 
Here's a minor piece of feedback. One thing that bugs me is when someone starts an explanation by saying something is simple... &gt; The idea is simple – if You have sequential process and each inner step could be represented as functional composition of reducing functions – we could make ‘composer tools’ for it (high order functions) and call them transducers. Maybe transducers aren't super complex; but I don't know what a "reducing function" is; and I don't know what you mean by "composer tools". Of course, it's not the author's fault that I don't know this stuff; but generally speaking it's not helpful to say that something is simple, and it can make people feel bad if they then don't get it. Better to just describe what you want to describe without pre-loading it by saying that it's simple.
Yes maybe '|&gt;' is a good compromise. Using the '|' operator for inner product sounds strange (speaking as a mathematician), but I realise this is tricky with the need to use different operators for inner (dot) and outer (cross) product. I think I'd prefer 'a.T() * b' though...
i really liked rust's original do notation with trailing lambdas (not quite the same, but related)
It is not useless, and is already supported by STL with the begin()/end() and cbegin()/cend() pairs. If you think about it, together with overloading, it is almost as having multi-dispatch in C++.
The C# devs actually discussed adding lambda captures to it. https://github.com/dotnet/roslyn/issues/117 
This was [already proposed](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/p0079r0.pdf) and rejected by EWG; see Bjarne's Kona trip report for details.
Sometimes I wonder how much better the safety culture in C world would have been, if the compiler vendors didn't try to sell lint as an extra tool, as part of product differentiation. Instead we had to wait to clang and eclipse codan, for it to become more widely accepted.
What's the price range of this? 
Yes, exactly. I feel a little bit like we're trying to take too much from C#, which I'm not particularly fond of because I think it tries to be too clever. 
**tl;dr** in [Expression Templates](https://en.wikipedia.org/wiki/Expression_templates) the objects often relay on not being captured by value (and hold on to references to objects that may disappear at the end of the expression). Using `auto` accidental for such objects can cause problems. This suggestion allows a type to modify what type will be inferred for it when using `auto` (and, one would assume, `decltype`). [[Shameless plug](http://lanzkron.wordpress.com/2011/02/21/inferring-too-much/)] ---- They say that the consensus was for the `using` syntax over `operator auto`. class proxy { using auto = matrix; // This syntax will probably be used matrix opeator auto(); // Rather than this syntax }; If I want to disable `auto` deduction then in the `operator` option I could just `= delete` it. Is there an equivalent option for the `using` option? 
If the author wasn't so serious, you'd think it was tongue-in-cheek, like: &gt;A monad is just a monoid in the category of endofunctors, what's the problem?
arrrrghhh. So we have to continue to suffer bouncing back and forward. how annoying!!!!! the standards committee must be willingly malicious
Great talk! I found it very informative, and I hope it will help dismiss some common misconceptions about how to write efficient C++. I found it perhaps a bit fast paced; I had to pause to read the LLVM IR more carefully. But as always, a very good talk from Chandler! Thanks for sharing.
It builds up on it. Yet (as I saw both live), this time chandler focused a lot more on loops, which afaik he didn't really cover at C++Now.
In the 3 to 4 digits apparently. http://www.gimpel.com/html/order.htm
The concept of expressing invariants through annotations is interesting. It would be nice to see a form of `restrict` make it into the language, possibly along with some others. I think it might have been interesting to see a nice strength reduction like `bswap` (`bsr`/`bsf`, `ror`/`rol`, etc...). Same with constant folding.
LTO seems to reduce binary size pretty dramatically, so I would guess it does a 'de-inlining' pass.
AFAIK LTO only does dead code elimination. Within a single TU the compiler cannot know (in some cases) if a function is used from another TU or not, so it has to generate code for it. However, when the optimizer sees all TUs during LTO, it can remove all the functions that aren't used, resulting in massive code-size reduction (e.g. if you are statically linking against some libraries but only using a tiny portion of their functionality). What I meant with de-inlining is, given: void bar() { // does some stuff foo(); } void foo() { if(condition()) { // huge block } // does a little stuff } the compiler might not be able to inline `foo` into `bar` because `foo` is too big. If the compiler were to "de-inline" the block: void foo() { if (condition()) { __huge_block(); } // does a little stuff } `foo` becomes small, which might allow it to be inlined into `bar`. This might be important, e.g., if the result of `condition()` can be inferred from within `bar`. 
Which version are you upgrading from? That particular dialog page is supposed to have a button labeled "next". There was one single release earlier this year where that wasn't true, but that was very quickly undone as noted here. If this is a recent release where this is missing please do let me know exactly which release and platform and I'll get it fixed. Edit: the button is of course supposed to say "skip", brainfart...
Some very nice changes here
I am curious how the optimizer would handle the last example if it was formed where computer was a member function that called the static or external function compute( S s ) with compute( *this ), would it still be bad or would the optimizer be happy.
It amazes me how similar compiler optimisation is to functional programming.
damn, really quick! Thanks for the update :)
Let me add that my logical brain tells me that it not possible without platform specific machine code-generation. I don't "see" it. But maybe there is an a-ha moment I'm missing.
Meeting C++ was in Berlin!
So it's a metric conversion issue?
How is the function normally called? Are you the first person to interop with this function? This sounds like a bad dream to me. If you know the fixed set of possible sizes, you can create a map at compile time of the all the possible invocation strategies, and then map into the desired one based on the user input.
I cannot overstate how significant autocomplete is: *This is the only reason I still use C++.* If I was happy to ditch it, I would have migrated to Rust already (or even my own language). Its' the mature IDE's that keep me here. 'dot Autocomplete' is at least a factor of 2 in productivity ( feels more like 4 ) - because it saves so much time switching between code &amp; documentation, by bringing key information right under the cursor and doing the work of looking things up, even as you type, digging deeper into each expression.
Of course, and that might allow more dead-code elimination after inlining, but it can also increase the code size. 
Sure I agree, autocomplete for discoverability is a big productivity boost. But it sounds more like a IDE limitation? Why can't IDEs do the UFCS lookup? Start writing obj &lt;dot&gt; f and let the IDE autocomplete to foo(obj) ? Is there a technical reason why did is not available in the major IDEs?
I like discoverability, so that reason might sway me. About the others, sorry I just don't see it. Most of the time when I'm chaining function calls it's container transformation pipes, where the pipe symbol feels more natural anyway. Mixing call syntax for the same function feels a lot like mixing brace styles or naming conventions.
I agree this should be possible and it would be great to get that- it is merely a re-ordering. But it does seem harder: its got to mess around re-interpreting your syntax more. There's a bigger distance between what you read and write. I do believe the OOP notation is a useful middle-ground between something easy to parse, and the way natural language intersperses operands(nouns) and operators(verbs). "subject verb object", but still some use of brackets and symbols to disambiguate and extend more combinations. It's nice how it approximates the 'piping' aspect too. One idea I've thought about is the idea of ```_``` placeholders (see haskell holes workflow). Imagine writing ``_(a,b,c)```, and you can click the right mouse button on the placeholder '_' character. (or get compile time information, 'potential functions at line:...' - this should be pretty easy to do as compiler plugin). This could be extended arbitrarily; you'd get suggestions based on multiple types. argument,field completion, etc. more sophisticated queries eg ```a._(b).bar``` (find a function that returns a type with a 'bar' field..). 'dot autocomplete' narrows suggestions down based on one argument. Still, its' a useful middle ground because we sort 'the most important argument' first. It's just there is too much conflict between identifying an important argument, and modularity/decoupling. It still isn't as immediate as 'dot-autocomplete' . And sadly the Rust people didn't want to "clutter their AST with an unnecessary feature"."oh, we'll get dot autocomplete eventually, and it shouldn't be in the AST, so we don't need a halfway house like this". Everyone lacks vision :) placeholders would have worked really well with Rusts' more advanced type-inference.
The source of this issue is Handbrake doing this by default. Working on a fix.
&gt;&gt; obj.func() is the idiomatic way. Not so much in C++. its only 'not idiomatic' because people have to use free functions to workaround the lack of extention methods! in Rust (not an OO language), they give you 'extention methods' via traits (see coming Concepts) which (i) allow bounding generic types for better compile time errors (ii) allow another style of vtable closer to COM objects. They allow compile time &amp; runtime polymorphism to share the same logical framework. The system is inspired by haskell and has been subsequently copied by Apple for Swift. In 'go' , its all open - you don't need to know the trait/concept/interface name before you write a function. &gt;&gt;the idiomatic way. Not so much in C++. Lambdas were never idiomatic in C++, do you want to take them out? ADTs aren't idiomatic in C++.. do you think we should never add them? Do you think we should always need another tool like Qt MOC for reflection or C X-macros, because there's no idiomatic reflection here? &gt;&gt; fractured styles We already *have* the fracturing, between what different libraries and programmers think should be in the class; and fracturing between vtables and compile-time resolution. This is all about *reducing* fracturing. Method call syntax is measurably better by reducing the distance between operands and the functions that use them. Class methods can also help writing heavily templated code, because you can share template arguments between many members. (in rust, similarly, you declare type parameters as part of the trait 'impl'). There are many situations where a bundle of functions are related, but you want decoupling. Rusts approach is interesting, groups of functions are called 'traits', and you implement as many 'traits' for a 'struct' as you like, in different places, giving you extention methods basically - and 'concepts/interfaces' handled by one logical structure. (I'm sure we could retrofit this in C++, but I don't even need all of it)
Here is a way to do it in C++14 (uses C++11 style constexpr, works in Visual C++ 2015). This fixes the limitations of the assumption of 32 bit signed integers. It will also precompute the tables for unsigned integers and 64 bit integers. #include &lt;limits&gt; #include &lt;utility&gt; template&lt;class T&gt; constexpr T cfact(unsigned f) { return f ? cfact&lt;T&gt;(f - 1)*f : 1; } template&lt;class T&gt; constexpr T factorial_max_helper(T value_so_far, T f) { return std::numeric_limits&lt;T&gt;::max() / value_so_far &lt; f ? f - 1 : factorial_max_helper(value_so_far*f, f + 1); } template&lt;class T, std::size_t... Indices&gt; T factorial_helper(T f, std::index_sequence&lt;Indices...&gt;) { static constexpr T ar[] = { cfact&lt;T&gt;(Indices)... }; return ar[f]; } template&lt;class T&gt; T factorial(T f) { return factorial_helper&lt;T&gt;(f, std::make_index_sequence&lt;factorial_max_helper&lt;T&gt;(1, 1) + 1&gt;{}); } #include &lt;iostream&gt; int main() { unsigned i = 7; volatile auto r = factorial&lt;int&gt;(i); std::cout &lt;&lt; r &lt;&lt; "\n"; } Also a link to code runnable in ideone: https://ideone.com/mA2VlI
Akuna Capital is hiring experienced C++ Developers: [C++ Developer-Chicago](http://www.akunacapital.com/job-details/?jobid=86052&amp;gh_src=) [C++ Developer-Infrastructure Team-Chicago](http://www.akunacapital.com/job-details/?jobid=65800&amp;gh_src=) [C++ Developer-Data &amp; Measurement Team-Champaign, IL](http://www.akunacapital.com/job-details/?jobid=80356&amp;gh_src=)
Sooo, Kleisli composition on the list monad.
&gt; its only 'not idiomatic' because people have to use free functions to workaround the lack of extention methods! What I meant is that in C# people use the obj.func() syntax, while if we get UFCS in C++ we will see a random mix of func(obj) and obj.func() due to different preferences. That's in new code too. I'm not that keen on even more more holy war and bikeshedding about styles.
I understand your viewpoint. In this case I was more referring to using the functions though. Currently it's unambigous and can only be done in one way. With UFCS it will be a random mix depending on the authors preference.
&gt; One idea I've thought about is the idea of _ placeholders (see haskell holes workflow). Imagine writing _(a,b,c)`, and you can click the right mouse button on the placeholder '_' character. (or get compile time information, 'potential functions at line:...' - this should be pretty easy to do as compiler plugin). Yes in Haskell I've found typed holes to be fantastically useful. It would be very interesting to see if it's possible to adopt it to C++.
&gt;&gt; "With UFCS it will be a random mix depending on the authors preference." as you see from this, http://en.cppreference.com/w/cpp/iterator/begin, *its' already a random mix*. Every author is forced to make a poor compromise. UFCS would have got rid of the motivation to write this dumb wrapper in the first place. There's plenty of other code where things ping pong back &amp; forth between members and non members. This wrapper exists because: you can't always add member function callable syntax to a given class. With UFCS you *can*, and this kind of dumb wrapper goes away. 
its' useless. those dumb wrappers 'auto begin(auto&amp; x) {return x.begin();}' exist only because you can't add methods outside of a class. Add UFCS and those stupid useless wrappers go away. You'd just use the superior ```.```-autocompletealbe, chainable, readable syntax everywhere.
the biggest problem is: the inability to add functions to a class, that show up in dot-autocomplete and read/write nicely for chaining. ```a.foo(x).bar(y,z).baz(w)```(clear) vs ```baz(bar(foo(x),y,z),w)``` (unclear). Hence the conflict over the privaliged functions that get to go in the class, receiving superior read,write,discoverability, and option of vtables, arbitrarily restricted. the dot notation is easier to read, and write. you don't have to move forwards and backwards balancing parens, and you got the 'dot-autocomplete' suggestions at every step.
Actually when the mini-version of the slides are displayed at the bottom right, they go out of the "4:3 window", so it looks like it's not purely an aspect ratio issue. Or, these mini-windows were added after conversion, but that would be a bit weird.
How many of these are standard c++? (c++17 possibly?)
Can you ELI5 what this means?
There are some rare situations where it's useful, eg. representing permutations of `class foo&lt;T, N&gt;` without using polymorphism. Bonus, if you forward declare the variant, then you can alleviate header inclusion for `foo&lt;T, N&gt;` in other interface headers. 
If you guys haven't been listening to this podcast, you should do so. The hosts are becoming much more effective at having meaningful conversations and they have insightful guests.
I assume you have no control of what checks are enabled, but I would definitely prefer to work in an over-picky environment than an overly permissive one. John Carmack's [article on static code analysis][1] mentions PC-lint and also I think takes the right point of view in general: &gt; Trying to retrofit a substantial codebase to be clean at maximum levels in PC-Lint is probably futile. I did some "green field" programming where I slavishly made every picky lint comment go away, but it is more of an adjustment than most experienced C/C++ programmers are going to want to make. I still need to spend some time trying to determine the right set of warnings to enable to let us get the most benefit from PC-Lint. [...] &gt; I learned a lot going through this process. I fear that some of it may not be easily transferable, that without personally going through hundreds of reports in a short amount of time and getting that sinking feeling in the pit of your stomach over and over again, "we're doing OK" or "it's not so bad" will be the default responses. &gt; The first step is fully admitting that the code you write is riddled with errors. That is a bitter pill to swallow for a lot of people, but without it, most suggestions for change will be viewed with irritation or outright hostility. You have to _want_ criticism of your code. [1]: http://www.gamasutra.com/view/news/128836/InDepth_Static_Code_Analysis.php
&gt;&gt;Without looking in other places you can not know if given method is const or not. eh? ````void foo(const Bar&amp;); // can't modify```` ````void foo(Bar&amp;); // can modify```` ```` class Foo { void foo() const; // can't modify}```` ```` class Foo { void foo(); // can modify}```` its' the same, surely. You look at the method/function declaration, and you can see, if it's const or not w.r.t each parameter; and you got the same compile time error messages helping you at the call site if you tried to do something wrong. 
None.`always_inline`, `cold`, and`flatten` are neither standard nor proposed for standardization. GCC and Clang support them (and many more). Compilers that do not support them must ignore them (just like pragmas). From what I can interpret from the C++ talks I've watched, the general feeling in the standard committee / compiler development community is that _if you need any of these your inliner is broken_. After 20 years of standard C++ all inliners are still somehow broken, so all compilers offer these in one form or another. The range comprehensions example of range-v3 comes to mind, where clang was 20x slower than gcc because it inlined things differently. "Perfect inlining" of code is hard, and an unsolved problem in practice.
&gt; The only thing I'm worried about is the fact that only pointers to the PMRs are passed around... How will we know (in more complicated systems) when it's okay to delete a PMR?! (Which, in the case of the specialized ones like the pool resources, frees all the allocated memory.) IIRC, they will never delete it. The containers don't *own* the allocators, since they should be shared between multiple.
Yes but that's exactly what I'm talking about! Previously it was at least possible to implement reference counting allocators (i.e. I could write an memory pool which was deleted *AFTER* all it's objects have been deallocated, by storing a shared_ptr inside all allocator copies). Actually you could do basically everything since all containers kept a copy of the allocator. Now the PMRs just store plain pointers... For C++11 it was decided that std::string must not do any COW optimization anymore, because of this: std::string s("str"); const char* p = s.data(); { std::string s2(s); (void) s[0]; } std::cout &lt;&lt; *p &lt;&lt; '\n'; // p is dangling (Source: http://stackoverflow.com/a/29199733) (IMHO removing it was a still bad decision though, due to the performance hit and breakage of ABI compatibility) But now with PMRs we do the same thing again and noone seems to have any issues with this... Because this will break again: std::pmr::unsynchronized_pool_resource pool; std::pmr::string s("str", &amp;pool); const char* p = s.data(); pool.release(); std::cout &lt;&lt; *p &lt;&lt; '\n'; // p is dangling Or: auto pool = new std::pmr::unsynchronized_pool_resource; std::pmr::string s("str", pool); delete pool; std::cout &lt;&lt; s[0] &lt;&lt; '\n'; // crash Or: auto pool = new std::pmr::unsynchronized_pool_resource; { std::pmr::string s("str", pool); delete pool; } // crash (destructor of string call deallocate()) Maybe I misunderstood sth., but otherwise: I don't get it... (It's an issue because `release()` (which is also called in the destructor) will release all allocated resources regardless if they are still used. IMO it should use reference counting, so `release()` etc. only works if all allocated resources have been deallocated again.)
&gt; Previously it was at least possible to implement reference counting allocators (i.e. I could write an memory pool which was deleted AFTER all it's objects have been deallocated, by storing a shared_ptr inside all allocator copies). Actually you could do basically everything since all containers kept a copy of the allocator. Now the PMRs just store plain pointers... Yes, this is a bad design decisions. The PMRs are now required to be ref-shared. This could have been avoided if we drop the whole abstract base class. Instead, use a traditional required interface like Allocator but without the construct()/destroy(), alignment support not type bound, instead just allocates raw memory, etc. Allocators now need to provide the interface instead of inheriting. The containers store the new Allocator by-value as usual. This allows containers to own their allocators like before. There just need to be rules about copying/assigning the allocators. For sharing between container objects, provide a class - let's say - `allocator_reference`, that stores a pointer to an Allcoator and forwards to it. The containers now store the reference class by-value which shares the allocator. It can also be implemented to *own* the Allcoator like `std::shared_ptr`, or in a seperate class. Implementign sharing from owning is much easier than the other way round. And to have Allocators decouple from the type, provide a type-erased reference that can store a pointer to any Allocator, an `any_allocator_reference`. This allows the universal, take any allocator container again, without the need for Java like base classes. This would be a better solution imo. And because I think so, I've implemented the whole thing already in my memory library: https://github.com/foonathan/memory/ The new concept is called `RawAllocator` and there is a wrapper class that provides the traditional `Allocator` interface like in PMR. &gt; But now with PMRs we do the same thing again and noone seems to have any issues with this... Because this will break again: That's an issues because of the `release()` function, not because the containers share the Allocator.
Your library is certainly interesting and good, but does it solve the problem that specifying the memory resource type as a template argument is kinda cumbersome? Or as [N3916](https://isocpp.org/files/papers/N3916.pdf) puts it: &gt; For example, assume we have a function that builds up a list: &gt; &gt; int build(std::list&lt;int&gt;&amp; theList); &gt; &gt; Because we did not specify an allocator parameter for the argument type, the default, std::allocator&lt;int&gt; is used. [...] Now, some would argue that the solution to the build function problem is to &gt; templatize build: &gt; &gt; template &lt;typename Alloc&gt; &gt; int build(std::list&lt;int, Alloc&gt;&amp; theList); &gt; &gt; or, better yet: &gt; &gt; template &lt;typename OutputIterator&gt; &gt; int build(OutputIterator theIter); &gt; &gt; Both of these templatized solutions have their place, but both add substantial complexity to the development process. Templates, if overused, lead to long compile times and, sometimes, bloated code. The same problem applies to many other areas, like e.g. comparing 2 objects which have different allocators and thus are of different types... Am I right to assume that your library has the same "problem"? I think that what PMR is doing is largely the right choice, but using raw pointers is kinda bad. And the fact that `release()` etc. exists is IMHO horrible because that means that there are really 2 points in your code now where memory can be deallocated and that's far from being RAII.
&gt; IMHO removing it was a still bad decision though, due to the performance hit and breakage of ABI compatibility In practice there's generally a performance improvement rather than a performance hit, due to replacing CoW behavior with the short string optimization, and due to the fact that move semantics mean CoW is no longer necessary to avoid unnecessary copies of larger strings.
&gt; Maybe you are trying to say "it's more likely a method changes the receiver and a function doesn't", but that is not a safe assumption exactly &gt; Dot syntax **feels** more ambiguous, maybe because I **often see** it used in a way where the function calls have side effects.
&gt;&gt; exactly well, given the number of accessors etc, I don't think its' a good assumption to make. And I've shown you free-functions that modify. (e.g. swap), and member-functions that don't. (e.g. count, find, ..); *and* we've got wrappers being introduced that just call members , to workaround the lack of UFCS. What if a free function goes on to call methods? It is no more or less ambiguous. My view of this is quite simple: method declarations are (i)just a handy shortcut for declaring lots of functions that share one parameter (especially useful for templated classes,sharing the 'template..'); (ii)and they make expressions easier to follow, by approximating infix notation; (iii)and they play well with autocomplete which is invaluable for making libraries easy to use. (iv) it makes function names easier to read - natural language gives us the form 'subject verb object' which gives you more hints about how the function name relates to the preceding and following arguments (you can postfix some prepositions onto your function name for clarity). All these benefits are completely orthogonal to immutability; you should not be deprived of them just because something is const. In this multicore era immutability is important to increase the amount of parallelism. Just because you want parallelism, you shouldn't be deprived of 'dot-autocomplete' or expression clarity. Whats 'idiomatic' is open to change. C++ never had lambdas, now it does. C++ was designed in the single-core era. Take a look at Rust - like C++ its' multi-paradigm; the dot-notation is used for functional code that flows in pipelines... ```foo.iter().map(||{ }).filter(||{..}).collect()``` .. the 'dot-notation comes from OOP but happens to serve the left-to-right dataflow purpose perfectly well. And we have this in C++, its' just conflated with access rights making it harder to use. Rusts' 'trait-impl' system is brilliant. In C++, they're putting in those dumb workarounds: today they're becoming idiomatic but its' not like its' a commandment from God that the world has to be that way. Its' just a clumsy workaround for missing features. C++ has always tried to let you 'add methods' with inheritance - its' just it doesn't quite work, so we've been told to fall back to free-functions. Yet the intent of inheritance is appealing. What they simply need to do is *extention* methods, or UFCS, to succeed where inheritance fails. Other languages prove its' possible. Remember there's concepts yet to come. Take a look at the 'trait/impl' system in Rust for an illustration of how it could be. Apples' swift has taken heavy inspiration too. C++ stagnated for a long time, and it seems like it took competition from 'web languages' to kick the 'standards committee' up the ass to motivate them to actually modernize it with lambdas and so on. Now they appear to be dragging there heels. The slightly more open nature of go, Rust, and D's UFCS show the way forward; and there's no reason that can't be combined with C++'s strengths
Presumably they think CMake's input language isn't as nice. It does seem kind of complex (macros, functions, scripts, generator expressions, etc.). On the other hand, maybe in a couple of years MesonBuild's will be just as crufty and confusing (presuming it survives).
The house building analogy is a good one. One can really "wing it" on small projects.
Also newly launched [Online Compiler](https://idedr.com) .
Very good article but actually a *show the examples* would have been better
You can use Vim. It has semantic tab completition with [YouCompleteMe](https://github.com/Valloric/YouCompleteMe) which uses clang for C/C++ languages and other completers for other(Python, etc.). It even has semantic coloring with [color_coded](https://github.com/jeaye/color_coded) same variables have same color you can see what is mistyped quickly. First because it has a wrong color and because it is underlined because variable doesn't exist for example. (Clang does that) The only thing it needs are two . files which configure what files need to be included for building so that type completer can do it's thing.
I totally agree. It's just a hard requirement that I wasn't allowed to change. I've tried very hard to be allowed to use TCP.
First of all: This is the paper recommending to make all iterators on basic_string safe for concurrent access (the last section - albeit very short - discusses possible disadvantages): http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2008/n2668.htm Your examples have a flaw though. GNU's CoW string implementation is quite old and bad actually - unfortunately I can't find a citiation example for this, but if you read the `__rc_string` code it should be obvious what I mean: Just like in most dumb reference counting implementations (like Boost's `shared_ptr` or GNU's `__rc_string`) they use the strongest ordering guarantees for all operations. Amusingly even [Boost.Atomic explains](http://www.boost.org/doc/libs/1_60_0/doc/html/atomic/usage_examples.html#boost_atomic.usage_examples.example_reference_counters) how to do it correctly: By using `memory_order_relaxed` for retaining a copy, `memory_order_release` for releasing it and `memory_order_acquire` thread fence before deleting the memory. The speed boost you get that way should not be underestimated, but I guess 20 years or so ago when they wrote `__rc_string` the "technology" (or knowledge) for this didn't really exist yet. Also what happens with the SSO type in your second example (which is up to twice as fast) if you just simply do not force a change? Well then it's only half as fast... Now you could say: "Hey thanks to move semantics we barely need to have multiple references to the same string anymore! And thus it's faster in average!" And you would be right... partially. Because even this claim heavily depends on your use-case. And are you even sure you claim holds up as soon as you fix `__rc_string` to use more modern atomics (making it a lot faster on many platforms) and try to anything remotely like splitting a string? Because it seems that's what everyone is overlooking. Imagine you've got an CSV file and you'd like to place the parsed fields into a matrix! The performance disadvantage due to the `std::string` is crazy. The requirement that it must end with a null-byte is crazy stupid as soon as use less and less C/POSIX-APIs and I mean: that should be the target right? Having a fast C++ library and not fast C-interop.? If you'd drop the null-byte at the end of the string you could do so many nice things and basically transform it to a grapheme-agnostic (i.e. use UTF32 etc.) and sliceable/shareable string which not just works fast within C++ code but is also easy to use for anything that's not just ANSII (because I don't see any difference between a `std::string` and a C-string with cached length information and some nice standard-APIs). Sliceable strings would be a bliss for parsing - instead you have to reinvent every wheel because you now have to either somehow make sure a buffer (a string or a vector) is stored to which `string_view`s point to (making sure it doesn't get deallocated to early or too late in e.g. async. code would be a horrible mess but I guess that's what the "great" minds of the C++ consortium have in mind), swallow the pill and use expensive copies for every field for every row (because... you know... some system are just required to be high performance and/or running for a long time which make too many allocations a bad thing) or reimplement it from scratch again as `modern_string_imp` which means all the APIs which only accept `std::string` will only work badly with it. And that's where my reasoning comes from: "I understand why SSO is used and why it can be faster, but I wonder if it's so much faster and if it was ever a good idea to not just fix the rotten API instead." &amp;nbsp; **EDIT**: Sure... Downvote me! But that doesn't change the fact that *removing* CoW *in favor of* SSO (i.e. not using both as it has been done before) is just the result of the horrible `basic_string` API and that it definitely *not just* hurt the performance in average *but also* makes slicing strings something extremely messy (if the API would have been fixed instead). We live in a time of Unicode and if you'd ever have cared "about languages other than Seventh Edition New Jersey ASCII" then you'd actually understand why the historical induced "we treat strings as bytes" approach plus the C-string compatibility and everything that comes with it is **utter poison** for the future of C++. Sure... No one is going to replace the plethora of old C++ code but that also means that C++ will stay being a 80s language at it's core, especially if you consider how we introduce new classes for all the shiny new things but we don't deprecate `basic_string` (which could stay as it is until EOL) and just introduce `basic_string_v2`... Can so. explain to me why that is? But you know what that class would use? CoW. Because it would work.
plus it's a useless question as every C++ vs XLang comparison
This looks awesome. Does anyone know roughly how it works? Are the vectors actual structs with members or do they not store anything? And can this be used as a complete replacement for AVX or are there cases where using compiler intrinsics directly is going to let you be way more efficient? In an older thread you (V_i_r) said this was originally a PhD project, is there no paper to go along with it?
Very useful. I understand that one of the main motivation for this screencast might have been presenting CLion functionalities, but I'm glad that it went way beyond that by showing some of C++11 idioms, where cling might fit and also how gtest workflow works.
Might I add that the difference on my i7 2677M is about 9%? Interestingly that's a lot less than on wandbox... Since I'm missing an IDE for g++ I'm also not really good in identifying which part belongs to where but there are a lot of places where atomic locks are added. If you print the assembly with `-S` there should be multiple occurencies of "lock" before the e.g. "addl" command. Could it be that those belong to the `__rc_string`? There are multiple calls to `__ZN9__gnu_cxx16__rc_string_baseIcSt11char_traitsIcESaIcEE4_Rep9_S_createEmmRKS3_` around it... quite a coincidence, huh?
If all you are doing is adding to the back of the vector( push_back or emplace_back) you can store the integer index of the element. As long as you have not added or removed any elements in fro t of the index it should be valid. 
Funny, that code snippet is almost exactly identical to the example [here](https://doc.rust-lang.org/stable/book/) of the kind of programming errors Rust prevents. You have a few options for achieving your goal. You can definitely not store a direct pointer (references are really just pointers) to a `vector`'s elements if you do any operation that may cause reallocation. 1. Use a different data structure. A `std::list` allocates its elements individually, and never moves them. As a tradeoff, lists are slower than vectors for almost any operation you'd want to do with them. 2. Store the offset. If you store a reference to `vec` and the index of the element, then you can use that information to retrieve the item even after reallocation. It doesn't work if you ever insert or remove anywhere besides the end, though. 3. Copy the element. Not always practical, but it's usually an option and it's certainly the safest route. 4. Don't store the elements inline. If instead of a `vector&lt;string&gt;` you stored a `vector&lt;shared_ptr&lt;string&gt;&gt;` or `vector&lt;unique_ptr&lt;string&gt;&gt;`, then the address of the string itself wouldn't change when the vector reallocated. 5. Write a wrapper around `vector` that keeps a list of every class that points into it, and whenever it reallocates, update the pointers inside each of those classes. 6. Pre-allocate enough space in your `vector` that it will never need to reallocate. If you had called `vec.reserve(2)` immediately after construction, then your example would have worked just fine with no danger of segfault.
Listen to this guy, /u/Ryuuke5. I just want to chime in here with a bit more information about each of the offered solutions and their tradeoffs. 1. This is almost a not-solution. It's true that `std::vector` is the de facto "default" standard C++ container, and that is for good reason (because it outperforms the others in the cases the majority of users face). However, if you don't have a solid grasp on how you're structuring your data and why, then you're doing programming horribly wrong. That is to say, you can't *typically* just drop whatever data structure you're using and pick up another one. In this case, changing out your `std::vector` for a `std::list` would lose you every advantage of the original data structure: Your elements would no longer be contiguous, they would no longer be accessible in constant time by index (and thus you would no longer get a random-access iterator), all accesses would incur the overhead of one or more indirections, etc. Most of the other standard containers would either cost you those same properties or suffer the same reference invalidation. The only special mention in this case is `std::unordered_map`, which I'll talk a bit about below. 2. This is the canonical way to do it if your elements are not going to be changing position -- that is, if you're only ever adding to the back of the container. This allows you to keep using a `std::vector`, and so prevents you from thinking about any of the issues mentioned above, and lets you unambiguously reference any entry, even across reallocations. 3. Another almost-not-solution. It works in some cases, but not in others. If it works for your case, i.e. you don't have to track changes to a particular element after initial access, then this is probably the best way to go, \#2 notwithstanding. 4. When you do this, you lose contiguity exactly as if you'd used a `std::list`, but you still have a random-access iterator and constant-time access by index. Effectively, it's the same as using a densely-packed `std::unordered_map&lt;size_t, WhateverT&gt;` -- where iterators, but *not* element references, are invalidated on reallocation -- except I'd imagine with slightly better performance. I haven't analyzed it; don't quote me on that. If you care about complexity but not data locality, this or a `std::unordered_map` might be the way to go. 5. This is an interesting option. If you wrote a `std::vector` wrapper and an associated element wrapper, then you could have them automatically updating to keep track of reallocations and even motion within the container (e.g. element 4 moves to position 5 because something was inserted in front of it). If carefully written, they could be used safely and transparently in external APIs, with minimal changes to your current usage, and would retain the performance and all useful properties of the `std::vector`. This is probably the best possible solution, but it is much more complex than the others. If you think you can handle it, or if you want to try your hand at a really cool problem with a really useful end result, then go for it! 6. Useful in theory; but if you know in advance how many elements are going to be in your container, why are you using a `std::vector` and not just dynamically allocating an array?
For #6, there are a couple reasons. If the number of elements is known before filling the vector but not at compile time, then you still can't use an `array`. Also, if it doesn't fit on the stack, you'll have to either use a `unique_ptr&lt;array&gt;`, which just feels dirty, or a `vector`.
I a came across boost::stable_vector the other day. I think it fits in 4 and 5, you won't have to write it yourself.
Looking at it, yes, that is exactly what \#4 refers to. \#5 is something totally different.
My point is that \#6 is a non-solution. If you are already having an invalidation problem, as OP is, and you know in advance how many elements you have and that that number will not change, which is one of a very few circumstances under which `std::vector::reserve` is a viable solution, then you could just as easily use a heap array and sidestep the problem entirely. I suppose you *could* have a section of code where you happen to know exactly, or at most, what the number of elements will presently be, and you will need to hold a reference to one of them that will only need to be valid for as long as that number happens to remain constant; but really, how likely is a scenario like that?
The construction issue for non-POD types is a valid concern; I hadn't thought of that. There're ways around that, too, of course, but at that point I guess it is easier as you said to just use a `std::vector`.
&gt; we get that now. No, we don't. Since C++ is not an object-oriented language, we never ever ever write `x.f()`. Unless we're bad wannabe Java programmers.
&gt;One idea I've thought about is the idea of _ placeholders (see haskell holes workflow). Imagine writing _(a,b,c)`, and you can click the right mouse button on the placeholder '_' character. (or get compile time information, 'potential functions at line:...' - this should be pretty easy to do as compiler plugin). I'm not a child. I don't use my mouse while programming.
I had originally put `std::array`, but another commenter correctly pointed out that it cannot be dynamically allocated.
This doesn't really have anything to do with `std::array` or its `size` member function. `size()` is in fact usable as a compile time constant: std::array&lt;float, 4&gt; foo; std::array&lt;float, foo.size()&gt; bar; The reason your example doesn't work is because `arr` is a member of the class, and so there's an implicit use of `this` which makes the whole expression not a compile-time constant. clang hints at this as the reason: 20151221.cpp:8:23: error: non-type template argument is not a constant expression std::array&lt;float, arr.size()&gt; out; // Non constant expression error ^~~~~~~~~~ 20151221.cpp:8:23: note: implicit use of 'this' pointer is only allowed within the evaluation of a call to a 'constexpr' member function 1 error generated. I'm not exactly sure how to work around that, but there's probably a way. 
Seems really strange that you can't access N through the std array's class definition. ie. why not be able to use `decltype(arr)::N`?
You can say `sizeof(arr)/sizeof(arr[0])`, just like with a C array. But what's wrong with just typing 4 again? Or, even better, make it a named `constexpr static` or take it as a template argument.
Rust prevents it, but does not solves it I guess.
Thank you [acwaters](https://www.reddit.com/u/acwaters) and [minno](https://www.reddit.com/u/minno). I ended up doing my own wrapper of vector, I don't know if it's the best implementation, but in my wrapper I kept the vector that hold the users data, and an other `std::vector&lt;std::pair&lt;T**, size_t&gt;&gt;` that point to the users pointers and update them whenever the capacity of the vector isn't enough to hold a new element. It works like a charm !
&gt; But what's wrong with just typing 4 again? 1. When that 4 inevitably changes to something else in the future, you have to hunt down all the other relevant 4s and change those too, which can be error prone. 2. It's not clear from the code that the several different 4s refer to the same value or are related, which can hurt readability and maintainability.
Right, that's (1) a problem that already exists in OP's code which is not significantly worsened by the addition of another 4 and (2) a thing that the third sentence in my comment addressed.
The tab bar looks cool, it has the same style as the vim-airline status bar, does anyone know what plugin is that?
&gt; Right, that's (1) a problem that already exists in OP's code which is not significantly worsened by the addition of another 4 The addition of a single duplicated magic number doesn't significantly worsen the code. Copying and pasting a single line of code doesn't significantly worsen it. Ignoring a single error condition here or there won't make it significantly worse. Adding an extra line to an already reasonably lengthy function won't worsen it significantly. Adding just one more method to an already large class won't make it much worse. It is the accumulation of decisions like this, none of which in and of themselves may significantly worsen the code, which leads to unmaintainable, difficult to understand, brittle and buggy code. You might not think it's much of a problem to have that 4 duplicated in a couple of places, but even a single duplicate is enough to cause code to erroneously diverge when another programmer later changes the 4 in the declaration to a different value without realizing that it's duplicated elsewhere. And as projects grow, duplicated magic numbers like that have a tendency to spread out even further. You asked what was wrong with it and I told you. By all means, do it all you like in your own projects, but at least admit that it's out of laziness and not because you actually have good reasons to and don't try to justify it unless you actually have a very good legitimate reason for doing so. And I don't consider '*but it doesn't make it THAT much worse*' to be a good reason. &gt; a thing that the third sentence in my comment addressed. You asked "*what's wrong with just typing 4 again?*" Well, *that* is one of the things that is wrong with "*just typing 4 again*".
The implicit use of `this` occurs when performing the call `arr.size()`, since it has to be passed as a hidden argument.
&gt; The question was (I thought obviously) rhetorical. Asking a rhetorical question of the form, "*What's wrong with X?*" heavily implies that you think there is, or should be, nothing wrong with X. This is a common idiom that is frequently used in most English speaking countries. For example, "*What's wrong with skipping breakfast? I never bother with it*" or "*What's wrong with drinking a bit of soda? I often have at least a couple every week.*" In this case, the implication was that there was nothing particularly wrong with duplicating a magic number for convenience. I chose to respond to your question and explain the problem with starting down that slippery slope because I disagree with the implication, in much the same way that someone may respond to the above with "*Actually, eating breakfast has many proven benefits...*" or "*Drinking small amounts of soda may be okay, but...*" You don't seem to actually disagree with the points I raised (especially after clarification), so I'm confused as to why you still appear to be trying to argue.
It's the tabline extension for airline, see my vimrc https://github.com/alepez/dotfiles/blob/7889d4ad4389ae9ba13c9d3130b61a6aa15974b2/vimrc#L420-L448 tabline is bundled with airline, just enabled it.
You can do something like this: template&lt;typename T&gt; struct ArrayTraits; template&lt;typename T, size_t N&gt; struct ArrayTraits&lt;std::array&lt;T, N&gt;&gt; { static constexpr auto Count = N; }; struct MyClass { std::array&lt;float, 4&gt; arr; float carr[4]; std::array&lt;float, 4&gt; function() { constexpr auto N = ArrayTraits&lt;decltype(arr)&gt;::Count; std::array&lt;float, N&gt; out; return out; } }; ---- **Edit:** I completely forgot about this: `std::tuple_size&lt;&gt;` also works with arrays.
The standard makes no explicit guarantees about the `sizeof` any aggregate. While it's likely to work as expected in most cases, it is *possible* for a standards-conforming implementation to have padding at the end of an `std::array` that does not exist in a C-style array, for example. Here's a [real example](http://stackoverflow.com/questions/8262963/stdarray-alignment) where somebody found that `sizeof(std::array&lt;int,5&gt;) = 32` where `sizeof(int) = 4`. In this case, `sizeof(arr) / sizeof(arr[0])` is 8 while the real size of the array is 5.
As far as I understand the situation, the implicit use of `this` is kinda like invoking `operator -&gt;`, which in itself not `constexpr`. The evaluation of `constexpr` expressions for function chains at compile time must be examined as whole, that is: `this-&gt;arr.size()`, so each an every function in the chain must be `constexpr`. 
I don't see that. making 2 functions that do different things called ```foo(a,b)``` and ```a.foo(b)``` would be confusing IMO (where a &amp; b have the same types in either case). Whats' more likely if you find those is: one is just a wrapper for the other, like ```auto std::begin(auto&amp; x){ return x.begin();}```. People have to put those wrappers in already to workaround the *lack* of UFCS. I'd also be perfectly happy with explicit opt-in, ```void foo(Bar* this,...)``` i.e. it only works for functions with an explicit this pointer. I'd even be happy with another way of extending the class, e.g.: ``` extend class Bar { void foo(...) }``` etc. maybe ```class Bar+={}``` to avoid needing a new keyword, whatever. The extention can't add fields or vtable members, obviously. (infact either of these would be better since they would facilitate moving code to &amp; from the class, but I'm happy with regular UFCS too); You think UFCS will create more bike shedding? Don't you see the bike shedding only happens because of the conflicting demands. If you give both styles all capabilities - the conflict goes away. People will just use the form thats' easier to read &amp; write. (.. given the power of autocomplete IDEs, you can be sure that method syntax will be more common..). At the moment the decision affects your whole program structure, its' so annoying !!!! With UFCS it no longer matters. if someone else wants to call my A::foo(b) foo(a,b) it doesn't affect me, and vica versa; whereas today, we have to fight over *what goes in the class*. Dot autocomplete is incredibly useful; it should be available to all functions. With UFCS we could move more code out of the classes, making it much easier to share &amp; re-use, whilst still having autocomplete/chaining. The world would unambiguously be a better place.
If, as you show here, all you need is to be able to add items to the end (or beginning) of the sequence without invalidating references/pointers to the elements, then you probably want to use a `deque`. It specifically supports that ("An insertion at either end of the deque [...] has no effect on the validity of references to elements of the deque.") Of the standard containers, `deque` is the most like `vector` in general (provides constant-complexity random access, etc.) so if it can meet your needs, it's usually the obvious second choice. Oh, one warning though: Microsoft's implementation of `deque` has what I'd consider a mistake in its design, so if your elements are very large, it ends up essentially equivalent to a vector of pointers. It still automates most of the work involved though, so I'd usually prefer `deque` to a vector of pointers, unless you truly need to ensure (for example) that each element is separately allocated.
Even though I'm not personally convinced, Bjarne wants UFCS and that's probably good enough for me. But it will be unfortunate if I can't use the pipe symbol for piping :(
have you dabbled with the Rust language? .. if so, what do you make of it? if not, i'd recommend taking a look. it's probably worth looking into because of the 'concepts' feature coming soon to C++, it has something similar in its' 'traits'. It all fits nicely. it has 'methods', but they're not 'in the class'. they're divided into groups, giving more structure than purely free-functions, but still having the advantage of bolting on seperately. Once you've seen this, hopefully it will break you out of the mindset that "." means OOP. There's 'go' aswell, which whilst it's limited compared to C++ (no generics, relies on GC), it too has a 'bolt-on' system, nothing 'in the class', but retaining the 'dot-notation' . I think it all flows perfectly naturally; I think it would be possible to merge Rusts' system with C++ (especially after it gets concepts). when it does use vtables, they are a different style, a bit closer to COM objects. I think, just like clang merges C,C++,objective-C into one AST, that you could build a single compiler that worked with a superset of those systems, with the appropriate subset being fed by a language front-end
Dlang seems similar to C++ so I think it would be interesting to hear how it has worked out for them in a big code base.
You forgot an 'e' at the end of your URL.
&gt;C++ is actually a multi-paradigm language, with OO being one valid aspect of it. Correction: one useless and very invalid aspect of it. &gt;Rust does this and is nothing like Java. There are no methods defined inside a struct; (it has no concept of a 'class' either), and anything with compile-time polymorphism (like templates &amp; overloading) is called with '.' Rust is a terrible language. &gt;Why not just use '.' in C++ when it works already in that capacity. Because you can just write `f(g(x))`. 
It's the pipe operator, widely used for building pipelines for nearly fifty years.
&gt;'dot notation' does not imply object orientation. with UFCS seen in D, it can be used for free functions. In rust it is used for templated code. D is a failure, why would we want to take one of its worst features? &gt;I guess you must write template&lt;typename X,typename Y&gt; auto add(const X&amp; a, const Y&amp;b){ return a+b;} etc because infix is useless, right? why should the functions 'add', 'subtract' etc have an infix form whilst 'dot', 'cross', 'transform' etc shouldn't? why abuse '&lt;&lt;' bit shift operator for file operations, why not a clearer name a.write(b) etc. Infix operators are horrible, yes. 
well given that C++ has so much that you despise.. OOP and infix operators, and 'pipe' repurposed for bitwise OR - why not get together with likeminded people and make a new language, then the C++ community can be freed from your opinions. 
&gt;Any serious program is a huge series of internal APIs. And if they're well organised, you don't need (or want) clunkly autocomplete. &gt;Even when working with something you did write , over time, as your program grows you are not going to remember the details of every single call. You don't need to *remember* the details. The API should be intuitive. &gt;Simply remembering more details of a specific peice of software might be taking up long term memory in your head which would be better spent on fundamentals like mathematics &amp; natural sciences. API's are transitory. You're merely being stupid trying to remember everything when you can delegate the search task to a computer. It's like using mental arithmetic when we have calculators (and of course computers,spreadsheets, REPLs) It's not about memorisation. &gt;In clojure they give you a threading macro (-&gt; (foo a b c) (bar d) (baz e)) to do the same job. F# has |&gt; I have no problem with `foo | bar | baz`. I do have a problem with 'if `foo(x)` exists, `x.foo()` means the same, and vice versa, unless they're both defined.' &gt;We are still missing ADTs. You'd do well to take a look around elsewhere for a broader view of what's possible. Many agree we need concepts, and they come from haskell. (rust has already achieved a blend of these with C++'s key features). Concepts most definitely do NOT come from Haskell. And yes, C++ has some missing features, and some missing misfeatures. It does not want or need UFCS. UFCS is a disgusting, ugly, confusing hack. &gt;It is objectively more readable because the functions are closer to their arguments. you can see a flow of values from left to right through the functions. It's objectively less readable. Hey look I can make statements with no backup either. Functions closer to their arguments? What? Why do you people always assume that there's a flow of values involved? Why do you people always assume there's a flow of values from ONE argument to MULTIPLE other arguments? Why can't it be from MULTIPLE to ONE? &gt;This is why we use infix notation; Infix notation for mathematics is objectively the worst option. We use it for historical reason. Prefix and postfix notation are both CLEARLY superior. &gt;its' why LISP isn't popular; Lisp's popularity has nothing to do with syntax. &gt;its' why natural language also evolved to do similar things. subject verb object; how it avoids needing so many parentheses What a biased thing to say. You do realise that word order varies between languages, right? You do realise that every single one of the six orderings has been attested in natural languages, right? VSO, SVO, SOV, VOS, OVS, OSV. Not all are as common as each other, and S before O is far more common than O before S, but VSO is a common ordering. &gt;you can disambiguate function names with trailing prepositions, and you've ruled out that they might apply to the first parameter. e.g. a.copy_from(b,c) is clear, copy_from(a,b,c) is less clear; it could mean copy from 'a','b' into 'c'. Poorly named function, then. &gt;The negative side is purely due to the fact you can't add methods outside of the class; thats' why C++ programmers have learned to fear it. 'Methods' don't exist. They're called member functions, Java programmer. &gt;But as soon as you gain this capability (which has been demonstrated in other languages, e.g D, Go, Rust, C#), the hazard goes away and it is universally better. F# has its' |&gt; to do a similar job,clojure gives you the threading macro; C++ already uses . so why not stick with that in our domain. Again, nobody has a problem with `foo() | bar() | baz()`, but `foo().bar().baz()` makes no sense. &gt;I guess your world is static and dull. Everything is set in stone, nothing evolves. Fuck off dude, I never said C++ shouldn't evolve. I said that we shouldn't adopt UFCS because it's stupid, ugly, confusing, and not at all useful. 
&gt;OOP No competent C++ programmer uses OOP except in a couple of very narrow areas (like GUI programming). &gt;infix operators Infix operators aren't *always* bad. They can be quite useful. e.g. in `sh` as the pipe operator for piping between processes. This is something that should be added to C++. But are you SERIOUSLY trying to convince me that infix operators are always better than the alternative by using fucking `&lt;&lt;` from iostreams? Iostreams is the worst API I have *ever* used and I've used some bad ones. std::cout &lt;&lt; '(' &lt;&lt; x &lt;&lt; ", " &lt;&lt; y &lt;&lt; ", " &lt;&lt; z &lt;&lt; ')'; std::cout &lt;&lt; std::endl; -- std::format("(%, %, %)", x, y, z); SO much better. SO SO SO SO SO much better. Please add this, committee, if you're reading this (which you aren't). 
Would `arr.size` work if `size` was a static function?
&gt;&gt; But that's not true. It's not easier to read. it is, measurably, easier both to read &amp; write, because it keeps operands closer to their operators. One way to look at it is, its' an optimisation for serialising a graph. 
&gt;&gt; except in a couple of very narrow areas (like GUI programming). ah, now we're getting somewhere. GUI is not a narrow area. Getting data to &amp; from humans efficiently is a huge deal. &gt;&gt; by using fucking &lt;&lt; from iostreams? thats' actually a classic case of something that would be clearer with a function with dot call notation. EDIT I did actually say that, *"why not .write()"* People were evidently desperate for something infix, but they obviously ran into the organisational problem with methods (the file objects would have to know about every streamable class, unworkable), so they abused the existing operators to do it. There's a lot like this in C++ - things that *almost* work, but features are missing, so people stretch whats' there in ugly ways to get something done. Just like the OP's abuse of '|' to do chaining, which introduces layers of template madness to get this done, and I bet he'd prefer a different operator like F# ```|&gt;``` &gt;&gt; std::format("(%, %, %)", x, y, z); I do prefer format strings to &lt;&lt; often.
&gt; And if they're well organised, you don't need (or want) clunkly autocomplete. I'm trying to put my finger on the way to best describe your nastiness here. There is necesserily more information in the world than any one person has encountered. Computers can help you find whats relevant. This is why google is such a big deal. You are basically opposed to a tool being readily available to programmers that makes it easier for them to find each others work. A tool that automates inter-programmer communication. There's the "preistly cult" mentality? Lets make this difficult, to create an artificial barrier. Then the activity becomes about one person asserting superiority and attacking others, rather than helping people. Because they're naturally nasty people. &gt;&gt; 'Methods' don't exist. They're called member functions, Java programmer. I can save a word here by saying method. and I've never used Java. &gt; foo() | bar() | baz(), but foo().bar().baz() makes no sense. It makes sense to every programmer that uses C++ with an IDE, because it flows from the keyboard naturally. &gt;&gt; Fuck off dude, I said that we shouldn't adopt UFCS because it's stupid, ugly, confusing, and not at all useful. I've explained why its' useful - and you come up with some bizarre attack on productive tool that most programmers love Anyway. Given that you don't want much in the way of tooling, why not leave C++ and just make your own prefix notation language, minus OOP. Then you don't have to inflict your opinions on me. Send an email to this chap explaining how wrong he is. https://isocpp.org/files/papers/N4165.pdf he explains it eloquently here. I agree with his explanation.
&gt;I'm trying to put my finger on the way to best describe your nastiness here. TIL I'm "nasty" because I disagree with someone on the internet. &gt;There is necesserily more information in the world than any one person has encountered. Computers can help you find whats relevant. This is why google is such a big deal. Again, you don't need the language to be defiled in order to make autocomplete work better. Feel free to use autocomplete, but don't make the language worse just so you can use it slightly better. &gt;I can save a word here by saying method. and I've never used Java. 'Method' doesn't exist. There is no such thing as a 'method' in C++. &gt;It makes sense to every programmer that uses C++ with an IDE, because it flows from the keyboard naturally. Unsubstantiated bullshit. &gt;I've explained why its' useful - and you come up with some bizarre attack on productive tool that most programmers love I have explained how it is not useful. It does not give a a large enough benefit. Its benefit is very, very small and its cost is an ENORMOUS increase in confusion and complexity. &gt;Anyway. Given that you don't want much in the way of tooling, why not leave C++ and just make your own prefix notation language, minus OOP. Then you don't have to inflict your opinions on me. I already have one. It's called C++. We write functions like this `f(x)`. It's quite nice. You should try it. 
&gt;&gt; You don't need to remember the details. The API should be intuitive. But software is too complex to be 'intuitive' at every step. Useful programs are hundreds of thousands of lines or more. Figuring out exactly what subset of all that is available at each point, or where to look for that part that you want, is inherently difficult. If you didn't remember the details, you're going to have to constantly shift focus to documentation. So we make search tools. We can leverage Type information for that .. hence dot autocomplete. (and the haskell holes idea which goes further, but lets run with what we have, and extend it). Simple text based search is limited because of overloading and namespaces,without which you'd run out of symbols. &gt;&gt; You do realise that word order varies between languages, right? "SVO is the most common order by number of speakers" So of the experiments, the most useful appears to have flourished here; it's the one like Infix, which also flourished for maths. &gt;&gt; Lisp's popularity has nothing to do with syntax. then what? Its' other features have been copied elsewhere (dynamic types, lambdas, high order functions) it's syntax has not. &gt;&gt; nobody has a problem with foo() | bar() | baz(), but foo().bar().baz() makes no sense. LOL for a C++ programmer the first is ORing some values together, whilst the latter flows easily from their dot autocomplete (and if they've had to work with multiple languages, its the syntax they've most likely already seen) Do you get confused by ```myvec.resize(4);``` ?
&gt;&gt;"is an ENORMOUS increase in confusion and complexity." you're confused by a.foo(b) REALLY???? someone so smart? yet you can switch between reading '|' as bitwise OR and 'pipe'? are you confused by 'a.foo' for field access? Its' like a field, but you call it. Seems pretty clear to me. &gt;" It does not give a a large enough benefit." the benefit is enormous. &gt;&gt; We write functions like this f(x) its' nice until you chain many together. Its also nice to separate the arguments (you have the opportunity to separate source &amp; dest either side); it makes it easier to come up with a function name that helps convey what the arguments do. (some people actually like going so far as to use the dot notation with 'builder' patterns and so on, just so they can annotate each parameter; personally I think thats' going too far, but I can see why they do it) &gt; 'Method' doesn't exist. There is no such thing as a 'method' in C++. language lawyer, LOL. I bet you knew what I meant, and I saved a word. You didn't advance this debate by pointing this out, you're just being pedantic for the sake of disagreement.
&gt;&gt; "Feel free to use autocomplete, " with the language in it's current state, the autocomplete I refer to is only available to member functions. That means people who write APIs are compelled to put functions in the class, with the resulting dependancy hazards I'm sure you know about. APIs written this way become more popular, because the tooling makes them easier to use. Like it or not thats' what we've ended up with. What we want is UFCS, so we get the right type of autocomplete, *without* needing to put functions in the class. Thats all. UFCS appears to be the most natural way to do it, other options would be to adopt something like the 'trait-impl' system from Rust (i don't know specifically if any of the proposals around concepts go that far, but it might make sense). Another way would be an explicit 'this' pointer, which would facilitate refactoring code (i.e. removing functions from classes , from legacy code).
&gt;there's no difference in DISTANCE there is. x is further from f. in the former example, 'f' is equidistant from 'a' and 'x', which are both adjacent. And? &gt;foo(bar(baz(a,b),c),d) vs baz(a,b).bar(c).foo(d). What about when you get really disgusting stuff with the latter like: baz(a, b).bar(a.foo().bar(b.foo())).baz(a.foo()) Also in your example, while arguments may theoretically be closer to functions, the functions are further away from the other functions, which interrupts the flow. I want to see the functions more prominently, because they're more important. &gt;its easier to read, and easier to write, because it's an efficient encoding of the graph. In an IDE the autocomplete would have helped you at every step, finding the functions you wanted, and telling you what the parameters are, which is a massive help when working on someone elses &gt;100kloc sourcebase. The codebase is the problem if its API is that complex that you need to have ALL of it available to your ALL the time. 
&gt;with the language in it's current state, the autocomplete I refer to is only available to member functions. That means people who write APIs are compelled to put functions in the class, with the resulting dependancy hazards I'm sure you know about. Then fix the autocomplete. Set it up so you can write `a.` the press TAB and it will autocomplete to `f(a)` and `g(a)` and `h(a)`. It's not hard. &gt;APIs written this way become more popular, because the tooling makes them easier to use. I disagree. &gt;What we want is UFCS, so we get the right type of autocomplete, without needing to put functions in the class. Thats all. Fix the autocomplete, don't defile the language. &gt;UFCS appears to be the most natural way to do it, other options would be to adopt something like the 'trait-impl' system from Rust (i don't know specifically if any of the proposals around concepts go that far, but it might make sense). No, fix the autocomplete.
&gt;you're confused by a.foo(b) Where does `foo` live? Is it on `a`? Is it just a random function template somewhere in the standard library? What happens when there are conflicts? Name resolution is already hard enough in C++. &gt;its' nice until you chain many together. Its also nice to separate the arguments; it makes it easier to come up with a function name that helps convey what the arguments do. You shouldn't write stuff like `x.a(m).b(n).c(o).d(p).e(q)` anyway. You should use intermediate variables so you can see what is going on. It makes debugging MUCH easier later and makes code MUCH more clear. // difficult to understand, debug and modify later. auto data = get_data() .filter(...) .map(...) .filter(...) .take(...); // easier to understand, to debug, and to maintain auto all_items = get_data(); auto only_valid_items = filter(all_items, ...); auto valid_items_names = map(only_valid_items, ...); auto starting_with_letter = filter(valid_items_names, ...) auto first_hundred = take(starting_with_letter, ...); &gt;(some people actually like going so far as to use the dot notation with 'builder' patterns and so on, just so they can annotate each parameter; personally I think thats' going too far, but I can see why they do it) Clearly it's going too far. Add named arguments, that will *actually* make the language easier to understand. Don't add UFCS, which encourages poor APIs. 
How cute!
Actually, it does support array, through unnamed values node (see our link, or my post where I explain how to do it :) ). But as you just pointed out, the property_tree structure wasn't design to handle JSON, and node aren't typed (all node contain only strings). The actual version doesn't provide typed output, although it could partially support it (there are some hack about it on stack overflow. I also proposed a pull request with a fix in the parser). But many time, you don't need a full support of types, and a partial support is fine enough, especially if you don't want to add one more library to your project.
This solves the example, not the problem – it is not generalizable, and consequently is a non-answer.
Try printing out response in the default case. See what it's actually ending up in there.
I printed out the response in default case but it skipped it when i press y, n or anything else it just skips the switch? maybe ill try playing the code line by line
Print out response before the switch to see what input it is picking up. Also try printing out something in the 'n' case.
Wow, libcrystax is wonderful. When I try to use Boost::asio by Crystax, an error occured: java.lang.UnsatisfiedLinkError: dlopen failed: cannot locate symbol "epoll_create1" referenced by ... I think this error is caused by Google's libc, and libcrystax is the answer, but how can I import libcrystax to my project? Now, I can use any Crystax boost prebulit libs in my project thanks for the sources\boost\1.59.0\Android.mk, but I can't find the same .mk file in sources\crystax folder.
Late, the final [3.6](http://blog.qt.io/blog/2015/12/15/qt-creator-3-6-0-released/) has been released days ago
Are you required by a class or an employer to learn c++ specifically? I ask because I've taught lots of new programmers, and I've taught c++, and every new programmer to whom I've taught c++ first struggled so much to learn the language that they had trouble learning to program. Every one of them who took my advice and switched languages (R, python, java in those cases) saw an improvement in their programming. I'm sure that some of them have gone back to tackle c++ (it took Java in college to prepare me to tackle c++ again after some juvenile thrashing in high school). I say this as someone who makes a good living with c++: if you can, start with a different language. Perhaps python? I like it quite a lot, it's *everywhere* in industry and academia, and it instills good habits and design patterns. On our project, we choose python every time we can, resorting to c++ only when warranted. I know lots of shops follow a similar model. After you have learned to program in your first language, learning the basics of another language is a matter of a few days. Unfortunately... C++ is complex enough I still learn new shit after ten years...
You'll need to flush the buffer because of a trailing '\n' from the cin. (Since you said you're new to programming, what this means is there is a '\n' waiting to be processed, which the getline consumes and thus exits the getline.) There might be other ways to deal with the hanging '\n', but I'm not sure. Maybe google it.
So the real point is why isn't it static then.
Finally I find the error reason is that I didn't set the Application.mk correctly. Now I can use asio freely.How wonderful the crystax is!!!
[http://redditmetrics.com/r/cpp](http://redditmetrics.com/r/cpp)
[correct](http://stackoverflow.com/questions/21936507/why-isnt-stdarraysize-static)
&gt;you can already write free functions inside a class. ('static..'), so free functions can already be anywhere. All you'd lose is the information that 'a.foo(b)' IS inside the class, but you don't want that anyway, so its' irrational for you to claim its' "adding confusion". (I don't want it inside the class either; the point of UFCS is to decouple more). And if you do, they're written `scope::foo` not just `foo`. &gt;Anyway just hit F12 or whatever to jump to definition. I don't have a jump to definition feature because the definitions I use are almost always deep inside header files. This is C++, **not Java**. &gt;the compiler knows. the IDE knows. I don't use an IDE. &gt;with all the potential overloading and namespacing it is already beyond easy human comprehension, but fortunately we have machines to help. It's beyond your comprehension, it is not beyond mine. I am a competent C++ programmer, you are not. &gt;Depends on the context. naming is hard. reducing the number of things you have to name helps declutter. To me it seems helpful to leverage the expression to eliminate temporaries altogether. Naming is hard if you're illiterate. 
&gt;&gt;Then SIMPLIFY THE SOFTWARE. Software is necessarily complex; there is a certain amount that cannot be simplified away. If it could we could end this argument because we could just diverge and choose alternative languages. C++ is important because of complex projects that we depend on. I looked into Rust, it was promising and had a lot that I liked but lacking the IDE tools the elegant language tweaks didn't produce a productivity boost. I merely learned the hard way how much the IDE &amp; tooling matters. I even rolled my own language borrowing what I liked from C++ &amp; Rust. It works, implementing my exact preferences with greater C++ compatibility than Rust, but I had the same problem: I can't produce the supporting tools single handedly. &gt;&gt;That's because IndoEuropean languages are dominant in the world, because of imperialism and colonialisation. &gt;&gt; Not because SVO is better. they list mandarin as SVO. &gt;&gt; No, it isn't. It's a pipeline. C++ has important niches in low level,embedded, where its' inheritance of C's bit-bashing is important. In graphics the first use of | is combining flags to pass to APIs (or bit bashing values that hardware will consume in lower level work, someone has to implement the drivers etc); then you get many people who like to overload it as vector dot-product. And, they often like putting member functions into vector classes for more besides, able to tame 3d maths expressions with the infix style. Its' widely regarded that GL's function interface taking non type safe ID's is inferior to D3D's more OO-like approach (even when it isn't doing vtable indirections, tweaked on a console). People are widely familiar with the a.foo(b) style, and easily read | as bitwise (or something else). I haven't heard any people say they'd prefer C++ to look like Bash.
&gt;Software is necessarily complex, there is a certain amount that cannot be simplified away. I fundamentally disagree. Sorry, but this is something we disagree on, it seems. You are NOT required to write complex code and bundle it up into gigantic monolithic overly complex APIs. Yes people do that all the time, NO that is not how to write good software. &gt;they list mandarin as SVO. Don't be intentionally obtuse. I didn't say every SVO language was IndoEuropean, I said that those numbers are heavily influenced by that fact. 
As an aside, you want `fstream moreInfo(firstname + "_" + lastname + ".txt", std::fstream::out | std::fstream::app);`. Theres a difference between | and ||, the latter always returning a boolean (0 or 1) and not a combination of the two flags.
Any idea how much of http://semver.org/ this supports?
&gt;&gt; I don't have a jump to definition feature because the definitions I use are almost always deep inside header files. we should be getting rid of those god awful header files with modules. And header files don't change the fact that the definition could be anywhere. header-file explosion is an unambiguously acknowledged problem, which is why the C++ community on the whole wants modules. &gt;&gt; This is C++, not Java. quit bringing up Java. I never said I wanted JIT, or Garbage Collection. I didn't even say I want vtables. (I just accept the option of them can be useful, sometimes) you're extrapolating and conflating unrelated concepts just to insult me. ad-hom argument technique. &gt;&gt; It's beyond your comprehension, it is not beyond mine. &gt;&gt; Naming is hard if you're illiterate. Naming is hard because its' subjective. See how you freak out with "a.foo(b)" whereas just about every programmer I've ever met is happy with it. (infact in my dealings I've had the reverse, where I've wanted to use free-functions to reduce header dependancies and other programmers insist on a.foo(b) and hence member-functions because they find it more readable. This is why I want UFCS, its the best compromise ). You seriously think | overloaded for pipes is less ambiguous, whereas in my circles it's second meaning is more likely to mean "dot product", and its' primary meaning is bitwise OR (flags being used all time time). If you can get such ambiguity from the potential meanings of *one character...* &gt;&gt; "It's beyond your comprehension, it is not beyond mine." it is beyond your comprehension, you reject "bad APIs" if you can't fit them in your head. in many domains the size of a program is dictated to you. &gt;&gt; It's beyond your comprehension, it is not beyond mine. I am a competent C++ programmer, you are not. Elsewhere you say *"a.foo(b) causes immense confusion"*, so something doesn't add up here. (its' beyond your comprehension perhaps?)
&gt;&gt; I don't use an IDE. This is like saying *"I must use mental arithmetic all the time".* *"I must never use google(or other internet search engine)"* Computers can make life easier, thats' why they were invented. They are there to automate chores, to process data beyond our immediate capacity. Rejecting IDE's is just illogical. *"I'm writing software but I refuse to use software to make writing software easier.."* Even if you don't use member-functions, you have overloading, namespacing, field acess which means definitions can't be found by a simple search (what fields does this type have? of, this field is also a struct, what fields does it have? what type is this return value?). An IDE is an invaluable tool. 
"I didn't say every SVO language was IndoEuropean" but you implied its' popular by virtue of imperialism. mandarin would appear to be a counter example. &gt;&gt; "Yes people do that all the time, NO that is not how to write good software." peoples' time is limited, so they have to make compromises. The fact is , there are pieces of software people need and use, that are complex, and much easier to deal with using an IDE with jump-to-definition, and dot-autocomplete. I discovered for myself how useful these are when I moved to rust. I prefer the language design in most ways, but the IDE productivity boost turns out to be more significant.
That's great! I say keep going. The language really isn't that hard. It gets a little weirder when you start needing to understand some of the darker corners, because maybe you're implementing some crazy library. But if you stay on the main road it's OK. 
&gt;but you implied its' popular by virtue of imperialism. mandarin would appear to be a counter example. Well firstly, you'd have to be pretty ignorant to claim that China hasn't historically been highly imperialist. And no, it isn't a counterexample. I said that it being the most common word order in Indo-European languages is A FACTOR in it being the most popular worldwide. &gt;peoples' time is limited, so they have to make compromises. The fact is , there are pieces of software people need and use, that are complex, and much easier to deal with using an IDE with jump-to-definition, and dot-autocomplete. No, they do not have to make compromises. They choose to make compromises. 
&gt;This is like saying "i must use mental arithmetic all the time". "I must never use google(or other internet search engine)" If you need to google how to use your programming language, you're incompetent. &gt;Computers can make life easier, thats' why they were invented. They are there to automate chores, to process data beyond our immediate capacity. And? &gt;rejecting IDE's is just illogical. "I'm writing software but I refuse to use software to make writing software easier.." I do use software to make writing software easier. I don't use an IDE because there are other ways to use software to make writing software easier without using a slow monolithic beast of a program. &gt;Even if you don't use member-functions, you have overloading, namespacing, field acess which means definitions can't be found by a simple search. An IDE is an invaluable tool. No, it isn't. It's a tool, and they're usually slow and bad.
&gt;&gt; UFCS is the one we're discussing and in the context of adding it to C++, it's retarded. I don't like to 'argue from authority' but Bjarne himself has proposed this feature. you think Bjarne, the creator of this language is retarded? The fact you use it would indicate otherwise. 
&gt;&gt; If you need to google how to use your programming language, you're incompetent. if you have to read a book because you didn't invent it all yourself you're incompetent? No. To leverage what other people have created, so you're more likely to create something complimentary to what already exists, that means reading through information to find *what* already exists. A book is a linear encoding of data. Google or other search tools in computers can keep a larger repository of information that you can ever hope to read, and use various hints (keywords in searches, or the types of variables) to find what is relevant to you, traversing the data in a non-linear way. This acceleration is highly useful. choosing an efficient tool does not make someone 'incompetent'. its just optimising how one uses ones' limited time. 80 20 rule. You want to spend your time memorising APIs' (which are transitory, going and out of favour over the years).. you are merely wasting your own finite time. &gt; And? And you seem oblivious to this fact. Listening to you, it seems you think the purpose of programing is to belittle others. *"you are incompetent"* is something you're throwing around a lot. over a "." (which is extremely popular), for fucks sake. &gt;&gt; "No, it isn't. It's a tool, and they're usually slow and bad." They usually work well, which is why people use them. (and why they in turn like to use 'dot notation' to leverage them). The combination of that, with type-aware *'jump to definition'* (much better than 'grep'), debugger integration, maybe profiling tools too, is an invaluable combination.
Yeah, that's about when I started, too. I'm telling you, this isn't an issue of "try something hard and prove yourself", it's literally that c++ is a terrible language to learn to program in. But if you're enjoying fighting your compiler, by all means carry on.
And here you can see drop in the last 3-5 days.
&gt;&gt; "Then quit trying to make C++ into Java." what? Ive never said anything about JIT, or garbage collection. Also, UFCS lets you move things OUT of the class, wheras the Java mindset is everything IN the class. UFCS actually makes C++ *LESS* like java than it *currently is*. &gt;&gt; "Are you trolling? Pipe literally never has meant dot product." &gt;&gt; "In no context does it mean dot product. " https://en.wikipedia.org/wiki/Bra–ket_notation Note the use of the *vertical bar separating the left and right parts of an 'inner' or 'dot' product*. This source of inspiration has made many *(educated)* people independantly use | for dot-product. Easy to put in brackets to look more like that. When I see this, I know why the author did it: they're assuming someone else who might work on 3d maths code would *also* have a maths/physics related education, or have been interested enough to read around the subject. But there you are calling me illiterate. Oh, and its' been around a *lot* longer than Unix pipes. ```&lt;a|b&gt;``` since 1939, ```[a|b]``` a century earlier, if you want to play "whats been around longer". Dot-product is common enough in 3d maths to want an operator; * doesn't make sense because thats' needed for (also common) multiplication by a scalar, and/or vector x matrix. Failing that of course, a *member function* lets you write expressions that still read&amp;write expressions in the order you mentally think of them. (sorry if they cause *you* 'great confusion', lol) I wouldn't want "." for dot product in C++, because it's already used for field access and Member Functions (and I use member functions simply because I want ... ). The use for fields extends to member-functions quite naturally IMO. 'Structs' with fields are pretty damn useful for graphics too. Come to think of it, ```a.foo``` could read like an accessor function. Lots of functional people seem to want it for 'function composition' but again, I'm happiest with its' current meanings. &gt;&gt; If you can't fit them into your head, they're fucking bad APIs. you can't fit a whole sourcebase in your head. But, an *intuitive* API is quite useable from writing the name of the most significant variable you want to use, hitting '.', and seeing a list of potential functions, then picking the one that sounds like what you want. Actually, intuitive APIs in conjunction with dot-autocomplete mean you can use them *without even needing to read documentation*. You can figure everything out from the autocomplete suggestions. What's really happening here is: dot-autocomplete is performing a type-based search; the IDE is doing the work of communicating between library writer &amp; user. It really accelerates someones ability to dive into an unfamiliar sourcebase. &gt;&gt; I don't have a jump to definition feature because the definitions I use are almost always deep inside header files. Jesus, do I have to spell everything out. 'jump to definition', 'jump to declaration'. an IDE usually falls back to declaration if there's no definition. You could make a little rule to cycle between them on one hotkey (if you're already at the declaration, go to the definition. show the declaration first if you prefer that). 
more great explanation from herb sutter: "It more directly corresponds to what programs do: State transition. Programs exist to express ways to transition the system through successive valid states. And that’s the difference: Functions and methods are merely names for the transitions. Objects are names for parts of the current state. And the state is far more important than the transitions: the result of a program is its final state; the thing you serialize and deserialize (to save to disk and restore, to send on a wire and re- ceive) is its state (or part thereof). If we recognize that programs are all about expressing how to get from this state to the next state, it becomes natural to realize that code wants to be written the same way, and that the fundamental question on every new line of code is: “From my state I have now (my objects and variables), what can I do to get to the next state (functions and methods)?” I start with the state I have now (my objects and variables), and then I do something to that (function or method).1" ... i.e. why it works so well with chaining. 'a series of state transitions'. if you used '|', you start with a variable then say "OR", that makes less sense in C++.. much more ambiguous.
The mods posted something about a month ago, about cleaning out old accounts finally, and that some subs would see a drop in subscribers. I guess its hitting this sub now. I could imagine the more technical subs might get hit harder %wise, since reddit was more technically oriented in its earlier days. 
Thank you for explanation.
&gt; im finding it a challenge but not like everyone says how hard it is. You completely misunderstand. It's not that C++ is hard to program in, it's hard to program in *correctly*. It's easy to write code that *looks* like it works, and that *appears* to work when you run it in simple programs, but which is still incorrectly-written C++. This is stuff that you cannot possibly notice is wrong until it trips you up in a more complex program... by which time you may have practiced the wrong way for months already.
Title is worth a chuckle. 
-1 and I wish I could do it thrice
pretty useful, thanks!
My weekly blogroll gives you a good overview: http://meetingcpp.com/index.php/blogroll.html
Nice work! It was quite a pain for me to work with Boost.Graph. Unfortunately I am not allowed to use Lemon Graph which is way easier and also faster for my use cases. Some remarks (being at page 65 of v1.2): * You often create vectors of vertices/edges/names. When using unfiltered graphs you could use `reserve` in combination with `num_edges`, `num_vertices`. * Sometimes, like when retrieving all the vertex names you first retrieve a vector of vertices to then iterate over them. In this case it is way more efficient to iterate directly over `vertices()` and avoiding the intermediate `vector` alltogether. * You are not consistent in the way you access property maps. Sometimes you use `my_map[XYZ]` and other times `get`. To have flexible code you should always use `get` and `put`. That way you can change the vertex storage from `vector` to something else, _without_ having to adapt all the other code. * You should also mention the complexity of operations. The way you retrieve a vertex by name is O(n). I guess in most use cases it will be more efficient to have an `std::unordered_map&lt;std::string, MyVertex&gt;` and doing a lookup instead. * You could use the standard algorithms in some occasions, for example when you search for a vertex by its name (5.2): auto vip = vertices(g); auto it = std::find_if(vip.first, vip.second, [&amp;](const VertexDescriptor &amp;vd) { return get(vertex_name_map, vd) == name; }); * You do not reuse your own functions, for example, you have an own function to retrieve the out degree of a vertex and then you have the same function when just a name was provided. I think a more natural way would be to retrieve the vertex given a name and to then call the out degree function with the retrieved vertex.
This tutorial is excellent, but I really would like to avoid using Boost.Graph in favor of something more lightweight and modern. Are there any lightweight c++11 libraries for doing some basic processing on directed graphs? I saw mat69 talk about Lemon Graph, would you recommend it? Any others?
I'm running juCi++ 1.0.1 on Windows with mingw. When clicking preferences I only get the config.json file. How do I change it to get a dark theme?
Change the variant to "dark" (under gtk_theme), and set for instance style to "juci-dark" (under source). The preferences gets applied automatically when you save the config.json file. 
&gt; The aos_vs_soa is especially impressive to me: compiled with -O3, I get a x3 performance improvement with soa. That's mostly the result of auto-vectorization, though. Disable that and you'll see the difference shrink down significantly. &gt; edit: too bad that soa performs much worse than aos if you need random access (not unexpected though). Seems like the choice soa vs aos is not as simple as some say. Thanks to register pressure, it even depends on whether you compile for x86 or x86_64!
What are you on about. Boost pwns.
&gt; http://stackoverflow.com/a/388282 so i should stick with books then online learning mazaterial? Since they are teaching me bad practises and habits?
Everything you said there is exactly the same as me. Started out with the same attitude and enjoyed it. I thought if I get into a 'tricky' relatively low-level language, then the other ones will be easier if I need them. I've been learning on and off for the past ~1.5 years. If you'd like resources I highly recommend looking at [this](http://www.learncpp.com) website (if you've not already seen it before) combined with TheNewBoston's c++ series on YouTube. Lastly, keep at it - it gets more fun when you have more freedom in what you know, good luck! :)
Consider what `avg &gt;= 90 || avg &lt;= 100` means. Given any number between 0 and 100 when is this condition true? When is it false? Obviously it is true for all numbers 90 and above but it is also true for all numbers 100 and below. Therefore, it is true for all numbers 0 to 100. You want to use `&amp;&amp;` instead of `||`.
That's true enough. I've now heard two strong arguments here for `std::vector` even when the size is known and fixed. Color me disproven.
I think there would certainly be cases where that would be very useful, but in most cases there is a reason that the release build of the code is shipped and not the debug version. Your version would certainly be some kind of debug build. Additionally, a ton of linux distros include the option to install sources and debug versions of libs and programs, which partly does what you want. Still, this is not the default and once again, I guess there are some good reasons for this.
&gt; Am I crazy here? Yes.
The best thing to do is just every now and then keep an eye on what new features are actually becoming supported in compilers. https://gcc.gnu.org/onlinedocs/libstdc++/manual/status.html#status.iso.2014 I don't think "following" the ongoing tweaks to the standard and various proposals would be a very productive use of time.
It is called `oberserver_ptr` now and will be part of the library fundamentals TS V2: http://en.cppreference.com/w/cpp/experimental/observer_ptr It should be noted though, that it won't help with safety, only with reasoning.
&gt; Tracing and telemetry these days seem rudimentary and practically useless for diagnosing issues. I'm not sure why you say that. We fix many, many, many bugs that come through WER since we have signed binaries.
The quantity of data you'd produce when you turned on the logging would be enormous. Let's say you could store all the information relevant to an instruction in 64 bits (realistically, you'd probably need more than that, but it'll do for a first-cut estimate). In a typical case, you can expect a single core to execute about 1.8 instructions per clock cycle. A typical modern CPU might have four cores and run at, say, 4 Gigahertz. Such a CPU would produce roughly 230 gigabytes of log data per second. The theoretical maximum bandwidth through a single SATA connection is 600 MB/s, so this would saturate somewhere around 380 parallel SATA connections. In short, there's no such thing as a motherboard with even close to the kind of I/O bandwidth you'd need to store your log data.
This is similar to the idea of core dumps, and we already have core dumps, and core dumps are a better idea than this idea.
r/learnprogramming is a better place to post this.
You should read up on scope, that variable is local to that function. You can not access it outside of that function, and any pointers to it are invalidated when the function ends. It's possible the data is still in memory but that would be sheer luck and not reliable.
The official website of The C++ Standards Committee: http://www.open-std.org/JTC1/SC22/WG21/.
I've always just used `std::fill` instead of `memset` (at least in C++).
Because a full dump is typically 4G. Not practical for out in the wild users. A mini-dump is like 1M and is a 50/50 shot at having enough information to root cause. People already give feedback through Windows Feedback. The balloon for how to do that pops up in your face so all they need to do is click on it. So we have precedent. You appear to be debugging simplistic programs. Bugs in real production code are really hard to track down, especially with poorly coded legacy code. My last paragraph gave an example of debugging environmental issues with this technology. In fact, there exists an ASM level tracing tool where you can diff traces, but good luck with the verbosity and matching asm to source code. Admittedly, my suggestion falls down for some race conditions (tracing adds 1-2% overhead) and hardware errors. Btw, including the last number of CPU steps doesn't help much since the source of a bug is often different than the eventual crash site (which is what dumps are for - typically crashes only). But a diff of the full call graph would be useful.
Thanks man for the extra help. I didn't have to change the data type to char though.
You can't ship a Valgrind instrumented binary since it's 2x slowdown, defeating the purpose. Tracing systems (ETW, WPP) only give 1-2% slowdown which is why they're used. My suggestion is processor level so likely even faster (though it would still need to log to disk for the repro run).
I see. Gotta love reddit parroting to make a position seem more valid. Read above for why core dumps from WER are often useless as well and only useful for actual exe crashes.
Which is why I said SOURCE level debugging. Not asm instructions/binary code.
Getting the tracing back is easy. Telemetry systems today log to a file and then upload it when the system is idle (at night). Full trace. You have a point where the user still needs to provide a decent bug report to identify what the bug is. But having which function calls occurred and the inputs would help track down a lot of issues. Figuring out how some data value got to be that value can be tricky, but at least you know that it is possible and your code doesn't handle that value properly.
I feel the article is somewhat incomplete without discussing some of the safer alternatives available in STL for the `mem*` functions.
I imagine this: using auto = void; should make your `proxy` unusable with `auto`. 
Thank you for your suggestion, I didn't think about going in that direction. :)
Wow that's weird. Thanks. I've been using it all over the place not knowing this...
I don't really understand why memset and sizeof are bad. I understand from the article that memset and a loop over your array will probably be compiled the same way but why one is better than the other I don't understand. For some microcontroller code i have the following: unsigned int numbers[4]; // It gets filled by some other functions memset(numbers, 0, sizeof(numbers)); What can go wrong with this way of resetting an array to 0 ? 
&gt; What can go wrong with this way of resetting an array to 0 ? Nothing. However I've seen the following mistake a couple of times: void foo() { unsigned int numbers[4]; // ... bar(numbers); // ... } void bar(unsigned int *numbers) { // ... memset(numbers, 0, sizeof(numbers)); // sizeof returns size of a pointer // ... }
Well, what about: unsigned int numbers[4] = { 0 }; // initialize all to 0 Proof: +/u/compilebot C++ #include &lt;iostream&gt; int main() { unsigned int arr[4] = {0}; for (auto a : arr) std::cout &lt;&lt; a &lt;&lt; '\n'; }
Output: 42 0 0 0 [^source](http://ideone.com/vpr02t) ^| [^info](http://www.reddit.com/r/CompileBot/wiki) ^| [^git](https://github.com/renfredxh/compilebot) ^| [^report](http://www.reddit.com/message/compose?to=compilebot&amp;subject=Report%20Abuse&amp;message=--report%20https%3A//www.reddit.com/r/cpp/comments/3y792d/sizeof_memset_memcpy/cybxush%20Include%20your%20reason%20for%20reporting%20here.) 
I do not think you know what it does. If you omit an initializer in the list initialization the remaining elements are set to 0. I do not have the standardese for it currently, but trust me. It is also seen in your example as well.
&gt; If you omit an initializer in the list initialization the remaining elements are set to 0. I see, didn't know that. Assumed it's the lack of optimization flags that zero-initialized them. I've seen compilers/libraries doing additional work when compiled without optimizations, like MSVC's version of std::vector throwing out-of-bounds exceptions when you compile using the debug configuration.
You do realize thats Java and even if it wasn't, there is a subreddit for code related questions?
Hi!, First this is CPP board, not java, second you must ask your questions here, https://www.reddit.com/r/cpp_questions/. Merry xmas.
&gt; I understand from the article that memset and a loop over your array will probably be compiled the same way This is not a good assumption, by the way. It did in his sample case, but take the following example code: struct Foo { int x; char y; }; Foo array[256]; void blah() { const Foo val { 1, 2 }; for(int i=0; i&lt;256; ++i) array[i] = val; } Compiler outputs: * x64 gcc 5.3.0 (-O3): dword+byte write per element * x64 clang 3.7 (-O3): unrolled qword write loop * VS2015 update 1, x86 (/Ox): rep movsd * VS2015 update 1, x64 (/Ox): unrolled qword write loop fill(begin(array), end(array), val) produced similar code constructs in the assembly output, although sometimes with minor differences. The moral of the story is that if you want memset(), you should actually write memset(). 
&gt; You know processors these days execute both branches and retire the one that was mispredicted Retiring is storing the actual result of the execution, not rolling it back. It's actually provably slower than a branch predictor that can only accurately predict slightly over 50% of branches. Current branch predictors easily get 90%+ performance, making it very bad to just execute both halves and to discard one of them. No, current processors do not do this. The IA64 architecture did this, even down to instruction encoding, in part of an effort to reduce decoder latency &amp; improve IPC. It worked for that, at the expense of using more power &amp; more execution resources for dead instructions. That was an OK choice in 2001, when it was new and when the Pentium 4 wasn't a proven failure, but right now we know that spending much more energy to go slightly faster isn't a net gain, and we're better off taking a bit more time to decode rather than execute a load of unuseful instructions.
wtf
Looking at the benchmark implementation Cap'n Proto does a full serialization and deserialization round trip, in the same way e.g. the Protobuf benchmark is written. But after deserialization the benchmark [only accesses the root object](https://github.com/STEllAR-GROUP/cpp-serializers/commit/73b3e42ee7a87954f9235d6fd38cab8d9e8b9700#diff-dfe5c65cf4ac041daf85f8f5f3d6dd74R206), so I assume Cap'n Proto does not really deserialize the whole message? /cc /u/kentonv would you be so kind and give an explanation on this?
This project needs to be cross-platform so I can't use that in linux.
You can put your external dependencies in a single MSVC folder CMakeLists.txt -- root option (generate_visual_studio_folders "Generate Visual Studio Folders?" ON) if (generate_visual_studio_folders) set_property(GLOBAL PROPERTY USE_FOLDERS ON) endif() CMakeLists.txt -- project set_property(TARGET ${PROJECT_NAME_STR} PROPERTY FOLDER "External") AFAIK you cannot selectively disable intellisense for those projects. 
What I do for Windows is that I build the libraries in the configurations I need them and put them in a folder structure like: winlibs\lpng\include\*.h winlibs\lpng\x64_debug\*.lib winlibs\lpng\x64_release\*.lib These folders are, like the source code, put into the version control system. And set up the solution using "$(SolutionDir)\winlibs\lpng\include" as additional include directory and "$(SolutionDir)\winlibs\lpng\$(Platform)_$(Configuration)" as additional library directory. This way I don't need to separate setups for different platforms/configurations and every developer who checks out the project can start immediately to work on it.
Makes sense. Storing precompiled objs or binaries. I guess it's the only clean way to do it.
precompiled for every architecture you target, right?
example for libxml : https://github.com/jamoma/JamomaCore/tree/master/Foundation/library/libxml2/win32
I have found it to be slightly unstable (esp. when using qgraphicsscene) but very useful for debugging a variety of graphical bugs.
We do build dependencies once for each platform (when we need them for this platform, which is often). We also build them in several configurations (DEBUG/NDEBUG/NDEBUG-without-optimizations, 32/64 bits etc.) We keep prebuilt .o and .lib (Windows) files in source control, but not binaries (.so and exes) - they are part of the build output and they get deployed later. Beats building them every time we start a project, doesn't it? (Not that it happens all that often, but still.) We then pass the include and lib folders of dependencies to the project build: if project X uses dependency Y, we add the include/lib path for dependency Y to the build options of the project X and that's it. The above sidesteps a build system, CMake included, when it comes to 3rd party dependencies. We do not use git anymore and we did not use submodules when we did use git (we also used git before submodules), but as far as I know, what we do would work with git submodules just the same - difference being that submodules would not be actual sources but rather whatever is needed for the build itself (inc/lib files). I would personally really disagree with trashing VS solution/project files with every CMake build. (I don't know if that does happen, it could be that it doesn't, but have heard that the CMake support for VS/MSBuild files isn't stellar). Finally, I am not saying what we do is somehow good or better than something else - just saying what we do. There's obviously a set of trade-offs to any approach.
Thanks for sharing! Two questions though: do you also support linux? Is it reasonable to compile something (.so or .o) in there as well? And what's the downside of using git submodules?
It's difficult to give an ELI5 as software licensing is complex and every application needs to evaluate its own requirements. Understanding the licensing terms requires that you understand common methods of software distribution and packaging (e.g. distinctions between static/dynamic linking, redistribution of source code etc.). So I'll try to explain like you're a novice software developer. Qt offers dual licensing. You can use it under a commercial license (by paying a licensing fee) if you plan to do things that are not compatible with the LGPL (static linking, modifying qt source without distributing the source modifications, etc.) or you can use it under the standard LGPL and comply with all that entails. If you don't understand the requirements of the LGPL there's plenty of material on the LGPL all over the internet. Just read some articles on it. If you are unable to comply with the LGPL then you **must** pay for a commercial license if you want to distribute your software. Here is an [FAQ](http://www.qt.io/faq/) on the Qt licensing options. Typically using Qt under the LGPL is sufficient even for commercial applications unless you're planning on making custom changes to Qt that you need to keep private. There really aren't any catches, or at least nothing out of the ordinary. There are only licensing terms that you must understand to protect yourself from liability. 
&gt; There are myriads of JSON libraries out there could you compare your library against them ?
Flowchart : - Is your app compatible with LGPLv2.1 or v3 ? =&gt; you can use open-source license. - Else =&gt; you have to use commercial license. Please note that LGPL is very not-restrictive : you can link proprietary apps to LGPL libs without problems, and can even ship iOS / Android apps (the former generally requiring static linking) as long as you provide `.o` files to relink against (the LGPL license ensures that the user of your software always the freedom to update / modify the LGPL parts).
&gt; You can link proprietary apps to LGPL libs without problems, and can even ship iOS / Android apps (the former generally requiring static linking) as long as you provide .o files Using LGPL on closed platforms like iOS or Google Play (any 'store' that excludes side loading or manipulating application packages) is a grey area at best because the end-user cannot replace LGPL code on their device. After Qt changed its site and licensing somewhat recently, they also made it clear on their site that they expected users of Qt to comply with the LGPL specifically in this regard. Note that they also changed their license to LGPL v3 for newer Qt code to provide even clearer terms for locked down devices. So saying that you can use LGPL on these devices is unclear at best and straight up wrong in the worst case scenario. Please link people to Qt's own license clarification instead (http://www.qt.io/qt-licensing-terms/) Here's an excerpt: &gt; The user is allowed to change and re-link the library used in the application or device – including reverse engineering. With LGPLv3 it is explicitly stated that the user also needs to be able to run the re-linked binary, and that sufficient installation information must be provided. As always, consult a lawyer when in doubt.
[This](https://github.com/Dekken/maiken) build tool I'm working on is cross platform and has dependency management based (currently) on git.
I'd really love to see updated results on that.
Hah. We do the exact opposite. A single build with everything but the standard library built from source, same CMake script on Linux and windows.
Why is JSON slow and what is faster than JSON? XML?
If you have structured data, a binary format should be considerably faster than JSON.
msgpack should be faster but is not human readable. 
Any format that needs to parse strings as numeric data is going to be orders of magnitude slower than something like Cap't Proto, MsgPack, or CBOR. If performance is a serious concern for your application, moving to a better format can likely save you 100x more than choosing the "right" JSON library. 
No, I do not use assertions.
GCC 4.8 already has issues with vectors, so there the type traits are not an issue. Clang is doing a fine job since 3.4. Which "C++11 compiler" do you mean? MSVC?
It's the same code :)
Why not `= {}`? AFAIK, `{0}` is only needed for C.
&gt; First, I don't even know if there's a straightforward 'legitimate' way to download the application off a device The one who makes the app has the necessity to provide such a way per the LGPL's requirement, by hosting the code and the entirety of the files necessary to rebuild the software somewhere themselves (like does all big company in the "open-source code" part of their website). Also, you can re-sign the original package easily (hence the website has to provide the original apk too); I guess that for complete compliance it is up to the application author to provide a way to transfer settings &amp; such when the signing changes. 
Very nicely written, its eye soothing :) . Its been long time since I have read such C++ code.
It is only needed for C. I just haven't thought and typed the version I was used to.
TFS. 
This might help: [Getting your C++ to the Web with Node.js](http://blog.scottfrees.com/getting-your-c-to-the-web-with-node-js)
Add a service to the library or make a separate service library. This will give you good flexibility for your front-end(s).
&gt; ANN Did you test any other libraries? I was a bit surprised to find around a 50% speed bump with FLANN compared to ANN (for 3D point clouds).
[emscripten](https://github.com/kripken/emscripten) might be worth a look. And I think Google is working on something similar, I forgot the name but I saw it in a CppCon 2015 talk on YouTube.
Is there any problem that Node.js can't solve? Followup: Is there any problem that Node.js is actually a good solution for?
Remotery (C++ profiling library) exposes a minimal HTTP server that only accepts WebSocket connections. The GUI is a web page with some JS that connects to your program's Remotery port over WebSockets, reads the data, and displays the GUI. That approach would be an option. See: https://github.com/Celtoys/Remotery (Hard to say whether this would be suitable or unsuitable for your situation.)
It was bcc64 (clang front end, but dinkumware64 standard library). Not sure if they have improved library support since then
Another idea is to expose your lib coding your boundary using microsoft [rest sdk](https://casablanca.codeplex.com) and make a standard web project in a convenient tech to call that.
Probably WebAssembly: https://github.com/WebAssembly CppCon 2015 talk: JF Bastien “C++ on the Web: Ponies for developers without pwn’ing users": https://www.youtube.com/watch?v=H-R-yW1-fbQ More details: - https://hacks.mozilla.org/2015/12/compiling-to-webassembly-its-happening/ - 2015 LLVM Developers’ Meeting: Jf Bastien &amp; Dan Gohman “WebAssembly: Here Be Dragons": https://www.youtube.com/watch?v=5W7NkofUtAw - https://brendaneich.com/2015/06/from-asm-js-to-webassembly/ Another one I've heard of is Cheerp: http://leaningtech.com/cheerp/ However, there doesn't seem to be much information about it -- other than an announcement -- http://leaningtech.com/cheerp/blog/2015/06/17/Cheerp-1.1/ -- and a discussion: https://news.ycombinator.com/item?id=10524784
Right, the lack of updates seems worrying. Found another one in the framework category (the Silicon Web Framework), seems more current: http://siliconframework.org/ / https://github.com/matt-42/silicon
Don't post this here. Your question is more suited for /r/learnprogramming . Although, I'm not sure if this question really even applies there. Even though your questions really shouldn't be answered here, I'll still attempt to (except the NSA thing because, well, who cares? They probably use C/C++/Python/anyotherlanguageyoucanimagine). Odds are you just finished learning the syntax of C++. This is not learning C++. Find a book on algorithms and data structures and get reading. Learn about OOP and pick up things like program design. I would suggest sticking with C++ for most of all of this until you have a much better understanding of the language. I don't mean to sound condescending, but I see questions like this all the time and they usually are from people with similar backgrounds in programming (none). Just focus on studying computer science and have fun. FYI, if you NEED another language, Python is pretty easy to pick up.
That might be what OP meant, but it most certainly is not what is being asked here. &gt; I'd like to build a gui for a C++ library that I wrote. means you want to write an interface for the library.
&gt; Odds are you just finished learning the syntax of C++. C++ is a gigantic language; I could even say no one can claim that they know the entire language.
Exactly my point! That's why I recommended to OP that he stick with C++ and learn more about the language and comp Sci in general. Anyone who claims to *know* C++, most likely doesn't know it in its entirety, even after working with it for years.
The rest of us seem to have figured out what they meant.
I made a biological neural network simulator in C++ with a web GUI using emscripten and three.js. You can check it out here: https://github.com/tfussell/cort The code is not very pretty, but you can see the general idea by looking at the C++-&gt;JS interface: https://github.com/tfussell/cort/tree/master/source/js and it's JS usage: https://github.com/tfussell/cort/blob/master/www/js/three-app.js#L342
Learn more C++. I've been writing C++ for 20 years and I still can't claim a total mastery of the language. Very few can. Dig deeper. At the same time, survey broadly. Concepts from in practically every other language can be mapped onto C++. Learn how. 
Over half of it is from Stanfords word net library. If it works and doesn't take 30 secs to run then I'll be happy. The paper it's based on is sane at least.
I've played around using Wt mentioned in /u/mttd's post and it was a pretty straight forward way to wirte an interface entirely in c++ (and html templating). The only thing I recall being a bit of a hangup is that it's not fully c++11 friendly yet since you can't put in conditional compiles that work across compilers (or couldn't when I used it last). Admittedly I was just experimenting with a plugin loader that created different ipsum generators for each plugin but it worked pretty well.
Is UCS actually happening? I kind of assumed that, among all the possible C++17 features, this one was way out there, as in science fiction material.
He's not saying he wants to put the GUI in the library code. He's asking how he can use his library within a GUI. You make libraries so that they can do work for you. His library is complete, so he wants to use it's processing capabilities within a user interactive environment.
I think it will be in the standard. Anyway it is syntactic sugar. What I miss in C++ is properties (like in C# or Delphi).
The idea behind that saying is to think about how you want to use the new module, not how it works internally. What data structures do you want to give it as input, what data structures do you expect as output? Don't worry too much about being "right" here. When working on a completely new problem, it's normal to not actually understand all the requirements beforehand. Once you've tried out a couple of approaches that didn't *quite* work, you will have a better understanding and can design a better interface. &gt; This is especially important when designing base classes or data structures since re-touching those things will exponentially break other things as the project progresses. Once you have a working version of your new module, start using it in practice. Major issues will become apparent very quickly and you can fix them before the interface is too ingrained in your project. ~~If~~ When you do encounter a case that requires changing the interface, remember that you can (almost) always *add* to an interface without breaking current users. It'll be a tradeoff between duplicating some code or spending some time going through the source code that uses your interface.
I can devise the input-output for my entire library/program, not for a single module which, for example, reads chunk of memory to extract some information (I have an abstract and foggy idea of that "information" although I have a clear vision of what I should get at the end of my 200 modules to write on github "I'm a cool guy, I wrote a library that does this thing")
I start by writing a few methods and data structures. Then later I realize "omg I had better write this differently" and I fix it.. thousands of errors and hours. Then I continue my project... if I eventually find out I could have designed the data structures even better.. either I stick with the current design or **get a waterfall effect of errors and problems if I try to change/refactor them once more**. Everything from that point forward accumulates technical debt.
How do you decide which methods there will be? It's all but impossible to program without having a goal in mind. 
add a RPC interface, e.g. with thrift or protobuffers and then use any of the highly specialized web frameworks where you are productive. this also allows a much cleaner separation of the library. if you really want a monolithic application you could try to use vibe.d and call your c++ code directly from D (watch out the docs on what is possible might be outdated)
Well I usually make a method when I need it. One action at a high level brings thousands of actions at a lower level and possibly one or more modules (and those modules could be used for other actions.. but I can't see it yet)
Well each module should do one thing. To me it helps to imagine that I already implemented the module that does this one thing, and that I can just use it. So the first thing I do is to just use it. I write some code that uses it (my tests). This code doesn't compile because I haven't written the module yet. After writing enough test code and iterating over the way I want to use it at some point I am kind of confident that the API is "solid enough". So then I just go and implement the API to get my code compile. This part is only about getting the types and function signatures right. This might result in me iterating over the tests and the API. Afterwards I implement the module to make the tests pass. As my knowledge of the problem increases I might realize that the API i wanted is too complex or hard to implement and might change it to arrive at a compromise. I might also have a couple of insights that might make me approach the problem from a different perspective. It is an iterative process but thinking about how you want to use something and actually writing that code first, even if that doesn't compile, does help me arrive at a better API every single time.
When the time comes to write your module for memory-reading, open a new file, and write an example of code of the API that you'd like to use. For instance I would like, for a memory reading API something like : (with a dubious example around it) template&lt;typename HashFun&gt; void hasher( MemChunkReader&amp; mem, HashedMemChunks&amp; hash, HashFun f) { if(mem.canRead()) { hash.append(mem.readNext())); }
Take your abstract and foggy idea of the "information" and try to make that into some concrete action you can do on the module to extract one logical bit of information. Make a test that tests that. Then write some code that does that. Then, find a bit of information that you also want, that you don't get yet. Refactor the code to make that easy to add, while not breaking anything. Add a test (that's now red). Add code for it (so it's green again). 
I recommend reading Growing Object Oriented Software Guided By Tests, and also watching the pluralsight course by Mark Seeman. Additionally, I've found the blog TheCodeWhisperer to be very useful as well. None of them deal directly with C++, but the concepts are transferable. One thing to start with is the use cases or user stories and write a failing Acceptance test. This test goes from your inputs at the user interface and drives a spike all the way through your application to the outputs at the database/network/whatever. So for example, write a test that takes some input and check that it got written to the DB. Get all the plumbing in place to make the test fail for the right reason. Get the UI test harness working, get the DB test harness working to verify the value is not written. Once it fails for the right reason, it's time to make it pass by driving out the design by writing unit tests. Write a unit test for the user interface. Figure out what it needs as collaborators, write the interfaces and mock them. Once you have that class working, write unit tests to flesh out the collaborators and see what new interfaces THEY may need. Continue until the acceptance test passes. Now you have an end to end architecture to build on. Now write the next acceptance test and repeat. And don't be afraid to throw away code if you realize you went down the wrong path. The acceptance tests will make sure you don't break user expectations, and unit tests can be thrown away if they are no longer testing the correct thing after the design changes.
Oops, sorry, i meant in the const version of the operator where currently the behavior is only undefined, and assertion would be useful.
If you can't figure out how to structure it, a simple way to start figuring it out is to write a description of the system and then just do noun-verb analysis (nouns are classes or fields, verbs methods). 
Others have already commented on how to interface between C++ and web languages (I can second that Node.js might be worth a look). What I would like to add is to suggest avoiding to mingle the web UI too much with your C++ code. Rather, you can use Node.js (or one of the other solutions) to help expose your C++ to REST calls to make a proper web API. From there you can consume the REST interface from any remote client you like, such as a single-page AJAX application or even a mobile app if that's desired in the future. It sounds like you're gonna want to build the AJAX application first, for that I'd like to suggest looking into JavaScript libraries like React.js and Redux. If you want more information towards that just reply to me or you can post in /r/javascript. Finally, others have also mentioned WebSockets, which is a good alternative to a REST interface if you need a more real-time, stateful connection between your remote client and your server logic.
There are no licensing issues with Qt on Windows.
Dunno any books, but the internet and MSDN generally suffice.
Use Windows Runtime APIs. That way, you could potentially abstract out the C++y parts of your app out and still reuse them in JS or .NET.
I have that book, and as you said, WinAPI is pretty cryptic and seems like a lot of code to do some simple things when compared to WPF.
Does that mean I can still use XAML or WinForms to build the app?
You can get by with just MSDN an the web in general. In fact, I think it beats any book on the subject, because you will inevitably spend most of your day searching anyway. That said, you really are in for a world of pain. I'd wholeheartedly recommend Qt as well. WinAPI always starts off looking fairly logical for creating the elements, getting some messages across etc., but you inevitably end up with a HUGE mess. The simplest tasks like organizing a couple of buttons in a dialog or setting a tab order will take days of your life. Qt might have a bit of an overhead, but the signal / slot system along with CSS based design and a bit of layout management are really a godsend. You can in fact combine the two if you so desire, though I wouldn't do it. It's really not just about crossplatformness, Qt is simply put the better solution right now. There are of course some issues, but there are just as many with WinAPI, which is obsolete and has a syntax that will put hair on your chest. You want to create a button? Here's 50 methods to do that, each very slightly different than the other one because why not. Want to change a button colour? Well now it's blinking for no good reason... Not to mention, Qt, while you may not really need that right now, is much more than a GUI platform. It's more like Boost with a bit of GUI on top. I'd seriously consider that an option if I were starting from scratch. I know Qt is paid for commerical purposes nowadays, but I'd still shell out for a license if I were to work on anything serious. WinAPI should have been dead a long time ago.
&gt; WinAPI is fucking horrible I SECOND THIS!
&gt; I'd like to avoid the Qt licensing issues Could you elaborate on this? AFAIK, Qt is available under multiple licenses: GPL, LGPL and commercial licenses, [source](http://doc.qt.io/qt-5/licensing.html). [LGPL](https://en.wikipedia.org/wiki/GNU_Lesser_General_Public_License) might suit your needs. You need to either link against Qt dynamically ([.dll](https://en.wikipedia.org/wiki/Dynamic-link_library)s) or provide an [object-file](https://en.wikipedia.org/wiki/Object_file) that's not linked to Qt upon request.
&gt; Sadly, it's 90% winapi for me at work.. Ouch, how long did it take you to become profiencent with winapi?
If you want to develop "modern" Windows apps (the ones you get from the Windows store) then I would recommend the book "Modern C++ and Windows Store Apps". Here you can use all the bells and whistles of XAML in C++. When you want to build an "old-style" desktop app you are basically in the Win32-Area. Here some C++-Wrappers exist. I would recommend the very lightweight WTL (Windows Template Library). There is some good WTL-Documentation on CodeProject (look for "WTL for MFC Programmers").
And that's a fair point (I am "in the industry" so to speak), and a REST API is a great example of something that is going to be serializing and deserializing JSON a fair bit - and performance is indeed critical when you want to have millisecond response times. 
You can rebuild and link against Qt statically (even if your app is proprietary and you want to use the LGPL license).
No. Not with LGPL. With LGPL you can only link dynamically, no static linking allowed for proprietary programs. With GPL you can't even do that. Which is why most libraries chose LGPL (or free-er licenses). 
I wouldn't be that fatalistic. In my job it's often a mix between creating new stuff and maintaining the old stuff. The sad truth is: as soon as you check-in new code into your VCS it's already legacy code. It will have bugs that you must fix or work-around, it will cause problems on some customer's machines and so on. These days I really like to DELETE obsolete code because I know this code won't cause any problems in the future. Finally it's also often a lot of fun and you are well paid :) The big problem with C++ is that it isn't really suited for refactoring. The language is very complex and brings all the legacy of C (preprocessor) that makes it very difficult to develop good refactoring tools. And without refactoring the maintenance of legacy code really sucks.
It's not being dynamically allocated. It's not at all. You mean declare it as a pointer? That's what I wondered as well. Just following the book example as I work through it and trying to understand the author's intention.
Windows Runtime (WinRT) is now Universal Windows Platform, or UWP, and yes, you can use XAML to build the UI, but not WinForms. It's a far better API than Windows API, and has C++ bindings, but you are closely tied to the Windows Store for distribution. *Technically*, with Windows 10 the user can side-load your application if they change their security settings; you could distribute that way, if you wanted to -- but it's not easy. It's a superior approach if you plan to distribute via the Windows Store, though. You could also do a WinForms app, if you wanted, but you'd have to do it in a .NET language. You could build the UI as a shell in C# and reference C++ for your heavy programming tasks, if you wanted; I've done this on numerous occasions. There's also a third option, if you prefer "all" C++: you could use WPF with C++/CLI, which is C++ that targets the .NET framework. I have to stress, however, that although C++/CLI has C++ in the name and looks and acts a lot *like* C++, it's not really C++, and has a lot of interesting gotchas when it comes to dealing with native libraries. Most of the time "it just works", but when it doesn't, it's totally nonintuitive as to why. 
&gt; No. Not with LGPL. With LGPL you can only link dynamically, no static linking allowed for proprietary programs. Yes you can. You just have to provide the proprietary .o of your app, so that one can relink with modified versions of the LGPL library. Straight from the GNU's mouth : http://www.gnu.org/licenses/gpl-faq.html#LGPLStaticVsDynamic
I'd like to add that as of Windows 10 it's possible, but painful, to build a Universal Windows Platform app (formerly known as WinRT) and distribute it outside of the Windows Store. The end user has to enable side-loading, and the install process isn't easy (most people also ship a powershell installer script with their bundle) but it can technically be done. 
&gt; Why would you ? To do exactly that. Thanks for the link. =)
&gt; Win32 is still the foundation for all of the higher level APIs. Not denying this. It's kinda obvious. I meant using it without an abstraction layer results in a messy code. You can write your own abstraction layer, but it's reinventing the wheel. &gt; have maximum control Nothing stops you from including `windows.h` and calling a function that is not implemented in the framework of your choice. Qt's QWidgets have a function called `winId()` that returns a handle for that purpose.
In the case of Qt maximum control would be eliminating the need for multiple megabytes of DLLs, and use only what you need. I know you can statically link but then you no longer get the benefit of the LGPL. In the case of MFC (which also allows access to the handle) maximum control is owning your own main() function and event loop. 
&gt; I start by writing a few methods and data structures. Write your tests before you write the methods and data structures. Before each method, write a test. &gt; Then later I realize "omg I had better write this differently" and I fix it.. thousands of errors and hours. Change your tests when you change your design. &gt; Then I continue my project... if I eventually find out I could have designed the data structures even better.. either I stick with the current design or **get a waterfall effect of errors and problems if I try to change/refactor them once more**. This is where the work you put in earlier pays off. You can try small changes and see if it breaks things you didn't expect. You should be constantly repeating the cycle of write test, make a small change, run test suite. If you break anything, it will be easy to track down. edit: Check out [this](https://youtu.be/YX3iRjKj7C0?t=1701) explanation by Bob Martin. Skip to 28:00 if you're on mobile.
lol, thanks for the laugh.
Awesome details, thanks! I get it now.
Thanks for explaining in detail.
Well what we did was base them of out project specifications/ use case diagrams 
I've worked for 35 years in the industry. People compliment me on the quantity and quality of my tests, which I have from an early stage in every project. So I like tests - a lot! But I've never worked with a professional programmer who routinely starts with the tests - not once. I occasionally read people claiming on the net that they do it. Everyone who likes testing has tried it a few times - but it doesn't seem to give any great advantage and has some drawbacks. For one thing, it makes top-down programming impossible. I personally don't design either top-down or bottom-up exclusively - I sort of beat at both ends alternately - but I generally start with a top-level sketch. For another, I find when I do that that it constrains my design too much, too soon. As I write the code, I often realize that the way I'm calling, filling, or using my data structures is wrong, awkward or misguided. But if I already have a test I'm writing to, I have two poor choices - throw away the test I never ran and restart, or warp my code to the crummy test. So I spend quite a while fiddling with a module until I have decided that the interface is to my liking - and only then do I write the tests. Don't use this as an excuse not to write the tests as you write the code. I strive for 100% coverage...!
Give up. Write the UI part of your code in C#, VB or JS. UI doesn't benefit from C++ all that much anyhow and the biggest reason to ask for C++ is "I only know that".
What is exactly what you want to do? If your purpose is to make a desktop app, you could even try using Node.js and Electron. Nothing easier than HTML/CSS to make all the UI you need. 
I had read that .o trick for static linking LGPL libraries but it's nice to have the exact part from GNU where it allows it. Thanks!
And make sure you get all those messy LPCWSTR typedef right. In the end you'll have to use MFC. Willing or unwilling. That is the way.
&gt; InsertFunctionHereEx(MAKEWORD(SOME_CONSTANT_HERE,0), NULL, INVALID_HANDLE_VALUE, NULL, _T("..\\tmp\\lol.txt")) 
http://lowendbox.com
Best guess is you're looking to set up something like this: http://yieldthought.com/post/12239282034/swapped-my-macbook-for-an-ipad Check out his opinions on using linode, I've had good experiences with digitalocean as well.
OP asked about a VPS which is entirely different from a VPN. 
I mostly work on Windows with Visual Studio but I like to compile Linux builds on Linux as getting clang working nicely on Windows has been a nightmare and a Debian VM "just works". I am seriously thinking about switching to Linux though as for development (in C/C++ anyway) is *so* nice. 
I would be a bit surprised if he was doing web development in C++, but it's not unheard of...
Most of them give you a VM you can play with via a terminal, in addition to their web-based code editors. It won't be up while you're not using it, so if you're looking to deploy a service you should look for a real VPS, but for development purposes they are fine.
[This](http://stackoverflow.com/questions/31351372/how-to-compile-c-for-windows-with-clang-in-visual-studio-2015) just came out recently and makes that process much easier. I've spent time in all three OSes as a developer and frankly Visual Studio is one of the better IDEs out there. If you don't need actual Linux libraries, this is probably one of the best approaches to just using clang.
You can build a DIY cartridge on RedHat's OpenShift. I rent Atom servers from microservers.io for $30/mo or so. I use docker to run VMs on them. 
&gt; No, therefore you add a suffix like "Ex" and/or "W" so that the functions are grouped together in IntelliSense. They didn't just add "W" the non Unicode suffix was "A", you just never saw that since the winapi header spammed macros that would expand to either depending on the definition of the unicode macro. I repeatedly ran into Microsofts macro fetish when I started to program, mostly in the form of hard to read compiler errors, fun times. Also in contrast to the "Ex" for extended the "W" and "A" suffixes at least documented what was special about that version of a function. The "Ex" suffix for any additional parameter just screams lazy and shows an ingrained hate for self documenting code. 
Yeah I have been meaning to look into this. Does it also install Clang myself? The way I read things it is just templates for VS to make use of Clang? Sorry if it is a stupid question, truth be told I only skimmed the article. 
The "problem" is that the operator calls "std::map::find" and accesses its "second" member. An assertion would add an additional check whether the result is not the end() iterator. This, however, is not required for operator[] as no bounds checking is performed. Or am I wrong?
I suggest you to avoid SDL if your idea is to learn C++ right. Actually, the snippets you posted are great examples of bad C++ (unnecessary get/set, raw pointers, unnecessary dynamic memory allocation, etc). SDL is just plain C, and using it directly without taking that into consideration makes the design and code of your game/library ugly and potentially buggy. If I were you I would consider SFML instead, is much more C++ish 
The Win32 API is a C (not C++) API. The C language doesn't support overloaded functions. So I think it's better to have a certain convention with the added "Ex" to basically show that "FindWindowEx" is an overloaded version of "FindWindow". Plus MS started to use extensible parameter structs to prevent creating new functions with every new parameter. These structs usually contain a cbSize-Member so that the callee knows which version of the parameter struct to use. If you really think this screams lazy then I recommend "The Old New Thing" (blog &amp; book) where it is documented how difficult it is to keep the extreme backward compatibility of Windows versions.
Always happy to see progress here. Standard conformance has come a long way. Ten years ago, it would have been a huge pain to work with GCC and Visual C++ on the same code base. Workarounds left and right. These days it more often than not just works. I am also glad that they don't just add any feature they can think of to the standard.
Too bad modules won't rid the world of header files. Functions called will still have to be declared or defined beforehand so now instead of just header files you get to use modules and header files! Yayyy!!!! To be clearer: Functions defined within a module have to be defined or declared before use within that module. Same with classes and everything else. So you'll see that they could have fixed the forward declaration problem with the power of modules but chose to only fix the compilation speed problem. And thus I say sarcastically: Yayy!! 1) Create a module Foo 2) In Foo define function Fun1, calling Fun2 within it 3) In Foo define function Fun2 Result: Compilation error. You'll have to forward declare Fun2.
Modules will export things (like function declarations) that currently header files have. And you can import them in other modules. IIRC, there were opinions that macros shouldn't be exported, and if modules go that way you would need header files for macros.
Importing a module is like including a header file, only less 1970. 
&gt; The only things modules solve is the needless reprocessing of header files I'll take it.
I haven't kept up with the latest specs, but every revision I've seen has a primary goal that both interface and implementation of a module *can* be in a single file. Regarding your edit: &gt; 1) Create a module Foo &gt; 2) In Foo define function Fun1, calling Fun2 within it &gt; 3) In Foo define function Fun2 With prelimenary syntax: /// a.cpp module Foo; void Fun2() {} export void Fun1() { Fun2(); } Even if they call each other, you would only need a forward declaration, but not a separate header file. Note that a large module can be composed of other modules, which would be the method of choice if Fun2 is used in multiple translation units of the module: /// 1.cpp module Foo.Details; export void Fun2() {} /// 2.cpp import Foo.Details; export void Fun1() { Fun2(); } --- FWIW, even if this were different, modules would still be the one addition that I'd give up all others for. 
Embed a http server, and design a REST api. Then do some browser side programming. Or, just use node.js, make your lib a module, still you need do browser side programming.
That's incorrect - modules can do something that headers inherently can't. Imagine you're a library where your Vector's implementation wants to call Rotate(), which is a publicly available algorithm in your library. Because you can't separately compile templates, dragging in the header for Vector must also drag in Rotate() (and all of its support machinery). This leads to users being lazy about including what they need, and breaks stuff as the library restructures its internal dependencies. With modules, if Vector and Rotate() live in separate modules, then importing the container doesn't import the algorithm for use, even though the compiler still has access to the implementation (as it must, since templates still must be instantiated for arbitrary stuff). The result is that the "if you use it, you need to explicitly include it" problem completely vanishes. (The reverse, unnecessary module imports, should be possible to cheaply diagnose.)
&gt; The Win32 API is a C (not C++) API. The C language doesn't support overloaded functions. I am well aware. I did not criticize the convention of having a postfix. &gt; So I think it's better to have a certain convention with the added "Ex" Well they could have used the postfix "Turd" instead which conveys the same amount of information and is just two letters longer. Your FindWindow example could be handled better. For example which is more readable: FindWindowEx FindWindowTurd FindWindowBelowParent &gt; Plus MS started to use extensible parameter structs Apparently that happened after the use of Ex as FindWindowEx shows, it does not take a parameter struct. 
Thanks for the advice.
I wish C++ had proper algebraic union types for handling errors. I use tuples now, but it's a hack. Exceptions are nice and all, but I work in highly restricted embedded environments where exceptions are turned off by the build environment (it's even a freestanding environment, as the thing boots as an OS)
Why does VPS = Web development? 
One of the first books I bought is a now battered second edition of Effective C++ in 2000 for 60$ at a now long-gone specialized library. Meyers and Sutter taught me C++. Farewell Scott, and thanks for everything.
Not a dumb question. I have not done it myself so I don't know. 
MSVC has just been so far behind generally that I think anytime a new release comes out with any new semi-conforming feature it gets praised to keep the encouragement going. Ultimately though I think the best decision MS has made was to bring support for clang to Windows. Once that's done I doubt MSVC will have much of any use case. Maybe the handful of people using C++/CX or AMP will continue using MSVC.
As opposed to what?
Would you recommend building the app directly on top of the library or from a flexibility standpoint would it be better to make an interface service and import that as a Wt Resource object? ie, using crow to make the interface and then grabbing that interface content.
except for having to join Facebook, I am with you in spirit. Not really.. God I hate the idea of joining Facebook. 
Also add: [Scott Meyers is retiring from C++](http://scottmeyers.blogspot.com/2015/12/good-to-go.html) :(
What practical use does that give you? It seems like a mild convenience which would be nice, but C++ has much bigger legacy issues to solve that dwarf mild convenience. 
Yes... unfortunately... what a news at the end of the year...
If you use modern mfc, you get to use direct2d. You only need to call enabledirrect2d() and you are ready to roll with hardware accelerated anti-alaised drawing.
well if you are curious, I'm a college student and I'm using a laptop/tablet as well as a pc. Since i constantly have to send my progress across several devices, things can become a bit messy at times. Having a VPS was the first idea that came into my mind as a possible solution to solve the problem and save space on my hard drives. Ofc, there are online IDEs that could solve the problem but using a VPS seems easier, more convenient and has other useful applications besides programming. 
&gt; Meyers and Sutter taught me C++. Same here. Solid foundations require structured approaches and talks/podcasts/StackOverflow, as useful as they are, cannot teach foundations, they can only build on top.
operator[] says that if the element is out of bounds you get undefined behavior which means that you can do anything you want. Accessing an element out of bounds using _unchecked_ access is a programmer error since unchecked access means "i know the element is there" (otherwise they would use at). An assertion adds a check _in debug mode_ that tells you why you are using operator[] wrong instead of segfaulting or doing something weird like modifying a const object. In release mode there are no checks, so when you compile for performance you pay nothing. In debug mode however the assertion can easily save you 5 minutes of debugging time. In this case somebody can assume that operator[] const is thread-safe, but since it is modifying a const object without internal synchronization it isn't, so it can potentially save somebody hours of debugging time. So if it cost nothing, and helps your users to write correct code, why don't do it? All major std lib implementations (libc++, libstdc++, range-v3) do this for a reason. Basically if your function has pre/post/invariant conditions, you should always assert them. You pay nothing for it, and they make sure in debug builds that they are not "unexpectedly" violated. IMO an invariant of operator[] const is that it doesn't modify the object. 
I'm open to suggestions!
What are some programs that I need to write/view code? 
&gt; P0002 proposes to remove the somewhat surprising increment operator for bool, deprecated since its introduction in C++98. The idea of something being standardized deprecated from the onset is somewhat... surprising :x
strstream was also deprecated in c++98. It's what happens when you standardize an existing language with lots of code written in it.
I would recommend: 1. Asking your "friend" that doesn't exist for help. 2. Not giving away the fact that you are 12 in your writing style.
What have you done to try to learn on your own so far?
The Ranges TS is not finalized yet. I wouldn't expect vendors to start shipping it until it's completed.
That is a pretty big over-simplification. Aside from the question of runtime performance, which is not as clear-cut as you imply, compiling with exceptions enabled will at the very least significantly bloat your executable, even if there are no try/catch blocks anywhere in your code and you have no interest in trying to recover from catastrophic failures like out-of-memory. I consider that to be a violation of C++'s principle of not having to pay for what you don't use. 
Curious, what's the status on a core guidelines checker for clang/gcc? I know it should be compiler agnostic but vs ain't exactly on Unix.
In the meanwhile, you can get Eric Neibler's implementation from his Github.
ok, thanks for the remarks!
&gt;P0012 proposes to make exception specifications part of the type system Wait... really? They're finally doing this?! Looks like I've got yet another major feature to look forward to in 2017!
to be honest I don't know... checker is probably not compiler agnostic, so each compiler team will have to implement it on their own I think.
It would be great to get feedback.
I am probably much less well-versed than you in C++ and programming (I have no idea what HTTP routing is let alone it being trivial). But, when your startup wants to grow and add more developers, finding good C++ developers who are comfortable enough with an unpopular use of the language is gonna cost some resources, perhaps more than it'd have costed with a Python application. But I agree with the performance advantage. We got lucky at our startup that we (kind of) didn't pay for our servers until we could afford it, but C++ runs blazing fast and efficiently compared to our previous Python backend.
Thanks for the kind words. Yeah, I agree they can look quite intimidating especially as they don't have a lot of examples so I should write a post to make Proxygen and Wangle a bit more accessible.
This is gutsy. I am curious: Did you build a data storage engine from scratch or you are using one of the off the shelf engines? How are your cubes build times? Do you aggregate across all dimensions or you aggregate at run time? How do you handle data explosions? OLAP cubes can get really big fast.
I don't know why this was down voted. It's a valid concern when increasing head count. Although the first few hires for a start-up will be through relationships where you know somebody has the chops to perform in the technology stack you've selected. After that then, if you're trying to keep things local, it could become difficult. If you allow for remote then it's not quite as problematic.
Hi lambdaburrito, nice post. I'd like to pick your brain on a few things. - Is merging fb{vector,string} into an STL implementation feasible, and if so, would it be the right thing to do? - Did you notice performance problems in std::{vector,string}, or was it simply easier to use containers from Folly? Do these problems exist in all c++ standard libraries (e.g libc++, libstdc++, STLport)? Edit: rephrased.
&gt; Yeah that's a very good point about hiring good C++ developers and it is a concern for the future. In my experience this problem is usually a bit overblown. There might be fewer developers that have a lot of experience with c++ than e. g. javascript, but it isn't as big a problem as some make it out to be. Or I might have been exceptionally lucky. One issue is that some experienced c++ developers sometimes make for worse c++ developers, especially those that did c++ in the 90s, and have since been using other languages so they haven't really followed the last decade of improvements. This is probably very subjective, but imho. a lot of the popular patterns from the 90s make for really "shitty" code (e. g. [CRTP](https://en.wikipedia.org/wiki/Curiously_recurring_template_pattern)). In some ways, generally good developers with little-to-no c++ experience are sometimes easier to on-board, IME. But I'd recommend you fairly early sit down and formalize in some way a high-level "coding conventions" document or similar, and enforce it from the get-go, to ensure that everyone you bring on board are on the same page. Some inspiration: * https://wiki.qt.io/Coding_Conventions * https://google.github.io/styleguide/cppguide.html * http://llvm.org/docs/CodingStandards.html * https://github.com/isocpp/CppCoreGuidelines (I guess you're already familiar with this.)
One concern you do not address are the slow build times which, in my experience, have a significant impact on productivity and are not easily addressable at this time. 
The same is true for any stack of reasonable complexity. I've spent years of hobby time dabbling with Spring and Hibernate and still feel like a total n00b.
I would think that the choice of a programming language is somehow related to the mission statement of your company. If your objective is to deliver a service, i would go for whatever high level solution. If you plan to innovate and deliver a new product, a low level language will offer more control on all the aspects of the design. Regarding productivity, i think it all depends on skills and surrounding tools, not language.
Really good questions! Building from scratch as I have experience developing data storage engines (for algo trading). We developed our own storage engine that uses our innovation: factorization tables to minimise the storage cost. Data is distributed between local and remote disks so scaling the storage is either adding an extra disk volume or another server. It aggregates across all dims and after our first release to our customers, we're going to offer real-time streaming so new data can be streamed and it updates the aggregations. It seems you have experience with OLAP so your feedback would be really valuable to us. I can give you a free beta account to try it out for your feedback. PM if you're interested.
I did briefly mention this at the end. The builds are not counter productive yet but I have thought about how to tackle this until C++17; modularizing my c++ into shared libraries and only kick off-rebuilds of shared libraries if they are changes so re-build is not needed for all of the classes. I'm hoping I can just write a small bash/python script to do re-builds of the shared libraries.
STLport has been dead for something like a decade and shouldn't even be on the table for consideration these days.
I think he is in a midlife crisis.
C++ is considered a controversial choice of language these days? Wow.
Make sure your build can take advantage of multiple cores (make -j). This is easy to do from a clean slate but a pain later. Also Pimpl as much as performance concerns allow. Templates in general wreak havoc on build times - use them wisely (be carefull with how you use boost)
Reread the build times bit in the article. Build time is a concern from day one because even building a single translation unit can easily take multiple seconds which is enough to break your flow and make you vulnerable to distractions.
Additionally you could look into a distributed build system (although I'm not sure how many resources you'll have to distribute as a startup). This can greatly improve build times.
Still nothing prevents writing a few native methods. 
That's a really good point concerning productivity and developing a product vs service. This was my line of thought; I'm developing a new novel product and want all control from low-level system calls to high-level abstractions. I'm really comfortable with clang, CLion and cmake so feel as productive as if I was writing Java.
Do you have a source for that? I'm curious. I mean, I learned C++98 in college like 15 years ago, and this was well know then. When I had to implement my own template vector class for school, the allocator used 1.5x because it was obvious. I find it very odd that GNU would be that naive. If what you are saying is true, then I am shocked.
No, but the JVM&lt;=&gt;native data barrier either makes the other code really messy, or calling the native methods have a large performance penalty.
Sure, one needs to make the same tradeoffs as RPC calls, minimise the amount of calls, maximize the work per call. I like C++ a lot, but nowadays I see it more as an infrastructure language, not a full stack one, specially since it is so easy to have developers not following C++ best practices for safety. Edit: For the downvoters, how to prevent pointer misuse, use of plain vectors, null terminated strings when the majority of developers still don't have static analysis as part of the build process, or code review processes in place? Hopefully the OP's startup will make use of C++'s security best practices, but I am yet to meet a typical enterprise that has them in place. 
Interesting, I recently wrote a similar program, witch lets you create structs(with some limitations) of mixed types and can enable arithmetic operations. #pragma once #include &lt;tuple&gt; #include &lt;utility&gt; #include &lt;exception&gt; namespace meta_util { // variadic enable_if template &lt; bool CONDITION &gt; struct true_if : std::conditional&lt; CONDITION, std::true_type, std::false_type &gt;::type {}; template&lt;typename T&gt; struct is_arithmetic : std::is_arithmetic&lt;T&gt; { }; template&lt;bool...&gt; struct bool_pack; template&lt;bool... b&gt; using all_true = std::is_same&lt;bool_pack&lt;true, b...&gt;, bool_pack&lt;b..., true&gt;&gt;; template&lt;typename... Ts&gt; struct all_are_arithmetic : true_if&lt;all_true&lt;is_arithmetic&lt;Ts&gt;::value...&gt;::value&gt; {}; // tuple iteration template&lt;typename... Ts&gt; void wrapper(Ts&amp;&amp;... args) { } // simple iteratio, only tuple as argument template&lt;class F, class... Ts, std::size_t... Is&gt; void for_each_in_tuple(std::tuple&lt;Ts...&gt;&amp; tuple, F func, std::index_sequence&lt;Is...&gt;) { wrapper((func(std::get&lt;Is&gt;(tuple)), 0)...); } template&lt;class F, class...Ts&gt; void for_each_in_tuple(std::tuple&lt;Ts...&gt;&amp; tuple, F func) { for_each_in_tuple(tuple, func, std::make_index_sequence&lt;sizeof...(Ts)&gt;()); } //simple iteration, with tuple + scalar template&lt;typename... Ts, typename S, typename F, std::size_t... Is&gt; void for_each_in_tuple(std::tuple&lt;Ts...&gt;&amp; tuple, S&amp; scalar, F func, std::index_sequence&lt;Is...&gt;) { wrapper((func(std::get&lt;Is&gt;(tuple), scalar), 0)...); } template&lt;typename... Ts, typename S, typename F&gt; void for_each_in_tuple(std::tuple&lt;Ts...&gt;&amp; tuple, S&amp; scalar, F func) { for_each_in_tuple(tuple, scalar, func, std::make_index_sequence&lt;sizeof...(Ts)&gt;()); } //simple iteration, with 3 tuples template&lt;typename... Ret, typename... A, typename... B, class F, std::size_t... Is&gt; void tuple_operator(std::tuple&lt;Ret...&gt;&amp; ret, const std::tuple&lt;A...&gt;&amp; a, const std::tuple&lt;B...&gt;&amp; b, F func, std::index_sequence&lt;Is...&gt;) { wrapper((func(std::get&lt;Is&gt;(ret), std::get&lt;Is&gt;(a), std::get&lt;Is&gt;(b)), 0)...); } template&lt;typename... Ret, typename... A, typename... B, class F&gt; void tuple_operator(std::tuple&lt;Ret...&gt;&amp; ret, const std::tuple&lt;A...&gt;&amp; a, const std::tuple&lt;B...&gt;&amp; b, F func) { tuple_operator(ret, a, b, func, std::make_index_sequence&lt;sizeof...(Ret)&gt;()); } } template&lt;typename... Ts&gt; struct ArithmeticStruct // clearly not overengineered { template&lt;typename = std::enable_if&lt;meta_util::all_are_arithmetic&lt;Ts...&gt;::value&gt;::type&gt; explicit ArithmeticStruct(Ts... args) { // only constructible if all types are arithmetic, ensures that arithmetic operations are posible local = std::make_tuple(std::move(args)...); } std::tuple&lt;Ts...&gt; local; // local storage of data // custom operators ArithmeticStruct operator+ (ArithmeticStruct&amp; comp) // vec add { ArithmeticStruct ret(comp); meta_util::tuple_operator(ret.local, local, comp.local, [](auto&amp; ret, const auto&amp; a, const auto&amp; b) { ret = a + b; }); return ret; } ArithmeticStruct operator* (ArithmeticStruct&amp; comp) // vec add { ArithmeticStruct ret(comp); meta_util::tuple_operator(ret.local, local, comp.local, [](auto&amp; ret, const auto&amp; a, const auto&amp; b) { ret = a * b; }); return ret; } template&lt;typename T&gt; typename std::enable_if&lt;std::is_arithmetic&lt;T&gt;::value, ArithmeticStruct&gt;::type operator* (T t) // scaling { ArithmeticStruct ret(*this); meta_util::for_each_in_tuple(ret.local, t, [](auto&amp; ret, auto scalar) { ret *= scalar; }); return ret; } // calc sum double sum() { double sum = 0; // the data type is an assumption that may fail meta_util::for_each_in_tuple(local, sum, [](auto&amp; element, auto&amp; sum) { sum += element; }); return sum; } // calc product typename std::enable_if&lt;(sizeof...(Ts) &gt; 0), double&gt;::type product() { double product = front(); // the data type is an assumption that may fail if (front() != 0) { meta_util::for_each_in_tuple(local, product, [](auto&amp; element, auto&amp; product) { product *= element; }); return (product / front()); // divide by 0 evaded } else return 0; // first element was 0, so product will be 0 } typename std::enable_if&lt;(sizeof...(Ts) &gt; 0), double&gt;::type product_if_all_positive() { bool allPositive = true; meta_util::for_each_in_tuple(local, allPositive, [](auto&amp; element, auto&amp; allPositive) { if (element &lt;= 0) allPositive = false; }); return allPositive ? product() : 0; // this is slower as there is 1 theoretically unnecesarry tuple itertion, but it is more flexible } // return first and last tuple element inline auto&amp; front() { return std::get&lt;0&gt;(local); // we leave the bound cheking to std::get } inline auto&amp; back() // tmp, should only be possible if sizeof...(Ts) is &gt; 0 { return std::get&lt;sizeof...(Ts)-1&gt;(local); } }; example usage: using Ingredient = ArithmeticStruct&lt;int, float, double, char&gt;; Ingredient a(1,2,3,4); Ingredient b(5,6,7,8); auto c = a * b + a; It checks at compiletime if those arithmetic operations are even possible with every type.
http://gittup.org/tup/ This is probably the coolest build system I have ever used. I believe he watches system calls to build a dependency graph of file for conditional compilation. I'm not sure why it isn't more popular tbh it's pretty stable.
That's why a lot of companies use java in this space. It's high performance compared to python and developers are easier to find than cpp developers. 
&gt; One issue is that some experienced c++ developers sometimes make for worse c++ developers, especially those that did c++ in the 90s, and have since been using other languages so they haven't really followed the last decade of improvements. This is almost exactly me. My last professional C++ experience was 2011 or so, and so was 2003-era (plus several now-standard idioms pulled in via boost). Been toying with reviving it for hobby purposes and *possibly* a hack-day experiment in replacing our existing application server (this article was highly motivating). If you could suggest one reference for somebody in that position to get back up to date quickly, what would it be?
I remember seeing a talk or interview with a prominent google developer who said if there were doing it again today they would probably go with exceptions. The google style guide has a lot of stuff that is a particular way for legacy reasons and they don't want to change it because they write insane amounts of code and having it not be consistent would be a huge cost.
Unfortunately I don't (I can't remember what talk it was) and I don't have time to look it up at the moment. Sorry. :(
Why is this shit getting upvoted?
It's hard to do proper RAII without exceptions. Making sure they are "exceptional" and not part of normal flow control is really the trick, imo. So I'd go with them in limited capacity. 
You can probably get them from game development, and they will love the better job stability and less crunch time.
Sure, let me whip up a microbenchmark that runs a tiny piece of code enough times that the JIT startup time is drowned out, and maybe sneak a couple of allocations into the C++ version's inner loop.
Effective Modern C++ covers a lot of best practices with the new stuff.
It's true. I do high performance computing on quad 18 core xeons and we've rewritten everything in javascript.
That's an easy question. Look at http://doc.qt.io/qt-5/qtmodules.html and http://www.boost.org/doc/libs/1_55_0/libs/libraries.htm Boost has a lot of low level stuff (like an MPL, a parser generator, math or computation), while Qt has very focused high level modules (like GUI, multimedia or XML/SQL/D-Bus bindings).
confirmed on G++ 4.8.4: #include &lt;vector&gt; #include &lt;iostream&gt; using namespace std; int main() { for(vector&lt;int&gt; v; v.size() &lt; 20; v.push_back(0)) cout &lt;&lt; v.size() &lt;&lt; "\t" &lt;&lt; v.capacity() &lt;&lt; endl; return 0; } 
Uh, CRTP is still common and it's how you get static dispatch... what do you think is wrong with it?
There is already the C++ Enthusiasts group on facebook which has over 2k members. Go join that one instead: https://www.facebook.com/groups/cppEnthusiasts/
That's going to happen regardless.
There is nothing well known about 1.5 vs. 2. There have been long standing arguments for and against 1.5 and 2, but no one has so far been able to produce a benchmark to show that 1.5 is better than 2 for general use cases. There are some fuzzy arguments about how 1.5 allows memory to be reclaimed whereas 2 doesn't, but those scenarios are mostly far fetched and actually don't even apply to `std::vector`. The GCC devs have said if actual benchmarks can be produced to validate the claim that 1.5 is faster than 2 then they'd be happy to switch over to it but the benchmarks they currently use to profile show that using 2 outperforms 1.5. The clang developers have come to the same conclusion. Personally I think 1.5 vs 2 is one of those things where people think using 1.5 is clever because of the golden ratio and other smart sounding arguments, but when push comes to shove it just really doesn't perform faster. Ultimately the GCC and Clang engineers feel that actual real world performance trumps theoretical smart sounding arguments that lack empirical evidence.
Why not just use a struct? It's too bad you can't just do a struct with C-style initialization.
&gt; how to prevent pointer misuse, use of plain vectors, null terminated strings. c++11/14 address all this issues and pretty much resolve them. For a full stack language, the only thing c++11 lack is a proper and portable unicode implementation and decent filesystem library. Static analysis is sadly not widely use indeed because it is too costly, to your workflow and to your startup and not reliable enough. But it certainly on the path to become better, Rust show us the way.
Talk: CppCon 2014: Titus Winters "The Philosophy of Google's C++ Code" Videos: - https://channel9.msdn.com/Events/CPP/C-PP-Con-2014/The-Philosophy-of-Googles-C-Code - https://www.youtube.com/watch?v=NOCElcMcFik Slides: https://github.com/CppCon/CppCon2014/tree/master/Presentations/The%20Philosophy%20of%20Google's%20C%2B%2B%20Style%20Guide See also: - https://stackoverflow.com/questions/5184115/google-c-style-guides-no-exceptions-rule-stl - https://stackoverflow.com/questions/19073441/google-c-coding-style-no-exceptions-rule-what-about-multithreading - https://www.reddit.com/r/cpp/comments/1x4f3s/c_coding_standards/ - http://www.randomprogramming.com/2014/10/googles-c-style-guide/ This particular guide also has been discussed here before: - https://www.reddit.com/r/cpp/comments/289n27/this_blog_post_matches_much_of_my_thinking_on/ - https://www.reddit.com/r/programming/comments/28alvi/why_google_style_guide_for_c_is_a_dealbreaker/ Personally, I'd also take a look at the following: - High Integrity C++ Coding Standard: http://www.codingstandard.com/ - CERT C++ Coding Standard: https://www.securecoding.cert.org/confluence/display/cplusplus 
How about [bazel](http://bazel.io)?
It isn't obvious that everyone should be using 1.5x for allocation growth. You're right that the reasoning behind choosing 1.5 is so that you can reuse previously-allocated blocks of memory, as explained in this nice writeup: https://crntaylor.wordpress.com/2011/07/15/optimal-memory-reallocation-and-the-golden-ratio/ However, as one of the comments after the article points out, the choice of the multiplier is a classic space vs. time trade off. Assuming that the "wasted" memory can be used for allocations in other parts of your program, it may be a better trade-off to grow the blocks in larger increments, letting your code run faster.
Interestingly, I hold the opposite view because I don't know the techniques to use for non native code. For example, I use hardware breakpoints a lot and need to learn what to do instead when that feature is taken away from me. 
Neat, but are there advantages to using this over an std::unordered_map? If you use operator[] the syntax is even simpler.
Yeah, I know that the real answer converges to 1.618..., but the problem with that is now you have to do floating point in what was pure integer code before. That is seen as unacceptable to enough users, that the approximation of 1.5 is used (close enough, and still integer only math). 
{JQuery, Angular, Backbone, ...}, the answer to all problems.
Compile-time name resolution instead of runtime.
Sure they are. How else am I supposed to spray blood out of my fingertips to dissuade attackers?
Custom JS JIT written in hardcore low-level on-the-metal asm. That's asm, you know. asm... .js. It JITs JS to JS, and feeds it back into itself.
You mean like member names part of the initialisation list?
For the same reason that you're being downvoted. Because it's interesting.
In C you can do typedef struct { int example; double someOtherField; some_other_type andSoOn; } Example; //create one named Example e = {.example = 42, .andSoOn = generateSomeStruct()}; //create one anonymously someFunc((Example){.someOtherField = 1.0}); you can do cool tricky stuff with this, but sadly you cannot do it in C++. I'm not sure why C++ didn't add this feature once C added it.
Why does it have to be a binary choice? You can probably identify pieces that benefit from the performance of C++, and those that benefit from the productivity of another language like python or ruby. Even back in the 90s, we would write cgi scripts in perl that called into C binaries, or GUI programs in VB6 that called into COM servers written in C++. You can identify modules that will change often (like the UI), and write them in a dynamic language. That makes it easier and faster to modify and maintain the system. Then if you keep your system modular, you can rewrite pieces as the interface gels and you can benefit from C++'s performance. I've found it is often easier to port a module written in (e.g.) python to C++ than to write it in C++ in the first place, because I find it easier to choose the correct algorithms and architecture when programming at a higher level. 
sure, that's cool. i'm not anti-js... it's just that in most cases, HPC is usually doing some numerical scientific computing - simulations, statistical modeling. there's not many js ecosystem infrastructure for this from what i've seen.
Sure, but how do I tell when a memory location is written to? 
That doesn't sound like a startup to me. If they want that they can look at goog, fb, finance etc.
This is great. C++ already powers so much of the web behind the scenes that it is great to see it actually come to the forefront. I hope your success (best wishes) will inspire others to also use C++. I just have a couple requests. 1) Keep us up to date on how things are going 2) If you run into problems/issues, writeups how you got around them would be appreciated 3) If you make stuff that is awkward in C++ easy to use, please release it as open source if possible.
Multiple inheritance makes the syntax ambiguous.
Set a breakpoint, watchpoint, etc.
That might work if you need speed but memory use is not an issue. &gt; So how do you make the remaining 99%, that doesn't even care about modern C++ as discussed at CppCon, use them? How is it not realistic for a startup to use static analyzers? Why does everyone need to use them for them to work? I'm not about C/C++ style, I write C++11. A startup can do the same. That's the advantage they have.
Tell that to the NANSA - the space intelligence agency.
You can write bad code in any language. Coding standards and reviews and rejecting stuff that doesn't do it right.
You can get those through ICU and Boost.
How? If you mean when two base classes have a member with the same name, you just qualify (`{.B1::x = 1, .B2::x = 2}`) just like for member access.
Joyent is pretty sweet. Pretty quick compile times, cheap, and you only need rent for the time you use.
Problem is you have to define comparison operators for structs. In C++11 you can easily initialize structs as long as you don't provide default values for any of the members. E.g. struct Example { std::string a; int b; double c; }; Example ex{"1", 2, 3.0}; 
I disagree and think you're a moron in the first place.
That would be a great post!
C++ can't even JIT.
For a startup, the goal is not to make 99% of the people to use them, but to make three people to use them.
I did look into GPU via Cuda but the data transfer from and to the GPU negated a lot the computational benefit. Have a look at OLAP on Wikipedia for a better understanding. They can be sparse and it is quite common to be sparse if the are no matching data points; for instance there are no sales for year 2000 and older.
Amazon offer instances with a Nvidia GPU; not sure about the others.
Great workshop, but seriously, why every single variadic template guide teaches how to use them totally wrong? With c++14 you should practically never use recursion in variadic templates. It's slow (both in compilation and execution time), results in horrendous error messages and implies a lot of boilerplate code. Just use index_sequnce and ... expansion to iterate. You can see examples implementing first two labs without recursion here: https://gist.github.com/telishev/516dba19737a498ce72d 
8 Cores, so it roughly processes 240 requests per millisecond for each core. The HTTP benchmark was just echoing the request; not calling the engine.
Valid argument... I will do some empirical testing to see how it works in practise as I am curious to know now.
Example screenshot: http://img.blog.csdn.net/20160103172239717
Compilation speed - see https://gist.github.com/telishev/673609d651c0baab0b8c . Recursive variant gets killed by timeout on godbolt, non-recursive - don't (gcc 5.3, -O3 -std=c++14 -ftemplate-depth=10000). On clang with libc++ it's possible to compile without timeout even up to 10000. This is because libc++ make_index_sequence is written using log(n) approach, which is much faster, and they're even considering using compiler intrinsic for it (along with msvc). After implementing that, non-recursive approach will be much faster and compilation time for such functions will be practically O(1).
thanks, it's interesting !
http://melpon.org/wandbox/permlink/OvU5npeqfZqq9CTq with C++17
The arguments certainly do apply to std::vector, I'm sure. With appropriate CRT support you could have a vector that attempts to grow in place, but I believe it's usual for a vector's capacity to increase by allocating a new buffer, moving each item from the old buffer into the new buffer, then freeing the old buffer. And the goal behind 1.5 is driven by this: it allows addresses used by previous buffers to be potentially reused for future higher-capacity buffers. Imagine growing a vector with a growth factor of 1.5. It's not inconceivable for the heap to look something like the following after a particular number of additions. (Assume the vector's capacity starts off at 4. "Adds" counts number of times push_back (or whatever...) was called to get to this state; "moves" counts the number of times a value was moved from one block to another due to reallocation as part of this. "U" is a used block; "F" is a free block. Sizes are expressed in number of vector elements.) ...| U4 |... (4 adds, 0 moves) ...| F4 | U6 |... (6 adds, 4 moves) ...| F10 | U9 |... (9 adds, 10 moves) ...| F19 | U13 |... (13 adds, 23 moves) ...| U19 |... (19 adds, 36 moves) And so on. With a growth factor of 2, you'll never be able to reuse the addresses used by previous allocations - which can actually be a factor for 32-bit systems. 32-bit address space exhaustion due to exactly this sort of fragmentation can be a concern even with realistic data sizes. 64-bit address space, for now, you may consider infinite, even though you currently only get 48 bits of it on many systems. Which makes a factor of 2 more sensible, because you have fewer moves per add (amortized). Watch a similar sequence of growths: ...| U4 |... (4 adds) ...| F4 | U8 |...(8 adds, 4 moves) ...| F12 | U16 |... (16 adds, 12 moves) ...| F28 | U32 |... (32 adds, 28 moves) ...| F60 | U64 |... (64 adds, 60 moves) (I should really code this up rather than just working through it by hand.)
There have been changes in `make_index_sequence` implementations lately, libstdc++ moved to a logarithmic approach ([patch](https://gcc.gnu.org/ml/libstdc++/2015-11/msg00129.html)) and libc++ is already making use of that compiler intrinsic you mention ([patch](https://www.mail-archive.com/cfe-commits@lists.llvm.org/msg09649.html)). Both changes are in trunk, and should be released soon.
&gt;Python/Ruby: I'm lumping these two together because they're both interpreted with similar performance overhead and library availability. Ruby's performance caught up to another language?
Like onlysoaa said, in your code you can't change the referred object. But it's possible to use dummy object to initialize std::reference_wrapper. Though still it will require using get() to assign the value.
I'm not sure I understand the motivation. Pointers and references are semantically different, and serve different purposes. If you encounter the need to change from pointer to reference, chances are there's an underlying design issue that needs to be addressed first. You can think of pointers as reseatable references. If you need to reassign the address of a pointer, use a pointer and don't disguise it as a reference. This will keep your code clearer as the pointers will behave as expected.
Some game development companies are not like startups, but they are known for their eternal crunch times and eventual team destruction when games are released. It's not startup like, but soul crushing like.
That's nice.
&gt; The arguments certainly do apply to std::vector, I'm sure. With appropriate CRT support you could have a vector that attempts to grow in place, but I believe it's usual for a vector's capacity to increase by allocating a new buffer, moving each item from the old buffer into the new buffer, then freeing the old buffer. No it can't grow in place, ever, period. It must allocate a new block and perform a copy/move. The standard's committee considered the grow in place/realloc approach and came to the conclusion that even std::realloc rarely ever performs a grow in place, even in situations where it could have done so in principle and concluded consequently that there is basically no point in complicating the standard and allocator interface to support the notion of 'grow in place'. &gt;Imagine growing a vector with a growth factor of 1.5. It's not inconceivable for the heap to look something like the following after a particular number of additions. The point is that it is inconceivable. The scenario you describe is so unlikely, even on 32 bit systems, that it's simply not worth considering. In order for your scenario to actually have any observable consequence your application would need to consist of a single std::vector that needs to grow from 2 GB to 4 GB and there can be no memory allocations at any intermediate step. If you have such an incredibly obscure and rare scenario as the one above, where you are growing a vector from a size of 4 up to 4 GB with no intermediate allocations in between the solution isn't to bake into `std::vector` a growth factor of 1.5, degrading performance for every other user. The solution is to simply reserve the amount of memory you need upfront by calling `vector&lt;T&gt;::reserve` which is vastly superior than using a 1.5 growth factor anyways.
`std::reference_wrapper`provides some sort of automatic dereferencing, but only in limited contexts ([ADL](http://en.cppreference.com/w/cpp/language/adl)). What you're probably after, and I personally think would be a boon, is something like [N4035](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4035.pdf), unfortunately not planned for the standard AFAIK.
For the record, I requested that compiler intrinsic, and it was first implemented in MSVC. Give us a little credit for driving the state of the art forwards! :-&gt; Specifically, I want credit for being lazy. A user reported that my linear implementation was slow and bad, and asked for a clever log implementation like libc++'s maintainers had written. I said "screw that, I'm gonna get the compilers to do my work for me". (At the moment, I've enabled use of the intrinsic when VC's STL is compiled with Clang only. Although C1XX implemented it first, I encountered a couple of bugs that my initial unit test missed.)
A pointer can access stored values and change the address of the pointer (i.e *x vs x). It sound like what you want to to flip the syntax so that the (simpler) unmodified base state (x) accesses value. However you will then require some syntax modifier to reassign the address. I'm assuming you use a constructor to do so in your value_ptr. I would recommend instead focusing more strongly on the design of your code. For instance encapsulate the portions that access by value into a lambda or function. You'll likely find when you do so that you do not even require an intermediate pointer/reference... and your code will be much cleaner.
Instead of using `first.m_object-&gt;m_value`, you may want to have `first.object_value()`. That localizes the responsibility of verifying that the pointer is not null, so that you don't have to have asserts in as many places.
I'll refer you to this StackOverflow answer: http://stackoverflow.com/a/7058373/951890 Basically, prefer references over pointers when you don't need pointers. You can always make a reference from a pointer when you know your pointer isn't null: assert(my_pointer!=nullptr); auto&amp; my_reference = *my_pointer; 
You could say the same thing about regular pointers. It's just about flipping the default from address to value (similar to how a reference is accessed, while it's a pointer under the hood), it's symmetric and doesn't introduce any new complexity.
&gt;Specifically, I want credit for being lazy I thought this is what programmers call getting paid.
Oh I missed that. I think this method makes it kind of inconsistent with the rest of c++ though, where the dot operator operates on the value of the type.
Anyone has an idea what "Focus on window frame, no more controls" means? Controls are not used in Metro apps?
Seriously, I have exactly zero idea what this code is for. Do I really have to build it to find out for lack of a coherent description?
&gt; the VM isn't supposed to leak, right? No, but especially in dynamic languages it's pretty much a wild west of arbitrary mutation of arbitrary objects from arbitrary locations.
Please read the sidebar
This library only focus on window frame, some button controls on the window title bar. It is most suitable for the use of HTML and Javascript to develop the client program.
How the fuck is this not downvo - oooo - ohhh, nevermind. ;) I haven't done any C++ in about 11 years, and regardless of the criticisms c++ receives, I know better than to make such statements. edit: 11 years later and I'm stuck in Java hell. Worst. Career. Mistake. Ever.
I was just rereading that article today. It's quite exceptional, you should expand the material and give a talk in your local cpp community (obviously, if you have any interest :-)). 
I didn't check all of them but after scrolling to a random position which is the 107th line, I found this: &gt; :ThreadPool{std::max(1u, std::thread::hardware_concurrency() - 1u)} If hardware_concurrency() returns 0, it will try to create really many threads.
Thanks for taking the time to read the post. Which include guards are you referring to? I don't think _THREADSAFEQUEUE_HPP or _THREADPOOL_HPP are reserved in any capacity, but if you know differently I'd be interested to learn more. Edit: Nevermind, you're totally right, I shouldn't be starting include guards with underscores. Great call out! Updated.
why would hardware_concurrency() return a number less than 1?
There's tons of ways to get static dispatch. It's a great tool for certain things but it's been heavily overused in the past. If the base class is not doing anything other than forwarding calls to the derived class you should just dump it. 
It isn't about a design of a program or why pointers are used. Why everyone keep changing the topic?
So you suggest to add a reference each time a pointer is used, or make a dedicated function for each expression that uses a pointer? How is that more concise or clean? You just took my first line of code and bloated it into 5/6 lines of code.
Does the crystax toolkit support cmake building?
This article is meh.. nothing new that I didn't know/heard of before.
Crap post, -1
This is correct, although technically `future` itself is an lvalue in the scope of the initializer list and constructor itself (it is an rvalue at the calling site only). std::forward would also work however, but i also prefer std::move for clarity
I imagine this is highly platform and architecture dependent so it may be hard to provide meaningful numbers. Spinning up a thread is, in generally a system call and it's never a bad idea to minimize those when possible.
Optimization is the same. 
&gt; Spinning up a thread is, in generally a system call This implementation uses mutexes and a contested mutex requires system calls, too. &gt; a system call and it's never a bad idea to minimize those when possible In theory yeah, but in theory one should use C or ASM in the first place. Home-brewed solutions that do the same things as something a system call was meant to do are usually way inferior, at least in features, but often also in performance.
Memset and sizeof are error prone. That's the case that Andrey Karpov makes, and I wanted to stress the fact that the use of sizeof might be a code smell - especially in the C++ context when you have more intelligent ways to do it. I also made the case that a loop might be just as fast as memset, so there's no reason not to use a loop over your elements (a structured approach) as opposed to a byte-filler (an unstructured approach).
I did read the WP:EN entry and it looks 100% biz talk to me. I understand the computational intensity of those things is fairly limited.
And why not auto &amp;vx = *x; ?
Not sure whether to upvote or downvote your post: All of what you say is absolutely correct, except this small bit, where I heavily disagree: &gt; in theory one should use C or ASM in the first place Using C++ can be a lot safer and less bug-prone, and most of the C++ abstractions disappear and get optimised away to assembly code that is as efficient as hand-written assembly.
This is even better.
Don't follow the Google style guide, a lot of C++ professionals agree it's not the best. It may suit a company with one of the largest codebases in the world (or may have legacy reasons), but for a "normal" company you will be more productive following a more modern style - see the isocpp core guidelines.
 explicit ThreadPool(const uint32 numThreads) :m_done{false}, m_workQueue{}, m_threads{} { try { for(uint32 i = 0u; i &lt; numThreads; ++i) { m_threads.emplace_back(&amp;ThreadPool::worker, this); } } catch(...) { ///// -&gt; here // I think you need to invalidate your queue here // or you may get a deadlock (or actually wait for infinity on condition variable) in already created worker threads // destructor won't run until all threads are joined, so it won't call invalidate for you // m_workQueue.invalidate(); m_done = true; throw; } }
Neat, but I suspect it is possible to make it neater with a little bit of effort: t["key"_K] instead of t[param("key")] With slightly more effort: t["key"] since actual field names are opaque to the caller anyway.
Threads are not joined on destruction by default. If a destructor for a thread which is still running is called, it causes the program to `std::terminate`.
Clean code isn't always about less lines. Clean code is primarily concerned with expressing intent clearly. Your original example expressed intent, but mixed different concerns, making it difficult to refactor, e.g. changing from pointer to reference, etc. You're also right in that it was a bit ugly. By encapsulating the logic into a function using pass-by-reference, the concerns become separated, with the caller side performing dereferencing (and null checks if necessary) and the function itself concerned only with business logic. Your code also becomes easier to refactor, as you won't have to touch the function at all if you want to pass in a reference or a value – you just change how you call it accordingly.
The mutex itself is reusable though. Pretty big difference.
underscores aren't actually the problem. In both C and C++, identifiers that begin with a single underscore followed by an uppercase character, or any identifier that contains two underscores, are reserved. This is why C has things like \_Bool and \_Complex, and compilers have stuff like \_\_declspec, \_\_inline\_\_, \_\_attribute\_\_ etc.
I have one question about the naming of private variables. why not use `_var` instead of `m_var` ? the first one looks cleaner and infers the same meaning as the second. 
I had a very quick look at your blog post, looks very well-written. Maybe you can split up the code a bit and not present a big blob of code, only to then explain it. I would do it more piece-by-piece. The formatting is also messed up on my browser (Win10, Chrome), I only see 40 chars or so in width. I'm not sure I like that you implemented your own queue. Have a look at this implementation [https://github.com/progschj/ThreadPool](https://github.com/progschj/ThreadPool) which looks a lot simpler.
More issues: - As someone else pointed out, the page layout is pretty broken. - Many missing includes (`&lt;utility&gt;` for `move` and `forward`, `&lt;type_traits&gt;` for `result_of_t`, `&lt;algorithm&gt;` for `max`, `&lt;functional&gt;` for `bind`) - Why does `ThreadSafeQueue::clear()` `notify_all()`? Wouldn't the waiting threads go back to waiting immediately afterwards because the queue is empty? - The catch block in `explicit ThreadPool(const uint32 numThreads)` (and that should be `uint32_t`) must join any `thread`s that are already in the vector, otherwise you'll `terminate()`; before that, it probably needs to invalidate the queue. - `auto submit(Func func, Args&amp;&amp;... args)` - if you are taking `func` by value, then you should `move` it, not `forward`. - Using `std::bind` is questionable. You probably don't want the nested `bind` magic.
&gt; 3 years or more before a developer can be trusted. Heh, that's optimistic. After almost 20 years of daily C++ I still don't trust myself :)
Excellent video here: https://www.youtube.com/watch?v=YnWhqhNdYyk
* in submit() you don't check, if the queue is valid * condition variables are not very reliable, e.g. the worker might wait in `m_workQueue.waitPop(pTask)` forever, especially when finishing * nice to have: a function, which lets you wait until all current jobs are finished * nice to have: suspend/resume, if you want to stop and dismiss current calculations Disclaimer: [My threadpool](https://github.com/elsamuko/copymove2/blob/master/src/threadpool.hpp) is a mix of this [C++11 style one](https://github.com/progschj/ThreadPool) and this [boost style one](http://threadpool.sourceforge.net/). If you want to test your threadpool, you could replace mine in the [copymove2 project](https://github.com/elsamuko/copymove2).
+1 on your comment regarding OpenGL. So many tutorials online that use legacy stuff. And impossible for a beginner to figure out what techniques are legacy and which are not.
I know lots of people with 3-4 years of experience, yet they have not even heard about C++11 and have pointers all over their code. It's a real problem. :-(
A lot of this stems from std::shared_ptr being thread-safe by default, which does make it slower than a manual reference counting implementation if you are only working on a single thread. But saying unique_ptr is slower than a raw pointer is silly. It should be identical on any half decent compiler (assuming you don't do things like disable all optimizations, or use a custom Deleter. And even a custom deleter can be inlined by gcc/clang if it is stateless and marked noexcept).
&gt; The analogous of what you're saying in C++ would then be: Use std::async instead of writing your own thread pool. Yes, exactly. &gt; std::async will be implemented in the best way for each given platform (using appropriate system calls). Yeah, indeed :-)
Nearly identical. As it has a non-trivial destructor there are certain ABIs for which it cannot be returned in a register and has to be stack allocated. Sadly, x86 is one of them. That being said: use it. The overhead is negligible, but the benefits are not.
It also has a lot to do with many people coming to C++ via C, where using array's and raw pointers is the norm.
Ah, right. When I most recently looked at texts, I immediately threw out anything that didn't give at least a nod to C++11.
My principle problem is keeping an eye open for parallel gpu programming with Cuda or OpenCL and I'm hesitant to use fancy stuff they don't support. :(
I thought that, on x64 at least, that it could get passed in register if the destructor is available for inlining (obviously if it is in another translation unit, it won't be avalible).
The most important thing is to question every single line of code you write, every day. Always ask yourself: "Is this the best way of doing this?" The day you stop asking is the day you become "that old guy."
As you should. Anything that doesn't use `auto` is obsolete. [edit: We're talking about C++ introductory textbooks here. I wasn't making a general statement on C++11.]
[Teach yourself C++ in 21 days](https://pbs.twimg.com/media/BZDu_vrIIAA1dLK.jpg)
Don't know why you were downvoted. It seems like working with raw arrays and pointers is usually the best approach for GPU code. Definitely a legitimate concern. 
I hate how this has become a tag line. It might not be premature optimization. We haven't established at what point in the profiling process we're in. Not every optimization is premature!
Key word being "responsibly." But why manage pointers yourself if the library and compiler can do it for you?
Oh yea. And they argue: "It's faster". Or "It's easier to read". :-)
&gt;how are you supposed to understand why, e.g. your program is running slow when you are using a vector where a list is the appropriate choice Like the standard does: the implementation doesn't matter as long as it follows the complexity requirements. Insertion into a `vector` is mostly linear, whereas it is constant-time for a `list`. &gt;I know that introductory classes can't teach everything, but I question what the relative value of each really is If all you do is an introductory class, then you'll end up having a *functional* understanding of the language and library. You'll be able to use streams, containers and iterators. If you follow this up with a second class, then you can start learning the low-level stuff and understand the magic behind `vector`. &gt;And what happens if I need to, god forbid, write an allocator? Then your introductory class is not enough. Whatever you learned in there won't teach you how to write an allocator or, god forbid, a streambuf. &gt;I feel like it's a hard question for most existing C++ programmers to answer My understanding is that it's still an open question. I don't know whether bottom-to-top or top-to-bottom is better. I *feel* like the latter has more advantages, but I have no idea.
Stroustroup's recent textbook [Programming -- Principles and Practice Using C++](http://www.stroustrup.com/Programming/) takes the 'pointers later' approach. It doesn't touch on them until almost 600 pages in. It also seems not to touch vectors or arrays until that point, either.
&gt; &gt; how are you supposed to understand why, e.g. your program is running slow when you are using a vector where a list is the appropriate choice &gt; &gt; Like the standard does: the implementation doesn't matter as long as it follows the complexity requirements. Insertion into a vector is mostly linear, whereas it is constant-time for a list. Except that empirically, this is false. For the most part, cache locality massively dominates the asymptotic difference, unless you're working with a huge data set in the absolute worst-case usage for `vector`
I like to work with data directly, makes it more readable for me, and I think it's better practice for CUDA compatibility. Also I'm too lazy to learn a new way to do things when my current approach works fine for me. E: don't know why I'm getting downvoted for this comment, because I called myself lazy? Seriously people
Precisely. I'm working on a game engine for my portfolio which is built off of a physics engine I wrote for my parallel computing course which needed to be significantly rewritten each time I was tasked to develop for a different framework.
I've taught the last few years using Programming Principles and Practice, but haven't got a lot of positive feedback from the students. I too am tired of seeing so much focus on the low-level in introductory C++ courses. Obviously there is a time and place to learn these details, but using the language properly should be the first step. I'll be teaching C++ this spring using C++ Primer 5th Edition. I'm going full-tilt C++11, and picking out important and relevant sections of the text and developing lectures and exercises around that. I'm planning to put all this up on github or similar, and solicit feedback, unfortunately, I'm a bit behind in doing so.
I'm confused as to why smart pointers are such a big deal. If you encapsulate your classes and deal with your manual memory allocation in the constructor/destructor (assuming manual allocation is even needed)... you can pass your objects around using references and architect your code so that you know which owns what... then what is the need for smart pointers? It seems wildly lazy and inefficient to me. Is the rest of the world so used to garbage collected languages that they just don't want to learn about memory management? Really I don't get it.
"Big deal" is a relative term, but they do help avoid some redundancy and make the intent clearer, as well as preventing some mistakes. I haven't found a case where I want to use `shared_ptr`, but `unique_ptr` is handy, and it is just as efficient as a raw pointer once optimized. Here's a related StackOverflow answer: http://stackoverflow.com/a/106614/951890
&gt;Except that empirically, this is false. This doesn't make much sense to me. Complexity is a useful metric for comparing different algorithms and data structures, that's all. You can't really test it empirically since, as you said, there are other factors in play. Ultimately, `vector` could be implemented as a guy on a stool playing with an abacus. In any case, all that is irrelevant. We're talking about pointers and arrays, and a class on those wouldn't give you any information on what you're talking about.
with OpenCL2.1 you have access to everyting in C++14 that does not require a runtime.
I too agree that there is a huge chunk of documentation that needs to be updated. It is hard to decide on what source gets you the best, most effective results. I am a C# and python (and electrician C99 very low level) programmer currently. They each have their own benefits. I am trying to teach myself C++ through a book, C++ black book, and it is going well so far. However, this post raises concern. What is the best source of training that you all have found so far? Hard Knocks? A book? A website? Should we spin up a new page that includes good foundations but does not sacrifice good form?
By definition (§16.6) #pragma is implementation dependent. Also it falls down broken in the case of files and/or projects on remote drives with intermittent access. http://stackoverflow.com/questions/23696115/is-pragma-once-part-of-the-c11-standard That's actually a really good overview as to when it's not a good idea to use. If you're writing libraries that other projects are going to use then it is a use-case that may happen and as such you should be using header guards not #pragma once.
As shown here: http://www.meetup.com/de/MUCplusplus/ Even when starting from bottom, all you do explain the perfect theoretical word. When actually many other factors such as cach, platform, allocater implementation, os and asychronus execution, play a significant role. And those would not fit in an introductory class.
RemindMe! 5 Years "Ask guy whether he trusts himself."
Spotted the dude without an Nvidia card in his main computer. e: Apparently AMD only supports 2.0? Isn't that 90% of the market or what?
https://www.youtube.com/watch?v=YnWhqhNdYyk for those that haven't seen it. It covers a lot of these complaints, and addresses how to teach modern C++ properly. I personally don't think there's any need to cover C-style arrays *at all* in any tutorial. We have `std::array`, we have range-based for loops, and so there's no need to do any unsafe pointer-based access and looping, or any manual memory management, at least in a beginner's tutorial. Where this isn't appropriate, use `std::vector` as the next best thing, and then consider other containers.
Can you explain how "The C Programming Language" is relevant to learning C++? Not meant to be sarcastic. Genuinely curious, but skeptical. I have the book - and obviously I would like to learn both C and C++ eventually. Just wondering how helpful working through that book would really be for learning C++, ultimately. Do you personally recommend it? Why/why not?
Agreed that it's implementation dependent (like the entire standard library for that matter) so that's not necessarily a bad thing. I think a person trying to include code across several file systems is a bit of an edge case personally. My libraries use pragma once, are reasonably well-trafficked and I've never heard anyone complain.
Platforms: Windows/OSX/NetBSD/Debian/RHEL Compilers: GCC/CLANG/ICC/NVCC/MCVC
Nvidia Is still on 1.1! :(
/u/millenix seems to be arguing a slightly different point. From /u/vanhellion's original question, &gt;&gt; how are you supposed to understand why, e.g. your program is running slow when you are using a `vector` where a `list` is the appropriate choice we should probably infer that the asymptotic complexity of the internal- or front-insertions we're doing is the problem, and that reading the standard is probably sufficient. On the other hand, if the original question were the other way around: &gt;&gt; how are you supposed to understand why, e.g. your program is running slow when you are using a `list` where a `vector` is the appropriate choice then some understanding of the expected implementation and its *is* relevant. A student trying to make their program run faster can reasonably assume that iteration over a `vector` will be more cache friendly than iteration over a `list`, even if the standard doesn't say anything about it.
&gt;What does legibility have to with dependability? Limits the mistakes you personally make. Also more clearly shows control paths. Helps prevent spaghetti. I guess it depends on your definition of legible.
&gt;Laziness is a virtue. Only with long term planning in mind :P
Did you hear about the Italian chef that died? He pasta way. 
What are you responding to? /u/personalmountains was talking about insertion, which is dramatically faster in linked lists than in vectors. You seem to be hinting at a traversal, which is a lot faster in vectors, even though it has the same complexity in lists. But no one said anything about traversals.
Imo there are enough possibilities to represent all kinds of ownership (plain variable, reference, shared_ptr, unique_ptr, reference_wrapper). Problem might be that there is no clear guideline when to use which, so people fall back to the easiest option.
Thanks for the feedback. I've updated the CSS on the page to make it take up more real estate for wider screens while still being suitable for mobile screens, as well. Let me know if you have time to look at the page again and see if it looks better on your end or if it still needs some work. Regarding the cert, yeah the one you're seeing is my hosting company. I will absolutely look into addressing that with Let's Encrypt, but may not get a chance until this weekend at the earliest. Thanks for bringing it to my attention.
Thanks for the feedback! I've updated the thread pool to include a private destroy() function that gets called either by the destructor or by the constructor if it throws. In both instances, it will be sure the queue is invalidated and any threads that did manage did start are joined before continuing. And yep, uint32 is just a typedef for std::uint32_t. I've included that in the updates, as well.
Yep, I wasn't verbose enough in my response to state why removing the underscore would address the issue. In case anyone else stumbles across this, [here](https://stackoverflow.com/questions/228783/what-are-the-rules-about-using-an-underscore-in-a-c-identifier?lq=1) is a stackoverflow question with the pertinent specification items listed.
Upvoted. Writing C++14 code and at the same time worrying about target compilers not supporting `#pragma once` is nonsense, in practice. There are 3 compilers able to build this code, and all of them support it. Also, I can bet money that if/when a 4th will exist, it will support `#pragma once` too. So yeah, there are objections that are technically correct, and everyone knows that that's the best kind of correct, but in practice `#pragma once` is good for everyone that uses modern C++.
I love the part about teaching references first then pointers as an extension of the concept, but one that is rarely needed.
Okay yeah, that's a fair point about CUDA, but what if I want to have a backup using openCL if the client PC doesn't have an nvidia card? Other than "pray they have an AMD card."
&gt; I know it has caused me a lot of headaches when trying to learn OpenGL. Fortunately, I think this has gotten a lot better lately.
&gt;And impossible for a beginner to figure out what techniques are legacy and which are not. Is it too much to ask to have all tutori writers include the version being targeted? Or at least what version they happen to use, even if it's not exact? 
;)
That moment when you wonder if you're in /r/shittyprogramming or not.
&gt; the way I would implement it The thread pool or the mutex? The mutex by design requires system calls. If you don't use system calls, it's a spinlock.
Yeah in the example having a reference is shorter because it's the simplest case, but what about if you want it as a member of a class? If you'd use a reference you'd have to have x available to the constructor, and you can't change it later, meaning you'd have to create a new object. You could try to make a reference every time you use the pointer, but then you have to add a line for every time you use it, compared to once when you set the pointer in value_ptr. My problem is like yours, I just don't want to suffer dereferencing at all.
Dereferencing isn't intent, the intent is to use the value, so it's arbitrary complexity. For example: area = width * height; Compared to *area = *width * *height; Dereferencing is implementation details, and it should be abstracted away. Yes having a function that takes in references creates the same abstraction, but it isn't practical to do it for every expression you have.
Will Scott Meyers be there?
User input is difficult to do correctly in C and C++ (although not so bad in C++), compared with other languages. Unfortunately beginner courses often seem to focus on user input . The Harvard CS50 course takes the approach of providing some "black box" user input functions with an easy interface, so that the student can write programs that require input without getting hung up on the details of the input. I think this is a good approach - you can't cover everything simultaneously and the nitty gritty of stream I/O can wait.
Please do
I have admittedly no idea what a front-end ist (only my cs degree claims otherwise ;) ). I just copy pasted the claim that CUDA uses an "Edison Design Group C language parser" from [here](http://www.geforce.com/hardware/technology/cuda/faq). Furthermore wikipedia claims that Edison "makes compiler frontends". Or are we talking about the fact that the NVIDIA CUDA Open64 Compiler (nvopencc.exe) does the actual compilation as stated [here](http://gpucoder.livejournal.com/)? That was indeed an oversimplification on my part. Edit : I actually would have liked to know why I was wrong... 
Not a single *Map* call I remember ever provided a compatible interface with `std::vector`, you might at most consider specific allocators at which point this would not be an `std::vector` in the proper sense. Consider [clEnqueueMapBuffer](https://www.khronos.org/registry/cl/sdk/1.0/docs/man/xhtml/clEnqueueMapBuffer.html), [D3D9 texture lock](https://msdn.microsoft.com/en-us/en-en/library/windows/desktop/bb205913\(v=vs.85\).aspx), [ID3D11DeviceContext::Map](https://msdn.microsoft.com/en-us/library/windows/desktop/ff476457\(v=vs.85\).aspx), [glMapBuffer](https://www.opengl.org/sdk/docs/man/html/glMapBuffer.xhtml). Main problem perhaps being those pointers are non-owned.
That is why CUDA is the API to go for most researchers. NVidia was clever to support C++ and Fortran from day one, instead of following Khronos idea that only C matters. Now OpenCL 2.1 is playing catchup with CUDA's C++ and Fortran support.
IME, C++Now is quite different compared to CppCon in that it is more of a "bleeding edge C++" rather than the "C++ training" conference. Though, admittedly, there is plenty of both at both (i.e., there have been some nice tutorials at C++Now and some pretty advanced stuff at CppCon). So, in this light, I doubt Scott will be interested in presenting. I don't think he ever has at C++Now.
The formatting works better now. It's still very hard to scroll horizontally though, you want to scroll at the top, and the scroll-bar is at the bottom of the long code snippet. If my mouse didn't have a "3D mouse wheel" (i.e. I can click the wheel sideways to scroll horizontally), it would be a pain in the ass. :-) I guess my point of view on the queue is that I would not trust myself or want to spend the time on implementing a thread-safe queue - others have done that than can do it a lot better, with less bugs and better performance. But if you're confident with your solution then that's fine :-)
it's called an "earned" reputation.
You shouldn't merely throw out anything that doesn't "at least" give a "node" to C++11. **Anything** that doesn't deal with C++11 first and foremost is an obsolete text. There's no reason to learn by writing C++98 anymore, never mind C fed to a C++ compiler.
&gt; In C++ there is a strong tradition of explaining the core language first, and then the Standard Library There's no modern C++ without smart pointers, move semantics, containers and at least some algorithms. You can go pretty far without using the I/O streams. From the point of a beginner or even intermediate student, the distinction between the "core" language and the library is only of interest to compiler implementers. It's nonsensical to teach C++ without the library support at first.
Scott presented at the first BoostCon, but given this: http://scottmeyers.blogspot.com/ I don't expect him to attend this year.
Many of them don't quite know what they are doing either. I like to think that 90% of programming tutorials should be treated as blind leading the blind: the "techniques" they propose may well work, but for anyone with a working pair of eyes they are horribly cumbersome.
This is C: `int foo[5];` This is C++: `std::array&lt;int, 5&gt; foo;` This is C: `for (int i = 0; i &lt; 4; ++i) ++foo[i];` This is C++: `for (auto &amp; val : foo) ++val;` For simple code, I'm not advocating `std::transform(foo.begin(), foo.end(), foo.begin(), [](int a) -&gt; int { return ++a; });`. I know that these are simple examples, but you are probably shooting yourself in the foot by "sticking with pointers and arrays mostly".
I don't know the exact reason. &gt; it is needed to add explicit joins for already created threads in thread pool constructor in case of an exception. --- good point! I forgot that in my own thread pool, I need to fix that. 
I don't even know what you're talking about, frankly said. If you need containers that provide aligned storage, you can use standard containers and aligned allocators, or write your own containers, or use a library. But it really isn't a problem if you understand what you're doing...
&gt; people decided to replace all pointers with `std::shared_ptr` Those must be some wildly misinformed people who take the cargo cult approach to programming :(
I think that the use of references (except in the case of pass-by-reference) should be discouraged. Too easy to confuse object values with object references.
it might just be me, but I have a really hard time understanding code that uses it heavily. and modern compilers often manage to avoid the overhead of dynamic dispatch.
I see this a lot on /r/cpp_questions as well. In fact often enough that I got sick of repeating those things and put the explanations on my own site so I can just link it: http://florianjw.de/en/modern_cpp.html I also agree that the problem is bad and would sign about 95% of [Kates talk](https://www.youtube.com/watch?v=YnWhqhNdYyk) only disagreeing about a few minor details. I have no problem whatsoever to believe her, when she says that she managed to teach some people the essentials of C++ in a weak (or was it even a day? It's been a while since I've seen the talk) C++ could be such a simple and intuitive language if we wouldn't first force everyone to unlearn the intuition only to teach it back to them later. The big problem that we have is that there are currently no good and free online-tutorials for beginners. cppreference.com once tried to create one, but that attempt died. BUT: I took what I wrote there and moved it to [my own page](http://cpp.florianjw.de/) where I somewhat extend it from time to time (far less frequent than I would like, but at least it isn't dead). If you want to write your own top-down tutorial, please consider participating here instead, maybe it will get to a sufficiently complete state in a finite time then. ;-) (It is written using pandoc-markdown with github as central repository, so the toolchain should be mostly familiar) Edit: If you really want to help (awesome!), please give me a short note to make coordination easier and avoid pointless work.
&gt;auto is a maintenance headache/nightmare In what way? &gt;seems to be a weak hack What else would you propose? Why is it weak? Why is it a hack? &gt;C++'s core problem of default implicit type conversion. What problem? Are you talking about primitive types? What does it have to do with auto?
&gt; I can't believe these guys are perfect programmers No one is a perfect programmer. Mistakes aren't a reason not to hire someone, often you learn your best lessons from mistakes. It's learning from them, fixing them, and moving on that are good reasons to hire someone.
I would say this is a typical example for Survivorship Bias. You only know those few successful programs from 30 years ago...
See slide 8 : http://www.iwocl.org/wp-content/uploads/iwocl-2015-tutorial-OpenCL-Next.pdf
From the experimental results I've seen reported, even `push_back()` is practically faster for `vector` than `list`, until you get to very large sizes. Both are specified with asymptotic constant time (amortized, in `vector`'s case), but `list` implementations require allocation on every element, while `vector` allocates much less often because of increasing its reservation by a constant ratio.
Well, there's Linus's [irrational hatred of C++ developers and the rants he flies into](http://harmful.cat-v.org/software/c++/linus) where he spews [ignorance filled venom](http://programmers.stackexchange.com/questions/45138/worst-practices-in-c-common-mistakes/45169#45169). I'd think twice before hiring someone like that.
&gt; I suspect the compiler has more leeway if the function in question has internal linkage and is itself inlined Even if the function has external linkage an inlined version isn't bound by ABI constraints. Full inlining also shouldn't be necessary; LTO and other cases where a single implementation is handling both sides of the call could eliminate the overhead regardless of the ABI constraints.
 std::transform(foo.begin(), foo.end(), foo.begin(), [](int a) -&gt; int { return ++a; });. can easily become transform(foo, foo.begin(), [] (int a) { return ++a; });
I would love to see more mistakes from Linus actually ;-) I kinda like his attitude nevertheless and he's a cool guy in some respect, but a lot of the things he says just go overboard. [This](https://www.youtube.com/watch?v=1Mg5_gxNXTo&amp;feature=youtu.be&amp;t=14m37s) part of that video is really fun to watch ;-)
&gt; even `push_back()` is practically faster for `vector` than `list`, until you get to very large sizes Mm. Moving a bit off-topic, I wonder if games (and other applications requiring better time guarantees) would like a data structure that's a linked-list of ever longer arrays, like a `vector` that has been "cut up" at the points where it should have "expanded." The benefits: - Iterators are not invalidated on `push_back` etc, - Real constant time `push_back`, not amortized, - No copying/moving of elements when you `push_back`. Potentially your objects don't need to be copyable or movable at all. The disbenefits: - Indexing is now log-time worst case (but expected constant time for random accesses if you iterate from the largest block to the smallest), - A few more cache misses when you iterate over the data.
Modern compilers in most cases actually can't optimize dynamic dispatch. Unless you use whole program optimization, you're usually going to define your virtual functions in a C file, and then the compiler can't inline it. Even if you define it in the header, you're probably putting your base class pointer into a container like a vector (like when implementing slots and signals), at which point the derived types inside may be mixed, and the compiler is totally hopeless then.
It would be better to link directly to http://nuwen.net/mingw.html for my distro. That URL is stable (the downloads aren't). Well, I will switch to HTTPS in the nearish future, with redirects. I am also amused to see data() causing trouble, since my fingerprints are on that one too.
That's like a month in regular person time.
Your `push_back` still won't be worst-case constant time, I don't think, because those blocks need to be constructed. Though they could maybe be left uninitialized, but I don't think the standard can quite require that. You can make indexing not log-time by keeping an array of pointers to the blocks, rather than a linked list. Also, `push_back` has to do one of copy or move construction of the new element. `emplace_back` wouldn't, though. If you only ever called that, then a type without those constructors could still be valid.
&gt; Though they could maybe be left uninitialized Yeah. I think you can use `std::aligned_storage` and placement-`new`. I am assuming you can allocate `n` bytes in constant time, though. &gt; keeping an array of pointers to the blocks I guess that works. You'd need a constant-time `log_2()` which is pretty reasonable. I guess the array of pointers would have O(`CHAR_BIT*sizeof(size_t)`) elements so you'd never have to grow it? To be honest I think I might rather give up constant-time indexing. I don't use it all that often, and an array of 64 pointers is a bit much if I may only be expecting a few hundred elements in my "vector".
Hey Josh, great to hear you're getting involved in robots and C++! I work in robotics and do all my programming in C++. In order to give you some good and targeted advice, do you know what robotics platform(s) you'll be working with? i.e., will you be using Arduino, Lego Mindstorm, ROS, a custom platform, etc?
To be fair to Linus, 2007 C++ was a lot worse than 2015 C++.
Pretty much anything involving number crunching. I get comparable runtime speeds for the same program compiled with msvc 2015 and gcc 5.3 on a NetBSD VM running on the same computer, but the mingw version (with the same compiler options) is 2 or 3 times slower.
Could be something with msvcrt.dll if you're calling CRT functions, or it's within the realm of possibility that my `--with-tune=haswell` (which can be overridden when you invoke GCC) is making a difference. See if you can reduce it to the smallest possible program, then inspect the codegen.
http://en.cppreference.com/w/cpp/experimental/apply
Ah, that's awesome and exactly what I'd be looking for. I'm sure compiler support is limited at the moment (I looked in VS2015 Update 1 and it's not there), but I think the recent version of the big 3 all support enough to manually implement it the way it's shown on that page. I'll definitely look into implementing it that way and see if I can't get rid of the need for std::bind altogether. Thanks for bringing that to my attention.
I use -march=native, and there's no OS specific stuff. I'm putting together a self contained tarball with an example that does a lot of md5 calculations - takes 30 seconds to run with MinGW, and 5 with msvc. Not sure how to get the Microsoft compiler to output assembly, and I'm not sure if it would help anyways. I'm not very fluent in it. I should find another MinGW distribution and see if it has the same problem...
Examples? I've compiled on consoles, phones, embedded environments and never run into this issue. Solaris and FreeBSD in addition to many linux variants as well. I realize it's a "technical" concern, but I think pragmatism is a virtue as well.
Which compilers have you used? We usually use the official OS vendor SDK. By not depending on compiler extensions we reduce time researching what each compiler does differently. 
So no aC++, xlC++, SunPro C++, ARM DS, TI C++, Green Hills C++, Atego C++.... Which of course is a reason for not having many problems. 
I think in the context of a C++14 library implementation, I'm making safe assumptions about the library's usage.
From the post: &gt; Conan is lead by former biicode employees, we have been working in this problem for more than 3 years now From LICENSE file in the repo: &gt; Copyright (c) 2015 Luis Martinez de Bartolome My assumption would be that a large portion of this codebase has been developed by biicode which has since folded. The big question is who holds the copyright to this work? Has it formally been transferred by investors (biicode was VC-backed) to Luis Martinez de Bartolome?
I and other people I know have looked at disassemblies and it actually happens more often than I thought.
Can you give any resources (books, websites) that are good to start with if you want to get into robotics programming?
There you are pretty safe as many of those compilers are still playing catchup with C++11.
&gt; First we are eating our own dog food. Conan user “lasote” has many hundreds of packages for Boost, OpenSSL and some other libraries. Sorry but a man that put the tin can around vegetables is not a farmer. So packaging C++ software is not writing C++ software. This is a huge problem for conan : the need for another software stack (Python) just to build C++ software. 
LOL, this is being heavily downvoted by newfags. 
Done, I have updated the link. Also I have switched to self-extracting 7zip archives because I could digitally sign them. If you have 14€ to spare (used to be free though), get a "Open Source Developer" authenticode digital certificate from [Certum](https://www.certum.eu/certum/cert,offer_en_open_source_cs.xml) – it would be nice to see the MinGW distro digitally signed ;-)
This looks really cool, I really like all the effort you have out into the documentation. Honestly if bicode was more like this I think they would have a better go of it (non-invasive, any build system). I have a quite a few questions: - Do you have a spec for the Conan package format? - Can you put up repo with the conanfile.py for the packages you already done? - Do you plan on supporting packaging signing (maybe I missed this)? - How are emded package paths handled? For example when you build some programs or libraries at build time certain paths are baked in. - I could not find any discussion on ABI compatibility handling. Are you taking steps to ensure that you can get packages built with the correct compiler ABI, libc ABI, C++ library versions, and OS level? - Can I install my compiler with Conan?
Thanks! :)
Yes but you probably did so in trivial test cases, whereas the conditions I just described are what actually happen in real apps. 
TIL Android is a programming language. 
Best for beginners in what sense? Quickest to learn? Most job opportunities? Most flexible?
I was happily filling it out, then they asked for my email address and I decided to save myself a bucket load of spam.
This is sort of like asking "what's the best tool to start with when learning to be a handy man?" And then listing things such as screw driver, hammer, saw, wrench. My point being, i dont think there is a best language for learning. Sure, languages like python are commonly referred as being beginner friendly since they are potentially a little less daunting then dealing with something like C and the ability to very easily make mistakes with pointers. That said, understanding pointers is crucial to programming, so there's something to be said for learning C as well. The more you understand about how the computer actually works when it executes your code, the better programmer you can be. The important thing is to just pick one and start, it doesn't matter which one.
I don't think people who vote Python realize the importance of the C-style syntax and how much it has influenced languages we have today. It's best to get used to it earlier rather than later because it's relatively more complicated than the others. Once you learn the C-style syntax, you'll easily learn other styles like Python, VB and Lisp (and if you can't, maybe programming is not for you). For beginners, I would go with C#: A better Java; it teaches the C-style syntax without the memory management trouble. Say what you want about Microsoft, C# is one of their best products ever.
Thanks for the comment. We appreciate every feedback in our survey helping us to make it better next time. We want to send you final result, and therefore we need your e-mail. If you don't want to leave your e-mail, you could fill "abc@abc.com" in instead. Thanks for your cooperation and participation.
Pascal is the second language I ever learned and it nearly drove me away from programming forever. I later went to college where I first learned Scheme &amp; then C (and dabbled in several others) and to this day, I would gladly write in either of those before going back to Pascal. All of Wirth's languages are god-awful. YMMV... For learning basic principles, Python offers a decent combination of simple syntax and intuitiveness (beyond that, I'm less enthused by it). Many of the Lisp-like languages are also good in this way.
&gt; Who said I was a C++ developer? I'm a python (and many other languages) programmer and now I'm just a "packer". So If I have written a C++ package manager I should "package" a lot, don't you think? If C++ is not your main development language, how can you know all the subtleties of building C++ projects? &gt; I think install an external tool (just install, you don't need python) is a very low price to pay in comparison with the conan's benefits. I would be very interested to know how you run conan without python. &gt; I'm sure you are a great C++ developer, if you don't have any problem managing your project dependencies conan is not for you. I have project dependencies problems, but conan is not a solution for me. If it is for others, that's fine. 
Is he any less of an idiot about it? Frankly, I find it funny because the second worse code I ever saw in my career was written in C by a C bigot. Globals everywhere, no bounds testing...dude got pissed when I'd add an initialization to a variable declaration... People can write crap in any language, but Linus decides that C++ *leads* to crap code. I very much doubt he's changed his perspective at all. The things he complains about are the very things that modern C++ is based on. His recommendation was to stick to C only, which is the old, broken way of doing things in C++.
&gt; If C++ is not your main development language, how can you know all the subtleties of building C++ projects? I don't! Who knows? Do you? But I learned enough working 3 years packaging C++ projects. I don't need to know a lot about templates and meta-programming. ;) &gt; I would be very interested to know how you run conan without python We provide standalone installers for conan. Interally uses libpython but its not required to install it. &gt; I have project dependencies problems, but conan is not a solution for me. If it is for others, that's fine. Ok! So if you want to give more feedback we will glad to try to make conan a better solution for you! Thanks again! 
Sure, consider this code: template &lt;class T&gt; void func(const T&amp; t) { auto u = t.func2(); std::for_each(u.begin(), u.end(), ...); } This code imposes no restrictions on T other than that it has a const method func2(), that returns something, and that something has methods begin() and end(). Of course, we had generic containers before auto and ranged for loops, and we needed to know the type of the iterator, so how did we deal with this? Well, as I'm sure you know, we imposed an additional requirement: containers *have* to provide typedefs that tell you the type of their iterators, i.e. the return type of begin()/end(). But that's already not doing the same thing, as it imposes more requirements. Basically, auto allows you to do inline what template functions allow you to do at function boundaries. You could potentially workaround using auto by declaring yet another template function and calling it internally, but again, I would argue that this is doing something quite different as you have to move your code to a different location (not a big deal when you have two consecutive 4 line functions, but if you have longer functions its rather absurd). Another attempt at a solution would be to try to infer the type using template metaprogramming, so that you could get the type inline and use it, but this doesn't seem to be possible in general: http://stackoverflow.com/questions/26080471/function-return-type-deduction-in-c03
&gt; I don't need to know a lot about templates and meta-programming. ;) Don't judge him people, it's my fault Lasote think that every C++ freak out there only knows to talk about templates and eat palmeritas.
As someone who learnt programming on GW-BASIC, I would suggest starting out with [SmallBasic](http://smallbasic.com/) rather than VB. Smallbasic makes it very easy to create graphics and animation which, as a kid, was my biggest draw towards programming.
This looks interesting, but a question comes to mind. Why would I pick this over MSYS2 (pacman) on Windows or pacman on Arch Linux? Not trying to be condescending in any way, I'm genuinely interested to know what the direct pros and cons are over the current package managers we have available.
Mooooooods!!!!!!! People are getting trolled by this. And it's the second time I see spam on here. delete[] pls;
&gt; And I'm not what I'll be working with, but it will be using metal, gears, motors, ect. Which is offered to middle school and high school. The instructor didn't give any platforms that corresponded to it so it's Hi Josh, I currently work in the embedded systems space, which is also focused in problem domains where many of the same automation concerns and resource constraints govern production. Additionally I focused heavily on robotics during my undergraduate work. I'd be happy to help mentor you if you like, so feel free to drop me a PM if you have any questions. As far as I can tell, the neither the Lego Mindstorm nor the Vex platforms specifically have the end user (you) writing the "code" the robot runs directly in C++, so if you are using one of those platforms you might be actually ok with not learning C++. Both look like they have specific SDKs (Software Development Kit) focused on early STEM education which offer language abstractions. If you are going to be directly programming "on the metal" of a micro-controller, so to speak, you have chosen a rather impressive curriculum for yourself, as this can be more challenging. But I guarantee you the material you learn will be invaluable! In my personal opinion, the hardest part about getting started with embedded / robotics programming is learning and understanding the process by which software is actually created, loaded, and then executed by the robot / embedded system. Having a -basic- understanding of these processes is, in the beginning, perhaps more important than understanding C++ if you want your robot to actually work and will be valuable even if you aren't programming in C++. If in the class you are using a commodity micro-controller, which is the less-powerful, but more efficient class of consumer hardware, (Arduino is a popular brand you might be familiar with) you might be using a more limited subset of C++, something much closer to a similar and simpler language both in name and syntax: C. If it turns out you are working on a more powerful system-on-chip (often abbreviated as "SoC") type hardware, something like the popular Raspberry Pi brand, then you would have enough computing power to not only use many modern C++ features, but you also would be able to run an operating system like Linux or even a local interpreted language like Python. I'm reasonably confident that you will most likely be working on either the Arduino or Raspberry Pi platforms. Both have very strong communities, an abundance of documentation, as well as lots of officially supported hardware, tooling and libraries. I think the best way to proceed would be to learn a little about each of the aforementioned platforms. Then find out as soon as you can from your instructor what platform you will actually be working with in the course - in this kind of work, the platform choice often strongly influences the tools and workflow you will perform. With regards to learning C++, specifically if learning as a first language and introduction to programming, I think "Programming: Principles and Practice Using C++" by the language creator is good as well as "C++ Primer 5th Edition". For an introduction into the C language which is VERY similar in basic syntax structure and VERY common in the micro-controller world, I can recommend the free resource "Learn C The Hard Way" found here: http://c.learncodethehardway.org/book/ Best of luck! 
This is true, but I think for most people asking the question "what language is best for learning", the end goal is to simply be a somewhat capable programmer. I was in the same boat once and I know in hindsight that it really didn't matter, the important thing was just starting somewhere.
Great, thanks!
Alright thanks man, I really appreciate you taking your time to write all this to give me a better view of how it works. :)
There are many different build systems out there for C++ development that try very hard to be easy to use (CMake, SCons, Eclipse CDT managed projects, and even Bazel come to mind). And for relatively straightforward projects, they are. However, the thing that bugs me about them is that they tend to be relatively high-magic systems that try very hard to abstract away much of the process of building software. For me, I keep coming back to GNU Make. It has one simple core idea - build an acyclic graph of dependencies and follow that graph in depth-first order. And because of that simple unifying idea, I find that it has far more power and flexibility than any other system out there.
It is probably more powerful, but this goes more for ease of use. OovAide uses CLang to parse the C++ files to find include dependencies. It most likely would be better if OovAide was transparent, but if it works well, the dependency graph will be constantly updated whenever an include dependency changes, which reduces the advantage of being transparent.
I use cmake, and I've found that dependency graph management is far and away the easiest part. 
I agree that too many build systems is not a good idea. But it seems like an improved module or package system (probably both) would help a great deal. I don't think that CMake goes as far as a build system could.
Can you use it like a copy constructor? E.g.: Test a(0, 0); Test b(a); If it compiles, then I would say that the class is copy-constructible (at least under certain conditions). **Edit:** Oops, now I remember. "T&amp;&amp;" might not actually be a "&amp;&amp;" in this case, because "T" is a template argument. See universal/forwarding references: http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4164.pdf So the template constructor can be instantiated with any "T&amp;", which basically makes it a copy constructor, except for "const Test &amp;", which should find the deleted constructor.
It's definitely a bug in boost. The standard defines `is_copy_constructable` as: &gt; For a referenceable type T, &gt; the same result as &gt; is_constructible&lt;T, &gt; const T&amp;&gt;::value, &gt; otherwise false As that class is not constructable from `const Test &amp;`, it must evaluate to false. 
&gt; is built from source in our repository by our build script Why not build a docker image containing the build environment? Sincere question, since we're considering to do it, so I'm interested in opinions.
For the future, don't write a headline like this. People don't know what your project is, why would they care about a version release.
This is a great point although I can remember writing dependency targets using cc -E piped to sed et al. But then again I was using UNIX with make before Linux even existed.
I think it's just one of the obscure language corners. The constructor which takes the forwarding reference parameter is greedy and "hides" the deleted copy constructor. Both GCC 5.2 and Clang 3.7 compile this code http://melpon.org/wandbox/permlink/TnXZB0lBurjC4GfF and it produces: Test(T&amp;&amp;) called Test(T&amp;&amp;) called 
Looking at the the stats, it got a lot more clicks than just "blah blah build tool" has, other factors may be the reason (time of day etc). I appreciate your criticism though, noted. Maybe I should take a PR class, or bleh, marketing...
First, it is not my benchmark. Second, the benchmark is not 'bogus'. Please let yourself know the subject before calling anything 'bogus'. At least read the [compiler documentation on the subject](https://gcc.gnu.org/onlinedocs/cppinternals/Guard-Macros.html). Then you would know how those optimizations work. Any source file must be read and preprocessed fully then included first time. There is no difference between pragma once and include guards. The compiler then remembers path of the file (in the case of pragma) or path + guard preprocessor symbol in the case of include guards. Then the file is included second time, the compiler looks up the path. It the file is already known to have pragma once it is not opened. If is known to have include guard, the compiler checks if the symbol is defined and if yes, does not open the file. *In both cases the file is not even opened second time*. Yes, include guard optimization is more fragile in a sense that it is syntax-sensitive. (There are limitations on the syntax which can be optimized). 
Your test code is insufficient, you need to declare `t` as `Test const` to test that a copy constructor is invoked. And lo and behold, it then fails to compile.
That's not a copy constructor. [class.copy]/2: &gt; A non-template constructor for class X is a copy constructor if its first parameter is of type X&amp;, const X&amp;, volatile X&amp; or const volatile X&amp;, and either there are no other parameters or else all other parameters have default arguments (8.3.6) --- &gt; Note that std::is_copy_constructible doesn't check if the class actually has a copy constructor. &gt; &gt; What makes you think that? The standard says so in [meta.unary.prop]/3 (table 49). &gt; For a referenceable type T, the same result as is_constructible&lt;T, const T&amp;&gt;::value, otherwise false. [meta.unary.prop]/7 defines `is_constructible` as: &gt; Given the following function declaration: &gt; template &lt;class T&gt; &gt; add_rvalue_reference_t&lt;T&gt; create() noexcept; &gt; the predicate condition for a template specialization &gt; is_constructible&lt;T, Args...&gt; shall be satisfied if &gt; and only if the following variable definition would be well-formed &gt; for some invented variable t: &gt; T t(create&lt;Args&gt;()...); Given that this can call a template function that would otherwise match the signature of a copy constructor, it doesn't just check for copy constructors.
Would be useful if the title indicated that this related to C++ Interview Questions rather than C++ generally. Would have saved me clicking though.
But http://www.boost.org/doc/libs/1_60_0/libs/type_traits/doc/html/boost_typetraits/reference/is_copy_constructible.html doesn't specify constructable from const T&amp;, nor that it gives the same answer as std::is_copy_constructible, only that T is a type "with a copy constructor". It's obviously not ideal that the boost trait is different from std, but if the boost version was published first, and then the standard tightened the std definition, it's not necessarily a bug if boost chose to keep its existing behaviour.
Any package system that comes with a distro does the job. We just need to get rid of non-FOSS projects that are touchy about the mode of distribution.
Correct, I’ve deleted the offending sentence. Nevertheless, the rest of my comment remains.
Overload resolution will favor an exact match over a template. Try it. $ cat foo.cpp struct Test { template&lt;typename T&gt; Test(T&amp;&amp; x, int y = 0) {} Test(const Test&amp;) = delete; }; int main() { const Test x(42); Test copy(x); } $ g++ -Wall -Wextra -pedantic -std=c++11 -g -O2 -D_GLIBCXX_DEBUG foo.cpp foo.cpp: In function ‘int main()’: foo.cpp:10:16: error: use of deleted function ‘Test::Test(const Test&amp;)’ Test copy(x); ^ foo.cpp:4:5: note: declared here Test(const Test&amp;) = delete; ^ foo.cpp: In instantiation of ‘Test::Test(T&amp;&amp;, int) [with T = int]’: foo.cpp:9:20: required from here foo.cpp:3:14: warning: unused parameter ‘x’ [-Wunused-parameter] Test(T&amp;&amp; x, int y = 0) {} ^ foo.cpp:3:25: warning: unused parameter ‘y’ [-Wunused-parameter] Test(T&amp;&amp; x, int y = 0) {} ^ foo.cpp:3:14: warning: unused parameter ‘x’ [-Wunused-parameter] Test(T&amp;&amp; x, int y = 0) {} ^ foo.cpp:3:25: warning: unused parameter ‘y’ [-Wunused-parameter] Test(T&amp;&amp; x, int y = 0) {} ^ 
Oh whoops you're right. For some reason I was thinking that `delete` just removed it from the overload set. I definitely knew this, I just forgot. Whoops.
qt is framework relying on MACRO hacks! boost is idiomatic c++ template based library! there are many side effects of those two facts!
its all BS! trust me i'm coming from there back in c++. I've adopted CLR since beta (I think 2001). There are excatly 0 reason for CLR/Java. Either go native or go dynamic. The middle ground C#/Java is for middleearth :P alot of convolution and always huge drawback on efficiency. not to mention maintenance hell. pleas use those 100 classes to accomplish something a normal language should in a snippet of 100LOCs
indeed finding c++ devs is ~2-4x harder than JS-monkeys or even brainwashed 'managed' ones. However, the good news is at least you have the best type of programmers: the thinking type!
till you havent debugged a memory leak in managed land. with stacktrace half in managed half in native land. where debugging might be hell the alternative is simply impossible. tiny runtime wins over complicated ones ALWAYS!
not only time-vs-space but the temporal patters / dynamics too should be considered too! thats why is silly to talk optimal without a concrete context!
this a fair point. use static and dynamic in the same project. e.g. c++&amp;LUA ; c++&amp;python; keep in mind you end up paying for the GLUE between those though. in terms of writing it once and supporting in the future! what I like most about c++ in building apps is that I have onle language where I can go as high and as low level and no need to get out of my comfort zone :) so whether you are parsing HTML request or talking to low level hardware it is all the same language, maybe different looking but hey it is still the c/c++
to add some example: many desktop apps use c++ and TCL for GUI. now tcl is a whole different language and the bindings between c++ and tcl are far from trivial. Now you need 2 expertise to solve truly 1 issue !
&gt; the libraries we need are not there jap, same story all over again. when people asy langauge they trully mean standard tested libraries and runtimes :)
wait a second, let's say we are using c# and ask you to query a DB! are all devs going to give you the same solution? string based sql query, then we have LINQ in form of lambdas or way worst in form of strings again, DbConnector, store procedures, which one!?!?!
DB apps like these are not CPU but IO bound !
The only way there are toxic legal issues is if you are re-implementing the API and not basing it off of openjdk. Almost nobody has a use case for that.
I won't argue with data but that's not marketing, it is common sense.
Using package managers can many times be a global solution to a local problem. Many times package managers have much older versions. Also, you may have software that requires different versions.
 make: *** [all] Error 2
Pure SQL or stored procedures if no DB portability is required, no need for the ORM of the month or to do at the client tasks that the DB can handle itself. 
&gt; Its going to be very hard to come up with a feature that any build system does that Make doesn't do. * Caching * Dependency-satisfaction based on checksums, rather than on timestamps. However, I think wrappers like **ccache** are better than relying on the build-tool (e.g. **scons**) to cache outputs. I see no value in `-MMD` etc. They are rarely used correctly, and they add needless complexity. Just clean and rebuild completely, with caching.
I recall reading this some time ago. Thank you for pointing it out anyway.
Same here. :)
&gt; Its going to be very hard to come up with a feature that any build system does that Make doesn't do. Well let's see: - usability - reliability - performance That was easy. I didn't even have to go into details such as having more than one output file for a build rule. 
I don't think so?
True, but they are so mature that all the side effects can be avoided following good programming guidelines
&gt; Any package system that comes with a distro does the job. Sadly not when you want to use libraries with special flags, like _GLIBCXX_DEBUG :(
 set_property(TARGET YourTarge PROPERTY CXX_STANDARD 14)
NSFW, reported. mods plz report this crap to the admins.
Thanks!
More elaborated thought: dependencies are not necessarily are C++ libraries, it's a mix of languages and tools. So no C++ module system can solve this completely. It's like a migration of a part of some specific build system into the language standard.
&gt; ... doesn't work for projects where there are duplicate include file names... Alas, supporting duplicate filenames (both source and header files) is a requirement for many projects, especially in the embedded space. Take a look at the ChibiOS, FreeRTOS, or RTEMS archives, for example. The filesystem naturally creates a hierarchical namespace and the build system should support that namespace.
That is a good point. A complete build system must be a superset of a C++ system of dependencies.
&gt; I want to say "hey this needs boost::asio &gt;= blah" and then have it either confirm that it exists find_package(Boost 1.5x REQUIRED COMPONENTS asio) if (${Boost_FOUND}) #blah endif() &gt;or go get it. I think there were a couple of systems available that tried to do that... but I think they kind of fizzled out. The problem is what you mean with "go get it". Which version? From where? What about authentication, do you have an md5 or a public key I should check? Git or svn? Trunk, head, or from a branch? Maybe you need to authenticate to get it? And after you download it, you will want to build it I suppose? Which additional flags/configuration should I use for that? Cmake has an [ExternalProject](https://cmake.org/cmake/help/v3.0/module/ExternalProject.html) function that does *all* of that, but you have to be patient enough to ask exactly what you want. 
Well, std::deque is nearly this. It's just an array of arrays, instead of a linked list of arrays. In fact, std::deque::push_back invalidates iterators, but not references. Although I'm struggling to understand exactly what this means; I assume it means that iterators could still be dereferenced but possibly ++ could go sour? I'm pretty sure that deque meets your other two requirements. And to top it off, its indexing is still constant time (not amortized). It does however have more cache misses. In practice, people tend to use a vector still unless they need push_front (which is constant time for a deque). I think that access/iterator speeds tend to trump insertion speeds for these data structures in the vast majority of applications. 
I think 3 years is a huge overestimate. People will make mistakes and do silly things, but that's what code review is for. With good training someone good can make major positive contributions within 6 months, and within a year I would trust them to design and write chunks of functionality at a thousand lines or so and get all the major points right most of the time. There's a lot of unsafe/obscure stuff you don't have to master to write solid code. I barely ever use unions, reinterpret_cast, const_cast, virtual inheritance, private inheritance, etc etc. If I didn't understand these things at all I could still write solid code, I'd just need a minor correction in code review once in a blue moon. 
Part II is at [Andrei Alexandrescu Writing Fast Code II](https://www.youtube.com/watch?v=3_FXy3cT5C8)
For those of you who might not know, Andrei is a legend. This looks like a very well produced video, with multiple camera angles and useful slide presentation. I can't comment on the content as I haven't seen more than a few minutes, but with part 1 clocking in at around 90 minutes, there's bound to be some great stuff in there.
a good read. i am very much looking forward to std::variant, i think it's coming out just right design-wise. an alternative approach is mapping the function-pointers into a 1-dimensional table, and computing the index of the function pointer corresponding to the variant-type coordinates by taking the inner product of the index-vector and an offset-vector (that you can compute at compile time): [source](https://bitbucket.org/jehelset/jeh/src/241fc8e65d43c0ebe9452632ed8966c59bc8fcd1/abstract.hpp?fileviewer=file-view-default) (offset_generation @line 68 and index computation @line 103)
Most people in this discussion deviate from the problem OP mentioned and put words in my mouth. The topic was using smart pointers vs raw pointers. No one talked about using shared_ptr absolutely everywhere. Unless you are using manual memory management instead of shared_ptr because you think you need the performance, without actually profiling. I that case we disagree and I think you are part of the problem OP talked about.
I am curious why rectrue publishes Code::Dive presentations when they are still missing on the Code::Dive official website and youtube channel. Been there - great conference. However (in my opinion) first edition (year 2014) was way better. You can check the presentations on the official youtube channel: [NOKIA Wroclaw Technology Center](https://www.youtube.com/channel/UC_l25lelCgcHtn3TeSyAQQA/videos)
I'm not sure I understand what you're getting at, but here's what I think I gathered: You cannot compute during compile-time values that depend on run-time information. You'd have to load the file at compile-time, which defeats the whole purpose of having files. For example, you can compute `2 + 3` at compile-time, because the compiler can tell that it can only be `5`, but it cannot do `x + 3` unless it can see what x is. Files are meant to be loaded from the user's computer, which you have no compile-time information about, because you literally have no access to the machine on which the program will run. Compile-time occurs when your program gets compiled, before run-time. Loading files is something generally done at run-time, because the whole point of files is to provide input and output when running code. When compiling `container.LoadFile("blah...");`, this code gets turned into an equivalent bit of machine code that will load a file when running the program. What this file will contain, will depend on when and where you run your program, so container will have to be a variable. This is a limitation of our current compilers, which cannot travel through time.
You can certainly invoke b2/bjam _from_ CMake; it's a single invocation per address-model, or a single invocation totally if you tell bjam to use hash directory structuring.
I would vote for meson anytime if it: 1.- had seen more use. 2.- had decent XCode and Visual Studio solutions generators. But right now, talking about support, cmake is difficult to beat: it is in IDEs such as CLion and it has become a de facto standard. I am considering to write some emacs integration through mesoninstrospect, but that will have to wait if ever done. Too busy! :)
interesting series about c++ and lua :)
change IsPowerOf3 to be: constexpr bool IsPowerOf3(unsigned int n){ and you can verify it: static_assert(IsPowerOf3(27) == true, "FAIL");
behold the power of compilers : http://goo.gl/TZXwnq and http://goo.gl/03ozCy
I think now it is back as **constexpr_if**. http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/p0128r0.html
so you are seriously saying that you are teaching students c++ without pointers? what is even the point of using c++ then?
I think this could work as well. constexpr bool f(int n) { if(n == 1) return true; if(n%3 != 0) return false; return f(n/3); }
Just to complement [/u/remotion4d](https://www.reddit.com/user/remotion4d) comment, [here](https://isocpp.org/files/papers/n3613.pdf) is a paper from 2013 by Bjarne, dos Reis and Sutton on why the original `static_if` proposal was perceived as flawed. The [new paper](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/p0128r0.html) on `constexpr_if` is proposing a restricted form of `static_if`, avoiding what was perceived as flaws on the original proposal.
only if program isn't taking input and calling function with literal. right?
Rather than using a std::set which has significant overhead, you'd be better off using a fixed sorted array, which still gives you logarithmic lookup time by using the likes of std::lower_bound. Though for such a small number of elements as this a linear search through an array would be perfectly fine as well.
Hmm I didn't knew that, though I don't understand another thing you mentioned. How would storing 'valid powers of 3 in an std::set' be better than simply using above method. std::set won't store those values in memory at runtime?
Oh yah i love that about CMake, it lets you make the build script all in one place so people can then choose what they want to work on. The only issue i have is that sometimes you have to write CMake code to edit compiler flags. Like for visual studio, if you want to link against the static standard library, you pretty much have to go through every flag and switch /MD to /MT. It's great you can edit compile time flags as the user but it can be a pain for the person writing the CMake as they can't choose the default compile flags, as far as i know without potentially overwriting a user's custom input for the flags.
http://ideone.com/dl2fMJ std::istringstream input("wasd 13\nesdf 103\nyghj 42\n"); constexpr str_const arr[] = { "wasd", "esdf", "yghj" }; int values[std::size(arr)]; // this can be runtime while(input) { std::string name; int value; input &gt;&gt; name &gt;&gt; value; for(int i = 0; i &lt; std::size(arr); ++i) { if(name == arr[i].p_) { values[i] = value; break; } } } // computing the indices here is compile time though, even if they are accessing runtime values std::cout &lt;&lt; arr[std::integral_constant&lt;int, Find(arr, "wasd")&gt;::value].p_ &lt;&lt; " = " &lt;&lt; values[std::integral_constant&lt;int, Find(arr, "wasd")&gt;::value] &lt;&lt; std::endl; std::cout &lt;&lt; arr[std::integral_constant&lt;int, Find(arr, "esdf")&gt;::value].p_ &lt;&lt; " = " &lt;&lt; values[std::integral_constant&lt;int, Find(arr, "esdf")&gt;::value] &lt;&lt; std::endl; std::cout &lt;&lt; arr[std::integral_constant&lt;int, Find(arr, "yghj")&gt;::value].p_ &lt;&lt; " = " &lt;&lt; values[std::integral_constant&lt;int, Find(arr, "yghj")&gt;::value] &lt;&lt; std::endl; So the indices are compile time, the problem i have is putting this into a class. Maybe it isn't possible as you can't define a parameter to be constexpr which str_const would have to be, but the function would have to return a non const value; 
It seems more readable the way it was :D
&gt; so you are seriously saying that you are teaching students c++ without pointers? No, of course not. But simply seeing pointers and using them does not automatically give a deep understanding of them. Once upon a time, pointers were part of a package deal involving direct access to blocks of memory: arrays. These were awful, and most of us have happily left them behind for nicer abstractions. What I'm observing is that this is a bit unfortunate from a pedagogical point of view, because it means students have neither the incentive nor the opportunity to truly grapple with the idea of pointers and gain an intuitive understanding of how they really work.
And, as usual, funny talk with full of jokes. If only the audience did get them...
Yes, you got the right idea. IsPowerOf3 can be made constexpr too. But you do have a bug. IsPowerOf3(1) returns false. Less serious, IsPowerOf3(43046721) returns false. For the latter, you just need to extend your list to pow3to(20) to cover the range of unsigned int on most systems. &gt; they've asked me to present a few examples that make newer features introduced in c++ better to read or understand. You should include binary literals, initializer lists (especially useful when working with containers), lamda functions (especially when working with &lt;algorithm&gt;), and static_assert. I'd be tempted to also include std::unique_ptr and std::make_unique. When reference-counted pointers are needed, std::shared_ptr, std::weak_ptr, and std::make_shared are nice. Lastly, user-defined literals can be helpful if you are in the right discipline. (For physics, chemistry, and engineering, these can be very useful.)
The book is basically a tiny tutorial hardly worth mentioning, and then all of the printed out documentation.
We need more details. What will you be doing with this library?
Yes, but we still need to consider: (1) do we expect to teach linked lists to people who don't really *get* pointers yet? (2) When are students going to figure out pointer *arithmetic*?
&gt; But the results, as you note, are lousy. What does that mean? I learned programming in C++ using the method you described and I don't ever recall having a significant issue with it.
I do know what it is though, problem isn't efficiency, i don't want my code to compile if i misspell a string. The strings are constant, they are known entities, they HAVE to be in the program. I have to define them in the program or well it won't work really. I should have made that clearer. I just want to move the error from runtime to compile time. std::map&lt;std::string, int&gt; map = { { "arguments", magic_loaded_int } }; int value = map["ops"]; // runtime error, won't know about it til this code is run constexpr str_const arr[] = { "arguments" }; int values[1]; constexpr int index = Find(arr, "ops"); // compile time error int value = values[index]; 
I thought only integral types can be template parameters? template&lt;typename S = str_const&gt; int Get(S string) { } Is that what you mean? I'd have to give that a try i don't know if it'll work. But if this is what you meant, then i know for sure it doesn't work (at least for vs2015's compiler): template&lt;str_const string&gt; int Get() { }
Currently Result _Updated 1250 (GMT-5) January 08, 2016 http://imgur.com/dwWCrVl
It would be great if you could pull [this](https://github.com/facebook/wangle/pull/21) as I will write a blog post on using Wangle that uses this example.
I wonder if any compilers will optimize this into a binary search.
GNUmake is actually on the same level as CMake. That's the thing with CMake, it does not actually fundamentally go to a higher level of abstraction. CMake also does what autotools do, which Make expects you to do yourself, but that's not a giant thing to do. CMake uses Make as a backend because it is ubiquitous, and it basically uses it as a lobotomized version of what it actually is.
I wonder what the performance is of using Clang (Fairly heavy) to analyze the dependencies. I also wonder how you can do that without having a build system in place to call Clang already with the right dependencies - after all, if it does not know a header file, how does it know where to find it in the future? 
That's very true. Make is not a bad tool - it's held up immensely well compared to other tools from the same age. The problem with using a compiler to determine the include paths, is that the compiler requires the include paths to be foretold in order to know which header to pick. It can essentially tell you what it's using from what you give it, but it will not give you new information, just a selection of your inputs. That's not valueless, but there are cases where it won't work.
&gt; I don't think it's worth it to put 15 integers in memory to find out if something is power of 3 quicker. Wait... we are talking about 15*4 = 60 bytes here. I understand the concerned with KB or MB of memory, but 60 bytes? If you're this short, you're better off avoiding `&lt;iostream&gt;` than you are switching out the 15 integers, you'll squeeze more bytes out of the shortened code! Also, this method is much better than using `std::set` (I thought you were concerned about memory, a `std::set` is positively HUGE in comparison, with at least 15*32 bytes occupied on the heap, with the allocator overhead sprinkled on top) and occupies about as much memory as a plain array, except that the compiler is more likely to optimize the branching with the switch than with a binary search over an array.
*cough* I've done that - http://github.com/dascandy/bob - and nearly everybody is vitriolic. You either get people angry at the syntax, people claiming that Make is obsolete or people saying that it's at the wrong level of abstraction. It works well for nearly all projects I make myself and it fixes the shortcomings I find in make, but that doesn't guarantee it'll help you.
&gt; Performance it's actually one of the fastest tools there is - you'd be surprised how hard it can be to be any faster. I trust you have modern up to date benchmarks with hard data backing up this claim. Links welcome. On the other hand there are many benchmarks that show the exact opposite. As an example [Tup is orders of magnitude faster than Make](http://gittup.org/tup/make_vs_tup.html) and [Ninja is 10x faster on Chromium builds](http://neugierig.org/software/chromium/notes/2011/02/ninja.html).
That's saying as much about Make as it says about nearly every other build system I've seen so far. Heck, Ant surprises me regularly with: ... null: returned 132 when it actually means, I ran this command and it segfaulted. See hundreds of lines up which command it actually was. Make at least stops building when that happens &amp; doesn't output a vomit-sized list of debug info in regular builds.
Ninja doesn't solve the same problem - it solves the rear half of the problem that Make also solves, and it concidentally fits closely with Cmake in the same role that Make fulfills there. If you use half the tool there's overhead. Tup solves a similar problem with different starting assumptions. It's exactly what the creators also say - the problem with building fast is that you are only reactive, and you need to take everything through a full tree of dependencies, when actually you want the opposite direction only. Yes, having that information online is very useful and it allows you to spend less time on analyzing dependencies and whether a target is up to date or not, but it also implies that you're not in the same situation as Make typically is - a system that has only timestamps to find out what's up to date, and no prior info what has or hasn't changed. If you change the design choices, you can go faster. If you fit the same roles that Make does, you are very hard pressed to go any faster.
Qt has become a pluggable GUI: overlay/underlay or mixed with your 3D scene.
I just looked at the source to see what black magic libstdc++ find does. Just some manual unrolling. I wouldn't expect any difference at higher optimization levels.
As far as something like Boost, are they public headers, or used more privately? Can they be used by directory proximity? I would really like to find a mostly automated solution. When it fails, it could be possible to have the user have to override the location. I think the C++ modules proposal may help with private headers.
Here's a presentation given at a recent C++ conference by Kate Gregory, an Engineer at Microsoft: [_Stop Teaching C_](https://www.youtube.com/watch?v=YnWhqhNdYyk) The talk isn't actually suggesting that C shouldn't be taught; Instead the talk is talking purely about the way C++ is taught. The point of the talk is that the most effective way to teach C++ is not to teach C and then to pile some C++ on top as 'extra'. This talk might provide you insight as to the benefits of not teaching C++ as though it were a superset of C with only a few minor additions, and what exactly C++ could offer to introductory classes.
`std::set` isn't a literal type and can't be used in `constexpr` evaluation.
That Fastware page has a "contact Scott directly link", so just write him. Furthermore, there is a [Fastware project page](http://www.aristeia.com/Fastware/) with a [16-page introductory chapter](http://www.aristeia.com/Fastware/Fastware%20Introduction%202008-12-15.pdf) of a book draft. 
That's disappointing.
This is for the public headers only. I've also written a tool that can do exactly this dependency checking and it signals which headers it finds within a source tree that can collide, for every possible way of including it (other than non-canonical paths). On my test project, a large corporate project with around 1000 components (order of size), it finds around 2500 possible colliding paths. I've looked through the list and found quite a lot inside Boost's include folder, for example, there's a http://www.boost.org/doc/libs/1_42_0/boost/tuple/tuple.hpp and there's a http://www.boost.org/doc/libs/1_59_0/boost/tr1/tuple.hpp. If you ask for tuple.hpp, that's a collision. Same thing goes for many things in other libraries, especially if you do this automatically, which means you'll also find collisions in detail/ folders. Not to mention people abusing the systems underlying their development by not recognizing the trouble they cause, and actively introducing these kinds of collisions for their own local gain. I've also found a few cases (&lt;10) of those.
A couple of nits: You have some redundant flow control in `IsPowerOf3`. There is no need to `break` after a `return`, and there is no need for a `default` case when you already end with `return false;` I would also recommend adding something like: if(n &gt; pow3to(15)) { // whatever your largest pre-computed case is throw std::out_of_range("Input " + n + " too large"); } at the start of your function, to avoid returning potentially incorrect information.
A boost? yes. But huge performance boost? you'd have to run some benchmarks to check that. After all a cache miss is a factor too. However generally speaking - yes, you are right, lookup tables are great at speeding up things but like you said it's better to construct those at runtime or better yet - use constexpr to build it w/o listing a comma separated list of dozens of weird numbers. Personally i would start with a simple function that i can tweak and template-arize to suit my needs. And switch to lookup tables only if it's really necessary. Next time i should word things better.
Why do you even bother with the non-const overload if it's doing the same thing as the const one? A const member function can be invoked on a non-const instance, so everything works fine if you have just the const version. 
A real world usage example would be this: auto container_type::lower_bound(const string &amp;s) -&gt; iterator { auto it = const_cast&lt;const container_type *const&gt;(this)-&gt;lower_bound(s); return underlying_container.erase(it, it); // Some standard container of strings that container_type encapsulates. } auto container_type::lower_bound(const string &amp;s) const -&gt; const_iterator { return lower_bound(underlying_container.cbegin(), underlying_container.cend(), s); } *iterator* and *const_iterator* are aliases of *decltype(underlying_container)::iterator* and *decltype(underlying_container)::const_iterator*. (edit) Point being, the *const* version returns *const_iterator* and the non*const* version returns *iterator*. 
It is in Effective C++, but you have it a little wrong (imo, yours should technically work though). In your case (no retval) you can just use a static\_cast to cast to const (const\_cast is generally used just for casting _away_ const): static_cast&lt;const foo&amp;&gt;(*this).bar(); If you had return values to member references or something you'd use two casts because the const function would return const, e.g.: const int&amp; bar() const { return m_intMember; } // cast this to const to call const member function and then cast away const on the return. int&amp; bar() { return const_cast&lt;int&amp;&gt;(static_cast&lt;const foo&amp;&gt;(*this).bar()); } The example in Effective C++ is for operator[]: class TextBlock { public: ... const char&amp; operator[](std::size_t position) const // same as before { ... ... ... return text[position]; } char&amp; operator[](std::size_t position) // now just calls const op[] { return const_cast&lt;char&amp;&gt;( // cast away const on op[]'s return type; static_cast&lt;const TextBlock&amp;&gt;(*this) // add const to *this's type; [position] // call const version of op[] ); } ... }; As for what I think about the paradigm, I like it when it's needed. I prefer the casting ugliness to code duplication.
This is actually useful although it isn't obvious at first. You can't overload based on return value so having two different functions with the same name but different const-ness can be useful. Img img; img(x,y) = 1.f; NeedsAConstValue( img(x,y) ); Here you can overload operator() and operator() const to give an elegant interface.
&gt; return const_cast&lt;int&amp;&gt;(static_cast&lt;const foo&amp;&gt;(*this).bar()); That is fucking great. I hope I'll remember it. Also, could you please comment on my update featuring a new example? :)
A solution with static generation of lookup table could be expressed this way: constexpr std::size_t three_to_the_power(std::size_t power){ if(power == 0) return 1; return 3*three_to_the_power(power-1); } template&lt;std::size_t... I&gt; constexpr auto helper(std::index_sequence&lt;I...&gt;){ return std::array&lt;std::size_t,sizeof...(I)&gt;{{three_to_the_power(I)...}}; } template&lt;std::size_t N&gt; constexpr auto powers_of_three(){ return helper(std::make_index_sequence&lt;N&gt;{}); } static constexpr auto powers = powers_of_three&lt;41&gt;(); bool is_power_of_three(std::size_t n){ if(n == 1) return true; if(n%3 != 0) return false; return std::binary_search(powers.begin(),powers.end(),n); } Here array `powers` holds all 41 values of power of 3 within uint64_t limit. It is constructed at compile time. `is_power_of_three` filters out obvious results and proceeds to do a binary search after that. This *should* work faster than runtime solution.
It isn't redundant, but it isn't necessary: const foo* a = pFoo; // the memory we're pointing to can't change cosnt foo* const b = pFoo; // now the pointer can't change either Most of the time you want the first, and you can write it foo const\* if you want, it only matters which side of the \* the const is on.
Just so you see it, this was addressed [in another comment](https://www.reddit.com/r/cpp/comments/403ch2/what_do_you_think_about_this_paradigm/cyr5jk0).
There is a proposal for std::as_const(arg) for adding const
I said redundant but what I meant was pointless. Wrong word.
&gt; it would be mildly interesting to see what code is produced from a 1-dimensional table approach as opposed to the n-dimensional one. i'd wager it wont differ much performance wise, and conceptually i think the n-dimensional approach is nicer. If you're talking about the codegen, I would be surprised if they didn't produced the exact result. But I haven't tested this, so I can't be sure. &gt; ideally we'd do some sort of table[variant.index()]... expansion directly, but that might be a syntactic pipedream. Yeah, it would certainly remove the utility code if we could. Syntactically I'm not sure what would make sense, and again, it should produce the same code. But this is also to be tested. &gt; note: seq::product just multiplies all the integers in a sequence of integer types, while seq::dir_prod computes the cartesian product. my apologies, the code is not meant for people. I see, cool. Thanks!
The CMake book pays for itself within the first day.
I can't speak specifically for them, but I've found error codes to be less descriptive and more fragile to code base changes than using named flags. I always prefer using named flags over numerical codes.
Is this for the case of command line args and pragmas to ignore them? I have found that looking up some of the more obscure warnings/errors - specifically their descriptive name on the command line is very difficult. Often times there is a semantically similar but unrelated topic that google will rank higher. 
Using QML you can create a separate gl context with sharing enabled back to the default qt context. You can then render to a texture in that context in a separate thread, and then bind and display it in the main thread. It's an extra pain in the balls, to be sure, but it's possible.
From my reading of the clang source the developer would have to explicitly put that in the warning string. Its not enforced by anything in the compiler. In general I've found the C++ warnings to be straight forward but Objective-C tends to be a different story.
Naming things that are hard to google should be frowned upon by more people. Two or three character name? That's a paddlin'. Common word for a name? That's a paddlin'.
They just want you to be aware that your girlfriend might be a prostitute. Hah, who am I kidding? We're C++ programmers; we don't have girlfriends.
 Why should we use this if there are tools such as ninja and tup?
Where on UNIX have you seen people using and documenting lots of error codes? It's just unnatural.
&gt; they've asked me to present a few examples that make newer features introduced in c++ better to read or understand It's the rvalue references that make C++ better to read. You often can pass big objects around without performance penalties. Other thing are lambdas that help with the code locality. With tuples you can return multiple values from function without writing too much code. In the future cpp there'll be std::optional that allows to just return a value regardless of whether it's there or not (and then deal with it in the point of use). It's like exceptions that you control and can store for later.
Using QML you can render to the same context in the same render thread. You can choose when to do the synchronization with the UI thread. That sync involves changing some uniforms and possibly uploading some simple geometry just once, so it should be ok. Texture loading is usually centralized in such projects, so Qt code doesn't do the texture uploads for its GUI stuff. I'd say it's very usable for the game development.
Why not make `powers` constexpr as well?
CMake is quite a bit more powerful than make. It is a higher level tool. Take a look at the language, functions and modules available, and it's quite clear that make doesn't provide this. You could maybe implement it with make in terms of lots of extra external tools, but that would be a huge effort and would negate all the portability advantages to using cmake. CMake using a subset of the make features is not a problem. It doesn't need pattern rules or any of the more advanced features since it itself already did the equivalent of these expansions internally. And this means it can then output build files for even more bare-bones tools like Ninja, which are significantly faster than make as a result.
&gt; VS 2015 Update 2 Is there any info on the date for this ? a 3 second google search did not yield anything. thanks !
&gt; Just don't like to overcomplicate things. Ah! Indeed, if this is not a bottleneck, then it's not worth the switch and a simple one-liner is probably more readable and maintenable.
So, maybe one of the mods would like to delete this spam? It's been 13 hours now.
I'll keep in mind the points you presented. Thanks a lot. and 3^0 == 1 :D
What,what,what :O f(): movl $1, %eax ret g(): xorl %eax, %eax ret Just this :O Edit: Hmm recursion. constexpt supports recursion :/
I want to learn assembly, not much but just to read what's happening above :(
It was just an example while I was learning something new :D
Brilliant talk, as all of Andrei's are. One question: Andrei says comparisons are cheap (in general of course, not always), and he shows this example where branching and comparing 4 times is cheaper than just the bare loop. I can see how this is true because integer division is just so expensive. However, ten years ago or so, it was general knowledge that branching (`if`'s) was about the most expensive and worst you could do, because of misprediction and flushing of the whole instruction pipeline (and possible other reasons). Is that not true anymore? Have current CPU architectures, branch prediction etc. gotten so much better, that `if`'s are not considered that detrimental anymore, even in inner loops?
&gt; you'd better use sorted `std::array` instead of `std::set`. Probably; but your reasoning: &gt; Things like std::lower_bound[2] and std::binary_search[3] have logarithmic time complexity and can find the value faster than linear search. is incorrect. Oh, those statements are true, but `std::set` stores its elements in sorted order and uses a binary search to find elements too, so on a gross `O()` level, the two solutions are the same. The reason to use `std::array` is that it's marginally cheaper to access elements than an `std::set`, not that access has a different time complexity, because it doesn't. 
That is a really nice optimization. It reduces the code size to a constant, gets rid of most branches, and should almost always be a good strength reduction. I normally wouldn't have expected to see a compiler do that. It looks LLVM can do the same with `if..else` chains too. bool IsConsonant(uint8_t c) { return !((c == 'a' || c == 'A') || (c == 'e' || c == 'E') || (c == 'i' || c == 'I') || (c == 'o' || c == 'O') || (c == 'u' || c == 'U')); } compiles into... _Z11IsConsonanth: # @_Z11IsConsonanth .cfi_startproc # BB#0: addb $-65, %dil movzbl %dil, %eax cmpl $52, %eax ja .LBB0_2 # BB#1: # %switch.lookup movabsq $4432058356055790, %rax # imm = 0xFBEEEFFEFBEEE movb %dil, %cl shrq %cl, %rax andl $1, %eax retq .LBB0_2: movb $1, %al retq I think this hints that `if..else` chains can probably also be optimized into `jmp %eax`, a jump table, or a lookup table.
CLang is heavy, but it is also correct in the case of complex macros. There could be something lighter, but I was already using CLang to generate analysis data. My other idea now is that the editor already has CLang loaded, so it could write the dependencies in some cases. The other strange trick I am using is that I scan the project first for include files, then pass in a lot of -I defines. I don't know if there is a fast way to use CLang to generate the AST with missing include paths. It may work for parsing the #defines in the code without having the paths set up, but I haven't tried it yet. I don't have a perfect solution yet.
&gt; As you know constexpr is evaluated at compile time so constexpr wouldn't work if the input is evaluated at runtime. This sentence seems potentially misleading. To clarify, constexpr means that the function or value is usable in constant expressions, not that it is exclusively usable in constant expressions. It will still work in non-constant expressions. In that case, it will be calculated at runtime, but it won't fail to compile or calculate the wrong answer or anything like that.
It hasn't been publicly announced yet.
I'm surprised there is no mention of embedding a scripting language interpreter. If the plugin isn't exposing a performance critical portion of your application, exposing internal functionality via Python or something similar (Lua is common for games) seems like a much more accessible solution for non-programmer users.
I feel like the article over complicates things quite a bit. A few simple techniques can take you pretty far, like using POD structs and null termination. plugin.h extern "C" { using Run_t = void(*)(); struct Plug { Run_t* theFunction; }; using GetPlugs_t = Plug*(*)(); } specific_plugin.cpp extern "C" { void DoSomething() { ...; } static Plug thisFilesPlugins[] = { { DoSomething }, { nullptr } }; __declspec(dllexport) Plug* GetPlugs() { return thisFilesPlugins; } } I probably forgot something, but the general idea is that you make a struct that you return and iterate like a C string, finding all the structs until the _function_ in this case is nullptr (not the struct itself!).
Wouldn't that limit plugins to be written only with the C++ compiler that the program was compiled with? Also the function comes from the fact that some cross platform shared library libraries only grab symbols for functions and not static variables.
Holy cheese I've been wishing for a SimAnt remake for over a decade. How can I help? I'm not the best with C++, especially with graphics, but I'd be happy to help with anything else. Finite state AI? Graphics? Terrain generation? Efficiently drawing graphics with C++ is pretty much the only thing I cannot do.
Right, but this cpp file would compile to a .dll that would be loaded dynamically, how would you extract the vector of std::functions from it?
My friends are istream and ostream.
This would be more appropriate in /r/cpp_questions. 
My friends don't even delete. 
&gt; Go manages it and works just fine. I think I've told this story here before, but the first time I heard Pike's arguments against generics in go and how you can just "do it yourself" I had spent about a day and half tracking down some weird bugs that were showing up because some predecessor of mine had decided to write their own stack class and flubbed the implementation instead of just using a std::stack. 
You can't use STL in a plugin API unless you mandate that plugins are compiled with the same compiler as the host application. Even then, a newer version of the same compiler might break STL ABI compatibility. 
Sure\*, but consolidate it to as few places as possible (ideally one, or even zero\*), and especially don't do it in every single function. This makes testing and maintenance a nightmare. Read about functional purity, and try to adhere to it as much as possible. Here's a good article on the topic by a rather famous ASM/C programmer: [Functional programming in C++](http://gamasutra.com/view/news/169296/Indepth_Functional_programming_in_C.php). And take note that he's a famous **_ASM/C_** programmer, which are not languages you typically think of when thinking about functional concepts. Good design applies to any language. \*Mutation is never technically necessary, and in some languages is highly discouraged or even prohibited, but it is idiomatic in C++, so we'll allow it here. ;-]
Thanks for linking this! Seems really interesting. I might test this out on some edge traversal I'm doing for a tokenizer assignment.
An improvement indeed! Further notes from a glance: - Strongly consider changing `find_opening` and `find_closing` to take a `environment const&amp;` argument and return a meaningful value that `interpret` can use to manage `env`. - Change `instruction_pointer` to be a `const_iterator` since you're only reading from `ip`. - Avoid using `std::exit` as it prevents stack unwinding; consider throwing an exception that can be caught higher up (likely in `main`) and terminate more gracefully. - `case ','` is reading from the wrong stream. - Get in the habit of using prefix-increment/decrement rather than postfix; ignoring any performance implications, they have different semantics, and if you're not capturing the result of the increment/decrement then prefix is the more _correct_ semantic. - Your current design explodes if `mp` is incremented 30000+ times. At the least, handle this gracefully, but better yet, add a bit of abstraction so you're not doing the moral equivalent of pointer access/arithmetic at the core of your interpreter – this is C++, not C. The obvious approach would be to make `ip` and `mp` private, and add member functions to `environment` to access them that handle range violations, expanding the size of `mem`, etc. That said, /u/F-J-W is quite right that this isn't the correct subreddit to pursue this conversation any further.
Nice article..but show me the performance numbers or it's useless..
It's not the error codes of the CLI commands.
They were very inspired by Netty. That would actually be a good benchmark to compare against Netty so I think I will do this.
This [one](https://github.com/scylladb/seastar)? No but it looks very interesting so will definitely check it out. Thanks for the heads-up.
I don't think such trivial example will mean anything to benchmark. Maybe make another less trivial example and write another article about benchmarking it?
Does this run on Windows? Couldn't find anything in Wangle.
Yes that one. From what I understand, it has a better HPC pedigree than Wangle. 
No Windows then.
I really don't like DOSbox, the VM runs better.
The assumptions about working in C++ often seem to be that you spend all your time writing everything from scratch, and that the code is 75% templates. This article is a nice counterpoint. (The lack of numbers didn't really bother me but it is a valid complaint.) As for things looking like Java - the proof of the pudding is in the eating. Most people seem to find this sort of approach very easy to use: it's clear what the designer was thinking, it's clear how to use it, and it's no more or less inconvenient to debug than any callback-type approach. If you've got a good handle on the use cases, e.g., by having written such a library previously, it's also pretty easy to create.
Perhaps you'll find this of some help: http://tinyurl.com/x86-64-assembly Personally, I'm partial to "Practical x64 Assembly and C++ Tutorials", because it also covers modern 64-bit assembly (including SSE and AVX--relevant, as checking whether your code has vectorized nicely is one of the reasons assembly can be useful): https://youtube.com/playlist?list=PL0C5C980A28FEE68D Slides: http://www.whatsacreel.net76.net/asmtutes.html For the same reasons, in case you're looking for a book, I'd go with "Modern X86 Assembly Language Programming: 32-bit, 64-bit, SSE, and AVX": https://www.apress.com/9781484200650 "x86 Assembly Primer for C Programmers" slides are also pretty nice for a quick overview: https://speakerdeck.com/vsergeev/x86-assembly-primer-for-c-programmers https://github.com/vsergeev/apfcp
I doubt XP can run SimAnt. Also I still didn't see any contributions to the project other than mine...
Review class/object concepts and ask again in /r/cpp_questions ;)
Do you know how wangle compares to proxygen? It looks similar enough that I'm surprised that FB did both.
As CMake is now a de facto standard cross-platform build system for C++, a de facto package manager is the logical next step. Hunter seems to be a great candidate AFAICT.
"This video is unlisted. Only those with a link can see it" - Everyone on the internet.
That would not be a good thing. Gradle for C++ is a better request (and, hey, they're working on it)
&gt; No emerge, apt-get, brew etc. needed before build, now it's simply cmake --build how does this work on CI instances with limited time ? (e.g. travis CI with 40 minutes, if your project depends on Qt or some other big library you wouldn't even be able to go past the "dependency building" stage).
Generally CLI programs return a value from main which serves a similar purpose. Although normally its only processed as a pass/fail.
have a look at other's brainfuck interpreters to get a better picture of how to organise the code. it seems you are new to OO programming but keep going at it and you will master it
I think I'm starting to actually enjoy the ridiculous too-lazy-to-google-or-read student questions that land here.
Uhh, anyone else click the google url on the github description only to be bought to some really wierd music video?
Check this CMake wrapper: http://floooh.github.io/fips/index.html
Feel free to browse the `c++` tag at SO. Or even worse, the MSDN VC++ forums. \*shudder\*
Who said anything about OOP?
The readme doesn’t offer any clue regarding the internal workings. How’s it compare to other language specific package managers? What solver does it use for dependency resolution and can it be exchanged for a different one? Does it interfere with system packaging? How does it relate to / interact with standard tools like pkgconfig? 
Why not? And please don't say because of the XML. From what I've seen so far using a scripting language for build configuration is not as great as it sounds because developers immediately jump at the opportunity and implement unmaintainable shit instead of thinking in terms of standardization.
And have you never gotten compiler errors? And how often did you get just a _single_ compiler error rather than a multitude? This subreddit, and my comment, are not confrontational, except to prompt one to use their mind before posting. C++ is not a language for mindlessness or inattentiveness. ;-]
Errors. From the compiler. Compiler errors. Diagnostics from the compiler that prevent your code from compiling. Do you know what compiler _warnings_ are? Think those, but errors. I don't know what you think you're talking about, but it surely is not the same thing as the rest of us.
This thread is about error codes used within UNIX. The OP of the comment thread saying they are uncommon. Errno being one example, the return value from a CLI program being another. Anyways I don't see the point in continuing this conversation since its clear you don't intend to be reasonable.
&gt; Traditionally I've been tied to the MSVC toolchain and grew to like their error codes. GCC and Clang do not use error codes preferring instead to use names (i.e. -Wreorder). A small subset of warnings do not even have a usable flag to control them. What part of this says **anything** about UNIX error codes? `-Wreorder` is a compiler flag controlling _compiler diagnostics_. What thread are you reading??
Me neither. I am yet to see any Gradle build outperform Maven. If it wasn't for Android Studio, I would never care for Gradle. 
I have not seen the talk (yet), but in general: predictor effectiveness has significantly improved; and in some cases the compiler can generate conditional move instructions instead of branch instructions (so no real branches despite `if` statements). The worst was Pentium 4: very long pipeline but not very effective predictor yet.
This song is great, it's Bjork. Song called Hunter, that's why this project called Hunter.
Hunter creates a local binary cache, if hunter has already built the dependency with the same compiler and flags it will use the version in the cache. At work we spin up a new docker container for each build and share the hunter cache directory on the host between them. As a result we only build each dependency the first time it is used in any build.
Versus JSON : Complexity (YANGNI like attributes) and verbosity (starting/closing node - weird character ( &gt; &lt; ) everywhere..etc). I agree this is not atrocious, but if I can avoid it, why not ?
would it be possible to build the dependencies pre-built on some machine, and upload them somewhere once built so that hunter is able to fetch them ??
It's too damn expensive IMHO.
...XP can definitely run SimAnt, just as well as Win95. DOSbox probably won't even work for my version of SimAnt because starting it from DOS just tells me to run it from Windows. What are you talking about? I work two jobs and haven't had a chance to sit down and dig through your project. Sorry I haven't contributed anything yet but as much as I'd like an updated SimAnt I'm not being paid for it so my jobs come first.
CMake makes me cry every time. I'm with the hype, so naturally, I want to make it happen, I try it every time. I'm waiting for the joy of CMake to somehow flow through me, but IT'S JUST A FUCKING ABOMINATION.txt. Nothing works, nothing happens, not even message, it never finds anything, what's this MACRO HELL!? How do I define something? What's with these weird functions with string arguments? Why are we loving Bash again? WHAT THE FUC!K What's wrong with maintaining a Makefile? Oh, you want cross platform? Then just use MinGW. (Or use VS and send patches. If you have budget for a Windows-based environment just go with the JVM, run multiple instances and put a load balancer in front of them.) Herp derp. So, hunter's CMake files are beautiful compared to those I've seen, I might give it a try!
Not every distro has a package manager (Windows), package managers might not be the best common denominator, because maybe there's something you cant implement with all of them (so you're back for custom scripts for that distro too). apt-get update &amp;&amp; apt-get install is much slower than a pip install. Providing hosting for every kind of distribution specific repository might be a bit extreme, and uploading to every kind of repository might be a bit extreme too. And waiting for distributions to package your latest header file might be a bit too optimistic also.
Use CLion... it maintains the CMakeLists.txt file for you
User? Developers use these package managers.
&gt; These are useful extensions but did you ever consider contributing any of these changes as patches? For some features you implemented there exist feature requests (e.g. pseudo inverse[1] ). Yes. The discussion of these (e.g. pseudoinverse) is exactly what made me *not* do that. After that bug (bug 257) has been around for 6 years, why is pinv still not in Eigen? If you do a Google search you find tons of people asking how to do it. In the Wiki they give source code for you to copy and paste into their package for the highly requested feature... So why is it still not in? I suspect my adding one voice the the crowd asking for it won't help. This page is meant to be a little stronger way of saying "Hey devs, really, put these obvious features in." Take sorting as another example. It's one line to sort in ascending order, and there are questions online about how to sort an Eigen::VectorXd in descending order. If people are asking how to do it, you should probably just include it in the library. I can't image that lack of a sorting function is because nobody has suggested it or because they find it too challenging. It's because, right now, they don't want to put it in. &gt; &gt; &gt; &gt; Another general remark is that almost every function you offered could be implemented as a free function. This would increase the chances of people using your extensions since they would just need to add another include directory vs. being forced to replace the entire library. I'm torn on this topic. I agree with you, but that wouldn't place pressure on the devs to actually integrate these features. My goal is about 10% to give people these features and 50% that I want the devs to properly implement these features so that I don't have to think about them anymore, and 40% that this motivates me to keep my Eigen code up to date and clean (I use this). &gt; &gt; &gt; &gt; I like the assignment operator (which actually needs to be a part of Eigen) and for the input operator[2] there exists a lengthy discussion on the bug tracker. Heh, I actually didn't google that one recently. I was annoyed a long time ago that it didn't exist and copied in my solution from back then. I should read up on it (and maybe they have a better implementation). &gt; &gt; &gt; &gt; Again, please try to submit your changes as patches. The Eigen devs are open to and happy about any kind of help. You can contact them on the mailing list or on the IRC channel (freenet, #eigen) for quick feedback. Well, I'll try, but I'm not hopeful, for the reasons discussed earlier. Thanks for the feedback! 
Ah, yeah I'll expose the epsilon. Thanks! Cigarette, joint... I didn't think it through that far.
Don't get me wrong, the problem still present, just less significant nowadays. If you'd like to hear about that, Chandler Carruth talked about it at CppCon 2015: https://www.youtube.com/watch?v=nXaxk27zwlk (that part starts at ~55:00) Update: Found interesting discussion here: https://gcc.gnu.org/bugzilla/show_bug.cgi?id=56309 Summary (as I got it): Optimization of branches is not that simple. Conditional move may be even slower on modern CPU's than branches. See also this comment https://gcc.gnu.org/bugzilla/show_bug.cgi?id=54073#c16
&gt; I find this very strange. I use Eigen all the time, it's unlikely I'm going to use this "replacement." Consider contributing these patches back to the Eigen project. See my comment to craven76. It explains why I didn't do this. In short, these "contributions" are tiny and incredibly simple. Their absence means that the devs don't want these features in Eigen. &gt; The Eigen library provides a vector class that does not have the ability to sort. I think that warrants its avatar being mocked a bit. &gt; &gt; &gt; The author here is really giving off vibes of being a jackass. Sorry it came off that way. That FAQ was intended to say *cough* fair use *cough*. &gt; The name of the project, Is a pun... It made me giggle a little and it's memorable. &gt; the tone that Eigen is somehow "stupid" because it didn't fulfill all of the authors' use cases right out of the box... Eigen isn't stupid. If it was stupid I wouldn't be using it. The problem is that it's too not-stupid. It's not nice to beginners. It doesn't provide us low-folk with the simple tools that we want. It makes us put in time to learn about the various linear solvers and which one to use, rather than just giving us a linsolve (or division operator) like Matlab. &gt; It reminds me of some young developers I work with who always think everyone else is stupid (when the truth is they jumped to a convenient conclusion without understanding the constraints/goals/requirements of another individual/project). I *think* that I do understand the constraints/goals/requirements that cause these basic features to not be in Eigen, and I *think* that it has nothing to do with the difficulty of adding the features. I also *know* that these are features that I want and use.
Thanks for the advice - I'll look into doing this. I had it on my TODO list to just list all of the code changes on the website, since there are so few. Perhaps I'll do both.
&gt; http://www.slideshare.net/DanielPfeifer1/cmake-48475415 thanks, I've been looking for a good summary
System/distribution package managers will never be sufficient as an answer unless you're willing to take on the burden of making your software compatible with each particular set of packages for each system you want to support. If you have even a few dependencies on libraries, that very quickly becomes an impossible task. It's much easier to build/distribute your dependencies (all at a particular version) than to hack your code to pieces supporting multiple combinations of API versions/levels of bug-fix support/etc. 
Because you probably learned it properly. I on the other hand just furiously googled for cmake link target blabla. And then got disappointed by their (lack of) documentation pretty fast. And my compliant is that it's not obvious, it lacks structure, it has funky macros (functions?) all over the place and magic keywords. It's not even clear if it's declarative or not. (I guess it's not, after looking at the tutorial.) It feels like a big sidestep compared to Gradle or all the fancy tools the NodeJS community barfed up :)
Take a look at its new subreddit! :)
Having worked as a compiler engineer on both a compiler that used specific error codes, and now clang, I've come to much prefer the named warning approach. If I'm looking at a command line/Makefile/CMakelists.txt/whatever I can see immediately what's happening if I see: -Wno-unused-parameter as opposed to: /wd4100 Similarly, this is immediately more readable to me: #pragma clang diagnostic ignored "-Wunused-parameter" than: #pragma warning(disable: 4100) Obviously in the pragma case I can explain with a comment, but I'd rather not have to and just use the comment to explain why I've decided to suppress a warning rather than what the pragma is actually doing. In clang, the set of warnings that don't have a usable flag is very small, and generally are just warnings that were implemented before all of the command line flag plumbing was in place and haven't yet been updated to use the new plumbing. I vaguely seem to recall that there was a regression test in place to ensure that the set would never grow.
Sorry for the slow response, I don't keep close track of reddit. It sounds like you're assuming Cap'n Proto does lazy deserialization, but this is not the case. Deserialization is fundamentally a translation from one format (the wire format) to another (the in-memory format). Cap'n Proto really does avoid the whole thing by using the same format for both. Deserialization in the Cap'n Proto case is basically casting a pointer. With that said, this benchmark is fundamentally flawed in that it tries to measure just parsing/serialization time in a loop rather than measuring a realistic end-to-end system. Benchmarks like this are 100% worthless, and adding Cap'n Proto to the benchmark was intended mainly to illustrate this fact through the absurd result. Even for comparing traditional one-copy (rather than zero-copy) serializers, running the serializer or parser in a loop is flawed for a number of reasons. One is that the behavior of various caches in the hardware in this scenario is completely unrealistic, because you're repeatedly operating on the same data. In the real world, performance will be very different, and different serialization systems will be affected to different degrees by this. Another problem is that performance of different serializers is wildly different depending on the data structure being encoded. Some do better at numbers, some do better at strings, some do better with lots of structure, some do better with flat messages, etc. You really need to benchmark the data you actually plan to use to get meaningful numbers, and you need to measure end-to-end, not just the serializer in a loop.
&gt; I apologize in advance if you find this comment a bit rude, but this had to be said. Since the target of your comment seems to be the blog/library's author you might want to post your feedback on his blog post instead of hoping he's a redditer and happens to see this...
https://github.com/ruslo/hunter/issues/75
&gt; The readme doesn’t offer any clue regarding the internal workings Because it's readme, not internal module reference :) &gt; How’s it compare to other language specific package managers? It confirms principle "do not mix package managers". If you want to use Hunter all projects that have dependencies should use Hunter. If you want to disable it and use system libs you can set HUNTER_ENABLED=OFF: https://github.com/ruslo/hunter/wiki/usr.variables#hunter_enabled Here is simple example of conflict when you violate this rule: https://github.com/ruslo/hunter/wiki/usr.adding.new.package.with.dependencies &gt; What solver does it use for dependency resolution and can it be exchanged for a different one? What you mean by solver? There is command `hunter_add_package(Foo)` - if this command called then package depends on Foo. That's all. &gt; Does it interfere with system packaging? It doesn't make sense. In terms of Hunter all of them have only one `toolchain-id` and one `confid-id` so there is no way to generalize such approach. Also different system package managers may have different versions of packages. I.e. brew install Boost 1.59 and apt-get install Boost 1.58. I think it's not something user expects from cross-platform package manager. Hunter install same version for all platforms. &gt; How does it relate to / interact with standard tools like pkgconfig? There is no interaction in general. The reason is simple - pkgconfig is not cross-platform (e.g. it doesn't work on Windows). And even on platforms where it can be used not all packages do use it in fact. CMake do same job in cross-platform fashion.
&gt; How does this compare to nuget in VS? I don't think nuget is friendly to CMake, hence there is no interactions with Hunter by design is possible.
I love Premake! The only bummer is that the new Xcode generator for the latest premake5 build isn't working too well at the moment :(
My comment is equally for the author and for other C++ programmers not to be fooled. But I posted a link to my comment on his blog, thanks for the suggestion.
I really really want to understand some of the outrageous complexities that metaprogramming offers, and this video has plenty to astound, but these programmers and the entire paradigm seems like it's on a completely different level from me. Are there any resources out there that are decisively "good" coverage for these topics? I really want to step my game up!
I can predict that nuget will be easier to use for very beginners. But if you goal is to build cross-platform product that is not limited only for Windows then CMake is your choice hence Hunter is the best way to manage dependencies. I have used nuget very little since it's not CMake friendly but I can predict that it's limited only for one toolchain and there is no way to specify build options for packages, in terms of Hunter it's limited only for one toolchain-id and config-id. May be some developer with more nuget experience will show more deep comparison.
[removed]
Naturally. As they haven't been spoiled by better tools, plus they start with the tutorial, and (hopefully) they ask seniors, who in turn can help them. 
[removed]
Learn a proper functional language; Haskell was mine, though in the long-run I prefer OCaml. Afterwards, TMP seems quite obvious – tedious, if anything, if you don't enjoy FP and C++ optimization, but certainly not difficult.
Thank you. That helps me understand a bit. I'm a little overwhelmed with c++ at the moment specifically because of these kinds of tools. Maybe that'll get easier in time though.
Yep. Everything he says is pretty much right on, and many of those things are common annoyances that C++ developers deal with every day. Even with all its faults though, it's still one of the best languages for accomplishing pretty much anything you ever want a program to do with significantly better performance that almost any other language. I often wish for 'roughly C++, minus all the warts' type language. It feels like D is actually on the right track, but I haven't brought myself to take a serious look at it yet.
Indeed, there is an opening in the market for a c++ replacement that uses all its good bits with none of the bad bits, but it is no coincidence that it does not exist yet. It would probably be too expensive to create in terms of effort, tooling, conpiler toolchain etc For me D does not cut it, it has its own major issues. 
Half of these are simply pulled out of the ass without actually knowing why things are the way they are or making a big deal out of things which happen very rarely.
I like C++ (minus the C parts) but aren't these enough alternatives for many uses cases? Eiffel, Ada, Spark, Chapel, Modula-3, D, Rust, OCaml, Haskell, Java (commercial JDKs do have AOT), .NET Native, Go, Scheme, Lisp, Dylan, Ruby (RubyMotion), Crystal, Nim, Oberon, Delphi
To be fair, some of these issues are because C++ didn't instantly appear in the form we see today*. It has a very long history. Features were added and improved over time, back when resources were much scarcer. Should every single one of these dumb issues have been fixed in C++11 (if not before)? Hell yes. So there's no excuse anymore, and "we did the best we could at the time" isn't a very good one to begin with. \* Eg., `class` was originally used in templates because the `typename` keyword [hadn't been added yet](http://stackoverflow.com/a/213135); `this` is a pointer because back [when it was introduced](http://www.stroustrup.com/bs_faq2.html#this), C++ didn't have references yet.
Lambdas are *objects*, not function declaration/definitions, putting them in headers is not wise most of time. Lambdas cannot violate ODR as every instantiation of a lambda is an instantiation of an object of a different type. If you want an inline function shared by mutltiple TUs, write an inline function. If you want an anonymous function object that can hold state, write a lambda. If you want both, write a functor.
It's already asked on [stackoverflow](http://stackoverflow.com/questions/34717823/does-using-lambda-in-header-file-violate-odr), but I don't (want to) believe the selected answer.
Gotta take the good with the bad I guess.
&gt;The type of "asdf" is char const[4] should be &gt;The type of "asdf" is char const[5] I guess this simple mistake kinda proves the exact point given in the **Truth** section. 
Fantastic way of taking an objective view of the complaints in the article. My own knee-jerk reaction was to to say, I know it, I love it and don't abstract me any more from bare metal. I want to put what I want where I want it, and I am completely fine with taking responsibility for my own actions.
I love C++ to death, but pretty much all of these points are true. From a language design perspective, there are a lot of "hindsight is 20/20" issues with C++ that were addressed with varying degrees of success in subsequent OOP languages. There are quite a few things that continue to grind my gears on a daily basis. The stream insertion operator was a bad idea, but the stream extraction operator was even worse. I remember being so confused by this when learning how to program - why can't I do *cin &gt;&gt; int x;*? The scope resolution operator is absolutely hideous, and clutters *everything*. Although I love the control we have with copies vs. all the forms of indirection, it is annoying to think about the consequences of copy constructors in nearly every line of code you write. I respect the ambition and power of const in C++, but sometimes it just really makes me sad. Const correctness is not an easy thing for all programmers to understand. I think that const is often overkill, when getters, setters, access specifiers, and designed immutability serve the same purpose. Const is, in my opinion, *abused* when a single class tries to weave two different implementations together for const/non const. "Sometimes this does this, sometimes it does that, depending on this, that, or the other" is not a very promising class description. Sure, you get compiler optimizations with const, but sometimes clean code is more important. Regardless, I use const religiously in my code. I think that function parameters have too much power by default. I don't like to call a function without knowing whether I'm giving a reference, const reference, or copy. I like C#'s contractual approach to reference passing, where a compiler error occurs if you don't acknowledge that you are passing a reference using the ref keyword. RTTI was a bad step in a weird direction. C++s absolute bitch of a grammar is compounded by hilariously poweful templates and further compounded by a hilariously powerful preprocessor, which has caused our static analysis tooling to fall drastically behind the rest of the programming world in some regards. Think about what would go into a renaming tool - how the hell are you going to rename a class member if the type has been passed into the black hole of a template? There might be a libclang tool for that, I don't know, but I don't currently use any renaming tools in C++ and it makes me very sad, even though I love templates.
Haha, yeah :) That's why I never count chars anymore, I either use a std::string or a string_view class.