surely one possible reason for this is interprocess synchronization...? maybe op didn't mean to do that, but it would make sense
There are proposals for pattern matching and better language support for monads, but I would expect these (they are pretty significant language additions) to be in 2023/2026 scope.
Requiring embedded platforms to stick only to freestanding subset of stdlib is far too restrictive in many cases. Just because you don't want megabytes or even hundreds of kilobytes of extra code doesn't mean you don't have use for, say, std::complex or indeed normal ASCII string handling.
I see what I can do!
It wasn't hard to find some discord channel announcement for this on codeforces (and if I remember correctly there were also several others announced in blogs from time to time): [http://codeforces.com/blog/entry/52778](http://codeforces.com/blog/entry/52778) As for subreddit - it seems like there isn't very alive one ([https://www.reddit.com/r/pcontests/](https://www.reddit.com/r/pcontests/) is the one I found). Maybe codeforces blogs etc. are considered good enough for this.
 const int&amp; ref = *((int*) nullptr); Undefined behaviour but still legal C++.
kkk! At each comment one hacky piece of code is fixed. Thanks!
Interestingly it goes against the recent committee decisions that out-of-memory error should just terminate which occurred while discussing [P0709](https://wg21.link/P0709): « The 2018-06 Rapperswil LEWG session supported adding `try_`versions of functions that could allocate memory: 16-13-1-1-0 (SF-F-N-WA-SA), and unanimously supported the direction of changing `bad_alloc` to terminate by default: 20-11-0-0-0 (SF-F-N-WA-SA). » If haven't followed the recent evolutions, but as far as I know the idea was also that contracts should terminate upon failure becausethey are logical errors and thus unrocoverable.
I think the API is still suboptimal in that it imposes requirements on the use of the enum (for example a count-member that introduces a new cases that you would have to deal with in switch-statements). [Here is my take](https://gist.github.com/Florianjw/9d0da283feeda4a84a4281e61e6fb486) on it which doesn't have the limitation.
To my mind, interfacing with C does not require calling non-placement-new yourself.
thx a lot
&gt; It is important to be precise or the language police will pull over. What, they'd pull over and let you get away? ;)
It’s important to be precise to avoid ambiguity and confusion. 
We could ask him. Hi u/berium
The form to obtain a trial key for PVS-Studio is broken
Any plans on also adding an \`unordered\_set\`? In my codebase, I have some typedefs that I use to swap in better hash map/set implementations as they come up, so it'd be awesome if there were both!
talk about c++ porn
No reason for all of that other that I didn't need it yet...
It does frequently mean having to manually allocate data and / or getting pointers to (preallocated) data passed to you. And sometimes the most convenient representation of a pointer is just a pointer, not pointer wrapped in some container for the sake of wrapping (or for sake of "being idiomatic").
The thought that some software might be able to sensibly recover from some allocation failures gets me hardcore triggered.
I think it's relevant. Game development is incredibly complex. You have a very ill-defined problem that requires fast iteration, real time deadlines, multiple physics simulations, interfacing with peripheral hardware, et al. It's a prime use case for C++ and provides an interesting assortment of problems at a language level.
SG14 was a mistake, tbh.
Are people using Conan? I'd like to use it but from what I see, too few developers care about it that it is just a burden to use.
Really impressive project! It slipped under my radar when I was looking for a similar Python Icecream lib on C++. The scope of CleanType broader that the one of IceCream-Cpp. The `CT_show_details()` macro alone has almost all of IceCream functionalities. I think that the minimalist approach of IceCream to be a small header file depending only on STL, has a value. It's easy copy that one file to anywhere, fix a bug and remove it after. However, optionally using the CleanType if it is present on system to improve the debugging information could be a good addition! A simple overload of `operator&lt;&lt;(ostream&amp;)` to containers is on my TODO list!
How does timer position prevent measuring remove? Are you saying remove for some reason is so super fast it's hard to measure?
Would you be able to give some examples on how to use it? I tried some simple examples, but i didn't get it compiling: &amp;#x200B; [https://godbolt.org/z/JhJzp3](https://godbolt.org/z/JhJzp3)
That's what `std::inplace_merge`, `std::stable_sort` and `std::stable_partition` do though: they try to allocate memory to perform a fast operation, and if they can't they fallback to an in-place algorithm which does the job slower but not at the cost of an insane complexity: for example `std::stable_sort` runs in O(n log n) if enough memory is available, and O(n log² n) otherwise, which is slower but shouldn't be slow enough to be considered an issue.
If the build system is in charge of mapping modules to files, then it is the most natural and reliable to give the compiler the direct mapping rather than relying on things like convention, search paths, etc.
If youre having the library allocate its own heap memory, youre not calling new yourself. Now, the pointer that you get back should in theory be wrapped in a unique_ptr with a custom deleter that calls the cleanup function, but thats not part of my claim and i know ive been lazy enough to not do that. If you have to allocate an object for the library to work on, place it on the stack, if at all sensible. If it needs to go on the heap, it should be wrapped in a smart pointer, probably unique_ptr. This is not wrapping pointers for the sake of wrapping them, but to get basic assurances that youre managing your resources correctly. So yeah, if youre trying to write modern C++ and you write your own pair of new-delete, you kind of missed one of the most important points of it.
You probably never used DOS. This was a mandatory part of every \*good\* software at that time.
Try to put your code into a function :) https://godbolt.org/z/QwSQYw
So, what is this?
oh my god.. i blame it on the end of the day!!
Removed. You should ask them to post in the jobs thread.
Competitive programming is sometimes discussed on [https://www.reddit.com/r/cscareerquestions](https://www.reddit.com/r/cscareerquestions), [https://www.reddit.com/r/programming](https://www.reddit.com/r/programming), and [https://www.reddit.com/r/learnprogramming/](https://www.reddit.com/r/learnprogramming/). There's also [https://www.reddit.com/r/CodingContests/](https://www.reddit.com/r/CodingContests/), but it isn't very active. &amp;#x200B; More useful than any of those: [https://www.quora.com/topic/Competitive-Programming](https://www.quora.com/topic/Competitive-Programming). &amp;#x200B;
I just gave it a try. Unfortunately I get a compile error for my bigdata test (I've reported it [here](https://github.com/Tessil/robin-map/issues/10)). Other than that, tessil's map is extraordinarily fast! Most benchmarks (insert, find) are about 20% faster than my map but use about 2.7 times as much memory. Iteration seems to be about 3 times faster with my map. I'll update the benchmark results when I have the time.
How is vulkan integrated in Magnum?? Do you use the vulkan headers and normal vulkan code, or there is some kind of wrapper as the one for OGL?
I'll try the dark mode. My eyes are less tired with this mode
So if I try to open an image in Photoshop that is too big for my memory you prefer a crash to an error message?
will do!
It's a work in progress at the moment :) There's function pointer loading, interfaces to math APIs and pixel format conversion etc. for asset import, so one can use Magnum with raw Vulkan code (or `vulkan.hpp` and others). Shader compiler infrastructure, wrappers for instances, devices, pipelines ... are being worked on in a branch, and will be introduced piece by piece to `master`.
It's good to *not* have a full scripting language in your build system. Removes the temptation to construct complex un-debuggable messes :) Meson is explicitly non-turing-complete as a design goal, and it's awesome.
it's pretty good. Viasfora is a game changer tho. also if you write lisp... gotta have it!
Actually, this is why there's not `get` method on the API I presented, only `operator-&gt;`: - Typing `m_concurrentState.makeLock().operator-&gt;()` is possible, but awkward. - C++ developers are used to smart pointers, where the lifetime of the pointee is tied to that of the pointer. So far, I haven't encountered the horror in question. Then again, we prefer to avoid locking at all in most cases, so it's used sparingly.
The idea is to not allow modifying contact violation handlers at runtime because that would give an exploit a very powerful attack surface. However implementions are recommended to provide a way to customise it at build time only.
Man this looks really good. Getting back into openframeworks after a little bit of a hiatus, might dive into this instead. Anyone have experience with both?
I wonder which are the API calls, that you would have to do transcoding to and from. It's interesting if the performance drop is really noticeable. In my case, I only have to deal with file paths, and opening files is relatively a rare operation. So I'm ok with transcoding with each API call, since it's encapsulated and overall architecture looks same regardless of OS.
Can't.
They are all over the place in the UI. In the common case it wouldn't be a huge deal. But with text editors and viewers it could get messy.
No, everything I have is my own. So I'm free to do whatever is practical given the time restraints I have.
If you have that much of trouble of compiling stl headers. Can't you pull your favorite Classes and Instantiation out in a static lib and compile all templates with extern template(To save compile Time)? The twitter Poll brought up a new Question for me: https://godbolt.org/z/-IpziQ What happens here? Due to the return of ternary operator is used ?
Almost no program would use UTF\_8 internally. That would be a disaster. The point of UTF-32 is that it does solve the problem. Any legal Unicode character can be represented. So you can get back to strings being indexable, and every character being the same size. UTF\_8 is great as a flattened format and I, like most folks, use it for that. And there are LOTS of things to do with text besides store it in a DB, which require extensive manipulation of the text. &amp;#x200B;
So I actually had dreams about this last night. My brain is already starting to trying to work out ways to reasonably deal with a UTF-32 implementation.
&gt; Interestingly it goes against the recent committee decisions that out-of-memory error should just terminate That's an over-simplification. :) The committee opinion is that we should _explore_ having standard `new` terminate instead of throwing; for applications sensitive to OOM, they could always still use `nothrow` overloads that return `nullptr` on allocation failure and check that result (same as they would with `malloc` for example). There's a bunch of open questions around it still, of course. And some decisions to make re the tradeoffs.
When we get to referring to the unicode standard, it's going to be an undated reference, with the understanding that an implementation can move to a new one freely. We did finally move to an undated reference to ISO/IEC 10646, so we have the latest character set. There's a dated reference to the 1993 version to support deprecated features in stdcvt. [http://eel.is/c++draft/intro.refs](http://eel.is/c++draft/intro.refs) 
What do you mean by "distribution"? In time? In space? In the code? I also have a hard time connecting "finding a distribution" with "benchmark".
I'm planning on logging the destination register after each floating point operating. So frequency in operations executed. A benchmark is useful because I need some program to patch. My little tests work OK but they're pretty lame. 
I have seen shit like that in production code. Some moron believed you can't use pointers without allocating memory in the heap. 
If you want to know what the destination register is you can look at the assembly. Frequency of operations can be measured with Intel VTune or things like PAPI. &amp;#x200B;
Source code: https://github.com/vietnguyen91/QuickDraw
https://twitter.com/gregcons/status/1092801268417028096
right well I want to know the value in the destination register at runtime. preferably the runtime of some interesting program (s)
Roght. I think that would happen if you declare the variable as `auto`.
Seeing as the gist of the post is done, I'll just nitpick by saying you should change the lambda to be an auto capture i.then([](const auto&amp;&amp; j) { return std::to_string(j); }); Let overload resolution resolve the call to to_string :)
Magnum is such an impressive project. I'm planning a new GUI app soon and it's a strong contender for my framework of choice. The inclusion of ImGui makes it even stronger!
Standard floating point benchmark suite if SPECfp. It includes individual benchmarks that are derived from some real life applications. You may also use any of the open source CFD solvers, such as OpenFOAM, SU2, etc. but these are all quite large projects, or any linear algebra suite like Eigen, Blaze, etc. (they normally come with examples or benchmarks), or a 3D game or graphical application. Or maybe a photo processing application, like RawTherapee or Darktable. 
That destroys any chance of heavy inline optimization, and performance is king for gaming.
awesome
Yes, the video in the Readme looks quite interesting, but what's exactly the unique selling point? And does it work with Boost.Test?
exactly what I was hoping for! thank you
Thanks! In my opinion you'd better provide a kind of `to_string()` for all containers (such as the fp::show() functions do), and then later use this inside your &lt;&lt; operators if needed : some people might want to be able to log without using an ostream. Or, make them optional, so that they do not conflict with operators provided by the existing code in a given codebase. If you are interested in using cleantype, please keep me posted:-) It is also a header-only library. 
lines starting with four spaces are treated like code: line_of_code(); anotherLine(); 
What are the semantics of multiple waiters on a single event? (particularly with reset == true)
So it's functional testing?
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/ani9q5/please_help_here/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
that only one would be woken up 
thanks :) corrected the post.
&gt;In libraries, you cannot call the `exit` function, if memory allocation failed I'd make an even stronger claim: "In libraries, you cannot call the \`exit\` function."
&gt;Almost no program would use UTF\_8 internally Whoa... It's been the standard for many many years so I'm surprised you are still advocating for such broken systems as utf16 and utf32. If Microsoft had a choice it would probably use UTF8 instead of UTF16 now too (they have been trying to support UTF8 correctly at the least). &gt;The point of UTF-32 is that it does solve the problem. It does absolutely not! And that's the problem. What it does is give the unwary developer a false sense of security. &amp;#x200B; This discussion has been settled ten years ago, and only UTF-8 is the only viable alternative for international programs. UTF-16 and 32 are just a pain in the ass with no redeeming qualities.
*Hey just noticed..* it's your **3rd Cakeday** gracicot! ^(hug)
Just wanted to thank /u/czmosra for Magnum, it’s an amazing project. 
It clearly hasn't been 'the' standard. Windows is UTF-16 based. .Net languages use UTF-16 as their native format. Everyone probably uses UTF-8 to STORE data or to EXCHANGE data. But I think it's a huge stretch to say that it's the standard to use UTF-8 as the internal character representation within programs. &amp;#x200B;
It's a multimedia framework right ? 
Yes. Wanted to clarify that in the title but then it became way too long :)
Time it takes to crack two different passwords?
It is a bit odd that multiple threads could come in and one says `wait(true)` and the others `wait(false)` and, depending on how they race in, one, some, or all, might get signaled.
I could use it for a game basically?
It has been for a long time. Windows (and .NET languages) is UTF-16 based because they adopted that before UTF-8 was born, and they have been regretting since. It seems they are slowly bringing support for UTF-8 as per last year (beta https://en.wikipedia.org/wiki/Unicode_in_Microsoft_Windows#UTF-8 ). The flaws of UTF-16 and 32 became apparent after their creation and the extension of Unicode, and as we know they don't make it easier to handle proper unicode there is just no point in using them aside from historical reasons (also, who wants to care about indianness of strings?). IMHO if your program needs to access the nth characters, split and merge strings all the time, then a better representation for a string would be a list of unicode characters (using ICU to convert from/to UTF-8).
Yes 
Yes. This might be helpful: https://magnum.graphics/is-magnum-what-i-am-looking-for/
I haven't used Magnum before and I probably don't have a use-case for it in the short-term future, but I just wanted to say how impressive and awesome I find the whole Magnum project. Every time there's some news about it here I love to read it. From the blog posts to the documentation... just awesome and very, very impressive. The "Is Magnum what I’m looking for?" is brilliant as well by the way. My highest congratulations and I really wish you and your project all the best and lots of contributions! Two small comments while I'm at it :-) How do you get to the "Is Magnum what I'm looking for" page via the menus? And, if it isn't there already (I couldn't find anything like it), a "Magnum vs SFML" comparison/overview might be really useful, perhaps including Openframeworks in the overview as well.
I agree. I definitely need to change that; haven't thought about it much, this was my first take at implementing an event object :-/
Not sure if you're looking for criticism, but you can avoid a lot of duplication by using a recursive function for the brute-forcing (instead of lots of nested loops, you have a function which does a loop for a given digit and recursively calls itself to guess the remaining digits). This also lets you reuse the same code for both the 4-digit and 5-digit version: https://godbolt.org/z/0WZLgP
I don't think your atomic_thread_fence is sufficient to enforce ordering here, since you didn't enforce memory ordering on whatever resource someone was presumably protecting with the semaphore.
would you be so kind and comment on the blog so that I and others can learn something. what would the solution be? &amp;#x200B;
Shouldn't you use notify_one rather than notify_all, then?
That slide still didn't say what Llewellyn Falco's "Approval Tests" approach means. From what I understood in http://approvaltests.com/, you manually approve a text output from a test in a diff tool. Then if the output changes, you need to reapprove it or fix your program. My question is - is this approach feasible for applications or classes that don't produce any text output?
 size_t getDeadRobots(Robot * output, size_t outputSize) size_t fill_buffer(std::vector&lt;int&gt; &amp; outBuffer) I've taken to calling this the BYOB pattern -- bring your own buffer. Not sure if I stole that from someone/somewhere else.
the other benefits are that it's cross plat, so it will work on Windows as well as Linux, and we support Linux remotely, it will also work with multiple generators, beyond MSBuild, in general you can leverage the CMake traits; you can edit CMake directly, you don't have to generate then go back, we support CMake natively, and we do not read the generated MSBuild files
Unfortunately I don't really have a solution; removing the thread fences and relaxed atomics is probably sufficient but I haven't spent a lot of time looking at it. Proving that there aren't any missed wakes is a nontrivial endeavor here.
you dont understand
I think it needs 2 versions of single: \_one and \_all :-/
25/75 as well, or 65/35 to get more detail about how it interacts with prediction. Without PGO, and without using compiler hints (`__builtin_expect[_with_probability]`, `__builtin_unpredictable`).
What makes it good for a GUI app?
Oh my, thanks a lot. Your comment is a motivation fuel :) The "Is Magnum what I'm looking for?" page was linked only from the main page at https://magnum.graphics/, right below the feature boxes and nowhere else, since it didn't really fit to the top menu. Now I added it at least to the footer to make it more discoverable. I'm afraid I currently don't have enough experience with SFML or OpenFrameworks to provide a relevant comparison. Noted though, good idea for inclusion. Broken link: fixed, thank you! Manual SVG postprocessing went wrong :)
Looks like it does not help generate text (or tests). What it is, is a sort of add-on for Catch2 that allows you to write tests like this: https://github.com/approvals/ApprovalTests.cpp.StarterProject/blob/master/tests/NewTest.cpp#L8-L12 An "approval test" like this: // located in ThisFile.cc or ThisFile.cpp TEST_CASE("FooBar") { Approvals::verify(std::to_string(2+2)); } is exactly equivalent to: TEST_CASE("FooBar") { ASSERT_EQ(contents_of("ThisFile.FooBar.approved.txt"), std::to_string(2+2)); } which is exactly the same as TEST_CASE("FooBar") { ASSERT_EQ("4", std::to_string(2+2)); } but more enterprisey. Putting the test output in a different file from the test code makes about as much sense to me as putting the first half of the test code in a different place from the second half (a.k.a. "fixtures"). But YMMV.
&gt; Most benchmarks (insert, find) are about 20% faster than my map Hmm, /u/tessil found that [absl was faster](https://www.reddit.com/r/cpp/comments/9jhk7r/swiss_tables_and_abslhash/e6s82qz/) a few months ago.
What about sparsepp?
Might be worth adding F14 to benchmarks: [https://github.com/facebook/folly/blob/master/folly/container/F14.md](https://github.com/facebook/folly/blob/master/folly/container/F14.md)
This is the only way I managed without g++ thinking I want to define a function that returns a 2d vector. &amp;#x200B; Why do I even bother with c++ : (
Photoshop doesn't perform blind allocations, it measures the amount of memory that is available and uses that as needed. Also note that Photoshop does not bring the entire file into memory if it does not fit, documents are divided into tiles. And when you zoom in or out, Photoshop caches the display version of the document so it doesn't need to keep the entire thing in memory.
Please read the sidebar for the appropriate place to ask questions. 
You can use ```auto``` to reduce the boilerplateness.
Well I have in mind a rather unusual GUI. It’s for a music making app, which will have lots of animation and effects. I have done things with JUCE in the past, which works very well, but for this project I want GPU effects. Magnum seems like a good level of abstraction for what I want to do.
Eh...no? this is the declaration. G++ will complain. error: non-static data member declared with placeholder auto auto m\_matrix = std::vector&lt;std::vector&lt;bool&gt; &gt;(m\_square\_size, row);//WTF C++??? 
If you're using c++17 then you can do something like: ```auto matrix = vector(4, vector(4, false));```
If you're doing fixed size, why not just do a multidimensional array instead of vectors? Much, much less hassle than that.
Previous members can cant be referenced in that style of initialization. They can in a regular constructor. If an array of bools whose size is always 4x4 is wanted, prefer a plain built in array: struct Tetromino { enum : size_t { N=4 };//this is an immediate value bool matrix[N][N] = {};//this syntax zero (false) initializes arrays of regular types }; 
An example of an app that does "blind allocations" is Notepad++: it handles OOM on opening too large file by catching bad\_alloc from the bowels of scintilla (technically, scintilla converts it to an error code at API boundary, and np++ converts it to an exception again)
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/anlarj/how_do_i_initialize_a_2d_vector_with_fixed_size/efub5kn/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/anhxq9/how_to_implement_an_event_in_c/efub79t/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
If i understand you correctly that you want a storage of 16 elements that never gonna change size, then Use this (very) basic 2d array class instead to store your data within the tetromino struct template&lt;class T,size_t X,size_t Y&gt; struct basic_matrix{ std::array&lt;T,X*Y&gt; storage; basic_matrix(T value): storage(value) {} T&amp; operator() (size_t x,size_t y){ return storage[x+X*y]; } }; With this your tetromino becomes struct Tetromino { basic_matrix&lt;bool,4,4&gt; m_matrix = basic_matrix &lt;bool,4,4 &gt;(false); }; given a Tetrimino object, you can access a specific element of the matrix with the operator () Tetromino tet; cout &lt;&lt; tet.m_matrix(2,3); If you're really sure a vector&lt;vector&lt;bool &gt;&gt; is what you want, you could make an alias for the type: using vectorvector = std::vector&lt; std::vector&lt; bool &gt; &gt;; Good luck
Plus you can just build a headless JUCE as a library and have all the awesome cross platform audio &amp; other stuff available in a magnum/unity/react native/etc project
(To the tune of "Still Alive":) Look at me still talking when there's charconv to do, when I look out there it makes me glad I'm not GNU. Seriously though, I wish libstdc++'s maintainers good luck with `from_chars()` and `to_chars()`, and I sent Jonathan Wakely an email with my understanding of the charconv algorithm domain (sans code) as soon as I had researched the area and begun implementation. I sent the same to libc++'s maintainers shortly afterwards. Even starting with the MSVC UCRT's implementation of `strtod()`, it took me several months to convert it into a form suitable for `from_chars()` (with a 40% perf improvement). Maybe they'll be faster/smarter than me, or maybe they'll be able to start with more malleable open-source code (I spent some time removing CRT generality like `FILE *` support). It still took a while to thoroughly audit the code for correctness and performance, make it header-only friendly, and change the CRT interface to the STL interface (no null termination, different error reporting, etc.). There was also an issue regarding overflow/underflow that I was the first to encounter.
I think stable sort should have an overload that takes an allocator.
Please post links as links, not text posts. I think I mentioned this before.
Welcome to C++; however, this is not on-topic for our subreddit.
!remove
OP, A human moderator (u/STL) has marked your post for deletion because it is not appropriate for r/cpp. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/anh78e/my_implementation_of_quickdraw_an_online_game/efugudh/,%20was%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
It is unclear to me what this is supposed to teach us about C++.
Well...most programs allocate without doing any inspection or management of available memory (mine included lol)
The list of broken concurrent primitives I have written, is long...
Tessil has the hopscotch map which is much lower memory usage, but almost as fast as his robin map so check that one out too! His sparse map is the most memory efficient, he claims it beats google sparse at memory as well. Those 3 maps from him are all interesting for their specific use case. 
&gt; Un­sure if Mag­num is the right fit for your project? Here are five case stud­ies loose­ly based on ex­ist­ing Mag­num users to help you de­cide. Only see 4 case studies. Text out of date? Or issue on my end?
I'm not sure what to tell you but this discussion is not really about Photoshop.
Could you throw together a few words about what, if anything, the C++ standard could include that would have made the Magnum Engine even better? Last year there were huge, heated, discussions on including the 2d graphics proposal into the C++ standard. While I was absolutely turned off by the idea, it did occur to me that some of the fundamental math concepts could be standardized in a way that almost (or even all) graphics related projects could rally behind. For example, I see Quaternion in your math namespace, as well as Matrix4, and various others. These seem almost like vocabulary types that most frameworks out there have little reason to implement differently. If these types had existed in the C++ standard version you were targeting, would you have used the provided versions instead of rolling your own?
I'll redo the benchmarks with all of the suggestions here but that will take a while
Is the technical content of that email available somewhere? I'd be curious to read it.
 Actually, this is a good example. If we remove any of the fences, or even weaken them, then the algorithm does \_not\_ work at all! The fences enforce the acquire/release relationship between the wait/post functions where wait is acquire, and post is release. The code has the position of the membars in the exact correct locations. The release is \_before\_ we do anything in post. The acquire is \_after\_ we do everything in wait. If the position of the standalone fences is changed, then the algorithm will bite the dust. Joe Seighs excellent algorithm is 100% correct, and the implementation I showed you is 100% correct. &amp;#x200B; This is using standalone fences. Imvho, they can be a bit more flexible. &amp;#x200B; There are no missed wakes. This algorithm works like a charm. &amp;#x200B;
Doesn't a relaxed fetch_add or fetch_sub do the same work as acquire/release anyhow (on X86) since it is a read-modify-write operation, and still needs LOCK? ie why use fence, instead of putting it in the fetch?
Not yet - it's outdated and incomplete with respect to my current understanding and latest developments, and it would take a bit of time to properly update.
&gt; CMake has a lot of resources online, and supports from project targets very quickly from when they're released. It's also pretty lightweight. The problem I have with Cmake's resources is that each is its own distinct beast. Most people are some nightmarishly Cthonian mix of old and new syntax, with little explanation as to why or how. The Cmake documentation and tutorials has a really bad case of "The rest of the F'ing owl" problem in regards to teaching the tool, and there is no unifying idea on how to write good cmake, and somehow survive that absolute wild-west that is other cmake projects.
The following discussion might be of interest to you: [https://groups.google.com/d/topic/lock-free/A1nzcMBGRzU/discussion](https://groups.google.com/d/topic/lock-free/A1nzcMBGRzU/discussion) I personally like the standalone fences, partly because of my work with the SPARC, and how they can be inserted in places that are \_exactly\_ where they need to be. The ingrained fences wrt std::atomic are fine, however, say, std::atomic exchange cannot skip membars like a standalone version. Take the case of the following code that removes all the nodes from an atomic stack in a single operation via exchange: `// try to flush all of our nodes` `node* flush()` `{` `node* n = m_head.exchange(nullptr, mb_relaxed);` `if (n)` `{` `mb_fence(mb_acquire);` `}` `return n;` `}` &amp;#x200B; This is from a simple atomic stack: [https://groups.google.com/d/topic/comp.lang.c++/RQMLZWO2HYc/discussion](https://groups.google.com/d/topic/comp.lang.c++/RQMLZWO2HYc/discussion) No ABA here! ;\^) &amp;#x200B;
There is nothing broken in here. Take a careful look at the wait conditions for wait and post. Nothing gets lost. Think about it for a moment. For a proof, modeling it as a mutex would be fairly simple. Focus on the wait conditions and see how the count from the outer fast\_semaphore is sort of \_connected\_ wrt the waits to the inner, or "slow\_semaphore", so to speak.
How is this different from a Benaphore? [https://en.wikipedia.org/wiki/Futex#BENAPHORE](https://en.wikipedia.org/wiki/Futex#BENAPHORE)
It’s ideal for testing legacy code that is maybe very hard to unit test. As long as you can serialise some output, you can capture something about its current behaviour, and store it in version control. Then you can start to refactor, and assert that you still get the same results. 
I don't think it is different at all! The first time I heard about the algorithm is from Joe Seigh over on comp.programming.thread's around 2006-2007. Afaict, he had to get it from this. He worked at IBM in the 80's, and 90's. Fwiw, here is a patent application for an interesting reference counting algorithm, that got granted iirc from the same very smart guy, Joe Seigh. Not sure if he invented it or not: [https://patents.google.com/patent/US5295262](https://patents.google.com/patent/US5295262)
I always use a count member for enums that go from 0 to N, so it doesn't bother me. It is often considered best practice. I worked at some studios where it was required by the coding standard. You know, you don't have to deal with it in switch-statements, \`default\` will deal with count and any other invalid value. I find your API verbose for what it is trying to do. You don't want to type 5 characters, but your declaration is 75 characters more than the original solution ;) Remember \`count\` is \`static\_asserted\` with a helpful message, so it won't break silently and a new user can't mess it up. I think it is worth the simplicity. I like simplicity. However, if you could get it to work without the verbose declaration, than yes that would be really cool. I'm sure there are scenarios where "pairing" the enum with the event like you propose would be better.
But you can do that with any framework?
I guess I should also compile with `-march=native`. I only used `g++-8 -O3`
Still don't see the point.
Abseil is on conan, that's bar none the easiest way to deal with your dependencies. Great job on the map! Any chance we get an \`unordered\_set\` out of it? Cheers
Bagel :( I've chosen not to use google projects because of that. Eat carbs? I don't think so.
Can you write up a full version of your understanding here?
Let's say that the unanimous vote was the over-simplified one then, because I don't have many more resources where I could fetch information about it :p Using nothrow overload is indeed a nice solution generally, but should we have an overload for every function that might allocate? Otherwise libraries might fail with an OOM and make the program using them terminate. 
Note that a std::from_chars is assured to work only with the corresponding std::to_chars of the same library / implementation and for this reason its use should be limited and not generally used. Old relevant thread from last summer https://www.reddit.com/r/cpp/comments/92bkxp/how_to_efficiently_convert_a_string_to_an_int_in_c/ please look at the comments and the discussion more that the post of the chap in the link
u/martinus: i reproduced my case and reported it on github. &amp;#x200B;
I too would like to read about the difficulties.
Looks like syntax sugar for tag dispatching on fixed function name. In fact library implementation given at the end does exactly this, with some operator overloading to mimic proposed invocation syntax. Not worth it.
It's more likely due to the fact that `robin-map` uses a default max load factor of 0.5 and the one of /u/martinus uses a default max load factor of 0.8. If the test is done when robin-map just had a rehash, it'd explain why it uses much more memory and is faster. I choose this max load factor as I noted (see [benchmark](https://tessil.github.io/other/hash_table_benchmark.html)) that the basic robin hood collision resolution performs poorly with a too high load factor compared to hopscotch resolution. But my implementations start to lag a bit behind. I started to develop the `hopscotch-map` library as at the time the only real alternative to `std::unordered_map` was the `google::dense_hash_map` which was not the state of the art. But a lot of new hash maps went out these last couple of months with mainly the [Abseil](https://abseil.io/blog/20180927-swisstables) hash map of Google and the [Folly F14](https://github.com/facebook/folly/blob/master/folly/container/F14.md) hash map of Facebook. I currently use the simple robin-hood collision resolution with backward shift deletions used also by the hash map of Rust. I have some plans to tests some improvements ideas I have on both `hopscotch-map` and `robin-map` and update my benchmark page with all the new hash maps, but I really need to find some time for that.
I am personally not quite sure what to think. Some stuff looks good, but the language is a bit bloated. If I understood correctly, this is compile-time only feature. It would probably increase compilation time.
Strongly against this. C++ already has two function/method declaration syntaxes. This proposal will effectively double that amount.
Is this just for the purposes of demonstrating the fast semaphore, or do you actually use a semaphore class based on a mutex/cond pair? This seems odd to me, since the usual benefit of semaphores is that the system-provided ones are significantly more efficient, and usable in some situations where mutexes aren't (POSIX signal handlers, realtime threads, and so on).
Please replace "assured to work" with "if you use \`to\_chars\` and then \`from\_chars\` you are guaranteed to recover the value exactly". I don't see why the use of those functions should be limited in any way (even among different implementations), as long as your code does not **rely** on exact round-trip.
&gt; it measures the amount of memory that is available Please kindly explain how do you think that is possible? When photoshop tries to allocate memory it check free RAM and... then what? That measurement is immediately outdated. As I see it, it still need a way to validate that memory was allocated successfully.
C++ is full of syntactic sugar. Operator overloading is syntactic sugar. Lambdas are syntactic sugar. However, the question to ask is if the syntactic sugar can make C++ better at expressing zero overhead abstractions. I believe in this case, the answer is yes.
C++ does have two function/method declaration syntaxes. This has a shot of uniting these in a more general, more programmable way.
That's an almost verbatim paraphrase of the Standardese, but it is (surprisingly) also misleading. What matters is not the charconv implementation, but the floating-point representation. For a given floating-point representation, e.g. IEEE floats with 23 explicitly stored fraction bits, or IEEE doubles with 52 explicitly stored fraction bits, then the transformation from floating-point value to character sequence (of shortest round-trip length, or given precision, always with round-to-nearest behavior) is a crystalline mathematical truth. Same for the reverse - given a character sequence and a given floating representation, there is a single correct value to determine. (Ignoring the overflow/underflow reporting thing that I mentioned, which the Standard didn't specify at first). In this respect, charconv's behavior is highly constrained, with the only variation being its performance. Interestingly and counterintuitively, hexfloats are weakly specified by charconv via the C Standard, to the point where I needed to make multiple judgement calls when choosing MSVC's behavior. Decimals are unaffected by those issues.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/anovpq/help_troubleshooting_program/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
If it just hadn't such a terrible interface I would be more excited/ interested. Seriously: Who designed this?
Just removing the fences of course would not work. Removing the fences *and* the relaxed atomics would probably work. Algorithm looks okay to me but missed wakes can be sneaky :)
thanks, should be fixed now
Not sure this is worthy of a blog post, but whatever...
I am nuclear busy but I’ll try.
Hi! You are right that I use 0.8 as the default max load factor. I've used the default hash for each of the maps which seemed to be the most reasonable choice to me. Also I didn't compile with `-march=native`, only with `-O3`. This will probably change the results for abseil a lot. I'll try to update the benchmarks with your other maps and F14 when I have the time
Are you sure this is better than the naive version? node* flush() { return m_head.exchange(nullptr, mb_acquire); } A quick test on compiler explorer (https://godbolt.org/z/CyzcJe) shows better code gen for the naive version on x86 and arm, but I might have made a mistake, when converting this to c++11 and I don't have a spark compiler at hand.
Given that they replace `unique_ptr` to avoid including `&lt;memory&gt;` there should be separate headers for such single classes.
This is really not that uncommon (assuming the OS actually tells you that you are out of memory and doesn't just kill you on acces). You app triggers an operation that requires lots of memory (e.g load a big file into memory) and when the allocation fails, you just abort the operation. No need to terminate the app and potentially loose user data in the process. Or a web server, that may just terminate a single connection/session instead of the whole app. I think many of the people advocating std::terminate on alloc failure focus too much on library code that indeed can rarely recover from such an error, but that is what exceptions are for: I can't handle this error locally (I.e. inside my current module), so I'm aborting and passing the error information to a higher level logic.
Over regular functions operator overloading provides terseness. Over regular Callable classes lambdas provide locality, implicit lexical context capture and reduce boilerplate. This, compared to tag dispatching, AFAICS just moves tag type from function arguments and into angle brackets. That's it. In fact it is *less* general than tag dispatching since it allows only one implicit function name. So no, this is not a good idea.
You mean how to organize the source files in git like repositories? 
If this is what you're looking for, take a look at the Pitchfork Project Layout. It's an attempt to standardize the layout of C++ projects. 
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/anpx4k/how_important_is_it_to_learn_data_structures_and/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
This is a controversial topic and I realize, no matter what opinion I present, it will backfire one way or another :) Back in 2015, I think, /u/mjklaim asked me a similar question, but for the 2D graphics proposal. There's now an [audio proposal](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p1386r0.pdf) [pdf] by largely the same people. I have two problems with these proposals: - The scope always ends up either too narrow so it's useless or too broad so it's overengineered (do we need 2D or 3D? GPU-powered? builtin circle primitives or builtin raytracing? image loading? should the audio support surround sound? Doppler effect? falloff curves? equalizers? audio decoders? encoders?) - Inevitably it causes the standard library to depend on some graphics/audio backend so it can open a window or play a sound. I don't think my libstdc++ should depend on PulseAudio, I think it should be the other way around. From the same people involved with the 2D and audio proposals, there's also a linear algebra proposal -- I guess you're aware of it ([1](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p1385r0.html), [2](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p1166r0.pdf) [pdf], [youtube talk](https://www.youtube.com/watch?v=pq4UEH-DbNs)). Without commenting further on what the three proposals have in common, there's a few things where STL and Magnum differ, and thus, in my opinion, a convergence will be never possible: - [Magnum::Math](https://doc.magnum.graphics/magnum/namespaceMagnum_1_1Math.html) has a graphics focus -- fixed-size matrices, quaternions etc., everything you need for creating pretty pictures, but *not more*. Compared to e.g. Eigen, it doesn't have dynamic matrices, triangle matrices, sparse matrices, complex solvers or anything like that. That's out of scope and such restriction makes the whole thing fairly simple. On the other hand, what I see from the linear algebra proposal, it tries to put *all* -- fixed-size matrices, dynamic matrices, sparse, triangle matrices... -- under a single API, to be as generic as possible. Inevitably that will lead to things being overly complex, slow to compile and algorithms hard to optimize. - C++ inherits the (in my opinion) crazy implicit conversion / type promotion rules from C, defining what's the result when `float` and `long` are multiplied and such. From my experience, this leads to many errors or calculations being accidentally done on a larger type than desired, so in case of `Magnum::Math`, all type coversions (`Vector2i` to `Vector2` etc.) have to be done explicitly. During the almost decade of Magnum being used for various things, this was never a problem, on the contrary -- it helped find numerous bugs. I was even playing with the idea to provide opt-in wrappers over builtin types in order to disallow implicit conversion there as well. In comparison, the linear algebra proposal aims to *preserve* the C type promotion rules, and in the talk suggesting them to be taught more, so "everyone knows them well and doesn't make mistakes anymore". - The Math API (and all Magnum APIs in general) have a bunch of minor but useful features differentiating it from STL, such as a way to [explicitly force the instance to not get initialized](https://doc.magnum.graphics/magnum/types.html#types-initialization) or an [ability to allow explicit conversion from/to 3rd party types](https://doc.magnum.graphics/magnum/types.html#types-thirdparty-integration). This is also consistently exposed to all containers, so you can disable element initialization, implicitly convert `gsl::span` to `Containers::ArrayView` or make them take / release ownership of an externally allocated memory. STL doesn't have any generic means to allow such interaction with 3rd party types, there's no way to disable initialization of container elements (unless you e.g. supply your own allocator to a `std::vector`) and neither the containers are able to generally acquire/release the underlying memory (AFAIK, all proposals to add that [were rejected](https://stackoverflow.com/questions/36643645/deny-stdvector-from-deleting-its-data/36644003)). Besides all of the above, there's the problem of STL header bloat and I don't see it getting any better any time soon, [even with modules](https://twitter.com/czmosra/status/1089838362373033985). The takeaway of that is, instead of aiming for having more things standardized, it seems to be more and more reasonable to actively go the other way and reimplement standard things from scratch to get back the lost performance.
Glad to see the series continuing OP! 
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/anpypu/why_is_this_code_so_slow_to_run_please_help_me/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Could you please elaborate on which details of the interface you find terrible?
Issue on your end, I guess? :) There are five (green, light blue, yellow, dark blue and red), while one of them suggests that Magnum is probably not a good fit.
Are you sure this will simplify language? You effectively propose syntax which does not have equivalent in any of the mainstream languages i.e. looks alien and most probably collides with existing grammar. Which is, I must admit, is already very complex and heavily context-dependent.
This was a triumph. I'm making a note here, great comment. It's hard to overstate my satisfaction...
Cppcon 2019 talk? :)
no i mena repository design pattern for access data from file or database and not git repository
Well, taking a `std::string_view` as parameter instead of two const char pointers would have been much better. Or at least if they provided the overloads it would make sense.
No std::string_view, no constexpr and I'm really no fan of the mix of return values and out parameters (although I think I understand the logic behind it). Oh and now we have at least three families of functions that convert strings to numbers, each having a different interface. Let's see, if we get another one, once something like expected gets standardized. At least it returns a struct with named members and not a tuple.
Seriously, I'm intersed in this also.
Thankee!
This semaphore is by no means "fast". 
The grammar is already ambigous enough to parse, this proposal just makes it worse...
codelite (by far the best) [https://downloads.codelite.org/](https://downloads.codelite.org/)
What's wrong with lambda? 
KDevelop or Kate
Qt Creator is pretty nice. But I typically use vim + console or Sublime Text 3 + console.
Nothing wrong with lambda. How would you do this in C?
Might as well suggest the commercial option of clion. 
To be honest, I don't understand what problem you're solving. 
Why would you think that isn't possible..? char (*x)(unsigned) = y;
Qt creator is really cool.
1. Sublime Text 2. Visual Studio Code
I use Eclipse CDT, cant recommend it.
CLion is very nice if you're using CMake. It's a little tricky otherwise, but can certainly be made to work.
You had some unnecessary parens, but you can do this. https://godbolt.org/z/SkVJ0p
&gt; by far the best Details, please? How is it better than other IDEs?
oh no, here we go again.
Cevelop (based on Eclipse) is good, once you get the includes right
If y isn't the name of a previously declared function: you won't.
 Is this what you mean? typedef string (*func)(void); string message(void); int main(void) { func my_functionPtr = &amp;message; cout&lt;&lt;my_functionPtr(); } string message (void) { return "Hello World"; }
I stand with qt creator: intellisense works really good (IMHO as good as Visual Studio) for both C and C++, good integration with CMake, debug view (GDB under the hood) is handy and a "fake vim" editor that can use your own $HOME/.vimrc setup.
I was using CLion but recently have just started using VS Code and compiling via a terminal. I find that VS Code is much more lightweight than CLion which was starting to feel a bit bloated and sluggish in recent releases. CLion has great support for refactoring tools (renaming symbols, restructuring interfaces) and a good graphical interface to the debugger; but if you learn the basic CMake syntax you can get a comfortable command line build workflow and VS Code's C++ extensions provide decent intellisense.
[https://wiki.codelite.org/pmwiki.php/Main/ReadMore](https://wiki.codelite.org/pmwiki.php/Main/ReadMore)
That's really unimpressive, to be honest. Have you tried any other IDE?
Emacs ftw
Spacemacs! &amp;#x200B; FunFact: spacemacs would have also been the correct answer to the following questions: &amp;#x200B; \- What should i use to surf the internet? \- What should i use to organize my life? &amp;#x200B; \- What should i use to read/send email via imap/smtp? &amp;#x200B; \- What should i do to find a hot GF? PS: eventually, if spacemacs isn't available then Qt Creator is the most featurefull and stable C++ ide on linux. If you feel more minimal and you are runnig Gnome, then Gnome-builder is a nice new addition to the scene. 
&gt; the new update of netbeans doesn't support c/cpp development wait what
i use it everyday in reverse engineering, working with devuan (no systemd crap) fast and closs-platform, even nightly builds are stable
Yeah netbeans since its been acquired by apache doesn't have support for c/c++ natively anymore, so I'm looking for an IDE to switch too and it seems like Qt Creator is coming out on top
Hey, I was like you! I had been using Netbeans for 15 years, and only recently jumped ship. I don't know what you're looking for in an IDE but for me personally I stayed with Netbeans for so long because it's surprisingly one of the few IDE that know how to support local code but remote compilation. (That always really surprised me. C++ is infamous for long compile times, I don't know why more IDE vendors don't assume people want/need to compile on beefy remote servers). If you don't need that, then QtCreator and CLion are both decent options (though there are things that personally annoy me about both of them) For the record, you *can* get the c++ modules working with Netbeans 9.x. I never bothered because it's (theoretically) going to have the exact same behaviour as the old 8.2, which as I'm sure you know, hasn't been updated in ages and is starting to show it's age. But other's have done it and if you just want a newer Netbeans 9.x wrapper for the same parser and etc, you can. https://stackoverflow.com/questions/51493882/netbeans-9-c-support Right now I use two different "IDEs". If you're not scared of a high activation cost, emacs can be a surprisingly comprehensive solution. It takes a *lot* of work to set up the first time, but my setup has a syntactic code parser for completion/navigation, full integration with git, easy file/text search, remote compilation, and more. I love it because I can personalize and customize anything I want. But I can't stress enough that it's a lot of work, so you shouldn't bother unless that doesn't scare you. The other IDE I use is eclipse. I'd actually tried to get into eclipse several times in the past and always backed off because I found it surprisingly confusing and hard to set up. I only succeeded in getting off the ground this last time because I started cuda programming and Nvidia's Nsight version of eclipse took care of all the setup for me. All I can really say about eclipse is that it's somewhere between alright and good once it's set up, but I still couldn't tell you how to actually set it up...
Vim + Console? How is debugging with that?
good. how to do this in one line?
That make sense.
I am still learning vulkan. But Is there a way to contribute or help with the vulkan integration?
Actually not so bad. gdb is a pain at first, but the reality is that a handful of its commands are what you need 90%+ of the time. Typically, you create your own gdb cheat sheet with all of the commands you actually need. The main problem with pure gdb is the lack of context information - you don't see the source code surrounding the lines of the backtrace. This can be fixed by using a gdb frontend like cgdb or kdbg. I guess there is a vim plugin for that, but I never looked for one.
Like this: void whatever () {} void (*x)() = whatever; ... It's only got one semi-colon and everything.
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/anr3yb/declare_and_define_function_point_variable_in_one/efvksvf/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Floating point base conversion is surprisingly tricky to get right. Take something as simple as hexfloat - you simply have to convert from base 2 to base 16 and vice versa. Should be simple right? Lets say I give you a 1000 digit hexfloat number, and ask you to convert it to binary double precision. Double precision has 53 bits of precision (ignoring denormals for the moment). So guess how many digits of the hexfloat number you have to read in the worst case before you can stop and ignore the rest of the digits? If you want a deep dive into floating point base conversion, [Exploring Binary](https://www.exploringbinary.com/) is a great resource.
That's part of the question. Should standard containers (and really the whole rest of the language) be penalized for everyone for the sake of the apps that can and do _correctly_ handle OOM? For the apps that _do_ handle OOM correctly, do they even use standard containers, or do they roll their own? For apps that handle OOM, are there better interfaces they'd prefer than `bad_alloc`? Answering those questions definitively will be necessary before the committee _actually_ moves forward with changing how OOM works. The status quo is pretty powerful when it comes to the standards process. :) For many cases where OOM can matter, it's worth pointing out that it's not always all-or-nothing. Someone brought up the example of loading an image in Photoshop; for that example, loading the image buffer(s) is a very different operation than hitting OOM while allocating text buffers for menu items, and it's not clear that the correct behaviour/interface for the one operation fits for the second. Likewise for something like Chromium. Given the multi-process model, and that most heavy allocation happens in either (a) graphics buffers, (b) the JS run-time's highly specialized allocators, or (c) the DOM tree's specialized data structures; is it reasonable to impose `bad_alloc` on all the other bits of codebase to deal with the likely failures in those modules? (I can't say either way, but getting Mozilla's formal input to the committee would be useful.)
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/ansq36/i_created_an_xcode_compatibility_table_for/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
`string_view` is immutable, so while it would be okay for `from_chars()`, you couldn't use it for `to_chars()`, leading to an asymmetric interface. One we have ranges, it would be good to have an overload taking `ContiguousIterator&lt;char&gt;` and a corresponding `Sentinel`, and another taking a `ContiguousRange&lt;char&gt;`. Or perhaps just `span&lt;char&gt;`?
When you say "they", who do you mean?
The yellow one isn't showing up. The reason is that UBlock Origin is blocking it. FYI, I guess. That's weird that UBlock would block that.
C++20 will have a format library to finally replace printf. So there will be one more conversion facility for sure.
You can try `:TermDebug` or, if you want something more powerful and much more heavy, there's [vimspector](https://github.com/puremourning/vimspector).
Thanks! I really appreciate the insights.
&amp;#x200B; My personal pattern is C++/linsql (so pattern without ORM - only 'tool' what I need is standard preprocessor): &amp;#x200B; `sql/_sql - macro/operator returns thread local procedure (inline stored/prepared procedure)` `universal - set of name/value as static dynamic variable (static names, dynamic values)` `universals - set of universal` `nil - empty universal` `nils - set of nil` `selectX[u] - procedure returns result set of universals` `selectX(u) - procedure call with universal as input/output and if select it takes only first row` `updateX(u) - procedure call with universal as input/output` `insert-set - C++/linsql variant of standard SQL insert-into` `:Name - named variable in SQL` `#Name - named constant in SQL (example #True=1, #False=0)` &amp;#x200B; Below my C++/linsql rewrite from Microsoft SQL Server samples (originally C# ja Python) &amp;#x200B; ///////////////////////////////////////////////////////////////////////////// #incluce &lt;teroxLibrary&gt; using namespace terox; using namespace terox::linsql; namespace demo::sqlserver { ///////////////////////////////////////////////////////////////////////////// struct universalAsAttributes ( companyId { this, "companyid" }, companyName { this, "companyname" }, color { this, "color" }, count { this, "count" }, customerId { this, "customerid" }, demo { this, "demo" }, employeeId { this, "employeeid" }, firstName { this, "firstname" }, lastName { this, "lastname" }, listPrice { this, "listprice" }, name { this, "name" }, orderDate { this, "orderdate" }, orderId { this, "orderid" }, orderTotal { this, "ordertotal" }, productId { this, "productid" }, productNumber { this, "productnumber" }, quantity { this, "quantity" }, standardCost { this, "standardcost" }, title { this, "title" }, unitPrice { this, "unitprice" } ) ///////////////////////////////////////////////////////////////////////////// namespace { auto selectSalesOrders sql ( select c.customerId, c.companyName, count(soh.salesOrderId) as count from SalesLT.Customer as c left outer join SalesLT.SalesOrderHeader as soh on soh.customerId = c.customerId group by c.customerId, c.companyName order by count desc ) auto insertSalesProduct sql ( insert SalesLT.Product set name = :Name, productNumber = :ProductNumber, standardCost = :StandardCost, listPrice = :ListPrice, sellStartDate = current_timestamp output inserted.productId ) } auto csharpVariationAsCpp() try { for(auto&amp; order : selectSalesOrders[nil]) { log::infoAs ( ID: % - Name: % - Order Count: %, order.customerId, order.companyName, order.count ); } universal product; product.name = "SQL Server Express"; product.productNumber = "SQLEXPRESS1"; product.standardCost = 0; product.listPrice = 0; insertSalesProduct(product); log::infoAs(Product ID % inserted, product.productId); } catch(Exception&amp; ex) { logExceptionAs(ex); } ///////////////////////////////////////////////////////////////////////////// auto pythonVariationAsCpp(universal const&amp; params) try { static auto selectCustomers sql ( select top 10 title, firstName, lastName from SalesLT.Customer where (:Demo is null or demo = :Demo) ) for(auto&amp; row : selectCustomers[params]) { log::infoAs(% % %, row.title, row.firstName, row.lastName); } universal product; product.name = "Bike"; product.productNumber = "B1'; product.color = "Blue"; product.standardCost = 50; product.listPrice = 120; product.demo = params.demo; static auto insertProduct sql ( insert SalesLT.Product set name = :Name, productNumber = :ProductNumber, color = :Color, standardCost = :StandardCost, listPrice = :ListPrice, demo = isNull(:Demo, demo), sellStartDate = current_timestamp output inserted.productId ) insertProduct(product); log::infoAs(Inserted Product ID : %, product.productId); } catch(Exception&amp; ex) { logExceptionAs(ex); } ///////////////////////////////////////////////////////////////////////////// } // namespace demo::sqlserver ///////////////////////////////////////////////////////////////////////////// &amp;#x200B;
What :O Is it because of the "premium support" link? Or because of the "blocks" word? Geez. I have no words.
Thank you for the interest! :) Well, for the more mature parts of the library I'm maintaining a list of self-contained / atomic tasks and features that could be contributed, but since the Vulkan support is still at the very beginning, there's not much of that yet -- mainly because I'm not even sure how I want to design the various parts. There's at least something already, though -- have a look at the checkboxes in https://github.com/mosra/magnum/pull/234 and the cards in the [Vulkan project](https://github.com/mosra/magnum/projects/3), maybe there could be something interesting for you.
Measuring memory suffers from a race condition. Sure, it works for a program which assumes it's alone on a machine, less so otherwise.
I'd make even more strong call: you can only terminate when releasing a synchronization object fails.
Of course it can! So I am a multithreaded server. A request comes in and it's too big. Do I terminate and drop **all other, parallel, requests**?! Hell no, I only drop the offending one. So I am an editor of some fashion. A user copy-pastes a lot of junk into me and I can't suck it in. Do I terminate and **drop user work**?! Hell no, I only drop the pasted data. Say I am a cmdline utility operating on whatever input, generating output from whatever I processed. Input becomes too big. Do I terminate and drop whatever results I managed so far? Hell no, I give up going further and present what I managed so far. There's probably more examples if one puts their mind into it.
My understanding is that the UBlock Origin guy is pretty receptive to feedback. If you're able to reproduce the problem on your machine (I mean, it could be something I screwed up, I have no idea), you might be able to file a bug report and get whatever's causing it fixed. I'm happy to help if there's something I can do, but if you can't reproduce the problem on your end all bets are probably off and we should just call this a PEBKAC error.
Adding constexpr would be near-trivial with is_constant_evaluated() as we could bypass the intrinsics that we need. charconv is surprisingly intrinsic-heavy.
Interesting - I'll just say not to use Nuklear, I found it to be a huge disappointment. 
No wchar_t support.
Just use phone and call a c++ program on the command line for anything it can't do.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
How would that work with the optimizer btw. IIRC, is_constant_evaluated() may only return true if the language standard mandates that it is evaluated during compiletime - not just because the compiler happens to know the inputs at compiletime. So the optimizer would still see the runtime branch using opaque intrinsics even though it managed to determine the inputs at compiletime and would be able to figure out the result if only it would look at the compiletime branch. Correct?
I'm not using uBlock (or any other content blockers for that matter), so I would first need to set that up... Can you reproduce with other browsers? Other devices?
That's probably a feature.
Another reason they take `char` pointers as parameters is it allows them to be used in applications (e.g. embedded) that ban templates and/or exceptions (not all `string_view` and `span` constructors are `noexcept`). It's of course trivial to write a wrapper that takes different parameters.
For UFCS, I expect the client code to be no more verbose than: int i = 42; string s = i.to_string(); Anything else would be boilerplate. The same goes for smart references and proxies. About how to implement smart references, I think it might be possible with meta-classes and generative code.
If you're on Windows it's a problem.
As an interesting learning experience, you can use [FastCGI](https://github.com/FastCGI-Archives/fcgi2) (or [fastcgi++](https://github.com/eddic/fastcgipp), which looks nicer, but I've ran into lots of bugs in it a few years ago; maybe they're all fixed now) to pass HTTP requests from web interface via some web server to C++ and handle them there. It's not that hard to set up and use, but it has some OS-dependent quirks (I remember having to patch it a bit for use on Windows). Alternatively, you can build everything in C++, using one of the few web frameworks available. I don't have experience with any of them, so I can't really recommend any single one, but here's a few links: [CppCMS](http://cppcms.com/wikipp/en/page/main), [Pistache](http://pistache.io/), [crow ](https://github.com/ipkn/crow). Crow seems the simplest one, and CppCMS is probably an overkill, but, again, I haven't used any of those.
If you feel like dipping your toe into the hellish sea that is ASIO, there's example code online for very minimal HTTP servers. https://www.boost.org/doc/libs/1_55_0/doc/html/boost_asio/examples/cpp11_examples.html
You know that the chars that come out can be trivially widened to wchar_t though, so doesn't seem like a huge problem to me?
My program is full C++, it takes pictures, talks in UART, interacts with databases and transfer files to could storage, I just need a way for people to send somehow settings to the database without using any other software like apache. So your idea, if I understood, is to do a full website, but I would only use 1 page with a form. I don't know if you see :/ I could use SSH to send a file parsed by the C++ but it's too difficult for the employees to use shells ... Some of them don't even know Linux exist ! &amp;#x200B; (Ideally, in the future, the project will have to be deployable to any Raspberry Pi using a pkg in the company and not need to add any other software to make it run)
FWIW I'm using Firefox + uBlock Origin on Win10 and all 5 show up fine.
It's "terrible" because it's the most basic building block with lowest overhead. It was designed to be as fast as possible (and is indeed is).
[After STL completely finishes charconv](https://www.youtube.com/watch?v=dVVZaZ8yO6o)
It feels like it deserves it's own blog-post/talk.
Why not mark the intrinsics as constexpr? There is no reason why BitScanReverse or add_carry or mulh cannot be constexpr.
&gt; you don't see the source code surrounding the lines of the backtrace. This can be fixed by using a gdb frontend like cgdb or kdbg There is a built-in option --tui that gives you the context without installing any frontends. 
too bad, looking at the way things are progressing, we are not still getting any coroutines in C++20 :(
this seems to count ...but what is here the type and what is the value? 
Hush now, Ant Man.
Having exceptions disabled does not mean you can only use functions which are \`noexcept\`. The only problematic cases are those where exceptions would be reasonably expected to occur and std::terminate() would not be an acceptable result. This in turn is arguably bad library design, as exceptions are not 'exceptional' but being used for flow control (e.g. \`boost::lexical\_cast&lt;&gt;\`, but fixed with \`try\_lexical\_convert&lt;&gt;\`). Much of the STL is not \`noexcept\` because of \`bad\_alloc\` for instance, although there are ideas to make that special allowing \`noexcept\` to be applied much more widely. Banning templates in C++, in any domain, is just bad practice, and so is unlikely to factor into any design choices.
to be fair, there is relatively a lot of stuff already trying to get pushed in
Nice I'll take a look at all of them thanks a lot. The fact is that I already did that with node, but it was a lot more easier. If I can't come up with a solution with your links, I'll try to figure out to do it in another way. Thanks !
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/anuvvm/can_anyone_help_me_to_create_crazy_8s_with_c/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/anuzn7/want_to_learn/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
After looking at crow, I think it's abandoned, but there are more links to other such libraries in one of the Issues on GitHub.
And the upcoming meeting will be reevaluating contracts. Turns out people don't like that violating a contract silently leads to UB.
There are contexts where exceptions (and `std::terminate`) are never acceptable, such as kernel, safety-critical or FFI code, or on (embedded) platforms that don't support exceptions. There are also legitimate reasons for avoiding templates, such as if binary size and/or compilation time are a priority, or if there can't be any name mangling. Since `to`/`from_chars` can be implemented without templates and with a rock-solid no-exceptions guarantee, it would be unnecessarily user-hostile not to do so. Again, it's trivial to write a wrapper with your preferred interface. Unrelated FYI: The "fancy pants editor" won't let you use Markdown.
Eeek! You mean like here^[1](https://en.cppreference.com/w/cpp/language/attributes/contract): &gt; Evaluation of the predicate must not have any side effects other than modification of non-volatile objects whose lifetimes begin and end within that evaluation; otherwise the behavior is undefined. I guess it would be impossible to make it ill-formed since there's no practical way of checking for side-effects.
Not books. Lynda has some C++ courses and you may have access with your university. Otherwise YouTube or wait to learn it in class.
I'm able to reproduce on two different computers (Both Gentoo Linux) with Chromium (The open source version of Chrome) with uBlock. I wasn't able to reproduce with Firefox (With uBlock) nor with an Android with Chrome (which does not support extensions). Using Chrome with Windows ten, I can't reproduce there either. *shrug*. It's probably not something you need to worry about, who knows where the bug might actually live. I know that when I turn uBlock Origin off on both linux chromium browsers, the yellow one shows back up. So at least it's happening on more than one computer. But since it's apparently very specific about, well, something, there might not be enough information to help fix the problem.
You didn't mention any of this in your original post
Best of luck to you. It's very difficult to learn it on your own without an impetus. If you aren't trying to solve a specific problem or create a program you find interesting, then you might end up getting lost in trying to connect all the dots. This is where a teacher/professor would help, with pointing you towards the important information. Unfortunately I don't know any pure beginner resources. It might be better if you started off with something like Racket and [HTDP](https://htdp.org/2018-01-06/Book/)
In Swift the `Character` type is actually a series of code-points representing a complete grapheme cluster.
Check out the Poco libraries. It has a Http server module. Remember that you have to crosscompile for Raspbian.
"Refactoring sucks. The end.
I was thinking about the second part, because I wasn't aware of the first part. Both parts have an understandable rationale, but I also understand people with the "don't make my functions so easily UB" point of view. Fingers crossed there's an actual consensus on what contracts should be. Because the worst case scenario is the paper named "Pull the plug on contracts" being accepted as is and contracts getting pushed back another 3 years.
A good book is Bjarne Stroustrup's *Programming: Principles and Practices Using C++*. Bjarne Stroustrup is the original implementor of C++ and is actively involved in its evolution today. You should know that the C++ language has evolved greatly, and C++11 is considered a major update that introduces many ideas of "modern C++." Many C++ resources may not teach the best practices. There's no guarantee that your professor is going to teach idiomatic modern C++. Check out https://stackoverflow.com/q/388242/8887578 for more recommendations of good C++ resources. 
Thank you for sharing. 
I'm sympathetic to the view that if it was ub before you put in a contact, is still ub when you turn a contract off. Contracts are not error checking. Now there's language that may imply that turning off a check may cause another check to be unintentionally elided, the working draft is silent on this afaict. This would cause checks that your think are on to be silently bypassed. But it seems to be is relatively simple wording to assure this doesn't happen -- you can optimize code based on an assumed check, but you can't elide nested checks.
There's some new information that might imply a different outcome from last vote, some from Facebook and possibly even Google, that would imply a modified version of TS is an acceptable (and possibly even only option).
You can fake them already with macros and \`switch()\` [https://github.com/g-pechorin/cpp-generators](https://github.com/g-pechorin/cpp-generators)
 auto x = reinterpret_cast&lt;T***&gt;(tmp); Good god.
\*\*Company:\*\* [Coreform LLC](https://www.coreform.com) \*\*Type:\*\* full-time and internship positions are available \*\*Description:\*\* Coreform LLC enables better engineering simulation through better geometry. A new highly accurate and performant approach to finite element analysis (FEA) engineering simulation is to run simulations directly on smooth splines, the building blocks of computer-aided design (CAD) models. Thousands of academic papers have been published since 2005 investigating this approach, and Coreform has invented a new unstructured spline type to enable commercial applications. Coreform Analyze (beta) is the first commercial solver natively built to run on a smooth spline basis, and could open the door to a future of isogeometric analysis (IGA) for some engineering workflows. In IGA, data conversion from CAD to an FEA mesh is eliminated, replaced by a single geometric definition suitable for CAD, simulation, optimization, and manufacturing. This is of significant value to the automotive and defense industries. Our founders are well-known and respected both professionally and academically in these fields. We are hiring C++ developers to help us build our end-user product. We expect to train you on our unique way of doing things, so our ideal applicant is a recent university graduate with under five years of post-college professional programming experience. \*\*Location:\*\* Provo, UT, USA. \*\*Remote:\*\* Yes, though our strong preference is to have you come onsite for some period of time for training \*\*Visa Sponsorship:\*\* No \*\*Technologies:\*\* We use C++ 17 extensively. We are open to using features in C++20 that are implemented in both GCC and clang. 3d graphics and openGL/webGL experience is strongly desired. We also value HPC experience. For more details on the job and desired qualifications [see our job posting](https://coreform.com/about/careers). \*\*Contact:\*\* matt@coreform.com
Yup saw the book list, gonna start reading one of them, as a senior all I have is time 
Boost.Beast. HTTP server example: https://github.com/boostorg/beast/tree/develop/example/http/server/sync
Yes, that works fine, and should be preferred. I have a habit using the standalone fences wrt my work on the SPARC. Here is an interesting discussion: [https://groups.google.com/d/topic/lock-free/A1nzcMBGRzU/discussion](https://groups.google.com/d/topic/lock-free/A1nzcMBGRzU/discussion) ;\^) &amp;#x200B; The SPARC would have to issue a MEMBAR instruction for acquire, iirc #LoadLoad|#LoadStore for every call wrt the integrated memory\_order wrt the std::atomics.
&gt; I've used the default hash for each of the maps which seemed to be the most reasonable choice to me. It's better to use the same hash for all hash maps to avoid any extra bias from the hash in the results. You don't want to compare the performance of the hash function (which can vary on each compiler with `std::hash`) but of the collision resolution scheme.
Check out the talks from all previous CppCon's on YouTube. There's some sort-of "beginner-talks" there as well, like some of the keynotes - they provide a higher-level overview of how to code good modern C++ nowadays and how to properly use the language, with modern types, value-semantics, and not raw-pointers and `const char*` and all that stuff. Perhaps also Kate Gregory's talks are good - she's actually teaching how to properly teach C++ nowadays, but I think it'll be on a level understandable to someone coming from Java and you'll learn right away how to judge if a book/video/tutorial etc. is good or teaching bad C++!
It is more concise, and should be preferred. I have a habit wrt using standalone membars due to my programming experience on the SPARC... However, that arch can tend to always execute the acquire barrier, even though it is not needed if flush() returns a nullptr, or even something special wrt marked nodes. The SPARC will bust out its MEMBAR instruction with a #LoadLoad | #LoadStore to handle the acquire...
Slides: https://www.slideshare.net/mobile/ClareMacrae/quickly-testing-legacy-code
¯\\_(ツ)_/¯ If it's just on this obscure page and doesn't cause any serious issues elsewhere, then whatever. Funny, I spent extra time making the site extra lean and snappy, with exactly zero user tracking scripts, ads, cookies, popups or other in-your-face annoyances and then uBlock does this to me :D
Removing the fences and relaxed atomic's would \_not\_ work at all, period, for this is a general purpose semaphore. Altering the position of the membars in the code with standalone fences would ruin everything. Also, weakening any membar would ruin everything all over again. Study the code very carefully. Also, study this: &amp;#x200B; [https://www.haiku-os.org/legacy-docs/benewsletter/Issue1-26.html](https://www.haiku-os.org/legacy-docs/benewsletter/Issue1-26.html)
It's technically two statements still - C doesn't require newlines to separate statements. It's the same as: void whatever () { } void (*x)() = whatever; Here `void (*)()` is the type of x. People normally use typedefs for function pointers because they wrap the variable name in a confusing way, but it's not required.
Why? Is the logic contained within the following link, incorrect?: &amp;#x200B; [https://www.haiku-os.org/legacy-docs/benewsletter/Issue1-26.html](https://www.haiku-os.org/legacy-docs/benewsletter/Issue1-26.html) &amp;#x200B;
But doesn't this mean you will be compiling Linux executables instead of Windows? 
Don't take this as criticism, but is there a reason you chose a GPL license for it? I thought (though I could easily be wrong) that BER was mostly used by commercial vendors these days, rather than the general open-source software community. For example in SNMP. And it's highly unlikely a GPL library would be used by such vendors, except for in test code or in things they don't release as part of their product externally. So I was just curious who your target audience is, in terms of other people using and contributing to the library.
Yes you will be, if you want it to compile an exe for Windows you would need a Windows compiler, I have also heard that Linux has some compatible compilers that can convert to exe but I haven’t personally used them.
Yes, people have been asking for that, although it would require some amount of compiler work ("lots", according to my vague understanding).
Indeed, I want to prepare a talk: "charconv: C++17's Final Boss".
Yes this is a valid point, the library is my first open source project. I will spend some time to research and consider a better licence option. Thank you
Intrinsics aren't opaque to the optimizer - that's the whole point of intrinsics (unlike asm).
Applied suggested changes. If you have anything else you would like to point out it would be helpful.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/antiwt/http_listener_for_app_settings/efwohy0/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/anx4ss/new_dog_here_in_2nd_semester_i_have_object/efwoj20/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/anvg6e/how_to_start_learning_c_with_near_zero_previous/efwok8u/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
This question is off-topic for our subreddit but I wish you the best of luck - C++ is indeed a valuable language to learn, and I started learning it around the same time as you.
Just removed variables a month ago. Is there anything else that would be considered as modern CMake.
As for the why, I am also required to use BER for my day job. I was not satisfied with the options available (poor interface, slow, lots of memory allocations) so I decided to try my hand at writing my own library.
Sams Teach Yourself C++ in 21 Days (5th Edition) &amp;#x200B;
Cool I’ll delete the post 
&gt; However, if we do it this way, every single use of zit-&gt;first causes a heap allocation! [Clang optimizes this away](https://godbolt.org/z/G9j-dQ), but I think it's the only compiler that implements this optimization. But `arrow_proxy` is the better way to go regardless.
The algorithm described in that link is literally exactly what I suggested. It has no explicit fences and uses plain (non-relaxed) atomic operations in the places the OP's code has them.
Oh yes, the audio stuff will definitely be in JUCE, that’s too good to ignore. But I want to try something different with the GUI :)
Why does clock_gettime clock block? I tested it extensively with CLOCK_MONOTONIC and cpu pinned a few months ago and don't think I noticed that . was trying to time clock_gettime latency actually (with __rdtsc) and saw some lag but I think it was only from cache issues on a context switch. It was using the the vDSO function and wasn't making a syscall (not in strace). Can you point to more information?
Fwiw, this special "fast" semaphore allows one to skip calls into the base, "slow", mutex/cond semaphore. Read here: &amp;#x200B; [https://www.haiku-os.org/legacy-docs/benewsletter/Issue1-26.html](https://www.haiku-os.org/legacy-docs/benewsletter/Issue1-26.html) &amp;#x200B; Also, it is 100% standard within C++11. No need to use system specific primitives.
That is fine. Imvvho, one should try to know how things are working under the covers, so to speak. The standalone fences can be "instructive" wrt showing exactly what is going on. The position of the membars for an acquire/release relationship is critical. The atomic ops with membars other than relaxed are fine, but one needs to know what is going on. Where does the membar exactly go wrt std::exchange(foo, mb_acquire)? The stand alone fences can help show one exactly where they need to be.
It seems like NanoLog's logging thread is flushing after every line by using std::endl instead of \n. It's obviously not intentional because they then do an explicit flush for critical log entries just below which is redundant after using std::endl. https://github.com/Iyengar111/NanoLog/blob/40a53c36e0336af45f7664abeb939f220f78273e/NanoLog.cpp#L150
&gt; still needs the acquire/release relationship Plain atomics have an acquire/release relationship (in fact a stronger relationship). &gt;The standalone fences can be "instructive" wrt showing exactly what is going on. They are tricky to get right, depend more on the particular hardware you're targeting, are pessimistic on some machines (e.g. x86), and are harder to optimize. But sure, they might be instructive in someone trying to learn the ins and outs of a weak memory model machine. &gt;Where does the membar exactly go wrt std::exchange(foo, mb_acquire)? For 99.99% (Yes, at least 4 nines) of users, they shouldn't pay attention to this at all. If you profile it and it happens to matter in a place on a particular piece of hardware you're targeting, maybe, but it doesn't help in this example.
Noob question - in the article it mentions &gt;Notice that in C++17 we can use CTAD and structured bindings to rewrite this as &gt; for (auto&amp;&amp; [k, v] : zip_range(keys, values)) { &gt; std::cout &lt;&lt; k &lt;&lt; ": " &lt;&lt; v &lt;&lt; "\n"; &gt; } &gt; I don’t recommend it, but you can do it. What is the downside of doing this? 
Would it be possible to avoid the dynamic allocation by embedding the pair inside the deleter of the `std::unique_ptr`? Correct me if I'm wrong but I think it is allowed to have stateful deleters, so you could technically use it as a storage instead of newing.
Note that this optimization is only valid from C++14 up, but it looks like Clang also does it for C++11. I was unaware that this optimization was allowed at all, but 5.3.4/10: &gt; An implementation is allowed to omit a call to a replaceable global allocation function (18.6.1.1, 18.6.1.2). When it does so, the storage is instead provided by the implementation or provided by extending the allocation of another new-expression. Which I find surprising, because `new` may throw, which to me is part of the program's observable state. What's more, even declaring an overload for `operator new` is not enough to prevent the optimization. The only way I found was to have a `try` around the `make_unique`, with a `catch` having something with a side-effect like `printf` _as well as_ a ` throw;`. I'm impressed by Clang's optimizations, but also slightly uneasy.
All your arguments that apply to new also apply to a move or copy constructor. Special wording is present to make the optimization doable in practice, and simply put you shouldn't write code where you expect constructors to have a side effect (that wouldn't be cancelled by the destructor). The same is true about new, you should write programs that expect new to do anything but grab memory (non placement new) and construct the object, so it should be ok for the compiler to optimize whenever the object itself is not needed.
Jut like `auto` under specific circumstances can deduce an unexpected type, so can CTAD. Arthur says that's a reason to never use CTAD.
There's no downside.
B..b..but I want to be able to declare variables at places rather than the top of my coroutine (especially if my types aren't default-constructable!). And yield from the middle of an expression. ): It is somewhat impressive, though. If C++ had a slightly more advanced macro system (à la Rust procedural macros), we could implement real coroutines with it. Until soomething happens, stackful coroutines are the way to go.
Please ping me if you do.
`libformica` will be a thing.
You are correct that this is probably a bug in NanoLog. For low latency logging, IO speed doesn't matter as long as it happens in a background thread. All that matters is that LOG(...) returns to the caller as fast as possible. So that slow flush shouldn't affect op's results at all.
I don't necessarily disagree. The only case I knew of that ignored the as-if rule was copy/move elision, but global allocation functions are apparently another one.
Weird usecase benchmark guy over here. Is there a reason your `class Iter&lt;bool&gt;` isn't default constructible? This is the usecase: https://github.com/Valloric/ycmd/blob/master/cpp/ycm/IdentifierDatabase.cpp#L73-L81 
&gt; So that slow flush shouldn't affect op's results at all. Obviously it doesn't affect their results otherwise their results wouldn't be their results would they?
Anyone considered building an asynchronous logger that runs in a separated process instead of a thread, so it can be resilient to process crash? The logging process can formats and flushes arguments sent with shared memory. Want to know if this is a bad idea.
What you may also want to add is a partial spinlock version to be used for paths where you know it is possible that the current locker may unlock in only a few hundred cycles.
coroutines are very expensive to the point of not being worth using
A function call, like the implicitly generated one to `operator-&gt;`, is a sequence point (in pre-C++11 parlance). There are dozens of reasons why using a function-local static is horrendously bad. Breaking the sequencing rules isn't one. ---- The simplest way is to not provide `-&gt;` at all. The new Ranges iterator concepts do not require it. Structured binding obviates the need to use `.first` and `.second`. And a generic `zip_iterator` would use something like `tuple` anyway, which has no real named members to use with `-&gt;` in the first place.
What is going to be the advantage over crash handling like g3log does? You'll still have to have some kind of locking mechanism to make sure the logging process always reads valid data. I'm sure that it could work, I just don't see the advantage over running in a separate thread with crash handling.
Advantages: 1. kill -9 your-app 2. better resource control: use cgroup to limit memory usage of main application/other processes, so the logging process always have enough resources to process logs. Also applies to CPU so that logging process can be pinned to a separate core to improve cache locality/reduce interference to main process. Actually such kind of "shared memory with a foreign process to improve crash resilience" technique is already well-used in cases like gaming server/HFT. I've built a prototype and used it in some side projects. It's a lock-free version and runs blazing fast.
Plain atomics without an explicit membar default to seq_cst. That is way too strong. Users should be paying attention to this! Knowing how everything works is essential to not only getting things right, but for performance and scalability as well.
The only way I can think of adding a spin is by using CAS. Not sure how much this would by you, need to check it out. This is basically a bakery algorithm at heart.
I guess I disagree. IMO one should always use seq_cst unless (a) you are targeting a specific kind of hardware where it matters and (b) you have profiling data indicating that it matters in that place. As of aarch64 all of the common platforms have "cheap" seq_cst instructions that don't require full barriers. (Yes, there are some Sparc and POWER machines in the world, but I'd wager most of us aren't targeting that, and I hope hardware designers on those platforms fix their ISAs, particularly that almost all languages that aren't C and C++, like Java, only have seq_cst atomics) And in this example in particular -- there's a condition_variable, that throws absolute scale out the window.
(Oh and I think on ARM, Sparc, and POWER the seq_cst operations here are equivalent to the explicit barriers, and will be better on x86 and amd64 than the explicit barriers)
Great work Sam. I second the use of perhaps an MIT style license (Boost). Do you have any benchmark comparisons against other solutions?
People use shared memory for IPC... to this day?! Disclaimer: my work uses it in a part made 15-20 years ago. I would expect that by now there's a higher-level abstraction (on top of shared memory, why not) as a norm?! (On Windows, there is, the thing they call DCOM).
Kicking the disk in the butt too often affects the system usually. What if the caller needs the disk? 
For performance-critical cases shared memory is still the only choice. Generally we implemented a lock-free writer-first SPSC queue on it. It's insanely fast yet easy to use as long as we call APIs of this queue - writer only need to perform two CASes to put a log entry to remote process on fast path.
I thought heap allocations can't get optimized away? That's a system call, how can a compiler optimize away something like that? 
 auto x = make_shared&lt;int&gt;(); sure hides a lot of intention. 
Then why is it a problem to have them in constexpr code?
There's a x86 instruction for that. Or you can use the provided functions like `mbstowcs_s`
http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2013/n3664.html
&gt; it is just a wrapper around clock_gettime which can block for hundreds of nanos. On my Linux system (and many others, if not the majority), clock_gettime goes through the vDSO, and a single call to it costs ~20 nanoseconds. Could you please elaborate?
one expression == one liner, you have posted what showed me the way. I will not be going into "litigations" on what is the "one liner" here :)
I know! But it works :)
I guess in all our codebase nobody ever needed that... According to the standard default constructed compared to end() must be true, and adding that would make iterating a bit slower
Does c++ have a concept of a system call?
Yeah, one would expect that a higher-level IPC would do the same in a "fire-and-forget" mode.
Well, to be fair, that part of code can be rewritten with a lambda, so the default constructor can be avoided.
POSIX queue is not the best implementation for this case where a flusher process periodically gets all messages. We used linked list of memory blocks to implement it, so getting all messages is simply a CAS operation on head pointer in the best case.
[Linux OOM killer has three modes](https://www.kernel.org/doc/Documentation/vm/overcommit-accounting). The default one is "heuristic", where it might even kill another process to give me space. Same thing might happen in the other mode. But there is also the "no overcommit" mode, where one won't ever be killed on access (well, they will be, on accessing NULL 😁). For example, [Postrges docs discuss using that mode.](https://www.postgresql.org/docs/9.3/kernel-resources.html)
Thanks Paul, hope you are enjoying yourself. I do not have any other benchmarks, due to the liscenes required for such libraries.
Huh? System calls can get optimized away if the compiler can prove that they're not called, just like any other function. Also, `new` is treated specially in this regard to allow the compiler to optimize it away. C++ had no notion of system calls.
Nice! Haven't looked at the code, but this will come in handy once I need an ASN.1 serializer - which will happen at some point in time. Looking forward for you to relicence it first, though. Boost, BSD, Zlib license would be sensible options IMO, but it's all up to you of course! :-)
Thanks!
I've planned it: https://github.com/martinus/robin-hood-hashing/issues/7 but don't know yet how to best do it... I don't want to duplicate code 
Compilers have been incorectly removing explicit calls to memset for years.
Yeah, I was talking about a with observable behavior, I should have been more clear.
Just FYI, the spdlog usage in the benchmarking code you shared is not correct. It uses loggers and sinks, loggers should be exposed to the callers, and sinks are internally called by loggers when they flush. The spdlog readme has a simple example of async logger.
Why should one always use seq_cst? That really damages performance. Heck, on x86 it has an MFENCE or a dummy atomic RMW for a standalone fence with seq_cst. Man that is bad. Check it out: https://godbolt.org/z/7MTAR2 notice that nasty mfence in xload? YIKES! I am wondering why would you advise people to just stick to seq_cst, and stay away from the tools that can actually allow for something to scale? Targeting a specific platform has absolutely nothing to do with it. Seriously, this is an abstract memory order. Btw, the condition_variable is contained within the "slow" part of the "fast" sema algorithm. The atomic RMW's can cleverly skip calls into this slow condvar. Afaict, you seem to be a little bit, sort of "afraid" of a relaxed memory order, why? Learning how the memory order works _is_ very important. Why just fall back to _everything_ seq_cst, then realize that it does not scale all that well... 
I have used boost::asio in the past (which also mentions a big switch statement underneath), since networking ts also may not to be making it in 20, I'm not planning to rewrite anything in asio :/
I've now added default constructible iterators in version 3.1.0
Also, checkout what happens to a simple store using seq_cst on the x86: m_head.store(nullptr, std::memory_order_seq_cst); https://godbolt.org/z/XLLGVT It magically turns a simple store into a damn XCHG!
Hahaha! Well, it is in some way, but the driver is still one of these build systems such as CMake or Meson :D
You need to break it apart into two separate classes. An auto-reset event, and manual reset event. The former can just signal a single thread. The latter basically needs to broadcast. You are trying to emulate the windows variety, right? The wait(true) and wait(false), as mentioned by tvaneerd, is a disaster just waiting to happen.
Imho, global new and delete don't violate the as if rule any more than optimizations that reduce the runtime or stack usage. In theory that is a different story with custom replacements but I'm very glad that the majority of programs doesn't get pessimized just to cater to programs that abuse that capability. 
If it isjust rd tsc and offset please tell me how it handles frequency drift and ntp adjustments.
From my experience with seeing coroutines getting used in production code, the minor savings in amount code written were not worth the hassles. In particular, it's extremely easy to capture a reference that might no longer be valid when the coroutine actually runs. I saw two different engineers make that error in two very different ways on the same 100 lines of code within a few months, and we were all alerted to the possibility the second time and it still got through code review. Boost coroutines also had the unfortunate "fixed stack size issue" at the time, though that seems to have been cleared up. If I had to do it again, I'd have a `struct` or `class` that represented the current state of the calculation and had a state machine. This has the additional advantage that you can interrogate the current state from another thread or process. Don't get me wrong - I think coroutines are promising, and I'd be interested in using them again - with a better discipline and methodology, and with a final "production" version of the coroutine library. However, compared to glorious things like concepts and metaclasses, coroutines are fairly low on my list. 
boost::context, make_context there are already so many ways
Under as if clang can do it in C++03 if there is no overload. "May throw" means may not, and code that never throws behaves as-if it may throw and did not. That simply permits compilers to also skip any global overload of new/delete.
Great! Thanks for that.
Folks interested in this should really look at Stepanov's [EoP](https://www.amazon.com/Elements-Programming-Alexander-Stepanov/dp/032163537X/ref=sr_1_1?ie=UTF8&amp;qid=1549535126&amp;sr=8-1&amp;keywords=elements+of+programming+stepanov), which has the algorithms we actually use. For example our implementation use the triple reverse version for random access iterators.
So it goes. New features in C/++ seem to mean cleaner and more consistent ways to do the same things. 
Said offset is computed by the kernel, it takes into account clock drift of any kind. It's periodically updated by the kernel.
&gt; notice that nasty mfence in xload? YIKES! That's because you used explicit fences, rather than associating what you are doing with the actual data in question. A sequentially consistent load on x86 or amd64 is an ordinary load, and on aarch64 is ld.acq. &gt; I am wondering why would you advise people to just stick to seq_cst Because I don't advise people juggle razor blades, and seq_cst atomics are cheap enough on most all of the platforms that are relevant today. Sure, if you're writing code for a big POWER cluster like Summit, where sequential consistency is super expensive, this might not apply to you. That's not most people. Note that is seq_cst *atomics*, not seq_cst fences. Achieving cheap sequential consistency on all three of x86, amd64, and aarch64 depends on being applied through the actual loads and stores (mov and xchg on x86 and amd64, ld.acq and st.rel on aarch64). &gt;Btw, the condition_variable is contained within the "slow" part of the "fast" sema algorithm. The slow part gets engaged whenever there's any contention at all though, so it still matters. Luckily Olivier Giroux has been busting his but to get the tools in the standard necessary to make implementing something like this easier. ( http://wg21.link/P0514 ) &gt;Why just fall back to everything seq_cst, then realize that it does not scale all that well Whenever I've tested this it was almost completely irrelevant; having two cores touch the same cache line is crazy expensive regardless of what instructions you use. Admittedly I didn't test on the kinds of hardware where full seq_cst is expensive.
Specifics?
well you have to save all registers, floating point contexts and worse - signal states, which require a kernel call on Linux. A single coroutine context switch can go into microseconds. More here: https://rethinkdb.com/blog/making-coroutines-fast/ 
Yes, seq_cst stores on x86 and amd64 are `lock xchg`. Yes `lock xchg` can take ~19 cycles vs. `mov mem, imm` can take 1 cycle. Having 2 cores attempt to write to the same cache line costs way more than 19 cycles. I would rather see the time one could spend fiddling with relaxed atomics reducing contention in their data structures, at least on the ISAs I think most people target (those being amd64 or aarch64).
Only that in vdso the "kernel" is your thread. It's your thread who computes that on behalf of the kernel. [Here, munch on this code](https://github.com/torvalds/linux/blob/master/arch/x86/entry/vdso/vclock_gettime.c) and stop vomiting your speculation around
Good article!
There is no such container in standard library.
No, the offset is computed in the (periodic) interrupts of the Linux timekeeping threads, your thread only reads said offset. Will you answer my question or should I just assume that your claims are baseless?
Though you can do this yourself via a hash table whose entries are threaded by a linked list, and sorting that list. Insertion would be O(n) though if you want to maintain sorted state.
Do you see vdso_fallback_gettime? You are looking very stupid 
Claims dismissed. Mr Bucher, is that you? :)
There are many ways to do it, you don't have to treat it like a preemptive interrupt. When the cooroutine calls yield, that can be treated like a function call with the caller responsible for saving some things. In fact it could be no more expensive than a function call plus stackpointer update. The real problem I see is how to handle the stack. If the coroutine has a full stack, that's a lot of ram. Meanwhile spaghetti stacks and growing stacks require compiler support.
No but interesting how doxxing becomes fast the last resort for people who dont have skills. Good luck in life, you look like a very good person /s
Direct link to slides: [https://slides.com/onqtam/faster\_builds](https://slides.com/onqtam/faster_builds)
Thank you for your answer
Thank you, but i add and remove a lot of element so I prefer having O(log(n)) for adding and removing than having O(n) for adding and O(1) for removing. 
[Here](https://github.com/torvalds/linux/blob/master/arch/x86/entry/vdso/vclock_gettime.c) From time to time the call has to sync up with kernel and that can be expensive
There is no such thing in the STD, and I don't think there actually exist practical data structures that with these guarantee. Note that complexity and speed are only very loosely related, `O(1)` doesn't mean fast. (after all `wait(10y);` is `O(1)`). If you want to find the best data structure for what you want to do, you'll first have to be very specific about what you want to do and on what kind of data. If you want `O(1)` insertions and deleting, the best probably is vector (vector is often the best for anything you can fit in RAM). It isn't always sorted, but sorting it just in time might just work, depending on why you need it to be sorted.
That's for something called stackful coroutines (or fibers). The Coroutines TS is stackless.
&gt;What about "sequence"? Bash has &gt; &gt;seq &gt; &gt;. Although C++ already has [std::integer\_sequence](https://en.cppreference.com/w/cpp/utility/integer_sequence) so it could confuse a lot of people
For an easier read, The Pragmatic Programmer is a good book and IIRC calls this the flipping hands technique.
not true at all. if allocations happen then the stack cannot be optimizd away in fact this is one of the resons google considered coroutines TS unusable
You are correct and I forgot to mention this as a modification. I think that tool was written by the Nano dev for an older spdlog version as it didn't compile directly. I had to change: spdlog::set_async_mode(1048576); auto spd_logger = spdlog::create &lt; spdlog::sinks::simple_file_sink_mt &gt;("file_logger", "/tmp/spd-async.txt", false); to auto spd_logger = spdlog::create_async&lt;spdlog::sinks::basic_file_sink_mt&gt;("file_logger", "/tmp/spd-async.txt"); I believe this change is in-line with the spdlog readme for a basic async logger. spdlog::set\_async\_mode doesn't seem to exist in the current spdlog version. 
That's very different than what you had said previously. Allocation, yes. Kernel call to switch contexts, no.
&gt;og This is not the case for my requirement, which is why I sent logs to /tmp/ mounted in ram vs a disk. There may very well be loggers out there that are very optimized for the write portion, but that's not relevant for my benchmark and I am not sure the candidates I reviewed claim to be the best in that regard either.
This change is new one, that's true. But I wasn't pointing out this mistake. The spdlog architecture has loggers which are used by your code to log stuff. These loggers use sinks in the background to actually flush the logs. If sinks are directly called, the logging call might not go the correct way. And I think that's the reason for performance difference. I'm on mobile so can't paste code, but check out the "asynchronous logging" section in the readme. It uses a factory to create the logger. Just a suggestion, it might not even change anything, but it's the correct usage.
I have a real CONTROVERSIAL OPINION. Maybe the C++20 Standard should instead be C++21? With some additional time, maybe they could also pass in papers that would not make it if 2020 was the deadline? If not, we would end up with C++23 being nothing more than a major bug-fix full of things C++20 should have had. 
I think you are talking about this sample: #include "spdlog/async.h" #include "spdlog/sinks/basic_file_sink.h" void async_example() { // default thread pool settings can be modified *before* creating the async logger: / / spdlog::init_thread_pool(8192, 1); // queue with 8k items and 1 backing thread. auto async_file = spdlog::basic_logger_mt&lt;spdlog::async_factory&gt;("async_file_logger", "logs/async_log.txt"); // alternatively: // auto async_file = spdlog::create_async&lt;spdlog::sinks::basic_file_sink_mt&gt;("async_file_logger", "logs/async_log.txt"); } I used the alternate. However, I didn't increase the thread pool size. Perhaps messing with init\_thread\_pool could improve performance. My understanding is that spdlog will block when it runs out of it's queue space. I suspect increasing this can improve results. However, this goes against my "unaffected by spikes" requirement as I don't know the required size ahead of run time.
Are you 100% sure it does not save signals across coroutines? that does require a kernel call 
Yes I have read about the spikes issue earlier. There is an article by the creator of g3log. I think it depends on the use case really, some would want no latency spikes, some want guaranteed logging. Also sometimes usage will be uniform frequency of log calls so the queue never saturates. Would be interesting to see how it varies with number of backing threads queue size though.
Two essential websites to start with. [Learn CPP](https://www.learncpp.com/) [CPP Reference](https://en.cppreference.com/w/) I also suggest you to buy or download (I prefer physical books over ebooks for personal reasons) The C++ Programming Language 4th edition by Stroustrup himself and Effective Modern C++ by Scott Meyers.
Why would you call IO on a hot path?
R is great for plotting data. And easy to use
For doing stuff like this, I feel C++ is not really suited. This is way easier to set up in for example, Python. Also, it might be handy to generate the data in C++, output the result, and then plot it using GNUplot. 
sphere is right. Coroutines don't concern themselves with concurrency features; they are oblivious to that. We've even had an SG1 issue to add a note to that effect. And claiming they care about signals is just preposterous.
Hah, I was going to suggest a method I would have called "double reverse" (inspired by an in-place algorithm to reverse the words in a string) and thought, "Huh, how could a *triple* reverse work?" But, of course, it's just that you call "reverse" three times. I wonder how small the array has to be (or how expensive copies have to be) before a move/swap-optimal algorithm becomes worthwhile. Probably not super common in practice.
Yeah, i was considering learning Python at some point. So this is a good way to start. 
Correct me if I'm wrong, but isn't R a simplified version of Python. And how does it exactly interface with c++. Could you post a link to a tutorial page? 
As others said I suggest Python or R but if it must be done with (somewhat) C++ there is [matplotlib-cpp](https://github.com/lava/matplotlib-cpp) It still calls python but provides a C++ interface, though I am not sure about the windows support
Aha there comes the cavalry. You have more flair than politeness, I can see. Perhaps Google is the only one [that can fuck up with the committee](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0973r0.pdf). Money talks I guess. I will leave the academic echo chamber that is this sub. 
Is it supported on Linux?
That's the best way. You could also simply output a csv (and plot in excel) or an html... 
I'm not long-term sold with the assertion that for-each loops are a thing of the past. With the addition of C++20 ranges, it became really natural to do stuff like this. ``` // display a miniature (color reversed) of the first 4 images in myContainrorOfImages for(auto&amp;&amp; miniature: myContainorOfImage | reverseColor | resize(0.2) | take(4) ) { miniature.display(); } ```
If only you actually understood Google's objections... :V And if only you knew how to check how NBs voted on merging the TS last time... :V
Interesting, but ultimately trying to solve template issues in C++ with more complex syntax is going to be futile and met with a lot of backlash.
I'm sure you'll be back soon enough under another alt, like you always have been. See you soon 😘
Normally I use matplotlib in Python but I've tested in Linux and it was fine. From what I remember the Makefile was pretty barebones and assumed Linux-like hierarchy for the location of Python. Also it was hardcoded for Python2 though changing that wasn't a big problem
Don't be scared, and you should not be. After you start learning C++, you will enjoy its powerful and performance which you can hardly get from Python. C++ is great, Python is great too. Mastering both C++ and Python will make you feeling great!
mind == blown, where the hell was this blog post 2 years ago when I was struggling with my proxy type??
k goodbye
R is completely unrelated to Python. R is a programming language with a heavy focus on statistics. Honestly, I can't recommend using it as the language itself isn't very good, and the libraries have a tendency towards being poorly documented and aren't very consistent in how they work.
I really like how the website author stares at you continously while you try to concentrate on the article.
For someone wanting a practical introduction to C++ wouldn't "A Tour of C++" be a better book than "The C++ Programming Language"? Sure, the later is more detailed, but it is also way more to read, and much of it is probably unnecessary for the task at hand.
He's got a creepy stare too, like he's watching intently as you drink something he's poisoned.
There is \[gnuplot-iostream\]([https://github.com/dstahlke/gnuplot-iostream](https://github.com/dstahlke/gnuplot-iostream)) library to plot with gnuplot, it claims Windows support but with caveats. 
aha sure buddy
https://linux.die.net/man/1/gdb
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/ao4e3v/time_complexity_of_algorithm_in_cpp/efy3wul/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Not really.
I'm not sure what are you trying to achieve. First of, you can't calculate time complexity by simply measuring time, it requires a lot of tries and some approximation methods. There are several libraries, that will try to do that for you, for example Google Benchmark: [https://github.com/google/benchmark](https://github.com/google/benchmark) &amp;#x200B;
Wouldn't median numbers be more meaningful?
It would be nice to have this integrated into the tables over at cppreference.com! :-o
Back when I was writing medical software that needed to display plots quickly (like EEG), I used Qt for a while. I think I worked off of: https://doc.qt.io/qt-5/qtwidgets-painting-basicdrawing-example.html
&gt;I agree with Arno that range-based for loops don’t generalize very well. All the examples of where for-loops "don't generalize" work very well with Ranges, which is what the author goes on to recommend, contradicting himself in the process. &gt;There may be time when it happens to apply (the loop body is at the same abstraction level as the loop construct), but if we write code that depends on the fact that it happens to apply, we lock that code into that needless constraint and make it harder for us to refactor or generalize the code later. Following this logic, we should replace all statement blocks with functions, to "remain on the same abstraction layer." On the point of refactoring, I think some people have to say something about that: &gt;\#1 problem in big code bases is entangled code dependencies. If you make code too generic or extract code too soon, you end up with more dependencies. Code used by 2+ call sites tends to eventually bloat with complex control flow. Bad performance, hard to understand and modify. ([source](https://twitter.com/SebAaltonen/status/1080077641477226496?s=19))
It may be worth looking at whether the median and average values are close together. However, using an average allows me to include worst cases for each percentile and I am interested in consistency. Median by itself isn't quite as good to show that in my opinion.
It's not an explicit system call, but an invocation of \`new\`. Strictly speaking, you are right, and optimising away this call does incorrectly prevent side-effects from happening. However, these are not side-effects that are relevant to your application. From perspective of C++ semantics, an allocation followed directly by deallocation has no effect, and can be transformed. &amp;#x200B;
I recently did some [performance work](https://github.com/tcbrindle/NanoRange/issues/42) on the implementation of `rotate` in NanoRange. From my testing, the "block swap" algorithm (recursively swapping ranges of decreasing size) is fastest for random-access iterators. GCD rotate, as used by libc++ for RA iters, is theoretically good (fewer writes) but is not as cache-friendly and thus slower in practise. The three-reverse algorithm, despite its aesthetic beauty, turned out not to benchmark too well, at least for me. (If anyone else fancies contributing some benchmark numbers to that bug report, I'd be very interested :) ). 
One can do a lot of crazy stuf with short-lived proxy types. In the simd library I wrote for my projects I use them to do stuff like this: x[simd_lanes&lt;0,2&gt; = {1, 8}] ...and this gets compiled to a single SSE instruction. 
What does valgrind tell you? Have you checked out r/cpp_questions ? 
Is there a question, or are you just presenting code that has a segmentation fault? 
I would not completely abandon range base for-loops. Sometimes it just reads better, for example with structured bindings. std::map&lt;std::string, unsigned int&gt; persons; &amp;#x200B; /\* add some persons here \*/ &amp;#x200B; for(const auto&amp; \[name, age\] : persons) { cout &lt;&lt; name &lt;&lt; "is" &lt;&lt; age &lt;&lt; "years old"; } reads pretty well imho.
Very interesting lessons, keep it up ! I will follow you :)
can you add some naive logger as reference, like: fwrite(str, sizeof(char), len, stdout); 
I normally use python for plotting. However I have recently started to use gnuplot for a few things. Output to a file and gnuplot over it. No native interface though, but there are some streamer wrappers. I'm thinking of writing my own if I ever find the time; seems like an interesting project. 
It’s not really scary anymore. The build systems and tool chains are probably the scariest part. Learn the parts that you need to solve your problem. Make sure to learn about RAII and why/when it’s good. Don’t get caught up in template programming yourself (I’ve rarely needed to write my own for personal projects). Memory sanitizers and valgrind are your friends. 
Also when you're looping over a very specific statically-known set of literals you can easily throw into an initializer list. for ( auto lang : {"en"sv, "es"sv, "ru"sv} ) But that argument goes away if you have a for_each that applies to ranges rather than iterators.
I thought it would not be allowed there, but maybe I was being overly cautious? Anyway, at least it is a start and can be migrated to cppreference.com, if there is consensus!
I think this would test speed of writing rather than speed of callback, no?
If you want to have good time with C/C++ (or any other native language) I would recommend learning how computer or some micro-architecture work. It will truly broader your horizons and make learning much more easy and fun (and even make sense).
I also found Shahar's explanations helpful, although less beginner friendly: * [vtables part 1](https://shaharmike.com/cpp/vtable-part1/) * [vtables part 2](https://shaharmike.com/cpp/vtable-part2/) * [vtables part 3](https://shaharmike.com/cpp/vtable-part3/) The concrete outputs helped me better conceptualize what was happening.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
Because I'm bored enough to actually take a look at this code: Your `Sort::sort(...)` method recurses infinitely.
thank you :)
Is the 17 support just that terrible or do you not have the info?
I've used gnuplot before, it works just fine. 
It bothered me **so much** I created a rule in my adblocker specifically to block his image.
vector isn't normally O(1) for insertions and deletions.
"New kid on the block" Been using fmt for years... :P
It's not scary. The committee has been making C++ more like Python every three years. 
It's amortized `O(1)` for insertions (actual `O(1)` if you use `reserve`), and `O(1)` for unordered deletions. 
cairo-mm - love this one! https://www.cairographics.org/cairomm/ sfml https://www.sfml-dev.org/tutorials/2.5/graphics-draw.php Qt and Qwt https://qwt.sourceforge.io And you can always embed python in c++ https://docs.python.org/2/extending/embedding.html#embedding-python-in-c matplotlib-cpp https://github.com/lava/matplotlib-cpp 
&gt; 1-2) Constant plus linear in the distance between pos and end of the container. https://en.cppreference.com/w/cpp/container/vector/insert
There are [ROOT](https://root.cern.ch/gallery) and [Qt Charts](https://doc.qt.io/qt-5/qtcharts-examples.html), but both are large dependencies.
@ek1010: would you be so kind and try spdlog 0.16.3 as well? The thing is since version 0.17 spdlog has switched from a very fancy MPMC lockless queue to a blocking one, implemented using condition variables and a mutex, which in cases of low contention performs worse.
We wrote a small wiki page explaining how to integrate with CMake: https://github.com/LoopPerfect/buckaroo/wiki/Building-CMake-Projects
I think the handwritten vectorized reverse we have contributed significantly to it winning in my tests. Maybe the answer changes depending on value_type; we are also interested :)
For what it's worth, when I really wanted this at a previous job GPL would've been just fine because the project was GPL anyhow. Remember: GPL only requires that you distribute the source to those to whom you distribute the binary. It does not require you put your source code up on gitlab or something.
I used to feel kind of bad I didn't do this myself. I'm quite glad you did. Kudos.
Thanks to all. I appreciate the information. Just out of curiosity, the Learn CPP tutorial recommends using CODE::BLOCKS for linux. Does anyone here use linux or mac for c++ dev? 
If Qt is an option, QCustomPlot is excellent and extremely easy to use.
I've played an F2P MMO that dynamically linked Lua but didn't protect the .dll with the anti-cheat they were using. Somehow, *none* of the various publishers in various regions ever picked up on how completely breakable their product was
Vector is stock as a block in the memory, so for each insertion, it has to move all data after the position of the insertion. So yes it's not O(1). push\_back is O(1), only if you use reserve. 
Gray colour means I don't have any reference. std::filesystem is known to not be supported, so I marked it as "no" (red).
And here am i wanting to make a C++ program that takes data form the microphone and continuosly plots the waveform and the Fast Fourier Transform result plus a few tidbits on the side, how hard would be that ?, i'm currently stuck in the alsa documentation while trying to capture audio data.
If you want to insert into a sorted vector, yes. My point is that there is no data structure that is sorted and has `O(1)` insertions and deletions, but you might get something quite close by using an *unsorted* vector (which has `O(1)` insertions and deletions), and sorting it only when necessary. 
Hey, question you can probably answer before I can find it - do you have a version of decode that takes a partially incomplete buffer (and indicates how many octets are required to finish the current structure)? I know for a fact that BER is sometimes used on ordered network protocols like TCP (and I believe serial though I never did that) where you might get part of a message now and part in the next packet. But you should have the length info needed to indicate how many more bytes must be waited for before processing.
Thank a lot for your help and advice. I have to keep the container sorted at each element adding. It's a sort of stack where I add an element not necessary on the back but inside the container. That why a have to keep it sorted. 
https://www.sfml-dev.org/tutorials/2.5/audio-recording.php 
&gt; push_back is O(1), only if you use reserve. Not exactly, It's amortized `O(1)`, always. So while some insertions will be `O(n)`, inserting `n` elements will be `O(n)`. I don't know what this datastructure will be used for, I can only speculate, and my speculation is that vector is probably the best here, even if it doesn't match your `O(1)` requirements, because vector tend to have ridiculously small constant factors on modern hardware and because I expect ordered traversals to be a lot less frequent than addition and deletions (so having to sort before traversal should be faster, than doing insertions or deletions in `O(log n)`.
&gt;F2P MMO Interesting, it is really common to have these engines inside games, and what's even more common is that the developers focus on protecting the game (data being stored server side, traffic, etc) but not the scripting engine it self. And sometimes it is easier to simulate the whole thing just using their scripts.
This zip\_iterator from the article makes a copy of each key and value, which will cause performance issues for any non-trivial type (e.g. std::string).
Oh, why do you think it wouldn't be allowed there?
LMAO. Somebody should tell him.
I’m confused, you’re teaching a course in Algorithms and Data structures but are having a hard time with this?
No, I am not teaching this course. I am a student taking this course at my uni. 
Yeah I was bit by that. 
Aha, thanks for clarifying. I was confused indeed. 🙂
😂, I am quite honoured that you were considering me an *processor
I answered my own question. In case someone else stumbles on this post. &amp;#x200B; [C++ IDE for Mac](https://www.reddit.com/r/cpp/comments/6g90jc/suggestions_for_c_ides_on_mac/)
Not only are the problems the author lists solved with ranges (as mentioned in other comments here), using \`for\_each\` also prevents usage of \`break\`, \`continue\` and \`return\`, which is a bad price to pay.
 &gt; I have to keep the container sorted at each element added. This seems really weird, are you really doing operations that require having the container be sorted in between each insertions? If it's a traversal, then doing an insertion will be almost free (since you are iterating over the thing anyway), if it's a lookup, use a hash map. 
I'll second EoP. It fundamentally changed me as a programmer more than another book has.
Yep! Waiting for my preordered copy :-)
Also, KISS / YAGNI. If a for loop works well, that's what you should probably do. All this worry about what if the loop will need to be changed later is pointless. If at some point there is a problem, a solution can be sought at that time, and it may be something else than modifying the loop body in an ugly way (e.g. if you need to filter, an alternative would be to keep separate collections in the first place).
well, it's used as a reference to inspect if the benchmark is malformed
Great! Time for some shopping!
**MY BLOG IS DOWN. WORKING ON BRINGING IT BACK ONLINE.**
Google Rcpp. There should be a bit. I recommended R as a simple solution for 2d plotting because it already offers everything you would need. I don’t think it’s hard to learn and the documentation is ok. If you have to do it in c++ of course then it’s not a real option. Sorry. Doesn’t hurt to look though :)
One of the fresh faces of C++ is on-line code generation.
I haven't used C++ coroutines but that's what I was suspecting. I'm a big proponent of async programming and event loops but care little about coroutines. Callbacks are fine for most things. I like how they generally force one to represent state explicitly and separate things done at different times into different functions.
You could just print the timing data to a text file and plot it with gnuplot or Excel. 
Apple's shenanigans with Clang/libc++ versioning are ridiculous. I can understand wanting to produce in-house polished and tested versions, but then they should at least make it easy to differentiate between their own AppleClang (or Apple libc++) and the upstream LLVM versions. Or at least tell us the corresponding upstream version numbers so that we can work things out for ourselves. Instead, they seem to go out of their way to make it difficult. The only way I know of to detect AppleClang is by looking for the `__apple_build_version__` macro, which is not defined for upstream Clang. This won't tell you if you're using Apple's libc++ or the upstream version, but the chances of someone using upstream libc++ with the Apple compiler are pretty slim I'd have thought. Even then, Apple try really hard to make life unpleasant. For example, the version of libc++ that ships with XCode 10 claims to support `&lt;variant&gt;`, and indeed the header exists; but if you try and use any of those functions when compiling on MacOS 10.13, you'll get an error telling you that the symbols are only available in MacOS 10.14. Why? I have no idea. Apple, please sort this rubbish out.
Well, Xcode is not a compiler after all, but an IDE, so I thought it would be frowned upon to shove it in there.
I've used gnuplot-iostream to great success. You can also just output a gnuplot script file or just dump gnuplot commands to stdout and pipe it to gnuplot.
Thank you, this will help a lot.
spdlog pre-allocates a queue with constant size with blocks the caller when full. Try creating a bigger queue. &gt;spdlog::init\_thread\_pool(1024\*1024, 1); &amp;#x200B; and then: &gt;auto logger = spdlog::create\_async&lt;spdlog::sinks::basic\_file\_sink\_mt&gt;("async\_file\_logger", "logs/async\_log.txt"); &amp;#x200B; Also, if all you caer is spikes and you don't care about losing messages under high load you can use the non-blocking mode: &amp;#x200B; &gt;auto logger = spdlog::create\_async\_nb&lt;spdlog::sinks::basic\_file\_sink\_mt&gt;("async\_file\_logger", "logs/async\_log.txt"); &amp;#x200B; &amp;#x200B; Where is the code of the tests?
Note that `new` isn't a system call. It calls `operator new`, which typically calls `malloc`. Most `malloc` implementations manage chunks in user-mode and will only request a new chunk when running out. This request is usually a syscall.
Relatively new =). It started in 2012.
Where lines of code are you referring to? For CLOCK_MONOTONIC, it is going to be in the do_hires)() function, and I only see the fallback method being called when the vgetccy() returns a negative number (rolls over?) . When I've run tests, I've never seen it do a syscall even with the slowdown I noticed. Is to synchronizing with the kernel without the syscall? Where is it done? I'm really interested so I can figure outt the clock_gettime() calls I have done seem to have peculiar performance. Here is my SO question: https://stackoverflow.com/questions/53252050/why-does-the-call-latency-on-clock-gettimeclock-realtime-vary-so-much And here is a response somebody sent me on HN: https://news.ycombinator.com/item?id=18529546 Cam you maybe shed more light on this?
Does anyone know what the changes in V2 are (because V1 is cheaper and I would like to get that if V2 is just an incremental update) else I will get V2
As with any language feature, I don’t like spending too much time in the weeds of generalizing which approach is right or wrong. Evaluate the pros and cons of each approach on a case by case basis and decide which is best for your specific circumstances. Everyone has brought up good reasons for using either. Range-for: - reads more naturally - debugs more naturally - allows us to early abort For_each: - encourages us to keep the scope at a common level of abstraction which promotes readability and reuse
&gt;For example, the version of libc++ that ships with XCode 10 claims to support &lt;variant&gt;, and indeed the header exists; but if you try and use any of those functions when compiling on MacOS 10.13, you'll get an error telling you that the symbols are only available in MacOS 10.14. Why? I have no idea. That sounds terrible. Does it give the error with &lt;any&gt; and &lt;optional&gt; as well? 
It's doubly bizarre because this game was an instanced action MMO, so a fair bit was actually verified client-side (hits and physics were client-side, whereas damage computation was server-side, etc.). Pretty much all enemy/player behavior was defined in Lua, too, so with control of the scripting engine I could break the game over my knee if I wanted to. (I didn't though, the game was way too good to consider doing that. I did experiment with modding new behaviors in. It was a good time until the game shut down, whoops.) But yeah I have no idea why they didn't just statically link it into the binary. It was way too trivial to just replace the lua dll with a custom version with a ton of hooks in it. Truth be told that game's engine in general seemed to be a giant stuttery mess so I don't know how much the devs actually knew what they were doing.
You could call extract_length on the input buffer. To receive the size of the top level PDU. If the length is less than the buffer size, continue, else wait for that number of bytes in buffer. Unfortunately if you synchronization there is no way to recover.
There's a summary in the forum, hope it helps: [https://forums.manning.com/posts/list/0/45335.page#p126973](https://forums.manning.com/posts/list/0/45335.page#p126973)
In general, in data-structures, sorted and O(1) are mutually exclusive. However, do you really need a *sorted* container? Looking at the definition `foo`, it doesn't seem too valuable, and if you don't need a *sorted* container than a `std::unordered_map` has: - O(1) find. - O(1) insertion/deletion. - O(n) iteration, in arbitrary order. 
Development team.
Problem is, range based is the only choise of you add (or remove) elements in the loop 
CLion is from intellij, at same level. However i'm not fan of closed software, so KDevelop, QtCreator are great IDEs.
This is exactly what I was looking for, thanks for the link. V1 it is (will read about the new stuff from cppreference.com as suggested in the thread)
I haven't tried, but it wouldn't surprise me. I forgot to mention that for a long time Apple shipped libc++'s `&lt;experimental/optional&gt;` *header*, but removed the definition of the `bad_optional_access` destructor from their libc++.a. The result was that `__has_include(&lt;experimental/optional&gt;)` worked fine, and your code would even compile, but fail to link. Perhaps it's all a sinister plot to make everyone move to Swift, I don't know. 
Using QPainter directly for plots is doing it the hard way. In the Qt ecosystem QWT, QCustomPlot or Qt Charts are all far better choices than doing it by hand.
Huh? Did you mean to say manual for loop? Ranged-based for is potentially incorrect if you add/remove elements just as much as for\_each, because the loop assumes the current iterator is still valid at the end of each iteration (because it calls ++i).
I personally like Visual Studio, especially with the time the teams have put in on the compiler and STL support for C++11/14/17 over the years. Never had an issue with slowness myself.
[https://codelite.org/](https://codelite.org/)
Will this work for my iterator https://github.com/boostorg/beast/blob/5a7a1a3f6c140ce7059b96d2f982e10414c51e7f/include/boost/beast/core/impl/buffers_adaptor.hpp#L300
Write to file in a CSV format (or whatever's appropriate) and use python or something. There are lots of other tools which are easy to pick up and are much easier to plot data with.
This was 10 years ago on Qt 3, so I'm not sure if any of those existed. I needed to do a lot of custom stuff to handle continuously scrolling, annotations, zooming, and overlaying video, so at the time doing it by hand was fine.
Sometimes they know that the game is going to die sooner or later and they decide to take the risk and don't waste time or money preventing those kind of cheats. Anyways, they could have prevented it in multiple different ways, even statically linking the dll into the binary wouldn't have fixed the issue. You would probably have been able to modify the dll in run time :P
For me, it's a *nix system with tmux and [[neo]vim](https://github.com/oblitum/dotfiles/blob/ArchLinux/README.md).
One of my favorites!
Im speaking of the old for (int i...) loop
I'd like to see this as a github repository with build scripts, tests, Travis CI integration, Appveyor (for Visual C++), documentation, code coverage, and badges.
I already have a massive code base and product of my own. I don't have remotely have time for that stuff. This is 'as is' code if anyone wants to use it. 
Already? I only got the first edition last year!
Why advise everybody to use seq\_cst everywhere? A simple store is converted to a full blown MFENCE or atomic xchg RMW on x86. This is terrible for performance, really bad! There are a whole class of algorithms that try to get around using these types of nasty membars. Avoiding a MFENCE or atomic RMW is very beneficial.
!remove help
The inability to use those flow control mechanisms is part of the point – it tells you immediately that unless the code is Machiavellian then the knowledge that those aren't possible communicates something immediately about the algorithm without even reading it.
Which development team? The C++ compiler in question? Magnum Engine? A development team using one of those two things?
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
The slow part of the condvar only gets engaged when a wait condition hits. If the sema had a count of say, 42, then we would have to call dec, or sema wait, 43 times in order to call into the slow condvar. There is contention on the single atomic variable, but this is radically different than contention on a mutex! Btw, seq\_cst is expensive on x86. There are whole classes of algorithms that strive to remove any expensive membars and/or atomic RMW's, for very good reason...
If you're on Windows you can use Event Tracing for Windows (ETW). Your log messages are replaced by highly structured (and thus filterable) events. Buffering and dispatching log events is done by the OS itself to any logging sessions with consumers (if there are any). When a consumer starts the event provider is notified of the consumers' logging level, keywords and filters and can optimize its logging accordingly (usually the enable state of events is kept in a process-local bitmask so that useless log calls are skipped). Events itself contain useful metadata like timestamp, process and thread id or (optional) stack trace. You can also combine your event provider with Windows' own user-mode and kernel providers to correlate your activity with the rest of the system and analyze it with tools like WPA.
Call it Apple Clang. You can do it like it's done with MSVC with `*` for specific XCode versions.
&gt; Apple, please sort this rubbish out. And [this](https://plus.google.com/+ThiagoMacieira/posts/2SmArLfeDZt)
Magnum Engine. Have you read the blog article? &gt; As not all up­dates can be made in a back­wards-com­pat­i­ble way, the change is hap­pen­ing grad­u­al­ly — this re­lease re­places most us­es of std::unique_p­tr and std::ref­er­ence_wrap­per with Con­tain­ers::Point­er and Con­tain­ers::R­eference in or­der to avoid heavy &lt;memory&gt; and &lt;functional&gt; in­cludes and the work will con­tin­ue in fu­ture re­leas­es.
Doesn't change the fact that I'd still like to see those things :) But I do appreciate that you published this, thanks!
seq_cst is not cheap. Why would a simple store always need to be an atomic RMW and/or full blown #StoreLoad style memory barrier, like mfence? Well, that is because the damn programmer used all seq_cst... Damn! Calling mfence basically destroys things.
In terms of being 'moh-dern', does it look reasonable in its use of the standard libraries and STL? &amp;#x200B;
&gt;Why would a simple store always need to be an atomic RMW Because that's the cheapest instruction that prevents stores from being reordered with other stores. Yes, that costs 18 cycles. Yes, I think 18 cycles is worth it most of the time. &gt;Calling mfence basically destroys things. I don't know about mfence but mfence is never required to achieve seq_cst on x86 so I don't see how that's relevant here.
Does not look modern. wide streams are a bit of a relic (iostreams in general are not great). There's not a single template that I could find. No way to stream into and out of user defined types. It uses virtual functions. This isn't terrible, it looks functional (although I haven't tried it) but it looks like garden-variety JSON code. Nothing wrong with that, but it won't be winning any awards either.
Chapter 10 is the one I'm really looking forward to!
Suggestion: add a data member (ie `int x;`) to that `C` class at the beginning. I think it will help: - an empty class is foreign to a new developer. Actually, add two members, x and y just to be comfortable and familiar - it helps the idea that the data lives with the `this` pointer, but the member functions don't. I know adding more can take away from the parts you want to focus on, but I think it might help in this case. (having the member function return x might also help?)
mfence and/or xchg are very expensive. Keep in mind that the xchg has an implied LOCK prefix... Keep that in mind...
Whether I had read the article doesn't have anything to do with your statements being ambiguous...
I've stared at both "Elements of Programming" and "From Mathematics to Generic Programming" for a while now but haven't pulled the trigger. Is there a particular rationale for getting one over the other? "From Mathematics to Generic Programming" seems better reviewed.
I don't mean this to sound like I'm not greatful that you took a look, I'm just wanting to understand what you are saying, and of course I'm going to question what I think is strange to me. And also part of this I hope is to help educate me and others, so explanations would be good. - Virtual methods are bad? They are at the core of OO. I couldn't imagine a world where they are considered wrong if you want to represent a hierarchy of 'is-a' type relationships, which the JSON hierarchy completely is. How would you represent such a hierarchy without polymorphism? - Why use a template if you don't need a template? What does a template contribute, other than code bloat if it's not increasing compile time safety? Or of course you need a template to place some tricks, as with the lambda callback parameter. Where in there would a template have done something better? - How would you stream data without streams? What is the replacement mechanism for I/O streams? 
Heap allocations can get optimized away or combined, it is explicitly allowed as of C++14. Both gcc and clang do it, but clang does it better.
Eh, thats a general feature of most compilers, suppressing warnings in a system header is typical. That "error" is actually a warning that defaults to error "-Wc++11-narrowing". This is a Clang feature.
&gt;I think it's the only compiler that implements this optimization. GCC implements this too, just not as well.
It is an error. In the system header.
EoP is more formal, and generally more in depth; FMtGP is more readable and easier to understand without a background in maths.
Yes. And that costs 18 cycles, as previously indicated.
Again, a warning, just one that is suppressed because it is in a system header. Warnings in system headers are incredibly common unfortunately. Since the Wc++-narrowing warning is defaulted to an error in the same way as with Werror, it is suppressed. The alternative would be compiling with -Werror making nothing that uses the standard library compile. The assertion that Thiago makes in that post that they "patch the compiler to support" this is incorrect. This is a clang feature. That said, why that code in the header lacks a cast is a mystery to me.
that took me 3 hours though -\_-
Thanks. I will propose it in the cppreference table discussion page.
All good questions! &gt; Virtual methods are bad? They are at the core of OO Well, "Object Oriented" is kind of an outdated concept. This kind of explains why, I'm sure other people could give more detailed reasons. The tl;dr is that trying to model real-world hierarchies using structurually identical C++ hierarchies is often suboptimal. &lt;https://medium.com/@cscalfani/goodbye-object-oriented-programming-a59cda4c0e53&gt; Typically, JSON libraries implement the value type as a "discriminated union" which has performance benefits, the compiler can see the entire type at once. `std::variant` is an example of a discriminated union although it comes with some baggage. &gt; Why use a template if you don't need a template? &gt; How would you stream data without streams? The answer to both of these is the same. You define a "concept", for example, "CharacterInputStream" and the requirements, and you implement your algorithm in terms of that concept as a function template. This is how everything in &lt;algorithm&gt; works. For example, your parse function could use iterators: ``` template&lt;FwdIt&gt; void parse(FwdIt first, FwdIt last); ``` Then, users aren't forced to use a stream.
Pardon me, but... Why? I'm seriously asking.
in certan situations you might want to use some characters that you cant find on your keyboard
codelite much better
As others have mentioned, usually this sort of thing is done by writing to a text file (I prefer TSV since it's easiest to work with) and plotting with more appropriate tools. It's worth mentioning, though, that this is a good idea in general, and not just a workaround to use a different language. Storing benchmarks and similar data in a timeless portable format like this means you can easily do other things with the data, like archive it, make different visualizations later, do statistical analysis and/or combine with other data, and so on. Plus it's just good decoupling in general. Having learned this lesson the hard way, I now make it a rule to always - always - store benchmarks in a simple text file. You quite often end up wanting to see things in a different way, or need to tweak your plots slightly for publication, or whatever.
It does much more than simply cost 18, or whatever cycles. It has to order everything, and that costs a lot. Study up on what the LOCK prefix or MFENCE actually does, under the covers.
What are you using for "extended ASCII". It looks like it's based on something that originated in Microsoft DOS. There are different standards for how to interpret values above 127. For example [ISO 8859-1] is a commonly used standard very different from the values you used. In general it's probably best to abandon any ideas about extended ASCII in favor of UTF-8 since it is now a widely accepted standard. It would also be very helpful to show the explicit value of each character even though it's not needed because you have every sequential value.
Well, we will absolutely disagree on OO being an outdated concept. I reject that out of hand. If your argument about the variant is that it should be done that way because OO is outdated, then I also reject that out of hand. If there's some other good reason for doing it that way, that outweighs the bloat benefits, I'm interested in hearing it. What if one type of node in a hierarchy required 1MB of data, and another type required 2 bytes? On the input abstraction, I obviously agree. But it was beyond the scope of this little exercize. Also, if I did my own, it would require doing ad hoc implementations of wrappers around files, sockets, strings, memory buffers, etc... Else every user would have to do their own. Is that really warranted? If using that kind of abstracted input mechanism is considered good modern C++ then the basis for it should exist in the STL and I'd think that there should be existing implementations of such a thing for all those potential sources of data. It seems a little crazy to me to reinvent that wheel for every file format you might want to write a parser for. If such a non-stream abstraction doesn't exist in the standard libraries, then presumably streams are that standard abstraction, and already provide access to all those sources of data. 
You should do an enum that covers utf-8... :)
ok, now do Unicode!
That would be Unicode which is much more than ASCII.
i dont want to get arthritis
&gt; If using that kind of abstracted input mechanism is considered good modern C++ then the basis for it should exist in the STL and I'd think that there should be existing implementations of such a thing for all those potential sources of data. Well there are... check &lt;algorithm&gt; for input iterators.
Never had clion, I use vscode because it's consistent across platforms and has integrated git and some nice extensions
Damnit, and I didn't get my 1st edition signed yet :P
I've spent a fair bit of time maintaining that page, including for compilers with much smaller user bases than Apple Clang. You've got my support. The hard bit is that it's ideal to be able to point at some bit of documentation for various features being supported, which Apple of course neglects, inspiring your intentions.
You'll miss security if you download if off MS's website. Their version bundles proprietary spyware... seriously. Use VsCodium: https://github.com/VSCodium/vscodium
Why not an enum class? You probably shouldn't have used the word NULL as an enum value. Especially since it's in the global namespace. Why do `, //!` instead of `= '!',`? I imagine I could do `for i in {0..127}; do ascii d${i}; done` and parse out the "Official name" and "Other names" faster than I could remember how to find your github.
I've had occasion to use start-of-header and stuff like that. But '\x01' works fine. 
If you don't see immediately, if your loop has control structures in it, you have imho much bigger things to worry about, because then your loop body is far too big and/or you are working without syntax highlighting. Thing is: The boilerplate that is currently necessary when using for each (ranges aren't comming for quite some time) is imho much more likely to hide a bug than a raw range based for loop.
You can download a table and transform it to source code through like sed or something.
In practice I agree, but in principle I would still rather declaratively restrict away functionality I'm not going to use whenever possible – there are (for me) too many potential upsides (theoretical, if not actual). And in both practice and principle I expect infrastructure code to be sufficiently well-tested to consider that a non-argument.
I'm not sure how you got CLion to use so much CPU; It uses like maybe 10% or so at best on my home PC (which is decent enough, but not an insane machine or anything like that). It certainly doesn't come even close to the CPU usage I get from building large projects or running a large test suite.
I'm not talking about bugs in for_each. I meant that the visual noise makes it more likely, that you overlook a bug in the loop body. Also, there are other trivial things, like not having autocomplete for auto parameters. And even with for each you can have a `continue`: an early return.
I'm not shooting the messenger, but the critique has to be within the realm of reason. Every person who writes a parser is not going to create four or five ad hoc implementations of InputIterator and all of the time suckage and potential errors (since they would just be doing it to get it done it has nothing to do with what they are writing?) That's obviously neither practical nor desirable. And they'd have created a completely non-inter-operable scheme in the process that only works for their stuff. Given that, it would seem to me that using streams is completely reasonable until such time as that issue is addressed. Otherwise the only practical solution would be to create one instance of it that takes an input stream by way of the base class (and all of the horrible virtual methods that would involve), which would just be jumping through a hoop to get back to the same side of the hoop you started on. 
The containers should still be able to handle OOM when using custom allocators. What we imho don't need are things like the strong exception guarantee. If oom during something like pushback is handled at all, it is almost always dealt with several layers higher, where the container is long gone. If you need the strong exception guarantee you can sn should code it yourself.
&gt; Every person who writes a parser is not going to create four or five ad hoc implementations of InputIterator Correct. You aren't the one who is writing the _InputIterator_, you are simply expressing your parsing algorithm in terms of it. The user is the one who provides their own _InputIterator_ type. Note that `char const*` is an _InputIterator_ (and also a _ForwardIterator_).
And there exists input iterator derivatives in the STL for files, and memory buffers and sockets and other things that they would want to parse from? If that's true, then yes, I'd easily update it to use an input iterator. If not, then they'd probably smack me around if I forced every one of them to to create a file input iterator just to parse a file. 
vi extension :)
I did the same months ago!
&gt; I'd easily update it to use an input iterator You don't have to update anything, if your code works for you then there is no reason to stop using it. &gt; input iterators I assume don't deal at all with any sort of transcoding or text encoding issues, line terminations, etc... That's sort of what streams were created to deal with. You do bring up a code point and I will point out that since you are using the streams, they will acquire the behavior of whatever codecvt facet / whatever is set. This means that depending on the global state of the program, your parser might accept invalid JSON, just because the stream converting something that was invalid into something that was valid. Yet another reason not to use iostreams.
Certainly text encoding is a mess in C++. I'm so spoiled with my stuff which is so clean in this area. OTOH, it's not like I'm going to re-implement a whole text transcoding system inside every STL based parser I create either. So the iterator scheme doesn't help on that front. It's not like you can just ignore text encoding. And they could deal with it relatively straightforward. Maybe they are thinking they have to do some galactic solution when something considerably less massive would make all the difference. In my system a text stream accepts a text converter. The stream doesn't have to understand the encodings, it just lets the converter deal with those issues, and the client code provides the converter. Of course C++ doesn't have a well defined portable wide character, but that's fine. Put that burden on the person creating the stream and have them tell the converter what wide character format they are dealing with. It won't be that hard for folks to be able to figure out what value to set an enum for local wide character format. If no converter is provided, install a default that does what happens now. It's all backwards compatible but it opens the door to getting C++ into some sort of coherent situation wrt to this very fundamental issue. 
Yeah, and that's fine as I said but you asked if this was "modern C++" and I would say it is almost there but not quite.
This was posted some time ago and it may be of interest to you: [https://pspdfkit.com/blog/2019/visual-studio-code-for-cpp/](https://pspdfkit.com/blog/2019/visual-studio-code-for-cpp/)
I've been waiting since 2017...
If you have a lot of data, plain text files are not optimal, because you will waste time doing the string to number conversions, and it will take much more space. When you have one million or more data points, something like Matlab really comes in handy, especially since you have binary files for saving your data as well.
is c++ mandatory? if not I would make a csv and use something like gnuplot to plot it. gnuplot can be invoked in batch mode. All the libraries mentioned are great, no one has mentioned GD image, and opencv. both are great too for your task. When I was in school I just used gnuplot. I like GD image cause it's one of the simpler ones. OpenCV is not really a graphing/drawing library but does have functions for it and I wouldn't recommend it unless you are also doing image processing.
What did you see when you profiled it?
Does look like a regression. Unless something has changed in the coro spec.
Thank you for the report. Filed as [https://bugs.llvm.org/show\_bug.cgi?id=40656](https://bugs.llvm.org/show_bug.cgi?id=40656) . &amp;#x200B;
Why is it called Halo?
The short answer is V1 reflects C++11. This new version reflects C++17.
See https://wg21.link/P0981R0 “Heap Allocation eLision Optimisation”
Expediency at its finest 
Alternative (but somewhat cursed) way: feed all data through a websocket server with https://github.com/zaphoyd/websocketpp to a HTML + JS plotting library. Benefits include much-better visualization/interactive libraries and real-time update.
+1 for your username
I bought the MEAP version last year, really brilliant book!
I recently added Meson to my project: [https://github.com/Ebenezer-group/onwards/blob/master/meson.build](https://github.com/Ebenezer-group/onwards/blob/master/meson.build) I decided to use Meson rather than Cmake. But I don't think I'm going to get rid of my makefiles. For now at least I'm going to keep the makefiles and Meson.
Well, nothing too strange really. Some samples (about 8% each) hit the `chk.resize()` lines, about 20% hit `fin.read()`, and about 55% hit `ReadFile()`). Most of the rest hit the destructor of `std::vector&lt;chunk_t&gt;`. I suspect that the approach that I used reading that file is somehow off.
An `ifstream` object probably has an internal buffer greater than 1000 bytes, like 4096 or something. It less often calls a slow `ReadFile` filling that larger size, so your `ifstream::read`calls are likely usually serviced by a cheaper `memcpy`. Also, for almost every chuck you read in the win32 version, you call `vector::resize` on, which you do not in the other version. Btw, if you are using the win32 api, you can use `GetFileSizeEx` to get the size of a file.
You are allocating a vector of vectors, which is silly.
I call `vector::resize` in each version to allocate the actual buffer (the chunk), not just in the win32 version. You've got a point, however. I'll try increasing the chunk size.
Try setting ifstream buffer size your chunk size
Apparently, they didn't like HAEO!
You're right! I increased the chunk size to 10KB and the two methods take about the same amount of time. There's one more question, however: I get the impression that ReadFile() also has some kind of buffering from [here](https://docs.microsoft.com/en-us/windows/desktop/FileIO/file-buffering). Does this mean that it refers to another kind of buffering?
I/O bound code should not be 2x faster using the same disk, and same file. Is it possible other tasks or servers are using the same shared disk? You have already taken caching into account. This is a wag, but can you run this from a powershell window? Get-WmiObject -Class Win32\_Volume | Select-Object Label, BlockSize | Format-Table -AutoSize And, then change your bytes\_per\_chunk value to the blocksize of the volume your files are on, and rerun? 
Well, I need to split the file into smaller chunks. Is there a better way?
Basically, setting a larger chunk size works. I'm not sure if this is because `ReadFile()` has no caching or if there're other reasons.
Even though the file contents may be in the system cache, functions like `ReadFile` may have to go into the kernel every time, which has a very high constant factor. I should have been more clear, both versions call `vector::resize` before calling `ifsteam::read`/`ReadFile`, but the win32 further calls it almost every time after the read call, when `res &gt; 0`.
This is what I came up with after looking over the project. It's late at night for me, so I haven't tested it, but it should give you a start. My assumption is that c_exception is a third-party library and that extern is where you're keeping those; Meson by default calls that `subprojects` but allows you to rename it. I'm pretty sure `CMAKE_C_COMPILER_ID MATCHES "Clang|AppleClang|GNU"` was intended to check if the compiler supports GCC-style options, but it looks like Meson now has a way to ask about that directly, so I used that. # ===================================== meson.build project('cprogram', 'c', 'asm', description: 'A CMake project template written for C programmers.', default_options: ['c_std=c11'], subproject_dir: 'extern', # by default it's called "subprojects" meson_version: '&gt;=49.0' version: '1.0.0', license: 'MIT') cexception_dep = dependency('cexception', fallback: ['cexception', 'cexception_dep']) subdir('project') install_data('README.md', 'LICENSE.md', 'CONTRIBUTING.md', 'CODE_OF_CONDUCT.md', install_dir: join_paths(['share', 'doc', meson.project_name()])) # ===================================== extern/c_exception/meson.build project('cexception', 'c') incdir = include_directories('lib') cexception = library('cexception', 'lib/CException.c', include_directories: incdir, install: true) cexception_dep = declare_dependency( link_with: cexception, include_directories: incdir) # ===================================== project/meson.build subdir('source') # ===================================== project/source/meson.build cc = meson.get_compiler('c') compile_options = [] if cc.get_id() == 'clang' compile_options += [ '-Wweak-vtables', '-Wexit-time-destructors', '-Wglobal-constructors', '-Wmissing-noreturn'] endif if cc.get_argument_syntax() == 'gcc' compile_options += ['-Wall', '-Wextra', '-Wunreachable-code'] endif if cc.get_id() == 'msvc' compile_options = ['/W4', '/w44265', '/w44061', '/w44062', '/utf-8'] endif cproject = executable(meson.project_name(), 'main.c', c_args: compile_options, include_directories: include_directories('.'), dependencies: [cexception], install: true) test('Passed zero arguments to exe', cproject, args: []) test('Passed first argument to exe', cproject, args: ['testing']) test('Passed two arguments to exe', cproject, args: ['hello', 'world']) test('Passed three arguments to exe', cproject, args: ['a', 'b', 'c']) 
The system happens in the kernel and buffering applies to both ReadFile and C++ ifstream, because the latter will end up calling... ReadFile! C++ ifstream ~~will~~really should have, however, user-mode buffering, that is made to match block size (or its multiple) on the system, making it "magically adjusted" to how the system works efficiently.
By "user-mode buffering" did you mean [this](https://en.cppreference.com/w/cpp/io/basic_streambuf/pubsetbuf)?
I'm guessing iostreams uses ReadFile 'better' than you do (i.e. either different flags, or different buffer size(s), or using async i/o internally, etc)
mfence or dummy atomic's RMW are required to implement seq\_cst on x86. Remember this: [https://godbolt.org/z/XLLGVT](https://godbolt.org/z/XLLGVT) Btw, a store followed by a load to a different location CAN be reordered on x86, this is why it requires membars to get seq\_cst up and running.
[Someone really wanted our initials to spell out HALO](https://www.youtube.com/watch?v=zPOl2WJyzlY).
Yes, basically since they won't update libc++ for older systems they restrict latest c++ runtime features to latest macos version. You can always build your own libc++ and ship it along with your app though.
I don't think you have stated your requirements for insertion anywhere in the post.
Using "not scary" and memory sanitizers in the same context is a bit contradictory.
If you are going to read the whole file into memory, allocate it once and if you MUST have a chunk, it should be a simple slice (a view into the memory). struct slice { char *ptr; size_t size; }; Or, just forget the whole slice/view thing and just read the thing in one go. At least time that against the current code and see if it is worse/better/same. 
Yes, something like it. Don't know what is ifstream really doing though.
You're going to be disappointed if you think an IDE can index your code base without using a lot of CPU time. 
In their dreams maybe. (Actually I don't think they aim for that).
19 is the figure in the optimization manual, and plain mov takes 1, so 18. https://software.intel.com/sites/default/files/managed/9e/bc/64-ia-32-architectures-optimization-manual.pdf?wapkw=ia32%20manual LOCK hasn't meant "lock the whole memory bus" in at least 10 years (the manual doesn't have data for before Sandy Bridge anyway). Again, I don't know about mfence, but that's not necessary to implement seq_cst, so I couldn't care less. x86 already has to "order everything" because like operations are not reordered (that is, all loads are acquires, all stores are releases, but with plain acq_rel rules rather than seq_cst rules).
Apple focus is foremost Objective-C and Swift. C++ support is good enough for the only places where they actually use it, namely IO Kit and Metal Shaders. You even need to be an Apple old timer to have Objective-C++ documentation around, as it is no longer available.
Any chance MSVC starts applying the same optimization?
The x86 can definitely reorder a store followed by a load to another location. X86 is NOT seq_cst by default. Not at all. Btw, I am not talking about locking the bus. LOCK works on l2 cache lines now. Using xchg and/or mfence for a simple store is just wrong. Radical overkill, and ruins performance. Wow.
&gt;I don't think your atomic\_thread\_fence is sufficient to enforce ordering here Why would you even think about saying that? Of course the fences are sufficient to enforce the acquire/release relationship here.
I'm wonder why someone use VSCode but not Atom, is there something different, except M$ branding ?
The question is exactly about extensions, so mentioning them instead of referring as "nice extensions" would benefit the thread :)
Why isn't STD::filesystem supported? :(
In practice there is no sorted container that has better than O(log(n)) insertion or deletion. Self-balancing binary search trees (which std::map usually is) have both O(log(n)). If you have a pointer to an element and want to delete it without looking it up (to obtain the iterator), you can either keep an iterator next to it (which wastes memory) or use an intrusive variant of the data structure (e.g. from Boost intrusive). But this does not change asymptotic time complexity.
In practice there is no sorted container that has better than O(log(n)) insertion or deletion. Self-balancing binary search trees (which std::map usually is) have both O(log(n)). If you have a pointer to an element and want to delete it without looking it up (to obtain the iterator), you can either keep an iterator next to it (which wastes memory) or use an intrusive variant of the data structure (e.g. from Boost intrusive). But this does not change asymptotic time complexity.
The context of this problem is that I'm working on [a text editor](https://www.reddit.com/r/cpp/comments/af3jux/crossplatform_text_editor_looking_for_contributors/). The whole file is broken into chunks and stored in a binary tree. These chunks are broken apart when text is inserted or removed, and reassembled when the chunks are too small. Sure I can use slices to save some memory, but reassembling chunks will then be painful. So, I opted for this more convenient solution for now. Also, won't allocating 2GB of memory be prone to OOM failures (although there is virtual memory and all...)?
Interesting. Can you give me a link/some pointers on how to do that? I’m currently relying on boost because `std::filesystem` is missing, this sounds an interesting alternative.
I have desperately wanted a table like this for ages. Is there a way I can indicate support for having this on cppreference?
Me too. I wrote a bug report to Apple. I highly recommend you do the same, it keeps the pressure on them. It will get marked as a duplicate, like mine did. They will not give you a link to the other report so you can’t get any info about when they will resolve it because _reasons_. It’s still worth doing, in my opinion. (One time with a different bug report that was also marked duplicate I wrote a bug report for the bug tracker about how they handled duplicates. I should do that again)
I didn't go that far but stopped reading the blog exactly because of that.
https://libcxx.llvm.org/docs/BuildingLibcxx.html
It is way faster. I have no idea why, given that they are both based on Electron. 
I created the proposal [in the talk page](https://en.cppreference.com/w/Talk:cpp/compiler_support#Adding_a_column_for_Apple_Clang). It has a link to this discussion, so your comment will be seen by anyone investigating :) In the proposal I say "If no one protests in two weeks, I will create the new column and add the initial references." &amp;#x200B;
It is supposed to work as &lt;experimental/filesystem&gt; in Xcode 10, but [people are reporting results to the contrary](https://stackoverflow.com/questions/42633477/macos-clang-c17-filesystem-header-not-found#comment93730948_50835358).
LOL. People downvoted you :D I guess no good deed goes unpunished.
I couldn't agree more, it's completely ridiculous how Apple literally has no release notes / change log whatsoever with regards to Xcode/C++/AppleClang...
Thanks!
So I checked the source for basic file sink, and it's just a thin wrapper doing c++ file io. The queue is not even involved when you use the sink directly. On the other hand when you use the async logger, that does involve the queue and a thread pool which consumes it. Might make a difference in the benchmarks.
It comes down to call overhead in `ReadFile()` on Windows. As you can see at https://github.com/ned14/llfio/blob/ebad78163b34e53786338ac8778c71c02cd090a3/programs/fs-probe/fs_probe_results.yaml, more than half the time to read 4Kb using `ReadFile()` goes on getting into the kernel, traversing the various filing system stack layers, and finally reaching the bit of code which does a `memcpy()` to user space. As `ifstream` reads larger chunks in advance and hands them out in pieces inside user space, the call overhead is much lower, and performance is better. On Windows, you either want to call `ReadFile()` with nice chunky buffers - 64Kb or 128Kb is what Windows itself likes to use - or use memory maps. If you'd like to see `ifstream` left in the dust, try https://ned14.github.io/llfio/classllfio__v2__xxx_1_1mapped__file__handle.html with hot cached file content. You can find an illustrative graph for various i/o block sizes in http://wg21.link/P1031 Figure 1 which compares `ifstream` to `llfio::file_handle` (`ReadFile()`) and `llfio::mapped_file_handle` (memory maps). As you will see, `ifstream` performs very poorly as it copies too much memory.
This is something that scares me about /u/GorNishanov's coroutines. Any random regression in the optimizer can make your code run a lot slower. What's the likelihood that this kind of situation repeats itself? 
There is no bug in the code presented. I don't appreciate them trying to get people to look for a bug and \*then\* deceptively introduce the macro.
My guess is that VS Code team as a higher budget/concern for optimizations
I wouldn't have suggested that unless I saw you returning a vector of vector's, which just increases overhead. But now I think it is just for benchmarking. If you are compiling for 32 bits then the problem with big contiguous block of memory is address space; it is more likely you find 2 GB worth of smaller ranges than one big 2 GB range. The user-facing, virtual address has to be contiguous while the underlying physical address doesn't. In this light breaking into blocks is the thing to do. Interesting problem .. if you have a 2 GB text file and you add or remove 400 bytes from the middle, or close to beginning.. how you handle that efficiently? You could keep a track of active ranges and commit them at the end, but such editing scheme makes closing the editor a bit slow.. or commit in a background thread and give user view of the current state no matter what's committed. Sound interesting to make it efficient. :) 
Im no expert but my understanding is that gtod uses vdso (kernel code in userspace) and linear extrapolation from rdtsc to keep the call in user space but once the frequency drifts it has to cross to kernel space to sync
It appears to be repeatedly indexing something. It goes up to 400%+ CPU for around 10 min and then stops for 30 min and then does it again. This is on an i7 Mac laptop and desktop and a project with around 700k lines of code. It stops when I turn on power save mode but that disables everything else too. Apparently there is a Mac issue in the tracker.
Are you using an IDE? If so what are you using? P.S.: I might still not be able to help you but at least if you answer I can try
LOL ``` // TODO: Handle HTTP/2.0 when it releases ``` https://github.com/scylladb/seastar/blob/428f4ac8fe3548e827696ca2ea8d68456e399e07/src/http/httpd.cc#L214
In linux the solution woukd be Memory map the entire file and traverse it thats how column based database storage backend like kdb or Parquet do
There most certainly is a bug. The really sad thing is that they don't even understand the bug that was already there before they introduced the macro, and that the macro was most likely intended to fix the bug. From [cppreference](https://en.cppreference.com/w/cpp/string/byte/isspace): *"****The behavior is undefined*** *if the value of ch is not representable as unsigned char and is not equal to* [*EOF*](http://en.cppreference.com/w/cpp/io/c)*. "* This is not an idle threat either: many compilers will do an unguarded table lookup, crashing your application if you feed it a character outside the allowed range. What probably happened: the Midnight Commander people found out that reading anything that triggered UB (which can happen extremely easily when reading a random file!) caused their application to misbehave. They fixed their code by applying this macro instead of just defining their own mc::isspace function. Of course we can hardly blame them for using isspace. After all, it is clear from the signature of isspace that it was always intended to be used directly on the output of some kind of file or file-like operation. Why else would it accept EOF as a valid input? Yet actually doing so risks introducing UB, based on user input! To the PVS Studio people: isn't it time to add a warning that isspace (and isalpha, isdigit, isxdigit, tolower, toupper, etc.) are \_all\_ UB if you give them a character with a value that is not in the range -1..127? Essentially, just about any use of these functions in the wild is going to be an automatic bug. To the standards committee: can we finally, finally get rid of this ridiculous piece of UB? What exactly are you trying to prove here? How many programmers, do you suppose, are using these functions on characters received from an external source (keyboard, file, whatever), and end up with a crash at best and an attack vector at worst? This is not a "solving this would require us to solve the halting problem"-class UB. All it takes is a cast to unsigned char inside isspace, and it would be safe. It is literally a free operation on any pipelined CPU. So why is this impossible to fix? &amp;#x200B;
I only just started reading mine. Got stumped at the chapter on atomics and memory order blah blah. I'm struggling to make sense of it all. I feel much of the intuition is missing from the text. I'm watching lots of videos and reading blog posts to try to make sense of it all before I return to the text. 
Please follow https://github.com/martinus/robin-hood-hashing/issues/17
What you quote about the requirements for isspace is true. But getc returns (https://linux.die.net/man/3/getc): "the character read as an unsigned char cast to an int or EOF on end of file or error". This satisfies the isspace requirement. 
Hello, yes i using an IDE (CLion) becouse I am a Java programmer ed I am usualy to use a intelliJ. &amp;#x200B; And I using Cmake for system of costruction code becouse Clion use this to defoult. &amp;#x200B; ps: I like to the divide code in two file for order but I would undestend all aspect
**Company:** [The Document Foundation](https://documentfoundation.org/) **Type:** Full or part time **Description:** The Document Foundation is the non-profit entity behind LibreOffice, the most popular open source office suite. We are looking for a Development Mentor to: * Build relationships between existing mentors and new contributors * Identify and onboard new contributors * Affirm and encourage their contributions and more. If you know C++ and have experience in open source projects, get in touch! [Full details](https://blog.documentfoundation.org/blog/2019/02/02/join-our-team-job-search-for-a-development-mentor-201902-01/). **Location:** Remote **Technologies:** C++17 features supported by our [build baseline](https://gerrit.libreoffice.org/plugins/gitiles/core/+/master/README.md). **Contact:** TDF is looking forward to receiving your applications, including curriculum vitae, your financial expectations, and the earliest date of your availability via e-mail to Florian Effenberger at floeff@documentfoundation.org no later than March 29, 2019. You can encrypt your message via PGP/GnuPG.
But what about [http://lionet.info/asn1c/download.html](http://lionet.info/asn1c/download.html) ?
&gt; isspace (and isalpha, isdigit, isxdigit, tolower, toupper, etc.) are \_all\_ UB if you give them a character with a value that is not in the range -1..127? I think you misunderstand the isspace requirement. It boils down to that it must be in the range -1..**255**. Because a char cast to unsigned char is going to be in the range 0..255 (assuming 8-bit char).
HTTP/2 should be the main concern for anyone trying to use ASIO in a custom webserver. Have you given it a shot?
Interesting, although I hesitate to accept Linux documentation as universal truth. [cppreference](https://en.cppreference.com/w/cpp/io/c/fgetc) doesn't mention this particular property of fgetc. Anyway, why would Midnight Commander have that weird macro? I still think my theory is correct - they ran into UB, just not in this function, and did a quick and dirty (and ill-advised) fix. 
How does one "give it a shot?" Is there a switch which may be flipped to achieve HTTP/2? Anyway, HTTP/2 is dead now that Google has effectively defined HTTP/3.
I did observe about 20% speedup using memory-mapped files. Thanks for your information.
https://justdomyhomework.com This subreddit is for discussions on C++ not for solving your homework.
cppreferece doesn't have any authority. And it's not just Linux documentation, it's in the C standard: "If the end-of-file indicator for the input stream pointed to by stream is not set and a next character is present, the fgetc function obtains that character as an unsigned char converted to an int..."
This is not proper place for posting questions like this. If you are asking as to do your homework for you, then it's better to try to do it by yourself. By the way: const auto common = std::string_view{ ... }; const auto words = std::vector{ std::string_view{ word1 }, std::string_view{ word2 }, ... }; for(auto&amp; word : words) { std::cout &lt;&lt; word.find_first(common) &lt;&lt; ' '; } where "common" is the common part and "words" is vector of all words.
By 'give it a shot' I meant trying to support the protocol. I don't know all the ins and outs, but I believe an Upgrade can be requested
This subreddit is more about discussions and news, that's why people downvote your post. For questions there's r/cpp_questions. Also POO is called OOP (Object oriented programming). 'Poo' means 'shit' in english. :)
[P1061](http://www.open-std.org/JTC1/SC22/WG21/docs/papers/2018/p1061r0.html) would be so useful to me. I had came up with a tuple of index sequence and `std::apply`. The best would be something like that: constexpr auto [...S] = std::make_index_sequence&lt;3&gt;(); return ((std::get&lt;S&gt;(tup1) * std::get&lt;S&gt;(tup2)) + ...); --- But at that point I wonder, would it be possible to skip the pack declaration and destructure inline instead? template&lt;typename F, typename T&gt; auto my_apply(F function, T tuple_like) { return function((...tuple_like)...) } The `(...tuple_like)` would destructure the `tuple_like` into a pack, and the `...` would unpack the introduced pack.
&gt;This subreddit is more about discussions and news, that's why people downvote your post. For questions there's Thanks for information. &gt;Also POO is called OOP (Object oriented programming). 'Poo' means 'shit' in english. :) Oh shit, sorry :)
I really want P1061 too. Building on top of that, I wonder how difficult it would be to allow implicit construction where possible, using structured bindings. e.g. struct foo { int a_; double b_; }; struct bar { int a_; double b_; }; auto [a, b] = foo{}; auto test = bar{ a, b }; could become struct foo { int a_; double b_; }; struct bar { int a_; double b_; }; auto test = bar{ foo{} }; 
Implementing HTTP/2 (or HTTP/3) is a *MASSIVE UNDERTAKING*. It requires ten times more code, the algorithms are harder to write, and the specs are harder to read.
Cpp questions are highly welcome in our subreddit r/cpp_questions Though we dont do homework
I've not even got that far to be honest. 99% of what I need is basic mutex, recursive mutex, lock guards and simple thread creation and joining. I've just dipped into the parts which I needed, and to be fair it's been OK for that but not the most readable book I've got.
If you don't mind me saying, I also think your algorithm all wrong. Don't create a `std::vector&lt;std::vector&lt;char&gt;&gt;`. Very inefficient. Create a **pre-reserved** `std::vector&lt;span&lt;byte&gt;&gt;` directly to the mapped file. Right now you're calling malloc a ton of times, where you only need to call it exactly once. You are also copying the bytes for every chunk many times, where you could be copying bytes exactly zero times. Such a design should be at least 10x faster than your original, possibly as much as 100x on Windows given how slow its `ReadFile()` is. Remember, the fastest program in the world is the one which does zero work. Doing no i/o at all will be very fast.
We are for years trying to do 2000 things in 2000 different contexts. In the meantime D has: foreach (t; tup) { } static foreach (t; tup) {} And those combined with static if. I wonder why we have to change to recursive thinking when the normal patterns in imperative language are iterative. Those D constructs are natural and unroll to what everyone would guess. I still wonder why not that and end all the stories with needing recursion and indirections: constexpr for + constexpr if sjould be almost everything we should need for metaprogramming. Namely: conditionals and iteration in non-weird ways. 
I assume you're French (or Canadian?) XD
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
I would just clarify that *normal patterns* depend on the data type. E.g. for recursive types, a recursive pattern is far more natural than an iterative pattern.
The video sidesteps the structural theory of key-value coupling and indirection. Fundamentally, using the STL is structured around indirection/low cost abstraction for *ROBUST* use. It is an intentional design decision to decouple program design from the volatility/gotchas of low-level programming in C, such as pointer management. Case in point: elements in vectors can be addressed by index regardless of pointer invalidation. The index can (and *should*) be lazily evaluated to access the element, avoiding pointer invalidation issues. It does mean that both the vector and the index must be tracked (approximately twice the size of a raw pointer), but in most cases the robustness is well worth the overhead. This can even be turned into a class with pointer-like semantics: ```c++ /// Customization point for containers--specialize for vector /// template &lt; typename Container &gt; struct key_type { using type = typename Container::key_type; }; /// Syntactic sugar /// template &lt; typename Container &gt; using key_type_t = typename key_type&lt;Container&gt;::type; /// Associative access--overload as needed to adapt container types. /// template &lt; typename Container, typename Key &gt; decltype(auto) access( Container &amp;&amp; container, Key &amp;&amp; key ) { return container.at(key); } /// Pointer access semantics into a container. /// /// Key type is lazily evaluated, avoiding many issues with pointer invalidation. /// Works with both const- and non-const template types. /// template &lt; typename Container &gt; class container_pointer { public: using key_type = key_type_t&lt;Container&gt;; /// Construct from a container and a key. Could potentially also construct from a container and an iterator with a little leg work. /// container_pointer( Container &amp; container_arg, std::add_const_t&lt;key_type&gt; &amp; key_arg ) : container( &amp;container_arg ), key( key_arg ) {} /// enable default constructor /// container_pointer() = default; /// Dereference operator--wraps access() /// decltype(auto) operator * () const { return access(*container, key); } /// Arrow operator, built on dereference operator. /// decltype(auto) operator -&gt;() const { return &amp;(operator*()); } /// Bool operator `if( pointer_instance ) {...}` /// operator bool() const { return container == nullptr; } protected: std::add_pointer_t&lt;Container&gt; container = nullptr; key_type key; }; ``` The above can be specialized to work with *most* containers via specializing `key_type` and overloading `access()`. For some use cases, it is desirable to have objects point directly at other objects, rather than via indirection. If it's a performance sensitive application, use pre-allocation (reserve) if an upper bound for utilization is available. Otherwise, use shared pointers as an indirection for those applications. From a best practices perspective, raw pointers into containers should be avoided whenever possible.
Well, we might soon have for (auto&amp;&amp; e : range) for ... (auto&amp;&amp; e : tuple) Which is basically the same thing?
I don't do any development in Apple's environment, so question - do they facilitate keeping multiple toolchain versions around and choosing which one to use? 
I'm italian student :)
1061 - implementation concerns with having the machinery for packs work outside of dependent contexts. Apparently this is hard for some compilers. 1096 - Rejected in San Diego (vote was close, 13-7). There's a view that we can certainly do structured bindings better, but these kind of tweaks are probably not the way to get there. 1381 and 1481 - Brand new papers that have been written since the last meeting.
I kinda have the same feeling when I first read memory\_order from cppref :-P : [https://en.cppreference.com/w/cpp/atomic/memory\_order](https://en.cppreference.com/w/cpp/atomic/memory_order) not a cs background, imho, Paul E. McKenney's "Memory Barriers: a Hardware View for Software Hackers" helped me /a lot/ [http://www.rdrop.com/users/paulmck/scalability/paper/whymb.2010.06.07c.pdf](http://www.rdrop.com/users/paulmck/scalability/paper/whymb.2010.06.07c.pdf) as well as articles from [http://preshing.com](http://preshing.com) , great resource. overall, this book strengthen my knowledge in this topic though :-)
NO! NO! C and C++ are different languages. C and C++ are different languages. However, C++ does a good job being able to compile most C code, and also has syntactic support to generate C ABI compatible code.
C++ was born from C. It used to be called C with classes. Since then they *both* have diverged. Almost none of what is considered modern C++ will certainly be mpile in C. But also there are things in modern C that do not compile in C++. There are very low level things and concepts that are considered define by the standard in one but not the other. C and C++ *both* have a common subset, but both are different languages. 
I have to say that most of the time I don't like those over generalized libraries that tend to play havoc with your compile times, autocomplete, code analysis, error messages and so on and so forth. If runtime overhead of your release build is your only concern, then they are nice. Otherwise I prefer libraries with concrete, common vocabulary types and happily do the occasional conversion between the datatypes if necessary. Admittedly c++ does a pretty bad job at providing vocabulary types though.
&gt; Is there ever a case where valid C code would not be valid c++ code Plenty of cases, especially with newer versions where C99 or C11 has features or syntax that C++ lacks. The simplest example case, though: /* C89 */ struct foo_t *foo = malloc(sizeof(struct foo_t)); In C++ that will fall to compile because `void*` does not implicitly cast to `foo_t*`. Further, all the new keywords in C++ mean any legal C code using those as identifiers will fall to compile as C++. &gt; is there ever a case where C code will compile more space/time efficient than c++ That would depend on the quality of the compiler, assuming you're comparing truly identical code. There's a few things like thread-safe statics in newer C++ or so on that would impact a comparison in C's favor, but for the most part, identical code _should_ result in similar output or an improvement for C++. &gt; is there a use for straight C in the modern day? One very valid use would be the lack of a C++ compiler for a certain environment, or a desire to avoid the dependency on a C++ runtime where even "small" dependencies are expensive. There are other reasons people prefer C that are harder to objectively qualify.
+1 for unreadability. I heard so many great things about the book and was slightly disappointed. Oh well all the information appears to be there just not in the most digestible format. 
Yes, those iterators do exist in the standard library (well, not for sockets, as the standard library doesn't have sockets, but there don't exist streams for sockets either): fstream::iterator, array::iterator, vector::iterator .... 
&gt; But also there are things in modern C that do not compile in C++. No need to go modern C for that. I'd wager there's almost no non-trivial C code base that will compile as C++ unless it is specifically designed to, for one simple reason -- implicit casts from `void*`. How many C programs actually put the cast in for `int * i = malloc(4);`?
Just name a variable 'class' or 'new' in your C code and you got a program that does compile with a C compiler but will fail with a C++ compiler. I doubt that there are situations where C code will compile to more space/time efficient than C++. Almost all valid C code is also C++ code after all. In general you provide more information to a C++ compiler than to a C compiler, so a C++ compiler can optimize better. C is a cross-platform assembler, it sure has its uses. But in almost all cases C++ is just more powerful and since it uses no-cost abstractions, that power comes with no extra cost in many cases. So I would personally always favor C++ over C. But considering how many programmers stuck out with C and never upgraded to C++ or Rust or Go or D or any other systems programming language, we will be stuck with C code for a long time. Buffer overflows will not die out anytime soon:-/
Of the top of my head: // C generic macros, not in C++ #define cbrt(x) _Generic((x), long double: cbrtl, \ default: cbrt, \ float: cbrtf)(x) struct Foo { int a; int b; }; main(void) { // implicitly int in C, error in C++ auto x = 5.5; // float x = 5.5 in C++, implicitly auto int x = 5; in C auto int y = 5; // explicitly auto int y = 5 in C, error in C++ register z = 5; // register int in C, error in C++ (implicit int *and* register) int a[x] = {0}; // variable length array are not C++ int b[3] = { [0 ... 2] = 0 }; // Ranged designated intializers are not C++ struct Foo c; // valid C/C++ Foo d; // valid C++, C needs a typedef struct Foo e = { .b = 1, .a = 2 }; // C++ designated initializers don't support reorder _Atomic char f = 'f'; // C atomics, not valid C++ } 
No, C++ is not a superset of C. The two languages have evolved separately. C99 and C11 have added new features which are not part of C++ -- for example variable-length arrays, `_Ugly` keywords, type-generic functions, built-in complex numbers, designated initialisers for structs, and probably more I've forgotten. Even in C89, there are differences in behaviour compared with C++; to pick one example, you can implicitly convert from `void*` to any pointer type in C, whereas doing so requires a cast in C++. However, there is a *common subset* of C and C++ -- carefully written code which can compile as either language. This is mostly useful for header files: if you write your headers using the common subset, then they can be consumed by either C or C++ compilers. Which language you write the implementation in is up to you.
I've been reading that stuff and its helping but its a lot to wade through and its not yet lead to the whole memory order business. I'd rather the book did justice to the entire story. Something to consider for the 3rd edition.
Explicit casts for `malloc` are actually strongly discouraged in C.
Thank you! While I have you here, can you comment on this: [https://godbolt.org/z/9TWmVg](https://godbolt.org/z/9TWmVg) It's a very strange optimization quirk where a trivial code change prevents a loop unroll even in clang 6.0.0.
Even with C89 and C++98 there are differences. Implicit casts from void*** or calling functions without having seen a declaration are an error in C++. The operator precedence of ?: is not the same in C++. 
Gor developed his implemention in concert with compiler developers. Recent discussions with other compiler developers regarding alternative proposals seems to be implying Gor's method may be the only feasible general[*] method. [*] There may be ways to allow special casing user provided frames, or the possibility of introducing a new fundamental structure in C++, but that's far from certain.
Return type can be auto.
I had never heard of that. Care to elaborate? Why is that so? It can't possibly be the same reason as C++. What are the alternatives?
Can you give an example where it wouldn't make sense to give these functions different names?
[This answer](https://stackoverflow.com/a/9568890/1371191) still stands. 
What about it? It has an old style C API. And considerably slower as shown in my benchmarks.
I agree. I think that the STL suffers pretty badly from 'because we can' levels of abstraction. But, anyhoo, that's obviously a matter of opinion. What's not an opinion is that there are good reasons that people over the decades worked hard to push as much of their code out of line as possible. Someone might think it's neat to write lots of templatized code, but it pushes so much code inline. When a tweak to a single line of that code, depending on where it is in the code base, means 10, 20, 40, 60 minutes of rebuild, you pretty quickly come to appreciate that templates should be used when they provide compile time safety in a way that couldn't be accomplished without them. So, in this little parser, I needed a templatized callback method in the callback version of the parser, but I put in some extra effort to keep all but a tiny bit of that code out of line. That kind of thing, in a code base as big as mine, can be the difference between life and death by compilation. &amp;#x200B;
c++ and C have a common subset, which incorporates most of C99, but not all - let alone C11. There are also some cases, where valid C code has indeed a different meaning than the identical C++ code (I think Stack overflow had a list) and some core language conepts are specified slightly different in both languages (e.g. around type punning). Regarding compilation: If you compile code that has the same semantics in C and C++ there is usually no inherint reason, why the C version should end up more efficient or smaller, but I can remember that there are some situations, where apparently identical code is compiled to different assembler code - I#m not sure if the heuristics are just differently tuned or if there where some subtle differences in the semantics under C or C++ that lead to those different results.
One more thing: character literal `'x'` is of type `int` in C and `char` in C++. 
Oh yeah, I do recall seeing that issue on macs before. I'm on linux or windows most of the time so it doesn't affect my work.
Can you provide an example? I don't think that's what the OP is asking.
This is the internet, so it's to be expected I guess.
 &gt; But also there are things in modern C that do not compile in C++. Example: [Flexible array members](https://en.wikipedia.org/wiki/Flexible_array_member) are not allowed in ANSI C++ (though many c++ compilers will compile them with warnings). 
I am working some legacy codes that the factory function(template) return different classes based on its input. For some reason that those return types have no common base class.
The official C++ extension is really really useful, the intellisense is amazing. Gitlens is also really handy
I've *wanted* to do this with specific conversion functions (but could have used different names): template &lt;typename T&gt; T convert(MyClass, ExtraContext); // ... specialize here int main() { // ... Foo foo = convert&lt;Foo&gt;(mc, ec); Bar bar = convert&lt;Bar&gt;(mc, ec); } Specifically, a static_cast/user-defined conversion wasn't appropriate because of the extra context data, and I didn't want to write convertToFoo, convertToBar, convertToQux...but ultimately ended up writing it that way :p. I was changing the type names a lot so it was getting annoying to change in the function names.
Ada can do this and probably a few others as well. I think you're right that implicit conversions are probably the main reason C++ can't do this. Also, not capturing the return value makes the call ambiguous as well.
`manual_event::reset()` does not need to notify the CV.
You repeat the type a smaller amount of times if you don't write an explicit cast. It doesn't make a difference if you intialize a pointer with malloc, such as `int *i = malloc(sizeof(int));`, but imagine the following: int *i = NULL; // Top of the function, "int" appeared once // rest of declarations, precondition checking... i = (int*)malloc(sizeof(int)); // actually initialized, "int" appeared 3 times // complex calculation/long state machine i = (int*)realloc(10*sizeof(int)); // new state, "int" appeared 5 times Now what happens when you realize `i` needs to be a `long`? You need to make sure you caught all 5 times an `int` appeared in relation to `i`. Now let's try to avoid unnecessary repeats: int *i = NULL; // let's leave this alone, "int" count: 1 // declarations &amp; initializations i = malloc(sizeof(*i)); // initialized, "int" count: 1 // calculations i = realloc(10*sizeof(*i)); // new state, "int" count: 1 Now we would only ned to change `int` to `long` in one place.
Sounds like somebody got carried away with templates &gt;.&lt;
thank you &amp;#x200B;
`_Complex` and `_Bool` are also a thing in C. The above list is just what came to my mind while I was writing the post.
Thanks!
`auto` won’t help here because your function decides what the return type is *at runtime*. The compiler needs to know what type to return at *compile time*. You could use `std::variant&lt;int, float&gt;` in your example, here
I don't think having an 'auto' return type fixes the brackets in this example since the template parameters are not used in the function parameters. It seems to me that OP is trying to overload by return type, which is not possible as /u/Wh00ster wrote
I use vs code for most cmake projects, sometimes generate a vcprojx and use visual studio but thats another thing ( it recognizes your cmake and can rebuild it if it changes) Had the same problem with VS Code like you. Idk if you're bound to using cl as a compiler (hope not). Because what fixed the kinda bad intellisense for me was using cquery addon for cmake + cquery and a compile database from building with clang. It gets the includes correct since it uses compiler commands. Feels so much better to use but an interesting Code highlighting which some people like, some don't.
&lt;3
Neat. But presumably wouldn't work for, say, a webassembly target? For those that are condemned to portable solutions, there are vectors that [provide stable iterators](https://github.com/duneroadrunner/SaferCPlusPlus#msevector) (shameless plug). The dereferencing implementation does involve an extra level of indirection, but for periods when you are not modifying the "structure" (i.e. the size) of the vector, you can [obtain](https://github.com/duneroadrunner/SaferCPlusPlus#make_xscope_vector_size_change_lock_guard) (memory safe) direct pointers to individual elements.
There is a paper in process trying to change that. 
Is the corresponding implementation available already, or are there any plans to release it? The repository I found at https://github.com/mknejp/vmcontainer is empty. 
Check out QtCreator.
Yea, this sounds like a XY problem from u/hashb1. It's cliche, but you have to take a step back and philosophically understand what you're trying to accomplish.
Is it different from the cppCon one?
Cant you just generate Visual Studio Project files with cmake?
I use [YouCompleteMe](https://github.com/Valloric/YouCompleteMe) for vim and it works for me, but I'm guessing it's more complicated to set up on Windows. *However*, learning the initial set up is a bit of a pain and can take a while. Valloric provides an example config file that generally requires minimal edits (adding in include directories, setting C++ version). I've also used KDevelop (I'm guessing that's not possible if you were looking at VS). It has nice semantic support but has crashed a lot for me, too.
Makes sense as the result of ( i* 0.1) is a double to not lose precision and then you are returning a 0 which would be an integer (no precision lost ) so to fix it make the 0 a 0.0 to have the same return type deduced from both return statements. Return statement results help the deduction of return types at compile time kind of like template type deduction rules.
Updated a little bit. As I made progress with the library. Updated benchmarks, examples in C++20 syntax and the trampolining explanation at the end.
Yes, but last time I tried the structure was really messed up. It doesn't reflect the project's structure.
I'm using Windows, but for Vim (and working on Swift) I'm using WSL because it's so much easier and requires a lot less setup. I'll check out YCM and see if it helps, thanks!
Can you be a little more specific ? For the compiler to deduce the return type the compiler needs a way to figure out the type at the signature of the function itself. Otherwise it won't make sense.
But it is possible to correct that, see [https://stackoverflow.com/a/41081377](https://stackoverflow.com/a/41081377) I'm working at a big university project with Visual Studio CMake (Open Folder) and I had not many issues with it. Most of the time it was really solid for my experience. What do you mean it does not recognize it as an CMake project?
I think I've found it to be faster, to ssh to a native linux machine and use all my vim plugins there and compile there, than it was to use WSL. See [here](https://medium.com/@leandrw/speeding-up-wsl-i-o-up-than-5x-fast-saving-a-lot-of-battery-life-cpu-usage-c3537dd03c74);
\&gt; What do you mean it does not recognize it as an CMake project? When I use the CMake features of VS (you open a folder containing a CMakeLists and it treats it as a project), sometimes it doesn't recognize my folder as being a CMake project.
You can write a function object wrapper with template conversion operator more easily than ever before, using aggregate base construction and CTAD deduction guides: template&lt;class F&gt; struct Auto : F { template&lt;class T&gt; operator T() { return F::template operator()&lt;T&gt;(); } }; template&lt;class F&gt; Auto(F) -&gt; Auto&lt;F&gt;; Then a wrapper would, generically, be: template&lt;class... A&gt; auto fooWrapper(A&amp;&amp;... a) { return Auto{[&amp;]&lt;class T&gt;() { return foo&lt;T&gt;(std::forward&lt;A&amp;&amp;&gt;(a)...); }}; }; Or specifically: template&lt;class... A&gt; auto fooWrapper(int i) { return Auto{[=]&lt;class T&gt;() { return foo&lt;T&gt;(i); }}; }; [Full example](https://gcc.godbolt.org/z/PIFZnE).
Actually, you don't need to pay for CLion after you graduate, you just won't be getting any updates. You need to have had a license for at least a year, I believe, and you keep your license for that version of that product forever. (Look up the policy if you're interested) 
constexpr if would work though...
This was the best talk of MeetingC++. Well done! :) What's the latest on MSVC support? 
I'm trying to install YCM, but I get this error when running the install script. Can you help me? &gt;\-- Downloading libclang 7.0.0 from [https://dl.bintray.com/micbou/libclang/libclang-7.0.0-x86\_64-unknown-linux-gnu.tar.bz2](https://dl.bintray.com/micbou/libclang/libclang-7.0.0-x86_64-unknown-linux-gnu.tar.bz2) &gt; &gt;CMake Error at ycm/CMakeLists.txt:107 (file): &gt; &gt; file DOWNLOAD HASH mismatch &gt; &gt; &gt; &gt;for file: \[/home/pierre/.vim/bundle/YouCompleteMe/third\_party/ycmd/cpp/../clang\_archives/libclang-7.0.0-x86\_64-unknown-linux-gnu.tar.bz2\] &gt; &gt;expected hash: \[54198c9f941cb32f5915698d3ce11effc5a2985fcfe58c3b42532233bc942a23\] &gt; &gt;actual hash: \[e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\] &gt; &gt;status: \[1;"Unsupported protocol"\] &amp;#x200B; &amp;#x200B; &amp;#x200B; CMake Error at ycm/CMakeLists.txt:123 (message): Cannot find path to libclang in prebuilt binaries &amp;#x200B; &amp;#x200B; \-- Configuring incomplete, errors occurred! See also "/tmp/ycm\_build\_6da5ep7e/CMakeFiles/CMakeOutput.log". ERROR: the build failed. &amp;#x200B;
what hath God wrought
If you don't need constexpr matching, it's working in MSVC 15.8.8+. But if you do need it, avoid greedy cycles (bug reported to MSVC).
Demonstration of the algorithm (for divisibility testing): https://gcc.godbolt.org/z/yqc5u2 Hoping that C++ compilers will begin to implement this optimization before long!
hmm that's disconcerting... YCM runs Clang libraries in the background and interfaces with it to see any errors reported by clang. Because the Clang API is pretty unstable between versions, YCM by default downloads a specific version and builds itself with those headers. It goes on to build that version of libclang. The error is saying there's a problem downloading Clang. Specifically the hashes don't match which is strange. I don't know if that's a red herring error, since it's also showing a "unspported protocol". I haven't built clang in WSL (WSL ubuntu I'm guessing), or windows in general, so I'm not really sure here. Hopefully that helps to add context to the error, though.
`span&lt;char const&gt;` is better than `std::wistream&amp;` if you want to go with concrete types.
So I've successfully ran the full build process exactly as explained in the guide. https://valloric.github.io/YouCompleteMe/#full-installation-guide However, when I run Vim, it simply says the the YCM server shut down, and I can't start it. What do I do next?
C++ is a language with some concepts that are hard to get right. Other languages make these things easier and are therefore easier to learn. For example Python and Java have garbage collection and therefore you don't need to get ownership right to use the language effectively. That being said, you can absolutely start with C++. There is no prerequisite to know other languages first, just be aware that you're jumping straight into the deep end.
[The New C Standard: An Economic and Cultural Commentary](http://www.knosof.co.uk/cbook/cbook1_2.pdf) probably has hundreds of examples, not that OP will bother to read any as he/she couldn't be bothered to use Google and click any link on first page of results.
Thanks for the answer! 
Start by writing out a list of steps that you want to accomplish, in english. Once you have a list of steps, then write some code for each step that know you how to do. Then you'll have most of a program. Then come back and ask for help with that part. 
That wasn't related to the topic of streams vs. something else. It was a more general comment on inline vs. non-inlined code. 
I understand I have to create a while loop but I don't understand all the Symantec stuff behind it. I kinda just gotta a hit from one of my buddies that I need to use &amp;.
There is a cmake tool in VS code by u/vector-of-bool which works great. 
There's a lot of setup in the beginning. You really do have to read through the whole readme carefully. It's because it's trying to support a lot of different platforms and user configs. 
Right. Deciding that you need to use a while loop or an &amp; is getting ahead of yourself. Start by solving the problem in english. 
We didn't have much time to prepare the code with holidays etc. in the way, but now that the talk is out we'll have to hurry up a bit. We will probably have to release it in whatever state it is so people can at least take a look at the implementation and play around with it, and then follow up with all the polish later.
It doesn't work for me sadly. IIRC that's what I used in the beginning and it kept complaining about the missing includes.
I don't know enough about webassembly to answer that question. If it provides an API for virtual memory then it should be possible to port.
The latest release prompts you to generate the cmake compile commands, which are then used for the include paths. 
Okay now, no need for hostility. I had googled it and hadn't found any comprehensive answers. This book didn't come up, and even if it had I'm not sure I want to read through 20 pages of introduction and prologue when I just wanted a simple, practical answer. I appreciate your efforts to combat people using reddit as a lazy substitute for google, but I don't think it's warrented here.
Still having a hard time to transfer it over to cpp because I don't know the Symantec. My book requires that I calculate the sums and the average of the two numbers which I have but the even part me and my buddy are stuck on even with the tip of writing it out in English. This is what we have #include &lt;iostream&gt; using namespace std; ​ int main() { ​ ​ ​ ​ int number1; ​ ​ int number2; ​ ​ cout &lt;&lt; "Enter one number: "; ​ ​ cin &gt;&gt; number1; ​ ​ ​ ​ cout &lt;&lt; "Enter another number: "; ​ ​ cin &gt;&gt; number2; ​ ​ ​ ​ cout &lt;&lt; "This is the sum" &lt;&lt; number1 + number2 &lt;&lt; endl; ​ ​ cout &lt;&lt; "This is the average" &lt;&lt; (number1 + number2)/2 &lt;&lt; endl; ​ ​ ​ ​ return 0; } 
This isn’t viable for commercial use I don’t think. 
If the only way to view your code is by downloading a zip folder, I don't think anything in it would likely qualify as "hip-n-with-it" modern C++ code.
Why wouldn't it? Licensing?
Mostly I agree with this. It's too much magic and complexity that doesn't add much real value, vs just writing \auto d = fooWrapper&lt;double&gt;(42)`. I did find it useful once though. I was writing some test utility code. In Gtest, a fixture is expressed via inheritance, so all of the variables you get initialized in your fixture are member variables, which cannot use the `auto` syntax. I also wanted to initialize them inline, because the initialization was relatively simple (one liners) and I didn't want to list all the members and then separately init them in `setup` or whatever. So I used this trick, which allowed me to write things like: TopLevelTestHarness x; NestedTestHarnessObject&lt;double&gt; y = x.make("foo"); Etc. I felt like this was ok because of the combination of not being able to use auto on the left, and the fact that this was code that was relatively "high up"; it was just utility code for writing tests quicker and wasn't going to be reused in a million places. More broadly I do agree with you that I wouldn't use it most places.
&gt; It's weird that the talk brings up and then disregards several better structural patterns for dealing with element access than externally storing raw pointers. Either using shared/unique pointers or using handles/iterators is far more robust/maintainable than dealing with raw pointers into containers. As we mentioned the goal of this design was the combination of contiguous storage and pointer stability. That is why we disregarded the alternatives because they provide only one of these properties. Whether your pointer use is "robust" or not depends on many things. True, you can just use an index, but as you yourself mention, it is not enough to get access to the value. You need to carry a reference to the container around and that increases the size to the "handle" type. &gt; Smart pointers are a much more light-weight and generalized approach than building a specialized container that's only performant for large allocations. Unless that is exactly the problem you are solving? People write their own specialized containers all the time. The LLVM code base alone has lots of them, for example. Smart pointers are anything but "light-weight" when you're dealing with managing mega- or even gigabytes worth of values. All the state that is associated with the "smartness" has to go somewhere. The reason for contiguous storage is iteration efficiency. Linear scan through an array is the fastest way to process a large number of objects and that is exactly why we did this. We need both fast iteration over the entire container but also indirection through pointers, depending on the situation. Yes, handles are safer, but also add an indirection, an almost guaranteed extra cache miss on every use. All of those things add up when you're squeezing frame rates out of a phone. &gt; Fundamentally raw pointers into containers are counter to best practices and should be avoided. I think this sentiment comes from the fact people don't know their containers or don't know what containers they are dealing with. In fact most(!) of the stdlib containers have stable references. You need to know your tools and know the architecture of your application. If a system hands me pointers I expect those pointers to remain valid unless I do something to the system that indicates otherwise.
 int parse(std::string_view) { ... }; double parse(std::string_view) { ... }; double x = parse("3.14"); int y = parse("3"); C++ doesn't support overloading on return type, but you can approximate the solution using templates and implicit conversion wrappers.
Qt Creator is free software tool and has no effect whatsoever on the licensing of the code you write using it. Why would you assume using vim is fine but using Qt Creator is not? If you use Qt in your project, then Qt does influence your licensing options -- just like Qt does when you develop your software in vim, VSCode, CLion or any other tool incl. Qt Creator.
Moreover you can always download EAP builds which are free.
Yes, I think so. https://www.qt.io/faq/ “The general Qt toolkit, consisting of Qt Essential code libraries, the Qt add-on APIs, and the Qt Creator IDE are available dual-licensed for commercial and GPL licenses.” As I read it, you can’t use it for commercial unless you abide by GPL, which would mean your code would be open source I think. Someone correct me if I’m wrong. 
QtCreator is developed under the GPL license, which only really matters if you intend to ship a modified version of the IDE itself as a part of your project. You are free to use QtCreator as an IDE for anything you develop with no license obligations.
&gt; I couldn't imagine a world where they are considered wrong if you want to represent a hierarchy of 'is-a' type relationships, which the JSON hierarchy completely is I don't agree with Vinnie's comments that OO is outdated, but that said this is exactly the kinds of problem you see with OO overuse. The json hierarchy is not a good OO hierarchy in any way. A string, null, number, array, and dict, all have completely different operations and actually share just about zero interface and implementation. It's a big mistake to look at something that seems like some kind of hierarchy and decide to copy that hierarchy into OO without thinking a lot more carefully; your statements here remind me a lot of the famous square-rectangle OO example. On the other hand, the list of types is very much fixed and unchanging. Classic OO is great when you want to keep the interface fixed, but make it easy to add new types. std::variant (discriminated unions) are great when you want to keep the list of types fixed and add operations. JSON, or language parse trees, are actually pretty much the most clean cut examples where a recursive variant/discriminated union/sum type approach makes a lot of sense and OO is meh. If you want an example of a pretty nice json library that fits in well with modern C++, I'd suggested looking at nlohmann's json library. 
In my experience QtCreator is very stable, and works well for large projects. Part of its design goal was to make it easy to work on the Qt libraries, which aren't exactly a small project. It comes out of the box with a code model based on clang and good cmake support.
It's probably the best place you could have started first but each to there own. You should recognise some principles and methods that your experience with python gave you. First off the big question why? Is this just general interest personal use or is it to develope a career? What career there are other options s if your looking at webstack then or even gaming then c#, PHP etc would be a good place to head. So big question first what do you want out of it and what's the goal? I always say given the age of social media and content available through YouTube as well as e-learning or college c++ would be an excellent learning curb for your building blocks. Let's face python is a great language for AI and data, adding this string to your bow will give you a very broad range of knowledge at the heart of developing in Machin language. There's so much available theres nothing to fear from building the road to success.
See my other reply. You do raise a good point, maybe they word it confusingly to trick people like me in to buying the expensive license.
I like C++ and Python. I'm not fond of Java.
Removed as off-topic.
First result of my google query is [Compatibility of C and C++](https://en.wikipedia.org/wiki/Compatibility_of_C_and_C%2B%2B#Constructs_valid_in_C_but_not_in_C++) and first section of the page is called **Constructs valid in C but not in C++** containing like 10 snippets of code that is valid C but not C++. &gt; Is there ever a case where valid C code would not be valid c++ code, or would do something different in c++? Same goes for your title and all of your other questions, you can find all the answers on google and probably stack overflow although I would imagine that SO questions would be closed down as "not constructive". &gt; This book didn't come up, and even if it had I'm not sure I want to read through 20 pages of introduction and prologue when I just wanted a simple, practical answer. Actually, that book in exactly what you asked for, it covers whole bunch of corner cases in C and has countless mentions of how other languages (C++, Fortran, ...) go about implementing things under the hood. It is actually much better answer to your question than simple list of all the places where syntax differs, if pick random page in that book and search "C++", paragraph is gonna come up telling you how C++ handles &lt;the thing&gt; differently or in the same way. &gt; no need for hostility. No need for exercise in offense taking either. I don't think you deserve answer this good (all the credit goes to author, that book is quite amazing bedtime read).
You might want to take it to r/cpp_questions (and read their sidebar about formatting tips). What do you mean by "the Symantec"? Do you mean "the semantics"? Speaking of semantics: what do you mean by "between those inputs"? The user gave you two integers: a and b. You need to print out each integer x that is even AND &gt; a (or &gt;=a ?) AND &lt; b (or &lt;= b)? In other words: [a, b] or (a, b) or [a, b) etc. ... filtered to only those which are even. using namespace ranges; for ( auto x : view::ints( number1, number2 ) | view::filter(is_even) ) That's one possible solution (specifically in the doubly-exclusive case), but if it's a school assignment I'll bet they won't let you use range-v3.
No.
Seriously. I'm testing C then C++ in that order.
Is this Ok.
I really don't like the last version, because it starts to undermine type safety. Two unrelated structures should not suddenly become easily convertible to each other just because they happen to be build up from the same basic data types. If you need that conversion, write a to_bar function.
Just more ugly (but it is c++, so that is a given)
Thanks for the reply. I do not come from a programming background nor computer science background. Although I have always had an interest of how things work in technology. I originally chose python because I wanted to get into the programming world quickly. It has been 2 years of learning (SQl, flask, python libraries). Although, I know fundamentals and can solve some simple problems I sometimes run into things that I dont know about fundamentally. I am very interested in microcontrollers. I play with the radpberry pi alot. I have 7 of them. Most recently, the esp microcontrollers and arduinos. I currently have a fulltime job which pays well. I have 3 college degrees aswell. However, if I could have done it all again, I would have majored in CS or maybe just focused on programming. I really want to be a good programmer and of what I had read, c++ would give me a better understanding in general. Although I have built a few webapps, I dont find a big interest in the web stack. Also, where I live there are a few companies that I could see myself working for that focus on the imbedded architecture and java, c#. So learning c++ seems like a win win in potentially being able to learn other languages such as java and c# or even understanding javascript. This is my assumption. but ease advise if I have been steered wrongly. 
Many people say that c++ is not the right language to start with but honestly as long as you learn it little by little and you like it it's going to be ok. I personally started with c++ and recommend it, but you should probably consider what you want to do and choose the right programming language for you. If you don't know what you're going to do c++ is fine, and then if you realise it is not what you want to do you can just learn another language and most of what you learned for c++ will apply there too
1 hour is a long time, forgive me for not watching the talk. Two questions: 1. Can you link to the library here? I'm assuming it's on GitHub. 2. Does the library also handle not-known-until-runtime regular expressions, or do I need a separate library for those?
It's `...` instead of `static`. Are we really splitting hairs over that? And I'm not sure what part of "static" suggests the behavior it's actually doing, where `...` does strongly imply expansion.
I very much disagree. It's wrong to consider what is common to be only the data. Functionality is also an important part of it. They do share functionality, as well as data. This little example has less common functionality than my more full featured one. And of course if you don't use a hieararchy then you end up, again, doing what OO was designed to get rid of which is switch statements to deal with the nodes based on what type they are. IMO, this kind of thing is exactly what OO was designed to deal with. 
&gt; trampolining explanation Nice, I was meaning to ask on that when you mentioned it during Cpp.chat stream. Nice workaround indeed.
&gt; trampolining explanation Nice, I was meaning to ask on that when you mentioned it during Cpp.chat stream. Nice workaround indeed.
OK. I'm sure we'll all survive your disappointment.
I'm not complaining about the ..., but the auto&amp;&amp;.
https://github.com/hanickadot/compile-time-regular-expressions
Single-return-type is baked into the DNA of C++ but one way to get around it is to invoke a passed function object with the result instead of using the return channel, as this function demonstrates: https://github.com/boostorg/beast/blob/06efddd8b851610b5b3a5832ac87f1c52b838d9b/example/http/server/sync/http_server_sync.cpp#L97
if you have a C++ question ask it in /r/cpp_questions 
Also, I should note that I have dabbled with quite a few different languages. I have found some very nice newer languages such as elixir, and I could see myself using rust. But again, back to the basics. After learning python, I feel like it is a bit of a crutch. I don't know. 
&gt; user-defined conversions It has those (as `From` and `Into` traits), they are just all explicit.
Ah I'm an idiot. I misread your comment. What i read was: &gt; Explicit uses of malloc are actually strongly discouraged in C. That's why I was so confused.
Return a std::variant?
What does `if ...` over an array mean?
Yes, they are implicit by default in C++.
I wouldn't expect an unqualified call to isspace to be strictly standard-compliant for C++, so in that sense it might be a bug. And coincidentally specifying std::isspace would indeed have prevented this mistake as it would not have compiled.
It is for compile time known regex only.
Complaint... I mean guaranteed by the standard to work using only the standard library.
BTW, I should qualify the above by saying... I do of course allow that it is more 'modern' in the sense that, in the process of doing it he is probably using STL features of a more recent vintage. But I don't at all accept that it's superior just because of not using an inheritance hierarchy. 
Exactly the same as over a tuple with identical elements. 
Are you trying to modify and sell qt creator?
Uh, great. What does `if ...` mean over a tuple?
Yes. Thanks &amp; Sorry
I dunno... I think the fact that you can do it no problem with an intermediary makes it far less questionable. Maybe even have it as opt in for the target class? Really, I just want to reduce the bloat for conversions between tuples, structs, pairs, etc. There's an incredibly amount of wiring that needs to be done to make general purpose containers "suitable" for everyday code. Automating that process reduces bloat and the opportunity for bugs - it's no more dangerous that implicitly generating equality and ordering operators, ala. &lt;=&gt; imo
I already did. I'm just reaching out to any Meson users and since this subreddit seemed helpful with CMake and introduced the idea of modern CMake. I would think this would be ok. If this was just a regular C++ question then sure I would only ask that 'cpp\_questions' subreddit. But I think this would also be a fun exercise anyway if not only a question for any given language.
&gt;As we mentioned the goal of this design was the combination of contiguous storage and pointer stability. That is why we disregarded the alternatives because they provide only one of these properties. That was actually one of my principle issues with the talk: It pitches pinned_vector as a general audience approach: the talk opens with "What's the most commonly used container? A vector!". But the talk doesn't compare the pinned_vector's performance with using common idioms. I would have like to have seen benchmarks vs shared_ptr and vs. a handle based approach. I'd especially like to see benchmarks where notable work was performed on each element, as the additional memory IO can influence the overall overhead. &gt;I think this sentiment comes from the fact people don't know their containers or don't know what containers they are dealing with. Relying on pointer stability (or iterator stability) can complicate reasoning about code behavior, impacting maintainability and debugging complexity. Sure, you *can* do it. However, as a rule of thumb STL abstractions and idioms should be followed except in edge cases where there is clear reason to disregard them--save unnecessary complexity for where it has a notable ROI. The pinned_vector container clearly is targeting such an edge case: &gt; Smart pointers are anything but "light-weight" when you're dealing with managing mega- or even gigabytes worth of values. Most code uses much smaller vectors with tens to a few thousand items. At those sizes, the talk's own benchmarks show pinned_vector is notably slower than std::vector--quite possibly slow enough to accommodate added indirection (handles, shared_ptr) and still be faster. If the talk was "managing very large vectors for games, databases, etc. with pinned_vector" I would be entirely on-board. However, it's labeled as a general topic. As such, it should address how to apply an idiomatic approach, and at what volumes that breaks down. Generically, I'd advise someone to try an STL/idiomatic approach before integrating a custom container. In the same vein, I would advise them to avoid storing pointers into externally managed memory unless absolutely necessary. Most algorithms can be implemented around shared_ptrs, key+container references, and STL abstractions with acceptable performance. Tight coupling generally bogs development down and should be reserved as an as-necessary optimization. So, from the talk, I don't think pinned_vector should be the preferred approach unless dealing with very large data sets. As a general approach, I'd encourage developers to practice designing around STL abstractions and idioms.
Sober up
After seeing this post, I can definitely say that C++ became way too expert friendly language...
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
QtCreator is piece of crap - it crashes, hangs, freezes few times daily for me. It’s simply not designed to handle more than basic projects. 
I don't know what your definition of "large" is but I use it for my codebase (a few hundred thousand loc), and sometimes Qt or Clang's codebase (a few million) and it does not crash. Old versions (4.1, 4.2) used to crash quite a bit with the clang code model but nowadays it's fairly stable.
This is typically called "continuation passing style", and it can help untangle situations like this quite nicely!
Project I am currently working on consist about 40 binaries (+ dozen of third party libs) - few millions of SLOC. There are like 100 or more cmake files, shitload of resources etc. Upon opening Qt Creator with this project it hangs for 2-3 minutes. You can forget running / debugging it from QtCreator. 
Well, thank you for this resource. I will definately consult it. I'm sorry if I came off as ignorant, that wasn't my intent. I did find several Stack Overflow articles, but a few of them contradicted each other and weren't very helpful. 
&gt; Upon opening Qt Creator with this project it hangs for 2-3 minutes a literal hang or it waits until cmake completes ? you can disable cmake startup auto-running in the option if that's that
Yeah, I disabled it - without it Qt Creator was unusable for 20 minutes :)
Just check https://bugreports.qt.io/projects/QTCREATORBUG/issues/QTCREATORBUG-21867?filter=allopenissues Almost 3.5k opened issues. 
I think the above is true for everything in C++, not just coroutines. &amp;#x200B; If coroutines become part of the standard, I expect a bit more investment in coroutines from the compiler writers than occasional hacking by coroutine enthusiasts we have at the moment.
I use Eclipse with CDT. It takes a little configuration to get going (include paths, C++ version, etc) but once it's going and your code is indexed it works great. 
Absolutely!
Nope, I was simply wrong. 
 👍
Thanks it's my first time here and thanks
I feel like I should say CMake here, but honestly... SCons. It has a couple killer features that few other systems have, and AFAIK none of the CMake back ends do. For example, basing rebuild decisions based on file contents rather than just timestamps. More accurate and, if you use the timestamp-MD5 "decider", potentially actually *faster* than the Make way. Another one that is great that I'm not sure if others have though *doubt* it is accurate rebuilds in the face of most build script changes. For example, if you change the build script to change the flags passed when building `foo.o`, then it will rebuild `foo.o` and just `foo.o.`. The big drawback is for huge projects it can be very slow.
&gt; template&lt;class F&gt; Auto(F) -&gt; Auto&lt;F&gt;; What does this mean?
Well, thanks! But honestly, what makes life easier for experts is good for everyone - aggregate base construction and CTAD are great features that cut down on boilerplate, which makes code easier to write and to read. 
You can generate Eclipse projects with CMake
:-) Halo worked like a clock! My guess is that in the second example, loop was unrolled first, which made the body bigger and it was harder to make sense out of it when it was inlined into the main. There is a discussion here: [http://lists.llvm.org/pipermail/llvm-dev/2017-November/119179.html](http://lists.llvm.org/pipermail/llvm-dev/2017-November/119179.html) and there is a bug "**Optimizer fails to unroll non-natural loop**" that should take care of it: [https://bugs.llvm.org/show\_bug.cgi?id=34293](https://bugs.llvm.org/show_bug.cgi?id=34293) &amp;#x200B; &amp;#x200B;
Its future is a bit uncertain at the moment, but QBS is my favorite build tool. The declarative system that they build around tags and rules to transform tagged files into other types of files is very powerful and leads to very simple and clear build files.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/aolmkn/help_requiredassistance/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
You could try [rtags](https://github.com/Andersbakken/rtags) with emacs or [ccls](https://github.com/MaskRay/ccls) with emacs or VSCode. &amp;#x200B; You just need to tell cmake to export compile\_commands.json and those tools with find all your includes correctly.
Fully agree, I use it for plain cpp projects every day. Pretty lightweight but still powerfull
https://en.cppreference.com/w/cpp/language/class_template_argument_deduction
Too bad Qt decided to deprecate Qbs. 
I saw the original cppCon talk a week or so ago, and it was the single coolest thing I've seen done with C++. 
Ctrl+Alt+R You're welcome.
http://wiki.c2.com/?ThreeStarProgrammer
For forwarding the parameter `a`, I thought we should use either `static_cast&lt;A&amp;&amp;&gt;(a)` or `std::forward&lt;A&gt;(a)`. What's the reason of using `std::forward&lt;A&amp;&amp;&gt;(a)`? It seems quite peculiar.
Check out waf. It originated as a scons enhancement, but later became its own thing.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/aomgd9/need_help_compiling/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
My company had so many problems with waf I still have PTSD flashbacks about it
Oops yeah, that's a mistake - I started writing one then switched to the other. Thanks! 
That's a (class template) deduction guide. 
Could you perhaps provide references or papers that pertain to these discussions/sentiments?
neovim/nvim-gdb/ccls/LanguageClient-neovim/ncm2
I don't care. I just want consistency. I don't want to deal with other people's bright ideas or biased opinions. I want to open a build declaration file and read it with minimal effort. Since cmake is the standard that means cmake wins. 
Assuming `foo`'s `i` parameter is evaluated at runtime, I think my preferred way would be to have `foo` return a `std::variant` of all the possible types. E.g. struct A { }; struct B { }; struct C { }; using Object = std::variant&lt;A, B, C&gt;; Object factory(int i) { switch (i) { case 0: return A { }; case 1: return B { }; default: return C { }; } } ... and then use a visitor on the return value ... std::visit( [](auto&amp;&amp; obj) { use_object(std::move(obj)); }, factory(n) ); (Full example: https://gist.github.com/gmbeard/25631362f74576e0837a5be1f39a4a87) 
Sorry for the late response. I don't log into this account that often. The gcc_example branch was created literally to just host that gcc_like.cpp example I wrote to respond to your post =).
I don't see anything that these types have in common API wise besides ultra generic things like copying, debug printing, etc. And in fact debug printing is the only meaningful piece of API you get in the base class. And to be clear, they don't share data. A string, a number, nil, etc are disjoint possibilities for the data that a json value can hold. But the different disjoint possibilities don't share any data at all (looking at your code, I have no idea why you store a "name" as part of the json base object, this isn't properly part of a json value at all). When you use std::variant you don't really use switch case (though it may be used as an implementation detail). And just because OO was designed to deal with something, doesn't mean that that thing is always worse than OO (though switch case was probably overused back in the day... leading to OO, which now often gets overused). With variant you are just changing the striping or grouping. With OO you write each type together with all its functionality. So it's easy to add a new type, but to add functionality you need to modify each existing type. With variant, you group each piece of functionality together. So it's easy to add new functionality, but to add a type you have to modify each existing piece of functionality. This isn't really a matter of opinion; it's pretty objective and easy to understand. In a given situation, you need to decide what is more likely to change. Even in your own code, you have an enum in the base class telling you what the derived type is. You note yourself, that this is faster than RTTI, which presumably would be used for downcasting. As soon as you have a fixed, finite list of types and you are storing an enum like that or downcasting, this is huge code smell that in fact variant is a preferable solution than inheritance. If you don't believe me, than listen to none other than Eric Lippert tell you that downcasting is code smell: https://softwareengineering.stackexchange.com/questions/366592/what-is-a-proper-use-of-downcasting. Anyway, I want to be clear, that the issue with your code is not that, in a vacuum it uses inheritance, or that it fails to use std::variant or other fancy 17 features. The issue with your code (well, one of them) is that you happen to be using inheritance, when there are significantly better solutions (which also happen to be more accessible in 17).
The only thing argagg does for you is write out options. If you want to provide usage text or a description that's up to you. It writes it out every definition (in definition order), four spaces indented. It first writes the flags for that option, and then the help text associated with that option. It's facilitated by an `std::ostream&amp; operator &lt;&lt; (std::ostream&amp;, argagg::parser)` overload: - https://github.com/vietjtnguyen/argagg/blob/e678cebf90d8f132f5e54f19c6b95b75e655226c/include/argagg/argagg.hpp#L1686-L1701
I honestly just wish that the standards committee would come together, decide a build/packaging system should be within their remit, and make one the single blessed choice, because the thing which gets on my wick more than the failings of any one build system is the fact there are so many, and it's such a goddamn pain when you see a cool library but you don't want to touch it with a barge pole because it uses some random build system you've never seen before. This is one of the reasons I mainly use CMake, warts and all. And yeah, the scripting language is just incredibly awful. But, on the other hand, when the word comes down from on high that we need to do a Windows port, Visual Studio understands what to do with CMake projects, and life is slightly less irritating.
Very interesting! Although, my intent was not to alter control flow but simply to provide the result of a calculation (which can have different types at run-time)
The papers aren't public yet, hopefully it'll be a draft for Kona fairly soon.
Me too. It finally shipped today, should get it Monday at long last.
How is the egrep test done? I tried to go through the repo but could not find it. GNU grep is notorious for doing unicode matching by default, even if its input is only ASCII. This slows it down a lot. Unicode can be disabled with something like `LC_ALL=C grep &lt;options&gt;` but grepping for LC_ALL or POSIX in the ctre repo did not produce any matches.
Since that announcement there has been a dramatic increase in the number of external contributions though, so it is possible that QBS will see life beyond this year.
Out of curiosity, what IDE do you use to work comfortably on such a huge codebase?
While the scripting language in cmake is pretty awful, the goal is to do as little scripting as possible
&gt;Unfortunately, the release date for the item(s) listed below has changed, and we need to provide you with a new delivery estimate based on the new release date: &gt; Williams, Anthony "C++ Concurrency in Action" Estimated arrival date: March 11, 2019 .... Goddamnit!
Hey! PM Lead for the Microsoft C++ team here. Any chance you might still be interested in helping my team investigate these issues? Hopefully, we will be able to surprise you with a quick turnaround on these issues. We definitely want VS to be for you the "rock-solid development environment that supports CMake projects" that you're looking for :)
This is actually due to the use case of this snippet, as in [my reply to t0rakka](https://www.reddit.com/r/cpp/comments/aob5tx/readfile_turns_out_to_be_slower_than_stdifstream/eg0aqrp/). If you've got any ideas for improvement for my case, however, I'm all ears.
GNU make is all you need. Use `include` appropriately. Use a tiny shell script to do out-of-tree builds if needed. Edit `config.make` manually to set flags and stuff. `make` may be old and quirky, but at least it's not braindead like a lot of replacements. There are some useful features it lacks, but nothing worth giving up the existing features for.
&gt; QtCreator is piece of crap - it crashes, hangs, freezes few times daily for me. you're holy shit fucking wrong. very fucking wrong.
&gt; But I don't at all accept that it's superior just because of not using an inheritance hierarchy. I don’t think anyone is arguing that. The reason to avoid inheritance hierarchy here is (arguably) design but that’s partially because a discriminated union here is (inarguably) faster.
It’s exceptionally easy to create a git repo and upload your code. Do you use version control in your own products?
For me Meson win hands down. The language is sensible and easily written. The amount of targets that gives you is great: sanitizers, unity builds amd precompiled headers are for free for example. The way to avoid boilerplate is also great (disablers + feature enable/auto/disable, which is an option thought for packagers). The last version can also consume CMake package files though I expect that to be not really mature yet. The option management is much clearer than in CMake also in my opinion. And the documentation is great! It has a manual, a wuick reference and a full reference of all functions.
Meson is systematic, things live in their place (meson.build and meson_options.txt) the DSL is very readable (90% python-like) and no macros or custom things. I think that would fit well your description. Great docs also.
Haha. Dare to man... and make it work in many platforms using dependencies.
Okay, now what? The only reason `automake` is so weird is because it *doesn't* depend on GNU make, it accepts other inferior implementations as well.
GENie is a fork of premake4.4 with tons of useful tweaks and extra script features (like built in generators for FASTBuild and Ninja). It also has a toolchain starter script that supports tons of configurations that you can use directly or customize to your heart's content (it's just a Lua file). http://github.com/bkaradzic/GENie
[conan.io](https://conan.io/) is awesome 
This does not work properly for negative integers. If you use the 'default' form on either an unsigned integer, or one that has been asserted to the compiler to always be positive or zero (`__builtin_assume`, `__assume`, or `if (!(...)) __builtin_unreachable();`), then it generates *very* similar code to what yours does.
For large projects you need to increase JVM memory limit for Eclipse CDT to be fast and responsive. And increase index cache size. But yeah... It is actually great. There are a few hiccups in STL parsing, mostly related to std::chrono, but other than that it's very accurate parser in terms of finding references and jumping to definition/declaration.
I played around with CMake and Meson the last week or so and am liking Meson more so far. Meson/Ninja can build my programs in around 4 seconds, whereas Make takes about 7 seconds. Those times are both with one core. If I add -j4 to both, Ninja is over 10% slower than Make. So that's one reason why I'm going to keep both the Makefiles and Meson. What you say could be another reason. It's extra work to maintain two build systems, but it gives users a better shot of being able to use the software.
Is any third party interested in taking a lead in QBS? Are they coordinating their actions somewhere?
The great thing about anecdotes is you can both be wrong! :D
I don't know that anyone has actually stepped up to be maintainer or lead developer. I haven't seen any real discussion of the future plans, but it is likely to come up on the mailing list in the next couple months. The community (both developers and users) seem to be pretty responsive on IRC as well.
A talk that lasts for 1h is "a long time"? 
It also values external code generators: [https://mesonbuild.com/Generating-sources.html](https://mesonbuild.com/Generating-sources.html)
Not too long ago I would have upvoted you. But now I have found our Lord and Savior, Meson!
Well, we just disagree on that. Well, I mean I agree with the basic this vs. that tradeoff. But the 'enum' wouldn't be any different if you did it the other way. The main external purpose for the enum is that I stored all simple values a text, so it lets the client code know what the node type is if they want to convert to its actual form. In my own JSON parser there are extraction methods to get the various types which validate the type in the process. I didn't do that in this little one. But the client code STILL would have to know what the node type is, one way or another, in order to call the right extraction method. And it would STILL need to know if it's a container or a value in many cases. So the exact same sort of thing would be done either way. I just prefer the hierarchical scheme as the one I find most flexible in the long run. And I've been in the long run for a long time, with a LOT of code. I obviously understand the other side of the coin. I've spent days going through a hierarchy to add some new functionality. But, in the end, it was still better than the alternative, which would have been 'is it an A, or a B or a C' everywhere. The reason being that it's easy for the compiler to tell you if you failed to add new functionality. It's not at all easy for the compiler to tell you if you correctly checked the this or that type everywhere to deal with the new type. 
Dude, yes I use version control. OTOH, I've been working 7 days a week for two decades and never will catch up no matter how hard I work. So, sorry, I don't have the time. &amp;#x200B;
I'll keep my build system free of rapid radioactive decay, thank you very much.
true. in general. in this particular instance, however, he's just fucking wrong.
At the risk of being burned at the stake: autoconf/automake. CMake works great for the things it supports, but it's hell to make it do things it doesn't really want to do. Whereas autoconf is just a shell script, so I can do whatever I want. Same with automake, I just have more control over the created Makefile. 
Eclipse does it well enough for me. CMake is a tool of the devil no matter what IDE you use though.
exe my_program : my_source.cpp ; I'm not sure what this is called. Anyone? 
CMake + Python + Vcpkg I work on a project with a lot of dependencies and a lot of target platforms... Win, Linux, Osx and Android currently. We used to have a complex set of build instructions, which were a pain to maintain and a pain to follow. Then we switched mostly to using the cmake external projects functionality, which reduced user pain but still made building from scratch annoying. We're currently migrating to Vcpkg for all external dependencies, but using Python to manage the Vcpkg bootstrap and execution. We also use Python for shader generation, because we have a custom shader language that we compile to various flavors of GLSL, then to SPIR-V, and then back to GLSL. CMake can technically do all this, but it's slow as shit and way more complicated because of CMake's lack of threads or map/dict like structures. Cmake is my favorite build system not based on it's features so much as it's broad adoption.
&gt;Why would a simple store always need to be an atomic RMW &gt; &gt;Because that's the cheapest instruction that prevents stores from being reordered with other stores. Yes, that costs 18 cycles. Yes, I think 18 cycles is worth it most of the time. x86 reorders a store followed by a load to another location. Stores are always release on x86. They only need to be atomic rmw or mfence's when somebody just uses seq\_cst all over the place without any regard to anything, basically. Why in the world would you advise anybody to use an atomic RMW, or XCHG, for a simple atomic store if the algorithm they are implementing does not need seq\_cst in any way, shape or form? And don't say, because its easier. What a cop out.
Just: egrep PATTERN input In the benchmark egrep is a baseline for me. Thank you for your point. I will update the benchmark for the last iteration of this talk.
I think a standard package description would be much better than standardizing a build system+package manager. If we ever get that, managing dependencies would become so much easier.
Curious why you're comparing make to Ninja instead of meson to CMake? CMake can generate Ninja too so it's a weird asymmetric comparison.
I think a lot of C++ programmers are also interested in code-size and performance trade offs (to address some of the hubbub with Eric Niebler's ranges post). It's a difficult topic to discuss well, but I think there's a big itch for that analysis.
Thanks for that. GCC Trunk does even better (and better than Clang).
Like what?
Yes.
Me too! `touch xcode_cpp17_features.txt` `cat xcode_cpp17_features.txt`
For loops don't need fixing. Stop creating problems where there are none.
You have time to respond to like literally every comment on reddit. But you don't have time to git set remote origin, git add, git commit and then git push.
Not waf.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
Ditto here, we used it for a lot of Python + C++ projects. I can't even remember what the problems were because it was years ago, but a lot of weird finicky things. I wish I could recall, but I've either forgotten or blocked it out..
Unfortunately it seems to be out of print. :( 
Yes, whatever. Pick up 10000 lines randomly from Github from C++ code. 500 lines per project. Tell me how many occurrences of for you see and how many occurrences of recursion. 
To make auto works as return type first return should describe exactly what's type is [http://cpp.sh/83mbr](http://cpp.sh/83mbr)
You can use cmake + Ninja! 
What kind of things make a build system great?
Sublime + CLI when developing new features, VS when debugging. 
I really don't think that's in the C++ committee's remit. A separate ISO standard, on the other hand, would be nice. In the meantime, I'm just glad the de facto standard is CMake and not still autotools.
Almost no one uses http/2 directly. From the view of application, the protocol is always http/1. Http/2 is only applied in edge servers.
Yep I find cmake pretty darn readable since if you have a sane structure all you do I declare some targets and their dependencies
I like using [Bazel](https://bazel.build/).
I think it may be better to release a polished version later than rush it. Hitting a hard bug makes tinkering orders of magnitude less fun and annoying if you want to try and fix said issue while using it. Aside: I want the Jai language to come out too, but I think it is smart and for the best it is polished with as few bugs as possible.
Not so much. https://cloud.google.com/load-balancing/docs/https/
One critique is that it's too conversational. That kind of prose is fine in a book, but distracting in a guide.
I think the programming space this talk is focused around doesn't really fit your domain. C++ stl has some low performance ideas (could be worse) which is why most high performance code is c++ lite and mostly c with templates for code gen and custom libraries. (See clang/llvm) Also recently constexpr to get some extra compiler optimizations. As for performance, they mentioned 2 talks at the end, go watch those to get your answers, they are quite informative and applicable
Oh you're writing a text editor. They're easy. You store the text as an undo buffer. So all new content edits always gets atomic appended to a memory mapped recovery buffer file, a journal of edits over time. A separate index is built up of spans of spans by replaying the journal of edits (and marking out paragraphs usually), this caches how to render the final file quickly without having to traverse the whole journal. Note there is only ever one copy of the content ever, and you never ever copy it. This lets you copy and paste gigabyte text files with ease.
Quote: Fundamentally raw pointers into containers are counter to best practices and should be avoided. This is sorta true, but the line between memory allocator and container is thin. In general it is best practice to avoid exposing resource management to the system at large, so you often have something like a vector, but it is safely managed for its given purpose behind a resource manager. So you still have a pointer into an allocator. In fact, the statement above is impossible for a application later programs since all dynamic memory from new/delete is a pointer into the allocators container(s). It is just thread safe and has certain guarantees, but ultimately it's a container. I shouldn't pick too much, and I think it is important to see that this is not a design so much as using your OS to solve a problem. This is a very new idea since this has only been possible since 64 bit pointers were released and become commonplace. Without that the address space of 64bit we couldn't do this. But now I could see this fixing many problems in high performance situations. Robustness isn't a factor when performance is king. So if your OS does this already, you've already paid the cost, why pay more? 
Please do release it, this would help a lot with high performance applications/games. Would save me a lot of work if I made my 9wn game engine.
None of this works for negative integers, does it.
so basically it does the same thing, but std::reduce might work in parallel?
It gives a different result. It is thus not an equivalent operation. If you constrain it to positive integers, the compiler already effectively does it.
You focus a lot on the specifics, but it would be nice if started way more general. First: what is this thing your reviewing? Maybe many of your readers know, but certainly not all, and more or less all we have to go on is the title. Second: who should read this thing? New c++ programmers? Old c++ programmers? And also, who shouldn't read it. For example, if I've already read Jeff Goldblums "Functional programming always finds a way", is this still useful? Maybe you've already answered this in your previous review, but you don't link to it, and most people aren't going to dig through your archive. Just some ideas for future reviews.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
I find it amazing how any kind of developer could think of telemetry as "spyware". Like... seriously?
Well that actually makes a lot of sense! I always thought of modifying the file and recording edit history as two separate things, but unifying them as you said may actually be much faster. There's one problem, though - what if, after a long time of editing the same file, there are too many separate spans? Like, each character in its own span? Is some kind of de-fragging necessary?
That's literally the opposite of what he wanted- he wants to use what everyone else is using, not the 5838th newfangled one
I misinterpreted that. I thought that those biased or bright ideas were due to a full scripting language and would have to deal with the code from others in creative ways. He meant just the opposite: do not restrict.
I agree with the other commenters regarding comparing like with like. Try CMake+Ninja to be fair. Also, 4 seconds with -j4 is nothing. 10% difference is 0.4 seconds difference. The startup overhead may predominate here, and to benchmark properly you would need to repeat many times and get the mean and standard deviation to realistically compare the two; but such small times make this of little value. I have some big builds which take around 20 minutes with -j8 and CMake+Ninja. MSBuild takes on the order of 90 minutes, and Make takes on the order of half an hour. The size and complexity really differentiates the tools, and the difference is much more than 10%. Ninja's parallelisation is the best I've encountered; MSBuild is miserable. Make is decent, but not as efficient as Ninja.
I have been using Meson for my projects recently. The language is simple and it does the right thing by default. Basically it just gets out of the way and lets me focus on the actual project as opposed to the build scripts.
Hey, I'd be more than happy to help! Just tell me what I need to do :) I've sent you a PM
Can we talk about the cover? I find it weirdly unsetling...
It does not do better. It does exaclty the same https://gcc.godbolt.org/z/C0wGNI 
Still great, it always baffled me that pcre "compiles" regexes but has to do it during runtime.