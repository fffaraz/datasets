hey! thank you for rcc++ i've learned a lot from your project! thank you!! (i don't use your lib, but it encouraged me enough to make something for my own needs. before i didn't even think this was feasible at all) https://www.youtube.com/watch?v=o1FcBP3Eqrc
A big thank you to this community as most of the votes (87%) came from here.
gud suggestion. have seen ur issue opened. would fix that 
Guards are a great way to keep your code clean and more understandable. They ensure that: * A function is exited immediately when something is in an incorrect state. * Any code after the guard now has guarantees about that state (e.g. variable != nullptr) that the programmer now no longer has to worry about. * All the code now becomes nice and flat instead of a bunch of nested if statements. It's one of those few coding conventions that is very hard to argue against.
WoW is CPU starved as fuck, it really doesn't help.
Must stuff can be done once. Go in all configuration and add your include, then go in debug &amp; release to add the right .lib for the build.
That's cool - if you release this or write it up somewhere do let me know and I'll add a link on the RCC++ wiki!
I'm a little bit supprised that Vim is second :) 
Great article. I had multiple places in the code where I was wondering - do bunch of else-ifs at the beginning or form multiple nested tree. The core point makes sense - use nesting when cases are of identical importance/same decision level (in the sense of expected behaviour) - use guards when it's a special case, unlikely to occur
It definitely doesn't help, but it works well enough.
Why is that? Seems quite common in my subjective impression. "UNIX as IDE" gives you most (all?) of the conveniences of an IDE while still being pleasant to use. And you can customise it be just like you prefer it. Since I'm spending so many hours every day in my dev environment it's well worth it setting it up properly.
I just thought that on Unix more people use CLion or QtCreator. 
I use Eclipse but mostly for convenience features like refactor-rename and autocomplete. Everything else is handled by unix tools. It's hard for me to imagine working without grep, sed, find, make, and so on.
I don't know how you got 40 FPS when I get a solid 60, but that's an entirely different discussion. :) Not having DX12 is weird especially considering that they do have Metal.
Hah, before seeing your answer, I thought /u/mapek8 was surprised that Vim was not first!
So really I must say that I wasn't aware of Vim's popularity! 
&gt; It's the blind leading the blind. That's exactly right. People do things not the way things are supposed to be done, but nobody really knows that - people just repeat what others did and it's mostly a clusterfuck. Well, there are a few people deeply invested in it who have a feel for how it's supposed to be used. But they are very few. The documentation is on the verge of being useless - it's the why and the nuts and bolts that need explaining, the reference is almost an afterthought then. 
&gt; you don't by the way, you can use file glob but shouldn't He wrote about “good ways” and I agree. globs work but are overly ugly and verbose and requiring me to enter all files manually is just stupid. I wouldn't say that CMake is worthless, but for regular, simple projects, there are cases where good old make is much better if you only care about gcc-compatible (clang, icc?, ...) compilers on unix-systems.
My biggest gripe with the VS project system is that filters and project files are completely separate. I usually keep my project files in a separate directory, because all of the Visual Studio files clutter the source directory. If you do it that way, you can't use the filesystem view for a project, you have to use filters. Then you rename a subdirectory and you have to remember to rename the filter and readd all files in the directory. I would prefer a bit of a stronger coupling between directories and filters, even at the cost of some flexibility. On the other hand I only use Windows at work, so for my home projects VS is a bit too mich effort to set up.
It was so hard to learn Modern CMake in early 2016. With Daniel Pfeiffer and Mathieu Ropert's talks and this article showing up since then, I could have saved myself a lot of time and agony. Oh well. It's great this is all starting to show up now, at least. There's still so much more that needs to be explained, though. The documentation itself, while clear on what all the commands do, completely fails to provide any helpful guidance on how to actually use CMake. I still learned something new from the article - I hadn't realized there was a `find_dependency` command. That'll tidy up my Config files a little bit :D. Thanks for posting!
I a purely basing this response on the VS Code documentation, but you can code navigate, compile, and debug with it but setting up the tasks to do so. In my mind that makes it an IDE. 
MISRA would disagree. Early returns or multiple code exit paths are a big no-no in automotive industry.
It just wasn't in the poll initially.
You also can code navigate and compile in vim, also I have seen a plug-in for vim that adds a gdb support. VS code is distributed as a code edditor, so IMO it is.
[N1377](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2002/n1377.htm#move_ptr Example) is the earliest mention of `unique_ptr`. At that time I called it `move_ptr`, and only later renamed it to `unique_ptr`. I purposefully stole as much as the `auto_ptr` API as I could so that people could more easily search/replace `unique_ptr` for `auto_ptr`.
I'm not saying the results are not plausible, but I wouldn't be surprised if the numbers are heavily skewed either. People voting on Reddit are certainly not a random sample of all c++ programmers. Have you checked how the numbers from different sources compare?
Having sum types + easy to use pattern matching would be an absolute game-changer. We're stuck with `boost::variant` (C++11), where I find the usage too brittle (the switch on `which`) to use it.
Didnt know that. Another pain point of mine is that when you go back to the default in the gui, the setting is changed in the xml instead of deleting it. 
Good luck integrating third parties into your project.
That is pretty much exactly what you write in cmake (actually, you need only two lines)
I would argue, that you are correct for production code. Invalid states should be reported when they occur, not when they are used. But for debug builds you should definitely throw some asserts or early returns in there. It will help you with debugging tremendously.
&gt; The symmetry thing isn't great IMO. Personally, I really liked the symmetry argument. It wasn't something I'd every really thought about before, but now that I look at it, it really lines up with my gut feel for when adding an `else` makes sense. &gt; I really don't like seeing an else when the preceding condition returns early, just makes things more verbose. I think that's the whole point. If you're returning early, use a guard. The cases where you should use `else` are those where you have multiple returns, but none of them should be considered a special case.
You're welcome. Keep in mind that most used doesn't necessarily means better. You could use VS Code with the C/C++ extension on Linux, but I would recommend you to try Qt Creator and KDevelop first.
maximized settings and ofcourse, some of them really take a toll on CPU, and I was exaggerating a bit, but its definitely around 50-60 ish, which is unfavorable on my 144hz screen, other than that, if you fly a bit above suramar you'll see your fps drop like crazy, somehow every model takes a huge toll on CPU, turning down environment detail to 8 instead of 10 gives a great boost in fps (easily +20-30 fps) without visible difference. Really hoping they'll be optimizing a bit for BfA. 
Well, if you want, you can almost do that include_directories("./inc/", "./ext/boost/") file(GLOB SRC "./src/*.cpp") add_executable(out ${SRC}) If you don't need globbing, you even only need two lines. And yes, this is not considered good cmake at all (the"right" version is also 3 lines), but most colosely resembles your pseudo code.
If you violate ODR, even in a PIMPL, you're in UB land. 
Since 87% of the votes came from here (/r/cpp), one also has to consider the demographics of the C++ developers here. What you find here is mostly the more advanced and interested devs, not really your "regular C++ programmer". Maybe the "pro's" here use VIM more, proportionally :-)
OK thanks so much for that tip I will try them both out!
Oh I am a big fan of asserts. :) And IIRC one old lecture there was research that says they improve code quality. :) 
Newer standards are completely removing things from older standards. There are good reasons for doing this, and the things being removed are old and broken, but do not expect to compile c++03 with a c++20 compiler. For example, `auto_ptr&lt;T&gt;` is gone. 
So I'm in that group of CLion users. I moved to it because I was doing python development before in PyCharm. My only issue is that there is no community edition of CLion. However it's tight integration of cmake and it's versatility make it, in my mind, worth it.
good point
Apart from the default `cmake_minimum_required(...)` and `project(...)` lines, which are not mandatory, cmake requires you to write one line for trivial projects and 4 lines for simple ones. I honestly don't see, how make is better.
Linux, Solaris, and AIX at work. Linux for myself. Library issues aren't as bad as the debug/non-debug split in MS's std lib, but they do occasionally show up. Or someone manages to use a different libstdc++ than the system one, for what they believe are good reasons. And the further up the application stack, the more likely something breaks, because you depend on the layout and inline function details of everything below you in the stack. Now, the workaround is straightfoward, you rebuild everything you're shipping with a toolchain that you control. Just hope the tests catch the depended on unspecified behavior in the library you're rebuilding. Large scale C++ is so much fun. 
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/7yx34v/please_help_me_get_my_c_certificate_school/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I agree with everything you wrote. What I do not understand is if vim was removed from that diagram, why VS Code was not?
what about some "cmake: the good part".
Right, which is why I qualified it with "very nearly". The things that have been deprecated or removed in newer standards are so harmful (or at least risky) that it's worth removing them anyhow.
If you want to know how many Vim users you know, just casually say something positive about emacs in passing in conversation, and we'll jump out of the woodwork to correct you.
I'm not exactly clear on what you're arguing. To steal his example: double applyDiscount1(double price) { if (reductionType_ == Percentage) { return price * (1 - reductionValue_); } else { return price - reductionValue_; } } double applyDiscount2(double price) { if (reductionType_ == Percentage) { return price * (1 - reductionValue_); } return price - reductionValue_; } I would claim that neither of these methods contains an early return, but `applyDiscount2` looks like it does. In it, the `reductionType_ != Percentage` case looks more important and normal. With its `else`, `applyDiscount1` make it clear that both returns are of a similar type. But I guess I'm just rehashing the article. I like it. You don't. No biggie. :)
have you compared it with simple linear search? For such small data set, I don't think it worthwhile to increase your compile time.
IMO any time you have multiple returns in a function, that classified as early returning.
That was the story of working on Paperboy for the N64. It was my first game right out of school. After that, I moved to engine/content pipeline work. You can read more stories from that experience [here.](https://www.reddit.com/r/gamedev/comments/xddlp/describe_what_developing_for_each_console_youve/c5lg7px/)
you could have use target_include_directories(out PUBLIC "./inc/", "./ext/boost/") and had slightly 'better' cmake
Honestly suprised eclipse isn't a little higher up
As I said, I tried to translate the pseudo code as literally as possible. The linked blog post shows how to do it right.
Bjarn has a background project trying out pattern matching in C++. http://www.stroustrup.com/OpenPatternMatching.pdf
Ultimately I think it's a narrow distinction. Vim provides a huge number of out-of-the-box IDE features, and with only a few plugins it can do most of the things IDEs can do - though not always as "nicely". But none of that makes it an IDE to me, and I say that as a die hard Vim fan. The difference for me between an IDE and text editor is the default experience. Vim's default experience is very clearly a text editor; it doesn't show you file lists, it doesn't understand project definitions or build scripts, syntax highlighting and smart indent are disabled. When I log into a remote server and open vim, it pretty much just edits text. VSCode on the other hand *looks* like an IDE after you first install it, with no plugins. It puts the file list and Git integration front-and-center, it has a generalized concept of a "workspace", syntax highlighting and smart editing features are enabled by default, it has code completion for a half dozen languages out of the box along with a built-in debugger...it's way more than a text editor, regardless of how it might be marketed. Now, it's not a C++ IDE out of the box, certainly; it's more of a "web languages" IDE. But it's still an IDE to me.
I use Spyder for Python. :) 
Definitely useful at the right time and certainly good for education/self improvement, just not super useful when I'm trying to get something working in CMake/any other system or language. Good documentation with examples is more immediately helpful when I'm actively working on a problem.
well yeah, but my argument was that if lua is a CPU hog (or part of LUA (the bindings)) that its a part of what makes WoW CPU limited..
Just saying, getting code complete to work in vim is a lot easier than Eclipse. Just install YouCompleteMe and make sure you have your compile_commands.json in your project root directory and it "just works"
I have used a tool almost identical to this to cut the build time of a large existing C++ project by more than 33%. Of course it is not perfect but no tool is. The real measure is whether it is useful, and according to measurements this one is.
"Completely agnostic except when it isn't."
The OP mentions "faced aliasing pointer problems in PL research area" ie not C++ but hypothetical programming languages. If you made unique_ptr intrinsic to your language, and removed raw pointers, etc, you could probably fix aliasing at compile time.
The reason for this choice is that VC Code is a code editor whereas Vim, emacs and others are "generic" text editors. Furthermore, it comes with built-in features that make it closer to an IDE rather than a text editor with plugins. Sorry for not clarifying it before, but it's been a busy day.
Is said tool available publicly? I would have use for it.
Do I need to setup compile commands for YCM to work? The problem is that we use very non-determiistic makefiles and you don't really know which defines are triggered, sometimes resulting even in different headers being included. I'm interested what I would need for YCM to work and what affects how it's working.
The MISRA standards in C discourage it, that has nothing to do with this. 
&gt; plug-in That's the opposite of Integrated, e.g. the "I" of "IDE".
Are we talking about the same VS Code? It's as IDEish an IDE as I've ever seen. It took a custom config file a couple dozen lines long to calm down all of its helpful flashy whizbang assistant features enough that I could actually use it comfortably, but it is now doing a very solid job of being an IDE.
Globs only partly work. They don't trigger a re-configure, so you have to re-run cmake as you add files. So you might as well just add the files. Also helps for the inevitable missing file in the commit, and the occasional stray file getting compiled and ar'd. I prefer explicit lists in makefiles, too. 
Just made the comparison, and it's faster than a linear scan (based on ``std::find``) on a ``std::array``. Here are the digits: BM_IntInFzSet 60 ns 60 ns 11581370 BM_IntInStdSet 136 ns 136 ns 5116932 BM_IntInStdArray 172 ns 172 ns 4061261 BM_IntNotInFzSet 54 ns 54 ns 12883362 BM_IntNotInStdSet 182 ns 182 ns 3853735 BM_IntNotInStdArray 312 ns 312 ns 2254495 BM_IntInFzUnorderedSet 163 ns 163 ns 4313455 BM_IntInStdUnorderedSet 542 ns 542 ns 1293126 BM_IntInStdArray 175 ns 175 ns 3991203 BM_IntNotInFzUnorderedSet 120 ns 120 ns 5793480 BM_IntNotInStdUnorderedSet 489 ns 489 ns 1424362 BM_IntNotInStdArray 312 ns 312 ns 2257491 It's not very surprising, at least for ``frozen::set``: even for relatively small numbers, a fully unrolled, branch-free binary search does less comparison than a linear scan. Benchmark source update: https://github.com/serge-sans-paille/frozen/pull/37
I use codeblocks for everything myself (for 5+ years), it mostly works for everything I need, not had many issues so far, although I wish the autocomplete were a bit more robust. Another big plus is that there's a tool to generate makefiles from the codeblocks build system, or use custom makefiles, which you can integrate into your codeblocks build system itself and distribute easily I do mostly solo dev work or small teams though, so it may be crap for working in a larger studio. Also its profiling integration isn't too great, certainly not as good as it is in visual studio. However personally I found visual studio to be profoundly buggy and I couldn't deal with it If you do decide to use codeblocks I'd recommend not using the bundled mingw distro, msys2 is pretty great
vim isn't an IDE. UNIX is an IDE (of which vim is part). Come on...
Does this refer to the two strawpoll questions, which came up recently? (https://www.reddit.com/r/cpp/comments/7ydk8y/bestworst_c_ide_you_have_ever_used/) If so, the wording of those two question was different. It was a question about the best / worst IDE ever used. That is a slightly different question than what IDE one is using right now.
&gt; "UNIX as IDE" vim is on more platforms than *nix. Granted, I'm probably in a very small minority of people developing in vim within PowerShell on Windows (I do debug in VS and WinDbg though). Unfortunately, rtags just doesn't work on Windows, and YCM was a nightmare and never really worked properly for me. I find ctags/cscope get me 90% of the way there though.
No it doesn't. The poll I posted is linked in [this thread](https://www.reddit.com/r/cpp/comments/7ve6x2/what_ide_do_you_use_for_cc_development/).
What you are saying is the practice on most high quality open source projects. Assertion on debug, but no handling for out-of-contact for internal functions or early returns.. just debug crashes. Not sure why you are being downvoted... maybe people have a biff against you just in general.
only with plugins is it IDEish, they just get downloaded automatically instead of manually installing them. without said plugins it's neither more nor less like an IDE than vim.
In my 15 years of professional development, I've never met anyone who said they use Vim, and I've only heard it seriously discussed on this subreddit. It may be that it's just not popular within my focus - game and web development.
What else would an IDE *be*?
Thanks for that information. Good to hear from someone else that likes it :) Who knows maybe after trying Qt Creator I will just go back to code:blocks. I need to decide soon I've spent a few days agonizing over this, it's not like I can't change my dang mind. 
Bikeshed alert: I don't like the return value of the very first example: double computePrice(Item const&amp; item) { if (!isAvailable(item)) return 0; // ... } For me, a price of zero means "free", not "unavailable."
You have to run a ridiculous amount of Lua code (=addons) to hit that on a decent PC. It does have a more pronounced effect on lower-end PCs, in large part because it runs on a single thread.
And it's even more significant for strings, as the cost of a « comparison » is higher: BM_StrInFzSet 325 ns 325 ns 2157230 BM_StrInStdSet 507 ns 507 ns 1365919 BM_StrInStdArray 455 ns 455 ns 1559959 BM_StrNotInFzSet 278 ns 278 ns 2615427 BM_StrNotInStdSet 465 ns 465 ns 1570297 BM_StrNotInStdArray 490 ns 490 ns 1476754 BM_StrInFzUnorderedSet 395 ns 395 ns 1505620 BM_StrInStdUnorderedSet 868 ns 868 ns 766311 BM_StrInStdArray 451 ns 451 ns 1531543 BM_StrNotInFzUnorderedSet 210 ns 210 ns 3612011 BM_StrNotInStdUnorderedSet 681 ns 681 ns 1031227 BM_StrNotInStdArray 462 ns 462 ns 1515190 
I'm not going to get into semantic arguments with double quotes being thrown around everywhere. If VS Code is an IDE, then so is vim. If it isn't, then neither is vim. The point is, you can't call one an IDE and not the other, not if you want to remain consistent.
I'm the opposite. In my current work there is a big mix of Visual Studio, Vim, Emacs, Sublime Text. 50/50 Linux/windows. Code base is around 500k lines
This article is awesome, I don't work in this kind of thing at all, and I feel like it's a good exersize for my brain. 
Yea, that's a good point! Btw the best title for this would be "What's your favorite/most hated development environment", or something like that. That would include both IDEs and text editors and avoids coined terms like "IDE" :-)
That's a good point! Talks (videos) are for education, not for documentation and/or when you're trying to solve a problem! On that note it is certainly very welcome that someone finally writes an awesome blog post about this topic.
I strongly disagree that multiple return statements (of any kind) make a function more confusing. Also, if you as a developer are making changes to a function without fully understanding it first, you're already making a mistake so serious it cannot be solved by any code design standards. 
I imagine this depends greatly on what environment one does the survey in. Certainly, I hear about Vim a lot on here. I'm a Vim guy myself. I'm also a CS professor. Most of my students use Visual Studio. Toss in Xcode, Code::Blocks, Eclipse, and a couple of web-based environments, and you've got at least 95% of them. I don't have any hard evidence about what they use after graduating, but I'm thinking that for most, the habits they picked up in school aren't going to go away easily. Somewhere out there is a huge population of programmers, among whom a Vim-as-IDE user is an oddity. But I guess these people tend not to answer polls on /r/cpp.
Hey, are you suggesting that there is something positive one might say about emacs? &lt;glares suspiciously&gt;
Well, since it’s impossible for beginners to exit vim they get stuck in it and have to keep using it forever. 
I am a huge fan of CLion but my answer is to try a few of ides to see what they deliver, i for example like how good the Visual C++ debugger works, it works where GDB cant or the lack of any build system but i cant use the "intelli"sense of VS, it sucks or at least is not as good as other or the poor performance the compiler delivers vs GCC/Clang Only trying and experiencing what you like and what not will help you make the rigth decision, for me is it CLion but as the survey says there are others who find other ides which suits they better
What about coders who don't use IDE-like plugins, and just use a straight text editor? I use vim with some builtin features turned on (smartindent, syntax highlighting), ctags, and the compiler. Are we folded in under "vim with plugins" or not counted at all?
I have a friend that's been messing around with the N64 C SDK. The only compiler provided is ancient at this point, and super buggy. In a function, you must declare all of the variables at the beginning, before anything else, or else the compiler will throw an error.
There is MISRA standard for C++.
I don't see the benefit to rewriting it in C++. It would be more productive to simply create a class/template based front-end, as many others have done (e.g. LuaBridge). What do you hope to get out of it? More performance?
Each MISRA rule usually describes in less or more details the reasoning behind it but for this one it only says _This is required by IEC 61508, under good programming style_
1 line if I don't care about warnings, a recent C++-version and am willing to add every single file manually to the CMakeLists.txt. I've written a simple tool to create makefiles in the past. For a reasonably simple project-structure, I have to call `mfc` once on the commandline and it created a working makefile with dependencies that I could call with simply `make`. I've since stopped developing it, but adding things like automatic detection of tests would definitely have been possible.
I dont know. I can debug C# from VS Code. 
On Linux sublime worked out of the box but I couldn't get vscode to resolve symbols for the same project files.
Not pertinent to my original question but targets could in theory be compiled with different C++ standards and still be ABI compatible, correct? Trivially, if a library doesn't expose any std types in its interface it could use whatever it wants, or am I missing something? 
Agree very poor type safety
&gt; Globs only partly work. They don't trigger a re-configure, so you have to re-run cmake as you add files. I don't disagree that they are badly designed and shouldn't be improved a lot. &gt; So you might as well just add the files. No, that is a lot more work. Instead of just running an additional command I have to touch the build-file every single time and add a different filename with a chance to misstype. Also: Since CMake has such a mediocre interface, I've written a script with the simple name `b` that will walk up the directory tree until it is in one that contains a directory with the name `build` in which it will look for the closest match of the argument of the command, enter that subdirectory, call cmake, and will then either call ninja or make with appropriate `-j`-parameter. The endresult is something that is actually nice and easy to use, since I just have to enter `b r` to trigger a release-build and `b d` to trigger a debug-build (assuming directory names `release` and `debug` with no further build-modes being set up.) Doing something like that with manual addition of sourcefiles to the CMakeLists.txt would require me to parse and edit files during the build-process, always risking to screw things up completely (yes, there is git, but it still wouldn't be fun) and almost certainly require specific formats to be used in the cmake-files. This is my main-issue with CMake, and mesons approach is much worse and the main-reason I won't bother to learn it: The one thing that REALLY annoys me about CMake is made worse with a terrible work-around in their FAQ next to a wontfix-note. The reason is also utterly stupid: Checking for new files in a large-directory is a sub-second operation for all but the largest projects which simply pales in comparission to what it takes to recompile even one TU. Making regularly needed but slightly slow operations hard to use, will just make people use worse-solutions since, guess what, if I need to perform some operation, I need to perform that operation.
&gt; maybe people have a beef against your username just in general. Yes. :) But you can guess how much I care about opinion of people on the internet. :) 
Same here. I primarily work on Linux and have been using Eclipse for a while. I toggle between eclipse, Unix as IDE and of late Sublime. 
That's an implementation detail. Eclipse and QtCreator are entirely plug-in based. CLion is an IntelliJ plug-in. You just have to allow inter plug-in dependencies.
Definitely agree with this. For your first point, I’d add that (debug-mode) assertions serve a similar purpose for checking pre-conditions that, if violated, will trigger UB. When you add these sorts of assertions, tests will end up crashing in an informative way which allows the caller to fix their invocation more quickly. This is better than the same function crashing in a random place, or even worse, not crashing but still triggering UB.
Worked for years as a game dev, with vim as my editor the entire time -- not hard to alt-tab back into VS to compile and debug.
Try with [Bear](https://github.com/rizsotto/Bear)
Yep. That's classic C. All C was like that back then. And, C++ was considered too slow and complicated for gamedev at that point. Fortunately, the lead engineer where I worked had a compiler background. So, he got a C++ compiler working for the PS1 even though Sony would not provide one. I don't recall if Nintendo provided the C++ compiler we used, or if our lead brought up that one too.
r/cpp is full of people who like c++ and are interested in new features of the language. I'd bet most c++ developers don't really like or care about the language.
The entry in the poll was mentioning only "vim", so it doesn't really matter if people use or not plugins. Anyway, my understanding is that most do.
Qt Creator has no c++, build system, debugging, or editing support without plugins. They are just part of the default install.
Yes. Lies. 
We already have a class/template based front-end and it's clunky and slow because it has to use the C interface that the current version of Lua provides.
vim is like a religion. nobody practices it and yet most people are ashamed of not assigning themselves to it!
&gt; I don't really care how vim is categorized. What you really mean is you don't want to deal with the cognitive dissonance of trying to claim vim isn't an IDE but VS code is when they're the exact same thing, code editors with a plugin system. It just shows how ridiculous your argument is here. vim is **clearly** not an IDE. It's a code editor that people have written plugins for to get many of the features and benefits of an IDE. That's exactly what VS Code is. I don't even know why it matters to you. Why you can't just simply say "sure it's a code editor, but I can turn it into an IDE with some plugins". That would be a compromise I think everyone would be able to agree to. But that VS Code itself is an IDE? No, and it's been explained to you clearly why it isn't.
Wow, I’m surprised Qt Creator is so high. It really is a great IDE. 
Do you mind sharing your .vimrc config?
I'm not so much trying to make an argument as I am simply struggling to understand your point of view. I think you must mean something very different when you say "IDE" than I do, because your categorization makes no sense to me. I simply can't imagine what it is that you mean. Are you defining it in terms of some specific collection of features?
&gt; game and web development. This is what I do. 90% of the time, I'm in Visual Studio, but sometimes, I just need to do a quick one line edit from somewhere else, so I'll ssh in and vim it up real quick. Also, as someone else mentioned, having vim and vs open on the same project is a surprisingly good workflow.
What does VSCode lack to be an IDE? It has a project manager, debugging tools, C++ navigation... please don't be it "the support is through plugins". It's an IDE for many programming languages, of course support for a specific language is modularized. Sublime Text is a text editor with some support added to edit C++. VSCode has everything an IDE needs from the start.
I moved from Sublime to VSCode. Never got C++ support working in Sublime. The project manager was a hack. VSCode worked almost out of the box. It's better in many ways, it's free. 
I'm still not sure what would change from having to deal with those poorly written ones now?
Stack overflow would be a great source for this topic. I mean, also in this case .
How are first party plugins for QtCreator any different than first party plugins for VS Code?
I really hope they add some property like "source directory" so it doesn't have to be the same folder.
This one makes some sense because it tens to be the less surprising for users. It avoids stuff changing in updates of VS and the like.
True, although as an application becomes more data driven the usefulness of asserts diminishes. You can't really let an application crash because someone put a bad value in a config file. So I stick to asserts for simple programming mistakes, like out of bounds errors, but if someone does something like creating a texture with dimensions larger than the device supports, I'd rather throw an exception, even though the programmer could have checked it himself. And of course, not all incorrect states are exceptional. Returning `false` or an empty `std::optional` can sometimes do the job as well.
This test does more than preprocessing, it actually compiles it. The compiler needs to do full parsing, internal data structure generation and all that. The only step that is missing is codegen. 
Interesting. Might be actually very good if it intercepts build commands and creates database of all symbols.
Yikes, didn't realize Qt was behind Vim. Ugh
I think Concurrency with Modern C++ is an inherently hard book to write. C++11 and 14 currently provides just the basic, sharp, dangerous building blocks for concurrency and parallelism with C++17 adding support for parallel algorithms which are mostly still not available in shipping standard libraries. I have more hopes for c++20 with papers on safe memory reclamation, rcu, concurrent queues, actually usable futures, and executors being discussed. Any book on C++ concurrency now will fell like an algorithms and data structures book written pre-STL, yes the algorithms haven't changed much, but how you express them in c++ and the abstraction level at which you are able to express them will have significantly changed.
What does it say about me that I prefer: return (reductionType_ == Percentage)?price * (1 - reductionValue_):price - reductionValue_;
Didn't mention IMO the biggest reason to use inheritance over std::variant, which is when you have an open type hierarchy. I'm not sure if that's the technical term, but I mean when you don't know what types you'll be choosing from - or when you _can't_ know this, because they come from a shared library or haven't been written yet. This situation isn't very common (I know the full set of possible types in my own programs probably 99% of the time), but it's one where inheritance really shines.
Not even close
Different defaults. Vim is a text editor that you can turn into an IDE. vscode is something on the fence between a very powerful code editor and a lightweight IDE by default and was - from the start - developed with that goal in mind - also, with a single plugin and a c++ toolchain, you effectively have a fully featured c++ IDE, whereas turning vim into a IDE is afaik much more work.
I reduced the compile time of my project by the same amount, and the biggest impact by far came from reducing inclusion of a header with barely any impact on a cpp file when simply #included like this tool is doing. Any steps taken to reduce the amount of code being compiled are likely to reduce overall build time, but the information provided by this tool is not going to be an aid to the process. 
Great, so you created your own meta build system on top of makefiles (that's exactly what cmake is btw) how does that make make superior to cmake? Just to be clear, I don't consider cmake to be all that good a build system. It's just that make is imho much worse. I've mentioned it a couple of times before writing makefiles feels kind of writing assembler to me. And btw.: I don't understand your comment about a recent c++ version. Care to elaborate?
One small difference is that out of the box (iirc) VS code will suggest you install plugins based on what you're currently editing. Like, if you open some C++ source it will prompt you to install a bunch of C++ plugins. So it's plugin-based, but a lot of the plugins don't require the user to go looking for them.
tell that to the 20k line legacy main function that the entire project depends on =[
&gt; Which means that statistically, the margin of error of the poll is around 2.99% with a confidence of 99%. That basically means the results shouldn’t be too far from reality. That's not how statistics works. How you collect samples matters *a lot*. r/cpp is likely going to be significantly skewed, though I don't know which way. And randomly sprinkling some data points from other sources on top is not going to help much. For an example of similar articles that I think are done well, have a look at [Stack Overflow blog](https://stackoverflow.blog/insights/). Their data is similarly skewed (especially when it comes to historical data), but I think they explain well where does the data come from and what its limitations are.
&gt; "UNIX as IDE" gives you most (all?) of the conveniences of an IDE while still being pleasant to use. How do you debug your code? And please don't say "using gdb", that's not pleasant at all, when compared with actual IDEs.
So supprise with visual studio but ... code blocks is so low? ...
Does that mean Visual Studio 2017 is not an IDE? Since I can install support only for the languages I use. (They don't call them "plug-ins", but I don't see much difference.)
I can vouch for conan. For 3rd party dependencies and building cross-platform software quickly it is amazing. When using VS (or other IDEs), check out the "cmake_multi" generator. It supports debug and release switching in your IDE. I haven't found it any more cumbersome than cmake (which is to say not cumbersome at all). For development of your own libraries though, it is sorely lacking. I hope they tackle that soon.
I cried internally reading that paper. The examples are vomit on a screen.
Couldn't agree more. Me reading your post : https://i.imgur.com/cUIk4AT.png
Inline functions. It can be so much fun when the definition of an inline doesn't match the layout of a linked in non-inline constructor. Your debugger will probably lie to you, too. 
I didn't say first party, neither did you.
I'd just like to interject for moment. What you're refering to as vim as an IDE, is in fact, UNIX/vim, or as I've recently taken to calling it, UNIX + vim... yeah I'm too lazy to finish it.
I have a solution for you then: return isAvailable(item)? applyDiscount(item.getPrice()):0; Single return statement, very clear as well.
Microsoft develops the plugins to write, build, and debug C++ in VS Code, just as the Qt Company develops the plugins for writing, building, and debugging C++ in Qt Creator.
You can use `NaN` instead, but I doubt the example was made to argue about the magic values.
VS Code ships by default with a debugger, code model, and project management (for JavaScript projects.). Your argument that it isn't an IDE because you need a plug-in for C++ is similar to claiming that eclipse isn't an IDE as it doesn't support c++ out of the box. Fun fact: Visual Studio doesn't ship with C++ support by default, that comes from an additional plugin you have to install.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/7z1tfa/netbeans_compiler_issue/dukv8y5/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Why ask a question just to exclude the obvious answer? gdb is versatile and powerful, and most 'actual IDEs' are just running gdb dressed in a custom GUI anyways.
Oh no, Emacs is a wonderful operating system ;)
Like Eclipse is a Java IDE..?
std::variant is implementation of algebraic data types, you know. So, it's just different approach, you can mix it together with inheritance freely. Do not oppose it to inheritance, because it's like saying "Apples over potatos". 
Systems engineer here. I pretty much only debug with gdb. Occasionally logging is helpful but it is not always the choice.
So far after an hour installing and futzing I'm still not even getting hello world working in this thing (keeps telling me my `main.cpp` is not part of my project even though it is in my project file etc etc). Also when looking for help online I get to wade through the 65 pages discussion of Qt programming, and Qt's weird documentation system (I have done a lot of PyQt programming so I am way too familiar with this). This is torture. I will try KDevelop now.
Well... it is pretty bad. I don't know why anyone still uses it.
This is the toolchain file I use for building with a local install of clang from tip of trunk with libc++ rather than libstdc++ &gt; set(LLVM_ROOT "$ENV{LLVM_ROOT}" CACHE PATH "Path to LLVM installation") &gt; set(CMAKE_C_COMPILER ${LLVM_ROOT}/bin/clang) &gt; set(CMAKE_CXX_COMPILER ${LLVM_ROOT}/bin/clang++) &gt; set(CMAKE_CXX_FLAGS &gt; "-std=c++2a \ &gt; -ftemplate-backtrace-limit=0 \ &gt; -Wall -Wextra \ &gt; -nostdinc++ -isystem ${LLVM_ROOT}/include/c++/v1 " &gt; CACHE STRING "CXX_FLAGS" FORCE) &gt; &gt; set(CMAKE_EXE_LINKER_FLAGS &gt; "-L ${LLVM_ROOT}/lib -l c++ -l c++abi \ &gt; -Wl,-rpath,${LLVM_ROOT}/lib" &gt; CACHE STRING "CMAKE_EXE_LINKER_FLAGS" FORCE) &gt; &gt; set(CMAKE_CXX_FLAGS_DEBUG "-O0 -fno-inline -g3 -fstack-protector-all" CACHE STRING "C++ DEBUG Flags" FORCE) &gt; set(CMAKE_CXX_FLAGS_RELEASE "-Ofast -g0 -DNDEBUG" CACHE STRING "C++ Release Flags" FORCE) 
 set(LLVM_ROOT "$ENV{LLVM_ROOT}" CACHE PATH "Path to LLVM installation") set(CMAKE_C_COMPILER ${LLVM_ROOT}/bin/clang) set(CMAKE_CXX_COMPILER ${LLVM_ROOT}/bin/clang++) set(CMAKE_CXX_FLAGS "-std=c++2a \ -ftemplate-backtrace-limit=0 \ -Wall -Wextra \ -nostdinc++ -isystem ${LLVM_ROOT}/include/c++/v1 " CACHE STRING "CXX_FLAGS" FORCE) set(CMAKE_EXE_LINKER_FLAGS "-L ${LLVM_ROOT}/lib -l c++ -l c++abi \ -Wl,-rpath,${LLVM_ROOT}/lib" CACHE STRING "CMAKE_EXE_LINKER_FLAGS" FORCE) set(CMAKE_CXX_FLAGS_DEBUG "-O0 -fno-inline -g3 -fstack-protector-all" CACHE STRING "C++ DEBUG Flags" FORCE) set(CMAKE_CXX_FLAGS_RELEASE "-Ofast -g0 -DNDEBUG" CACHE STRING "C++ Release Flags" FORCE) 
Thanks for your thoughts here. I have code::blocks up, and it works, and I think I will just keep using that until I am good enough to appreciate the difference. :)
yes? are you confused perhaps?
So get up in arms about Eclipse being on the list, too; if you're going rail against critical thinking, at least be consistent. ;-]
&gt; as a C++ dev, libclang and things like rtags / ycm etc has been a game changer. Ctags and cscope doesn't cut it IMO. You want a proper compiler backend. While this is relatively new capabilities for the UNIX editors, it's a bit of a staple for VS: it already comes with a compiler, and it's "intellisense" refactoring/tagging tool has been able to leverage it for years now. Furthermore, being technically able to build a project in order to provide tagging support &amp; completions isn't enough for being *actually* able to do so. The libclang tools needs to know how to build your project, meaning that if your project happen to be a steaming pile of hand-crafted makefiles and not some neat &amp; correct CMake, you're pretty much out of luck. VS deals with that by claiming ownership of the project from the start, creating its own project files when the user begins something from scratch, etc. What I would love to see from the "UNIX as IDE" crowd is a similar effort. I believe Microsoft made an effort to standardize interaction with language tools through it's [language server protocol](https://en.wikipedia.org/wiki/Language_Server_Protocol), and it would be neat to see some projectfile management standard emerge too. [Bear](https://github.com/rizsotto/Bear) (or clang compilation databases in general) is a good starting point, I think.
If my job is anything to go by, this is most likely true. A lot of my co-workers write their code in the "C with classes" style, they make light usage of C++11/14 features at best, and don't really care about the latest technical specifications or standards committee minutes or anything like that. To them C++ is just a tool they use to get the job done.
Relevant SO question: https://stackoverflow.com/questions/5189072/c-bool-question TL;dr: 0 == false &gt;0 == true
just walk some values of x through the flow chart. try -5, 0, and 5. seeing what happens on those first two should give you an idea of what to check for at &lt; x &gt;. 
The "usually vs. no dynamic allocation" is a simplification. If I have one instance of whatever, which I pass around by reference, then the two are the same. If there is a container of things, then there can be both a dynamic allocation plus more expensive copying in variant case. The data locality can (but doesn't have to be) better with variant and a vector. And probably more.
Guess it's time I post this again, people seem to plain forget about it: [composition over inheritance](https://en.wikipedia.org/wiki/Composition_over_inheritance).
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/7z340a/cppflowchart_question_i_am_wondering_what_the/dul2u6h/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
My favourite has always been KDevelop.
Anyone ever use TextWrangler? Shout out to 2005.
It is not so much runtime, as it is about compile-time dependencies. If I have a class `HasAFoo` that has a `Foo * foo` member (and yes, should be a smart-ptr), that `foo` could be a `DerivedFoo` _but I don't need to include DerivedFoo.h_ in HasAFoo.h. Nor update HasAFoo when someone adds SomeOtherFoo later. Even if all the derived Foo's are known at compile time, I still don't want HasAFoo to know about them (to keep the compile fast, but more importantly because knowing about them leads to code that depends on them, and does dynamic_cast "is this a DerivedFoo?" and leads to spaghetti, etc etc etc). Keeping things separate is the usefulness of interfaces and inheritance. Not that I use inheritance that much, "inheritance is the base class of evil" (Sean Parent). And of course, there are times when I really want to say "this is an A B or C and nothing else", so variant is great there. Basically, instead of "when you don't know what types you'll be choosing from" I'd say "when you don't WANT to know what types you'll be choosing from".
Trying to move to VSCode because of the great reviews it gets. I am working in a CMake project with the main code being C++ but a mixmash of different languages, including our own scripting language. How do I make VSCode work? Its CMake support seems severely limited or very well hidden.
Lovely. Let me see if I understand this correctly. If you call malloc(), as in the first example in the paper, the resulting 'thing' is not an object, and formally that means that using it (or, who knows, even just 'forming a pointer to it') is UB. Correct? Now unfortunately, it is also a very common programming pattern, and it's therefore bad form to treat it as UB. So we need some way to turn this into defined behaviour. Correct? So we add a new function, std::bless, which we use to magically turn our pointer to whatever into a pointer to objects, thereby removing the UB condition. And we also add auto-blessing properties to a small handful of functions, such as malloc. *Everything else*, however, remains as UB under this proposal. That's essentially _every single C library call that returns a struct_. If I call `pango_cairo_create_layout()`, for example, accessing the resulting struct is UB. Yes, it _might_ have come from a call to malloc. But there is no way to be sure (other than reading the source to every library involved, including all the closed source ones), and there is likely no guarantee either (in the next version it might do things differently). But hey, for such function calls we now have the power of std::bless, right? And yes, we do - but please forgive me for thinking of this as a breaking change in the language. In the past, there was precisely one way to call functions like `pango_cairo_create_layout()`. Maybe doing so was always UB, but given that it was the only option available, everybody was doing it anyway. Maybe I understood this bit wrong, of course. If so, thanks for modding me down and/or quoting the text of the proposal in super-bold font, it really helps with understanding. But if I'm not wrong, then quite frankly I'd rather see that the _standard_ be fixed to allow behaviour that is already commonly used (and could not be avoided), rather than adding some new function that is all of a sudden mandatory in programs that were always perfectly fine before. Because that last choice would mean we have to inspect and fix _all_ of the C++ programs on the planet. So rather than hitting that downvote button, tell me why this is not a breaking change. Or if it is, tell me why it is acceptable that we break every billions of lines of code. 
&gt; Great, so you created your own meta build system on top of makefiles (that's exactly what cmake is btw) how does that make make superior to cmake? That doesn't, I'm just talking about what I would consider good ergonomics, which cmake simply lacks. &gt; I don't understand your comment about a recent c++ version. Care to elaborate? CMake simply uses all compiler-defaults, which tend to be quite bad (shame to the compiler), instead of using the most recent standard by default. This is one of the things I would consider the build-systems job to fix unless it is told otherwise. Same goes for warnings.
MISRA started as a C specification. Actually, there's two MISRA specifications: MISRA-C and MISRA-C++. But in C, a single exit point was frequently encouraged because there is no RAII. It also allows one to more easily insert logging or tracing at the end of a function. Well, that was the consensus of people I dealt with the last time I dealt with MISRA-C.
- Demo: https://youtu.be/oYtnXEZC0jk?t=28m15s - Herbgrind: http://herbgrind.ucsd.edu/ - Herbie: http://herbie.uwplse.org/ - FPBench: http://fpbench.org/ - Tools from the Floating-point Research World: http://fpbench.org/community.html
– *formally that means that using it (or, who knows, even just 'forming a pointer to it') is UB* – *remains as UB* – *doing so was always UB* I just find your calling it a "breaking change" confusing, personally.
How odd, you didn't mention how many elements are in your containers. How odd, you have two identical columns in both your posts. How odd, you label many of your tests by what the int is *not* in. How odd, you didn't label your columns. I hope you edit your posts to be a touch less odd. 
Thank you for noticing, I'll check again and post a fix. :)
Here I am! About the overflow you're absolutely right, talking about overflow in the context of unsigned types is inaccurate: I'll review my postand adjust the incriminated sentences. Actually that part needs a bigger restructuring because of the automatic promotion of smaller types in expressions... Thank you for your comment, and the pointer in the standard, I'll add that as a note, too.
When I first tried CLion I used the 30 day trial to bootstrap some CMake scripts and learn the syntax, then I switched to a free CMake + Vim + (gdb,ctags,etc) dev environment. But I liked CLion's visual debugger and refactoring tools so much, I switched back to it about a year later. :-)
Yeah it's a bit depressing to see that poor codeblocks at the bottom.
Well, there is also the constness of the parameter. Looks like it could be (const Item const &amp; item), but that also wasn't the point of the article....
What's the issue exactly, and what is `const Item const &amp;` supposed to mean?
That's a fine rant, and I'm already more-or-less on your side of it so you're preaching to the choir a bit there, but it doesn't address the fact that for something to be a "breaking change" something has to have actually _changed_. &gt;_&gt; (This comment is rhetorical.)
So you don't consider the fact that we would have to go and add `std::bless` everywhere in our source to be a breaking change? I'm asking because there wasn't any `std::bless` before that we _could_ add, and it looks like it might be a mandatory thing in the future - at least for people who want to avoid UB for one reason or another. 
would be more useful if it would also list the operating system or use case.
The parameter is already const though... o_O
Definitely. I am planning to run a more detailed poll in the future.
Checking for files in a large folder is fast. Ninja does it all the time for me when I build Chrome, and it's quite a large project! But the problem here is that CMake isn't actually building. It will be msbuild, xcodebuild, make, Ninja or some other IDE. Unless CMake builds directly, this won't happen. I sometimes dream of Ninja being integrated in CMake directly for that purpose...
I tried to improve the situation a little bit with my library: [scelta](https://github.com/SuperV1234/scelta). It provides lambda-based visitation that resembles pattern matching (and also additional goodies such as monadic optional utilities). It is compatible with all major implementations of variant and optional.
You trolled me for a second here that this was about fixing CMake. It's not. Modern CMake may look better the old cruft. If you're stuck in the hell which is are old/inconsistent CMakeLists.txt you may be longing for a "modern CMake" setup and think it's paradise. It's not. The amount of boilerplate, even with "modern CMake", is ridiculous. CMake doesn't help you one bit with detecting compiler features. Sure you can request `cxx_std_17`, which by the way maps to `-std=gnu++1z` by default, even for clang, but it's doing nothing more. CMake has no clue whatsoever which compiler version supports which language/library feature. So if you want to use `std::[experimental::]filesystem` you're again on your own linking `stdc++fs` and whatnot. CTest is ridiculous, it doesn't even add dependencies from running to building a test... and that's a [9 year old bug](https://public.kitware.com/Bug/view.php?id=8774) not being addressed whatsoever. Hell, just look at the example `CMakeLists.txt` from the article... 100 lines of code for the simple example including hideous boilerplate like: list(INSERT CMAKE_MODULE_PATH 0 ${CMAKE_SOURCE_DIR}/cmake) Basically everything there is boilerplate, because CMake knows no sensible defaults whatsoever. However you look at it, it's still CMake - so at best it's a polished turd.
And btw please make the library header to be named appropriately. Instead of `#include &lt;elf_parser.h&gt;` people prefer `#include &lt;elf_parser/elf_parser.hpp&gt;`. First, it explicity states it's C++ (annoying thing when you have mixed language repositories), second the library has own directory - this lets you make a external dependencies directory where each subdirecotry is for each library and you add just 1 path to the IDE and compiler. - deps - libpurec - libfoo - libbar - boost - core - src #include &lt;libpurec/purec.h&gt; #include &lt;libfoo/foo.hpp&gt; #include &lt;libbar/bar.hpp&gt; #include &lt;boost/math/xxx.hpp&gt; IDE settings: just add `deps` directory to the project settings.
I am not disputing the power of gdb. What I am saying is that it's hard to use and that it has a steep learning curve. That's why I would call an IDE that's using gdb in the background "convenient", but not gdb itself.
The reference is const. What it refers to is not. Consider: 1) int * a OK: *a = 42 OK: a = nullptr 2) const int * a Not OK: *a = 42 OK: a = nullptr 3) int const * a OK: *a = 42 Not OK: a = nullptr 4) const int const * a Not OK: *a = 42 Not OK: a = nullptr Same for references, but I am typing on mobile and super lazy :) 
I have to agree with Guy: standard library additions are far less risky than language additions. There is already a good chunk of the C++ standard library that most people don't use, there is even a chunk which nobody *should* use. Expanding the chunk which isn't regularly used is mostly zero cost to those who don't use it. As for whether graphics support ought to be added or not, as I've said before, stuff gets into the standard based on willing champions. No champion = no standard support. If you have some pet thing you want into the standard, go champion it and make it happen. Otherwise don't slam those who are getting things you don't want into the standard.
the whole point of an IDE is that it's integrated. You don't have to set up and customize, everything comes out of the box and works together. Thus, vim is by definition not an IDE, regardless of how it stacks up against VisualStudio. 
&gt;“A graphics library shouldn’t be part of the standard library. The standard library is too big already, and this will make it so much bigger. It’s just not appropriate. The library should only contain small types.” I find it funny that people argues that when *Stroustroup himself* had argued that C++ stdlib should be *a lot* bigger. **If and only if** C++ had a decent package and dependency ecosystem (like say java, python, rust, etc) i'd be ok with a small bare bones only stdlib, because it would be easy to pull in other libraries.
So the question would be why not to go lower level, for even more control? C-- language exists.
I am still overwhelmed from the basics and more stuff just keeps coming 
It is similar in principle, but really designed for MSVC users. You don't need to modify your build system to use Stashed. sccache requires some changes like prepending the compile command line with sccache.exe. It also is more focused on co-located teams. Caching happens on the local network and local disk caches. If a lot of users want it, adding S3 support to Stashed would be pretty straightforward. It implements a "direct mode" like ccache. I don't think sccache does this. CL.exe's preprocessor is obscenely slow for this sort of thing, mostly because the template processing is 2-pass -- great for handling complex templates, really bad for just getting "gcc -E" style output quickly. Another tool I tried was clcache. It was such a chore to get configured properly. I couldn't imagine trying to get a whole team of developers to set it up correctly. clcache also doesn't have support for common options. Stashed can handle PDBs (/ZI) and PCHs, though mixing the two is a bridge too far at the moment. Microsoft's compiler tools are a real bear to work with, which is why it has taken so long to get ccache-like functionality for the platform. It is nice to just run the installer and never really have to think about it again. sccache has a bunch of installation/usage instructions, which are very light on how to integrate with MSVC. Setting up and using Stashed is download, install, go.
Within powershell? Why not use the windows-linux subsystem and run vim there? I'd hope there would be better compatibility with rtags there, too.
&gt; stuff gets into the standard based on willing champions. No champion = no standard support. That's unfortunately a pretty dumb system in my opinion. Or let's phrase that a bit nicer: I think it's a large problem. I understand that somebody's gotta do the work. And I also don't have a ready-made solution. But there is a large amount of money involved in C++ and very large corporations (Google, Microsoft, dozens more, who send one/multiple people to standards meetings). So I sort-of expect "these people" to do it with all that corporate money behind it. Who else do we expect it to do? The hobbyist or professional programmer in his evenings and free time? Unpaid? And then also pay the large costs to attend multiple standards meetings (if they can even afford it)? Yes, some people are doing this - enthusiasts that are very enthusiastic about the language, see it as resume-boosting, for social connections, as an awesome life-achievement, and can somehow spend the money to attend. This is absolutely awesome, I hope this continues, and I wish to be one of these people. But clearly, this cannot be the answer to how something gets a chance of being added to the standard. If I had to make an example the poster-child would probably be (multi-dimensional) array view, or linear algebra in general. Sorely missing from the standard, a limited number of people have tried championing it but it has been stalling/died multiple times over the past years. Yet there are few domains that do not use multi-dimensional arrays or even linear algebra. It's everywhere.
It really takes all of a day, maybe a week to learn. There are plugins to colorize gdb directly, there are stand-alone gui's that wrap gdb, and if all else fails you can just have an IDE sitting side-by-side if you really don't want to use the other alternatives.
Ugh, after 10 years of .NET and then coming back to C++, I find the STL clunky, insanely over-engineered, and at the same time lacking in basic features. I’m pretty sure that the whole iterator mess was added to the library to give library writers something to work on - what other language has such a convoluted concept of walking over containers? 6 (SIX!) different iterator categories AND I STILL CAN’T DOWNLOAD A STRING EASILY?! Focus on some 2018 use cases and stop messing around with the containers. &lt;/rant&gt;
Haha, yeah, the iterators. The idea was that you could "easily" change the underlying container. Before auto keyword what it really meant was: oh f**k; DO I REALLY need to write the iterator type AGAIN? std::vector&lt;foo::BarType&gt;::iterator i = c.begin(); Easily switch from one container to another, yeah, right. The fix was to typedef the container type somewhere, then do some convenience typedefs for the iterators as well and we're good. Then came the auto keyword. Everything was much nicer. Who really went back and upgraded the old code, though? What for? It's written, tested, works. THEN came the range iteration; it's actually pretty sweet - the end. :) (So, in this light at least some good came out of the endless tinkering) 
I use python quite a bit and frequently get a new VM server stood up that is running python 2.6 and not python 3.4 or later.
&gt; Lightweight header-only elf binary parser with no external dependencies - Sections, Symbols, Relocations, Segments Line 12: #include &lt;elf.h&gt; // Elf64_Shdr This is a dependency, unless elf.h was added to the standard while I was looking away...
Items I intend to bring to WG21 to begin standardisation later this year: - Efficient and race free file i/o (AFIO) with persistent memory support (DAX). This implements shared memory, control over the MMU and virtual memory, lots of other goodies. I've been working on this for many years now. - Simple embedded transactional key-value store. So, a 128 bit key for some arbitrary length binary value. It'll be Atomic, Consistent, Independent, Choice of none/late/immediate durability. - DMA attributes for `span&lt;T&gt;` so STL algorithms can become DMA aware/friendly - `&lt;system_error2&gt;` which fixes the problems with `&lt;system_error&gt;` with a new `status_code` to replace `error_code` - `result&lt;T, E = status_code&gt;` which refines `expected&lt;T, E&gt;` to implement a subset of Outcome - Some form of RDMA/libfabric support, yet to be discussed in much detail
&gt; The reference is const. There's no such thing as a const reference; references are always const, by nature. &gt; 3) int const * a OK: *a = 42 Not OK: a = nullptr This is wrong, you're thinking of `int * const`. &gt; 4) const int const * a Not OK: *a = 42 Not OK: a = nullptr This is wrong (and nonsensical – you can't apply `const` to the same thing twice), you're thinking of `int const * const` or `const int * const`. Declaration specifiers can go in any order, so `int const` and `const int` are identical, as are e.g. `typedef int foo;` and `int typedef foo;`. Consequently, `Item const&amp;` and `const Item&amp;` are also identical, and again, `const Item const &amp;` is simply nonsensical.
&gt; By definition, &lt;cmath&gt; functions aren't allowed to be constexpr. I guess this comes from ISO C (which is just pasted/appended to the ISO C++ standard). But how hard can it be to change this and provide C++ functions in the C++ standard library for this, and which are allowed to be `constexpr`? Great post btw!
let us know
`const` apply to the element on the left, unless `const` itself is the element the more on the left, then it's applied on the right. `const T &amp;` == `T const &amp;` == reference to a const element. `const T *` == `T const *` == mutable pointer pointing to a const value. `T * const` == const pointer to a mutable value.
You are correct. I was considering the const int const *.
I always wonder how the various caching tools deal with location information that is embedded into resulting object files. Specifically, I am talking about the debug information and things like `__FILE__` (e.g., in `assert()`). Do you expect every developer on the team to have all the source code in exactly the same directories? FWIW, we are planning to support distributed caching in `build2` at some point but we've started with fixing [the compiler](https://gcc.gnu.org/bugzilla/show_bug.cgi?id=70268#c16) first.
 Shared memory Lock free contiguous memory data structures Simple relational database/table Thread local lock free memory allocation
Another point of feedback: currently i can only find an option to analyze the whole solution, but that is not very productive if i am working on a large solution and i am just modifying a few files. I didn't test it yet, but does it automatically detect only the changed files such that analysis remains fast for larger projects (also for clang-tidy?)
&gt; When Stroustroup himself *Newton himself* argued that light is nothing but particles. Should we all agree? One's opinion is not 100% correct only because of one's authority. By the way, with all respect Stroustroup doesn't get to decide what is good for C++ and what is not - there is a committee for that.
Select the files/projects you want analyzed in the solution explorer, then invoke "Find Code Issues" from the context menu.
The most important thing are vocabulary types. When using third-party libraries I don't want to deal with N number of different implementations of stuff like variant, string_view etc. At least these days most libraries don't implement their own string types like back in the dark ages. (Of course there are exceptions for when you want very specific performance characteristics.)
Part of the problem is a lot of the cmath stuff alters errno. Altering global/thread local state is illegal in constexpr.
For caching tools that run the preprocessor (gcc -E) they really can't do that. The preprocessed output is going to be different. Looking strictly at the contents (direct mode, for ccache, as an example) only has to concern itself about whether the inputs are different to force a cache miss. That PR/commit looks awesome! I doubt CL.EXE will provide similar support anytime soon :( It was my experience with gcc + ccache + distcc that motivated the project in the first place. Having gone through it, I can see why MSVC support has been lagging so far behind :) It is much more difficult to support. Version 1.4.6 works best when using the same source location if the distributed cache is used. A version that does not impose that restriction is coming very soon.
Having been in Go and JavaScript for a bit, build2 really scratches that itch I feel when working in C/C++ :)
Ah, clear. I am completely new to ReSharper, but now it seems quite obvious. Thanks!
&gt; Newton himself argued that light is nothing but particles. Should we all agree? That's a really poor argument. Did Newton design and create the initial versions of light? Stroustrup designed and built the initial versions of C++. "Newton" in your argument is just some random bystander who made an (incorrect) observation about C++. *Shouldn't we all agree?*
[and yet his software subsurface migrated from C/GTK to C++/Qt]( https://www.youtube.com/watch?v=ON0A1dsQOV0)
Seems perfectly valid though, that you do not want abstractions if what you work with is hardware control. I tend to go C whenever I need to control hardware. I then need my code to be bit-perfect because that is what the hardware needs.
Conversely, at the time the pool of people one might consider experts on light was quite a bit smaller than the pool of people we'd now consider experts on C++ design. Shouldn't that lend Newton's opinion more weight? 
Linus is a datapath guy. In the kernel, every ms you spend in code block A is taking that time away from code block B. That's it. C++ offers good performance out of the box with the ability to dig in and get extra performance, if you need it. You can also build out high quality software in a time frame that's interesting. *Then you measure* and optimize your hot spots.
Isn't wave particle duality pretty popular meaning that while light is more wave like that a baseball a baseball is technically still partially a wave meaning that light is "just a particle" as much as anything else is unless you want to nit pick portions 😀 Also when Newton was alive you would be good to listen to him, no major player proved him wrong for way too long to give him a hard time about recent advances in science...
Important things that are definitely needed and should be part of the standard, but will likely never make it because of all those people who love to implement everything themselves or mess around with 10 different libraries that use 15 incompatible code-styles that are all inconsistent with the stdlib: * basic but extendable GUI. I'd consider that about as important as networking and IMO all arguments against it are just bullshit. * networking with modern TLS-support. Unencrypted and unauthenticated networking is just irresponsible and stupid nowadays. * HTTPS. Both server and client-side. * 3D-graphics with basic access to opencl * basic sound and video input/output. * multimedia-libraries (support for PNG, JPG, OGG-Vorbis, VP9, ...) 
One thing that’s important to me. Fixed-point math. It’s 2018 and you still need 3rd party libraries to avoid floating-point errors. Meanwhile, Python comes with the decimal module.
&gt; The Java Class Library consists of, at first glance, support for UI, database connection, networking, sound, image manipulation, XML, CORBA, encryption, even hosting for scripting languages: the list goes on. Well, CORBA it is then! 😁😁😁😁
Have you considered just dropping out, giving up, and living as a homeless person instead?
Am I arguing with that? Kernel must not waste any instruction and programmer must control what it does *exactly*, and that is what Linus want. C++ give you more power than C, but in kernel development you could easily collapse under the weight of all those features. So in Linus eyes, an average C dev would arguably do less damage than average C++ developer and that we agree with. However, each of posts debunking Torvalds original post focus on *C++ has features and I use the features and I deliver faster because of features* and hardly any of them admit, that if someone pointed a random line in their code and asked what it does in ASM and how would they debug it seeing only ASM output and with no possibility to attach their beloved Visual Studio debugger, they would shit themselves. And that *it works for ME &amp; HE doesn't like it =&gt; his argument is invalid* attitude is what I find actually stupid.
A book; my personal favorite being The C++ Primer Plus
I use this very useful class template in one of my projects. Actually, it's so useful that I can't believe I'm the first one to write something like this. Does anyone know another implementation? Also, feedback is welcome!
You refer to “the current version of the TLS-standard”. I agree with you that the commitee should stay away from specifying the specific cipher-suites, but once we get TLS-1.3 there will be a mostly sane and reasonably small set of required and strongly recommended algorithms. The implementation in the stdlib would simply end up calling whatever library is considered default on the system in question. Leave security-levels to something like “basic” (128 bit), “high” (192 bit), “very high” (256 bit) and once we get it something like “post_quantum”. Other languages manage to do such things, there is no real excuse for C++ to fall behind so much.
&gt; Shared memory I'll be proposing that to WG21 later this year. It'll look like this: https://ned14.github.io/afio/classafio__v2__xxx_1_1mapped__file__handle.html &gt; Simple relational database/table I'll also be proposing a simple ACID embedded key-value store, something on top of which you can build other stuff. One can implement relational on top thanks to the transaction support. That'll be on the end user however, as will indices, string keys, serialisation etc &gt; Thread local lock free memory allocation You can get most of the way there using http://en.cppreference.com/w/cpp/memory/unsynchronized_pool_resource. Just make sure the same thread frees as allocates. &gt; Lock free contiguous memory data structures These are tricky to make widely reusable. I have a concurrent sparse hash map I use in my own code which is blazingly quick, but it comes with substantial gotchas, ones which WG21 would not like. I may have a crack at a concurrent lockfree B+ tree implementation, that shouldn't suffer from the same showstopper problems as a lock free hash map. We'll see. I do think there is a chance that something like Boost.Intrusive could get standardised one day. That's a niche use case for most users, but the standard containers other than `std::vector` look increasingly too heavy for modern code. 
Correct, but that doesn't make the GP's argument any less poor. Newton is not analogous to Stroustrup in this discussion at all. Their argument would have been much better if they had left off their failed analogy.
Could you explain why all arguments against a GUI in the standard library are bullshit? I've written at length about not wanting a GUI in the standard, and have yet to see a convincing argument (or an argument other than what I can summarize down to "Because it'll make things easier!!!") from people wanting it. I'm quite eager to see a rational provided that convinces me that adding a GUI library benefits me, personally, without also adding a large amount of work to me, personally, or to the various compiler implementers and STL writers, that wouldn't be better served by existing 3rd party libraries.
I am not sure what you are arguing. My guess: "Working with hardware you want things as close to ASM as possible." Correct? That's the part I responded to, and the part I agreed with you about if the above is correct. To iterate my point - if it is not yours as well - the C++ features that helps you 'deliver', as you put it, also obscures. C++ is better than C if you have a complex problem that does not have a well-definable solution. If you need anything to be not so fuzzy, go as close to ASM as you can. And writing C as ASM seems perfectly valid then.
That was my understanding; "one exit point" was a hold-over from C where you had to release your resources manually. But in C++, *even if* you only have one `return`, you could still have multiple exit points, due to exceptions being thrown, so it doesn't really make sense any more.
In the first example, which return is "early" and which one comes "later"? If you're going to classify a return as early, surely it must occur earlier than some other return.
That's more or less what i ment.
Neat patch you have there!
How does it differ from https://github.com/Naios/function2 ?
Thanks. Doing the groundwork, so to speak.
Thanks (and also re: PR). The upcoming release will be even more of an itch scratcher with support for *version control*-based repositories (`git`).
I definitely agree with you that a large `std` is no a panacea and may be more troubles than it's worth. As acclaimed as the STL is, for its separation of concerns between containers and algorithm, I absolutely *loathe* the inefficient iterator design, and some containers have "interesting" set of guarantees preventing implementations from performing as well as you'd expect. And the main issue, of course, is that because of backward compatibility many problematic pieces **cannot be fixed**. There's a reason for the mantra: `std` libraries are where modules go die.
Irrational numbers are more troublesome with floating-point. They can lead to some very undesirable errors in financial or engineering calculations. With fixed-point, I can dictate how precise a number should be which can be more suitable.
I actually, I'd like to see all of them in the standard library. They don't have to be used as the internal types of 3rd party libraries but the interfaces should support them. It is redicolous that almost every library expects their own 2D/3D vector implementation as an input.
Those are not *that* different from WebGL or OpenGL ES... Perhaps the hello world you have in mind is not the literal "display Hello World text" but, say, displaying a scene of some sort. That gets complicated real quick, you're correct.
Decimal library. So then we can, like, do financial transactions right. It looked like decimals were finally going to make it into the standard, but then it disappeared. Now it seems to have died a natural. G++ has it as an extension, but there are quirks. Come on, COBOL has been playing nice with decimals since its inception.
First of all, std:: function, std::map also are Crossplatform enough for must of the use cases. Where there are not, their existence doesn't prevent you from using the boost version. But I would find it extremely annoying if I had to depend on 3rd party libraries every time I need to type erase a function object or use an associative container.
It takes you a few hundred lines of code just to set up GPU device state that would be the equivalent of glBegin and maybe 3 lines of code. Displaying a triangle with no vertex buffers takes around a thousand lines of code. There is no driver state machine, you have to specify all GPU state yourself. I'd say it's pretty different. 
I only ever saw Linus mouth off about C++ in the context that some weeaboo brings it up on the kernel mailing list. The linux kernel is in C and that's not going to change and if you don't understand why then you probably shouldn't comment. I wouldn't take anything Linus said in that context at face value. He was just trying to get people to shut up and not waste time. I don't think he's ever seriously critiqued C++.
Really interesting, could you give some more examples of this?
Something like Numpy and something like Pylab
Really interesting, could you give some more examples of this?
Notepad++ is a code editor. It's closer to an IDE than Vim is, but farther than VS Code. I think I'd have a hard time calling it an IDE because it doesn't include any build mechanism, you need a plugin like NppExec - whereas VSCode has "tasks" built in, some of which are preconfigured (like TypeScript). Of course, Vim *does* come with build integration, but is still missing the other things I mentioned by default. Ultimately it's a continuum, and kind of a judgement call. This is how I'd place text editors on the spectrum personally. You may disagree. &lt;-Text Editor-----------------------Code Editor-----------------------IDE-&gt; Notepad vi Vim VSCode VStudio Pico Nano nvi Notepad++ IntelliJ Ed Sublime Eclipse Atom Xcode
The most obvious difference is that function2.hpp is 1033 sloc long, where multifunction.hpp is 98 sloc long. This implementation seems much more complete than mine, but OTOH seems much less straightforward. It emulates overloading manually, by relying on tuples and by implementing a virtual table mechanism from scratch. multifunction doesn't have as many features, but entirely relies on the overloading mechanism of the language. I wonder if we could have the best of both worlds: a more "native", feature-complete implementation.
~pg 17 here: https://llvm.org/devmtg/2012-04-12/Slides/Mark_Charlebois.pdf has some good examples. This project: http://llvm.linuxfoundation.org/index.php/Main_Page had to hack the kernel a bit to try to get it to work, and I think failed. There is also a case that sticks to my mind where the kernel did something like: for (Ptr = something();Ptr-&gt;member != offsetof(Ptr, member) ;Ptr = something_else(Ptr))
**Reported for referral link spam across multiple accounts.** https://www.reddit.com/user/UnkindTaborp/submitted/ https://www.reddit.com/user/UnkindTabora/submitted/ https://www.reddit.com/user/UnkindTaboro/submitted/ https://www.reddit.com/user/unkindtabori/submitted/ https://www.reddit.com/user/unkindtabors/submitted/ https://www.reddit.com/user/UnkindTabory/submitted/ https://www.reddit.com/user/UnkindTabore/submitted/ https://www.reddit.com/user/fegertsa/submitted/ https://www.reddit.com/user/trukirukia/submitted/ https://www.reddit.com/user/buyuksd/submitted/ https://twitter.com/nerd2techdeals/ name changed to https://twitter.com/techdealsandmor and https://twitter.com/dealstechjunky https://twitter.com/give2emsome name changed to https://twitter.com/give3emsome https://twitter.com/GeekDailyDeal
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/7z6uqc/dont_know_where_to_start/dum0zlb/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
And if you started with a vector (which should be your default), why would you ever switch to another container?
In my own personal opinion, I would opt to choose python over relearning modern C. This is simply my opinion and other redditors can beg to differ with it. I have my own personal reasons for preferring python programming language over C programming language and this is simply because python is more motivating to use than modern C on any given day. There are many performance advantages that modern C has over python but the advantages are counterbalanced with its disadvantages as well. One advantage of using python programming language is that with python, you will need only to learn how trees and list algorithms work and you won’t have the need to write the algorithms yourself. With the build system that you mentioned, it is comparatively feasible to manually compile your program now as it was a couple of years ago. Therefore, you will find little use for them but for mere demonstration or sample exercises. That being said, you may want to check out a good programming school that can teach you the libraries and other techniques used in creation of modern software systems. That school would be Holberton School (https://www.holbertonschool.com/) as it has a good curriculum to help you to learn how to develop software applications from scratch. 
There are quite a number of online communities for student developers which can help you to become a better software developer in general. As you have said, since you are interested in C++ communities, there are only a few online communities for the same that you can be part of and be able to interact freely with each other. Some of the C++ slack communities that I know of include: KDE c++ community and CPPlang community. You can check out on what each of these respective communities offer and then make an appropriate decision on which one of these two communities you can join. You can decide to join both of them if you like and you are free to check out on other C++ communities other redditors will recommend to you. On the other hand, if you wish to learn deep C++ among other programming techniques that are currently in use today, you can join our good programming school called Holberton School (https://www.holbertonschool.com/). Our school has a 2-year full stack software programming curriculum that can help you get knowledgeable in creating modern software applications. You will find a C++ developers community there and you will end up benefiting a lot from our program. 
Python has a "batteries included" attitude, and you know, it has made it my go-to tool because of this, particularly for short tasks. I'd be really happy with significant more _specific_ stuff in the STL. Things that haven't been mentioned here yet * JSON! * also Windows INI files * Compression (zip, tar, gz...) * Multiprocessing 
One of these things is not like the others. There are a lot of relational databases out there already, and it's pretty clear that to be useful, they can't really be _that_ simple... And if we're going to get shared memory, there should be some sort of multiprocessing framework as well.
Plotting in the standard library? No thanks.
Ooh okay, yea that's right! That's a good motivation to try a couple of other things on Mac and see whether it works decently, thank you very much! :-) I am definitely spoiled by Visual Studio (with CMake, not VS build), nothing comes close to it in terms of productivity and debugging tools.
&gt; Newton himself argued that light is nothing but particles. Should we all agree? But as you almost certainly know, light is actually made up of particles called [photons](https://en.wikipedia.org/wiki/Photon). In other aspects it is of course a wave, but Newton wasn't wrong (and does he really say "nothing but"? skeptical...) Stroustrup's opinion likely has extra weight over any other individual's, and there's a committee for the actual decision-making process. I think pretty well everyone agrees that C++ would be better with a significantly bigger standard library. Even very large libraries are just not an issue if they are obviously purpose-divided. Yes, Boost - but it suffers badly from the fact that it has too many sub projects and many of them have fanciful names or do obscure C++-y things and too few do boring, import things.
&gt; Did Newton design and create the initial versions of light? NATURE and Nature’s Laws lay hid in Night: God said, “Let Newton be!” and all was light. [-Alexander Pope](http://www.bartleby.com/297/154.html)
&gt; Because it'll make things easier Of course that is a very important argument. If you don't care about making things easier for normal users, then why do we have things like `std::vector`, `std::sort` or threads in the library? They too could be provided by third-party-libraries. Aside from that: * It would provide true portability, which is not really the case at the moment for any of the GUI-frameworks. Why do I have to develop multiple frontends, when I just need one? A standardized GUI would solve that. (I don't think about something overly fance, that's why I consider extendability important, but basic buttons, textfields, frames, ... would solve be perfectly fine for MANY applications. Also note that this might even allow TUIs (like ncurses) as fallback, so even plattforms without graphics would benefit. * Speaking from experience with std-APIs vs. 3rd-party-APIs, the std-API would almost certainly be better integrated into the language and feel less like a foreign object. (Yes, technically a 3rd-party library could do that, but none does (Gtkmm is relatively close, though and could provide a decent base from which work could start). * Similarly a standardized GUI-API as part of the standard could easily evolve with the standard and be well integrated with it's other types. If we got for example basic support for image-manipulation, I could use the same image-buffer for displaying it to the user as well as for work on it (potentially using a third-party-library, since standardized components might be used by those), avoiding slow and cumbersome conversions between types of different libraries. * Extendability would mean that there could be better third-party-libraries that provide specific features to the GUI in a way that works for everyone. * Implementing a GUI in ISO-C++ is simply IMPOSSIBLE since the concept doesn't even exist. The code differs heavily for every plattform and people who don't own a compatible system cannot develop for those plattforms. * On a more dogmatic level, I believe that a good language should allow to implement a web-browser purely by using stuff that is in the standard. Not necessarily the fastest one arround, or without a lot of work, but POSSIBLE. Otherwise the language lacks important features IMHO. Just pointing to third-parties is a lame excuse IMO. &gt; without also adding a large amount of work to me, personally, or to the various compiler implementers and STL writers I don't consider work for the implementers of the standard-library a great argument: If it is too hard for you, don't you think that it will be even harder for regular programmers? If you who know their plattforms and compilers perfectly well consider it too much work to implement if for those few specific plattforms, how is it not even worse for people who don't have these things and who cannot easily add specific compiler-support for whatever might seem helpfull?
It's also misspelled in the title here :P
So a sorted vector then :-) I was being a bit flippant, I guess. I should have added a smiley. My point being that vector is usually a good choice. When STL was first being introduced, people actually thought they might switch from vector to list, etc. (Similarly - why would you ever use list? :-) If you switch from a sequential container (vector, list, etc) to a look-up container (map, etc), you typically need to change more than just the iterator type. You change the code the uses it, not just a typedef. Sorry for being obtuse.
I don't think a table that can be sorted by one or more of it's columns has to be overly complicated. Boost has a multi-index class though it is a nightmare to use. Dedicated databases exist that do sophisticated caching, handling of different disks, SQL parsing, etc. I think that there could be an in-memory data structure that would allow for columns of different types and efficient range queries without being an impossible rabbit hole. &gt; And if we're going to get shared memory, there should be some sort of multiprocessing framework as well. What do you mean by multiprocessing framework?
What really grinds my gears is that you then have to convert them to yet another format, `glm`, to be able to easily use them with OpenGL. It sucks.
That implies insertion sort; doesn't sound std::vector friendly..
Some of this stuff is already in development, but still: * Endian conversion utilities (way to check for current endianness, way to convert any basic type) * Resizable std::bitset (not std::vector&lt;bool&gt;) * Cross-platform support for importing/exporting functions and looking them up (so we don't have to #ifdef the macros and wrap the functions)
Thats not at all true. See this bug and thread: https://bugzilla.kernel.org/show_bug.cgi?id=195235 Particularly this response: https://lkml.org/lkml/2017/1/16/100 &gt;Sure, we're way outside of what the C language spec says, but who bloody cares ;-) &gt;If llvm wants to compile the kernel, it needs to learn the C dialect the kernel uses. 
Your library has an interesting ways of how to implement an overloadable callable object wrapper. There are several reasons why [function2](https://github.com/Naios/function2) implements its own vtable rather than relying on the features of the language. Similar implementation in the [CxxFunctionBenchmark](https://github.com/jamboree/CxxFunctionBenchmark) have shown that manual vtables paired together with a command table for modifying the unerlying erased object benefits from better compiler optimization and speed. Additionally function2 uses two modifications of the same vtable in order to ellide the data pointer (through joining it together with the buffer for small object optimization). 
Couldn't an implementer have the function detect if it is being run in a constexpr context and use an alternate error reporting method if so? A constexpr context only exists in c++, so no worries about making it not conforming to ansi c because it would fall back on default behavior.
We'll have to agree to disagree on this one then. Anything that uses the deref OPERATOR is a dereference always, not just from a language lawyer POV. IMO, the only thing you can call "C" is standards compliant C. Everything else is a strange dialect. Once you have nested functions, it stops being "C" and starts being a dialect.
&gt; built-in GUI? If so, make it good (no missing widgets and other problems) The "no missing widgets" part is completely unrealistic, which is why I think that any GUI support in the standard should, on the contrary, be as minimal, but as flexible and extensible, as possible.
Well, yea, it would take an update of the standard to support it. They could add wording that says something like "implementers are permitted to provide constexpr versions of any C standard library functions, so long as they behave as defined by the C standard when not run in a constexpr context" or something to that nature.
You should spend a while with the Linq extensions in C# and then come back and see how you feel. IEnumerable is so simple and yet still so flexible. The C++ iterators will seem positively over engineered in comparison.
*concept* `Widget`
I get anything that's not "gamer-y", has a full num pad, and has Cherry MX Red switches
Like what Python has, say: https://docs.python.org/3.6/library/multiprocessing.html
What is it about linear feedback that makes you prefer it over force feedback?
A 10€ logitech, nothing fancy or special, it works and is what i need
Have you tried modern ergonomic keyboards?
Why would you need to do process level concurrency when you can do thread level concurrency in the same memory space with the atomic primitives that C++ already gives you?
Even if i am a CLion user it is nice that others products improves, i dont know if someday i will be forced to use VS and i am pleased to see that now it has a native Catch integration or others features
While I appreciate the content that is presented in the article it is riddled with so many grammatical mistakes it makes for a difficult read.
&gt; I don’t know anyone who actually uses the regular expressions, nor the localisation, nor std::multimap. Something tells me I don't want you writing standard libraries....
Argument goes double for emacs, which has many of those plugins out of the box. 
A bug report would be great :) The worst that should happen is the builds are simply not accelerated whenever something goes wrong. Following the issue tracker or chat should show a pretty quick turnaround on user feedback. Send an email along so it can be fixed :)
Removed as off-topic.
I don't like clicky feedback because of the noise, and the fact that they tend to be heavier keys As for just tactile feedback I really don't have a use for it. With switches as light as reds I bottom them out pretty much all the time, and I'm not really a huge fan of even a small bump to overcome
More like move semantics were added in order to implement something like unique_ptr. It wasn't obvious at all before. 
Can't post meta stuff? :/
If you want to help, you could write a short document explaining the API's deficiencies, from the perspective of a graphics engineer. WG21 has relatively few people with domain-specific knowledge. It takes far less effort to prevent a mistake from being Standardized, than it does to unwind it later. (From the little I've seen of the API, combined with my minimal self-taught graphics knowledge, I am also opposed to this approach - which is why I'm interested in having a professional explain the deficiencies better than I can.)
Find another subreddit, please.
QString, QVariant, QVector, etc.... GRRRRR!!!!
&gt; Compression I'd be for a compression library that is designed somewhat similar to &lt;random&gt;. The standard could define standard compression algorithms for zip, tar, gz, and 7z. Other compression algorithms could be defined by compiler/standard library vendors or by customers.
Doing the full comprehensive review will take a lot of time but I can jot down my initial reactions here for you and other interested: 1. Imperative "fixed-function" style programming is inferior. Most UI based systems end up being heavily data driven as opposed to a sequence of commands like "draw a box here" with a corresponding flush. This is mainly because layouts need to generally be flexible and support a variety of screen sizes, scrolling, making things expand to fit available space, etc. 2. Given point #1, you might ask, why not create a layout engine in the provided specification? The answer is that the engineer savvy enough to do so is likely going to understand what aspects of the layout need to be retained, and what components need to be streamed. Building command buffers to send to the GPU is expensive if done incorrectly, and handling aspects like scrolling, scaling, animations, and more requires lower-level control to modify push-constants, uniforms, and more (which in turn get consumed by a shader). Without this control, I just can't imagine a flexible layout engine written using this specification as being performant for real-world usage. 3. User interactivity is tricky. Most systems that do so leverage an event bubbling approach so if a user clicks something, the event is passed to the inner-most component and bubbled upwards through a tree and each component has a chance to handle and/or capture the event. Think of a button inside of a draggable box inside of yet another button. A bubbling scheme gives the developer flexibility in how to handle the event. This means we need some sort of spatial partitioning scheme for all the bounding boxes that are being dynamically laid out. However, if I'm going to be managing all that myself, why do I want to incur the headache of synchronizing it with another system? 4. Things mentioned in the draft potentially rely on hardware-dependent things. Font rendering is a big deal for example. Different graphics cards have different antialiasing capabilities. They may also support varying numbers of available swapchain framebuffers, bindable texture units, etc. For some aspects of a 2D api, sure, this might be overkill, but in other applications not. For example, if I want to render a texture on a button, it's very important to know if I expect the texture to be changing frequently (every few frames or so), or if I know that the texture is never going to change. Modern graphics APIs let me specify if the memory this texture is being allocated in is host visible or device visible. Basically, there's enough stuff that isn't contemplated that makes me feel like this is just being proposed to make toy applications. It's far shy of what the browser renderer is capable of. The actual parts that really would benefit is getting a vulkan/direct3D/openGL/metal context as well as handling OS messages in a standard way. Similar to what SDL, SFML, or GLFW does now.
So std::variant&lt;std::function&lt;...&gt;, std::function&lt;...&gt;&gt;?
I don't think specific serialization formats should be part of the standard library (ie. json, it is just too opiononated), although some user overloadable serialization and deserialization functionality wouldn't be a bad thing. Also multiprocessing can be done in so many different ways that IMO it shouldn't be part of std, but of course I"d like to see a standard subprocessing module.
The article seems to assume that standard library implementers would have to implement all this from scratch instead of just providing a standard API over existing OS-specific libs. Given the many examples (given in the article!) of such cross platform APIs already existing, it seems this is a problem that is well enough understood to attempt a standard API. You may say that graphics is a complex and performance sensitive enough area that a simplified standard API would useless, but as a counter example let's look at the parallel extensions to the std algorithms. They are (I'm assuming, admittedly) implemented on top of OS/hardware specific parallelism libraries like TBB, PPL, GCD. Anyone wanting to be able to tweak things to perfection would potentially choose to use the specific library directly instead of using the std extensions. Yet the parallel extensions are still a very valuable addition to the standard library.
&gt; The article seems to assume that standard library implementers would have to implement all this from scratch instead of just providing a standard API over existing OS-specific libs. Actually the author addressed this point too. &gt; Given the many examples (given in the article!) of such cross platform APIs already existing, it seems this is a problem that is well enough understood to attempt a standard API. If you standardize an existing API, then you essentially have to standardize the entire existing API, including the dependencies on other features not currently included in the language such as support for Unicode text, event-driven input handling, etc. You can't just run a lobotomy on libSDL and standardize "just the 2D parts". But even if you could, now that's development work instead of just doing s/boost::/std::/. &gt; You may say that graphics is a complex and performance sensitive enough area that a simplified standard API would useless The author didn't say a standard API would be *useless*. They did say that, given the many pressing issues in C++ that warrant attention from the overworked members of the C++ committee, that a 2D graphics API surely must rank lower than other needs which are not being taken up.
&gt; but basic buttons, textfields, frames, ... would solve be perfectly fine for MANY applications. Bah. I hear this a lot but I don't think this argument actually holds any water. This sort of hand-waving and diction ("*all* you need is XYZ") is probably the sort of thinking that created the issue we're in. OK let's try it. Text field. What happens on mobile? Keyboard pops up. Does the UI push up? Does the keyboard occlude part of the screen? Oh gosh I hear people say, you need to handle it? Yes. Yes you do. Ok now the keyboard is up and the user wants to cancel the input. Usually tapping away hides it. Oh god so how do we do this now? Cover everything that isn't the input in a "button"? Maybe you have buttons in buttons and how will that work? Do I support copy/paste from other text fields? Let's not just reduce what is actually a tremendous amount of complexity. I find your kind of reasoning infuriating because it's half-baked but comes with a very strong assertion about what ought to be done. &gt; If we got for example basic support for image-manipulation, I could use the same image-buffer for displaying it to the user as well as for work on it Bah no this just isn't how it works. A lot of the image formats exist for a *reason*. Pixels are swizzled to make warp or wavefront access on a GPU much more efficient than the scanline encoding. Images have various compression artifacts when encoding in row-major vs column-major order. You keep looking for something that "just works" without considering that there are in fact, real reasons why the complexity exists. No you can't just have an all-inclusive solution because the API that contemplates it is going to ask you lots of questions. You could replicate it, but it already exists elsewhere and people are using it. &gt; I believe that a good language should allow to implement a web-browser purely by using stuff that is in the standard. Name a good language. I'm pretty familiar with browser tech. Let's try it. 
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/7zb3bi/help_with_2d_array/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
&gt; I do think there is a chance that something like Boost.Intrusive Whoa. That would be awesome! I'd be (pleasantly) surprised if Boost.Intrusive got into `std`. I think it gets used by a lot more people than you'd think. It appears Facebook uses it, for example. (it's used in several areas of their folly library)
&gt; If you don't care about making things easier for normal users, then why do we have things like std::vector, std::sort or threads in the library? I think there's a big distinction between purely virtual and abstract concepts like std::vector, std::sort, and threads, which can exist entirely independent of any help from an operating system (e.g. cooperative multitasking), and the concept of interacting with the hardware to render a GUI. There is an unbelievably massive difference in the complexity between authoring std::vector (commonly given to programmers as an interview exercise), and authoring a GUI library. I mean, really, the difference is apparent. The GUI proposal is over 100 pages long, whereas a relatively straightforward (perhaps not insanely optimized) implementation of vector is about 500 lines of code, give or take. &gt; They too could be provided by third-party-libraries. Yes, and they were for a good long time, and those third party libraries all ended up converging on roughly similar designs for the same data structure. There's really not a huge amount of wiggle room for std::vector when it comes to API design. I mean, sure there are some choices, but it's mostly 6-of-one, half-dozen-of-other, type choices. Nothing that fundamentally changes the concept of std::vector in a meaningful way. Whereas all of the existing GUI libraries have *radically* different internal designs, APIs, performance considerations, platform support, style and theme. There's no consensus on how to do things, and on the large part every aspect of all of these major libraries are so fundamentally different that it's challenging to meaningfully compare them beyond the highest level concepts. Further, GUI library technology is evolving rapidly still. As far as I can tell, in the last 3 years, each major GUI framework has started adopting the concept of a scene graph, where that wasn't the technology of choice even 5 years ago. The concept of a computer-science vector, or "grow-able array" has remained essentially fundamentally identical since the days of FORTRAN, hasn't it? I mean, maybe I'm misinformed, but I honestly don't think it's changed much, ever, has it? &gt; It would provide true portability, which is not really the case at the moment for any of the GUI-frameworks. How is it going to actually accomplish that? How is this GUI library going to work seamlessly with all of the following: * X11 / X Windows * Wayland * Mir (deprecated, for the most part, I know) * FrameBuffer * Surface Flinger (Android) * win32 API * DirectX * OpenGL * Metal * Vulcan * Cocoa * IPhone * NCurses * Whatever QNX, Solaris (OpenIndiana), ***BSD, XBox, PlayStation, Nintendo Switch, and name your favorite platform, offer. It's not. It's going to require someone to implement support for all of these. And that's not something that should be baked into a language standard. If we baked into the standard, we'd CONSTANTLY be playing catchup to new technologies. Instead, it'll be left in the hands of the compiler and STL implementers. It'll be another opportunity for the classic Embrace Extend Extinguish, or if not that, it'll be a point of compatibility that never actually gets smoothed out enough across various compilers / platforms to prevent someone from grumping about it on reddit. &gt; Why do I have to develop multiple frontends, when I just need one? Well, you don't. There are plenty of existing 3rd party tool kits that are truly cross platform. Personally I recommend Qt, but you have plenty to choose from. Most of these existing tool kits are * Open Source in either commercially friendly ways, or copy-left, depending on your preferences. * Work on nearly every platform out there * Heavily optimized * Nicely integrated into the existing look and feel of the platform in being run on Whereas, I'm extremely skeptical that the GUI provided by the C++ standard is going to be any of those last three bullets. * Cross platform -- It's a new technology. Bugs happen. I don't expect this to work well on any platform for several years, and it'll NEVER work on at least some platforms, ever. (whereas 3rd party libraries probably already do). * Heavily Optimized -- Well, according to wikipedia (https://en.wikipedia.org/wiki/Qt_version_history) it's taken the Qt framework about 23 years to get to where they are today. I'm not going to hold my breath that such an all encompassing concept is going to get good performance within a decade. * Nicely integrated into the platform being run on -- See above two points... &gt; A standardized GUI would solve that. I disagree, as you've seen elaborated above. &gt; (I don't think about something overly fance, that's why I consider extendability important, but basic buttons, textfields, frames, ... would solve be perfectly fine for MANY applications. Also note that this might even allow TUIs (like ncurses) as fallback, so even plattforms without graphics would benefit. Right, so you recognize that the various GUI environments that will need to be supported are numerous. Thus where my own objection comes from. I'd rather not expect free work out of the GCC and Clang developers to support every platform under the sun. I'd also rather not see my license costs for Visual Studio to increase to pay for this. What I'd rather do, is use one of many existing, well supported, well tested, battle-hardened, high performance, feature rich, flexible, extensible, and best of all "already works!!!" 3rd party libraries that do exactly what's being proposed, only better and... already doing it. &gt; Speaking from experience with std-APIs vs. 3rd-party-APIs, the std-API would almost certainly be better integrated into the language and feel less like a foreign object. (Yes, technically a 3rd-party library could do that, but none does (Gtkmm is relatively close, though and could provide a decent base from which work could start). Except for this is a pure library addition proposal. No new syntax or other language-level features are involved. This GUI library is the new kid on the block. It has no street cred, and no integration with the existing STL beyond living in the same document. There's no meaningful difference between the existing proposal, versus someone appending the tar.gz of https://download.qt.io/archive/qt/5.9/5.9.1/single/qt-everywhere-opensource-src-5.9.1.tar.xz.mirrorlist or https://www.gtkmm.org/en/download.html to the end of the standard (beyond licensing, and specific API and implementation choices, of course). A GUI framework that's *truely* integrated into the language is strictly, and significantly, different than a library-only change to the standard. This isn't that GUI framework. I'd rather use an existing GUI framework that's been battle tested in commercial environments for years. Further, personally I don't really think the "foreignness" of a GUI library is relevant. GUIs are significantly different beasts than concepts like std::vector that I don't mind one bit if the api doesn't feel 100% fully native to the language. It's a hard problem. 
 &gt; Implementing a GUI in ISO-C++ is simply IMPOSSIBLE since the concept doesn't even exist. The code differs heavily for every plattform and people who don't own a compatible system cannot develop for those plattforms. Well, if it's so impossible, how in the world is this proposal, which is a library-only change (It makes no changes to the actual language itself) going to change that? And if it's so impossible... how exactly do libraries like Qt, GTKMM, and so on exist? The code to implement this is going to have EXACTLY the same problems as existing 3rd party libraries. * Different platforms have different ways of drawing stuff on the screen. So what, now compiler vendors need to figure that out for every platform they support? Yea, good luck with that. We'll be back in the dark-ages of Borland C++, and Visual Studio 2005, where you both had to deal with the vendors special-flavor of the STL (If they even offered one), but also the special language quirks that they offered as "optimizations". * Most small time compiler vendors won't offer this API. So you'll be in a world where only the major 3 vendors (Microsoft, GCC, Clang) are allowed to exist, because they're the only ones that can afford to actually offer full compliance with the standard (haha, even VS2017 doesn't do that. I get internal compiler errors on code that GCC and Clang both handle no problem every week. Visual Studio is a joke of a compiler, though I'll admit that it's improved significantly in the last couple of releases). I mean... how exactly do you think this GUI library is going to be implemented? Under the hood, it's basically going to be Cairo-alternate, right? So it's going to live on your system as a collection of header files, and a collection of shared-objects (.dll, or .so or whatever). When you want to use the "standard" GUI, you #include the headerfiles you want, and you tell your build system to link against the shared object(s). There's no magic here. The only difference is that this shared object comes from my compiler vendor, instead of a 3rd party. It's identically the same aside from the vendor of choice. The compiler vendor still has to solve all of the same problems that, e.g. the Qt framework has to solve. But we'll have all of the problems that come from new code bases. * Bugs. Always bugs * Inflexible -- multiple vendors of the same API means you can't fix problems in your version of the API, or you risk breaking compatibility with others. * Glacially slow update schedule * Vendors who interpret the standard differently, giving you fun Heisenbugs, or worse, Embrace, Extend, Extinguish, style "improvements" or liberal mal-interpretations. * Not all vendors will support the library. I mean, frankly, I'm not sure how we could possibly expect the various C++ interpreter or virtual machine projects out there to support this, nor do I expect any embedded vendors to. And honestly I don't see how people think Clang or GCC are going to either. So we'll have half the world using compilers that don't support this. That's even worse than what we have not where you can download a 3rd party lib yourself, and it works out of the box. &gt; On a more dogmatic level, I believe that a good language should allow to implement a web-browser purely by using stuff that is in the standard. Not necessarily the fastest one arround, or without a lot of work, but POSSIBLE. Otherwise the language lacks important features IMHO. Just pointing to third-parties is a lame excuse IMO. There's literally nothing stopping you from doing this now. You're perfectly capable of implementing a web-browser, today, yourself, in pure C++. It'll even be cross platform. This is how Google Chrome and Mozilla Firefox are built. Well, Firefox is using Rust in addition to c++ in recent versions, but you could always implement, e.g. Firefox 4.0 or something in pure C++ I'm sure. Just because the standard doesn't hold your hand doesn't mean you can't do it. The existing GUI libraries that are out there for C++ are..... written in C++, or C. There's no magic. Just an insane amount of work by dedicated programmers. What's next, are you going to ask for an IDE to be included in the standard, because you can't build a web browser without the IDE? Do you prefer Vim or Emacs? &gt; I don't consider work for the implementers of the standard-library a great argument: If it is too hard for you, don't you think that it will be even harder for regular programmers? You misunderstand. My concern is that every man-hour that gets put into implementing a GUI library for the standard is a man-hour that didn't go toward more fruitful endeavors. For example, I'd much much much rather have metaclasses, https://herbsutter.com/2017/07/26/metaclasses-thoughts-on-generative-c/ Metaclasses is going to be *THE FEATURE* of C++ when it's finally approved. For the first time, we'll be able to remove words from the standard, while simultaneously increase the languages flexibility and feature set all at once. In fact, we'll be able to remove those words specifically BECAUSE of the new features and flexibility. I mean, come on. The potential for domain specific language types of usages for Metaclasses is just AMAZING. Why is anyone even considering including a 100+ page GUI proposal when they could be working on metaclasses? &gt; If you who know their plattforms and compilers perfectly well consider it too much work to implement if for those few specific plattforms, how is it not even worse for people who don't have these things and who cannot easily add specific compiler-support for whatever might seem helpfull? Maybe you have a misunderstanding of what I do. I, myself, am not a compiler vendor, or STL implementer. My day job involves managing the compilers that my company uses to compile our own codebase. That means I generally download the new versions of things like Visual Studio, GCC, Clang, and so on, and their accompanying standard library implementations. Then I compile our entire codebase against those updates, and if everything works fine, I push it to the rest of the company. Part of that work almost *always* involves fixing stupid bugs in the STL code of the compilers. Like, tweaking a function to stop screaming about some meaningless warning or another, or adding back a function that the compiler in question had for years and then mysteriously removed with no warning. People on my team sometimes even have to patch the compiler itself, because they add bugs that breaks on code that we've had for longer than I've been alive. We've also got our own STL compatibility layer to massage out the differences between Microsofts STL, Clang, GCC, and so on, and damn do they have differences. So I have to do a lot of hacking on that to get it working with underlying STL changes. If a GUI library gets added into the language standard, my company won't ever use it. It's just not going to happen unless the day comes when the various GUI libraries that we do use somehow depend on it (which I'm skeptical of. I mean, look at Qt, it still has it's own vector class *shrug*). So instead, we'll remove it from the STLs of the compilers we upgrade to. I'll just go into the GCC and/or Clang package, and delete the shared library, and the associated header files. We're especially concerned about adding the new shared libraries to our deployment packages, with the increased security surface area that that would come with. Just not worth adopting something like this when our existing GUI libraries are perfect for our needs. So what I meant was that this GUI library is so contrary to how an existing multi hundred person development team operates uses C++ that we're going to delete it from the STL implementation we use. That's how bad of an idea this is, that we're going to purge it from our copy. You don't hear anyone claiming that they're going to purge std::vector, because std::vector is fundamental and universal. std::gui is neither fundamental nor universal.
I'm not suggesting standardising an existing API - I'm saying those existing APIs are very useful data points when designing a more or less original API. Again, in the same way that the parallel algorithms approach was tested and proven by existing parallelism APIs. If it were up to me I'd use the committee's time differently too, but the fact is that there are people actively contributing on this WG and not on things you and I might prefer. At the end of the day no committee member is forced to read or vote on any specific proposal, so if they feel their personal time is better spent on other proposals I'm sure they'll do that.
You know fuck it. Lets just slam the rest of boost in there. Toss in rapidjson just for good measure. Maybe Tim Sweeney will be open to the idea of including the Unreal Engine into the mix as well. Seriously, this is getting completely out of hand. Shit is being seriously considered for the standard library that has no business being anywhere near it.
I appreciate your response. I'll look into the developer and user mailing lists.
A move of all the functionality in Python's str and Qt's QString would be a good start. We got std::regex before string splitting!
Maybe glm should be standardized
 &gt; I think pretty well everyone agrees that C++ would be better with a significantly bigger standard library. Citation needed? I am extremely against the standard library growing, even at all, much less significantly. Of course, I'm not a member of the committee, so my opinion isn't really considered to be very important.
It sounds like it already has been...?
Well, my build system uses MSBuild+MSVC, and there are a number of native CLI programs I frequently use for work. I also really like PowerShell and have my environment customized to take advantage of it. I don't really enjoy working in bash whenever I have to these days. It's possible to invoke linux apps via WSL from PowerShell though, which I do sometimes. I never considered using WSL vim like this to use rtags and YCM. I might give it a try.
I don't think it has, considering others in the thread have "linear algebra/geometry" on their wishlists.
Personally, I'd like some linear algebra. We already got `vector` for the one-dimensional variety, and I don't think it'd be completely unreasonable to slap the 2D (matrix) and 3D (cube) variants in there too. Add your normal matrix operations like addition/subtraction, multiplication, cross- and dot product, rank/transpose functions etc, and I'd be happy enough.
We also have external libraries for networking, and they're just fine, but people still want to add networking into the standard... So in my view, this argument doesn't work.
Looks like a great opportunity to be cheeky and do `return NAN;`
Especially considering that Cairo will also give you output to printers, PDF, Postscript, SVG, etc. which I don't believe is planned for the C++ library. Oh, and it integrates nicely with Pango if you want proper text output as well.
I **knew** what the result for "worst IDE" was going to be, and that it would be the "winner" by a long shot, even before I saw the results...
&gt; With fixed-point, I can dictate how precise a number should be which can be more suitable. I still don't follow. Irrationals cannot not exist in finite memory. Transcendental functions though are problematic because you're never sure whether the calculation of such function returned a properly rounded result. But to get properly rounded results, you need to use extended-precision arithmetic. That you can have also with floating-point. So what problem does using fixed point math solve? 
Based on your argument, perhaps networking shouldn't be part of the standard library, but that doesn't mean there shouldn't be a standard implementation, e.g. POSIX.
`string_view` was really necessary for any splitting functionality to be worthwhile. Of course, `string_view` could certainly have come much sooner...
&gt; It takes far less effort to prevent a mistake from being Standardized, than it does to unwind it later. Reading this statement I simultaneously over and under flowed. 
Objectively, tons of people use the builtin networking features of other languages, but, except for people doing C# forms or WPF apps on Windows, very few people use the standard library graphics APIs of other languages. Mono bundled Tao and Cairo and supposedly supports System.Drawing , but everyone uses OpenTK, FNA, MonoGame, SDL2-CS, and SFML.Net. Python has Turtle graphics and TK. But the few who do graphics work in Python use PyOpenGL, Pyglet, PyGame, or Kivy. People who make games in Java use JOGL, lwjgl or LibGDX. I presume there's still Swing apps out there, but...come on now. Qt also already fills that need well.
I like the graphics proposal and I hope it gets accepted. I would use it as a replacement of std::cout for most numerical data once it is in. If only for debugging since there is yet no text
No see, this stuff shouldn't be standardized. The basics are VERY easy to get right. The useful libraries that exist though use SIMD or AVX or even compute on your GPU depending on the size and scale. They handle sparse matrix representations and do a ton of in-memory rearranging to make operations coherent. No no no. A `vector` has nothing to do with the mathematical vector and is purely a dynamically resizing block of memory for storing a homogeneous set of items.
2017 vs comes with a source view, no need for filters afaik
Why not? Have you any objective arguments, why that stuff should not be in the standard library other than "OMG I hate change"?
I prefer 3rd party. There are too many shitty std implementation out there.
I'm not saying it isn't useful. I'm saying we need to do the low level primitives right first. Detecting CPU architectures and providing an abstraction around SIMD instructions and registers (heck even just detecting the capabilities) is a useful cross platform feature that would be a necessary prerequisite for all real-world vector/matrix libraries.
&gt; We got std::regex before string splitting! That’s a Good Thing™: regex are a *core tool* for working correctly with Unicode text. They’re more essential than operations such as `substr` and `find` (which aren’t Unicode aware!) — and, yes, `split`. In fact, the Unicode standard makes explicit reference to how regular expressions shall support Unicode. In fact, the above-mentioned operations could (and, arguably, should) all be implemented in terms of the regex engine (with a fixed matcher, for performance) to ensure consistency. But of course that’s no longer possible since their specification explicitly forbids that (they operate on bytes not Unicode encoding specific characters).
Sorry, but something like this should be built-in by default into Visual Studio. Having to pay for such a solution is a no-go in 2018 imho. In fact, I could imagine that Microsoft would even like to do this, but it would destroy the business model of several companies by doing so (e.g. Incredibuild, and this one). Sad. If you are on platforms other than Windows, you already get this functionality for free for &gt; 15 years with distcc or [icecream](https://github.com/icecc/icecream).
This is actually really interesting. Can you point me to your writeup on it or draft if it exists?
uhm I would argue that splitting a string in multiple strings is very much worthwile even if it allocates..
Dear committee. Unicode. Please make it work. Sincerely, everyone and their dog.
std::chrono is riddled with constexpr. One of the main defining features of a clock is the ratio of the number of ticks that clock has in one second, which should be a thing that you can define on the fly, but I didn't see a way to do that. Admittedly I've only used the thing a couple of times so I'm still pretty unfamiliar with it, so I could be wrong about that. You might want to define a new one on the fly, perhaps, if you're working with video or audio in ffmpeg, which uses the same concept for its presentation time stamp -- pts is stored using a ratio that's defined in the codec context for the media type you're using. If you could create a new std::chrono clock at run time, you could then use std::chrono's functionality to convert pts times to milliseconds, microseconds, fractional seconds or pretty much anything else that std::chrono can express, trivially.
Is still still about the indexed mesh builder example? How do I know to sort the vector while I am building it? Alright. I'm game, I'd like to know how this is going to be efficient: struct Vertex { float32x3 position; float32x3 normal; float32x2 texcoord[2]; uint32 diffuse; }; std::vector&lt;Vertex&gt; vertices; std::vector&lt;uint32&gt; indices; Vertex v; uint32 index; if (find_index(vertices, v, index)) { indices.push_back(index); } else { uint32 index = uint32(vertices.size()); indices.push_back(index); vertices.push_back(v); } // The Job is to see if this vertex, v, is already in the vertices // vector and if so, what is it's index in there so that we can refer to it // in the indices array. // TODO: implement fast find_index() function!!! My solution to this is to use std::map to find the vertex; O(log n). I get what you mean by "already sorted" ; if the vector is sorted, finding a duplicate will be a binary search which is same complexity as the binary tree but with more tightly packed data. Where this breaks down is to keep the vector sorted we must be able to insert into the middle of the vector, which is very inefficient. That's what I meant by the earlier "that implies insertion sort".
I'm opposed to the Network TS for some of the same reasons. The network TS requires needed executors, C++ doesn't have them so they added threading facilities in `&lt;network&gt;`. Of course I use sockets, but if we are going to standardize things, let's do it from the bottom up. 
Eigen got it pretty much right. :-) Eigen is pretty easy to use (header-only) though so no need to really have it in the standard library. But what would be nice to have in the standard is the underlying abstraction, a multi-dimensional view on memory. But the committee is not really progressing on standadizing that, as I mentioned in other threads here already :P That would make interfaces, interoperability between libraries, etc., all very much easier.
I totally agree. It has been almost two decades and nothing easily useful has turned up. My friends and I were fired when the game studio shut down, and making something like, (or better than) ccache was something I really wanted to create. But, like most everyone, there are bills to pay, so we went with a dollar a day approach. Mostly for commercial studios that are building software for profit. Spending one dollar per day per programmer is not a great hardship (compared to the ludicrous charges for other tools). If you are on an open source project and also making life better for other programming humans, send us a shout. The pricing is written in CSS, not stone :P The whole motivation was to make something that is helpful, and reciprocating good will is no sin :) 
&gt; I'm not exactly looking forward to waiting 13 years for bugs in the GUI library to be fixed If you have severe bugs in the standard-document itself, it likely means that it goes into too much detail that should be left open for implementers. Bugs in the implementation on the other hand can of course be fixed through the regular release-cycle of the stdlib. &gt; What kind of image manipulation? Like, actual image formats? Or bitmaps in the ycbcr, or rgb, or whatever color spaces? for the start: bitmaps in a parametric colourspace (extendable, but the standard should at least provide rgb, rbga, black-white) as well as functions to load and safe them from/as PNGs and JPGs (other image-formats could be left as possible extensions to the vendors(. &gt;If you mean various image formats, like jpg, gif, so on. No way. Not a chance. Patent landmines, copyright issues, I'm aware that some developing countries still have issues with software-patents, but at least for JPG and PNG I'm pretty sure that this is a non-issue at this point even there. &gt; huge implementation libraries, bikesheds about optimization, API, and so on. Just not happening. You always have bikesheds about APIs during standardization, but a standard-solution would precisely end these arguments.
It would be super useful if you sent this sort of feedback to the appropriate study group, which is SG13 (Graphics). I don't know if the appropriate people are here on Reddit, or on this specific discussion thread.
&gt; Cross-platform support for importing/exporting functions and looking them up (so we don't have to #ifdef the macros and wrap the functions) That's proposed: https://wg21.link/P0275
I am sorry. I forgot to mention that there are some free alternatives. clcache and sccache are both meant to work with MSVC. There are some caveats, like needing to retool your build system and not being able to use some pretty standard features of CL.exe. The setup for both are either not documented or requires a great deal of effort from each programmer installing them (and changing their build system, so they can't share their changes very easily). If you would prefer a free alternative, I am happy to tell you exactly what we had to do to make it work with Microsoft's tool-chain. It was not easy and took very experienced coders (30+ years of experience) over a year to get it right. That was a year we were not getting paid for our work. We would like to pay our debts from that year :) The secret is not in the implementation. It is in the execution. And yes, we did pay our dues to free software in our commercial projects. 
Yeah there's a lot of fun stuff in there, lots of new shiny tools to play with for those interested in tighter control over i/o and memory. If accepted, it should provide a superb base for building a much more efficient iostreams v2 somewhere in the future. Before that can happen though, we need to make some decisions on how best to let STL algorithms know they are working with i/o-able memory, so for example, if a Range transformation knows its output is going straight to storage, it ought to use non-temporal stores to avoid cache pollution and the expensive cache flush performed before a DMA is issued. That sort of thing. A lot of this is complicated by the new persistent memory support landing in CPUs i.e. the new CLWB and CLFLUSHOPT opcodes, and only just recently they used to have a PCOMMIT opcode which is now gone. So this is very bleeding edge stuff, and almost none of us have real hardware to test any code on, so we're working blind. But it is what it is, we push forwards the best we can.
Qt's QString is indeed a very nice string library. It has a lot of nice utility functions and unicode support.
&gt; no missing widgets and other problems PS no bugs :)
Don't forget these 2 missing things: operator+(const std::string&amp; str, std::string_view); std::string::replace(std::string_view, std::string_view); Seriously, for replacing most languages have only 2 overloads: replace(String, String); replace(char, char); C++ [has 10](http://en.cppreference.com/w/cpp/string/basic_string/replace) but none allows `str.replace("foo", "bar");`
- An improved string class (with **unicode** support and more utility functions like split and join (have a look at QString for instance)). - Support for launching processes would also be great! Again you could have a look at [QProcess](http://doc.qt.io/qt-5/qprocess.html#details), as I have used it in the past and is quite nice, it would be best however to be a RAII style library. - I guess the network library would also be a nice addition (I believe it could be used in a lot of software, like games, networking tools, network programs, api programs etc). - Even a nice and simple command parser library would be a nice addition imo, we could grab the boost options which imo I think it is pretty nice.
You can't define a clock's ratio at run-time, as far as I can tell. But you can use a floating point type for a clock's 'rep' type. The ratio, then, becomes much less important. 
We care about priorities. We need unicode and string facilities, more math and modules. This stuff can wait, most arguments for any library will be over if we get package manager and most missing parts of the standard library.
&gt; This graphics proposal is literally just trying to compete with browser JavaScript. Maybe I'm just a curmudgeon, but it sounds like a very odd idea to me when phrased like this. With webassembly and support for C++ DOM bindings / webgl wouldn't work on this be meaningless?
I really like your list but I don't think a **built-in GUI** will be a good choice. Even if one is created I don't think it could ever compete with "industrial" ones like Qt. Plus I believe it is a area in constant evolution (new OS, new native widgets etc), so to maintain such library would cost the committee / std maintainers a lot of time. I think it would come to be something like Tk for Python, which nobody uses? I have also wonder if the **linear algebra** library would be a good choice, we have some pretty good external ones like Eigen3, and these libraries need to be constantly be updated, especially to take in account new hardware advantages like multi-threading, avx / sse instructions etc.
What is inefficient about the iterators?
&gt; Notepad++ is a code editor. You know, I have no idea how i missed that. Kinda feel silly now. Says so right on the site, code editor. Notepad++ can run external commands though, so could be shortcutted to build system.
How come I've never heard of Cairo - is it not a C library? A quick Google search turns up cairomm, which seems to be a C++ wrapper for Cairo. The API of cairo looks horrible to use (https://cairographics.org/tutorial/). What the ... is that? It seems to me like they're choosing a C library from the nineties for standardization? (Ok I'm exaggerating a bit here, the tutorial is in fact "Copyright © 2005–2007" and last edited 2012). What's going on here? Why would anyone sane standardize a C library from 10-20 years ago for the C++ standard, in the age of modern C++11/14/17?
I’ve yet to see someone talk about C++, use the word “functor” and actually is talking about the functors of category theory or functional programming.
To be fair, it probably bans exceptions too.
Wouldn't stripping the binary be more effective?
Yeah. They aren't terrible. But not as good as the MS keyboard. They really made something great, it is a shame they discontinued it.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/7zenc9/new_udemy_course_coupon_compilation_get_enrolled/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
To me std chrono always felt very over-engineered, unintuitive and most of all very impractical. For example in webkit they [dropped std chrono](https://lists.webkit.org/pipermail/webkit-dev/2016-May/028242.html), because it introduced more issues than it solved.
With RTTI the names would be still there.
&gt; exposed to the potential garbage(user input, random people calling your service) I like your thinking
&gt; not run in actual production code Why not? How do you validate random user input then?
Indeed, what's inefficient about iterator design?
This is something different. OP wants to use different names for symbols, what you proposed removes them. AFAIK there are no symbols in standalone executable, only in dynamic link libraries. You can't really strip a library as there would be no way to load it. So either make all-in-one executable or hash/mangle symbol names in libraries
I looked through the standard, and what I got back was `true`.
This is some higher level humour
&gt; AFAIK there are no symbols in standalone executable I believe there _can_ be. $nm cppcheck | grep ' T ' | wc -l 1265 $strip cppcheck $nm cppcheck nm: cppcheck: no symbols Yes I was under the impression they wanted to mangle symbols as a way to obfuscate those who would reverse engineer. I would think (not an expert on this) stripping the symbols would do that even more effectively.
That's a fair point. Even after stripping: $strings cppcheck | grep _ZN10CheckOther18redundantCopyErrorEPK5TokenRKSs _ZN10CheckOther18redundantCopyErrorEPK5TokenRKSs 
Subjective.
But decimal arithmetic is not the same as fixed-point arithmetic. In fact, all of applied physics uses decimal floating-point arithmetic, e.g., planck's constant is ~6.626e-34.
Appropriate username.
This is seriously good work. An excellent approach - and your writing is just so engaging and unpretentious. Yay!
Well done! I've got a nice one too, for MSVC. If you declare a global inline variable, and use it in multiple translation units, it will be constructed and destructed in each translation unit. For example, File main.cpp: #include &lt;iostream&gt; #include "test.h" int main() { Test.x++; foo (); std::cout &lt;&lt; "done\n"; return 0; } file test.h: #include &lt;iostream&gt; class cTest { public: cTest () { std::cout &lt;&lt; "constructing test value " &lt;&lt; x &lt;&lt; "\n"; } ~cTest () { std::cout &lt;&lt; "destructing test value " &lt;&lt; x &lt;&lt; "\n"; } int x = 0; }; inline cTest Test; void foo (); file test.cpp: #include "test.h" void foo () { Test.x++; } Running this produces the following output: constructing test value 0 constructing test value 0 done destructing test value 2 destructing test value 2 It's clearly the same variable, it just gets constructed and destructed multiple times. Adding further translation units also adds more calls. Inline variables are supposed to be supported from VS2017 15.5 (https://docs.microsoft.com/en-us/cpp/visual-cpp-language-conformance). gcc (7) works as expected. I've reported this to Microsoft, and their response was "We appreciate you taking the time to report this problem. We are currently prioritizing problems that are impacting a broad set of our customers, so we may not be able to investigate this one immediately. We know this problem is important to you, so we will continue to monitor it." 
To be fair Apple’s Swift requires braces after if, maybe to prevent a future “goto fail”? :)
Could be useful for things like debuggers and dlopen(nullptr//... I guess? 
It talks about extensive use of C++17 but the example features mentioned are all C++11/14, or am I missing something?
std::function_view FTW!
[The genesis of move semantics](https://www.youtube.com/watch?v=vLinb2fgkHk) is the first bullet in this talk, given by the guy who brought move semantics to C++11. The chief motivation was a massive optimization opportunity. `unique_ptr` was fortuitous gravy.
Even compiled in release mode?
Thing is: I'm willing to bet that more readers of a c++ library readme understand functors in the c++ sense than whatever it means in FP/CAT.
Certainly you can choose compiler flags that would omit them. I don't know what release mode means in your makefile. Where I work we usually use CMake's "release with debug info" build type when going to prod (more readable stack traces if it crashes), so it certainly has all the class and function names in that binary one way or another.
 &gt; If you have severe bugs in the standard-document itself, it likely means that it goes into too much detail that should be left open for implementers. Bugs in the implementation on the other hand can of course be fixed through the regular release-cycle of the stdlib. Sure. So lets avoid having to deal with bugs at all, by not adding things that are guaranteed to have implementation problems for years and years to come? &gt; or the start: bitmaps in a parametric colourspace (extendable, but the standard should at least provide rgb, rbga, black-white) as well as functions to load and safe them from/as PNGs and JPGs (other image-formats could be left as possible extensions to the vendors(. I think that leaves us open to far too many ways to skin that cat. The number of ways to represent parametric colorspaces is numerous and varied. Why should that be in the standard? You can just as easily do it yourself. &gt; I'm aware that some developing countries still have issues with software-patents, but at least for JPG and PNG I'm pretty sure that this is a non-issue at this point even there. By developing countries, do you mean countries like the United States? From https://en.wikipedia.org/wiki/JPEG#Patent_issues &gt; In 2002, Forgent Networks asserted that it owned and would enforce patent rights on the JPEG technology, arising from a patent that had been filed on October 27, 1986, and granted on October 6, 1987 (U.S. Patent 4,698,672). The announcement created a furor reminiscent of Unisys' attempts to assert its rights over the GIF image compression standard. &gt; You always have bikesheds about APIs during standardization, but a standard-solution would precisely end these arguments. No they wouldn't. A standard solution simply adds another competing standard. Appear to have an assumption that a GUI library being added to the standard will result in widespread adoption of that GUI library. I think this is a point that we disagree on. My assumption is that a GUI library being in the standard will be adopted by a relatively small subset of the C++ community. I don't see the postulated benefit of adding this library as being worth doing, EVEN IF it's bug free, truely cross-platform, and highly optimized. There are simply too many applications that are overwhelmingly invested in their existing GUI technology at this point to justify adding something this large. Add fundamental data types, like point, line, so on. Types that are so fundamental and universal that the majority of C++ GUI frameworks adopt those types. Then you can start boiling the frog. This is biting off much more than we can chew, and we're going to choke on it.
 &gt; The stdlib-vendors know their plattform and can therefore use functionality that is provided by the OS and graphics-card. There is however no portable way to do that for people who just want to use the standard. No they don't. You think that the GCC developers are looking forward to supporting literally every display technology in use today? I mean, you looked at my list, right? I had like 15 different distinct and unique display technologies within moments of thinking. Why do you say there's no portable way for people to interface with platform dependent APIs and hardware specific interfaces? The job of the language standard is not to provide you with perfect cross-platform abstraction. That's never been something the C++ community has tried to do, from my perspective. What you're asking for is that people who have little to no experience in graphics technologies provide an implementation of graphics technologies on every platform they support, which for compilers like GCC and Clang represents almost every hardware platform and operating system that exists. &gt; That is simply wrong. In ISO-C++ I cannot create a window, play sound or set pixels on screen. All these browsers use additional non-standardised functionality of the OS (possibly via further libraries). You also aren't able to construct a POD object with "malloc" in ISO-C++. But I betcha you've been doing it just fine for your entire career. http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0593r2.html The C++ language, in the concept of a language, not a library, is incapable of abstracting every single possible difference between hardware capabilities, and it's difficult enough to get it working with hardware instruction sets that almost don't change, but to ask the compiler to also abstract over vender specific APIs that change nearly every release... I'm just not seeing the benefit here. The language on paper being incapable of doing some task does not imply either that the language SHOULD be able to do that task, nor that you can't actually do it. You're perfectly capable of writing a web browser right now, today. It'll even be cross platform if you want that. Stop claiming that you can't. &gt; Metaclasses are certainly an interessting topic, but IMO much less important than GUI. That's ok. Agree to disagree.
See https://www.reddit.com/r/cpp/comments/7z50oa/batteries_not_included_what_should_go_in_the_c/dunsb94/
&gt; Is still still about the indexed mesh builder example? I'll say no, because I don't what example you are talking about. But your code example explains it enough I think. Yep, that's a case with no easy solution for vector. Inserting into the middle of the vector isn't that inefficient, but it would also invalidate your indices, so that's two problems. If this was for reading in a 3D object, I might convert it to sorted vectors after it was built and all the correspondences were figured out (assuming it wasn't going to be modified much afterwards). A sorted vector won't fix every case, but once I wrote a sorted_vector&lt;&gt; class, I found it improves _most_ cases.
Yes it's naive to think it doesn't have a tangible impact on the standards folks and getting other things into the standard. But I was just pointing out that even if you ignore that aspect, there are other long-term impacts as well.
&gt; I don't know why people hate on std::list so much. It has real uses, and some nice properties for very specific situations/needs: Because it is overused. Not as much as it was in the past (because we've been harping about it, I think), but still overused. &gt; iterators/references to node entries don't change with inserts/removals/swaps/moves - so if you can save them properly, they don't become stale and can be used for very fast remove/move later I've found that most code that relies on iterators staying valid, is fragile code. Not all, but most. It implies there some inter-object relationships going on, ie entanglement ie spaghetti. But if you were to wrap that all up into a single-purpose class, fine, it can be maintained. At which point you could also probably use vector and still maintain those interrelationships (because you've encapsulated it all into a small class that does that and nothing else). &gt; the types stored in it don't have to be copy-assignable nor copy-constructible (since C++11), depending on the operations you perform Also true for vector, although more limited. And types should be copyable. Use value-semantics. &gt; it's a very small size when empty (two pointers and a size_t), and its overhead/size-growth only grows by the number of the entries plus 2 pointers each Vector is smaller when empty. It's overhead and size-growth is... different. I suppose there are times one is preferred over the other. &gt; if you have the iterators to it, removal/moving of an entry is constant time and very fast emplacing and popping from front/back is also constant time and very fast sure &gt; So what could you do with such properties? Well one example would be a timer wheel... Maybe. maybe try implementing it with a list and a vector then decide which performs better. &gt; The only downside is the heap memory allocation required to create the node entry in the std::list to begin with, memory allocation (time) and the non-locality of memory that goes along with that. Allocation is unfortunately very slow (unless you go to lengths to use specialized allocators, etc). And it tends to mean thread synchronization. But as slow as it is, in the end, it is the non-locality that kills you. &gt; which you can avoid if you use a boost::intrusive::list instead. But std::list isn't a bad fallback if you don't want to use boost::intrusive::list. intrusive-list doesn't avoid the allocation, it just moves it out of the list code. The thing was still allocated somewhere. And the memory is still non-local (typically). Anyhow, yes, list has its uses. I just haven't run into them in over 20 years. Honestly, I haven't found a place where they were the best solution. So I just find list us overused. 
I always miss `starts_with` and `ends_with` :(
I think the phrase you are looking for is "username checks out"
&gt; The list, of course goes on. I don’t know what is a good candidate for a C++ library, but, according to the committee itself, a library proposal should: &gt; - Be useful to most people &gt; - Have a stable API that isn’t too subject to frequent change &gt; - Have real world experience and feedback. That’s why most C++ library started their lives as boost library. Which is why I think a graphic library is one step too far. There are **a lot of headless** programs written in C++, for which a graphics stack is pure bloat.
Nah that's played out. Gotta switch it up.
Sorting before computing the indices breaks the topography; the vertex order _is_ how the mesh is triangulated.
You're right - it should do what networking did: go to Boost. Get graphics into Boost and let it percolate for a few years, then come back to the standards committee.
Not sure why this is downvoted... &gt; Indeed, ithare::kscope uses a LOT of C++17-specific constructs (it especially heavily uses-and-abuses constexpr functions and variables, seriously recursive template instantiations, and so on). Nothing mentioned in parenthesis is C++17-specific.
Finding bugs in major compilers is one thing, getting them to fix them is something else entirely.
Agree, well said
That may very well be true, but correcting past misnomers is an opportunity to learn and educate. 
Because on linux shared libraries can import symbols from the executable they run into.
Personal opinion but if you're going to standardise basic C++ graphics, go for SFML, that is one of the nicest and cleanest graphics libs i've used
Do you have a link to the Developer Community issue you created? 
What I have to ask is what it ht problem at MicroSoft? Everytime something like this is done we find MS C++ compiler in bad shape compared to just about everybody else.
I was curious what problems they found, because my work's been converting over to using `std::chrono` pretty heavily. If you follow their long email thread and look at the bug they cite, the answer is _not_ a problem of `std::chrono` per se. It's that they overloaded it to carry multiple meanings. They use the `max()` value of a duration to mean `false`, and end up getting overflows when they convert a `seconds::max()` to a `milliseconds`. Unfortunately `std::chrono` really is meant for human-timescale numbers, afaict; and for those there's no overflow. So like anything else entering your domain, you have to check `std::chrono` for valid/logical/sane values before accepting one from outside your domain of control. In their case, though, by using `max()` to have meaning they've basically allowed any (positive) value to be valid. Note I'm not knocking the webkit folks - they're busy, and I'm sure they have a better grasp on their development needs than anyone else; everyone has personal tastes/feelings and it's all cool.
Not with that attitude. 
No, definitely not. The assignment operators could have been defaulted as well
Is anyone on here who has done this before interested in sharing their experience? It sounds pretty neat
well yes, and even though the compiler is doing all of this, it's still negligible in time vs just a bunch of &lt;variant&gt; uses.
&gt; So why provide a standardized text output? C++ can use native OS API for that and there are certainly Cross-Platform libraries out there that do a better job than the STL. Please don't get me wrong, I think the current standard library has already gone too far, but there's a huge difference between an unordered map, linked list, or vector implementation, which is just an abstraction on top of memory management (and for which the library even provides allocators to eliminate the one source of friction between an OS and the library implementation), and something backed by a device driver like a NIC or a graphics card. Linked lists never change; in that time, every single thing about HIDs (except the first 127 ascii characters), graphics, networking, and physical storage has completely changed. A programming language is not a toolchain nor an OS. Why anybody would willingly conflate these concepts (again, unless forced due to being a VM) is beyond me. If you want a standard and portable networking library, then go for it; just don't push it as part of the language; it will result in some combination of highly leaky abstractions that fail the test of time (possibly seeming sufficient at first and growing worse with age), poor performance (you can't win them all), and increased cognitive load for people who use Vulcan or Posix or other standards who now have to deal with C++ zealots re-jiggering what has been painstakingly forged over years and years of time. Nothing good can come of standardizing networking outside of *possibly* facilitating C++ use in academia, and the cost will be felt in the real world.
Why would you use a global inline variable though?
Well, using +inf for timeouts that don't expire makes sense to me - you don't have write special cases for no timeout. Obviously doing this with integers while changing bases is much trickier. Personally, I agree with sentiment in that thread. Having time base as compile time parameter carries tradeofs (uglier syntax, casts, being able to accept arbitrary precision duration requires templated function, and template creep in project of webkit magnitude is not something to be taken lightly), without many benefits (still prone to overflow). I'd prefer something like CMTime, where ticks and time scale are just regular values. Than again, I'm sure there are people that prefer compile-time based approach.
Yeah, supposed-to-be-C++17-compliant compilers have problems even with a proper support C++14 (which still means they're incompliant with C++17). I corrected the wording in the OP to make it more precise. 
FWIW, lessons learned so far in this regard (going beyond obvious "make the bug report reproducible following respective guidelines"): * regressions are MUCH more easily fixed than new-features-not-working (i.e. if you can demonstrate it did compile ok under previous version - it can help A LOT). * problems arising from invalid code get MUCH less attention than those resulting from valid one (especially with MSVC). * assertions/crashes within compilers are getting fixed relatively easily (there is no need to prove it is a bug). One exception is when the code involved is more-or-less obviously invalid. * problems with compiler refusing valid code are MUCH more difficult, AND require quite a bit of the explanation (we have to convince compiler writer that it is a NON-COMPLIANT behaviour - and it can be very difficult, as quite a few of them - especially GCC - tend to have their own understanding of the language, which is not necessarily coherent with that of developers-using-the-compiler). However, referring (a) to the code being-compiled-ok-by-both-competing-compilers (and OP does has this luxury), and (b) referring to a specific section of the standard MIGHT help. 
FWIW, IF you're looking for a workaround - then a very similar thing can be achieved via dummy templates, as discussed in https://stackoverflow.com/a/27070265 (IIRC it is used somewhere within kscope, and for sure it is working ok with current MSVC/GCC/Clang). 
One example is to have a header-only library (which are a Good Thing(tm)). 
That is because your code is find-and-replace. C++ split find from replace.
Rather, network access is well understood and you can write a good enough library. Audio and graphics are in much more rapid flux, with state of the art changing rapidly. In one case, standardizing current best practices is likely to be of practical valur for decades. In the other, the library will be obsolete before it is published. Possibly having an obsolete graphics API is better than having none; but saying this is the same as having a non-obsolete networking API seems wrong. 
I was a volunteer last year and I'll hopefully be one this year. Going to C++ conferences is great because you meet lots of incredible people and can have long discussions. But going to C++Now is even greater because of the unique audience. It isn't a big conference, but the people who are coming are in the C++ standards committee, Boost Libraries developer, and other experts. Talking with them is just an amazing experience. Without the student volunteer program I would have been unable to attend. I can only recommend it. You don't need to do too much work and get to interact with students like you in addition.
IDK why this has so few upvotes, this guy is quite bright and explains things in a way that is nice. Yes, the stutter is irritating at first, but I think if you go past that his talks are always great.
Just looking at the first example code, I will only say this: be wary of race conditions!
I think many of your downvoters don't understand the meaning of **headless**, and perhaps **"Be useful to most people"**
U can't do both, there will be a data race.
Can confirm. Excellent tutorials and very intuitive API.
Maybe to intentionally piss off one side? I have heard people writing in JS are strongly recommended to use K&amp;R brace style because the language has parsing flaws return // JS automatically appends semicolon here { // some values }; Result: The function returns *undefined* or *null* (don't remember). Lines below return are dead code.
This is the best C++ conference on the global circuit. It's the most exclusive, the most high brow, and the most concentration of experts. It is also the most expensive. I alas cannot justify the cost of attending, otherwise I'd be there every year.
Ranges are quite nice for smaller projects where you need the speed of c++ and the expressivity of composability. I haven’t had the opportunity to really go full guns and use it on a large project yet, but I am certain that I will use Ranges when that time comes. Compile times might become an issue but with Modules coming down the pipe this might not be a problem. Coroutines are very exciting to me but I must admit I’m in a holding pattern until some libraries emerge (Lewis Baker’s for example). To me the most interesting thing in this space is the simplification (elimination) of some state machines and native threads in my code, so I’m actively watching this space.
&gt; IO that can wrap an old-timey FILE or fdes out of the box. So the first thing to call on program start will be sync_with_stdio_and_streams(false)? How about not making legacy support a core "feature" of the new API? If it has to be flexible enough to support your other use cases a desperate user should be able to implement their own broken wrapper without bloating the standard on all possible interactions between the APIs.
&gt; that used debug information to preserve state I have no idea what you are talking about :) and I have a feeling I do not want to know. :) 
You are defining values twice, so it's wrong. 
Oh, I'm fine with not making legacy support a core "feature"... if the core features can accomplish at least as much as the legacy support stuff does. I suppose boost::asio does a better job of that than iostreams does anyway, but a couple of _decades_ of using C file IO because the C++ stuff was inadequate is ridiculous. I suppose I should have just said "Fix iostreams" or better yet, "Properly document boost::asio and replace iostreams with it." Although jumping through boost::asio's hoops just to open and read a file into memory seems like a huge pain in the ass, so I'd probably still end up using C APIs to do it.
Dear committee. Reflection. Please make it work. Sincerely, everyone and their dog.
The most common graphics library on python is surely matplotlib. Having plotting included in the standard eliminates most of the need of python in my daily work 
For what it’s worth, it was a surprisingly portable approach. Our tooling worked with MSVC pdb, and on OS X/Linux with anything that output dwarf. It dumped stack to thread local storage for that particular yield instance, and then returned to a caller way up the stack. It performed well (memcpy isn’t slow) but I’m glad I don’t have to maintain it anymore though. 
It's a good alternative for declaring a global in a .cpp file and adding an extern declaration in a header. Why repeat yourself? 
I practically live and breathe state machines. Do you have links to any examples of how coroutines are used to simplify them?
There is VS for Mac! I’m not talking about VS Code. 
Hmm, you’re right. I forgot the time I wrote this code and then just reuse it from the library. Yep, it’s on the long side. 
Isn't asking "how can coroutines simplify state machines" like asking how printf can simplify formatted printing? Here is someone doing it in python: https://eli.thegreenplace.net/2009/08/29/co-routines-as-an-alternative-to-state-machines basically you turn the state machine into code flow. For an infinitely complex state machine this can resemble spaghetti code; for a simple sane one, it looks like if conditions and while loops and event processing code. Your input stream becomes an awaitable object, and you just write code as if your input was already there. Then you feed your coroutine the data as you get it, and it transitions and generates its own output in turn (it possibly also being awaitable, which permits it to be used as the input to *another* state machine). 
&gt; I practically live and breathe state machines. Do you have links to any examples of how coroutines are used to simplify them? IDK if it helps but a lot of it was c/p from C#(except ugly keywords) so you may like this article: https://www.codeproject.com/Articles/581181/Implementing-a-finite-state-machine-using-async-aw
&gt; Isn't asking "how can coroutines simplify state machines" like asking how printf can simplify formatted printing? Well if I knew the answer to that I'd probably be using coroutines! I've read a bit about them but mostly in the context of toy examples like generators or asynchronous programming. Never drew the line in my head between asynchronous programming and state machines as far as how to design and structure them. 
I use coroutines at work throughout the whole project. Mostly for generators but that is already very useful. That said I'm having quite some issues with Boost::Context (we use Boost::coroutine2). On Windows 32bit we had some weird crashes which we could not solve: https://svn.boost.org/trac10/ticket/13245 . Also on armv7 (Android) we once noticed some stack corruption, which might have been caused by Boost::context. Although I can't prove this since I did not investigate it further... For now we worked around the issues but I hope to have some more time soon to further look into them. That said I'm all for integrating a GOOD stackless implementation into the standard!! I'm scared when I think about Boost::context manually modifying the stack and segment registers, there is simply too much that could go wrong! A well tested implementation supported by gcc/clang would be amazing!
Any idea if stackful coroutines are possible with this TS? I would love to trade fcontext in for native solution, but from what i gathered there was no obvious way to do stackful coroutines. I am still hoping i am wrong though..
Now we need only 8 years for 3.11 to get to all distros we still have to support, 15 for online tutorials to use this and `inf` for this to propagate to existing projects.
I thought boost fibers are that?
Yeah, it got mistriaged because of that mistake! Charlie is a debugger dev lead. He probably saw it and thought the report made no sense, so he'll look at it later. I'll grab it and send it on to my team. 
Just give us some cli option so that we can disable the legacy cruft and actually use *only* the modern features.
Transparent comparison for all containers with 'find' functionality.
&gt; You can use NaN instead, but I doubt the example was made to argue about the magic values. std::optional&lt;double&gt; computePrice(const Item&amp; item) { if (!isAvailable(item)) return std::nullopt; // ... }
They have portable binaries for major platforms (including generic Linux tarball, that actually works) on their website. So no, you don't, because local installing a newer cmake version takes like 3 minutes.
Yeah that's how we do it. Trivial to install
Multiple return statements are allowed in AutoSAR C++14, it gives many examples. [PDF for those interested.](https://www.autosar.org/fileadmin/user_upload/standards/adaptive/17-03/AUTOSAR_RS_CPP14Guidelines.pdf)
Not the full glory of the Python library but at least the primitives to let you launch, communicate with and manage a subprocess... 
This is my favourite conference. It is likely also the only one I'll go to (and/or speak at - if you want to hear the usual unusual talk from me, this is your only chance) this year.
&gt; something I've used it extensively in several projects, and while it's not perfect, it does have several advantages I miss in other time API's. Especially in messy applications with a lifetime measured in decades, the compile time requirements become a boon instead of a burden. I think I used to average about one bug per year that would ultimately trace down to someone confusing timepoints with durations, or incorrectly mixing different units of time. None of that has ever happened in places where we use std::chrono. And most of the perceived downsides of std::chrono disappear once you embrace floating point ticks. You can then, for example, use std::numeric_limits&lt;double&gt;::infinity() for stuff like what it seems they wanted to do in WebKit. And being a proper infinity, it converts and compares across time units without overflow and such.
Sorry about that. And thanks for looking into it!
No worries! I just wanted you to understand the response you got. A huge number of the issues reported to Microsoft are reported by people who don't understand the issue. Those issues become the lowest priority to investigate. Labelling this as a debugger issue was a clear signal that you had no idea what you were talking about : )
Well, we can argue about levels of abstractions all we want, but the algorithms offered by the standard library today work with pairs of iterators, and this sets the tone for "modern C++". I'm looking forward to Eric Niebler's range proposal integration in the standard library.
You forgot that you can now also alias imported targets that are flagged as global. :) 
&gt; Are boost fibers using TS coroutines? No, but I mean I think they are stacful coroutines? Could be I am mistaken, boost has a billion different cool threading libraries. :)
&gt;and `inf` for this to propagate to existing projects. Where I work, we are currently rewriting existing CMakesLists to use the target based commands. In one file I actually included a comment where I wrote "with CMake 3.11 we can presumably replace this with target_include_directories", as the command didn't work properly with interface targets pre 3.11. Can't wait to see if it actually works now! 
Please try the release candidate binaries ( https://cmake.org/download/ ) and report back. 
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/7zqxka/anyone_need_help_with_an_open_source_project/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I actually was thinking about trying it out tomorrow...but since you asked so nice, I advanced the test: it works like a charm! Now all I have to do to include Catch is: find_package(Catch REQUIRED) add_library(Catch INTERFACE IMPORTED) target_include_directories(Catch INTERFACE ${CATCH_INCLUDE_DIRS}) And then just use it like so: target_link_libraries(sometarget Catch) Perfect :)
Hmm, I think this Herbie tool is not perfect: http://herbie.uwplse.org/demo/d2a47baeafea3b14cca75bf0a657e089f001e775.c33faf5941b9514a739d9415b56d8aaa9413fe06/graph.html 1/(1+e^(-x)) &amp;rarr; log(e^(1/(1+e^(-x))))
Do you not make use of all the helpers in matplotlib to drae different types of plots and easily set their bounds and all that? None of that is going to be in this proposal, so you'd have to either write your own or use a library. So again, the pertinent thing to me seems to be fixing the library situation.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/7zr1i7/c_pancake_glutton_begginner_asking_for_help/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Excellent! The feedback on rc1 has been really low compared to previous releases, so it is nice to hear that it is working for people.
What's the problem with specifying the sources through add_library() and add_executable()?
Lets say you have a directory layout that looks like: - lib/ - lib/&lt;arch&gt;/files.cpp you can now construct the a target in 'lib' and then traverse down into &lt;arch&gt; without adding any sources. While before you had to either reverse the order and parent_scope the information or have a higher level CMakeLists.txt know the contents of a subdirectory. This change is a quality of life improvement, that will help people that want a more declarative format.
In the example during the importation of RapidJSON the author had to explicitly set the target property 'INTERFACE_INCLUDE_DIRECTORIES'. Now the example can be updated to be: target_include_directories(RapidJSON::RapidJSON INTERFACE "${RapidJSON_INCLUDE_DIR}")
I was more referring to the fact that there are still people who refuse to use a compiler released this decade.
I use all kinds of help I can find. And a lot of the matplotlib stuff is awesome at helping me. I don't really care if that is in the proposal or not. The professional plots I would show others will still need to be made using software someone else designed to make the data presentable. I just want basic debug features. Instead of printing the numbers on the command-line, I want them printed on commandline/PNG/PDF/whatever. Edit: To be clear, I do not care if the full details of plotting is in the standard. I just hink ut makes sense!
The talk might appear "slow" and the subject simple, but the arguments, one after one, are relentless; good wisdom!
IMHO, the talks starts to be very interesting from 29 min
In my current project I've got two targets which are set up almost identically. What I do is create both targets with add_library(), then use a macro to fill in all the common details. Because add_library() has to have a source file, I include an empty dummy.cc file there just to stop it throwing an error at me. Not having to have that dummy file there just to make CMake happy is better. 
I accidentally deleted my reddit account (for those wondering about the "deleted" account status). I'll try to submit an email at some point this weekend.
I use ranges::view *a lot* in production code. Iirc though this is not part of the TS. As for the rest: what exactly is the rest?
Ah, I didn't notice your ``Catch`` flair earlier...how fitting! I just looked through the Catch github, you're referring to the main CMakeLists.txt, right? I think the "header only" part looses some of its advantages if I include the whole Catch project as subproject...So I'll probably stick to our custom 10 line FindCatch.cmake ;) But your comment (``Catch2::Catch``) reminds me that I'm still not used to namespaces in CMake.
On of the biggest things is that it makes getting the correct include directories/compile flags easier. If you use a static library you will need to make sure it target_include_dirs / target_compile_options the correct dependencies as the consumer does. 
Unless I missed something, "VS for Mac" doesn't even have C++ support. It's a very, very light edition, completely different from Windows VS. Or did I miss something in the last half year?
Very strong argument that if a function needs only public interface make it free. However, I mostly ended up with static functions.
I really don't mind the syntax. Most of the time you're just setting some properties on targets anyway
I see, so then you're not specifying include dirs and compiler options globally
i feel their advertising here may be getting a little excessive
First, thanks for the good bug reports! Second, with regards to this: &gt; [195665](https://developercommunity.visualstudio.com/content/problem/195665/-line-cannot-be-used-as-an-argument-for-constexpr.html) (reportedly already-known to MSFT internally but not fixed yet; OTOH, some MSFT ppl say this incompliance is actually a feature (really?)) Yes, really. I'm backing up JonCaves on this being a feature. Rather, a side effect of another feature (Edit &amp; Continue) that's not going to get fixed. We have updated the documentation for [/ZI \(Edit &amp; Continue\)](https://docs.microsoft.com/en-us/cpp/build/reference/z7-zi-zi-debug-information-format) to note that it causes conformance issues: &gt; The /ZI option produces a PDB file in a format that supports the Edit and Continue feature. If you want to use Edit and Continue debugging, you must use this option. The Edit and Continue feature is useful for developer productivity, but can cause issues in compiler conformance, code size and performance. Because most optimizations are incompatible with Edit and Continue, using /ZI disables any #pragma optimize statements in your code. The /ZI option is also incompatible with use of the __LINE__ predefined macro. Code compiled with /ZI cannot use __LINE__ as a non-type template argument, although __LINE__ can used in macro expansions.
Nothing more misleadingly pointless than an `exists()` method on a file/directory class.
The entry point function is a little non-standard (why not just support passing args through instead of the compiler generated global variables?). Also would be great to get this working with cmake and VS Code examples.
great and clean talk and content. but i feel the presenter is sliding a little bit too often into an "acting" which reduced the overall professionalism a bit. i have 2 questions: a) when my free function is an implementation detail and can be put into the cppfile, i put it into the unnamed namespace. this way it has only internal linkage and can not be called from another translation unit. will this prevent the "put into cpp but it could technically still be called" case? is it uncommend to put a lot of stuff into the unnamed namespace? the talk does not mention it. b) at 26:00 he talks about performance and how the existence of a this pointer prevents some kind of optimization. in this example (which has its roots from another talk in 2015) he is passing the data struct by value and he states explicitly that its not passed by reference. this may allow some optimization. how can i decide when to switch from passing by reference to value? where can i read up on this? 
Because they need to be `wchar_t`s
Why not use `wmain` like desktop? 
But if you're building C++ code for android using the recommended toolchain, you're stuck on CMake 3.6.
This seems imminently reasonable--so I'd expect a lot of resistance.
Except that it defines the behavior signed integer overflow. Say goodbye to your idea of using ubsan to catch subtle signed integer arithmetic errors. I don't particularly mind restricting representations to 2's complement, but this proposal goes way beyond that.
I love this talk. I feel like there is a middle-way. The function overloading arguments combined with templating is pure beauty in my opinion.
How much time is spent allocating coroutine frames?
If you're a non-expert, this probably would confirm an assumption you've been (wrongly) making all along - that integers in C++ must be two's complement. Practically speaking, it would have _almost_ no discernible effect but that doesn't stop it from being mildly controversial. 
Not that this is relevant to the original thread but I think there is a typo in the proposal. I see the word sepantics when I'm pretty sure you meant semantics. &gt; Library solution for two’s complement integers with trapping or undefined overflow sepantics.
Even if it wasn't the original intention, one of the reasons nowadays signed types are prefered is UB on overflow, because that allows the compiler to do the arithmetic on a bigger register if that is faster. How do you do a signed char multiplication on modern hardware, for example?
A few examples: * `((a + b) + 32765)` is not the same as `((a + 32765) + b)` or `(a + (b + 32765))`. * `INT_MAX + 1` is undefined behavior, not `INT_MIN`. * `-INT_MIN` is undefined behavior. * `(int)0xFFFFFFFFu` is implementation behavior. * `(0x1 &lt;&lt; 31) &gt;&gt; 31` is implementation behavior. You can see people get into... interesting screaming matches about this when they write "naïve" overflow checks which are security-critical: https://gcc.gnu.org/bugzilla/show_bug.cgi?id=30475 I've personally fixed a lot of code like this. Here's someone who gets surprised by this behavior: https://stackoverflow.com/questions/7682477/why-does-integer-overflow-on-x86-with-gcc-cause-an-infinite-loop Documented "safe" fixes are often broken (though I'd say compiler bugs hit any solution!): http://blog.robertelder.org/gcc-signed-overflow-trapping-ftrapv-doesnt-work/ The Linux view on this: https://lwn.net/Articles/511259/ EDIT: fix impl-def, should answer past bed time.
UBSan has that for unsigned, which isn't UB: `-fsanitize=unsigned-integer-overflow`. Noise is indeed people's concern, but then any noise wasn't an actual bug :-)
&gt; Specifically, the current wording has the following effects: [lists inconveniences] I think, only the second one is of decent value, but even then, it's trading performance for making some broken code not being so. Weird situation, frankly. I am kinda in the other camp to be honest: why is unsigned effectively specced as being two's complement? That seems like an accident. OTOH, I know, the practicalities of implementing addition/subtraction on a CPU lead to two's complement. Lemme get some popcorn!
Defined behavior on signed overflow.
&gt; Wraparound is what all hardware does (add on signed is literally the same instruction as add on unsigned). One of the two pillars of C++ according to p0939r0 "A direct map to hardware (initially from C)”. No love for saturation arithmetic?
&gt; I am kinda in the other camp to be honest: why is unsigned effectively specced as being two's complement? That seems like an accident. Because modular arithmetic is really useful for some cases, e.g. hashing.
While we at it, can we make char signed or unsigned, I don't care which, so long as it's _always_ the same everywhere!
Just because it's defined does not mean it's correct, does it ? 
I liked that talk there are few things that I didn't understand. I didn't quite get that performance part. Can someone elaborate it a bit more, please ? Why would free function be more efficient than member function in that case ? When do we use member functions then ? Is it the main idea to have class definition in .h file (maybe with all of its private data members hidden using PIMPL), with no private member functions and after class definition come free functions prototype (with implementation is in .cpp), and all "private" free functions that know how to operate on private members are in .cpp file? 
&gt;There is hardware that does not do wrapping overflow though. DSPs use saturating overflow ARM does both, depending on which instruction you choose. 
Shouldn't `find_package(Catch REQUIRED)` automatically attach include directories to `Catch` target?
&gt; - The original reason for UB on overflow was hardware divergence, not bug finding or optimization. Otherwise unsigned integers should have gotten the same treatment. That original reason is now invalid. &gt; - Wraparound is what all hardware does. Nope. By forcing wrapping on signed overflow you have now pessimised using `int` as an array index. The problem is that 32bit (or smaller) types live within 64bit registers, these days. Thus, when you add something to that value it may overflow into the 64bit range. With your proposal an extra *and* would have to be inserted after each instruction. For normal arithmetic that *and* gets replace by different instructions (register names) but for pointer arithmetic things are more complicated. See the following link to a talk by Chandler on UB for a better explanation. [Garbage In, Garbage Out: Arguing about Undefined Behavior…](https://youtu.be/yG1OZ69H_-o?t=39m25s) Great example starting at 39min. 
IIRC there is a proposal for `char8_t`, similar to `char16_t` and `char32_t`. If this gets through, you won't need `char`: use `std::(u)int8_t` for small integers, `char8_t` for UTF-8 characters and `std::byte` for aliasing.
Another embedded guy here. This isn't really about what people in general think, it's about how the language is defined and what the official contract between compiler and programmer is supposed to be. Undefined behavior is a precise term in the language standard with a specific meaning--you may be able to use some of these things in ways that appear to be predictable, and which could actually be documented and guaranteed by your particular compiler, but they remain Undefined Behavior according to the language standard. I've found it very useful to root out and replace all the undefined behaviors in my systems with portably-defined alternatives. This might go against the grain of some vendor-provided libraries or the way things are typically done on a platform, but they get rid of a *lot* of the annoying debugging crap because compilers are forced to behave identically regardless of platform when you stay in that part of the language. It's not always possible, but it's made my life a lot easier to make effort in that direction.
Your fourth bullet point is implementation-defined, not UB
Two's complement is a representation of negative numbers. There are no negative numbers in unsigned arithmetic. So I am not sure what you are trying to say.
Sort of the whole point. Nothing is forward _or_ backwards compatible with char. It's "implementation defined" as to whether it's signed or not. One of the many things I like about D. So many of the stupid "implementation defined" or "undefined" gaps are just closed. It's defined. You can rely on it. 
I suppose this is a bit of a nitpick, but isn't `(int)0xFFFFFFFFu` implementation defined, not undefined behavior, as per §7.8.3? Perhaps not much better, but I can at least be sure that it will do what I expect on e.g. [gcc 7.3](https://gcc.gnu.org/onlinedocs/gcc-7.3.0/gcc/Integers-implementation.html#Integers-implementation) (probably pretty much every other compiler too) and not have to worry that optimizations might break it. 
Don't you mean "_Some_ DSPs can _optionally_ do saturation overflow"?
&gt; knowing what the hardware will do. That's not how undefined behavior works. 
&gt; How do you do a signed char multiplication on modern hardware, for example? In all versions of C++, the operands of such multiplication are _required_ to be promoted to `int`^1, and the result is a `int`^2. On modern hardware no UB can be triggered. I don't think the proposal will change that. ---- 1. or `unsigned int`, when `int` cannot represent all the values of `unsigned char` and pigs fly 2. or `unsigned int`, again when pigs fly
signed chars will anyway be promoted to ints.
Kind of is, though. A basic example is integer overflow. Compilers may consider it undefined behavior but it sure isn't undefined if you understand a full-adder. 
That's definitely a good point and probably wise. I just take certain shortcuts in the interest of more concise code, especially code I'm not worried about ever porting, but ...
The dream of being able to easily use utf8 from C++...
Isn’t unsigned overflow defined behavior?
I never understood why all aspects of the behavior of signed integer type haven't just been implementation defined, rather than UB
So your example isn't undefined behavior anyway (C++ says that unsigned integers use modular arithmetic). &gt; There's plenty of stuff that goes into the 'undefined behavior' bin that works fine if you understand what the **compiler** and hardware will do. (emphasis mine) Perhaps, but compilers aren't required to (and in most cases do not) document how they handle undefined behavior so understanding what the compiler will do isn't necessarily easy. Even if you know what the `add` instruction of your processor does, it doesn't matter if your compiler doesn't generate an `add` instruction (or something equivalent) where you think it does. And even sticking with the same compiler on the same architecture, if you rely on undefined behavior, it might work for some set of flags (such as optimization level) but not others.
The proper solution to that is using the correct type for the array index, not relying on undefined behaviour. Using a 64-bit offset results in shorter generated code than with UB on 32 bit anyway: https://www.reddit.com/r/cpp/comments/7w6vu3/video_arvid_norberg_integers_in_c/du3m46e/
I know, but there are millions of lines of code out there written by inexperienced programmers. With this change their previously perfectly good code becomes suboptimal. So this is a tradeoff from one quirks (UB) to another one (slow down).
If the CPU is doing two’s complement (as opposed to e.g. 1’s), these operations are easier to make, signed or unsigned, doesn’t matter (CPU doesn’t know).
FWIW, as it was mentioned in /r/programming, the idea behind is somewhat similar to CSmith ( https://embed.cs.utah.edu/csmith/ ) - but with C++ in mind and using very different internal mechanics. 
Only if the compiler actually defines the behavior (even if the standard doesn't.) You might not even get to use the result of the full-adder if the compiler assumes the overflow won't happen. And it can assume that, because if it happens, the behavior is undefined.
That would mean I need a namespace for every struct.
I read a lot of disassembly output so I guess I'm overly comfortable with it. Meh. I'm probably being incautious at this point. 
That part is clear. What I can't swallow is the cost of not having every possible function that can be called for an object show up in a pop-up menu once I enter `.` or `-&gt;` when you're dealing with bloated frameworks. I know how dumb that sounds. I'm fully aware. But it's so damn useful and convenient. However, if you're not working with APIs that come with bloated class hierarchies and giant classes, I can see why that's not a huge issue. But if you **do** work with these APIs, where a class has 50 member functions, and there's dozens and dozens of classes with dozens of member functions each, you kind of rely on being able to hit `.` and get those functions right there. This makes the chaos more manageable. If you would "clean up" the API and end up with 50% of those functions now being free functions, suddenly, you're having a hard time writing code. You're constantly looking up the API reference to find the function you need. It slows things down considerably. From a library writer perspective, I do agree with you. You should write small, clean and lean classes with free functions. But from a non-library writer perspective and when you're dealing with frameworks that are hugely bloated, free functions will make things even worse than they already are.
Assuming you meant signed integers, that's only undefined behavior if overflow happens.
I am not quite sure myself, and I am not sure exactly where in the standard to look it up, but is the last point really undefined behaviour? I know UBsan doesn't catch it (https://godbolt.org/g/LDoFmy), but I know that doesn't necessarily mean it is defined.
Yeah I may have misremembered. Sorry. Signed overflow is just knowing how an adder works, really; I have no problem relying on it as long as I'm sure the compiler is putting out the right assembly. 
Why namespace by feature instead of layer?
This is actually two proposals in one. One is "signed integers are two's complement": indeed, I don't know of a machine where they are not. OK, why not. The other is "signed overflow should wrap". Especially when doing DSPs, we have machines with saturating operations and accumulators with headroom, sometimes even with different behaviour depending on optimisation (e.g. saturation only when auto-vectorized). Thus, leaving that aspect undefined sounds reasonable to me.
Indeed. I wish the proposal focused on two's complement :(
This is great! I hope that MSVC udpates their bundled CMake pretty soon. For all other use cases, it's very easy just to download and use the binary from cmake.org, but for MSVC this doesn't seem to be possible as they apply some MS-specific patches and you couldn't just replace their bundled one, so it's a big bottleneck always waiting for them!
Thank God for devtoolset. Easy install and the resulting binaries will run on vanilla system glibc
True, they bundle 3.6 with Android studio for their own support sanity, but you can point to your system cmake. https://developer.android.com/studio/projects/add-native-code.html#vanilla_cmake
The main problem there is that is any of those static libs just have global objects that are not otherwise referenced (think test cases that register themselves automatically for example), the static library won't be linked in AT ALL. So your tests won't be included in your program by default, you'll need special linker flags to force them in. In this case, it's easier to have them all added to the main executable to make sure they are linked in. In CMake, you could also have those libraries have 2 sources, one with a dummy symbol in the PRIVATE sources, and one with an extern pointing to that same symbol, in the INTERFACE sources. INTERFACE sources will be added to all users of the library and compiled within that context. Meaning all users of your library will be looking for a symbol you provide, forcing the linker to link all your tests too!
Yes, unless you specify a contract. With this proposal, you would have to explicitly state where overflow was not allowed to happen.
How many projects actually use `-fsanitize=unsigned-integer-overflow`? Looking through https://github.com/google/oss-fuzz, I could find two (llvm_libcxx and librawspeed), which enabled it. If signed integer overflow were to be well-defined, then it would seize to be a bug, and library authors would be entirely correct in writing code that takes advantage of it. If a library user wants to run UBsan to check their own code for overflow bugs, they have to disable it for all the library code they call into that depends on the wrapping behaviour, which is done on a per function basis. My prediction would be that if signed integer overflow were to become well defined, then the value of `-fsanitize=signed-integer-overflow` would significantly diminish, unless you happen to be in control of every dependency. Also I believe the simplest, most terse syntax on integers should be undefined for overflow, because in general overflow is a bug when working with signed integers. The cases where it isn't are the ones that should stand out either by a keyword requesting wrapping behaviour (which does not currently exist), or by calling a special function that provides it, which is really easy to implement generically (https://godbolt.org/g/ibVktH), and stands out, making the intent clear. Other than that I am on board with making two's complement the standard, as it basically already is de facto, since every major vendor treats the implementation defined parts the same way (as far as I know).
Ah right. Somehow i assumed that `find_package()` was finding a cmake-exported target.
I suspect you'd want overflow to be implementation defined, not undefined. That said, there was a relatively recent proposal for saturating arithmetic. http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0543r0.html I imagine those functions would be implemented by intrinsics that lower to the operations you want.
But new IDEs support autocompleting x.f =&gt; foo(x). Please don't use member functions just because of IDEs
Probably to allow some optimizations.
Pretty sure you are correct there, but he claimed it was undefined.
I think what he is saying is you have it backwards - two's complement is popular because it integrates so well with modular arithmetic. I.e. it enables signed arithmetic to take advantage of modular (unsigned) arithmetic CPU instructions, not the other way around. 
Zero extension doesn’t have to be everywhere, compilers are way smarter than that. If they aren’t, that’s an optimizer bug. The compiler I currently maintain has no UB on signed overflow, supports pretty much only 64-bit, and has no overhead from this compared to other compilers. Also, the proposal doesn’t make pointer overflow undefined. I was at Chandler’s talk. First row. Even made one of the slides. :-)
&gt; Wouldn't implementation-defined be better? If the implementation can say "this implementation defines this to be undefined", sure :) It's been a while. Blackfins have saturating and non-saturating arithmetic, and the saturating ones come in more flavours (parallelizable, vectorizable). Same thing for fused-multiply-add. Thus, in the end it's up to the compiler whether it ends up using a saturating instruction or not. I didn't get too intimate with TI DSPs but as far as I remember they have similar choices in their instruction set.
I feel that this is a question of support from tooling. It would be great if autocomplete tooling could support universal call syntax, even if the compiler does not itself. That way you could still type a . or -&gt; and get the list of all relevant functions. I wonder if any of the tooling vendors have considered this and if so why it is not implemented.
Please point me at specific names of HW that only saturated and supports modern C++. I’ve yet to find some every time someone. Every time someone says what you just did it turns out the HW supports regular two’s complement add (because it’s literally the same instruction unsigned ont uses), or doesn’t use modern C++. 
You let it overflow into the top bits. Only if you shift them down do you need to zero extend, that’s rare and a minimally smart compiler can eliminate zexts. 
“False positive” sounds an awful lot like “not a bug”. Which bugs are we preventing? Should the minority use case be a standalone library class or special operator?
Yeah I wonder what modifications they do. It would be great if they would open source their fork for us to see the changes they make and also so that we can build it ourselves. Also serves to let us see when and if those changes can make it back to mainline CMake.
And you really think that those millions of line of code, written by inexperienced programmers (most likely for hardware being 10 years old) has performance optimizations to the level that such details become important?
As in: https://www.reddit.com/r/cpp/comments/7zsj86/comment/durasi6 I’d appreciate names for those DSP. I agree with Andrew downthread otherwise. 
The paper’s premise is that two’s complement won and all hardware do the same thing for signed addition. In fact, they also the the same bing on unsigned addition: it’s literally the same instruction. So I totally agree that the language is the problem here. 
For example?
Yeah, I like to dream. But that being said, realistically, handling utf8 isn't that much more difficult than utf16/wstring. If your really want to do correct text processing &amp; rendering, you have to anyway deal with things like normalization, internationalization and the cases, where a code point requires two utf16 symbols (or whatever the official name is). On the other hand, simple things like splitting a string on typical characters like `" ",/,(,)` etc. doesn't require any utf8 awareness at all. 
&gt; I was at Chandler’s talk. First row. Even made one of the slides. I am jealous. ☺
It's not unusual when coding for embedded to rely specifically on such behavior to produce faster, more compact code.
1. networking - fk this have been ignored for a long time and a few solutions available are far from perfect 
vim/emacs/vscode(meh).. i stopped using real IDE's long time ago
/u/StonedBird1 is correct: the fact that [Microsoft's compiler has been shipping for 35 years](https://books.google.com/books?id=qURs4j9vKn4C&amp;pg=PA503#v=onepage&amp;q&amp;f=false) is a large part of why it's so hard for us to achieve Standards conformance. (One could argue--correctly--that we didn't prioritize conformance until recently. But the same is true of most compilers: it took a long time for any compiler to be C++11 conforming. Nowadays most compilers have implemented the Standard before the ink is dry.) We have been ["rejuvenating" our compiler for a couple of years now](https://blogs.msdn.microsoft.com/vcblog/2015/09/25/rejuvenating-the-microsoft-cc-compiler/). And in doing so, [we've made significant progress towards Standards conformance](https://blogs.msdn.microsoft.com/vcblog/2017/11/15/msvc-conformance-improvements-in-visual-studio-2017-version-15-5/). We expect to have implemented all the features from C++11, 14, and 17 by the VS2017 15.7 release. It would have been much easier if we'd been able to just publish a big breaking change for conformance. But we can't break existing code. We've had to implement conformance using tricks like a [/permissive- conformance switch](https://blogs.msdn.microsoft.com/vcblog/2016/11/16/permissive-switch/#comments). And so yes, it's taking us a long time to get Standards conformance. But we're doing it, and we're doing it without breaking people. 
[icecream](https://developer.mozilla.org/en-US/docs/Mozilla/Developer_guide/Using_Icecream) and distcc are the ones I've heard of.
If you just want to remotely compile your code on another machine and get back results and errors, then no special build system is needed as such, you just rsync your sources to the machine, ssh into it and run your build script, then rsync the artefacts back. This is my actual setup to be able to code on a notebook but build on a faster machine. If you need full-fledged distributed compilation than you might want to look at Google's [Goma](https://chromium.googlesource.com/infra/goma/client/) (only the client is currently open-sourced) or [dist-clang](https://github.com/abyss7/dist-clang).
I think cannot be done easily because Windows whole core uses wchar_t for unicode. So if they would provide this, it would be at the cost of conversion of all their API calls. Maybe sometime if they change the core of Windows (or another os name) it will be feasable.
Visual Studio supports Linux remote compilation, if that is what you are looking for. 
As I said above I'm hoping that I'm not coming off negative here but in a couple of years it will have been a decade since C++11. As for breaking changes it is debatable as to how much of a problem a publishing a breaking change compiler would have caused long term. Sometimes the aversion to breaking changes are more trouble then actually breaking things.
&gt;&gt; As for breaking changes it is debatable as to how much of a problem a publishing a breaking change compiler would have caused long term. Nobody thinks about the long term. People need to keep their businesses running today.
We are talking about reading command line arguments. Doing a single conversion from utf8 to utf16 once per program execution is negligible (if that is necessary at all - many arguments are not passed to the windows API at all). Btw. a straight forward (i.e. without normalization) translation from utf8 to utf16 or vice versa is generally not that expensive. You don't want to pay the cost at every API call, but most of the time it is just nose. Edit: Also, you have to start somewhere and whenever you are designing a new API anyway, that seems like a good opportunity.
It is already implemented for some IDEs. And I agree, this is for the tooling to solve not the language.
This &gt;doesn’t use modern C++ is an extremely shitty argument. By playing with definition of modern we could disregard anything not x64 linux. Also unless you propose saturation support, then this is a bad argument as well &gt; supports regular two’s complement add "Well, you might want to do A), but because you can do B), we mandate you do B)."
&gt; Should the minority use case be a standalone library class or special operator? I think it should. That's **precisely** my point, actually: **developers rarely want modular arithmetic**. And therefore I think signed overflow should lead to an **unspecified** value. Unspecified Behavior here captures the best of both worlds: - compilers are allowed to optimize based on the assumption that if overflow occur, they can use any value as a result, - static analyzers/runtime instrumentation is allowed to flag any instance overflow as a bug, - yet, a compiler cannot elide an entire run of code because it can prove that overflow will occur. Unspecified Behavior is immensely preferable to Undefined Behavior, yet it doesn't prevent common optimizations and bug-detection from occurring.
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/7zxkao/build_system_able_to_remote_compile_cpp/durlvyt/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I guess in his example the code in the `if`-block relies on that conversion, i.e. it doesn't compile when `T` isn't convertible to `std::string_view`. And then you need `if constexpr`.
Couldn't they technically just have MSVC define the char type as having 16 bits and still be compliant? Then all the wchar_t stuff just fits into a char. I know some embedded platforms have odd non 8 bit char types.
Heh, I guess that would work if your goal is to be compliant. But if your goal is to be compatible with most code out there, I’m afraid it’d be a poor choice :)
&gt; Wouldn't implementation-defined be better? Consider `if ( i - 1 &gt; i ) { /* do smtn*/}`. If you leave underflow undefined, the compiler is allowed to optimize this to `if (false) `. Leaving it unspecified, an implementation has to take a consistent solution, so either wrap-around or saturate. None of this choices allows this optimization.
Does having used Windows Fibers extensively count, rather than the new coroutines library? Stackful vs stackless, but still coroutines.
That's high praise, thanks ! It wasn't easy to write though, I wouldn't want to hurt the people working on 2D graphics.
Saturation is a separate proposal, already under way. 
&gt; Naïve overflow checks, which are often security-critical, often get eliminated by compilers. They are eliminated because signed overflow is undefined. Signed overflow being undefined has led to one of the *few* actually interesting opti, which is not caring about the msb of indexes on archs where indexing require a full-length word to be used, but a shorter signed type was used in the source code. I'm usually quite strongly against exploitation of any random bit of UB for attempts to optimize, but this one is amongst the few that are actually interesting and prevalent in virtually all code bases, so I do expect *extreme* resistance to disallowing this optimization, and for sure merely stating that signed integers are to be coded in 2's complement will not be enough to define signed-overflow in the standard, and given what the language has become, it might actually not be desirable anymore to define it now.
Which ones? I haven't seen this in VS, Visual Assist X, or Re++ yet?
Nice to see some people don't lose perspective over a single benchmark example.
Resharper C++ does this. See https://blog.jetbrains.com/rscpp. They refer to it as postfix completion. Here is a demonstration: https://d3nmt5vlzunoa1.cloudfront.net/rscpp/files/2017/04/FreeFunctionCompletion.gif 
See the other reply. This is already solved by tooling. Example: https://d3nmt5vlzunoa1.cloudfront.net/rscpp/files/2017/04/FreeFunctionCompletion.gif
Yes and no. If the compiler literally optimized such code, it is indeed a programming error that the compiler should report. If it is one step in a long chain of inlining and optimization steps it may be exactly what you want your compiler to do. But yes, I've seen very few discussions with examples, where UB on overflow would allow a really useful optimization. The canonical example from Chandler that everyone points to these days is imho given far too much weight considering the small scope in which it is applicable.
You seem to make the assumption that the compiler does little more than translate c++ code more or less literally into assembler code, but that's not at all what happens as soon as you turn on optimizations.
&gt; Yes and no. If the compiler literally optimized such code, it is indeed a programming error that the compiler should report. If it is one step in a long chain of inlining and optimization steps it may be exactly what you want your compiler to do. It may, or it may not, and it might just be a corner case in some intermediate piece of code that the programmer overlooked. A diagnostic (with options for appropriate code markup to indicate a specific outcome) still sounds like the appropriate approach to me. But then again I have similar ideas concerning many of the cases that the standard classifies as UB (most notoriously, the inactive union member access thing).
I'm not sure if I understand you correctly, but I believe what you propose (essentially listing all assumptions on which an optimization is based for all optimizations) will generate faaaar too much noise.
I don't think this sounds dumb at all. Without uniform function call syntax and autocompleter that can figure out which (possibly templatized) functions are appropriate in current context, this has bound to have negative impact on productivity.
Woooow! That's awesome! Amazing! Might be worth trying to switch again :-))) Last time I tried switching from VAX to Re++ I had to switch back after a couple of days because the auto-completes took like &gt;=200ms (sometimes up to a second) so I was faster actually typing it by hand than waiting for the autocomplete, while VAX completes within unnoticeable, instant time (like &lt;=50ms I guess).
Then stop violating the rules of the language you claim to program in and you have perfectly predictable behavior (modulo bugs in the compiler and it the standard itself). Failing that, you can choose to program in pseudo c++ and turn optimizations of, which will mostly give you what your want or maybe code a different language altogether (I can recommend Ada for safety critical software). That is of course not to say that the language couldn't be improved by changing some of these rules.
A one-liner diagnostic to at least warn about the thing happening would be sufficient, even though of course the possibility to get more information if the user so wish would be nice.
I'd be very curious to know some real-world statistics about how often such situations arises, where deep optimization chains lead to expressions that can only be optimized away due to UB, without any of the intermediate expressions being “critical” by themselves. I doubt they'd be that common.
Indeed. Some hard data on this would be pretty useful. I wonder if one couldn't just rig llvm to produce those statistics and then run it over a codebase.
You could just define `int` to have the same width as a pointer, which is what anyone using it as an array index is assuming anyway.
They're probably expecting overflow at the 64 bit max, not the 32 bit one.
I was part of the first round of student volunteers back in 2013. I got to meet incredible people, some of which I already knew. We all shared one thing; we loved C++ and we loved pushing the boundaries of the language in crazy ways. I learned a whole lot of tricks, but the biggest thing for me was to be immersed in a group of people with interests similar to mine, but who were experts at it. I made friends I still see today and started being involved in the Boost community. Looking back, I can now clearly say that this experience changed my life. I don't know if it'll change yours, but I think it's worth trying out if you're into C++. Big up to the Student Volunteer program, and especially u/blelbach, who started it back in 2013.
wow, now we can stop doing horrible factored designs and start writing whole programs in a single function, how elegant 
What is this talk actually about? The title is nonsense.
I've also come across odd stuff similar to /u/johannes1971 with global inline stuff. For example, if I declare a `static inline` class method, and in the definition include a `static const` variable, that variable can be missing and cause link errors. Here's [a fix I made a few days back](https://github.com/apache/xerces-c/commit/d5cce44617374665e34458aa7cc22654c56e682a). The odd thing is, this worked for years, though the use of a bunch of odd `-G` `cl` options, which must affect how inlined static variables are exported or elided by the linker. It took a while to figure out what was going on, because it didn't fail on every system I tested on. And it worked on all the Unix platforms without trouble. Sometimes I think many of the esoteric `cl` options are more of a hindrance than a help, when I just want sane standards-conforming behaviour by default!
The usual book recommendations about modern C++: Tour of C++, Effective Modern C++, etc.
No, that isn't UB. UB means the compiler can generate any code it wants. It doesn't just have to pass the instruction through to the hardware. When you program in C++ you are asking the compiler to generate code that maintains the contract of the language, you aren't writing some sort of "high level asm". For example, if the compiler can know that the overflow will happen, it can simply remove that chunk of code as an optimization. It could even put in a runtime check to see if it happens and refuse to do it if it thought that was faster. This is why you commonly see people saying that turning optimization "breaks" their code. In -O0, the compiler pretty much does pass through each line of code straight through to the hardware to make it easier to debug high-level logic errors. It's only when you turn on optimizations does the compiler/optimizer really start to take advantage of all the things available to it.
I can ask what my colleagues think of it at Weta Digital (visual effects studio).
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/800j5w/interview_for_a_job_that_primarily_uses_c/dus3w1q/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Hey that's what I used to do! :-) Let me know if you want someone with whom to do a mock interview. I do 3d development now, but I wouldn't need to change most of my typical interview questions. Do you know one of the maths libraries for C++? You'll end up using whatever they use there of course, but the basic structure of the libraries are pretty similar so experience in one helps in the others. Personally I like the GNU Scientific Library which comes with a good number of functions. It's pretty ancient though, you could focus on matrix stuff and use the more modern Eigen. Or you could be super hip and use Blaze. Personally I'm trying to transition to Blaze, but in your case GSL or Eigen would both be solid starts. One exercise I like when learning a new math library is writing little simulations. An Earth Moon Satellite simulation is good fun (but a little time consuming). Rewriting matrix exponentiation is also a good one. Or rewrite some older code of your own. I learned a lot by rewriting some neural activity analysis code in C++. Outside of that it's hard to provide helpful input without knowing more of your background. Edit: out of the basic C++ books I like Effective Modern C++ but learncpp is also a great start
&gt; By playing with definition of modern we could disregard anything not x64 linux. You could, but then you wouldn't be talking about the same thing as everyone else, so why would you..? ;-]
sieze? I'm guessing you mean cease.
But you never know what seemingly unrelated bit of code changing will cause the optimizer to look at some code differently and change what happens in an UB situation.
*off
While it looks that way, I think changing how the main() arguments (which can be modified) is not that trivial and do imply some impact on a lot of API. But maybe my xp with windows API makes me see it more complex internally than it is. So far I don't seem to be wrong, but it's just a very strong intuition based on xp.
honestly, if you can, `tbb` is a really amazing library for doing concurrency. I think it will automatically use both green threads and real threads to maximize performance, and knows about how many cores you have. I think the standard should take some inspiration from `tbb`.
I don't understand who needs unicode handling that much. Isn't it useful only for text parsing applications, which are only an extremely small segment of software written in c++ ? I've never worked in a team who had to handle anything related to unicode.... char* and std::string are always "byte buffers", you don't need to know what's inside.
Well it's not solved for me, because the IDEs I use don't do this.
That's a pretty unprofessional attitude to take.
"Another way to see the same numbers is using a bar chart," Ok, Yes, I suppose that is true. However, does it really need to be said?
Char is the smallest addressable unit by the spcific platform. Changing that to be 16 bits affects a lot of other parts and you can't use 8 bit types anymore, which makes a lot of thing (e.g. networking) more annoying. 
Sometimes it's way more natural to put it in one function. SFINAE always seemed like a hack to me. Like it was not even intended to be used for the things we ended up using it, and a `static if` (which is what `if constexpr` is) would have been way better to express the things we wanted to do. (Not that this applies in this case. Template specialization is one thing. But for some SFINAE stuff, `if constexpr` feels like a godsent.)
Fixing what ain't broke is premature optimization. 
You know, we're hiring. 
I'd love to see an example of this, so that this discussion gets based more on facts than assumptions. Btw.: One reason to make something undefined as opposed to making it implementation defined is so that the compiler can completely optimize certain operations away /fuse them with others without having to consider all possible corner cases.
Wow, I REALLY hope you're not responsible for mentoring anyone. You have an awful attitude AND you don't even understand the words that you're saying.
You should probably go and open an issue with Microsoft, rather than posting here. I only posted here because I felt it wasn't being taken seriously - admittedly my own fault as you can read in the discussion above... 
When folks are asking about a GUI , are they looking for a library that can render to a context in either 2D or 3D or is the ask for a user interface - aka Widget set? There are numerous ways of drawing pixels on a screen, but if you want a basic widget library with the ability to plug in a custom pixel drawing engine that is march harder to find. I've been looking for a widget library like this where I can provide a simple implementation of primitive drawing routines - drawRect, drawText, etc - and it will provide a working UI. 
I started and run the C++Now student volunteer program. What most people don't know is why. When I was 18 I attended and spoke at BoostCon 2011 a few months after dropping out of college. I can only describe it as a life changing experience. The lessons I learned and connections I made set me on the trajectory that led me to where I am today. Over the years, it's been my pleasure to watch the conference have the same impact on other young programmers.
&gt; Now we need only 8 years for 3.11 to get to all distros Just download binaries from cmake.org and use 3.11. If You can't fix CI scripts to use cmake 3.11, just ask your Junior developer. There is no any problem using latest Cmake in your project if You really need it.
Mine was indeed a silly example, [this](https://godbolt.org/g/M7bUKm) is probably more realistic. My point is that if the overflow behavior is undefined, the compiler can assume 'normal' algebra for integer operations.
Why not just use a typed pointer to the actual context object, or at least an ABC? IOW, why is it helpful to obscure the context's type?
&gt; disregard anything not x64 linux What, why the restriction to Linux? Let's add.... Windows, macOS, iOS, Android (ARM64 at least), ... probably Windows Mobile Universal whatever-it's-called as well... I don't have experience with embedded but I'm sure we can add at least half or more of embedded chips to this list as well as stuff like Raspberry Pi etc.
Practically this is quite nice. Requiring the latest version isn't really a problem. Since we require 3.8 anyway, which the outdated distros don't have anyway, we can live with a custom installation. Also I have on pity with systems that use outdated software anyway... However, actually I'd rather see CMake die completely. Maybe it is the *best* build system we have, but I don't believe it can ever be transformed into a *good* build system. The fact that fixing such a obvious stupid bug is a big deal for a new release show the kind of state CMake and it's development is in. How many more versions is it supposed to take to fix the remaining glaring stupid bugs?
In C++ you can cast a pointer to T to a pointer to U and interpret the bytes of T as U. This is only allowed for specific U and T however. One of those is: if U is char/unsigned char/std::byte, T can be any type. See strict aliasing rule for more.
That's a very interesting example, thank you, but I'm still not sure why it couldn't just as well be addressed by implementation-defined rather than undefined behavior.
The doc says desktop and IoT only
[`std::any`](http://en.cppreference.com/w/cpp/utility/any) is probably what you are looking for. It's built into C++17, and [here's](https://github.com/tcbrindle/cpp17_headers/blob/master/include/stx/any.hpp) an implementation for C++11/14.
The problem is that a lot of software was written assuming `int` is 32-bits, notably in C when reading network packets, and therefore "upgrading" it to 64-bits, while perfectly conforming, would have broken so many critical pieces of infrastructure.
You’re trying to do type currying on callbacks. You should look at that topic. Google has a really google callback/closure system that does exactly that.
I'd rather have *unspecified*, so that an implementation is not forced to pick a consistent behavior. With Unspecified Behavior, the only guarantee is that `INT_MAX + 1` is somewhere between INT_MIN and INT_MAX (inclusive); the implementation is allowed to make it *any* value, but it must *pick one*. That is: if (i + 1 &gt; i) { printf("%d", i + 1, i); } cannot output in `printf` two values for `i + 1` and `i` for which `&gt;` doesn't hold. It can, however, replace the check with `if (i != INT_MAX) { printf("%d", i + 1, i); }`.
I'm guessing you are correct.
After thinking about it for a bit I am not sure anymore... One point would be that this could open for a lot of optimizer-dependent behavior, meaning `foo` from my example would return different values depending on how smart the optimizer is, and for real world code this is largely dependent on the context (inlining, code surrounding the mult, etc.)
That sounds horrific, and also very semantically incorrect. Why would an array index have _anything_ to do with "pointer differences" or whatever `ptrdiff` means. Yea of course I know that arrays are contiguous memory and indexing is pointer arithmetics... but the point is by using an array type with indexing, I am abstracting away from that and I don't have anything to do anymore with pointers (which is the whole point of abstraction and value semantics). If anything, wouldn't `std::size_t` be much more appropriate, as well as convey much more semantically?
I see, the limitation of implementation-defined is that the behavior should be defined in a consistent way. [The suggestion here](https://www.reddit.com/r/cpp/comments/7zsj86/p0907r0_signed_integers_are_twos_complement/dusso5b/) is to make it _unspecified_. This might be a compromise.
My utility class can have several types of clients, each with a different type of context. Currently I instantiate a Utility&lt;clientType1Context&gt; and a Utility&lt;clientType2Context&gt; and use each with only one type of client. Seems a waste since the Utility just needs to store and return an object pointer.
&gt; What is more likely: inexperienced programmers get bitten by defined behaviour which is a bug in 99% cases or they catch most of the errors by simple compiler warnings and the rest by special tooling? The tooling and ability for it to be caught doesn't change here, what does change is the nature of the bugs GCC will quite happily do completely bizarre things to your code with UB. What's easier to debug, a signed integer overflow, or the compiler literally applying magic to your code to do something you don't know about behind your back? :P
Thanks. As noted above std::any and c++98 don't mix but I'm coming to terms with void * for c++98 and something with more type safety when c++14 migration is complete. 
You asked for the appropriate **type**, not for the appropriate name. There is actually a proposal to have `using index_t = ptrdiff_t;`: same type, better name. C++ designers, starting with Stroustrup, have recognized that using an `unsigned` type for indexing was a mistake, and wished that they had been using a signed type instead of trying to squeeze an extra bit. `ptrdiff_t` is **the** signed type which scales with pointer size, and therefore with maximum collection size. 
Okay, thank you very much for this piece of information. Sounds very reasonable. That `using index_t = ptrdiff_t;` proposal sounds great... surprised this didn't make it into C++17. But I guess this is C++, so anything can be controversial... :-) Do you happen to have the number of that proposal so that we can keep track of it? I just did a quick Google search and couldn't find it.
How about a struct with the void* hidden inside? You could even make it private with the parts of your code that want to use it made friends.
I really like how he goes through his example and explaining each step of going from one design to another. It's almost reading from a textbook which is about programming basics but as a video XD
This honestly only seems to overcomplicate things, and would require any developer on the project to relearn how to write C++. It doesn't exactly make the code more readable either. Everyone understands factories with virtual make functions, but when you see this type erasure magic it just makes you wonder what the hell is going on. Maybe I'll be more convinced when concepts are a language feature, but for now I prefer to keep things simple.
Byte swapping and saturating arithmetic functions. It'd be a nice-to-have that removes a small amount of boilerplate
But it DOES change. Because the suspicious behaviour stops being a bug. And as soon as you use some lib that relies on it not being a bug than most diagnostics loose all their remaining usefulness due to noise. &gt;What's easier to debug, a signed integer overflow, or the compiler literally applying magic to your code to do something you don't know about behind your back? :P The latter of course. Both may result in similarly broken code but in the second case when you try to diagnose it you know it's a bug when you find it. You can pretty much automate the bug funding with something like UBsan. Also, it's already really hard to make a naive UB bug like `x &gt; x + 1` if you use proper warning levels. Most other cases are actually legit bugs which would likely still break the program even with behavior being defined. They'd just move from code bugs to logic bugs which are harder to find a fix.
It's a neat trick and I get his point, but I don't know if the trade-off in readability is worth it in this case.
I agree. The talk boils down to "world class c++ requires boost", boost can overcome the short comings of the language. As someone who doesn't have access to boost in my project, this frustrated me. 
I haven't watched the talk but with C++17 (and a variety of awesome modern C++ libraries on GitHub) there's really no or few convincing reasons anymore to make Boost a dependency of a project.
If you don't want to use pointers, use handles. Integral values which correspond to indexes into a private data structure. You could reserve some bits in the handle for type information, flags or verification bits.
&gt; Microsoft's compiler has been shipping for 35 years GCC also exists for about the same time (since 84) =&gt; excuse is rather lame. &gt; But we can't break existing code. Neither can Clang, and it is a completely separate codebase, which is 99.99% compatible even with GCC quirks. It serves as a hard proof that it IS possible to rewrite compiler without breaking existing code (another successful example of such rewrite was EGCS which later became newer-and-better GCC); whether it is possible to do it in a commercial environment (with ultra-heavy NIHs, untouchable chunks of code and untouchable teams/people, (mis)features which are deemed to be all-important commercially, etc. etc.) - is a completely different story (though MS itself did go through a major rewrite of MSVC around 94 or so - when they got some key ppl from Borland, though I don't remember the names now). 
That's actually a pretty tough question, possibly tough enough to warrant a couple of papers. My initial intuition was 'any type that's at least as wide as the pointer it offsets'. This would guarantee that the pointer itself would overflow (which is also UB) before the offset overflows, thus making the last a moot point. One possible choice for such a type could be size_t, which makes sense in so far that it is also a type commonly used in the language for representing sizes of arrays and array-like things (i.e. it won't trigger any compiler warnings because of mismatching types in a for loop). 
you could create a "context" class and use it as a base class. then every actual "context" type can inherit from it. the utility class just takes and passes a (possible smart) pointer of type context.
I wondered how he thought he was simplifying anything, but then I remembered him saying he had been involved with boost for a very long time. 
A lot of replies to both Guy's post of my own were about specific wishes people have. /r/cpp has 60K subscribers. It's a long way from the millions of C++ developers worldwide but it's not insignificant either, so I thought that maybe it would be interesting to see what a "popular vote" looks like. What do you think ?
&gt; Nobody thinks about the long term. As (during my dozens of years in development), I've seen most of the companies-I-worked-for, _thinking_ about the long-term, you should obviously mean that "nobody in _MS_ thinks about the long term" - which can be true, but is rather sad. &lt;/trolling&gt; P.S. FWIW, I remember release of VS2003 (or was it 2002?), which was soooo buggy that it wasn't able to compile even industry-standard-at-that-time SGI STL (crashing with now-infamous C1001); that's given that SGI STL was (a) industry-standard (and recommended over hopelessly-buggy MSSTL), and (b) long-compilable with anything-else-out-there-VS6-included. And IIRC, VS stayed generally unusable until VS2005. 
In times of snapcraft and flatpak this shoulf not happen. 
Seems a bit contradictory to use thirdparty libraries from github but not from Boost. What's the difference?
If the other 3rd party libs are also hundreds of megs of compiler-torture-test C++, then there is no difference. But, that’s usually not the case.
Except Boost is a collection of libraries, most of them header only. You only pay for what you use, exactly like when cloning libraries from github
so one of the advantages he mentioned is no more virtual functions. but is the code that gets generated by boost type erasure really better than a virtual function call?
It's much more interesting for me whether certain features were proposed or not. I see `char8_t` but nothing further for actual unicode. Very good to see "Extending &lt;chrono&gt; to Calendars and Time Zones". C++ lacks something like DateTime in C#.
Boost.SIMD was developed partially by a company that used it in its products. Let's just say that they had internal issues, and that at the end decided not to open source it.
The only thing I'm thinking about right now is retirement!!!! Hopefully the economy doesn't collapse in the next three years and my 401K remains intact. Yes an old fart.
The point about considering replacing the factory objects with a callable function made a lot of sense to me. Having a "Provider" function rather than a factory object is easier to work with, and it allows you to pass in lambdas; to me, it simplified the design. The idea of just calling a function to get a value is quite simple. Type erasing the returned object was a lot more questionable to me. It could still be a useful technique, but it seems potentially overcomplicated.
Here is more info on the situation: https://github.com/NumScale/boost.simd/issues/545 TLDR: They decided to make a large portion of the library proprietary, so they deleted all their releases and git commit history with a "sensible subset" of it which is open-source.
There's nothing about `any` that necessitates better than C++98; Boost has had it forever.
things need to happen sequentially, I think the author of `char8_t` (/u/tahonermann) is focusing on that, it's unfortunately poised to be controversial as it breaks some existing code. He is however working on something absolutely amazing, aka full blown, range-based Unicode support (it can also support more encodings) http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0244r2.html
I enjoyed reading [p0939r0, Direction for ISO C++](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0939r0.pdf). I mostly agree with everything that's said therein. Unfortunately, I think the paper will have less than the desired impact.
Just bundle the headers you need. Super simple. Boost libraries are exactly like GitHub libraries. You use what's most suitable. I don't get this almost religious refusal to use Boost.
They've also got a lot of interdepencies between these libraries, so I can't drag out a single one without taking a couple others with it (except in a couple cases). It also doesn't stop boost from being a compiler tortutre test. That's the main reason I stay away from it, it just blows out my build times completely. Still a really robust library though. I'd probably pick it for most industry applications that would benefit from how expressive and powerful the library is. But any smaller companies, or for hobby use, I'd avoid it.
The first point is sort-of that all (sub)libraries in boost are heavyweight because it's an all-or-nothing decision. It's more like a framework actually. Pulling specific headers out of boost is mostly a futile effort. Nobody is talking about a blanket ban.
&gt; We will come back to you as soon as this new version is ready for release. Now the big question is what that means - ready for release for open-source, or commercially.
So it would be OK to say that “in some circumstances signed integer leads to modular arithmetics, but with this optimization level the division by a constant may act as if no overflow had occurred in previous operations”? I don't know, I have a hard time thinking how it could be defined while still allowing the kind of optimizations shown in the `(x*x)/42` case.
I just started using cereal, it’s really good but hasn’t been updated for ages which is a bit concerning.
&gt; Type erasing the returned object was a lot more questionable to me. It could still be a useful technique, but it seems potentially overcomplicated. Not just overcomplicated - it kinda hides performance-impacting effects too. At least if the `boost::type_erasure::any` works the way his [github explanation for it](https://github.com/BorisSchaeling/worldclasscode/blob/master/13%20-%20handmade%20any%20class.cpp) does. Because under the hood it's essentially an `std::any`that exposes a way to invoke a named method on `any`'s contained object. But similar to `std::any`, it allocates a copy-constructed copy of the type on the heap. (well, `std::any` can do a move, but this is just example code) My point is each time his `main()` does `c = TCPConnection();` or `c = UDPConnection();`, it's allocating one of those on the heap. Of course that was going to be necessary no matter what, but now the user of the code can't see that that's what's happening - it's hidden behind boost's impenetrable APIs. Compared to for example providing a function called `make_connection()`, where you can assume just from its name that something is being constructed on the heap without looking into the details.
I was a volunteer what, three times? I know I'm kinda late for you since you already decided, but I'm going to write this anyway, for the benefit of anyone else. The fact that I've been a volunteer three times probably speaks for itself already. The program allowed me to attend the conference before I was able to afford it myself, and I can't really say anything about the volunteering experience without mentioning that C++Now is an awesome conference; very small number of people, all integrating during breaks and dinners (it's hard not to at least speak a few words to every attendee, really); there's always a picnic that only makes the atmosphere so much better. Volunteering itself is also fun, though. There's a bunch of stuff to help with, and it's a great opportunity to meet some of the brightest stars of the community - but also some of the brightest young people that C++ hopes to keep, who are going to be volunteers like you. I can't really explain all this in a coherent manner, but let me just tell you that arriving (late due to crazy weather and a crazy roadtrip down to Aspen from Denver) at a restaurant on your first night and bumping straight into Sean Parent and Bartosz Milewski is pretty out of this world for a first timer. Anyway, Aspen is a great place to be, conference or not. The air is clear and the weather in early May is just fabulous (even though it gets crazy sometimes). Add to that some great people, incredible atmosphere and some really good talks - and you've got yourself a recipe for the perfect week. Doesn't really matter if you do it as a volunteer or not - both are great - and as a volunteer you also get the feeling you've really done something worth the trouble of having your stay paid for by the conference.
It really breaks my heart when I see a paper being 13 years on hold - [[P0934R0] A Modest Proposal: Fixing ADL](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0934r0.pdf)
Eh? http://www.boost.org/doc/libs/1_66_0/tools/bcp/doc/html/index.html
&gt; They've also got a lot of interdepencies between these libraries, so I can't drag out a single one without taking a couple others with it (except in a couple cases). And thank the spaghetti monster for it! I would not like each and every boost library to reinvent the wheel when you have battle tested libraries already accepted into boost. This is not a weakness, but a major strength. IMO.
IMO the biggest problem is the lack of move semantics. Very hard to have good smart pointers there.
&gt; it'll copy a couple hundred headers just for string split. And the problem there is what exactly? A few hundred 1kB files are far preferable to a few megabyte header file. hell, it should be be reasonably easy to collapse all the hundred files to a single header file. 
heh, that's a good point, because he was kind enough to show what `boost::type::any` is doing on his [github example](https://github.com/BorisSchaeling/worldclasscode/blob/master/13%20-%20handmade%20any%20class.cpp), and it sure looks like under the hood it ends up calling `send()` as a virtual. And really, how could it not? The compiler doesn't know what type it's going to be at runtime, at the time `send()` is invoked in his example. (in one of his earlier examples the compiler _does_ know the type, which is why he can avoid the virtual) So no, you get nothing better, afaict.
To be completely honest with you I have no idea what a "math library" for C++ even is. lol, i have absolutely no programming experience except a basic understanding of JAVA up to basic OOD, and a little bit of matlab experience. Basically the job is at a company that produces gambling machines for casinos etc. so i would be doing a lot of programming for random number generation, combinatorics, probability, and statistics. Does that help at all with clearing it up? They only mentioned that it would be a basic assessment but i want to be prepared for it
Just read the Boost peer-review threads. It's full of drama, but explains everything.
http://www.boost.org/doc/libs/1_66_0/libs/dynamic_bitset/dynamic_bitset.html ?
I had made a comment before... you need currying... no ugly dynamic cast.
PEPE SILVIA
Well depending on how you look at it, the advantage of boost is that with a single external dependency, which is available almost anywhere, you get almost all the functionality you want. The other way to see this is as you said: especially the older libraries have so many internal dependencies, which often wouldn't be necessary in c++11 (and particularly 17 code) that it a) becomes difficult to understand what's going on and b) compile time
That was exactly his point: You can't extract individual libraries, because they depend on so many other libraries. So you only can extract big groups of libraries together (most of the time it's a dozen or few dozen core libs on which all others build).
Oh I totally agree - but since this was a talk about generalizing code, using a different design pattern than classic factory methods, I just felt it was worth pointing out the consequences.
&gt; You only pay for what you use, No, you often pay heavily in compile-time for things that are not really necessary if the libraries were designed with a more recent c++ standard in mind. Pick any pre c++11 library and check the number of boost internal dependencies, including transitive dependencies you might be supposed what's getting drawn in.
Many of that dependencies are simply unnecessary. Some could be replaced by standard library facilities and some dependencies are simply unnecessary and where just taken, because it saves a few lines of boilerplate code and ... well .. because it was available.
Sorry, I don't follow
Honestly, I really doubt that the overhead of virtual functions on modern pcs matters outside of hot loops. The main drawback is that it is much harder or impossible to inline such functions. But I doubt any of the other techniques are much better.
In case you weren't aware, there's a new `observer_ptr` in `std::experimental`. You can find out about it on [cppreference.com](http://en.cppreference.com/w/cpp/experimental/observer_ptr), or in [this paper](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4282.pdf). (note: I am _not_ the author, don't know the author, etc. - I'm just a random dude) Unfortunately, the name `observer_ptr` is _very_ misleading. The `observer_ptr` has nothing to do with the well known Observer Pattern, nor the English definition for an "observer", nor the expected C++ const-ness rules one would expect of an observer. Despite its "observer" name, an `observer_ptr` is free to modify the state of its pointed-to resource. It's not an "observer" by any measure. Apparently the C++ committee had a difficult time coming up with an appropriate name for it, and didn't like the current one much either. (from my googling about it) And it seems like a waste of their time to have them debate it at their meetings, and slack isn't a good medium for it either. So... I thought maybe reddit would be a place to poll for an appropriate name. (crazy?) I'll take the results to the slack channel. Sorry for the strawpoll format - I figured having a starting point was good, but clearly someone else might have an even better name choice. So post your own new name if ya got one. 
Most likely, you can implement the relevant parts of any yourself without too much trouble. Essentially a wrapper around a void* with optional dynamic type checking support (and you need to decide if you want to support copy semantics).
I don't see a reason for using inheritance here. What functionality does "context" provide that justified that another data structure, which is probably otherwise completely unrelated to the utility class, inherited from it (instead of just using a void pointer)?
Why not KISS and call it `raw_ptr`? Yes it isn't a simple typedef for T* but it essentially is supposed to behave like one (and I'm actually no fan of most of the member functions, but that's a different topic)
Thanks.
Boost.Hana and Boost.Outcome has very little, if anything, in common. That's why Boost needs to be viewed as a collection of libraries where each library should be judged on its own merits.
TLDR: fwd declarations took 40% off our full rebuild times
Ahh, they're names of some of the sub-libraries, righto.
The point of smart pointers though is to deal with lifetime and ownership. From that perspective it seems like an observer to me. Like a raw pointer but it tells the reader that it's not owning what it's pointing to, only observing.
The video CppCon 2016: “From Numerical Cosmology to Efficient Bit Abstractions for the Standard Library" (https://www.youtube.com/watch?v=PA7oFnarcXQ) describes how the bit library (https://github.com/vreverdy/bit) is much faster than std::vector&lt;bool&gt;. At time 47:27, shows benchmarking on a logarithmic scale. See also 49:14 for benchmarking using STL algorithms.
A raw pointer can own what it's pointing to though, this thing cannot and AFAIK that's the whole purpose?
std::ptr std::pointer There isn't any prefix you can add to the word 'pointer' to describe this class because the word 'pointer' already perfectly describes it. Classes such as 'shared_ptr' need the prefix because they are doing something in addition to providing a pointer.
view_ptr
How is it "observing" what it's pointing to, when it can invoke non-const member functions of the pointed-to object? I don't mean due to error, I mean just as a normal thing. 
We have `shared_ptr` which denotes shared ownership, and `unique_ptr` which denotes unique ownership. Therefore the obvious name for this non-owning "smart" pointer would be `unowned_ptr`, surely?
Thank you!
Value semantics: thinking in value terms, trying to push value-based and declarative thinking at architectural level. The second parts exercises this by showing how to do Unidirectional Data-Flow Architecture / Flux / Redux for C++ interactive apps.
http://www.boost.org/doc/libs/release/doc/html/move/reference.html#header.boost.move.unique_ptr_hpp Not entirely a show-stopper... ;-]
I would take C++ 03 plus expanded standard library ( batteries included ) over any language stuff they added in C++11, 14,17
It's there in the history: https://github.com/senior7515/smf/issues/203 We have 3 users. They just wanted the RPC. The WAL is there and I hope to bring it to life in a different project. We met w/ all the users and asked them if they every wanted to use the WAL work and all didn't care for the filesystem yet. I think it's useful - and to my knowledge one of the fastest WAL impls out there, see this (my blog, so bewarned): https://www.alexgallego.org/perf/toplev/2018/02/08/performance-debugging.html We needed a simpler project because the scope was scaring users away. It was a hard decision, but ultimately, I want the project to survive and all our early adopters didn't care... I think if I package it as a service (like TANK) people would use the service. Let me know if you want to test it on one of your projects, and I'll consider bringing the filesystem back into a different subproject soon. Thanks! 
If I can invoke non-const member functions using get() or operator* can't I invoke delete on it as well ? With that in mind both use_ptr and access_ptr does not seem better than observer_ptr. &amp;nbsp; If only difference between this and raw pointers is the name, then we can just call it std::pointer as /u/cwize1 suggests. 
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
Simple and avoids confusion the most of all the suggestions I've seen here. The only drawback is for auto-complete since it shares a lot of the firs letters as `unique_ptr` (2 and i/o can be easily mistyped).
C++03 over: variadic templates, rvalues (move semantics), return value optimization/named return value optimization, expanded SFINAE (e.g. failing on template types/template expressions), constexpr, noexcept, lambdas, auto/decltype/declval, list initilization e.g. {}, static_assert, override &amp; final, range based for, nullptr, the plethora of library features that are actually cross platform/not a pain to install for ever dev. Alright...
This is something that's great but at the same time can break a lot of code in subtle ways. I think it would make the language better, but there will be pains for the transition.
I also think that C should follow the same rule in a newer version as well.
The standard already allows `int` to be 64 bits, and if you want to be sure about the size of your types there are types that have a consistent suze.
I think you are probably right. I liked the idea/title of the talk and think he did a good job explaining things, but think things fell kind of flat at the end. He didn't claim that the second approach led to a smaller text segment and/or better performance. 
I think some evil people had 32-bit `char`.
Because then, when talking to another programmer, I can no longer say “raw pointer” to mean an actual raw pointer.
https://www.linkedin.com/pulse/serialization-benchmarks-brian-wood/
cmake should work (if you use C++/WinRT) I guess. 
Unowned pointer. It’s likterally a pointer to an unowned chunk of memory. std::ptr sounds like a base class to the entire family. 
More crucially than the overhead is the fact that the state of an object is undefined after it's been moved from, according to the language rules. I think it would be counter-productive to have one specific object in the STL whose post-move state is defined while all the rest of the objects in the whole language are undefined. Besides, there's already the `release()` member function which will do what you describe. If you're concerned about keeping an `observer_ptr` instance in a defined state, just call `release()` on it instead of passing it through `std::move(~)`.
&gt; If I can invoke non-const member functions using get() or operator* can't I invoke delete on it as well yes, you can of course get the underlying raw pointer and call delete; but that would be fatal as soon as the caller also deleted it or dereferences it sometime later. I mean you could also `const_cast` away const-ness from things your API takes in, too, and do what you like. But lying about your function's API kinda subverts the point of documenting it. ;) Anyhoo... just up-vote the comment post for `pointer` and I'll count those as votes too. thanks!
Good point, but I doubt it would be very intuitive to type the middle of a word first. `iq` might autocomplete to `unique` just fine, but it's not obvious.
I tend to use "naked pointer" as well as "raw pointer".
The GitHub for anyone who wants to see the code itself. https://github.com/tahonermann/text_view It looks amazing, really hope something comes out of it. 
&gt; You only pay for what you use If it is one-developer shop - yes. However, with a codebase which is worked on by 100+ devs - then one of them will start using another library within boost:: (the library is already in your source tree, so using it is super-easy, and saying "you shouldn't use it" is not easily enforcible), and then somebody else - another library, and then in no time you'll find your project using the WHOLE boost. 
It seems that you also removed 'many unnecessary includes (for historical reasons, laziness, or naiveté…)'. Did you try to measure the effects separately (of removing the unnecessary includes, and using forward declaration)? 
Yup. I think after only two or three more revisions, it stands a chance of becoming reasonable. :-)
It's surprising just how useless std::string is on its own. I worked for a startup a few years ago who had promised early on they would stay an English only company. Well that changed one day and a LOT of code had to be redone. You can do literally nothing with std::string once you leave the world of ascii.
https://github.com/tahonermann/text_view A current proposal. Looks promising, but no action taken in a while.
Http1 clients are everywhere, but man where are all my http2 clients at :(. Curl + nghttp2 is...ok..not great. I'm not saying this is an argument for a networking ts, but networking in c++ is so far behind.
The state of a moved-from object is not undefined. The pointer types currently in the standard library are explicitly defined to be set to `nullptr` when they are moved from.
I think `std::make_unique&lt;T&gt;` is so common it's worth a special shortcut.
It seems that he was trying to demonstrate a use case for boost type erasure. And while such use cases do (arguably) exist - the example he took is not one of them. Actually, with this-example-he-took and without further context all the implementations (saving for boost abomination which he conspicuously omitted from summary slides under "//Boost.TypeErasure code") are pretty much equivalent, so arguing about them doesn't make much sense. In the BIGGER context, there MIGHT be reasons for type erasure, but for TCPConnection (created to send something only once, no less!) - gimme a break. 
I think std::ptr&lt;T&gt; can only ever be a typedef for T*. This is a different kind of pointer.
Typically, you should avoid negatives, as it tends to easily lead to double negatives once combined with other things. Also, the pointer is owned, just not by you.
Ah yeah, from the standard: &gt; Unless otherwise specified, such moved-from objects shall be placed in a valid but unspecified state. I forgot about the first clause, "Unless otherwise specified", and thought all objects' states were unspecified after moving from them.
gsl::not_null is a fairly unusual beast though, mostly for when using C APIs is my impression?
`ptr_view` ? 
is it though ? both are non-owning references to another object / part of object
For me, raw pointer is a general concept, like an array. I'd recommend *native pointer* vs *std raw_ptr*, just like *native array* vs *std array*.
Functionality wise, I like that Idea a lot, but on the other hand it doesn't transport intend. And the only reason to have this class in the first place (as opposed to T*) is to explicitly communicate the non-owning nature of it.
ptr_view it is, then. 
Problem is that view implies const semantics.
But it's not a general pointer. It's specifically a non-owning pointer.
It's not an unowned pointer (the pointer itself is most likely owned by someone) but at best a unowning pointer. For my taste it is also too long.
What? I was looking forward to a talk from you at CppCon :(
Come to think of it, I don't see the purpose of the class. Apparently it is supposed to behave just like a native pointer but should explicitly show the intent to used as a non-owning pointer, in which case I'd find template&lt;class T&gt; using non_owner=T void foo(non_owner&lt;int*&gt; bar); Much more sensible (the counter part to gsl::owner). In particular, because it keeps the `*` as a visual clue and can be applied without affecting the abi.
I've seen a NonOwningPtr, which obviously is the wrong style for std, but does convey "it might be owned, but not by this pointer". Still negative though.
Agree yes that's a slippery slope. But in my experience the same is true for thirdparty libraries pulled from GitHub. Unless you appoint a gatekeeper the number of dependencies will keep growing.
Did you present that before at a conference, or point to it on slack or reddit? I could swear I've seen most of your points before, almost verbatim. p.s. yeah "cadged" is not a well-known term, at least in the US; most folks would probably think you'd misspelled "caged".
&gt; Unless you appoint a gatekeeper the number of dependencies will keep growing. Sure, there should be a gatekeeper, BUT it is enormously difficult for a gatekeeper to prevent unwanted furniture from being used in the house as long as huge trucks are getting past him under a verbal promise of "no, we won't use anything but this small chair out of this whole truck" ;-). Control at the level of "we won't let checking in 3rd-party code beyond absolute necessary" happens to be much more efficient than "we won't let USE code-which-is-already-in-our-source-tree". The former is easy to see, easy to explain, and easy to prevent. The latter is extremely difficult to see, rather difficult to explain, and next-to-impossible to prevent. 
To spell it out: I should neither need to copy a few hundred 1kb files nor a single few MB header just to split a string (I shouldn't need a third party dependency for that at all, but that is a different story)
wrapped_ptr ptr raw_ptr (ok, that's misleading)
for the c++11 &lt;= part, i came up with the following. u can store a std::function object as a callback in the utility class and give it a lamda with the actual call for your callback with the context: http://coliru.stacked-crooked.com/a/2fbc0c80d38c1277 i dont know if there are utilitys for c++98 to make it this readable and easy
&gt; In our world, it’s easy to find code from the 2000s with explicit heap allocation and no smart pointers, as for example in this [QT4.8 Getting Started sample from 2011](http://doc.qt.io/archives/qt-4.8/gettingstartedqt.html#adding-a-quit-button). Actually, that's still true in 2018 for Qt 5.10: https://doc.qt.io/qt-5/qtwidgets-widgets-calculator-example.html
view_ptr or ptr_view ?
I believe the politically correct term would be: `indentured_servant_ptr`.
Damn, it's based on seastar?
It depends on which *kind* of static variable you mean, as there are multiple types of them. For example class template static variables, specialized class template static variables, non-local variables with static storage duration, non local variables with thread-local duration, static local variables, etc. There's a synopsis in the [initialization page of cppreference.com](http://en.cppreference.com/w/cpp/language/initialization).
If you're willing to live with heap allocated members, you might want to think of converting some things to using the pimpl idiom. That saved us some build time too, since you can basically hide a whole bunch of member types (and thus their headers or even forward declarations) from being seen by users of the "main" class/struct.
It's also about 1) distributing it to clients, and 2) enabling others (co-workers, other open-source developers, interested parties etc in case of an open source library) to get started with the project, compile it etc. You wouldn't believe how many hours I've spent with clients and collaborators to get just Boost working on Windows with CMake. And that's only the people that got back to me asking for help, there must be a lot more that just gave up and left without ever reporting anything. It sounds like a totally trivial thing and it should be. Our software builds on AppVeyor, yet if I reproduce the steps taken there on clients machines, you won't believe how many times it just won't work and won't find Boost for unknown reasons, even though you specify all paths correctly, etc. Both with building boost from source as well as using boost-binaries. I think sometimes it fails because it thinks MSVC's 19.xx versions are incompatible with each other, not sure that's part of the trouble. Since a few months ago, we've got vcpkg, which is a big savior. Yet it is not without its own bugs, and not all clients are ready to use vcpkg. Compare this to finding a neat, self-containing modern C++ library on GitHub to _exactly_ the task at hand, integrating it nicely into the build setup once (as a submodule, some are header-only, most have proper cmake scripts nowadays), and be done with it - and not only you are done with it, but all clients and users / developers of your software too. On all platforms. And frankly 3), if you ever need to extend a 3rd party library with some functionality, or debug a potential bug or something, it's much easier if things are nicely separated into modules, and you don't have complex, intertwined dependencies. Yes, the "C++ packaging problem" is part of the problem but it's not the whole story.
The point of observer_ptr is not as a replacement for raw pointers, it's to document the specific use case of a non-owning pointer.
Is it [this thread](http://boost.2283326.n4.nabble.com/simd-Hardware-support-td4693499.html) perhaps? It sounds like they didn't knew what they wanted to do with the library. Open source it, but only on a x86, make it a Boost library, but also keep a proprietary version with support for niche architectures.
nop_ptr unmanaged_ptr 
&gt; Try using Windows. Your first error is using Windows for anything important. Your second is pushing a workaround for Microsofts crashing runtime behavior into the C++ standard. 
We have std::array, why not std::pointer? I also like std::raw_ptr quite a bit. It seems like the point of this is for documentation purposes, but I'm unsure how a std::something_ptr will aid self documenting code. I think figuring this out would help decide the ideal name.
I applied IWYU as well on our code base, resulting in 30~% savings, afterwards i optimized our precompiled headers saving 50~% on compile times. Final result is about a 3x speedup. Really pays of to invest some time here.
It's a little more complicated than that with Qt, because (for Widgets at least) you have the parent-child ownership model where widgets are owned by their parent widget. For GUI code, this is probably the best way to go, which is why while smart pointers should be used in most cases, they shouldn't be *mandated* in all cases.
A raw pointer is a non-owning pointer. Also, if standardization is important std::raw_ptr would match the current scheme better than anything else suggested so far.
starts_with is C++20
Agree, std::ptr sounds like it could be an owning pointer.
&gt;The purpose of observer_ptr is to make that convention more explicit. Oh... well the answer is clear: std::stupid_ptr , jk jk
What about std::naive_ptr ?
Amazing. Modern C++ is easy-peasy for application writers, but redonkulously complex for library writers. These improvements are very very welcome.
Only recently did I learn that forward declarations are prohibited by the Google style guide!
I can get an extended library via GitHub, boost, qt etc.. I can only get a small part of the language features in any other way than using a newer c++ standard (for some you can of course find macro / tmp emulations)
Is there a reason you went only to c++11 and not 14? I understand that c++17 can be considered to be and lacking support, but wouldn't it make sense to get as much advantages as possible out of such a break?
I suppose I could have, but I did not because it was more efficient to do both while I was already going through the headers.
&gt; you can choose to program in pseudo c++ and turn optimizations *of*
Thanks. Fixed
Yeah, I thought that would be an interesting point of discussion. It's been my observation that a lot of teams "use" some version of the Google style guide, so other devs should be aware that they may see some pushback if they want to go nuts on fwd declarations like I did.
Thanks for the comment. Your point about PCH is very interesting to me because that's one of my next efforts! The project's automated build has been a full clean and rebuild for about a year now, and as such, PCH only serves to slow things down so they've been turned off. Eventually I'll get the project back to nice incremental automated builds, and doing PCH right is very important (esp with large parallel builds given the memory bugs MSVC has)
Why does the implementation of `optional` need to be so complicated, and why is an implementation like [this one](https://github.com/mawww/kakoune/blob/master/src/optional.hh) not enough?
After reading that implementing `optional&lt;T&gt;` is extremely difficult to implement correctly I wonder how the Rust code looks, well, it's [extremely simple](https://doc.rust-lang.org/src/core/option.rs.html#159-166) (4 sloc). PS: No, I don't hate C++ and no I'm not a Rust fanboy. I'm just interested in many different programming languages and read stuff all over the place, so please don't flame me for the above comparison :)
It's because rust has "sum types" as a standard language feature, and C++ does not.
It's time we move some of the vocabulary types to the language. Like enum class
I've been calling this a weak pointer.
And it takes [hundreds lines of code](https://doc.rust-lang.org/src/core/option.rs.html#172-1203) to implement all the methods. Rust's `Optional` has much more methods than C++'s `std::optional`, so that's not comparable.
&gt; "view" is already a thing in STL. ie string_view, with others to follow, and this pointer is unrelated to that. no it is not... string_view is nonowning view into a "string" view_ptr is nonowning view 
&gt; It also gives us the ability to constrain functions that we previously were not able to constrain at all. Most relevantly in this case, like the special member functions. We need optional&lt;int&gt; to be copyable, but optional&lt;unique_ptr&lt;int&gt;&gt; needs to be non-copyable, only movable, and optional&lt;mutex&gt; needs to be neither copyable nor movable. Today, the way to implement that kind of functionality is through indirection: we inherit from a type that has each special member defaulted or deleted based on the characteristics desired. It is possible to constrain special member functions using `enable_if` with an integral template parameter with a default value, isn't it? Porbably requires explictly deleting the compiler-generated special member functions however.
My condolences. IIRC vs2013 even had many problems with c++11 but maybe they got fixed.
ref_ptr?
Which is a horrid design error inherited from C. We have std::byte in C++ now, designed to replace char in a lot of low-level situations, and std::char8_t, 16_t and 32_t for unicode characters/strings, but the standard still requires "char" to be the smallest arithmetic type. But I guess, we're now free to not use it?
Yeah
Mathieu is quite right, many of the Modern C++ features were already even possible in C++98. Back on my C++ dev days I always pushed for RAII, iostreams as safe IO, std::vector, std::string, references and all the nice features available on the standard library. Even MFC already had smart pointers, at least for dealing with COM. The biggest issue was fighting with devs that insisted in using C++ as plain C with C++ compiler, or having to wrap those libraries that only had unsafe C bindings 'cause C++ can anyway use them directly. The latest example of this way of thinking are the NDK C APIs, which are actually written in C++.
I believe QScopedPointer is similar to unique_ptr, at least how they both delete the underlying object once you leave scope. It does seem like Qt has their own version of everything. 
Yup. In no particular order: - No constexpr - No user defined litterals - No =default on move constructor &amp; assign - Couple issues with chrono and duration_cast - Expression SFINAE only works in some cases
This... this is actually easy to implement in clang at least. Do you have any particular compiler in mind? I could put a patch up somewhere if you promise to actually use it 😁. 
But how? `#include` is basically preprocessor-time copy-and-paste. Undoing copy-and-paste can be more difficult than first glance. Removing visible name would require recognizing those name first. That is beyond preprocessor and become the land of compiler proper.
We've made it easier for ourselves: coroutines are not reentrant, and in any given thread there can be only one. They store their state in TLS and the allocation cost amortizes to zero :)
Yes, unfortunately it's for .Net development only and doesn't support C++. And yes, it is a different thing than the flagship VS. For .Net development, VS for Mac is quite nice though.
You can already achieve some of that by defining the header guard macro matching the header you want to exclude. It's not pretty, it's not modern. But when you are working with old headers, you shouldn't have high hopes for any of that anyway. I had to do that once to exclude some Apple headers that would have conflicting macro definitions in their &lt;Debugging&gt; header (or something similar).
This is something different. I want to include that file, use it's names and macros, then exclude it to avoid others being polluted by what they do not need.
Also worth noting is that Option&lt;&gt; is heavily special-cased by the Rust compiler. For example, "Option&lt;T&gt;::None", if T is a pointer type, is represented as a NULL pointer.
`C++` needs more `static`!
If you can un-define all names at the end of the header and it will still compile, there is no reason for them to be there in the first place, as it means they are not referenced from outside your header. Put implementation-specific stuff into implementation compile units, not in the public headers.
Our include directories are not part of the include name. E.g. To include a file from a project called core with a header named mystring.h we just type #include &lt;mystring.h&gt; instead of a more sensible convention to use #include &lt;core/mystring.h&gt;. To mitigate this we order includes per project and put a comment which indicates the project from which the group of includes originates. Iwyu simply sorts on include names and ignores this convention.
`observer_ptr` is not read only.
honestly, I would much rather `use namespace std;` every time in function scope when I use `std::operator&lt;&lt;` than have ADL. This would make a lot of stuff clearer and more explicit.
Why? 
Templates *have* to go in the header file.
It's no good. Even QScopedPointer will double-delete. This happens when the pointer has already been deleted by the parent and the smart pointer goes out of scope afterwards, at which point it's deleted again.
Instead of sprouting "nonsense" go make something useful that is not unbelievably ugly. 
I know that feeling. I'm always sad that we just can't do this: namespace internal { #include &lt;Windows.h&gt; }
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/80dnio/beginner_question_what_are_pointers_and_why_use/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Templates can call non-template functions which do windows-specific stuff, they are not a reason to incorporate Windows API as part of your public API.
&gt; cmake path/to/project -DBOOST_ROOT=c:/boost_1_66_0 Then let me tell you that this is exactly what works on AppVeyor and for some random, unknown reasons, does not work sometimes, on some of the systems. And we've encountered that regularly. And even in the end when we get it to work it's often not reproducible and we don't know what caused it not to work in the first place. Yea it's probably user-error and some configuration mistake on the system, some PATH setting or whatever, but there is some peculiarity to Boost and/or its CMake or FindBoost.cmake script that makes this very unreliable. I'm very happy for you though that it seems to work 100% of the time for you... I wish it did for us.
As I remember Herb Sutter wasn't a fan of `enum class` either and has criticized as bifurcation of type system in C++.
You can define `WIN32_LEAN_AND_MEAN and `VC_EXTRALEAN (the actual #define may be slightly different — I'm going from memory and can't confirm the exact definitions at the moment) to exclude a bunch of stuff from &lt;Windows.h&gt;. You can then import any additional headers you actually need. 
You can opt out of some bad behavior of this one header file, but even with just windows.h you still have to be careful of other libraries not opting out of its nonsense. Include something that include windows.h and you can still end up with macro min and max.
Yes, you are right that manually deleting something after it's parent is deleted will result in a double deletion crash, however it seems like you are mixing and matching ownership models here. If I'm going to assign a QWidget a parent in Qt, then I don't need a smart pointer to that QWidget. I can just rely on the destruction of the parent to delete the children. If I don't have a parent to my object, then I need to start worrying more about who owns this memory, and different flavors of smart pointers may fit the bill. In regards to Qt documentation, I agree for a newbie that is just copy and pasting examples, it can lead to bad habits. But I was just reading a similar thread on here about using a graphics library that pointed out the purpose of documentation isn't to show people how to write the cleanest code in the world. The purpose is to show an example of how to use the API that they are documenting. It is up to the author to understand their own object ownership scheme and make sure you write code that isn't going to leak or crash on double deletes. The documentation is just showing an example of the class they are trying to explain. 
&gt; If I'm going to assign a QWidget a parent in Qt, then I don't need a smart pointer to that QWidget. That is not correct. QObjects can be reparented, or unparented. And many times, this is a normal thing to do. They can also be deleted before their parent, which must be done manually if you're not using a smart pointer (otherwise you end up with a leak that lasts for as long as the parent is around.) Also, `make_unique` has some additional advantages when it comes to exception safety that you don't have with raw `new`. You do need smart pointers in Qt, just like you do in most other cases. The parent-child model of Qt is not adequate.
I'm agreeing with you that smart pointers can be helpful in Qt. Can you give an example of when I'd want to reparent or unparent a QObject multiple times in it's lifetime? I haven't had to use a mechanism like that in my last few years of using Qt, but I'm all for understanding why someone else would want to do that.
But then `whose_ptr` is it anyway?
Off the top of my head, merging the contents of two widgets comes to mind. Or splitting a widget into its own window. Stuff like that.
I would expect a view_ptr to be a pointer to a view, not a view itself. Maybe we could just make a generic `view` ? But then I think people would expect more interface than what smart ptrs have.
At least for now. That might change with Ranges.
This is why you should go to C++Now.
Like the famous &lt;Windows.h&gt; #define min/max? ;-) You don't have control over that. (I mean you do, with #define NOMINMAX or whatever their macro is, but that's beside the point).
Yes, I have slides that are similar. github is basically where I keep my notes. The part about "warning signs" is the newest piece.
Also, most of those lines are documentation.
&gt; Your first error is using Windows for anything important I normally don't use Windows. Not out of my own choice. &gt; Your second is pushing a workaround for Microsofts crashing runtime behavior into the C++ standard. The standard does not *require* this to work. This is a problem. Microsoft's implementation doesn't do what the standard doesn't require, which is completely reasonable.
Not only weird but wrong. I've seen it too many times before on projects so I feel your pain.
In the case of merging two widgets, it doesn't sound like you have to unparent them to perform that operation. Just make your new object with data from the old ones, and delete the old objects with something like QObject-&gt;deleteLater(). In the second case of splitting a new widget into a new window, you don't have to unparent to do that. You can set a Qt::window flag to get that behavior. According to qt documentation here: http://doc.qt.io/qt-5/application-windows.html, you usually only want your main application to have this behavior. So while you can get yourself into trouble if you unparent/reparent a bunch, I haven't personally come across this need in my day to day. If I do need to delete an object before the parent is deleted, then yeah I manually clean up after myself. However, since I 99% of the time assign objects to parents and don't move them, I don't try to manually delete objects those objects after the parent is deleted and I avoid double deletes. Therefore back to my original point that you can use Qt's smart pointers as long as you are careful with object ownership. 
What do you mean with wrong in this context? One reason i can think of is files with the same name being ambigious. We just don't do that, but i agree it is really annoying. Especially because the only thing you safe is typing the project name in the include, all the rest will be easier.
&gt; You can do literally nothing with std::string once you leave the world of ascii. This is largely OK, you literally should do almost nothing with strings in most cases. Read them, write them back. Once you start doing text processing you need a lot more than primitive std::string methods, but the string storage itself should still be OK. 
And two times the generated code bloat from the hack of an abomination that is std::variant.
There is still some macro nonsense that is unavoidable afaik. Like `GetClassName` becomes `GetClassNameA/W`. This can cause linking issues.
Some partial specialization? class util { void f(void* context); void *g(params) { returns context } template&lt;class ctx&gt; ctx* g(params) { return static_cast&lt;ctx*&gt;g(params); } } 
I don't understand why the pointer to member function class-type example won't compile. Doesn't this do the trick? template &lt;typename T&gt; struct member_pointer_base; template &lt;typename T, typename U&gt; struct member_pointer_base&lt;T U::*&gt; { using type = U; };
Raw ptr vs raw pointer. Duh.
The power of abstraction and objected oriented design. That's what happens to your static variables.
peeper_ptr or, nullywut_ptr
rented_ptr, then? ;-)
That's interesting, but I think you may have strayed even further from the point of this post.
Oh; did you have to dash my hopes :'(
&gt; The standard already allows `int` to be 64 bits, Isn't it exactly what I said? Doesn't change the fact that it would have broken a lot of software out there.
You only use `GetClassName` if you explicitly support end user configuration of Unicode and ANSI builds. If you support Unicode only, always call `GetClassNameW`. If you support ANSI only, always call `GetClassNameA`. Or if this is tl;dr; just always write out the `*W()` form for all Windows APIs all the time.
Totally agree. You can do a nice modern C++ code with 98/03 versions, a far cry of what can be seen in too much places around the web. As I once read somewhere one of the biggest problem C++ has is the way it has been taught. C with cout and classes it is still common unfortunately.
Or, just include the very specific Windows headers you actually use. That didn't used to work well due to inclusion order being important, in recent Visual Studios it's become usually viable.
I am undecided but I think that Herb Sutter (based on his participation in the metaclasses proposal) maybe wants to make the language more capable of being compile time extensible to simplify all forms of vocabulary types and make them able to fit various scenarios without burdening everyone with all features.
Of course it's different, but at least you can limit what kind of macros and symbols are propagated by some header that includes too much that way. Don't forget, the preprocessor is just a TEXT processor, it doesn't know much.
Note that the replication is already in the standard as of C++17.
If the committee can agree on that, this would be my prefered name. 
I’m skeptical of the application vs library developer dichotomy. I’ve heard it banded around a few times, but I don’t really buy it. In my experience, any non-trivial application needs some form of application-specific abstraction, which you could argue becomes “library” code. I think we all write library code. Some of us also write application code too.
The [derive line](https://doc.rust-lang.org/src/core/option.rs.html#157) above the type is also interesting in that it is basically the equivalent of all the copy/move stuff, the `&lt;=&gt;` comparison stuff, and also pretty printing and hashing.
Write a generator of (color, tick) that consumes an awaitable (sensor, tick) stream. Write a generator of (color) that consumes an awaitable (color, tick) stream and guarantees you only see transitions. Write a generator of (sensor, tick). Write a generator of light control signals changes that takes an awaitable generatormof colors. Wire the four together, get a generator of light control signals. Connect hardware at both ends. Seems to make sense to me. 
std::ptr
As of [semi-recently](https://github.com/rust-lang/rust/pull/45225), it goes even farther than that. The compiler will take any range of invalid values in any enum's payload and use that to store the discriminant. For example: * `Option&lt;bool&gt;` is only one byte, because it can use `0`/`1` for `Some(false)`/`Some(true)`, and `2` to signify `None`. * Likewise, `Option&lt;Option&lt;bool&gt;&gt;` is still only one byte, because it can use `2` for the inner `None` and `3` for the outer `None`. * Your own enum, say `enum E { A(bool), B, C, D }` is *still* only one byte, because it can use `2`, `3`, and `4` for `B`, `C`, and `D`. * `Option&lt;char&gt;` is 4 bytes, because it can use an invalid Unicode codepoint to signify `None` (Rust `char` is 32 bits and always a valid codepoint). * In Rust, empty types can be zero-sized rather than a single dummy byte, and empty enums (i.e. `enum Nothing {}`) have *no* possible values and so are "less than zero-sized." So `Option&lt;Nothing&gt;` can thus only ever be `None`, which means it can be zero-sized.
The approach I ended up taking is that an unrecognized /foo option is treated as a positional argument instead of an error. Unrecognized dash options are still treated as errors. And the -- flag can be given to cause all following inputs to be treated as positional arguments.
Partial specializations cannot have default template arguments - and even if it could, it would deduce `FunctionType` directly (ignoring the default argument), and not deduce `C`, `ReturnType`, or `ArgType`. Did you run your code through a compiler?
As an application writer I've certainly very very very rarely have to write as sophisticated code as what's necessary for std::variant or std::tuple
I am most excited about "Deducing this". http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0847r0.html This will address one of the biggest warts that ordinary programmers run into in writing classes.
I think the name is quite fitting, but maybe `view_ptr` (in relation to `string_view&lt;..&gt;` und `array_view&lt;...&gt;` would be more consistent.
Does it? The GSL defines `array_view&lt;...&gt;` which does not have to be const. 
My apologies! For some reasons I thought I was using default arguments while it was another parameter without the default. I wonder if there's a name for this...
Where did you get that from? I thought that class was renamed to `span` a long time ago. IIRC that was done exactly as a result of a discussion with some committee group on that topic. IIRC the people behind the gsl where not too fond of that naming scheme either, but conceded to the committee's advisement. 
For different compilers, use toolchain files, and create a different build directory for each one. 
but no other standard library class follows this scheme: `std::unique_ptr` is not a ptr to something some `unique` class, `weak_ptr` is not a pointer to something weak and while `shared_ptr` is pointing to something shared that is not a property of the class we are looking at but again of the pointer. In particular, the full name wouldn't just be `std::view_ptr`, but e.g. `std::view_ptr&lt;Foo&gt;`, which - for me - says quite clearly something to view a `Foo` object.
A very good tutorial: https://pabloariasal.github.io/2018/02/19/its-time-to-do-cmake-right &gt; compile with many different compilers Generate multiple build directory with CMake directly, for example `build-gcc/` and `build-clang/` &gt; compile with different external libraries find_package(pkgname REQUIRED) The command above will find all external library, even libraries locally installed for the specific project. In fact, you can setup a directory where you install all libraries not provided by your system: list(APPEND CMAKE_PREFIX_PATH "${CMAKE_CURRENT_SOURCE_DIR}/extern/") When installing a library (using make install or similar) set the installation path to your project's `extern/`. If your library don't export it's target, then write a `findxxx.cmake` file. Read https://pabloariasal.github.io/2018/02/19/its-time-to-do-cmake-right/#if-you-want-it-done-right-do-it-yourself &gt;* compile only a single executable out of 100s That depends on the target build system. Usually it's supported out of the box. On visual studio, simply right click on a single project (or CMake file) and build it. On Unix flavoured OS, most likely `make tagetname` will work. &gt; compile in release, debug, static, debug-static etc... Again, generate another build directory like `build-gcc-release/`. You can control the profile with `-DCMAKE_BUILD_TYPE=Debug`. But again, use many build directory. Some IDEs can manage those build directory themselves. &gt; easily add new executables add_executable(exename &lt;source...&gt;) target_link_libraries(exename PUBLIC &lt;dependencies...&gt;) Read more [here](https://pabloariasal.github.io/2018/02/19/its-time-to-do-cmake-right/#model-dependencies-with-target_link_libraries) and [here](https://rix0r.nl/blog/2015/08/13/cmake-guide/#program) &gt; compile with different flags for specific systems(cxx11 vs cxx17 vs cxx03 etc..) set(CMAKE_CXX_STANDARD 17) #set(CMAKE_CXX_STANDARD 14) #set(CMAKE_CXX_STANDARD 98) Read about that in the [official reference](https://cmake.org/cmake/help/v3.1/prop_tgt/CXX_STANDARD.html) &gt;Almost every implementation I've tried always ends up with a rabbit hole of nested `cmake` files with corner cases for every damn option, and being extremely tedious to debug... I usually have one `CMakeLists.txt` by module, and I use `add_subdirectory(...)` for each subdirectory that end up containing a module. To setup options for your project, use [`option`](https://cmake.org/cmake/help/v3.1/command/option.html) If the option is a choice, read [this blogpost](https://blog.kitware.com/constraining-values-with-comboboxes-in-cmake-cmake-gui/). And [this tutorial](http://blog.bethcodes.com/cmake-tips-tricks-drop-down-list)
I think you're demands are a bit weak. I would have asked to be serenaded.
Damn! It's cool and uncool. cool: all the goodies of seastar is prolly inherited. uncool: Seastar will be tedious to compile at first (I've done it). Gosh! I had to use at least 16GB RAM to compile.
I'm pinning this for a few days for visibility. This feedback will be really valuable to the C++ committee and the C++ foundation. It shouldn't take long to fill out!
In the same vein as `slave_ptr`: `secondary_ptr`, because there needs to be some kind of other, primary reference to that object. Or `link_ptr`, because it is just a link to something as opposed to actually guaranteeing that it is there. Maybe even `std::dangling_ptr`? I also thought of `ephemeron_ptr` (https://en.wikipedia.org/wiki/Ephemeron), but that would kinda indicate a pointer that keeps the pointee alive (only) when another one points to it.
subordinate_ptr unowning_ptr secondary_ptr aux_ptr 
Skynyrd_ptr because it is free as a bird
I think you can pin it even longer. This is very important and I will completely miss it otherwise. Thank you isocpp.org for doing this surveys. I think it is very important to get feedback from the wide C++ community.
I did follow up and googled type currying and even found the Google callback code, but I'm afraid I didn't quite follow it and was concerned from a KISS point of view. I'll try again 😀
You can also look into unity builds, putting everything into one big compiler invocation so that intermediate results don't get thrown away and re-compiled. It might cause issues with macros, though. You could also try not using such a slow to compile language. /s
Isn't there an alignment issue with your static cast. Void * are ok to point at any address, but other types must point to appropriately aligned addresses. So the static cast is undefined behaviour??
Euh... not for static cast? I think? Reinterpret, yes, static, from void\*, no.
C++ takes a while. Seatsar is pretty good these days. About 10mins on my laptop. But don't see the issue, incremental builds are fast ~2secs. The client and server are more modular than the default seastar RPC. It is based on Twitter's finagle and Facebook's wangle ideas. 
This is a great idea. Reminiscent of module systems where you must import anything you use everywhere you use it (auto-excluded). I know this isn't really the place to talk about it, but can anyone sell me on C++'s text-oriented include system? I've been working professionally in C++ for under a year and it's driven me crazy. 
The survey lists structured bindings as a C++14 feature, when they are in fact a C++17 feature.
One thing that we got bitten by recently at work with VS2013: No magic statics. It compiles, but isn't thread safe at all.
I'm partial to `leaf_ptr`. Of the names already mentioned ITT I also like `borrowed_ptr`, `unowned_ptr` or `ptr`.
What is the deal with question 11? Where is the "no/none" option?
On most compilers, you can use compiler hints (like `__assume`) to add additional constraints to operations. Very useful if you wrap it into a strong type class, and get get you more optimizations.
The way I implemented it a long time ago was to rename all the symbols, including preprocessor symbols, with a prefix that cannot be uttered - say `@1` or somesuch. A coworker who used to hack (reverse engineer, not work at MS) on VC++6 made it work there - but he further mangled the symbols instead of prepending, so as not to change their length. I don't believe that I have the .exe of the loader/patcher that he made, but essentially it was a front-end replacement that would hook loading of the preprocessor and the front half of the compiler and patch them with "modifications" on load. It actually worked very well, we clung to vc++6 much longer than warranted just because of that one feature and the big heap of code that depended on it. It was a royal pain to get rid of it.
&gt; can anyone sell me on C++'s text-oriented include system? It's kinda necessary for it's memory model. Classes are value-based rather than creating everything on the heap. At first stages of C, it was very useful depending on the target.
The problem is that you don't know what namespace to include in generic code because a type might have its `operator&lt;&lt;` in namespace `foo` and not `std`.
While I haven't dug around in the source to confirm, IIRC gcc won't read the profile data files without -fprofile-use.
Interesting. I will try it out and report back.
I would not recommend decomposing the pointer-to-member type all in one go as you do in your sample code. There are lots of different parts to decompose here, and you've missed (at least) three of them (the *cv-qualifier-seq*, *ref-qualifier-seq* and *noexcept-specifier* on the function type). Handling all of those cases would require quite a lot of duplicated code. Generally, I'd suggest you first split off the class type from the pointer-to-member, and share the logic for handling a function type between the two cases. You can match a pointer-to-member very easily: template&lt;typename Class, auto Class::*F&gt; class Foo&lt;F&gt;;
What if the Windows-specific function implementations need to use templates? I don't understand how you can avoid including the Windows headers in that case.
My thoughts too. While something like meta-classes would be *scary* for me as a application developer, it gives library developers a huge flexibility. Honestly I cannot imagine how they can be NOT confused in presence of meta-classes. There are just too many possibilities. 
This is a manufactured "problem" if I've ever heard one.
They should have added a "favorite features" section to see what people really liked in the last revisions.
These special member functions must be non-templates, so SFINAE does not work. No, deleting them does not work: it will render `void f(std::optional&lt;int&gt;&amp; a, const std::optional&lt;int&gt;&amp; b) { a = b; }` ill-formed.
Unity builds are sort of all the rage right now, but they're another tool that may be abused. They'll definitely not waste any work compiling for a full rebuild, but at the cost of incremental builds. That is, there is no such thing as an incremental build anymore when you switch to unity builds. Perhaps you could cobble some way to support both: incremental builds for the devlop branch, and unity builds for the release branch, but I think I'll wait for Modules.
Yup, that was my "magic wand" request as well. For projects I've worked on, there will frequently be a fantastic solution that already exists (e.g. boost::program_options or CLI11 for command line parsing), but everybody writes lesser versions of them because it is too tedious to interface with the build system.
I migrated my company's build system to cmake, and created this small test project to develop all the features we needed. Perhaps it is of some use to you https://github.com/skebanga/cmake_test
I doubt it'll happen, but my magic wand request was to get rid of headers and use specifiers like "public" and "opaque". Public would be like struct vector2 { double x; double y; } and opaque would be like struct vector2; and no specifier would be like no mention in the header file. 
"Woof woof bark reflection." - /u/brackersordeath's dog
Does it still \#define `min` and `max` by default?
Nice, at least they try to hear from us and improve C++ I has done and hope it helps to get a better C++
Those two things seem to conflict to me? If the point of smart pointers is to deal with lifetime and ownership, how can you have a smart pointer whose entire purpose is not to deal with that? Seems a bit excessive to add something to the standard library that's essentially a comment saying "We don't own this pointer"
Seems a bit excessive when you could just as well write a comment saying "we don't own this pointer" I don't really see a need for a class to do that or a problem that it solves. A styleguide saying "All raw pointers are non owning" works just as well.
In a large scale (&gt;20 convenience libraries/sub components) CMake based project: 1) Do not use raw cmake commands - write wrappers that you can control. That's it. Everything else follows.
Spoken. Please tell me you don't pronounce ptr as "p. t. r." instead of "pointer"
But the same argument can be used against observer_ptr, since it must provide a way to get the native pointer, theres nothing stopping someone from using it as an owning one. They'd be a terrible programmer and person if they did, but i've seen worse. I don't really see much benefit to observer_ptr over the convention of "document your shit, and preferably treat all raw pointers as non owning, except in localized required areas(Qt, anyone)"
It has to, It's a compatibility break otherwise.
Wait until you start architecting a 20-year-long millions-of-LOCs project with 100+ developers involved, you'll find it _very_ real :-( 
You might need to explain that one in a little more detail because it sounds to me like a complete non sequitur. 
Awesome, thanks for this!
You either put those templates in implementation .cc files or into your internal headers included from those .cc files. Can you give an example of a problematic situation?
If everyone used modern cmake you could just add_subdirectory() or find_package() them and it would be easy.
Standardizing a package manager would break the ability to package C++ for the system package manager easily. Pretty much every language-specific package manager interacts badly with the system ones.
&gt; What do you mean with wrong in this context? One reason i can think of is files with the same name in different projects being ambigious. If you have a file of the same name but existing in different directories, how do you tell which one you want to include without hacking the build scripts? Similarly, let's say you're examining a source code which contains such an ambiguous include directive. How does one tell which header really it is? This also has a negative effect on the tools because it also makes them harder to reason about this information. 
Maybe we should all take a better look at build2 and see if we can contribute to making it truly great before the 1.0.0 version is released. Its ambition seems to be to become the build and package manager that C++ so desperately needs, so it might be a good candidate. But it probably needs more feedback and attention from the C++ community if it is to become a really fantastic build system.
What's wrong with std::tuple?
Well, Modules is coming soon, which will mostly be used instead of headers in the future. Maybe you should take a look at that feature if you haven't already.
I was also surprised that the core guidelines recommended placing const to the left. As you, I have for many years placed it to the right, perhaps after having read the same article. 
The idea is essentially to be able to distinguish between raw pointers from legacy code which might or might not be owning and "raw" pointers from new code that follow the guidelines you just mentioned by making them distinct types. So whenever you see an observer_ptr in code you know it is non-owning. When you see a native pointer, you don't know / have to check if it follows the guidelines or predates shared &amp; unique pointer. Personally I don't believe people will use it unless forced by a style guide, because it doesn't bring many direct advantages and I'm also sceptical about the design (see my comment about owning/non-owning type alias), but well, the paper was written by people smarter than me and with more experience, so I'm willing to give them the benefit of the doubt.
Even if you don't _write_ conventional const notation, you still need to _read_ it, because this is how types are printed by compilers.
Doesn't that have a completely different semantic than a "raw" pointer in c++?
You could write a preprocessor to do that, if you wanted.
My main wish for C++20: please don't screw up std:optional and add a bind mechanism (in a monadic law sens). My dream code would be struct T{ int foo(blabla); }; std::optional&lt;T&gt; o; // o may be set or not //Returns optional&lt;decltype(T::f())&gt;. None if optional is empty or o.get().f(blabla) auto ret = o-&gt;f(blabla); I don't want to write. if(o.set()){ auto ret = o-&gt;f(blabla); } 
I read it as ‘Integral constant’.
 // something.h #include &lt;Windows.h&gt; // Belongs to the public interface of this header file. template &lt;typename T&gt; void foo() { // depends on &lt;Windows.h&gt; }
Yes, but... The original object needs to point to a correct object in the first place. Will going from `type*` `to void*` change the pointer value? I really don't think so. =&gt; UB starts when going *to* `void*` =&gt; no problem :-).
This is bait.
I might be the only one, but I actually think headers are a good thing. After fighting with some Java code, having a separate file where exist a list of functions and classes without implementation details is a great thing, compared to wading through a giant pile of code in attempt to understand just how many functions are there and what they do, and what parameters they take in. Sure, it can be solved by providing proper interface classes, etc., but the thing with headers is that they work even with code that is not very well written in terms of structure: the author is still forced to provide the reader with the list of his APIs (unless he's a complete psycho and writes all code in the header, but then, we can do nothing about it).
Headers are needed because at the compilation stage compiler must know the size of each type. Higher level languages do not need it because built-in types are always known and practically everything else is allocated on the heap because the pointer size is known.
How do you feel about pointers? This reminds me of: int *a; int* b; I switched from `b` to `a` when I found out that int* c, d; Makes `int *c` and `int d`.
I'm in the west-const camp. The reason is that when I have a type, the const I'm most interested in is the one for the actual thing at the end of the chain of references and pointers. Is the actual string/vector/map const, or not? **This** const should be the one most visible, and putting it at the front makes very clear when you start reading a declaration whether it is or isn't const. Whether it's part of this object or not is a secondary thing - is the actual thing eventually being referred to const?