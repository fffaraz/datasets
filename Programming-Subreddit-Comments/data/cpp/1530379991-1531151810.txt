&gt;Minimize memory allocations - one big is much better than many small &gt; &gt;Structure memory access. Linear access means prefetching, which hugely reduces stalls due to cache misses and memory latency. Did you mean that is better to store Ndimensional matrix in one big linear vector than N vectors? &gt;Use SIMD (This will go hand in hand with how data is structured in memory. ISPC is the best way I have found to take advantage of SIMD so far). I have to get to know SIMD programming. It will be very helpful in my work. I write real time robotics programs. Do you recommend any sources to learn performance-oriented (SIMD) programming?
&gt; Did you mean that is better to store Ndimensional matrix in one big linear vector than N vectors? Infinitely better - making a two dimensional matrix/image etc out of a vector of vectors is a huge red flag. &gt; I have to get to know SIMD programming. It will be very helpful in my work. I write real time robotics programs. Do you recommend any sources to learn performance-oriented (SIMD) programming? Learning ISPC is the best way that I know, though it is mainly for x64 CPUs.
Thanks! I'm starting right now!
Oopsie. Shouldn't have used a template to force the coercion.
I accidentally used a template, when I meant to force a coercion to `std::string`. Here you go.
&gt; I've been burnt before with algorithmically more complex things that still are faster up to a higher N than needed because the actual implementation is just so simple &amp; fast. That, and it's nice and all to optimize the argument parsing algorithm of `grep` but it's unlikely to speed it much...
Measure, understand time and space complexity.
I say "skip file" on the entire standard library implementation and when I try to step into `std::sort` with my custom comparator, gdb doesn't stop in my comparator, it just skips the entire call. MSVC presumably lands you in your comparator as the first example shows. 
r/SIMD https://www.youtube.com/watch?v=Nsf2_Au6KxU http://gdcvault.com/play/1022249/SIMD-at-Insomniac-Games-How http://gdcvault.com/play/1022248/SIMD-at-Insomniac-Games-How 
This is quite old book, but I think still useful. At least some tricks still work. https://www.amazon.com/s?search-alias=stripbooks&amp;field-isbn=9781931769242
Yeah I don't how you do it but that's not my experience. For me it doesn't skip the entire call but instead stop at the first non-skipped code
The value isn’t determined in this case, it is undefined behavior...
I prefer books which were published after 2011 year. Then I can think that the author use modern c++.
Both of the snippets you pasted are pretty clear and consistent with each other. The cppreference link makes it clear that an inherited constructor retains the accessibility of the parent class, regardless of if the using statement itself is in a public section. Having a compiler error is correct. The visual studio snippet is just saying that their compiler used to be nonconformant, and was instead implicitly giving you a new constructor in B behind the scenes. e.g. using A::A; was actually implicitly generating something more like explicit B(int val) : A(val) {} Which would be a valid way to expose the protected constructor of A in the child class, but is not how inherited constructs are meant to work. Also in your godbolt link note that both gcc and clang are saying they generated no assembly. Just add a main function that tries to instantiate a B class, and you'll see all three compilers consistently complaining about access.
I can't claim to give you the original rational, but it seems sensible to me. The mechanism for "inheriting constructors" is pretty simple and pretty course. The base class may multiple constructors, some of them public and others being protected/private ones for behind-the-scenes delegation. Having a single "using" statement make all the protected ones suddenly public seems more likely to break a API than anything else. If a child has a need to expose a parents protected constructor it do them on an individual bases. "using Parent::Parent" is really just a shorthand, saying "I want to behave similarly to my Parent, let me just inherit it's constructor API without having to write a million boilerplate constructors to forward them individually"
here is a snippet that more closely resemble what we have in our codebase https://godbolt.org/g/ekr2tU as you can see you can instantiate a B class (inside a static method in B) using the inherited A protected constructor fine with gcc and clang (and msvc prior to 15.7) 
The first thing is to work out if it is good enough. If it isn't good enough, they shoukd have a case that describes what not good enough is like. Examine that case. First, make it *aweful*; if thr problem is loads of 10000 are too slow, feed it 100,000 or a million. In most cases (not all!) this highlights the part that is wasting time. If you have a profiling suite, feel free to use it. But if not, run the program in the debugger (with optimizations and debug symbols). Make sure the awefulness is macroscopic -- takes multiple seconds (if not, make the case more aweful). Hit break in the debugger. Look at where you stopped. Read the call stack. Get an idea what the program is doing. Look at other threads too. Repeat 5 times. 90/100 times those 3-5/5 times will be in the same chunk of code. And with high confidence that is your bottleneck, or at least one. Automated profiling tools in my experience give you the above information in a flurry of noise and setup pain. I call this monte carlo profiling, and it relies in the 80/20 rule: 80% of the time you are running 20% of your code. Now you just need to (a) confirm that is the slow code, and (b) understand why it is slow. Confirming it is slow could involve profiling, more Monte Carlo profiling, or even manipulating the algorithm to exagerrate the slow part (repeat substeps a 100 times, or skip stubsteps, etc). Understanding why the code is slow is sometimes easy, sometimes hard. Usually I just count loops, and notice a n^3 or n^2, honestly. Other times overenthusastic use of memory, or node based data structures. Find a point to refactor, leave old implementation intact, replace the slow subsystem, test against old behaviour. Measure performance difference. Adapt and/or write unit tests. Once the code is faster iterate and find remaining bottleneck. You can often take legacy code and manage 10x speedups in a short window; correctness is honestly the hard part. So it can be worthwile to fast iterate speedups (eliminate bottlenecks repeatedly) until you get fast enough, then ensure correctness on the entire mass of rewritten code. With good source control and versioning, you can always roll back to your first fix if it is the cause of errors, and your expertise with correctness and what the code actually does will improve over the time you make the code faster. Plus after 3 monte carlo iterstions you can sometimes have insane speedups, which helps justify the time spent on correctness; if the best you manage is 10% after weeks of test harnesses, maybe you shouldn't have bothered. But if you first prove a 1000%+ speedup possible, checking for correctness after that is a better investment. 
it is indeed sensible in this particular case the inherited constructor is protected and yet I can't use it inside the derived class with the new MSVC update (clang&amp;gcc allow it)
Float versus double can help if it lets you use SIMD with twice as much data per operation.
Thanks for sources and subreddit link. Currently I'm going through this easy because well explained tutorial: [http://www.cs.uu.nl/docs/vakken/magr/2017-2018/files/SIMD&amp;#37;20Tutorial.pdf](http://www.cs.uu.nl/docs/vakken/magr/2017-2018/files/SIMD%20Tutorial.pdf)
Ah, apologies, I failed to properly appreciate why the original example had construction happening in a static member. I got hung up on another posters suggestion that the using statement should be capable of making protected exposed as public in the child, which I gather now wasn't your intent. Yeah, I think MSVC is still being incorrect. It sounds like they stopped automatically generating a new constructor and instead tried to have the base constructors participate in overload resolution like they are supposed to, but screwed up handling access qualifiers. You can even take the static factory function out of it. If you add a default constructor B() : A(0) {} works where B() : B(0) {} does not. They should be identical, since all of A::A should participate in overload resolution when calling a form of B::B. 
On mobile. Forgive typos. struct Base { friend a whole bunch of classes; or don't. It doesn't matter. protected: Base(...) { } void function(){} }; struct Derived : public Foo { public: using Base::Base; &lt;- nothing can call this, because Derived::Derived() is protected, but doesn't friend anything. using Base::function; &lt;- this is public now, regardless of friend-ness. }; In order to allow things to construct a class derived from a class with a protected constructor. You need to write a constructor like template&lt;template ... ARGS_T&gt; Derived::Derived(ARGS_T &amp;&amp; ... args) : Base(std::forward&lt;ARGS_T&gt;(args)...) { }
On mobile. Forgive brevity. Counter example On mobile. Forgive typos. struct Base { public: int function(int){} protected: void function(){} }; struct Derived : public Foo { public: using Base::function; &lt;- Both versions of function are now public. }; Constructors are nothing special. They're just another function that returns void and happens to always exist and be called at well known situations. By treating the "using" rule differently for regular functions than for constructors we make my life more difficult for no good reason.
I think offering such a specific memory scheme is not constructive. The user-provided allocator version encompasses this use case because you can always define a custom allocator that uses a pre-allocated buffer.
Little known fact: R'lyeh is under Lake Washington.
&gt; Minimize memory allocations - one big is much better than many small In modern OS's it's definitely not "much better." The LFH does a great job and is pretty fast.
&gt; Constructors are nothing special Except they are *very* special. You even acknowledge a portion of what makes them special while trying to brush them away. But even ignoring the fact that controlling the lifecycle of an object happens at a much more fundamental level than any other API any class provides, the mere fact that every constructor definitionally has the same name makes them special. Yes, if you've got 12 constructors that do wildly different things you've probably got some serious design issues with your class. But it is plenty common to have one or two protected/private constructors that do *partial* construction, so that the common portion of different public constructors can be efficiently shared. If your parent has a protected "Parent::Foo" you want to expose, you can be reasonably sure all overloads do related things and bringing them all into scope is probably the right thing. If your parent has a protected constructor you want exposed, you can't make the same assumption, and bringing them over individually by creating your own constructor that calls it is more appropriate. 
I'm very skeptical of this. What is 'the LFH' ? 
You can watch the show live at http://cpp.chat/live and you can participate in the CppLang Slack chatroom at https://cpplang.slack.com/messages/cppchat For details on how to subscribe to CppLang Slack, go to http://cpp.chat That page also has a countdown to the show and links to show archives.
The question may be vague and generalized for a reason. They may be looking for a generalized answer like "I would meet with the colleagues that wrote the code to see if they know any shortcomings or inefficiencies. I would also make sure I have a proper way to test and profile the code. " 
That's true, but it has nothing to do with my point, which is independent of any specific example.
Still on mobile, still brevity. Your arguments apply equally to functions and constructors. I remain unconvinced. I also remain unconvinced that constructors are special beyond the *additional* semantics we assign them at the language level. They're functions "and". Not functions " except". You can construct an object or a class manually, but c++ thankfully takes a lot of the work in doing so off of our hands. You can define a private initializer function to do the common initialization just as well as making a private constructor. In fact, we've been doing so for decades. Only with C++11 with chained constructor calls has this changed. If you want private initialization bits, put that in a private function, not a *protected* constructor. Then I can get on with my job without the language being deliberately inconsistent
Low Fragmentation Heap
Depends on context; do you need fast code, or just less slow code? For getting less slow code, the "profile, profile, profile" loop works pretty well, since gentle incremental improvements can work wonders. It's fairly terrible for making actually fast code though. For getting fast code, the first thing you should do is get a truly deep understanding of the problem. Nothing substitutes for *really* understanding the problem, the whole problem. Then you need to plan. Only when you have really thought about things deeply can you make fast processes. You should not expect to get fast code by incremental improvements to bad code any more than you should expect smooth AAA graphics by piecemeal optimizing a software renderer.
And why would it be so much better than other heaps that memory allocations suddenly stop having such a large performance impact? 
Figure out why it needs to be optimized; which can either avoid optimizing it or how much optimization it really needs. For instance, maybe the system was getting 100k chunks and anything under a second was fine, but now it is getting 150k and is a bit over a second and will soon be getting 200k chunks. Thus you can say that getting 200k back under a second is fine. With something of this magnitude, you might be able to quickly see that the code is a mess of cartesian products and is easy to optimize. Or maybe it is a hot mess and you can recommend some faster hardware as an easier solution. But maybe your company just merged with another and the 100k chunk is now 50G and it is taking 20hours and it needs to get back to a few seconds. This changes everything. This is going to probably go all the way back to architecting how data flows into and through the system, not just using better pointers or some inline assembly. This is the difference between a developer and a programmer. 
LFHs store a list of small blocks. When you allocate something it's really just quickly picking one element from this block, and doesn't actually query the OS for more memory.
How is that different from jemalloc or even normal malloc? Those don't memory map in more memory from the OS on every call either. OpenBSD is the only platform that I know of that uses memory mapping on every allocation, and that is for security. 
100% agree. So many "rules of thumb" in development are either dead or never really held up to real-life measurements. I have had the optimization argument so many times over things where someone either was wrong or optimization wasn't applicable such as optimizing a for loop that took 1ms and ran once on startup and typically started up on boot once every few months at most. 
Here is the item tracking this: https://developercommunity.visualstudio.com/content/problem/265966/protected-inherited-constructor-not-available-for.html
Very cool. Jacco really knows his stuff. You should post that to r/simd :)
Optimization isn't just about doing same thing faster, preferably you wanna do loss work to achieve the same effect. Classic example of this is following interview question: &gt; We define f(X, Y) as number of different corresponding bits in binary representation of X and Y. For example, f(2, 7) = 2, since binary representation of 2 and 7 are 010 and 111, respectively. The first and the third bit differ, so f(2, 7) = 2. &gt; A=[1, 3, 5] We return: &gt;f(1, 1) + f(1, 3) + f(1, 5) + f(3, 1) + f(3, 3) + f(3, 5) + f(5, 1) + f(5, 3) + f(5, 5) = &gt;0 + 1 + 1 + 1 + 0 + 2 + 1 + 2 + 0 = 8 You can do it naively in O(N^2) or "the smart way" in [O(k*n)](https://github.com/cruxrebels/InterviewBit/blob/7a2f30d1b11a3c7ad8b6872ac6c0ccdb455ea893/BitManipulation/DifferentBitsSumPairwise.cpp).
The most important thing is to approach the problem scientifically. Quantitatively measure the performance of your code, through profiling, measuring overall execution time, throughput, latency, etc. Form a hypothesis about why your code is slow, then test your hypothesis by writing an optimisation to address that problem, and then test and measure again, and compare against your previous measurements. This is important on a couple of levels: one is that until you measure, you're just guessing about what's slow. This is an easy way to waste time making something faster that really doesn't need to be faster. The second is that it means that you know exactly the impact you're making. Sometimes, you'll get a hypothesis wrong, and write an 'optimisation' which does no good, or even makes the code slower, or makes such a tiny improvement which isn't really worth the complexity introduced. Unless you have concrete data, you can't make those decisions well.
It's still not manual memory management. There is no manual allocation or deallocation there. That's just accessing an object that no longer exists. That is an error in every language.
I haven't seen too many _robots_ running on x86 though.
What if you want to sort an `array` or your own container?
OK, let's use the rules for regular functions. One of which is this: struct C { void foo(); private: void foo(int); }; struct D : C { using C::foo; // error, all overloads of foo must be accessible at the point of the using-declaration }; 
Could you explain why the allocate model is unsuitable?
Your counter example doesn't actually refute mine. It Agrees with mine. My example used protected. Not private. Right now, you can't use "using" on protected constructors. That's not consistent with "using" on protected functions. I want functions and constructors to have the same rules with "using" declarations. They currently don't, and I think that treating them differently in this way is a bug in the spec.
So you would prefer having a single private constructor to prevent all derived classes from using inheriting constructors? Your disagreement with the design doesn't make it a bug.
Yes, obviously if algorithmic complexity can be decreased then it is probably the first thing to hit, but this should be obvious. If something needs to be faster, you can't methodically decrease the algorithmic complexity. It also isn't going to be what shows up on a profiler. 
Ok, let's put this little sub-sub-redit to bed then.
Assembly?
People who form a loudly arguing minority always seem more numerous on the internet than in real life. I write python code and I'll tell you right now that it's not "far from agreement", in real life most people just use spaces. Sane people just use PEP8 because it's a standard thing to point to and it avoid's wasting everyone's time on nonsense. The only modification I've ever, ever suggested to PEP8 for a team I've been on was 100 instead of 80 columns, and I would have withdrawn it if people had argued at all.
The first question needs to be "Do we need to optimize for space or optimize for runtime?". These two are often mutually exclusive, and you go about them differently The second question is "What measured value will be 'good enough' for our purposes?" The third question is "What is our present measured value?" If the present value is good enough, go home and have a cold one. If not, you need to estimate whether "good enough" can even be obtained. If good enough seems attainable, define test cases for benchmarking and regression testing, then grind at the problem until things are sufficiently performant while still being functionally correct. 
&gt; One big memory allocation as a rule sounds like a great way to get junior programmers to write a Gordian knot of code trying to do this instead of a bunch of smaller ones. It can be as simple as `vec.reserve(known_input_size);`. I don't see any Gordian knots here.
I would entirely say that there are two groups really hurting C++ learning. One is the "I AM A C++ GOD!!!" group who use templates in a hello world example. And the other are 58 year old professors who teach a combination of C and C++ with lots of double deferenced pointers, pointer arithmatic, and a side order of inline ASM for a laugh. These same avoid concepts like unit testing or how to be a developer. The above are in competition with the intro to programming courses that teach bio, etc students how to do some really cool stuff in Python. By the end of week one they have loaded images, made the images dance, etc. By week 2 they are doing pretty plots of complex data, and week 8 has face replacement in images. By week 8 in the C++ course the students have memorized terms like variadic, aggregate, double dispatch, explicit instantiation, explicit constructor, explicit qualification, two-phase lookup and been told that their line length should not exceed 80 chars. But the code they have written barely exceeds bringing a file in, messing about with it in memory, some streams, and then pooping it back on to the drive.
Except that float is half the size = 2x more data that fits into the cache.
What do they run on? If its ARM, you've hopefully got NEON. Or, at least VFP. If not ARM or x86, then good luck to you...
Your "structure memory access" guidance doesn't work for memory coalescing architectures.
Finally. I am going to move to CLion from QtCreator if they would support ClangD 100&amp;#37; (Code completions, warnings, etc).
How I do it? I say "skip file", as simple as that. This most certainly doesn't work for me. Here's an example transcript GNU gdb (GDB) (Cygwin 7.12.1-2) 7.12.1 Copyright (C) 2017 Free Software Foundation, Inc. License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt; This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. Type "show copying" and "show warranty" for details. This GDB was configured as "x86_64-pc-cygwin". Type "show configuration" for configuration details. For bug reporting instructions, please see: &lt;http://www.gnu.org/software/gdb/bugs/&gt;. Find the GDB manual and other documentation resources online at: &lt;http://www.gnu.org/software/gdb/documentation/&gt;. For help, type "help". Type "apropos word" to search for commands related to "word"... Reading symbols from ./main...done. (gdb) start Temporary breakpoint 1 at 0x1004010b0: file main.cpp, line 13. Starting program: /tmp/main [New Thread 12012.0x16c0] [New Thread 12012.0x6a74] [New Thread 12012.0x6054] [New Thread 12012.0x2a64] [New Thread 12012.0x658c] [New Thread 12012.0x4f4c] [New Thread 12012.0x3be0] [Thread 12012.0x6a74 exited with code 0] [New Thread 12012.0x1f70] [New Thread 12012.0x673c] Thread 1 hit Temporary breakpoint 1, main () at main.cpp:13 13 std::vector&lt;int&gt; v{1,-1,-2,3,-3,-2,-1,5,-5,-7,-2,-1,2,3,7,5}; (gdb) skip file /usr/lib/gcc/x86_64-pc-cygwin/7.3.0/include/c++/bits/predefined_ops.h File /usr/lib/gcc/x86_64-pc-cygwin/7.3.0/include/c++/bits/predefined_ops.h will be skipped when stepping. (gdb) skip file /usr/lib/gcc/x86_64-pc-cygwin/7.3.0/include/c++/bits/stl_algo.h File /usr/lib/gcc/x86_64-pc-cygwin/7.3.0/include/c++/bits/stl_algo.h will be skipped when stepping. (gdb) skip file /usr/lib/gcc/x86_64-pc-cygwin/7.3.0/include/c++/bits/stl_vector.h File /usr/lib/gcc/x86_64-pc-cygwin/7.3.0/include/c++/bits/stl_vector.h will be skipped when stepping. (gdb) n 15 std::sort(v.begin(), v.end(), cmp); (gdb) s 17 std::copy(v.begin(), v.end(), std::ostream_iterator&lt;int&gt;(std::cout, ",")); (gdb) and here's the source #include &lt;vector&gt; #include &lt;algorithm&gt; #include &lt;iostream&gt; #include &lt;iterator&gt; bool cmp(int a, int b) { return a*a &lt; b*b; } int main () { std::vector&lt;int&gt; v{1,-1,-2,3,-3,-2,-1,5,-5,-7,-2,-1,2,3,7,5}; std::sort(v.begin(), v.end(), cmp); std::copy(v.begin(), v.end(), std::ostream_iterator&lt;int&gt;(std::cout, ",")); } As you can see, no stop in `cmp`. Same results on my Linux machine with gdb8.
Note that the MSVC++ implementation will use a stack allocation if the temporary space needed is less than 4kb in 2017 15.8.
Standard allocators come from a time when segmented memory was the main concern and it shows in terms of API complexity (although things got much better by now). I find the model where the user simply provides a buffer much more useful and easier to use.
This is way too flimsy justification to call &lt;random&gt; harmful. It just means there exist purposes for which it is unsuited, namely some engines do not provide cryptographic security, and do not pass strong tests of unpredictability. The distributions are totally fine, and no analysis is done on the general engine construction class templates (subtract_with_carry_engine, shuffle_order_engine, ...), which might suit your needs just fine.
I went in, clickbait title notwithstanding. These kind of explorations are useful and the comparison tables the author shows are useful to take an informed decision on the algorithm you want to employ (it would be nice to have them e.g. on cppreference). With this said, not every application needs an unpredictable PRNG with a period of 10\^200, and the people developing applications who do (e.g. because of security concerns) should know better than just slapping in the first generator they find.
Later in the article, I mentioned that the building blocks are there to build a decent enough engine (LCG can be tweaked into being an okay'ish generator), but this requires deep knowledge of the domain, and the defaults should know better. 
I couldn't withstand the clickbait. ;) The problem with most of the default engines (except mt19937 &amp; ranlux) is that they aren't even random. PractRand is testing for statitistical randomness, and most fail miserably. 
I dunno why you thought copying the title of a very popular talk was a good idea. 
Mersenne Twister is not initialized correctly. It needs more than 32 bit randomness for its internal state. Unfortunately there is no real standard conforming way to initialize it correctly. See for example https://stackoverflow.com/a/50198303
He just fed a 32-bit seed to an mt19937, rendering the conclusion pretty much moot... He says to use ranlux (even though it's super slow) with the argument against mt19937 being that it's "slow" (although much faster than ranlux...), bad statistical results (that's because you seeded 2 KB of state with 32-bits, yea...), and predictable (people don't use any of these for cryptography... so predictability isn't usually a problem, and ranlux's predictability seems to be unknown...?).
We're talking about a persistent data structure, so it already differs immensely from `std::vector`. Having a non-const `data()` method is not an option, as the container is immutable. But I stand by my original argument that it still presents the properties and *semantics* of a vector. What would be a better name for a direct-indexed persistent container providing O(1) access, O(1) append and O(n) search?
For our prototype we've chosen Intel Pico board with Intel Core i7. It's small and powerful. After testsing our algorithms maybe we'll find something smaller and lighter because the weight matters here. 
I don't think C++'s &lt;random&gt; is meant to provide the sort of thing being testing here. You use &lt;random&gt; for stuff where a low level of randomness is "good enough". For when you need some data that's not a simple pattern and has some level of uniformity. It's not designed for something where you need a 1 terabyte statistical analysis to pass. If you need something on that level, you probably need something that's cryptographically secure, in which case you should KNOW that you need something that's cryptographically secure. Also nice `#include`s and `void*` cast. Maximum C++-usage awareness.
Great. That makes it even worse. You generally don't pipe in 2KiB of entropy into a random number generator. You'd almost deplete your whole entropy pool just by seeding some random number generator. Although, this depends on how `random_device` is implemented. If it's `/dev/random`, it might even just block till there is enough randomness again. Common practice, which even includes crytographic generators, is to read a decent amount of real entropy (usually between 64 and 128 bytes) and seed a PRNG with that, which in turn seeds another PRNG. 
That's some great interface design right there. How am I even supposed to know how much entropy I'm supposed to feed in there (assuming I even *have* 2KiB of entropy, which is highly unlikely). Isn't making anything better, really.
You're right. You never know what answer the recruiter expects. Maybe he wanted to hear the general method or more detailed. But the discussion under this topic is really fascinating and tough me a lot. It pointed me path to further self development :)
Most don't even pass the 128M statistical test. They don't have any randomness. 
Structure of Arrays vs Array of Structures.
unicode, unicode, please, please
Yea, the interface does suck. `&lt;random&gt;` isn't very good. But that's not mt19937's fault. When speaking of predictability with PRNGs it's really talking about whether a computer could predict the PRNG's output based on previous numbers. Humans can't possibly predict MT19937. As for PRNG in games, if it's single player they have full control anyway, if it's multiplayer, the PRNG is likely being shared amongst many other tasks, making it impossible to predict, even with the aid of a computer.
Arena-style allocation certainly helps. A system should optimize around multiple goals: latency, fragmentation, parallelism
Mathematical operators are always highly context dependent and in math means wildly different things depending on the context. Couldn't you make the case that C abuses the multiplication operator to dereference pointers? Anyhow, I use the pipe operator everyday in various contexts such as shells, while as a C++ application dev perform XOR operations once every 5 years.
No, that's not the fault of the generator. And I'm not trying to blame them. Most of the predefined generators are just really old, and were considered decent at the time. However, newer research showed the flaws and we have, as a result, newer and better PRNGs today. And for games especially, you might want to consider looking into other PRNGs to use than mt19937, because of the performance factor. Newer generators like xorshift1024* or PCG32 have a much better cpb footprint in comparison.
I'm not convinced. I measured MT19937 and PCG32 in my game and saw PCG32 was faster only by a very small margin--but it also was less accurate. The version of PCG that was as accurate (possibly more?) was even slower than MT19937. MT generates its numbers in chunks, meaning it's not _too_ bad on the cache, and getting numbers is very quick most of the time, except for the occasional reseeding (which is really fast anyway). Honestly unless you're generating like a million numbers a second it's pretty unlikely to matter.
Daniel Lemire, from the post you linked, did a little benchmark on non secure PRNGs, unfortunately without xorshift1024*: https://lemire.me/blog/2017/08/22/testing-non-cryptographic-random-number-generators-my-results/ If you're concerned that it fails Big Crush, than you shouldn't be using mt19937 either, since it also fails Big Crush (BigCrush is largely equivalent to the 512G bracket in my PractRand test).
There was no 128M test, I guess you mean the 256M one? More than half pass that one. But in any case, my point is that they're not designed to be the best PRNGs. Like a lot of the time, you just need a quick, easy, not-necessarily-the-best PRNG to get *some* sort of random data - super unpredictable or statistically perfect is not what you care about. That is exactly what the Standard Library's PRNGs are for. Testing them with enormous analyses, of course they'll fail. They're not the best, they're not designed to be, move on. With the includes and cast I was just joking on whoever did the testing missing the purpose of what C++ provides. C includes, C `void*` explicit cast.
Yes, I was referring to the 256M (you can see that PracRand did 128M tests for some, if you look at the raw results). The C++ standard library is always striving to provide the best, without compromises, and all of a sudden we shall compromise in a part of the library which is reasonably easy to fix (by just adding new generators, and making the default good)? The void cast can be omitted, that's true.
cpb footprint?
Cycles per byte. 
What would be really nice is being able to change the operator precedence and define custom operators.
You are allowed to call it as you like. As you said yourself, it differs **immensely** from `std::vector`, so using the word vector seems in-appropriate to me. This sub-discussion, at the end of the day, is just good ol' bike-shedding, so I said what I wanted to say, you (and others) responded, job done.
 template&lt;typename RandomNumberEngine&gt; constexpr std::size_t state_bits(); template&lt;&gt; constexpr std::size_t state_bits&lt;std::mt19937&gt;() { return std::mt19937::state_size * std::mt19937::word_size; } template&lt;&gt; constexpr std::size_t state_bits&lt;std::mt19937_64&gt;() { return std::mt19937_64::state_size * std::mt19937_64::word_size; } template&lt;&gt; constexpr std::size_t state_bits&lt;std::minstd_rand0&gt;() { return sizeof (std::minstd_rand0::result_type) * CHAR_BIT; } template&lt;&gt; constexpr std::size_t state_bits&lt;std::minstd_rand&gt;() { return sizeof (std::minstd_rand::result_type) * CHAR_BIT; } auto seed (RandomNumberEngine&amp; engine) { using seed_seq_type = std::seed_seq::result_type; static constexpr std::size_t const seed_seq_size = state_bits&lt;RandomNumberEngine&gt;() / (sizeof (seed_seq_type) * CHAR_BIT); std::random_device source; std::array&lt;seed_seq_type, seed_seq_size&gt; seed_data; std::generate (seed_data.begin(), seed_data.end(), std::ref (source)); std::seed_seq seed_sequence (seed_data.begin(), seed_data.end()); engine.seed (seed_sequence); return seed_data; } is what I use. Hopefully, I understood state size correctly.
I doubt it actually matters.
No, the purpose of an optimizer is to make real code faster..
A simple overload of sort that took the container itself and optionally the predicate with it just calling the existing begin, end, pred version would make it so much nicer to use.
Like 90% sure you can do this *way* faster. Give me a bit and I'll hack something up.
please ask questions at /r/cpp_questions 
Can you explain what chips use that and what it means? A quick google search makes it look like it is something very academic.
&gt; The C++ standard library is always striving to provide the best, without compromises Citation needed.
Alright, since you said I seeded the generators incorrectly, I redid the tests for `ranlux24_base`, `ranlux48_base`, `minstd_rand` and `minstd_rand0`. And, unsurprisingly, really, they fail equally fast. The mt19937 tests are running, but I'm not expecting any different results. 
No modules, no concepts. Both are in limbo for a very long time.
Untested so I might have messed something up, but the idea is there: https://godbolt.org/g/w7nDuV
It doesn't make it a bug. It simply means that I think it is one. Microsoft apparently agrees with me, or else they wouldn't have changed the way using declarations work for constructors to match other member variables.
I think you're fighting a losing battle here...
Huh? The problem is mostly with mt19937 because the state is so big. How are you seeding it?
I'm seeding the full state via `random_device` now. It changes nothing, simply because even if I just seed it with 32-bit, the libcxx implementation is seeding it with something which resembles a xorshift: x[0] = seed &amp; _Max; for (size_t i = 1; i &lt; __n; ++i) x[i] = (f * (x[i-1] ^ rshift&lt;w - 2&gt;(x[i-1])) + i) &amp; _Max; i_ = 0; The conclusion isn't moot at all.
Doesn't change anything. mt19937 stays weak, because the standard libraries are correctly seeding it, even if you just pass in 32-bit of entropy. 
Don't forget safe numerics !
Have you tried xoroshiro? It's pretty good.
No. The object someObject is local to the for-loop. The object is created, the method of the object is invoked and then the object's destroyer is called before the for-loop creates the next object.
The title is a bit harsh. Yes, the "considered harmful" suffix is an attractive reference to have in a title, but should be used responsibly. A correctly initialized mt19937 is a very good choice for non-cryptographic uses for example, but is not intended to be used in cryptography.
But how can a destroyer be called when there is no destructor defined? 
If you don't define a destructor, the compiler will create a default one for you.
By default, all class objects have a destructor. When you define one, you are just overriding the default destructor.
The object is destructed at the end of its scope, which is the end of the `for` block. A new object gets constructed when it gets to the constructor on the next iteration. $ cat temp.cc #include &lt;iostream&gt; class MyClass { public: MyClass() { std::cout &lt;&lt; 'C'; } ~MyClass() { std::cout &lt;&lt; 'D'; } }; int main() { for (int i = 0; i &lt; 10; ++i) { MyClass someObject; } std::cout &lt;&lt; '\n'; } $ clang++ temp.cc $ ./a.out CDCDCDCDCDCDCDCDCDCD $
What's a 'destroyer' in this context?
An object is constructed and destructed on the stack in each iteration of the for loop.
Debugging c++ is much more difficult than C or Java.
Nothing. He meant “destructor”.
Where is the default destructor defined? Does it just call „delete Object“?
No, the destructor is called as part of `delete object`, not the other way around. I don't know what to tell you about where. It's part of the class whether you or the compiler defines it.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
My experience working in Python has been the same. The column limit is a contentious and often ignored, and everything else has near universal acceptance. Non-PEP8 code is pretty much only old codebases and code written by people who don't write much python.
I almost think that the ‘problem’ with C++ is that it is run by a committee rather than a BDFL. I love where the language is going, but Python, Go and others are already there. This indicates inefficiency in the C++ development process. Having seen the Vasa, I think Bjarne is right, but the issues seems to be a lack of clear direction or vision of what the language should be. I hope he gets the Secretariat he mentioned.
Are Games really that sensitive to the speed of the prng? It's usually not like you have to generate thousands of random numbers per frame. Not saying there aren't others that are a much better fit, but I wonder if your requirements aren't a bit high
Can you explain what that means for the people not familiar with the details of random number generation? Does it mean, that the first 256 Gigabyte are statistically indistinguishable from "true random data"?
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/8vbz6y/a_top_engineer_at_my_company_said_i_should_learn/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
The article seems strange. Main point of the guy seems to be that Wikipedia is wrong (which always baffles me). And the supposed weakness is even documented in [original code](http://vigna.di.unimi.it/xorshift/xoroshiro128plus.c) for low 32 bits of result.
Thanks a ton! I'll keep referring to this :D
FYI: I'm building a website about C++, similar to learncpp.com but focused on more advanced content and updated language tutorial
Predictable randomness is exactly how Minecraft manages to have world seeds that can be shared so that different people can play the same world. It’s a repeating pattern you see in solitaire-style games as well.
That's very different. The predictability in minecraft is achieved by using the same seed. That's the definition of a PRNG. It should, however, not be predictable from it's **output**. 
There is an astonishing amount of different xorshifts. Even wikipedia doesn't list them all. It's easy to mix them up.
Sorry, can you explain what idea is in this piece of code? Looks like you rewrote my SECDED to use pdep or something like that? I'm confused.
I like the sentiment here, and I think far too many of us develop impostor syndrome that helps us avoid doing just this. Most people that aren't deep in the weeds would rather see a decision on a recommended path, and use that until they have reason to dig deeper. I posted something about CMake superbuilds, and the the dominant approaches with a section called don't cross the streams, [https://blog.kitware.com/cmake-superbuilds-git-submodules/](https://blog.kitware.com/cmake-superbuilds-git-submodules/) where someone commented about a new feature. We had a great discussion in the comments, I agreed with him that the new feature might be nice for some use cases but if you ask me downloading content in the configure step is a terrible idea. I personally strongly favor separating any touching of version control from CMake, and if we must have network access then is should live in the build step only. Too long for a comment, great to see some good discussion. I think we need to find better places to put guides on best practices for various elements of CMake development/use. Blogs are nice for us as we can get technical, be opinionated in them, and spark conversation. It would be good to perhaps move some of the content later to something that lives longer with the project. That could then be updated too, but I think there is room for both. Even clang-format isn't perfect as it changes across versions some, but it is so much better than reviewing code style, and a cmake-format would be a great addition.
I rewrote your code to make it faster, yes. The idea is that you can do masks in parallel with integer operations and then do an xor reduction.
Yes. And in math, a [vector](https://en.wikipedia.org/wiki/Vector_\(mathematics_and_physics\)) in a vector space has a fixed dimension.
Author here: as other pointed out, this is called vector because it is meant to be a functional replacement for vectors and it tries to have similar asymptotic complexities. And because "vectors" in Clojure, Scala, and other places are implemented with these data-structures. The original paper for RRB-Trees also clearly states this is a library for implementing functional vectors. Note that the word "vector" as in "the O(1) access sequential container" is already an abuse when we consider mathematical vectors. Also, with this naming I hoped that client code would look simple and that data-structure options become more obvious. If you have a functional data-model tree, it should be a bunch of "structs", "vectors" and "maps" (like in JSON and most data-modeling, etc.) and you should not need to know what a relaxed-radix-balanced tree is. But I understand the criticisim in that it may be not obvious for low level C++ programmers that this data-structure does not provide contiguous memory (in fact, to make matters worse, the library provides an `array` data type that is fully contiguous, but that is not compile-time sized... don't kill me :-) Oh, and thanks y'all, I am glad the license change made you all happy!
Thanks Vinnie!
Depends on how big is your structure and what is your access pattern though.
After trying about a dozen C++ IDEs and having no clue how anyone can stand most of them (especially Eclipse and NetBeans, which, IMO, are terrible), I decided to shell out for CLion, because for me, it's easily the best.
GPUs are one example, and it's not just something to handwave away. Sure, GPUs can hide latency, but that's no excuse for poor memory access patterns. E.g. instead of hiding cache misses just don't have them.
Debug codegen *matters*.
Throwing debug codegen out the window may be something libc++ decided to do. It isn't something all library implementers have decided to do.
I think it would relatively easy to fix this; as long as the string library does the "am I small?" read through `char*`, that gets explicit exemption from all the strict aliasing rules. At least, that's how I plan to do that if/when I change MSVC++'s string to look like libc++'s.
&gt; GPUs are one example What is a different example? Also why are you talking about exotic architectures? This is clearly about CPU optimization. &gt; Sure, GPUs can hide latency, but that's no excuse for poor memory access patterns I'm not sure what point you are trying to make here. It seems like you are trying to dive into niche and irrelevant topics to somehow say that the generalization of linear memory access doesn't hold. Again, this was my list of optimization priorities and is about general purpose CPU. &gt; instead of hiding cache misses just don't have them I think you will have to give an example of this.
I think there are a few things (some of these are generic to programming as a whole): * Malloc/new/free/delete (this is mainly an issue prior to C++11). * Templates (and some other things) can barf up hundreds of lines of compiler errors that are difficult to parse. * A couple of times a day now, I get an error that spews up \~100 lines or errors and I have a hard time finding the line that tells me which file/line the error is on. * (not certain if this is an issue) The C++ community does not have a prebaked set of rules about how you should write code (i.e., snake\_case vs. camelCase) and a variety of other formatting issues. I feel as though some people embark on holy wars with beginners over a trivial issue and then beginners are stuck not knowing what to do and thinking it is important. * The lack of certain things being in the STL, e.g., sockets and graphics, and pre-c++11 threads as well. * Also, I think for some people that we frequently direct people towards Boost is confusing. * Lacking a standard installer the installs all the necessary packages for a beginner. * Writing a header file and a source file. * Probably that there was not a standard until 1998 when Java and Python were standardized earlier. * To some extent inheriting any complaints about C. * Having learned C as my first language, I thought my college class overemphasized public/private too early. * For more recent beginners I can foresee the following issues: * Overemphasis on tedious issues (e.g., const correctness) * Also virtual vs override and that virtual is not necessary for a class that inherits virtually but from which no one will inherit. * noexcept * final * Certain things would be really nice to put into std::vector, but can't because they are non-copyable. * Plethora of ways of doing the same thing: e.g., malloc vs new vs placement new vs shared pointers vs unique pointers vs weak pointers (vs references vs r-value references vs values). * One issue I have is when I google a somewhat obscure problem and the first 5 links are for a similar but not exact issue and the responses are all specific to those problems and lack any generality and so can't work with my issue. * Another, when I google for X and the top rated answers are: "You shouldn't do X, you should do Y, heres how to do Y". Sometimes I really need to do X. * I found this to be an irritation in Python as I had a function that could take either an X or a Y and I needed to know the length. For some odd reason, the function to call for an X was one thing and the function for the Y was something else. The function needed to determine the type of the input to figure out which one to call. However, all the google searches at the time turned up lots of comments: "You do not need to know type in Python" (which I find interesting since python now allows people to specify types, but w/e). * My pet peeve with C++ is that formatted printing with std::cout is a pain. I can never remember the formatting codes (and I personally find the std::cout &lt;&lt; "Variable a: " &lt;&lt; reallyLongNameToPassCodeReview.getSomeField &lt;&lt; " Variable b: &lt;&lt; "myLastCodeReviewGotS\*\*tUponForNotLongEnoughVariableNames.getSomeOtherField() &lt;&lt; "..." &lt;&lt;~~std::endl~~&lt;&lt;"\\n") to be a pain to read). * std::endl crossed out as it can slow the program down * I find printf("Variable a: &amp;#37;d Variable b: &amp;#37;d"...) to be much easier.
I went to 'Modernizing Your C++' (or maybe a similar course) a few years back, and it felt like I was back in school. Teacher will lecture, ask some questions for the audience, and give some practice problems. Lather, rinse repeat. That one specifically at some points felt like a read-through of [cppreference](https://en.cppreference.com/w/) with some examples i could take back to my co-workers. I would recommend going to a course where you think you'd be just a little in over your head. The lecturers are great about answering questions and the slides are usually available to download afterwards. 
My first thought seeing this was "ugh, unnecessary vectors..." I write a lot of performance sensitive C++, and throwaway memory-allocation is something I like to avoid. If this was for something performance sensitive, *and* I was writing this for re-use in a library, I'd probably start with something like this, basically eliminating the vector via a lambda that takes each substring in turn: template &lt;typename ForEachString&gt; constexpr void split(std::string_view s, std::string_view delimiter, ForEachString f) { while (!s.empty()) { auto i = s.find(delimiter); f(s.substr(0, i)); if (i &gt; s.size()) { break; } s = s.substr(i); s = s.substr(std::min(s.size(), delimiter.size())); } } The separate calls to substr() allow the compilers I tried this on to eliminate the range_error exception that string_view::substr can throw, as well as the "i &gt; s.size()" rather than "i != s.npos"; you mileage may vary, but logically it shouldn't throw an exception (could add a noexcept declaration based on whether f is noexcept or not...) I'm not actually sure how constexpr this really winds up being, as it'll depend on the ForEachString lambda... I like using a lambda here because it: * makes the function more reusable, and * gives the optimizer an opportunity to do more So you could use this for counting substrings like so (without any memory allocations): int count = 0; split(string, delimiter, [&amp;](auto) { ++count; }); or capture in a vector (potentially re-using an existing vector...): vector&lt;string&gt; strings; split("What did the fox say?", " ", [&amp;](auto s) { strings.emplace_back(s); }); It is interesting to look at the assembly generated when using string literals here. Both clang and gcc efficiently turn string literals into string_views (strlen calculated at compile time). Unfortunately neither are smart enough to turn something like: int foo() { int count = 0; split("Now is the summer of our discontent", " ", [&amp;](auto) { ++count; }); return count; } into: int foo() { return 7; } 
What do you mean by less accurate?
Could you dm me the link? 
I looked at this extensively (as an amateur), and came to the conclusion that the best generator is `pcg64()` [good quality good speed]. `xoroshiro` is not so good, but most importantly, not as fast as `pcg64()'. For a long time I did my testing adding the random value to a value and then in the end print it. This made me believe xoroshiro was almost twice as fast as pcg, wrong! If you'd make that variable volatile, the deck-chairs are moved, now xoroshiro is slower than pcg. Having said that, splitmix64 is my preferred one, it has a small foot-print, is only slightly worse than xoroshiro and is ever so slightly faster. I've implemented [a Boost version of both xoroshiro-generator-family and splitmix64](https://gist.github.com/degski/acd5827bfa82b438e37b8dd58cf9762a). There are also some modified versions of xoroshiro128, which improve on the quality, but are slower, with the exception of one, that appears to be faster and better, I named that one: xoroshiro128plusshixostar.
Wow, a lot of comments just plain don't understand randomness. The tl;dr is, as far as I know, entirely correct. I don't claim to be an expert, and I am almost certainly going to get some things wrong in this comment, but I have at least done a bit of research on this topic before hammering out my opinion and claiming someone is wrong and stupid. 1. How you initialize an engine shouldn't have any effect on the statistical quality of the output. Even if you simply do `std::mt19937 mt(42);` the output should (if it isn't it is the fault of the engine) be of the same quality as if you read 4992 bytes (the size `std::mt19937`s internal state) from `std::random_device`. 2. Don't read more than 256 bits from `std::random_device` at a time. The [man page for `/dev/urandom`](https://linux.die.net/man/4/urandom) says it pretty plainly: &gt; no cryptographic primitive available today can hope to promise more than 256 bits of security, so if any program reads more than 256 bits (32 bytes) from the kernel random pool per invocation, or per reasonable reseed interval (not less than one minute), that should be taken as a sign that its cryptography is *not* skillfully implemented. You might get more bits, but they won't be of a higher quality. 3. `std::mt19937` might be good enough for you use case, but so might `rand`, and that is still not a good excuse to use it when better alternatives exist. Sure, if that alternative used more space, was slower or was a huge dependency, it might be a good reason, but `pcg32` is both smaller, faster and can be implemented in less than 10 lines, plus it passes [BigCrush](http://www.pcg-random.org/statistical-tests.html) and [PractRand](http://www.pcg-random.org/posts/pcg-passes-practrand.html). Rant over.
I've also created a Boost version of [seed_seq_fe.hpp](https://gist.github.com/degski/747d0e50ac69d34547a81e719554f31d), which I was authorized by **Melissa E. O'Neill** [the author of pcg] to re-license under BSL, see her (very interesting) [blog](http://www.pcg-random.org/blog/), for more details as to why and how.
&gt; tabs vs spaces Alternate spaces and tabs. Sometimes use things like em quad. Or hair space.
What I'd add to this is, (if you use your prng sensibly) does the period really matter? I'll try and explain what I mean, if f.e. you use the same [instance of a] prng to both things that are influenced by the user and other things outside his reach, like random angles or whatever, then even 1 click of the user (or the absence of it) will shift the application of the whole forward sequence to different elements, like, `r` is no longer applied to the angle, but now the colour.
The worst is NL.18
Please consider this: https://reproducible-builds.org/
Outside of Windows, Nix is way way way ahead anything I've seen: https://nixos.org/nix
Pros: - Multiple versions of any dependency can coexist at any level of the dependency graph. - Fully deterministic, easy pinning. - Non polluting environments (nix-shell) - Language and build system agnostic, works with libraries, tools, anything. - Everything is almost trivially binary cached. - Fully self-contained developer environments (compiler, etc. can also be fetched via Nix). - If it works on my machine, it does on yours too. Cons: - Windows?
Actually, the standard library rarely strives for the best without compromises, because there rarely is a "best" solution for everyone and in the end, the committee members are also just humans with limited time and rarely domain experts. I stand by my general advice: If you have very specific requirements, the standard library is rarely a good fit.
https://github.com/Xeverous/Xeverous.github.io The thing is still under construction, I have some articles written but the actual website is not publicly visible yet. And the README is not done either. I have the technology setup, now it will just take me time to write the actual content.
If I find the time, I'll write and test AVX2 versions of those, which at least in my mind (untested though) can deliver a better (in terms of randomness) `xoroshiro`generator, by mixing the states of four parallel `xoroshiro`instances, using [lane-crossing shifts and or rotates AVX2 instructions](https://gist.github.com/degski/b5fbac1ec6c8200d1d8ad102f89df89f).
 C:\&gt;FileSizes.exe C:\ 0 Using SEQ Policy EXCEPTION: recursive_directory_iterator::operator++: ╬Єърчрэю т фюёЄєях. C:\&gt;FileSizes.exe C:\ 1 Using PAR Policy EXCEPTION: recursive_directory_iterator::operator++: ╬Єърчрэю т фюёЄєях. 
I've added it to my watchlist. Thanks!
First you'd figure out what the actual performance goal is. Then you'd acquire actual data for the program on which it was expected to meet that goal. Then you'd run it and see if it met that goal. Then you'd profile it on the production data to see where the hot spots are. Then you'd make sure you had sufficient regression testing for the hot spots so you can test that you didn't break them while optimizing. Then you'd figure out why the hot spots were slow and adjust the code. Then you'd profile again to see if it met the requirements and repeat fixing hotspots until it does. Then you'd run it through all the regression tests available.
In which case thanks! Let me plug your code into my code's unit test and benchmark suite and I'll get back to you with results.
If you guys think it matters more than interfaces of standard functions, then i don't really know what to say.
In `build2` we have the `small_{vector,list,forward_list}` containers which are based on (that is, derived from) their `std` equivalents with a custom allocator. You can see them (`small-*.mxx`) [here](https://github.com/build2/libbutl/tree/master/libbutl).
The classes are great. I'm biased, as I'm one of the organizers, but I usually sit in on each class for at least 1-2 hours. I highly recommend them!
Expect commits every few days or more often. I will message and post on relevant subreddits once the site has it's planned content released - then will add more articles on demand, but I have a plan for what I want to have at initial release.
This has already been posted and discussed here: https://www.reddit.com/r/cpp/comments/8v8rq9/random_considered_harmful/
C is full of compiler specific extensions and UB, quite a few things to learn.
It would be interesting to see this implemented using Parallel Ranges + LLFIO's `mapped_file_handle`, and see what the performance difference would be.
I think "generally agreed" is the crux of the issue here.
Are you gonna propose addition of PCB to random?
I attended a class last year (Modern C++ Template Programming by Steve Dewhurst) and I learned a lot of very useful things. In my opinion it's certainly worth the time and money.
This is a follow-up to yesterdays article: https://www.reddit.com/r/cpp/comments/8v8rq9/random_considered_harmful/
&gt; pcg32 Yes, PCG is good. It’s also new. `&lt;random&gt;` (and pretty much any standard library providing RNGs in other mainstream languages) predate the publication of PCG. If you design a PRNG library nowadays, by all means include it (and make it the default, I guess). But at the time there was nothing wrong with (most of) the choices made in `&lt;random&gt;`. The article makes some good points but arguing implicitly (as you seem to be doing) that it’s bad because it didn’t default to PCG is a seriously ignorant statement.
&gt; The C++ standard library is always striving to provide the best, without compromises You should look up when the `&lt;random&gt;` proposal was published, and when PCG or SplitMix were published.
Anything using Eigen I'd wager
Here is critique of PCG by Xoroshiro author, Sebastiano Vigna. http://pcg.di.unimi.it/pcg.php Here is a reply by PCG author, Melissa O'Neill http://www.pcg-random.org/posts/on-vignas-pcg-critique.html
I do use vector with custom allocators. There's boost::pool_allocator which is fairly used.
Can you try testing my favourite small PRNG which is by Bob Jenkins? It's been my go-to prng for non-crypto uses for many years now, mainly because it's small and has reasonable performance on all the platforms I use (32 bit ARM, x64 etc): /*! \class small_prng \brief From http://burtleburtle.net/bob/rand/smallprng.html */ class small_prng { uint32_t a; uint32_t b; uint32_t c; uint32_t d; static inline uint32_t rot(uint32_t x, uint32_t k) noexcept { return (((x) &lt;&lt; (k)) | ((x) &gt;&gt; (32 - (k)))); } public: explicit small_prng(uint32_t seed = 0xdeadbeef) noexcept { a = 0xf1ea5eed; b = c = d = seed; for(size_t i = 0; i &lt; 20; ++i) (*this)(); } inline uint32_t operator()() noexcept { uint32_t e = a - rot(b, 27); a = b ^ rot(c, 17); b = c + d; c = d + e; d = e + a; return d; } }; 
I used libstdc++ [`bitmap_allocator`](https://gcc.gnu.org/onlinedocs/gcc-4.6.2/libstdc++/manual/manual/bitmap_allocator.html) together with `std::list` a few times: it works best for single object allocation, which is what happens most of the time when using lists. It proved reasonably faster than `std::allocator` in my benchmarks.
Because of what they said two paragraphs earlier: &gt;It has to have a copy of the function object in a storage that it can guarantee lasts as long as the thread it is about to launch lasts.
Doesn't forwarding create a copy?
I can't speak for the article, but my point, at least, was that `pcg32` is so short and easy to implement that there is no reason to use Mersenne Twister over it, even if Mersenne Twister is in the standard.
I'm fully aware of that. &lt;random&gt; has been added in C++11. Two new standards were published without improvements. 
I suggest you read Scott Meyers’s blog post on Universal (Forwarding) References.
Not quite what you are asking about, but we use a custom allocator on std::vector&lt;trivial\_type&gt; to prevent the O(N) initialisation of the data when appropriate.
In my use case `boost::pool_allocator` doesn’t seem to offer much perf benefit over `std::allocator`, sometimes it’s even slower. Not sure why, perhaps I’m using it for the wrong things. 
The current state of the art for practical non-cryptographic purposes is [this](http://xoshiro.di.unimi.it/), the sample at the right side of the page is under public domain, and the page itself explains which variation to use in which case (there is also an [in-depth paper](http://vigna.di.unimi.it/ftp/papers/ScrambledLinear.pdf) if you prefer to know what exactly you are running and why should it work well for you). tl;dr: all variations are stupidly fast and have better quality than MT19937 despite having a much smaller state.
&gt;There is a minor change in the interface, related how the generator is seeded. To seed any of the generators, you need to pass in the `std::random_device` (or any class which implements `operator()` and returns an `unsigned int`) you want to use, instead of just the seed. By doing so, I can make sure each generator is seeded accordingly. Why the hate for the [`SeedSequence` concept](https://en.cppreference.com/w/cpp/named_req/SeedSequence)?
&gt; One is the "I AM A C++ GOD!!!" group who use templates in a hello world example. You mean having a function that can receive either a string, char *, char [], std::vector&lt;char&gt; plus receive an int that specifies how many characters to print out 
No, xoroshiro are known to fail a number of statistical tests. State of the art is [PCG](http://pcg-random.org/).
No, and the answer says as much: &gt; **If it took its argument by-value**, it would make a copy when the constructor was called, then have to make another copy to the persistent storage. By taking it by forwarding reference, it makes exactly one copy. Forwarding is what it does now, i.e., it makes one copy. 
Could you please share a link that mentions that anywhere or has any data about that? (xorshift != xoshiro/xoroshiro, and the link you provided only mentions xorshift)
Then you'd better use the [xoshiro series](http://xoshiro.di.unimi.it), in particular [the latest one](http://xoshiro.di.unimi.it/xoshiro256starstar.c). The authors wrote [multiple papers](http://vigna.di.unimi.it/papers.php#BlVSLPNG) on them and did serious evaluations. Chrome and others are using variants of the xoshiro PRNGs.
There have been several reddit threads about PCG vs. xoshiro, where the xoshiro author and others were actively defending and arguing that many claims by the PCG author are not right. Based on those discussions, I don't buy that PCG is the state of art. PCG has weakness as well as advantages. From a practical point of view, 64-bit PCG is complicated to implement because it has to emulate 128-bit integers if I am right, which is quite annoying.
I'll run your generator through the TestU01 and PractRand statistical test suites when I get to work in a couple hours and report back. The smallest PRNG I've seen (which passes many, but not all, statistical tests), was implemented in Webkit for a while and looks like this: uint64_t seed; uint32_t rand() { return (seed += seed * seed | 5) &gt;&gt; 32; } (Based on [this paper](https://link.springer.com/content/pdf/10.1007/3-540-36400-5_34.pdf).)
I'd trust Bob Jenkins long before most others. Moreover, his PRNG does not use multiply, which was historically a big win over others, back when a multiply could suck down twenty or thirty cycles. The reason I'm curious about Arvid's results is that I've never been persuaded that Bob's PRNG can be improved upon for the simple non-crypto use case, hence I've been using it exclusively for a decade or so. But if PCG is beating Bob's PRNG for both randomness and speed, and given how cheap multiplies are nowadays even on a low end ARM, I'll change my standard practice.
Firstly, my thanks in advance. It will be interesting to see how Bob's PRNG fares in modern analysis. Back when he wrote it, personal computers were considerably less able to test by brute force. I've seen the above PRNG before. Always found it a bit yuck, but statistics is impervious to beauty.
Thanks for that, I **did** read the first link before, but not the second one, tuff girl, Melissa. I just judged them, based on the results from PractRand and my own speed-testing. That they argue, is not relevant, other than the interesting details that are being brought up in the mutual slaying. It's also quite entertaining :-).
It seems entirely reasonable to... add pcg32
I'm currently running it through the tests. It's at 512G. Will report back when/if it fails.
It isn't a C++ codebase, but the bourne shell does it.
I added some stuff to the first post, but you probably already were aware of that.
Does reserve/resize not work for you?
Right, by all means use it. But criticising its non-inclusion into a standard that was written before it existed is disingenuous.
I strongly agree. And you are familiar with how the committee operates. So why not write a proposal?
C++14 *also* predates PCG’s and SplitMax’ publication, as did much of the work done for C++17. For it to be included into the standard, somebody has to write a proposal. Honestly, that would be a whole lot more productive than to write a blog post repeating well-known weaknesses of the existing algorithms (which is presumably why this blog post was *not* well received here on Reddit).
you mean [https://www.boost.org/doc/libs/1\_67\_0/libs/iostreams/doc/index.html](https://www.boost.org/doc/libs/1_67_0/libs/iostreams/doc/index.html) from boost?
I'm not saying PCG should definitely be in the standard, I was saying that what is in the standard is very dated and should be avoided. Even at the time when the proposal was written MT wasn't a "state of the art" generator, neither were the others. 
I have seen it produce 10X speed differences, easily. We can't deliver a 10X performance regression for q feature that, let's face it, isn't going to have a comparatively high number of users.
Reading through it, both seem to be kinda butthurt, which is super odd to me. Shouldn't we be happy about efforts on improving it? I wasn't aware of the "rivalry". Sure, a little bit of rivalry can't hurt, but that's simply childish from both sides. Although, I can see why Vigna is angry, it's kinda obvious that applying the inverse of the generator will make the result worse. 
I've been, on purpose, a little bit click-baity on the title, I apologize. Although, I've since shown a couple improved generators which can be used instead. https://www.reddit.com/r/cpp/comments/8vhrzh/better_c_pseudo_random_number_generator/ I'd love to write a proposal for inclusion, but without someone vouching for it to get it through, this is lost effort. 
Why can’t the compiler detect that the type is trivial?
Because this isn't an area I'm either interested in, nor expert in.
Vigna gives the impression that he's unable to tolerate any criticism of his baby and that he holds a grudge.
Why does the constructor advance the state 20 times? What difference does it make?
Thank you
I've been tinkering with deferred allocation with allocators so they can use `realloc`/`try_realloc`. My custom containers use them and show *far* better performance during insertions, but I'd rather use standard implementations.
&gt; the example by the xoroshiro's author actually makes PCG practically unusable for some of my cases Honestly not sure why your issue with PCG is. Maybe just don't use the `insecure` generators? I've not seen a critique from Vigna that continued to trouble me after a bit of thought.
I generally define xorshift and variants as random engine interfaces. I almost never need a statistically-perfect generator, and the quality seems at least equivalent to Marsenne Twister. I write low latency simulations, so faster PRNGs make a big difference. Will likely be switching to a mixing table PRNG, though, to speed it up more. Hopefully it stays resident in-cache
Is it any different to optimising for the target CPU? 
I wasn't.
Twice as fast? That surprises me. I did a CPU cycle estimate for PCG vs Bob's and I reckoned Bob's about a quarter faster on a Skylake. I must be getting rusty. Bob said that he tested it up to 1T values, plus various other configs in various ways up to 16T values. He was limited by what a PC could do in 2007, and 32 bit compatibility. For some odd reason, his PRNG never gets mentioned in the PRNG wars where various people with large egos claim their latest invention beats all others, but when I have in the past tested theirs against Bob's, Bob's always wins. Yet nobody mentions Bob's. I guess there is no big ego to drive his PRNG.
If I remember rightly, Bob calculated that 20 iterations was the mathematically correct minimum number for getting sufficient cascade of seed bits. Bob Jenkins is actually a crypto guy, that's what he used to do all day long, and he came up with this non-crypto PRNG about ten years ago as what he thought was the smallest possible which wasn't awful in some way. You can read lots more at http://burtleburtle.net/bob/rand/smallprng.html
I think it's quite a common use case to split a large random number into several independent pieces and treat them as orthogonal. Surely some use cases would be totally fine if split "21+43 bits" has weird dependencies. I'm not sure my cases are going to be fine. I understand that one could just generate several numbers instead, but if we care about the speed and practical quality (not in a secure sense), it's better to just pick a twice faster alternative that doesn't have this particular problem, and keep doing the trick without worrying that it will behave horribly wrong. I also understand that there may be people who have an actual practical case where xoroshiro would perform badly. But unless there is something obvious, I see no reason to pick a twice slower generator over a twice faster one.
Using reserve you can not access allocated elements directly and resize default initializes as well.
That sounds like a reasonable approach ( docker + using cmake to drive the build ).
Oh my word no, definitely not. I mean the reference library for P1031 *Low level file i/o*, so specifically `mapped_span&lt;T&gt;` from https://ned14.github.io/afio/classafio__v2__xxx_1_1algorithm_1_1mapped__span.html. I'd suggest creating the underlying file using `handle::flag::maximum_prefetching`, and the mapped span using `section_handle::flag::prefault`. Then feed the mapped span to the Range algorithm. You *may* also get a bit of speed up by not using the awful `filesystem::directory_iterator`, which is crap, and instead using LLFIO's `directory_handle::enumerate()`. LLFIO can be entirely used without ever allocating memory, and I'd suggest doing that for maximum performance.
Looks like a viable alternative to me, so far. It does the 1T in ~5400 seconds, while splitmix and pcg do it in ~12600 seconds.
&gt; I think it's quite a common use case to split a large random number into several independent pieces and treat them as orthogonal. Surely some use cases would be totally fine if split "21+43 bits" has weird dependencies. I'm not sure my cases are going to be fine. Why do you think this is a problem?
Some discussion and testing of it: http://www.pcg-random.org/posts/bob-jenkins-small-prng-passes-practrand.html
The xoshiro series come with several versions without multiplications. For example, [xoshiro256+](http://xoshiro.di.unimi.it/xoshiro256plus.c) and the older [xoshiro128+](http://xoshiro.di.unimi.it/xoshiro128plus.c). A problem with these versions is that the lowest bit (maybe 2) is not random. Arvid's benchmark is far from comprehensive. There are multiple benchmarks (e.g. [big crush](https://en.wikipedia.org/wiki/TestU01)) specifically designed to test the "randomness" of PRNGs. Both PCG and xoshiro are often evaluated on these benchmark datasets, but I rarely see Bob Jenkins' among them. This is why I would trust pcg/xoshiro more. Furthermore, pcg32 can generate 4 billion independent streams; xoshiro uses "jumping" to achieve a similar effect. This feature has been very useful to me.
It's a battle between two non-crypto-safe, practical generators. One author made a post figuratively soaked in poison, discussing problems of another work that don't exist in practice (one would think that someone who writes PRNGs is expected to know a thing or two about probabilities, and yet there is a brick of text about a 256-bit state that somehow got initialized with lots of 0s). Another author mentioned a lot more practical problem, that is likely to affect many some where people would knowingly pick an insecure PRNG just to save some cycles, hoping that it's at least not too terrible since it passes some tests. Unfortunately, PCG is exactly that terrible (in these cases). I'm not saying PCG is terrible in all cases. I'm not saying xoroshiro is awesome in all cases. I'm just saying that it seems to be much faster, passes all tests and doesn't seem to have practical problems (unlike PCG), so the author's claims seem quite sensible, and if there are no faster options of comparable quality, it is, indeed, the current state of art (among non-secure generators). I'll be happy to be disproved by someone who can link a better alternative. That would mean I can replace xoroshiro in my code with something even faster without losing the quality. In fact, I would be quite grateful, because it is still visible in the profiler for me in one of the scenarios (about 0.3%, but still).
I remember differently. At the time, MT was considered a high-quality PRNG that provided an excellent trade-off between quality and speed, at the cost of memory footprint.
We're working on updating our Tutorial to better reflect "Modern CMake" practices. We plan to update the copy in CMake's source code (that is subject to nightly testing) soon. In the meantime, you can download a copy of our updated tutorial here: https://data.kitware.com/api/v1/item/5b3379ab8d777f2e62258e11/download For each step, read directions.txt and follow the instructions. This is meant to be a fairly comprehensive introduction to the most-used CMake commands.
ok, I haven't tested this library. I'm happy to see the results of such implementation. Of course the example is not a production code. So you might want to decide if you just want a simple app, some utility... or go for the full speed and optimizations.
The exception text is "Отказано в доступе" - access denied (in russian locale). On windows some folders on drive C can not be accessed without proper permissions.
The xoshiro series have several variants without multiplication such as xoshiro256+ and the older xoshiro128+. pcg32 also supports generating 2 billion largely independent streams; xoshiro uses "jumping" to achieve a similar effect. This feature is useful for high-dimensional data.
I've used string and vector with a custom allocator for non-paged memory. i.e mlocked. We use them for storing secrets (keys, passwords, etc) https://github.com/mongodb/mongo/blob/master/src/mongo/base/secure_allocator.h
I do not know, I'm not an expert. I've applied a number of suggestions in the guide, as my development platform is linux/x86\_64/g ++, and I think most of it is for most CPUs.
Talking about performance – you are using a version of xorshift with multiplications, while the typical versions I see use bit/plus only and pass BigCrush, too. It would be better to point out the exact xorshift/xoshiro versions you are evaluating. Their performance can differ by a factor of 2.
The group I work with tried to. But our attempt to was eventually defeated by people external to our group because "using a custom allocator changes the type" and that is apparently a problem.
And even more discussion and testing of it: http://www.pcg-random.org/posts/random-invertible-mapping-statistics.html. Thanks hugely for that link. I wasn't aware, until now, that the PCG guy had spent so much time investigating Bob's PRNG. Which I now know is called JSF (Jenkins Small Fast). I'm also not sure why, after the PCG's guy's ample empirical results, he doesn't conclude that JSF is a better general purpose PRNG than his own PCG algorithm which is a lot slower, and not *that* much better given the tradeoffs involved. Looks to me I'll be sticking with Bob's PRNG for a few more years yet ...
That's when you start using the new polymorphic memory allocator :p
I worked on a project with its own memory management system that everything had to go through. Default "new" was not allowed. We used a custom allocator to adapt STL containers to our system occasionally, but more often we just avoided STL. Our system was not a great match for how containers/allocators work because we wanted to allocate memory from pools of fixed-size allocations, which was unsuitable for containers like vector, and challenging even for things with uniform allocations like std::map (since there's no great way to determine the node size ahead of time).
 C:\&gt;sudo FileSizes.exe C:\ 0
Why not make the default constructor do nothing? 
So far it's passed Crush and SmallCrush, running BigCrush will take a few hours.
* Malloc/new are not a issue after C++11 especially where the STL can create a dynamic vector etc.. Also using smart pointers is a safeguard when dev forget to write the delete statement :p * Having a graphics STL will create portability issues for the compiler and header as well. * Goto is a necessary evil. It is good for extreme beginners, bad when you learn more. Although it may pass on Procedural programs, OO programs simply hate this. Although the assembly code might/will contain these jump statements anyways. (eqvt. of goto in asm)
What kind of access? What object is being accessed? Why error message is not in human language? Why `recursive_directory_iterator::operator++` is shown to the end user? With this kind of error message, how do user fix this? 
CSPRNGs like Fortuna are pretty fast. You don’t NEED cryptographically secure random for most applications, but with crypto extensions it’s almost free. 
The C++ source code is labeled with "insecure", but the C version isn't. It is not clear that you should avoid`rxs_m_xs_64_64` which is 50-100% faster than the preferred one.
PCG lady*
The C++ Working Draft missed its own post-meeting deadline?
Seems reasonable. Is this what people used to refer to as 'adjective syntax'?
Fixed, thanks.
No, but it's inspired from that idea if I'm not mistaken.
No haha :) They just need to be processed for ~1 week and then are published.
So, instead of 2D Graphics, Hal Finkel [proposes to standardize `web_view`](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p1108r0.html) -- basically an embedded web browser engine, together with [prototype implementation](https://github.com/hfinkel/web_view). This must be less controversial thing. It only needs to standardize HTML, ECMAScrtipt, CSS and a few more, but otherwise it's pretty simple... 
Hmm, that does sound like an oversight. Thanks for pointing it out.
Why would you not withdraw such a proposal after Bjanr's 'Remember the Vesa!' paper... 
That's not correct. While `at()` will throw, `operator[]` does not. &gt; A similar member function, vector::at, has the same behavior as this operator function, except that vector::at is bound-checked and signals if the requested position is out of range by throwing an out_of_range exception. Needless to say accessing a reference on memory outside the vector bounds is undefined behavior. 
This claims to be attack resistant *and* faster than anything else. Perhaps you can try it? https://github.com/google/randen
You sir are a better programmer than I: OPTION 1: GCC 7 (-march=skylake): Variable buffer size calculating is approximately 615.615 Mb/sec, or 4.79551 cycles/byte OPTION 2: GCC 7 (no -march): Variable buffer size calculating is approximately 670.766 Mb/sec, or 4.40118 cycles/byte OPTION 2: GCC 7 (-march=skylake): Variable buffer size calculating is approximately 1115.43 Mb/sec, or 2.64652 cycles/byte OPTION 3 failed to pass conformance. I take off my hat and bow to you sir. Thank you.
github.com
Unfortunately, that's the situation for `std::unique_ptr`, for example.
https://www.amazon.com/Tour-2nd-Depth-Bjarne-Stroustrup/dp/0134997832
&gt; I'm also not sure why, after the PCG's person's ample empirical results, they don't conclude that JSF is a better general purpose PRNG than their own PCG algorithm Part of it is personal pride I'm sure but also there appears to be many axes by which to evaluate the quality of an PRNG -- and everyone seems to have their own favorite subset. Semi-off-topic: Dr. O'Neill's original claim to notoriety: https://www.cs.hmc.edu/~oneill/papers/Sieve-JFP.pdf 
Apart from the web browser engine, I can see the advantages over what happened with graphics. We were speccing out a large API and essentially reinventing things. EWG is by no means an expert body in the domain and couldn't truly properly review the proposed additions. These required standards don't have changes so rapid and drastic that waiting up to three years would kill the whole thing. There's no need to review the standards themselves; their respective bodies have already done so well enough for widespread use. We'd just reference them like we do with C and possibly Unicode in the future. The API itself is a minimal entryway into this established standard territory. Now that API doesn't look amazing to me, but the real kicker is how to run this. Having implementors build or include a web browser engine is very new territory. I simply don't see how that's going to happen. The rest is at least conceivable to me, however.
C++ 11? That‘s a little bit outdated ;)
https://en.wikipedia.org/wiki/C++11
From [http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p1062r0.html](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p1062r0.html) \&gt;Michael Spencer and Billy Baker, who provided invaluable feedback at a bar. Now we know the how standard papers are really written :) I wonder what percentage of the standard is due to discussions at a bar?
Like Bryce, I'm one of the organizers, so I share his bias, but I'm proud of what we can offer. Most of these instructors are available as freelance instructors (some have day jobs) that can come to your company and teach a class. But if you work at a small company or have a small team of C++ engineers, the cost per engineer can be pretty prohibitive. Offering these classes is a way for us to make available to you some of the best in C++ instruction without you having to have the instructors come to your company. Look at who these instructors are. We are getting the top names. There are only a couple of instructors that I'd like to have that we can't get, but if you can't arrange to have an instructor come to your company, this is your best opportunity. When we set the fees a few years ago, we looked at the cost of publicly offered C++ training and found that it was priced at about $500 per day (surprisingly uniformly). But that was for classes offered by training companies where you didn't necessarily know who the instructor would be or, if you did, you'd not likely have heard of them before. Our courses are better priced and we are offering top instructors.
We have our own simple allocator, merely to block signals in allocate()/deallocate(). Because, yeah, we do all sorts of crap within signal handlers...
Glad it worked out, 2 of 3 is a lot better than I assumed :). I was surprised option 2 was faster than `pdep` without `-march`, but it seems GCC vectorizes it even then, which is neat. Feel free to steal this if it's something you still care about.
That doesn't match my experience. Memory allocaton patterns have popped as an issue way more often for me than actual computation that could be helped with stuf like SIMD that seems to get more attention. Avoiding un-necessary allocations, avoiding copies, etc. Once you have to start worrying about NUMA effects, it starts to feel silly to call the machines "computers" because so little of your attention is on actually computing stuff.
If I understand this correctly, they don't have to include a web browser engine. Just because the interface is mirroring a Wendstandard, doesn't mean the implementation actually had to be done in terms of a web engine. Instead you could e.g. use OpenGL or directx
I'm minded that your technique can be extended to a SSE register, and likely an AVX register. But it's not a high priority work item right now, that would be standards stuff as usual. I am going to retain your code in an ifdef'ed out block, so when the time comes, I can do it proper. Thanks once again!
&gt; The programming world now broadly recognizes that programming bugs (e.g., out-of-bounds access, null dereference, and in general all pre/post/assert-condition violations) cause a corrupted state that cannot be recovered from programmatically, and so they should never be reported to the calling code as exceptions or error codes that code could somehow handle. I beg to differ. UB is unrecoverable after it occurred, but if an out-of-bounds access is catched before it happens you might be able to recover from it - usually by restarting the subsystem. And even if you can't recover, you might at least write some debug information to disk, before you crash the program. Sure, during development fail fast is usually the better approach, but release builds running at the customer should not just die and take the current working set with them, just because there is a spurious bug somewhere in the rendering engine. 
C++ Primer 5th Edition Effective Modern C++, Scott Meyers Maybe watch a few Cpp Con talks by Herb Sutter and the rest of that crew just to see what’s out there. Check out the core guidelines: https://github.com/isocpp/CppCoreGuidelines And check out the cpp slack channel; there’s some pretty high visibility users there that will be able to answer questions—and of course you’ll get community feedback as well. 
Regarding constexpr: Is there any progress towards constexpr destructors?
interesting indeed, i use reserve a lot and then index into the vector to initialize elements.
I hope you don't use auto_ptr :S
It seem rather optimistic compared to the other trip reports. Let's hope the predictions in this one will end up true! Also, congratulation on the merged modules proposal. Let's bring C++ to the next level in 2020!
The new rules for what constitutes an aggregate type can break code (in rare/unusual cases). Some language features deprecated in C++11 are now removed (e.g. the register keyword). By far the biggest churn is caused by things removed from std, such as random_shuffle. All such things were deprecated in C++ so you might have already cleaned these things up. Compilation errors can occur due to the new float overloads for the math functions, most commonly in calls to functions like std::min. This set of API changes can also change the floating point results of code, which can be a problem if tests or systems are sensitive to that.
What a mind-boggling proposal... Having given it a cursory read-through, it seems to just wash its hands of what the underlying browser engine actually provides. It could be the latest version of Google Chrome, or it could be IE6. Even if `web_view` required a certain level of Web standards support, how far would that go? HTML5/CSS3/ES5? WebGL/WebM/WebRTC/WebAssembly? And what if that support *wasn't* standardized, but most engines provided it anyways, making it a de facto part of standard C++? Would newer versions of C++ upgrade to newer Web standards once the current ones become obsolete? Can of worms, anyone?
I second this: recovery can be very useful, for example for hot reloading. But I expect there will be at least a compiler switch (`--no-self-destruct-on-contract-failure` or `/Fz`) because this seems like something that will break a lot of programs.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/8vkycr/need_a_refresher_of_c/e1oeg0p/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
You've gotten a couple of good suggestions - while I don't want to discourage your learning, help posts are off-topic for this subreddit. (Perhaps we should have an occasional thread for discussing recently added features, though...)
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/8vhual/why_stdthread_makes_a_forwarding_reference_and/e1oeni1/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I remember the Vesa. It was killed by PCI.
I'm confused. Herb says: &gt; You get to install your own violation handler and ship a release build with the option of turning on enforcement at run time. This was my understanding of contracts too. But then the [wording](http://eel.is/c++draft/dcl.attr#contract.check-5.sentence-3) says: &gt; There should be no programmatic way of setting or modifying the violation handler. What gives?
&gt; And even if you can't recover, you might at least write some debug information to disk, before you crash the program. Exception handlers are a sub-optimal way to go about that kind of error response approach . At the point of the error you have a lot of potential forensic information, including the stack (and all its contents) as well as any other transient application state that may be pertinent. As soon as you throw an exception, unwinding starts happening and destructors start getting called, each throwing away or otherwise mutating bits of that forensic information. By the time the exception handler is called, critical information may have been lost. It's not always reasonable to package _everything_ into the exception, either, as the code that throws the exception likely isn't aware of the bits of application state that led to the erroneous condition occurring (e.g., the out-of-bounds checking code knows the requested index and the available range, but knows nothing about the data that the calling code used to _calculate_ the index, which is where the real bug resides). If you want to log and exit, don't use exceptions; just log and exit at the point you detected the error. Bonus point for allowing multiple error log hooks, so different subsystems can inject their own state into the log dump even if they aren't directly tied to the point of the error (e.g., dumping the scripting system stack, or metrics on various resource usages, or a "context" trace, or so on).
That's fine for a struct, but std::vector&lt;char&gt; x(size); will lead to a big fat memset(), and there's not really much you can do about that.
Calling \`operator\[\]\` on the reserved, but non-constructed part of the vector is UB. No object is present at that memory location.
the issue is that vector&lt;char&gt;(size) does't just allocate the memory, it also zero's it out, which is sometimes undesirable. using reserve()/resize() leads to the same behavior. reserve() allocates, and resize() zeros it out.
There is a way to set a contract handler, just no C++ API. Instead it is a compiler flag or something like that.
The compiler can't always tell if using the memory uninitialized is equivalent to using it initialized. Tak this for example: `std::vector&lt;char&gt; contents(size);` `file_stream.read(`[`contents.data`](https://contents.data)`(), size);` I know that the result will be the same wether or not contents is filled with 0 or not, but the compiler may not have enough information to be able to make that call.
auto_ptr was flagged as deprecated in C++11 so unique_ptr should already been here
Good to see "Zero-overhead deterministic exceptions: Throwing values" still in the list there. I feel like that proposal has potential to resolve a lot of the long-standing issues with error-handling.
There actually isn't any tension between what you said and what you quoted me as saying, because you can do all of that without (ab)using a callee precondition to perform a check that the caller is perfectly capable of performing. I agree that *the caller* should check bounds and do arbitrary recovery that makes sense for the call site and the application. For bounds in particular, the caller can tell whether they're about to make a call that would violate the callee's precondition. But relying on *the callee* to perform a test on a precondition on behalf of the caller, and making the caller rely on the callee to do, is not a substitute for the caller's ensuring the precondition in the first place. A call site that fails to ensure the precondition is at best a lazy call site, and at worst (and more likely) is already corrupt in other ways.
Remember the proposal *To boldly a pub crawl for C++ Toroton. Pubs are at the *heart* of any proposal.
Only in my STL containers ;)
I'm skeptical that that really has an impact on speed of a program unless you are doing something pathological. 
Sick. 
It baffles me that the author failed to find any references to one of the most studied [combinatorial objects in existence](https://en.wikipedia.org/wiki/Random_permutation_statistics).
When I worked at Bloomberg, we were not allowed to use `std` in our code and had to use `bsl` or Bloomberg standard library. If I understand correctly, they rewrote the entire STL over a disagreement regarding object-specific allocators. IIRC, at least in C++11, the allocator proposals were submitted almost exclusively by Bloomberg developers. The background information regarding bsl can be found here: https://github.com/bloomberg/bde/wiki/Bde-Allocator-model.
Well, yes, this is only really impactfull in a handfull of situations, but it certainly comes up. A good example would be allocating the backing store of a large pool allocator.
Interesting, thanks. I’m still a little confused though. How does a custom allocator solve the problem? If I recall correctly, it’s the vector’s constructor that is zeroing the memory, not the allocator. If you default constructed the vector and the called `reserve`, the memory wouldn’t be zeroed unless the allocator zeros memory it allocates, which I don’t believe `std::allocator` does. (of course, you’d then be unable to set the size without overwriting the memory, but that’s beside the point) 
Just include Firefox in libstdc++.
You are not allowed to use reserved memory until the vector has been resized. It's Undefined Behavior.
*register* keyword still works though on some architectures where it is meaningful.
Yes, you can probably re-enable `register` (and many other things eliminated from C++17). At that point you're no longer using C++17 but instead a vendor specific language extension: https://en.cppreference.com/w/cpp/keyword/register
Hm. Do you know if there's an example somewhere of how that would end up looking?
I agree with this, but the problem I find is that you're almost certainly using libraries that communicate unrecoverable error conditions through exceptions. So you need to install a first-round, pre-unwind exception handler anyway, and then you may as well use exceptions in your own code. 
They did say that they left out lots of math. And I kinda got the feeling that they assumed the reader "just knew".
I miss `register` now.
The problem with the current web is that no one sticks to the standards and they're always a moving target. If `web_view` somehow manages to make it in, who knows, maybe we'll actually have some standardized functionality we can actually depend on. We don't have to keep up with the mistakes of web developers.
You should take a look at `string_view` and start evaluating where it makes sense in your code base.
&gt; You are not allowed to use the reserved memory until the vector has been resized. It’s Undefined Behavior. Yes, of course. I wasn’t suggesting that you do so, just trying to point out that your example, it is the vector clearing the memory, not the allocator. I looked at the documentation for `DefaultInsertable`, so I see what you are talking about. Interesting, thanks!
I guess this proposal was not really serious. Even sarcastic, maybe. 
boost::filesystem::recursive_directory_iterator 's operator++ can throw exceptions (so they have another function named increment(system::error_code); ) , which is somewhat weird. How about std::filesystem::recursive_directory_iterator ?
... and other lies programmer tell themselves.
I actually have somewhat very similar needs. Using the generator mostly for simulation purposes. Speed being a primary concern. I'm curious what you have settled on using for your needs.
Probably with weak symbols, the same way, e.g. overriding global operator new works: the compiler provides a function implementation that gets discarded if the user defines it. Sadly, without a standard interface this basically means implementing different functions for different compilers
You should find some way to record your disappointment. Maybe you can create a central list where everyone who also misses it can indicate their state of mind. 
if it's undefined behavior, you can't do it. You can't do it safely, you can't do it with any guarantees. even if you didn't have `operator[]` you could get the allocated memory area via UB
I would, but disappointment has to be put in a specific register, and barring vendor-specific extensions, I can no longer specify that I am writing to that register.
&gt; I agree with this, but the problem I find is that you're almost certainly using libraries that communicate unrecoverable error conditions through exceptions. Well, I guess it depends. I certainly am not using libraries that communicate errors with exceptions, because I live in a strictly `-fno-exceptions` world and hence just do not use libraries that mandate their use. :p Fixing the "popular libraries use exceptions so now you have to do it too even if you don't wanna" problem that already bifurcates the C++ community is kinda one of the main reasons for Herb's proposal. Not to mention one of the reasons behind proposals like `expected` or `outcome`.
That's behavior of that is undefined, don't do it.
I didn't see any "insecure" labels. In fact, if you look at the homepage, PCG quality is universally marked "Excellent" (and only them, nothing else in this world is supposed to make PCG look bad in comparison), "Very Fast" and otherwise amazing. I guess it felt better than mentioning actual numbers on some specific machine, providing sources for competitor's implementations, and splitting PCG variations into individual rows ("this one is fast but super-crappy, this one is not so crappy but twice slower, etc"). If the author first actively tries to deceive me on their web page (probably for some academic reasons, or just for the pride, who knows), then tries to deceive me in their blog post (are we seriously discussing zero-state for a generator with a 2^256-1 period? or predictability property for a practical non-crypto PRNG? Or unlikely bijections that only slightly reduce the quality properties? No actual mention that xoroshiro is WAY faster than less crappy versions of PCG?), then tries to deceive me again (as a random reader of the thread) in replies to Vigna's replies, I sort of don't care if Vigna forgot to mention some fine details. It's understandable due to the [Bullshit asymmetry principle](https://en.wikipedia.org/wiki/Bullshit#Bullshit_asymmetry_principle). What I do care about are the final results. Does xoroshiro variants work for me? Yes. Do PCG variants work for me? Some of them probably do, it's hard to see under the pile of bullshit on the projects homepage. Are they way slower than xoroshiro? Yes. Why should anyone bother then?
I think you're confusing memory access and a memory allocations. Memory access patterns is one of the most important things for optimizations, for sure. But I was saying that the _overhead_ of allocating smaller chunks vs one big one isn't as big as people make it out to be. Of course if you have a 1000 allocations vs 1 that would make a huge difference... But trying so hard to modify the code to group allocations together ends up being a mess with not much benefit.
Before anyone makes a fuss: this is the announcement, not the video; the conference is in September.
Please tell me that you still have 0. measure and 5. measure
*looks at username* *looks at* [*youtube*](https://youtu.be/QTLn3goa3A8?t=15m22s) ಠ\~ಠ
[We already have that](http://slashslash.info/petition/)
I am somewhat conflating the two, but not entirely by accident. The more intermediate wasteful copies you do, for example, the more you will thrash the CPU cache with the copies of intermediate objects, evicting other useful stuff. You can consider that a memory access problem because you are accessing more stuff out of cache, but it's a memory access problem that you can fix by doing less allocations. Likewise, if you fragment memory on the local NUMA node, the allocator will be more likely to allocate a large segment on a remote node. All the stuff you access from the remote node will be slow, so it's definitely a memory access problem, but it's also one caused by allocation problems. And once memory is all fragmented to poop, you wind up just spinning waiting on kswapd for multiple ms while you wait for you malloc to return. It also depends on the problem domain (like most things). If the memory you are allocation is involved in a buffer on a GPU, the process of allocating it may require a slow round trip across a PCIe bus, so many small allocations would be a lot more costly in that kind of exotic scenario than when the bookkeeping data for an allocation all lives CPU-local. But you are probably right that there are a bunch of people who are inheriting some wisdom from an article from the bad-old-days without measuring and seeing if any of that crap actually applies to their use case. Measure Twice - Cut Once certainly applies! My perspective is heavily colored by working at a place where we are constantly running up against that crap. The last talk I submitted to a conference was even about how malloc is evil and hates you. :)
I thought that was implied with &gt; This is only the most basic advice on optimization.
Well it seems that there is going to be a clean up of the STL with less exceptions when preconditions are violated since contracts will handle it.
Interesting! I'm a game dev, and we definitely use unity files pretty much always. In the past, we had great success with a similar solution, [RudeBuild](https://marketplace.visualstudio.com/items?itemName=Trass3r.RudeBuild). I hope this built-in solution work for all target platforms as RudeBuild does (PS4, Xbox One). 
Do you manually set up the size as well?
You're going to find this hilarious - but I realized the other I didn't compile it with -DCMAKE_BUILD_TYPE=Release and we went from 2.5 minutes to 0.5 minutes
Assuming the allocation (but not initialization) is ensured by `reserve`, and your type is trivially constructible, I'm pretty sure it is not UB.
There's a few ways this can go wrong. A) when the size of a vector is 0, it's `data()` is allowed to return `nullptr`. Most implementations still return the backing data, but they don't have to. B) Dereferencing unconstructed objects as if they existed is not allowed. Again it "works" on most compilers, but it's not technically legal. You could get away with it for `char` and `unsigned char`, because those types refer to raw memory, but anything else is a no-go. Now that is a "bit" of a lie. You could technically get around point B) like so: std::vector&lt;float&gt; x; x.reserve(10); new (x.data()) float[10]; x[3] = 0.5f; 
Are there any classes that stood out to you?
It says P0912R2: Merge Coroutines TS into C++20 working draft Adopted, does that mean we will get Coroutines in C++20 ? I thought there were two competing papers.
It's pretty straight forward. Just try changing your build settings to \`--std=c++17\` and see for yourself. Better template type deduction is probably the first thing you'll notice when you start writing code.
No matter what kind of user you trying to be, there always will be directories you are not allowed to read. Directory listing is never exact, it is always partial - at the time you finished traversal, some new entries can appear, some disappear. So if you can't enter some directory, who cares? (I'm not saying there should be no API for those who do). It should not throw by default. In fact [Python](https://stackoverflow.com/a/120701/5050343) does not throw, [Rust](https://doc.rust-lang.org/nightly/std/fs/fn.read_dir.html#examples) does not throw. I have 10^6 files on my disk, program written in modern C++ chokes on 3rd file. Then it produces unreadable and unhelpful message. This one simple example (FileSizes.exe) shows quite a lot of problems in current C++. There is no way `sudo` can fix poorly designed std::filesystem.
The fun thing is that a placement `new` on raw memory can do nothing at all for core types. And yes I know it is UB in general, but on a specific implementation (that you now because it's template code) it can very well work. Just curious, but is there any implementation where using uninitialized memory you own would not work? I'd say as Linus puts it, if the standard makes something UB while any sane implementation makes it defined, the standard is "wrong".
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/8vpfqv/best_book_for_beginners/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
The standard being wrong (or more specifically incomplete) is the most likely scenario here. There's actually a proposal to make the spontaneous creation of instances a formal part of the language. http://open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0593r2.html
If you are aware of an algorithm that achieves that in `O(n lg n)` time without consuming extra space I'm sure a lot of standard library implementers would be interested :) Looking here: https://en.wikipedia.org/wiki/Sorting_algorithm All the following algorithms that are O(n lg n) and stable consume O(n) space: * Merge sort * Timsort (because it's a merge sort) * Cubesort * Binary Tree Sort There is a claim that "Block Sort" works without extra space, but the description I see on its page seems to indicate it requires extra space as well (and even if one accepts the claim that the `sqrt(N)` buffer can be considered "constant", the complexity analysis seems incorrect because it assumes the internal inplace merge operation is O(n) but it looks like the classic O(n lg n) inplace merge algorithm to me....).
Minor typo: it's `-std`, not `--std`
There are some parts where I'm not familiar enough with standardese to be sure I understood, but it seems to be a good proposition. The fact that it works in C is a big argument as well (and since the beginning).
Block sort is implementable: actually it uses extra memory as available, but uses a stable in-place merge algorithm described by Kim &amp; Kutzner to merge with internal swap buffers instead when no extra memory is available. Just like the current implementations of std::stable_sort it takes advantage of any extra space allocated but can work with the stack only. A quality implementation (a bit different than the algorithm described by Kim &amp; Kutzner) can be found on Github under the name WikiSort. IIRC it's under a permissive license :)
Just because something compiles doesn't mean it's correct 
Calling an out of bounds operator[] is UB as by the standard library specification period. In practical terms this may result in crashes on debug builds as iirc some standard library implementations perform bounds checks in debug builds. Also, any growth of your vector will destroy your data and it doesn't follow on copy construction. The question that comes to mind: If you use a vector in that way, why not just use a std::unique_ptr&lt;T[]&gt;?
The problem is not writing to uninitialized memory it simply violates the preconditions on `operator[]`
I'm with Tony on this one. The problem with calling an ADL `size(std::customization_point{}, blah)` is that overload resolution will happily select your unrelated `template&lt;class... Ts&gt; void size(Ts&amp;&amp;...)`. (`size` here being a stand-in for "whatever is the next common name to get stomped on by the STL." Obviously [no sane programmer would ever name a user-defined function `size`!](https://quuxplusone.github.io/blog/2018/06/17/std-size/) /sarcasm) Whereas I think we can say, non-sarcastically, that the only reason to ever user-define a function named `std_size` would be for the purpose of customization. That makes it the better choice. It has unambiguous *intent*. Very minor bonus point: The name-mangling of `my::std_begin(const T&amp;)` is much shorter than the name-mangling of `my::begin(std::customization_point, const T&amp;)`. [`_ZN2my9std_beginER1T` vs `_ZN2my5beginESt19customization_pointR1T`](https://godbolt.org/g/ddyTqk).
As a developer trying to get my org to adopt Unity files, IDE integration sounds great. It will solve most of the complaints. In manual testing I've been *very* impressed how quickly Unity files compile. 100+ cpp files combined in a Unity take about twice as long to compile as *each individual source file*. That's about a 50x speedup in my testing. If this VS feature allows me to easily build source files individually when I want and also automatically bundles them, it only leaves a few concerns: 1. Can the compiler detect source issues likely to cause Unity problems? Such as #defines or conflicting static symbols? 1. Can I use Unity files with the older build tool-chains? And of course the granddaddy of all C++ questions, can I somehow use this to reduce linker time?
Shipped a few games using SBA custom allocators adapted for a custom memory manager.
It is definitely UB. `operator[]` requires a valid index. An implementation could e.g. throw on invalid indices. Or it could assume i &lt; v.size() and have all sorts of "wrong" optimizations done because of that.
&gt; because you can do all of that without (ab)using a callee precondition to perform a check that the caller is perfectly capable of performing. Sorry, but I absolutely disagree: Yes, calling `std::vector:: at` with an out of bounds access should be considered a programming bug and be fixed. That doesn't mean that extra line of defense can't be useful. Now what you proposing is that instead of performing the range check at a central place (the callee) and thus ensuring that it is checked everywhere, you want every call site to perform the check - hopefully in a correct manner and thus making code less readable. &gt; But relying on the callee to perform a test on a precondition on behalf of the caller I didn't say anything about relying on. Ok, in the case of `std::vector::at` you can rely on it, because it is guaranteed by the standard, but strictly speaking an out of bounds index is not violating a precondition anyway due to this guarantee. Again, the reason to let the callee perform a check instead of the caller is less code duplication, simpler code at the callside and less chance to get it wrong. That doesn't mean that contracts aren't immensely useful, either as an replacement for `assert` or on functions, where currently no check is performed at all (i.e. `std::vector::operator[]`). I just don't see them as a replacement for exceptions and I even less see that "the industry agrees on...." &gt; even though only some call sites may be lazily relying on the behavior Just to make sure I understand you correctly: Is a codebase that doesn't check `std::variant::valueless_by_exception` everywhere lazy?
if you replaced them with standard versions, would performance decrease significantly?
My low level component often doesn't know, ifI want to lug and exit the whole program or just reload that specific component. Also, I don't want to make my nice generic container depend on whatever logging framework my current application uses. The idea that a lie level function doesn't know how to handle am error is the whole permisis behind exceptions. If I can handle the error directly, or 1-2 layers up, there is no reason to use exceptions in the first place.
Good question. We haven't tried that but it would definitely be interesting to do at some point.
An implementation can't throw because it is `noexcept` and there is no sane reason that would make you make a slow version when there's `at()` for that.
Is there not a physical limitation to this on the hard disk as there is only one needle reading from the disk but you have multiple threads trying to read files on the same disk?
It can throw because the behavior is undefined
Nevermind, I see now that you read all your files into memory which I would say is not very scalable. Imagine an image database which you want to count the number of "words".
Your rotation is problematic for the general case (eg. k=0). Just as a warning for people that might want to copy this code.
I really hope modules are going to do to C++20, we need them badly.
&gt; The initial contemplated step, definitely not for C++20, would be to change the default new_handler from throwing bad_alloc to calling terminate. That might sound like a big change, but it’s not. That's a pretty huge change, and you all *are* crazy for considering it.
&gt; You get to install your own violation handler and ship a release build with the option of turning on enforcement at run time. I assume the main executable owns the violation handler? If so, assuming I dynamically load libdecryptbluerays.so (a library that is written in shiny new C++20), can I override that libraries contract handling and so potentially extract DECRYPTION_KEYS? What's the difference between a violation handler and an exception handler?
I'm part of aCurrently maintaining a large codebase and we recently moved to C
&gt; Networking: This is pretty much ready except that it depends on Executors. Soon after Executors are ready for C++20, Networking is ready to slide in right behind it. There is no reason for this dependency.
would it take more than 5 minutes? do you depend on allocator's implementation in other ways than performance?
With standard containers?
However note that the rotation function is specifically intended for the compiler to recognise and replace with a single cycle `rot` opcode, and handling the zero case may interfere with that optimisation on some architectures.
I don't think brains work quite like CPU caches!
Yes. Mostly just went with the defaults to fall through to the engine memory manager. There were a few cases where a small block allocator made the most sense, so passed that along as a parameter. Usually decided after perf analysis and starting on optimization. Oddly, container operations usually aren't the bottlenecks that get the biggest performance gains (in games). I have seen that once in my career, using a map instead of a hash map for O(N^2) operations, but that was just the wrong algorithm, not a problem with the allocator used.
Ok, so if JSF is twice the speed of PCG, xorshift or xoroshiro, then really its only major limitation is the 2^32 seed possibilities i.e. there can only be 2^32 possible random streams. I think that a fine tradeoff for performance for the use cases I will ever have. Thanks for the testing and feedback. Good to know all the work I invested a decade ago in choosing JSF has paid off nicely, indeed I may go poke WG21 to add JSF to `&lt;random&gt;`, it'll be a short proposal paper, easy to get through.
I'm currently working in a team that maintain a 1+Mil loc codebase and we recently upgraded from C++11 to C++17. The main issues that took us time was upgrading our dependencies to the latest versions and squash the few regressions. Overall, it was fairly straightforward and took us less than 2 weeks, which is way way less than what it took to do the 98-&gt;1x move, for a net gain everywhere : compile time, run time, stability and day to day quality of life.
Came across this article today, and while the text and background colors are horrible I think the point of view is very well stated and balanced. http://www.humus.name/index.php?ID=383
Hi, Thank you for sharing the post. Can you please let me know how can share my profile for scrutiny ?
Shifting by more than 32 is undefined and broken on other architectures. ¯\\_(ツ)_/¯ It's a pity that rotation is a standard operation on all architectures, but C++ has no easy way to express it.
You are either lucky that you started doing C++ programming in this decade, or completely biased... You have no idea how many companies are stuck with old C++ code and can't easily switch to the latest (say C++14)! Sociomantic is not stuck - they use the latest stable version of D. You complain about Sociomantic using 10+y old D tooling - how many companies are using C++98 ??? Answer: THOUSANDS!
You are either lucky that you started doing C++ programming in this decade, or completely biased... You have no idea how many companies are stuck with old C++ code and can't easily switch to the latest (say C++14)! Sociomantic is not stuck - they use the latest stable version of D. You complain about Sociomantic using 10+y old D tooling - how many companies are using C++98 ??? Answer: THOUSANDS!
Proper test (multiple platforms/compilers, workloads, etc) will definitely take longer than 5 minutes. I did a quick test by replacing just `small_vector` (which in our case is the most commonly used by far) and see about 12% speedup on the build system's up-to-date check. Interestingly, the build with `std::vector` also has much higher variability while the "small" build is pretty consistent. This is, BTW, with GCC 7, `-O3` on a Linux machine.
Yes, if they're trivial, they're now enabled for constexpr.
Sure they can! **https://github.com/dlang/DIPs/pull/126**
Agreed. But the proposal authors want it to be so, so there it is.
There was once a proposal for `&lt;&lt;&lt;` and `&gt;&gt;&gt;` operators to implement rotation, but it's that brokenness is the problem. Different platforms are very inconsistent on what they implement. That said, if somebody proposed a paper with `rotl()`, `rotr()`, `bsf()`, `bsr()` along with standardised editions of all the other popular builtins, I'm very sure it would be quite warmly received.
Are you adding one for Q3 soon?
Yes, the other parts of the function allocate memory.
nice, thanks :)
Why did the committee decide to make this important part nonportable? 
I was more hoping for the same semantics as with regular functions: If it doesn't do anything "non-constexpr" for the given input (in this case the object value), it can be called in a constexpr context
C++ doesn't necessarily talk about how shared libraries work. What they currently allow you to do already allows you to extract keys &amp; passwords from a local copy, even without any contracts mingling.
You need to use share button on godbolt for anyone else to have a chance of looking at your code.
I don't question implementability, I question the complexity analysis. For example, Kim's paper claims that classic merge requires O(m+n) space, but classic inplace_merge requires only O(min(m,n)) space for linear time operation. Things like that make taking seriously other claims in the paper difficult. In the nonlinear case i think the classic divide and conquer algorithm needs something like O(n (lg n / bufferSize)) time (though I'm squinting through the Master Theorem here as it is 2AM for me) because it switches to the linear algorithm once the bufferSize &gt;= min(m,n) condition is satisfied. T(n) = n &lt;= bufferSize ? n : 2T(n/2) + n. sqrt(n) grows faster than lg n, so with the proposed sqrt(N) buffer, I think the classic algorithm is linear, but I'm not positive. I'm clearly not being super rigerous here of course; practical demonstrations of faster algorithms welcome.
If you go read the documentation on std::vector in the Template parameter section it says, "The type of the elements.T must meet the requirements of CopyAssignableand CopyConstructible." https://en.cppreference.com/w/cpp/container/vector
Oh, sorry I misunderstood your doubts. I'm no computer scientist so I won't be able to help you with double checking the complexity analysis of the algorithm.
Thanks, fixed that
I believe it is true only pre-c++11, since I can construct the vector just fine in the code sample.
You may want to use *the algorithm* [std::move](https://en.cppreference.com/w/cpp/algorithm/move).
Question is not about what to use to copy elements of vector, but rather why this particular example does not compile anywhere but MSVC
Having a GC is pretty desirable for a lot of code. But we're now recognising use cases where this is not the best tool for the job. After all, D started as Walter's retirement project ;)
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
Correct me if I'm wrong here, but doesn't dereferencing `std::vector::iterator` return a reference? If that's the case, the compiler must invoke copy assignment to convert `T&amp;` into `T` type.
Did not read the proposal, but without any graphics - 2D or not - where should the web_view be hosted? In the console using ASCII and line drawing characters? :)
&gt; Exception handlers are a sub-optimal way to go about that kind of error response approach . At the point of the error you have a lot of potential forensic information, including the stack (and all its contents) as well as any other transient application state that may be pertinent. I mean... most of the time in production software you strip your symbols anyways so it's not like you are going to get anything meaningful, but at least the user of your software has a *chance* to have an emergency backup save being saved somewhere. The software I work on has a global catch-all handler in the main on release mode, and it's one of the feature most of my users have thanked me for - in four years, there was maybe one or two occurences of really bad corruptions that fucked up everything but 99% of the time, it works and allows the user to recover everything he was doing, except maybe the very last action. 
The plan was the standardize it later if a need for it arise.
There are two almost orthogonal sides to this: on one side is standartisation process, on the other is compiler support. Practically speaking, we should be more interested in the latter. Personally I'd much prefer TS with good support from compiler vendors to IS feature with bad support (like, say, C++17's PMR is right now). Clang and MSVC claim to have modules support for a while (I think they both mean TS-ish modules now?), but frankly I found it lacking. E.g. i couldn't even get sample code from p0909r0 paper to compile on either, and I've saw failed assertions on clang side and ICEs (saying "not implemented") on MSVC side. Maybe current level of support works for some projects but apparently it is unusable for my usecase for now. Now, say some miracle happens and next trip reports say "modules are in IS today!" - it won't change anything for measly developers like myself. There still won't be proper support in compilers - or any in gcc case, still won't be any support is buildsystems (build2 excluded) etc.
As far as I am aware, this is right now not the case. But it's looking very possible that constexpr vector will make it into C++ 20, and if so, non-trivial constexpr destructors become a necessity. So, give it another two meetings maybe.
How does allocating the memory for a pool allocator end up having a noticeable speed impact? I'm genuinely curious about it - I understand your allocator and that it gives you a lack of initialization while keeping the benefits of a vector over something like malloc, but I haven't ever seen trivial initialization make an impact. 
I wouldn't say they're completely orthogonal. Being standardized means much less room for change. TSes are still subject to change before going in. That risk of part of the work to implement the TS becoming obsolete for the final version can be a deterrent for spending the resources to support the TS. There's also going to be a group of people who feel that supporting a non-standard TS before finishing standard support is bad prioritization. It seems reasonable to me that both of these could cause the orthogonality to decrease.
You can read the [actual proposal](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0380r1.pdf) for the why. The example it presents is security-related.
This looks a lot like [Boost.Lambda](https://www.boost.org/doc/libs/1_67_0/doc/html/lambda.html) and [Boost.Phoenix](https://www.boost.org/doc/libs/1_67_0/libs/phoenix/doc/html/index.html). Have you run into those before?
So it looks like I have reinvented the wheel. I was not aware of those libraries, but boost seems to have everything.
It's the creation of the pool itself that is affected. With default initialization (no memset) it becomes a O(1) process, instead of O(N) which std::vector will have by default. http://quick-bench.com/TUeOFWzH2CUmdkkJr0e1frVFKCI
Operator[] is not noexcept? https://stackoverflow.com/questions/20517259/why-vector-access-operators-are-not-specified-as-noexcept
Now also available in Embedded flavour: https://meetingembedded.com/News/items/Embedded---Arduino-User-Group-meetings-in-July-2018-.html
&gt;And of course the granddaddy of all C++ questions, can I somehow use this to reduce linker time? sure! Imagine the following scenario: compiling the same inline function from a header (perhaps a template) included in 100 source files - then the linker has to remove 99 of the identical weak copies of that symbol. If however you build those 100 source files as 8 unity files with 12 or 13 sources in each - then there are only 7 copies for the linker to remove. I bet there are other reasons for unity builds to link faster - this is just 1 example. Also unity builds can be done with any build system - it's just that some build systems support them "out of the box" - such as FastBuild and Meson. There are also CMake modules like \[cotire\]([https://github.com/sakra/cotire](https://github.com/sakra/cotire)) Perhaps I should do a blog post about unity builds in depth...
Yes I realize that, I understand what you are doing and why. I'm just not sure what scenario leaving out memset would actually be a better option than just taking the creation of the memory pool out of an inner loop. Whatever the size, if any non-trivial chunk of the memory is going to be used, the time to use it should pale in comparison to the memset. 
It's a good instructive exercise. It's definitely how I accidentally started with template programming.
In your examples: `auto derived = static_cast&lt;Derived&amp;&gt;(*this);` will copy Derived. Either do auto&amp; or use a pointer. 
I've mostly encountered and solved this problem in the context of strong typedefs; the variadic CRTP is used to specifically grant the strong typedef functionality by forwarding to the underlying type. The thing is that with strong typedefs, even if they have the exact same set of skills, they still need to be distinct types. That means that if a user wants to declare a strong typedef `MyType`, you actually need to create some kind of "tag type" anyhow to ensure that it's distinct. You could put this on the user, but it's pointless and error prone. So I had a macro like this: #define STRONG_TYPEDEF(NAME, UNDERLYING_TYPE, ...) The ... are the skills (I called them policies) of the strong typedef. So, STRONG_TYPEDEF(MyType, int, Addable); Would expand to something like: template &lt;class T&gt; struct MyTypePolicy : Addable&lt;T&gt; {}; using MyType = StrongTypedefTemplate&lt;MyTypePolicy&gt;; If not for the distinctiveness problem, I'd probably use the solution you recommend.
Yes. It's based on that proposal. In fact the author of that paper is a co-author of this one. Even better, everyone that has a "terse syntax" paper has in some way co-authored this. This seems like a very strong contender terse syntax in Concepts. This is great, we might get a terse concept syntax i C++20 after all!
&gt; pointer Kittens dead 😥😥😥😥😥
Boost.HOF and Boost.Hana also have (lighter) implementations.
My bad, you're right on this.
I would also be pleased to see same example having added *progress feedback* and *possibility to cancel*. These two features are often overlooked but are real requirements in real-life applications.
&gt; I'm just not sure what scenario leaving out memset would actually be a better option than just taking the creation of the memory pool out of an inner loop. The tfact that I can Re-architech an application around a limitation of the default (and overridable) behavior of the standard library is not exactly a strong argument. &gt; Whatever the size, if any non-trivial chunk of the memory is going to be used, the memset should pale in comparison to the time to use it. This assumes that you will be using the entire pool of memory, which is far from a given. But I'll indulge you and create a more specific example: Let's say I have a gaming application, I need to fetch about 2Gb of data from files to load a level, and I want to use std::vector&lt;char&gt; to manage the load buffers because I like RAII and not reinventing the wheel. Getting rid of these memset() would remove at least 0.5 seconds of load time (and probably more with TLB thrashing taken into account), which is easily worth the trouble. 
Yes from a quick read it looks very nice. I'm rooting for this
&gt; If you use a vector in that way, why not just use a std::unique_ptr&lt;T[]&gt;? Because I need to track/propagate the size of the allocation, I'm not going to create a `struct {std::unique_ptr&lt;T[]&gt; data; std::size_t size;};` with a full set of iterators when `std::vector&lt;T&gt;` has exactly the interface I want already.
That'd be great. Thanks for the heads up
Raw pointers are fine if they don’t have responsibility to call new and delete
a codebase should almost never check valueless_by_exception
I see all those methods called on placeholders are actually *implemented*, e.g. to do `_3.size()` one had to add constexpr auto size() const { return ::Magic([f = this-&gt;f](auto&amp; tup) { return f(tup).size(); }); } Is it possible to have this without such forwarding helpers?
Nitpick: They are fine as long as they do not imply ownership, shared or otherwise, even transiently.
**Not** fine if they do not mean "this can be nil" (case here). I have seen enough of code involving pointers that checks them for nil but they can't ever be and vice versa. Screw that crap code.
Can we stick to a concrete example? `vector::at` isn't a good example, because it throws, and will probably continue to throw in the future. That is why the function exists at all. So `vector::operator[]`. What are you suggesting? I think the committee is going in the direction that it continues to have UB, and it will probably have contracts of some kind on it. ? 
...And their lifetime is guaranteed to be wholly within the lifetime of thing pointed to.
Good point
The reason it needs to be in The IS is so that different vendors start implementing the same version of modules. Afaik clang's modules are completely different from the TS, which followed the implementation in msvc or vice versa (I think gcc also started to work on the TS version). There is little motivation for a vendor to create a production quality implementation, if the design has to significantly change once it is in the standard.
Nitpick: And the lifetime of **their assignment** is guaranteed to be wholly within the lifetime of thing pointed to. :P I can go all day. (yes, I know lifetime of assignment is not a thing, but you know what I mean)
Serious question: do you actually use `std::optional&lt;std::reference_wrapper&lt;T&gt;&gt;&gt;` in production? I have yet to see it in the wild.
Looks great to me :-)
Hsutter was talking about replacing exceptions with contracts for signaling pre condition violations that is what I'm disagreeing about and the only two examples from the standard library that came to mind where this change could be applied were `at` and operations on variants. `std::vector::operator[]` doesn't currently throw exceptions and I explicitly said it is a good candidate for adding precondition checks via contracts. 
&gt; there is no sane reason that would make you make a slow version when there's at() for that. Sure there is: debugging. $ cat oob.cpp #include &lt;vector&gt; int main() { std::vector&lt;int&gt; v; v.reserve(10); v[3] = 5; } $ g++ -D_GLIBCXX_DEBUG oob.cpp $ ./a.out /usr/include/c++/5/debug/vector:409: Error: attempt to subscript container with out-of-bounds index 3, but container only holds 0 elements. Objects involved in the operation: sequence "this" @ 0x0x4021c8 { type = zsh: segmentation fault (core dumped) ./a.out Or $ /opt/llvm-svn-2017-12-16-lto/bin/clang++ -stdlib=libc++ -Wl,--rpath=/opt/llvm-svn-2017-12-16-lto/lib -D_LIBCPP_DEBUG oob.cpp $ ./a.out /opt/llvm-svn-2017-12-16-lto/bin/../include/c++/v1/vector:1503: _LIBCPP_ASSERT '__n &lt; size()' failed. vector[] index out of bounds zsh: abort (core dumped) ./a.out and whatever MSVC's is (I can't check that quickly).
That's why we have unit tests, system tests and integrated tests right? .... right!?
/u/hemenex &gt; ... and other lies programmer tell themselves.
😀. At least you figured it out. I have spent way to much time tracking down performance issues caused by a non release build. 
&gt; The fact that I can re-architect an application around a limitation of the default (and overridable) behavior of the standard library is not exactly a strong argument. I wasn't making that argument, I was asking a question. I suppose the answer in your case is that would be more trouble to hoist the allocation outside of hot loops.
No, because you cannot overload operator. and even if you could it works differently than others (some you can't even to it for operator-&gt;)
My point is that I do not have to even ask myself the question whether hoisting the allocation out of the loop is worth the trouble or not. There is no tradeoff to be made here. I can have my allocation as close as possible to the point of first use AND not incur any additional overhead, why would I spend time wondering if an alternate design would also work?
You can find the description of the insecure variants in the [documentation](http://www.pcg-random.org/using-pcg-cpp.html#insecure-generators). Criticizing a problem of a single pcg variant (that is also pointed out in its paper) without actually naming the variant and therefor implying a general problem with pcg, like you did, seems quite some bullshit to me... I have to wonder if picking this variant (instead of the recommended ones) in vignas comment was exactly for this reason. Vigna is also known to [exaggerate the qualities](https://lemire.me/blog/2017/09/08/the-xorshift128-random-number-generator-fails-bigcrush/) of his rng. So, by your standards, you should probably look for something else.
Unfortunately, variant, at least valueless_by_exception, isn't something you can pre-check - you don't know if a constructor will throw until you call it (ie U's constructor when switching a variant from a T to a U). So maybe we don't _have_ a good example. The committee will look at each replacement case by case. I can imagine that we say "but this will break people" for a lot of things, and not change old classes, but at least have a direction for new classes.
* Eliminate header files - That seems to be the point of modules. (Note: It wasn't the original point, but that seems to be where people are taking it now) * Assignment always being move. - How would that even work? That would be a fairly radical departure from literally every common imperative language. Just glancing through a single function in my codebase and I see this as \_awful\_. * Just no... std::array is downright required for a huge swath of what C++ is used for. std::vector is "the performant one". Arguably std::forward\_list needs tweaking to be "the other performant one". And then you want some hashed container, but probably std::unordered\_map or \_set. std::list is only kept around for CS101 courses and people who don't know any better. * This should be done as part of modules. * Meh?
&gt; My point is that I do not have to even ask myself the question whether hoisting the allocation out of the loop is worth the trouble or not. There is no tradeoff to be made here. Well... more allocations are going to be slower, but I think in general you are right, I tried memset in tcc (windows libc dll) and it was much slower than I expected. 
I meant something like following: [](auto x) {return x.size();}(vector&lt;int&gt;{}) I still can define lambda which calls `size` and it doesn't need any *proxy*. I.e would this `(_3.my_method())(MyClass{})` work? Provided I have class with corresponding method.
No matter, which is "better", vcxproj forces me to use Visual Studio IDE which drives me angry as I just don't like it, and I always want to have a choice.
Nevertheless, great work!
Please do not do what almost every other language has done to support "unicode". "code points" are not "characters", and treating them as such is literally worse than nothing.
Thanks for that cotire link, didn't know something like it existed! As for reduced link times, you got it right. Basically it's about saving the linker time parsing similar export symbols from multiple object files. Reduce the number of object files, and we reduce the link time. 
I've been trying side-channel attacks on Chandler's system, to get an early copy of the slides at least, but no success. All I have so far are Chandler's credit card numbers and google source code. Nothing worthwhile.
You would have to do a method in `Magic` similar to the `size` method. The only problem is that you cannot make it generic, because names of identifiers cannot be templated.
Thank you, I was originally inspired by scala's functional features, especially using placeholders to form partially applied functions. I think it's a very intuitive and powerful syntax (though would be breaking for C++). Although I feel a little bad that I posted something that I could have found with a little reaserch I'm happy that my approach wasn't complete rubbish.
Thanks for the list. I got the following when I clicked the link for Las Vegas: # The page you're looking for doesn't exist The link you followed may be broken, or the page may no longer exist.
Beware that constexpr member functions are not const by default starting from C++14.
Are others interested in a C++ meeting in the St. Paul/Minneapolis area? A few years ago a C and C++ meeting started here. Now it seems they have turned into a C, C++, assembly, embedded, and OS development group: [https://www.meetup.com/TwinCities-C-Meetup/](https://www.meetup.com/TwinCities-C-Meetup/) While that could be an interesting group, their last meeting was on Go (golang). :( I think the future of C++ is bright. If you're interested in a more focused meeting than what's currently available, please let me know.
Seems to be a bug from meetup, as I do read their ical files. And I do refresh the list before posting. Link for Las Vegas: https://www.meetup.com/The-Las-Vegas-C-C-Meetup-Group/events/251625091/
Yeah, Vigna doesn't address the 'don't multiply by 57 or any number whose lowest byte is 57' issue.
Honestly the biggest issue I've had so far is third-party libraries that don't support C++17 (or only support it in newer, non-backwards-compatible versions than the ones you're using). All the issues that arose in our own codebases were pretty simple to fix. auto_ptr usages can be resolved by a simple search-and-replace with unique_ptr in the majority of cases.
In the perfect world yes :(
You may want to have a look at `boost::spirit::qi`, which takes this concept and runs with it to a frankly silly level.
If one wants to write a UI based on web tech, just embedding an HTTP (+ websockets) server seems like a more tractable problem. The user can use whatever browser they have (which has a much better chance at receiving timely security updates compared to any embedded browser engine). I don't particularly think either belongs in the C++ standard though.
So fun ways to improve this. 1) Make `operator+` a friend function. 2) Write a macro #define RETURNS(...) \ noexcept(noexecept(__VA_ARGS__)) \ -&gt; decltype(__VA_ARGS__) \ { return __VA_ARGS__; } now we can do: template &lt;typename LhsFuncT, typename RhsValueT&gt; constexpr auto operator+(Magic&lt;LhsFuncT&gt; lhs, RhsValueT&amp;&amp; rhs) { return Magic([lhs, &amp;rhs](auto&amp; tup) RETURNS((lhs(tup)) + rhs)); } and we get `noexcept` and SFINAE out of it. (There is a proposal to add something directly to C++ that does this). 3) Your `operator+(..., RhsValueT)` has a danging reference to rvalues. You need to store if rvalue (or just store) the rhs. 4) The bodies of `operator _( Magic&lt;Lhs&gt;, Magic&lt;Rhs&gt; )` are almost identical. I'd pass `std::plus&lt;&gt;` to a helper method in `Magic`. Even the + non-magic operator can do this. 5) You can decouple `.size()` from `Magic` by using smart member pointers. Write a `smart_mem_fun` type: auto size = smart_mem_fun([](auto&amp;&amp;x) RETURNS(x.size())); now have it support `(Magic&lt;?&gt;-&gt;*size)()` by overloading `operator-&gt;*` (or, with a bit of operator abuse, `Magic-&gt;&lt;?&gt;-&gt;size()`). You can now write member function extensions to `Magic` without adding it directly to the `Magic` class itself. `-&gt;*` can also be extended to support `std::variant` (and invoke `std::visit`). I've even written super_any&lt; &amp;size &gt; any_with_size; to automatically create a `std::any` that guarantees anything stored in it supports `-&gt;*size`. 5) You need to start walking down the path of monads. Monad-bind, return, etc. The syntax and patterns of monads will let you generate an even more expressive kind of operations. 
What I don't like about CMake is that it offloads responsibility to the user so now I have to run even more commands to get someone else's package to work. What a horrible mess. And for some reason these developers expect me to know how CMake works to make their products work, and so here I am. God dammit.
Minor request: can you put the date in the Reddit post subject rather than "tomorrow" so that it's easier to figure out? Love the show :)
I don't remember the last time I saw a raw pointer implying ownership outside of Qt code and interfaces with C libraries.
no issues, but being able to replace metaprogramming recursion with fold expressions has allowed me to shave a few megabytes out of debug executables all while reducing compile times.
Sure, go for it :) Organizing is fun, and gives you many interesting contacts...
&gt; My low level component often doesn't know, ifI want to lug and exit the whole program or just reload that specific component. Also, don't want to make my nice generic container depend on whatever logging framework my current application uses. Of course not. Nobody is suggesting that, either. The idea for putting such things _in the standard_ is that there'd now be a standard way for all code to raise an error and for exception-using apps to throw and for exception-free code to invoke a handler supplied by the application or to return something like an `expected` (which itself might throw in exception-using code). No need to modify containers or make them specific to applications. &gt; EDIT: Regarding the forensic information: If you do want to gather that information, you can put it into the exception. No, not really, for all the reasons you just stated. If the container _doesn't know_ about its contextual state (because it's generic) how can it put that information into an exception? How can it put a whole memory dump into the exception? How can it know to grab a copy of the scripting language's stack trace (and not just a "standard" C++/machine stack trace) before throwing and unwinding through an interpreter call? The only information you can put in a C++ exception is the immediately local information. Worse, putting a *lot* of information in there (like a full trace) just because someone *might* use that information in a catch handler is a violation of pay-for-what-you-use and just makes all that hypothetical "exceptions are fast, stop avoiding them" nonsense obviously untrue. :) 
This is the top-level comment for **meta** discussion. Reply here if you have questions or concerns about this post.
Good points, thank you. Ad 3, i have done it when I tried implementing some range-like functionalities earlier, but it was a lot of boilerplate and double the current code. Ad macros, I have never been doing hardcore metaprogramming so I never really use them, but i should probably learn them properly for such cases.
Has there ever been a TS with a faithful implementation by major vendors, before it was moved to IS?
What about sub-string operations where pos &gt; size()? They currently throw std::out_of_range. Will they be turned into noexcept with contracts?
I am curious what the use cases are? I am a scientist who does computational and machine learning work. The added speed sounds nice, but the bottlenecks in performance I have experienced are usually with distributions. Still, I will try out xorshift and PCG to see how much time I save. Also, I am curious where the improvements on statistical performance would have meaningful effect on results? Off the top of my head, all I can think of are maybe some niche applications in very large Monte Carlo runs on supercomputers that may benefit from this.
I imagine that MSVC would implement it atop Edge.
If you need speed, give the small prng from Bob Jenkins
Ok, let's look at the documentation. &gt;They are compact, and are statistically excellent, but should not be used except in specialized scenarios. Ok, what is a specialized scenario? Any scenario where I expect it to actually not be completely useless? Feels like this can be rephrased as "they are statistically garbage, except for a few selected scenarios" without any loss of information. No, sorry, this is not a documentation. I expect something like a table with timings and a description of flaws if the author expects anyone to use this code in practice, otherwise the decision about using or not using is purely a matter of trust, which I don't have based on what the author is trying to do on the homepage. I'm not sure why people (both PCG's author and you) are trying really hard to pull xorshift into the conversation. It's not xoroshiro. I don't have to rely on author's empty promises (like in case of PCG), because I have [a sensible table](http://xoshiro.di.unimi.it/) and some sensible code that I can easily rerun on my machine (both for xoroshiro and competitors) if I have any doubts about the legitimacy of numbers, and flaws of each version are openly discussed. I don't care if Vigna made mistakes in the past. I am by no means an expert in the area of PRNGs, but even my limited knowledge is sufficient to follow the conversation between the two authors and understand their arguments. Looks like Vigna makes sense, and his opponent doesn't. Now, if someone was able to find actual problems in his new work (or misinformation on the website, or just ordinary bugs), that would be a different story. But so far I've seen none, except for some heavily biased BS from PCG's creator. Let's look at the [example](http://www.pcg-random.org/posts/a-quick-look-at-xoshiro256.html): &gt;8000000000000000000000000000000000000000000000000000000000000000 .. &gt;There are many similar state sequences. Here is another: .. &gt;0100000000000000000000000000000000000000000000000000000000000000 Let's think about what we are looking for. We are looking at 2 out of 256 neighborhoods of states where only 1 bit is set. 256, as in 2^8. Out of 2^256 - 1 possible states. If you are curious the probability of randomly getting any of them it is about ~2.2x10^-75. The probability of generating a seed that has one of these bad states somewhere within the next 2^64 random numbers is ~4x10^-56. Just for comparison, number of atoms in a Sun-sized star is about 10^57. Even if I'm off by an order of magnitude here, it's still irrelevant. Even if you have a huge cloud of machines, and each uses xoroshiro, it's still irrelevant. No human who spent some effort on proper initialization will ever encounter this state in practice. Just stop for a second and think about the truly astronomical scale of bullshit in that PCG's article. Picking a state with "quite a few" zeros wasn't enough, they absolutely had to find 2 out of 256 worst ones, and pretend that it's a typical scenario. I don't know about you, but I'm truly impressed. That's my new personal standard for maleficent deception.
I thought we talked about not making clickbait headlines for talks that are just being *announced*. 
\*\*Company:\*\* \[[www.zivid.com](https://www.zividlabs.com)\]([http://www.zivid.com](http://www.zividlabs.com)) -- 3D machine vision \*\*Type:\*\* Full time \*\*Description:\*\* Zivid creates a 3D video camera for use with robots in industrial automation. We are looking for a senior machine vision engineer. The detailed job listing can be viewed at \[[www.zividlabs.com/jobs](https://www.zividlabs.com/jobs)\]([http://www.zividlabs.com/jobs](http://www.zividlabs.com/jobs)). \*\*Location:\*\* Oslo, Norway \*\*Remote:\*\* No \*\*Visa Sponsorship:\*\* Yes \*\*Technologies:\*\* C++17, OpenCL \*\*Contact:\*\* Questions: PM or \[e-mail\](mailto://jobs@zividlabs.com). Applications: \[Online form(s)\]([http://zividlabs.com/jobs](http://zividlabs.com/jobs)).
maybe stuff like ensuring that a container is sorted before calling unique ? 
Anyone interested in a c++UG in Bordeaux, France ? (ping /u/Lectem)
No problems that went already flagged in c++11 mode. Replacing boost types with their std equivalent can take some time but that is a separate issue.
**Company:** [Optiver Europe](https://www.optiver.com) **Type:** Full time, Internships **Description:** At Optiver, a proprietary trading firm, we need the most advanced technology and continuous innovation to remain successful as a global market maker. We build high-performance software that is used by our own traders to trade a variety of financial instruments on exchanges. Our story begins in 1986, with a single trader on the floor of Amsterdam's options exchange. Today, we are at the forefront of trading and technology, employing around 1000 Optiverians of 40 nationalities across offices on four continents. ****Jobs @ Optiver**** We have opportunities at any level in your career! From graduate to years of experience. We are looking for exceptional engineers, who favour simple solutions for complex problems and have a passion for clean code and good architecture. Knowledge of financial systems is not required. * [Graduate Software Developer](https://www.optiver.com/eu/en/job-opportunities/eu-510831?gh_jid=510831&amp;gh_src=6c0pe11) * [Low-Latency Systems Engineer](hhttps://www.optiver.com/eu/en/job-opportunities/eu-1163402?gh_jid=1163402&amp;gh_src=7karyx1) * [Control Software Developer](https://www.optiver.com/eu/en/job-opportunities/eu-1206128?gh_jid=1206128&amp;gh_src=d0gtnc1) * [And more](https://www.optiver.com/eu/en/job-opportunities/) **Location:** Amsterdam, Netherlands **Visa Sponsorship:** Yes **Remote:** No **Technologies:** C++14 on Linux, next to that C#, Python and Lua and FPGAs also form part of our technology stack. Want to learn more, [watch our CppCon talk from last year](https://www.youtube.com/watch?v=NH1Tta7purM)! Although optimization is important, it's not the only thing to do and certainly not a must! **Contact:** Please e-mail Jinre van der Veen or Patrycja Ostrowska at recruitment@optiver.com for any questions. 
#### [CppCon 2017: Carl Cook “When a Microsecond Is an Eternity: High Performance Trading Systems in C++”](https://www.youtube.com/watch?v=NH1Tta7purM!) ##### 39,092 views &amp;nbsp;👍735 👎13 *** Description: http://CppCon.org—Presentation Slides, PDFs, Source Code and other presenter materials are available at: https://github.com/CppCon/CppCon2017—Automate... *CppCon, Published on Oct 8, 2017* *** ^(Beep Boop. I'm a bot! This content was auto-generated to provide Youtube details. Respond 'delete' to delete this.) ^(|) [^(Opt Out)](http://np.reddit.com/r/YTubeInfoBot/wiki/index) ^(|) [^(More Info)](http://np.reddit.com/r/YTubeInfoBot/)
**Company:** [Stash](http://stashcrypto.com) **Type:** Full time **Description:** We are looking for two senior engineers to maintain [Open-Transactions](https://github.com/open-transactions) and develop products based on this library. You will be responsible for creating products that bring financial disintermediation and autonomy products to individuals, as well as solve many classes of problems in online and traditional B2B commerce. **Experience** Required: * 5 years of C++ experience * Familiarity with modern (&gt;= C++11) C++ Desirable: * Familiarity with Bitcoin/cryptocurrency * Background in cryptography **Location:** Austin, Texas **Remote:** No **Visa Sponsorship:** No **Technologies:** C++17, Linux, Blockchain, ZeroMQ, Qt **Contact:** [Wire](wire.com): @hirowhite
Awesome! Thanks for the link.
Those are good examples, I think. Don't know if those will be changed, but I'd be interested in what others think - how would your code be affected?
Sorry, I'm not sure I'm following. What are we multiplying by 57 exactly? The output? Ok, how about picking any output of any other PRNG on the planet, and multiplying it by 2? Surely there is a test somewhere that will look at output numbers and say "dude, wtf, all your numbers are even, this is suspicious!" Am I misreading what is going with this "issue"?
"This ~website~ C++ code runs best in Microsoft ~Internet Explorer~ Edge." \*shudder\*
**Company**: DarkVision Technologies -- Downhole Imaging **Type**: Full Time **Pretty Pictures:** [**https://imgur.com/a/UOe3io5**](https://imgur.com/a/UOe3io5) **Description:** We make a variety of ultrasound logging tools that inspect oil wells across the globe, and the software to go with it. Some of my coworkers are doing crazy mechanical/electrical engineering with some robotics here and there. I'm in the software group, mostly working on visualization software (Windows, DirectX 12, Cuda, ImGui, etc.). Several of us have a game development background, and we have heaps of fun doing volume rendering of terabyte datasets. We also write the embedded pieces that run on ARM64 &amp; FPGA (PetaLinux) multiple kilometers underground. Although I might be able to drum up a job description, to be entirely honest; we're hiring smart people across the board -- so the main thing we're looking for is some decent C++ programming chops, an interest in doing visualization and or (buzz-word ahead) machine learning stuff (defect detection, improved signal to noise extraction, etc), and an ability to show passion about your profession during a casual interview. Come have lunch with us... **Location:** Vancouver BC, Canada **Remote:** No **Visa Sponsorship:** No **Technologies:** Cross-platform-ish C++ 14/17, for Windows and PetaLinux/ARM/Xilinx, using DirectX 12 and Cuda -- some of the libraries in our \`Libs\` folder are: ImGui, Glm, Stb, Catch, NanoVG, Embree, Eigen, AWS, Lengyel Slug, NLohmann Json, etc. **Contact:** [suter@darkvisiontech.com](mailto:suter@darkvisiontech.com) Don't bother with a cover letter. Instead, send me a resume and a way for us to instant-message (Slack, Messenger, Whatsapp, Skype, whichever), and we'll chat from there.
You forgot to put this thread on contest mode :)
std::edge
Leave it as is please. This way, I can sort and view the newest comment or post instead of having to search for the newest one.
This is intentional, as I promised a couple of threads ago. Let’s see how people like plain mode - if most people want contest mode back, we can do that next quarter.
Ahh okay :)
I could change the suggested/default sort to new.
FYI I ended up choosing yours @Veedrac, and you are credited in the paper. Thanks everybody for participating! Got to see some cool stuff.
I have a working prototype which will let you portably override, on a thread-local basis, what signal handling, Windows SEH handling and the C++ global handlers do. It was specifically designed to dovetail Herb's proposal. It's getting some use maturity first, but I plan to propose it for standardisation in Cologne next year. Until then, you can find its documentation at https://ned14.github.io/quickcpplib/namespacequickcpplib_1_1__xxx_1_1signal__guard.html and an example of actual, real world, usage at https://github.com/ned14/afio/blob/3a85fcd9bc327da7d7ad21cb9143eb8dab114812/include/afio/v2.0/detail/impl/posix/map_handle.ipp#L557
Would have been nice to not have to come into the comments to see, that, though.
Instead of making your own `HAS_FILESYSTEM` signal with your build config, you can use the [feature testing macro](https://en.cppreference.com/w/cpp/experimental/feature_test) `__cpp_lib_filesystem`.
Why not ask directly? If I were doing a presentation at a major conference, I'd very much want to have my deck reviewed by *willing* people in the know.
Because... jokes are funny?
Yeah CMake does tend to do a lot of hidden stuff. You kind of get used to it. Sometimes its a huge pain. For most stuff its fine in my experience, though.
That is only true for a very small subset of *jokes*.
There are more details about the different pcg variants in the paper. The main problem of the insecure variants is stated right in the first sentence in their documentation - I have no idea why you fail to acknowledge this. The link I gave you does mention xoroshiro not passing standard statistical tests (like PactRand or bigcrush). Maybe you have to read more carefully. As far as I can tell, vigna only acknowledged these problems after he created a new pnrg that passes those tests. Again, you come of as being incredible hypocritical. Both authors like to make bold claims and "market" their work. I just don't understand why you only call out one of them for it, and with such vigor too...
Lucky for you. Myself, I'm in the midst of modernizing a legacy codebase that uses raw pointers all over the place. Lifetime and ownership is...confusing. ACE complicates things as it encourages passing things as void*. One battle at a time...
You're not wrong in the general case, but std::vector&lt;bool&gt; does not return a reference: it returns an object wrapper to the bit referrenced.
**Company:** [Microsoft](https://www.microsoft.com) \&gt; [C\+\+ team](https://blogs.msdn.microsoft.com/vcblog/) \&gt; [C\+\+ Developer Advocate](https://careers.microsoft.com/us/en/job/442634/Senior-Program-Manager) **Type:** Full time, Senior Program Manager **Location:** Redmond, WA, US or remote **Remote:** Yes (details below) **Description:** Our mission on the C\+\+ team at Microsoft is to build the best C\+\+ tools for any developer, any app, any platform. Did you know that our C\+\+ compiler and libraries are fully conforming with the latest C\+\+ standard? Or that Visual Studio can use C\+\+ to build not just apps for Windows, but also for Linux, Android, and iOS? How about the rich C\+\+ experience in Visual Studio Code that is available on Windows, Linux, and macOS? And did you hear about Microsoft's latest announcement for an open source C\+\+ library manager for Windows, Linux, and macOS? There are still many C\+\+ devs in our target audience, VS users or not, that haven’t heard about any of this news and we need your help! We are looking for a developer advocate to help us reach the entire C\+\+ developer market around the world and build a large and dynamic C\+\+ community for the Visual Studio family of products. This position *can be remote. We are optimizing for finding the best person over optimizing for where they are located*. Travel will be required, depending on where developer events are held, and also to Redmond. *Responsibilities:* * You will collaborate with the PM team on integrating C\+\+ developer feedback into Microsoft products. * You will measure our customer reach and provide data\-driven insights into where the team should focus their efforts. * You will be the editor\-in\-chief of our Visual C\+\+ blog and rely on several Microsoft\-wide supporting programs and resources, e.g. MVP program, MS Academy. Your goal is to double and then double again our blog readership and engagement. * You will integrate the work of the product and engineering teams at Microsoft in compelling content, apps, and demos. * You will share these through our established channels (blogs, social media, conferences, direct customer outreach, MVP program) or experiment with new channels with the goal of supporting both new and existing audiences. * You will work with marketing teams to ensure Microsoft conferences have the right C\+\+ content. * You will collaborate with our doc writers to ensure our documentation is consistent with the product. * You will make sure that no question about one of our C\+\+ products goes unanswered on the internet (not necessarily by answering it yourself, but at least by connecting the right person on our team to the forum to answer it) *Qualifications:* * A BS or Master’s degree in Computer Science or equivalent industry experience * 2\+ years of software development experience. * Evidence of being both a strong technical writer as well as a dynamic public speaker. * Experience working with communities, social media, and blogging required. * Previous experience as a C\+\+ developer is required. * Previous experience with campaign tracking, SEO/SEM, or a desire to build those muscles, is important. Ability to meet Microsoft, customer and/or government security screening requirements are required for this role. These requirements include but are not limited to the following specialized security screenings: This position will be required to pass the Microsoft Cloud background check upon hire/transfer and every two years thereafter. **Visa Sponsorship:** No **Technologies:** C\+\+, Visual Studio **Contact:** [Apply for job](https://careers.microsoft.com/us/en/job/442634/Senior-Program-Manager) or DM @mluparu on twitter or email mluparu at microsoft.com with any questions you might have
It doesn't look like this got into boost.random. I'm interested in bringing it to life, see here: [https://github.com/boostorg/random/issues/40](https://github.com/boostorg/random/issues/40) Are you interested in working to provide this generator in boost.random?
Let's get this out of the way, xoroshiro's home page about this specific variant: "For general usage, one has to consider that its lowest bits have low linear complexity and will fail linearity tests". This is in the same paragraph where the + version is introduced. Top of the front page. I don't understand why people hate Vigna so much, this is as direct warning as possible. What, should he put a blinking red banner on the frontpage and a popup window "by continuing using this site you state that you acknowledged that lowest bits of a slightly faster + version fail linearity tests, please also sign here and pass this captcha test to continue"? Sorry, I wasn't around when his previous works were discussed, and I don't care. Why would any of that should influence my attitude? I look at the current state of things, I described what I see in the thread above. Is this how computer scientists are trained in universities? "If a public domain algorithm A is better, but you dislike its author for historical reasons, ignore the reality and pick worse algorithm B just out of spite"? Now let's talk about PCG. I checked the frontpage: only bullshit there. I downloaded sources and looked for comments that will tell me not to use some specific functions: there is nothing. I checked the link you sent, and literally quoted what it has to say (nothing but marketing bullshit). Now I should go to paper, apparently? Ok, you know what, even if I have no hope, let's do it! Ctrl+f "insecure": &gt;To discourage their use by casual users and warm the hearts of security professionals, these variants are explicitly marked insecure Emm... nevermind, next: &gt;m. In a cruel twist of fate, we will give it the rottenest job, Sorry, what a we reading, a scientific paper or someone's blog post about an unsuccessful attempt to unclog the toilet without a plunger? Ok, let's dive a bit deeper into this (quite expected at this point) bullshit. Reading, reading... aaaand nothing. We learned how it miraculously passes SmallCrush in 32/32 case (emm... congrats?). We learned how it it can be 64/64. We didn't see an explicit explanation about why is it terrible and how it is going to fail. Is it hidden somewhere in these 56 pages? Are all of them written like the quotes above? I think at this point any sensible person would just abandon all hope, especially since we have an alternative that doesn't seem to be worse in any practical sense, and is faster than even the "insecure" (for whatever reason) version. But as you politely noticed, I have too many personal flaws, so I would be willing to give it one more try if someone is kind enough to literally post something like "hey, on page N paragraph K there is **an actual useful part**, without bullshit, that actually describes what should be used when, and what flaws the faster version has!". Not really expecting that someone is nice enough (or that this part literally exists exists), to be honest. Author put too much effort into hiding the essential information from the reader already. I wouldn't mind that PCG exists. It's fine, there are always older and worse algorithms somewhere, preceding newer and nicer ones. And they are not necessarily terrible, it's just people tend to discover better things as time evolves. What pisses me off quite a bit is that PCG's creator deliberately spreads misinformation, lies, and tries to undermine the reputation of a better algorithm. Someone out there there are programmers who didn't have time to refute all the bullshit (like I tried to do above), carefully read the discussion, and realize that one butthurt author is just trying to shit-talk another one to make their inferior work look less useless. These programmers may accidentally make the wrong choice, obtain a few misconceptions in the process (something like "omg, all-zero states are super common in xoroshiro, and they are horrible!"), and release a software that will be a bit crappier than it could, which will make the world a bit worse place than it could be. This makes me sad. Why would anyone write bullshit like the one with "255/256 bits are zero" case? I see two general groups of reasons: * Stupidity and/or inability to understand statistics 101. Seems unlikely: it's not a random person from a street, it's an inventor of another good PRNG algorithm. * Deliberate misinformation. Now **that** hurts the entire community. I'm looking forward to explaining to some possible future colleagues that their understanding of the topic is wrong and they shouldn't trust everything they read online. Sorry for being idealistic, but that's not how experts in a specific field should behave (in the ideal world without assholes).
Am I missing something or is the CRTP here just added noise? The example works exactly the same without any templates or inheritance: https://godbolt.org/g/LKqNCL
The same error message can also happen for a lot of variety of other different issues. It's not enough to determine the actual issue.
You guys should probably update the doc page: https://cmake.org/install/ with a reference
**Company:** [Broadsign](https://broadsign.com) **Type:** Full time **Description:** As the leading SaaS company in digital signage, we’re a place for people who envision a better digital future and aren’t afraid to embark on ambitious challenges to change the status quo. We're looking for C++ developers to work on our Control suite consisting of a back-end, cross-platform media player and desktop administrative application. A more detailed description is available [here](https://broadsign.com/careers/software-developer/#view_job) and some of the reasons why Broadsign is a kick-ass place to work are [here](https://broadsign.com/careers/). **Location:** Montréal, QC. Speaking French is a plus, but not required. **Remote:** No **Visa Sponsorship:** No **Technologies:** C++11 (14 soon), Qt, PostgreSQL, SQLite, CMake, Jenkins. Both Windows and Linux. You're free to choose your tools. **Contact:** [Online form](https://broadsign.bamboohr.com/jobs/view.php?id=22). Feel free to PM me if you have any questions.
You might consider using gperf to generate the string to resource mappings.
This is super useful. Was looking for something like this for a previous project. Will give it a go when the need comes up again. Thanks for making it!
Especially since they all have slightly different semantics. .
Concepts and Coroutines both have had good TS implementation. Of course, not in the same compilers. Ranges, also, on the library side. 
Having a consistent library that actually fits together is a reason. Without that constraint, boost asio is still right there. 
Oh, thanks.
Nice, I didn't know of gperf. Thanks for the tip!
Yes, that is true. However, `std::vector&lt;bool&gt;::iterator::operator*` actually returns `std::vector&lt;bool&gt;::reference&amp;`, which is also a reference. Also, note that when dereferencing iterators, they always return an lvalue-reference to the element in the original container. Therefore, the move constructor won't participate in the overloading of `std::vector&lt;bool&gt;::reference::operator=`, as seen in GCC's error message. Conceptually speaking, a move constructor here won't make any sense either, since the original elements should still be retained in the original vector in a valid state after the `insert` operation.
std::embed() http://wg21.link/p1040 
&gt; It doesn't look like this got into boost.random. I'm interested in bringing it to life ... When I write "This (without the mods) has been reviewed by a Boost maintainer", that maintainer is SW. I wrote the classes, they were reviewed, I corrected them and then we started to differ in our opinions. Steven wanted me to write also tests and documentation. This is obviously very reasonable, and required, but at the time I was not on gh (or git), so a big handicap, the tests have to be written within the Boost.Test framework (in C++03, duh) and the docs, well something called quickbook or some other tool. Docs seems simple (too me), "it works like all gens!", as to under the hood, it's documented in the source files. In other words I gave up, plugged the files in my local Boost install, job done. And then I started messing with a finisher on top of `xoroshiro`, of which one was successful. The finisher is simply a reversible int hasher (so it's more like a mapper), the magic constant is found by minimizing the avalanche error (deviation from 50%), the inverse (it has to exist for this to be mathematically sound) is found by calculating the modular inverse of the first number. So, here you have it, once those things are done, it'll be in Boost.
std::lynx!
One last thing, I was in contact with Melissa a couple of time by email, and I'm relatively certain that she does not want `PCG` to be included in boost (and thereafter be limited in what she can change to/in here generator), she seems to be a `take-no-prisoners` (very clever) lady.
 **Company:** [**nuTonomy**](https://www.nutonomy.com/) **Type:** Full time **Description:** nuTonomy aims to be the first company in the world to launch an autonomous taxi system, and we are building up an awesome team to make this goal a reality. We are developing the first-of-its-kind complete solution for providing point-to-point mobility via large fleets of autonomous vehicles. This includes software for autonomous vehicles, smartphone-based ride hailing, fleet management, and teleoperation. The company's software has been tested extensively on public roads in the U.S. and Singapore. We offer a unique opportunity to work closely with experts from a wide array of backgrounds, to create ground-breaking technology with potential for huge impact. Our C++ engineers would potentially be working in several different teams; either pure software, or hybrid software + researcher teams. Depending on the team, you would be building software applications, or contributing to design/architecture, and even refactoring our old code, and just generally working towards the future of transportation. **Location:** Boston, USA OR Singapore **Remote:** No **Visa Sponsorship:** No for USA, Yes for Singapore **Technologies:** We use C++11 on Linux mainly. Any additional experience in any of the following will be beneficial: * GPU Programming/CUDA/OpenGL/Graphic engines etc * Map related software/API (ArcGIS, Google Maps, Tomtom etc) * Robotics/motion control software * Radar/Camera related software/libraries **Contact:** If interested, you may email CV/questions to [eugene@nutonomy.com](mailto:eugene@nutonomy.com), or apply via [https://www.nutonomy.com/careers/](https://www.nutonomy.com/careers/)
CRTP may seem a bit as an overengineering, but it has one significant advantage: compile-time interface check. If I change in your example `void foo()` to `int foo()` in any implementation (arm, for example), the compilation will pass. CRTP will raise a compile-time error. Therefore, it is designed to enforce the same interface among all the platforms, which namespace-based solution cannot provide.
&gt;What pisses me off quite a bit is that PCG's creator deliberately spreads misinformation, lies, and tries to undermine the reputation of a better algorithm. Again you are very quick at judging the PCG website without being specific (what lies are you talking about!?) - while at the same time downplaying the problematic attitude of Sebastiano Vigna. His website claimed for years his algorithm passes tests it did not. So why should I trust that his new algorithm lives up to his claims, when it's only been releassed a few months ago and has barely been studied by third parties. &gt;Sorry, I wasn't around when his previous works were discussed, and I don't care. Why any of that should influence my attitude? Your posts previously only spoke of xoroshiro, and not his current algorithm. Why are you now suddenly claiming you never cared about his privious work? In the face of this, your paragraphs on how "deliberate misinformation hurts the entire community" realy don't come of sincere at all... Every time you are given information you where requesting you either delete your comments or just tell us its not enough. And when given more information, its suddenly to much to read. You are not arguing in good faith, so why should I continue to try to refute your problems with the PCG website?
Will you be able to restore the old behaviour of throwing on failed allocation? 
References share this lovely property too
Speaking as somebody learning it right now, it's the learning curve towards being able to read code. As somebody who had originally only really dabbled in C, Smalltalk (Squeak actually), and Python, when I first saw C++, a lot of the language seemed a bit unintuitive at first, and took a bit of getting used to. I had to go over templates a few times to really understand them, I learned a bit more about how the linking process works in order to understand how static member variable initialization worked, and also had to figure out (albeit it's not too hard looking back at it) what things such as `std::unique_ptr` and `std::shared_ptr` were and why they should (or shouldn't) be used. 
Also, putting the topic of discussion would be really helpful. 
Consistent with what? You don't need executors to make a tcp connection.
Please, don't take me wrong; I think modules getting to IS is really important. I agree with both your points (except for clang modules being different - they had their own in clang 4 but went with TS in clang 6, even changed -fmodules to -fmodules-ts). However, for me the main question is, egoistically "how soon can I use the modules"? So, worst to best scenarios: * modules don't get to IS for a while, and compilers don't support them - means I don't get it for a long long time * modules get to IS soon, and then compilers start to implement them - means I don't get it for a while (think about how long it took to get full C++11 support in MSVC - are we there yet?) * modules get to IS whenever, and compilers implement whatever proposal is in play - means I get something usable soon Now, luckily for me all three major compilers are already going with the latter approach, namely implement TS version (presumably they'll try to keep up with latest version there is). Not there yet but much better than doing nothing until IS version. One more note: it would be a big win for many if merged (rather intersected) proposal, as presented at Rapperswil, gets to IS. It would be a big loss for me if compiler vendors implemented exactly that, since IIUC that means that I have to choose between using modules and using e.g. Boost (or until Boost gets forked and modularized). 
Not that many TS been out there, but IIRC filesystems TS got pretty good support from GCC's and MSVC's stdlibs (not sure about clang).
Technically yes, as Herb showed. But the real problem will be that all new code will be written to expect OOM etc can't throw, and you can't mix both types and preserve the semantics each expects without making at least minimum source code changes to the older code (I.e. wrap calls of old code with my signal guard). Remember the new behavior would only occur if you switch on that C++ edition. Older standards have existing behavior. So old code would either need to upgrade, or stay on the older standard.
please spell check posts before linking them here.
Can you add some sort of tldr/conclusion to your blog? 
Thanks. Fixed. I initially did, but then added some last minute changes and forgot
Good idea! I will
I think a better strategy is to give a name of a function as a compilation parameter, that function must have the exact required signature and maybe no overloads. That way the naming problem is not a problem.
Ok, I didn't realize clang also implemented the TS version. My apologies to you and the clang devs. I agree that I prefer to have a feature in the compiler than on paper. It just seems to me the very few features are implemented portably across multiple implementations until it lands in the IS (at least in the working draft)
This program will most likely malware your computer. It's really shady and telnets some unvetted libraries while compiling. Garbage from an serious incompetent who doesn't understand m4 and autotools recursive programming.
Nice troll account you're just mobious4 in a sock puppet account.
Lickily for you I was paying attention :)
&gt; except for clang modules being different - they had their own in clang 4 but went with TS in clang 6, even changed -fmodules to -fmodules-ts Both are present at the moment, with the original (still under `-fmodules` and `-fcxx-modules`) probably a lot more mature. Last time I played with `-fmodules-ts` was a while ago, but it was pretty incomplete.
Isn't a star-star version also a current one? I open the web page, I see 4 algorithms mentioned in detail (xoshiro256**, xoshiro256+, xoroshiro128**, xoroshiro128+). If the history lesson I got from this thread is right, his old ones are "+", and the other 2 are new. I'll correct myself: when I mentioned any of the algorithms, I meant any 4 from above, from which you can pick whatever fits your goals. The flawed '+' versions are explicitly marked as such (and it's explained what is wrong with them), the star-start versions are a bit slower. You and other people (or maybe your other accounts?) keep reminding me that previously xoroshiro128+ was misadvertised. Ok, I don't know if it's true, and like I said, I don't care. Still not clear why I should. When I tell it's not enough: well, it is not. It should not be a long quest to see what you are dealing with. Each time I ask about details, people send me in the wrong direction, and there is nothing in the link I receive. Surely anyone could just quote something like "hey, here on the front page is an explanation about what kinds of problems you can expect from PCG RXS M XS 64 (LCG), you just missed it". So far no one was able to. Still unclear which problems each version has, still unclear why anyone should care if faster alternatives are available. I'm more and more inclined to think that you (based on the style) is somehow related to PCG's author. Very low signal-to-noise ration, half-lies, etc. For example, so far I deleted 1 comment in this thread that was not very constructive (I guess anyone can figure out what I think about PCG's author as a person without me writing it out, and it's not relevant to the conversation or algorithm's qualities), and it had no replies, and yet you managed to insert it into a sentence "Every time you are given ... you either delete" which makes it sound as if someone gave me something, and I deleted the request, and even that it happened on several occasions. Melissa, is that you?
Thanks!
&gt; Unfortunately, there are things which can be done only by using macros. I’m not fond of this solution, feel free to contact me and propose a better one. Move platform-specific implementation to separate translation units. Use the build system to build relevant files depending on the platform you're building for.
This uses CMake and doesn't telnet anything, quit your fucking bullshit.
It is possible, but the way I imagine, it would require either an `extern` to resolve at the link-time or auto-generated `.hpp`\-files to include only the suitable code. I don't really like any of those methods, correct me if I'm wrong. It is vitally important to keep both `Intel` and `Common` implementations to be able to compare those for the optimizations correctness.
Incorrect it has to be installed or compiled like any plugin or development tool. It uses many libraries of which the target user knows nothing about. Autotool is clearly superior, and far more vetted. This is some Trojan garbage.
&gt;For example, so far I deleted 1 comment in this thread that was not very constructive &gt; &gt;Melissa, is that you? This is getting ridiculous. You know everyone can look up deleted reddit comments, right? I came here to point people to the information you could not find on the PCG website, and later remind you that Vigna himself has put up misleading information on his own page. For this I'm the one "hating on Vigna" while you are "defending the better algorithm" by linking a weak "analysis" of a flawed version of PCG made by Vigna himself. You are trying to protect the community from the "malicious" content of the PCG website, but don't seem to care when I demand the same scrutiny with Vignas posts or website. Your comments here could easily taken as trying to mislead the community as well. You generalized a problem with a single PCG version to all PCG rngs, while stating xoroshiro passes all the tests - but thats okay, because you just deleted those claims after you found they are not true. Maybe this is just a misunderstanding, and you should be more careful with naming the algorithms you are actually discussing... Instead of ending it there, you are now harping on about how the PCG website is maliciously misleading people to not use Vignas algorithms. I clearly disagree with that. I'm also clearly not changing your mind. So other people should just make up their own mind and see if [this](http://www.pcg-random.org/posts/a-quick-look-at-xoshiro256.html) is an honest quick review of an expert or "deliberate misinformation". P.S.: Your name calling makes you look like an immature prick.
That 5 day account has posted nothing but racist and misogynistic content. Followed op from r/gamedev. Harassment is not far from the apple tree for the poor kid behind that account.
[removed]
&gt; It is possible, but the way I imagine, it would require either an extern to resolve at the link-time or auto-generated .hpp-files to include only the suitable code. I don't really like any of those methods, correct me if I'm wrong. If we have a translation unit X that depends on the symbols defined from translation unit Y then what we need to do to get a successful build is: (1) Compile X, (2) Compile Y, (3) Link X against Y. I am not sure why would you need `extern` here or header auto-generation. Factory function would be a convenient mechanism abstracting away the platform completely. &gt; It is vitally important to keep both Intel and Common implementations to be able to compare those for the optimizations correctness. But this is not something you absolutely need in your target build (?). This is, as far as I understand, for verification purposes and probably better place to put it is in a separate binary (e.g. unit tests).
Seems reasonable, although I hate that they're attempting to sneak in `Concept x` as a shortening of `Concept auto x` for variables; I would argue that that is a break in mental model that isn't useful or healthy.
Since every DSL originally designed for certain domains will soon grows into a general-purpose language, it would be glad to see that xmake adopted lua instead of reinventing the wheel.
This isn't really as true anymore, with the splitting up of memory resources and allocators; also, the standard library could easily give allocator adapters, like monotonic_allocator, which take from user-provided buffers.
What would be the drawback (besides duplicated effort) of using `std::is_same_v` or other stricter traits to dispatch to `memmove`?
I will update the doc this week to explicitly build in release mode. 
And _lickily_ for you, so was I :)
So current exceptions make c++ harder to use ? Can this proposal "[Zero-overhead deterministic exceptions: Throwing values](http://open-std.org/JTC1/SC22/WG21/docs/papers/2018/p0709r0.pdf)" make things easier ?
&gt; generalization of linear memory access doesn't hold It doesn't, dude. That's specific to one class of processor design.
please spell check comments before commenting them here.
Yup, you're correct, I misunderstood you in the first place. 
There's P1103, which should be the merged proposal.
&gt;bar generates 30 instructions on GCC Pretty strange, given that bar() parameters cannot alias (or can they?), and adding \_\_restrict__ to pointers allows to optimize both functions to memcpy.
Pendants should be hung
Sounds like you need a `unique_ptr&lt;std::function&lt;void(int)&gt;` to keep the rule of zero. (/s ... maybe)
Pedants, on the other hand should be cherished for their attention to detail.
What's the reason for move constructors being able to throw?
I, personally, am a fan of the "none whatsoever" answer to this question but I'm sure someone will list some obscure and convoluted use-cases
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/8w1kr2/project_based_approach_to_learn_c/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Thanks! If any suggestion/comment/improvement pops in when you're using c-rez, please let me know :)
&gt; There is no guarantee that the variables captured by value from a lambda will have noexcept move constructors. std::function must be able to hold any lambda, so for that to be possible it can’t have a noexcept move constructor of its own. Yeah but it must use type erasure so (unless I'm forgetting something) the lambda capture itself must be dynamically allocated which means the move could just be a `unique_ptr` move. In reality, they're probably leveraging some kind of small buffer optimization, forcing moves to be nontrivial... so then it's just a QOI issue.
A virtual move ctor could try to move if possible or copy if not at runtime, and the copy could throw. It can be worth it to avoid large copies. Of course it will cause problems with standard containers.
Or sufficiently large values of _funny_.
http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2010/n3050.html &gt;In some cases class maintainers may need to choose between move-enabling their class and maintaining its current guarantees to users. For example, Dinkumware's list implementation currently derives QOI benefits from having no resource-less state—“begin” and “end” iterators maintain their relationships even after lists are swapped. If throwing move constructors were banned, that would no longer be possible.
http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2010/n3050.html &gt;In some cases class maintainers may need to choose between move-enabling their class and maintaining its current guarantees to users. For example, Dinkumware's list implementation currently derives QOI benefits from having no resource-less state—“begin” and “end” iterators maintain their relationships even after lists are swapped. If throwing move constructors were banned, that would no longer be possible.
Well, you could have a noexcept move, if you had no small buffer optimization at all. But that would be pretty brutal, that optimization is very important. And in fact, as it stands it is mandatory in certain cases.
Reading your complaints, instead of a magic function there needs to be a standard way to include large resources without the build performance hit of encoding each byte in an array. * the proposal is inferior compared to processing tools: * if you want to embed an entire directory or include everything matching a certain pattern quickly. * std::embed_options is not robust or complete as described. * there is no way to specify a custom transformation. * after applying a transformation (e.g. gzip) the author's comment that "the biggest problem is that the above C++-ready source file is no longer valid in as its original representation" is debatable, because one would not want the original representation in the final executable. * see https://stackoverflow.com/a/35744201 
The thing is that the small buffer optimizations can be enabled \*only\* for noexcept-movable functions (which I assume is the vast majority). And, as commenters in Cpplang Slack pointed out, this is indeed the case with the newer implementations of both libc++ and libstdc++ (which come with gcc 6+ and clang 5+). It is (still) not the case, though, with the standard library which comes with MSVC
Right that makes sense.
If being no-throw movable is important, just add static_assert(is_nothrow_move_constructible_v&lt;T&gt;); static_assert(is_nothrow_move_assignable_v&lt;T&gt;); ?
Oh wow this is a thing!
yeah, I'm gunna have to give you a big ol' *whoosh* on that one.
This was obviously about CPU optimization and again, it seems like you are desperate to create some sort of an argument by making irrelevant points. 1. You didn't mention what other architectures besides GPUs are considered 'memory coalescing'. 2. You didn't give an example of of 'just don't have cache misses' instead of hiding them. 3. You also keep repeating claims without backing them up with any information, essentially saying - 'nope, nuh uh, not true'. I can't take you seriously until you confront these things. 
It's an XML file with a schema; no one is forcing anything on anyone.
This needs to become standard. Until then both xxd or this handy little tool (c-rez) will have to do.
You let me know when you can get a directory-globbing #include in the standard, and I'll make a std::embed that can directory-glob and push it into the standard! (In other words: good luck getting that past literally anyone in the standards committee.) std::embed_options is not customizable because that's not the customization point. It includes all of the bytes at constexpr time: run your favorite constexpr algorithm over the bytes! If you want to gzip-decompress the bytes, write a constexpr version of that so only that gets embedded. Or, do it at program load time: whatever tickles your fancy. I'm not getting in the business of specifying a million enum options for tons of transformations. You either do your transformations outside, or you write a constexpr algorithm for them and pray your compiler only serializes the final result. (With the new "constexpr!" (immediate) functions coming through, which is what this paper will switch to when it gets ratified for C++20, this will be even less of a potential problem). The comment about source file not being valid in its original form is not for strictly binary resources. These are for things like Shader Files which you have to use raw string markup inside of the file in order to #include it in. Raw string literals do not parse in HLSL, GLSL, or CG: thus, the file is no longer original in its valid representation. Nobody cares if a file becomes not-gzip (after you run your constexpr gunzip on it) when it enters an executable, because you had to opt into that and it was intended. No weird customizations you don't make yourself, no surprises.
Why should trivial optimizations like this be implemented in the library instead of in the compiler?
If that’s the one that proposes `throws` as the opposite keyword to `noexcept` then dear god do I hope it is accepted.
&gt; Well in hindsight it’s obvious. There is no guarantee that the variables captured by value from a lambda will have noexcept move constructors. That's not quite right. `std::function` never needs to move the underlying type, and wouldn't erase the move constructor anyway - it's unnecessary, it just erases the copy constructor. `std::function`'s move constructor could be made noexcept, and there is a paper that nearly got adopted in Rapperswil that would do just that: [P0771](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0771r0.pdf). Indeed, on recent versions of libstdc++ and libc++, `static_assert(std::is_nothrow_move_constructible_v&lt;std::function&lt;void(int)&gt;&gt;)` does not fire. 
Ok, I am assuming I will let go my wish on directory gobbing and the problematic constraints of writing constexpr transformations which are better suited to processing tools ran before build in my usage. I think this proposal would be easier to implement correctly (besides MSVC) if constexpr allowed asm sections so that .incbin could be used to specify area and alignment. Sadly it does not.
&gt; In reality, they're probably leveraging some kind of small buffer optimization, forcing moves to be nontrivial... so then it's just a QOI issue. There is, at least in libstdc++ you should not have an allocation if your lambda only needs 8 bytes of storage. Thus, you need to choose between: 1. A `noexcept` move constructor for `std::function`, 2. Small Buffer Optimization for 8 bytes items which cannot be moved. At a glance, I'd pick (1) over (2) since I cannot think of such trivial objects which cannot be moved, so they don't seem very common, but I guess the committee had motivating examples.
&gt; So current exceptions make c++ harder to use? Exceptions in move constructors make C++ harder to use. &gt; Can "Zero-overhead deterministic exceptions: Throwing values" proposal make things easier? Not from its main proposal, since it still leaves throwing move constructors. It did raise the question of whether `new` throwing should be deprecated, and if *that* came to pass then suddenly a whole host of functions could be made `noexcept`. For example, most copy-constructors/copy-assignment-operators only throw in case of allocation failures (the data of the source is already checked, after all). Sutter did a pass and estimated that a large part of the `std` library would instantly become `noexcept`, with significant code-gen and algorithmic advantages.
MSVCs standard library needs it (or any type that needs to allocate in every constructor, including the default constructor)
&gt; If throwing move constructors were banned, that would no longer be possible. I’m probably being thick but this isn’t obvious to me: is this because they need to allocate memory? If so, why? Can’t they simply move the relevant pointers?
It is at least the proposal for a thing. But the committee hasn't made it a thing yet.
https://www.reddit.com/r/cpp/comments/45vwqr/vc_containers_list_map_deque_allocs_head_node_on/
https://www.reddit.com/r/cpp/comments/3a64no/standardizing_variant_difficult_decisions/csacjet/?context=4
So that, with C++11, existing code could automatically benefit from move semantics as optimization. It was IMHO A Really Dumb™ decision. 
It seems dumb, and if the language started from scratch, it would be dumb to design like this. Having unknown amount of code broken wasn't an option though. &gt;If so, why? Can’t they simply move the relevant pointers? I think its safe to assume this was looked at by enough sensible people before they decided to go with throwing moves. Hopefully, there is a lesson learned here for people implementing stdlib though.
I used to do this with a custom tool, but on Mac with universal binaries everything gets duplicated since its linked once for each architecture (e.g. 32 &amp; 64 bit). Is there any way of solving that? (Currently I just use the native resource system which works fine so I won't switch, just curious.)
How's that? Of course, I can change my employer 😉 But I would love to have a chance to change only my IDE instead 😊
I hope you will understand how "stay on an older standard" is unacceptable as answer. The software I'm currently maintaining is roughly 23 years old and going strong; it was started in MSVC 5.0, and has been carefully maintained over the years so that it is now a C++17 application with all the bells and whistles. "Stay on an old standard" means that a few years down the road, there will be no more off the shelf libraries, no more up to date compilers, and no more new features (what if modules don't make it into the language until C++26?). In short, it means an ever-decreasing ability to do maintenance and upgrades, and eventually the decision to rewrite because of obsolescence. What grates is two things. First, I feel a move like this should not be undertaken without some really careful investigation into whether exceptions cannot somehow be improved to reduce the perceived problems. I'd be happy with a more limited exception system; for example, something where you can only throw things that are derived from std::exception (making exception type checks potentially much cheaper and thus faster). And second, it feels like the people who used the language badly all those years are now getting rewarded by making their use of the language into the standard, while the people who carefully wrote exception safe code are getting royally screwed. And I very much doubt it is just me. Surely there are lots of C++ projects out there relying on exceptions, and none of them are going to be happy with this proposed change. 
&gt; I just know I want to learn it and eventually create small games for practice do that, learn by doing. solve problems, learn, increase your toolkit programming is like cooking, practice
I’m not quite sure where to start though. I don’t know how to even begin making a game? I looked into and was told many different things, but the closest thing i’ve gotten to be successful is looking into game libraries like SFML and SDL? 
this is part of learning - assess different libraries, read reviews - pick your poison
I think you might be confusing different parts of P0709. If WG21 follow my proposed implementation of P0709: - SG14 status_code and standard error object for P0709 Zero-overhead deterministic exceptions http://wg21.link/P1028 - SG14 [[move_relocates]] http://wg21.link/P1029 - SG14 A C Either metatype D1095 ... then as far as I am aware, deterministic and non-deterministic exceptions are 100% interoperable, *including* for binary blobs compiled by ancient compilers. Where the breakage I was referring to is is in the changing of the default action of OOM. Until now, it throws an exception. Under the proposal, it terminates the process, and moreover, STL containers will be upgraded to become much more noexcept than currently. The former is not a breaking change. Your code will work as it did before. The latter is a breaking change, and one voted to date unanimously by the committee. And there is lots of form here: I too currently work on 2M lines of 1990s era C++. Using a recent compiler, especially if flipping on C++ 17, breaks things horribly, but 99% of it is due to breaking changes in the STL. Not the language. Historically the STL has been broken many times as it has evolved. Code using the STL is expected to upgrade itself. The language, however, is very very rarely changed in a breaking way. Nothing in P0709 is out of the ordinary, given practice until now. So tl;dr; I'm afraid you're probably just going to have to suck it down, same as I am currently doing at work as I modernise our codebase all day long every day. Sorry.
&gt; It seems dumb, and if the language started from scratch, it would be dumb to design like this. [Another language](https://www.rust-lang.org/en-US/) that started from scratch with move semantics did make it impossible for them to throw exceptions, but did it by removing move constructors altogether, which causes issues with certain C or C++ idioms like objects storing references to their own members and updating those references on move.
This was posted recently: https://www.reddit.com/r/cpp/comments/8rxppz/avoid_adl_calls_to_functions_with_common_names/ In short, using a global function called size caused conflicts with std::size when used with ADL.
On top of the other commenter, I know when I was first getting started I was very nervous about picking the "right" or "best" library to use but it's not a zero-sum game, learning one library provides a great knowledge base to learn others. There's no such thing as bad experience, so just dive in. 
&gt; It seems dumb, and if the language started from scratch, it would be dumb to design like this. Having unknown amount of code broken wasn't an option though. Wouldn't that code be broken by C++11 anyway? The default move constructor wouldn't know it should allocate anything.
I don't know what this means; why would anyone care how you edit the project file? I use VS at work, and edit vcxproj files with a text editor, can't say anyone has ever noticed...
Do you have an editor or IDE you like? Are you comfortable with the compile/link cycles? A lot of tutorials gloss over the tools you'll be using, but you're going to be spending a lot of time in them and should make sure you like the ones you're using. When learning a new language, I often like to do a simple and fairly well-defined and just barely non-trivial example. Modeling a deck of playing cards is a common one I pick, with some additional code to make some players, deal them out some cards and evaluate winning hands for poker or blackjack. The rules to these things are well understood, but you still have to think about how you're going to design them for your program. I'd suggest starting with a fairly simple project and just plowing into it and seeing what kinds of problems you encounter. Since you're unfamiliar with design, you might want to look into test driven development as a good way to get the ball rolling. You can get a unit test framework like cppunit or gtest and start writing unit tests to test your code before you even write a line of code. I haven't fully drunk the TDD kool aid yet, as I'll usually write a good chunk of a class before writing some tests, but I do tend to write tests alongside every class. A lot of times doing so will expose some weakness or something I hadn't thought of in my design. It's worth getting in the habit of testing your code thoroughly.
IMO the move semantics of Rust are way better though on the following crucial point; you can't use a moved-from object. This is what you want 99.99(9999?)% of the time. Hey, in C++ I've almost been bitten by mindlessly throwing an std::forward in a template to attempt to get perfect forwarding. Who would not do that? Except the std::forward was in a loop. I let you imagine the wreck this could have caused, in some cases, depending on obscure factors. Without even a compiler diagnostic. Oh actually you can't precisely imagine the wreck this could have caused, because you don't know on which kind of object this would have applied, and some standard one have well specified moved-from states, while other standard ones have mostly only valid for destruction but otherwise unspecified states. Well, in this case, why I am even allowed to reuse them? That makes no sense. If the only valid uses are either replaceable by other constructs, or the destruction of the object, or representing an empty state, just destroy it automatically already! I understand the free perf benefits without any application level source code change the introduction of move constructor and rvalue references gave us. But that came with great associated risks, given how the details were chosen, when all the tricky mechanisms actually began to be used directly in application code... And we often see that pattern: C++ features are meant to be used by experts, with nasal daemons and other goodies as a punishment is they are "misused" (and with the compiler authors being soo imaginative, the definition of misused is vast, and potentially becoming vaster every day). They end-up being used by everybody, including myself. And we write (nasty) bugs. And even experts sometimes write nasty UB triggering bugs. Or even do not know anymore if some whole class of devices are possible at all to be written in portable C++ anymore (a simple memory allocator, anybody? good luck with that...) 
I really like the layout of Visual Studio and i’ve been using that for as long as I have been learning. So I’ll definitely try your technique, thank you! 
Default move-ctor wouldn't be generated for those types. The issue is that there would be no way to write a non-default move-ctor for them - affected stdlib types would have to be made non-movable. And that would be completely arbitrary list. Im not sure whether what we have right now is better though. Im sure it was considered by the committee. 
Good post, thank you 
So, this may be an unusual opinion, but I really liked starting by writing a logger. Everything needs a logger, and a basic logger is very easy to write. But then someone says"hey, can my messages have different serverities?" or, "hey, can I print different things to the screen and to file?" or, "hey, is this logger thread-safe", or "hey, what about log rotation", or "hey, can logging be low-priority" and so on. Iterating teaches good dev habits, and each iteration teaches new skills (concurrency, file I/O, macros, smart pointers, etc.). My other recommendations would be to use CMake for your build system (it's very standard these days), and to use some standard unit-testing framework (catch2, googletest). If you can write modern version-controlled (use git!) c++ with cmake and ctest (bonus points for Jenkins integration or similar), you'll be ahead of many professionals. Just my two cents :)
This is not really making games, but what you learn practicing those puzzles is useful and it has a lot of bells and whistles to keep it interesting: [codingame](http://www.codingame.com)
If I for example load a project somehow to QtCreator or CLion I can not easily navigate through code, use most refactoring features that those IDEs provides, debug Code etc... Just because those IDEs doesn't understand vcxproj and for example dont know where to search include files or how to build the project. You know what I mean...
Good question. I suppose you could make a single, shared 32bits library and link both 64 and 32 bits binaries to it, but I'm not sure that's possible in all systems. 
Precisely. We're trying to make something portable and useful to all implementations. We don't expect to solve the last 10% of use cases, but we do expect to cover the 90% of "please just make this file available to me so I can do stuff with it". Getting it put into RO memory versus writable memory versus other things is something that can't be done reliably, unfortunately.
`-O0` is one of the reasons why
&gt; You know what I mean... Well, I do now... :-] Agreed that MSBuild sucks in that regard.
If you haven't, start out by making small command line games. It'll give you an idea about what a game looks like in code without having to worry about libraries. When you're ready, pick up SFML. It's a great library. Very simple and easy to understand. It's a great starting point when dealing with graphics. I use it all the time.
you can use the gnu linker to do the same: ld -r -b binary attack.png -o attack.o
You can use C++ for *EVERYTHING* Its the latin of programming languages, once u understand cpp, you learn every other language in a week
that’s what I’m hoping for
I came to be a software engineer by route of a dual major in electrical and computer engineering. Graduated about 15 years ago, then landed in finance. In my experience, most C++ work in college from courses was a joke. Yes it is important to learn your data structures, algorithms, threading and such. But they dont teach why and when to use such things. I picked that up by doing, not being told. Being on an EE/CPE track is good. You should come out with a better understanding of how a computer actually works, rather than the run of the mill JavaScript folks that fancy themselves being real engineers. In so far a suggestions for projects: automate your homework. I remember one project I had to implement an 8-bit ALU in verilog. I wrote a c++ program to generate exhaustive tests for it. Took less than an hour, saved multitudes. Another project, I didnt do it in c++, but I had to run dozens of simulations on power transmition failure scenarios. Was boring and tedious. Fill out some excel, export to matlab, import back in, etc. Each run took hours. I was absle to script one run in the same time it took me to do obe manually. Impressed my instructor enough he came over to my apartment with a case of beer to help him with a work issue. Short of it is: do. You have to practice the trade to become better. Choosing a project is personal. What's going to make your life better?
Ummm. You _can_ use it for everything, but you shouldn’t. Games are a great choice, and it’s true that if you can learn C++ then you’ll be very well positioned to learn _most_ other languages. Don’t mean to piss on the parent post, just bringing in some old man get off my lawn vibe. And when you get the chance, maybe after a year or two, pick up a very loosely typed language (I like Lua), and a more strongly typed language (Haskell is amazing), and then you’ll become an even better C++ programmer! Best of luck!
For a little context to what I'm about to say: I started programming using a language called QBasic, which was designed to run on PCs running MS-DOS. It was cool, because you could basically say "switch to graphics mode", then "draw these pixels in this color", and so on. Literally 2 lines into the program, you're putting graphics on the screen. C++ was the third language I had contact with. If I was still working in DOS, I could (technically) work with graphics with just a few more lines, since the language gives you direct access to the memory of the computer, and DOS didn't protect parts of the computer like the graphics memory. Working with Windows or any modern OS now takes a lot more work, because the hardware that we use now isn't as simple, and the operating systems end up being a lot more complicated and security-conscious. The short answer is that a library like SFML can take care of a lot of that work for you, but using an external library also introduces its own complications and forces you to know more about how the language works. So usually, you start learning C++ as a language just for working with text and numbers (and that's how you're likely to use it in a Computer Engineering degree, anyhow). Later, when you deal with linking multiple object files into a program, it should be easier to understand what's happening when you link a library, and you should be familiar enough with the language by that point that digging into the SFML documentation would be a reasonable way to make some good progress in learning. For learning the language itself, there should be little example projects of increasing complexity in most textbooks, but there's also a jump from those kinds of projects to working on something "real", where you actually have to break down a problem into parts and solve the parts. Programming itself is kind of a separate skill from learning any particular language, and courses are usually designed to increase your skill as a programmer while teaching you the language, but it's still kind of a jump.
My best advice on where to start? Grab SFML and... #include &lt;SFML/Window.hpp&gt; #include &lt;iostream&gt; auto main(size_t argc, char const * const * argv) -&gt; int { sf::Window main_window(sf::VideoMode(800, 600), "My Window"); std::cout &lt;&lt; "And so it begins...\n"; return 0; } --- Read articles on GameDev, watch videos, check out some books. But when it comes down to it nothing beats actually doing something. My very first game was a silly Game of Life with some extra predator/prey rules and I learned a lot from it. Meanwhile some of the least productive moments of my education were sitting around wondering if X was better than Y or if Z was worth learning for my portfolio or not. Some Resources: * [C++ STL documentation at cppreference](https://www.cppreference.com) * [SFML your 2D game needs](https://www.sfml-dev.org) * [Game Design Patterns](http://gameprogrammingpatterns.com/contents.html) In terms of learning C++... I really got to say it's a messy subject. Most of what exists online is poor or outdated, especially with C++11 onwards. I'll defer opinions on that to others.
Ah, great, thanks guys. So I'll try to convince our project lead ("it's really just a st'd::move").
&gt;Maybe we will get at some point `if constexpr(we_are_in_a_constexpr_context)` ?) We [probably](http://wg21.link/P0595) will. [Until then... ](https://github.com/SaadAhmad/in_constexpr)
Thanks so much, very detailed response and i appreciate it greatly! I’ll check all this stuff out! 
Probably the easiest entry is to find some C++ game source code - not too big - then change it to do something different. The behavior of the enemies or something. 
C++ is a weird mess.
I guess you could add (another) parameter to the `std::function` template, that will determine whether move is constexpr or not. It would default to this unless the function needs to allow exceptions, and a implicit conversion from exception-less `std::function` to exception-allowed `std::function` would be added. Is there something I'm missing here?
Well the main part was making `noexcept` the default and having to explicitly put `try` on every statement that might throw (which is easy to tell as the function will have to say it can throw).
&gt; __restrict__ Isn't that GNU-cpp. 
I hate C++ so much :(
Oh man, this is awesome! Thanks for doing this, even though I can't possibly make it to Berlin. It's great that there are people doing this sort of thing for students. Seems like most of the large C++ (or programming in general) conventions are pretty heavily gated, even for student tickets.
&gt;Where the breakage I was referring to is is in the changing of the default action of OOM. Sure, but those things are closely related. The proposal stated the goal was to make STL usable to groups currently not using it. The reason they don't use it is 'exceptions'. Exceptions, in STL, mostly come from OOM, and they cannot really be eliminated because there just isn't any error return path in the language other than exceptions for many of the cases involved. The goal may be STL, but the problem really is exceptions. I'd like to see some research into making those more acceptable before we break such a significant part of the language. &gt;Historically the STL has been broken many times as it has evolved. Those breakages were part bad specification, part bad implementation, and part vendor extensions, and they never went as far as this. And because of all those little breakages STL had a really bad reputation, and was avoided by many, something that only disappeared after C++11 and strict standardization. 
Indeed, fixed, thanks.
Hey, I made something like this before too! However, I did even more unspeakable things and made it work with arbitrarily many underscores which all refer to different arguments: https://godbolt.org/g/LX7u8c
&gt; The reason they don't use it is 'exceptions' The reason they don't use it is the *indeterminacy* of exceptions. &gt; I'd like to see some research into making those more acceptable before we break such a significant part of the language. Ah, but we've already tried that. Eric and Casey argued their hearts out for a stl2 so we could redo the containers into a form less sucky than the current ones. But the committee didn't like the idea of new containers, so we've ended up stuck between a rock and a hard place where we're going to breakingly change the current containers instead. &gt; and they never went as far as this Sure. And that's partially what those behind the stl2 movement wanted to avoid. But the committee have decided they want to improve the current containers, and impose the costs of transition onto the user base. A good chunk of us think that unwise, but we also get that the committee thinks that designing brand new v2 containers would be extremely tiring and exhausting, and a choice to be avoided until unavoidable. 
Yes, that would work fine if that's the functionality you need. 
That's hilarious. Surely this functionality is applicable to any non constants?
 \*\*Company:\*\* \[XLN Audio\]([https://www.xlnaudio.com/careers/rendering-ui-engineer](https://www.xlnaudio.com/careers/rendering-ui-engineer)) \*\*Type:\*\* Full time \*\*Description:\*\* At XLN Audio we develop software products for music creation used by professional producers and music lovers around the world. Given our rising needs for delivering fluid interactions and crisp visuals, we are looking for an experienced C++ developer to join our growing product development team in Stockholm and help us design and build a new cross-platform rendering back-end for our products. You have 3+ years of experience in a development role, and you're experienced in developing cross-platform (Windows/macOS) GPU-based UI systems using common APIs such as Metal, OpenGL, Vulkan... \*\*Location:\*\* Stockholm, Sweden \*\*Remote:\*\* The position is on-location in Stockholm. The work hours are flexible and you can occasionally work remotely if you need to, but that's the exception rather than the rule. \*\*Visa Sponsorship:\*\* Yes if you're already in the EU. Otherwise, given the very long waiting time to get permits for people who are outside the EU, it would be rather unlikely. \*\*Technologies:\*\* We use C++11/14 for now. Development is in C++ and Lua for the most part, targeting both macOS and Windows. For this position, expertise with (at least one of) OpenGL, Metal, Vulkan, etc is needed. \*\*Contact:\*\* Read the full description of our job opening \[here\]([https://www.xlnaudio.com/careers/rendering-ui-engineer](https://www.xlnaudio.com/careers/rendering-ui-engineer)) then send your CV and a cover letter to: jobs \[at\] xlnaudio \[dot\] com 
Yes...? That's exactly what these classes are for. Note, however, that the get a value from `std::any`, you need to know the type of the value. [See here](https://en.cppreference.com/w/cpp/utility/any/any_cast).
I don't get why you need \`std::optional\` around \`std::any\` when \`std::any\` already has an empty state (see member function \`has\_value\`)
Glad to hear I got the right idea of the use of these classes then! Thanks for the tip and the link, I will be making use of these shortly no doubt.
does has_value() return null if the variable doesn't exist?
Thanks for the link. Clearly I need to think about this more because I still don’t see why we couldn’t just swap the sentinels of the moved-to and moved-from object instead of allocating.
It returns `false` for default constructed `std::any` which can in turn be assigned to other `std::any` to empty it, so it has built-in optional-like behavior. Both `std::any` and `std::optional` has `has_value` (https://en.cppreference.com/w/cpp/utility/any/has_value)
I think using Qt is a great way to start. You can make a little user interface without writing a line of code, and then add your C++ as you learn.
Yup, which is the way I would prefer it to be. (Okay I would also like a convenient syntax for saying “if this `throws` just terminate, I don’t care. Then we have everything)
Yes. GNU extensions tend to be supported by clang though - so they are pretty portable in Linux world. The point of using them, was to show that compiler gets stuck on alias analysis. As far as i understand, it should have the same effect as using pointers to two different types that cannot alias (as is original bar() code).
Any is a type erasure thing so it has a performance overhead. std::any should be used when otherwise you'll be using void*, so in a moderately Ok code-base almost never.
Really hope this gets standardized at some point.
I don't really get it - you need to register for the conference first (and therefore pay?), before you can apply for a student ticket? And 25 get randomly selected from all conference (student?) attendees who then get their money back? And the draw is completely random? (What's the idea behind that? Presumably some students have lots of money or didn't even pay by themselves (company/internship/uni sponsored) while others really lack the money. PS: There's a typo, "accomondation".
Well in this paper he proposes to terminate on contract violations (which are the main case where you'd want to terminate on throw), and on allocation failure (another common case for that). Actually outside of this there are very few exceptions, which are basically for opening files and the like and this I can live with.
I use clang on windows (and drink Kool-Aid ;-) ), so that works for me on windows as well.
...and other lies programmers tell themselves.
No, you need to register with Meeting C++ as a platform, get an account. GDPR makes this necessary. No payment in anyform is needed.
Ah! Interesting, thank you very much.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
&gt; After a while I had to add a unique_ptr member to that struct… and then I got a compiler error that the copy-constructor of simple_struct was implicitly deleted and I can’t have a vector of those. What does this mean? The code below compiles without any error. struct simple_struct { std::function&lt;void(int)&gt; func; std::vector&lt;int&gt; data; std::unique_ptr&lt;int&gt; p; }; int main() { std::vector&lt;simple_struct&gt; stuffs; return 0; }
\*\*Company:\*\* \[[Lumicks](https://lumicks.com/)\] \*\*Type:\*\* \[Full time\] \*\*Description:\*\* \[ Lumicks is bringing novel tools for single-molecule biophysics to market, enabling scientific researchers across biology and medicine to unlock new types of experiments. Our primary technology, C-Trap, can be used to "grab" a single molecule, and apply precise mechanical forces to it. At the same time, one can visualize the molecule using highly-sensitive fluorescence microscopy. Our customers use it to watch DNA being copied by the molecular machinery of the cell, or observe molecular "engines" walking across the scaffolding structures of a human cell. Lumicks systems are currently in use in opinion-leading labs across the globe, including Rockefeller University, ShanghaiTech, Max-Planck, and Pasteur Institute. We're an academic spin-off from a research group at VU University Amsterdam. We care deeply about providing our users with easy-to-use, reliable software that actively supports Open Data and Reproducible Science. To make this happen, we’re looking for a fifth software engineer to join our software team. As part of the software engineering team, you are flexible in taking on tasks spanning all aspects of software development. This can include: ▪ Designing, implementing, testing and maintaining our instrument control software ▪ Interfacing with new hardware, firmware development ▪ Working with our business developers and designers to create novel user interfaces that allow easy operation of complex instruments ▪ Software-related customer support, including on-site support of instrument users ▪ Optimizing software engineering processes \] \*\*Location:\*\* \[Amsterdam\] \*\*Remote:\*\* \[No\] \*\*Visa Sponsorship:\*\* \[Yes\] \*\*Technologies:\*\* \[Windows as primary target, but we develop both on Linux and Mac, C++17 (Latest MSVC/Clang), Qt 5, Python 3, C++ Actor Framework, OpenCV, Github, TeamCity CI\] \*\*Contact:\*\* \[Apply directly [here](https://lumicks.com/c-developer-opening/)\]
And there was a small bug in the registration forms for student / support tickets, so registration actually works now ;)
Well, shoot... you are right. I oversimplified the story to spare some boring details. I wasn't using std::vector but a custom vector-like container which also uses \`move\_if\_noexcept\` (I also wasn't using \`unique\_ptr\` but another non-copyable class, but that at least doesn't matter). Now, \`std::vector\` will also copy the struct (I did at least check that) but it does fall back to a non-noexcept move constructor waiving exception guarantees if the copy constructor is deleted (which the custom vector-like container I used didn't do). Funny enough, had case been exactly that, adding the \`unique\_ptr\` as a struct member would have actually improved the performance, because it would have forced \`std::vector\` to fall back to the "non-safe" move. I will have to think how to change the article, because even though the prelude is different, the conclusion is the same.
No but you need executors to schedule/run some work when that TCP connection is made.
Sad but true. :(
 \*\*Company:\*\* Denuvo is a leading gaming security company specialized in the development of software protection systems for games created by the largest development studios and publishers of computer games around the world. Whilst combatting the fight against gaming pirates/hackers, you will be part of a tight-knit mid-sized technical team. As fully owned subsidiary of Irdeto, Denuvo is embedded in a global network of digital platform security companies. For more information visit: www.denuvo.com \*\*Type:\*\* Full-time, permanent contract \*\*Description:\*\* We are looking for a forward-thinking Software Engineer with a passion for programming applications using C or C++. Your task will be to develop new security concepts in cooperation with our customers. You will be performing security analysis, design and discuss new features and implement them in the next iteration of our technology. The team follows the agile process which you will also join in on related activities (Scrum). At times this position may also require you to travel to our customers/offices. \*\*Location:\*\* Salzburg, Austria. \*\*Remote:\*\* In exceptional cases this might be considered, though preference is to relocate to HQ. \*\*Visa Sponsorship:\*\* Yes. \*\*Technologies:\*\* We expect you to have obtained a technical degree, and be focused on programming in C or C++ using object-oriented development methods. We are using Visual Studio 2015 which relates to C++11 with some C++14, predominantly on Windows. Debugging techniques on the binary/x86-64 assembler level is a big plus, using tools such as IDA, WinDbg, etc. \*\*Contact:\*\* Please apply directly via our career portal [https://career4.successfactors.com/sfcareer/jobreqcareer?jobId=20241&amp;company=irdeto&amp;username](https://career4.successfactors.com/sfcareer/jobreqcareer?jobId=20241&amp;company=irdeto&amp;username)= this way we can ensure the team reviews your application 😊
Thanks for your clarification. I really like this post.
Cool. I didn't know that (obviously hehe).
I feel that it's like saying "you should avoid using `std::nullptr_t` as a member.", that is, the pattern might be not very useful, but it doesn't make sense to "avoid" it when you need it.
&gt; has a throwing move, because the use of `const` keyword on the member variable prevents the compiler from using the move constructor of `std::string` with `id`, instead the compiler generated move constructor for `A` will invoke the copy constructor of `A::id`, which can throw. In my experience, 99.9 % of the time you're moving whole containers, and moving e.g. a std::vector won't call any copy or move constructor. &gt; you should still not use `const` -- what if someone later has to refactor `id` to be a `std::string` instead of an `int`? ... then they'll change int into string ? what's the problem ? In general, I'd much rather start with the safety of const members and risk a throwing move (I frankly never saw one in ~6 years of programming in C++11 and later) than the opposite. 
&gt; In my experience, 99.9 % of the time you're moving whole containers, and moving e.g. a std::vector won't call any copy or move constructor. It's not about moving the container -- it's about, when you `push_back` into the vector, and the vector has to resize, does it move your objects or copy them? That depends on whether you have a throwing move. If you have `const std::string` in your class, then you get `n` new dynamic allocations and all your strings get copied for no reason. If you have non-const `std::string` it works correctly.
hmm, I did not know that vector would do a move in this case but it certainly makes sense. Interestingly that's still the case even with -fno-exceptions.
You can use quotes and code formatting on reddit. See [this page](https://www.reddit.com/wiki/commenting).
Perhaps we need another access type, like 'immutable'. Where they can still be moved and are semantically owned by the class, but they simply cannot be directly altered. Thus, a `move` would be legal.
If the member is move-only then making it const will prevent the class from being movable by default. For example it seems sensible to implement a pimple style class with a const unique_ptr that is initialized in the constructor because you can be sure the pointer is not null for the life of the object, but then your class will not get the compiler generated move functions.
&gt; In my experience, 99.9 % of the time you're moving whole containers, and moving e.g. a std::vector won't call any copy or move constructor. I think you can make that 100% because that behaviour is required by the standard. See [move constructor](https://en.cppreference.com/w/cpp/container/vector/vector): &gt; After container move construction (overload (6)), references, pointers, and iterators (other than the end iterator) to other remain valid, but refer to elements that are now in *this. The current standard makes this guarantee via the blanket statement in §23.2.1[container.requirements.general]/12, …
&gt; In general, using `const` in a member variable is bad because you are enforcing an API invariant at too low a level Yes, but in some cases this the proper place - thank you for the writeup of some of the non-obvious pitfalls relating to moves. I have used const with immovable objects, perhaps this should be recommended if going down this path (i.e. immutable -&gt; immovable as a rule of thumb).
I was saying 99.9% of the time as in, if I take my code, 99% of std::move and other move occurences are called on containers such as std::vector, hash_maps, etc
The performance gap is quite huge indeed emplace_back is more than 3 times slower when there is a const member: http://quick-bench.com/T1F8RVgLMfUNtPCa3pryGDbEIEg
that website is great ! 
&gt; Interestingly that's still the case even with -fno-exceptions. That's because it has nothing to do with exceptions or move_if_noexcept. The OP says: &gt; has a throwing move, because the use of `const` keyword on the member variable prevents the compiler from using the move constructor of `std::string` with `id`, instead the compiler generated move constructor for `A` will invoke the copy constructor of `A::id`, which can throw. This is most correct except this isn't a "throwing move", it's a copy. I disagree with the OP, const member vars would be useful if it wasn't for this unfortunate side effect, in the same way as any other use of "const". In this case it states your intention that this member does not mutate after construction, and provides compile-time enforcement for same.
This is a good point, thanks!
I have updated the install guide with how to enable release mode / optimizations.
I mean, most coding guidelines are like this -- it's not a rule, it's a guideline, and there may be good reasons to ignore the guideline. But you should be prepared to defend in code review etc.
Me too. Please please please let it be accepted!
&gt; `std::function` that are type-erased and no-throw move constructible and assume the function objects are no-throw move constructible. Why assume? Check. You'll want a non-small buffer based anyhow; when you run into a throwing move ctor, use the non-small buffer based version (which is nothrow). Or if you don't want that, static assert it isn't a throwing move. 
I'd really like a "const except for move and assignment"
Rather, we need the concept of destructive move; an operation that it both a move-from and a destruction at the same time. You can destructive move-from a const value. 
The difference is that most people who are sold on the idea of using `const` as much as possible go through a phase of trying to use it on all their member variables before discovering that it has some problems, while no one goes through a phase of using variables of type `nullptr_t`.
&gt; Otherwise, given the very long waiting time to get permits for people who are outside the EU, it would be rather unlikely. Is that specific to Sweden? Because, e.g. for Germany it was 2-3 weeks basically.
Agree. I think it's valuable that in: T a = foo(); T b = bar(); You know that `a` and `b` have the same type. It's only the presence of `auto` that signals that they might _not_ have the same type. Unfortunately, this is already kind of broken with CTAD: std::pair a(1,2); std::pair b('a','b'); But still.
MSVC has __restrict also.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/8wd55b/a_begginer_looking_for_help/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
This is simply not true. First of all, you're not measuring \`emplace\_back()\`'s performance, but \`std::string\` copy constructor's performance vs \`std::string\`'s move constructor performance (and also vector's resizing plays a role here too!). First you create your object (\`T\`) which creates string, then you're moving it by passing it (temporary) to \`emplace\_back()\` - and since member is const, it has to be copied. And later it can't be moved when vector is resizing so it is copied each time. After fixing creation of this object there is only 1.66x speedup (versus 3x): [http://quick-bench.com/UeGStwyp-JCzO-MLcJtA15ifnIQ](http://quick-bench.com/UeGStwyp-JCzO-MLcJtA15ifnIQ) After fixing usage of vector (\`std::vector::reserve\`), you get exactly the same performance on both structs: [http://quick-bench.com/wVCGX7D8vNSFtQwbYaqy6sf9iT0](http://quick-bench.com/wVCGX7D8vNSFtQwbYaqy6sf9iT0) This shows that you don't have to loose performance if you know what you're doing. Of course there are some cases where you will end up with CopyConstructor instead of MoveConstructor (and it obviously will be slower, but again - it depends on how many copies will be made and how long the strings will be). Even your TC assumes string will be very long (not make it into SSO), which might not be the usuall case. I hope that shows that benchmarking is not that easy and you really have to know what you're doing, otherwise something completely different will interfere with results. Here you simply testes CTOR + CPYCTOR + k\*CPYCTORs vs CTOR + MCTOR + k\*MCTORs, which will obviously result in lot worse performance. 
My guideline is, `const` can only have 2 forms: `T const*` and `T const&amp;`. No other places can use `const`, unless semantically equivalent to the 2 forms above.
I think the biggest issues is that kind of type is not copy assignable, unless you implement a copy assignment operator with really weird semantics (not really copying the const member). Not being copy assignable will forbid you to place an instance of this type into a vector. You may be able to do so if you don't insert/erase anything, but that's implementation details.
&gt; what if someone later has to refactor `id` to be a `std::string` instead of an `int`? Then he simply changes or to a non-const string - where is the problem? In particular changing an int into a string will require a lot of refactoring irrespective of wether it is const or not. That doesn't invalidate your other points of course
I agree with this rule, and you covered the most "surprising" reason to do it, but not the main reason. More simply, your type is not going to be naturally move assignable, or swappable. There's rarely a good reason for a type not to provide that functionality (immovable types are a very rare case). Note that an extension of this rule, is to never have reference member variables: they are automatically const, of course. Reference member variables are worse in at least one way as well; at least with const member variables you can eventually decide to simply drop the const. With references, you have to change them to pointers and change every single usage of `.` to `-&gt;`. Raw pointer member variables are also somewhat smelly, but if you're going to do something along those lines it's better to make a raw pointer member than a reference member (and enforce non-nullness in the constructor).
Exactly
&gt; because the use of `const` keyword on the member variable prevents the compiler from using the move constructor of `std::string` with `id`, Why is this?
Move construction requires a non-const rvalue. The signature for string's move constructor is (ignoring the fact that \`string\` is actually a type alias for a class template instantiation): std::string(std::string&amp;&amp;) noexcept; But if you're moving from a const member, then you don't have a \`std::string&amp;&amp;\`, you have a \`const std::string&amp;&amp;\`, which can be passed to a function that accepts a \`const std::string&amp;\` but not one that accepts a \`std::string&amp;&amp;\`. So the snippet: const std::string x; std::string y{std::move(x)}; ends up calling the copy constructor, not the move constructor. This makes sense; you declared the function \`const\` and that means that nothing may modify it. Moving from it would modify it, so you can no longer move from it. (As far as I'm aware there's no real good use for const rvalues.)
I learned pretty early on in my C++ career that `const` non-static member variables are more trouble than they are worth.
What if there's a helper function used by the assignment operator, that needs to modify the variable?
The benchmark is not a universal truth, it is here to illustrate the point of the article, which is that const member inhibit efficient move, so it can lead to poor performance when 1. move would have happened if the member had been mutable and 2. move operation is cheaper than copy &gt;you're not measuring emplace\_back()'s performance, but std::string copy constructor's performance vs std::string's move constructor performance Of course I am measuring copy vs move , emplace\_back is just a way to invoke copy or move in this context. &gt;After fixing creation of this object there is only 1.66x speedup (versus 3x) This is not be always possible, eg a function sinking an argument as value to do stuff with it and store it in a container: template&lt;typename O&gt; void f(Obj o) { // Do stuff with o // ... // then put it in a vector getVector&lt;O&gt;().emplace_back(std::move(o)); // Depending on Obj, move does not always happen } &gt;After fixing usage of vector (std::vector::reserve), you get exactly the same performance on both structs Of course there is no difference when no copy or move is involved &gt;Even your TC assumes string will be very long (not make it into SSO), which might not be the usuall case. obviously, objects which have move operation identical to copy operation show the same performance. That said, when the string is empty the results are switched mutable member have slower performance than const member: [http://quick-bench.com/PlF18XMH16LZOofx4cw6D-U\_ZFM](http://quick-bench.com/PlF18XMH16LZOofx4cw6D-U_ZFM) , I guess it is a consequence of an implementation detail of SSO ?
A thread pool is sufficient. Your io thread(s) just pass(es) work off to these via a concurrent queue of some sort. If a server can be written in C without executors then C++ doesn't need them either
seems weird to me that a const would require copy ctor. there's a workable scheme of copy on write.
Well contracts are in, and I believe some compilers will allow terminate on contract violations, so that should be good in 2020. The allocation failure case, I bet there will be a switch for it before it makes it into the IS if people are eager for it.
Using non-const local variables just to be able to move from them later is very annoying for me. I like const variables because they make the code easier to read, but at the same time current move semantics make it so that there have to exceptions and making variables `const` requires more thinking about the context as it should. I'm afraid though that it won't change as it would break code with move constructors/assignment with side effects.
&gt; I guess it is a consequence of an implementation detail of SSO ? I saw this mentioned somewhere (Twitter?) the other day... at least libc++'s implementation of `std::string` (and maybe the other two) zero the source string after a move, even though they don't have to -- so a move is indeed more expensive than a copy if you're within the SSO buffer.
There's a difference between writing "*a serverr*" and writing a library which is supposed to enable the writing of many different servers, applications, et cetera with varying needs et cetera. For example: What if I want to have a pool of threads, but certain sets of jobs within that pool of threads need to be executed one at a time (i.e. I need a strand executor).
The possibly non-`noexcept` move constructor isn't the worst part about `const` member variables. The worst part, as plenty of other people have mentioned, is that they can't be moved from (because of course, you can't change them!) -- any attempt to move them will just call the copy constructor or copy assignment operator. This doesn't matter for trivial types of course, but can be surprisingly expensive for types that do dynamic allocation on copy, especially if you think you're doing the right thing and using `std::move` everywhere. The best solution would be for C++ to have a destructive move operation, like that other language does. Then the compiler could turn off const in the "move destructor", as it does in ordinary destructors today, and `const` members could be moved properly. I remember Sean Parent and a couple of other people talking about destructive move a couple of years ago, and I seem to recall a paper on it, but sadly it never got anywhere.
Modern c++ std::string cannot use COW IIRC, they are instead encouraging SSO.
Nice! Small nit, there's a period after "Release", new users / developers may not understand that cmake will silently accept that period and not enable Release.
Well destructive move would solve the problem.
Most serialization libs don't support const members or reference members.
Have you seen the [east const petition](http://slashslash.info/petition/)?
I mean there is `std::reference_wrapper&lt;T&gt;`
yet another BS from the standard on my part. When I saw this trait I thought "finally, they have something for blitting values". 
Waffle. Boost.ASIO has been around for many years and has no concept of executors. Networking TS was supposed to have standardised that, ut no, they lumped executors in with it, again for no real reason. They could have been added later, just like execution policies were to some algorithms.
Partially: Not for the object I'm assigning to.
You can imagine different solutions of course, but quite frankly: I'm not sure I can remember a case, where I wanted to Mark a member const and needed a helper member-function that would modify it. Be aware that. - as such a variable would be non-const in the context of an move out assignment, you could bind a non-const reference to it and pass it to a free function like `std::exchange`
But assignment when you have a const member sounds ridiculous.
Not at all. There are lots of examples in my code where the only place that a member gets mutated is the assignment operator (be it move our copy assignment). I call them "quasi immutable" types. That's why I mentioned assignment it in my original post. Consider you want to perform an std::rotate on an array of your objects: Logically you don't change the individual elements, you are just shifting them around, so a (logical) const member would be fine. Physically, rotate is implemented as a number of move assignments, so you have to be able to mutate your members.
Even if your C++ standard library used copy-on-write strings, this would still require the copy constructor to be used in this case. True, the copy would be cheaper, as it'd be an atomic refcount increment and a pointer copy, rather than having to duplicate the string buffer. Copy-on-write strings would benefit from move semantics too, though, as they could avoid touching the refcount. So even then: cow_string x; cow_string y{std::move(x)}; ...would be faster than: const cow_string x; cow_string y{std::move(x)}; ...but not as significantly as with a non-copy-on-write string. (NB. C++11 bans copy-on-write strings, by specifying that the non-const `operator[]` isn't allowed to invalidate iterators. So it's a workable scheme for a type you create but not something that you'll actually use when writing code that manipulates `std::string` objects.)
Well you could use a pointer;)
Sure ;) Or just not use const on members ;)
&gt; (As far as I'm aware there's no real good use for const rvalues.) Likely not because applying const to temporaries defeats the purpose of being able to do everything with temporaries. Rarely `const&amp;&amp;` appears in some complex templates for consistency (when you forward rvalues but don't need to change them).
I'm pretty sure it was meant in release/optimized environment. MSVC stdlib had a lot of debugging overhead. As such it's evident that even optimized routines will have some asserts in debug mode to catch some early bugs, so it's hardly a point.
Having that struct A: A a = { "id", 7 }; A b = std::move(a); Is this really a copy-ctor here?
&gt; The latter requires that you create a new array every time you push back Can you explain why? Why can't it just return a bigger array than necessary? (as big as capacity()) Why do you think you'd have to reallocate it on every push\_back?
Do people use this to replace pointers in practice? Whenever I've tried, I eventually give up and just use a pointer. 
I'm saying it may be an easier refactor in a large code base.
Also, if you are from another EU country, you don't need a visa anyway. You have the right to move freely within the EU and choose a job in any member country.
Another benchmark, showing dramatic performance difference (*3.5) when calling std::vector::emplace\_back with types having a const member vs only mutable member: [http://quick-bench.com/ZXe7-4sa1xjtg\_lyAp9LVkz8t3Q](http://quick-bench.com/ZXe7-4sa1xjtg_lyAp9LVkz8t3Q)
Cool ! Month ago I've started job as embedded, saved for later ;)
Love the guy. I enjoyed his CppCon2016 talk on MQTT. Does this CppCast differs from his [C++Now2018 talk](https://www.youtube.com/watch?v=c9Xt6Me3mJ4) in terms of content?
In every case I've written a const member variable it implies immutability of the class/struct and also deleted the copy/move operator/constructor.
**Company: Stevens Capital Management LP** **Type:** Full time **Description:** Stevens Capital Management LP (SCM) is a registered investment adviser located in the heart of Philadelphia’s Main Line suburbs. SCM manages a multi-billion dollar hedge fund that has been in business for 25+ years. SCM specializes in the rigorous development and disciplined implementation of empirically based quantitative trading strategies. Our highly productive team works in a fast-paced collegial environment, utilizing extensive data sets, technology and the scientific method to devise and employ trading strategies throughout the world’s most liquid financial markets. **Primary Responsibilities:** * Develop new software and enhance existing systems in C++ on a linux platform. * Create tools to process, store and analyze quote, order and financial data. * Work closely with our quantitative research analysts, engineers and other groups to provide software solutions. **Requirements of the Candidate include:** * Undergraduate or graduate level degree in Computer Science or Mathematics. * C++ programming experience in a Linux environment. * Excellent academic record. * Strong problem solving skills. * Knowledge of shell scripts and other languages including Perl, Bash or CSH is a plus. * Knowledge of relational databases including Sybase, SQL Server and Oracle is a plus. **Location:** Philadelphia, USA **Remote:** On-site only **Visa Sponsorship:** Yes **Technologies:** C++, Linux **Contact:** For more details on all open Developer roles, please visit and apply here: [https://grnh.se/f330a6f81](https://grnh.se/f330a6f81)
I wasn't saying that this benchmark doesn't make any sense. I'm simply showing that: &gt; emplace\_back is more than 3 times slower when there is a const string member is a lie here and can lead to false conclusions, especially by those that are not proficient enough with the language to know why is there such a difference in performance and repeating a lie that `emplace_back()` is very slow. No it's not. The difference here is when we can move and where we can copy. In most cases move is much cheaper, so it's preferred, but saying that using `const` members is 3x slower is false - it's not. In some cases, due to more copies then move, it can be 3x slower, 10x slower, or exactly the same. This is not a real life scenario and I think that it is important to note in such benchmarks details like this so that everyone can make proper conclusions. Also - it only partially prohibits efficient moves (as stated earlier) - if your object is dynamically allocated and held by (for example) `unique_ptr`, then this probably won't affect you at all (performance wise). I for one prefer cleaner and easier to understand/argue code and avoiding premature optimization. If something is slow because it is copied thousands of times instead of moves, then measure, find and optimize it. If this is one object that is not moved anywhere - no sense in making such optimization too early. In the end - final argument - you can always remove `const`, but adding it might be very hard in some cases. If you know that some member is set in ctor and must not change for object's lifetime, then I'd recommend to put `const` there. If this is problematic, you can always wrap it so that access to it is const (can't change this value) but can move from it (which obviously can change this value, but nobody should ever move-from value just to change it so less options to screw something up by accident).
Are you saying, change from a reference to reference_wrapper, or just use a reference_wrapper to start with? reference_wrapper I find pretty awkward because you can't directly call any methods of the type with `.` or `-&gt;`. The only benefit that reference_wrapper gives you in return is not being null. If anything you can write a `not_null_ptr` which is like `observer_ptr`, but with no default constructor, and constructed from a reference instead of a raw pointer. This is basically exactly equivalent to reference_wrapper, but with more convenient syntax.
Could a modifier for class methods be made called mutable that would allow the method to modify const class members? This would be opposite to how declaring a method const restricts it from modifying nonmutable member variables.
Either this is a good idea or a bad idea.
Yeah so if I have \`const int\` I could change it to regular \`std::string\`, but if that is the only thing preventing the \`id\` from being changed then I'm reluctant to leave it at that, because I've removed a layer of safety and the original programmer thought there should be some protection. What I'd probably end up doing is make the string private and add an accessor. What I'm saying in the guideline is really, that's how it should have been in the first place. It's true that this kind of change likely involves a lot of code changes anyway and the extra cost here is marginal, so the example isn't that great.
The problem is that copy on write \`std::string\` is not thread-safe, and it would mean that if you pass your \`std::string\` by \`const &amp;\` to a \`std::thread\`, you get screwed. It was decided that this is too terrible to tolerate after we added thread support in the standard library etc. There was a big breaking change between gcc 4 and gcc 5 standard library where they moved away from COW \`std::string\`.
Yeah that's a good point, thanks :)
I dig the business model. :D
Pointer arithmetic is only valid with arrays. It doesn't matter that they are placed contiguously. Because the all elements in that array need to be constructed if you create a bigger array. And if capacity() &gt; size() then you construct more elements than you need to. See first point. No array, no pointer arithmetic.
Glad we nailed that one down.
The point of only being able to work with objects that exist is to allow the compiler to reason about the behavior of your program. Things like aliasing are important to save on double checking if an `int*` and a `double*` point to the same memory, so when I write a loop copying from a `int const*` to a `double*` I don't have to reread the `int*` every time I write to the `double*`; they are unrelated types, so it isn't legal for them to point to the same memory. The fact that the operation `::new` is a noop in the actual hardware doesn't mean it is a noop in the abstract machine, or it cannot change the behavior at the abstract machine level. Even if it is a noop on *all* hardware the abstract machine runs on. 
This is pretty cool - I like vscode, and didn't know about xmake.
Yeah, destructive move would really be helpful for those cases. BTW: Relying on sideeffects of move sounds broken by design
I just don't buy it. Again, if you change a public variable from int to string, I think you have much more to worry about than the const-ness of it. Again, that doesn't mean I disagree with your general guideline. I just think it is a very weak argument (and a "what if... at if")
Or [not even wrong](https://en.m.wikipedia.org/wiki/Not_even_wrong)
I think everyone would like to have destructive move, but I guess no one wants to introduce yet another overload for copy and assignment.
&gt; Upper bounds [for unwinding a single stack frame] tend into the hundreds of milliseconds on a machine with limited free RAM, due to page faulting in the EH tables. I would really like to see some benchmarks for this. This benchmark from 1998 talks about 3ms per page fault: https://www.usenix.org/legacy/publications/library/proceedings/usenix98/full_papers/saito/saito_html/node23.html This more recent paper talking about page faults *for data stored on a SSD* (https://pdfs.semanticscholar.org/dd0a/dcde7d074a414a9df76fb20d52a0d8aa8c71.pdf) measures 14µs page faults (from a quick skim). I really doubt that they would be 1000 times slower for RAM.
I have gone ahead and dropped the period
Yeah, what a mess. The difficulty in how to correctly initialise this implementation is what makes it harmful, not the algorithm. The amount of code out there that is initialising it with 32 bits is insane. 
There are two types of page faults, "soft" and "hard". The difference between them is whether I/O is involved (hard) or not (soft); and hard page faults are massively slower than soft ones. Unread portions of binaries, such as the EH tables which are usually segregated apart, will indeed generally lead to a hard page fault *on first access*, as the OS needs to actually pull in the bytes from disk to RAM. One simple trick I've seen used to avoid this first hard page fault is as simple as `cat /usr/bin/my_program &gt; /dev/null` prior to running the programming; forcing the OS to load the whole program file in memory. Of course, the OS could still decide to *unload* some parts later if there is memory pressure, which would negate the trick. --- For those following at home, a page fault occurs when the virtual memory address is not mapped (according to the TLB) to any physical memory address. The OS is then called (via an interrupt) to indicate which physical memory address is actually backing the virtual memory address of the current process, if any. A hard page fault will occur if, for example, after mapping a file to RAM with `mmap`, the particular page in question has not yet been loaded in RAM, requiring a round-trip to the disk to fill the RAM before the OS hands-over the physical memory address to the CPU. From experience, such a hard page fault can cause a 1ms pause with a HDD. On the other hand, soft page faults are resolved with "only" the cost of an interrupt, in a few µs. 
A temporary alternative would be a preprocessor pragma that can call an external program, and expands to stdout.
are there cases on common desktop OSes where you would execute a program and it wouldn't entirely be loaded into ram even before main is called ? 
In your mockup, there are more convenient ways to set/clear the carry flag. Namely, `STC` and `CLC`. They're 1-byte instructions, and you can run 4 of them per cycle. You can also use `SETC r8` for the test instead of using `SBB`, which has a dumb dependency on the value of the _destination_ register.
&gt; I would really like to see some benchmarks for this As the P1031 *Low level file i/o* guy I actually can supply these: https://github.com/ned14/afio/blob/ebad78163b34e53786338ac8778c71c02cd090a3/programs/fs-probe/fs_probe_results.yaml 99.999% of the time, a random 4Kb read on Windows 10 from a spinning rust hard drive with queue depth of 16 will take less than 805ms, 99% of the time less than 232ms, 95% of the time less than 134ms. Mean latency is 36ms. So on a machine with heavy memory pressure and spinning rust storage, absolutely can a page fault exceed half a second. For a SATA connected top end Samsung SSD same test: 99.999% &lt; 8ms, 99% &lt; 0.2ms, 95% &lt; 0.17ms, mean 0.03ms. For a NVMe connected very top end SSD: 99.999% &lt; 3ms, 99% &lt; 0.2ms, 95% &lt; 0.16ms, mean 0.096ms. SSDs really gobble up queue depth, and QD16 is nothing to these high end SSDs. You're still talking single digit milliseconds for a page fault though. That's a few million CPU cycles which P0709 *Deterministic Exceptions* makes never happen, not *ever*.
"Relying on sideeffects of move sounds broken by design" I completely agree, but sadly commitee cannot say that.
Heh. I was trying to show that the compiler could usually fold in the setting or clearing of the carry bit by reordering, or slightly changing, or using non-flags setting instructions, the function epilog, without usually needing to use explicit instructions to set or clear the carry bit. In other words, you get to set the discriminant for "free". I'll try to clarify that in the next revision. Thanks for the catch.
Groan
It could be made not UB by reading through char* instead.
Depends on the representation they use.
Accessing the null through `std::string` is very explicitly allowed. Note &lt;= size rather than &lt; size like the other containers: http://eel.is/c++draft/string.access
It seems like an interesting idea. I'd like to hear more thoughts on this by other people, but to me it feels that we can do better than introduce a new exception style and differentiate between functions that throw the old style and the new one. Something popped in my head that we maybe can introduce a mechanism where the compiler can assist automatically forward return values from a function much like 'throw' given some types. This will allow us to either implement your zero-overhead deterministic error handling or do other fun things, this way: (I wrote it from scratch pretty much now so it may contain many mistakes, I hope I succeed in explaining the idea) * Introduce the following syntax: ``` throw class my_throw_class { /* class members */ bool throwing() const; // Returns true if we want to throw, else false. /* user defined type */ throwable(); // Returns the object to 'throw'. /* user defined type */ value(); }; ``` The keyword `throw` is added before the keyword class/struct/union to make the compiler aware that after construction of this class, the function `throwing()` should be called, and if it returns true, then, if F returns a throw class/struct/union and it is well formed to do, return 'caller_throw_class(throwable())', else throw an exception 'throwable()'. * Example of throwing exception case: ``` my_throw_class f(); void g() { auto g = f(); // Translated to: // { // auto &amp;&amp; value = f(); // if (value.throwing()) { // throw value.throwable(); // } // // construct g from value.value(). // } } ``` * Example of forwarding exception as return value due to being able to return the type: ``` my_throw_class f(); my_other_throw_class g() { auto g = f(); // Translated to: // { // auto &amp;&amp; value = f(); // if (value.throwing()) { // return my_other_throw_class(value.throwable()); // } // // construct g from value.value(). // } } ``` * This essentially allows to declare the following type: ``` namespace std { template &lt;typename Value, typename Exception&gt; throw class result { /* acts pretty much as an std::variant of Value and Exception (or unique pointer of Exception if you like) */ bool throwing() const; // Returns true if we have exception in the variant, else false. Exception throwable(); Value value(); }; } ``` * Do the following: ``` std::result&lt;file, std::system_error&gt; open_file(); std::result&lt;parsed, std::exception&gt; parse_file(); int f(); ``` So that: ``` std::result&lt;parsed, std::exception&gt; parse_file() { auto file = open_file(...); // Translated to: // { // auto &amp;&amp; value = open_file(...); // if (value.throwing()) { // return std::result&lt;parsed, std::exception&gt;(value.throwable()); // } // // construct file from value.value(). // } } ``` Supporting also functions that do not return throwing class/struct/union: ``` int f() { auto file = open_file(...); // Translated to: // { // auto &amp;&amp; value = open_file(...); // if (value.throwing()) { // throw value.throwable(); // } // // construct file from value.value(). // } } ``` I can see several problems as I'm writing this, nor how much you will consider it useful for implementing your idea, but I hope you can share what you think about it. 
That is pretty cool. But, in your specific example code, returning auto screws that up. [https://godbolt.org/g/DtGDMB](https://godbolt.org/g/DtGDMB)
Is there any chance I can send you my resume to you. Your applicant tracking system is not accepting my resume(Either in PDF or word format)
All Linux and Windows page-fault binaries into memory. There might be prefetching involved but it is an optimization rather than the primary mechanism.
1ms is very optimistic for a hard disk. Consider this thought experiment: if the disk rotates at 7200RPM, that's 120 rotations per second -- so on average you have at least 4ms latency only due to rotation of the platter.
Well that'd be an argument for the `restrict` keyword, and also potentially contracts about that. If you start doing funny stuff with pointers, you better know the aliasing rules.
I thought that `reference_wrapper`'s `operator T&amp;` would make it just do the right thing, so I decided to check and you're right it doesn't really work.
Thank you microsoft, you are making C++ a better place!
Make C++ great again!
DiaF Microsoft
How much is cost?
On the /r/rust subreddit, [you write](https://www.reddit.com/r/rust/comments/8wlphf/d1095r0n2xxx_draft_3_a_c_either_metatype_so_rust/e1xb4ti/) &gt; Yeah, your Result type got discussed a lot during Expected. A majority felt, strongly, that the mistakes in its design must be avoided in Expected. They won out. A minority felt, strongly, that the mistakes in its design were easily rectifiable, and a better-than-Result ought to be Expected. Everybody agreed on the "obvious" mistakes in your Result. You did not want to start a Rust vs C++ there on that subreddit, but maybe you can discuss it here. I am curious to know what does the committee consider as the design mistakes in Result
Uhm, no... C++ is making Microsoft a better place.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/8wr3ur/someone_please_help_me_debug_this_code_its/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
But most hard disks have large caches nowadays - last time I checked 64 megabytes was fairly common
Using auto in the `Interface` part kinda screws up the whole "define the interface" point. You can use the trailing retrun type to keep the declaration simpler, but either way you have to tell the compiler, what type should the implementations return: [https://godbolt.org/g/Y16Rwc](https://godbolt.org/g/Y16Rwc)
Great! Thank you for pushing this.
It's not "optimistic", it's derived from diagnosing a 1ms pause which happened "randomly" during the first few minutes of the application running. It was a rather elusive bug, too. And adding instrumentation would change the spot in which the pause would occur, driving us nuts. Then finally it was realized that this was a hard page fault and was simply due to the OS mapping a code page it had never needed yet... Of course, YYMV depending on your own disk, etc.
I had the issue with a recent distribution of Centos, so at least this one.
F
As a graphics nerd I am sooooooooooooooooooo excited about this talk. Can't wait for the recording.
Why do you want that _Expected and _Unexpected are ignored in non-_Either contexts? I would intuitively want the compiler to report an error instead.
The podcast just covers a brief summary of what Michael talked about at C++Now, but in the second half they move on to talk about Michael's experience with Boost, touching on Spirit and Boostache as well as C++Now's "Library in a Week" sessions. 
I wouldn't x consider 64 mega large compared to several gigabytes of RAM. If the stuff really got out on disk because ran was full I find it unlikely that it just happened to stay in the HDD cache.
You can see [https://github.com/tboox/xmake](https://github.com/tboox/xmake)
The `final` specifier helps a lot with these optimizations. You don't seem to have used it anywhere.
I agree. I was doing if for my purposes and in some places my classes branch a lot... But in real life the difference will probably be even higher. Try removing volatile and allow your compiler to inline non-virtual calls. 
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/8wtsj8/c05_quick_reference_help/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I'm a c++ dev and visual effects artist. I'm so excited for this. Houdini is such a cool bit of software. Great that the vfx world is getting some attention with this keynote.
Not much in here about embedded systems :/ TL;DR: Many chip vendors want you to use their IDE, and make it hard to use C++. That's uhh... that's about it, in terms of discussion on embedded systems.
Eigen v3.2.2 (the version shipped in Debian 8) spews all kinds of warnings when compiled with `-std=c++17`.
Your analysis is not very accurate. With O2, O3 and Ofast, VirtualBase1 and VirtualBase1* is actually faster than direct call, according to your own data. Am I missing something?
I was hoping someone from LLVM/Clang community would comment on this. Maybe some weird optimization is taking place there... I have checked multiple times and was surprised myself, that this gave me results like that. Did you try to run it on your machine?
Better conformance and consistency across implementations helps everyone.
Also take a closer look at the last column values in the last and prelast rows. 
Briefly looking at the generated assembly, at O3 gcc already is inlining all the "direct" calls, so getting something to run faster than this probably means that you are measuring something else.
Why are indirect calls frequently being measured as faster than direct calls? According to godbolt, the direct calls are being inlined, while the indirect calls are not - so what gives?
On my local machine I was trying with platform-specific “no-inline” flags. Didn’t measure gcc that way. The code in Gist is platform independent and only uses STL. The only thing that it may include is the high resolution clock. Not sure if its influence can vary a lot in different tests... will try later. 
To overcome inlining on godbolt - put extra flags. You can google them for every platform and compiler. Didn’t want to overload the file with macros..
Direct calls runs before everything else. Maybe the rest is somehow cached in registers... I tried to make things a bit more difficult for compiler with a large volatile buffer, but maybe its not enough. IMHO, fluctuations within 10% don’t really matter. 
I was also curious so I started searching, but couldn't find anything more substantial than this: https://www.reddit.com/r/cpp/comments/6qo1m3/outcome_v2_has_reached_stability_wg21_paper_will/ The most generous reading I can make of 14ned's comments in that thread is that 1) they didn't like how many methods `Result` had, and 2) they didn't like that it defined its own `map`/`and_then`/etc., claiming that this made it incompatible with a general "monadic" operator. This second part is wrong, of course- `?` is already that general operator, and also works with `Option`, for example. Rust's `EitherMonad` concept (as 14ned calls it, I have no idea if this is an actual thing at this point) is the `Try` trait.
The one issue with Unity Builds, of course, is that suddenly you have lost all modularization. The standard defines Translation Unit, and Unity Builds smashes them down: anonymous namespaces and `static` functions are suddenly "unity" wide, instead of source-file wide, changes to a `.cpp` file can suddenly affect the meaning of "downstream" code, ... Unity Builds make incremental builds impractical, and have the gall to change the meaning of the code. I'm not a fan of the strategy, to put it mildly. 
all fair points, but still some teams decide to use this technique. I guess it's a matter of weighing the pros against the cons for yourself. The fact that Visual Studio just recently added experimental support for this says enough.
There are almost always other tasks that can be done while waiting for a build; using time/cost lost is a poor excuse for bad time management.
Saying that there are always other useful things to do is a very bold generalization for all companies/teams/projects to make. And sometimes the build takes just 1 minute - what are developers to do in that 1 minte? why not cut it down to 20 seconds? 10?
Haven't listened to it yet, but I would have expected some pointers on what techniques are sound for achieving fast/small/zero-overhead code, and what techniques to avoid. Virtual functions are a known no-no of old, but what of the newer stuff in recent standards? Just `constexpr` all the things and call it a day? Anyway, I'll go listen to the talk now... Maybe I'll get some answers.
You could easily test that hypothesis by running the test in a different order. And you did run it multiple times, right? 
Many times - yes. With more iterations - yes. With different compiler flags - yes. Different order - not yet. 
I'm sorry maybe I'm missing something but I'm puzzled here. You opened a thread about polymorphism being slow but you yourself realized your data indicates it's actually faster and wanting to ask that to LLVM team? What was the purpose of putting your benchmark data there if it indicates the exact opposite of your claim? Also as other answers mention, you're measuring something else, and that something else is probably compiler's ability to optimize the code based on given abstraction (which might be why polymorphism is faster).
Its approximately the same in some cases. In other cases its considerably slower. The purpose was to see precisely how much time each call takes and how its affected by your design. I have only tried it on a single Intel CPU and plan to try on other hardware once I have may hands on it. Then I will be able to make table. But until then I decided to share this. 
So basically `std::add_pointer_t&lt;std::add_const_t&lt;int&gt;&gt;` but with less typing and less standardization?
You could watch it in person. I'm just saying... https://cppcon.org/registration/
How do unity builds compare to precompiled headers? It sounds like PCHs are the best of both worlds.
For creating larger, nested structures like JSON I do consider the overhead to be significant. We use JSON for log-messages (structured data rulez, no stupid plain strings), and logging really needs to be fast. As I outlines in my \[SO answer\]([https://stackoverflow.com/a/36411040](https://stackoverflow.com/a/36411040)), you can use \`mutable\` to create a proxy and then move away from the const elements from an initializer list. It's not perfect, but for us it works well and does the job.
I would ... Alas I cannot afford to attend :-(
They are easier to configure. * For example you can split your project into several related unified compilation units (each made up of many cpp files). Using several different precompiled headers in a project is a bit harder to organize (given that it's compiler-specific). * The workflow described in a previous comment (where you have a unity build but you often take out some cpp-s out of the unit to work on them without rebuilding everything every time) is also a bit harder to organize with precompiled headers (especially if you're a fan of automatically including them. But the most notable thing that I've seen is that gcc and clang generally do a poor job with precompiled headers. For example templates, even instantiated ones, especially instantiated variadic templates in a precompiled header don't seem to improve the build time *at all*! If you have a lot of templates, with gcc and and clang you can often see rebuilds \*several times\* faster with unity builds compared to precompiled headers.
I'm not aware of anything new since [P0065R0](http://open-std.org/jtc1/sc22/wg21/docs/papers/2015/p0065r0.pdf). The proper venue for such discussion, including your motivating cases, is the [std-proposals](https://groups.google.com/a/isocpp.org/forum/#!forum/std-proposals) mailing list. I just reviewed the minutes of the committee discussion: It might be productive to cc Bjarne and Gaby Dos Reis to be sure they are looped in, that the proposal is practical and not an academic exercise.
I hope this does not crash MSVC anymore then! template&lt;&gt; #include&lt;&gt; 
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/8wwqr0/how_to_setup_for_boost_c_library_in_codeblocks/e1z0uql/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Yes. I don't use it, really, as I am a fan of the verbosity, I just like the clean look of that syntax.
The article fails to mention (or maybe I missed it?) the biggest (arguably) drawback of unity build: It greatly slows down **re**compilation! Sure, building from scratch is much faster, but hardly anybody makes changes to all modules between every compile. Once the unity-build takes 30 minutes to build, that 30 minutes is of *any* small change to *any* part of the project. Regular, non-unity, modularized builds allow recompiling only those translation units that were modified so even if building from scratch takes 2 hours, an individual module might be modified, recompiled and linked in a minute.
There's some truth in what you say, yet the build time improvement makes it all worth while. If you do some crazy stuff in a few source files, just exclude them from the Unity.
&gt; It greatly slows down recompilation Not true in my testing.
Unity is a colossal speedup over just PCH.
Like browse reddit. Seriously, taking my mind off the task at hand is a productivity killer. I can't keep 5 things in my mind at the same time to multitask like you suggest.
oh god. how is such a problem even discovered, and what horrors were they trying to unleash upon the world with template include?
Use Google Bench or QuickBench.
Apologies for not getting back to anything on Reddit last 24 hours, was surprised by early arrival of my children which I needed to go have fun with + I needed, very badly, some sleep after this past week of no better than five hours per night. In reverse order. In short, I couldn't do justice, in the time that I am willing to expend, on what issues we would generally be agreed to have with Rust's error handling model. I'll reply in a bit more detail to Rusky below, plus I'll reply in lots more detail in /r/rust tomorrow evening once I'm on the train back to Dublin, but ultimately I think that our general concern is that we don't think that the Rust approach can scale well over tens of millions of lines of code base and more. I'll try to detail that some more tomorrow evening, it's not an open and shut case in C++ land either.
Yours would not be an inaccurate, on first glance, interpretation of that very, very, very long and intense discussion about what form Outcome ought to take. Which, in many ways, is still ongoing wrt to deterministic exceptions. And thank you for making the effort to wade through all that, it's a non trivial investment of one's time. You're right that we would generally feel that member functionality ought to not be on the types themselves, but rather be a separate overarching common framework which applies itself to all types under its aegis. I would also say that the TRY operation is orthogonal to the monadic bind/map/etc functionality. TRY is much more fundamental to C++ than the monadic operations, at least probably to a majority of users. However there is a bigger picture here in terms of scalability over really huge code bases, and I am getting a feeling from the /r/rust feedback that there is an amount of disquiet with the consequences of Rust's choice of `Result&lt;T, E&gt;` and the current form of panics. And I'll be happy to respond as usefully as I can on what my best understanding of where the C++ leadership is roughly at on that topic. Though, given it's 2.30am right now where I'm at, let it be tomorrow, and on /r/rust rather than here. So, I'll get back to you over in that subreddit, tomorrow evening if that's okay.
You can use a wrapper class to enforce and document the expected behaviour without having to do things like specifying move constructors. struct A { read_only&lt;int&gt; id; int foo; }; All read_only has is a few access operators like -&gt; and * plus an operator T const &amp; to implicitly become T. 
Order didn't affect the result.
The main issue people get is not performance, but usually how `unique_ptr` becomes hard to use so they switch to something else. That's quite dangerous. If you care about performance, you can always find ways to make it work. But if people who are learning the language find friction like with `unique_ptr`, it can hurt their adoption and end up with raw pointers.
\&gt; suddenly you have lost all modularization. Well, there's modular and there's *Modular*. How many cores are you compiling on? Breaking your system into 2x that many modules where each is a separate unity conglomeration should still give good speedups.
https://cppcon.org/volunteers/
You see I like posts from quuxplusone because every time I see one on reddit mobile the thumbnail is this dude’s awesome profile picture of him juggling oranges. 
Libraries that use unity builds are usually developed "the normal way", and end up having a script configuring the unity build. FWIW, I'm a big fan ofconsuming them - maintainingis a different topic, you are right. 
That depends a lot on individual factors. If a single unity TU is taking 30+ minutes to (re)build, one of two problems is likely. One, your unity build is just _too big_. If you have 1,000+ source files then you probably shouldn't compile them _all_ in one big unity file. Break down your unity files into groups of 20-50 original source files; measure and refine as necessary for your project. Two, individual TU compilation time is already too high. We had single non-unity TUs that took multiple minutes to build thanks to certain template abominations; if you're trying to bundle monsters like those together then you're in for a world of hurt. Either exclude those files from the unity bundles or fix whatever is wrong with the code that chokes the compiler so badly.
Ok, thanks for trying and letting us know. That's a mystery, though, isn't it? Surely the take away lesson shouldn't be that virtual functions are faster than non-virtual functions...
Yeah, but two pumpkins is child's play. Can he do three pumpkins at a time?
Thank you. I hope this explanation makes it to std-discussion/std-proposals and a future conference presentation. 
I wish I was smart enough to write a proposal without introducing issues. Move semantics are quite hard to get right and there are a lot of pitfalls.
Your post has been automatically filtered because it appears to be spam (it was a link to imgur.com). If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Spam%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/8x02es/what_do_you_guys_think_about_this/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Sure, and then there are subtle differences when using auto or passing it to a function template. Not saying it isn't a good solution - just that it probably isn't worth it most of time.
I see this is being downvoted :/ based on the old sidebar I'd say ask at r/cpp_questions I don't think this question would be allowed on normal Stackoverflow either, not that their modern rules make sense or aren't contradictory.
It’s fairly difficult to deliver technical development content through podcast. I think Rob and Jason always find the right balance in the content delivered. If anything, I find it a good gateway to discovering more technical content that I wouldn’t have otherwise found. Especially having the episodes released on a Friday afternoon. It means I’ve immediately got a bit of weekend time to look into anything that sounded interesting. 
Great article. I never thought that function overloading had a downside other than name mangling / breaking compatibility with C or ASM without extern. 
&gt; But in real life the difference will probably be even higher. That assumption is based on what? In my experience, virtual call overhead rarely matters as far as application performance is concerned, unless it happens in a tight loop and each function consists only if very few instructions in which case you are most likely abusing polymorphism anyway.
Have you got some numbers to share? In my experience, recompiling the full unity TU is an order of magnitude slower than a single source file. Whether that actually matters or not to you depends on what order of magnitude you're starting out on.
As someone else pointed out, you can break up your unity build into smaller units, so you only need to compile one of the unity TUs. Some implementations will hook into source control and detect changed files and compile them independently of the unity build steps. &gt; even if building from scratch takes 2 hours, That's a quarter of my day. Our codebase changes heavily every day, so I tend to have to sync up to the latest version every day or other day. If it took 2 hours to build every day, nobody would get anything done.
Or maybe even better: [https://codereview.stackexchange.com/](https://codereview.stackexchange.com/)?
Ofcourse that depends on the codebase - the heaviness of headers and the size of the sources. If you use some of the heavier boost headers in most of your sources and you tend to stick to small source files I would bet that compiling 10-20 sources into 1 unity source file isn't that much different from compiling a single one of them. It depends - use reason to determine if this technique is appropriate for you. For example I wouldn't recommend it that much for C codebases - they a tiny miniscule amounts of zero-cost abstractions in header files compared to a typical C++ codebase. Also there is C++, and there is C++ - people go to different lengths with their use of zero-cost abstractions - some code in C with classes just for the destructors and RAII. It depends.
My main C++ project takes about 7 minutes to clean compile and link. I took a selection of ~100 files and manually changed them to Unity build. The whole Unity file takes as long to compile as any two individual cpp files. Overall it shaved 45s off a clean rebuild of the project. The files themselves were relatively simple but include quite a few headers, mostly through PCH.
&gt; How many cores are you compiling on? On my personal machine, 8, on our build servers 48. On my personal machine, though, I mostly perform incremental builds, so changing out a single cpp file generally result in more time spent linking than actually compiling. On the build servers, it is nigh exclusively from scratch builds. CCache is very useful there. 
Mastering the [Master theorem](https://en.m.wikipedia.org/wiki/Master_theorem) is not hard (if you are not interested in its proof) and pays off immediately when designing your own algorithms.
&gt; The article fails to mention (or maybe I missed it?) the biggest (arguably) drawback of unity build: It greatly slows down recompilation! Sure, building from scratch is much faster, but developers don't compile from scratch most of the time. but the point of unity build is not to use it on individual developer machines, but on build servers where you generally want rebuilds from scratch every time
I'm using unity builds for CI builds and PCH for local builds in my projects. Whole unity builds are ~2 minutes on my machine, whole PCH builds ~10 minutes.
That's not what he was asking
You are right, but sometimes the speed up is well worth these costs, especially if you build system can mitigate them. For example, you could dynamically "de-unity" modified files and have your integration server run non unity build to check for common errors like missing includes. 
Move semantics were an unknown quantity when `initializer_list` was created. But… 1. A paper was written to address the issues before C++11 was finalized. But it led to a decision to ignore the issues, leave the `std::initializer_list` proposal as it was, and try again later. 2. Move semantics are easy to get right if ownership is defined properly. But `std::initializer_list` ignores ownership and takes the approach of "givez me teh dataz." The original intent was only to cover trivial types such as `int`. The numerous proposals behind `initializer_list` seldom if ever mentioned non-trivial element types. 3. It has other ownership problems besides `move`, such as usage as a return value or class member. These problems are avoided due to a special optimization which occurs for trivial element types. `initializer_list` was designed to solve the particular problem of specifying lists of integers in local scope, but then it was standardized to do more than that, with no further analysis or design work. When problems were noted in the context of movability, a couple precautions could have been taken: 1. Revert the scope creep and take only trivial types (and static array storage duration). 2. Apply `const` more sensibly to leave room for future expansion into the domain of responsible ownership. If the analysis and knowledge available in 2009/2010 had been applied properly, the mess wouldn't be so big today. But, the proposal already had support so they didn't want to tinker with it. And the same attitude continues to this day. If you ask about non-trivial types, return values, or whatever, the designers will say, that's not really what it was intended to do — and not something anyone should need.
The article (titled "everything about unit builds") seems to not have mentioned build servers which is kinda strange if that is the *point*. Supporting both unity, and modular builds has the problem of them not being quite the same - a program that is correct in one build mode but ill-formed (or worse, UB) in the other. Why would you generally want rebuilds from scratch on build severs? Isn't that a waste of time? What's the advantage?
&gt; As someone else pointed out, you can break up your unity build into smaller units Once you have multiple smaller translation units, how does this differ from having multiple translation units that you have without unity build?
We use unity builds with PCH and the results are great.
If anything I'd say unity builds are highly overrated. I get it, sometimes it's sort of a necessary evil until we finally have proper modules... But then again, incremental builds with a proper code architecture seem way more practical... although that sometimes means you'd want a PIMPL, which I'm also not a huge fan of. One drawback that annoys me a lot is include hygiene. With unity builds you often get away with using stuff without including the proper headers. Then some time later / on a different branch you get the undefined errors without any correlation between cause and triggering change. To me it seems that throwing a ton of hardware/cores at build times seems really underrated. If you have a good amount of cores and you could easily build all change-affected CUs in parallel, with a unity build you might build a few less CUs but your critical path is still longer...
Not a single C++ book though... Mostly books on hardware/making.
not true - many teams use unity builds on their development machines as well - it's not just for CI builds (although some companies use them only for CI builds)
You can't really develop them quite "the normal way". In a normal cpp file I can put a class names "helper" in an annonymous namespace without affecting anyone else. In a unity build that will likely give a name collision. Things like this are only minor annoyances though - not in any way a deal breaker.
I was talking about embedded nulls. `std::string` can contain null chars anywhere which would greatly confuse functions expecting c-strings. I.e. one doesn't usually think about null-termination when dealing with std::string* types.
Preface: I’m not arguing that unity builds are universally awesome. Meanwhile, how modular is your code? Are there really more than 16 separate modules of functionality in your codebase? 32? 48? I wonder if linking 16 object files with little interconnection would be faster than linking a bunch of highly interconnected .Os. ;) I’m just speculating. Testing these theories is on my todo list. Worst case, to could break each module into a shared object. No linking!
Is P0921 really that empty? I only see a page and a half.
Qt does the static_casting as seen [here](https://doc.qt.io/qt-5.6/qprocess.html#finished) in Qt &lt; 5.7. Qt &gt;= 5.7 uses [qOverload](http://doc.qt.io/qt-5/qtglobal.html#qOverload) and the QProcess example with qOverload is [here](http://doc.qt.io/qt-5/qprocess.html#finished)
Thanks. Something like qOverload looks much easier to be standardized than P0573 (even though the proposals sound awesome to me, but they're kind of a big change).
My first thought is that Herb really wants it to be easy for existing code bases to be ported to deterministic exceptions. That means preserving the existing semantics, existing code, and just changing the mechanism under the bonnet into a much more efficient one. Your proposal wouldn't do that. But I'll CC /u/hsutter, and maybe he'll comment further on your proposal.
&gt;can't we static_cast a function name to a particular overload? This could still cause problems with the backwards-compatible changes that are allowed - e.g. adding a defaulted parameter. int f(); // in the header int a = f(); // ok fun([]{ return f(); }); // also ok fun(static_cast&lt;int(*)()&gt;(f)); // works for now But then you upgrade your library: int f(double p = 1.0); // new header int a = f(); // still ok fun([]{ return f(); }); // also still ok fun(static_cast&lt;int(*)()&gt;(f)); // broken :(
Isn't f with no arguments ambiguous?
Thanks. I think your proposal is indeed good, it also covers constructors out of the box, and overall if it enters into the standard I'll definitely use it, and can even find use cases where performance does not matter (if I'm right this can be implemented in a way that does not require an external runtime unwindind library - which is great). What I was trying to show is that we can maybe achieve the same thing, after working a little harder than I did, and maybe build a generic core language mechanism that allows implementing what you proposed using a standard library feature (such as the std::result mentioned). If this turns out completely out of reach, complicated, or not useful enough, than your proposal will definitely nail it either way. What do you think? 
He’s suggesting it as a prototype change rather than a new overload. 
I was thinking of use in metaprogramming mostly, where you might want to indicate expected vs unexpected to a return type which may, or may not, be an _Either, but you couldn't know in advance. Equally, perhaps being strict as you suggest might make more sense.
http://lmgtfy.com/?q=cppcon+registration
My experience with VC++ is that you can get compile times pretty close to unity builds with an aggressive PCH. Link times may differ, I haven't looked closely at that since the project I tried the experimental support on didn't appreciably speed up with a unity build. Clang (iOS/Android) is different, unity builds seem to have a clear advantage there as the compiler takes a long time to read in the PCH if a lot is in it. I worked on a mobile project where we weren't able to speed up the non-unity build remotely as much even after throwing everything into the PCH. 
It isn't worth the time. But it is better than int const id in most cases. 
Sure, I probably just wouldn't use const. But if I had a language feature like the one I described I'd probably use that. That being said, such a language feature is pretty low on my wish list.
TRWTF is that overload sets aren't an object in their own right.
Well obviously both approaches will have advantages and drawbacks. I'd prefer that the compiler help me to find programming errors over the occasional convenience of a weaker typing. If we can require in the standard that compilers emit warning diagnostics, maybe that would be somewhat of a middle ground (but even then only of questionable value, given tons of important projects use Werror); but on the top of my head I don't think requiring warning diagnostics is a thing yet, so maybe it's wiser to make it an error. Without that, it is somewhere between cumbersome and too hard to detect that new class of programming errors (probably use a static analyzer like clang based ones or cppcheck, etc.), and not everybody will even attempt to. OTOH it will probably be possible for the few who will want to do crazy metaprogramming to use even more of their medicine to reach their goals. Plus from a purely logical standpoint it does not make any sense to randomly throw e.g. "int x = _Expected(5);" if the _Expected is ignored and given the rest of the semantics of the language. 
Please avoid posting benchmarks of code with optimizations disabled. Really. Work out a way for the compiler to not be able to optimize your code due to its structure. Because "I told.it.to be slow and it was" is not an interesting benchmark.
Sorry I disagree, sometimes it's useful to know how much of an impact a specific optimization has. It's not real-world, but it's still useful
Damn I shouldve applied for that!
&gt;Once you have multiple smaller translation units, how does this differ from having multiple translation units that you have without unity build? It's still a big win in overall compilation time if you compile several source files together.
It took me a few seconds to remember the answer to the first one. The second-to-last snippet makes sense, the last one is a mystery to me because I don't know much about C.
In C you are allowed to define file-scope variables of incomplete type with no initializer, so long as the type is completed by the end of the translation unit. So it is a valid definition of object named `final`. 
*Beep boop* I am a bot that sniffs out spammers, and this smells like spam. At least 100.0% out of the 4 submissions from /u/UnitedHeron1 appear to be for Udemy affiliate links. Don't let spam take over Reddit! Throw it out! *Bee bop*
If swapping is not officialy defined in terms of move, then why do we care if the move assignment has side effects or if the type is moveable at all?
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/8x8tw9/looking_for_growing_c_open_source_projects/e21nq8i/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
!remove
OP, A human moderator (u/blelbach) has marked your post for deletion because it is not appropriate for r/cpp. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/8x88dl/c_short_and_sweet_part_1_and_more_courses_for_free/e21nqkn/,%20was%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/8x8zx2/help_with_input_files/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Who cares.
No. 
Why are most of the quizzes I find about bad coding practices?
Because they're convoluted examples to showcase something interesting.
I can’t deny that they’re interesting... you’re right, but I’m always hoping for quizzes that would help me progress in the learning of the language, whereas a lot of these cases should never ever make it into a codebase... does that make sense? I don’t know.
Web devs are still going to use web languages, they already know these languages and they can also compile to wasm and if necessary they can just fall back on the raw code for a performance hit if wasm isn't enabled/supported without any extra effort.
How is this possible when you're already "done" with C++17? Is the preprocessor not part of the C++17 specification?
I don't think so. It's good for porting already existing code to web, but I think we can all agree that writing code for sites in C++ and compiling into WebAssembly is a Bad Idea, because it creates gigantic WASM files with very little (and that's telling it generously) benefit to the developer. That's not to say WebAssembly is useless for a C++ developer: for example, creating a web-playable demo of your game is a sure way to boost sales.
All mainstream languages are getting WebAssembly on their compiler backends, so it will be as relevant as in other platforms.
I learned today that `final` only applied to class definitions. I apparently never was in the situation where I had to declare a `final` class, or I did and never noticed the discrepancy. I also learned to be a bit more careful with contextual keywords. I also learned that this guy is behind `[[trivially_relocatable]]` and that it's about to be formally proposed. Depends on what you want to learn, I guess.
So you are saying that creating a website in C++ in Webassembly will be a bigger WASM file than if you would do the same with Javascript to Webassembly? 
With C++ - certainly, especially if you use templates. The amount of code generated by the compiler in this case is very huge. Plain C code might lead to a smaller WASM file, but once again - I don't think there are benefits to writing site code in C over JS even if C has full and comfortable access to DOM.
I didn't even know such a thing as contextual keywords existed. I guess it makes sense, I do wonder if `auto` couldn't have been `var` then.
That makes some sense. As a late beginner/very early intermediate c++ learner, I probably focus on different things than others who might be more advanced!
I think that will greatly depend on linkers if they could fold identical functions with different names and identical bodies (e.g. `vector::size()`) to single functions. Compiling to wasm essentially enables to use full program optimizations and lto if I understand everything correctly.
`vector::size()` is not the best example, it is inlined as nearly a single instruction (member variable access).
It's still too early to say for sure, but discussions on WG14 are currently hinting towards C adopting deterministic exceptions wholesale, which is huge if it comes to pass. I should stress there is a huge gap between an initial consensus, and standardisation. But WG14 are surprisingly unopposed to C adopting exceptions. Which amazes me. I guess maybe the time is now right.
&gt; One thing I haven't understood from your paper and Herb's, is how to migrate from application/domain specific exception classes to the new mechanism It is not well documented, true. Can I cheat and point you at a real world example of a custom error code: https://github.com/ned14/llfio/blob/302db08dd88a5e77fb40103ed632be1e72066bf1/include/llfio/v2.0/status_code.hpp If it doesn't make sense, come back to me. &gt; Also, can the new model support attaching stack traces, at least with some compiler flags or activation macros? Absolutely. The above custom error code capture log entry, stack backtrace, handle causing error (with pertinent file system paths). I would say, though, that it's not usually a one to one conversion from existing custom exception classes due to the much tighter requirements on `errored_status_code`. If we get move relocation, then you can of course simply wrap your custom exception class into a `std::exception_ptr`, and send that. Indeed, legacy exception throws may just get auto converted into that for you, if expected implementation comes to pass.
&gt; I am getting a feeling from the /r/rust feedback that there is an amount of disquiet with the consequences of Rust's choice of Result&lt;T, E&gt; and the current form of panics. Could you mention where are you getting this feeling from or what this "disquiet" is about? As someone that interacts a lot of the community, the only feeling I get about `Result` from just about everyone using Rust is that everybody enjoys using it for error handling, and IIRC every RFC related to `Result` in the last 3 years has been about either enabling its usage in more situations or making it easier / less typing to use so that people can use it more. I might have missed some RFCs about this, but I do not recall a single RFC about either using it less, or adding something else to the language or library to use instead of Result.
&gt; creating a web-playable demo of your game is a sure way to boost sales I don't even know what to say. Library support? Huge game size? Porting your whole game to a web browser? I'm at a loss here.
The metaprogramming stuff with templates compile away even at -O1 a lot of the times.
All the C++ quizzes be like: "Is the following valid C++?" ;;{}{}{}{}{N;; int xxx; &lt;&gt;{}()\[\];;;sdfkj;}
Wasm binaries are a lot bigger for languages with a GC, which is normally incompatible with the browser GC. So Wasm matters less for Go, C#, Java and similar.
Honestly, the Rust ecosystem is moving a lot faster in the Wasm space.
Not in my experience with Emscripten (thought, to be fair, I last attempted to do anything with it more than a year ago, and things might have improved since then). Our game wasn't even using very heavily templated code like Boost, just some STL containers and algorithms and a few custom classes, and still the size and the load time of the resulting WASM file were unacceptable.
Just for your information, there's no such thing as "JavaScript to WebAssembly". JS and Wasm will remain orthogonal to each other. But to answer your question: Yes, it'll most likely be bigger than doing the same thing in JS.
We're not talking Assassins's Creed here, of course, but mostly indie games, which tend to be on a smaller side (and for demo, a lot of content can be cut). If you're mostly using wide-used libraries like SDL and FMOD and have a decent build system script (e.g. CMake), you can probably port your game to run in browser using Emscripten in a week or two. Even less, if you develop it from the beginning with Emscripten in mind (that mostly means build scripts, though if you want to allow users to save/load their progress in web demo, you need to get used to the way Emscripten works with the browser's local storage - it's asynchronous and somewhat inconvenient). I have some positive experience with this, as I single-handedly ported Allegro game library to work in browser in relatively short time (under month), and was then able to run a few of my pet projects. Of course, if you use hand-coded engine with lots of DirectX calls instead of SDL/Allegro/Whatever, then you might be in trouble, but who does that any more? More graphically intense 3D games will have more problems, since WebGL is a bit limited compared to desktop OpenGL, but, once again, most indies aren't using advanced graphical features, even in 3D.
In the days of JavaScript frameworks larger than Quake just to display text that is a moot point. Unity can target WebAssembly with sizes of a few hundred KB. Flash also had a GC and outside geek circles very few people minded. This is just FUD against managed languages. http://platform.uno/Playground/index.html
&gt; The code in f5() looks messy with deeply nested if-statements! The only reason there are deeply-nested if-statements is because they're formatted like if (a) b else if (c) d else if (e) ... instead of the more conventional if (a) b else if (c) d else if (e) ...
&gt;Stevens Hi, Yes, please go ahead and email your resume to [recruiting@scm-lp.com](mailto:recruiting@scm-lp.com). Could you give me more details as to why our ATS did not accept your resume? Did you get a error message? I'd like to look into it and fix the issue. Thanks,
Yes, but later in the article this fuction uses std::visit. So at the end we have a nice code. See f51()
I dislike this kind of approach, as you end up with stuff like this: void f2(any&amp; param) { auto&amp; v = any_cast&lt;Params&amp;&gt;(param); v.push_back(getnum&lt;double&gt;("Enter a real")); } void f6(any&amp; param) { auto&amp; v = any_cast&lt;Params&amp;&gt;(param); v.push_back(getnum&lt;double&gt;("Enter a real between", 5.5, 50.5)); } void f3(any&amp; param) { auto&amp; v = any_cast&lt;Params&amp;&gt;(param); v.push_back(getchr("Enter a char")); } These functions are not type-safe, and unnecessarily accept `any` as an argument. What I would prefer, instead, is to define them as follows: void f2(double param) { // ... } void f6(double param) { // ... } void f3(char param) { // ... } And have my `menu` class automatically figure out what the parameter type is. This is almost trivial with `boost/callable_traits` and C++17 *fold expressions*: template &lt;typename... Fs&gt; struct menu : Fs... { menu(Fs... fs) : Fs{fs}... { // Print menu selection auto print = [i=0]&lt;typename X&gt;() mutable { std::cout &lt;&lt; i &lt;&lt; ") f" &lt;&lt; i++ &lt;&lt; '\n'; }; (print.template operator()&lt;Fs&gt;(), ...); // Choose function to invoke int n; std::cin &gt;&gt; n; // Dispatch invocation auto call = [this, n, i=0]&lt;typename X&gt;() mutable { if(n != i++) return; using arg_t = std::tuple_element_t&lt;0, boost::callable_traits::args_t&lt;X&gt;&gt;; arg_t arg; std::cin &gt;&gt; arg; static_cast&lt;X&amp;&gt;(*this)(arg); }; (call.template operator()&lt;Fs&gt;(), ...); } }; [**live example on wandbox.org**](https://wandbox.org/permlink/BeEUgLbVn7PeTIUd) --- Note that this is incomplete and just a proof of concept, but I find this approach better compared to what the blog post presents. The parsing of the arguments and error handling could all be automatically done by the `menu` class.
That's great, but the justification for changing it isn't. Arguing about a sequence of chained if-statements is fine, but the nesting has an obvious solution. 
macros and anonymous namespaces indeed are the primary problems. However, macros suck anyway and namespaces can be handled easily at least when planning for unity builds from the very beginning. Retrofitting that on an existing large project can be painful, though. Still beats writing "how to compile SupaLibb with &lt;select your environment&gt;" in my book.
This is a recurring pattern with these C++ "bloggers". They invent problems and intentionally obfuscate otherwise simple solutions just so they can slam dunk "this latest and greatest C++17 feature that makes code simpler" at the end of the article.
You didn't download the GC on every page view with flash.
\&gt;modern C++17 \&gt;using string instead of string_view
The benefit is speed. People seem to be missing this. A library created in webasm can be called from JavaScript, and the advantage is that it will be much faster.
 try {That makes me nostalgic feel for my Java days. } catch(IOException ex){}
But how many sites, or even web-apps need that speed? Most of them aren't doing heavy computations in browser, and should not be doing them. OK, maybe if client-side neural networks will become more widespread, we might need WebAssembly to run them in browser. But even then, I doubt it will create a need for more C++ developers.
Ever heard of PWAs and IndexDB? https://developer.mozilla.org/en-US/docs/WebAssembly/Caching_modules http://www.wasmrocks.com/topic/237/webassembly-caching-to-html5-indexeddb
Maybe it is good for crypto currency minor disguised as AD.
You ported Allegro to the browser? The old version that still supports MSDOS? That would be really fun, being able to compile the same code to run in MSDOS (and dosbox), various other more or less modern systems, and in a browser.
No, the new one (5.x). My port was never added to the official repository (since nobody wanted to be a maintainer, including me), but you can check out a [demo](http://zxstudio.org/projects/allegro/skater/skater_r.html).
I agree, but could not think of a better example. 
&gt; Visa Sponsorship: Yes So for the next round of H1B's, i.e. in 2019? 
The episode's title might be somewhat misleading, yeah. If you haven't already, I do recommend watching Michael's C++Now talk though, which cover the topic quite extensively. 
Not sure if you're the author, /u/onqtam, but I'd like to add that [waf](https://waf.io/) also supports automatic generation and handling of unity builds.
Gosh this is gonna be so cool to hear the recording for. I'm in the midst of building a nice and capable (and flexible, of course, might as well get all those vague words in there) visualization system for a work application - hearing how a large scale software like Houdini has been built and maintained since the early days will be incredibly useful I imagine. It's not even supporting things like framegraph/rendergraphs or using the Vulkan API that has proven the most difficult - it's building all the supporting architecture and functionality required for a software product as complex as a rendering system
Are these posters for presentations, or just posters that will be in the lobby?
GC is planned feature for wasm, it just wasn't part of the original spec. AFAIK.
"Look how messy and hard to read this range-for is. Let's change it to a few better double-templated algorithm function call that no other programmer will understand!"
&gt;almost trivial I disagree with that characterisation. The first example seems like the fastest to write and easiest to maintain to me.
 &gt; This is just FUD against managed languages We are in r/cpp
What does Rust have to do with WASM?
I'm writing a paper about optional (and consequently, variant and other vocabulary types in the standard). I need some data about what codebases have. I have been doing this research by-hand for a while and manually asking tons of people, until I realized that maybe a Form would be a better idea. Feel free to fill out everything to the best of your ability! This stuff will go into a paper as a proposal to the standard.
wtf is so interesting about optional. every other post is about std::optional. it's pretty basic, no?