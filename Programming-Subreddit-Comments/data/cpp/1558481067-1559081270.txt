Though Hunter is written in CMake it is a large, fully-featured package manager, comparable to conan or vcpkg. These usually have a central database of dependencies (though some allow adding external projects as well) and require a special recipe containing install instructions for each dependency. If you are interested I've found a great post [here](https://www.reddit.com/r/cpp/comments/8t0ufu/what_is_a_good_package_manager_for_c/) comparing different package managers. CPM takes a different approach as it aims to be extremely lightweight and to require no setup from package creators. Any downloadable project can be directly added as a version-controlled dependency with CPM. Also for users of a library that uses CPM it should not be noticeable. The main downside to CPM is that each new project needs to download and build all its dependencies from scratch, though there are workarounds. Also shared dependencies must always be added using the exact same name, as otherwise the same target may be created twice. I recommend using the name of the target created by the dependency. For me the setup-free approach for users and maintainers greatly outweighs the cons and CPM has allowed me to focus on creating great libraries and not worry about dependencies.
Thanks for pointing me in new directions. Indeed coroutines does look like it kills two birds with a single stone. Also, thanks for everyone in the other Promise implementations.
As a side note: I was able to compile and hear all sounds used in the Hello World example. I'll tinker some more and if I resolve this issue, I'll keep you all updated.
It was a problem with my sound file. Sorry, guys. Everything works just fine.
So I've done more research into this and now I understand why I was seeing such variable performance on key lookups across different msgpack libraries, and I'm also not sure if it'll be possible to implement a fair head-to-head comparison with msgpack, at least for object key lookups. From a design perspective, the msgpack format seems to focus entirely on two things: representation size on the wire, and compatibility with incremental encoding/decoding. To these ends, msgpack doesn't actually encode *any* information about object layout on the wire (beyond the size), expecting client libraries to implement a distinct unpacking step to raise the encoded object into a higher level API that's efficiently queryable (I forgot this was actually part of the reason we rejected using it, I'll have to update the Dart readme). msgpack-c does this by providing an unpacking/conversion API to different STL types, and also an API to allow users to extend this to their own custom types (it's actually really pretty cool, just not good for a comparison). Dart, by contrast, focuses on being usable, directly, in-place, on the receiver end (I wanted to have many separate processes working on packets simultaneously, in shared memory, with no copying), and therefore encodes additional information to allow efficient access on the receiver end without unpacking. The existing benchmarks try to measure the cost of going from a packet received over the network, directly to querying keys/values from it, which, for Dart/Flexbuffers/sajson, is a simple matter of querying the underlying binary format directly. For msgpack-c, before you can query the object you have to unpack the data into some intermediate type, like std::map, which will so thoroughly dominate the performance trace that I'm not sure it makes sense to pursue. There are other msgpack implementations like [https://github.com/ar90n/msgpack11](https://github.com/ar90n/msgpack11) and [https://github.com/jonathonl/goodform](https://github.com/jonathonl/goodform) that *do* produce an immediately queryable representation, but in that case I would be benchmarking the performance of that particular implementation, and the post-unpacking data structures it chooses to use, instead of the format itself. I would, however, be able to write a head-to-head benchmark for heterogenous array performance, since that doesn't require additional representation overhead, so I think I'll pursue in that direction. Your thoughts?
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/brhv40/need_help_asap/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Well thank you very much! I've put quite a lot of time into the library over the last few months, so I'm glad it shows! Also, thanks for the offer, I'm flattered, if anything changes on my end I'll definitely let you know. Also, yeah, if you've got schema information for your streams, a library like flatbuffers is absolutely the way to go. It'll always be faster because it depends on code generation and is basically just a struct with a statically encoded vtable, reducing "lookup" to just an indirect load. In my experience, dynamic formats also tend to get very messy over time, since all discipline related to maintaining the schema over time is optional, leading to a lot of awful validation logic, and structured libraries like flatbuffers/protobufs/etc remove this problem completely. Dart really shines when you're looking for a more efficient way to interact with JSON specifically, or if you need to efficiently interact with badly behaved data streams that you can't change, as was the case for me. I ***really*** like the idea of using the customization point to add constexpr hashing in the context of key lookups. My team has internally done some work with precomputed hashes for specific use cases, but the feature didn't seem easily extensible to me at the time, and so I didn't pursue adding it into the public release. But as the most common use case will almost certainly be the user looking something up with a string literal, this could almost completely remove the hashing overhead for the general case while still providing the associated speedups. Plus, constexpr evaluation is an area of C++ I'm still weak on, so this'll give me a great opportunity to sharpen up my skills. Are you aware of any existing C++14 and up constexpr hash implementations I could start researching?
I also agree that it's a good idea to provide some feedback to the user if collisions are getting really common and degrading performance, but generally speaking I prefer libraries not to log unless they absolutely have to as they tend not to integrate with whatever logging scheme the surrounding application uses. I'll have to give this some further consideration.
Looks like technical vs conceptual definition. Primitive types has well defined properties like addition, subtraction etc.
Can I say the same about chars?
I've actually also done some work on lock-free, shared memory, hash tables in the past few years! Not a very common pastime, and comes with lots of unique challenges, so it's really cool to see someone else interested in this space. Reading over simdb I see some similarities with tables I've worked on previously with regard to algorithmic structure/memory layout, but you've gone the extra mile by actually using shared memory regions to simulate different tables within a database, which is extremely cool. One suggestion I might have (which you've already explicitly called out in the readme) is just to add a benchmark case or two. Doesn't have to be super complicated, but it *really* helps to drive confidence in the library on the user end. Really cool work, I'll have to check out LAVA in general; it seems extremely ambitious!
I noticed a thread about [CPM](https://www.reddit.com/r/cpp/comments/bpr7wq/cpm_a_setupfree_cmake_git_dependency_manager_v09/) recently. A tool I wrote, cmake-cooking, has similar goals. That is, it's a light-weight wrapper over CMake for managing external dependencies for reproducible development environments. I think one major difference is that cmake-cooking is a layer over `ExternalProject` whereas `CPM` uses `FetchContent`. cmake-cooking is one option for managing dependencies in the [Seastar](https://github.com/scylladb/seastar) project (the other being system packages). Comments and bug reports are welcome.
I would disagree with the second defintion. An object doesn‚Äôt have to represent a real world concept, and trying to map the two together, save for simplistic stuf, fails terribly.
Why make people ask? Just post the github link.
Yeah. I was gauging interest before I spend time getting it ready for presentation and stripping out specific pieces related to the parent codebase. I'll try to follow up with that.
Came here to say exactly this. :) Nixing the idea that objects are supposed to model real-world taxonomies of things is one of the most frequent "lessons" I have to give to associate developers.
Thanks. Something else I never quite understand is... say I wanted to emulated a plate reverb. So that's an actuator on a metal plate that vibrates it and a sensor somewhere else on the plate that picks up those vibrations. So I have a fairly small input for each round, which is some incoming audio wave samples. And I have a fairly small output, which is some sort of summation of the average deflection under the sensor which will create another set of audio samples of the same size. But, I have a large data set since every point on the plate I'm using to simulate this vibration has to be persistent and used on an ongoing basis because it reflects the current vibration patterns on the plate. But I can only run a certain number of rounds before I have to get a result out because this is real time'ish stuff. I will get, say, 64 ms worth of input samples, and will collect 64 ms worth of output samples in return. Then I need to stop because the amount of samples I can see ahead affects the latency of the output audio to the person doing the recording (because it requires buffering.) Then at some point later, another 64ms of samples will become available and I can do another chunk. Am I reloading that whole data set to the CUDA board every time I invoke the process to calculate another chunk of samples?
Are controls or graphical widgets on a screen real world objects in this definition? Or do you take that to mean vacuum cleaners and stretch pants and such?
Do you use unified memory? If yes, I'm not sure how CUDA "cache" those in device memory. I usually avoid unified memory when I want performance. If not, you manually do the transfers of the data by doing memcpy from host to device. You do not need to send the input again (if it didn't change), and it will keep it there between kernel calls. It might get evicted from L2 caches but that's negligible overhead.
It's hard to be really, really general. But I would say this: An object is an arbitrarily selected (but in practice closely related) set of values which are used to represent any attributes of some concept or real world entity you wish to model, modifications to which are only allowed through a set of specifically associated actions that insure those values are never placed into an inconsistent or invalid configuration.
I don't know enough about CUDA to know what a unified memory is, so hard to say :-) The above was just an imaginary example scenario that I'd thought of before as an interesting application of CUDA.
An interesting approach. Here's some feedback: * A variable is required for storage so you end up with 2 lines per argument, and you end up typing the var name twice (again with "\_var" suffix) * The code should be able to distinguish from null/unspecified and empty or 0 option values. Maybe show that in the example. * It's often preferred to store results in a map object, which is easier to pass around to other functions or merge with values from a config file. * Creating a scope for temporary processing vars is a bit awkward and it's not obvious how these variables bind to the parser (hidden static/global variable?). Requiring a function for each sub-command is also a bit awkward. What if the sub-command also has it's own options and arguments? * What if "--help" appears after a sub-command? I'll often be in the middle of a command and forget something and just type "-h" at the end of all the options I typed so far. Then I can edit my last command and remove the "-h" * Consider supporting "global options" before and after the sub-command, so they work before and after the sub-command -- many types the context of a sub-command doesn't matter * How flexible is the auto-generated help? Can it be given extensive documentation with details, bullet points, and an epilog? What if an option has an extensive multi-line description? For many command-line tools written in a hurry the usage help is the documentation. * What if there are multiple command-line parsing instances at once? Like for example a multi-threaded server processing commands through telnet. Are separate parsers thread safe? Most people won't expect cases like this, but worth a thought. More flexibility also makes it easier to unit test. * I've found code like this to be more readable when it looks more like the usage help itself, especially when you see actual option names (with dashes) in the code like "-f" and "--file" followed by descriptions shown in usage help * Have you tested in Windows where options use forward-slash instead of dash and colon instead of equals? * I suggest moving your basic usage example near the top of the README -- many people want to see that first &amp;#x200B; Some libraries I suggest taking a look at for inspiration: * [Evo CommandLine](http://jlctools.github.io/evo/evo-0.5.1/html/classevo_1_1_command_line_t.html) class -- note: I'm the author * [https://github.com/docopt/docopt.c](https://github.com/docopt/docopt.c) \-- command-line processing inferred from writing usage help * [https://docs.python.org/3/library/argparse.html](https://docs.python.org/3/library/argparse.html) \-- many people are already familiar with interfaces like this
Great question! I'll start by noting that I probably should have said "class" rather than "object" in my prior post, since the latter term can mean a few different things. I generally wouldn't consider UI controls to be real-world objects, but if you take it to the extreme like "buttons" then they certainly can be. I will definitely argue that creating distinct types for modeling the different varieties of common UI control is wrong. In object-oriented programming, model _behaviour_ and not _taxonomy_. As a thought exercise: what's a button, besides being something that receives mouse clicks and has a particular render style for idle/hovered/pressed? How is that different than a hyperlink other than the rendering style? Can't other controls receive mouse clicks? And can't other controls have multiple render states? A good UI framework will focus on objects/classes that enable composition of independent behaviours (input handling, render states, layout, etc.). A poor UI framework will strongly proscribe some explicit taxonomy of UI controls (via specific `Button`, `List`, etc. classes with special-cased behaviours that aren't factored out). Which boils back down to your question: the concept of a "control" is perhaps a good case for an object/class (though arguably it might be better as a composition of objects), but the _specializations_ of a "control" probably shouldn't be classes. Though this can also be somewhat limited by choice of implementation language, as sometimes the best tool the language provides for certain cases is a class (esp. when the language lacks the notion of a closure and the only way to encapsulate data+behaviour is via a class).
Can't find one either. I'd just heard that C was getting/had gotten function overloading in recent history. Maybe it's just the inline keyword...at any rate...I'm obviously wrong. :p
As with all things software, there's a lot of ways to skin the same camel. I would say that taxonomy does matter. Even if you say you are modelling behavior in the creation of the widgets, the code that uses those things will (at least in a lot of places) work in terms of taxonomy. Here I will only accept something that's a button or a derivative of a button. A link isn't acceptable, because this code works with buttons (a button configuration dialog, for instance.) Or I will only work with containers or container derivatives because I configure containers or I am a popup dialog type manager and can only accept containers of widgets. I think that UI frameworks are some of the best applications of straightforward OOP principles. I have two very complex ones in my code base and they very much are taxonomic along the main line, but with behaviors not related to the main taxonomy mixed in via interfaces. So I have a text display widget base class and various derivatives that implement specific types of displays of text. But I need to allow most of those variations to have a statically convfigured (and/or set via command at viewing time) text value, a value gotten from a device under control of the system, a value from a UI system variable set by user logic, and so forth. The button hierarchy allows for very straightforward configuration of all types of buttons. Where their values come from are done via mixed in interfaces, since that's not part of the basic taxonomy of buttons and those value source scenarios need to be applied at various places throughout the class hierarchy. This type of setup works very well.
`char c = 'a'; assert(++c == 'b'` sure, why not?
Consider it posted! [https://github.com/arlettedata/promise/](https://github.com/arlettedata/promise/blob/master/promise.h)
Oh god after your message I checked it and realised I have DarkReader enabled on Chrome so it looks great for me. I made changes to the visuals before I posted here but didn't turn off DarkReader. Sorry about that, it looks absolutely awful hahaha! That was not intentional.
I've obviously never seen your framework so I can only make conjecture; this all is opinion based on my experience and even if I often speak with absolute conviction, I concede that I can be wrong. :) &gt; Here I will only accept something that's a button or a derivative of a button. A link isn't acceptable, because this code works with buttons (a button configuration dialog, for instance. And that's where we differ in opinion. :) I'd argue that code that only works with buttons and not links is problematic. What's the difference? Why isn't your configuration dialog the place where you decide whether a particular clickable "thing" looks like a button or looks like a hyperlink? Why can't I make an arbitrary block of text look like a button even if it can't be clicked? Why can't I make an image click like a button but without any custom styling? Gobs of code that can only configure the entirely-arbitrary definition of "button"? How many repetitive variants of configuration dialog are necessary to configure everything? What behaviour is so special for a button that no other widget is allowed to reuse that logic? &gt; a button configuration dialog, for instance. &gt; Or I will only work with containers or container derivatives because I configure containers or I am a popup dialog type manager and can only accept containers of widgets. I do not believe that one should use _types_ to differentiate those things. Any control could contain children, and any control could act like a button. It can be purely dynamic whether a particular control is a button or is a "container". There are reams of examples of "bad UI design" where a designer legitimately wanted to make something act like a button and it _almost_ works (e.g. because only `Button` interacts with tab-selection or screen readers or whatever, but the designer can't use `Button` because it's saddled with some other undesired functionality or is missing something only found in some other `Widget`-child). A programmer could probably go in an make a new `Widget` with all the required behaviour for this designer, but that's perhaps a bad use of time. A designer should not be beholden to an engineer prognasticating their every need, and should not have to wait on the turn-around from an engineering team (which probably already has a big enough backlog as it is) just to try out prototypes and ideas that may not even make it into the final product. Excessive or misguided object typing/taxonomies can unintentionally impose undesired limitations not just on engineers but on everyone who _depends_ on the engineers. :( Though it usually is only brought up for game development, I'd suggest reading through the classic [Evolve Your Hierarchy](http://cowboyprogramming.com/2007/01/05/evolve-your-heirachy/) article. &gt; I think that UI frameworks are some of the best applications of straightforward OOP principles. I fully agree! I just disagree that having e.g. a `Button` explicit type is necessary to express straightforward OOP principles in UI. :) &gt; So I have a text display widget base class and various derivatives that implement specific types of displays of text. I don't feel that what you describe from this point really says why taxonomies or hierarchies are needed. There are purely composition-based UI frameworks that can do everything you outline and do it easily. I would point to the modern Web and the overwhelming popularity of FRP-style UI frameworks (like React) as the prime examples, sans their legacy detritus hanging around for back-compat reasons. &gt; But I need to allow most of those variations to have a statically convfigured (and/or set via command at viewing time) text value, a value gotten from a device under control of the system, a value from a UI system variable set by user logic, and so forth. I wouldn't consider this value-binding to be specific to text display. What if I want to bind a value from a system device to the name of the font used by the text control? If `Text` is some widget with magic for binding its target string to an outside resource, does that imply that the engineer has to correctly guess up front which properties need to have configurable bindings and to what inputs? Follow the SOLID principles, specifically Separation of Concerns: a `Text` object that can draw text is a reasonable thing, sure. But then _selecting which text to draw_ is a separate concern and so it should not be tightly tied into the `Text` object itself. This is precisely why so many modern UI frameworks have very rich MVVM systems with flexible value binding support, or why Elm-inspired FRP approaches like React have become so popular for building UI on the Web. &gt; The button hierarchy allows for very straightforward configuration of all types of buttons. Except hyperlinks, which to me are conceivably just inline-styled buttons with a convention of using a blue font color. :p And presumably if you have a separate `Hyperlink` widget, all that button configuration dialog logic has to be duplicated to configure the behaviour and appearance and bindings of links. There's of course still a taxonomy to be found here! A "button" is a "button" after all, and that's a key part of the design language of the UI! Where we disagree is that I believe this taxonomy _does not belong in code_. It belongs in data. And that data is read, configured, and stored in code classes/objects that _describe_ the taxonomy but do not themselves belong to it. :)
You mean like blaming all of Boost and linking to a single library's design rationale?
As you can imagine, the word "object" is very general, and can mean slightly different things in different contexts. &amp;#x200B; The first definition, is a more C++ and technical definition. See also the first chapter of Stepanov's Elements of Programming for more of this definition in depth. But the basic idea is that we have just memory - a bunch of numbers, like cells in a spreadsheet. That's all a computer has. But we apply rules to the memory, and say these 4 bytes here will be controlled by rules that make it act like a single integer, etc. Almost everything in C++ is objects. Calling malloc gives you raw memory, but calling \`new\` gives you an object. \`int x = 17;\` gives \`x\`, which is an object, stored somewhere as bytes in memory (or in a register, but ignore that). The \_value\_ of \`x\` is 17 (regardless of what the value of the bytes in memory are in order to build 17), but the object \`x\` is the recognition that the value is stored at a memory location. Note that objects have memory locations, whereas values do not. The return value of \`int f()\` isn't really an object until it is stored (ie assigned) somewhere. &amp;#x200B; The second definition comes from Object-Oriented Programming, for any OOP language. Which tends to talk about "real world" objects, like vehicles, cars, trucks. Which are modeled as classes that store state and methods that expose behaviour. &amp;#x200B; But these definitions are not incompatible. &amp;#x200B; An \`int\` has state - the number it stores. And behaviour - the math operations. Even \`std::cout &lt;&lt; x\` is behaviour of \`x\` even though \`&lt;&lt;\` isn't a member function of \`int\`. &amp;#x200B; One of the beautiful parts (and design goals) of C++ is that your own classes can act as natural as the native types. C++ does not make a distinction (for the most part) between native types and the classes you define. They are both considered "objects". And they are also both considered "values" that can be returned, assigned, copied, passed along, etc. (This is why C++ gives classes default copy constructors - so they can naturally act like values.)
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/brkpk0/update_database_with_filename_where_id_is/eoeoc4s/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Your code isn't C++; I think you're looking for a different language entirely.
It even was C# Code and not C++ üôÑ
David Sankel (committee member) has done work in this area https://www.youtube.com/watch?v=pKMZjd9CFnw https://www.youtube.com/watch?v=2OY0Zn3oBCE
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/brhf9n/developing_with_irrklang_on_macos/eoep0zr/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
!remove
OP, A human moderator (u/STL) has marked your post for deletion because it is not appropriate for r/cpp. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/brl211/i_created_a_hockey_shootout_game_try_it_out_and/eoeqrap/,%20was%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Thanks! Great work, I'll definitely use it
I'd be careful about this since you run a danger of trying to ascribe higher meaning to idiosyncratic nomenclature. What constitutes an "object" depends on the context, framework and intended use. Strictly speaking, in C++ an "object" is just a readable/writeable regions of storage ‚Äî this is how the C++ standard defines the term. Usually, when one uses the term, one refers to some object-oriented programming model (as per "behavior and state", "real work concept" definition examples, which are very popular, but ultimately useless aside from being a reasonable teaching aid for OOP introduction). My advice would be not to focus that much on all these definitions but rather look at what a particular language does with them.
I love the wsl integration and language support for cmake. Also have to check how address sanitizer integration works in practice. Is &lt;charconv&gt; complete?
Woohoo, cmake project loading finally becomes usable! Thank you Microsoft for taking my feature request on this to production! Now I have a ton of build configs to convert over to the new system, but that's a good thing.
&gt; Lambda support has been overhauled, addressing a large number of long-standing bugs. Is there a list of these fixed bugs regarding lambdas?
What would really set any serialization code-generator apart is micro-optimizations. If you watch any typical video on performance optimizations in algorithmic trading, you can see that people typically write their own algorithms for unpacking, say, integers within a specific range faster than the default serializers do. Having this sort of functionality auto-generated for you would be really cool imho.
When you send data to GPU DRAM (called global memory), it stays there until you deallocate it, so you can send data once and then run kernels multiple times on the same data. Unified memory enables you to access CPU-side memory (with some limitations) from the GPU. It serves to ease the programming, but for obvious reasons (you have to to through PCI), it may not be very performant. It evolved over the years so it exists in several variants, the newest GPUs can automatically migrate memory between CPU and GPU on a page-by-page basis, which can alleviate some of the costs.
&gt;CMake integration now supports the Clang/LLVM toolchain for projects targeting Windows and/or Linux. Is that clang-cl or clang++ on windows?
Very nice! Minor comment: The link to the blog post on that page is broken: [https://devblogs.microsoft.com/visualstudio/visual-studio-2019-version-16-2-preview-1/](https://devblogs.microsoft.com/visualstudio/visual-studio-2019-version-16-2-preview-1/)
No charconv changes in 16.1; it had a short dev cycle. For 16.2 (which is feature-complete and locking down for release), I've checked in another major step towards completeness: fixed precision (like printf %f) and scientific precision (like printf %e), powered by more of Ulf Adams' impossibly fast magic. This also improves the speed of shortest fixed notation. I've also improved from_chars() in 16.2, changing its behavior for overflow/underflow to align with strtod() and user expectations (LWG issue resolution pending). And I fixed a couple of bugs in from_chars() that were inherited from the UCRT implementation (obscure corner cases, like parsing a thousand zeros followed by a one; nothing to worry about). There's one remaining part for charconv to be complete, which is general precision (like %g). I hope to finish that for 16.3, but no promises yet. (I also want to go back to integer charconv and make it faster, but that's separate from feature completeness.)
Hey, author of CPM here, thanks for sharing your project and linking to my thread! :) Cooking looks interesting. I think it would be great though if you could you provide a minimal working example or a tutorial (e.g create a test suite using Catch), so that users have a quick starting point and can also see the most important functionality at a glance. Do you have a reason to use ExternalProject over FetchContent? ASAIK ExternalProject tries to download the dependencies at build time, which I imagine it would create problems when working with recursive dependencies, as the full dependency tree cannot be known until building is complete. Can you also elaborate on the focus on composition and how it differs from the CPM approach? Using CPM a project can also ‚Äúinject‚Äù its own version of a library into its dependencies by adding a more recent version of the library before adding its dependencies. Great work!
&gt; If only a few things were updated and a few features added. Which is an ongoing process since 1983 :)
If C++ is your first language, programming principles is the way to go.
Yeah sound, well it arrived yesterday so just started going through it, seems very well written, at least of what i‚Äôve read anyway
At the start of every episode Jon reads out some random funny disclaimer :)
Qt needs to release MSVC 2019 binaries before I can give it a go
As a reminder, VS 2019 16.x remains binary-compatible with VS 2017 15.x. There are a couple of restrictions (no LTCG, final linker must be new), but you should definitely be able to use older separately compiled libraries - that's why we go to such great lengths to preserve bincompat.
I was wondering the exact same thing. My bet would be clang-cl for now.
If it's WSL it should be clang, not clang-cl.
Do you know what the state of cmake and system headers is? Is it possible to supress warnings now from headers that come from a 3rd party, be it by target_link_libraries or target_include_directories(SYSTEM.
It's clang-cl.
I can‚Äôt read the Reviewer‚Äôs Guide, Has someone been able to read it ?
It does not matter, just pass the clang++-specific options you might want to pass with `-Xclang whatever-option`.
It matters, because if it was clang++, I could simplify some of my cmake scripts for projects that don't actually have to compile with msvc as long as I get a windows binary (no \`if(MSVC)\` anymore). But at least in the past,cmake didn't support clang++ on windows.
What are you (or am I) missing? For all intents and purposes, `clang-cl` =:= `clang++`, `clang-cl` does exactly as `clang++`, iff passed the relevant options/parameters the appropriate way.
Starts_with, ends_with and contains? Have have the world come to?!
May I ask how big your experience is with c++? Projects like these are the ones I aspire to do some day.
Almost 10 years. :)
I can use clang++.exe on windows perfectly fine from the command line, using the usual linux gcc flags like -O3 (no idea, whether it is using libc++ or Microsoft's standard library by default) and can use it to successfully compile semi-complex projects by hand. What I can't do is instruct cmake to generate appropriate Ninja (or whatever build system you prefer) files that would use clang++.exe and the reason why I would like it to do that, because then I wouldn't have to worry about e.g. adding \`/W4\` when compiling with msvc (or clang-cl for that matter) but \`-Wall -Wextra\` when compiling with clang or gcc on linux. More generally: It would be one less compiler driver to worry about . Btw.: I know that the ms standard library is being tested regularly with clang. I don't know if they test it with a mode where clang pretends to be msvc or not though.
I'm in the exact same boat. I would much rather use clang++ just, without the extra layer that is clang-cl.
Very cool
&gt; ... no idea, whether it is using libc++ or Microsoft's standard library by default ... Unless some magic happened, it's using the MSVC-STL. &gt; What I can't do is instruct cmake to generate appropriate Ninja ... Yeah, I get what you mean. On my system it detects MinGW64-gcc-8.3 (that's what's there, so no complaints about that), but I don't (indeed) know how to make it [ninja] use the windows-bit of the world (beit vc or clang). &gt; I don't know if they test it with a mode where clang pretends to be msvc or not though. The MSVC-STL needs to know about `_MSC_VER` so, I don't think there is much choice.
Never would have thought charconv would be the long tail of c++17 support (I think libc++ and libstdc++ are also not done yet, but IIRC they are missing parallel algorithms too). But I think the fact that something so fundamental it is so hard to implement very much justifies its addition to the standard.
 Version 2.5.8 is available :) https://forum.adlice.com/index.php?topic=3584.msg9151#msg9151
There is no extra layer, they are two interfaces to the same thing [but the clang++ one is more extensive]. The binaries are the same [like the same file-hash], the different behavior gets triggered by the file-name [an old c-trick].
If you mean something like this: std::vector&lt;int&gt; v = {1,2,3,4,5}; , you are actually initializing it with an [initializer list](https://en.cppreference.com/w/cpp/utility/initializer_list) (constructor #8 in [this page](https://en.cppreference.com/w/cpp/container/vector/vector)). The first link has an explanation and sample code, but, in short, the list has the information of where it ends, unlike a simple array.
That explains it, thanks.
I'm getting some compiler errors. &amp;#x200B; Is this code valid? [https://godbolt.org/z/mu8KG7](https://godbolt.org/z/mu8KG7) &amp;#x200B; its supported by all compilers prior to this. Getting some other errors too will try to make small examples
David Sankel is proposing that the `Promise&lt;&gt;` object implements `then()`. However, the direction seems to be that `future&lt;&gt;` implements `then()`, and `std::promise&lt;&gt;` is just an underlying container. I looked at https://stackoverflow.com/questions/12620186/futures-vs-promises which gives a bit of explanation. Is there a mistake being made in the C++ standard library? Shouldn't promises be just simply building blocks for creating continuation chains, and calls to them can happen in various ways, and synchronization layered onto them, rather than be more tightly built in?
Folly provides a very similar API to capnproto‚Äôs and runs in event loops as well (called EventBase in folly design). Docs are [here](https://github.com/facebook/folly/blob/master/folly/docs/Futures.md). Interestingly, it provides another type called SemiFuture to force callers to provide an executor (interface that EventBase confirms to) to run the continuations on.
Can we talk about the *installer* itself needing updates and being 67 MB ?
I can confirm that `_MSC_VER` is defined (to 1921 in my case) and `_LIBCPP_VERSION` is not defined.
Thanks for following this up and coming back to report your findings, much appreciated. I agree it's difficult to fairly compare lookup in the circumstances. The equivalent for schema-full formats would be Cap'n Proto's claim to be 'infinity percent faster' than Protobuf as it avoids the decoding step ;) I'd guess it'd be fair to compare MsgPack in a scenario where you want to decode all the data anyway. I'm guessing Dart would still have some potential advantage as fast lookup would maybe allow better allocation strategy. I'm definitely interested in seeing a head-to-head comparison of heterogeneous array performance. It may be that my use-case is unusual, but I have far more use for that than key-value.
My take on the SemiFuture is that also is a common base class that handles the void-vs-non-void choice for T. I also noticed the similarity with my implementation in: In Folly \`Promise&lt;T&gt; : private SemiFuture&lt;T&gt;\` with methods exposed using \`using\`. The original reason I introduced a base class was that I failed to find a nice way to hide data field T for \`Promise&lt;void&gt;,\` but then I proceeded to put as much stuff into those base classes instead of constexpr's in derived \`Promise&lt;T&gt;\`.
&gt; I have a B1 object b1 and a B2 object b2 and I call b1 = b2 That would not compile. The only instance I'm aware of where slicing is a problem is: void assign( const Base&amp; src, Base&amp; dest){ dest = src; } main(){ Derived d1{...}; Derived d2{...}; assign(d1,d2); assert(d1 == d2); // usually fails } Here the reader (and probably also the author) of the code expects `d1` to be equal to `d2` after the call to assign, but because `assign` only operates on the base class parts (Maybe it was written before `Derived` even existed), this is not necessarily the case. Not that here it doesn't matter if d1 and d2 are of the same type or different types that derive from Base.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
I was wondering the same - @STL?
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
I think it might be nice if VS could have faster patches for optimizer bugs that make VS unusable. There are currently a \[few\]( [https://developercommunity.visualstudio.com/content/problem/497271/bitwise-not-operators-removed.html](https://developercommunity.visualstudio.com/content/problem/497271/bitwise-not-operators-removed.html) ) of them listed on Developer Community, and although at least one is \[fixed\]( [https://developercommunity.visualstudio.com/content/problem/540079/vs2019-mis-optimizes-some-simd-constructs.html](https://developercommunity.visualstudio.com/content/problem/540079/vs2019-mis-optimizes-some-simd-constructs.html) ), that fix won't be available for who knows how long(16.2, whenever that is released). Meanwhile VS2019 is not usable-- &amp;#x200B; Also for my sanity could someone please fix \[this\]( [https://developercommunity.visualstudio.com/content/problem/440009/vc-fails-to-inline-initialization-of-internal-arra.html](https://developercommunity.visualstudio.com/content/problem/440009/vc-fails-to-inline-initialization-of-internal-arra.html) ) so /std:c++17 doesn't make my program slow as molasses?
The extra layer for me is about the MSVC compatible args to compiler. I would rather keep Clang args "standard".
My VS enterprise install at work is 20GB+
I've been building with cmake &amp; clang++ on windows for months, where is it going wrong for you ?
[https://godbolt.org/z/HiR7HJ](https://godbolt.org/z/HiR7HJ) Breaks down with internal compiler error. Pretty sure this is supposed to work
&gt; (I think libc++ and libstdc++ are also not done yet, but IIRC they are missing parallel algorithms too). They're adding parallel algorithims with Intel's pstl stuff. https://github.com/llvm-mirror/pstl https://github.com/gcc-mirror/gcc/tree/master/libstdc%2B%2B-v3/include/pstl They're adding them, but it's still all based on Intel's TBB, the only one which ISN'T is Microsoft's.
OK, so my basic misunderstanding was assuming that data to be operated on was loaded along with the kernels each time they were invoked. I didn't realize you could allocate completely separate memory space and assign kernels values in that space.
Is there a way to downgrade to 16.0?
Thanks for the positive feedback! I handle the issue of multiple stages by invoking `cmake` twice through `cooking.sh`. I think adding some basic examples for popular project is a great idea. Unless I misunderstood CPM's documentation, the flexibility of cmake-cooking is not just around having the most-recent version but of configuring a project differently. For example, if my project configures `fmt` in "debug" mode but a consumer of my project wishes to use `fmt` in "release" mode, then the consumer can inject their version of `fmt` into the build of my project.
Thanks
The comment was about the installer (the gui that let's you choose which components to install)
There is no hyperlink in this particular case. The one I'm talking about here is my touch screen client architecture for my CQC automation system. It's not a controls or DOM based browser framework, it's a whole faux windowing system done via graphics widgets. It's really complex because I'm creating the 'DOM' bit and the viewer and the editor and the networked deployment system for them and all that. It can access web content, but via a dedicated web widget that's not a button because it's not a link. It's a target for commands that can tell it to load a URL (or one statically configured.) It's a much more controlled situation than a browser where the person who designs the interfaces can strictly limit what can be done (because it's in control of devices in the home.) Selecting what text to draw is separate, as I said. The data sources are mixin interfaces that as I mentioned are mixed in at various places in the hierarchy as required. I do use a lot of mixin type interfaces. In my particular case, I don't use configuration dialogs, that was just an example. I use an attribute system that just calls down the hierarchy and lets each layer add attributes to a list, which are then presented in a common sort of multi-column layout for editing. But there are definitely places in the code where only specific families of widgets are acceptable. Certain code assumes a certain interface which has to be provided via a base class so that variations on that type can be manipulated. I just don't like the approach you describe. It doesn't, IMO, provide any particular advantage while making things much looser. My approach works very well for this type of system.
I see, so with consumer you mean another developer using your library, right? CPM currently also allows adding additional configuration options to a dependency, though it will raise a warning if they clash with options explicitly requested by another dependency. Thats currently intended behaviour as users should be aware that something might break (I assume here that there is a good reason if you explicitly request to configure `fmt` in debug mode).
Sounds interesting, but I gotta admit the name is making my eye twitch :)
Could be documented better, though. Took me some time today to figure out how to set environment variables in the launch settings of an executable. Would be nice of this stuff was consistent with VS Code.
What switches were you using? Depending on the permutation you may be using the new experimental lambda processor which might have bugs. Also, feel free to file a bug on DevComm https://developercommunity.visualstudio.com/spaces/8/index.html
The answer is _all_ of them :). In all seriousness, the new lambda processor fixes a lot of issues around how we capture identifiers. There are many cases with the old implementation where a generic lambda just didn't have the correct context to determine what identifiers in its body needed to me captured. You might want to tweet @joncaves if you want more info. He went through the pain to implement it.
Composition over inheritance, always.
Unfortunately, now the compiler fails to compile some lambdas which are coroutines. Compiler either produces ICE, or generates bizarre errors. Making the lambda coroutine a free/member function fixes everything.
Several problems in software development can't be solved: * time estimations; * selection of names; * tabs vs. spaces... ;)
Has this new implemented been ever tested with lambda functions which are coroutines? I'm getting a lot of ICEs or bizarre error messages with coroutine lambdas which worked perfectly before. Making them free/member functions fixes everything.
&gt; TL;DR: For now, you'll get a bigger bang for your buck by mastering English, than by mastering any programming language. I would add that what is important is being able to understand technical english, and the best way to do it is to read CS related book/blog and watch conferences (on youtube for example).
Those are likely to be compiler issues. Please file a bug on DevComm with a repro and we'll fix it (if it's not already fixed). &amp;#x200B; We are trying to push the quality of the new lambda processor as it solves a lot of problems we were not able to previously address. &amp;#x200B; [https://developercommunity.visualstudio.com/spaces/8/index.html](https://developercommunity.visualstudio.com/spaces/8/index.html)
&gt;Accuracy: VAX suggestions are context dependent based on the type expected which IntelliSense is not. Have you tried turning on the Experimental feature called "Predictive IntelliSense"? It does type filtering which may address your needs. I would love to hear about your experience if you try it. You can turn it on via "Tools &gt; Options &gt; Text Editor &gt; C/C++ &gt; Experimental" (or just type "Predictive" in the Ctrl+Q search).
Too true :)
&gt;Can we talk about the installer itself needing updates and being 67 MB ? The installer is effectively its own standalone application because it can install and manage multiple Visual Studio versions, down to each individual component you may want for a given installation. Since it is more complex than traditional installers and there is still room for improvement for it, it receives updates. There are plans to overhaul the installer in the future, which may improve the update experience for it as well.
Great list. ASAN and designated initializes make me go Woot!
Neat new features, but I was really hoping for some intellisense performance improvements. For a project I'm working on right now, it's 2-3x faster to just guess and compile the program than it is to wait for the suggestions window to open.
One of the things that most promise designs impose is that the work begins before the consumer waits or attaches a callback using \`.then()\`. In C++ this requires allocation and synchronization to order the calls to set\_.. on the promise and the calls to wait/get/then on the future. This 'eager' implementation is sometimes the right solution, but a different design Based on Concepts instead of types allows different implementation options. The Sender/Receiver concepts are just a slight refactoring and renaming of the Promise and Future types. With Sender/Receiver a Sender has a \`submit(R)\` method that takes a Receiver and a Receiver has \`value(Tn...)\`, \`error(E)\` and \`done()\` methods. Thus \`Sender::submit(R)\` is like \`Future::then(F)\` and \`Receiver::value(Tn...)\` is like \`Promise::set\_value(T)\`. &amp;#x200B; The difference come in the implementation. implementing a Sender can allocate and start the work immediately and then order the result with the call to \`submit()\` using synchronization. a Sender implementation may also choose to wait to start the work until \`submit()\` is called and then the work has the receiver up-front so no synchronization is needed, sometimes no allocation is needed either. &amp;#x200B; [http://wg21.link/p1341](http://wg21.link/p1341) demonstrates how these concepts allow coroutines and Sender/Receiver to be unified into a general pattern for many implementations of Promises and Futures.
\&gt; Preview IntelliCode features - Custom Models, C++/TS/JS support, and Editorconfig inference - are disabled by default. To enable them, go to **Tools &gt; Options &gt; IntelliCode**. &amp;#x200B; Where are they? I have nothing in Tools&gt;Options. VS 2019 16.1 with moderate size mixed C#/C++ project
&gt; the fact that something so fundamental it is so hard to implement Mostly because of performance. Doing the conversions with an arbitrary precision BigInteger implementation, while still not trivial, is far far easier.
You can install the toolsets side-by-side and then go back to the 19.20 toolset (shipped with 16.0).
\ One of my favorite features is following the stacktrace of a compilation error using F4 in the output. I didn't know about this. I think you just restored my sanity (especially when using the CMake support which doesn't take you to the relevant line in the Output window when you double click in the Error List).
This confused me too. It turns out you need to install Intellicode. Run the VS Installer and modify your installation to include Intellicode. It shows up after that.
I am in a similar situation, with a twist. I have programmed c/++ for many years, but have been away for a while. I share your frustration. I am available to help in any way I can.
We test MSVC‚Äôs STL with the clang-cl compiler driver because that allows our test infrastructure to pass mostly the same compiler options to it. (We additionally test with `-fno-ms-compatibility -fno-delayed-template-parsing` for maximum strictness.) Note that the choice of clang-cl versus clang++ compiler driver affects the style of command line options; this is separate from how the Clang front-end imitates MSVC in terms of extensions supported (like `__declspec(dllimport)` and how the LLVM back-end imitates the MSVC ABI. According to my understanding, Clang/LLVM can also imitate MinGW on Windows, which MSVC‚Äôs STL inherently can‚Äôt test with due to ABI.
We ship micro-updates (e.g. 15.9.7) which patch exactly those kinds of bugs. Not all bugs meet that bar. Upvote DevCom issues to boost their priority (there are internal processes that ping devs about highly-upvoted bugs).
&gt; There are plans to overhaul the installer in the future, which may improve the update experience for it as well. Great :) One point that is already positive I think, is that it took over the VS2017 installer, so at least we only have one instance of it.
The x64 exception handling changes for file size reduction doesn't seem to be on by default. I believe it was stated this would be enabled by default for VS2019 Update 1: [https://devblogs.microsoft.com/cppblog/making-cpp-exception-handling-smaller-x64/](https://devblogs.microsoft.com/cppblog/making-cpp-exception-handling-smaller-x64/) Unfortunately, I can't really turn this flag on for our production builds as it's undocumented and unsupported. Do we know when this might be enabled?
Ninja is not updated to 1.9.0. Any reasons for that?
I auto write C++ auto every day, but I auto find 'modern' auto C++ rather auto unreadable. Like auto sometimes makes auto sense in certain contexts, but auto otherwise it is just auto pure noise.
I'd be careful updating, as I immediately hit an internal compiler error: https://developercommunity.visualstudio.com/content/problem/577035/internal-error-in-p2symtabc-line-7476-1610.html
I read the introduction. Yep, it does seem to delve into what I was suspecting about the viability of using std::future&lt;&gt; in our code when all I want is continuation chains. The paper argues: "Also, by separating of the creation of the object representing the asynchronous operation from the step of attaching a continuation this allows these higher-order functions to compose lazy asynchronous operations together efficiently without introducing extra overhead for synchronising and storing intermediate results such as would be required with an eager std::experimental::future-based API" Could you help me understand what is meant by "eager?"
It looks like the consensus among other languages is to put variable name first and then the type. This can be applies to C++ with (Almost?) Always Auto.
Why is the new processor only enabled by default with -std:c++latest, and not 14 &amp; 17?
eager is when there is shared state between the promise and future and the order of calls to p.set\_value() and f.get() are allowed to overlap in time. When both the promise and future are being used to set and get the result at the same time, then the shared state must synchronize to prevent a data race on the result.
Aha! Thank you
&gt; I am available to help in any way I can. ok, so if you really want to get involved - the brief info: URL for the site - nothing so far, still constructing the framework (it will be hosted as a static site on GitHub pages). Only repository so far: https://github.com/Xeverous/Xeverous.github.io/tree/develop/content I have a large long-term plan but obviously it will take time to write these (I have a list of links + planned ~200 articles already, apart from already existing ones). I'm also changing the website generation framework (Jekyll =&gt; Nikola) for various reasons. The project might now feel dead because I'm working on [something else](https://github.com/Xeverous/filter_spirit) but in reality a lot happens for both in the background - I will start pushing when the framework is ready and decided on few things. The planned content is similar to the site learncpp.com but much more thorough (including everything about templates), updated for newest standards + some libraries guides, tools and all the related things (compiler, linker, makefiles, glossary, dos and donts). There are some articles already that are mostly complete (mostly C++ tutorial up to some point). You can browse the repo and read anything - pages are in Markdown so you can view them online on GitHub (note that only `content` directory on branch `develop` contains the articles). Obviously tons of content is spread accross and unsorted but feel free to open an issue to ask a question or propose something - I need someone unexperienced to verify if it's readable and contains enough examples etc. You can also contact me on Discord - Xeverous#2151
Lol no
Top notch workaround they've provided there.
I don't know about good code to look at, but are you aware that the world is moving away from object-oriented programming towards a more functional style? If you do find some code, make sure it is up to date and uses the latest standards.
This was a decision made as an effort to not break users. The new implementation requires more validation/feedback before we can call it "done". Having it be opt-in through two paths, either explicitly through the \`/experimental\` switch or through \`/std:c++latest\`, was the best path for customers who do not want to see spurious breaks.
OOP is not going anywhere. CS is a world of hype and buzzwords. OOP is not the craze right now I agree but it will be back in style in a few years.
The current plan is to enable it in 16.2, according to a mail from Modi last week. He checked in that change to the compiler backend branch on May 15. According to my understanding, the delay was due to needing to update the UWP libraries, working with Windows to build and test the OS with FH4, and apparently an interaction with LTCG was fixed. Disclaimer: I'm not a compiler backend dev, and as usual, no promises until you see an official announcement.
That's the submitter posting a workaround for their own issue.
Can you give lambdas methods?
[removed]
Thanks for reporting the ICE promptly. Although ICEs are annoying (speaking has someone who has ICEd the compiler hundreds of different ways), they are typically very specific to certain code patterns, so they usually shouldn't be feared. Note that while your repro is straightforward, you can make it easier for compiler devs to investigate by distilling your IDE project down to a preprocessed repro or link repro. (You have a backend codegen crash, as indicated by "Utc" in the compiler source path.) A preprocessed repro + exact command line allows for faster investigation, although it is not strictly necessary. See https://docs.microsoft.com/en-us/cpp/overview/how-to-report-a-problem-with-the-visual-cpp-toolset?view=vs-2019 for details.
Cmake has trouble with clangs that have gcc style syntax but, by default, target x86_64-pc-windows-msvc. Interestingly it still has this trouble if you tell it to compile for x86_64-pc-windows-gnu with such a compiler. It's a cmake bug complicated by the fact that all the versions of clang on windows tend to confuse people.
Derp, thanks for pointing that out.
&gt; This is a very hard project to do alone, so would anyone want to help me on this? As someone also working on a [DAW](https://ossia.io), I agree :p would you consider making your core algorithm "generic" / not too dependent on external libraries so that it could be integrated in other environments ?
Sorry for the late ping. Just a question that popped to my mind recently while thinking once more to this thread. \&gt;The allocation of components happens in virtual memory for us as we already have a custom memory allocator, that might be causing discrepancies as we don't allocate dynamically (and it's a requirement for us). Are you paginating the packed arrays under the hood or do you front-reserve memory for the components and still have a full packed array? I'm asking this because the way you described it made me think that probably you're making vectors grow one page at a time in your sparse sets. This is something I was thinking of recently, but I'm not that sure about it and would like to have a feedback from you if you've already faced the problem. Thanks!
oh no, i'm not trying to code a VST. i don't know what the compatibility goal would be, but i'm not looking for much. The outputs can be processed somewhere else after, if need be.
I've tried it when it came out and several times since and it doesn't really convince me for several reasons. It might be good if I take time to write a more elaborate / complete answer explaining what I find better in VAX compared to IntelliSense (especially here I'm at home without my working computer with VAX) but here are few examples: * VAX feels more responsive especially on large projects. And there's sometimes latencies when IntelliSense is updating. * VAX heuristic seems to focus on user code and symbol locality while IntelliSense provide a full list of symbols found deep down in STL implementation or Windows headers that I don't really care. Imagine that in the menu of a restaurant you get a full list of what's in the fridge \^\^. Here is [small IntelliSense defects](https://imgur.com/nOa1AhI) (in VS2017): so Ok `MyFunc` **appears first but it's not preselected!** (which is really annoying) and the list is full of internal symbols I won't ever use. * Regarding "Predictive IntelliSense" more specifically, it base its heuristic on the type only? It's not a bad idea, better than doing nothing like regular IntelliSense but as said above local symbols matter more IMHO. But it's hard to be objective here without concrete examples. * Predictive IntelliSense was also to restrictive: symbols like keywords, macros and snippets were not visible anymore in the list unless to hit the "show more" shortcut which slows down considerably the keystroke. * VAX starts the suggestion after assignment `=` operator or while writing initializer list without typing anything and providing quite smart suggestions. While with IntelliSense we must type at least one character or hit "Complete word" shortcut. For example: &amp;#8203; QWidget* w = [cursor is here] // suggestion: new QWidget() struct MyStruct { int m_Variable; MyStruct(int iVariable) : m_Variable([cursor is here]) // suggestion: iVariable }; * Also one thing I think you underestimate (a lot) is the syntax coloration in parts of the IDE other than the text editor. It's a powerful tool to quickly identify a symbol by its type even before reading the text itself. VAX can color the code everywhere it appears (tooltip, suggestions, find result, goto symbols, ...). I've seen in last VS2019 you've implemented it in tooltip. That's great! Please keep going and propagate it everywhere else. I didn't have play with IntelliCode yet to see if AI approach brings more relevant results. **TL;DR**: VAX is more responsible, more focus on my symbols hence I can blindly commit suggestions more often than with IntelliSense. I hope it helps.
Does that mean \`+\[\]{}\` works under visual studio now or it will still be ambiguous?
&gt; oh no, i'm not trying to code a VST. well, wouldn't it be nice if your DAW was embeddable ? I really like software that can run both standalone and as part of another - in particular in real time audio where you don't want the overhead of synchronizing across multiple processes.
yeah, well i don't necessarily see why a later work of my own software can't port to communicate and script itself into my software with a few mods.... GL and ALUT and GLUI are arbitrarily unembeddable, thats to say it is it just has to be worked with by another piece of software. i argue people should make software that works with mine. haha.
Thanks! I'm aware my repro is not minimal, but it is self-contained enough, and rather than spending a ton of time trying to reduce my codebase, I thought I'd first report it to see if I'd get a "this is a duplicate of X, we're already working on it" response (which has happened in the past).
Can we `/experimental:-newLambdaProcessor` to disable if when using c++-latest?
I was thinking less logging and more optional assertion
Yes, but this doesn't work out in practice for a large library like Qt. For example, Qt's 2015 distribution wasn't compatible with 2017.
Glad to hear it seems like a good idea to you too! Unfortunately I'm not aware of any constexpr hashing implementations off the top of my head, but a quick stack overflow check did turn up some interesting leads, and I'm positive it's possible (though it may drive up compile times significantly)
No. But you can inherit from lambdas with something like the curiously recurring template pattern, or the "lambda visitor" pattern.
IncrediBuild was the tool I've seen generally employed in Windows shops.
Ah thank you, I was looking into it before but it seemed too costly. Do you know of any free tools?
Not from the top of my head now... the only time needed such tool was in a place where builds were horrid and for that reason they licensed that, which indeed worked great.
I'd be interested to know what prevents it from working.
YES! See [this response](https://www.reddit.com/r/cpp/comments/brdg1x/c_based_promises/eofzbzf/) from /u/kirkshoop. My hope is that what you suggest will very much be the conclusion of the multi-year Executors effort of the Committee. We're getting closer.
Can confirm. Is expensive, however it works a treat...
SN Systems (Sony) make a distributed build system named SN-DBS, but I believe it's licensed only to Sony platform developers (e.g. PS4). Still, you can take a look. It works very well.
[FASTBuild](http://www.fastbuild.org/docs/home.html) *might* do what you are looking for. I don't have much experience using it personally (I know it's a bit more fiddly than IncrediBuild for sure)- but considering it's free you can't complain too much.
We've been using Incredibuild but we're experimenting with replacing it with [FASTBuild](http://www.fastbuild.org/docs/features.html). I'm an outside observer to this work, so I don't have many details to go into. It sounds like its a full build system but we seem to be getting it to work as a IB/distcc/ccache replacement. From what I have seen - Developers have been happy - We see less stalls (times when IB is doing nothing) - We are getting gains from building targets in parallel (with our build system at least, IB only let's us build one target at a time) and more multi-core nodes (we only have so many of those IB licenses) Some areas we still need to look into - Distributing unit tests (WIP) - Integrating it into our Linux builds - Take advantage of the ccache-like behavior I suspect the main thing holding us back from switching is the right people having the time to polish up the integration of FASTBuild into our internal build system.
Fair enough. I think I disagree I'm the end conclusions, but I think at this point we need code to sort out the differences. :P
I'm glad you put some [authoritative] clarity into this, particularly the separation of command-line options, front-end and back-end.
does it have improved cpp intellisense (or overall better workflow?)?
`echo | clang -dM -E -` gives you a list of all pre-defined macros, can come in handy. Another thing I found out is that if you would like to tell `clang` f.e. `-fconstexpr-steps=10000000` (a gcc-style option) using `clang-cl, you need to pas it like this `-Xclang -fconstexpr-steps -Xclang 10000000`
Anyone have thoughts about using icecc with clang + dockcross to cross compile on to windows? I've started to look in to this, but we use python in parts of our build steps and it's presenting itself as an issue that I need to overcome with dockcross
About 200 hours and your good
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/bry6rn/please_help_with_this_problem/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Yeah. I'm having some valid code that is failing to compile now. If that's possible it would be great.
You and /u/NotAYakk can use: C:\Temp&gt;type lambda.cpp #include &lt;stdio.h&gt; int main() { auto lambda = [](int x) { return x * x; }; printf("%d\n", lambda(7)); } C:\Temp&gt;cl /EHsc /nologo /W4 /std:c++latest lambda.cpp &amp;&amp; lambda lambda.cpp 49 C:\Temp&gt;cl /EHsc /nologo /W4 /std:c++latest /experimental:newLambdaProcessor- lambda.cpp &amp;&amp; lambda lambda.cpp 49 However, **please** report bugs you encounter with the new lambda processor to DevCom so we can fix them, before using this workaround!
At work we use SN-DBS [https://www.snsystems.com/tech-blog/2014/01/06/building-with-the-network/](https://www.snsystems.com/tech-blog/2014/01/06/building-with-the-network/) and it's awesome, but it's only available if you are Playstation Developer (though can distribute any other compile/build job). &amp;#x200B; My favourite, outside of job, build system is bazel. I fell in love with it, back when I worked at Google (blaze then). Now I haven't used any of the distributed building, caching (like --disk-cache=c:/folder), but there is the concept of Remote Workers mentioned here: [https://docs.bazel.build/versions/master/remote-execution.html](https://docs.bazel.build/versions/master/remote-execution.html) \- then another (syntaxtically similar, but quite different) system, again from google called GN can generated Ninja files, that can be distributed over with GOMA - [https://groups.google.com/a/chromium.org/forum/#!topic/chromium-dev/eOtBzosZtd8](https://groups.google.com/a/chromium.org/forum/#!topic/chromium-dev/eOtBzosZtd8) \- haven't used it either. &amp;#x200B; But then there is also: \- [https://electric-cloud.com/products/electricaccelerator/](https://electric-cloud.com/products/electricaccelerator/) \- [https://github.com/microsoft/BuildXL](https://github.com/microsoft/BuildXL) &amp;#x200B; and plenty more... Tough time now to evaluate :)
Somebody has probably rigged up HTCondor to do this in a hacky way. Pretty sure the options are really: IncrediBuild, buy a big fast machine, or switch to linux.
&gt; *Colorized code in Quick Info tooltips* Can you also colorize the Call Stack window? That would be awesome!!111
Looks like the WSL integration is not working if the project path contains spaces. Great work though, keep on going and making the VS better!
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/brytqh/whats_the_based_way_to_organize_a_general_c/eohqf1h/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
MSVC has a plethora of command line options to suppress warnings from external, as well as system, libraries. It's actually one of the very best compilers on this. Have a look at https://devblogs.microsoft.com/cppblog/broken-warnings-theory/
[https://stashed.io/home](stashed.io) is an alternative to incredibuild : a distributed &amp; cached compiler frontend for cl.exe. It cost 29$ per machine per month, with a one month trial. The main difference with incredibuild is that it does provide a cache (which incredibuild does not).
Yes that was what I was refering to, but I am not able to configure those options
Reported, I assume you can see the flags there? [https://developercommunity.visualstudio.com/content/problem/578834/expanding-one-of-two-parameter-packs-break.html](https://developercommunity.visualstudio.com/content/problem/578834/expanding-one-of-two-parameter-packs-break.html) [https://developercommunity.visualstudio.com/content/problem/578832/nested-template-parameters-give-internal-compiler.html](https://developercommunity.visualstudio.com/content/problem/578832/nested-template-parameters-give-internal-compiler.html)
Happy to help! ;)
Depends where you're coming from, we ran into trouble quickly as we have a lot of legacy code that relies on things only present in VisualStudio and the Windows SDK. There were solutions to all the issues... but it took a fair bit of time. It did eventually work though. We had the same problem with our build support code (we use python too) ... but I've no advice. We just had to slog it out and gradually make the tools accept either platform. It was worth it though, setting up a Linux build chain, especially an ephemeral one, is (for us, I'll accept opinions differ here!) significantly easier.
If only the CMake generator ever got finished. [https://gitlab.kitware.com/cmake/cmake/issues/15294](https://gitlab.kitware.com/cmake/cmake/issues/15294) [https://github.com/InSimo/CMake/commits/fastbuild-attempt4](https://github.com/InSimo/CMake/commits/fastbuild-attempt4)
Or guided deducations template&lt;class T&gt; std::pair(const char*, T&amp;&amp;) -&gt; std::pair&lt;std::string, T&gt;; template&lt;class T&gt; std::pair(T&amp;&amp;, const char*) -&gt; std::pair&lt;T, std::string&gt;;
ccache works on Windows using MinGW and Clang. You can use my CMake build port: https://github.com/cristianadam/ccache-cmake I haven't tried building icecc though. I don't know what happens if you have ccache cache files on a network share either.
Why not? We use C++ for building WEB backends. And recently I've released FastCGI implementation in modern C++ - [https://github.com/dmitigr/fcgi](https://github.com/dmitigr/fcgi) In conjunction with one of the C++ APIs to PostgreSQL (for example, [https://github.com/dmitigr/pgfe](https://github.com/dmitigr/pgfe)) and with some of the template engines available, it's possible to develop high performance WEB backends relatively easy.
After the update the IDE started freezing indefinitely on a CMake project when trying to open the Errors tab. Fixed by erasing .vs folder and the build cache, but still.
We use memory mapped/virtual memory under the hood (mmap on Unix, VirtualAlloc on Win32). This allows us to create GBs of memory upfront, but allocate none of it until needed and grow dynamically (handled by the OS). This type of memory is extremely fast to allocate, as it's already been reserved by the OS and mapped in the app's pagetable. As a side effect is that the OS will grow this by the page size, but it is fully invisible to the container type touching that memory. We went that route simply because we didn't want to malloc giant regions of memory, or have to realloc memory whenever we wanted to grow our container. Both had inherent problems (for our use case), with malloc we'd need to know ahead what size we needed or run the chance of over- or under allocate memory. With dynamic growing, realloc would run into the problem of having to need space for both the small original region, as well as the big new region (and the copying isn't fun either), potentially pushing us into OOM scenarios. Virtual memory/memory mapped regions sidestep those problems altogether, you pre-announce your intentions to the OS, and then you link it to your container type's allocator. It grows as you touch those regions of memory, so your app doesn't start using gb's of memory when nothing is actually used. We do have a specific version of our sparse_array to deal with this (non ideal, and I've been looking at collapsing the 2 versions, but it's a low priority task). Unix' implementation for this functionality is better (less work needed), but it's not too hard to match the needed features on Win32 with some work.
Oh, ok, so no pagination at dense array level. You announce the memory and logically reserve it for the container that therefore never reallocates. Well, this isn't really viable in EnTT, but still really interesting to know about. Good idea. Thanks for your time!!
No worries! Too bad it's of no help, but good luck with your next set of features, looking forward to that multi-threading!
Yes, this to me is the missing piece of the jigsaw.
This seems a little on the pricey end when Fastbuild is free!
Over the past few years I've found that the biggest strides for unit testing in C++ (and probably elsewhere) can be made by designing for testability. Composition and dependency injection have significantly reduced our reliance on opaque, often manual integration tests. Most testing and mocking frameworks can take care of the rest without any trouble. The biggest hurdle for me is project organization. Most of the projects I deal with at work have a DLL with a very constrained public interface, and unlike some other languages C and C++ don't make it easy to link a single component into the test. The solution I tend to go with is to have a static library containing most of the code, and a separate DLL project that links with the static lib. The test project links with both, or sometimes I'll have separate unit and integration testing projects.
We've had great success with greenfield projects and unit testing, but less so with brownfield ones. Our major issue is that C/C++ really need to be designed for test - adding tests to old code is hard in a statically compiled language. Its absolutely doable though... In fact, I would say our _biggest_ issue is cultural. Our C/C++ developers have never used unit or integration testing (as previously its been hard) and changing their mindset to see its usefulness is an ongoing problem.
In `void loop()`, where's the `plugin` variable declared?
Use /r/cpp_questions sub for those type of questions dude.
Absolutely - untangling an existing project is hard as hell. Fortunately we don't have the cultural friction - we support automated testing in a hardware production line, and as a hardware biz integration testing was always core to the process. But because a lot of work was done 10 years ago by people who are hardware devs first, the software design is often lacking in old stuff and *I hear you there.*
Well, you can't, really, it needs to be declared somewhere else, where loop() could see it. Also just as a heads up, your post will likely get removed by a moderator because r/cpp_questions is the appropriate subreddit for this type of posts.
What do you mean " where is it going wrong for you ? "? It works perfectly fine. I'd just be even more happy if I could remove any MSVC/clang-cl specific parts from my cmake files and only have to deal with gcc/clang++ - style flags.
Oh shit, sol2 was pretty fantastic to work with. I'll definitely play with this soon.
Maybe it's because I'm on my phone, but I don't see a link to the project anywhere on that short novel announcing the project's release.
Here you go: https://github.com/ThePhD/sol2/tree/v3.0.2 Seems like there's no direct link in the post strangely.
The `magnetSensor` function returns the value of `plugin`. What you need to do is, in `loop()`, get the returned value, like this: bool plugin = strip1.magnetSensor(6); Notice that, even though they are named plugin, they are independent from each other. You can name it whatever you want, it'll still work. You can't access a variable in the middle of a function from another, so return values are a way of exchanging data between them. As others have said, this subreddit isn't the appropriate for questions, so next time, go to r/cpp_questions. A mod will probably delete your question soon.
Forever
üéµ **REST IN HEAVEN**
That's a standard lame excuse for bloated softwares (cpu will be faster in 20 years, storage is cheap and so forth and so forth)
Yeah, the project pretty much has to be designed from the start to be testable. The vast majority of the corporate code I've seen over the years is far too tightly coupled to add tests after the fact. I've taken to asking if they unit test during the interview and the response always seems to be "We'd LIKE to, but..." There seems to be this expectation that programming for a big company somehow causes some sort of magical quality fairy to bless the code, but in my experience corporate code is always far messier than open source code is. The UI is sometimes more polished if it's for end user consumption, but in-house projects are, in my experience, almost always the worst possible code that can get the job done. And a lot of the time it can't even get the job done.
Much appreciated, ATTENTION MODERATER, feel free to delete i got my answer lol
Well thanks all for mostly telling me to post this else where (always something wrong with a post on a forum so go figure) but thank you to the 1 guy who actually answered my question and told me to post else where in a kind way. Appreciate it you a real one, rest of you are toxic hall monitors lol. xD
Thanks for the heads up
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
Thanks hall monitor appreciate it
Awesome project! The only real issue that stopped me using sol2 were the humungous compile times and RAM requirements as soon as we began to use it more. Have there been improvements regarding compilation in sol3?
Yes, see this: https://thephd.github.io/sol3-compile-times-binary-sizes A lot of problems with compile times were caused by usertype generating gigantic std::tuple with all registered members. Now it can be easily avoided by registering methods one by one (kinda like it was done using `simple_usertype`, but now this functionality is available for general `usertype` and `simple_usertype` was removed).
So then if I read it correctly sol3 is about 10% faster than sol2 for users who didn't use `simple_usertype` before? It's definitely a step in the right direction, but unfortunately not the large improvement I was hoping for.
I think that differences might be more noticeable in less extreme test cases. I think that in the test case from the article the conditions might have been very stressful for compiler to show bigger improvements. I recommend trying out `&lt;sol/forward.hpp&gt;` + not passing tons of arguments in any sol functions (`new_usertype`, `create_table_with`, etc.). In my experience, it really helps.
I'll try that, thanks!
Do you cross compile from linux to windows? Or do you build your windows binaries / dlls on windows? &amp;#x200B; If you do cross compile, what are you using python for, and how are you using it for cross compiling? Anyways, we're using python to generate C++ bindings for python using riverbank's sip. We probably don't actually need python, but the initial examples I had found from riverbank used python so we kept it.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/bs39bf/similar_books_to_oop_in_c_by_robert_lafore/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
In this case, cross compiling linux to windows. The python is used for the build system as we're based on scons at the moment - so I think our issue is very different to yours. Our python runs locally, and the cross compiler gets called just to compile &amp; link C++.
This is an ad for TypeMock's Isolator++ mocking solution.
I've had _exactly_ the same experience. I've seen lots of projects hit a technical debt spiral (slow to develop -&gt; spend less time resolving technical debt -&gt; even slower to develop...) and its rare that I've been allowed to stem the flow of features enough to refactor for testability or add reviews to fix it.
Thanks /u/STL I couldn't find where to report bugs to the VS team. I have created a gist with a small reproducible test case for two issues that I managed to reduce to a small sample. https://gist.github.com/Rogiel/b5dd14f93fe9322312e95d58f57b1b30 The first bug only happens when using a template variable that holds a lambda with an `auto` argument. It seems to not be able to capture the `auto F` parameter inside the lambda. The implicit decay into a function pointer might or might not be relevant, I just extracted the problematic code from my code base. The second bug is much weirder. It only happens with `/permissive-` but with `/std:c++17` or `/std:c++latest` mode. I could not find a way to reproduce it without the `Naios/continuable` library. In this bug the compiler fails to evaluate a `std::forward`inside a lambda. This appears to be related to the nesting of lambdas caused by the library, but I am not sure. `/experimental:newLambdaProcessor-` doesn't work in this case. If you want me to report this directly to the VS team, please direct me to where to report bugs to. DevCom did not not yield anything useful to me :(
&gt; Slow Builds &gt; The C++ build process is more involved and more time-consuming than for other languages. The C++ build process has two steps: compiling and linking. That difference alone is significant. But, the time to compile code that makes heavy use of templates and can add even more time. &gt; Add to this how many teams structure their large projects. They create a single target, and that is the product of many other builds. Finally, after those targets finish their builds, the system generates a set of executables. One of them is the test binary. &gt; Toss in build targets for a few different platforms, and a complete build cycle can take many minutes, or even hours. This more involved compiling and linking process slows the code/build/test cycle to a crawl. &gt; So, if tests are difficult to run, developers will run them infrequently. They may even ignore them. Eventually, they‚Äôre forgotten. &gt; The solution to this problem isn‚Äôt easy, but it‚Äôs better than not running tests at all. Break the application down into independent components. Create dynamically-linked libraries and built and test them in isolation. &gt; This is a lot of work, and it may feel like that time could be better spent writing new code. But working with a slow build process that everybody hates is an obstacle. It hampers many aspects of the development process, especially tests. This makes me lose my shit. Why the fuck would I build everything in my development cycle?! And for a few different targets, no less?! 'Course I don't do that! Then, some people just love their single executable. Fine, but even then: build a bunch of static libs and run tests for them, no need to have shared libraries for *that*! People who complain about the slow build process *deserve* all the wait they get!
It doesn't compile under `/permissive-`, that's quite a big one! I've worked with Lua &amp; sol in the past and if I still was, this would be an immediate showstopper.
Thanks! Let me know with any questions or suggestions. It is in a state where it does work, though would probably need some work on some of the low hanging fruit to polish it enough for other people to be productive right away. My experience so far is that it is a huge breath of fresh air and that I wouldn't want to work on any non trivial software another way. I appreciate you emphasizing the benchmarks. It will almost certainly destroy just about anything else comparable, though some of that is because most key value stores keep their keys sorted, so few comparisons might be apples to apples. If you know of standard benchmarks that people would look for, that would be helpful.
Yeah, this is unfortunate. In my case, I've disabled `/permissive-` and I trust GCC's and Clang's `-Wall -Wextra -pedantic` for now. Hopefully MS will fix problems with `/pesmissive-` at some point.
resharper c++ is free for students and teachers
&gt; Some consider templates the modern-day replacement for the legacy preprocessor. They‚Äôre not wrong, since replacing text macros with compiled code is always a better alternative. But templates replace the preprocessor‚Äôs lack of type checking with ‚Äúduck typing.‚Äù This mechanism can still hide your intentions from the compiler and make an end run around type checking. Hu???? Templates are typesafe. Unless you mix it with legacy C construct (C-cast, macro), or use dynamic_cast it's completely typesafe. Am I missing something?
strings vs enums ?
Interesting and well written.
Unless I'm missing something you never account for the fact that moving from an engaged optional does not reset it but keeps its value in whatever its moved from state is. B would need a move constructor manually resets its optional field. The default one isn't enough which makes the conditional Copyable base class redundant.
Can you possible point me in the direction of the bug report? I'll certainly take a look at it and I apologize for the break.
Yes, it's called content marketing and it's a plague on programming subs. See also: viva64 and other static analyzer spam on every damn subreddit.
Hey, sol3 dev here. I haven't filed a bug report because I haven't had a chance to produce a minimal repro yet. The code works with GCC and Clang on their strictest conformance modes and when I simplify it the bug disappears, so I seem to be making the minimal repro incorrectly or not adding enough layers of complexity. It's been reported by dozens of users when just compiling the code under /permissive-, but I didn't feel comfortable with making a bug report unless I could accurately repro it (after all, "this whole thing fails under /permissive-" isn't really a helpful report...!).
sol3 was 10% faster for a project that already extensively used speed up techniques. Compared to regular techniques to do the same the speed up was pretty much orders of magnitude in difference (I doubt some those larger codebases would compile in an acceptable timeframe if they weren't using the speed-optimized sol2). That being said, there's some fundamental limitations I won't be able to solve until C++20/23. But, by then we'll have a shiny reflections TS, which will be pretty amazing I think!
Added a link to the project GitHub and the release directly. Sorry, I guess I was too used to it being sprinkled everywhere while I was writing the docs that I missed out on the obvious!
I mean it's been several years since I used VS but most of what they offer is already built-in, except maybe the auto . to -&gt; .
SemiFuture exists to achieve two things: * Support laziness within the model. That is that we can defer work on the SemiFuture and only run it if someone cares about consuming work. Deserialization of network responses is a good example of this. * Enforce executor safety by requiring that an explicit executor be attached before any continuations can be expected to run. We found the latter to be particularly important. The eager model of Futures (noting Kirk's [https://www.reddit.com/r/cpp/comments/brdg1x/c_based_promises/eofzbzf/](post) above on why eager can be problematic) makes adding a continuation racy if there is no explicit context in which to run work. That makes the location in which a continuation runs nondeterministic, which can be a serious problem for heavily threaded systems where a lot of different developers are putting code on threads. Not explicitly attaching an executor also means that if I run a network library, and my caller adds work to a future I return, then that work my run in *my* context - well now I have a situation that I may have a carefully sized thread pool, intended to deal with lightweight network responses, only to find my caller takes a lock on one of my threads. SemiFuture then should really be seen as a potential Future. It could really be encoded as a type that when passed to a "via" operation, along with an Executor, that via operation returns a Future. The combination of a SemiFuture and an Executor gives you a Future, on which all continuations will run in a controlled fashion. It *also* supports a blocking get operation, and deferred work, but all of that is as much an artifact of trying to slowly evolve an API that already has tends of thousands of use sites than because it is the right design.
Yeah, C++20 is really looking amazing. I hope proper compiler and platform support won't take too long. Regarding sol, don't you think it might drastically speedup compilation to separate the class registration from the Lua API calls and compile them separately? I've done that for [my own lua wrapper](https://github.com/TheLartians/Glue/blob/master/tests/lua_glue.cpp) and it compiles reasonably fast. Of course functionality is nowhere near to sol, but extending it theoretically won't add much overhead.
Also, I'd consider it a far nicer product. Highly recommended!
Would you mind briefly clarifying why? I've been using Resharper C++ for a couple of years now, but have gotten a bit tired of the buggy error highlighting and lagginess and was thinking of trying out Visual Assist. But maybe it's just worth staying with Resharper?
I used to used visual assist; I found that reshaper teens to get less confused regarding namespaces; didn't notice any obvious speed change but the project wasn't that large. Definitely try the evaluation, it is free anyway. Just starting that both tools have their merits, and the price of reshaper may not be worth it in your situation.
Alright. I'm still a student for one more year, so Resharper is currently a better deal for me money-wise, but might try out the eval for Visual Assist just to see how it feels to use.
Enjoy the student perks while you can. Maybe you can even get a yearly license for free if you ask nicely. It should be if your university requests a license...
Apologies for the confusion, I shouldn't have abbreviated it. The place to report bugs is Developer Community: https://developercommunity.visualstudio.com/spaces/62/index.html
Clion ;)
It caught me by surprise as well :)
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/bs64wz/help_rewrite_c_project_co_c/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
&gt; There seems to be this expectation that programming for a big company somehow causes some sort of magical quality fairy to bless the code If you fail quietly enough you can get transferred to another team before the component burns down. It's actually a bit of a problem at my current job, because some components don't go through end-to-end testing but are treated as gospel so if they're incorrect it creates red herrings down the pipe, assuming the problem is even caught at all.
Students *frequently* trip over `const_iterator` being a different type from `const iterator`. However, I don't think a localized renaming would help at all. The benefit of the existing naming scheme is that it mirrors the native naming scheme: when I talk about a "const char pointer," I mean a pointer _to_ a immutable char, not literally an immutable pointer! And east-vs-west-const doesn't matter: a "char const pointer" sounds even _more_ like a "const pointer." So students do have to learn the "const pointer"/"const iterator" colloquialism at some point, in order to communicate effectively with other programmers in spoken English. They might as well be forced to learn it as part of dealing with `std::vector`. Besides, with `auto`, it's been literally a decade since I've seen `const_iterator` or `const_pointer` mentioned in any codebase. The typedefs exist, but nobody names them in code anymore.
This doesn't seem to be working for IntelliSense warnings. Maybe I'm doing something wrong.
But I only have an 18 core overclocked xeon and can't afford to upgrade.
I love Visual Assist, but haven't used it in years even at work where they would pay for the license. There's only a couple of features that I really used, and just got used to living without it.
4 months is a long time.
I have a related side-question if you don't mind. &amp;#x200B; Will compiling different parts of my code with a mismatch of /permissive and /permissive- cause any ODR (or other) issues? This is blocking my adoption of sol3 because I use /permissive- everywhere (as it should be). I could disable it temporarily for the code which uses sol3, just not sure how safe that is...
Templates in C++ compile if the syntax is right, but don't check semantics. For instance two classes have a method "empty()", the first one meaning "is it empty?" (like in std), the second one meaning "remove all elements". The template function instances using empty() for each of these classes will have different semantics. Concepts would be an answer to this problem, but again in C++ they only check syntax, not semantics. The only solution left in this language is deriving from interfaces, but it comes with it's own problems of managing memory.
I entirely agree with you, but I was talking about the name, not the type.
Instead of "system" do: ``` cin.ignore(); ```
Just run the exe from a terminal. They use it to read the output, nothing else.
But it's Teribbly slow (at least for larger solutions)
:-D
Welcome to the ricefields!
What Eric said, except that I have less personal knowledge of all the executor stuff. Wish I had more time - I've written executor-like things before, and I think I know something about good APIs, so I feel I could help. But it sounds like maybe, finally, if-we-are-lucky, etc, we might have a good model just around the corner.
No language feature can fix that. If you have a strange implementation of an interface or of a concept, in both case you are in trouble.
Great job and happy hacking my friend! Please don‚Äôt think I am trying to nit pick you, but break the habit of using namespaces while you are still green!
Ive taken two university level programming classes using c++ and the professor made us use namespace std all the time. :(
ie specifically, remove the "using namespace std;" line, and then use `std::cout` instead of `cout`.
Yep, you're absolutely right, and i realized It during debugging tonight. Looks like I'll have to write my own moveable optional. I'll fix the post tomorrow.
Just from the top of my head, it would be easy to fix with a combination of static interfaces (or "traits" in other languages), contracts and proper constness. Notice the functions I mentioned before operate on different kinds of objects const-wise, but people will probably will use the C++ default of nonconst which will lead to runtime error instead of compile time.
With Visual Studio 2019 I didn't bother to renew my license and for hobby work I'm really not missing much. The code complete suggestions and some refactoring tools are a bit better with Visual Assist but IMO not to the point of paying $99 a year for it. If I was doing commercial work I probably would still buy it because it is still nice to use.
I don‚Äôt understand why this thinking is so prevalent. As long as you don‚Äôt use them in header files, there is little harm. Any decent compiler will warn you about ambiguity, which is what would cause serious problems.
Instead of commenting on your code, I'd advice you to dump this trash of IDE and start using a real one like Visual Studio/Qt Creator/CLion. Not only they offer better functionality, but they also come with actually up-to-date compiler and not half-decade old GCC.
This is a perfectly valid strategy and in fact a number of customers utilize this if their engineering system is capable. &amp;#x200B; As far as the ODR question, we have not observed any situation where mixing \`/permissive-\` and default mode creates and ODR violation. Since we do not provide a macro to indicate \`/permissive-\` is active users cannot tell at a source code level so potentially ODR violating situations cannot arise. We also ensure that we maintain ABI compatibility in both modes so linkage is never an issue.
Welcome to C++. However, this is off-topic for our subreddit.
Okay, then tell me how are you able to call system() without including stdlib.h or cstdlib ? :D
A preprocessed repro with an exact command line is sufficient. Compiler devs can debug into that (not as easily as a fully reduced repro, but it's still actionable).
I could intentionally craft an ODR violation, but I don't think it could be encountered unintentionally. Extremely low risk.
http://open-std.org/JTC1/SC22/WG21/docs/papers/2018/p0931r0.pdf
Well, Object oriented programming is not formally defined, every author provides a different definition and not necessarily an object is a model of a real world concept. OOP can be even used in some languages without object such as C where objects can be emulated using opaque pointer (void\*) to incomplete types and using functions as methods. In Lisp objects can be invented using closures, functions with local state variables. &amp;#x200B; \&gt; In the case of a single instance of a variable of a primitive type, what do you think would be it's behavior, since it is not based in a class with methods? &amp;#x200B; There is no behavior for a single variables of a primitive type, even in Java primitive variables doesn't have behaviors or methods. The only language where primitive types have behavior is Smalltalk which is a pure object oriented language where everything is an object such as primitive types, numbers, functions and even classes.
Why
Be careful with nlohmann json implicit conversion, it's likely [on it's way too be deprecated](https://github.com/nlohmann/json/issues/958), and hopefully replaced with explicit conversions.
Thank you for your feedback. It might help to understand my original goal. Originally, I wrote this library because I wanted to set variables in my code from the command line directly, so if you were to type something like `command --URL=`[`www.example.com`](https://www.example.com), it would set a specific variable and convert it to the type directly. I also wanted to avoid any heap allocated memory management since that leads to all kinds of bugs, so I made everything stack allocated. As it currently stands, only stl objects do any memory management. Since I made them stack allocated, they either have to have a name or they have to be heap allocated and stored in a vector of `cli::Interface`s. I'm planning on adding a feature where you can just do something like `p.var(..)` and it will manage its own memory. I was just being a little paranoid. Plus, you wouldn't have to specify the type since functions can infer it. I don't know what you mean by "null/unspecified and empty/0 option values". I think you're referring to arguments that do not have arguments, like -r for the cp command. I do have those, but they're called `Value`s. When one is encountered on the command line, the parser sets the variable to the value you provided when declaring it. The \_var variables represent the link between the list of flags and the variable. Subcommands can also have subcommands and their own unique flags, just treat them like you're writing a main function. The parser also cleans up after itself when you enter a subcommand, since the subcommand has its own flags that do different things. Using either -h or --help will display the help message for the command and all subcomands that were called in the command. If you were to type `git push test` and put a --help anywhere in there, it would display the help message specifically for the subcommand test. I'm following git's style of subcommand handling. You can also pass information from a command to a subcommand. The library currently does not support Windows-style arguments (slash and colon), but it will run on Windows. Autogenerated help will provide a help file in the syntax 1. Usage Message (You can fill out the usage message however you like, but it will display the command and all the subcommands leading up to it.) 2. Header (You can put literally anything here and it will be printed exactly as you write it.) 3. List of Subcommands 1. Subcommand and Description (The descriptions can be anything, but the names are set when you add the subcommand.) 4. List of Options 1. Options and Descriptions (The descriptions can be anything, but the flags are set when you create the cli variable.) 5. Footer (You can put literally anything here and it will be printed exactly as you write it.) It will also wrap lines so that no line is longer than 80 (by default, as you can change it) characters. I decided not to allow non-standard options like "-long-option" because it could either be "-l -o -n..." or "-l ong-option", which makes parsing significantly harder. Sample usage that seems to fit the code/help message generator pattern you recommended. cli::Value&lt;std::string&gt; some_var(some, { "d", "dir" }, "dir", "help string"); The variable you store it in doesn't need to be stack allocated, it just needs to be a valid memory location with some way of knowing the type for later use. You could replace some with hash\_table\["dir"\] or something. The library does not support multithreading in its current state. However, adding the `p.var(..)` functionality will allow it to be multithreaded. In short, the biggest problem here is that my README is not explaining what it needs to explain clearly. I'll have to rewrite it for clarity. I already have half of the features mentioned in your comment (notably recursive subcommands, null/unspecified options and empty or zero value options, a flexible help menu generator with usage, header, autodocumentation for subcommands and flags, and help applying to subcommands), and I don't think implementing some of them would be beneficial, like storing things in a map by default.
Great results and a great writeup! Do you think this could make a better general purpose sort function for unsigned integral types, or are there (non-pathological) cases where a comparison sort will always win?
In the future, you can find papers by doing this: `https://wg21.link/pXXXX` where `XXXX` is the number. This will automatically take you to the most recent revision of the paper. If you want to look at a specific revision, you use `https://wg21.link/pXXXXrY` where `Y` is the revision number. In this instance, you want https://wg21.link/p0931
Thanks to both!
You will understand after you debug your code for 2 days, just to find that the maker of the library decided its good idea to create mysql::string completely seperate from std::string... Of course, in the documentation it was not obvious, because in the code snippets, it just called string, which I assumed is std::string. From then on, I am always explicit about namespaces.
&gt; This change actually cuts the memory bandwidth requirements of the algorithm almost exactly in half [...] Yet the overall speedup is small Note that there's a visible kink at 1 million elements, because your last-level cache is obviously 2*sizeof(uint64_t) million = 16 MB. Though 8 MB might be enough to show the same shape, especially since you aren't testing many sizes. `lstopo` is a nifty program to show all this kind of info. It's meaningless to talk about memory bandwidth for the smaller cases, since you're not hitting memory at all - you only care about cache bandwidth. *** It's also worth noting that, for certain sizes (2^n and 2^(n)-1 at least), there are (poor-quality, but fast) RNGs that directly generate the values without duplicates. If you don't have exactly the size, simply pick the smallest `n` that works, and discard if it's too high (no more than half the time).
It's easy to implement yourself, but it will be very bad with performance.
I assume it's not really 67MB of changes, it's just completely rewriting itself (afaik it's about the total size of the installer). It's easier to just replace everything that doing a smart update sometimes.
Seriously well done! Bookmarked your blog
It‚Äôs probably been answered in other posts about releases of HPX but what is the adoption of this library like? Do a lot of people here use it? It seems like there are some nice things in it, just wondering others‚Äô thoughts on actually integrating it and using it.
I disagree that online tutorials are equivalent/comparable to peer teaching. I doubt that the key factor in those studies is the ignorance of a student's peers, rather the social environment they share. &amp;#x200B; I agree with the original commenter, tutorials by beginners are inevitably harmful. C++ in particular has a lot of dated features. Understanding the syntax is not even half the battle of learning how to write good code.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/bsb5hd/why_is_my_open_mpi_program_not_working/eolatq7/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Your arrogance is totally bewildering to me. Cherno blows you out of the water. Like its not even close. There is a difference between understanding the syntax of a language and knowing how to program. &amp;#x200B; &gt; All the other c++ tutorials (especially Cherno and boston) are fucking garbage shit because they‚Äôre too fast paced and don‚Äôt really cover use cases of how to do it. If you are looking for "use cases", as just one example you could watch Cherno's video on [how to render objects with OpenGL](https://www.youtube.com/watch?v=7D8lLbp9_rQ). I look forward to your video on "loops" lol
The performance has gotten massively better with the latest update
It would be great to see TimSort added to the benchmarks.
For a C string you can‚Äôt know the length until you scan it to the end. For strings and string views, compilers can exploit the fact that the size *may* be known in certain circumstances and if it fits in a register or so, great.
is that an HI thing or am i missing something?
It's a very good sorting algorithm used in Python and Java.
And please make only good memes.
Your second case is wrong, it is identical to the first case. You should compare against `y`, not against `"hello"`. This leads to a major difference in performance, making the second case the fastest. In the last case, I think it would be more meaningful to remove the construction of `string_view` from the loop.
Those are the static analyser and EDG parser. Totally unrelated to MSVC, different codebase.
Great post. Just wondering: Have you compared this to boost::integer_sort (spread_sort) or ska_sort? I think something like this should really be added to boost (assuming it outperforms the existing algorithms in at least some relevant cases)
Can you elaborate on the RNGs? Or share a reference?
I was asking about this : &gt; But at least in the past,cmake didn't support clang++ on windows.
Timsort is optimized for sorting typical "real-life" data (as in: exploiting things like partially sorted arrays), I doubt it performs better than radix-sort.
cmake doesn't support clang++.exe it supports clang-cl.exe (same compiler, but using msvc command line parameters instead of the g++ - style parameters)
well no, that's what I'm saying, I've been using a clang++ / libc++ toolchain on windows with CMake for months without problems
I find the vanilla VS intellisense since version 2015 to be more than adequate and it gets better and faster every new major version with my own code. Sadly I am forced to use VAX because the standard one craps out when using Unreal Engine 4.
I checked it out, and `boost::integer_sort` lies somewhere between `radix3` and `radix4` performance on my laptop.
Well, nothing new after all. When using PCH, just activating it is only the first step. The fun part is deciding what's going to be in there.
Even with `f.flush()` called in the function, there is still a little work done in the `fstream` destructor: it closes the file. The operating system also does some buffering, so there is still a chance that this will fail, although admittedly it's unlikely. But the safest and simplest thing to do is replace `f.flush()` with `f.close()`.
If you're on linux make sure overcommit is disabled too, or you may get false negatives
Timsort generally doesn't perform better than `std::stable_sort` in these kinds of benchmarks, except when sorting data with already somewhat presorted data, where it tends to outperform the other algorithms. That said it should be possible to create benchmarks where it is rather consistently faster when comparisons are expensive, but as long as you're sorting fixed-size integers it probably won't shine that much.
As far as sorting unsigned integers can be called general purpose yes (to be honest despite not being a comparison sort, a radix sort can be made much more useful with projections support). Some comparison sorts can win on specific patterns, but for general random data chances are that a properly tuned radix sort will always be faster.
The author seems to have never used c++/Winrt. In this project, the PCH makes a huge imact.
Question 3 of the survey has "select all that apply" with radio buttons, making it impossible to select all that apply.
In our (anecdotal and qualitative...) experience, caching was most effective, then distributing the compilation and finally PCH. In our experience, caching bordered on a silver bullet - PCH was a mixed bag, ultimately worthwhile but only just.
Caching is indeed the most effective, especially with a shared cache (check sccache for that) The big win about caching is that is can be added transparently to most build systems, without adding any complexity to the build scripts.
I wonder how it stacks up to https://github.com/orlp/pdqsort.
We haven't managed to try sccache yet, its on the list though! ...along with many many other things.
You should add a readme to your repository.
Yeah, I used VS because of UE4
POSIX `close()` can absolutely fail e.g. `ENOSPC`. So I completely agree with this comment, don't flush, flush + close explicitly. (P1031 has exactly the same problem, closing a `handle` explicitly can fail, destructing a `handle` silently sinks any failure)
The thing is - why the same code base compiled using PCH with MSVC cuts the compilation times by 3 but with GCC/Clang you gain only \~10%
THats great news. Which version of CMake are you using? How are you invoking cmake such that it picks clang++? If I'm trying something like cmake -G"Ninja" -DCMAKE\_CXX\_COMPILER="C:\\Program Files\\xDev\\LLVM\\bin\\clang++.exe" .. with cmake 3.14, I get CMake Error at C:/Program Files/xDev/CMake/share/cmake-3.14/Modules/CMakeDetermineCompilerId.cmake:859 (message): The Clang compiler tool "C:\Program Files\xDev\LLVM\bin\clang++.exe" targets the MSVC ABI but has a GNU-like command-line interface. This is not supported. Use 'clang-cl' instead, e.g. by setting 'CXX=clang-cl' in the environment.
I can answer your question right now: 90% of codebases do not handle oom.
It was not really possibly to give sensible answers to the survey, since it pre-supposes that handling out-of-resource errors is something we want to do. We handle them by exiting. Hard &amp; Immediately.
TLDR: #including more in your PCHs does reduce the parse time but may inflate the time spent (by clang at least) dealing with template instantiations. Unfortunately that's about it. The first half of the post is just blabla. Then you get some analysis using the new `-ftime-trace` option, I particularly liked that. But in the end it isn't revealed why msvc seems to be better on the very same code or how to fix it for clang, just some bragging about it.
thanks bad typo, the literals question still remains though
for a literal the compiler does know the size though, in fact if you do a strlen on a literal, most times the compiler will just feed the constant length as an immediate
you dont know what does it mean?
My bad I was reading on small screen and read the title as "vs cstr" instead of "vs cstr literals"
Will do.
I think this is a beautiful illustration how flawed the fundament of C++ is. The fluid nature of basic types and automatic type promotion has been a source of many bugs and even more confusion.
While the investigation could be a fun thing in itself, `char+char` has no meaning and + operator for it should be deleted/made private.
`int`s are required to be at least 16 bits by section 5.2.4.2.1 of the C99 spec, so you can't have an 8-bit `int`.
`avr-gcc` has an `-mint8` flag which makes `sizeof(int) == sizeof(char) == 1`. But that flag also comes with a warning that says "This is not standard compliant." &amp;nbsp; In other words, thank you for pointing out that "no one knows" actually means "I don't know what is an `int` according to the standard".
`char` is not (only) a character (as in a string character), it is an integral type like `int`
but you could have a 16-bit `char`
&gt; So for instance you could have an eight bit system where both char and int are eight bits. Wrong. `int` is required to be at least 16 bits. This is an actual pain in the ass on 8 bits controllers because the type of the result of operations on the architecture's native size is not the architecture's native size. However char can be 16 bits. Hell, you could have char = short = int = long = long long = 64 bits.
If the committee decided to take a page from Java's book and add a specific type for bytes, I would be completely OK with this. int8_t and uint8_t are just simple aliases for char/unsigned char under most (maybe all?) implementations right now. Proper separation of the two would be a godsend.
There's `std::byte`.
std::byte in C++17 is what you're looking for, I believe. That does not allow arithmetic operations, but does allow for eg bitshifts.
Not really. This is an illustration of what happens when the person writing a blog doesn't know about standard section 5.2.4.2.1.
That's what `std::byte` is for :)
Do you mean that you should use signed/unsigned char when you're using it as a number, or to never use those types as numbers at all?
https://www.ti.com/microcontrollers/c2000-real-time-control-mcus/delfino-premium-performance/overview.html These guys have CHAR_BIT == 16 and sizeof(int) == 1
That section doesn‚Äôt invalidate his point. Everything else he says is true.
For C, this is not a flaw, but an intentional choice: Most of the implementation liberties in the C standard allow the implementation to use native types and constructs. Whether C++ should have inherited most of that, open to debate. However, a perfect and clean C++ would have played no role in a flawed world. --- The blog too much tries to present this as "look how crazy!" I've seen the material presented much better. It is a precarious balance between portability and allowing the compiler to use optimal native constructs as much as possible.
And I think the c lib coming with avr-gcc doesn't work with `-mint8`.
It makes his point stronger, this person may not be an expert but they have at least basic competency and presumably did some research for this, and still made this error.
`char` is and has always been an arithmetic type.
IMO, `char` should be a character, and you shouldn't be able to add two characters as that's not logical. `signed`/`unsigned char` are integer types that could do with better names, and the restrictions on what a `char` can do shouldn't apply to them. Subtracting two `char` should be allowed, yielding an integer type. Adding/subtracting an integer type from a `char` should also be allowed - that's used a lot in printing decimal/hex/etc (`'0' + i`). But not adding two `char`.
I'm using these toolchains which use the mingw ABI indeed : https://github.com/mstorsjo/llvm-mingw/releases (from a cmd.exe shell with the normal CMake and Ninja)
int8_t is signed char, which is a separate type than char (because char could be unsigned). So: * arithmetic -&gt; (u)int8_t * bit manipulation and memory reinterpretation -&gt; std::byte * ASCII characters -&gt; char * UTF8/16/32 -&gt; char8/16/32_t
And now we don't need named parameters in language.
I've always wondered how does that work. Am I allowed to store `500` inside a 16bit `char`? What about `int8_t`? Is it 16bits wide as well? Can I get to low and high bytes?
Ah ok, that clarifies my confusion. Thanks.
What is even worse, is that int8_t+int8_t yields also an int ! https://godbolt.org/z/ARP7qN
Did this, got an error saying cont isnt a member of std
Github paper tracker: https://github.com/cplusplus/papers/issues/395 Doesn't say much, but it's all I have to offer.
MSVC and clang/gcc have very different models for PCH. In particular, MSVC pch also emits a .obj file containing the generated code for everything in the pch header, while clang/gcc seem to just be a cache of the parsing state. While this makes MSVC pch a bit harder to plug into a build system (because you also need to ensure the .obj gets linked in), it is able to save significant time in the backend of the compiler, not just the frontend. It also has the surprising effect of making linking faster because there is less redundant crap in the obj files to merge/remove. This is especially important because link.exe is absurdly slow. In fact, for our windows unit test builds, the faster linking made a much larger difference to build times than faster compiles! There is also the issue that windows.h is such a behemoth that parsing headers costs more on windows than on linux, so there is more gain available by making them faster there. IIRC macOS system headers have a similar issue.
this is a perfect " we don't want to hire you" interview question.
No. It got hit by a little scope creep trying to get all the stuff in `&lt;functional&gt;`. Turns out it's really hard to word constexpr `bind`. /u/sphere991 is working on it.
1) Yes, but it's non-portable, 2) 3) No such thing, `int8_t` only exists if there is an 8-bit integer type, 4) There's only one byte, and it's 16 bits wide, so there's no low and high bytes, but you can access the low and high octets by masking and bit shifts.
&gt; char can be 16 bits. can it? i thought char was guaranteed to be 8 bits. i could be wrong, of course.
If `char` is 16 bits, then there will be no `int8_t`.
Ah yes, the well-known CSILP64 data model.
"No one knows" here meaning "Theres no single answer for all implementations". Since all the information you need to predict the behavior is implementation-defined, the implementation needs to tell you what its behavior is. Thus you can predict the behavior for each implementation, once youve read its documentation.
sizeof(char) is guaranteed to return 1 but that doesn't mean that the return value of 1 actually indicates the number of octets in a char. There is a C macro, CHAR_BIT, which you can use to tell how many bits are in a single char if you absolutely need to.
Another option is `std::numeric_limits&lt;char&gt;::digits`.
Isn't that a somewhat required step to make range algorithms `constexpr` since they are supposed to be used with all kinds of `Invocable`?
That's still an important datapoint for the survey. Since this is about [P0709](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0709r2.pdf) and the proposal suggests that "handle [snip] by exiting. Hard &amp; immediately." should be the default and the current default should opt-in (read the paper for more details). &amp;nbsp; That said, I'm in the same boat as you. Maybe we should open a github issue for directions? (By the way, your comment is currently the most upvoted).
&gt; In CMake, everything is a function! so that's the new strategy ? convince the haskellers ?
My experience is (really) opposite for the past 20 years, using Visual Studio, for a large application.
Significant figures are a high school method for representing certainty. Digits are irrelevant. One should specify the their estimate of the mean and standard deviation.
Which is an amazing‚Äîor appalling‚Äîlack of clarity for such a fundamental feature of the language. The language does not determine which function `f(x+y)` calls when `x` and `y` are elementary types. This is a major defect of the language made possible by several other defects in the language. I say this as someone who loves C++ and uses it every day.
16 CHAR_BIT is pain to work with as someone that has to write code for C2000. It is just horrible to try to write code that works on multiple platforms when one of those platforms has CHAR_BIT == 16
Ok... Now the question: where in what I have written so far is this curse lurking... ?
This is just something called [‚Äúnumeric promotion‚Äù](https://en.cppreference.com/w/cpp/language/implicit_conversion) in C++‚Ä¶ there‚Äôs lots of unintuitive / gotcha situations like this, where an arithmetic operation like addition is happening. If you were to only define the `int8_t` version of the `f` function, it would behave the way you think it would, but providing an `int` version allows it to be a ‚Äúcatch all‚Äù for any types lower than itself. I believe if you enable flags along the lines of ‚Äúdisallow / warn about implicit conversions‚Äù and ‚Äúwarn about narrowing‚Äù you can catch it when it happens.
Absolutely, I find this infuriating. [https://www.nayuki.io/page/near-duplicate-features-of-cplusplus](https://www.nayuki.io/page/near-duplicate-features-of-cplusplus)
Except it can't hold most characters and even if it is holding a character you have to know the encoding, which isn't going to be a good one.
Couldn't you provide overloads for the arithmetic operations you want?
I use GCC (on both windows &amp; linux) &amp; Clang's PCH feature, and although I use a handful of templates, it still cut the compile time for one of my projects from 30 seconds down to 10-12. I think it's just as effective as MSVC's and it's a little pig-headed to assume that nobody uses it, as this article does.
I don't think this is really as big as a deal as you describe. If the overall semantics of `f(x+y)` is in any way dependent on which exact type `x+y` results in, then the overload set of `f` is not well designed. Such an overload set would be surprising and unintuitive to users. Integer promotion is there to allow implementations to extend integers to the size of a register, to be optimize integer arithmetic.
This type of confusion is the source of many subtle errors in C++ code. Often times, these problems only show of in some cases/configurations/compilers. So testing cannot guarantee that one's program will work. If you want to address this is a definitive way, Look into the [Boost.SafeNumerics](https://github.com/boostorg/safe_numerics) library which is designed to prove that your integer arithmetic will never return wrong results. In many/most cases, this adds zero runtime overhead to your application. See: [https://github.com/boostorg/safe\_numerics](https://github.com/boostorg/safe_numerics) [Boost.SafeNumerics](https://github.com/boostorg/safe_numerics)
&gt; The only thing we know for sure is that it‚Äôs not 3), f(char)! Silly question, but... why? What is the reason the addition of to chars is not a char?
Why do you think so? The obscurity of your citation hardly testifies to the clarity of the type system. You‚Äôre argument appears to be, the article does not illustrate the fluidity of the type system and byzantine promotion rules because while explaining those rules the professional C++ programmer who wrote it, despite clearly having researched this issue, made a mistake about section 5.2.4.2.1 of the standard. That is not convincing to me in the least. In fact, if he had understood the cited section, his blog post would be virtually identical, with only a few 8‚Äôs changed to 16‚Äôs. Section 5.2.4.2.1 of the standard is immaterial. And the ‚Äúbug‚Äù in the blog post is Exhibit A for how easy it is for this flaw of the type system to be the source of subtle errors *even when programmers are looking out for them.*
How are you going to define "char" if you want it to store a human-meaningful character? That character is one codepoint the vast majority of the time, which for the forseeable future would fit in std::uint32_t, but it could be multiple codepoints sometimes. So maybe something like a `variant&lt;uint32_t,unique_ptr&lt;string&lt;uint32_t&gt;&gt;&gt;` ?
&gt; Why is boyer_moore_horspool so 'slow'? Because your test data is ridiculously small? Try comparing on data that are a few MB large...
&gt; Integer promotion is there to allow implementations to extend integers to the size of a register, to be optimize integer arithmetic. And yet on 8 bits archs, `uint8_t + uint8_t &gt; uint8_t` will do a 16 bits compare even if there is no support for it.
I genuinely could not tell whether this was a parody until I read the replies.
At the time of writing the above comment, I did forget that `CHAR_BIT` could be 16 instead of 8. However, there's still no magic here. The rules are well defined, even if they are implementation defined and not universal, so "no one know the type of char + char" is still misleading. Is there no single answer that applies to all conceivable architectures? Sure. Does it mean I can't know what happens on the architecture I'm targeting? Of course not. Someone above mentioned TI's MCU which has `CHAR_BIT == 16`, but if you're targeting that, you're definitely not targeting x86 or ARM (and vice versa).
Rather, it's an intentional choice that turned out to be a flaw. C's approach does *not* make it easy to write portable code. Code just doesn't work unless it knows the sizes of its types. A simple solution would be to have only `[u]intN_t` types, with no promotion to larger sizes, and all operations are undefined on overflow without explicit wrapping operations, and have implementation defined size (though a packed type would be nice). Then you can actually write portable code, using the smallest type necessary, the runtime can use whatever is fast and large enough, and nobody is confused about what code is getting called by what.
Thanks, you're right. My use case are lines in text files for a search tool.
I guess the most sensible thing would be to define it as being a single utf32 code point (or ASCII on ascii systems, etc). Multiple-codepoint characters is just a pain, and would probably have to be a string type. Units of a smaller encoding that may not be a complete character like UTF8 would be their own type that would have to be non-arithmetic (adding to a utf-8 unit which might be a fraction of a complete character can't end well). `wchar_t` was sort-of introduced to help unicode support but is pretty broken for that on several systems (looking at you Windows where it's UTF16, which still contains surrogates so it's still not a complete codepoint), and then you're still left with `char` not being useful either. You end up with `char8_t` for utf8 units and `char32_t` for complete codepoints, and people ignoring "char" and "wchar" altogether. In short, it's a mess.
Clearly C wasn't designed for 8-bit machines. 16 bit and 32 bit really. 64 bit doesn't work correctly with integer promotion either, as "int" isn't 64 bit on most 64-bit machines, so they don't promote up to the register size regardless.
It‚Äôs the only choice. Fundamentally we have two data types, discrete (integers) and real (floating point). Characters are countable and therefore fall into the discrete domain. The only reasonable way to represent them is when an integer.
Not always. Here's a case that bit my ass recently. I was checking a timer, basically doing something like this to neutralize the timestamp rollover (unsigned overflow is perfectly defined): unsigned start_timestamp; unsigned current_timestamp; bool has_elapsed(unsigned duration) { return current_timestamp - start_timestamp &gt;= duration; } But then I realized 8 bits were enough for all my timers. Since I was on a 8 bit ¬µC and I used that function several time per main program loop, I rewrote it like that: uint8_t start_timestamp; uint8_t current_timestamp; bool has_elapsed(uint8_t duration) { return current_timestamp - start_timestamp &gt;= duration; } A wild rollover bug appears!
&gt; ASCII characters -&gt; char Pray you don't have to handle extended ASCII...
TFA: pch might not be great with template/header-heavy code. Me: surprised Pikachu face. Nice graphs though. Was that a Clang advertisement, in fact?
That's what this survey tries to get evidence for.
Why should algorithms depend on bind? Or did I misunderstand you?
LFSRs have period 2^(n-1) and are published for all `n` up to `1206`, most `n` up to `2598`, and some `n` up to `5196`, based on the [the Cunningham tables](https://en.wikipedia.org/wiki/The_Cunningham_project). Except for very small `n`, there are at least 4 streams per size (Fibonacci vs Galois, and you can mirror the taps across `n/2`), and often more. For `n` up to at least 200 or so, you can dynamically generate them relatively quickly even with an unoptimized matrix multiply - I generated up to 214 before starting to optimze, but some of the last ones were slower than you'd want for interactive use. PCG's ["insecure" generators](&lt;http://www.pcg-random.org/using-pcg-cpp.html#insecure-generators&gt;) have period 2^n and are published for `n` in `{8, 16, 32, 64}` and it's possible to create the constants for other `n`, although I have not done so. There are 2^(n-1) streams for each size. Many other RNG algorithms can be considered variants of an LFSR, at least as far as the `jump` math goes.
&gt; Characters are countable Define countable? Each character is a variable number of codepoints, which are a variable number of code units. Code units you could represent nicely with an integer.
But it's better not to confuse newbies and call code units characters. And that's why I strongly dislike the name `char`
Because PDP-11.
Is it specified in the C++ spec though? They‚Äôre not actually the same language, even less so recently
And how exactly would C++/WinRT be related to the huge LibreOffice code base, which the post was about?
Which compiler version do you use on linux? Last time I've checked strstr was faster than std::find
You're completely right that std::byte exists. :-) I'm sort of discounting it in this context since it can't be used (natively) with arithmetic operations. I'd rather a simple separation between a character type and an arithmetic one (including bit operations). But that's just my thought!
Very good features. But they are not addressing the main problem. The UI and the whole framework is buggy and slow as hell in non-OSX machines. I do have last generation core-i7 32GB ram 1tb PCI Express M.2 and still, I cannot use CLion on a midsize project (let alone big project).
&gt;the times are ca 3x worse in the native terminals. That‚Äôs very unlikely.
`char` is guaranteed to be *at least* 8 bits.
Could you explain the bug? I'm struggling to understand it. My *guess* is `current_timestamp` and `start_timestamp` in the subtraction are both promoted to `int` as they as both `unsigned char` and an `int` can hold all an `unsigned char`'s values. Then `current_timestamp - start_timestamp` can result in an underflow that is undefined for signed integers if `sizeof(char) == sizeof(int)`? Or is it more simply that the `int` created from `current_timestamp - start_timestamp` when compared to `duration` could now be negative rather than wrapping like you intended, which wouldn't have happened with the unpromotable `unsigned`s above, resulting in the wrong behaviour?
I just switched from 7.4 to 9.1, the times didn't change, though.
By countable I mean the math definition of countable, which basically means that the set of possibilities is representable by a mapping to integers. I hope that makes sense. True, and I think that can be extended. Code units can be represented as integers. Therefore each character is a variable number of integers, since code points can be represented as integers. So, each number is represented by a sequence of integers, which is also an integer by simple concatenation.
On Linux: https://imgur.com/a/VOIj82G
From skimming over the code, it seems like everything is synchronous, is that correct? If so, that would be a significant limitation for any real-world application.
MSVC's strstr is fast because it is optimized SSE assembly, SSE42 or regular SSE on x64 platforms. On i386... it is optimized for those two paths as well as a non-SSE path. For std::string::find it uses __builtin_char_memchr, walks the entire string and compares it or uses regular memchr (pre-CXX17). Not sure about any other implementations, but those are all very good reasons for it to be fast. But your results seem dumb because they should be more consistent between platforms, etc. because library maintainers aren't stupid.
The C++ standard uses the C standard as a 'normative reference' relies on it for many things. In particular in this case it leaves the meaning of `INT_MAX` entirely to the C standard saying that "The contents [of C++ header &lt;climits&gt;] are the same as the Standard C library header &lt;limits.h&gt;."
Also true. It's actually got a dual meaning between "character" in the ASCII sense and "character" (meaning byte) with the same root that led to "word" meaning 2-4 bytes in CPU design / assembly language.
Maybe, compliers should support unity build mode
I don‚Äôt know what went wrong (maybe you used a debug version), but the terminal doesn‚Äôt influence a find in a string.
Are they even working on this?
Hey, have you filed a bug about wrong highlightings? If not please do create one in the [issue tracker](https://youtrack.jetbrains.com) or contact our support.
Why do people waste their time thinking about this sort of thing? I genuinely don't get it. That a particular named type is slightly underspecified (despite never actually varying in practice) is just so profoundly uninteresting.
Let say `start_timestamp = 250` and `current_timestamp = 10` (a rollover happened between the two). The difference is `10 - 250 = -240` instead of `(10 - 250) % 256 = 16`. So `has_elapsed(15)` returns `false` instead of `true`.
Can confirm, after a small change to the code, the IDE can take over a minute to make up its mind.
Man I didn't even know c++ allowed overloads. I've always basically used it as C, but with classes and smart_pointers
An hypothetical port to UWP.
I actually just ran across this which seems really solid: https://github.com/skypjack/entt/wiki/Crash-Course:-core-functionalities#hashed-strings
Thanks for pointing this out, I've updated the article to use 16 bits in the example instead of 8 bits.
&gt;set (C_COMPILER gcc) &gt;add_custom_command(OUTPUT hello.o COMMAND ${C_COMPILER} -c hello.c DEPENDS hello.c) Please don't do this. `CMAKE_C_COMPILER` exits, has greater effect, and can be set on the command line. &gt;foreach(file ${ARGN}) `foreach(file in ${ARGN})` is the "modern" syntax, and it allows processing embedded lists correctly.
This is going to change. Current draft of the standard contains [Table 10 in [basic.fundamental]](http://eel.is/c++draft/basic.fundamental#tab:width) that directly specifies minimum widths for integer types.
Most of the time is just a "we are fucking retarded" hiring process.
It's rarely a problem in practice, because we rarely add chars. If we do, we really ought to declare them as signed or unsigned explicitly. What has been more of a problem for me in practice is not knowing whether a `char`, or an `int` that was promoted from a `char`, can be used to index an array. If `char` is signed (and it usually is), then you have to worry about negative values.
Did you read the article? It is not just that. According to [the standard](https://en.cppreference.com/w/cpp/language/types#Character_types), `char` may or may not be unsigned and have an arbitrary width [which may very well be 16 bit](https://www.reddit.com/r/cpp/comments/bsflbt/noone_knows_the_type_of_char_char/eon102k/). Thus, not all values of a `char` may fit into an `int` and thus depending on your architecture, `char + char` may either be `int` or `unsigned int`. This is neat enough to warrant a post.
That must be the worst introduction to cmake I've ever seen. &gt; Here is the version you would use if you didn‚Äôt know how to build the thing on your own: Apart from the fact that even that version is horrible, it is still better than manually building it yourself - even if you know how to do it.
Shouldn't `char z = x + y` display a warning, then?
I meant that they depend on `std::invoke`: it's the simplest tool to make algorithms work when you give pointers to members as projections or comparisons.
Does Linux have anything similar to AppVerifier? This looks like something it can already do, but if there's no alternative for platforms other than Windows, it could be pretty useful (in case someone wants to know that their code indeed does not handle OOM).
Does anyone know a system from this millennium where int actually is of the same size as char?
I don't mind so much `int8_t + int8_t` yielding an `int`. I do mind the fact that `int += int;` is warning free but `int8_t += int8_t;` is not. Inconsistency is just so annoying :/
This is not "no one knows," this is implementation-defined behavior. This is also a known pitfall with the char type, its size and signedness can vary between implementations and you shouldn't rely on it. So yes, if you set up a situation that relies entirely on implementation-defined behavior, it's going to be implementation-defined behavior. &gt; And if you answered 2), maybe you tried the code on your own computer? Or maybe I know what a char is on my implementation and how integer promotions work. This is called "knowing the programming language you're using." Accusing your readers of cheating for knowing a relatively basic feature of the language is a bit... I don't know what it is, but you don't need to do that.
On OSX it‚Äôs very slow on mid sized projects as well; for me.
Move refactoring screenshot shows non-monospace font for code...
Can confirm. Additionally it takes 400% CPU on idle.
Still being stuck on C++03 is my bigger complaint....I think TI has C++14 support for the MSP430 and C6000(?). For the CHAR_BIT issue, I just avoid char entirely.
The problem with `conan` is that it doesn't always follow the upstream [CMake find module](https://cmake.org/cmake/help/latest/manual/cmake-modules.7.html) naming conventions, and you are forced to use their packages on all platforms. Unlike `conan`, `vcpkg` actually does follow the CMake find module naming convention. Let's say you have this example: find_package(PNG REQUIRED) target_link_libraries(main PRIVATE PNG::PNG) This will work with CMake on Linux, and vcpkg on Windows, but not with conan, or Hunter. |Package / Target|CMake upstream|vcpkg|conan|hunter| |:-|:-|:-|:-|:-| |zlib|[ZLIB](https://cmake.org/cmake/help/v3.14/module/FindZLIB.html), ZLIB::ZLIB|[ZLIB](https://github.com/microsoft/vcpkg/blob/master/ports/zlib/usage), ZLIB::ZLIB|[ZLIB](https://github.com/conan-community/conan-zlib/blob/release/1.2.11/test_package/CMakeLists.txt), ZLIB::ZLIB|[ZLIB](https://github.com/ruslo/hunter/blob/master/examples/ZLIB/CMakeLists.txt), ZLIB::zlib| |libpng|[PNG](https://cmake.org/cmake/help/latest/module/FindPNG.html), PNG::PNG|[PNG](https://github.com/microsoft/vcpkg/blob/dev/grdowns/5938/ports/libpng/usage), PNG::PNG|[PNG](https://github.com/lasote/conan-libpng/blob/release/1.6.32/FindPNG.cmake), no target|[PNG](https://github.com/ruslo/hunter/blob/master/examples/PNG/CMakeLists.txt), PNG::png| |FreeType|[Freetype](https://cmake.org/cmake/help/latest/module/FindFreetype.html), Freetype::Freetype|[Freetype](https://github.com/microsoft/vcpkg/blob/master/ports/freetype/usage), Freetype::Freetype|[no package](https://bintray.com/conan-community) no target|[freetype](https://github.com/ruslo/hunter/blob/master/examples/freetype/CMakeLists.txt), freetype::freetype| On Github Conan Community has [46 repositories](https://github.com/conan-community), Hunter has [485 examples](https://github.com/ruslo/hunter/tree/master/examples), vcpkg has [1022 ports](https://github.com/microsoft/vcpkg/tree/master/ports)! CMake has [151 find modules](https://cmake.org/cmake/help/latest/manual/cmake-modules.7.html), which do not follow a sane naming convention, and not all of them have targets and so on. With the upcoming `CMAKE_FIND_PACKAGE_PREFER_CONFIG` you can have something like: find_package(PNG REQUIRED NAMES PNG Png png) target_link_libraries(main PRIVATE PNG::PNG) Which will try to find the CONFIG package with those names, or if not found, the MODULE package. Unfortunately the target names are case sensitive, and the suggestion to have [Case insensitive targets](https://gitlab.kitware.com/cmake/cmake/issues/19287) is not going to happen: &gt;There is a lot of internal logic in CMake that assumes target names are fixed strings. Switching it all to case-insensitive handling will be quite difficult and likely slower at runtime. I'd really rather not offer case insensitivity. Even if we did it wouldn't fully solve the problem because packaging systems could disagree on spelling of target names in other ways. &gt; &gt;There could also be packages that already try to provide multiple case variants. &amp;#x200B; Portable package management in CMake is not that simple at the moment.
Can you elaborate in terms of C++. I get that there would be architectures where you cannot do 8 byte additions, but doesn‚Äôt standard say that char‚Äôs need to be min 8bit and sizeof(char) is 1. In that setup you could use 16bit registers and still have a char type as far as the language is concerned.
This article takes the subject somewhat to extreme, but I can confirm that `cmake_paths` fits very nicely into an already working `fimd_package()` scheme - provided your Conan recipes can build libraries in the same configurations your project uses. We are currently porting our project from old custom buildsystem to Cmake, and on Mac it turned out to be much easier to use Conan for dependency management. Lokking forward to mirating to it on all supported OSes ^.^
Why would we need `constexpr` bind when we have `constexpr` lambdas? It'd be nice, sure, but definitely shouldn't be blocking.
Caught between the Scylla and the CHAR\_BIT?
I personally have had a hard time deciding whether this "intentional choice" is good or bad. The job of a higher level language is to specify how a program behaves while abstracting the machine details, and it is the job of the compiler to generate efficient code given the intent of the source code. I would prefer a world where every integer type is the same number of bits regardless of machine architecture, and should be up to the programmer to pick the integer with the right number of bits (which have to do anyway in the real world).
Not unheard of in the embedded world.
Maybe (in retrospect) `fstream`'s destructor should abort on an error rather than swallowing it. Not too different from how `thread` aborts if you don't either `join` or `detach` it before destroying it. An exact parallel would be aborting if `fstream::close` hasn't been called.
Haha, yeah but it's hard to beat for control system microcontrollers
It's costly to construct boyer-moore-horspool for every searching. Typically we init a searcher with a search term then use it to perform multiple searching.
The 8-bit processors I'm most familiar with cheat by having instructions that use a pairs of 8-bit registers like they are a 16-bit ints. I don't really know if that was how all of them worked
Thanks -- that was intended to be covered in the first option, I've added a couple of words to hopefully make it clearer: &gt; 2. Before doing this test, what was your expectation about how well the program handled allocation failures? &gt; &gt; o My program was not expected to handle allocation failures at all, *&lt;ins&gt;it exits immediately and&lt;/ins&gt;* at most it installed a new_handler and/or terminate_handler &gt; ...
Fixed, thanks.
If you have to worry about the value being negative, don't you also have to worry about the value being 4294967292?
Still, isn't that the reason we now have all the confusion with the unsigned vs. signed size types \[e.g. 1\]? C/C++s behaviour can sometimes be really counterintuitive, which is really dangerous especially since most of the time the behavior is intuitive. &amp;#x200B; \[1\] [http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p1428r0.pdf](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p1428r0.pdf)
That certainly used to be the case, but things have changed and continue to change. The `cmake_find_package` generator creates a Find Module that is not contained in the package. It is the same template for every package, filled in by information from the Conan recipe. Every Find Module generated by `cmake_find_package` exports a target. The `libpng` package, for example, will export the `libpng::libpng` target. (By the way, the PNG package you linked for Conan is not the preferred one; [this one](https://bintray.com/bincrafters/public-conan/libpng%3Abincrafters) from Bincrafters is.) Bincrafters has emerged as the leading contributor of Conan recipes. They have [481 repositories](https://github.com/bincrafters); not all of them are packages, but the vast majority are. If one wants to support *multiple* package managers at the same time, I agree it is difficult due to inconsistencies in names of Find Modules, Package Configuration Files, and targets. It can be addressed with aliases (`NAMES` for the `find_package` command, and `add_target(ALIAS)`).
That Frankfurt position is closed. Do you plan to have C++ positions open in Germany again soon? Thanks.
It's actually true in a few ways. Learning a bit of Rust has made my C++ somewhat better. (But then again, C++ Core Guidelines probably is more influential)
Good to know that Bincrafters 396 packages. From their [PNG](https://github.com/bincrafters/conan-libpng) and [Freetype](https://github.com/bincrafters/conan-freetype) examples I don't know if they support targets. Unlike variables, a missing target in CMake will generate an error.
Hi, do you plan to have open positions for Linux C++ programmers within Europe? Thanks.
I have so much to say about this topic since I've been trying to teach this dichotomy to undergrads for the last 6 years. Unfortunately, I'm in my phone, so I'm not going to type it all out. Remind me tomorrow.
But those instructions still run slower than the real 8-bit alternative.
 Dead on arrival, what a waste of time and effort, why do i still have to be bothered with 2 different files AGAIN
The auto . to -&gt; is built-in VS. I just verified it works to make sure
The good news is that you don't have to inspect their source code to see if they support targets. You can check whether they publish a Package Configuration File, but if they don't, then the `cmake_find_package` generator in Conan will *generate* a Find Module that exports a target. Always. The generated Find Module *always* exports a target. If the package is named `xxx`, then the generated target will be named `xxx::xxx`.
Nice thank you :)
Can you update us about your progress so far ? How do you find the program?
&gt; The rules are well defined, even if they are implementation defined and not universal "Implementation defined" is literally the opposite of well defined‚Äîit *means* that the language *does not define it.* But even if every bit of it was completely spelled out in the standard, a formally standardized tangled mass of spaghetti is a tangled mass of spaghetti nonetheless. &gt; so "no one know the type of char + char" is still misleading. No, it isn't misleading, it is *a statement of fact.* The answer to the question, "what is char + char?," is unknowable without knowing the compiler's implementation. That's just a brute fact. In other languages, it is exceedingly unusual to have to dig into the internals of the compiler implementation to know how to write programs. With C++ we have Compiler Explorer. &gt; Does it mean I can't know what happens on the architecture I'm targeting? Of course not. In principle, it could indeed mean that, as the compiler is free to do whatever ludicrous nonsense it wants, "magic" as you put it, so long as it stays within loosely defined bounds of the standard. If I sound combative, it's only because of the inadequacy of text as a medium of communication. I am actually enjoying our conversation. Even if I am unconvinced, it gives me the opportunity to think through more carefully why I think the way I do, which I think is an important exercise for all our beliefs. Cheers!
It's not about the current architectures. It's about legacy decisions that made sense/felt right at the time. When C was originally developed for PDP-11 there was basically just an `int` type (well, also pointers), hence it was easier and "made" sense to have everything just implicitly done on `int` (especially since there was no efficient way to access "byte" from a register). That's why you could just omit types and something like ``` main(argc, argv) { return 0; } ``` was a perfectly valid code (it sill compiled btw).
&gt; So yes, if you set up a situation that relies entirely on implementation-defined behavior, it's going to be implementation-defined behavior. This is the author's point, in my reading. That the language doesn't define what function is called *is* bizarre, even if we're used to it, even if it's well-known. &gt; This is called "knowing the programming language you're using." Accusing your readers of cheating for knowing a relatively basic feature of the language... No, you *don't* know what function is called on your platform for that reason. In fact, the whole point is that you *cannot* know what function is called *because you know the language.* The reason you know what function is called is because you know what your specific compiler implementation does. Which is fine, and if you're happy with that, then there really isn't a problem. But it isn't a feature of the language at all. Rather, it's completely undefined by the language, which *is* unusual, even if we are used to it. I personally didn't interpret that part of the article as accusing his readers of cheating, but then again most C++ programmers I know would be surprised by the answer to the question, which likely colors my perspective. You and I probably run in different technical circles. At the very least, we can see that enough C++ enthusiasts find the article compelling enough to upvote it to second from the top of r/cpp with 81 upvotes. Cheers!
One more question then - where in C++ (or maybe C) standard can I find wording that prevents the type of char+char from being char? Just so I know for the future.
For "common" platforms it is int -- and that probably includes mainstream STL implementations btw -- so there is a shitload of code where you can just pretend it is int, without it causing any issue ever. If you target an uncommon platform that is exotic enough that CHAR_BIT is not 8, I really hope you know it...
(Note that I'm not a hiring manager.) It's unlikely, given that Ian's posting is Redmond/non-remote. However, in my personal opinion, almost everything is negotiable if your qualifications are strong enough. It may also be possible to find a different team in DevDiv that's looking for someone with your background. I'd recommend searching the Microsoft Careers site, and if your background is highly aligned with compiler backend work, also go ahead and email Ian anyways (tell him I told you to, and that the secret password is "meow").
Doing a couple of searches it looks like the only 8-bit processors with this feature were the Intel 8080 and Zilog Z-80. I imagine that would make other 8-bit processors a poor Target for a Few compiler.
There is plenty of info on this topic on [SO](https://stackoverflow.com/questions/4814668/addition-of-two-chars-produces-int).
Why are you getting down-voted???
And the Motorola 6809. The odd man out here was the Motorola 6502, which only had a single 8-bit accumulator.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/bsnqz6/uninitialized_memory_error/eoon6bq/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
One way to figure this out could be looking at style guides and patterns for languages that utilize this type of chaining, such as Javascript. One popular method is pretty similar to yours, but the first `.then()` is put in the first line. I've seen this style used around and used them myself, but I couldn't find a single style guide that directly recommends it for more than 1 "then". What seems to be a popular one is breaking the line before each `.`, with an extra step of indentation (jQuery, AirBNB, Google). An example of how these two usually work together (first one for 1 method, second one for longer chains) could be seen with the [Express.js routing examples(https://expressjs.com/en/guide/routing.html) (down in the app.route() section). Personally, I like the readability of the first one for multi-line and the second one's for single-line ones (don't like the clutter of `})` in one line, followed by another line with `.then`, but, at the end, just like any coding style guides, just choosing something reasonable and sticking with it should be enough.
Although it's by no means a full substitute, I use fastfind as a substitute for visual assist's shift+alt+O quick find. It also searches for text in files in addition to filenames. It has a free 30 day trial and is fairly cheap (around 15 euros IIRC).
&gt;Clearly C wasn't designed for 8-bit machines. So what, we're just supposed to program our Arduinos in assembly?
To clarify, say you have option "--foo" with a string value and option "--bar" with an integer value, and the command-line is: program --foo "" --bar 0 Can the code tell the difference from a command-line with no (i.e. null/unspecified) options? Another fun sub-command case is what if "--help" goes after an invalid sub-command? Does it show genera usage help or "invalid command" error? program invalid-command --help
I would answer this with "Yeah, I don't have the entirety of the standard memorized to the letter, I'd have to google that and get back to you."
I second this. Have been using fastfind for the last few years and it replaced visual assist for me. Sure it doesn't do semantic stuff like finding symbols, but I can rely on intellisense for that if I really need it. But honestly having an immediate find in files is a game changer in a large codebase.
I think you have that backwards. C does not have function overloading while C++ does.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/bsp711/key_value_stores/eoowz5e/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Hypothetical port to the hypothetical popular platform.
Having worked with both sides, I'd take a Cortex-M4 over C28x *any day*
I didn't knew that Windows has stopped being popular among consumers. All new APIs are UWP only and that isn't going to change. Even React Native for Windows is being rewritten on top of UWP.
I think you're confusing "undefined behaviour" and "implementation defined". Undefined truly is "magic" and anything could happen. If something is "implementation defined, you don't need to dig through the compiler's code to find out the answer, as the documentation of your compiler is required to specify these things, so you just have to read your compiler's documentation. Besides "undefined" and "implementation defined" the standard also recognizes "unspecified" which is somewhere in between. It's not "undefined" in the sense that your program is still considered formally correct if it exploits "unspecified" behaviour. On the other hand, with "unspecified behaviour", the compiler's behaviour can be influenced, by potentially seemingly unrelated things. &amp;nbsp; Fundamental variable sizes were always "implementation defined". &amp;nbsp; &gt;&gt; so "no one know the type of char + char" is still misleading. &gt; The answer to the question, "what is char + char?," is unknowable without knowing the compiler's implementation. &gt; it is exceedingly unusual to have to dig into the internals of the compiler implementation to know how to write programs. Like I tried to explain above, you're not supposed to dig into the compiler's code. Though you are supposed to read your compiler's documentation if you want to know things like "what's the size of `int`". &gt; In principle, it could indeed mean that, as the compiler is free to do whatever ludicrous nonsense it wants, "magic" as you put it, so long as it stays within loosely defined bounds of the standard. This is what made me thing you're confusing "undefined" with "implementation defined".
I stopped using PCH and just use the multi-file build scheme with VC++. I just start one instance per CPU minus 1 to leave one free so it doesn't make the machine too sluggish. I found that PCH would basically work, but occasionally something wouldn't go right and something wouldn't get rebuilt and I would waste hours and hours trying to find a bug that really didn't exist.
Do you have any reason that you want to treat .then() specially? I would treat it a normal chained function call, then you can use any existing code style. So your sample code is just: 1. two chained calls to .then(). So apply chained call style here. 2. each .then takes a lambda as the parameter. So apply lambda parameter style here. In my style, I may write that as, auto my_promise = foo().then(blah blah).then(blah blah); if it fits in one line. Otherwise, auto my_promise = foo() .then(blah blah) .then(blah blah) ; if it's too long to fit in one line.
Just because it's the easiest language to use doesn't mean it's perfectly suited - as mentioned above and in the article most arithmetic operations in C promote to 16 bit ints and end up doing a lot of potentially unnecessary extra work on an 8 bit CPU. The only way to stick to the 8 bit register size is to cast back to 8 bit after every operation in a calculation!
In case of 8 bit machines, the right data type needs to be used and if you really want an optimized binaries, always inspect the assembly listing and look for the compiler optimization options. Even with that, compilers have different implementations (e.g there are compilers that will treat unsigned int as 8bit unsigned char). C has been used for decades for embedded world for 8 bit products. If the assembly output is very inefficient, the fallback is to use inline assembly for further optimization although nowadays that is very rare since the compilers for most embedded systems had matured a lot.
It's a little ridiculous that so many platforms have char be signed when they use an 8 bit character set where the values of the characters officially go to 255...
To me it always felt more as a research group implementing new techniques. i've never tried to use it, hence can't really comment on the quality for production use.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/bsrkt2/help_and_advice_with_my_makefile/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
From time to time someone picks up the pieces and rebases it.
I have done so in the past but not for the current bugs I think. Sure, guess I'll do that later today.
The entirety of Boost is designed based on the assumption that the STL is good.
4 months later.. any news? :)
char are not intended to be used in arithmetic operations.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/bss3h2/help_me_explain_array_private_member_in_class/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I'm thinking I said something really stupid to c+- veterans, but no ones took the time say what it was; so it must be so dumb they don't even bother. That's what I'm getting out of it anyway.
It depends on whether you are using operator[] into an array, or operator+(type*, char). In the first case, you likely get something past the ended of your buffer. In the second, you get something before your buffer. Neither good, but still distinct situations.
Can you elaborate on the 36-bit?
In both cases you described, since it's storing "" and 0 into variables, you can test if it's set to "" and zero. If all the options you provide look just like the default values, then there is no reason to care. It's why gcc doesn't crash when you provide "-o a.out". I don't see why this matters. The error you described with the invalid subcommand is indistinguishable from providing the program with a standard argument (i.e. 'cp invalid-command location' will try to copy invalid-command to location even though it's intended to be a subcommand.). The library, as it stands, will only set variables and run subcommands (however, I'm also going to allow you to run functions in a later edition). Since I don't force you to use any flags nor do I feel it necessary to crash if you get extra arguments, it's up to you whether or not it will display help or detect an invalid command. You can look in the test programs for example usage.
Headline is **at best** only applicable to specific situations. Introducing precompiled headers on a multi million line code base reduced compile times overall by multiple hours (out of build times measured in days)
Headline is **at best** only applicable to specific situations. Introducing precompiled headers on a multi million line code base reduced compile times overall by multiple hours (out of build times measured in days)
Certain linters will
Intrigued, I tried to use PCH with one of my gcc/autotools projects. Observations: 1. It takes longer to compile the headers than it does the whole project (8.5min vs 7.25min) 2. Each PCH needs \~50MiB 3. It doesn't make any difference to the final compile time (actually it increased a bit: 7.4min vs 7.25min) I think the OP, and especially the top title, is way too generalised; it only applies in the author's particular environment and not generally to any C++ compilation.
This is the right answer. Adding two characters should be an error.
It's like pointers, right?
Thanks!
Pybind11, simply the best c++ to python wrapper
What's surprising about this comment is that you know about smart pointers which are C++11, but don't know about overloading which is pre-C++98. On the other hand I learned lambdas before I understood iterators.
I assume you're avoiding answers such as mine, but it might help others.. TheCherno is pretty good.
My code isn't written for platforms with 16-bit chars, or 32-bit chars, so I don't have to worry about them being over 255. I mention ints because of functions like `isspace().` I dabble in Unicode, and C++ support for that is so poor that I felt I had to use my own types and not use `L"string"` etc.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/bssrwj/help_setting_up_c_development_in_visual_studio/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I would be surprised by a 16 bit char in an embedded system. Can you name one?
https://en.cppreference.com/w/cpp/language/implicit_conversion Read the part about numeric promotion.
There is [https://github.com/mikael-s-persson/templight](https://github.com/mikael-s-persson/templight)
I'm not entire convinced that "following the CMake find module naming convention" is a selling point. Like you mention yourself, the Find modules that are part of the CMake distribution do not all follow the same naming convention or even have targets (some of them predate "modern CMake ", so it is understandable). CMake itself is [actively discouraging](https://gitlab.kitware.com/cmake/cmake/merge_requests/2087#note_413298) new find modules from being merged to CMake , for good reasons, moving the responsibility to the library maintainers themselves. So other than for legacy purposes and for a subset of common-use libraries, CMake upstream seems like a dead-end for newer libraries. The world outside CMake is not that much brighter either: for libraries like `glog`, you'll find all sorts of naming conventions. A quick google search gives me `FindGlog.cmake`, `FindGLog.cmake`, and then we have glog's own generated cmake-config configuration which is all lowercase. When it comes to target names themselves, there also isn't a set convention. OpenCV has `opencv_modulename` as an imported target, when these days one would probably expect it to be something like `OpenCV::modulename`. Qt on the other hand will start their target names with a capital letter, e.g. `Qt5::Core`. &amp;#x200B; So it does seem odd to claim that conan doesn't follow CMake naming conventions while other package managers do, when there isn't any convention to follow: there is not one convention that CMake themselves follows or advocate for (as this has evolved with time) and there is not one convention that library maintainers follow themselves with a reasonable degree of uniformity. &amp;#x200B; Now, from the point of view of being able to integrate conan into an existing CMake project without having to modify every single call to find\_package, sure, I think there is a valid discussion to be had. When integrating conan into a cmake project, conan exposes libraries in a number of ways: * `CONAN_PKG::PkgName_LibName` (using the cmake generator and instructing conan to set up imported targets) * `{name}::{name}` when using the find modules generator, where name is the name of the conan package (and both conan and cmake are case sensitive) Additionally, one can by bypass the ones above. Provided that one of the following are true: * The folder/file layout inside the package is the same that a pre-existing Find module would expect * The conan package itself contains a generated xxxConfig.cmake file (I presume we are not very likely to find these in public conan repositories if they fully rely on the `package_info()` logic in conan) One can use the `cmake_paths` generator (explained both in post by OP and [here](https://blog.conan.io/2018/06/11/Transparent-CMake-Integration.html), which sets `CMAKE_PREFIX_PATH`, and will cause cmake too look in those paths with higher priority. So one can *still* use both conan **and** the built-in CMake find targets and expect things to reasonably work, at least for packages like zlib, png and freetype. That's why I have the impression that the table above is not entire accurate/clear or is comparing apples to oranges, because if you rely on CMake to provide the upstream Find Modules, and on conan to provide you with the path in which to find these libraries, then conan does not intervene in the target names at all. We also need to consider that conan supports more integrations other than cmake. And while cmake keeps gaining lots of traction for C++ projects to the point where it is close to becoming the de-facto standard, I think it's reasonable that conan are striving to become as build-system agnostic as possible. There are in fact efforts to make "Library definitions" more agnostic: * [Common package specification](https://mwoehlke.github.io/cps/) * [Libman](https://api.csswg.org/bikeshed/?force=1&amp;url=https://raw.githubusercontent.com/vector-of-bool/libman/develop/data/spec.bs) I hope moving forward something like this gains traction!
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
The PDP-10. It is a very odd system - technically it has 36 bit registers, but the address bus is only 18 bit and so a pointer would actually be smaller than an int by the traditional definition. Also, it didn't have a fixed size byte, though 9 bit was common.
Yeah the rules actually sound an awful lot like the rules for pointers.
https://www.reddit.com/r/cpp/comments/bsflbt/noone_knows_the_type_of_char_char/eon102k
What about `uint8_t`? Same applies.
[Here is one](https://news.ycombinator.com/item?id=3112704)
I updated the times with pre-calculated BMH, KMP. Now BMH is the fastest searcher, except with strstr on Windows.
A terminal slows down printing (compared to `&gt; /dev/null`), maybe the OP is also timing I/O?
Both are release builds. On Windows and macOS, the times within Qt Creator and on terminal are more consistent and closer to each other.
https://github.com/shafik/cpp_youtube_channels
Unit tests. Instantiate the template for the expected types, maybe even for unexpected types, if you expect your template to fail compilation then (math matrix of string for example).
Thanks for this. I‚Äôm starting to look into containerized development environments. Your post couldn‚Äôt have come at a better time. Curiously, r/programming just had something similar using VS Code. https://www.reddit.com/r/programming/comments/bsn5i9/visual_studio_code_remote_development_may_change/?utm_source=share&amp;utm_medium=ios_app
I know [Cevelop](https://www.cevelop.com/features/#templator) has some template visualization features, but I haven't used it personally.
I have tried `templight`. It provides ways to inspect the instantiation of template. However, its output is not enough pretty. Thank you for your sharing.
Unit test is a good choice. But it's suitable for a built program. If a template program could't be built, I need other tools to help me to work around the instantiation of the template.
I wrote my own little library that produces compile time strings for every template type that I am working with so that at least I can verify that the instantiated types are correct at any given point in the code.
Been using the library on a few personal projects for a bit the last few days, and I'm really finding it quite enjoyable to use. I'm just wondering though, what use case did you have envisioned for `entt::resource_cache`? More precisely, why does the cache only support returning shared\_ptrs via `entt::resource_cache::handle` and is there any reason for only returning const references as opposed to mutable references?
And a lot of template code can be checked with static_asserts that don't even require you to run any tests, just see if the file compiles.
I'm glad to hear this. I invite you to join also the gitter channel if you've any question. The cache supports only shared ptrs because it's literally an intermediate step towards a model backed by custom allocatiors (where naked pointers will be managed directly from handles). The current API won't change (but for the loader probably) and therefore I'll be able to switch to a new version without an impact on my codebase. Mutable references are already on master instead, most likely part of v3.1.0 :-)
I agree with you, but the fact that we need to declare the signedness of the char is itself rather silly. Does there even exist any character set with negative code points? On the one hand we say that char doesn‚Äôt mean bytes. On the other hand we say that char also doesn‚Äôt mean character‚Äîcharacters only make sense in the context of an encoding. So what is char? A historical artifact we still have to use for important things. I totally agree re: indexing into an array. I occasionally use this as a poor man‚Äôs hash and have to spend way too many brain cycles making sure my engineering is correct. This speaks to the larger point that I am trying to defend: the C++ type system has a lot of flaws that make it exceedingly challenging to work with and is the source of innumerable and often subtle bugs. Half of Meyer‚Äôs Effective C++ books is about the type system and the other half is about memory management. (Not that I‚Äôve counted, just speaking rhetorically.) The flip side is that the type system (and memory model) is also powerful enough to be used for good instead of evil.
Ha has this one always been for free?? Somehow I totally thought it wasn't.
Cool, makes sense to me. Thanks for the quick reply.
Then you should indeed try [https://www.cevelop.com/features/#templator](https://www.cevelop.com/features/#templator) as suggested here.
Here is your today's reminder :)
Good for you. BTW, you could increase length of a term to 9 or greater, to see if it make difference. That probably prevent the optimization of strstr.
&gt;All new APIs are UWP only and that isn't going to change. Time will tell if that's not going to change. &gt;Even React Native for Windows is being rewritten on top of UWP. Just like Xamarin supports UWP and it is still a target nobody gives a damn about. &gt;Apparently some people still don't understand that UWP goes beyond a couple of store APIs. True. Now tell me why LibreOffice is going to be ported to UWP if they do not care about the Store?
What exactly do you wish to debug ? For example, if you intend to see what function you are in (be it a standalone function template instantiation or a class template instantiation method), you can just print the stack trace, template instantiations have their name composed from the name of the template and from the types the template was instantiated with. If you want to break in the `std::swap` instantiation for ints, the stack trace would have an entry with the method `std::swap&lt;int&gt;` or something similar, depending on how exactly the template looks like. This naming also appears in assembly, I think, the same as when jumps are made to functions. It is certainly useful.
&gt; If a template program could't be built Are you saying your code doesn't compile?
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
HPX for us is going to be a core piece of technology. We're an advanced hobbyist group (some of us are professional developers) trying to develop a multiplayer game with a scalable server (MMORPG style, no sharding, single world). HPX takes a lot of complicated stuff away from us we have discussed internally earlier, like taskifying everything, massive leverage of parallelism, asynchronous, event driven programming model, moving of objects between machines/regions etc. - many things. An alternative would have been Spatial OS (The "Rolls Royce"), but they do charge at some point, which for us is not an option, because we have not decided if and if yes when and how to monetize, so we can't really use anything which will cost at some point. And HPX feel like the "Mercedes" - totally good enough for us. I'm extremely happy we found HPX, though we are still at a beginning. The guys in the IRC channel are very helpful when questions come up and it feels like a good community to work in.
I updated to a longer string and a longer search term with 17 chars. strstr on Windows is now 3x faster than BMH.
The London University Ferranti Atlas computer was 36 bit but was before the time of C. Also the G-345, IBM 7090 and 7094 had a 36-bit word size, 15-bit addressing, and 6-bit character encoding, but again, I believe they were also prior to C. My understanding, which may be incorrect, is that C began on the PDP-11, which has a 16-bit word and uses 7- bit ASCII. It was then ported to the Burroughs B5000, which has a 48- bit word size.
Didn‚Äôt C start on the PDP-11, which is 16 bit? These is this oddly fascinating book called Coded Character Sets: History and Development by Charles E. MacKenzie (1964), which catalogs the development of the different charact sets and why they are the way they are today. I believe the PDP-11 was ascii base, but I‚Äôm not sure.
`static_assert` is a good choice to check instantiation when the file compiles
Yes. Maybe we need to fix the template instantiation bugs for complex templates when compiling.
Could you share your own library with me? Or just describe the idea what you did.
&gt; Am I missing something? Maybe check this out. Could have something to [do with this](https://www.reddit.com/r/cpp/comments/bs0p9u/the_biggest_problems_of_unit_testing_with_c/eoiib83/)
Yeah, that was a bit of a coincidence. Containerized development must be in the programming zeitgeist.
I believe what you're looking for is something akin to Visual Studio's [Template IntelliSense](https://devblogs.microsoft.com/cppblog/template-intellisense/). You can provide sample template argument and your source code will highlighted with all the syntax error that you would get if you had manually replaced all instances of the template parameters with your sample arguments.
Does the Promise support co-routines? Maybe Co-Routines as implemented in C++ could make the code easier to read Something like int a = co_await foo(); int b = co_await bar(a + 1); This could probably end all debates and issues? (I am rather new to Promises and am trying to read up on async as much as I can but I think similar libraries like Microsoft's PPL and C++WinRT supports usage like this instead of then() chaining.)
Hmm, I'm not sure.
C started on the PDP-11, but AFAIK there was a compiler for the PDP-10 as well
 I agree that \`co\_await\` eliminates the issue, but we are using C++17. &amp;#x200B; BTW, I wonder why the keyword couldn't just be \`await\`.
Pointers are nullable, so you can have "optional" parameters if you use pointers. null references aren't legal. Also, in C code it's common to pass a pointer and a size for arrays. With pointers you can directly use the syntax p[i]. It would be strange to use references for this purpose. Other than that I guess it's up to personal preference, but some might say that using pointers rather than references (especially pointers to non const) makes it more obvious when you are mutating something.
&gt;BTW, I wonder why the keyword couldn't just be await I think it had something to do with CoRoutines having 3 types 1. await 2. yield 3. return Return as we know it is already a keyword so they decided to introduce co\_return as a Keyword and renamed await and yield to `co_await` &amp; `co_yield` for consistency. Initially I think MSVC implemented it as `await` &amp; `yield` before the changes. I remember reading about it on VS's Blog and on /r/cpp as well. (I could very well be wrong though! Maybe someone more involved with the Standards or Compilers like STL or Gor Nishanov might know better)
You could try wren.io It uses some nice tricks to beat other scripting languages for various tasks.
Many do because passing by reference is ‚Äúinvisible‚Äù at the call site. While taking the address of a thing isn‚Äôt.
I would not dismiss JavaScript. Projects like ChakraCore or V8 are easily integrate-able into C++ projects and come with bytecode, JITting, etc. out of the box.
I'll check it, thanks!
1. Because pointer are iterators. It is possible to use a pointer to an element of an array to iterate over its siblings. 2. Because pointers are nullable, while references are not. This makes it possible to have an optional argument. 3. Because the API is used for cross-language calls, and is therefore limited to what is available in C. C does not have references. Most languages are able to call C API, but not able to call C++ API. The C API can nevertheless be implemented in C++. If you we need neither 1, 2 nor 3 but do need indirection, then we usually use a reference. About nomenclature: `&amp;` here is not an *operator*. This is important, since there are `&amp;` operators in the language, which do something unrelated to references.
The way I've seen recommended and what I usually do: void foo(type* inOutVar); &lt;== pointer when using optional input / output variables Passing a null in this case says I do not care about this and do not try to send me anything. void foo(const type* inVar); &lt;== pointer when using optional input variables void foo(type&amp; inOutVar); &lt;== ref when using non-optional input / output variables void foo(const type&amp; inVar); &lt;== const ref when using non-optional input (specially when object is expensive to copy) void foo(type inVar); &lt;== When the object is cheap to copy. I usually do this for native type or object of sizes comparable to the size of a pointer
16.2, a preview that includes the tool should be out quite soon. Maybe there is even a Nuget package that you can download earlier, have to look into that.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
This seems like a reasonable way forward. The TM TS has the fatal flaw that it bifurcated function types (just about every C/C++ system that pursues such methods runs into trouble). If I skimmed the paper correctly, this proposal removes that bifurcation.
WRT &amp; not being an operator. I get what you mean as that'd be a bitwise-and... But i know it as the "address-of operator". What is the correct nomenclature?
I'm not very good with Assembly and below, but I think the upper 32 bits are zeroed when you write a 32 bit value to a 64 bit register. Does that help with this problem?
There are two `&amp;` operators. The binary `&amp;` operator is biwise-and and the `&amp;` unary operator is the address-of operator. `&amp;` here is part of the type name and denotes that the type is a reference. I don't know if there is a technical name for this. It's just part of the grammar.
You could take look at [Huginn](https://huginn.org/) although I am afraid it can have the same performance problems as *chaiscript*.
I agree, I don't think `std::ratio` would be a direct fit. But its API (and those of other libs, like the mentioned *nholthaus/units*) is interesting and could lend itself to *vivid* as well. However, I wasn't able to step into this easily (as u/parnmatt said, the API and implementation probably would need to be thought about a lot). And so I went for another strong typing paradigm for now, which is out with `v2.0.0`! It's a good start I say :).
Done and included with `v2.0.0`! Probably could use some more involved cpp-magic, but I think it's a good start. I kept the `Color` class high-level and easy-to-use with implicit constructors, while the low-level API uses strong types all the way through. I.e. the compiler now throws errors when you e.g. try rgb_t col1 = { 1.f, 0.f, 0.4f }; hsl_t col2 = hsl::fromHsv( col1 ); // [...] error: no viable conversion from 'vivid::rgb_t' to 'const vivid::hsv_t' Yeah \\o/.
Thanks for the hint
That is correct. I assume you mean async calls for the client interfaces, right?
Huh. Nice to know!
Damn. More you know, eh?
The main reason is probably that `new` (and thus `make_unique`) might throw `std::bad_alloc`, and the compiler can't make many assumptions around that. When `malloc` fails, it just returns a null pointer. If you're ignoring everything `malloc` returns, the compiler can easily optimize that function call away.
Post links to example code on compiler explorer (https://godbolt.org/)
There's always the nothrow versions of new, though I don't know how to use them with std::make_unique()
iirc the nothrow version is just new in a try/catch
`try`/`catch` didn't do anything clever, it just added a few more instructions for the `catch`. https://godbolt.org/z/EIVDAh `std::bad_alloc()` occurred to me as the reason why this happens. That's definitely the reason why `std::string` wasn't optimized out. However, why is clang optimizing `unique_pre`? https://godbolt.org/z/2Lt2AL Also, standard specifically allowed allocations to be elided, though I'm not sure if it is allowed under the "as-if" rule or are there some special rules. Coroutines are heap allocated, but compilers implement "Heap Allocation eLision Optimization".
Maybe they don't do that, because they assume that the constructor is not known in the compilation unit and thus nothing about possible side effects is known.
I went through the same process, and settled on [AngelScript](http://www.angelcode.com/). It's like Chaiscript, but without the performance problems. It is easy to integrate, shares a great deal of syntax with C++, runs efficiently, and gives great errors and warnings. So far I'm very happy with it!
i mean, unless they rewrite the whole thing in c++ i don't see things getting better...
Clang results are beautiful: [https://godbolt.org/z/2Lt2AL](https://godbolt.org/z/2Lt2AL) &amp;#x200B; Also take a look at MSVC with full optimizations: [https://godbolt.org/z/NDH0Jb](https://godbolt.org/z/NDH0Jb)
But it's a `char`. Compiler definitely knows everything about `char`.
I know. As for MSVC, I thought that was just my unfamiliarity with its flags.
That's the next thing I was going to check, if clang was smarter than GCC. Looks like it is. I do wonder if there's a gray area around the optimizer pretending `new` will never throw. Most people writing dodgy C++ assume it *doesn't*, though, not the other way around!
Still same code even with `new(std::nothrow)`.
Right. What I wanted to say is that the heuristic they use may skip new, because they assume it is not possible most of the time. But by that also miss those low hanging fruits.
If `new char` throws you're in trouble. Exceptions are heap allocated and what happens if you try to allocate `std::bad_alloc` with not a single byte of heap available? That's why (at least) gcc implements a special section of the binary to allocate possible `std::bad_alloc` objects. This is Herb's argument in P0709 for having allocation failures result in `std::terminate()` instead, at least by default.
Yeah, I got your point the first time. I'm saying that if a compiler assumes that it should essentially be considered an optimizer bug.
I wouldn't be surprised if this is on the table for GCC, but that the work to implement it simply hasn't been done yet. It was only a somewhat recent development that eliding `new` became allowed in the first place.
Optimizing away \`new\`/\`delete\` is allowed by in C++14 (\[paper\]([http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2013/n3664.html](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2013/n3664.html))), in more complicated cases, and regardless of \`bad\_alloc\`. Probably \`gcc\` did not implement this optimization yet.
&gt; Besides "undefined" and "implementation defined" the standard also recognizes "unspecified" which is somewhere in between. I knew about undefined and implementation defined, but I don't recall unspecified. A quick googling yields this language from the C++ standard: &gt; 3.4.1 1 implementation-defined behavior unspecified behavior where each implementation documents how the choice is made... &gt; 3.4.3 1 undefined behavior behavior, upon use of a nonportable or erroneous program construct or of erroneous data, for which this International Standard imposes no requirements... &gt; 3.4.4 1 unspecified behavior use of an unspecified value, or other behavior where this International Standard provides two or more possibilities and imposes no further requirements on which is chosen in any instance... So implementation defined must be documented, and unspecified apparently may or may not be documented but must fall within the range of possibilities delineated by the standard. I guess that makes sense.
Great news!
If you like Python, you could take a look at [cppyy](https://cppyy.readthedocs.io/en/latest/) which lets you directly wrap C++ code or [Cython](https://cython.org) which lets you write glue code in a Python subset.
It's not very beautiful, but it works in GCC, Clang and MSVC: https://godbolt.org/z/KB1KSL void* operator new(std::size_t count) { return ::malloc(count); } void operator delete(void* ptr) noexcept { ::free(ptr); } void operator delete(void* ptr, std::size_t) noexcept { ::free(ptr); }
You can declare a template class without definition like this template &lt;typename... Ts&gt; struct show_type; And then in your template code you can try to instantiate this with a type you're interested in. It will lead to a compile error and the error message will show you the concrete type.
sounds promising, i'll give it a try!
https://developercommunity.visualstudio.com/content/problem/301214/newdelete-pair-optimization.html
Interesting even though you can't really replace the global `operator new` with this. You implementation seems to work only for trivially constructible and trivially destructible non-array types.
We live in different worlds, around me lots of corporations do care about Xamarin. I guess it all depends if LibreOffice cares about using modern Windows APIs, or is happy being stuck with the legacy Win32 ones from Windows 7.
5 years is new?
Keep in mind that operator new can be replaced globally. Could do anything including side effects. But looks like they explicitly allow it now via N3664 to legalize clang's behavior.
This seems to be already reported (at least 4 or 5 times), here are two https://gcc.gnu.org/bugzilla/show_bug.cgi?id=78104 https://gcc.gnu.org/bugzilla/show_bug.cgi?id=23383
You‚Äôre essentially right. `co_return` has a subtly different meaning from `return` and `yield` is a fairly common identifier (used as a standard library name, even). So after some bikeshedding we decided to uniformly prefix all three related keywords.
I usually hold that coffee that doesn't compile isa failed test. The whole idea of unit tests is that you can isolate this template and test it for various scenarios, without getting bothered with other *units*. If your template cannot be initiated for unit testing without other code failing to build, your coupling is too tight.
I eventually settled on flatbuffers!
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
I thought I posted this in Cppquestions.. Omfg sry.
Huh? Why do you think that?
What's the issue, as you've said bad_alloc is special-cased (or is it not in other compilers? )
It's a missed optimization, not a bug.
Summary: MSVC knows they just don't care.
This should really be a warning, not an optimization...
Because the default `new` invokes the constructor and `delete` invokes the destructor, while `malloc` and `free` don't. Furthermore, `operator new[]` and `operator delete[]` overloads are missing.
It doesn't have to be special-cased, but a more serious problem is hardening your code against heap exhaustion is made even harder than it would be if exceptions were not dynamically allocated. Stack unwinding may or may not allocate more memory, which depends on the CPU architecture and (probably) the compiler. MSVC handling of exceptions involve multiple copies from stack to heap and back. Thus, if `new char` fails, you may not have enough memory to unwind the stack.
I said somewhat recent and I stand by it. As far as C++ goes, calling C++14 somewhat recent is accurate to me.
A missed optimization is a kind of bug. Otherwise having a compiler that implements flags like `-O3` and `-Og` but doesn't actually support any kind of optimization would be "fine" and you wouldn't be able to raise a bug report about it.
Why? Even if the allocation has side effects, if the compiler can optimize it away why would that be a bad thing?
Awesome! Just one question that popped into my mind: why are there no conversions between RGB and sRGB? Is it because they cover different parts of the spectrum or something or because you lose precision? I would think that converting between the two is a very common use case which is why I'm asking. Or maybe I'm just misunderstanding the documentation. Cheers ;)
Right, we don't implement this particular temporary allocation optimization at the moment. /Ox is not full optimizations, /O2 is. MSVC++ /O2 ~= GCC /O3 (in terms of what the switch is supposed to do). (I don't mention clang because they follow both switch forms depending on the entry point ;)) You get identical output for all 3 forms with `/Zc:throwingNew`: https://godbolt.org/z/1ic3UI Also note that our assembly listing includes inline functions that the linker will throw away, /Zc:inline was added to prevent those from getting emitted in the .obj, but the assembly listing wasn't fixed up for that, so it often looks like we emit a lot of extra spew but that doesn't end up in a resulting binary.
Overloads of operator new and delete do not invoke constructors or destructors.
Because the likelihood of it being unintended is extremely high. Why would you even write something like that?
Because optimizations should only make a program go faster, they should not turn a correct program into an incorrect program or vice versa. Say this function got inlined into 2 other places, and in one case the optimizer "fixed" it and in another case it did not. You'd be tearing your hair out looking for that memory leak forever
This does not comply with the requirement to throw an exception on allocation failure.
Are you saying that the compiler wouldn't optimize away a corresponding delete? I don't understand why that would make the program incorrect.
&gt; Otherwise having a compiler that implements flags like -O3 and -Og but doesn't actually support any kind of optimization would be "fine" and you wouldn't be able to raise a bug report about it. ... There's a huge difference between all and nothing. &gt; A missed optimization is a kind of bug. Then every compiler out these is filled with thousands and thousands of bugs. It's not feasible to eradicate every missed optimization, some of which are hard to implement and are only for rare cases. I'd rather see optimization work done in common code.
Hmmm I read this as initially as malloc/new without free/delete and compilers removing that. :sigh:
Well still, if the compiler removes a memory leak for you, all the better. :)
Right, what I'm saying is I don't think that's better. Not as an optimization pass anyway.
You're confusing the new operator with the new expression.
So only the `new` expression invokes the constructors? I thought that was the responsibility of the operators. Thanks for correcting me.
Right, that's why `/Zc:throwingNew` is a thing.
Appreciate the feedback! So, this is my take on it after digging into the topic over the last weeks - and I may stand corrected: RGB represents a triple of red/green/blue components. It doesn't really say though how those values are to be interpreted. Is it sRGB? Is it linear RGB values? Does it have some gamma correction applied already? As we mostly work with display colors, and sRGB has been the most widely used standard, it is often simply assumed that RGB == sRGB. Consequently, I use RGB as a general "RGB" container. The `Color` class works with sRGB internally. For some operations, it doesn't even matter what the working space actually is. For example HSV doesn't care about the "meaning" of the RGB values, it just visualizes and let's you work with them in a different arrangement. For instances where it matters, I'm being specific about what RGB working space is actually expected. E.g. the xterm color tables are stored in sRGB, which is why there is `srgb::fromIndex()` but no `rgb::fromIndex()`. Or XYZ, which has specific conversions from both sRGB and Adobe RGB, which have different color gamuts. But there is no `xyz::fromRgb()` as it wouldn't know how to interpret those RGB values. One can get lost in all the color theory very easily very deeply (as I found out ... ;) ). Luckily, color management is graciously handled by our operating systems, or in this case `vivid`, so that the user doesn't have to care if he just wants to get some god damn colors. With P3 and other wide gamut displays being more common now, this continues to be a very interesting topic. Maybe someday we'll have floating-point LAB colors as standard, who knows \*shrugs\*. For now though, I'm already happy if I can print a red heart in my console &lt;3. tl;dr * RGB is usually assumed to be sRGB, but can actually represent any RGB working space * The `Color` class uses sRGB internally, but for ease of use and not confusing high-level users sticks with "RGB" in its naming * I should totally clarify this in the readme ...
&gt;The whole idea of unit tests is that you can isolate this template and test it for various scenarios, without getting bothered with other units. If your template cannot be initiated for unit testing without other code failing to build, your coupling is too tight. Yes. It's what I'm looking for. Do you know any open source like this?
I want to show and inspect the instantiation process when compiling not after compiling. It maybe right to read the symbols on a elf file. But it's not easy for complex templates. We need to demangle the symbols.
There are infinitely many possible optimizations which a compiler could perform, and it is absurd to claim that failing to implement any specific one is inherently a bug. It would only be a bug if the compiler *attempts* to implement that optimization and it simply doesn't work. A non-optimizing compiler letting you pass `-O3` as an argument for compatibility with other compilers would not be a bug. gcc letting you pass `-O4` despite it not doing anything different from `-O3` is similarly not a bug.
&gt; /Ox is not full optimizations, /O2 is. It would be pretty cool to have things like that in the documentation about the options. [This](https://docs.microsoft.com/en-us/cpp/build/reference/o-options-optimize-code?view=vs-2019) could use something that says which one is "full optimizations." As it is, it's very technical documentation, with very little practical documentation (all what, no why).
I also disliked Lua, until I discovered the amazing [TypescriptToLua](https://github.com/TypeScriptToLua/TypeScriptToLua) project. Typescript is an amazing type-safe scripting language and the transpiler emits high-quality lua code. There are also many good C++ lua bindings that make embedding lua very simple.
I think you can't elide allocs under as-if, so it has to be (and is) explicitly allowed. This is because you can provide your own allocator with the observable side effects you want, and clearly elision will change those, so it does not follow as-if.
[sol3](https://github.com/ThePhD/sol2) is an excellent lua/c++ wrapper.
If you click the /Ox link from that page, it takes you here which recommends using /O2 instead. https://docs.microsoft.com/en-us/cpp/build/reference/ox-full-optimization?view=vs-2019
I'm in the program right now and I got it for $899. With that said, what are people spending their money on if $900 is too much for them? C++ will give you valuable lifetime skills. More than likely if you are learning C++, you will probably be a programmer in one of the various fields: 1. Embedded Systems/IoT, 2. Self-Driving Cars, 3. Video Game development, 4. etc. &amp;#x200B; You are capable of working directly with the hardware. The nanodegree program could be better though imo.
Are there any benchmarks on the transaction hardware in recent cpus?
It does. It also says, emphasis not mine, that "In some versions of the Visual Studio IDE and the compiler help message, this is called _full optimization_..." On the other hand, the [`/O1, /O2`](https://docs.microsoft.com/en-us/cpp/build/reference/o1-o2-minimize-size-maximize-speed?view=vs-2019) documentation doesn't say `/O2` is full optimization. You, somebody I'd happily give or accept as an appeal to authority in an argument about this, have said "/Ox is not full optimizations, /O2 is." Wat. Regardless, my original suggestion was that it would be cool if the page listing all of the optimization options listed which one was the "full" optimization option, as part of a small snippet about _why_ you might use each one. It's great documentation from a technical detail perspective, but without a lot more background on a lot more technical details it might not help somebody make a decision about which to use.
Right, that naming has created the misconception that /Ox is our /O3, which is why in current docs it no longer calls that switch "full". In my response I mean "the highest optimization level currently available in the compiler" which is what people usually think they mean when they say that. I think there are legacy reasons the switch had that name, but that's well before my time. I think the optimizer folks are trying to get away from any "full" naming in part to slowly eliminate the /Ox misconception, and in part in case different optimization switches are needed in the future (e.g. if /O3 is ever added turning on more aggressive inlining or something). I agree this is kind of a mess, all I can do is just tell people "just use /O2 /Zc:inline /Zc:throwingNew".
That should still permit the compiler to detect that there won't be an exception throw, no?
So just add `/O3` as an alias for `/O2` to be replaced in the future by a _superset_ of `/O2`, and problem solved ;)
You mean because of the `noexcept` on the function? Yeah, probably, but I'm not an expert (in fact, not even a novice) about using `noexcept`. The only reason I know that is from a years old argument/discussion about exceptions being slow.
Just wanted to chime in that I don't know how this will shake up, but I'm really interested in your continuing progress and I hope you keep going! :)
I see 3 unused function, assembler window should be empty, as best optimization.
Without `static` the functions are global entities and the compiler can't know if some unrelated TU is calling these functions, even without the header available.
It helps with avoiding using extra instructions if you cast to 64 bit, but (by the rules of C) adding two large 32 bit numbers will overflow rather than give a 64 bit result (assuming 32 bit int like most 64 bit machines). This is contrary to when adding 8 or 16 bit numbers which will give an int (32 bit) result on the same machine, without overflow.
Default behavior üòâ
The original C++ standard is here: [Voynich manuscrit](https://brbl-dl.library.yale.edu/vufind/Record/3519597)
I don‚Äôt get it.
That would be too consistent with other compilers ;)
On a related note, I've seen people use temporary heap objects instead of a simple stack object just because they thought objects are always created with new.
Indeed `/Zc:inline` does not work in assembly printing mode. Is there a ticket for that?
In the original post I added a link to the Volnich manuscrit. But it does not seem to work. I don't see anyway to erase a post. I'll just won't use reddit anymore!
Not a humor subreddit.
Oh. That makes more sense.
Because they are not static functions, add static and you will get an empty assembler window.
I see your point! I think that we may have some different use cases though. If you just want to pick a colour and print it in your console, then this is absolutely fine. But when we get into the realms of image processing, having a clear distinction between linear RGB and sRGB can be really useful. Gamma correction (i.e. sRGB) is an often misunderstood subject and have lead to a lot of bugs and incorrect colour results. Just read [this excellent article](http://blog.johnnovak.net/2016/09/21/what-every-coder-should-know-about-gamma/) and you'll know what I'm talking about. This is why I would advocate for distinct types for linear RGB and sRGB with easy conversions between them. But if your library is not meant for that use case, then so be it. :P
Why write this in C++ at all? Seems like you want a REPL. A lot of graph algos have quick library implementations in scripting languages/can compile the heavy lifting if needed (like lisp, c#)
maybe helpful https://lists.freebsd.org/pipermail/freebsd-current/2010-August/019310.html
i don't need the program itself to offer algorithms, i need the program to be a platform for the user to test his algorithms on. (of course i will put a couple premade algorithm scripts as example for the user but that's it) I see it mainly used by students; to test an algorithm they are working on for an assignment for example. One friend that graduated with me for instance had to write variations of a specific algorithm and test them, and he used the previous version of my program (without scripting) to visualize the graphs he was working on. He said me it would have been amazing if he could test the variations directly in the software interacting with the graph. It would also support any kind of generic algorithm, up to something that modifies the graph itself adding and removing nodes and arcs during execution.
I would hope that the toolset does whatever is necessary for stack unwindingto always work, given destructors which won't throw due to memory exhaustion (user code attempting to throw exceptions could have whatever exception it meant to throw be replaced w/ bad_alloc)
Yes but that would not apply when using \`-fno-exceptions\` flag, right?
Israel, no.
Interesting opinion of Linus on HTM: https://www.realworldtech.com/forum/?threadid=184919&amp;curpostid=184946
I'm a fan of pybind11
Actually, Clang removes it in that case too: https://godbolt.org/z/1r0sGd
&gt;We live in different worlds, around me lots of corporations do care about Xamarin. Most probably I didn't make myself clear. I know Xamarin is used a lot, it is the real deal. That said I know no company using it for UWP apps. They care about their apps running on iOS, Android and some of them looking at the WPF/macOS support added in Xamarin Forms. &gt;I guess it all depends if LibreOffice cares about using modern Windows APIs, or is happy being stuck with the legacy Win32 ones from Windows 7. You are talking from the perspective of the developer. I get it, I also like modern, better APIs and you only need to write some simple apps using the Windows API to see that the later is showing it s age badly. Truth is however that unless UWP offers an "unique" feature that for their specific case adds value there is no reason to port anything.
*shudder*
This is also a bit of a misconception. Clang follows GCC's switches because they needed to be drop in compatible with GCC. Just like clang-cl follows cl's switches on order to be drop in compatible with it. Both piles of switches have 30+ years of legacy and it's best to not use one's behavior to reason about others. Both vendors are guilty of choosing switches and terms for identical features that are wildly different, even recently. For example our /GL and LTCG that GCC and/or clang renamed -flto and LTO.
Nice. I learned about bloom filters in a Big Data course I took when I was still studying for a MSc in Comp Sci. You should also look into Skip Lists (useful for O(log n) inserts *and* searches). That's what I did a research paper on for the course. Another thing to look into is the Count-min sketch which is comparable to the Counting Bloom Filter for storing *frequency* of object appearances.
These data structures look interesting, especially the skip list. Will definitely look into them, thanks!
I thought that is was referring to bloom filters in graphics at first
Pawn is a nice and well-established language if it's C style syntax you're after https://www.compuphase.com/pawn/pawn.htm
&gt; Since calculating MD5 hashes is (relatively) slow, only one MD5 hash value is calculated, which is then split up into k different values. This means only one MD5 hashing operation has to be done instead of actually doing k hashing operations. This is still gonna be slower than using two really quick 128-bit hashing algorithms (like [xxHash](https://github.com/Cyan4973/xxHash) and MurmurHash), then using the technique described in [this paper](https://www.eecs.harvard.edu/~michaelm/postscripts/rsa2008.pdf) to simulate as many k hashing algorithms as needed, I think.
This is a last reminder. Your collaboration will be very welcome and will be a opportunity to help others to make a better world.
Can anyone tell us lowly self taught plebs what a bloom filter is and what it's useful for?
This post is really well-written. As someone quite new to the C++ language I was able to follow it word-for-word and learned a lot, especially regarding the false positivity formula and hash functions in general (which I Googled whilst reading your article). &amp;#x200B; Thank you for not using jargon just for the sake of using jargon. It really helps out new programmers such as myself.
The same article without the ad... [https://dzone.com/articles/the-biggest-problems-of-unit-testing-with-c](https://dzone.com/articles/the-biggest-problems-of-unit-testing-with-c)
&gt; A Bloom filter is a data structure that keeps track of objects without actually storing them. Literally the first sentence of the article.
It‚Äôs a very memory efficient data structure that can tell you if an item is in a set with a given probability. The advantage is that it uses much less memory than an actual set. The disadvantage is that it‚Äôs not 100% and can give false positives that an item is in a set when it really isn‚Äôt. Wikipedia has a good article: https://en.m.wikipedia.org/wiki/Bloom_filter
&gt; A Bloom filter is a data structure that keeps track of objects without actually storing them. Literally the first sentence of the article.
Might be better to template on `hash_function_count`, make bloomfilter_store_size `= 1 &lt;&lt; MD5_result_size_bytes`, `static_assert(hash_function_count &lt;= (MD5_result_size_bytes/bytes_per_hash_function))`, and make all constexpr. Also the hash result does not need to be dynamically allocated, it is always a fixed size.
It's like a hash table representation of a set, where the only operations are to add an item and to check if an item is already in the table. It's not a map--you can't give it a key and receive an associated value. The benefit over a regular hash table is that it takes up much less memory. The downside is that when you check if an item is in the set, the result will occasionally be wrong. It will never misidentify an item that is not in the set; it will only misidentify an item that is in the set. In other words, if the "exists" method returns "false" then it is definitely correct. If it returns "true", then it may or may not be correct. The accuracy rate is predictable, and can be easily tuned by adjusting the speed and/or memory usage. It can be useful as a sort of cache to quickly filter out searches that will definitely fail. Say you've got a huge database that's slow to access. If you build a bloom filter on the key in memory, then you can quickly check if a key is not in the table and avoid a slow database search. In a sense it's a counterpart to a least-recently-used data structure. For example, say you make a hash table that can store up to 100 items. When it is full, then adding another item will first evict an existing item to make room for the new one. If you search for an item in the table and find it, then the item is definitely in the table. If you fail to find an item, then it might not be in the table, or it might have been added but was then evicted.
So there are two main components: a hash function and an array of bits. The hash function takes in any input and tells you which bits of the array to check or set. So first step is to build a dictionary (in the common sense of the word, not the CS term). You take in a input and you set the bits the hash function tells you to. You do this for every input that you want to be a part of your dictionary. Now some bits in your array are set (i.e. 1) and others are clear (i.e. 0). Now the second step is checking to see if a given input is in your dictionary. You again take an input and hash it, but this time it'll you what bits to _check_. If all the bits you check are clear, then your input does not exist in the dictionary, because if your input was in the dictionary, exactly those bits would have been set when the word was added. However (and this is crucial!) if all the bits you check are set, **this does not mean your input is in the dictionary!** the reason is because the union of the bits set by two previous inputs might exactly be the bits checked by your current input. Here's a quick example. Imagine our array is 5 bits and the hash function gives you which two bits to set or check. Suppose we put these two words in the dictionary: "Apple" ==&gt; bits 0,3 "Banana" ==&gt; bits 1,4 Now let's say we wanna see if this input is in the dictionary: "Orange" ==&gt; bits 0,1 Our bloom filter will say that is un the dictionary even though we never added it! The union of "apple" and "banana" covered "orange". The takeaway is that bloom filters will never give a false negative, but they could give false positives. Using some math (which idk at the moment), you could determine the probability of a false positive. Now to make the bloom filter perform better, you would want a hash function that very sparsely assigns bits so that overlap is rare. For that you'd want a large array too. Of course this requires more memory and performance. Thus, you have a tradeoff. What you go with depends on your application. An example of how to use this would be if you were writing a Boggle game. When someone makes a word, you could check if that word is in the dictionary quite fast. A linear search over the English dictionary is much slower than checking a bloom filter, but the bloom filter might accidentally count non-existent words... Also note that in my explanation I used the word "input" instead of "word" to describe the objects being added. This was intentional; anything that can be hashed can be added to a bloom filter.
The author would probably be surprised at the performance of my sorting algorithm: https://github.com/orlp/pdqsort/. It's a comparison sort (not just radix) and works out of the box with small to great speedups compared to `std::sort`. It's only 500 LOC of plain old C++. The state of the art for comparison sorts for very very large arrays to my knowledge is https://github.com/SaschaWitt/ips4o. It has a parallel and a serial version. The author should probably add that as a comparison as well. --- As for the original problem of generating random numbers, I think there's a much better approach that is embarrassingly parallel, cryptographically secure, works for massive number ranges and can instantly give you the `k`th distinct random number in your array. It works by constructing a random permutation out of your range in such a way that you can directly query the `k`th number in the permutation without having to shuffle an entire array (even if your range spans 10 billion elements). The technique is called Sometimes Recurse Shuffle: https://eprint.iacr.org/2013/560.pdf. I have a toy example implementation in Python here: https://gist.github.com/orlp/33535eefce782a59e185e4a971cda1a3.
Lets put it this way, many of the new Office features are built on top of UWP APIs.
Yall need to stop getting 0.03% more performance with these bespoke frameworks and go convince ppl to finally let COBOL die. Write an optimizing Perl-to-Java deobfuscating transpiler for once.
Other than this not being the appropriate subreddit for this question... I have absolutely no idea what this question is asking.
If Google is to be believed, I think they want to monitor https://www.off---white.com/en/US for... some purpose? I would imagine sales notifications or something.
That site gave me a brain aneurysm.
Integer promotion is the rule used here. It's inside the C++ specification. Any arithmetic operation on char, short and enum will be promoted as integer.
The Bloom filter is neat --- but one thing that really slows it down is that the memory access pattern is pretty poor (e.g. k random accesses per-query). There are some nice practical improvements that can vastly improve the cache performance of the bloom filter, like the [pattern-blocked bloom filter](http://algo2.iti.kit.edu/singler/publications/cacheefficientbloomfilters-wea2007.pdf). Also, the [quotient filter](https://www.usenix.org/legacy/event/hotstorage11/tech/final_files/Bender.pdf) and [counting quotient filter](https://www3.cs.stonybrook.edu/~ppandey/files/p775-pandey.pdf) are nice, cache-friendly approximate membership query (AMQ) data structures that also provide some operations (e.g. iteration over the hashes of inserted keys) that Bloom filters do not (disclaimer; I'm a co-author of the latter paper).
I haven't used it, but I've heard [metashell](https://github.com/metashell/metashell) is helpful. There's also [msgui](https://github.com/RangelReale/msgui) for a GUI on top of metashell.
Like? I'm seriously interested.
You can't evict from a bloom filter though. Therefore it's most useful for data that won't change frequently, since you'll need to rehash your entire dataset to remove an item. The Wikipedia pages data set that the author was using is a pretty good example.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/btehiz/compiling_static_library_in_vs_with_cmake/eoya3hi/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Handling SVG and glTF images with GPU support, Fluent UI, UI Visual Layer and animations, HoloLens integration. BUILD 2018 has some talks about it.
Of course, I completely forgot about the fact that the discussion was about references! And clearly the `&amp;` is a part of the type just as much as `const` or `*`
I am torn on this. On one hand, it's great to have cl.exe running in Docker instead of big fat Windows Servers. On the other hand, I'm not sure I want to take on the responsibility of troubleshooting some weird-ass error that comes from the fact that this is running under wine.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/btjvce/need_help_with_ofstream_of_hightxt_file/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Might as well read the article at this point...
uh...what does that do?
I wonder what is the purpose of using `auto` in this line: auto cs_md = fmu.get_model_description(); //smart pointer to a CoSimulationModelDescription instance If you specify the type in the comment, why not using it stratight away to declare your variable? Why not the following? std::shared_ptr&lt;CoSimulationModelDescription&gt; cs_md = fmu.get_model_description(); std::unique_ptr&lt;CoSimulationModelDescription&gt; cs_md = fmu.get_model_description();
What is "early execution"?
"Early support" for execution, not "early execution" ;)
That's called bad wording. It's about "early support for code execution".
Execution of e.g. ARM binaries via qemu would be nice to have.
Allocate a large buffer, then build your own allocator on top. If all your objects are first created then destroyed you can use a monotonic allocator. If the lifetimes are more complicated maybe a freelist can be a good idea. If you end up filling up your allocator you can split it into blocks. There have been a few good talks about allocators at cppcon (?), you can find them on youtube. If i remember correctly, one was by Andrei Alexandrescu and another one was by someone from Bloomberg.
It means CE will now summarily lop off your head if you give it code that fails to compile
A block allocation system means memory isn't returned to the operating system when some sub-section of the things are freed. A free-list allocation system has all of the overhead of individual allocations. Neither of those systems does what I'm looking to do: a large amount of individual allocations up front, sporadic allocations and de-allocations, and returning memory to the OS when something is de-allocated.
Is it not possible to use a Windows nano-server (or whatever the image is called) with the VC Build Tools and run that in Docker? Should be fairly lightweight as well?
Ah thanks! I really didn't get it until I read your post.
Only works with recent MSVC versions and you still need a big fat Windows Server host, so I don't consider it lightweight (especially since you have to pay the severe NTFS perf hit for anything you do).
You can `free()` empty blocks when all the 'subblocks' get freed. The overhead of a (fixed size block) freelist is almost nonexistent, it's just changing two pointers around. I'm pretty sure the typical `delete` and `free()` implementations don't return memory to the OS either, they keep it around in a local allocator so subsequent calls to `new` and `malloc()` are faster. Do note that your problem is not easy to solve. If you want granularity in the deallocations, you need granularity in the allocations. If you want speed, you need to do fewer allocations. Your two objectives kind of oppose each other.q The obvious answer is to batch allocations and cut your allocation/deallocation count by some constant factor. Of course, the size of those batches really depends on wether you want to save on time or memory usage... I might be missing something here though.
Right, so adding two large 16 bit numbers will never overflow, but yield a 32 bit answer. Adding two large 32 bit numbers *will* overflow and also yield a 32 bit answer. This does not change between a 32 bit and a 64 bit system. But the problem you're talking about is that the 32 bit system can be more efficient in implementing this behavior, since the register itself actually overflows?
Unfortunately it's not possible because Windows containers cannot run on Docker for Linux which makes people do experiments like this one (Wine). There is also https://github.com/StefanScherer/windows-docker-machine but kinda diminishes Docker advantages by putting the VM into the equation.
Other people replied already. Sorry for the bad wording :)
&gt; I might be missing something here though. Yes - I want a way to do multiple allocations at once (the topic title) thus satisfying the "fewer allocations". Something like: ```size_t multiple_malloc(size_t chunk_size, size_t count, void** out_result);``` Where: ```size_t chunk_size`` is how big each allocation should be, ```size_t count``` is how many allocations, ```void** out_result``` is a pointer to an array of result pointers that get allocated, and the return result is how many allocations succeeded. Yes, I know it's a C interface but that's just because I'm basing this off malloc (which new calls for all intents and purposes). Because I can imagine that "malloc" is implemented via something like: void* malloc(size_t size) { lock(mutex) // other stuff like going from user-space to OS-space for things void* result = ...; unlock(mutex) return result; } and *some* significant amount of the time is just overhead that could be avoided if you could just tell it "do that 10 times, and store the results here".
If you want to make a platform app, I think using a sophisticated programming language would be nicer. If I was the user, I don't want to learn a whole new language. Popular languages will reduce users' learning costs and let them get started easier. So in my opinion, Python, JavaScript are both good choices. If it's possible, you can create a sandbox environment and expose APIs to make compiled program (using languages like C++, Java. Of course, it is advanced and can be complicated.) be able to execute in it.
See the blog post. Speeds up type merging in the linker.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/btlvua/help_a_newbie/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I'm pretty positive you'll have to write a custom allocator for this. The problem with "a large amount of **individual** allocations up front" is that to implement this and have the granularity of "sporadic allocations and de-allocations" is very contradictory to avoiding your problem with using a freelist, specifically: "has all of the overhead of individual allocations." Either you have fine-grained control over individual blocks in the batch-allocated array or you lower the overhead by treating the entire array as a single allocated block. I mean, perhaps you *could* come up with something to work around this, but it'd take some work.
Great, can't wait to get a portable stdx::simd in the future! I'm a happy user of the 1.4 branch of Vc already!
I feel like you are too fixated in "how do I implement this solution" rather than "how do I solve this problem". I feel like allocating in pairs (or N-tuplets) and actually freeing when both (or all N) objects are destroyed would be a good strategy. If that is really not good enough maybe we could use some more information about your platform. Do you own the malloc implementation? If you do, you can totally implement what you described. Otherwise, adding a faster and smaller allocator on top is probably the way to go. Are you running under an OS? If you are, which one? Maybe it has some non-portable way to do what you want.
Thanks for reporting this! The thing is that when there are heavy headers included for testing purposes then the lightness of doctest starts to disappear in the sheer scale of the code. If you take something which contributes only 20% to the overall compile time and you make it 100 times faster you would still have optimized the total time by up to 20%. &amp;#x200B; The cool thing about doctest is that it is the only framework which would be practical for use in the production code itself ([light](https://github.com/onqtam/doctest/blob/master/doc/markdown/benchmarks.md), [warning-free](https://github.com/onqtam/doctest/blob/master/scripts/cmake/common.cmake#L73), [easy interop with production code](https://github.com/onqtam/doctest/blob/master/doc/markdown/main.md), [can remove everything testing-related from the binary for a final release build](https://github.com/onqtam/doctest/blob/master/doc/markdown/configuration.md#doctest_config_disable)), so if you wrote your tests at the end of the .cpp files for a specific module then you wouldn't be compiling the headers for the test code twice (for the actual implementation code and for the tests) but only once and then the tests will be just an additional 5-10% of your build time. &amp;#x200B; Writing tests right next to the production code is possible in other compiled languages such as D, Rust and Nim. Some people are already trying it out with C++ using doctest. &amp;#x200B; And one more shameless plug: doctest can actually be used for a general-purpose assert library so you could use asserts from the testing framework [in the production code itself](https://github.com/onqtam/doctest/blob/master/doc/markdown/assertions.md#using-asserts-out-of-a-testing-context) even when it is being executed outside of a testing context! Here is an article from 3 years ago regarding the speed of compilation of asserts for doctest which is still very much relevant: [https://baptiste-wicht.com/posts/2016/09/blazing-fast-unit-test-compilation-with-doctest-11.html](https://baptiste-wicht.com/posts/2016/09/blazing-fast-unit-test-compilation-with-doctest-11.html)
I heard that you guys were at one point considering replacing your compiler with Clang. Why'd you decide not to, when you got rid of EdgeHTML? truly just trying to understand.
\&gt; Is there any more performance oriented, c-like scripting language that can interact with c++ classes? I wouldn't worry about performance. If you find that you have something you need to do in your scripting language that's really slow you can expose some new API from C++ to cope with it. I went through a similar process in the past and actually ended up inverting my program i.e. instead of embedding python into my C++ app I ended up writing my UI in python and calling my C++ API for the heavy lifting. The big advantage was that I could create my plots in matplotlib. Giving up static typing was a pita though.
If all of your objects are of the same size (or even just similar enough so you can take the max size), maybe you want something like a Slab allocator? Also note that an allocation overhead is typically not a syscall overhead, unless your objects are (very) large. General purpose allocators maintain their own internal data structure using some kind of optimized free lists + nowadays things like per cpu or thread arenas, and only fallback to actually allocating from the OS when the request can not be fullfiled by already allocated memory. Symmetrically, they don't release all freed memory directly to the OS but simply put it back to the free list until there is too much of local free memory -- at which point they *do* release it to the OS. What is your platform and libC? I think if they are a few years old or more, you should try an alternative high perf allocator (e.g.: jemalloc) Also, why can you not profile more precisely?
If you haven't updated to 2019.1 please do - it includes a number of performance fixes. Here's the basic situation with performance. Opening a solution is expected to cause some lags (unfortunately R# has to do some project model synchronization with VS on the primary thread). After that R# starts indexing the solution, which might take several minutes on very large solutions and might cause hangs during editing. The reason is R# is a managed extension and allocates a lot of managed memory during indexing. That causes frequent garbage collections, which stop all the threads. We are working on moving ReSharper out of the Visual Studio process to eliminate the hangs, but do not have an estimate yet when this work fill finish. Initial indexing however should be a one-time operation, after it's finished hangs should be rare. However, if the Visual Studio process consumes a lot of memory, it starts hitting the memory limit of a 32-bit process and GC pauses tend to be very long. If you notice that the VS process consumes more than say 2 GB, collecting a [memory snapshot](https://resharper-support.jetbrains.com/hc/en-us/articles/115000265844-Collect-memory-snapshot-in-Visual-Studio) will help us understand how the memory is used. One possible way to reduce memory usage is to [exclude parts of the solution](https://www.jetbrains.com/help/resharper/Reference_Options_Code_Editing_Third_Party_Code.html) from indexing. Otherwise if memory usage is not particularly high and hangs still happen for some reason, please try to collect a [performance trace](https://resharper-support.jetbrains.com/hc/en-us/articles/210652849-Collect-Timeline-performance-snapshot-in-Visual-Studio) which captures the hangs. The trace will show when and why the UI thread is blocked. Finally, you can use free [ReSharper Command Line Tools](https://www.jetbrains.com/resharper/features/command-line.html) both for linting and reformatting without installing ReSharper into VS. Please feel free to create an issue in our [issue tracker](https://youtrack.jetbrains.com) or a post in the [support forum](https://resharper-support.jetbrains.com/hc/en-us/community/topics/200366089-ReSharper-C-). Reddit is not the best of places for support :)
Your imagination about how malloc is implemented is way too simplistic. A good malloc avoid locking in common cases, and avoid syscalls by maintaining its own free lists (typically multiple ones, and fancy data structures and not just linked lists). Now if you *really* have too much syscall overhead for your workload (which is possible but **must** be checked), you can write your own allocator that get/release OS memory with mmap/munmap under Linux/OS X or VirtualAlloc/VirtualFree under Windows + put some internal data structures to manage what zones are free or not, and some heuristics to know when to release whole pages to the OS. I would not recommend it if threads are involved, unless you want to become an expert on the subject. Actually it will be non trivial even if threads are not involved, but if you are very careful it might be doable. Maybe just try to get a precise profile and/or try something like jemalloc, in a first time.
you probably didnt read the full question. Scripting is not for me as developer of the software, but for users to write algorithms that are tested by the software
With this, Compiler Explorer now does became a one spot for C++ education and testing.
Quick comment: In the develop branch of boost.test there is a CMake file which \*drastically\* reduces the compilation time of using boost.test. This should come out next release, but of course you can clone the head.
can you provide a link?
"memory isn't returned to the operating system" I would love to know how can YOUR program can have any advantage by better releasing resources back to the operating system?
lol i thought gamedevs were supposed to know this shit. or do they just spend all day trashing OOP instead?
Let me ask you more questions: 1) Are you anticipating iterating through this entire list in a way that is performance-critical? 2) Do you need to reference the instances through random-access iterators (of any type) or will pointers do? 3) What exactly is the scale of your allocation? 6kb is incredibly tiny.
I can gaurentee you it is because clang can't compile windows, remember they still use MASM in some parts, and it is likely that they use MSVC's inline assembly in some spots strategically. It also is likely to be better optimized for windows since that is its main target. It's why they added ARM support to MSVC rather than adding CLANG. They do a lot of work to make sure that their customers are happy and internally Windows actually works as expected, hidden intricacies and all. Remember: in OSes this old, the main reason people still use them is either that they genuinely prefer them, or, for enterprise businesses and governments, their legacy software STILL works on them unaltered.
It execute only the stuff before ‚Äòmain‚Äô.
I thought any namespace name starting with std was reserved for the implementation.
Why -O2?
https://github.com/boostorg/test/blob/develop/build/CMakeLists.txt
Eh I thought the article was a bit light in my opinion. But also if the article was sufficient the commenter I replied to probably wouldn't have asked.
&gt; I'm pretty sure the typical `delete` and `free()` implementations don't return memory to the OS either, they keep it around in a local allocator so subsequent calls to `new` and `malloc()` are faster. On windows at least, it absolutely returns pages to the OS when you delete everything inside them. Honestly I think most allocators (for desktop OS's?) will do this too. It's probably a pretty common use case to have programs that are long running but allocate 2-3x their operating memory during startup for initialization.
I think the bad wording is my fault; that's the wording in the MOTD on the main site (which I'm now changing...)
what does that file do - I mean how will it improve the build time of my tests when I include the boost test header and write asserts? Isn't that file related to the build of boost test itself? I see no build-speedup things such as precompiled headers or whatnot..
That was a good read! I'm aware of the topic. *vivid* in fact already has all tools in place to work with gamma correction and uses them internally. There's the linear `lrgb_t` type, which converts to and from `srgb_t`. There's also methods for sRGB gamma compounding and RGB gamma correction (`srgb::compound(...)`, `srgb::inverseCompound(...), rgb::gamma(...)`). I'm having a hard time however to come up with a clean high-level API extending `Color` to make linear RGB a first class citizen. If we'd include linear RGB as one of its internally stored types, then how would you be able to know after a conversion to e.g. HSV if that in turn is linear or not? You would need an additional flag that holds that info. However, that flag is completely irrelevant for LCH and other non-RGB spaces. And so we would have a pretty confusing mess. You're having a very good point though in making gamma correction (or the lack of it) more transparent to the user. For now, I might at least include a `lerpLinearRGB()` method for `Color`, that converts the implicitly stored sRGB to linear RGB, interpolates and converts back. For everything else - until I have a better picture of the use cases, how people apply or want to apply the library, and what a good API would be for those - you can work with the low-level API. Hope that works and let me know if you have any smart ideas about it! ;) &amp;#x200B; PS: And as you conjectured, I don't see *vivid* for hardcore image processing quite yet. It's not targeted to be crazy performant and support OpenMP and AVX512 and all. It's certainly good to do some testing and quick experiments though! Again, curious how people will use this, and I'm happy to develop it further in any direction.
&gt; However, if the Visual Studio process consumes a lot of memory, it starts hitting the memory limit of a 32-bit process and GC pauses tend to be very long. That there is still no 64 bit version of VS in 2019 is frankly ridiculous (regardless of whether this is the root-cause for this particular problem or not).At least VS itself moves more and more things out of process too.
Thanks for posting this! &amp;#x200B; If you find issues, please raise them on the GitHub issue tracker: [https://github.com/mattgodbolt/compiler-explorer/issues](https://github.com/mattgodbolt/compiler-explorer/issues) \- thanks! &amp;#x200B; You can still DM me on Twitter or post on the slack, but this feature is "close enough" to release that I want to track the issues on GitHub. Thanks!
 tCIDLib::TSInt main(tCIDLib::SIn4 iArgs, tCIDLib::TSCh** apszArgs) It‚Äôs an admirable work. However, I don‚Äôt see how it would appeal to anyone to incorporate your libraries, which, according to you, are monolithic, or to build on top of it while ignoring the STL or an established battle-proven framework like Qt. I think it would be better to modularize your library in a way that it would be easy to incorporate bits into other projects.
That's completely what this system isn't intended for. The world doesn't need another pieces and parts system. There are already plenty of those. It's an alternative to that. Even Qt is built on the standard libraries, with all of the compromises that involves. And some of the best stuff could not be incorporated into other projects because it depends fundamentally on having a fully integrated architecture, where all code participates in various capabilities.
I thought we had std2 reserved, but this is what the current working draft says: http://eel.is/c++draft/reserved.names#:name,reserved Using `stdx` is currently OK, AFAIK.
Then I misunderstood what was told to me. I thought anything starting with sad was reserved.
Hm. That seems to be library. Do we have another for the language?
Oh right, didn't quite get that LRGB stood for Linear RGB, thought it meant something else for some reason... my bad! As I haven't had the chance to actually try out the API yet, I can't really give an opinion on how it feels to use. Haven't done too much image processing in a while, but as I'm playing around a bit with some graphics stuff now, I might try it out and see if it works out well for any use cases I come up with!
You could use `std::vector&lt;std::optional&gt;`. optional will use placement new for you. Optional may take up a little extra space, so you may want to find an intrusive optional implementation. Having said that, do you really need to hold onto all that unused memory? Allocating unrelated objects is new's job
&gt; Maybe just try to get a precise profile and/or try something like jemalloc, in a first time. I always start by profiling. In this case &gt; 30% of the time was in system calls which is what led me here.
My living wage is paid by the people who use our software and they dislike it when it consumes all of their memory leaving none available for other programs on the computer. So in that regard our program gets an advantage by memory being released back to the operating system when we're done with it allowing it to have a smaller runtime footprint. If you wanted to take the example further: all the memes about chrome memory usage speak for themselves.
&gt; 1) Are you anticipating iterating through this entire list in a way that is performance-critical? Yes &gt; 2) Do you need to reference the instances through random-access iterators (of any type) or will pointers do? Always random access &gt; 3) What exactly is the scale of your allocation? 6kb is incredibly tiny. In the example where this showed up as a slow spot in profiling it's creating 1'282'082 of them in the loop when it goes to de-serialize the file.
OK. Block allocation is the preferred solution to this problem. If it's OK that iterators (indices) get invalidated, you can use a std::vector, and for deletion you can swap your item to be deleted and the 'back()', then pop\_back on the vector. &amp;#x200B; This has the upside of block allocation, fast iteration, random access and fast deletion (unless moving your item is a heavy operation.. you can probably refactor if it is). It has the downside that you invalidate iterators on deletion, which could be a no-downside if you are doing it in a somewhat controlled way.
&gt; anything starting with _sad_ was reserved.
Thanks for the low level details that it's basically a bitset, that really makes it easy to understand why it would falsely say something is there but can't say it's not.
Right, but that doesn't address the "give the page(s) back to the operating system when the single object is freed if nothing else is using that page" part. I'm well aware of how block allocators and free lists work and the tricks to keep them all O(1) time. I was looking for something even better and wondered why it doesn't seem to exist anywhere.
std::vector::shrink\_to\_fit may fulfill your needs on this front.
The objects also need stable memory addresses so storing them by-value in a vector isn't going to work.
If you need a memory location contract and dynamic sizing, random access can't ever work.
I think I'm confusing you by mistake. When I replied to the random-access question I meant: I'm going to allocate the objects and store them somewhere and then randomly access them.
OK, so this is what you would like: Random access (which means accessing by an index). Stable memory location. Fast Iteration. Block allocation. Garbage Collection. If you really need all of these features, I would implement this as a multi-block chain. You would keep a separate side list of all the 'erased' items for re-use. If one block is completely empty, you can garbage collect it. If your blocks are small enough (similarly to std::deque which you shouldn't use) you will have good garbage collection. Iteration is a bit slowed between blocks, but not really. Random access is a bit slowed due to an modulus operation, but this likely isn't measurable in real runtime. &amp;#x200B; We use this technique to manage billion-scale number of vertices in a dynamic mesh during refinement/coarsening operations.
I think the page not loading had more to do with me being on mobile chrome than anything else.
&gt; We currently have no easy way to link against third-party libraries, so only pure header-only libraries are supported. It's not easy to be a C++ library dev and protect your work. I've been working on an on-line code generator in part because of this.
how about avail for download compiled executable file
cl itself running in wine has never been an issue for me; it's a basic and old CLI program that doesn't do anything nontrivial with the win32 API. Now msbuild in wine is a whole nother story and not something I would recommend.
iOS auto-incorrect. You know wha I typed.
Why do you need the const char* overload? Wouldn‚Äôt the string_view overload suffice?
You don't include the same header-you need to use \`BOOST\_TEST\_DYN\_LINK\`; here's the github issue: &amp;#x200B; [https://github.com/boostorg/test/issues/201](https://github.com/boostorg/test/issues/201)
I know. It just found that sentence amusing) `sad` namespace... I know a few projects that belong there xD
Yeah. Some people say that the hash chosen for C++ belongs there. I was never smart enough to understand hashes. But I understand those guys are smart. Hashes are like cats. You put a thing, bigger than the box, into the box. And it fits and sits.
If [std::string is made constexpr](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0980r0.pdf), the basic_string member functions could be marked `constexpr` too.
May I ask what is your particular role/responsibility in Factorio Development team? I'm quite surprised that a developer of a very popular game shows complete lack of understanding of how memory allocation works on language/OS level.
See "auto to stick" https://www.fluentcpp.com/2018/09/28/auto-stick-changing-style/
While I agree in general that returning memory to the OS is the right thing to do, even if you call `free()` on it, it won't necessarily happen. Your libc/libstdc++ will often just hang on to the memory and give it right back to you the next time you allocate something. It really depends on OS and libc/libstdc++/the allocator used, usually there's something like a size threshold. Another thing to consider is that memory you have allocated but never/not recently used is not necessarily backed by physical memory by the OS. This makes the picture even more muddled w.r.t. whether free()ing the memory is always a valuable thing to be doing. If there's a good chance you'll need the memory again anyway, then it's not that bad of a strategy to just hang on to it I think. You can have allocation pools that are smart about this, and free large chunks of contiguous memory where possible, without incurring too much overhead for many small allocations. Also check out advanced allocators like jemalloc, they have a large number of different strategies for these kind of things.
I've found this guide to be more helpful to me. https://hackernoon.com/a-c-hello-world-and-a-glass-of-wine-oh-my-263434c0b8ad
Everyone seems to be saying this is a dumb idea, and maybe it is, but we don't know. The question is what overhead could be eliminated with a single call over multiple calls. Maybe 6K is too big for your allocator - maybe it is getting 4K chunks from the system, so it is doing a sys call on each allocation. So asking for N at once could get some benefits. The allocator could make one call to the system. Or maybe there is some other overhead that could be eliminated. Someone would need to go into malloc() and see what gains are there to be made. You could do this by playing with an open-source implementation. The alternative/lazy path would be to assume that if there were gains to be made, someone would have done this by now. But you never know. And yes, you could "just" write your own allocator. But I think that misses the point - it would be useful to be able to get all the benefits of using the standard allocator, without mucking with allocation yourself. P.S. it would be a bit weird with `new` however - do they all get constructed with the same constructor params? Would we only allow default construction? Etc.
Why would you use msbuild when there's ninja though.
Brilliant, now I don't have to switch to any of the terrible online compilers to actually run the snippet.
AFAIK for namespaces only `std`/`std[0-9]` and `posix`/`posix[0-9]` are reservered by the standard(I was unable to see anything regarding namespaces on that page).
Aah that's too bad that you do need a full-blown Windows host to run the Windows Docker container...
Hey if you're implementing Contains() why not some other sensible functions such as StartsWith() or EndsWith()?
starts_with and end_with have already been added to the C++2a draft.
And are shipping in VS 2019 16.1, recently released for production use.
Template argument deduction. basic_string_view&lt;CharT&gt; won‚Äôt deduce CharT given a function argument of const char *, because template argument deduction doesn‚Äôt consider implicit conversions (in general).
Nice article! It also gets me thinking that now Concepts are in C++20, some of the STL operations can loosen the type requirements to Concept requirements so that as long as two types meet certain criteria they can perform certain operations, roughly like how implicit type conversion works but better controlled.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/btsxmy/multi_dimensional_array_help/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
A problem of new test frameworks are the lack of test adapters for IDE integration which allow to discover and run all tests from the IDE and quickly go the file and line where the test failed. Doctest is way faster than most test frameworks, however it doesn't have test adapters for usage with IDE such as GTest or Boost have. So, do you miss the IDE integration with Doctest framework or are you running all tests from command line or building system? Another good features missing in Doctest is the lack of data drive test where is possible to use a vector or collections of tuples containing inputs and expected results as test cases.
May i ask how you were able to enroll for the whole course as a one-time payment? I have seen this option before, but only see a monthly enrollment fee now.
It happened prior to when the Nanodegree program began. Essentially, I paid for the program 14 days before it commenced.
&gt; Right, but that doesn't address the "give the page(s) back to the operating system when the single object is freed if nothing else is using that page" part. I'm confused, this sounds exactly like what most block allocators do, If you're using regular new/delete on windows, it uses HeapAlloc, rather than attempting to use VirutalAlloc and block-allocate. https://github.com/mjansson/rpmalloc#implementation-details seems to describe something along the line of what you want. Either you want something like HeapAlloc from the windows API (and allocate a high-memory fragmentation Heap) or VirutalAlloc and allocate a huge page and then use committing and uncommitting of pages to successfully free when a page is no longer used. There is a reason everyone is telling you block allocators: they are the only thing that works in this case, and afaik no one has implemented any tricks that try to squeeze out more performance along those lines.
&gt; May I ask what is your particular role/responsibility in Factorio Development team? Feature development, bug fixing, optimizations, code review. Essentially anything which involves touching the code. &gt; I'm quite surprised that a developer of a very popular game shows complete lack of understanding of how memory allocation works on language/OS level. What makes you think I don't know how memory allocation works?
&gt; P.S. it would be a bit weird with new however - do they all get constructed with the same constructor params? Would we only allow default construction? Etc. If such a thing existed, you would most likely need to use placement new after getting the memory from the theoretical "multiple_malloc" call.
A lot of what you describe is available on [LeetCode](https://leetcode.com) minus the bits specific for Boost or Qt. I definitely recommend it as a great learning resource for any developer. The site also includes many questions/problems used for interviews.
Ah, you want it to execute, but only in the morning. Interesting. :)
Those are member functions, not template member functions?
Great, another because another langauge has it, C++ should have it. Have you looked at &lt;algorithms&gt;? You realize this functionality already exists, right? Not for just strings.
It would be great to put a template on the container so I could use another container e.g. the vector in EA STL. Probably no difference but why do you store the number of bits instead of calculating it every time from the vector‚Äôs size?
&gt; Remember: in OSes this old, the main reason people still use them is either that they genuinely prefer them, or, for enterprise businesses and governments, their legacy software STILL works on them unaltered. Ah yes. Because Windows 8 and Windows 10 truly are just like their predecessors.
You‚Äôre correct, please ignore my comment.
You said that already
1. Not exactly 2. And?
C++2a adds `starts_with()` and `ends_with()`. `contains()` is an obvious addition with those. &gt; Have you looked at &lt;algorithms&gt;? &gt;You realize this functionality already exists, right? Not just for strings. There is no direct equivalent of `contains()` in `&lt;algorithm&gt;`. The closest is probably `count()`, but that still requires additional boilerplate, especially pre-ranges. &gt; Great, another because another langauge has it, C++ should have it. Just because everybody in the world *can* (and does) write the same `str.find(foo) != str.npos` boilerplate does not mean that `contains(str)` is not a useful addition to the standard.
Which open-source projects with Doxygen-based documentation should I "make-over" and add to the sample set? Currently, we have LibUSB, LibSSH, OpenCV and a few others (links in the README). Any other questions/suggestions are welcome as well.
Creating another way to do the same thing is superfluous. Contains can be duplicated with functionality in algorithms easily. Not to mention using find(). By your argument, every linear container should have sort() on it. Create multiple ways to do something because others refuse to learn to use the existing interface is not a reason to reduplicate it. There are better problems to solve than this one.
**Type** Full time, entry level **Description** internal tools using React, server side shell scripts using PHP **Location** New York City **Technologies** C++, C, React, Java, networking, servers, apache, linux, AWS **Contact** DM **Interested** I really like C++, Go, and any type of heavy duty systems programming. I am a math major so I have an interest in optimization, algorithms, data science, and thing that are generally "nerdy"
Couldn‚Äôt you use that entire argument to say all programming languages are pointless and we should all write assembly?
The /r/learnpython subreddit does something like this I think. A coding challenge on a regular basis (I think it's monthly). Having different difficulty levels would be quite nice too.
No, where did you come up with that as a premise? This is akin to saying we need separate add instructions for every integer.
While that would be useful for sure, I feel like it would be a little bit outside the scope of the site.
&gt; Creating another way to do the same thing is superfluous. Only if the other way doesn't add or change anything. In this case, it adds *significant* brevity to a **very** common operation. &gt;Contains can be duplicated with functionality in algorithms easily. And `equal_range()` and be implemented in terms of `lower_bound()` and `upper_bound()`, and a fair number of other members of the `&lt;algorithm&gt;` functions can likewise be implemented by their brethren. By your own argument, every one of those is superfluous and should be stripped from the standard. /u/DiaperBatteries has it right, obviously: just because a given abstraction can be implemented in terms of other abstractions doesn't mean it's worthless. &gt; There are better problems to solve than this one. This a remarkably simple and nearly universal function for string types. C++ is the only high-level language I am aware of that doesn't have it. Adding it to the standard is obviously not detracting from other harder problems, and it makes the readability/accessibility of the language better.
Brevity? I bet you're one of those guys that does #define C class for brevity. Why not keep things consistent? I prefer consistency to brevity. You didn't answer my question about sort. Should we add it to everything for brevity? Do we need to add it to string?
Is there a roadmap of C++20 features in MSVC published anywhere? I'd love to know roughly when we'd get to use `std::is_constant_evaluated`, for example.
I wasn't really talking about a coding challenge per se. There's lots of that out there. It was more about seeing things implemented with different tool sets. That won't be nearly as much time suckage since no one would be particularly expected to be super-clever about the algorithm itself. Just a reasonable implementation would be fine. It was more about seeing how the tools are used to do that implementation. Of course if folks also want to do a real coding challenge where the algorithmic cleverness is the point, nothing wrong with doing that either.
The optimization level was decreased when we found similar to this bug - [https://gcc.gnu.org/bugzilla/show\_bug.cgi?id=87062](https://gcc.gnu.org/bugzilla/show_bug.cgi?id=87062). [https://godbolt.org/z/QtRLpj](https://godbolt.org/z/QtRLpj) I mean, it's not that our code was affected so much. It's just that some people claim O3 sometimes produces strange code and then we hit such case and ... We haven't observed performance degradation when we got from O3 to O2. It's just that we don't have so much code which will benefit from loop unrolling, vectorization, etc. Maybe we'll get back to O3 when we upgrade to some newer version of GCC.
Aim for a long run. Learn any languages that bring food on your table. Hone your c++ at home. One day, investment returns.
Yes please! Other low hanging fruit functionality that would be useful : `split` (on a delimiter or multiple delimiters) and `replace_all`. Thanks for taking the time to do this and good luck! The standard committee takes pride in the lack of basic functionality in our standard library ;)
squirrel
I am unaware of such plans (and even if I was, I wouldn't be able to talk about them).
&gt; Why not keep things consistent? I prefer consistency to brevity. Ah, yes, consistency, what a good argument: `string::find()` returns a `size_t` which is set to `string::npos` in the case of a miss. `map::find()` returns a `map&lt;key, value&gt;::iterator`, which equals `map::end()` on a miss. `std::find()` returns an input or forward-iterator, depending on the underlying `begin()/end()` iterators used in the search. `std::vector()` doesn't have a `find()` operation at all. How consistent! Or, hey, what about `std::set::contains()`? You're right, we *should* be consistent! Every container type should have a `contains()` function, since one of them already does. &gt; You didn't answer my question about sort. Do we need to add it to string? Obviously not; there is no universally-recognized need to sort a string, or even what that would mean. Considering that a heavy percentage of strings are really just `const char*`, they're not even sortable without making copies. Furthermore, `std::string` is not a container-type, and even if it *were*, none of the other container-types have a `sort()` member (either modifying or copying in nature). I thought you liked consistency? &gt; Should we add it to everything for brevity? Again, obviously not; unlike `string::contains()`, it's a much more involved operation, which requires modifying the underlying data in-place or copying it. Its usage and cost are very-much specific to the underlying types. But, I'm sure you know that. It's completely non-controversial to add `contains()` to a standard string type. Honestly, you seem to be arguing for the sake of argument, and it's just silly.
Ah right. Now that you mention it, I remember it was discussed here on reddit too. It wasn't a problem for us, so I forgot about it. Thanks.
If you're going to have `split`, don't forget `join`! Both functions are in my "grr, these should be in the standard library" header.
Sounds cool, let the mods know about it. If they don‚Äôt want to clutter the sub with a bunch of these challenges, could always just start a discord and whoever‚Äôs actually interested could join
You could block allocate but keep track of what slots are free: Allocate block of 64 objects and add uint64 variable to block header which signifies which objects are in use. Allocator then contains std::vector of pointers to allocated blocks and iterator/index of block that contains free space. When block is freed, it zeroes its bit in uint64 and if it was first object freed in the block, the block pointer in vector is swapped with the last block pointer that is full and iterator/index of first free block is decremented. Allocations can just always check the last block pointer in the vector and if it doesnt have space then allocate a new block. If a block becomes full then it can be swapped with the first block pointer with free space and iterator/index to the first free can be incremented.
Can you give more detail about what the profiler's results were? Was the "&gt;30%" based on the entire amount of time between when you call `new` and when it returns, or is it specifically the time spent switching in and out of kernel code? Also, what is the lifetime distribution like? Do you have a majority of the objects deallocated at a certain point, but a few longer-lived ones scattered around that prevent you from just throwing everything into an arena?
Everytime I need to work with strings I get the desire to write my own string class. The class is just too badic so work with it productively
No, every platform needs a different executable. It would be totally infeasible.
Is that really necessary?
The "problem" is that by C's design any numbers that fit in a register (what "int" is intended to be) shouldn't overflow. 32-bit + 32-bit on a 64-bit machine _shouldn't_ overflow, but it does because there are too many variable sizes supported on a standard 64-bit machine to allow for "int" to be the register size like was intended.
I certainly don't agree with the post you answered to, but I'd like to point out that std::list has a sort member function. The general reason, why some containers have member functions that others don't is that it e.g. can be implemented more efficiently that way than the equivalent standard algorithm (list.sort swaps pointers and list isn't random access anyway). String is it's own beast anyway
NotUniqueOrSpecial already gave a couple of good points. That aside, I'd say that day to day c++ programming would be much more enjoyable if the committee would put a stronger focus on making common operations simpler to spell and read.
My concern with this kind of method (i.e. returning bool) is that it often would be likely followed by operations that would like to get a substring or similar, and then the operation would be essentially duplicated. &amp;#x200B; I'd much rather see a method with a signature of `std::optional&lt;size_type&gt;(std::string_view)` or similar that would enable chaining of operations without the duplication of the find/contains operation.
wg21.link/namespace.future and wg21.link/namespace.posix are what we were looking for. Right above the section I linked before. I.e. `stdx` is fine to use, and `^std[0-9]*$` and `^posix$` are reserved for the standard.
 if (intMap.find("Hello Super Long String")) wait, what?
I find \`.then\` on new line indented with 1 indent to work best, e.g. allows easier refactoring and extension auto my_promise = foo() .then([](int a) { return a + 1; }) .then([](int b) { return b * 2; }) ;
it's all monads when you dig deep enough :p
Indeed, I use join a lot more than split!
Also, why is the const char* variant not 'noexcept' like the others? If it is to throw in case of nullptr, I think it should rather just return false on a null pointer input and be noexcept.
If the system calls are an issue, you could try [tuning malloc to fit your needs](https://www.gnu.org/software/libc/manual/html_node/Malloc-Tunable-Parameters.html), i.e. let it allocate more memory, when it needs to grow its pool. This will waste a bit of memory, but should do fewer system calls. I don't know of a system call that returns you multiple chunks, that can be returned individually, so I can only reiterate that implementing a custom allocator could solve your system call overhead. You still have to make a tradeoff of how much memory you waste, but in the case of Factorio, using something like 4MiB chunks instead of 128kiB or less, that I think malloc uses, should still improve system call overhead by a lot, with only a marginal cost to memory. I'd also check, which system call you are actually waiting on. Maybe you checked already, but it could also be thread synchronization in malloc or maybe something completely different. I'd say, start playing around with the `M_TOP_PAD` environment variable and then explore other options.
I find the examples under "Unintentionally Defined Macros" hard to follow. Does the code show the contents of one or two files? What does `//...// my_source.cpp` mean?
And what exactly should split do? Return a list of strings? Or a vector of strings? Or a vector of string_views into the input string? Or a lazily evaluated range of string_views? Should it support quoting of delimiters? Or escaping? Or both? If so, should it unquote / unescape? What should it do with subsequent delimiters or with a delimiter at the end? Yield an empty string? Ignore? Throw? ... etc.
It's a map of ints, the keys are strings.
But `find()` retuns an iterator which doesn't evaluate to bool, does it?
I see what you mean here, and yes, we do plan to have UE4 support / C++ in Rider some time soon. Rider C++ will especially target Unreal Engine case. Debugger for MSVC code (both for Rider C++ and CLion) is also in development right now. We have to reimplement from scratch, doing this now on top of LLDB.
&gt;What does &gt; &gt;//...// my\_source.cpp &gt; &gt; mean? there are several places in examples where newlines are missing, here it is 2 lines `// my_header.hpp` `#define DO_MY_THING 1` `//...` `// my_source.cpp` `// The source does _not_ include my_header.hpp` there are also other cases, e.g. `#define BMBF_LINUX() 0void clear_temp_directory() {` which instead is 2 lines: `#define BMBF_LINUX() 0` `void clear_temp_directory() {`
Split is just *begging* to be a view type. But you could have an "old fashioned" version that takes an output iterator that could be a `back_inserter`.
Probably because constructing a string\_view from a const char\* requires it to scan the whole string to find the length.
So does a ‚Äúcontains‚Äù method though
Look into functional programming. Haskell would be a great place to start, but there's also Scala. Leveraging your math background to understand the category theoretical concepts that make functional languages tick would give you a real edge compared to the average programmer. Frankly, functional programming is the future and anyone that says differently is kidding themselves.
&gt; It was more about seeing things implemented with different tool sets. That won't be nearly as much time suckage since no one would be particularly expected to be super-clever about the algorithm itself. Just a reasonable implementation would be fine. It was more about seeing how the tools are used to do that implementation. Surely there are very many useful things lying in boost that are known by only a small fraction of people. It's amazing to see that some common problems can be solved in just few lines if you know the right library.
Not necessarily. Having a const char\* overload leaves more options open for the implementers to do something clever. They might for instance want to abort the calculation of the string length prematurely if it is found that it exceeds this-&gt;length().
Not only more efficiently. You can't use `std::sort` with `std::list::iterator` at all, because they're not random access iterators.
Presumably for consistency with other similar member functions of `std::basic_string`. The ones taking a pointer have a precondition that the pointer points to a null-terminated array of characters. There's a rule of thumb in the std::lib that functions with preconditions are not `noexcept` (a rule I dislike, but apparently I'm not allowed to be King of All C++ and decide such things all by myself, _harrumph_).
Yes. I think people get easily confused because one _can_ run Linux container on a Windows host. This however had to be implemented by Docker and Microsoft which is why I don't believe it is going to happen for Windows-container-on-Linux-host scenario.
And I mentioned that. Or are you saying list wouldn't have gotten the sort member function if std::sort would accept bidirectional iterators?
Ugh, no I just can't read and/or didn't see the "and list isn't random access anyway" part, sorry.
C++ really needs extension methods (like C#) so devs don't have to wait around for functionality to be added directly to types outside of their control. Currently the only alternative is free functions, but that is syntactically a nightmare compared to the alternative (most of the time).
&gt;I learned Javascript day in and day out, which has really afforded me the opportunity to get the job I have Then you're a professional software developer with experience under your belt - don't go for entry-level jobs. Most of being a developer has nothing to do with languages: * Communication skills * Version control * Documentation * Logical reasoning * Debugging strategies Your CV says you already have these qualities (implicitly), so what about C++? Create some public Git repos and start filling them with personal projects, it doesn't matter how useful they are, only that they show off architectural and language skills. Once you have some projects that you are proud off, send out your CV *clearly pointing to your repos*. Your CV shows that are a *professional* developer, your repos how that know the language enough to be useful quickly. &amp;#x200B; &gt;... and I am not going to a prestigious school I can't speak for the US, but here in the UK - no one gives a shit. Seriously, a prestigious school proves you have rich parents, *nothing else*. I, and every engineer I've ever met, will take someone who can show me C++ over someone who can show me a certificate.
Source is available here: [https://github.com/monsdar/katacoda-scenarios](https://github.com/monsdar/katacoda-scenarios) Feel free to contribute. Think this is an awesome way of learning about a technology like Conan.
&gt; Why is there such a high fence to jump for C++? Unnecessary complexity introduced by academics. Most of the industry does not use all these useless features
I did physics and was in a similar situation as you. I took a poorly-paying but fascinating job as an applied mathematician for a CAD company. Learned C++ well. Learned the whole CS curriculum well. Now I have an exhausting job at a bank that pays bonkers cash. You‚Äôll do well if you find a niche and push yourself to become the best.
Go directly to the system and map an address space. If it exceeds the page size it will automatically grow, and you can de-allocate pages. Now you can placement new your objects as needed. If you free any of them, keep a free list (which can be directly in the free memory). no need for any malloc.
oh, duh. Probably just an error on the writers' part, he uses the correct find("") != x.end() format in the next code sample.
Hmm, very interesting! Well, one can hope. I do think it would be in Microsoft (and Docker's) interest if this would work and Microsoft has been very active in the area of Linux in the last few years.
This is impressive. I‚Äôm tempted to start a long pull and replace all macro flags in my project with these. Any reason not to? What are the gotchas?
FYI just a few formatting issues in the code samples where there needs to be a newline: `#define BMBF_LINUX() 0void clear_temp_directory() {` `#define BMBF_PERFORMANCE_IMPROVEMENTS() 1void my_function() {` `#define BMBF_TARGET_OS_PRIVATE_DEFINITION_LINUX() 0#define BMBF_WITH_FEATURE(X) BMBF_WITH_FEATURE_PRIVATE_DEFINITION_##X()`
&gt; std::list has a sort member function Ah, yeah, I'd forgotten. Just another knock against his empty call-to-consistency, though. As for everything else, I totally agree.
IFIAKÔºåCLion only supports remote building and remote deployment. That is, store project sources in your local server, and configure remote tool chains to build remotely. Then CLion would sync files using sftp. Please tell me if I‚Äôm wrong.
Hey - author here. Apologies for the newline issues throughout the examples in the article. I've reached out to Jonathan and hopefully they'll be addressed soon.
I think there are no downsides
Thanks for the great article!
The biggest gotcha we've hit so far has been dealing with legacy tools that don't support function-like macros. If you have headers that are shared between your C++ and other tools (Rez on macOS or RC on Windows, for example) you have to have a hybrid solution that uses straight macros in the old tools and function-like macros in the compiler. Other than that, the number of gotchas in our code has dropped considerably! If you do find any, though, please reach out.
Awesome. I guess C++ support in Rider will be based on Resharper C++?
Moving find() out of string has been a monumental task in itself. npos is a hold over from the 1980's before STL. Find needs to be moved out of string and deprecated. &amp;#x200B; No one said it was controversial, I'm saying it isn't necessary, and not consistent with the direction of C++. It also adds another linkage issue with shared libraries and DLL's that has to be exported. &amp;#x200B; isupper(), islower(), hasupper(), haslower() could all be used as the same argument you're making. They're all unnecessary. &amp;#x200B; You're being ridiculous over this issue. You obviously know C++ doesn't need it, yet you're advocating for it, and you want to go against the overall simplicity. &amp;#x200B; STL is supposed to contain algorithms, iterators, containers, and functions. If we take the set of requirements, contains() is a what? It is a algorithm for searching. &lt;algorithm&gt; already has everything necessary, where it should belong. Moving find() to algorithm would be appropriate. I can tell you're young, and very inexperienced. I would recommend you learn the history. &amp;#x200B; Having the std set of templates has been like pulling teeth since the 1990's. Now, inexperienced developers that do not understand the fundamental issues want to break it, add complexity for complexity sakes. Thanks, really appreciate that.
I mean, I don't think it's insane at all to export all functions that aren't marked static. Thats the only sane option.
[removed]
Your comment has been automatically removed because it appears to contain disrespectful profanity or racial slurs. Please be respectful of your fellow redditors. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Vulgar%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/btpsvh/string_contains_member_function_proposal/ep5dzac/?context=3.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I just checked with the recruiter and all the Frankfurt teams that were hiring have filled their open positions for now I'm afraid - no immediate plans for that to change that I know of.
What's with the aggressive overlay? Why do I have to sign up to/for something without being given the chance to find out what I'm actually signing up for?
yes, another hold over from before STL. It needs to be deprecated.
If you are good at math, you can help out with Boost.Math. We need a reverse-mode automatic differentiation, an FFT, Hamiltonian Monte-Carlo integration, higher dimensional interpolators, and a large number of digital filters. &amp;#x200B; I also like to think I'm a very polite code reviewer and help people get past the problems they hit! &amp;#x200B; I can say with 100% certainty that if you do any of these, no C++ shop will even ask you if you graduated from college.
The aggressive overlay is definitly a no go for me, on mobile it blocks the whole site.
Is N a fixed number? Is N very very large? 6000 bytes isnt very large compared to 64bit address spaces. Are you sure the slowness is from system call time? Is this a normal unix/windows system? Have you run using 'perf'? Are you using a standard heap or jemalloc? &amp;#x200B; I've worked on projects that regularly churn ( allocate/process/free) 400mm jobs per minute. We used to use jemalloc, but later switched that processing to a pool allocator, and later our own arena-style allocator. Since that switch, our profiles are almost always in processing time vs allocation time. This specific ask about returning to the OS seems confused. Most heap allocators only deal with contiguous blocks, and often the minimum block size is 64k, and usually larger. Id be very surprised if there was a system did anything useful with a 'hole-y' space. &amp;#x200B; &amp;#x200B; One 'cheap' and easy trick you might try, if you have a good idea what N might be - \- allocate one big chunk of N \* 6000 bytes - BALLAST \- allocate one extra 'guard' chunk ( 64k ) - GUARD \- free BALLAST \- allocate your individual chunks. \- note - its entirely possible your heap will defeat the pre-sizing offered by the heap.
DM the repo and I'll take a whack. I saw boostorg/math?
Ok, I have clearly reread the linked conversation and indeed there might be some interesting thing in it. More precisely: if a class is non-trivial to copy/destroy does implementing `= default` in a source file speeds up compilation vs `= default` OR none (rule of 0) in a header file? On one side rule of 0 means no code to write but on the other - default generated member functions may be much bigger than what you would usually put in an inline implementation. I wonder if compilers have actually any compilation optimization for such code - eg whether a struct that contains few string just refers to string copy ctor or indeed reinstantiates it in every source file where the struct is used.
Yeah, it takes time, but if you would learn C++98 you would cover like 80-90%% of what you need to know about C++, the rest are (obviously) improvements to that. You might also look ahead and skip what was deleted in latter revisions. One year should be enough to apply for a job, but it depends on a person really. Checkout these links: * Changes between C++11 and C++14: [http://open-std.org/JTC1/SC22/WG21/docs/papers/2018/p1319r0.html](http://open-std.org/JTC1/SC22/WG21/docs/papers/2018/p1319r0.html) * Changes between C++14 and C++17: [https://isocpp.org/files/papers/p0636r0.html](https://isocpp.org/files/papers/p0636r0.html) Also, before applying, google "C++ interview questions", works every time. Protip: those guys asking questions on interview googled that too. Good luck.
Haha, good look. I took a year of C and C++ courses at college. The only things I would need to work on are templates and just the general STL. Vectors, Queues, etc. I did member operator overloading, OOP, and pointer arithmetic. I'm sure there is way more to learn and right now I have the base to dive into Java, C++, Javascript, C really deep a d I think C++ would yield the best return on knowledge and usability in industry.
[https://github.com/boostorg/math](https://github.com/boostorg/math) &amp;#x200B; Another idea is to finish off the Taylor methods for ODEs in Boost.ODEInt. This one has the benefit(?, maybe not?) of being halfway done: &amp;#x200B; [https://github.com/headmyshoulder/taylor](https://github.com/headmyshoulder/taylor)
You can't use the STL one as-is. STL `sort()` requires random-access iterators, which `std::list` doesn't have.
No, you are doing it wrong, you should almost always use auto! Auto auto auto auto. Auto auto you auto auto auto.
I'll just go ahead and start one. No matter how many up-votes this gets, if no one else bothers to contribute, then we know the answer is really no. If it goes well, maybe we can get the mods to get involved and start doing it regularly.
Thanks for the article .. it's useful for even us dinosaurs.
 // // Toolset: // 1. CIDLib // // Assumptions: // 1. No more than 64K-1 unique URLs // #include "CIDLib.hpp" // --------------------------------------------------------------------------- // For this simple program, start main thread on a global // --------------------------------------------------------------------------- tCIDLib::EExitCodes eMainThreadFunc(TThread&amp;, tCIDLib::TVoid*); CIDLib_MainModule(TThread(L"Interview1MainThread", eMainThreadFunc)) // --------------------------------------------------------------------------- // Test data. Given this data,the answer should be: // // 1. https://bogusworld.net/home.html // 2. http://bogusworld.net/interviews.html?v=43 // 3. http://bogusworld.net/interviews.html?v=53 // --------------------------------------------------------------------------- struct TRawAccessItem { const TString m_strCust; const TString m_strURL; const tCIDLib::TCard4 m_c4TimeOfs; }; static const TRawAccessItem aitemsTestData[] = { { L"Carly Gauss" , L"https://bogusworld.net/home.html" , 20 } , { L"Lenny Oiler" , L"http://bigeyedfish.net/index.html" , 5 } , { L"Lenny Oiler" , L"http://bigeyedfish.net/signup.php" , 45 } , { L"Stevie Hawkley" , L"http://makebigbucks.com/login.php?id=none" , 60 } , { L"Stevie Hawkley" , L"http://makebigbucks.com/login.php?id=644" , 68 } , { L"Stevie Hawkley" , L"http://makebigbucks.com/ripoff.php" , 48 } , { L"Lenny Oiler" , L"http://bigeyedfish.net/Walleye.html" , 45 } , { L"Carly Gauss" , L"http://bogusworld.net/interviews.html?v=43" , 20 } , { L"Carly Gauss" , L"http://bogusworld.net/interviews.html?v=53" , 24 } , { L"Stevie Hawkley" , L"http://makebigbucks.com/ripoff.php" , 58 } , { L"Lenny Oiler" , L"http://bogusworld.net/signup.php" , 20 } , { L"Lenny Oiler" , L"http://bigeyedfish.net/Nemoids.html" , 92 } }; static const tCIDLib::TCard4 c4RawItemCount = tCIDLib::c4ArrayElems(aitemsTestData); // --------------------------------------------------------------------------- // Unique id counters for customers and URLs. They can't be zero! // --------------------------------------------------------------------------- static tCIDLib::TCard4 c4NextCustId = 1; static tCIDLib::TCard4 c4NextURLId = 1; // --------------------------------------------------------------------------- // To convert customers and URLs to unique ids, we create a very simple struct // that has a string and the unique id assigned to it. // --------------------------------------------------------------------------- struct TUniqueStr { TUniqueStr() = delete; TUniqueStr(const TString&amp; strVal, const tCIDLib::TCard4 c4Id) : m_strVal(strVal) , m_c4Id(c4Id) { } TString m_strVal; tCIDLib::TCard4 m_c4Id; }; // --------------------------------------------------------------------------- // Two keyed hash sets of the above struct. Use a lambda for the key extraction // callback. Key ops object is providing hashing. // --------------------------------------------------------------------------- using TUStringSet = TKeyedHashSet&lt;TUniqueStr, TString, TStringKeyOps&gt;; static TUStringSet colUniqueCust ( 509 , new TStringKeyOps(kCIDLib::False) , [](const TUniqueStr&amp; ustrCur) -&gt; const TString&amp; { return ustrCur.m_strVal; } ); static TUStringSet colUniqueURL ( 509 , new TStringKeyOps(kCIDLib::False) , [](const TUniqueStr&amp; ustrCur) -&gt; const TString&amp; { return ustrCur.m_strVal; } ); // --------------------------------------------------------------------------- // Our view of the data, with customers and URLs converted to unique ids. We // can construct from a raw test data object. We create a vector of these to // load the test data into. // --------------------------------------------------------------------------- class TAccessItem { public : TAccessItem() = delete; TAccessItem(const TRawAccessItem&amp; itemSrc) : m_c4TimeOfs(itemSrc.m_c4TimeOfs) { // Use a private helper to find or add the two strings and store the ids m_c4CustID = c4AddOrUpdate(colUniqueCust, itemSrc.m_strCust, c4NextCustId); m_c2URLID = tCIDLib::TCard2 ( c4AddOrUpdate(colUniqueURL, itemSrc.m_strURL, c4NextURLId) ); } tCIDLib::TCard4 m_c4CustID; tCIDLib::TCard2 m_c2URLID; tCIDLib::TCard4 m_c4TimeOfs; private : // Find the string or add it and assign the next unique id from counter tCIDLib::TCard4 c4AddOrUpdate( TUStringSet&amp; colList , const TString&amp; strNew , tCIDLib::TCard4&amp; c4Counter) { tCIDLib::TCard4 c4RetId; const TUniqueStr* pustrTest = colList.pobjFindByKey(strNew); if (pustrTest) { c4RetId = pustrTest-&gt;m_c4Id; } else { c4RetId = c4Counter++; TUniqueStr ustrNew(strNew, c4RetId); colList.objAdd(ustrNew); } return c4RetId; } }; using TAccessList = TVector&lt;TAccessItem&gt;; static TAccessList colAccessItems; // --------------------------------------------------------------------------- // Program entry point // --------------------------------------------------------------------------- tCIDLib::EExitCodes eMainThreadFunc(TThread&amp; thrThis, tCIDLib::TVoid*) { // We have to let our calling thread go first thrThis.Sync(); TTextOutStream&amp; strmOut = TSysInfo::strmOut(); // Load test data to our massaged form. If we max out URL ids, give up for (tCIDLib::TCard4 c4Index = 0; c4Index &lt; c4RawItemCount; c4Index++) { colAccessItems.objAdd(TAccessItem(aitemsTestData[c4Index])); if (c4NextURLId == kCIDLib::c2MaxCard) { strmOut &lt;&lt; L"Maximum unique URLs reached, not all data will be processed" &lt;&lt; kCIDLib::EndLn; break; } } ...continued...
 .... continued ... // // Now sort by the time, we use a lambda for the comparator. As mentioned // above, this is just sorting pointers, not the whole objects. // colAccessItems.Sort ( [](const TAccessItem&amp; item1, const TAccessItem&amp; item2) -&gt; tCIDLib::ESortComps { if (item1.m_c4TimeOfs &lt; item2.m_c4TimeOfs) return tCIDLib::ESortComps::FirstLess; else if (item1.m_c4TimeOfs &gt; item2.m_c4TimeOfs) return tCIDLib::ESortComps::FirstGreater; return tCIDLib::ESortComps::Equal; } ); // // Here are a little clever. We will build up a list of all three page // sequences found (to fcolAssSeqsList.) We encode them into a 64 bit // value as 0000 firstpage secpage thirdpage. So all we need is a single // 64 bit value per customer. We create each new sequence by shifting // that customer's value left and masking in the new page id. Once the // firstpage word becomes non-zero we have enough pages for this customer // to start storing sequences. We aren't trying to ignore dups here. // TFundVector&lt;tCIDLib::TCard8&gt; fcolAllSeqsList; { // // A list with one 64 bit value per unique customer. Each customer's // value is at customerid-1 in this list. // TFundArray&lt;tCIDLib::TCard8&gt; fcolCustSeqList(c4NextCustId); { // Iterate our time sorted list of data via cursor TAccessList::TCursor cursSorted(&amp;colAccessItems); for (; cursSorted; cursSorted++) { const TAccessItem&amp; itemCur = *cursSorted; // Udpate this customer's current sequence tCIDLib::TCard8 c8Seq = fcolCustSeqList[itemCur.m_c4CustID - 1]; c8Seq &lt;&lt;= 16; c8Seq |= itemCur.m_c2URLID; c8Seq &amp;= 0xFFFFFFFFFFFF; fcolCustSeqList[itemCur.m_c4CustID - 1] = c8Seq; // If we are now into valid sequences for this customer, keep it if (c8Seq &amp; 0xFFFF00000000) fcolAllSeqsList.c4AddElement(c8Seq); } } } // // Not sort all the sequences. We are just sorting 64 bit values, so not // to heavy. Again, a lambda for sort comparator. // fcolAllSeqsList.Sort ( [](const tCIDLib::TCard8&amp; c81, const tCIDLib::TCard8 c82) -&gt; tCIDLib::ESortComps { if (c81 &lt; c82) return tCIDLib::ESortComps::FirstLess; else if (c81 &gt; c82) return tCIDLib::ESortComps::FirstGreater; return tCIDLib::ESortComps::Equal; } ); // // Now count adjacent dups to get the count for each unique sequence. // Remember the last best one as we go. We don't bother if there is a // tie, we use the first one one we find. // tCIDLib::TCard8 c8LastBestSeq = 0; { tCIDLib::TCard4 c4LastBestCount = 0; const tCIDLib::TCard4 c4AllSeqCount = fcolAllSeqsList.c4ElemCount(); tCIDLib::TCard4 c4Index = 0; while (c4Index &lt; c4AllSeqCount) { const tCIDLib::TCard8 c8CurSeq = fcolAllSeqsList[c4Index++]; tCIDLib::TCard4 c4RunCount = 1; while (c4Index &lt; c4AllSeqCount) { // If not the same, we are done for this one, else bump values const tCIDLib::TCard8 c8NextSeq = fcolAllSeqsList[c4Index]; if (c8NextSeq != c8CurSeq) break; c4RunCount++; c4Index++; } // If this count is better than the last, then take this one if (c4RunCount &gt; c4LastBestCount) { c4LastBestCount = c4RunCount; c8LastBestSeq = c8CurSeq; } } } // // And, now we have the most used sequence. If we want to get the actual // URLs, we'll have to go back and find these URL ids in the unique URL list. // // We pay a little at this point for our optimization above since we can // do no better here than just bull through the whole unique URL list and // look for the matching ids, since that relationship was lost above. // TString strURL1; TString strURL2; TString strURL3; { // Break out the three page ids for convenience below const tCIDLib::TCard4 c4URL1 = (c8LastBestSeq &amp; 0xFFFF00000000) &gt;&gt; 32; const tCIDLib::TCard4 c4URL2 = (c8LastBestSeq &amp; 0xFFFF0000) &gt;&gt; 16; const tCIDLib::TCard4 c4URL3 = (c8LastBestSeq &amp; 0xFFFF); // // Stop once we find our three guys, no need to do the whole thing // in most cases. // tCIDLib::TCard4 c4Found = 0; TUStringSet::TCursor cursURLs(&amp;colUniqueURL); for (; cursURLs &amp;&amp; (c4Found &lt; 3); ++cursURLs) { const TUniqueStr&amp; ustrCur = *cursURLs; if (ustrCur.m_c4Id == c4URL1) { strURL1 = ustrCur.m_strVal; c4Found++; } else if (ustrCur.m_c4Id == c4URL2) { strURL2 = ustrCur.m_strVal; c4Found++; } else if (ustrCur.m_c4Id == c4URL3) { strURL3 = ustrCur.m_strVal; c4Found++; } } } // And let's display them strmOut &lt;&lt; L"\nThe top three page sequence is:\n" &lt;&lt; L" 1. " &lt;&lt; strURL1 &lt;&lt; kCIDLib::NewLn &lt;&lt; L" 2. " &lt;&lt; strURL2 &lt;&lt; kCIDLib::NewLn &lt;&lt; L" 3. " &lt;&lt; strURL3 &lt;&lt; kCIDLib::NewLn &lt;&lt; kCIDLib::EndLn; return tCIDLib::EExitCodes::Normal; }
Us dinosaurs have to stick together!
Is it possible to use feature macros but to set them from the build system (whatever that may be), rather than directly in the code. With a plain macro, one can pass e.g. -DFEATURE=1, is there an equivilent with feature macros?
Yeah, I've only been shipping commercial software for 35 years. I get these new kids fresh out of school who like to tell me how evil I am for having a raw pointer in my code.
Knowing a programming language or several itself is not very definitional to an engineer in my opinion. A lot of it is being resourceful in coming up with solutions, using available solutions, documenting appropriately, diagnosing issues, and having a good intuition about how a system will behave in the future. You‚Äôre still in the phase of learning the tools, which is obviously critically important. Engineers that don‚Äôt understand how to use a debugger, inspect a stack trace, or have a good workflow are essentially handicapped. As such you will always be learning tools (new and old) throughout your entire career and occasionally writing them when appropriate. That said, this won‚Äôt help you with all the skills mentioned at the start of this paragraph (the intuition part). I would recommend actually building things to build that intuition. If you like C++ and you like the power it affords, you necessarily should choose something where performance is critical. As a former physics/math guy, I naturally found my way into graphics programming but have more or less spiraled from there into lots of other areas. The tools are wildly different but the problem solving faculties are the same.
Author here. I like `auto`. Especially since my main language nowadays is Kotlin. Honestly, I used it here because it looks better. The comment is there because it's a readme, and I wanted to make it clear for readers what the returned type was. In regular code it would be given by the context. With `fmi4cpp` , an `fmu` returns a `model_description` while a `cs_fmu` and `me_fmu` returns specialized `model_description` instances with additional data.
&gt; Be sure to sort by Old, instead of New, so that continuations show up in the right order and sequentially. I suggest posting continuations as separate comments, or linking out to a separate pastebin-style site.
very helpful, thanks a lot.
If the code isn't here, I'm not sure many people will bother to even look.
Would be helpful, if you could offer some meaningful test data. In your example, there aren't any sequences that occur more than once.
http://eel.is/c++draft/range.split http://eel.is/c++draft/range.join
Unless you are going to actually run it, I don't think it really matters. We know what the form of the data could be in a real scenario, so everyone can convince themselves (or not) that any given implementation would deal with such. I didn't want some long list because it's already too many lines anyway. If someone really wants to test anyone's implementation, they can easily add more data if they want.
I know this is /r/cpp, but my first inclination is to use SQL. Edit: example when I'm at a computer and not a phone, maybe.
Standard library only. Maybe I'm misunderstanding the challenge? Only tested with small samples, but as long as the set of all sequences that actually occur fit in memory this should work? Assumptions: * Either fairly small (low thousands) number of URLs _or_ most sequences of URLs don't occur (otherwise not everything fits into memory anymore... it'd be trivial to adapt this to work on disk, but that'd make it _really_ slow) * visiting the same page multiple times in a row counts as a sequence (trivial to filter out, but it wasn't obvious to me that this isn't valid) Also, requires C++17. Again, easy enough to adapt all the way down to C++98 if you want to (although then you'd have to drop `unordered_map` for `map`). ``` #include &lt;cinttypes&gt; #include &lt;vector&gt; #include &lt;algorithm&gt; #include &lt;unordered_map&gt; #include &lt;stdexcept&gt; // "dummy" types; although I imagine IRL they'd not // look too different from this, or otherwise it'd be fairly // easy to squeeze input values into these enum class timestamp_t : std::int64_t {}; enum class time_delta_t : std::int64_t {}; enum class url_id_t : std::uint64_t {}; enum class customer_id_t : std::uint64_t; [[nodiscard]] std::int64_t as_integer(timestamp_t timestamp) { return static_cast&lt;std::int64_t&gt;(timestamp); } [[nodiscard]] std::uint64_t as_integer(url_id_t url_id) { return static_cast&lt;std::uint64_t&gt;(url_id); } [[nodiscard]] time_delta_t get_delta_time(timestamp_t first, timestamp_t second) { if(first &gt; second) { std::swap(first, second); } return time_delta_t { as_integer(second) - as_integer(first) }; } struct access_t { timestamp_t timestamp; customer_id_t customer_id; url_id_t url_id; }; struct url_visit_sequence_t { url_id_t first; url_id_t second; url_id_t third; [[nodiscard]] bool operator==(url_visit_sequence_t other) const { return first == other.first &amp;&amp; second == other.second &amp;&amp; third == other.third; } }; namespace std { template&lt;&gt; struct hash&lt;url_visit_sequence_t&gt; { // I make no claims that this is a good hash function. // Probably isn't. [[nodiscard]] std::size_t operator()(const url_visit_sequence_t&amp; sequence) const { auto const int_hash = std::hash&lt;std::uint64_t&gt;{}; auto hash = int_hash(as_integer(sequence.first)); hash = (hash &lt;&lt; 16) ^ int_hash(as_integer(sequence.second)); hash = (hash &lt;&lt; 16) ^ int_hash(as_integer(sequence.third)); return hash; } }; } // this could also take a reference if you really care about not creating another copy /// Get the most frequently accessed triple of sequential accesses of different urls by the same customer /// \param accesses all accesses, must be non-empty // \param max_delta_time The maximum amount of time between two accesses for them to still count as a sequence url_visit_sequence_t get_most_frequent_sequence(std::vector&lt;access_t&gt; accesses, time_delta_t max_delta_time) { if(accesses.empty()) { throw std::runtime_error{"cannot get largest access sequence out of empty list of accesses"}; } // sort everything by customer std::sort(accesses.begin(), accesses.end(), [](auto const&amp; lhs, auto const &amp;rhs) { return lhs.customer_id &lt; rhs.customer_id; }); auto sequence_score = std::unordered_map&lt;url_visit_sequence_t, std::uint64_t&gt;{}; auto customer_access_begin = accesses.begin(); while(customer_access_begin != accesses.end()) { auto const customer_id = customer_access_begin-&gt;customer_id; // find the last access of this customer auto const customer_access_end = std::find_if_not( customer_access_begin, accesses.end(), [customer_id](auto const&amp; access) { return access.customer_id == customer_id; }); // sort this customers accesses by timestamp std::sort(customer_access_begin, customer_access_end, [](auto const &amp;lhs, auto const &amp;rhs) { return lhs.timestamp &lt; rhs.timestamp; }); auto first = customer_access_begin; while(first != customer_access_end) { auto const second = std::next(first); if(second != customer_access_end &amp;&amp; get_delta_time(customer_access_begin-&gt;timestamp, second-&gt;timestamp) &lt;= max_delta_time) { auto const third = std::next(second); if(third != customer_access_end &amp;&amp; get_delta_time(second-&gt;timestamp, third-&gt;timestamp) &lt;= max_delta_time) { ++sequence_score[url_visit_sequence_t{first-&gt;url_id, second-&gt;url_id, third-&gt;url_id}]; } } // could occasionally skip two here actually, didn't bother here first = second; } customer_access_begin = customer_access_end; } return std::max_element( sequence_score.begin(), sequence_score.end(), [](auto const &amp;lhs, auto const &amp;rhs) { return lhs.second &lt; rhs.second; })-&gt;first; } // --------------------------------------------- // testing // -------------------------------------------- #include &lt;iostream&gt; std::ostream&amp; operator&lt;&lt;(std::ostream&amp; out, const url_visit_sequence_t&amp; sequence) { return out &lt;&lt; as_integer(sequence.first) &lt;&lt; ", " &lt;&lt; as_integer(sequence.second) &lt;&lt; ", " &lt;&lt; as_integer(sequence.third); } int main() { auto const monday = timestamp_t{0}; auto const tuesday = timestamp_t{1}; auto const wednesday = timestamp_t{2}; auto const thursday = timestamp_t{3}; auto const friday = timestamp_t{4}; auto const saturday = timestamp_t{5}; auto const sunday = timestamp_t{6}; auto const frank = customer_id_t{1}; auto const john = customer_id_t{2}; auto const alfred = customer_id_t{3}; auto const home = url_id_t{1}; auto const shopping_cart = url_id_t{2}; auto const checkout = url_id_t{3}; auto const login = url_id_t{4}; auto const logout = url_id_t{5}; auto const accesses = std::vector&lt;access_t&gt;{ {tuesday, frank, login}, {friday, john, logout}, {thursday, alfred, login}, {friday, alfred, home}, {wednesday, alfred, home}, {thursday, frank, shopping_cart}, {saturday, frank, logout}, {wednesday, john, login}, {friday, frank, checkout}, {thursday, john, home}, {saturday, alfred, shopping_cart}, {tuesday, john, home}, {wednesday, frank, home}, {monday,frank,home}, {sunday, alfred, logout} }; auto const most_frequent_sequence = get_most_frequent_sequence(accesses, time_delta_t{1}); // 1,4,1 because home/login/home is the most frequent sequence std::cout &lt;&lt; most_frequent_sequence &lt;&lt; '\n'; } ```
But is this case common enough (and slow enough) to deserve a dedicated optimization? After all, those who care about this can always take `s.data()` and do ad hoc optimization.
&gt;If you're going to have `split`, don't forget `join`! Both functions are in my "grr, these should be in the standard library" header. Yeah. And trim, for that matter. Basic functionality.
Any reason you are not using chrono for the time stamps?
No practical reason per se, I just wrote this without a reference and I pretty much never have reason to use `chrono` so I don't have its API memorised.
Would you mind converting the codestyle to use the 4 preceding spaces instead of triple-backticks so that it also works on the old reddit presentation?
While I'd like to see a solution using ranges-v3, here is a pretty simple solution only based on the standard library. There are a couple of things that could be polished and optimized ( in particular, use a more efficient data structure than `std::map`), but without having a realistic context and an idea about the problem size, I don't think that would be particularly useful: #include &lt;algorithm&gt; #include &lt;iostream&gt; #include &lt;map&gt; #include &lt;string&gt; #include &lt;string_view&gt; #include &lt;tuple&gt; #include &lt;vector&gt; struct AccessItem { std::string name; std::string url; int time_stamp; }; // clang-format off std::vector&lt;AccessItem&gt; test_data = { { u8"Carly Gauss" , u8"https://bogusworld.net/home.html" , 20 } , { u8"Lenny Oiler" , u8"http://bigeyedfish.net/index.html" , 5 } , { u8"Lenny Oiler" , u8"http://bigeyedfish.net/signup.php" , 45 } , { u8"Stevie Hawkley" , u8"http://makebigbucks.com/login.php?id=none" , 60 } , { u8"Stevie Hawkley" , u8"http://makebigbucks.com/login.php?id=644" , 68 } , { u8"Stevie Hawkley" , u8"http://makebigbucks.com/ripoff.php" , 48 } , { u8"Lenny Oiler" , u8"http://bigeyedfish.net/Walleye.html" , 45 } , { u8"Carly Gauss" , u8"http://bogusworld.net/interviews.html?v=43" , 20 } , { u8"Carly Gauss" , u8"http://bogusworld.net/interviews.html?v=53" , 24 } , { u8"Stevie Hawkley" , u8"http://makebigbucks.com/ripoff.php" , 58 } , { u8"Lenny Oiler" , u8"http://bogusworld.net/signup.php" , 20 } , { u8"Lenny Oiler" , u8"http://bigeyedfish.net/Nemoids.html" , 92 } }; // clang-format on int main() { // sort by group and access time and remove dupes std::sort( test_data.begin(), test_data.end(), []( const auto&amp; l, const auto&amp; r ) { return std::tie( l.name, l.time_stamp ) &lt; std::tie( r.name, r.time_stamp ); } ); test_data.erase( std::unique( test_data.begin(), test_data.end(), []( const auto&amp; l, const auto&amp; r ) { return std::tie( l.name, l.url ) == std::tie( r.name, r.url ); } ), test_data.end() ); // count frequencies of sequences with at least 3 entries using Sequence = std::tuple&lt;std::string_view, std::string_view, std::string_view&gt;; std::map&lt;Sequence, int&gt; sequ_frequ; for( int i = 0; i &lt; test_data.size() - 2; ++i ) { if( test_data[i].name != test_data[i + 2].name ) { continue; } ++sequ_frequ[Sequence { test_data[i].url, test_data[i + 1].url, test_data[i + 2].url} ]; } // Print out sequence with highest frequency auto max_el_it = std::max_element( sequ_frequ.begin(), sequ_frequ.end(), []( const auto&amp; l, const auto&amp; r ) { return l.second &lt; r.second; } ); std::cout &lt;&lt; std::get&lt;0&gt;( max_el_it-&gt;first ) &lt;&lt; '\n' &lt;&lt; std::get&lt;1&gt;( max_el_it-&gt;first ) &lt;&lt; '\n' &lt;&lt; std::get&lt;2&gt;( max_el_it-&gt;first ) &lt;&lt; '\n'; }
sure
Behold the elegance of c++17 standard library. Assumes problem fits in memory. #include &lt;cstdint&gt; #include &lt;vector&gt; #include &lt;array&gt; #include &lt;tuple&gt; #include &lt;map&gt; #include &lt;string&gt; #include &lt;string_view&gt; #include &lt;algorithm&gt; #include &lt;iostream&gt; int main() { struct access_t { std::string customer_id; std::string page_url; std::uint32_t timestamp; }; std::vector&lt;access_t&gt; accesses = { {"Carly Gauss" , "https://bogusworld.net/home.html" , 20}, {"Lenny Oiler" , "http://bigeyedfish.net/index.html" , 5}, {"Lenny Oiler" , "http://bigeyedfish.net/signup.php" , 45}, {"Stevie Hawkley", "http://makebigbucks.com/login.php?id=none" , 60}, {"Stevie Hawkley", "http://makebigbucks.com/login.php?id=644" , 68}, {"Stevie Hawkley", "http://makebigbucks.com/ripoff.php" , 48}, {"Lenny Oiler" , "http://bigeyedfish.net/Walleye.html" , 45}, {"Carly Gauss" , "http://bogusworld.net/interviews.html?v=43", 20}, {"Carly Gauss" , "http://bogusworld.net/interviews.html?v=53", 24}, {"Stevie Hawkley", "http://makebigbucks.com/ripoff.php" , 58}, {"Lenny Oiler" , "http://bogusworld.net/signup.php" , 20}, {"Lenny Oiler" , "http://bigeyedfish.net/Nemoids.html" , 92}, }; std::sort(accesses.begin(), accesses.end(), [](auto&amp; a, auto&amp; b) { return std::tie(a.customer_id, a.timestamp) &lt; std::tie(b.customer_id, b.timestamp); }); std::map&lt;std::array&lt;std::string_view, 3&gt;, std::size_t&gt; histogram; for (std::size_t i = 0; i &lt; accesses.size() - 2; ++i) { auto&amp; a = accesses[i ]; auto&amp; b = accesses[i + 1]; auto&amp; c = accesses[i + 2]; if (a.customer_id == b.customer_id) { ++histogram[{a.page_url, b.page_url, c.page_url}]; } } auto top = std::max_element(histogram.begin(), histogram.end(), [](auto&amp; a, auto&amp; b) { return a.second &lt; b.second; }); if (top == histogram.end()) { std::cout &lt;&lt; "\nNo top three page sequence exists." &lt;&lt; std::endl; return 0; } auto&amp; [a, b, c] = top-&gt;first; std::cout &lt;&lt; "\nTop three page sequence is:\n" &lt;&lt; " 1. " &lt;&lt; a &lt;&lt; "\n" &lt;&lt; " 2. " &lt;&lt; b &lt;&lt; "\n" &lt;&lt; " 3. " &lt;&lt; c &lt;&lt; std::endl; }
I don't think we even need to assume it's an actual time stamp. I assumed in mine that the collection of the data created basically just offsets from the start of collection time (seconds, or whatever.) That would be easy to do during collection and save work downstream in analysis.
As someone that only knows the barest minimum about SQL, I'm looking forward to see this.
I'm definitely no Big O kind of guy, and have't spent too much time really analyzing things in those terms. Maybe someone who is into such things can provide some comparative analysis of the scenarios presented. Is there any significant performance vs. resource usage vs compactness difference? For myself, I was leaning more towards efficiency, since I assume the data set could be pretty large.
I see we're had almost the same idea ;)
Great minds think alike :P
thanks! I've fixed the code, it should be ` != intMap.end()` of course.
I think of structured binding though. Much nicer than `std::get` (and I'm not sure, why I used tuple instead of an array for the sequence in the first place)
That would be a different challenge from the one you originally posted here. And would require actual benchmark data set.
Well, I don't know, and if the authors of the proposal are not sure that no sane implementation would ever want to do that I think they do a wise decision in leaving it up to the implementers to decide. Another argument is consistency with `find`. It makes sense that `contains` has the same complexity as `find` which is O(n \* m) where n is the length of the string you are searching and m is the length of the string that you search for. If n == 0 it means `find` is O(1). `contains` would technically also be O(1) but if there were no overload for `const char*` the combined complexity when taking the construction of the string\_view into account would be O(m). const char* s = ... std::string empty_str; empty_str.find(s); // O(1) empty_str.contains(s); // O(strlen(s)) if a string_view has to be created here
I'm sure someone here understands the rough order of magnitude of these implementations. A lot of folks are really into that kind of thing. It doesn't make any of them wrong either way, just applicable to different situations. If you don't have large data sets, then compactness might be more important. If you do, efficiency might be more important. If you actually were asked this in an interview, guessing roughly what the needs of that company are might lead you to present something at one end of the spectrum or another I guess. And knowing that sort of thing would be a good part of the 'for the newbies' aspect of this. It would be good for me for that matter, since, as I said, I'm not a Big O kind of guy. For all I know, maybe my optimizations didn't buy me that much comparatively.
Sorry if this is a stupid question, but what would you use instead of `uint32_t` in an actual application to represent time stamps?
Didn't you explicitly say in your original post that those code challenges shouldn't focus on clever algorithms?
alternatively you can preprocess the source using cpp before sending to Rez or RC
Algorithmic complexity is basic computer science. Mine, /u/kalmoc and /u/HKei's solutions use the same basic approach (though /u/HKei did two-level sorting for some reason), with `n*log(n)` time complexity (dominated by comparison sorting/map accesses). So it's down to constant factors and cache effects, and that definitely needs benchmarks. I don't feel like trying to comprehend your solution.
Any person may choose to do whatever they want along that spectrum. But, either way, I think it's useful to have some feeling for the relative trade-offs of any given implementation.
Well going along with the theme you could use a `time_point` or something from `&lt;chrono&gt;`
At my last job, I implemented the change of using = default in the cpp file for a few data types, and saw a small, but measurable, improvement in compile times. Considering it was a multi-million line of code codebase, it wouldn't have surprised me if diligently applying it to all of the data types in the "lower level" parts of the codebase would have resulted in a very significant (multiple hours per build) speedup. The most annoying part of the whole situation is that there was no way to turn it into a macro and just have people stamp the macro in the header file and be done with it. Since the macro text replacement happens in the parsing phase, and the decision of whether the type is trivially ***able or not happens later, there's no way to have one-macro to rule them all. I had considered making a multi-layered macro, that allowed for the "consumer" (aka, my co-worker programmars) to simply say the name of the type, and "true" or "false" to indicate if they expected the type to be trivially ***able, and then have the macro automatically 1) Statically assert on the trivialness, or lack there of. 2) If trivial, use = default in the header 3) If non-trivial, use = default in the CPP file. But I left that company before I had the time to properly code that up.
Toolset: Your favorite database engine (as long as it supports window functions), used to store the access log. I tested with sqlite. First, some sample data to work with: CREATE TABLE visits(user TEXT, url TEXT, timestamp INTEGER); -- Adjust as needed INSERT INTO visits VALUES('Bob','a',0); INSERT INTO visits VALUES('Bob','b',1); INSERT INTO visits VALUES('Bob','c',2); INSERT INTO visits VALUES('Bob','d',3); INSERT INTO visits VALUES('Joe','c',4); INSERT INTO visits VALUES('Joe','d',5); INSERT INTO visits VALUES('Bob','a',5); INSERT INTO visits VALUES('Bob','b',6); INSERT INTO visits VALUES('Joe','a',6); INSERT INTO visits VALUES('Bob','c',7); INSERT INTO visits VALUES('Bob','e',8); INSERT INTO visits VALUES('Joe','c',8); INSERT INTO visits VALUES('Joe','d',9); INSERT INTO visits VALUES('Joe','e',10); INSERT INTO visits VALUES('Bob','a',10); INSERT INTO visits VALUES('Bob','b',11); INSERT INTO visits VALUES('Bob','c',12); INSERT INTO visits VALUES('Joe','c',12); INSERT INTO visits VALUES('Joe','d',13); INSERT INTO visits VALUES('Joe','c',14); INSERT INTO visits VALUES('Joe','d',15); INSERT INTO visits VALUES('Joe','e',16); INSERT INTO visits VALUES('Bob','b',14); INSERT INTO visits VALUES('Bob','c',15); INSERT INTO visits VALUES('Bob','e',17); Using your database's C++ bindings, run the following query and do whatever you need to do with the results: WITH sequences AS -- Generate sequences of three URLS (SELECT user , lag(url, 1) OVER sorted AS url_1 , url AS url_2 , lead(url, 1) OVER sorted AS url_3 FROM visits WINDOW sorted AS (PARTITION BY user ORDER BY timestamp)) , counted AS -- Count repeats (SELECT user, url_1, url_2, url_3, count(*) AS num FROM sequences WHERE url_1 IS NOT NULL AND url_3 IS NOT NULL -- Filter out the end rows GROUP BY user, url_1, url_2, url_3) , ranked AS -- And number them in order of count (SELECT user, url_1, url_2, url_3, num , row_number() OVER (PARTITION BY user ORDER BY num DESC) AS rn FROM counted) -- Finally display the top three per user SELECT user, url_1, url_2, url_3, num FROM ranked WHERE rn &lt;= 3 ORDER BY user, rn; Sample results: user url_1 url_2 url_3 num ---------- ---------- ---------- ---------- ---------- Bob a b c 3 Bob b c e 2 Bob b c b 1 Joe c d e 2 Joe a c d 1 Joe c d a 1 Variation that finds overall most popular sequences, not most popular per user: WITH sequences AS -- Generate sequences of three URLS (SELECT lag(url, 1) OVER sorted AS url_1 , url AS url_2 , lead(url, 1) OVER sorted AS url_3 FROM visits WINDOW sorted AS (PARTITION BY user ORDER BY timestamp)) , counted AS -- Count repeats (SELECT url_1, url_2, url_3, count(*) AS num FROM sequences WHERE url_1 IS NOT NULL AND url_3 IS NOT NULL -- Filter out the end rows GROUP BY url_1, url_2, url_3) , ranked AS -- And number them in order of count (SELECT url_1, url_2, url_3, num , row_number() OVER (ORDER BY num DESC) AS rn FROM counted) -- Finally display the top three SELECT url_1, url_2, url_3, num FROM ranked WHERE rn &lt;= 3 ORDER BY rn;
Done.
In an application like this (some analyzer for existing data), you don't get to decide what the data is. But otherwise it depends on the requirements, `std::uint32_t` might be entirely reasonable. Maybe wrap it in `std::chrono::time_point`, as /u/ricco19 says.
One of the things that I found most surprising was the sheer number of instances of various symbols. I once write up a script that used nm and grep and such, to go through every .o file that we built, and show me the most commonly code-genned symbol out of the whole codebase. There were numerous such symbols that were being code genned a few thousand times each, and it was all thanks to people writing the constructor as = default in the header file (or, since a lot of the code was ancient, as inline TYPE::TYPE() {} ;)
MS got that one right, only export those symbols which are explicitly meant to be exported. This option just fixes their mistake of also exporting inline methods. Doesn't make sense as everyone has the definition anyway.
&gt;And `equal_range()` and be implemented in terms of `lower_bound()` and `upper_bound()`, With some loss of performance. `equal_range()` can calculate both iterators with the same loop.
Why add this for strings and not for other container classes? I use code like `find(v.begin(), v.end(), value) != v.end()` with vectors far more often then I search strings.
Nothing I could change I'm afraid. I'm not related to Katacoda in any way - just found it to be a good way to create interactive tutorials. If anyone knows a better alternative I'd love to hear more.
Not completely sure if it is standard SQL but several DB engines have support to insert multiple rows in a INSERT statement. For a statement as big as this is not much different but for bigger ones it will be more efficient.
On a similar topic, here a clever Qt trick: /* The QT_CONFIG macro implements a safe compile time check for features of Qt. Features can be in three states: 0 or undefined: This will lead to a compile error when testing for it -1: The feature is not available 1: The feature is available */ #define QT_CONFIG(feature) (1/QT_FEATURE_##feature == 1) #if QT_CONFIG(thread) .... #endif
We even forced the band to rename themselves the `Smart Ptr Kids On The Block`.
`INSERT INTO foo VALUES (1), (2), etc.`, yeah. Not sure if anything uses that for a dump of table contents, though. `sqlite3`'s `.dump` doesn't.
Relative to some discussion in the other thread, I figured I'd throw this out there as something maybe to use moving forward, assuming others agree. This is not a coding contest but a tools comparison. But the trade-offs of the solutions are not totally unimportant, for educational purposes, possibly practical transfer of some of the ideas to real world systems, or tool set selection criteria. So, maybe: 1. The extent to which two implementations are the way they are just because of how the algorithm was written is not that important. If the two could have switched these aspects of their respective implementations easily enough, then it's not that important for tools comparison. 2. OTOH, where a particular implementation is the way it is due to specific idiomatic aspects of that tool set or due to showcased benefits of that tool set, then probably some discussion of the speed, size, and compactness trade-offs of those aspects of the implementation is useful.
I've just updated the regular site with this support too!
What do you think about future Graalvm stuff from Oracle? if they compile the whole thing in AOT, wouldn't that make the whole thing a lot more responsive?
Adding yet another member function to `std::basic_string` seems unnecessary. Yes, it's already got a huge number of redundant member functions, but that doesn't mean we should make the problem worse by adding yet more. I'd be much more open to the idea of adding a set of free functions `std::contains` (and/or `std::ranges::contains`) which does `std::find` or `std::search` as appropriate. I don't find the argument that &gt; The drawback of a free function is that the order of parameters of a free function is ambiguous particularly compelling, given that standard library algorithms all consistently use the range to operate over as the first argument (or pair of arguments for the iterator overloads). As far as readability is concerned, with the "pipe" syntax used by ranges, I don't see that my_string.contains("foobar") is all that much better than my_string | contains("foobar") particularly when the latter is fully generic and could be used by any kind of range, not just strings.