wtf is `trinkle`?
Simply Awesome, I love the Go build system and I think this is a fantastic idea. Actually I think this is so awesome that the majority of the cpp community will be shitting on it in no time.. just sit and watch it happening. 
Putting compiler flags into source files makes certain things needlessly difficult. As an example you often want to compile your program with completely different compiler flags, as an example to build with address sanitizer. Replicating the same thing with environment variables is tedious. Similarly not supporting optional features in your build is not nice because in the real world they are quite popular. The system also does not seem to support configuring your build based on features on the system (such as testing if some header file has a certain definition and what the sizes of some system structs are).
Ya in recent videos I improved it. Thanks for feedback.
Yes it does work with C++98. Obviously wrong choice to not mention --the ancient sounding-- C++98 but to do mention veeceesix.
Reworded in terms of C++98 and pre-C++11. Thanks for the heads-up.
Inanimate things don't live, don't die, do not become dead. simple. 
How do i build shared objects? &lt;g&gt;
Too many professors are bad at C++ (and teaching it) unfortunately. Most of them actually, which is really unfortunate. Also, it's hard to change professors opinions. Maybe if there was more "ready made" learning material available, it would be easier. Things like a demo slide deck and/or exercises. But then again, most professors don't even know such a thing as C++11 exists.
Hi, Yes, it is possible and already done with Liblogicalaccess ! The only limitation is the rfid reader in your android and the [Supported Tag Technologies](https://developer.android.com/guide/topics/connectivity/nfc/advanced-nfc.html#tag-tech) ("Optional supported tag technologies" are only supported by some old chipset as I seen for now...license problem from constructor ?). I also have to tell you that some phone (specialy all new phones) have very bad chipset...I have faced different problem of communication because the chipset was sending random data to card for detecting if it was still near ([my Stackoverflow Issue](https://stackoverflow.com/questions/21460535/android-isodep-command-chaining-failure?noredirect=1#comment32386380_21460535)). About Liblogicalaccess: -Liblogicalaccess is not currently able to build on android...so I have create a proxy android application. -Like told on first post, this library have a high level generic abstraction, having a HID/pcprox reader or a TCPSocket is the same for him ! The Liblogicalaccess connect to the android by TCPSocket and will pass all the card communication in it like a simple reader ! Android App forward the data to the card and send back the response. It is pretty easy to make. At the end, I have been able to authenticate with a DESFireEV1, createApplication, read Cipher data and more... You can find the application here: (It is a POC, so not available for sell, only test) https://play.google.com/store/apps/details?id=com.islog.datawriter I just seen that there is not exemple of how to use the liblogicalacces with a "TCP Reader" if you are interested, I can give you one :)
Hi, HCE is very too much limited...you can only emulate the AID that you have "bind". It is enough for PayApp that usually only use one AID with a simple communication behind. Moreover, android API don't let you set the ATR of your emulation card, it use a random ATR that change permanently, It mean that readers will not be able to detect properly the type of card you are using. So It let us only the ISO compatible Readers and Cards. For me, it is possible to emulate for example a DESFireEV1 in ISO mode to be able to authenticate and send "our stored data" but it is a lot of work for pretty nothing... I already seen this Black Hat video and to tell the truth...nothing impressive, he copy a simple number from a card to another. There is absolutly no security on this card (he is testing Prox card). I agree that it is one of the most used card in the world, therefore It is a problem ... but because it is not a ISO technologie, you phone is not compatible :( You need a home made hardware that work with 125khz and enjoy. There are cards that store cipher data or certificate, with advanced authentication and are ISO. This cards have a real challenge for android. We will only be able to emulate them when we will have a better API (probably this is the point of the lack of it?). 
I just try to understand and (hope) help understand how to use STL (I would say effectivelly but it seams I am overvaluating me). My little post really do not pretend to correct or complete STL. After your comment I've asked myself if I was really just reinventing (badly) STL objects with reordered arguments, so I'm trying to use find_if (as an example) and functional helpers from pure STL (restricting to C++98 or at most TR1, I must stay within VS2008 capabilities) vector&lt;A&gt;::const_iterator i = find_if(begin, end, bind2nd(equal_to&lt;string&gt;(), string("Pluto") ) ); Of course here I'm using the same data structures from the article. Clearly this do not compile because the functor produced by bind2nd accept a string but I'm passing a more complex structure. And here I stalled. How can I transform on the fly the object to the string using its "getString" method? What I miss is the ability to compose functors.
Happy holidays! :)
I'm very sorry about this, My English is not that well, hope the argument is understandable anyway.
VS 2008? Yuck. bind(&amp;MyClass::m_data, _1) can be used to get an object's public data member, or bind(&amp;MyClass::getString, _1) can be used to call a member function. Using nested bind(), you can compare it for equality to something else. However, it's terrible to write, and if you attempt to use std::tr1::bind(), you'll have to deal with its many many bugs in that ancient implementation (all finally fixed for VS 2015 RTM). boost::bind() will probably work. But seriously, upgrade your tools.
What's the Big-O of this?
The probability of each iteration succeeding is 1/n!, since there's a 1/n chance of putting the smallest element at the beginning, a 1/(n-1) chance of putting the next smallest in the next place, and so on. That means the expected number of iterations is n!. And as a special little extra fuck-you, each iteration takes linear time, so it's O(n\*n!).
Don't use std::random_shuffle(). Use std::shuffle() instead. random_shuffle() is deprecate since C++14 and will be removed in C++17. The problem with random_shuffle() is that the standard requires it be implemented in terms of rand(), which itself has its own issues: there are no guarantees as for how random it's return values are, how uniform the distribution is, and so on. std::shuffle() uses the new C++11 random number generation tools, which in turn replace rand(). They're more elaborate to use than rand() but they provide stronger randomness. Other than that your sorting algorithm is swell.
I'm laughing at this because, while it's absolutely completely true, happens to not be the real problem with this particular algorithm.
It's not guaranteed to halt for N &gt; 1, so O(∞).
But Big-O notation isn't about expected performance, it's about _worst case_. See **Plorkyeran**'s answer.
I was talking about the average-case complexity. It's the same reason that people usually call quicksort O(n log n) instead of O(n^(2)) unless they specifically say they're talking about the worst case.
Thank you for the answer. Thank you for making this thread, and teaching us about RFID communication!
&gt; expected performance Average performance*
Do the needful, OP
Big-O isn't about worst case or best case, Big-O is strictly about grouping classes of functions whose asymptotic growths are bounded according to a given formalism, basically in terms of a constant multiple +/- some constant offset. The function T(n) is used to represent the maximum number of operations an algorithm requires as a function of its input, n. T(n) is often referred to as the worst-case scenario. Big-O can and is often used to place an upper bound on T(n) so that instead of calculating T(n) exactly, which may depend on specific architecture/hardware details, or could just straight up be a burdensome calculation, one places an upper bound on T(n) and that upper bound is good enough to abstract and reason about T(n) across a variety of architectures. However, t(n) is a function used to represent the minimum number of operations an algorithm requires, and Big-O can similarly be used to place an upper bound on t(n), despite t(n) representing the "best case" scenario. Similarly there is also a function to represent the average case scenario and Big-O can be used to place an upper bound on the average case scenario. So for example, with respect to bogo-sort, t(n) (best case scenario) is an element of O(n), whereas T(n) (worst case scenario) is not an element of any class of asymptotic functions as it is unbounded, and the expected running time which is sometimes denoted as E(n) is an element of O((n + 1) !). Ultimately, Big-O isn't about worst case performance, it is a formalism that can be used to place an upper bound on worst case, best case, average case, or simply used to group any class of functions together whose growth is bounded according to its formal and rigorous definition. For more information refer to: http://en.wikipedia.org/wiki/Best,_worst_and_average_case The table in that link uses Big-O to place upper bounds on the time complexity of various sorting algorithms, including best case, worst case, and average case, all of which Big-O can be used on.
I'm pretty sure that simplifies: `O(n*n!) -&gt; O((n+1)*n!) -&gt; O((n+1)!) -&gt; O(n!)`
With a minor change, you can make this a [quantum bogosort](http://en.wikipedia.org/wiki/Bogosort), which has O(n) complexity, which is even better than any other general purpose sorting algorithm. template &lt;typename value_t&gt; void BogoSort(std::vector&lt;value_t&gt; &amp; data) { std::random_shuffle(data.begin(), data.end()); if (!std::is_sorted(data.cbegin(), data.cend())) { destroy_universe(); } } I leave implementing `destroy_universe()` as an exercise to the reader.
&gt;having checked in my &lt;functional&gt; overhaul And with it, you fixed a bug I reported long ago! Got the notification recently. It was an amusing surprise! :) It was the one with something to do with `std::ref(*derived)` or some such... Thanks for you efforts!
Instead of templating it on the value type, template it on the container type, then every container that can be checked and shuffled works.
It halts with probability 1 (assuming a properly random shuffle).
Yes? That's exactly why it halts with probability 1: for `n` elements, the chance of having *not* succeeded after `k` shuffles is ((n! - 1)/n!)^k and this limits to zero as `k` increases to infinity. In fact, the number of shuffles required follows a geometric distribution with probability of success `1/n!`.
The last step is invalid, as `O((n + 1)!) != O(n!)` since the two expressions aren't constant multiples of each other.
No, it means that it will do its job and stop instead of being stuck in an infinite loop. Well, at least we can compute an *expected* time. But that's the theory. In practice I'd be concerned about whether each permutation is actually “reachable” due to possible limits of entropy w.r.t. pseudo random number generator seeds. Invoking `next_permutation` instead of `shuffle` is probably a *slightly* better idea in practice. ;)
I thought the non-member std::begin() and std::end() were the current standard for obtaining the beginning and end iterators.
How about this deterministic version? while(!std::is_sorted(data.cbegin(), data.cend())) { std::next_permutation(data.begin(), data.end()); }
Determinism? In *my* bogosort? Heretic!
To be honest, I'm still figuring out a lot of the new best practices for C++11/14. *Edit: Okay, okay, I've updated the code. :)*
Probability 1 does not mean "always happens".
... doesn't std::shuffle() take random-access iterators?
Something occurring with probability 1 is different than saying that it always happens, from a mathematical perspective. I'm on mobile, so I can't really link you, but see the Wikipedia page for "Almost Always" for more information. 
Yes. You are right. Although I was thinking that the additional time complexity wouldn't be a major problem in this case, all things considered. 
1. Write function to emulate Turing Machine given a tape and a set of instructions 2. Write out the list on the tape in unary 3. Generate a random set of instructions 4. Run the Turing Machine with those instructions on that tape 5. Check to see that the tape contains, represented in unary, a sorted list containing identically those elements in the original list. If not, return to step 2. Or, if you want to be horrendously unsafe: 1. Write the list to a file 2. Generate a random string, and write that also to a file 3. Attempt to compile the second file as a C++ program (or another language, if you prefer) and run it. If unsuccessful, return to step 1. 4. Check to see if there exists a new file, generated by the subordinate program, which contains a string representation of the correctly-sorted list. If not, return to step 1.
The first time in my life I've ever had my code forked and it had to be *this*.
I've updated the code to work with any random-access-capable container, and to use std::shuffle() instead of std::random_shuffle(). You may now deploy this to production code.
I tried `next_permutation` and it's an order of magnitude or two faster. But it's deterministic and therefore a sin in today's modern stochastic world.
It is your best work!
This is an awfully opinionated build system.
Yay! Now if you'll excuse me, I have to go curl up under that desk over there and have a sobbing meltdown. *Edit: If someone wants something actually useful, try my [random number generator wrapper class](https://gist.github.com/jrandom/64c8972b438bf8f1d0dd) -- for all those times you just want to generate some random numbers but don't want to dig through the standard library references to remember how to put all the pieces together.*
Here's a better [fork](http://wmrentalco.com/wp-content/uploads/2013/04/gold-dinner-fork.jpg).
I was reading the comments on here for it and was wondering what the code was since the responses were pretty serious. Had a good laugh, thanks!
I fully expected this post to be downvoted to oblivion. Instead we get a discussion on big-O notation and runtime limits.
Well, qsort vs. std::sort is much size vs. speed tradeoff. qsort is generic and type unsafe, but std::sort is duplicated on each type sorted.
This talk got the best voting (average) at Meeting C++ this year!
Why not just write a file with random byte code and execute it, skipping the whole compilation step?
Please do not use the std:: namespace qualification with std::begin and std::end. Doing so prohibits the use of argument-dependent lookup (ADL) for user-provided implementations of begin and end. e.g. class MyContainer { /* ... */ }; MyContainer::Iterator begin(MyContainer&amp; cont) { return cont.GetBegin(); } The correct way to call begin and end in a generic context is to bring std::begin and std::end into your local scope and make unqualified calls to begin and end: template &lt; typename container_t &gt; void BogoSort2(container_t &amp; data) { using std::begin; using std::end; std::random_device rd; std::mt19937 ung(rd()); while (!std::is_sorted(begin(data), end(data))) { std::shuffle(begin(data), end(data), ung); } }
Seriously? Shit like this is why 'modern C++' takes so long to actually be used anywhere.
The chance of it halting on *each try* is 1/(possibl sequences). But the chances of it *eventually* halting is 1. That's how infinity works.
Functions like malloc() and free() are implemented as part of the standard C library by your compiler vender. As a result, how they are implemented may differ depending on if you are say using GCC versus Microsoft. Since GCC's source is available, you should be able to see the software that implements these. A further complication is that new and delete can be overloaded in C++, which can come in handy say if you have a mechanism for finding memory leaks at runtime. Something that may interest you if you are interested in different memory management schemes is to see how these functions are implemented in resource constrained systems, such as embedded processors. For example, [FreeRTOS](http://www.freertos.org/a00111.html), which is an open source real time operating system targeted for these types of processors, implements five different memory management schemes ranging from "there is no free" to a much more advanced version that tries and prevent memory fragmentation and can span non-continuous memory spaces.
gcc is just a compiler, it doesn't include a standard C library (libc). On Linux, the libc is usually glibc, but alternatives like musl, dietlibc, or uClibc also available. On MinGW, the libc is MSVCRT with some augmentations. On OS X it's the system-provided libc.so, which is probably derived from FreeBSD. If you want to look at how `malloc()` is implemented, you'd have to look at one of those. Or you could look at [jemalloc](http://www.canonware.com/jemalloc/) or [dlmalloc](http://g.oswego.edu/dl/html/malloc.html) which are standalone implementations. In C++, allocators sit between containers and `operator new`, and dictate allocation policy. A given implementation of the C++ standard library could have any number of different allocators for different needs. The GNU C++ standard library (libstdc++) has [several allocators](https://gcc.gnu.org/onlinedocs/libstdc++/manual/memory.html) that you can choose, and you can of course write your own. I'd imagine that other implementations of C++ standard libraries are similar. 
Because Sqlite is used in so many environments, they have a variety of memory allocating/freeing routines built in. You might want to look at those also.. https://www.sqlite.org/malloc.html
Can you point me to any source?
Fast multi-threaded allocation is a key requirement. Check out tcmalloc: http://goog-perftools.sourceforge.net/doc/tcmalloc.html 
Source to what? A `malloc()` implementation? I linked to two of them, both of which are open source. 
&gt; gcc is just a compiler, it doesn't include a standard C library (libc). GCC comes with a standard C library. You can replace it and use another library that implements the standard but GCC itself certainly includes a default standard library. Saying that GCC is just a compiler and doesn't include a standard library could be misleading and even confusing to people who might be interested in using GCC and believing that GCC itself would lack a standard library or they would need to download or install one separately. GCC itself includes a standard library as part of its distribution. Furthermore, while I don't know much about C's standard, strictly speaking, all standard conforming C++ compilers are required to include, as part of their distributions, a complete implementation of the standard library. Once again, it's sometimes possible to replace parts of the C++ standard library that ships with a compiler with an alternative, but that doesn't change the fact that it's required to provide one.
&gt; GCC comes with a standard C library. It most emphatically does not. You must pair it with some external libc (such as glibc, newlib, etc.) in order to have a usable compiler. The fact that this is virtually always done for you does not change that fact. It's possible for gcc to have a standard C++ library and not a standard C library because the standard C++ library is implemented completely on top of the standard C library, but the standard C library is extremely platform specific, and gcc targets dozens of different platforms. 
Oh you're right... That's easy \^_^
You always have got the choice to use qsort in C++, but you never have got the choice to use std::sort in C.
I would start out by reading Knuth's malloc implementation. It's not used, but it is an easy way to begin your foray in this area.
I can address the CMake question: CLion uses CMake for project configuration. CMake is great because the CMakeLists.txt build file is actually generic and can be used to generate Makefiles (the ones you're used to), but also more interesting things, like XCode or Visual Studio projects. This is helpful when working with cross platform projects. I made a starter lib project that uses gmock and cmake. Maybe this will help you get your projects organized: https://github.com/film42/cpp-starter-template/
Does Clion have a memory viewer window?
Im not an expert on this stuff, but I can tell you what Ive been doing lately, which is at the very least fun and most of the time informative. Just start coding c++11/14. Use stl functions. When you don't understand something, look it up on cppreference.com, watch a talk about it, and continue. Wrap small things you would normally do in a helper class in lambda functions. Use smart pointers instead of raw ones as much as possible to learn about std::move and such, and to learn when to use them. Try std::thread, std::atomic for a simple multithreaded stuff. If you need ideas, it doesnt really matter as long as your projects don't become too big (so you won't feel bad about abandoning them). Little games (pong, relentless logic, simple point and click, simple text based adventures, tetris), useful programs (watch an rss feed, montage a set of pictures into a slideshow, your personal movie-database-webserver), anything goes. So, basically what everyone always says: learn by doing! Oh, if you need resources: r/cpp, r/programming, and talks by smart people. Some people also like programming books, but they're not for me.
Things the Stroustrup was talking about is beyond 1 semester of programming. I think after learning the basics, the best thing you can do is practice them. Go find tutorials for things like brick breaker or pong if that's what interests you. Actually writing code that does something instead of just copy and pasting is an invaluable practice exercise.
CLion is a new IDE that's currently supporting the [CMake](http://www.cmake.org/) build system. it's a very good one I recommend, it's also multi-platform. [CMake is quite easy to use on the basic level](http://www.cmake.org/examples/). all you need to do in CLion to change the CMakeLists.txt file and add couple of code files, everything else kind of happens automatically.
It appears to be C? Might want to try a subreddit for C. I was all prepared to read a C++ threadpool (I wrote one recently) but I'd be the wrong person to read the same thing in C.
How would I compile gmock using Windows? For school, I've been using a UNIX server. I recently installed MingW g++ compiler, and then CLion. I guess to be a bit more specific in my problems, I've been exploring a lot on Google Code for the past few days, and been looking at other people's code to try and become a better programmer. When I download their source files, I have no idea how to run anything :/
Pointer fun, there's a ton you can do with pointers. Also personally I'm in to Reverse Engineering, so figuring out how the compilers work etc is fun for me. You figure out about different calling conventions and how to debug certain issues with corrupted stacks etc in your code when the debugger fails.
1. Focus on data structures. Even more than algorithms (IMO), data structures will help inform your design choices as a developer far into the future. 2. Like others have said, focus on using STL rather than 3rd-party libs. 3. Learn how to work with threads and sockets. 4. Learn how to estimate algorithmic complexity of code blocks, and then how to determine the algorithmic complexity of larger programs (which are just a series of code blocks). &lt;== this is _huge_ for if you want to get a job later and they ask you "what is big-O notation and how would you determine the big-O of this white-board exercise". 5. Learn about templates and how they complicate the mess out of everything. Mostly, do what /u/hijinked said: make something that really does something nifty or cool that you want to build in the real world -- not just exercises out of a book. 
If you want to learn the language, then read a book. For example, "The C++ Programming Language", written by Bjarne Stroustrup. C++ is very complex language, so you couldn't learned more than very basics during school semester. Of course, reading a book won't suffice. You need to practice too. Be aware that learning C++ will take you several years.
C++ has its own threading and concurrency libraries now, so it'll be very different. There's much more to C++ than C with objects, especially in the latest versions. Sorry, wish I could help, but I've never used raw pthreads.
I think you just need to make sure g++ is exposed in your PATH. Can you fire up a command prompt and run g++? If not, you might need to configure MinGW to work right. I'm pretty sure that's the only requirement to get started (https://www.jetbrains.com/clion/quickstart/).
Oh, I have it configured correctly In your github tutorial, I don't know how to build cmock without a terminal (can you install gmock in CLion without having to run commands like "cmake ." or "make"?
Nope, you need to build gmock so CMake will recognize the lib. If you can run CMake from the command prompt and have it work, then CLion should work just fine.
I think the best way to learn programming is to write something that excites you. Games are great! Start small, and make sure you get something gratifying to happen often enough so you feel rewarded. Writing GUI code has a lot of overhead, so you may find it goes faster if you start with a working app that someone else already wrote, and then improve it.
Visual Studio is god on Windows, Linux I use Sublime/NetBeans with gcc.
Despite the downvotes, it's simply not true that GCC doesn't come with a standard library and unless we're arguing some serious pedantry it's fairly misleading to people who may have an actual interest in using GCC to say that GCC is just a compiler without a standard library. Heck the compiler itself includes a good chunk of the standard library built right into it. On Windows, MinGW comes packaged with GCC compatible header files since the MSVC header files are not compatible. Even on GCC's main page, GCC is described as: &gt;The GNU Compiler Collection includes front ends for C, C++, Objective-C, Fortran, Java, Ada, and Go, as well as libraries for these languages Bottom line is that any distribution of GCC will include the standard libraries for it, so for anyone reading this who has a genuine interest in using GCC rather than arguing academic technicalities on the Internet, don't feel like if you install GCC that you will need to also install a separate standard library. That's simply not the case, your distribution will come with all the appropriate plumbing needed for your particular platform including the standard library. Only in exceptional cases will you ever feel the need to replace the default standard library for your platform with some alternative, but if you're in that position chances are this conversation isn't of much relevance to you to begin with.
You're lovely! :)
&gt;I thought there wasn't much difference between c and cpp I hate to seem harsh because you seem to have come here in good faith but: So what you're saying is that you literally have no idea of the differences between C++ and C?
You don't build gmock in CLion, you build it from the command line. My advice would be to attempt everything outside of CLion (aka, just learn how to use CMake), and then introduce CLion. You'll come to find CLion is mainly indexing header files and autocompleting your code for you. It doesn't do a whole lot right now, but if you're familiar with the JetBrains IDE (i.e. IntelliJ, PyCharm, etc) you might enjoy how the debugger works with the interface (I certainly do), etc. In other words, until you can figure out how to use CMake outside of CLion, there's a good chance you're going to continuously run into trouble. Try following the tutorial from the starter template readme. I should also add that I wrote that CMakeLists.txt with a unix OS in mind, so YMMV.
The person was asking to see the implementation of `malloc()`. That is implemented by a libc, not by gcc. You implied that they should download the source to gcc to see how `malloc()` is implemented. That is preposterous, because it simply does not exist there. The fact that gcc is commonly distributed with a libc does not change the very simple fact that *gcc does not include a libc*, and telling someone to look at the gcc source to find a libc is a fool's errand.
KK, will try everything from scratch
everything you've mentioned aside from pt. 2 isn't c++ specific.
That doesn't make it bad advice. :) But, I see your point. [minor edit] Spelling &amp; btw: templates are evil *is* C++ specific.
i think programming principles and practices by stroustrup might be a better fit for him. the programming language is an in-depth reference with examples - it's not really light reading.
I appreciate when library writers have a prefix for their function calls. It's annoying when I want to use a library and find they've called a function something that is already used in another library and I have to then pick one to modify. Ugly.
Recently on cscareerquestions there was a question about what constitutes a 'strong understanding" of C++'. SofaAssassin gave a terrific answer about things a (professional) C++ programmer should know: https://www.reddit.com/r/cscareerquestions/comments/2q7oo6/a_strong_understanding_of_c/cn4e4r6 
I second your recommendation. **Programming: Principles and Practice using C++ (2nd Edition)** has been perfect for a newbie like me. I suspect it's perfect for c++ newbies in general, too. He has other books which are meant for the more experienced c++/programmers, and the talk that OP heard was probably on that level; i.e not for beginners at all.
&gt; brick breaker or pong what is that? 
Experienced C and C++ developers should *damn well* know their primary differences. Experienced developers in other languages? Absolutely. It's somewhat unintuitive at a glance.
[Brick Breaker](http://sandbox.yoyogames.com/extras/image/name/san2/273/507273/original/screenshot102.png) [Pong](https://kdadams1.files.wordpress.com/2010/05/tsp-pong.jpg)
Oh, if they're experienced in the languages, of course. But many people who haven't used C++ very much will assume that it's "C with objects". I've seen it quite a lot, and it's certainly something I'd expect from a student.
From the sidebar you can check out /r/cpp_questions but I wouldn't mind you also adding it in your submission.
i know, but the question was about c++ in a subreddit dedicated to c++, and pretty much no one has answered his specific question, rather provided general advice (good advice, i won't argue that) for furthering his developer skills. he could have gotten that advice anywhere, ranging from /r/programming to stackoverflow.
I've pastebin'd them and added to the first pots. Thanks.
He answered your question in the post you replied to: &gt; Please do not use the std:: namespace qualification with std::begin and std::end. Doing so prohibits the use of argument-dependent lookup (ADL) for user-provided implementations of begin and end.
I suggest you look at this threadpool implementation: https://github.com/progschj/ThreadPool/blob/master/ThreadPool.h and compare it to yours. Regarding your vector: You only have resource-management data in there (your _data_ is a unique_ptr), wouldn't it be better in that case to follow the rule-of-zero and not define move-constructors etc because the compiler will get it right and do it better?
Good lecture. Well worth the watch!
Has the recorder of this video never heard of "*stereo*"?
I don't understand what's up with so many programmers wanting to forego speed for simplicity. If you want speed and simplicity, why don't you just go for something like C#. If you think const reference arguments are complicated then C++ probably isn't for you. I'm not going to copy an argument when I know the function is only going to read from it (hence the **const** reference).
The author seems very confused about C++. His tagline: "Pass by value or by const reference — why is the simple task of writing function parameters so complicated in C++? " is completely wrong. It isn't complicated, it's incredibly simple. You pass in whatever you need. * I need a value: pass a value. * I need to modify an object's internal value: pass a reference. * I need multiple values from an object: pass a const reference. * I want the address of an object: pass a const reference or pointer. * I want ~~ownership of~~ to move an object: pass a [forwarding reference](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4164.pdf). EDIT: getting move 'ownership' with rvalues confused with ownership via smart pointers.
The original "Effective C++" is for C++ 98; "Effective Modern C++" is for the new features in C++11/14 - Scott says as much in the intro. Ie, you'll want both. 
&gt; Performance, huh? Can we get some documentation of this claim that the STL's performance is bad? &gt; check out what jonathan blow says about C++ and STL, boost. I agree; basically its bad to have to put simple things behind too many layers of abstractions. Often gamedev just wants simple flat arrays, not much in the way of pointer chasing, but in the idiomatic C++ style everything is abstracted behind iterators and nested policy templates... its hard to figure out whats going on , which is stupid because you want it to compile to something very simple. the iterator way of doing things lets you switch between link lists, vectors but we already know link lists are slow and to be avoided for most performance code.
I'll have to try his out. Based on the code I'm a but confused about the API. edit: I don't know what you mean about the vector.
&gt; Also, it's hard to change professors opinions. I absolutely agree with this. I have to say that in my university they use Visual Fox Pro 6 to teach databases... Fortunately I know English and I can teach myself a lot of stuff
The standard specifically specifies that it does this.
By that same logic: O(n^2) -&gt; O(n^2 * n! / n!) -&gt; O(n * (n+1)! / n!) -&gt; O(n * n! / n!) -&gt; O(n) So no, you don't simplify `(n + 1)!`.
The problem with a const reference is that it isn't constant. You can't verify that the argument will not be changed during the execution of the function, only that it won't be changed through that reference.
That's not what const means at all. It means you can't modify it within that function.
No, it means you can't modify it *through that reference*. If the function has access to it via some other reference then it may inadvertantly modify that argument during its execution.
Yes. But in C++ there's no way to express a pointer or reference to an object which does not change. The only way to get that guarantee is via a value.
Author here. I'm not anti-optimisation in any way - it is of course one of the main reasons to use C++. However, I think it's been a fairly long time since we have needed to optimise so heavily that our default practices involved optimisations, even with C++. Some applications really do require it and that's fine, but beginners are certainly not going to need it and many others won't either. For me, I see a logical flaw in taking a reference to an object when we only care about the value. I just see it as a premature optimisation. Sure, references are not very complicated and people should know about them anyway, but they're still not really the appropriate tool in most cases. By choosing a const ref, you are exposing internal details to the caller that should be irrelevant to them. I understand that different people have different aspirations for their code, but I think a default practice should be logical and clean. Teach this first then teach optimisations later. Edit: Thanks for the feedback.
1. In that case, you have no choice but to need to look at the caller's object. You're right, I should probably mention this explicitly, but I figured it was implied by my paragraph on genuine uses for const references. 2. Seeing this as a "premature pessimisation" implies that you prefer optimise first, clean up later. I think that that approach is fine for certain projects, but not as a default. If we disagree here, then we just have different ideas about programming. 3. Copy-on-write should be invisible to the calling code. If you depend on the internal copying happening at a certain time, then I suspect there's something wrong with your design. 4. Const ref hasn't been the "default" since C++11. Instead, the default is to evaluate what your function is going to do with the object and then pick either value or const ref. This is essentially exposing information about the internals of your function, which should be irrelevant to the caller. Thanks for the feedback.
Perhaps the tagline is a bit dramatic (got to draw in the readers), but deciding on parameter types in C++ is more difficult than it should be. The types of your parameters shouldn't depend on some internal details of the function (considering that both value and const ref typically convey the same meaning to the caller). I'm intrigued by what you mean with "I need multiple values from an object". I've not heard that one before. Edit: also, you use a forwarding reference when you want to preserve the value category of the caller's argument expression, which doesn't really have anything to do with ownership. Ownership is only a factor with dynamically allocated objects and is transferred through the use of smart pointers.
Okay, I'm remember the "past some N, c*f(x) &gt; g(x)" thing now ...
Feedback appreciated.
This might be a little shortsighted of me, but I instantly tune out whenever I read this kind of clumsy, downright ugly Windows API code. I understand that it's a relevant example here, but my solution would be, completely hide this windows-specific garbage in a platform dependence isolation layer. 
I'm not sure I understand what you mean honestly. Can you provide some examples in which a const ref doesn't make sense but passing by value does? &gt; By choosing a const ref, you are exposing internal details to the caller that should be irrelevant to them. Like what? You're exposing the same thing by passing a copy.
I mean that a const ref represents different information. A const ref gets access to the caller's object (which transitively gives you its value). Passing by value gives you just the value. If you just need the value, passing by value makes much more sense. Current best practice is that you would take by value if you're going to copy/move the object internally and take by const reference if you aren't. This generally gives the most optimal solution. However, why should the caller care whether you're copying the object internally? They shouldn't. This is the detail that it leaks.
There's also `unique_ptr&lt;T[]&gt;` for some cases.
"Really slow" just isn't true. It may be *slower* than optimising by default (of course), but it rarely matters. Optimising without really knowing that you need to is the definition of premature optimisation. Not every C++ project needs every little thing optimised.
Maybe you would rather see the purity of VMS API code instead. 
decc$i_hate_my_self()
Are you mostly concerned with the aesthetics of the interface? I agree that a beginner first needs to learn how to pass a value to a function he wrote, then start to learn about the differences between pass by value, pointer and reference and the const modifier. That's the order in which it's taught in all tutorials/books I've seen. But once you understand these basics, you'll never be puzzled when a library function asks for a const reference to an object as one if it's parameters, because you'll immediately recognize that it's done as an optimization. But I agree that it would be nice if the compiler optimized all value parameters to references if they don't get modified inside the function.
By multiple values from object I simply meant if I needed MyObj.a, MyObj.b, MyObj.c ...may as well pass MyObj by const ref instead of passing all the values invidually. Yes you are correct, I have no idea why my brain thought ownership had anything to do with this. I think I was getting confused with passing in something via move; you are moving or 'transferring' it to the receiving function.
I love clean, safe code that speaks for itself. Nice interfaces are part of that. I agree with your point about the compiler optimisation, but it could only do it under the as-if rule which is difficult to prove. One option is to add a copy-elision style rule that would allow it.
Concerning second: I'm not considering references to be nether premature optimization nor messy. Akin raw pointers. Those are legitimate tools. You just should not use them wrong. You are probably right, that it is complicated in C++ to pass parameters and to choose the right type. But that doesn't mean, passing everything as value is the right thing to do. To me it seems like only using one gear while driving a car, because otherwise you can drive to fast, which in fact might be dangerous. Concerning third: I'm just trying not to slow down my code by design. Sometimes you have no choice, but reason about what statements will cost you more run time than others. This is probably some advanced stuff nobody wants to teach :) For instance,you don't want to hold a lock during a copy-on-write. e.g. void do_something(widget w){ std::mutex m; std::lock l(m); w.update(some_data); // you wouldn't expect the copy here } Concerning fourth: I didn't mean default since C++11, I meant default back in "the good ol' days" of C++98. Also default didn't mean, "use it no matter what". It was meant as the first thought.
I get what you're saying. One way to look at movable classes is as containers, but I don't feel like that is a particularly useful abstraction to use with them. Looking at them that way doesn't really help me solve any problems. Movable classes are about providing a cheap copy at the cost of invalidating an object. I think that is the real message people need to hear.
You could have two references (to the same thing) as parameters to a function, with one being constant. 
That makes sense in general, but it gets messy when you need the address of the object to stay the same.
Thinking about moves in terms of an optimization is fairly problematic. For one, moves are not necessarily cheap, they can be more expensive than a copy, although they can also be cheaper than a copy too. Second, moves may have nothing to do with copying, for example move-only classes such unique_ptr, but also locks and streams. One is likely to have a better understanding of moves as a concept, basically it's a form of linear typing where some resource is passed from object to object in a strictly linear fashion and at the end the resource is destroyed. I think using "containers" as a way to introduce the idea of transferring ownership is sensible. Sure it's not a perfect analogy but it's good enough and most developers are unlikely to want to read up on the formalisms behind substructural type systems or linear logic to have a more comprehensive grasp of rvalue references. The linear type system is a concept in and of itself that allows new categories of statically verifiable guarantees to be made about ones code, guarantees that were not possible prior to the introduction of r-value references in C++. The fact that some of those guarantees open up new opportunities for optimizations is a great side-effect and certainly was a motivating factor, but the type system itself would have been welcome even if it didn't result in any optimizations. Having unique_ptr, or being able to transfer ownership of resources is the real message to take away from moveable classes.
RAII is about expressing ownership of a resource, and ownership is the responsibility to acquire/release the resource. It is *not* about controlling access to the resource. RAII is not an exercise in object-orientation, whereby a resource is encapsulated inside an object and can only be accessed via that object's interface. For example, unique_ptr handles the ownership of allocated memory, and although we *can* access the memory through the unique_ptr, we don't have to: it's absolutely fine to access that memory via a raw pointer. This is also the advice given recently by Herb Sutter at CppCon. You seem to be mixing ownership and access together and expressing that combination as a single Window object, which, in this particular case is causing problems. You've created the very problem that you are then solving with indirection (yuk). It's inappropriate to set the WindowLongPtr to the address of the owning object. By doing so you've created an invariant that couples the internal state of the resource to the owning object: transferring the ownership from one instance to another mutates the resource. This is not a good idea. The reason you've probably done this is so that you can obtain the owning Window object from the underlying HWND handle (for example in the window procedure). And the reason that you've done this is because you're in the mindset that "all access to the window must go through its owner". Instead, here's what I would do: separate access from ownership. The owner (e.g. WindowOwner) is an RAII class that does creation and destruction only. Moving means transferring ownership, which only involves moving the HWND, which does not mutate the resource. Then you separately have an object that provides access to all the window's functionality (e.g. WindowAccess). The WindowAccess object takes a raw handle (HWND) in its constructor, but it does not own that window, it just provides access by wrapping the C API. WindowAccess is both moveable and copyable, while the WindowOwner is moveable and non-copyable (unique ownership implies non-copyable). Therefore you can choose to have WindowOwner inherit from WindowAccess (so that the owner can provide access, just like unique_ptr has dereferencing functionality), but not the other way round. When you use SetWindowLongPtr (which will be provided by WindowAccess), you should give it the address of something that is independent of its WindowOwner. This will be some part of your program that uses/accesses the window, not something that participates in its ownership. 
Thanks for the link! But finally I tried it by using avx directly (avx branch), but without success, it's much slower than the pure C code, seems it is not that simple as I thought.
You might accidentally do that.
&gt; scott meyers effective C++, item 11 When people say that, I never know which version to check. :(
TL;DR: [POSIX] Historically: mostly [`sbrk`](https://en.wikipedia.org/wiki/Sbrk); nowadays: mostly [`mmap`](https://en.wikipedia.org/wiki/Mmap). * https://en.wikipedia.org/wiki/C_dynamic_memory_allocation#Implementations This is a standard topic for a "systems programming" course, so for a fuller treatment I'd go with one of the usual textbooks. For instance, "Computer Systems - A Programmer's Perspective" by Bryant &amp; O'Hallaron discusses this in Section 9.9, "Dynamic Memory Allocation" (or, more precisely: 9.9.1, "The `malloc` and `free` Functions"). There's even a free MOOC based on it: https://www.coursera.org/course/hwswinterface I'd highly recommend it -- in fact, this is the topic of the final programming assignment (Lab 5: Writing a Dynamic Storage Allocator): "In this lab you will be writing a dynamic storage allocator for C programs, i.e., your own version of the `malloc` and `free` routines." For somewhat briefer starting points, see: * https://stackoverflow.com/questions/19676688/how-malloc-and-sbrk-works-in-unix * https://stackoverflow.com/questions/2076532/how-does-sbrk-work-in-c?rq=1 * http://web.eecs.utk.edu/~plank/plank/classes/cs360/360/notes/Malloc1/lecture.html * [PDF] http://www.inf.udec.cl/~leo/Malloc_tutorial.pdf * [PDF] http://moss.cs.iit.edu/cs351/assets/slides-malloc.pdf 
&gt;&gt; they can be more expensive than a copy, &gt; I wouldn't go so far, seeing how moves at worst are supposed to decay into copy. (Obviously, for move-only classes this comparison doesn't make any sense) There's RVO that eliminates copying entirely, unless one forces a move. Apples-to-oranges, but just pointing out that a move isn't always at least as fast as a "copy" in that special case.
find an example that doesn't require interface code. a struct that contains a collection itself is very trivial and works exceptionally well with std::move(). granted a compiler will std::move optimize this anyways with default constructors, etc, but for sake of example it would work fine.
I'll give a name to your "something that is independent of its WindowOwner." Say, WindowDelegate, because my mind has been addled by Cocoa. Then there are some equivalences: nicolasgz | injx --|-- `Window` | `WindowDelegate` `WindowContainer` | `WindowOwner` `WindowContainer*` | `WindowAccess` What's the difference between these two schemes, really? The point is that there exist resources with an identity that isn't coupled to their C++ object, and movable objects expose this reality.
move can be slower than copying. For example, moving into a string causes it to throw away the memory it used to have. If you're always moving, then you're constantly throwing away memory (whereas copying into a string would copy over the existing memory as long as you have enough.) This gives you bad cache performance.
I needed an opaque resource of some kind.
&gt; But these myths are not true, so intellectually honest promotion of status quo, alternatives to C++, or avoidance of modern C++ programming styles cannot rely on them. Cruising along with an older view of C++ you get the same kind of myths / priestly cult attitudes defending C++ against alternatives. This might be why we're still stuck with header files in 2014 (imminently 2015). I've seen it both ways of course, in the Rust community they do occasionally perpetuate myths about the level of unsafety in C++ (every now and again theres a comparison that pretends unique_ptr doesn't exist). But equally it makes my blood boil whenever I read that header files are somehow essential for native code with no garbage-collector. Yes, that does happen: I regularly hear this in arguments from people who claim an alternative isn't needed. "you don't want headers, java's that way" (no, I grew up coding asm, I don't accept any language as being some gospel truth interface to a computer, and I don't want JIT or GC, and I don't want to declare things twice, that's just silly) Jonathan Blow talking about his new language articulates some interesting points well IMO; a reason for resisting the 'modern c++' style is that you're often hiding simple things behind many layers of abstraction. There's a cost in (i)compile times, (ii)compiler complexity (is it really going to take the optimal inlining decisions, on every platform?), (iii)understandability. (EDIT I even forgot, error messages!). this might be why some gamedeveloppers do like to throw out STL. He's been motivated to write a whole new language driven by issues like this. This has always been my personal choice too. I much prefer rolling my own simple dynamic array types. (if C++ ever gets UFCS there will be less reason too) and I use 'stl' grudgingly. Part of the theory is adding a dedicated 'pointer+size' slice concept to the language would simplify basic tasks and speed up compile times. we all know vectors are fast on modern CPUs so burying your code under many layers of abstraction for the ability to swap vectors for slow link lists is questionable. There's other syntactic reasons for an alternative: C++ shoe-horns it's high level features into low-level syntax. e.g., so [] means just a pointer when it could mean 'pointer+size'; and its' very pleasing in rust to just be able to throw brackets &amp; commas around something to group multiple return values... the use of commas in C/C++ is odd. I wonder if it would be possible to at least get something like SPECS retrofitting a modernised syntax to an existing compiler? It's ironic because I would actually defend sticking with lower level C techniques, because its' easier to interface with C from other languages and that would give more hope of actually escaping C++'s problems. Part of Rusts' simplification is making move semantics default, basically building the language around them. move is cheaper than copy, so a good default, then you type more (`.clone()` or #[copy..]) to make it do something more expensive. They get rid of constructors/conversion operators (its' all just functions), starting out with a named field initialiser , &amp;&amp; etc and its' actually all quite pleasing. The problem with C++ for me is that it takes headers from C( where they can be forgiven for its' age, and you aren't having to put functions inside structs so its' easier to declare things partially) and makes them MUCH worse. a compiler is obliged to check that #defines or include order doesn't change behaviour. There's an excessive amount of context. And C++'s features stop short of actually obseleting the humble #define. you still want x-macros or some sort of bolt on code generator to do things which should be basic by now
&gt; I wouldn't go so far, seeing how moves at worst are supposed to decay into copy. This is untrue, moves can in many simple use cases be more expensive than a copy and they do not simply decay into a copy. For many typical use cases, a move will perform a copy **and** invalidate/reset its internal bookkeeping, whereas a copy would have just performed a plain copy without the invalidation/resetting. This happens when working with a lot of small objects where the cost of invalidation becomes fairly proportional to the cost of the copy, in which case it would be faster to just perform the copy on its own. For example, working with smaller std::strings whose lengths are roughly 16-24 characters, or smaller std::functions assigned to function objects whose size is less than 16-24 bytes, but many other examples exist.
I also don't think that the author's definition of identity as something you can hold a known-valid pointer to is workable in C++, where pointers become invalidated all the time. Except as an implementation detail, classes with pimpls aren't containers and yet they're quite movable.
Um, why not just allocate the `Window` struct on the heap, pass around the (raw) pointer and be done with it? It doesn't make sense to shoehorn value &amp; RAII semantics on top of a resource (window) that has indefinite dynamic extent just like -- guess what -- heap-allocated memory. The next-best solution is to assume that `SetWindowLongPtr` won't fail when setting the userdata pointer and abort the program if it does. (I cannot imagine it failing when setting userdata -- except giving invalid handle -- but there are other use-cases that might fail.) IMO, you're overcomplicating.
ps: I posted it here because this question doesn't seem suitable for /r/cpp_questions
Try the ClangCodeModel for autocompletion. Works like a charm.
in 2015 it would be nice to have proper named parameters instead of jumping through hoops to hack them. They're not essential everywhere, but they have their uses. Wouldn't they play well with C++'s adhoc overloading? .. i.e. you've got more ways of being explicitely disambiguating if you need to. (over in Rust I'm disappointed they want neither named params nor overloads). r.e. the 'parameter struct' methods, imagine if you didn't' have to decide one or the other.. imagine if every function rolled a struct representing its's args already, and also generated an overload to call itself with that struct.
C++ is over 20 years old. You talk of it having headers as if it's a new language when it's very much an offshoot of c. Either way, fingers crossed for modules 2017. Edit: One thing about headers is that it provides an index of every compilation unit. Programming Java felt bad to me because i had to scroll through a thousand lines of code to just see what a class did. I hope whatever comes, people will still forward declare their classes. 
It would be interesting to see what the Big O math on this would be as you increase the size by factors of n.
Also, the newline has a forward slash. It should be a backslash. /n --&gt; \n But that won't keep it from compiling, just won't do what you expect. 
He's probably programming from Principals and Practice in C++ Did you get the header copied correctly from here? http://www.stroustrup.com/Programming/std_lib_facilities.h 
Whatever that include at that top is is throwing you for a loop, and is where the error lives. More importantly... **Get something modern** Looking at release dates, 4.9.9.2 came out in *2005*. While that doesn't make it invalid, it does mean you should probably be using something newer, considering how many free IDE's there are, including a newer releases of that same IDE. Whatever tutorial you are learning from that is suggesting that IDE, is probably out of date. 
I thought I'd never see that IDE again. Hasn't changed since, huh?
Please use online development enviornment, like this one for example: http://ideone.com/
Changed the code to this. It's giving me the same errors. I'll grab a new IDE. #include &lt;iostream&gt; int main() { std::cout &lt;&lt; "Hello World!"; } 
Get a good IDE and C++ compiler. If on Windows Visual Studio Express works fine for beginners. Find a good C++ reference. Find some tutorials to get started. Take a C++ class. Google (or anther search engine ) is your friend.
1. Replace "std_lib_facilities.h" with "iostream" which has definition of cout function. 2. Add "std::" before cout so the compiler knows this function is defined inside std namespace. You can also add "using namespace std;" line before main. Then, the namespace std prefix will be assumed. 3. Replace /n with \n. The combination of backslash character (\\) and n means newline. For more examples see [C++ Character Literals](http://msdn.microsoft.com/en-us/library/6aw8xdf2.aspx). The corrected code: #include &lt;iostream&gt; int main() { std::cout &lt;&lt; "Hello world!\n"; return 0; }
I'm now thinking it's some config error with the way the IDE is interacting with the compiler and linker. I would suggest just going for [Microsoft Visual Studio Community Edition](http://www.visualstudio.com/en-us/downloads/download-visual-studio-vs#d-community). It's free, should be pretty much install and go.
Just a small nitpick - Express has been superceded by Community, which is the same as Professional, but at the same low, low price as Express (free).
Get "the C++ Programming Language (4th Edition)" by Bjarne Stroustrup. Read the whole book. It is a long read, but well worth it. 
I recently started learning c++. I've tried several times in the past but never really found a book or learning resource that hooked me. I've been using '[Programming: Principles and Practice using C++ \(2nd Edition\)](http://www.amazon.com/Programming-Principles-Practice-Using-2nd-ebook/dp/B00KPTEH8C/ref=sr_1_1?s=digital-text&amp;ie=UTF8&amp;qid=1419892006&amp;sr=1-1&amp;keywords=Programming%3A+Principles+and+Practice+using+C%2B%2B)' by Bjarne Stroustrup (creator of C++), and it hits the sweetspot for me.
&gt; Do you recommend something else? I just went off stack exchange's yearly definitive list to c++ books. Stick to it. It's one of the best ones. I avoided using that .h file though when I started with it, as I wanted to learn early on which #includes were needed when.
If you wish to use this book, get precisely the 4th ed as that provides information of C++11 as well (the 2011 standard).
I second this recommendation over his other books as it's far more targeted towards the beginners than his other ones are!
I would not be surprised if there was a way to close a HWND from outside a process.
I'm not sure why you are getting downvoted, but to some degree online environments are a great way for newbies who just want to get some code running for learning purposes. It's important to learn how to setup the proper programming environment, but can be a huge hindrance when you don't even know how to program in the first place!
I believe the entire header is covered later in the book. Not quite there yet, and super new to programming. It worked for me. 
Finally! This is the first one I could get to work for me. I got various errors with others. Not quite sure what was wrong :/
It'll help if you copy-paste those error messages here...
&gt; get some code running for learning purposes. IMHO, for learning purposes, you don't run code, you step through code with a debugger. ideone is not a debugger (and by definition, not an ide).
Well, you should understand what the [linker is and how it works](http://en.wikipedia.org/wiki/Linker_%28computing%29). The problem is likely not with your code, because the linker step is a separate compilation step -- your code has already compiled by then, but then it needs to be linked. Looking at the errors, there's something pretty obvious: there are undefined references to functions! But they aren't functions that *you're* using, so where are they? They're functions that your header file is using. That's the only remaining possibility. But now, what is a header file? It's a .h file that contains function *prototypes* -- that is, a thing that tells you how to *use* a function. It tells you what kinds of arguments the function takes and what it returns. But it doesn't actually *define* the function. It doesn't tell you what it *does*. That information is in some code that has already been compiled, known generally as a library. What's happening here is that the linker isn't finding that library, or maybe the library doesn't have those functions because it's old or the functions are old or something. Check that you've installed everything correctly; some other library may have needed to be compiled that you missed.
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Linker (computing)**](https://en.wikipedia.org/wiki/Linker%20%28computing%29): [](#sfw) --- &gt; &gt;In [computer science](https://en.wikipedia.org/wiki/Computer_science), a __linker__ or __link editor__ is a [computer program](https://en.wikipedia.org/wiki/Computer_program) that takes one or more [object files](https://en.wikipedia.org/wiki/Object_file) generated by a [compiler](https://en.wikipedia.org/wiki/Compiler) and combines them into a single [executable](https://en.wikipedia.org/wiki/Executable) file, [library](https://en.wikipedia.org/wiki/Library_(computing\)) file, or another object file. &gt;A simpler version that writes its output directly to memory is called the *loader*, though [loading](https://en.wikipedia.org/wiki/Loader_(computing\)) is typically considered a separate process. &gt;==== &gt;[**Image**](https://i.imgur.com/sHTdJ25.png) [^(i)](https://commons.wikimedia.org/wiki/File:Linker.svg) - *An illustration of the linking process. Object files and static libraries are assembled into a new library or executable* --- ^Interesting: [^Relocation ^\(computing)](https://en.wikipedia.org/wiki/Relocation_\(computing\)) ^| [^Library ^\(computing)](https://en.wikipedia.org/wiki/Library_\(computing\)) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cn8vycx) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cn8vycx)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
Read up on pointers. Its a bit of a paradigm shift from languages that don't have them. Confusion here can cost you a few weeks of productivity in class assignments. Peter Van Deer Linden's Deep C Secrets book is a great classic read.
That's true, but even if you only move rvalues you still need to solve the problem of asking "Is this object really the same as the object I saw before?" In that case, you might now need some kind of unique ID since the address can no longer be relied on as a unique identifier. &gt;and you would never be keeping a pointer to an rvalue. Unless an rvalue is keeping a pointer to itself, as in the case of the userdata example.
Very good lecture, I learned many more GCC warning flags.
&gt; good tutorial HAHAHA, and perhaps a unicorn too. Seriously, get a good book by a well established author. The C++ Primer 5th edition is a good choice.
My advice. Don't use an IDE, it just masks a load of stuff under the surface that would be benificial to know in the long run. Furthermore is that it is just a sticking plaster on windows as a wholly unprogrammer freiendly OS. Others WILL disagree, but I for one am sick of having to work with people who are completely tied into an OS and an IDE because that how they learnt it. A get Linux distro, run it off a pen drive if you like, something with a package manager. get a text editor (a good one) and get a compiler like clang or gcc. But most importantly of all, get a good C++ book. Online resources are simply not up to snuff. Something like The C++ Primer 5th edition or Bjarne Tour of C++.
I was where you are a few years ago and I'd recommend watching one of those "how to programm c++" youtube series and experimenting yourself with the things you see/learn on those videos
Just meant the 5 user limit in small organizations. 
There are comments telling you how you should start, but I don't feel like I can objectively assess that. So I will just tell you how I started and maybe you can take some advice from that. C++ was my second language, my first being Ruby. Those are very different from each other (and thinking back, my Ruby code was horrendous). I started C++ with an online tutorial of a person I knew from Ruby development. It was definitely not that bad (for example much better than the in German communities infamous Jürgen Wolf) but it was not that great either. Looking back, I don't think online tutorials are the way to go for C++. I feel confident saying that C++ is one of the hardest things to teach well and therefore there are many tutorials out there doing this wrong. The thing is that C++ not only requires you to learn the power it offers but also which parts of that power are obsolete and old. Then I bought a small book about learning C++, which was actually recommended on Stack Overflow but it was very similar to the tutorial so I did not like it either. At last, I ordered myself the C++ Primer by S. Lippmann if I am not mistaken. That book is **huge** and contains not many practical exercises as far as I remember. But it did teach me the language and its traps. If you have the time and will to work through this, I don't think this is a wrong choice. Lastly, reading a book won't help you without practical experience. I think the best way to start is using Linux (maybe with Virtual Box?) and a text editor. I used Ubuntu and gedit. Then I compiled everything within the terminal with g++. Linux I think is better because I always hated doing stuff in Windows with the command line. And I feel like compiling it yourself will give you a better feeling about what is happening. You will sooner or later get a linker error in your code and if all you ever did was press the "compile" button in some IDE, you might be lost then. As I said, I also recommend a text editor without auto completion. I was a tutor in several programming classes for freshmen and that is usually what they recommend as well. It is the same concept as driving: if you drive without a GPS or navigation system it will be harder and you will fail more often but in the end you have learned more and do not depend on it. Hope I could help a bit.
I agree. Whilst learning the basics of the language it is simplest to just pass a file to the compiler using the command line. There is no need for IDEs, makefiles, version control, debuggers etc, at this stage. They have more than enough to learn without concerning themselves with all the tools used by professionals for large projects. 
I disagree, it's horrible for beginners. It's a "must have" as a reference for people already familiar with C++. But for a beginner to read and learn - no.
And carpenters should use rocks instead of hammers. Gotta learn how to put those nails in the hard way.
Good advice in this thread so I am mostly seconding what others say. I would get one or both of these: C++ Programming Language (4th Edition)by Bjarne Stroustrup C++ Primer (5th Edition) by Stanley B. Lippman (Not to be confused with Primer *Plus*, which is *not* recommended) I actually read them side-by-side. I'd usually get stuck on Bjarne, so I would then turn to Lippman to help clear up my confusion. Stick to sources that are c++ 11 or greater. Recent changes in the c++ standard involve more than a few added features. Standard methodologies have evolved since the old days and you should learn the modern way (the aforementioned *Primer Plus* book which I warned you about was an example of the old c++ mindset as "c with classes" and should be avoided.) When I started learning I decided to go on a little "hello world" tour and get a c++ program compiled and running in different environments. VS on windows, g++ on linux, xcode on mac, etc. Use different IDEs, then try it with command line, then see if you can create a makefile, then see if you can get cmake to create a makefile. I don't know if this is good advice for everybody, but I did it this way because I wanted to overcome my fear/aversion of "different" environments. Some folks have urged against using the VS IDE ... I have mixed feelings about this. Code completion can be pretty handy as training-wheels to get you started quickly, and the debugger is unmatched. But there are a lot of developers who can't function outside of the IDE and you don't want to fall into that trap. So make sure you stay comfortable writing code using a text editor and command line compilation. Finally, I urge you to not get discouraged. Understand that c++ *is* kinda hard ... but not so hard that you can't tackle it! If you feel like your progress is slow (compared to how quickly you learned html/css), don't worry! It just takes time and practice. We all went through it. And when you master it, you'll find that what you are capable of doing on a computer will have increased tenfold. 
Do something fun, like a very simple video game.
For added fun: Debug &gt; Windows &gt; Disassembly
Hadn't seen Community edition, will give it a look. Cheers.
It's just the overview chapters from The C++ Programming Language expanded on and it's only 193 pages, perfect for getting a quick handle of the language. How is that a good reference for experienced users? I think you are confusing books.
It is a great book, but I don't think it's suitable for a beginner. Bjarne himself says beginners should start with his "Programming - Principles and Practices Using C++", which in its 2nd edition has been updated for C++11/14.
Especially great for core dumps (which a novice will get a fair share of).
99% of debugging problems are going to come down to "Where is the problem" and, generally, simply printing out "here 1" in one spot and "here 2" in another spot will let you see that hte problem happens between two spots, allowing you to narrow down. For a novice this is the fastest way to debug, because compiling is so fast for tiny projects. Naturally, debugging is an invaluable skill, and a requirement for larger projects, but I'd leave that sort of things for later.
[The easiest way to "Teach Yourself C++ in 21 Days".](http://abstrusegoose.com/249)
Now I feel really bad for using header only libraries like glm because I can't control the error messages anymore. 
Sounds cool. I wish these competitions provided a VirtualBox Image of the test system so people could easily get started and so that it was consistent for everyone.
Get access to "Accelerated C++", it's a good book that doesn't assume you're an idiot and need to be spoonfed everything.
I read somewhere (though I can't find it now) that there's an annual income limit of $1M or something.
The trial system is just a basic 64 bit Ubuntu. To build a vbox image yourself, just do this: - install Ubuntu - sudo apt-get install g++
While I don't participate in the competition, I love seeing the submissions!
There is. But do you really want to code so defensively to cover all such cases? Do you think anyone does?
Not bad, thank you. Here is my explanation, which I think is even easier on the mind: **a monad is a computation pattern**. 
A monad is a design pattern that controls code execution flow.
The announcement says that it's the default one of Ubuntu 14/10 (utopic), so [4.9.1](http://packages.ubuntu.com/utopic/g++).
Good approach, but one thing is missing: the benefits of the monad. The reader is left with the question, "OK, and why should I use this". When you have fully explained the return, map, join operations, you should also demonstrate how useful these can be in C++. For example, write some pseudo code that runs several functions in a sequence, each of which can fail. Write one version of this code with monads, and one without. This immediately shows how much clearer the monad code is, compared to the non-monad one.
Any and all computation pattern(s)?
What's a computation pattern?
yeah, it's not so bad. * In all regular functions, throw an exception when an API call fails. * In the destructor, just ignore it or log it. (It's closed externally anyways.) However you can't be noexcept in move operations, so it's better to just disable move.
I use a different vocabulary in the c++ code I developed that does these kind of things. Maybe&lt;T&gt; (instead of optional). Because Maybe there is a value in there or maybe there isn't, who knows?. apply (instead of map). Because you are potentially Applying the possible value in a Maybe as an argument to a lambda. collapse (instead of join). Because you are collapsing the entire potentiality of a value/type to it's actuality, which may in the end be nothing at all. So an example of the code I tend to write: Maybe&lt;CoolStuff&gt; GetCoolStuffCouldFail(); Maybe&lt;int&gt; intMaybe = collapse(apply(GetCoolStuffCouldFail(), [](CoolStuff &amp;&amp;cs){ if(cs.isCool()) return Maybe&lt;int&gt;(42); return Maybe&lt;int&gt;(); // fail })); Here apply gets (via templates) the return type Maybe&lt;Maybe&lt;int&gt;&gt; which needs to be collapsed. Then you go on to do something like: apply(intMaybe, [](int i) { SomeRandomGlobalFunction(i); });
A pattern of computations. A specific way to compute something.
A specific way to compute something.
I'd say yes, but I am not a mathematician, so I may be wrong.
Hm, I cannot see how it can be defined for std::pair. What does nothingness mean for a pair?
The C++ standard is more than just the language specification. It is also the specification for the standard library. It would be nice if your chart showed where each of the implementations stood in standard library compliance as well as language compliance.
When i first started paying attention to monads years ago, i latched onto the saying that theyre "programmable semi colons". That made sense for the io monad and the maybe monad. Now that I'm much more familiar with them i just remember the operators and laws, because any analogy i try to use eventually falls apart. I.e. monads are monads and they behave like monads :)
Is that not like saying quicksort is an algorithm? It's technically true, but doesn't help anyone to understand quicksort.
Probably because nobody cares. Actually I use Sol studio at work and the very first thing in 2015 is porting to gcc
One such thing can be sanitized enough to be safe, I guess, but this some rogue program closing your window can just as well close any other handle in your program, including those used by user32 or msvcrt that you have no control of.
&gt; Probably because nobody cares ...except us who have paying customers using these compilers.
Then this description (in the OP link) is wrong
Most of them are on par, or even ahead of MSVC.
It's succinct, but it is not an explanation.
Haskell represents a monadic pair as a State monad. http://www.reddit.com/r/cpp/comments/2lx4jw/state_monad_implemented_in_c14/ If you're referring to the article's mention of a unit (or `void` or `()`) and C++'s lack of, that could be trivially solved by making a `unit` class. struct Unit {}; The `return` (or I'll call it `mreturn`) function would return this: std::make_pair(std::move(x), Unit{});
Do they offer anything better than GCC or clang? I guess Intel's has very specific optimizations for their processors but that would probably only help you in very niche applications. 
ok, so it isn't the pair that is empty, it is the elements. Or rather a pair is empty if both elements are empty. Partially empty if one is empty.
The previous article I wrote has these examples, actually. I could have sworn I linked to it. I'll update the article to link to it in the first paragraph.
Please back this up with evidence.
None of this is making any sense
Here's a table listing much of the popular functionality used in C++11/14. http://en.cppreference.com/w/cpp/compiler_support IBM's compiler is on par with MSVC 2013, and Oracle's compiler is on par with MSVC 2015. IBM's compiler is behind MSVC 2015, but 2015 is still in beta. IBM is releasing a new compiler next year as well and they plan to add even more support for C++11/14.
Yes, the VS version number is skipping 13. The C++ compiler has a different version number, because it predates the Visual in Visual C++. Notably, the compiler version (which can be inspected through the _MSC_VER macro) is incrementing normally, from 2013's 18.0 to 2015's 19.0. And yes, we had a 13.0 compiler long ago (in 2002).
VS's versioning couldn't be any more confusing.
Ideally, something analytic, though I will settle for continuous and differentiable. (And I don't want to hear anything about this being impossible with a quantized range and domain.)
I'm sorry, but when I look at that table, Oracle is *behind* MSVC 2015 (no atomic operations, user defined literals, ref qualifiers, and concurrent object construction/initialization/destruction). And while IBM's just-released compiler is on par with VS2013, it is a year behind in release. I don't see any evidence to support your earlier claim that other compilers (non-gcc, non-clang) are on par or ahead of MSVC. EDIT: And it looks like [IBM is starting to move some of their platform compilers (currently Linux, Power platform) to use a clang front end](https://en.wikipedia.org/wiki/IBM_XL_C%2B%2B). So IBM compiler compliance will become irrelevant (except that commercial compiler suites using open-source front-ends usually end up being several months to a couple years behind the open-source counterpart. Ex: QNX's gcc-based compiler has very recently gotten upgraded to gcc 4.8, previously supporting only gcc 4.4.2; gcc is well into its 4.9 releases.)
Intel's compiler is nice in that apart from the optimizations it integrates pretty much flawlessly with Visual Studio. The tooling from Composer, Advisor, and Parallel Studio are pretty damn good. The sheer cost of all of that though pretty much relegates it to like you said niche use cases. I use C++ as a hobby, ICC did nothing for me MSVC didn't do (and at the time I last used it, ICC supported less C++11 stuff than MSVC did)
&gt; Yes that's true, the only major feature IBM has that VS 2013 doesn't is constexpr, however, they both are missing most of the same things. wat All of the things I listed are implemented in VS 2013 (and some long before that). They are not even close to "missing most of the same things".
Yes they are both missing most of the same things, and yes VS 2013 has some stuff IBM doesn't and IBM has some stuff VS doesn't. None of this is exactly Earth shattering. One of the issues with the table is that it is comparing beta or CTP releases of the Visual Studio series against fully supported versions of IBM's compiler. So for example VS 2015, which is still unreleased, is compared to IBM's older C++ compiler which hasn't been updated in awhile. However, as I said, which you conveniently ignored for whatever reason, IBM has made a decision to contribute to clang and use clang for their compiler's front-end while still retaining their own back end. This means that in 2015 IBM will have full support for C++11 and C++14 while MSVC will still be missing many features widely used in open source libraries and only partially supporting many other aspects of the standard. Feel free to continue ignoring that rather crucial point as it may suit you.
Don't worry about it, Crazy__Eddie's comment was not directed at you. He was sarcastically pointing out that spinwizard69 committed some grammar errors himself: "Way way to many spelling errors many probably simple typos." Grammatically correct version: "Way**,** way **too** many spelling errors**,** many probably simple typos." 
Because it doesn't explain anything.
&gt;It’s been pointed out to me that the word “functor” is not suitable for describing C++ function objects No. Functor is the correct nomenclature in this domain. Words mean things, and quite some are overloaded (many times), whether math guys like it or not. If you discuss both domains in the same place, some disambiguation may be necessary though. Otherwise you may get to silly things, like stop calling C++ functions, a `function`, because this is also claimed by math guys and means something slightly different.
Thanks for your input!
I've taken to specifying include directories of third-party libraries as 'system includes' so that g++ and clang++ won't display warnings within those headers. Use `-isystem` instead of `-I`. If you use CMake, you can write `include_directories(SYSTEM path/to/headers)`.
It's funny (or not), some people say that there is too much in C++; and some other say that there is not enough in comparison to standard libs like those of Java, c#, Python... 
Well the standard libs argument I can definitely appreciate, and having a lot of the boost stuff standardized so I can actually use it is nice (boost is an absolute nightmare when dealing with multiple applications, all linking against a different version). I guess it feels to me like C++ is really 3 languages bolted together now: C, C++03 and C++11/14/17. The trouble is that the last one of those just looks completely alien to me :) I'd better brush up...
I agree with you that the C++ Standard is becoming bigger and bigger; I do admit that it sometimes frighten me, however if you look at it more closely you will realize that the amount of *core language* change is actually relatively small. Concepts are coming in, Modules as well, which are really welcome (and tardy) and otherwise there is some cleanup, but it's actually old news already: much newer languages have had those features from the get go! The biggest changes, these days, are on the libraries. The Standard library has grown tremendously with C++11, and it keeps growing, and the new library TS will keep adding to it. However those changes do not require learning new idioms: they just require learning new APIs, much like learning to use any library would. And for anyone who has had to deal with threading or filesystems "by hand", they are life saviors, for those are areas that generally require platform-specific code, so that everyone without access to Boost/QT will keep recreating abstractions to hopefully get similar behavior on various platforms... ... so, for my part, what I see is simply a standardization of known pain points. It makes the Standard bigger, but does not make it any harder to learn C++ because unlike core language changes you can always ignore a library whose functionality you do not need.
Hope there will be more news on modules.
I'm so down with removing unary_function and binary_function if it means we can then remove the typedefs in function objects for result_type, etc.
You are aware that C++98/03 permitted unary and binary operator&amp; to be overloaded, right? (This is the Standard Library Implementer's Bane; C++11 added addressof() to defend against the unary form.)
Are both unary and binary a problem? Binary seems like it'd be one of the straightforward operators.
Oh good, I was worried it was gone for good.
/u/STL do you know if the MS implementation of std::filesystem will have a decent support for very long file names? In my experience boost::filesystem v3 is completely broken for anything above MAX_PATH where you need the \\\\.\\ prefix as well as making sure all the slashes are backslashes.
Effective Modern C++ covers the how and why of some of the critical stuff quite well.
&gt; You are aware that C++98/03 permitted unary and binary operator&amp; to be overloaded, right? You're not suggesting that these overloads were removed from C++11, are you?
Codegolfers are going to hate the removal of trigraphs.
VS 2015's implementation of the Filesystem V3 TS respects \\\\server\directory paths as required by the spec, but does not attempt to handle raw NTFS paths (that can exceed MAX_PATH). I've looked into it and concluded that it's fraught with peril.
What I mean is what happens when you have a filesystem::path which contains a 257 characters long, which looks like "C:/verylongname/verylongname2/..." and then you use operator/() to concatenate to it another string "verylongname999" and you end up with a filesystem::path which is 272 characters long, more than MAX_PATH. You then use this path with something like filesystem::copy() or filesystem::rename() which then fail since MoveFileW() and CopyFileW() expect the path to be shorter than MAX_PATH. So you have a standard-legal set of operations which result in an unexpected error (I assume the standard doesn't know about MAX_PATH) The right thing to do of course is to detect when the path is longer than MAX_PATH and then, right before calling an API, to change the path to its "\\\\?\C:\verylongname\verylongname2\..." format which can handle up to 32,767 characters. My question is - is this going to work properly? I'm asking because this very problem forced me to implement most of boost::filesystem myself on a project I'm currently working on. (my original question said \\\\.\ but I actually meant \\\\?\\)
It's a definition. 
I'm curious about their implementation as well. I investigated hotloading code by linking as a dylib/dll and then loading into runtime with dlopen/LoadLibrary, but have yet to resolve static/global variables across the dynamic library boundary. (yet another reason besides thread safety to avoid globals)
http://codegolf.stackexchange.com/ It's a good time
What the fuck?
Will it still be under the experimental namespace or how does this work?
Technical Specification (TS) is document that isn't mature yet to be an International Standard (IS), but it could be implemented by C++ vendors as an experimental library. See [ISO/IEC JTC1 Procedures](https://isocpp.org/std/iso-iec-jtc1-procedures) for details.
as I understand the Sutter proposal is what I'm after, and the Stroustrup proposal is a superset of it; so the hope would be that if someone implemented it speculatively, the guys maintaining clang or gcc would integrate it (maybe requiring a pragma or compiler flag to enable), in the hope that it *does* get into the standard.... instead of waiting for the standardisation process. to me it would seem a good bet to implement the Sutter version.
Reading the document made me all warm inside....I'm damaged.
It is a formal and legal technical document intended primarily for people writing filesystem library implementation.
AFAICS they have mostly same API, but I see small differences in string conversions using locales. Probably it isn't implemented yet in boost::filesystem.
&gt; other will appear in C++17 Standard Is the standard being expanded more at the moment than in the past or am I just hearing about it more? 
Reminds me of cling which JITs the code using llvm instead of executing the compiler and loading a lib... https://root.cern.ch/drupal/content/cling
to put it very very mildly, maybe you should embrace change, isn't that one of the joys of our profession? [when i see what the intern has done on my project](http://thecodinglove.com/post/103724065284/when-i-see-what-the-intern-has-done-on-my-project) on a serious note, this is not right sub for this kind of discussion.
I want to piggyback onto kosenkos answer, he is 100% absolutely correct that the C++ standard is permanently expanding. However, depending on your age, this might be the first expansion you saw, due to a lull in development (due to various reasons, but not because work stopped). There was a new standard in 1990, in 1998, but then there was a 13 year gap to 2011, when everyone working on it was hoping for an 200x release, which didn't happen. Stroustrup wants a new standard to be ratified every 5 years, but, the best laid plans of mice and men...
Does it solve the problem of mapping drives/volumes in a cross platform way? That is still a major issue for boost::filesytem::v3
The authors of this project have videos explaining (very briefly) on how this works: http://runtimecompiledcplusplus.blogspot.com/
It's not meant to be practical to use _yet_. It just so happens that Boost also has an implementation of this, and the TS is heavily based on it, which diminishes the utility of _std::experimental::filesystem_. Having the experimental namespace gives library and compiler maintainers a chance to get pieces of stdlib and the necessary compiler machinery for a given feature out there without forcing everyone to have it and use it. It allows them to sort out some of the bugs and implementation deficiencies before fully releasing it. If you're attempting to use std::experimental in production code, you're doing it wrong. At this point, like you've already noted, just use the Boost version if it exists until the TS becomes a standard. 
Thanks for the feedback! I wasn't aware of `QVariant`. I'll definitely look into it. One thing I'm not fond of in my design is that I need a static class to keep track of all the from/to converters; `VariantConverter`. This was because the only information related to the 'type' in my design would be the `VariantValue::getType()` method. The `template` type is lost with the 'type erasure'. `QVariant` might give me a better idea to redesign my version.
And never shrinking.
I don't really see what you need a variant for in the network layer. For our fork of eathena (which has changed a lot in the 10 years), I've just finished a python script that describes all the packets and *generates* all the code that directly deals with them. While we don't have any packets whose contents vary between protocol versions (since we have an open-source client we can just add a whole new packet), the same idea would apply. I'm currently converting my variant from the existing MATCH macro to paired MATCH_BEGIN/MATCH_END macros to avoid the broken-break problem, which turned out to be far more significant in practice than I imagined. After that I'll get back to working on the python script that formally describes all config options ... It looks like you're using a finite variant, not a generic variant ... that's a far simpler problem to solve. I implement my own generic variant because boost's didn't support move correctness: https://github.com/themanaworld/tmwa/blob/master/src/sexpr/variant.hpp Edit: reordered paragraphs.
Why bother? That's adding a significant amount of complexity (i.e. latency) to your server. Since bandwidth is not a concern, might as well just make all integers in packets be 64-bit.
That would be true, if only the size of the int didn't change between packet versions. I was initially using boost::variant prior to designing mine when I faced the shift in int type. The prior packet version used 16-bit, while the renewal version changed that to a 32-bit integer. I was extracting it as a 16-bit in my code, which failed because boost::variant wouldn't convert between types. Also consider that there will be strings in the packet, like that chat related packets. Union is a bad solution for this particular use case. Also how would this particular Union read the right amount of bytes from the network stream?
Hi, consider that the A class is there only for me to shortly explain my idea, I know that it has horrible and quite useless get/set methods. They are there just to stub any reasonably complex query methods is in a real class/struct. 
Outstanding!
Do you have a better solution, or just quoting?
Working with the type system and not trying to work around it? It's there to help you.
Someone I know tried to use libclang to analyze #pragma statements in the AST, but was unable to do so for the same reasons mentioned in the article. It would be nice if libclang had an option to incorporate information into the AST that it would normally discard. cldoc, a Markdown-based, documentation generator for C++, also has various issues due to missing features in libclang. 
I guess I haven't done a good job of explaining the problem I was trying to solve. See the comments below about the packet versions in the game client I'm trying to emulate. TL;DR: There are two types of servers, renewal and non-renewal ragnarok online servers. The packet format that each server has will vary slightly between each other, where a 16-bit integer field in the packet is now a 32-bit (or even a float). Since a ragnarok players can play on any of the servers, I devised a flexible packet definition system. In my code, I will always read from the Variant storage as a 32-bit integer, while the variant could be storing the actual value (as read from the network packet) as either a 32/16 bit.
Anyone wanna take a stab at an answer ? Here is a project I'm working on : https://github.com/OSSIA/i-score , if somebody can tell me what monads could make better :) 
I have seen fields implemented as variants before, but only in very general cases like `class MySQLDB;`, where you are consuming an unknown database with unknown fields. In this case you know all the field types ahead of time. It seems to me that using OOP here would be a superior solution. You are still doing the type checking/choosing somewhere in the code saying `if(version == x.xx) fieldType = int16` wouldn't just building that information into your types organizer your code better and make it simpler? It would deffinitely make your code safer and faster.
Good point with the naming! I'll check that...
And put the damn thing in a namespace, especially since you make modern C++ claims... No need to pollute the global namespace with JSON. 
Good point! What name would you propose?
I changed the name to "json", and it feels better. Thanks for pointing that out. (I was used to capitalize the names of classes, but totally missed that all STL containers have lower-case names...)
Thanks for pointing that out - I fixed it.
Wow, this looks really awesome, and now I'm hoping I come across a reason to tinker with it sometime soon! I do have a really random nitpick though... I happened to notice that you seem to be using `noexcept` on constructors that allocate memory. Since `new` can throw an exception, this seems to be rather odd. The behavior from this is going to be that any thrown exception is going to call `std::terminate` instead of having an exception thrown. Perhaps this is the desired behavior and a tradeoff you're willing to make given the rarity of `new` actually throwing. Considering this is a significant deviation from the philosophy of the standard containers, and that it will limit portability a small amount, I just wanted to throw it out there.
You can see the kind of havoc this causes very clearly in the Google Test framework. Here's a snippet concerning the use of tuples in `include/gtest/internal/gtest-port.h`: // Determines whether Google Test's own tr1 tuple implementation // should be used. #ifndef GTEST_USE_OWN_TR1_TUPLE // [edited for brevity ] #endif // GTEST_USE_OWN_TR1_TUPLE // To avoid conditional compilation everywhere, we make it // gtest-port.h's responsibility to #include the header implementing // tuple. #if GTEST_HAS_STD_TUPLE_ # include &lt;tuple&gt; // IWYU pragma: export # define GTEST_TUPLE_NAMESPACE_ ::std #endif // GTEST_HAS_STD_TUPLE_ // We include tr1::tuple even if std::tuple is available to define printers for // them. #if GTEST_HAS_TR1_TUPLE # ifndef GTEST_TUPLE_NAMESPACE_ # define GTEST_TUPLE_NAMESPACE_ ::std::tr1 # endif // GTEST_TUPLE_NAMESPACE_ # if GTEST_USE_OWN_TR1_TUPLE # include "gtest/internal/gtest-tuple.h" // IWYU pragma: export // NOLINT # elif GTEST_ENV_HAS_STD_TUPLE_ # include &lt;tuple&gt; // C++11 puts its tuple into the ::std namespace rather than // ::std::tr1. gtest expects tuple to live in ::std::tr1, so put it there. // This causes undefined behavior, but supported compilers react in // the way we intend. namespace std { namespace tr1 { using ::std::get; using ::std::make_tuple; using ::std::tuple; using ::std::tuple_element; using ::std::tuple_size; } } // [edited for brevity] #if defined(GTEST_TUPLE_NAMESPACE_) // Import tuple and friends into the ::testing namespace. // It is part of our interface, having them in ::testing allows us to change // their types as needed. using GTEST_TUPLE_NAMESPACE_::get; using GTEST_TUPLE_NAMESPACE_::make_tuple; using GTEST_TUPLE_NAMESPACE_::tuple; using GTEST_TUPLE_NAMESPACE_::tuple_size; using GTEST_TUPLE_NAMESPACE_::tuple_element; #endif // defined(GTEST_TUPLE_NAMESPACE_) I remember this because I was bit by it. MSVS 2012 has `std::tuple`, but MSVS 2010 only has `std::tr1::tuple`.
The code is IMHO really nice, the only things that i could nag about are: * 100% coverage usually means at least **branch** coverage (for me). * Autoconf gives me nightmares :( Would you accept patches to use CMake (as an additional build-tool)?
Indeed. Documentation is not my strong point, especially as I usually just read source and examples. I've added some more content and will keep doing so. If you have specific questions I'll try to answer them and add to the wiki.
Hopefully the links in the comment I made above (if it remains above) helps.
Well, json seems to easy and again risky in getting conflicts. I'd either go for json or modern_json or some other combination with json.
I completely agree with my poor explanation. I'll (hopefully) get it rectified today or as soon as I'm able to (I'm traveling ATM). The types are not stored as strings internally though. If that was the case I wouldn't be able to store `struct`s, which is just Variant that stores `map&lt;String, Variant&gt;`. Network packets fields can have a list of PODs or `struct`s like the network packet that lists all characters (and their basic stats). A list is represented as a Variant as well, just that it stores a list 'properties'; like list of `std::pair&lt;String, Variant&gt;` (but not exactly in my implementation). As mentioned as part of my answer to your previous comment, the type is not exactly known and having a huge list of if-else in code doesn't really help me as there are atleast 20 different packet versions (actually more). I want my implementation to have little or no change due to packet version differences.
Possibly linux development only? (Linux never actually lets you throw bad_alloc, it would rather terminate your process &gt;.&gt;) --- I stand corrected
I'd go for the longer one - it's a lot easier to rename the namespace in the using clause than it is to fix a conflict.
I think the [general](http://stackoverflow.com/questions/228783/what-are-the-rules-about-using-an-underscore-in-a-c-identifier) [consensus](http://programmers.stackexchange.com/questions/191828/might-starting-variables-members-with-an-underscore-puzzle-the-compiler) is to not use underscores at the start of variable names, since that particular usage may be used by the compiler implementation. Most people who want to use underscores for private/member names use them as a suffix rather than a prefix. It's an ugly hack, but it gets around the aforementioned problem with prepended underscores. But then again it doesn't seem to be broken in your case, because you've stayed away from double underscores and underscore/capital letter combinations.
I was once using a library with a noexcept on a destructor that threw an exception on some edge case. It was the most frustrating bug I've ever had to deal with because I couldn't break the code where exception occurred as it just terminated the application instantly and I had to hunt it down through trial and error and tracing the whole program. Does anyone know why noexcept exists as opposed to letting the exception propagate to main and crash the application? 
Thank you for pointing that out! I was not aware of the problems with when underscores are used as prefix. I renamed the members to use "_" as suffix.
Thank you! - I am currently just using what coveralls provides - is there a simple way to measure branch coverage as well? (It took me quite a while to reach 100% code coverage, and I will invest in high branch coverage as well...) - Autoconf is neither simple nor really required in my case. As I have little experience with CMake, any patch would be welcome!
Hey just curious, are you not handling Unicode encoding (of the form \\uXXXX)? I did a basic search on my mobile of your code and tests and don't see anything regarding that.
The primary reason is to let the *standard library* perform some extra optimizations. The basic problem it was added to solve was that `std::vector` couldn't use move constructors in `resize()` and maintain the exception guarantees that it had in C++03 (i.e. that if it throws, the vector is left unchanged).
Love it! I think this would be fare more useful as a header only library. I'm down for sending a PR with the change if you are.
`new int[-1]` will throw `bad_alloc` (and I've seen that happen in practice on Linux due to some missing error checking resulting in passing an error code rather than a size), as will plain old address space exhaustion on 32-bit.
I often use m_var for member, and s_var for static.
My example was to highlight that variants would be one way to handle any database schema. I am getting an idea of why you went this route. I agree that keeping a separate meta-info file much better suits to such volatility in the types. No one would want to redeploy binaries just because the packet version changed slightly.
I guess you will have to expand on your blog post some more :) Both the problem and your solution sound interesting.
web::formats or some such
Very nice. Do you know if it will compile with Visual C++ (2013 or 2015)?
This guy... he da real MVP. I'll definitely be using this.
Love it! What would be the best way to read json from a file? Something like this? std::ifstream config_file("config.json"); std::stringstream config_buffer; config_buffer &lt;&lt; config_file.rdbuf(); json config; config &lt;&lt; config_buffer; Do you have any plans to add file handling?
One thing I wish I could change about Json, Are quotes really necessary on the lhs. { foo : "bar" } seems so much better than { "foo" : "bar" }.
Very cool stuff. Looks similar but simpler than rapidjson, and more modern. Can your initializer-list syntax disambiguate 'array of 2 strings' from 'object with a single string field'? e.g., how would you represent: {"help":["a","b"]}
First, the code looks nice. Still, I would really be against this as a "true" part of C++. I think this is confusing a data structure/abstraction with a serialization format (and a horrible one at that). What we've got here are, IMHO, two different concerns, which are worth addressing separately. 1. Wouldn't it be nice to have an auto-typed std::tuple (which implies that it can be hierarchical)? 2. Wouldn't it be nice to have a convenient function for serializing std::tuple's to JSON, and deserializing a std::tuple from JSON. With those separations of concerns, the problem a) looks simpler and b) avoids confusing serialization with tuple literals. You also realize just how close the language already comes to letting you do the job. You also realize that you should probably use tuple for this instead of a hand rolled variant type.
Just to clarify what I mean, to a large degree you already have all the functionality you want with a std::unordered_map&lt;string,variadic_type&gt; type construct, but that is way more overhead than you really need/want for a lot of non-JSONy type contexts. Instead, you want tuples with named fields. Consider how close you get to what you really want just with this basic scaffolding: template &lt;typename T&gt; using named_field = std::pair&lt;const char*, T&gt;; //there are more elegant ways to do the type transform, //but this is quick and dirty and pretty clear template &lt;typename... Args&gt; struct named_tuple_mapper; template &lt;&gt; struct named_tuple_mapper&lt;&gt; { using type = std::tuple&lt;&gt;; }; template &lt;typename T, typename... Args&gt; struct named_tuple_mapper&lt;T, Args...&gt; { using type = decltype(std::tuple_cat(std::tuple&lt;named_field&lt;T&gt;&gt;(), named_tuple_mapper&lt;Args...&gt;::type())); }; template &lt;typename... Args&gt; using named_tuple = typename named_tuple_mapper&lt;Args...&gt;::type; Now you can define an arbitrary tuple with named fields, and we haven't even created a new type yet! There is *no* restriction on the type of the fields, but if you wanted to narrow it down you could always but some restrictions in your named_field type. With some inconvenience, you could use string constant pointers as template parameters, though that's pretty evil and likely would have surprising limitations. Without that, you can still have operator[const char*] overloads for accessing fields (they just become runtime computed scans to find which N to pass to std::get&lt;N&gt;). You would probably want to make a convenience function out of std::make_tuple(...) that constructed named_tuples cleanly, but you can otherwise exploit all the stuff that is already in std::make_tuple. You also don't have to work around JSON's type ugliness (and the problems with character encodings!!!). When you do want those, you tack that with formatting. When it comes time to deal with formatting, you should handle that not so much by having a custom type and parse/to_string functions (the latter is particularly bad because it requires you allocate the entire string then append to the stream rather than appending as you go to the streambuf), but simply have a custom IO manipulator for json.
Needs more boost. :)
I'm sure that was sarcasm, but boost could help if you wanted to actually use a variadic type for the value field (though I think in most cases that is way overkill). 90% of what I'm describing is already there in the language standard. They just didn't make an explicit named tuple construct.
What they mean is that the term "code coverage" really means branch coverage. So 100% "code coverage" doesn't really mean 100% of your code is tested, just that 100% of the branches are ran. It's not something I traditionally rely on because it's not exactly truthful in it's assertion.
There should be enough information to integrate this into your code already, but if not please ask questions and I'll try to answer them and incorporate this into the documentation.
Why wouldn't you handle the conversion part of the problem through type casting (perhaps std::dynamic_cast it needs to be decided at runtime)?
Why was that a good point? I liked JSON better. Besides, isn't it a common practice to name classes starting with upper case? 
The standard library uses snake_case. To me, CamelCase looks java-ish
It's not handling any of that. It doesn't handle strings in general properly. It finds closing quotes and calls it a day. AFAICS, the JSON string `"\n"` will parse as the C++ string `"\\n"`, when it should parse as the C++ string `"\n"`.
That makes no sense. The compiler doesn't know anything about JSON strings that only exist at runtime.
&gt; The compiler doesn't know anything about JSON strings that only exist at runtime. No, it doesn't, and I see the disconnect. I thought you were worried about: json j; j["foo"] = "bar"; In which case, sure, it doesn't know about JSON strings, but it knows about string literals, and the standard string literal encoding rules would apply. You're looking for a way to encode unicode characters in to a file that gets parsed by the json parser. Yeah, it's not a fully functional JSON parser. You'd need to either enhance the parser or swap in a different one. In general, this isn't yet a fully functional JSON solution, and the escape literals are just one of many reasons not to want JSON as something core to how structured data gets represented in the language.
Great library! However, I'd suggest you rethink your choice of std::map as a container for objects. A simple std::vector&lt;std::string, json&gt; should always be faster for small objects (with less than say 100 or 1000 fields, which will probably always be true for your use case) due to better memory locality and branch prediction when looking up with std::find_if. Alternatively, you could keep the vector sorted by inserting new items at their appropriate locations and use binary search, which will improve lookup times but at the cost of slower insertion. This is the approach taken by boost::flat_map. Also, in enum class value_type I'd put null=0. Plays nicer with the debugger.
I mentioned in my [comment](http://www.reddit.com/r/programming/comments/2rbj96/json_for_modern_c_what_if_json_was_part_of_modern/cnembo4) in /r/programming that I think you can just use `boost::variant` for a JSON type typedef boost::make_recursive_variant&lt; double, std::string, bool, std::vector&lt;boost::recursive_variant_&gt;, std::unordered_map&lt;std::string, boost::recursive_variant_&gt;, std::nullptr_t, &gt;::type json;
What do you mean by JSON has char? I can't see any mention of that in JSON documents - I feel like this is a joke that's gone over my head! I can't see how `std::tuple` is appropriate for JSON. You need to know the types of the fields at compile times, which you aren't going to know if you are deserializing. If someone gives you the JSON { "a": 1, "b": false } Then you can't possibly return the type `std::tuple&lt;int, bool&gt;` from your parser since types cannot depend on runtime information. A recursive variant is the correct type for a JSON object.
Oh, yeah, you've gotta handle escape sequences correctly. I doubt he's encoding correctly either then; you can't have line breaks within json strings as I recall either so if he's not encoding them on output that'll be a problem too. I think json strings aren't allowed to have raw escape sequences at all in them either (like tabs.) You'd have issues if you're dealing with servers or other services that needed them.
Json (when encoded properly) uses utf-16 character encoding, but in c / c++ you'd use utf-8 character encoding for std::string or char\* types since its ascii / backward compatible. In other words, it's something you have to do when parsing, not anything handled by the compiler or operating system.
What is the reason you are not using smart pointers (unique_ptr) so you can remove your deletes?
I would suggest std::json. Ha ha Really though, great work. I will certainly be using this in a project I'm currently working on. It will vastly simplify some of the things I've been trying to do.
I use excel very often at work, I typically use the integrated vba language. I found python with pandas a while ago and fell in love. However, it is not the greatest in terms of speed. I also felt like I coded slower than in vba (go figure) . Probably because there were so many different libraries (xlw/xlrd, xlwings, pandas, etc) . So I ended up back with VBA for work projects (40-80% excel) . It took me a bit of googling and trial and error to find the best way to use python to interact with excel. Do you have an opinion on some libraries that you could suggest? Hopefully this question doesn't come off as lazy, I just am somewhat of a novice in c++ so I may not realize what is a good /bad library. 
Any speed benchmarks? 
I chose "json" on second thought as all other built-in types and the STL containers all use lower case. I also use class names starting with upper case in other settings.
I compiled it with Clang 3.5 and GCC 4.9 using "-std=c++11". Which C++14 features are used, and how can I make sure that I stick to the C++11 standard?
Thanks for trying! Do you know whether there are plans for Visual C++ to support all C++11 features?
Tried to use it a little but got annoyed that the conversion functions aren't part of the ujson::value. Personally i prefer value.object_cast() than ujson::object_cast(value) because i can use code completion more quickly. Also, any reason to allow duplicated keys? Most json libraries that i used don't allow it. I'll stick with json11 for now. Edit: the parser seems to coerse invalid numeric values to zero, is this intended? seems like a bug to me: #include &lt;string&gt; #include &lt;iostream&gt; #include "ujson.hpp" using namespace std; int main() { try { auto value = ujson::parse("{\"number\": 1k2}"); ujson::object const &amp;ref = object_cast(value); auto it = at(ref, "number"); while(it != ref.end()) cout &lt;&lt; it++-&gt;second &lt;&lt; endl; } catch(const exception &amp;e) { cout &lt;&lt; e.what() &lt;&lt; endl; } } This will print "0" instead of throwing an exception.
But then you would exclude spaces in key names :-)
I prefer free functions, so that the interface of ujson::value can be kept as simple as possible. Also, you don't need the namespace prefix for free functions like object_cast, since they are found using ADL. Regarding duplicate keys, the JSON spec does not explicitly disallow it, though I would never use duplicate keys in my own code.
Don't forget that gcc 5 will get rid of CoW, and other such future backwards-compatibility problems (I noticed MSVC noexcept in passing). 
I think you may have changed it to someone else's suggestion that I didn't see, before you were declaring several plain functions with the form auto function_name(parameter_list) { //... return someVal; } which is actually a C++14 feature, not C++11 (in C++11 you'd add a `-&gt; return_type` clause before the open brace). I can't find them now, though, so there's no problem.
You are right - the string parser currently treats anything between two unescaped quotes as a string. I know this is too vague, and I wrote &gt; Furthermore, we allow for more escape symbols in strings as the JSON specification. While this may not be a problem in reality, we are aware of it, but as long as we have a hand-written parser, we won't invest too much to be fully compliant. in the README. I tried to use C++11 &lt;regex&gt; to exactly cover the JSON specification, but the resulting code was slower by an order of magnitude. For the future, I either try to build code from parser generators such as Flex/Bison, or overwork the code manually to be compliant.
OK, then I am relieved :-) The only thing that is in the code are some lamdas in the unit tests like auto id = [](json::array_t v) { return v; };
Parse 2524695 bytes autogenerated JSON string, best of 64 runs. Code for generating the JSON test file can be found in ujson/test/test.cpp. * rapidjson: 5.1345 ms (879def8) * ujson: 10.1318 ms (d52d47f) * jsoncpp: 19.8838 ms (f44278c) * json11: 20.0187 ms (be63116) * json_spirit: 103.521 ms (using the zip from codeproject and boost 1.57) i7 3770K, Visual Studio 2013, CTP_Nov2013, 64 bit. 
Just a matter of habit. A quick Google search shows me that there seems to be no "right" C++ file suffix: http://stackoverflow.com/questions/18590135/what-is-the-difference-between-cc-and-cpp-file-suffix - http://stackoverflow.com/questions/1545080/correct-c-code-file-extension-cc-vs-cpp
Thanks!
Good catch! Fixed in latest commit.
The "little to no overhead" gives me headaches. I'll check what sizeof says :-)
If I'm not mistaken, there is no memory overhead because it just stores the raw pointer internally. But there could be a little runtime performance overhead when using another deleter. So when using the default deleter instead of manually call delete, there is no overhead.
as zzyzzyxx said, but shorter: I don't want to pay for what I do not use. In a console app, the lock_guard is a thing that I do not need or want. Why is it there? edit: if you can provide thread safety without the use of mutexes .... that's amazing then, please do so. Can you do it while matching/surpassing the speed of the library without thread safety? Even more amazing, you're a god among men. 
Interesting, are there alternative tokens for references/addresses too or are they that much newer than `and`?
I agree with you, free functions are nicer when appropriate. 
Code looks great! Why did you decide not to use unique_ptr if you were going for modern c++? Doesn't seem to be any reason to need a non owning raw pointer
Please, add [json_spirit](http://www.codeproject.com/Articles/20027/JSON-Spirit-A-C-JSON-Parser-Generator-Implemented) to the test if possible.
No overhead with regular destructors. Unique_ptr is just a wrapper around a raw pointer so you can use RAII
That's pretty good. Do you think it can be optimized to match rapidjson?
You can see them listed [here](http://en.wikipedia.org/wiki/Operators_in_C_and_C%2B%2B) along with their conventional counterparts. Just to have the list of non-conventional operator keywords in one place, they're not_eq (!=) not (!) and (&amp;&amp;) or (||) compl (~, bitwise NOT) bitand (&amp;) bitor (|) xor (^, bitwise exclusive OR) and apply to both C and C++. I can tell if you were to use them exclusively your code might look much more readable, although odd at first. if(not(x or y) and //if neither x nor y is true ((flag bitand SOME_VALUE) not_eq SOME_VALUE)) { //and that flag isn't set flag = flag bitor SOME_VALUE; //set that flag } else { flag = flag xor (compl SOME_VALUE); //otherwise, flip every other flag } It's actually quite a bit more readable! I might just start using this more.
Would have liked to have seen this mentioned - I hope something comes of it: http://open-std.org/JTC1/SC22/WG21/docs/papers/2013/n3601.html
That's simply false, on top of my mind: * export * trigraph * http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4190.htm ?
This part was most likely generated with a parser/lexer generator like bison or ragel.
Ah, yeah, totally correct. It's been awhile since the job where we were using boost::any. I got it mixed with boost::variant in my head, since QVariant is closer to boost::any. Thanks for the clarification.
You could use [re2c](http://re2c.org/) like [µjson: a small, C++11, UTF-8, JSON library](http://www.reddit.com/r/cpp/comments/2rf39s/%C2%B5json_a_small_c11_utf8_json_library/)
You might want to look at HPX here: https://github.com/STEllAR-GROUP/hpx. It gives you an uniform syntax for local and remote execution (on distributed systems, currently mainly clusters). It supports remote object creation and method invocation on those. All of that fully asynchronous and 100% conforming to the interfaces as defined by C++11.
I'm using: json_spirit::Value value; bool result = read(json, value); This is the vector version, if I understood the documentation correctly?
If you're interested in CORBA or E, do take a look at [Cap'n Proto](http://kentonv.github.io/capnproto/). The homepage describes it thus, &gt; Cap’n Proto is an insanely fast data interchange format and capability-based RPC system. Think JSON, except binary. Or think Protocol Buffers, except faster. The RPC system is very closely based on CapTP, which is the protocol used in E.
This isn't a hidden feature (its actually fairly well-known), but the [Pimpl Idiom](http://c2.com/cgi/wiki?PimplIdiom) is something that is useful that I never learned in school. Hopefully it'll be outdated when modules come along in hopefully c++17. Also, not really a feature either but [the evils of template function specialization](http://www.gotw.ca/publications/mill17.htm) is one of those surprising things that people don't usually know about.
Parameter packs. E.g., compare http://xll.codeplex.com/SourceControl/latest#trunk/xll/excel.h to this http://xll8.codeplex.com/SourceControl/latest#xll/excel.h More general and far fewer lines of code.
Write a comparison function and pass to sort function. See http://www.cplusplus.com/reference/algorithm/sort/ for more info
FYI: The class now lives in a namespace.
Already forked it, although I'm working on the reverse iterator problem atm.
My understanding is that modules do not solve the PIMPL problem, at least not anymore according to the current proposal. The proposed UFCS might help a little, but there's nothing on the horizon to solve it completely.
hidden feature: you can avoid virtual functions and inheritance completely and still enjoy many benefits over C
I would say, IMO, the current state-of-the-art revolves around the approach taken by Thrift/Protocol Buffers/Cap'N'Proto. Other libraries I know of: MessagePack, Avro My impression is that Thrift is still somewhat immature in the code it generates. The C++ generated code is particularly weak. The Java side is pretty good. Protocol Buffers has an extremely unnatural API for creating objects (at least in C++ &amp; Java). It also has a strange requirement that the generated code is tightly coupled to the corresponding library version which makes it a pain to upgrade (has to be done in lockstep). Cap'N'Proto looks very interesting but I haven't had a chance to use it yet.
I am. What is your suggested improvement to map parameter packs to C style vararg functions? -Thanks.
the boost asio doc provides an vanilla http server in cpp11. It should be an useful resource. As for the client, the code is pretty simple. You can get examples just on SO , search asio http.
so will the next block always get executed or never get executed? as it is wrapped in the if statement
I don't like the term 'hidden'. What you seem to be asking about are features that are not widely known. And those features tend to be useful only in limited circumstances, which is why they're rare. The most commonly mentioned ones are: - trigraphs - alternate spellings of operators (e.g. `and` vs `&amp;&amp;`) - [function `try` block](http://stackoverflow.com/questions/6756931/difference-between-try-catch-syntax-for-function) - lots of stuff involving member function pointers, such as [disambiguation casts](http://stackoverflow.com/questions/17874489/disambiguate-overloaded-member-function-pointer-being-passed-as-template-paramet) - various disambiguation tricks involving the [scope resolution operator](http://stackoverflow.com/questions/9338217/why-does-c-need-the-scope-resolution-operator) - the fact that you can write `return foo();` inside a function returning `void` if `foo()` also returns `void` - rules for `goto` when trying to jump into a block in such a way that bypasses initialization of an automatic variable - I don't think a lot of people are very familiar with the actual formal grammar of the language; for example this is a perfectly valid but meaningless program: int main() { a:b :do c:switch ('d') e :f: do g :switch ('h' )i: for(; ; ) j:if(int k = 'l') m : n:":"":"";" ; while ('p' ) ;while ('q') ;r: s:; } 
I would love to see more comments with options on this one ;o
I have used cpp-netlib at http://cpp-netlib.org/ I believe it uses asio under the hood
I'm pretty sure that if the case is IDM_COMPONENT_NEW, then it will always start execution at that point. If the case is IDM_COMPONENT, it will only get executed if the condition is true.
a more benign application of this rule is to put the `default` case first. never done it myself but saw it in a tutorial video. might help readability if the rest of the statement is large but the default case is a legitimate option rather than an assert or exception for "never should get here".
Plenty to choose from. Here are some: 1. [Casablanca](https://casablanca.codeplex.com/) 2. [Poco](http://pocoproject.org/docs/Poco.Net.HTTPServer.html) 3. [Proxygen](https://code.facebook.com/posts/1503205539947302/introducing-proxygen-facebook-s-c-http-framework/)
There is also [cpp netlib](http://cpp-netlib.org/), however, it isn't very much actively developed right now(perhaps again in the future). Also, nghttp2 does look to have a nicer api. Also, for related REST API components: Boost.PropertyTree works nicely for basic json and xml(although it still uses Boost.Spirit v1 for json parsing which is not threadsafe, so you will need to add preprocessor flag for that). Of course there seems to be plehora of json libraries in C++11. Also, for general serialization, Boost.Fusion can be nice. You can adapt regular struct as tuples and them iterate over them like data.
Hi, Today I would use https://github.com/facebook/proxygen. I developed one too because proxygen was not yet out and the other are way too complicated or heavy for my usage: https://github.com/daedric/httpp (it is running in production in my current and last job). In C: https://github.com/lpereira/lwan looks very interesting. Have fun. 
I've not used it but ICE is the suggestion that makes sense to me. People tend to throw out the capnproto or thrift answer to this distributed computing question when that's just a rather small piece of the puzzle. You'd wind up implementing tons of stuff yourself on the way to a robust system that ICE appears to do for you.
Good point - I renamed it to dump() (similar to Python's json.dumps()) - https://github.com/nlohmann/json/issues/13
Not sure if it's not well know, but you can declare variable in if statement and it will be visible in that scope, like this if (MyClass* myObject = SomeFunction()) { } I've used it all the time with smart pointers when worked on C++ project, but can't recall the syntax right now.
Thanks, here is the link I believe, http://www.boost.org/doc/libs/1_55_0/doc/html/boost_asio/examples/cpp11_examples.html I was aware of it, but haven't looked in details.
Thank you, I had followed Proxygen's announcement and had meant to follow up, now seems to be the time! Checking the others out also.
Just that they aren't implemented I guess, although it seems weird yo need them now that I think about it
Thanks for the link to your micro-http server, and proxygen. I might well go with the later, but I don't exclude to support a lighter one for basic apps now, possibly relying on yours. EDIT: very cool lwan, wow!
Proxygen is a lot of code... I guess I am not the only one who would love to see one of these libs easily available as packages on most Linux distros...
It's nice for `optional` optional&lt;int&gt; foo(); int main() { if(auto i = foo()) std::cout &lt;&lt; "Function returned " &lt;&lt; *i &lt;&lt; std::endl; }
Yes, I did not implement them... I had them on my list, but then read that there are simpler ways to implement the whole family of iterators. I hope - with some help - to get new ideas how to have a general approach.
The point I was trying to demonstrate is that you can put labels in a lot of places that people may not realize, and that you can put multiple labels on a single statement, and that whitespace is truly insignificant.
There's more you can [do](https://en.wikipedia.org/wiki/Duff%27s_device) with `switch`, but there are probably very few valid use cases for jumping into the middle of control structures anymore (most compilers can unroll general loops where there are gains). If you want to reduce code duplication, just write a function (and `inline` it if you need).
You can return the result of a `void` function within another `void` function: void foo() { std::cout &lt;&lt; "foo"; } void bar() { std::cout &lt;&lt; "bar"; return foo(); } Which is useful in templated code.
I used something like this the other day for a function that was meant to push certain messages to the beginning or end of a collection. A bit debatable whether it is more readable, but I liked the fact I could see where certain messages were being moved to in relation to the "default" case. int order(message const&amp; msg) { switch(msg.type) { case message::grumpy: return -2; case message::dopey: return -1; default: return 0; case message::sleepy: return 1; case message::happy: return 2; } } int main() { std::vector&lt;message&gt; msgs = get_messages(); std::stable_sort(msgs.begin(), msgs.end(), &amp;order); }
You have a good eye. I don't own the file that collects the arguments into a C-style array. In fact, I made my case during the Excel 2007 beta test to not do that. It looks pretty bad pushing 255 pointers on the call stack, but the Microsoft engineers challenged me to test the performance hit. My recollection was that it only involved moving a stack pointer. Always happy to look at code that compiles to test performance. The point of the Excel&lt;X&gt; function is to hide creating the C-style array from library users. It's kind of funny how Excel is purely functional but the C SDK makes it really difficult to write code in the same style. The LXOPER&lt;X&gt; class was designed for that. As others have pointed out, it is not really a matter of hidden features, it is just a struggle for puny human brains to keep up with all the amazing advances many very smart people have been devoting their time to simplifying and increase the expressiveness of C++. They have the constraint of not starting from a blank slate. As Stroustrup said, “There are only two kinds of languages: the ones people complain about and the ones nobody uses.”
I like Casablanca.
Will you guys field relocation expenses? I'm near Denver, CO. Also, what is the name of the company?
Doesn't that return 0 for both sleepy and happy?
[Local classes](http://www.geeksforgeeks.org/local-class-in-c/) 
No, the return statement exits the function before it gets a chance to move onto any other cases/
&gt; There is also cpp netlib[1] , however, it isn't very much actively developed right now(perhaps again in the future). Thanks for the ref to cpp netlib, I had missed it. Just FTR it seems to still be getting attention from the developers, many recent commits: https://github.com/cpp-netlib/cpp-netlib
Thanks for pointing this out! The main plus (for my purpose) is that it seems already packaged for Ubuntu (and probably other distros) as libcppnetlib-dev (http://packages.ubuntu.com/source/trusty/cpp-netlib).
The ability to access _Ugly / __ugly tech, granted only to implementers.
My biggest problem with these is that they instantly cloud the purpose of a function. Instead of a function doing things, they define data types first and then do things, but the definition and the doing things are intermingled so it takes a lot of discipline on the writer to make it clear, and extra time by the reader to figure out wtf is going on, and it ends up not being worth the visibility benefits
Yeah, modules are basically "only" automatic pre-compiled headers per cpp-file as I understand it. Maybe a little more optimized and better at dealing with macros.
Sadly not yet production-ready, but looking very promising: https://simonask.github.io/w/# The Hello-World is really as easy as it should be: #include &lt;w&gt; int main(int argc, char** argv) { w::App app { argc, argv }; app.get("/", [](w::Request&amp; req) { return w::render_text("Hello, World!"); }); return app.run(); } Just for the record: I am not involved in that project, I just remembered that this was posted here a while ago.
&gt; One of the hidden 'features' of python is the GIL. That's an implementation detail of CPython, not of the Python language. You can use any implementation you want, some of which don't have a GIL, such as Jython or IronPython. By that logic, if there was a popular C++ compiler that was unable to do tail call elimination, then that must mean that C++ does not support tail call elimination, even though there are other implementations that can do that optimization. 
&gt; function try block To extend on them: I really like them because in my opinion they can help with readability of code by further separating the normal-cases from the error-cases and saving another level of indentation. Compare: int main() { try { do_stuff(); if (!some_request()) { return 1; } do_other_stuff(); } catch (std::runtime_error&amp; e) { std::cerr &lt;&lt; "Error: " &lt;&lt; e.what() &lt;&lt; '\n'; return 2; } catch (std::exception&amp; e) { std::cerr &lt;&lt; "Unexpected Error: " &lt;&lt; e.what() &lt;&lt; '\n'; return 3; } } And: int main() try { do_stuff(); if (!some_request()) { return 1; } do_other_stuff(); } catch (std::runtime_error&amp; e) { std::cerr &lt;&lt; "Error: " &lt;&lt; e.what() &lt;&lt; '\n'; return 2; } catch (std::exception&amp; e) { std::cerr &lt;&lt; "Unexpected Error: " &lt;&lt; e.what() &lt;&lt; '\n'; return 3; }
asio is also available as standalone library. Same cpp11 examples page is available here: http://think-async.com/Asio/asio-1.10.2/doc/asio/examples/cpp11_examples.html Edit: forgot to mention that asio standalone is [header only](http://think-async.com/Asio/AsioAndBoostAsio) :) 
It sounds like QML (part of Qt) might be another option, though it's not exactly lightweight.
It is possible the compiler will generate sequential tests in some cases, but my understanding is it tries to go for a [jump table](http://en.wikipedia.org/wiki/Branch_table) if it can. They are much faster, as it computes the offset into the table then a looks up where to jump to, rather than testing each case individually. Regardless of how it gets to the initial case label, it will only "fall-through" to another case label if it does not encounter a break, continue, return, etc. Those statements will cause it to jump out of the switch entirely. And will not try to keep executing through the statements in the switch.
PIMPL achieves two things: - compile-time firewall - ABI stability The former might indeed by outdated when modules come along, but the latter is there to stay.
There's been another version of the talk given at C++Now 2014: https://www.youtube.com/watch?v=yaHNF6sGYl0 Although looking at the slides there are some differences: * http://meetingcpp.com/tl_files/2014/talks/2014_12_05_multiplatform_cpp.pdf * https://github.com/boostcon/cppnow_presentations_2014/blob/master/files/2014_05_14_multiplatform_cpp.pdf
You might want to take a look at [CppRemote](http://www.cppremote.com). It is simple to use.
I do this all the time. All my C++ code right now basically looks like heavily templated, namespaced C.
Jeez, why is this question always analyzed so much. It's not rocket science. There are some things that are men are more inclined to do and some things women are more inclined to do. It has nothing to do with sexism. I don't see a thousand posts asking why there aren't more male hair dressers or elementary school teachers.
Also agreeing here. RPC is *baaaad*. It attempts to hide network behavior and failure cases behind a shiny object like wrapper which you can then ignore....except it's not possible to ignore these failure cases. Even if these failures are not an issue, pretending a remote call is the same as a local call causes a mental domain miss match which can lead to badly designed code. Common examples are looping and calling a single access remote instead of calling some kind of faster aggregate remote call.
&gt; C++ is not really suited that good for distributed programming because it lacks introspection. libclang and you have introspection! :-)
You could try [NanoVG](https://github.com/memononen/nanovg). There's a DX11 port, and making your own port isn't too hard. It's very lightweight, fast and great for animation. However it doesn't have external stylesheets - you'd have to write your own system for that.
Well op asks for "display only", in which its not really a UI anyway... sfml is awesome for 2d rendering, which sounds like what op wants. Also, doing simple animations as op describes (such as fading text) is easy in sfml. 
Yeah, I wouldn't really call anything with no input an interface. 
[Clanlib](http://clanlib.org/documentation/3.0/GUIFramework.html) - Uses CSS and runs on top of DirectX and OpenGL.
Why do so many men go into programming?
I don't get any sound at all. 
what's the point of the #define, why not use the user define literal as is? 
He said he's using MediaFoundation for playing video. That requires DirectX - it won't work with OpenGL.
I recently was told of an interesting article on this subject, and inspired by this thread, went and looked it up: [http://readwrite.com/2014/09/02/women-in-computer-science-why-so-few] What's interesting about it is not that it pinpoints all the reasons women might not choose programming, but rather initiatives that have been taken by colleges and universities to increase female attendance. *excerpt:* &gt; At Harvey Mudd College, a private liberal arts college near Los Angeles, initiatives are underway to make the computer-science department more welcoming. As a result, 40% of its computer-science students are women. Harvey Mudd is still working to ensure women feel as welcome and as capable as their male computer science peers. &gt;“These strategies aren’t like, ‘Oh we turned everything pink,’” Colleen Lewis, assistant professor of computer science at Harvey Mudd, said in an interview. “These are best practices for getting students with a broad range of interests interested in computer science.” Another article, on women in STEM field, notes how women tend to do better in science and mathematics courses in high school, but do not pursue related fields. [http://techpageone.dell.com/business/study-women-stem-careers/]
Direct2D and DirectWrite?
For some of my projects, I have classes representing various functions or distributions with several hyperparameters. Typing `"blah"_f` for all of the hyperparameters results in code that is harder to read and maintain than `fixed(blah)`.
&gt; Arrays and objects do require heap allocations, since they are stored internally using a `std::shared_ptr` (usually just a single allocation is required, since most STL implementations allocate the object and control block together). While this does make construction more expensive, it has the advantage that copying values containing arrays or objects is cheap, since it only amounts to incrementing a reference count. Does this mean that copying `ujson::object` does not perform a deep copy?
&gt; There is no shame in admitting the fact that women are physiologically different than men, and have different interests and strengths. Yes, for example, ["girls in the U.S. have been out-performing boys in math and science classes for some time"](http://techpageone.dell.com/business/study-women-stem-careers), therefore they'd probably make better programmers than men. &gt; But it does mean that men and women naturally gravitate towards certain occupations. It's funny that ["more women than men tend to show aptitude in both math and language skills, and yet the rate of women choosing STEM careers remains low."](http://healthland.time.com/2013/03/25/how-cultural-stereotypes-lure-women-away-from-careers-in-science/) &gt; Even early in the days of personal computers men flocked to it and women didn't. Yeah, I mean it's not like the [first programmer was a woman](http://en.wikipedia.org/wiki/Ada_Lovelace) or something crazy like ["the number of women studying computer science was growing faster than the number of men"](http://www.npr.org/blogs/money/2014/10/21/357629765/when-women-stopped-coding) before 1984.
I'm pretty sure that a template literal is currently the only way to split the `char[N]`. I've asked [a related question](http://stackoverflow.com/questions/15858141/conveniently-declaring-compile-time-strings-in-c) on SO before, and none of the answers offer both nice syntax (e.g. not like `foo&lt;1, 2, 3, ...&gt;`) and the ability to manipulate the string during compile-time.
I would recommend learning directly C++11 to have less headache with how pointers are managed. I guess you plan to use Visual Studio? VS 2013 Community supports C++11 and some feature from C++14. I'm not sure if Effective C++ is a beginner book, but I would recommend reading it, then Effective Modern C++ (it's about C++11). And of course The C++ Programming Language 4th edition from Bjarn Strauss, but I think it's a really big book. https://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list As for blogs: - http://scottmeyers.blogspot.com/ - http://herbsutter.com/ (check the GotW section) - http://www.stroustrup.com/ - http://en.cppreference.com/
I would prefer it, since I really like Visual Studio, but I don't have any problem if I need to use other IDEs or change to use another different set of tools. I need to learn about what composes a productive development environment for C++ too. If VS Community supports it I would begin with that. But I will reach out to the community to see the different options for a development environment.
Nice, I need to add C++ to my list of interests in Stack Overflow.
Adding onto this: [SFML](http://www.sfml-dev.org/) [Box2D](http://box2d.org/) [boost](http://www.boost.org/doc/libs/) (essential) [Qt](http://qt-project.org/) [Ogre3D](http://www.ogre3d.org/docs/manual/) (ugly API, singleton abuse) 
This --&gt; [Programming: Principles and Practice Using C++ (2nd Edition)](http://www.amazon.com/Programming-Principles-Practice-Using-Edition/dp/0321992784/ref=pd_sim_b_4?ie=UTF8&amp;refRID=17SQPNVM0MWR3GM42E50) Seriously it's very good and it's by Bjarne Stroustrup and it's current as of may 2014..I would start here and try not to get ahead of yourself with some of the more advanced things people are posting in this thread.
[isocpp.org](https://isocpp.org) should be the first choice! Read the official [C++ FAQ](https://isocpp.org/wiki/faq/) Since you mentioned that you have some C experience, you could give [The C++ Annotations](http://cppannotations.sourceforge.net/annotations/html/) a try. It's being constantly updated, it has C++11 support. 
`ujson::object` is a typedef for `vector&lt;pair&lt;string, ujson::value&gt;&gt;`, so this is just a regular C++ vector. What the last section in the readme is talking about is what happens when you copy a `ujson::value`. When you copy a `ujson::value`, the contained object, which could be either a `std::string`, an `ujson::array`, or an `ujson::object`, is never deep copied. However, this does not mean `ujson::value` suddenly has reference semantics. Since the contained `ujson::object` is immutable, an `ujson::value` still has proper value semantics. This is a nice property to have, especially in a multithreaded world. This is inspired by the awesome talks by Sean Parent, btw. 
Thanks. Is there anything in particular (of what has been posted) that I should avoid for the time being?
That women are better in math and science classes does not mean that women are interested or like engineering more than men. The fact that women have different biological traits than men is not in conflict with the fact that women are smarter then men. 
This will help. http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list
This book is more for teaching programming to a beginner than for teaching C++ to an experienced programmer. Stroustrup has a book aimed at teaching C++ to experienced programmers: [_A Tour of C++_](http://www.amazon.com/Tour-In-Depth-Series-Bjarne-Stroustrup/dp/0321958314).
Is this still a good book if one is an experienced developer (in python for example) ?
Glad to hear that `ujson::object` is immutable if it's shared. Is the library not losing a lot of flexibility if you can't mutate `ujson::value` objects? I don't want to presume what he was thinking, but what I got out of that talk was that Sean Parent was advocating for `std::shared_ptr&lt;T const&gt;` when dealing with polymorphism. I believe he said something along the lines of he has never needed to mutate objects polymorphically. I didn't think he was advocating immutable objects across the board.
Straight to bookmarks. There are some very interesting reads in there...
Definintely go for modern C++ (C++11 or newer).
Not having used C++ for over 4 years, I found this a very helpful reference to all the "new hotness" available: http://en.wikipedia.org/wiki/C%2B%2B11 I do actually dislike C++ as a language, much prefer C#, but there are some projects where C++ is the only viable option, and C++11/14 makes it less insane and more like something you could actually write proper software in while still maintaining sanity (my opinion, your opinion may vary :) I've been thoroughly impressed with the new features and how much they affect my coding style, making my code much more readable. unique_ptr and lambdas solve a whole host of problems that used to be really annoying 5 years ago.
Will be hard to beat as rapidjson has custom allocators -- that's where the speed is coming from
To use COM interop you would have to wrap your native C++ code in COM compliant components (implement IQueryInterface, IDispatch, use IDL, etc.). A less abrasive route would be to wrap your native C++ types in a managed assembly using C++\CLI. Another option would be to implement a plain C interface in front of your native C++ types (i.e. extern "C") and then use P/Invoke directly from your C# code.
I agree with this. If you know c++ and c#, using c++/cli is really easy
&gt; Stroustroup, Sutter, Chandler Carruth, Scott Meyers This is something that I forgot to ask! which are the makers / people behind the standards or specifications. They are those people right? Anyway, you gave quite a good advice right there. I've seen CMake mentioned a lot throught-out the net, so this is something that I definitely have to check out.
I think you missed the last s in Scott Meyers. 
What's the difference between this and just calling foo()?
None that I know of.
[There was a thread nine month ago](https://www.reddit.com/r/cpp/comments/229z4m/how_to_quickly_get_up_to_speed_on_modern/) in which quite a few aspects of modern C++ were discussed. It's probably worth your time to read through that. Going-Native-talks have been mentioned already, which is a notion that I totally support (there are a few very advanced ones, that might not help you until you have more experienced, but most of them are fairly easy to follow). I would like to especially point out [Bjarnes Keynote from 2012](http://channel9.msdn.com/Events/GoingNative/GoingNative-2012/Keynote-Bjarne-Stroustrup-Cpp11-Style) and Sean Parents [C++ Seasoning](http://channel9.msdn.com/Events/GoingNative/2013/Cpp-Seasoning). 
I can't recommend *Accelerated C++* any more than I already do. It's terse with a wealth of information. 
True, what I gather is that the only good `std::shared_ptr` is a `std::shared_ptr&lt;T const&gt;`. But I'm not suggesting there be any `std::shared_ptr`s in your `ujson::value`, I would prefer mutable variables, which I think are more idiomatic in C++. If everything performed a deep copy and I want reference copies, can I not just pass around `std::shared_ptr&lt;ujson::object const&gt;` and have all the benefits? I agree that it's not ideal to duplicate the interfaces. I've mentioned before, on other threads about JSON libraries, that my ideal (again, with all the naivety of thinking about this for an hour or so) would be a library where the JSON type is something like this recursive `boost::variant`: typedef boost::make_recursive_variant&lt; double, std::string, bool, std::vector&lt;boost::recursive_variant_&gt;, std::unordered_map&lt;std::string, boost::recursive_variant_&gt;, std::nullptr_t, &gt;::type json; The actual meat of the library would of course be a parser, but also several `boost::static_visitor` functors to work with the `json` class. The most useful of which would probably be a type-safe accessor down the JSON tree. Something like this: int main() { // Let's just pretend this line will compile without escaping quotes json obj = json_parse("{ "id": 1234, "people": [ {"name": "foo"}, {"name": "bar"} ] }"); // Get the ID boost::optional&lt;json&gt; id = boost::apply_visitor(json_value("id"), obj); if(id) { std::cout &lt;&lt; boost::apply_visitor(json_printer{}, id); // prints 1234 } // Get the name of the second person boost::optional&lt;json&gt; name = boost::apply_visitor(json_value("people", 1, "name"), obj); if(name) { std::cout &lt;&lt; boost::apply_visitor(json_printer{}, name); // prints "bar" } // Tries and fails to get the surname of the first person boost::optional&lt;json&gt; surname = boost::apply_visitor(json_value("people", 0, "surname"), obj); if(surname) { std::cout &lt;&lt; boost::apply_visitor(json_printer{}, surname); // never gets here as surname == boost::none } } The syntax could of course be cleared up to remove the visitor stuff so it looks something like: json obj = json_parse(...); boost::optional&lt;json&gt; name = obj.get("people", 1, "name"); boost::optional&lt;std::string&gt; name_str = obj.get("people", 1, "name", as_string); I am also partial to overriding `operator()` for accessing objects and `operator[]` for override array access, which would give you, json obj = json_parse(...); boost::optional&lt;json&gt; name = obj("people")[1]("name"); But the first version of having a variadic function means you don't need to deal with the case where the first `operator()` returns `boost::null`.
Indeed that is a better name, thanks for the suggestion. I've renamed the header to `ratio_literal.hpp`, `_f` to `_ratio`, and `cc_fixed` to `cc_ratio`. Hopefully this will make the purpose clearer.
Can noone help me?
add STL Stephan T. Lavavej to important people, he's awesome, and check out [his site](http://nuwen.net/) where he hosts a great free MinGW distro for win also, be sure to watch these two talks: from GoingNative2013, [inheritance is the base class of evil](http://channel9.msdn.com/Events/GoingNative/2013/Inheritance-Is-The-Base-Class-of-Evil) and CppCon2014 [modern template metaprogramming](https://www.youtube.com/watch?v=Am2is2QCvxY)
C++/CLI if you're on Windows. C++/CLI was designed for this.
I like boost a lot and you can do a lot with it in just a few lines of code. However, I suspect that having boost as a dependency would greatly reduce the number people who would consider using ujson, unless they were already using boost. There's a lot of value in being small and self-contained. With your approach I wonder how you could enforce invariants, such as the string being valid UTF-8 and the number being finite. Also, I don't know anything about the efficiency of using these boost variants or their memory layout and I suspect that the implementation is a template nightmare. &gt;If everything performed a deep copy and I want reference copies, can I not just pass around `std::shared_ptr&lt;ujson::object const&gt;` and have all the benefits? I don't see how. Lets say you passed the root object of your big JSON file around like that. Then it wouldn't be possible to pass a subtree of that JSON file on to other functions or threads as a `shared_ptr`. This is trivial with `ujson::value`. WRT the mutable interface. I just don't see a way of making `ujson::value` mutable without making a mess of the interface. 
Yep, STL's lectures are fantastic! Another great talk to mention from CppCon 2014 is Jon Kalb's exceptions talk.
Streams aren't part of the STL. The STL consists mainly of the various templated containers and the generic algorithms based on iterators.
Yes, I did. My apologies.
before C++ standardisation, iostreams and the "STL" where two separate libraries. It's like asking why Qt's xml doesn't use boost variant. Admittedly, the standardisation process should have ironed that out.
I just went and checked, it was finally fixed in C++11, so hurray? :-D
Learn C++11, Visual Studio 2013 if on Windows, gcc+sublime text/codeblocks on ubuntu/linux. To be honest, just jump into it. EDIT: Only thing that will trip most C# up when switching back and forth to C++ is Pointers... auto vs var. ref vs void*. char[] vs string. etc. I switch almost daily/hourly between C++/C#.
Here is my advice (did quite a lot of interop work back in the day): If you know (or want to learn) C++/CLI, use it Else If you already know COM, go with that Else Write a C wrapper for your C++ module and call it from C# directly
You can find the snapshots [here](http://llvm.org/builds/).
It makes sense to have them for interoperability with old C code that doesn't use `std::string`, but they should have added ones that take `std::string` too.
I know and it is nowhere near production ready. What I want them to do is to help move Clang on Windows forward enough that it doesn't have to rely on cl.exe fallback heavily. 
I will as soon as I move to a better parser. :-)
Happy holidays! :)
I see your point. I'll see what I can do.
:-)
Doesn't support throwing exceptions or a lot of debug info, or some of the changes made in VS 2013
Yeah. I mirrored a dude who's site is now 404ing [for setting it up](http://blog.tankorsmash.com/?p=592) http://roguecentral.org/doryen/libtcod/download/ for the library tutorial for actually using it http://codeumbra.eu/complete-roguelike-tutorial-using-c-and-libtcod-part-1-setting-up I ended up making [BiochRL](http://www.biochrl.com/) with it, so I'm happy.
My mom doesn't know anything about generic programming!
does the double container version have performance hit compare to the simpler version? like it needs to call the constructor twice?
When you create an array of 10 vector&lt;int&gt;-s: vector&lt;int&gt; a[10]; There is a constructor called for each element, so 10 calls to vector&lt;int&gt; constructor. Such array exists on the stack (unless you allocate using new). When you create a vector&lt;vector&lt;int&gt;&gt; with 10 elements: vector&lt;vector&lt;int&gt;&gt; v(10); There is a call to vector&lt;vector&lt;int&gt;&gt; constructor and calls to constructors of the 10 elements of type vector&lt;int&gt;. The internal array exists on the heap. All in all the difference is negligible. If you need just need 10 vectors (or any other constant number) you can use an array. But if at any point you require to change the number of elements, use a vector of vectors, so you don't have to manually manage allocated memory. Additionally, among other things, vector has the added benefit of the fact that it remembers how many elements it has (so you don't have to) and it can perform the bounds check (using the [at](http://en.cppreference.com/w/cpp/container/vector/at) method). So if any of the vector functionality is seems useful to you, don't hesitate to use the vector.
Just use the vector.
Killed by glioblastoma multiforme, The Emperor Of All Cancers, a few years ago.
sorry for the mess, dont know how to format the code :(
4 spaces in front of the code (on each line) BTW: r/cpp_questions is where you want to ask your questions.
Shouldn't using initializer list directly, or accepting `T` and asserting container, remove the need to allocate upon calling of `print`?
Sign up / sign in popup when I clicked through, weird bolding of text, run like hell.
&gt; To be honest, I've never seen a place where you'd want to explicitly declare an initializer_list. std::min on multiple values.
The problem is that the type of `{vv}` is not `std::initializer_list&lt;vector&lt;int&gt;&gt;` but of type `std::initializer_list&lt;vector&lt;vector&lt;int&gt;&gt;&gt;`. I don't know what you're trying to do. But to get your example working, you'd have to do something like this, either: int main() { vector&lt;int&gt; v1{0, 1}; vector&lt;int&gt; v2{2, 3}; print({v1, v2}); return 0; } or int main() { print({{0, 1}, {2, 3}}); return 0; } Otherwise, if you want to print a vector of vectors, you could do template &lt;typename T&gt; void printVecOfVec(T vectorOfVectors) { for(auto vector : vectorOfVectors){ for (auto j : vector) cout &lt;&lt; j &lt;&lt; " * "; cout &lt;&lt; endl; } } which is actually improperly named because it works for every container. You could probably make this more generic to support any amount of container nesting but I won't bother here.
I said explicitly declare (i.e. std::initializer_list&lt;T&gt;(blah)). Why would you type all that extra cruft when the curly brace initialisation syntax works just as well? I suppose if you were getting the values from some other container, but at that point, maybe it would be better to use std::min_element instead.
Programming is not an art it's a craft
I'm terribly sorry to hear that :(.
You are using C++14 and You should't use auto inside for: for(elem : container) otherwice here is unnecessary copying... 
Yes, "for (auto elem" copies and should basically never be used. But my "for (elem : range)" proposal was never part of C++14, and was rejected for C++17. (I will be proposing new syntax for C++17.) Use auto&amp; or const auto&amp; here.
Lots of things to think about here: a and b don't need to be private: but you might want them to be constant. This gets rid of the "GetA" and "GetB" member functions, which don't do much, and are kind of annoying. If you want a more natural API, you can overload the function call on that member. thus `GetFXToX(double x)` becomes `operator()(double x)`, and it is used like so: LinearFunction f(1,2); double result = f(2); //is pretty much like calling f.operator()(2); Another think to think about: A linear function with a non-zero `a` is also a linear function. So, instead of calculating the linear function inverse for that point, you could return another LinearFunction that is the inverse of the first linear function. LinearFunction f(1,2); LinearFunction f_inverse = f.inverse(); // with some assert to guarantee that `a` != 0. double result = f_inverse(3); // now you can call it like a regular function. And one last thing: you can template your whole function on the data type: linear functions exist for `float` and complex numbers too, and templates allow you to do that.
That's what happens when you copy/paste code from the OP and don't think about it :D Thanks for pointing it out. Why are you making the comment about C++14? Yes, I am using it.
Read sidebars. 
Again: post your errors. (But my psychic debugger says it's a Unicode/Ansi issue.)
You included lines 5 through 16 twice. If you want to edit those values, do it inside WinMain.
True.
This is a nice project to start with. I've got a couple of suggestions on your `LinearFunction` class and some links to the rationale. 1. Make all functions `const` whenever possible ([GotW #6b](http://herbsutter.com/2013/05/28/gotw-6b-solution-const-correctness-part-2/)) 2. `a` and `b` can be public members, it's simpler than writing your own getters/setters 3. Prefer to make functions free instead of methods ([GotW #4](http://www.gotw.ca/gotw/084.htm)) 4. Don't add destructors if you can help it, (e.g. because it can disable move constructors), try to follow the [rule of zero](http://flamingdangerzone.com/cxx11/2012/08/15/rule-of-zero.html) My ideal version would look something like this (later on you can make this a templated class so you can have a `LinearFunction` of `float`s for example). class LinearFunction { public: LinearFunction() : a{0.0}, b{0.0} {} LinearFunction(double c, double d) : a{c}, b{d} {} double operator()(double x) const { return a * x + b; } double a; double b; }; bool parallel(LinearFunction const&amp; l, LinearFunction const&amp; r) { return l.a == r.a; } LinearFunction inverse(LinearFunction const&amp; f) { if(f.a == 0) { throw std::runtime_error{"Cannot invert when a == 0"}; } return {1/a, -b/a}; } static const LinearFunction xAxis; And you use it like so... int main() { LinearFunction f{2, 3}; std::cout &lt;&lt; "f " &lt;&lt; (parallel(f, xAxis) ? "is" : "is not") &lt;&lt; " parallel to the x-axis" &lt;&lt; std::cout; LinearFunction invF = inverse(f); std::cout &lt;&lt; "f^-1(6) = " &lt;&lt; invF(6) &lt;&lt; std::cout; } Functions such as your `ContainsPoint` are going to be problematic as others have suggested due to rounding inaccuracies with doubles.
This would be a circular definition, as `std::swap` is defined in terms of `operator=`. If you instead tried to do `this-&gt;swap(new)` and define your own `swap`, you'd find that you can't update `a` or `b`, so you have no way of writing it. (Also, you can't have a variable called `new` and `operator=` should return a reference.)
The former makes sense, the latter (while possibly sometimes useful in a resource-limited system) is stylistically weird. The former creates a dynamic array object of elements of vector&lt;int&gt;. The latter creates a static array of vectors. If you know what you're doing, the latter might lead to marginally greater performance and marginally lesser memory consumption (just because of the pointer and size storage), but that is *very* rarely a bigger benefit than being consistent. 
Think of tuples as being the closest C++11 comes to supporting reflection.
[A C++ "byte" can have more than 8 Bits](https://isocpp.org/wiki/faq/intrinsic-types )
[Compiler error](http://ideone.com/8OqT13).
That was sarcasm... 
everyone can use a different subset, and to them it feels like their knowledge is 8,9. 
I don't know about the specific circumstances, but static analysis tools are what you are looking for. My personal favorite is made by Coverity, which is free for open source projects, but insanely expensive for non-open source stuff. PVS-Studio is reasonably priced if you don't have the $$$ for the Coverity tools.
There are *some* useful idioms here. They are hiding among the many dated and narrowly-scoped examples. I suppose the most constructive thing I could offer is that the *"also known as"* and *"used in"* fields would be helpful if they appeared in the table of contents. Then an idiom with no aliases that was used once would stand out more as *"not so idiomatic"* as the others.
Why was it rejected? And what new syntax will you be proposing?
People were concerned that it could lead to unintentional shadowing. My new syntax will be `for elem(range)` where `elem` is an identifier and `range` is any range expression as usual.
It's a Wikibook, nothing keeps us from updating it :)
We could edit it and tag the outdated content as "outdated"
I've just updated my post. I was AFK for a few days due to travelling.
Just see the full post. It is tutorial for adding two numbers without using arithmetic operators... 
This looks like a bad question for a job interview (no offense but I got tired of stupid questions like this).
nope. There is no C++ I can see...
I expected something better than drawing each line by other command. Nothing special there, nothing cpp.
Beside static analysis tools, IIRC compilers often have a variety of compiler flags to let you specify "forbidden things". Maybe a bad example but I think gcc has a "-no-long-long" flag or something that makes sure a warning appears when you do that. I can imagine singletons being harder since they come in a variety of shapes, but checking for new in the constructor doesn't sound too crazy to me. If it doesn't work out you can probably script something that does that.
&gt;took a class, was boring.. hated it. &gt;Seriously.. I have like ADD or something. I don't think many people would put learning C++ in the fun section. It isn't exactly a super fun language. More frustrating that anything else. Why do you want to learn C++? What did you find boring about it? If you hated it why do you want to continue learning it? I honestly can't give you an answer on a fun C++ book though sorry. All the ones I have read are pretty dry. Maybe C++ For Dummies or something? 
If you're only willing to work on fun portions of a program, you'll sooner or later get stuck and learn nothing new.
The problem is that you need to get experience before that. I'll give you some talks that are nice to watch while still teaching a lot of things (they are not introductions to the language, but in your case those don't seem needed), but at the end of the day you have to write code. When you've done that for a while you will reach the point where you can write productive programs, but there really are quite a few steps to take before. Imagine it like learning to read and to write: In the beginning you were horrible at it (if you apply the standards that you have today) and you mainly used it to read pointless texts for school and write down stuff that didn't serve any purpose; that is besides the purpose of forcing you to write to get better at it. And while your handwriting may or may not still suck today (mine sucks) it is certainly several orders magnitude better. The situation for programming is similar. Now for the talks: * [This](http://channel9.msdn.com/Events/GoingNative/GoingNative-2012/Keynote-Bjarne-Stroustrup-Cpp11-Style) is a very important one telling you how to write good code that I recommend to everyone. I wouldn't call it outright “fun” to watch, but it's probably still a lot more entertaining than most lectures you will find elsewhere. * [This](http://channel9.msdn.com/Events/GoingNative/2013/rand-Considered-Harmful) is a now famous 30 minute introduction to the C++11 random-facilities and why you should totally use them instead of the `srand()`/`rand()`- functions. A very good talk too and definitely entertaining. * Aside from those: All Going Native talks are good, but some really target experts, some contain now outdated advice/information and some are more dry than others. If you can bear Bjarnes Keynote, just try a few of the others. 
I'm not sure "fun books" are the best way to learn C++ because one first needs a lot of base knowledge to start doing much at all in C++, which is not a scripting language. Having said that, "Accelerated C++" comes close to being "fun" in that sense, or let's say the closest while still being practical. Although "Effective C++" should come next to understand why some things are done in certain ways and not in other ways, or if you already know C and some C++, it will teach you have to do things properly in non-C-ish *modern* C++.
I hate to break it to you, but "useless" programs is where you start. You don't start lifting olympic-level weights when you're out of shape. You don't start reading war and peace when you're learning a new language. Why don't you try to extend your calculator to do something else? Maybe implement all the advanced trig functions, and allow for more advanced parsing of parameters? The one caveat is you have to figure it all out on your own without anyone telling you.
Since this is otherwise such an incredibly clear code (it’s frankly a joy to read), allow me to provide some unsolicited code review: * The big one: your handling of errors. This is my only real criticism, since it’s moderately atrocious. You should probably use exceptions instead of numeric error return codes, and the exception should contain the error description – such a description should *not* be written to `std::cout` inside the function. If you just want to fail for all these exceptions, have a global exception handler surrounding your `main` which just catches all exceptions and prints their messages. At the moment, *no* handling is done, really. * Related to this, [you’re using `.at()` instead of `operator[]` on a vector](https://github.com/Alexander-0x80/violet-vm/blob/master/src/vm/vm.cpp#L22) but you don’t handle the exception which may result from that. Might as well use `[]`. * Why are you allocating the `Vm` in `main` on the heap, via `new`, without using a smart pointer, and not deleting it (leak)? The best course of action would be to just put it on the stack – I can’t find a reason not to do this here. * Since you don’t check for IO success, there’s no reason to explicitly close files via `file.close()` – the stream will close automatically at the end of the scope. Calling `close` only makes sense if you subsequently test the stream state for success (via the failbit). * Don’t use C-style casts, use the appropriate C++ cast (you’ve done this elsewhere, but missed it [in at least one place](https://github.com/Alexander-0x80/violet-vm/blob/master/src/etc/utils.cpp#L22). * Since you’re using C++11 anyway, use the appropriate standard typedefs for `u8` and `u16`. `single`, in particular, is not guaranteed to be 16 bits, as your comment rightly observes. * [`dump_regs`](https://github.com/Alexander-0x80/violet-vm/blob/master/src/vm/vm.cpp#L53) could be a one-liner by using the appropriate constructor (taking iterators): return std::vector&lt;u16&gt;(std::begin(regs), std::end(regs)); There’s some more small stuff – for example, many of your `const`s could be `constexpr`s. But like I said, this is a remarkably clear and pleasant code. By the way, for such fairly small projects, you might want to head to http://codereview.stackexchange.com/ for thorough code review.
The licensing makes it useless. (gpl3)
But those terrible APIs wouldn't be terrible if this thing was in the language.
If I'm not missing something obvious, wouldn't a simple replacing of use of named arguments with a normal function call with arguments ordered to match the names and missing arguments replaced with default values suffice? That should be easy to do. The only problem I can see rises from the syntax, as arguments can be any valid statement, and an assignment is one. Why would someone want to use a return from assignment is beyond me though. Replacing = with : or something else would alleviate this problem.
'Useless' is pretty strong, but I agree - I'd love there to be a good, lightweight, standalone BSON library for C++ but I'd also prefer something with a more permissive license.
Looks like someone disagreed with a downvote. If people think this book is bad, please let me know. That would be way more useful than a downvote.
I agree that 'useless' is very strong, yet not many people will find this library usesable because a couple of other with more permissive licenses exist already. If I have the choice to taint my project with the GPL, or to use MIT / Apache, I always go for the later.
I'm almost through C++ Primer Plus (6th edition) by Stephen Prata and he gives very clear examples and explanations. But what I like about it is he gives you small programs you can immediately run. (What I mean is instead of a code snippet he gives you a full, compilable program. A small program but compilable. Sometimes authors just give a snippet and you have to guess what to do with it. I'm looking at you Stroustrup.) 
What sort of goals did you have for the library? I can see interesting niches in: * easy to use mutable api with dynamic allocation. * constexpr/template compile time magic * header only, easy to integrate variant. For what it's worth, I'm the current https://github.com/mongodb/libbson/ maintainer (C bindings). I'm interested in a good C++ api for bson and happy to answer any implementation questions you might run into.
Maybe I'm missing a point here but if you never expect a null pointer to be passed then you should use a reference.
I am really not a fan of c++ primer. I found that book incredibly slow
Also check out C++ for the Impatient by Brian Overland. It is brisk so should hold your attention. 
The issue is you can't pass a std::string from a program that was compiled with stdlibc++ to a library compiled and expecting a std::string from libc++
The goals were one-step integration (thus header-only, no dependencies beyond STL) and C++98 compatibility (so no constexpr and limited template magic).
I agree, though. But in cases where using lots of parameters is the only and the easiest way to do something, this would be very helpful.
Yeah I know; but it's better than reading a book that is wrong. Ideally AC++ will come out with a C++14 version sooner or later.
Defensive programming can include making sure that your code gives a clear unambiguous error when possible, even if the caller had already invoked undefined behaviour. (I can't recall having seen (or written) code that checks for a null reference though.) "It's a pointer not a reference because it's also used with a C API, but if it is NULL the caller has broken the preconditions of the call" is a real use case though. Compare with some of std::string's constructors, which take a char* and have undefined behaviour if it is NULL.
Can you guarantee the semantics are the same across all of them?
This is obviously just an example, you're avoiding the real question. Imagine that the example got an `int` which was assumed never to be zero and divides by it. The point of the question is how does defensive programming behave when it meets an unexpected state (especially when such state can lead to undefined behaviour). 
The main reason for this, I think, is C++’ utter lack of a general module/packaging ecosystem in the past. These are only now starting to emerge (I’ve heard great things about [Biicode](https://www.biicode.com/), but I haven’t used it yet). Generally, installing and maintaining library dependencies for C++ is far from trivial.
I always find it odd to spot `memcpy` in C++ code. `std::copy` is exactly equivalent performance-wise, and offers an interface compatible with other C++ algorithms. Of course there’s nothing *wrong* with `memcpy`, it’s just a bit like having a meter-breaking line in a poem.
Looks very handy.
If you like video tutorials, I suggest you to check out these ones I created: https://www.youtube.com/playlist?list=PLTEcWGdSiQenl4YRPvSqW7UPC6SiGNN7e They're about game development from scratch using SFML and modern C++11.
Books: First [A Tour of C++](http://www.amazon.com/Tour-In-Depth-Series-Bjarne-Stroustrup/dp/0321958314) and then [Effective Modern C++](http://www.amazon.com/Effective-Modern-Specific-Ways-Improve/dp/1491903996). Website: isocpp.org (it features many blogs, conference announcements, Stackoverflow questions regarding C++11/14).
Exactly what i was looking for! thanks a bunch.
It's surprisingly standard for not being standard.
I ran into this a while back. IIRC, the only major problems with `#pragma once` are: * Compiler support - usually not a problem unless you want to compatible back to some older GCC versions or what-have-you. * It can be foiled by symlinks/hardlinks. That said, if you're working with something like a Vagrant VM, symlinks are a big no-no anyway. That and it's not unreasonable to call out a compatible compiler suite to use your software. Besides, the recent push towards C++11 is going to put you in an environment where `#pragma once` is supported. Anecdotally, I have actually "turned off" a header by strategically placing a `#define` in my code. This was needed to prevent name collisions on an un-needed library header that was pulled in by some dependency. So you could say that include guards are more flexible in some ways; but they're very easy to screw up with an errant copy/paste.
If this line in the article is correct: &gt;int result = 2, 3; // error: expected unqualified-id before numeric constant then it should fail to compile.
Another issue not mentioned yet is tooling other than the compiler. Think dependency checking, data injection, etc. Many shops have this extra tooling that would need to be updated to support pragma once. 
Output: 1 [^source](http://ideone.com/Bd29w6) ^| [^info](http://www.reddit.com/r/CompileBot/wiki) ^| [^git](https://github.com/renfredxh/compilebot) ^| [^report](http://www.reddit.com/message/compose?to=compilebot&amp;subject=Report%20Abuse&amp;message=--report%20http%3A//www.reddit.com/r/cpp/comments/2sac4m/the_forgotten_comma_operator/cnnqynj%20Include%20your%20reason%20for%20reporting%20here.) 
C may knowingly do the same (assert does nothing with NDEBUG), but my point is that is exactly what you want! The premise is that it is an error to pass nullptr. If so, the best action is to just demolish all, but leave the complete dump,so that the problem can be fixed. For example, leaving with an exception is worse because code is broken, and the state of the stack is lost due to unwind,making it harder to know what caused the nullptr to enter.
In c++14 you can do: salary = 1'000'000; 
I was interested in a version I could use with Visual C++. I notice that there is another branch named cpp03 that is tested against Visual C++ 2013, although it appears that it is way behind the cpp14 branch. Does anyone have experience using the framework with Visual C++?
What's your point here?
&gt; Defensive programming can include making sure that your code gives a clear unambiguous error when possible, even if the caller had already invoked undefined behaviour Checking if you are in an undefined state is pointless - it's unreliable and a waste of time. Defensive programming means you report errors *before* your program becomes invalidated by UB.
At first agree that run-time switch between dependencies is not needed very often. On the other hand DI is not only about easier testing. DI is just an approach and one can deal without a framework for sure, but as mentioned below (different replay) doesn't matter how manual DI will be accomplished one still will have to create all the required objects and maintain them, which DI framework might do automatically. If it comes to testing itself - with DI one can go a bit further and introduce something like automatic mocks injection (https://github.com/krzysztof-jusiak/mocks_injector), which becomes really handy in larger projects. Overhead introduced by DI obviously depends, but it's not always true as well, DI might be faster than factories or manual creation. Boost.DI, due to it's compile time nature, is easily optimized by compiler and in most cases generates the same code as for example make_unique - see http://krzysztof-jusiak.github.io/di/cpp14/boost/libs/di/doc/html/di/performance.html for further reading. 
The difference is that `int result = 2, 3;` is a declaration where, according to the language grammar, the comma separates one declarator from the next. The compile error is due to `3` not being a valid declarator. But `salary = 1,000,000` is an expression, and the commas do end up parsing as operators rather than as some other thing in the grammar. The thing that's tricky is that the comma operator has the lowest precedence, and that means lower even than assignment (in C and C++ assignment is an expression rather than a statement.) The spacing of `salary = 1,000,000` makes it look like we're assigning `1,000,000` to `salary`, but in fact the whole expression parses as (salary = 1), 000, 000
C++14 version doesn't support Visual C++ yet :( sorry, it't due to lack of C++14 features (Visual 2015 is almost there but not quite yet, but in the newest one you can use clang as a compiler for Visual C++ IDE). On the other hand C++03 version does support Visual, but yea, it's miles behind C++14 version if it comes to compile times as well as run-time execution speed, although basic features are supported there.
With a bit of common sense, nullptr. The intent is clear (set deleted pointers to a clearly dead value), it's just that the first rule is not up to date with the second.
The real problem: Getting grad students to read and understand it. I know that 6 years ago a lot of this would go over my head.
While welcome, I'd have much preferred 1_000_000. It shouldn't be rocket science for compiler writers. A leading _ introduces an identifier, an _ in the middle of a number is a separator. Sadly, C++ seems to be getting burdened with cruft like this.
`'` is going to mess up syntax highlighting...
* Guru of the Week (GotW) Series: http://herbsutter.com/gotw/ (might be a good idea to read the comments as well) * C++ FAQ: http://isocpp.org/wiki/faq/ // and &lt;http://isocpp.org&gt; in general -- e.g., the books at https://isocpp.org/get-started * Conferences -- talks (videos usually easy to find): [C++Now (previously BoostCon)](http://cppnow.org/), [CppCon](http://cppcon.org/), [GoingNative](https://channel9.msdn.com/Events/GoingNative), [Meeting C++](http://meetingcpp.com/) * /r/cpp `// ;]` 
&gt; Sadly, C++ seems to be getting burdened with cruft like this. What is cruft in this case? It's a minor syntactic style you're complaining baout. And frankly I prefer the apostrophes.
This kills the C#.
I didn't read the article, but from the title it looks like you forgot perf. FYI perf is included in the kernel source tree and can measure everything under the sun, from cache misses to overall power consumption 
~~FireStream~~ / Xeon Phi. Its like comparing Titans to integrated Intel GPUs. Even if Titan is way better, you wont put it into an ultrabook. Edit: dunno if AMD actually has something there that is actively being worked on
nice library, would be awesome to have some di library in boost
CUDA with C++11 support or OpenCL with C support, choices.... Does anyone know is SYCL progressing? Just curious, I don't don any GPGPU work.
don't forget to checkout /r/gamedev 
&gt; in the newest one you can use clang as a compiler for Visual C++ IDE No I think you can't. Only to compile Android stuff. You can't use it to compile to Windows x86/x64 code unfortunately.
Specifically with regards to how much fire to use.
I guess nobody remembers oprofile any more. :-(
It's primary use is obfuscation. That's why its forgotten and disliked. 
http://i.stack.imgur.com/qJi92.png
I remember there being a free preprint of the c++11 standard, wonder if the same is true for c++14.
First I've heard of OpenACC! Will vendors not need to provide drivers/implementations like for opencl? 
The Oovcde project is accurate, works with threads, and is fairly low overhead, but may be more difficult to use on some projects.
So, will this officially be C++14 or C++15?
I believe the draft closest to the C++14 standard is n4296: edit: oh, actually it looks like n4296 has the first C++17 features. According to [this](https://github.com/cplusplus/draft/blob/master/papers/n4139.md) the closest draft to C++14 is n4140. https://github.com/cplusplus/draft/tree/master/papers (C++11 is n3337)
Thats just how C++ rolls.
Thank you. It would help if the github readme mentions that the library is not yet an official boost library. It's very misleading as it stands.
For the conferences, are there any text translations ? Watching them takes sooooooooo much time, and it's a pain if you need to go back to a specific part....
ANSI only wants 60 bucks for C++11 (which they call C++12) http://webstore.ansi.org/RecordDetail.aspx?sku=INCITS%2FISO%2FIEC+14882-2012 -- they will likely discount this one as well if you want an official copy.
A discussion on Futures is happening on the Boost mailing list: http://thread.gmane.org/gmane.comp.lib.boost.devel/256343/focus=256397
Huh. My guess would have been 0; it didn't occur to me that assignment would have HIGHER precedence than comma.
Someone needs to pay ISO expenses.
Many thanks.
"Game Engine Architecture" http://www.amazon.com/Engine-Architecture-Second-Jason-Gregory/dp/1466560010/ and "Game Programming Patterns" http://www.amazon.com/Game-Programming-Patterns-Robert-Nystrom/dp/0990582906/ http://gameprogrammingpatterns.com/ come to my mind.
Technically dereferencing a null pointer is undefined behavior, and not guaranteed to segfault. It's much better to explicitly end the program than to hope that it crashes. And the language I've been working in lately (Rust) has `assert` run in both debug and release builds, and `debug_assert` in the same role as C's `assert`, so I really did mean crashing the program whether or not the preprocessor directive was defined.
It was a joke. 
So [this](https://github.com/cplusplus/draft/archive/0d8d6b01387bd812c13cb3dab5e8c3e1390f6d84.zip) is the download-link for the sources of what is now the official standard?
I blame it on their use of ``fprintf()``
I don't understand what I'm about to buy, it this a C++ book that starts with what a computer is, variables and arrays. Or does this PDF have details about every feature/code available so far in C++.
You know, seeing the optimizations becoming more and more "mean", you are right about that immediate termination (through abort, that normally works with the system to produce a crash dump). You are right about the "technically " as well, it's been years since I had such a system at hand, one forgets :-)
[clang warns about this](http://melpon.org/wandbox/permlink/Klm7aTMwJYsgwvf2) &gt; prog.cc:9:32: warning: adding 'int' to a string does not append to the string [-Wstring-plus-int]
Ah, thats cool.
&gt; Wouldn't it be cool if we get full (100%) C++11 Support on all major compilers this year? [Me, in a VCBlog comment:](http://blogs.msdn.com/b/vcblog/archive/2014/11/17/c-11-14-17-features-in-vs-2015-preview.aspx) &gt; However, I can tell you that while it'll be close, 2015 RTM will not fully support C++11, as Expression SFINAE and Attributes are not planned for RTM. (This information was previously announced when I posted Herb's slide with the CTP3 feature table.)
same as: const char*p = "my favorite number: "; foo(string(p+4)); not what was wanted, but not illegal either 
I doubt it, since something like this is legal (assuming I've got the syntax right) albeit weird: char int2hex(int n) { return *("0123456789abcdef" + n); }
A string literal is a `const char*`. Adding an integer to a pointer is perfectly valid. Something like lint may recognize that as a potential problem, though. 
You really *should* blame him. Somehow he's wangled his way onto a C++ job without understanding some of the most fundamental and basic facts of the language. Putting aside for a moment the question of how he slipped through the hiring process and why your management didn't catch this inadequacy, presumably he misrepresented his abilities at interview and/or on paper... which is clearly exceedingly unethical. Besides, every one of our bugs is our own fault — personal responsibility &gt; *.
Actually a string literal is a `const char[N]`. Don't let array name decay fool ya.
yikes
&gt; All switch statements must have a default clause. [switch-default ] &gt; In some cases the default clause can never be reached because there are case labels for all possible enum values in the switch statement, but by having such an unreachable default clause you show a potential reader that you know what you are doing. &gt; You also provide for future changes. If an additional enum value is added, the switch statement should not just silently ignore the new value. Instead, it should in some way notify the programmer that the switch statement must be changed; for example, you could throw an exception With recent versions GCC and CLANG, **-Wswitch** makes a better justification for not doing this, and is what my company requires. With that, a switch on an enum will error if all cases are not specified. This gives you a compile-time check for a missing case if someone changes the enum later, rather than a runtime one. 
Code reviews are a great way to educate beginners.
Okay, so let's just let him keep his misuse of "then" forever then.
I'd argue that: char int2hex(int n) { return "0123456789abcdef"[n]; } is clearer.
You're no fun. :(
Challenge [yourself](https://www.hackerrank.com/) . No one will have more incentive than when you start coding for prizes.
&gt; the missing features aren't a big deal/rarely used afaik The lack of expression SFINAE is a pretty big deal IMO. It means VC++ *still* won't be able to compile my range-v3 library.
Oh. Great to know...
Fair point, on the other hand http://llvm.org/releases/3.5.0/LLVM-3.5.0-win32.exe seems to be working fine with Boost.DI on windows, but probably not all apps will compile using it yet (http://clang.llvm.org/docs/UsersManual.html#clang-cl) and Visual doesn't support it by default for windows apps.
Bullshit, If you are so fucking scared of pointers use C# or something else, why the fuck mess with C++? I would say: Don't waste your time using a raw pointer to manage a resource when there are simpler alternatives, in that way you can avoid having to implement a destructor, copy constructor, move constructor or assignment operators in your code. 
It's a decent workaround for the fact that typedef works more as if it declared an alias or used [structural equivalence](https://en.wikipedia.org/wiki/Structural_type_system) instead of nominal. In languages like Ada you can create a new type based on an existing one for that. type SpriteId is new Integer; see: http://ideone.com/8jd03X
&gt;What with all those pesky NSA backdoors, runtime random number generation is just not secure. While this article is more of a fun hack / joke, I feel like I should point out that Linear Feedback Shift Registers should not be used for encryption.
**pseudo**random generators shouldn't be used for encryption!
I wrote something like that a while ago: https://github.com/Florianjw/type-builder It was my first attempt at template-metaprogramming, so yeah, the code is not perfect, but it seems to work (I don't use it in production).
That's true, but you need reseeding often enough that one cannot predict the internal state. Even for the Mersenne Twister, you can't go much beyond 600 samples before needing to reseed with a true RNG. In a similar vain, LFSRs might be safe if you use only a very small number of samples before reseeding -- but that would be impractical. Anyway, my point is that you need a real RNG somewhere; you can't rely *only* on a PRNG.
This isn't really the situation the blog is proposing I think. It isn't that the resource isn't being cleaned up, it is the wrong resource is being cleaned up. If you have a collection of sounds as you describe and want to remove one based on it's id from the collection you can run into the same error.
comma has the lowest precedence of any operator.
This is commonly known as `strong typedef` or `true typedef` or `opaque typedef`. It has been also proposed as a language feature at some point ([found it](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2013/n3515.pdf)). You can probably find some code online that implements a macro that does all the boilerplate. 
A simpler implementation is to use enum classes from C++11. enum class sound_id : int {}; enum class sprite_id : int {};
The example is poorly chosen for its message. The point is that conceptually dissimilar values are mechanically interchangeable, and that can lead to bugs (famously, [Mars Climate ~~Orbiter~~ lander](http://en.wikipedia.org/wiki/Mars_Climate_Orbiter)). This is a trick that can help to avoid that.
Yeah, taking the post as here is a simple way to add extra type safety to a common type it is okay as an example, but thinking about it from an architecture point of view I would side with your argument more times that against. There are probably use cases for IDs that I am not thinking of, and I am wondering if they are the rule or the exception.
Regardless of "better", certainly an RAII class is better in some situations. And we already have those in the Standard Library: shared_ptr, unique_ptr. It would be a simple matter to allow an optional tag as a template parameter for those. Sounds like a good idea to me. EDIT: Sounds like a *great* idea. The more I think about this, the more I like it.
How's that work? Don't you need to put a name for every possible ID inside the braces? Or is the idea to use some casting trick?
http://www.meetup.com/Madrid-C-Cpp/
Qt
F/OSS FTW
Yeah, that's a pretty strong case for F/OSS. I don't even know who does all the work on gcc. Is it all volunteers? Do companies like Redhat contribute?
The API can include the ability to print it out in its interface, along with any other functionality. ostream &amp;operator &lt;&lt; (ostream &amp;os, sound_id id); Plus, even though the enum class is type safe, a debugger can show the integral value of the ids without any need to put casts in the source.
Aha! This really is a thing! http://www.xkcd.com/221/
[Image](http://imgs.xkcd.com/comics/random_number.png) **Title:** Random Number **Title-text:** RFC 1149.5 specifies 4 as the standard IEEE-vetted random number. [Comic Explanation](http://www.explainxkcd.com/wiki/index.php?title=221#Explanation) **Stats:** This comic has been referenced 184 times, representing 0.3835% of referenced xkcds. --- ^[xkcd.com](http://www.xkcd.com) ^| ^[xkcd sub](http://www.reddit.com/r/xkcd/) ^| ^[Problems/Bugs?](http://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me) ^| ^[Delete](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=delete&amp;message=delete%20t1_cnriaym)
What about incrementation, addition, etc...
A handle isn't used like that, handles are not arrays, so addition and other math operations don't matter.
Golden. Thank you.
So the first question any time someone is using a linked list - why? Do you have control over if a linked list is used? If so, I'd suggest considering other options. If you are trying to keep a velocity over time I'd look at series calculation algorithms - you might not need to store the samples at all. If that doesn't work, I'd next consider a ring buffer of some sort with a fixed capacity. Or if that gets too complex and you want something straight out of stl, a deque. 
The pdf is already outdated. GCC 5 has complete C++14 support. https://gcc.gnu.org/projects/cxx1y.html For people interested in GCC development please checkout /r/gcc 
We'll be lucky to get C++11 support in gcc 5. To give one example, both MS and clang had std::wstring_convert and friends 5 years ago. Still an 'N' on https://gcc.gnu.org/onlinedocs/libstdc++/manual/status.html#status.iso.2011 Edit: very nice, only 5 days later it's 'Y'. Looks like 5.0 is indeed complete C++11 except for a few 'partials'
Patches welcome
The union is not as generic as the version before; I think the correct solution here is to use `std::aligned_storage` which is designed to solve exactly that problem.
The original code only supports a fixed set of types, so there's no change in genericness.
Needing handles is common. Theyre roughly equivalent to weak pointers. Even more common is needing handles from other APIs like the windows API. These would help with that. 
Handles aren't the only thing that require strong typing. I'm thinking more of actual enums. A lot of the times you might want to go to the next or even previous value.
I prefer `using` instead of `typedef`, it's so much clearer: using sprite_id = ID&lt;sprite_tag, int, -1&gt;;
I imagine it wouldnt be all that difficult to brute force the hell out of that if known and the compilation didnt take eternity
That's a really nice trick (as long as integer handles is all you need)!
It's such a shame that `using` has the same semantics as `typedef`.
Comparisasions between clang, gcc and msvc always end up with open source advocates bashing Microsoft's support of ANSI C++ standard. It is only faire to include the majority of C++ compiler vendors, then people at large would understand Microsoft's support is actually not that bad around companies asking for money for compilers.
They could, but is in their interest? At the moment, VC++ has not direct concurrent on Windows. Oh sure, there are compilers like ICC but the fees are not the same so they do not exactly target the same market; and sure you can get Clang and GCC through mingw, but it's not exactly "native windows" and is not necessarily as efficient. Clang is still working on generating code for the Windows 64 bits ABI, and been working on a ms-compatibility-mode for years. They even have a driver that takes the arguments from the VC++ command line and interprets them. When those efforts bear fruit and the implementation matures, maybe MS will reconsider.
Hm, why do you think that is? What's in it for Microsoft to provide good support for C+11 and not for these other commercial vendors?
As a recent user of aCC, XLC, and Oracle (and current user of ICC), I disagree.
That listing only contains compiler features. Does the runtime library used with GCC still have a reference counted std::string? Also MS has to support one of the best available IDEs and related tooling with their compiler. GCC doesn't support any tooling by design.
No. He's talking about a missing C++11 feature.
&gt; Hm, why do you think that is? Because the Reddit and HN young crowds seem to have a very narrow view of the computing world and think GNU/Linux, BSD, Mac OS X and Windows is all there is. &gt; What's in it for Microsoft to provide good support for C+11 and not for these other commercial vendors? The same as every other commercial vendor. They care about the features their customers pay money for. So like any other commercial vendor, features get implement depending on customer priorities. Of course, when one narrowly looks at Microsoft without seeing the big picture with the other vendors, they get the spotlight of being the only non-compliant vendor.
Just downvote it then
&gt; Because the Reddit and HN young crowds seem to have a very narrow view of the computing world and think GNU/Linux, BSD, Mac OS X and Windows is all there is. I'm an old guy (as in "cut my teeth on the PDP-11") but that list, and the video game consoles, probably covers 98% of the programming jobs on the planet in 2015. &gt;&gt; What's in it for Microsoft to provide good support for C+11[...]? &gt; The same as every other commercial vendor. They care about the features their customers pay money for. BUZZ - not right. Visual Studio is NOT a money maker for Microsoft, in the same way that XCode is not a money maker for Apple. In each case, the company is compelled to issue a cheap or free development system to encourage developers to write for their platform. By that reasoning, Microsoft should primarily be caring about the features that allow developers to quickly write solid and compelling programs for MS's Windows platform. And honestly, they've been trying to do a lot better on C++11 feature compliance recently. Writing and supporting a C++ compiler/IDE is simply a difficult task, and that team is still catching up with a decade of technical debt due to Microsoft's neglect in the past...
Embarcadero has moved to Clang + Dinkumware for STL for their 64 bit / arm compiler. Unfortunately they don't have a free version of their compiler, like Microsoft has with the Express version or now with the community edition of Visual Studio.
Gracias.
It is mentioned in the fourth paragraph. Apparently this was added later, after feedback from comments.
Terrible article: Code as images (rather than text) is unacceptable.
I think it's an important feature that allows the new syntax to completely replace the old syntax. We also need strong typedefs, but as the existing proposals have been shown, strong typedefs have to support additional flexibility, which requires extra syntax for controlling that flexibility. My conclusion is that the nice, simple `using` syntax works well for a simple feature that just replaces typedefs and, for a more complicated feature like fully describing strong typedefs, we will need syntax with more knobs to control the necessary flexibility.
For CppCon, all the slides are [here](https://github.com/CppCon/CppCon2014). Edit: oops, yes, just slides. No transcripts.
The worst part about it is that with a different object model, you *could* very easily do this.
Parenthesizing the function's name disables ADL. So you could have this example failing using your macro: const auto vec1 = std::vector&lt;std::string&gt;{"a", "b", "c"}; const auto vec2 = std::vector&lt;std::string&gt;{"A", "B", "C"}; auto vec3 = std::vector&lt;std::string&gt;{}; std::transform(vec1.begin(), vec1.end(), vec2.begin(), std::back_inserter(vec3), MYLIB_RESOLVE_OVERLOAD(max)); Without the parenthesis, ADL kicks in and `std::max` is used.
For some other types like `std::string` or `std::vector`, you could use a simple allocator as explained in this [StackOverflow answer](http://stackoverflow.com/a/26691247/2073257). 
C++11 indeed forbids COW basic_strings.
I wrote a type-safe index and called it "arithmetic_type": https://github.com/gnzlbg/arithmetic_type It, however, allows much more than what is required for an identifier, but uses the same strategy as the implementation there (using a tag to differentiate types).
This might be a nice library. I have no idea, since I can't find a link to the repository where I can easily browse the source code or documentation. As-is, this being a lonely, lost gzipped file on SourceForce, with no indication on activity of development, etc., I won't be checking it out.
Well, I guess some people would like disabling ADL ;-). But yes, this is a very good point and I think I'll change the article in that point . Do you want to be cited?
This is the problem that std::less&lt;&gt; (no template argument given) is supposed to solve. But std::max is a function not a functor, so you can't do the same trick, sadly.
I was going to mention that. It seems like an omission of the standard to provide transparent versions of all the normal comparison operators but not `std::max`. But the user can still provide one in a different namespace: #include &lt;vector&gt; #include &lt;iostream&gt; #include &lt;algorithm&gt; #include &lt;iterator&gt; namespace utility { template &lt;typename T = void&gt; struct max { constexpr const T&amp; operator()(const T&amp; a, const T&amp; b) const { return (a &lt; b) ? b : a; } }; template&lt;&gt; struct max&lt;void&gt; { template &lt;typename U, typename V&gt; auto operator()(U&amp;&amp; u, V&amp;&amp; v) const { return (std::forward&lt;U&gt;(u) &lt; std::forward&lt;V&gt;(v)) ? std::forward&lt;V&gt;(v) : std::forward&lt;U&gt;(u); } }; } using utility::max; int main() { const std::vector&lt;int&gt; vec1 {3, 15, 7, 8, 1}, vec2 {5, 1, 3, 7, 3}; std::vector&lt;int&gt; vec3; std::transform(vec1.begin(), vec1.end(), vec2.begin(), std::back_inserter(vec3), max&lt;&gt;()); for(const auto &amp; item : vec3) { std::cout &lt;&lt; item &lt;&lt; ' '; } std::cout &lt;&lt; '\n'; } Of course, this doesn't solve the problem in a general way like the macro, but maybe in a few years it will be common practice for library authors to provide transparent versions of things where it makes sense, and we won't have to worry about it any more. 
Talking about manual memory management, using c arrays, not using the standard algorithms... I hope nobody learns C++ with this tutorial.
Do you have a link to it?
It is fine as-is, thank you.
The more you know the more you realize you don't know.
Thanks for the reply! Sorry it's taken me so long to respond. I'll be sure to start learning CMake, if it's so common. When I came across it before, I assumed it was a less popular variant of GNU Make. Looking at some samples now, it's clear that's not the case. I haven't heard about Gradle being used for C++ either! I already use it for Java, so I just happened to stumble upon its C/C++ features. I found it much easier to build modules with it than with GNU Make. I'll see how I find myself using the language and then decide whether I care to use a non-standard build tool. I understand that other test libraries might compile faster for larger projects. I'll cross that bridge when I get there. Thanks for the warning, I enjoyed your article. Fortunately, I've yet to feel the urge to declare a variable "Java style". As for the C, I rarely enjoy writing it unless I'm abusing numeric booleans or pointers for something trivial. Hopefully, I'll find C++ as pleasant as you do. Right now, some of the syntax is a bit off-putting and the libraries seem overwhelming. But I'm committed to learning it and excited to see what it can do. Thanks for the tips!
Theres really no member functions except `swap` which is not really necessary.
&gt;If possible, even teachers should be exposed to industry experiences every once a while. Never going to happen,
A hospital has lots of patients; programming requires lots of patience.
&gt; When you say "see" people expect to create GUI or cool pictures, and you can't do that right away. Turtles.
It just needs to be taught well. The first time i ever truly started to love coding was reading Stroustrup's(the guy in the article) book on Programming on my own. He made coding fun and like an adventure. It wasn't GUI or any form of graphical coding. Just simple console inputs and outputs, but he had me immediately writing code. Every class I have ever taken on coding has sucked and i have lost interest in coding for several years afterwards. I know plenty of others who have had similar experience. I strongly believe coding should be apart of the general education of my country. I'm not saying everyone should be able to be able to write a complex program, but at least write a simple calculator :)
It can be hard finding a good implementation of Logo, but Microsoft's [Small Basic](http://smallbasic.com/) provides a good basis for immediate feedback. 
Even better, watch some early Alan Kay videos. (Sadly I'm at work, and don't have time to search for links now).
&gt; Many people find programing hard. Also you don't see visual results right away. GUI programming and any form of graphics programming starts very late. When you say "see" people expect to create GUI or cool pictures, and you can't do that right away. In many ways math and programming have parallels in terms of how people learn them. You have to remember that programming started as a mathematical tool. By "see results" right away, I mean basic output. With math, if you are doing something wrong, everything is wrong and there is very little way to figure out, on your own, where you screwed up. With programming, something as simple as a print statement gives you a peek into exactly wants happening. GUIs are nice, but the terminal is the father of all computer output (at least for screens). Not only this, but you can manipulate chunks of code and see the result the moment you rerun it. Compilers are vague and confusing to non-programmers, but still offer good feedback to what you did wrong. Every step of the way, there is some kind of feedback that the student receives that gives them a clearer picture of what is going on. This kind of feedback simply doesn't exist with math on paper which is how math is predominantly thought. Programming by nature is a lot more approachable. Note: I am not comparing the two disciplines in terms of "better" or "worse". Just the contrast in how learning/teaching is approached.
Interesting, I just stared it.
Using a type-alias instead of a real type (by using `typedef` or `using`) creates two problems: * The error messages become less readable. Using a real type creates more context if you later get `in pegtl::sor&lt; integer, ... &gt;` instead of `pegtl::sor&lt; pegtl::seq&lt; pegtl::opt&lt; pegtl::one&lt; '+', '-' &gt; &gt;, pegtl::plus&lt; pegtl::digit &gt; &gt;, ... &gt;`. * You loose the anchor-point, going back to the type that you aliased. You can no longer use different real types with the same base class and attach different actions to each of the derived classes. That said, if you are aware of the above you *may* use a type-alias in *some* cases. But since this seems too complicated to always think about, we generally recommend to use real types.
&gt; If supporting tooling makes it difficult to extend language features, than clang should be way behind YouCompleteMe for Vim, and I believe XCode are both clang powered. No doubt many more are too.
Is "modern" C++ adoption really going so slowly in the industry and academia? Here in my university we were taught up and front C++11 and C++14 (not really a standard then though), I am also hearing that people starting this year will be introduced to the TS proposals and recommended to keep up to date with them in for C++17. Industry wise, many companies around here seem to be already up and using C++11 (to a certain extent though) and planning to move up to C++14 since it extends a lot of stuff introduced in C++11. So in my opinion, most companies here at least are up to date with the stuff being taught at universities.
In my experience, this book leads to some really terrible misunderstandings. The order in which it teaches is pretty bad, too.
Working commercial software here and we use aC++ and Oracle studio. While it may be only 2% of the programming jobs on the planet I'm sure they represent more than 2% of the servers so they aren't going away any time soon.
RAII does address this problem, but you don't always have that available as an option. I too would prefer RAII over naked handles though
Expecting pointers to be required far more often than they really are, expecting new to be required when dealing with pointers far more often than it really is, irrational fear of exceptions.
What you say about the progress bar is true, but there is a subtlety here: Even the relaxed model guarantees that each value is committed to memory, i.e. the compiler is not allowed to store the value in a register, or elide all the writes to a single update at the end. That means that the workers are guaranteed to publish their progress, even if the view might miss some or all of these updates. In practice relaxed is a good fit for progress indicators (of long running worker threads) since it is relatively unlikely that the progress view will miss all the published counts. 
&gt; What situations is the pattern in the blog a better solution than creating RAII-based classes? Consider this API (that could be for a C library): session_id create_session(); void destroy_session(session_id id); // pwrfect for RAII // add quible to the session and return a handle quible_id add_quible(session_id session); void transmigrate(session_id session, quible_id quible); If a quible is owned by a session (and destroyed when the session is destroyed), there is no requirement for RAII, for a quible_id (because there is no resource here to release and no extra responsibility acquired on creation - by definition, RAII does not apply). The strong typing of a quible_id is still a good choice (you still do not want clients to be able to pass a quible id for a session_id). 
The examples using decltype are even more horrific. Imagine if you had that in your company style guide. Just keep using "for" until something else is simpler. 
This probably would have a significant speed up due to eliminating the exceptions/OS fixup, but would likely still be slower than also using correctly aligned storage which would permit faster aligned memory accesses. But yes, in general memcpy should be preferred over either reinterpret_cast or unions: http://blog.regehr.org/archives/959 reinterpret_cast can easily be misused to produce undefined behavior (and I've personally fixed up SIGBUSs caused by other people's misuses of casting). In C++ type-punning through unions is almost always undefined behavior, even though compilers typically support it. memcpy can be safely wrapped up to make type punning more succinct and readable: http://pastebin.com/MmPjWBiU
[It's not always faster.](http://tinodidriksen.com/2011/08/31/cpp-include-speed/)
Cool that you tried compiling it using clang-3.5 on Windows! And nice to see there seems to be some progress on the clang for Windows front :) Last time I checked there was very important stuff like support for exceptions missing, and I thought that in its current state, it's not usable yet.
This is really awesome. However, since I don't see any rationale for the return-type in it: Is this an oversight? Because I really think that it should not be modified in any way. 
Nice tutorial but i wonder why the user uses the C Api, instead of the C++ API. At the beginning he writes: &gt; In this example, I’m going to use the C API, because it is available in the LLVM &gt; distribution, along with a C++ API, and so is the simplest way to get started. But later on when actually compiling the example, he writes: &gt; Even though we’ve written a C program, the linking step requires the C++ linker. &gt; (LLVM is a C++ project, and the C API is a wrapper thereof.) So wouldn't it be the simplest way to just directly use the C++ API? But i also wonder why there is a C wrapper in the first place. I mean usually you see C++ wrappers that wrap C APIs in order to make them easier to use, not the other way around.
the c wrapper is meant to provide abi stability between releases. for llvm/clang, using the c++ interface is a lot easier if you don't need such stability. op is confused. there is no such thing as a c++ linker.
I am completely in favor of them defining new associative containers that do allow a B-tree implementation.
You do need to link the C++ standard Library, which linking via g++ or clang++ will do automatically.
This is a serious question. Why write C when you can write C++ unless your developing one of the (2%?) solutions that actually has a space requirement.
&gt; I mean usually you see C++ wrappers that wrap C APIs in order to make them easier to use, not the other way around. C APIs are needed for ABI stability. C++ APIs are nice for the full richness provided by C++. So people wrap C++ APIs in C when they need stabilty and C APIs with C++ when they want more expressiveness, convenience, safety. Sometimes both at the same time: [Hourglass Interfaces for C++ APIs](https://www.youtube.com/watch?v=PVYdHDm0q6Y)
[isocpp.org](http://isocpp.org/) is a good place to start following C++ happenings. I'm looking forward to the adoption of [ranges](https://ericniebler.github.io/std/wg21/D4128.html), [concepts](http://concepts.axiomatics.org/~ans/) and [modules](http://isocpp.org/blog/2012/11/modules-update-on-work-in-progress-doug-gregor).
Thank you! This is exactly what I needed. I started with learncpp.com but it was kind of outdated and incomplete, so I was looking for something to improve my knowledge.
To expand on what /u/hotoatmeal is saying: &gt; ABI stability ... you really do need C **interfaces** I think this is the key point. Even if you need a C **interface** for ABI stability you can still write the **implementation** in C++ and glue a C interface on top of it. This gives the best of both worlds, an interface with a stable ABI for applications/libraries that need to link in your code, and the power of C++ for writing the implementation. It's a fairly common practice but is not immediately obvious if you've never encountered it before. 
At a glance, this is fairly terrible---bad grammar and more than a bit of misguided, misunderstood, or meaningless advice. Sorry.
I'm not sure what you mean. Whose return type?
That's a good point. I missed that. I'll have to think about before making the change, but I suspect that you're right. The lambda should be completely transparent to its arguments and their returns. By the way, "decay" is a library concept. The difference here is between template argument deduction rules and decltype deduction rules, which are core language concepts. Decay does something else.
Uninstall windows and install Linux, then use emacs, gcc, and make. 
You're using Linux and Emacs? Pleb. Every good programmer uses vacuum computers and bit-shifters for their *introductory programming courses.* (Don't be an ass, puffins.)
&gt; String literals can't be used as template non-type params :( I'm not entirely sure what you meant by this sentence. But if you were talking about parsing string literals during compile-time, then it's totally possible now. I use [this technique](https://github.com/adityaramesh/ccbase/blob/master/include/ccbase/utility/ratio_literal.hpp#L22) myself to parse ratios and other objects during compile time: using r = "123.456"_ratio; using id = " 1 0 0 0 1 0 0 0 1 "_matrix; Disclaimer: template &lt;class Char, Char... Ts&gt; constexpr auto operator"" _suffix() is currently a GNU extension based on a standard proposal that I suspect will likely get included due to its usefulness. It's supposed by both GCC and Clang. You might find [metaparse](http://abel.web.elte.hu/mpllibs/metaparse/) useful toward this end, especially if your parsing is not trivial.
i think this is great, a lot of useful info(and updated) in one place, i was particularly impressed that boost was listed and has many relevant tutorials that i have had a very hard time finding
I would love a good FAQ to help us noobs :)
My proposal is more conservative: uninstall codeblocks and install Qt with Qt Creator
Im also currently learning c++ and i find this: https://www.youtube.com/playlist?list=PLAE85DE8440AA6B83 tutorial a very good one, it explains every little thing and its fun too, if you then want to move over to another language sites such as codecademy and khanacademy are two good sites for that. Hope this helps!
There already is [such a post](http://stackoverflow.com/q/388242/559931), though it's on StackOverflow.
Nope. If you're serious about learning C++, get [a book](http://stackoverflow.com/q/388242/559931).
I miss a part about writing cross-platform code. And about cross platform compiling e.g. [Emscripten](http://kripken.github.io/emscripten-site/)
I agree. UTF8 should be the only format (especially for source code). But why Windows uses UTF-16 by default is a mystery...
Why don't you use boost::asio as a TCP socket lib?
Mostly because I enjoy low level development.
&gt; I am new to c++ and programming in general but I am already falling in love. ...really? Interesting. I mean don't get me wrong - I can dig C++. I like writing stuff that amazes me with how quickly it can process data and what not. But my first go at it - even after having been programming for 6-7 years... was hardly love at first sight! You must have some damn good professors.
It's not a mystery at all, you just have to look into the history of Unicode and Windows support for it. Java uses UTF-16 also for much the same reason. 
No, it is not. A better C++ is a programming language with the same target domain as C++ without all the C++'s problems. Other languages target different domains, so they are not 'better C++' than C++ in the C++'s domain. They might be better than C++ in their domain though. 
I am going to catch hell for posting this here but now that rust is stabilizing it looks like it is shaping up to be a serious contender.
You're missing the point. C++ used to be useful in a much larger variety of domains, but new languages now do those things better. So from the perspective of someone who works entirely within one of those domains, the new language serves as a better C++. 
&gt; `upgraded = new map&lt;unsigned int, bool&gt;();` Please, no.
C++ was designed for *many* areas of applications. It isn't the best for many of them anymore (maybe for many of them it wasn't even good in the first place). For some it still is, but surely not all of them. In a lot of areas C++ excelled at *before* because of how it was design, it doesn't anymore exactly because better alternatives came to be. These things also change over time. C++ is from the 80's. It was created in a different time. The way people talk about C++ now isn't the same way people talked about C++ back in the 80's or even in the 90's. *Today* people ignore the fact that C++ failed in many areas it was design for. They focus on the areas in which it succeeded. And why wouldn't they? It's the useful thing to do. The point is that it makes it easy to forget that failures were there (and in the case of C++, there were many). So it's absolutely *not* true that C++ is the best for what it was designed for. C++ was designed to be *way more general* than how it's used today. For all those other uses C++ was designed for that it's not much applied anymore people have found other languages that they consider better alternatives. C++ remains the best for a subset of the areas in which it was design for, but all that shows is that it isn't the best for what it was design for, it's only best for a small subset of it. And with other languages coming in, like Rust and maybe you're kind enough to consider Jon Blow's JAI, the space in which C++ is applicable ought to shorten even more over time (as it has been happening over the past 2 decades). __EDIT:__ Just to be clear, I'm not the one downvoting.
C++ attempted to be a good language for several domains through characteristics that you mentioned (and yes, I "catch your drift"). It was a good fit in the 80's and 90's for many of them, but as time went on things changed (like I said, these things change over time). &gt; That C++ was used in domains that the above criteria were not important was incidental. It wasn't incidental. C++ people did the best they could to reach many application domains (there was and still is a huge effort). And over time, the effort they did became not very relevant to many of those domains, and then other languages became more interesting because even though they didn't do much of what C++ did, they did other more interesting stuff. Stanley Lippman said (in BoostCon 2013 I think) that Stroustrup would go around showing people that they could do in C++ whatever they thought they couldn't in the earlier days. That's not so that people would use it incidentally. There was interest, lots of it, to get people of several domains to use C++. For several domains that people used C++ before, ... (blah blah blah -- I think I said this enough times now). C++11, C++14, and C++17 seem like a reaction to this, IMO. It was said (I think in CppCon 2014, or maybe it was in the GoingNative conference) that one of the reasons why people were working on so many libraries and language features to make C++ more convenient is so that it becomes more attractive to other programmers in other areas (inclusive beginner ones). 
The goto problem will need to be addressed first, in my opinion. I love Rust though.
No. C++ was not built with domains in mind. It was built around specific principles. 
&gt; like neural networks for example I think [this](https://github.com/nyanp/tiny-cnn) is a much better demonstration of the awesomeness of C++(11) than the link you posted.
For anyone serious about C++, "a better C++" means a language with at least the same performance, but with some modern conveniences that a lot of other languages have (but not garbage collection). Crucially, it would also have a massively bigger standard library that includes proper socket and database support etc. etc. Of course there is also the safety aspect that Rust is trying to address. I'm interested to see how Rust turns out, but C++ itself could become the "better C++" before anyone else does it if they decide to ditch some backwards compatibility. For a start fundamental types should auto initialise (e.g. int should auto initialise to 0) with a way to opt out for the extreme performance case. A lot of that kind of default behaviour from C just doesn't make an sense anymore, although it should always be possible to override safety features when you *really* need to.
Unlikely. Can you imagine the massive shift in expertise that this needs? Languages take 20 years to become mainstream, if ever. It's not only expertise. It's environment, libraries, "problem bibliography", etc. It's a massive effort. I am also interested in rust, and I will consider taking a look at it soon, but to me, and for the time being, the choice is clear. If you want performance, get dirty and go commando: use C. If you want to stay cushioned, use python. C++ does its best to introduce features of dynamic languages into a static environment. This results in bulky, complex compilers and environments, and potentially large compilation times. C++ imho is a great example of how you can literally blow something up to unmanageable complexity when you force too much responsibility on the compiler, which in turn forces too much responsibility on the programmer. 
It's a hard problem; Rust has the advantage of 27 years of research compared to C++, and it uses them. The ownership system was based on Cyclone's, an academic language developed in 2001 for example, with a focus on... ownership.
&gt; For anyone serious about C++, "a better C++" means a language with at least the same performance, but with some modern conveniences that a lot of other languages have (but not garbage collection). This is very centered on a C++ programmer of "now" (late 00's, early 10's). Serious C++ programmers of late 80's and early 90's using C++ for other areas for which we don't use it anymore could have been (and were) concerned with other things. In the past a lot of the use for C and C++ wasn't "performance critical" programs. People had to use C because of existing libraries and OSes. C++ came as a way for people to have more convenient features while keep using their C libraries. That was the reason for lots of people to move into C++. For these cases, and there were *many* of them afaik, the initial reason why C was chosen had nothing to do with "performance critical". It was just the practical need to use a library X or Y, or the OS Blah. Another interesting fact is that in the past this performance situation was a bit different. If you look for example at the book "The Practice of Programming" (from 1999), it implements an algorithm in C, C++, AWK, Java and Perl. It then compares the performance of these. The results are curious because today we're used to the fact that if you get a slower C++ program than what it should be in C for example, then you're doing something wrong. In the past, though, compilers were just not good enough (somethings they were just missing features, sometimes they just didn't optimize well enough, or whatever else). Implementations of the STL, which today we know are already fast and optimized, were not always fast. In fact, the performance comparison that it's done in the book shows how slow using C++ and the STL made the code to be (there were two versions of the C++ code, one being 4.7 times slower and the other being 7.2 times slower than the C version). Remember also the size of binaries? As far as I know this isn't a problem *anymore*, but in the 90's it was. So yes, I understand where you're coming from, but "better C++" happened to many people in the past when they used C++ for more convenience on top of clunky C libraries they had to deal with. The *major* example I can think of is C+Win32 API versus C++ and class wrappers built on top of the Win32 API. Later, a lot of these people didn't mind switching to C# *at all*. So to say that a better C++ hasn't happened yet is just false. It may not have happened in the performance critical area, but that was just one area that C++ acted on. C++ made more promises than just "bare metal performance" (I hate that terminology, but it's what people use). Compatibility with C coupled with more convenient language features were *huge*. Today many people see compatibility with C more as a curse, but it was probably the reason why C++ didn't die in its first years. Rust seems interesting... I wonder how long before it's actually usable.
https://github.com/nemasu/libasock/blob/master/test/recv_spitter.cpp The mix of new's and perhaps over use of inheritance terrifies me.
There's always the labeled break, if you're desperate.
I accept that a lot of ex-C++ programmers have already found their "better C++", but that point seems moot if we are talking about people who are still discussing the notion. As a C++ developer I certainly see lots more advantages beyond performance for liking the capabilities of the language (and I don't even actively dislike the syntax, although it would be a huge benefit if it was easier to parse), but performance is certainly the thing that is pushed beyond all else (at least I would say) by the *modern C++* crowd. I believe Stroustrup himself has said words to the effect of C compatibility is C++s greatest strength and simultaneously its greatest weakness (maybe it was someone else, but it is certainly a familiar sentiment).
If it has debugging tools as easy to use as java with the control of C++ I'm in!
Thank you! I'll look into your solutions!
Using templates is part of a space-time tradeoff. You generally use template to do compile-time polymorphism, which translates to more data in the binary (more space) that you would otherwise solve with virtual calls, which induces more computations at runtime. And if you write three overloaded methods, or a template instantiated with three types, you get the exact same amount of code in your resulting binary... 
&gt; I accept that a lot of ex-C++ programmers have already found their "better C++", but that point seems moot if we are talking about people who are still discussing the notion. As a C++ developer I certainly see lots more advantages beyond performance for liking the capabilities of the language (and I don't even actively dislike the syntax, although it would be a huge benefit if it was easier to parse), but performance is certainly the thing that is pushed beyond all else (at least I would say) by the modern C++ crowd. That's right. I don't disagree. The discussion was more about the point: &gt; but the fact is that in all these years, no one has actually made a better C++ This is a *very strong* statement. Extremely bold. It doesn't only involve those of us today still discussing C++. It involves everything "in all these years" - that's a lot more than just those of us today =D. This is why I've said "in the past" so many times through the course of this discussion. 
Except every other line that needs to do something has .unwrap()
Once you understand it, its obvious why it increases binary size. The problem is that it is apparently not common knowledge to everyone which is why it causes problems.
&gt; C++ was designed with specific criteria in mind: performance,.... &gt; So, for the criteria defined above, there is no better language than C++. Ada, C and Assembly
While it doesn't have the best debugging tools right now, I think it is well setup to have them in the future. C++'s biggest problem with debug tools is the fact that it is extremely context sensitive. The preprocessor and template system really do a number on IDEs trying to figure out what the heck is going on. Rust, on the other hand, just isn't like that. It is really easy for an IDE to divine exactly what is happening. But don't think that is losing flexibility, Rust's macro system is really pretty interesting. I think it will open up some new and exciting metaprogramming possibilities. For example, people have already made Json and SQL query validators using the rust macro system.
Oh yeah, I was just linking my own implementation of feedforward neural networks as an example of the projects like I described. I would *not* consider it very "good" beyond that it works and is minimally readable.
Visual Studio for Windows, for the debugging. Geany for Ubuntu, easy to use with gcc.
Qt.
Emacs
I can tell you there is absolutely nothing lightweight about Eclipse.
You don't need to use Express anymore if you want free. VS comes with the community edition, a full version, free for teams up to 5 devs IIRC.
Visual Studio 2013 + Visual AssistX for me. It's ok, there are occasions the intellisense gets confused, loading up a project in the morning takes a while. Sadly C++ is not an easy language to parse for fast intellisense. I don't complain, it's miles behind what you would get with modern languages such as C# and Go but still miles better than what you get with other IDEs like Qt Creator and CodeBlocks.
Code::Blocks
I use QtCreator or Vim usually.
Qt creator is the only IDE I've found useful, and I've not actually used it for a Qt project yet.
Vs2013 community
Vim is great, I'm able to get whatever I need and its still really light weight.
&gt; I dislike IDEs because they hide important information I recommend Visual Studio. It hides nothing, it simply calls the compiler for each source file, then calls the linker. No magic at all!
How does python relate to gdb?
This looks pretty good, thanks.
Lol, just because you can't *see* what it's hiding doesn't mean it's *really* not hiding anything. As a random example, Visual Studio includes *two* different, incompatible, compilers, and it is fairly frequent for only one of them to work on a given file. But more relevant to newcomers: how do they even know the difference between "compiler" and "linker"?
Gedit &gt;= 3.12. I'm the only one :c Everyone always asks me what IDE I use when people see too. Here's how it looks: http://i.imgur.com/RIWGtah.png Although the project I'm currently working on is written in Lua -- not C++ -- but you get the idea.
I don't use Prelude... my Emacs configuration has evolved over the last 28 years. But if you're starting out it is probably worth using. 
I use Visual Studio, but I read that orwell dev c++ is pretty lightweight. You might want to try that and see how you feel about it.
1. Learn a basic subset of C++ 2. Learn how to use the compiler tools to build a program from the command line 3. Learn how to automate command line tools with scripts and makefiles ----- For text editing, I typically resort to gvim. Platforms I use primarily use either custom Eclipse (Altera, Microsemi, or TI) or VS (Atmel) IDEs. If I was focused on the Windows platform, I'd probably use VS.
I got co-workers that always give me the eye when I say that I use VS for serious development. VS is up there in the world's most advanced IDE, albeit a C++ compiler that's been behind standards for a while.
I have mixed feelings about it, I love the IntelliJ framework but Clion seems far from a finished product. I was getting constant crashes and hanging. I'll be keeping my eye on it but I'm not sold yet.
No love for Kdevelop? It has the best syntax highlighting ever.
Lol, don't use compilers and linkers. They hide important information.
It is far from a finished product. Their EAP releases are from their Early Access Programs. These are generally provided with alpha-level (or even pre-alpha levels) of disclaimers about performance and stability. So yea, I'd agree it's not close to a finished product, but in its current iteration it's not really supposed to be. Jetbrains has earned my trust with IntelliJ IDEA and PyCharm as well as ReSharper for VS so I'm not too worried about when Jetbrains decides to release it as a full product.
And even with that foundation, it was still a really hard problem that took a few years of iterating on to get working well.
On the plus side, you would get kind of an automatic expression de-duplication/equvailence, which would be useful.
I currently use vim and exuberant ctags.
I guess I was going for more of the kind of answers that I've been getting. Just a general "what do you use to code in c/c++?" So I guess we could drop the I in IDE and that would be more accurate in terms of what I was asking. 
XCode -- decent, free, full C++14 support. But it's mac-only, though.
I've got it running fine on an Ubuntu system.
because when i recently tried to download visual studio to give it a go and the installation was 9GB with only the basic features installed, I though I might want to look for some "lighter weight" alternatives.
That make under a certain $$ threshold
KDevelop is always my go-to.
are you on a 32bit machine by any chance
That's fair, it is large. I actually thought you meant Eclipse, but it's the same question, if it works why not?. You do have to keep in mind that the SDKs alone are huge and come with VS. It also includes several compilers, debuggers, cross compilers, the runtimes and additional tools. I'm not saying it's equivalent, but if you add up Java, Eclipse, GCC (and other languages they throw in), GDB, make and friends, all the devel packages for the libraries, the runtimes for those libraries... none of the comparable IDE's come cheap. VS just has it in one lump really and you don't always need to instal everything if you aren't going to use it. If you are going to use it, then it's not a waste. If you add up all the dependencies, development is pretty heavy weight period.
Wow. Looks like Atom. I wouldn't have guessed it were gedit.
The plugin is much smoother to get working, now. It's "fairly" pain free for me. I personally don't use it, though, because if you're not using it for python or C/C++ then it tends to really suck and it's not nearly as powerful as neocomplete for "general" usage or LaTeX (to me), which is a shame.
Visual Studio + Visual Assist Visual Studio "because Windows" - yedt it's a good IDE. Clunky at parts, braindead on others, but after two decades it would probably be very hard to move. Visual Assist "fixes" the not-so-stellar refactoring support, source code navigation is what makes the combination addictive, even though VS caught up a lot since VC6. ~~It's a commercial combination (addins are not supported in express), so probably not an option for you.~~ Community Edition is free for personal and small team commercial use, and is a good IDE even without Visual Assist (which is paid). Visual Studio Express itself is "lightweight enough" on a good machine, but on a vanilla box, it feels a bit heavy. 
The modern neo-luddite.
i'm trying to so hard to write a proper response to this. but i got way tooo high. i'm gonna try again in the morning.
Community Edition of VS supports add-ins and is still free ;] Just change of heart from Microsoft ;]
Visual Studio 2013 + Visual AssistX
No, c++ was not made with domains in mind. It was made with specific criteria. The core principle "do not pay for what you do not use" is a cross-domain principle. 
Qt Creator because it's open spurce, runs on every platform and it's being written in C++. One could learn Qt programming by studying it and why not contribute back!
Since people are suggesting emacs and vim which aren't exactly IDEs, I figured I'd chip in. I personally use Sublime Text. It's ridiculously lightweight (seriously, it starts in less than a second on my old macbook) and there are a lot of plugins. The multiple cursor support is also fantastic. It has decent project support, as well as build system settings for makefiles and cmake (probably?). You can also install SublimeClang to have real time code linting and error checking. Of course at the end of the day what editor you use is up to you. One point; if you're on windows, VS is unbeatable as an IDE. It has an excellent debugger, and it looks quite nice too. Only thing is that the MSVC++ compiler is somewhat antiquated wrt. recent C++ standards (C++14). Whatever you do though, do not use eclipse. It's slow, bloated and generally a bad piece of software.
Oh, so hard drive space is expensive for you?
I modified the default dark theme so that line numbers didn't have a black background, and also a whitespace viewer plugin; again, I changed the theme to make the whitespace a little less visible. Other than that, the plugins I use aren't visible in that screenshot. The file browser is a plugin, but it both, comes with it, and is enabled, by default IIRC. Oh, I also start gedit -- via an alias -- with `GTK_THEME=Adwaita:dark gedit` (gedit doesn't have a dark theme option yet).
&gt; It has the best syntax highlighting ever. How's this still a 'feature'? In Visual Studio alone you can configure almost everything in the syntax you can possibly think of.
Visual AssistX parsing. In theory the project is "loaded", but the IDE is very unresponsive until VAX has finished parsing the entire thing.
Should probably mention this is for Linux.
&gt; Their EAP releases are from their Early Access Programs They should've probably named them EAB, because that's pretty damn confusing.
I tried it a while ago (maybe it's better) it wasn't good.
Personally I even use Qt Creator for JavaScript development! I liked it so much when doing C++ development, that I just stuck with it. Its build system configuration is flexible enough that I can set it up to build projects with Grunt or Gulp and ever since Qt introduced QML, their IDE actually has quite good JavaScript support.
I never had any problem compiling it, neither on arch, OSX nor Fedora. What distro are you using and on which architecture?
VS2015 Preview, because finally M$ released an IDE with decent C++11 support.
And it has nice valgrind integration! Yes, real programmers need profilers. I hope that everybody voting for Visual Studio bought the Ultimate edition, since cheaper versions don't include a profiler.
Visual Studio 2013 Community. It runs fast, has great intellisense and debugger. And all the features of Pro VS for $0.
d'oh! Completely forgot about that! 
Care to elaborate?
I see. VS can only colour based on the type of the variable (argument, member, local variable). I wouldn't find the scope-based colouring very useful, and I'd probably find it confusing instead. So I suppose "best syntax highlighting" is pretty subjective.
vim and emacs integrate calls to the compiling chain. They can also integrate debugging, smart completion, VCS, and simplistic refactoring (for now). As such, they are Integrated Development Environments. I can't say for Sublime Text -- I don't know it well enough.
Sublime is much like vim and emacs insofar as it has a fairly expansive plugin ecosystem that turns the base editor into an IDE, and supports many of the same features, just with a modern architecture. It's really a lovely, lovely, editor. The only trouble is that development seems awfully slow--SublimeText 3 has been in beta for what feels like forever--and some of the most useful plugins (SublimeClang being the prime example) are not being actively developed and there's no real alternative yet. 
A book helps, but for the first steps a tutorial providing examples covering basic topics is better for the newbies. Also note there are a lot of bad C++ books out there. We have the opportunity to write a good tutorial for C++ noobs, something our community needs a lot.
that's exactly why I feel this is a great opportunity :) Let's change that.
I am too ashamed to say.
Visual Studio 2013, as our uni provides us all with licenses. It's not particularly lightweight, but I find it a dream to work in and now the Community Edition is a thing so everyone can get Professional-equivalent for free
Emacs 
This is the selling point for me in this.
I tend to use Sublime Text and switch to QtCreator whenever I'm working with Qt or I'm dealing with some weird third-party libraries. That's when QtCreator's auto completion and code navigation saves my life.
This should be titled "Memory Layout of Programs according to some Operating System or some ABI or some other convention". I don't see anything about C++ in there. (Not even about C, which is actually what article mentions)
XCode, it's the least bad I've tried so far on mac. It's not optimized for C++ though, especially when your projects get bigger.
I have tried it and I do not thing it worth the time I spent. On mac it is borderline unusable. Maybe it performs better on windows.
The slowest part for me is Perforce integration, especially if I'm connected through my cel phone. If I turn p4 integratino off, a million-line sln opens in seconds.
NetBeans
On Windows: Visual Studio or Netbeans On Linux: Geany On Mac: XCode
&gt; and I'd probably find it confusing instead I thought so too, before using it. but now I feel the argument against it is a bit like an argument against syntax highlighting in general. it actually improves the speed with which I can comprehend some code immensely, suddenly I don't really have to constantly recognize the variable names, or at least I do it much quicker, with the hint from the color.
At the office we use slick edit...
Sublime Text + Mingw-w64 + CMake
I think the C++ specific features of a proper IDE are essential to development as they make things like refactoring deterministic. As an example, one of the most common actions is renaming a variable to increase clarity and with Emacs the best you can do is a search and replace which has a degree of risk even if you're clever in your use of regular expressions. However, there is this perception that using these tools is somehow a crutch to developers. It cultivates this culture where emacs and vim are still widely regarded despite continued advancement in proper development tools. More over, languages are being bloated with unnecessary features because we don't treat programming as an ecosystem. We create syntactical short cuts with the pretense of speeding up development, so the developer doesn't have to type as much etc (like creating Lambda expressions where functors are sufficient but wordier). Language complexity will limit how we can process the language itself using out tools. (Have you ever used the refactoring features in Eclipse? You can literally move functions to other classes deterministically and it will re-arrange the parameter lists as necessary. Very few refactoring tools allow this and it's because of the base essential nature of language features of Java that make it possible). It's fundamentally the wrong perspective. Code shouldn't even be text anymore. It should be object data briefly represented by text because keyboards are essentially the only effective input method we have for creating this object data but it should be stored as the language structure it essentially is. Working in Java and C# has taught me that separating editing from compilation is silly. It slows down the turn around on development. Having to wait for C++ to compile and link means that I take bigger risk in code changes before I commit to testing to see if it works. Instead, we have developers who are proud that they don't rely on the "crutch of an IDE". It's proud of using a hammer when a nail gun is 10 times faster and more efficient.
I suppose it also depends on how much nesting occurs in your projects. I usually like to keep it to a bare minimum.
nesting?
I heard good things about [Plastic SCM](http://www.plasticscm.com/home.html). Might be faster than P4. I tried using P4 before because I needed binary versioning but it honestly was such huge pain.
There is ClangComplete for Sublime on linux.
Does it work well? It's only for ST3 right?
https://en.wikipedia.org/wiki/Nesting_(computing)
&gt; Where is c++ found in every day life? - games - embedded devices - operating systems - mobile devices - High Performance Computing - High Performance Trading &gt; What projects have inspired you? None that I can relate to. Maybe it better to explain how I came to C++. Back in the day (approaching 40 now), one of my get to go languages was Turbo Pascal. When I got to learn C, around 1992, it was a meh language, given that Turbo Pascal 6.0 was much more feature rich in terms of OOP, modules and memory safety, while allowing to do everything that C allowed for. Also be aware that back then to achieve real performance in home computers meant coding everything in Assembly and higher level languages were our scripting languages, so to speak. On the same year I got to learn about C++ and was sold. There I had a language with similar features like Turbo Pascal, but I also could take to other OS. Sadly Turbo Pascal was PC only and suffered the fate of C spreading into the industry. Nowadays I mostly code in JVM and .NET languages at work, but keep up to date on C++ and do use it occasionally for hobby projects. For example, if you want to write portable code across all mobile OS, C++ is an option, even if you need a bit of OS specific glue. &gt; What is the c++ community currently looking forward to? Modules
I don't see the relevance?
Qt Creator and Visual Studio, though I prefer Qt Creator, because it's more lightweight and tries to mimic the VC6 interface. In the past I used VC6, and before that Borland C++, and before that Turbo Pascal (though that is not C++). Those are about all the IDEs I've ever used extensively, I know some other IDEs but I use them occasionally. 
Yes, but it is only accessible if you subscribe for factory twitter which posts references to twitter builder which posts references to Java twitter which you have to post into to register your twitter in it so it posts in your twitter Java programming posts from it. I know it is not abstracted enough and there are people working on v2 of it to add 8 extra layers in between those...
We're deep into Perforce and there won't be any momentum to switch away. Someone at my office investigated Plastic, and as of a few months ago they only supported complete branches, not individual files or directories. That flexibility in perforce (integrate anything anywhere and it will remember) may come at a performance cost when you integrate, but that is such a small price to pay for the flexibility. Maybe Plastic has changed since then? Perforce is so good at what it does well that it makes sense to put up with the few things it does poorly.
Ah I see from your username you're the developer! When you say it integrates nicely with CMake, do you mean it can pull the compiler flags from the CMakeLists.txt directly? That would be awesome. What's stopping you getting it working on Mac? I develop mostly on OSX so I'd be very interested in helping if you need?
&gt; When you say it integrates nicely with CMake, do you mean it can pull the compiler flags from the CMakeLists.txt directly? Well not directly from the CMakeLists.txt, but it parses the cmake files in the build directly. &gt; What's stopping you getting it working on Mac? Well originally it was more difficult because I was using python's library, but I have since dropped that, so it should be much easier now. Here is a list what needs to be done: * Build the shared object on the mac using either clang from apple or clang from homebrew(this shouldn't be difficult, its just different between linux and the mac) * Load the library in python on the mac * Update some configurations, like where headers are located on the mac &gt; I develop mostly on OSX so I'd be very interested in helping if you need? That would be great, thanks.
Thank you!
License is GPL 3 or pay .
My only issue with it is that the header indexer will choke once your project gets large enough. For anything that isn't, say the Linux Kernel or Boost you should be OK.
As one of the authors of the PEGTL and being not very familiar with Boost.Spirit, that comparison will not be very fair or useful if I'd try to go into details. Boost.Spirit is obviously *much* larger, most likely more powerful and maybe more complex. Its authors have put a lot of effort and genius in it and it is certainly worth to check it all out if you have the time or the need. That said, I think that the PEGTL's main advantage is its size. The code base is **small** and **clean** and it concentrates on **doing one thing:** Helping you define a PEG. We don't use macros so that a solid C++11 knowledge allows you to understand all the code you write with it. Having no dependencies and being header-only, the PEGTL is very easy to integrate with other code bases. As the PEGTL uses templates to define the PEG, almost everything is compile-time and can therefore be optimized by the compiler. Boost.Spirit uses operator overloading and generates more run-time code than the PEGTL (AFAIK, please someone correct me if I'm wrong). What is better for your use-case is left to you, I don't think there is a general answer. 
Can someone please explain to me what is going on here? template &lt;class F, class... Args&gt; void for_each_argument(F f, Args&amp;&amp;... args) { [](...){}((f(std::forward&lt;Args&gt;(args)), 0)...); } I tried it, and it does indeed work. The passed-in function gets called for each argument. What does the lambda do? And what is the , 0 doing there? Shouldn't variadic templates use recursion? 
Here comes dependency injection: follow article's guide but changing C++ for Java, it should work ;)
&gt; I think the C++ specific features of a proper IDE are essential to development as they make things like refactoring deterministic. As an example, one of the most common actions is renaming a variable to increase clarity and with Emacs the best you can do is a search and replace which has a degree of risk even if you're clever in your use of regular expressions. I will admit that there are no good refactoring tools available for emacs. Honestly though this is a non issue for me, the amount of time I spend refactoring is a negligible amount of my work. The rare refactoring I do is changing a variable in a single function, which is as easy as doing a region-expand to select the function and then doing a local search and replace. &gt; However, there is this perception that using these tools is somehow a crutch to developers. It cultivates this culture where emacs and vim are still widely regarded despite continued advancement in proper development tools. There are continuing advancements in emacs/vim as well. One of the tools I mentioned, flycheck, is a vastly improved package to replace the older flymake. And easymotion/acejump are fairly new packages that make moving around on screen a lot easier. One thing emacs users will never shut up about is that we can make our own advancements to the editor as well. &gt; More over, languages are being bloated with unnecessary features because we don't treat programming as an ecosystem. We create syntactical short cuts with the pretense of speeding up development, so the developer doesn't have to type as much etc (like creating Lambda expressions where functors are sufficient but wordier). Language complexity will limit how we can process the language itself using out tools. (Have you ever used the refactoring features in Eclipse? You can literally move functions to other classes deterministically and it will re-arrange the parameter lists as necessary. Very few refactoring tools allow this and it's because of the base essential nature of language features of Java that make it possible). I think lambda functions are a poor choice of example here. In my experience they actually reduce the mental load on people reading the code (I have a history with functional languages like lisp and Haskell). In java for example it removes those hideous anonymous classes. As far as modern languages getting bloated I don't see that personally, though I only occasionally use java and never use c#. &gt; It's fundamentally the wrong perspective. Code shouldn't even be text anymore. It should be object data briefly represented by text because keyboards are essentially the only effective input method we have for creating this object data but it should be stored as the language structure it essentially is. This I can agree with. It's one of the reasons I enjoy working with lisp in emacs, it gives your tools for structural editing instead of just text editing. &gt; Working in Java and C# has taught me that separating editing from compilation is silly. It slows down the turn around on development. Having to wait for C++ to compile and link means that I take bigger risk in code changes before I commit to testing to see if it works. Back a few posts I mentioned flycheck, which can do a quick pass of all your code through clang as you work and annotate the code with errors and warnings. I don't see how that is different at all from an IDE. &gt; Instead, we have developers who are proud that they don't rely on the "crutch of an IDE". It's proud of using a hammer when a nail gun is 10 times faster and more efficient. Depends how you gauge faster. You can definitely refactor code, generate class boilerplate, and other IDE like things faster than me. But I'd be willing to bet that I'm faster at moving around in a file, jumping between files, moving text back and forth between a file and a term/repl, etc than you are. Each tool has it's strengths but I wouldn't say one is 10 times faster than another, maybe 1.5 times at best. 
would you pleas ELI5 profiler?
Just like CORBA, DCOM, OpenDoc or SOM. :)
OP, here is a good site for tutorials and references http://www.tutorialspoint.com/codingground.htm Also, if your serious about learning C++, you cannot easily do it over tutorials and reading code. Which helps yeah but you want a good understanding of the language first. C++ Primer 5th edition best book I've read about C++ in all my years of coding in it. Novice to Advanced takes you through the entire journey. Promise you its not a waste of time.
I mean..I speak and understand and all but I wish there was subtitles in this one..
&gt; I don't want or need autocomplete because i want to actually learn something. This is a bad argument from developers stuck in the '80s. With autocomplete (or, rather, **autosuggest**, as it actually is) you will easily discover a class's API. Should you write a loop over `std::vector` to erase elements or is there a clean and optimal API for that? Just take a second to see what `std::vector` offers, thanks to autosuggest. 
Awesome! [This is the book](http://www.amazon.com/Primer-5th-Edition-Stanley-Lippman/dp/0321714113) right? Doing tutorials was just the very first steps, but I'm interested in learning it in much better detail, thanks a lot!
If you use a boost fusion object instead of a tuple, it can do what you want.
What about the evalution-order ? Because this prints the arguments in reverse order [proof](http://coliru.stacked-crooked.com/a/d85379686b5e91b8) or bug ? 
I always overload operators. Creates a lovely usability for the library/module.
Fair point. I shall think about this once more. 
Nice work, but remember we have c++14 and you don't have to stick to homogeneous tuples, you can mix types and use 'auto' in your lambdas.
Yes, and compiler should to it, so my example could be interpreted by compiler as : auto tuple = std::make_tuple(2,3,"string", 4.6); { auto&amp; elem = std::get&lt;0&gt;(tuple); std::cout &lt;&lt; elem; } { auto&amp; elem = std::get&lt;1&gt;(tuple); std::cout &lt;&lt; elem; } // and so on ... Or even better, there may be template version or for loop: for&lt;2&gt;(auto&amp; elem : tuple){ // use 'for&lt;&gt;' for autodeduction std::cout &lt;&lt; elem; } In this case instead of 'std::begin/end', std::get&lt;&gt; may be used, so you will be able to override std::get for your types, like you usually do for std::begin/end. std::get may became new customization point. 
&gt; Evaluation order of function arguments is unspecified by the standard. Sure, that makes sense then.
zero-based numbering obviously
I can build a car to get me from point A to point B... or I can just use the cars that are already built. The value of integration is that the developer of the IDE has given some thought to the usability of the parts as a whole. Rather than being a collection of disjoint knowledge that a developer has to memorize, you can design an IDE to exploit usability principles and makes accessing those features more easily. Besides, I don't see how you can have something like code completion without it integrated into your editor. (an essential feature that reminds you of existing interfaces and provides you the API documentation at your fingertips). 
If called with a function as well as a list of arguments, it will call the function for each single element of the list of arguments. E.g., for void fun (int i) { std::cout &lt;&lt; i &lt;&lt; "\n"; } for_each_argument (fun, 1, 2, 3); it will call fun (1); fun (2); fun (3); (but as noted in https://www.reddit.com/r/cpp/comments/2tffv3/for_each_argumentsean_parent/cnyrlly not mandated in that order) This is mostly a hacky thing to do as most of the time, you likely know your arguments and can just write that list of function calls manually, but in some cases of metaprogramming, it might be nice to have such a helper function. With the unspecified order of evaluation, a use case is not particularly obvious. The use case Sean described in a follow-up tweet is one not relying on order of evaluation. He has a set of objects he wants to call `.wait()` on, in no particular order and wants to return if all `.wait()` calls have returned. This might be useful for waiting on `std::future`s (results of async operations), where you fire up a load of operations and just want to have them all finish, no matter what comes first.
There are also disadvantages to integration, which we deal with in current IDEs. For example, two issues we see in IDEs today are 1) live syntax errors and Intellisense errors do not always match up precisely with the real errors produced by the compiler in Visual Studio, and 2) the integrated nature of an IDE essentially creates a 'silo' that can keep many other tools or components from being used. These are both examples of the fundamental issue with IDEs; solving the problems with IDEs always requires more integration. The distinct errors between actual compilation and the live reporting are due to the compiler lacking the capability of sufficiently integrating into the IDE to support live errors. Visual Studio's text editing is not sufficiently vim-like for my tastes, and that could be solved by integrating genuine vim directly into VS. The argument against IDEs is not against things working together per se. "integration" in the sense of current IDEs is essentially a 'quick and dirty' way of getting things to work together. The IDE team says they want to support live errors. They can't integrate the compiler so they hack together their own engine, maybe licensing some other parser component that works close enough to to the real compiler most of the time, writing their own semantic analysis and they slap it into the IDE. There are real and valuable benefits to that, in terms of making it easier to produce such tools and providing experience with what sorts of features are useful. Whereas a 'non-integrated' approach relies on components being designed with sufficiently powerful and general interfaces, something which is harder. In fact it wouldn't really have been reasonable to expect the first compiler writers, or perhaps even compiler writers 20 and 30 years ago, to foresee and architect their software as the platforms which modern compilers like clang and and roslyn are being designed as. Basically, IDEs are prototypes that taught us about important use-cases for these kinds of codebases, and now we can design the components better, and produce programming environments that are better architected than current IDEs, including being more loosely coupled. &gt; Besides, I don't see how you can have something like code completion without it integrated into your editor. Well, the editor has to support an interface, but vim and emacs do that. The intelligence does not need to be integrated into the the same program as the editor component, as we can see with the code completion plugins for these editors which shuffle off the responsibility for populating the completion UI to the actual compiler.
I use Visual Studio... mostly because a majority of our software development is C# we use TFS for source control. To be honestly though I feel like the IntelliSense ("autocomplete") for VC++ is complete crap compared to what it is in C#. 
&gt; For example, two issues we see in IDEs today are 1) live syntax errors and Intellisense errors do not always match up precisely with the real errors produced by the compiler in Visual Studio This is only a problem with Visual Studio. Modern languages have a much better grasp of error reporting than the legacy of C++ compilers. Infact, when I use eclipse and java, not only do I get an exhaustive list of compiler errors, I have features that allows for suggested correction of those errors. &gt; the integrated nature of an IDE essentially creates a 'silo' that can keep many other tools or components from being used. Not true. It just requires integrating them. I mean when you start editing a local file, your IDE will automatically check it out for you. You don't get that in your "suite" of manual features. &gt; Visual Studio's text editing is not sufficiently vim-like for my tastes Visual Studio, while a much used example of IDEs, is actually only the second worst IDE among the players. I used VI in university. I can navigate it. I can't be bothered to memorize all the special features that makes me a pro user and VI can't be bothered to teach me/remind me as a good UI should. &gt; The intelligence does not need to be integrated into the the same program as the editor component, as we can see with the code completion plugins for these editors which shuffle off the responsibility for populating the completion UI to the actual compiler. Code completion is not a compiler responsibility. Compilers turn code into assembly/byte code. Your editor is responsible for the presentation of additional information that makes programming more efficient. You really haven't made a case for emac/vi usage. Just better IDE design. (although your goto case of Visual Studio isn't really representative of a good IDE). 
You can get pretty close with generic lambdas: #include &lt;tuple&gt; #include &lt;utility&gt; #include &lt;iostream&gt; #include &lt;type_traits&gt; template&lt;typename F, typename T, size_t...Idx&gt; void doit(F f, T&amp;&amp; t, std::index_sequence&lt;Idx...&gt;) { // C++17 // (... , f(std::get&lt;Idx&gt;(std::forward&lt;T&gt;(t)))); // C++14 workaround const auto _ = { (f(std::get&lt;Idx&gt;(std::forward&lt;T&gt;(t))), 0)... }; (void)_; } template&lt;typename F, typename T&gt; void tuple_for(T &amp;&amp; t, F f) { using size_type = std::tuple_size&lt;typename std::decay&lt;T&gt;::type&gt;; doit(f, std::forward&lt;T&gt;(t), std::make_index_sequence&lt;size_type::value&gt;()); } int main() { auto t = std::make_tuple(1, "2ABC", 3.5); tuple_for(t, [](auto&amp;&amp; x) { std::cout &lt;&lt; x &lt;&lt; std::endl; }); }
npp is pretty cool. I think that you can do a lot with npp and makefiles.
I always wonder why people seem to think overloaded operators are potentially more misleading than any other function. This a + b and this add(a, b) read about the same to me, and if either of them implemented subtraction or multiplication it would be equally surprising. Of course if you use some obscure operator like, say, '&lt;&lt;' to mean 'print', that would not be obvious to someone seeing it for the first time...
Here is what the linked meme says in case it is blocked at your school/work or is unavailable for any reason: #***Yeah That'd Be Great*** &gt;***Post Title:*** *When trying to work with CPP from other languages...* &gt;***Top:*** *YEAH, IF YOU CAN STOP USING INLINE FUNCTIONS IN THE HEADER AND LET COMPILERS ACTUALLY COMPILE THEM* &gt;***Bottom:*** *THAT'D BE GREAT* [Original Link^1](http://imgur.com/zCRtyJX) | [Meme Template^2](http://imgur.com/memegen/create/zCRtyJX)
Compilers do compile them. The code is inserted "inline", if possible. 
Sometime in different language, you can invoke based on the Entry Point aka the Mangled Name for functions in C++ Library. This allows other languages to invoke functions directly from C++ Library natively. Inline make that impossible when there are some critical functions hidden from other language for use.
But, anything which was inlined was almost assuredly not meant to be part of a library API. Also, how are you getting a reference to this inlined function? That is, how do you even know it existed? 
That's a good question that anyone should ask themselves when they think about overloading 'operator+()'. In this case, if we wanted it to return "hello4", we might consider "hello" + 4 add("hello", 4) concat("hello", 4) append("hello", 4) and hopefully decide that `concat` or `append` are better names than `+`, although personally I don't like making appending an integer to a string a single operation like this whether it's a function or `operator+`. My preference would be for something like format("hello{}", 4) In other words, deciding when it makes sense to overload an operator is something that may require some experience to do well. I completely understand if companies or open source projects forbid beginners to overload operators in their code; but as general advice to beginning programmers I don't agree. I think beginning programmers **should** overload operators as much as they want -- you only get good at something by doing it badly first. **EDIT:** I might add that in Python 2.* the example would be: "hello%d" % 4 It's not necessarily obvious what that does if you haven't seen it before, but the resemblance between the format specifier `%d` and the operator `%` makes it easy to remember once you do learn it.
The only time I've found overloading to be particularly useful is in a composition where I want to maintain the interface of the original object. For example, wrapping a vector in a class that stores other information and maintaining the ability to use [] to access elements of the composition, that way the interface is preserved. (And yes, there are other good reasons to use operator overloading)
In every language there are conventions that people follow. Take iteration over items in a container. In Python, you provide an iterator for your containers by making an `__iter__` function which returns something with the `next` function. In C#, you can use `yield return`s and other ugly stuff. C++ just follows a different convention, and in my opinion it works quite well. It tries to treat similar concepts the same. Traditional loops would be indexed by a variable, normally `i`, and was then incremented with `i++`. Very standard, old ways of doing things. When iterators were put into play they copied this syntax and made it so the `next` was just the increment operator. Same goes for functors. Rather than have some convention like .invoke() on an functor, you literally just 'call' the object directly like `myFunctor()`. In any case, it's just convention and you can argue all day about that. Might as well argue about tabs vs spaces or vim vs emacs.
Me too! int add (int lhs, int rhs) { return lhs * rhs; } int x = add( 3, 6); // I am pretty sure this function adds without looking at the code Really, almost every language out there allows for non-alphanumeric methods, function names.[0] Still don't get why only C++ gets bashed, it is just an identifier. [0] With C, JavaScript, Go, Java being the only mainstream exceptions
That is a fantastic example, because it does exactly what operator overloading should be used for: provide a familiar interface to a class that internally may be pretty complex. If you read the the r1 formula, there is no way to misunderstand. 
Please never actually do this (executing a statement inside a conditional) unless you are actively trying to write bad code.
it is a conditional statement, something happens or not, on the condition of the value of n.
Agreed. It is a conditional statement. OP maybe confused at the fact that all bit-wise operators produce conditional statements.
operator overloading is a common practice in the C++ world. Suggesting that operator overloading is almost always bad sounds like someone coming from other languages where this is not allowed. Overloading the callback operator(), for example opened up endless possibilities, so much that in C++11 lambdas were introduced. operator&lt;&lt; and operator&gt;&gt; help readability for streaming objects in or out. For god's sake, I even had a case where overloading "operator," made sense. 
I believe it's the logical operators that usually result in some sort of conditional because of short-circuiting. The bitwise operators don't short-circuit.
&gt; Non-type template parameters in C++ allow [dependent types]. This statement is slightly misleading because, although non-type template parameters *do* allow implementing dependent types, they are not *necessary* to do so. One example of using type parameters (rather than non-type parameters) to encode dependent types is harnessing [Peano axioms](http://en.wikipedia.org/wiki/Peano_axioms). Here’s a [quick’n’dirty, proof-of-concept implementation](https://gist.github.com/klmr/44df12049f4ae141c687). It’s not very useful but it demonstrates that it can be done.
I'm not completely certain, but it looks like there is a use of an unbounded type `T` instead of `decltype(x)` (with perhaps a `std::decay` thrown in).
Way too opinionated to recommend to a beginner IMO. Whether it is true that the other proposed ways of doing concurrency/parallelism are any better or not, using threads is the current reality of doing parallelism in C++, and a newcomer is not going to profit from learning about a technique that might become relevant in 5-10 years.
Because outside of c++, it is ubiquitously understood to be an arithmetic operator with a lot of implications (a + b == b + a). But in c++ it can also be a method call and it matters very much what's on the left and what's on the right. It's syntactic sugar at the cost of throwing thousands of years of established mathematical fundamentals out the window.
I agree 100%, as in my post the point I was making is to preserve the interfaces for whatever type of object your class is. It's the same reason why vectors use brackets just as arrays did, and why iterators can use addition/increment just as pointers do.
No I am afraid I completely disagree. My previous job to this was writing parallel algorithms so I know the domain well. Here's the thing, plain threads to someone who has done a lot of type of work are just as much of code-smell as raw owning pointers; using something like TBB, PPL, ASIO or HPX is like using containers and smart pointers, where as `std::thread` (for most cases) is more like `new` &amp; `delete`, it's extremely easy to get wrong and (if you ever work with the code) incredibly difficult to read code which tries to manage threads on algorithm level.
Whether you think using raw threads is code-smell or not, if you are trying to read and understand real-world code, you will need to understand raw threads, because that's how basically 100% of apps are structured. Also, if you are participating in a team that is writing software, in almost 100% of the cases you will be required to write and understand code that uses raw threading (putting the discussion of whether this is the correct decision by the project manager or not aside.) So learning the basics really well is the thing you should do (and learning something well only comes by practicing it, a lot), rather than trying to gloss over the underlying details by using other libraries, which will leave you in a bad situation once you are trying to contribute to any real project, because you won't have any grasp on what's going on. I could also sing you a song about how e.g. having less state and programming functionally (or even in a functional language) is the best thing ever, but you wouldn't accept "learn haskell rather than C++" as a good recommendation, would you?
Oh okay, i didn't know that he was not recomended, but i can agree now that i have read up on the facts. 
&gt; Because outside of c++, it is ubiquitously understood to be an arithmetic operator with a lot of implications Not really, this is a small list of languages that allow redefining operators, or where operations are just plain function/method calls - Smalltalk - Lisp - Scheme - Ada - Eiffel - C# - Ruby - Python - D - Haskell - OCaml - F# - Scala - Rust - many others as this isn't an exhaustive list So I fail to see why only C++ gets bashed.
Well in the article I was mainly focusing on compile time values, but actually, you can using the visitor pattern something like this: template&lt;class F&gt; void visit(bool b, F f) { if (b) f(tick::true_type()); else f(tick::false_type()); } template&lt;class Tuple&gt; void print_numbers(bool enable, const Tuple&amp; t) { visit(enable, [](auto b) { auto numbers = simple_filter(t, [](auto x) { return b and (is_integral&lt;decltype(x)&gt;() or is_floating_point&lt;decltype(x)&gt;()); }); for_each(numbers, [](auto x) { std::cout &lt;&lt; x &lt;&lt; std::endl; }); }); } However, this may not be feasible for some larger types(like `std::size_t`), but it works well for small ranges of numbers, booleans, and enums(perhaps `char` as well), although a table or switch statement maybe be used instead.
Working as a C++ programmer. Consider myself way above average and I have absolutely no clue what this does. I thought lambdas had to be assigned to a variable....
[8]
Basic usability comes from "Integration" because it's about consistency. A pillarstone of usability is consistency. It's what allows us to make that leap of deduction that what applies to one thing may apply to another. Through experimentation we discover that it does. Integration aligns feature consistency in your tools. Programming is all about usability. Or we'd all be programming in assembly. 
haha. i'm super new to the whole ent life, it felt like a 10. i'm sure i'm gonna look back on this moment in some years and laugh at myself for thinking that but for now, it was the highest i've ever been and it was fun.
What sub am I in again?
C++ dawg. 
Thank you sooooo much, been meaning to look this up and I just came across this, fantastic timing
On my linux I use Sublime Text and g++ in the terminal. On windows I use VS.
&gt; char buf[64]; &gt; memset(buf, 64, '\0'); This isn't traditional initialization. This is non-initialization followed by a memset. Traditionally you'd do this: char buf[64] = {};
Yea, thanks for that I wasn't sure if doing `char buf[64] = {}` would initialize everything to zeros or if it was undefined.
Scalable parallelism isn't about diddling with minor stuff, its really an engineering and application design effort. From my experience there's a couple of levels of "paralellesm" with a huge chasm inbetween the two. Compilers do a fine job of the fist via vectorization, etc. Identifying what type of tasks can be done in parallel (in our case typically on the order of 5s to 20mins per thread) takes care of most of the rest. I find things like openmp sit in the chasm in the middle, every time I've tried to use them I've always seen very measureable performance hits as they just don't scale. I'll also put most things requiring atomics there as well. Find a way to do more work, collect it, scrub it then merge it. Merge time should be several orders of magnitude less than all the other work each thread is doing.
Thanks for the input. The issue of overload matching and a constructor explicitly accepting an initializer list is one I didn't consider before.
You can use it by default, but "everywhere"? **No**. I'd like to do it, but unfortunately, you can't. Any type that takes *brace initializers* as a constructor will assume that's what you're requesting - even if that option is malformed and another constructor is well-formed. Crazy! What that effectively means is that you're pretty safe using it for fundamental types and your own types. For standard library types, always ask - "Could this be a *list*?"
What you are talking about is exactly what my last job concerned itself with. &gt; Compilers do a fine job of the fist via vectorization, etc Especially the Intel compiler; and brilliantly it'll even tell when something could be parallelism (-vec-report). &gt; I find things like openmp sit in the chasm in the middle, &gt; every time I've tried to use them I've always seen very measureable performance hits as they just don't scale. This is normal, that's because OpenMP classic relies on fork join parallelism, this is know now to scale pretty terribly for most use cases. And almost all OpenMP can be done with library solutions (like TBB) rather than language extensions. &gt; Find a way to do more work, collect it, scrub it then merge it. Merge time should be several orders of magnitude less than all the other work each thread is doing. Yes that's a better approach but it should still be done from a high level, like using a parallel reduce or even (for more complex cases) a task dependency scheduler 
Thanks for the input. Could you give me an example of your last point? 
I can't speak for the other languages, but overloading in Haskell can only be done with typeclasses (a sort of interface that defines some behavior), so including it is a bit disingenuous. In order to "overload" + for your new type, you must make your type an instance of the Num typeclass by implementing the following operations: ```(+), (*), abs, signum, fromInteger, (negate or (-))``` So at least in haskell, (+) is understood to be a numerical operator with the implication that the type can also be multiplied, subtracted, negated, has an absolute value, has a sign, an can be converted from an integer. 
&gt; The most I've dealt with are 64 core s That's the most I've dealt with too, on a single node at least. After than I use MPI to control mulitple nodes. &gt; Sadly more of these customers opt for windows over linux which is a poor platform for threading as it hits substantial bottlenecks very quickly that irritatingly must be dealt with. Indeed a problem that plagues us all, customer pay for us to optimise the shit out of our work and then go and stick it on windows. &gt; Judicious use of const correctness is critically important for robustness and debug. I would never dispute that. 
Certainly; containers are mandated by the standard (so available essentially everywhere, with very few exceptions), require no additional libraries, they are a proven technology, they are widely used, and knowing them will give the asker a skill that is useful and will make him/her more attractive on the job market. It is also not a controversial opinion that containers are great to use when appropriate, and the safe choice for the beginner. Hence such a suggestion would be appropriate, and not meet the undesirable criteria I described above.
'integration' and 'developed by a single developer' aren't the same thing. Multiple developers can work on integrated software (e.g., Visual Studio, Eclipse... in fact all major IDEs). And a single developer can write multiple, non-integrated components.
I am currently trying to realize issue https://github.com/nlohmann/json/issues/20 and have a question: When I want to dump the JSON to a string, I need to return for instance "null". For std::string, I can return std::string("null"), but for std::wstring, I need to return std::wstring(L"null"). When I am writing a class where the string type is given with a template (e.g. with the name string_t), then I currently do not find a portable way to write "string_t("null")" - for string_t=std::string, this is find, but for string_t=std::wstring, this does not work. Any idea to realize this?
Braces have several advantages: * They permit value-init. For example, `atomic&lt;int&gt; atom1;` is garbage-inited, but `atomic&lt;int&gt; atom2{};` is value-inited (i.e. zero). * They grant immunity to the Most Vexing Parse. * They forbid narrowing conversions. I haven't decided whether to use braces more frequently, but I'm unusual in that I'm extensively familiar with all forms of initialization, so I can switch between them without fear.
The supply of special characters, especially paired ones, is extremely limited. Parens were used by old initialization, and square brackets were used by arrays (`int x[11];` is an array of 11 garbage-inited ints, so it can't be a single int initialized to 11). That leaves angle brackets, which might work (aside from injected-class-names in class templates), but braces already have initialization connotations thanks to aggregate initialization. Control flow looks different due to indentation, and the fact that it's preceded by a keyword (`if`, `for`, etc.). Even when initialization is spread across multiple lines with indented guts, the end looks different - control flow ends with a lone `}` while initialization ends with `};` (and yeah, so do class definitions, but those are hard to confuse with anything else).
The point is that you are no longer talking about integration.
As an example, `std::vector&lt;int&gt;(10,0)` from C++03 onward will create a vector with **ten** entries, all with the value 0. `std::vector&lt;int&gt;{10,0}` instead creates a vector with those **two** values. It's assuming an initializer list.
Hmm... I think you'll find the similarities are greater than you realize. While Boost can have runtime logic, it also allows for it's parsing logic to be resolved at compile time &amp; optimized by the compiler in much the same fashion as PEGTL. The library is header only and about the same size as PEGTL (just counting the headers, ignoring docs, tests, and examples): PEGTL cbsmith$ find pegtl -type f -print0 | xargs -0 wc | tail -1 4054 15798 122619 total boost csmith$ find spirit/include -type f -print0 | xargs -0 wc | tail -1 4754 12493 192363 total That's actually a bit of an unfair comparison because it isn't just Spirit.Qi, but also includes all of Spirit's "classic" support as well as the Karma library. I haven't compared the two, so I can't say about code generation (and I'd be really curious about that), but I'd love to understand the design differences that would suggest something in PEGTL's favour. I appreciate your candour and your thoughts on this. I'd encourage both projects to learn &amp; understand from each other's work, as there is clearly a lot of overlap.
I hate to say this but that first graph needs lots of work. I really don't know what it is trying to convey. As for visual C++ catching up. LOL 😅😅😅😅😅😅
So many typos T_T
To be fair, I think he is a non-native English speaker. Unless he has misspelled things in which case we must destroy him.
There are typos ("followiong", "Barland C++") and grammar mistakes / misspellings ("that problems", "an euphemism", "an horrible"). I can understand the misspellings for not being English, but I'm sure he could easily correct a few of the typos or even mistakes if he just proof-read the articles he writes.
Well, the other graphs weren't made by him, so...
It's not that hard to read. X-axis: C++x feature, Y-axis: % completion, colour (terrible choices): the specific compiler. It encodes a lot of information. TL;DR: clang, gcc are awesome, the rest are like omg wtf Also I didn't see Borland/Embarcadero on there but from my understanding, they're trying to follow the standard in a big way.
biggest gotcha with lambda in C++, 1. capture a member variable by value. 2. delete the class. 3. use the lambda in a way that access the captured value. 4. crash!!! This bit hard in with gcc 4.7.2. I think compilers should either error out,or produce a warning when capturing member variables by value since the code looks like a variable is being captured by value but the compiler silently transforms the variable capture to capturing "this" pointer.
That is one of the reasons why avoid python / lua for anything complex, I just quite quickly get sick with debugging spelling and type errors. 
Because it's error prone since it doesn't have compiler. Though, python is the only language I could use among scripted ones. Very easy and clean syntax. "I could never write PHP/Perl" is better :p
Well from that list perl doesn't have this particular undeclared variable problem and will give you an error. "use strict".
I like Python for when shell scripts would get too complex. But my tolerance ends when the project size gets over one file. 
Not the same. The perl will give an actual compiler error. As far as I understand it Python only errors when the routine is actually run.
But those are runtime errors.
&gt;Writing safer code in a dynamic language is a skill that takes time to learn! More like a waste of precious life time. Why should I spend thousands of man hours to learn something I get for free from a compiler? (Btw. I don't believe you can really learn to actively avoid typos and brainfarts).