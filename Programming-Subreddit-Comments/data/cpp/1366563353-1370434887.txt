 #define class struct That example code better hope that there's nothing like "template &lt;class T&gt;"...
The issue I find with a lot of standardization by committee is perhaps then that unless a suggestion accommodates every single use case including obscure use cases that hardly anyone uses, then it's rejected. I'm not saying mine is perfect or even good, I don't know, but I do think that lambdas in C++ are incredibly verbose and taxing to read and there is a demand, so to speak, for a short legible lambda syntax. After all, lambdas are just a shorter legible syntax over writing a struct with a callable operator that accommodates a great deal of use cases, same thing can go for deduced parameters, it's just a short form syntax used to accommodate a great deal of use cases, even if it doesn't accommodate every single one of them. &gt;It copies, which is inefficient for std::string. I'm pretty sure the C++ standard allows copies to be eliminated and the use case for terse lambda expressions is such that they're pretty much always inlined and hence the copy can be eliminated. I don't think this is unreasonable either. Lambdas are often expected and assumed to be inlined, so assuming/expecting that copies will be elided is also reasonable. &gt;It copies, which is impossible for unique_ptr. So don't use it with unique_ptr or move only types. Just because the feature doesn't accommodate that 5-10% of use cases doesn't mean the remaining 95% of use cases should be ignored. &gt;It copies, so modifications don't affect the original. Once I again I feel like the majority of parameters passed into a function are such that modifications are not to be made to the original.
&gt; I plan to propose "for (elem : range)" at Chicago (I wanted to for Bristol, but ran out of time), expanding to "for (auto&amp;&amp; elem : range)". That's a really nice idea. I don't see any downsides. Good luck with the proposal.
&gt; For C++ questions, answers, help and advice see r/cpp_questions. I'm not sure how I missed that. I saw EVERYTHING on the sidebar except for that somehow lol. Thanks. I will go subscribe there.
&gt;http://social.msdn.microsoft.com/Forums/en-US/vclanguage/thread/17497297-5fdc-437c-b50c-efee048dd8cb Works correctly in VS 2012.
&gt; It is true that having to specify their parameter types in C++11 is more verbose than desirable. I'm wondering, would you happen to know whether adopting the [Phoenix library](http://www.boost.org/libs/phoenix/) (verbatim?) would even be feasible as a solution to this issue? For instance, take a look at the example from the [Lazy Operators](http://www.boost.org/doc/libs/release/libs/phoenix/doc/html/phoenix/starter_kit/lazy_operators.html) section: std::find_if(begin(c), end(c), arg1 % 2 == 1); This seems significantly less verbose compared to: std::find_if(begin(c), end(c), [](auto x) { return x % 2 == 1; } ); References are allowed using [ref](http://www.boost.org/doc/libs/release/libs/phoenix/doc/html/phoenix/starter_kit/references.html), somewhat akin to std::ref. Are there any downsides?
The problems with library solutions are: * Arguments, especially function pointers, are stored as data members, which optimizers have extreme difficulty seeing through. * Syntax contortions are sometimes necessary because not all operators can be overloaded (e.g. operator dot). * Misuse results in absolutely horrible compiler errors (and I say this as someone who eats templates and drinks compiler errors for a living). Phoenix may be better than the old Boost.Lambda (I haven't looked at it) but these problems are really fundamental to any library solution. This is why lambdas were put into the Core Language despite C++'s preference for library solutions.
Thanks for the reply! Continuing this thread, would adopting this as a core language feature be feasible (analogously to how C++11's lambdas were adopted instead of the library-based BLL)?
&gt;tagged union type Is there anything wrong with struct tagged_union { int flag; union { type1 t1; type2 t2; ... typeN n; }; };
The problem, I think, is really caused by attempting to construct functors from the bottom up (rather than something library-specific). C++11 lambdas construct functors from the top down, like handwritten functors except with less syntax, so they don't suffer the same problems. It *might* be possible to specify a Core Language feature that gives bottom-up construction the same advantages as top-down, but that's beyond my ability to imagine.
You need placement new to call a constructor for one of the types in the union in order to implement the constructor, copy/move constructor, etc.
That is based on a five year old version of GCC.
Headers separate interface fromimplementation meaning your interface is the header and the implementation is how you do it - implementation can be a cpp file, or a pre-compiled object that you link against. What you are proposing can actually be done, but the other way around: just put all your code in the header files :) 
This could work for open-source code. But not for closed source API's. If you use an pre compiled, closed-source API, you won't be able to use it without a header file. I also thing the header files keep the code clean and it makes it easier to program. You can quickly see which functions and variables a file contain in the header file.
A module system is something that people have been after for decades. But I'm afraid it is a much, much harder problem to solve than you might think -- if it were really that easy, somebody would have implemented it. Precompiled headers are the best compromise solution -- and they've been around for decades too -- but they have their own issues and aren't always faster. There's much more to it than just scanning to see what functions are exported. I believe there is a proposal by one of the LLVM developers that will be considered for C++17, but it's far too early to say if anything will come of it. 
work in progress: https://github.com/matthewaveryusa/averyws It's 100% compliant to the RFC, the only trouble is, I'm the only one coding it and it may take some time before I get around the ever-growing todo list. I did run a benchmark against node and python implementations and it's hilariously fast.
Just as a point of comparison, [Here](http://blogs.msdn.com/b/ericlippert/archive/2010/02/04/how-many-passes.aspx) is an interesting article on the C# compilation process. Basically, it boils down to doing a two-pass step over the source text, and that gets it into the AST form that will be used for the rest of compilation. Once in the AST form, it uses many many passes to process the code.
Sure it would work, you just save and give everyone the output of the compilers "first pass." Perhaps save that result, maybe call it a "header" or something.
The compiler having to parse the same header for every translation unit makes compilation much slower, especially with templates. On simple ('normal') toolchains the code for std::string, std::map, std::whatever gets recompiled unecessarily for every translation unit. If you have a large code base this can be seen by the *vast* speedup possible by catenating every source file together with apprpriate headers at the top. This sadly cannot be done automatically because (a) there are per-translation unit scopes which can be violated by this (static, anonymous namspace) and (b) header's don't *necessarily* mean the same thing every time they are included. A decent module system would make compilation faster, not slower.
Templates are a source of one complication. The actual code for a template can only be generated when it is known what types are it is to be instantiated with. So either the translation unit with the code in in needs to be explicitly told what instantiations to make, or the code must be available to all translation units. A related problem is that most compilers (by default) only do optimizations and inlineing within a translation unit. Less stuff in headers means less optimizations!
I always liked Pascal's module implementation - public declarations at the top in the "Interface" segment, with actual code and unit-private declarations below the "implementation" keyword. More importantly, the result was a blazingly fast compiler (Turbo Pascal/Delphi) that didn't need to recompile single code files unless a dependency changed somewhere below.
This has actually been done 15 years ago. IBM's Visual Age 4 Compiler did this. Headerfiles were optional. Obviously you still needed them for Libs and DLLs, but for your normal Non-API code you could just write all your code in cpp files. Another nice thing with this approach was the Compile times. because the compiler stuffed all the needed information in one gigantuan database file the incremental build did took only milliseconds. The IDE had reflected this in that it was class based, not file based. But as you never heard of this it obviously did not catch on. Even though it was totally optional to use this feature and the compilers C++98 was way ahead of Visual Studio 6 nobody used it. I think the main problem was the horrendous RAM requirement. You needed at least 64 mb of ram for it to be usable, better yet 128 mb. this was a time when 32 mb of ram was considered a lot... 
Personally (having programmed in c++ and then switched to java for a class) I enjoyed the separation that c++ allowed. To me it allowed me to control different aspects of the program much more efficiently. 
You can name them anything though. I mean, he could put everything in .cpp files and just include those.
And don't forget that nowadays we have FreePascal (and Lazarus).
That's how I write a lot of my C code, "static inline" on the function body and bob's your uncle. 
What you are looking for is the CLR for .Net. C# for example has no headers.
I was going to make this point as well. For templates to work as they currently do, the code needs to be available at compile time. In op's thought experiment you would only be able to use templates within the same translation unit. I suppose you could do something like serialize the AST of templates into the object file for later instantiation in other translation units. But you would probably want the linker to strip out any leftovers from the final binary.
I wish this distinction was more marked. I would love it if the header files just defined the external class interface, and all implementation details (i.e. anything private) was defined in the source file. This would be neater and faster to compile. The only option for this now is the PImP pattern, which is a little bit clunky.
An important feature that any module system would have to offer is storing something like a serialized representation of the AST of all sufficiently small or explicitly labeled functions so that they can be inlined; this can be a huge win when you have a lot of small functions because not only does it reduce all that overhead from calling them but it often opens up others optimizations such as constant folding that improve the code even more.
So without visibility on the private fields of a class, how would a compiler know how much stack space to allocate for it?
What you are looking for is called module system and exists at least since 1978, with Modula-2 being one of the first languages to introduce this concept. Sadly C and C++ decided for another compilation model that plagues our compilation times. Hopefully C++17 might get modules.
This is my answer: [A fallacy: "Efficiency of static analysis can be estimated by comparing analysis results for the last year's code base release and the current one"](http://www.viva64.com/en/b/0196/#ID0EGPAG)
I think GCC's `-frepo` option does something like that.
Funny how the article makes it quite clear that "next generation" means "we cannot touch a single one of its million lines of code or it could break".
What do you mean by commands? Do you mean the functions/classes definitions and documentation? You can find those here: http://www.cplusplus.com/reference/ http://en.cppreference.com/w/ 
I was told it was called commands so yea I ment those
Is this what you are suggesting? auto lamarck = [](int a, int b){ std::cout &lt;&lt; a &lt;&lt; b; }; register(lamarck); In this case, `lamarck` will *not* be a `function&lt;&gt;` type. Instead, it is a lambda type, and the standard doesn't say much about what the lambda type will be, it can vary from implementation to implementation. The only guarantee is that they can be easily converted to a `function&lt;&gt;` type. Maybe the `register` function isn't very behaved and it's not possible to pass a lambda object to it directly. Maybe it does something stupid and does a C-style cast without checking types properly. If that is the case, then it would be necessary to do something more explicit to force the conversion into the correct type. The goal of the blog, as far as I can see, is to minimize the overhead, allowing: auto lamarck = [](int a, int b){ std::cout &lt;&lt; a &lt;&lt; b; }; register(make_function_from_lambda(lamarck)); or even: register(make_function_from_lambda( [](int a, int b){std::cout &lt;&lt; a &lt;&lt; b; } ));
I'll give you one tip, but otherwise you should **do your own homework**. (In the past, I've taken pity on a beginner, crying [a single tear of liquid C++](http://www.reddit.com/r/cpp/comments/191utf/simple_problems_not_so_obvious_solutions/), but you haven't described putting any effort into this whatsoever.) &gt; generating 10 random numbers from 0 to 500 You want mt19937 and uniform_int_distribution from &lt;random&gt;.
We cannot name a function `register`, as it's a keyword.
Thanks, fixed.
You can forward-declare classes in headers for most cases. So these are all legal in a header: class Foo; //These two work with references and pointers void doSomethingWithFoo(Foo x); Foo FooReturner(); class Bar { Foo&amp; FooReference; Foo* FooPointer; }; You can also define a function that takes/returns a pointer/reference to Foo as long as you do not use the members of Foo. I have no idea when that would be useful, but it's there. Anything else you can't do. That's pretty much everything you would want to do in a header, though.
vim, VS2012, sublime text 2, pycharm, PHPStorm, intellij IDEA, netbeans, pycharm... i think thats all that i personally use
sorry i thought this was in /r/programming not /r/cpp
I prefer VS2008 with VA, but my coworker like to use QtCreator. What is your budget?
What I use: Emacs What I recommend: Code::Blocks What I want: A modernized version of Emacs (without the problems of integration with graphical environments and a modern language for scripting)
Just gave up on Visual Studio 2012. So now, primarily CodeBlocks and MinGW.
In order of personal use: * Sql Server Management Studio (I'm a data whore) * VS2010 (With Reshaper) - C#, VB.Net Asp.Net * Netbeans - PHP with attached debugger * IntelliJ Idea * Eclipse - Toying with Java * N++ - more for copy/paste/regex editing * VIM - command line commando, bash scripting * Powershell IDE - Windows command line 
Microsoft Visual Studio 2012. Though, I'm trying to learn to use Vim.
As a vim user, I second this recommendation for Code::Blocks.
Vim. 
VS2012/2010 Express when developing for Windows app. vi when developing Linux app from Linux env Notepad++ when developing Linux app from Windows.
Aptana for Web Development 
I bounce between vim and Sublime Text 2.
Code::blocks and mingw for strictly c/c++
Visual Studio 2010 for C/C++. Sublime Text 2 and Notepad++ for most other things. I typically avoid Java IDEs because of their horrendous performance.
Usually, vim, Makefiles, and gcc at work. Sometimes VS 2010, when I have to do Windows dev. Sometimes Code::Blocks when I'm working on a project at home, other times I just fall back to vim.
SlickEdit for android c/c++ VisualStudio 2012 for windows c/c++ Eclipse for java of any sort Vim for scripts or quick edits for c/c++ files outside my current workspace 
Netbeans with MinGW 4.7.2. I get all of the C++11 features I need, plus it can switch between Linux/Windows without any hassle.
Sublime and a terminal. On rare occasion Qt IDE.
Real programmers only use vi.
Visual studio 2012. 
gvim
I use n++ with commmand line for compiling, but I only do school related stuff or personal projects
Indians.
emacs
+2
I'm gonna get downvoted for this cuz... not free and all... but Sublime Text. SO worth it. Scripted via python with tons of plugins. I'm a big fan.
/r/WahoosTipi 
QtCreator. It works great for our team with developers coding in both Windows and Mac.
Eclipse and vim, variously. I like Eclipse's semantic hightailing (eg variable/member) and other index-related features. I also like Mylyn, as it integrates with our JIRA instance. I like vim because it doesn't it doesn't require &gt;1GB ram, is faster to use, has keybindings that don't horribly clash with GNOME etc.
Grab vsvim. Really good free vim plugin for visual studio. However nothing bears vimtutor to get your hands on the basics. 
Qt Creator, sometimes Sublime Text when getting to know a new project.
Vim.
Thanks for the suggestion. I'll take a look!
Ever hear of [Notepad++](http://notepad-plus-plus.org/)? Much more optimized for code writing. Plus it's free.
Nearly always just vi or vim. It has the "abuse my keyboard and get so much done" that no other text editor can reproduce. Also, the deterministic output of what you type - as long as you hit the right keys you can be 100% sure of what's going to happen and where you are, so you don't need to see what the text editor made of your input to know what to do next.
vim
This attribute only tells the compiler that the returned pointer is guaranteed to not alias any other pointer in existence (because it's new). You need something reasonably contrived to demonstrate a difference (in a small example). And there is usually little use for this attribute in real-world code. Have you already covered the "pure" attribute, which can be much easier to use? 
Yes, I'm covering pure as well. And const, for that matter. The problem is, as you say, in contriving a small example. I might just end up telling my students what the attribute is *supposed* to do and show them my examples where it doesn't do anything (since that's what *I* have learned in this) :P
You can use GCC to write code?
vim + [ycm](https://github.com/Valloric/YouCompleteMe) + [syntastic](https://github.com/scrooloose/syntastic). does a fantastic job for c/c++ with native semantic code completion based on [clang](http://clang.llvm.org/).
Too bad I could never make its auto-indentation work as I wanted.
Why not 4.8.0?
I've tried a bunch. IIRC, Notepad++ has a tendency to make stuff blink far from the cursor (e.g. change the color of an opening bracket if the cursor is on the corresponding closing backet), which annoys me.
I should have mentioned I'm using [MinGW-TDM](http://tdm-gcc.tdragon.net/). It's almost the same thing, but just provides slightly easier configuration over the regular version.
It's free if you can deal with the occasional "Buy me" popup (only happens on saves, and rarely). Still worth it imo.
I just tested their code sample on g++ 4.7.2 in Windows with -O3. The assembly it generates doesn't even contain the output string, but it does if you remove the attribute. **tl;dr It works, you just have to turn on optimization.**
Visual Studio. There is a free edition available at Microsoft website. It is called Visual Studio Express.
The latest version of MinGW-TDM only ships with version 4.7.2 of GCC. Hopefully they'll update it soon.
I guess you can use the same examples as you use to illustrate other pointer aliasing issues? I.e., the same optimizations can apply. :)
Vim when on Linux. At work we use Visual Studio 2010 and very occasionally VC6(leave this well alone!!)
I use vim because I am used to it. I would say Code::Blocks because it doesn't suck.
Recently vim+tmux. I have used vim quite a bit in the past but I never got around to actually learning anything more than the basics. Now I'm starting to use macros and things like the dot command and ex commands. Being able to touch type seems like it would help (I kind of suck ☹). I ordered a fancy mechanical keyboard with the clicky keys ☺. Also did the remap caps-lock to control, but I haven't gotten into the habit of using it yet (maybe I should unbind regular control and force myself to use it). I recommend the ctrlp plugin, just hit ctrl+p in a nearby directory and type a few letters of the file you are looking for. Makes switching between files much eaiser. Main problem with vim is it's autocomplete kind of sucks (using clang complete currently, looking at YouCompleteMe, but I don't really like the plugins that require configuring and most of the autocomplete ones do although cmake works well with clang by turning on the option to generate compile_commands.json). Refactoring is almost nonexistant for vim. Next I guess I'll look at snipits/templates. Vim will let you build the project within vim :make, but normally I just use anther tmux session. Although invim should let you find errors quickly. qtcreator is fairly good though. Other than that, gedit (there is a Windows version, although it's older).
XCode's actually really good for C++ these days. I remember the first time I saw auto complete working with smart_ptr&lt;&gt; and I felt a great rejoicing inside.
But on their website it says "*the most recent stable release of the GCC toolset*". Tsk tsk! ; )
Visual Studio 2012 with Visual Assist X and a few other free add-ons and Sublime Text 3.
So do I but after a chick check it does seem to come with neither a compiler nor disk partitioning tool. From what I heard emacs should have those included.
Hmm, interesting. I went to take a walk, came home, tried it again, and it works. Of course. Thank you. The interesting bit is that I've had optimization turned on all the time, but I had modified their example slightly so it'd look more like the "high performance scientific computing" that the class is supposed to be about. I *thought* that the changes I made weren't important. Here's the code, from which I produce assembly code with -O0, -O3, and -O3 -DUSE_MALLOC: #include &lt;stdlib.h&gt; #include &lt;stdio.h&gt; #ifdef USE_MALLOC #define MALLOC __attribute__ ((malloc)) #else #define MALLOC #endif float * foo; float ** MALLOC allocate_matrix(const int n) { float * dat = malloc(n*n*sizeof(float)); float ** mat = malloc(n*sizeof(float *)); int i, j; for(i=0; i&lt;n; i++) { mat[i] = &amp;dat[i*n]; } return mat; } int main (int argc, char**args) { int i; const int N = 10000; float ** myMat; float ** myNullMatrix = &amp;foo; *myNullMatrix = NULL; myMat = allocate_matrix(N); // null must still be null, so this is always false if (*myNullMatrix) printf("Should not show up in assembly code"); } 
I have to use Xcode for the osx/ios parts a cross platform piece of code. It crashes ALL THE TIME, the tab system is a joke among other stuff. I dread the days where I have to test some new code and can't let the build system handle apple compiles :/ It does have some nice things over vs, like 'foo is not defined, did you mean FooBar' but I think that's more down to clang compiler
While true only one 'thread' instantiates it, (I am assuming you are using a template singleton class) IIRC the instantiation will always happen in the main thread as the linker places the instance in the data address space (assuming nontrivial initialization). This complicates things if you require the singleton instance be created atomically in a specific thread other than the main thread. 
sublime-text.
Gedit or Notepad++ here. Sublime Text is tight too.
Visual Studios.
Vim? Hah. Emacs? Sheesh. Real men write their code using a blank cdr, a laser pointer, and a steady hand. 
emacs certainly does like to include the kitchen sink ... but it's happier to use your system build of gcc, clang, icc ...
Further to what tamrix suggested, I've found the viEmu plugin to be a little bit better than vsvim (supports more vim movements, seems to be more configurable) - its not free though unfortunately.
CodeLite (a great IDE) KDevelop (impressive) QtCreator (fantastic) Emacs
To program in C++ I pretty much exclusively use Qt Creator because I prefer gcc/clang over VS. This is more of a, I understand the gcc/clang much more than Cl.exe and friends. Also, it's nicer when cross-platform programming.
Eclipse for Java and C++. For C++ in Eclipse I use MinGW for a compiler. I used to use Visual Studio 2005 but stopped coding after college and when I wanted to pick it up again I didn't feel like paying for a new version of Visual Studio or dealing with pirated versions. I was also using Eclipse for Java and it was easy to set up the C++ compiler in it.
vs2012, but i miss the look and feel of 2010 :(
vs2012, and vs2010 before that. I tried code::block found its performance and features to be lacking. I also used bloodshed for ages but that receives no patches so eh...
Well I was on the fence for a while. Visual Studio, Combined with Visual Assist X is really, really nice. Ultimately what turned me off was the compiler, and the debug. The compiler has less intuitive errors/warnings first off. Second it was nice to get away from the .NET dependencies. But I think the main thing was I was regularly having problems with the debug. Things that would debug easily in Codeblocks would be a complete Scooby Doo mystery in VC++. This semester I had a class on Data Structures and Algorithms, and we were working with a lot of recursive functions. I would regularly have to move my code into Codeblocks (the school of course encourages Visual Studio) because VS would go full retard when debugging. Throw the same code into Codeblocks and it would tell me exactly where the error was, and g++ would tell me at least generally what was wrong. VS acted like it didn't even know what to do with how badly I had screwed up.
I've used scite forever I bounce between that and vim. Mostly scite though which is basically notepad with better search and regular expressions.
Fingers? 
That is intended functionality. All the major IDEs do this by default. Many coders (myself included) find that quite helpful, especially when dealing with nested expressions/statements. Especially when dealing with multi-line expressions in LISP (yes, I know this is /r/cpp). Assuming you also indent your code "properly" (meaning indenting nested blocks), this will help you identify any mismatched brackets, parentheses, and braces (which can cause a good deal of pain when trying to figure out where the problem *really* is, rather than where the compiler stopped). Unfortunately, there is no way to turn it off without modifying the c++ language settings.
On Unix systems - vim. Nothing beats it when it comes to code editing. Unfortunately I find ctags and cscope inadequate for code browsing - looking forward to something like ycm to help with that. On Windows, VS 2010 + VsVim. Slow and clunky, but code browsing works great and VsVim is almost good enough to make code editing a good experience.
Visual Studio 2012 Pro @ home Notepad++ @ work
They both look pretty much the same http://i.imgur.com/b4oyKu9.png 
Does anyone know how vsvim compares to viemu?
well everything thats good with vim keybinds to begin with! the first answer in [this](http://stackoverflow.com/questions/1218390/what-is-your-most-productive-shortcut-with-vim ) SO thread is an excellent write up that me and my friends learning vim comes back to over and over again 
emacs. It makes me incredibly productive and I use it for everything. That said, if there were a really killer IDE for C++ I'd be all over it. When I was doing Java, I saw Eclipse (in the early days) and I'd completely switched to using it by the end of the week - the fact that I was quite a bit slower in editing was more than made up by the amazing refactoring tools. As it is, Xcode or VS are somewhat better at locating errors, but much slower for me to edit - I'm constantly having to use the mouse! - so I end up being much faster on emacs. Don't forget - you can run your shells and your telnet sessions and your ftp sessions and edit your directories, both local and remote, in emacs....
What?! I'm a huge emacs fan but AFAIK there's no C++ compiler or disk partitioning tool(!) in emacs, or any editor - why would you want that as part of your editor?!
Could you make your slides or lecture notes available?
Intel just open sourced their openmp implementation under a BSD license: http://www.openmprtl.org/ Clang should be able to take advantage of that.
I know that, but im pretty sure clang has some part in variable replacement suggestion if a variable is undefined. It's a compile error, nothing to do with auto correct. I'm pretty sure using clang though cli would show the same message.
I had to download a theme to get those colours. :( And dont get me started on the menu's being all in caps &gt;_&lt;
there is nothing practical about programming x64 assembly
I'm surprised by the number of sublime text endorsements here. I hadn't even heard of it. What does it have over emacs?
No you don't. It's one of three default themes. :)
Sure, why not: http://www.it.uu.se/edu/course/homepage/hpb/vt13
thanks!
A nice implementation for connecting qt4-signals to boost::function: http://gitorious.org/qtboostintegration Has some minor problems though, but works and should give you a basic idea. Quoting myself: in QtBoostIntegrationBindingObject::bind, you first check for existance using a non-normalized signature before getting the normalized one for further handling. const int signalIndex (sender-&gt;metaObject()-&gt;indexOfSignal (signal + 1)); should be QByteArray signalSignature (sender-&gt;metaObject()-&gt;normalizedSignature (signal)); const int signalIndex (sender-&gt;metaObject()-&gt;indexOfSignal (signalSignature.data() + 1)); where signalSignature is just pulled up from below. (Nevermind the minimally different syntax used.) This also is the case in unbind. This for example allows to write SIGNAL (signal4 (unsigned int,QString)) instead of SIGNAL(signal4(uint,QString)) and also complies to the documentation of QMetaObject::indexOfSignal: "Note that the signal has to be in normalized form, as returned by normalizedSignature()."
Not that shit again.
I think this one is actually the best as far as x86-64 ASM is concerned -- quite possibly better than any available book on the subject (and I don't say this often of on-line tutorials, certainly never found one on C++ that would deserve this characterization). In fact, I found the SSEn &amp; AVX explanations more user-friendly and useful than whatever I could find on intrinsics. 
One note regarding optimization of array access (where you illustrate replacing indexes with pointers): http://www.drdobbs.com/cpp/sometimes-optimizations-cancel-each-othe/240153129 As a suggestion, when you talk about cache optimization, you can mention the processor-memory gap and data-oriented design (a typical example here is AoS vs. SoA, i.e., Array of Structures vs. Structure of Arrays): http://seven-degrees-of-freedom.blogspot.com/2009/10/latency-elephant.html http://software.intel.com/en-us/articles/how-to-manipulate-data-structure-to-optimize-memory-use-on-32-bit-intel-architecture http://www.slideserve.com/maine/array-of-structures-aos-vs-structure-of-arrays-soa [PDF] http://research.scee.net/files/presentations/gcapaustralia09/Pitfalls_of_Object_Oriented_Programming_GCAP_09.pdf (note: you should not think of this merely as a critique of OOP design, but of *any* design that doesn't take the data-orientation into consideration, like ignoring the aforementioned AoS vs. SoA issue) http://gamesfromwithin.com/data-oriented-design A related topic is a twist on "choose good data structures" -- surprisingly often, contiguous arrays will beat lists even with insertions/deletions in the middle (a textbook case of "lists should be good here, no?"), see "Access memory less" @ http://www.stroustrup.com/Software-for-infrastructure.pdf BTW, if you're looking for more literature for your students, I can strongly recommend Agner's optimization manuals: http://www.agner.org/optimize/ 
I use [Geany](http://www.geany.org/). Kind of a poor man's IDE, with syntax highlighting, basic text completion, symbol/function browser, etc. Super fast, tabbed interface, and cross platform (to the extent that GTK+ is, anyway.)
How does one watch videos in youtube? They keep restarting from the beginning due to the youtube player not having enough data after a few minutes.
How is that shit? Templates have significant entry barrier to learn.
It's a repost and was rightfully not received well in /r/programming a few days ago. I personally think that this series has at points poor or misleading wording, but there are more points raised in the original discussion over in /r/programming. 
The mentioned criticism is made of nitpicking on guy's English and how he calls token a bracket. Then the discussion derails into pros and cons of templates and how are they better or worse than macros. There is very little feedback on the actual knowledge passes in the article. Someone who wants to learn template metaprogramming has to start somewhere and until you point out a better source than this, why do you downplay this source? 
Just curious. If I started a book series called "[Something] for Geniuses" would you read that? I think I'd actually prefer that. Haha
Pay attention in class. I'm certain you were given all the information you needed. Don't come here asking people to do your homework for you.
Be sure to come back tomorrow and tell us how you did!
You can skip at least the first ten minutes unless you're really new to C++. Didn't watch the rest due to boredom.
Have to agree, it was uncharacteristically boring and mundane. The title of the video and the contents seem to have a "logical" disconnect. 
I have to say the author of the articles is a bit long winded (eg: "Explicating the new C++ standard (C++0x), and its implementation in VC10" is another title for an article he wrote). That said, if you see past the cruft he makes some interesting points, and covers the basics quite well. 
and your point being?
[The Intelligent Man's Guide to Science](http://en.wikipedia.org/wiki/The_Intelligent_Man%27s_Guide_to_Science), by Isaac Asimov. &gt; Years later, when he was confronted by annoyed feminists who asked why the book was restricted to men, Asimov would claim that the "intelligent man" of the title referred to himself[3] — thus anticipating the title Asimov's Guide to Science adopted for the third edition.
Hey, thanks a lot, this is brilliant! Especially Agner's page, excellent! Hmm, are we really saying that array accesses can be optimized by using pointers? That's not a suggestion that I would make, so I assume it's one of the other teachers. Most of the course material has been created by a series of PhD students, and we're struggling to provide support (i.e. working examples) for all our claims. The SoA vs AoS issue should already be mentioned somewhere. If it isn't, it must've gotten lost somewhere along the way. Hrrm, as you can tell, the course needs a little looking over...
~~With cinder you can add templates to its internal project generator called TinderBox. Wouldn't take much to make an emacs project template.~~ Edit: My mistake, it looks like you can't do it through TinderBox.
so sorry, i forgot i posted this &gt;.&gt; thank you all for the comments though.
my budget is free. lol i am getting kicked out of the army, so i cant afford to buy anything
lol wut? 
eesh who would use return type deduction!? seems like the laziness:obfuscation ratio would be too much. I'm not a huge fan of auto to begin with, although I will admit Herb Sutter is a much smarter man than I. 
First, this belongs into either /r/cpp_questions or /r/learnprogramming. Second, even there you would be hard pressed to find someone that will do your homework for you when you don't show any effort whatsoever on your part.
It's actually quite nice to see support for this kind of type deduction build into the language. Now for the reasoning that code becomes hard to read: auto's current behavior already allows it in some ways, so you have probably seen the effect in code. If it's used here and there to write shorter more elegant code than it's actually quite nice; and after all the type is (has to be) unambiguous, e.g. because you assign the result of a function (type R) to a variable (now also has to be of type R). As always: If you don't like it, you don't have to use it.
Lambda initializers seem kind of lackluster. All the standard algorithms take functors by value, and you can't copy a lambda that captures a non-copyable type. Unless they're changing this, this proposal is much less helpful than it sets out to be.
&gt; seems like the laziness:obfuscation ratio would be too much. I agree 100%. There must be cases (generic programming?) where this is helpful, but for most of us mortals it will mean spending time trying to figure out what exactly a function is returning. 
A network library? That's cool. The more libraries the better. Still hoping for xml/json standard library. 
Currently you often have to copy and paste the entire body of a function into the return type specifier. This is awful and unmaintainable, and the obvious solution is to use a macro to define the functions, which makes already complex code even more obfuscated. This change has the potential to make code that's currently quite hairy *vastly* more readable and understandable. I do think that using auto return types for non-templated functions is rarely if ever going to be a good thing.
Perfect forwarding is a useful concept. Unfortunately, with C++11, there's no other way to do it than this: template &lt;...&gt; auto foo(...) -&gt; decltype(SOME_LONG_EXPRESSION) { return std::forward&lt;...&gt;(SOME_LONG_EXPRESSION); } The same expression is literally copied, and that's the only way to do it without having to fix things up or risk introducing subtle bugs through implicit conversions. This isn't easier to read than the exact same code without the `-&gt; decltype...` bit.
Look up `std::ref`/`std::cref`. :) They capture a reference to an object and give it value semantics. Example: void foo() { auto noncopyable_lambda = [&amp;](){...}; auto constref_to_noncopyable_lambda = std::cref(noncopyable_lambda); std::some_algorithm(..., constref_to_noncopyable_lambda); // success! }
Ah, and my Brain! Those are the two must important tools for writing code: Brain and fingers.
:) thx
With boost.filesystem you can set the global encoding to utf-8 with boost.locale and the encoding-related issues mostly go away. Even ignoring that it's a pretty terrible library, though. The API isn't very good, and the error reporting is awful. It uses platform-specific error codes, so it doesn't actually help in writing portable software. I'll be very disappointed if anything as awful as boost.filesystem makes it into the standard library.
Sometimes it isn't possible - the only way to return a lambda from a function is to wrap it in std::function, which incurs some memory and runtime overhead, or some similar construct. /u/Plorkyeran's comment about repetition in the return type specifier is familiar and also makes my DRY-obsession itch somewhat.. I personally am a massive fan of auto generally; although I hear your laziness/obfuscation concern (I too was sceptical initially) having used it for a commercial project over the last 18 months I now use it profusely. Most of my statements that both declare &amp; initialize some variable use auto without, I think, any loss of clarity. Another big benefit is also the time it often saves much time correcting type names during redesign/refactoring where the types in use are under flux (although this is more common in prototyping where useful typedefs have been omitted).
Do you really believe it makes code less readable? This is a concern for me, as I currently work on an early-days project with 2 others, which will at some point be exposed to the rest of the team (who are currently restricted to C++03). I thought it would harm readability at first, but concluded after a while that the type carries - and I think *should* carry - no meaning relevant to understanding what the code is doing. By cutting out the type names of initialized variables where possible, the code that you must visually parse is reduced. The meaning is much better carried by good variable &amp; function names, IMHO.
Why would you want to copy a lambda that captures non-copyable type? What would it mean? For this facility you would capture by mutable reference. I have a related issue with this though - having a move-only lambda with move-only captured member is great, but std::function's constructor requires the callable object passed in be copy-constructible, unless this has been updated elsewhere...
Had a quick play with the RC the other day and it seems to work pretty well. You just tell it what package you need and it automatically pulls in the headers and libs depending on your configuration (debug, release, x86, x64, whatever). I have been pondering over how it will fit together with existing projects that use CMake or something, since it's pretty heavily geared towards Visual Studio. I haven't really come up with a good answer yet..
Oh yeah btw, a while back I had a unique_ptr I wanted to move into a lambda, then put the lambda on the work queue for a threadpool - without the ability to create a move-only lambda &amp; std::function I ended up having to 'upgrade' it to a shared_ptr, which then propagated through the rest of the system; once it's shared there's no going back. Not a problem per se, but using shared_ptr on something you never need to strictly *share* didn't feel right to me.
So following your line of reasoning, it wouldn't hurt readability if none of the parameters had explicit types listed either? ~~And while we are at it, the types of the variables inside the function body as well?~~ (Actually, now that I think about it, I often program without typing the variables within a function, it's just that I do it in Haskell instead of C++.)
The problem with using auto as a return type is that you either need to document the return type in a comment, in which case all you have done is transferred a part of the documentation from a place where it is machine-checkable to a place where it is not, or you force people to read through *the implementation* in order to learn *the interface*. The function name is *not* a substitute for this information unless there is no way that *anyone unfamiliar with the code* could possibly be mixed up about what type is returned; in fact, a problem with becoming familiar with a code base is that one loses the ability to tell which types are obvious to mentally infer and which are not.
For template functions the following syntax works and I find it more readable than the latter, particularly where the latter is a member function defined out of line. auto sum(auto a, auto b) { return a+b; } template&lt;class T&gt; T sum(T a, T b) { return a+b; } The first one does omit the precondition that requires a and b to be of the same type, however if there is an operator+() for them I think it's unlikely to matter. The generic lambda expressions paper extends the standard to allow the first syntax. Yes for types of variables in the function body as exists now with the type inferred from the initializer: auto answer = 42; // int for (const auto&amp; person : people ) { /* person is const ref to people iterator's value type */ } If there is no initializer then it cannot be inferred, and is invalid, so the language is still statically typed.
Awesome! I'm really excited for better lambdas, convenience functions, syntactic shortcuts, concepts, and modules!
It's not just about adding paths. What happens when you share your project with someone else who has different paths set up? And why not make it easier, even if it is already not that hard? Anything that lets you focus on the actual task rather than the meta tasks around it is good.
As I understand it, the only guarantee that you get from `__attribute__((malloc))` is that the pointer it returns doesn't alias anything. However, it could have modified a global value in the course of producing that unique pointer. (In this case: foo). A situation this might arise is if your `allocate_matrix` implementation was as follows: int matrix_offset = 0; float * allocate_matrix(unsigned n) __attribute__((malloc)) { static float memory[10000]; float *ptr = memory + matrix_offset; matrix_offset += n; return ptr; } Note that the pointer returned will be unique, but a global variable that you could touch from the main function is also modified. I'd also recommend __not__ including the body of the allocate_matrix function when you push it through the compiler to look at the assembly output. Clang for example, optimizes the entire program to `int main() {return 0; }` when it has the body of `allocate_matrix()`. 
Indeed. Very trivial examples.
Compiling C++ to javascript. This seems so backwards, yet as someone who's invested in C++ and would rather not spend time with javascript, I do hope it becomes a standard, mature, "thing"...
Thanks, that makes a lot of sense. But now I'm confused as to why IBM's example does work, how is it different?
I'm still hoping javascript will someday be replaced with something usable...
What's always worked for my teams in the past (very large with lots of short-term seasonal folks) is that we either (a) standardized on a common folder layout or (b) used environment variables. I personally found (b) to be easier for everyone to use. Just put $(FOOBAR) as part of your include path, $(OUTPUTHERE) for the output folder, etc. That way the .sln file is the same for everyone. 
So you can convert JavaScript to C++ and vice versa. Translation party, anyone?
Very enlightening and helps with answering some questions I had about this.
I think the same about this whole thing of trying to use the browser as a VM.
I tried out emscripten just yesterday. It worked very well for the couple of cases I tried, although the size of the output was hilarious. A hello world C++ program compiled to a 2000 line JavaScript file. Another ~700 line C++ program compiled to ~200,000 lines (~5MB) of JavaScript. After minification and compression, this came out to ~650KB, which is usable. But it did work!
Let's start with a simpler example. float * allocate_matrix(unsigned n) __attribute__((malloc)); int main (int argc, char**args) { float *M1 = allocate_matrix(100); float *M2 = allocate_matrix(100); M1[0] = 0; M2[0] = 1; assert(M1[0] == 0); } So, this should work because we know that `M1` and `M2` must point to different addresses (or one or both could be null, but by dereferencing them, we would have caused undefined behavior, so the compiler can ignore that case). Also important to note here. Could the second call to `allocate_matrix()` change where `M1` points to? I don't see any way it could legally do that. --- So, let's look at another case. This time without any mallocs. int main (int argc, char**args) { float V1; float V2; float *M1 = &amp;V1; float *M2 = &amp;V2; M1[0] = 0; M2[0] = 1; assert(M1[0] == 0); } Here, we have a very similar case, except the locations that `M1` and `M2` point to are on the stack, instead of a variable that has a malloc attribute associated with it. Again, the compiler will optimize out the `assert()` because it can interpret that `M1` and `M2` don't alias. ---- The IBM case is a hybrid of both of these. Let's take a look at it. float * allocate_matrix(unsigned n) __attribute__((malloc)); float a; int main() { float *M1 = &amp;a; float *M2 = allocate_matrix(100); M1[0] = 0; M2[0] = 1; assert(M1[0] == 0); } So again, let's look at the rules here. `M2` is not supposed to alias any other pointer on the system, so `M1` and `M2` shouldn't overlap. So we're good again. ---- Let's look at something that fails. float * allocate_matrix(unsigned n) __attribute__((malloc)); float a; int main() { float *M1 = &amp;a; M1[0] = 0; float *M2 = allocate_matrix(100); M2[0] = 1; assert(M1[0] == 0); } This code __will verify the assert at runtime__. What's going on here... So, is it possible that allocate_matrix, while it returns a perfectly sane unaliased pointer, that it increments `a` in the process. That's a perfectly legal operation. And thus, the compiler is not able to optimize that `M1` has not changed. It still does know that `M1 != M2` though. This test case could be even smaller though. A simpler view at what is being tested can be seen here: float * allocate_matrix(unsigned n) __attribute__((malloc)); float a = 0; int main() { allocate_matrix(100); assert(a == 0); } ---- Let's rotate the order of those addresses. float * allocate_matrix(unsigned n) __attribute__((malloc)); float a; int main() { float *M1 = allocate_matrix(100); M1[0] = 0; float *M2 = &amp;a; M2[0] = 1; assert(M1[0] == 0); } Here, we'd really hope that the compiler understands that `M1[0]` hasn't changed. And it can figure that out, and optimizes away the `assert()`. ---- Here's another that __fails to optimize__, although I think this is just the lack of a compiler optimization. I don't see any reason why we couldn't figure out at compile time that `M1` and `M2` don't alias. There may be something I'm missing about `__attribute__((malloc))` in this case though. float * allocate_matrix(unsigned n) __attribute__((malloc)); int main() { float *M1 = allocate_matrix(100); float *M2 = allocate_matrix(100); assert(M1 == NULL || M2 == NULL || M1 != M2); } ---- I was thinking a bit more about some fun edge cases, and this came to mind. Let's take that example that first example that failed to work, and play with it. float * allocate_matrix(unsigned n) __attribute__((malloc)); static float a; int main() { float *M1 = &amp;a; M1[0] = 0; float *M2 = allocate_matrix(100); M2[0] = 1; assert(M1[0] == 0); } The only thing that I've changed, is that `a` is now `static`. Because of this, the code will optimize out the `assert()`. (Remember, that without the `static`, the compiler could not do that). What's going on here? Because `a` is static, and nothing in this compilation unit has exposed the address of it to the outside world, the compiler knows that it can't be modified by `allocate_matrix()`, which is, in my cases, in a separate compilation unit. Well, what would happen if `&amp;a` was visible outside this compilation unit... void touch(float *a); float * allocate_matrix(unsigned n) __attribute__((malloc)); static float a; int main() { touch(&amp;a); float *M1 = &amp;a; M1[0] = 0; float *M2 = allocate_matrix(100); M2[0] = 1; assert(M1[0] == 0); } As you might guess, the compiler __can not optimize__ away the `assert()`. This is because it's once again possible for `allocate_matrix()` to have modified `a`. ---- Here's a final one that I thought was interesting. Let's remember the very first case I showed. It was nice and simple, and it did what we expect. Let's look at a very simple modification that might be surprising. Instead of storing the variables on the stack, let's store them in global scope. float * allocate_matrix(unsigned n) __attribute__((malloc)); float *M1; float *M2; int main() { M1 = allocate_matrix(100); M2 = allocate_matrix(100); M1[0] = 0; M2[0] = 1; assert(M1[0] == 0); } I imagine that you can guess what will happen here, from the previous examples. In this case, the compiler __can not optimize__ the `assert()` away. ---- ---- ---- One final note. I did all my testing on LLVM's clang. I imagine that all of this will also be true for gcc, but I find reading llvm bitcode far easier than reading x86 assembly. $ clang -v Apple LLVM version 4.2 (clang-425.0.27) (based on LLVM 3.2svn) Target: x86_64-apple-darwin12.3.0 Thread model: posix
Quick note as to a bug: http://www.it.uu.se/edu/course/homepage/hpb/vt13/Lect6_Optimization_2013.pdf In the __Side effects on loops__ page, you have the following code: char *str = "Hello World!"; int i; for (i = 0; i &lt; strlen(str); i++) { if (str[i] == '!') str[i] = '?'; } This code invokes undefined behavior because you're modifying a string literal. You should change it to this: char str[] = "Hello World!"; int i; for (i = 0; i &lt; strlen(str); i++) { if (str[i] == '!') str[i] = '?'; } 
The point is to not use std::set, like he does at the beginning. Watch the video to know why.
Clarity, wonderful clarity. I understand the behavior now. Much appreciated! Any other thoughts on the course will be much appreciated. I've been working at updating the material and structure from year to year and there's always more that could be done. Next year I'm hoping to "flip the classroom", if time permits. 
Good catch! I saw that as I taught the lesson and forgot to change it before hitting the upload button. I hope no one actually uses that code, though ;)
This is a good feature but a poor example. It would be simpler and cleaner here to use default parameters, not delegating constructors.
I personally I just like plain old makefiles, but if I wanted something a bit less involved I would probably just use CMake because it is the next most prevalent.
Personally, I think CMake is the least evil of those (but still pretty evil, if you want to do anything it doesn't support out of the box). I also keep an eye on [premake](http://industriousone.com/premake) for future projects.
I'd recommend CMake on all counts. I've used it for many projects in the last 6 years or so, many are cross-platform with tests and dependencies. It's worked fantastically and in my experience it's much better than any of the competition.
The first is indeed a generic function; as I said [the accepted generic lambdas proposal](http://isocpp.org/files/papers/N3649.html) enables that exact syntax for lambdas: auto sum = [](auto a, auto b) { return a+b; } You are correct in saying that all of the variables must have a single, definite type, and auto does not change that (i.e. C++ is still statically typed). Auto infers exactly 1 definite type. The parameters in the above function have no *fixed* type, which is exactly why it is a generic function, so the types are inferred when the function is *instantiated* just like with a template function. Compare the equivalent template function that supports 2 different parameter types with a potential 3rd result type: template&lt; class T, class U, class R = decltype( std::declval&lt;T&gt;() + std::declval&lt;U&gt;() ) &gt; R sum( T a, U b ) { return a + b; } This template function has no definite types until it is instantiated either. I'm not trying to force you to prefer the former syntax; I personally prefer it, and am just trying to show it works fine without loss of specificity of meaning, and a function with the former syntax can be shown to be equivalent to some template function. My prior examples were contrived of course; I'd post some real-world code, but I'm at home. I'll drop some when I'm at work next week if there's anything suitable. &gt; ...on the other hand it is often a good idea to explicitly write out the type because it acts as an assertion that the value has the type that you are expecting; this becomes more useful the more that you encode invariants into the types so that the invariants become machine-checkable, which is the major strength of having a static type system in the first place. I think this is where our preferences differ; by allowing yourself to drop expectations of 'the type' of an object and focus on its 'concept' (e.g. iterator, pointer, sequence container) I think you end up writing more generic, less brittle code: auto pConn = connectionCache.get(); // obtain some pointer type to connection Now it doesn't matter whether the connection cache returns a raw pointer, unique_ptr, shared_ptr, 3rd party or custom smart pointer, or whether that changes in the future as long as our expectations of the operations supported by the returned object continue to be met. The idea is similar to duck typing, but with maintenance of the safety afforded by static typing - exactly the model we get with C++ templates. 
Hell yes to those, particularly modules. I'm a little hazy on their details as it's been ages since I looked through a paper on them, but they look very much like a massive leap forward in a rather medieval aspect of C++ development :-)
Is CMake really more prevalent than Autotools these days? How things have changed...
Maybe I missed it, but that looks like a cross platform utility library, not a build system..?
Wow this will save me a few minutes every year! Awesome!
Autotools! It's a de facto standard, difficult to set up, but once done it works **everywhere**.
Like a lot of others, I'd have to say CMake is the least of all current evils. In any of these build systems, if you require custom steps, there will be some pain. However, the prevalence of CMake, the size of the community and their contributions, and the overall comprehensiveness of the system means that it's probably the best solution you're likely to find.
&gt; The first is indeed a generic function I tried compiling it in C++11 mode using Clang and it didn't work, so your claim is false, unless you are making up syntax.
I agree with you, however, I might see a few Unit Testing gurus in my office shitting a brick or two. 
The only notable omissions I can think of are [gyp](https://code.google.com/p/gyp/) and [ninja](http://martine.github.io/ninja/). Both were developed to be used together by google for chromium, and gyp(Generate your projects) is used in v8 and node.js as well. Gyp itself is a fairly spartan set of python scripts. I was able to move glfw over to it for a small project simply by reading the node/chromium config files, so it isn't too complicated. Gyp's primary purpose is to create your xcodeproj/makefile/sln/ninjafile/whatever. Unfortunately, outside the chromium/v8 world it's hardly used. Ninja on the other hand is a direct alternative to make, with the big selling point being ridiculously fast incremental builds in large projects. Compared to make it is very bare-bones, instead expecting the complexity to exist in the tool that generates its files (CMake or gyp). Note that it is also primarily intended for Unix-ish environments, with windows still having only preliminary support. From the ninja manual: &gt; For Chrome (~30k source files), Ninja reduced no-op builds from around 15 seconds to under one second. &gt;A Mozilla developer compares build systems: "While chromium’s full build is 2.15x slower than firefox’s, a no-op build is 78.2x faster! That is really noticeable during development. No incremental build of firefox can be faster than 57.9s, which means that in practice almost all of them will be over a minute." 
But does your code work **everywhere**?
Just wanted to say: good luck to you. There's a quite intentional gap in my knowledge in this area. I'm really hoping that the new module stuff that the clang/llvm guys are working on takes off and totally eliminates the need for stuff like autotools once and for all.
I prefer [premake](http://industriousone.com/premake): instead of rolling its own scripting language it embeds Lua, which is great. It is simple, easily extensible and just works.
Hey now everyone, I am as much an autotools hater as the next guy but I would have hoped that this subreddit people contained the kind of people who would reply to someone proposing a tool that they don't like with an argument as to why it is a bad choice, rather than just lazily giving them downvotes to signal their displeasure for even *daring* to bring up one of the most used build systems out there.
It looks cool, but unlike say, CMake, it doesn't come with "batteries included" for a lot of the major packages.
Including Windows?
I've never had a problem using it under msys or cygwin. But autotools is even easier to use if you cross-compile to Windows from a sane OS :)
+1 for waf. I've found it to be fast for large codebases. It's usually well documented, and has an active user community for the cases where documentation fails.
[Here is my favorite page for interop info](http://www.pinvoke.net/)
I would love to hear a better one if someone has one. :-) 
&lt;sigh&gt; No gcross I am not making up syntax, and you appear to have missed the intent of the post, as well as the relevant parts I have clearly pointed out to you. This is "Overview &amp; code samples of changes accepted for C++14", so unless you have a compiler that already implements the accepted changes **that will be standardised in 2014**(which if any does then Clang is a good bet) then no, you can't compile it yet.
About time!
I suggest CMake + ninja + gold linker
Er... Emacs. That is all. 
There is also an /r/gcc. It is very small. But I hope to attract more readers, enthusiasts, and gcc developers. http://www.reddit.com/r/gcc/comments/1cqoq9/support_for_colorizing_diagnostics_in_gcc_49/
emacs has already own c compiler?
The competition between GCC and LLVM/Clang has been great. I think one more large-scale, open-source compiler for C/C++ would be good, but I’ll take what I can get.
Protip: [colorgcc](http://schlueters.de/colorgcc.html)
Finally!
Latest release was June 2010.
In addition, they wrote decltype(auto) with a straight face!
Microsoft should be sued for giving C++ such a bad name. Many people, especially managers and newbies, think C++ is a very bad language thanks to all the boilerplate code COM requires. 
He probably mean that when you compile from within Emacs, gcc output is already colorized. I guess the same is true for other gcc IDEs. The new feature is mostly useful for people who compile from a terminal window.
http://www.open64.net/ , don't know the status of it as of today though.
You can already do this using some sed magic to inject ANSI escape codes. To get "error" to stand out in bold red and "warning" in bold magenta, pipe your GCC output through this command: gcc main.c 2&gt;&amp;1 | sed -r 's%error%\x1b[31;1m&amp;\x1b[0m%g; s%warning%\x1b[35;1m&amp;\x1b[0m%g' For other colors and ANSI codes, refer to [this](http://en.wikipedia.org/wiki/ANSI_escape_code#Colors).
It is a joke about Emacs. It has so many tools that they are creating fully operational shell with: email, irc, ftp clients or file manager, and somewhere there is text editor.
/r/vim 
/r/vim 
An "operating system" is just a name you give for everything you left out of your editor.
I am just using qt-creator for a non-Qt simple project. It builds in windows, linux and mac os x without problem using the very same .pro file
Just like in 1970!
CMake + ninja = win
Already submitted 13 days ago ..
In my experience so far, on Windows you have Visual Studio and Everything Else. If you're not using Visual Studio then everything is hard work. And - if you are using Visual Studio then you've got the problem that you're using Visual Studio... (Which I know some people like, but I've never got on with personally)
It is nice to see LLVM/CLANG putting a little pressure on the GCC guys. 
Have you ever done any CORBA? If that is the case then the OMG guys should be sued before.
Nope, I have not. Is it cumbersome?
Holy hell, mate!
I'd guess because, those who need this, already use a type of gc (Android NDK does f.e.), and that the compiler site implementation is just not done due to lack of resources/actual need. Also with shared/unique_ptr C++ goes a different approach in memory management, based on RAII and without the need to ever directly allocate resources (make_shared/make_unique).
VC has implemented the library hooks as no-ops, which is permitted by the Standard.
Right. But why add it to the standard when there was apparently no intention by *any* compiler vendor to implement it? As far as I can see (on a cursory reading) these hooks could just as well be supplied by a third-party library and the only wording that is actually required in the standard concerns traceability of pointers.
Oh god here comes another nudge nudge winky winky smiley :) UNIX propeller head. At least you said "Windows" and not "Windoze". But admit it, you still do say "M$" instead of "Microsoft", don't you. *SAY IT!* I get so sick of this "sane OS :) " crowd. Your shit stinks just as bad and you know it. 
One of the nice things about being an STL maintainer is that I just have to do what the Standard says, I don't have to think about the rationale if I don't want to. :-&gt;
What the hell is that supposed to mean? Or is that supposed to demonstrate an error?
P.S. Read this else if (A == &amp;inbound) str = "inbound"; else if (A == &amp;outbound) str = "outbound"; as else if (A == &amp;inbound) str = "inbound"; else if (A == &amp;inbound) str = "outbound"; I will correct a typo in this article tomorrow.
I wonder when SDL 2.0 will be released
Cool article. I read this comment first and was thoroughly confused because it looked so wrong :).
It's either boilerplate or non-standard extensions. (Which is actually what C++/CX is - nonstandard extensions to C++ to provide syntactic sugar over COM)
May is the supposed release month according to the forums... but I am not holding my breath.
Especially now that it has backing from Valve. At least it's not SDL 3.0...
Microsoft Xbox 360 samples are a terrible mess. They've been out for years and people are still finding bugs in them. Shameful.
Took it long enough.
Yeah these kinds of mistakes have nothing really to do with drivers or windows 8 specifically.
It does look interesting. Can any users comment on their experience with this library? Pros/cons? Ease of use? Is it worth learning or do you believe you know of a better alternative? What alternatives are there/how do those alternatives compare?
I'll admit I did just skim the article, but I think the gripe is that these bugs are in the sample drivers MS is publishing for windows 8 driver developers. The author seems to think driver developers won't catch them and will just copy pasta them into their own drivers. 
At GDC he said that SDL 2 was ready, he just needs to get around to packaging it up and making it official. Valve themselves have been using 2.0
General changes: https://github.com/LaurentGomila/SFML/wiki/FAQ#wiki-grl-changes http://en.sfml-dev.org/forums/index.php?topic=5343.0 Detailed list (commits): https://github.com/LaurentGomila/SFML/commits/master HTH :-) 
It's sad that Microsoft C++ code still looks like this after almost 30 years of having a Windows API. I thought by now Herb Sutter would've at least gotten them all to stop using Hungarian notation, but apparently not: _Inout_updates_bytes_(iBuffSize) LPSTR szBuff No. Just. No.
It's catchier than "The Windows 8 driver examples are full of bugs" :)
Yeah, the title could have been a skosh more accurate. :)
I find Andrey's blog posts very interesting but they're also ads, so that might be why catchiness won out. I don't think it's a bad title, though.
Hungarian notation is considered legacy in Microsoft documentation. Their best practices documents state to use it just for Win32 compatibility when required.
It is likelier that the drivers are buggy because they are immature and/or some dev introduced a bug along the way, not because of bad documentation. If I had a nickel for every time I saw a new network card driver with a huge memory leak (on any platform)...
When it comes to build systems, I have a bias against scripts that create build scripts. Personally, I really like waf. Its just python, so its portable. It can be included as one file with your source, and supports all of your criteria. 
I am using 2.0 RC from some time. It works like a charm, but the sound part with openAL seems somewhat buggy. Not for SFML itself but for openAL IMHO
I once thought C++ needed GC, but I no longer think so. In fact, one of the main reasons for using C++ is predictability of behaviour due to control of resource allocation, and GC will utterly destroy that. 
I don't see the need for GC in C++ either, it's just strange to me that it was accepted as part of the standard and yet Clang and GCC seemed to have ignored it as of their most recent releases. The status of GCC 4.8 even shows that every other C++11 feature has been adopted, except for GC: http://gcc.gnu.org/gcc-4.8/cxx0x_status.html
I don't think that yet another build program is a good idea. Scons does almost everything you're asking for and could fill in the blanks with a pretty simple scons script (scons uses Python), so why not do that instead?
You want 'make', but instead of it being one of the most retardedly, mouth breathingly, simple programs out there, you want it simpler? Am I reading you correctly? 
Give me a makefile that is platform/compiler independend and automatically manages dependencies based on #includes and is no longer than a few lines for a small project, and I am happy.
I use CMake on windows and linux. I use it to build static libraries, shared libraries, and executables of all my stuff. CMake has its own unit testing, but I link to google test instead and that is easy too. I haven't used static checks. I've dabbled with CPack for making packages. I can't comment on the others except makefiles. I prefer cmake atm.
&gt;Provide a functionality to only recompile files that have been changed or their include files have been changed (or everything if a compile flag or the compiler has changed) I've also been thinking about this. Something like the way git keeps track of what files have been modified would be nice.
There is already a module system for C++ in the works that should fix most problems with link flags, all you would need then is a trivial makefile to only recompile files on change.
I don't know all the features of scons, on first look it looks fairly verbose (which is not perfect, but ok). But if I understand it correctly, the build scripts are written in python. That means that if you standardize it, any implementer of that standard will have to be able to parse and run python, which looks like overkill to me.
Scons is incredibly simple for simple projects: Program('program', Glob('*.cpp')) ...will compile all .cpp files in the current directory into an executable called 'program'. It automatically tracks new changes across individual files and their include dependencies, and not just by file size or date, it can do a CRC of every file. It has a method to setup include, paths, defines and input and output extensions irrespective of the actual compiler. You can easily do an 'if debug:' in the script. Isn't that exactly what you wanted? It can also be as complicated as you like for complicated projects. Parsing and running python is not exactly a big deal for someone who's trying to compile a C++ program. Your answers so far sound like your mind is made up that the wheel needs to be reinvented and your simplistic view of project compilation is enforcing this. Here is an example of what we do in our system. How would we do this with yours? We have a number of defined platforms for which the code can be compiled. On compilation, the platform is specified. Any source files which contain a platform name that is not the one we are compiling for are ignored. So on Win32, any files that contain Linux, Android, &lt;whatever&gt; will be ignored. On Linux, Win32, Android, iOS and so on will be ignored. This allows us to have platform-specific classes without the unnecessary overhead of inheritance and allows the resultant object instantiation code to be much simpler.
No, that looks simple enough. The features you list sound really nice. So you think this is general enough to become part of ISO C++, so that compiler vendors include it with their software?
&gt; And all this bullshit just because one company can't accept that they chose the wrong Unicode encoding. To be fair, essentially every API or environment developed back then made the same mistake; Windows, Java, Cocoa, ICU, AIX, etc. The problem isn't so much the use of UTF-16 as it is the refusal to adequately support UTF-8. Windows is in a bit of a hard place here because of the way they supported UTF-16; Looking at the detailed wording of the C++ spec, using UTF-16 for wchar_t is arguably conformant as long as they never do something like support a UTF-8 locale.
One thing that makes moving to C++ painful is that C++ is not great for making libraries that are expected to be used by other languages via an FFI. It can be done but it's fairly painful and error prone compared to using C.
just a tip: don't read the comments.
It has been ignored because GC is incompatible with the language design so far in all practical ways.
I have to disagree with you there. Writing a C-interoperable library in C++ is *equivalent* to writing a library in C. It's not more painful or error-prone than that (in fact, the implementation side will likely benefit from the extra features of C++, while headers are unaffected aside from extra `extern "C"` declarations).
Agreed...If I read that tired old Linus quote one more time...
&gt; You know how some people require Java 7 or Python 2.7 or Ruby 1.9 for their code? Is that list supposed to be of new versions of languages? Python is well into 3.x!
Yeah but that's missing the point. Sure if all you care about is being technically correct, yes you're right, you can use C++ to write a C library by only using the subset of C++ that's valid C code. If you look at the intent of this post, which is making use of C++ in terms of things like classes, RAII, the use of C++'s standard libraries, perhaps using things like exceptions, so on so forth... then it's a huge pain to make sure your library can be used by foreign function interfaces on many other platforms like Java, Python, and even used by other C++ compilers from other vendors. C has the benefit of having an ABI that is pretty easy and straight forward to standardize across compilers and configurations. With C++, doing so much as changing a single compiler flag can result in inconsistencies across libraries. Usually people write the API in C, and then provide a C++ wrapper over it or wrappers in other languages. It is possible to write the API in C++ and then find a way to expose it in C or other languages, but doing so is very error prone because if you accidentally have any C++ specific feature leak out via the C API you enter into undefined behavior territory. To see the extreme lengths that library writers go to in order to do this, look at how Qt does it and the pain they go through to provide as much binary compatibility as possible as well as the extreme lengths they went to to provide wrappers for Java and Python, wrappers which in many cases don't even work properly. They had to forgo making use of the C++ standard library, they don't use any exceptions, their classes are declared both within namespaces as well as outside of namespaces because of name mangling inconsistencies, their classes make use the pimpl idiom, and they do some other tricks which require a great deal of maintenance and care.
&gt; yes you're right, you can use C++ to write a C library by only using the subset of C++ that's valid C code. That's not what he is saying. What he is saying is that you write the library in C++ using all the funky features you want and then write a C API wrapper around that C++ library. Thus you get a C-ABI, but can still use all the C++ you want internally, you just have to make sure they don't leak out.
The problem is you can't use all the funky C++ features you want because those C++ features don't have any way to be exposed via C. I understand what he's saying, you write your class in C++ like so: class SomeClass { public: SomeClass(const char* name); void Method(int someParameter); }; And then you expose it in C via something like this (sort of pseudocode): extern "C" { struct SomeClass; struct SomeClass* MakeSomeClass(const char* name); void FreeSomeClass(struct SomeClass* self); void SomeClassMethod(struct SomeClass* self, int someParameter); } And then behind the scenes you implement that wrapper by making the C++ calls. What I'm saying is that it's waaaaay easier said than done, incredibly error prone, and realistically unless your library is fairly simple and you're pretty well versed in all the ways that C++ can leak through the C/C++ boundary you're probably better off just sticking to using C. The tiny subset of C++ you will be able to safely use will not justify the increase in complexity of wrapping your API so that it can be used in C. Remember, none of the C++ classes can be exposed via your API, so your API can not make use of std::string, or any of the STL containers, and if you use anything you better make sure you handle all exceptions because exceptions that leak through C++ and into C doesn't result in a crash, it's simply undefined behavior. That means if something unexpectedly throws an exception you have no idea what the consequence will be. It's not as simple as just wrapping things with an extern "C" and bingo bango.
There are still several large projects that use Python 2. Upgrading just hasn't been worth anyone's time yet. 
Handles, names, and void pointers are common ways to pass objects in and out of C-style interfaces, but you discount the possibility of not having any sort of object-oriented concepts in your API at all. There is no reason why you shouldn't present an interface that is purely in a C mindset, but use the full power of objects, template meta-programming, lambdas, etc to achieve those results.
&gt; Peter, just wondering is possible that google go would be a good language choice today to create a new database programme? Umm...
I think it is a good move. Ability to use namespaces, stronger type checking and automatic memory management alone are already worth it.
Question: what if you have an object that is not owned by anyone in particular, but is shared between objects, and you don't want to involve the upper scope to deal with its instantiation, because it is not its concern?
Haha seriously... the author's entire reason to switch to C++ is because it seems to have wider adoption than C now. And some commenter thought it would be a brilliant idea to suggest a language that nobody uses?
That's what [`std::shared_ptr`](http://en.cppreference.com/w/cpp/memory/shared_ptr) (or [`boost::shared_ptr`](http://www.boost.org/doc/libs/1_53_0/libs/smart_ptr/shared_ptr.htm)) are there for.
Yes, but these use heap-allocated instantiation. The point of the article is to keep instantiation on the stack.
So the dev team got skilled enough to consider adopting C++ as a new tool.
then use the singleton pattern edit: I wrote some code out to show how. It's not safe but it proves the point: http://pastebin.com/a8e8jXwV
An awful lot of well-designed software, in any language, but let's say C, uses object oriented design anyway. That is to say: object oriented programs don't have to be written in object oriented languages. C++ is the language I reach for out of choice; and I find writing object oriented programs is helped a lot with an object oriented language -- you get a lot more compile time checks and some good syntax that you otherwise end up emulating with #defines and type-casts. The Linux kernel in particular screams "object oriented". If your software is already like this, then the conversion will be easier than otherwise. However, if it's already like that, you have to ask -- "why bother?", which is the argument (when they aren't blinded by language religion) of the Linux developers. I have no idea if PostgreSQL is the same, I've not looked at its code base; but don't imagine that conversion would be a small job. And given its size, it's likely that they've already written a lot of the object oriented goodies in their own code-base anyway.
Or, use thread local storage.
I'm not sure I understand. If the object is allocated on the stack, then wouldn't the stack frame that allocated the object ultimately own it? Once he goes away, the party is over for anyone else trying to share that object. If you do want sharing independent of the creator of the object, then you have to move it to heap or global storage; it can't live on the stack.
you can have the object in the stack, and a pointer to it on the heap.
&gt; in fact, they should contact me about job opportunities Looking to [outsource][1] your job, hmmm? [1]: http://articles.latimes.com/2013/jan/17/business/la-fi-mo-man-outsourced-job-to-china-20130117
You're correct that a C++ API cannot be used directly as a C API. But that's not a requirement. A C API for a C++ library is *equal to* a C API for a C library — i.e., it's not harder to write a C API calling C++ code than it is to write a regular C library. If you demand that all classes be represented 1-to-1, then you will inevitably run into type bridging issues (such as converting between a C string representation and a C++ one), but that's the case with any library that doesn't use basic C types for everything.
As I tried to repeat, it really is harder to write a C API using C++ code, and I've tried to provide actual examples in practice of why that is. It is harder because there's a great deal more that needs to be considered than syntactic implications, but rather the run time implications in terms of dependencies and run time behavior which can leak out of the C++ 'boundary' so to speak and result in undefined behavior. I never said it was impossible or no one can do it, I said that it's a pain and something that needs careful consideration which in many, if not most cases, ends up causing more headaches than the advantages of using C++ strictly for implementation purposes.
Nice presentation! But I did not like the slide transition effects =p
Very nice presentation! (But the same slide transition style... Which I found very disruptive)
Yeah, I was actually searching for the way to disable this. Found [this](http://community.prezi.com/prezi/topics/simple_switch_from_slide_to_slide_without_any_animation_zooming_twisting): "you can speed up the transition between path steps by rapidly hitting the forward arrow key twice on your keyboard. " ~~A natural idea was to press it thrice -- it worked! :-)~~ // EDIT: nope, that's a bit too fast and skips slides :-( 
I think you are missing the context of these posts. &gt; well then, std::move(f) To quote esbio (emphasis mine): &gt;&gt; Question: what if you have an object that is not owned by anyone in particular, but is **shared between objects**... std::move achieves the opposite of sharing. Anyone who keeps a pointer to the object after a move won't be pointing to the data they want. If instead they each make a copy to avoid this problem, the object is no longer actually being shared. &gt; and if you want it globally available move it to a singleton. To again quote esbio (emphasis mine): &gt;&gt; The point of the article is to keep instantiation on the **stack**. Typically a singleton won't use the stack for storage, but will ultimately use global storage (or maybe I should say static storage or static duration, I forget the official term), which I already noted as an alternative. If you do manage to create a singleton that uses the stack, you still have all the potential pitfalls my posts have been bringing up. My posts intend to point out the problems with esbio's desire to achieve both of these things at the same time (that is, stack allocated objects with a shared lifetime) to help esbio think through the issues with his request, or to get clarification if I misunderstood him. Personally, I agree with grunzl; if he wants shared lifetimes, he wants a shared_ptr. If he wants it to be stack allocated, than he doesn't want shared lifetimes, he wants the function that created the object to own the lifetime and he needs to make sure any outstanding references/pointers are no longer used after this function exits. Though they are a solution, I would avoid singletons. I prefer global const variables (if it really does need to be global) or explicitly passing arguments to whoever needs it rather than globally accessible mutable instances.
yeah the whole transition thing makes it hard to use - any chance to have them removed? Edit: double tap your arrows to make transitions faster...
well, whatever it is he wants isn't idiomatic in c++. if he wants to share its a shared ptr. if he wants clustered memory then he can use a custom buffered allocator whose size was predefined at compile time or newed at the beginning of the application like this : https://raw.github.com/matthewaveryusa/averyws/master/lib/utilities_buffered_allocator.hpp
Agreed. The animations looked fancy at first, but got very annoying quickly.
Oh, I'm not the author (just a mere submitter), but thanks anyways, I've enjoyed the content, too :-)
std::vector&lt;float&gt; is probably a good start.
&gt; the default access specifier if none is specified is *private* for class, and *public* for struct It's worth mentioning, especially in an article about inheritance, that the default access specifier also applies to inheritance. That is, this class CTestBase { public: int _iA; int _iB; }; class CTestDerived : public CTestBase { public: int _iC; int _iD; }; is exactly equivalent to this struct CTestBase { int _iA; int _iB; }; struct CTestDerived : CTestBase // public inheritance { int _iC; int _iD; }; and, of course, to this class CTestBase { public: int _iA; int _iB; }; struct CTestDerived : CTestBase { int _iC; int _iD; }; If in any of the cases above the subclass declaration instead was class CTestDerived : CTestBase // private inheritance then the base class' members would be private within the subclass. Separately, I recommend against starting any identifier with an underscore, including member variables. Such identifiers may be reserved and I find it difficult to remember [the rules](http://stackoverflow.com/questions/228783/what-are-the-rules-about-using-an-underscore-in-a-c-identifier) about when it is and isn't okay, especially when considering the C and POSIX standards as well. The post does not violate any of the rules, but it is not a big leap for one unfamiliar with them to make a seemingly small change and unknowingly use a reserved word. It's simply easier to not do it all. Aside from the technical reason, there is little value added from the prefix underscore and some (arguably minor) drawback, namely that all members now have longer names that start with the same character, which increases typing and reduces the effectiveness of autocomplete. If you really want a visual indicator that a variable is a member (and using `this-&gt;` or `.` is insufficient or undesirable) then a trailing underscore will work just fine without having any of the issues mentioned. I'm also not a fan of the systems hungarian notation used here due to its lack of semantic information. The `i` prefix to indicate an integer is really just noise and has the same drawback as a leading underscore when it comes to autocomplete. And what happens if I change its type to a `long`, for example? I'd have to refactor the variable name everywhere its used even though it serves the same purpose. Seems to me for the purposes of this post that `a`, `b`, `c`, and `d` would have been enough. Lastly, because it's a pet peeve of mine, "C/C++" is not a language. C and C++ are vastly different languages with some commonalities and have very different styles and practices. This article doesn't even apply to C because the concept of inheritance isn't in the language. Presenting them as if they're the same is wrong, in my opinion, even when discussing their common aspects. C has some in common with several other languages too. You don't see people talking about "C/C#" or "C/Java". If you want to present concepts in C++, fine, go ahead. You can even mention some aspects work the same in C. But pick a language and stick with it. If you're using Visual Studio, pick C++; it's a pretty poor C compiler. Saying "C/C++" is just being lazy. Edit: typo
You can't be serious. Visual Basic for Applications is the only valid choice here, really.
For Windows development, BUILD (http://www.buildwindows.com/) tends to have quite a few C++ talks, specially with the new focus in native code. GDC (http://www.gdceurope.com/) also enjoys C++ related talks. Advanced Developers Conference zu native C++ (http://adcpp.de/) if you happen to be in Germany and are German speaker. C++Now 2013 (http://www.eventbrite.com/event/2717332615?ref=ecount#), the former Boost conference. 
You can follow [here](http://isocpp.org/blog/category/events) upcoming events. 
Attendance is limited to 64 people. &lt;--- not really a conference, more like a gathering of elitist douches
oof, abuse of auto may lead to code that is difficult to read and maintain. Will have to see about lambdas. For now I view them as a convenient way to inline 1 line adapters and replace the impossible to remember binder calls.
Well, I'm obviously biased, but [Meeting C++](http://www.meetingcpp.com) will be very good if you are from Europe. Call for Papers lasts 10 more days, so schedule will be there in June. ADC: Been there last year, good conference for german speakers, especially if you're interested in the Microsoft world. C++Now: Sold out this year, very good, afaik best conference. But its a full week. 
well, they scaled down the attendance, to focus on the few who could make it. Also this has always been a very premium like conference. Content is ofc premium with those 3 titans of C++ too.
Developers of languages with automatic type inference don't seem to be have problems with them since a few decades. It keeps surprising me that auto is such a big issue for C++ developers.
I gave up. Too annoying presentation. The content should be the focus, not fancy ways to use the graphics card.
Update: [PDF] https://dl.dropboxusercontent.com/u/38495654/presentations/kcdc-13-modern-cxx-language.pdf [PDF] https://dl.dropboxusercontent.com/u/38495654/presentations/kcdc-13-modern-cxx-library.pdf 
Update: [PDF] https://dl.dropboxusercontent.com/u/38495654/presentations/kcdc-13-modern-cxx-language.pdf [PDF] https://dl.dropboxusercontent.com/u/38495654/presentations/kcdc-13-modern-cxx-library.pdf 
Update: [PDF] https://dl.dropboxusercontent.com/u/38495654/presentations/kcdc-13-modern-cxx-language.pdf [PDF] https://dl.dropboxusercontent.com/u/38495654/presentations/kcdc-13-modern-cxx-library.pdf 
large code bases that require a good level of verifiability, especially scientific applications.
&gt; Developers of languages with automatic type inference don't seem to be have problems with them since a few decades. Don't know about that - I've worked with C# for a couple of years and found *var* to be pretty problematic. Don't see why *auto* would be any different.
&gt; The code was running on a machine without a profiler This is about the same time I would install a profiler.
Doesn't support Windows Phone 8.
I regularly use valgrind (callgrind), and occasionally gprof. On Windows I sometimes use the VSTS Profiler, but I mostly just use Very Sleepy. If I had to choose a favorite, I would say my least unfavorite of them would be callgrind with KCachegrind. callgrind is quite detailed and accurate, and KCachegrind is pretty powerful, and has all the bells and whistles you would expect (and is still usable).
Well, that indeed is a 180 degree turn from the C++11 "sequential consistency all the things!" approach to atomics. The author has obviously thought long and hard... Just I'm not seeing the benefit of starting with relaxed memory order and *then* adding the fences over starting sequentially consistent and progressively relaxing your algorithm/implementation. If one is doing this kind of low-level work, they're most certainly carefully using the appropriate memory orders already, no? In the case they are not, how is this better?
Most languages don't have expression templates and compile-time type manipulation that can totally screw up with auto.
Many scientific applications in research areas make use of ML languages.
By "some experience" - do you mean working in teams with multiple contributors on big code bases? I didn't have any problem with type inference in SML, but I've only used the language for very small tasks and never within a team.
Thanks, resubmitting!
What a mess.
My ML experience is with small teams (2 - 3 persons) I do however have experience in C# projects done with 50+ developers, across three development sites, where *var* was used everywhere. Not a big deal. When in doubt a mouse hover was enough to know which type it was, and the variables did have sensible names.
I think that's a bit harsh, even though I generally agree with everything you've said. I think he provides some valuable information for someone wanting to learn a bit about the implementation of inheritance (I also like that he brought in a little assembly). The only thing that really strikes me as dangerous is the leading underscore.
&gt; I make a novel suggestion: don't use it I didn't - others did, and I had no way to stop them. 
People can abuse any language feature. `auto` is perhaps the least abusive language feature you can hammer on. If `auto` is the biggest source of gripe about C++11, then I'd say you're lucky to have pretty minor issues with your codebase. Most of this quibble is resolved through a good IDE. If your IDE doesn't give you type information of functions and variables when you ask for it (eg, like Eclipse CDT, Visual Studio, and Qt Creator do), then find a better IDE.
&gt; auto is perhaps the least abusive language feature you can hammer on On the contrary. Except for some rare use cases of generic programming, auto is nothing but trouble and the fact that you need an IDE as a workaround is just one more proof for that.
&gt; When in doubt a mouse hover was enough to know which type it was So, we should make C++ dependent on an IDE, like Smalltalk? Even in that case, an IDE doesn't help with articles or books.
Perhaps it was. I intended to end my little rant with "other than that, good content", but clearly forgot by the time I reached the end of the tirade :).
Well the language is already dependent on tools if you want to assure that you are writing code that doesn't blow in strange ways. Are you aware of Visual Age for C++? They created a DB representation of the project to speed up compilation times. Another IDE dependency example for C++. As for articles and books, it is up to the author to ensure the readers understand the message he/she is trying to pass.
link doesn't work :(
Moved (honestly don't know why): * http://herbsutter.com/2013/05/04/guru-of-the-week-and-the-exceptional-c-series/ * http://herbsutter.com/2013/05/06/gotw-1-variable-initialization-or-is-it-310/
I see Nigel Tufnel wrote that article.
I remember reading or seeing a presentation on the topic of perfect forwarding and std::forward. But could someone please remind me about why the template parameter of std::forward cannot be infered? Because, in my opinion, it would be neat if this worked: auto forwardingLambda = [](auto&amp;&amp; param) { f(std::forward(param)); }; Edit: This "enhanced" forward would need to detect on the inside if param was declared an rvalue reference. But since it is a variable, it is an lvalue, no matter the declared type. So since the declared type of param is unknown to forward and cannot be made known to it without spelling it out, there is no way of knowing if a move would be legal or not. This is why std::move can live without it: it just assumes a move is always legal and forces the type to rvalue-reference no matter what. Note that std::forward internally does the same: it promotes everything always to rvalue reference, but the return type of it will force the type back to lvalue reference if an lvalue reference type was passed in as template argument (using reference collaps rules). All that said, of course you could still do a define: #define better_forward(param) std::forward&lt;decltype(param)&gt;(param) auto forwardingLambda = [](auto&amp;&amp; param) { f(better_forward(param)); }; Still, it's quite sad that only the preprocessor is capable of doing this. Would be nice if C++ would be enhanced to cope with this.
Doesn't a pure virtual function point to null anyway?
&gt; could someone please remind me about why the template parameter of std::forward cannot be infered? I believe that `std::forward` is deliberately written to prevent template argument deduction from being possible, because it would not work properly if that happened. As you point out, the crucial part of perfect forwarding is being able to differentiate between having been passed an rvalue or lvalue. And that's possible only in conjunction with the special magic combination of having a function argument of `T&amp;&amp; arg` and then doing `static_cast&lt;T&amp;&amp;&gt;(arg)`. That T from the argument has to be explicitly passed on down to the `static_cast`, it can't be deduced from `arg`, because that is how the lvalue/rvalue information is captured.
Consider the following three definitions: int x0 = ...; int &amp;x1 = ...; int &amp;&amp;x2 = ...; All three of these will seem 100% identical in the rest of the program. Nothing, *except decltype()*, can see the difference between them. You're right that param is an l-value in that context. Also, the type of param is useful because it will be either `&amp;` or `&amp;&amp;` depending on whether or not the lambda was called with an r-value. Therefore, we can use this *type* information to infer the *value* category and do forwarding accordingly. But the frustrating thing is that the only thing that can see the difference between them is `decltype`, and therefore we must use it. This is probably a good 'problem' though. In C++, a reference really is supposed to be equivalent to the thing it is referencing. If there were obvious differences between `int&amp;` and `int`, then this would break this ideal.
Evil macros safe the day ... ;-) #define FORWARD(x) ::std::forward&lt;decltype(x)&gt;(x)
Would it have been impossible to have perfect forwarding automatically?
Shit the ascii arts kind of messed up but I am basically just trying make every row with out put move its position to the left. I only have the first row moving. HELP!
Also, N is in int main(), to replace double p with a user input.
Not an iostream user myself, but I would strongly suspect moving the cursor before printing the image would only work for the first line. The newline between each line will reset the X value to 0, not the X value you provide at the start. Savvy? What you could do to fix it is to add an argument to the draw image routine to set a per line prefix length. Each line would print out prefix_count spaces, then that lines' data and newline. 
Its platform specific, but in UNIX and probably Mac OS you might be able to trap the signal (Probably SIGQUIT) and perform some actions. Here's some info on catching signals: http://www.thegeekstuff.com/2012/03/catch-signals-sample-c-code/
Trapping the correct signals is probably the right approach. You can also create a memdisk and write to a file on said memdisk (and fflush() the FILE pointer, or alternatively set the buffer to null with `setbuf(myfilepointer, NULL);`), which will not have much overhead. But the simplest will be to implement a signal handler for termination signals (SIGTERM, SIGKILL, SIGABRT) and just print the last two numbers, and their index, so that your output is something like f7 13 f8 21 and just redirect the output to a file, like so ./fib &gt; result The relevant code for `fib` would be something like #include&lt;stdio.h&gt; #include&lt;signal.h&gt; void handler( int signal_nr ) { switch( signal_nr ) { case SIGABRT: case SIGKILL: case SIGTERM: printf("f%l %s f%l %s\n", first_idx, first_nr, second_id, second_nr ); default: } } int main() { if( signal( SIGTERM, handler ) != SIG_ERR &amp;&amp; signal( SIGKILL, handler) != SIG_ERR &amp;&amp; signal( SIGABRT, handler) != SIG_ERR ) { /* FIBONACCI STUFF */ } else { fprintf(stderr, "Can't link signal handler!\n"); return 1; } return 0; } I wrote the above from memory and I don't have a compiler handy, so it will likely not work. It's there to give you an idea as to what to do.
Forgive me I'm new to this but what would be the "signal" , would it be a control c or a kill command or something else?
A CTRL-C would signal SIGINT (interrupt). You can send signals to processes with the un-aptly named `kill`-command: kill -SIGTERM 1234 will send `SIGTERM` to process 1234. Combining all this, your cron job should look like the line I gave you above, and then you can have a second cron job that runs kill -SIGTERM `pidof fibonacci` or something like this.
Start your fib program, and have your cron command suspend it with something like "kill -s SIGTTIN \`pidof fib\`". This is like sending Control+Z in an interactive terminal. You can resume it similarly, "kill -s SIGCONT \`pidof fib\`". You don't have to change anything about your program.
 killall -TSTP fib killall -CONT fib
These kinds of questions should always include the current results, as well as the desired results. A very quick and simple look at the code reveals 1) You are comparing an int(i) to a double(p + 5). 2) You never update j(infinite loop). 3) The condition you have on the while loop is always true(infinite loop). 4) Seeding the random number generator with a constant at the beginning of this function means you will always produce the same sequence of random numbers(this may be by design). 5) The way you have stated the problem is extremely unclear, I have at least 3 interpretations. It will be hard for people to help. 6) It seems you are having trouble with even just the logic/problem solving part of programming, C++ may not be the correct language for you at this time.
Thanks for the subreddit suggestion; I literally just put /r/cpp and found this. Thanks for the input, ill try to implement it. 
Be extremely careful with signal handlers, you are very limited on what you can do inside a signal handler, see http://pubs.opengroup.org/onlinepubs/009696899/functions/xsh_chap02_04.html#tag_02_04 The safest thing to do is just set a sigatomic_t variable and regularly poll that. Trying to use "printf" inside a signal handler can cause your application to deadlock (as the signal handle might have interrupted another I/O function holding some lock).
Another option I was thinking about was creating an argument in the program called STOP. This would just create a second instance of his program that runs that stays up while there are two instances of the fib program. The first would constantly check for the presence of a second program and when it detects it goes into a shutdown function. Once the fib STOP sees only itself it exits.
I don't see any problem in his code. The return cannot happen until all local objects in the scope are destroyed, and the exception is thrown when this is being done. There is no "return flow" interrupted. 
That's not the problem. It's perfectly legal (though often a questionable design choice) to throw an exception from a destructor. 
&gt; ~fail() { &gt; throw 1; &gt; } How fitting :) Disclaimer: I didnt read whole article.
I don't even get what this is about. Generating C++ from XML?
I know its been 14 years and probably no one cares about this any more. Just the actual algorithm for the falling characters turned out to be pretty small, so I decided to post it.
I really like auto for expression templates. auto e = (_1 * val&lt;2&gt;) / _2; looks a lot better than expr&lt;div, expr&lt;mul, _1, val&lt;2&gt; &gt;, _2&gt; e = (_1 * val&lt;2&gt;) / _2;
I liked it!, thanks for posting
How about string find_addr( const list&lt;employee&gt;&amp; emps, const string&amp; name ) { auto e = find(begin(emps), end(emps), name); if (e != end(emps)) return i-&gt;addr; return ""; } I'm not sure if I preserved the operational semantics here, or if string{""} is different than string{}.
God, C++ is the worst.
[What's keeping you here, then?](http://www.youtube.com/watch?v=IAQfglRyPlM&amp;t=7s)
[Are you sure?](http://en.wikipedia.org/wiki/COBOL)
I wish std::vector&lt;int&gt; v{1,3} std::vector&lt;int&gt; v(1,3) were more visibly different. Sure I can tweak my font, but this just looks like a future sore-point.
As someone who has always wanted to get into C++ development, are there any static code analysis tools that would help expose these type of issues? Preferably something open source or at least priced within reach for personal use?
You have to delete [] what you new [] ! * http://www.parashift.com/c++-faq-lite/delete-array-built-ins.html * http://www.parashift.com/c++-faq-lite/delete-array.html 
This is a bit nit-picky, but I can't help but point out this example could be resolved by changing: void scale(vector&lt;double&gt;&amp; v, const double&amp; x) to: void scale(vector&lt;double&gt;&amp; v, const double x) Or even: void scale(vector&lt;double&gt;&amp; v, double x) Yes, this would be bad practice with almost anything other than primitive scalar types, but in this case they are just that.
That's the whole point with the post, though, isn't it? Using a reference was a bad idea. What bothers me about this series of posts is that I can't fathom making this mistake. Who in the (C++) world worries about the performance cost of copying a single scalar value? The situations where I try to avoid copies is when passing large-ish structs or arrays to a function, and references are what people expect in those situations anyway, so there is no clarity problem. Is there?
Yes. If that *is* the point of this article, I can't imagine why it was published. Anecdotally speaking, I have never seen code where scalars ate passed by const reference. In this context, the issues I see are always vectors and large objects passed by value.
*Of course* that is the point of the article. Is it that hard to image an more "realistic" example? void append(std::vector&lt;std::string&gt;&amp; v, std::string const&amp; s) { for (auto&amp; e : v) e += s; } std::vector&lt;std::string&gt; v = {"One", "Two", "Three"}; append(v, v[0]); In short: aliasing is a non-trivial problem.
Or, for an even less obvious aliasing issue, introduce a template: template&lt;typename Container, typename Value&gt; void append(Container&amp; c, Value const&amp; v) { for (auto&amp;&amp; e : c) e += v; } std::vector&lt;std::string&gt; v = {"One", "Two", "Three"}; append(v, v[0]); It's not always even obvious when you might have an aliasing problem.
There are two basic ways of analyzing cache misses: (1) time different access patterns. (2) Use CPU Performance Counters. Intel VTune will do this. As will the 'perf' tool on linux. You can also try perfmon/pfmon: http://perfmon2.sourceforge.net/pfmon_usersguide.html#intro What do you mean read-only memory in registers? A register is like its own variable, a copy of data. It doesn't matter if the data came from read-only/read-write memory. Are you talking about 'const' values? Generally, if you have a choice on making a variable const and not making it const, you should make it const. 
To be perfectly honest you still lost me at "code generation." The "Hello World" of Generative Programming sure would help. I tried to look at one of the PDFs you link to but it gets past page 25 without a clear and succinct explanation.
The question about read-only &amp; read-write memory I think comes from reading about GPU programming. I recall something about it being important. I have vector of structs. My algorithm traverses over the vector reading some fields of the struct and writing to others. I'm wondering if it would be any more efficient if I spilt my vector up into two; one for read-only data, and the other write-only. 
To elaborate, I think generic programming has a perfectly clear one sentence definition: Reduce algorithms and inputs to the minimum type/property requirements possible. Is there such a sentence for "generative" programming?
I made the change and I did get some performance gains. I think it's because the algorithm traverses the vector sequentially, but writes to elements in a random order (i.e. the reads are sequential, but the writes are randomly distributed over the vector). So removing the parts written to to another vector improved the performance, because the write vector is much smaller and can stay in the cache. That's my guess, anyway.
I think this tool may be relying on the fact that most #include&lt;&gt; directives generally include standard headers and there is little you could or would want to do about the standard library. I supposed there is no reason other headers could not be included with &lt;&gt;, but I have never seen it in production code.
Maybe try [PAPI](http://icl.cs.utk.edu/papi/) if you want to analyze a certain part of your code, like a particular loop. You can even restart counters and print statistics for different iterations. I haven't used VTune, but if you have access to it, I think it gives you a lot more counters.
If it's the same CPU core, then write in whatever order you want. For reading, you want to minimize the time you're waiting for cache-lines to read in. The first part of that is minimizing the number of cache-lines you read from: pack as much data into contiguous 64-byte blocks as possible. The second part is to use the CPU's cache-line prefetcher as much as possible. Read cache-lines according to a linear function (of address), and the CPU will start fetching those lines in earlier. Some more information: http://www.agner.org/optimize/
Let me ask a bigger question - what overall goal are you trying to accomplish? If you haven't finished the program yet, you shouldn't be fiddling with this stuff at all. Both algorithms have the same O() and a similar time constant - pick the one that's easiest to get 100% right. Once you have a fully-working program that isn't working fast enough, then profile it and see which parts needed tuning. It probably won't be this part. I almost guarantee you that your time would be better spent elsewhere than on this problem - assuming you aren't just experimenting on vectors but have some larger game plan you're trying to achieve. 
[Cachegrind](http://valgrind.org/docs/manual/cg-manual.html), part of the excellent valgrind tools, will give you statistics on cache misses and where they occur in your code. It's fairly slow though (since it basically emulates an x86 processor)
My Uni course contained a module specifically about threading and cache-efficient programming, so doing things like accessing arrays height x width (so for instance if you have a 2d array your for loops would be for height, for width) thus you are accessing contiguous memory, which allows for cache hits. Not entirely sure about your actually query, just throwing some of the shit I know out there.
Somewhat fitting here: Maybe have a look at the load-hit-store problem, strict aliasing and the restrict keyword. I think [this article](http://cellperformance.beyond3d.com/articles/2006/05/demystifying-the-restrict-keyword.html) is a nice introduction.
Regarding constant memory in the GPGPU context, it's a form of cache. Compare slides "CPU Memory Hierarchy" and "GPU Memory Hierarchy": https://www.math.umass.edu/~johnston/CUDA_WG_2012/memory_hierarchy_lec2-2x2.pdf // Regarding constant memory, note: "Only 64KB of constant memory, but big benefit is that each SM has a 8KB cache" // Also gives this pretty good reference: http://lwn.net/Articles/252125/ See also “CPU-style” memory hierarchy and “GPU-style” memory hierarchy in the following: http://www.cs.cmu.edu/afs/cs/academic/class/15869-f11/www/lectures/08_mem_hierarchy.pdf 
Passing by reference can actually be slower, except for the bigger types. Even if you have a structure with up to 16 bytes, it is better to pass this by value. (I'm sure I read a blog post with a load of experiments on this, but can't find any.) Passing a reference to a really small value just wastes memory. Your cache then has to store the reference and the values, and it has to be paranoid about making changes. With most smallish values, it's better to pass by value because the compiler can just put them directly into registers and everything is just simpler and faster.
Yeah i have been looking into this for a little bit now, generic code description seems to have potential for code optimization by eliminating unnecessary branches and malloc() calls, by keep the code on the stack and triggering as few os interrupts as possible it offers the potential for good performance... I feel that this is a lot closer to what C++ would be if it was burdened by it's C backwards compatibility, minus say the markup (at least outside of 'modules' :), just that generic 'constructive system' such as there is no 'int' so much as there is a int&lt;class size&gt; where size is proportional to the requirements of said int; this is just one of many possibilities. 
Would be cool if you could see the right answer if you wanted. Edit: I also have no idea what the difference between unspecified and undefined is.
* https://github.com/knatten/cppquiz/issues/6 * http://c2.com/cgi/wiki?UnspecifiedBehavior HTH :-)
Not just export the answers, but have a button on the webpage that shows you the right answer.
All good questions, I'd say, since they're exactly the same to the ones I've been asking myself (and in many cases still am)! :-) *// I can especially relate to the Hello-World-should-appear-before-20something-pages sentiment :-) // For instance, the thesis itself applies generative programming in the development of the Generative Matrix Computation Library (GMCL), but that's pretty much the opposite of a "simple Hello World"...* I think a one-sentence definition would be: "programming that concentrates on solving software engineering problems in families instead of one at a time." Note how the generalization of generic programming falls out of this definition, too: in this case "problems" are algorithms (and implementations thereof), while "families" are organized over the requirements on type(s), including the choice of data-structures. [Boost.Spirit](http://www.boost.org/libs/spirit/doc/html/spirit/introduction.html) is a (relatively) well-known case, where you're able to generate generic parsers (instead of being provided solely with a library of generic parsers--which would be the case of applying generic programming itself). Typical libraries to achieve this goal would also be Boost.Proto and Boost.MPL. Another example would be NT2 (using, among others, Boost.Proto): http://www.slideshare.net/joelfalcou/designing-architectureaware-library-using-boostproto OpenMesh library also mentions relying on generative programming for implementation: http://www.openmesh.org/Daily-Builds/Doc/ http://www.graphics.rwth-aachen.de/media/papers/openmesh1.pdf http://openmesh.org/Documentation/OpenMesh-2.3-Documentation/mesh_cpp.html Some more examples: http://www.twonine.co.uk/articles/GenProgGoesLive.pdf https://www.lri.fr/~falcou/pub/falcou-boost-con09.pdf http://repository.readscheme.org/ftp/papers/topps/D-434.pdf 
Could you modify the drop-down so that the meaning of unspecified and undefined is more clear? Question 26, for example, stumped me for a moment because the program is clearly both compilable and deterministic (namely: deterministically undefined). On reflection it became clear what the drop-down is really for, but I think options like: "compilable, deterministic result" "compilable, undefined result" et cetera would make this clearer.
You're talking about the division by zero one? Undefined behavior is never deterministic. Just because it happens to be the case that most implementations will raise some kind of signal or fault doesn't mean that is required. It could launch nethack or format your hard drive.
No I'm taking about ambiguity in the parsing of the drop-down. I'm aware of this, but I on quick inspection considered the drop-down to consist of four disjunct options, i.e. "compiles and is deterministic" as one option, and "doesn't compile and ..." as three options. As the example compiles, and in all cases results in undefined behaviour, I automatically jumped to that option and was confused as to what output was expected.
Very cool, but given you mention C++11, I wish you had mentioned the C++11 way of getting around the most-vexing-parse (using curly braces) in the Expert question as well. I got the Expert question before the other question where you do mention it. http://herbsutter.com/2013/05/09/gotw-1-solution/
On the question where: #include &lt;iostream&gt; int main() { static int a; std::cout &lt;&lt; a; } In the answer explanation you say that the output would not be 0 when you remove the static keyboard. When I tried removing the static keyword a is still being initialized to its default value of 0.
It may happen to have a value of 0 when you run it, but it isn't guaranteed to.
http://stackoverflow.com/questions/11962457/why-is-using-an-uninitialized-variable-undefined-behavior-in-c
Where are the answers?
How do they ensure this is compiler agnostic?
Presuming all compilers are standards-compliant in all corner cases :-) I'm sure I could break the crap out of ancient GCCs, suncc, HP aCC, IBM xlC, MIPSpro cc, Compaq CC etc. Because they're all super relevant today. (Edit: I'm not sure what my point is.)
I've noticed, but it's still annoying and makes no sense. Asking beginners expert questions will only cause frustration, as the expert ones are really difficult. The opposite is also true, and while it indeed takes just a few minutes overall to answer the beginner questions, it's still wasted time. This attitude is exactly what the defenders of spam were saying in 1990's (If you don't like, don't read it) and I like to think that nobody thinks this way anymore.
It's a planned feature. I am prioritizing getting more questions in the database first though, so that you get a decent selection of questions even when you choose just one level.
Several people have pointed out that there should be some way to see the answer if you give up on a question. I will implement this.
Several people have pointed out that there should be some way to see the answer if you give up on a question. I will implement this.
I will rewrite question 13 (and 14 I think it is) which has to do with the order of initialization of non-local static variables. Since stdout itself is a static, it is not guaranteed to be initialized before I start using it in those questions. So I have to find some other way to demonstrate this. Any ideas are welcome! :)
Good idea! What do you think about this explanation? http://cppquiz.org/quiz/question/31?result=CE&amp;answer=&amp;did_answer=Answer
Cool, I didn't know! There seems to be some confusion in that thread though, I checked the standard and made a clarifying comment to http://stackoverflow.com/a/8784923/7084
Thanks! That's what I'm trying to avoid. Which means things are progressing somewhat slowly... :)
Where's the drop down option to "beat the original programmer with a hose"? Seriously, we don't get to do that often enough IRL.
There should be a question right there on the front page. If you don't see a question, could you please post a screenshot together with the url you are using, so I could look into it?
Here ya go. http://i.imgur.com/t5tMSI7.png
you need to go to the root domain (http://cppquiz.org) to see the questions. I'm not sure why the submitted link is to the about page if there's no clear link to the actual questions on that page.
If you had a visible link on the page that would be better ("This quiz is available here", for example).
int main() { int i = std::numeric_limits&lt;int&gt;::max(); std::cout &lt;&lt; ++i &lt;&lt; std::endl; } this returns -2147483648, it isn't undefined. Unless I'm following the wrong standard, I think the quiz got this question wrong! (Too lazy to make a github account)
Good idea. I just never thought of that someone would land somewhere else than on the front page. Just click on the header to get to the front page.
What do you mean it returns -2147483648? Do you mean _your_ compiler returns that, or the standard says it should? This is a big difference, as compilers are only obligated to comply with cases that are defined by the standard. In undefined behaviour, they can do whatever they want. This is very important to be aware of, as you might have code that relies on for instance signed integer overflow wraparound, but in the next version your compiler has instead decided to launch ballistic killer kittens.
Help wanted! The quiz has been live for a few weeks, and it's become clear that I could use some help. -Take the quiz! Let me know if anything is wrong, unclear, uses incorrect terminology (please be pedantic) etc. -Contribute your own questions: Click "Create your own" in the right hand menu -Suggest questions: If you don't want to create the full question yourself, just suggest a short suggestion, and I will make a full question of it -Help me write new features. It's all Python/Django/Javascript, and available on GitHub at https://github.com/knatten/cppquiz . A number of ideas for new features are available at https://github.com/knatten/cppquiz/issues?state=open -Improve the design (as you can see, I'm not a designer) -Suggest other ways you or others can help I am happy to take any questions/feedback here, as GitHub issues (or even better, pull requests), on Twitter or whatever really.
You should try to make your vector access sequential, then you'll have to worry less about caching issues. Splitting the vector into two might help if updates are conditional and happen only very rarely, but it will usually be a loss.
The question is absolutely correct -- signed integer overflow is undefined behavior. Just because your particular compiler decided to generate code that causes it to wrap around does not mean anything. Undefined behavior means that all bets are off and there's no way to reason about what the code might or might not do. You can't answer a question about undefined behavior by examining the output of what any compiler does -- it's a question about the language specification. If you want a more vivid demonstration, the following results in an infinite loop under some versions of gcc: for(int i = 1; i &gt; 0; i++) ; 
Cheers. I got them all right except for an embarrassing void* / std::string overload failure. [Question 15](http://cppquiz.org/quiz/question/15) gave me pause as well, but got it right first time. What I especially like is that it's an actual test of language knowledge, rather than just common 'gotchas'.
Thanks for your feedback! I'll look into making the naming more consistent. I am however going to continue using one-letter function/class/struct names, as it makes it easier to have the output correspond to the names, and still have short output. Or do you have any other suggestions? I don't think anyone is using cppquiz.org to evaluate someone's ability in programming. It is certainly not intended to. I agree that naming is an important skill for programmers. So is giving clear and specific feedback! :)
Hmm. Here's a start: class Employee { public: Employee(const std::string&amp; name, int id, int rank) : mName(name), mID(id), mRank(rank) {} private: std::string mName; int mID; int mRank; }; Where did he start? What do you understand so far and what don't you understand?
i understand how to create the employee and depot class, I am having trouble with the constructor and creating employees using new and then pushing that employee onto depots private data, called workers 
 class Employee { public: Employee(const std::string&amp; name, int id, int rank) : mName(name), mID(id), mRank(rank) {} private: std::string mName; int mID; int mRank; }; Ok, well, this bit here: Employee(const std::string&amp; name, int id, int rank) : mName(name), mID(id), mRank(rank) {} is the constructor. Another way to write it that is more explicit would be: Employee(const std::string&amp; name, int id, int rank) { mName = name; mID = id; mRank = rank; } It takes in your parameters and initializes your data members. When you want to create an instance of Employee, you'll have to create it like that. In code, someone would do something like: Employee e("john doe", 7, 10); So, in depot, you probably have something like: class Depot { // ... void ReadDataFile(const std::string&amp; file) { // open file // for each entry in file // get employee's name, id and rank Employee e(name, id, rank); mWorkers.push_back(e); } std::vector&lt;Employee&gt; mWorkers; }; That's what you need to do, in essence. I haven't explained very much though, what questions do you have about that? Edit: changed from raw pointer to just making a copy. it looks like people that working hard on the newest c++ don't want you to know anything about it's "abominable" roots in C.
Thats making much more sense. what is "std::vector&lt;Employee*&gt; mWorkers;"?? would that be depot's private data? 
You know you'll probably learn this better if you actually read your course book, instead of getting others to do your homework for you.
ok thats what I thought, i just got confused with the syntax.. Thanks I appreciate it a lot! one more question, I now have to compare the employee ID numbers that we pushed into the vector, workers, to a list of ID numbers in a different file. I do not understand how i can compare a vector to a list of numbers in a txt file. 
&gt; Employee* e = new Employee(name, id, rank); &gt; mWorkers.push_back(e); vectors of owning raw pointers are abominations. You're teaching really bad technique to a beginner. Please stop.
I wondered if I should mention that. Seems like that's what the professor was asking for.
So, as someone else mentioned, irl you wouldn't really use a vector of raw pointers. You can just make a copy of it, or, in more modern applications, would use either boost::shared_ptr or std::shared_ptr. Hmm, yeah, the rest is an exercise for the reader, good luck! :)
sweet, thanks again!
Oh, there's apparently a bug on that page, the questions don't get added to the database. Sorry, I'll look into it!
Fixed it! I would be very happy if you could try again.
The best tool by far if you are developing with Intel in mind (and even if you aren't but have access to an Intel machine) is Intel's Amplifier. It's commercial but there are free personal use and academic licenses. 
Most of the questions are around inheritance/order of construction/destruction. Few more topic suggestions: * Memory leak deduction * Data race deduction * Template compilation errors like missing typename. * Undefined behavior due to dangling reference/pointer, double free. * Identifying move/copy construction. Implicit generation of move/copy constructors 
It's a paradox. Being a student, I have lots of time and motivation to learn stuff, but no money to buy a book like this.
I don't understand the downvotes...I simply do not buy dead trees ever since I bought an Android tablet. I would buy this book if it was available in electronic form, but since the publisher can't be bothered it's their loss. In 2013 it should be a no brainer to release books as ebooks too. Obviously the typesetting is done electronically, so it's not like there's really much additional work required on their end.
"You can already go to the amazon.com page for the book and express your interest in a Kindle edition." When has that ever resulted in a kindle edition? I honestly think they forward those requests to /dev/null
This edition will include C++11 so it should be really nice.
I can't wait for mine to ship!
Ingenious insight!
While I agree with you, for reference manuals things I actually prefer books. It is rare I read them in sequential order and tend to flip back and for quickly. I don't know if it applies to this book really but in general with programming books this is how I use them, and I just get that experience on a tablet. 
I emailed him about an error, got a reply. That's like an electronic signature. (Several editions ago.)
Yes.. I meant why only a print option at launch. Hopefully they will release an electronic version soon. 
The problem is quite old. There is a solution. It's called library. There are even not so legal ones online that should help you get expensive books to read. 
As I said [here](http://www.reddit.com/r/cpp/comments/1b7c6l/preface_to_bjarne_stroustrups_the_c_programming/c94cx2f) (on a thread about a month ago): &gt;Seeing as I have the special edition, I'm not sure if it's worth buying the 4th edition... Hmm. Still not sure. Any thoughts?
Yes ebook would be nice.
&gt; problem where I had a vector that was growing once, being iterated over once, and then deallocated That is the use case of `std::deque`. No?
Depends on whether the iteration is linear.
In practice maybe - if vendors all use a list under `std::deque` then I guess it's worth taking advantage of that fact. It's still a little dissatisfying, though, because readers of your code are going to assume you're doing it for the operations the deque supports rather than some very specific performance characteristics. Still, with an explanatory comment and a reasonable assumption about implementation details it's a workable solution.
I use this rationale to argue for big stacks in 64-bit processes. If the stack was 4GiB we would never discourage recursion and probably not even care as much about TCO. It would also make runtime-sized arrays more palatable.
The stack has to be a set size, though. You can do the "reserve address space" trick for std::vector because it has to do the "should I grow" check every time anyway. The stack never does that check. This article is badly worded: MEM_RESERVE doesn't reserve memory, it reserves address space. The writer uses the functionality correctly, though.
&gt; if vendors all use a list under std::deque then I guess it's worth taking advantage of that fact. What? &gt; assume you're doing it for the operations the deque supports rather than some very specific performance characteristics If you need the operations the deque adds over vector, then almost certainly would benefit from it's performance characteristic too. (IE fast frontal insertion).
Not really. a deque is a random access container.
&gt; runtime-sized arrays more palatable C++14 is likely to add them.
Why not have a vector of pointers? You can allocate each object manually. That way you don't have to worry about reallocations.
Oh, you're right. My bad, I was thinking of `std::list`.
What happens if you reserve() 4GB with a std::vector?
Because a large number of small allocations is more expensive than a single large allocation, and storing the data inline has the twin advantages of contiguos layout and avoidance of memory indirections so it plays more nicely with the cache.
Tried it on OS X 10.6 64 bit with 4GB RAM using clang and libc++, both from SVN: #include &lt;cstdio&gt; #include &lt;vector&gt; int main() { std::vector&lt;char&gt; v; v.reserve(4ULL * 1024ULL * 1024ULL * 1024ULL); getchar(); } Output from top -S: * Physical memory: 532K * Virtual memory: 6475M Without v.reserve(): * Physical memory: 524K * Virtual memory: 2379M No swapping in either case. *But that's a single compiler and a single standard library on a single OS. It's perfectly legal for a C++ standard library to fill the allocated, but unused memory with a specific bit pattern for debugging purposes. And suddenly the program really uses 4+GB. And I don't even want to know what happens when running in valgrind or clang's memory sanitizer...
Why 4 GB? Why not 512 MB or 128 GB?
The program works by chance. glBindFragDataLocation &amp; glBindAttribLocation (please, use it ...) need to be issued _before_ glLinkProgram.
Good to know about, I rolled my own json parser with spirit, but I would rather use an existing implementation if I need the functionality again. It would be cool if this was put on something like github so I could easily keep track of it.
I don't see how it is different for the stack: especially because the stack could never grow when the allocated (or reserved or however you call it) memory is exhausted, it makes even more sense for the stack to do that. OP on the other hand claims at this point he could as well remove the capacity check to get rid of all overhead in the vector, essentially meaning there would not be any difference between between a huge preallocated stack and his vector. &gt; This article is badly worded: MEM_RESERVE doesn't reserve memory, it reserves address space. I don't see any metion of MEM_RESERVE in the article or the linked code. The code essentially allocates memory using the syscall for memory allocation (mmap). The underlying kernel might (or might not) over-commit, so that there might not be real hardware memory for the allocated memory available, without failing the allocation. The reason is that the OS already has control over virtual memory and can detect when memory that has been allocated but not yet assigned in the page tables, and can just to the necessary work to "swap in" some real hardware memory there. And since most programs also over-allocate and never use the full memory that they allocate, this is not a real problem. To my knowledge, no syscall exists just for address space reservation.
&gt;&gt; if vendors all use a list under std::deque then I guess it's worth taking advantage of that fact. &gt; What? Ack, autocorrect. I meant to write "[vlist](http://en.wikipedia.org/wiki/VList)". My main point in that sentence was to point out that the formal performance specifications of `std::deque` still only require *amortised* constant-time back-insertion, even if the data structure typically used provides it in linear-time in the worst case. &gt;&gt;assume you're doing it for the operations the deque supports rather than some very specific performance characteristics &gt; If you need the operations the deque adds over vector, then almost certainly would benefit from it's performance characteristic too. (IE fast frontal insertion). My point here is that the author *doesn't* need any of the additional operations `std::deque` provides, so its use could be confusing.
Seems kind of pointless when boost already offers this. (as mentioned in comments). Also I really don't mind using the std:: algorithms in these cases std::for_each(c.rbegin(), c.rend(), ...);
I see, but as you said, a single line comment would clear that all up.
It is, and I look forward to it if it happens - relying on `alloca` and placement-`new` is... awkward. That said, they raise some interesting problems, in that they make it really easy for user-supplied data to blow out a small stack. With heap-allocated arrays that's not a problem, and with big stacks it's a smaller problem. I suspect the solution will just be, "be more careful with user input and don't put anything that might get big onto the stack." This is C++, after all. Unfortunately I think that safety issue could result in runtime-sized stack arrays not being used in a lot of places they'd ideally be appropriate. 
The benefit of this method over reserve() is that you don't need prior knowledge of the final vector's size to use it.
Not so fussed personally. I find std::vector does the trick the vast majority of the time. But I do see that C++ is missing a trick by ignoring something that most CPU architectures are offering.
Many request for an ebook and yet I was not able to find even old editions as ebook from Bjarne Stroustrup. Is it possible or I am too bad with google searching? Does someone have a buy link?
On windows x64 you can reserve at max 8192gb. The article below explains the limits of Windows' virtual memory system with good detail. http://blogs.technet.com/b/markrussinovich/archive/2008/11/17/3155406.aspx
More information: http://cppnow.org/
The OS can grow the stack if it engineers a page fault on the last page of the stack and has address space for it to grow.
Me too, I just spent almost $200 last month on a handful of tech books for my Kindle. &gt; I'd pay $40.00 - $45.00 bucks for a DRM-free EPUB version of this book. Even a PDF would be better than nothing Chances are that this market will be served by someone other than the publisher - someone's going to scan the book &amp; post it as a PDF. Then the publisher will only get 25-50% of the ebook sales it would have gotten, and say, "See? We told you no one would buy the ebook!" And people wonder why publishing is dying...
What? Are you aware of this "new" standard known as "C++11"? That's really the main motivation for the 4th edition. I've been using C++ for about 20 years, and I'd say that the changes in C++11 are perhaps the most widespread changes to the language since I've been using it. In other words - yes, there will be a hell of a lot of new material. And the "old" material will almost certainly be updated to reflect the "new, better" way of doing things - use of auto, etc. I don't have my copy of the most recent "Special Edition" handy, but as I recall he didn't even cover the RAII idiom (like I said, I *think*). I would be shocked if RAII wasn't covered in the 4th edition.
I also think of C++11 as *the* reason to get it. That being said: &gt; RAII Covered in Section 14.4 of the 2000 edition :-)
The Standard requires deques to have guaranteed constant time insertion at the ends, in terms of element operations. Wall clock time is not specified, but it's typically amortized constant.
Thanks!
When I have more questions in the database, I will make it possible to do a "fixed" quiz with a given number of questions with given difficulties. Then there will be a special page when you have finished that quiz. 
I suspect the result would be highly different with a non-POD vector type (so not char) that has a constructor defined that initializes some object member(s) ...
I've not had time to become properly familiar with C++11, so can you (or somebody) explain how the following line from the boost docs works? input += 1,2,3,4,5,6,7,8,9; Obviously, that's somehow turning into 9 push_back() calls. But I don't understand *why*. Is it something boost is providing? Or something that c++11's vector&lt;&gt; offers? I'm referring both to the '+=', as well as the comma-separated list. This looks more like python or ruby than C++ ( and that's cool! But confusing to this old-timer ) 
Not a comment - a typedef! The comment is only seen in one place - you use the typedef name every time you use it. And you should be using typedefs for almost all your containers anyway. 
&gt; because readers of your code are going to assume you're doing it for the operations the deque supports If you use a typedef for the name of the container, then your reader won't know the actual implementation until they go to the definition: typedef std::deque&lt;Dalek&gt; UnboundedDalekList; or something like that. You should be using typedefs for any compound STL class, anyway - it makes the code easier to read. Even something simple like `std::map&lt;string, Dalek&gt;` requires you to pull it apart in your head as you process it - whereas as `DalekPointerMap` actually says what it is. I do agree that `deque` is not the right solution - but that's because it's nearly always implemented as a `vector` of `vector`s so it does little to solve the problem.
Say, what?! This is explained in the third sentence of the article! &gt; The problem was that I also could not predict well how big the vector would be ahead of time. It could vary by orders of magnitude for input that looked similar at first. And `reserve` actually reserves all the memory, even if you never use it, whereas this doesn't actually acquire the memory until right when you use it. That's also discussed in the article - I wonder if you read it.
I suspect the result would be similar even for vector of non-POD types. reserve() does not call any constructors.
Arg! Terrible, terrible idea! Your idea uses _more_ memory - one more pointer per record. If the original vector were `vector&lt;unsigned char&gt;`, your idea can easily use _16 times as much memory or more_ than the original. 16 times? In the original strategy, each byte occupies a byte in memory. In your strategy on a 64-bit machine, you need an 8-byte pointer to that byte. Memory allocation usually has a certain minimal amount you can get, 4 or 8 bytes, and everything over that first byte is wasted AND there's additional overhead per allocation stored in the heap management system which is easily another 8 bytes. Of course, this factor will diminish as the size of your records increases - but it's quite likely that if you have 4GB of records of something you've worked pretty hard to make each record as small as possible, and 16 bytes of overhead on each record could be quite significant. But wait, there's more (badness). One of the huge advantages of having a massive vector laid out in memory is [locality of reference](http://en.wikipedia.org/wiki/Locality_of_reference). If you are iterating through that huge vector, you're going to be going sequentially through memory, and your CPU's caches will be getting hits almost every time, almost all of your predictive loading will be correct. If you iterate through your vector of pointers, you lose all this advantage. Each pointer dereference can go to pretty well anywhere in memory, particularly if your vector grew gradually over time. Almost every one of these pointer references will involve a cache miss. These aren't tiny differences - they're huge! I can't find the code now, but a few years ago I did a simple test where I allocated a fairly large array in memory, and then performed a fairly simple operation on each item. In one test, I just went through linearly - in the other test, I made large skips through the data that were guaranteed to cache-miss every time, but still calculated each value. (I was careful to make the same index calculations in both cases, and to use those indices to make sure the optimizer didn't make them go away.) The results were astonishing - the linear operation was an order of magnitude faster. And I assume it would be even worse for your strategy - try it out! You could write the code in half-an-hour. The differences would be gross enough you wouldn't need a profiler - just the Unix `time` command. And don't get me started about how your extra level of indirection stymies the optimizer... or how throwing millions of extra allocations into your heap memory manager will slow down each and every `new` and `free` in your code... 
`deque` is almost always implemented as a `vector` of `vectors` so it really isn't going to help the problem one bit.
&gt; `std::vector&lt;int&gt; input;` &gt; `input += 1,2,3,4,5,6,7,8,9;` That's Boost Assignment Library, http://www.boost.org/libs/assign/ C++11 provides list-initialization, http://en.cppreference.com/w/cpp/language/list_initialization, which turns this into a one-liner: `std::vector&lt;int&gt; input {1,2,3,4,5,6,7,8,9};` 
Just a quick comment after an (extremely) brief look at [ftl / examples / parser_combinatorics.cpp](https://github.com/beark/ftl/blob/master/examples/parser_combinatorics.cpp) -- note that [`std::stoi`](http://en.cppreference.com/w/cpp/string/basic_string/stol) should work as a standard replacement for `string2int`.
I don't know much about Haskel but I'm glad you are interested in faster than light (FTL) drives. 
You are right, after some experiments, TIL that my belief that the containee type T of a vector does not require a default constructor. Unfortunately, I have no idea where I got this notion... Thanks!
Good point. However, `std::stoi` cannot be passed directly to `functor::map` because it takes more than one parameter--even if all but the first one have default values. At least a quick test indicated as much (I'm actually a bit preoccupied right now, so couldn't be bothered to read through the mile long template error `std::stoi` generated).
Heh, when I first started to think about naming the library, I had many others in mind. However, as soon as this one popped into my head, I knew I had to use it.
Ah, fair enough. Have you considered making `functor::map` a [variadic template](http://en.cppreference.com/w/cpp/language/parameter_pack) so that it could support functions like `std:stoi`? // Edit: a temporary workaround would be to just call `std:stoi` from your unary `string2int` to avoid reimplementation.
As a further explanation: &gt; The requirements that are imposed on the elements depend on the actual operations performed on the container. Generally, it is required that element type meets the requirements of [`MoveConstructible`](http://en.cppreference.com/w/cpp/concept/MoveConstructible) and [`MoveAssignable`](http://en.cppreference.com/w/cpp/concept/MoveAssignable), but many member functions impose stricter requirements. Source: http://en.cppreference.com/w/cpp/container/vector *// Note the change in C++11*
It's not quite that easy. I would have to generalise the entire functor concept to map n-ary functions to types parametrised by n types. And yes, I have considered this :) Might possibly happen at some point in the future, we'll see. As for your workaround, think I'll do just that. I don't like re-inventing wheels if I don't have to.
I think the biggest sell to other developers will be showing FTL-based examples that are unambiguously smaller and faster than a traditional imperative C++11 style.
Very true. I'm not sure I'm trying to sell it just yet, though. Eventually I might, but for now it's still at a quite early stage and mostly in the category of "amusing hobby project". One of the things I'm considering for future "sales", is expanding the parser combinator tutorials ([part 1](https://github.com/beark/ftl/blob/master/docs/Parsec-I.md) and [part 2](https://github.com/beark/ftl/blob/master/docs/Parsec-II.md)) into a proper library--or full fledged Parsec clone, if you prefer. That would make a pretty cool showcase, I think.
Not to seem like a smart arse, but how did you not discover JSON Spirit before writing your own? The project is 5 years old... (and updated today, after 18 months, which is why this is news I guess).
Honestly, I was disappointed with this. I'd like to have seen more about how it was done using Boost Spirit, rather than just "this is how you use the lib". From the title, it read as "I wrote a JSON parser using Boost Spirit, and this is how I did it", not "I wrote a JSON parser using Boost Spirit, and this how you use it.".
There is also a thing called a "job". A job puts money in your pocket and could lead to a date. For the geeks out there a "date" is a social activity involving a man and a woman that some times starts with dinner or maybe a show. 
hey i appreciate your help very much and i have made a lot of progress thus far. One thing i am very confused on is what would go into my public data for depot. I know my depot constructor goes there but i don't understand what that will be
I'll probably never need to know this but I'm really glad I read this just in case the day comes that something reminds me of this article and saves me roughly an hour of painstakingly googling the problem
I'd like to make contributions to improve this code. Mostly just documentation but I'll let you know what all I've done when I complete it, most likely within the next 72 hours.
Wow - boost never ceases to shock me. Thanks for the info!
Nice catch and a good, concise read. It is worth noting that when the Author says &gt; Unfortunately (for us — but perhaps fortunately to others), the following initializations &gt; NullableNameList l = {}; NullableNameList m{}; pick the default constructor. Surprised or not? These are the rules of C++ initialization. he is referring to [copy elision](http://en.wikipedia.org/wiki/Copy_elision), a peculiar standard-compliant optimization.
neither a job nor money are necassary for a date or a relationship. I'd abstain from aquiring love with money. 
[Bjarne to all the suckers buying his new book and continue to use c++](http://assets.diylol.com/hfs/60b/f62/313/resized/jesus-says-meme-generator-got-ya-there-you-fell-for-it-bf9329.jpg)
well, you can download the source code. Spirit is heavily used here (I consider this section to be the 'heart' of the project): https://github.com/sirikata/json-spirit/blob/master/include/json_spirit/reader_template.h#L426 To really understand what's going on you should read the whole boost spirit tutorial here (holy shit, they just updated all their documentation less than a month ago): http://www.boost.org/doc/libs/1_53_0/libs/spirit/doc/html/spirit/introduction.html This library is really fantastic - I use it a lot
That's a good point!
&gt; I don't see any metion of MEM_RESERVE in the article or the linked code. I inferred the author was using the Windows API function VirtualAlloc with the option MEM_RESERVE due to the use of the phrase "reserve memory" to mean "reserve address space" as it was in the article. &gt; To my knowledge, no syscall exists just for address space reservation. That's what MEM_RESERVE does. &gt; the OS already has control over virtual memory and can detect when memory that has been allocated but not yet assigned in the page tables, and can just to the necessary work to "swap in" some real hardware memory there. Is there a way (in Windows or otherwise, you seem to be more familiar with POSIX) to set that up automatically? [notlostyet](http://www.reddit.com/r/cpp/comments/1eayxe/reserving_4gb_of_virtual_memory_per_stdvector_to/c9ynryf) made a good point that you could intercept the overflow exception and grow the stack then. That actually would be pretty cool!
Not C++. 
Your program could periodically write its state to file.
Coroutines work best in languages that don't make heavy use of the stack (or no stack at all). Otherwise, the coroutine implementation has to 1. either make sure the stack is not used in the coroutine 2. or it has to unwind the stack (and restore it next time) 3. or it has to provide a separate stack for the coroutine Option 1 greatly reduces the areas, they can be used in. Option 2 would have to make sure that on restoration the stack has not grown, otherwise pointers will be wrong (or we have to make sure no pointers/references exist). Option 3 essentially make the coroutine a (cooperative) thread, in which case the only advantage would be the easier programmability. But we could also have a small library that "limits" threads to have the same syntax as coroutines. I really like the idea, because sometimes coroutines best model the necessary flow of an algorithm. But in case of C++ I'm don't think they have a big advantage over threads.
Does one normally have the ability to exactly switch from one thread to another, rather than switching being a nondeterministic process? If not, then coroutines do offer an advantage over threads. Furthermore, I suspect that the overhead of coroutines is much less than that of threads.
&gt; Does one normally have the ability to exactly switch from one thread to another, rather than switching being a nondeterministic process? Yes, there are many ways to synchronize threads. &gt; Furthermore, I suspect that the overhead of coroutines is much less than that of threads. What additional overhead should there be with threads? If you have to maintain separate stacks to do coroutines, the only overhead of threads is the synchronization. On the other hand you may be able to execute part of the code in parallel with threads, which in many cases can bring a boost. And even if that's not the case: switching from one thread to the other might be faster than jumping between coroutines, because the whole state of the thread can be "alive" in a different core (or the same core with hyper-threading) and might not need to be restored at all. EDIT: The thing about coroutines is that the syntax is so simple that people are easily fooled into thinking it's low overhead. But from the technical side a coroutine is nothing different from a thread deprived of it's ability to run in parallel with the caller thread (which doesn't help in terms of performance). Take the usual consumer/producer example: it is pretty simple to write a queue that does the necessary synchronization. In the best case (which is that only one of the two has to do any real work) coroutines will have more or less equal performance. But for most normal applications consumer and producer can work in parallel. Furthermore the producer can work ahead and queue up some items if the consumer temporarily needs some more time than average for some items. Now, if you have something like [this](http://www.chiark.greenend.org.uk/~sgtatham/coroutines.html), you really gain something in performance (if and only if on side does almost nothing), but only because the functionality is so limited, that it's almost never worth it. Boost::Coroutine on the other hand does indeed maintain separate contexts, [including stacks](http://www.boost.org/doc/libs/1_53_0/libs/coroutine/doc/html/coroutine/stack.html).
&gt; Yes, there are many ways to synchronize threads. This is a different thing from synchronization, though. I am well aware of the fact that there are mechanisms by which one can make sure that a thread is stopped until another thread wakes it up (such as locks). However, in general does one have the ability to tell the operating system: put the current thread to sleep right now, wake up this other thread until it returns a result, and then put it to sleep and wake me back up? Because in general all that you can do is yield to the scheduler; you don't have any control over which thread it selects next. &gt; What additional overhead should there be with threads? It depends on the operating system. For example, my understanding is that OSX has a thread overhead of 1 MB, which is partly why they created Grand Central Dispatch to make it easier to use thread pools to obtain parallel speed-ups, as using lots of individual threads could be prohibitively expensive at times.
What is the performance of these like? I once [wrote a python game framework using co-routines for game entities](https://github.com/Fiona/Myrmidon). It's a pretty awesome paradigm for writing games and I'm interested in translating the method to c++. 
&gt; But from the technical side a coroutine is nothing different from a thread deprived of it's ability to run in parallel with the caller thread (which doesn't help in terms of performance). The cost of boost::coroutine can be much lower than you think because, unlike in the case of threads, a context switch between coroutines doesn't involve a trip to the operating system and back to switch the context. See [here](http://www.boost.org/doc/libs/1_53_0/libs/context/doc/html/context/performance.html) for the measured performance of boost::context, which is the implementation behind boost::coroutine. Even the case that ucontext is used, my understanding is that you still are benefiting from not having to go through the kernel thread scheduler just to essentially change stacks.
&gt; For example, my understanding is that OSX has a thread overhead of 1 MB Why would you think coroutines have less overhead? A thread has to store the CPU registers and a stack in the TCB. The exact same thing is true for (full featured) coroutines. Of course it makes sense to have thread pools if your application starts and stops threads a lot. But the same thing is true for coroutines: if you allocate a new stack and storage for registers each time you start a new coroutine, it will be just as slow.
I don't like the syntax. This looks better to me: curry(computeAlotOfStuff, eventuallyInt(), eventuallyFloat(), eventuallyObject()); But this also makes sense: [&amp;]() { return computeAlotOfStuff(eventuallyInt().get(), eventuallyFloat().get(), eventuallyObject().get());}; Really, why not a C++ lambda? 
&gt; Why would you think coroutines have less overhead? A thread has to store the CPU registers and a stack in the TCB. The exact same thing is true for (full featured) coroutines. Easy: they can be given a smaller stack. In fact, by looking at the file `coroutine/detail/stack_allocator_posix.hpp`, it would seem that the default stacksize (on posix systems) for boost::coroutine is just a little over 8 kiB, which is orders of magnitude smaller than 1MiB.
Thank you! Appreciated!
&gt;Why would you think coroutines have less overhead? In practice I noticed an absolutely enormous performance improvement switching to boost::context over using native threads. Why this is the case would require an enormous amount of investigation I'm sure, but in actual practice, I took a codebase that used to be based on a thread-pool, switched it to using boost::context with very few changes needed to be made, and noticed quite a significant improvement. From the looks of it, the cost of a context switch as a result of a native OS thread is on the order of 2000-3000 cycles vs. roughly 60-70 cycles using a boost::context.
Well, first of all, the syntax is basically the result of doing a fairly faithful port of Haskell's applicative and monadic syntax to C++. The `curry` call is unfortunate noise, required because C++ does not have curried functions by default. It is the operators that do the work (in fact, your first example would not compile, because `curry` takes a single function-like object as parameter). Second, certainly, your last example works. If you're building more complicated sequences of asynchronous calls, however, I'm quite sure you'll find applicative and monadic styles reduce noise. You'll probably also suffer less confusion, because there won't be different conventions for forcing the lazy/asynchronous computation: `get()` will always do what you want, whereas if you wrap them in lambdas as you suggest, some will use `operator()` and others `get()`. Perhaps a minor thing, but it's there. Also, one of the points of having the functor, applicative, and monad concepts around isn't that they necessarily always result in shorter (though they often do) or faster code, but that they give you a nice standard way of interacting with data structures. _All_ of the things they do can be done exactly equivalently without, but then you're dealing with a type specific interface, i.e. you have to look up the interface of the type, see what invariants and quirks it has, and so on, whereas if you use these abstracted interfaces you are (presumably) already familiar with their laws and how they work. Finally, if you don't like the library, you are of course free not to use it. I'm not quite sure anyone should use it for anything besides fun or experimentation yet anyway! Do look at some of the other examples before you completely disregard it though.
When I switched over my system I did have to ensure that another thread does not ever take over a context, so to speak. The subtle problems come as a result of things like thread local storage and mutexes. A mutex, for example, can only be unlocked by the thread that locked it.
I read through the comments there and at this time no one is talking about using delegating constructors rather than default parameters? Is this better practice now? I have always been against default parameters, probably because i mostly see them used as the "oh i need to add a variable to this method for this one call over here and I don't want to bother updating the other methods that call this already". 
In any case a coroutine is used, a lambda function can be used as well. Why bother with coroutines?
1) if curry takes a function object only, and it returns a function object only, then it is reduntant. Why not make the function object itself curry-able? 2) I wouldn't use function get(). I'd use operator() and so any confusion would be avoided. 3) somehow you haskellers always say that the existing interfaces are all that will ever be needed. However, as a programmer, I create new interfaces every day. 4) if your library does things better than other libs, we would be fools not to use it. So why are you proposing we don't use it? it's either better so we should use it or worse and we should avoid it. 
1) How do you propose giving e.g. a function pointer a curry method or equivalent? No, `curry` must be a free function. I have, however, considered making the generic function object container used in FTL (ftl::function) curried by default. But that's for a future update, if so. 2) And if you're composing a future with a lambda-wrapped future? Then you would be mixing them. But like I said, that's really a quite minor point. The real win comes when, for example, you want to apply a pure function in the context of lazy/asynchronous computations. With your lambda way: `auto x = [](){ return someFunction(someAsync().get()); };` Using future's functor instance: `auto x = someFunction % someAsync();` Sure, it might not be a lot, but it does reduce noise. Add in another async operation that you want to be sequenced (because it depends on the result of the first one), and the difference is even larger: The original line + `auto y = [x](){ return otherAsync(x()).get(); };` vs. _Only_ the line `auto x = someFunction % someAsync() &gt;&gt;= otherAsync;` Also consider the fact that futures aren't just monads in FTL, they're also monoids (well, if the value they compute is a monoid). Even more fun ways of combining things. 3) First, I'm not particularly more of a Haskeller than I am a user of C++. Or C. Or a number of other languages. I just try to take away some neat things from every new language I learn and see if they're also valuable in the other languages I use. Second, of course you do. Everyone does. Rarely does an abstracted, "universal" interface cover everything you want to do with some data structure. But that does not mean the generic interface is useless or undesirable. 4) Main reason not to use it: it's not stable yet. Even the API might yet see some changes, in addition to bug fixes and feature additions. So, definitely not usable in a production environment. Eventually though? I know I'll use it for my next project, at least, and that it will be very helpful there. *edit: fixed code blocks for better readability.
&gt; In my hypothetical example, someFunction did not accept a parameter of type std::future&lt;whatever_type&gt;, but of whatever_type. The above would not compile. Then bind it with this syntax: bind(someFunction, someAsync()) &gt; You still have the above issue, but in addition, you're now also passing a lambda to otherAsync, which accepts a pure value? Isn't otherAsync a curry-able function object? Then bind it again: bind(otherAsync, bind(someFunction, someAsync)) &gt; But what if they're part of a library you're using? Or what if you want them to be useful in other contexts aside from this specific one? I think the bind-like syntax is more acceptable for me. The one you propose seems strange in the context of c++. Personally I'd write all my functions as lambda objects, and then evaluate them at the last possible instance. 
&gt; Then bind it with this syntax: &gt; &gt; bind(someFunction, someAsync()) Still doesn't work, but it's probably my fault you get the types wrong--I should have been more explicit with the type signatures. We have something like: `b_type someFunction(a_type);` `std::future&lt;a_type&gt; someAsync();` `std::future&lt;c_type&gt; otherAsync(b_type);` Now, `someFunction % someAsync()` would return a value of type `std::future&lt;b_type&gt;`. Feeding that to the left of `&gt;&gt;= otherAsync;` yields us a `std::future&lt;c_type&gt;`. Hopefully, that makes things clearer. The currying only comes into play if `someFunction` has an arity greater than one (binary, ternary, ...), in which case you apply it one parameter at a time with `ftl::operator*`. &gt; I think the bind-like syntax is more acceptable for me. The one you propose seems strange in the context of c++. &gt; &gt; Personally I'd write all my functions as lambda objects, and then evaluate them at the last possible instance. That's fine, you're entitled to this view and I don't begrudge you for it. Hell, I can both understand and relate to it, even if I don't share it. I was certainly expecting some (or a lot) of people to dislike the syntax; it is not precisely what you normally see in C++. If ever I find an equally generic way of interacting with data types that is more in line with "normal" C++ syntax, I'd be happy to use that instead. For now though, I'm going to keep working on FTL, if nothing else, then for my own entertainment. Oh, by the way, I'm happy you keep challenging me; it has already lead to an improvement in FTL. Instead of me putting it off for some vague "future" occasion, I've now actually made `ftl::future` curried by default (but without breaking regular function call syntax; you can now do either of `fn(a, b, c)` or `fn(a)(b)(c)`, whichever makes sense in the context). If further testing reveals no issues with this, it'll soon end up in the public repo.
Can you give any examples of algorithms where coroutines are useful?
Fn(a)(b)(c) is something I like. I also like fn(a _, _)(b, _)(c). I actually did this in my own prelude-like library. 
Intersting, although it covered sequence points without mentioning how C++11 cleans that up with sequenced-before and sequenced-after relations.
&gt; e.g. you cannot represent an ordering relation of a&lt;b&lt;e &amp;&amp; c&lt;d&lt;e. Now you can, and the new rules allow finer control. Wait a second, a &lt; b &lt; e is still evaluated as (a &lt; b) &lt; e (the first one returns a bool) which is probably not what one would expect, coming e.g. from python where this is more like the mathmatical equivalent. What's wrong with expressing ordering relation in terms of std::tie() ?
I think [Joel's article](http://www.joelonsoftware.com/articles/Wrong.html) explains this much better.
Great read! Thanks
&gt; 30 files away Every file should be at your fingertips and info about variables should be even closer. Types should be available at a glance but without having to put that info into the name. That said, I find some conventions mentioned in the article make things easier to read for me, and he didn't give any reasons against them. In particular I like having a different naming convention for user-defined, domain specific types from other things (variables, functions, etc.). I don't see any particular conflict between these two things as there is between naming functions and variables in the case of functors. I also have used `m_` member prefixes before, but I think I'm moving away from that.
Maybe [boost::property_tree](http://www.boost.org/doc/libs/1_53_0/doc/html/property_tree.html) is what you really want?
Right, and often there is a good reason for it. So then you have to change the variable... everywhere!
I agree with most of what he said _except_ for special naming for member variables being bad (though I prefer `name_` to `m_name` myself). You absolutely need a naming convention that distinguishes member variables! The reason is that a member variable is an entirely different sort of creature than anything else. Assigning to a member variable has a dramatically different effect than assigning to a local variable (or, God forbid, a global variable...) And there are all sorts of gotchas that can be avoided... many of which won't generate a warning even if you have all your warnings on (which I always do). You can shadow your member variable with a local variable - there are so many ways that can go wrong! You can have a member variable that looks similar to the class variable, and then accidentally assign to that class variable in some code paths. Heck, I've seen this ridiculous anti-pattern many times: struct Foo { int var; Foo(int v) : var(var) {} }; and most of the time it compiles without warnings.... It needs to be very obvious when you are assigning to a member variable. Other people use `this-&gt;name`, which is certainly clear, but less concise than `name_`.
Honestly I can't see using this as a defense this day in age. Most IDE's will tell you what FLAGS or OPTIONS are just by hovering over them. Computers are there to assist us, so let them. In this case the PC can look up types much quicker than I can by hand. That said, this is obviously a style choice so you aren't wrong for doing things this way by any means, it's just not how I do them. You still get an upboat because you have good points. To note, I work on a large project (read +100k lines) and have never needed this convention of naming.
I use CamelCase for functions and underscores for variables, and I can't think of a single time where the problem of having to change the variable name based on its new type has ever come up in practice --- it's just not that often that things you declare as functions suddenly become variables or vice versa, except *maybe* in languages like Haskell where the distinction between the two is sometimes blurry, but in that case the blurriness itself implies that neither of the options is a "wrong" choice and so it still isn't a big deal, just suboptimal at worse. Usually whenever I change a variable name it has nothing to do with updating the naming convention but rather because I have come up with a newer naming scheme that makes it easier to understand what is going on, and in such cases `sed` can do most of the work for me so it isn't that big of a deal. (I can afford to do this because the code is my own; obviously in a group it would be important to check with the other team members first.) Edit: Rather than downvoting to signal that I am an idiot, why not reply to tell me why?
&gt; while it certainly isn't specified it's determined once and for all during compilation That's incorrect. N3690 1.9 [intro.execution]/15: "Except where noted, evaluations of operands of individual operators and of subexpressions of individual expressions are unsequenced. [ Note: In an expression that is evaluated more than once during the execution of a program, unsequenced and indeterminately sequenced evaluations of its subexpressions need not be performed consistently in different evaluations. —end note ]"
&gt; Don't downvote this because you disagree. He has a very valid point. True, but people tend to be turned off when a comment begins by making unfounded negative assertions about others: &gt; Dude is apparently not a long-time programmer, and has never had to maintain a code base of any reasonable size, or had to refactor a legacy project.
I cannot fathom why people would think that it's not a good idea to prefix m_ onto member variables. It makes code so much clearer.
I agree that name "warting" is useless. I had to go through a codebase at one point and replace every instance of lpcstrMyName because I had changed char*'s to use actual std::strings and vowed never to do hungarian notation again. Except for lifetime - m_ for a member variable and some specification for global (g_ or GLOBAL_VARIABLE) is invaluable for determining the lifetime of a variable (scope, class scope, "forever"). My current company uses p_ for variables coming in from a function call (IE MyFunc(int p_a, int p_b) ) but I don't find that as helpful (I also tend to keep my functions under one screen size so there's that too). They also use _t for typedefs which I agree with the OP on but overtime I'm glad THIS codebase does it because my first thought upon seeing that when reading new code is "Oh, this is something else" and promptly go looking for it to determine if the usage was actually optimal (or correct)
Why? I have always found such code to be *harder* to read because it adds noise at the beginning of each and every member variable.
&gt; N3690 you are referring to a very recent document that uses the new "sequenced {before,after}" semantics, while the slides clearly talk about the pre-`C++11` sequence points (see slides #30 and later). Does talking about `C++03`-or-earlier (which wasn't obvious since I didn't state it explicitly - gotta remember to be more precise on this subreddit) make me correct again?
The serious problem with this approach is single processing. In shell all elements are executed in parallel and for example gzcat | grep would be much faster than in this c++ version. Nice idea though.... 
&gt; It can also be used in places where it is not a good fit, for example, consider this monstrosity that solves the FizzBuzz problem I don't think it's necessarily bad fit. It's a lot uglier if you're trying to separate the Fizz, Buzz and FizzBuzz transforms, but if you combine them but separate out the I/O it's quite clean. #include &lt;cstdlib&gt; #include &lt;boost/coroutine/all.hpp&gt; #include &lt;string&gt; #include &lt;iostream&gt; namespace coroutines = boost::coroutines; typedef coroutines::coroutine&lt;unsigned (void)&gt; generator_t; typedef coroutines::coroutine&lt;std::string const&amp; (unsigned)&gt; filter_t; typedef coroutines::coroutine&lt;void (std::string const&amp;)&gt; printer_t; void to_100 (generator_t::caller_type&amp; caller) { for (unsigned i = 1; i &lt;= 100; ++i) caller (i); } void buzz_filter (filter_t::caller_type&amp; caller) { caller(""); while (true) { unsigned i = caller.get(); if (i % 15 == 0) { caller ("FizzBuzz"); } else if (i % 3 == 0) { caller ("Fizz"); } else if (i % 5 == 0) { caller ("Buzz"); } else { caller (std::to_string(i)); } } } void print_line (printer_t::caller_type&amp; caller) { while (true) { caller(); std::cout &lt;&lt; caller.get() &lt;&lt; std::endl; } } int main (int const, char** const) { generator_t generator (to_100); filter_t filter (buzz_filter); printer_t printer (print_line); // pipeline while (generator &amp;&amp; filter &amp;&amp; printer) { filter (generator.get()); printer (filter.get()); generator (); } return EXIT_SUCCESS; }
Because you know it's a member variable. It's not about the 'look' of the code, it's about the extra info. 
Yes, but by extension does it not make sense to put "i_" before all integer variables?
You can do concurrency, you'll just need to introduce fan-out and fan-in stages to your pipeline, along with a bit of synchronisation. On Linux you could probably pass your coroutine stack to the clone(2) system call.
I tend to put a trailing underscore on member vars. It looks ugly, which is a good thing because it encourages a wrapper function.
Wrapper function? How so?
 const foo GetBar()const{ return bar_; } Or whatever you need for that specific member type;
In general my view is that m_ being useful is a code smell. If it's not immediately obvious whether a variable is a member variable or a local variable even without the prefix, then there's probably far too many variables in scope, or too much happening in a single function. Prefixing the member variables merely makes it less obvious that such things need to be refactored, while eliminating only one of the problems.
I put `this-&gt;` in front of all member variables. Except of course, if I'm accessing a member 'from the outside' in which case we obviously have to do something like `x.foo`. If something appears after a `-&gt;` or a `.` it's a member. Otherwise it's not a mamber (it's probably a local variable) Also, if it's not a member variable, then what else could it be? We should avoid using global variables, therefore I usually put `_global` on the end of the names of global variables. You might think that typing `this-&gt;` takes up a lot of characters. But I find that, when dealing with a particular member, I access it mostly from outside as opposed to from the inside. Therefore, it's more convenient to keep the name as short as possible.
"You're doing something wrong" is not an explanation.
Also Chandler Carruth's presentation on static ASTMatchers at C++Now 2012 http://www.youtube.com/watch?v=yuIOGfcOH0k
Aha, but it might add *less* noise. If the member variable is directly readable from outside the class, then my scheme could be more efficient (as I argued in my comment). (Yes, I know that one *shouldn't* have publicly accessible data members, but in reality I do allow myself to use them, especially if the object will be `const`.) With `m_`, you have to add `m_` to every access of the variable, inside and outside. With `this-&gt;` it makes sense only to use it inside class methods.
If you are unlucky they will teach you C, and only a little bit of C++. Which is baggage you dont need. The new way to teach C++, is to start with the STL and avoid C. Like: http://www.stroustrup.com/programming.html
I'd say those suggestions are pretty good. For further reading, I'd also recommend the following list: http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list One advice to the original poster: if you see a book (or a tutorial, but using a tutorial to learn C++ is an *extremely bad* idea in general anyway) which: * starts code with `using namespace std` (before explaining why/when is it a bad practice), * introduces pointers before `std::vector`/`std::array` and `std::string`, * uses `int` (instead of `size_t` or the associated `size_type`) to index `std::vector`/`std::array`(/any other array/container), then I'd recommend to stay away from it. It's not that any of the above has to be _always_ wrong (well, [`using namespace std` is probably wrong in general](http://www.parashift.com/c++-faq/using-namespace-std.html)), it's just that using it indiscriminately / without being aware of the downsides is (and that's why none of this fits in the introductory C++ material, since it runs a high risk of inadvertently instilling bad practices from the start -- due to beginners *not* being able to be discriminating yet). So far, I've found these to be good heuristics to spot writers who are not qualified to even use C++ themselves, let alone teach others about it.
A good C++ class should teach you everything you need to be productive using the language, which in my opinion is everything in the book called [Accelerated C++](http://www.amazon.com/Accelerated-C-Practical-Programming-Example/dp/020170353X). Also it should have you do a non-trivial project every week, or large projects every 2 weeks. By the end of the class you should be well versed with OO, templates, and know your way around the standard library.
An intro class will probably cover basics week-by-week, so variables one week, functions on another and so on. Here are the things that I had to look-up for myself and study because I didn't pay close enough attention the first time: * Pointers! Pointers! Pointers! * References! References! References! * Templates and why you NEED to understand them * Vectors! Why the instructor felt it necessary to not delve deeper into vectors is beyond me as they're used EVERYWHERE! * DRY - *"don't repeat yourself"* 
While getting started with C++ may be easy, mastering it is not. Congrats on taking the first step down the rabbit hole ;-) Also please avoid macros.
you will learn how to program in an object oriented program. Unlike many other languages though, you will have the responsibility to manage your own memory. With great power comes great responsibility and in the words of Bjarne - the inventor of C++ - "C makes it easy to shoot yourself in the foot; C++ makes it harder, but when you do it blows your whole leg off." more seriously, once you learn C++, you'll be equipped to take on any other language. 
 I was originally signed up for "Intro to Java" but decided to switch because of the universal impression I had been getting about C++. How would C++ be applied or related to say, cell phone app design, computer programming, and other general software creation/manipulation?
Indeed, I actually came across that not so long after posting that comment. It has Json serialise functions built right in. That said it is a very general tool, whereas I was parse basically a subset of Json into an existing data structure. Interesting non the less.
At that point you can simply forget coroutines and simply use threads. Run each stage in a separate thread and use a FIFO buffer to communicate between the threads. This essentially replicates how pipes work with separate processes, with the exception that you can share memory (pointers) between stages.
And would you use that in that class's member functions, or only external to that class?
Doing what wrong, exactly? Seems fine to me. 
A function is going to have as many variables declared as required. If you reviewed my code and told me to refactor because a function had too many variable declared, I'd probably tell you to piss off. There is *nothing* wrong with prefixing with m_. In the past 10 years I've worked in 4 companies writing C++ and every one of them had this coding convention. No one complains and everyone finds it useful. 
Most phone apps these days are written in Java (Android) or Objective-C (iOS). C++ is commonly used for applications where performance is important (games, SDR, computer vision, HFT, etc) and GUIs using the Qt framework. Many large applications (e.g. Firefox) are written largely in C++. 
That's a bit long-winded though. It's easier to write m_var that this-&gt;var. I'd agree that for simple structs with public members it is clearer to not use the m_ because the fields are always accessed after a '.' or '-&gt;' Although most classes I write tend to have private member fields, with public (const) getters if required. 
That's a bit long-winded. 
&gt; How would C++ be applied or related to say, cell phone app design Possibly the only way to target all of {Mac OS X, iOS/iPhone, Android, Windows [incl. Windows Phone], Linux, and BlackBerry} with frameworks and libraries available &amp; ready for this: http://visualstudiomagazine.com/articles/2013/02/12/future-c-plus-plus.aspx // Possibly other than HTML5, which, incidentally, you can target, too: http://isocpp.org/blog/2013/04/cpp-on-the-web-run-your-big-3d-game-in-the-browser
\#undef emddudley
So is `m_*`.
But coroutines aren't an alternative to threads, they're an alternative to API visible callbacks (in C++ probably an object completion handler which implies the current state by only being called after satisfying certain preconditions). 1:1 threads are often used as sledge-hammers so programmers don't have to think about what blocks or might introduce latency, rather than tools to achieve concurrency. This puts a lot of complexity and heuristics in to the OS scheduler, as to appear fair and work well over a bunch of different workloads. I also don't agree [with marglexx](http://www.reddit.com/r/cpp/comments/1el61w/coroutine_pipelines_in_c/ca1pgqw) that many of the shell commands implemented in the article would actually benefit much from concurrency. Anything that reads in a file line by line and has to display them in the same order has to be synchronised at both ends i.e. through thread joins.
No it isn't. You can't get more succinct for the purpose, bar doing this: mVariableName. EDIT: or perhaps prefixing/postfixing with _
Yes, pairs of underscores give italics, `_this_` -&gt; _this_ If you want to avoid this, you should escape your underscores, i.e. write `m\_` instead of `m_`.
My point is, in both cases, it's largely unimportant information to the person reading the code, and is only there as a reminder that it's a class member. But when you access a class member, it should really only ever be done within the class scope, and never by outside code, so the name of the variable matters only for the maintenance of the class. Therefore, the reminder that it's a member is, well, redundant.
I'll rephrase, then, and hopefully clarify: When you're working within a class, the **only** variables you should be accessing *at all* is the class members. The reason for this is encapsulation and separation of concerns: A class should be responsible **only** for the specific data it contains. The class should be agnostic and independent of everything that exists outside its scope. It should not access anything that is not a direct member. That is, of course, to make the class easier to test: It's easier to create a mock, and it's easier to create unit tests, because the class can be tested in complete isolation. It depends on nothing, and can therefore be hoisted out into a completely new environment for other uses or for testing. So, when you reference a variable inside a class member function, it had better be a member variable. If it isn't, you're doing something terribly unholy. The reminder of `m_`, in that it means "hey, this is a member variable," should say in your head, "Well, *duh*, of **course** it's a member variable. What else could it *be?*" But my line of thinking continues: *Oh, right. The guy that wrote this code used the `m_` prefix so he'd be able to tell the difference between this and globals and... oh my god, this must be a spaghetti nightmare, or he wouldn't have done this.* Hence: It's just as redundant and long-winded as explicitly qualifying `this-&gt;`.
The "doing something wrong" is to do with scope. If you're walking outside class scope, it's a major code smell, in particular because it increases dependence on outside code, which makes it harder to test, and harder to find the source of a problem when it goes horribly wrong. In that way, prefixes like `m_` are a huge code smell.
Are you saying that member functions should not have input parameters, or locally declared variables? Are you f**king serious? I would laugh my way way out of an interview with you. 
It's a smell, not a problem in itself. Having a large number of variables in scope is often a result of a function trying to do too many things. You would refactor to fix that, not to reduce the number of variable declarations. If a perfectly clear and understandable function happens to have a ridiculous number of variables in scope for whatever reason then of course you wouldn't refactor just to change that, but such code is fairly rare in my experience.
Sometimes it takes a lot of code to do "one thing". Deal with it. EDIT: while I would love to write many small functions in C++, it can be tricky because private member function need to be declared in the header, forcing large rebuilds and exposing needless info in the header. 
I generally keep both the class definition and declaration files open at the same time. I have a spectacularly bad memory for short words, so I keep the header file open at all times as a reference as I'm writing my code. I also keep my functions as short as reasonably possible, and factor out complex functionality whenever possible to keep them short. As such, to know whether a variable is a member or a local, it's a simple glance at the screen. And if I don't immediately know which it is, I've done something horribly wrong. In this way, I realized I no longer needed a prefix or suffix to mark member variables. So, a few years ago, I gave up that habit completely and found my code to be more readable as a result. All I'm saying is that `m_` indicates a code smell. That you have to do a search at all speaks to that. In those cases, your classes may not adhere to the YAGNI principle, the single-responsibility principle, or proper encapsulation. In all three of those possible cases, it's time to refactor.
Based on your other posts I think I agree with the point you're trying to make, but I don't know how to read "When you're working within a class, the only variables you should be accessing at all is the class members" as not saying that you shouldn't use local variables or function arguments.
A very small number of people code with the header visible at all times. You are making your code less readable to others. You are not writing "socially responsible" code. Refactoring is time consuming and hence expensive. Time is money. Code can't be perfect, and 'perfect' is very subjective. You seem to be a bit too idealistic. 
I'm sorry, I have an unfortunate tendency to occasionally use restricted, specific words when I mean to indicate an either-or scenario. I *meant* that the only variables you should be accessing at all *beyond local scope* is the class members. That's why I didn't understand why you misconstrued that to mean you shouldn't use parameters. The idea is laughable, since no reasonable program could be written without them.
The kind of refactoring I'm talking about is trivial: Create a new function to contain a discrete chunk of another function, for the express purpose of making that unit of code easier to test and the calling function smaller and easier to reason about. I don't understand why you're being so resistant to this idea.
The business reasons for using C++, or any language, are more important than the technical reasons. Business strengths: The C++ standardization process is thorough and high quality; few languages are as carefully crafted. There is a strong C++ culture geared to using the right idiom for the job and teaching people how to use the language well. Encapsulation is encouraged in the language and the C++ culture, which is important for writing software for others as part of a team (not just for yourself). There are several excellent free compilers such as g++ and clang. Some technical strengths: C++ is a nearly-complete superset of C, so it inherits all the benefits of low-level access to hardware. Yet C++ has very high-level features that make it great for writing very large program involving hundreds or thousands of contributors. C++ can be as fast as Fortran if compilers are directed to assume that arrays are not aliased. Criticisms of C++: It is complicated and difficult to learn. It is rather slow if used naively, such as not paying attention to what constructors are doing.
Two points: 1) writing this-&gt; is a choice. Eventually some programmer will decide not to, and ruin coding convention consistency. 2) Members should generally be private, so accessing the var outside of class scope should be very rare (unless it's a simple struct, in which case leaving off the m_ is fine).
Judicious use of macros is beneficial to your health.
Same rule in C++98/03, just without the enlightening note. In Standardese, unspecified behavior can be different over the course of a program's execution.
That's incorrect, but for an extremely subtle reason. N3690 23.2.1 [container.requirements.general]/2 - the Standard specifies complexity in terms of element operations. deque push_back is guaranteed to copy exactly one element, but in wall clock terms it may reallocate its "vector" of block pointers. (I was surprised too, when I learned this in the first year of maintaining an STL implementation!)
My objection to this-&gt; is that it's dead code. A very trivial bit of dead code admitted, but even that can be a source of confusion. Writing code which doesn't do anything is in a way lying to the reader, as it breaks the assumption that code is written to achieve a functional result, rather than for the mere sake of existing. Dead code always makes me much less comfortable modifying code I'm not confident I fully understand, as there's always the possibility that it *isn't* actually dead and instead has some subtle non-obvious effects. I don't think this is a terribly strong argument - any mildly complex C++ codebase is going to have far bigger traps for anyone who would have issues with this - but it is an argument against it other than the verbosity.
I agree strongly about pointers, but not about using-directives and only a little about int. As I see it, the main dangers are picking up bad practices that are hard to unlearn, and being endlessly confused by working at too low a level of abstraction (many beginners get lost in pointers/etc. because they don't have the necessary skills to deal with them yet). Using-directives are of course terrible to put in headers at file scope, and overuse elsewhere is also sometimes problematic (I'm updating an old codebase of mine and I'm finding that I prefer to avoid using-directives now), but this is the sort of thing that can be easily corrected later. Indexing with the right type is certainly important, but I don't think I'm prepared to say that seeing int in a beginner tutorial is an instant sign of cluelessness. size_t is pretty easy to introduce (although everyone forgets that it lives in &lt;stddef.h&gt;), so perhaps not introducing it is indeed a bad sign. I'd add that "void main" is a classic shibboleth, stay the hell away from Schildt, and as a general rule, anything written in the 90s should be avoided.
It is my opinion that vector is C++'s most important data type.
Typically you use getters and setters for external access to the class, and access the member within the class by its own name.
Exactly. With the m_ prefix, if the developer has been kind enough to use that coding convention. 
What do you guys think of this [book](http://www.amazon.com/Starting-Out-Early-Objects-7th/dp/0136077749/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1369023724&amp;sr=1-1&amp;keywords=starting+out+with+c%2B%2B) 
So you agree that sometimes using a prefix to indicate something about a variable is useful and sometimes it is annoying, so we are now only arguing over which category "m_" falls into. Personally, I cannot think of a single time when reading C++ code that I wished that the member variables were tagged with "m\_" to improve clarity, and I cannot think of a time I read code that uses "m\_" everywhere when I have *not* found it incredibly annoying because it just adds noise.
Not sure what you mean here. When I write code I'm very conscious that others will have to read and understand it. m_ increases it's clarity IMO. 
My point is that not everyone has the same notion as you regarding what makes code easier or harder to read, so you shouldn't be acting like your standard is the universal optimum. From my perspective you are writing socially *irresponsible* code by adding unnecessary line noise that makes code harder to read. Edit: Fixed typo.
&gt; On your second point: do you ever wonder about the scope of a variable in a function? If you do, how do you determine its scope? It is usually it is pretty clear from context what the scope is so I rarely need to actually try to figure this out. In the rare circumstances where I need to do so, it is not that difficult to first check the local declarations and parameters, then to check the class member variables, and finally to check the global variables. Once I have done this, I can cache this knowledge and I no longer need to look it up again in the short term. If it were always very difficult to tell whether a variable was a member variable or a global variable then I might agree with you that adding "m_" makes sense, but in practice I find that the scope is something that is not all that hard to infer, especially when global variables are rare enough that if there is any amguity it will nearly always resolve to the variable being a member variable rather than a global variable.
But one could argue that prefixing all integers with "i_" is exactly the same: it is annoying at first, but you eventually get used to it and are grateful for the information.
I love **void main**! Its a great way to pick out teachers to avoid.
I am by no means an expert, but I have picked up on a couple things from a guy who is. For me personally, I wouldn't touch the book because this is a book in its 7th edition and [judging by his author's page](http://www.pearsonhighered.com/gaddis/) he seems to have published a lot of books on a variety of subjects with many of them being into at least a couple of editions. I am expecting these things to be marketed towards universities and colleges. From the actual table of contents, he does not get into the 'STL' until chapter 16. What he does have in there is a few pages long. There are entire books written on the STL because of how central it is. In his chapter 17 he introduces linked lists, with a little note about the 'list' class from the STL. In general, he uses bare pointers everywhere (after introducing them) when new code should use shared pointers or unique pointers. Also, he has 'using namespace std' at the top of his code in a lot of places - which as mentioned above is not good practice. I suspect the book might be good for some people, but the habits developed from this book and the stuff it doesn't cover are what would kill it as a book recommendation for me. Published in 2010, it means it has not been updated for C++11, that is another reason to dump it.
I disagree. Because then you mind has to decode a large number of prefixes (instead of just one, m_) and the code really is harder to read. And there will always be unique types that have no shorthand prefix. EDIT: although you would probably get used to it after long enough. 
One of the [books](http://www.amazon.com/Starting-Out-Early-Objects-7th/dp/0136077749/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1369023724&amp;sr=1-1&amp;keywords=starting+out+with+c%2B%2B) somebody asked about earlier would likely explain why it was at the end - because it was that way in a lot of text books peddled to schools.
http://en.wikipedia.org/wiki/Aliasing_(computing)
I didn't even know the difference between bare and smart pointers. I'm getting a new book, thanks. 
Yeah I had to use gaddis for my intro to c++ class. We used Nyhoff for our Abstract Data Types / Data Structures class. Nyhoff is somewhat better then Gaddis, but yeah it hasn't been updated. I still don't know what using directives do completely, I know you have to use std and the scope resolution operator (::) before most everything if you don't include it. I get some what that other libraries (like boost) have naming convention clashes. By using std:: you are stating that the compiler should use the std library definition of that command. That is the extent of my knowledge on the subject. Care enlighten me or direct me to a good site?
Thanks for making me feel great about my education... We didn't even touch c++ objects until the third csci class I took. Templates we had a ton of that in the third csci class, but the second was mostly just c. First csci class we did stuff like build circuits using boolean algebra, writing code at the machine level, and learning how encription algorithms work (very basic ones anyway). We also learned Pseudocode and other ways to approach problem solving.
You should start with C first. IMO if you don't understand C (no need to be an expert though), you're going to be confused by C++. C is a relatively simple lanaguage so it should be possible to do some self learning.
If you get a large coat with big pockets you will be able to take much, much more. You might be able to just walk out with a computer, chances are nobody will stop you, they will just assume you have a legitimate reason. Maybe get a fake employ badge and wear a professional looking shirt. But joking aside, C++ runs everywhere, desktops, servers, Windows, Linux, OSX, Android, iPhone, in the browser (Emscripten + asm.js or Google's native client), Arduino. It also makes for some high performance website backends (Facebook). But it's a systems programming language, meaning you get much more control but often that you have to do a lot more of the work other languages would do for you. It will likely take you longer with C++ than many other language (main scripting ones). It's also a language that lets you skip the Object Orientated approach when you want giving you much greater flexibility.
Ugh no, please don't. Learning C and then learning C++ is like learning latin, only to forget everything and learn a latin-derived language. Please, just leave C out of the whole thing.
&gt; If you're walking outside class scope, it's a major code smell, in particular because it increases dependence on outside code Who says I am? This is about code inside the class, so I can distinguish members from locals for every variable access in a method. &gt; [...] are a huge code smell. You're doing it again! Phrases like "doing something wrong" and "code smell" just show that you're doing something wrong and make your argument smell.
Are you acquainted with generators and yield in Python? You can implement this easily with coroutines. As a concrete example, coroutines are useful to convert recursive code into seemingly iterative code (for example, tree or graph traversal). As another example, you can package up "ugly" state-machine code (e.g., stateful web apps) into a coroutine with a "nice" control-flow. I guess they're also useful in discrete event simulations (IIRC, Simula was the first wide-spread language with coroutines.)
Wow that'st he exact list of things that I didnt comprehend in my intro to C++ class. I tried but a one hour class wasnt enough. I had to do plenty of research on my own.
True, but not all of us use editors with such powers (not because we are luddites, but because other editors have features that we like more).
... which I think is exclusive to C only.
http://stackoverflow.com/questions/7298546/gcc-c-c-assume-no-pointer-aliasing Note that this is less of a problem for C++ than for C, due to type-based alias analysis: http://www.drdobbs.com/cpp/type-based-alias-analysis/184404273
You can expect from this class the ability to read C++ code, with the ability to eventually interpret a complex construct you can't initially understand. You should be able to recognize all the keywords and how they function in the common cases. You should be able to find and understand documentation describing the details of any given construct in the language, from keywords, to syntax rules, to the standard library. You should not expect to learn good coding practices. In fact, you may make several unwarranted jumps, and assume some very bad habits, as a consequence of the material just trying to demonstrate a part of the language. For example, you're going to learn about raw pointers, new, delete, and destructors. You might think allocating resources on the heap and managing them yourself is a good idea - in reality, the common wisdom is to use smart pointers, and some of the newer emplacement constructs (I'm still new to C++11 myself, so I'm not terribly sharp on the terminologies for this stuff myself) to allocate resources (you shouldn't have to call new or delete in your code). Learn raw pointers, and then refrain from using them. Learn macros, because you're going to see them, and refrain from using them. You're going to have to learn good practices on your own. Once you're done with this class, I recommend you start with Herb Sutter, his books, and Guru of the Week.
My school teaches c++ in 'intro to c++' and in 'cs 1' then switches to java in 'cs 2'. We barely skimmed vectors at the end of 'cs 1' with one slide and no assignments to cover that material and it never made it onto any tests. 
Do text book publishers pick cover images with a random image picker? 
For private members, I think I see now that `m_` is better. I tend to make most members available publicly, but that works for me because I often use a functional style of programming where most objects are `const`. But I will consider a different approach in future in cases where the member is private.
Good advice, a couple nitpicks: I don't think that being able to recognize *all* the keywords is important. There are a few more obscure ones that could be picked up if needed. &gt; xor_eq, export, typeid, volatile, etc. And you generally shouldn't have to call new in your code *except* to pass the resulting pointer to a smart pointer constructor. That exception is still important in C++11 for building some complicated data structures. And of course, follow best practices but make exceptions when you have to (just remember to feel vaguely unclean when you do it). I used a macro the other day because it was simply the best tool for the job.
Bare pointers mean that you have to manage any and all memory you allocate, a la C. Smart pointers relieve you of [most of] that burden. [`unique_ptr`](http://en.cppreference.com/w/cpp/memory/unique_ptr)s will delete the memory they allocate once they go out of scope. Ditto for [`shared_ptr`](http://en.cppreference.com/w/cpp/memory/shared_ptr), with the caveat that it only deletes the allocated object once all the `shared_ptr`s pointing to it have gone out of scope. There is also [`weak_ptr`](http://en.cppreference.com/w/cpp/memory/weak_ptr), which is basically a `shared_ptr` that does not contribute to the reference count. i.e., when all `shared_ptr`s go out of scope, the underlying memory is deleted and `weak_ptr`s pointing to the same object are no longer valid. The general rule is that for most code written in modern C++ style, you should never have to write `new` or `delete`. It is definitely worth learning how bare pointers work, though.
&gt; There is also weak_ptr, which is basically a shared_ptr that does not contribute to the reference count. Actually, weak_ptrs update a "weak reference count". The strong reference count keeps the object and the control block alive, while the weak reference count keeps only the control block alive. The special thing about weak_ptrs is that they can sense when the object has been destroyed (by calling expired()), because they communicate through the control block.
you call get_output with the wrong parameters (portion1 instead of calculation_c)
Unless I'm missing something, the functions: int calculation(int input_1); int calculation2(int input_2); are call by value. Which means the value of input parameters are sent to function. Inside function a copy of the parameters are modified. So the modification will not affect the actual input parameters. 
You may find the following helpful: "Working with Dynamic Memory in C++", &lt;http://www.informit.com/articles/article.aspx?p=1944072&gt; // Incidentally, it's a (sample) chapter from C++ Primer, 5th Edition -- highly recommended!
Always enraged me.
Ah, I didn't know that. Still, I can't imagine what else he was referring to and it seems like it's de facto supported anyways, but I can see why, for having actual guarantees, it's not very comforting.
I have some questions: * Why should "virtual" inheritance still be used when we have CRTP? * When is runtime polymorphism still used over CRTP and should it be?
Here are a few sources: http://en.wikipedia.org/wiki/Pointer_aliasing http://stackoverflow.com/questions/146159/is-fortran-faster-than-c http://www.cs.indiana.edu/pub/techreports/TR542.pdf http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.41.7266&amp;rep=rep1&amp;type=pdf
CRTP?
Googled it http://en.wikipedia.org/wiki/Curiously_recurring_template_pattern
I know what template are, I know how their work, but what I don't know is why I need to understand them. Currently, I feel like the only place I'll encounter them is in the STL. That's why I don't spend a lot of time on templates... Do you have good examples to change my mind?
Nope. Don't delete posts they may help someone in the future with the same problem as you.
&gt; This is about code inside the class, so I can distinguish members from locals for every variable access in a method. ... Which is a code smell. What I mean is: You should only ever be accessing locals or class members, and your functions should be small enough that they're easy to reason about and local declarations should be readily visible. If your local variables are not readily visible within your editor window, *the function is too long and is doing too many things and needs desperately to be refactored.* (And by refactoring, I mean, simply, that the function needs to be simplified by extracting functionality into logically reasonable function calls, the implementations of which are short and easy to test and trivial to reason about.) And since you should be able to see, at a glance, all of the names of local variables and parameters, all that remains is class members. If any of those names are not class members, you've done something horribly wrong, and your class code has dependence on outside code, which makes it inordinately more difficult to test. Hence: This code stinks like a pair of wool socks worn by a fireman on a hot day, and `m_` is what told me so.
CRTP still requires a complete type, while all that is needed with runtime polymorphism is a vtable (eg an interface). Using delegates / function pointers / etc is another way to achieve similar goals without the restrictions or side effects of virtual classes. 
&gt;Make null pointers of types T and U, then dereference them This sentence makes me all sorts of itchy.
if decltype is like typeof, is there a syntax that would use decltype on the passed template type itself? Eg T and U. Without the need for a null pointer?
great, thanks.
C++ makes you fly over the beautiful ocean.
I am assuming OP has never come into contact with low level language before. If he can't get basic stuff like pointers and manual memory management, he is going to be confused by the C++ object oriented stuff.
Android supports apps developed in C++ with the NDK, though you're probably right that most Android apps are Java. While iOS's frameworks all use Objective-C, iOS apps are 'native' and therefore you can use any native language, including C++. iOS supports Objective-C++ specifically to facilitate C++ programs' access to the frameworks. I would guess that most iOS apps are a mix of C++ and Objective-C++, rather than straight C and Objective-C.
&gt; When is runtime polymorphism still used over CRTP and should it be? Whenever you need runtime polymorphism. The answer is in the question.
Not all private functions need be declared as members of the class. If they're purely functional - that is, they have no dependence on anything but the parameters - they can be declared as `static` in the global namespace, to restrict them to file scope. In that way, you can extract code that does nothing beyond mutating local variables into a separate function that is short and easy to reason about. Then your huge function does one less thing and is easier to reason about. You cannot say that a lot of code does only one thing. It may be that in order to do what it's meant to do requires a lot of code, but each and every line of code is *one thing* that can potentially be refactored into a new function. The idea of having functions that do only "one thing" is not an absolute: These functions are free to do more than one thing; the only restriction is that the function must be short, its name must be descriptive of its simple purpose, and it must be easy to reason about. That is, it must be short enough that the functionality of the code is clear at a glance. Then, the larger function can be a series of simple function calls and a few simple branching constructs, which can be analyzed at a glance. In code like this, prefixes like `m_` are completely and utterly unnecessary.
&gt;Well, I'm sold. I'm still not sure where that difference comes from, but ok. Probably because boost::context doesn't do any system calls which will be much faster than a native OS thread context switch. This is the reason why languages like erlang and scala can have such fast concurrency models (by having a VM create userland threads).
coroutines and state machines are very closely related, you can go from one to the other very easily. So if you don't like writing state machines, just use coroutines, see [here](http://eli.thegreenplace.net/2009/08/29/co-routines-as-an-alternative-to-state-machines/) for an example.
for one, they allow you to write state machines in an elegant way.
Anonymous namespace functions in the translation unit: Yes, of course. But sorry, regardless of how many small anonymous functions you have, m_ is still useful. Question: how many input params and local variables can a function have? Go on, have a look through your code base. Make sure you look at code that you didn't write. 
"ugly hack"
... This is all just idealistic bullshit. Some of us live in the real world. 
And some of us write new code in exactly the way in which you've described as idealistic bullshit, and do so in the real world quite successfully.
This is so much more succinct.
Yes *you* can write code as correct as you want. What you can't do is control how others code. And they will not code to your standards no matter how much you want them to. This is the hundredth time I've said this: m_ is useful when reading code **not written by you**. 
Using this-&gt; is not dead code. That is actually hows it called by the compiler. It just makes it explicit. I think its much better writing it explicity, rather then rely on the the compiler to implicity call this-&gt;. Its especially important too for clarity when calling member functions, to make it clear that this is being passed as parameter to the function.
Floating point math gives you different results depending on the architecture, compiler and optimization levels, fixed point is completely deterministic. That can matter for example with demo-recording in games, especially if it's an Open Source game and you can't enforce a compiler, arch or optimization level. With new games you of course have little choice in avoiding floating point, but with older 2D games fixed point might be all you need, it also helps with older hardware like the Playstation Portable. See [Floating Point Determinism](http://gafferongames.com/networking-for-game-programmers/floating-point-determinism/)
&gt; on modern CPUs with floating point units On such CPUs, using the native FPU is *usually* the best approach (there are sometimes reasons to avoid the FPU anyway). But don't forget that 97% of the CPUs that are sold every year are embedded processors that typically don't have FPUs.
My eyes, my glorious eyes.
root window or your own window? The root window encompasses the whole screen, while your window may not.
And writing state machines with lambdas isn't elegant somehow?
It's not consistent: compare the type parameters to join_range and std::multimap. They're indented to different levels, and join_range uses leading commas while std::multimap uses trailing commas. Even ignoring that, I found it very hard to read for a few reasons. There's such large mid-line gaps that I consistently completely missed things floating off by themselves at the end of the line, such as `this_type` and the semicolons (although missing the semicolons is not a huge deal unless the code does things along the lines of `while (...);`). I initially didn't include `map_type` in my copy and paste until I realized that there had to be something after the `&gt;` which I had simply not seen. Having `join_range`'s type parameters indented in between the `typedef` and `join_range` confused me greatly at first, as it seemed to be implying some sort of structure that didn't make any sense and could not exist.
I gather this is solely for expository purposes, so that the name stands out in the assembly source code (note that you no longer have the same notion of a "type" once you translate from C++ to the assembly language, so you can't rely on the facts you know about the C++'s type system).
The most interesting thing about this is the very lightweight way it handles portability.
I understand that a fixed point library will give you consistency across hardware. But my question is more about whether any fixed point libraries outperform the FPU on, say, an Intel corei7 at the same level of precision.
Thanks but can't see a specific fixed-point class here (i.e one that handles fractional part)
I like the yes/no macro trick. I haven't seen that before.
I don't understand this trick. Why wouldn't he just use the platform-dependent macros in his code below? At one point he already needs to use `__linux__` because he needs to have code for all other platforms except linux. And I can also point out code which is in every one of his platform-dependent macros in the `get_any_mac` function and could easily be only written once.
I totally disagree. Naming conventions are extremely valuable, especially in a language as organically designed as c++. My only gripe is that a c prefix is generally not informative enough, I love it when a coding convention distinguishes between: * Pure virtual classes * Pure compile time types * POD types * Templated types * Alias types (typedefs) * primitive types
&gt; Naming conventions are extremely valuable I did not object to that. But the rest of your answer is simply wrong. The whole point of an extensible type system (such as C++’s) is that types are treated *as uniform* – in fact, one of the fundamental design principles of C++ is that classes should be designed so that they behave as much as possible (and reasonable) as `int` – that is, as built-in types. Drawing a distinction between types by giving them different names shows a fundamental misunderstanding about what the purpose of C++’ type system is. For instance, prefixing classes with `C` and structs with `S` draws a nonexistent distinction and leaks implementation details. The same is true, to some extent, for other kinds of types. Many (but not all) of the distinctions you suggest would only serve as a substitute for a bad design in the first place. Primitive types and PODs are indistinguishable. Type templates (*not* “template types”, this doesn’t exist and is another misunderstanding) are just that – templates to generate vanilla types. “Pure compile time types” – I have no idea what that is. “Alias types” don’t exist, type aliases do. And as the name suggests, they are *aliases*, and hence identical to types. In particular, they must be replaceable by types (and vice versa). If they had different names this would introduce breaking changes.
I remember his [talk](https://channel9.msdn.com/posts/C-and-Beyond-2012-Herb-Sutter-You-dont-know-blank-and-blank) from C++ and Beyond 2012, I wonder if there's more to that than what's in that talk.
boost UUID's random generator is literally the output of the mersenne twister from boost.random, with the appropriate version bits set. 
Some of your post feels like nitpicking, and some of it feels close minded. &gt;“Alias types” don’t exist, type aliases do. &gt;Type templates (not “template types”, this doesn’t exist and is another misunderstanding) are just that &gt;“Pure compile time types” – I have no idea what that is. "This doesn't exist, and this doesn't exist, and I have no idea what this means". I don't think you're in a great spot to tell me what "does and doesn't exist". This is tricky stuff, but I chose my words with great intent and I hope you'll at least acknowledge that the real-ness of "template types" and "alias types" is a matter of perspective. These are *very* real concepts at compile time, and given that compile time is part of my software's lifecycle it's important that I understand how it exists and the transformations it undertakes during this phase. The following is a bit of a rant: The only time robust naming is bad design is if you're distributing an API, meaning you're going to give up the ability to change names except for during major releases (and even then, you should feel bad about it). That's not what *most* code is about. Most code should value expression far more than flexibility because there is not a tradeoff. There's no tradeoff because if your implementation needs a primitive instead of a struct renaming all references to that type should be trivial, and it would be even more trivial if CPP were sufficiently well designed to foster a good tool ecosystem (fortunately llvm is slowly rescuing us from our past sins, so this point is becoming moot). As for your point about types in C++ being uniform, I'm sorry but that's *bullshit*. C++'s design principles is that you shouldn't pay for what you don't use, not that all types should be somehow interchangeable. I picked the things I listed very intentionally because there are operations that can be performed syntactically on these types that are an error. Sometimes the error is detected at compile time but sometimes it is not, and a naming convention can convey intentionality to other programmers and *that* is most of the point of programming. My point remains: C++ is fucking hard to parse, a naming convention can correct this. I'll try to post some code examples illustrating why I find distinguishing between these types so important, but I probably won't have time for a couple weeks.
I can't comment because I dont want a wordpress account. But const in C++11 means thread safe. As stated in his talk.
You don't need a WP account to comment.
Hmm, it stopped me when I tried and asked me to login. Oh well :)
There have been a few proposals and discussions in the boost mailing list; many refer to the Dobbs article at http://www.drdobbs.com/cpp/fixed-point-arithmetic-types-for-c/184401992
It never even occurred to me that I could use lambdas for custom deleters. I've got so much legacy code to delete now...
&gt;std::unique_ptr&lt;int[]&gt; p(new int[10]); Why would you want to write such a convoluted thing, instead of using `std::array` or `std::vector`?
Right! But using smart pointers is another option for arrays. Of course vectors (or even new std::array) are better.
&gt; using smart pointers is another option for arrays Is there any context where you'd want to use a dynamically-allocated C array?
I'm pretty sure I've never seen that exact case. Typically, C libraries return a `int*`, not a `int[]`. And quite often, you need to use a library-specific function to free the resources, meaning you have to make your own RIAA class / smart pointer.
For every yield your function does, you provide a lambda parameter to invoke. For example, if you have the following program: int a() { yield 1; yield 2; yield 3; } print(a()); print(a()); print(a()); You can do it like this with lambdas: a(f) { f(1); f(2); f(3); } a(print); 
Some additional answers from stackoverflow: [link to stackoverflow question](http://stackoverflow.com/questions/16711697/is-there-any-use-for-unique-ptr-with-array)
Is this cross platform?
Are the server components slated to come back in? They were there when this was a research project.
Yes. Right now we support Windows and Linux. But we built the library in such a way that it should be portable to other platforms as well. We hope to have help from the community to help us with supporting more platforms. 
Yes. We pulled them out initially because we didn't feel they were ready to be used for production code. We will bring them back in one of our upcoming releases once we feel that they have received enough testing. 
I notice the two downloads available are both MSI files, which is fine - I went to the source code to download what turned out to be a zip file. But inside the zip file it has a bunch of folders and files in the root of the zip file, against the best practice of putting everything inside of a folder so you know where it is when it is extracted. More a criticism of codeplex as it is out of your control - but now I have to clean up a directory.
Will this make me rich?
C++ OOP does not require the use of pointers. Modern C++ tends to avoid manual memory management. Why not start with vector, string, map, and friends, instead of the stuff you'll have to un-learn later anyways?
Thanks, it just bothers me that I implemented a full REST SDK on top of WinHttp that follows pretty much the exact same patterns as you, but I wrote it myself and I didn't know about yours. That being said, the main missing feature in yours that I had in mine was something like this: mytaskthing&lt;sometype&gt; result = client-&gt;request(...); result.get().someOperation() That is, it had the ability to automagically convert the response to some C++ type.
Is this really the idiomatic way to use the library: https://casablanca.codeplex.com/SourceControl/latest#Release/collateral/Samples/BingRequest/bingrequest.cpp ? 
aha, i made it up :D
matter of tastes, I guess! :D
Alternately we could store smart pointers in the vector.
Previous discussions: * /r/cpp -- http://www.reddit.com/r/cpp/comments/1ee7yt/an_interview_with_bjarne_stroustrup_informit/ * /r/programming -- http://www.reddit.com/r/programming/comments/1ee9gh/an_interview_with_bjarne_stroustrup_informit/
Weird. reddit usually finds the previous submissions; it didn't this time.
And now you have 2 problems.
It might've gotten fooled by the following part of the URL: `&amp;WT.mc_id=IT_NL_Content_2013_5_22`. I usually just try to strip every potentially extraneous part from the address before submitting, that's often enough :-)
&gt; Universal-character-names can also be used to name characters of the basic source character set. However, the use of any of them in a place other than a character or string literal is undefined behavior. This isn't accurate; rather than having undefined behavior such programs are ill-formed. Also it should be noted that support for some of these features is spotty. - VC++ doesn't support alternative tokens, except that they do provide a header that fakes some of them. - gcc has some experimental support for UCNs in identifiers, but they seem to behave differently than writing characters literally. VC++ and clang seem to generally work.
C ≠ C++
It is not the shortest Programm on on my Mac: kretikus@Nepumuk:~$ gcc small.c ld: file too small for architecture x86_64 collect2: ld returned 1 exit status :) 
The problem described in this article has nothing to do with what is in the vector, but rather the location of the vector elements themselves. Whatever you are storing in the vector, the whole vector is likely to move to another part of memory when it reallocates itself. Thus, any references or pointers you had to the original memory locations are invalid. It doesn't matter if the stuff in the vector is ints, strings, pointers, cheese, whatever, the point is that they all moved elsewhere.
The smart pointer moves, what it points to doesn't. Problem solved. 
This is roughly the idea behind `boost::stable_vector`, except `stable_vector` has a much better interface and is probably a little faster. It's still going to be absurdly slower than a regular `vector` in most cases, though.
That should have been staggeringly obvious. 
I think that skips the usual reason for holding the iterator. Usually the reason you hold the iterator is because you want to do something with it, like remove the thing from the vector, or maybe insert some more stuff at a certain position, or search for something starting from that position. If you just keep pointers in the vector, and then dereference the pointer to get your actual thing, you can no longer interact with the vector without finding the item again.
&gt; Problem solved. No, because iteration invalidation (which this article is about) is invariant with respect to container's `value_type` (which is what you're talking about): http://stackoverflow.com/questions/6438086/iterator-invalidation-rules
Slower at doing what? If you're storing references to objects in a vector you're indirecting one way or another, and I suspect that storing a reference to a particular item means you're not too interested in iterating, so that really just leaves you with insertion and deletion being slower, but given that these objects are long-lived enough that you're sprinkling references to them places I doubt that's a very big part of your execution time. 
It's not just iterators, any reference or pointer to an object held inside a vector is subject to invalidation. In that case, a vector of smart pointers does indeed solve the problem.
The point of using indirection would be have things A, B, and C in a vector, now I can remove thing B without updating pointers to things A and C. 
Yeah, that must have been it. Sorry!
If it works in C, it may work in C++. I challenge you to make a C++ program without any C construct.
&gt; Unless you really need contiguous allocation, it's a good choice for your default goto container, especially with highly variable sizes. I would like to strongly disagree. After `array` a `vector` is really the next best choice. It will work nicely with caches since the data is kept compact. One should use other containers if there are special requirements (e.g. on iterator validity) and not only to keep bad habits.
Herb Sutter actually once expressed the same opinion, [in this article](http://www.gotw.ca/publications/mill10.htm) &gt; I'd like to present an amiably dissenting point of view: I recommend that you consider preferring deque by default instead of vector Deque does keep data *somewhat* compact, at least for small objects. The GNU implementation keeps chunks to 512 bytes, which eliminates a lot of the (size) overhead for fundamental types. Fixed sized chunks are a requirement to keep random access to O(1) For larger objects you may begin to lose the benefits of memory locality with std::vector anyway, as it's increasingly unlikely that you actually *need* the entirety of each object (Perhaps you only intend to access one member?). Many modern x86 CPUs have 64 byte cache lines. The biggest loss for the deque, I would think, is the impedance to prefetching by the CPU. The allocator might still allocate contiguously though, and you might get away with it. I think it's a shame that deque doesn't let you change the node size or, in the very least, call reserve(). &gt; After array a vector is really the next best choice I'd probably pick vector before an array (C or std::array), unless your size is fixed, and even then I'd probably still use vector + reserve().
Unfortunately msvc uses 16 byte chunks for `std::deque` for some reason, which makes it a lot less appealing.
I found [a post on Microsoft Connect](https://connect.microsoft.com/VisualStudio/feedback/details/509141/std-deque-performance-is-sub-optimal), circa 2009, that seems to confirm this. That's piss poor. Out of interest found this in LVMs libc++, which seems to suggest it's set to max(16, 4096/sizeof(T)) objects, not bytes. static const difference_type __block_size = sizeof(value_type) &lt; 256 ? 4096 / sizeof(value_type) : 16;
I really like these articles that walk through the process parallel to your train of thought instead of outright giving the final solution and stating why it works.
Oh, I get it, never mind then.
If you've read the full article, then you may know other forms of write the same thing: int main; // it works on C++ The cool thing is the explaination, not the "shortest crashing c program".
It seems like this guy goes back a few times when someone points out to him that what he's doing is a special case on his platform. Best/quickest/guaranteed way to crash a process is to either dereference an illegal memory location, or cause a stack overflow.
I was expecting something like: int main() { return main(); }
For more details about make_shared for arrays in Boost see http://svn.boost.org/svn/boost/branches/release/libs/smart_ptr/make_shared_array.html
For general overview of C++, something around that time is probably ok. C++98 and C++03 are very very similar. (03 is just a bugfix version) You'd miss info about TR1 (http://en.wikipedia.org/wiki/C%2B%2B_Technical_Report_1) and of course C++11. But any generally well written text about C++ should be good to use.
C++ is a constantly evolving language. Accelerated C++ is a great place to start to learn good C++98 practices which are certainly solid enough coding standards to get you your first job writing in C++. That said, check out 'The C++ Programming Language. 4th edition' by Bjarne Stroustrup. It literally just came out and goes over best practices in C++11. On his website you can find a pdf of exercises that go along with the book, which I'd highly recommend. If you want to know some of the new features of C++11 I'd also recommend the Going Native 2012 video lectures [here](http://channel9.msdn.com/Events/GoingNative/GoingNative-2012?d=1). 
Wait, isn't 'The C++ Programming Language' a reference text? Not a teach-yourself text? You recommend that over 'Accelerated'?
'The C++ Programming Language' isnt really aimed at beginners. Its not just a reference text either, as it has plenty of examples. You can check out the first chapter: http://isocpp.org/images/uploads/2-Tour-Basics.pdf C++11 and C+14 books for beginners are very scarce. I dont know any. Maybe later this year there will be some. So unless you go for the above one, you are left with C++98. There are plenty of those, but this is among the newest one: http://www.stroustrup.com/programming.html Its aimed at beginners and teaches you c++98 from the top down, instead of bottom up. There is no need to start with learning C. That just teaches you bad habits that are hard to break. Better is to start using STL as quickly as possible, that way you learn good habits from the start. There is half joking saying that goes "The worst person to learn C++ is a C programmer". So try to forget C when learning C++. Also modern C++ isnt really about OOP (classes and inheritance) anymore. Its about using the STL. Accelerated C++ is popular and its not too bad if I remember correctly. But if I was you id go for Stroustrups beginner book. 
 localalloc=false; T*t (new T); localalloc=true; delete t; // leak. Please store allocation type per pointer, don't depend on global state.
The problem is none of those more accessible books have been updated for C++11 yet. So you can either go with a good c++98 book, go with the reference text, or wait.
I recommend *C++ Primer* by Stanley Lippman.
You're going to buy several books on C++ so, don't sweat one or two being out-of-date as long as they have other virtues. 
I second this. Just don't confuse it with C++ Primer *Plus*, which is something entirely different.
Ugh, why use global variables instead of an overloaded version of new? (As in, new (std::nothrow))
The newest edition of *C++ Primer* also covers C++11. I'd recommend reading that before reading TCPPPL. See http://www.amazon.com/Primer-5th-Stanley-B-Lippman/dp/0321714113
The poster has since corrected this - so I guess you are right!
Yes, as other are, I would also recommend the C++ Primer 5th edition over TC++PL for a beginner.
5th edition.
Doesn't alloca also allocate from the stack?
The overhead of a virtual function call is basically derefencing a pointer. I can't imagine new/delete being faster than that, even ignoring any time the constructor takes to run. (Profile anyway though.) And be [very very careful](http://www.parashift.com/c++-faq/calling-virtuals-from-ctors.html) calling virtual functions from contructors. Best practice is probably to avoid it.
Yes, it' old. But it's not out of date. It was the first among the "modern" books about teaching C++. It's nicely compact (350 pages) and accurate! It obviously does not cover the new things we got in C++11. Still, I can recommend it if you want a compact introduction to programming in C++. The 5th edition of C++ Primter is more comprehensive and also covers the new bits in C++11. 
Three years ago, Accelerated C++ was pretty much up to date. Today, C++11 is out, so, yeah, AC++ is a little bit outdated. That said, it's still a very good book to learn what C++ is all about. Coming from C, there's one big thing you'll have to learn: let the compiler do stuff for you. In particular, let the compiler manage the memory. You should use dynamic allocation pretty rarely (In fact, you can do pretty big programs without ever using it), and you should never deallocate memory yourself. And Accelerated C++ should be pretty good at guiding you. While incomplete, I believe it's still a very good beginner's book. Besides, pretty much all C++98 code you'll write is perfectly compatible with C++11, and will be accepted by a C++11 compiler. Which means, you can start with C++98 (which is still heavily used today, anyway), and add C++11 features as you learn them.
&gt; I can't imagine new/delete being faster than that Exactly my point. :) &gt; And be very very careful[1] calling virtual functions from contructors. Yes, but to my knowledge the "Clear" function can be resolved at compile time and thus isnt a "real" virutal function, ie it's a direct call resolved at compile time. 
&gt; Is that really just a feeling, or did you actually measure it? Kind of sort of measure it. It's difficult to profile because VS seems to have some issues with mulitthreadig. I was very motivated to declare the second way to be faster - but i can hardly justify that. &gt; calling virtual functions in a constructor (or destructor, for that matter) is dangerous Yeah, but i am calling an implementation of the B class and thus it's a static call, ie resolved at compile time.
The author is right: Don't ever do this, and if you need something like it, do it any other way. Some use cases can be sped up with a linear allocator approach. The correct way to implement that is with a scratch pad type allocator, or what DICE calls a [scope stack allocator](http://dice.se/wp-content/uploads/scopestacks_public.pdf). Same performance characteristics as `alloca`, without the crashes. :)
POSIX Async I/O seems a strange choice, [given how poorly it's implemented by operating systems](http://blog.libtorrent.org/2012/10/asynchronous-disk-io/). Boost.Trie would be a great addition though.
Interesting article, learned something new, but it fails to answer an obvious question: Why is a manually defined empty default constructor less efficient than one implicitly declared by the compiler, while they're functionally the same?
I was wondering that, too. The only contrived example I could think of was how obscenely deep inlining and additional user code (even though it might do nothing) might make the inliner hit some size limit so it wouldn't inline as much as with some defaulted function it might expand at a later stage. This assumes that "more inlining"=="more optimizations"=="more efficient" which is at least questionable. I am not sure how much cases like this are an issue in C++98 with current compilers (or if at all).
While we're at it: why is X()= default; considered easier to write than X(){} ?
&gt; learned something new Wasn't it mentioned in one recent GotW?
I don't know why people even try to use ublas when there is eigen. Wasting effort in a somewhat dead component
It is easier because of uniformity with defaulting copy constructors, assignment operators and destructors. Also it declares intent explicitly which is always better. Consider if X has constructor that takes an int, now no compiler generated special member functions are generated. Which is better? X() = default; ~X() = default; X( const&amp;X ) = default; X&amp; operator=( const&amp; X ) &amp; = default; or: X() { }; ~X() = default; X( const&amp;X ) = default; X&amp; operator=( const&amp; X ) &amp; = default; 
&gt;Why is a manually defined empty default constructor less efficient I guess thats because the XL C/C++ compiler sucks.
He is writing for C++14 because time machine.
If working with something such a particles (all the same size) then you could get just as much performance with a slab allocator.
If you use std::vector::operator[], then it does not throw if you go out of range. If you use std::vector::at, then it throws. It would be nice if we could parametrize vectors on throwing on operator []. 
plain wrong! alloca returns stack mem; deallocates when leaving scope
[This one](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2013/n3656.htm), proposed by some guy and voted into C++14 by the LWG a month ago.
You don't really have to worry that much about using move copy constructor, as what you can do instead is a copy-by-value followed by a std::move(), i.e.: MyClass::MyClass(std::vector&lt;int&gt; lst) : m_lst(std::move(lst)) {} 
How is this even possible? The book is so new and shiny and starts with a 40% discount. I'm buying it!
Ouch still £30 quid. I guess they are expecting companies and the like to pay full whack, at £50.
You mean we'll have to wait 'til summer :/
Thanks, Just ordered it. Its not in stock, so who knows when I will get it. But it was cheap. Shipping was £5.48 to Finland. 
It might grow it quite a bit, but it wont change day to day programming style in the huge way C++11 changed it. (concepts lite is mostly for library builders to make error messages better for users, and the filesystem lib will be almost be identical to boost::filesystem, if i remember correctly)
So tempted to create an account _JUST_ to order this.
I am a library builder. Also a library based design is really good way of writing C++ so I suspect it will have a big affect.
Didn't see an obviously corollary for those of us on American soil. Even the publisher's site is charging full fare.
If that constructor took a const reference. Wouldn't it be the same number of copies ? (It would create a copy when passing it into the vector constructor)
`std::vector` can do move construction/assignment, so the user can do: MyClass(std::move(lst)) and save a copy. If you use a `const&amp;` the `std::vector` has to be copied at least once.
You don't now if it will die horribly silently or launch that nuke. That's the problem. 
I still have (i think the second edition) from the mid 90s. I still refer to it. It's worth every penny.
Is (or will be?) e-book version somewhere?
 template &lt;typename T, typename... T_Args&gt; std::unique_ptr&lt;T&gt; make_unique (T_Args&amp;&amp;... args) { return std::unique_ptr&lt;T&gt;(new T(std::forward&lt;T_Args&gt;(args)...)); }
So if you use move the compiler figures out its rvalue and uses the double reference copy constructor (I.e. move one?)
For a copy constructor, you could imagine the compiler leveraging memcpy() if all of the data members are PODs. For a default constructor... there's probably not much difference in practice. One consideration (I believe) is that only default-ed constructors may be called for const_expr values. There also may be other similar restrictions put on the compiler if you have a class hierarchy composed entirely of trivially constructed types.
Yes, `std::move()` simply returns an rvalue reference to the given object, which in turn then means the move construction/assignment is called instead of the regular one.
Still way smaller of any Java or .NET reference. I am ordering the book right now. :)
Not for the time being. Bjarne says it depends on the publisher.
I mean, the program crashes. So unless your program is supposed to abort a launch you don't have to worry, lol.
There's no correct mathematical answer. In OP's case, the answer is ignored, so, any number would do. In other contexts, it's possible that some value would be better than some other value.
My first thought was that logging every single directX call to a file would result in huge overhead, I guess this isn't the case though?
Meyers hasn't updated his books for C++11 yet. These are all C++11 books.
ah, good point, I didn't realize, good to see that C++ primer has been updated. I'd love to see something in the style of Exceptional C++ / Exceptional STL done on the C++11 features.
The other books are coming. In his Going Native keynote last year Herb Sutter put up a guess at a timeline for books. TC++PL was "Late 2012" on that list (it just arrived), Effective C++ was "2013-14?" and C++ Coding Standards was "2015?". Sutter also ramped up GotW again this month in preparation for the new versions of Exceptional C++. Slide 35 [here](http://view.officeapps.live.com/op/view.aspx?src=http%3a%2f%2fecn.channel9.msdn.com%2fevents%2fGoingNative12%2fGN12HerbSutterCpp11VCBeyondDay2.pptx) is where he gave his estimates. This is from February 2012.
Great, thanks for the info. I look forward to those books coming out, cheers.
I can tell you that Scott Meyers is working on updated books. I was one of several developers at my company interviewed by Scott for this very purpose. It is in the works, but he does not want to rush it. He wants it be as correct as he can get it first run.
I should also note: probably 95-99% of Scott's suggestions in the current books still hold in C++11. They are still worth following. (I do - and I write C++03 &amp; C++11 code day-to-day). The benefit you're going to see in newer editions is clarity about how/why to do things and covering move semantics. The vast majority of what Scott has to offer in the current editions is still perfectly valid.
That's awesome! Cool story. So you provided some input and material to inspire him?
What about *make_unique_default_init* and similar? Why is it missing?
Full article is [here](http://thbecker.net/articles/auto_and_decltype/auto_and_decltype.pdf) for those that don't want to click through 11 pages. 
Wait, when did you start getting exceptions for integer division by zero in c???
I bought Accelerated C++ used from amazon last year. Even though I had been programming in C++ since 1996 or so, I was self taught, mainly a hobbyist, and had a lot of gaps in my knowledge, and I found Accelerated C++ to be an excellent read. I originally tried to teach myself C++ from Bjarne Stroustroups The C++ Programming Language book, but found it really tough to learn from. After I had programmed in C++ for a number of years (learning from other books), I went back and re-read TCPPPL, and found it to be an excellent resource for sure, but it is very difficult to learn the language from. I still think that Accelerated C++ is a great book to learn from, even though it may not have all the fancy-smancy whizbang C++11 features it is still a solid book to learn from.
 int x = int(); // x is an int, initialized to 0 const int&amp; crx = x; // crx is a const int&amp; that refers to x x = 42; auto something = crx; // something is int ???? I understand the rationale, but this is yet another trap to watch. I really believe auto should have been constrained to generic programming.
Google says 1.5 million other people have used this word.
After I presented all the options (and explained why the array initializer forms were actually deficient compared to the Core Language), the LWG requested Standardese for only the simplest forms. As I despise garbage-init, I was delighted to drop those.
boost filesystem v2 will be used afaik, boost is currently on v3.
Aye, there needs to be an empasis that modifiers are not copied, which I am starting to see as a really good design decision. auto foo = bar; What is foo? The same *type* as bar and it holds a copy value of bar. const auto foo = bar; What is foo? It is a *constant type* of a copy of bar. auto&amp; foo = bar; What is foo? It is a *reference type* which references bar. It allows for more control since you only capture the type, but its definitely a nasty trap, since this can cause unwanted object copies. Edit: You can always easily add modifiers (const, &amp;) but its kind of a bitch to remove them if you aren't sure if they are there or not. If the modifiers were also copied with auto, how would you make a copy of an object? Example: SomeBigObject foo; do_something_dangerous_safely(foo); ------------- template&lt;typename T&gt; void do_something_dangerous_safely(const T&amp; obj) { //Make a modifiable COPY of object auto transaction_copy = obj.refence_to_some_big_data; //This can throw and corrupt the object! Do the operation on the COPY and then swap them if no exception happens dangerous_potentially_exception_throwing_function( transaction_copy ); using std::swap; swap(transaction_copy, obj.refence_to_some_big_data); } Its easy to re-add type modifiers since you know which ones you need in the piece of code that uses auto. Its hard to remove modifiers, since you don't know which modifiers will be transfered to the auto variable. Crappy example, hope it gets the point across. Edit2: I see I should have read the linked explanation since it describes what I wanted to say, only much better. Oh well lol. Edit3: Wow... I didn't know half of those details in the article. More stuff to learn!:D
Great, the site is down now...
Because C++14 is finishing up what was left out of C++11 due to time constraints. Another 3 years of wait would be horrible, best to split it into two parts.
From the project page: "The biggest issue in my mind is that printing to the log is rather slow, and this is apparently primarily due to printf being slow (outputting the log to a ramdisk didn't have much of an effect, and disabling logging makes everything rather fast, so the wrapping itself isn't an issue)."
Neat project. Thanks for sharing.
It's useless and creates the same sorts of problems. If you want to refactor a member away you generally turn it into an auto or pass it as a parameter. Why should this require a name change? If your functions and classes have so many variables that you can't keep track of it all without tricks like this then you need to work harder to create smaller entities. You're probably violating SRP at the least and almost certainly stinking of "Monolithic Function/Class".
You reduce this in a number of ways. 1. Use class declarations instead of including the headers to every symbol you need. This means of course not depending on silly typedefs like Ptr_t inside your classes. 2. Don't stick your private functions in your classes. It's almost never necessary. Simply create static/anonymous functions and call them with the members they need as parameters. You can even put your members in a substructure if you generally need them all: struct my_class { private: struct members { //... } impl; } Adds 0 overhead. It's only an issue when you need to create a bunch of protected functions. That's not generally what I've seen happen though.
Most shops I've worked in have coding standards at the very least and forced reviews most of the time. See some fucktard making a ginormous class and you say, "Fuck dude! Split that shit up!!! I'm a human, not a fucking robot!"
This. Way this. Most places that have the problems POGO describes also have numerous other failings that make their code difficult to work on at best. Looooong compiles because they include all their headers; huge classes that are impossible to grasp so people just hack at some area until it passes the rudimentary, manual test they came up with and hope for the best; total hatred of unit tests because they don't know how to make testable code... The list goes on. They seem to think it's all theoretical crap because they've never done anything but pound away on unsustainable spaghetti. It's why I code circles around a lot of people who should be smarter than I.
Uh...writing 'm_' is certainly a choice as well. Eventually some programmer will decide not to, and ruin what is a rather silly coding convention because people generally are irritated having to do pointless crap.
A little. Provided some feedback on gotchas I've encountered with my limited C++11 experience, such as unexpected captures of "this". He was at my company giving his fastware presentation (valuable, if you have a chance to attend). The application I was working on at the time was highly parallelized, and he questioned us on how we handling the threading/queueing, etc (long of it: we don't - we built on top of Intel TBB, with a little abstraction).
C permits void * to be implicitly converted to X *. (In C, you don't have to cast the return value of malloc().) C++ sensibly forbids this.
Reminds me of [this](https://medium.com/i-m-h-o/eef96ea6f4cb).
For a 1300 page book, the price is more than fair, especially with the discount IMO.
C is less typesafe. As it allows implicit conversions from void*. But just as importantly C++ style standard library offers typesafer alternatives to the C standard library. 
And what if the fucktard writer of the class left the company 5 years ago, and you need to understand the code *now*? Having m_ is useful. You might even have debugged straight into an unknown function, and you know instantly which of the vars are members. You can send me as many replies as you want (5 recently?), but nothing you've said has convinced me of anything. 
That's OK. I realized you'd rather flip out on people than reason anyway and decided it wasn't worth the bother.
Then why don't you reply to my point above? If you have such excellent reasoning skills?
[See here.](http://www.reddit.com/r/cpp/comments/1fci2v/an_interesting_parallel_pixar_and_c_philosophy/ca9ekz1) Also, I don't consider offering safer **alternatives** to be the same as being more restrictive, since you can opt not to use them if you need something more specific. That's like saying that introducing *snprintf* made C more restrictive, even though *sprintf* still existed.
A language is not just the core language but also its standard library. So yes, the C++ standard library is more restritive/typesafe than the C standard library. 
It's absolutely economic in nature. Consider [NASA](http://lesswrong.com/lw/6ww/when_programs_have_to_work_lessons_from_nasa/), with $1500 per line of code. Compare that to the [linux kernel](http://vladnevzorov.com/2011/01/31/how-much-does-it-cost-to-develop-a-line-of-code-sloc/), with $103 per line of code. NASA's code must be as bug free as humanly possible. That kind of accuracy costs money. 
Hasn't clang been c++11 feature-complete for a few months now?
http://gcc.gnu.org/projects/cxx0x.html http://gcc.gnu.org/onlinedocs/libstdc++/manual/status.html#status.iso.200x I wouldn't really call it feature complete until the standard library is also finished.
I keep this website as a reference for C++11 compiler support. http://wiki.apache.org/stdcxx/C++0xCompilerSupport It seems to be quite up to date.
Agree. Language Complete, but the library still lacks f.e. full support for &lt;regex&gt; afaik.
Clang has a feature complete build but it's in beta and won't be released until next month. GCC 4.8.1 was released to production just today and it is feature complete.
He was talking about clang.
 optional&lt;vector&lt;gadget&gt;&gt; load_gadgets() noexcept { vector&lt;gadget&gt; ret; // ... populate ret ... return move(ret); // important: move() here to avoid a silent copy } Wow, is it just me or is missing this "move(ret)" a new performance gotcha that is not only not caught by the compiler but also likely to make it through a code review? I couldn't find more info in the standard, but does the type of the returning parameter really determine if "return &lt;local object&gt;" will move or not?
I haven't tried it myself, but there are some indications that libc++ can be used with gcc. If that's the case then gcc 4.8.1 + libc++ should be C++11 feature complete, library features as well as language features, similar to clang 3.3 + libc++.
I haven't tried it myself, but there are some indications that libc++ can be used with gcc. If that's the case then gcc 4.8.1 + libc++ would be C++11 feature complete, library features as well as language features.
Apparently it can be, at least with the above example: $ g++-4.8.0 test.cpp -std=c++11 -nostdlib /usr/lib/crt1.o -lc++ -lc -I/usr/include/c++/v1/ -o test $ ./test Give me a real number! 42 float Give me a real number! foobar Invalid input Give me a real number! Not quite as convenient as clang's `-stdlib=libc++` flag, but it works.
Cool! I'm happy to be proven wrong, I'll get to make use of that soon enough I think ;)
I haven't tested this with anything more complex though (exceptions, rtti), so it might not work for everything - my `libc++` is compiled against `libcxxrt` and `libunwind` and I have no idea if they are compatible with gcc's exception handling code.
I remember reading somewhere that reddit chooses the picture with the highest contrast ratio, since those make better, more distinctive thumbnails.
It's required here because the return statement requires calling a converting constructor due to the fact that `ret` has a different type than the return type. For the purposes of that call, `ret` is an lvalue, and so that means a copy ctor, unless you make it a rvalue with `move` so that it can call the move ctor. As to whether it would be workable for the compiler to automatically treat `ret` as an rvalue (or more properly, an xvalue) when used as part of an expression in a return statement, I don't know. I'm sure you could come up with some scenario where that would have extremely surprising consequences, where it's worse than an accidental copy. 
Can you do block level compression?
Two concerns: ZipArchive archive = ZipFile::Open("archive.zip"); ZipArchiveEntry* entry = archive-&gt;CreateEntry("file.dat"); Why is archive a pointer when it does not appear to be, and shouldn't you be using a shared_pointer? It just seems to be using more pointers than I usually see modern code using.
Even if that's the case, it's still the wrong picture, no matter how high its contrast ratio is. 
In ZipArchive there is operator -&gt; which just returns "this". Therefore there is no difference if you use "." or "-&gt;" on ZipArchive. I've added it just only to have "consistency" between access operators (I know, it is little bit clumsy). And yes, I have the use of shared pointers in my to-do list. :) Edit: fixed example and removed removed obscure operator -&gt;
I wanted to use unique pointer for incoming istream, shared pointer for entries and weak pointer for holding archive parent in entries. &gt; You should have started with that. If you want to write C++11 code, you should completely stop using naked pointers. There was few factors which made my decision this way - usually nobody creates unique pointers for istream, because they are created on the stack and the second thing was, smart pointers would be slightly overkill for that small library. 
&gt; smart pointers would be slightly overkill for that small library. If they were part of an external library, maybe. But smart pointers are part of the language, just like naked pointers are. There's no reason not to use them. `archive-&gt;CreateEntry("file.dat")` returns a naked pointer. What do I do with it? Do I need to delete it at some point? Can I get rid of it, or does the library still need the pointed data? I have no way of knowing all that upon seeing the code. &gt; usually People are still discovering C++11. There's no such thing as "usually." &gt; nobody creates unique pointers for istream Indeed. When I need to return a iostream, I typically return a reference. It's even more true for `ZipArchiveEntry::SetCompressionStream`: Why the hell is the parameter a pointer? I see no reason to use a pointer here instead of a reference, be it in C++11 or in C++03.
This is a dangerous statement, because this point will inevitably be distorted to be a blank check on writing inherently insecure software where no checks are done whatsoever. Just like the premature optimization mantra ended up being distorted to be a blank check on writing inherently inefficient software.
Encapsulation, RAII. Your point is that you can also write unrestricted software in C++, but in reality you will use C++ components which use C++ features designed to impose these restrictions. Hence, C++ ends up being more restrictive, in spite of being almost a superset of C.
 const char* zipFilename = "archive.zip"; ZipFile::AddFile(zipFilename, "file.txt"); This is terrible. Why not encapsulate the archive on which you're operating? This might as well be a C API.
Not exactly true. The language is the core language. The standard library is a set of libraries. Just because a set of libraries are included in the standard it doesn't mean that they define the language.
You're probably right with the "suprising consequences", otherwise a rule of "implicit move when returning local variables" could have prevented this problem. Now that C++11 has move-semantics in addition to conventional copy-semantics there is just not enough visibility of what is going on. In light of the example above I think Herb Sutter's recommendation to "never return std::move" should be "always return std::move if you intend to move" and not rely on the implicit behavior.
You didn't read the whole article, did you?
I'd even go as far as generally proposing to avoid pointers altogether in cases where no unusual lifetime of objects occur. Simply return by value, (N)RVO (or moving) most likely will take care of it. One may then even enforce some stricter semantics and make objects non-copyable but moveable (I didn't look at the code in question in detail, this is just meant generally).
At various times I have read herb Herb Sutter and I believe Stroustrup state C++ is the core language plus the standard library. The C++ specification includes both the core language and the standard library. Implementers must implement both parts to be allowed to call themselves C++. Finally some of the standard library is required by the core language. Like std::type_info, std::initializer_list, std::bad_alloc, etc. 
A component doesn't suddenly become the language when it it moved from boost to the standard.
Greenspun's tenth rule (variation): *Any sufficiently complicated C or Fortran program contains an ad hoc, informally-specified, bug-ridden, slow implementation of half of Erlang.*
By the the definition above it does.
Thank you for pointing out that all! I've edited the project to return the smart pointer of ZipArchiveEntry instance and SetCompressionStream is now receiving reference instead of pointer. Edit: also, article is edited too
but why not use simpler and more convenient good-old OOP: ZipFile archive("archive.zip"); archive.addFile("file.txt");, 
so true; have an upvote
Seen the talk at C++Now, nice library. Recordings should be available in July.
The project looks cool. But the name sounds like old dial-up modem.
Without commenting on the overall quality of the code, here's your problem: if (c % i == 0) isPrime = false; break; The if needs braces. As it is, you're only testing if a number is even and returning that. Solution: if (c % i == 0) { isPrime = false; break; }
In addition to the dcoder_ and r_s correct answers, a more idiomatic C++ version: #include &lt;iostream&gt; using namespace std; bool isPrime(int n); int main() { int amountPrime = 0; for (int i = 2; i &lt; 100; ++i) { if (isPrime(i)) amountPrime++; } cout &lt;&lt; amountPrime &lt;&lt; endl; system("PAUSE"); return 0; } bool isPrime(int n) { for (int i = 2; i &lt; n; ++i) { if (n % i == 0) return false; } return true; } As for the algorithm, there are other, more efficient ways of determining primes, e.g. [Sieve of Eratosthenes](http://en.wikipedia.org/wiki/Sieve_of_Eratosthenes). 
Thanks for all of the awesome responses, and sorry for the poor formatting Just started C++ a few weeks ago, this is a lot of help.
Thanks a lot, that looks much cleaner.
Still, my primary concern was that I believed GCC to be unusable with other STL implementations. Full compatibility with libc++, STLPort, etc. seems to me to rest on the library implementation, so my original complaint was invalid.
I think that in the case of `CreateEntry`, the created object should live as long as the `ZipArchive` object that has created it, because the latter will need the latter when writing the .zip file on disk. In such a case, I'd store the `ZipArchiveEntry` in a container inside the `ZipArchive`, and return a reference. I agree with you on principle though.
Agreed. Also skip by 2's bool isPrime(const int n){ if( n &lt; 2) return false; if(n == 2) return true; if(n &amp; 0x1 != 1)//Divisible by 2 return false; for(int i = 3; i &lt;= sqrt(n); i+=2){ if(n % i == 0) return false; } return true; } Edit: added (n == 2)
&gt; if(n &amp; 0x1 != 1)//Divisible by 2 That looks like some high level wizardry. What's this doing? Two's compliment, I guess 
No, it just looks at the least significant bit. If it is zero, the number is even and we can rule it out. I would probably have written the condition as (n%2 == 0). The compiler would probably optimize.
That's really quite clever 
&gt; I've added it just only to have "consistency" between access operators It's not consistent, on should act on the value and one should act on the dereferenced value. Where there is no dereferencing it's better not to define it at all.
It is not terrible, general libs should have basic API's for making it simple to build your own objects. It takes about 10 minutes to wrap it ;) If you are forced to use one a class then it is not as general anymore. General libs should focus on flexibility
Is there any difference between using a bool function vs an int function in this case?
yes, using an int is wrong and happens to work and using a bool is correct and also works. Returning a boolean result as an int is a C throw back.
If you're going to be generating a large number of primes, I would suggest using a [prime number sieve](http://en.wikipedia.org/wiki/Generating_primes#Prime_sieves) such as the [Sieve of Eratosthenes](http://en.wikipedia.org/wiki/Sieve_of_Eratosthenes) . It's much more efficient.
questions at this level would be far better received in /r/learnprogramming
I'll post it there, thank you.
I wrote a QuickCheck clone for C++ called [autocheck](https://github.com/thejohnfreeman/autocheck).
yes. use a vector of functions that return string. main just pushes onto the vector. implement run which calls each in turn. empty string is successful, otherwise return non empty string of accumulated errors from the function and print, main returns non zero on error. a non over engineered solution that can leverage scripting.
I hope you are interested in non-preprocessor solutions just out of curiosity since the preprocessor can be a really a nice fit to build DSLs which can make writing tests much more bearable (at least as long as you don't need to change the test framework implementation).
I've been using [TUT](http://tut-framework.sourceforge.net/) for many years in many projects.
It's simpler than the author says. If you really can't update your sources, just change your tr1 headers to include the non-tr1 headers, plus this: namespace std { namespace tr1 = ::std; } that makes std::tr1:: an alias to std:: All your old code, with things in it like std::tr1::shared_ptr&lt;Test&gt; aTest(new Test); compiles fine. Problem solved.
While I think your question is interesting, I think it may be misguided in trying to avoid the preprocessor. Unit tests in C++ are always going to be a dirty thing to do, and what you want is something that works and requires minimal effort to write tests in (otherwise you won't write them). People are moving away from the preprocessor (in my opinion) because it creates code that can be hard to understand and maintain, but unit tests aren't production code and shouldn't be treated as such. Is there any reason I'm missing that using the preprocessor for unit tests could be bad?
Click on code; you can then browse or checkout the source with eg subversion. 
uhh. what? like i said. im new to all this 
Check out: http://sourceforge.net/ https://github.com/ https://gitorious.org/ http://code.google.com/ http://arxiv.org/corr/home and like everything else, try dropping it into google and see what happens "Source code -movie" https://www.google.com/webhp?hl=en&amp;tab=ww#hl=en&amp;sclient=psy-ab&amp;q=source+code+-movie&amp;oq=source+code+-movie
Primarily a curiosity, because a non-horrible solution would imply that a way was found to generate code that would automatically register the tests. I was looking at TUT just a moment ago, and it has template parameters indexed - which is an interesting idea to me.
Possibly one: You assert that the preprocessor generated code is hard to maintain and understand. This make sense to me. Now you say that unit tests aren't production code. Advocates of test driven development might argue that unit tests are a very important part of the production process, perhaps serving the same role that a proof does in math (not perfect analogy). By this reasoning, I would say that unit tests are critical supports to production code, and should thus be as easy to understand and maintain as possible. == The reason why I bring up the question is because such a method would imply a way to automatically register the tests - which would be a difficult to maintain portion of the tests without that. Now in TUT, I notice they used numbered templates on tests. I wonder if something like that could be exploited. 
No you dont understand. I know where to go to get the source code. I went to sourceforgeand downloaded a few c++ programs. But im looking through thr files and i dont see how to look at the code. How do i do that?
Source files are extension .cpp and .h. Open them up in any preferable text editor, but you'd have to feed them through a compiler to have them execute.
TR1 was always a little odd, it didn't even specify how the headers are called, thus [MSVC and GCC used different names](http://stackoverflow.com/questions/1228402/how-does-one-include-tr1). It's best to just skip TR1 and use Boost instead if C++11 isn't an option.
 typedef std::shared_ptr&lt;int&gt; spInt; Ugh. Don't do this :(
I definitely agree that unit tests are an essential part of a software product, but I think unit test code and feature code are very different and therefore should be held to different standards. In your feature code, it is important that the requirements of the product can change and the code be as modular as possible to accommodate these changes. Things like preproccessor macros can be bad here because they may be hard to maintain. Unit tests, on the other hand, exist solely to test the feature code. If you replace a module with a new one, it may be nice to keep some of the old unit tests (especially if you are maintaining compatibility with an API), but you'll probably need to re-write most of them anyway, so it isn't as important to maintain. Of course they need to be understandable and new engineers need to be able to maintain the tests, but I don't think relying on a framework which uses macros is nearly as harmful as writing your own macros in your feature code. Mostly, I think when selecting a unit test framework the most important things are how easy it is to write the tests and how many useful features the framework has, much more so than how it is implemented. Using macros, you can write code like TEST(TestFoo) { ASSERT_TRUE(SomeFunction()); } which is about as simple to understand and minimalist as you can get. This to me is much more important than using something which doesn't rely on as many "hacks" but requires you to jump through hoops like numbering your tests. == The issue of how to register tests is definitely an interesting curiosity, and something worth looking into, but not worth choosing a framework for a project over.
this is and was always the best advice. It's funny that the new tr2 will (hopefully) do the inverse with boost::file_system.
yeah mixing of camelCase and snake_case is pretty grotesque. :P
Markdown Protip: place 4 spaces in front of text to give it a monospace font. Any other space after those 4 spaces will be literal like this or this with 4 extra spaces (total of 8) Or, alternatively, you can surround each line with ` (grave accent or backtick, found underneath the esc button) `like this` Protip: [Markdown Primer](http://www.reddit.com/r/reddit.com/comments/6ewgt/reddit_markdown_primer_or_how_do_you_do_all_that/)
No it's not. One style for declarations the other for instances. It's a great aid for searching for a particular usage.
gross. also in post I was commenting on spInt IS NOT an instance, it's still a type. I agree that std::shared_ptr&lt;int&gt; myInt; is not quite so bad.
Excellent thought so. retsotrembla solution seems like a pretty big hack.
yeah I knew what you meant, I was just injecting some c++ humour.
Can you please mention the license you use on both your blog post and the README on BitBucket? It makes evaluating it for commercial use much faster than drilling through the repo for the license text (which seems to be the same as the zlib license).
to be fair, what you call snake_case is part of STL's shared_ptr. Your project might use some sort of camelCase. It could use CamelCase for typedefs (since they're new types and all type might be capitalized) and camelCase for variables, for example.
&gt; to be fair, what you call snake_case is part of STL's shared_ptr Yes, this is the strongest reason I have for using snake_case in all my projects, do as the standard does. Same reason, god forbid, I had to write Java, I would use camelCase. When coming up with a scheme for a project this sort of thing should be thought about.
I understand but sometimes it's not up to you, or it's legacy code, or you're working with a particular API that uses CamelCase (Qt, for example) or worse, several APIs with differing conventions.
Just wait for C++14: template&lt;typename T1, typename T2&gt; auto Add(T1 t1, T2 t2) { return t1+t2; }
Using an int for booleans is a hangover from the days [before bool existed as a type](http://www.informit.com/guides/content.aspx?g=cplusplus&amp;seqNum=176).
Do you have a link to the paper for that? Is it limited to single statement functions?
Top-level namespace is author's name ಠ_ಠ
[N3638](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2013/n3638.html). It's not limited to single statement functions, it seems that it can be pretty much anything as long as the return statements all agree.
I wrote a small C++11 library named unittest. It's not 100% complete at the moment, as I have to still fix up the CMakeLists.txt to allow for easy packaging (as well as change how I currently handle compiler flags). Unfortunately, it requires you to compile it, which doesn't hit the first part of your question. Were I to rewrite the library, I would have made it header only (and not taken my "design it to look like python's unittest library" so literally. Oh well. That's what inline namespaces are for.) You can find it [here](https://github.com/mnmlstc/unittest). A small example of creating a (really awful) test: test("my-test") = { task("assert-equal") = [] { self.assert_equal(1, 2, "optional message"); self.assert_throws&lt;my_exception_type&gt;([]{throw my_exception_type;}); }, task("fails") = [] { self.fail(); }, task("skip") = skip("always-skip") = [] { self.fail(); } }; There's a link to the documentation in the Overview. Please realize that the documentation that is there is not actually 100% complete, and while I tried to explain a few semantic differences between this unittest and others, I've not gotten feedback on how it works 100%. The output is also not all that great at the moment. When I find the time to work on it, I'll be giving it a once over, and then doing a full 1.0 release, hopefully sometime this month. Oh and one more thing, but the way it was written requires a *fully* compliant C++11 compiler (minus `std::future&lt;T&gt;` not working in MinGW in some cases, as I discovered during development)
Consider Boost ScopeExit. Now that it's powered by lambdas, it's really nice.
I refused to look at the code because it wasn't monospaced or indented. 
That's so ... weird.
I think an example will explain it best. What you see below is something similar to **setw**, but instead it specifies the maximum width to print from a buffer. What you're actually doing is outputting an object to the stream, and that object's **ostream operator** knows how to write the data to the stream. As you can see it's a two step process - first you construct a **maxw** object which captures the maximum width of data you with to output, and it has an ostream operator which returns a **maxw_stream** object whose ostream operator takes a const char* buffer and writes a maximum width of data from that buffer to the ostream. See below for example: #include &lt;iostream&gt; struct maxw { maxw(unsigned n) : _n(n) { } unsigned _n; }; struct maxw_stream { maxw_stream(std::ostream&amp; stream, unsigned n) : _stream(stream) , _n(n) { } std::ostream&amp; _stream; unsigned _n; }; inline maxw_stream operator&lt;&lt;(std::ostream&amp; os, const maxw&amp; m) { return maxw_stream(os, m._n); } inline std::ostream&amp; operator&lt;&lt;(const maxw_stream&amp; os, const char* data) { os._stream.write(data, os._n); return os._stream; } int main() { const char* buf = "abcdefghijklmnopqrstuvwxyz"; std::cout &lt;&lt; maxw(10) &lt;&lt; buf &lt;&lt; std::endl; return 0; } &gt; output: abcdefghij
assignment requires setw
Well now I have to ask, why do you need to do this?
I'm calling C from within a MATLAB function. The MATLAB simulation was way too slow, and the project has the specific constraint that the front end, including this loop, be written in MATLAB rather than C, which is what prevents me from just shoving this in there as well. From what I understand, I can't write another c function that calls srand prior to the loop, because they're considered 2 separate C programs, so seeding in one place won't affect the other. TL;DR: Matlab is the Flanders of programming languages. Stupid Flanders...
What do you mean 'assignment requires setw'? As in you're doing an assignment and you need to use setw; or the assignment of some value (ie: **operator=**) requires setw?
Nice library. C++ offers the required features to do high level programming as any other language, specially C++11. Much of the bad reputation is caused by people doing C level coding instead of using proper abstractions.
How will this work with type checking and header files?
Yeah I completely agree. The legacy code is easy, just do-as-it-was-done. Once you throw in Qt to a new project (or LLVM...) then I guess you have to decide, it's not easy decision at all. But for your average code the stdlib &amp; boost are going to be what I am working with the most.
I haven't seen anyone do that since university.
C or C++? if the former you are in the wrong place.
How platform independent does your solution have to be? ANSI C? STL? Just Unix and Windows? If just ANSI C, you could do something like this: try to open file "seed.txt" if file exists read seed srand &lt;seed&gt; else seed = time(0); srand &lt;seed&gt; end if //use rand() write another rand() to seed.txt Slower, but doable (in *ANSI C*), but I don't know how random that'll turn out eventually. As for C++11, you might look at the [new random number facilities](http://en.wikipedia.org/wiki/C++0x#Extensible_random_number_facility), especially [std::random_device](http://en.cppreference.com/w/cpp/numeric/random/random_device) If by platform independent you just mean unix and windows, you could *#ifdef* around [CryptGenRandom](http://msdn.microsoft.com/en-us/library/windows/desktop/aa379942%28v=vs.85%29.aspx) and [/dev/random](http://en.wikipedia.org/wiki//dev/random) or use some 3rd party library like [boost](http://www.boost.org). Other than that, depending on what your scope of "platform independentness" is, you'll have a really hard time. 
You need to reset with the current time and you seem to reset always with the same value, which always gives you same results. And time(NULL) is a common way for this.