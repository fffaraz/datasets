You shouldn't use memset_s. It's not in the C++ standard, and it's optional in C11 with extremely poor adoption - using it locks you into MSVC, and their version of Annex K doesn't even conform to the standard.
Unfortunately, there's probably orders of magnitude more crappy code like this out in the wild than there is good C++.
What's so bad about assuming an object has been moved when it hasn't actually?
Forward March! 
Kalmoc... didn't you use to work at google? You should well familiar with this policy yourself.
&gt; Free as in Free Beer. Not to be a pedantic ass but did you *really* mean to be backwards here? I believe the expression is typically ["free as in beer"](https://www.google.com/search?q=free+as+in+beer), i.e. it costs no money as opposed to "free as in speech".
there is no "consistency" issue here. The export always goes before the thing that is exported.
I really don't see the problem. Assuming an object has been moved from after it has been bound to an r-value reference is the conservative and 99% of the time right expectation. After calling move on an object I simply don't use it anymore until it is rest (e.g. via assignment or e.g. clear). I don't see a reality problem here. If on the other side I have to start wrapping my objects into some special types whose only purpose is to guarantee me that the object has been moved (a guarantee I don't need anyway) that is where for becomes more difficult to read and understand.
wxWidgets doesn't use Gtk+ on Windows but WinAPI itself. There's also wxQt btw.
Those screenshots are to small and unreadable (at first I though they were just miniatures that lead to the full images but it looks like they are not).
noexcept
It's easier to switch the compiler to clang++, than to switch the programming language to Rust. Or: Let's not compare Rust with C++ then, but with "Clang-C++".
My distro has a suppression file, but doesn't include the standard library for some reason. I made my own suppression file, and it now shows 0 leaks, and 72k suppressed. Thanks!
Thanks a lot for the kind words! Also, FYI, you can replace `is_struct(hana::typeid_(value))` by `hana::trait&lt;hana::Struct&gt;(hana::typeid_(value))`: https://wandbox.org/permlink/zBhdKXqzsfeZCgTL
&gt; If you think “the last combination is somewhat useless” - you’re right. But not having it [const rvalue] probably breaks some weird code. See [LWG 2485](https://cplusplus.github.io/LWG/issue2485) for the correctness problems that happen when generic code doesn't handle const rvalues.
Clang is available prebuilt for MSYS2, uses GCC for linking.
noexcept is incredibly weak, since it's completely optional and can be lied to. Furthermore, it says nothing about _which_ exceptions a function might throw.
Static analyzers can enforce it. Maybe even check the types? Not sure about that.
&gt;in clang 7 and gcc 9 and MSVC 2028 ! FTFY
I don't think there's anything wrong with it. You could handle the uncommon cases (maybe-consuming API) the same way the STL's rare cases do: By annotating the function name with "try_".
OK, then I agree, but I am worried about the cost to the implementers. If they are fine with this I am fine with this. :) 
&gt; Amortised complexity guarantees is so 1990s. I want absolute complexity guarantees. I think C++ needs to gain that if it is to remain relevant in a world full of Rust et al. C++ needs to move much closer to the metal. Oh look what do we have here: https://doc.rust-lang.org/std/vec/struct.Vec.html#capacity-and-reallocation
I'm still going to read it, but your poster needs much bigger type and less whitespace.
The author of `foo` in this example has the choice: Do I need to move from `value` or not? If yes, `MyValue&amp;&amp;` is a reasonable choice. If no, then it is not. If maybe, then it can still be a valuable choice if the author of `foo` documents when it will move, and when it will not. The most common (and useful) pattern for "maybe" is if `foo` has to first do something that might throw (like allocate memory). The documentation can say something like: &gt; If I throw, I won't move. You can catch the exception and recover the value if that is important to you. If `foo` passed by value, it couldn't make a API that gave the client that option. That's not to say that one should always pass by rvalue-ref instead of by value. Certainly not. I'm saying that both are useful tools to have in the toolbox.
It was printed on something like A0, so it was readable in person
I'll settle for good reflection 
Thank you for being pedantic!. I was not aware of the distinction. I owe you a beer :)
Can't wait until compile-time reflection.
&gt; Furthermore, a string_view class was added. Every previous method returning a std::string, was replaced with returning a rttr::string_view. See for example type::get_name(). Side note, because RTTR still works with c++11 compilers, I had to implement this class myself and not used the new C++17 std::string_view. I find this kind of reasoning a bit interesting. I mean, sure, there are tons of compilers out there with various degrees of C++17 support, but... In practice, aren't everyone using either GCC, Clang, or MSVC these days, [all of which have outstanding support](https://en.cppreference.com/w/cpp/compiler_support#C.2B.2B17_features) for just about every feature? It's not as if upgrading to a newer compiler is particularly hard. Sure, compiler regressions are a thing, and upgrades for sure adds additional Q/A time, but... At what point have we had enough, then? Why even pick C++11 as the supported version when C++03 compiler support is even more widespread? I guess I'm saying that at least for me personally, when I find myself implementing a standard library feature, it's a pretty strong indicator that I should just use the standard library feature instead.
Even if you have a recent stdlib it doesn't mean you're compiling in C++17 mode.
&gt; For example, std:: algorithms check the iterator_traits of the arguments. It'll decide the algorithm to use based on this. So a list.begin iterator has the bidirectional_iterator trait. You can't use algorithms like quicksort efficiently, so std::sort will use something like the cocktail sort algorithm. WTF did you get 5 upvotes? std::sort requires RA iterators and in fact std::list blowing up with horrible template errors is one of the motivating examples for Concepts. 
But, why?
Ignore this - waste of time - they never reply.
Not really. Reflection &amp; injection maybe. Metaclasses is an important but relatively small Delta on top of that (not to mention that it won't get standardized before 2023 and much more likely sometime 2026 or later)
I think there was a recent survey where it turned out that a higher number of projects is still using c++03 and c++11 is currently by far the dominantly used language standard. Especially on Linux many developers want their program compilable with whatever is the default compiler on the distribution they want to support (e.g. gcc-4.8 on Ubuntu 14.4). On Windows, not everyone is buying a new version of visual studio when it gets released. Personally, I think the c++ community should be much more aggressive about migrating to newer standards (maintaining backwards compatibility just for convenience is a vicious cycle) but even then, afaik there isn't a fully conformant c++17 toolchain out there yet (although I think all support string_view by now) so I understand why someone would be reluctant to switch to c++17 for a library you want to be used by others.
Because that's just work in theory. For example I had to add explicit support in order to compile RTTR in c++17 mode, because "noexcept" is now part of the function signature. Otherwise I would have get compile errors and warnings. When you now combine this with other dependencies, which has not yet been updated, you can not upgrade. So you stick with your current mode what ever this might been. 
So does or doesn't your library compile in c++17 mode?
Mind giving a few examples of what breaks when you switch standard? This is not something I've had much troubles with when working with legacy code. Does Visual Studio even allow you to target older standards in pre-2017 versions?
I wouldn't rate Rust's vector. Over complicated and over engineered. I'm actually thinking of something much simpler, or at least outwardly so. If they give me the study group I'll be asking for, it'll be one of the first algorithms we tackle probably.
It compiles fine with C++17. See all the CI servers, e.g. appveyor: https://ci.appveyor.com/project/acki-m/rttr/build/job/9ticxe86h37md83j#L63
1 - Not everyone uses clang or is targeting systems supported by clang 2 - At CppCon, I think CppCon 2015, Herb Sutter asked the audience how many used static analyzers. The answer was about 1%. Video is available.
Might still be more users than Rust to which we are comparing against here.
Rust was only one example, I specifically stated "languages like Rust", and not "in Rust". The point was about programmer languages with better type systems, that don't need to rely on external tools for basic safety validations.
&gt; This is why I tend to shy away from a decent amount of newer c++ features, I can't say with certainty that they do not use heap allocations. I am really curious what are those features... Please do not say smart pointers :) 
Clang isn't an external tool, it's the compiler. In languages like Rust it's also the compiler who checks for type system errors.
Right, I don't know why I wrote overload, thanks for the correction.
We are not talking about C11 here, be nice to little Microsoft.
What are the motivations for using smart references? 
That `#define sprintf` made me physically wince.
If you look at a recent feature table you'll find that VS 2017 fairs really well! Bad C++ standard support is a past for MSVC. They're riding the wave with C++14 and C++17. (Yes, feel free to bring up missing complete C++11 support... but the latest preview is as good as there).
As @goldsborough already indicated, the pdf was printed on a big piece of paper (in fact the size of 3 A0 sheets), which made it readable. Therefore, reading it on a computer screen (or smartphone / tablet) might not be ideal. Note that the link to the pdf links to a github preview, which totally screws up the rendering, resulting in a lot of empty space. I suggest to download the pdf directly (in case you didn't do that): https://github.com/erikvalkering/smartref/raw/master/poster.pdf. I'll also update the original post to link to that one instead. If you're interested in the usage of the library, you can also read the README.md page on github, which basically contains the leftmost column of the poster. The technical details, however, can only be found on the poster (or you can browse through the source code). I'm planning to write several blog posts in which I go into these technical details. 
I might be wrong on this, but I watched Andrew Sutton's talk and I have the impression that injection was designed as the foundation for the Metaclasses proposal, so when I say Metaclasses, yes, I'm with you on that. Injection is really the most important feature here.
bye hyperactiveinstinct
There are many cases in which you want to enrich the behavior of an arbitrary class, for example by logging the function calls to an object for debugging purposes, or implementing remote procedure calls. You can achieve this by overloading the `operator-&gt;` member-function. However, it is very likely that the original non-enriched class is already used in a considerable part of the code base, which would force you to update the uses **everywhere** to use pointer semantics. What you *actually* want, is to be able to overload the `operator.`. Unfortunately, C++ currently doesn't allow this. This library let's you do that anyway, though in a different way. As a result, the code base doesn't need to be updated, since the usage syntax didn't need to change. I also did a lightning talk in which I gave an example: https://youtu.be/Z9JabkvQSi0 
&gt; Are not generally available in other compilers Many languages don't even have "other compilers". If I write a compiler for Rust which doesn't check the types, but crashes at runtime on mismatch, it wouldn't change anything for most other Rust users. If it's "external" or "part of the language" is just nitpicking in my opinion and in practice doesn't matter for me.
lol. and then I realized the date :) http://www.lenholgate.com/blog/2004/03/
/r/template_magicians or /r/template_wizards?
Lots of languages have other compilers. Ada, Pascal, Modula-2, Modula-3, SML, C#, Java, Oberon. &gt; If I write a compiler for Rust which doesn't check the types, but crashes at runtime on mismatch, it wouldn't change anything for most other Rust users. Then it wouldn't be Rust any longer, since it has other language semantics. &gt; If it's "external" or "part of the language" is just nitpicking in my opinion and in practice doesn't matter for me. It matters a lot for those that get to use only the tools that other choose for them, and happen to work in teams across companies with different visions on code quality. Good for you that you can choose your own tools and have full control how it gets used.
[oh my](http://lmgtfy.com/?q=fmod+non+commercial+license)
Dekken I already did, but I had some confusion with the sentence, that's why I posted here. But you can help with this Non-Commercial use means that you do not make money from the product in any form including up front purchase, subscription, in app purchase or any form of sponsorship/promotion. If you have questions, please get in touch. If I add advertisement in app. Will it call commercial?
If you're making money, it's commercial. There is a free tier even for commercial apps, see [the FMOD licensing page](https://www.fmod.com/licensing) - you have to have a budget under $500k and need to register and include the logo in your project.
Are you making money from the ads? I think the answer is obvious, which also means you're making money from your app through ads. And that's exactly what it says you're not allowed to do. If you're still unsure, do as they said: shoot them an email and get a definitive answer. 
Looks like 2015 update 3 https://blogs.msdn.microsoft.com/vcblog/2016/06/07/standards-version-switches-in-the-compiler/
How would unique_ptr be a bottleneck, though? Initializing to nullptr?
By Len on March 4, 2004 Why do you waste my time?
I recently used Hana for some reflection related stuff (and it's been great!). IMHO, it would be great if Hana provided functionality built in to do some of the most common reflection oriented tasks. As it is, Hana provides all the raw tools for reflection, but you end up having to write quite some stuff yourself, even for the absolute most common use cases, like traversing a reflective struct. Hana is probably the best library in existence for compile time reflection, but it's almost easy to miss for that purpose because much of the API feels focused on compile time computation (of course, you can easily argue these are really the same things, but IMHO the feel, use cases, expected interfaces, etc, are different). The first thing I needed to do to use Hana was to write this: template &lt;class R, class F&gt; void reflect_traverse(R &amp;&amp; r, F f) { namespace hana = boost::hana; constexpr auto accessors = hana::accessors&lt;std::decay_t&lt;R&gt;&gt;(); hana::for_each(accessors, [&amp;](auto &amp;&amp; x) { auto getter = hana::second(x); f(hana::to&lt;const char *&gt;(hana::first(x)), getter(std::forward&lt;R&gt;(r))); }); } It's not long and for you it's probably trivial, but this took 1-2 hours to write. Reflecting over all members of a struct is such a common use case though that I think a function like this should be built into Hana, as should a deep traversal apply visitor, which is considerably less trivial to write.
 void foo(std::unique_ptr&lt;T&gt;&amp;&amp;) { /* do nothing */ } &gt; This function will not actually move from the argument Today I almost learned...why isn't the argument to `foo` moved?
I understand this isn't the point of the article, but in this case wouldn't the simplest way to add parallelism be std::reduce(std::execution::par, begin, end);
I used to think the old guard were overly conservative because they pushed process-based parallelism so hard. Now that I’m a couple decades into C++, I think they were right. Communicating Sequential Processes all the way. It doesn’t have to be literal processes. Basically, don’t try to synchronize access to the same memory across threads. It’s not just hard, it leads to bad designs. These days I use the same pattern all the time for parallelism: thread-safe queues feeding interpreter-style infinite loops. Mutexes, semaphores, atomics all have their place: 99% *“internals of a thread-safe queue”*, 1% *”expert-level parallelism that you should try really hard to avoid”*. And, if you see a call to sleep(), 90% chance you should refactor your design to only block on queues.
Well, they used to be Visual Studio centric for quite a while. The warning is still correct in the sense that the call to `memset` could be removed.
When calling you just construct a reference to the argument. The move constructor isn't invoked.
For map/set, you can just use the member [find](http://en.cppreference.com/w/cpp/container/map/find).
No, `foo(std::move(ptr))` is equivalent to `foo(static_cast&lt;T&amp;&amp;&gt;(ptr))`, the result is then bound to the reference.
Depends on the domain. CSPs are fine and already commonly employed for high bandwidth parallelism where latency isn't an issue and you can scale horizontally, but when latency does matter CSPs are basically worse than using a single thread. The use of atomics/mutexes are for domains where the bandwidth is fixed or limited but the latency matters a lot, such as games and other desktop consumer applications, embedded systems, financial trading systems, etc...
I agree. I'd also say that shared read-only or even modifiable data is fine, as long as it's only modifed only at rendezvous points - when all the async tasks are done and all the promises are ready for that rendezvous. It also saves locking of the shared data: the rendezvous is the lock.
I get the point of the article, but when it comes to performance optimization, then the very first rule is to always measure. It's not exactly rocketscience that synchronizing a variable across different threads is more expensive than a simple addition.
You are using the library wrong. `std::reduce`, man. Check out the CUDA Thrust library, which the parallel algorithms are inspired by.
&gt; Now that I’m a couple decades into C++, I think they were right. &gt;Basically, don’t try to synchronize access to the same memory across threads. It’s not just hard, it leads to bad designs. Maybe every programmer writing multithreaded code should be forced to write some MPI equivalent first. Since my background is in distributed memory parallelism, it never occurred to me that what you said wasn't obvious to multithreaded coders. What better way to make sure memory access is screwed up than by having it live in totally different processes and requiring explicit communication to access each other?
This is so critically important. The author used the wrong algorithm for the job and tried to shoehorn a reduction into what is supposed to be independent.
&gt; These days I use the same pattern all the time for parallelism: thread-safe queues feeding interpreter-style infinite loops. :+1:, it's much more efficient and very hard to get wrong.
&gt; What better way to make sure memory access isn't screwed up than by having it live in totally different processes and requiring explicit communication to access each other? note that "Communicating Sequential Processes" does not necessarily mean different OS processes, it is meant as "computational process" but they can entirely be in different threads.
but, but, but... threads are apparently bad now
While I agree he did it wrong I don't think that it's a stretch to think that someone who's inexperienced with STL &amp; parallelization would write it. I think most people, after thinking about the problem, could figure out to divide the problem and do core-X smaller bits but it's a question of writing the code to do that. I help newer coders at my work and the biggest problem I see isn't not knowing how to do something (assuming they're reasonably intelligent) but how to write it. I think the code he wrote /seems/ fairly reasonable to newer devs, and std::reduce is a function that's hard to wrap your head around.
I wonder if thrust will ever switch to much better approach of using output iterators for `reduce` instead of synchronizing with cpu (like cub)? It totally breaks any streaming attempts. Why std is inspired by thrust instead of cub? 
In my readings and my experience, high performance, low latency systems are built on ring buffers. https://traxnet.wordpress.com/2011/07/18/understanding-modern-gpus-2/ https://martinfowler.com/articles/lmax.html And at the lowest level, are graphs of packetized, serial networks all the way down (down to the hardware component level). https://fgiesen.wordpress.com/2014/03/23/networks-all-the-way-down/ https://fgiesen.wordpress.com/2014/03/25/networks-all-the-way-down-part-2/
&gt; I think there was a recent survey where it turned out that a higher number of projects is still using c++03 and c++11 is currently by far the dominantly used language standard. but are these projects going to introduce new libraries into their codebase now ? 
there is no work in the workers except a `+=` (which has virtually 0 cost), of course you're getting funny results --- you're just measuring the performance of atomics and locks. 
The tool is (was?) VS-centric, but the advice is sound for it and is a good hint as to what to do (use your systems secure wiping out of memory).
Yes, but the deal is, it **will go on** unless too!ing is used; to err is human.
Afaik this is not a new library. But I have no idea if it has any significant user base that depends on c++11 compatibility. Might be the author himself uses it in a c++11 project. As I said, I'd also welcome a more aggressive adoption of newer standards.
Yea, that is indeed true too! I also encounter ICEs regularly with MSVC.
Nevertheless: we now have tooling that finds it. And I think it's more than a fair deal.
This ead my thought as well. The example is so trivial that it almost isn't valid. Adding a set of numbers inherently has each step dependent on the result of the last; i.e. not-parallizable, unless it is broken into shards and use a map-reduce based solution...I'm curious what they expeced a language to do that would allow it to essentially recognize this and restructure your entire code path for you? In other words...how _would_ you parallize the above code without restructuring it to do the additions in shards and combining the result at the end...that's not concurrent expertise...just programming.
I'm not sure I follow. Do we need to get continually reminded that there are static analyzers out there?
Comments like this give the Rust community a bad rep. Just don't.
1 isn't about a macro for defining a function. It's about a macro renaming a function, hiding a function of a different name.
From the code snippet, the analysis of 7th looks wrong. It appears that the `memset` is supposed to just clear the struct before being used as an out parameter, but then there's a typo and the wrong pointer is actually passed - look at this *very* suspicious argument pair at the end: `&amp;out, sizeof(dout)`.
I agree -- but I also see what he's getting at: if you give people an STL algorithm with a magic flag that seems says more hardware is being brought to bear, and you end up slowing things down considerably, people are going to be surprised and confused. At the very least that includes this author.
Maybe they should learn how a computer works and write some assembly code for a few days? You know, before trying to write paralleled, useful, C++ code.
I have not yet looked into the paper for metaclasses. Is it in a stage safe to say, that it will definitely come into the standard?
&gt;In the meantime, HPX has something very similar. You don't need something as sophisticated as HPX for this. OpenMP's `reduction` clause will do just fine and is supported by every compiler you are likely to encounter.
OpenMP loops don't play well with non-array-like containers. What if you want to do something with a set or map?
http://en.cppreference.com/w/cpp/chrono/tzdb Did you just assume my preferred allocator?
I have used Howard Hinant's date and timezone in the past. The overall design and implementation feels like a work of art. Everything composes together so well and is easy to use. I am so glad that it made the standard!
How many serious code bases would hard code their dates like `auto d1 = 2018_y / mar / 27;`? IMHO most dates will be from some dynamic source like user input so library development direction should be guided more into that generic use.
Yup it definitely is. Doing parallel right and efficient (meaning almost linear performance gain) is an engineering problem and not really a coding issue. Things like openmp, etc seem to thread at too low a level which in the cases I've tested which ends up with very poor scaling..
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/u_vectrum] [Old c\/c++ code](https://www.reddit.com/r/u_vectrum/comments/87m5al/old_cc_code/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
&gt; thread-safe queues feeding interpreter-style infinite loops "Threads are for people who can't program state machines" -Alan Cox
I think the key here is what type the json record is.
Then you have to put more effort into parallelizing it. There's no free lunch, even if openmp is pretty close to a free lunch. 
Partial note to self to ask you later when I have more time, but the last time I used thrust (2010 maybe?) I found that to do things like stencil algorithms I had to use zip iterators, and the performance was atrocious and the code the ugliest thing I've ever seen. Does that sound right?
JSON only really has Number anyway, so it won't matter if the underlying type is std::uint8_t or std::uint16_t ... they'll all map to a JSON Number (JSON doesn't even distinguish float from int).
However, `int32(Value)` will truncate 64-bit, and improperly handle `uint32_t` underlying types.
But the original should have been implemented using std::accumulate. That’s the point I’m trying to make
`T* const` tells me that the pointer is const in this scope, e.g. we aren't doing pointer arithmetic, nor are we ever pointing to anything but what this pointer is initialized with. Just like saying `int const`is telling me that this `int` is initialized where it is declared and never takes on any other value in this scope.
You don't have to put more effort in when using parallel algorithms. That's their whole point.
 enum : long long {Foo = 0xDeadBeef0}; static_assert(int(Foo) == Foo); // Fails
&gt; &gt; do code in a generic way if there is no reason not to then you should use `using CWidgets = ptr_map&lt;std::string, CWidget, std::less&lt;&gt;&gt;;` : this way, map lookups will also work with std::string_view for instance
&gt; Does this make sense why SG14 would be a poor fit, or do I need to explain more? It's late, long day, I'm not sure if I am being clear or confusing, sorry. I get the vague idea, but some things are confusing(use cases, "persistent algorithms" (did you mean "persistent containers"?), etc.... But anyway tnx for the info, like I usually say with ISO speed I have 5 years to catch up with this, assuming it ever gets standardized. 
I've had similar confusing results with other magic flags, such as.openmp #pragma omp flags. Even with non trivial for loops.
You should be able to use `decay_t` instead of `remove_cv_t` and `remove_reference_t`.
What do you mean by `DoesInstantiationExist` exactly? Not mistaken with specialization?
C++ choosed technical consistency.
"Forget what you learned in kindergarten. Stop sharing" That's my first rule of threading.
It has `parse` and `from_stream`; what's missing?
Good replies, both. It got me wondering what the precision of a JSON Number is and the general consensus seems to be to [stick within the range of an IEEE-754 double](https://stackoverflow.com/questions/13502398/json-integers-limit-on-size/39681707#39681707). So yes, don't cast to int32 because that doesn't even exhaust the range of integers exactly representable as a 64-bit float.
damn, I never distinguished the place where the rvalue reference is created from the place where the move ctor is called. Those were simpler times, I was so young and naive...now let me read you blog post again...
Oh, indeed, but I thought you were suggesting that OP use HPX for something as simple as a reduction on a `std::vector`. Parallelism on node-based containers carries a lot of problems (any non-contiguous data structure has these same issues, but I'm focusing on the usual ones). For me, this is one of the reasons not to use node-based containers in parallel contexts *unless* they can be converted to a more amenable memory layout (vis a vis an array_list or segmented_vector). Once you have a parallel-friendly memory layout, you can rely on the same shared- or distributed-memory algorithms you've come to know and love (mostly). And algorithms aren't the only hardship faced by node-based containers. You also have NUMA conflicts and a higher possibility of cache coherence issues (or even thrashing, in really bad cases) when using non-contiguous structures. Depending on the internal representation of a single element, all of these can be very SIMD-unfriendly. I'm keenly interested to see what happens with executors between now and the next ISO meeting. I think this will be the gateway to getting better parallel data structures and algorithms into the standard library.
I think the point is, if parse and from_stream are what will be typically used, is there still benefit to making things like `/` work? And even if there is benefit, what's the _cost_?
That's no less true when using `#pragma omp`.
Yes, that's exactly my point. Libraries can make parallelization easier, but they can't help you make your algorithm correct.
I don't see any new release yet since 2015: https://thrust.github.io/. How's the progress on Thrust going and what's the roadmap? Any details available somewhere about that? I know you're working on it but the website's last version is still 2015 and the latest GitHub commit is from 14 months ago.
https://www.reddit.com/r/cpp/comments/7erub1/anybody_still_using_thrust/dq88pm5/
With GCD, PPL, TBB, Boost, and friends you can get fairly good results by thinking in terms of tasks, forks, and joins. But the thing is you must think about the flow of data and how much communication between tasks is necessary, it's a graph. 
I'm curious, which parts of it landed in the standard? The concatenation with `operator/` (`auto d1 = 2018_y / mar / 27;`) too? I thought that for `filesystem::path`, the "abuse" or "weird use" of `operator/` to concatenate paths is more or less okay, but dates, I am not so sure. Apart from that... Howard Hinnant's library is completely awesome! :-)
Sure, but the point is that a person just getting started won't automatically know what you've said. If all they know is some marketing literature that says "Hey just do this and it'll be faster and you don't need to worry about the details with this easy new API" then they'll be confused and frustrated by the results. And I do think that vendors can be a bit too eager to pat themselves on the back when they say how their latest new things solves all the problems and makes hard things easy. The post even starts out with &gt; if you’re doing parallel programming for living – please ignore this post (this stuff will be way way way too obvious for you)
That's the committee's job. Someone brings a proposal, we question it. Even if the work's already done, it still means more work for all the other implementors. Howard's proposal is great (that seems true for all his proposals), but it is still worth questioning. There are some odd corner cases (as with anything in C++). Maybe if you re-prioritize the use cases, a different trade-off could be made?
The Committee has been trying to avoid decay overuse, which is typically more expensive for compiler throughput. C++20 is introducing the `remove_cvref_t` trait to make this easier. The way to tell whether you need decay is whether you care about functions decaying to function pointers and arrays decaying to object pointers. When matching against a specific, non-templated type like MyClass, then decay can't affect the result, so you can be faster and just use remove_cvref.
The main problem here is the decaying of members inside the tuple for the provided `Foldable` model, right? Because this works out of the box: ``` template &lt;class R, class F&gt; void reflect_traverse(R &amp;&amp; r, F f) { boost::hana::for_each(std::forward&lt;R&gt;(r), hana::fuse(f)); } ``` The only problem is that you'll get copies of the members of the struct. That's a known problem -- and actually a very difficult one. For the same reasons it doesn't make sense to store references in `std::vector`, it's very difficult to _meaningfully_ store references in a tuple.
What tradeoffs were made, though? Again, what's missing? I agree with you in principle, but I think it's quite clear that in this case the implementation cost for these literals is extremely minimal and I don't see any obvious gaps in functionality, so I feel like I'm missing something here.
A one line std style library call is no more versatile than a pragma, that's the point. 
It works with non-random-access iterators unlike the pragma; this doesn't qualify?
Presumably every time there's a new chunk of subscribers that didn't see it before. I consider it a fair deal, and don't think that they are somehow undeserving of spreading the word around. They support many OSS projects and are very good sports about it. Exemplary, I'd say.
Couldn't agree more. One major purpose of libraries like Boost.Hana (or Boost.Phoenix) is to show where the libraries have to stop and where the language has to begin. For reflection, there's a clear understanding that we need compiler support and we're working on getting the C++ community something nice -- much nicer than any library could do.
I don't know. Maybe it's perfect. It might not just be a question of the literals, but of `/` or of separate `year`, `month`, `day` and `years`, `months`, `days` types. How much of the design stems from the example? Here's the only odd thing I've seen that is a bit odd: `std::chrono::seconds seconds_in_2017 = 2018y - 2017y;` That isn't actually seconds in 2017. It is seconds in an average year.
Every new idea introduced into the standard library adds some non-negligible overhead to all future maintainers of code that uses those ideas/features. It is always a wise question to ask if an addition is warranted. "The work has been done" is not a satisfactory answer. Good design is not just knowing what to add, but also knowing where to stop. As for the specific feature in question, I think date literals is good for demos/code snippets/exposition, but will be more useful for hardcoded data in test drivers. I would be surprised, however, to find it in any production code.
Here's one: https://github.com/ripple/rippled/blob/develop/src/ripple/ledger/impl/View.cpp#L67-L68 How many more would you like? (not that I'll go out and collect them for you, but it sounded to me like you're looking for an existence proof)
The cost is a bit more specification and implementation, but nothing at run time. You don't pay for a `constexpr y/m/d` if you don't use one. Not in code added to your program, or to the std::lib you must link against, nor in compile time.
The sane way to look at this is: ``` static_assert(2018y - 2017y == years{1}); ``` The fact that `years` has an implicit conversion to `seconds` is a historical accident that dates back to 1582. It just is. And uses of that fact are typically reminiscent of [false precision](https://en.wikipedia.org/wiki/False_precision#Examples).
&gt; restructuring it to do the additions in shards and combining the result at the end I mean a reasonably clever parallelizing compiler could do exactly that: recognize that this loop is just a summation and rewrite it as a parallel reduction.
And in this case it's not just a matter of the synchronization cost not being worth the parallelism. There's actually *no parallelism* at all in the 2nd and 3rd attempts. No two iterations can execute in parallel.
&gt; E.g. feature X will be active in this peer-to-peer network on `sys_days{2018/March/30} + 4h`. If you hard-code that constant into your code, how are you going to write a test driver for it?
With a test peer-to-peer network (we have that too).
To avoid suicidal thoughts well writing parallel code, pure functions are necessary. Side effects will only bring pain.
C1XX is now taking such shortcuts, yes.
I don't disagree, in the specific case, but what I'm trying to say is that _beyond_ simple examples it's not generally as simple as “oh I should have used this stdlib algorithm instead, and I would have gotten parallelization for free”, simply because your entire code is not _structured_ in a way to be amenable to that, and the accumulation/reduction/scan is “hidden” in your project structures. 
You still might want to combine a year, a month and a day, even if those are not hardcoded.
I didn't quite understand what they said about macro exportation, but I like the idea of incrementally merging modules and not waiting until everyone is happy with it. If coroutines make it, I think there is hope for c++20 to become the next c++11
&gt; I'm pretty sure this is intentional It is. :-)
&gt; In practice, aren't everyone using either GCC, Clang, or MSVC these days Just because you're using one of the Blessed Three doesn't mean you're using the latest versions thereof, for any number of reasons. Especially at bigger companies. Upgrading a version of a toolchain component requires updating large swaths of CI infrastructure, making sure all in-sourced development teams get the same upgrade (coordinating between IT departments and such), as well as ensuring that all third-party plugins and middleware are compatible and that all external contractors get all the updates required (including on their own CI infrastructures). Upgrading a version of *anything* part of the pipeline is insanely difficult in many larger orgs. Meanwhile, upgrading a library is as trivial as dropping it into a `third_party/` library and making it sure it builds on the very-strictly-versioned CI infrastructure. Thus getting `std::string_view` can be very difficult while adding a dependency on a library that includes its own `string_view` can be rather easy, at least for some organizations.
Very important "side effect" of this proposal is the iostreams support for durations.
FWIW, it is about what I am going to speak on ACCU2018 (in a talk titled "Multi-Coring" and "Non-Blocking" instead of "Multi-Threading", or using (Re)Actors to build Scalable Interactive Distributed Systems"), so if by any chance you're at ACCU anyway - you might want to attend &lt;/shameless-plug&gt;
Ok, I'll bite: what happened in 1582?
Ok, I'll bite: what happened in 1582?
Focusing on the `x += item` is missing the point entirely. It's a small, synthetic piece of work inside a loop, intended to illustrate a point.
The Gregorian calendar happened.
Not sure what you mean. Subtracting two sys_days afaik yields days, not seconds. And why would you apply a date cast to a duration?
Been there!
In general, I agree, but "my" estimates of applicability boundaries are different from "yours". From my experience, message-passing a.k.a. CSP a.k.a. (Re)Actors can achieve single-digit-millisecond latencies _easily_ (it is single-digit microseconds which are difficult to achieve with CSPs, though I've seen a real-world (Re)Actor-based system with characteristic latencies of the order of 10-20us; however, reducing it further to &lt;1us is indeed very difficult, if at all possible :-( ). This, in turn, means that for all-domains-I-know-about-except-for-HFT (="High Frequency Trading"), CSPs are fine (this certainly includes games and desktop apps; as for embedded systems - they're way too broad to generalize). There are some reservations, and yes - there is a problem of a One Huge State, but in general - CSPS tend to do very well: first, they can be made deterministic, and therefore testable (with an option for post-mortem production debugging), and second - they tend to outperform mutex-based sync at each and every corner (TBH, with thread context switch - including cache invalidation costs - taking from 10K to 1M CPU cycles on modern multi-cache-level CPUs, speaking about mutexes and latencies at the same breath is a major fallacy; for a real-world example of non-blocking-CSPs-vs-blocking - see nginx-vs-apache). As for atomics - yes, non-blocking stuff can outperform CSPs, but complexity is usually that high (and gains are _relatively_ low) that doing it is worth the trouble only for some _very_ demanding apps (once again, HFT being a prime example). 
&gt;The point is that saying that "hey, all you need to do to get parallel is to add std::par to a call" (without having a clue of what you're doing), is deadly wrong. So your argument is basically "people with no clue about X will get X wrong"? That's reasonable but not very insightful. &gt; As OP says in big bold letters, "Writing parallel code in C++ is still a domain of the experts." Clearly not, it's a single call to `std::reduce`.
Right, thanks - it's too early ;) But anyway, converting years to second was already possible before that.
&gt; That's reasonable but not very insightful. Well, with certain people claiming otherwise (see [MSDN] ref in OP) - it deserves to be said explicitly. &gt; it's a single call to std::reduce. Even in the trivial case of adding elements of the array it is not that simple (hint: std::reduce has semantics which is different from both for_each and accumulate, and adding par will lead to results being non-deterministic even in an obvious case of adding floats; so is any parallel algo, but this is a yet another non-trivial result of parallel ops which has to be taken into account). More on it in the promised follow-up post. 
The Julian calendar had numerous irregular years, so you couldn't just convert years to seconds without knowing _which_ years.
&gt; and adding par will lead to results being non-deterministic even in an obvious case of adding floats; so is any parallel algo, but this is a yet another non-trivial result of parallel ops which has to be taken into account But that has nothing to do with parallelism, only with how IEEE754 floats work. You could demonstrate the same result by simply adding the array backwards or piece-wise.
I only skimmed the Wikipedia article, but afaik, the Julian calendar was even more regular than the Gregorian (one leap year every 4 years without exception).
Concepts, even without natural syntax in time, coroutines, and macroless modules? Probably, yeah. Not to mention the library side.
&gt; But that has nothing to do with parallelism, only with how IEEE754 floats work. I'd argue it is "how _any_ float works" (implicit rounding is non-linear pretty much whatever-we-do-about-it :-( ). &gt; You could demonstrate the same result by simply adding the array backwards or piece-wise, no parallelism involved. Sure, but without parallelism, one given program will be (most likely) still deterministic, so knowledge of this phenomenon wasn't really required; however, adding parallelism exposes this issue (and can easily cause all kinds of trouble, at least as unit tests will start to break :-(, but also in some cases algos may start to diverge accidentally! etc. etc. etc. ). 
Wish I could attend :) I'd watch a recording if one is made available.
Sorry, you're right, I was thinking of the Roman calendar.
we need executors in c++20.
It is not always entirely obvious at the call site that the types involved will provide a day/hour. It's very easy to fix though since duration's constructors do not narrow if you're using integer types: ``` return seconds(last-first).count() ``` Which has be benefits of giving you seconds even if first and last are hours, giving you a compiler error if they are milliseconds, and being far easier to figure out what the unit of the returned integer is.
&gt; I'd watch a recording if one is made available. Not sure about the video (last time ACCU, unlike CPPCON, recorded only 2/3rds of all the sessions); however, slides+kinda-transcript will be made available on my blog ithare.com for sure. 
FYI: The purpose of the chief function was to return days, not seconds (which is exactly what it did) that's why I am a bit confused by /u/OmegaNaughtEquals1's post. That aside, yes I think it should be best practice, to always explicitly stated the expected type before calling `count()` (and even better to never call `count()` at all).
That assumes someone would have written the non-parallel version like this in the first place. I'm pretty sure you'd have either used std::accumulate, in which case the parallel version would have done exactly what you want or you would have used a range based for loop which requires a bit more work to transform anyway. I don't think the author was confused. In fact, I'm pretty sure he knew exactly what he was doing, otherwise he probably would not have come up with that example in the first place.
Have you actually seen this in the wild? Such an example seems more to be the result of malicious intent rather than insufficient knowledge. Also, writing correct and efficient code in c++ is generally not easy (I don't think you have to be an expert thought)
I think you have to know exactly what you are doing in order to come up with a broken example like that.
But how does the author get from: " it is non-trivial for complete novices to transform badly written sequential code to parallel code" to "Writing parallel code in C++ is still a domain of the experts"? There is a huge gap between the two, and I'm still not convinced, a novice would write that kind of code to begin with.
Nevertheless, isn't this more related to the parallel programming model being used,i.e. https://en.wikipedia.org/wiki/Parallel_programming_model than C++ libraries specifically? As I see it, the programmer must first study how the underlying sequential algorithm will be parallelized (if it is possible) and then choose the appropriate implementation. My point is that to the uninitiated, choosing the correct implementation is tricky with any language, not just C++.
Ideally, it would compile it down to some sort of SIMD add.
&gt; Howard Hinant's date and timezone yes
&gt; transform badly written sequential code to parallel code It seems that you think that std::accumulate was The Only Right Way(tm) to code it; I'd say this is arguable, as there is no discernible difference between for_each and accumulate in the sequential code, so I'd argue it is more about style than anything else - especially if the code is more complicated than simplistic example given; in particular, if we'd have to calculate two things over the same array - coding it efficiently in accumulate style would be way too bulky, though for parallel stuff it can become justified. More importantly, even in this case a replacement of std::accumulate with std::reduce is inherently non-trivial in the real-world (hey, there WAS a reason WHY they renamed it to reduce: because there is significant difference in semantics(!) between the two); in a very simple example, even floats are not exactly associative, which means adding par makes reduce-over-floats non-deterministic(!!) - which in turn carries TONS of strange implications, most of them VERY non-obvious for complete novices. &gt; There is a huge gap between the two Sure, one can argue that there are 50 shades of gray between "complete novice" and "expert" - but this is purely terminology (and terminology disputes can last forever-and-ever while adding absolutely nothing to the point). &gt; I'm still not convinced, a novice would write that kind of code to begin with. As complete novices (who ARE the target audience) here on Reddit have already noted - OP does provide useful insights for them; this is The Only Thing which really matters. 
 Notice: get_currentuserinfo is deprecated since version 4.5.0! Use wp_get_current_user() instead. in /home/sankeld/public_html/davidsankel.com/wp-includes/functions.php on line 3830 Love me some outdated WordPress
nice to see that they're finally putting gifs ! 
In that case I completely agree, it is simply disingenuous for anyone to claim that parallel programming can be made easy by using any new programming language construct or programming language for that matter. Parallel programming is easier on paper than concurrent programming, since the former is deterministic but it is still hard because it spans different architectures. Unfortunately a catch-all solution for parallelization on every single architecture does not exist. Even when dealing with a single type of architure you can get close to easy parallelization depending on your application, e.g. for single-node shared memory data/task parallelism, OpenMP is quite easy to grasp and use but again it is not without pitfalls, for example it is harder to reason about container types without random-access iterators, the fact that is uses directives might not be convenient for some and so on.
Is it wrong that I still use `&lt;thread&gt;`?
Note that this can be installed with MSYS2 pacman very easily, and works out-of-the-box with mingw64 . 
Wish they’d just stick macros in. All that’s needed is a decision on visibility rules and conflict resolution. Why leave devs with four more years of modules side by side with crappy headers just containing out-of-context macros?
Very nice! The clang tidy integration looks amazing!
I for one am very disappointed that they didn't use a better format like WebM or APNG.
It does but I'm less convinced now after trying. Clang-tidy is super expensive. So you fix one warning using a fix-it and then wait 20secs until you can do the same for the warning on the next line as the file is reparsed. This makes using it rather tedious Not much qtcreator can do about afaict
I like the integrated Model Editor, good Job!
I am aware of this post, as I mentioned: "I know you're working on it". However it's from 4 months ago and it also says "I can't get into details yet". So I was asking for an update &amp; more details now, because he advised here to use Thrust, and my reply is that before using a library that hasn't been active in 1-3 years and is supposedly active again, it would be nice to know some details.
Cool! Congrats and thanks for all the hard work! :-)
Awesome! Does upgrading Clang-based code model helps intellisense to work with variables declared by `auto` too? 
Thanks for this one! Exactly what I was looking for to get an old project into shape :-)
&gt;All that’s needed is [...] ... and also change `import` the C++ declaration to `#import` the preprocessor directive.
Can you provide Conan package please?
I'm pretty sure, no one is suggesting that macros can influence a module that is being imported. Imho it would still be a bad idea.
You also mentioned the last release being 2015 and the last GitHub commit being 14 months ago, so it didn't really appear that you were aware of that post since you didn't also mention _it_. ;-]
Looks like this mostly could've been done using regular function overloading.
&gt; How many serious code bases would hard code their dates like auto d1 = 2018_y / mar / 27;? any codebase that would do some JIT compilation
Influencing this kind of thing is (among other things) the purpose of macros. It should be perfectly legal to do so if they were exported (which can be translated by "allowed to be leaked through module"). I have two points : * it's a bad idea to allow leakage of macro through modules (hence turning importing into a preprocessor directive instead of a core language directive). * it's also a bad idea to define rules to restrain macro leakage when compiling.
Is it possible to donate custom Colour Schemes?
The type of the result of `last - first`, where both arguments have type `sys_days`, is `days`. My advice for this code would be to keep it in `days` instead of converting it to `int` with the `.count()`. If you wanted the answer in seconds you could `return seconds{last-first};`.
Right. Deduction guides are an important component for both `zoned_time` and `time_of_day`. The github library has `make_zoned` and `make_time` which do nothing but provide template-deducing factory functions to make up for the lack of deduction guides in C++11/14. The proposal dropped these because they aren't needed in C++17 and later.
The paper has: auto ymdl = year_month_day_last(today.year(), month_day_last{ month{ 2 } }); Here's another supported syntax to do the same thing: auto ymdl = today.year()/February/last; Both work, both have the same performance and do the same thing. The choice is simply stylistic.
Crosspost, because I didn't get any reply on the CMake sub.
Wouldn't it be better to expose version as `string_view` and zones, links and leaps as `span`?
Did you try OpenMP?
No idea how, but I'll find out 😅. I agree integrating it into your projects should be a no brainer.
His example was taken literally from cppreference, so it was something beginners are likely to do. Don't get me wrong, I'm not relieving anyone of their responsibility to profile, I'm just saying we're going to see a lot of these "optimizations" in the future. 
Ability to export results of static analysis to some kind of report would be awesome.
Your example is not exporting a macro. It just has a compilation branch in one module and a local macro in the main translation unit. I haven't read the latest Google proposal, but I'm pretty sure the point is not to turn a module interface unit into a glorified header, where preprocessor information can flow in both directions. IIRC, the whole discussion essentially is about whether a macro defined in moduleA (think qt macros, include guards, assert etc) is visible in a translation unit that imported that module. I would be really surprised if anyone would suggest information flow in the other direction, as that would make the whole module Idea pretty much useless.
a const T&amp; provides the same const-view semantics as a T* const except the latter can be nullptr, which either introduces a bug /or/ mixes up two different responsibilities.
Sure! All contributions need to go through codereview.qt.io though, which is a bit painful to set up:-(
We are using it right now in our firmware to format timestamps for logging in the correct timezone The main complaint we have is that it relies on global variables to read the timezone data from the OS. I'd rather if it used a context pointer so that I can control all the state associated to date. I want that our logging is safe to use during teardown of global variables, after `exit()` has been called, so that we can put logging in destructors of things and debug problems. When date itself relies on these same global variables instead of using a context pointer, it makes it harder for me to use date in our logging, which is one of the most obvious use-cases of the library. I'm not saying date isn't better than the alternatives, I mean, we are still using it. but this is a pain point for us.
C++ makes already far too many compromises to stay compatible with decade old code - let's not add more of those to the language than we absolutely have to.
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/87slov/cmake_sub_seems_to_be_dead_how_to_handle/dwfa5e6/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Love to see a (relatively speaking) more fully developed out of the box IDE for C/C++ that's Linux compatible, guess I'll give it another try once it's progressed more, even though I'm not a huge fan of JetBrains IDEs in general. Something about them seems so sluggish and unappealing to me, idk. Anyone feel/felt the same?
The globals tear down should happen in reverse order of construction. If you manage to initialize the tzdb first in your application, it should be last thing to be destructed in the atexit chain. A gratuitous call to `get_tzdb()` will do the job.
I can agree with that point of view, but we don't always have the luxury of restructuring the entire code base to embrace that point of view. Sometimes you just have to play the hand you are dealt. In such circumstances, I'll declare my pointers `const` to make it clear that I'm not modifying them, just like I declare other local variables `const`.
Well, the central thesis is on east-const - and that we should restructure our west-const codebase to east-const for a benefit (and not just hide behind consistency with tradition). So if you're not willing/able to alter your code to improve it... Then you're not going to be able to use east-const either.
Good to see that ISO did not crush Gor's spirit... yet. 
Thanks for sharing this extensive report!
Yeah, that would be great, but I'm not sure that C++ gives us a way to make sure that it is ordered before any other global variable? Right now we have patched date to just leak the tzdb... it is a hack but the only downside of this that we can see is that valgrind reports it as a leak.
great point about tooling... for years I have been shouting in my head that C++ needs a breaking change where most of the migration is done by some clever tool that understands old C++ and new C++. 
Love the new Clazy integration! It made some very good points in my hashes and vector iterators... Nice job!
What happens if your code already uses suffix "_y"? Is there actually a way to avoid a clash? 
Compute3D is a class, thus you should be searching for Compute3D. Calculate is the name of the class instance within the specific scope. arg1, arg2, arg3, arg4 are the arguments passed to the constructor of Compute3D. Compute3D(...){...} should be what the definition of the constructor looks like. (roughly)
Not OP but to me the text rendering looks of poor quality.
In John's post, he's arguing for a change in idiom, but I don't see where he's instructing you to restructure your entire code base. I suggested that such could be done safely by writing a check for clang-tidy. You could probably also write a check for clang-tidy to replace uses of pointers with uses of references. I'm not aware of any tool that does this currently. So when I say I may not have the luxury of restructuring the *entire* code base, I'm talking about practicality and risk and not whether or not I am allowed to make edits.
Can't you call `get_tzdb ()` in all initializers of variables that must be init-ted after tzdb?
I'll give this more thought. The C++ standard "leaks" the std-streams (`cout`, etc.), presumably for much the same reason.
I last tried CLion just as it was exiting preview. It was very sluggish for me at that point in time. I now use Qt Creator and I haven't looked back.
In the github libary `_y` is in an inline namespace `date::literals`. You can choose not to expose that namespace (or `date`), or you can use `year{2018}` in place of `2018_y`. Both syntaxes work, and have the same meaning, behavior, and performance.
Clang tidy and Clazy integration is _nice_, but right now it's way, way too slow to use as it runs in the same thread as the other clang code model stuff. If it were migrated to run asynchronously and not interfere with the code model that'd be much better, but I've no idea how hard that would be to do. SMOP, eh?
Thank you very much!
Thinking about this some more... It may be that the correct thing to do is go into the logging header and put the call to `get_tzdb()` there? Is this what you are saying? I think that guarantees that any global variable who uses our logging, and therefore includes the logging header, must appear after the call to `get_tzdb()` in any translation unit. James McNellis writes here: https://stackoverflow.com/a/3746249/3598119 &gt; Global variables in a single translation unit (source file) are initialized in the order in which they are defined. &gt; &gt; The order of initialization of global variables in different translation units is unspecified. I don't know if this is merely *true of all compilers that James McNellis uses*, *true of all major compilers*, or *required by the standard* though. I don't recall reading this guarantee in the standard but maybe I've forgotten it
&gt; I think that guarantees that any global variable who uses our logging, and therefore includes the logging header, must appear after the call to get_tzdb() in any translation unit. I don't think it is enough, imagine that you're calling `log()` in the destructor of a class, but the destructor is declared out-of-line. You would include the logging header in the implementation file, not the header for this class. The global variable leaving in a different object you can't guarantee that the logging header will be included there. 
The contrast of the vertical slider in the dark-theme is still an issue: https://bugreports.qt.io/browse/QTCREATORBUG-15865 That would be such a trivial fix, I wonder why it and other GUI issues are being ignored.
I'm not sure tbh. This is what it looks like: template &lt;typename T&gt; struct IsRTTREnabled; And then if a struct has rttr registered I do: template &lt;&gt; struct IsRTTREnabled&lt;MyStruct&gt;{};
&gt; Under design review; some controversy. Well expected! 
Gor is an indomitable spirit. :) 
I see, thanks
Every enum is its own type so you'd probably have to overload the function for every single enum. Also, for every struct, you'd have to create its own saveload functions and mention all the variables again. I used the visit_struct project to allow me to basically use something similar `for constexpr(auto&amp; members: struct.members)`. I am probably wrong but this seemed like the most straight forward method.
No kidding. All I want is my symbols tagged... our cmake build is so convoluted (generated by a bunch of python scripts at runtime) that I can't get clion to properly index all the files in the project. 
You don't have to rewrite the entire code base to depreciate T* const in favour of other language features though.
I would name it then something like `has_rttr_enabled` and alias member to `has_rttr_enabled_v`. Don't use PascalCase when mixing with standard library, **especially type traits**.
The intellisense with auto have already worked (for me) before. The added feature in this release is that you can see the type of the variable by hovering over it.
Hehe yep! I'd really love Thrust to pick up some momentum, as a standalone library mainly (not part of CUDA). Hope this happens, as it's quite an awesome library. Too bad it went completely dead in 2015.
Wooow! This is awesome! WSL support! That is sooo awesome. And on top of that MSVC support too. This is an amazing release. I also love the breadcrumbs. Congrats on this release!
I didn't understand the last tip, what is the difference between your 'type_safe::object_ref&lt;T&gt;' and 'std::reference_wrapper&lt;T&gt;' ?
OK, I missed that when I skimmed the article and when I was searching it again to see if he was telling you to change the entire code base. John's talking about doing it incrementally over time. Eventually, that does mean restructuring the entire code base; I'd argue that if you want to make this change everywhere that it's better to invest in a clang-tidy check that makes the change all at once and keeps it that way forever more in an automatic manner in the same way that people use clang-format or artistic style to keep the formatting style consistent in an automatic way. I've noticed in your summarization of my points that you keep subtly changing the language to make my propositions sound more silly and your propositions sound more reasonable. To me that's a cue that this conversation has ceased to yield any more useful benefits for me. If you want to have the last reply on the thread and I'll be happy to let you have it.
Sort of. You can open them up now (in the linked blog post as a new feature) but you'll get a reduced functionality set since it still uses cmake to infer project information and without it , it can't do as much. 
What’s qt creator 
Compact, fast and very powerful cross platform IDE for C/C++. 
It's a C++ IDE made by the same guys who make the Qt GUI toolkit. It has built-in support for Qt-specific tools and files, but it's also just a nice development environment for C++ even if you don't use Qt.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/87v38a/learn_programming_web_development_networking/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
thanks! I'll give it a try.
&gt;Subtracting two sys_days afaik yields days, not seconds I have no idea how I messed that up, but I did! Indeed, `operator-` returns `days`, not `seconds`. &gt;And why would you apply a date cast to a duration? As Howard [noted](https://www.reddit.com/r/cpp/comments/87kspk/c_calendars_and_time_zones/dwf4cgh/), they should have just left it as `days` instead of converting to `int` via `count`.
Yeah. The latency in JetBrains IDEs is very noticeable. Especially if you are not on a high-end machine with everything on a fast SSD and with lots of RAM. Recently I've opened single project (very simple single header + single cpp/main) in both QtCreator and CLion and the latter consumed consumed almost 2(!) Gigs of RAM (well, more like 1.7), while it took less than a 100 MBs in QtC. I'm sure the difference becomes less noticeable on a much bigger codebases but I doubt it'd work any better.
Maybe - if we get modules - c++ could finally cut ties with c, define a proper FFI and consider a few other breaking changes.
In regular cases CLion detects Valgrind path automatically. But with WSL case it's not working easily, so we ask to set it manually.
I've not ever experience sluggishness with CLion, although I have dealt with it in KDevelop. I try out CLion for a while, and then ultimately move back to vim (and just use CLion as a visual debugger when I need it). So with that out of the way... I understand what you mean about their IDE's always being a little 'off'. I think their IDE's are outstanding in a lot of ways, but I much prefer the VS/KDevelop style of IDE. But I think that's just a preference/comfort thing more than an actual issue with their IDE. For example, I love datagrip, and in a lot of ways I think it's better than SSMS, but when I'm designing new tables and so forth, I still fire up SSMS because there's just something a little... off about the way datagrip does things. But for querying and the like, it blows SSMS out of the water. hopefully that made sense.
Yeah, you can't even buy this thing. You can only lease it for some time. No, thanks.
The “fallback” aspect is what bothers me with Jetbrains. It’s true you have a perpetual license, but you lose a whole year of update if you exit their subscription model. I don’t know of another company with such license, it’s turning me away from their products when so many free alternatives are good enough.
 auto obj2 = std::move(builder).finish(); // okay I get the idea of this, but I think code ugliness is not worth the safety.
I don't think there is any way to determine this, no. There currently aren't ways to determine if a function is being invoked at compile time or runtime; see [here](https://stackoverflow.com/questions/28683234/determine-constexpr-execution-during-compilation-or-at-runtime), [here](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0595r0.html), and [here](http://open-std.org/JTC1/SC22/WG21/docs/papers/2013/n3583.pdf). Similarly, there is no way to inspect if a function is constexpr or not. (`std::is_literal_type` is the closest thing, but that is deprecated in C++17 for not being all that useful, and I don't think it can be used to solve your problem). GCC provides the builtin `__builtin_constant_p`, which detects if an expression can be evaluated at compile time, but even with that I wasn't able to solve this. All that said, this seems like it might be an example of an XY problem. Why exactly do you think you need to know at compile time if a type can be copied at compile time?
"good enough" - so they're not as good. 
Also the only reason his code can compile at all is its testing ints and int like types. floats/doubles or user defined classes afaik can't be called in a manner such as.. template&lt;typename type, type a = type{}&gt; Although if there were a way to check any constexprness of a variable or class's ability with sfinae I'm sure it'd be possible to magic up the rest of the requirements. And as far as I can test/find out along with what you've posted there is not, best that can be done is a compile error.
I'm not sure modules help much. It's not just breaking compatibility with C, but with the existing C++ code.
If you don't mind also requiring that the type is constexpr default-constructible it's pretty straightforward, but I can't think of a way around that. I'm on mobile at the moment but I'll post code when I get home.
With user defined operators, that sounds more like a change to overload resolution and integral promotion. Which would be welcome, except for the very large amount of code depending on the existing behavior. When it comes to subtle breaking changes, I'm actually worried more about equality than relational operators. This change would make intVal == -2147483648 fail, for instance. 
Do people really write that (with the intentional thought of "negative i is handled", as opposed to "I forget about i being negative") And isn't the mapping of negative integers into unsigned actually implementation defined? (Still needs to be beyond the positive integers though.)
Eh. I think the posted blog went out of their way to engineer slow code by using synchronization primitive inside one of the algorithms.
No. Thrust started off as a research project and has since been productized. The backend is based on CUB, which is carefully tuned. It's optimized for CUDA like any other accelerated CUDA library.
We'll be adding future&lt;T&gt; based asynchronous APIs instead.
Care to elaborate on what specific performance issues you have with CUB?
I provided an update here: https://github.com/thrust/thrust/issues/888
/r/gatekeeping "You can't write useful C++ code unless you write a computer in assembly"
I think this was mentioned in another thread: The idea would be that maybe you can compile different modules in different modes / language versions. I'm not fully convinced that this is would/should allow significant breaking changes to the language, but I find the idea intriguing. Regarding this particular case (comparison of signed an unsigned) I'm with the committee with this: It might be a breaking change, but in must cases, where that would be relevant the code has probably a bug, and where it doesn't, it is easy to adapt.
Sure, if you got a fast Internet connection. GIF has enormous file sizes, lower quality and no streaming support. A better format like the ones I mentioned would offer lower file sizes and higher quality at the same time.
How are you guys doing on C17/18 or whatever it ends up being called? and fixing threads in general, do you think you'll support threads.h, like, ever? or will it be another 15 years?
Of course, the code is intentionally rather extreme (it is always necessary to go to certain extremes to illustrate the point), but OTOH... the code was (pretty much) taken from cppreference.com. Moreover, that's what LOTS of MT-newbies will be doing even without that "hint" from cppreference :-( (some of them even commented here on Reddit that this was insightful for them - which is The Only Thing(tm) which matters TBH), so the message "DON'T believe it is as simple as adding 'par' to the std:: call" is IMNSHO quite justified. Otherwise, we'll be getting even more crashing (and/or cycle-wasting) programs then we have now. And TBH, I am sick and tired of MT-related crashes (starting with my article in C++ Report published 20 years ago about a bunch of crashes and deadlocks - AND about a slowdown by a factor of up to 100x(!) - in no less than STL implementations by several major compilers, which was caused EXACTLY by "using synchronization primitive inside one of the algorithms". And things do NOT improve in this regard - recently I found pretty much the same problem in one of 2016 WG21 proposals. And **if WG21 members and std:: library implementors cannot get their MT right, we cannot expect Joe Average programmer to do any better, this is for sure**). 
Will _Generic support be included with that?
Seems unlikely, as that's a C thing.
Ah, excellent! Thanks, that's very helpful.
What's the overall community attitude towards the 2D graphics TS? It seems a bit strange to me, not really a bad idea, but I agree it might not be the best use of the committee's time...
I've encountered that very idiom quite intentionally written in recently-produced code. Coding with those kinds of "tricks" in mind is not at all uncommon in the "machine cult" programmers (common in games and embedded, and I'm sure elsewhere) that see C++ as a bloated intermediary between themselves and raw CPU instructions. These are often the same kinds of programmers who also rant about how C is the superior language because it requires less cognitive overhead when you're trying to code directly to the machine.
&gt; Have you actually seen this in the wild? About _specifically_ this lib - it is very new, so cppreference is one such example (though some here on Reddit seem to say "hey, it is just a sample, which nobody will take seriously" - believe me, they will). As for NOT-EXACT-BUT-SIMILAR stuff of using mutex to "enable parallelism" (causing crashes, deadlocks, or 100x slowdowns in the process) is a _recurring theme even within std::_ (!!). Back 20 years ago I wrote an article in C++ Report about such bugs in several STL implementations (causing crashes, deadlocks, and 100x slowdowns). Worse, things do NOT improve in this regard: very recently, I found pretty much the same bug in one of WG21 proposals (!). And _if WG21 members / std-library-devs can make this kind of mistakes - we certainly cannot expect an average app-level developer to avoid them_. Dixi. 
From [the Ranges TS](http://en.cppreference.com/w/cpp/experimental/ranges/algorithm/sort): template&lt; ranges::RandomAccessRange Rng, class Comp = ranges::less&lt;&gt;, class Proj = ranges::identity &gt; requires ranges::Sortable&lt;ranges::iterator_t&lt;Rng&gt;, Comp, Proj&gt; ranges::safe_iterator_t&lt;Rng&gt; sort(Rng&amp;&amp; rng, Comp comp = Comp{}, Proj proj = Proj{}); Invoked identically to what you're proposing. What's wrong with it?
I was talking about bad performance of thrust, not cub. Cub is awesome and fast. Thrust can be fast too, but it loves synchronizing with cpu and allocating memory too much, preventing you from doing send\receive and computation overlapping. 
 if they make me write template &lt;Sortable __S&gt; void sort(__S&amp; s);, then I'm just going to write template &lt;Sortable sortable&gt; void sort(sortable&amp; s); anyway and they can kiss my ass. Nobody is forcing you to write `template &lt;Sortable __S&gt; void sort(__S&amp; s);,` (which is identical to the second sort you wrote, just with a different name for the type), this is an example of what `void sort(Sortable &amp; d)` is equivalent to. 
One of the example codes in the stackoverflow question does pretty much this but I'd be happy to see your version.
Lovely stuff I can't afford. :( Back to VIM for me. 
Can you elaborate more on how you do cluster deployment? I think I'll be in a similar situation soon.
You can inspect if a function invokation is constexpr in some cases, and that is a good reason why compilers can't just add `constexpr` qualification to methods in the standard (e.g. `std::accumulate`). See here if you can default-construct the argument types, works since c++11: https://stackoverflow.com/questions/15232758/detecting-constexpr-with-sfinae What's true is that it is impossible to do for arbitrary expressions of unknown, arbitrary input types. But what is being asked here is also much more specific than that. In this case, we have two advantages over the general expression problem: - The expression in question has not been evaluated and we know how to do so in possible templates. - The expression only involves one specific type To answer your question about use case: Basically, just because we maybe can? My interest is mainly in the language question, being able to get as much information from the compiler as possible without the standard explicitely requiring it to. But from a practical standpoint it might be useful to enable certain function templates in meta-programming. For example one could build a wrapper type which only copies its argument if this is truly zero runtime cost but otherwise takes as reference. The downside to taking as reference is that it imposes additional linkage requirements on its argument.
Look at Qt creators generic project import. It doesn't have "advanced" features like add new file to project, but it allows you to edit your project with working auto completion and refactoring
Floats are only disallowed as template parameters, but can be constructed in constexpr context. So a workaround for this is: &gt; template&lt;typename type, int=(type{}, 0)&gt; 
Smalltalk and java use lowerCamelCase for methods and UpperCamelCase ir PascalCase for classes and refers to the system as camel case C# jist always capitalizes the first letter
It was probably the thread for Vittorio's trip report. As I recall, he discussed how he brought up Rust's take on this.
Did you miss the 3+ competing proposals to this? Whichever you prefer, it's not fair to discount the others. Personally, I was all for the original syntax you describe, but I have to say Herb's paper is a really fair compromise for my tastes, even if the braces remain mandatory in the future.
Cool! That's awesome. Thank you.
I think there is the fear that it will become the next std::regex. Hard to maintain and not used for serious work because there are better solutions already available
Here's what I had in mind: template&lt;typename T, bool IsDefaultConstructibleV = std::is_default_constructible_v&lt;T&gt;&gt; struct constexpr_instance; template&lt;typename T&gt; struct constexpr_instance&lt;T, true&gt; { constexpr T operator ()() const { return {}; } }; namespace detail { template&lt;typename T&gt; struct copy_helper { template&lt; typename V, typename = std::enable_if_t&lt;std::is_same_v&lt;V, T&gt; &amp;&amp; std::is_copy_constructible_v&lt;V&gt;&gt; &gt; explicit constexpr copy_helper(V const&amp; v) : val_(v) { } constexpr operator bool () const { return true; } private: T val_; }; template&lt;typename T&gt; auto attempt_copy(int) -&gt; std::bool_constant&lt;copy_helper&lt;T&gt;(constexpr_instance&lt;T&gt;{}())&gt;; template&lt;typename T&gt; auto attempt_copy(long) -&gt; std::false_type; } template&lt;typename T&gt; using is_constexpr_copyable_t = decltype(detail::attempt_copy&lt;T&gt;(0)); template&lt;typename T&gt; is_constexpr_copyable_t&lt;T&gt; constexpr is_constexpr_copyable_v{}; The glaring drawback is that one needs an actual constexpr object to attempt to copy, so non-default-constructible and non-constexpr-default-constructible types will give false-negatives OOTB. An extension point to support non-constexpr-default-constructible types occurred to me – one needs to specialize `constexpr_instance` for those types to construct some instance, though it need not necessarily be valid (i.e. uphold invariants) since it will never actually be "used". Fortunately this is done non-intrusively, and I suspect most types supporting constexpr are constexpr-default-constructible anyway.. Online demo with tests: https://godbolt.org/g/4mmeC5 I haven't looked at the SO link yet; I may add an answer there later if this ends up being appreciably different to what's posted there already.
Let me get this straight. you're literally rewriting your preprocessor, and you or whoever is in charge of that has such an ideological hateboner for C, that you're STILL refusing to support the latest C standard... When are you motherfuckers gonna drop MSVC and just use Clang like everyone else?
That's quite cool. Is there anyway to tell the status of a proposal? As the blog post mentions, there was 2nd revision submitted to Oulu in June 2016 but I can't tell what the response was. I did a quick grep through the minutes from Oulu at http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/ but I don't know if I'm looking in the correct place?
Is there a specific reason for unique_ptr by value? Does it impact the correctness/performance of real code?
I don't know. I've always used unsigned, but find Sutter's, Stroustrup's, and others' arguments to switch to signed persuasive. I have existing code which uses large unsigned values as named constant sentinels. If I switch to signed, then the sentinels become negative, but the existing checks will still work. Under the proposal they'd break, suggesting that I shouldn't make the switch.
This is pretty cool! You claimed zero overhead in the readme, probably a good idea to throw some benchmarks in your upcoming blog post! Please include non optimized builds, as they obviously will have overhead and it is good to show your users how much of a hit they will take there.
Data type with size of 1 byte. Meant to store a single character code (0 to 255). `char* ptr` is a pointer to-char and usually used for C-string: The string is an array of `char` for the characters of the string, terminated by a `char` with value 0. The pointer points to the first `char` in the array. For example a string literal (`"test"`) is a `char` array with values 116, 101, 115, 116, 0. When used as an integer, it may be signed or unsigned depending on the compiler. For that purpose, `unsigned char` and `signed char` should be used instead (or `std::uint8_t` and `std::int8_t` from `&lt;cstdint&gt;`)
This isn't the right place. &gt; For C++ questions, answers, help, and advice see r/cpp_questions or StackOverflow. That said, SO would rail on this question as-is because there's no research effort and it's unclear which aspects of `char` you're looking for.
If this were a joke it would still be low effort
If you pay for a years subscription, it is the same as buying it since you get that perpetual license. You either have to pay per year up front to get new perpetual versions or complete a year of monthly subscriptions
`char` is short for 'character'.
Lol I'm still new at c++
http://en.cppreference.com/w/cpp/language/types
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/880qdc/explain_char_in_c/dwgz1r4/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Thanks! Good idea about benchmarking the non-optimized builds, didn't consider that.
Fine, I'll fucking email the motherfucker my comment then.
Well it really depends on what you're doing. You can setup very complex deployment configs or for something simpler like highly programs to train paralellized ML models that are just copied over to the cluster and a batch file to submit them with qsub is run. Try looking at the JetBrains docs for Deployment Configuration and Remote Interpreters. They have complete walk throughs for how to set both up.
&gt; Edit: Is the above implementation is wrong and clang buggy? Or is it correct and an answer to the question? Anyways, language lawyers highly appreciated. I don't see why dereferencing a nullptr would be any more legal at compile-time than at runtime. ;-]
You don't write computers in assembly: computers are written with chemitry and physics.
Noooo! Don't push modules away! ;_;
wtf is a borrow type? std::string_view/boost::string_ref are just references to sub strings. And that's all. Don't make things overcomplicated.
This strikes me as an overly restrictive set of rules that would diagnose a lot of completely valid uses of these types. Calling this "a sin" is extremely excessive: auto sv1 = w.getName(); Of course you won't get into trouble with `string_view` if you follow these rules - you'll hardly be able to use it at all!
&gt; Regardless, if f is a function so annotated, the result of f must not be stored into any named variable except a function parameter or for-loop control variable. For example, `auto x = f()` must still be diagnosed as a violation. I get where you are coming from, and this is certainly a good rule of thumb, but I think it needs exceptions: If you just use the variable (that should idealy be a constant) because you need to read the value two or three times and getting it is a bit less trivial than in your example, this is fine. Of course the same amount of care that should be put into all reference-variables needs to be had here and it should not be a common thing. But compare these two code-snippets: std::cout &lt;&lt; vec[i].foo().bar().str(); fun(vec[i].foo().bar().str(), whatever); another_fun(vec[i].foo().bar().str()); std::string_view str = vec[i].foo().bar().str(); std::cout &lt;&lt; str; fun(str, whatever); another_fun(str); You have to be carefull here, but the second version is much more readable IMO.
Speak for yourself, if you are looking for HAZMAT, look at pretty much anything that C++ has taken from C, there you will actually find things.
I don't get the hate for `std::regex` at all, it's awesome that we have it in the standard and the next time I regexes I will certainly use them.
I guess it's about the implementers side, and you have made the point pretty well for why the current situation is far from ideal.
I would care a lot more if they finally added an acceptable alternative to GLOBs. And no, writing out files by hand is not one. And the argument that some plattforms would have to rerun cmake every time if they did is also uninteresstings, since thats exactly what I'm doing right now anyways.
https://www.reddit.com/r/cpp/comments/821b17/til_that_sg13_graphics_mostly_are_the_basement/dv6p9ct/
Did I? It's certainly lost on me then – every part of what I pasted appears _necessary_ to me, and certainly an improvement on the emulation in ranges-v3.
Throw in "fix minds of those people who still think it is a good idea to use mutexes", and we'll have a deal ;-). More seriously - a good feature should, in addition to allowing doing things the right way, also PREVENT doing things in the wrong way, and current STL parallel stuff fails BADLY on this account :-( (except for std::reduce() - though even reduce() has its own quirks such as being non-deterministic for floats :-( ). BTW, I heard that there are long-term plans to introduce HPX-like future-based stuff into std:: ; do you know whether there is any truth in it (THAT would be a HUGE improvement, as it is MUCH more difficult to misuse)? 
I see all the proposals.... I read the whole report. The difference between the TS and all the other proposals is that the other proposals force verbosity on people. The TS allows people to choose. This is a key factor when one of the most important concerns for growing c++ is its verbosity. Concepts can be both powerful for language writers while being simple for end users, but these guys won't have that. Even the simplest indicator requirements are not necessary to an end user, but they want to remove the option from end users based on some misguided sense of needing to protect the users from themselves &gt;&gt;&gt;&gt; because there were concerns that you can’t tell apart an AFT from a non-template function without knowing whether the identifiers that appear in the parameter list name types or concepts." Sorry but that isn't a good excuse.
Is it me or does this github icon look like ET? 
Yeah I know! I really appreciate your efforts. I really hope modules gets into C++20 though.
Hey Timur, why are you concerned about the on-disk/cached compiler-specific format? Whatever that it, it's not for distribution. So, the entire source code would have to be available for my project that your tools are parsing. So, I fail to see the concern here. The only other thing that comes to mind is the precompiled bundle that may (well, already is with VC++) distributed with the compiler for the new module world. But again, that's an optional thing as the normal C++ code must still compile. That is, you can always brutally expand the traditional includes that comprise the new module-optimized environment, parse that an cache it. (that would be another frontend-specific cache).
Your comments in the other thread made me look a bit closer at the regex implementations. The gnu one is horrible, both performance and security wise. It's trivial to find inputs that cause stack overflows or hangs. The llvm and boost one look better but are both slower (and not as good tested?) then re2. And than you have hyperscan, which is even faster but seems rather new and chokes on some inputs.
You only realize how annoying it is once you try glob support and stop doing things manually. These days I hardly edit buildfiles. Also, I don't know how it is in CMake, but for me personally the killer was forgetting to list a header: the project still builds fine locally so you only detect the omission once you make a source distribution and try to build that.
I want to setup my build-system once and not have to worry about it afterwards. (In fact setting up cmake is already more complicated than it should be, but that is another thing.) And there are no valid technical reasons why it shouldn't work like that (prooven by the fact, that you can get to that point with GLOB, though everybody insists that they should not be used). Everything below that (quite low) bar is clearly not a good tool.
I like your use of `operator bool` and your extensive test suite. I would code it is such: namespace detail { template &lt;int&gt; using Sink = std::true_type; template&lt;typename T,bool SFINAE=true&gt; struct ConstexprDefault; // { static constexpr const T&amp; instance() { return *static_cast&lt;const T*&gt;(nullptr); } }; // uncomment if you want to risk clang undefined behaviour template&lt;typename T&gt; struct ConstexprDefault&lt;T, Sink&lt;(T{}, 0)&gt;::value&gt; { inline static constexpr T val = {}; static constexpr const T&amp; instance() { return val; } }; template&lt;typename T&gt; constexpr auto constexpr_copiable(int) -&gt; Sink&lt;sizeof(Sink&lt;std::size({ ConstexprDefault&lt;T&gt;::instance() })&gt;)&gt;; template&lt;typename T&gt; constexpr auto constexpr_copiable(...) -&gt; std::false_type; } [https://godbolt.org/g/gir412](https://godbolt.org/g/gir412)
It happens in unevaluated context, that could surely change things?
Personal note: change avatar ASAP :)
And when will people stop complaining about lack of tabs and accept that there are other valid ways of handling the list of open files?!
It's one of the fairest subscription models I've seen. You pay for a subscription, and you get a perpetual licence for the ~recent version you paid up for. If you terminate the subscription, then you don't have a perpetual licence for the newest shiny version. Absolutely shocking that there would be an incentive to keep you subscribing! You still have a perpetual licence for the software though, which is vastly better than most subscriptions. How is this a problem? I'm unwilling to spend money on most subscriptions, but this is one I would be happy to spend money on.
Don't blame CMake, blame MSBuild and xcodebuild for not supporting that. CMake is *just* a project generator for those.
Agree I struggle to so how it's possible to implement it in a way that works with those generators
What happens when it globs some temporary file or a copy of an existing file and it ends up breaking things? There are good reasons not to blindly glob and include the results in your build.
The solution is very simple: Run cmake every time you build your codebase. that fraction of a second is not going to hurt at all compared to the time spend actually compiling the code.
Simply run CMake every time you build. It's fast enough to begin with, and those IDEs (?) would likely add support sooner or later anyways. At the moment there is however an active incentive for them not to add it, because even if they did, nobody would profit from it.
Why would you have temporary files mixed with into your source-tree? If that is an issue, your problems are elsewhere. And of course you need a reasonable project-structure anyways, if the build-systems forces you to have that, that's a feature.
I think providing for more cool updates and features is enough of an incentive to keep the regulars subscribed. I doubt most people would get out of the model considering how frequent considerable improvements are made. Anyway, I was just voicing my views on it. ¯\\_(ツ)_/¯
Actually, Visual Studio supports CMake. But it doesn't solve the glob problem since so format CMake generates to supports them. And CMake isn't fast i' large projects since people will make network requests, search libraries and more from it. It can be quite noticeable. 
&gt; Whatever that it, it's not for distribution. That's actually up for debate. A number of actors want that format to be standardized across implementations. Which would certainly make it distributable. Also keep in mind that "distribution" is a vague word. Do you mean distribution to end users? Distribution to co-development teams in other offices? Distribution to other engineers in your office? Distribution between the build farm cluster? Distribution as in checking-in precompiled large modules so you don't have to recompile it again? If the format is strongly standardized, though, all of those would be possible. &gt; So, the entire source code would have to be available for my project that your tools are parsing. It's not about the source being required or parsing being required; it's about _who_ does the parsing. That is, if I write a tool today to extract info about a C++ TU, I might write a parser myself. Or plug in an API like Clang's, at which point my tool can only handle whatever that version of Clang can handle; the tool and the actual compiler the user is using wouldn't necessarily match up in terms of supported C++ features, nor configuration (defines/includes/etc.) without extra work. With a standardized BMI format or library, a tool can just consume the output of whatever compiler the user is using. Writing these tools becomes massively easier and the resulting tool more accurately reflects the user's environment. This is kinda similar to the language server protocol work that VSCode did (and that a ton of other editors are picking up now). The idea is to turn a language/tool problem from an M*N space into an M+N space, by communicating between tools using a standardized mechanism rather than an ad hoc tool-specific plugin interface.
Sorry about that. I shall disable the inbox replies for this question now.
&gt; That's actually up for debate. A number of actors want that format to be standardized across implementations. Which would certainly make it distributable. This is not up for debate at all. Please refer to the TS - there is no format spec - the artifacts are in a compiler-specific format I attended the meeting when the TS was presented - it's not a distribution system.
A standardized BMI would certainly be useful, but it is not mandatory. It could easily be added later on. Also, I wouln't force compilers to use a format, but encouraging compiler writer to add functionality export and comsume BMIs. For example, I could easily imagine some sort of "compiler server" where it caches all module information in memory. Notice that there is no BMI in that case! I great use case for a "standard" or a "common" BMI format would be IDEs and refactoring tools. I would however first push for a common format, and look of standardization worth it.
&gt; Actually, Visual Studio supports CMake. Which is one of the reasons for me to assume that they would actually ad support for GLOB-like-features. &gt; But it doesn't solve the glob problem since so format CMake generates to supports them. Sorry, I don't understand what you are trying to say here &gt; And CMake isn't fast i' large projects since people will make network requests, search libraries and more from it. CMake is very fast if it detects that there is little work to do (so: on re-runs). The first time you run it, you will usually compile the entire codebase anyways making CMake again a non-issue. 
 constexpr std::string_view when = "never";
&gt; Please refer to the TS I'm not talking about the TS. I'm talking about what people have pushed for _in addition to_ the TS. 
Forgetting to install a public header is a problem that exists with CMake too, and the inverse where you mistakenly ship a private header that you don't need as part of your 'public API'. In general the solution has been to either have build tests you run on your source distribution, or some form of heuristic test that you run after building your package.
The GLOB support is not for the Visual Studio IDE but for MS Build. Also, builds should be deterministic, I doubt MS engineers will appreciate implementing this feature! And if CMake doesn't find something, it won't cache anything, so on the next run it will search for it again. 
&gt; A standardized BMI would certainly be useful, but it is not mandatory. It could easily be added later on. Also, I wouln't force compilers to use a format, but encouraging compiler writer to add functionality export and comsume BMIs. That works too. It doesn't really matter that the compiler use a standardized BMI directly so long as a standardized BMI can be run through the pipeline in some fashion. &gt; I would however first push for a common format, and look if standardization worth it. That is exactly what some parties are trying to do. "Standardization" in any case would be a bit complicated. I don't think anyone is currently thinking of standardizing it in C++ itself but rather as an external/free-standing (semi-)standard. All after modules get in into C++ in the first place, of course. :)
KAI C++ compiler comes to mind (the only one compiler to implement (that) export as I remember).
This is probably the best you could do. It must be possible to provide a specialization for `constexpr_instance`, as `LiteralTypes` must be &gt; a type with at least one constexpr (possibly template) constructor that is not a copy or move constructor [as per cppreference](http://en.cppreference.com/w/cpp/concept/LiteralType) and probably convoluted and spread out in the standard.
After having waited for modules for 10 years, I'm willing to wait a few more years if it's what it takes not to be saddled with issues for the next 10 years! Of course, I still hope they make it into C++20!
If all else fails they could just stop to use MS Build and use Ninja. If they don't appreciate implementing it, then they should maybe be replaced by people who are willing to do their job. Also, some meassurements: I have a full clone of the openmw-codebase on my system, consisting of 350KLOC and roughly 1800 source-files. Their use of CMake doesn't appear to be overly idiomatic, so there is certainly room for improvement. The time to run cmake is less than 0.7 seconds if there is nothing to do. Running ninja takes 0.09 seconds if there is nothing to do. Linking the executable (necessary after change!) takes 1.6 seconds (and that is without compiling a single file, a situation you only encounter by manually deleting the output-executable). I also touched a bunch of random .cpp-files (no headers!) and ran ninja after that and typicall times where around five seconds. Optimizing the 0.7 seconds in that situation is really a case of having the wrong priorities. On another, admittedly very small (29 files, ~1200LOC) project that uses GLOBs, running CMake takes 0.03 seconds. This is REALLY not something I care about. I'm literally using a script for building any of my projects that *always* calls cmake first in order to ensure that GLOBs are working well. It really doesn't matter.
r/cpp_questions but... you just do one after the other, I think, A for loop is just "syntactic sugar," i.e.: for (init;check;update) { ... } is just: init; while (condition) { ...; update; } 
Thanks mate
&gt; there are no valid technical reasons why it shouldn't work like that It's strictly more efficient and correct. If that's not a valid technical reason, then I don't know what is. 
&gt; You only realize how annoying it is once you try glob support and stop doing things manually. Yeah, I just don't agree. The first team I worked with used globs. It's just not worth it. &gt; These days I hardly edit buildfiles. Neither do I. That's my point. The amount of time you spend editing the existing code dwarfs the amount of time you spend to add a file or two by such a ridiculous amount that I would never trade the correctness and efficiency of my build for that tiny savings. 
Word homie
Ah, I see that [inline was added in C99](http://en.cppreference.com/w/c/language/inline). This code predates that by about 15 years :-). I'll update the article, thanks.
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/884be6/magnum_graphics_for_qt_chart_application/dwht2tg/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
That is an impressive result indeed.
&gt; std::string_view sv2 = std::string("hello world"); If this compiles, then it pretty damn well shouldn't. I presume that `operator basic_string_view() &amp;&amp;=delete` would do it? It's a bug in the standard if that's allowed. 
Thanks for verifying the work! To be very clear we at Kitware focused mainly on the performance of custom commands. I would expect for most people the runtime improvements will come from the hard work of the general community in improving the speed of querying the sources of a target, and reducing the number of unneeded string copies.
String_view seems like a solution in search of a problem.
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/88479a/can_anyone_write_a_program_for_this_i_dont_know/dwhzit4/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
that sounds like a form of monkey patching, which is useful, but not what I would expect from the term "smart ref".
Man, you know the world has drastically changed when Raymond Chen is blogging about obscure details of non-x86 CPUs.
This disallows `foo(getStr())` if `foo` takes a `string_view`. C++ has no concrete way of making both work, and proposed language changes around this have seemed to me to be unfavourably received by the committee.
I would say that the reason standard library implementers can't just add `constexpr` is because: 1. It makes it easier to accidentally write non-portable code that depends on the particular implementation of the standard library you use. 2. If people rely on the `constexpr`-ness of a function, the standarization committee is more constrained when changing that function in the future (perhaps to make it no longer `constexpr`-able). With regards to your possible use case, I'm personally not convinced. Detecting at compile-time if it's possible to copy a value at compile time isn't particularly helpful. If you *need* to be able to do so, then you should just assume you can and let the compiler raise the error when that's not the case. If you'd *like* to be able to do so, you'll have an easier time just assuming you cannot. In the second case, I think your users would appreciate the consistency as well. I'd rather not have a function that takes a reference only when it cannot do a compile time copy of the passed time. That's drastically different behavior that can switch due to a subtle code change somewhere totally different. Not sure what linkage concerns you are talking about. I believe I"d have no problem calling a template function with a type or object with internal linkage. You will upset the compiler if you have a class with external linkage that has a base or member with internal linkage, but that's equally true whether a value or reference data member.
I guess the question is, what is more likely: you forgetting to v as a file to cmake or glob picking up a file you didn't intend to. Personally I think the first one, but that's just a guess. All that aside: No one would be forcing you to do this.
The part about correctness assumes manually editing the cmake file is less error prone than the automatic version. I actually doubt that.
Our cmake build definitely takes much longer than that, and we don't have a particularly large codebase.
The creation of that list does not necessarily need to happen in one file. Actually, in that case, as you pointed out, you could create it by hand or via macros. A more realistic situation is when you are creating a library that uses this technique to allow users to register their types so that after that, the library can process and generate custom code in compile time depending on the type list content. For instance, the creation of serializable types could be done individually in each individual .h that defines a class suitable to be serializable. The serialization code could be in a translation unit that takes advantage of this meta-variable with all the types. In this case, the creation of the list and the usage is totally separated. Regarding the difference in translation units obviously, you could be creating different lists if you would include different files in each translation unit. Even in the case that you include the same files that make use of the ADD_TL if they are in different order they could create different lists. In that case, you could sort the list as well, but as I said the final outcome depends on how you use this. And thanks for that link, I will take a look at it, although the __COUNTER__ is very well implemented but yeah, not standard. 
Say I have a library function like the following: template&lt;typename T&gt; constexpr auto internalize(const T&amp;) -&gt; [..]; If detecting `constexpr copy`, I can sensibly handle both the following uses: struct Foobar { int ctr; }; constexpr auto use_with_temporary() { Foobar temp = {}; return internalize(temp); } as well as: struct NoCopies { size_t secrezs; NoCopies(const NoCopies) = delete; static inline constexpr NoCopies instance = [..]; }; constexpr auto ref = interinalize(NoCopies::instance); Of course one could just hard error in these cases but matter of fact is that compile time errors are hard to read, hard to understand, and because we have no detection, hard to customize. If this happens deeper inside a library, I conjecture that it will be almost impossible to quickly find the correct documentation even if it exists. And if you don't think anything like this will ever happen in the real world, [this bug in catch](https://github.com/catchorg/Catch2/issues/449) applies to all of those attributes.
Building a distribution in CI would be an easy solution. With free services like [Travis-CI](https://travis-ci.org/) and [Appveyor](https://www.appveyor.com/) and open source software like [Jenkins](https://jenkins.io) there is little reason for any project with more than 2 people to not have CI.
Why not add a test to Continuous Integration. Just like Unit Tests any project worth the complexity of C++ with CMake should have tests that run on every commit, preferably being accepted into the main/master branch. Surely, this would let you know if you missed something like a whole file in your CMakeLists.txt. From the other perspective it wouldn't let you know about extraneous files unless you listed out all your files individually anyway.
In other languages you use zip() but it's not yet available on C++
I would write this with [range-v3](https://github.com/ericniebler/range-v3) as ([**DEMO**](https://wandbox.org/permlink/j0irTibDOCKuQ0wC)): int main() { std::vector&lt;int&gt; v1{1,2,3,4}, v2{9,8,7,6}; for (auto const&amp; [x1, x2] : ranges::view::zip(v1, v2)) { std::cout &lt;&lt; x1 &lt;&lt; ", " &lt;&lt; x2 &lt;&lt; '\n'; } } 
I can't wait until CMake 3.14. "CMake Almost Pi"
Please Kitware, add a debugger and some type/variable safety to cmake.
Where I work, I tried switching to c++17 (with a backported clang). Our code was clean, but 3rd party reps were still using `std::auto_ptr` and the `register` keyword. ( that last one came from some gSOAP generated junk. Luckily that part is in its own little padded corner )
This is an example of a question that is fine for this subreddit: * It is an open-ended design question. * The subject matter is interdisciplinary, cross-cutting and will be of interest to a wide audience. * The OP presents some possible solutions and discusses tradeoffs. * It has clear and concise code examples. If you want to ask questions to initiate a discussion on this subreddit, this is how to do it. Otherwise, taste my hammer!
https://en.wikipedia.org/wiki/Edison_Design_Group Unless KAI uses EDG as their front-end, of course.
Nice. Is there a performance impact comparing to the alternatives in that question? 
The second option is nice. The first one introduces new function with a long name and new month_day_last type. It seems a bit redundant.
 &gt; You add files far less frequently than you edit them. That is exactly the problem, it feels like a huge hassle because you so rarely do it, and then you add a new file and maybe forget to add it, and then remember to add it, and then you're grumpy. But if you did add files all the time, you'd remember that you have to do it, but then you'd be annoyed that you spend to much time editing CMakeLists.txt. There's no escaping to badness.
&gt; it feels like a huge hassle You type a line in a file. Are you kidding me?
There is no "alternative" to globs. A build is either explicit or implicit. Globs are implicit, and a list of files in a build file is explicit.
It's awesome for parsers.
&gt; You type a line in a file. That's why I said it *feels* like a huge hassle. It's not a big deal at all. But when you're in the flow and reorganizing code or starting a few new modules for a new piece of functionality it's just one more interruption to add to the pile. I forgot to add a file to a listfile last week. ¯\_(ツ)_/¯
I'm not going to say it's amazing, but I wrote a little helper for this so I can write: vector&lt;int&gt; v1{1,2,3,4,5}; vector&lt;int&gt; v2{6,7,8,9,10}; auto sum = 0; for(auto [e1, e2, i] : each_i(v1, v2)) { std::cerr &lt;&lt; fmt::format("adding {} {} {}", e1, e2, i) &lt;&lt; std::endl; sum += e1 + e2 + i; } https://github.com/xaxxon/xl/blob/f4b3e5278ddd6667bce03499d74c2ec4434080a7/include/xl/library_extensions.h#L207-L263 feel free to just snip this bit if you want. 
wg21.link and npaperbot are our search tools, they are actually the one good piece of infrastructure we have.
The counter is a nice touch. I think there should be a version w/o it though for performance sake but it's a trivial change... Love the implementation approach.
&gt;In a globbed system, the build may include files I didn't tell it to. In an explicit one, it cannot. Technically, a globbed system also only includes the files you tell it to... by putting them in paths that are getting globbed. The filesystem *can* be just as much a part of your build specification as your CMakelists.txt, it's just a matter of whether that's expected or useful to you.
In my tests neither this nor your alternatives vectorizes with latest ICC/GCC/Clang. To make vectorization possible you want to first compute the minimum size (only fast for random access iterator) and then iterate over that: for(int i=0;i&lt;std::min(v1.size(), v2.size()); i++ f(v1[i], v2[i]); //do something with it Doing the same is possible with a zip function (quick and dirty proof of concept): https://godbolt.org/g/wrHuP7 . I think it should be possible to do the same for range-v3 zip for random-access ranges. Has anyone tried?
You don't create more language features to make something a little more convenient if it isn't even used very often. The mantra reads as: "make **common** cases simple".
No, it was Comeau C/C++ compiler: https://en.wikipedia.org/wiki/Comeau_C/C%2B%2B "In 2006-2008 it was described as the only mainstream C++ compiler to fully support the export keyword for exported templates."
&gt; To make vectorization possible you want to first compute the minimum size It's unexpected.
Read this for an in depth discussion about that: https://foonathan.net/blog/2017/03/22/string_view-temporary.html
To be able to vectorize you have to know that at least N iterations are left (where N is the SIMD width). For a single loop variable this can be computed as end-i.
And from EDG's wikipedia, it says that Comeau was indeed one of their clients. Neat.
I agree, it is needlessly un-generic and can be replaced by a range of `char`.
If you want your system to only do exactly what you tell it to, why are you using c++ and not assembler? Why are you even using cmake and not make/ninja/python whatever? CMake (if properly used) already does a lot of things for you automatically. Globbing files when you ask it to isn't that much of a stretch (we are talking about a syntactical simplification of something that is already possible anyway). Regarding the complex project: The point of automation and simplification of common things is a) to have more time for the really complex aspects and b) reduce the likelihood of errors due to humans overlooking things - you said it yourself: &gt; The build system doesn't forget anything. YOU forget. That's why I rather leave simple &amp; repetitive talks to the computer and concentrate on the things that do require a human. What exactly are you afraid of? No one is taking away your ability to specify each and every file manually and no one is suggesting cmake should suddenly try to understand your project structure and determine what needs to be done (buildsystems in other languages actually have that capability thanks to standardized layout, but I guess that train left long ago for c++). Of course you will always find situations, where you need manual control but a) I doubt it is the majority of cases and more importantly b) no one is taking that away from you
Only the fresh one or also on rerun?
https://godbolt.org/g/jeyuQx
Also on rerun. It doesn't take *too* long, but probably on the order of 10 seconds or so. Long enough that eating that time on every incremental build would be irritating.
What do you need that const-correctness doesn't give you OOTB?
Anything wrong with this approach? #include &lt;iostream&gt; #include &lt;string&gt; struct Message { std::string sender; std::string recipient; std::string body; }; int main() { const Message m{"julien@bretagne.fr", "travis@washington.us", "Me zo o komz gant ma amezeg"}; std::cout &lt;&lt; m.sender &lt;&lt; "\n"; //m.sender = "foo"; fails return 0; } Or declare the individual members const, same thing. 
I didnt explain it well enough above. Ill add this .:. With immutable objects its nice to be able to copy one, but only change 1 or 2 members. That would look like .:. const auto m2 = m.copy( sender = "newsender@place" ); 
Scala and C# also have reference semantics, so it's not clear what you actually expect to have in C++. Should every field be a `shared_ptr`..? If you want to see reference code for a library that already does this sort of thing, to see what approach they took, see [immer](https://github.com/arximboldi/immer).
Yeah, I need to take another look at immer. However, I cant use GPL licensed stuff which puts it out of reach for me right now. It works fine without using pointers or refs as you can see in my response to zom-ponks. 
I don't think you can easily (or at least not cleanly) do this in C++, at least not to my knowledge (no named parameters to begin with). 
Even for *C#* we have to use a code generation. For *C++* I would generate something like const auto m2 = m.withSender( "newsender@place" );
I hacked together something but this is best my hungover brain could muster, feel free to laugh :) #include &lt;iostream&gt; #include &lt;string&gt; struct Message { std::string sender; std::string recipient; std::string body; Message copy(const std::string&amp; s_= "", const std::string&amp; r_ = "", const std::string&amp; b_ = "") const { return Message{s_!="" ? s_:sender, r_!="" ? r_:recipient, b_!="" ? b_:body}; } Message withSender(const std::string&amp; s_) const { return Message{s_, recipient, body}; } Message withRecipient(const std::string&amp; r_) const { return Message{sender, r_, body}; } Message withBody(const std::string&amp; b_) const { return Message{sender, recipient, b_}; } }; int main() { const Message m{"julien@bretagne.fr", "travis@washington.us", "Me zo o komz gant ma amezeg"}; std::cout &lt;&lt; m.sender &lt;&lt; "," &lt;&lt; m.recipient &lt;&lt; "," &lt;&lt; m.body &lt;&lt; "\n"; Message m3 = m.copy("", "", "Hello, World!"); std::cout &lt;&lt; m3.sender &lt;&lt; "," &lt;&lt; m3.recipient &lt;&lt; "," &lt;&lt; m3.body &lt;&lt; "\n"; Message m4 = m.withBody("Hello Again!").withSender("foo@example.com"); std::cout &lt;&lt; m4.sender &lt;&lt; "," &lt;&lt; m4.recipient &lt;&lt; "," &lt;&lt; m4.body &lt;&lt; "\n"; return 0; } The copy method is closest to Scala, but then you'll have positional parameters. 
You can probably make something that generates everything based on macros?
Very cool. Going to combine this with /u/Hindrik1997 's suggestion of macros, and I should be able to get there. Ill let you know what I get. 
It might not be efficient when comparing apples : apples, but what it opens up is easy to write massively parallel code. At work we have a game server with heavily tangled gameplay code, but 0 locks and we can run it on 60 cores with few bugs. Its pretty neat. Had a similar engine in *Scala* that ran on a many core machine too with no weird threading bugs. Doing this type of server with locks would be slightly scary. I am open to more C++ish paradigms to solve the same problems though. This just happened to be the best method Ive used so far. 
Anyone have experience with OPDASH here?
I was sure that I had seen one of the std algorithms do something like this. Taking two begin iterators and an end iterator and assume the containers are of equal size.
I'm really curious why so many people use this argument. Other languages with proper module systems have all those parts nicely split into submodules. So I would like to see Boost split into proper modules with proper dependencies. And each module be its own namespace.
It's not an argument, it's reality. I think everyone would like a more modular Boost, but it's both a huge amount of work and a breaking change.
Not sure if I fully understand what you mean, but boost future offers [.then continuations](http://www.boost.org/doc/libs/1_66_0/doc/html/thread/synchronization.html#thread.synchronization.futures.reference.unique_future.then). You could spawn a thread that you treat (and implement) like a pure function, i.e. does not access any "global" state. Pass it a Message copy, fire it off and retrieve the result when it's done. This way, each one of these "tasks" can keep it's own state that it can modify in any way it needs to, without interfering with other tasks/threads. C++ is the most multi-paradigm language I have come across. And since C++11 functional paradigms have received a lot of love and cool features in the language. No need to enforce OOP.
Here, I must also disagree with you. Having limited separation of components due to limitations of existing tools (headers, namespaces) is understandable as a current state. But aiming to keep such status quo at all costs will lead to have flawed and limited solution. Do we want proper modules? Or just some crude alternative for headers? For now, I see current proposals to aim module migration to be as cheap as possible, even at the cost of overall design consistency.
The range-v3 implementation is probably the one to use if possible, failing that there is also an implementation of zip in [cppitertools](https://github.com/ryanhaining/cppitertools#zip) and I made my own one in [irate](https://github.com/jeffpollock9/irate#zip)
So you will use wx to rid yourself of the complexity of moc? Good luck.
Oh Ive been using them for many many years. Used judiciously they can build powerful APIs or solve thorny problems that are difficult to work around. Like any feature people will abuse it. 
Yeah, I love the fact that its multi-paradigm. The only other language that comes close (that Ive used regularly) is *Scala*^([1]). I generally like to keep with a language's natural idioms rather than port idioms in, but the case class idiom was just so damn useful. Who knows, maybe we'll get something like it in the future since it tends to be in functional languages. Maybe simple const in the right places will just solve this too. I need to investigate that too. --- ^([1]) *Scala* has these neat things called Traits which are multi-inheritance done right. Luckily, I found out folks were using the CRTP to [do the same thing](https://www.fluentcpp.com/2017/12/12/mixin-classes-yang-crtp/) in C++. This pretty much ended my desire to program in *Scala*. 
then, you just implement your own copy method. It's just unnecessary to take these types of sugar into c++.
You mean in situations where you rely on CMake macros like ParseAndAddCatchTests to add tests?
Just for anything else reading this comment: immer uses the **L**GPL license. There are of course cases where one cannot use the LGPL, but it is significantly less restrictive than the GPL.
A couple of links to coroutine concerns and response are broken: - https://wg21.link/p0973r0 - https://wg21.link/p0979r0 They they pending upload?
I don't agree with the article either, but it strikes me as the wrong use of `string_view` to use it like that. What is wrong with: class A { public: const std::string&amp; name() const { return name_; } private: std::string name_; }; It does look to me that have `name` returning a `string_view` rather than a `std::string` is indeed not well thought out.
Forgetting to add a file will fail the build and/or tests. Globbing can result in odd behaviour - it might not notice a change without re-running cmake, including both file additions and file removals - it might pick up stuff it shouldn't, leading to failure; or worse, silent success and subtle misbehaviour If CMake were Maven, and we had a standardised layout for components, including public and private headers, sources, libraries, binaries, tests etc., then CMake could greatly simplify things. You could do this today with a custom module which would introspect the layout. But we're not in that situation; C++ has never had that degree of enforced standardisation, and is unlikely to get it anytime soon.
I had something similar - what if we could do this: template&lt;typename T&gt; constexpr void func(constexpr T t) // forces t object to be compile-time { t.do_something(); t.do_something_else(); } It's a non-breaking change and somewhat we already have: compile_status static_assert(constexpr bool condition, const char* msg);
one of the std::transform
I assume they meant it would be nicer to have direct references to the contained elements rather than just an index.
I think iterating over the zip of two containers is a pretty common case.
&gt; or learned CLion is using something like 'Code Blocks MinGW Makefile' generator :) 
In a way, it's (code) duplication. You duplicate the path of your files to the cmake files, when your sources already have that information, unless you really only compile part of your source tree. Yes, it's less explicit than listing them manually, but so is any other kind of deduplication. And it's not just adding that you have to handle: also renaming, moving and deleting. 
&gt; ¯_(ツ)_/¯ You're missing an arm. Make sure to properly escape the arm backslash.
Thank you!
Yeah :( Sigh. Related additions to the language don’t seem to scale. It seems there needs to be some mechanism instead to mark known incorrect constructions as errors. This would allow marking up common bugs in other libraries as well, and perhaps not only bugs related to object lifetime. Perhaps some sort of template code matching could be added. I’d personally call them error templates. Say `template error &lt;&gt; [](std::string &amp;&amp;a){ std::string_view = a; }`. I wonder if that would be something worth pursuing instead. Upon matching, the compiler would flag the offending statement as an error. One could also match an expression I guess: `template &lt;&gt; error(std::string&amp;&amp;a)(std::string_view = a)`
We solve this by using a generator for our cmakelists that runs cmake if the files change. Then cmake of course generates ninja or make files... seems like overkill, but I think it's the only solution that doesn't eliminate cmake altogether.
Sorry, I'm still not convinced. You actually illustrate my exact concern with the hypothetical use case you talked about earlier. You omit the return type of `internalize`, but it seems to be: std::conditional_t&lt;is_constexpr_copy_constructible_v&lt;T&gt;, T, T&amp;&gt; That's just asking for a dangling reference. If the function switches from making a copy to returning a reference when a class no longer has a `constexpr` copy constructor, that's going to catch most users of this function by surprise. That handling is the opposite of "sensible". I think you'd be better served just writing the most general version you can and letting the optimizer figure out what it can get away with doing. I still don't see a legitimate use case for this. I think you have a solution in search of a problem.
He had a series about Alpha CPUs a while ago. Those are dead now though :-)
Actually `year_month_day_last` is a type, so that is a construction, not a function. I prefer the second too. I find it far more readable, and easier to remember the syntax. But some people are allergic to the `/` syntax, so they can use the more traditional construction syntax.
I'm not using `thread_local` for anything.
Unnecessary is not an argument against syntactic sugar. It may be unnecessary to how you program, but different folks approach problems differently. We have around 300 Immutable classes in our server with around 8 fields each. So thats around 2400 completely boilerplate functions. Plus probably another 600 or so. Thats well worth having the compiler autogen it. I mean, the C++ standards committee gave us the ability to use using to bring boilerplate constructors into subclasses, so theyre definitely not going for minimal syntactic sugar like *Java*. 
In this specific instance, sure. But `string` isn't the only container that can hold contiguous `char`s. Maybe you're storing a `vector&lt;char&gt;` or a `unique_ptr&lt;char[]&gt;` and a length separately, and that detail isn't important to the caller at all. Maybe you *are* storing a `string` but you only want to return part of it without incurring allocation. Those kinds of situations lend themselves pretty well to favoring returning `string_view` over `string const&amp;`.
no.
I've been writing mostly Python lately but I wrote `for a,b in zip(list1, list2):` literally a few days ago. I certainly reinvented zip in C++ bunch of times too. It's definitely a common pattern, at least in what I do. I can't understand why are you so conservative on this matter. C++ standard library is ginormous, including a zip function won't overflow your harddisk.
PYTHON! Can someone teach a man how to find out all attributes available for any object..otherwise going is great!
what does it matter what I think. I am not on any committee.
Two glaring issues: 0. The for loop is also using a different (read: incorrect) type for the index. Yes, it happens to be signed, which happens to be known to optimize better in many cases, but it also technically makes the code handle only a subset of the input the other cases do, in a way that causes UB instead of handling it gracefully. 0. You're using `DoNotOptimize` wrong. It's meant to invalidate potentially-cached memory, not substitute for an actual workload. The key difference between these approaches is painfully ignored by the benchmarks, and that's how the data is able or not able to compose together in a performant way (read: vectorize). Invalidate the whole collection with `DoNotOptimize` then do actual work with the data and I'd warrant that the results change significantly.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/88b7es/implementing_programming_challenge_need_help/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
@dodheim thanks for this - looks like I have some reading to do!
You can tell most compilers to perform a syntax check without actually compiling a translation unit. E.g. for clang it's `-fsyntax-only`. Also, this is 'probably' the wrong place to post this. (See /r/cpp_questions)
Keep studying, you'll soon see that nothing is really simple about the language... 
How do you add member functions to the latter?
[removed]
I see. It makes sense, but what is 'end'? for(int i=0;i&lt;std::min(v1.size(), v2.size()); i++) I think I have to do more research to understand it. How does it guarantee that v1.size() when i in std::min(v1.size(), v2.size()) - N ?
There are no "guarantees"; the best you can do is hint in the optimizer's general direction. In this case such hints are sufficient for Clang but not for GCC — YMMV.
!removehelp
The whole language is a really complex mixture of ~40 years of history. As more "simple structures" are added, the interactions with existing features get more and more complex. It's not a bad thing, but you need to know a lot about everything to be able to use this complexity effectively without shooting yourself on the foot. That's the reason most people tend to choose a subset of features to use, so that the complexity becomes more manageable. Nowadays you can safely restrict yourself to C++ 11+ features for most of your code and not be exposed to everything else, but it'll still be there to explore as you learn and, more likely, to creep on you when you mess with other people's code. 
Why wouldn't Clang do the optimization regardless of that particular hint? Does it just want to know that the potentially expected loop size is greater than some_factor * N ?
You think this, as a design, is worse than newer languages?
That's rather missing the point, which is: there's no way of knowing except empirically. As it happens, in this case [I tested](https://www.reddit.com/r/cpp/comments/8865oc/multiple_ranges_in_for_loops/dwiqu8u/). ;-] Remember, it doesn't matter 97% of the time, so write what's idiomatic; but for that other 3%, being even a little familiar with what tends to work or not for your primary toolsets/targets _can_ be very rewarding (albeit probably rarely). If you _really_ cared, you'd probably vectorize things explicitly (or otherwise parallelize) rather than just crossing your fingers.
I totally agree. I think I was wondering why clang guys decided on their optimization choices in this particular case but perhaps it doesn't really matter... )
No. template template parameter were made to extract the parameters of a template and to act as a constraint. Each time you want to do that template template parameter is the way to go. You used "decltype(declval&lt;Container&gt;().front())" as an alternative for instance but if I really were to use this solution I would need to write this instead: std::decay_t&lt;decltype(declval&lt;Container&gt;().front())) //now 2 more header dependencies If you really think that the above is LESS complicated and more readable that just using a template template parameter you're just factually wrong.
When several == 2 you could abuse `std::mismatch`. std::mismatch(v1.begin(), v1.end(), v2.begin(), v1.end(), v2.end(), [](int a, int b){f(a, b); return true; } 
I've seen this style used in the [Git release notes](https://github.com/git/git/blob/master/Documentation/RelNotes/2.9.3.txt) too.
So with this constraint how would you write the functional programming map function? Aka input: Container, function to transform one value to another (possibly outputs a new type) Output: Container with the new values
Why not both? I set up all my build-related stuff (compiler flags, directory locations, etc.) in a separate CMake file and my project files just include that file and list the source files for that project. Separate concerns in separate files.
It’s both great and horrible. What it has over more ‘elegant’ languages is it’s mapping to real machines in a way that more faithfully expresses their capabilities.
It is written – the ranges TS has template &lt;InputRange Rng, WeaklyIncrementable O, CopyConstructible F, class Proj = identity&gt; requires Writable&lt;O, indirect_result_of_t&lt;F&amp;(projected&lt;iterator_t&lt;R&gt;, Proj&gt;)&gt;&gt; tagged_pair&lt;tag::in(safe_iterator_t&lt;Rng&gt;), tag::out(O)&gt; transform(Rng&amp;&amp; rng, O result, F op, Proj proj = Proj{}); You'd omit the projection to meet your exact requirements, but it's a good thing; and without concepts you replace the `requires` with SFINAE. What would template-template parameters offer you here?
Lol! Got me!
There are no plans to ever add tabs: Those scale horribly to the number of files open in an IDE.
Again, it's about reachability: if you can't prove that `e` is reachable by incrementing `b` then you can't vectorize without risking undefined behavior. The result of pointer arithmetic is guaranteed to be reachable by incrementing (the simplest form of pointer arithmetic; go figure).
Thanks, it is falling into place for me now.
My first exposure to unix was at college where an entire lab of X terminals was hooked up to an Alpha server running Digital Unix. Today I suspect my phone has more power. I miss the old days sometimes.
Yes! Imho at least. 
If you really want to see how fancy complex features can be built on top of a few small fundamental building blocks, check out scheme.
[Data Model](https://docs.python.org/3/reference/datamodel.html)?
TLDR: If your code requires a retry loop, use weak, otherwise use strong.
That can be implemented non-intrusively: template&lt;typename, typename...&gt; struct rebind_template; template&lt;template&lt;typename...&gt; class TT, typename... TTs, typename... Ts&gt; struct rebind_template&lt;TT&lt;TTs...&gt;, Ts...&gt; { using type = TT&lt;Ts...&gt;; }; ([Demo](https://godbolt.org/g/feoQ93)) No need to clutter your API for the sake of avoiding a simple utility.
C++ is really simple. Other than multithreading, you can pretty much gain a deep understanding of the entire language by implementing string, tuple, and variant.
This appears to be a mispost intended for /r/lisp
`&lt;thread&gt;` is like `void*`. Nothing wrong with using it. It's just really low level. 
 struct Message { std::string sender; std::string recipient; std::string body; }; const Message m{"message", "recipient", "body"}; This is your immutable object with auto-generated constructor and copy/move constructor/assignment operator. You control immutability from outside the class (const instance) instead of inside (const members). C++ doesn't give you a default comparison operator yet (see https://isocpp.org/blog/2016/02/a-bit-of-background-for-the-default-comparison-proposal-bjarne-stroustrup).
Good point
That's great! I've seen two or three bugs related to such mischievous casts in the last year, and it took quite some time to figure out the root cause each time.
Yes. Feature interactions is a curse. Any time you add a feature, you have to check how it interacts with the N existing features (and their *combinations*), so as more features are added, there are inevitably issues that arise that were not spotted in time. And that's not even counting features added concurrently :x The problem is, once a problem surfaces, what do you do? - Tweak one (or both) of the features: break any client relying on it, - Wince, but be pragmatic enough to realize that backward compatibility is more important than elegance/orthogonality. Well, C++ mostly takes the "wince" route; and after ~40 years (accounting for C's history) it shows. If I may comfort you, though, any of those newfangled languages will have to make the same choice at some point. And if they have learned anything from Python3, they'll take the "wince" route, and end up full of warts. *shrug*
I'm not talking about beta testing the feature. I'm talking about beta testing the spec. Finding typos, things that were stated incorrectly, internal inconsistencies. This /is/ in-field testing - for the spec.
The problem is that the first time you use getName on a temporary you may be in for nasty surprises. String view is a reference like type that doesn't have lifetime extension and can be reseated, it's far easier to make it dangle. Hence why I favor deleting rvalue overloads for functions like getName.
&gt; It's not a bad thing, but you need to know a lot about everything to be able to use this complexity effectively without shooting yourself on the foot. &gt; &gt; That's the reason most people tend to choose a subset of features to use, so that the complexity becomes more manageable. Honestly... what features are you talking about ? 
Yes, they should become active in a few days, when the post-meeting mailing is published.
Yes, that’s true. I meant to say that unlike some other languages, which may appear more elegant, you can follow the abstractions all the way to the hardware. This keeps C++ honest, in a manner of speaking.
Well it also has class xD
https://yosefk.com/c++fqa/
&gt; Today I suspect my phone has more power. Almost certainly. But if it was one of the very last, biggest AlphaServers they ever made, the server would actually still be much more powerful. The last generation had a model that supported 64 21364 CPU's that were greater than 1 GHz. It'll still be a while before your phone's CPU catches up with that beast. But who would let college kids use something like that?
That's sort of true, but the hardware is much more complex than the language makes it seem. C++ has no concept of things like cpu caches, speculative execution, instruction level parallelism, instruction op-codes, etc. When it comes down to it, even assembly has a surprising amount of opaque abstraction built in. C++ gives you most of the tools you need to somewhat control how the code interacts with the quirks of the hardware, but none of that is explicit in the language, and requires a bit of external understanding to leverage.
I mean, both types of languages have a place. That said, C++'s zero-overhead abstractions are definitely a huge part of its success.
Any language that compiles to machine code has this property.
Following both r/cpp and r/rust, I had to double check where this was posted eh
To be fair, that is a rather beautiful thing about C++. Every other language with more modern features hides the implementations in the standard library or compiler. I'm quite fond of just how accessible everything in C++ is.
Have you seen initialization rules? Template deduction? Partial template specialization vs Full template specialization vs overload resolution?
Try TMP + SFINAE
1. Likely no, just don't overuse overload resolution and implicit convertions. The same goes for overusing initialization rules and chosing wrong brackets. 2. GNU's STL unordered map has 5 private and 1 public parent.
It's pretty clearly a joke, since those are three of the hardest standard types to implement correctly.
I get the variant and tuple (variadic recursive templates) but why string? Because null-termination? SSO?
size? Isn't this just straight O(1) end_ptr - begin_ptr? 
This was the mid 90's, so probably hardware running the 21164. 
Depends on if you want to count the literal size of a string or the number glyphs it has. An example; how long is: 🕴️ ? Is it 1, because there's one glyph, or is it 3, because you're looking at it from UTF-8, where it's `EF B8 8F`, or is it 2, because it's UTF-16 `FE 0F`, or is it 4, because it's UTF-32 `00 00 FE 0F`?
r/simd/ doesn't get enough love...
Ok, silly question, I know: but if you use a linux distro like Linux Mint, or Debian stable, what is a good way to get updated gcc/clang compilers? On linux mint right now I'm using gcc 5.4, and clang 3.8. I'd rather not install everything from source myself and risk breaking my toolchain, etc. Any advice?
Yes, definitely. For example - (almost) every STL container accepts allocator as a second template parameter. Usually, it's not a problem... until you want to implement template function, that correctly operates or returns std containers. It's very annoying and makes code less readable... for no benefit to language at all! This second template parameter is ALWAYS std allocator - basically, this feature made sense only for DOS running on 16 bit x86 processors (see short pointers and far pointers), but is not used since. It's a dead feature, that plagues STL for close to 30 years and will probably never be removed. Another problematic part is iostream - design is too generic resulting in most common usage pattern (standard I/O) being too slow. Also std::string - class structure clashes with constexpr, making it impossible to create constexpr std::strings (which would be neat for many reasons). I can go on, but you should get it now... C++ is not an elegant language. After years of learning about corner cases, I grew to appreciate how plain C is much more elegant. Nowadays I would prefer (and am learning) Rust.
It's pretty safe to install from source if it goes under /usr/local, which is the default for every package I've encountered. If you're paranoid about this, try ./configure --prefix=/usr/local Other than that, you could create a container or VM and install a more bleeding-edge distro inside of it.
&gt; NEWLIB &gt; ... &gt; 64-bit time_t support. Huzzah! Huzzah! Huzzah!
While a single tree is just fine for packages maintained by the OS (deb, rpm, etc), it makes managing locally-installed packages overly difficult. If you are running effectively single-user, then you can install to a custom --prefix=${HOME}/Programs/gcc-version. Otherwise, if you are sharing the system with others, then install to a directory under /opt.
&gt; C++ is really simple. Wut? Modern C++ is anything but simple. 
I think you're talking about C++--. Or, you know. C. 
This is why I've always loved C++. Yes it has a lot of warts as a result of backward compatibility, but these typically won't affect you if you strictly adhere to one of the newer specs. I would much rather have a powerful language with a lot of features, rather than trying to fight simplifications / assumptions. Shooting yourself in the foot with code complexity is a sign that the developer doesn't understand the features they are utilising - not a sign that the language has too many features.
**Company: [AutoX](https://www.autox.ai/jobs)** **Type:** [Full Time] **Description:** AutoX’s disruptive camera-first AI brings self-driving cars out of the lab and into the real world.We believe that autonomous driving should not be a luxury, and we are making it universally available to everyone. We needs great C++ coders to help put all advanced algorithms into real practice for our **autonomous driving platform**; develop scalable frameworks to support many types of vehicles and configurations; design efficient components and optimize existing software for limited compute platforms; collaborate with other engineers to implement, integrate, and deploy **robotic perception, mapping, localization, and sensor calibration software**... **Location:** San Jose, California, USA **Remote:** NO **Visa Sponsorship:** YES absolutely **Technologies:** C++ 11 (might shift to C++14 or C++17 but doesn't matter much) * For system&amp;tools: Operating Systems, Databases, Concurrency, Linux Kernel, Compilers, Distributed Systems/ VTK and Qt application framework * For perception: strong background in algorithms, data structures and math in general * For mapping: mapping industry experiences **Contact:** Apply through our job page or email me at **careers@autox.ai**
I feel like there ought be an option like -nocompatibility and -wcompatibility or something that gets rid of the backwards copmpatibiy cruft. -nocompatibility would disable the old features like maloc, struct, the preprocessor(#include after modules), and other things I'm not thinking of, as introduce backward-compatibility breaking behavior. The -wcompatibility would just give a warning if you use an old feature. Maybe that list bit would make it even more a of clusterfuck (is this with -nocompatibility? cause if it is, it does X, otherwise it does Y) but at least have it get rid of C-isms. 
I wanted to make something which can work faster than `make` in default configuration. You don't have caching in make by default, in my opinion it is still not that usable for big projects, but pretty useful for medium size projects. I am still adding features to it, would be helpful if can recommend some features you would like to see in it.
You monster
Whoosh... 🙃
Seriously... Media relating to simd doesn't has its own centralized place for it to be spoken about outside of... a stackoverflow tag or something.
The code fails to compile on gcc 7.3.0 error: could not convert ‘{nullptr}’ from ‘&lt;brace-enclosed initializer list&gt;’ to ‘X::ptr {aka std::unique_ptr&lt;O, void (*)(O*)&gt;}’ ptr i_ { nullptr }; ^
Your program is ill-formed. From _23.11.1.2.1 unique_ptr constructors_ in the C++17 draft: &gt; `explicit unique_ptr(nullptr_t) noexcept;` &gt; [...] &gt; Remarks: If `is_pointer_v&lt;deleter_type&gt;` is `true` or `is_default_constructible_v&lt;deleter_type&gt;` is `false`, this constructor shall not participate in overload resolution. The C++11 standard had a different, but equivalent wording in _20.7.1.2.1_: &gt; If this constructor is instantiated with a pointer type or reference type for the template argument `D`, the program is ill-formed. Unfortunately, 15.6.4 is non-conforming as it doesn't reject the program. It seems fixed in 15.7.0-pre.2.0: error C2665: 'std::unique_ptr&lt;O,void (__cdecl *)(O *)&gt;::unique_ptr': none of the 2 overloads could convert all the argument types [...] note: while trying to match the argument list '(nullptr)' clang: In file included from /usr/bin/../lib/gcc/x86_64-linux-gnu/5.4.0/../../../../include/c++/5.4.0/memory:81: /usr/bin/../lib/gcc/x86_64-linux-gnu/5.4.0/../../../../include/c++/5.4.0/bits/unique_ptr.h:159:9: error: static_assert failed "constructed with null function pointer deleter" { static_assert(!is_pointer&lt;deleter_type&gt;::value, g++: /usr/include/c++/5/bits/unique_ptr.h:159:9: error: static assertion failed: constructed with null function pointer deleter { static_assert(!is_pointer&lt;deleter_type&gt;::value, 
Report the bug on VS (button on the top right corner of the IDE). This is not a bug reporting forum.
Here's my take on this: [https://godbolt.org/g/xFYKFy](https://godbolt.org/g/xFYKFy) C++ doesn't really have named params, but there's a trick you can use to imitate them. This lets you do everything with just a plain const struct. The actual method ended up looking like this: struct Message { std::string sender; std::string recipient; std::string body; }; void test() { const Message m1{"julien@bretagne.fr", "travis@washington.us", "Me zo o komz gant ma amezeg"}; const Message m2 = copy(m1, make_param(&amp;Message::sender, m1.recipient), make_param(&amp;Message::recipient, std::string("claire@bourgogne.fr"))); } 
Any chance you could fix https://bugreports.qt.io/browse/QTCREATORBUG-1920 ? I work in FPGA SoC embedded systems, and this (seemingly) trivial bug pisses me and my team off on an hourly basis. Your IDE is still the best for C++ though.
&gt; 2. Or &lt;50 if implemented by inheriting from vector. Assuming one line per additional member function, that will be over 100 LOC. 
&gt; until you want to implement template function, that correctly operates or returns std containers. I don't see a problem. I just make template taking a `typename T`. &gt; std allocator - basically, this feature made sense only for DOS Not really. It is still used when performance is a concern. &gt; Also std::string - class structure clashes with constexpr, making it impossible to create constexpr std::strings It isn't the class structure. It is the fact that `std::string` uses dynamic allocation.
Instead of obscure details of x86 CPUs?
\#1 on my list of things to remove from C++ is "magic 0" and NULL. That's a horrid hack if ever there was one.
Are you running it on Windows? Try running through Cygwin. A lot of QT devs are also KDE devs, and KDE's windows ports are pretty shit. 
Haha, damn. But, really though, that thread about Reddit's old code really had such a positive aura that I hadn't see for quite a while in r/programming.
Looks like we are going to get simd in the core which is about as close to the registers as you can get without being hardware.
Where is it possible to see these libraries implemented in human readable (non-library) code so that we can break them down?
Ubuntu
if the allocator is never used, you can just ignore it when you write a function template, because it has a default.
Couldn't tell you. IMO the most readable open source STL implementation is (G++'s) [libstdc++](https://github.com/gcc-mirror/gcc/tree/master/libstdc++-v3); here are its implementations of [`string`](https://github.com/gcc-mirror/gcc/blob/master/libstdc++-v3/include/bits/basic_string.h), [`tuple`](https://github.com/gcc-mirror/gcc/blob/master/libstdc++-v3/include/std/tuple) and [`variant`](https://github.com/gcc-mirror/gcc/blob/master/libstdc++-v3/include/std/variant).
I liked it, I can't understand the downvotes. It was funny.
&gt; I grew to appreciate how plain C is much more elegant. Pluck my life! Worst line I've heard in 2018. U only write C: * Because u don't know C++ * No C++ compiler on that platform Either your frustration is understandable &gt; Nowadays I would prefer (and am learning) Rust. Nowadays I would prefer (and am learning) D... feels good. macro_doesn't_rules! no_apologies { }
Sorry I might be out of my depth here. Why would such a cast cause bugs? When using a packed structure you can always access unaligned integers at character offsets...
Wow, if that is human readable I guess I am an alien. 
They didn't talk about packed structs, but using them you can also make mistakes. For example, pack the following struct : char a; unsigned long b; And do the following : unsigned long* x = &amp;packed_struct_instance.b; And then pass that x to some function that is not aware that it came from a packed struct, that function can try to dereference it and it'll cause unaligned access. On x86 with a modern OS it'll just cause a slowdown but on baremetal ARM, by default it'll cause the code to crash. 
The readme in this repo discusses how small string optimization (the complex part of `string`) is implemented: https://github.com/elliotgoodrich/SSO-23 Here's a good series on implementing `tuple`: http://blogs.microsoft.co.il/sasha/2015/01/12/implementing-tuple-part-1/ http://blogs.microsoft.co.il/sasha/2015/01/16/implementing-tuple-part-2/ http://blogs.microsoft.co.il/sasha/2015/01/23/implementing-tuple-part-3/ http://blogs.microsoft.co.il/sasha/2015/01/28/implementing-tuple-part-4/ http://blogs.microsoft.co.il/sasha/2015/02/03/implementing-tuple-part-5/ http://blogs.microsoft.co.il/sasha/2015/02/13/implementing-tuple-part-6/ http://blogs.microsoft.co.il/sasha/2015/02/22/implementing-tuple-part-7/ I can't find any good sources on the implementation of `variant` ATM, but it would be similar to `tuple`, with `union`s in place of `struct`s.
One thing that I think is really a mess in C++ is variable initialization. I don't know how to initialize my variables anymore. See [here](https://herbsutter.com/2013/05/09/gotw-1-solution/).
The remark was about std::vector. std::list doesn't have an operator[] to begin with.
Very nice. However its not perfect. Unfortunately it does not work with precompiled headers. I tested it with MSVC2017.
[std::allocator Is to Allocation what std::vector Is to Vexation](https://www.youtube.com/watch?v=LIb3L4vKZ7U)
`-Wcast-align` is not about a packed struct, it's about direct casting. For example: `char* a; (int*) a`. Packed struct can also exhibit the problem. Direct access to a packed struct member is always okay (compiler magic), but taking a pointer to it is contingent on it being correctly aligned. Note that another warning was introduced specifically for packed struct: &gt; **-Wpacked-not-aligned**: &gt; Warn if a structure field with explicitly specified alignment in a packed struct or union is misaligned. The proper way to handle this is to create a wrapper struct around the type, and specify its alignment with an attribute. For example: `unaligned&lt;int&gt;` in C++.
&gt; I don't see a problem. I just make template taking a typename T. And since C++17, there is no problem at all. I had problems with this in C++14 when implementing higher-order template functions (e.g. map function, that accepts and returns container of the same kind as input container). I think C++17 does not address my concerns at all, but I would need to look at my old code to check. &gt; Not really. It is still used when performance is a concern. Show me an estabilished project, that uses std containers with non-std allocator, please. &gt; It isn't the class structure. It is the fact that std::string uses dynamic allocation. You mean std::basic_string uses dynamic allocation. ;)
So I am being told, but I was never shown any real example. If you have one, then show me, please, I really want to know if there are projects, that use std containers with non-std allocators.
That's an ecosystem split, though. Unless magic! FWIW, Rust is planning a "mixed-mode" approach, where each library can be compiled against different "editions" of the language and still interoperates. This means that the same compiler would handle: - libfoo in C++98, where `auto` is a storage directive (like `register` and `static`, and where trigraphs are a thing), - libmine in C++20, where `0` and `NULL` cannot be used to initialize pointers, ... Once we get proper modules, it may be the way to go, as you basically allow "opt-in" deprecation.
&gt; Nowadays I would prefer (and am learning) D... feels good. Good for you, D seems like great language :) In some cases I think it's still ahead of competition - it's the only one, that can evaluate regexes at compile time at the moment (but Rust is getting there…).
C is easy to understand if you're an expert in assembler. C++ is easy to understand if you're an expert in rainbows, unicorns, and dancing angels. 😉
But that doesn't mean RedHat/CentOS updates the default toolchain from GCC 4.8.5? It works OK with devtoolset, but why not provide more recent packages for those interested?
You already can do something similar to this: using FunctionPtr = int (*)(params); is equivalent to: typedef int (*FunctionPtr)(params); That's good enough for me. I am using typedef/using anyway for function pointers for readability.
Boost.Xpressive came out 12 years ago...
&gt; I think the last time I forgot to add a file to a listfile must be over 10 years ago, because I literally can't remember it happening. In contrast, I do forget once in a while... at least once per month. I often add files multiple times per week. 
&gt; The point of automation and simplification of common things is a) to have more time for the really complex aspects and b) reduce the likelihood of errors due to humans overlooking things you have less likelihood of error if you don't use glob. If you use glob, every time you add a file, and commit, you have to inform your coworkers that they have to re-run CMake manually since it won't detect that a file was added. I used only glob for years then switched to listing source files manually, and it's overall much less of a hassle.
I'm afraid the ones I'm familiar with are not publicly available, sorry. But the basic idea is to aim for NUMA awareness and cache alignment in allocation, as well as thread-local allocation to reduce contention for small allocations; frequent choices are Intel's TBB scalable memory allocators, and trivial allocators written on top of C alternative allocators such as tcmalloc or jemalloc.
&gt; It's fast enough to begin with A CMake re-run of some projects I work on takes on average ~30s. It's certainly not "fast enough" (can't wait to try 3.11 btw)
&gt; The time to run cmake is less than 0.7 seconds if there is nothing to do. that's because you are on linux. On windows, on a NVMe SSD, the following CMakeLists: cmake_minimum_required(VERSION 2.8) project(bugmsvc) add_executable(${PROJECT_NAME} "main.cpp") takes *eight* seconds to run and 170 milliseconds to re-run. 
...unless you want to support allocators other than the default.
Right, thats the one
&gt; rtant for me this time. My number 1 annoyance is that there is still no simple way to reach ctest to first update the test binaries before running the tests. Yes that is an example - in partucular if you use MSVC-s integration for ctest. However, I generally find it rediculous, that runing a test seems to have no dependency on the binary being run. If I change a test source file and run ctest, it should imho trigger a rebuild.
Try `unsynchronized_pool_resource` if you haven't yet. I've become a huge fan of `std::pmr` over the last few months.
&gt; unsynchronized_pool_resource last time I checked it wasn't yet available on the compilers I use, I 'll look into it again thanks !
C++11 is about the newest that anything should *require* at this point. I'm using a recent Linux distribution and all my version of GCC supports is C++11, and you have to turn that on. I have never been allowed to use these new standards professionally due to legacy code, tooling, and libraries. Frankly, I would be surprised if I get a job by 2020 that will let me use these skills. It sucks in a way but I'm used to waiting at this point.
The initial time is however completely irrelevant to this discussion, since you have to do it one way or another. The 0.17 seconds that you mention are the interessting value and definitely something that I do not care about if they are necessary for every incremental build (which will almost always take multiple seconds).
That's not an unevaluated context; you're _executing_ a constant expression to yield a value for the template argument. This becomes evident if you try to do something that's illegal in constexpr functions, e.g. throw: https://godbolt.org/g/9NBCDk GCC complains about it being illegal to do in a constant expression, and Clang SFINAEs it out due to it's ill-formedness and so the static_assert ends up failing for the same reason as it does in GCC.
I looked through examples provided with boost allocator and there IS an example of using boost::pool_allocator as template parameter to std::vector - thanks for this! Replacing malloc implementation has nothing to do with C++ STL interfaces though.
I'm not saying this isn't the reality of things, I think however, that the allowed c++ standard should not be limited by the default c++ compiler on a "supported" Linux distro. Maybe the situation will improve once c++ package managers and things like flapjack become more prevalent.
`std::array` doesn't allocate; what would it need an allocator for?
It obviously depends on the typical compilation time on incremental builds, but I agree, that 10 secs more can be very annoying.
The question is: why are Linux projects usually restricted to the default compiler, when it is dead simple to install a newer toolchain? The main reason I've heard so far is that people want to be compatible/be able to use the libraries provided by the system package manager. If there was an easy way to use libraries compiled with a different toolchain and an easy way to ship all dependencies as part of your app, that limitation might fall.
I have a question about your currency, what if the value goes down so much that there aren't enough coins in the nobodys wallet? 
&gt; But it means, that sometimes you need to write two function definitions - one for containers with allocators and one for containers without. Why would it? What are you doing with a container where you would care if it carries an allocator or not? &gt; as they are so extremely rarely used This is wrong; _you_ not using them is not something you can generalize. &gt; it's easier to just replace malloc implementation That's rarely why they're used; you have awfully strong opinions about a subject you clearly have no experience with... &gt;_&gt;
Thanks for posting this. These articles are great. I often find myself relying too much on compiler auto-vectorization and this is a good way to force SIMD without those nasty intrinsics all over my code. 
&gt; Why would it? What are you doing with a container where you would care if it carries an allocator or not? Just an example: I am implementing template `map` function, that gets a container reference and a function and returns a container of function results. &gt; This is wrong; you not using them is not something you can generalize. Well, I think I can generalize based on responses in this thread. But again - if you have some example code, that depends on both standard containers and non-standard allocator, I would gladly look at that and change my mind, thank you in advance.
&gt; Just an example: I am implementing template `map` function, that gets a container reference and a function and returns a container of function results. [And](https://www.reddit.com/r/cpp/comments/889k2o/template_template_parameters_considered_harmful/dwjkvbi/)..? That answers why _you_ use them, not why they're needed. (They're not.) &gt; But again - if you have some example code, that depends on both standard containers and non-standard allocator, I would gladly look at that and change my mind Most of the code I write at work involving vector uses a custom allocator. I can't show you this code, but it's there and it's absolutely the norm. The idea of a professional C++ dev never having used a small_vector or fixed_vector implementation is pretty hard to swallow.
Crossposted.
Compilers optimize and make lots of decisions at compile time. An optimized C++ program will often use memory in very different ways to what you write in your source file. And pointers can sometimes introduce aliasing issues that may force the compiler to not do some optimizations. So, i'm not sure why you assume that other native languages don't have pointers, i'm not sure why you think explicit pointer usage means a faster program, and im not sure why you think a more abstract pointer to memory can't be optimized to zero overhead. 
I don't think it's a Linux limitation or even a problem exclusive to Linux but I'll try to explain. First of all, each distro has its own idea of what a "recent" version of anything is, according to how well-tested they want it to be. You can find some that ship everything on the bleeding edge, but those are not what businesses tend to use because they want stability and security. Choosing the stable distros introduces some delay, perhaps a year for introduction into the distro and a couple years or longer for that newer distro release to get actually deployed within an organization. Then many businesses that use Linux use a distro and get tied to its particular versions of libraries they use (or even dependencies of dependencies) in some way. Want to build only your stuff with a newer compiler, and use packages for the rest? Not so fast. First, you'd have to build a package to backport the newer compiler to the old system, because not everyone should be building that over and over. Those libraries you depend on? Oh, they're all linked with old, slightly incompatible versions of other libraries due to them being built with the old toolchain. Now you're looking at rebuilding and possibly breaking dozens of packages just because you thought you wanted fucking lambdas and `auto`. At that point, most people conclude that it's better to wait for the distros to use a newer GCC. Keeping a clean, coherent set of system-level packages takes work, thus we have seen a raft of containerization solutions to work around making incompatible setups work on the same computer without fear. Not only does each business have its own inertia, but it has inertia from other businesses' products which it relies on. Upgrading those products to a newer version which supports C++11 for example could require upgrading a massive codebase to a new API, plus all the deployment logistics and testing involved with dealing with that. This is all pretty costly. At my current job there are several dependencies we have like this, and it feels like we're almost ready for C++11 but it could also be a couple of years longer. Maybe I should be thankful people are starting to require C++11, because eventually one of those libraries might be deemed critical for a business perspective by someone and start a domino effect of upgrades in the business world. And certainly I should expect people to push the envelope with their side projects, sometimes using new languages and libraries they don't get to use at work. But when you're in the crowd that just can't have nice things for the reasons I've explained, the bottom line is that you just have to wait for an indefinite period of time.
For Ubuntu and Mint, you can install more recent GCCs and such from the [Ubuntu toolchain](https://launchpad.net/~ubuntu-toolchain-r/+archive/ubuntu/test) PPA. 
&gt; And..? That answers why you use them, not why they're needed. (They're not.) It requires you to create your output outside of your function call, so it's not what I was talking about. Here's exact code, that I am talking about: template &lt;class F, template &lt;class, class&gt; class C, template &lt;class&gt; class A, class T&gt; auto map (F f, const C &lt;T, A&lt;T&gt;&gt; &amp; xs) -&gt; decltype(C &lt;decltype (f(xs.front())), A &lt;decltype (f(xs.front()))&gt;&gt; ()) { typedef decltype (f(xs.front())) U; C&lt;U, A&lt;U&gt;&gt; ys (xs.size()); std::transform(xs.begin(), xs.end(), ys.begin(), f); return ys; } With this I can basically write: std::vector&lt;int&gt; xs = { 1, 2, 3 }; auto ys = map(f, xs); and I don't need to know beforehand what is result of `f`. &gt; I.e. all the code you have that only works with std::vector&lt;T, std::allocator&lt;T&gt;&gt; fails to work with types that come with the stdlib OOTB. EXACTLY my point. You can't just depend on fact, that default is `std::allocator` and expect, that your code is correct. It is one of those myriad tiny cuts, that make C++ so annoying at times.
In this situation, after removing all possible coins, those in the users' wallets become the only ones and on their basis the price of one coin will be counted. I guess there is no other way, I think
The way to do a simply immutable data structure in C++ is basically: class Foo { struct FooData { string sender; string recipient; }; using FooState = shared_ptr&lt;const FooData&gt;; FooState m_state; Foo(FooState state) : m_state(state) {} public: Foo changeSender(string sender) const { auto new_state = make_shared&lt;FooData&gt;(*m_state); new_state-&gt;sender = move(sender); return new_state; } }; The Foo class is quite DRY, because all the data is stored in immutable shared pointers which automatically know how to copy themselves around. All member functions of Foo should be const. If follows the usual paradigm of creating a new version of the object every time you want to make a change. Copying Foo is just a lightweight reference counter bump. This is nice if you need a lot of copies of something decently large but relatively rarely need to make changes.
Sigh... template &lt;class F, class C&gt; auto map (F f, const C &amp; xs) -&gt; rebind_template_t&lt;C, std::decay_t&lt;decltype(f(*begin(xs)))&gt;&gt; { rebind_template_t&lt;C, std::decay_t&lt;decltype(f(*begin(xs)))&gt;&gt; ys; std::transform(begin(xs), end(xs), begin(ys), f); return ys; } - Significantly shorter - Less restrictive: no need for allocator awareness, no dependency on `front`, and with a minor change could avoid dependency on a sized-constructor - With a single additional specialization of `rebind_template` it will work with any `std::array`-like object as well, unaltered: template&lt;template&lt;typename...&gt; class TT, typename... TTs, std::size_t N, typename... Ts&gt; struct rebind_template&lt;TT&lt;TTs..., N&gt;, Ts...&gt; { using type = TT&lt;Ts..., N&gt;; }; How would `std::array` support fit in to your approach..? (_Rhetorical._) This whole subthread is Dunning-Kruger in action, I don't think I have anything else to add.
**Company: [AutoX](https://www.autox.ai/jobs)** **Type:** [Full Time] **Description:** AutoX’s disruptive camera-first AI brings self-driving cars out of the lab and into the real world. We believe that autonomous driving should not be a luxury, and we are making it universally available to everyone. We needs great C++ coders to help put all advanced algorithms into real practice for our **autonomous driving platform**; develop scalable frameworks to support many types of vehicles and configurations; design efficient components and optimize existing software for limited compute platforms; collaborate with other engineers to implement, integrate, and deploy **robotic perception, mapping, localization, and sensor calibration software**... **Location:** San Jose, California, USA **Remote:** NO **Visa Sponsorship:** YES we sponsor or transfer **Technologies:** C++ * For system&amp;tools: Operating Systems, Databases, Concurrency, Linux Kernel, Compilers, Distributed Systems * For perception: algorithms, data structures and math in general * For mapping: mapping experiences * Robotics **Contact:** Apply through our job page or email me at **fyang@autox.ai**
I don't assume any of those things. All I said was that at the bottom of all machines is CPU operations. Many beautiful and elegant languages (like Lisp), operate on a "virtual" machine, some sort of idealized operations (lambda calculus or message passing, or whatever), while C++ operates on abstractions that directly map to CPU operations, without a compiler or interpreter in the way. Obviously compilation does a lot of transforms to code, but C++ still deals with real machine vocabulary. A Monad is not a machine vocabulary. Like someone said, there is plenty of room for both types of language.
Why does it have to be either or though?
This was about about std::string. There is no ambiguity or difficulty there (as far as size is concerned)
 for (auto i:indexes( std::min(v1.size(),v2.size() ) ) ){ f(v1[i], v2[i]); } where indexes (n) returns an index range upto n. There are too many reasonable ways to handle zip corner cases.
Out of curiosity what text editor was it?
Yes, it does not allow *any* change. It does, however, allow quite a lot. First of all, it allow any *syntactic* change: - lexing rules, such as allowing `&gt;&gt;` at the end of template parameter lists, - new keywords: such as `await` or `yield`, - fixing the Most Vexing Parse, - ... It could even allow forbidding `const` on the left side (an abomination, we all agree /s). There's a cost, of course; namely maintaining all set of valid syntaxes in the compiler. Secondly, it allows a subset of semantic changes, in various situations: - any change which does not affect interfaces is okay: - changing ADL rules, - forbidding 0 or NULL to initialize pointers, - any change which *expends* the ability of interfaces is okay: - allowing `auto` in type signatures or template parameters, - ... It's even possible for an old module to depend on a new module as long as the old module only uses the subset of the new modules whose interfaces it understands. I think this is a very promising system to manage evolution without the bloodshed of a revolution.
Ah, yep, true enough. My brain totally segued there.
I got u fam, [cppitertools.zip](https://github.com/ryanhaining/cppitertools/tree/cpp17#zip)
Just as with multiple inheritance I think template template parameters are useful as an implementation detail, such as when using policy based design, crtp etc... but I generally don’t use it as an architectural or API design.
Thanks for the write up; I didn’t have to do this for a while. On the conversion to using “bool” instead of “int”, if code expects the “true” value to be “1”, its perfectly safe to let the compiler convert “bool” into “int” as per §4.7/4 from the C++ Standard (Integral Conversion). So you can avoid littering glue code between C++ and C with “someboolexpr ? 1 : 0”.
Maybe see [Beast](https://github.com/boostorg/beast)?
https://pocoproject.org/
Just skimmed the documentation: There still doesn't appear to be any support for cryptographic signatures or even a basic understanding¹ of what they are and why not having them in a package-manager is simply completely unacceptable. I'm hesitate to say “use GPG”, since it's codebase is also completely unacceptable, but if you did, it would be a reasonable decission. ¹ If you [confuse hash-functions with signatures](http://docs.conan.io/en/latest/reference/tools.html?highlight=signature#tools-check-with-algorithm-sum), you have lost any credibility with regards to cryptography.
There are several C++ libraries for embedding HTTP-server: * [Beast](https://github.com/boostorg/beast) * [C++ REST SDK](https://github.com/Microsoft/cpprestsdk) * [Pistache](https://github.com/oktal/pistache) * [CROW](https://github.com/ipkn/crow) * [RESTinio](https://bitbucket.org/sobjectizerteam/restinio-0.4) * [Silicon](https://github.com/matt-42/silicon) 
Cool project dude ! 
Thank you !! I have been looking for a way to do this for a while. Does anyone know if ARM supports SIMD ops ? 
In my experience apache MPM modules are quite performant in a multithreaded environment.
Just for my own edification, are you talking about asymmetric cryptography / public key authentication? generally curious. 
!removehelp
Of course. You cannot create a secure code-sharing-plattform without.
Thanks. I know just enough about cryptography to be dangerous.
There is some ongoing work for using GPG for checking sources retrieval (https://github.com/conan-io/conan/pull/2356). For package signing in the public repositories, there is https://bintray.com/docs/usermanual/uploads/uploads_managinguploadedcontent.html#_gpg_signing
NP!
The cost is that overloading "/" to mean something other than division breaks generic programming.
Why? Is’t signature just crypto hash result of file?
Crazy, right?
Do you have a better term. I think we need one. For things like this, and for observer_ptr. 
Or range of char with length, maybe bundled together into a class so they don't get separated...
reference_ptr probably doesn't work for observer_ptr :-) I like transient, thanks. Others: contingent, ephemeral, dang (dangerous/dangling), cadged (like 'mooched', look it up)
Perfect! Thank you. 
I think its usage should just be less ubiquitous than its name would maybe imply. 
&gt; Is’t signature just crypto hash result of file? No, absolutely not. What you call a hash-function¹ simply takes strings of arbitrary length as input and outputs (pseudo-)random strings of fixed length, though same inputs will always have the same output. For now imagine it like this: std::uint64_t hash(std::string_view str) { static std::map&lt;std::string, std::uint64_t&gt; map; if (auto it = map.find(str); it != map.end()) { return it-&gt;second; else { auto rd = std::random_device{} auto dist = std::uniform_int_distribution&lt;std::uint64_t&gt;{}; const auto val = dist(rd); map[str] = val; return val; } } On it's own thats pretty much useless, except possiblity to check whether a transmission got corrupted by accident. In that case it provides some safety but no security, since an attacker could simply replace the hash. A signature on the other hand ties a string to an idendity. I have a public key (pk) that everyone is allowed to know ad well as a secret key (sk) that only I am allowed to know. If I want to sign something I can put my secret-key and the message into an algorithm and get back a signature. Since only I have sk, only I can do that. There is also a verification-algorithm, that takes the message, the signature and pk and returns one bit, whether the signature was valid. Since pk is known by everyone, everyone who has the message, the signature and pk can verify that I did indeed sign this myself. The security-notion that we usually demand from signature-schemes is called EUF-CMA (Existential UnForgability under Chosen Message Attacks), which roughly states that even if I sign everything that you ask me to sign as often as you want, you will not be able² to find any message-signature-pair that I did not give to you previously. Signatures allow us to publish a public-key once and from then on proove that some message (in this case: software-archive) was indeed created by us and not somebody else. To get the thing to the point where it scales well, you would also have to introduce some form of key-signing where some people/organisations verify other peoples public-key by signing the message “`$PUBLIC_KEY` does belong to `$PERSON`”. For a proper software-manager you would usually have a bunch of big organisations that you would trust as well as some developers that you have reason to trust in (for example because they are publicly known to maintain widely used software). It's important that the users should tell the system whom they trust, otherwise the whole thing is pointless. Hashes are building-blocks and pretty much every signature-scheme you will encounter in actual use will use hashes to shrink the message-size, but technically this is not necessary. You can furthermore build signature-schemes from hash-functions, though the result is not very efficient (but secure against quantum-computers!). Finally, since this is a widespread missbelieve: Signing is not encrypting with the private key of a public-key-encryption-scheme. The only scheme where this is kind-of true is textbook-RSA which is totally insecure for both signing and encrypting. (Secure versions of RSA do exist, but for them the statement doesn't hold.) [1] “What is a hash-function?” is a shockingly complicated topic. What I'm explaining here is the random-oracle-modell, since it is easy to get a rough idea, but it is, mildly put, a highly controversial model among cryptographers. [2] This is simplified; a more precise definition would be this: There is no probabilistic attacker with polynomial runtime in the security-parameter with a chance of success that is higher than any inverse polynomial in the security-parameter.
&gt; Linear Algebra is deep, and numerical linear algebra is even more so. New algorithms are appearing over the decades. The closest things to standardise is Matrix/Array/Tensor ABI, BLAS API and LAPACK API in my mind. Do we know where is the cut off for standardisation? I would suggest porting Python's [Scipy](https://docs.scipy.org/doc/scipy/reference/py-modindex.html) and [Numpy](https://docs.scipy.org/doc/numpy-1.13.0/reference/) to C++. Imagine having all these algorithms and numerical infrastructure in C++; the optimizations that could be done, the libraries that would be built on top of this... 
**Company:** [NVIDIA](https://nvidia.com) **Type:** Full Time **Description:** We make parallel computing platforms! You've probably heard of NVIDIA, but you may not know that we have a rich history as a C++ shop. C++ is the programming language used by CUDA, our parallel programming environment and SDK, and a large part of our codebase is written in C++. We do make hardware, but we're also a software company. NVIDIA is a great place to work for C++ devs these days, as we're at the forefront of a number of booming technologies, like parallel computing and machine learning. Come join us! **Location:** Santa Clara, CA, USA or Pune, India. **Remote:** No. **Visa Sponsorship:** Yes, but not for new college graduates. **Technologies:** C++03/11/14 and Boost. Experience in at least one of these areas is strongly desired: parallel/concurrent programming, machine learning, or graphics. Experience with any of the following is desirable: Linux kernel development, Windows driver development, processor emulation, hardware design, CUDA, DirectX, Clang/LLVM, TensorRT, or TensorFlow. We are primarily a Windows and Linux shop. **Contact:** blelbach@nvidia.com, @blelbach on Twitter or wash on the C++ Slack/Freenode IRC.
This is the top-level comment for **meta** discussion. Reply here if you have questions or concerns about this post.
**Company:** [NVIDIA](https://nvidia.com) **Type:** Full Time **Description:** We make parallel computing platforms! You've probably heard of NVIDIA, but you may not know that we have a rich history as a C++ shop. C++ is the programming language used by CUDA, our parallel programming environment and SDK, and a large part of our codebase is written in C++. We do make hardware, but we're also a software company. NVIDIA is a great place to work for C++ devs these days, as we're at the forefront of a number of booming technologies, like parallel computing and machine learning. Come join us! **Location:** Santa Clara, CA, USA or Pune, India. **Remote:** No. **Visa Sponsorship:** Yes, but not for new college graduates. **Technologies:** C++03/11/14 and Boost. Experience in at least one of these areas is strongly desired: parallel/concurrent programming, machine learning, or graphics. Experience with any of the following is desirable: Linux kernel development, Windows driver development, processor emulation, hardware design, CUDA, DirectX, Clang/LLVM, TensorRT, or TensorFlow. We are primarily a Windows and Linux shop. **Contact:** blelbach@nvidia.com, @blelbach on Twitter or wash on the C++ Slack/Freenode IRC.
Brand new implementation, not derived from the experimental one. Doesn't allocate memory for path::has_foo. Supports symlinks and junctions. Doesn't chdir to implement absolute(). Engages Win10 RS1+ NTFS POSIX delete semantics for more reliable remove_all. Probably a whole bunch more other improvements, almost every time I tried to demo improvements I ran into bugs I was *not* trying to demonstrate. Note that we think there are enough breaking changes that we do not auto upgrade callers of the experimental one to the std one, the experimental one will be left untouched until sometime it is removed completely.
Win10 RS1+ POSIX delete semantics? Are you saying windows finally after all these years allows you to delete an open file? Any link? We've been struggling with this...
Will be glad if I can get some feedback on it, the project is still at early stages.
Great!!!
RS1+ only, NTFS only, yes. If you call std::filesystem::remove we handle the "try POSIX thing and fall back if that fails" for you. ``` [[nodiscard]] __std_fs_remove_result __stdcall __std_fs_remove(const wchar_t * const _Target) noexcept { // remove _Target without caring whether _Target is a file or directory __std_win_error _Last_error; #if _STL_ALWAYS_HAS_SetFileInformationByHandle #define _SetFileInformationByHandle SetFileInformationByHandle #else /* ^^^ _STL_ALWAYS_HAS_SetFileInformationByHandle ^^^ // vvv !_STL_ALWAYS_HAS_SetFileInformationByHandle vvv */ const auto _SetFileInformationByHandle = __vcrt_SetFileInformationByHandle; if (_SetFileInformationByHandle == _Not_supported_SetFileInformationByHandle) { // Windows XP if (RemoveDirectoryW(_Target)) { // try RemoveDirectoryW first because it gives a specific error code for "the input was a file"; // DeleteFileW on a directory input returns ERROR_ACCESS_DENIED return {true, __std_win_error::_Success}; } _Last_error = __std_win_error{GetLastError()}; if (_Last_error == __std_win_error::_Directory_name_is_invalid) { // input may have been a file if (DeleteFileW(_Target)) { return {true, __std_win_error::_Success}; } _Last_error = __std_win_error{GetLastError()}; } return {false, _Translate_not_found_to_success(__std_win_error{GetLastError()})}; } #endif /* _STL_ALWAYS_HAS_SetFileInformationByHandle */ constexpr auto _Flags = __std_fs_file_flags::_Backup_semantics | __std_fs_file_flags::_Open_reparse_point; const _STD _Fs_file _Handle(_Target, __std_access_rights::_Delete, _Flags, &amp;_Last_error); if (_Last_error != __std_win_error::_Success) { return {false, _Translate_not_found_to_success(_Last_error)}; } // From newer Windows SDK than currently used to build vctools: // #define FILE_DISPOSITION_FLAG_DELETE 0x00000001 // #define FILE_DISPOSITION_FLAG_POSIX_SEMANTICS 0x00000002 // typedef struct _FILE_DISPOSITION_INFO_EX { // DWORD Flags; // } FILE_DISPOSITION_INFO_EX, *PFILE_DISPOSITION_INFO_EX; struct _File_disposition_info_ex { DWORD _Flags; }; _File_disposition_info_ex _Info_ex{0x3}; // FileDispositionInfoEx isn't documented in MSDN at the time of this writing, but is present // in minwinbase.h as of at least 10.0.16299.0 constexpr auto _FileDispositionInfoExClass = static_cast&lt;FILE_INFO_BY_HANDLE_CLASS&gt;(21); if (_SetFileInformationByHandle(_Handle._Get(), _FileDispositionInfoExClass, &amp;_Info_ex, sizeof(_Info_ex))) { return {true, __std_win_error::_Success}; } _Last_error = __std_win_error{GetLastError()}; if (_Last_error != __std_win_error::_Invalid_parameter) { return {false, _Last_error}; } // Filesystem without POSIX delete support, or older than Windows 10 RS1 version without such support: FILE_DISPOSITION_INFO _Info{/* .Delete= */TRUE}; if (_SetFileInformationByHandle(_Handle._Get(), FileDispositionInfo, &amp;_Info, sizeof(_Info))) { return {true, __std_win_error::_Success}; } return {false, __std_win_error{GetLastError()}}; #undef _SetFileInformationByHandle } ```
Ah, yes, that's right. We now support / handle a user doing `\??\`, `\\?\`, or `\\.\` in their paths without choking on that. We do not attempt to transform paths without such prefixes into one with such prefixes.
What happens if I try to use this on a windows 7 box?
Cheers from russian travellers - getting US Visa can indeed be a long task. That you are willing to send invitations before registration is a noble deed.
You're the Mod, first comment and first job poster...Nice!
Thanks. I will take a look at it. What was the exact configuration?
We support this all the way back to XP. (You won't get "delete while open" semantics on Win7 but that's because the OS has no support for that)
http://en.cppreference.com/w/cpp/utility/tuple Copy, move, equality and less-than comparison are generated if the member types have those functions defined. You can make the immutable with const member types, although that may be overkill. For hash, you can write a generic recursive hash for tuples.
Very foresightful. Good job!
vista?
shadow?
And so it begins...
April fool ?
I certainly hope so
It has to be, right? This would completely destroy C++.
Given the reference to garbage collection at the end, I'm pretty sure it is.
An idea whose time has come. No longer should we be bound by legacy constructs from C. But why stop here. We should eliminate other bug ridden constructs. Raw C arrays with their strange decay to pointer rules. And how often have you debugged a problem only to discover it occurred within a C style function body? There is much to clean up in C++, and today is the day to do it on. Write it diwn: April 1, 2018. The day C++ finally incremented beyond C.
We either get some really huge change or one of the best april fools joke. Good shit OP
I could not include standard library headers.... &gt;&lt;source&gt;:1:10: fatal error: 'type_traits' file not found &gt;#include &lt;type_traits&gt; 
I forgot what day it was and nearly had a heart attack reading this headline
The MIT license says "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software." Your github project does not do this, you only state "Licence: MIT" :)
**Company:** [Applied Research Associates](https://www.ara.com/). [Careers page](https://recruiting.ultipro.com/APP1010ARAI/JobBoard/07442cec-d18e-4589-ab15-8342edc29af7/?t=physicallocation&amp;v=9033f5bc-5190-574b-a1e7-f7997b975bf7&amp;q=&amp;o=postedDateDesc) **Type:** Full time, internship **Description:** With ARA’s Advanced Modeling &amp; Simulation Systems team in Raleigh, NC, you will support our growing business in the areas of physics-based simulation, geometric modeling, and GIS. Our team focuses on modeling a diverse range of phenomena including weapons effects, blast modeling, structural damage, collapse, equipment response, and sensor systems. C++ developer specialties within the team include 3D graphics, artificial intelligence, GIS, databases, big data, and geometric modeling among other skills relevant to modeling and simulation. **Location:** Raleigh, NC is the primary office hiring C++ developers. **Remote:** No **Visa Sponsorship:** No. Due to the nature of the contracts employees must be US citizens, with the ability to obtain a security clearance. **Technologies:** Currently using C++11 in most of the codebase. Development is currently on Windows using Visual Studio. Familiarity with development on Linux desired. Experience with other languages such as Python also desired. Git is the primary SCM. **Contact:** If you have any specific questions about any positions listed in the above company careers page, please PM me.
why separate from the currently active slack one?
The currently active slack(and all other slack communities) suffers from one major disadvantage - the majority of discussions and history is hidden behind a paywall. This is the reason why we chose discord in the first place. But this isn't the primary reason people should choose to join discord server. Our community is far more beginner friendly and our intent is quite different from currently active slack community. We focus on peer-learning through active participation in code reviews, weekly problems, requested tutorials etc. The project based learning approach was done in offline communities first and then requested by friends to bring similar thing to online social communities and people are already actively participating in it. I hope to see more participation since its the #1 question that people ask after learning some parts of language - _what should I create with it_. Most of these are missing from slack community and (in my experience) it seems more directed towards the experts/masters of c++ language. Hope this answers your query :)
Use `-stdlib=libc++`.
-fconcepts just like GCC, Nice! Suggestion: Why don't u post a permlink with some examples showcasing the support on the site.
Shouldn't this thread be in contest mode like last time? Because currently we can vote on jobs...
 std::cout &lt;&lt; std::floor&lt;std::chrono::days&gt;(std::chrono::system_clock::now()); Neat
My eyes! 
This is obviously a case of first of April, but I for one would like to go into that direction for real.
Fools day aside, I'd be really happy if arrays got an overhaul.
Thank god these are the top comments! I've gone through a series of serious/non-prank content and this totally caught me off guard. Whew...
&gt; The day C++ finally incremented beyond C Love this line
Ever heard of Java?
Would love to experiment with it on my local machine. Is there a good description on how to create a fully optimized build of the toolchain - using libc++ - for Linux somewhere? I found bits and pieces in the past, but almost always ran into problems sooner or later.
&gt; We support this all the way back to XP. My condolences. I know it is OT, but is there any official word if/when XP support in msvc gets deprecated? In particular, how much advanced warning can we expect, before support for XP gets completely dropped?
I have no problems with that. Give me optional references though and I'll happily ditch many uses of raw pointers. I've thing I disagree with the article: when ownership semantics are not needed, passing references **and** raw pointers as parameters are a better alternative to passing smart pointer. Actually, I think it's a mistake a lot of users do when they start to use smart pointers. When a function need to do something with an object but don't need to know how they are allocated, then don't pass a smart pointer. Pass a reference. That's because if the function doesn't have to know about it's allocation strategy or ownership strategy, then it should not know. It makes refactoring easier and your code faster. I have to agree though that passing a pointer may not be the ideal but hey, we don't have optional references yet.
Well, just give me optional references and we'll talk! Funny thing this is almost how I do things now. The only thing I don't do is reference wrappers as members, but I'm thinking about it.
Java has virtual machine. How can't cpp support a function as: foo(int *ptr)
ICI Services opportunity in Oxnard, CA (C++, .NET, and F#): https://www.linkedin.com/jobs/view/607325334/ 
std::array is as good as we get.
I've been using `boost::optional&lt;T &amp;&gt;` a lot and a bit concerned with what we'll do when C++17 is a thing in our org and people now have to choose between std and boost for this... `std::optional&lt;std::reference_wrapper&lt;T&gt;&gt;` has good (ideal, IMO) semantics, though it's unfortunately a bit verbose to use `opt.value().get()` vs. just `*ptr`! The price you pay for type safety...
Oops.
``` safe { // Write Rust here } ```
I agree in principle, but C++ being hard keeps my salary up so there's that.
&gt; TFW an idea you proposed unironically is written up as an April Fool's joke a few weeks later.
Can't you just fork the language then?
Lifetimes are a solution. struct MyStruct&lt;'a&gt; { const &amp;'a char my_string; }; const &amp;'a char return_field(const &amp;'a MyStruct my_struct) { return my_struct.my_string; } Here we have a lifetime called 'a. MyStruct doesn't own the data of the char*, so it has to declare a lifetime to say that "the data that my_string points to must be alive until the instance of the MyStruct is destructed. Also, while the MyStruct is alive, no other code can modify the original value". The function says: given a MyStruct, I will return a reference that will live as least as long as the MyStruct instance. Now, in complex scenarios, you'd still need raw pointers. Lifetimes + borrow checking are a solution, maybe not *the* solution. But you can go pretty far with them.
Don't forget to fix signed/unsigned convertion rules and get rid of unintuitive C declaration syntax.
`char8_t` might happen, and it's a breaking change
&gt; Trump coming up with changes to gun ownership laws
Inb4 C++20 date/time
Imagine if it was with 2d graphics proposal. People would not believe it was not a troll proposal
You mean this would indicate that they would be willing to also make breaking changes to native arrays too? I'm not sure if you can compare altering the meaning of a relatively recent feature (u8 suffix) with making changes to a fundamental part of the language that probably existed since the early days of C.
This will make C++ *far* more difficult to use in embedded.
Or D++ :P
I hate this day. Not interested in pranks, dont like dealing with people in general... and this day I have no process everything with even more skepticism.
Apparently the 2d graphics proposal has evolved far beyond Cairo. Not sure it's true. I'd really love for the graphics SG to inform people about how the proposal has evolved and "neutralize" a bit of the bad press it has gotten - if it's really better now, that is. But the fact is, I don't know - all I know is that in the beginning it was based on Cairo and it was pretty much horrible.
D already exists
raw pointers can be thrown away. There are unique pointers and shared pointers that can do the job. With them, we may not need new. functions like make_shared() could do pointer creation. (just a guesswork)
Popup window? Have a downvote. 
A lack of pointers in C++ would screw over the embedded systems industry. I use lots of modern C++ features, but sometimes you have to use raw pointers and even sometimes inline assembly to have code work efficiently and take up less space
There is no official word with regards to "when". With regards to "if", yes, we will deprecate XP. When XP support gets deprecated, it's very likely we'll continue to support an XP-capable toolset for years in the future. This may not include new feature development, but almost certainly will include bug fixes and security fixes. This, despite the fact that anyone running XP already has the world's biggest security flaw: an 18-year old operating system. 
They are pointers in Java
I think, it would be nice to put note somewhere in the title (instead of readme) that Boost.Context was used and not experimental C++ stackless coroutines since the difference is huge and expectations will be different. More precisely, I saw the example and was curious how do you manage "tasks" and other things you need to think when using C++ coro
You can be smarter than Boeing with this one neat trick https://www.forbes.com/sites/leemathews/2018/03/30/boeing-is-the-latest-wannacry-ransomware-victim/#69ea0e8a6634
Not sure if serious or April fool's.
array types as literal value types: yes, now! That's by the way a problem that's been addressed by D. Making string_view a literal type and the type of a string literal would also be great. removing raw pointers: please no.
Could you elaborate on the declaration syntax? Btw. The committee is seriously considering to make signed/unsigned comparison safe(r) so that `-1&lt;0u` becomes true. Of course that is just one of the many pitfalls there.
I know of course...
Very very few raw pointers in my program are derived from the result of (manual) new. Should we get rid of new and delete? Maybe/Probably (although you of course need something to implement smart pointers). Should we get rid of raw pointers? I don't see the benefit.
Not at all. They much more behave like shared_ptr. Aside from the completely different ownership model, each access is checked against nul, you can't perform pointer arithmetic on them and there are a ton of dangerous casts you can do on c++pointers, but not with Java references. 
- fix pointers and references to that: - `T name[N]` becomes `T[N] name` - `const T(&amp;) arr[N]` becomes `const T[N]&amp; arr` - `int i, *p, arr[10]` is invalid - `T* p1, p2` declares 2 pointers - and so with function pointers
Either way, this is a huge troll.
What’s wrong with [ifstream](http://www.cplusplus.com/reference/fstream/ifstream/ifstream/) ? fopen isn’t c++, it’s C.
Oops. It should get fixed in an hour or so, sorry about that!
No need to wrap system or C header includes in `extern "C"`, they already have that (along with `#ifdef __cplusplus`). Also, I too thought this used the coroutines TS that clang added support for in 5.0, which would have been cool.
Why is it that there was a blog post from last week (March 26, 2018) that says the same thing: http://www.modernescpp.com/index.php/no-new-new Was that an early April Fool's? Was that just part of the elaborate hoax?
**Company:** [VividQ](https://www.vivid-q.com) **Type:** Full Time **Description:** VividQ is the ultimate solution for 3D visualisation, enabling 3D data to be captured, stored, transmitted and displayed as genuine 3D holograms, in real time. The company offers a complete, end-to-end software suite, which improves the efficiency of any system making use of 3D data, and enables truly holographic mixed reality with multiple depth planes. VividQ was founded in February 2017, with the aim to master 3D data processing and holographic image generation. With seed funding, VividQ has grown its Commercial and Technical teams, made a full software release, and secured partnerships with world-class clients across data processing and display markets. Today, with a set of proprietary, patentable algorithms, VividQ establishes a new software standard for 3D data compression and real-time holographic displays. The company is currently closing an A round of funding, looking to raise a B round by the end of 2018. The successful candidate will be responsible for extending and maintaining the code base. The VividQ API is highly optimized to facilitate fast true 3D holography. The senior software developer is expected to be well trained in profiling and optimizing performance of software. The successful candidate will be involved in the full development cycle. As a senior member, this position requires good communication skills that allow other (more junior) members of the team to benefit from the senior developer's experience. Skills we are looking for: • Strong C/C++ is a must (3+ years) • Experience with API development in Windows • Experience with any of the following: CUDA, OpenGL, DirectX, Vulkan, C#, Unity • Experience with version control (Git, svn,...) • Strong problem solving abilities and a drive to deliver promptly • Good communication skills It would be great if you: • Have an interest in the AR/VR field • Have an interest in high-performance parallel computing • Have an interest in 3D data compression or computer vision **Location:** Cambridge, UK **Remote:** No **Visa Sponsorship:** No **Technologies:** C++11, Boost, CUDA, Unity. Our development environment is Visual Studio 2017 on Windows, using Git for source control. Experience with CUDA, OpenGL, DirectX, Vulkan, C#, Unity is desirable. **Contact:** To apply send over your CV to info@vivid-q.com and a couple of lines why you believe you would be a good fit for VividQ.
I hope this is true. At least there will be a fork outside the hands of the clowns at the C++ committee.
I am interested in cppfuck if you have some
It might be fixed by now, feel free to give it another try! :\)
Poorly timed post, but it's not an April Fool's!
Yes, we need pointers. But hiding them really well is my personal best practice. Something like a double deference offends me now. 
The requires(T a, T b) {...} syntax is not supported, all other parts of the syntax are supported.
This isn't April fool's. If you're getting errors, please do open an issue on my github repo as stated in the OP to help me get this working :) 
NB: You can fix the email link by changing it to \[contact the conference organizers](mailto://info@cppcon.org)
I'm sure it's an Apr fool's thing 
This appears to be an actual series of patches, not a joke.
Yea obviously it's an April fool thing. Don't you know Torvalds opinion on C++...? :-) But the guy went through real lengths creating all these patches... wow!
Yeah I should've probably thought about this before posting lol :P
Right decision. Way better make :)
Yeah, It looked real. I will rather hope and wait
Oh, that makes a lot of sense now, thanks! It sound like the IDEs will get into a tight bind when we move into the new module-only era. In the interim, more and more hacks/special cases...
it is an April fool, because in linux kernel there is a word "class" which will not compile by a c++ compiler (about class word I have seen it in Kroah-Hartman, Greg youtube video).
[Similar and interesting](https://bugzilla.kernel.org/show_bug.cgi?id=191051)
Given that it makes reference to Boccara's blog post made today, I'm guessing they fudged the date on that post.
Or 'Rust'. That's a cool name.
You can always use `#define private whatever` and it will work just fine*^(just need to undef it later)
What happens to the program that held the handle to the file when you delete an open file? Does it have a way for failing gracefully?
This is high effort, regardless of its status as a prank or not. 
Except that it's undefined behaviour if you include any standard library headers :)
No idea, I didn't test. If they don't want that all they have to do is not specify FILE_SHARE_DELETE on open.
Which you wouldn't in kernel code.
Hopefully compilers will have a flag to see what happens with the other option.
I'm assuming older programs don't though.
I would expect most programs don't. The intent is to avoid conflicting with programs which are trying to avoid being a problem, like A/V tools; not to be forceful deletion out from under programs that don't want to allow it. To clarify, we aren't working around `ERROR_SHARING_VIOLATION`, we are working around files which have successfully gotten delete on close set but are still present because they have open HANDLEs.
Regardless of joke status... I'm honestly surprised by how few changes it took him to get at least one of the many files compiling. It'll take _way_ more work to do anything real. Of course, banning constructors and destructors is basically throwing away the baby, bathwater, bathtub, plumbing, and sewer system of the language. I foresee one of three outcomes: 1. Linus sees this and says "Haha lol funny joke ok bai." 2. Linus sees this and delves into a rage, at which point Howells will shout "It's just a prank bro!" while getting beaten on the pavement by kernel developers. 3. Linus sees this and says "Oh nice. _merge_." (Not likely.)
You can try. Good luck.
OH here we go. One of the guys that profit from making things more complex without actually solving any real problem.
Hope Jetbrains will support conan soon.
Well, doing something about it means you have the resources to do it. I don't, and many others don't. We have full time jobs and families to support. Kitware has the resources, so if lots of us tell them 'hey, your product stinks in this in that', maybe they care enough to fix it. 
A link would help. ;-]
Sorry forget it.
It seems to guy did actually do the work required and found some issues with g++ that gcc didn't pick up. He submitted patches for those issues.
Poland, Bulgaria, Romania, and Croatia.
Rewrite a drive or something? Hard to suggest anything without knowing your skill level
!removehelp
No, I don't think you understand how hard it is to start a programming language.
Does `ifstream` do `mmap`?
Good things come to those who do CI :)
In a globbed system, the directory contents become one of the inputs to the build system, yet they are not versioned. All modern VCSs let you get away with changing the directory and not being aware of it via ignores, or committing without noticing an added file of there’s lots of changes. It makes it harder to reason about the correctness of the build. Globbing saves time only when you first add CMake to a big code base. Later on, it’s a hindrance. 
To support this in C++, you need metaclasses. That’s all. Your problem then reduces to straightforward library code. 
Unfortunately, it's not a joke. That makes MSVC the only mainstream compiler without concept support ! Sorry :D
I can’t believe that anyone would still say that. Code generation makes you more productive. You essentially dislike using tools. That’s not something to brag about...
I’d even argue that if your build system doesn’t easily accommodate custom tools, it is hindering your productivity. I can’t imagine going back to a “pure” no-code-generation environment. Even small projects we do at work now include a clang build and deploy several little clang-based tools that make our life easier, and those are all used to generate code for our code in the project. 
Oh but it is even undefined behavior regardless of what you include, even if you only do that on your own classes. The reason is that the compiler is allowed to consider that private really means private, and emit code accordingly. Some already use that to e.g. optimize some accesses to private members, for example if according to the language rules it seems that all the possible accesses are visible in the same TU. So at least if you break ODR (by inconsistently applying an illegal define on the private keyword) you can already run into troubles. Defining keywords is explicitly undefined behavior according to the standard, IIRC, so even if you see "no reason" that something would break (on this keyword or others), don't do it. Because you'll either miss something right now, or a future compiler will be sufficiently smart to break your assumptions. 
There is a simple reason; it explicitly undefined behavior. And clang already do optims considering that private really means what it means, IIRC.
Jokes on the LKML are often practiced through actual series of patches, and most of the times they even compile (and maybe run)
moc and other code generators are such a straw man. My experience leads me to paraphrases everyone complaining about code generators to mean that they dislike using tools to automate menial tasks and would rather be less productive. It’s an instant interview disqualifier. Such an attitude is precisely what we don’t want in an employee. I want people I work with to be productive, to write correct-by-design code through the use of state machine tooling, lexers and parsers, introspection metaclass generators, etc. People who complain about moc are either working on toy projects or have an extremely productivity-robbing attitude to their self-professed big project work. My general approach is to keep the codebase growth slowing down in relation to the pace of feature additions. Tooling and code generation are a critical enabler of that. 
If moc is a complication, you’re working on you projects... 
Moc is a code generator. So are many other tools you should be using, or already are - including the compiler. It most definitely is not a preprocessor like the C++ preprocessor is. It does not transform the code. It only adds new code. If you shun code generation, I shudder to think about all the time you may be wasting doing menial stuff instead of relegating it to the tools. 
I don't know if it does or not, but according to [this benchmark](https://lemire.me/blog/2012/06/26/which-is-fastest-read-fread-ifstream-or-mmap/) performance of fstream is comparable to mmap, so either it does, or it doesn't matter?
&gt; Regardless, defining private in one TU and not in another would violate ODR, and always defining private in all TU is not very interesting. It can change object layout, which can be interesting. Not often probably, but possible.
IIRC (going by memory, not evidence), MSVC groups members by access level, so if you define e.g. publics then privates then publics, all the publics get grouped together. Consequently changing everything to private would change the order of members and potentially the size and alignment of the object.
Possibly not! The reason we opted to use `decltype(auto)` was so that the constness of `v1` and `v2` are passed onto the elements accessed by `boost::get` but after some messing around it looks like `const auto&amp; elements` would've worked. 
Qt's moc being less painful than most build tools doesn't make it painless either. I'll take anything that can reduce the pain of setting up my builds.
Microsoft supports clang as the front end, that should help you get some decent cross platform support.
Fair. I guess that changed over time. Messing with ODR definitely won't turn out well either way. My comments were on the act of redefining the keyword rather than what further consequences it has on the following code.
While it is undefined behaviour, I have yet to see any implementation where it wouldn't work, as the preprocessor will happily work as stupidly as a regex parsing html. Obviously it's bad, macros are terrible anyway. But only the preprocessor would see "private", so I think it wouldn't break anything. https://godbolt.org/g/kmAQWU (very shitty example but it proves my point that every compiler is stupid when it comes to macros).
I understand what you say, and in very controlled environment I would even myself not be afraid of such hacks, but be careful with the "I have yet to see any implementation where it wouldn't work" stance. They are famous last words before nasty bugs :p Also, compiler authors are getting more and more creative with the kind of optimizations and otherwise various features that the letter of the standard allow them to implement; so if something is not guaranteed by anything (not the language standard, nor the platform standard, and also not the compiler manual), you better avoid known pitfalls if you are making a piece of software susceptible to be recompiled in a few years. Also, think of third party non-compiler tools: IDE or even static analysis tools might be disturbed by things that are not supposed to exist.
&gt; In a nutshell: Is this sort-of a modern version of MPI? So if I've used MPI 5 years ago but probably never use it again because it's a horrible old C library, but I need something like MPI today - would HPX be what I need? HPX can be used to implement things that conventionally have been based on MPI. The API and concepts are very different, though. &gt; It's a bit too bad though that it still depends on Boost - with C++14 (and more widespread adoption of 17 around the corner), really most things you should need are in the standard library - and the things that are not you would probably write by yourself anyway or there's nice modern projects/headers for it on GitHub. There are still things like Boost.Spirit or Boost.Accumulator that I wouldn't like to miss and that have no replacement. For all things that can be replaced the HPX team works hard on gradually doing so.
&gt; Every feature since C++1 simply do not advance my business bottom line one inch. Okay, so: * Either you aren't in the C++ business or I don't believe you. * Are you really going to tell me with a straight face that there was not a single thing in C++11 that you care about? * C++ is a successful language because it is multi-disciplinary and multi-paradigm. C++ has experienced a resurgence in recent years due to C++11/14/17. * There are 5 million C++ users world-wide in a broad range of industries. Every group has varied and sometimes incompatible requirements and priorities. * We don't try to satisfy everyone's requirements and priorities because that is impossible. We prioritize the things that will have greatest impact to the C++ community as a whole 5-10 years in the future. * So user feedback is useful, but your business needs are not any more important than the other 4,999,999,999 C++ programmers out there. * Some people, such as yourself, will always be unhappy with our prioritization, because they are thinking about how our work will affect them/their project/company/industry personally. Most people do not have empathy and fail to recognize that not all 5 million C++ programmers share their requirements and perspectives. We all live in our own bubbles. Some examples from your post: &gt; All the complexity added just to make templates work. * Some C++ users don't use templates at all. * Some C++ users consider templates and generic programming the most important C++ feature. * Some even write "C with Templates", eschewing all other features, including classes and object-oriented programming. &gt; However much easier is to use Ninja or Mako templates and generate code. Simpler and way more maintainable - you don't need to hire a "C++ guru", you can just hire someone out of school. * Some projects use external tools for code generation. * Some projects go to great lengths, such as template-based domain specific languages, to avoid using external tools/code generators. For example, Boost.Spirit instead of bison. * Some projects even make header-only libraries to avoid having to deal with shipping binaries. * Why? Because expressing things in pure C++ can be less brittle and more portable than having to deal with binary distribution or code generation, both of which can be brittle. * Most C++ users would probably say that all these approaches are valid, depending on the project. &gt; The way it is right now, it only benefits Sutter and friends, who make delix money every time a company hits the complexity wall that they built from inside. Huh? I've worked with Herb for a number of years. * He's one of the people pushing for things to be simpler. * Herb doesn't own stock in "C++ Incorporated" because that's not a thing. * There is no secret cabal of C++ book authors and trainers scheming to make the language more difficult or complex. Complexity doesn't help them or provide job security, it makes things more difficult for them. * The authors, trainers and teachers on the committee are the people who push the rest of us to keep things simple and avoid complexity. Also what is "delix"? &gt; Qt is what C++'s STL should have been ... I probably can't do this justice, so I'll just invoke /u/cs_barbara and /u/asermersheim to formulate a proper response to this. &gt; On the STL side, most of the maintainers acknowledge it has tremendous flaws and it is unusable. ... Paging /u/stl, /u/CaseyCarter (MSVC standard library maintainers), /u/redi, /u/rodgertq (GCC libstdc++ maintainera), /u/mclow, and /u/EricWf (LLVM libc++ maintainers). Do any of you feel this way? &gt; Why don't you take this kind of criticism, We do. &gt; have a look We have. &gt; if it has any merit Feedback always has merit. 
At the moment I do have few things in mind, one is implementing concurrency which since I am using Golang, should be my tag line but that will be done only after I implement the import feature, with which someone can have separate Recipe files for separate folder and import all of them into the parent Recipe which is on the top of the hierarchy and has the main entity. One advantage of having entity vs a list of sources is, if you want to not include an entity and its dependencies you could just erase its name from the entity which depends on it and cook will skip building the excluded entity and its dependencies.
You can get the whole studio for free with an open source license
As of today, I think Clang is the best Open Source C++ compiler with cross-platform support. As noted by [u/lanevorockz](https://www.reddit.com/user/lanevorockz), MSVS supports Clang. Over the past few years, many great people dedicated their time to make Clang available for Windows users. Also, to get an idea of how good Clang support on Windows is: Google Chrome devs recently modified their buildbots [to use Clang](http://blog.llvm.org/2018/03/clang-is-now-used-to-build-chrome-for.html) on Windows. Originally, Apple switched to LLVM Clang (although they use a modified version of it) in macOS, which made Clang the default compiler on Mac computers. Also, Clang is mostly developed on Linux, so Linux support is very strong there. All in all, Clang looks very solid on all major platforms.
!removehelp
Well I am stopping here, after you called out so many people. Last time (another account) someone doxxed me and sent a message to my employer. I have family. Apologize. Bye.
http://en.cppreference.com/w/cpp/links#C.2B.2B_Language_and_library_references
Nice link. Thanks!
Looking at the code/documentation it doesn't seem that you're doing this idiomatically. Take a look at the way that `boost::asio::use_future` and `boost::asio::yield_context` are implemented: You're supposed to use the customization point offered by [`boost::asio::async_result`](https://www.boost.org/doc/libs/1_66_0/doc/html/boost_asio/reference/async_result.html).
Keep tuned to https://github.com/conan-io/conan-clion-plugin
It's true that we can rely on the implicit conversion for syntactical and semantic correctness. However, I like to leave the noise in place to remind me that this is a temporary placeholder and what we really want is for the function to return `bool` at some point later down the road.
Yes, I got so tired of looking these up that I linked the C++11, C++14 and C++17 drafts on the right sidebar at the [Utah C++ Programmers](http://utahcpp.wordpress.com) wordpress blog.
Because it's both simultaneously better than and worse than IRC and it includes p00p emojis.
Yes.
The absolutist approach to undefined behavior never applies to the implementation, because there are tons of stuff that can't be expressed as pure strictly conforming library code. However, while I *would like* implementations to take a forgiving approach, they are not doing that, quite the opposite, and they show little sign of reversing their direction, unfortunately. So better be safe than sorry, especially for such insane things as defining private to something else, or things of that level. A few years ago when I only began to understand the consequences of the modern approach of C++ compilers, I still was not very worried about that kind of stuff, and would happily use ugly hacks because I "knew" that they were "safe". I knew shit. I knew shit at that time, and the actual situation now is actually way "worse" now than what it was at that time; now some people will pretend that it is not "worse", it is "better", because my program was "meaningless" and I should be punished for that instead of punishing the geniuses who wrote meaningful programs by making their "slow". Like they exists :/ Anyway I'm with you on what should be software engineering, but the unfortunate state is that today, if you really want to program in C++ for serious stuff, you have to be extremely paranoid, and see the compiler as an adversary. And look for real reasons about why you can use some explicitly undefined behavior fearlessly -- because in an astonishingly high number of cases, you actually can't. Note that all of these considerations mostly do not apply if you are programming things in which bugs do not matter (much), for example a video game. That's not my case, and unfortunately I'm working on legacy C++ codebases for serious applications (and I would prefer to use a more serious language, now that the approach of too many compilers has thrown *real* safety through the window, but it also won't happen overnight that legacy codebases be migrated to more serious languages), so I have to be extra careful. And I would prefer that other engineers also be, instead of being in denial of explicit warnings of not doing insane (or at least explicitly forbidden) things. 
So it is Fixed-term. Any permanent staff positions?
Not even slightly supported and hasn't been for almost a decade. XP is incredibly frustrating to support, don't even want to think about what 9x support would entail. Running anything out of support isn't even responsible to network anyway.
WTF, are you kidding me? I feel like I just got back from the last CppCon and now there's a call for submissions already?
I consider writing OS kernels to be "serious" software engineering and Linux uses a crap load of GCC specific details as well as a boatload of undefined behavior, and the Linux kernel developers simply don't care. If you use boost, you're using undefined behavior, it's full of it and they document it and make a conscious decision to use it because the consequences are nothing more than theoretical. If you use Qt, it's full of undefined behavior all over the place and they're not even shy about it, they do all kinds of things like `if(this == null) ...`. If you use Crypto++, which is the defacto C++ crypto library, it's also full of undefined behavior (makes use of all kinds of signed integer shifts that are technically undefined behavior but in practice works as you would expect it to). If you're writing code in C or C++, your code has undefined behavior in it, case closed. So if your attitude is you should never have any undefined behavior of any kind then you may as well stop using C or C++ because that's just not possible in any sense. Instead, the practical approach is to consider that not all undefined behavior is the same even though in theory the standard treats it all the same. For example, using a `void*` to store generic function pointers is not at the same threat level as accessing a dangling pointer even though they are both undefined behavior. On any sufficiently complex project, you will need to make trade-offs, and a major trade-off you often end up making is locking down your software to work on architectures where certain assumptions are true and safe... like a flat memory model, or two's complement, or maybe even not so safe assumptions, like your software will work only on 64-bit platforms. There is nothing wrong, in those cases, of writing your code to target those assumptions at the expense of not taking every single form of undefined behavior as a showstopper.
To me, mmap is more about convenience than about performance.
The reference semantics are the same - the ability to perform arithmetic, automatic value validation, and the lack of reinterpretation casting are secondary.
Writing many a data processing task to work with all the data mapped to VM is often much easier than getting it to work right on chunks... `mmap` is a well debugged part of a kernel. Every time I adapt an algorithm or data decoder to deal with chunks, I’m essentially making reimplementing a custom variant of `mmap` that comes with no hardware support and that I have to get right... 
&gt; Feedback always has merit. Thanks but I have been doxxed in the past. I have a family.
This is not the correct sub for these types of submissions. Please post in /r/learnprogramming or /r/cpp_questions.
That seems like a poor excuse for buggy code, IMO.
sidebar -&gt;
Also, try using http://godbolt.org and seeing how your code is turned into _assembly_ - the language more closely related to how the hardware actually works.
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/891u6k/where_are_data_types_stored/dwon05a/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
!removehelp
Holy shit, I've always just been using -s to learn a bit of assembly but that looks so much more convenient
You rock.
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/891ggo/starting_c_curriculum/dwon1ub/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
https://www.youtube.com/watch?v=WsUnnYEKPnI
Windows 2000 moved to long-term support in 2005. That's 13 years ago. 
I feel like Linus is made enraged by the mere fact that C++ *exists*. The guy has some rather unreasonable problems with the language.
Whats neat about C++ is we can explore paradigms that havent been tried before. I work in an engine where you have access to an in memory immutable db, but in our code, you can check out mutable versions (copy them). You do whatever youd like with that, then if nothing else has touched what you have touched, the mutable versions get converted back to immutable. Immer is another neat C++ specific way to build a set of immutable datastructures. I mean, I love using the immutable style programming with many cored (30+) code. Its easy to write safe code. On the flip side, I love C++ and how fast you can make things, which is why Im looking at how they mix together. 
Ill have to ponder on this. I like tuples for some other things. The lack of names makes them a little bit of a maintinence nightmare to use heavily. 
2000 left extended support July 13, 2010. XP left extended support in April 2014 but we're still supporting it in VC for some reason.
It's almost always timed to make Jon able to bug people about submitting in Aspen, before the deadline :P
nah, he even uses C++ for his user space software subsurface
This shit will be truly real if they manage to get better performance.
`mmap` is an unwise choice in many circumstances, but not a terrible *default* choice. You may thus find https://ned14.github.io/afio/classafio__v2__xxx_1_1mapped__file__handle.html#details of interest. I've written the paper proposing it for standardisation. It'll land in the Rapperswil mailing. We'll see how it goes.
Cool! I watched one of your talks in the mean time btw (https://www.youtube.com/watch?v=js-e8xAMd1s) and have a bit of a better idea. I must say that this is a really excellent talk, congratulations and thank you very much. The talk has a great motivation which you follow throughout, and it is also very accessible to non-experts. Really nice! Great to hear that whenever possible, Boost is being replaced by C++17 / more modern header-only stuff! :-)
I might want to switch from Eclipse + TDM-GCC to Qt Creator + MinGW. Eclipse is good but only supports C++14^( )^( )^( )^(without literal operators and templated type aliases)
In particular, there is a very long standing bug in the Win32 `CreateFile()` implementation which very, very unfortunately returns access denied for a "I cannot open this file as it is currently in the process of being (secure) deleted after all open handles in the system to it were closed". This confuses all POSIX code written to use lock files, for example. And quite a lot of other portable code breaks too. I have complained about this to the Filesystem team, and they cannot fix it because a certain large Microsoft product relies on the buggy behaviour. 
Probably Windows Point of Sale, supported until 2019 and a little birdy told me probably soon 2021 as somebody wealthy bought a support extension. It's essentially a XP subset.
&gt; Of course, banning constructors and destructors is basically throwing away the baby, bathwater, bathtub, plumbing, and sewer system of the language. I assumed that was a significant part of the joke.
Of course MSBuild and xcodebuild require explicit file lists and don't support globbing for a reason; Namely that it's a bad practice, especially for large projects with many contributors. Here's BillyONeal [commenting][1] on silent issues caused by globbing, and I've seen similar ones. It's certainly enough to put me off of globbing for any serious projects. [1]: https://www.reddit.com/r/cpp/comments/524844/recommend_a_build_system/d7itluo/
Also check https://godbolt.org/g/25RKgH
[sub microsecond message latency, and check out other performance stat here:](https://bitbucket.org/hmbd/hmbdc-rel/wiki/Home) 
Well, it doesn't work entirely like POSIX. If someone has a handle to the file open, you still get `ERROR_SHARING_VIOLATION` or similar. This mitigation applies only to the "you could open a handle to the file requesting DELETE access rights, you successfully set the delete on close bit, closed your handle, but the parent directory can't be removed yet because some other program that used FILE_SHARE_DELETE still has an open handle". Also note Win10+, RS1+, NTFS only. We care about things being implementable on (at least) Vista. And even on Win10, FAT, CIFS, and ReFS filesystems are things that exist which do not have such non-delete-on-close support. If AFIO depends on this I think we would be obligated to oppose AFIO, so please do keep that section :) I don't know about MSDN; I told the team that owns this lack of MSDN was a problem, but it's at least documented in headers in the Windows SDK. Look for FileDispositionInfoExClass.
I wonder how they're supporting something like that given that PCI compliance on XP is impossible.
You just provided feedback in this thread. &gt; You guys form a huge echo chamber We really don't. There is plenty of dissent on the committee. You just choose to see the world a certain way. 
*Never knew CPPCon existed* (But then again I'm not particularly a CPP-expert yet ;P) I'll keep an eye out on the presentations that get given for this year's one though. I'm hoping over the summer to get a chance to start properly learning it.
**Company**: [Cruise Automation](https://www.getcruise.com/) **Role**: C++ Software Engineer, **Type**: Full time **Description**: We're the driverless car company. We believe in improving people’s lives by making transportation safer, more accessible, and more convenient. Our team is small and we move quickly. We’re currently testing a fully driverless solution on city streets in San Francisco. We're looking for smart, ambitious people to help build the world’s largest fleet of driverless cars. We are looking to hire C++ engineers across the entire company so please check out our [open roles](getcruise.com/careers)! Check out [this video](https://www.driverless.id/news/video-analysis-new-gm-cruise-self-driving-video-shows-more-mastery-sf-roads-time-with-pip-proof-0176178/) of our car driving fully autonomously through SF! [How we built the first real self-driving car] (https://medium.com/kylevogt/how-we-built-the-first-real-self-driving-car-really-bd17b0dbda55) [Why testing self-driving cars in SF is challenging but necessary] (https://medium.com/kylevogt/why-testing-self-driving-cars-in-sf-is-challenging-but-necessary-1f3f7ccd08db) [How we’re solving the LIDAR problem](https://medium.com/kylevogt/how-were-solving-the-lidar-problem-8b4363ff30db) **Location**: San Francisco **Technologies**: C++ on ROS **Visa Sponsorship**: We can transfer Visas **Remote:** No remote work **Contact**: Anthony@getcruise.com
You'll see a little comment and note about the most unfortunate behaviour at https://github.com/ned14/afio/blob/develop/include/afio/v2.0/detail/impl/windows/import.hpp#L1279, plus my own reimplementation of `CreateFile` which works correctly. Note the explicit check at the end to undo the default NT kernel error code mapping. A senior member of the Microsoft Filesystem team confirmed this behaviour, and agreed it is highly unfortunate given how it breaks lock file portability. My memory may be faulty, but I believe he said that the source commit log shows it was changed and then restored due to a request from a major internal customer whose entire data reliability implementation relies on that semantic. You probably know much more than I about that. Either way, it's no difference for the proposed standardisation. AFIO provides lock files as a first order primitive, so code will ask for a lock file, and get a guaranteed working lock file. If standardised, up to library implementers like you to do whatever is needed to implement that on your specific platform matching the semantics we will no doubt spend a decade agreeing upon. Yay. 
Heh. Big and wealthy enough customers do what they like! I feel very bad for the team still stuck on XP support. Must be one of the most depressing and morale sapping dev roles in Microsoft.
&gt; This mitigation applies only to the "you could open a handle to the file requesting DELETE access rights, you successfully set the delete on close bit, closed your handle, but the parent directory can't be removed yet because some other program that used FILE_SHARE_DELETE still has an open handle". It *could* be sufficient. It depends on whether the entry disappears immediately or not. To explain, since NT, an entry marked for delete-on-close remains visible on the filesystem until some time after the last open handle to it in the system is closed. "Some time" is usually milliseconds, but it permitted by NT to be hours or days to permit the secure data scrub to complete as part of C2 compliance. And that, as you rightly mention, prevents deletion of the directory tree. The historical workaround is to rename all such files to the temp directory or if not possible, to the root of the tree being deleted with nice random names, that lets you clear out the tree immediately and the files will get deleted eventually. It does, as you mention, require all processes involved to explicitly say that they support this. It is not the default. So if NTFS + Win10 RS1 can now immediately disappear the file entry on the first process marking it for deletion, that would tick all the boxes POSIX needs to not break on Windows. I would suspect that the WSL folk might have driven this change, stuff like cmake is subtly unreliable on WSL due this semantic, apt-get is slightly broken and so on. AFIO's unit tests fail on WSL. I have logged many bugs :) &gt; And even on Win10, FAT, CIFS, and ReFS filesystems are things that exist which do not have such non-delete-on-close support. If AFIO depends on this I think we would be obligated to oppose AFIO, so please do keep that section :) Useful to know that this is a NTFS only semantic. BTW, I am surprised it was permitted. It opens the same security vulnerability as permitting symbolic links does i.e. TOCTOU attacks. It's why NT never implemented POSIX unlink semantics. Now, the other big elephant in the room is that NT won't permit the rename of a directory where ANY subdirectory contains ANY file which is open by any process in the system. That breaks an absolute ton of portable code, even things like WinRAR :(
&gt; Explain to me why intrusive pointers are not in the standard. Because they are somewhat specialized and not everyone uses them, so they haven't been a high priority. Someone is working on a paper on this. &gt; Everyone uses them. Untrue. I rarely use anything more than unique_ptr. We understand that they are popular in certain domains, though. Perhaps we should have built shared_ptr on top of an explicit intrusive pointer API from the start. But shared_ptr is the commonly used case, and intrusive pointers are a generalization of them that some users need.
The ability to link code compiled with different settings seems so far outside of standard c++. It’s more of a tool chain thing, no? I mean, is rust really going down the route of ‘to be compliant a rust tool chain must support linking objects/modules/whatever compiled with different language revisions’?
I used to work for a low-latency trading company and we had something similar. Unless I am missing something however, you only posted the code for your demo app, not the code for the message lib itself. If you can show us "hmbdc/app/Context.hpp" that would be much more useful. Also: * You have a typo on * hmbdc.cpp:135, decalre -&gt; declare * hmbdc.cpp:202 - inicaitor -&gt; indicator * You're safer to pre-increment on lines 187/190, and everywhere else. It's guaranteed to be equal to or faster than post increment. * MyContext* doesn't need to be a pointer. You don't check for nulls anywhere, and it doesn't make sense for it to be null, so make it a reference. You may get a small performance boost by saving the dereference (though compiler should be smart enough to optimise it already). 
I didn't know the async\_result(not a careful docs reader&gt;\_&lt;) policy, thanks for the information. I'll consider carefully to fine-tune my implementation.
here is pasrt of Context.hpp since the whole file (600 lines) is too big to post here: /** * @brief start the context and specify its Pool and direct Clients * @details the following starts the pool powered by 3 threads that are affinitied to * the lower 8 cores; client0 affinitied to 4th core and client1 affinitied to 5th core * the last true value inidicates there might be more direct mode clients to start * start(3, 0xfful, client0, 0x8ul, client1, 0x10ul, true); * * @tparam typename ...Args types * * @param poolThreadCount how many threads to power the Pool, 0 means no pool * @param poolThreadsCpuAffinityMask which cores, the pool threads to run on * @param args pairs of direct mode Client and its cpuAffinity; * optionally followed by a bool as the last arg (default false), false to indicate there is * no more direct mode Client to start. If a cpuAffinity is 0, the Client's affinity rotates * to one of the cores in the system */ template &lt;typename ...Args&gt; void start(uint16_t poolThreadCount, uint64_t poolThreadsCpuAffinityMask , Args&amp;&amp; ... args) { static_assert(cpa::has_pool, "pool is not support in the Context type"); if (!startToBeContinued_) { std::cerr &lt;&lt; "Exception: previously indicated start completed - cannot start more; - see doc for start and startMore;" &lt;&lt; std::endl; exit(1); //this exception message might not print out - use the above //HMBDC_THROW(std::runtime_error, "already started"); } if (pool_) { pool_-&gt;start(poolThreadCount, poolThreadsCpuAffinityMask, false); } usedHmbdcCapacity_ = poolThreadCount; currentThreadSerialNumber_ = usedHmbdcCapacity_; startToBeContinued_ = startClients(std::forward&lt;Args&gt;(args) ...); if (!startToBeContinued_) { this-&gt;markDeadFrom(this-&gt;buffer_, usedHmbdcCapacity_); this-&gt;send(Flush()); } } /** * @brief start the context (without its Pool) and direct Clients * @details the following starts client0 affinitied to 4th core and client1 affinitied to 5th core * AND there is no more direct mode clients to start * start(client0, 0x8ul, client1, 0x10ul); * * @tparam typename ...Args types * * @param args pairs of direct mode Client and its cpuAffinity; * optionally followed by a bool as the last arg (default false), false to indicate there is * no more direct mode Client to start. If a cpuAffinity is 0, the Client's affinity rotates * to one of the cores in the system */ template &lt;typename Client, typename ...Args&gt; typename enable_if&lt;!is_integral&lt;Client&gt;::value, void&gt;::type start(Client&amp; c, uint64_t cpuAffinity, Args&amp;&amp; ... args) { if (!startToBeContinued_) { std::cerr &lt;&lt; "Exception: previously indicated start completed - cannot startMore; - see doc for start and startMore;" &lt;&lt; std::endl; exit(2); //this exception message might not print out - use the above //HMBDC_THROW(std::runtime_error, "already started"); } startToBeContinued_ = startClients(c, cpuAffinity, std::forward&lt;Args&gt;(args) ...); if (!startToBeContinued_) { this-&gt;markDeadFrom(this-&gt;buffer_, usedHmbdcCapacity_); this-&gt;send(Flush()); } }
Dont know why my ealier reply didnt show up properly. Sorry if this is a duplcate. Fixed the typo - the demo code is trying to be demonstrative for the usage of the lib instead of being good code. :-) I was trying to post the Context.hpp here but found it exeeds the limit of a reply. The source code is located in the RPMs in the download section of the links above. Here is the start function for Context: template &lt;size_t MaxMessageSize = 0, typename... ContextProperties&gt; struct Context : private context_property_agregator&lt;ContextProperties...&gt; , ThreadCommBase&lt;MaxMessageSize , typename context_property_agregator&lt;ContextProperties...&gt;::Buffer &gt; { ... /** * @brief start the context and specify its Pool and direct Clients * @details the following starts the pool powered by 3 threads that are affinitied to * the lower 8 cores; client0 affinitied to 4th core and client1 affinitied to 5th core * the last true value inidicates there might be more direct mode clients to start * start(3, 0xfful, client0, 0x8ul, client1, 0x10ul, true); * * @tparam typename ...Args types * * @param poolThreadCount how many threads to power the Pool, 0 means no pool * @param poolThreadsCpuAffinityMask which cores, the pool threads to run on * @param args pairs of direct mode Client and its cpuAffinity; * optionally followed by a bool as the last arg (default false), false to indicate there is * no more direct mode Client to start. If a cpuAffinity is 0, the Client's affinity rotates * to one of the cores in the system */ template &lt;typename ...Args&gt; void start(uint16_t poolThreadCount, uint64_t poolThreadsCpuAffinityMask , Args&amp;&amp; ... args) { static_assert(cpa::has_pool, "pool is not support in the Context type"); if (!startToBeContinued_) { std::cerr &lt;&lt; "Exception: previously indicated start completed - cannot start more; - see doc for start and startMore;" &lt;&lt; std::endl; exit(1); //this exception message might not print out - use the above //HMBDC_THROW(std::runtime_error, "already started"); } if (pool_) { pool_-&gt;start(poolThreadCount, poolThreadsCpuAffinityMask, false); } usedHmbdcCapacity_ = poolThreadCount; currentThreadSerialNumber_ = usedHmbdcCapacity_; startToBeContinued_ = startClients(std::forward&lt;Args&gt;(args) ...); if (!startToBeContinued_) { this-&gt;markDeadFrom(this-&gt;buffer_, usedHmbdcCapacity_); this-&gt;send(Flush()); } } /** * @brief start the context (without its Pool) and direct Clients * @details the following starts client0 affinitied to 4th core and client1 affinitied to 5th core * AND there is no more direct mode clients to start * start(client0, 0x8ul, client1, 0x10ul); * * @tparam typename ...Args types * * @param args pairs of direct mode Client and its cpuAffinity; * optionally followed by a bool as the last arg (default false), false to indicate there is * no more direct mode Client to start. If a cpuAffinity is 0, the Client's affinity rotates * to one of the cores in the system */ template &lt;typename Client, typename ...Args&gt; typename enable_if&lt;!is_integral&lt;Client&gt;::value, void&gt;::type start(Client&amp; c, uint64_t cpuAffinity, Args&amp;&amp; ... args) { if (!startToBeContinued_) { std::cerr &lt;&lt; "Exception: previously indicated start completed - cannot startMore; - see doc for start and startMore;" &lt;&lt; std::endl; exit(2); //this exception message might not print out - use the above //HMBDC_THROW(std::runtime_error, "already started"); } startToBeContinued_ = startClients(c, cpuAffinity, std::forward&lt;Args&gt;(args) ...); if (!startToBeContinued_) { this-&gt;markDeadFrom(this-&gt;buffer_, usedHmbdcCapacity_); this-&gt;send(Flush()); } } ... }; 
Of course - and you're making the point for me. Even though it's kernel-side `mmap`, you still have to implement that chunking in the userland - even though it's often unnecessary. And of course the kernel's page cache is not contiguous in the virtual memory space of the kernel, so it's like page-at-a-time `mmap` all over the place. A minor detail of course. From the userland it's all nice and contiguous. Heck, even the kernel can remap it to look nice for the use of a driver, of course.
You don't want to use 10*exp(-13); that means 10*e^-13, which is 0.0000226. You want 1e-13.
There seems to be a problem with this post as I can only view 2 of the 6 comments posted. My own comment looks like it was removed a few minutes after posting. Here it is again Looks good but AFAIK the library itself appears to be closed source and I couldn't find a license file. It is good that the company can offer commercial support and are willing to target other platforms for a fee. Will you be publishing your app code and benchmark code so that comparisons against libs such as zeromq, nng, or serialisation plus transport such as protobuf3 or flatbuf over say https/2?
That is a great idea - I just posted the throughout and latency benchmark code: https://bitbucket.org/hmbd/hmbdc-rel/src/e71f9859a42751f10fd03d3f86e9de13c9712f14?at=default hmbdc-net and hmbdc-netmap are open source. hmbdc-base is mostly header, but is a closed source rpm. They r all freeware though and the only difference is that the licensed version provides more core count support (8-64) in the broadcast type Context. I would think there is limited use for the licensed version since the partition type Context doesn't post a limit on core count. 
Thank you. Nothing wrong with freeware of course, but probably best to clarify the commercial nature of the post. Still a valuable option and good to see the throughput benchmarks. Perhaps you could clarify. Are the sources of the components you note as open source available, and can they be used without the closed source base library?
I was experiencing the same earlier - but later the comments do show up. Weird Reddit problem.
minyc, The sources are all located in their rpms. I never thought the hmbdc-net hmbdc-netmap would be used without hmbdc-base which is closed source, now you mention it, I would tentatively say, maybe you can if you come up with your own Context type - but I probably need to test this theory. I am going to work on this probably make another release. :-) 
&gt; The order of allocation of non-static data members with different access control is unspecified. http://eel.is/c++draft/class.mem#18
Can't the hash still be trusted/treated as a signature if you got it from a trusted source? I.e. from an author website other https/from commit message/mail signed with gpg or something? I mean it'd be somewhat harder to confirm that the author didn't change, but other that? P.S. doesn't negate your point that it lacks proper crypto.
sorry no - I don't think I can do that since hmbdc-base acts like a lower layer lib and there is more than just one piece being used by hmbdc-net and hmbdc-netmap. 
buggy port != entire codebase is bugged
When I looked into it, the document that best helped me understand this was http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n3964.pdf which provides some nice background, rationale, and examples. The document was written for written for the standards committee but it is by Kohloff the asio author.
Ohhhh okay. I have it written down as 10e-12 Would that be the same as 1e-13? 
That's actually going the wrong direction; 10e-12 is 1e-11, not 1e-13. 
&gt; At this meeting, we considered further improvements to the modules design, including a renewed proposal focusing on a bridge to help existing header-based code move toward a modules-enabled world. By the end of the meeting, the main participants had hammered out a plan to, over the next few meetings: &gt; move a core set of modules functionality into C++20 that is “clean” and uncompromised by legacy concerns; and concurrently update the remaining modules TS with features specific to transitioning header-based code to modules, which might include support for macros. That sounds like a very reasonable thing to do. Frankly, I would not be sad at all, if the macro stuff never made it into modules. 
That is interesting. As far as I know I have been paying for the registration of this company for two years by now. Thanks for letting me know. Let me find out.
Ah, found it: - where is the LLC database you checked? https://wyobiz.wy.gov/business/FilingDetails.aspx?eFNum=119203133170094191202163017238143044237182219233
But do you ever do this without const muchless use assignment? The whole controversy around allowing optional references was regarding `operator=` semantics.
Yes, very clever approach. If the questionable legacy parts are pushed off to C++23 the problem might perhaps resolve itself before that once people can start using the good parts. Hope it happens.
!removehelp
Thanks 
I assume that you mean image-size, not file-size. There are several C libraries for image manipulation, like libjpeg and linpng. They will do the job. For C++, you could look at [Boost.GIL](https://www.boost.org/doc/libs/1_66_0/libs/gil/doc/index.html) or - if you want it easy, [QT](https://www.qt.io/).
FWIW, the other trip reports posted here have covered it. 
code generation makes you more clueless, reduces understanding and ads complexity. thats not something to brag about
I haven't fully read (and tried to understand) the latest modules paper from Google. Assuming the modules TS gets merged into the standard as is and won't be changed till c++20 gets published. Would that prevent any of the changes suggested by google (because they would break compatibility?). I really dislike the macro stuff, but IIRC, a few other points seemed sensible at first glance.
They'll be in the post meeting mailing.
Does immer "dumbly" copy the whole structure e.g. when you add the element? In Haskell and other languages with accent on immutable structures it is done through the means of structural sharing.
Actually `fstream` is very comparable to `mmap` for bulk transfers. Anything where the device is slightly slower than main memory gives the rest of the system opportunity to "fill the gaps" as it were. So sequential transfer tests always come out about the same. Latency is where the big difference is at, and especially random i/o latency. iostreams is truly awful at small buffer random i/o. Which is fair enough, it was designed for streaming transfer. Point is though we don't have any standard facilities for random i/o. These are what I propose at Rapperswil.
Your description doesn't line break and doesn't fit on my laptop screen, so I didn't read it. 
You're not wrong, but there are a few pertinent extra details. Firstly, DMA doesn't care how physical 4Kb pages are mapped. That's higher level than it works at (though Intel platforms do have fancy DMA controllers which can see into CPU caches and DMA straight out of them). Secondly, everything is always in 4Kb chunks in any case, as that's the hardware maximum that PCIe is capable of. You may have seen that DMA engines have 64 to 96 max scatter-gather slots on recent Intel platforms, this is because 64 byte cache lines * 64 = 4096. There is little point going much higher except maybe for network cards where scatter-gather buffers might regularly be below 64 bytes each. `read()` and `write()` do come with the big added benefit of atomicity visibility guarantees, so writes are never seen torn, reads acquires, writes release etc. If the platform + filing system implement them as per POSIX, of course. And `read()` and `write()` are the best by far choice for networked storage, and probably will always remain so.
Ah. Good point. Didn't consider that.
[removed]
There was this thing linked a week or so ago here which makes newer compilers available on RHEL I think.
Heavily beaten and hopefully buried under TS. Some admited it took too far before any stronger denial.
this is quite interesting, i would like to see a few more examples, right now i am abusing lambdas with asio, maybe this can help me to write a bit more sane code. thanks for sharing this.
I would like to see breaking comparisons between different enum types
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/896a0s/trying_to_product_a_sine_function/dwpzjje/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Honestly I've applied `optional&lt;T &amp;&gt;` thousands of times and didn't even notice this controversy until it came up on an internal discussion forum. Most of the time the "optionality" is quickly unwrapped, for me. Mutation is pretty much a dirty word in my code reviews, short of algorithmic code in a shallow scope.
A little bit off topic, but why took it almost 6 years (from c++11 to c++17) to get std::filesystem into the standard? Beside the fact that boost::filesystem is from 2002 original. 
It's really about C++'s lack of willingness to enforce a stable ABI.
That's not uncommon
Do you mean the [Red Hat Developer Toolset](https://developers.redhat.com/products/developertoolset/overview/)?
It correctly unrolls the loop and generates code that calls `putc` 100 times, instead of doing jumps and branches.
any LLVM/Clang developer here? :D 
We need **std::net** , I hope we don't wait 5 years.
Invite doesn't work.
The takeaway is a lot of businesses don’t run bleeding edge systems (not at all limited to linux) and that makes using newer features far more difficult. The scale of dependencies on third party libraries makes running multiple sets of compilers and libraries prohibitive.
Whats stopping you from using the stackful co routines that asio already supports?
Some of them read reddit, but most of them tend to hang in https://bugs.llvm.org/ wink wink 
Gor talks about them in the latest going native: https://channel9.msdn.com/Shows/C9-GoingNative/GoingNative-65-ISO-C--Jacksonville-Debriefing
The library wouldn't be very worthwhile if it did... ;-] https://sinusoid.es/immer/introduction.html#features
No, the answer is that intrusive pointers don't fit the backwards dogma of the committee, the language purists, the academics that hijacked c++ in order to push for their functional theory papers. You guys lost connection with the public, which is the main reason several stl clones were created by the major companies. Nobody uses the stl when performance is needed. Performance is an afterthought for the committee, just look at the email lists. I think you guys are killing the language. There is absolutely no feature in c++11 that makes any software faster or easier to maintain. Just sluggishness and increased complexity. I can rewrite any c++11 code in c++03 with increased performance gains.
Been a while since I did any heavy C++ coding, but I was thinking about the library issues he brings up the other day. Aren't the linkers smart enough to only pull in the pieces of the library that are used in the binary or does it end up binding the entire library into the binary? If it is the former then what is the main reason for not going static? Sizes shouldn't get too bad, you eliminate the dynamic loading requirements and don't run the risk of wrong libraries being loaded. If it is the later then what about an idea of the *library* being either pre-compiled .o files or just delivered as the source only with defined dependencies, then projects just pull in what they need?
I don't understand how to use them exactly.
&gt; No, the answer is that intrusive pointers don't fit the backwards dogma of the committee Bullshit. As I said, it's being worked on and has been well received by the committee. &gt; the language purists, the academics that hijacked c++ in order to push for their functional theory papers. Bullshit. &gt; Nobody uses the stl when performance is needed. Bullshit. &gt; Performance is an afterthought for the committee Bullshit. &gt; There is absolutely no feature in c++11 that makes any software faster or easier to maintain Bullshit. &gt; I can rewrite any c++11 code in c++03 with increased performance gains. Bullshit. Move semantics? Atomics? &gt; You guys lost connection with the public, You've lost touch with reality.
Indeed. I put it in the github repo title. What do you mean by managing tasks ? All I have to keep a record of all "coroutines" is a std::vector of boost::context::continuation 
I wanted to support g++ but the coroutines TS is not implemented there. That said it won't be too much work to re-implement this with c++ coroutines.
Clang has little documentation on what each level of optimization actually enables, but I believe that at `O3`, Clang enables loop unrolling but GCC does not. If you pass `-funroll-loops` to GCC, you'll see similar code. However, GCC does not completely unroll the loop, while Clang does. I'd expect the GCC version might perform better, but obviously the only way to know is to test it.
Yea I think that was it!
The C++ Language Slack workspace may be joined here: https://cpplang.now.sh/
"Concepts in-place syntax" is horrible, I hope they change it to something that is less disgusting. 
&gt; Bullshit. Is that your best argument? Actually that seems to be your ONLY argument. Well done representing NVidia. You know, that is what I see. A bunch of kids acting like they are in the Marxist convention. They do not care about economics, they only care about feelings and expressing themselves. When challenged, the goto mode is swearing, doxxing and name calling. Again, you guys are destroying a beautiful language with your utopic delusions. 
[Live at head](https://www.youtube.com/watch?v=tISy7EJQPzI).
And generates slower code..
 &gt;If it is the former then what is the main reason for not going static? Sizes shouldn't get too bad, you eliminate the dynamic loading requirements and don't run the risk of wrong libraries being loaded. Imagine that you have X programs that statically link against library Y. If there is a bug in Y you need to recompile and distribute and install X programs. If they are dynamically linked you can simply replace Y. &gt;If it is the later then what about an idea of the *library* being either pre-compiled .o files or just delivered as the source only with defined dependencies, then projects just pull in what they need? The problem is that c++ doesn't have an single dependency management/ build tool 
&gt; We are going to try to ship coroutines in C++20. That's really cool. We need those. Also I'm also really happy as my only concern about coroutines has been addressed! If there's no need for dynamic allocation for coroutines to work, that would be awesome, and may enable constexpr coroutines in the future.
I think it is highly unlikely that the committee will be able to add executors and networking to the c++20 standard (just getting executors into the standard will already be a challenge).
You like handwritten lexers, parsers, communication protocol state machines, UI state machines, and such? I use all of those and they never made me more clueless. They objectively improve the quality of my code, and they objectively improve my understanding of what the code does - or, as often is the case, of what it most definitely can't do. Correctness by design is a thing. A good thing. It makes it easy to reason about the designs and keep out huge classes of bugs that can be shown everywhere. I mean, I run almost hourly into iOS bugs that have to do with spaghetti UI state management code. You're arguing that writing code that won't ever have such bugs makes me more clueless and adds complexity?! Wut?
Except that does not enable advanced optimisations such as vectorization.
&gt; Tackling your only non-offensive sentence for the sake of Christ living in us. One can think of Christ as a shared_ptr
There is a difference between not using bleeding edge and using a compiler that is probably more than half a decade old. If you want (for whatever reason) to use a completely outdated platform, then there is some cost associated to it. That is the root cause of your problem - not the evolution of c++. The particular "problem" with c++ on Linux (on Windows you have other problems) is the tight integration of the build tools with the distribution.
gcc unrolls loop at O3. Sometimes also too much. It's not easy for a compiler to decide if a loop needs to be unrolled or not. Actually I hope modern compiler are (or are getting) somehow conservative in that regard, given that CPU are able to somehow do it themselves when appropriate now.
I sympathize with using / for connecting filesystem paths but here in case of dates it's less obvious since different countries use different conventions. For example in my country we use dd.mm.yyyy format. Another popular format used in SQL statements and etc. is the ISO format yyyy-mm-dd. Of course we can't use these in C++ directly but all these cases make overloading / here less obvious for me. But I could get used to it. That being said the first call looks way too convoluted. Why not to use simple function like auto ymdl = encode(today.year(), February, last); 
-Os for Clang generates similar code as GCC. Though you can open an issue on https://bugs.llvm.org/ I also found this: https://stackoverflow.com/questions/15548023/clang-optimization-levels which might be helpful. It states that -Os is same as -O2, even though in GCC it is for "Optimize for size".
More like RTTI. He is there silent all the time so to save you when you die.
You're right, Gor. Being able to wait for the completion of a length process can make it more useful. I'll consider expand the return types in the near future. And for the implementation for the operations with timeout, the seemingly heavy shared_ptr of JobCoordinator is necessary for correct codes. I just write a description about this in the repo. https://github.com/JCYang/coro_io/blob/master/ImplementionChallenge.txt 
What kinds of examples would you like to read? The usage is quite straight and simple already, I guess?
Do we need it that urgently, though? I mean it will certainly be nice to have when it gets in, but in the mean time Boost.Asio is here, works today, and will (hopefully) be easy to upgrade to `std::net` once it's available. I haven't followed the executors proposals in detail, but I'd rather time was spent getting the fundamentals right (and good interop with coroutines), even if it means we don't get the final version till '23.
Do we need it that urgently, though? I mean it will certainly be nice to have when it gets in, but in the mean time Boost.Asio is here, works today, and will (hopefully) be easy to upgrade to `std::net` once it's available. I haven't followed the executors proposals in detail, but I'd rather time was spent getting the fundamentals right (and good interop with coroutines), even if it means we don't get the final version till '23.
future.then in C++23? why!? i need this now
**Company:** [Carmeq](http://carmeq.com) **Type:** Full time **Description:** Carmeq is a subsidiary of the Volkswagen Group. With a clear focus on software for vehicle electronics, we are competent consultants, experienced project managers and inventive developers of new features and functions. In this post I am mostly looking for a new teammate in our [simulation team](https://recruitingapp-5052.de.umantis.com/Vacancies/645/Description/31), but feel free to have a look at our career page for other opportunities. We develop scalable solutions for virtual simulation and testing of advanced drivers assistant systems, using C++, the Automotive Data and Time-Triggered Framework (ADTF) and Virtual Test Drive (VTD). We hire both junior and senior developers, the only strong requirements are a solid grasp of C++ and good knowledge of the German language. Experience with either ADTF or VTD is a plus, as well as experience with Docker / Kubernetes / OpenShift. A background in computer vision, robotics, distributed systems or artificial intelligence would be perfect. **Location:** Berlin or Wolfsburg (you choose). Our workplace language is German, a knowledge of German is a job requirement. **Remote:** No. **Visa Sponsorship:** No **Technologies:** We develop software for both Windows and Linux and try to keep everything cross plattform. On Windows, we are currently transitioning to Visual Studio 2017, so you'll be able to use most of C++17. Our main external dependency is ADTF (Automotive Data and Time-Triggered Framework). We use Boost, Qt and Unity. We use both SVN and GIT for source control and Jenkins for Continuous Integration. **Contact:** Use our [online form](https://recruitingapp-5052.de.umantis.com/Vacancies/645/Application/New/31) to apply. I'm happy to answer questions here on reddit.
tldr;
Dependency on executors. std::async is a pretty face completely missing a body.
How is it horrible? The idea solves pretty much all ambiguous syntax that we had with the old proposal from Concepts. Naming a few: 1. Type or non-type parameter? `template &lt;Number N, Numeric value&gt;`. Both introduce constrained typenames. with Concepts in-place we could say `template &lt;Number{Type}, Numeric{} value&gt;`. 2. Which parameter is which? `template &lt;ComparableTo&lt;X&gt; T&gt;`. That's equivalent to `template &lt;typename T&gt; requires ComparableTo&lt;T, X&gt;`, which is reversed. with Concepts in-place, we could say `template &lt;ComparableTo&lt;T&gt;{X}&gt;`, and, if we wanted the first template parameter `T` to be the introduced constrained typename: `template &lt;ComparableTo{T}&lt;X&gt;&gt;`, which is equivalent to `template &lt;typename T&gt; requires ComparableTo&lt;T, X&gt;`. I really like the approach Herbs went with: it's consistent, it solves the previous ambiguity, both visually and functionally, and is simple enough to understand.
I couldn't upvote this enough. +1000 :-))) There's also a security risk of using such ancient compilers. And it's actually much more than half a decade (5 years wouldn't even be so bad, lol!): RHEL6 has gcc-4.4 as default compiler, which was released in 2009. Ok - it had its last patch-release in 2012... so 6 years, if you count in RHEL's favor. Btw, RHEL7 ships with gcc-4.8 from from 2013 - not too much better. In 2018.
Thanks, I just shortened the line breaks. It does that on an ipad. Desktop (with larger screen)should have had no problems.
It works :) https://godbolt.org/g/W6uMdB Thanks for making it available. It's good to be able to beta test this kind of thing.
Out of all of the C++ overloadable operators, exactly one has the [correct precedence](https://en.wikipedia.org/wiki/Operators_in_C_and_C%2B%2B#Operator_precedence), and has existing use as a [date component separator](https://en.wikipedia.org/wiki/Calendar_date). For example, if `operator-()` had been used as a component separator, there would have been issues like this: auto d = months{6} + 2018y-April-03; The C++ parser would have first parsed `months{6} + 2018y`, which is not what is intended. Another way to construct `ymdl` in this example is: auto ymdl = year_month_day_last{today.year(), month_day_last{ February }}; And it is certainly conceivable that another constructor could be added to `year_month_day_last` to bring the syntax down to: auto ymdl = year_month_day_last{today.year(), February}; This theoretical latter syntax breaks a pattern in the API that the field types just have constructors that take each field that is stored, in the order that it is mentioned in the type's name. `year_month_day_last` stores a `year` and a `month_day_last`. In developing this library, I continually tried to keep the number of names (both types and functions) to a minimum, avoiding introducing any name (such as `encode`) that wasn't absolutely necessary. The type `month_day_last` is absolutely necessary as it is the type of the expression `February/last`, and has use cases beyond just representing this expression. For example a holiday planner might need the "last day of the month of a not-yet-specified year" to record the rule for a holiday. But `encode` is nothing but a factory function for a `year_month_day_last` type, and I've already settled on `operator/()` to create factory functions for all of the types. It was a design choice that I considered more compact and readable. That being said, I was keenly aware that a vocal minority of my customers would not like the `/` syntax. Therefore another design decision was to not hide the constructor syntax, and to make it as simple and predictable as possible. Here is the complete specification for [`year_month_day_last`](https://howardhinnant.github.io/date/d0355r7.html#time.calendar.year_month_day_last).
Oh, imagine how many years we should wait till modules and ranges :)
It has grown on me. It's not ideal but I now think it's ok. Certainly much better than what we currently have with the template typename boilerplate
In the end, it doesn't really matter. Bugs are bugs.
reported on llvm-dev
&gt; Atomics - look that the C++ implementations all yield to the C library when it comes to the heavy duty stuff. The memory model was developed in C++, and then adopted by C, not the other way around.
The language has had a remarkably stable ABI. 17 is introducing one change, making noexcept part of the signature, but that's been it for a long while. The std library changed std::string such that it isn't copy-on-write, and most now use a small string optimization. However, other libraries are more likely to make changes. The header may make use of new features of the language, and will therefore be incompatible with other, old, compilations. C++ binds early and eagerly, making it highly optimizable, at the cost of ODR problems. Undefined behavior, no diagnostic required. 
&gt; What does a forward declaration have to do with a scoped_ptr? Am I reading it wrong? I guess they wanted to use the PIMPL idiom + using smart pointers; thus a scoped_ptr (should be close to a unique_ptr). Some extra reasons I think of: - not having to `delete`the impl pointer. - const-correctness - combining PIMPL and value semantics if need be if a clone-like method exist.
I'm comfortable with people using a decade old distribution not being comfortable though. Honestly, I wish we were more comfortable with breaking ABI and even API compatibility. It's better in the long run even if it causes short term discomfort. As to your first point, ?. I know the *class* she is talking about, I'm saying she mistakenly wrote that it grants the ability to forward declare the class.
Willingly?
Do I see right? It requires dynamic allocations for objects of size greater than intptr_t?
&gt; I'm comfortable with people using a decade old distribution not being comfortable though. If it's only decade-old stuff that is breaking, yeah, that would be ok. Not great, just ok, becasue C++ used on long-lived programs. But program written with few-year old compilers have also issues. In the end, the safest is to compile everything with the same cpompiler, but it's not always possible (properitary lib; yeah, FOSS is great, but sometimes you have to work with non-FOSS stuff) or hard (build system fragmentation). _______ I haven't used `scoped_ptr`, but I thought you could pre-declare the class, like so: class Engine; class Car { scoped_ptr&lt;Engine&gt; engine_; // yadda yadda... }; instead of : #include "Engine.h" // can't pre-declare class Car { Engine engine_; // yadda yadda... }; I believe there is some rule about `std::unique_ptr`and whether the class has a special deleter or not. Can't look it up right now.
&gt;but in the mean time Boost.Asio is here, works today Which raises the question: Why should the committee and vendors waste their (valuable) time on creating their own "perfect" version of Asio? It's a huge effort which will take years to complete. By the time the committee is done with it and it wends its way through the compiler/library developers, It will probably be found that the current library version will have evolved to something better. A good example is the standard C++ io system. Very complex, elaborate (locales, facets, etc.) and widely ignored by many/most programmers. Ideally, this should have evolved by now. But that's hard to do as the current system is "standardized". Are we really better off today for having designed (by committee) and (re) implemented this gargantuan component 20 years ago which we're bogged down with today? I would recommend that the committee eschew efforts on the elaborate/complex libraries like ASIO, Ranges, serialization, GUI interface and concentrate efforts on "enabling" features. e.g. What would be the minimum support required to static reflection? context switching to support co-routines, etc. I'm 70 years old. I can't wait until 2028. Do less - get more done.
Maybe it would just be simpler to hold CppCon in Russia?
Almost true. It requires dynamic allocations for objects of size greater than sizeof(void *)
Having to call the destructor is super annoying. Glad I'm a C++ developer!
I agree with you. Developers C live harder :)
&gt; [[likely]] and [[unlikely]] A major reason to use this feature is not actually to optimize (though it can help if you don’t have PGO), but to control which path gets optimized for other reasons. For example, for some code it is essential to make the uncommon path faster so that it is faster when you do hit it — and in such cases you would actually use this attribute in the inverted sense, so please also write a comment nearby to document that intent otherwise some hapless reader (more than likely your future self) will be temporarily confused. I can't believe this feature was designed to be used with an intent exactly opposite of its name. And that the committee recommends adding a comment to fix its confusing usage, so that now you have to maintain two states - of your code and of your comments. The obvious solution would be to name it [[optimize_path]] or similar. Please, it's not too late to change it. 
I heard that, Robert. I don't want to have to compete with C++ Russia, which, by the way, has a great first-time keynote speaker this year. http://cppconf.ru/?lang=en
I think you may wanna use generic macros of C11. Converting int to void* using a macro adds unacceptable amount of visual noise, imho.
we need beyond pointer, like tagged memory etc: http://www.lowrisc.org/docs/tagged-memory-v0.1/
I slightly disagree that this is applicable here. Here is an example of use: http://en.cppreference.com/w/c/language/generic This means that there must be a definition for any possible type of function. In fact, the generalized code written in C is rather complicated. What options did I see: either write a very large macro that would use a type substitution, or implement everything via a pointer void *. I chose the second option. The first is bad, because the code is so harder to maintain and postpone and it's easier to make mistakes.
&gt; Just use Engine* engine and forward declare it. - No automatic releases of resources (even if it's trivial in the usual PIMPL idiom). - Wacky const-correcteness, that has to be solved by being careful/macros. &gt; I've always been a fan of forcing people to update. If they would rather stop updating the compiler and let their codebase rot so be it. When those people are your clients, and when they have payed for 2, 5 or 10 years of maintenance, updates, especially when they break stuff, can become a big no-no. &gt; Periodic maintenance on a 3 year tick is really not too much to ask in my opinion. Look, this may be true for medium systems or stuff you can easily test and such. It's not true at all for larger projects or megaprojects, or complex ones (ones with billion LOC, with 3rd party dependencies that can go go in the dozens or hundredths.) &gt; And C++ will always support the same breadth of platforms Even if true: it doesn't matter; if it break a critical library that can't be ported (because team is too busy, because it's third-party and you don't have the source, because the source is too complex, because upper-management doesn't want to pay for the update, ...) and can't be swapped (because too complex, etc.), then you're screwed. 
Using it since last week and so far no issues, but shiny GCC 7.2
It's not the same people working on networking and modules. Dropping networking will not give us reflection any quicker. Iostreams despite its warts is still widely used so it's absolutely not a waste to include. The small standard library of C++ is a big drawback compared to other languages.
It seems it was designed to standardize widespread existing usage. The wording http://eel.is/c++draft/dcl.attr.likelihood doesn't talk about adding comments.
OpenBSD 6.3, which was just released, comes with gcc *4.2*. (And clang 5, but I haven't checked yet to see if that uses libc++, or if it shares a decade old libstdc++ with gcc)
Good point, `[[fast_path]]` and `[[slow_path]]` might be better. (Also lets it be used as a function attribute).
Yeah, I know. That's kinda what I meant. AFAIU, compared to regular hash on a trusted source, signature only gives you the confidence that the author didn't change (well, at least if his PC wasn't compromised) (though that makes it possible to use it safely even on non-trusted sources, but the initial "trust transaction" is in no way safer).
Gosh you really aren't reading the original post. Nobody is talking about the advantages of an RAII pointer. Just that it isn't required to forward declare something (which is what she wrote originally). Full stop. If you're still lost after this, I don't really know what to tell you haha. As for your second point nobody is forcing you to update your compiler! Just keep shipping C++03 code in 2100 for all I care. I've worked in those megacodebases I'm aware. But the reason everything ossifies so much is precisely because the culture has bred mentalities like your own.
While `likely` is the common name of the attribute, when it is used properly I often see it aliased along the lines of `optimize_for` and `dont_optimize_for`. We could've fixed something during the standardization but noooo, that would be too reasonable.
&gt; It has grown on me. You really are not bothered by the fact that RandomAccessIterator{It} means that It is RandomAccessIterator(reverse from when you would want to form a sentence reading left to right by pretenting {} means is ).
No one can afford to wait.
One person does not work on the entire code. In additional, equal time is not spent on the entire codebase. Do you think the KDE team, whose flagship product is a desktop environment for Linux, is going to spend a lot of time on a Windows port? That'd be like MS spending a lot of time on a linux port: It doesn't happen (if they even make one at all!)
Try pretending {} means 'named', that is RandomAccessIterator{It} means RandomAccessIterator named It. 
As well as networking =(
Half the language is already in Urdu order, and there was a recent proposal for left to right evaluation order, so we need Concepts to be right-to-left, to keep the ratio 50/50. We don't want to be directionist.
&gt; But if it’s still widely debated, maybe it’s because no satisfactory solution has been found so far. no, it's because everyone without any clue can comment on the internets and have their comments taken as mantra by other, gullible people who then repeat it like a choir, creating the impression that there was a consensus in the first place. exhibit A: this very comment.
Of course a smart pointer isn't required to have forward declaration. My point is author wrote a smart pointer to avoid a forward declaration, because the considered choice was "smart pointer + forward declaration" vs "simple attribute (non-pointer + full include", and not "smart pointer" vs "raw pointer" - as author wants RAII. Ofc it's an educated guess, deduced from the context. This is why I reacted to: &gt; What does a forward declaration have to do with a scoped_ptr? Am I reading it wrong? Because yeah, you were reading wrong. &gt; As for your second point nobody is forcing you to update your compiler! Sort of OP's point basically. Having to make the choice between going stale and breaking everything is a terrible choice to make. &gt; But the reason everything ossifies so much is precisely because the culture has bred mentalities like your own. Yeah, personal attacks, nice. FYI, I prefer to update as much as possible. I'm not the one who negotiated those contracts, who decided not to wrote test and such. I'm the one who arrive with a heavy codebase, and learn and try to do things are are *possible*, while pushing to improve stuff. "Go fast and break things" is just not possible in some industries, some of which are huge C++ users. get that in your head and some bother ring other people.
So, after some trial-and-error, I managed to create a Conan package :) I've also updated the README.MD by reworking the 'How to use' section (previously 'Build instructions'), which now contains a Conan section: https://github.com/erikvalkering/smartref#how-to-use 