I think this is a very important question.
Basic errors can be part of the normal flow execution, sometimes it is expected to occur. Whereas exceptions might happen due to some irrecoverable problem and the state of the application could be potentially undefined. Sure, the two domains can overlap in their use, but they should not be regarded as the same thing.
&gt; What's a more proper name for Class A? "Let's put this constructively. Name your classes anything you want. Then delete words that don't add any meaning. Examples of words that are unlikely to add meaning are Object, Manager, Handler, Data, Entity, Component, Element, Item, and Thing. If deleting a nothing word would result in a clash (Drawing and DrawingObject?), find a [SystemOfNames](http://c2.com/cgi/wiki?SystemOfNames) that helps you resolve the conflict (Drawing and Figure)." -- [Don't Name Classes Object, Manager, Handler, Or Data](http://c2.com/cgi/wiki?DontNameClassesObjectManagerHandlerOrData) See also: * http://blog.codinghorror.com/i-shall-call-it-somethingmanager/ * http://www.bright-green.com/blog/2003_02_25/naming_java_classes_without_a.html * http://stackoverflow.com/questions/1866794/naming-classes-how-to-avoid-calling-everything-a-whatevermanager
Perhaps it's the wrong terminology, but I think of __declspec(novtable) as an annotation on the class that gives the compiler more information that it can't otherwise obtain. Is this not correct?
Nice work, but I was expecting a C++11 implementation. :)
&gt; (here's where Rust went a horrible way) Elaborate?
Fatso doesn't introduce a separate repository. Fatso doesn't require the collaboration of library writers. Fatso is open source. Fatso doesn't intend to include Windows developers at this stage. And finally, Fatso has a better name. ;)
Thanks! Ugh, just so sanctimonious. How about 'Thanks! It fits a need in my code. Ide prefer X or Y or Z, but you know what, you just saved me hundreds or thousands of hours of work.' 
But please do not use `using namespace std` and `std::endl`, but qualify the calls (or use `using` explicitely) an use `\n` instead of `std::endl`. The latter flushes the stream, which is unnecessary in most cases. Why do we see this in all introductionary code examples?
Oh, I don't recognize the existence of that extension. :-&gt;
Most likely even more often, it is a C code base and I think I have seen mgr multiple times in the linked code, it is a wonder that manager isn't mangled every time its used ( someone should gift poor Linus some RAM :-). However the first few pages at least don't make a good argument for naming something manager, I think you could remove it and wouldn't loose a bit of information about what the structs/code do (leaving you with more chars for relevant names).
&gt; Concerning 7, ... The problem with a Singleton, is that soon enough you find yourself wanting two values... A singleton embodies two things you don't want: - unique: but... I wanted to compute two independent things! - global: but... I wanted to compute two independent things in parallel! There is rarely, if ever, a good reason for a singleton (or global variable). &gt; Concerning 11, ... I was admit I was surprised knowing the author's expertise that he would take such a position, I wonder how familiar he is with `Option`/`Either` from the functional world.
Admittedly, a single one is already a code smell. The only place it would be appropriate is when writing a "smart" pointer of some kind, and let's be honest the standard library already comes well equipped.
I suspect the author is one [R. Martinho Fernandes](http://stackoverflow.com/users/46642/r-martinho-fernandes), who is admittedly pretty knowledgeable about C++ in general. For example of his work, you might want to look at [Ogonek](http://flamingdangerzone.com/unicode/cxx11/2013/09/10/towards-nice-apis.html), a C++11 library to deal with Unicode strings. This is a difficult domain (Unicode has many pitfalls), and therefore it is pretty hard to come up with a simple API that is not immediately rejected by the "people in the know" because too restrictive, so it should give good insights into his way of designing APIs.
But it helps you to avoid exceptions and return error codes instead! ;)
I only follow Rust lightly and didn't know this. There is a little more information on the reasoning in [the guide](http://doc.rust-lang.org/complement-lang-faq.html#why-is-failure-unwinding-non-recoverable-within-a-task?-why-not-try-to-%22catch-exceptions%22?). I don't know enough to say anything for or against the design but I am firmly in the pro-exceptions camp. &gt; please someone tell me that the name is just a bad coincidence and they have nothing in common with C macros. Well, they generate code, so they do. They are [a completely different beast from the C preprocessor](http://doc.rust-lang.org/guide-macros.html), however. I am still mostly excited about Rust but there are definitely some issues with the language and the design process that make me a little sceptical.
when are we gonna get move elision in the standard? :) also shouldnt compilers already eliminate moves for "no sideefect" move ctors/dtors using that good old asif rule. 
const cast is not used in cases like that... most of the time compiler cant see the const you get so it cant inline it. :) If you ever end up working in a big company have fun looking through source... you will find const_cast-s that work... Also to be noted I dont ever remember me writing const_cast in production code, because I am a const nazi. :) I am merely a witness of the times. :P
I still like `std::bind`. Sometimes I use lambdas, but sometimes `bind` is nicer. Generic lambda's finally do offer similar capability, but `bind(foo(), _1)` is still nicer looking and clearer than [f = foo()] (auto &amp;&amp;arg) mutable { return f(forward&lt;decltype(arg)&gt;(arg)); }; [(ex)](http://coliru.stacked-crooked.com), if I even got that lambda right. Plus proposal [n4171](https://isocpp.org/blog/2014/10/n4171) adds new capabilities to `bind` which generic lambda's won't have, so that not only will `bind()` do forwarding magic for me, it will do variadic function magic too. `bind` should not be deprecated or removed. (This proposal doesn't include removing `bind`, but indicates that the author will present such a proposal in the future.)
Yeah it smacks of poor social skills or ability to express ones feelings. 
VC++ doesn't do this. There's no way to choose a C++98 mode, or C++11, or C++14 mode as there is with gcc and clang. I wouldn't be surprised if many embedded compilers were like this; they've worked on providing one implementation and that's what they've tested and require users to target.
&gt; There is rarely, if ever, a good reason for a singleton (or global variable). The situation that I always have to think of is this one: std::mt19937&amp; get_urng() { static thread_local std::mt19937 urng{std::random_device{}()}; return urng; } template&lt;typename Integer&gt; Integer rand_integer(Integer low, Integer high) { std::uniform_int_distribution&lt;Integer&gt; dist{low, high}; return dist(get_urng()); } template&lt;typename Real&gt; Real rand_real(Real low, Real high) { std::uniform_real_distribution&lt;Real&gt; dist{low, high}; return dist(get_urng()); } This code is completely better then the alternatives and completely safe. I admit that this is a very rare case, but it is relevant enough to disagree with a “never”-rule. Almost all of the remaining time though, I agree that globals are bad.
I would answer this like that: “Then don't do stuff with my library that I clearly documented are undefined behavior. Be thankful that I called terminate instead of allowing really bad stuff to happen.”
AFAIK the idea is that you use lots of tasks anyways, so that this won't be much of a problem: I for one haven't written a catch-block outside `main` in ages. (I admit that my programs are pretty small and failure an acceptable end-result, BUT: I throw relatively often and care a lot for exception-safety.) That doesn't mean that you shouldn't catch exceptions, but that this should usually happen in very few places, so formalizing this with tasks shouldn't be that bad.
&gt; You have to ask yourself, am I in an exception-safe context in my code, or not. The answer to this question should *always* be “yes”.
Thanks for reporting on the issue tracker, will look in to it.
Thank you so much! Those links are very helpful
The Standard already specifies copy/move elision, but not as aggressively as it could. If there are no observable side effects, then the As If Rule always applies.
bind() is seductive but dangerous. The problems with bind() are: * A bind() expression involves reading and writing a language that is Not C++. In contrast, a lambda's body is ordinary C++. Yes, there's extra stuff introducing the lambda that has to be learned, but lambdas are popular so programmers are going to learn them. * bind() conceals much more behavior from the programmer. Did you know that bind() passes bound arguments as lvalues? I learned that the hard way, and I'm an STL maintainer. I've seen other experts get this wrong (and it matters, e.g. when trying to pass unique_ptr). In contrast, a lambda makes it perfectly clear how it's passing its bound arguments and ordinary arguments. * bind() makes it harder to see and control when things are evaluated. For example, bind(functor, meow()) immediately calls meow() at the time of binding, not the later time of invocation. Many people don't realize this (I've seen experts make this mistake). If you want to delay meow()'s call to the time of invocation, very few people know how to do that, and it's absolutely horrible (nested bind()). In contrast, lambdas make it easy to control: ordinary calls in the body happen at the time of invocation, and we now have init-captures to do things at the time of construction. * When bind() goes wrong due to misuse, it *explodes*. I eat angle brackets and drink compiler errors for a living, yet bind() errors horrify even me. They're going to complain about a hugely complicated mess of STL machinery - much more so than something simple like trying to sort constant or bidi iterators (which terrifies most programmers, but shouldn't). In contrast, because a lambda's body is ordinary C++, errors are ordinary. * bind() is less efficient. bind() stores the bound functor as a data member, and that is very difficult for optimizers to see through. Function pointers will typically not be inlined, unlike when passing them as arguments to algorithms (which all compilers are now capable of inlining). Bound arguments are also stored as data members which are less likely to be optimized away. In contrast, lambdas often have the opportunity to hardcode their "bound" functor and arguments, making them ordinary candidates for inlining and optimization. bind() still has some tricks up its sleeve, like what it does with PMFs. But it's just not worth the cost. I almost always encourage the use of Library machinery over Core, but with bind() it's the reverse. It was a good idea in the TR1 era, but lambdas really are superior, even if they can be more verbose in certain situations.
All shall love C++14 and despair.
In one of going natives during alexandrescu talk alexandrescu learns about somebody proposing move elision to the standard and he is delighted... are you telling me we got that in c++14 or alexandrescu and guy from the audience were talking about something else? 
There are certain places where you simply cannot be exception safe, in areas of code where you expect input will be error-prone and the code is executing many times using exceptions will totally destroy performance. For example, trying to determine the surface color for each pixel on screen during a raytrace, if there is no object behind that pixel then what do we do? Throwing thousands of exceptions a frame is surely not the answer, and choosing a blank space color deep in the code (or using some mysterious mechanism to set it) isn't great either. It's much better to return a special value indicating there is no object there, and thus, no color.
C++11's copy/move elision says that any chain of temporary construction can be collapsed, but it doesn't allow temporaries to be totally eliminated in certain situations.
Wasn't IBM going to object at the next meeting?
Don't know of anything that explains it better than the Standard.
I work for a defense contractor and the answer to that is ALWAYS no. We can't have exceptions being thrown when a pilot is in the air. Your library, should it be appropriate for my sphere, needs to tell me there is a problem and then I will decide how to handle it from there.
&gt; A bind() expression involves reading and writing a language that is Not C++. I don't see a problem with this. Anyway plenty of programers don't know C++ either, but we're still able to put it to good use. &gt; bind() conceals much more behavior from the programmer. Did you know that bind() passes bound arguments as lvalues? I did. It means I can say `bind(a(), b(), c(), d())` instead of `[a = a(), b = b(), c = c(), d = d()] () mutable { return a(b,c,d); }`. To someone that knows `bind()` the former is clearer and harder to mess up when this is the desired functionality. We should prefer code that is clearer and harder to mess up, and sometimes that's not lambdas. &gt; I learned that the hard way, and I'm an STL maintainer. I've seen other experts get this wrong (and it matters, e.g. when trying to pass unique_ptr). Yeah, that was the async/unique_ptr bug, right? I remember running into that. &gt; In contrast, a lambda makes it perfectly clear how it's passing its bound arguments and ordinary arguments. Only to people who know C++ well enough. I don't think that's too much to ask. &gt; bind() makes it harder to see and control when things are evaluated. For example, bind(functor, meow()) immediately calls meow() at the time of binding, not the later time of invocation. Many people don't realize this (I've seen experts make this mistake). This is as obvious as the behavior of lambda bodies or capture lists. Experts have made mistakes with those too. (Actually I think `bind()`s behavior here is more obvious than lambdas. Knowing the behavior of lambdas requires learning the unique features of lambdas. Learning this behavior requires learning how _regular function calls_ work.) &gt; If you want to delay meow()'s call to the time of invocation, very few people know how to do that, and it's absolutely horrible (nested bind()). Nested `bind()`s are awesome and not horrible at all, although needing them is a hint that the 'clearer and harder to mess up' balance is shifting toward lambdas, where the nested `bind()` behavior is default. Implementing `bind()`s default behavior in lambdas may require using the lambda capture list more, and that's one hint that the 'clearer and harder to mess up' balance may be weighing more towards using `bind()`. &gt; In contrast, lambdas make it easy to control: ordinary calls in the body happen at the time of invocation, and we now have init-captures to do things at the time of construction. It's easy to control in `bind()` too, it's just that the default behavior for `bind()` vs. a lambda is different. &gt; When bind() goes wrong due to misuse, it explodes. Yes, this is true. I agree lambdas are better on this one. Of course, if we build `bind()` into the language then we could get nicer error messages there too... But I don't think it's that much of an issue. Leaving `bind()` as a library feature is fine. &gt; bind() is less efficient. bind() stores the bound functor as a data member, and that is very difficult for optimizers to see through. Function pointers will typically not be inlined, unlike when passing them as arguments to algorithms (which all compilers are now capable of inlining). Bound arguments are also stored as data members which are less likely to be optimized away. In contrast, lambdas often have the opportunity to hardcode their "bound" functor and arguments, making them ordinary candidates for inlining and optimization. I've had more issues with `std::function` than `std::bind`. Whenever I've looked, I've found that function _objects_ get inlined just fine with `bind()`. Free functions too, usually, unless I really force it to handle a pointer to an unknown function. Perhaps you have data for other compilers which supports you, but I'm comfortable sticking with `bind()` in cases where it makes the code more readable and less error prone and accepting some potential performance penalty due to a failure to inline, at least until I measure performance and determine that it's actually causing a problem. &gt; bind() still has some tricks up its sleeve, like what it does with PMFs. For anyone else unfamiliar with `bind()` who's curious what STL is referring to, 'PMFs' stands for 'pointers to member functions', and the 'trick' is that `bind()` automatically treats pointers to member functions and pointers to member data as though they're wrapped in `mem_fn`. I.e. it treats them as functors which take as their first argument an object of the appropriate type and calls the member function on that object or returns a reference to the object's data member. struct S { void f() { std::cout &lt;&lt; g &lt;&lt; "\n'; } int g; }; auto a = bind(&amp;S::f, S{10}); auto b = bind(&amp;S::g, S{20}); a(); // calls f() on the bind object's bound object. b(); // returns a reference to the g member of the bind object's bound object. &gt; But it's just not worth the cost. I don't agree. If a programmer doesn't want to use it then they don't have to and they pay no cost (unless they happen to be a library maintainer...). It's reasonable for a programmer to make their own decision for their own situation. Anyway, the appendix of [n4171](https://isocpp.org/files/papers/n4171.html) perfectly summarizes my opinion on the matter: `bind()` is useful because there are circumstances in which is produces more readable and less error prone code. Those are the times to use `bind()` and it probably shouldn't be used otherwise. n4171 also, coincidentally, provides some handy new functionality which lambdas do not provide and which otherwise requires a user to write unreadable and error prone variadic template code.
This doesn't mean that your code isn't exception safe; in fact I would rather trust my live to code that uses exceptions and is exception-safe, than code that is neither. Exceptions-safety should be achieved by RAII, which you are certainly using.
Thumbs up to this comment! I'm a C++ developer, but constantly run into small tasks that definitely don't justify a full C++ program. Python is the best thing for writing little scripts to do tasks you don't want to do by hand. (Though it is definitely suitable for much bigger tasks, too!) I have a huge library of these little scripts now, it's pretty nice.
Actually, this very well may be faster than expanding the template version at compile time. Obviously not faster at compile than the runtime version, though.
For an example, see mmap documentation and MAP_FAILED: http://man7.org/linux/man-pages/man2/mmap.2.html mmap is supposed to return a pointer, except that failure is encoded as pointer too (MAP_FAILED is (void*)-1). Concretely here, a pointer type is constructed with a bogus value.
&gt; 10.If your library does not play nice with the standard library, I will hate you. It's next to impossible to deliver a binary-only library with headers which uses standard containers in its interfaces. All of containers are implemented in headers and if there's a slight mismatch between the definitions in your library and the definitions in the user's headers, hell will break loose. &gt; 11. If functions in your library return error codes instead of throwing exceptions, I will hate you. Corrolary: if your library doesn't have a single base exception type, I will hate you.
Well, if it is `thread_local`, there is not a single instance, so it is no longer a Singleton (by definition), although it is still "global" in some sense. The C++ Standard used to have `std::random_shuffle` for example, and it has been deprecated and replaced by `std::shuffle` where one explicitly provides the random number engine; it allows concurrent operations *within a thread* (such as what is done with continuations and event-driven programming) to be independent for example. Also, while `thread_local` variables can be useful to improve performance (jemalloc as thread-local arenas for example), beware that relying on the state of `thread_local` variables can make it near impossible to integrate with languages that have more logical threads than OS-threads (sometimes called green-threads, greenlets, fibers, ...). There are other challenges, but if the variable is sufficiently protected (unnamed, for example), then it actually make this integration nigh-impossible without high-level brittle hacking. *On a side note although for a stateless distribution you can indeed create the distribution and throw it away each time you generate a number, in general the distribution should be kept around.*
Yes, the article is 11 years old. Nevertheless, I found it interesting and still relevant. Do you happen to know any other technique that enables a programmer to have enum-like behavior and also lets them extend the enum domain with custom entries?
&gt; #1 If your library forces me to use new all over, I will hate you. What alterantive does the author suggest for those libraries that handle sets of polymorphic objects, provide the definition for the base class, expect the end-user define custom subclasses, and expect the end-user to pass objects of these sub-classes to library components through a public interface ? Sounds like an obvious case where forcing users to use new all over is the best solution available.
Are there any important changes in C++11/14 that make the article wrong or just bad advice?
Why does the author even use weird integer IDs to denote a sound? Most traditionally in games I see a lot of std::map/std::unordered_map and they just access the resource via the filename, which is at least meaningful (note that std::unordered_map element access is typically O(1)). However, if you're storing all the sounds in the game within an array, and you want to ensure that you aren't using magic numbers, then enums are perfect. For example: // if you're storing the sounds you load // into an array std::vector&lt;Sound&gt; sounds; enum class SoundIdentifier { EXPLOSION, ATTACK, VICTORY, COUNT // this is kind of pointless as this should == sounds.size() }; enum class SpriteIdentifier { PLAYER, EXPLOSION, COUNT }; void play(SoundIdentifier si) { const auto index = static_cast&lt;size_t&gt;(si); sounds[index].play(); } // ... play(SoundIdentifier::EXPLOSION); play(SpriteIdentifier::EXPLOSION); // ERROR Now how do I iterate over the enum? Well that's quite easy... for(size_t i = static_cast&lt;size_t&gt;(SoundIdentifier::EXPLOSION); i &lt; static_cast&lt;size_t&gt;(SoundIdentifier::COUNT); ++i) { auto&amp; sound = sounds[i]; // ... } But really you know there wont be any duplicate values, so what the heck is the point in testing that if you aren't assigning values to the enum? To loop through every sound just loop through them... that is: for(auto&amp; sound : sounds) { // ... } I just don't really see the point in this article.
&gt; Why does the author even use weird integer IDs to denote a sound? The author addresses that concern right in the second paragraph. &gt; Most traditionally in games I see a lot of std::map/std::unordered_map and they just access the resource via the filename, which is at least meaningful (note that std::unordered_map element access is typically O(1)). Calculating a hash value of a string is a bit more computationally expensive than simply providing the hash value. If you're trying to squeeze every drop of performance out of a loop, this is the sort of stuff that you'd avoid doing. &gt; However, if you're storing all the sounds in the game within an array, and you want to ensure that you aren't using magic numbers, The approach covered in the article uses magic numbers exactly like standard enums use. 
I don't think you understand the points I was trying to get across. &gt; The author addresses that concern right in the second paragraph. What are you talking about? No he doesn't. e.g. const int explosionSnd = 1001; Why is `explosionSnd` the value 1001? Why not 10, 100? ?? How/why is 1001 meaningful? If it's just the index of an array, then a standard enum is perfect. &gt;Calculating a hash value of a string is a bit more computationally expensive than simply providing the hash value. If you're trying to squeeze every drop of performance out of a loop, this is the sort of stuff that you'd avoid doing. You're not going to be playing a sound every frame. This is really just premature optimisation. Sure you could argue you need to draw an image every frame, however, you would obviously cache the value into a variable.
&gt; You can't pass a TrafficLightState::red into a function that expects a CarColor. You can't do that with old enums either.
The benchmark source is missing some includes. I had to add `#include &lt;range/v3/algorithm.hpp&gt;` and `#include &lt;range/v3/view.hpp&gt;`. My results with clang 3.5 and `-Os -std=c++14` (with asserts enabled) insertion_sort_n (random-access) : 171 ms insertion_sort (random-access) : 173 ms insertion_sort_n (forward) : 291 ms insertion_sort (forward) : 291 ms It's interesting that here forward iterators don't show as large a slow-down as in the paper. -70% vs -780%. In any case, these results duplicate the paper's results: there's virtually no performance penalty for counted iterators. I also tried to see if I could run it under VS2013, but VC++ is still missing too much.
Same here, but it did take a lot of work to get to this point.
-O2 insertion_sort_n (random-access) : 167 ms insertion_sort (random-access) : 170 ms insertion_sort_n (forward) : 294 ms insertion_sort (forward) : 288 ms -O3 insertion_sort_n (random-access) : 172 ms insertion_sort (random-access) : 167 ms insertion_sort_n (forward) : 261 ms insertion_sort (forward) : 288 ms Looks like maybe -O3 is able to get a bit more out of insertion_sort_n (forward), so there is some slight 'penalty' in that case. Unfortunately gcc's not available to me at the moment, but the paper already includes gcc -O3.
I've consistently found gcc's optimizer to be better than clang's. It's possible that the slight performance difference you see with clang and -O3 would go away with gcc. That's what my tests showed. Thanks for double-checking the results.
_HELL_ _NO!_
&gt; gcc is a very large program. Any large program will have a bug tracker with tens of thousands of issues. That's just the norm for large and complicated projects. This. Additionally, every GCC user in the world is free to file any report that crosses their mind, from the complex to the inane. We can't expect that the volunteer maintainers will always be able to comb through the torrent of incoming reports with enough speed to handle the influx of reports. These reports do pile up. I believe this holds true for every large project. A couple of months ago I received an email informing me that a bug report I filed on KDE's bug tracker was marked as invalid. That bug report was filed in 2006.
&gt; Perhaps I missed it, but wouldn't it be nice to tell the reader, which unit testing framework you are gonna use, before you state: I would go a step further and say that it should be mentioned right in the title. There are plenty of ways to skin a cat, and plenty of combinations of tools that can (and are) used to get the same effect. The underlying principles are important, but more important than all, particularly in tutorials targetted at the greenest of newbies, is getting things to actually work. To achieve this, knowing which frameworks are being used and which tools are being employed is of fundamental importance.
I was agreeing with trueanalytic :D. C++ exceptions are for code paths you don't expect to execute in a well-formed program, given expected input.
Seems to be a solved problem that a programmer thinks is broken when mathematically the STL has chosen the best solution available with begin/end. It works equally well with both integers and floating point calculations for iteration. Since begin/end is half open interval based any interval can be broken up and expressed with multiple adjacent begin/end pairs and still be a fully continuous space. With closed intervals (ranges) you lose this ability to break up things and retain continuity. Thinking only in terms of integer space is very short sighted.
I don't believe this is a replacement, only an alternative.
&gt; These values are used to represent distinct enum values. This is exactly the way standard C++ enums work, with the exception that the choice of these magic values are by default left to the compiler. Except you shouldn't have to explicitly define the values of the enumeration. Unless they are meaningful values, such as powers of two or useful constants (that are not weird and obscure values such as "100 to 200 are human sounds"). 
Jumping on the discussion a little late, but... I like to use exceptions on global resources not possible to fully constrain within your program like file i/o, because errors can arise in any point along the chain of operations, but it is very likely the recovery path code will be the same for any of these failures. Also, it's the only way to signalize a failed attempt to construct an object.
I assume this would be the ultimate example, though the other examples provided in this thread would count as well: &gt; Instead, if the construction of a UnicodeString fails, for example when it is constructed from a NULL UChar * pointer, then the UnicodeString object becomes "bogus". This can be tested with the isBogus() function. A UnicodeString can be put into the "bogus" state explicitly with the setToBogus() function. This is different from an empty string (although a "bogus" string also returns TRUE from isEmpty()) and may be used equivalently to NULL in UChar * C APIs (or null references in Java, or NULL values in SQL). A string remains "bogus" until a non-bogus string value is assigned to it. For complete details of the behavior of "bogus" strings see the description of the setToBogus() function. (from http://userguide.icu-project.org/strings)
I use `vector` and friends for collections. I don't know what else "maintaining a collection" could mean. I bet this is exactly what the author is ranting about.
But that's no longer an expression of hatred! You changed both content and style.
a reason i'm so adamant about this is because this latest code base (physics based modelling software) we decided for some reason to fully embrace half open interval across the board. Doing this ended up automatically resolving former issues we constantly had with off by 1 errors and also sub pixel errors when going between screen space and continuous space. I'm not fond of the "range" concepts CS people seem to naturally fall into.
I refactored the benchmark [here](https://github.com/det/bench_ranges). Each benchmark is now its own program and the Makefile runs it 5 times and then prints the best time. It also runs in various configurations of both clang and gcc. Unfortunately, the stable release of libstdc++ doesnt appear to support all the type traits used so I was unable to get numbers for gcc. My older desktop CPU (Intel Wolfdale): clang -O2 forward: 667.762 clang -O2 forward_n: 722.903 clang -O3 forward: 721.611 clang -O3 forward_n: 722.881 clang -O2 random: 655.867 clang -O2 random_n: 655.503 clang -O3 random: 655.956 clang -O3 random_n: 654.238 My newer laptop CPU (Intel Ivy Bridge): clang -O2 forward: 595.106 clang -O2 forward_n: 594.06 clang -O3 forward: 592.723 clang -O3 forward_n: 593.785 clang -O2 random: 594.733 clang -O2 random_n: 593.727 clang -O3 random: 593.748 clang -O3 random_n: 593.645 If you would like to run the benchmark yourself be sure to init/update the git submodules and use the "bench/bench_clang/bench_gcc" make targets.
Bind in the debugger sort of sucks too. You have to step through all that dispatcher code to get at the real call and it's pretty deep. On the other hand debuggers that are up-to-date and can handle lambda do so better. Binds are also useful when you just want to ignore a lot of parameters. So if you have a function that takes 1 argument and you want to bind it to a `boost::signal` or `std::function` that provides 5 you can do so without having to define a wrapper lambda that takes all 5 arguments. Lambda doesn't completely deprecate bind. Lambda makes a better default, but bind shouldn't go away or be massively discouraged imo.
One optimization technique in some game engines for hard coded strings is building a massive string table so while the code may use a "soundname" as a key it changed to just be a pointer value/comparison for map lookups. can't find the article but I think it was maybe crytek engine that did this and there was a bug in their stl with an incorrect function template that caused an issue a hard to find crash.
Luck. I hope this makes it in. I've not really leveraged `boost::range` a lot but I've liked it when I did. What I've reviewed of this proposal seems to be a better, more rigorous version that I'd like even better.
Great, thanks. Your numbers seem to agree with mine.
Actually if I care about speed I will prob prefer rand since fancy C++11 RG are fast but huge. export is a fake example since it was not used... gets() will never be truly deprecated. Set keys is also one thing you said you enjoyed implementing but it is a minor thing compared to other stuff. again c++ bw compat is a burden and a strength... just because you think it would be cool to remove a feature that doesnt make it a logical thing to do... anyway Im sure ISO is filled with pragmatic people like myself so Im not too worried about this being accepted. :) Maybe you could do a trial and remove stuff from this proposal from MS codebase. :) You will need 9 lives to do that. :D 
Size isn't speed. mt19937 is extremely fast, despite the size of its state. gets() was removed outright from C11 and C++14. I've removed std::gets from VC14 (removing ::gets is up to our CRT maintainer). set immutability was actually a pretty dire breaking change, considering all the code depending on it, although it was definitely a good thing.
One thing that stands out is that member functions on the referred-to-class can be called fine, but non-members would require a dereference of the handle to invoke (4.6), which might be a problem in codebases that use a lot of non-member functions. I think begin() will work though (provided std::begin is 'used').
Not if x.f() to f(x) transformation (4.7) is accepted too.
&gt; const cast is not used in cases like that And how does that make the video any better? &gt; you will find const_cast-s that work And how does that make suggesting const_cast any better? Teaching people to rely on unreliable features is not good teaching.
I've only had a quick look so far, but it seems to me that neither paper suggests extending the `x.f(y)` syntax to non-class objects. I'd say this is only truly uniform if we're able to do things like `a.begin()` where `a` is an array type object and it would call `std::begin(a)`. This would require some extra thoughts about the "namespaces" of built-in types, but I think it's necessary for such a proposal.
Yet another proposal that will make code and tool development more difficult than it ought to be, without offering any important benefits to the programmer. 
Thanks - serves me right for commenting before reading the whole article!
I like this proposal. Especially if they allow member call for arrays with specified size: size(), begin() and end() int arr[10]; arr.size(); arr.begin(); arr.end(); 
abhorrant! ABOLISH ALL member functions, allow ONLY OPERATORS. PUNISH DEVIANTS. *the endophile*
But... that makes all my function calls one character longer.
I have to say I agree with this. Both Bjarne and Sutter are people I respect but this change seems to me too theoretical of a fix with too little practical application. Sure, a uniform syntax is nicer than what we have...I guess. I can at least see the argument for it. Truth be told though before I saw the name attached I was going to say something along the lines of, "I worry that with the velocity the C++ committee is gaining in changing and updating the language it's going to be inundated with everyone's pet change and then fall into a tar pit." Seeing both Bjarne and Sutter have similar, opposing opinions to mine does give me pause but there's a whole lot of other shit I think could actually provide real benefit to C++ I'd like to see happen before a change like this. Neibler's range stuff for example. They've changed my mind before though so I'll be open minded about it...but it still seems like a waste of time.
And the debugger, oh my.
Herb argues that it actually makes tooling easier, since x.f(y) is more constrained than f(x, y), after you write "f(", and that this allows tooling to provide you with better autocompletion. And about important benefits to the programmer, it has some very important ones (http://www.reddit.com/r/cpp/comments/2j3kkm/n4174_call_syntax_xfy_vs_fxy/cl857ir)
Like I said, I can see an argument for it. The workaround is silly simple though.
Not to say that I ever implied anything of the sort and you're not just creating random controversy...but given the example you gave yes, I believe I do.
I think the problem that I see this proposal is trying to solve is the inability to pass a reference and a smart pointer to a unique template function.
&gt; Hence, downvoted. Argument from authority... No, I downvoted you because * I believe your first point isn't relevant for the use cases proposed. * The cons represented by your second point are minor compared to the benefits of the proposal. Don't be so quick to jump to baseless conclusions.
I suppose the suggestion is implicit. I was expecting to see it mentioned more explicitly as part of the unification.
Also, it's pretty clear at this point that for C++, "intellisense" (actually code completion, the other is MS-specific marketing slang) is only possible via solutions like libclang where an actual compiler comprehends the code. Then it's really not a question anymore whether or not your autocompletion will work with a language feature.
Heh the fact you are telling /u/STL about proper C++ is a little amusing :)
&gt; will make code and tool development more difficult than it ought to be Out of interest, why do you think that? My observation is that code generation for `x.f(y)` is essentially `f(x, y)` under the hood. The `this` pointer for `struct X` is implicitly passed as the first parameter for the member function `X::f(int)` during the function call. I think standardising this alternate invocation has several benefits. First, it exposes some aspects of the underlying C++ ABI to the programmer and clarifies how member function binding works. This is especially illuminating when you want to understand how to correctly use `std::bind` with objects and their (non-`static`) member functions. Second, some C programmers already use `f(x, y)` style calls to emulate object oriented design patterns. Porting such code to C++ could be easier if the language natively supports such a syntax. (However, since C++ is backwards compatible with C, the second example might be a moot point.) One particular aspect about Bjarne's argument resonated with me: &gt; For example, I prefer `intersect(s1,s2)` over `s1.intersect(s2)`. I have been doing some computational geometry development and faced similar situations. I often find myself writing auxiliary `intersect(const Solid&amp;, const Solid&amp;)` functions, which are external to the `Solid` class in order to facilitate the alternate style. Sometimes this alternate style is more readable, but accessing private member data in external functions is restricted (...although this is not an issue for most cases). 
This is really nice. The only downside is that almost all C libraries prefix their function names. Thus you would have this: im-&gt;gdk_pixbuf_do_something(...); instead of im-&gt;do_something(...); Though if they could, by some miracle, do the latter, it would be massively awesome.
&gt; because it does solves real world problems involving proxies No, it does not. Proxies are served by overloading the operator -&gt;. Adding more ways to proxy things simply adds more confusion, especially since a Ref&lt;T&gt; object may hold either a pointer to something or a reference to something. &gt; Second, because your performance claim is moot. I did not speak of program performance, I spoke of tools performance. &gt; Finally, a good intellisense tool will have to cope with operator-&gt; anyways. That's the problem, C++ is so complex that no tool can cope with operator -&gt; adequately. &gt; If you are not using your compiler's AST for this you deserve what you get. C++ is not a context free grammar, in order to create the AST you need a fully fledged C++ compiler front end. 
It's a mistake to do that automatically. A smart pointer shall not be reduced to a reference automatically. If you have a template function that accepts references only, and then you have a smart pointer to an object, your design is simply erroneous. Mixing references with smart pointers is a recipe for disaster. 
I do not understand either of your points. You say: &gt; this allows tooling to provide you with better autocompletion To what does 'this' refer to in the above sentence? If x.f(y) is more constrained than f(x, y), then it is x.f(y) that will give more precise autocompletion. ? And about important benefits to the programmer, it has some very important ones (http://www.reddit.com/r/cpp/comments/2j3kkm/n4174_call_syntax_xfy_vs_fxy/cl857ir) Then so provide the functions as methods of the relevant classes.
[YouCompleteMe](https://github.com/Valloric/YouCompleteMe) is an extremely fast autocompleter that links against Clang's frontend. It's never had any issues parsing `operator-&gt;()` in my experience. Since Clang's C/C++ frontend is crossplatform (or nearly), anybody writing their own parser for an "intellisense" tool deserves their suffering.
&gt; the class Ref&lt;T&gt; holds a pointer to T. That's indirection. How do you think references are implemented? &gt; There are no actual benefits from this proposal. I guess you never had to write a proxy class, a COW wrapper or something similar. This proposal is *very* useful, we can discuss if it is the best solution to obtain a class with "handle" semantics, but, especially in modern C++, a proposal like this would be very useful. &gt; The tools are a really important part of development. Absolutely, but is the tool that should be designed around the language, not the other way around. And tbh I dont see how this proposal would be hard to implement for Intellisense.
&gt; class Ref&lt;T&gt; holds a pointer to T As does T&amp;, i.e. references are implemented via pointer indirection anyway.
&gt; where an actual compiler comprehends the code. MS intellisense uses a full C++ compiler frontend (not their own) licensed just for that purpose so it doesn't include a backend.
No, they are not entirely the same. There are cases where they are different. A reference doesn't have an address, a pointer has, and thus references can be optimized better than pointers. 
&gt; How do you think references are implemented? References are not 100% equal to pointers. A reference doesn't always have an address. References can be optimized in a better way than pointers. &gt; I guess you never had to write a proxy class I've written countless proxy classes, from server/client proxies down to using duck-typing to wrap existing classes. The benefits of proxies are well known in certain situations. I am not arguing against proxies, I am arguing against the proposal. &gt; Absolutely, but is the tool that should be designed around the language, not the other way around. Not really. At some point, for professional development, the tools matter more than the language. &gt; And tbh I dont see how this proposal would be hard to implement for Intellisense. Have you ever used intellisense regarding operator -&gt;? isn't that bad? half of the time the intellisense tool cannot simply find the appropriate members. 
From the page you linked above: &gt; YCM has no official support for Windows So unless this fine technology is ported and used in Windows, and until Microsoft and other IDE makers adopt it, we are screwed. 
It compiles fine, there's just no official support. Here's [the instructions](https://github.com/Valloric/YouCompleteMe/wiki/Windows-Installation-Guide) if you want to give it a try.
I do hate legacy systems. To summarize "Yeah, the people that still using cobol on their mainframes also want trigraphs in C++."
I remember several situations in the past where I wished C++ had this exact feature. I really hope it becomes standard someday. 
A useful summary of this talk is available [here](http://www.infoq.com/news/2014/10/modern-cpp-essentials).
I think object notation is really useful when function parameters are of the same type, but are not commutative. e.g. finding a substring or projecting a vector onto another. I'd prefer Vec v = a.projectedOnto(b); auto found = s.findStr("blahblah"); over Vec v = projectedOnto(a, b); auto found = findStr(s, "blahblah"); for unambiguity. This proposal would be cool because it means we could declare `findStr` somewhere else - like `stringtools.h` - as a non-member function, but still call it like the first code block. I think classes get bloated a lot because people want this nice syntax, but the methods really should not be part of the class unless they need to know about its internal representation.
wat. There are people out there that have old school mainframes and they want to use c++17 on those machines? wat. 
&gt; If x.f(y) is more constrained than f(x, y), then it is x.f(y) that will give more precise autocompletion. That is correct. Thus, being able to call non-member non-friend functions like f(x,y) using x.f(y) syntax, will provide better autocompletion for them. &gt;Then so provide the functions as methods of the relevant classes. No. To the irony of Java, non-member non-friend functions provide better encapsulation than class methods. They also allow you to write more generic code. Furthermore, you cannot extend all classes (e.g. if their source code is outside your control). You cannot add methods to literal types.
How well will this work with the STL? IIRC std::lower_bound uses a different implementation and it's noticeably slower than std::set::lower_bound.
Why is that important? Is there no "Step into..." and "Goto definition" functionality in your IDE/Debugger?
Anyone remember how revision 1 differs from this? Are there any significant changes?
I didn't bother posting this in that thread when I first saw it, but I'm not sure how good of a summary it is. I'm only 20 minutes into the talk (I've been too busy for CppCon videos, and Herb's was too dense for me not to give it some additional attention), and I'm already bumping up against 90% of what is in that "summary". Given that the talk is 1h40m long, it has to be missing a lot.
&gt;We will continue to oppose trigraph removal, because we feel someone must speak for the minority of users who cannot speak for themselves Hmmmm
So as I understand it, your goal was to change `typedef existingType newType;` to `existingType typedef newType;`? That already works: int typedef MyInt; MyInt i = 5; Really, though, I would prefer the newer type alias syntax: using MyInt = int; Just as a heads up, you're using reserved identifiers. Any name that contains two adjacent underscores, or has a leading underscore, followed by an uppercase letter, or is present in the global namespace and has a leading underscore, is reserved for the implementation.
And their keyboards don't have brackets. 30 year old keyboard, gcc 4.9.
MS *already uses* a compiler backend to support Intellisense with recent versions of VS. In fact they use an even more standards-compliant compiler backend (EDG's) to handle that task than their own code-generator compiler.
I don't understand why the seemingly practical solution isn't to ban trigraphs from ASCII/Unicode encoded files, and to offer a tool to convert back and forth with EBCDIC encoded files that transforms back and forth to tri-graphs. Wouldn't that a) simplify the language and tooling for the common case of not having EBCDIC, and b) still provide a "way out" for source files that need trigraphs to represent certain symbols?
How would these participate in overload resolution? How would that behave with overloaded operator . that some other proposal describes? Also, does D do this both ways as well? Edit: Also, swap will finally work as intended ;)
I think we need to think more clearly about why people like the `x.f(y)` syntax. I like doing `cat file | sort | uniq` at the command line. We read text from left to right, and therefore the order of functions should be left to right. When I'm using R, I define a custom operator so that I can do something like `get_data() %|% sort %|% cumulative.sum %|% plot` . We like piping (`|`). The important thing is that the function name appears after the data, and that we can chain multiple calls together. x.f(1).g(2).h(3).i(4); is better than i(h(g(f(x,1),2),3)4) ; // which param goes with which function? But do we have to use the `.` syntax? I guess we can't use `|` as it's already defined and would change the meaning of existed code. But `$` is unused in C++ and perhaps we could use it for this. In fact, let's be really bold and drop the brackets :-) x $ f 1 $ g 2 $ h 3 $ i 4; *Update:* If that's too much for you, here's something much more conservative that can be partly implemented already x(f,1)(g,2)(h,3)(i,4) You just need to define the `operator()` operator for your `x` object. Of course, that won't work if `x` is `int`, or something you haven't defined yourself, such as `vector&lt;int&gt;`. In fact, hopefully/maybe the current proposals will all for this? If we're going to be allowed to define new methods from 'outside' a class, then hopefully that includes the `operator()` method.
I am confused.
I don't know that it simplifies the language so much as now instead of "You can either have a or b" you now have to say, in the language definition, "If file is encoded with standard x then all feature a" for each of the trigraph things. On top of that, compiler writers to be standards compliant now have to go through and disable/enable features in the language based on file encoding. Ultimately, we should just remove it from the language. From now till eternity IBM will support trigraphs in their compilers as penance for their sin of creating EBCDIC, but future compilers won't have to pay for their mistakes. The simple solution is to remove it from the language. Writing a tool that can replace trigraphs with curly braces should be simple enough.
Everyone hates trigraphs. They pretty much only exist because IBM made a stupid standard for the sake of making stupid standards (EBCDIC). So the committee proposed we remove this stupid language feature. IBM balked and said "Well, people still use our stupid standard to save and compile their code!" If we are lucky, the committee will acknowledge and ignore IBMs worries and remove this abomination from the language. The small subset of the C++ community that uses trigraphs probably won't even realize that they were removed from the standard as IBM is probably going to support them from now until the end of time.
The future is Unicode. One of the best decisions D made was to go "all in" with Unicode.
Does D allow arbitrary unicode in source? As in int 💩 = 3; ? 
lol. I mean, im all for keeping backward compatibility, but this _should_ be just mechanical replacement of things. Its also pretty surprising that there actually is code written with trigraphs out there. Also, if i were IBM, id probably not say a thing, if only to prevent people from making fun of me for having non-trivial amount of trigraph ridden code.
 #include &lt;cstdio&gt; int main() { int x = 1; // Why isn't this code working????????/ x = 5; std::printf("%d\n", x); } 
D allows arbitrary Unicode in comments and string/character literals. Unicode in [identifiers](http://dlang.org/lex.html#Identifier) is constrained to match what is allowed for C99 Appendix D, otherwise known as Universal Alphas. Typing in Unicode can be difficult with some keyboards, so D supports [named character entities](http://dlang.org/entity.html) which are far easier to remember than \Uxxxxxxxx numbers.
In his talk, Herb devotes a lot of time to discussing parameter passing, and comparing how different cases stack up in C++98 conventions and what kind of problems several alternative, incorrect suggestions entail. This discussion is kept to a minimum of useful information in the summary, since it would have been too a dense discussion, otherwise, for that kind of post. I regret that you may find it not good enough. On the other hand, I hope you agree that a summary cannot convey all the information of a 1h40m talk. Its aim is giving an idea about the talk content, so you can decide whether it is worth to look at it or not. Thanks for the comment, though.
Phew. I mean, you said "all in", and there are languages out there which do allow arbitrary unicode (or at least a lot of it) in identifiers. This being valid Go code is pretty scary for me: package main import "fmt" func main() { var ざ int = 3 fmt.Println("Hello, 世界", ざ) } Edit: On second thought ... package main import "fmt" func main() { var １ int = 2 fmt.Println("Hello, 世界", １) }
As the paper mentions, supporting trigraphs will still be a conformant extension, as it will then fall under the unspecified physical character to shource character translation that occurs in phase one. --- &gt; We recognize the removal of trigraph will make C++ less surprising, easier to teach, and possibly improve its adaption for non-experts for a majority of users because the majority are in the ASCII or non-EBCDIC Uncode world, According to Walter Bright trigraphs are also a [performance problem](http://www.drdobbs.com/cpp/c-compilation-speed/228701711) for C++ processors. I'm not sure how accurate that is, but I've never seen IBM address this argument. --- So there are some banks which will not be affected by the removal of trigraphs because they're never going to update anyway. There are some users which can't use square brackets for some reason. digraphs support them just fine, if they're really insistent on not figuring out how to use square brackets. (The digraphs `&lt;:` and `:&gt;` look way better than the trigraphs `??(` and `??)` anyway.) There's a consulting firm that uses IBM-1047 "because it's the best match for ISO-8859-1." I'm not sure why ISO-8859-1 isn't a better match, but whatever. Trigraphs are not needed at all when writing source using IBM-1047 so removing trigraphs should not be an issue here either. "Why drop something which will break something?" Because the something we're dropping breaks other somethings. --- Also, what's this talk about C++ being "ASCII-centric"? The usage that IBM wants to preserve has nothing to do with ASCII. The problem (from an earlier paper by IBM) is that they want to compile source code which does not have a set EBCDIC encoding. That is, they have source in one (or more) of many possible EBCDIC encodings, and they need to use only characters that are shared among all EBCDIC codepages until the source code sets some encoding #pragma or something to specify the exact codepage. Since not all of C++'s basic source character set is in the common set of character's shared by all EBCDIC codepages, that means they need to be able to write C++ without using certain characters until they can specify an encoding in source. But this practice is not something that C++ has ever supported. C++ does nothing to support this practice in ASCII. There is nothing ASCII-centric about continuing to not support this usage. Some other compilers have more reasonable methods of handling encoding, such as gcc's -fsource-encoding and similar flags, or Clang's support for UTF-8 exclusive of everything else. Unfortunately there are some other compilers that support bizarre encoding practices, such as VC++ and their `#pragma setlocal` (Which should also never be used, btw; It can lead to things like the compiler thinking [`L'Я' == L'ß'`](http://stackoverflow.com/a/13628093/365496). I would not be surprised if IBM's compilers have similar problems.). There's nothing 'ASCII-centric' about C++. If you want to write C++ you can do so using whatever encoding you like, but you should _pick one_.
Swift allows emojis inside the code as actual names. [Yes, I'm serious](https://developer.apple.com/library/ios/documentation/Swift/Conceptual/Swift_Programming_Language/TheBasics.html#//apple_ref/doc/uid/TP40014097-CH5-XID_454) (scroll down to "Naming Constants and Variables").
My surprise is simply that the content of the summary seems to only be the first 20m of the talk. The only thing in the summary I haven't seen yet when watching the first 20m is the part on tuples. Obviously there are going to be details in a 1h40m presentation that don't need to be summarized. My point was that I can't imagine that Herb just belaboured the point for an additional 80 minutes. See e.g how [high scalability summarizes talks](http://highscalability.com/blog/2014/10/13/how-league-of-legends-scaled-chat-to-70-million-players-it-t.html) for what I consider a detailed summarization. Edit: Also, be aware that going forward if you use your account like you have been so far you're going to fall afoul of reddit's [issues with self promotion](https://www.reddit.com/wiki/selfpromotion). I don't want to discourage your participation and I think they're silly, but falling afoul of them can mean getting shadow banned.
A C++ post that's voted into oblivion here, but got tons of votes at /r/programming. What's the world coming to?
And yet we expect Koreans to use code bases with English ones.
We're smart enough to know better. I complained about the link in /r/programming and was gived with a controversial comment indicator, meaning I got some significant number of downvotes.
I don't see why that's particularly scary. I mean, #include &lt;iostream&gt; int main() { auto I____________ = 5; auto I___________ = I____________ + 3; auto I__________ = I___________ + I____________; std::cout &lt;&lt; I____________ * I__________; } is perfectly legal C++; it's not like naming discipline only becomes a concern once unicode is permitted.
Well, conceptually I'm pretty bothered by the fact that I can't use the type system to enforce the non-nullability of a smart pointer, eg. an unique pointer that can't be null, so there's clearly a missing symmetry: lent owned nullable * std::unique_ptr non-null &amp; ??? we miss a way to express an "owned reference" here. And in practice it means that I have to go back to assert()ing the validity of unique and shared ptrs, and after having converted most of the code to use &amp; where non-nullable it feels like a step backwards. This (albeit the whole "fallback" thing feels like an hack) would solve this quite real-world problem.
This will be a very welcome addition indeed
Most encouraging bit is MS is experimenting with the necessary compiler changes so it's not going to be just Clang/GCC-based compilers that support it.
It looks like N4165 also allows for extending at least x-&gt;f(y) syntax to non-class objects: the examples around FILE and functions using it (fseek, fputs, fclose) propose changing from &lt;&lt;FILE *file = ...; fseek(file, 9, SEEK_SET);&gt;&gt; to &lt;&lt;FILE *file = ...; file-&gt;fseek(9, SEEK_SET);&gt;&gt;. As far as I've seen, though, arrays aren't addressed in particular.
I hope this proposal has a higher priority to become a standard...
I haven't done a side by side comparison, but this does seem to be pretty much the same. --- I still think that the experience with clang has shown that exporting macros from modules is reasonable, and important for module adoption. Namely it enables 'well behaved' headers to be converted trivially to modules and then users instantly gain the benefits of modules. I'd really like to see more from the people who have implemented modules in clang. Their module.map thing may not get standardized but they've got a lot of experience with exactly what needs to be in a module interface, what libraries actually need, etc.
Can't come soon enough.
??/ is a trigraph that turns into \ So that code turns into // Why isn't this code working??????\ x = 5; Which has an escaped new line and so is the same as // Why isn't this code working??????x = 5;
I did a lot of ETL work for a major financial institution that does... Which is terrifying.
Don't quoted entities conflict with some expressions? Other than quoted entities this is pretty much the same as C++. (Though it took a long time for compilers to support even the C++98 rules for identifiers.) 
C++ and D do allow those as identifiers.
&gt;C++ already lets users define the values of the enumeration. Yes, but it's pointless to do so, unless it has a meaningful constant value. And in this case it does not.
You seem to have misunderstood the proposal. Your talk of half-open ranges being better than this proposal is a non sequitur: the ranges in this proposal _are_ half open.
Because the preprocessor stages are very specifically laid out to avoid ambiguity. (This instance is “stupid”, but unambiguous—comments are processed after line-escape removal, which happens after trigraph processing, so no two preprocessors will handle it differently if they’ve got trigraphs enabled. All sorts of corner cases pop up, though— /??/ * a comment *??/ / is another similar case.)
Trigraphs were the original solution to the problem of certain characters not being available everywhere. E.g. some keyboards not having keys for curly braces, or the common text encoding in some country not including backslash. Over the last 40 years those problems have largely disappeared, and we've gotten enough experience to know why trigraphs were a bad solution in the first place, and so now trigraphs _won't_ be part of the language, starting with C++17. Using backslash to eliminate newlines, however, will still be in the language, and it still gets used a fair amount.
oh the backslash to eliminate newlines is cool, it's sort of like ... in Matlab, which I used all the time back when I was writing Matlab more often
Named entities can only appear in comments and string/character literals.
Is it just me, or does this poses much more questions than other proposals?
Well, it is possible, but you know, it's not free. Why write boilerplate when you can let the language manage this? I was favouring Stroustrup's proposal because of the multimethods at first. But I think Sutter did a very appealing proposal that is simpler to integrate and does not require as much juggling as would be to introduce completely uniform syntax. On top of that it is true that it is good for the tooling AND it still keeps all the features, including multimethods.
Does exist any benchmarking or some numbers about how much improves compile/link time using clang modules?
finally! after decades of lost productivity time I hope this will become a standard. BTW, there's no excuses for vendors waiting for a standard, they could have done an implementation long before this being standardized....
Nice. Have you considered this kind of [reservoirs](https://github.com/dropwizard/metrics/blob/master/metrics-core/src/main/java/com/codahale/metrics/ExponentiallyDecayingReservoir.java)?
I wouldn't even mind if compile and link times are the same (theoretically of course, they should be better). I'd just be glad not to have to re-declare things multiple times and avoid all the namespace noise in header files. The improvements when refactoring things will be marvelous.
That's an interesting situation. Probably because their compiler does not generate an AST (I've heard) and so is not easy to re-use in such contexts.
We've seen build times cut in half so far. We only have a sample size of one large program, but we're measuring more as we can.
Oh, whoops! I thought that only applied at the front of identifiers— my mistake. `s/_/I/g` or something, I guess.
&gt; There are lots of times where I wanted to forward the inner object interface. Why didn't you use the operator -&gt; then? 
References are nullable too. The following is legit code: Foo *foo = nullptr; Foo &amp;foo1 = *foo; 
How do they manage to have such shitty intellisense then, when it comes to operator -&gt; and compared to Java? It Java, the intellisense for operator . is spon on, unlike c++ for operator -&gt;. And then there are the free tools: Eclipse, Codeblocks, Anjuta Dev Studio, etc. 
&gt; Why didn't you use the operator -&gt; then? With this operator, it is pretty much automatic from what I understood. With an old pimpl, you have to forward *manually* each member function you want to expose. Please correct me if I'm wrong. 
When I say 'in debugging', I do not only mean 'in debugging session'. I mean when I am reading the code in order to find the problem, with or without debugging. And not all platforms have good debuggers. 
Please name some.
Yeah, like everything in C++ you can shoot in your foot hard if you misuse it... but at least with references you have to be actively stupid to get a crash instead of just forgetting yet another nullcheck. And in an ideal world of default-is-reference where pointers are few, used appropriately and always checked before use, I think it's pretty hard to end up in that situation.
The rules are: \_Leading\_underscore\_capital and double\_\_underscoreAnywhere identifiers are reserved everywhere, \_leading\_underscore\_lowercase is reserved at global scope.
You can't have a C++ program with few pointers and lots of references. References are not rebindable, like pointers are.
If MS wanted to do it in a way incompatible with the rest of the world they would probably not care writing a *standard proposal*. They'd just do it.
&gt; I don't know that it simplifies the language so much as now instead of "You can either have a or b" you now have to say, in the language definition, "If file is encoded with standard x then all feature a" for each of the trigraph things. On top of that, compiler writers to be standards compliant now have to go through and disable/enable features in the language based on file encoding. When you frame it like that, it sounds difficult. If instead you frame it as, "trigraphs are a feature available for representing source code in character encodings that don't support the language's native glyph set". And you don't have to go through disable/enabling features, you just tweak a standard character set decoder for EBCDIC to include decoding of trigraphs (perhaps you have to expose it has high as the lexer)... and that's only if you even support parsing source encoded with EBCDIC, which you probably don't. This actually *reduces* complexity because you'd be able to write portable header files without much thought to trigraphs beyond possibly C compatibility (and hopefully the C guys would follow suit). Compiler wise you'd likely be able to drop out of worrying about trigraphs that much sooner. &gt; The simple solution is to remove it from the language. Writing a tool that can replace trigraphs with curly braces should be simple enough. From a practical standpoint, is that really different from what I'm suggesting? Most compiler writers won't support EBCDIC, and those that do (basically IBM) will invariably need to use some kind of work around, and the trigraph one seems preferable if for no other reason than C compatibility.
This is unexpected indeed. Wat you're saying is that /r/programming hates C++, but for some reason that you don't know voted up that link anyway and downvoted you, who was critical about it? Then at your home turf here, you organized all your friends to downvote the link, and there's nobody around here to upvote it? Strange... 
Interesting. What I use at the moment is a simple [reservoir sampling](http://en.wikipedia.org/wiki/Reservoir_sampling) where every *collection_interval* seconds it gets reset.
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Reservoir sampling**](https://en.wikipedia.org/wiki/Reservoir%20sampling): [](#sfw) --- &gt; &gt;__Reservoir sampling__ is a family of [randomized algorithms](https://en.wikipedia.org/wiki/Randomized_algorithm) for randomly choosing a sample of *k* items from a list *S* containing *n* items, where *n* is either a very large or unknown number. Typically *n* is large enough that the list doesn't fit into [main memory](https://en.wikipedia.org/wiki/Main_memory). The most common example was labelled *Algorithm R* by [Jeffrey Vitter](https://en.wikipedia.org/wiki/Jeffrey_Vitter) in his paper on the subject. &gt;This simple O(*n*) algorithm as described in the *Dictionary of Algorithms and Data Structures* consists of the following steps (assuming that the arrays are one-based, and that the number of items to select, *k*, is smaller than the size of the source array, *S*): &gt;The algorithm creates a "reservoir" array of size *k* and populates it with the first *k* items of *S*. It then iterates through the remaining elements of *S* until *S* is exhausted. At the *i*^th element of *S*, the algorithm generates a random number *j* between 1 and *i*. If *j* is less than *k*, the *j*^th element of the reservoir array is replaced with the *i*^th element of *S*. In effect, for all *i*, the *i*^th element of *S* is chosen to be included in the reservoir with probability *k/i*. Similarly, at each iteration the *j*^th element of the reservoir array is chosen to be replaced with probability *1/k * k/i*, which simplifies to *1/i*. It can be shown that when the algorithm has finished executing, each item in *S* has equal probability (i.e. *k/length(S)*) of being chosen for the reservoir. &gt; --- ^Interesting: [^Combination](https://en.wikipedia.org/wiki/Combination) ^| [^Fisher–Yates ^shuffle](https://en.wikipedia.org/wiki/Fisher%E2%80%93Yates_shuffle) ^| [^Jeffrey ^Vitter](https://en.wikipedia.org/wiki/Jeffrey_Vitter) ^| [^Abiogenic ^petroleum ^origin](https://en.wikipedia.org/wiki/Abiogenic_petroleum_origin) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cl91u8d) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cl91u8d)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
No they're not. That's undefined behaviour. &gt; ... the standard calls this exact situation out in a note (8.3.2/4 "References"): &gt;&gt;Note: in particular, a null reference cannot exist in a well-defined program, because the only way to create such a reference would be to bind it to the “object” obtained by dereferencing a null pointer, which causes undefined behavior. http://stackoverflow.com/questions/2727834/c-standard-dereferencing-null-pointer-to-get-a-reference?rq=1
Not really a surprise to me now that if you love big and complex stuff, you love relational databases, and hate NoSQL.
Your statement about references not being rebindable does not logically imply that you can't have a C++ program with few pointers and lots of references. Can you explain why you think that this is the case?
This is /r/cpp: we all know that that is not legit code. Any code that contains undefined behaviour is not legit, and all bets are off safety/language-wise.
I get 404 on that link
Alternative URL: https://www.hackinparis.com/sites/hackinparis.com/files/SebastienAndrivet.pdf &amp; https://github.com/andrivet/ADVobfuscator
Template metaprogramming is a software obfuscation method in its own right.
Of course it is legit code. 
Because when you have indirection variables, most of the time you need to rebind them to another value. 
If the compiler allows it, it is legit code. It's not well defined code, I can give you that. But this situation can arise for many different situations. The pointer can be set to null in a place in the code that is extremely far and disconnected from the place where the reference is created. If the compiler doesn't guarantee that references cannot be null, then they can be, period. 
Just because a compiler allows it to compile doesn't mean it's not undefined. Once you dereference that null pointer you will get undefined behaviour, which in turn, if the compiler allows that code to be compiled, will result in a run-time error. 
http://i.imgur.com/mgc1gAh.png http://i.imgur.com/r5tl3Xh.png http://i.imgur.com/d6Rwgvf.png I don't have eclipse, code::blocks or VS (I don't use VS because I'm on OS X).
Can you quantify "most of the time" for me? This sounds like a bunch of hand-waving. In my code at work, we only use pointers heavily when writing device drivers. Everything else on top of that is roughly 90% references and values, 10% pointers.
See [this](http://www.reddit.com/r/cpp/comments/2j3ecc/n4173_operator_dot_bjarne_stroustroup_and_gabriel/cl94dwu) reply of mine. 
In any c++ project I've been involved in the last 15 years, it's 99% pointers, 1% references. 
Well then I guess we've reached the obvious conclusion: different projects are different. In that case, why do you assume that &gt; when you have indirection variables, most of the time you need to rebind them to another value. holds for everyone, and not just projects you have personally worked on?
It's actually pretty easy to enforce. There is a list of things that are considered "undefined" in C++: don't do them. Work it into your code review or your in-house programming style. For this particular case of not dereferencing null pointers, it's as easy as ensuring that you either check if it is not null in an if-statement or assertion. Let's not blow this out of the stratosphere.
A discussion [here](https://www.reddit.com/r/cpp/comments/2j5vo9/resumable_functions_yes_please) as well. 
Someone can correct the information if it's wrong but they already did it for their version of C++ for WinRT.
&gt;WinRT uuuurrrrgghhaaaaaaaa
This is pretty cool.
Wooooooooow. Now you're going to follow me around and mock me everywhere I go? I asked an honest question. I don't love relational databases. I don't hate NoSQL. I pointed out that NoSQL turned out to not be a catchall solution, and that hurt your feelings.
No, it is not. Obviously, you have not worked in a large project where programmers of various degrees of experience come and go. 
It's easy. Change instances of x = *ptr; to if (ptr) x = *ptr; else // Do something else. Report error, set to default, whatever you need to do. If your programmers of various degrees of experience cannot adhere to a simple rule like "check to make sure this pointer isn't null" then you have interviewing problems. As for my work experience, currently I work in applied physics, and many of the programs that I end up maintaining are written by students of all people (i.e. novices). Even they are capable of checking to see if a pointer is null before dereferencing it. And if they don't, then it is caught via code reviews and fixed. Honestly, it's not difficult. I'm not saying mistakes don't happen, as well make them. But this is pretty easy to catch and fix with a teeny weeny bit of discipline.
By hurt feelings, you meant to say you are factually incorrect, and cannot accept such.
When you can provide some evidence for your wide-sweeping claims, then maybe people will start to believe you. I'm sure we've *all* worked in a lot of computing fields.
Oh, so you _are_ saying that NoSQL _is_ a catchall solution.
So he is not allowed to make sweeping statements, but [you are](http://www.reddit.com/r/cpp/comments/2j3ecc/n4173_operator_dot_bjarne_stroustroup_and_gabriel/cl90gyt), is that right? Bub, you need to check yourself before you wreck yourself.
It's almost (but not quite) orthogonal to parallelism in terms of cores. You should look up the concept of coroutines which is effectively what is being suggested here.
I'm glad they haven't offered this. The reason is that if each compiler has a different implementation, then it would be difficult to get the best solution standardized. That being said, people have experimented with it using clang and gcc. I'm glad for the experiments so lessons could be learned and help the committee come up with a better solution.
How would link times be better? (Compile times should be better, but link time escapes me.)
&gt; No. It will make it harder for the autocompletion mechanism to come up with the proper suggestion, because it will make parsing harder. That doesn't matter since to correctly parse C++ you need a compiler front-end anyways. It will only make this harder for people who are already doing it wrong. &gt; They don't. They do in my programs, and in other people's programs [0 - 1]. &gt; They also allow you to write more generic code. That's why we have inheritance. How does inheritance help you write generic code? I hope it is not by using inheritance to provide polymorphic interfaces, since inheritance is pretty bad at that when compared against the alternatives [2-3]. Inheritance is a way to reuse behavior or state, using it for anything else is not the best solution in most common cases. &gt;And obfuscating the code by pretending that it is a good thing is good some how? I don't think it obfuscates code at all. &gt; If I see the following code: &gt;int i; &gt;i.x(); &gt;I will think that int is a custom class and there is a preprocessor macro that redefines the keyword int. No. New and old C++ programmers will learn that f(x,y) == x.f(y), and thus you know that there is a function x(int) somewhere since int is a literal type. Other programming languages work like this and people cope with this just fine. Btw redefining int using the preprocessor is undefined behavior. &gt; When I read the code, in one case the method 'bar' of class Foo is invoked, and in another case the function 'bar' in the local translation unit is invoked. No. In the second case the call to bar also results on a call to Foo::bar since member functions have priority (see the conclusion of... the link at the top of this page). The compiler will issue a warning (since you specialize bar for a particular foo) saying that this function will never be called because Foo already defines a bar member function. [0] http://www.gotw.ca/gotw/084.htm [1] http://www.drdobbs.com/cpp/how-non-member-functions-improve-encapsu/184401197 [2] https://www.youtube.com/watch?v=_BpMYeUFXv8 [3] http://channel9.msdn.com/Events/GoingNative/2013/Inheritance-Is-The-Base-Class-of-Evil
One way linking can be improved with modules is that debug info for an imported module can be kept with the module rather than in every object file where the module was imported. That means smaller linker input and less duplicate stuff to manage. Another benefit is that debuggers can potentially access imported modules and can therefore do things like use template specializations that were not used in the static source: Since they have access to the template the debugger can instantiate new specializations on request (like when you try to evaluate an expression that needs a specialization that was not used in the exe being debugged.)
I recall one presentation where Doug Gregor showed the improvements for a few Obj-C projects. The compile/link time improve a few percent for a project that previously used meticulously maintained pre-compiled headers and ~40% for a smaller project which didn't use precompiled headers. And keep in mind that these weren't C++ projects and so the headers contained just interfaces, not significant parts of the implementation. See [here](https://developer.apple.com/videos/wwdc/2013/) and look for "Advances in Objective-C". A free Apple developer account may be required to access the content. That was when they just released module support as production-ready for C/Obj-C. A lot of work has been done since then, and the C++ module support was just recently rolled into the `-fmodules` flag by default. (Previously it was under `-fcxx-modules` as it was considered 'experimental'.)
Just an awful idea. Really, really bad.
If my type is a value, I dont want to change the syntax from operator. to operator-&gt;. Why? Generic code.
In which way it worsens the status quo? Dont tell me it can be abused. Every feature can. This improves syntax uniformity. Did you read the paper carefully? Maybe needs some refinement but I find it a useful idea.
Interesting.
No, I didn't say that. &gt; you organized all your friends to downvote the link What gives you that impression? My point is just that I think a 300 link dump is close to useless, and tons of the resources are suspect. The first link under videos is to "Awesome C Programming Tutorials in Hi Def [HD]" which is from 2010 and starts off by recommending BloodShed DevC++ using GCC 3.4.2. The rest of the videos look similarly horrible. Spreading this junk should be discouraged.
I just got started using coroutines in C#. They are fantastic for adding parallelism to code that is not thread safe.
I'm happy to pay for it! The tablet I'm getting has 2GB of RAM, and 2.2GHz processor - it is more powerful than my laptop, and that runs c++ code fine. I couldn't imagine coding anything on a 5 inch screen - thanks for the response :)
It works great, I got it on my phine so that I could learn on long commutes.
&gt; Resumable traits &gt; If the signature of a resumable function is &gt; R func(T1, T2, ... Tn) &gt; then, a traits specialization `std::resumable_traits&lt;R,T1,T2,...,Tn&gt;` will indicate what allocator and what coroutine promise to use Did I read wrong, or does this mean that once someone, somewhere, has specialized `resumable_traits` for his/her own signature; then should you wish a resumable function with the same signature you will be coerced into using the same promise type and allocator? If so, I don't quite like that...
Its awesome for what it does. The developer will even respond when emailed.
That's fascinating, any chance you'd have a link to some extra info? Doesn't necessarily have to be C++ or C#.
Have you been able to fix your problem yet? I had no problems finding the installed JDK/JRE under Windows. I assume you have set your JAVA_HOME? Btw: CDT has also its own parser, not just Cevelope (and Cevelope is CDT based with some plug-ins and other changes that didn't get accepted as sumbits into the CDT).
You always have the return type to vary. For instance making a thin wrapper over `std::future`. ~~I don't know enough about traits, but is there a requirement that they be universally unique? Or just unique in a given execution context?~~ EDIT: Removed incorrect bit. I do kind of like the wrapper idea for the return type however. You can look at the wrapper used to determine what promise type and allocator are being used if you architect it the right way.
I have to agree 100% with that statement. It would also help if the or maybe better a language widely implements Unicode math characters in a logical way and maybe more importantly a standard way. 
I'm using unity3d: http://docs.unity3d.com/Manual/Coroutines.html
Ah cool. I was thinking of parallel as in, say AMP's `parallel_for_each`. But now I see this coroutine technique, I want it in C++ too :-)
Traits are just templates, so this is the same as for all template specialization: They have to be unique throughout the entire program (all definitions must exactly match each other).
What's the advantage over the following? #define NAMESPACE foo namespace NAMESPACE { ... }
co-routines are not about parallelism, there is only one co-routine active at any given time.
you are correct in that when using a single namespace a single define is the easiest solution. however the advantage is that you can compose nested namespaces by comma separated lists. e.g. NS_BEGIN(a,b,c) wil generate namespace a{namespace b{ namespace c{ so you can define a namespace with #define MY_NAMESPACE a,b,c and then nest it deeper or less deep just by changing MY_NAMESPACE. 
You can modify them to simulate multi-threading, it's not the standard use.
Thanks for the pointer.
After rereading the proposal, I'm hopeful that the committee can craft a library only version. I'm not sure why, but I feel like this doesn't need language support as much as it needs platform support. Maybe it just seems too magical to me!
With a library only version you cannot do much better than fibers. Fibers don't scale and a context switch is rather expensive. With compiler support, compiler knows exactly which registers it need to save at this particular suspend point. Suspend could be as cheap as a single store (save suspend IP) and return. 
You're right.
C# provides two kinds of resumable functions. Generators (must return IEnumerable&lt;T&gt;) and async functions (must return task&lt;T&gt;). We are trying to be more flexible in C++ and open it to library developers to invent new generator types and new task types. Not limiting to one particular library. Essentially, whoever defines "MyGenerator&lt;T&gt;", also needs to provide a specialization of resumable_traits&lt;MyGenerator&lt;T&gt;,Whatever...&gt;. That will take care of hooking up his library machinery to resumable functions. Now if you are not the library writer, but want to tweak something a little and override whatever library writer provided you have two options. Make your own MyVeryOwnGenerator that inherits/aggregate MyGenerator and provide resumable_traits for MyVeryOwnGenerator. Or create some tag type. JustForMe_t and provide specialization resumable_traits&lt;MyGenerator&lt;T&gt;, JustForMe_t, Whatever...&gt; In this case, you will be able to force resumable function to use your machinery if you supply JustForMe_t tag type as a first parameter. But, most of the time, this is unnecessary. Library writer invents new coroutine abstraction and provide the resumable_traits specialization for it. Nobody else should care.
True, but they *are* about concurrency- multiple tasks being scheduled and run in the same time period. That's the beauty! You can write concurrent tasks as coroutines in a much more natural procedural style.
While we're at it, here's a similar one: http://inforum.org.pt/INForum2012/docs/20120025.pdf
I've already stated this in my child replies below and as i've said already there are never co-routines executing in parallel, there is only one co-routine active at any given time. They are time sliced, they do not "run in the same time period". The only time that could happen is if you have 2 sets of co-routines running on different threads but they can never collaborate across threads. I am not saying they do not have any value, I never said anything of the sort. You would never write a parallel algorithm using co-routines, if you did you wouldn't have a parallel algorithm anymore.
co-routines are not a replacement for a parallel for loop, they are always serial, never execute in parallel, never utilize more than 1 core, you do not speed up your loop using them. That's not the point of co-routines. 
...They do run in the same time period. If I schedule 2 coroutines, both of which have some yield points, then run the loop, they are essentially running in the same time period. True, the actual execution point is only ever at one place at a time, but they are running *concurrently*. Even though they aren't running in parallel, they have a lot in common with parallel processing- the order of execution is non deterministic at the yield points, each coroutine is running separately from the others but they share memory, etc.
&gt;If you are starting to work on a library and do not know exactly how your namespaces are going end up these macro helper are for you. Why? Just name your namespace relating to your library (e.g. the name of it or something similar). If you decide to change it later, just replace text via a tool (your IDE, text-editor or whatever). If the user of your library doesn't want to type out the complete namespace (for instance if it's very long or there are quite a few nested namespaces), then they can simply use the language to help them out (via [namespace aliases](http://en.cppreference.com/w/cpp/language/namespace_alias)). e.g. namespace really_long_namespace { void foo(int bar); } namespace rln = really_long_namespace; rln::foo(bar);
[Here's](http://www.open-std.org/Jtc1/sc22/wg21/docs/papers/2014/n3985.pdf) an unrelated (as far as I know) coroutines proposal from May if anyone's interested.
All in all, following the discussion, we can conclude that parallelism and concurrency are not the same term. The confusion came from there :D
If you want to change your life a bit right now and you can rely on boost, use boost.coroutine. I have used them successfully. At first they were a bit tricky to understand for me, since I was not very familiar, but, hey, I must say they work great for a lib solution.
Could someone fill me in on what this is? A list on the proposals which are being considered to be taken into the standard of C++17?
The MS c++ compiler is extremely buggy. The compiler developers (Radigan and co) should spend their time fixing the compiler bugs and regressions that are still lingering around from over the last decade rather than wasting their time trying to add useless new keywords to the standard. I can tolerate STLs' and Sutters' efforts as they are somewhat productive for the general good of the C++ language. But all this other stuff just smells of resume padding to me. 
Those are the proposals which mostly will be handled at the C++ Committee Meeting in Urbana. Most will influence C++17.
Yeah I noticed in the source, this is why I was asking. I'll try to use Cavalieri someday :) Good job anyway !
Hey, try Terminal IDE (it doesn't require root), it's free and opensource and has builtin tutorials in "Help". It uses Vim, and you can run C/C++, and Java code. I tried it yesterday on my Samsung galaxy tab pro 8.4, and i run some code samples from tutorials, and it works nice so far.
Agree the compiler is quite buggy. I suffer it at work (in its VS2012 version), and, compared to gcc or clang, about standards compliance, there is no contest.
In the trivial case I think your right. However if you have systematically named namespaces which are nested (sometimes very deeply as in my case). The need for controlling them automatically can arise. And these macros are the solution I came up with. - as I stated this is a niche case 
As in the other answers - replace will not work in nested cases where you might want to add or remove "nest". Further I think of the preprocessor as a tool which is should be used where applicable. And using it to replace code where making errors is easy (as in nested namespace) is its whole purpose. But as always beauty is in the eye of the beholder. 
&gt; It will only make this harder for people who are already doing it wrong. Which are quite a lot. &gt; They do in my programs, and in other people's programs [0 - 1]. 0: moving code outside of a class doesn't make a class less monolithic. The functions outside of the class are still part of the class' API. 1: the article is wrong: the degree of encapsulation and the degree of modifications required when a class changes is irrelevant. Even if a function is not part of a class, if the class API is modified, then the function will need to change. &gt; How does inheritance help you write generic code? By coding the common parts between classes in a base class. 2: sorry, I don't have the time to watch an one hour and 43 minutes presentation in order to get a single proposition. 3: again, I don't have the time to watch videos. I found the pdf though. In the pdf, the author simply implements polymorphic behavior based on use. In other words, it creates functor objects that inside them do various things, and all these functor objects have the same signature. He could have done the same simply using std::function and lambdas, but for the sake of the argument let's suppose that he does that for illustrative purposes. Even so, he actually uses subtype polymorphism in order to implement the functors. It's impossible not to use subtype polymorphism, even if it is in the root object. However, applying this pattern to large software components that can handle many messages will quickly become a maintenance nightmare: functors will be scattered around the code, introduced at arbitrary places, split responsibility between many different files etc. So no, this type of polymorphism is not better than the classic one, for many cases. &gt; I don't think it obfuscates code at all. You may think so, but it actually does. I gave you an example of how it does obfuscate code. &gt; No. New and old C++ programmers will learn that f(x,y) == x.f(y), and thus you know that there is a function x(int) somewhere since int is a literal type. Learning such stuff is easy. Reading code with this is difficult. &gt; Other programming languages work like this and people cope with this just fine. These languages are not in mainstream use yet. &gt; Btw redefining int using the preprocessor is undefined behavior. The compiler allows it anyway. &gt; No. In the second case the call to bar also results on a call to Foo::bar since member functions have priority That means my function bar() introduced locally will never be invoked. But when reading the code, I will assume, out of habit, that it will. And then I will unlearn that a free standing function is not a free standing function, so I will have to look up the class to see if it is a freestanding function or not. Too much fuss without any real benefit. &gt; The compiler will issue a warning (since you specialize bar for a particular foo) saying that this function will never be called because Foo already defines a bar member function. So now I will have to pay attention to one more message from the compiler, without any actual benefit. No thanks. Really. 
Of course he is allowed to make sweeping statements. Even wrong ones such the one that he did. On the other hand, my sweeping statement is not wrong at all. Have you ever tried to write c++ code without using pointers? it's not possible. 
Haha. Was funny your comment lol! But it is useful.
In the case of 3 or more fields to order by, would you use variadic template to implement this? 
Yeah, after googling error messages, fixing up its .ini file and downloading different version (32bit vs 64bit) because that seemed like the easiest way of unfucking the JRE problems. All in all, not impressed with the delivery, although the IDE is pretty nice. 
Damned if you do, damned if you don't
Which is a pretty reasonable expectation, given that there are an estimated 1200 million speaking english and 80 million people speaking korean, and every major existing software project is already developed in english.
Oh God, never once did we discuss not using pointers in C++. I have issue with your statement that "You can't have a C++ program with few pointers and lots of references." You need to learn a few things a) How to understand what others write b) That C++ can be written without resorting to pointers in 99% of the case c) That the style of C++ that you have experienced in the workforce is not an indicator of the style of C++ that is used worldwide Until you can come to grips with these three points, I think our conversation should be put on hold. It seems that a lot of people in /r/programming and /r/cpp like to downvote your comments. It's not a hivemind conspiracy, you're just not adding anything to the discussion and you're lashing out when you're getting called out on your incorrect statements.
Maybe I'll look into this, thanks.
&gt; How to understand what others write I understood what you said, very well, thank you. &gt; That C++ can be written without resorting to pointers in 99% of the case No, it cannot. &gt; That the style of C++ that you have experienced in the workforce is not an indicator of the style of C++ that is used worldwide Yes it is. &gt; It seems that a lot of people in /r/programming and /r/cpp like to downvote your comments. That's because they don't understand. That's not my fault, and it is also not an indication of what I write being incorrect. &gt; you're lashing out when you're getting called out on your incorrect statements I never lash out. I just offer counter arguments. Now, on to the point. Any application that needs to mutate references (to mutate the references themselves, not the objects the references refer to) or allocates data on the heap directly in order to share them via shared pointers requires pointers. The above includes: 1) gui applications. 2) console applications that need to allocate big chunks of data to be passed around efficiently. 3) console applications that receive data over the network. The above alone makes 99% percent of c++ applications. If 99% is not a good number for you, we can take it as low as 90%. The argument still holds: the majority of c++ programs need pointers. 
Sure but the co-rountine version is not executing child calls in parallel.
&gt; Which are quite a lot. The list of editors/IDE/tools supporting auto-completion/semantic analysis via a compiler fronted is actually pretty large (VisualStudio, XCode, emacs, vim, sublime text, KDevelop, Eclipse, Doxygen...). I cannot think of a widely-used editor/IDE that supports auto-completion and doesn't support a compiler front-end to do it. I would be surprised if you could provide any evidence. &gt; These languages are not in mainstream use yet. Ruby, C#, ObjectiveC, Python, Javascript offer this (via extension methods). The UFCS proposals are just a first step in the same direction. The next step is the multi-methods proposal (also for C++17). &gt;The compiler allows it anyway. Since `main` has to return int, I highly doubt it. &gt;The functions outside of the class are still part of the class' API. True. &gt; moving code outside of a class doesn't make a class less monolithic. Not true. Non-member non-friend functions can only use the class public interface. Non-member friend functions and member functions can also use the protected and private interface. Since `public + protected + private &gt; public`, non-member non-friend functions improve encapsulation. &gt; By coding the common parts between classes in a base class. I thought that by generic you meant polymorphic. Reusing behavior is fine. &gt; 2: sorry, I don't have the time to watch an one hour and 43 minutes presentation in order to get a single proposition. &gt; 3: again, I don't have the time to watch videos. I found the pdf though. You got the points from the talk wrong. &gt;it creates functor objects that inside them do various things, and all these functor objects have the same signature. He could have done the same simply using std::function and lambdas, but for the sake of the argument let's suppose that he does that for illustrative purposes. No, he implements a polymorphic interface with value-semantics that is not based on subtyping. That is the whole point. &gt;Even so, he actually uses subtype polymorphism in order to implement the functors. It's impossible not to use subtype polymorphism, even if it is in the root object. Using a virtual-function for type-erasure is an implementation detail. &gt;However, applying this pattern to large software components that can handle many messages will quickly become a maintenance nightmare: functors will be scattered around the code, introduced at arbitrary places, split responsibility between many different files etc. Proof? The author actually is lead architect at Adobe, which has bought many companies, and has to build single applications using completely independently developed code-bases. The author argues that not applying this pattern is what leads to a mess, and shows proof that inheritance based polymorphism doesn't scale across independent codebases while concept-based polymorphism does. Concept-based polymorphism is also faster than inheritance based one (there are a couple of blog posts on probablydance.com about this) since you only pay for polymorphism when you need it. With inheritance-based polymorphism you pay all the time not only for the polymorphism you use, but for the possibility of using more polymorphism in the future. This is why devirtualization without final and LTO doesn't work across TUs. &gt; Reading code with this is difficult. &gt; Too much fuss without any real benefit. &gt; So now I will have to pay attention to one more message from the compiler, without any actual benefit. &gt; No thanks. Really. It is difficult for you, for me it is actually way easier. For me (and most people on the reddit thread), this features has a lot of benefit. &gt;That means my function bar() introduced locally will never be invoked. But when reading the code, I will assume, out of habit, that it will. If you don't want to change habits when changing to a different programming language you probably shouldn't change. Noone forces you to program in c++11/14/17, it is opt-in. Just stick with 03, 98, or C with classes, and you will be fine. [*] as in code that works with a lot of different types, not code reusing behavior through inheritance. 
Sure it does. Here is an example of naïve scheduling. fib(n-1) and fib(n-2) launched as tasks. fib(n) is suspended 'await'-ing on when fib(n-1) and fib(n-2) are ready, then, it sums the results up and continues. Of course, with this naïve scheduling, we will explode the state due to doubling number of tasks at every recursive step. A better scheduling strategy is to use parent-stealing. Namely, we schedule only one child, fib(n-2). Parent will go directly into fib(n-1) and when done will suspend itself waiting for completion of fib(n-2).
First of all, I'm glad you finally constructed some decent points to back up your opinion. Kudos! Secondly, I still don't think you fully understand why people take issue with what you say because nobody ever previously mentioned writing C++ without pointers, yet you felt it was necessary to counter our arguments with &gt; Have you ever tried to write c++ code without using pointers? it's not possible. Let me re-state that: never once did anybody make the claim that you can program *without pointers*. I brought up the fact that I use pointers 10% of the time in my at-work codebase, and references are much more prevalent. You seemed to take issue with that. But did you see anywhere me mention that I never use pointers at all? It's that, and other issues, that lead me to feel like you just don't understand the conversation... 
&gt; I would be surprised if you could provide any evidence. Codeblocks. Anjuta. Others, lesser known. Even those you mention are not good enough to be able to present the appropriate suggestions all the times. &gt; Ruby Not mainstream. &gt; C# I can't seem to find any relevant documentation. &gt; ObjectiveC Nope. It's [self &lt;method name&gt;]. At least in the official docs. &gt; Python Again, I can't find relevant documentation. &gt; Javascript Ok, you found one. Nice. &gt; Since main has to return int, I highly doubt it. Yes, the compiler allows it. It does not have to be in a translation unit visible from main(). &gt; Not true. Non-member non-friend functions can only use the class public interface. Non-member friend functions and member functions can also use the protected and private interface. Since public + protected + private &gt; public, non-member non-friend functions improve encapsulation. Again, encapsulation != monolithic. Monolithic means 'set in stone' and 'cannot easily be changed. As long as a non-friend static function uses a class public API, it is tied to that specific API. It's monolithic design. &gt; You got the points from the talk wrong. Nope. &gt; No, he implements a polymorphic interface with value-semantics that is not based on subtyping. That is the whole point. In the presented code, the class model_t inherits from concept_t which is polymorphic. Hiding the polymorphic class behind a non-polymorphic facade does not make the code not use polymorphic classes. &gt; Proof? The author actually is lead architect at Adobe, which has bought many companies, and has to build single applications using completely independently developed code-bases. The author argues that not applying this pattern is what leads to a mess, and shows proof that inheritance based polymorphism doesn't scale across independent codebases while concept-based polymorphism does. Yeah, that's why Adobe apps crash twice a day. I am using Flash Designer and Flash Builder daily, and they either lock up or crash constantly. There are other huge applications, much larger than Adobe's, that use the straight polymorphism c++ offers, which are built from many other code bases, and run fine. Microsoft Office, browsers, real time defense applications, games, etc. &gt; It is difficult for you, for me it is actually way easier. For me (and most people on the reddit thread), this features has a lot of benefit. Yeah, argument from popularity. A real winner. Galileo is already spinning in his grave. &gt; If you don't want to change habits when changing to a different programming language you probably shouldn't change. I am not against changing habits, if the benefit is great. There is no benefit from this proposal. 
I know it's pedantry on my part, but, strictly, on a single core system, no multi-tasking executes in parallel. So that distinction is not the key one when talking about co-routines. The difference between co-operative and pre-emptive multitasking is important to understand (not for you, but possibly for those reading your comments). So when you say "They are time sliced", you are not correct (under the traditional meaning of "time-slice") because a co-routine can run for as long as it likes, if it never yields, it will never be sliced. 
Yes I'm familiar with Cilk and parent-stealing but I'm not convinced with the co-routine version that's not how I've known co-routines alone behave from other programming languages. Unless that spawnable type is doing something else I'm not seeing like queuing/forking a parallel task for each branch. EDIT: Okay checking the paper that is what's happening, it's not co-routines that gives you this feature. That's working with/on top of them but by themselves co-routines don't execute in parallel.
&gt; First of all, I'm glad you finally constructed some decent points to back up your opinion. Kudos! I did not say anything in the last post that I have not said in the previous posts. &gt; You seemed to take issue with that. But my point is that in most c++ programs, 90% of the code uses pointers, and not the other way around. &gt; It's that, and other issues, that lead me to feel like you just don't understand the conversation... Again, I have understood correctly what you said. You seem to not be able to understand that I do not agree with your point about the 10%. How hard is that to understand? 
That's why I said they are great for code that is not thread safe, it's not actually multi-threading. You don't use them to speed up a for loop, you use them to sequence GUI stuff.
Actually in C++ you would try to write a range with iterators; it is certainly doable and very nice to use, but sadly a lot more code. This is about as simple as it get's: https://github.com/ryanhaining/cppitertools/blob/master/range.hpp And *that* is the point that you no longer have any doubts about coroutines being better.
&gt; I did not say anything in the last post that I have not said in the previous posts. Sure you did. This is the first post in which you even attempted to explain how you came to your 99% (or 90%) figure... You fleshed out three categories of programs and argued that those alone make up 99% of C++ applications. This is new stuff to this discussion. &gt; But my point is that in most c++ programs, 90% of the code uses pointers, and not the other way around. You still have not fully justified this... You've simply gone from "I say that 99% of C++ code uses pointers" to "I say that 99% of C++ code uses pointers because X", and you have not given any reason for us to believe X is true. What kind of metric are you using to determine that those three classes of applications alone makes up 99% of C++ applications. If you can't back up your numbers, then don't argue with numbers. And furthermore, even if that class of applications makes up 99% of C++ programs, what proof do you have that they contain 90% pointers? &gt; Again, I have understood correctly what you said. You seem to not be able to understand that I do not agree with your point about the 10%. You clearly don't understand, because I was talking about *my codebase* at work using pointers roughly 10% of the time, and references the other 90%. Last I checked you don't work in my office, so how can you disagree with a codebase that you have never seen?
coroutine is a very old term. It got used to mean a lot of things :-). Since it preceded threads and fibers, it has been used to mean them too. Modula-2 coroutines are pretty much threads. Boost::coroutine are fibers. N4134 tries to distill coroutine to the essence. Function that can resume and suspend. Compiler only provides an efficient way to suspend and resume. Library writers define what semantics of the coroutine is and allows them to do things like 'spawnable&lt;T&gt;' to invent new kinds of coroutines. In the example above. spawnable&lt;T&gt; is similar to a future that was returned from std::async(launch::deferred). When you ask for the value via .get(), it will get scheduled and give you the result. But, unlike, current std::future, it allows to hookup .then to supply continuation callback and then post it to a work queue to be executed whenever and provide the result later. 
Not for competent developers. It tends to keep the incompetent ones out - which is a benefit...
Ok thanks :)
&gt; The number is out of my ass, based on experience. So it's not a general statement, it's a number out of your ass. Instead of dragging this out, why didn't you just say that in the first place? All I've ever asked for is for you to explain why you throw around words like "most of the time" and "99%" the way you do... &gt; Now what about your number that only 10% of c++ code needs pointers? let us see you backup that. Look again, I never said that. I said that in my codebase, 10% of the C++ needs pointers. The rest is handled with references. Please re-read my previous comments and present a quote of me saying that only 10% of all C++ code needs pointers. As for the rest of your comment... It sounded like a bunch of hand waving *not* because it did not apply to my use case of C++ (device drivers, GUI's, data analysis software), but because you used the phrase "most of the time" without any backing evidence or additional explanation. That's waving your hands. It was only a few comments ago that you even bothered to try and explain your stance. All that I ask is that you back up your claims with something tangible. Were there any studies done that show how prevalent pointers are to C++ codebases? How old are the codebases? What about new projects (say, since the release of TR1)? Instead of throwing around general statements and assuming everyone is going to simply accept them as irrefutable truth, why not try to argue with some evidence? Not numbers out of your ass that you "strongly believe" are correct. Just a thought.
&gt; That's because they don't understand. That's not my fault, and it is also not an indication of what I write being incorrect. Also, if everyone seems to misunderstand you, maybe they're not the problem. If it smells like crap everywhere you go, check under your shoe.
Yes, indeed. Too bad you weren't around when Galileo did not think the Earth was flat. 
I like this proposal more than the other similar one. It has a lower impact and with the arbitrary position for the this parameter it makes C interfaces much nicer to work with.
There are refactoring tools that understand the structure of your code. In a recent talk, the Google maintainer mentioned that Google is working on open-sourcing an indexer that can be used to search code, which would be the first part of refactoring.
The refactoring maybe, but the convenient syntax is something the standards body is looking IIRC. Something along the lines of namespace foo::bar::car { }
I think the trait system is designed to better align with how people typically use allocators. Or more specifically allocator choice is often a program level selection, not a function level selection. That isn't to say you don't sometimes need to choose a non-default allocator for a given function, but isn't that the exception, not the norm?
Sorry to be really pedantic but he's not using `forward` correctly. (I didn't know much about type erasure, so I am glad I watched it. And my comment doesn't affect the main point of his talk.) Anyway, the slides around 18m09s should have `T&amp;&amp;` instead of `T`. The code there isn't buggy, it just fails to make full use of move semantics. If you want to perfectly forward things, you must follow this rules to the letters. If you want more background, watch the [excellent Scott Meyers talk](http://channel9.msdn.com/Shows/Going+Deep/Cpp-and-Beyond-2012-Scott-Meyers-Universal-References-in-Cpp11). template&lt;typename T&gt; anything:: anything(T&amp;&amp; t) : // don't forgot the &amp;&amp; here handle(new handle&lt;typename std::remove_reference&lt;T&gt;::type&gt;( std:: forward&lt;T&gt;(t) )) If you want to perfectly-forward `t`, then: - the type of `t` in the parameters must be `T&amp;&amp;`. It can't be `const T&amp;&amp;` or anything else, it must be *exactly* `T&amp;&amp;`. - you must use `std::forward&lt;T&gt;(t)` or `std::forward&lt;T&amp;&amp;&gt;(t)`, *not* `std::forward&lt;T&amp;&gt;`. Actually, I think you could sneak a `const` in here if you wanted. - `T` must be a deduced parameter. - `T` must be a (deduced) parameter of this very function/constructor. It can't be a parameter from a containing class or anything like that that. The `template&lt;typename T&gt;` must immediately precede the name of this function/constructor. If you break any of these rules (he broke the first one) then you don't get the new C++11 behaviour.
It's an interesting point, the result is pretty expressive. My purpose was not to introduce concepts of c++11 because (unfortunately) I can't use it at work. However it is a good point to use to convince coworkers and managers to switch. Many thanks for your contribution 
My favorite bit is at 14:55: &gt; This is not C++14 tech, this is not C++11 tech, this is a C++98 rule. People love to whine, "Ohhh, C++ is so complicated, it makes my brain explode!" And you know, with some justification. But when the complicated rules work, as they work in this case, it's really awesome. We just write the overloads we want, and their structure guarantees that they're unambiguous.
Yep. &gt; Actually, I think you could sneak a const in here if you wanted. You don't want to add constness when perfect forwarding. As a minor note, `static_cast&lt;T&amp;&amp;&gt;(t)` is equivalent to `forward&lt;T&gt;(t)` (ignoring forward's second overload; if you don't know about that one, you don't need to know). In our STL implementation, we use static_cast only when we're in code that literally lives above forward's definition, otherwise we use forward everywhere.
Awesome talk, as always! Couple of questions about the compiler/library test suites you mentioned: 1) are such tests publicly available somewhere? 2) do they cover all the code examples in the Standard? 3) shouldn't working paper authors proposing new features also be encouraged (mandated?) to supply unit tests for their proposals?
I've been waiting for his talk in particular to be uploaded. Great talk as always from STL.
&gt; 1) are such tests publicly available somewhere? libc++'s test suite (which we're using) is publicly available. So is libstdc++'s. VC's (now-misnamed) devcrt is MS-internal, and our (now-misnamed) tr1 is licensed from Dinkumware. Other third-party test suites (part compiler, part library) include Perennial, Plum Hall, and McCluskey, which are licensed. &gt; 2) do they cover all the code examples in the Standard? Some test suites attempt to be comprehensive, others (like devcrt) don't. The Standard's examples are occasionally used as tests, but they're far closer to "does this feature vaguely look like it works" instead of "is this feature absolutely bulletproof and radiation-hardened". &gt; 3) shouldn't working paper authors proposing new features also be encouraged (mandated?) to supply unit tests for their proposals? That would be nice, but even for library features it'd be a whole bunch of work. You can tell, because companies make money selling such tests. That said, if you look at [Uniform Container Erasure, Rev 1](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4161.htm) you'll notice that it includes both an implementation and a decent amount of testing (although not hyper-fanatical).
To be fair, there *are* instances where code written with "generators" might be faster than the equivalent idiomatic C++. - Generators make it easier to stream-process, and to deal with things in a single pass. If your code is tight and your data are many, you're effectively trading dcache misses for some icache pressure. - In "normal" C++ the control goes one way -- A calls B calls C, and when functions return they "forget" where they were. It's easy to make them remember state, but it can be costly to make them remember where they were (often resulting in a store on exit and a `goto` on entry. There are probably better ways to do this.
That's interesting. I assumed the "context switch" would kill performance.
I think that would leave `` ` (backtick) and `$` as the only characters on my keyboard that are not used by C++.
Context switches with boost.coroutine take 10~50 cycles (i.e. similar to a L1 cache miss).
New User Groups in the planning stage/first meetings: C++ User Group Edinburgh https://twitter.com/cppedinburgh @sftrabbit C++ User Gruppe Ruhrgebiet: http://pottcpp.de C++ Mailing List for Argentina https://groups.google.com/forum/#!forum/cppba C++ User Group Udine, Italy http://cpp.ud.it/ C++ User Group Montpellier http://www.meetup.com/Montpellier-CPP/ 
This doesn't happen per allocator, or per element type, it happens per construction. If we're trying to use an allocator to construct an element from Stuff, the Standard requires us to ask whether the allocator provides a construct() from Stuff. If it does, we need to call it. We aren't allowed to second-guess the user and skip calling their construct().
That's still pretty heavyweight. For statically predictable, non-recursive call graphs I think you can get the cost of going between generators/consumers down to the cost of a function call in each direction. For more complicated call structures you'll probably need some computed jumps as well.
I like this idea. IMO text formats are a bit overused for the sake of easy editing and human readability. Programmers and CPUs both spend a lot of time parsing strings. Tools like this could help make binary formats less scary. Put a little effort up front into solid editing/viewing tools for binary formats and reap the benefits forever.
Yeah, I'd expect something with actual compiler support to be able to do much better than a pure library solution, but even with boost.coroutine it's plausible for it to be a performance improvement if your dataset is too big for L1 cache.
Heh, I'm glad somebody made the joke.
It may with boost::coroutines, but, not with compiler supported coroutines. Context switch is a single store instruction followed by a return for suspend and call followed by indirect jump on resume
If I understood it correctly, the two overloads are not ambiguous because one of them is templated by two types (`IT1` and `IT2`) and the other is templated by three types (`IT1`, `IT2` and `PredT`). So, I have few questions: * What if my predicate type is the same as iterator type? It would not compile due to ambiguity, right? Is it forbidden by the standard? * It is forbidden to have different begin and end iterator types, right? Even in C++98 era. Maybe ranges proposal will change that algorithms will accept begin iterator and end predicate.
Really cool, Eric: auto GetEvens = view::for_each(numbers, [](int i) { return yield_if((i % 2) == 0, i); }); Is almost as cool as C++ generators :-) auto GetEvens = [&amp;] { for (i : numbers) if ((i % 2) == 0) yield i; }; What about multiple yield statements? Something like: generator&lt;int&gt; WalkTree(Tree* r) { if (r == nullptr) return; yield WalkTree(r-&gt;left); yield r-&gt;value; yield WalkTree(r-&gt;right); } Range Comprehensions are awesome, but, can they flatten the tree? 
C++ and C++/CLI are not the same language. Just sayin'.
Here is the thread from /r/programming on the video: http://www.reddit.com/r/programming/comments/2hw0bz/cppcon_dataoriented_design_and_c_video/
I did a basic compile-time string implementation in https://github.com/cdyson37/rebind by implementing a string as a sequence of types - e.g. std::tuple&lt;std::integral_constant&lt;char, 'A'&gt;, ...&gt;
You want to link directly to your string implementation? I'm not finding it. Was there something specific about your implementation that applies somehow to what I said in my blog?
Here you go: https://github.com/cdyson37/rebind/blob/master/examples/reverse_string/reverse_string.cpp Only linking for interest's sake - slightly different approach. All I did was reverse a string - a lot less comprehensive than your blog post!
&gt; Besides, what happens if the parameter in the header file is renamed? What happens if the function itself is renamed? ;)
I was thinking about the very same thing the other week. I reckon it's a good idea. The use of named arguments in conjunction with strongly typed enums, and user defined literals would be awesome. Self documenting code is something I would always support. 
Neat, I experimented with something similar a while ago. One disadvantage of doing compile-time string processing using constexpr arrays instead of the preprocessor/external tools is that the compiler is no longer able to share the storage space for duplicate strings or string suffixes. Is there a way to tell the compiler that certain constant static variables / temporaries don't actually need a unique memory address?
A valid proposal, useful when there are many parameters. Another solution you can use today is to have such functions accept a struct. The caller will fill out the struct members *by name*. It's as clear and as verbose as this suggestion, and doesn't add complexity to the language.
Syntactic sugar is like "Code Deodorant". `someMethod(false, true, true, true)` *looks* bad, so the code smell is obvious. When something looks nice thanks to syntactic sugar, the code smell is hidden.
&gt; Having multiple bool parameters is bad because it's unclear. I even agree to some extent. But this is very often abused in a way that functions do several things at a time. It is much better to write Splitter splitter; splitter.setMovable(true); splitter.setVisible(false); than Splitter splitter(movable : true, visible : false); since the first version **does only one thing at a time**. So while the argument seems flawed, it's maybe a bit less flawed than you might think :-)
Would you argue that a constructor should only take one argument?
There is a [Boost library](http://www.boost.org/doc/libs/1_56_0/libs/parameter/doc/html/index.html) that does exactly this, although I must admit that is quite a mess to use. The fact that its user-base is quite small should point out that the language does not need this feature at the moment.
Do you mean something like the [Named Parameter Idiom](http://www.parashift.com/c++-faq/named-parameter-idiom.html)? I found it to be a quite elegant solution, sadly not all of my coworkers agreed.
I hadn't seen that before. That seems like it could be quite elegant in the right situation. Reminds me somewhat of the std::streams functionality for dictating formatting info with &lt;&lt;. However, I think /u/AceyJuan is proposing something more of the form: typedef struct arg { int i1; int i2; char c1; char c2; } arg_t; void foo(const arg_t a); foo( { .i2 = 1, .c1 = 'a' } );
Yes, it supports writing bad API, but the flipside is that it makes a bad API usable (suppose you don't have influence over that API). 
It feels really evil but something like a smart pointer that allows assigning the underlying type. (Apologies if the following code doesn't compile) template&lt;class T&gt; class Pointer { T* value; Pointer&lt;T&gt;&amp; operator=(const T&amp; other) { *value = other; } } So I guess not, since I wouldn't want this kind of structure typically.
There's probably some weird pathological case involving side effects, where you can do something like Foo() = something; And that causes a side-effect. I'm not saying that's a great design for 99% of problems, but there's probably one out there somewhere.
Assuming that I understand you, and the concept of copy on write correctly, I would say that they don't conflict. Copy on write means, that the object that is referred to internally will be copied, the copy will be changed, and the internal reference will then point to the new version. E.g. Object a(original); a.munge(); // a now holds a reference to a munged object. b.frob(); // a now holds a reference to a munged and frobbed object. // original is left unchanged.
``` `` ` ``` can be used to display a singe back-tick `` ` ``, the extra space isn't even displayed. EDIT: Apparently the "correct" way is ``` `` ` `` ```. Also I finally figured out the rule, if you want to display n back-tick use n+1 back-tick around the whole thing. For instance to show ``` `` ` `` ``` I typed ```` ``` `` ` `` ``` ````.
Thanks!
True, if the list is big enough, the stack will overflow on container destruction. I think we need something like shared_ptr&lt;T&gt;::release() and then manually delete the chain of pointers. 
Eventually I figure we're going to get method signatures that can be natively exposed to bash, so we can write //main.cpp #include &lt;iostream&gt; int main(int i=0, bool b=false) { if (b) std::cout &lt;&lt; i &lt;&lt; std::endl; else std::cout &lt;&lt; -1 &lt;&lt; std::endl; } and invoke it like $ ./a.out -i10 -b 10 Command-line things *all* have loads of boolean flags, so it can't be a horrible idea :-) Named args is a big first step here.
What I'm finding interesting here is that at least in my compiler this bit based on your code works: constexpr char const str[] = "hello"; template &lt; char const* Str &gt; struct whatnot {} whatnot&lt;str&gt; something; But no combination of using my string type does. Also can't instantiate the template with a non-global char array, which I guess could be the source of the issue doing it like so: constexpr auto str = make_string("hello"); whatnot&lt;str.c_str()&gt; blahblah; It says I don't have a constant expression there. I'm wondering if it isn't the decay to char* that's the issue, but I tried an intermediary also and though I can assign to a constexpr I can't then use it to instantiate the template: constexpr auto str = make_string("hello"); constexpr char const* cstr = str.c_str(); whatnot&lt;cstr&gt; blah; // still not a constant expression! For a sec there I thought it might be possible to leverage something like what you were doing to create string types, but if it has to be a global constexpr I think that would be too limiting. I wonder though if it's not a compiler bug.
I've not done any experimentation regarding how these things get stored. I would think the compiler would have no problem treating them just like static strings...if they even appear in the program at all.
I'd strongly suggest you to avoid c++ if you're not familiar with. AFAIC the best solution for you is to install [Python](http://www.python.org) and use it something like this: from ctypes import * dll = cdll.LoadLibrary("Roccat Talk SDK.dll") dll.Set_LED_RGB(0,1,12,25,78) dll.RestoreLEDRGB() where 12,25,78 are RGB color. Put above code in file with extension ".py" (roccat.py), place in the same folder as .dll and run it from command prompt like this: c:\Python27\python roccat.py You need only this part from documentation: void Set LED RGB (BYTE bZone , BYTE b E f f e c t , BYTE bSpeed , BYTE c o l o r R , BYTE c o l o r G , BYTE c o l o r B ) ; * bZone The effect zones are Ambient (0x00) and Event (0x01). Use Ambient when you have a low rate of updates. Use Event for fast paced updates. (When in doubt: use Event (0x01)). * bEffect Off (0x00), On (0x01), Blinking (0x02), Breathing (0x03), Heartbeat (0x04). * bSpeed no Change (0x00), Slow (0x01), Normal (0x02), Fast (0x03). * colorR simple RED value 0x00 to 0xFF. * colorG simple GREEN value 0x00 to 0xFF. * colorB simple BLUE value 0x00 to 0xFF. Please remember to turn off the SDK mode when your application exits. To restore the user set colour to the TalkFX devices just use this method: void RestoreLEDRGB ( ) ;
Every attempt to avoid templates I've seen has been vastly worse than judicious use of templates.
Of course, go with the c++ if that is your primary intention and this keyboard is *just a cause*. :))
After a while I was doing my own transform in my head and started to hear: "Everything's a plumbing problem!" "You have to make sure the pipes are full!" "It's all about the sludge moving through the pipes!" It's really not though. It's just that the problem he's solving requires him to use the system to its fullest capacity to avoid blowing the inlet gasket. All joking aside, it was a good talk with some valid criticisms. 
Thanks for clarifying. I think I see now how this is a problem. What we need is a way to get our original type back out of mungeable to be able to then stick it into a frobbable robe. How about the following: T original; mungeable a(original); a.munge(); T munged = a.get&lt;T&gt;(); frobbable b(munged); b.frob(); T munged_and_frobbed = b.get&lt;T&gt;(); Here we assume an interface similar to what boost any provides. Now, if we look at this more closely, it is really silly. We could just do this: T original; original.munge(); original.frob(); So, I think the problem you're describing is actually a misuse of type-erasure. Type erasure is meant as a way of defining polymorphic interfaces without forcing user code into an inheritance hierarchy, or templated functions. So, the correct solution for the above would be to define an interface that supports both `munge`, and `frob`; and then take a parameter of that type. E.g.: class mungefrobbable { /* ... */ void munge(int x) { /*...*/ } template&lt;class T&gt; void frob(T value) { /*...*/ } /* ... */ }; void mungefrob(mungefrobbable a) { a.munge(42); a.frob("squirrel"); } I think this makes a lot of sense. If a function takes a parameter it is going to have requirements on the type of that parameter. That is what you would call the required interface of that parameter type. Following the type-erasure idiom, we provide a class which wraps anything that provides that particular interface.
You shouldn't be appending _t to your typedefs. It is a reserved namespace. 
mungefrobbable doesn't seem very satisfactory as it means that interfaces can't be composed except by hand. It would be nice to be able to write something like: typedef concept_compose&lt;mungeable, frobbable&gt; mungefrobbable;
I'm getting the following error: Traceback (most recent call last): File "C:\Users\Myname\Desktop\Roccat\roccat.py", line 3, in &lt;module&gt; dll.Set_LED_RGB(0,1,12,25,78) File "C:\Python34\lib\ctypes\__init__.py", line 364, in __getattr__ func = self.__getitem__(name) File "C:\Python34\lib\ctypes\__init__.py", line 369, in __getitem__ func = self._FuncPtr((name_or_ordinal, self)) AttributeError: function 'Set_LED_RGB' not found
I work in the games industry and I think this first hand experience helps give me a very clear idea of where he comes from. At the same time, I've worked at different companies than Mike, so my perspective is slightly different (I will not say wider - only different). Most of my comments have been made elsewhere (in /r/programming or here in /r/cpp), but I'm going to try and make this an exhaustive comment explaining why C++ does not solve Mike's problems. First, I want to adrress a misconception: **Limited** template use is common. Many games codebases have their own template library that fulfills a subset of the STL, often while also making it easier to control allocation and synchronization policies at compile time. As a specific example, it is common to have a replacement for vector that has a fixed size at compile time, ala boost::static_vector. Generally the implementation will be more straightforward and less boosty, with an emphasis on reducing the amount of code generated, rather than worrying about reusing code in the implementatoin (the way static_vector does with it's base class). The size and style of this proprietary template library will vary wildly between studios. I would expect insomniac's to be very small, whereas EA has EASTL, which was significant in size when it was originally released. The reasons for this template library existing are many: 1. The STL has poor debugging support, this is HUGELY IMPORTANT. 2. The STL solves a lot of important video game problems very poorly. std::map has a poor API, poor cache locality on lookups, and generates a lot of code. std::string and localization is objectively a disaster, std::list makes it easy to use a datastructure that is a poor solution for many problems in games, std::queue is neither threadsafe nor easy to use, std::vector's allocator's parameter has been historically hard to use, and specializing/tuning vector for a common fixed size-case is hard. That said, many (mostly smaller) games have shipped with lots of stl code. It's the big studios, that are at the top of the food chain that have the privilege of maintaining their own template library. I hope that gives you a clearer idea of how subtle the games industry's relationship with c++ is. Now, what makes games different from other programs: 1. Games are being iterated on for *years* before they're in production. This makes them significantly different from other software applications, which release in an early form and need to maintain binary compatibility. Changing large bits of code during production *can* be very cheap. It is not uncommon for things like pathfinding solutions to be rewritten just months before release. 2. The size of the "source" content on a video game is huge. A very small percent of this content is c++. 3. Games are a soft real time application. Many top-tier games will exhaust naive performance bounds immediately, and from that point on everything needs to be optimized. There is unlikely to be a single obvious bottleneck, at least in AAA games with large teams of programmers. I think that's really it. What's important is the implication of those three simple differences. When making a product *iteration time rules*. And so when making a great game, that actually has new mechanics, better graphics, and more compelling universe, iteration time of the entire build is the most important thing. Templates do not help with this problem. The things that do help are: 1. Computing resources (and the ability to use them) 2. Reliable memoization With those simple goals in mind the following c++ features become actively harmful: 1. Whole program optimization (yes, i know it's not in the standard - but multiple compiler vendors have recommended we use it. Thanks you stupid fucker, but a 30 minute link time is *never going to be acceptable you fucking walking penis*) 2. Template metaprogramming (terrible incremental build performance, not the fault of the standard, but the standard doesn't tell vendors not to recompile the entire program, so they do) Anyway, I think when you identify the iteration bottleneck you'll start to understand where Mike is coming from. He has a huge team, doing exploratory work. He needs to identify who broke what, what's slow, and what's working. The data pipeline should not be some 'discovered' feature that shapes itself underneath some 'real' code - it is the primary product that the engineering team is working with and needs to understand.
Sorry about the typos, spat this out between compiles... I'll leave it unedited so that you know I was a little rushed :)
I don't believe that's necessarily true. All the atomic operations can specify a memory order requirement, &amp; you can easily relax it. Also, when you say "publish", does it mean that other CPUs see that value too?
In the end of the talk there is a question about class hierarchies. The answer that was given is "repeat yourself." I would agree that this is not very satisfactory.
Just a side note: Depending on weather or not those two setters are virtual and some other things, the constructor-version will be faster. In most cases the compiler will be able to optimize away most of the overhead. This may not always matter (usually it won't), but it still might. Readability still comes first, but frankly I find the new, more compact version clearer and easier to read. 
Great comment! Typos? Huh, I'll have to read it again;) That sums up the impression I got from watching the video. What you and he describe is much different from the set of constraints, issues and operating conditions that I have to deal with. I understand and respect the choices.
As you point out, it's a mess to use. I suspect that's why the user-base is small, not that the language feature wouldn't be used widely if implemented neatly in the compiler. I looked into trying to use it, &amp; there was just a crap-ton of boilierplate &amp; macro magic.
Yes, that's a compiler error in C++14 and VS14. Sorry, but permitting temporary regexes in the regex iterator constructors is just too dangerous, even if there are valid uses like yours. Note that temporary regexes are also harmful to performance - a regex is *not* a string, it's an NFA, and quite expensive to construct. You really should have const named regexes that you use repeatedly. (With C++11 magic statics, you can even construct them once during the lifetime of your program.)
As an STL maintainer, I've acquired a pretty good working knowledge of atomics, although I certainly don't claim to be an expert (especially when it comes to architecture-specific details). I can explain some basic things with confidence. First, when trying to understand atomics, *forget* about CPUs and cache lines and registers and all of that stuff. Think about the abstract machine. (The abstract machine must be implemented in silicon, by getting a library developer, a compiler developer, and an architecture manual to sit down in a room together and figure things out. But if you aren't one of those people, "it's implemented with magic" is a perfectly fine understanding.) By default, &lt;atomic&gt; provides full sequential consistency (SC). SC is the *only* model that mortal programmers can reason about, without having their brains explode. (It is possible for highly advanced experts to use weaker-than-SC atomics, but it's extremely dangerous even for them. This is the sort of thing where I say, "if you have to be told how to do it, you shouldn't be doing it", like brain surgery.) The principle is, *atomics are for communication* between threads. SC atomics allow you to reason about how the program might be executed in a fairly simple way ("fairly simple" for multithreading is still tricky). Here's a simple example. Let's suppose you have two threads, and they want to access a `vector&lt;int&gt; vec`. One thread wants to insert a bunch of stuff, and the second thread wants to read the stuff. `vector` provides The Usual Multithreading Guarantees (same as `int`), forbidding simultaneous read/writes, so we need some form of synchronization. While we should use locks by default, here's how to use atomics. You have an `atomic&lt;bool&gt; atom(false);` where `atom` means "thread 1 is done filling the vector, thread 2 can read it or do whatever else it wants". The threads execute this code: Thread 1: v.push_back(stuff); atom = true; // same as atom.store(true); // DON'T TOUCH v EVER AGAIN Thread 2: // DON'T TOUCH v YET while (atom == false) { } // spin; same as atom.load() == false for (const auto&amp; e : v) // read or mess with v as much as we want Atomics do a couple of things (via magic, remember). First, they ensure that reads, writes, and special operations are actually atomic, i.e. indivisible. With an `atomic&lt;int&gt; ai`, I can say `++ai` and that's an atomic increment. Second, because atomics are for communication, they interact with *ordinary variables*. In my example, `atom` interacts with the ordinary vector `v`. What this means is, the program behaves as if Thread 1 and Thread 2 execute in some arbitrary interleaving of statements (the Standard gets really fine-grained about "sequenced before", but you can think at the statement level for basic stuff). Each thread (which is furiously being optimized by the compiler and processor) observably behaves as if it's executing its own statements in order - i.e. traditional single-threaded behavior is preserved. So Thread 1 finishes filling `v` before it writes to `atom`. Thread 2 waits until it reads the special value from `atom` before reading/messing with `v`. And because the only communication between threads is done via the sequentially consistent atomic variable, the program as a whole behaves as if Thread 1 and Thread 2's statements are executed in some arbitrary interleaving. Because of the assignment and test, we've imposed a constraint that Thread 1's write to atom has to happen before Thread 2 reads the special value and finishes the spin loop. Therefore, Thread 1 has finished filling v before Thread 2 starts reading from it, and everything is guaranteed safe. The library/compiler/architecture has to work together to make this happen (and it's a horrible mess of interlocked instructions, compiler barriers, memory barriers, stores not being reordered on some architectures, blah blah blah). Magic. Now, as soon as you weaken the atomics to something less than SC, then you have to worry about apparently-insane reorderings. Don't do that.
&gt; As a specific example, it is common to have a replacement for vector that has a fixed size at compile time, ala boost::static_vector. That sounds exactly like `std::array&lt;T, N&gt;`. &gt; 1. The STL has poor debugging support, this is HUGELY IMPORTANT. VC's STL, at least, has ultra-helpful visualizers and debugging assertions that detect most forms of misuse. (Multithreading mischief is a notable exception.) &gt; std::queue is neither threadsafe `int` isn't "threadsafe". The STL provides The Usual Multithreading Guarantees, same as built-in types. Simultaneous reads of a single object are OK (i.e. reads are physically reads), simultaneous read/writes of different objects are OK (i.e. nothing shared/global). This is a very good thing. &gt; nor easy to use You push, you get the top, you pop. Easy. And yes, pop and top are intentionally separate. Why? Speed!
Well the first thing to note is that the standard does not care about caches. All implementation details are left to the hardware and compiler. An atomic write with `std::memory_order_release` does not allow *any* writes ("stores", when speaking atomically) to go past it (it guarantees all stores "happen-before" it, in standardese), even writes to completely different memory locations. The same applies to reads (or "loads") and `std::memory_order_acquire`, it guarantees *all* loads are sequenced after it. This is why an atomic spinlock can guard non-atomic variables. On a deeper hardware-specific level, meaning CPU architecture, the implementation varies and is unspecified by the standard. On the x86 platform in particular, loads and stores *always* have acquire and release semantics, so atomics are basically free outside of compiler reordering. And regarding caches in particular, most modern CPUs will use some variant of the MESI protocol to guarantee cache coherency. http://preshing.com has some very good articles regarding how acquire and release semantics work.
Yeah, but in most non-trivial applications of command-line parameters, you are going to be expecting a variable amount of them. This isn't an argument against named parameters, but argv parsing is probably not the best use case for them.
This video only made me realize I'm not smart enough, I keep using my mutexes and when they fail me i use some other lib some smarter person have created.
No, but only arguments that are either very convenient. Example: Splitter splitter(Orientation::Horizontal); // an enum
&gt; Not true. In order to introduce new interfaces, you have to a) write the interface class, and b) subclass that class. No. The interfaces that Sean Parent uses can be created once, provide meaningful defaults, and be extended by means of non-member non-friend functions only. You never need to change your type. You don't even need to change the interface, just provide a function that can be found by ADL. &gt;But if the public API doesn't change due a change in the protected and private API, then the functions that are public are not affected in the same way standalone functions are not affected. If the public API doesn't change non-member non-free functions are not affected _at all_, while you might need to update the implementation of the public functions. This is why non-member functions provide better encapsulation than public member-functions. If the public API changes, code calling the public API changes, while code calling non-member non-friend doesn't need to change if those non-member non-friend functions are updated. &gt;And clang is not available for windows as a binary installation. Clang binaries are available for windows. There is even an installer... - http://bit.ly/1og3PAB &gt;These are different things that what we are discussing. They do not allow to express a method call as a call to a standalone function. They just allow you to create functions that call the appropriate methods. That's different from what we are discussing. No. Given a class A already implemented and a free function foo(A), they allow you to write _anywhere_ in your code something like: // Extend A methods with free_function class A: foo() { foo(A); } A a; a.bar(); a.foo(); foo(a); They are more powerful tho, since they let you do way more things than just this.
This is a good example of API abuse for several reasons: * concatenation it is bad for debugging * why should ::movable return a pointer to the object? It is not self explaining
Maybe of interest here: Qt has compile time strings as well through QStringLiteral. You may want to have a look how it's implemented there.
(As Herb said in this video, his Atomic&lt;Weapons&gt; video is the best place for all this. I'm just passing on my (possibly incorrect) knowledge of that. He did present it very well though.) There is no guarantee that the publishing would happen 'soon'. The idea is that when threads, or other CPUs, see the value that was written to the atomic variable by thread X they will also see all the earlier writes by X (even those writes to non-atomic variables). i.e. there is a lot of reordering of reads and writes that is allowed, but atomic variables put restrictions on the reordering. And he also stressed that thinking of caching is not very helpful. Reordering, and delaying, can be done by the compiler, by the processor, and by the caches. But crucially all of them are entitled to perform *exactly* the same kinds of reordering and delaying. So you don't need a complex understanding of how these three things can effect your code. Just understand how the compiler can reorder is sufficient to understand this all.
Proxy types. For example, in std::vector&lt;bool&gt;: std::vector&lt;bool&gt; v{true, false, true}; auto p = v[0]; // p is a std::vector&lt;bool&gt;::reference proxy p = false; // reference::operator(..) &amp;; v[1] = true; // reference::operator(..) &amp;&amp;; assert(v[1] == true); // OK assert(v[0] == true); // FAIL! vector modified through p In this code snippet, p is not a value type, it is a reference type. That is, a user might think he is changing the value of a locally scoped bool, but he is inadvertently modifying the vector. The implementation of std::vector&lt;bool&gt;::reference _could_ (is not the case) define .. operator(...) &amp; = delete; // prevents the error above .. operator(...) &amp;&amp; {...} // this is what you want people to use .. operator(...) const&amp; {...} // this is ok too, since assigning to a const&amp; results in compiler error to prevent this (it doesn't). I've only used ref-qualifiers two or three times, but it was always tangentially related to preventing user errors in some APIs. They are not the most used language feature, but it is good to have it when you need it.
That paper is indeed brilliant. Many thanks.
&gt; it's possible to replace `atom = true;` with `atom.store(true, std::memory_order_release);` But later on, that same thread will want to read from `atom` to see if it is its turn to work again. So it should `acquire` it again at some point before attempting to read it? (I've already decided I'll never use non-standard memory orderings, at least not for a *loong* time. I enjoy talking about it here, and I'm happy to be told that certain blocks of code are correct, but I'll still avoid them for real. As recommended by Herb and STL, I won't use them for real until I have year's experience simply using atomics with the default ordering. Is the following true: If a single thread will write to a variable twice, without reading from it in between, the first write can *always* be `std::memory_order_release`? I just want to know if that is *always* safe before giving a moment's thought to the second write. 
`auto p = atomic_load(&amp;a);` There was a lot of discussion around the correctness of this line also, around 38m30s. Where `a` is a `shared_ptr`, there is a question about whether it will be copied correctly, and the internal reference count will be incremented. I don't think the discussion quite cleared it up. Can we say that `atomic_load` does a full copy construction internally, and therefore it's correct? There will already be (at least) one copy construction done inbetween the memory barriers surrounding `atomic_load`, and it will be copied atomically?
A simpler question is: You seem to imply (to my naive reading) that all `store`s can be done as `memory_order_release` instead of the more conservative default `memory_order_seq_cst`. But if that was true, then this would be the default in the standard. So that can't be true. Therefore, I would be interested in seeing an example of a store that should *not* be `memory_order_release`. If people can understand when store needs to full `memory_order_seq_cst`, then it might be easier to understand the isolated situations when `memory_order_release`.
Thanks for posting this. Haven't seen it anywhere else yet. Also from InformIT last week: [A Video Interview with Andrei Alexandrescu on the D Programming Language](http://www.informit.com/articles/article.aspx?p=2258260). 
Euh... I have a massive "no" for you there. Microsoft's compilers didn't change much since at least MSVC2005 with respect to construction of *global* (as opposed to local) statics, and that happens before main, or before your code hits your own DllMain (if DLL). This behaviour is so fundamental that way too much code would break if it changed over the years. You must have been a victim of the static initialization fiasco. Is it possible that your global statics were spawning some threads?
I generated the asm output for the fizzbuzz program and the only static string that appears in it is the final one. .asciz "1,2,fizz,4,buzz,fizz,7,8,fizz,buzz,11,fizz,13,14,fizzbuzz,16,17,fizz,19,buzz,fizz,22,23,fizz,buzz,26,fizz,28,29,fizzbuzz,31,32,fizz,34,buzz,fizz,37,38,fizz,buzz,41,fizz,43,44,fizzbuzz,46,47,fizz,49,buzz,fizz,52,53,fizz,buzz,56,fizz,58,59,fizzbuzz,61,62,fizz,64,buzz,fizz,67,68,fizz,buzz,71,fizz,73,74,fizzbuzz,76,77,fizz,79,buzz,fizz,82,83,fizz,buzz,86,fizz,88,89,fizzbuzz,91,92,fizz,94,buzz,fizz,97,98,fizz,buzz" So it would appear that it works as I'd expect, leaving only those bits that are actually used during runtime in the program. Intermediate steps are not kept.
http://stackoverflow.com/questions/5602112/when-to-overload-the-comma-operator Short answer: almost never Long answer: [Boost.Assign](http://www.boost.org/libs/assign/) and [Boost.Phoenix](http://www.boost.org/libs/phoenix/) 
The proposal doesn't override or suggest overriding the comma operator. It merely gives an example of using the comma operator for what it's usually used for - sequencing a series of expressions to be evaluated in turn.
[openFrameworks](http://www.openframeworks.cc) works on all platforms.
At least the Boost.Assign case appears to have been obsoleted by `std::initializer_list`.
Good to know. When I saw that overload, I wasn't sure what to make of the rest.
You claim to be a game developer but you dont know basics of thread safety... LOL at everybody who upvoted you. 
What a hack. I'd much rather see more general feature in next std revision (introspection) instead of this. It also looks like this is a good time to look into 'defaulting' things, and possible expose this to the user.
I love STL and the talk is really nice... but the suggestion for inner product to throw on length mismatch is a terrible terrible idea... I present evidence A: http://blogs.msdn.com/b/ericlippert/archive/2008/09/10/vexing-exceptions.aspx?PageIndex=2 (bonehead exception) 
I fear the syntax proposed here is going to be rejected for being too weird, despite not being much weirder than parameter pack syntax already.
The other alternative would be termination, which the Standard Library occasionally resorts to when bad things happen (e.g. a thread functor throwing). Haven't decided yet. Exceptions are for recovery, so there's no such thing as an exception that should never be caught. However, there is certainly such a thing as a scenario where an exception should never be thrown. People differ on whether logic errors are such a scenario.
Here's how it works. STL objects, like vectors, provide The Usual Multithreading Guarantees: simultaneous reads of a single object are OK (i.e. reads are physically reads), simultaneous read/writes of different objects are OK (i.e. nothing shared/global). A read is anything that can be done to a const object (excluding construction/destruction). For vector, these guarantees are achieved automatically, with no special code. shared_ptr *also* provides these guarantees, but it needs special code to do so. (Here, we're thinking about a shared_ptr object, not about what it points to.) You can copy from a const shared_ptr, so that's a read. But note that shared_ptr reads are *not* physically reads - they're incrementing the strong refcount. Then, note that simultaneously read/writing different shared_ptr objects may want to update the same refcount - obviously there is shared state. The solution to both is to use an atomic refcount - this restores the usual multithreading guarantees. However, this just gets shared_ptr to achieve the same status as vector. Simultaneously read/writing a *single* object, whether shared_ptr or vector, is still crashtrocity. If you want to simultaneously read/write a single vector, the Standard demands that you use external synchronization. It does provide helpers for shared_ptr, but they are problematic - atomic_load(), atomic_store(), etc. are overloaded for shared_ptr. If you want multiple threads to simultaneously read/write a single shared_ptr, the Standard demands that *all access* be done through these atomic_meow() functions. If even a single access is ordinary (like an ordinary copy construction), you're dead. Herb's proposal to make atomic&lt;shared_ptr&lt;T&gt;&gt; valid would get the type system to enforce this. But as long as you play by the current obnoxious rules, this is safe and correct. Note that it would be silly to have your whole scenario be two threads simultaneously atomic_load()ing a shared_ptr (since ordinary copies already make that safe). So let's say the scenario is three threads, two of which want to atomic_load() and one which wants to atomic_store(). They all want to do this simultaneously. First, the atomic functions guarantee that the threads don't step on each other, and they execute in some unspecified total order (yay SC). Let's say that the order is load, store, load. The first thread doesn't quite stop the world, but it does need to prevent the other atomic_store() and atomic_load() from happening (implementations use a spinlock). First it reads the shared_ptr's data members (there are 2 raw pointers: pointer to owned object, pointer to refcount control block), so it can copy them and make a second shared_ptr object. Then it needs to update the refcount in the control block, which it does. It might be tempting to say "oh, this can be an ordinary increment", but remember that the Standard only requires that all access to *this shared_ptr object* be done with atomic_meow(). Other shared_ptr objects that share ownership can be accessed normally, so other threads might be furiously incrementing and decrementing the shared refcount. Therefore we need an atomic increment (as usual) of the refcount. Then the first thread is done, so we release the spinlock. Now the second thread steps in and grabs the (hidden) spinlock. It's time for atomic_store(), so we need to decrement the refcount (again atomically, there could be other threads messing with it), then we copy the source's two data members (this is why we need the spinlock), then we increment the source's refcount (again atomically). Then we're done. Then the third thread does its atomic_load(), same as the first. So yes, the thing gets copied correctly and the refcount is incremented.
i disagree, IMAO it is clear "assert thing". are you gonna throw when sort comparator does not satisfy strict weak ordering, are you gonna throw when binary_search range is not sorted...? exceptions are not for recovering from bugs in the code. 
Well, it is sorta weird and a bit inconsistent with established rules for param packs, namely what '...' being on the right vs. left mean. I also wonder why it shouldn't instead be implemented as a library extension. I suppose it explicitly avoids the recursive function definitions, but it seems like a silly implementation indeed that doesn't just inline them. So I'd think this would be better: template &lt; typename ... Pack &gt; auto sum(Pack ... pack) { return std::foldl(plus&lt;&gt;(), pack...); // or return std::foldr(plus&lt;&gt;(), pack...); }
You're confusing function local statics and globals. Function level statics are initialized on first use, like you describe. Globals are initialized before main.
acq_rel applies to increments and decrements. In VS14, shared_ptr uses relaxed increments and acq_rel decrements, because the decrements are used for communication.
I don't yet know how to use double-wide atomics (which are non-Standard) to implement shared_ptr's atomic operations lock-free. Perhaps someday.
Hi, I'm the author of the proposal. The document proposes a compromise. The explicit notation does not change the meaning of the existing code, is easy to explain and easy to use. The implementation is also very simple (in the Clang/LLVM world). Yet it is still a compromise. This should have been in the Core language from the beginning... but alas. (please see Stepanov's lectures for the details on equality, copying, assignment and regular types)
&gt; The standard says this can happen any time before the first use, just like function-local statics. In MSVC, GCC, TurboC (yeah, I'm *that old* 😉), xlC, *dynamic* initialization was happening before main throughout various versions (I obviously don't know about *all* versions, but know about GCC 3.4, 4.7, MSVC 2005/2010/2012, xlC 10). Standard perhaps is silent as to when initialization will happen, but implementations are more constrained than that. For example, implementations support threading. On-first-use dynamic initialization with threading would largely be asking for trouble, I would think. I am sorry, but you really should better accept that you don't know what was happening with your code then, than suggesting what you are suggesting now. The effect you were seeing, "it works, then it starts crashing again" is better explained by static initialization fiasco and the change in the compilation unit order during compilation (you presume one order, which works, then for some reason, which indeed is implementation-depended, that order changes). Finally, note that if MSVC '10 indeed did on-demand in it of global statics, you could easily make that evident right now with a test program, and you could have asked MS support for explanation at the time.
Yes, I was not talking about immediates: When you generate two different strings in this way that happen to have the same final contents, the compiler will need to store them separately because the two arrays are different objects and therefore need different memory addresses. What this boils down to is: constexpr char a[] = "Hello World"; constexpr char b[] = "Hello World"; assert(&amp;a != &amp;b); // true This is different from string literals where the compiler is free too (an generally will) merge literals that contain the same data: assert("Hello World" != "Hello World"); // generally not true What I was wondering was if there is some attribute `[[shared_storage]]` (either for the type or for the variables) so that constexpr char a[] [[shared_storage]] = "Hello World"; constexpr char b[] [[shared_storage]] = "Hello World"; assert(&amp;a != &amp;b); // can be false Maybe an ideal compiler would be able to see that no use actually depends on the two objects having different addresses and still be able to merge them. However, even that is likely to break down once you pass the string (addresses) to library calls. This is of course not likely to be a big problem for any real use, but is a "regression" from plain string literals that would be nice to solve.
I don't understand what you are trying to do. Why can't you use a base class that notifies on instantiation, and derive the classes you need to "listen to" from that? It would work with normal heap- and stackallocation, and for PODs you could write a wrapper. 
Actually, its not compliant with any C++ as you are using identifiers you are not allowed to.
Which of these checks won't be found by other code sanitizing software?
In your final paragraph, you discuss the situation I was referring to. So, let's restate a clearer version of my original question. I don't necessarily need to fully understand all the differences between `memory_order_acq_rel` and `memory_order_seq_cst`, but perhaps if I had a conservative underestimate of the guarantees provided by `memory_order_acq_rel`, then it might help. - Thread X writes value `1` to atomic `m`. - Thread X later in its source code writes value `2` to value `m`. *Same* writing thread, *same* target variable. The scenario I want to avoid is: - Consumer thread Y reads value `2` from atomic `m`. - Thread Y later in source code reads value `1` from atomic `m`. Same thread, sees this single variable in the 'wrong' order. This is a kinda crazy scenario. If a thread makes two writes to the same atomic, no individual consumer should think the latter write happened before the former write. In my opinion. I hope/assume `memory_order_acq_rel` on both writes (or just the first?) is sufficient for this. I accept that things might get more complicated with multiple variables and multiple threads. I'm less interested in identifying what can go wrong, but in identifying at least one simple rule that can't go wrong. (Thanks for your patience, no worries if you don't reply. I'm still sticking with a strong preference for full `memory_order_seq_cst`, if/when I start writing this kind of code for real.)
&gt; Well, the good news is atomic_load has an explicit specialization for shared_ptrs that is guaranteed to do the right thing. I kinda think that's bad news actually. Special support for shared_ptr means that other classes, such as those I write myself, are *not* supported. I would like a guarantee that, no matter what type is involved, an `atomic_load` will *atomically* complete the full copy constructor as an integral part of the atomic operation. If that isn't 100% guaranteed for all types, then that's OK. I'll just make sure I'm not relying on copy constructors. And I'll (somewhat reluctantly) remember that `shared_ptr` has some magic support in the standard. (Remember, `atomic_load` returns `T` by value. Therefore, there is at least one copy construction that happens before `atomic_load` returns. This is why I'm still hoping somebody can confirm that this support for copy constructors is not limited to shared_ptr)
I must admit being slightly concerned with the "default" values for empty parameters pack. Instead, I would argue that an empty left folding expression (resp. right) should "swallow" the binary operator immediately preceding it (resp. following it), and that if there is none or if it is different from the one used in the folding expression then the program is ill-formed. Thus, for example: `0 + args + ...` would, for an empty pack, expand to `0` and similarly a `... + args + NullMatrix` would, for an empty pack, expand to `NullMatrix`. Simple and explicit. My immediate worry otherwise is that some programs will produce potentially hard to diagnose errors: template &lt;typename... Matrices&gt; auto add(Matrices&amp;&amp;... matrices) { return matrices + ...; } That the above snippet will produce a result of type `int` and value `0` when invoked with an empty list of matrices certainly violates the Principle of Least Astonishment.
Excellent. So yes, copy construction does happen atomically as part of the "read". But that's not always good enough, e.g. with shared_ptr. Because the atomicity refers only to the single shared_ptr, and not to the control block can be accessed by multiple different shared_ptr s I can also see how multiple shared_ptr can refer to the same logical data. (By definition, that's the point of shared_ptr!). And therefore atomic_load only guarantees atomicity with regard to the individual shared_ptr, and some care needs to be taken by shared_ptr itself to make sure this works correctly. (Slight change of subject for the remainder of this comment:) But I wonder do we need multithreading to break an incorrect implementation of shared_ptr? Is there a single-threaded way to break things? Imagine my code is in the middle of copying a `broken_shared_ptr` by doing a read-increment-write (without locking) on the ref count. Then imagine a system interrupt of some sort (Ctrl-C by the user) interrupts just after the read. The interrupt handler might, among other things, make another copy and increment the refcount. When the interrupt handler completes and execution returns, it will then increment and write using an out-of-date refcount. Does the standard say anything about this? I guess I'm saying that we can have reentrant code even with single-threaded applications. Is there a simple example of how a single-threaded program can cause some of the problems that are nowadays associated primarily with multithreading?
There's actually a bit more going on in the project I mentioned, but essentially, I needed to write it so that the class itself knew when it had been fully constructed.
\_\_InstantiationNotifier__ and \_\_NOTIFIER__.
Ah, forgot about those. Ideally, that class and variable would be completely hidden from the developer, but unfortunately, I don't see any way to separate the implementation here. In any event, you're right. Thanks for pointing that out. 
If it's just development speed you are going for, I can recommend using some macros. If you are not familiar with them, they will seem confusing and unreadable at first, but after getting used I actually prefer them over typing out everything. In particular, I use [macros](http://pastebin.com/VBgXtpQ8) for defining properties (i.e. getter &amp; setter) and comparison operators. For example, something like class Foo { public: PROP_VAL_RW(int, X) PROP_VAL_RW(int, Y) ECOP_ALL(Foo, prop_X, prop_Y) }; would be expanded to http://pastebin.com/SmKWjS90 I know it's not pretty but until proposals like yours are taken into the standard (if ever) I think macros are a fine compromise.
The performance issue of std containers in games is mostly BS. There are of course areas where one wants total control over the memory layout in order to maximize cache performance etc, but that is not the majority of the code. The majority of the code, is and always has been, the same as all other programming domains; not performance critical. But the bits that are, one *may* need to avoid std containers and algorithms. This is the great thing about C++, one can move between the very high level and the very low level in the same code base. In my experience, the result is usually an all out ban on the standard library, and in my opinion it's horribly misguided. 
If the only thing you want is to save some typing, couldn't you use snippets for that? Could accomplish the same as the macros without all their downsides.
I had a look at it, and it turns out to be possible: [here](http://aherrmann.github.io/programming/2014/10/19/type-erasure-with-merged-concepts/). Note that the mutability issue you're describing comes from the value semantics. I think it would absolutely be possible to write a type-erasure container with reference semantics. Replace the `shared_ptr&lt;const Model&gt;` by `unique_ptr&lt;Model&gt;`, and add all the necessary ctor, and assignment fluff.
I wondered if by writing that concept_compose line someone would go off and do it. Then I could use it! :) +1
&gt; The scenario I want to avoid is: Perhaps surprisingly, atomics always guarantee that this can't happen. Even if the stores and loads are performed with memory_order_relaxed, the weakest memory_order that permits the craziest reorderings, it still can't happen. The Standardese is N4140 1.10 [intro.multithread]/8: "All modifications to a particular atomic object M occur in some particular total order, called the modification order of M. If A and B are modifications of an atomic object M and A happens before (as defined below) B, then A shall precede B in the modification order of M, which is defined below. [ Note: This states that the modification orders must respect the “happens before” relationship. -end note ] [ Note: There is a separate order for each atomic object. There is no requirement that these can be combined into a single total order for all objects. In general this will be impossible since different threads may observe modifications to different objects in inconsistent orders. -end note ]" In somewhat more intelligible English, this says that (regardless of memory_order) each atomic variable, *considered in isolation*, has a linear history of updates. Multiple threads can't observe an inconsistent history for a single atomic variable. The crazy reorderings come into play when you start asking about the histories of multiple atomic variables, or you start using atomic variables to protect accesses to ordinary variables. &gt; I hope/assume memory_order_acq_rel on both writes I know what you mean, but you can't give memory_order_acq_rel to store() (VC will trigger a debug assert helpfully telling you so). You give memory_order_release to store(), and memory_order_acquire to load(). The way to remember it is, when using an atomic flag to protect some ordinary variable, storing "it's the other thread's turn" to the flag is *releasing* ownership of the ordinary variable, while loading "hey it's your turn" from the flag is *acquiring* ownership of the ordinary variable. memory_order_acq_rel is used for operations that are both reads and writes, like increments and decrements. This is a lesson that I learned very expensively a year or two ago. shared_ptr's decrement is used for communication: multiple threads are simultaneously decrementing the refcount, and looking at the updated value. For the threads decrementing the refcount to something above zero, they're writing to the refcount, so they need to use release order - earlier they could have been doing things like reading the owned object, so they need to release ownership of the owned object. (Otherwise the reads of the owned object could flow below the decrement, as observed by other threads.) For the thread decrementing the refcount to zero, they're reading zero from the refcount afterwards, so it needs to use acquire order - it's about to do nasty things to the object (and usually the control block itself) like destroying it, so it can't allow any of those writes to an ordinary variable to flow above the decrement (as observed by other threads). The decrement, a single operation in the source code, "communicates with itself", so it must be acq_rel.
atomic&lt;T&gt; works for user-defined types if they're trivially copyable (you can think of this as Plain Old Data that can be memcpy'ed; the Standardese is more precise). If your UDT is the same size as an integer (1/2/4/8 bytes), the STL will use the special lock-free atomic operations for it (not guaranteed, but everyone will). Larger UDTs will be protected by spinlocks.
Oh. That's interesting, especially with respect to `shared_ptr`. So, `shared_ptr` isn't formally trivially copyable. Therefore it shouldn't really work with atomics. *But* it is very very *close* to being trivially copyable. When a `shared_ptr` is copied, the raw pointers in the `shared_ptr` are memcpy'd unchanged. The copy constructor doesn't change anything but it does *follow* the pointers and do stuff at the memory location pointed to by the pointers. So one can almost imagine that the memcopy of the raw data is performed as the atomic operation, and that any follow up work (the full constructor) actually happens *after* the atomic operation. The real copy constructor will need to start more atomic operations or lock-taking, but from the hardware's point of view they are two seperate atomic operations. First, the hardware sees an `atomic_load` of the raw data in the `shared_ptr` and then, shortly afterwards, at another point in memory it sees a mutex (or something equivalent) being used to increment an integer. Correct? (Thanks!)
That's really helpful. Thanks! The link you sent earlier about IRIW was helpful too. `memory_order_relaxed` reminds me of Einstein's Special Relativity. There is no single true timeline, different observers can see the same events in a different order. But that doesn't mean that anything can happen. There is still some sanity required - you can't see somebody dying before you see them being born. Full sequential consistency is more like Newtonian mechanics, there is a single clock and a single "official" ordering of all events.
That is a surprisingly accurate analogy.
Maybe a better version of my question is as follows: I understand that `shared_ptr` has to be special in some way for atomics to work as expected, and now I understand why. But what form does that special treatment take? Is it that there is a specialization of atomic_load, because the normal atomic_load requires trivially copyable objects: template&lt; class T &gt; shared_ptr&lt;T&gt; atomic_load( const std::atomic&lt;shared_ptr&lt;T&gt;&gt;* obj ); More concretely, if I had my own implementation called `my_shared_ptr` (which already provided the normal multithreading guaranteed, and incremented the ref counter safely) what would I need to do to make it work correctly? Just provide the above specialization? If I had other types that weren't trivially copyable, am I allowed/expected to make such specializations in such situations where I am able to do it correctly?
* shared_ptr isn't special. atomic&lt;T&gt; requires T to be trivially copyable, and shared_ptr isn't trivially copyable, so atomic&lt;shared_ptr&lt;U&gt;&gt; is forbidden. * There's no such thing as a partial specialization of a function template. If you think you're looking at one, it's actually an overload. * The specialness is that atomic_load() has been overloaded for shared_ptr, with a handwritten implementation. Herb was the first to realize that this is a terrible design - these overloads should be eradicated, and instead we should get a handwritten partial specialization of the class template atomic&lt;shared_ptr&lt;U&gt;&gt;, so that the type system enforces correctness. &gt; what would I need to do to make it work correctly? Just provide the above specialization? Following the Standard's current design, you would need to provide overloads of atomic_load()/etc. but that's a terrible design. Instead you could partially specialize atomic (which is allowed, as long as you uphold the Standard's guarantees). Either way you need handwritten magic. If you can't do it lock-free, there's no real point to doing this. shared_ptr is an exception because it's such a fundamental vocabulary type.
Hehe. Yes, you successfully nerd-sniped me. =) I hope it turns out to be useful.
&gt; Nice post, thanks for sharing your examples. Thanks for reading it. =) &gt; [...] why I'd want to do this over a template [...] Some points are made at [12:08](http://www.youtube.com/watch?v=0I0FD3N5cgM&amp;t=12m8s) in the first talk. Another good motivation are containers. If you want to store things in a container (e.g. `std::vector`) then they need to have the same type. Templates won't work in such a scenario. With type-erasure the issue goes away. See [this example](https://github.com/aherrmann/rubber_types/blob/master/examples/drawable.cpp).
Thanks. And wow, I didn't expect this to land on hackernews. &gt; I'm actually working on something similar at the moment. I'd be curious to hear more. One other thing I've been wondering about is what influence this has on performance. The merging of concepts generates a lot of inheritance, parts of it virtual. I don't know if that adds additional cost compared to a "monolithic" type-erasure class.
I couldn't help but wonder why anyone should bother with all the boilerplate you were proposing when the examples you provided are trivially solved with a templated function in C++11 and auto function parameters in C++14. Plus that solution benefits from inlining and is more efficient as there's no hidden dynamic dispatch involved. I see you mention containers, but I don't find this compelling. Anything in a container will in practice have an is-a relationship with everything else in the container and thus could be solved with normal C++ polymorphism. I've never found a practical case where I've wanted to store completely disparate types in the same container... why is this a problem anyone wants to solve?
What Scott Meyers calls "universal references" and Herb Sutter now calls "forwarding references" are powered by what I call the "template argument deduction tweak", followed by what the Standard calls "reference collapsing". (Anyone who says that it's just reference collapsing is wrong.) Given `template &lt;typename T&gt; meow(T&amp;&amp; t)`, `string lvalue("purr");`, and `string rvalue() { return "hiss"; }`, let's examine what happens for: `meow(lvalue)` is called. Template argument deduction notices the universal/forwarding reference pattern (`T&amp;&amp;`, where `T` is a template parameter belonging to the function template itself; nothing else fits the pattern), so the tweak is activated when the argument is an lvalue. `T` is deduced to be `string&amp;` (without the tweak, template argument deduction never deduces types to be references). Then, the compiler needs to substitute this deduced `T` into `T&amp;&amp;` to get the function parameter's type. For a split second, `string&amp; &amp;&amp;` is formed, but C++ doesn't permit references to references, so reference collapsing activates. The rule is that "lvalue references are infectious", so this collapses to `string&amp;`. Therefore the function parameter is `string&amp; t`. Given the call `meow(rvalue())`, the argument expression is an rvalue, so the template argument deduction tweak doesn't activate (it's only for lvalues plus the perfect forwarding pattern). So `T` is deduced to be `string`, that's substituted into `T&amp;&amp;` to get `string&amp;&amp;`, and the function parameter is `string&amp;&amp; t`. Reference collapsing also activates when you try to form references to references via typedefs; you can play around with it that way and see what happens.
the problem this solves cannot be trivially solved with a templated function [...] nor by inheritance based polymorphism. watch this: http://channel9.msdn.com/Events/GoingNative/2013/Inheritance-Is-The-Base-Class-of-Evil 
The first rule of _ITERATOR_DEBUG_LEVEL is: **don't mess with it**. The second rule of _ITERATOR_DEBUG_LEVEL is: don't mess with it **yet**. When you mess with IDL, you've subverting C++'s assumption that every part of a program agrees on the representations of objects. It can be done safely (see note), but it requires a bunch of knowledge and attention to detail. If you have to be told what to look out for, you shouldn't be doing it. Note: this stuff is tricky enough that we've had trouble supporting it in the implementation (due to the 2 DLL thing, as I mentioned). All of VC8 RTM, VC8 SP1, VC9 RTM, and VC9 SP1 were screwed up in different ways wrt IDL (starting with, oh, container swap being broken). In my first full release cycle, VC10, I managed to eradicate the worst of the problems, but a few remained elusive. I fixed the /clr IDL customization issue in VC12 (2013), which took me a while to understand - the actual problem was an instantiation of std::string sneaking into the import lib. There was another problem with _Container_base12 being separately compiled, an artifact of the pre-VC10 era that I missed overhauling. That's been fixed in VC14 (*not being released this year*), and I think we're finally done with IDL headaches. I hope. Seriously, don't mess with the default settings, unless it's absolutely necessary. Non-optimized release really is debuggable. If something seems to be wrong, it's almost certainly because something is sneaking through a complicated IDE/build system.
Awesome explanation. I like the idea of testing it and learning through typedefs, and I can evaluate the type instantly with intellisense. I have seen a few of your channel 9 videos and you are always really good at breaking down complex topics to be easy to understand. Much appreciated.
&gt;While I still can’t pinpoint the root cause, even when compiling release builds with /Od (optimizations disabled) the debugging experience is severely crippled. (and yes, of course I raised the proper PDB generation switches in both the compiler and the linker). You didn't build everything without optimizations then. Obviously, you can't build CRT, but all those STL templates, yes. VC 2012 has magic 😉 switch to improve optimized build debugging experience, not documented yet, and I didn't try it, but might help.
Nice post. I believe type erasure is one of those relatively simple ideas which are currently overly complicated to realize in C++. Just FYI, I am (slowly, but steadily) working on a proposal to add language support for type erasure to C++ in the form of what I call "virtual concepts". A preliminary draft including introduction, motivation, design goals, and some example is available here: http://bit.ly/1CSmFRl. I've created a GitHub repo with code examples for existing library solutions here: https://github.com/andyprowl/virtual-concepts. There is also a discussion thread on std-proposals: https://groups.google.com/a/isocpp.org/forum/#!topic/std-proposals/4gEt2OBbSQM. Any kind of feedback ("I like it", "It sucks", whatever) would be very welcome.
There's also the uniform call syntax from D: http://dlang.org/function.html#pseudo-member
&gt; the "template argument deduction tweak" Interesting, it seems that this means that in the following, `T` will be deduced differently for `x` and `y`. template&lt;typename T&gt; void foo(T&amp;&amp; x, T y) { } int main() { int x; foo(x,x); return 0; } And indeed it is, and so it doesn't compile: http://ideone.com/yDqnqU
Until the proposals get accepted, you could write the function as a [`pipable`](http://pfultz2.github.io/Fit/doc/html/pipable/). Which you could define the functions like this: struct where_f { template&lt;typename T, typename UnaryPredicate&gt; std::vector&lt;T&gt; operator()(std::vector&lt;T&gt; const &amp; c, UnaryPredicate predicate) const { std::vector&lt;T&gt; v; std::copy_if(std::begin(c), std::end(c), std::back_inserter(v), predicate); return v; } }; constexpr const pipable_adaptor&lt;where_f&gt; where = {}; struct select_f { template &lt;typename T, typename F, typename R = typename std::result_of&lt;F(T)&gt;::type&gt; std::vector&lt;R&gt; operator()(std::vector&lt;T&gt; const &amp; c, F s) const { std::vector&lt;R&gt; v; std::transform(std::begin(c), std::end(c), std::back_inserter(v), s); return v; } }; constexpr const pipable_adaptor&lt;select_f&gt; select = {}; struct sum_f { template&lt;typename T&gt; T operator()(std::vector&lt;T&gt; const &amp; c) const { return std::accumulate(std::begin(c), std::end(c), 0); } }; constexpr const pipable_adaptor&lt;sum_f&gt; sum = {}; And then use them like this: auto s = v | where([](int e){return e % 2 == 0; }) | select([](int e){return e*e; }) | sum(); This blog post [here](http://pfultz2.com/blog/2014/09/05/pipable-functions/) shows how to write a simple pipable adaptor for functions in C++14. Of course, having actual extension methods would be much better.
Can't do "break" and "continue" with those though.
That's a good point.
What would be especially cool with this is to add methods to primitive types
Note that while the tweak applies to only the perfect forwarding pattern, template argument deduction for lvalue references also differs from template argument deduction for values. Try `(T&amp; a, T b)` called with `const int c = 0;`.
Template metaprogramming is what comes to mind for me. As far as what it works on, your example sounds consistent. b.f() would be f(Base&amp;), as would bp-&gt;f(), since bp-&gt;f() is equivalent to (*bp).f(). bp.f() is more interesting, and that would be an example of why I would want this functionality. There are many times when I'm doing template programming only to hit a special case where I then have to change all the calls in the template of some member function from foo.bar() to barAdapter(foo) and some enable_if to handle my special case. If instead these two were equivalent, I could just define a free function to handle my special case and not have to deal with all the SFINAE shenanigans.
Obviously if it's making your program entirely unusable you'll have to turn off iterator debugging, but it's something that's caught enough issues for me that I'm quite willing to put up with the speed hit normally.
[YES!](http://media2.giphy.com/media/aurUBBayxC55m/giphy.gif) *the endophile*
I now have done a side-by-side comparison. Basically what was changed is that instead of an `export` section you can now apply `export` directly on each declaration you want to export. Also the module declaration does not have to be the first thing in a module file. Here's the list of changes I noted: diagram added to 3.2 removed from 4.1 &gt; In principle, this declaration could be allowed to appear anywhere at top-level. However, for simplicity we require it be the first declaration in any translation unit defining a module unit. Therefore we arrive at the first rule: The above is replaced with: &gt; For simplicity, there can be at most one module declaration per translation unit. In a previous design, we required the module declaration to be the first declaration in a module unit; that requirement wasn’t necessary (as acknowledged at the time). To support gradual transition from the current compilation model to a world with module we allow toplevel declarations to preceed the module declaration in a module unit. Such declarations do not belong to the nominated module. They belong to the global module. Removed from "Rule 1": &gt; , and any such declaration must come first 4.2.1 The syntax changed from `export { toplevel-declaration-seq }` to `export toplevel-declaration`. Removed "The braces in this context do not introduce a scope, they are used only for grouping purposes." Removed from "Rule 2" "The (group of) exported declarations of a module unit shall follow its module-name declaration." 'Note' changed to refer to the export keyword instead of using "in the interface section" 4.2.2: "Rule 3" and "Note:" deleted. Added examples and the text: &gt; In the example above, modules Alfa and Bravo contributes structure S1 to the global namespace. Both of them define their own structures S2 and S3. Despite both Alfa and Bravo defining structure S2, it is possible for another module to import from Alfa and Bravo. 4.2.3: "Rule 4" renamed "Rule 3" 4.3 Removed "or inside an export declaration" 4.8 Typos added. The text: &gt; All exported symbols belong to the namespace in which they are declared. is replaced with: &gt; All expimport declaration. All exported symbols belong to the namespace inorted symbols belong to the namespace in which they are declared. The example parsing.cxx changed to use the new export syntax (no braces). A Standardese: The grammar is simplified.
One thing I haven't seen mentioned so far is how it will work with namespaces. I can see examples like this: char c = 'a'; //bool lower = islower(c); bool lower = c.islower(); (I assume the fact that `islower` takes an `int` is not an issue. Actually, won't having to take all possible type conversions into account slow down autocomplete?) But often I see this: bool lower = std::islower(c); What then? Namespaces can't be ignored because collisions. `c.std::islower()` is a bit ugly. `using namespace std;` is not an option. Could it be possible to move standard library code to inline namespaces? If I get them correctly, this wouldn't break existing code and allow using only parts of the library.
&gt; Can someone give me a great reason why this is needed in C++? I've always believed Extension methods in C# exist to alleviate the problem brought on by requiring all functions exist inside of a class. The problem is when you start to nest a lot of free functions it becomes difficult to write and read. He was giving an example of this in his blog post.
There is this Linq library [here](https://github.com/pfultz2/Linq). It does lazy evaluation for its operations.
&gt; Actually, won't having to take all possible type conversions into account slow down autocomplete? I don't like it as well. It will be a big problem.
Well, it is a constant expression but since the result of c_str is a reference to a non-static class member it must be this latter part that makes it not work. That's an unfortunate exclusion. I wonder why.
If `c.islower()` were to be equivalent to `islower(c)` then I assume the standard ADL would apply. So here since `c` has no namespace it wouldn't find it unless you do a `using std::islower`. This is not unlike the situation is now. If you use `sort` in a generic scope for example you really want to say `using std::sort` and then later call `sort` rather than calling `std::sort`. The reason being is that you want to call the right sort function and that may be in the namespace of the class you call it on.
Took me a while to realise that wasn't a sad face..
Yea, I was just following what was in the blog.
Shouldn't the talk title have been "You Won't Believe What the Committee Did Next "?
Obligatory boost hint: noncopyable 😉
That's great when the class should never be copied, but sometimes a class needs to be copy-able, or at least makes sense to be copy-able, but you just don't want it to be copied accidentally when it could have been moved.
Not my idea, but you can use boost::counting_range to do this. E.g. the following prints "0 1 2": int main() { std::vector&lt;int&gt; v{0, 1, 2}; for(const auto it : boost::counting_range(v)) { std::cout &lt;&lt; *it &lt;&lt; std::endl; } } 
&gt; If public API changes, non-member non-friend might need to change. If public API doesn't change, non-member non-friend do not need to change. Exactly. So it has nothing to do with 'better encapsulation'. &gt; Someone just wrote a review of this paper comparing it with extension methods in C#: Again, the C# thing is different from the C++ proposal: in C#, it is a deliberate design decision to add 'this' to a function so as that it becomes part of the public API of a class, in C++ it is not: any function can be invoked as a method. 
&gt;If public API changes, non-member non-friend might need to change. &gt;If public API doesn't change, non-member non-friend do not need to change. If the protected/private API changes without a change in the public API, non-member non-friend do not need to change, while the implementation of the public API might have to. Hence, better encapsulation.
It can't handle multiple yield statements like that, but I can imagine a slightly different syntax that would achieve the same end. It will always be more limited than full closures, though.
Again, your logic is faulty. You are comparing apples and oranges. I am going to put it differently so that you might understand it: suppose those non-member non-friend functions were member functions with the exact same code. Would a change in the protected/private API affect those? no. So there is not 'better encapsulation', it is just a logical fallacy. 
Making the copy constructor explicit can also help to prevent accidental copies.
What will be the effect on bad code that erroneously puts overloads in namespace std? I notice that the function object is placed within an anonymous namespace within namespace std; is that just for ODR?
"12 things you won't believe the committee did next"
Would that code break if Niebler's technique was adopted?
Pretty sure this disables RVO.
If the grammar in your post is any indication of the quality of your project, I think most people will pass on this.
The following answer uses overloading instead of specialization.
At least, you should give a general idea of the project if you want people to invest some time.
&gt; And then use them like this: &gt; auto s = v | where([](int e){return e % 2 == 0; }) &gt; | select([](int e){return e*e; }) &gt; | sum(); &gt; I really dislike overloading operators with different behavior than the standard one. This code is confusing as hell until you dig into the guts of implementation... 
In the update, isn't he saying how specializing has its problems too?
This.
As others have observed, Howard specifically addresses this in his updated answer on the page you link. The trouble is that, although you can fully specialize a function template, you can't partially specialize one. So if your type happens to be a template, there's no conforming way to put your `swap` in the `std` namespace.
Yes. To be clear, I'm not suggesting that the definition of swap or begin should be changed in this version of the standard. We can use this pattern for future customization points though. And there may be a time when breaking changes to the standard is allowed. I'm thinking in particular of what happens when we get concepts. It's clear were going to need a way to ship another version of the standard library side-by-side with the current one.
Since it's an open source project, I think you could give more details about it, probably would help to find people who are interested. And other thing: do you guys need someone to go work in Norway, or can people work from anywhere in the world? 
Doesn't really matter, though. It forces an explicit call to std::move which is all RVO does anyways, basically.
Good point. I guess when it comes down to it, this is just offering an alternate syntax for the explicit copy which can be useful if the class has an unwieldy name. 
It would be nice if all the standard customization would be prefixed with `std_`so then the fully qualified `std::swap` could be used easily. Plus it doesn't have to invade the global namespace as much with functions such as `swap`, which could have strange side effects. I do remember boost range library used `range_begin` as its customization point so that `boost::begin` can be used fully qualified. I usually tell new prorgrammers to use `boost::begin`, since I find trying to use `std::begin` to be more complicated to use correctly. I like your idea, I think it can help simplify using things like `std::begin` and `std::swap`.
Interesting point. With the anonymous namespace, it's not a hard error to put an overload of `begin` in the `std` namespace (although the standard forbids it). But without the anonymous namespace, bad code like that causes a hard error. ~~The anonymous namespace is for ODR purposes, but that might be in angels-dancing-on-the-head-of-a-pin territory. It might not make any difference in any practical code.~~ EDIT: I'm mistaken. The anonymous namespace wrapping the definition of `std::begin` is to prevent `begin` from being multiply defined in different translation units. Without the anonymous namespace, you get linker errors. 
It does not. Copy-elision can occur if the copy OR move constructor would be called and the move constructor is still accessible.
It doesn't force an explicit call to std::move(); the return value is always an rvalue. And this is not what RVO does; it entirely elides the copy/move construction and existed before move semantics were a thing.
&gt; Unity builds in C/C++ – combining source files into one file to reduce file access Ugh.
Ah, there you go. I figured someone else must have done the same thing at some point. Thanks for bringing this to my attention.
I already used this pattern few times in my code, only difference is sink takes object by r-ref: void sink(MyClass&amp;&amp;); 
I see. I read a little more about the topic and came across [this](http://www.gotw.ca/publications/mill17.htm) article. What do you think of the suggestion mentioned in Moral #2 (forward the function call to a static method in a templated class, which in turn can be partially specialized)? Because if I understand you correct, you rely on Koenig Lookup, which might not be straight forward (for example what about multiple argument types from different namespaces?)
Was literally just coming here to post this one. Definitely one of the more entertaining talks.
Moving and return value optimizations are quite different. Return value optimizations mean that the object is constructed directly in its final destination location (i.e. in the caller's specified location), so there is no move or copy to perform. That means that even if you have written a move or copy operator/ctor, they won't be called. That's significant: it means there are observable differences, and this is not under the usual umbrella of "any optimization is allowed as long as the observable behavior is identical." This optimization requires special dispensation from the standard.
&gt; for example what about multiple argument types from different namespaces? Yeah, what about that? What if we took the recommendation in Moral #2 from that article: We write our `foo` function such that it internally dispatches to some `FooImpl&lt;X,Y,Z&gt;::call(x, y, z)` static member function, and we tell people to (partially?) specialize `FooImpl` for their type(s). How do you specialize a template that takes three parameters? Do you fully specialize it? Partially? On which arguments? How many specialization do you need? Are your specializations ambiguous amongst themselves? Amongst other specializations in third party libraries? It's tricky and awkward. The rules of function overload resolution and partial function ordering are famously difficult to grok, but by and large people don't need to grok them because most of the time, they *Just Work*. In comparison, class template specialization is verbose and fiddly. (Incidentally, I'm told Andy Koenig doesn't like it when people call ADL "Koenig Lookup". I can't blame him.)
&gt;(Incidentally, I'm told Andy Koenig doesn't like it when people call ADL "Koenig Lookup". I can't blame him.) I learned the concept and name from Danny Kalevs book. I wasn't aware. Personally I favor template specialization over cross-namespace overloading, but I can see why some would disagree. Yes it is awkward to write. But from code reading perspective it makes more sense if you don't know the exact library implementation and how ADL works. What I mean by that is if you just look at the 9 lines of your "namespace NS" example most readers would not assume that the supplied swap function will be called, because the code explicitly states std::.
I think you are being too soft on them... :) Unless there's a very strict adherence to the #include's order and macros, most often than not it will end up with incorrect code being generated.
Well yes, but I guess I consider a construct and move to be functionally equivalent to a construct in place for nearly any movable type, at least in terms of time.
Right
Does non-profit mean, non-paid?
What are the more cache-friendly alternatives to `std::map`? Chandler mentioned a Google sparse map implementation; is that hiding around somewhere? Or what else is out there?
Matt Austern (another Google employee) has a nice write up of why to avoid std::map and some alternatives: http://lafstern.org/matt/col1.pdf It essentially boils down to your use case. Frequently, a sorted std::vector is more than sufficient (and for more efficient) than std::map.
&gt; Nice post. Thanks. &gt; I believe type erasure is one of those relatively simple ideas which are currently overly complicated to realize in C++. I would agree. E.g. some form of compile time reflection could automate the process. To my understanding, the proposed dot operator would be too blunt of a weapon, as it would not allow to restrict the interface. &gt; Just FYI, I am (slowly, but steadily) working on a proposal to add language support for type erasure to C++ in the form of what I call "virtual concepts". Thanks for pointing this out. I haven't gotten around to read it whole yet. But, so far I like it. In particular how it is coupled with compile-time concepts. One question came to mind: On p.39 you talk about the issue of functions which could be members, or free. Have you thought about how [unified call syntax](https://isocpp.org/blog/2014/10/n4165) would affect this, and the concepts in general? Btw, I think that I spotted a few typos: * p.13, par.1: GDP &lt;-&gt; DGP * p.33, par.2: ... cannot **be** hidden * p.33, par.5: ... a generic ~~an~~ algorithm ... * p.37, bottom: `if(a==lexical_cast&lt;T&gt;(`**s**`))` * p.39, par.1: ... wanted ?to? rvalues to be moved-from
This is a good lecture. It highlights the fundamental design point of modern computer systems: deep memory hierarchies. For a detailed explanation of what actually happens to the code, as well as carefully obtained performance numbers, I recommend Stepanov's "Programming conversations" course: https://www.youtube.com/playlist?list=PLHxtyCq_WDLXFAEA-lYoRNQIezL_vaSX-
&gt; if you just look at the 9 lines of your "namespace NS" example most readers would not assume that the supplied swap function will be called, because the code explicitly states std::. It's not fundamentally different than what you suggest. Either way, a qualified call to a function in the `std` namespace ends up executing user-specified code. It's really just an education issue either way. And my way makes best use of the existing language facilities, greatly reduces boilerplate, and is easier to get right (IMO).
More information about the project will be given upon contact, i cannot reveal anything about the project to the public at this time. People can contribute to the project from anywhere in the world.
https://code.google.com/p/sparsehash/
In the initial starting phase yes, but that might change as the project evolves.
&gt; I have a pet peeve about the use of the word “functor” in C++. [...] The word functor has a very precise meaning in mathematics Oh get over it. C++ is not mathematics. Each domain is free to define its terms as it sees fit. C++ *defines* the term to mean a "function-like object". SML and OCaml define "functor" to mean something else. Math *defines* terms without any consideration for their meaning in other domains (groups, rings, fields and modules anybody?); why should C++ programmers be bothered about other meanings of "functor"? 
Thank you for reading the document and spotting those typos, I just uploaded a fixed version. Concerning compile-time reflection, yes, that would definitely help, but it would not still not solve the proxy dilemma, which would make reference semantics (especially through smart pointers) problematic. Compile times are also likely to be affected, and supporting things such as refinement/subsumption would add complexity as well. Indeed I am aware of N4165 and N4174, however I haven't considered how these features would interact with virtual concepts yet. The problem is quite hard, so I have to tackle it step-by-step, but this is definitely something to keep into consideration. Thank you for your feedback!
TL/DW If you want performance don't use std::map ever. std::map is so bad it should not be in the standard library. std::vector is the way to go, always. I have heard variations of this advice before from people who know more C++ than I will ever know. But every time I have tried to replace std::map in my code with any std::vector derived equivalent I end up with worse performance. My typical use of std::map is load once and read many times and this case I have found it outperforms std::vector in all tests I have tried.
&gt; Matt Austern (another Google employee) has a nice write up of why to avoid std::map and some alternatives: http://lafstern.org/matt/col1.pdf May be the same arguments apply but the paper you linked to is about std::set not std::map
the people you heard were probably referring to this [article](http://lafstern.org/matt/col1.pdf) (or they figured it out themselves). In any case the vector has to be sorted and lookups are done by lower_bound. boost::flat_map implements exactly that interface.
&gt; the people you heard were probably referring to this article The article you linked to is talking about std:set. May be the arguments are similar but my own tests were on std::map. I have tried boost::flat_map and didn't find it faster than std::map in my use cases
Did you sort your vector and use a binary search? That should outperform a std::map with separate load and lookup phases.
Stack creation would be nice and I actually had something similar to that initially. However in the project I am writing, certain types' lifetimes are managed by the API. I could, obviously, just return a pointer handle from the create function, I just feel that my solution looks a little cleaner. I could expand 'snew *type-id*' out to 'resource *type-id*' for clarity, I suppose. 
No one learning about math rings is going to get confused. "You mean I can't wear it on my finger?" Someone learning about math functors *as applied to programming* could get quite confused. Some collisions are more unfortunate than others. That's all he was saying.
You have a friction between "std::vector is the way to go, always" and "My typical use of std::map is load once and read many times". "Always" is too big a-word. 😉
I agree. I'm often frustrated with mathematics' appropriation of common everyday words to mean esoteric things, but "functor" isn't a common everyday term. It means something specific in a pretty relevant domain. Try googling "functor" and see what you get. Hint: it ain't a C++ function object.
Did you have rather large (multiples of the cache line size) objects? I'm just trying to figure out what may cause the measurements you saw.
I'd be willing to bet break even read/insert is lower than most people expect though. Even with full reallocate/memcpy, the access pattern is much more regular with std::vector. There are valid reasons not to use it, or at least use it carefully, though. *edit - this is basically his point, data structures and access patterns matter*
[Jason's variant implementation on Github](https://github.com/JasonL9000/cppcon14).
Wonder if it works the other way around.
What do you mean with "the other way round"?
Maybe VS has some warnings that clang doesn't making it a good idea to run both in all cases.
&gt; Did you have rather large (multiples of the cache line size) objects? I'm just trying to figure out what may cause the measurements you saw Usually I use std::map in situations where the container size is unpredictable. For example reading data from a database or file, performing lookups on std::string keys. Kind of in-memory join. The elements could be in a few hundreds or hundred thousands.
&gt; Did you sort your vector and use a binary search? I didn't actually try to use the std::vector directly but tried maps that are implemented using the std::vector such as boost::flap_map and Loki::AssocVector
He offered the `dense_hash_map` solution that google implemented. Though, I can tell you that this is not a silver bullet either. I think there are advantages and disadvantages to any implementation of an ADT. Chandler is thinking on the processor level, in terms of nanoseconds of waiting and in terms of how many CPU cycles are wasted simply waiting for data from main memory because it wasn't placed into cache instead. In that light, it does seem that `std::map` and any other container that has the idea of links and separately allocated nodes in it will be much, much slower because waiting on data from main memory is orders of magnitude slower than getting data from the cache. I think the way to figure out what implementation you should use you should do exactly what Chandler said: profile your application(s). Don't write a useless program that inserts things into a map. Replace every instance of `std::map` in your application with boost's `flat_map` instead, and see the performance speedup/slowdown/no change. Benchmarks of these pointless applications that insert and print things are not useful for large scale applications. I've read that some people have had performance speedups and some haven't. Some people may have even achieved worse performance by using flat maps or open addressed hash tables, though they're not many, I think.
This is really an apples vs oranges comparison considering that the higher level Clang warnings are effectively static analysis warnings. VS has a static analysis tool, I wonder if they give the same warnings as Clang.
Until it supports SEH exceptions and/or SEH as C++ exceptions its impossible to use Clang on large Win32 products. Maybe there are better flags that I need to use but I've had trouble compiling even minimal sections because of this. 
[Part 2](https://www.youtube.com/watch?v=a0FliKwcwXE) 
Any reason to use SDL over SFML for this sort of thing?
Not OP, but I once tried to use SFML instead of SDL. It's really nice, but there isn't as much support behind it as SDL.
What does that mean? Both are straightforward sets of functionality. They either work or don't. I made a few visualizations with SFML and was impressed. Easily handled millions of particles in fluid motion.
Try Crucible from Atlassian. I used to do formal code reviews, but I've found that asychronous code reviews tend to foster teamwork and collaboration better: - All comments in code become a permanent record. - The code review comments serve as a basis for debating best practices. - New team members can research the organization's practices through search. - The review can be tied to Jira tickets. - Real participation can be tracked to individuals, encouraging more participation. - Time spent reviewing code can be captured and used to establish appropriate timeboxes. - Developers feel less defensive without a group of peers criticizing their work face-to-face in one room. 
The tool you use is probably the least important part of the process. A diff in an email or an over the shoulder discussion will do as good a job. It's more important to actually incorporate code review into the release process. Something that should be scheduled as a task to be completed and signed off on. Without that, it really doesn't matter what tool you use, in my opinion.
Actually SFML might have been better, but it was a project for my grade 11 cs class last year, and my teacher suggested SDL so that's what I used. But there's no reason it couldn't have been done in SFML
I mean community. SDL has this whole, well-developed, mature, community behind it. Lot's of people support it. Any problem you experience is probably already solved. SFML doesn't. It doesn't have as active of a community behind it, and it's rather hard to find answers.
`void_t` looks a lot like [`enable_if_type`](http://nt2.metascale.fr/doc/html/boost/dispatch/meta/enable_if_type.html). From what I hear this technique has been used for a long time now, although `void_t` seems to be a particularly elegant variant of it.
Well, I'm glad I never have to look at how anything in &lt;type_traits&gt; is implemented. I understand what he was saying, but that syntax is crazy.
It's a good talk. I respect Chandler, but I have to take issue with one thing he said because it can be easily misinterpreted: that you should always do the micro-optimizations for efficiency because profilers won't be able to show you where you missed it. Taken literally, it amounts to homeopathy. If you can't measure the performance difference between two changes (i.e. it's in the noise), there's effectively no performance difference as you haven't disproven the null hypothesis. I'm going to assume that what Chandler meant to say is that the current set of tools make it hard to regain lots of little performance drops resulting from poor local performance. Even still, I don't know if that's true, nor if it's good general advice. If the run-time is on the order of hours, it's hard to claim there's any noticeable effect to shaving off a few seconds here or there.
Personally I like Reviewboard, but there's lot's of good tools. If you can get others on-board, I strongly recommend a pre-submission model where automation merges features in so that it's impossible to ever have mainline failing to compile. If you add tests, you can also guarantee that master is guaranteed to have some level of quality at all times.
I don't know. I think e-mail is such a clunky &amp; annoying review tool that it can turn people off of code review. A dedicated tool eases the burden by making the experience more like over-the-shoulder (inline comments) but asynchronous (discussion threads, view of which reviews are pending etc).
I thought exactly the same thing...
The way I took his message in this area was that there are certain practices that are just good performance practices period. They may usually be micro-optimizations, but sometimes they can make a significant difference and it is better to be in the habit of writing code in this performant way. For example: using preincrement over postincrement. For fundamental types (and even things like vector iterators in release builds), there will be no performance difference. However for some iterator types, there is a difference. In certain situations, that difference is measurable. So be in the habit of using preincrement anyway. It's been over a day since I looked at the video, so maybe I misinterpretted it or just heard what I wanted to hear. But that is what I took away from that part of the talk.
That's kind of what I took away as the message, except he was claiming that you can't recover it via profiling tools. I would counter though that you should write code in the way that's easiest for others to understand &amp; most natural for you (in that order). You should work to optimize the latter over time for readability, lowest bug count, &amp; performance in that order. Sure, you should try to develop better habits &amp; think about performance. I think however, while Chandler did make a good point that both server &amp; mobile care about power, it's incorrect to say that CPU power draw is the sole factor for poor battery on mobile (I understand that he's trying to make a point &amp; it's a presentation). On mobile, other subsystems can easily dominate: radios, screen, sensors, etc can easily blow your CPU power draw out of the water. Additionally, some of these, like sensors, can easily dominate your CPU in &amp; off themselves (i.e. regardless of what you're doing in your application). The point is that on mobile you really have to understand what the expensive power operations you are performing are. I think I'll refine my objection to Chandler's point: worrying solely about CPU optimization in mobile only works in a very small subset of applications. The CPU tends to sit idle for the most part in any given application. Android, I think, made a bad design choice to not restrict background applications in some way &amp; thus this is less true for Android. Regarding post-increment, I have been bitten exactly 0 times by post-increment vs pre-increment. I have yet to encounter a real-world scenario where the way an iterator increments matters in a way that's visible in a profiler.
Absolutely. The balance is between data sizes (key/data), container size, modification rate and heap state. It is still too situation-dependent for the use of the word "always".
I'm not sure I entirely agree with that. If the memory access pattern is random (ie std::map traversal), you'll generally lose orders of magnitude in performance by completely missing the cache (and waste memory through pointer allocation). If the access pattern is regular though, and especially doesn't cross page boundaries (ie std::vector), you generally don't have to pay the 100+ cycle cost for memory accesses (it's less than 5 cycles for L1). So the additional complexity costs (sorting/memcpy/reallocate/etc...) can probably be hidden by typical CPUs. I think this was the major point he was trying to convey. So, the argument probably could be made that there is no valid reason to use std::map ever. I can think of counter-arguments, but they're not common scenarios and it's dubious std::map would be the optimal solution.
&gt;I'm not sure I entirely agree with that. Euh... what, specifically? I don't see what you disagree with from the rest of your post. &gt;If the memory access pattern is random (ie std::map traversal) That's unfair: if your access is mostly traversal, why use a map at all? It is specifically made for speed of modification and search. I understand, of course, why cache effects favours a vector, bit dig this: yes, very much so if container element data is "flat". If not (which is a common case, I should think, think stuff as common as a string), then less so. In fact, in that case, absence of reallocation helps the data in a map, because it tends to stay together, and blows the cache with a vector, because part of the data is suddenly far away after e.g. an insertion.
I like it - it's definitely great for more than one reviewer. For small things I tend to just use 'meld' as I can actually edit the code to clean things up if the mood takes me, then send a pull request (I use git) back to the original developer.
I want to use SFML, I realy do. But it still has a lot of rough edges, especially the stable 2.1 version (which is over a year old). Some that I've noticed when working with it: - [`PollEvent` function is really slow](http://en.sfml-dev.org/forums/index.php?topic=6079.0) because of slow joystick polling. I recompiled SFML from source just to disable this. I'm not sure if this has been fixed. - [You can't focus the window by clicking inside it](https://github.com/LaurentGomila/SFML/issues/437). Fixed in upstream. - [Alt-tabbing in fullscreen mode is buggy](https://github.com/LaurentGomila/SFML/issues/306). I think there was also something with window/fullscreen/borderless switching but I can't find that now.
It's really jarring to read. I use C++ as my main language at work, but reading the literature and seeing function objects referred to as functors immediately causes my brain to stutter as I wonder "Huh, what should I be mapping over where?"
Fantastic speaker.
Pretty good game. Personally, I'm also interested in making simple games using SDL. I have been looking through [LazyFoo](http://lazyfoo.net/SDL_tutorials). What tutorials had you been using?
But SFML has a very nice documentation.
Fun game! would have been cool if you shared the source though :D
&gt; t's incorrect to say that CPU power draw is the sole factor for poor battery on mobile Indeed, Chandler's colleague at Google Android team may seem to hold this view since they [recommend](https://developer.android.com/tools/sdk/ndk/index.html) developers use Java instead NDK.
I've tried phabricator, barkeep and gitlab. Phrabricator was bloated with features and hard to use. Barkeep was excellent only for code review - very user friendly. Gitlab is an open source clone of github. I liked it the most. And that's the tool I would choose for next time. 
Last post was 18 days ago
Best talk from CppCon i have watched so far. 
In copyright infringement alley.
[Part II of the talk](https://www.youtube.com/watch?v=a0FliKwcwXE) [Slides here (PDF)](https://github.com/CppCon/CppCon2014/blob/master/Presentations/Modern%20Template%20Metaprogramming%20-%20A%20Compendium/Modern%20Template%20Metaprogramming%20-%20A%20Compendium%20-%20Walter%20E%20Brown%20-%20CppCon%202014.pdf?raw=true)
I'd love to agree with you because I too believe that a crash is better than dealing with SEH but unfortunately I'm working with real world legacy code. There isn't much I can do about removing these because catching them is part of our contract at this point. Since SEH is the exception style MS chose instead of pure signals the lack of SEH support in Clang is sort of like &lt;signal.h&gt; is missing. Is it required? Not really but code that requires it isn't going to work and if that is deeply ingrained in your code base there isn't any way you are going to compile with Clang.
I, too work with real-life legacy code and can't count the number of times when the thing crashed and we have no idea why, whereas a crash dump would have offered a plethora of additional information. BTW, I cannot **believe** that you're up-voted and me down-voted. Oh well...
That's exactly what I used to get started, i highly suggest it. When I was developing it the SDL2 tutorials weren't released yet so I had a hard time with some outdated things, but overall its the best tutorial series for sdl
We need more parallelism. Let's use unity builds.
There are a lot but I would suggest you'll need to change your process a little bit. In my experience when you do the branch and merge process you end up with fairly sizeable merge changesets. Too much to be really reviewed. If you want your reviews to be of any use other than to slow you down, you want to encourage *real* reviews, not rubber stamps. So post reviews more often. Do this even if you still have to do the big one. One problem you may run into, that I did, is that nobody bothers to review the little ones. It's not part of their branch, it's not in trunk, they don't care enough. I don't know what to do about this unless you're a team lead or something. Frankly, short of telling people, "You will do code reviews," I've not found a way to encourage them. When you do that though they end up not really being done, or they're all about code formatting and no substance. But large reviews for sure make a mess of things. You might also reconsider the branch/merge process. It's not the recommended approach in agile methodologies. If you're agile you work directly on the trunk AND you keep it always clean. You do this with sprintable features, things that can be done and tested in a sprint. Do this and massive changesets with months of changes in them can't exist.
Don't most people use versioning to avoid this issue entirely? DllHell doesn't exist when you put versions in the name. I've never had any problem with updating any library on a Linux system and not recompiling everything. So why is this needed? Is RH altering libstdc++-1.1.1.so?
[Slides in PDF format available here.](https://github.com/CppCon/CppCon2014/blob/master/Presentations/Optimization%20Tips/Optimization%20Tips%20-%20Andrei%20Alexandrescu%20-%20CppCon%202014.pdf?raw=true)
Yes but how do you know what version to label something? Tools like this help you develop sane versioning policies.
Woot! My talk has been finally posted. I am here to answer any questions you might have.
When you use small ref-count by sharing it with pointer or by allocating from some special custom allocator or by re-using some spare bits in payload you face more problems than leaking objects. Destructors of leaked object will not be called, which may / may not be critical for your application. For example wen you have `custom_shared_ptr` pointing to a file, it will not be flushed and closed.
&gt; Yes but how do you know what version to label something? I must not understand the question because I don't see how it matters. Use a GUID if you want. So long as it never matches some other version you're fine. Of course, you do have to change the version number every time you release, but only a really silly person (or someone on windoze) wouldn't. If the same of the library always changes then ABI doesn't matter. Only time it does is if you perhaps re-compile a dependency with a different compiler. I can see how this would be really important to a windows developer. I've worked places where we had to battle ABI from 4+ years back. You can't change member layout, can't add virtual overloads...you can usually get away with new virtuals if you add them at the end and don't overload but it's not guaranteed. If your public interface makes any sort of use of templates you're fucking yourself. It's a horror. But in Linux systems the version is almost always part of the library name. Links are set up to point at the appropriate one. Then you can override all the links, add new versions, etc...without causing any harm at all to any currently compiled program. It won't even try to use the possibly incompatible library until you re-link it...and why would you when you could generally recompile it instead?
It's a fair question all around, you just didn't catch my clue as to what this is for. The point is, the version number should reflect on the ABI in some way. But version numbers are assigned by humans after all. If the tiniest increment happens you don't expect the thing that depends on the library to totally break if you upgrade the library. Yet, that is exactly what can happen if the library author does not take care to ensure that their numbering scheme is correctly reflecting ABI changes. This kind of tool is capable of telling you when your ABI has changed, so you can choose the next version number accordingly.
The reason to prefer preincrement isn't performance, it's clarity. Using preincrement by default makes the necessary postincrements stand out.
Great talk, Andrei is hilarious too
Version number should reflect on a lot more than the ABI. If the ABI stays the same and the behavior changes it should still have a different version number.
I have studied SDL 1.2, but have never touched SDL2. Would it be hard or useful to go through all tutorials in SDL2?
Yes that's another point to consider. But in those cases it's better to try to break ABI as well as change versions.
Interesting talk. What downsides (if any) is there to using coroutines debugging, code maintenance ...
 I just want to say that from an end-user perspective these look very nice. I've previously used Python generators to implement coroutines, and found it very useful indeed. Having proper support for the same in C++ would make it much simpler to express certain patterns. One issue I ran into when using boost::coroutine was with libpng, which uses setjmp/longjmp for error handling. When calling longjmp from a different context (different stack I guess) things go bad very quickly. I ran into this when using it via Qt, so it's not very easy to get rid of the dependency in that context. How does your solution fare with regard to jump buffers?
Lets say the function at the 13th minute is in a GUI thread and the programmer does not want to block the GUI while waiting for the network. Wouldnt it be better if the whole loop was inside a single await or for a separate thread to be created and have the loop run there? To me, it seems inefficient to await in a loop or to have multiple awaits within the same function. I could not watch the entire video on my shaky network so my apologies if below questions were discussed in the video. Are awaits powered by threads or threadpools behind the scene? If doing a work using a thread costs 100 points of effort, using await will cost how many points of effort?.
As long as we don't inline (and we don't yet), debugging experience should be what you expect. When you "Step-in" into a pull operatation, you will end up in the middle of the coroutine, when you step-out of yield, you will go back to whomever pulled the generator. In Preview, we did not do anything about debugging (no time), but nevertheless, with the debugger as is, you can step over resumable functions, examinee the local variables on the coroutine frame etc. (It does some annoying jumping to the beginning / end before getting to yield, but, we will fix it for RTM) Maintenance. I think coroutines affect two patterns, generators and async. Generators allow to write certain kind of algorithm simpler (see same-fringe example.). Asynchronous programming is dramatically simplified with coroutines. Given that, simpler more straightforward code =&gt; easier maintenance.
We explored initially to forgo compiler supported coroutines and use boost::fibers (N3985 proposal). However, apart from performance and scalability limitations, another problem was that switching stacks is not compatible with some existing software. Coroutines as in N4134, are normal functions in all respects. When you call them, they look to the caller as a normal function. When you call something from resumable function, it is a normal function call. We don't changes the stack, we are a normal function that just uses a tiny bit of stack and keeps its locals on the side. In fact, as I mentioned in a talk, you can pass them across C boundary as a Callback + void* (see sleep_for) example and code that has no idea about C++ or coroutines will be able to resume it
 std::future&lt;ptrdiff_t&gt; f; MyWindowProc(msg) { switch (msg) { case OnClick: f = tcp_reader(1000); break; } } When you click, you start tcp_reader, it executes on the UI thread until it submits an async I/O to the OS to establish a connection. Then it yields control back to the UI thread. When connection is established, OS will call a completion routine that will resume the coroutine (now it runs on the thread that does I/O completions. Windows Threadpool owns that thread). Again, coroutine runs for a very brief moment to initiate read async I/O and immediately return back to the OS thread as soon as I/O was accepted. So this coroutine is only on the processor for brief moments between awaits. It does not consume any resources apart from the memory for its locals . If a thread is 100000 unit of effort, coroutine is 1. (Not really sure how to operate in effort units :-).
My understanding was that ubsan in GCC was based on the one in clang so I don't know if there's any significant advantage to running both (beyond that of the benefit of just using two different compilers in general).
The other thing not mentioned in the article is that the "OOP implementation" can be put in the CPP file, whereas the "Generic Implementation" is put in the header file, slowing down recompilation times, and in the real world, the compilation time of your project can limit your productivity for the day. (Yes I know that Generic programming speeds up the run-time, but often times the Pareto principle applies so the run-time speed doesn't matter as much).l
Ah, thanks for the info. Guess it doesn't hurt to use both either way.
This will be addressed by modules. 
I really like the talk and (from what I can tell from the slides) is being proposed. I am curious how much talk there is between different study groups because I can see how stackless resumable functions can allow for simpler interfaces or implementations for some libraries. How are ranges, filesystem, etc... being affected by these proposals like this?
Also by writing in the headers, your source code is now visible in the header file, dependency cycles become an issue, and you lose your clean interface. Edit:and you lose precompiled headers. 
I have heard both Chandler &amp; Herb state explicitly to do it for performance. As for calrity, perhaps it's more a function of what you're dealing with day-in &amp; day-out? I'm not dealing with implementing the STL on a daily basis. I just did a quick grep of a large codebase we have: the only places I have pre-increment or post-increment are: * On a stand-alone line * As part of a trivial for-loop (for int i = 0; i &lt; n; i++) In none of those cases does it matter if you pre-increment or post-increment from the logic level. I find it's far simpler to just avoid assigning the result of a pre-increment/post-increment. Far less ambiguous about what's going on in what order and it's not like the compiler is generating less efficient code.
See also http://www.reddit.com/r/programming/comments/2k3tyq/some_reasons_why_modern_c_adopted_the_generic/
There is a Youtube video somewhere (a talk by Scott Meyers I think) that explains variadic templates really well.
Also, and while it's kind of a distasteful position, needing to place code in the header for things like this makes it harder to distribute a closed implementation of your software. That said, I'm not aware of any technology that allows for compiled/obfuscated *compile-time* libraries. 
&gt; Still not quite sure how to get the syntax right and how to traverse through the template arguments in case I need to modify one before passing it down to the library, but it's starting to seem possible. This sort of stuff is definitely possible if I get your meaning, though it can get a little mind-bending and I'm still really terrible at it. For example say you had a variadic function for printing out numbers. And you want to pass a bunch of arguments to it but want to multiply floating point numbers (and only floating point numbers) by two. Then in C++14 you could do something crazy like this (Warning: ungodly code): http://codepad.org/msgyaVUQ which should work in gcc 4.9 (though I can't test it), and works in gcc 4.8 if you have an integer_sequence header lying around. And will output `1 4 3` A similar technique can be used with std::conditional if you want to conditionally cast variadic arguments to different types depending on what type traits they match. 
Are you talking about [*Variadic Templates are Funadic*](http://channel9.msdn.com/Events/GoingNative/GoingNative-2012/Variadic-Templates-are-Funadic) (Andrei Alexandrescu)?
&gt; which should work in gcc 4.9 (though I can't test it) FYI, there are a few online code pasting sites that have the latest gcc. [Here's one](http://melpon.org/wandbox/permlink/TPoWXpiCQd7OzvQO). 
Good to know!
The paper mentions &gt; One example is the Associative Container std::set (and its siblings map, multiset, and multimap). as well as &gt; The basic purpose, though, is managing a collection of elements that can be looked up by key. (The Associative Container map is very similar, except that in a set the elements are their own keys while in a map the elements are pairs; the first member of each pair is the key, and the second is some value that's associated with the key.)
The proposal is here: http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4134.pdf It is mostly the same material as in presentation, but, in less fun form :-). We just started socializing the proposal and the first official full committee meeting will be in a week. I think, if adopted, it will impact ranges, executors, pipelines, networking proposals and, indirectly, file system proposal. As at the moment File System is not even tackling asynchronous operations at all. There is also a funny interactions with monadic classes such as optional and expected. It should make code using them shorter and leaner. 
I just explained, ABI checkers are tools to help you assign "decent" version numbers! If you don't know that your ABI broke then you might declare a version number that sends the wrong message to users. How much clearer can I be? This is a tool to help you do the right thing with your numbering (among whatever uses you can come up with).
&gt; I just explained, ABI checkers are tools to help you assign "decent" version numbers! That's not an explanation if you can't answer why ABI has anything at all to do with version numbers. I don't think it matters, and I said that already..and explained *why*. So you just repeating it again doesn't really do much for me. &gt; How much clearer can I be? At this point I'm not optimistic. Can't say I care anymore either. Already frustrating trying to wring reason out of stone...when it starts getting snippy about it I'm out.
[N4190](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4190.htm): &gt; D.7 "char* streams" [depr.str.strstreams] &gt; This was also deprecated when C++98 shipped. The LWG felt that strstreams haven't been superseded with respect to performance, so they can't be removed at this time.
Oh, I hate the title. There is **no such thing** as "C functions on a 64bit architecture". First off, what about calling C functions from a static CRT build for **any** architecture? There is only "my C language implementation's ABI on architecture X", and there's "system ABI". The two often go hand in hand, because the system ABI uses the "dominant" C language implementation (or perhaps vice versa). **C language** has no such thing as an ABI. It can't ever have it, because (and rightly so) does not specify the calling convention(s) nor data alignment.
`std::strstream` can use a fixed-size array of char as a backing buffer, which means you can construct one into a local stack-allocated array and avoid any heap allocation. Maybe you are writing a logging function for example and you want to build up a log message in a temporary buffer before writing it out to a file handle, but you don't want any heap allocations. You can't get that from `std::ostringstream`. (Maybe you can, if you're willing to write a custom allocator for `std::basic_string` but it sounds enormously tedious, especially in in C++98. And it still wouldn't work very well because `std::basic_string` wants to reallocate and copy to expand; it doesn't know that it has an array it can expand into. So your local stack allocated char array is going to have to be a lot larger than it would under `std::strstream` because it has to fit all of those geometrically-increasing temporaries in addition to the final string.) 
Ok, I will look into that. Thanks :)
another silly way to do this is to wrap the function into a struct to get pattern matching like [this](http://melpon.org/wandbox/permlink/OGbAk1QsnIH9GzGS)
This posting deals with the proposals for concurrency, modules is coming. There is a proposal for modules, its going to be covered later in the series: http://www.open-std.org/JTC1/SC22/WG21/docs/papers/2014/n4214.pdf Yet I'd be careful with modules being in C++17, its a long way to go for this to work in C++. But finally some work in this area.
**Communicating breakages is usually done via version numbers, and various levels of compatibility should be communicated through version numbers.** Bug fixes generally don't break anything. These are the assumptions that you seem to be missing. So if you don't change your version number in the right way (3-part schemes are common), and break your ABI, then you will ship some binary which may not work as a replacement for another version. An ABI break usually requires users of a library to be *recompiled* against the new version. A tool like this lets you examine actual binaries and headers to automate the ABI break analysis. Without a tool you must examine the source and know what the hell constitutes an ABI break. I'm done. I think that is technically repeating myself, but it's slightly different and more detailed so you might get it.
&gt; Size isn't speed Sure it is, it just gets hidden if you generate a lot of numbers since it is constant. If you do not generate a lot of numbers... complain to that STL guy that removed rand() ;)
When used in dynamic mode, strstream's str() gives you direct access to its underlying buffer. stringstream's str() always makes a copy. When used in static mode, strstream parses or writes data directly from/to a user-provided array (analogous to stringstream with a working pubsetbuf, last I checked gcc's worked, Microsoft's didn't)
I don't see anything there about ASIO as the fundamental model for concurrency that can support both callbacks and futures :/ I really like that proposal. Furthermore, ASIO just got an Executors and Schedulers implementation based on concepts that is IMO way better than the one proposed (based on virtual functions). You can still have an "any_scheduler" or "any_executor", but don't have to if you don't want to. And then there is AFIO.. The only think I don't like about futures is that by default they cause a memory allocation/deallocation (although you can pass them your own allocator).
I appreciate the sentiment. As they say: "Once bitten, twice shy." I've been flamed before to the tune of "how dare you use FOSS for profit work." Never mind that I'm the guy that's constantly reminding his co-workers about how to respect different licenses. Ever since, I've been careful when outing myself as a part of the for-profit software industry.
When in doubt, **GO BOLD**. :p I know what ABI breaks are there, guy. Like I said, spent some time struggling with them. Windows doesn't have the same sym link structure as Unix, or at least didn't used to. Still don't know why you think it breaks anything on a Linux system though, where every version (including revision level versions) has an entirely different name on the system and requires re-link at a minimum before a program even tries to use it. User of your library has to quite on purpose decide to re-link without recompiling...you can't exactly ship a breaking binary unless you don't actually change version numbers when you release. If you are doing that then fuck you. So far as I have ever run into it is only source level compatibility you need worry about in your version scheme. Revision means you've not really changed much of anything, minor means you've added some stuff but backward compat should be intact, and major means all bets are off. Of course, this is the GNU versioning scheme and Stallman was a big time C guy. Source level changes are reflected in the ABI in C. So I guess one could develop the assumption that minor versions are all ABI compatible. I've never made that assumption and tried to just re-link something on an upgraded library--especially when I have the source at my disposal and can just recompile. Generally if I don't give a fuck I just don't give a fuck and since by default upgrading a library has zero effect on existing binaries on a Linux system it has caused me no grief at all in nearly 20 years of use.
&gt; Frankly, short of telling people, "You will do code reviews," I've not found a way to encourage them. One major bank I know makes the reviewer take full responsibility for any problems with the code, meaning he gets the phone calls at night and bonus cuts if it gets to that (the programmer does too, equally). Of course, they also allocate a huge part of project time for reviews. &gt; If you're agile you work directly on the trunk +1
I want this in the standard.
There is a talk by Niall Douglas at BoostCon14 [0] about how a header only C++ world could look like in a post C++17 world. It assumes modules (among other things) and a tentative implementation is in his github (I think it is called Triplegit). IIRC Boost.AFIO (asynchronous file I/O) was born for implementing this. There is also a paper about it in arxiv. [0] https://www.youtube.com/watch?v=8TkCwizP14Y&amp;noredirect=1
Well, write a proposal :) Not sure how deep the knowledge about asio is in the concurrency working group. After all its often seen as a networking library.
yes, you can capture the function argument list using decltype like [this](http://melpon.org/wandbox/permlink/3GSlng5BTqydCY8D) is this what you want?
 you can do so with function pointers that haven't been casted into nonsense, since function pointers carry type information with them. It doesn't make much sense to use *addresses* since TMP happens at compile-time. nyanscat showed one way (that I'll have to take some time to digest). But since I already wrote this up, here's an example of how you could use type-traits to convert a function type or a function pointer type to a tuple that represents the arguments -- which may or may not be completely different from what you want: http://melpon.org/wandbox/permlink/Dk2owwvpytGXnL6W (can you tell that I really like tuples? It's because it's pretty easy to use them interchangeably with variadic templates?) 
There are a couple of proposals already: - N4045 Library Foundations for Asynchronous Operations, Revision 2 - N4046 Executors and Asynchronous Operations - N4242 Executors and Asynchronous Operations, Revision 1 (this is new, and IMO N4046 and N4242 are way better than Google's proposal) ASIO is way more than a networking library. It's an extensible framework for asynchronous operations. It supports futures (std::future, boost::future, ... slow), callbacks (really fast, no allocations), coroutines, fibers, ... It also comes (since N4242) with a generic implementation of Executors and Schedulers (to manage how and when things get executed asynchronously). You can use it for asynchronous networking, but you can use it anywhere asynchronous operations are required as well. For example Boost.AFIO lies on top of ASIO and provides asynchronous file I/O in less than 1000LOC of C++11 code (which I find just amazing). 
Seems like I forgot the last 4 proposals for concurrency. Will update the post later. Thanks for noticing! 
Thank you for your reviews of the proposals. They are a great way to know what is going on without having to read them all. Googles proposal Revision 4 has a comparison against N4046 and N4242 that is worth reading in case you are interested. I'm just so strongly opposed to Google's proposal that can't help but say it loudly every time i have the chance. Their only argument against N4046 and N4242 is that their proposal is "shorter". They call it "simpler", but it is only simpler if you want to do what their proposal allows you to do. In a nutshell, it is a proposal based on a inheritance-based polymorphism and std::function. That is, memory allocations all over the place, no inlining, ... just a remark: today in the Boost mailing list Niall Douglas was explaining how to use constexpr stack allocated futures... OTOH N4242 and N4045 are based on concepts. They are very extensible (they work with every executor we know of), and they perform very very good if you are willing to use e.g. callbacks instead of futures with a heap allocated shared state. If you want a single interface you can easily model their concept with an "any_executor", but that is _opt in_, not forced on everyone by design. IMO executors and schedulers is something extremely fundamental that has to work for _everyone_ (how, where, when, and by what is _work_ executed). It has to be extensible, performant, and generic. And it is something you want to get "right". A "shorter" proposal that is slower, less extensible, and doesn't work with everything we already have, doesn't solve the problem, it creates a new one. I find it amazing that they have pushed their proposal this far (to Revision 4), instead of writing a new one addressing the fundamental issues. 
Yes, that looks like exactly what I need. I'll try putting this to work on Monday... thank you so much!
&gt; you can do so with function pointers that haven't been casted into nonsense, since function pointers carry type information with them. It doesn't make much sense to use addresses since TMP happens at compile-time. Good point and thank you for the clarification. Like nyanscat's code, the code pasted also solves exactly one of the problems I've been looking at. Thanks so much!
digest what? the silly example? no, please don't ;) in the debugger class I specify as a template parameter the type I'm looking for (T), and ignoring the lambda(that gets forwarded) i create an call a helper class with that at the start, and a delimiter Del{} at the end. so you have &lt;lambda, T, Arg, etc..., Del&gt; in general if the helper doesn't recognise the argument Arg, it moves it to the end, and calls a helper with the new argument list. if it regognises it, calls the lambda, and moves it to the end. if it sees the delimiter, the argument list has gone full circle, and calls (or whatever...).
Hey it's early! Reading template code is hard in the morning :D
No, i mean, i used very short and meaningless names, it wasn't written to be read... i hope the explanation is clear...
Ad mining link. Use author's site directly instead http://www.agner.org/optimize/optimizing_cpp.pdf
If you don't generate many random numbers, by definition you don't care about speed.
That sounds like a really awful place to work. I hate blame cultures.
&gt;&gt; I know what ABI breaks are there, guy. Like I said, spent some time struggling with them. &gt; This is exactly the problem. You don't know how things can break in subtle, non-obvious ways. ABI breaks are much broader than API (source level) breaks. If you do something as simple as change the order of fields in a class or struct provided by a library, things can break. Imagine if you declared one of those in your code. The definition from the old library, which you compiled with, will not match the new one. Addition or removal of fields is the same. smh
Thanks.
Given that you have struggled with ABI breaks do you agree that it would be awfully nice if you could tell from the version numbers whether you will have ABI breaks? That's really all I'm suggesting. Some people have that policy but they need to know that the ABI has broken to be reliable about it. Tools like this can help analyze the libraries for ABI changes.
Indeed I had overlooked the last 5 proposals for concurrency last night. Now I understand what you are talking about, and I think you are right.
N4134 does not impose requirements on other features, but other components can take advantage of N4134. For example, yesterday on the reflector, Geoffrey Romer observed that n4134 can interact nicely with std::optional: optional&lt;Foo&gt; FooSource(); optional&lt;Bar&gt; BarFromFoo(const Foo&amp;); /////////// with await ////////////// optional&lt;Baz&gt; f() { Bar bar = await BarFromFoo(await FooSource()); Baz baz; // Compute baz from bar return baz; } /////////// Equivalent code without await ////////////// optional&lt;Baz&gt; f() { optional&lt;Foo&gt; foo = FooSource(); if (!foo) { return nullopt; } optional&lt;Bar&gt; bar = BarFromFoo(*foo); if (!bar) { return nullopt; } Baz baz; // Compute baz from *bar return baz; } 
Guess I wasn't clear. I sure thought I was. No. I don't agree that's useful. I assume any new release is going to change the binary interface of a library, especially in C++. Since Linux has a symbolic link to versions system I don't have to worry about it either because existing executables don't even use the upgraded library unless I explicitly force them to. Frankly I think the idea of using this detector as a crutch is dubious at best. You should know what changes alter the ABI. Only reason you might not is that you were silly enough to use C++ when you knew you'd want to make ABI compatible changes. It's just the wrong language for that. It can be done, but it's pure hell having more to do with being able to make the changes you need...not in knowing what will break the ABI because that is easy: almost everything.
Even so it is desirable to be able to upgrade libraries without rebuilding every client (or any at all), if only to fix security holes and bugs. Tools like this make it feasible. Mind you, the upgrades already happen based on trust so nothing is lost here except the issues that make shared libraries fail to provide some of the promised benefits over static libraries. "LibFoo uses automated testing to guarantee binary compatibility" implies "we may simply put the new version out and trust it will work with our app, or else not waste time finding out."
It's perfectly possible to put template code in the cpp file instead, but then you must instantiate it in the cpp file for the types that you use it with so that the linker can find it.
&gt; I think it's happened because of compiler that may add some clearing code for us automatically, but I may be wrong. Oh, here's a crazy idea, why don't you just look at the dissembled code and fucking figure it out, instead of guessing. You might actually learn something that way. And if you want to use a screwdriver, stop picking up the hammer and calling it evil because you're trying to pound screws with it. 
&gt; If you wrote your own struct in C++, you have to define constructor to initialize all members with some default values. This is false. You may let an implicit default constructor be generated by the compiler and it will not initialize values of fundamental type such as the ones in the example.
`memset(&amp;tm_struct, 0, sizeof(tm_struct));` is an anachronism; since ANSI C (and probably since K&amp;R at least) you can use initialization: struct tm tm_struct = { 0 }; Initialization is better because you cannot accidentally memset too much or too little. I would consider the memset version to be bad coding . I almost never use memset and memcpy in my own code, only when there really is no alternative. This is from experience, far too many bugs have come from doing this; code looked OK at first but became broken years down the track. Structure assignment and initialization is clearer and less error-prone than memcpy and memset. The main lesson to take from the code in your article is *read the documentation for whatever API you are using*. 
Using `memset` in C++ isn't just unnecessary (except that often it isn't) - it's also potentially a bug. A C++ `struct` is the same thing as a C++ `class` - the only difference is that members are `public` by default instead of `private` by default. So a `struct` can have `virtual` member functions, `virtual` bases etc. Although the mechanism isn't defined in the standard, in practice what this means is there's a hidden field - initialized by the constructor (even if it's otherwise a do-nothing constructor) - containing a pointer to a vtable, which is used to resolve run-time polymorphism. Zero that and your method calls, dynamic casts (yuck), even sometimes accesses to member fields (if you have multiple inheritance) will try to read that vtable and cause some kind of access violation. The wording in the standard is probably something about `memset` potentially causing undefined behavior. And BTW, it's not just the vtable for the struct as a whole you need to worry about - members may also have vtables. If the `struct` really is a "C" `struct` (or "POD" as in "Plain Old Data"), you should be OK, but it's still a bad habit. As OldWolf2 notes, C has an initializer syntax which C++ provides too. This will not corrupt vtable pointers, or otherwise cause undefined behavior. What's more, since C++11, there's initializer syntax for C++ objects too - very similar syntax, though the mechanism involves a constructor call. 
This only tells you what's happening in those particular compilers, which isn't important or interesting. The next versions of the same compilers may behave differently. Undefined behavior is undefined behavior - it's not really that useful to know which exact demons might fly out of your nose. Also, even if you find something that happens to work on those two compilers, that doesn't mean it has fully defined behavior. It could work on ten or more different compilers and still be undefined - I've had that in the past with a pointer alias issue in very old trusted code that I couldn't really believe was broken at first. Undefined behavior means it may even work, but you can't rely on it to continue working. The fix is to use fully defined behavior. You can't figure out how to do that by looking at the disassembled code. I've hardly ever looked at disassembled code for well over a decade, and I used to program in multiple assembler languages. It's just not that helpful - more like a distraction if not quite actively deceptive. Instrinsics for handling things that would be inefficient handled in plain C or C++ (from extra bit-fiddling operations to, of course, SIMD vector operations) are as close as I've got to assembler for a long time. 
Yup. The only legacy from C that is really a bother to me is the preprocessor. Beyond that, C++ has answers and alternatives to pretty much every Cism.
It's a shame that this doesn't build (at least under Windows). Because this is so often the case I wrote my own header only lexer and parser libraries.
I didn't say it was important or interesting. My point is, you don't need to guess as to why it's happening. You can actually determine exactly what is happening. These are the same types of people that are always convinced they've stumbled over a compiler bug, but, the reality is that they're just being boneheaded and don't understand the tools they're trying to use. If an engineer working for me actually said, "It just happened, and that's all", I'd really question their competence. I've actually had engineers who wanted to check in bug fixes without understanding the bug in the first place. They will change 5 lines of code and submit it, saying, "this fixes it... I'm not sure why, but it does". And I will revert their changes, and tell them, "great, you can commit it again when you've figured out *why* that fixes it". C programmers know you can't rely on uninitialized memory. That's why I tell people to stop testing debug builds of their code, and test release builds. And you never fix the gnarly bugs by stepping through a debug build in the debugger anyways. You actually have to sit and think and come up with a theory of what is happening, and test your theory. 
On debuggers - I fully agree. Using a debugger is the only reason I ever use Visual Studio these days. And since the last version of Visual Studio I actually used was 9 (2008) - and even then, the Express version - sooner or later I'll have to stop saying I use it ;-) C++ used with modern idioms isn't bug-prone. You get almost all silly mistakes reported at compile time (though admittedly if those silly mistakes involve templates, you won't want to read the error listing). Failing that, tests catch most of the rest. Except for some old code I have which still uses some ancient hackery, the only errors I really get in C++ are from misunderstanding either the language, the library, or the problem I'm trying to solve - all three still happen at times. A debugger can help localize where the misunderstanding is, but usually it's in the code I just wrote anyway, so a diff from the last check-in will reveal it quickly. In any case, I agree the debugger can't explain the misunderstanding or tell you how to fix it properly. That said, I do like to play with a REPL in some other language to build an initial understanding of some problems. There's still something to be said for trying things out as a quicker way to build an understanding than staring at reams of paper. 
The default constructor actually *would* initialize all members, it is just not invoked automatically for POD types with automatic storage.
The article is 100% on point. Most of the problems c++ has is due to C legacy: * wild pointers is the result of manually managed memory. * buffer overflows is the result of unchecked array access. Using managed pointers, iterators and checked array access can easily result in c++ products that are almost bug-free, and due to RAII, in better shape than their Java/c# counterparts. 
 #include &lt;iostream&gt; struct test { int a; float b; int *p; }; int main() { test t; std::cout &lt;&lt; t.a &lt;&lt; " " &lt;&lt; t.b &lt;&lt; " " &lt;&lt; t.p &lt;&lt; " " &lt;&lt; std::endl; return 0; } yields: 0 0 0x0 using clang 3.5 
Thanks! I will give you feedback soon.
Visual studio is pretty awesome for windows. I use emacs with lots of customization for linux.
If you ask me Bjarne was a real d*ck when young kid asked about combinatorial explosion of constructors. Still nice soft skills talk... 
using g++ 4.9.1 via MinGW 6127424 0 0x1
Express edition is free, however it does not support plugins and lacks a profiler.
Damn. What about the non - express version?
Even without plugins its a very good IDE, and you can always use a third party profiler.
We agree that that objects with automatic or dynamic storage duration will get *default-initialized*, however that is not the same as calling the default constructor: (8.5/6 [decl.init]) &gt; To default-initialize an object of type T means: &gt; — if T is a (possibly cv-qualified) class type (Clause 9), the default constructor for T is called (and the initialization is ill-formed if T has no accessible default constructor); &gt; — if T is an array type, each element is default-initialized; &gt; — otherwise, **no initialization is performed**.
Pro is not cheap. There used to be some cheap "standard editions", but they died off a long time ago - replaced by the free express editions. Oddly enough, the free express editions are maybe better than the cheap-but-not-free standard editions were, even allowing for the times. For example the Visual C++ 2003 standard edition didn't include optimization for the compiler - the express editions always have that. The one thing I think VC++2003 standard had that the express editions don't is an old-style win32 resource file/dialog editor - I don't think many people would care about that. 
QtCreator and KDevelop are multi-platform.
For what little I've done in C++ I've always been pretty happy with [Eclipse](http://www.eclipse.org/cdt/).
I like Xcode when I do C++11 and on. Sublime is often surprisingly ok.
Emacs personally, but it's a fairly big commitment to dive in and start learning emacs. 
There's [a claim on StackOverflow](http://stackoverflow.com/questions/406760/whats-your-most-controversial-programming-opinion/1562802#1562802) that "If you're hunting for elephants in a room (as opposed to mice) do you need to know how big they are? NO! All you have to do is look. Their very bigness is what makes them easy to find! It isn't necessary to measure them first." What he's basically advocating is taking a few random samples of the call stack and seeing what's there too often. Personally, I find I'm too prone to not seeing the elephant in the room - there's a program called [Luke StackWalker](http://lukestackwalker.sourceforge.net/) which does the sampling for you and gives you a GUI view of a call graph with "hot" and "cool" coloring. 
Hmm.. Could be. I was quite sure it was by Scott Meyers, but now I'm not so sure. Actually, I'm quite sure it's this one. Thanks.
This young man has been rehashing that (overly convoluted IMO) `sink&lt;T&gt;` approach on both std-proposals and StackOverflow and each time he got the about same response as that the panel gave. Plus it had nothing to do with writing c++ books.
Yeah I read that but I was under the impression that the POD struct was a subset of "class type", which case it would be default-initialized trivially. Have you seen any part that contradicts that?
Whoops, for some reason I assumed that class type referred to non-POD classes. So I guess you were right all along, sorry for the trouble. (Interestingly, the rules for class members that aren't explicitly initialized in an initalizer list work slightly differently: Here, non-POD class members get default-initialized and everything else is left in an unspecified, uninitialized state. Not that it would make a difference ;)
the previous post is here http://gpuoti.github.io/smart_order_by.html hope this will help someone, critics are wellcome!
Personally I use vim with YouCompleteMe (clang-backed) and syntastic and can seriously recommend that. Vim is certainly not perfect, but if you take a little time to learn the basics, you may really end up liking it. I should mention though, that I am a very heavy commandline-user and do many things that way (which avoids lots of fights with IDEs who try to reimplement the native interface of tools and sometimes fail there).
How does this compare with http://ispras.linuxbase.org/index.php/ABI_compliance_checker ?
Geany
For an IDE: QtCreator. For a plain text editor: Vim, Emacs, Sublime, Geany.
In practice, it actually matters for pointers to members, whose representations are complicated. For example, null PMDs usually aren't all-bits-zero.
I'm in the minority here, but I use gedit for everything, including C++. It has a folder view pane and to be honest (paired with indentation and syntax highlighting) that is all I need.
If you're a student or have a university email, you should be able to get the professional editions for free.
Isn't that the least of your worries? Beyond that you don't mention operating system. Given that here are a few comments: 1. XCode on the Mac is vastly improved and via LLVM/Clang offers some of the very best development tools out there for C/C++. Discount old comments about XCode as it is vastly improved even if it is a bit buggy in the 6.x versions. 2. Eclipse can be a very interesting solution. It is free and further supports Python really well. You need to load all of the extensions required to support ac/C++ and Python but that is no big deal. 3. There is alway EMACS. There are actually many free editors and IDEs out there, you just need to search around for them. 
Correction, if you've got any university email, you can sign up.
Just know that according to the license you can't use it for anything commercial.
Its not free but Slickedit is my editor of choice for its tagging abilities. Especially when not on windows or coding a large project with multiple sub-projects/libraries on windows (Otherwise it's on par with visual studio.)
vim
On Windows i use Sublime Text + Mingw + Plugins. Best code editor i've ever used. Visual Studio is probably the best IDE.
I use NetBeans. 
Sublime text is not a 'popular alternative' in your books?! It's practically free, cross platform and if you get SublimeClang to work has good autocomplete or intellisense or whatever. Also scriptable with Python (ew python) if you're into that kind of thing. Did I mention it's incredibly lightweight (unlike eclipse ahem)?
Bjarne gave him one big fat FU. Anyway I never liked Bjarne talks, but now I dislike him on a personal level. And Scott gave him best available answer but that answer still sucks... since your nick seems familiar to me you prob know better than me that there was even a boost talk about this and basically conclusion is all options suck... Ill try to find it. 
Same here. Awesome cross-platform IDE.
found the link https://www.youtube.com/watch?v=YKz05N223uE nice talk, a bit of a heavy accent, but guy knows his stuff.
I've had a bad experience with that - I profiled an application using such a profiler and then ran it through callgrind, and the profiler pointed me to one call taking 70% of the time, where callgrind showed it to be more like 1%. I optimized the other bits and got to about 30% of the total run time - so that call that I didn't optimize certainly wasn't 70% to start with.
Be more specific. What did you install? MSVC? Visual Studio? MinGW? MSYS? Cygwin? GCC? Clang/LLVM? What operating system? Also, you don't install C++, you install the compiler, which compiles your C++ code into an executable binary. Some compilers, like GCC support many languages, some support less.
Look up some tutorials on how to use it. I've never touched VS before, but try googling "c++ tutorial visual studio"
\#include &lt;iostream&gt; add std::cout &lt;&lt; "Hello world" &lt;&lt; std::endl; between { and }. Update resume. But seriously. What do you want to do?
I'm actually not sure I'm correct still, the answer to this question from stackoverflow seems to agree with your line of argument so at this point it's anybodys guess :) http://stackoverflow.com/questions/8256293/default-initialization-of-pod-vs-non-pod-class-types
I'm confused by the claim that no one writes compilers for Facebook and Google, and so they have to do ugly things in code to work around the compiler. Google *does* pay people to work on clang, and I don't see why Facebook can't do the same with gcc. At the kind of cost saving for performance gain that Facebook gets it really wouldn't be hard for it to be cost effective to pay for more people to work on gcc's backend.
you installed visual studio? congratulations! you have!
What you installed is an Integrated Development Environment. It's a set of tools for programmers (code editor, compiler, debugger etc) that allow you to write and compile programs. You can start by simply creating a new Win32 Console Application project. For further information you should check [this one](http://www.learncpp.com).
C++ is a language, Visual Studio is an IDE (Integrated Development Environment) that is used to HELP PRODUCE c++ source code. VS is not c++. You can use VS to code in other languages other than c++. Grab a book on beginning c++ like Programming: Principles and Practice (written by the inventor of the language), write some code, learn how to compile and run programs and also, learn how to use google effectively. If you can not do that, you'll be lost forever without advancing. Also, check out /r/learnprogramming and read the sidebar 
I enjoy codelite for it's simplicity. i am a fairly casual user of c++, but codelite seems like it handles most things adequately. it was also easy to set it up for a cross platform project which was quite nice. 
sublime is great.
QtCreator.
I've had any number of co-workers say: "just use emacs" The thing is that invariably you end up doing something on some server without emacs installed and then it's (you guessed it) vim time again. So I've always just ended up sticking with vim for everything and it has served me well.
I use QtCreator and you can even use it for javascript and python. (Although I haven't used it for python.) 
oh, don't get me wrong, I enjoyed the talk. But his implementation requires a C++14 compiler, and maybe you'd like something like that but are stuck on C++11 only.
Its Clang integration (for autocomplete) is also very good and supports C++11. It also supports using custom Makefiles and the like.
Just curious - how is the above a leak? Assuming that he later properly calls delete on everything in the vector (what a pain), there's no leak, just leak potential, unless I'm missing something.
You should perhaps define "good" and "editor" (that, because Code::Blocks isn't an editor if you ask me). Otherwise, others have already answered, and as you can see, the answer is largely "the one I use". 😉
Guess what happens if push_back throws.
Qt Creator is great also on Windows. You can get a Qt Creator version bundled with GCC and GDB debugger from [qt-project.org](http://download.qt-project.org/official_releases/qtcreator/) or setup a Visual C++ environment: * compiler from Visual Studio Express versions [2008](http://download.microsoft.com/download/E/8/E/E8EEB394-7F42-4963-A2D8-29559B738298/VS2008ExpressWithSP1ENUX1504728.iso), [2010](http://go.microsoft.com/?linkid=9709969), [2013](http://www.visualstudio.com/en-us/products/visual-studio-express-vs.aspx) * debugger from [Windows SDK](http://msdn.microsoft.com/en-us/windows/desktop/bg162891.aspx), just install the "Debugging Tools for Windows" * build process manager [cmake](http://www.cmake.org/download/) * build system [ninja](https://github.com/martine/ninja) * documentation [cppreference.com](http://en.cppreference.com/w/Cppreference:Archives) 
&gt; (though admittedly if those silly mistakes involve templates, you won't want to read the error listing). That's why we have `c++filt` and why the Clang and MSVC guys have been working so hard on improving diagnostics. It's getting better. But I still enjoy reading them.
I'm trying to install some software from source on my Linux laptop, and some of the tgz files that I download require QT. Is it not possible to create source which doesn't use QT? It's a bit frustrating to have to install all of this stuff, particularly in that I don't always have root on the systems where I'm trying to work.
Wow that's impressive research skills you got there, wouldn't have occurred to me that it was different definitions in the spec. However it is like you pointed out earlier that this change is backwards compatible or at least from what I can deduce, since the same rules seem to apply.
&gt; That also happens to be the crux of Linus Torvalds' rant about C++: He uses C because it keeps the bad C++ programmers out, not because C++ is bad. I've always suspected that the main motivation behind his rant was that he was simply bored of the same suggestion being made. My guess is that C++ is suggested very regularly in the kernel mailing list. One thing I've learned in academia is that I don't mind people making arguments that (I think) are bad - but I do object to people repeating themselves with the same argument, to the same audience, many times. I'd rather hear a bad *new* argument, over a good argument I've heard many times. He doesn't need a strategy to keep bad [C++] programmers out. He isn't forced to accept anybody's code. But anyway, I think I agree with you. For example, I will never again put "C/C++" on my CV. Anybody who thinks they are pretty much the same language is somebody who probably doesn't know either.
Yes but do you really need to learn a lot about EMACS to start learning C++. By the way one editor/IDE I forgot to mention is JGrasp @ http://www.jgrasp.org. It has some very nice features for someone new to programming or even somebody that is experienced but working with a lot of code written by others. Here I'm talking about their CSD or Control Structure Diagram. I can't say I use the editor often but it has come in handy a couple of times trying to understand really dense undocumented code. 
Running a similar setup here. Very configurable to your style of working - agree def worth spending some time learning the tools.
Traditionally, doing work on the main thread is bad because you're stealing cycles from the interactive thread. Is there any risk with co-routines that you're now potentially inverting the problem &amp; background operations will starve for cycles instead, potentially causing denial-of-service if there are timeouts on operations?
Non-optimized means /Od everywhere, but thanks for the bug report.
When applied to async problems, coroutines could be thought as a fancy callbacks you can pass to async I/O API as completion routines. When callback is invoked, coroutine is resumed. I don't believe they introduce any new issues. If callbacks worked for you before, coroutines will work too and will allow you to write your code simpler. 
Do you want an IDE or just an editor? For editing C++ code (or any code for that matter) I stick to emacs. However IDE-wise, Visual Studio on Windows or QtCreator elsewhere is a pretty good choice.
What a remote scenario on a modern pc! Honestly I've not thought at it. Anyway my intent was only write code to help me explain some perhaps not perfect ideas (understanding of yet known concept) 
&gt;They're overloaded, it's just that it's a poorly designed overload set. The compiler was ignoring the second overload, it just yield another instance of the first one with Obj=Person* (generating compile errors) &gt;Your implementation should really avoid duplicating code between the object and pointer cases. You are right my bad! I did't clean up the code after some tests :$ Sorry for the missing pointer test, it is just explanatory code it do not pretends to be production one. I'll try the tag dispatch based solution. I'm not sure to be able to imlement it on the spot but i'll try and publish the third solution (for you to comment) many thanks for taking time to correct me, I really appreciate! 
I just have a hard time getting a good flow on Windows. I like it on Linux so I just use the command line in another window, but in Windows I have a difficult time setting it up to work well. I know it's possible. I can get it to build though, just sometimes including stuff doesn't work like I expect... 
[The Boost C++ Libraries](http://en.highscore.de/cpp/boost/) is a great introduction to boost. But I'd say you'd want to learn the STL first.
Most of the time, the STL will get you very far &amp; more of boost is making it's way into the STL. Here are the important bits from boost I find I need to supplement the STL depending on which version of C++ you are in: * Filesystem (until C++17 hopefully) * Ranges (until C++17 hopefully) * Optional (on some compiler in C++14 mode, available in std::experimental::optional) * Smart pointers (only useful pre-C++11) * Function objects (only useful pre-C++11) * Regex (only useful pre-C++11) * Boost.Locale (if you're doing any kind of string conversion) * Multi-threading (only useful pre-C++11) More difficult parts of boost: * IOStreams * ASIO * Containers * IPC Anything else tends to be esoteric &amp; domain-specific. I would call out Boost units as being particularly useful if you're doing any kind of math/physical simulation. Zero-abstraction overhead but ensures at compile-time you're using units appropriately.
Since you mentioned ASIO, do you have any recommendations for network programming by chance?
Sorry to bump an old thread, but the solution is a mix of conda (for packaging + dependency management) and CMake (for building your own stuff). Here's what sucks about system packagers: 1) You are married to versions of libraries that were decided by the distro. If you are on RHEL5, for example, then your version of python is over 10 yrs old. Good luck 2) You are forced to maintain completely separate builds for all flavors of Linux (in addition to Windows and Apple). 3) Users need root privileges to install your package+dependencies. This is usually impossible. Linux folks, free your minds from the shackles of system dependencies. This is one of the worst design flaws of Linux. I'll never go back to that lunacy. Conda fixes this (on Linux, Windows, and Apple) by creating "environments". These are analogous to Java jars - they are self-contained directories that contain your application + all dependencies. They don't pollute anything else, and they can be installed by regular users. You are now free to use whatever libraries+versions you want, and you are independent of whatever flavor of Linux you find yourself on. Binary packages are managed like artifactories in Java. A well-designed conda environment can have almost zero system dependencies. Write your build scripts in CMake and use conda for dependency management. It's not as simple and clean as Java dependency management, but it's (by far) the best solution out there. As more people join the conda movement the available packages and functionality will only improve.
It also leaks if anything else throws before you loop through the vector and delete its owning raw pointers. This is why containers of owning raw pointers are extremely, thoroughly bad - they are the very antithesis of modern C++.
&gt; Function objects (only useful pre-C++11) boost.signals is still somewhat useful. Unless you just want to write your own stuff heh (i.e. a vector of std::function's).
The boost::asio library is really good for network programming, do you mean beyond that? It really covers everything you should need. The code is kind of a marvel of modern C++, I highly recommend browsing the source.
I've actually fallen out-of-love with boost::signals (&amp; signals &amp; slots in general as a concept). I think event buses are a far better mechanism as it takes decoupling to the next level. listeners need not know about generators at all &amp; can live in drastically different parts of the codebase.
That went better as of Monday evening.
Josuttis is pretty good for stl. Failing that just use cppreference etc.
My impression is that boost::asio is very lowlevel. If you're doing stuff directly with TCP/UDP, it might serve you well (although even still it seems overly verbose). They "reference" HTTP implementation in the examples page is just giant. I belive for HTTP, http://cpp-netlib.org/ gets recommended around here (which builds on top of boost::asio?). In my opinion, network programming in C++ is actually not in a very good state at the moment. It also suffers from being mobile-ignorant: there's no API that could replace NSURLSession (to be fair, Android doesn't even have a comparable API for resumable downloads).
Kind of strange to say, given the conference and title, but this talk seems kind of off-topic. Not much (any?) C++ related content in it imho.
The gentleman who wrote the original STL (Alexander Stepanov) has a lecture series on youtube: https://www.youtube.com/playlist?list=PLHxtyCq_WDLXryyw91lahwdtpZsmo4BGD If you have the time to follow along it's a good way to understand the motivation and usage behind the types and concepts STL relies upon (semi-regular, regular and totally ordered etc). Its not a bad introduction to template programming either and the knowledge translates over into being able to understand and use Boost effectively, too. Not everyones cup of tea, I'm sure.
N4232 has a very pragmatic conceptualization on how we could easily achieve stackless resumeable functions using coroutines and some compiler magic
...thus, the signal/noise ratio on isocpp.org takes yet another hit.
Exactly – what is this supposed to be? Regardless of that, the example code is just patently bad. if (false == lambda_func(index)) … return (rand() % 5) ? true : false; That’s terrible, and has no place in example code.
Not a tutorial but still worth to mention is [cppreference.com]( http://en.cppreference.com/w/) The concepts of the STL are pretty simple and I think compared to learning with a tutorial a good reference where you can find the right functionality and how to use it is far more helpful.
It's a great talk, and I mentioned it in the article :-) 
The best I've ever read is Effective STL, although it doesn't cover C++11 it definitely gives you a very good idea about the way in which the STL was designed to be used. Read that and top up with some of modern C++ lectures from the likes of Herb Sutter, Meyers and Barjne and you'll be good to go!
That only helps with the stuff you know you don't know, it won't help with the bits you don't know you don't know.
From what I've heard, [POCO](http://pocoproject.org/) is a very nice modern alternative to ACE or ASIO if you're looking to do network and internet focused work.
as I said, it was a joke so it's not completely relevant, apologies.
Only if you don't mind &gt;10mb size header files! And &gt;100mb pre-compiled (with clang). So expect sluggish tool chains accordingly.
That can help with "aggregate" cache locality (the entire block is together) but not "in order" cache locality (the next element is in the next chunk of RAM). The "flat" containers in Boost guarantee "in order" cache locality, but if you have an "insert heavy" workload then you probably won't see any gains (or potentially even a reduction in performance) from having to do all the copies during an insert.
It's the nature of templates sadly. Modern c++ is kind of a monster in this regard, it's the price of having both compile time determinism and flexibility. 
I've found that it's usually worth trying out [Boost's "flat" containers](www.boost.org/doc/libs/1_41_0/doc/html/container/non_standard_containers.html#container.non_standard_containers.flat_xxx) before rolling your own solution.
agreed! Their interface is quite simple, and performance from what I have seen / tested is pretty good.
 float FastInvSqrt(float x) { float xhalf = 0.5f * x; int i = *(int*)&amp;x; .... I love me a good bit hack but &gt; it’s a computation that just happens to use the somewhat exotic but completely well-defined and meaningful operation of bit-casting between float and integer. I'm pretty sure this is UB as it's casting between pointers of incompatible types. I don't doubt that it works across a lot of compilers, I'm just quibbling with the phrase "completely well defined."
Bjarne responds directly to this in the Meet the Authors panel at CPPCon. He mentions he has been trying to kill off macros for two decades, but hasn't succeed because he's not sure what to replace them with. Before we can get rid of them, we need a replacement and nobody knows what that is. I'm not sure if there have been any serious proposals, or attempts, at a replacement.
The reason macros are hated, aside from experience, are that they don't play with the type system, work outside of the language type system (i.e. they're super-dumb), &amp; they're chok-full of side-effects. #if sizeof(int) == 4 // do something useful #else #error not useful #endif Woops. Compile error since sizeof(int) is unavailable in the pre-processor. A naiive assert implementation breaks code in subtle ways: #define assert(x) if (!x) abort() What happens if you pass: `assert(5+ 3 == 8)`. abort because it expands to `if (!5 + 3 == 8)`, since ! has a higher order of precedence, you effectively get `if(0 + 3 == 8)`. What about defining swap as a macro: #define swap(x, y) auto tmp = x; x = y; y = tmp; This is horribly broken in so many ways: swap(x, y); swap(a, b); // error: cannot redefine variable tmp Or how about broken conditionals: int tmp = 5; int x = 6; int y = 7; if (&lt;some condition&gt;) swap(x, y); // silent failure - x is assigned 7, y is assigned 5. compiler *might* warn about tmp being unused &amp; shadowing.
If you need \_\_FILE__ or \_\_LINE__ - as you do in test suites, asserts and so on - I don't think there's any reasonable replacement, nor any sign of one in the pipeline. Minimizing preprocessor games, using the preprocessor to create minimal wrappers for inline functions, say, rather than using big chunks of code generated directly by the preprocessor is probably a good idea, though. Even then I find that for things like protocols and serialization I often need _some_ sort of preprocessing step to generate boilerplate code from a "one true definition". I'm trying to do that with an explicit code generation step in the build process (yay, perl!) rather than forcing it into the c preprocessor.
The support is pretty broad for x86 platforms. Most compilers treat ints as little-endian 32-bit numbers and they'll use the IEEE single-precision floating point standard for floats because it's natively supported by the processor. So the exceptions that would break it on x86 would be the few compilers that treat ints as 64bit or 16bit numbers; none of which are used much anymore and would break a lot of other things as well. Outside of x86, any platform with big endian numbers would also mess this up. The IEEE floating point standard is still popular outside of x86 but platforms without hardware floating point will probably do things differently to emulate floating point math.
I have on more than one occasion been called over to help a colleague exit a vi/vim session they started in console and then could not exit! At the very least, learn enough vi to get the hell out. If you learn a bit more, you'll find it very rewarding!
&gt; So the exceptions that would break it on x86 Or an optimizing compiler that decides it can get a small performance improvement in benchmark speed by eliminating the undefined behavior entirely. Remember a C or C++ compiler doesn't have to do the "obvious" thing in the face of UB. https://isc.sans.edu/diary/A+new+fascinating+Linux+kernel+vulnerability/6820
Did you read the text of my post? I know macros are terrible for function call replacements like swap() and the even the version of assert() that you wrote. (Usually assert() includes some information about where the assertion failed and so the definition will expand to include \_\_FILE\_\_ and \_\_LINE\_\_ somewhere.) My question is more about what should macros be replaced with in order to solve problems of text replacement. And if there are no solutions, then why do people hate them so much? (I have to imagine that the people who hate macros are probably using test and mock suites that use macros.)
&gt; #define assert(x) if (!x) abort() I agree with most of your comments, but this one isn't a valid argument. It can be easily fixed by changing it to: #define assert(x) if (!(x)) abort() Yes, I get you mentioned it was the "naive" implementation, but the same sort of gotchas with "naive" implementations bite templates and all other sorts of things and not just macros.
A fun little read. Thanks for sharing! 
For `__FILE__` &amp; `__LINE__`, see: http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n3972.pdf For protocols &amp; serialization, a code-generation approach with an IDL specification works really well (protobuf, thrift, etc).
I used to hate them, but I don't anymore. They are just a very powerful, very easy to misuse language feature. From a purely pragmatic point of view, they make me more productive, and they make my code cleaner. &gt;So my question is 'with what should macros be replaced that will still allow things to be written like assert(), test suites, and other uses?' First of all I don't think anyone is going to touch macros much due to backwards compatibility. I also don't see anyone proposing a second preprocessor any time soon. Having said this... In the cases you mention I don't see much point in replacing macros. For `assert`, they are just used for conditional compilation (`NDEBUG`). In the test suites, they are used to get line number, file, ... as a character string, and for text substitution. I think these usages are just fine. Still, as a general pourpose tool, some languages have improved them significantly. A big step forward are hygienic macros which make them safer to use (variables in the macro have local scope, they are local to the current header but can be exported explicitly, ...). I think Rust/Nim hygienic macros are pretty good, but lots of other languages have them too. Another step forward is making them more powerful, that is, allow them to interact with the type system, change the AST... In Haskell you have both macros and template Haskell. When you need conditional compilation, or plain old dumb pure text repetition, macros are there to help you.
Gotchas with templates fail safely. It could manifest as a performance issues or your code may fail to compile. The code still roughly executes what you intended without side-effects (a function-call arguments get evaluated before the call occurs). Macros fail dangerously: the code is obfuscated &amp; the code the compiler sees can be subtly broken in a way it can't warn you about (&amp; function call arguments get evaluated "after" the macro function is invoked. Yes, this example is simple. Yes, if you've been working with the CPP the problem &amp; solution is obvious in this example given that I showed you exactly what's broken. However, finding this bug can be time-consuming (cause &amp; effect can be very separate). It can also be easily introduced even if you're an expert &amp; just happen to be careless.
It's UB because it violates the aliasing rules. The hardware's behavior may not matter because the compiler can do pretty much whatever it wants. In particular it may conclude that this function can never be called and not emit any code for it. A proper implementation (which still depends on the hardware's behavior) is: float FastInvSqrt(float x) { float xhalf = 0.5f * x; int i; std::memcpy(&amp;i, &amp;xhalf, sizeof i); i = 0x5f3759df - (i &gt;&gt; 1); std::memcpy(&amp;x, &amp;i, sizeof x); x = x*(1.5f-(xhalf*x*x)); return x; } http://blog.regehr.org/archives/959 http://stackoverflow.com/questions/3275353/c-aliasing-rules-and-memcpy
Also a healthy dose of sexism. 
Also, a macro-less testing library is possible: http://mrzechonek.github.io/tut-framework/ It might require some boilerplate, be pretty ugly &amp; not necessarily offer all the features, but it's possible. I would imagine with some language extensions it could be possible.
I would expect he'd want to know about trying to avoid errors/crashes/etc - fault tolerance. I'd want to make sure you understand RAII and how they help with this. Also issues like exception handling. How can you avoid crashing if you get an exception while creating an object. What happens? How can you clean up? 
There is one macro that you will pry only from my cold, dead, hands. It appears on a high proportion of my lines of code (during development and testing, at least). I have a macro `PP` such that PP(x); will print the variable name and the value on stdout: x: 3.7 It can work with functions too: PP( foo(y) ); will print this: foo(y): "hi"; A macro is needed to convert the argument into a string suitable for output. I have extended it over the years to improve it, so that it can handle any number of args. Somebody might argue that macro names should be much longer, in order to avoid clashes, but I use this so often that I guarantee I would just put: #define PP much_longer_name_forced_upon_me_by_pointy_haired_boss Yes, it's easy to come up with loads of great reasons why macros are bloody awful, but there are a small number of problems that they solve really *really* well (compared to the alternative solutions).
I'm assuming you have a general grasp of C++ already &amp; want to know what some more advanced topics might be: * C++: Understand how rule of 5 (rule of 3 in pre-C++11) is the best way to write exception-safe classes. Understand why it's a good idea even without exceptions. * General: Understand the limitations of profiling tools (e.g. cache locality does not show up as a hotspot). * C++11, get a really good grasp of what r-value, x-value, l-value are &amp; what std::move/std::forward really do. This is probably the most difficult topic to truly understand at an expert level, but a workable understanding is possible. * C++11: &amp; and &amp;&amp; specifiers on functions. * C++14: decltype(auto) vs auto * C++11: auto vs const auto vs const auto&amp; vs auto&amp;&amp;. * General: thread-safety, general concurrency topics, atomics &amp; when they might be useful etc. * General: why should you prefer composition over inheritance? why should you restrict inheritance to pure-virtual interfaces. * C++11: what does override do &amp; why is it necessary? * C++11: what does final do &amp; how why is it important for compiler optimizations * C++11: variadic templates &amp; universal references * C++11: write a perfect-forwarding function (e.g. make_unique). * C++11: constexpr - when does it not work as you might expect? i.e. why is `constexpr int foo() { throw std::runtime_error(); };` `int main() { foo(); }` a runtime error instead of a compile error Having a good grasp of overall system architecture (why cache locality is important), available data structures (vector, unordered_map), iterators, inheritance (why can having parent classes implement virtual functions you override be an expensive operation, etc)
Uau! I guess I started in the Bronze Age then. Quite interesting.
A superior replacement would be something akin to Scheme's [hygienic macros,](https://en.wikipedia.org/wiki/Hygienic_macro) which provides a syntax-aware means of generating code at compile-time that doesn't interfere with the surrounding code where the macro is invoked. In the C preprocessor, everything is tokenized, and then includes and macros are expanded, replacing one token with several others. That, as we all know, leads to code that can be trivially broken in subtle ways when great care is not taken to avoid it. Hygienic macros *can't* have this problem, by definition, as they generate code in place that is syntactically valid. People hate preprocessor macros simply because they're too unintelligent, too syntax-unaware, and too prone to error.
This is really cool! I don't think any libraries for other languages have this, at least I haven't seen it.
RAII: object constructor allocates all object variables, destructor frees all object variables Exception Handling: class foo{ foo(){ try{ //allocate all variables// } catch(...){ std::cout &lt;&lt; "Error initializing foo" &lt;&lt; std::endl; } } ~foo(){//deallocate//} }; Would something like that be valid exception handling for this type of error? The program would crash later if the program tries to access "x", but the program doesnt crash during creation of the foo object, and you can give feedback there? 
I would be astonished if I heard most of those questions arise in an interview. The 'general' ones I can imagine, but C++14 calling conventions? Even if somehow it did come up I think I'd have to ask them why they thought that was important. 
I expect that you'll be asked about C++'s placement new. It's one of those things that isn't covered by Stroustrup's book, it's a basic requirement to develop highly efficient C++ code (memory pools), and it's one of those things that only the people who use C++ seriously in demanding applications ever have a need to know.
My friend made an interesting observation. A good interview makes the interviewee feel like the edge of their knowledge is being tested. This lets the interviewer know what the gaps are &amp; how important they feel they are. It does have the downside of stressing out the interviewee though if you don't prepare them. Knowing the difference between decltype(auto), auto, auto&amp;&amp;, const auto&amp;, T&amp;&amp; etc, tells me that you've had a lot of experience writing C++11 code. Even if you cop-out &amp; say "I stick to X because I haven't mastered Y yet" let's me know that you're at least aware that dragons-be-here &amp; you haven't yet gotten a chance at fighting them.
The only advice I can give you is to search the Internet for "interview questions at &lt;Company Name&gt;". Different companies and even teams within a same company have vastly different coding styles, expectations, experiences and therefore different interview questions. At some places, they will put you in front of a whiteboard and ask to solve a coding problem. At others, they will ask silly riddles to see how smart you are. There is no rule - all you can do is try finding someone who has interviewed with them in the past.
Interesting reference, thanks. std::source_context or something similar would be very nice to have here. And, yeah, IDL based code generation is a great approach - I'm using protobuf where I can - but some of the protocols I'm implementing are a bit _legacy_, and some ad-hoc code generation makes them much more pleasant to handle.
No. Exception handling does not mean "supress all exceptions". Exception handling means at the outer-most relevant scope, catch the exception &amp; recover. For example, if you're writing a file 5 functions deep into your callstack &amp; it throws an exception, and level 2 is where the overall operation is being performed, then you would catch it there because you can centralize all the exceptions (i.e. catch all file I/O errors, network etc) &amp; perform a recovery operation or undo any work. The reason you don't allocate any resources manually is so that when the stack is unwound to get to level 2, all the intermediary resources are freed correctly. Think of it like a database rollback transaction. Regarding your example, it's incorrect. You should only ever have two types of classes: Composite classes that have value member variables. These classes *must not* specify *any* of the default 5 functions (or *must* = default *all* of them). Ownership classes that own 1 resource &amp; expose value-like semantics. These *must* specify all 5 if they specify any *1* of the 5 default functions. For example, if foo is a composite class: class foo { std::unique_ptr&lt;bar&gt; _bar; public: foo() : _bar(std::make_unique&lt;bar&gt;(...)) {} }; Note how none of the 5 default-generated functions (3 prior to C++11) are specified: there's no destructor, no copy assignment, no move assignment, no copy constructor, no move constructor. We simply let the compiler automatically generate the correct things &amp; it will know that this is a move-only type because it contains a move-only type. Specifying a copy-constructor in this case might be tempting, but instead you are likely using the wrong type for _bar (maybe you want shared_ptr or something else). Let the compiler figure things out for you due to the semantics of the types of variables it contains. If you have an ownership class, presumably you will have a non-trivial destructor (you will somehow release your resource in the destructor). Thus you have to specify the other 4 otherwise-default-generated functions: move constructor, copy constructor, move assignment, copy assignment. You can delete them if you wish to disable moves or disable copies or both. Move-only types that own resources are usually *more* common &amp; valuable than ones that are copiable (e.g. what does it mean to copy a file descriptor &amp; is that something you would expect someone to do correctly?). I corrected the numerous bugs in the wikipedia page example code so it should be OK to grasp the important bits: http://en.wikipedia.org/wiki/Rule_of_three_%28C%2B%2B_programming%29#Example_in_C.2B.2B
That's a good one regarding the virtual destructor. I did put the disclaimer that these are all advanced topics. If you're applying for a junior position then you probably don't need most of these. If you're applying for a lead C++ developer, then maybe familiarity with at least some of them is a good idea. You never get penalized for knowing more than what you'll get asked in an interview.
I have nothing against ad-hoc code generation. It's far better than trying to do macro magic &amp; you can at least improve it as you need to. I've found macros to generally be unmaintainable.
why did someone downvote this? He's asking a frikkin question! Some people just don't understand reddit. The specifics of how you would handle an error in any particular situation are not really that important (although you may be asked about a specific situation). It's more important to understand the principles behind RAII, which is that when things leave scope they are tidying themselves up and freeing the relevant resources. The relevance of this to exception handling is that you cannot guarentee a nice procedural execution of your program, so resources must be cleaned up in a stack-unwinding friendly way, that is that when anything leaves scope it does not leave behind a mess of dynamically allocated resources.
That's a really neat trick. I'll have to incorporate that in my code. It took me a little while to process what exactly is going on, but once I understood it, this is genius. It's basically moving all the logging code elsewhere in the codebase so that locally you only have a single function call (i.e. if(log enabled) logThisMessage(...)) instead of having the compiler inline all the calls to ostream. This actually complements /u/andralex talk about the dangers of inlining: http://www.reddit.com/r/programming/comments/2jt5wr/mo_hustle_mo_problems_optimization_tips_by_andrei/ The other surprising insight on why this saves overall code size is that there's only so many combinations of 2 types that people want to log. I think this part only works if your linker is good enough to collapse all the duplicate types.
well you wouldn't get penalised for knowing the entire c++ standard off by heart, but I think that is slightly missing the point ;)
When doing HFT which is worse - being 5 ms late or crashing?
I wouldnt expect anything modern. Its mostly big legacy code bases and old programmers out there. So its probably low level C, and C++98 without STL, RAII or exceptions. Maybe you will get questions about the time complexity of some code. Optimise this code. Find this bug. Implement an algorithm for this problem, etc. Maybe some deadlock and memory leak questions. Tell me if im wrong.
Surprised nobody has mentioned this. One of the evils of macros is that they don't know about or respect scope (or namespaces). Its a primitive and dumb textual "find and replace all". They pollute everything. They leak out from one scope into another. From one library header into another. From a library header into client code and the other way. Causing havoc. There are many other problems. People use them because sometimes there is no other way. Eventually they will die. Once we have language features for every case where they are used.
Callbacks. Callbacks are huge now. It is just a pointer to a function.
Sure, but try using "min" or "max" in a Win32 environment without defining "NO_MIN_MAX". The problem is compounded further by C++ devs doing "#define blah xxxxxxx" instead of "const int blah = xxxxxx". It is made even worse when attempting to use a wrapped (or utilize multiple wrapped) C lib that exposes it's header in all its gory details, polluting not just the global namespace, but also the preprocessor (there is but just one preprocessor namespace). When you *do* have an issue, finding the cause is a major pain in the ass, because compilers don't emit the preprocessed source code, by default, and they only give the line/column in the *original* code where the fault occurred. So, for anything but a trivial macro, you're often left scratching your head. If you want an open-source example of macros gone bad, take a look at ACE. Every platform-specific nuance is if-def'd via various macros in every single function. It is very hard to wrap your head around what is going on, and you better remember exactly how you compiled the lib to begin with.
Does `-std=c99` or `-std=gnu99` not do that?
Nowadays I think that placement-new is the only new that is acceptable in a codebase. If you want to allocate stuff yourself use an allocator.
My really brief history of C++: In the beginning, programming was sane. Then, C++.
if its a real hft shop, the code is going to be modern and cutting edge. 
I worked in algo trading and HFT for ten years before leaving for a silicon valley firm a few months ago. I interviewed a lot of people, though none in recent memory were just out of school, and there is a lot of relevant material I wouldn't expect them to know. Multi-threaded concepts are going to be very important. Atomics, locks, issues with different designs, how to make things thread safe. Cache locality is another huge thing these days. What is cache locality- how do multicore systems ensure their cache's are in sync? How do you get around this problem? Asynchronous architectures and callbacks are what you will be dealing with every day. Why are signals slow and why is context switching bad? What exactly happens during a context switch? Something that doesn't even appear on your list are OS and network concepts. TCP/IP and ethernet aren't really used on these systems, but I wouldn't expect you to know about Infiniband or other more exotic stuff like Melanox cards out of school. Understand tcp and udp, how can you maximize performance out of a socket? What is user space and kernel space? Do you know what epoll is? How about rdtsc and microsecond level timers? What modifications would you make to the kernel to tune it for low latency? I personally always wanted to see that the candidate was always honing their craft and on the cutting edge, so I would ask about C++ 11/14. I tended to focus on questions like perfect forwarding and move constructors. auto sure, lambdas for me not so much, they are really just sugar IMHO, but you never know who will be on the other side of the table and they may love them. I also liked to ask questions about the recent major releases of gcc and llvm, which the candidate liked and why. Another example of an open ended differentiating question I would ask is "what feature didn't make it into C++14 that you really wanted to see?" (though for someone still in school, I would probably change that to what is your favorite feature of C++11 of C++14) Yeah and then there are your basic C++ questions. Any of them are fair game, though in general there is a shift towards templates and generics and less so on heavily object oriented design. Know the basics of STL and iterators, though these aren't used that heavily anymore. Understand SFINAE and be able to write templated functions. Really popular questions these days are about smart pointers. What are the different types, how would you code a boost::shared_ptr or std::unique_ptr (Hint- you have to have a separate reference count object instantiated on the heap) Its unlikely they will ask much about exceptions. HFT rarely uses them. One last thing is be prepared to write code. We often asked candidates to write a container type or sort algo on a whiteboard or piece of paper. So remember your merge sort, quick sort, binary search, etc, and be able to write them cold. Good luck!
Note that a lot of C++ pros can't answer all these questions, as they aren't needed in all domains. Whatever happens in the interview, don't feel bad or defensive about what you know, but confident in your potential and humble in your knowledge. C++ is the sort of language that you'll be reluctant to ever call yourself a master in, even 20 years in, and candidates who claim to know it all usually know the least. If you don't know an answer, say you don't know for sure and then try to guess.
Testing, QA, continuous integration, bug tracking, unit-testing, product management, playing nice with others, integration-testing, revision control, documentation best practices, profiling, static analysis, network handling (latency, latency, latency), ops, post-mortem debugging. Did I mention documentation? Oh, and probably some C++ stuff too.
If they had a few years experience, I would actually expect them to know pretty much everything above, plus knowledge of financial markets, these are elite groups. But yeah for an undergrad, I would focus on the basics and just keep probing to keep where you break. That's important to understand- they are going to keep asking questions until they find your limits, so are you going to leave feeling stupid. 
Which book do you mean? In PPP, he at least makes you look it up for an exercise somewhere. And I'm pretty sure he covers it in TC++PL4, no?
Thanks for bringing this up; I hadn't heard of this before. I always wondered how manual memory allocation worked using C++ methods.
Macro's are essentially a really basic refactoring tool, I imagine that as clang's libtooling matures and general purpose refactoring tools are created in it, that they will essentially take a form very similar to macros. Except they will allow you to target very specific code substitutions that are syntax aware and type safe. In the end I imagine they will be very similar to how current preprocessor macro's work in terms of usage, they will just be easier to deal with once things go wrong.
&gt; What modifications would you make to the kernel to tune it for low latency? Is this really ever done? Perhaps I've just drank to kool-aid that the linux kernel is configurable enough that you would never have to do this.
From my experience (eight years in the Bay Area, CA) very few people ask C++-specific things in interviews. When they do, the usual topic is virtual functions. Sometimes people ask about in-memory class layout and member function calls. All interviews I have ever been to ask things about algorithms and data structures. IE invent something for doing X, then optimize for Y, etc. These things would look pretty much the same in any lower-level compiled-to-bare-metal language.
They are now that we have lambda syntax in the language. But if you're stuck with an older compiler/platform, then it's bye-bye std::function, and hello Boost "functor" structs/classes.
&gt; if you include windows.h (which declares an absurd number of macros with very common names), a bunch of standard library functions like std::min can no longer be called. That situation is so comically bad that [Boost was fed up to the point of writing their own private Win32 API headers](https://github.com/boostorg/winapi).
+1, even if it's not quite college-level material, it's a good general list: I've been asked and I keep asking many of these myself (plus exceptions of course) even in non-HFT finance. Shows what to look forward in near future.
I found [1] and [2] that both give some hints for uses of placement new. Can you point to any additional information? I have seen it being mentioned once or twice in the context of performance and allocators, but never found anything really specific/in depth. [1] http://www.parashift.com/c++-faq/memory-pools.html [2] http://stackoverflow.com/questions/222557/what-uses-are-there-for-placement-new
another thing that isn't mentioned here is that it duplicates code. #define LOG(x) if (x) { printf("%s", x); } LOG(some_function()); some_function will be called twice, while using another function instead could let the compiler inline the call. In your assert example, it could be a problem if you assert(function) to check the returned value.
Part of the "trick" is the use of the no inline attribute. So a small remark: You can actually mark a lambda as `[[noinline]]`. That is, you can, cleanly and locally, prevent any block of code from being inlined. If you know that some code is cold, you can help the inliner tremendously with minimal effort. This is useful, for example, within hot functions where there is a big cold code path that almost never gets called.
That’s no excuse for bad code. “simple” ≠ “bad”. Since it’s apparently not obvious: the boolean literals are entirely superfluous in these expressions and represent an instance of [cargo cult programming](http://en.wikipedia.org/wiki/Cargo_cult_programming). If I were *really* nitpicking I would also criticise the use of `rand`, which should be considered deprecated in favour of the `&lt;random&gt;` header.
 //must have its own scope #define SWAP(x, y) {auto tmp = x; x = y; y = tmp;} //Macros 101: wrap the variables, always. #define ASSERT(x) if (!(x)) {abort();} //Additionally, I have put them in all caps to avoid naming problems. only possible issue is redefining SWAP and ASSERT within the same project. Usually you should use distinctive names, specially within a library. Macros are dangerous when used wrong. Like pretty much everything else. One should be specially careful with them, and if you can't be that careful, don't use them. In addition to this, macro problems usually happen at compile time (specially if you're aware that you must wrap the variables, which is the common run time problem), so they are easily noticeable. Other things like pointers used wrongly can cause more serious problems that can go unnoticed for a long time.
 #define DO_THIS(condition) if (condition) { dothis() } else { doSomethingElse(); } if (foobar) DO_THIS(otherThing) Woops - there's yet another runtime error (granted, AFAIK, this is the last class of runtime-errors that I know for macros, but I don't pretend to know every possible way it can fail). Yes, you can write macros safely if you know what you're doing. It still is really easy to make mistakes. So the runtime problems are easy to make (especially if you're tired while writing or happen to be careless momentarily). Even when it's not a runtime issue, debugging issues in macros can be an exercise in masochism.
For windows.h: http://www.suodenjoki.dk/us/archive/2010/min-max.htm 
I also have as a rule that if I ever need to put sentences in a macro, always wrap the whole thing in brackets. But usually one shouldn't use a macro for that. And yes, if you do anything complicated in a macro you have to stop and think what could fail. Usually it's a matter of isolating everything. Anyway, I'm not advocating for macros as an everyday tool for everything. Usually there's better, cleaner solutions and inlining can make it almost the same thing for cases like this. But sometimes macros can save a lot of tine and even make your code cleaner.
Every windows project I build starts with adding defines for VC_EXTRALEAN, WIN32_LEAN_AND_MEAN, and NOMINMAX to the compiler switches. It is comical and sad at the same time that I have to do that. 
SWAP is still broken in a few ways that are not obvious until you try them. int a = 1; int tmp = 2; SWAP(a, tmp); // compiles, but does nothing if (a) SWAP(a, b); else // Error: expected a statement b = 0; std::unique_ptr&lt;FOO&gt; a, b; SWAP(a, b); // Error: attempting to access a deleted function std::vector&lt;int&gt; foo() {...} std::vector&lt;int&gt; bigVector(5000000); SWAP(bigVector, foo()); // Calls foo() twice, and makes unnecessary copies of the bigVector.
I don't understand why this would be downvoted. Op asked what he can expect at an HFT firm interview, and I was using my decade of experience to tell him what is expected. You may not like it, but that's why you don't work at an HFT firm. Doesn't make the answer invalid. 
I meant configurations, not actual code changes. Sorry if that wasn't clear. At the firms I worked for, no we never actually patched the kernel for our uses. Some firms reportedly did though, in the network stack area. 
Twice I've been asked these ones: * stuff about virtual functions, how does vtable work (maybe for multiple inheritance as well) * constructor/destructor ordering * the well known example with pass-by-copy but with pointers * in the code snipper make sure there are no memory leaks EDIT: bullets
I have something very similar with macros, you can do it a bit simpler: (https://sourceforge.net/p/cppregpattern/code/ci/master/tree/registry.h)
[The Fall of Conceptinople](http://www.informit.com/guides/content.aspx?g=cplusplus&amp;seqNum=441)
Yes, and we are discussing when it's "reasonable" to use macros - and the answer is "almost never".
It's not really fair when someone asks, "What should I do?" and you reply with a language feature proposal, which isn't even guaranteed to ever be adopted, and if it is, won't be available to the applications programmer for years.
Most compilers support #pragma once.
&gt; you'll be reluctant to ever call yourself a master in, even 20 years in As an entry level person I agree 100%, which is why I hate when interviewers ask me "From 1 to 10 how much C++ do you know?" I mean what is the benchmark for a 10?
You can make callbacks in older versions of C++... it's just a little more involved. I don't generally use Boost - though I know its common... and have used it. 
&gt; Regex (only useful pre-C++11) Boost.regex is Unicode-aware, C++ regex not so much. Likewise other boost alternatives have improved since C++ forked them. Even something as basic as threads.
:-) OK. First, to clarify how it is used. PP(foo(), a.bar(3)); will print: foo(),a.bar(3): 17, hi assuming that `17` and `hi` are the return values of those functions and methods. There are two parts to this: #define PP1(x) do{ std :: cout &lt;&lt; #x &lt;&lt; ":" &lt;&lt; (x) &lt;&lt; std :: endl; }while(0) #define PP2(x,y) do{ std :: cout &lt;&lt; #x &lt;&lt; ',' &lt;&lt; #y &lt;&lt; ":\t" &lt;&lt; (x) &lt;&lt; " , " &lt;&lt; (y) &lt;&lt; std :: endl; }while(0) #define PP3(x,y,z) do{ std :: cout &lt;&lt; #x &lt;&lt; ',' &lt;&lt; #y &lt;&lt; ',' &lt;&lt; #z &lt;&lt; ":\t" &lt;&lt; (x) &lt;&lt; " , " &lt;&lt; (y) &lt;&lt; " , " &lt;&lt; (z) &lt;&lt; std :: endl; }while(0) #define PP4(x,y,z,w) do{ std :: cout &lt;&lt; #x &lt;&lt; ',' &lt;&lt; #y &lt;&lt; ',' &lt;&lt; #z &lt;&lt; ',' &lt;&lt; #w &lt;&lt; ":\t" &lt;&lt; (x) &lt;&lt; " , " &lt;&lt; (y) &lt;&lt; " , " &lt;&lt; (z) &lt;&lt; " , " &lt;&lt; (w) &lt;&lt; std :: endl; }while(0) #define PP5(x,y,z,w,v) do{ std :: cout &lt;&lt; #x &lt;&lt; ',' &lt;&lt; #y &lt;&lt; ',' &lt;&lt; #z &lt;&lt; ',' &lt;&lt; #w &lt;&lt; ',' &lt;&lt; #v &lt;&lt; ":\t" &lt;&lt; (x) &lt;&lt; " , " &lt;&lt; (y) &lt;&lt; " , " &lt;&lt; (z) &lt;&lt; " , " &lt;&lt; (w) &lt;&lt; " , " &lt;&lt; (v) &lt;&lt; std :: endl; }while(0) But you can't call these directly - if you do, you'll get the incorrect variable names. Instead you need these macros to count the number of arguments and select the right one for you: #define GET_ARG_11(_1,_2,_3,_4,_5,_6,_7,_8,_9,_10,N,...) N #define COUNT_MACRO_ARGS(...) GET_ARG_11( __VA_ARGS__, 10,9,8,7,6,5,4,3,2,1,I_CANNOT_SEE_ZERO_ARGS) #define SELECT_PP_IMPL( n ) PP ## n #define SELECT_PP( n ) SELECT_PP_IMPL(n) #define PP(...) SELECT_PP( COUNT_MACRO_ARGS(__VA_ARGS__) )(__VA_ARGS__) When I want to use more fields I just define `PP6` and `PP7` as needed, and so on. I think I'm up to `PP11` now. All credit to someone on Stackoverflow for showing me how to count the args.
I've been browsing around a couple of various chapters and they look really good! It's gonna be a very valuable resource :-)
Thanks OP, and happy cake day!
cromissimo was probably being downvoted because they're wrong that Stroustrup doesn't cover it.
Yes, they are great.. Does everyone not already know about them?
I'd say it's probably not about awareness but rather having another resource on how/when to use them.
Oh.. I didnt notice its a actually a new resource.. I thought it was just a link to the normal Boost site, however now I remember that that is boost.org.. Yes, this resource looks great!
Wonderful, I always was a bit afraid of boost and only used it when I had a problem and someone told me "this specific boost library can solve your problem"; now I can really understand the goal of each. 
Boost.regex is Unicode-aware only if you've compiled the library (regex is normally header-only) &amp; you happen to have ICU available on your platform. For the majority of cases, the STL is still the better option: 1. Backwards compatibility is much better than with boost (for example, optional had a breaking API change recently). This does vary across the entire boost codebase. 2. No 3rd-party compilation needed (neither of boost nor of ICU) 3. You can omit boost &amp; ICU as compile-time &amp; distribution-time dependencies. Yes, there are cases where boost regex is better (unicode support if you need it). At least for libc++, I've found it to be faster &amp; have an extended API. However, it's also largely drop-in-compatible with C++. My point is reach for the STL features before you take on boost (walk before you run). I'm not aware of any improvements in boost threading over C++11 threads - can you list some? I'd be interested to know.
Market data is almost entirely using infiniband, which uses RDMA. In larger shops, where there are hops between the order generators and downstream gateways, there is some use of this for shipping messages around internally, though its more common to see something like 10 gig Ethernet for anything that is going to interface externally.
This is really advanced C++ (SFINAE, what didn't make it into C++14?, ..etc..) and high performance programming (epoll, rdtsc..). I'm pretty sure 95% of the C++ programmers in the world don't know about SFINAE for example. So I'm curious about which company asks this kind of questions? (I know you said HFT industry, but could you be more precise?) 
There are indeed C++ programmers who are unaware of Boost. I remember when I started a job years ago and I was quite surprised to find several programmers there who hadn't heard of it. They knew the language fairly well but seemed to be pretty much entirely cut off from the wider C++ community; unaware of common terminology, trends and community best practices in general. That's unfortunate, considering how much our knowledge of C++ has improved over the years; we can write much better code using even C++98 today than we could in 1998, because we've learned much better practices and techniques. And that's all done through community engagement. I suspect that the industry is full of many pockets of such programmers.
You code compiling to fast? Now you can quadruple your build time by using boost!
I took a job once and ran into C++ experts that didn't know about Boost. They also didn't know what an initialization list was though.
Self proclaimed experts I'm guessing. Although It seems to me how much someone claims to know C++ is inversely proportional to how much they actually know until they get to the compiler writing stage.
well... its HFT, these firms are small groups of very smart people, the bar is very high. These days HFT isn't as lucrative as it was, but it was about 5 years ago, so it was quite literally the best and the brightest. Example firms: Knight/Getco, groups at MS, GS, CS, JPM. Sun Trading, Hudson River, Renaissance, volant, and many other small names you wouldn't know unless you were actually in the mud doing this stuff. (I am guessing your real question was some names of HFT firms to look up ;) ) 
1) small terminology detail: linked lists typically use the terms "head" (or "root") and "tail", not "first" and "last" 2) I really don't like how you mix references and pointers inside LinkedList.h. I know you had some comments somewhere talking about your preferences for reference, but I think all "Node" manipulation should be via pointers. Just IMHO. I'm talking about code like this: node.setNext(*first_); first_-&gt;setPrevious(node); 
Does Boost ever deprecate and remove? I mean when new language and standard template features are released, many modified only slightly from boost, the slight variation between boost and standard only serves to clutter the boost library making it less accessible to beginners. At what point does Boost modify their internal usage of libraries to standard version to de-clutter to allow for removing features like, regex, chrono, for_each, lambda, etc...
Probably after c++11 is adopted by most users. Even today, c++11 is not the default in most compilers. You have to explicitly specify in command line. 
Don't use per-member-function locking. That's a pointless abomination.
There is nothing about making games that should prohibit you from using exceptions.
Vector isn't a cure-all either. It really depends on the usage. You need to factor in the amount of data, the flow and operations you'll be doing on the data. Using unique_ptr for the node pointers is good advice.
I've never gone wrong with saying 7 or 8 because I know how much there is to know and probably so much I don't know. Being humble never seemed to hurt.
I'm not sure I understand. CommandPool::register takes a const Command&amp;. You are passing it a return_e (*)(const command_parameters&amp;). How is that supposed to work?
You can use a do while to get around the second issue, and creative naming to get around the first: #define SWAP(x,y) \ do { \ auto x##y = x; \ x = y; \ y = x##y; \ } while(0) I think you can also wrap the right side of the assignments with std::move to avoid the other two issues. You might have to include move's header to avoid compilation issues there, though. 
From Boost.Variant &gt; With C++11, the requirements for union were relaxed. I wish I knew this before I started a very big and lengthy implementation using std::string*
regarding threads, boost has barriers, thread interruption, timed join, thread_group, and thread attributes. There are many small helpful tweaks, like the overload of lock() that takes an iterator pair. (looking now, I am seeing things I didn't see before: scoped_thread, strict_lock, make_unique_locks.. it's certainly getting attention!)
Depends what part you're using. If you just use smart pointers or variants, it won't. If you use one of the parts that is heavy on template metaprogramming like Spirit or MPL it can get very slow.
Ah. I'm mainly on iOS these days, so I'm dealing mostly with dispatch queues which have all of that. Good to know though. Thanks.
Actually there are many things that do, particularly for console development. Speed and code size for one. Program complexity, extra error handling code, code written to be more fault tolerant because exceptions can't be thrown, they create "invisible code" making it harder to reason about what could be going on in a piece of code, they create unseen exit points in functions. I have never worked at a place that used exceptions nor has it even been a topic of debate. Stl, lambdas, smart pointers, templates, rtti - fine. Exceptions no.
The person who chose those font colors should have their eyes gouged out with a spork.
That person is me and I think I messed up some CSS. Its supposed to have a darkish background.
Why does Node need to be an abstract base and have a factory? What problem is this solving? Your iterator doesn't qualify as an iterator. You need a whole slew of typedefs, template specializations, etc... Have you checked what happens when you try to copy one of these lists? For a beginner it's not the worst I've seen. In fact it's as good or better than some "professional" C++ I've seen. But keep studying.
It doesn't actually work out that way though. Perhaps if you are always inserting at a point you already have figured, but in general the navigation to the insertion point far outweighs the speed of avoiding the moves forced on you by vector. While the list navigation has random memory access patterns, the vector move has a very specific and predictable access pattern that plays quite nicely with modern hardware. I would suggest setting up some tests to measure the performance. We're all taught that lists are supposed to be faster, but that is quite ancient advice. College courses on data structures have not done well in keeping up with the times.
Yep.
I tried to Google "per member function locking" and couldn't find a simple explanation (I am kinda new to C++). Care to elaborate, please?
That's why you also use a map to get constant time searches! Granted the only time I've done this is when implementing an LRU replacement algorithm.
When I did this for implementing LRU, I also maintained an unordered_map to get constant time lookups in the list.
One thing I would suggest implementing is a short pause at the start and after losing a life. Sometimes when you start a new game an obstacle will be directly in front of you, and unless you have ninja reflexes you are going to hit. Same with after losing a life... would be nice to have a second to re-orientate yourself as to where you are spawning and whatnot. Cool game though, would be nice to see the source code but I am guessing you are not willing to release it.
This was already posted about 6 days ago here (with http instead of https)... http://www.reddit.com/r/cpp/comments/2k4lng/locks_mutexes_and_semaphores_types_of/
That makes sense. So basically something like this: Thread 1: std::lock_guard&lt;std::mutex&gt; LockGuard(mv.GetMutex()); mv.PushBack(11); // One mv.PopBack(); // Two Thread 2: std::lock_guard&lt;std::mutex&gt; LockGuard(mv.GetMutex()); if (!mv.Empty()) { // A int x = mv.Back(); // B mv.PopBack(); // C Use(x); } 
Your iterator looks bidirectional but isn't quite. Technically, it lacks a bunch of typedefs and such but that's no big deal. A bigger problem is that decrementing a past-the-end iterator should work (if the list isn't empty, of course) but your implementation will dereference a null pointer. 
So why not just store it in an unordered_map to begin with? 
To fix the double evaluation problem, you need to assign both to references, before doing the swap. I don't think you need to include anything for std::move, because that's just a cast to a temporary value. Although, we've now spent a lot of effort solving problems that do not occur with a templated function (i.e. std::swap). And that's why macros are bad. Not because they can't be used well, but because it's easy to use them badly.
This was invaluable for me when I was writing an event system. The relaxed union rules allowed me just wrap each event in a simple struct to store in a event queue.
I would say until there are C++17 compilers and that feature is part of the official standard, it is a moot point to talk about it in a introduction to what modern C++ is about.
Already implemented in Clang 3.5 and MSVC 14 CTP. But even without it, `std::for_each` is not progress compared to C++11 range-for.
Fixed here: http://uint32t.blogspot.ca/2014/10/a-walk-through-cool-code-generation.html
There is undefined behavior in the final version (slide 210 and following): You must not write to std::cout from multiple threads without appropriate synchronisation. Also: Passing the launch-policy explicitly is only needed, because of libstdc++'s and libc++'s extremely poor implementation of `std::async`. Maybe that should be mentioned too. And finally there is no need to include `&lt;functional&gt;` if you just want to use lambdas without saving them in a `std::function`.
&gt;Concurrent access to a synchronized (§27.5.3.4) standard iostream object’s formatted and unformatted input (§27.7.2.1) and output (§27.7.3.1) functions or a standard C stream by multiple threads shall not result in a data race (§1.10).
Sorry I missed the discussion. I'm watching the talk now and it's intensely interesting. Gor's only contender for best talk is the one Herb Sutter gave on lock-free programming, as far as I'm concerned. Besides C++ I do ruby programming as well, where yield is an ingrained idiom. I thus have no problem at all seeing how to put this to good use in C++. Looking forward to it! I do have questions though: What would happen if an await call never returns? Is there a system from recovering from that? Also: it appears to me that co-routine calls are disconnected; I mean there's no reason to assume that an await/yield gets called immediately. As long as the local execution flow is respected, the call can be abritrarily suspended. So I'm wondering, is the intention that there is some form of scheduling underwater for co-routine calling? If so, would this be part of the standard or up to the implementer?
ok, interessting. In that case you still have a high-level-race though, because a valid execution-order is 1. print string literal 2. print i 3. print std::endl from i 4. print std::endl following the literal I admit, that this isn't nearly as bad, but it should be avoided nonetheless. And it would btw. have given a great opportunity to show `std::unique_lock` or `std::lock_guard`.
&gt; I guess it depends how deep one wants to go into functional programming when coding in C++. It is still great progress, if you just have the iterators of course. Otherwise it really depends: Using it with lambdas is a bad idea, but just executing an existing function with all values from a range as argument: That really depends on your preference. One advantage of `std::foreach` is that when we get parallel algorithms, porting them might be somewhat easier.
So there is a scheduler; Gor mentions it round 25:00. I was too early with that question.
This is my experience. C++ interviews have been typically capped at C++98 and focus on the typical interview questions like data structures sorting etc. Usually you'll get bonus points for talking about modern C++ but you won't get a chance to use it.
Looks like a variation on [X Macros](http://en.wikipedia.org/wiki/X_Macro).
Cannot recommend those books enough. Also check out ["Beautiful Architecture"](http://www.amazon.com/Beautiful-Architecture-Leading-Thinkers-Software/dp/059651798X)
The macro should be: if (!s_bLoggingEnabled) {} else xyz such that in code like "if (e) LOG("a"); else ..." the else binds properly. I'm surprised nobody mentioned that in the Q&amp;A. Also, the use of &lt;&lt; is actually an antipattern so dedicating code to supporting it is a net negative. Using comma with variadics would have been both better and easier to implement.
Likely the same way I did: via other research into programming techniques to solve some problem. In my case, I believe I was looking for a convenient/elegant way to initialize mappings of enumeration values to printable strings.
General osmosis, can't remember any specific place. The "C Programming" wikibook has an entry demonstrating [this exact technique](http://en.wikibooks.org/wiki/C_Programming/Preprocessor#X-Macros). The `#undef EXPAND_EXPAND_STAR_MEMBER` at the end is a nice touch. I really wish we had compile-time reflection, but until that day (c++2x?), X macros have our backs. :)
It's nice to put a name to the technique. "X Macro" is hardly descriptive, but googleable enough. I was half expecting it to be related to X window managers!
I usually say that std::for_each() is the STL's least useful algorithm. Its only real virtue is that it's able to unwrap iterators behind the scenes, and that only matters in VC's debug mode these days.
It is actually possible for characters to be interleaved; each op&lt;&lt; is not guaranteed to be executed as an atomic unit.
Using a shared_ptr/weak_ptr for the links is 1) abosolutely unnecessary, 2) a big performance hit.
Because you can't implement LRU with just an unordered map unless you add overhead and iterate over the entire map. There is no useful relationship between adjacent entries in a map.
Unused variable warnings ought to be heeded, though. If you have an unused variable in your code, it can lead to confusion and it results in additional worthless memory usage on the stack. Moreover, in the case of unused arguments, it results in copying over a value that ends up never getting used. If you have a function where you need it to ask for a certain type of argument even though you never use that argument (this can happen pretty common with the virtual functions of classes), then all you have to do is remove the name of the variable from the function declaration while leaving its type in place. This tells the compiler that you won't be using that variable and therefore it doesn't need to copy a value over. Also, I realize that you probably know all of this; I just thought it might be worth sharing for anyone else who comes along reading this thread and isn't aware of this practice.
unordered_map map is almost as bad as list, for cache misses. These days nothing beats contiguous memory. So std::vector always (almost). Also sorting a std::vector and doing binary search, is most often faster than std::map. Which is a bit of a surprise. More about it here: https://www.youtube.com/watch?v=fHNmRkzxHWs 
It's a O(n) algorithm for a vector, vs O(1) for a linked list. You'd need to have very few elements for cache efficiency to win out.
Yes, the preprocessor trick itself is not very impressive. The file generation step, however, is way more impressive; tlbgen defines a very good system to succinctly express lots of things. C++ attributes may seem lightweight, but tblgen is also used for: - all the diagnostics that Clang may generate - describing the various CPUs (their registers, instruction sets, etc...) that LLVM generates stuff for That in general the dedicated tblgen plugin generates a X Macro like file is some kind of an accident, it can actually generate anything since you write the plugin.
There has been talk of [buffered output for streams](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2013/n3750.html) which would avoid the high-level races.
It is needed because you need tool to make sure you don't break shit. You need to be able to modify and existing DSO to fix bugs. If not what's the point of DSO and why not link all static. And why would you fix bugs? Because they have an overall impact on the safety of information systems: bugs can cause crashes, security vulnerabiltiy, serious computation errors, etc.
My own company is still stuck at gcc 4.3.2 (conscious choice to settle on a pre-C++11 for maturity concerns) on the way out of gcc 3.4.2 (a couple leftovers). When it already works, there is little incentive in trying to change something... and potentially break it.
Lookup is O(n) for a linked list, and every step in the traversal is a cache miss (pointer indirection). There are very few cases when you don't need to lookup or traverse a list. What is surprising is that today often "worse is better". That is hardware cache friendly memory layout (of a data structure), is a more important factor than abstract time complexity. Today we the bottleneck is slow memory bus, not slow CPU. I recommend watching the video. Its very interesting.
Interview questions I've seen: - difference between struct &amp; class - overloading - multi-threading &amp; mutexes - Recursion - RAII - inheritance/polymorphism &amp; dynamic_cast vs static_cast - STL &amp; Boost Though I'll say I HATE phone interviews, especially when they ask you to "fix the following code" as they read it line by line. F that. 
And here I was thinning Clang was literally using some unknown trick with "sizeof(uint32t)".
False advertising
Erase-remove to filter followed by sort? You might as well skip the erase part and sort the partitioned subset of the container: auto end = std::remove_if(begin(container), end(container), myfilter); std::sort(begin(container), end); std::for_each(begin(container), end, transmit_item); I suppose it doesn't really matter if the container's lifetime is about to end; all elements will be erased shortly one way or the other. This does have the disadvantage of not being able to use the range-based for loop. Certainly things would look better and work more fluidly if the standard library had been implemented with ranges instead. Also, I really don't think you want to be writing a function that takes `T &amp;&amp;` where `T` is a template type parameter and where the function isn't forwarding the arguments. When it was written as `std::vector&lt;int&gt; &amp;&amp; log` only a modifiable rvalue reference would work, so either you already have an rvalue or you have an lvalue and you must use `std::move` and you are signing the dotted line of the contract that says you're okay with never using this object again after this. That's sort of unconventional (in the sense that you'd expect there to be a const-lvalue-ref overload that copies because eventually you're going to want that), but at least somewhat justifiable. However, with `T &amp;&amp;` now it will bind to anything, including a non-const lvalue without `std::move`, and that's dangerous as hell, because it's going to go ahead and modify the object whether you signed on the dotted line or not. That's asking for trouble. (Also, you can leave off `std::` on `std::begin` and `std::end` due to ADL. I'm not sure that's something that should be done in example code or not.)
If he is smart then he will test you coding skills before anything else, probably some simple thing on paper. Knowing about theory is important but if you can't code then you can't produce.
Except your Person object includes your logging object which includes a bunch of TMP. What is interesting though is that now the developer of the Person object knows everyone who uses it which is even more valuable (i.e. you know all the things that will be affected by a change).
&gt; Also, I realize that you probably know all of this; I just thought it might be worth sharing for anyone else who comes along reading this thread and isn't aware of this practice. Fair enough. I agree with all you said.
It's not just the cache, the prefetcher also has a major impact here. Herb Sutter compares it to having a cache that is infinite in size. I have never actually measured the performance myself, but there are numerous experts who have. They show a linear search through a vector being almost as fast as a search in `std::map`. Bjarne tried to find an upper limit where list won out and found none.
You forgot a 4th method of keeping threads from stomping on each other: immutable data. This usually still requires some sort of reference counting mechanism if you're passing around this immutable data, but if its in global scope/lifetime even that's unnecessary. At any rate, that is pretty simple to facilitate and then basically ignore. Never writing to shared data is my personal favorite way to deal with MT issues. In fact I like to push the fact that data is even shared behind a value object so different threads of execution look like they're working with independent values. Way easier to reason about that way. Not always possible though. Sometimes it is just not the right answer. I find though that being as close to pure-functional as you can get is quite often the easiest and fastest approach. Making copies of everything all the time seems expensive, and for any one thread it is, but it often scales better than the alternatives. I would also add that anyone wishing to get into MT in C++ should buy [Wiliams's book](http://www.amazon.com/C-Concurrency-Action-Practical-Multithreading/dp/1933988770/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1414707527&amp;sr=1-1&amp;keywords=c%2B%2B+concurrency+in+action). He does pretty good at explaining the kinds of issues you're talking about and showing what it takes to make a thread safe container interface...it is doable but they're pretty different from the non-safe versions.
It's more impressive but less generally useful. I wonder if there is a tblgen equivalent in python. I could make use of such a thing.
What compiler were you using?
There were changes in both C++03 and C++11, and there are some defect reports which may end up in this being changed again. Also, not all compilers have faithfully updated their behavior for every revision. The bottom line is that you probably shouldn't rely on the behavior of not specifying an initializer for a POD object.
Dude you're just comparing a best case for exceptions versus worst case without them, this is hardly a fair comparison. Also you could write the first version much cleaner and use non-retarded return values ;) But my point is why not build the system so you can write this: void DoWork() { f1(args); f2(args); f3(args); } 
Well, if DoWork() returns void, I assume by that you it is obligated to resolve errors it encounters? So for error codes, you'd instead have: void DoWork() { int errorVal; errorVal = f1(args); if(errorVal &lt; 0) handleError(errorVal); /... } Or alternatively: void DoWork() { handleError(f1(args)); /... } Or am I misinterpreting what you meant?
mingw g++, 4.8.1 on windows. Shame I didn't save those error messages somewhere :/
No I meant often using exceptions means you need to handle errors that shouldn't even be possible or might not be necessary In most cases the return values are not error codes but results. Most functions and systems are architected to not return error values but just do work. The functions then become void f1(args); and then you can legitimately write void DoWork() { ... f1(args); f2(args); } I also prefer error codes over exceptions because then I know when I need to handle them - and I know that just from the function signature. Otherwise I need all this exception handling code "just in case".
http://img1.wikia.nocookie.net/__cb20130710154045/cardfight/images/thumb/6/60/Facepalm.png/463px-Facepalm.png
I will totally do that, **IF** you either champion it or find someone else who champions it. Unless one of the next meetings is in Karlsruhe or at least another town in south-west-Germany, visiting meetings personally is totally out of question for me, as much as I dislike that. But I am a student and I don't have that much spare money. So again: If someone would champion it, I would definitely write it. 
I know, but they are not used in the slides. ;-)
When will it support code complete for std::unique_ptr?
Another way to do a similar idea is to use Boost preprocessor. It lets you define macro-world data structures: #define MY_SEQUENCE (one)(two)(three) #define MY_LIST (four (five (six, BOOST_PP_NIL) ) ) And then use the appropriate for_each to apply a macro to each. So for example, #define MACRO_ONE(r, data, elem) int elem = data; #define MACRO_TWO(r, data, elem) string elem = "data"; BOOST_PP_SEQ_FOR_EACH(MACRO_ONE, 1, MY_SEQUENCE) BOOST_PP_LIST_FOR_EACH(MACRO_TWO, hello, MY_LIST) becomes int one = 1; int two = 1; int three = 1; string four = "hello"; string five = "hello"; string six = "hello";
Ok, gimme a break. First off the vast majority of functions in a code base that supports exceptions are not declared as noexcept. Second you can't see from a function signature the ways in which exceptions could be thrown while in that function. I also don't get your point about poorly written function signatures. I was saying that because I can look at a function signature I understand how it is supposed to be used. I don't get that information when using exceptions (besides the fact that an exception could be thrown). And why are you suddenly talking about returning references? And removing confusion (what confusion again??) by returning const references??? I think this thread has gone on too long. It's been fun. Ciao.
Ever heard of [Precompiled headers](http://en.wikipedia.org/wiki/Precompiled_header)?
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Precompiled header**](https://en.wikipedia.org/wiki/Precompiled%20header): [](#sfw) --- &gt; &gt;In [computer programming](https://en.wikipedia.org/wiki/Computer_programming), a __precompiled header__ is a ([C](https://en.wikipedia.org/wiki/C_(programming_language\)) or [C++](https://en.wikipedia.org/wiki/C%2B%2B)) [header file](https://en.wikipedia.org/wiki/Header_file) that is compiled into an [intermediate form](https://en.wikipedia.org/wiki/Intermediate_form) that is faster to process for the [compiler](https://en.wikipedia.org/wiki/Compiler). Usage of precompiled headers may significantly reduce [compilation time](https://en.wikipedia.org/wiki/Compile_time), especially when applied to large header files, header files that include many other header files, or header files that are [included](https://en.wikipedia.org/wiki/Include_directive) in many [translation units](https://en.wikipedia.org/wiki/Translation_unit_(programming\)). &gt; --- ^Interesting: [^Single ^Compilation ^Unit](https://en.wikipedia.org/wiki/Single_Compilation_Unit) ^| [^Prefix ^header](https://en.wikipedia.org/wiki/Prefix_header) ^| [^Alphabetical ^list ^of ^filename ^extensions ^\(F–L)](https://en.wikipedia.org/wiki/Alphabetical_list_of_filename_extensions_\(F%E2%80%93L\)) ^| [^Alphabetical ^list ^of ^filename ^extensions ^\(M–R)](https://en.wikipedia.org/wiki/Alphabetical_list_of_filename_extensions_\(M%E2%80%93R\)) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cloxhpb) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cloxhpb)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
Please highlight modules too
Also please highlight a good macro system. There are so many things that can't be automated right now at compile time but can't due to the lack of such a system. 
The correct approach for a macro system would be c++ code that gets called from the compiler on the AST, after the translation unit has been parsed. Let's say we want to add our own reflection information for a class. This is something quite useful, and many libraries do it by using macros and external tools (Qt and UE4, for example). Suppose we have this class: Class Point { Int x; Int y; }; And we would like to automatically create property information for x any y. A good way to do that would be the following: Class Point { [[Property]] Int x; }; Our property macro would be like this: Macro void property(field f) { Cout &lt;&lt; f.get_declaring_type().get_name(); Cout &lt;&lt; f.get_type().get_name(); } Sorry for the typos, i am writing this on a phone. Anyway, the macro function property would be invoked with the ast object that has been created by the compiler and can modify it or add new code to the current ast tree in the form of new ast entries. In this way, the macro system would be legal c++ code, play well with namespaces and all that, but also have the full ability to modify the code as needed. 
The problem is going to be difficult to solve at language level. A lot of the concurrency problems come from the OS. For example, it's hard in Linux to wake on any of: wait condition, mutex unlock or file descriptor wake (select/poll) in a single call. And it's absolutely vital that you can so that you can wait for (say) new socket connections, be woken by an OS signal to check for shutdowns, or be woken by another (say UI) thread for a state change. Windows, while slightly better, has its own different set of problems. It's doable, but I'm not sure how you would do it in a way that would be justifiable in a standard library.
I had no idea there are different versions out there: &gt; For users of the Professional or Enterprise edition, we added experimental support for running the Clang Static Analyzer on your projects, as a new tool in Analyze mode. Can someone explain how Qt's distribution model works exactly? There's a open source version, but apparently it has less features than the others? What features is the open source version missing?
Not sure what you mean with Person including the logging object and TMP. You can take a closer look at the full proposal if that helps: http://blog.biicode.com/file-based-cpp-dependency-manager/ 
I REALLY hope we get modules in c++17, simply because it's not something I can do at all right now. Better parallelism/concurrency would be nice, but I can get by with just std::thread. ConceptsLite is going to be very nice, but again, I can currently get by with `enable_if` and `void_t`. Modules adds something new that, in my opinion, is surely needed.
https://github.com/apenwarr/redo You can construct a similar system within redo. This is definitely the better way for things to work.
How do we stop the destructor being called on these objects? Is there a way to call `delete` such that the destructor won't be called, but the memory itself will be freed? Or is it assumed that this will be used only in situations where you are managing memory allocation yourself and you can do everything correctly yourself?
Also in lambdas and inline classes :(
That's the current policy. But in the n4034 proposal, there is as a postcondition to `destructive_move`: &gt; Postconditions: `*to` (after the call) is equivalent to (i.e., substitutable for) `*from` before the call except that it has a different address. The lifetime of `*from` is ended (but from still points to allocated storage). [Note: To avoid invoking the destructor on the destroyed object, from should not point to an object with automatic storage duration. – end note] We must, somehow, ensure the destructor is not called on an object that is destructive-moved from.
That will compile, but the behavior is undefined so it doesn't "work" in any meaningful way.
&gt; Also: Passing the launch-policy explicitly is only needed, because of libstdc++'s and libc++'s extremely poor implementation of std::async. Maybe that should be mentioned too. With libstdc++ and libc++ the default policy (`launch::deferred | launch::async`) behaves the same as `launch::async`. So if one desires the policy to be strictly `launch::async` on all platforms then the reason one has to manually specify `launch::async` is that some platforms implement the default `launch::deferred | launch::async` as doing something different from `launch::async`. Whatever you think about treating `launch::deferred | launch::async` identically to `launch::async`, there's no way you can blame libstdc++ or libc++ for users needing to write `launch::async` when they really want the `launch::async` behavior. Furthermore, VC++'s thread pooling implementation of `launch::deferred | launch::async`, which I presume is what you're thinking of as a good implementation, has the unfortunate property that it may not actually be reasonably implementable under constraints imposed by C++'s requirements for destruction of objects of thread storage duration. I believe VC++ doesn't yet support thread local objects with destructors, so so far it hasn't been a problem for them. Clang and gcc, of course, both do support thread local destructors.
Here's an example where you new up an object, do something to it that invokes dmove, and then deallocate the memory allocated by `new` without calling the destructor: Foo *x = new Foo(); some_consuming_function(std::move(*x)); // invokes dmove, *x is not destructible after this operator delete(x); // deallocates memory without calling destructor But the question really is, how do you stop the deallocator from being called when the compiler is responsible for the destruction: { Foo f; if (rand() % 2) { some_consuming_function(std::move(f)); // invokes dmove, f is not destructible } else { some_copying_function(f); } // implicit f.~Foo() } Even if the compiler figures out how to do the destruction just when allowed in this case there will always be a case where we can sufficiently 'hide' the dmove so that the compiler can't figure it out. Fortunately, the proposal avoids this by not proposing any implicit dmove behavior. Instead it just proposes library features that provide a common interface for destructive move.
Can we stop saying 'The new C++11 features' they're not new, they're not even the current standard.
I hate "two state" classes, because they tend to let broken program state to creep in, and that tends to rear its ugly head when things go wrong. The other name for two-state is two-phase initialization, BTW. I believe that this is more and more frowned upon in C++, simple because it violates the "don't make me think" design principle. I also dislike your initialization example, I prefer e.g: Foo createFrom(const Bar&amp; params) { switch (params.something) { case pfft: return something(); // etc } } And then Foo x = from(someBar); I prefer this because it tends not to jumps and down the "logical" abstraction ladder: when working with x, y and z, I prefer not to clutter their use with their construction, I rather want to see how they are combined to produce whatever result is needed. As for move semantics, they are, above all, about the optimization of copying. That works rather well for types who naturally have the "empty" state (containers, strings being the prime example). For types who don't have it, less so. But then again, we used those just fine by making them non-copyable up until C++11, and they can stay that way. If move is added to those, it should IMNSHO be used exclusively to "sink" them around.
The other solution is to have a 1 state class, and use `boost::optional` (unfortunate that it was not standardized eh?)
&gt; As far as I can tell, there's no good reason to have a std::unique_lock without a mutex, except for the ability to have a decent move constructor or assignment. If you do a .wait() on a condition variable the unique_lock won't own the associated mutex while the thread is blocked by the condition variable. AFAIUI.
Ah right - I thought you were talking about the .owns_lock() method. You are right of course. I'm guessing the associated or not is so that we can express "I will at some point be associated with a mutex, but don't know which one it will be". I can envision it being useful for a plugin loadable driver, or something like that. Why you'd do that rather than hide the locking behind an API, I'm not sure. Maybe it works nicely with a mutex in shared memory, for example. 
Not sure I see the advantage of destructive_move, also seems to me like it introduces needless complexity to the language, consider: std::string s = ...; std::string y; if(condition) { y = std::destructive_move(s); } else { y = std::move(s); } f(y); So now the compiler needs to add additional checks to determine whether y was destructively moved or not in order to call the destructor, rather than being able to deduce it statically. As an even more complicating example, consider: std::string y; f(y); // y is passed into f by reference. // We don't know at this point whether y was destructively moved or not.
I was sort of assuming it was so you could do code like this: { std::unique_lock&lt;std::mutex&gt; outerLock; //No associated mutex { std::unique_lock&lt;std::mutex&gt; innerLock(mutex); //Mutex is locked here outerLock = std::move(innerLock); //outerLock is associated with Mutex, innerLock becomes unassociated. } } //Mutex is unlocked here...up one scope. Now this is a pretty contrived example, and I can't think of an easy use off of the top of my head. But it's nice if you need it, and it's exactly the kind of pattern I was talking about with the two state objects above. I like to avoid them, but I'd rather have them and proper move semantics then not have them at all.
I really hope this gets accepted and implemented. I am so sick to death of bouncing between functions and methods, and the issues with dependancies in classes. Driven by this one issue i've, been looking into the Rust language (with its' impls'). This feature in C++ would be a lot easier than getting a whole new language (although there are other nice things about rust)
there should be no distinction. Methods are superior for chaining expressions together, and discovery via IDE autocomplete; free functions are superior for decoupling, because they don't introduce dependancies into classes. You should not have to choose one or the other. You should have both routinely available. in my perfect world there would be no methods; just overloaded free functions, all callable with a.f(x) sugar, and something else for declaring vtables (which just gather the free functions)
its' really with C++ overloaded free functions where it comes into its' own IMO; free functions are often a better choice than methods.. with this you get the best of both
I like these and wish they didn't uglify headers so much. I wanted to use them for structures that can generate pretty-printing and parsing functions automatically, but they unfortunately cause the struct/enum defs to look too different than what programmers are used to.
Alternative for g++ : https://gcc.gnu.org/onlinedocs/libstdc++/manual/parallel_mode.html
I know i am missing spaces in the three last lines, but i have no idea how to fix..
The only reason you'd want to pass a unique_ptr as a function parameter is if you wanted to take ownership of the object - for which you need it to be non-null.
Thank you for posting this link, I've been looking for it again. This is a great consolidation of the C++ general guidance post teh CppCon2014 from the C++ commitee chair.
&gt; Eventually they will die. Once we have language features for every case where they are used. Good riddance. The strong safety guarantee is one of the greatest features of C++ over C. When you can rely on today's optimizing compilers to choose the best course of type evaluation then you can generally assume a better outcome than when human designers solely take charge. I, for one, welcome our new non-polluting overlords.
Well, by mistake. Admittedly this is something that maybe happened once to me, so it's more of a theoretical "it would be nice to make it impossible" thing. However, as there is no reason to it kind of proves my point... Why is it good to allow it then? But the main idea is to discourage to use raw pointers directly, the unique_ptr thing is more of a consequence of it.
Can we get a decent cross platform parallelisation solution yet? OpenMP comes closest but still doesn't have GPU acceleration support. As well as the aforementioned solutions we have PPL, C++ AMP, OpenACC and the low level CUDA and OpenCL to name a few.
It's worth it though
You could have, this use case is one of the ones where it wasn't terribly broken. And honestly, I don't find the lambda -&gt; recursion substitution that much better.
I don't know of any way, but there's not too much lost in just doing it yourself: struct Fixture { Foo foo; Bar bar; }; BOOST_FIXTURE_TEST_CASE(my_test, Fixture) { //Do stuff with foo; //Do stuff with bar; } vs: template&lt; class T &gt; struct Fixture { Foo&lt;T&gt; foo; Bar&lt;T&gt; bar; }; BOOST_AUTO_TEST_CASE_TEMPLATE(my_test, MyType, MyTypes) { Fixture&lt;MyType&gt; f; //Do stuff with f.foo; //Do stuff with f.bar; } Or, if you're really worried about not prefixing your types with `f.` template&lt; class T &gt; struct Fixture { Foo&lt;T&gt; foo; Bar&lt;T&gt; bar; void runTest() { //Do stuff with foo; //Do stuff with bar; } }; BOOST_AUTO_TEST_CASE_TEMPLATE(my_test, MyType, MyTypes) { Fixture&lt;MyType&gt;().runTest(); } 
Same here. You can register, if you haven't yet, and vote for the issue. 
&gt; I don't know of any way, but there's not too much lost in just doing it yourself: That's also the case with test case templates, and Boost Test offers a convenience macro for that purpose anyways. If Boost Test offers this functionality for test case templates, I assumed there wasn't a reason to leave test fixtures out.
I haven't seen a few of the functional concepts in this library in C++ before! * http://pfultz2.github.io/Fit/doc/html/infix/ * http://pfultz2.github.io/Fit/doc/html/pipable/ Though, I'm not a fan of using adaptors for things like partial application. "If the function can not be called with all the parameters, it will return another function." So if I... auto sum = [](int x, y){ return x + y }; auto ten = partial(sum)(1,2,3,4); Since `sum` can't be invoked with four arguments, won't `ten` be a function that can never be invoked?
In your person.cpp: #include "log.h" In your person.h: #include "my_traits.h" In project 1, getting person.h must also pull in person.cpp (or you'll get undefined symbols). Thus you end up pulling in the logging framework and TMP you happened to use in 1 particular project which may not be relevant for project 2 (or maybe it is - who knows). It's certainly fast from an iteration perspective, but it also sucks because you're effectively just duplicating the code. And what happens when that code necessarily diverges?
With the modular compilation model, would the current issue of circular dependencies be in headers be fixed? (ie module a uses module b and vice versa, but they can still be compiled without using any forward declaration BS, maybe through some kind of lazy symbol resolution?) 
The code you have before can take advantage of the same things without C++11 - your pre-C++11 insert &amp; search take pointers where you compare against null whereas your C++11 insert &amp; search take references. There's no reason your pre-C++11 code doesn't do the same thing. Better yet, changing insert &amp; search into member-functions might make things even clearer.
Quality content by Olve Maudal, as always. I couldn't find any videos, but even though the PDF has over 200 slides, it's not condensed content. The slides behave just as if it were a movie if you press "next page".
As far as I understand import is not like include a directive for the preprocessor. This means that each module is compiled separately, and then the linker will link the modules together (IMHO).
I like some of the ideas in the library. I disagree with some names (`fit::lazy` which is essentially `std::bind` - why lazy?). And you really have to work on docs verbosity (I mean, most of them aren't verbose at all) and fix some grammar mistakes. I still try to understand what `fit::protect` does and how it might be useful. ;) I also noticed that most adaptors in fact return something like `foo_adaptor&lt;T&gt;` and they're described nowhere (or I missed the description). What are the properties of these foo_adaptors besides being implicitly convertible to `T` which is quite obvious from the examples?
Something like pipable can be found in Boost (no suprise - Boost contains everything ;)): [boost::range adaptors](http://www.boost.org/doc/libs/1_47_0/libs/range/doc/html/range/reference/adaptors/introduction.html). Recently Eric Niebler wrote a [standard proposal](https://ericniebler.github.io/std/wg21/D4128.html#range-adaptors-are-lazy-algorithms) which also includes the above. About infix, there's also a library available on a [github](https://github.com/klmr/named-operator). Although I'd probably kill someone who'd use either of these. ;)
Wow. When I saw the infix syntax, I thought, "what is this voodoo‽" &gt; constexpr auto operator&lt;( ... Oh. Clever.
I only make a function a member when the function is closely tied to the class's internal state. This makes the class's interface minimal, leaving behind only the essentials that are needed to understand what the purpose of the class is. It also allows the class to be reused in many different contexts without its interface getting cluttered. In OP's case, I think it makes sense to make search and insert global functions.
It depends on a lot of things, like OS, load, and disk type. On windows, with not much else going on, to either disk or SSD, my experience is that it doesn't get much faster than a simple fwrite of a large array. EDIT: also, keep in mind that things like memory alignment and block size can make a HUGE difference here. You'll have to experiment a lot. On the other hand, you might be able to use some OS-specific functionality to get better/different features. For example, if you don't need the file's contents to be updated immediately after writing to it, in some cases it's faster to use a memory mapped file (e.g. MapViewOfFile ) that you simply memcpy into. Then you just let the OS handle the cache flush whenever it gets around to it. From your point of view, writing the file is as fast as memory access. 
&gt; Since sum can't be invoked with four arguments, won't ten be a function that can never be invoked? Yes, unfortunately. I have some ideas to try and help with that. Perhaps have a `final` utility that will either return the correct result or do forensics if it still is a partially applied function. Or there could be a `limit` function adaptor that limits the number of arguments and if they get called with more there is a hard error.
&gt; My suggestion would be to make partial a regular function I dont see how that would help. You would still have the same problem.
&gt; They are not necessarily implicitly convertible to T. Hopefully, I don't have an example showing that. No, it's just me not seeing a few brackets in your examples. :) &gt; Maybe that part needs to be documented better, but I'm not sure how to show it. Maybe you should document adaptors, not functions producing adaptors. Example: instead of `fuse` document `fuse_adaptor` like this: Definition: template&lt;typename FOType&gt; class fuse_adaptor; FOType requirements: template&lt;typename FORetType, typename Args...&gt; FORetType operator()(Args...) const; // or equivalent Member functions: * (constructor) * (destructor) * FORetType operator(std::tuple&lt;Args...&gt;) Factory function: template&lt;typename FOType&gt; fuse_adaptor&lt;FOType&gt; fuse(FOType f) EDIT: As I wrote above example I wondered how is it possible for your library to be C++11 compatible and yet it has auto return type deduced so nicely in your examples. And let me tell you: I absolutely love your hack :D #define FIT_RETURNS(...) -&gt; decltype(__VA_ARGS__) { return __VA_ARGS__; } static_assert(true, "") template&lt;class T&gt; constexpr auto operator()(T &amp;&amp; x) const FIT_RETURNS ( //... ); I think that it's `FIT_RETURNS` in a new line that did it for me, ;)
Please fix the spelling mistake (Behavoir -&gt; Behavior), its kinda painful to look at. 
thanks, fixed. Was on this, but a few survived...
You might want to look at using something other than just "write some stuff to disk using open() and write()". For example, SQLite [strongly targets](https://www.sqlite.org/appfileformat.html) that idea. Richard Hipp, SQLite's original author, discussed that in [this years TCL keynote](http://www.eurotcl.tcl3d.org/presentations/EuroTcl2014-Hipp-SQLite.odp). By making creating use of transaction size and possibly [touch some other settings](http://www.sqlite.org/faq.html#q19), you can make SQLite perform breathtakingly fast. It also has the benefit that it's binary on-disk, but you can continue to manipulate everything via whatever makes you comfortable.
Look at my post above about SQLite. Among other things: &gt; I want to be logging this at some fraction of the compute frequency - likely something like one snapshot per 10 computes, but potentially as high as 1 per 1. What you really want to do is be writing to SQLite and just running a COMMIT once in every while.
But how do we know if it has too little arguments or too many? &gt; If partial() returns a regular function object we get a compile error at (1), and if it returns an adaptor, we get one at (2). I dont really understand your example. Also, an adaptor is a regular function object. I dont understand the difference.
http://olvemaudal.com/talks/ &gt; tfw no video ;s; However there's a link for his Insecure Coding talk at NDCOslo2014 http://vimeo.com/channels/ndc2014/97505677 Maybe someone can find out from him directly if this Thales Norway, Competence Day talk was video'd? If so I'd like to see it as well.
&gt; If you have suggestions, or can point out the typos, let me know. Thanks. Okay. &gt; Fit is an header-only C++11 library "An" and "a" being used incorrectly is a pet peeve of mine, and is rather difficult for me to ignore in written text. I can't think of any English accents where "header" starts with a vowel sound, since the "h" should not be silent. Therefore, Fit is _a_ header-only C++11 library.
Done. :-)
While I mostly agree, RAII should always be one of the first things taught. No matter the level of the course, it's a fundamental idea in C++. But still, if you're trying to show how a bst works, things like lambdas aren't helping, though the code is technically cleaner. It depends on what kind of course/level it is at though (haven't checked the video and where/if it fits in a series of topics).
I also hate blame cultures like Crazy__Eddie. Theyre horrible for morale and people just start using cover your ass techniques. Take a look at articles on how the space shuttle software was written. There, bugs are everyones fault, and everyone comes together to fix them. In addition, they review their process and change it so that bugs have a harder time getting into the code, from the spec write through to the testing. 
Im a huge fan of the in person code reviews with 1 other reviewer having done both at different places. I like the immediacy, the fact that its directed by the person that made the change (though the reviewer sometimes will direct it to, it just depends). I think the social aspect of this works better to align peoples coding styles (not just textual, but how you conceptually solve problems, which is the important part of coding styles). Itd be less easy at a place with lots of remote people of course. Ide have to ponder ways to make that doable. 
Well, that's only an issue with poorly written macros (and poorly written code, by extension). The above problem is trivially "fixed" by tweaking the syntax slightly: #define LOG(x) { const auto&amp; result = x; if (result) { printf("%s", result); }} LOG(some_function()); 
most examples here could be rewritten. But the fact that the compiler can inline the call if something to keep in mind. With your macro, you will always create a temporary variable.
See this question: https://stackoverflow.com/questions/2160920/why-cant-we-declare-a-stdvectorabstractclass
typelists or boost::mpl::list http://stackoverflow.com/questions/10910584/assembling-a-compile-time-list-of-types-one-by-one-c
It has every feature that could possibly be mashed into it, without deriving any common ground from any of them! Buy now!
*edit* What's with the downvotes? Did I misunderstand the question? I would've used a vector of shared_ptrs. They would be automatically freed when they're no longer needed. #include &lt;iostream&gt; #include &lt;string&gt; #include &lt;memory&gt; #include &lt;vector&gt; class IF { public: virtual std::string str() = 0; }; class A : public IF { public: std::string str() { return "A"; } }; class B : public IF { public: std::string str() { return "B"; } }; int main() { std::vector&lt;std::shared_ptr&lt;IF&gt;&gt; list = {std::make_shared&lt;A&gt;(), std::make_shared&lt;B&gt;(), std::make_shared&lt;A&gt;(), std::make_shared&lt;A&gt;()}; for(auto l : list) std::cout &lt;&lt; l-&gt;str() &lt;&lt; std::endl; return 0; }
Not sure where you got this impression from. HPX aligns itself 100% with what the C++11/C++14 standards have and follows the proposals for the next standard closely. All of this extended to the distributed use case. There are only very few things beyond that.
My implementation using C++11: https://github.com/zxmarcos/cpp11-bst/blob/master/btree.h 